<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ko" datatype="htmlbody" original="opentsdb">
    <body>
      <group id="opentsdb">
        <trans-unit id="42e8a8eb0dbceb59c44012721ad8075ac321a31d" translate="yes" xml:space="preserve">
          <source>Example Multiple Data Point Put</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1deb45ecf6c13cc6eb49d35426e1e9a662b73de3" translate="yes" xml:space="preserve">
          <source>Example POST Create Request</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ac60c7d7f94a76093cc8f9700df080b4aa4f08f" translate="yes" xml:space="preserve">
          <source>Example POST Edit Request</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf538b505e2f8e680d2bf0f380f6192c26629160" translate="yes" xml:space="preserve">
          <source>Example POST Request</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60f05c642281aff167194ef905807306b949426d" translate="yes" xml:space="preserve">
          <source>Example POST or PUT Request</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3005e19577780108a8b4e679ad143638639bebdf" translate="yes" xml:space="preserve">
          <source>Example POST/PUT Request</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b88a5e62eac97f29700e08fa77e1657dd464bea9" translate="yes" xml:space="preserve">
          <source>Example POST/PUT Response</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="74d63ee8d8b5272d3ccf34a8464ac0b402e3263b" translate="yes" xml:space="preserve">
          <source>Example Query String Request</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="631f63e855f4012e44366ec6616888570ec12442" translate="yes" xml:space="preserve">
          <source>Example Query String Requests</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86d13d5d9ffe3261b6f7da235e67c6cab35d6d21" translate="yes" xml:space="preserve">
          <source>Example Request</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fabe692d6e0b9a1be974f6b5efc44a48cd61f362" translate="yes" xml:space="preserve">
          <source>Example Request:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="438b5e83eed686f43b4ef55607c0fd4c1852b682" translate="yes" xml:space="preserve">
          <source>Example Requests and Responses</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7490fb58b2e77d8b7794135a76342afd3dc41b53" translate="yes" xml:space="preserve">
          <source>Example Response</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abf3d6b2d941e118e275c1dd4cb16389ca78fbaa" translate="yes" xml:space="preserve">
          <source>Example Response With Details</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61614bffdb27e421543d7450cd46d964a16e3def" translate="yes" xml:space="preserve">
          <source>Example Response with Summary</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2534fc4cd371f731b61cc6c6a209a0ff9ebfa52b" translate="yes" xml:space="preserve">
          <source>Example Response:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c11d48d15a104537c041c015d0e839c6252ee77" translate="yes" xml:space="preserve">
          <source>Example Responses</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b32f46cccfa8c2aa828ca28c754f84f708abd19" translate="yes" xml:space="preserve">
          <source>Example Root GET Query</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f4657b86bd642f0d5c3ed82f1e64d5f08d543d5" translate="yes" xml:space="preserve">
          <source>Example Single Data Point Put</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57dc7b883e6e8359c59c651c4ca1011026e95800" translate="yes" xml:space="preserve">
          <source>Example TSUID GET Request</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a25837379daa43baa478f75cf34eaa075af66af1" translate="yes" xml:space="preserve">
          <source>Example With Show Summary and Query</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c63737abd7347a7ae582cb9fbdf37d6c0e5b251e" translate="yes" xml:space="preserve">
          <source>Example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb01bf04c9a0e8a71c45816513df424f1c7ffedb" translate="yes" xml:space="preserve">
          <source>Examples</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ea76fe1c74ac9e2846d0e7caa5682a6c11e691f" translate="yes" xml:space="preserve">
          <source>Examples include &lt;code&gt;2013/01/23-12:50:42&lt;/code&gt; or &lt;code&gt;2013/01/23&lt;/code&gt;. Formatted times are converted from the default timezone of the host running the TSD to UTC. HTTP API queries can accept a user supplied time zone to override the local zone.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20049bc069b0a04404c23d571b5e0b56f0660c02" translate="yes" xml:space="preserve">
          <source>Exception</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d69596fca7661daec8469daa2de230f434836e53" translate="yes" xml:space="preserve">
          <source>Execution priority for the thread</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a1e71b36d4b469d2c9ce206baa43befc3443c5dc" translate="yes" xml:space="preserve">
          <source>Expanding on the metric examples above:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31085149a29caa582afa845f4c5156358fdd477e" translate="yes" xml:space="preserve">
          <source>Explicit Tags</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15ea18044920350d391c460b6b67518889e0aee8" translate="yes" xml:space="preserve">
          <source>Expressions - Query time computations using time series data. For example, dividing one metric by another.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4843de3d1f355a8c702bfcba6bb1d134bac37401" translate="yes" xml:space="preserve">
          <source>FSCK - An updated FSCK utility that iterates over the main data table, finding and fixing errors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="97cdbdc7feff827efb082a6b6dd2727237cd49fd" translate="yes" xml:space="preserve">
          <source>False</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e852e130909023ba0ed41bc99491ec8cb79176c" translate="yes" xml:space="preserve">
          <source>Field (value)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aae2da294e748510b8f34a37a1971b9e8c9991bb" translate="yes" xml:space="preserve">
          <source>Field Name</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd1bb10a7b8d492ff3e11b47052a7c1ecf0f9240" translate="yes" xml:space="preserve">
          <source>Fields for a bulk delete request are defined below:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba2a62842c14be861a16d27d30f3a7d0f22da1a2" translate="yes" xml:space="preserve">
          <source>Fields for posting or updating annotations are documented at &lt;a href=&quot;index&quot;&gt;&lt;em&gt;/api/annotation&lt;/em&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09699d405557536307d8bbb523d9b9f9c7c10ad0" translate="yes" xml:space="preserve">
          <source>Fields found in the response include:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5da448ed1aa1226618f1ef99ad0d85862c28e0f" translate="yes" xml:space="preserve">
          <source>Fields present in &lt;code&gt;summary&lt;/code&gt; or &lt;code&gt;detailed&lt;/code&gt; responses include:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7e0c7e8f7f472d8c21125da0bd862d36afcdaac" translate="yes" xml:space="preserve">
          <source>Fields returned with the response include:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4c06c05ee7df5ab8574fd70259359b7a76c1117" translate="yes" xml:space="preserve">
          <source>Fields that can be supplied with a request include:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83cab9651541d6505641439c0f1356ce8d3d088c" translate="yes" xml:space="preserve">
          <source>File Locations</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99105c630799800a47cbb5b0df1b9cec9151a7fa" translate="yes" xml:space="preserve">
          <source>Fill Policies</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b158af4bd77784a1efb8c5321fed7ccff0c38256" translate="yes" xml:space="preserve">
          <source>Fill Policy - Enable emitting NaNs or Nulls via the JSON query endpoint when data points are &quot;missing&quot;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96e578211aa295317cf257310712fa28ccd8f6c6" translate="yes" xml:space="preserve">
          <source>Filters</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c252395aed84f1d75df62393be892caf7017f7c8" translate="yes" xml:space="preserve">
          <source>Filters are for selecting various time series based on the tag keys and values. At least one filter must be specified (for now) with at least an aggregation function supplied. Fields include:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dcdd673713d141c411565cd7fdee8f4be7536d4b" translate="yes" xml:space="preserve">
          <source>Filters the time series emitted in the results. Note that if no filters are specified, all time series for the given metric will be aggregated into the results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca9154ad9a0ac20f55a6852e0fd8dd72ee07ada5" translate="yes" xml:space="preserve">
          <source>Filters using POSIX compliant regular expressions post fetching from storage. The filter uses Java's built-in regular expression operation. Be careful to escape special characters depending on the query method used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f392ca4ac00a9eac07b85c697b8d8f15c958eff" translate="yes" xml:space="preserve">
          <source>Find or create the proper directory under &lt;code&gt;third_party/&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87f2527ac2186504d9ed239b48c2b8f00cecbd77" translate="yes" xml:space="preserve">
          <source>Find the &lt;code&gt;&amp;lt;dependencies&amp;gt;&lt;/code&gt; XML section</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c834e88c2e9a415536d3eba510bf52d947c46f0" translate="yes" xml:space="preserve">
          <source>Find the &lt;code&gt;pom.xml: pom.xml.in Makefile&lt;/code&gt; line in the file</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="035b0068125a70f1506f82646127defb1b15fadc" translate="yes" xml:space="preserve">
          <source>Find the &lt;code&gt;tsdb_DEPS = \&lt;/code&gt; line</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7df188f2c595233b41c433cfa5136e5a27965127" translate="yes" xml:space="preserve">
          <source>Find the canonical source to download the dependent JAR file</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7847d1c2d514f27e310c74fb667013b83f72638" translate="yes" xml:space="preserve">
          <source>Fire up Eclipse or your favorite IDE</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c1dd204752ba2478bf550c677ce5bd5bbd62f1b" translate="yes" xml:space="preserve">
          <source>First &amp;amp; Last</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0986d744840d2eddf0d364d3938cc5b73c5b0e63" translate="yes" xml:space="preserve">
          <source>First, pick one of the metrics and put that in the &lt;code&gt;Metric&lt;/code&gt; box. For example, &lt;code&gt;proc.loadavg.1m&lt;/code&gt;. As you type, you should see auto-complete lines pop up and you can click on any of them.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39aa9ee47866c0f5ed1d61d509f27ddd22f43e73" translate="yes" xml:space="preserve">
          <source>First, you must create the &lt;code&gt;tsdb-tree&lt;/code&gt; table in HBase if you haven't already done so. If you enable tree processing and the table does not exist, the TSDs will not start.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21469d5d5ace823e59f0dff39e9698b5532c62cf" translate="yes" xml:space="preserve">
          <source>First, you need to setup HBase. If you are brand new to HBase and/or OpenTSDB we recommend you test with a stand-alone instance as this is the easiest to get up and running. The best place to start is to follow the &lt;a href=&quot;https://hbase.apache.org/book/quickstart.html&quot;&gt;Apache Quick Start&lt;/a&gt; guide. Alternatively you could try a packaged distribution such as &lt;a href=&quot;http://www.cloudera.com/content/cloudera/en/products-and-services/cloudera-express.html&quot;&gt;Cloudera's CDH&lt;/a&gt;, &lt;a href=&quot;http://hortonworks.com/products/hdp-2/&quot;&gt;Hortonworks HDP&lt;/a&gt; or &lt;a href=&quot;#id2&quot;&gt;&lt;span id=&quot;id3&quot;&gt;`MapR&amp;lt;https://www.mapr.com/&amp;gt;`_&lt;/span&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99a423164819c464ad91761b94c3e9df171d91a1" translate="yes" xml:space="preserve">
          <source>Fix</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a774409a00c21de377cf8ed5c6a56b8547973042" translate="yes" xml:space="preserve">
          <source>Flag</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64435fd82de7b1d614dfb9844848a48b14c6cd2c" translate="yes" xml:space="preserve">
          <source>Float</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4961d422ae1e1f2124f216a51f1baa1ad8676222" translate="yes" xml:space="preserve">
          <source>Floating Point Values</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="977fc0033df80714e079fadaa81f36d90c440334" translate="yes" xml:space="preserve">
          <source>Follow the steps in &lt;a href=&quot;https://cloud.google.com/bigtable/docs/creating-cluster&quot;&gt;Creating a Cloud Bigtable Cluster&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="831990ed5c61e7674b6cf184578d19bda0d6d050" translate="yes" xml:space="preserve">
          <source>Follow the steps in &lt;a href=&quot;https://cloud.google.com/bigtable/docs/hbase-shell-quickstart&quot;&gt;HBase Shell Quickstart&lt;/a&gt;, paying attention to where you download your JSON key file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e5b9be444e281f8790d9c768462affa86110546" translate="yes" xml:space="preserve">
          <source>For URI queries, the type precedes the filter expression in parentheses. The format is &lt;code&gt;&amp;lt;tagk&amp;gt;=&amp;lt;type&amp;gt;(&amp;lt;filter_expression&amp;gt;)&lt;/code&gt;. Whether or not results are grouped depends on which curly bracket the filter is in. Two curly braces are now supported per metric query. The first set is the &lt;em&gt;group by&lt;/em&gt; filter and the second is a &lt;em&gt;non group by&lt;/em&gt; filter, e.g. &lt;code&gt;{host=wildcard(web*)}{colo=regexp(sjc.*)}&lt;/code&gt;. This specifies any metrics where the colo matches the regex expression &quot;sjc.*&quot; and the host tag value starts with &quot;web&quot; and the results are grouped by host. If you only want to filter without grouping then the first curly set must be empty, e.g. &lt;code&gt;{}{host=wildcard(web*),colo=regexp(sjc.*)}&lt;/code&gt;. This specifies nany metrics where colo matches the regex expression &quot;sjc.*&quot; and the host tag value starts with &quot;web&quot; and the results are not grouped.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd20e471b0c467fceb6c617f71de758e78cce615" translate="yes" xml:space="preserve">
          <source>For a complete list of downsample &amp;amp; aggregation modes, see &lt;a href=&quot;../query/aggregators#available-aggregators&quot;&gt;http://opentsdb.net/docs/build/html/user_guide/query/aggregators.html#available-aggregators&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d7f3f2b6ebc69b9acf3858d421f67146d6fd8db" translate="yes" xml:space="preserve">
          <source>For additional parameters used for tuning the AsyncHBase client, see &lt;a href=&quot;http://opentsdb.github.io/asynchbase/docs/build/html/configuration.html&quot;&gt;AsyncHBase Configuration&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1194ed3bc051e338585b059eeb2f1e5fb7199518" translate="yes" xml:space="preserve">
          <source>For brand new installs you will see much better performance if you pre-split the regions in HBase regardless of if you're testing on a stand-alone server or running a full cluster. HBase regions handle a defined range of row keys and are essentially a single file. When you create the &lt;code&gt;tsdb&lt;/code&gt; table and start writing data for the first time, all of those data points are being sent to this one file on one server. As a region fills up, HBase will automatically split it into different files and move it to other servers in the cluster, but when this happens, the TSDs cannot write to the region and must buffer the data points. Therefore, if you can pre-allocate a number of regions before you start writing, the TSDs can send data to multiple files or servers and you'll be taking advantage of the linear scalability immediately.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2de08637338025b3f30822fed9e319ca26b5b3f7" translate="yes" xml:space="preserve">
          <source>For complex queries with multiple values, each type is &lt;code&gt;AND&lt;/code&gt;'d with the other types and &lt;code&gt;OR&lt;/code&gt;'d with it's own type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06ddefcd6ceafe843f0571c2923294d859b0fb8b" translate="yes" xml:space="preserve">
          <source>For debugging a rule set, the test endpoint can be used to run a TSMeta object through a tree's rules and determine where in the heirarchy the leaf would appear. Or find out why a timeseries failed to match on a rule set or collided with an existing timeseries. The only method supported is &lt;code&gt;GET&lt;/code&gt; and no changes will be made to the actual tree in storage when using this endpoint.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="324e19211c4a905de814c832063b1a4104ecd213" translate="yes" xml:space="preserve">
          <source>For debugging purposes, you can ask for the response to include a summary of how many data points were stored successfully and failed, or get details about what data points could not be stored and why so that you can fix your client code. Also, errors with a data point will be logged in the TSD's log file so you can look there for issues.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e528cdb4772e636e8e19376225f08137615d419e" translate="yes" xml:space="preserve">
          <source>For details on crafting a query, see &lt;a href=&quot;../../api_http/search/lookup&quot;&gt;&lt;em&gt;/api/search/lookup&lt;/em&gt;&lt;/a&gt;. The CLI query is similar to an API query but spaces are used as separators instead of commas and curly braces are not used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad1b0d7547148acac5ec3d92b6fa26ffa68ffa0a" translate="yes" xml:space="preserve">
          <source>For early versions of OpenTSDB, the actual time stamps for the new data points will be an average of the time stamps for each data point in the time span. As of 2.1 and later, the timestamp for each point is aligned to the start of a time bucket based on a modulo of the current time and the downsample interval.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8964d55bd87e07ad0a366409d5f685461d73514e" translate="yes" xml:space="preserve">
          <source>For example we can compute &quot;a + b&quot; with a group by on the host field. Both metrics queried alone would emit a time series per host, e.g. maybe one for &quot;web01&quot;, &quot;web02&quot; and &quot;web03&quot;. Lets say metric &quot;a&quot; has values for all 3 hosts but metric &quot;b&quot; is missing &quot;web03&quot;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e3edbe38f8de4d56d56d5e2cd67d19a10162120" translate="yes" xml:space="preserve">
          <source>For example, &lt;code&gt;0100&lt;/code&gt; means the column value is an 8 byte, signed integer. &lt;code&gt;1011&lt;/code&gt; indicates the column value is a 4 byte floating point value So the qualifier for the data point at &lt;code&gt;1292148123&lt;/code&gt; with an integer value of 4294967296 would have a qualifier of &lt;code&gt;0000011110110100&lt;/code&gt; or &lt;code&gt;07B4&lt;/code&gt; in hex.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e69a7cdfe27433b54cc84719cf3bbf1acd43adb5" translate="yes" xml:space="preserve">
          <source>For example, if we have a host tagk with a tagv of &lt;code&gt;web01.nyc.mysite.com&lt;/code&gt;, we could use a regex similar to &lt;code&gt;.*\.(.*)\..*\..*&lt;/code&gt; to extract the &quot;nyc&quot; portion of the FQDN and group all of the servers in the &quot;nyc&quot; data center under the &quot;nyc&quot; branch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76d5801b06c02a6a142bb3be71cbecf9c1285d78" translate="yes" xml:space="preserve">
          <source>For example, take series &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;B&lt;/code&gt; in the first table under &lt;strong&gt;Aggregation&lt;/strong&gt;. The data points cover a 50 second time span. Let's say we want to downsample that to 30 seconds. This will give us two data points for each series:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="914f9247a6bf6b146d4a2c991364552f5310c808" translate="yes" xml:space="preserve">
          <source>For example, the query &lt;code&gt;tsd.hbase.rpcs{type=*,host=tsd1,host=tsd2,host=tsd3}&lt;/code&gt; would return only the time series with the metric &lt;code&gt;tsd.hbase.rpcs&lt;/code&gt; and the &lt;code&gt;type&lt;/code&gt; tagk with any value and a &lt;code&gt;host&lt;/code&gt; tag with either &lt;code&gt;tsd1&lt;/code&gt; or &lt;code&gt;tsd2&lt;/code&gt; or &lt;code&gt;tsd3&lt;/code&gt;. Unlike a data query, you may supply multiple tagks with the same name as seen in the example above. Wildcards always take priority so if your query looked like &lt;code&gt;tsd.hbase.rpcs{type=*,host=tsd1,host=tsd2,host=*}&lt;/code&gt;, then the query would effectively be treated as &lt;code&gt;tsd.hbase.rpcs{type=*,host=*}&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="473c4ecbae758e97908f5828ecb5e6821fec1bb0" translate="yes" xml:space="preserve">
          <source>For example, using the data set above, if we only care about metrics where &lt;code&gt;host=webserver02&lt;/code&gt; and there are hundreds of hosts, you can craft a query such as &lt;code&gt;start=1356998400&amp;amp;m=avg:explicit_tags:sys.cpu.user{host=webserver02,cpu=*}&lt;/code&gt;. Note that you must specify every tag included in the time series for this to work and you can decide whether or not to group by the additional tags.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="059c3e8cce263b2945a18ac90b2637e10a8026b1" translate="yes" xml:space="preserve">
          <source>For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6090ced2abde65a9e0c8a8b9b6836cda7299cdc9" translate="yes" xml:space="preserve">
          <source>For future use, this field can be used to extract user information from queries and help debug who is using a TSD the most. It's fairly easy to modify the TSD code to extract the user from an HTTP header.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27590aaa6b924dff2d49c79e9e255b70c71d4fbb" translate="yes" xml:space="preserve">
          <source>For information on the various sections and data from the stats endpoint, see &lt;a href=&quot;../../user_guide/query/stats&quot;&gt;&lt;em&gt;Query Details and Stats&lt;/em&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eff1ff620adff716b39b3d62b8445683ebcd59c9" translate="yes" xml:space="preserve">
          <source>For metrics or time series with different scales, you can select the &lt;strong&gt;Right Axis&lt;/strong&gt; check box to add another axis to the right of the graph for the metric's time series. This can make graphs much more readable if the scales differ greatly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4fd583b4639484347b03bc44cf09e7b1bdcdc493" translate="yes" xml:space="preserve">
          <source>For more details on querying, please see &lt;a href=&quot;../query/index&quot;&gt;&lt;em&gt;Querying or Reading Data&lt;/em&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8a416a189f9026501a67f58821b4dbb38eae887" translate="yes" xml:space="preserve">
          <source>For more information on storing data in OpenTSDB, please see &lt;code&gt;../writing&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3af0a5983f44eb879efd6da713d031abec8d593a" translate="yes" xml:space="preserve">
          <source>For real-time tree building you need to enable the &lt;code&gt;tsd.core.meta.enable_tracking&lt;/code&gt; setting as well so that TSMeta objects are created when a timeseries is received.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3c9d22143c636f322e4d39fa2a18e7fcd5e2570" translate="yes" xml:space="preserve">
          <source>For scalar fills, an optional value that can be used during substitution</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08d04a58e1e26d45094578d03be1a19fa926d2e3" translate="yes" xml:space="preserve">
          <source>For situations where a TSD crashes before metadata can be written to storage or if you do not enable real-time tracking, you can periodically use the &lt;code&gt;uid&lt;/code&gt; CLI tool and the &lt;code&gt;metasync&lt;/code&gt; sub command to generate missing UIDMeta and TSMeta objects. See &lt;a href=&quot;cli/uid&quot;&gt;&lt;em&gt;uid&lt;/em&gt;&lt;/a&gt; for information.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48e7e86f416f72e25da8221207ea2472545e9bb5" translate="yes" xml:space="preserve">
          <source>For some CLI tools, this command will allow for INFO and above logging per the logback.xml config. Otherwise without this flag, some tools may only log WARNing messages.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f60ab2be6f2f16d48e379425311e3f86a3545f3e" translate="yes" xml:space="preserve">
          <source>For the JSON serializer, the timestamp will always be a Unix epoch style integer followed by the value as an integer or a floating point. For example, the default output is &lt;code&gt;&quot;dps&quot;{&quot;&amp;lt;timestamp&amp;gt;&quot;:&amp;lt;value&amp;gt;}&lt;/code&gt;. By default the timestamps will be in seconds. If the &lt;code&gt;msResolution&lt;/code&gt; flag is set, then the timestamps will be in milliseconds.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="539b3b0bfd8f6b49eeb3d5bc30cb7407e5b47c2e" translate="yes" xml:space="preserve">
          <source>For the Main Class, search for &lt;code&gt;net.opentsdb.tools.TSDMain&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6564bc41548c085c15263c2c730db26b540afe55" translate="yes" xml:space="preserve">
          <source>For the fields and what they mean, see &lt;a href=&quot;../../api_http/query/index&quot;&gt;&lt;em&gt;/api/query&lt;/em&gt;&lt;/a&gt;. Some notes about the fields:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4db5fc3d07fed04c5275e1b9cb905a56dfad676b" translate="yes" xml:space="preserve">
          <source>For the following example, two TSDs were running and the query was: &lt;code&gt;http://localhost:4242/api/query?start=1h-ago&amp;amp;m=sum:tsd.hbase.puts{host=*}&lt;/code&gt;. This returns two explicit time series.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d52b60a641506861149397a7893993ba59ab1694" translate="yes" xml:space="preserve">
          <source>For the most part, these statistics should be self-explanatory. &lt;code&gt;Key Values Processed&lt;/code&gt; indicates the number of individual columns in HBase. &lt;code&gt;VLE&lt;/code&gt; referse to &lt;code&gt;variable length encoding&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="004eaa2f721a92f602d6585b2734b644ce98020c" translate="yes" xml:space="preserve">
          <source>For timestamp &lt;code&gt;ts0&lt;/code&gt; the data points for &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;B&lt;/code&gt; are summed, i.e. &lt;code&gt;5 + 10 == 15&lt;/code&gt;. Next, the two values for &lt;code&gt;ts1&lt;/code&gt; are summed together to get &lt;code&gt;10&lt;/code&gt; and so on. Each aggregation function will perform a different mathematical operation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8de833b1002a4cdd4ef6ebb2ea75d747a52b1238" translate="yes" xml:space="preserve">
          <source>Forward metrics mapping bar -&amp;gt; 000001 is different than reverse mapping: 000001 -&amp;gt; foo</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70f91ba96db5731dffce596c58d9b8b3a97ff81f" translate="yes" xml:space="preserve">
          <source>Forward metrics mapping is missing reverse mapping: foo -&amp;gt; 000001</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec46d2c9cd981c9995786c9501345d0a7eb54493" translate="yes" xml:space="preserve">
          <source>Four options are available, starting with the least impact to the most.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="229b7677e2c311b357d444f88eaa7bde97c57a56" translate="yes" xml:space="preserve">
          <source>Front Ends</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed94395c13549ea66981a73bbfe1b627b1781100" translate="yes" xml:space="preserve">
          <source>Full Table Vs Queries</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b961dea1dc0c60ddf9a2c8e9d090f6f7d082483" translate="yes" xml:space="preserve">
          <source>Functions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d22048f766ce9f1e87388dbab6e65bc817878ea" translate="yes" xml:space="preserve">
          <source>Functions that accept a single metric query will operate across each time series result. E.g. if a query includes a group by on host such as &lt;code&gt;scale(sum:if.bytes_in{host=*},1024)&lt;/code&gt;, and multiple hosts exist with that metric, then a series for each host will be emitted and the function applied. For functions that take multiple metrics, a union is performed across each metric and the function is executed across each resulting series with matching tags. E.g with the query &lt;code&gt;sum(sum:if.bytes_in{host=*},sum:if.bytes_out{host=*})&lt;/code&gt;, assume two hosts exist, &lt;code&gt;web01&lt;/code&gt; and &lt;code&gt;web02&lt;/code&gt;. In this case, the output will be &lt;code&gt;if.bytes_in{host=web01} + if.bytes_out{host=web01}&lt;/code&gt; and &lt;code&gt;if.bytes_in{host=web02} + if.bytes_out{host=web02}&lt;/code&gt;. Missing series in any metric result set will be filled with the default fill value of the function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="040c5373d5621aa737e101cc596fa0199c9dc5ff" translate="yes" xml:space="preserve">
          <source>Future Object</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05b984c7680c660c662ae37a773152687a66b062" translate="yes" xml:space="preserve">
          <source>Future objects are left alone during fsck. Querying over the data with a TSD that doesn't support the object will throw an exception but versions that do support the object should procede normally.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f030bbbd32966cde41037b98a8849c46b76e4bc1" translate="yes" xml:space="preserve">
          <source>GET</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f9b4f6375e2d76aa3b1a242f843ad430cf3a9da" translate="yes" xml:space="preserve">
          <source>GET - Lookup one or more TS meta data</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8926dcca7f66eea0aecefd1e4c4c08649f289c9" translate="yes" xml:space="preserve">
          <source>GET - Query string only</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ce6361cbf22f09d8c0d0ea8a51698b32ac6030a" translate="yes" xml:space="preserve">
          <source>GET - Retrieve a single annotation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af15b002a1973f6c806ef7624184ab996efd051c" translate="yes" xml:space="preserve">
          <source>GET - Retrieve one or more rules</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a430332aec47b6e41ff327b1978e9becc211571b" translate="yes" xml:space="preserve">
          <source>GET - Retrieve one or more tree definitions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db70060e1353cad0958a6d0ba6ea4b37a206e518" translate="yes" xml:space="preserve">
          <source>GET Requests</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa4cef86416f362b892f15c1889c53f14b014a2d" translate="yes" xml:space="preserve">
          <source>GOOGLE_APPLICATION_CREDENTIALS</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75ebc687f6257857cd417c34b00fa35ec1f0c809" translate="yes" xml:space="preserve">
          <source>GUI</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61b5af097b76945e5188a9517fa98db5ee45483c" translate="yes" xml:space="preserve">
          <source>Gauge</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9239ee2cda84eca4c3440e2a7b50148af67da3d4" translate="yes" xml:space="preserve">
          <source>General</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e2549d61177002aa302ae43756c26669a07aec3d" translate="yes" xml:space="preserve">
          <source>General Development</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dbb20357e5bb1af7e6f2d6437e34af3bb4fc8431" translate="yes" xml:space="preserve">
          <source>Generalities</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e21f502d63a6ce0a832723cdf8fe421e1b2a696" translate="yes" xml:space="preserve">
          <source>Generating Rollups and Pre-Aggregates</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a41da041f577a4de3083d99ccda4e60c8b21f53" translate="yes" xml:space="preserve">
          <source>Getting Fancy</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5819778898df55e3a762f0c5728b457970d72cae" translate="yes" xml:space="preserve">
          <source>Git</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f078275340ef5ad40593f96c102481ff656adb7a" translate="yes" xml:space="preserve">
          <source>Given the example set at the top, we may want to look at the total interface traffic by colo (data center). In that case, we can aggregate by &lt;code&gt;SUM&lt;/code&gt; and &lt;code&gt;COUNT&lt;/code&gt; similarly to the rollups. The result would be four &lt;strong&gt;new&lt;/strong&gt; time series with meta data like:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1aa78eb4e06d65423fd30d49bc7d30059efb258b" translate="yes" xml:space="preserve">
          <source>Given the series above, lets store the &lt;code&gt;sum&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; with an interval of &lt;code&gt;1h&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f1184f7df96c5928092ad9c6b550699bf887826" translate="yes" xml:space="preserve">
          <source>Global</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="832788a7c14775bf0aa9434da5b02cfec0a58f30" translate="yes" xml:space="preserve">
          <source>Global stats are printed to the standard log, stats page. The full global, sub query and scanner details are available in the query log and via the query API when &lt;code&gt;showSummary&lt;/code&gt; is present. Timing stats at a lower level are aggregated into max and average values at the upper level. Counters at each lower level are also aggregated at each upper level so you'll see the same counter metrics at each level. A table of stats and sections appears below.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2e41024d46fbd335db45e3f12fb8978eebe10c8" translate="yes" xml:space="preserve">
          <source>GnuPlot 4.2 or later</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d7fecd2d20e3ca40b0619f84d121e2fafc9a177" translate="yes" xml:space="preserve">
          <source>Gnuplot opts</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a63c4054d750d485ad4a58076c2f551183e12cc" translate="yes" xml:space="preserve">
          <source>Google's Bigtable client communicates with their servers over HTTP2 with TLS using ALPN. As Java 7 and 8 (dunno about 9) lack native ALPN support, a &lt;a href=&quot;http://www.eclipse.org/jetty/documentation/current/alpn-chapter.html&quot;&gt;library&lt;/a&gt; must be loaded at JVM start to modify the JVM's bytecode. The build script for OpenTSDB will attempt to detect your JDK version and download the proper version of ALPN but if you have a custom JVM or something other than Hotspot or OpenJDK you may run into issues. Try different versions of the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92911d7e707d6f4c9a9b51364eedc0a895364120" translate="yes" xml:space="preserve">
          <source>Graph - This is the default that lets you issue a query and generate a graph</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6acd98080b50b996a98852f9a1ff5d3e7382294b" translate="yes" xml:space="preserve">
          <source>Graph Style</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e406e8adb11e62c64cf765d118f3ff164d4d98fd" translate="yes" xml:space="preserve">
          <source>Graphing</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fa6e52dad263c6dbb79df880ff102a5176d52ee" translate="yes" xml:space="preserve">
          <source>Graphite Style Functions - Additional filtering and mutation of data at query time using Graphite style functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="18d5ace8621b1d7463c2ed63d0b03e6eae885f41" translate="yes" xml:space="preserve">
          <source>Graphite is an excellent storage system for time series data with a number of built in functions to manipulate the data. To support transitions from Graphite to OpenTSDB, the &lt;code&gt;/api/query/gexp&lt;/code&gt; endpoint supports URI queries &lt;em&gt;similar&lt;/em&gt; but not &lt;em&gt;identical&lt;/em&gt; to Graphite`s expressions. Graphite functions are generally formatted as &lt;code&gt;func(&amp;lt;series&amp;gt;[, param1][, paramN])&lt;/code&gt; with the ability to nest functions. TSD`s implementation follows the same pattern but uses an &lt;code&gt;m&lt;/code&gt; style query (e.g. &lt;code&gt;sum:proc.stat.cpu{host=foo,type=idle}&lt;/code&gt;) in place of the &lt;code&gt;&amp;lt;series&amp;gt;&lt;/code&gt;. Nested functions are supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="171a0606f7c74580fd3982cf57c49d604104120a" translate="yes" xml:space="preserve">
          <source>Group</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ae6967b07a45b63c8543a6c5e34052414ba32af" translate="yes" xml:space="preserve">
          <source>Grouping</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="141d1d74d8a6b3e7a7f1418ef539a53ce746ef34" translate="yes" xml:space="preserve">
          <source>Guidelines</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5dd9519270e42fb31ab2e8f7c1f6446d2ac3cb4c" translate="yes" xml:space="preserve">
          <source>Guidelines When to Create Metrics</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="49b1e0db67ab38a4c28c5af3baaa07d19da30efb" translate="yes" xml:space="preserve">
          <source>HBASE_CLASSPATH</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b04c8e199179ff515d100fb8aa43a4e1d8f59675" translate="yes" xml:space="preserve">
          <source>HBASE_HOME</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b9f457bba25569d1348fca2cf15c6c2da7a6f18a" translate="yes" xml:space="preserve">
          <source>HBase 0.92 or later</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38ba4d2a511e81ad3b13944ddaf5b88c3123a609" translate="yes" xml:space="preserve">
          <source>HBase Schema</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0cb1ab1dc9ae09b748d055778990d1470d15fa90" translate="yes" xml:space="preserve">
          <source>HBase region servers can be collocated with the HDFS data nodes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3f382fac22ac5e99c7a8827ded870b2dc98048c" translate="yes" xml:space="preserve">
          <source>HBase will run in stand-alone mode where it will use the local file system for storing files. It will still use multiple regions and perform as well as the underlying disk or raid array will let it. You'll definitely want a RAID array under HBase so that if a drive fails, you can replace it without losing data. This kind of setup is fine for testing or very small installations and you should be able to get into the low thousands of data points per second.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="368a8d5b9f0f92c791e9aa9169513fea68b43043" translate="yes" xml:space="preserve">
          <source>HTML - If a request is bad or there was an exception, the response will often be in HTML, hard-coded and not using templates</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c76df737782a8dc75169ed775fd7d6d4018f0bb" translate="yes" xml:space="preserve">
          <source>HTTP API</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b311e5a4de25627cc22bc659449936bce9e8747" translate="yes" xml:space="preserve">
          <source>HTTP RPC Plugin</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d38b27eedf5edc26990140cba297bf78d446ff74" translate="yes" xml:space="preserve">
          <source>HTTP Serializers</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c4838a55a5bab95fa29d626610f3bf01d402744" translate="yes" xml:space="preserve">
          <source>Handles all of the wire protocol work for you, as well as future enhancements</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5551ebd48f7eaa66477f72c449e4b2ccfc0f9609" translate="yes" xml:space="preserve">
          <source>Hashes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50cbfd777176fbaf8041c1168e0c19d8470a5ab6" translate="yes" xml:space="preserve">
          <source>Having enough RAM or disk space to spool the data locally on for each TSD.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="46a866fa5b0697b1633cf1f4ec02d361e0275938" translate="yes" xml:space="preserve">
          <source>Health checking backends</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ff3bfd6884fe2b3af8d05c7955b9377fa25efa7" translate="yes" xml:space="preserve">
          <source>Here &quot;1234567890&quot; is the current epoch time (date +%s) in seconds. The next number is the value of the metric at this time. This is data from host A, so it's tagged with &lt;code&gt;host=A&lt;/code&gt;. Data from host B would be tagged with &lt;code&gt;host=B&lt;/code&gt;, and so forth. Over time, you'll get a bunch of time series stored in OpenTSDB.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc94514da5f7641513e6140ea086a3d4e76ddcec" translate="yes" xml:space="preserve">
          <source>Here are some common means of dealing with cardinality:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1583291f5e206e3587d40cedd45e940b0db69726" translate="yes" xml:space="preserve">
          <source>Here is an example that is recommended for production use:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e7957dc08763e3ef4ec2cac90a4487e86307d0f" translate="yes" xml:space="preserve">
          <source>Here is another slightly more complicated example that came from the mailing list, depicting how multiple time series are aggregated by average:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="afacbf355c5e66d595b2eadc685d6a27cada19d0" translate="yes" xml:space="preserve">
          <source>Hexadecimal encoded ID of the branch</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ea9dd882e80498a937edf97793ab12036b941e1" translate="yes" xml:space="preserve">
          <source>Hexadecimal encoded timeseries ID</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="637af2d1db990cf876706daab5751328fd7208a6" translate="yes" xml:space="preserve">
          <source>How do you &lt;em&gt;sum&lt;/em&gt; or find the &lt;em&gt;avg&lt;/em&gt; of a number and something that doesn't exist? One option is to simply ignore the data points for all time series at the time stamp where any series is missing data. But if you have two time series and they are simply miss-aligned, your query would return an empty data set even though there is good data in storage, so that's not very useful.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a93bd095966e3b009e53b1d81240c2b7de5a50e" translate="yes" xml:space="preserve">
          <source>How long, in milliseconds, before canceling a running query. A value of 0 means queries will not timeout.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e9caf107f6d4b6968f9f94b2beb49f1b7ea9440" translate="yes" xml:space="preserve">
          <source>How long, in seconds, to wait in between compaction queue flush calls</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9326fcee1863e116a8a39028e5efd11a1454440d" translate="yes" xml:space="preserve">
          <source>How many RPCs (batched or individual) in total were blocked due to the connection's send buffer being full. A positive value indicates a slow HBase server or poor network performance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b57e60458a53a2c3468b02c17e5ca2bd230854a" translate="yes" xml:space="preserve">
          <source>How many queries were executing at the time the query was made (note that for the stats page this will always be up-to-date)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47fb310fc695e6e9e72e53f9e421d5cb01e92358" translate="yes" xml:space="preserve">
          <source>How many rows of data are currently in the queue to be compacted. (v2.2)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbf83715f17ba58a5d8b2f887b6fb02bdd4e2897" translate="yes" xml:space="preserve">
          <source>How many scanners completed successfully. Per query, this should be equal to the number of salting buckets, or &lt;code&gt;1&lt;/code&gt; if salting is disabled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80ccec15ddbe1571599adb3a9021b8da9665045d" translate="yes" xml:space="preserve">
          <source>How many times metric UIDs attempted a reassignment due to a collision with an existing UID. (v2.2)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6309f5bf51f66618cafc1766e8cad58ccd7a5c37" translate="yes" xml:space="preserve">
          <source>How often, in milliseconds, to flush the data point storage write buffer</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="302e95b8ce1699bc2288532f8fddf2d7d5a670d2" translate="yes" xml:space="preserve">
          <source>However if an error occurs, the importer will stop and the errant line will be printed. For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50845b64c08f8a1debf07be0c89dfdfb16d0ccbd" translate="yes" xml:space="preserve">
          <source>However if we have many web servers in the system, this could create a ton of results. To filter on only the hosts we want you can use the pipe operator to select a subset of time series. For example &lt;code&gt;start=1356998400&amp;amp;m=avg:sys.cpu.user{host=webserver01|webserver03}&lt;/code&gt; will return results only for &lt;code&gt;webserver01&lt;/code&gt; and &lt;code&gt;webserver03&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f85ed86cc5b896cc5d3192c5294481f70c37f2ae" translate="yes" xml:space="preserve">
          <source>However if you want serious throughput and scalability you have to setup a Hadoop and HBase cluster with multiple servers. In a distributed setup HDFS manages region files, automatically distributing copies to different servers for fault tolerance. HBase assigns regions to different servers and OpenTSDB's client will send data points to the specific server where they will be stored. You're now spreading operations amongst multiple servers, increasing performance and storage. If you need even more throughput or storage, just add nodes or disks.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00c7893f422890d955c45179e46dd3c775755953" translate="yes" xml:space="preserve">
          <source>However in some situations, verbs such as &lt;code&gt;DELETE&lt;/code&gt; and &lt;code&gt;PUT&lt;/code&gt; are blocked by firewalls, proxies or not implemented in clients. Furthermore, most developers are used to using &lt;code&gt;GET&lt;/code&gt; and &lt;code&gt;POST&lt;/code&gt; exclusively. Therefore, while the OpenTSDB API supports extended verbs, most requests can be performed with just &lt;code&gt;GET&lt;/code&gt; by adding the query string parameter &lt;code&gt;method_override&lt;/code&gt;. This parameter allows clients to pass data for most API calls as query string values instead of body content. For example, you can delete an annotation by issuing a &lt;code&gt;GET&lt;/code&gt; with a query string &lt;code&gt;/api/annotation?start_time=1369141261&amp;amp;tsuid=010101&amp;amp;method_override=delete&lt;/code&gt;. The following table describes verb behavior and overrides.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84c16ae40aec126c6e59903414c561ea67bcda46" translate="yes" xml:space="preserve">
          <source>However sometimes it doesn't make sense to define a scalar for missing data. Often you may be recording a monotonically increasing counter such as the number of bytes transmitted from a network interface. With a counter, we can use &lt;strong&gt;interpolation&lt;/strong&gt; to make a guess as to what the value would be at that point in time. Interpolation takes two points and the time span between them to calculate a &lt;em&gt;best guess&lt;/em&gt; value at the time stamp requested.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ee278da548b594fb092cde3516bb3c524bb5ee9" translate="yes" xml:space="preserve">
          <source>However what if we have 20,000 hosts, each with 8 cores? Now we will have 3.8 million rows per day due to a high cardinality of host values. Queries for the average core usage on host &lt;code&gt;webserver01&lt;/code&gt; will be slower as it must pick out 691200 rows out of 3.8 million.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b5c2ffd33a79a8991d339b9021bc03cff26a6db" translate="yes" xml:space="preserve">
          <source>Http API</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98a81a35f1584d5f5070065dbea832e61fb0bf0f" translate="yes" xml:space="preserve">
          <source>HttpResponse</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89f89c02cf47e091e726a4e07b88af0966806897" translate="yes" xml:space="preserve">
          <source>ID</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="391f3bc539f2bd2a3249fe96c0e9c539a12880bc" translate="yes" xml:space="preserve">
          <source>ID of the tree to purge</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e547d6e73ab38f6c4bc9587c9fe3f09024aa53e2" translate="yes" xml:space="preserve">
          <source>IDEs</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="499eb3d037dece034f2c849a052eb684131285dc" translate="yes" xml:space="preserve">
          <source>IDs are created this way primarily due to the method of branch and leaf storage but also as a way to navigate back up a tree from a branch anywhere in the tree structure. This can be particularly useful if you know the end branch of a path and want to move back up one level or more. Unfortunately a deep tree can create very long branch IDs, but a well designed tree really shouldn't be more than 5 to 10 levels deep. Most URI requests should support branches up to 100 levels deep before the URI character constraints are reached.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a9937b4d8eb7ce8e6c860fa9aeff4ef25f37c28" translate="yes" xml:space="preserve">
          <source>Ideally a timeseries will only appear once on a tree. But if the TSMeta object for a timeseries, OR the UIDMeta for a metric or tag is modified, it may be processed a second time and a second leaf added. This can happen particularly in situations where a tree has a &lt;em&gt;custom&lt;/em&gt; rule on the metric, tag name or tag value where the TSMeta has been processed then a user adds a custom field that matches the rule set. In these situations it is recommended to enable &lt;em&gt;strict matching&lt;/em&gt; on the tree so that the timeseries will not show up until the custom data has been added.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f83388e8dd093f476573a949cb9318d1da9ae86" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;--delete-bad-rows&lt;/code&gt; is set, then the entire row will be removed from HBase.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e87f6faa003e7571c4beb4b21ec761014a9ac6a2" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;--delete-orphans&lt;/code&gt; is set, then the entire row will be removed from HBase.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e4b0765d6430d03591f1a69c38e12c55efc9666" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;--resolve-duplicates&lt;/code&gt; is set, then all data points except for the latest or the oldest value will be deleted. The fix applies to both stand-alone and compacted data points. If the &lt;code&gt;--last-write-wins&lt;/code&gt; flag is set, then the latest value is saved. Without the &lt;code&gt;--last-write-wins&lt;/code&gt; flag, then the oldest value is saved.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32397a97d6f4a015b9290523f139864128924396" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;storeFailures&lt;/code&gt; is diabled for the tree, this endpoint will not return any data. Collisions will still appear in the TSD's logs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9547949621e4e26f63692c0a4e7ad57eb088c954" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;storeFailures&lt;/code&gt; is diabled for the tree, this endpoint will not return any data. Not Matched entries will still appear in the TSD's logs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d94eae1bf1e677517007429baa667fdd7e794638" translate="yes" xml:space="preserve">
          <source>If HBase is running, you can choose to install OpenTSDB from a package (available under &lt;a href=&quot;https://github.com/OpenTSDB/opentsdb/releases&quot;&gt;Releases&lt;/a&gt; in Github) or from source using GIT or a source tarball.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1db02c106516e55a1e0fc084e050b531f9e4adf" translate="yes" xml:space="preserve">
          <source>If a TS meta object already exists in storage for the given metric and tags, the fields will be updated or overwritten.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="818447798cf955d8bb49b82fe6db1762ece7f7c3" translate="yes" xml:space="preserve">
          <source>If a TSD process dies, you'll either loose the data for the aggregation or it must be bootstrapped from storage.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="583561b35d482d184868dcbbe484de6edf2cc056" translate="yes" xml:space="preserve">
          <source>If a branch contains child leaves, i.e. timeseries stored in OpenTSDB, their metric, tags, TSUID and display name will be contained in the results. Leaf fields are as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0791883989a60e6f7cb1412670df9bbea2fc6dd5" translate="yes" xml:space="preserve">
          <source>If a command is sent to the API that is not supported or recognized, a response similar to the following will be shown:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95b97d76c8280b4006ffc5f5ae128a1de5291993" translate="yes" xml:space="preserve">
          <source>If a manual tree synchronization is running somewhere or there is a large number of TSMeta objects being created or edited, the tree rule may be cached and modifications to a tree's rule set may take some time to propagate. If you make any modifications to the rule set, other than to meta information such as the &lt;code&gt;description&lt;/code&gt; and &lt;code&gt;notes&lt;/code&gt;, you may want to flush the tree data and perform a manual synchronization so that branches and leaves reflect the new rules.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd279341814b2ba7fe2a543cb0a726bd2d246330" translate="yes" xml:space="preserve">
          <source>If a method is not supported for a given API call, the TSD will return a 405 error.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5dd1ca8d33f2550a1bca29c6b1d30c4e79f33e62" translate="yes" xml:space="preserve">
          <source>If a row is repaired for any reason and has one or more compacted columns, the row will be re-compacted regardless of the &lt;code&gt;--compact&lt;/code&gt; flag.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65171f243b2de36caea783b8936204050efc93ec" translate="yes" xml:space="preserve">
          <source>If a row key is found that doesn't conform to the OpenTSDB data table specification &lt;code&gt;&amp;lt;metric_UID&amp;gt;&amp;lt;base_timestamp&amp;gt;&amp;lt;tagk1_UID&amp;gt;&amp;lt;tagv1_UID&amp;gt;[...&amp;lt;tagkn_UID&amp;gt;&amp;lt;tagvn_UID&amp;gt;]&lt;/code&gt;, the entire row is considered invalid.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e3bc3c4a145775208572793f7aa47db63aba03c" translate="yes" xml:space="preserve">
          <source>If a row key is parsed as a proper OpenTSDB row, then the UIDs for the time series ID (TSUID) of the row are resolved to their names. If any of the UIDs does not match a name in the &lt;code&gt;tsdb-uid&lt;/code&gt; table, then the row is considered an orphan. This can happen if a UID is manually deleted from the UID table or a deletion does not complete properly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ad38a0e8d8f36f4f3c4f1167e74dd8f86405a59" translate="yes" xml:space="preserve">
          <source>If a serializer isn't found that matches the &lt;code&gt;&amp;lt;serializer_name&amp;gt;&lt;/code&gt; value, the query will return an error instead of processing further.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ecad6f0b1cb5186fdfc6524aa95c00f3ceab7c28" translate="yes" xml:space="preserve">
          <source>If a write to the underlying storage layer fails for any reason, an exception is raised. When this happens, if a a storage exception handler plugin is enabled, the data points that couldn't be written can be retried at a later date by spooling to disk or passing to a messaging system. (v2.2)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2660584b179c554c8bcf4cd46601ff044f0d6eb1" translate="yes" xml:space="preserve">
          <source>If an endpoint is marked as (&lt;strong&gt;Deprecated&lt;/strong&gt;) below, it should not be used for future development work.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="903ab31c2fec515473e1621cc6d0027c39320b15" translate="yes" xml:space="preserve">
          <source>If an error occurs, the API will return a response with an error object formatted per the requested response type. Error object fields include:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b9c4d04316aa89aaa6e3f85e750b8207e15fb925" translate="yes" xml:space="preserve">
          <source>If an orphaned reverse map points to a resolved forward map, this error occurs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee4bdf989787de67528332598425427aa52118fb" translate="yes" xml:space="preserve">
          <source>If both &lt;code&gt;detailed&lt;/code&gt; and &lt;code&gt;summary&lt;/code&gt; are present in a query string, the API will respond with &lt;code&gt;detailed&lt;/code&gt; information.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c36e8a3b0be3d5157ac244323a8bb9516548960" translate="yes" xml:space="preserve">
          <source>If collision storage is enabled for a tree, a column is recorded for each time series that would have created a leaf that was already created for a previous time series. These columns are used to debug rule sets and only appear rin the collision row for a tree. The qualifier is of the format &lt;code&gt;tree_collision:&amp;lt;tsuid&amp;gt;&lt;/code&gt; where the TSUID is a byte array representing the time series identifier. This allows for a simple &lt;code&gt;getRequest&lt;/code&gt; call to determine if a particular time series did not appear in a tree due to a collision. The value of a colission column is the byte array of the TSUID that was recorded as a leaf.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbe3eb1a0d22f586b762d7bd4f19bb3547e38609" translate="yes" xml:space="preserve">
          <source>If compactions have been enabled for a TSD, a row may be compacted after it's base hour has passed or a query has run over the row. Compacted columns simply squash all of the data points together to reduce the amount of overhead consumed by disparate data points. Data is initially written to individual columns for speed, then compacted later for storage efficiency. Once a row is compacted, the individual data points are deleted. Data may be written back to the row and compacted again later.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09f9bf7cd1b935ead5b1e04a958076066df6e6f0" translate="yes" xml:space="preserve">
          <source>If compilation was successfully, you should have a tsdb jar file in &lt;code&gt;./build&lt;/code&gt; along with a &lt;code&gt;tsdb&lt;/code&gt; script. You can now execute command-line tool by invoking &lt;code&gt;./build/tsdb&lt;/code&gt; or you can run &lt;code&gt;make install&lt;/code&gt; to install OpenTSDB on your system. Should you ever change your mind, there is also &lt;code&gt;make uninstall&lt;/code&gt;, so there are no strings attached.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4672070a343e5d106db860df68a544a70beb2d0" translate="yes" xml:space="preserve">
          <source>If downsampling is not used, this can be included to determine what to emit in calculations. It will also override the downsampling policy</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0da37deeb3bbff226a60e6ffe2504eea559123f2" translate="yes" xml:space="preserve">
          <source>If downsampling was requested, each individual time series is down sampled into smaller time spans using the proper aggregator</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f3d61315662298e7fd247cc3e0d1bee2d65ec37" translate="yes" xml:space="preserve">
          <source>If more than one timeseries were included in the result set, i.e. they were aggregated, this will display a list of tag names that were found in common across all time series.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44851765f146145b2ba4e0261827f21649fb3235" translate="yes" xml:space="preserve">
          <source>If requested by the user, the query will scan for global annotations during the timespan and the results returned in this group</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="027d435f2ecb5bca03fe3b0566e91cb5f6790d0e" translate="yes" xml:space="preserve">
          <source>If something is a counter, or is naturally something that is a rate, don't convert it to a rate before sending it to the TSD. There's two main reasons for this. First, doing your own rate calculation, reset/overflow handling, etc. is silly, since TSD can do it for you. You also don't have to worry about getting the units-per-second calculation correct based on a slightly inaccurate or changing sample interval. Secondly, if something happens where you lose a datapoint or more, if you are sending the current counter value then you won't lose data, just resolution of that data. The golden rule in TSD is, if your source data is a counter (some counter out of /proc or SNMP), keep it that way. Don't convert it. If you're writing your own collector (say, one that counts how often a particular error message appears in a tail -f of a log), don't reset your counter every sample interval. Let TSD to do the work for you.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a088a9d408db4ed31fd494b9d5f94407ca3fc590" translate="yes" xml:space="preserve">
          <source>If the &lt;code&gt;Origin&lt;/code&gt; domain did not match a domain in the configured list, the response will be a 200 status code and an Error (see above) for the content body stating that access was denied, regardless of whether the request was a preflight or a regular request. The request will not be processed any further.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="725744767dbc6a62de61f6817b0facd3f60de8b5" translate="yes" xml:space="preserve">
          <source>If the &lt;code&gt;rate&lt;/code&gt; flag was detected, each aggregate will then be adjusted to get the rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="348fcc91ee07aa0c24a6b025597a445d7de911f0" translate="yes" xml:space="preserve">
          <source>If the &lt;code&gt;tsd.mode&lt;/code&gt; is set to &lt;code&gt;ro&lt;/code&gt; instead of &lt;code&gt;rw&lt;/code&gt;, the TSD will not accept data points through RPC calls. Telnet style calls will throw an exception and calls to the HTTP endpoint will return a 404 error. However it is still possible to write via the JAVA API when the mode is set to read only.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9021cff063f627045e8430ce672cf29cabe4299" translate="yes" xml:space="preserve">
          <source>If the &lt;code&gt;tsd.mode&lt;/code&gt; is set to &lt;code&gt;ro&lt;/code&gt;, the &lt;code&gt;/api/put&lt;/code&gt; endpoint will be unavailable and all calls will return a 404 error.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad1575667a6722e790a63ed18fe72e287d74f693" translate="yes" xml:space="preserve">
          <source>If the &lt;code&gt;tsd.storage.fix_duplicates&lt;/code&gt; configuration value is set to &lt;code&gt;true&lt;/code&gt; then the latest value will be saved regardless of &lt;code&gt;--last-write-wins&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98f18c5a9db305c7ffbfeff808f8556acfaddd66" translate="yes" xml:space="preserve">
          <source>If the TSUID is empty, the annotation is considered a &quot;global&quot; notation, something associated with all timeseries in the system. When querying, the user can specify that global annotations be fetched for the timespan of the query. These notes will then be returned along with &quot;local&quot; annotations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5af1922e248f200b6e454ecec6c18f9251830614" translate="yes" xml:space="preserve">
          <source>If the content you provide with the request cannot be parsed, such JSON content missing a quotation mark or curly brace, then all of the datapoints will be discarded. The API will return an error with details about what went wrong.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43adc0299da880d24de7a57e97f56fb6179d0ee3" translate="yes" xml:space="preserve">
          <source>If the dependency is only used for unit tests, then add it to the &lt;code&gt;test_DEPS = \&lt;/code&gt; list</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e699d4e37243c7f30cd9404aeaa2384c024911bf" translate="yes" xml:space="preserve">
          <source>If the field value should be split into multiple branches, provide the separation character.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ab266f18d0ea315934a670a75565f89b6177303" translate="yes" xml:space="preserve">
          <source>If the plugin is not configured or enabled, endpoints other than &lt;code&gt;/api/search/lookup&lt;/code&gt; will return an exception.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="159c56e59ed62ef7d1e16c4515b9f8dc947f93ff" translate="yes" xml:space="preserve">
          <source>If the query does have one or more tags defined, then it will still scan all of the rows matching &lt;code&gt;&amp;lt;metricID&amp;gt;&amp;lt;timestamp&amp;gt;&lt;/code&gt;, but also perform a regex to return only the rows that contain the requested tag.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58e12e0fd46e1496f38823fe417a57b2abd48800" translate="yes" xml:space="preserve">
          <source>If the query doesn't have any tags or tag values, then it will grab any rows of data that match &lt;code&gt;&amp;lt;metricID&amp;gt;&amp;lt;timestamp&amp;gt;&lt;/code&gt;, so if you have a ton of time series for a particular metric, this could be many, many rows.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a209f6f0a0b4c5c8c9e2813d29a085493737df1e" translate="yes" xml:space="preserve">
          <source>If the query failed, this field will include the message string and the first line of the stack trace for pinpointing. If the query was successful, this field will be null.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e4668bcf30cca2fde069853efc7945dbd240fc1" translate="yes" xml:space="preserve">
          <source>If the query retrieved annotations for timeseries over the requested timespan, they will be returned in this group. Annotations for every timeseries will be merged into one set and sorted by &lt;code&gt;start_time&lt;/code&gt;. Aggregator functions do not affect annotations, all annotations will be returned for the span.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e703a16686319c4c12e2f865500c06021cd76c4" translate="yes" xml:space="preserve">
          <source>If the same query was executed multiple times (same times, same agent, etc) then this integer counter will increment. Use this to find out when a client may want to start caching results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd33afab6419ca1a20222eb59df6a9a73757bdce" translate="yes" xml:space="preserve">
          <source>If the time stamp in a time box is invalid, the background will turn red. This may happen if your start time is greater than or equal to your end time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff826db6838f1a2576158b4c97cb0bdfcfbefadc" translate="yes" xml:space="preserve">
          <source>If the value from a &lt;code&gt;put&lt;/code&gt; command is parsed with a decimal point (&lt;code&gt;.&lt;/code&gt;) it will be treated as a floating point value. Currently all floating point values are stored on 4 bytes, single-precision, with support for 8 bytes planned for a future release. Floats are stored in IEEE 754 floating-point &quot;single format&quot; with positive and negative value support. Infinity and Not-a-Number values are not supported and will throw an error if supplied to a TSD. See &lt;a href=&quot;https://en.wikipedia.org/wiki/IEEE_floating_point&quot;&gt;Wikipedia&lt;/a&gt; and the &lt;a href=&quot;http://docs.oracle.com/javase/specs/jls/se7/html/jls-4.html#jls-4.2.3&quot;&gt;Java Documentation&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f8a261b99ce5675102b5f064c6d0335c74161823" translate="yes" xml:space="preserve">
          <source>If the value from a &lt;code&gt;put&lt;/code&gt; command is parsed without a decimal point (&lt;code&gt;.&lt;/code&gt;), it will be treated as a signed integer. Integers are stored, unsigned, with variable length encoding so that a data point may take as little as 1 byte of space or up to 8 bytes. This means a data point can have a minimum value of -9,223,372,036,854,775,808 and a maximum value of 9,223,372,036,854,775,807 (inclusive). Integers cannot have commas or any character other than digits and the dash (for negative values). For example, in order to store the maximum value, it must be provided in the form &lt;code&gt;9223372036854775807&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89a4ec0c04ce75c613d5e72cc319256402bd3db6" translate="yes" xml:space="preserve">
          <source>If there any non-numeric named directories in the &lt;code&gt;collectors&lt;/code&gt; directory, then they are ignored. We've included a &lt;code&gt;lib&lt;/code&gt; and &lt;code&gt;etc&lt;/code&gt; directory for library and config data used by all collectors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc321052c82c25561b08f67c1715da047a21e8d9" translate="yes" xml:space="preserve">
          <source>If this branch belongs to tree &lt;code&gt;1&lt;/code&gt;, the row key for &lt;code&gt;dal&lt;/code&gt; would be &lt;code&gt;\x00\x01\x00\x01\x83\x8F&lt;/code&gt;. The branch for &lt;code&gt;myapp&lt;/code&gt; would be &lt;code&gt;\x00\x01\x00\x01\x83\x8F\x06\xBC\x4C\x55\x06\x38\x7C\xF5&lt;/code&gt;. This schema allows for navigation by providing a row key filter using a prefix including the tree ID and current branch level and a wild-card to match any number of child branch levels (usually only one level down).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50af69fede169d295a716cfa58952f5fd3a600ee" translate="yes" xml:space="preserve">
          <source>If this happens it is usually due to a corruption and indicates the max ID row was not updated properly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b404b012c322854d5d55034c6d682335707fdba1" translate="yes" xml:space="preserve">
          <source>If this is the first time that you are running OpenTSDB with your HBase instance, you first need to create the necessary HBase tables. A simple script is provided to create the proper tables with the ability to enable or disable compression. Execute:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05ffa35dd032c3063d7b178ed3b9c56d59b81343" translate="yes" xml:space="preserve">
          <source>If we want to aggregate the results for a specific group, we can filter on the &lt;code&gt;host&lt;/code&gt; tag. The query &lt;code&gt;start=1356998400&amp;amp;m=sum:sys.cpu.user{host=webserver01}&lt;/code&gt; will return a value of &lt;code&gt;5&lt;/code&gt;, incorporating only the time series where &lt;code&gt;host=webserver01&lt;/code&gt;. To drill down to a specific time series, you must include all of the tags for the series, e.g. &lt;code&gt;start=1356998400&amp;amp;m=sum:sys.cpu.user{host=webserver01,cpu=0}&lt;/code&gt; will return &lt;code&gt;1&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba13028663f7b8c77bfa59c0ed0eaefcc882b125" translate="yes" xml:space="preserve">
          <source>If we want to query for the average CPU time across each server we can craft a query like &lt;code&gt;start=1356998400&amp;amp;m=avg:sys.cpu.user{host=*}&lt;/code&gt;. This will give us three results:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c060f4365e05a8152a1bfc223633fc54a89fb77" translate="yes" xml:space="preserve">
          <source>If you are importing data from another system or you need to backfill historical data, you can use the &lt;code&gt;import&lt;/code&gt; CLI utility. See &lt;code&gt;cli/import&lt;/code&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44360168341e9b25e22cb4def23c1bc1042542c9" translate="yes" xml:space="preserve">
          <source>If you are looking to integrate OpenTSDB with your application, the compiled JAVA library has a consistent and well documented API. Please see &lt;a href=&quot;http://opentsdb.net/docs/javadoc/index.html&quot;&gt;JAVA API Documentation&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="46a596df52ec3499541cb1c556d0cbb802c3598f" translate="yes" xml:space="preserve">
          <source>If you can't connect to Zookeeper, check IPs and name resolution. HBase can be finicky.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af8e51416483b0a47c9c31808b5d7299bbb309df" translate="yes" xml:space="preserve">
          <source>If you desperately need more than 16 million values, you can increase the number of bytes that OpenTSDB uses to encode UIDs from 3 bytes up to a maximum of 8 bytes. This change would require modifying the value in source code, recompiling, deploying your customized code to all TSDs which will access this data, and maintaining this customization across all future patches and releases.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0dce8527c0f9d304c94e6805bf1ab9328f444bc2" translate="yes" xml:space="preserve">
          <source>If you do adjust the byte encoding number, you must start with a fresh &lt;code&gt;tsdb&lt;/code&gt; and fresh &lt;code&gt;tsdb-uid&lt;/code&gt; table, otherwise the results will be unexpected. If you have data in an existing setup, you must export it, drop all tables, create them from scratch and re-import the data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95c3538bd36edc2444a0de1b77828d4a53d6d676" translate="yes" xml:space="preserve">
          <source>If you do perform a rolling upgrade where you have multiple TSDs, heed the following warning:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="822483a7d90d6801a3d69a29b5fe4dd063313e09" translate="yes" xml:space="preserve">
          <source>If you don't have a MySQL server to monitor, you can try this instead to collect basic load metrics from your Linux servers:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3f557eda3181d3cc4c17986aefdb6c0c4cc499b" translate="yes" xml:space="preserve">
          <source>If you don't know the exact timestamp to request you can submit a time in the past relative to the time on the system where the TSD is running. Relative times follow the format &lt;code&gt;&amp;lt;amount&amp;gt;&amp;lt;time unit&amp;gt;-ago&lt;/code&gt; where &lt;code&gt;&amp;lt;amount&amp;gt;&lt;/code&gt; is the number of time units and &lt;code&gt;&amp;lt;time unit&amp;gt;&lt;/code&gt; is the unit of time, such as hours, days, etc. For example, if we provide a &lt;strong&gt;start time&lt;/strong&gt; of &lt;code&gt;1h-ago&lt;/code&gt; and leave out the &lt;strong&gt;end time&lt;/strong&gt;, our query will return data start at 1 hour ago to the current time. Possible units of time include:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9943b2621aad5f550241f3599574ff2f5f2f187" translate="yes" xml:space="preserve">
          <source>If you have already used OpenTSDB to query data, you are likely familiar with &lt;strong&gt;downsamplers&lt;/strong&gt; that aggregate each time series into a smaller, or lower resolution, value. A rollup is essentially the result of a downsampler stored in the system and called up at will. Each rollup (or downsampler) requires two pieces of information:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8380f6ca874cf5d29ccd89858f10abad46293313" translate="yes" xml:space="preserve">
          <source>If you have want to test your parameters against some specific point in time, you can use the &lt;code&gt;--now &amp;lt;UTC&amp;gt;&lt;/code&gt; parameter to specify an explicit unix timestamp which is used as the current timestamp instead of the actual current time. If set, the script will fetch data starting at &lt;code&gt;UTC - duration&lt;/code&gt;, ending at &lt;code&gt;UTC&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bbe4624b2247ae4ecbbacc206990042cc093389" translate="yes" xml:space="preserve">
          <source>If you have working code for calculating aggregations, please share with the OpenTSDB group. If your solution is open-source we may be able to incorporate it in the OpenTSDB ecosystem.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d204e9467f7c40074b009856617bfaebb85a2566" translate="yes" xml:space="preserve">
          <source>If you include the &lt;code&gt;--delete&lt;/code&gt; flag, &lt;strong&gt;ALL&lt;/strong&gt; data in 'any' row that matches on the query will be deleted permanently. Rows are separated on 1 hour boundaries so that if you issued a scan command with a start and end time that covered 10 minutes within a single hour, the entire hour of data will be deleted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb9f0a231d78c4667f95e1b8cf574eea84630b87" translate="yes" xml:space="preserve">
          <source>If you install OpenTSDB for the first time, you'll need to create the HBase tables using the script located at &lt;code&gt;/usr/share/opentsdb/tools/create_table.sh&lt;/code&gt;. Follow the steps below.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cae0ab66e53339fa22b4e29520e8a4c5a7c469f1" translate="yes" xml:space="preserve">
          <source>If you intend to use meta data or tree features, repeat the keyspace creation with the proper table name.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2cff44eb51d5c619fb4a3e2226ec23b78dbcfa4d" translate="yes" xml:space="preserve">
          <source>If you know the exact TSUID of the timeseries that you want to retrieve, you can simply pass it in like so:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9cad45718955e61b4b4fe177f9dcffceb51d4878" translate="yes" xml:space="preserve">
          <source>If you know the width of each UID (by default 3 bytes as stated above), then you can easily parse the UID for each metric, tag name and value from the UID string.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32f13251c174b788f46bdc738a3cf768d0f48e8e" translate="yes" xml:space="preserve">
          <source>If you need to distribute OpenTSDB to machines without an Internet connection, call &lt;code&gt;./build.sh dist&lt;/code&gt; to wrap the build directory into a tarball that you can then copy to additional machines.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf2d188527c30e3316afb887ed73b3698d1ef761" translate="yes" xml:space="preserve">
          <source>If you restart a TSD, it will have to lookup the UID for every metric and tag so performance will be a little slow until the cache is filled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a3749ed4ed1ea5a6dc8f8a27a2b501be53c0e43" translate="yes" xml:space="preserve">
          <source>If you start by picking a start and end time then as soon as you enter a metric, the TSD will start to graph &lt;em&gt;every time series for that metric&lt;/em&gt;. This will show the &lt;code&gt;Loading Graph...&lt;/code&gt; status and may take a long time before you can do anything else. So skip the times and choose your metrics first.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c874138c5b25f3c2ec98be596e75c8f3352267e5" translate="yes" xml:space="preserve">
          <source>If you think that the UID limit may impact you, first think about the queries that you want to execute. If we look at the &lt;code&gt;web.app.hits&lt;/code&gt; example above, you probably only care about the total number of hits to your service and rarely need to drill down to a specific IP address. In that case, you may want to store the IP address as an annotation. That way you could still benefit from low cardinality but if you need to, you could search the results for that particular IP using external scripts. (Note: Support for annotation queries is expected in a &lt;em&gt;future&lt;/em&gt; version of OpenTSDB.)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68c42185e015731815cc304a07fbbd78bf60122b" translate="yes" xml:space="preserve">
          <source>If you want to use metadata in your OpenTSDB setup, you must explicitly enable real-time metadata tracking and/or use the CLI tools. There are multiple options for meta data generation due to impacts on performance, so before you enable any of these settings, please test the impact on your TSDs before enabling the settings in production.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b7518b538b3bd242d934d58942770406c2210ea" translate="yes" xml:space="preserve">
          <source>If you wrote data using a salted table or changed the UID widths for metrics, tag keys or tag values then you cannot downgrade. Create a new table and export the data from the old table, then re-write the data to the new table using the older TSD version.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="056515f7651025bc71f1b0b06e95d44bfba3e505" translate="yes" xml:space="preserve">
          <source>If your IDE didn't, create a &lt;code&gt;./test&lt;/code&gt; directory under your dev project folder. This will be used for unit tests.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e66b5f97b5e0c42932d45b11eb69bd4a911a5a94" translate="yes" xml:space="preserve">
          <source>If your data file is large, consider gzip'ing it first. This can be as simple as piping the output of your cron job to &lt;code&gt;gzip -9 &amp;gt;output.gz&lt;/code&gt; instead of writing directly to a file. The import command is able to read gzip'ed files and it greatly helps performance for large batch imports.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="474d60ba146d3c51dfc9f91b10115acf18a07811" translate="yes" xml:space="preserve">
          <source>If your request uses &lt;code&gt;PUT&lt;/code&gt;, any fields that you do not supply with the request will be overwritten with their default values. For example, the &lt;code&gt;description&lt;/code&gt; field will be set to an empty string and the &lt;code&gt;custom&lt;/code&gt; field will be reset to &lt;code&gt;null&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f6f1419b4fbde70c813259ad6e3acc3143af58b" translate="yes" xml:space="preserve">
          <source>If your request uses &lt;code&gt;PUT&lt;/code&gt;, any fields that you do not supply with the request will be overwritten with their default values. For example, the &lt;code&gt;description&lt;/code&gt; field will be set to an emtpy string and the &lt;code&gt;custom&lt;/code&gt; field will be reset to &lt;code&gt;null&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56d3b044647576ce38f2cc3896e8047f7eeaa474" translate="yes" xml:space="preserve">
          <source>If, for example, your ZooKeeper quorum is behind the DNS name &quot;zookeeper.example.com&quot; (a name with 5 A records), instead of always passing &lt;code&gt;--zkquorum=zookeeper.example.com&lt;/code&gt; to the CLI tool each time you use it, you can create &lt;code&gt;./tsdb.local&lt;/code&gt; with the following contents:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2ba883c2a482ca722242daca95202f48b9bdff3" translate="yes" xml:space="preserve">
          <source>Ignored for lookup queries, always the default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c963a437bdd4953d9750f3ce7a0047e3b20a67e9" translate="yes" xml:space="preserve">
          <source>Ignored for lookup queries.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f66b99e47af4b13f8b07e52c7964fe82262790b" translate="yes" xml:space="preserve">
          <source>Imagine each if your servers actually ran two webservers, say, one for static content and one for dynamic content. Rather than create another metric, just tag the http.hits metric with the server instance. Have your collector send stuff like:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3648ab11c16f2b305a1f889e5c0d6bdaf30d25da" translate="yes" xml:space="preserve">
          <source>Import Format</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="33660e7944a7a188932fab0ac6bd486a6c7866ce" translate="yes" xml:space="preserve">
          <source>Improved Expressions - Perform group by, downsampling and arithmetic modifications in any order. Potentially support UDFs as well.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5123cea6256eb144211bbf7609ac984451066550" translate="yes" xml:space="preserve">
          <source>In 2.2 salting is supported to greatly increase write distribution across region servers. When enabled, a configured number of bytes are prepended to each row key. Each metric and combination of tags is then hashed into one &quot;bucket&quot;, the ID of which is written to the salt bytes. Distribution is improved particularly for high-cardinality metrics (those with a large number of tag combinations) as the time series are split across the configured bucket count, thus routed to different regions and different servers. For example, without salting, a metric with 1 million series will be written to a single region on a single server. With salting enabled and a bucket size of 20, the series will be split across 20 regions (and 20 servers if the cluster has that many hosts) where each region has 50,000 series.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="007103ae538929fc37fdef47a06df6e3dc21036e" translate="yes" xml:space="preserve">
          <source>In OpenTSDB 2.2 tag key and value filters were introduced. This makes it easier to extract only the data that you want from storage. The filter framework is plugable to allow for tying into external systems such as asset management or provisioning systems.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53b6c3a1c9a7d6d8c1dd16ae76de2f0507700b27" translate="yes" xml:space="preserve">
          <source>In OpenTSDB's implementation, a new, users configurable tag is added to all time series when rollups are enabled. The default key is &lt;code&gt;_aggegate&lt;/code&gt; with a value of &lt;code&gt;raw&lt;/code&gt; or an aggregation function. The tag is used to differentiate pre-aggregated data from raw (original) values. Therefore pre-aggregated data is stored in the same manner as original time series and can either be written to the original data table or stored in a separate table for greater query performance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="145eb572e147dd69eaf4d6451ed9d18b6e0ad5fa" translate="yes" xml:space="preserve">
          <source>In OpenTSDB, a metric is named with a string, like &lt;code&gt;http.hits&lt;/code&gt;. To be able to store all the different values for all the places where this metric exists, you tag the data with one or more tags when you send them to the TSD. TSD stores the timestamp, the value, and the tags. When you want to retrieve this data, TSD retrieves all of the values for the time span you supply, optionally with a tag filter you supply, aggregates all these values together how you want, and plots a graph of this value over time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69c3f8e3a072461111a263409eb9c4c1a7c3117d" translate="yes" xml:space="preserve">
          <source>In OpenTSDB, pre-aggregates are differentiated from other time series with a special tag. The default tag key is &lt;code&gt;_aggregate&lt;/code&gt; (configurable via &lt;code&gt;tsd.rollups.agg_tag_key&lt;/code&gt;). The &lt;strong&gt;aggregation function&lt;/strong&gt; used to generate the data is then stored in the tag value in upper-case. Lets look at an example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ac5f7db47736ad0f3818d26aa10226db624d0c8" translate="yes" xml:space="preserve">
          <source>In OpenTSDB, when you write a timeseries data point, it is always associated with a metric and at least one tag name/value pair. Each metric, tag name and tag value is assigned a unique identifier (UID) the first time it is encountered or when explicitly assigned via the API or a CLI tool. The combination of metric and tag name/value pairs create a timeseries UID or TSUID.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44cd0fd53c9044885c33b68760d400e266c81ef4" translate="yes" xml:space="preserve">
          <source>In anything above a small environment, you probably have clusters or groups of machines doing the same thing. Over time these change, though. That's OK. Just use a tag when you send the data to TSD to pass this cluster info along. Add something like cluster=webserver to all the datapoints being sent from each of your webservers, and cluster=db for all your databases, etc.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93c7393534821643b07e7457b9965c1125e01384" translate="yes" xml:space="preserve">
          <source>In general, queueing on a writer is a bad idea. Avoid the pain.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2184a60863992605fc3e1f135ec5c011bcbd15b9" translate="yes" xml:space="preserve">
          <source>In general, upgrading within a single major release branch is simply a matter of updating the binaries or package and restarting a TSD. Within a branch we'll maintain settings, APIs and schema. However new features may be added with each minor version that include new configuration settings with useful defaults.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54c523f2790688cd0c9445ee46b49dbb268f39fe" translate="yes" xml:space="preserve">
          <source>In general, you should aim to compute and store the &lt;code&gt;MAX&lt;/code&gt;, &lt;code&gt;MIN&lt;/code&gt;, &lt;code&gt;SUM&lt;/code&gt; and &lt;code&gt;COUNT&lt;/code&gt; for each time series when storing rollups.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a24b4b1b42867bab396570686f48aff30a9fa35f" translate="yes" xml:space="preserve">
          <source>In most situations, if a duplicate data point is written it is usually an indication that something went wrong with the data source such as a process restarting unexpectedly or a bug in a script. OpenTSDB will fail &quot;safe&quot; by throwing an exception when you query over a row with one or more duplicates so you can down the issue.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b9b3a093b7b3a218a338f9fc14f178a450a5c49e" translate="yes" xml:space="preserve">
          <source>In order for this endpoint to function with metric string queries by scanning for matching time series, the meta data table must exist and have been populated with counters or TSMeta objects using one of the methods specified in &lt;a href=&quot;../../user_guide/metadata&quot;&gt;&lt;em&gt;Metadata&lt;/em&gt;&lt;/a&gt;. You must set either &lt;code&gt;tsd.core.meta.enable_tsuid_tracking&lt;/code&gt; or &lt;code&gt;tsd.core.meta.enable_realtime_ts&lt;/code&gt;. Queries with a backscan parameter will skip the meta table.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="184ad7fd33fe268fc1b69fb9b996350842ccce59" translate="yes" xml:space="preserve">
          <source>In our example data, we had some old timeseries that didn't have a &lt;code&gt;dc&lt;/code&gt; tag name. However the &lt;code&gt;host&lt;/code&gt; tag does have a fully qualified domain name with the data center name embedded. Thus the first level of our rule set has two rules. The first will look for a &lt;code&gt;dc&lt;/code&gt; tag, and if found, it will use that tag's value and the second rule is skipped. If the &lt;code&gt;dc&lt;/code&gt; tag does not exist, then the second rule will scan the &lt;code&gt;host&lt;/code&gt; tag's value and attempt to extract the data center name from the FQDN. The second level has one rule and that is used to group on the value of the &lt;code&gt;host&lt;/code&gt; tag so that all metrics belonging to that host can be displayed in branches beneath it. The final level has the metric rule that includes a separator to further group the timeseries by the data contained. Since we have multiple CPU and application metrics, all deliniated by a period, it makes sense to add a separator at this point.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e711870b822e6f1aaf97b69b4662f68ecd61510" translate="yes" xml:space="preserve">
          <source>In some CLI tools and log files, a UID may be displayed as an array of signed bytes (thanks to Java) such as the above example of &lt;code&gt;[0, 0, 1]&lt;/code&gt; or &lt;code&gt;[0, 0, -28]&lt;/code&gt;. To convert from this signed array to an an array of unsigned bytes, then to hex. For example, &lt;code&gt;-28&lt;/code&gt; would be binary &lt;code&gt;10011100&lt;/code&gt; which results in a decimal value of &lt;code&gt;156&lt;/code&gt; and a hex value of &lt;code&gt;9C&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25df3a1cb11cedec4d53348a929927db0d868def" translate="yes" xml:space="preserve">
          <source>In some situations, you may want to extract only a component of a metric, tag or custom value to use for grouping. For example, if you have computers in mutiple data centers with fully qualified domain names that incorporate the name of the DC, but not all metrics include a DC tag, you could use a regex to extract the DC for grouping.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47d9431e739d0f4af9c4b97ed6bff49247873464" translate="yes" xml:space="preserve">
          <source>In that directory, create a &lt;code&gt;&amp;lt;depdencency&amp;gt;.jar.md5&lt;/code&gt; file</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="715d7d267232f7cdc0d67349ef242bd160eae946" translate="yes" xml:space="preserve">
          <source>In the &lt;code&gt;tools&lt;/code&gt; directory is a Python script &lt;code&gt;check_tsd&lt;/code&gt;. This script queries OpenTSDB and returns Nagios compatible output that gives you OK/WARNING/CRITICAL state.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1a339404b9aacd4860dfb298f7f81cf3287bb72" translate="yes" xml:space="preserve">
          <source>In the UI you'll see that the TSD has filled one or more &quot;Tags&quot;, the first one is host. What TSD is saying here that for this time range it sees that the data was tagged with a host tag. You can filter the graph so that it just plots the value of one host. If you fill in A in the host row, you'll just plot the values over time of host A. If you want to give a list of hosts to plot, fill in the list of hosts separated by the pipe symbol, e.g. A|B. This will give you two plots instead of one, one for A and one for B. Finally, you can also specify the special character &lt;a href=&quot;#id1&quot;&gt;&lt;span id=&quot;id2&quot;&gt;*&lt;/span&gt;&lt;/a&gt;, which means to plot a line for every host.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="995df84e5dad2848054c7443018b4b6361e4a8e3" translate="yes" xml:space="preserve">
          <source>In the config file, set</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c1af3269f7f9e903c72435a07a10ac776b0e5b7" translate="yes" xml:space="preserve">
          <source>In the constructor for your plugin, you should initialize your plugin and make any external connections required here. For example, to connect to a service discovery tool such as Etcd or Curator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9987ec1284289baf422ac89320d08630540b3e36" translate="yes" xml:space="preserve">
          <source>In the event that a valid configuration file cannot be found and the required properties are not set, the TSD will not start. Please see the properties table below for a list of required configuration settings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d883989391b09490a6a08fdfc806734dd7fe054" translate="yes" xml:space="preserve">
          <source>In the example above, both time series &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;B&lt;/code&gt; had data points at every time stamp, they lined up neatly. However what happens when two series do not line up? It can be difficult, and sometimes undesired, to synchronize all sources of data to write at the exact same time. For example, if we have 10,000 servers sending 100 system metrics every 5 minutes, that would be a burst of 10M data points in a single second. We would need a pretty beefy network and cluster to accommodate that traffic. Not to mention the system would be sitting idle for the rest of 5 minutes. Instead it makes much more sense to splay the writes over time so that we have an average of 3,333 writes per second to reduce our hardware and network requirements.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ead5cde21eb4973fb35a9aa916cd05136492f953" translate="yes" xml:space="preserve">
          <source>In the tree row there are 0 or more rule columns that define a specific processing task on a time series. These columns are also UTF-8 encoded JSON objects and are modified with CAS calls. The qualifier id of the format &lt;code&gt;rule:&amp;lt;level&amp;gt;:&amp;lt;order&amp;gt;&lt;/code&gt; where &lt;code&gt;&amp;lt;level&amp;gt;&lt;/code&gt; is the main processing order of a rule in the set (starting at 0) and &lt;code&gt;order&lt;/code&gt; is the processing order of a rule (starting at 0) within a given level. For example &lt;code&gt;rule:1:0&lt;/code&gt; defines a rule at level 1 and order 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="676e405b24f132766a02622263caca28491886c5" translate="yes" xml:space="preserve">
          <source>In this case a value was encoded on 8 bytes with the first four bytes set to a non-zero value. It could be that the value is an 8 byte double since OpenTSDB never actually encoded on 8 bytes, the value is likely corrupt. If the value was compacted, the compacted column will be invalid as parsing is no longer possible.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77833a3f2332004f97fea6fa9ca108e32dd94410" translate="yes" xml:space="preserve">
          <source>In this case the UID was not used more than once but the reverse mapping was incorrect.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae7175b25856b7e4df72222f6f7e1cae01e70d1b" translate="yes" xml:space="preserve">
          <source>In this case the rollup spec is one of:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b26d5693adce5277e3bdbf4de43dbc5411667fde" translate="yes" xml:space="preserve">
          <source>In this example, we will have 3 groups returned:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eaa639e0e255f653e13034f78f776cfbe936ec31" translate="yes" xml:space="preserve">
          <source>Inconsistent forward metrics mapping bar -&amp;gt; 000001 vs bar -&amp;gt; foo / foo -&amp;gt; 000001</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cdb88beb0c16acc651be9d01e7bff7424298fc8c" translate="yes" xml:space="preserve">
          <source>Inconsistent reverse metrics mapping 000003 -&amp;gt; foo vs 000001 -&amp;gt; foo / foo -&amp;gt; 000001</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89f8f64fdcb014206d50188109e232a940351bb9" translate="yes" xml:space="preserve">
          <source>Inconsistent tags can cause unexpected results when querying. See &lt;code&gt;../writing&lt;/code&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89b7073dc42dac6489a4ed94570aab67ba9c37f2" translate="yes" xml:space="preserve">
          <source>Indent code with 2 spaces, no tabs</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc400fa85066d64045bdb76a544ff0c4d68e922a" translate="yes" xml:space="preserve">
          <source>Indeterminate</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="991c706c79afb5be60b8d0e1bf1c8d82c73b2e51" translate="yes" xml:space="preserve">
          <source>Indicates a corruption in the max ID row.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8e8c3b60558e25f0316919a24626917b8800899" translate="yes" xml:space="preserve">
          <source>Information about the JVM's memory usage.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b06ac4620a2be4226c886d1c939da0d80fc631e" translate="yes" xml:space="preserve">
          <source>Information about the system</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a390c4f1908ccfa931e32bb4b1d37c6c4f0db2e" translate="yes" xml:space="preserve">
          <source>Information about the various garbage collectors such as how many times GC occurred and how long the process spent collecting.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8535f681184477d374f876408b5b9da214089418" translate="yes" xml:space="preserve">
          <source>Information provided by the API user, via a query string or content data, was in error or missing. This will usually include information in the error body about what parameter caused the issue. Correct the data and try again.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85b50c81f8d6e04d62a3d19314675a664e45a814" translate="yes" xml:space="preserve">
          <source>Ingest Plugins - Accept data points in different formats</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a459dff3012da591453989e5860a6fd825f63ce3" translate="yes" xml:space="preserve">
          <source>Initialize</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c7935726f449ea7185a4fe42a9ddf2d1c53a2e4" translate="yes" xml:space="preserve">
          <source>Input Format</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c968ad8768affe487c292b6adc7616df4a013a6b" translate="yes" xml:space="preserve">
          <source>Input Methods</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c81b79df3c6448eae7c4f80428b54cd5692a17d7" translate="yes" xml:space="preserve">
          <source>Installation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89ca21055beb3df30d3aa6d0ef3a19552bd88da5" translate="yes" xml:space="preserve">
          <source>Installation includes an init script at &lt;code&gt;/etc/init.d/opentsdb&lt;/code&gt; that can start, stop and restart OpenTSDB. Simply call &lt;code&gt;service opentsdb start&lt;/code&gt; to start the tsd and &lt;code&gt;service opentsdb stop&lt;/code&gt; to gracefully shutdown. Note after install, the tsd will not be running so that you can edit the configuration file. Edit the config file, then start the TSD.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba4685d41a8fbde77d97c449bb4b97c89a036837" translate="yes" xml:space="preserve">
          <source>Installation of tcollector</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9edcffff4461c9083fbff857f8dcee0f0769cbd4" translate="yes" xml:space="preserve">
          <source>Integer</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2536e8bab30f215602182766e7831f56b678a0c2" translate="yes" xml:space="preserve">
          <source>Integer Values</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4eefcd703adf54514a38840d40069ffd4f23d1b" translate="yes" xml:space="preserve">
          <source>Integer, Float, String</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b4db7ef1fa23cfb5e115a2a2c89d46a6a2ebc4a" translate="yes" xml:space="preserve">
          <source>Interface</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="534d23d2db4ff77beebaffcb96c45e2acb850465" translate="yes" xml:space="preserve">
          <source>Internally, all data is associated with a Unix (or POSIX) style timestamp. Unix times are defined as the number of seconds that have elapsed since January 1st, 1970 at 00:00:00 UTC time. Timestamps are represented as a positive integer such as &lt;code&gt;1364410924&lt;/code&gt;, representing &lt;code&gt;ISO 8601:2013-03-27T19:02:04Z&lt;/code&gt;. Since calls to store data in OpenTSDB require a Unix timestamp, it makes sense to support the format in queries. Thus you can supply an integer for a start or end time in a query.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b7f4433512bdb6249a73c463ee65748fccf1840" translate="yes" xml:space="preserve">
          <source>Interpolated A</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e547e41ddd420190786eb61bbe7b32285c113dd5" translate="yes" xml:space="preserve">
          <source>Interpolated B</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a9858c9bf3149456595f98943cf88e41039822e" translate="yes" xml:space="preserve">
          <source>Interpolation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="703bdb74e3129043886da27e694edd35abc8f244" translate="yes" xml:space="preserve">
          <source>Interpolation is only performed at query time when more than one time series are found to match a query. Many metrics collection systems interpolate on &lt;em&gt;write&lt;/em&gt; so that you original value is never recorded. OpenTSDB stores your original value and lets you retrieve it at any time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3461532ec142009199b33a0d25a2167bb6957b7" translate="yes" xml:space="preserve">
          <source>Intervals are specified by a number and a unit of time. For example, &lt;code&gt;30m&lt;/code&gt; will aggregate data points every 30 minutes. &lt;code&gt;1h&lt;/code&gt; will aggregate across an hour. See &lt;a href=&quot;dates&quot;&gt;&lt;em&gt;Dates and Times&lt;/em&gt;&lt;/a&gt; for valid relative time units. Do not add the &lt;code&gt;-ago&lt;/code&gt; to a down sampling query.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb541eb9d60d617eb465af8d87eba390ffe6a1e6" translate="yes" xml:space="preserve">
          <source>Invalid maximum ID for metrics: should be on 8 bytes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7934af76805c24e0f4ca5efcac9ed41591d0d569" translate="yes" xml:space="preserve">
          <source>Issuing a &lt;code&gt;POST&lt;/code&gt; will merge the given rule set with any that already exist. This means that if a rule already exists for one of the given rules, only the fields given will be modified in the existing rule. Using the &lt;code&gt;PUT&lt;/code&gt; method will replace &lt;em&gt;all&lt;/em&gt; of the rules for the given tree with the new set. Any existing rules for the tree will be deleted before the new rules are stored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d13f1f2dd1250d1e694ae6aef1b4af28548fe48c" translate="yes" xml:space="preserve">
          <source>It can be a little daunting at first but you can break it down into components. If you're ever confused, try using the built-in GUI to plot a graph the way you want it, then look at the URL to see how the query is formatted. Changes to any of the form fields will update the URL (which you can actually copy and paste to share with other users). For examples, please see &lt;a href=&quot;../../user_guide/query/examples&quot;&gt;&lt;em&gt;Query Examples&lt;/em&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dbef3623630c264f0e2d99e41a71b7280a4c9739" translate="yes" xml:space="preserve">
          <source>It is possible that your situation requires this value to be increased. If you choose to modify this value, you must start with fresh data and a new UID table. Any data written with a TSD expecting 3-byte UID encoding will be incompatible with this change, so ensure that all of your TSDs are running the same modified code and that any data you have stored in OpenTSDB prior to making this change has been exported to a location where it can be manipulated by external tools. See the &lt;code&gt;TSDB.java&lt;/code&gt; file for the values to change.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb2ac4e5581dc46967329d03e4b77df252c67cf5" translate="yes" xml:space="preserve">
          <source>It is safe to run this command at any time as it will not destroy or overwrite valid data. (Unless you modify columns directly in HBase in a manner inconsistent with the meta data formats). The utility will split the data table into chunks processed by multiple threads so the more cores in your processor, the faster the command will complete.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04865d820ea135a8cf2d8c3244b5ab6dff76d5fb" translate="yes" xml:space="preserve">
          <source>It is similar to a regular metric query but does not allow for aggregations, rates, down sampling or grouping operators. Note that if you supply a backscan value to avoid the meta table, then you must supply all of the tags and values to match the exact time series you are looking for. Backscan does not currently filter on the metric and tags given but will look for the specific series.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77c352fcae9418e7b551a2b5c45231080ced86dd" translate="yes" xml:space="preserve">
          <source>It seems intuitive from the image above that if you &quot;stack up&quot; the red line and the green line, you'd get the blue line. At any discrete point in time, the blue line has a value that is equal to the sum of the value of the red line and the value of the green line at that time. Without interpolation, you get something rather unintuitive that is harder to make sense of, and which is also a lot less meaningful and useful:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a66fd5267715524c544f852261194c03ce5110a8" translate="yes" xml:space="preserve">
          <source>Iteration continues over every timestamp for which a data point is found for every series returned as a part of the query. The resulting series, using the &lt;strong&gt;sum&lt;/strong&gt; aggregator, will look like this:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="511fb9d29540bc341499a38b2530c6786ac510db" translate="yes" xml:space="preserve">
          <source>JAR to see what works for you.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c01ceebfcaaf3262991f1050f2d8e92b54b707d9" translate="yes" xml:space="preserve">
          <source>JAVA_HOME</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b67be8e6eb2a527d8d26ada76cf4d9595877ada8" translate="yes" xml:space="preserve">
          <source>JBOD for the HDFS data nodes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c83f878d10f3c07f6e5b0e198a8e29d125c55b2" translate="yes" xml:space="preserve">
          <source>JSON - Many calls can respond in a JSON format when the &lt;code&gt;json&lt;/code&gt; query string parameter is appended</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff4ceb5b4ec6d9649ff6df0ad563ea0bc2da2d04" translate="yes" xml:space="preserve">
          <source>JSON Serializer</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a51684e373169b33dd5e28744788ac71c209eaf1" translate="yes" xml:space="preserve">
          <source>JSON requests follow the search query format on the &lt;a href=&quot;index&quot;&gt;&lt;em&gt;/api/search&lt;/em&gt;&lt;/a&gt; page. Limits and startNote that tags are supplied as a list of objects. The value for the &lt;code&gt;key&lt;/code&gt; should be a &lt;code&gt;tagk&lt;/code&gt; and the value for &lt;code&gt;value&lt;/code&gt; should be a &lt;code&gt;tagv&lt;/code&gt; or wildcard.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42c6036ddd5d662bc456c530699d3704be7c5087" translate="yes" xml:space="preserve">
          <source>JSONP</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2199c97fce8130bafac545632824e9d5461764c9" translate="yes" xml:space="preserve">
          <source>Java Development Kit 1.6 or later</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e88ad705384c70ef2b44fc2c1030c1eff0201e7" translate="yes" xml:space="preserve">
          <source>Java Long.MaxValue</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66b12d3504d1e54c34ceb06199a2fc10bdd0c9b3" translate="yes" xml:space="preserve">
          <source>Java Runtime Environment 1.6 or later</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9cc24886f802218b1111161da682da22b4b9ba5" translate="yes" xml:space="preserve">
          <source>Javadoc all of your classes and methods. Some folks make use the Java API directly and we'll build docs for the site, so the more the merrier</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bccbe151cb94ab829e59fc1a7c70ed10061810bb" translate="yes" xml:space="preserve">
          <source>Keep code to 80 columns</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1e2c6f1017f4bada2b2cee540da233c3ca9a0bf" translate="yes" xml:space="preserve">
          <source>Keep the cluster in a single data center</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3bcd90c2c2b4af0b0ee0ede997c3bb2cf209e8d2" translate="yes" xml:space="preserve">
          <source>Key Tab</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="098eeaebc4158474bc2be818c08af354bd7af4d9" translate="yes" xml:space="preserve">
          <source>LOOKUP</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="317610f45198965a3b4afdcfa294ec50b7a31b4d" translate="yes" xml:space="preserve">
          <source>Large queries - A very large query with many time series or for a long range can cause the TSD to OOM. Try reducing query size or break large queries up into smaller chunks.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd340895ea4c2472332113954c7b3f6f7e4dfacb" translate="yes" xml:space="preserve">
          <source>Last Data Point API - Query for the last data point for specific time series within a certain time window</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4214f511c21ec4af5bd5105a09d600ed09ce364" translate="yes" xml:space="preserve">
          <source>Late or historical data may not be rolled up unless some means of tracking is in place to trigger a new batch on old data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3838fea112b44109e870060efe55094b0a8809c5" translate="yes" xml:space="preserve">
          <source>Late/historical data must be handled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="114e55035387c3915c69418cde2713565cf60f2a" translate="yes" xml:space="preserve">
          <source>Leaf Column</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84c102209b5f000bb964c0f273ba6ed753c13ff2" translate="yes" xml:space="preserve">
          <source>Leaves</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01d13bc2a41dbdec54060f088548e62e3f01c280" translate="yes" xml:space="preserve">
          <source>Leaves are mappings to specific time series and represent the end of a hierarchy. Leaf columns have a qualifier format of &lt;code&gt;leaf:&amp;lt;TSUID&amp;gt;&lt;/code&gt; where the TUID is a byte array representing the time series identifier. The value of a leaf is a UTF-8 encoded JSON object describing the leaf. Leaves may appear in any row other than the collision or not matched rows.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b91a39e715b5dd79fd41f5b421f6dd720aaa1107" translate="yes" xml:space="preserve">
          <source>Let's imagine that you have a cron job that crunches gigabytes of application logs every day or every hour to extract profiling data. For instance, you could be logging the time taken to process a request and your cron job would compute an average for every 30 second window. Maybe you're particularly interested in 2 types of requests handled by your application, so you'll compute separate averages for those requests, and an another average for every other request type. So your cron job may produce an output file that looks like this:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02848a973c3f5f337d2abad5e1799b74f0be976a" translate="yes" xml:space="preserve">
          <source>Let's take the following data set as an example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4288c40739461a208df032b261c3b6bbf137871d" translate="yes" xml:space="preserve">
          <source>Lets say there is a branch with a display name of &lt;code&gt;cpu&lt;/code&gt; off of the &lt;code&gt;sys&lt;/code&gt; child branch. &lt;code&gt;cpu&lt;/code&gt; returns a hash of 98728 which converts to &lt;code&gt;000181A8&lt;/code&gt; in hex. The ID of this child would be &lt;code&gt;00010001BECD000181A8&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c7f5d049fad2569721d446c4a811f9bd5da5393" translate="yes" xml:space="preserve">
          <source>Level</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed47f098118b3a4908065115144a054c9afe75d6" translate="yes" xml:space="preserve">
          <source>Levels</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e6fa6bf971a599c07b4de7c9b9baceed7df4e7d" translate="yes" xml:space="preserve">
          <source>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="728c047e152b6ac5fdb87c190b43566da98bc782" translate="yes" xml:space="preserve">
          <source>Likewise with 2.3, the introduction of new backends (Bigtable or Cassandra) requires setting up new storage tables and migrating data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="febb6bd9ba9ee24d9e33ae64c2a225eecf493c60" translate="yes" xml:space="preserve">
          <source>Limits the number of results returned per query so as not to override the TSD or search engine. Allowable values depends on the plugin. Ignored for lookups.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf20aa01df73b14ef91c22a3239e5742b38f16b5" translate="yes" xml:space="preserve">
          <source>Linear Interpolation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a1fffaaafb7cc996685bceb829c053cc4f7de43d" translate="yes" xml:space="preserve">
          <source>List</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9dffa170c15c512b1149fb8f10d0f65f8eda692f" translate="yes" xml:space="preserve">
          <source>List of parent branch names and their depth.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f75c5ea1889d1c9e89c1aaa936ec37be51f075f6" translate="yes" xml:space="preserve">
          <source>Load Balancing with Varnish</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c778e2a003e4796bd49dc9aa189e437eb9a53b26" translate="yes" xml:space="preserve">
          <source>Location of a directory where static files, such as JavaScript files for the web interface, are located. E.g. /opt/opentsdb/staticroot</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e5fda6a6bf40b9db053433b812886f36ea75872" translate="yes" xml:space="preserve">
          <source>Lock-less UID Assignment - Drastically improves write speed when storing new metrics, tag names, or values</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4cdd83a8d932d2c1c756729303b6f4199a33d0b3" translate="yes" xml:space="preserve">
          <source>Log to Rotating File</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="012294fbc07fc652fdbbd3b8b48183b6e7925dda" translate="yes" xml:space="preserve">
          <source>Loggers</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea42056a00f753aedb3d5e8bd44091a241ec3cd1" translate="yes" xml:space="preserve">
          <source>Loggers determine what data and what level of data is routed to the appenders. Loggers can match a particular Java class namespace and affect all messages emitted from that space. The default OpenTSDB config explicitly lists some loggers for Zookeeper, AsyncHBase and the Async libraries to set their levels to &lt;code&gt;INFO&lt;/code&gt; so as to avoid chatty outputs that are not relevant most of the time. If you enable a plugin and start seeing a lot of messages that you don't care about, add a logger entry to suppress the messages.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57003616863fe634c645e342ee9080681e419c5f" translate="yes" xml:space="preserve">
          <source>Logging</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24a8149d217351f60f5a6d88af39249b331f548a" translate="yes" xml:space="preserve">
          <source>Logs - If Logback is configured, this tab will show you a list of the latest 1,024 log entries for the TSD.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7015ab4fc4ea24735dbe884238cc1b54bf915eca" translate="yes" xml:space="preserve">
          <source>Lookup</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8efadfb0d466b81d278891967086e84ba83fc97" translate="yes" xml:space="preserve">
          <source>Lookup Queries</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39a231ee59452a0ac63678ccbc459bcd2a576f16" translate="yes" xml:space="preserve">
          <source>Lookup queries use either the meta data table or the main data table to determine what time series are associated with a given metric, tag name, tag value, tag pair or combination thereof. For example, if you want to know what metrics are available for a tag pair &lt;code&gt;host=web01&lt;/code&gt; you can execute a lookup to find out.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a0d45630834d0012fbb8a2eaa67128321c422a6" translate="yes" xml:space="preserve">
          <source>Lookup queries use either the meta data table or the main data table to determine what time series are associated with a given metric, tag name, tag value, tag pair or combination thereof. For example, if you want to know what metrics are available for a tag pair &lt;code&gt;host=web01&lt;/code&gt; you can execute a lookup to find out. Lookups do not require a search plugin to be installed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf52ef6ec575d50f585f43290fec0787329218bc" translate="yes" xml:space="preserve">
          <source>Lookups are performed against the &lt;code&gt;tsdb-meta&lt;/code&gt; table. You must enable real-time meta data creation or perform a &lt;code&gt;metasync&lt;/code&gt; using the &lt;code&gt;uid&lt;/code&gt; command in order to retreive data from a lookup. Lookups can be executed against the raw data table using the CLI command only: &lt;a href=&quot;../../user_guide/cli/search&quot;&gt;&lt;em&gt;search&lt;/em&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45922392891b6cd57294e30b7438cfa8350c7cf9" translate="yes" xml:space="preserve">
          <source>METRIC</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07c776843600a1a0ee886c00c16cde4637a672ae" translate="yes" xml:space="preserve">
          <source>METRIC_CUSTOM</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aed201d3a5d999b16d4db18fa72d635462a3905c" translate="yes" xml:space="preserve">
          <source>METRIC_CUSTOM, TAGK_CUSTOM, TAGV_CUSTOM, TAGK</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a94431ee22f05f141107f9355ed3127d0f0c4d5a" translate="yes" xml:space="preserve">
          <source>Make</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4b4166148ec00d91d7af8a2a17b98841df8c9503" translate="yes" xml:space="preserve">
          <source>Make sure the &lt;code&gt;tsd.core.plugin_path&lt;/code&gt; is configured</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e63e4519432a184f2c433088dda29083ad55f057" translate="yes" xml:space="preserve">
          <source>Manifest</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75eadec51943b660371436450ab8dd81e67e84d3" translate="yes" xml:space="preserve">
          <source>Many devs use an IDE to work on Java projects and despite OpenTSDB's non-java-standard directory layout, working with an IDE is pretty easy. Here are some steps to get up and running with Eclipse though they should work with other environments. This example assumes you're using Eclipse.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="332ade048d7b4069806d7889df5fdcb23926198f" translate="yes" xml:space="preserve">
          <source>Many metrics administrators are used to supplying a single name for their time series. For example, systems administrators used to RRD-style systems may name their time series &lt;code&gt;webserver01.sys.cpu.0.user&lt;/code&gt;. The name tells us that the time series is recording the amount of time in user space for cpu &lt;code&gt;0&lt;/code&gt; on &lt;code&gt;webserver01&lt;/code&gt;. This works great if you want to retrieve just the user time for that cpu core on that particular web server later on.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab478f3efc840eebab919dff1b9512286f70c10c" translate="yes" xml:space="preserve">
          <source>Map</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a95e85aed56318093b024674e217cae0bd30241d" translate="yes" xml:space="preserve">
          <source>Max</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4599a7eb62394713f702cc7b07d3015ceb4b6d32" translate="yes" xml:space="preserve">
          <source>Max ID for metrics is 42 but only 41 entries were found. Maybe 1 IDs were deleted?</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db86474dec388c24f37806fc4a4a0131c727c441" translate="yes" xml:space="preserve">
          <source>Maximum if missing</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="576c9b593a3820495f3179673411340efc0d26f1" translate="yes" xml:space="preserve">
          <source>Mbps</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57f5f5efbc5990f5230aa95359042338b856707b" translate="yes" xml:space="preserve">
          <source>Menu</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0803ee338b6dc33a0b43f8b4a70d850da40d5399" translate="yes" xml:space="preserve">
          <source>Meta Data - Record meta data for each time series, metrics, tag names, or values</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6255e06ebf274c8e49075ff0a301f02e9cb57eae" translate="yes" xml:space="preserve">
          <source>Meta Data Cache Plugin - A new API for caching meta data to improve query performance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52926b7418fef758980e37e0c8b86a1b3d922c1d" translate="yes" xml:space="preserve">
          <source>Meta Table Schema</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53fc4e26ad23e4ee8830730831adf7a698659e9b" translate="yes" xml:space="preserve">
          <source>Meta data around the query including the first and last timestamps, number of result &quot;sets&quot;, or sub arrays, and the number of series represented.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="251edc0eb5a820646bda4e103f0f007fd55321f3" translate="yes" xml:space="preserve">
          <source>Metadata</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54a7ed73595c70862f494206b4fae823925d91a4" translate="yes" xml:space="preserve">
          <source>Methods named &lt;code&gt;likeThis()&lt;/code&gt; starting with lower case letters</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2bb7604c825f95a49cbb58b776a65bf15a636d5" translate="yes" xml:space="preserve">
          <source>Metric</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2942b0071aadad2ad2037667c07810c94a395e55" translate="yes" xml:space="preserve">
          <source>Metric Query String Format</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="828c5735ccb81c197f0b62ccf9b6ede40d74abf1" translate="yes" xml:space="preserve">
          <source>Metric and tags are not limited in length, though you should try to keep the values fairly short.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7babd971d8b691f64fc4dbdbafa503727784a15f" translate="yes" xml:space="preserve">
          <source>Metric_Custom</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a1ba5a43c2e3e88980be3bfc95a987be3b859b4" translate="yes" xml:space="preserve">
          <source>Metrics Section</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a288895283a58f59282edc123ab26fb45f6eb69f" translate="yes" xml:space="preserve">
          <source>Metrics and Tags</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6e7c7ea27e0a9afddbddaef07902a5c6c92dff1" translate="yes" xml:space="preserve">
          <source>Metrics need to be registered before you can start storing data points for them. This helps to avoid ingesting unwanted data and catch typos. You can enable auto-metric creation via configuration. To register one or more metrics, call the &lt;code&gt;mkmetric&lt;/code&gt; CLI:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="172a4d46f41d1c4a8751714123b984496c77ee49" translate="yes" xml:space="preserve">
          <source>Millisecond Resolution - Optionally store data with millisecond precision</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b46d6b2f487f5c498f14fd5bf3bdc6b81a497a8" translate="yes" xml:space="preserve">
          <source>MimMax</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3b4067d5ea6d0acca341c7696ad0da3d1411717" translate="yes" xml:space="preserve">
          <source>MimMin</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7eb0cee888ab55b559592d38eec027e9118d7d35" translate="yes" xml:space="preserve">
          <source>Min</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7b81776894ab205b79ada629ab1690b24afc965" translate="yes" xml:space="preserve">
          <source>Minimum if missing</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f2cbd107037ed23248e5058a7a64cd6bae05468" translate="yes" xml:space="preserve">
          <source>Miscellaneous</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9b302a6528230e8fad06287d3026dae18ccadf3" translate="yes" xml:space="preserve">
          <source>Missing Data</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="efbc0994901f961de2f359700e2d40663558e4c7" translate="yes" xml:space="preserve">
          <source>Missing required parameter</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b36f0db7aa40c151d482e1f00e6437f8376302ea" translate="yes" xml:space="preserve">
          <source>Missing value: type</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3ea079ded57effba0d3c11311c33855f14ee35e" translate="yes" xml:space="preserve">
          <source>Modification</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06c182132e7848ec4952598addababab10da20c5" translate="yes" xml:space="preserve">
          <source>Modify your</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a81434589757e654444719de434c44e9adc0c708" translate="yes" xml:space="preserve">
          <source>Monitoring</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e4c0ee80cd508e22520769ddbd59a304cfc7bd7" translate="yes" xml:space="preserve">
          <source>Monotonically increasing counter handling options</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29a0218f3ace5bc2a8fa10d617b8301a61cb0c13" translate="yes" xml:space="preserve">
          <source>More Stats - Gives greater insight into query performance via the query stats endpoint and new stats for threads, region clients and the JVM</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b04ca253f1e5b83aa515505663386283f1c863e" translate="yes" xml:space="preserve">
          <source>Most of the API endpoints support query string parameters, particularly those that fetch data from the system. However due to the complexities of encoding some characters, and particularly Unicode, all endpoints also support access via POST content using formatters. The default format is JSON so clients can use their favorite means of generating a JSON object and send it to the OpenTSDB API via a &lt;code&gt;POST&lt;/code&gt; request. &lt;code&gt;POST&lt;/code&gt; requests will generally provided greater flexibility in the fields offered and fully Unicode support than query strings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9fd6a7b547c07fe911d9e9da377a2b1c907b5c6c" translate="yes" xml:space="preserve">
          <source>Most of the endpoints can return data in one or more of the following formats:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c015179e33ea024b4a1eb95711b092dc00e7400" translate="yes" xml:space="preserve">
          <source>Multiple NSREs from HBase - See the section above about TSDs being slow to respond.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="653a65a6c1dcab77391413c4444ee836b7b34fc4" translate="yes" xml:space="preserve">
          <source>Multiple TSDs</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b3ebc3263f8da11db4556b59021611f7378cfa9" translate="yes" xml:space="preserve">
          <source>Multiple data points must be encased in an array:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9fc72ec8c2bc223a0823c73f7a70a9abccdc92a" translate="yes" xml:space="preserve">
          <source>Multiple filters on the same tag key are allowed and when processed, they are &lt;em&gt;ANDed&lt;/em&gt; together e.g. if we have two filters &lt;code&gt;host=literal_or(web01)&lt;/code&gt; and &lt;code&gt;host=literal_or(web02)&lt;/code&gt; the query will always return empty. If two or more filters are included for the same tag key and one has group by enabled but another does not, then group by will effectively be true for all filters on that tag key.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5869a3f20dea67419a630ed689cf876406a93707" translate="yes" xml:space="preserve">
          <source>Multiplies each series by the factor where the factor can be a positive or negative floating point or integer value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08d2e98e6754af941484848930ccbaddfefe13d6" translate="yes" xml:space="preserve">
          <source>N/A</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7fd9c68f804acda665d2ab082217bb1583318f2" translate="yes" xml:space="preserve">
          <source>NaN</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="701cf559ebe2d962b264f4a812b01780267ee7f8" translate="yes" xml:space="preserve">
          <source>NaN (&lt;code&gt;nan&lt;/code&gt;) - Emits a &lt;code&gt;NaN&lt;/code&gt; in the serialization output when all values are missing in a series. Skips series in aggregations when the value is missing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="887b71119b10892a3b47c01960d6e01fd10126b2" translate="yes" xml:space="preserve">
          <source>Nagios Setup</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="709a23220f2c3d64d1e1d6d18c4d5280f8d82fca" translate="yes" xml:space="preserve">
          <source>Name</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef9f6d0443d96293fe85e547bae432178f74eb55" translate="yes" xml:space="preserve">
          <source>Name - The name of the field</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ad059102e8676ae5c5357762581cd3a7425f55d" translate="yes" xml:space="preserve">
          <source>Name of the HBase table where UID information is stored</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4adda46b26e78164254ddd4943f39536029cfb2" translate="yes" xml:space="preserve">
          <source>Name of the HBase table where data points are stored</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc4b90de13ab71d4e4840a71bcce71b9a5194b2e" translate="yes" xml:space="preserve">
          <source>Name of the HBase table where datapoints are stored</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39223f9e2b299e3eea02c4efd5248e0dd14fc317" translate="yes" xml:space="preserve">
          <source>Name of the HBase table where meta data are stored</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93ebdf3a9e3c1fb9dcd22effb7a9676ee92dc781" translate="yes" xml:space="preserve">
          <source>Name of the HBase table where tree data are stored</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="969ee789daa07c2b78860af95b44f9cd31260ed2" translate="yes" xml:space="preserve">
          <source>Name of the branch as determined by the rule set</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c22037b848fced86611c8b80fb22a14007943bc" translate="yes" xml:space="preserve">
          <source>Name of the metric for the time series. Only returned if &lt;code&gt;resolve&lt;/code&gt; was set to true.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e39d2273c1deab0556ac58d2dc7d2107fb39705b" translate="yes" xml:space="preserve">
          <source>Name of the metric retrieved for the time series</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78a90167e16837a3d0f85d379ee76fd9048a01a7" translate="yes" xml:space="preserve">
          <source>Name of the metric the statistic is recording</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="febdd5d7e1c369f366fa56d2af084ce5d63a0a6d" translate="yes" xml:space="preserve">
          <source>Naming Conclusion</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5eb6bf51c4795dd9f8b5ced82a5fd8bc74e134db" translate="yes" xml:space="preserve">
          <source>Naming Schema</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24dc711689882d2a851fc1014063372ed284f34d" translate="yes" xml:space="preserve">
          <source>Natively, OpenTSDB supports ingesting data points via Telnet or HTTP. The RPC plugin interface allows users to implement and choose alternative protocols such as Protobufs, Thrift, Memcache or any other means of storing information. More than one plugin can be loaded at a time via the &lt;code&gt;tsd.rpc.plugins&lt;/code&gt; or</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12e9c7608e195a4ecdf0e706d80c058155b03ad0" translate="yes" xml:space="preserve">
          <source>Navigating a tree starts at the &lt;strong&gt;root&lt;/strong&gt; branch which always has an ID that matches the ID of the tree the branch belongs to. The root should have one or more child branches that can be used to navigate down one level of the tree. Each child can be used to navigate to their children and so on. The root does not have any parent branches and is always at a depth of 0. If a tree has just been defined or enabled, it may not have a root branch yet, and by extension, there won't be any child branches.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08f31997c6791e050f02358be3741b9cd2c4d5b1" translate="yes" xml:space="preserve">
          <source>Network Infrastructure</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="963ea2d63a7dcb65df8d0ed2a6513b4943a1e702" translate="yes" xml:space="preserve">
          <source>Network Outage</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="464ea25d57932d60c237d290a43157e97cab1b3e" translate="yes" xml:space="preserve">
          <source>New Aggregators - None for returning raw data. First and Last to return the first or last data points during downsampling.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3be56acd35942405baf46cbf78c0431fe4f8b992" translate="yes" xml:space="preserve">
          <source>New I/O worker #23</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9cdcd6337ad0d17e960f98b30fd0d49a333db9a7" translate="yes" xml:space="preserve">
          <source>New features or major changes should be done in the &lt;code&gt;next&lt;/code&gt; branch</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96ea1a9cbe64e58764ab1df7aacde024f16079e5" translate="yes" xml:space="preserve">
          <source>New for 2.2, OpenTSDB includes expanded and plugable filters across tag key and value combinations. For a list of filters loaded in the TSD, see &lt;a href=&quot;../config/filters&quot;&gt;&lt;em&gt;/api/config/filters&lt;/em&gt;&lt;/a&gt;. For descriptions of the built-in filters see &lt;a href=&quot;../../user_guide/query/filters&quot;&gt;&lt;em&gt;Filters&lt;/em&gt;&lt;/a&gt;. Filters can be used in both query string and POST formatted queries. Multiple filters on the same tag key are allowed and when processed, they are &lt;em&gt;ANDed&lt;/em&gt; together e.g. if we have two filters &lt;code&gt;host=literal_or(web01)&lt;/code&gt; and &lt;code&gt;host=literal_or(web02)&lt;/code&gt; the query will always return empty. If two or more filters are included for the same tag key and one has group by enabled but another does not, then group by will effectively be true for all filters on that tag key. Fields for POST queries pertaining to filters include:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7095ef4b2b72741bf011f8434168f7fbffa5c517" translate="yes" xml:space="preserve">
          <source>New tags, on the other hand, are automatically registered whenever they're used for the first time. Right now OpenTSDB only allows you to have up to 2^24 = 16,777,216 different metrics, 16,777,216 different tag names and 16,777,216 different tag values. This is because each one of those is assigned a UID on 3 bytes. Metric names, tag names and tag values have their own UID spaces, which is why you can have 16,777,216 of each kind. The size of each space is configurable but there is no knob that exposes this configuration parameter right now. So bear in mind that using user ID or event ID as a tag value will not work right now if you have a large site.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b349d12fb871e6a915de00d20d28cc3322c86c50" translate="yes" xml:space="preserve">
          <source>Next for some data written at 15 minute intervals:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0711f68c03674cae96bc08fa69428a0f97b86897" translate="yes" xml:space="preserve">
          <source>Next we run across a value for &lt;code&gt;A&lt;/code&gt; at time &lt;code&gt;ts0+10s&lt;/code&gt;. We request a value for &lt;code&gt;ts0+10s&lt;/code&gt; from time series &lt;code&gt;B&lt;/code&gt; but there isn't one. But &lt;code&gt;B&lt;/code&gt; knows there is a value at &lt;code&gt;ts0+20s&lt;/code&gt; and we had a value at &lt;code&gt;ts0&lt;/code&gt; so we can now calculate a guess for &lt;code&gt;ts0+10s&lt;/code&gt;. The formula for linear interpolation is &lt;code&gt;y = y0 + (y1 - y0) * ((x - x0) / (x1 - x0))&lt;/code&gt; where, for series &lt;code&gt;B&lt;/code&gt;, &lt;code&gt;y0 = 10&lt;/code&gt;, &lt;code&gt;y1 = 20&lt;/code&gt;, &lt;code&gt;x = ts0+10s (or 10)&lt;/code&gt;, &lt;code&gt;x0 = ts0 (or 0)&lt;/code&gt; and &lt;code&gt;x1 = ts0+20s (or 20)&lt;/code&gt;. Thus we have &lt;code&gt;y = 10 + (20 - 10) * ((10 - 0) / (20 - 0)&lt;/code&gt; which will reduce to &lt;code&gt;y = 10 + 10 * (10 / 20)&lt;/code&gt; further reducing to &lt;code&gt;y = 10 + 10 * .5&lt;/code&gt; and &lt;code&gt;y = 10 + 5&lt;/code&gt;. Therefore &lt;code&gt;B&lt;/code&gt; will give us a &lt;em&gt;guestimated&lt;/em&gt; value of &lt;code&gt;15&lt;/code&gt; at &lt;code&gt;ts0+10s&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bfdd939b5f32adf3f8614a85ba076be26f264c93" translate="yes" xml:space="preserve">
          <source>Next, back in the &lt;code&gt;third_party/&lt;/code&gt; directory, edit the &lt;code&gt;include.mk&lt;/code&gt; file and if you added a new directory for your dependency, insert a reference to the &lt;code&gt;.mk&lt;/code&gt; file in the proper alphabetical position.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="816c52fd2bdd94a63cd0944823a6c0aa9384c103" translate="yes" xml:space="preserve">
          <source>No</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d30ccc274646f697767e29cf7a6a4abc5ed1d458" translate="yes" xml:space="preserve">
          <source>No fix necessary</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee909257fd1272060e0268789f432865547a951b" translate="yes" xml:space="preserve">
          <source>No fix yet.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb2d3eadd1e3f429c8fc9b3a67a969cc063785ae" translate="yes" xml:space="preserve">
          <source>No implementations at this time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f260c46cb10dc6d62956dca30890ea1b36ba3b72" translate="yes" xml:space="preserve">
          <source>No implementations, aside from the default, at this time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c79d10acbd7d432840012722438f0491c360e019" translate="yes" xml:space="preserve">
          <source>No parameters are available, this is a read-only endpoint that simply returns system data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad65a67cca5a6396458f91765ea1237bcbea0ff7" translate="yes" xml:space="preserve">
          <source>No parameters available.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b2907e25c8db4308af5a98fdda6bc0efb3dedf6" translate="yes" xml:space="preserve">
          <source>Non-Interpolating Aggregation Functions - For situations where you require raw data</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6eef6648406c333a4035cd5e60d0bf2ecf2606d7" translate="yes" xml:space="preserve">
          <source>None</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b8145c46da81fb2c02b5f159fb720d1b27fa8ef" translate="yes" xml:space="preserve">
          <source>None (&lt;code&gt;none&lt;/code&gt;) - The default behavior that does not emit missing values during serialization and performs linear interpolation (or otherwise specified interpolation) when aggregating series.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76a082e19851598e10fa3219e56afd8d62440ba0" translate="yes" xml:space="preserve">
          <source>Normalization works very well for common queries such as a day's worth of data downsampled to 1 minute or 1 hour. However if you try to downsample on an odd interval, such as 36 minutes, then the timestamps may look a little strange due to the nature of the modulus calculation. Given an interval of 36 minutes and our example above, the interval would be &lt;code&gt;2160000&lt;/code&gt; milliseconds and the resulting timestamp &lt;code&gt;1388549520&lt;/code&gt; or &lt;code&gt;04:12:00 UTC&lt;/code&gt;. All data points between &lt;code&gt;04:12&lt;/code&gt; and &lt;code&gt;04:48&lt;/code&gt; would wind up in a single bucket. Also note that OpenTSDB cannot currently normalize on non-UTC times and it cannot normalize on weekly or monthly boundaries.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5d7b8f294aa1e68ea08907ac6af566941bed6d8" translate="yes" xml:space="preserve">
          <source>Normally, tags a provided in the format &lt;code&gt;&amp;lt;tagk&amp;gt;=&amp;lt;tagv&amp;gt;&lt;/code&gt; and a value is required on either side of the equals sign. However for lookups, one value may an asterisk &lt;code&gt;*&lt;/code&gt;, i.e. &lt;code&gt;&amp;lt;tagk&amp;gt;=*&lt;/code&gt; or &lt;code&gt;*=&amp;lt;tagv&amp;gt;&lt;/code&gt;. In these cases, the asterisk acts as a wildcard meaning any time series with the given tagk or tagv will be returned. For example, if we issue a query for &lt;code&gt;host=*&lt;/code&gt; then we will get all of the time series with a &lt;code&gt;host&lt;/code&gt; tagk such as &lt;code&gt;host=web01&lt;/code&gt; and &lt;code&gt;host=web02&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75dcfd2f41e017dd595f80e8cc405fc11af3d537" translate="yes" xml:space="preserve">
          <source>Not Matched</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1608e3939389f0a2e3cb2a0bd7ae3f05a7df518" translate="yes" xml:space="preserve">
          <source>Not Matched Column</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d71eab6323b7c31e94cdd0d65a77dff04da7974b" translate="yes" xml:space="preserve">
          <source>Not Set</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93039e609d94a24f3572b794a31b21525a09af2b" translate="yes" xml:space="preserve">
          <source>Not set</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c924e3088204ee77ba681f72be3444357932fca" translate="yes" xml:space="preserve">
          <source>Note</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86bc12cd5a7d70bbb75c28cf9c0f24afb35122d3" translate="yes" xml:space="preserve">
          <source>Note that a query may return data points before and after the timespan requested. These are used in downsampling and graphing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56f3d7b4a0ccdc933e27edbd8902936ee35393f7" translate="yes" xml:space="preserve">
          <source>Note that for this example we won't be using any custom value rules so we don't need to show the TSMeta objects, but assume these values populate a TSMeta. Also, the TSUIDs are truncated with 1 byte per UID for illustration purposes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73a7c970db8feb7b2baafc98950f0492291adfd6" translate="yes" xml:space="preserve">
          <source>Note that if you try to supply a value that is incompatible with the type the query will throw an exception. E.g. supplying a value with the NaN that isn't NaN will throw an error.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85974a60bb2d8b3377f2a5f6128e435ab080d2b4" translate="yes" xml:space="preserve">
          <source>Note that some type of filters may cause queries to execute slower than others, e.g. the regex and wildcard filters. Before fetching data from storage, the filters are processed to create a database filter based on UIDs so using the case sensitive &quot;literal or&quot; filter is always faster than regex because we can resolve the strings to UIDs and send those to the storage system for filtering. Instead if you ask for regex or wildcards with pre, post or infix filtering the TSD must retrieve all of the rows from storage with the tag key UID, then for each unique row, resolve the UIDs back to strings and then run the filter over the results. Also, filter sets with a large list of literals will be processed post storage to avoid creating a massive filter for the backing store to process. This limit defaults to &lt;code&gt;4096&lt;/code&gt; and can be configured via the &lt;code&gt;tsd.query.filter.expansion_limit&lt;/code&gt; parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1d10cee5959c33e409f7ce4209dd03fb5dbb632" translate="yes" xml:space="preserve">
          <source>Note that the daemon does not fork and run in the background.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0b633a005658ea918dd2c53b81c73b0bd883bd8" translate="yes" xml:space="preserve">
          <source>Note that the in example #2, the &lt;code&gt;web01&lt;/code&gt; group included the odd-ball timeseries #4 and #5. We can filter those out by specifying a second tag ala:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5bb5b4ad4aa01c2c6d8a42df40c7b5a18f81cd70" translate="yes" xml:space="preserve">
          <source>Note that the stack trace is truncated. Also, the trace will include system specific line endings (in this case &lt;code&gt;\r\n&lt;/code&gt; for Windows). If displaying for a user or writing to a log, be sure to replace the &lt;code&gt;\n&lt;/code&gt; or &lt;code&gt;\r\n&lt;/code&gt; and &lt;code&gt;\r&lt;/code&gt; characters with new lines and tabs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82b46b5b65d57112e05c7348d31e573643e345fe" translate="yes" xml:space="preserve">
          <source>Note that when a query specifies a down sampling function and multiple time series are returned, downsampling occurs &lt;strong&gt;before&lt;/strong&gt; aggregation. I.e. now that we have &lt;code&gt;A Downsampled&lt;/code&gt; and &lt;code&gt;B Downsampled&lt;/code&gt; we can aggregate the two series to come up with the aggregated result on the bottom line.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b09f8fe2df18a6273b261ccd186c635c91636e35" translate="yes" xml:space="preserve">
          <source>Note that while queries require an aggregator, it is effectively ignored. If a query encompasses many time series, the scan output may be extremely large so be careful when crafting queries.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77e852ae20c0336da14bc329c67b89a0d0e4c2ee" translate="yes" xml:space="preserve">
          <source>Note that you can mix multiple metric and TSUID queries in one request.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83423c198b6099edba08f185f940042d5dba3b79" translate="yes" xml:space="preserve">
          <source>Note:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b13bbdc26b02eec3b76f748ec07fee4db78ebeb" translate="yes" xml:space="preserve">
          <source>Note: The TSD will allow clients to cache static files for 1 year by default, and will report the age of the file on disk. If the file name contains nocache, then the TSD will tell clients to not cache the file (this idiom is used by GWT).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88a53dfed68a71e7def0d19dbf3ba792f8b0f011" translate="yes" xml:space="preserve">
          <source>Notice how the blue line drops down to the green data point at 18:46:48. No need to be a mathematician or to have taken advanced maths classes to see that interpolation is needed to properly aggregate multiple time series together and get meaningful results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ed4053c53437c6637cc39ce65ddb59738f02f96" translate="yes" xml:space="preserve">
          <source>Notice that all timestamps align to the top of the hour regardless of when the first data point in the interval &quot;bucket&quot; appears. Also notice that if a data point is not present for an interval, the count is lower.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53b57163efeb90411f3588e280a765845223f3b1" translate="yes" xml:space="preserve">
          <source>Notice that some data points are missing. With those data sets, lets look at rollups first.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d31bc3ee6182b0bd3f5039458dfc9bfa968baa5e" translate="yes" xml:space="preserve">
          <source>Notice that the &lt;code&gt;metric&lt;/code&gt; did not include a specific number or a time. That is becaue a &lt;code&gt;metric&lt;/code&gt; is just a label of what you are measuring. The actual measurements are called &lt;code&gt;datapoints&lt;/code&gt;, as you'll see later.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a74b3c2aedf70733bde3131fdc78193eefa5a071" translate="yes" xml:space="preserve">
          <source>Notice that these time series have dropped the tags for &lt;code&gt;host&lt;/code&gt; and &lt;code&gt;interface&lt;/code&gt;. That's because, during aggregation, multiple, different values of the &lt;code&gt;host&lt;/code&gt; and &lt;code&gt;interface&lt;/code&gt; have been wrapped up into this new series so it no longer makes sense to have them as tags. Also note that we injected the new &lt;code&gt;_aggregate&lt;/code&gt; tag in the stored data. Queries can now access this data by specifying an &lt;code&gt;_aggregate&lt;/code&gt; value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d98cb4c48ce6b2941f4331dc3bfd29f569039b1" translate="yes" xml:space="preserve">
          <source>Notice that they all have the same &lt;code&gt;metric&lt;/code&gt; and &lt;code&gt;interface&lt;/code&gt; tag, but different &lt;code&gt;host&lt;/code&gt; and &lt;code&gt;colo&lt;/code&gt; tags.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1825507c9f865eb1e2f64447d56c32d3eb64219" translate="yes" xml:space="preserve">
          <source>Notice we're simply associating each data point with the name of a metric (myservice.latency.avg) and naming the tag that represents the request type. If each server has its own logs and you process them separately, you may want to add another tag to each line like the &lt;code&gt;host=foo&lt;/code&gt; tag we saw in the previous section. This way you'll be able to plot the latency of each server individually, in addition to your average latency across the board and/or per request type. In order to import a data file in the format above (metric timestamp value tags) simply run the following command:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c12ab03ec2a6ea2fc222718e0ee20ee233cd8ba4" translate="yes" xml:space="preserve">
          <source>Now add the downloaded dependencies by clicking Project -&amp;gt; Properties, click the &lt;code&gt;Java Build Path&lt;/code&gt; menu item and click &lt;code&gt;Add External JARs&lt;/code&gt; button.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ef52326927e1416433f51171ebe75b0da093754" translate="yes" xml:space="preserve">
          <source>Now click Run (or Debug) -&amp;gt; Manage Configurations</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01f93e21e3ae6406a7fa620eea25f1050322b8f5" translate="yes" xml:space="preserve">
          <source>Now compile your JAR and make sure to include the manifest file. Each IDE handles this differently. If you're going command line, try this:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91f47abf8b7b23db830acf95273e98fbb27a8e92" translate="yes" xml:space="preserve">
          <source>Now edit away and when you're ready to publish changes, follow the directions above about modifying the build system (if necessary), publish to your own GitHub fork, and issue a pull request.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f72bd99fa33373b701c413a9783df5639f6ff8e" translate="yes" xml:space="preserve">
          <source>Now for the resulting data:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b92adc045743897881d726bc37857db20415155" translate="yes" xml:space="preserve">
          <source>Now let's setup a tree with &lt;code&gt;strictMatching&lt;/code&gt; disabled and the following rules:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea59d18f380d5390673100ed51038ad9693b5793" translate="yes" xml:space="preserve">
          <source>Now run a build via &lt;code&gt;./build.sh&lt;/code&gt; and verify that it fetches your dependency and builds without errors. * Then run &lt;code&gt;./build.sh pom.xml&lt;/code&gt; to verify that the POM is compiled properly and run a &lt;code&gt;mvn compile&lt;/code&gt; to verify the Maven build works correctly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="49e16452c87892d03cf9510cfed81b066d3590dc" translate="yes" xml:space="preserve">
          <source>Now we'll only get results for #1 - #3, but we lose the &lt;code&gt;dc=lax&lt;/code&gt; values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4235244fa6908de47f1ba75397159be77c2da1d6" translate="yes" xml:space="preserve">
          <source>Now when you plot CPU activity for your webserver cluster, you see all of them aggregated into one plot. Then let's say you add a webserver or even change it from a webserver to a database. All you have to do is make sure the right tag gets sent when its role changes, and now that box's CPU activity gets counted toward the right cluster. What's more, all of your historical data is still correct! This is the true power of OpenTSDB. Not only do you never lose resolution of your datapoints over time like RRD-based systems, but historical data doesn't get lost as your boxes shift around. You also don't have to put a bunch of cluster or grouping awareness logic into your dashboards.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="81dbb9313e698241aca8c1b1a632af97b86bfaad" translate="yes" xml:space="preserve">
          <source>Now, let's revisit what we talked about here at the beginning. A time series is a series of datapoints of some particular metric (and its tags) over time. For this example, each host is sending two time series to the TSD. If you had 3 boxes each sending these two time series, TSD would be collecting and storing 6 time series. Now that you have the data, let's start plotting.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8b931175c4ab1f3ae871a1c0170de5241795fa9" translate="yes" xml:space="preserve">
          <source>Null (&lt;code&gt;null&lt;/code&gt;) - Same behavior as NaN except that during serialization it emits a &lt;code&gt;null&lt;/code&gt; instead of a &lt;code&gt;NaN&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb9ad5c3318845684d645086e5118bc9200c3e23" translate="yes" xml:space="preserve">
          <source>Numeric ID of the thread</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2883f191bc5ebfdc16c0813eff659b35363ea69b" translate="yes" xml:space="preserve">
          <source>Object</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cccc0a58e247265b3a723676dbc5c4cc969f90bb" translate="yes" xml:space="preserve">
          <source>Objects are encoded on 3 or 5 byte qualifiers and the type is determined by a prefix. If a prefix is found that OpenTSDB doesn't recognize, then it will report the object but it will not be deleted. Note that this may actually be an unknown or corrupted column as fsck only looks at the qualifier length and the first byte of the qualifier. If that is the case, you can safely delete this column manually.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e212a8c677b0f644c3c7fde1b3587f9bdf7a67c" translate="yes" xml:space="preserve">
          <source>Occasionally the data extracted from a tag or metric may not be very descriptive. For example, an application may output a timeseries with a tag pair such as &quot;port=80&quot; or &quot;port=443&quot;. With a standard rule that matched on the tagk value &quot;port&quot;, we would have two branches with the names &quot;80&quot; and &quot;443&quot;. The uninitiated may not know what these numbers mean. Thus users can define a token based formatter that will alter the output of the branch to display useful information. For example, we could declare a formatter of &quot;{tag_name}: {value}&quot; and the branches will now display &quot;port: 80&quot; and &quot;port: 443&quot;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f97da408855eb51aafbe04577224b00399b84310" translate="yes" xml:space="preserve">
          <source>Old Version Floats</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7439a1e6455850b1d20aa1d344fd661d0c127cce" translate="yes" xml:space="preserve">
          <source>On many Linux distros (including Debian and Ubuntu), you need to put the configuration above in &lt;code&gt;/etc/varnish/default.vcl&lt;/code&gt;. We also recommend tweaking the command-line parameters of &lt;code&gt;varnishd&lt;/code&gt; in order to use a memory-backed cache of about 1GB if you can afford it. On Debian/Ubuntu systems, this is done by editing &lt;code&gt;/etc/default/varnish&lt;/code&gt; to make sure that &lt;code&gt;-s malloc,1G&lt;/code&gt; is passed to &lt;code&gt;varnishd&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4eb4c893506b69bf3356f0c4eaaf3083d880b33e" translate="yes" xml:space="preserve">
          <source>On most Linux and BSD systems, you can look under &lt;code&gt;/usr/share/zoneinfo&lt;/code&gt; for names of timezones supported on your system.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="001d9ec058f48344c8f56f253f45173fbbcc7fd3" translate="yes" xml:space="preserve">
          <source>On succesfully binding to the default IPv4 address &lt;code&gt;0.0.0.0&lt;/code&gt; and port it will simply print out the line below and start writing. When you're ready to resume using a TSD, simply kill the process.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e38a502537f763069da7a684e38c0157198f5118" translate="yes" xml:space="preserve">
          <source>Once all of the data has been returned, OpenTSDB organizes it into groups, if required</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41c069cd751a95d7a9c4f7c534f3f900bfebf770" translate="yes" xml:space="preserve">
          <source>Once the JARs are in place, they must be selected in the configuration file for the type of plugin specified. Usually this will be the fully qualified Java class name such as &quot;net.opentsdb.search.ElasticSearch&quot;. Each plugin should have an &quot;enabled&quot; property as well that must be set to &lt;code&gt;true&lt;/code&gt; for the plugin to be loaded. Plugins may also have configuration settings that must be added to the &lt;code&gt;opentsdb.conf&lt;/code&gt; file before they can operate properly. See your plugin's documentation. See &lt;a href=&quot;configuration&quot;&gt;&lt;em&gt;Configuration&lt;/em&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bff029a41300d2438696f24c2fe2979bc0ba3579" translate="yes" xml:space="preserve">
          <source>Once you have a TSD up and running (after following the &lt;a href=&quot;../installation&quot;&gt;&lt;em&gt;Installation&lt;/em&gt;&lt;/a&gt; guide) you can follow the steps below to get some data into OpenTSDB. After you have some data stored, pull up the GUI and try generating some graphs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="97add01475232543b5c1a7fdc1a0f521688201b6" translate="yes" xml:space="preserve">
          <source>Once you've written some data using any of the methods above, you can now try to create a graph using that data. Pull up the GUI in your favorite browser. If you're running your TSD on the localhost, simply visit &lt;a href=&quot;http://127.0.0.1:4242&quot;&gt;http://127.0.0.1:4242&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52da6f787c3481bbd0a938d27f46549ca1a3bd31" translate="yes" xml:space="preserve">
          <source>One method that is commonly used by other time series databases is to read the data out of the database after some delay, calculate the pre-aggs and rollups, then write them. This is the easiest way of solving the problem and works well at small scales. However there are still a number of issues:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f40afbcae58f091deb5e33988f48fb68853f5d36" translate="yes" xml:space="preserve">
          <source>One of the valid Java thread states</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ce8b6707ae00ce5cce75deded2a95727b5ec3d93" translate="yes" xml:space="preserve">
          <source>One or more command line queries</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb8564c9b488fdea4a61775425f00ca0665b007a" translate="yes" xml:space="preserve">
          <source>One or more command line queries similar to a data CLI query. See the query section below.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2013387939e4bb2e916526b01f3010776bf17cf" translate="yes" xml:space="preserve">
          <source>One or more key/value objects with tag names and/or tag values for lookup queries. See &lt;a href=&quot;lookup&quot;&gt;&lt;em&gt;/api/search/lookup&lt;/em&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef9d840c5aba7fc7d2fae01d6427b3dcc0ce53ad" translate="yes" xml:space="preserve">
          <source>One or more names to assign UIDs to. Names must not be in quotes and cannot contain spaces.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e09b8358e249074fa042018cad83d9700d1e54b0" translate="yes" xml:space="preserve">
          <source>One or more sets of tags</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0d4efb0c6904bd06dfb6ae8e288b69e691efaca" translate="yes" xml:space="preserve">
          <source>One or more sub queries used to select the time series to return. These may be metric &lt;code&gt;m&lt;/code&gt; or TSUID &lt;code&gt;tsuids&lt;/code&gt; queries</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34e1032bd876a917fd1cf2911e3abea3fc0314dd" translate="yes" xml:space="preserve">
          <source>Only the following characters are allowed: &lt;code&gt;a&lt;/code&gt; to &lt;code&gt;z&lt;/code&gt;, &lt;code&gt;A&lt;/code&gt; to &lt;code&gt;Z&lt;/code&gt;, &lt;code&gt;0&lt;/code&gt; to &lt;code&gt;9&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt;, &lt;code&gt;_&lt;/code&gt;, &lt;code&gt;.&lt;/code&gt;, &lt;code&gt;/&lt;/code&gt; or Unicode letters (as per the specification)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c72ffe53b2511cbf8b460c54fafb6abcb8ed23be" translate="yes" xml:space="preserve">
          <source>OpenTSDB</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1831015d74799070f2f8aeb4f8595af5adfd9884" translate="yes" xml:space="preserve">
          <source>OpenTSDB 1.x had a simple HTTP API that provided access to common behaviors such as querying for data, auto-complete queries and static file requests. OpenTSDB 2.0 introduces a new, formalized API as documented here. The 1.0 API is still accessible though most calls are deprecated and may be removed in version 3. All 2.0 API calls start with &lt;code&gt;/api/&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c849480e4b2bcabbb398394ed5f46f42344dc773" translate="yes" xml:space="preserve">
          <source>OpenTSDB 2.0 introduced a plugin framework, allowing varous contributors to quickly and easily customize their TSDs. This document gives you an overview of the plugin system and will link to some available implementations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7302af12d0969ecce0f8e874d040cc394c942359" translate="yes" xml:space="preserve">
          <source>OpenTSDB 2.0 introduced meta data for tracking the kinds of data in the system. When tracking is enabled, a counter is incremented for every data point written and new UIDs or time series will generate meta data. The data may be pushed to a search engine or passed through tree generation code. These processes require greater memory in the TSD and may affect throughput. Tracking is disabled by default so test it out before enabling the feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44f4a3dbb22a267ca975fea1ab305f56a652a540" translate="yes" xml:space="preserve">
          <source>OpenTSDB 2.0 provides support for special monotonically increasing counter data handling including the ability to set a &quot;rollover&quot; value and suppress anomalous fluctuations. When the &lt;code&gt;counterMax&lt;/code&gt; value is specified in a query, if a data point approaches this value and the point after is less than the previous, the max value will be used to calculate an accurate rate given the two points. For example, if we were recording an integer counter on 2 bytes, the maximum value would be 65,535. If the value at &lt;code&gt;t0&lt;/code&gt; is &lt;code&gt;64000&lt;/code&gt; and the value at &lt;code&gt;t1&lt;/code&gt; is &lt;code&gt;1000&lt;/code&gt;, the resulting rate per second would be calculated as &lt;code&gt;-63000&lt;/code&gt;. However we know that it's likely the counter rolled over so we can set the max to &lt;code&gt;65535&lt;/code&gt; and now the calculation will be &lt;code&gt;65535 - t0 + t1&lt;/code&gt; to give us &lt;code&gt;2535&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="883ea986b25d1f1a956ceb6733a2f66141986278" translate="yes" xml:space="preserve">
          <source>OpenTSDB 2.0 supports objects such as annotations in the data table. If a column is found that doesn't match an OpenTSDB object, a compacted column or a stand-alone data point, it is considered an unknown object and can likely be deleted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08bcc78f91d9890621ca948e4725793a3fbfcace" translate="yes" xml:space="preserve">
          <source>OpenTSDB 2.0's API call calls are versioned so that users can upgrade with gauranteed backwards compatability. To access a specific API version, you craft a URL such as &lt;code&gt;/api/v&amp;lt;version&amp;gt;/&amp;lt;endpoint&amp;gt;&lt;/code&gt; such as &lt;code&gt;/api/v2/suggest&lt;/code&gt;. This will access version 2 of the &lt;code&gt;suggest&lt;/code&gt; endpoint. Versioning starts at 1 for OpenTSDB 2.0.0. Requests for a version that does not exist will result in calls to the latest version. Also, if you do not supply an explicit version, such as &lt;code&gt;/api/suggest&lt;/code&gt;, the latest version will be used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="117ce23b1471458fda6fbcfd31f5c88ffae9a77c" translate="yes" xml:space="preserve">
          <source>OpenTSDB 2.2 introduced the idea of writing numeric data points to OpenTSDB using the &lt;code&gt;append&lt;/code&gt; method instead of the normal &lt;code&gt;put&lt;/code&gt; method. This saves space in HBase by writing all data for a row in a single column, enabling the benefits of TSD compactions while avoiding problems with reading massive amounts of data back into TSDs and re-writing them to HBase. The drawback is that the schema is incompatible with regular data points and requires greater CPU usage on HBase region servers as they perform a read, modify, write operation for each value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a93bf4a7d7f70ef527cb9660e41d26e2b593e26" translate="yes" xml:space="preserve">
          <source>OpenTSDB 2.3 is fully backwards compatible with 1.x data. We've taken great pains to make sure you can download 2.3, compile, stop your old TSD and start the new one. Your existing tools will read and write to the TSD without a problem. 2.3 introduces two new tables to HBase schema for storing meta-data. From the directory where you downloaded the source (or the tools directory if installed with the Debian package), execute:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06ba79d79d6db240434450ecdfaae9503a2a6564" translate="yes" xml:space="preserve">
          <source>OpenTSDB 2.3 works off a configuration file that is shared between the daemon and command line tools. If you compiled from source, copy the &lt;code&gt;./src/opentsdb.conf&lt;/code&gt; file to a proper directory as documented in &lt;a href=&quot;user_guide/configuration&quot;&gt;&lt;em&gt;Configuration&lt;/em&gt;&lt;/a&gt; and edit the following, required settings:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="307344d9f6f20a14cdd5692c586d3a6a6ac5262c" translate="yes" xml:space="preserve">
          <source>OpenTSDB can be configured via a file on the local system, via command line arguments or a combination or both.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="944fa24aebd8c071d7b975942ee37251d48d751b" translate="yes" xml:space="preserve">
          <source>OpenTSDB can emit meta data and annotations to a search engine for complex querying. A single search plugin can be enabled for a TSD to push data or execute queries. The &lt;code&gt;tsd.search.plugin&lt;/code&gt; property lets you select a search plugin and &lt;code&gt;tsd.search.enable&lt;/code&gt; will start sending data and queries. Search plugins will be loaded by TSDs and select command line tools such as the UID Manager tool.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc64d057c656a8ce8eab74371a67d80a12903179" translate="yes" xml:space="preserve">
          <source>OpenTSDB can ingest a large amount of data, even a data point every second for a given time series. Thus queries may return a large number of data points. Accessing the results of a query with a large number of points from the API can eat up bandwidth. High frequencies of data can easily overwhelm Javascript graphing libraries, hence the choice to use GnuPlot. Graphs created by the GUI can be difficult to read, resulting in thick lines such as the graph below:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb3cbe062d0caf5b79e2c9a85b0e6a6613e8d31c" translate="yes" xml:space="preserve">
          <source>OpenTSDB can scale to writing millions of data points per 'second' on commodity servers with regular spinning hard drives. However users who fire up a VM with HBase in stand-alone mode and try to slam millions of data points at a brand new TSD are disappointed when they can only write data in the hundreds of points per second. Here's what you need to do to scale for brand new installs or testing and for expanding existing systems.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ed368bd619259dc124433a1b72b25d51e43f795" translate="yes" xml:space="preserve">
          <source>OpenTSDB compactions trigger large .tmp files and region server crashes in HBase</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5cbd5df1617f3b5c1158a29984810736daaa0095" translate="yes" xml:space="preserve">
          <source>OpenTSDB consists of a single JAR file that uses a shell script to determine what actiosn the user wants to take. While the most common action is to start the TSD with the &lt;code&gt;tsd&lt;/code&gt; command so that it can run all the time and process RPCs, other commands are available to work with OpenTSDB data. These commands include:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10fb9125264faaa716d50964bb6efc79344cc61e" translate="yes" xml:space="preserve">
          <source>OpenTSDB currently supports Apache HBase as its main storage backend. As of version 2.3, OpenTSDB also works with Google's Bigtable in the cloud (fitting as OpenTSDB is descended from a monitoring system at Google and HBase is descended from HBase). Select the HBase link below to learn about the storage schema or Bigtable to find the configs and setup for use in the cloud.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5cfc3197f32c9807942d0d50de82b0e649f076c6" translate="yes" xml:space="preserve">
          <source>OpenTSDB does not itself calculate and store rollup or pre-aggregated data. There are multiple ways to compute the results but they all have benefits and drawbacks depending on the scale and accuracy requirements. See the &lt;a href=&quot;#generating&quot;&gt;Generating Rollups and Pre-Aggregates&lt;/a&gt; section discussing how to create this data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe3091990a0f22b0a3281c764e4a3f97055a4200" translate="yes" xml:space="preserve">
          <source>OpenTSDB handles things a bit differently by introducing the idea of 'tags'. Each time series still has a 'metric' name, but it's much more generic, something that can be shared by many unique time series. Instead, the uniqueness comes from a combination of tag key/value pairs that allows for flexible queries with very fast aggregations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2284bdff240ee7c5e594b1c6a0a9bfeae21d14bc" translate="yes" xml:space="preserve">
          <source>OpenTSDB has a strong and growing base of users running TSDs in production. There are also a number of talented developers creating tools for OpenTSDB or contributing code directly to the project. If you are interested in helping, by adding new features, fixing bugs, adding tools or simply updating documentation, please read the guidelines below. Then sign the contributors agreement and send us a pull request!</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3a2eca6e52db32db804c31217b9f78b557d72b6" translate="yes" xml:space="preserve">
          <source>OpenTSDB has a thriving community who contributed and requested a number of new features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a40b0d6e5b252afd2807744e28f3de71fb896d0" translate="yes" xml:space="preserve">
          <source>OpenTSDB implements a very simple plugin model to extend the application. Plugins use the &lt;em&gt;service&lt;/em&gt; and &lt;em&gt;service provider&lt;/em&gt; facilities built into Java 1.6 that allows for dynamically loading JAR files and instantiating plugin implementations after OpenTSDB has been started. While not as flexible as many framework implementations, all we need to do is load a plugin on startup, initialize the implementation, and start passing data to or through it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16ea52e2182b6e1632fa2fe39950bbca51067a41" translate="yes" xml:space="preserve">
          <source>OpenTSDB is a time series database. A time series is a series of numeric data points of some particular metric over time. Each time series consists of a metric plus one or more tags associated with this metric (we'll cover tags in a bit). A metric is any particular piece of data (e.g. hits to an Apache hosted file) that you wish to track over time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d17cb9c630084b4298c40ffe9cfc99c2dfc0dbf7" translate="yes" xml:space="preserve">
          <source>OpenTSDB is also a data plotting system. OpenTSDB plots things a bit differently than other systems. We'll discuss plotting in more detail below, but for now it's important to know that for OpenTSDB, the basis of any given plot is the metric. It takes that metric, finds all of the time series for the time range you select, aggregates those times series together (e.g. by summing them up) and plots the result. The plotting mechanism is very flexible and powerful and you can do much more than this, but for now let's talk about the key to the time series, which is the metric.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a22e2601b3fb754038fcefd15bc459963f828a7" translate="yes" xml:space="preserve">
          <source>OpenTSDB is built using the standard &lt;code&gt;./configure &amp;amp;&amp;amp; make&lt;/code&gt; model that is most commonly employed by many open-source projects. Fresh working copies checked out from Git must first be &lt;code&gt;./bootstraped&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="837f33e9ebf62aa1d3c950d7f51a86a50bc576ba" translate="yes" xml:space="preserve">
          <source>OpenTSDB is designed to make it easy to collect and write data to it. It has a simple protocol, simple enough for even a shell script to start sending data. However, to do so reliably and consistently is a bit harder. What do you do when your TSD server is down? How do you make sure your collectors stay running? This is where tcollector comes in.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df18f60cbfb181fa81cfb041b567a97576b6bdac" translate="yes" xml:space="preserve">
          <source>OpenTSDB is great, but it's not (yet) a full monitoring platform. Now that you have a bunch of metrics in OpenTSDB, you want to start sending alerts when thresholds are getting too high. It's easy!</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5b6081e070f255901a60e070c0aff1a64ad45bf" translate="yes" xml:space="preserve">
          <source>OpenTSDB is sometimes used within environments where additional initialization or registration is desired beyond what OpenTSDB typically can do out of the box. Startup plugins can be enabled which will be called when OpenTSDB is initializing, when it is ready to serve traffic, and when it is being shutdown. The &lt;code&gt;tsd.startup.plugin&lt;/code&gt; property can be used to specify the plugin class and &lt;code&gt;tsd.startup.enable&lt;/code&gt; will instruct OpenTSDB to attempt to load the startup plugin.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70179876cedd62b52e6ab76a218436ce13469a8f" translate="yes" xml:space="preserve">
          <source>OpenTSDB isn't laid out like a typical Java project, instead it's a bit more like a C or C++ environment. This page is to help folks who want to modify OpenTSDB and provide updates back to the community.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3921dcc99235b95f6b8c108c42102d34f01458e" translate="yes" xml:space="preserve">
          <source>OpenTSDB may be compiled from source or installed from a package. Releases can be found on &lt;a href=&quot;https://github.com/OpenTSDB/opentsdb/releases&quot;&gt;Github&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="069e2a951aeb051adc9d27d759661bdda79510b2" translate="yes" xml:space="preserve">
          <source>OpenTSDB offers a number of means to extract data such as CLI tools, an HTTP API and as a GnuPlot graph. Querying with OpenTSDB's tag based system can be a bit tricky so read through this document and checkout the following pages for deeper information. Example queries on this page follow the HTTP API format.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eca140383bae44b30cbb6a0f76597619e035900b" translate="yes" xml:space="preserve">
          <source>OpenTSDB offers a number of metrics about its performance, accessible via various API endpoints. The main stats are accessible from the GUI via the &quot;Stats&quot; tab, from the Http API at &lt;code&gt;/api/stats&lt;/code&gt; or the legacy API at &lt;code&gt;/stats&lt;/code&gt;. The Telnet style API also supports the &quot;stats&quot; command for fetching over CLI. These can easily be published right back into OpenTSDB at any interval you like.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7dfcd7e7d1a4cc7fa3d51cf85e59cadebe1d686d" translate="yes" xml:space="preserve">
          <source>OpenTSDB provides an HTTP based application programming interface to enable integration with external systems. Almost all OpenTSDB features are accessiable via the API such as querying timeseries data, managing metadata and storing data points. Please read this entire page for important information about standard API behavior before investigating individual endpoints.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bfb18e6fb8003db0826e0a13e31022f87c6c61d1" translate="yes" xml:space="preserve">
          <source>OpenTSDB provides simple and preflight support for Cross-Origin Resource Sharing (CORS) requests. To enable CORS, you must supply either a wild card &lt;code&gt;*&lt;/code&gt; or a comma separated list of specific domains in the &lt;code&gt;tsd.http.request.cors_domains&lt;/code&gt; configuration setting and restart OpenTSDB. For example, you can supply a value of &lt;code&gt;*&lt;/code&gt; or you could provide a list of domains such as &lt;code&gt;beeblebrox.com,www.beeblebrox.com,aurtherdent.com&lt;/code&gt;. The domain list is case insensitive but must fully match any value sent by clients.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c5ce5043e0b91e09b3352433f73cc9e0c4cbe694" translate="yes" xml:space="preserve">
          <source>OpenTSDB supports a number of date and time formats when querying for data. The following formats are supported in queries submitted through the GUI, CliQuery tool or HTTP API. Every query requires a &lt;strong&gt;start time&lt;/strong&gt; and an optional &lt;strong&gt;end time&lt;/strong&gt;. If the end time is not specified, the current time on the system where the TSD is running will be used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98f0ce49c05795d7f63d3e5930319ab330770c1b" translate="yes" xml:space="preserve">
          <source>OpenTSDB supports common data formats via Serializers, plugins that can parse different data formats from an HTTP request and return data in the same format in an HTTP response. Below is a list of formatters included with OpenTSDB, descriptions and a list of formatter specific parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9df70ed7ef17e83f17e9a7f865e17e6ff1dbb12" translate="yes" xml:space="preserve">
          <source>OpenTSDB uses a directory for caching graphs and gnuplot scripts. Unfortunately it doesn't clean up after itself at this time so a simple shell script is included to purge all files in the directory if drive where the directory resides drops below 10% of free space. Simply add this script as a cron entry and set it to run as often as you like.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc046615fc6b6bd73538ea2b7fe66bd9cb553456" translate="yes" xml:space="preserve">
          <source>OpenTSDB uses the &lt;a href=&quot;http://www.slf4j.org/&quot;&gt;SLF4J&lt;/a&gt; abstraction layer along with &lt;a href=&quot;http://logback.qos.ch/&quot;&gt;Logback&lt;/a&gt; for logging flexibility. Configuration is performed via an XML file and there are many different formatting, level and destination options.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a1fe20712bc4d10b33bdf407ce751e2c5f71b61" translate="yes" xml:space="preserve">
          <source>OpenTSDB was designed to efficiently combine multiple, distinct time series during query execution. But how do you merge individual time series into a single series of data? Aggregation functions provide the means of mathematically merging the different data series into one, giving you a choice of various mathematical operations. Since OpenTSDB doesn't know whether or not a query will return multiple time series, an aggregation function is always required just in case.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e9b64b4de1eb7254ef91330aff99a6e40b5f1b9" translate="yes" xml:space="preserve">
          <source>OpenTSDB will &lt;em&gt;automatically&lt;/em&gt; aggregate &lt;em&gt;all&lt;/em&gt; of the time series for the metric in a query if no tags are given. If one or more tags are defined, the aggregate will 'include all' time series that match on that tag, regardless of other tags. With the query &lt;code&gt;sum:sys.cpu.user{host=webserver01}&lt;/code&gt;, we would include &lt;code&gt;sys.cpu.user host=webserver01,cpu=0&lt;/code&gt; as well as &lt;code&gt;sys.cpu.user host=webserver01,cpu=0,manufacturer=Intel&lt;/code&gt;, &lt;code&gt;sys.cpu.user host=webserver01,foo=bar&lt;/code&gt; and &lt;code&gt;sys.cpu.user host=webserver01,cpu=0,datacenter=lax,department=ops&lt;/code&gt;. The moral of this example is: &lt;em&gt;be careful with your naming schema&lt;/em&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="275dc1aa52e0e6c9f9330b17aaa5065dd615bbee" translate="yes" xml:space="preserve">
          <source>OpenTSDB's query language is fairly simple but flexible. Each query has the following components:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c6c4102d4dfec3b1aa41117e0e344046c58a151" translate="yes" xml:space="preserve">
          <source>Optional</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4044b94f4f7e3c49d524fcf652f534a37e2a6234" translate="yes" xml:space="preserve">
          <source>Optional additional queries to execute. Each query must follow the same format starting with an aggregator. All queries share the same start and end times.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70f6f42ae498130cd9690ff21f48c9e78d77f4f5" translate="yes" xml:space="preserve">
          <source>Optional downsampling specifier to group data into larger time spans and reduce the amount of data returned. Format is the literal &lt;code&gt;downsample&lt;/code&gt; followed by a timespan in milliseconds and an aggregation function name</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5d872a2bcfa96ad29e5d02e7c0cecfcdaeff656" translate="yes" xml:space="preserve">
          <source>Optional end time for the query. If not provided, the current time is used. This may be an absolute or relative time. See &lt;a href=&quot;../query/dates&quot;&gt;&lt;em&gt;Dates and Times&lt;/em&gt;&lt;/a&gt; for details</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e0f3b10431a48837081923010190d22c6e7e12a" translate="yes" xml:space="preserve">
          <source>Optional flag that deletes data in any row that matches the query. See warning below.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66ad5ccf55ede57103d4b610c9726fe8012c0dff" translate="yes" xml:space="preserve">
          <source>Optional flag that outputs results in a text format useful for importing or storing as a backup.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f437eb5160329e44b789bdc3aea9f779eed745c1" translate="yes" xml:space="preserve">
          <source>Optional flag that will attempt to repair errors. By itself, fix will only repair sign extension bugs, 8 byte floats with 4 byte qualifiers and VLE stand-alone data points. Use in conjunction with other flags to repair more issues.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03a8288b7d9a29ad2da60ea6165e406f941490b6" translate="yes" xml:space="preserve">
          <source>Optional flag that will cause the lookup to run against the main &lt;code&gt;tsdb-data&lt;/code&gt; table. &lt;em&gt;NOTE:&lt;/em&gt; This can take a very long time to complete.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76b207706ebcfac97d1d6a0a453bf511c87d02c3" translate="yes" xml:space="preserve">
          <source>Optional literal &lt;code&gt;counter&lt;/code&gt; that indicates the underlying data is a monotonically increasong counter that may roll over</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d615126b595922ee6b770d485ba868b69ca7a7e" translate="yes" xml:space="preserve">
          <source>Optional pairs of tag names and tag values</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e594fd3ac91a19e7a10456fc05270a21d68aaff" translate="yes" xml:space="preserve">
          <source>Optional values used to generate Gnuplot scripts and graphs. Note that the actual graph PNG will not be generated, only the files (written to the temp directory)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cdc1541ebad50bd7ed59a63a46439804c3cb078" translate="yes" xml:space="preserve">
          <source>Optional*</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d75774c0f96b6ee44eb6643c9fea71b50b90ea8" translate="yes" xml:space="preserve">
          <source>Order</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de1f5e0bc71aa3099a3ff783953933f0864134b7" translate="yes" xml:space="preserve">
          <source>Order of Precedence</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d40b0108be447cfee486a299331da9d0e416e84" translate="yes" xml:space="preserve">
          <source>Order of operations</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3ed86c1334d74f0ae883f47feef902d83b9d8c6" translate="yes" xml:space="preserve">
          <source>Ordering</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="793358761400695b7451e052b0ee772c8ac8b868" translate="yes" xml:space="preserve">
          <source>Original value processed by the rule. For example, if the rule uses a regex to extract a portion of the value but you do not want the extracted value, you could use the original here.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d52147c6622aac281870f5e548e76e3b5fffeba1" translate="yes" xml:space="preserve">
          <source>Orphaned Rows</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d2a4282532b7dba2bfd474438b0e20ba4ee50dd" translate="yes" xml:space="preserve">
          <source>Other Fields</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4bed336194a9a5c86b6a734f03b3570d2aae1a68" translate="yes" xml:space="preserve">
          <source>Output</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93590f4618aa3de869dd2a0094ceb820d409d024" translate="yes" xml:space="preserve">
          <source>Output Format</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84219262228fd04cf972a0330569bfde39825c30" translate="yes" xml:space="preserve">
          <source>Override</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de76fe61e2d111daee168d11e313d6364dd26d0b" translate="yes" xml:space="preserve">
          <source>Override Tag Widths - You can now override tag widths in the config instead of having to recompile the code.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0efc2e6be4c23b9a513d7ce0dcff8ed80e8912e7" translate="yes" xml:space="preserve">
          <source>Overview</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88e34afd8fba118e62586557b3ff056dc9331032" translate="yes" xml:space="preserve">
          <source>PNG - Some requests, including exceptions and errors, can generate an image file. In these cases, an error is sent to GnuPlot and the resulting empty graph with a title consisting of the message is returned. Append the parameter &lt;code&gt;png&lt;/code&gt; to the query string.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61ff81c30aa3c76e78afea62b2e3bd1dfa49e854" translate="yes" xml:space="preserve">
          <source>POST</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83050a6074031a29cb707fdc7c7257c8fca1d311" translate="yes" xml:space="preserve">
          <source>POST - Create or modify a rule</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b39e50de61ad5765ef14210e92e9dee0fdf943d" translate="yes" xml:space="preserve">
          <source>POST - Create or modify an annotation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8003216ffc13d3e8a4a11c64d2b8bf67a1c1a3b6" translate="yes" xml:space="preserve">
          <source>POST - Create or modify annotations</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e2512999d46fa39724cf8b7a2af266c06510937" translate="yes" xml:space="preserve">
          <source>POST - Edit tree fields</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3e023f51c9b98a893e63d7562cd243054bcdb78" translate="yes" xml:space="preserve">
          <source>POST - Merge rule sets</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0686e7d67128c5cce509946fc26f30a8918fc10b" translate="yes" xml:space="preserve">
          <source>POST - Updates only the fields provided</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd5a202f9261cf73685571bf0e0f22f95bc0d5fa" translate="yes" xml:space="preserve">
          <source>POST/PUT</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="30833a3043ee8733ddee0da257e693e2414036af" translate="yes" xml:space="preserve">
          <source>POST/PUT Requests</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6c4170f0e615f9fa2848d48db2ab50f375369c3" translate="yes" xml:space="preserve">
          <source>POST:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="091b0ce42eb0bd96169ea00b16dd938f6d63ac95" translate="yes" xml:space="preserve">
          <source>PUT</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9cf9c53e8a52392a679ca8dbb9779e5dbe3c07b" translate="yes" xml:space="preserve">
          <source>PUT - Create or replace a rule</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="864fd152fa1ffd3106b535e9872012398d1f0829" translate="yes" xml:space="preserve">
          <source>PUT - Create or replace an annotation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="309e19a5abf3cda132e168701d51f76fc7a0dc8e" translate="yes" xml:space="preserve">
          <source>PUT - Create or replace annotations</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c21d9f8a52d3a85d1bac74606bcbf159737bab35" translate="yes" xml:space="preserve">
          <source>PUT - Overwrites all user configurable meta data fields</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0002cc36330fbf12c456430cc5c70dfd7d5185c" translate="yes" xml:space="preserve">
          <source>PUT - Replace the entire rule set</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb0ef7f3dd9a7a517404717e5018045d1512bb17" translate="yes" xml:space="preserve">
          <source>PUT - Replace tree fields</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f699f295e5ae4ac633cfa18437fed38d028b3fdb" translate="yes" xml:space="preserve">
          <source>Parameter</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a975eea30db9fa05003e3b5097688bd49ec7e01b" translate="yes" xml:space="preserve">
          <source>Parameters</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3dfccb0cd5b083f639b4cf1cfc860db69fd9211" translate="yes" xml:space="preserve">
          <source>Parameters specific to the UID utility include:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1132a0ac95d36d88102a9e7575e1e4e4787b01a2" translate="yes" xml:space="preserve">
          <source>Parameters used by the lookup endpoint include:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c99f0c3c57a2b8a364097e70936cb16c9e7b983" translate="yes" xml:space="preserve">
          <source>Parameters used by the search endpoint include:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="381c775599d6e4185d4410725809e360928357cd" translate="yes" xml:space="preserve">
          <source>Parameters:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e79e4f803b96c5744f746e1859167ce3a0e684d" translate="yes" xml:space="preserve">
          <source>Paste the MD5 hash of the entire jar in that file and save it</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e00c68766885ef81c14b0d6fd051b7ade79efe1e" translate="yes" xml:space="preserve">
          <source>Path to a directory where data files should be written. A file is created for each client with the IP address of the client as the file name,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f15ab6ad06cc6d22a958e4c0c623165ecbb5e42" translate="yes" xml:space="preserve">
          <source>Path under which is the znode for the -ROOT- region</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad173720e6d621712fb1bcfbe54f647565224146" translate="yes" xml:space="preserve">
          <source>Path under which the znode for the -ROOT- region is located</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0cba1c3c053071e72957980214a74aa21f22c59f" translate="yes" xml:space="preserve">
          <source>Paths may be absolute or relative</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d70015223b3ee8688897d3f8b01143b0a50e79ae" translate="yes" xml:space="preserve">
          <source>Percentiles</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b00bd9defdbcf26642da838de81c16244acdc391" translate="yes" xml:space="preserve">
          <source>Persistent Connections</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e53250e5dbeddb17a8b87d2873bce7d2710fed5" translate="yes" xml:space="preserve">
          <source>Plain Test - Or ASCII, the default for many requests will return a simple page of data with the Content-Type &lt;code&gt;text/plain&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c6ba5e23be4bf442d02de4c4bff30372244f2de" translate="yes" xml:space="preserve">
          <source>Please &lt;em&gt;respect the coding style of the code&lt;/em&gt; you're changing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="134207ead83140b0dd4c1c3b554651e6151059cd" translate="yes" xml:space="preserve">
          <source>Please break down your changes into as many small commits as possible.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="364590e1fa4ccd4c45779a0c07392eeb0cef69be" translate="yes" xml:space="preserve">
          <source>Please file &lt;a href=&quot;https://github.com/OpenTSDB/opentsdb/issues&quot;&gt;issues on GitHub&lt;/a&gt; after checking to see if anyone has posted a bug already. Make sure your bug reports contain enough details so they can be easily understood by others and quickly fixed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb37d887848ac0f130ad07835db67722db5bc17c" translate="yes" xml:space="preserve">
          <source>Please note that deleting a meta data entry will not delete the data points stored for the timeseries. Neither will it remove the UID assignments or associated UID meta objects.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60a8bcb3f60333cf9a8276f6af52b3b932f3818c" translate="yes" xml:space="preserve">
          <source>Please see &lt;a href=&quot;../index&quot;&gt;&lt;em&gt;HTTP API&lt;/em&gt;&lt;/a&gt; for details on selecting a serializer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71cfd207cbcbdfee8af484351a9c512935159282" translate="yes" xml:space="preserve">
          <source>Please see the serializer documentation for request information: &lt;a href=&quot;../serializers/index&quot;&gt;&lt;em&gt;HTTP Serializers&lt;/em&gt;&lt;/a&gt;. The following examples pertain to the default JSON serializer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="342d54cf4ce9191755c22cccd2652b38277ff2bf" translate="yes" xml:space="preserve">
          <source>Pluggable Serializers - Enable different inputs and outputs for the API</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab2e26dd8b8868a3969cb3321e0c983c0d9d67d4" translate="yes" xml:space="preserve">
          <source>Plugins</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35816b08aa41ad53ca4fcd1c9d705757140b3f7a" translate="yes" xml:space="preserve">
          <source>Plugins and their dependencies can be pretty chatty so you may want to tweak your Logback settings to reduce the number of messages.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d2109da903adc69583b0fe64aeb835f03450080" translate="yes" xml:space="preserve">
          <source>Plugins are JAR files that must be downloaded to a directory accessible by OpenTSDB. Once a directory is created, it must be specified in the &lt;code&gt;opentsdb.conf&lt;/code&gt; config file via the &lt;code&gt;tsd.core.plugin_path&lt;/code&gt; property. If the plugin has dependency JARs that were not compiled into the plugin and are not located in the standard class path, they must be copied to this plugin directory as well.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7184b5e5c1faba5bbd4334e00131c7222d17cc22" translate="yes" xml:space="preserve">
          <source>Plugins are loaded at run time by a TSD or command line utility. Once the program or daemon is running, plugin configurations cannot be changed. You must restart the program for changes to take effect.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fab093d4b7de22bc088a9c8b769dcc0bd40e0170" translate="yes" xml:space="preserve">
          <source>Port: {ovalue}</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f74d88ca19d61a699312dff98a8ef7c8f8b1625" translate="yes" xml:space="preserve">
          <source>Pre-Aggregate - For a metric with high cardinality (many unique tag values), scanning for all of the series can be costly. Take a metric &lt;code&gt;system.interface.bytes.out&lt;/code&gt; where there are 10,000 hosts spread across 5 data centers. If users often look at the total data output by data center ( the query would look similar to aggregation = sum and data_center = &lt;a href=&quot;#id2&quot;&gt;&lt;span id=&quot;id3&quot;&gt;*&lt;/span&gt;&lt;/a&gt;) then pre-calculating the sum across each data center would result in 5 data points being fetched per time period from storage instead of 10K. The resulting pre-aggregate would have a different tag set than the raw time series. In the example above, each series would likely have a &lt;code&gt;host&lt;/code&gt; tag along with a &lt;code&gt;data_center&lt;/code&gt; tag. After pre-aggregation, the &lt;code&gt;host&lt;/code&gt; tag would be dropped, leaving only the &lt;code&gt;data_center&lt;/code&gt; tag.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7602496c3c3246fe3a65089d9e5c23af7e2be6a3" translate="yes" xml:space="preserve">
          <source>Pre-Aggregate Example</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d362a50be44bdad8b3e7592f74a46b267ee5f8cc" translate="yes" xml:space="preserve">
          <source>Pre-Aggregate Schema</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8662c8b3a9f10d9c4f9f5cb43639ad89cba28e29" translate="yes" xml:space="preserve">
          <source>Pre-Aggregates</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39e2c47003f73e33c5c8571e0e32faaaa284ca71" translate="yes" xml:space="preserve">
          <source>Pre-Split HBase Regions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c5e583c967c944309417b7245b24e3ac3708af8" translate="yes" xml:space="preserve">
          <source>Precisions on Metrics and Tags</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba9769c34d2bfb87f48f782237cf25e08ef346a6" translate="yes" xml:space="preserve">
          <source>Prepare the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e9f7a31eef4c69e0aacb643f6856372cd6e3247" translate="yes" xml:space="preserve">
          <source>Present</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e791a22ccb2849c7bef3ce9b6b7d631c59a7968" translate="yes" xml:space="preserve">
          <source>Previous to 2.1, timestamps were not normalized. The buckets were calculated based on the starting time of the first data point retreived for each series, then the series went through interpolation. This means a graph may show varying gaps between values and return more values than expected.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ce448bc7f324d1112e78968bb9db07ab5d1e526" translate="yes" xml:space="preserve">
          <source>Probably the most useful endpoint in the API, &lt;code&gt;/api/query&lt;/code&gt; enables extracting data from the storage system in various formats determined by the serializer selected. Queries can be submitted via the 1.0 query string format or body content.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e6b86dce8c4fbace004e330925fe8345d92db90" translate="yes" xml:space="preserve">
          <source>Problems</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5441dba1d81b3da959a819eb27c9e4ef8c846254" translate="yes" xml:space="preserve">
          <source>Processes the name of the metric associated with the timeseries</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc6c88db2f0703a9e2461a4a8060ccf1cb881998" translate="yes" xml:space="preserve">
          <source>Properties</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ae33a7d0ecb82cae8f04aafab20bf90425b7b8c" translate="yes" xml:space="preserve">
          <source>Property</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da77ffc73a97a448b79064a8a61c4ae9031ed9b6" translate="yes" xml:space="preserve">
          <source>Provides case sensitive postfix, prefix, infix and multi-infix filtering. The wildcard character is an asterisk (star) &lt;code&gt;*&lt;/code&gt;. Multiple wildcards can be used. If only the asterisk is given, the filter effectively returns any time series that include the tag key (and is an efficient filter that can be pre-processed).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="028de6904f63e4c27afe0b6ca3939cbf9d813109" translate="yes" xml:space="preserve">
          <source>Providing millisecond resolution does not necessarily mean that OpenTSDB supports write speeds of 1 data point per millisecond over many time series. While a single TSD may be able to handle a few thousand writes per second, that would only cover a few time series if you're trying to store a point every millisecond. Instead OpenTSDB aims to provide greater measurement accuracy and you should generally avoid recording data at such a speed, particularly for long running time series.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbd5727562438a620d030d12c1ff09ab0c492d06" translate="yes" xml:space="preserve">
          <source>Purges the metric, tag key and tag value UID to string and string to UID maps.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e3604888c4b4ec08e2837913d012fe2834ffa83" translate="yes" xml:space="preserve">
          <source>Python</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e1e7e60ab0f3524e522a556bffe92134b0aada2" translate="yes" xml:space="preserve">
          <source>QS</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2692488689f52761bb1ce60a84eedb77519b97ca" translate="yes" xml:space="preserve">
          <source>QS - If the parameter can be supplied via query string, this field will have a &lt;code&gt;Yes&lt;/code&gt; in it, otherwise it will have a &lt;code&gt;No&lt;/code&gt; meaning the parameter can only be supplied as part of the request body content.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a135c4b45e5bbff666489bf930d934dd4ad0cc41" translate="yes" xml:space="preserve">
          <source>Queries can only be executed via GET using the URI at this time. (In the future, the &lt;a href=&quot;exp&quot;&gt;&lt;em&gt;/api/query/exp&lt;/em&gt;&lt;/a&gt; endpoint will support more flexibility.) This is an extension of the main &lt;a href=&quot;index&quot;&gt;&lt;em&gt;/api/query&lt;/em&gt;&lt;/a&gt; endpoint so parameters in the request table are also supported here. Additional parameters include:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c75b4947d81a1b8f5eca3270a031d1767e2918f8" translate="yes" xml:space="preserve">
          <source>Queries the TSD for data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5a5344104f41a79531810b57b445b4375388ba9" translate="yes" xml:space="preserve">
          <source>Queries using Unix timestamps can also support millisecond precision by simply appending three digits. For example providing a start time of &lt;code&gt;1364410924000&lt;/code&gt; and an end time of &lt;code&gt;1364410924250&lt;/code&gt; will return data within a 250 millisecond window. Millisecond timestamps may also be supplied with a period separating the seconds from the milliseconds as in &lt;code&gt;1364410924.250&lt;/code&gt;. Any integers with 13 (or 14) characters will be treated as a millisecond timestamp. Anything 10 characters or less represent seconds. Milliseconds may only be supplied with 3 digit precision. If your tool outputs more than 3 digits you must truncate or round the value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cff1f3ff95b8585679758335abcefc583d72c034" translate="yes" xml:space="preserve">
          <source>Queries via query string to the HTTP API can specify a &lt;code&gt;tz&lt;/code&gt; parameter with a timezone identification string in a format applicable to the localization settings of the system running the TSD. For example, we could specify &lt;code&gt;tz=America/Los_Angeles&lt;/code&gt; to convert our timestamp from Los Angeles local time to UTC.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a618b4be8d3ac72545f3085fe616d342b7139fba" translate="yes" xml:space="preserve">
          <source>Query</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34f2c5226152faeef262fb5c246ee8591f023965" translate="yes" xml:space="preserve">
          <source>Query 1 - All Time Series for a Metric</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="820baeef87cfa11fde7f2ffda52a32baddff4302" translate="yes" xml:space="preserve">
          <source>Query 2 - Filter on a Tag</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcc0cb6d84e7bdc585f6f33aa063cb6ef88f8b2b" translate="yes" xml:space="preserve">
          <source>Query 3 - Specific Time Series</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80c639e11a27beaf4a82284c6c8b1a558c0ec6f7" translate="yes" xml:space="preserve">
          <source>Query 4 - TSUID Query</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b71eb86a8c4af3c1a87e74688d72076b59464e94" translate="yes" xml:space="preserve">
          <source>Query 5 - Multi-TSUID Query</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a9c3544b06e8173a3d1545ea7598cbc9b1ce178" translate="yes" xml:space="preserve">
          <source>Query 6 - Grouping</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c5dc314ae9fc0d4185134d54d57780b1c48b2fb3" translate="yes" xml:space="preserve">
          <source>Query 7 - Group and Filter</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="600ee730365c98287ad19295a8f0e8bc3ec9830c" translate="yes" xml:space="preserve">
          <source>Query 8 - Grouping With OR</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ccbb9d789eb64f4666fdee8d907d5d52e59fa5ac" translate="yes" xml:space="preserve">
          <source>Query API Endpoints</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5752b1edfe3998904906517dbe2981d50e924cf2" translate="yes" xml:space="preserve">
          <source>Query Builder</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4b718b47f2dc698c28df65909364098f158777af" translate="yes" xml:space="preserve">
          <source>Query Caching - Improve queries with time-sharded caching of results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8e2ab82daca0993e127cf00f45397538db3e29c" translate="yes" xml:space="preserve">
          <source>Query Components</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1bad01ea329a277a2f7c606f1ab437317de7d86d" translate="yes" xml:space="preserve">
          <source>Query Details and Stats</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4db030b8dc0f80507cc12ed4565cce8883110b95" translate="yes" xml:space="preserve">
          <source>Query Examples</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="710cad0b42762c089da135ef422ef2eba802456a" translate="yes" xml:space="preserve">
          <source>Query Filters - New filters for flexibility including case (in)sensitive literals, wildcards and regular expressions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef287eb83c477cf3f358fbb333a58125de47d97f" translate="yes" xml:space="preserve">
          <source>Query Format</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2a8dd1cc6dace2297cebe0559b503d1d30b735c" translate="yes" xml:space="preserve">
          <source>Query Stats - Query details are now logged that include timing statistics. A new endpoint also shows running and completed queries.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c53af2bbd582252a00906e7e1c9f166915d5fe12" translate="yes" xml:space="preserve">
          <source>Query String Vs. Body Content</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a48207956ff7d3d872ae8a427d995734d43e8e39" translate="yes" xml:space="preserve">
          <source>Query String:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07baa6a1fec2183f2163cf0cea9124e40cd7ce0e" translate="yes" xml:space="preserve">
          <source>Query string and content body requests are ignored. Rather the requested file is a component of the path, e.g. &lt;code&gt;/s/index.html&lt;/code&gt; will return the contents of the &lt;code&gt;index.html&lt;/code&gt; file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d61da113e0275d2223f109dfbfa3c2012034ef4a" translate="yes" xml:space="preserve">
          <source>Query, Global</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0bc0dcad3297de0bb6631a5f7d20ad6ce3718a9" translate="yes" xml:space="preserve">
          <source>Querying or Reading Data</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="455083cac2ae96eabe3895762b6080aa09e6afa4" translate="yes" xml:space="preserve">
          <source>Quick Start</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c5db7969dcd30635e5d7867040b6cc76158dd175" translate="yes" xml:space="preserve">
          <source>RAW</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86282ad0a8acc92fe00462f240dfe652af4cb3dd" translate="yes" xml:space="preserve">
          <source>RO</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3282cbbcba660116d62c007822229220838a1c6" translate="yes" xml:space="preserve">
          <source>RPC</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be07c1988ec3964711280da0df3af522df5a8ef0" translate="yes" xml:space="preserve">
          <source>RUNNABLE</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="59eca6055c6e00ee7487f596017c191c3275da72" translate="yes" xml:space="preserve">
          <source>RW</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f52db2ce1da00a320deea5665dd9a851173c95d5" translate="yes" xml:space="preserve">
          <source>RW - Describes whether or not this parameter can result in an update to data stored in OpenTSDB. Possible values in this column are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23d372c6ff008b3f6d0979c189a4aae530f9b5db" translate="yes" xml:space="preserve">
          <source>Random Metric UID Assignment</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b47180c4ffd8ca4fbc653042ad6ac32fe64a04db" translate="yes" xml:space="preserve">
          <source>Random Metric UIDs - Enables better distribution of writes when creating new metrics</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f495f8ce046ef8f21c78184cda4aa8ca41db695e" translate="yes" xml:space="preserve">
          <source>Random metric generation can be enabled or disabled at any time by modifying the &lt;code&gt;tsd.core.uid.random_metrics&lt;/code&gt; flag and data is backwards compatible all the way back to OpenTSDB 1.0. However it is recommended that you pre-split your TSDB data table according to the full metric UID space. E.g. if you use the default UID size in OpenTSDB, UIDs are 3 bytes wide, thus you can have 16,777,215 values. If you already have data in your TSDB table and choose to enable random UIDs, you may want to create new regions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a9c736b3175d6576311a0ce0ad8c80fa6631f94" translate="yes" xml:space="preserve">
          <source>Rate</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dddc48c19027db4c411d73b90fe952c2e37e8a0c" translate="yes" xml:space="preserve">
          <source>Rate Calculation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed2f431b0b0d42cedae8b54c1fa5b396b6a31a55" translate="yes" xml:space="preserve">
          <source>Rate Counter Calculations - Handle roll-over and anomaly supression</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e572ed8f93ee217490e56560c7ee08af6f09117" translate="yes" xml:space="preserve">
          <source>Raw Names</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abf941b6393e9e9047e42577f26df40de0ea278e" translate="yes" xml:space="preserve">
          <source>Raw Output</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d25d5ed0dba672c5a30cbacad83d7e3f3ff957b6" translate="yes" xml:space="preserve">
          <source>Read &lt;a href=&quot;deprecated&quot;&gt;&lt;em&gt;Deprecated HTTP API&lt;/em&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4c04c5dc893a519f489331cdca319a17573c562" translate="yes" xml:space="preserve">
          <source>Read from alternate stores. One example is to mirror all data to another store such as HDFS and run batch jobs against that data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9d0539d7f5f90618e32702172050cbd0db2271f" translate="yes" xml:space="preserve">
          <source>Read more about Varnish:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b54ee660f91dcc238af044e8eeab64ea24b321c" translate="yes" xml:space="preserve">
          <source>Read the &lt;a href=&quot;http://www.gnuplot.info/&quot;&gt;GnuPlot Manual&lt;/a&gt; for &lt;em&gt;Format Specifiers&lt;/em&gt; to find out what is permissible.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a6b5f53b25172bd1e6e3f83b2d78c14c44e3640" translate="yes" xml:space="preserve">
          <source>Read the Development page for tips</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3de0cd489a11ec7f9d6c8ac1d45d74eee846daa9" translate="yes" xml:space="preserve">
          <source>Read/Write Modes - Block assigning UIDs on individual TSDs for backup clusters</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d7b6e802632a010dd934610bbd44ad286e0f34f7" translate="yes" xml:space="preserve">
          <source>Reading from replicated systems, e.g. if you setup HBase replication, you could have users query the master system and aggregations read from the replicated store.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20c7c5522fc28c5817550dd82bc3272eb6a991c7" translate="yes" xml:space="preserve">
          <source>Ready</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89722078f8c089e5c130ab082547ddc2e82042a5" translate="yes" xml:space="preserve">
          <source>Real Time Publishing</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3696428894b1ddf8bfa9cd7dbb363111d4ddaecf" translate="yes" xml:space="preserve">
          <source>Real-Time Publishing Plugin - Send data to external systems as they arrive to your TSD</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39b1f17c701b58480338e33e15a8acbb9a6973a5" translate="yes" xml:space="preserve">
          <source>Recall from the &lt;a href=&quot;../query/index&quot;&gt;&lt;em&gt;Querying or Reading Data&lt;/em&gt;&lt;/a&gt; documentation that if you only provide a metric without any tags, &lt;em&gt;every time series with that metric&lt;/em&gt; will be aggregated in the results. If you want to drill down, supply one or more &lt;strong&gt;Tags&lt;/strong&gt; to filter or group the results. A new metric section will have two boxes next to &lt;strong&gt;Tags&lt;/strong&gt;. The left box is for the tag name or &lt;code&gt;tagk&lt;/code&gt; value, e.g. &lt;code&gt;host&lt;/code&gt; or &lt;code&gt;symbol&lt;/code&gt;. The right hand box is for the tag value or &lt;code&gt;tagv&lt;/code&gt;, e.g. &lt;code&gt;webserver01&lt;/code&gt; or &lt;code&gt;google&lt;/code&gt;. When you add a tag, another pair of boxes will appear so that you can keep adding tags to filter as much as necessary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b34be1c018fccfcb673c3181c08c1760b4b54625" translate="yes" xml:space="preserve">
          <source>Reduces the number of data points returned. The format is defined below</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9cf5cea5d3384a71dbf4a81cd1db9621d11d30b3" translate="yes" xml:space="preserve">
          <source>References to OpenTSDB</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b37213bee81db6505e080aa0df30da5fbbec41c" translate="yes" xml:space="preserve">
          <source>Refresh the directory lists in Eclipse and you should see all of the source files</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09d3c5d512d06cc085fe192c277ae91055708410" translate="yes" xml:space="preserve">
          <source>Regardless of the method used, fsck only looks at the most recent column value in HBase. If the table is configured to store multiple versions, older versions of a column are ignored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e681935761236016678d2656c1d667f0fe6fdac" translate="yes" xml:space="preserve">
          <source>Regex</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20721fb3e4c8c7852b117a464f16c924dff183f5" translate="yes" xml:space="preserve">
          <source>Regex Rules</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fde4a35e7c249904c41ca2d2ccdf999a36950fec" translate="yes" xml:space="preserve">
          <source>Regular expression, wildcard filters with a pre/post/in-fix or literal ors with many values can cause queries to return slower as each row of data must be resolved to their string values then processed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="979b63354f43dac53577a66d5b5f7d9f123bb841" translate="yes" xml:space="preserve">
          <source>Relative</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4244a520b5347f7b007da0516ecf77281a1515da" translate="yes" xml:space="preserve">
          <source>Relative times do not account for leap seconds, leap years or time zones. They simply calculate the number of seconds in the past from the current time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c94030b41d7b1bbc08e5b9e0574d78837055a874" translate="yes" xml:space="preserve">
          <source>Remove the reverse map</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7955e3ef470f89aca95cd0c0417db1795188093b" translate="yes" xml:space="preserve">
          <source>Removes all branches, collision, not matched data and optionally the tree definition itself for a given tree. Parameters include:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d48a692f6dc84130ece0fdcd622ed7534a54b1c7" translate="yes" xml:space="preserve">
          <source>Removes any column that does not appear to be a compacted column, a stand-alone data point or a known or future OpenTSDB object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff67430bfb552aa266c333376ff42538370ca1ae" translate="yes" xml:space="preserve">
          <source>Removes any row that doesn't match the OpenTSDB row key format of a metric UID followed by a timestamp and tag UIDs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71385a6fe55e8f0a79b978f24d553621bd990f10" translate="yes" xml:space="preserve">
          <source>Removes any stand-alone data points that could not be repaired or did not conform to the OpenTSDB specification.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc7a6a8ec498b2dcbb47bec283268fd1e88caaa8" translate="yes" xml:space="preserve">
          <source>Removes columns that appear to be compacted but failed parsing. If a column parses properly but the final byte of the value is not set to a 0 or a 1, the column will be left alone.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50f15e003634408db60dc3814b94d7f442e39b6c" translate="yes" xml:space="preserve">
          <source>Removes rows where one or more UIDs could not be resolved to a name.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac9b85ec7951060d829e1835b2ccbb38006a6728" translate="yes" xml:space="preserve">
          <source>Removes the mapping of the UID from the &lt;code&gt;tsdb-uid&lt;/code&gt; table. Make sure all sources are no longer writing data using the UID and that sufficient time has passed so that users would not query for data that used the UIDs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36cce374d11935905800da542bd293761ac5ccbd" translate="yes" xml:space="preserve">
          <source>Replace an entire object in the system with the provided content</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4aed03cac49d5e43da4e855a967286931a4d621a" translate="yes" xml:space="preserve">
          <source>Request</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2580bf51a6ec3910334fbda8ee17c6c4f4fb2915" translate="yes" xml:space="preserve">
          <source>Request Parameters are a list of field names that you can pass in with your request. Each table has the following information:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8e9cee9ea782225616f228114d36efc31728b41" translate="yes" xml:space="preserve">
          <source>Request parameters include:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc9f76d037bad4352207c3d36baac99d5ae35b32" translate="yes" xml:space="preserve">
          <source>RequestHeaders</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7194e6a0d0b838382b202853e7c198d693fbabc" translate="yes" xml:space="preserve">
          <source>Requests</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f8c6bd887fb4f89a8823ffedc9fdb53d368e13b5" translate="yes" xml:space="preserve">
          <source>Requests the root which is the GWT generated OpenTSDB GUI. This endpoint only returns HTML and cannot return other data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eed6bfb41051ed5b74447340f3c2e29d11e99a7c" translate="yes" xml:space="preserve">
          <source>Required</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73410efa43bfe42951bd721b27171b86625fa2de" translate="yes" xml:space="preserve">
          <source>Required - Whether or not the parameter is required for a successful query. If the parameter is required, you'll see &lt;code&gt;Required&lt;/code&gt; otherwise it will be &lt;code&gt;Optional&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05afc31ba4837eaf4cfeda18f43c83f9e8ab536d" translate="yes" xml:space="preserve">
          <source>Required name of a metric to query for</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cd50fa45ebd645252c4bab90f5bec2fca94ed67" translate="yes" xml:space="preserve">
          <source>Required*</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ce9879058b3bb4d39fa1d46836617549fd6182fe" translate="yes" xml:space="preserve">
          <source>Reserved Query String Parameters</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e617e4fc9da3de9693eac5990613543b86c63f9" translate="yes" xml:space="preserve">
          <source>Response</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e2d6b845732445ba93b54ea2eb6b870add110395" translate="yes" xml:space="preserve">
          <source>Response Codes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1850e237f506f40e4c4a36f1ada8c564ce221bdf" translate="yes" xml:space="preserve">
          <source>Responses are handled in the same was as for the &lt;a href=&quot;put&quot;&gt;&lt;em&gt;/api/put&lt;/em&gt;&lt;/a&gt; endpoint.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73cbf7d514e16d54420bbb88c44827c4b040de32" translate="yes" xml:space="preserve">
          <source>Restful API - Provides access to all of OpenTSDB's features as well as offering new options, defaulting to JSON</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5faa59d4bc3756040b8ce9e673c09f929e6ee9ba" translate="yes" xml:space="preserve">
          <source>Result</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="612e12d29278b5519294bc25cdaddffec6d0f1c6" translate="yes" xml:space="preserve">
          <source>Results</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9583ec9f7aa942bfe8fc15e3d5dbe25d72539bf1" translate="yes" xml:space="preserve">
          <source>Results are returned to the caller</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5bbc9221d351db6c25ac45712f9b8af2b0718a46" translate="yes" xml:space="preserve">
          <source>Retrieved data points after being processed by the aggregators. Each data point consists of a timestamp and a value, the format determined by the serializer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9b76990cd60c8c024b37c5485d69140e6fcdd13" translate="yes" xml:space="preserve">
          <source>Returns a list of available aggregation functions in JSON format only. Other formats are ignored. This method does not accept any query string parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ffcaa1c92bee66abfc7eaac30c7d3d99acd693a" translate="yes" xml:space="preserve">
          <source>Returns a list of the commands supported via the Telnet style API. This command does not modify TSD in any way.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31e244222ae9c1a35423211abc393700d885d151" translate="yes" xml:space="preserve">
          <source>Returns information about the various HBase region server clients in AsyncHBase. This helps to identify issues with a particular region server. (v2.2)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68156699e329fa169dc4abca6355515e27bec5a6" translate="yes" xml:space="preserve">
          <source>Returns only the smallest data point from all of the time series or within the time span. This function will perform linear interpolation across time series. It's useful for looking at the lower bounds of gauge metrics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e22a3741a8f8a6e7f63ce32e873fab1e814e7db" translate="yes" xml:space="preserve">
          <source>Returns statistics about the running TSD</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e83886b4767a0f403655a9c73135b6613a6076b9" translate="yes" xml:space="preserve">
          <source>Returns the data points formatted as an array of arrays instead of a map of key/value pairs. Each array consists of the timestamp followed by the value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a42477d60eecb4a1558099599f7780fc0c21ad2f" translate="yes" xml:space="preserve">
          <source>Returns the difference of all series in the list. Performs a UNION across tags in each metric result sets, defaulting to a fill value of zero. A maximum of 26 series are supported at this time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="810d70a77924a8865457b44b5a2f7e3c76a6ae5a" translate="yes" xml:space="preserve">
          <source>Returns the first data point in the set. Only useful for downsampling, not aggregation. (2.3)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="125428f56df3be26b8588ea1531cb2f7ed1a5d6d" translate="yes" xml:space="preserve">
          <source>Returns the last data point in the set. Only useful for downsampling, not aggregation. (2.3)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0fbdaa865652b03b2365815501cef78795d0862" translate="yes" xml:space="preserve">
          <source>Returns the latest lines logged by the TSD internally, returning the most recent entries first. OpenTSDB uses LogBack and the &lt;code&gt;src/logback.xml&lt;/code&gt; file must have a Cyclic Buffer appender configured for this endpoint to function. The XML configuration determines how many lines will be returned with each call. Output defaults to plain text with message components separated by tabs, or it can be returned as JSON with the proper query string.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3734e9fe88ce3e432eddbb4d2c42a2b56053e50" translate="yes" xml:space="preserve">
          <source>Returns the number of data points stored in the series or range. When used to aggregate multiple series, zeros will be substituted. It's best to use this when downsampling.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15bcd0c8e02191edfe687dfc17546d931b09f66d" translate="yes" xml:space="preserve">
          <source>Returns the product of all series in the list. Performs a UNION across tags in each metric result sets, defaulting to a fill value of zero. A maximum of 26 series are supported at this time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e49392640aa0073c556970c5c5e28b88b8cbb19d" translate="yes" xml:space="preserve">
          <source>Returns the quotient of all series in the list. Performs a UNION across tags in each metric result sets, defaulting to a fill value of zero. A maximum of 26 series are supported at this time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f021b616b58aa099c36aa0666d254f16334b7788" translate="yes" xml:space="preserve">
          <source>Returns the series that include only the tag keys provided in the filters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76ba08e06f345cdd02cf7c52ba5b7c05fd816f65" translate="yes" xml:space="preserve">
          <source>Returns the sum of all series in the list. Performs a UNION across tags in each metric result sets, defaulting to a fill value of zero. A maximum of 26 series are supported at this time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="33606c05bdfefa9f6381628a9519fdb44d89446c" translate="yes" xml:space="preserve">
          <source>Returns version information about the build of the running TSD. Can be returned in either the default of plain-text or JSON.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e1304ec14afe111fadcdd759217985505c00be5" translate="yes" xml:space="preserve">
          <source>Reverse metrics mapping is missing forward mapping: bar -&amp;gt; 000002</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd3707792d1c1686c8d0894e695458417aa413a0" translate="yes" xml:space="preserve">
          <source>Right click the &lt;code&gt;net.opentsdb.tsd.client&lt;/code&gt; package under SRC and select &lt;code&gt;Build Path&lt;/code&gt; then &lt;code&gt;Exclude&lt;/code&gt; from the menu</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e2cc05a9a89ef965b3cd38a0fbee7b7d67fef84" translate="yes" xml:space="preserve">
          <source>Right now, you cannot combine two metrics into one plot line. This means you want a metric to be the biggest possible aggregation point. If you want to drill down to specifics within a metric, use tags.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b73d8876a2184b492a1716f84b5b77a17008cd93" translate="yes" xml:space="preserve">
          <source>Rolled up data must be stored in a separate table from the raw data as to avoid existing schema conflicts and to allow for more performant queries.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95fa7ec96fdbaf78e2b6b8e26e1e7ecedf0962ef" translate="yes" xml:space="preserve">
          <source>Rolled-up Pre-Aggregate - Pre-aggregated data can also be rolled up on time similar to raw time series. This can improve query speed for wide time spans over pre-aggregated data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="762f84b0fc92d6bfc5c6eb07bdc056c3fcc4e10b" translate="yes" xml:space="preserve">
          <source>Rolled-up Pre-Aggregates</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f9b57721250691fdb25c1289a335b7893d55f1d" translate="yes" xml:space="preserve">
          <source>Rollup - This is a downsampled value across time for a single time series. It's similar to using a downsampler in query where the time series may have a data point every minute but is downsampled to a data point every hour using the &lt;code&gt;sum&lt;/code&gt; aggregation. In that case, the resulting rolled up value is the sum of 60 values. E.g. if the value for each 1 minute data point is &lt;code&gt;1&lt;/code&gt; then the resulting rollup value would be &lt;code&gt;60&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="620b8ecd6aafe4cf4453ac57a97f09e82376ab5b" translate="yes" xml:space="preserve">
          <source>Rollup And Pre-Aggregates</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6954b8e2b0759594d8cc87e6d86fc404b8a75f96" translate="yes" xml:space="preserve">
          <source>Rollup Example</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e83990956304f5087beb5571d6e7d9e63d71e1ad" translate="yes" xml:space="preserve">
          <source>Rollup Schema</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="589e968b73f2dc9616e01f632e2f028e7e429c69" translate="yes" xml:space="preserve">
          <source>Rollup Tables Schema</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27ae60684ff8126340ecfdbb963457237db98069" translate="yes" xml:space="preserve">
          <source>Rollup and pre-aggregate values are extensions of the &lt;code&gt;put&lt;/code&gt; object with three additional fields. For completeness, all fields are listed below:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e9264523eaa29788a45e5e85d2f8432f9928495" translate="yes" xml:space="preserve">
          <source>Rollup/Pre-Aggregates - Support for storing and querying time-based rolled up data and/or pre-aggregated values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f14b7461eb4bdbd051d13a9bb0960a70c2b3bb5a" translate="yes" xml:space="preserve">
          <source>Rollups</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e96857c58f716104caead648ee6aa61ab8e41cdc" translate="yes" xml:space="preserve">
          <source>Root</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82cdf2eb144609f9d3d7dcaeaf1537618a861649" translate="yes" xml:space="preserve">
          <source>Row Key</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a1e3bb6775cbadc9f9cd6b96e8bb6efcf1c882e8" translate="yes" xml:space="preserve">
          <source>Row Key Format</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d287e360db918b84ca75138b55454f0005650f53" translate="yes" xml:space="preserve">
          <source>Row keys, column qualifiers and column values are emitted as Java byte arrays. These are surrounded by square brackets and individual bytes are represented as signed integers (as Java does not have native unsigned ints). Row keys are printed first followed by a new line. Then each column is printed on it's own row and is indented with two spaces to indicate it belongs to the previous row. If a compacted column is found, the raw data and number of compacted values is printed followed by a new line. Each compacted data point is printed on it's own indented line. Annotations are also emitted in raw mode.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca319a6235d69499af014e7094650ef53c2ad4bf" translate="yes" xml:space="preserve">
          <source>Rule Column</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd3c7ea6419a215ecc7fd758a6f8561f1f83265a" translate="yes" xml:space="preserve">
          <source>Rule Config</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11393c5b15a889d5925765458c5dd3dcc3e6e496" translate="yes" xml:space="preserve">
          <source>Rule Processing Order</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4ffd38d37bd93c784bb1513eadc8402e1b1a9ff" translate="yes" xml:space="preserve">
          <source>Rule Type</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7db51e52e1da7bf0904f75a1394a05b60272f164" translate="yes" xml:space="preserve">
          <source>Rule Types</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb11a8e3f8712e36e7cd9d1c615a4e3dbb03336a" translate="yes" xml:space="preserve">
          <source>Rules</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d923f6bd37ca509285101eead1a2611eab348ce4" translate="yes" xml:space="preserve">
          <source>Run or Debug it and hopefully it worked</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bef3483e7a79f182abf07b135c10765bacfa0c4f" translate="yes" xml:space="preserve">
          <source>Run the &lt;code&gt;uid&lt;/code&gt; tool with the &lt;code&gt;treesync&lt;/code&gt; sub command to synchronize existing TSMeta objects in the tree</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88b7c5c10f6abbefc86a6e4e5997da1f308135f3" translate="yes" xml:space="preserve">
          <source>Run the TSD via</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f042a3fa115eb0141cdd322fe57f03646aa1487" translate="yes" xml:space="preserve">
          <source>Run the tsd via</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4f3f16eabbec435a9eead457473db789b990b8f" translate="yes" xml:space="preserve">
          <source>Running fsck with &lt;code&gt;--fix&lt;/code&gt; or &lt;code&gt;--fix-all&lt;/code&gt; may delete data points, columns or entire rows and deleted data is unrecoverable unless you restore from a backup. (or perform some HBase trickery to restore the data before a major compaction)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6534109d759c78f95c317b7dd0800b432bda37aa" translate="yes" xml:space="preserve">
          <source>Runs all of your data collectors and gathers their data</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26040c694b2740f98001fa0a642d4c4d68ed9820" translate="yes" xml:space="preserve">
          <source>Runs through the list of TSMeta objects in the UID table and processes each through all configured and enabled trees to compile branches. This command may be run at any time and will not affect existing objects.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d9fcb4568960b83da7bf1003d67459561594e03" translate="yes" xml:space="preserve">
          <source>Runtime Requirements</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b579d946fe9e821a6cdd044b98e64303d29c6a33" translate="yes" xml:space="preserve">
          <source>START-DATE</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c798885ebfbe383227dbd5c2205277f8af9d524" translate="yes" xml:space="preserve">
          <source>SUM</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b2135f5c724ca50dc33953fd0a2abe601fba5a1" translate="yes" xml:space="preserve">
          <source>Salting</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c553dde88c284b35482cbba9a736372924942791" translate="yes" xml:space="preserve">
          <source>Salting - Enables greater distribution of writes for high cardinality metrics as well as asynchronous scanning for improved query speed. (Non backwards compatible)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93cc16cad7601675158b9331513b5740a09166e4" translate="yes" xml:space="preserve">
          <source>Sample Data</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ead4d604225cc7b39d0cf105ccb75ee6d1103dd" translate="yes" xml:space="preserve">
          <source>Saving Your Work</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7ee483aa3d72126406fe52b8ed91bb9c419d02f" translate="yes" xml:space="preserve">
          <source>Scanner</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14727485740cacfb59c1ef7e049b5d0381c81e21" translate="yes" xml:space="preserve">
          <source>Scanner, Query, Global</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d3d61994e825ea8fc0f66e776355704d7a65071" translate="yes" xml:space="preserve">
          <source>Scans the entire data table. &lt;strong&gt;Note:&lt;/strong&gt; This can take a very long time to complete.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bce06414177f72ab70e6387b6af9f8ceef0d6049" translate="yes" xml:space="preserve">
          <source>Search</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2bac1e07ba00740c672b57711dd25b6804ac2967" translate="yes" xml:space="preserve">
          <source>Search API Endpoints</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a35d0cc397280e5041592b41e642284d30531b08" translate="yes" xml:space="preserve">
          <source>Search Plugins - Send meta data to search engines to delve into your data and figure out what's in your database</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb46b29e953e890885a389f38b0a7f1066c99bbc" translate="yes" xml:space="preserve">
          <source>Searches the list of tagks for the given name. If matched, the tagk metadata custom tag list is searched for the given secondary name. If that matches, the value associated with the custom name will be processed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d2405a5b3383cdc7e1a24670d097a63ca6427ca" translate="yes" xml:space="preserve">
          <source>Searches the list of tagks for the given name. If matched, the tagv value associated with the tag name will be processed</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ad2e034c754fe891d3053c0c392da1a5cae2c17" translate="yes" xml:space="preserve">
          <source>Searches the list of tagvs for the given name. If matched, the tagv metadata custom tag list is searched for the given secondary name. If that matches, the value associated with the custom name will be processed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e700fe77c5d58fcdd9d23978528e999d3fb1ea2" translate="yes" xml:space="preserve">
          <source>Searches the metric metadata custom tag list for the given secondary name. If matched, the value associated with the tag name will be processed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2c6b564bd8119e16a3e573a6f9e7c6d1ac7820f" translate="yes" xml:space="preserve">
          <source>Section</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3c88a14491e7aadfd11c3775d13d24b0891f098" translate="yes" xml:space="preserve">
          <source>Secure AsyncHBase - Access HBase clusters requiring Kerberos or simple authentication along with optional encryption.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d011418be32412fc99602923d5dbc4c7466a9e0f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../user_guide/query/aggregators&quot;&gt;&lt;em&gt;Aggregators&lt;/em&gt;&lt;/a&gt; for a list of supported fill policies.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67c4dda637957fc2327f58e285fc899071e100b9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../configuration&quot;&gt;&lt;em&gt;Configuration&lt;/em&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ef4101f6b3da8517c211b9bf8121b2fcb9140ff" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;lookup&quot;&gt;&lt;em&gt;/api/search/lookup&lt;/em&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea9f67744e6f5139ae869fc99552ab8875712c8d" translate="yes" xml:space="preserve">
          <source>See Below</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="991eebed8e8ef59753544a3ea571d149d9d00920" translate="yes" xml:space="preserve">
          <source>See Description</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="725d697f6537c641ba2a4fe7f68563865ce0f254" translate="yes" xml:space="preserve">
          <source>See above</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a605bea659bf1929726d4e155f4fcf47a6badfa" translate="yes" xml:space="preserve">
          <source>See below</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1532b1aadfb4040dfe4dfeab444b467ca6414bc0" translate="yes" xml:space="preserve">
          <source>Selecting a different output format is done with the &lt;code&gt;png&lt;/code&gt; or &lt;code&gt;json&lt;/code&gt; query string parameter. The value for the parameter is ignored. For example you can request &lt;code&gt;http://localhost:4242/suggest?type=metrics&amp;amp;q=sys&amp;amp;json&lt;/code&gt; to return JSON data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f43504e8dfe0c9116c5869c76acd3113592dcaa3" translate="yes" xml:space="preserve">
          <source>Selects the largest data point</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3087f621b091b58d2e26cb52364df5c157d89c3" translate="yes" xml:space="preserve">
          <source>Selects the smallest data point</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2df19ab039acd47b1bbaa61fed6864580b1c1c9a" translate="yes" xml:space="preserve">
          <source>Self Monitoring</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4b289a7b76be83adf9d38e7a3ee28190349bff2" translate="yes" xml:space="preserve">
          <source>Separator</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d57f563068a2196a8c3f7f3621ed4637bd30cab1" translate="yes" xml:space="preserve">
          <source>Separator Rules</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0230f382c2236f86683640a4d63459257009b045" translate="yes" xml:space="preserve">
          <source>Serializer Name</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="652930d791c00b3834f3617e29b5a1ccf7243cfa" translate="yes" xml:space="preserve">
          <source>Serializer Options</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71796031218483adb9338df6ac1fe8ad1217e178" translate="yes" xml:space="preserve">
          <source>Serializers</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e2b489813d20e25543ecaac1a99d98806f1ae16f" translate="yes" xml:space="preserve">
          <source>Series ID</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c149b4df5b946b70872b91c6642aadb7bf2578d2" translate="yes" xml:space="preserve">
          <source>Servers are frequently using UTC as their timezone. By default, the TSD renders graphs using the local timezone of the server. You can override this to have graphs in your local time by specifying a timezone in &lt;code&gt;./tsdb.local&lt;/code&gt;. For example, if you're in California, this will force the TSD to use your timezone:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ada2ee28d77fa96a4761fb546862ea43fe3c9296" translate="yes" xml:space="preserve">
          <source>Serves static files, such as JavaScript generated by the GWT compiler or favicon.ico. The TSD needs a &lt;code&gt;--staticroot&lt;/code&gt; or &lt;code&gt;tsd.http.staticroot&lt;/code&gt; argument to start. This argument is the path to a directory that contains the files served by this end point.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="448ab73ba1c21e671e218fb91f2644c834f0c16f" translate="yes" xml:space="preserve">
          <source>Set</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93c87825f844886a14b11c8c9784e214ee0dca40" translate="yes" xml:space="preserve">
          <source>Set the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6310d659f89689a9e156078a1d03e05af378dbc" translate="yes" xml:space="preserve">
          <source>Set the max ID row to the largest detected value</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a95a85ae49a356e1c318567b4e36adca483e0fb7" translate="yes" xml:space="preserve">
          <source>Sets all repair flags to attempt to fix all issues at once. &lt;strong&gt;Use with caution&lt;/strong&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8096e4c12eb894bbe1020f48f2e9113f027f1a91" translate="yes" xml:space="preserve">
          <source>Sets the maximum number of connections a TSD will handle, additional connections are immediately closed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71643ad5580283dd9e11699f17fdff8aa6f118dd" translate="yes" xml:space="preserve">
          <source>Sets the mode for OpenTSDB</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cdd7bb2816b7a8f88bce0e47be39943bc369516b" translate="yes" xml:space="preserve">
          <source>Setup</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a44b5051601ad725a88f27d508548e0e61fcf69c" translate="yes" xml:space="preserve">
          <source>Setup Zookeeper on at least 3 servers for fault tolerance. They must have a lot of RAM and a fairly fast disk for log writing. On small clusters, these can run on the Name node servers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b50b61ac9d260c08ff4ecb21a0dcd912ab821435" translate="yes" xml:space="preserve">
          <source>Setup a Cassandra cluster using the &lt;code&gt;ByteOrderedPartitioner&lt;/code&gt;. This is critical as we require the row keys to be sorted. Because this setting affects the entire node, you may need to setup a cluster dedicated to OpenTSDB.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3df975c0562890b4af4f4180dafd42e67abbbff" translate="yes" xml:space="preserve">
          <source>Setup your Google Cloud Platform account.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7fddb7d8d1d60b1eeefa9af01082e0811d4b484d" translate="yes" xml:space="preserve">
          <source>Shutdown</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82779e48197dac29d9f883139c8a962e62e4921f" translate="yes" xml:space="preserve">
          <source>Similar to a file system check, the fsck command will scan and, optionally, attempt to repair problems with data points in OpenTSDB's data table. The fsck command only operates on the &lt;code&gt;tsdb&lt;/code&gt; storage table, scanning the entire data table or any rows of data that match on a given query. Fsck can be used to repair errors and also reclaim space by compacting rows that were not compacted by a TSD and variable-length encoding data points from previous versions of OpenTSDB.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="989215056b446955225dbdc8164e6ace8f4fc56b" translate="yes" xml:space="preserve">
          <source>Similar to collisions, when enabled for a tree, a column can be recorded for each time series that failed to match any rules in the rule set and therefore, did not appear in the tree. These columns only appear in the not matched row for a tree. The qualifier is of the format &lt;code&gt;tree_not_matched:&amp;lt;TSUID&amp;gt;&lt;/code&gt; where the TSUID is a byte array representing the time series identifier. The value of a not matched column is the byte array of the TSUID that failed to match a rule.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5e3555a8cb2fdca87e36c63af6eef2cdff1314d" translate="yes" xml:space="preserve">
          <source>Similar to the standard query endpoint, there are two methods to use in selecting which time series should return data:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2aae23d6a41b7efd0e3905c6759da1bd197320f5" translate="yes" xml:space="preserve">
          <source>Simply supply one or more space separate metric names in the call.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="22437f13978de8edd5f83c3b66265fb9cf54b266" translate="yes" xml:space="preserve">
          <source>Since OpenTSDB doesn't know whether a query will return multiple time series until it scans through all of the data, an aggregation function must be specified for every query just in case. When more than one series is found, the two series are &lt;strong&gt;aggregated&lt;/strong&gt; together into a single time series. For each timestamp in the different time series, the aggregator will perform it's computation for each value in every time series at that timestamp. That is, the aggregator will work &lt;em&gt;across&lt;/em&gt; all of the time series at each timestamp. The following table illustrates the &lt;code&gt;sum&lt;/code&gt; aggregator as it works across time series &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;B&lt;/code&gt; to produce series &lt;code&gt;Output&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27c84463d0a5776a02deece0b591991fc7e2581d" translate="yes" xml:space="preserve">
          <source>Since OpenTSDB uses HBase as the storage layer, you could use strings as the row key. Following the current schema, you may have a row key that looked like &lt;code&gt;sys.cpu.0.user 1292148000 host=websv01.lga.mysite.com owner=operations&lt;/code&gt;. Ordering would be similar to the existing schema, but now you're using up 70 bytes of storage each hour instead of 19. Additionally, the row key must be written and returned with every query to HBase, so you're increasing your network usage as well. So resorting to UIDs can help save space.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a06de4dbb8898d4efb07b249a561653fe86d06b5" translate="yes" xml:space="preserve">
          <source>Since TSDB is JVM based, keeping all of that data in RAM and then running GC will hurt. A lot. (spooling to disk is better, but then you'll hit IO issues)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f88eebdeae9512fa13589628fba1091fb7242f90" translate="yes" xml:space="preserve">
          <source>Since calculating a Unix time in your head is pretty difficult, OpenTSDB also supports human readable absolute date and times. Supported formats include:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db59ae557e158970904475846042c893d57aea02" translate="yes" xml:space="preserve">
          <source>Since we're performing a group by aggregation (grouping by &lt;code&gt;colo&lt;/code&gt;) we have a value for each timestamp from the original data set. We are &lt;em&gt;not&lt;/em&gt; downsampling or performing a rollup in this situation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23e7e78e921c8c8fccc99fdeb23353b77063b385" translate="yes" xml:space="preserve">
          <source>Single Data Point Column Format</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2360f1dda855fe3c8576a4cdaa33a9b5dffdc76f" translate="yes" xml:space="preserve">
          <source>Site-specific Configuration</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="97ca91337e3c0f1ab7e2e8dd4c936299dd544b9f" translate="yes" xml:space="preserve">
          <source>Size of the compaction queue that must be exceeded before flushing is triggered</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f07f642619ca7b895de939d1da145539d6517a1c" translate="yes" xml:space="preserve">
          <source>Skips group by aggregation of all time series. (2.3)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cc5da5cdbd0c1a735113432e9e5d454cfc69ca1" translate="yes" xml:space="preserve">
          <source>Snow falls in many regions so we may record a &lt;code&gt;tagk&lt;/code&gt; of &lt;code&gt;region&lt;/code&gt; to get &lt;code&gt;region=new_england&lt;/code&gt; or &lt;code&gt;region=north_west&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38314556cda7601a4dc6cd1a3a2d76033456f17f" translate="yes" xml:space="preserve">
          <source>So now that we have our 2 metrics, we can start sending data to the TSD. Let's write a little shell script to collect some data off of MySQL and send it to the TSD:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75931427d7864a063f9bd45b6176e676f0a7efb6" translate="yes" xml:space="preserve">
          <source>So, now you have a plot of your web hits. How does that correlate against load average? On this same graph, click the &quot;+&quot; tab to add a new metric to this existing graph. Enter proc.loadavg.1min as your metric and click &quot;Right Axis&quot; so the Y axis is scaled separately and its labels on the right. Make sure &quot;Rate&quot; is unchecked, since load average is not a counter metric. Voil?! Now you can see how changes in the rate of web hits affects your system's load average.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05b004a92e5eda3ec6e47516b582fc25b61b35b9" translate="yes" xml:space="preserve">
          <source>Solutions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b19b9cc7ff04a2c2dd4432e7ce2d09b73b02e08d" translate="yes" xml:space="preserve">
          <source>Some configuration values require special consideration:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10f01acbc579f98749050aaf14595d2cb2b09b18" translate="yes" xml:space="preserve">
          <source>Some example unsalted row keys, represented as hex are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e092cacb21835e74829c48ab87e893ed73b385c" translate="yes" xml:space="preserve">
          <source>Some methods of improving batch processing include:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ffa5f1170b8e525f5e4861962da6c01a91e74ac" translate="yes" xml:space="preserve">
          <source>Some query string parameters can be supplied that alter the response to a put request:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ce9c38c64d64e9b4b466a146c6e78a39116b298" translate="yes" xml:space="preserve">
          <source>Some versions of OpenTSDB may have encoded floating point values on 8 bytes when setting the qualifier length to 4 bytes. The first four bytes should be 0. If the value was compacted, the compacted column will be invalid as parsing is no longer possible.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="feb3ada0e682f4e4cfd5fd64c9c34dc41f52b26e" translate="yes" xml:space="preserve">
          <source>Sorts all resulting time series by the maximum value for the time span and emits &lt;code&gt;n&lt;/code&gt; number of series with the highest values. &lt;code&gt;n&lt;/code&gt; must be a positive integer value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aaee3011489372e223b81d615a8dd09a3ac53da0" translate="yes" xml:space="preserve">
          <source>Sorts all resulting time series by their most recent value and emits &lt;code&gt;n&lt;/code&gt; number of series with the highest values. &lt;code&gt;n&lt;/code&gt; must be a positive integer value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="30a1c6a0266e94955aef3e62df2cc0bf48957ed0" translate="yes" xml:space="preserve">
          <source>Source Layout</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a8cd27e1baaf46933b7b9996146685300427299" translate="yes" xml:space="preserve">
          <source>Spaces are not allowed</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4bc9012dd88243a09f1a91f3182d62e6847abd20" translate="yes" xml:space="preserve">
          <source>Special characters must be escaped with a backslash include: &lt;code&gt;#&lt;/code&gt;, &lt;code&gt;!&lt;/code&gt;, &lt;code&gt;=&lt;/code&gt;, and &lt;code&gt;:&lt;/code&gt; E.g.:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7127ee3e62698fe1e49605ccbb8876fe3a6099c3" translate="yes" xml:space="preserve">
          <source>Specification of the ZooKeeper quorum to use, i.e. a list of servers and/or ports in the ZooKeeper cluster</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf256b7a0076aa656de9efb669caa65616ab0b93" translate="yes" xml:space="preserve">
          <source>Specifying the &lt;code&gt;--compact&lt;/code&gt; flag along with &lt;code&gt;--fix&lt;/code&gt; will compact any row that has stand-alone data points within the query range. During compaction, any data points from old OpenTSDB versions that qualify for VLE will be re-encoded.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e68bc425e76c77028ef38cc652b4d2a7f748bd2" translate="yes" xml:space="preserve">
          <source>Split the metric by dot</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0460c9cd240d074acbabff6d3d71780c0b35252" translate="yes" xml:space="preserve">
          <source>Start Collecting Data</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41c1074ddb72ef2d03a6706ccec180ec410aee4a" translate="yes" xml:space="preserve">
          <source>Start Time</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="19c812dba83db07bd50c82080d370a57266f072b" translate="yes" xml:space="preserve">
          <source>Start a TSD</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebfe0e18412e1f435c14d9ca61190ba53bb09684" translate="yes" xml:space="preserve">
          <source>Starting time for the query. This may be an absolute or relative time. See &lt;a href=&quot;../query/dates&quot;&gt;&lt;em&gt;Dates and Times&lt;/em&gt;&lt;/a&gt; for details</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dff544b5731437875ce7fcda6c030aa746ae9332" translate="yes" xml:space="preserve">
          <source>Starting time for the query. This may be an absolute or relative time. See &lt;a href=&quot;dates&quot;&gt;&lt;em&gt;Dates and Times&lt;/em&gt;&lt;/a&gt; for details</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="607cccfe9f30188c7ed272c606249ee1faa46789" translate="yes" xml:space="preserve">
          <source>Startup Plugins</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7232c73848d7ccab0005c467cdcb34262791bebc" translate="yes" xml:space="preserve">
          <source>Startup Plugins - APIs to help with service discovery on TSD startup.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d24539d6d6926febbcf99c223a6a651255251ad" translate="yes" xml:space="preserve">
          <source>Startup Plugins can be used to perform additional initialization steps during the OpenTSDB startup process.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9a0d4194308065c82429af7960a754c7b11c1a4" translate="yes" xml:space="preserve">
          <source>Startup and Service Discovery</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="192915da46ada22b17ed7e8ed027cd963eeea272" translate="yes" xml:space="preserve">
          <source>Statistical Analysis Tools</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be763e9aba2af6b8baabada85d5e26c043c93fed" translate="yes" xml:space="preserve">
          <source>Stats</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4a70d99f775999a81ef43bacb0a8417cb0df1cb" translate="yes" xml:space="preserve">
          <source>Stats - This tab will display a list of statistics about the running TSD. The same stats can be retrieved via the &lt;code&gt;/stats&lt;/code&gt; or &lt;code&gt;/api/stats&lt;/code&gt; endpoints.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e092dda4f0e27d0c7686ddd00272079e678b6e6" translate="yes" xml:space="preserve">
          <source>Storage</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc61e2573021d658355b7841b297ad61e99a22fc" translate="yes" xml:space="preserve">
          <source>Storage Exception Handler</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab89cd10e4d5bbee4c232ee91b5cc73e8b63827e" translate="yes" xml:space="preserve">
          <source>Storage Exception Plugin - Enables various handling of data points when HBase is unavailable</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b924576ff89b726aaf06bc9d6ef69d63ba7f040" translate="yes" xml:space="preserve">
          <source>Store Data Via HTTP - Write data points over HTTP as an alternative to Telnet</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50e208b55d94ce23ee77fcd77bffb07836fb4fc6" translate="yes" xml:space="preserve">
          <source>Strict Matching</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3df63b7acb0522da685dad5fe84b81fdd7b25264" translate="yes" xml:space="preserve">
          <source>String</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82a6444a323d167c802fbb886cfa9636ff70d335" translate="yes" xml:space="preserve">
          <source>String name of the thread, usually assigned by default</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aecb528c9ba69f56f194c38a6ba103457a098e2b" translate="yes" xml:space="preserve">
          <source>String or Integer</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a84f4e1a18dff0d5a71a2641d8f7291414a6bb4" translate="yes" xml:space="preserve">
          <source>String, Integer</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3816c4beac471c733eed1d91c213f8c2b6a29262" translate="yes" xml:space="preserve">
          <source>Strings</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc59e7b9958053d02e0118666b0ee41326c62ee3" translate="yes" xml:space="preserve">
          <source>Strings - Strings, even those with spaces, do not require quotation marks, but some considerations apply:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9fd588758603ba5c5941d10352b30e9d84893496" translate="yes" xml:space="preserve">
          <source>Strings are case sensitive, i.e. &quot;Sys.Cpu.User&quot; will be stored separately from &quot;sys.cpu.user&quot;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ff839d4aa081d5b07cbb608f3acbe3888f03234" translate="yes" xml:space="preserve">
          <source>Style Tab</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1fb22e7591b0556a7b78a9f8047fb5abb0d9df7" translate="yes" xml:space="preserve">
          <source>Sub Queries</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cb653c42b6427ffc7ebc02dffab76f5442750fb" translate="yes" xml:space="preserve">
          <source>Successful processing will result in responses like:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc9ce14b28c6f2c3b72caf056ca604b2b96f7d2b" translate="yes" xml:space="preserve">
          <source>Sum</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61bfcc1b44fc1003d5eee48d9895791de41c39b4" translate="yes" xml:space="preserve">
          <source>Summed Result</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0797816ee0cecfb2443b94e09274e9303559e6a1" translate="yes" xml:space="preserve">
          <source>Supported as of version 2.3</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ffffbc05f815c8a1a33a62c6c03f8ca9db1c1650" translate="yes" xml:space="preserve">
          <source>Switch #5 died and was replaced</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6fb998729ab13837b94e876048c962ff6a63c359" translate="yes" xml:space="preserve">
          <source>Synchronous Writing - The HTTP Put API now supports synchronous writing to make sure data is flushed to HBase.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7351477e90e7ffee06819bb8bd7dd9f6e6152273" translate="yes" xml:space="preserve">
          <source>System Busy</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80c0b230762f1b4764b9bec6b3b1ff958262b7bd" translate="yes" xml:space="preserve">
          <source>System CPU Time</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef717ba5a6550ee67a95c7601b699e02d5ba79ed" translate="yes" xml:space="preserve">
          <source>System Configured</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="49c68a7a88999bf572de251d20b60c389467843d" translate="yes" xml:space="preserve">
          <source>System processor time</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bdbc83c5d52622ad269c3020cd057a61c8507c76" translate="yes" xml:space="preserve">
          <source>Systems that track data in counters often revert to 0 when restarted. When that happens and we could get a spurious result when using the max counter feature. For example, if the counter has reached &lt;code&gt;2000&lt;/code&gt; at &lt;code&gt;t0&lt;/code&gt; and someone reboots the server, the next value may be &lt;code&gt;500&lt;/code&gt; at &lt;code&gt;t1&lt;/code&gt;. If we set our max to &lt;code&gt;65535&lt;/code&gt; the result would be &lt;code&gt;65535 - 2000 + 500&lt;/code&gt; to give us &lt;code&gt;64035&lt;/code&gt;. If the normal rate is a few points per second, this particular spike, with &lt;code&gt;30s&lt;/code&gt; between points, would create a rate spike of &lt;code&gt;2,134.5&lt;/code&gt;! To avoid this, we can set the &lt;code&gt;resetValue&lt;/code&gt; which will, when the rate exceeds this value, return a data point of &lt;code&gt;0&lt;/code&gt; so as to avoid spikes in either direction. For the example above, if we know that our rate almost never exceeds 100, we could configure a &lt;code&gt;resetValue&lt;/code&gt; of &lt;code&gt;100&lt;/code&gt; and when the data point above is calculated, it will return &lt;code&gt;0&lt;/code&gt; instead of &lt;code&gt;2,134.5&lt;/code&gt;. The default value of 0 means the reset value will be ignored, no rates will be suppressed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="531e79cf49e65e5ef03f9eda35aa58258cb7a812" translate="yes" xml:space="preserve">
          <source>TAGK</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbea4f712c9e7e49547eeea644aec2d1ca98d167" translate="yes" xml:space="preserve">
          <source>TAGK_CUSTOM</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b13fff1bfa536de1715d7dd7056429937e7ff0c9" translate="yes" xml:space="preserve">
          <source>TAGV_CUSTOM</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8945ea9535c673462009544ee44ab437a74852a6" translate="yes" xml:space="preserve">
          <source>TCollector</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6512bcf27e448d005da1c245bf45ce5f632159aa" translate="yes" xml:space="preserve">
          <source>TODO - include scripts for pre-splitting.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="46388f2b25d1970fcb2e75b3daf49c8d38e5ba23" translate="yes" xml:space="preserve">
          <source>TS#</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08f128e9c175d3e68eba8c8c4626919341fba913" translate="yes" xml:space="preserve">
          <source>TSDB found 7 total timeseries that included the &quot;host&quot; tag. There were 3 unique values for that tag (web01, web02, and web03).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="149c17e96333c492e2c273e9bb42e96c480c29e1" translate="yes" xml:space="preserve">
          <source>TSDB implements a subset of Graphite functions though we hope to add more in the future. For a list of Graphite functions and descriptions, see the &lt;a href=&quot;http://graphite.readthedocs.org/en/latest/functions.html&quot;&gt;Documentation&lt;/a&gt;. TSD supported functions appear below.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5abf1d19a79f3f793aa515466f9fdf75b882fd28" translate="yes" xml:space="preserve">
          <source>TSD_proxy</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3184f55b8352dbcac783b33184159256f1499926" translate="yes" xml:space="preserve">
          <source>TSDs are slow to respond after region splits or over long run times</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47127bff908b0d7cfaccdd186959973669880283" translate="yes" xml:space="preserve">
          <source>TSDs are stuck in GC or crashing due to Out of Memory Exceptions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="669b912447b55fd4522c2cbd90ed087034b7f8db" translate="yes" xml:space="preserve">
          <source>TSMETA</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00341c52c32e4182980d639e5d201e1746f297bb" translate="yes" xml:space="preserve">
          <source>TSMETA Response</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8568e05fda1ef1197f0c4f1031548069d7b48162" translate="yes" xml:space="preserve">
          <source>TSMETA_SUMMARY Response</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d587bb4051ddac89c4585794c8cad3c78a512c9" translate="yes" xml:space="preserve">
          <source>TSMeta</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2cc183e88945fdbacb7bd18fe8d8ddcb856a2759" translate="yes" xml:space="preserve">
          <source>TSMeta Column</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e74af808ae8c67e80609cf6b6bf5f945bc84c2e" translate="yes" xml:space="preserve">
          <source>TSUID</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="74dacca945a9843902c13fd53af1bc8f1f2c3dc1" translate="yes" xml:space="preserve">
          <source>TSUID Query String Format</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56a7f3846182fe60d61f8d9befdbb8bd845091bf" translate="yes" xml:space="preserve">
          <source>TSUID queries are simpler than Metric queries. Simply pass a list of one or more hexadecimal encoded TSUIDs separated by commas:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2f8426b25a30d2cb2b7a5e712d3dd69d208411c" translate="yes" xml:space="preserve">
          <source>TSUIDS Response</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d009e840cf2b335339b4d132c1c643b3e2506b3f" translate="yes" xml:space="preserve">
          <source>TSUIDs</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88de905d5aaf8c4b9cb1e3cdaadcdb423b2662ca" translate="yes" xml:space="preserve">
          <source>Tag 1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca06241d4100e0d93621b6b9318210c0b2c05838" translate="yes" xml:space="preserve">
          <source>Tag 2</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c05bbe45c714e32caae782282ecc51cee1956ad" translate="yes" xml:space="preserve">
          <source>Tag 3</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84fcc161a94be1e47f30ac8360f8225de46f02a0" translate="yes" xml:space="preserve">
          <source>Tag Filters</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="369e53f2aeda5a80f30d273987ca59a65645ab3c" translate="yes" xml:space="preserve">
          <source>Tag keys and values that were common across all time series that were aggregated in the resulting series</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a55527a22bf89ac76e88e12f4385664123f36301" translate="yes" xml:space="preserve">
          <source>Tag keys that appeared in all series in the resulting series but had different values</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f11070ecf59f30d0c40f3a451d7e5efb42fd1182" translate="yes" xml:space="preserve">
          <source>Tag names (tagk) are sorted alphabetically before storage, so the &quot;host&quot; tag will always appear first in the row key/TSUID ahead of &quot;owner&quot;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d27f0ece0dd1fc85ffadbe1497b229d16b02b36" translate="yes" xml:space="preserve">
          <source>TagK</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51f9b85045e61aafb5e16b1691897ee8ffda8ee9" translate="yes" xml:space="preserve">
          <source>TagK_Custom</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="633e55297dab7db5cd50b0019b47703e60c9870f" translate="yes" xml:space="preserve">
          <source>TagV_Custom</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="848eed0fbd5429f556b2982dec3ea87136e33e44" translate="yes" xml:space="preserve">
          <source>Tags</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7e2a98f1637d7abf3d4fe2fa8265bcecc4b4e94" translate="yes" xml:space="preserve">
          <source>Tags are your Friend</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10e366bda0b1ece664990de73ac6e042e868acda" translate="yes" xml:space="preserve">
          <source>Tags vs. Metrics</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c13a0ac4f7b09536b0287df5418517204d9bc476" translate="yes" xml:space="preserve">
          <source>Take a look at these two time series where the data is simply offset by 10 seconds:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a5d3db51a8599a926199e948d42c51799cee6fd" translate="yes" xml:space="preserve">
          <source>Take the previous example where the metric was &lt;code&gt;webserver01.sys.cpu.0.user&lt;/code&gt;. In OpenTSDB, this may become &lt;code&gt;sys.cpu.user host=webserver01, cpu=0&lt;/code&gt;. Now if we want the data for an individual core, we can craft a query like &lt;code&gt;sum:sys.cpu.user{host=webserver01,cpu=42}&lt;/code&gt;. If we want all of the cores, we simply drop the cpu tag and ask for &lt;code&gt;sum:sys.cpu.user{host=webserver01}&lt;/code&gt;. This will give us the aggregated results for all 64 cores. If we want the results for all 1,000 servers, we simply request &lt;code&gt;sum:sys.cpu.user&lt;/code&gt;. The underlying data schema will store all of the &lt;code&gt;sys.cpu.user&lt;/code&gt; time series next to each other so that aggregating the individual values is very fast and efficient. OpenTSDB was designed to make these aggregate queries as fast as possible since most users start out at a high level, then drill down for detailed information.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3607a844763a866c47dcf9063543470c81d893b" translate="yes" xml:space="preserve">
          <source>Takes a single literal value or a pipe delimited list of values and returns any time series matching the results on a case sensitive bases. This is a very efficient filter as it can resolve the strings to UIDs and send that to the storage layer for pre-filtering.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83b69ad961f6b6f31d3bca4220adb5ce771721e8" translate="yes" xml:space="preserve">
          <source>Tcollector does several things for you:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89307d419a2fe4fbb69af92b3d3af27b6ec14d3e" translate="yes" xml:space="preserve">
          <source>Telnet</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8878fa9acaed98a9ff3c51469716f7c9095b9c3" translate="yes" xml:space="preserve">
          <source>Telnet Style API</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="579449da0a08d0283723e20761119211b7a3e95a" translate="yes" xml:space="preserve">
          <source>Test the rules with some TSMeta objects via the HTTP API</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1d9414a8889e69c3e19978de0b12f441312f8ce" translate="yes" xml:space="preserve">
          <source>Test throughput on your systems to make sure it handles the load properly. Since it writes each point to disk immediately this can result in a huge disk IO load so very large OpenTSDB installations may require a larger number of drains than TSDs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0820b32b206b7352858e8903a838ed14319acdfd" translate="yes" xml:space="preserve">
          <source>Testing</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="245c78dcc135adbf31b9d351b04afff74eec2611" translate="yes" xml:space="preserve">
          <source>Thank you to everyone who has contributed to 2.3. Help us out by sharing your ideas and code at &lt;a href=&quot;https://github.com/OpenTSDB&quot;&gt;GitHub&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="434f16906b89bfcadd1fff4351fcbd8427f67516" translate="yes" xml:space="preserve">
          <source>The &quot;maximum if missing minimum&quot; function returns only the smallest data point from all of the time series or within the time span. This function will &lt;em&gt;not&lt;/em&gt; perform interpolation, instead it will return the maximum value for the type of data specified if the value is missing. This will return the Long.MaxValue for integer points or Double.MaxValue for floating point values. See &lt;a href=&quot;http://docs.oracle.com/javase/tutorial/java/nutsandbolts/datatypes.html&quot;&gt;Primitive Data Types&lt;/a&gt; for details. It's useful for looking at the lower bounds of gauge metrics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ba12a4e4a1c23f18ba3ff01121c2abe7799a274" translate="yes" xml:space="preserve">
          <source>The &quot;minimum if missing maximum&quot; function returns only the largest data point from all of the time series or within the time span. This function will &lt;em&gt;not&lt;/em&gt; perform interpolation, instead it will return the minimum value for the type of data specified if the value is missing. This will return the Long.MinValue for integer points or Double.MinValue for floating point values. See &lt;a href=&quot;http://docs.oracle.com/javase/tutorial/java/nutsandbolts/datatypes.html&quot;&gt;Primitive Data Types&lt;/a&gt; for details. It's useful for looking at the upper bounds of gauge metrics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ebf32e6a3ccf24d30015e546ff2de322adc833c" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;*&lt;/code&gt; (asterisk) is a grouping operator that will return a data set for each unique value of the tag name given. Every timeseries that includes the given metric and the given tag name, regardless of other tags or values, will be included in the results. After the individual timeseries results are grouped, they'll be aggregated and returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1630aa5aee22e58dd5ff2c49ff491538b01d544" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;*&lt;/code&gt; operator is greedy and will return &lt;em&gt;all&lt;/em&gt; values that are assigned to a tag name. If you only want a few tag values, you can use the &lt;code&gt;|&lt;/code&gt; (pipe) operator instead.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d213e8505dd4c6807cbb03c9d3cd25ad8092a5f0" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;--batch -N&lt;/code&gt; flags ask the mysql command to remove the human friendly fluff so we don't have to filter it out ourselves. Then the output is piped to awk, which is told to split fields on tabs &lt;code&gt;-F&quot;\t&quot;&lt;/code&gt; because with the &lt;code&gt;--batch&lt;/code&gt; flag that's what mysql will use. We also create a couple of variables, one named &lt;code&gt;now` and initialize it to the current timestamp, the other named ``host` and set to the hostname of the local machine. Then, for every line, we print put ``mysql.&lt;/code&gt;, followed by the lower-case form of the first word, then by a space, then by the current timestamp, then by the second word (the value), another space, and finally &lt;code&gt;host=&lt;/code&gt; and the current hostname. Rinse and repeat every 15 seconds. The &lt;code&gt;-w 30&lt;/code&gt; parameter given to &lt;code&gt;nc&lt;/code&gt; simply sets a timeout on the connection to the TSD. Bear in mind, this is just an example, in practice you can use tcollector's MySQL collector.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="958cccad0f210bb53355e9895ab90133cb6edc17" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;--delete-bad-values&lt;/code&gt; flag will remove the column. You could try parsing the value as a Double manually and see if it looks valid, otherwise it's likely a corrupt column.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2a6bd71a55b8dfa1abccd4c62738a32510ad393" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;--delete-unknown-columns&lt;/code&gt; flag will remove this column from the row.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b419f269ec14cfab928a853af8c60568f67fdd8a" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;--fix&lt;/code&gt; flag will repair these errors by rewriting the value without the first four bytes. The qualifier remains unchanged.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90d929e2ceae35355dec5e982c8d5389c2f16e4d" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;/api/stats&lt;/code&gt; endpoint is a good place to execute a health check for your TSD as it will execute a query to storage for fetching UID stats. If the TSD is unable to reach the backing store, the API will return an exception.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="428f512707967a9c9eb4a2e356883786abc2951c" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;/query&lt;/code&gt; endpoint is documented below. As of 2.2 data matching a query can be deleted by using the &lt;code&gt;DELETE&lt;/code&gt; verb. The configuration parameter &lt;code&gt;tsd.http.query.allow_delete&lt;/code&gt; must be enabled to allow deletions. Data that is deleted will be returned in the query results. Executing the query a second time should return empty results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d58387d83b5eaa9c39405b574cf498162711e9f" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;/tree&lt;/code&gt; endpoint allows for creating or modifying a tree definition. Tree definitions include configuration and meta data accessible via this endpoint, as well as the rule set accessiable via &lt;code&gt;/tree/rule&lt;/code&gt; or &lt;code&gt;/tree/rules&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="760249a73b5e7583f9c6e5108aa82f2a96b00b8b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;build.sh&lt;/code&gt; script will compile a JAR and the static GWT files for the front-end GUI if no parameters are passed. Additional parameters include:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df458126ae8093bc751cd58e0b0195ae07222946" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;id&lt;/code&gt; field for all objects can not contain spaces, special characters or periods at this time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="537be3025bd9b95207ce2248a8ef6ee8d5270155" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;messages&lt;/code&gt; field of the response contains information about what occurred during processing. If the TSUID did not exist or an error occurred, the reason will be found in this field. During processing, each rule that the TSMeta is processed through will generate a message. If a rule matched on the TSMeta successfully or failed, the reason will be recorded.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="676c920245d2617269c2ded461715bf69412aca8" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;name&lt;/code&gt; family may also contain additional meta-data columns if configured.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="649587aff540e788c230bb88d6f869ff2d6a52dc" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;regex&lt;/code&gt; rule parameter must be set with a valid regular expression that includes one or more extraction operators, i.e. the parentheses. If the regex matches on the value provided, the extracted data will be used to build the branch or leaf. If more than one extractions are provided in the regex, you can use the &lt;code&gt;regex_group_index&lt;/code&gt; parameter to choose which extracted value to use. The index is 0 based and defaults to 0, so if you want to choose the output of the second extraction, you would set this index to 1. If the regex does not match on the value or the extraction fails to return a valid string, the rule will be considered a no match.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1baed2dca19c62c217b3a083941f5b8970a08fa" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;tags&lt;/code&gt; map should have the same number of entries as the &lt;code&gt;filters&lt;/code&gt; array has &lt;code&gt;group_by&lt;/code&gt; entries. This is due to backwards compatibility with 2.1 and 1.0. Old style queries are converted into filtered queries and function the same way.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12289f8b6b9937ca2a13b5f3c696031a9ee3475d" translate="yes" xml:space="preserve">
          <source>The &lt;strong&gt;Aggregator&lt;/strong&gt; box is a drop-down list of aggregation functions used to manipulate the data for multiple time series associated with the sub query. The default aggregator is &lt;em&gt;sum&lt;/em&gt; but you can choose from a number of other options.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57a8d526177945847aee669211a42db76e52de2d" translate="yes" xml:space="preserve">
          <source>The &lt;strong&gt;Box&lt;/strong&gt; check box will toggle a box outline around the key. This is on by default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c54039217970784cee9c2a22d575005f93c6ffc7" translate="yes" xml:space="preserve">
          <source>The &lt;strong&gt;Cache Directory&lt;/strong&gt; stores temporary files generated when a graph is requested via the built-in GUI. These files should be purged periodically to free up space. OpenTSDB doesn't clean up after itself at this time but there is a script that should be run as a cron at least once a day located at &lt;code&gt;tools/clean_cache.sh&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="461dd0406e77a542a8ac791f482a34f90bc3c7f9" translate="yes" xml:space="preserve">
          <source>The &lt;strong&gt;Downsample&lt;/strong&gt; section is used to reduce the number of data points displayed on the graph. By default, GnuPlot will place a character, such as the &lt;code&gt;+&lt;/code&gt; or &lt;code&gt;x&lt;/code&gt; at each data point of a graph. When the time span is wide and there are many data points, the graph can grow pretty thick and ugly. Use down sampling to reduce the number of points. Simply choose an aggregation function from the drop down list, then enter a time interval in the second box. The interval must follow the relative date format (without the &lt;code&gt;-ago&lt;/code&gt; component). For example, to downsample on an hour, enter &lt;code&gt;1h&lt;/code&gt;. The last selection box chooses a &quot;fill policy&quot; for the downsampled values when aggregated with other series. For graphing in the GUI, only the &quot;zero&quot; value makes a difference as it will substitute a zero for missing series. See &lt;a href=&quot;../query/dates&quot;&gt;&lt;em&gt;Dates and Times&lt;/em&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7d07bd6cdf46ff621a1e674f4be5e288be862f6" translate="yes" xml:space="preserve">
          <source>The &lt;strong&gt;Format&lt;/strong&gt; box can alter the numbers on the Y axis according to a custom algorithm or formatting. This can be useful to convert numbers to or from scientific notation and adjusting the scale for gigabytes if the data comes in as bytes. For example, you can supply a value of &lt;code&gt;%0.0f Reqs&lt;/code&gt; and it will change the axis to show an integer value at each step with the string &lt;em&gt;Reqs&lt;/em&gt; after it as in the following example.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f07f50481b14d844b6300f7d7d4fd15a6fe4ca7e" translate="yes" xml:space="preserve">
          <source>The &lt;strong&gt;Label&lt;/strong&gt; box will add the specified text to the graph alon the left or right Y axis. By default, no label is provided since OpenTSDB doesn't know what you're graphing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a509d5c29208ff3524de9318acd40f7e62ac72e9" translate="yes" xml:space="preserve">
          <source>The &lt;strong&gt;Log Scale&lt;/strong&gt; check box will set a base ten log scale on the Y axis. An example appears below.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60ca5ced4da42ef922c21dab5d29a7b230de537a" translate="yes" xml:space="preserve">
          <source>The &lt;strong&gt;Metric&lt;/strong&gt; box is where you'll choose a metric. This field auto-completes as you type just like a modern web browser. Auto-complete is generally case sensitive so only metrics matching the case provided will be displayed. By default, only the 25 top matching entries will be returned so you may not see all of the possible choices as you type. Either click on the entry you want when it appears or keep typing until you have entire metric in the box.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4a254ffa3a75243d3a9a1b139214acdd91cab74" translate="yes" xml:space="preserve">
          <source>The &lt;strong&gt;No Key&lt;/strong&gt; check box will hide the key altogether.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac6a90057ec6b93f6337bb8a1120915817044824" translate="yes" xml:space="preserve">
          <source>The &lt;strong&gt;Range&lt;/strong&gt; box allows you to effectively zoom horizontally, showing only the data points between a range of Y axis values. The format for this box is &lt;code&gt;[&amp;lt;starting value&amp;gt;:&amp;lt;optional end value&amp;gt;]&lt;/code&gt;. For example, if I want to show only the data points with values between 700 and 800 I can enter &lt;code&gt;[700:800]&lt;/code&gt;. This will produce a graph as below:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1259612763b5ef3a02e9b5cd34f24b6629880188" translate="yes" xml:space="preserve">
          <source>The &lt;strong&gt;Rate&lt;/strong&gt; box allows you to convert all of the time series for the metric to a rate of change value. By default this option is turned off.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f1f6cac5e2131a891082dc173de56c40877c2b1" translate="yes" xml:space="preserve">
          <source>The &lt;strong&gt;To (now)&lt;/strong&gt; link will update the &lt;strong&gt;End&lt;/strong&gt; box to the current time on your system.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e9cb52a17cf12d28119228edb67c9904257a2ae" translate="yes" xml:space="preserve">
          <source>The &lt;strong&gt;WxH&lt;/strong&gt; box alters the dimensions of the graph. Simply enter the &lt;code&gt;&amp;lt;width&amp;gt;x&amp;lt;height&amp;gt;&lt;/code&gt; in pixels such as &lt;code&gt;1024x768&lt;/code&gt; then tab or click in another box to update the graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="396ad0ee0266369a555c9112f80d637e3b33f152" translate="yes" xml:space="preserve">
          <source>The API can accept body content that has been compressed. Make sure to set the &lt;code&gt;Content-Encoding&lt;/code&gt; header to &lt;code&gt;gzip&lt;/code&gt; and pass the binary encoded data over the wire. This is particularly useful for posting data points to the &lt;code&gt;/api/put&lt;/code&gt; endpoint. An example using curl:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b37aab75b0b432b16311642cc9d11cdd0bf686d" translate="yes" xml:space="preserve">
          <source>The API documentation will display requests and responses using the JSON serializer. See plugin documentation for the ways in which serializers alter behavior.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da3c026a62b1758e8ff9d3d724f96476d8d4ee00" translate="yes" xml:space="preserve">
          <source>The Annotation endpoint returns a list of Annotation objects that match the query.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef75ef0644e2f311cb50de378a1b4c4f34c98458" translate="yes" xml:space="preserve">
          <source>The Debian package also creates an &lt;code&gt;opentsdb&lt;/code&gt; user and group for the TSD to run under for increased security. TSD only requires write permission to the temporary and logging directories. If you can't use the default locations, please change them in &lt;code&gt;/etc/opentsdb/opentsdb.conf&lt;/code&gt; and &lt;code&gt;/etc/opentsdb/logback.xml&lt;/code&gt; respectively and apply the proper permissions for the &lt;code&gt;opentsdb&lt;/code&gt; user.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f343c220846787b0d026723a29509dd45a707f3f" translate="yes" xml:space="preserve">
          <source>The Debian package will create the following directories:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbf1a8d58559703099f7cf4f4a2352299e75867d" translate="yes" xml:space="preserve">
          <source>The Graphite style expression to execute. The first parameter of a function must either be another function or a URI formatted &lt;strong&gt;Sub Query&lt;/strong&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8522c8e7da1b2d04cf3786bbe5c95a31c8ee36bf" translate="yes" xml:space="preserve">
          <source>The HTTP API is RESTful in nature but provides alternative access through various overrides since not all clients can adhere to a strict REST protocol. The default data exchange is via JSON though pluggable &lt;code&gt;formatters&lt;/code&gt; may be accessed, via the request, to send or receive data in different formats. Standard HTTP response codes are used for all returned results and errors will be returned as content using the proper format.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ce7665d99f274e32f0e6665fcbbc2f0fcedc1c70" translate="yes" xml:space="preserve">
          <source>The HTTP API is RESTful in nature, meaning it does it's best to adhere to the REST protocol by using HTTP verbs to determine a course of action. For example, a &lt;code&gt;GET&lt;/code&gt; request should only return data, a &lt;code&gt;PUT&lt;/code&gt; or &lt;code&gt;POST&lt;/code&gt; should modify data and &lt;code&gt;DELETE&lt;/code&gt; should remove it. Documentation will reflect what verbs can be used on an endpoint and what they do.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="198f981162920f585a01507e823880f2cc6f77cb" translate="yes" xml:space="preserve">
          <source>The HTTP API provides a plugin interface for serializing and deserializing data in formats other than the default JSON formats. These plugins do not require a plugin name or enable flag in the configuration file. Instead simply drop the plugin in the plugin directory and it will be loaded when the TSD is launched. More than one serializer plugin can be loaded on startup. Serializer plugins may require configuration properties, so check the documentation before using them.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d889dec7f2536c92375ad8a660649edb106f9a69" translate="yes" xml:space="preserve">
          <source>The HTTP specification states that there shouldn't be an association between data passed in a request body and the URI in a &lt;code&gt;GET&lt;/code&gt; request. Thus OpenTSDB's API does not parse body content in &lt;code&gt;GET&lt;/code&gt; requests. You can, however, provide a query string with data and an override for updating data in certain endpoints. But we recommend that you use &lt;code&gt;POST&lt;/code&gt; for anything that writes data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5270e504f2e810bcb80b698fc095abb55c5262a9" translate="yes" xml:space="preserve">
          <source>The HTTP status code</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7577025a92b0d6b1bdf17dbe635969a20e37849" translate="yes" xml:space="preserve">
          <source>The ID of the last RPC sent to HBase. This may be a negative number</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28de56939c5be8b6c2c29ac79d7d0e4736fcbe56" translate="yes" xml:space="preserve">
          <source>The ID of the metric or expression</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="617b4698251bec18b7f179efd810dbbd301d585f" translate="yes" xml:space="preserve">
          <source>The ID of the tree the branch belongs to</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8de18dad3365cdffd7d5536686eae01b82674b95" translate="yes" xml:space="preserve">
          <source>The ID of the tree to pass the TSMeta objects through</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8392de52f57b931ee31ac291b8c8e52406b351db" translate="yes" xml:space="preserve">
          <source>The IP and port of the region server in the format '/&amp;lt;ip&amp;gt;:&amp;lt;port&amp;gt;'</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f3e8260297034cfc5716c50024c506dadd606d6" translate="yes" xml:space="preserve">
          <source>The Initialize hook is called once OpenTSDB has fully read the configuration options, both from the file, and the command line. This is called prior to creating the TSDB object so you can modify the configuration at this time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="984a759ef54ab929b13bf0ecda01787a9e0d4c70" translate="yes" xml:space="preserve">
          <source>The JSON formatter can wrap responses in a JavaScript function using the &lt;code&gt;jsonp&lt;/code&gt; query string parameter. Supply the name of the function you wish to use and the result will be wrapped.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0bcf051686b3b3382b8b699cc819f596a85da49e" translate="yes" xml:space="preserve">
          <source>The JSON serializer allows some query string parameters that modify the output but have no effect on the data retrieved.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0e3b1c232e3b4b7148ded4ec7b9a410da6ac007" translate="yes" xml:space="preserve">
          <source>The JSON specification states that fields can appear in any order, so do not assume the ordering in given examples will be preserved. Arrays may be sorted and if so, this will be documented.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="881322cd2027e93b41d89d3d7f45c4d606e8f739" translate="yes" xml:space="preserve">
          <source>The OpenTSDB compaction process is entirely separate in scope and definition than the HBase idea of compactions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f4cdaf144dcba76d95b0210acaec62f7e68a487" translate="yes" xml:space="preserve">
          <source>The TCP port to listen on</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a483364a5157335203b7f46a486ebfa3f3ff54a2" translate="yes" xml:space="preserve">
          <source>The TCP port to use for accepting connections</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5346efd405f2a70ee5b2ce7422d98363a6899d4c" translate="yes" xml:space="preserve">
          <source>The TSD command launches the OpenTSDB daemon in the foreground so that it can accept connections over TCP and HTTP. If successful, you should see a number of messages then:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="960eda974d484197fd443c785e555e5abba711ea" translate="yes" xml:space="preserve">
          <source>The TSD will attempt to return the correct &lt;strong&gt;Content-Type&lt;/strong&gt; header for the requested file. However the TSD code doesn't support very many formats at this time, just HTML, JSON, Javascript and PNG. Let us know what formats you need or issue a pull request with your patches.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b259ede633a4cd04bab14f38c0ebe68dfa6fe38" translate="yes" xml:space="preserve">
          <source>The TSMeta Summary endpoint returns just the basic information associated with a timeseries including the TSUID, the metric name and tags. The search is run against the same index as the TSMeta query but returns a subset of the data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8770057dfd84bf53b6806f9ee84d569ec3b333fd" translate="yes" xml:space="preserve">
          <source>The TSMeta endpoint returns a list of matching TSMeta objects.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d16e3b34d9874c618f2a683da658d63e7113b1b6" translate="yes" xml:space="preserve">
          <source>The TSMeta object loaded from storage</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26f35648ffc5301a7e5cf9db69d0ddfd76ec7611" translate="yes" xml:space="preserve">
          <source>The TSUIDs endpoint returns a list of TSUIDS that match the query. The search is run against the same index as the TSMeta query but returns a subset of the data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf4125d33f93ff60dcf788458b1936f5b77b9c08" translate="yes" xml:space="preserve">
          <source>The Telnet method of writing is discouraged as it doesn't provide a way of determining which data points failed to write due to formatting or storage errors. Instead use the HTTP API.</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
