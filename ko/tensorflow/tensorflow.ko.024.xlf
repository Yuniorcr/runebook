<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ko" datatype="htmlbody" original="tensorflow">
    <body>
      <group id="tensorflow">
        <trans-unit id="518b59930c6aba89eacb1d11ae58ecb811d616aa" translate="yes" xml:space="preserve">
          <source>Sequence of all sub-modules.</source>
          <target state="translated">모든 서브 모듈의 순서.</target>
        </trans-unit>
        <trans-unit id="77d33f49edae396f86350b207276bb3695b6378b" translate="yes" xml:space="preserve">
          <source>Sequence of trainable variables owned by this module and its submodules.</source>
          <target state="translated">이 모듈 및 해당 서브 모듈이 소유 한 학습 가능한 변수의 시퀀스.</target>
        </trans-unit>
        <trans-unit id="a3f1d94e94b85124fcce6f3e4a558dad963712d8" translate="yes" xml:space="preserve">
          <source>Sequence of variables owned by this module and its submodules.</source>
          <target state="translated">이 모듈과 그 서브 모듈이 소유 한 변수의 순서.</target>
        </trans-unit>
        <trans-unit id="be5344f4e08fccd605ede2af586ad05148fddb02" translate="yes" xml:space="preserve">
          <source>Sequences longer than &lt;code&gt;num_timesteps&lt;/code&gt; are truncated so that they fit the desired length. The position where padding or truncation happens is determined by the arguments &lt;code&gt;padding&lt;/code&gt; and &lt;code&gt;truncating&lt;/code&gt;, respectively.</source>
          <target state="translated">&lt;code&gt;num_timesteps&lt;/code&gt; 보다 긴 시퀀스 는 원하는 길이에 맞게 잘립니다. 패딩 또는 잘림이 발생하는 위치는 각각 &lt;code&gt;padding&lt;/code&gt; 및 &lt;code&gt;truncating&lt;/code&gt; 인수에 의해 결정됩니다 .</target>
        </trans-unit>
        <trans-unit id="fdcc1d0546d49f37f108c4b90e55c5886698ffd0" translate="yes" xml:space="preserve">
          <source>Sequences that are shorter than &lt;code&gt;num_timesteps&lt;/code&gt; are padded with &lt;code&gt;value&lt;/code&gt; at the end.</source>
          <target state="translated">&lt;code&gt;num_timesteps&lt;/code&gt; 보다 짧은 시퀀스 는 끝에 &lt;code&gt;value&lt;/code&gt; 으로 채워집니다 .</target>
        </trans-unit>
        <trans-unit id="df96bb1e937831e2c805016ef1785a1be98f2bd9" translate="yes" xml:space="preserve">
          <source>Sergey Ioffe, Christian Szegedy</source>
          <target state="translated">세르게이 아이 프, 크리스티안 세게 디</target>
        </trans-unit>
        <trans-unit id="cda8b23adee9ccebc4f0ee14eb0856f276cdb138" translate="yes" xml:space="preserve">
          <source>Serialize &lt;code&gt;N&lt;/code&gt;-minibatch &lt;code&gt;SparseTensor&lt;/code&gt; into an &lt;code&gt;[N, 3]&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;N&lt;/code&gt; 미니 배치 &lt;code&gt;SparseTensor&lt;/code&gt; 를 &lt;code&gt;[N, 3]&lt;/code&gt; &lt;code&gt;Tensor&lt;/code&gt; 로 직렬화하십시오 .</target>
        </trans-unit>
        <trans-unit id="fd6e9915c3012a1991bd2cb773131895928dac7e" translate="yes" xml:space="preserve">
          <source>Serialize Keras object into JSON.</source>
          <target state="translated">Keras 객체를 JSON으로 직렬화합니다.</target>
        </trans-unit>
        <trans-unit id="70b742bd7d5132c017e37c97bc7002dd5c15e8e9" translate="yes" xml:space="preserve">
          <source>Serialize a &lt;code&gt;SparseTensor&lt;/code&gt; into a 3-vector (1-D &lt;code&gt;Tensor&lt;/code&gt;) object.</source>
          <target state="translated">&lt;code&gt;SparseTensor&lt;/code&gt; 를 3- 벡터 (1-D &lt;code&gt;Tensor&lt;/code&gt; ) 객체 로 직렬화 합니다.</target>
        </trans-unit>
        <trans-unit id="387bc1747419aab3e8c0cd9fce2a44287ca4f717" translate="yes" xml:space="preserve">
          <source>Serialize a graph along with other Python objects such as &lt;code&gt;QueueRunner&lt;/code&gt;, &lt;code&gt;Variable&lt;/code&gt; into a &lt;code&gt;MetaGraphDef&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;QueueRunner&lt;/code&gt; , &lt;code&gt;Variable&lt;/code&gt; 과 같은 다른 Python 객체와 함께 그래프를 MetaGraphDef 로 &lt;code&gt;MetaGraphDef&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="194f3fc08c9ae161f9584c69b7e614affd39ae79" translate="yes" xml:space="preserve">
          <source>Serialize the ProfileProto to a binary string.</source>
          <target state="translated">ProfileProto를 이진 문자열로 직렬화하십시오.</target>
        </trans-unit>
        <trans-unit id="b223667c02dfe98fd9e504bdcfb350ab3bbf7648" translate="yes" xml:space="preserve">
          <source>Serializes a list as a CSV string or unicode.</source>
          <target state="translated">목록을 CSV 문자열 또는 유니 코드로 직렬화합니다.</target>
        </trans-unit>
        <trans-unit id="b8ffc3d75e2ae6e2c695e965396c6efad99c4b77" translate="yes" xml:space="preserve">
          <source>Serializes the flag.</source>
          <target state="translated">플래그를 직렬화합니다.</target>
        </trans-unit>
        <trans-unit id="aba77dbba5568088bbb6d959635ef17d6b8f9d69" translate="yes" xml:space="preserve">
          <source>Session-like object that handles initialization, recovery and hooks.</source>
          <target state="translated">초기화, 복구 및 후크를 처리하는 세션과 유사한 객체입니다.</target>
        </trans-unit>
        <trans-unit id="48c79c47e20b16985ff763355cf65710d044a709" translate="yes" xml:space="preserve">
          <source>Session-like object that handles initialization, restoring, and hooks.</source>
          <target state="translated">초기화, 복원 및 후크를 처리하는 세션과 유사한 객체입니다.</target>
        </trans-unit>
        <trans-unit id="46893ca773425535bdadeda51dc3f006148b7e4d" translate="yes" xml:space="preserve">
          <source>Set &lt;code&gt;x[:, 3, :] = 0.&lt;/code&gt; and &lt;code&gt;x[:, 5, :] = 0.&lt;/code&gt;</source>
          <target state="translated">집합 &lt;code&gt;x[:, 3, :] = 0.&lt;/code&gt; 및 &lt;code&gt;x[:, 5, :] = 0.&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="ad047cfaa68caa1c3db011a461aefd34950ce606" translate="yes" xml:space="preserve">
          <source>Set a &lt;a href=&quot;strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; as current without &lt;code&gt;with strategy.scope()&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;with strategy.scope()&lt;/code&gt; 없이 &lt;a href=&quot;strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; 를 현재로 설정하십시오 .</target>
        </trans-unit>
        <trans-unit id="77762344b3eeefb7d5d8440477e63198d9fd1bdd" translate="yes" xml:space="preserve">
          <source>Set caching_device for this scope.</source>
          <target state="translated">이 범위에 대해 caching_device를 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="9ccdef39b2ba0c658c6864bb5350b21d1c676c0c" translate="yes" xml:space="preserve">
          <source>Set custom getter for this scope.</source>
          <target state="translated">이 범위에 대한 사용자 지정 게터를 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="25e4c693df73432d9b224bf0a703523782bdae2c" translate="yes" xml:space="preserve">
          <source>Set data type for this scope.</source>
          <target state="translated">이 범위에 대한 데이터 유형을 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="e9291f2652d56e29e2003d31f1c3c02e8bbdbb96" translate="yes" xml:space="preserve">
          <source>Set experimental optimizer options.</source>
          <target state="translated">실험 최적화 옵션을 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="f40acf12c60f73570ce227513e0fe349679d3b21" translate="yes" xml:space="preserve">
          <source>Set if JIT compilation is enabled.</source>
          <target state="translated">JIT 컴파일이 사용 가능한 경우 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="e64d6fb8ece5f461d68de885a93a9cee281d8e3d" translate="yes" xml:space="preserve">
          <source>Set if device placements should be logged.</source>
          <target state="translated">기기 게재 위치를 기록해야하는지 설정합니다.</target>
        </trans-unit>
        <trans-unit id="cb7ca3d2b34b3cf92a9a8da5406cc8920b37367a" translate="yes" xml:space="preserve">
          <source>Set if memory growth should be enabled for a &lt;code&gt;PhysicalDevice&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;PhysicalDevice&lt;/code&gt; 에 대해 메모리 증가가 사용 가능한지 여부를 설정하십시오 .</target>
        </trans-unit>
        <trans-unit id="5bf36098a63c869b0141ff0f43f9ff3ba0844cd1" translate="yes" xml:space="preserve">
          <source>Set if soft device placement is enabled.</source>
          <target state="translated">소프트 장치 배치가 사용 가능한 경우 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="796585419b43d9eceb6738683df615eda205554c" translate="yes" xml:space="preserve">
          <source>Set initializer for this scope.</source>
          <target state="translated">이 범위의 이니셜 라이저를 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="dedc542f22d4594b43eb3efcfe545bbbdbeebc1e" translate="yes" xml:space="preserve">
          <source>Set number of threads used for parallelism between independent operations.</source>
          <target state="translated">독립 작업 간의 병렬 처리에 사용되는 스레드 수를 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="82747f8ffb2d4a288dc813ca2ed7be04331f620b" translate="yes" xml:space="preserve">
          <source>Set number of threads used within an individual op for parallelism.</source>
          <target state="translated">병렬 처리를 위해 개별 op 내에서 사용되는 스레드 수를 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="bf3f0ddac040aaf5b4d59bdb2ed55c27914f9963" translate="yes" xml:space="preserve">
          <source>Set of tools for real-time data augmentation on image data.</source>
          <target state="translated">이미지 데이터에 대한 실시간 데이터 기능 보강을위한 도구 세트.</target>
        </trans-unit>
        <trans-unit id="2c54672e9e7917803b57b36352423d4eeed81f7d" translate="yes" xml:space="preserve">
          <source>Set partitioner for this scope.</source>
          <target state="translated">이 범위에 대한 파티 셔 너를 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="4f4132cf847abb73dff5a8da1552edde55a72bca" translate="yes" xml:space="preserve">
          <source>Set regularizer for this scope.</source>
          <target state="translated">이 범위에 대해 정규화기를 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="785d44923eabbf7703915e72866e368ec759a967" translate="yes" xml:space="preserve">
          <source>Set the list of visible devices.</source>
          <target state="translated">보이는 장치 목록을 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="7fd54c097269449a834528679cdaa3277317db33" translate="yes" xml:space="preserve">
          <source>Set the logical device configuration for a &lt;a href=&quot;physicaldevice&quot;&gt;&lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;physicaldevice&quot;&gt; &lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt; &lt;/a&gt; 의 논리 장치 구성을 설정하십시오 .</target>
        </trans-unit>
        <trans-unit id="cc5bc3aa4792ffb17b488fdab0db17f316de7d54" translate="yes" xml:space="preserve">
          <source>Set the maximum depth of display.</source>
          <target state="translated">최대 표시 깊이를 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="d8385cc2994ca430a788d3ad888514e6d1ab7d8e" translate="yes" xml:space="preserve">
          <source>Sets Keras model and creates summary ops.</source>
          <target state="translated">Keras 모델을 설정하고 요약 작업을 만듭니다.</target>
        </trans-unit>
        <trans-unit id="22d6f7a214f9c2601d906cb380f53cf537bedc95" translate="yes" xml:space="preserve">
          <source>Sets Keras model and writes graph if specified.</source>
          <target state="translated">Keras 모델을 설정하고 지정된 경우 그래프를 씁니다.</target>
        </trans-unit>
        <trans-unit id="9f11cd7e280cc3ae4ab5ec8d73b9cf82e018d551" translate="yes" xml:space="preserve">
          <source>Sets attributes to use later for processing files into a batch.</source>
          <target state="translated">나중에 파일을 일괄 처리 할 때 사용할 속성을 설정합니다.</target>
        </trans-unit>
        <trans-unit id="46a75e77654be7340a64ab7e8fdb3212e4c0f0be" translate="yes" xml:space="preserve">
          <source>Sets entries in &lt;code&gt;x&lt;/code&gt; to zero at random, while scaling the entire tensor.</source>
          <target state="translated">전체 텐서의 크기를 조정하면서 &lt;code&gt;x&lt;/code&gt; 의 항목 을 임의로 0으로 설정합니다 .</target>
        </trans-unit>
        <trans-unit id="53a4ffa2cb16e85275ec3dafa3a60ef0fb2a5bf1" translate="yes" xml:space="preserve">
          <source>Sets stop requested field.</source>
          <target state="translated">중지 요청 필드를 설정합니다.</target>
        </trans-unit>
        <trans-unit id="e30e85ef5b9784a4bc13bb7f4133a675b327d3b3" translate="yes" xml:space="preserve">
          <source>Sets summary recording on or off per the provided boolean value.</source>
          <target state="translated">제공된 부울 값에 따라 요약 기록을 설정하거나 해제합니다.</target>
        </trans-unit>
        <trans-unit id="b01db1185bf6c8610fcd6e68749085f6779cb603" translate="yes" xml:space="preserve">
          <source>Sets the AutoGraph verbosity level.</source>
          <target state="translated">자동 그래프 상세 수준을 설정합니다.</target>
        </trans-unit>
        <trans-unit id="5eee6e4b23edd9d039095db17f400acc13212df1" translate="yes" xml:space="preserve">
          <source>Sets the current thread device policy.</source>
          <target state="translated">현재 스레드 장치 정책을 설정합니다.</target>
        </trans-unit>
        <trans-unit id="69aeb14a87cd9bb1d92bc6975c1a6ff0178ce261" translate="yes" xml:space="preserve">
          <source>Sets the default float type.</source>
          <target state="translated">기본 부동 유형을 설정합니다.</target>
        </trans-unit>
        <trans-unit id="81ee165c08a161961e636c871163a138f3c06d75" translate="yes" xml:space="preserve">
          <source>Sets the default summary step for the current thread.</source>
          <target state="translated">현재 스레드의 기본 요약 단계를 설정합니다.</target>
        </trans-unit>
        <trans-unit id="a6ee376b220695cc14c8651d5944644b5ca38101" translate="yes" xml:space="preserve">
          <source>Sets the global Policy.</source>
          <target state="translated">글로벌 정책을 설정합니다.</target>
        </trans-unit>
        <trans-unit id="1b60e305d9f40ed7048515d95cd6ae85a4a93866" translate="yes" xml:space="preserve">
          <source>Sets the global TensorFlow session.</source>
          <target state="translated">글로벌 TensorFlow 세션을 설정합니다.</target>
        </trans-unit>
        <trans-unit id="87559fecd3f45916d97c6e9fbd6227b2aacf9415" translate="yes" xml:space="preserve">
          <source>Sets the global random seed.</source>
          <target state="translated">글로벌 랜덤 시드를 설정합니다.</target>
        </trans-unit>
        <trans-unit id="34db6c7e3f0d7339e94c79d52f9bdd4a063f0615" translate="yes" xml:space="preserve">
          <source>Sets the global time step of the accumulator.</source>
          <target state="translated">누산기의 전역 시간 단계를 설정합니다.</target>
        </trans-unit>
        <trans-unit id="1203cecd4c168b15b56316a61570bda52858c7e7" translate="yes" xml:space="preserve">
          <source>Sets the graph-level random seed for the default graph.</source>
          <target state="translated">기본 그래프의 그래프 수준 임의 시드를 설정합니다.</target>
        </trans-unit>
        <trans-unit id="f82070f4e6e578084e2bcfce350c2c40eb9811c7" translate="yes" xml:space="preserve">
          <source>Sets the learning phase to a fixed value.</source>
          <target state="translated">학습 단계를 고정 된 값으로 설정합니다.</target>
        </trans-unit>
        <trans-unit id="c36e7ccd12af3e2921d55376aed6a178d9dce246" translate="yes" xml:space="preserve">
          <source>Sets the list of old checkpoint filenames and timestamps.</source>
          <target state="translated">이전 체크 포인트 파일 이름 및 타임 스탬프 목록을 설정합니다.</target>
        </trans-unit>
        <trans-unit id="9f1f7f924a96a25924bd4ffa8d90642ae8bcbc51" translate="yes" xml:space="preserve">
          <source>Sets the list of old checkpoint filenames.</source>
          <target state="translated">이전 체크 포인트 파일 이름 목록을 설정합니다.</target>
        </trans-unit>
        <trans-unit id="dd1ec01930055185c723c2164a4ee961ebe3e731" translate="yes" xml:space="preserve">
          <source>Sets the manual variable initialization flag.</source>
          <target state="translated">수동 변수 초기화 플래그를 설정합니다.</target>
        </trans-unit>
        <trans-unit id="44f6aa83524e8110a15510e482c4f7f69176ba12" translate="yes" xml:space="preserve">
          <source>Sets the parameters of this estimator.</source>
          <target state="translated">이 추정기의 매개 변수를 설정합니다.</target>
        </trans-unit>
        <trans-unit id="56a313eaa4d7219c0e54a35524dd48fd016f708d" translate="yes" xml:space="preserve">
          <source>Sets the threshold for what messages will be logged.</source>
          <target state="translated">기록 할 메시지의 임계 값을 설정합니다.</target>
        </trans-unit>
        <trans-unit id="11ca3ad7417baf7f998046a059f0228174b2ffe2" translate="yes" xml:space="preserve">
          <source>Sets the value of a variable, from a Numpy array.</source>
          <target state="translated">Numpy 배열에서 변수 값을 설정합니다.</target>
        </trans-unit>
        <trans-unit id="c1517ea48001427554cf370385a0726e25cc147e" translate="yes" xml:space="preserve">
          <source>Sets the value of the fuzz factor used in numeric expressions.</source>
          <target state="translated">숫자 표현식에 사용 된 퍼즈 팩터의 값을 설정합니다.</target>
        </trans-unit>
        <trans-unit id="72cf04bee0bc2722d3e620d885646dd816e3c9ab" translate="yes" xml:space="preserve">
          <source>Sets the value of the image data format convention.</source>
          <target state="translated">이미지 데이터 형식 규칙의 값을 설정합니다.</target>
        </trans-unit>
        <trans-unit id="6b6406cb503da1fb9f6e6a4513446339017d45f7" translate="yes" xml:space="preserve">
          <source>Sets the value of the input tensor. Note this copies data in &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="translated">입력 텐서의 값을 설정합니다. 이 &lt;code&gt;value&lt;/code&gt; 데이터를 복사 합니다 .</target>
        </trans-unit>
        <trans-unit id="ca85f21725b3895962c5c41d8ee4badd9566c1a0" translate="yes" xml:space="preserve">
          <source>Sets the values of many tensor variables at once.</source>
          <target state="translated">많은 텐서 변수의 값을 한 번에 설정합니다.</target>
        </trans-unit>
        <trans-unit id="93d4ff12e9b47a77f00869086fc9dea5a82d066f" translate="yes" xml:space="preserve">
          <source>Sets the weights of the layer, from Numpy arrays.</source>
          <target state="translated">Numpy 배열에서 레이어의 가중치를 설정합니다.</target>
        </trans-unit>
        <trans-unit id="0654a1305fc13289ab53b2062558d71378812c24" translate="yes" xml:space="preserve">
          <source>Sets up a Monitored or Hooked Session.</source>
          <target state="translated">모니터 또는 후크 세션을 설정합니다.</target>
        </trans-unit>
        <trans-unit id="5143090d4de7f657548f9137355ea82c80bc3e74" translate="yes" xml:space="preserve">
          <source>Sets up a graph with feeds and fetches for partial run.</source>
          <target state="translated">부분 실행을위한 피드 및 페치가있는 그래프를 설정합니다.</target>
        </trans-unit>
        <trans-unit id="9031702dfbe9a6eaf1e712063391d87f017a1a49" translate="yes" xml:space="preserve">
          <source>Sets vocabulary (and optionally document frequency) data for this layer.</source>
          <target state="translated">이 레이어에 대한 어휘 (및 선택적으로 문서 빈도)를 설정합니다.</target>
        </trans-unit>
        <trans-unit id="e08368a366513eb104acaaf1c716a4d2e93b2ce7" translate="yes" xml:space="preserve">
          <source>Sets whether or not to use GNU style scanning.</source>
          <target state="translated">GNU 스타일 검색 사용 여부를 설정합니다.</target>
        </trans-unit>
        <trans-unit id="e25c325d68a191bf94048b2e56ffc29cdcbdcba8" translate="yes" xml:space="preserve">
          <source>Sets whether to use ResourceVariables for this scope.</source>
          <target state="translated">이 범위에 ResourceVariables를 사용할지 여부를 설정합니다.</target>
        </trans-unit>
        <trans-unit id="f1ac28b31a1edd841df4e792cf901bfb44e32631" translate="yes" xml:space="preserve">
          <source>Settable attribute indicating whether the model should run eagerly.</source>
          <target state="translated">모델을 열심히 실행해야하는지 여부를 나타내는 설정 가능한 속성입니다.</target>
        </trans-unit>
        <trans-unit id="2a4bfb358dca5dac451b5b1d4d36881360437571" translate="yes" xml:space="preserve">
          <source>Setting &lt;code&gt;l = (1 + (q - 1) * z)&lt;/code&gt;, to ensure stability and avoid overflow, the implementation uses</source>
          <target state="translated">설정 &lt;code&gt;l = (1 + (q - 1) * z)&lt;/code&gt; , 안정성과 피 오버플 구현을 보장하기 위해 사용</target>
        </trans-unit>
        <trans-unit id="d38a742a55ebdf3234cb2609807919063a2aed43" translate="yes" xml:space="preserve">
          <source>Setting &lt;code&gt;new_shape&lt;/code&gt; as [2, 3, 6] will be fine as this shape is larger or equal in every dimension compared to the original shape [2, 3, 5].</source>
          <target state="translated">이 모양이 원래 모양 [2, 3, 5]에 비해 모든 차원에서 더 크거나 같으 &lt;code&gt;new_shape&lt;/code&gt; 를 [2, 3, 6]으로 설정하는 것이 좋습니다 .</target>
        </trans-unit>
        <trans-unit id="1f4878a5d627ce0b4cb5d7aa839f9c424a437da6" translate="yes" xml:space="preserve">
          <source>Setting &lt;code&gt;trainable&lt;/code&gt; on an model containing other layers will recursively set the &lt;code&gt;trainable&lt;/code&gt; value of all inner layers.</source>
          <target state="translated">설정 &lt;code&gt;trainable&lt;/code&gt; 다른 층을 포함하는 모델은 반복적으로 설정할 것이다 &lt;code&gt;trainable&lt;/code&gt; 모든 내층의 값.</target>
        </trans-unit>
        <trans-unit id="55b7e50e9668e45dcf8255f80ca6fadf2582adc0" translate="yes" xml:space="preserve">
          <source>Setting environment variable depends on the platform. For example, on Linux, it can be done as follows (&lt;code&gt;$&lt;/code&gt; is the shell prompt):</source>
          <target state="translated">환경 변수 설정은 플랫폼에 따라 다릅니다. 예를 들어, Linux에서 다음과 같이 수행 할 수 있습니다 ( &lt;code&gt;$&lt;/code&gt; 는 쉘 프롬프트입니다).</target>
        </trans-unit>
        <trans-unit id="98ad210a1d424d551560599f71277ae77def8cb8" translate="yes" xml:space="preserve">
          <source>Settings for warm-starting in &lt;code&gt;tf.estimator.Estimators&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;tf.estimator.Estimators&lt;/code&gt; 의 웜 스타트 설정 .</target>
        </trans-unit>
        <trans-unit id="a98628dac38a3430897e254ca10765d67ac37f0e" translate="yes" xml:space="preserve">
          <source>Shai Shalev-Shwartz, Tong Zhang. 2012</source>
          <target state="translated">Shai Shalev-Shwartz, Tong Zhang. 2012 년</target>
        </trans-unit>
        <trans-unit id="03b27b03a5a8c1c0c654f82f78f573cfbaed2f7f" translate="yes" xml:space="preserve">
          <source>Shannon entropy in nats.</source>
          <target state="translated">nats의 Shannon 엔트로피.</target>
        </trans-unit>
        <trans-unit id="009311e40b8a060c5eba67f1263146e04b4c6942" translate="yes" xml:space="preserve">
          <source>Shape &lt;code&gt;[B1,...,Bb, N]&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; of same &lt;code&gt;dtype&lt;/code&gt; as &lt;code&gt;self&lt;/code&gt;.</source>
          <target state="translated">형상 &lt;code&gt;[B1,...,Bb, N]&lt;/code&gt; &lt;code&gt;Tensor&lt;/code&gt; 똑같은 &lt;code&gt;dtype&lt;/code&gt; 같은 &lt;code&gt;self&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f5f650ce75b03189c59505b001df917ebf24c8e8" translate="yes" xml:space="preserve">
          <source>Shape &lt;code&gt;[B1,...,Bb]&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; of same &lt;code&gt;dtype&lt;/code&gt; as &lt;code&gt;self&lt;/code&gt;.</source>
          <target state="translated">형상 &lt;code&gt;[B1,...,Bb]&lt;/code&gt; &lt;code&gt;Tensor&lt;/code&gt; 똑같은 &lt;code&gt;dtype&lt;/code&gt; 같은 &lt;code&gt;self&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b1001d9c716df0dd002a90e5c7fd8de460514793" translate="yes" xml:space="preserve">
          <source>Shape compatibility</source>
          <target state="translated">모양 호환성</target>
        </trans-unit>
        <trans-unit id="ac03ca13af059aaa395f5255f16fd2fd96c23ad5" translate="yes" xml:space="preserve">
          <source>Shape of a single sample from a single batch as a 1-D int32 &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="translated">1-D int32 &lt;code&gt;Tensor&lt;/code&gt; 로 단일 배치에서 단일 샘플의 모양 .</target>
        </trans-unit>
        <trans-unit id="d7a27ac567178ca13d2c09207cad38c1e0d0b931" translate="yes" xml:space="preserve">
          <source>Shape of a single sample from a single batch as a &lt;code&gt;TensorShape&lt;/code&gt;.</source>
          <target state="translated">단일 배치에서 단일 샘플의 모양으로 &lt;code&gt;TensorShape&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5f99bcf8393473453e114ff85b09d70b2a53cf20" translate="yes" xml:space="preserve">
          <source>Shape of a single sample from a single event index as a 1-D &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="translated">단일 이벤트 인덱스에서 1-D &lt;code&gt;Tensor&lt;/code&gt; 로 단일 샘플의 모양 .</target>
        </trans-unit>
        <trans-unit id="7161805a9dac7fd0ebaae5bd71a7d234bdc85012" translate="yes" xml:space="preserve">
          <source>Shape of a single sample from a single event index as a &lt;code&gt;TensorShape&lt;/code&gt;.</source>
          <target state="translated">단일 이벤트 인덱스의 단일 샘플 모양으로 &lt;code&gt;TensorShape&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="6483c91eba66015ed4ab8776064d3eff5ab14061" translate="yes" xml:space="preserve">
          <source>Shape of batch dimensions of this operator, determined at runtime.</source>
          <target state="translated">런타임시 결정되는이 연산자의 배치 차원 모양.</target>
        </trans-unit>
        <trans-unit id="86345db94ce3a243e33554a24858c2c6ec60dcbd" translate="yes" xml:space="preserve">
          <source>Shape of the block dimensions of &lt;code&gt;self.spectrum&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;self.spectrum&lt;/code&gt; 의 블록 치수 모양 .</target>
        </trans-unit>
        <trans-unit id="b7771a110dd20b18041b5dd6f9cc30e1bbacace1" translate="yes" xml:space="preserve">
          <source>Shape of this &lt;code&gt;LinearOperator&lt;/code&gt;, determined at runtime.</source>
          <target state="translated">런타임에 결정되는 이 &lt;code&gt;LinearOperator&lt;/code&gt; 의 모양입니다 .</target>
        </trans-unit>
        <trans-unit id="b1985e387405e4d4afb40d5dac9b2656f5d6f770" translate="yes" xml:space="preserve">
          <source>Shapes</source>
          <target state="translated">Shapes</target>
        </trans-unit>
        <trans-unit id="8430380665211689f2767ccff906ec9a4099f769" translate="yes" xml:space="preserve">
          <source>Shapes of parameters given the desired shape of a call to &lt;code&gt;sample()&lt;/code&gt;.</source>
          <target state="translated">파라미터의 형상에 대한 호출의 원하는 형상을 주어진 &lt;code&gt;sample()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="fee9aae8e9097ba138d796c2823f16ecbde75b1b" translate="yes" xml:space="preserve">
          <source>Shards &lt;code&gt;computation&lt;/code&gt; along the batch dimension for parallel execution.</source>
          <target state="translated">병렬 실행을위한 배치 차원에 따른 샤드 &lt;code&gt;computation&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e4bb91eacfcfd178011a31a6c6822d94c8087f62" translate="yes" xml:space="preserve">
          <source>Shards &lt;code&gt;computation&lt;/code&gt; for parallel execution.</source>
          <target state="translated">병렬 실행을위한 샤드 &lt;code&gt;computation&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="debe55a1300ea7ca4f227b9dd635acc8ca3e4415" translate="yes" xml:space="preserve">
          <source>Sharing a variable by capturing a scope and setting reuse:</source>
          <target state="translated">범위를 캡처하고 재사용을 설정하여 변수 공유</target>
        </trans-unit>
        <trans-unit id="dd4356118ce17af4ac61d8e18b734f9c851e6a93" translate="yes" xml:space="preserve">
          <source>Shift the zero-frequency component to the center of the spectrum.</source>
          <target state="translated">영 주파수 성분을 스펙트럼 중심으로 이동합니다.</target>
        </trans-unit>
        <trans-unit id="fc7f2ac5dda0cc4b1661846c36ed51a2eb0bf538" translate="yes" xml:space="preserve">
          <source>Should be called by the same thread which called &lt;code&gt;start()&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;start()&lt;/code&gt; 라는 동일한 스레드에서 호출해야합니다 .</target>
        </trans-unit>
        <trans-unit id="b13ab1f9184cdb80dd3b3d41d39fff0fa20bca5c" translate="yes" xml:space="preserve">
          <source>Show operation time and memory consumptions.</source>
          <target state="translated">작동 시간 및 메모리 소비를 보여줍니다.</target>
        </trans-unit>
        <trans-unit id="6565ab72f751d6e2a51ac78e2d5fc643343301f7" translate="yes" xml:space="preserve">
          <source>Shows the directory name where evaluation metrics are dumped.</source>
          <target state="translated">평가 지표가 덤프되는 디렉토리 이름을 표시합니다.</target>
        </trans-unit>
        <trans-unit id="9de79067e565fc76cd3de53fce4b140bf7336fc3" translate="yes" xml:space="preserve">
          <source>Shuffles and repeats a Dataset, reshuffling with each repetition. (deprecated)</source>
          <target state="translated">반복 할 때마다 데이터 세트를 섞고 반복합니다. (더 이상 사용되지 않음)</target>
        </trans-unit>
        <trans-unit id="d4f00c7e0891d5c31b2c8a6e17b656882662f089" translate="yes" xml:space="preserve">
          <source>Shuts down a running a distributed TPU system.</source>
          <target state="translated">실행중인 분산 TPU 시스템을 종료합니다.</target>
        </trans-unit>
        <trans-unit id="fc806c70d1611220fd7aeabffc0d3443c8d9ead0" translate="yes" xml:space="preserve">
          <source>Shuts down the TPU devices.</source>
          <target state="translated">TPU 장치를 종료합니다.</target>
        </trans-unit>
        <trans-unit id="653f9237345e8d0600d0ec6769702eee8a0052a9" translate="yes" xml:space="preserve">
          <source>Sigmoid activation function.</source>
          <target state="translated">S 자형 활성화 기능.</target>
        </trans-unit>
        <trans-unit id="8a2ebe28a5b913a93292c6f412f0d6d3f3ef1e4c" translate="yes" xml:space="preserve">
          <source>Sigmoid is equivalent to a 2-element Softmax, where the second element is assumed to be zero.</source>
          <target state="translated">S 자형은 2- 요소 Softmax와 동일하며, 두 번째 요소는 0으로 가정됩니다.</target>
        </trans-unit>
        <trans-unit id="69de1c17f59d07d87a7f26dd959bbed0c9e2517e" translate="yes" xml:space="preserve">
          <source>Signal processing operations.</source>
          <target state="translated">신호 처리 작업.</target>
        </trans-unit>
        <trans-unit id="60a6d3dc2068bbd0e202a705df4076defbac1a1c" translate="yes" xml:space="preserve">
          <source>Signature constants for SavedModel save and restore operations.</source>
          <target state="translated">SavedModel 저장 및 복원 조작에 대한 시그니처 상수.</target>
        </trans-unit>
        <trans-unit id="d756df7ce4459b133ef8b55a21a899c0ad61fbc4" translate="yes" xml:space="preserve">
          <source>SignatureDef utility functions.</source>
          <target state="translated">SignatureDef 유틸리티 기능.</target>
        </trans-unit>
        <trans-unit id="7dd975d808d1764b7c7f8ac983bc35a1fa661a03" translate="yes" xml:space="preserve">
          <source>Signatures are available in objects returned by &lt;a href=&quot;load&quot;&gt;&lt;code&gt;tf.saved_model.load&lt;/code&gt;&lt;/a&gt; as a &lt;code&gt;.signatures&lt;/code&gt; attribute. This is a reserved attribute: &lt;a href=&quot;save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt; on an object with a custom &lt;code&gt;.signatures&lt;/code&gt; attribute will raise an exception.</source>
          <target state="translated">서명은 &lt;a href=&quot;load&quot;&gt; &lt;code&gt;tf.saved_model.load&lt;/code&gt; &lt;/a&gt; 에서 &lt;code&gt;.signatures&lt;/code&gt; 속성 으로 반환 한 객체에서 사용할 수 있습니다 . 이것은 예약 된 속성입니다 : &lt;a href=&quot;save&quot;&gt; &lt;code&gt;tf.saved_model.save&lt;/code&gt; &lt;/a&gt; 속성 을 가진 객체에 &lt;code&gt;.signatures&lt;/code&gt; 는 예외를 발생시킵니다.</target>
        </trans-unit>
        <trans-unit id="dab261f335187b67b677777cdba885fb48cdddc8" translate="yes" xml:space="preserve">
          <source>Signatures associated with the SavedModel are available as functions:</source>
          <target state="translated">SavedModel과 연관된 서명은 함수로 사용 가능합니다.</target>
        </trans-unit>
        <trans-unit id="624f9b9b51fcc8c2cb3e5e2ecd0130f80784494b" translate="yes" xml:space="preserve">
          <source>Similar to &lt;code&gt;numpy.assert_allclose&lt;/code&gt;, except tolerance depends on data type. This is due to the fact that &lt;code&gt;TensorFlow&lt;/code&gt; is often used with &lt;code&gt;32bit&lt;/code&gt;, &lt;code&gt;64bit&lt;/code&gt;, and even &lt;code&gt;16bit&lt;/code&gt; data.</source>
          <target state="translated">&lt;code&gt;numpy.assert_allclose&lt;/code&gt; 와 유사 하지만 공차는 데이터 유형에 따라 다릅니다. 이는 &lt;code&gt;TensorFlow&lt;/code&gt; 가 종종 &lt;code&gt;32bit&lt;/code&gt; , &lt;code&gt;64bit&lt;/code&gt; 및 &lt;code&gt;16bit&lt;/code&gt; 데이터 와 함께 사용 되기 때문 입니다.</target>
        </trans-unit>
        <trans-unit id="c87d10048c4cbad8372cf7d364561c0e72d785c8" translate="yes" xml:space="preserve">
          <source>Similar to &lt;code&gt;parse_example&lt;/code&gt;, except:</source>
          <target state="translated">다음을 제외하고 &lt;code&gt;parse_example&lt;/code&gt; 과 유사합니다 .</target>
        </trans-unit>
        <trans-unit id="4de3634c50466157902a321a02b640e31be54ca3" translate="yes" xml:space="preserve">
          <source>Similar to AdamOptimizer, the epsilon is added for numerical stability (especially to get rid of division by zero when v_t = 0).</source>
          <target state="translated">AdamOptimizer와 유사하게, 엡실론은 수치 안정성을 위해 추가됩니다 (특히 v_t = 0 일 때 0으로 나누기 위해).</target>
        </trans-unit>
        <trans-unit id="e09d8883f82a81272daabf33772fad0fb0c8817e" translate="yes" xml:space="preserve">
          <source>Similar to the unidirectional case above (rnn) but takes input and builds independent forward and backward RNNs with the final forward and backward outputs depth-concatenated, such that the output will have the format [time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of forward and backward cell must match. The initial state for both directions is zero by default (but can be set optionally) and no intermediate states are ever returned -- the network is fully unrolled for the given (passed in) length(s) of the sequence(s) or completely unrolled if length(s) is not given.</source>
          <target state="translated">위의 단방향 사례 (rnn)와 유사하지만 입력을 가져 와서 최종 정방향 및 역방향 출력 깊이와 연결된 독립적 인 정방향 및 역방향 RNN을 생성하여 출력의 형식은 [시간] [배치] [cell_fw.output_size + cell_bw .output_size]. 정방향 및 역방향 셀의 input_size가 일치해야합니다. 양방향의 초기 상태는 기본적으로 0이지만 (선택적으로 설정 가능) 중간 상태는 반환되지 않습니다. 시퀀스의 지정된 길이 (또는 길이) 동안 네트워크가 완전히 언 롤링됩니다. 길이가 주어지지 않으면 풀린다.</target>
        </trans-unit>
        <trans-unit id="96173f43f9d1e4fc459561cb67357e147eabfef0" translate="yes" xml:space="preserve">
          <source>Similarly to initialize the whole line as keys and the line number as values.</source>
          <target state="translated">마찬가지로 전체 줄을 키로 초기화하고 줄 번호를 값으로 초기화합니다.</target>
        </trans-unit>
        <trans-unit id="41e75f4217ba1a24afbe7a28f6325ea930c061df" translate="yes" xml:space="preserve">
          <source>Similarly, a sequence of &lt;code&gt;with_space_to_batch&lt;/code&gt; operations with identical (not uniformly 1) &lt;code&gt;dilation_rate&lt;/code&gt; parameters, &quot;SAME&quot; padding, and odd filter dimensions</source>
          <target state="translated">마찬가지로, 동일하거나 균일하지 않은 &lt;code&gt;dilation_rate&lt;/code&gt; 매개 변수, &quot;SAME&quot;패딩 및 홀수 필터 크기를 갖는 일련의 &lt;code&gt;with_space_to_batch&lt;/code&gt; 연산</target>
        </trans-unit>
        <trans-unit id="054ffb3d11e09da3aee30ad29c8d4f62a44cd16c" translate="yes" xml:space="preserve">
          <source>Similarly, for the following input of shape &lt;code&gt;[1 2 2 4]&lt;/code&gt;, and a block size of 2:</source>
          <target state="translated">유사하게, 다음 형태의 입력 &lt;code&gt;[1 2 2 4]&lt;/code&gt; 및 블록 크기 2에 대해 :</target>
        </trans-unit>
        <trans-unit id="7109f8585ba165d9ea6569c12e4bf258fbfc4419" translate="yes" xml:space="preserve">
          <source>Similarly, for the following input of shape &lt;code&gt;[1 4 4 1]&lt;/code&gt;, and a block size of 2:</source>
          <target state="translated">유사하게, 다음 형태의 입력 &lt;code&gt;[1 4 4 1]&lt;/code&gt; 및 블록 크기 2에 대해 :</target>
        </trans-unit>
        <trans-unit id="27aaa10f901b0745041dcdfe2c1fa5c22a8f5591" translate="yes" xml:space="preserve">
          <source>Similarly, if the regularizer is &lt;code&gt;None&lt;/code&gt; (the default), the default regularizer passed in the variable scope will be used (if that is &lt;code&gt;None&lt;/code&gt; too, then by default no regularization is performed).</source>
          <target state="translated">마찬가지로 정규화 기가 &lt;code&gt;None&lt;/code&gt; (기본값) 인 경우 변수 범위에 전달 된 기본 정규화 기가 사용됩니다 ( &lt;code&gt;None&lt;/code&gt; 경우 기본적으로 정규화가 수행되지 않음).</target>
        </trans-unit>
        <trans-unit id="db81e254d32ebfc457fd518e82be835eabb42976" translate="yes" xml:space="preserve">
          <source>Similarly, we raise an exception when trying to get a variable that does not exist in reuse mode.</source>
          <target state="translated">마찬가지로 재사용 모드에 존재하지 않는 변수를 얻으려고 할 때 예외가 발생합니다.</target>
        </trans-unit>
        <trans-unit id="6b19adeccf3b4fca9b692f573cead18c7b6a60bb" translate="yes" xml:space="preserve">
          <source>Simpilfy creating loss and metrics for the train and test loop in Eager execution.</source>
          <target state="translated">Eager 실행에서 기차 및 테스트 루프에 대한 손실 및 메트릭 생성을 단순화합니다.</target>
        </trans-unit>
        <trans-unit id="2b623fadddbd419adf01bb1b94c77999b5aa2c2b" translate="yes" xml:space="preserve">
          <source>Simple example of how to create a new variable:</source>
          <target state="translated">새 변수를 만드는 방법에 대한 간단한 예 :</target>
        </trans-unit>
        <trans-unit id="2a5da838ff3165a207fd299af72846704817596b" translate="yes" xml:space="preserve">
          <source>Simple example of how to reenter a premade variable scope safely:</source>
          <target state="translated">미리 만들어진 변수 범위를 안전하게 다시 입력하는 방법에 대한 간단한 예 :</target>
        </trans-unit>
        <trans-unit id="cab3d3babf94443c799382f4fccfd16541936062" translate="yes" xml:space="preserve">
          <source>Simple implementation of ClusterResolver that accepts a ClusterSpec.</source>
          <target state="translated">ClusterSpec을 받아들이는 ClusterResolver의 간단한 구현.</target>
        </trans-unit>
        <trans-unit id="e6111f09e0dac798ce37b958000c7772f9a4fc90" translate="yes" xml:space="preserve">
          <source>Simple indexing into a matrix:</source>
          <target state="translated">행렬로 간단한 색인 생성 :</target>
        </trans-unit>
        <trans-unit id="d6ae8276e39b497fd17f4088846d89e28bba5559" translate="yes" xml:space="preserve">
          <source>Simplify writing model_fn and to make model_fn more configurable for Estimator.</source>
          <target state="translated">model_fn 작성을 단순화하고 Estimator에 대해 model_fn을 구성 할 수있게하십시오.</target>
        </trans-unit>
        <trans-unit id="a8315af54a6663133741824c0be422ac2397d08e" translate="yes" xml:space="preserve">
          <source>Since &lt;a href=&quot;../keras/model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; objects are also Trackable, this function can be used to export Keras models. For example, exporting with a signature specified:</source>
          <target state="translated">이후 &lt;a href=&quot;../keras/model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; 의&lt;/a&gt; 물체도 추적 가능하며,이 기능은 Keras 모델을 수출하는 데 사용할 수 있습니다. 예를 들어, 지정된 서명으로 내보내기 :</target>
        </trans-unit>
        <trans-unit id="985151447a1d9d253acc12d655dc23bfee7a7e23" translate="yes" xml:space="preserve">
          <source>Since &lt;a href=&quot;fill&quot;&gt;&lt;code&gt;tf.fill&lt;/code&gt;&lt;/a&gt; does not embed the value, it can produce dynamically sized outputs.</source>
          <target state="translated">이후 &lt;a href=&quot;fill&quot;&gt; &lt;code&gt;tf.fill&lt;/code&gt; 이&lt;/a&gt; 값을 포함하지 않는, 동적으로 크기 출력을 생성 할 수있다.</target>
        </trans-unit>
        <trans-unit id="4e62738c37806ffe366436c3da479daa7dfcc7ff" translate="yes" xml:space="preserve">
          <source>Since RepaparameterizationType instances are constant static global instances, equality checks if two instances' id() values are equal.</source>
          <target state="translated">RepaparameterizationType 인스턴스는 상수 정적 전역 인스턴스이므로 등식은 두 인스턴스의 id () 값이 같은지 확인합니다.</target>
        </trans-unit>
        <trans-unit id="4c5ffebed7cf9ec80c72712271fcad69d30db523" translate="yes" xml:space="preserve">
          <source>Since it is only traced once, variables and state may be created inside the function and owned by the function wrapper object.</source>
          <target state="translated">한 번만 추적되므로 변수와 상태는 함수 내부에서 만들어지고 함수 래퍼 객체가 소유 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="0ba257e987a6ec0d23383c4f65c48c3f5a7e84a6" translate="yes" xml:space="preserve">
          <source>Since python &amp;gt;= 3.5 the @ operator is supported (see &lt;a href=&quot;https://www.python.org/dev/peps/pep-0465/&quot;&gt;PEP 465&lt;/a&gt;). In TensorFlow, it simply calls the &lt;a href=&quot;../../linalg/matmul&quot;&gt;&lt;code&gt;tf.matmul()&lt;/code&gt;&lt;/a&gt; function, so the following lines are equivalent:</source>
          <target state="translated">python&amp;gt; = 3.5이므로 @ 연산자가 지원됩니다 ( &lt;a href=&quot;https://www.python.org/dev/peps/pep-0465/&quot;&gt;PEP 465&lt;/a&gt; 참조 ). TensorFlow에서는 단순히 &lt;a href=&quot;../../linalg/matmul&quot;&gt; &lt;code&gt;tf.matmul()&lt;/code&gt; &lt;/a&gt; 함수 를 호출 하므로 다음 행은 동일합니다.</target>
        </trans-unit>
        <trans-unit id="b99374751d687608923563ea3ad3d8ae48b9e59a" translate="yes" xml:space="preserve">
          <source>Since python &amp;gt;= 3.5 the @ operator is supported (see &lt;a href=&quot;https://www.python.org/dev/peps/pep-0465/&quot;&gt;PEP 465&lt;/a&gt;). In TensorFlow, it simply calls the &lt;a href=&quot;linalg/matmul&quot;&gt;&lt;code&gt;tf.matmul()&lt;/code&gt;&lt;/a&gt; function, so the following lines are equivalent:</source>
          <target state="translated">python&amp;gt; = 3.5이므로 @ 연산자가 지원됩니다 ( &lt;a href=&quot;https://www.python.org/dev/peps/pep-0465/&quot;&gt;PEP 465&lt;/a&gt; 참조 ). TensorFlow에서는 단순히 &lt;a href=&quot;linalg/matmul&quot;&gt; &lt;code&gt;tf.matmul()&lt;/code&gt; &lt;/a&gt; 함수 를 호출 하므로 다음 행은 동일합니다.</target>
        </trans-unit>
        <trans-unit id="33c43d8e2c8435ba1c70dd9f1c5833ddcd430b11" translate="yes" xml:space="preserve">
          <source>Since python &amp;gt;= 3.5 the @ operator is supported (see &lt;a href=&quot;https://www.python.org/dev/peps/pep-0465/&quot;&gt;PEP 465&lt;/a&gt;). In TensorFlow, it simply calls the &lt;a href=&quot;matmul&quot;&gt;&lt;code&gt;tf.matmul()&lt;/code&gt;&lt;/a&gt; function, so the following lines are equivalent:</source>
          <target state="translated">python&amp;gt; = 3.5이므로 @ 연산자가 지원됩니다 ( &lt;a href=&quot;https://www.python.org/dev/peps/pep-0465/&quot;&gt;PEP 465&lt;/a&gt; 참조 ). TensorFlow에서는 단순히 &lt;a href=&quot;matmul&quot;&gt; &lt;code&gt;tf.matmul()&lt;/code&gt; &lt;/a&gt; 함수 를 호출 하므로 다음 행은 동일합니다.</target>
        </trans-unit>
        <trans-unit id="9c24586d747ff13c9898915f9c6e35375c327247" translate="yes" xml:space="preserve">
          <source>Since the DFT of a real signal is Hermitian-symmetric, &lt;code&gt;RFFT2D&lt;/code&gt; only returns the &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; unique components of the FFT for the inner-most dimension of &lt;code&gt;output&lt;/code&gt;: the zero-frequency term, followed by the &lt;code&gt;fft_length / 2&lt;/code&gt; positive-frequency terms.</source>
          <target state="translated">실제 신호의 DFT는 Hermitian-symmetric이므로 &lt;code&gt;RFFT2D&lt;/code&gt; 는 &lt;code&gt;output&lt;/code&gt; 가장 안쪽 차원에 대해 FFT 의 &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; 고유 구성 요소 만 반환합니다 . 제로 주파수 항과 &lt;code&gt;fft_length / 2&lt;/code&gt; 양의 주파수 자귀.</target>
        </trans-unit>
        <trans-unit id="9c097ba51429f68058eff266dfe6cc4cfcb58b9a" translate="yes" xml:space="preserve">
          <source>Since the DFT of a real signal is Hermitian-symmetric, &lt;code&gt;RFFT3D&lt;/code&gt; only returns the &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; unique components of the FFT for the inner-most dimension of &lt;code&gt;output&lt;/code&gt;: the zero-frequency term, followed by the &lt;code&gt;fft_length / 2&lt;/code&gt; positive-frequency terms.</source>
          <target state="translated">실제 신호의 DFT는 에르 미트 대칭이므로 &lt;code&gt;RFFT3D&lt;/code&gt; 는 오직 리턴 &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; 의 가장 안쪽 차원에 대한 FFT의 고유 성분 &lt;code&gt;output&lt;/code&gt; 제로 주파수 용어는 다음 : &lt;code&gt;fft_length / 2&lt;/code&gt; 포지티브 주파수 자귀.</target>
        </trans-unit>
        <trans-unit id="f1e248daa91294df97613a89bf8b58086208a4f1" translate="yes" xml:space="preserve">
          <source>Since the DFT of a real signal is Hermitian-symmetric, &lt;code&gt;RFFT&lt;/code&gt; only returns the &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; unique components of the FFT: the zero-frequency term, followed by the &lt;code&gt;fft_length / 2&lt;/code&gt; positive-frequency terms.</source>
          <target state="translated">실제 신호의 DFT는 Hermitian-symmetric이므로 &lt;code&gt;RFFT&lt;/code&gt; 는 FFT 의 &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; 고유 구성 요소, 즉 제로 주파수 항과 &lt;code&gt;fft_length / 2&lt;/code&gt; 양의 주파수 항만 반환합니다 .</target>
        </trans-unit>
        <trans-unit id="c67d048cd6c2913cd8d994cb1ded2c7adf3a8ba3" translate="yes" xml:space="preserve">
          <source>Since the function takes numpy arrays, you cannot take gradients through a numpy_function. If you require something that is differentiable, please consider using tf.py_function.</source>
          <target state="translated">함수는 numpy 배열을 사용하므로 numpy_function을 통해 그라디언트를 수행 할 수 없습니다. 차별화가 필요한 것이 있으면 tf.py_function을 사용해보십시오.</target>
        </trans-unit>
        <trans-unit id="e9a68f1c294406fa4a8ecaa3e3461419d04f7f5b" translate="yes" xml:space="preserve">
          <source>Single TensorSpec or nested structure of TensorSpec objects, describing how the layer would transform the provided input.</source>
          <target state="translated">레이어가 제공된 입력을 변환하는 방법을 설명하는 단일 TensorSpec 또는 TensorSpec 객체의 중첩 구조.</target>
        </trans-unit>
        <trans-unit id="88fd65a1c7507102379f1c644b7234548a37e96b" translate="yes" xml:space="preserve">
          <source>Single or list of &lt;a href=&quot;tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; which &lt;code&gt;func&lt;/code&gt; computes.</source>
          <target state="translated">&lt;code&gt;func&lt;/code&gt; 이 계산 하는 &lt;a href=&quot;tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; 의&lt;/a&gt; 단일 또는 목록 .</target>
        </trans-unit>
        <trans-unit id="bc31f17d3be434d3691746b3f80ea4176a1c5e98" translate="yes" xml:space="preserve">
          <source>Single-input usage:</source>
          <target state="translated">단일 입력 사용법 :</target>
        </trans-unit>
        <trans-unit id="4fc818dae3875a35fb808f116b7d884f4e5a68ca" translate="yes" xml:space="preserve">
          <source>Size entries in the specified shapes are checked against other entries by their &lt;strong&gt;hash&lt;/strong&gt;, except: - a size entry is interpreted as an explicit size if it can be parsed as an integer primitive. - a size entry is interpreted as &lt;em&gt;any&lt;/em&gt; size if it is None or '.'.</source>
          <target state="translated">지정된 모양의 크기 항목은 다음 항목을 제외하고 &lt;strong&gt;해시&lt;/strong&gt; 를 통해 다른 항목과 비교하여 검사됩니다 .-크기 항목이 정수 기본 형식으로 구문 분석 될 수있는 경우 명시 적 크기로 해석됩니다. -크기 항목 이 None 또는 '.'인 경우 &lt;em&gt;모든&lt;/em&gt; 크기 로 해석됩니다 .</target>
        </trans-unit>
        <trans-unit id="c2e425277c86cf87b08f16d6e85336a78993742d" translate="yes" xml:space="preserve">
          <source>Size of the last dimension of the logits &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="translated">로짓 &lt;code&gt;Tensor&lt;/code&gt; 의 마지막 차원의 크기입니다 .</target>
        </trans-unit>
        <trans-unit id="a008fa4b1b36f74860c2b0319ada954a82d0026f" translate="yes" xml:space="preserve">
          <source>Skip the data if it is &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;None&lt;/code&gt; 인 경우 데이터를 건너 뜁니다 .</target>
        </trans-unit>
        <trans-unit id="b5ea08df6d74ffe12d371d56e3535c8ca96d4047" translate="yes" xml:space="preserve">
          <source>Skip this test.</source>
          <target state="translated">이 테스트를 건너 뛰십시오.</target>
        </trans-unit>
        <trans-unit id="bc3578c5f747f70325a17b79e89d9cd6ce54d02b" translate="yes" xml:space="preserve">
          <source>Slice a &lt;code&gt;SparseTensor&lt;/code&gt; based on the &lt;code&gt;start&lt;/code&gt; and `size.</source>
          <target state="translated">&lt;code&gt;start&lt;/code&gt; 과 크기 에 따라 &lt;code&gt;SparseTensor&lt;/code&gt; 를 슬라이스하십시오 .</target>
        </trans-unit>
        <trans-unit id="ee71d16608227222a38300f09a56709ba50fac40" translate="yes" xml:space="preserve">
          <source>Slice indexing into a matrix:</source>
          <target state="translated">인덱스를 행렬로 슬라이스 :</target>
        </trans-unit>
        <trans-unit id="a3f2f860e7230e19be9c90ddaafa179acf158e07" translate="yes" xml:space="preserve">
          <source>Slices a shape &lt;code&gt;size&lt;/code&gt; portion out of &lt;code&gt;value&lt;/code&gt; at a uniformly chosen offset. Requires &lt;code&gt;value.shape &amp;gt;= size&lt;/code&gt;.</source>
          <target state="translated">균일하게 선택된 오프셋에서 &lt;code&gt;value&lt;/code&gt; 의 모양 &lt;code&gt;size&lt;/code&gt; 부분을 잘라 냅니다 . &lt;code&gt;value.shape &amp;gt;= size&lt;/code&gt; 필요합니다 .</target>
        </trans-unit>
        <trans-unit id="dde09794c40b9ff8d5edc9bca08c6f0b4982af49" translate="yes" xml:space="preserve">
          <source>Slides a window of size &lt;code&gt;frame_length&lt;/code&gt; over &lt;code&gt;signal&lt;/code&gt;'s &lt;code&gt;axis&lt;/code&gt; dimension with a stride of &lt;code&gt;frame_step&lt;/code&gt;, replacing the &lt;code&gt;axis&lt;/code&gt; dimension with &lt;code&gt;[frames, frame_length]&lt;/code&gt; frames.</source>
          <target state="translated">프레젠테이션 크기의 창 &lt;code&gt;frame_length&lt;/code&gt; 위에 &lt;code&gt;signal&lt;/code&gt; 의 &lt;code&gt;axis&lt;/code&gt; 의 스트라이드 차원 &lt;code&gt;frame_step&lt;/code&gt; 교체하는, &lt;code&gt;axis&lt;/code&gt; 과 사이즈 &lt;code&gt;[frames, frame_length]&lt;/code&gt; 프레임.</target>
        </trans-unit>
        <trans-unit id="0c1a16e17517d5db584e59f03e5701a1df0aec29" translate="yes" xml:space="preserve">
          <source>Slots</source>
          <target state="translated">Slots</target>
        </trans-unit>
        <trans-unit id="43d71da8d4d61956de0bee2c8031a772e572d8e9" translate="yes" xml:space="preserve">
          <source>Small helper to get the global step.</source>
          <target state="translated">작은 발자국이 세계적인 발걸음을 내딛습니다.</target>
        </trans-unit>
        <trans-unit id="6cb7bde6d7a37e1c073124906d5e4a5a1de3cce9" translate="yes" xml:space="preserve">
          <source>So we will quantize input values in the range (-10, 9.921875) to (-128, 127).</source>
          <target state="translated">따라서 (-10, 9.921875) ~ (-128, 127) 범위의 입력 값을 양자화합니다.</target>
        </trans-unit>
        <trans-unit id="1c9d521a5361c2a4e0c8be9915daeeb347ef99b6" translate="yes" xml:space="preserve">
          <source>So, for example, in the following code</source>
          <target state="translated">예를 들어 다음 코드에서</target>
        </trans-unit>
        <trans-unit id="dd84a8e23b8d2ff2cbfa9622de69fe4f6a14dee2" translate="yes" xml:space="preserve">
          <source>Softmax activation function.</source>
          <target state="translated">Softmax 활성화 기능.</target>
        </trans-unit>
        <trans-unit id="435a5fbd962f93b0e89d8a9426fbd39681b834f5" translate="yes" xml:space="preserve">
          <source>Softmax converts a real vector to a vector of categorical probabilities.</source>
          <target state="translated">Softmax는 실수 벡터를 범주 확률의 벡터로 변환합니다.</target>
        </trans-unit>
        <trans-unit id="249c1a48d4ec51326b792523af23da85663854be" translate="yes" xml:space="preserve">
          <source>Softmax is often used as the activation for the last layer of a classification network because the result could be interpreted as a probability distribution.</source>
          <target state="translated">Softmax는 결과가 확률 분포로 해석 될 수 있기 때문에 분류 네트워크의 마지막 계층에 대한 활성화로 종종 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="b8982e960ed4f330d0cb5926c5c4b221c348a553" translate="yes" xml:space="preserve">
          <source>Softmax of a tensor.</source>
          <target state="translated">텐서의 Softmax.</target>
        </trans-unit>
        <trans-unit id="2202b3e41bb92b188bacbc372d323cfbcb9740a9" translate="yes" xml:space="preserve">
          <source>Softplus activation function.</source>
          <target state="translated">소프트 플러스 활성화 기능.</target>
        </trans-unit>
        <trans-unit id="8df1d4d78a7aabc863e4139f21878e11ce36dd73" translate="yes" xml:space="preserve">
          <source>Softplus of a tensor.</source>
          <target state="translated">텐서의 소프트 플러스.</target>
        </trans-unit>
        <trans-unit id="43b8de4427acbb41005ce6b4afa9d4ea7a06be43" translate="yes" xml:space="preserve">
          <source>Softsign activation function.</source>
          <target state="translated">Softsign 활성화 기능.</target>
        </trans-unit>
        <trans-unit id="3823a5541395abfd11e5acd5bb48e38fef9b5479" translate="yes" xml:space="preserve">
          <source>Softsign of a tensor.</source>
          <target state="translated">텐서의 Softsign.</target>
        </trans-unit>
        <trans-unit id="3351dcb01c7f12cd9e045a1b6aae29aac909ca39" translate="yes" xml:space="preserve">
          <source>Solution to &lt;code&gt;A x = rhs&lt;/code&gt;, shape &lt;code&gt;[..., M, K]&lt;/code&gt;.</source>
          <target state="translated">해결책 &lt;code&gt;A x = rhs&lt;/code&gt; 모양 &lt;code&gt;[..., M, K]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0579522c86b686853068caf06aebd1d1ae6f6310" translate="yes" xml:space="preserve">
          <source>Solve (exact or approx) &lt;code&gt;R&lt;/code&gt; (batch) systems of equations: &lt;code&gt;A X = rhs&lt;/code&gt;.</source>
          <target state="translated">방정식의 (정확하거나 대략적인) &lt;code&gt;R&lt;/code&gt; (배치) 시스템을 풉니 다 : &lt;code&gt;A X = rhs&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e4c2e52438cd935f70a74acd4d38768b01e1a684" translate="yes" xml:space="preserve">
          <source>Solve single equation with best effort: &lt;code&gt;A X = rhs&lt;/code&gt;.</source>
          <target state="translated">최선의 노력으로 단일 방정식을 풉니 다 : &lt;code&gt;A X = rhs&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="30b5f81be63f62e7ed07c97f7610ff7e0335f79c" translate="yes" xml:space="preserve">
          <source>Solves and determinants will be attempted unless the &quot;is_non_singular&quot; property of L and D is False.</source>
          <target state="translated">L과 D의 &quot;is_non_singular&quot;속성이 False가 아니면 해결 및 결정이 시도됩니다.</target>
        </trans-unit>
        <trans-unit id="cef513b85495a63c763aa1ff3fe9333568ffc35d" translate="yes" xml:space="preserve">
          <source>Solves one or more linear least-squares problems.</source>
          <target state="translated">하나 이상의 선형 최소 제곱 문제를 해결합니다.</target>
        </trans-unit>
        <trans-unit id="24624018f5a4d5f829f115776528e0a470a298b2" translate="yes" xml:space="preserve">
          <source>Solves systems of linear eqns &lt;code&gt;A X = RHS&lt;/code&gt;, given Cholesky factorizations.</source>
          <target state="translated">Cholesky 인수 분해를 고려 하여 선형 방정식 &lt;code&gt;A X = RHS&lt;/code&gt; 시스템을 해결합니다 .</target>
        </trans-unit>
        <trans-unit id="68140ca3dee6c8c6fa35ce72695917b227b59d2e" translate="yes" xml:space="preserve">
          <source>Solves systems of linear eqns &lt;code&gt;A X = RHS&lt;/code&gt;, given LU factorizations.</source>
          <target state="translated">LU 인수 분해를 고려 하여 선형 방정식 &lt;code&gt;A X = RHS&lt;/code&gt; 시스템을 해결합니다 .</target>
        </trans-unit>
        <trans-unit id="8db83c4672e0b070edd5ca0add3871905385cc13" translate="yes" xml:space="preserve">
          <source>Solves systems of linear equations with upper or lower triangular matrices by backsubstitution.</source>
          <target state="translated">역 치환에 의해 상부 또는 하부 삼각 행렬을 갖는 선형 방정식 시스템을 해결합니다.</target>
        </trans-unit>
        <trans-unit id="8ac71fd5f2af5c2c74118e3fda788f2d57c82bcb" translate="yes" xml:space="preserve">
          <source>Solves systems of linear equations.</source>
          <target state="translated">선형 방정식 시스템을 해결합니다.</target>
        </trans-unit>
        <trans-unit id="86ed1050cfe36e63b5ab748299b6d79ebedba8a7" translate="yes" xml:space="preserve">
          <source>Solves tridiagonal systems of equations.</source>
          <target state="translated">삼각 방정식의 해를 구합니다.</target>
        </trans-unit>
        <trans-unit id="233c464b3700ed0d67632d8ee7a7f1c70df38bb6" translate="yes" xml:space="preserve">
          <source>Some &lt;code&gt;Optimizer&lt;/code&gt; subclasses use additional variables. For example &lt;code&gt;Momentum&lt;/code&gt; and &lt;code&gt;Adagrad&lt;/code&gt; use variables to accumulate updates. This method gives access to these &lt;code&gt;Variable&lt;/code&gt; objects if for some reason you need them.</source>
          <target state="translated">일부 &lt;code&gt;Optimizer&lt;/code&gt; 서브 클래스는 추가 변수를 사용합니다. 예를 들어 &lt;code&gt;Momentum&lt;/code&gt; 및 &lt;code&gt;Adagrad&lt;/code&gt; 는 변수를 사용하여 업데이트를 누적합니다. 이 메소드는 어떤 이유로 필요한 경우 이러한 &lt;code&gt;Variable&lt;/code&gt; 오브젝트에 대한 액세스를 제공 합니다.</target>
        </trans-unit>
        <trans-unit id="8f8a5c8d8f8398cf8f49b3a4c453c5a68d4c865e" translate="yes" xml:space="preserve">
          <source>Some distributions do not have well-defined statistics for all initialization parameter values. For example, the beta distribution is parameterized by positive real numbers &lt;code&gt;concentration1&lt;/code&gt; and &lt;code&gt;concentration0&lt;/code&gt;, and does not have well-defined mode if &lt;code&gt;concentration1 &amp;lt; 1&lt;/code&gt; or &lt;code&gt;concentration0 &amp;lt; 1&lt;/code&gt;.</source>
          <target state="translated">일부 분포에는 모든 초기화 매개 변수 값에 대해 잘 정의 된 통계가 없습니다. 예를 들어, 베타 분포는 양의 실수 &lt;code&gt;concentration1&lt;/code&gt; 및 &lt;code&gt;concentration0&lt;/code&gt; 의해 매개 변수화되며 , &lt;code&gt;concentration1 &amp;lt; 1&lt;/code&gt; 또는 &lt;code&gt;concentration0 &amp;lt; 1&lt;/code&gt; 경우 잘 정의 된 모드가 없습니다. .</target>
        </trans-unit>
        <trans-unit id="4c48b1d1e86f2b2608be9d7366644d3071986fef" translate="yes" xml:space="preserve">
          <source>Some examples below.</source>
          <target state="translated">아래에 몇 가지 예가 있습니다.</target>
        </trans-unit>
        <trans-unit id="01706013cfdbcb0fc543d3c97784f3f4c235d630" translate="yes" xml:space="preserve">
          <source>Some examples:</source>
          <target state="translated">몇 가지 예 :</target>
        </trans-unit>
        <trans-unit id="5888e34897c8c7e5c512a504808b2aefe317599c" translate="yes" xml:space="preserve">
          <source>Some losses (for instance, activity regularization losses) may be dependent on the inputs passed when calling a layer. Hence, when reusing the same layer on different inputs &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt;, some entries in &lt;code&gt;layer.losses&lt;/code&gt; may be dependent on &lt;code&gt;a&lt;/code&gt; and some on &lt;code&gt;b&lt;/code&gt;. This method automatically keeps track of dependencies.</source>
          <target state="translated">일부 손실 (예 : 활동 정규화 손실)은 계층을 호출 할 때 전달 된 입력에 따라 달라질 수 있습니다. 다른 입력에 동일한 층 재사용 할 때 이에 및 &lt;code&gt;b&lt;/code&gt; , 일부 항목 &lt;code&gt;layer.losses&lt;/code&gt; 은 에 의존 할 수 의 일부 &lt;code&gt;b&lt;/code&gt; . 이 방법은 자동으로 종속성을 추적합니다. &lt;code&gt;a&lt;/code&gt; &lt;code&gt;a&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="64f905b7f1fcde32b3aea4717774e00ef6c12c19" translate="yes" xml:space="preserve">
          <source>Some notes on passing Callables to customize splitting and normalization for this layer: 1) Any callable can be passed to this Layer, but if you want to serialize this object you should only pass functions that are registered Keras serializables (see &lt;a href=&quot;../../../utils/register_keras_serializable&quot;&gt;&lt;code&gt;tf.keras.utils.register_keras_serializable&lt;/code&gt;&lt;/a&gt; for more details). 2) When using a custom callable for &lt;code&gt;standardize&lt;/code&gt;, the data recieved by the callable will be exactly as passed to this layer. The callable should return a tensor of the same shape as the input. 3) When using a custom callable for &lt;code&gt;split&lt;/code&gt;, the data recieved by the callable will have the 1st dimension squeezed out - instead of &lt;code&gt;[[&quot;string to split&quot;], [&quot;another string to split&quot;]]&lt;/code&gt;, the Callable will see &lt;code&gt;[&quot;string to split&quot;, &quot;another string to split&quot;]&lt;/code&gt;. The callable should return a Tensor with the first dimension containing the split tokens - in this example, we should see something like &lt;code&gt;[[&quot;string&quot;, &quot;to&quot;, &quot;split], [&quot;another&quot;, &quot;string&quot;, &quot;to&quot;, &quot;split&quot;]]&lt;/code&gt;. This makes the callable site natively compatible with &lt;a href=&quot;../../../../strings/split&quot;&gt;&lt;code&gt;tf.strings.split()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">이 레이어에 대한 분할 및 정규화를 사용자 정의하기 위해 Callables를 전달하는 것에 대한 참고 사항 : 1) Callable &lt;a href=&quot;../../../utils/register_keras_serializable&quot;&gt; &lt;code&gt;tf.keras.utils.register_keras_serializable&lt;/code&gt; &lt;/a&gt; Layer에 전달할 수 있지만이 객체를 직렬화하려면 Keras 직렬화 가능 기능으로 등록 된 함수 만 전달해야합니다 ( tf.keras.utils 참조) . 자세한 내용은 register_keras_serializable 을 참조하십시오. 2) &lt;code&gt;standardize&lt;/code&gt; 를 위해 커스텀 콜 러블을 사용할 때 , 콜 러블이 수신 한 데이터는이 레이어로 전달 된 것과 정확히 동일합니다. 콜 러블은 입력과 같은 모양의 텐서를 반환해야합니다. 3) &lt;code&gt;split&lt;/code&gt; 을위한 커스텀 callable을 사용할 때 , callable에 의해 수신 된 데이터는 &lt;code&gt;[[&quot;string to split&quot;], [&quot;another string to split&quot;]]&lt;/code&gt; 대신에 1 차원을 짜게됩니다. &lt;code&gt;[&quot;string to split&quot;, &quot;another string to split&quot;]&lt;/code&gt; . 콜 러블은 분할 토큰을 포함하는 첫 번째 차원의 Tensor를 반환해야합니다.이 예에서는 &lt;code&gt;[[&quot;string&quot;, &quot;to&quot;, &quot;split], [&quot;another&quot;, &quot;string&quot;, &quot;to&quot;, &quot;split&quot;]]&lt;/code&gt; .이와 기본적으로 호환 호출 사이트하게 &lt;a href=&quot;../../../../strings/split&quot;&gt; &lt;code&gt;tf.strings.split()&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="feb7b4ee12e100be2f687c1c0bcffc79014d8346" translate="yes" xml:space="preserve">
          <source>Some of the args below are hyperparameters, where a hyperparameter is defined as a scalar Tensor, a regular Python value, or a callable (which will be evaluated when &lt;code&gt;apply_gradients&lt;/code&gt; is called) returning a scalar Tensor or a Python value.</source>
          <target state="translated">아래의 인수 중 일부는 하이퍼 파라미터로, 하이퍼 파라미터는 스칼라 텐서, 일반 파이썬 값 또는 스칼라 텐서 또는 파이썬 값을 반환하는 호출 가능 ( &lt;code&gt;apply_gradients&lt;/code&gt; 가 호출 될 때 평가됨 )으로 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="11f76fcf688ca010a98217641ecd535f27ce8159" translate="yes" xml:space="preserve">
          <source>Some operations may raise this error when passed otherwise-valid arguments that it does not currently support. For example, running the &lt;a href=&quot;../nn/max_pool2d&quot;&gt;&lt;code&gt;tf.nn.max_pool2d&lt;/code&gt;&lt;/a&gt; operation would raise this error if pooling was requested on the batch dimension, because this is not yet supported.</source>
          <target state="translated">현재 지원하지 않는 다른 인수를 전달하면 일부 작업에서이 오류가 발생할 수 있습니다. 예를 들어, &lt;a href=&quot;../nn/max_pool2d&quot;&gt; &lt;code&gt;tf.nn.max_pool2d&lt;/code&gt; &lt;/a&gt; 작업을 실행하면 배치 차원에서 풀링이 요청 된 경우 아직 지원되지 않기 때문에이 오류가 발생합니다.</target>
        </trans-unit>
        <trans-unit id="20cef832e1649a427e222d654a87a81502c3b58e" translate="yes" xml:space="preserve">
          <source>Some optimizations may come at the cost of accuracy.</source>
          <target state="translated">일부 최적화는 정확도가 떨어질 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="eea1875658d39629200b30d5f8a835b05524f8c2" translate="yes" xml:space="preserve">
          <source>Some optimizer subclasses, such as &lt;code&gt;MomentumOptimizer&lt;/code&gt; and &lt;code&gt;AdagradOptimizer&lt;/code&gt; allocate and manage additional variables associated with the variables to train. These are called</source>
          <target state="translated">&lt;code&gt;MomentumOptimizer&lt;/code&gt; 및 &lt;code&gt;AdagradOptimizer&lt;/code&gt; 와 같은 일부 옵티 마이저 서브 클래스는 학습 할 변수와 연관된 추가 변수를 할당하고 관리합니다. 이것들은</target>
        </trans-unit>
        <trans-unit id="8116995a516d4171a76880af533d292c0bbc2e45" translate="yes" xml:space="preserve">
          <source>Some resource has been exhausted.</source>
          <target state="translated">일부 리소스가 소진되었습니다.</target>
        </trans-unit>
        <trans-unit id="d0a1011ddf516ad6ec7be68cafcf80c7f137789d" translate="yes" xml:space="preserve">
          <source>Some useful examples:</source>
          <target state="translated">유용한 예 :</target>
        </trans-unit>
        <trans-unit id="f25ae134af3b43a3a1105e6fe76023fec8620e82" translate="yes" xml:space="preserve">
          <source>Some useful partitioners are available. See, e.g., &lt;code&gt;variable_axis_size_partitioner&lt;/code&gt; and &lt;code&gt;min_max_variable_partitioner&lt;/code&gt;.</source>
          <target state="translated">몇 가지 유용한 파티 셔 너가 있습니다. 예를 들어 &lt;code&gt;variable_axis_size_partitioner&lt;/code&gt; 및 &lt;code&gt;min_max_variable_partitioner&lt;/code&gt; 를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="667cf0b7e45f4e36e4bea2c73c06b38bafc26add" translate="yes" xml:space="preserve">
          <source>Sorts a tensor.</source>
          <target state="translated">텐서를 정렬합니다.</target>
        </trans-unit>
        <trans-unit id="f620b61bc526606d7744ac5849b8a20527d8358e" translate="yes" xml:space="preserve">
          <source>Source Datasets</source>
          <target state="translated">소스 데이터 셋</target>
        </trans-unit>
        <trans-unit id="e7cc83312e2a1c912c21eec7771b4fd2244b10c4" translate="yes" xml:space="preserve">
          <source>Source: &quot;Searching for Activation Functions&quot; (Ramachandran et al. 2017) https://arxiv.org/abs/1710.05941</source>
          <target state="translated">출처 : &quot;활성화 기능 검색&quot;(Ramachandran et al. 2017) https://arxiv.org/abs/1710.05941</target>
        </trans-unit>
        <trans-unit id="eb6aebda039a15f53e457e68d7d438b1cff01ed3" translate="yes" xml:space="preserve">
          <source>Source: &lt;a href=&quot;http://www.cs.utoronto.ca/%7Ekriz/conv-cifar10-aug2010.pdf&quot;&gt;Convolutional Deep Belief Networks on CIFAR-10. A. Krizhevsky&lt;/a&gt;</source>
          <target state="translated">출처 : &lt;a href=&quot;http://www.cs.utoronto.ca/%7Ekriz/conv-cifar10-aug2010.pdf&quot;&gt;CIFAR-10의 Convolutional Deep Belief Networks. 크리츠 헤프 스키&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5d171992414a7599766d9131cfb8c37f4925b830" translate="yes" xml:space="preserve">
          <source>Source: &lt;a href=&quot;https://ai.stanford.edu/%7Eamaas/papers/relu_hybrid_icml2013_final.pdf&quot;&gt;Rectifier Nonlinearities Improve Neural Network Acoustic Models. AL Maas, AY Hannun, AY Ng - Proc. ICML, 2013&lt;/a&gt;.</source>
          <target state="translated">출처 : &lt;a href=&quot;https://ai.stanford.edu/%7Eamaas/papers/relu_hybrid_icml2013_final.pdf&quot;&gt;정류기 비선형 성은 신경망 음향 모델을 향상시킵니다. AL Maas, AY Hannun, AY Ng-Proc. ICML, 2013&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="8b607ebb0ce412857986816d3db8a881d545fbfc" translate="yes" xml:space="preserve">
          <source>SpaceToBatch for 4-D tensors of type T.</source>
          <target state="translated">유형 T의 4 차원 텐서 용 SpaceToBatch</target>
        </trans-unit>
        <trans-unit id="083730c076520c06f329b3a1d05a2c9ceace46aa" translate="yes" xml:space="preserve">
          <source>SpaceToBatch for N-D tensors of type T.</source>
          <target state="translated">유형 T의 ND 텐서 용 SpaceToBatch</target>
        </trans-unit>
        <trans-unit id="70947ab2fc979f29296aaef123d22483ba02139e" translate="yes" xml:space="preserve">
          <source>SpaceToDepth for tensors of type T.</source>
          <target state="translated">T 유형의 텐서에 대한 SpaceToDepth</target>
        </trans-unit>
        <trans-unit id="b32e033310ebd5e93b4041f5df9964210ade963a" translate="yes" xml:space="preserve">
          <source>Sparse Tensor Representation.</source>
          <target state="translated">스파 스 텐서 표현.</target>
        </trans-unit>
        <trans-unit id="069a9228c751a538f52a392a1cd0e50f26fac743" translate="yes" xml:space="preserve">
          <source>Sparse gradients are represented by &lt;code&gt;IndexedSlices&lt;/code&gt;.</source>
          <target state="translated">희소 그라디언트는 &lt;code&gt;IndexedSlices&lt;/code&gt; 로 표시됩니다 .</target>
        </trans-unit>
        <trans-unit id="7b4c1d1909f9bc68a995624a409254a398966f07" translate="yes" xml:space="preserve">
          <source>SparseTensor is not supported. The return value of the decorated function must be a Tensor or a list/tuple of Tensors.</source>
          <target state="translated">SparseTensor는 지원되지 않습니다. 데코 레이팅 된 함수의 반환 값은 Tensor 또는 Tensor 목록 / 튜플이어야합니다.</target>
        </trans-unit>
        <trans-unit id="a1ffd7ce11921ece1834d4731c951cc910508d1f" translate="yes" xml:space="preserve">
          <source>SparseTensor referred by first key:</source>
          <target state="translated">첫 번째 키로 참조되는 SparseTensor :</target>
        </trans-unit>
        <trans-unit id="1c32b414e828af630366a2f4a79388908c22a788" translate="yes" xml:space="preserve">
          <source>SparseTensor referred by second key:</source>
          <target state="translated">두 번째 키로 참조되는 SparseTensor :</target>
        </trans-unit>
        <trans-unit id="fa5e3369b1a543faf6701e41ac2ec3d01253f981" translate="yes" xml:space="preserve">
          <source>SparseTensorValue(indices, values, dense_shape)</source>
          <target state="translated">SparseTensorValue (표시, 값, 밀도 _ 모양)</target>
        </trans-unit>
        <trans-unit id="6ee93c8da33edf23834992d6432a8f0e409815de" translate="yes" xml:space="preserve">
          <source>Spatial 1D version of Dropout.</source>
          <target state="translated">Dropout의 공간 1D 버전.</target>
        </trans-unit>
        <trans-unit id="44ada72cd6d79ae9c07a9cb3d7a9ed46bb7aa114" translate="yes" xml:space="preserve">
          <source>Spatial 2D version of Dropout.</source>
          <target state="translated">Dropout의 공간 2D 버전.</target>
        </trans-unit>
        <trans-unit id="1b491fa379bdaddd72ebc9a3730d0e2efd96f9bc" translate="yes" xml:space="preserve">
          <source>Spatial 3D version of Dropout.</source>
          <target state="translated">Dropout의 공간적 3D 버전.</target>
        </trans-unit>
        <trans-unit id="c3f29e68c2f47d80899bc4477479be5589b1d283" translate="yes" xml:space="preserve">
          <source>Special math functions (like: &lt;a href=&quot;../../math/igamma&quot;&gt;&lt;code&gt;tf.math.igamma&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../math/zeta&quot;&gt;&lt;code&gt;tf.math.zeta&lt;/code&gt;&lt;/a&gt;)</source>
          <target state="translated">특수 수학 함수 (예 : &lt;a href=&quot;../../math/igamma&quot;&gt; &lt;code&gt;tf.math.igamma&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;../../math/zeta&quot;&gt; &lt;code&gt;tf.math.zeta&lt;/code&gt; &lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="42e77439e21bd348d1d9ca7ffa4988277cfd7529" translate="yes" xml:space="preserve">
          <source>Special math functions (like: &lt;a href=&quot;math/igamma&quot;&gt;&lt;code&gt;tf.math.igamma&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;math/zeta&quot;&gt;&lt;code&gt;tf.math.zeta&lt;/code&gt;&lt;/a&gt;)</source>
          <target state="translated">특수 수학 함수 (예 : &lt;a href=&quot;math/igamma&quot;&gt; &lt;code&gt;tf.math.igamma&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;math/zeta&quot;&gt; &lt;code&gt;tf.math.zeta&lt;/code&gt; &lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="c7001c1ac0b17fbd7ca3a02ab7f20b52959b8e41" translate="yes" xml:space="preserve">
          <source>Specifically, &lt;code&gt;y = 1 / (1 + exp(-x))&lt;/code&gt;.</source>
          <target state="translated">구체적으로, &lt;code&gt;y = 1 / (1 + exp(-x))&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="954c9de28a55b63501fe0fe04e4bf1cb501e7df5" translate="yes" xml:space="preserve">
          <source>Specifically, &lt;code&gt;y = log(1 / (1 + exp(-x)))&lt;/code&gt;. For numerical stability, we use &lt;code&gt;y = -tf.nn.softplus(-x)&lt;/code&gt;.</source>
          <target state="translated">구체적으로, &lt;code&gt;y = log(1 / (1 + exp(-x)))&lt;/code&gt; 입니다. 수치 안정성을 위해 &lt;code&gt;y = -tf.nn.softplus(-x)&lt;/code&gt; 합니다.</target>
        </trans-unit>
        <trans-unit id="6597172c93c2b702bcd7586ce5fa7c1bf3b6fa02" translate="yes" xml:space="preserve">
          <source>Specifically, in the case that &lt;code&gt;data_format&lt;/code&gt; does not start with &quot;NC&quot;, given a rank (N+2) &lt;code&gt;input&lt;/code&gt; Tensor of shape</source>
          <target state="translated">구체적으로 &lt;code&gt;data_format&lt;/code&gt; 이 &quot;NC&quot;로 시작하지 않는 경우 , 순위 (N + 2)의 &lt;code&gt;input&lt;/code&gt; 텐서가 주어지면</target>
        </trans-unit>
        <trans-unit id="4685e2fad46095eee9ba25a53c669f27eb8ab429" translate="yes" xml:space="preserve">
          <source>Specifically, returns &lt;code&gt;True&lt;/code&gt; if the dtype of &lt;code&gt;tensor&lt;/code&gt; is one of the following:</source>
          <target state="translated">특히 &lt;code&gt;tensor&lt;/code&gt; 의 dtype 이 다음 중 하나 인 경우 &lt;code&gt;True&lt;/code&gt; 를 반환합니다 .</target>
        </trans-unit>
        <trans-unit id="0556709f41308a40346ba1c586e66a03dc18eabe" translate="yes" xml:space="preserve">
          <source>Specifically, the op extracts patches of shape &lt;code&gt;sizes&lt;/code&gt; which are &lt;code&gt;strides&lt;/code&gt; apart in the input image. The output is subsampled using the &lt;code&gt;rates&lt;/code&gt; argument, in the same manner as &quot;atrous&quot; or &quot;dilated&quot; convolutions.</source>
          <target state="translated">특히, 영업 모양의 패치를 추출하는 &lt;code&gt;sizes&lt;/code&gt; 이다 &lt;code&gt;strides&lt;/code&gt; 이격 입력 화상하여. 출력은 &quot;atrous&quot;또는 &quot;dilated&quot;컨볼 루션과 같은 방식으로 &lt;code&gt;rates&lt;/code&gt; 인수를 사용하여 서브 샘플링됩니다 .</target>
        </trans-unit>
        <trans-unit id="fae6543b085f90e9db03167ac9f6f9969607441e" translate="yes" xml:space="preserve">
          <source>Specifically, this function implements single-machine multi-GPU data parallelism. It works in the following way:</source>
          <target state="translated">특히이 기능은 단일 시스템 다중 GPU 데이터 병렬 처리를 구현합니다. 다음과 같은 방식으로 작동합니다.</target>
        </trans-unit>
        <trans-unit id="0c8f3483a76d71d8bb0d00a6d0eabe91ca24c35a" translate="yes" xml:space="preserve">
          <source>Specification of target device.</source>
          <target state="translated">대상 장치의 사양</target>
        </trans-unit>
        <trans-unit id="ea883e74b6a3843ac1a29b4ff2add9d3a018b23d" translate="yes" xml:space="preserve">
          <source>Specifies a TensorFlow value type.</source>
          <target state="translated">TensorFlow 값 유형을 지정합니다.</target>
        </trans-unit>
        <trans-unit id="50ddb4ee8c52d872568fecc64ff41f8830ff5dee" translate="yes" xml:space="preserve">
          <source>Specifies that a flag is a key flag for a module.</source>
          <target state="translated">플래그가 모듈의 키 플래그임을 지정합니다.</target>
        </trans-unit>
        <trans-unit id="60e17bd62fb185088c8acaab226bfbeedef8f34c" translate="yes" xml:space="preserve">
          <source>Specifies that ops of type &lt;code&gt;op_type&lt;/code&gt; is not differentiable.</source>
          <target state="translated">&lt;code&gt;op_type&lt;/code&gt; 유형의 op를 구별 할 수 없도록 지정합니다 .</target>
        </trans-unit>
        <trans-unit id="847ad11bfeecb8d48ed0c0033c02e5d0d9d05fd9" translate="yes" xml:space="preserve">
          <source>Specifies the device for ops created/executed in this context.</source>
          <target state="translated">이 컨텍스트에서 작성 / 실행 된 조작에 대한 디바이스를 지정합니다.</target>
        </trans-unit>
        <trans-unit id="a23f6051fc3fbb5815e141c943efca771d21b5b9" translate="yes" xml:space="preserve">
          <source>Specifies the ndim, dtype and shape of every input to a layer.</source>
          <target state="translated">레이어에 대한 모든 입력의 ndim, dtype 및 모양을 지정합니다.</target>
        </trans-unit>
        <trans-unit id="17dc1bc89affaacc3206c6d8f591c91199d8edfc" translate="yes" xml:space="preserve">
          <source>Specifies whether operations are executed synchronously or asynchronously.</source>
          <target state="translated">작업이 동 기적으로 또는 비동기 적으로 실행 될지 여부를 지정합니다.</target>
        </trans-unit>
        <trans-unit id="86a70a978ffb3c314d3fa9e073f9f1ebb89c519c" translate="yes" xml:space="preserve">
          <source>Specifies which &lt;code&gt;PhysicalDevice&lt;/code&gt; objects are visible to the runtime. TensorFlow will only allocate memory and place operations on visible physical devices, as otherwise no &lt;code&gt;LogicalDevice&lt;/code&gt; will be created on them. By default all discovered devices are marked as visible.</source>
          <target state="translated">런타임에 표시 할 &lt;code&gt;PhysicalDevice&lt;/code&gt; 개체를 지정 합니다. TensorFlow 만 그렇지 않으면로, 눈에 보이는 물리적 장치에 메모리와 장소에 작업을 할당합니다 &lt;code&gt;LogicalDevice&lt;/code&gt; 에 합니다. 가 생성 . 기본적으로 검색된 모든 장치는 표시되는 것으로 표시됩니다.</target>
        </trans-unit>
        <trans-unit id="c1dc8e11dd50b0215e624b3b32a9d0f31a9f6f8b" translate="yes" xml:space="preserve">
          <source>Specify tensors to watch and their Jacobian-vector products.</source>
          <target state="translated">시청할 텐서와 Jacobian-vector 제품을 지정하십시오.</target>
        </trans-unit>
        <trans-unit id="b5641c8d22b21d1e9602ce014b4719ee01c9c37b" translate="yes" xml:space="preserve">
          <source>Specifying &lt;code&gt;''&lt;/code&gt; requests an in-process session that does not use RPC.</source>
          <target state="translated">&lt;code&gt;''&lt;/code&gt; 을 지정 하면 RPC를 사용하지 않는 프로세스 내 세션이 요청됩니다.</target>
        </trans-unit>
        <trans-unit id="405b7de568617cf3ae840e38096fa116bfa8c971" translate="yes" xml:space="preserve">
          <source>Specifying &lt;code&gt;'grpc://hostname:port'&lt;/code&gt; requests a session that uses the RPC interface to a specific host, and also allows the in-process master to access remote tensorflow workers. Often, it is appropriate to pass &lt;code&gt;server.target&lt;/code&gt; (for some &lt;a href=&quot;../../../distribute/server&quot;&gt;&lt;code&gt;tf.distribute.Server&lt;/code&gt;&lt;/a&gt; named `server).</source>
          <target state="translated">&lt;code&gt;'grpc://hostname:port'&lt;/code&gt; 를 지정 하면 RPC 인터페이스를 사용하여 특정 호스트에 대한 세션을 요청하고 프로세스 내 마스터가 원격 tensorflow 작업자에 액세스 할 수 있습니다. 종종 &lt;code&gt;server.target&lt;/code&gt; ( `server라는 이름의 &lt;a href=&quot;../../../distribute/server&quot;&gt; &lt;code&gt;tf.distribute.Server&lt;/code&gt; )&lt;/a&gt; 을 전달하는 것이 적절합니다 .</target>
        </trans-unit>
        <trans-unit id="26bd73b0bd8bb18d70c2dc4595792f67ad9856b4" translate="yes" xml:space="preserve">
          <source>Specifying &lt;code&gt;'local'&lt;/code&gt; requests a session that uses the RPC-based &quot;Master interface&quot; to run TensorFlow programs. See &lt;code&gt;tf.train.Server.create_local_server&lt;/code&gt; for details.</source>
          <target state="translated">&lt;code&gt;'local'&lt;/code&gt; 을 지정 하면 RPC 기반 &quot;마스터 인터페이스&quot;를 사용하여 TensorFlow 프로그램을 실행하는 세션이 요청됩니다. &lt;code&gt;tf.train.Server.create_local_server&lt;/code&gt; 를 참조하십시오 . 를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="e8d93b14898782206a27c2f623c3e13068558d40" translate="yes" xml:space="preserve">
          <source>Split a &lt;code&gt;SparseTensor&lt;/code&gt; into &lt;code&gt;num_split&lt;/code&gt; tensors along &lt;code&gt;axis&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;axis&lt;/code&gt; 따라 &lt;code&gt;SparseTensor&lt;/code&gt; 를 &lt;code&gt;num_split&lt;/code&gt; 텐서 로 분할하십시오 .</target>
        </trans-unit>
        <trans-unit id="48c476197d75a69934319a7ec0da01331434b536" translate="yes" xml:space="preserve">
          <source>Split a &lt;code&gt;SparseTensor&lt;/code&gt; into &lt;code&gt;num_split&lt;/code&gt; tensors along &lt;code&gt;axis&lt;/code&gt;. (deprecated arguments)</source>
          <target state="translated">&lt;code&gt;axis&lt;/code&gt; 따라 &lt;code&gt;SparseTensor&lt;/code&gt; 를 &lt;code&gt;num_split&lt;/code&gt; 텐서 로 분할하십시오 . (더 이상 사용되지 않는 인수)</target>
        </trans-unit>
        <trans-unit id="da7b9513b11ddbf83b6b96223d58f5a656aa657d" translate="yes" xml:space="preserve">
          <source>Split elements of &lt;code&gt;input&lt;/code&gt; based on &lt;code&gt;sep&lt;/code&gt; into a &lt;code&gt;RaggedTensor&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;sep&lt;/code&gt; 를 기준으로 &lt;code&gt;input&lt;/code&gt; 요소를 &lt;code&gt;RaggedTensor&lt;/code&gt; 로 분할합니다 .</target>
        </trans-unit>
        <trans-unit id="58404bb00065199a0e549c463f07be748d39a794" translate="yes" xml:space="preserve">
          <source>Split elements of &lt;code&gt;input&lt;/code&gt; based on &lt;code&gt;sep&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;sep&lt;/code&gt; 에 따라 &lt;code&gt;input&lt;/code&gt; 요소를 분할합니다 .</target>
        </trans-unit>
        <trans-unit id="48ef48c846fb000283c6182d2a2c88def70c9079" translate="yes" xml:space="preserve">
          <source>Split elements of &lt;code&gt;source&lt;/code&gt; based on &lt;code&gt;delimiter&lt;/code&gt;. (deprecated arguments)</source>
          <target state="translated">&lt;code&gt;delimiter&lt;/code&gt; 기준으로 &lt;code&gt;source&lt;/code&gt; 요소 분리 . (더 이상 사용되지 않는 인수)</target>
        </trans-unit>
        <trans-unit id="feeb0afbc717961d923c1bb6d0a2cbd2235c11fc" translate="yes" xml:space="preserve">
          <source>Split string elements of &lt;code&gt;input&lt;/code&gt; into bytes.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 문자열 요소 를 바이트로 분할합니다 .</target>
        </trans-unit>
        <trans-unit id="2ec109a46f53e7a89dab4ee2f80314ae2e476dd5" translate="yes" xml:space="preserve">
          <source>Split the values of a &lt;code&gt;Tensor&lt;/code&gt; into the TensorArray.</source>
          <target state="translated">&lt;code&gt;Tensor&lt;/code&gt; 의 값을 TensorArray로 분할하십시오 .</target>
        </trans-unit>
        <trans-unit id="2525a2c7ac0234994f7780711bb8b426b3f60464" translate="yes" xml:space="preserve">
          <source>Splits a tensor into sub tensors.</source>
          <target state="translated">텐서를 하위 텐서로 분할합니다.</target>
        </trans-unit>
        <trans-unit id="4d43c36bbfca1a538b2005f5a195827db6f584b5" translate="yes" xml:space="preserve">
          <source>Splits each rank-N &lt;a href=&quot;../../../../sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.SparseTensor&lt;/code&gt;&lt;/a&gt; in this dataset row-wise. (deprecated)</source>
          <target state="translated">이 데이터 세트에서 각 순위 N &lt;a href=&quot;../../../../sparse/sparsetensor&quot;&gt; &lt;code&gt;tf.SparseTensor&lt;/code&gt; &lt;/a&gt; 를 행 단위로 분할합니다 . (더 이상 사용되지 않음)</target>
        </trans-unit>
        <trans-unit id="d2558021e23f8309108fd307b098699b10771f98" translate="yes" xml:space="preserve">
          <source>Splits each rank-N &lt;a href=&quot;../../../sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.SparseTensor&lt;/code&gt;&lt;/a&gt; in this dataset row-wise. (deprecated)</source>
          <target state="translated">이 데이터 세트에서 각 순위 N &lt;a href=&quot;../../../sparse/sparsetensor&quot;&gt; &lt;code&gt;tf.SparseTensor&lt;/code&gt; &lt;/a&gt; 를 행 단위로 분할합니다 . (더 이상 사용되지 않음)</target>
        </trans-unit>
        <trans-unit id="f4d1aaee79561119dd0a5d338e2a7ca4f1422ce7" translate="yes" xml:space="preserve">
          <source>Splits each string in &lt;code&gt;input&lt;/code&gt; into a sequence of Unicode code points.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 각 문자열을 일련의 유니 코드 코드 포인트로 분할합니다 .</target>
        </trans-unit>
        <trans-unit id="94584a38ee61d0af4ef0ac0752e5ef4eaa3d1dc9" translate="yes" xml:space="preserve">
          <source>Splits each string into a sequence of code points with start offsets.</source>
          <target state="translated">각 문자열을 시작 오프셋이있는 일련의 코드 포인트로 분할합니다.</target>
        </trans-unit>
        <trans-unit id="c47b3f827bb53db64e834684eba00cbf35296512" translate="yes" xml:space="preserve">
          <source>Splits elements of a dataset into multiple elements on the batch dimension. (deprecated)</source>
          <target state="translated">배치 차원에서 데이터 집합의 요소를 여러 요소로 분할합니다. (더 이상 사용되지 않음)</target>
        </trans-unit>
        <trans-unit id="b8bd28acaf2b895effd8654557c3dacbebf4a2c4" translate="yes" xml:space="preserve">
          <source>Splits elements of a dataset into multiple elements.</source>
          <target state="translated">데이터 세트의 요소를 여러 요소로 분할합니다.</target>
        </trans-unit>
        <trans-unit id="c3dcf86335eb4dcd9df560b318acb47a8f5d257d" translate="yes" xml:space="preserve">
          <source>Stacks a list of rank &lt;code&gt;R&lt;/code&gt; tensors into a rank &lt;code&gt;R+1&lt;/code&gt; tensor.</source>
          <target state="translated">순위 &lt;code&gt;R&lt;/code&gt; 텐서 목록을 순위 &lt;code&gt;R+1&lt;/code&gt; 텐서에 쌓습니다.</target>
        </trans-unit>
        <trans-unit id="a8f192bcec355d760ffbcfb5d4356d125221a71c" translate="yes" xml:space="preserve">
          <source>Stacks a list of rank-&lt;code&gt;R&lt;/code&gt; tensors into one rank-&lt;code&gt;(R+1)&lt;/code&gt; tensor in parallel.</source>
          <target state="translated">&lt;code&gt;R&lt;/code&gt; 등급 텐서 목록 을 하나의 등급으로 쌓습니다 &lt;code&gt;(R+1)&lt;/code&gt; . 병렬 텐서에 쌓습니다.</target>
        </trans-unit>
        <trans-unit id="411d8e2a06e5fa2c606474dc5fbe557c7d2ba8bb" translate="yes" xml:space="preserve">
          <source>Stacks a list of rank-&lt;code&gt;R&lt;/code&gt; tensors into one rank-&lt;code&gt;(R+1)&lt;/code&gt; tensor.</source>
          <target state="translated">순위 &lt;code&gt;R&lt;/code&gt; 텐서 목록 을 하나 의 순위 &lt;code&gt;(R+1)&lt;/code&gt; 텐서에 쌓습니다.</target>
        </trans-unit>
        <trans-unit id="07a81968a5e580e3ddc7f3c1dfe616f113f25eb2" translate="yes" xml:space="preserve">
          <source>Stacks a list of rank-&lt;code&gt;R&lt;/code&gt; tensors into one rank-&lt;code&gt;(R+1)&lt;/code&gt;&lt;code&gt;RaggedTensor&lt;/code&gt;.</source>
          <target state="translated">순위 &lt;code&gt;R&lt;/code&gt; 텐서 목록 을 하나의 &lt;code&gt;RaggedTensor&lt;/code&gt; &lt;code&gt;(R+1)&lt;/code&gt; RaggedTensor로 쌓습니다 .</target>
        </trans-unit>
        <trans-unit id="244b873bd8fa37f33bd8c2425d0c77e7748a72b7" translate="yes" xml:space="preserve">
          <source>Stacks dynamic partitions of a Tensor or RaggedTensor.</source>
          <target state="translated">Tensor 또는 RaggedTensor의 동적 파티션을 쌓습니다.</target>
        </trans-unit>
        <trans-unit id="c79e6e247019a81999cc68e49d7a710622176286" translate="yes" xml:space="preserve">
          <source>Standard deviation is defined as,</source>
          <target state="translated">표준 편차는 다음과 같이 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="055d92b4a3c41965fe47264346978d7a3185cce9" translate="yes" xml:space="preserve">
          <source>Standard deviation of a tensor, alongside the specified axis.</source>
          <target state="translated">지정된 축과 함께 텐서의 표준 편차.</target>
        </trans-unit>
        <trans-unit id="df9f5f66c6d3882cf2305d67d9a9474489134d03" translate="yes" xml:space="preserve">
          <source>Standard deviation.</source>
          <target state="translated">표준 편차.</target>
        </trans-unit>
        <trans-unit id="f057b861993d91873adb8d03059b68337b2c76e0" translate="yes" xml:space="preserve">
          <source>Standard names for Estimator model modes.</source>
          <target state="translated">Estimator 모델 모드의 표준 이름.</target>
        </trans-unit>
        <trans-unit id="4f99c39141bb3ddf1a7d22eeab71658b76e3cad1" translate="yes" xml:space="preserve">
          <source>Standard names to use for graph collections.</source>
          <target state="translated">그래프 수집에 사용할 표준 이름입니다.</target>
        </trans-unit>
        <trans-unit id="594ca634eb315bc3997ded1357b2f6c715d7772e" translate="yes" xml:space="preserve">
          <source>Start a LooperThread that calls a function periodically.</source>
          <target state="translated">주기적으로 함수를 호출하는 LooperThread를 시작하십시오.</target>
        </trans-unit>
        <trans-unit id="15aa8e658d8f3e8d9e2bcd223fef378355b8f614" translate="yes" xml:space="preserve">
          <source>Start a step: fetch variables and compute gradients.</source>
          <target state="translated">변수를 가져오고 그라디언트를 계산하십시오.</target>
        </trans-unit>
        <trans-unit id="08ad0056ecc29209217961803b2e9f7137506856" translate="yes" xml:space="preserve">
          <source>Start by either creating a &lt;a href=&quot;../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; normally or using &lt;code&gt;tf.distribute.experimental_make_numpy_dataset&lt;/code&gt; to make a dataset out of a &lt;code&gt;numpy&lt;/code&gt; array.</source>
          <target state="translated">&lt;a href=&quot;../data/dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; 을&lt;/a&gt; 정상적으로 작성 하거나 &lt;code&gt;tf.distribute.experimental_make_numpy_dataset&lt;/code&gt; 을 사용하여 &lt;code&gt;numpy&lt;/code&gt; 배열 에서 데이터 세트를 작성하여 시작하십시오 .</target>
        </trans-unit>
        <trans-unit id="d86e406e531f06a60d2dee1e4984ec027b2308d0" translate="yes" xml:space="preserve">
          <source>Start the next batch.</source>
          <target state="translated">다음 배치를 시작하십시오.</target>
        </trans-unit>
        <trans-unit id="faf298f1e87c04adba60787926533cc120075122" translate="yes" xml:space="preserve">
          <source>Start the scope block.</source>
          <target state="translated">범위 블록을 시작하십시오.</target>
        </trans-unit>
        <trans-unit id="8cbf1285faa03571413d56c285dbab6cefc1bca8" translate="yes" xml:space="preserve">
          <source>Start the standard services for 'sess'.</source>
          <target state="translated">'sess'에 대한 표준 서비스를 시작하십시오.</target>
        </trans-unit>
        <trans-unit id="6981642129cbd20083e772ec5f952609a47be106" translate="yes" xml:space="preserve">
          <source>Start the thread's activity.</source>
          <target state="translated">스레드 활동을 시작하십시오.</target>
        </trans-unit>
        <trans-unit id="83b5898849275d244f9dc1b3986f7cb88a3fa122" translate="yes" xml:space="preserve">
          <source>Start threads for &lt;code&gt;QueueRunners&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;QueueRunners&lt;/code&gt; 의 스레드를 시작하십시오 .</target>
        </trans-unit>
        <trans-unit id="edf1fcfb7060b839d58846461c7fe9ea1192ffb9" translate="yes" xml:space="preserve">
          <source>Starts a trace to record computation graphs and profiling information.</source>
          <target state="translated">계산 그래프 및 프로파일 링 정보를 기록하기위한 추적을 시작합니다.</target>
        </trans-unit>
        <trans-unit id="817af290c476c6f8d3234f21fb9c38bd1fc07a8f" translate="yes" xml:space="preserve">
          <source>Starts all queue runners collected in the graph. (deprecated)</source>
          <target state="translated">그래프에서 수집 된 모든 큐 러너를 시작합니다. (더 이상 사용되지 않음)</target>
        </trans-unit>
        <trans-unit id="8263038cce7fa6e464120a6a80cc9bb67343087c" translate="yes" xml:space="preserve">
          <source>Starts reading from current position in file.</source>
          <target state="translated">파일의 현재 위치에서 읽기를 시작합니다.</target>
        </trans-unit>
        <trans-unit id="e91bf74af9bf0945d6f92cab271e149069e0083c" translate="yes" xml:space="preserve">
          <source>Starts the handler's workers.</source>
          <target state="translated">처리기의 작업자를 시작합니다.</target>
        </trans-unit>
        <trans-unit id="d4baf635ff2545da5d38edb917b754f17529ea58" translate="yes" xml:space="preserve">
          <source>Starts this server.</source>
          <target state="translated">이 서버를 시작합니다.</target>
        </trans-unit>
        <trans-unit id="4342bc56c343c89819e7b2431ab23a0028e31c50" translate="yes" xml:space="preserve">
          <source>Stateful operations, such as variables and queues, can maintain their states on devices so that they can be shared by multiple processes. A resource container is a string name under which these stateful operations are tracked. These resources can be released or cleared with &lt;code&gt;tf.Session.reset()&lt;/code&gt;.</source>
          <target state="translated">변수 및 대기열과 같은 상태 저장 작업은 여러 프로세스에서 공유 할 수 있도록 장치에서 상태를 유지할 수 있습니다. 리소스 컨테이너는 이러한 상태 저장 작업이 추적되는 문자열 이름입니다. 이러한 리소스는 &lt;code&gt;tf.Session.reset()&lt;/code&gt; 으로 해제하거나 해제 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="2656236f800a76ebc0f7b49c14ff22e2c68fde8c" translate="yes" xml:space="preserve">
          <source>Static assert that values is a &quot;proper&quot; iterable.</source>
          <target state="translated">정적은 값이 &quot;적절한&quot;반복 가능하다고 주장합니다.</target>
        </trans-unit>
        <trans-unit id="ffa05fac8dc7f5a7d7afa20754fed148f2437c90" translate="yes" xml:space="preserve">
          <source>Statically asserts that the given &lt;code&gt;Tensor&lt;/code&gt; is of the specified type.</source>
          <target state="translated">주어진 &lt;code&gt;Tensor&lt;/code&gt; 가 지정된 유형 임을 정적으로 주장합니다 .</target>
        </trans-unit>
        <trans-unit id="60df8ae87178e3ec5ce8d8d0fa30901d76174405" translate="yes" xml:space="preserve">
          <source>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)**2] is also undefined.</source>
          <target state="translated">의미가있는 경우 통계는 +/- 무한대를 반환합니다. 예를 들어, 코시 분포의 분산은 무한대입니다. 그러나 때로는 통계가 정의되지 않은 경우도 있습니다. 예를 들어, 배포의 pdf가 배포 지원 범위 내에서 최대 값을 달성하지 못하면 모드가 정의되지 않습니다. 평균이 정의되지 않은 경우 정의에 따라 분산이 정의되지 않습니다. 예를 들어 df = 1에 대한 Student 's T의 평균은 정의되지 않았으므로 (+ 또는-무한대라고 말할 수있는 명확한 방법은 없음) 분산 = E [(X-mean) ** 2]도 정의되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="22071530d6c4d9de4a3df64a6b62d022124955f6" translate="yes" xml:space="preserve">
          <source>Steps 2 through 4 are done automatically by class &lt;a href=&quot;../../../keras/optimizers/optimizer&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt;&lt;/a&gt; if you call its &lt;a href=&quot;../../../keras/optimizers/optimizer#apply_gradients&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer.apply_gradients&lt;/code&gt;&lt;/a&gt; method in a replica context. They are also done automatically if you call an &lt;code&gt;assign*&lt;/code&gt; method on a (non sync-on-read) variable that was constructed with an aggregation method (which is used to determine the reduction used in step 3).</source>
          <target state="translated">복제 컨텍스트에서 &lt;a href=&quot;../../../keras/optimizers/optimizer#apply_gradients&quot;&gt; &lt;code&gt;tf.keras.optimizers.Optimizer.apply_gradients&lt;/code&gt; &lt;/a&gt; 메소드 를 호출하면 2-4 단계는 클래스 &lt;a href=&quot;../../../keras/optimizers/optimizer&quot;&gt; &lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt; 에&lt;/a&gt; 의해 자동으로 수행됩니다 . 또한 집계 방법 (3 단계에서 사용 된 감소를 결정하는 데 사용됨)으로 구성된 (읽지 않은 비 동기화) 변수 에서 &lt;code&gt;assign*&lt;/code&gt; 메서드 를 호출하면 자동으로 수행됩니다 .</target>
        </trans-unit>
        <trans-unit id="f210a94770e322853957792583d184bd18568f9b" translate="yes" xml:space="preserve">
          <source>Steps 2 through 4 are done automatically by class &lt;a href=&quot;../keras/optimizers/optimizer&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt;&lt;/a&gt; if you call its &lt;a href=&quot;../keras/optimizers/optimizer#apply_gradients&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer.apply_gradients&lt;/code&gt;&lt;/a&gt; method in a replica context. They are also done automatically if you call an &lt;code&gt;assign*&lt;/code&gt; method on a (non sync-on-read) variable that was constructed with an aggregation method (which is used to determine the reduction used in step 3).</source>
          <target state="translated">복제 컨텍스트에서 &lt;a href=&quot;../keras/optimizers/optimizer#apply_gradients&quot;&gt; &lt;code&gt;tf.keras.optimizers.Optimizer.apply_gradients&lt;/code&gt; &lt;/a&gt; 메소드 를 호출하면 2-4 단계는 클래스 &lt;a href=&quot;../keras/optimizers/optimizer&quot;&gt; &lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt; 에&lt;/a&gt; 의해 자동으로 수행됩니다 . 또한 집계 방법 (3 단계에서 사용 된 감소를 결정하는 데 사용됨)으로 구성된 (읽지 않은 비 동기화) 변수 에서 &lt;code&gt;assign*&lt;/code&gt; 메서드 를 호출하면 자동으로 수행됩니다 .</target>
        </trans-unit>
        <trans-unit id="85a411ea2f2761d1ddcb88eb51ad0e8e10187389" translate="yes" xml:space="preserve">
          <source>Stochastic Dual Coordinate Ascent helper for linear estimators.</source>
          <target state="translated">선형 추정기의 확률 적 이중 좌표 상승 도우미.</target>
        </trans-unit>
        <trans-unit id="5db97c77f8ae58c61c9d9965b48bf1937ae6418f" translate="yes" xml:space="preserve">
          <source>Stochastic gradient descent and momentum optimizer.</source>
          <target state="translated">확률 적 경사 하강 및 운동량 최적화.</target>
        </trans-unit>
        <trans-unit id="133b83393780c8ea9a29cf07bcedf37ff11c6738" translate="yes" xml:space="preserve">
          <source>Stop condition: In order to support both distributed and non-distributed configuration reliably, the only supported stop condition for model training is &lt;code&gt;train_spec.max_steps&lt;/code&gt;. If &lt;code&gt;train_spec.max_steps&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt;, the model is trained forever. &lt;em&gt;Use with care&lt;/em&gt; if model stop condition is different. For example, assume that the model is expected to be trained with one epoch of training data, and the training &lt;code&gt;input_fn&lt;/code&gt; is configured to throw &lt;code&gt;OutOfRangeError&lt;/code&gt; after going through one epoch, which stops the &lt;a href=&quot;../compat/v1/estimator/estimator#train&quot;&gt;&lt;code&gt;Estimator.train&lt;/code&gt;&lt;/a&gt;. For a three-training-worker distributed configuration, each training worker is likely to go through the whole epoch independently. So, the model will be trained with three epochs of training data instead of one epoch.</source>
          <target state="translated">정지 조건 : 분산 및 비 분산 구성을 확실하게 지원하기 위해 모델 교육에 지원되는 유일한 정지 조건은 &lt;code&gt;train_spec.max_steps&lt;/code&gt; 입니다. &lt;code&gt;train_spec.max_steps&lt;/code&gt; 인 경우 없습니다 &lt;code&gt;None&lt;/code&gt; 모델은 영원히 훈련. 모델 정지 조건이 다른 경우 &lt;em&gt;주의해서 사용하십시오&lt;/em&gt; . 예를 들어, 모델이 하나의 에포크 교육 데이터로 훈련 될 것으로 예상되고, 훈련 &lt;code&gt;input_fn&lt;/code&gt; 이 하나의 에포크를 &lt;code&gt;OutOfRangeError&lt;/code&gt; 후 OutOfRangeError를 발생 시키도록 구성되어 &lt;a href=&quot;../compat/v1/estimator/estimator#train&quot;&gt; &lt;code&gt;Estimator.train&lt;/code&gt; &lt;/a&gt; 을 중지 한다고 가정 하십시오.. 3 명의 교육 담당자 분산 구성의 경우 각 교육 담당자는 전체 시대를 독립적으로 거치게됩니다. 따라서 모델은 하나의 에포크 대신 세 개의 에포크 교육 데이터로 학습됩니다.</target>
        </trans-unit>
        <trans-unit id="0b73c19e56bb305894a3de5407fb01e4f9a8fe89" translate="yes" xml:space="preserve">
          <source>Stop the services and the coordinator.</source>
          <target state="translated">서비스와 코디네이터를 중지하십시오.</target>
        </trans-unit>
        <trans-unit id="acaf908480f4f7513719d5d37193f12e822e8df4" translate="yes" xml:space="preserve">
          <source>Stop training when a monitored quantity has stopped improving.</source>
          <target state="translated">모니터링 된 수량의 개선이 중단되면 훈련을 중단하십시오.</target>
        </trans-unit>
        <trans-unit id="5492e7af5bc227efd8741534cde9d83c515b2fee" translate="yes" xml:space="preserve">
          <source>StopIteration</source>
          <target state="translated">StopIteration</target>
        </trans-unit>
        <trans-unit id="7ca958edd4ae9334803b83d98f9fa435aceacaef" translate="yes" xml:space="preserve">
          <source>Stops and exports the active trace as a Summary and/or profile file.</source>
          <target state="translated">활성 추적을 요약 및 / 또는 프로필 파일로 중지하고 내 보냅니다.</target>
        </trans-unit>
        <trans-unit id="55a9229e4f89292e865188cb6a0d2d8542aff987" translate="yes" xml:space="preserve">
          <source>Stops gradient computation.</source>
          <target state="translated">그래디언트 계산을 중지합니다.</target>
        </trans-unit>
        <trans-unit id="e4e14f4106f6a3870d0e38ef853369d42ee937fd" translate="yes" xml:space="preserve">
          <source>Stops running threads and wait for them to exit, if necessary.</source>
          <target state="translated">스레드 실행을 중지하고 필요한 경우 종료 될 때까지 기다리십시오.</target>
        </trans-unit>
        <trans-unit id="9b208b5f31ff1c56cafbcbee9b5e3c8091431b21" translate="yes" xml:space="preserve">
          <source>Stops the current trace and discards any collected information.</source>
          <target state="translated">현재 추적을 중지하고 수집 된 정보를 버립니다.</target>
        </trans-unit>
        <trans-unit id="2d87fc3a0f3a70413df9f203b126effeeeda2c89" translate="yes" xml:space="preserve">
          <source>Stops the trace and exports all metadata collected during the trace to the default SummaryWriter, if one has been set.</source>
          <target state="translated">추적을 중지하고 추적 중에 수집 된 모든 메타 데이터를 설정된 경우 기본 SummaryWriter로 내 보냅니다.</target>
        </trans-unit>
        <trans-unit id="498891dd84278fabc1afd5025cb9d7776029cb2e" translate="yes" xml:space="preserve">
          <source>Stores &lt;code&gt;value&lt;/code&gt; in the collection with the given &lt;code&gt;name&lt;/code&gt;.</source>
          <target state="translated">주어진 &lt;code&gt;name&lt;/code&gt; 컬렉션에 &lt;code&gt;value&lt;/code&gt; 을 저장 합니다 .</target>
        </trans-unit>
        <trans-unit id="7487de8aca0f8eb26902fa7d5921abad1adb56f6" translate="yes" xml:space="preserve">
          <source>Stores &lt;code&gt;value&lt;/code&gt; in the collections given by &lt;code&gt;names&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;names&lt;/code&gt; 지정된 컬렉션에 &lt;code&gt;value&lt;/code&gt; 을 저장 합니다 .</target>
        </trans-unit>
        <trans-unit id="a8ad5005cffff07e7ce60dc5e8a6e835ce897462" translate="yes" xml:space="preserve">
          <source>Stores two elements: &lt;code&gt;(c, h)&lt;/code&gt;, in that order. Where &lt;code&gt;c&lt;/code&gt; is the hidden state and &lt;code&gt;h&lt;/code&gt; is the output.</source>
          <target state="translated">&lt;code&gt;(c, h)&lt;/code&gt; 두 요소 를 순서대로 저장합니다. 여기서 &lt;code&gt;c&lt;/code&gt; 는 숨겨진 상태이고 &lt;code&gt;h&lt;/code&gt; 는 출력입니다.</target>
        </trans-unit>
        <trans-unit id="2dae3f8a26c540bddc508bd4fc20a264913a3400" translate="yes" xml:space="preserve">
          <source>Strict nesting also applies to combinations of &lt;code&gt;ForwardAccumulator&lt;/code&gt; and &lt;a href=&quot;../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;. More deeply nested &lt;code&gt;GradientTape&lt;/code&gt; objects will ignore the products of outer &lt;code&gt;ForwardAccumulator&lt;/code&gt; objects. This allows (for example) memory-efficient forward-over-backward computation of Hessian-vector products, where the inner &lt;code&gt;GradientTape&lt;/code&gt; would otherwise hold on to all intermediate JVPs:</source>
          <target state="translated">엄격한 중첩은 &lt;code&gt;ForwardAccumulator&lt;/code&gt; 와 &lt;a href=&quot;../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; 의&lt;/a&gt; 조합에도 적용됩니다 . 더 깊이 중첩 된 &lt;code&gt;GradientTape&lt;/code&gt; 객체는 외부 &lt;code&gt;ForwardAccumulator&lt;/code&gt; 객체 의 제품을 무시 합니다. 이를 통해 (예를 들어) 내부 &lt;code&gt;GradientTape&lt;/code&gt; 가 모든 중간 JVP를 유지할 수있는 Hessian- 벡터 제품의 메모리 효율적인 순방향 역전 계산이 가능합니다.</target>
        </trans-unit>
        <trans-unit id="1491a3bd88f9e10c7ce3a5a0f1112506bd8f631c" translate="yes" xml:space="preserve">
          <source>String denoting the name attribute of the input function</source>
          <target state="translated">입력 함수의 이름 속성을 나타내는 문자열</target>
        </trans-unit>
        <trans-unit id="7b4c8e7832ea4bb28fb1ecea1eb04c21acf3235a" translate="yes" xml:space="preserve">
          <source>String lengths of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">의 문자열 길이를 &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="9c2aad5c6a931d4c7513d72ecffc8d9eb68b3cc5" translate="yes" xml:space="preserve">
          <source>String paths to latest checkpoint files as they arrive.</source>
          <target state="translated">최신 검사 점 파일이 도착할 때의 문자열 경로.</target>
        </trans-unit>
        <trans-unit id="aeb494b5d1b54f48ea849048d1edcfe06dd51044" translate="yes" xml:space="preserve">
          <source>String to Id table wrapper that assigns out-of-vocabulary keys to buckets.</source>
          <target state="translated">어휘 외의 키를 버킷에 할당하는 문자열 대 ID 테이블 래퍼입니다.</target>
        </trans-unit>
        <trans-unit id="aaa81af7916f61c4c8df3b14acde35215be76a44" translate="yes" xml:space="preserve">
          <source>String, dtype of &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="translated">문자열의 DTYPE &lt;code&gt;x&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ea9f5b6cc332ffad44ba87818cd1c1307282d6c3" translate="yes" xml:space="preserve">
          <source>String, path to the saved model</source>
          <target state="translated">문자열, 저장된 모델의 경로</target>
        </trans-unit>
        <trans-unit id="a0a3d9cd808b86047665f49535c974af481846b3" translate="yes" xml:space="preserve">
          <source>String, path where to save the model</source>
          <target state="translated">문자열, 모델을 저장할 경로</target>
        </trans-unit>
        <trans-unit id="54bc218b3ac398424451a14065ba255b110489cd" translate="yes" xml:space="preserve">
          <source>String, the current default float type.</source>
          <target state="translated">현재 기본 부동 유형 인 문자열</target>
        </trans-unit>
        <trans-unit id="57e5867b01bfc07f9eb74efe89e78ace68c7ff5a" translate="yes" xml:space="preserve">
          <source>String: name of an optimizer</source>
          <target state="translated">문자열 : 옵티 마이저 이름</target>
        </trans-unit>
        <trans-unit id="4783a53435e04475242288debdaae1f5d02699bf" translate="yes" xml:space="preserve">
          <source>Strings.</source>
          <target state="translated">Strings.</target>
        </trans-unit>
        <trans-unit id="66bf723a15be4c8e82544fa8db7d3459828330ba" translate="yes" xml:space="preserve">
          <source>Strip leading and trailing whitespaces from the Tensor.</source>
          <target state="translated">텐서에서 앞뒤 공백을 제거합니다.</target>
        </trans-unit>
        <trans-unit id="f350b1261d4080472d67731c5c9e2f0603eeb906" translate="yes" xml:space="preserve">
          <source>Structure to create or gather pieces commonly needed to train a model.</source>
          <target state="translated">모델 훈련에 일반적으로 필요한 조각을 생성하거나 수집하는 구조입니다.</target>
        </trans-unit>
        <trans-unit id="7c98ab4418a813d6b943f2b02fac0d62645ae018" translate="yes" xml:space="preserve">
          <source>Student's t-distribution.</source>
          <target state="translated">학생의 t- 분포.</target>
        </trans-unit>
        <trans-unit id="7ffaefd8b7f218faf62448be773733b362a94c3c" translate="yes" xml:space="preserve">
          <source>Subclasses are expected to implement a leading-underscore version of the same-named function. The argument signature should be identical except for the omission of &lt;code&gt;name=&quot;...&quot;&lt;/code&gt;. For example, to enable &lt;code&gt;log_prob(value, name=&quot;log_prob&quot;)&lt;/code&gt; a subclass should implement &lt;code&gt;_log_prob(value)&lt;/code&gt;.</source>
          <target state="translated">서브 클래스는 동일한 이름을 가진 함수의 밑줄이 그어진 버전을 구현할 것으로 예상됩니다. &lt;code&gt;name=&quot;...&quot;&lt;/code&gt; 생략을 제외하고 인수 서명은 동일해야합니다 . 예를 들어, &lt;code&gt;log_prob(value, name=&quot;log_prob&quot;)&lt;/code&gt; 를 활성화 하려면 서브 클래스가 &lt;code&gt;_log_prob(value)&lt;/code&gt; 구현해야합니다 .</target>
        </trans-unit>
        <trans-unit id="2a6721e7c506f9fb97672ded9cc77a3beb182cd0" translate="yes" xml:space="preserve">
          <source>Subclasses can append to public-level docstrings by providing docstrings for their method specializations. For example:</source>
          <target state="translated">서브 클래스는 메소드 전문화를 위해 docstring을 제공하여 공개 레벨 docstring에 추가 할 수 있습니다. 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="7aec789137a8d9a01ede9775ea920d915b4cb613" translate="yes" xml:space="preserve">
          <source>Subclasses of &lt;a href=&quot;module&quot;&gt;&lt;code&gt;tf.Module&lt;/code&gt;&lt;/a&gt; can also take advantage of the &lt;code&gt;_flatten&lt;/code&gt; method which can be used to implement tracking of any other types.</source>
          <target state="translated">의 서브 클래스 &lt;a href=&quot;module&quot;&gt; &lt;code&gt;tf.Module&lt;/code&gt; 는&lt;/a&gt; 도 활용할 수 있습니다 &lt;code&gt;_flatten&lt;/code&gt; 다른 유형의 추적을 구현하는 데 사용할 수있는 메소드를 활용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="6710338017625456fa4561184c0ed0ef98bc5b38" translate="yes" xml:space="preserve">
          <source>Subclasses of &lt;code&gt;LinearOperator&lt;/code&gt; provide access to common methods on a (batch) matrix, without the need to materialize the matrix. This allows:</source>
          <target state="translated">&lt;code&gt;LinearOperator&lt;/code&gt; 의 서브 클래스는 매트릭스를 구체화 할 필요없이 (배치) 매트릭스에서 공통 메소드에 액세스 할 수 있도록합니다. 이를 통해 다음이 가능합니다.</target>
        </trans-unit>
        <trans-unit id="42876d8a9661050716824a58ac5a82c08c248d20" translate="yes" xml:space="preserve">
          <source>Subclasses should also define a syntactic_help string which may be presented to the user to describe the form of the legal values.</source>
          <target state="translated">서브 클래스는 또한 유효한 값의 형식을 설명하기 위해 사용자에게 제공 될 수있는 syntactic_help 문자열을 정의해야합니다.</target>
        </trans-unit>
        <trans-unit id="aea78081ca45ef2980de5a15e286ad2bbda54156" translate="yes" xml:space="preserve">
          <source>Subclasses should only implement the assert methods (e.g. &lt;code&gt;assert_non_singular&lt;/code&gt;) if they can be done in less than &lt;code&gt;O(N^3)&lt;/code&gt; time.</source>
          <target state="translated">서브 클래스는 &lt;code&gt;O(N^3)&lt;/code&gt; 시간 이내에 완료 될 수있는 경우 에만 assert 메소드 (예 : &lt;code&gt;assert_non_singular&lt;/code&gt; )를 구현해야합니다 .</target>
        </trans-unit>
        <trans-unit id="cf637286e0e32e92c7c31e4552b50b7fae1598ef" translate="yes" xml:space="preserve">
          <source>Subclasses should override class method &lt;code&gt;_param_shapes&lt;/code&gt; to return constant-valued tensors when constant values are fed.</source>
          <target state="translated">상수 값이 제공 될 때 상수 값 텐서를 반환하도록 서브 클래스는 클래스 메소드 &lt;code&gt;_param_shapes&lt;/code&gt; 를 대체해야합니다 .</target>
        </trans-unit>
        <trans-unit id="37df94753f92ace08cbf9f39640c831c989de432" translate="yes" xml:space="preserve">
          <source>Subclasses should override class method &lt;code&gt;_param_shapes&lt;/code&gt;.</source>
          <target state="translated">서브 클래스는 클래스 메소드 &lt;code&gt;_param_shapes&lt;/code&gt; 를 대체해야합니다. .</target>
        </trans-unit>
        <trans-unit id="8ce7d0131be24554322a374d91443a37c9bff932" translate="yes" xml:space="preserve">
          <source>Subclasses should override for any actions to run.</source>
          <target state="translated">조치를 실행하려면 서브 클래스를 대체해야합니다.</target>
        </trans-unit>
        <trans-unit id="a7a01ff259fb1b5c2717e8c75756ea59f3bfc673" translate="yes" xml:space="preserve">
          <source>Subclasses should override for any actions to run. This function should only be called during TRAIN mode.</source>
          <target state="translated">조치를 실행하려면 서브 클래스를 대체해야합니다. 이 기능은 TRAIN 모드에서만 호출해야합니다.</target>
        </trans-unit>
        <trans-unit id="82494d5df2327066831b19fcbdbc11f57f406da0" translate="yes" xml:space="preserve">
          <source>Subclassing</source>
          <target state="translated">Subclassing</target>
        </trans-unit>
        <trans-unit id="4ee2b1df95332be247a338e3703c536ed3849d29" translate="yes" xml:space="preserve">
          <source>Submodules are modules which are properties of this module, or found as properties of modules which are properties of this module (and so on).</source>
          <target state="translated">서브 모듈은이 모듈의 속성이거나이 모듈의 속성 인 모듈의 속성 등으로 알려진 모듈입니다.</target>
        </trans-unit>
        <trans-unit id="165eb6fe055989673d9f7ff7fc05154aebafbb3c" translate="yes" xml:space="preserve">
          <source>Subtracts &lt;a href=&quot;../../indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt; from this variable.</source>
          <target state="translated">이 변수에서 &lt;a href=&quot;../../indexedslices&quot;&gt; &lt;code&gt;tf.IndexedSlices&lt;/code&gt; &lt;/a&gt; 를 뺍니다 .</target>
        </trans-unit>
        <trans-unit id="f35f0686291951a05d8c56e0435069d27921f5e4" translate="yes" xml:space="preserve">
          <source>Subtracts &lt;a href=&quot;indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt; from this variable.</source>
          <target state="translated">이 변수에서 &lt;a href=&quot;indexedslices&quot;&gt; &lt;code&gt;tf.IndexedSlices&lt;/code&gt; &lt;/a&gt; 를 뺍니다 .</target>
        </trans-unit>
        <trans-unit id="862f9417a21c1ab694eec964a2530921649cc05a" translate="yes" xml:space="preserve">
          <source>Subtracts a value from this variable.</source>
          <target state="translated">이 변수에서 값을 뺍니다.</target>
        </trans-unit>
        <trans-unit id="533efd56cc6494d580885f7e5b88d2e19d328bec" translate="yes" xml:space="preserve">
          <source>Subtracts sparse &lt;code&gt;updates&lt;/code&gt; from an existing tensor according to &lt;code&gt;indices&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;indices&lt;/code&gt; 에 따라 기존 텐서에서 희소 &lt;code&gt;updates&lt;/code&gt; 를 뺍니다 .</target>
        </trans-unit>
        <trans-unit id="f7f817b1800d31c4059e5eec01c90ea508fa2de1" translate="yes" xml:space="preserve">
          <source>Subtracts sparse updates to a variable reference.</source>
          <target state="translated">변수 참조에 대한 희소 업데이트를 뺍니다.</target>
        </trans-unit>
        <trans-unit id="ffab6af063b75339c2da62f252c5b9fd21c5a8b2" translate="yes" xml:space="preserve">
          <source>Such a boolean flag does not take an argument. If a user wants to specify a false value explicitly, the long option beginning with 'no' must be used: i.e. --noflag</source>
          <target state="translated">이러한 부울 플래그는 인수를 사용하지 않습니다. 사용자가 명시 적으로 false 값을 지정하려면 'no'로 시작하는 긴 옵션을 사용해야합니다. 즉 --noflag</target>
        </trans-unit>
        <trans-unit id="6a79dcd29d4b3b6000264a88496dc0b21c3bb9bd" translate="yes" xml:space="preserve">
          <source>Suitable for passing to &lt;a href=&quot;checkpoint#restore&quot;&gt;&lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt;&lt;/a&gt; to resume training.</source>
          <target state="translated">&lt;a href=&quot;checkpoint#restore&quot;&gt; &lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt; &lt;/a&gt; 로 전달하기에 적합훈련을 재개 로 .</target>
        </trans-unit>
        <trans-unit id="0767ec9c89c14ac885f6aac10f61d8b491a9b0fe" translate="yes" xml:space="preserve">
          <source>Sum of concentration parameters.</source>
          <target state="translated">농도 매개 변수의 합.</target>
        </trans-unit>
        <trans-unit id="8e620e3b949e70befef0ae092fde25014ac70320" translate="yes" xml:space="preserve">
          <source>Sum of last dim of concentration parameter.</source>
          <target state="translated">마지막 농도의 희미한 파라미터의 합입니다.</target>
        </trans-unit>
        <trans-unit id="828ac024d0a463272c3865c79e2c0bf52a749629" translate="yes" xml:space="preserve">
          <source>Sum of the values in a tensor, alongside the specified axis.</source>
          <target state="translated">지정된 축과 함께 텐서의 값의 합입니다.</target>
        </trans-unit>
        <trans-unit id="099c5812d8fa488a0e61fa106c074634bb1f9d7f" translate="yes" xml:space="preserve">
          <source>Sum the input tensor across replicas according to group_assignment.</source>
          <target state="translated">group_assignment에 따라 복제본에서 입력 텐서를 합산하십시오.</target>
        </trans-unit>
        <trans-unit id="10af7e4de27c05194aa88c5baa285ca841cf04ab" translate="yes" xml:space="preserve">
          <source>Sum the weights of false positives.</source>
          <target state="translated">오 탐지의 가중치를 합산하십시오.</target>
        </trans-unit>
        <trans-unit id="2a3284e36f760f4254131fea54732c3ba499239f" translate="yes" xml:space="preserve">
          <source>Sum the weights of true_negatives.</source>
          <target state="translated">true_negatives의 가중치를 합산하십시오.</target>
        </trans-unit>
        <trans-unit id="42dd5be548c1e47f53fdb48f3d5c971ee04367e9" translate="yes" xml:space="preserve">
          <source>Sum the weights of true_positives.</source>
          <target state="translated">true_positives의 가중치를 합산하십시오.</target>
        </trans-unit>
        <trans-unit id="8333177a21c8e3581d5ed83f3b343cfae98cec5f" translate="yes" xml:space="preserve">
          <source>Summarizes textual data.</source>
          <target state="translated">텍스트 데이터를 요약합니다.</target>
        </trans-unit>
        <trans-unit id="b079c2d8619aadef5a47beee8545f1de33276597" translate="yes" xml:space="preserve">
          <source>Support class for stubbing methods out for unit testing.</source>
          <target state="translated">단위 테스트를 위해 스텁 메소드를 지원하기위한 지원 클래스.</target>
        </trans-unit>
        <trans-unit id="7c570510ec02530b48ce8c6a2822119f29cc294e" translate="yes" xml:space="preserve">
          <source>Support for training models.</source>
          <target state="translated">훈련 모델을 지원합니다.</target>
        </trans-unit>
        <trans-unit id="9f45023b45c5bcb0e2e566e86c212c8ad3099045" translate="yes" xml:space="preserve">
          <source>Support wide range of machine learning models. Since most heads can work with logits, they can support DNN, RNN, Wide, Wide&amp;amp;Deep, Global objectives, Gradient boosted trees and many other types of machine learning models.</source>
          <target state="translated">광범위한 머신 러닝 모델을 지원합니다. 대부분의 헤드는 로짓으로 작업 할 수 있으므로 DNN, RNN, Wide, Wide &amp;amp; Deep, Global objectives, Gradient boosted tree 및 기타 여러 유형의 머신 러닝 모델을 지원할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7ca7b2b776a1a659ec26ed62726c8ba0fc984e92" translate="yes" xml:space="preserve">
          <source>Supported Python entities include: * functions * classes * object methods</source>
          <target state="translated">지원되는 Python 엔티티는 다음과 같습니다. * 함수 * 클래스 * 객체 메소드</target>
        </trans-unit>
        <trans-unit id="8ce9158bd839abeef632632d7ada1c1f6e0c0ccf" translate="yes" xml:space="preserve">
          <source>Supported attribute includes micros, bytes, occurrence, params, etc. https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/g3doc/options.md</source>
          <target state="translated">지원되는 속성에는 마이크로, 바이트, 발생, 매개 변수 등이 포함됩니다. https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/g3doc/options.md</target>
        </trans-unit>
        <trans-unit id="9794d24ec85271049a86498f820c37d015564882" translate="yes" xml:space="preserve">
          <source>Supported types</source>
          <target state="translated">지원되는 유형</target>
        </trans-unit>
        <trans-unit id="abd5978641e98b805d5cc09691807cae3f3387cc" translate="yes" xml:space="preserve">
          <source>Supports all values that can be represented as a string, including 1D iterables such as np.ndarray.</source>
          <target state="translated">np.ndarray와 같은 1D 이터 러블을 포함하여 문자열로 표현할 수있는 모든 값을 지원합니다.</target>
        </trans-unit>
        <trans-unit id="104d684cf03eff52e2dbd8ee731bf94a0c3b8a59" translate="yes" xml:space="preserve">
          <source>Supports custom &lt;code&gt;loss_fn&lt;/code&gt;. &lt;code&gt;loss_fn&lt;/code&gt; takes &lt;code&gt;(labels, logits)&lt;/code&gt; or &lt;code&gt;(labels, logits, features, loss_reduction)&lt;/code&gt; as arguments and returns unreduced loss with shape &lt;code&gt;[D0, D1, ... DN, label_dimension]&lt;/code&gt;.</source>
          <target state="translated">사용자 정의 &lt;code&gt;loss_fn&lt;/code&gt; 을 지원합니다 . &lt;code&gt;loss_fn&lt;/code&gt; 은 &lt;code&gt;(labels, logits)&lt;/code&gt; 또는 &lt;code&gt;(labels, logits, features, loss_reduction)&lt;/code&gt; 을 인수로 취하고 모양이 &lt;code&gt;[D0, D1, ... DN, label_dimension]&lt;/code&gt; 감소되지 않은 손실을 반환합니다 .</target>
        </trans-unit>
        <trans-unit id="a316cf92878313bf869404b90ceec201fde29a87" translate="yes" xml:space="preserve">
          <source>Supports loading into partitioned variables, which are represented as &lt;code&gt;'&amp;lt;variable&amp;gt;/part_&amp;lt;part #&amp;gt;'&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;'&amp;lt;variable&amp;gt;/part_&amp;lt;part #&amp;gt;'&lt;/code&gt; 로 표시되는 파티션 된 변수로의로드를 지원합니다 .</target>
        </trans-unit>
        <trans-unit id="e964d3014915281d079adadf918032ad21ee9376" translate="yes" xml:space="preserve">
          <source>Supports many numeric types and boolean.</source>
          <target state="translated">많은 숫자 유형과 부울을 지원합니다.</target>
        </trans-unit>
        <trans-unit id="f7d38c23447a54dd0a8a5a8f23ba246013d5bca2" translate="yes" xml:space="preserve">
          <source>Supports multidimensional indexing and slicing, with one restriction: indexing into a ragged inner dimension is not allowed. This case is problematic because the indicated value may exist in some rows but not others. In such cases, it's not obvious whether we should (1) report an IndexError; (2) use a default value; or (3) skip that value and return a tensor with fewer rows than we started with. Following the guiding principles of Python (&quot;In the face of ambiguity, refuse the temptation to guess&quot;), we simply disallow this operation.</source>
          <target state="translated">한 차원의 제한으로 다차원 인덱싱 및 슬라이싱을 지원합니다. 비정형 내부 차원으로 인덱싱 할 수 없습니다. 이 값은 표시된 값이 일부 행에 존재할 수 있지만 다른 행에는 존재하지 않기 때문에 문제가됩니다. 그러한 경우, 우리가 (1) IndexError를보고해야하는지의 여부는 확실하지 않다. (2) 기본값을 사용하십시오. 또는 (3) 그 값을 건너 뛰고 시작했던 것보다 적은 행을 가진 텐서를 반환합니다. 파이썬의지도 원칙 ( &quot;모호함에 직면하여 추측하려는 유혹을 거부한다&quot;)에 따라, 우리는 단순히이 동작을 허용하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="465d7f75658c4dd0bcc894320c0de2a6164e5f1f" translate="yes" xml:space="preserve">
          <source>Suppose &lt;code&gt;H.shape = [B1,...,Bb, N0, N1, N2]&lt;/code&gt;, we say that &lt;code&gt;H&lt;/code&gt; is a Hermitian spectrum if, with &lt;code&gt;%&lt;/code&gt; meaning modulus division,</source>
          <target state="translated">가정 &lt;code&gt;H.shape = [B1,...,Bb, N0, N1, N2]&lt;/code&gt; , 우리는 말할 &lt;code&gt;H&lt;/code&gt; 는 허미 시안 스펙트럼으로, 만약 &lt;code&gt;%&lt;/code&gt; 로 계수 분할을 의미</target>
        </trans-unit>
        <trans-unit id="f72a981b2d0bc9ee25053f2c6bb8efd804f77034" translate="yes" xml:space="preserve">
          <source>Suppose &lt;code&gt;H.shape = [B1,...,Bb, N0, N1]&lt;/code&gt;, we say that &lt;code&gt;H&lt;/code&gt; is a Hermitian spectrum if, with &lt;code&gt;%&lt;/code&gt; indicating modulus division,</source>
          <target state="translated">가정 &lt;code&gt;H.shape = [B1,...,Bb, N0, N1]&lt;/code&gt; , 우리는 말할 &lt;code&gt;H&lt;/code&gt; 는 허미 시안 스펙트럼 경우 함께이다 &lt;code&gt;%&lt;/code&gt; , 모듈러스 나눗셈을 나타내는</target>
        </trans-unit>
        <trans-unit id="69e9539be0d74edf27965ae7808985529de3daca" translate="yes" xml:space="preserve">
          <source>Suppose &lt;code&gt;H.shape = [B1,...,Bb, N]&lt;/code&gt;. We say that &lt;code&gt;H&lt;/code&gt; is a Hermitian spectrum if, with &lt;code&gt;%&lt;/code&gt; meaning modulus division,</source>
          <target state="translated">&lt;code&gt;H.shape = [B1,...,Bb, N]&lt;/code&gt; 이라고 가정하십시오 . 우리는 말할 &lt;code&gt;H&lt;/code&gt; 는 에르 미트 스펙트럼 경우가와입니다 &lt;code&gt;%&lt;/code&gt; 모듈로 나눗셈을 의미 .</target>
        </trans-unit>
        <trans-unit id="9c13ea8e213e123c5d46aca6ff82c0ff6d54078b" translate="yes" xml:space="preserve">
          <source>Suppose &lt;code&gt;operator&lt;/code&gt; is a &lt;code&gt;LinearOperatorCirculant&lt;/code&gt; of shape &lt;code&gt;[N, N]&lt;/code&gt;, and &lt;code&gt;x.shape = [N, R]&lt;/code&gt;. Then</source>
          <target state="translated">가정하자 &lt;code&gt;operator&lt;/code&gt; A는 &lt;code&gt;LinearOperatorCirculant&lt;/code&gt; 형상을 &lt;code&gt;[N, N]&lt;/code&gt; , 및 &lt;code&gt;x.shape = [N, R]&lt;/code&gt; . 그때</target>
        </trans-unit>
        <trans-unit id="c7ae0d4dbc265f3305695b532a6acdf5985ab031" translate="yes" xml:space="preserve">
          <source>Suppose &lt;code&gt;operator&lt;/code&gt; is a &lt;code&gt;LinearOperatorDiag&lt;/code&gt; of shape &lt;code&gt;[N, N]&lt;/code&gt;, and &lt;code&gt;x.shape = [N, R]&lt;/code&gt;. Then</source>
          <target state="translated">&lt;code&gt;operator&lt;/code&gt; 가 모양 &lt;code&gt;[N, N]&lt;/code&gt; 이고 &lt;code&gt;x.shape = [N, R]&lt;/code&gt; &lt;code&gt;LinearOperatorDiag&lt;/code&gt; 라고 가정합니다 . 그때</target>
        </trans-unit>
        <trans-unit id="0ba1a907b3f27c40ff85272978f14bd8fe9cc06b" translate="yes" xml:space="preserve">
          <source>Suppose &lt;code&gt;operator&lt;/code&gt; is a &lt;code&gt;LinearOperatorLowRankUpdate&lt;/code&gt; of shape &lt;code&gt;[M, N]&lt;/code&gt;, made from a rank &lt;code&gt;K&lt;/code&gt; update of &lt;code&gt;base_operator&lt;/code&gt; which performs &lt;code&gt;.matmul(x)&lt;/code&gt; on &lt;code&gt;x&lt;/code&gt; having &lt;code&gt;x.shape = [N, R]&lt;/code&gt; with &lt;code&gt;O(L_matmul*N*R)&lt;/code&gt; complexity (and similarly for &lt;code&gt;solve&lt;/code&gt;, &lt;code&gt;determinant&lt;/code&gt;. Then, if &lt;code&gt;x.shape = [N, R]&lt;/code&gt;,</source>
          <target state="translated">가정하자 &lt;code&gt;operator&lt;/code&gt; A는 &lt;code&gt;LinearOperatorLowRankUpdate&lt;/code&gt; 형상 &lt;code&gt;[M, N]&lt;/code&gt; 랭크에서 만든 &lt;code&gt;K&lt;/code&gt; 의 업데이트 &lt;code&gt;base_operator&lt;/code&gt; 수행 &lt;code&gt;.matmul(x)&lt;/code&gt; 에 대한 &lt;code&gt;x&lt;/code&gt; 갖는 &lt;code&gt;x.shape = [N, R]&lt;/code&gt; 과 &lt;code&gt;O(L_matmul*N*R)&lt;/code&gt; 복잡성 (와 마찬가지로 &lt;code&gt;solve&lt;/code&gt; , &lt;code&gt;determinant&lt;/code&gt; . 그러면 &lt;code&gt;x.shape = [N, R]&lt;/code&gt; 이면</target>
        </trans-unit>
        <trans-unit id="0c77e9c8aaab3edc5678c3e6e549ae40d1713585" translate="yes" xml:space="preserve">
          <source>Suppose &lt;code&gt;operator&lt;/code&gt; is a &lt;code&gt;LinearOperatorLowerTriangular&lt;/code&gt; of shape &lt;code&gt;[N, N]&lt;/code&gt;, and &lt;code&gt;x.shape = [N, R]&lt;/code&gt;. Then</source>
          <target state="translated">가정하자 &lt;code&gt;operator&lt;/code&gt; A는 &lt;code&gt;LinearOperatorLowerTriangular&lt;/code&gt; 형상 &lt;code&gt;[N, N]&lt;/code&gt; , 및 &lt;code&gt;x.shape = [N, R]&lt;/code&gt; . 그때</target>
        </trans-unit>
        <trans-unit id="23ed1b4df71c9959792073ca5b67ae2e12e27635" translate="yes" xml:space="preserve">
          <source>Suppose head1.logits_dimension = 2 and head2.logits_dimension = 3. After</source>
          <target state="translated">head1.logits_dimension = 2이고 head2.logits_dimension = 3이라고 가정하십시오.</target>
        </trans-unit>
        <trans-unit id="5c269bc606f19d8edaa319f84a6c255fb252f362" translate="yes" xml:space="preserve">
          <source>Suppose that &lt;code&gt;elems&lt;/code&gt; is unpacked into &lt;code&gt;values&lt;/code&gt;, a list of tensors. The shape of the result tensor is &lt;code&gt;[len(values)] + fn(initializer, values[0]).shape&lt;/code&gt;. If reverse=True, it's fn(initializer, values[-1]).shape.</source>
          <target state="translated">&lt;code&gt;elems&lt;/code&gt; 가 텐서 목록 인 &lt;code&gt;values&lt;/code&gt; 로 압축 해제 되었다고 가정하십시오 . 결과 텐서의 모양은 &lt;code&gt;[len(values)] + fn(initializer, values[0]).shape&lt;/code&gt; 입니다. reverse = True이면 fn (initializer, values ​​[-1]). shape입니다.</target>
        </trans-unit>
        <trans-unit id="d3c35f6ed89e8be18a5dda61c0fefcaae20da780" translate="yes" xml:space="preserve">
          <source>Suppose that &lt;code&gt;elems&lt;/code&gt; is unpacked into &lt;code&gt;values&lt;/code&gt;, a list of tensors. The shape of the result tensor is &lt;code&gt;[values.shape[0]] + fn(values[0]).shape&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;elems&lt;/code&gt; 가 텐서 목록 인 &lt;code&gt;values&lt;/code&gt; 로 압축 해제 되었다고 가정하십시오 . 결과 텐서의 모양은 &lt;code&gt;[values.shape[0]] + fn(values[0]).shape&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="dffca82b48f3566d75cc894aa925b53a25bf73ca" translate="yes" xml:space="preserve">
          <source>Suppose that &lt;code&gt;elems&lt;/code&gt; is unpacked into &lt;code&gt;values&lt;/code&gt;, a list of tensors. The shape of the result tensor is &lt;code&gt;fn(initializer, values[0]).shape&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;elems&lt;/code&gt; 가 텐서 목록 인 &lt;code&gt;values&lt;/code&gt; 로 압축 해제 되었다고 가정하십시오 . 결과 텐서의 모양은 &lt;code&gt;fn(initializer, values[0]).shape&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="3bdc81326d20683103cdcdb7d7d719aec67b18bc" translate="yes" xml:space="preserve">
          <source>Suppose that &lt;code&gt;elems&lt;/code&gt; is unpacked into &lt;code&gt;values&lt;/code&gt;, a list of tensors. The shape of the result tensor is fn(initializer, values[0]).shape`.</source>
          <target state="translated">&lt;code&gt;elems&lt;/code&gt; 이 &lt;code&gt;values&lt;/code&gt; 으로 압축 해제 되었다고 가정하십시오. 텐서 목록 인 . 결과 텐서의 모양은 fn (initializer, values ​​[0]). shape`입니다.</target>
        </trans-unit>
        <trans-unit id="f480af4470b536307bbf09765cdc8e2696cc548a" translate="yes" xml:space="preserve">
          <source>Survival function.</source>
          <target state="translated">생존 기능.</target>
        </trans-unit>
        <trans-unit id="3226a9be6189190c548f628801bd70aeb6bac060" translate="yes" xml:space="preserve">
          <source>Switch to cross-replica mode by calling &lt;code&gt;tf.distribute.get_replica_context().merge_call()&lt;/code&gt; with the updates and variables as arguments.</source>
          <target state="translated">업데이트 및 변수를 인수로 사용하여 &lt;code&gt;tf.distribute.get_replica_context().merge_call()&lt;/code&gt; 을 호출하여 교차 복제 모드로 전환하십시오 .</target>
        </trans-unit>
        <trans-unit id="c82b9c388b0f25a72fdba537900d4ee1afe829a0" translate="yes" xml:space="preserve">
          <source>Switches between two operations depending on a scalar value.</source>
          <target state="translated">스칼라 값에 따라 두 작업 사이를 전환합니다.</target>
        </trans-unit>
        <trans-unit id="4bd6d6747309915056dbba0e2193c97595c133f2" translate="yes" xml:space="preserve">
          <source>Symbolic tensors are allowed to pass through.</source>
          <target state="translated">기호 텐서가 통과 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="ed4aff47c3be607749bd2e1d76c1e799b5c23200" translate="yes" xml:space="preserve">
          <source>Synchronous training in TPU donuts or Pods.</source>
          <target state="translated">TPU 도넛 또는 포드의 동기식 훈련.</target>
        </trans-unit>
        <trans-unit id="b9cb28847740ddfa22df77ecf9af53c7bcc458c9" translate="yes" xml:space="preserve">
          <source>System configuration library.</source>
          <target state="translated">시스템 구성 라이브러리</target>
        </trans-unit>
        <trans-unit id="c3c9fd8a607c0fc8d5f20ab08a585b5a769813a4" translate="yes" xml:space="preserve">
          <source>TFDecorator captures and exposes the wrapped target, and provides details about the current decorator.</source>
          <target state="translated">TFDecorator는 랩핑 된 대상을 캡처하고 노출하며 현재 데코레이터에 대한 세부 사항을 제공합니다.</target>
        </trans-unit>
        <trans-unit id="b0ae8b7e5c1a9027f31ac3b8b9a304ad1f03ee67" translate="yes" xml:space="preserve">
          <source>TFLiteConverter class.</source>
          <target state="translated">TFLiteConverter 클래스</target>
        </trans-unit>
        <trans-unit id="40c2a70a8ac9081500125d800973c1f2856d001e" translate="yes" xml:space="preserve">
          <source>TFLiteConverter object.</source>
          <target state="translated">TFLiteConverter 객체.</target>
        </trans-unit>
        <trans-unit id="5a3f9ca39eb5977717f75ea98c14ebd341cb7b0c" translate="yes" xml:space="preserve">
          <source>TFRecord and tf.Example</source>
          <target state="translated">TFRecord 및 tf.Example</target>
        </trans-unit>
        <trans-unit id="f2a1cfdc5a677069b65778d10bf6ba1ec74141b1" translate="yes" xml:space="preserve">
          <source>THIS CLASS IS DEPRECATED. Training with HDF5Matrix may not be optimized for performance, and might not work with every distribution strategy.</source>
          <target state="translated">이 클래스는 더 이상 사용되지 않습니다. HDF5Matrix를 사용한 교육은 성능에 최적화되지 않았으며 모든 배포 전략에서 작동하지 않을 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="ea3b5253f8acd939a0fcfcfde0d4f81758ceb6ec" translate="yes" xml:space="preserve">
          <source>THIS FUNCTION IS EXPERIMENTAL. Keras layers/models are the recommended APIs for logit and model composition.</source>
          <target state="translated">이 기능은 실험적입니다. Keras 레이어 / 모델은 로짓 및 모델 구성에 권장되는 API입니다.</target>
        </trans-unit>
        <trans-unit id="6e68009384c2a3495a678e12d2ac69897187a9e4" translate="yes" xml:space="preserve">
          <source>TIP: V2 is recommended as it is more flexible (eg: batching, etc).</source>
          <target state="translated">힌트 : V2는보다 유연하므로 (예 : 배치 등) 권장됩니다.</target>
        </trans-unit>
        <trans-unit id="86c515aa235c35a6dd43d1bb6f6bd5b2174b6173" translate="yes" xml:space="preserve">
          <source>TODO(phawkins): consider adding support for broadcasting Tensors passed as inputs.</source>
          <target state="translated">TODO (phawkins) : 입력으로 전달 된 Tensor 브로드 캐스트에 대한 지원 추가를 고려하십시오.</target>
        </trans-unit>
        <trans-unit id="0670d6d1899b8c7a6ede58b5b723e5aff4b026c8" translate="yes" xml:space="preserve">
          <source>TODO: add doc.</source>
          <target state="translated">TODO : 문서를 추가하십시오.</target>
        </trans-unit>
        <trans-unit id="6907e140b23b35d38f6441293f654f8fc707a293" translate="yes" xml:space="preserve">
          <source>TPU distribution strategy implementation.</source>
          <target state="translated">TPU 배포 전략 구현.</target>
        </trans-unit>
        <trans-unit id="c2e6d3a312671dc52e2d71bde402cdc7f8d14f6d" translate="yes" xml:space="preserve">
          <source>TPU embeddings do not support arbitrary Tensorflow optimizers and the main optimizer you use for your model will be ignored for the embedding table variables. Instead TPU embeddigns support a fixed set of predefined optimizers that you can select from and set the parameters of. These include adagrad, adam and stochastic gradient descent. Each supported optimizer has a &lt;code&gt;Parameters&lt;/code&gt; class in the &lt;a href=&quot;../../../../../tpu/experimental&quot;&gt;&lt;code&gt;tf.tpu.experimental&lt;/code&gt;&lt;/a&gt; namespace.</source>
          <target state="translated">TPU 임베딩은 임의의 Tensorflow 옵티 마이저를 지원하지 않으며 임베드 테이블 변수에 대해 모델에 사용하는 기본 옵티마이 저는 무시됩니다. 대신 TPU embeddigns는 매개 변수를 선택하고 설정할 수있는 사전 정의 된 고정 최적화 프로그램의 고정 집합을 지원합니다. 여기에는 adagrad, adam 및 stochastic gradient descent가 포함됩니다. 지원되는 각 최적화 프로그램에는 &lt;a href=&quot;../../../../../tpu/experimental&quot;&gt; &lt;code&gt;tf.tpu.experimental&lt;/code&gt; &lt;/a&gt; 네임 스페이스 에 &lt;code&gt;Parameters&lt;/code&gt; 클래스가 있습니다.</target>
        </trans-unit>
        <trans-unit id="c46f66d84964d9d9b6cca0e4bf0d96c3c3563722" translate="yes" xml:space="preserve">
          <source>TPU evaluation only works on a single host (one TPU worker) except BROADCAST mode.</source>
          <target state="translated">TPU 평가는 BROADCAST 모드를 제외한 단일 호스트 (한 TPU 작업자)에서만 작동합니다.</target>
        </trans-unit>
        <trans-unit id="608813e35435b00f9557600b0760339a8be2fba8" translate="yes" xml:space="preserve">
          <source>TPU prediction only works on a single host (one TPU worker).</source>
          <target state="translated">TPU 예측은 단일 호스트 (한 TPU 작업자)에서만 작동합니다.</target>
        </trans-unit>
        <trans-unit id="bea46edc5a09b34d108296e7caa64c56863439a0" translate="yes" xml:space="preserve">
          <source>TPU related configuration required by &lt;code&gt;TPUEstimator&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;TPUEstimator&lt;/code&gt; 에 필요한 TPU 관련 구성 .</target>
        </trans-unit>
        <trans-unit id="15462f6b704e5cb2f8f24f59de3042ec97404e38" translate="yes" xml:space="preserve">
          <source>TPU version of &lt;a href=&quot;../../../../feature_column/embedding_column&quot;&gt;&lt;code&gt;tf.compat.v1.feature_column.embedding_column&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../../../../feature_column/embedding_column&quot;&gt; &lt;code&gt;tf.compat.v1.feature_column.embedding_column&lt;/code&gt; 의&lt;/a&gt; TPU 버전 .</target>
        </trans-unit>
        <trans-unit id="9d40306c82f3b12d754e570cc8b1cc658af2d7ec" translate="yes" xml:space="preserve">
          <source>TPU version of &lt;a href=&quot;../../feature_column/shared_embedding_columns&quot;&gt;&lt;code&gt;tf.compat.v1.feature_column.shared_embedding_columns&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../../feature_column/shared_embedding_columns&quot;&gt; &lt;code&gt;tf.compat.v1.feature_column.shared_embedding_columns&lt;/code&gt; 의&lt;/a&gt; TPU 버전 .</target>
        </trans-unit>
        <trans-unit id="87bcdd18e5c8f3b283a01e8df873660ee1d3e88c" translate="yes" xml:space="preserve">
          <source>TPUClusterResolver supports the following distinct environments: Google Compute Engine Google Kubernetes Engine Google internal</source>
          <target state="translated">TPUClusterResolver는 다음과 같은 고유 한 환경을 지원합니다. Google Compute Engine Google Kubernetes Engine Google 내부</target>
        </trans-unit>
        <trans-unit id="3090232b8a50e355f64d4b6a9078737dd646c783" translate="yes" xml:space="preserve">
          <source>TPUEstimator also supports training on CPU and GPU. You don't need to define a separate &lt;a href=&quot;../../../../estimator/estimator&quot;&gt;&lt;code&gt;tf.estimator.Estimator&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">TPUEstimator는 CPU 및 GPU에 대한 교육도 지원합니다. 별도의 &lt;a href=&quot;../../../../estimator/estimator&quot;&gt; &lt;code&gt;tf.estimator.Estimator&lt;/code&gt; &lt;/a&gt; 를 정의 할 필요가 없습니다 .</target>
        </trans-unit>
        <trans-unit id="2ddc9467e5f271b2c256312505abf3c2d4c6b0c7" translate="yes" xml:space="preserve">
          <source>TPUEstimator handles many of the details of running on TPU devices, such as replicating inputs and models for each core, and returning to host periodically to run hooks.</source>
          <target state="translated">TPUEstimator는 각 코어에 대한 입력 및 모델 복제, 주기적으로 호스트로 돌아와 후크를 실행하는 등 TPU 장치에서 실행하는 많은 세부 사항을 처리합니다.</target>
        </trans-unit>
        <trans-unit id="b7e3ce08e3020395f3645372f9a127852462deaa" translate="yes" xml:space="preserve">
          <source>TPUEstimator transforms a global batch size in params to a per-shard batch size when calling the &lt;code&gt;input_fn&lt;/code&gt; and &lt;code&gt;model_fn&lt;/code&gt;. Users should specify global batch size in constructor, and then get the batch size for each shard in &lt;code&gt;input_fn&lt;/code&gt; and &lt;code&gt;model_fn&lt;/code&gt; by &lt;code&gt;params['batch_size']&lt;/code&gt;.</source>
          <target state="translated">TPUEstimator는 &lt;code&gt;input_fn&lt;/code&gt; 및 &lt;code&gt;model_fn&lt;/code&gt; 을 호출 할 때 params의 전역 배치 크기를 샤드 별 배치 크기로 변환합니다 . 사용자는 생성자에 전역 배치 크기를 지정한 다음 &lt;code&gt;params['batch_size']&lt;/code&gt; 에 의해 &lt;code&gt;input_fn&lt;/code&gt; 및 &lt;code&gt;model_fn&lt;/code&gt; 의 각 샤드에 대한 배치 크기를 가져와야 합니다 .</target>
        </trans-unit>
        <trans-unit id="39242b58e44e50c227c356940f2f4790b1a6c7ad" translate="yes" xml:space="preserve">
          <source>Table initializers from a text file.</source>
          <target state="translated">텍스트 파일의 테이블 이니셜 라이저.</target>
        </trans-unit>
        <trans-unit id="e9a99855991e9fba416a14570cf1cb6a0187f661" translate="yes" xml:space="preserve">
          <source>Table initializers given &lt;code&gt;keys&lt;/code&gt; and &lt;code&gt;values&lt;/code&gt; tensors.</source>
          <target state="translated">&lt;code&gt;keys&lt;/code&gt; 와 &lt;code&gt;values&lt;/code&gt; 주어진 테이블 이니셜 라이저 텐서가 .</target>
        </trans-unit>
        <trans-unit id="1af97a71a1a73644d18d0f047160d91771a21862" translate="yes" xml:space="preserve">
          <source>Takes a &lt;strong&gt;doc&lt;/strong&gt; string and reformats it as help.</source>
          <target state="translated">걸린다 &lt;strong&gt;문서를&lt;/strong&gt; 문자열과 도움으로 다시 포맷을.</target>
        </trans-unit>
        <trans-unit id="b5507e3c183afb3feb1fdd594429bbf04fe50d0d" translate="yes" xml:space="preserve">
          <source>Takes data &amp;amp; label arrays, generates batches of augmented data.</source>
          <target state="translated">데이터 및 레이블 배열을 가져 와서 확장 된 데이터의 배치를 생성합니다.</target>
        </trans-unit>
        <trans-unit id="dc5dd136fb3e20832ac83739b0d79852faeb82ca" translate="yes" xml:space="preserve">
          <source>Takes input and builds independent forward and backward RNNs. The input_size of forward and backward cell must match. The initial state for both directions is zero by default (but can be set optionally) and no intermediate states are ever returned -- the network is fully unrolled for the given (passed in) length(s) of the sequence(s) or completely unrolled if length(s) is not given.</source>
          <target state="translated">입력을 받아서 독립적 인 정방향 및 역방향 RNN을 작성합니다. 정방향 및 역방향 셀의 input_size가 일치해야합니다. 양방향의 초기 상태는 기본적으로 0이지만 (선택적으로 설정 가능) 중간 상태는 반환되지 않습니다. 시퀀스의 지정된 길이 (또는 길이) 동안 네트워크가 완전히 언 롤링됩니다. 길이가 주어지지 않으면 풀린다.</target>
        </trans-unit>
        <trans-unit id="53df57e552ce83928403023542fdf87dfd9006ea" translate="yes" xml:space="preserve">
          <source>Takes the dataframe and the path to a directory and generates batches of augmented/normalized data.</source>
          <target state="translated">데이터 프레임과 디렉토리 경로를 가져 와서 확장 / 정규화 된 데이터 배치를 생성합니다.</target>
        </trans-unit>
        <trans-unit id="271a488ff4179dc414b9d598c0dc902bde38633e" translate="yes" xml:space="preserve">
          <source>Takes the path to a directory &amp;amp; generates batches of augmented data.</source>
          <target state="translated">디렉토리로의 경로를 취하고 증강 데이터의 배치를 생성합니다.</target>
        </trans-unit>
        <trans-unit id="1ca63275fee9de8e1de06948cce8c928cfa17e6c" translate="yes" xml:space="preserve">
          <source>Task: The task index.</source>
          <target state="translated">작업 : 작업 인덱스</target>
        </trans-unit>
        <trans-unit id="0d5c8c8a1221df9d08630309c4e00e480ca26a66" translate="yes" xml:space="preserve">
          <source>Temporarily stops recording operations on this tape.</source>
          <target state="translated">이 테이프의 녹화 작업을 일시적으로 중지합니다.</target>
        </trans-unit>
        <trans-unit id="b284c7bc2378fc04ec8bfcb09803127b9f601fb1" translate="yes" xml:space="preserve">
          <source>Tensor contraction of a and b along specified axes and outer product.</source>
          <target state="translated">지정된 축과 외부 제품을 따라 a와 b의 텐서 수축.</target>
        </trans-unit>
        <trans-unit id="38618f2d27b4f14fefef4170aa6ae920945a40f0" translate="yes" xml:space="preserve">
          <source>Tensor contraction over specified indices and outer product.</source>
          <target state="translated">지정된 지수 및 외부 제품에 대한 텐서 수축.</target>
        </trans-unit>
        <trans-unit id="0eb7922b93e36f198944524d3ccbd887eb62554c" translate="yes" xml:space="preserve">
          <source>Tensor holding edge maps for each channel. Returns a tensor with shape [batch_size, h, w, d, 2] where the last two dimensions hold [[dy[0], dx[0]], [dy[1], dx[1]], ..., [dy[d-1], dx[d-1]]] calculated using the Sobel filter.</source>
          <target state="translated">각 채널에 대한 텐서 홀딩 엣지 맵. 마지막 두 치수가 [[dy [0], dx [0]], [dy [1], dx [1]], ...를 보유하는 [batch_size, h, w, d, 2] 모양의 텐서를 반환합니다. , [dy [d-1], dx [d-1]]]을 Sobel 필터를 사용하여 계산했습니다.</target>
        </trans-unit>
        <trans-unit id="998135bad24dda7870bc2f0601f12e030cb5ca03" translate="yes" xml:space="preserve">
          <source>Tensor instance (with Keras metadata included).</source>
          <target state="translated">텐서 인스턴스 (Keras 메타 데이터 포함).</target>
        </trans-unit>
        <trans-unit id="cd4eaaecc52921b6ace4791b28568b11625a63a9" translate="yes" xml:space="preserve">
          <source>Tensor of rank N+2, of shape [batch_size] + output_spatial_shape + [num_channels]</source>
          <target state="translated">모양 [batch_size] + output_spatial_shape + [num_channels]의 순위 N + 2의 텐서</target>
        </trans-unit>
        <trans-unit id="cb76e00fc954d9b6160cc47c8ab840677d6dc502" translate="yes" xml:space="preserve">
          <source>Tensor of same shape and dtype of input &lt;code&gt;x&lt;/code&gt;, with tanh activation: &lt;code&gt;tanh(x) = sinh(x)/cosh(x) = ((exp(x) - exp(-x))/(exp(x) + exp(-x)))&lt;/code&gt;.</source>
          <target state="translated">tanh 활성화시 동일한 모양과 입력 &lt;code&gt;x&lt;/code&gt; 의 dtype 텐서 : &lt;code&gt;tanh(x) = sinh(x)/cosh(x) = ((exp(x) - exp(-x))/(exp(x) + exp(-x)))&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f229fd06f270a1472ee5fc7d946ec114e17083e8" translate="yes" xml:space="preserve">
          <source>Tensor with dtype &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="translated">dtype &lt;code&gt;dtype&lt;/code&gt; 을 가진 텐서 .</target>
        </trans-unit>
        <trans-unit id="5b127d103d72c024e0c3a7e4c213e3125d5bed59" translate="yes" xml:space="preserve">
          <source>Tensor with exponential activation: &lt;code&gt;exp(x)&lt;/code&gt;. Tensor will be of same shape and dtype of input &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="translated">지수 활성화 된 텐서 : &lt;code&gt;exp(x)&lt;/code&gt; . 텐서는 입력 &lt;code&gt;x&lt;/code&gt; 의 모양과 dtype이 같습니다 .</target>
        </trans-unit>
        <trans-unit id="c04a1202ada48999add7a1b4944833aee2cdad3e" translate="yes" xml:space="preserve">
          <source>Tensor with one scalar loss entry per sample.</source>
          <target state="translated">샘플 당 하나의 스칼라 손실 항목이있는 텐서.</target>
        </trans-unit>
        <trans-unit id="a1bcf3e6714689670e8871ddc1423b42db7d58cf" translate="yes" xml:space="preserve">
          <source>Tensor with same type and shape as &lt;code&gt;initializer&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;initializer&lt;/code&gt; 와 동일한 유형 및 모양의 텐서 .</target>
        </trans-unit>
        <trans-unit id="7eb3ed83767298c300168c3e7bea9ba8df3bf9a3" translate="yes" xml:space="preserve">
          <source>Tensor with shape (samples,1) containing the CTC loss of each element.</source>
          <target state="translated">각 요소의 CTC 손실을 포함하는 모양 (샘플, 1)의 텐서.</target>
        </trans-unit>
        <trans-unit id="c6e0a539edac6a669824128887ac83f25a022bed" translate="yes" xml:space="preserve">
          <source>Tensor with the sigmoid activation: &lt;code&gt;(1.0 / (1.0 + exp(-x)))&lt;/code&gt;. Tensor will be of same shape and dtype of input &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="translated">S 자형 활성화 텐서 : &lt;code&gt;(1.0 / (1.0 + exp(-x)))&lt;/code&gt; . 텐서는 입력 &lt;code&gt;x&lt;/code&gt; 의 모양과 dtype이 같습니다 .</target>
        </trans-unit>
        <trans-unit id="86989d8c3ba1ef406d202928da376f95029f14db" translate="yes" xml:space="preserve">
          <source>Tensor, output of softmax transformation (all values are non-negative and sum to 1).</source>
          <target state="translated">텐서, softmax 변환의 출력 (모든 값은 음수가 아니고 1로 합산 됨).</target>
        </trans-unit>
        <trans-unit id="0c870eac18cde0821e85a6e2e0cd690795d9b0f8" translate="yes" xml:space="preserve">
          <source>TensorBoard is a visualization tool provided with TensorFlow.</source>
          <target state="translated">TensorBoard는 TensorFlow와 함께 제공되는 시각화 도구입니다.</target>
        </trans-unit>
        <trans-unit id="d6c5b7495606642427d84d9560c2c6fa48e983ac" translate="yes" xml:space="preserve">
          <source>TensorBoard will pick the graph from the file and display it graphically so you can interactively explore the graph you built. You will usually pass the graph from the session in which you launched it:</source>
          <target state="translated">TensorBoard는 파일에서 그래프를 선택하여 그래픽으로 표시하므로 사용자가 작성한 그래프를 대화식으로 탐색 할 수 있습니다. 일반적으로 그래프를 시작한 세션에서 그래프를 전달합니다.</target>
        </trans-unit>
        <trans-unit id="91920dffa2de075aa71252ce246c4919ca2918b7" translate="yes" xml:space="preserve">
          <source>TensorFlow</source>
          <target state="translated">TensorFlow</target>
        </trans-unit>
        <trans-unit id="0aa8b8730f9d4ee0f6fd230f9d2510cbf8c53747" translate="yes" xml:space="preserve">
          <source>TensorFlow 1 version</source>
          <target state="translated">텐서 플로우 1 버전</target>
        </trans-unit>
        <trans-unit id="4e54099f7adc352258d80aa2a07931abd0dfaf7a" translate="yes" xml:space="preserve">
          <source>TensorFlow 1.x and 2.x</source>
          <target state="translated">텐서 플로우 1.x 및 2.x</target>
        </trans-unit>
        <trans-unit id="895342c8e5449651b084f46f85af49138e2e8798" translate="yes" xml:space="preserve">
          <source>TensorFlow 2 quickstart for experts</source>
          <target state="translated">전문가를위한 TensorFlow 2 빠른 시작</target>
        </trans-unit>
        <trans-unit id="4d7a6f2a780bcce78ffe938ccead5b3061683157" translate="yes" xml:space="preserve">
          <source>TensorFlow Compiler Bridge (TF Bridge) is responsible for translating parts of TensorFlow graph into a form that can be accepted as an input by a backend compiler such as XLA.</source>
          <target state="translated">TensorFlow Compiler Bridge (TF Bridge)는 TensorFlow 그래프의 일부를 XLA와 같은 백엔드 컴파일러가 입력으로 받아 들일 수있는 형식으로 변환하는 역할을합니다.</target>
        </trans-unit>
        <trans-unit id="5218d7001def4141ae436cbd9f4e4ab5c90eec24" translate="yes" xml:space="preserve">
          <source>TensorFlow can execute operations synchronously or asynchronously. If asynchronous execution is enabled, operations may return &quot;non-ready&quot; handles.</source>
          <target state="translated">TensorFlow는 작업을 동기식 또는 비동기식으로 실행할 수 있습니다. 비동기 실행이 활성화되면 작업이 &quot;준비되지 않은&quot;핸들을 반환 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="6b177522823bac7fab49a3e953658eb26bd8be99" translate="yes" xml:space="preserve">
          <source>TensorFlow can utilize various devices such as the CPU or multiple GPUs for computation. Before initializing a local device for use, the user can customize certain properties of the device such as it's visibility or memory configuration.</source>
          <target state="translated">TensorFlow는 CPU 또는 여러 GPU와 같은 다양한 장치를 사용하여 계산할 수 있습니다. 사용하기 위해 로컬 장치를 초기화하기 전에 사용자는 가시성 또는 메모리 구성과 같은 장치의 특정 속성을 사용자 지정할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="aeb6cbc7489405eda828caa72395bff0364182ee" translate="yes" xml:space="preserve">
          <source>TensorFlow does not support strides, &lt;a href=&quot;matrix_transpose&quot;&gt;&lt;code&gt;linalg.matrix_transpose&lt;/code&gt;&lt;/a&gt; returns a new tensor with the items permuted.</source>
          <target state="translated">TensorFlow는 보폭을 지원하지 않습니다. &lt;a href=&quot;matrix_transpose&quot;&gt; &lt;code&gt;linalg.matrix_transpose&lt;/code&gt; &lt;/a&gt; 는 항목이 치환 된 새 텐서를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="9ab173e45e5b70ecdfa453b1565a9d48b4aea76c" translate="yes" xml:space="preserve">
          <source>TensorFlow does not support strides, so &lt;code&gt;transpose&lt;/code&gt; returns a new tensor with the items permuted.</source>
          <target state="translated">TensorFlow는 보폭을 지원하지 않으므로 &lt;code&gt;transpose&lt;/code&gt; 은 항목이 치환 된 새 텐서를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="7258b473d648b978f0063efc0c3f0fba649a7ae7" translate="yes" xml:space="preserve">
          <source>TensorFlow example</source>
          <target state="translated">텐서 플로우 예제</target>
        </trans-unit>
        <trans-unit id="80a5a18b376b7e19393c2007205799ec5fa64c3e" translate="yes" xml:space="preserve">
          <source>TensorFlow graph optimization with Grappler</source>
          <target state="translated">Grappler를 사용한 TensorFlow 그래프 최적화</target>
        </trans-unit>
        <trans-unit id="faa0af6a22961093bbe0a8dd50a78c706f27b26f" translate="yes" xml:space="preserve">
          <source>TensorFlow has been supporting a 3 week forward-compatibility window for programs compiled from source at HEAD.</source>
          <target state="translated">TensorFlow는 HEAD의 소스에서 컴파일 된 프로그램에 대해 3 주 순방향 호환성 창을 지원하고 있습니다.</target>
        </trans-unit>
        <trans-unit id="72769cecd87d42b437dab4e9d4a607af2d9ab1dc" translate="yes" xml:space="preserve">
          <source>TensorFlow lacks support for unsigned integers. The ops represent uint64 types as a &lt;code&gt;DT_INT64&lt;/code&gt; with the same twos-complement bit pattern (the obvious way). Unsigned int32 values can be represented exactly by specifying type &lt;code&gt;DT_INT64&lt;/code&gt;, or using twos-complement if the caller specifies &lt;code&gt;DT_INT32&lt;/code&gt; in the &lt;code&gt;output_types&lt;/code&gt; attribute.</source>
          <target state="translated">TensorFlow에는 부호없는 정수에 대한 지원이 없습니다. ops는 uint64 유형을 동일한 2 보완 비트 패턴 (명확한 방법) 으로 &lt;code&gt;DT_INT64&lt;/code&gt; 로 나타냅니다 . 부호없는 int32 값은 &lt;code&gt;DT_INT64&lt;/code&gt; 유형을 지정 하거나 호출자 가 &lt;code&gt;output_types&lt;/code&gt; 속성에 &lt;code&gt;DT_INT32&lt;/code&gt; 를 지정하는 경우 two -complement를 사용하여 정확하게 표현할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="173be625ee6b740f87a6f6b6b09514fbf3c93296" translate="yes" xml:space="preserve">
          <source>TensorFlow multi-step profiler.</source>
          <target state="translated">TensorFlow 다단계 프로파일 러.</target>
        </trans-unit>
        <trans-unit id="8d014f833e885f8b8ed6b7a6c3ea673ead6d65d8" translate="yes" xml:space="preserve">
          <source>TensorFlow provides a variety of math functions including:</source>
          <target state="translated">TensorFlow는 다음을 포함한 다양한 수학 기능을 제공합니다.</target>
        </trans-unit>
        <trans-unit id="305519ec0cbf6a7bdfd33f052e7a4a788bce222c" translate="yes" xml:space="preserve">
          <source>TensorFlow provides several operations that you can use to perform common math computations on tensor segments. Here a segmentation is a partitioning of a tensor along the first dimension, i.e. it defines a mapping from the first dimension onto &lt;code&gt;segment_ids&lt;/code&gt;. The &lt;code&gt;segment_ids&lt;/code&gt; tensor should be the size of the first dimension, &lt;code&gt;d0&lt;/code&gt;, with consecutive IDs in the range &lt;code&gt;0&lt;/code&gt; to &lt;code&gt;k&lt;/code&gt;, where &lt;code&gt;k&amp;lt;d0&lt;/code&gt;. In particular, a segmentation of a matrix tensor is a mapping of rows to segments.</source>
          <target state="translated">TensorFlow는 텐서 세그먼트에서 일반적인 수학 계산을 수행하는 데 사용할 수있는 몇 가지 작업을 제공합니다. 여기서 세분화는 첫 번째 차원을 따라 텐서의 분할입니다. 즉, 첫 번째 차원에서 &lt;code&gt;segment_ids&lt;/code&gt; 로의 맵핑을 정의합니다 . &lt;code&gt;segment_ids&lt;/code&gt; 제 치수의 크기이어야 텐서 &lt;code&gt;d0&lt;/code&gt; 범위의 연속 ID가, &lt;code&gt;0&lt;/code&gt; 하는 &lt;code&gt;k&lt;/code&gt; 여기서, &lt;code&gt;k&amp;lt;d0&lt;/code&gt; . 특히, 매트릭스 텐서의 세그먼트는 행을 세그먼트에 매핑하는 것이다.</target>
        </trans-unit>
        <trans-unit id="476649b1950b2c7e7e27717793935f815d493aa9" translate="yes" xml:space="preserve">
          <source>TensorFlow represents a sparse tensor as three separate dense tensors: &lt;code&gt;indices&lt;/code&gt;, &lt;code&gt;values&lt;/code&gt;, and &lt;code&gt;dense_shape&lt;/code&gt;. In Python, the three tensors are collected into a &lt;code&gt;SparseTensor&lt;/code&gt; class for ease of use. If you have separate &lt;code&gt;indices&lt;/code&gt;, &lt;code&gt;values&lt;/code&gt;, and &lt;code&gt;dense_shape&lt;/code&gt; tensors, wrap them in a &lt;code&gt;SparseTensor&lt;/code&gt; object before passing to the ops below.</source>
          <target state="translated">TensorFlow는 희소 텐서를 3 개의 개별 밀도 텐서 ( &lt;code&gt;indices&lt;/code&gt; , &lt;code&gt;values&lt;/code&gt; 및 &lt;code&gt;dense_shape&lt;/code&gt; )로 나타냅니다 . 파이썬에서는 세 개의 텐서가 &lt;code&gt;SparseTensor&lt;/code&gt; 클래스에 수집되어 사용하기가 쉽습니다. 별도의 &lt;code&gt;indices&lt;/code&gt; , &lt;code&gt;values&lt;/code&gt; 및 &lt;code&gt;dense_shape&lt;/code&gt; 텐서 가있는 경우 아래 ops에 전달하기 전에 &lt;code&gt;SparseTensor&lt;/code&gt; 오브젝트로 랩핑 하십시오.</target>
        </trans-unit>
        <trans-unit id="a47222eb58bbdfce0fc55dcabde531b7c9adb406" translate="yes" xml:space="preserve">
          <source>TensorShape(None) is compatible with all shapes.</source>
          <target state="translated">TensorShape (None)은 모든 모양과 호환됩니다.</target>
        </trans-unit>
        <trans-unit id="bac8d5b9c3640fab327ab07d92ee55320fd3913d" translate="yes" xml:space="preserve">
          <source>TensorShape([1, 2, 3]) is the most specific TensorShape compatible with both TensorShape([1, 2, 3]) and TensorShape([1, 2, 3]). There are more less specific TensorShapes compatible with above mentioned TensorShapes, e.g. TensorShape([1, 2, None]), TensorShape(None).</source>
          <target state="translated">TensorShape ([1, 2, 3])은 TensorShape ([1, 2, 3]) 및 TensorShape ([1, 2, 3])와 호환되는 가장 구체적인 TensorShape입니다. 위에서 언급 한 TensorShapes와 호환되는보다 덜 구체적인 TensorShapes가 있습니다 (예 : TensorShape ([1, 2, None]), TensorShape (None)).</target>
        </trans-unit>
        <trans-unit id="0224569211f435d2df63b768abb6efc726a69d01" translate="yes" xml:space="preserve">
          <source>TensorShape([32, 784]) is compatible with itself, and also TensorShape([32, None]), TensorShape([None, 784]), TensorShape([None, None]) and TensorShape(None). It is not compatible with, for example, TensorShape([32, 1, 784]) or TensorShape([None]).</source>
          <target state="translated">TensorShape ([32, 784])는 자체와 호환되며 TensorShape ([32, None]), TensorShape ([None, 784]), TensorShape ([None, None]) 및 TensorShape (None) 과도 호환됩니다. 예를 들어 TensorShape ([32, 1, 784]) 또는 TensorShape ([None])과 호환되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="9d64401ff7bd3446564470a92463f73e24f52237" translate="yes" xml:space="preserve">
          <source>TensorShape([32, None]) is compatible with all two-dimensional shapes with size 32 in the 0th dimension, and also TensorShape([None, None]) and TensorShape(None). It is not compatible with, for example, TensorShape([32]), TensorShape([32, None, 1]) or TensorShape([64, None]).</source>
          <target state="translated">TensorShape ([32, None])은 0 차원에서 크기가 32 인 모든 2 차원 모양과 TensorShape ([None, None]) 및 TensorShape (None)과 호환됩니다. 예를 들어 TensorShape ([32]), TensorShape ([32, None, 1]) 또는 TensorShape ([64, None])과 호환되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="59fc38face567505b51ef9cc1d627c3ec48e0458" translate="yes" xml:space="preserve">
          <source>TensorShape([None, 1]) is the most specific TensorShape compatible with both TensorShape([2, 1]) and TensorShape([5, 1]). Note that TensorShape(None) is also compatible with above mentioned TensorShapes.</source>
          <target state="translated">TensorShape ([없음, 1])은 TensorShape ([2, 1]) 및 TensorShape ([5, 1]) 모두와 호환되는 가장 구체적인 TensorShape입니다. TensorShape (None)은 위에서 언급 한 TensorShapes 와도 호환됩니다.</target>
        </trans-unit>
        <trans-unit id="0f0011d7d16cb288f3076f4ccc9f15a9b93ab18d" translate="yes" xml:space="preserve">
          <source>TensorShape([None, None]) is compatible with all two-dimensional shapes, such as TensorShape([32, 784]), and also TensorShape(None). It is not compatible with, for example, TensorShape([None]) or TensorShape([None, None, None]).</source>
          <target state="translated">TensorShape ([None, None])은 TensorShape ([32, 784]) 및 TensorShape (None)과 같은 모든 2 차원 모양과 호환됩니다. 예를 들어 TensorShape ([None]) 또는 TensorShape ([None, None, None])과 호환되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="eb7208ca53baf0c906efb86ab8419484372d57aa" translate="yes" xml:space="preserve">
          <source>Tensordot (also known as tensor contraction) sums the product of elements from &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; over the indices specified by &lt;code&gt;a_axes&lt;/code&gt; and &lt;code&gt;b_axes&lt;/code&gt;. The lists &lt;code&gt;a_axes&lt;/code&gt; and &lt;code&gt;b_axes&lt;/code&gt; specify those pairs of axes along which to contract the tensors. The axis &lt;code&gt;a_axes[i]&lt;/code&gt; of &lt;code&gt;a&lt;/code&gt; must have the same dimension as axis &lt;code&gt;b_axes[i]&lt;/code&gt; of &lt;code&gt;b&lt;/code&gt; for all &lt;code&gt;i&lt;/code&gt; in &lt;code&gt;range(0, len(a_axes))&lt;/code&gt;. The lists &lt;code&gt;a_axes&lt;/code&gt; and &lt;code&gt;b_axes&lt;/code&gt; must have identical length and consist of unique integers that specify valid axes for each of the tensors. Additionally outer product is supported by passing &lt;code&gt;axes=0&lt;/code&gt;.</source>
          <target state="translated">텐서 도트 (텐서 수축이라고도 함)는 &lt;code&gt;a_axes&lt;/code&gt; 및 &lt;code&gt;b_axes&lt;/code&gt; 로 지정된 인덱스에 대해 &lt;code&gt;a&lt;/code&gt; 와 &lt;code&gt;b&lt;/code&gt; 의 요소 곱을 합산합니다 . 리스트 &lt;code&gt;a_axes&lt;/code&gt; 및 &lt;code&gt;b_axes&lt;/code&gt; 는 텐서를 수축시키는 축 쌍을 지정합니다. 축 &lt;code&gt;a_axes[i]&lt;/code&gt; 의 &lt;code&gt;a&lt;/code&gt; 축과 동일한 치수 있어야 &lt;code&gt;b_axes[i]&lt;/code&gt; 의 &lt;code&gt;b&lt;/code&gt; 모두 &lt;code&gt;i&lt;/code&gt; 의 &lt;code&gt;range(0, len(a_axes))&lt;/code&gt; . &lt;code&gt;a_axes&lt;/code&gt; 및 &lt;code&gt;b_axes&lt;/code&gt; 목록길이는 동일해야하며 각 텐서에 유효한 축을 지정하는 고유 한 정수로 구성되어야합니다. 또한 &lt;code&gt;axes=0&lt;/code&gt; 을 전달하여 외부 제품을 지원합니다 .</target>
        </trans-unit>
        <trans-unit id="3da1e8a48fb9ee2ea5423ca2bee26f977fbfb800" translate="yes" xml:space="preserve">
          <source>Tensorflow 1.x and 2.x APIs</source>
          <target state="translated">텐서 플로우 1.x 및 2.x API</target>
        </trans-unit>
        <trans-unit id="df64ef28dfdc0fed49d20c14d6e6f4dee9cf4df9" translate="yes" xml:space="preserve">
          <source>Tensorflow set operations.</source>
          <target state="translated">텐서 플로우 세트 조작.</target>
        </trans-unit>
        <trans-unit id="c78b40e19c215435bc3ed71dd1958e2bcae7efd3" translate="yes" xml:space="preserve">
          <source>Tensorlow Activation function denoted by input string.</source>
          <target state="translated">입력 문자열로 표시되는 텐서 로우 활성화 기능.</target>
        </trans-unit>
        <trans-unit id="08f39ae099e26b016733e9e9c40c5aeddf309f4f" translate="yes" xml:space="preserve">
          <source>Tensors are broadcast to all shards if they are lexically captured by &lt;code&gt;computation&lt;/code&gt;. e.g.,</source>
          <target state="translated">텐서는 &lt;code&gt;computation&lt;/code&gt; 의해 어휘 적으로 캡처 된 경우 모든 샤드에 브로드 캐스트됩니다 . 예를 들어</target>
        </trans-unit>
        <trans-unit id="bf0313234b1dcd5626309aecb9ec7ec9391ddedf" translate="yes" xml:space="preserve">
          <source>Tensors returned by the call to either &lt;code&gt;true_fn&lt;/code&gt; or &lt;code&gt;false_fn&lt;/code&gt;. If the callables return a singleton list, the element is extracted from the list.</source>
          <target state="translated">텐서 중 하나에 대한 호출에 의해 반환 &lt;code&gt;true_fn&lt;/code&gt; 또는 &lt;code&gt;false_fn&lt;/code&gt; . 콜 러블이 싱글 톤 목록을 반환하면 요소가 목록에서 추출됩니다.</target>
        </trans-unit>
        <trans-unit id="a48b71c8b807b599bf508a6dbc5c09d5b67d8a03" translate="yes" xml:space="preserve">
          <source>Tensors where required information about the tensor is not found are not added to the list. This includes temporary tensors without a name.</source>
          <target state="translated">텐서에 대한 필수 정보가없는 텐서는 목록에 추가되지 않습니다. 여기에는 이름이없는 임시 텐서가 포함됩니다.</target>
        </trans-unit>
        <trans-unit id="f7b5ca3ec5313c82b6abfc2564bf0e69a6804f5b" translate="yes" xml:space="preserve">
          <source>Tensors with the same shapes and dtypes as &lt;code&gt;primals&lt;/code&gt;, or None if no JVP is available.</source>
          <target state="translated">primals와 모양 및 dtype이 동일한 &lt;code&gt;primals&lt;/code&gt; 또는 사용 가능한 JVP가없는 경우 None</target>
        </trans-unit>
        <trans-unit id="f63302361128babd351769e59c1a4b3a6ec16f94" translate="yes" xml:space="preserve">
          <source>Test the model on a single batch of samples.</source>
          <target state="translated">단일 샘플 배치에서 모델을 테스트합니다.</target>
        </trans-unit>
        <trans-unit id="bdf696f0dd4d97504f4a88d9e975e9f3294e8162" translate="yes" xml:space="preserve">
          <source>Testing.</source>
          <target state="translated">Testing.</target>
        </trans-unit>
        <trans-unit id="922aa0452fde3720fa66aa3c8e60b54fc1c9bf57" translate="yes" xml:space="preserve">
          <source>Tests if a variable has been initialized.</source>
          <target state="translated">변수가 초기화되었는지 테스트합니다.</target>
        </trans-unit>
        <trans-unit id="f458c872a2ebaf65e5d7df76b800c1d13ed30e7f" translate="yes" xml:space="preserve">
          <source>Tests whether &lt;code&gt;v&lt;/code&gt; was created while this strategy scope was active.</source>
          <target state="translated">이 전략 범위가 활성화 된 동안 &lt;code&gt;v&lt;/code&gt; 가 작성 되었는지 테스트합니다 .</target>
        </trans-unit>
        <trans-unit id="e0beba45f94aef1d128461a461734027a1cbdc6a" translate="yes" xml:space="preserve">
          <source>Text classification with TensorFlow Hub: Movie reviews</source>
          <target state="translated">TensorFlow Hub를 사용한 텍스트 분류 : 영화 리뷰</target>
        </trans-unit>
        <trans-unit id="af2326670284928f1fa19c7cb38f5c886d723da5" translate="yes" xml:space="preserve">
          <source>Text classification with an RNN</source>
          <target state="translated">RNN을 사용한 텍스트 분류</target>
        </trans-unit>
        <trans-unit id="666b2045ab57fe75e30e76d0ab8d952507d4bb84" translate="yes" xml:space="preserve">
          <source>Text classification with preprocessed text: Movie reviews</source>
          <target state="translated">전처리 된 텍스트를 사용한 텍스트 분류 : 영화 리뷰</target>
        </trans-unit>
        <trans-unit id="238cbda9697b2819cc76abe6b2dfc721f459f878" translate="yes" xml:space="preserve">
          <source>Text data summarized via this plugin will be visible in the Text Dashboard in TensorBoard. The standard TensorBoard Text Dashboard will render markdown in the strings, and will automatically organize 1d and 2d tensors into tables. If a tensor with more than 2 dimensions is provided, a 2d subarray will be displayed along with a warning message. (Note that this behavior is not intrinsic to the text summary api, but rather to the default TensorBoard text plugin.)</source>
          <target state="translated">이 플러그인을 통해 요약 된 텍스트 데이터는 TensorBoard의 텍스트 대시 보드에 표시됩니다. 표준 TensorBoard Text Dashboard는 문자열에서 마크 다운을 렌더링하고 1d 및 2d 텐서를 테이블로 자동 구성합니다. 2 차원보다 큰 텐서가 제공되면 경고 메시지와 함께 2d 하위 배열이 표시됩니다. (이 동작은 텍스트 요약 API에 고유 한 것이 아니라 기본 TensorBoard 텍스트 플러그인에 고유합니다.)</target>
        </trans-unit>
        <trans-unit id="215d4fed2fcabcf3c40621205317566597794ae1" translate="yes" xml:space="preserve">
          <source>Text generation with an RNN</source>
          <target state="translated">RNN을 사용한 텍스트 생성</target>
        </trans-unit>
        <trans-unit id="61400e23cf34d05c482b01eaced08ef2d8868035" translate="yes" xml:space="preserve">
          <source>Text tokenization utility class.</source>
          <target state="translated">텍스트 토큰 화 유틸리티 클래스.</target>
        </trans-unit>
        <trans-unit id="fdb6f1dda58b475840646d14c94922eb6f72f336" translate="yes" xml:space="preserve">
          <source>Text vectorization layer.</source>
          <target state="translated">텍스트 벡터화 레이어.</target>
        </trans-unit>
        <trans-unit id="f1625deb08cd91b1818022a22d98396b875c5eb8" translate="yes" xml:space="preserve">
          <source>TextFileIndex.LINE_NUMBER means use the line number starting from zero, expects data type int64.</source>
          <target state="translated">TextFileIndex.LINE_NUMBER는 0부터 시작하는 행 번호를 사용한다는 의미이며 데이터 유형은 int64입니다.</target>
        </trans-unit>
        <trans-unit id="52639d0bc1ea1e6f18d19dfc84aced6fc473d4b7" translate="yes" xml:space="preserve">
          <source>TextFileIndex.WHOLE_LINE means use the whole line content, expects data type string.</source>
          <target state="translated">TextFileIndex.WHOLE_LINE은 전체 행 내용을 사용하고 데이터 유형 문자열을 예상 함을 의미합니다.</target>
        </trans-unit>
        <trans-unit id="fad4058d06803c465e05d1c5344e342b15bc7c35" translate="yes" xml:space="preserve">
          <source>That is, the data from the input tensors is joined along the &lt;code&gt;axis&lt;/code&gt; dimension.</source>
          <target state="translated">즉, 입력 텐서의 데이터가 &lt;code&gt;axis&lt;/code&gt; 치수를 따라 결합됩니다 .</target>
        </trans-unit>
        <trans-unit id="819444ab5f8a03046c9bdaef264812c5a336db87" translate="yes" xml:space="preserve">
          <source>The &quot;default&quot; behavior to is to output all intermediates when using v2 control flow inside Keras models in graph mode (possibly inside Estimators). This is needed to support taking gradients of v2 control flow. In graph mode, Keras can sometimes freeze the forward graph before the gradient computation which does not work for v2 control flow since it requires updating the forward ops to output the needed intermediates. We work around this by proactively outputting the needed intermediates when building the forward pass itself. Ideally any such extra tensors should be pruned out at runtime. However, if for any reason this doesn't work for you or if you have an infernce-only model you can turn this behavior off using &lt;a href=&quot;output_all_intermediates&quot;&gt;&lt;code&gt;tf.compat.v1.experimental.output_all_intermediates(False)&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&quot;기본&quot;동작은 그래프 모드에서 Keras 모델 내부 (예상자 내부)에서 v2 제어 흐름을 사용할 때 모든 중간체를 출력하는 것입니다. 이것은 v2 제어 흐름의 그라디언트를 지원하는 데 필요합니다. 그래프 모드에서 Keras는 필요한 중간체를 출력하기 위해 순방향 op를 업데이트해야하므로 v2 제어 흐름에서는 작동하지 않는 기울기 계산 전에 순방향 그래프를 고정 할 수 있습니다. 정방향 패스를 만들 때 필요한 중간체를 미리 출력하여이 문제를 해결합니다. 이상적으로 이러한 여분의 텐서는 런타임에 정리해야합니다. 그러나 어떤 이유로 든 이것이 작동하지 않거나 추론 전용 모델 인 경우 &lt;a href=&quot;output_all_intermediates&quot;&gt; &lt;code&gt;tf.compat.v1.experimental.output_all_intermediates(False)&lt;/code&gt; &lt;/a&gt; 사용 하여이 동작을 끌 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="0b9fa0a04a1154461443bf2e15e0c100a29ae547" translate="yes" xml:space="preserve">
          <source>The 'key' part of the state of a counter-based RNG.</source>
          <target state="translated">카운터 기반 RNG 상태의 '핵심'부분.</target>
        </trans-unit>
        <trans-unit id="3318a80b2f7ae85ea4618b44f96f90cdc30913bf" translate="yes" xml:space="preserve">
          <source>The 'step' here refers to the step defined by &lt;code&gt;Profiler.add_step()&lt;/code&gt; API.</source>
          <target state="translated">여기서 '단계'는 &lt;code&gt;Profiler.add_step()&lt;/code&gt; API에 의해 정의 된 단계를 나타냅니다 .</target>
        </trans-unit>
        <trans-unit id="32756cff4dc3fe86f44d1b62b470239afbc36f52" translate="yes" xml:space="preserve">
          <source>The -32768 to 32767 signed 16-bit values will be scaled to -1.0 to 1.0 in float.</source>
          <target state="translated">-32768 ~ 32767 부호있는 16 비트 값은 부동 소수점으로 -1.0 ~ 1.0으로 조정됩니다.</target>
        </trans-unit>
        <trans-unit id="a500fcca2783caaf16ae016a052e05e8f3aac0f1" translate="yes" xml:space="preserve">
          <source>The .value attribute of the registered 'Flag' objects can be accessed as attributes of this 'FlagValues' object, through &lt;strong&gt;getattr&lt;/strong&gt;. Both the long and short name of the original 'Flag' objects can be used to access its value: FLAGS.longname # parsed flag value FLAGS.x # parsed flag value (short name)</source>
          <target state="translated">등록 된 'Flag'객체의 .value 속성은 &lt;strong&gt;getattr&lt;/strong&gt; 을 통해이 'FlagValues'객체의 속성으로 액세스 할 수 있습니다 . 원래 'Flag'객체의 긴 이름과 짧은 이름을 사용하여 해당 값에 액세스 할 수 있습니다. FLAGS.longname # 구문 분석 된 플래그 값 FLAGS.x # 구문 분석 된 플래그 값 (짧은 이름)</target>
        </trans-unit>
        <trans-unit id="310600070b5ce2b07429f189bd9cdba9eeaed7e3" translate="yes" xml:space="preserve">
          <source>The 4-D &lt;code&gt;input&lt;/code&gt; tensor is treated as a 3-D array of 1-D vectors (along the last dimension), and each vector is normalized independently. Within a given vector, each component is divided by the weighted, squared sum of inputs within &lt;code&gt;depth_radius&lt;/code&gt;. In detail,</source>
          <target state="translated">4 차원 &lt;code&gt;input&lt;/code&gt; 텐서는 1 차원 벡터 (마지막 차원)의 3 차원 배열로 취급되며 각 벡터는 독립적으로 정규화됩니다. 주어진 벡터 내에서 각 구성 요소는 &lt;code&gt;depth_radius&lt;/code&gt; 내의 가중 제곱 입력 합으로 나뉩니다 . 상세히,</target>
        </trans-unit>
        <trans-unit id="0f0e683a1673564b6d46b0b9fa5e4680c1843f5c" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; returned by &lt;code&gt;input_fn&lt;/code&gt; should have a per-replica batch size, which may be computed using &lt;code&gt;input_context.get_per_replica_batch_size&lt;/code&gt;.</source>
          <target state="translated">&lt;a href=&quot;../../../../data/dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; 는&lt;/a&gt; 에 의해 반환 &lt;code&gt;input_fn&lt;/code&gt; 사용하여 계산 될 수있는 당 복제 배치 크기, 있어야 &lt;code&gt;input_context.get_per_replica_batch_size&lt;/code&gt; 를 .</target>
        </trans-unit>
        <trans-unit id="457c92aa7bdffea8661a2def17f70e375b2b0d14" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; returned by &lt;code&gt;input_fn&lt;/code&gt; should have a per-replica batch size, which may be computed using &lt;code&gt;input_context.get_per_replica_batch_size&lt;/code&gt;.</source>
          <target state="translated">&lt;a href=&quot;../../../data/dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; 는&lt;/a&gt; 에 의해 반환 &lt;code&gt;input_fn&lt;/code&gt; 사용하여 계산 될 수있는 당 복제 배치 크기, 있어야 &lt;code&gt;input_context.get_per_replica_batch_size&lt;/code&gt; 를 .</target>
        </trans-unit>
        <trans-unit id="c669108152980f350f27d9f945606a7f5042af07" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../compat&quot;&gt;&lt;code&gt;tf.compat&lt;/code&gt;&lt;/a&gt; module contains two sets of compatibility functions.</source>
          <target state="translated">&lt;a href=&quot;../../compat&quot;&gt; &lt;code&gt;tf.compat&lt;/code&gt; 의&lt;/a&gt; 모듈은 호환 함수의 두 세트를 포함한다.</target>
        </trans-unit>
        <trans-unit id="01d2d82dc787cbf3a2ae3987bb1b5d16410bae2e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../v1&quot;&gt;&lt;code&gt;compat.v1&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../v2&quot;&gt;&lt;code&gt;compat.v2&lt;/code&gt;&lt;/a&gt; submodules provide a complete copy of both the &lt;a href=&quot;../v1&quot;&gt;&lt;code&gt;v1&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../v2&quot;&gt;&lt;code&gt;v2&lt;/code&gt;&lt;/a&gt; APIs for backwards and forwards compatibility across TensorFlow versions 1.x and 2.x. See the &lt;a href=&quot;https://www.tensorflow.org/guide/migrate&quot;&gt;migration guide&lt;/a&gt; for details.</source>
          <target state="translated">&lt;a href=&quot;../v1&quot;&gt; &lt;code&gt;compat.v1&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;../v2&quot;&gt; &lt;code&gt;compat.v2&lt;/code&gt; &lt;/a&gt; 서브 모듈은 완료 모두의 사본을 제공 &lt;a href=&quot;../v1&quot;&gt; &lt;code&gt;v1&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;../v2&quot;&gt; &lt;code&gt;v2&lt;/code&gt; &lt;/a&gt; TensorFlow 버전 1.x 및 2.x 또는 3.0을 통해 앞으로 뒤로위한 API와 호환성을 자세한 내용은 &lt;a href=&quot;https://www.tensorflow.org/guide/migrate&quot;&gt;마이그레이션 안내서&lt;/a&gt; 를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="fbe9cc0c9957673c491ce6d30fbea4a26885b807" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;as_dtype&quot;&gt;&lt;code&gt;tf.as_dtype()&lt;/code&gt;&lt;/a&gt; function converts numpy types and string type names to a &lt;code&gt;DType&lt;/code&gt; object.</source>
          <target state="translated">&lt;a href=&quot;as_dtype&quot;&gt; &lt;code&gt;tf.as_dtype()&lt;/code&gt; &lt;/a&gt; 함수로 변환은 유형 및 스트링 유형 이름 NumPy와 &lt;code&gt;DType&lt;/code&gt; 오브젝트.</target>
        </trans-unit>
        <trans-unit id="32f6a4f580c3c6e3fc936c05d3cb6e72f0b9bb8c" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;asin&quot;&gt;&lt;code&gt;tf.math.asin&lt;/code&gt;&lt;/a&gt; operation returns the inverse of &lt;a href=&quot;sin&quot;&gt;&lt;code&gt;tf.math.sin&lt;/code&gt;&lt;/a&gt;, such that if &lt;code&gt;y = tf.math.sin(x)&lt;/code&gt; then, &lt;code&gt;x = tf.math.asin(y)&lt;/code&gt;.</source>
          <target state="translated">&lt;a href=&quot;asin&quot;&gt; &lt;code&gt;tf.math.asin&lt;/code&gt; 의&lt;/a&gt; 동작의 역 복귀 &lt;a href=&quot;sin&quot;&gt; &lt;code&gt;tf.math.sin&lt;/code&gt; &lt;/a&gt; 같은 그 경우 &lt;code&gt;y = tf.math.sin(x)&lt;/code&gt; 그리고, &lt;code&gt;x = tf.math.asin(y)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1fe608389d1e1d156ec65aaf39eda66bf4b6d78b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;atan&quot;&gt;&lt;code&gt;tf.math.atan&lt;/code&gt;&lt;/a&gt; operation returns the inverse of &lt;a href=&quot;tan&quot;&gt;&lt;code&gt;tf.math.tan&lt;/code&gt;&lt;/a&gt;, such that if &lt;code&gt;y = tf.math.tan(x)&lt;/code&gt; then, &lt;code&gt;x = tf.math.atan(y)&lt;/code&gt;.</source>
          <target state="translated">&lt;a href=&quot;atan&quot;&gt; &lt;code&gt;tf.math.atan&lt;/code&gt; &lt;/a&gt; 동작의 역 복귀 &lt;a href=&quot;tan&quot;&gt; &lt;code&gt;tf.math.tan&lt;/code&gt; &lt;/a&gt; 같은 그 경우 &lt;code&gt;y = tf.math.tan(x)&lt;/code&gt; 그리고, &lt;code&gt;x = tf.math.atan(y)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="377c0dfe96375de255d1078e440f823480e3a6ef" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;compat&quot;&gt;&lt;code&gt;tf.compat&lt;/code&gt;&lt;/a&gt; module contains two sets of compatibility functions.</source>
          <target state="translated">&lt;a href=&quot;compat&quot;&gt; &lt;code&gt;tf.compat&lt;/code&gt; 의&lt;/a&gt; 모듈은 호환 함수의 두 세트를 포함한다.</target>
        </trans-unit>
        <trans-unit id="b3d73ba603d6fb92f75b91298f4942e6c40c7715" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;compat/v1&quot;&gt;&lt;code&gt;compat.v1&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;compat/v2&quot;&gt;&lt;code&gt;compat.v2&lt;/code&gt;&lt;/a&gt; submodules provide a complete copy of both the &lt;a href=&quot;compat/v1&quot;&gt;&lt;code&gt;v1&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;compat/v2&quot;&gt;&lt;code&gt;v2&lt;/code&gt;&lt;/a&gt; APIs for backwards and forwards compatibility across TensorFlow versions 1.x and 2.x. See the &lt;a href=&quot;https://www.tensorflow.org/guide/migrate&quot;&gt;migration guide&lt;/a&gt; for details.</source>
          <target state="translated">&lt;a href=&quot;compat/v1&quot;&gt; &lt;code&gt;compat.v1&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;compat/v2&quot;&gt; &lt;code&gt;compat.v2&lt;/code&gt; &lt;/a&gt; 서브 모듈은 완료 모두의 사본을 제공 &lt;a href=&quot;compat/v1&quot;&gt; &lt;code&gt;v1&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;compat/v2&quot;&gt; &lt;code&gt;v2&lt;/code&gt; &lt;/a&gt; TensorFlow 버전 1.x 및 2.x 또는 3.0을 통해 앞으로 뒤로위한 API와 호환성을 자세한 내용은 &lt;a href=&quot;https://www.tensorflow.org/guide/migrate&quot;&gt;마이그레이션 안내서&lt;/a&gt; 를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="296ec246e39e89b77945b24475c46eb438f28485" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; API supports writing descriptive and efficient input pipelines. &lt;code&gt;Dataset&lt;/code&gt; usage follows a common pattern:</source>
          <target state="translated">&lt;a href=&quot;dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; 을&lt;/a&gt; 설명하고 효율적인 입력 파이프 라인을 작성하는 API를 지원합니다. &lt;code&gt;Dataset&lt;/code&gt; 사용법은 일반적인 패턴을 따릅니다.</target>
        </trans-unit>
        <trans-unit id="8c3d4e4e633551f12e713ed696a5627504df6738" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;dtypes/dtype&quot;&gt;&lt;code&gt;tf.dtypes.DType&lt;/code&gt;&lt;/a&gt; specified by this type for the SparseTensor.</source>
          <target state="translated">&lt;a href=&quot;dtypes/dtype&quot;&gt; &lt;code&gt;tf.dtypes.DType&lt;/code&gt; 는&lt;/a&gt; SparseTensor이 유형에 의해 지정.</target>
        </trans-unit>
        <trans-unit id="70d5ec6de5836f215309b5a86984ea31fb17eefc" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto&quot;&gt;&lt;code&gt;ConfigProto&lt;/code&gt;&lt;/a&gt; protocol buffer exposes various configuration options for a session. For example, to create a session that uses soft constraints for device placement, and log the resulting placement decisions, create a session as follows:</source>
          <target state="translated">&lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto&quot;&gt; &lt;code&gt;ConfigProto&lt;/code&gt; 의&lt;/a&gt; 프로토콜 버퍼는 세션에 대한 다양한 구성 옵션을 제공합니다. 예를 들어, 장치 배치에 소프트 제한 조건을 사용하는 세션을 작성하고 결과 배치 결정을 로그하려면 다음과 같이 세션을 작성하십시오.</target>
        </trans-unit>
        <trans-unit id="ee6db31a7766468eec0b350c9fc9a1f275e8fb70" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;reshape&quot;&gt;&lt;code&gt;tf.reshape&lt;/code&gt;&lt;/a&gt; does not change the order of or the total number of elements in the tensor, and so it can reuse the underlying data buffer. This makes it a fast operation independent of how big of a tensor it is operating on.</source>
          <target state="translated">&lt;a href=&quot;reshape&quot;&gt; &lt;code&gt;tf.reshape&lt;/code&gt; 은&lt;/a&gt; 순서 또는 텐서 요소의 총 개수를 변경하지 않고, 그 재사용 할 수 있도록 기본 데이터 버퍼. 이것은 얼마나 큰 텐서가 작동하는지에 관계없이 빠른 작동을합니다.</target>
        </trans-unit>
        <trans-unit id="7963552cb54b1ec49bf3619d53b5f98fe3bf0679" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;summary&quot;&gt;&lt;code&gt;tf.summary&lt;/code&gt;&lt;/a&gt; module provides APIs for writing summary data. This data can be visualized in TensorBoard, the visualization toolkit that comes with TensorFlow. See the &lt;a href=&quot;https://www.tensorflow.org/tensorboard&quot;&gt;TensorBoard website&lt;/a&gt; for more detailed tutorials about how to use these APIs, or some quick examples below.</source>
          <target state="translated">&lt;a href=&quot;summary&quot;&gt; &lt;code&gt;tf.summary&lt;/code&gt; &lt;/a&gt; 모듈은 요약 데이터를 작성하기위한 API를 제공합니다. 이 데이터는 TensorFlow와 함께 제공되는 시각화 툴킷 인 TensorBoard에서 시각화 할 수 있습니다. 이러한 API 사용 방법에 대한 자세한 자습서 또는 아래의 몇 가지 간단한 예 는 &lt;a href=&quot;https://www.tensorflow.org/tensorboard&quot;&gt;TensorBoard 웹 사이트&lt;/a&gt; 를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="24f9ea8adfa7610b42fddb644a5a51e051b8eaa7" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;tensorshape&quot;&gt;&lt;code&gt;tf.TensorShape&lt;/code&gt;&lt;/a&gt; of elements in this TensorArray.</source>
          <target state="translated">이 &lt;a href=&quot;tensorshape&quot;&gt; &lt;code&gt;tf.TensorShape&lt;/code&gt; &lt;/a&gt; 에있는 요소 의 tf.TensorShape 입니다.</target>
        </trans-unit>
        <trans-unit id="04e6781a375d8a3c0003a07e94ac44bcb3e616e5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;tensorshape&quot;&gt;&lt;code&gt;tf.TensorShape&lt;/code&gt;&lt;/a&gt; specified by this type for the SparseTensor.</source>
          <target state="translated">&lt;a href=&quot;tensorshape&quot;&gt; &lt;code&gt;tf.TensorShape&lt;/code&gt; 는&lt;/a&gt; SparseTensor이 유형에 의해 지정.</target>
        </trans-unit>
        <trans-unit id="66692c6576fc19dc600e497055779a41aa378ba7" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;AUTOGRAPH_VERBOSITY&lt;/code&gt; environment variable</source>
          <target state="translated">&lt;code&gt;AUTOGRAPH_VERBOSITY&lt;/code&gt; 의 환경 변수</target>
        </trans-unit>
        <trans-unit id="5dca74f64b67802ef6255942a005b4b0e987ede6" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;D&lt;/code&gt; dimensional DFT of this kernel is the frequency domain spectrum of this operator.</source>
          <target state="translated">이 커널 의 &lt;code&gt;D&lt;/code&gt; 차원 DFT는이 연산자의 주파수 영역 스펙트럼입니다.</target>
        </trans-unit>
        <trans-unit id="66b37f1319974cb5f0fa3b6a811c37b0c0727341" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;DType&lt;/code&gt; of &lt;code&gt;Tensor&lt;/code&gt;s handled by this &lt;code&gt;Distribution&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;DType&lt;/code&gt; 의 &lt;code&gt;Tensor&lt;/code&gt; 이 처리 s의 &lt;code&gt;Distribution&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6bb640578d6cd791bb5862104fe6d0205745975e" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;DType&lt;/code&gt; of &lt;code&gt;Tensor&lt;/code&gt;s handled by this &lt;code&gt;LinearOperator&lt;/code&gt;.</source>
          <target state="translated">이 &lt;code&gt;DType&lt;/code&gt; 가 처리하는 &lt;code&gt;Tensor&lt;/code&gt; 의 &lt;code&gt;LinearOperator&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="d9d4756bd9db645b28103af34e5194ce4953cfef" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;DType&lt;/code&gt; of elements in this tensor.</source>
          <target state="translated">이 텐서 요소 의 &lt;code&gt;DType&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="b5ab67eadac883aa6725083774a80ae7132a5bd6" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;DType&lt;/code&gt; of this variable.</source>
          <target state="translated">이 변수 의 &lt;code&gt;DType&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="53e90665615d6d49947adc54462569d15bfa77ff" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;DType&lt;/code&gt; of values in this tensor.</source>
          <target state="translated">이 텐서의 값 의 &lt;code&gt;DType&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="b7a67bba30f7a7c9709251275c277fca1bfce8ef" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;DeviceSpec&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;DeviceSpec&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a0310f14b96c9ed2b643415080c07ecfa0544c1f" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Estimator&lt;/code&gt; object wraps a model which is specified by a &lt;code&gt;model_fn&lt;/code&gt;, which, given inputs and a number of other parameters, returns the ops necessary to perform training, evaluation, or predictions.</source>
          <target state="translated">&lt;code&gt;Estimator&lt;/code&gt; 목적은에 의해 특정되는 모델 랩 &lt;code&gt;model_fn&lt;/code&gt; 다른 파라미터의 수가, 트레이닝, 평가, 또는 예측을 수행하는 데 필요한 OPS를 반환 주어진 입력과.</target>
        </trans-unit>
        <trans-unit id="196e0cebbe1e15bfa0065abbfc42918c9e99edb0" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;FileWriter&lt;/code&gt; class provides a mechanism to create an event file in a given directory and add summaries and events to it. The class updates the file contents asynchronously. This allows a training program to call methods to add data to the file directly from the training loop, without slowing down training.</source>
          <target state="translated">&lt;code&gt;FileWriter&lt;/code&gt; 의 클래스는 지정된 디렉토리에서 이벤트 파일을 작성하고 요약 및 이벤트를 추가 할 수있는 메커니즘을 제공합니다. 클래스는 파일 내용을 비동기 적으로 업데이트합니다. 이를 통해 훈련 프로그램은 훈련 속도를 늦추지 않고 훈련 루프에서 직접 파일에 데이터를 추가하는 메소드를 호출 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="196ae7d5b42d47f46f7482c41ead4515ecb54223" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Graph&lt;/code&gt; of this variable.</source>
          <target state="translated">이 변수 의 &lt;code&gt;Graph&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="584ca58bfd11413a8b78de2539e6a0dc60006c1e" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Graph&lt;/code&gt; that contains the index, value, and dense_shape tensors.</source>
          <target state="translated">&lt;code&gt;Graph&lt;/code&gt; 인덱스 값 및 dense_shape 텐서가 포함되어 있습니다.</target>
        </trans-unit>
        <trans-unit id="5ca109a80501f1caf39360f020e2482be69cd6ee" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Graph&lt;/code&gt; that contains the values, indices, and shape tensors.</source>
          <target state="translated">&lt;code&gt;Graph&lt;/code&gt; 값, 인덱스 및 형상 텐서를 포함한다.</target>
        </trans-unit>
        <trans-unit id="a3f124e19ecf06b5bede3c16429a910c11d7deff" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Graph&lt;/code&gt; that contains this operation.</source>
          <target state="translated">이 작업이 포함 된 &lt;code&gt;Graph&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="ca5e3e755e232a9bd4baefb017c11720d3cb6b8d" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Graph&lt;/code&gt; that contains this tensor.</source>
          <target state="translated">이 텐서가 포함 된 &lt;code&gt;Graph&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="ad04e8ed6553bb23d3fbb8f177dc964899bc3ca0" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;IndexedSlices&lt;/code&gt; class is used principally in the definition of gradients for operations that have sparse gradients (e.g. &lt;a href=&quot;gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">&lt;code&gt;IndexedSlices&lt;/code&gt; 의 클래스는 스파 스 구배를 (예를 들어,이 작업을 위해 그라디언트의 정의에 주로 사용된다 &lt;a href=&quot;gather&quot;&gt; &lt;code&gt;tf.gather&lt;/code&gt; &lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="b67dd6295f95267a6fd766fa43e3a4f8445ff608" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Lambda&lt;/code&gt; layer exists so that arbitrary TensorFlow functions can be used when constructing &lt;code&gt;Sequential&lt;/code&gt; and Functional API models. &lt;code&gt;Lambda&lt;/code&gt; layers are best suited for simple operations or quick experimentation. For more advanced usecases, follow &lt;a href=&quot;https://www.tensorflow.org/guide/keras/custom_layers_and_models&quot;&gt;this guide&lt;/a&gt; for subclassing &lt;a href=&quot;layer&quot;&gt;&lt;code&gt;tf.keras.layers.Layer&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;Lambda&lt;/code&gt; 층 구성 할 때 임의의 TensorFlow 기능을 사용할 수 있도록 존재 &lt;code&gt;Sequential&lt;/code&gt; 및 기능 API 모델. &lt;code&gt;Lambda&lt;/code&gt; 레이어는 간단한 작업이나 빠른 실험에 가장 적합합니다. 고급 쓰임새를 들어, 다음과 &lt;a href=&quot;https://www.tensorflow.org/guide/keras/custom_layers_and_models&quot;&gt;이 가이드&lt;/a&gt; 서브 클래스에 대한 &lt;a href=&quot;layer&quot;&gt; &lt;code&gt;tf.keras.layers.Layer&lt;/code&gt; 을&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="12b734c9cea4d788668e7d42b41afdea642fee23" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;LinearOperatorIdentity&lt;/code&gt; is initialized with arguments defining &lt;code&gt;dtype&lt;/code&gt; and shape.</source>
          <target state="translated">&lt;code&gt;LinearOperatorIdentity&lt;/code&gt; 는 인수가 정의로 초기화됩니다 &lt;code&gt;dtype&lt;/code&gt; 와 모양.</target>
        </trans-unit>
        <trans-unit id="d73311c5178545cf753217309588019e38f9d709" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;LinearOperatorScaledIdentity&lt;/code&gt; is initialized with &lt;code&gt;num_rows&lt;/code&gt;, which determines the size of each identity matrix, and a &lt;code&gt;multiplier&lt;/code&gt;, which defines &lt;code&gt;dtype&lt;/code&gt;, batch shape, and scale of each matrix.</source>
          <target state="translated">&lt;code&gt;LinearOperatorScaledIdentity&lt;/code&gt; 가 초기화되는 &lt;code&gt;num_rows&lt;/code&gt; 각 행렬의 크기를 결정하고, &lt;code&gt;multiplier&lt;/code&gt; 정의하는 &lt;code&gt;dtype&lt;/code&gt; 각 행렬의 배치 형태 및 크기.</target>
        </trans-unit>
        <trans-unit id="b6a140a1c911bc07b4bf6bf40190ce8128dc1514" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;LinearOperatorZeros&lt;/code&gt; is initialized with arguments defining &lt;code&gt;dtype&lt;/code&gt; and shape.</source>
          <target state="translated">&lt;code&gt;LinearOperatorZeros&lt;/code&gt; 는 인수가 정의로 초기화됩니다 &lt;code&gt;dtype&lt;/code&gt; 와 모양.</target>
        </trans-unit>
        <trans-unit id="b1f24df7eab694b0f1703da39cd73b8c86b688da" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;LocallyConnected1D&lt;/code&gt; layer works similarly to the &lt;code&gt;Conv1D&lt;/code&gt; layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.</source>
          <target state="translated">&lt;code&gt;LocallyConnected1D&lt;/code&gt; 의 계층은 비슷하게 작동 &lt;code&gt;Conv1D&lt;/code&gt; 필터의 다른 세트는 각각 다른 입력의 패치에 적용되는 가중치는 그 비공유이다 제외 층.</target>
        </trans-unit>
        <trans-unit id="70697b9bab37838191095266898ffadfd97d828c" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;LocallyConnected2D&lt;/code&gt; layer works similarly to the &lt;code&gt;Conv2D&lt;/code&gt; layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.</source>
          <target state="translated">&lt;code&gt;LocallyConnected2D&lt;/code&gt; 의 계층은 비슷하게 작동 &lt;code&gt;Conv2D&lt;/code&gt; 필터의 다른 세트는 각각 다른 입력의 패치에 적용되는 가중치는 그 비공유이다 제외 층.</target>
        </trans-unit>
        <trans-unit id="b8fa1143a320d647d8e801e00a58c7e05a50565b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;LossScale&lt;/code&gt; instance associated with this optimizer.</source>
          <target state="translated">&lt;code&gt;LossScale&lt;/code&gt; 의 이 최적화와 관련된 인스턴스입니다.</target>
        </trans-unit>
        <trans-unit id="98a41775ad95ce382b63a77e41954693dabb7a8c" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;MetaGraphDef&lt;/code&gt; allows running the given graph via &lt;code&gt;saver.import_meta_graph()&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;MetaGraphDef&lt;/code&gt; 을 통해 주어진 그래프를 실행 허용 &lt;code&gt;saver.import_meta_graph()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1d513aeb35380001cdceb5f916046f228692a7e2" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;MetaGraphDef&lt;/code&gt; protocol buffer loaded in the provided session. This can be used to further extract signature-defs, collection-defs, etc.</source>
          <target state="translated">&lt;code&gt;MetaGraphDef&lt;/code&gt; 에 제공된 세션에 로딩 프로토콜 버퍼. 시그니처 데프, 콜렉션 데프 등을 추가로 추출하는 데 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="cb465f350147752217292b36e4f6e8af3b681307" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;NodeDef&lt;/code&gt; proto representing the op that failed.</source>
          <target state="translated">&lt;code&gt;NodeDef&lt;/code&gt; 의 실패 연산을 나타내는 프로토.</target>
        </trans-unit>
        <trans-unit id="ff313cdcfce21b44585ea5f9a91a7a3dc6de0178" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Operation&lt;/code&gt; objects on which this op has a control dependency.</source>
          <target state="translated">이 op에 제어 종속성이 있는 &lt;code&gt;Operation&lt;/code&gt; 개체</target>
        </trans-unit>
        <trans-unit id="87fc441eb7b6054082173c9f1ab6bf4c42c56cd4" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Operation&lt;/code&gt; of this variable.</source>
          <target state="translated">이 변수 의 &lt;code&gt;Operation&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4a9cda719e59cf9091cbf0d01fc46d4aaf72fff1" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Operation&lt;/code&gt; that failed, or None.</source>
          <target state="translated">&lt;code&gt;Operation&lt;/code&gt; 실패하지 않거나 아무도 그.</target>
        </trans-unit>
        <trans-unit id="438a9dc8c58e4a098826c43ea413784f9b3995d6" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Operation&lt;/code&gt; that produces &lt;code&gt;values&lt;/code&gt; as an output.</source>
          <target state="translated">출력으로 &lt;code&gt;values&lt;/code&gt; 을 생성 하는 &lt;code&gt;Operation&lt;/code&gt; 입니다 .</target>
        </trans-unit>
        <trans-unit id="b9d068224c3abe35b7ed380528fe996c78ebd4f5" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Operation&lt;/code&gt; that produces this tensor as an output.</source>
          <target state="translated">이 텐서를 출력으로 생성 하는 &lt;code&gt;Operation&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="05c1129e9d0be24dc0a8495f7e24b9eaf32d0723" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Operation&lt;/code&gt; with the given &lt;code&gt;name&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;Operation&lt;/code&gt; 주어진와 &lt;code&gt;name&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="207e00a2d0ea7a2feedfe3c413469ac89cde7bb0" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;QueueRunner&lt;/code&gt;, combined with the &lt;code&gt;Coordinator&lt;/code&gt;, helps handle these issues.</source>
          <target state="translated">&lt;code&gt;QueueRunner&lt;/code&gt; 는 의와 결합 &lt;code&gt;Coordinator&lt;/code&gt; , 이러한 문제를 처리하는 데 도움이됩니다.</target>
        </trans-unit>
        <trans-unit id="c6875e1876426bfecf07e4b4acdb8ea569eea6f3" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;SavedModel&lt;/code&gt; contains:</source>
          <target state="translated">&lt;code&gt;SavedModel&lt;/code&gt; 에는 다음 이 포함됩니다.</target>
        </trans-unit>
        <trans-unit id="6f4f2790a6a7f05dc0c928fcd21f48c92ded1ee8" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;SavedModel&lt;/code&gt; saved by the &lt;code&gt;export_saved_model&lt;/code&gt; method does not include the cluster centers. However, the cluster centers may be retrieved by the latest checkpoint saved during training. Specifically,</source>
          <target state="translated">&lt;code&gt;SavedModel&lt;/code&gt; 는 에 의해 저장 &lt;code&gt;export_saved_model&lt;/code&gt; 의 클러스터 센터를 포함하지 않는 방법. 그러나 훈련 중에 저장된 최신 체크 포인트로 클러스터 센터를 검색 할 수 있습니다. 구체적으로 특별히,</target>
        </trans-unit>
        <trans-unit id="e6039bfa2164055554cd488d18e16d9f34bf9b47" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;SavedModelBuilder&lt;/code&gt; class provides functionality to build a &lt;code&gt;SavedModel&lt;/code&gt; protocol buffer. Specifically, this allows multiple meta graphs to be saved as part of a single language-neutral &lt;code&gt;SavedModel&lt;/code&gt;, while sharing variables and assets.</source>
          <target state="translated">&lt;code&gt;SavedModelBuilder&lt;/code&gt; 의 클래스는 구축하는 기능 제공 &lt;code&gt;SavedModel&lt;/code&gt; 의 프로토콜 버퍼를. 특히 변수와 자산을 공유하면서 여러 메타 그래프를 단일 언어 중립 &lt;code&gt;SavedModel&lt;/code&gt; 의 일부로 저장할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7cd194d774bf843726a9b31fd8c5760738d54965" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Saver&lt;/code&gt; class adds ops to save and restore variables to and from &lt;em&gt;checkpoints&lt;/em&gt;. It also provides convenience methods to run these ops.</source>
          <target state="translated">&lt;code&gt;Saver&lt;/code&gt; 클래스는 저장과에서 변수를 복원하기 위해 작전을 추가 &lt;em&gt;체크 포인트&lt;/em&gt; . 또한 이러한 작업을 실행하는 편리한 방법을 제공합니다.</target>
        </trans-unit>
        <trans-unit id="4996fa4000c885aea5b079a558bc6345b7b96a57" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;SparseTensor&lt;/code&gt; must have rank &lt;code&gt;R&lt;/code&gt; greater than 1, and the first dimension is treated as the minibatch dimension. Elements of the &lt;code&gt;SparseTensor&lt;/code&gt; must be sorted in increasing order of this first dimension. The serialized &lt;code&gt;SparseTensor&lt;/code&gt; objects going into each row of the output &lt;code&gt;Tensor&lt;/code&gt; will have rank &lt;code&gt;R-1&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;SparseTensor&lt;/code&gt; 는 랭크 있어야 &lt;code&gt;R&lt;/code&gt; 에 1보다 큰를, 제 1 차원은 minibatch 차원으로 처리한다. &lt;code&gt;SparseTensor&lt;/code&gt; 의 요소는 이 첫 번째 차원의 순서대로 정렬되어야합니다. 출력 &lt;code&gt;Tensor&lt;/code&gt; 의 각 행으로 들어가는 직렬화 된 &lt;code&gt;SparseTensor&lt;/code&gt; 오브젝트 는 &lt;code&gt;R-1&lt;/code&gt; 등급을 갖습니다 .</target>
        </trans-unit>
        <trans-unit id="b42219c4a7badee8ff4052cb167c2aad9136d9f3" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;SparseTensor&lt;/code&gt; returned by this function has the following properties:</source>
          <target state="translated">&lt;code&gt;SparseTensor&lt;/code&gt; 이 함수에 의해 반환에는 다음과 같은 속성이 있습니다 :</target>
        </trans-unit>
        <trans-unit id="ef8d47ae2cffd6a60717723743196db2da48e873" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;SparseTensor&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;SparseTensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e61a9703a7b332edaa3d2a56d6128abb09ee039b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;Operation&lt;/code&gt; in the Graph corresponding to &lt;code&gt;obj&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;obj&lt;/code&gt; 에 해당하는 그래프 의 &lt;code&gt;Tensor&lt;/code&gt; 또는 &lt;code&gt;Operation&lt;/code&gt; 입니다 .</target>
        </trans-unit>
        <trans-unit id="21aeac68c332c23a4035410d874f4d643b5e9753" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Tensor&lt;/code&gt; with the given &lt;code&gt;name&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;Tensor&lt;/code&gt; 주어진와 &lt;code&gt;name&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="062bc5ef63073ebe0bba42c69dd60fbbac0ba11a" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;TensorShape&lt;/code&gt; of this variable.</source>
          <target state="translated">이 변수 의 &lt;code&gt;TensorShape&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="7d5f495d7cfc5ed68324d2dab206b4e7d15c1c2e" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Variable()&lt;/code&gt; constructor requires an initial value for the variable, which can be a &lt;code&gt;Tensor&lt;/code&gt; of any type and shape. The initial value defines the type and shape of the variable. After construction, the type and shape of the variable are fixed. The value can be changed using one of the assign methods.</source>
          <target state="translated">&lt;code&gt;Variable()&lt;/code&gt; 생성자는 될 수있는 변수의 초기 값이 있어야 &lt;code&gt;Tensor&lt;/code&gt; 모든 유형 및 형상을. 초기 값은 변수의 유형과 모양을 정의합니다. 시공 후 변수의 유형과 모양이 고정됩니다. assign 메소드 중 하나를 사용하여 값을 변경할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="1083cab47ab61c7cdda4d83367b338d6c7e04350" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Variable()&lt;/code&gt; constructor requires an initial value for the variable, which can be a &lt;code&gt;Tensor&lt;/code&gt; of any type and shape. This initial value defines the type and shape of the variable. After construction, the type and shape of the variable are fixed. The value can be changed using one of the assign methods.</source>
          <target state="translated">&lt;code&gt;Variable()&lt;/code&gt; 생성자는 될 수있는 변수의 초기 값이 있어야 &lt;code&gt;Tensor&lt;/code&gt; 모든 유형 및 형상을. 이 초기 값은 변수의 유형과 모양을 정의합니다. 시공 후 변수의 유형과 모양이 고정됩니다. assign 메소드 중 하나를 사용하여 값을 변경할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="127a5eff8bb10c7a9751d8d922f006229b0755c5" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Variable&lt;/code&gt; for the slot if it was created, &lt;code&gt;None&lt;/code&gt; otherwise.</source>
          <target state="translated">&lt;code&gt;Variable&lt;/code&gt; 슬롯에 대한이 생성 된 경우, &lt;code&gt;None&lt;/code&gt; , 그렇지.</target>
        </trans-unit>
        <trans-unit id="368fe6644a57bbac64f15832c728e327af009d67" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Vocabulary&lt;/code&gt; object will performs the following mapping:</source>
          <target state="translated">&lt;code&gt;Vocabulary&lt;/code&gt; 객체는 다음 매핑을 수행합니다 :</target>
        </trans-unit>
        <trans-unit id="519c59ffc79a16af729e3142dd3abe9ca662d6c6" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;accuracy&lt;/code&gt; function creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the frequency with which &lt;code&gt;predictions&lt;/code&gt; matches &lt;code&gt;labels&lt;/code&gt;. This frequency is ultimately returned as &lt;code&gt;accuracy&lt;/code&gt;: an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;accuracy&lt;/code&gt; 함수는 두 개의 로컬 변수 생성 &lt;code&gt;total&lt;/code&gt; 과 &lt;code&gt;count&lt;/code&gt; 되는 빈도를 계산하는 데 사용되는 &lt;code&gt;predictions&lt;/code&gt; 일치하는 &lt;code&gt;labels&lt;/code&gt; . 이 주파수는 궁극적으로 반환된다 &lt;code&gt;accuracy&lt;/code&gt; : 단순히 분할가 멱등 동작 &lt;code&gt;total&lt;/code&gt; 로 &lt;code&gt;count&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="eb05150efdb907d6c2345164aacf0bfaba0751c2" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;apply()&lt;/code&gt; method adds shadow copies of trained variables and add ops that maintain a moving average of the trained variables in their shadow copies. It is used when building the training model. The ops that maintain moving averages are typically run after each training step. The &lt;code&gt;average()&lt;/code&gt; and &lt;code&gt;average_name()&lt;/code&gt; methods give access to the shadow variables and their names. They are useful when building an evaluation model, or when restoring a model from a checkpoint file. They help use the moving averages in place of the last trained values for evaluations.</source>
          <target state="translated">&lt;code&gt;apply()&lt;/code&gt; 메소드는 훈련 변수의 섀도 복사본을 추가하고 자신의 섀도 복사본에 훈련 된 변수의 이동 평균을 유지 작전을 추가합니다. 훈련 모델을 만들 때 사용됩니다. 이동 평균을 유지하는 작전은 일반적으로 각 훈련 단계 후에 실행됩니다. &lt;code&gt;average()&lt;/code&gt; 및 &lt;code&gt;average_name()&lt;/code&gt; 메소드는 그림자 변수와 이름에 대한 액세스를 제공합니다. 평가 모델을 작성하거나 검사 점 파일에서 모델을 복원 할 때 유용합니다. 평가를 위해 마지막 훈련 된 값 대신 이동 평균을 사용하도록 도와줍니다.</target>
        </trans-unit>
        <trans-unit id="606eed9ef4b94263c255e5099fa91bbc0424bdd2" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;apply()&lt;/code&gt; method has to be called to create shadow variables and add ops to maintain moving averages.</source>
          <target state="translated">&lt;code&gt;apply()&lt;/code&gt; 메소드는 이동 평균 유지 OPS 그림자 변수를 생성하고 추가 호출되어야한다.</target>
        </trans-unit>
        <trans-unit id="fc2517e9824df1742df7d5a7c8c3c56a268719aa" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;auc&lt;/code&gt; function creates four local variables, &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; that are used to compute the AUC. To discretize the AUC curve, a linearly spaced set of thresholds is used to compute pairs of recall and precision values. The area under the ROC-curve is therefore computed using the height of the recall values by the false positive rate, while the area under the PR-curve is the computed using the height of the precision values by the recall.</source>
          <target state="translated">&lt;code&gt;auc&lt;/code&gt; 기능은 네 로컬 변수 생성 &lt;code&gt;true_positives&lt;/code&gt; , &lt;code&gt;true_negatives&lt;/code&gt; , &lt;code&gt;false_positives&lt;/code&gt; 및 &lt;code&gt;false_negatives&lt;/code&gt; AUC를 계산하기 위해 사용된다. AUC 곡선을 이산화시키기 위해 선형 간격의 임계 값 세트를 사용하여 리콜 및 정밀 값 쌍을 계산합니다. 따라서 ROC- 커브 아래 영역은 리콜 값의 높이를 가양 성 비율로 사용하여 계산되는 반면 PR- 커브 아래 영역은 리콜에 의해 정밀도 값의 높이를 사용하여 계산됩니다.</target>
        </trans-unit>
        <trans-unit id="8af58715c30e66d456c8d6905c0d5153fbdbbc7c" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;band&lt;/code&gt; part is computed as follows: Assume &lt;code&gt;input&lt;/code&gt; has &lt;code&gt;k&lt;/code&gt; dimensions &lt;code&gt;[I, J, K, ..., M, N]&lt;/code&gt;, then the output is a tensor with the same shape where</source>
          <target state="translated">&lt;code&gt;band&lt;/code&gt; 다음 부분이 계산된다 가정 &lt;code&gt;input&lt;/code&gt; 갖는 &lt;code&gt;k&lt;/code&gt; 개의 치수 &lt;code&gt;[I, J, K, ..., M, N]&lt;/code&gt; , 그 출력이 동일한 형상을 가진 곳 텐서</target>
        </trans-unit>
        <trans-unit id="c1eb08b43ce7219e68f0c3bd3c76b2d17d8da595" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;branch_fns&lt;/code&gt; parameter is either a dict from &lt;code&gt;int&lt;/code&gt; to callables, or list of (&lt;code&gt;int&lt;/code&gt;, callable) pairs, or simply a list of callables (in which case the index is implicitly the key). The &lt;code&gt;branch_index&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; is used to select an element in &lt;code&gt;branch_fns&lt;/code&gt; with matching &lt;code&gt;int&lt;/code&gt; key, falling back to &lt;code&gt;default&lt;/code&gt; if none match, or &lt;code&gt;max(keys)&lt;/code&gt; if no &lt;code&gt;default&lt;/code&gt; is provided. The keys must form a contiguous set from &lt;code&gt;0&lt;/code&gt; to &lt;code&gt;len(branch_fns) - 1&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;branch_fns&lt;/code&gt; 의 파라미터는 하나의 딕셔너리이다 &lt;code&gt;int&lt;/code&gt; callables, 또는 (목록 &lt;code&gt;int&lt;/code&gt; , 호출) 쌍, 또는 단순히 (인덱스 키 암시되는 경우) callables 목록. &lt;code&gt;branch_index&lt;/code&gt; &lt;code&gt;Tensor&lt;/code&gt; 의 요소를 선택하는 데 사용됩니다 &lt;code&gt;branch_fns&lt;/code&gt; 일치와 &lt;code&gt;int&lt;/code&gt; 다시 떨어지는 키를 &lt;code&gt;default&lt;/code&gt; 경우 없음 일치, 또는 &lt;code&gt;max(keys)&lt;/code&gt; 어떤 경우 &lt;code&gt;default&lt;/code&gt; 제공되지 않습니다. 키는 &lt;code&gt;0&lt;/code&gt; 에서 &lt;code&gt;len(branch_fns) - 1&lt;/code&gt; 사이의 연속 세트를 형성해야합니다 .</target>
        </trans-unit>
        <trans-unit id="191ea315ef50769cbc5f21b205a7c35e5f727b01" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;capacity&lt;/code&gt; argument controls the how long the prefetching is allowed to grow the queues.</source>
          <target state="translated">&lt;code&gt;capacity&lt;/code&gt; 인수는 프리 페치가 큐 성장을 허용 얼마나 오래 제어합니다.</target>
        </trans-unit>
        <trans-unit id="90470bf7983fc786e9b2f478b52410df3cb933b0" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;compact&lt;/code&gt; format is recommended as the one with best performance. In case you need to cast a tensor into a compact format manually, use &lt;a href=&quot;../gather_nd&quot;&gt;&lt;code&gt;tf.gather_nd&lt;/code&gt;&lt;/a&gt;. An example for a tensor of shape [m, m]:</source>
          <target state="translated">&lt;code&gt;compact&lt;/code&gt; 형식은 최고의 성능과 하나로 좋습니다. 텐서를 컴팩트 형식으로 수동으로 캐스팅 해야하는 경우 &lt;a href=&quot;../gather_nd&quot;&gt; &lt;code&gt;tf.gather_nd&lt;/code&gt; 를&lt;/a&gt; 사용 하십시오 . 모양의 텐서 [m, m]의 예 :</target>
        </trans-unit>
        <trans-unit id="97f57a9366600ee779830b27b2d179f2f5db2b92" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;concentration&lt;/code&gt; represents mean total counts of class occurrence, i.e.,</source>
          <target state="translated">&lt;code&gt;concentration&lt;/code&gt; , 즉 클래스 발생의 평균 총 수를 나타냅니다</target>
        </trans-unit>
        <trans-unit id="01ab58045b90ae07778088607a3eab393fc1bb6a" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;condition&lt;/code&gt; tensor acts as a mask that chooses, based on the value at each element, whether the corresponding element / row in the output should be taken from &lt;code&gt;x&lt;/code&gt; (if true) or &lt;code&gt;y&lt;/code&gt; (if false).</source>
          <target state="translated">&lt;code&gt;condition&lt;/code&gt; 텐서는 각 요소의 값에 기초하여 선택한다면가 출력 내의 대응하는 요소 / 행에서 수행되어야하는지 여부 것을 마스크로서 역할을 &lt;code&gt;x&lt;/code&gt; (true 인 경우), 또는 &lt;code&gt;y&lt;/code&gt; (FALSE 경우).</target>
        </trans-unit>
        <trans-unit id="9bfb9121150515c59120455c6322fe9bdac07ae9" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;config&lt;/code&gt; argument can be passed &lt;a href=&quot;../../../estimator/runconfig&quot;&gt;&lt;code&gt;tf.estimator.RunConfig&lt;/code&gt;&lt;/a&gt; object containing information about the execution environment. It is passed on to the &lt;code&gt;model_fn&lt;/code&gt;, if the &lt;code&gt;model_fn&lt;/code&gt; has a parameter named &quot;config&quot; (and input functions in the same manner). If the &lt;code&gt;config&lt;/code&gt; parameter is not passed, it is instantiated by the &lt;code&gt;Estimator&lt;/code&gt;. Not passing config means that defaults useful for local execution are used. &lt;code&gt;Estimator&lt;/code&gt; makes config available to the model (for instance, to allow specialization based on the number of workers available), and also uses some of its fields to control internals, especially regarding checkpointing.</source>
          <target state="translated">&lt;code&gt;config&lt;/code&gt; 인수는 전달 될 수 &lt;a href=&quot;../../../estimator/runconfig&quot;&gt; &lt;code&gt;tf.estimator.RunConfig&lt;/code&gt; 의&lt;/a&gt; 실행 환경에 대한 정보가 포함 된 개체를. 그것은에 전달 &lt;code&gt;model_fn&lt;/code&gt; 경우 &lt;code&gt;model_fn&lt;/code&gt; 는 &quot;구성&quot;(동일하게 입력 기능)라는 매개 변수를 갖는다. 는 IF &lt;code&gt;config&lt;/code&gt; 매개 변수가 전달되지 않으며, 그것은에 의해 인스턴스화 &lt;code&gt;Estimator&lt;/code&gt; . 구성을 전달하지 않으면 로컬 실행에 유용한 기본값이 사용됩니다. &lt;code&gt;Estimator&lt;/code&gt; 는 모델에 구성을 사용할 수있게하며 (예 : 사용 가능한 작업자 수에 따른 특수화 허용) 일부 필드를 사용하여 내부, 특히 검사 점 지정을 제어합니다.</target>
        </trans-unit>
        <trans-unit id="0bec4775822937a50bbd9f3cbf347be8160f7726" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;config&lt;/code&gt; argument can be passed &lt;a href=&quot;runconfig&quot;&gt;&lt;code&gt;tf.estimator.RunConfig&lt;/code&gt;&lt;/a&gt; object containing information about the execution environment. It is passed on to the &lt;code&gt;model_fn&lt;/code&gt;, if the &lt;code&gt;model_fn&lt;/code&gt; has a parameter named &quot;config&quot; (and input functions in the same manner). If the &lt;code&gt;config&lt;/code&gt; parameter is not passed, it is instantiated by the &lt;code&gt;Estimator&lt;/code&gt;. Not passing config means that defaults useful for local execution are used. &lt;code&gt;Estimator&lt;/code&gt; makes config available to the model (for instance, to allow specialization based on the number of workers available), and also uses some of its fields to control internals, especially regarding checkpointing.</source>
          <target state="translated">&lt;code&gt;config&lt;/code&gt; 인수는 전달 될 수 &lt;a href=&quot;runconfig&quot;&gt; &lt;code&gt;tf.estimator.RunConfig&lt;/code&gt; 의&lt;/a&gt; 실행 환경에 대한 정보가 포함 된 개체를. 그것은에 전달 &lt;code&gt;model_fn&lt;/code&gt; 경우 &lt;code&gt;model_fn&lt;/code&gt; 는 &quot;구성&quot;(동일하게 입력 기능)라는 매개 변수를 갖는다. 는 IF &lt;code&gt;config&lt;/code&gt; 매개 변수가 전달되지 않으며, 그것은에 의해 인스턴스화 &lt;code&gt;Estimator&lt;/code&gt; . 구성을 전달하지 않으면 로컬 실행에 유용한 기본값이 사용됩니다. &lt;code&gt;Estimator&lt;/code&gt; 는 모델에 구성을 사용할 수있게하며 (예 : 사용 가능한 작업자 수에 따른 특수화 허용) 일부 필드를 사용하여 내부, 특히 검사 점 지정을 제어합니다.</target>
        </trans-unit>
        <trans-unit id="0aeca4b97eca00ef17635cebe947fcd9da586a15" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;context_features&lt;/code&gt; keys are associated with a &lt;code&gt;SequenceExample&lt;/code&gt; as a whole, independent of time / frame. In contrast, the &lt;code&gt;sequence_features&lt;/code&gt; keys provide a way to access variable-length data within the &lt;code&gt;FeatureList&lt;/code&gt; section of the &lt;code&gt;SequenceExample&lt;/code&gt; proto. While the shapes of &lt;code&gt;context_features&lt;/code&gt; values are fixed with respect to frame, the frame dimension (the first dimension) of &lt;code&gt;sequence_features&lt;/code&gt; values may vary between &lt;code&gt;SequenceExample&lt;/code&gt; protos, and even between &lt;code&gt;feature_list&lt;/code&gt; keys within the same &lt;code&gt;SequenceExample&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;context_features&lt;/code&gt; 의 키는와 연관된 &lt;code&gt;SequenceExample&lt;/code&gt; 시간 / 프레임의 전체 독립적있다. 반대로 &lt;code&gt;sequence_features&lt;/code&gt; 키 는 &lt;code&gt;SequenceExample&lt;/code&gt; 프로토 타입 의 &lt;code&gt;FeatureList&lt;/code&gt; 섹션 내에서 가변 길이 데이터에 액세스하는 방법을 제공합니다 . &lt;code&gt;context_features&lt;/code&gt; 값 의 모양은 프레임에 대해 고정되어 있지만 &lt;code&gt;sequence_features&lt;/code&gt; 값 의 프레임 차원 (첫 번째 차원)은 &lt;code&gt;SequenceExample&lt;/code&gt; 프로토 타입 간에 , 심지어 동일한 &lt;code&gt;SequenceExample&lt;/code&gt; 내의 &lt;code&gt;feature_list&lt;/code&gt; 키 간에도 달라질 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="bb1682e2f681183d97e2a0110f16b4f60410e0df" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;coord&lt;/code&gt; argument is an optional coordinator that the threads will use to terminate together and report exceptions. If a coordinator is given, this method starts an additional thread to close the queue when the coordinator requests a stop.</source>
          <target state="translated">&lt;code&gt;coord&lt;/code&gt; 인수는 스레드가 함께 종료하고 예외를보고하는 데 사용할 옵션 코디네이터입니다. 코디네이터가 제공되면이 메소드는 코디네이터가 중지를 요청할 때 큐를 닫기 위해 추가 스레드를 시작합니다.</target>
        </trans-unit>
        <trans-unit id="79d54183b850ac8c8ff0b7cfd536e56b95627d32" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;cycle_length&lt;/code&gt; and &lt;code&gt;block_length&lt;/code&gt; arguments control the order in which elements are produced. &lt;code&gt;cycle_length&lt;/code&gt; controls the number of input elements that are processed concurrently. If you set &lt;code&gt;cycle_length&lt;/code&gt; to 1, this transformation will handle one input element at a time, and will produce identical results to &lt;a href=&quot;../../../../data/dataset#flat_map&quot;&gt;&lt;code&gt;tf.data.Dataset.flat_map&lt;/code&gt;&lt;/a&gt;. In general, this transformation will apply &lt;code&gt;map_func&lt;/code&gt; to &lt;code&gt;cycle_length&lt;/code&gt; input elements, open iterators on the returned &lt;code&gt;Dataset&lt;/code&gt; objects, and cycle through them producing &lt;code&gt;block_length&lt;/code&gt; consecutive elements from each iterator, and consuming the next input element each time it reaches the end of an iterator.</source>
          <target state="translated">&lt;code&gt;cycle_length&lt;/code&gt; 및 &lt;code&gt;block_length&lt;/code&gt; 의 인수 소자를 제작하는 순서를 제어한다. &lt;code&gt;cycle_length&lt;/code&gt; 는 동시에 처리되는 입력 요소 수를 제어합니다. &lt;code&gt;cycle_length&lt;/code&gt; 를 1로 설정하면 이 변환은 한 번에 하나의 입력 요소를 처리하고 &lt;a href=&quot;../../../../data/dataset#flat_map&quot;&gt; &lt;code&gt;tf.data.Dataset.flat_map&lt;/code&gt; &lt;/a&gt; 과 동일한 결과를 생성합니다 . 일반적으로이 변환은 &lt;code&gt;map_func&lt;/code&gt; 를 &lt;code&gt;cycle_length&lt;/code&gt; 입력 요소에 적용 하고 반환 된 &lt;code&gt;Dataset&lt;/code&gt; 객체에서 반복자를 연 &lt;code&gt;block_length&lt;/code&gt; 를다음 각 반복자에서 연속 요소를 생성 하고 반복자의 끝에 도달 할 때마다 다음 입력 요소를 소비합니다.</target>
        </trans-unit>
        <trans-unit id="ee978764731ae2547628b468794cefc836bc4795" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;cycle_length&lt;/code&gt; and &lt;code&gt;block_length&lt;/code&gt; arguments control the order in which elements are produced. &lt;code&gt;cycle_length&lt;/code&gt; controls the number of input elements that are processed concurrently. If you set &lt;code&gt;cycle_length&lt;/code&gt; to 1, this transformation will handle one input element at a time, and will produce identical results to &lt;a href=&quot;../../../data/dataset#flat_map&quot;&gt;&lt;code&gt;tf.data.Dataset.flat_map&lt;/code&gt;&lt;/a&gt;. In general, this transformation will apply &lt;code&gt;map_func&lt;/code&gt; to &lt;code&gt;cycle_length&lt;/code&gt; input elements, open iterators on the returned &lt;code&gt;Dataset&lt;/code&gt; objects, and cycle through them producing &lt;code&gt;block_length&lt;/code&gt; consecutive elements from each iterator, and consuming the next input element each time it reaches the end of an iterator.</source>
          <target state="translated">&lt;code&gt;cycle_length&lt;/code&gt; 및 &lt;code&gt;block_length&lt;/code&gt; 의 인수 소자를 제작하는 순서를 제어한다. &lt;code&gt;cycle_length&lt;/code&gt; 는 동시에 처리되는 입력 요소 수를 제어합니다. &lt;code&gt;cycle_length&lt;/code&gt; 를 1로 설정하면 이 변환은 한 번에 하나의 입력 요소를 처리하고 &lt;a href=&quot;../../../data/dataset#flat_map&quot;&gt; &lt;code&gt;tf.data.Dataset.flat_map&lt;/code&gt; &lt;/a&gt; 과 동일한 결과를 생성합니다 . 일반적으로이 변환은 &lt;code&gt;map_func&lt;/code&gt; 를 &lt;code&gt;cycle_length&lt;/code&gt; 입력 요소에 적용 하고 반환 된 &lt;code&gt;Dataset&lt;/code&gt; 객체에서 반복자를 연 다음이를 순환하여 &lt;code&gt;block_length&lt;/code&gt; 를 생성합니다. 각 반복자에서 연속 요소를 반복하고 반복자 끝에 도달 할 때마다 다음 입력 요소를 소비합니다.</target>
        </trans-unit>
        <trans-unit id="04f48577e80fcfb603fa15b3b9e05181dd539f9e" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;cycle_length&lt;/code&gt; and &lt;code&gt;block_length&lt;/code&gt; arguments control the order in which elements are produced. &lt;code&gt;cycle_length&lt;/code&gt; controls the number of input elements that are processed concurrently. If you set &lt;code&gt;cycle_length&lt;/code&gt; to 1, this transformation will handle one input element at a time, and will produce identical results to &lt;a href=&quot;../dataset#flat_map&quot;&gt;&lt;code&gt;tf.data.Dataset.flat_map&lt;/code&gt;&lt;/a&gt;. In general, this transformation will apply &lt;code&gt;map_func&lt;/code&gt; to &lt;code&gt;cycle_length&lt;/code&gt; input elements, open iterators on the returned &lt;code&gt;Dataset&lt;/code&gt; objects, and cycle through them producing &lt;code&gt;block_length&lt;/code&gt; consecutive elements from each iterator, and consuming the next input element each time it reaches the end of an iterator.</source>
          <target state="translated">&lt;code&gt;cycle_length&lt;/code&gt; 및 &lt;code&gt;block_length&lt;/code&gt; 의 인수 소자를 제작하는 순서를 제어한다. &lt;code&gt;cycle_length&lt;/code&gt; 는 동시에 처리되는 입력 요소 수를 제어합니다. &lt;code&gt;cycle_length&lt;/code&gt; 를 1로 설정하면 이 변환은 한 번에 하나의 입력 요소를 처리하고 &lt;a href=&quot;../dataset#flat_map&quot;&gt; &lt;code&gt;tf.data.Dataset.flat_map&lt;/code&gt; &lt;/a&gt; 과 동일한 결과를 생성합니다 . 일반적으로이 변환은 &lt;code&gt;map_func&lt;/code&gt; 를 &lt;code&gt;cycle_length&lt;/code&gt; 입력 요소에 적용 하고 반환 된 &lt;code&gt;Dataset&lt;/code&gt; 객체에서 반복자를 연 다음이를 순환하여 &lt;code&gt;block_length&lt;/code&gt; 를 생성합니다. 각 반복자에서 연속 요소를 반복하고 반복자 끝에 도달 할 때마다 다음 입력 요소를 소비합니다.</target>
        </trans-unit>
        <trans-unit id="eccbe3ff90cfb1e82cccca44957962bdd5ce30cd" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;cycle_length&lt;/code&gt; and &lt;code&gt;block_length&lt;/code&gt; arguments control the order in which elements are produced. &lt;code&gt;cycle_length&lt;/code&gt; controls the number of input elements that are processed concurrently. If you set &lt;code&gt;cycle_length&lt;/code&gt; to 1, this transformation will handle one input element at a time, and will produce identical results to &lt;a href=&quot;dataset#flat_map&quot;&gt;&lt;code&gt;tf.data.Dataset.flat_map&lt;/code&gt;&lt;/a&gt;. In general, this transformation will apply &lt;code&gt;map_func&lt;/code&gt; to &lt;code&gt;cycle_length&lt;/code&gt; input elements, open iterators on the returned &lt;code&gt;Dataset&lt;/code&gt; objects, and cycle through them producing &lt;code&gt;block_length&lt;/code&gt; consecutive elements from each iterator, and consuming the next input element each time it reaches the end of an iterator.</source>
          <target state="translated">&lt;code&gt;cycle_length&lt;/code&gt; 및 &lt;code&gt;block_length&lt;/code&gt; 의 인수 소자를 제작하는 순서를 제어한다. &lt;code&gt;cycle_length&lt;/code&gt; 는 동시에 처리되는 입력 요소 수를 제어합니다. &lt;code&gt;cycle_length&lt;/code&gt; 를 1로 설정하면 이 변환은 한 번에 하나의 입력 요소를 처리하고 &lt;a href=&quot;dataset#flat_map&quot;&gt; &lt;code&gt;tf.data.Dataset.flat_map&lt;/code&gt; &lt;/a&gt; 과 동일한 결과를 생성합니다 . 일반적으로이 변환은 &lt;code&gt;map_func&lt;/code&gt; 를 &lt;code&gt;cycle_length&lt;/code&gt; 입력 요소에 적용 하고 반환 된 &lt;code&gt;Dataset&lt;/code&gt; 객체에서 반복자를 연 다음이를 순환하여 &lt;code&gt;block_length&lt;/code&gt; 를 생성합니다. 각 반복자에서 연속 요소를 반복하고 반복자 끝에 도달 할 때마다 다음 입력 요소를 소비합니다.</target>
        </trans-unit>
        <trans-unit id="cdd71fb6bd2b9b57b19cddd99579978c6dafa2a7" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;data_format&lt;/code&gt; attr specifies the layout of the input and output tensors with the following options: &quot;NHWC&quot;: &lt;code&gt;[ batch, height, width, channels ]&lt;/code&gt; &quot;NCHW&quot;: &lt;code&gt;[ batch, channels, height, width ]&lt;/code&gt; &quot;NCHW_VECT_C&quot;: &lt;code&gt;qint8 [ batch, channels / 4, height, width, 4 ]&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;data_format&lt;/code&gt; 의 ATTR의 지정은 다음 옵션 입출력 텐서의 레이아웃 &quot;NHWC&quot; &lt;code&gt;[ batch, height, width, channels ]&lt;/code&gt; &quot;NCHW&quot; &lt;code&gt;[ batch, channels, height, width ]&lt;/code&gt; &quot;NCHW_VECT_C&quot; &lt;code&gt;qint8 [ batch, channels / 4, height, width, 4 ]&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="5cd12fa44d77e3c12fe697b0db4b93e48339e374" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;dataset_fn&lt;/code&gt; should take an &lt;a href=&quot;../../../../distribute/inputcontext&quot;&gt;&lt;code&gt;tf.distribute.InputContext&lt;/code&gt;&lt;/a&gt; instance where information about batching and input replication can be accessed:</source>
          <target state="translated">&lt;code&gt;dataset_fn&lt;/code&gt; 는 해야 &lt;a href=&quot;../../../../distribute/inputcontext&quot;&gt; &lt;code&gt;tf.distribute.InputContext&lt;/code&gt; 의&lt;/a&gt; 배치 및 입력 복제에 대한 정보를 액세스 할 수있는 인스턴스를 :</target>
        </trans-unit>
        <trans-unit id="0e86d0834b58ce3b47a884a1d468afe9d9201946" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;dataset_fn&lt;/code&gt; should take an &lt;a href=&quot;../../../distribute/inputcontext&quot;&gt;&lt;code&gt;tf.distribute.InputContext&lt;/code&gt;&lt;/a&gt; instance where information about batching and input replication can be accessed:</source>
          <target state="translated">&lt;code&gt;dataset_fn&lt;/code&gt; 는 해야 &lt;a href=&quot;../../../distribute/inputcontext&quot;&gt; &lt;code&gt;tf.distribute.InputContext&lt;/code&gt; 의&lt;/a&gt; 배치 및 입력 복제에 대한 정보를 액세스 할 수있는 인스턴스를 :</target>
        </trans-unit>
        <trans-unit id="dab43a435b361f56a83a42c04da29fda060c86e3" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;dataset_fn&lt;/code&gt; should take an &lt;a href=&quot;../inputcontext&quot;&gt;&lt;code&gt;tf.distribute.InputContext&lt;/code&gt;&lt;/a&gt; instance where information about batching and input replication can be accessed.</source>
          <target state="translated">&lt;code&gt;dataset_fn&lt;/code&gt; 는 해야 &lt;a href=&quot;../inputcontext&quot;&gt; &lt;code&gt;tf.distribute.InputContext&lt;/code&gt; 의&lt;/a&gt; 배치 및 입력 복제에 대한 정보에 액세스 할 수 인스턴스를.</target>
        </trans-unit>
        <trans-unit id="f7ca657c4395755383bc81fcb9f2b453ce90db09" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;dataset_fn&lt;/code&gt; should take an &lt;a href=&quot;../inputcontext&quot;&gt;&lt;code&gt;tf.distribute.InputContext&lt;/code&gt;&lt;/a&gt; instance where information about batching and input replication can be accessed:</source>
          <target state="translated">&lt;code&gt;dataset_fn&lt;/code&gt; 는 해야 &lt;a href=&quot;../inputcontext&quot;&gt; &lt;code&gt;tf.distribute.InputContext&lt;/code&gt; 의&lt;/a&gt; 배치 및 입력 복제에 대한 정보를 액세스 할 수있는 인스턴스를 :</target>
        </trans-unit>
        <trans-unit id="6fde1903f8238ad03f3998edc676b8256c4d75c5" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;dataset_fn&lt;/code&gt; should take an &lt;a href=&quot;inputcontext&quot;&gt;&lt;code&gt;tf.distribute.InputContext&lt;/code&gt;&lt;/a&gt; instance where information about batching and input replication can be accessed:</source>
          <target state="translated">&lt;code&gt;dataset_fn&lt;/code&gt; 는 해야 &lt;a href=&quot;inputcontext&quot;&gt; &lt;code&gt;tf.distribute.InputContext&lt;/code&gt; 의&lt;/a&gt; 배치 및 입력 복제에 대한 정보를 액세스 할 수있는 인스턴스를 :</target>
        </trans-unit>
        <trans-unit id="f20e1c4521e0296106d88f47b84176329b10342a" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;decode_proto&lt;/code&gt; op extracts fields from a serialized protocol buffers message into tensors. The fields in &lt;code&gt;field_names&lt;/code&gt; are decoded and converted to the corresponding &lt;code&gt;output_types&lt;/code&gt; if possible.</source>
          <target state="translated">&lt;code&gt;decode_proto&lt;/code&gt; 의 영업 이익은 텐서에 직렬화 된 프로토콜 버퍼 메시지에서 필드를 추출합니다. &lt;code&gt;field_names&lt;/code&gt; 의 필드는 가능한 경우 디코딩되어 해당 &lt;code&gt;output_types&lt;/code&gt; 로 변환됩니다 .</target>
        </trans-unit>
        <trans-unit id="61bfd7600a5bc08577b34e4662502a0cb1a1a96f" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;decorator_func&lt;/code&gt; argument with new metadata attached.</source>
          <target state="translated">&lt;code&gt;decorator_func&lt;/code&gt; 의 새로운 메타 데이터 인수 부착.</target>
        </trans-unit>
        <trans-unit id="a514f3a1501df389c97cb427fbd5d632c8c0d4a6" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;default_value&lt;/code&gt; is used for keys not present in the table.</source>
          <target state="translated">&lt;code&gt;default_value&lt;/code&gt; 테이블에 존재하지 않는 키에 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="8f256cc69c0f762014c0c50a38e920065363cfb4" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;descriptor_source&lt;/code&gt; attribute selects the source of protocol descriptors to consult when looking up &lt;code&gt;message_type&lt;/code&gt;. This may be:</source>
          <target state="translated">&lt;code&gt;descriptor_source&lt;/code&gt; 를 찾는 경우 속성 선택 프로토콜 기술자의 소스는 상담 &lt;code&gt;message_type&lt;/code&gt; 을 . 이것은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="9a92bd94cb0af3355b6f29220671131a1d4a6adc" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;device_name_or_function&lt;/code&gt; argument may either be a device name string, a device function, or None:</source>
          <target state="translated">&lt;code&gt;device_name_or_function&lt;/code&gt; 의 인수는 하나의 장치 이름 문자열, 디바이스 기능, 또는 유료 일 수있다 :</target>
        </trans-unit>
        <trans-unit id="19b121f477789a4199014186a6e228b0aa000947" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;enqueuer.get()&lt;/code&gt; should be an infinite stream of datas.</source>
          <target state="translated">&lt;code&gt;enqueuer.get()&lt;/code&gt; datas 무한 스트림이어야한다.</target>
        </trans-unit>
        <trans-unit id="ae1bab6951216e7b0f3d9533c0fe4cef0e27a5dc" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;fetches&lt;/code&gt; argument may be a single graph element, or an arbitrarily nested list, tuple, namedtuple, dict, or OrderedDict containing graph elements at its leaves. A graph element can be one of the following types:</source>
          <target state="translated">&lt;code&gt;fetches&lt;/code&gt; 인수 그래프는 단일 요소 또는 임의로 중첩리스트 튜플 일 수 namedtuple 그 잎의 그래프 요소를 포함하는 딕셔너리 또는 OrderedDict. 그래프 요소는 다음 유형 중 하나 일 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="785d7e8c57af0973369bcb00a38fc045b0c9ae7b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;file_pattern&lt;/code&gt; argument should be a small number of glob patterns. If your filenames have already been globbed, use &lt;a href=&quot;../../../../data/dataset#from_tensor_slices&quot;&gt;&lt;code&gt;Dataset.from_tensor_slices(filenames)&lt;/code&gt;&lt;/a&gt; instead, as re-globbing every filename with &lt;code&gt;list_files&lt;/code&gt; may result in poor performance with remote storage systems.</source>
          <target state="translated">&lt;code&gt;file_pattern&lt;/code&gt; 인수는 글로브 패턴의 소수이어야한다. 파일 이름이 이미 파악 된 경우, 모든 파일 이름을 &lt;code&gt;list_files&lt;/code&gt; 로 다시 지정 하면 원격 스토리지 시스템의 성능이 저하 될 수 있으므로 &lt;a href=&quot;../../../../data/dataset#from_tensor_slices&quot;&gt; &lt;code&gt;Dataset.from_tensor_slices(filenames)&lt;/code&gt; &lt;/a&gt; 대신 사용 하십시오 .</target>
        </trans-unit>
        <trans-unit id="ae29332866e5bc8b9ee07b134fda5a738b8021d6" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;file_pattern&lt;/code&gt; argument should be a small number of glob patterns. If your filenames have already been globbed, use &lt;a href=&quot;../../../data/dataset#from_tensor_slices&quot;&gt;&lt;code&gt;Dataset.from_tensor_slices(filenames)&lt;/code&gt;&lt;/a&gt; instead, as re-globbing every filename with &lt;code&gt;list_files&lt;/code&gt; may result in poor performance with remote storage systems.</source>
          <target state="translated">&lt;code&gt;file_pattern&lt;/code&gt; 인수는 글로브 패턴의 소수이어야한다. 파일 이름이 이미 파악 된 경우, 모든 파일 이름을 &lt;code&gt;list_files&lt;/code&gt; 로 다시 지정 하면 원격 스토리지 시스템의 성능이 저하 될 수 있으므로 &lt;a href=&quot;../../../data/dataset#from_tensor_slices&quot;&gt; &lt;code&gt;Dataset.from_tensor_slices(filenames)&lt;/code&gt; &lt;/a&gt; 대신 사용 하십시오 .</target>
        </trans-unit>
        <trans-unit id="3f18a1c227e50f0bcfa83536b4f1a61f14aca11e" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;file_pattern&lt;/code&gt; argument should be a small number of glob patterns. If your filenames have already been globbed, use &lt;a href=&quot;../dataset#from_tensor_slices&quot;&gt;&lt;code&gt;Dataset.from_tensor_slices(filenames)&lt;/code&gt;&lt;/a&gt; instead, as re-globbing every filename with &lt;code&gt;list_files&lt;/code&gt; may result in poor performance with remote storage systems.</source>
          <target state="translated">&lt;code&gt;file_pattern&lt;/code&gt; 인수는 글로브 패턴의 소수이어야한다. 파일 이름이 이미 파악 된 경우, 모든 파일 이름을 &lt;code&gt;list_files&lt;/code&gt; 로 다시 지정 하면 원격 스토리지 시스템의 성능이 저하 될 수 있으므로 &lt;a href=&quot;../dataset#from_tensor_slices&quot;&gt; &lt;code&gt;Dataset.from_tensor_slices(filenames)&lt;/code&gt; &lt;/a&gt; 대신 사용 하십시오 .</target>
        </trans-unit>
        <trans-unit id="a5d371bf05fee9ac34c79b3ecb1708c225ca7a5e" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;file_pattern&lt;/code&gt; argument should be a small number of glob patterns. If your filenames have already been globbed, use &lt;a href=&quot;dataset#from_tensor_slices&quot;&gt;&lt;code&gt;Dataset.from_tensor_slices(filenames)&lt;/code&gt;&lt;/a&gt; instead, as re-globbing every filename with &lt;code&gt;list_files&lt;/code&gt; may result in poor performance with remote storage systems.</source>
          <target state="translated">&lt;code&gt;file_pattern&lt;/code&gt; 인수는 글로브 패턴의 소수이어야한다. 파일 이름이 이미 파악 된 경우, 모든 파일 이름을 &lt;code&gt;list_files&lt;/code&gt; 로 다시 지정 하면 원격 스토리지 시스템의 성능이 저하 될 수 있으므로 &lt;a href=&quot;dataset#from_tensor_slices&quot;&gt; &lt;code&gt;Dataset.from_tensor_slices(filenames)&lt;/code&gt; &lt;/a&gt; 대신 사용 하십시오 .</target>
        </trans-unit>
        <trans-unit id="ae4fe9c389bd86de17fd613b2cb617cf5b34971a" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;generator&lt;/code&gt; argument must be a callable object that returns an object that supports the &lt;code&gt;iter()&lt;/code&gt; protocol (e.g. a generator function). The elements generated by &lt;code&gt;generator&lt;/code&gt; must be compatible with the given &lt;code&gt;output_types&lt;/code&gt; and (optional) &lt;code&gt;output_shapes&lt;/code&gt; arguments.</source>
          <target state="translated">&lt;code&gt;generator&lt;/code&gt; 인수는 호출 객체 여야가 반환 객체가 지원하는 &lt;code&gt;iter()&lt;/code&gt; 프로토콜 (예 : 발전기 기능). &lt;code&gt;generator&lt;/code&gt; 가 생성 한 요소 는 주어진 &lt;code&gt;output_types&lt;/code&gt; 및 (선택적) &lt;code&gt;output_shapes&lt;/code&gt; 인수 와 호환 가능해야합니다 .</target>
        </trans-unit>
        <trans-unit id="d34ef9051018aee7b571f4ddcf30ab7cfc4276af" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;get_losses_for&lt;/code&gt; method allows to retrieve the losses relevant to a specific set of inputs.</source>
          <target state="translated">&lt;code&gt;get_losses_for&lt;/code&gt; 방법은 입력들의 특정 세트에 관련된 손실을 가져올 수있다.</target>
        </trans-unit>
        <trans-unit id="c06d13d8339819e2aa27ef381a46e85c67ddba64" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;get_updates_for&lt;/code&gt; method allows to retrieve the updates relevant to a specific set of inputs.</source>
          <target state="translated">&lt;code&gt;get_updates_for&lt;/code&gt; 방법은 입력의 특정 세트에 관련 업데이트를 검색 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="ec9647e5e43640fc561f86326ed66d7b1839d523" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;ignore_longer_outputs_than_inputs&lt;/code&gt; option allows to specify the behavior of the CTCLoss when dealing with sequences that have longer outputs than inputs. If true, the CTCLoss will simply return zero gradient for those items, otherwise an InvalidArgument error is returned, stopping training.</source>
          <target state="translated">&lt;code&gt;ignore_longer_outputs_than_inputs&lt;/code&gt; 옵션은 입력 이상 출력이 시퀀스를 처리 할 때 CTCLoss의 동작을 지정할 수 있습니다. true 인 경우 CTCLoss는 해당 항목에 대해 단순히 0 그라데이션을 반환합니다. 그렇지 않으면 InvalidArgument 오류가 반환되어 교육이 중단됩니다.</target>
        </trans-unit>
        <trans-unit id="3e77ea3b32e4a62532979c99f1006fa100924b5f" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;indices&lt;/code&gt;, &lt;code&gt;values&lt;/code&gt;, and &lt;code&gt;shapes&lt;/code&gt; lists must have the same length.</source>
          <target state="translated">&lt;code&gt;indices&lt;/code&gt; , &lt;code&gt;values&lt;/code&gt; 및 &lt;code&gt;shapes&lt;/code&gt; 목록은 같은 길이가 있어야합니다.</target>
        </trans-unit>
        <trans-unit id="8cca3019d062a9892e2676ec309dbc9e2a90d317" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;input&lt;/code&gt; tensor has shape &lt;code&gt;[batch, in_height, in_width, depth]&lt;/code&gt; and the &lt;code&gt;filter&lt;/code&gt; tensor has shape &lt;code&gt;[filter_height, filter_width, depth]&lt;/code&gt;, i.e., each input channel is processed independently of the others with its own structuring function. The &lt;code&gt;output&lt;/code&gt; tensor has shape &lt;code&gt;[batch, out_height, out_width, depth]&lt;/code&gt;. The spatial dimensions of the output tensor depend on the &lt;code&gt;padding&lt;/code&gt; algorithm. We currently only support the default &quot;NHWC&quot; &lt;code&gt;data_format&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 텐서 형상 갖는다 &lt;code&gt;[batch, in_height, in_width, depth]&lt;/code&gt; 상기 &lt;code&gt;filter&lt;/code&gt; 텐서 형상 갖는다 &lt;code&gt;[filter_height, filter_width, depth]&lt;/code&gt; 즉, 각각의 입력 채널이 독립적으로 자신의 구조 기능 다른 것의 처리된다. &lt;code&gt;output&lt;/code&gt; 텐서는 형상을 갖고 &lt;code&gt;[batch, out_height, out_width, depth]&lt;/code&gt; . 출력 텐서의 공간 치수는 &lt;code&gt;padding&lt;/code&gt; 알고리즘 에 따라 다릅니다 . 현재 기본 &quot;NHWC&quot; &lt;code&gt;data_format&lt;/code&gt; 만 지원합니다 .</target>
        </trans-unit>
        <trans-unit id="e66cb3e17296e0dbd7031b533b7074c9bfdfef6b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;input&lt;/code&gt; tensor has shape &lt;code&gt;[batch, in_height, in_width, depth]&lt;/code&gt; and the &lt;code&gt;filters&lt;/code&gt; tensor has shape &lt;code&gt;[filter_height, filter_width, depth]&lt;/code&gt;, i.e., each input channel is processed independently of the others with its own structuring function. The &lt;code&gt;output&lt;/code&gt; tensor has shape &lt;code&gt;[batch, out_height, out_width, depth]&lt;/code&gt;. The spatial dimensions of the output tensor depend on the &lt;code&gt;padding&lt;/code&gt; algorithm. We currently only support the default &quot;NHWC&quot; &lt;code&gt;data_format&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 텐서 형상 갖는다 &lt;code&gt;[batch, in_height, in_width, depth]&lt;/code&gt; 및 &lt;code&gt;filters&lt;/code&gt; 형상을 갖는다 텐서 &lt;code&gt;[filter_height, filter_width, depth]&lt;/code&gt; 즉, 각각의 입력 채널이 독립적으로 자신의 구조 기능 다른 것의 처리된다. &lt;code&gt;output&lt;/code&gt; 텐서는 형상을 갖는 &lt;code&gt;[batch, out_height, out_width, depth]&lt;/code&gt; . 출력 텐서의 공간 치수는 &lt;code&gt;padding&lt;/code&gt; 알고리즘 에 따라 다릅니다 . 현재 기본 &quot;NHWC&quot; &lt;code&gt;data_format&lt;/code&gt; 만 지원합니다 .</target>
        </trans-unit>
        <trans-unit id="17d78b23014241429cebda7a7ed18dd11ac18169" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;input_fn&lt;/code&gt; should take an &lt;a href=&quot;../../../../distribute/inputcontext&quot;&gt;&lt;code&gt;tf.distribute.InputContext&lt;/code&gt;&lt;/a&gt; object where information about batching and input sharding can be accessed:</source>
          <target state="translated">&lt;code&gt;input_fn&lt;/code&gt; 해야 &lt;a href=&quot;../../../../distribute/inputcontext&quot;&gt; &lt;code&gt;tf.distribute.InputContext&lt;/code&gt; 의&lt;/a&gt; 배치 및 입력 샤딩에 대한 정보에 액세스 할 수있는 개체를 :</target>
        </trans-unit>
        <trans-unit id="5a7667b672c0fb6a912c80d541aa0d63d101f97d" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;input_fn&lt;/code&gt; should take an &lt;a href=&quot;../../../distribute/inputcontext&quot;&gt;&lt;code&gt;tf.distribute.InputContext&lt;/code&gt;&lt;/a&gt; object where information about batching and input sharding can be accessed:</source>
          <target state="translated">&lt;code&gt;input_fn&lt;/code&gt; 해야 &lt;a href=&quot;../../../distribute/inputcontext&quot;&gt; &lt;code&gt;tf.distribute.InputContext&lt;/code&gt; 의&lt;/a&gt; 배치 및 입력 샤딩에 대한 정보에 액세스 할 수있는 개체를 :</target>
        </trans-unit>
        <trans-unit id="659e1fc33dd53c3ed2709a794415182888957e1f" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;inputs&lt;/code&gt; Tensor's innermost dimension size, &lt;code&gt;num_classes&lt;/code&gt;, represents &lt;code&gt;num_labels + 1&lt;/code&gt; classes, where num_labels is the number of true labels, and the largest value &lt;code&gt;(num_classes - 1)&lt;/code&gt; is reserved for the blank label.</source>
          <target state="translated">&lt;code&gt;inputs&lt;/code&gt; 텐서의 안쪽 치수 크기, &lt;code&gt;num_classes&lt;/code&gt; 을 나타냅니다 &lt;code&gt;num_labels + 1&lt;/code&gt; num_labels 사실 라벨의 수 및 최대 값이고, 클래스 &lt;code&gt;(num_classes - 1)&lt;/code&gt; 빈 레이블이 예약되어가.</target>
        </trans-unit>
        <trans-unit id="54adbaacaf1b1235d65bae24606d9417fde02168" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;job_name&lt;/code&gt;, &lt;code&gt;task_index&lt;/code&gt;, and &lt;code&gt;protocol&lt;/code&gt; arguments are optional, and override any information provided in &lt;code&gt;server_or_cluster_def&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;job_name&lt;/code&gt; , &lt;code&gt;task_index&lt;/code&gt; 하고, &lt;code&gt;protocol&lt;/code&gt; 인수는 선택 사항이며, 제공 정보 오버라이드 (override) &lt;code&gt;server_or_cluster_def&lt;/code&gt; 를 .</target>
        </trans-unit>
        <trans-unit id="a121b1c952b1d66b82abf663f7114cd18e26ce58" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;labels&lt;/code&gt; shape must match &lt;code&gt;logits&lt;/code&gt;, namely &lt;code&gt;[D0, D1, ... DN, label_dimension]&lt;/code&gt;. If &lt;code&gt;label_dimension=1&lt;/code&gt;, shape &lt;code&gt;[D0, D1, ... DN]&lt;/code&gt; is also supported.</source>
          <target state="translated">&lt;code&gt;labels&lt;/code&gt; 모양이 일치해야 &lt;code&gt;logits&lt;/code&gt; , 즉 &lt;code&gt;[D0, D1, ... DN, label_dimension]&lt;/code&gt; . 만약 &lt;code&gt;label_dimension=1&lt;/code&gt; , 형상 &lt;code&gt;[D0, D1, ... DN]&lt;/code&gt; 또한 지원된다.</target>
        </trans-unit>
        <trans-unit id="1a7473ff7ad3c16ed4893e43c01e352fd1f3c9c8" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;labels&lt;/code&gt; shape must match &lt;code&gt;logits&lt;/code&gt;, namely &lt;code&gt;[D0, D1, ... DN]&lt;/code&gt; or &lt;code&gt;[D0, D1, ... DN, 1]&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;labels&lt;/code&gt; 모양이 일치해야합니다 &lt;code&gt;logits&lt;/code&gt; 을 즉, &lt;code&gt;[D0, D1, ... DN]&lt;/code&gt; 또는 &lt;code&gt;[D0, D1, ... DN, 1]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="337997246db8337cb34ef7810fd235c2b2595916" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;load&lt;/code&gt; operation requires the session in which to restore the graph definition and variables, the tags used to identify the meta graph def to load and the location of the SavedModel.</source>
          <target state="translated">그만큼 &lt;code&gt;load&lt;/code&gt; 운전 그래프 정의와 변수 하중과 SavedModel의 위치 DEF 메타 그래프를 식별하는 데 사용되는 태그를 복원 할 수있는 세션을 요구한다.</target>
        </trans-unit>
        <trans-unit id="7d30c15fc4a153c98926b67d30f2faeb014c1e26" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;local_init_op&lt;/code&gt; is an &lt;code&gt;Operation&lt;/code&gt; that is run always after a new session was created. If &lt;code&gt;None&lt;/code&gt;, this step is skipped.</source>
          <target state="translated">&lt;code&gt;local_init_op&lt;/code&gt; 는 인 &lt;code&gt;Operation&lt;/code&gt; 새로운 세션이 생성 된 후 항상 실행됩니다. 경우 &lt;code&gt;None&lt;/code&gt; ,이 단계를 건너 뜁니다.</target>
        </trans-unit>
        <trans-unit id="2701808169cb5f6edee74183d83e4eef575157e2" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;logs&lt;/code&gt; dictionary that callback methods take as argument will contain keys for quantities relevant to the current batch or epoch.</source>
          <target state="translated">그만큼 &lt;code&gt;logs&lt;/code&gt; 콜백 메소드는 현재 배치 또는 시대에 관련 수량에 대한 키를 포함 인수로 취할 것을 사전.</target>
        </trans-unit>
        <trans-unit id="fc148a0836cef52be69ad741735a0b91ff403bfd" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;loss_collection&lt;/code&gt; argument is ignored when executing eagerly. Consider holding on to the return value or collecting losses via a &lt;a href=&quot;../../../keras/model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;loss_collection&lt;/code&gt; 의 열망 실행시 인수는 무시됩니다. 를 통해 수익을 유지하거나 손실을 수집하십시오.&lt;a href=&quot;../../../keras/model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; 을 하십시오&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="1e3ee2c38e78144a1138ef9d3009b14144429a19" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;mean&lt;/code&gt; function creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the average of &lt;code&gt;values&lt;/code&gt;. This average is ultimately returned as &lt;code&gt;mean&lt;/code&gt; which is an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;mean&lt;/code&gt; 함수는 두 개의 로컬 변수 생성 &lt;code&gt;total&lt;/code&gt; 과 &lt;code&gt;count&lt;/code&gt; 평균 계산하는 데 사용되는 &lt;code&gt;values&lt;/code&gt; . 이 평균은 궁극적으로 반환 &lt;code&gt;mean&lt;/code&gt; 단순히 분할가 멱등 동작되는 &lt;code&gt;total&lt;/code&gt; 의해 &lt;code&gt;count&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="9d502617cdf652bd304ad5b305d7afe67fbd9b64" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;mean_absolute_error&lt;/code&gt; function creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the mean absolute error. This average is weighted by &lt;code&gt;weights&lt;/code&gt;, and it is ultimately returned as &lt;code&gt;mean_absolute_error&lt;/code&gt;: an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;mean_absolute_error&lt;/code&gt; 의 기능은 두 개의 로컬 변수 생성 &lt;code&gt;total&lt;/code&gt; 과 &lt;code&gt;count&lt;/code&gt; 평균 절대 오차를 계산하는 데 사용된다. 이 평균에 의해 가중되는 &lt;code&gt;weights&lt;/code&gt; 하고, 궁극적으로 반환된다 &lt;code&gt;mean_absolute_error&lt;/code&gt; : 멱등 동작은 단순히 나누는 것을 &lt;code&gt;total&lt;/code&gt; 로 &lt;code&gt;count&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5274af314d757e1ddc8b38db5fa05ae667819167" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;mean_cosine_distance&lt;/code&gt; function creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the average cosine distance between &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt;. This average is weighted by &lt;code&gt;weights&lt;/code&gt;, and it is ultimately returned as &lt;code&gt;mean_distance&lt;/code&gt;, which is an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;mean_cosine_distance&lt;/code&gt; 의 기능은 두 개의 로컬 변수 생성 &lt;code&gt;total&lt;/code&gt; 와 &lt;code&gt;count&lt;/code&gt; 사이의 평균 코사인 거리를 계산하기 위해 사용되는 &lt;code&gt;predictions&lt;/code&gt; 및 &lt;code&gt;labels&lt;/code&gt; . 이 평균의 가중치는 가중치로 &lt;code&gt;weights&lt;/code&gt; 가 부여되며 궁극적으로 &lt;code&gt;mean_distance&lt;/code&gt; 로 반환됩니다. 이 평균은 단순히 &lt;code&gt;total&lt;/code&gt; 를 &lt;code&gt;count&lt;/code&gt; 나누는 dem 등식 입니다.</target>
        </trans-unit>
        <trans-unit id="336c620aa42f01c6ce6a5a126282c5957ed048ef" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;mean_relative_error&lt;/code&gt; function creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the mean relative absolute error. This average is weighted by &lt;code&gt;weights&lt;/code&gt;, and it is ultimately returned as &lt;code&gt;mean_relative_error&lt;/code&gt;: an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;mean_relative_error&lt;/code&gt; 의 기능은 두 개의 로컬 변수 생성 &lt;code&gt;total&lt;/code&gt; 과 &lt;code&gt;count&lt;/code&gt; 평균 절대 상대 오차를 계산하는 데 사용된다. 이 평균에 의해 가중되는 &lt;code&gt;weights&lt;/code&gt; 하고, 궁극적으로 반환된다 &lt;code&gt;mean_relative_error&lt;/code&gt; : 단순히 분할가 멱등 동작 &lt;code&gt;total&lt;/code&gt; 로 &lt;code&gt;count&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="67c2bbcc205906b964a9ff8ac3199c6be162fe51" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;mean_squared_error&lt;/code&gt; function creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the mean squared error. This average is weighted by &lt;code&gt;weights&lt;/code&gt;, and it is ultimately returned as &lt;code&gt;mean_squared_error&lt;/code&gt;: an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;mean_squared_error&lt;/code&gt; 의 기능은 두 개의 로컬 변수 생성 &lt;code&gt;total&lt;/code&gt; 과 &lt;code&gt;count&lt;/code&gt; 평균 제곱 오차를 계산하는 데 사용된다. 이 평균에 의해 가중되는 &lt;code&gt;weights&lt;/code&gt; 하고, 궁극적으로 반환된다 &lt;code&gt;mean_squared_error&lt;/code&gt; : 단순히 분할가 멱등 동작 &lt;code&gt;total&lt;/code&gt; 로 &lt;code&gt;count&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3b117bfd9e6e5a2c416636178e1f60670fea3d28" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;mean_tensor&lt;/code&gt; function creates two local variables, &lt;code&gt;total_tensor&lt;/code&gt; and &lt;code&gt;count_tensor&lt;/code&gt; that are used to compute the average of &lt;code&gt;values&lt;/code&gt;. This average is ultimately returned as &lt;code&gt;mean&lt;/code&gt; which is an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;mean_tensor&lt;/code&gt; 의 기능은 두 개의 로컬 변수 생성 &lt;code&gt;total_tensor&lt;/code&gt; 및 &lt;code&gt;count_tensor&lt;/code&gt; 평균 계산하는 데 사용되는 &lt;code&gt;values&lt;/code&gt; . 이 평균은 궁극적으로 반환 &lt;code&gt;mean&lt;/code&gt; 단순히 분할가 멱등 동작되는 &lt;code&gt;total&lt;/code&gt; 의해 &lt;code&gt;count&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="61901168dd1572e51930a90d2c41288724617770" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;min_after_dequeue&lt;/code&gt; argument allows the caller to specify a minimum number of elements that will remain in the queue after a &lt;code&gt;dequeue&lt;/code&gt; or &lt;code&gt;dequeue_many&lt;/code&gt; operation completes, to ensure a minimum level of mixing of elements. This invariant is maintained by blocking those operations until sufficient elements have been enqueued. The &lt;code&gt;min_after_dequeue&lt;/code&gt; argument is ignored after the queue has been closed.</source>
          <target state="translated">&lt;code&gt;min_after_dequeue&lt;/code&gt; 인수는, 발신자가 후에 큐에 남아 요소들의 최소 수를 지정 할 수 &lt;code&gt;dequeue&lt;/code&gt; 또는 &lt;code&gt;dequeue_many&lt;/code&gt; 동작이 완료된 요소의 혼합의 최소 수준을 보장한다. 이 불변은 충분한 요소가 큐에 들어갈 때까지 해당 작업을 차단하여 유지됩니다. 그만큼 &lt;code&gt;min_after_dequeue&lt;/code&gt; 큐가 닫힌 후 인수는 무시됩니다.</target>
        </trans-unit>
        <trans-unit id="87f93cdb7fe70e84bf2c6a1f629508cf097e91cf" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;model_fn&lt;/code&gt; with following signature: &lt;code&gt;def model_fn(features, labels, mode, config)&lt;/code&gt;</source>
          <target state="translated">다음 서명 이있는 &lt;code&gt;model_fn&lt;/code&gt; : &lt;code&gt;def model_fn(features, labels, mode, config)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="6b0f2d1521a662066e2e88bb2088b1a4f0eee648" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;name&lt;/code&gt; argument determines the compute and variable dtype, the default loss scale, and has no additional effect on the Policy. The compute and variable dtypes can only be specified through &lt;code&gt;name&lt;/code&gt;, and cannot be specified directly.</source>
          <target state="translated">&lt;code&gt;name&lt;/code&gt; 인수는 컴퓨팅 및 변수 DTYPE, 기본 손실 규모를 결정하고, 정책에 추가적인 영향을주지 않습니다. 계산 및 변수 dtype은 다음을 통해서만 지정할 수 있습니다 &lt;code&gt;name&lt;/code&gt; 을 수 있으며 직접 지정할 수 없습니다.</target>
        </trans-unit>
        <trans-unit id="caae61aec33371ff4b676bc337e8ca5b2b3735d7" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;name&lt;/code&gt; argument will be interpreted as follows:</source>
          <target state="translated">&lt;code&gt;name&lt;/code&gt; 은 다음과 같이 인수는 해석됩니다 :</target>
        </trans-unit>
        <trans-unit id="0bb4358003786fb876ae7af1510a743596ce0c00" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;output&lt;/code&gt; is a string &lt;code&gt;Tensor&lt;/code&gt; of the same shape as &lt;code&gt;bytes&lt;/code&gt;, each element containing the decompressed data from the corresponding element in &lt;code&gt;bytes&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;output&lt;/code&gt; 문자열이다 &lt;code&gt;Tensor&lt;/code&gt; 동일한 형상의 &lt;code&gt;bytes&lt;/code&gt; 에 대응하는 요소로부터 압축 해제 된 데이터를 포함하는 각 요소 &lt;code&gt;bytes&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5b4d4c43eca0087042a4ac89a69f9618fa9ccf44" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;padding&lt;/code&gt; argument has no effect on the size of each patch, it determines how many patches are extracted. If &lt;code&gt;VALID&lt;/code&gt;, only patches which are fully contained in the input image are included. If &lt;code&gt;SAME&lt;/code&gt;, all patches whose starting point is inside the input are included, and areas outside the input default to zero.</source>
          <target state="translated">&lt;code&gt;padding&lt;/code&gt; 인수는 각 패치의 크기에 영향을주지 않습니다, 많은 패치가 추출되는 방식을 결정합니다. &lt;code&gt;VALID&lt;/code&gt; 인 경우 입력 이미지에 완전히 포함 된 패치 만 포함됩니다. 만약 &lt;code&gt;SAME&lt;/code&gt; 인 시작점이 입력 내부에있는 모든 패치가 포함되며 입력 외부 영역은 기본적으로 0입니다.</target>
        </trans-unit>
        <trans-unit id="5d6511601b9be092f62183d45376bcdd0b07ca55" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;params&lt;/code&gt; argument contains hyperparameters. It is passed to the &lt;code&gt;model_fn&lt;/code&gt;, if the &lt;code&gt;model_fn&lt;/code&gt; has a parameter named &quot;params&quot;, and to the input functions in the same manner. &lt;code&gt;Estimator&lt;/code&gt; only passes params along, it does not inspect it. The structure of &lt;code&gt;params&lt;/code&gt; is therefore entirely up to the developer.</source>
          <target state="translated">&lt;code&gt;params&lt;/code&gt; 인수는 하이퍼 파라미터가 포함되어 있습니다. 그것은에 전달 &lt;code&gt;model_fn&lt;/code&gt; 경우 &lt;code&gt;model_fn&lt;/code&gt; 는 &quot;PARAMS&quot;이라는 파라미터를 갖고, 동일한 방식으로 입력 기능한다. &lt;code&gt;Estimator&lt;/code&gt; 는 매개 변수 만 전달하며 검사하지는 않습니다. 따라서 &lt;code&gt;params&lt;/code&gt; 의 구조는 전적으로 개발자에게 달려 있습니다.</target>
        </trans-unit>
        <trans-unit id="9d95e516d4f18ca77f6adc9dd062547aed852bf4" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;partition_strategy&lt;/code&gt; is always &lt;code&gt;&quot;div&quot;&lt;/code&gt; currently. This means that we assign ids to partitions in a contiguous manner. For instance, 13 ids are split across 5 partitions as: &lt;code&gt;[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;partition_strategy&lt;/code&gt; 는 항상 &lt;code&gt;&quot;div&quot;&lt;/code&gt; 현재. 이것은 우리가 연속적으로 파티션에 ID를 할당한다는 것을 의미합니다. 예를 들어 13 개의 ID는 다음과 같이 5 개의 파티션으로 분할됩니다. &lt;code&gt;[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="52630b2e3206fda8f0264a5aa2143342644368d9" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;percentage_below&lt;/code&gt; function creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the percentage of &lt;code&gt;values&lt;/code&gt; that fall below &lt;code&gt;threshold&lt;/code&gt;. This rate is weighted by &lt;code&gt;weights&lt;/code&gt;, and it is ultimately returned as &lt;code&gt;percentage&lt;/code&gt; which is an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;percentage_below&lt;/code&gt; 함수는 두 개의 로컬 변수 생성 &lt;code&gt;total&lt;/code&gt; 및 &lt;code&gt;count&lt;/code&gt; 의 비율의 계산에 사용되는 &lt;code&gt;values&lt;/code&gt; 을 하회 &lt;code&gt;threshold&lt;/code&gt; . 이 레이트에 의해 가중되는 &lt;code&gt;weights&lt;/code&gt; 하고, 궁극적으로 반환된다 &lt;code&gt;percentage&lt;/code&gt; 단순히 분할가 멱등 동작이다 &lt;code&gt;total&lt;/code&gt; 의해 &lt;code&gt;count&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7ff7ad77d0b4964b4f1ddd1a1b58d2783393a3a7" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;precision&lt;/code&gt; function creates two local variables, &lt;code&gt;true_positives&lt;/code&gt; and &lt;code&gt;false_positives&lt;/code&gt;, that are used to compute the precision. This value is ultimately returned as &lt;code&gt;precision&lt;/code&gt;, an idempotent operation that simply divides &lt;code&gt;true_positives&lt;/code&gt; by the sum of &lt;code&gt;true_positives&lt;/code&gt; and &lt;code&gt;false_positives&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;precision&lt;/code&gt; 함수는 두 개의 로컬 변수 생성 &lt;code&gt;true_positives&lt;/code&gt; 및 &lt;code&gt;false_positives&lt;/code&gt; 정확도를 계산하기 위해 사용된다. 이 값은 궁극적 으로 &lt;code&gt;true_positives&lt;/code&gt; 를 &lt;code&gt;true_positives&lt;/code&gt; 와 &lt;code&gt;false_positives&lt;/code&gt; 의 합으로 나누는 pot 등식 연산 인 &lt;code&gt;precision&lt;/code&gt; 으로 반환됩니다 .</target>
        </trans-unit>
        <trans-unit id="5dd1225edff0d711a1d881f6569af599477db82d" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;precision_at_thresholds&lt;/code&gt; function creates four local variables, &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; for various values of thresholds. &lt;code&gt;precision[i]&lt;/code&gt; is defined as the total weight of values in &lt;code&gt;predictions&lt;/code&gt; above &lt;code&gt;thresholds[i]&lt;/code&gt; whose corresponding entry in &lt;code&gt;labels&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, divided by the total weight of values in &lt;code&gt;predictions&lt;/code&gt; above &lt;code&gt;thresholds[i]&lt;/code&gt; (&lt;code&gt;true_positives[i] / (true_positives[i] + false_positives[i])&lt;/code&gt;).</source>
          <target state="translated">&lt;code&gt;precision_at_thresholds&lt;/code&gt; 의 함수 네 로컬 변수 생성 &lt;code&gt;true_positives&lt;/code&gt; , &lt;code&gt;true_negatives&lt;/code&gt; , &lt;code&gt;false_positives&lt;/code&gt; 및 &lt;code&gt;false_negatives&lt;/code&gt; 임계 값을 다양. &lt;code&gt;precision[i]&lt;/code&gt; 의 값의 합계 중량으로 정의되고 &lt;code&gt;predictions&lt;/code&gt; 상기 &lt;code&gt;thresholds[i]&lt;/code&gt; 그 안에 진입 대응 &lt;code&gt;labels&lt;/code&gt; 인 &lt;code&gt;True&lt;/code&gt; 의 값의 합계 중량으로 나눈 값, &lt;code&gt;predictions&lt;/code&gt; 상기 &lt;code&gt;thresholds[i]&lt;/code&gt; ( &lt;code&gt;true_positives[i] / (true_positives[i] + false_positives[i])&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="6eefdf49a7cc35e9901e07fb1fbbe5c8a0436241" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;pred_fn_pairs&lt;/code&gt; parameter is a dict or list of pairs of size N. Each pair contains a boolean scalar tensor and a python callable that creates the tensors to be returned if the boolean evaluates to True. &lt;code&gt;default&lt;/code&gt; is a callable generating a list of tensors. All the callables in &lt;code&gt;pred_fn_pairs&lt;/code&gt; as well as &lt;code&gt;default&lt;/code&gt; (if provided) should return the same number and types of tensors.</source>
          <target state="translated">&lt;code&gt;pred_fn_pairs&lt;/code&gt; 각 쌍의 부울 스칼라 텐서 및 텐서를 생성 파이썬 호출을 포함하는 딕셔너리 또는 크기 N. 쌍의리스트이다 파라미터 부울 참으로 평가되면 반환한다. &lt;code&gt;default&lt;/code&gt; 은 텐서 목록을 생성하는 호출 가능입니다. &lt;code&gt;pred_fn_pairs&lt;/code&gt; 의 모든 콜 러블 과 &lt;code&gt;default&lt;/code&gt; (제공된 경우)은 동일한 개수와 유형의 텐서를 반환해야합니다.</target>
        </trans-unit>
        <trans-unit id="34976fcb5528295e8ddc3902a61df136b0d0ffdf" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;pred_fn_pairs&lt;/code&gt; parameter is a list of pairs of size N. Each pair contains a boolean scalar tensor and a python callable that creates the tensors to be returned if the boolean evaluates to True. &lt;code&gt;default&lt;/code&gt; is a callable generating a list of tensors. All the callables in &lt;code&gt;pred_fn_pairs&lt;/code&gt; as well as &lt;code&gt;default&lt;/code&gt; (if provided) should return the same number and types of tensors.</source>
          <target state="translated">&lt;code&gt;pred_fn_pairs&lt;/code&gt; 각 쌍의 부울 스칼라 텐서 및 텐서는 불리언 평가되면 참으로 리턴 될 작성 파이썬 호출 포함 크기 N. 쌍의리스트는 파라미터. &lt;code&gt;default&lt;/code&gt; 은 텐서 목록을 생성하는 호출 가능입니다. &lt;code&gt;pred_fn_pairs&lt;/code&gt; 의 모든 콜 러블 과 &lt;code&gt;default&lt;/code&gt; (제공된 경우)은 동일한 개수와 유형의 텐서를 반환해야합니다.</target>
        </trans-unit>
        <trans-unit id="968a8378fc8eb3fdd1fb2170f34eb48e9c1bec93" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;ready_for_local_init_op&lt;/code&gt; is an &lt;code&gt;Operation&lt;/code&gt; used to check if the model is ready to run local_init_op. The model is considered ready if that operation returns an empty 1D string tensor. If the operation returns a non empty 1D string tensor, the elements are concatenated and used to indicate to the user why the model is not ready.</source>
          <target state="translated">&lt;code&gt;ready_for_local_init_op&lt;/code&gt; 는 입니다 &lt;code&gt;Operation&lt;/code&gt; 모델이 local_init_op 실행할 준비가되어 있는지 확인하는 데 사용됩니다. 해당 작업이 빈 1D 문자열 텐서를 반환하면 모델이 준비된 것으로 간주됩니다. 조작이 비어 있지 않은 1D 문자열 텐서를 리턴하면 요소가 연결되어 모델이 준비되지 않은 이유를 사용자에게 표시하는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="8200e403875e28ce9b4147cac96db59b27a581ff" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;ready_op&lt;/code&gt; is an &lt;code&gt;Operation&lt;/code&gt; used to check if the model is ready. The model is considered ready if that operation returns an empty 1D string tensor. If the operation returns a non empty 1D string tensor, the elements are concatenated and used to indicate to the user why the model is not ready.</source>
          <target state="translated">&lt;code&gt;ready_op&lt;/code&gt; 는 입니다 &lt;code&gt;Operation&lt;/code&gt; 모델이 준비가되었는지 확인하는 데 사용됩니다. 해당 작업이 빈 1D 문자열 텐서를 반환하면 모델이 준비된 것으로 간주됩니다. 조작이 비어 있지 않은 1D 문자열 텐서를 리턴하면 요소가 연결되어 모델이 준비되지 않은 이유를 사용자에게 표시하는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="6e2627a0b13cf79619cf55143c1bafbedffc6df2" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;recall&lt;/code&gt; function creates two local variables, &lt;code&gt;true_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt;, that are used to compute the recall. This value is ultimately returned as &lt;code&gt;recall&lt;/code&gt;, an idempotent operation that simply divides &lt;code&gt;true_positives&lt;/code&gt; by the sum of &lt;code&gt;true_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;recall&lt;/code&gt; 함수는 두 개의 로컬 변수 생성 &lt;code&gt;true_positives&lt;/code&gt; 및 &lt;code&gt;false_negatives&lt;/code&gt; 회수를 계산하기 위해 사용된다. 이 값은 궁극적 으로 &lt;code&gt;true_positives&lt;/code&gt; 를 &lt;code&gt;true_positives&lt;/code&gt; 와 &lt;code&gt;false_negatives&lt;/code&gt; 의 합으로 나누는 dem 등원 연산 인 &lt;code&gt;recall&lt;/code&gt; 으로 반환됩니다 .</target>
        </trans-unit>
        <trans-unit id="bb44adc5fb4d7d2974a8444bc13883fdc576fe0e" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;recall_at_thresholds&lt;/code&gt; function creates four local variables, &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; for various values of thresholds. &lt;code&gt;recall[i]&lt;/code&gt; is defined as the total weight of values in &lt;code&gt;predictions&lt;/code&gt; above &lt;code&gt;thresholds[i]&lt;/code&gt; whose corresponding entry in &lt;code&gt;labels&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, divided by the total weight of &lt;code&gt;True&lt;/code&gt; values in &lt;code&gt;labels&lt;/code&gt; (&lt;code&gt;true_positives[i] / (true_positives[i] + false_negatives[i])&lt;/code&gt;).</source>
          <target state="translated">&lt;code&gt;recall_at_thresholds&lt;/code&gt; 의 함수 네 로컬 변수 생성 &lt;code&gt;true_positives&lt;/code&gt; , &lt;code&gt;true_negatives&lt;/code&gt; , &lt;code&gt;false_positives&lt;/code&gt; 및 &lt;code&gt;false_negatives&lt;/code&gt; 임계 값을 다양. &lt;code&gt;recall[i]&lt;/code&gt; 의 값의 합계 중량으로 정의되고 &lt;code&gt;predictions&lt;/code&gt; 상기 &lt;code&gt;thresholds[i]&lt;/code&gt; 누구의 엔트리에 대응하는 &lt;code&gt;labels&lt;/code&gt; 이다 &lt;code&gt;True&lt;/code&gt; 의 총 중량으로 나눈 &lt;code&gt;True&lt;/code&gt; 의 값 &lt;code&gt;labels&lt;/code&gt; ( &lt;code&gt;true_positives[i] / (true_positives[i] + false_negatives[i])&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="1de524f73c4314e7c1d91fd220ad1d6d3224de54" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;reverse&lt;/code&gt; and &lt;code&gt;exclusive&lt;/code&gt; kwargs can also be combined:</source>
          <target state="translated">&lt;code&gt;reverse&lt;/code&gt; 및 &lt;code&gt;exclusive&lt;/code&gt; kwargs로도 결합 될 수있다 :</target>
        </trans-unit>
        <trans-unit id="7095d9dae674a6139b14cf56a48942249fb95a3a" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;root_mean_squared_error&lt;/code&gt; function creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the root mean squared error. This average is weighted by &lt;code&gt;weights&lt;/code&gt;, and it is ultimately returned as &lt;code&gt;root_mean_squared_error&lt;/code&gt;: an idempotent operation that takes the square root of the division of &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;root_mean_squared_error&lt;/code&gt; 의 기능은 두 개의 로컬 변수 생성 &lt;code&gt;total&lt;/code&gt; 과 &lt;code&gt;count&lt;/code&gt; 루트 평균 제곱 오차를 계산하는 데 사용된다. 이 평균의 가중치는 가중치로 &lt;code&gt;weights&lt;/code&gt; 가 부여되며 , 결국 &lt;code&gt;root_mean_squared_error&lt;/code&gt; 로 반환됩니다 . 즉, &lt;code&gt;total&lt;/code&gt; 를 &lt;code&gt;count&lt;/code&gt; 나눈 제곱근을 취하는 dem 등식 연산입니다 .</target>
        </trans-unit>
        <trans-unit id="458e5a2574272cd3d33b7c903a0b4f0ec7f14636" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;run_context&lt;/code&gt; argument is a &lt;code&gt;SessionRunContext&lt;/code&gt; that provides information about the upcoming &lt;code&gt;run()&lt;/code&gt; call: the originally requested op/tensors, the TensorFlow Session.</source>
          <target state="translated">&lt;code&gt;run_context&lt;/code&gt; 의 인수는이다 &lt;code&gt;SessionRunContext&lt;/code&gt; 다가오는에 대한 정보 제공 &lt;code&gt;run()&lt;/code&gt; 원래 요청한 연산 / 텐서의 TensorFlow 세션 : 전화를.</target>
        </trans-unit>
        <trans-unit id="cf828e3dc7b5c6afebb2a4e95b3f86639dbbc64b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;run_context&lt;/code&gt; argument is the same one send to &lt;code&gt;before_run&lt;/code&gt; call. &lt;code&gt;run_context.request_stop()&lt;/code&gt; can be called to stop the iteration.</source>
          <target state="translated">&lt;code&gt;run_context&lt;/code&gt; 의 인수는 동일한 하나의 전송이다 &lt;code&gt;before_run&lt;/code&gt; 전화. &lt;code&gt;run_context.request_stop()&lt;/code&gt; 을 호출하여 반복을 중지 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="94f5d1df32e6ce942188c9ddfd764b608ff17856" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;run_values&lt;/code&gt; argument contains results of requested ops/tensors by &lt;code&gt;before_run()&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;run_values&lt;/code&gt; 의 인수에 의해 요청 작전 / 텐서의 결과를 포함 &lt;code&gt;before_run()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="be802e4b5940c54925a16198fd046cde07510ef1" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;save_path&lt;/code&gt; argument is typically a value previously returned from a &lt;code&gt;save()&lt;/code&gt; call, or a call to &lt;code&gt;latest_checkpoint()&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;save_path&lt;/code&gt; 의 인수는 일반적으로 이전에서 반환 된 값 &lt;code&gt;save()&lt;/code&gt; 호출, 또는를 호출 &lt;code&gt;latest_checkpoint()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f865f0bbd1d6f2fff1a5c15f6500c2a842d180ca" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;seed&lt;/code&gt; argument produces a deterministic sequence of tensors across multiple calls. To repeat that sequence, use &lt;a href=&quot;set_seed&quot;&gt;&lt;code&gt;tf.random.set_seed&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">&lt;code&gt;seed&lt;/code&gt; 인수는 여러 통화에서 텐서의 결정 순서를 생산하고 있습니다. 이 순서를 반복하려면 &lt;a href=&quot;set_seed&quot;&gt; &lt;code&gt;tf.random.set_seed&lt;/code&gt; 를&lt;/a&gt; 사용 하십시오 .</target>
        </trans-unit>
        <trans-unit id="cd56b7af0c6b81f60b1e8953cb5fa5a8ea87a447" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;sensitivity_at_specificity&lt;/code&gt; function creates four local variables, &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; that are used to compute the sensitivity at the given specificity value. The threshold for the given specificity value is computed and used to evaluate the corresponding sensitivity.</source>
          <target state="translated">&lt;code&gt;sensitivity_at_specificity&lt;/code&gt; 의 함수 네 로컬 변수 생성 &lt;code&gt;true_positives&lt;/code&gt; , &lt;code&gt;true_negatives&lt;/code&gt; , &lt;code&gt;false_positives&lt;/code&gt; 및 &lt;code&gt;false_negatives&lt;/code&gt; 을 주어진 특이 값의 감도를 계산하는데 사용된다. 주어진 특이성 값에 대한 임계 값이 계산되어 해당 감도를 평가하는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="e87df8700aa595c22c3204338d3a54c757320ca4" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;sequence&lt;/code&gt; format is recommended as the one with the best performance.</source>
          <target state="translated">&lt;code&gt;sequence&lt;/code&gt; 형식은 최고의 성능과 하나로 좋습니다.</target>
        </trans-unit>
        <trans-unit id="4c2d41a4697cb394d4d9e0620c83a904374239b4" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;session&lt;/code&gt; argument can be used in case the hook wants to run final ops, such as saving a last checkpoint.</source>
          <target state="translated">&lt;code&gt;session&lt;/code&gt; 후크는 마지막 체크 포인트를 저장하는 등의 최종 작전을 실행하고자하는 경우에는 인수를 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="8c5409b22ac50361a38c4e5620fb792814a952ea" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;session&lt;/code&gt; argument to the constructor makes the returned &lt;code&gt;FileWriter&lt;/code&gt; a compatibility layer over new graph-based summaries (&lt;code&gt;tf.contrib.summary&lt;/code&gt;). Crucially, this means the underlying writer resource and events file will be shared with any other &lt;code&gt;FileWriter&lt;/code&gt; using the same &lt;code&gt;session&lt;/code&gt; and &lt;code&gt;logdir&lt;/code&gt;, and with any &lt;code&gt;tf.contrib.summary.SummaryWriter&lt;/code&gt; in this session using the the same shared resource name (which by default scoped to the logdir). If no such resource exists, one will be created using the remaining arguments to this constructor, but if one already exists those arguments are ignored. In either case, ops will be added to &lt;code&gt;session.graph&lt;/code&gt; to control the underlying file writer resource. See &lt;code&gt;tf.contrib.summary&lt;/code&gt; for more details.</source>
          <target state="translated">생성자에 대한 &lt;code&gt;session&lt;/code&gt; 인수는 반환 된 &lt;code&gt;FileWriter&lt;/code&gt; 를 새로운 그래프 기반 요약 ( &lt;code&gt;tf.contrib.summary&lt;/code&gt; )에 대한 호환성 계층으로 만듭니다 . 결정적으로,이 방법은 기본 작가 자원 및 이벤트 파일은 다른 공유됩니다 &lt;code&gt;FileWriter&lt;/code&gt; 같은 사용하여 &lt;code&gt;session&lt;/code&gt; 및 &lt;code&gt;logdir&lt;/code&gt; , 어떤으로 &lt;code&gt;tf.contrib.summary.SummaryWriter&lt;/code&gt; 이 세션에서 기본적으로 범위하여 동일한 공유 리소스 이름을 (사용 logdir에). 그러한 리소스가 존재하지 않으면이 생성자에 나머지 인수를 사용하여 생성되지만 이미 존재하는 경우 해당 인수는 무시됩니다. 두 경우 모두 op가 &lt;code&gt;session.graph&lt;/code&gt; 추가됩니다.기본 파일 작성기 리소스를 제어합니다. 자세한 내용은 &lt;code&gt;tf.contrib.summary&lt;/code&gt; 를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="97ff29fadf0e70b89b34fdebe66a53feae7519dd" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;set_verbosity&lt;/code&gt; function</source>
          <target state="translated">&lt;code&gt;set_verbosity&lt;/code&gt; 의 기능</target>
        </trans-unit>
        <trans-unit id="303d3a64650f2563c6f2537d372e68f6d33680c2" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;shape&lt;/code&gt; argument to &lt;code&gt;Variable&lt;/code&gt;'s constructor allows you to construct a variable with a less defined shape than its &lt;code&gt;initial_value&lt;/code&gt;:</source>
          <target state="translated">&lt;code&gt;Variable&lt;/code&gt; 의 생성자에 대한 &lt;code&gt;shape&lt;/code&gt; 인수를 사용하면 &lt;code&gt;initial_value&lt;/code&gt; 보다 덜 정의 된 모양으로 변수를 구성 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="c69ff0d563e037b396ab2e9976bb7ebc62fb1134" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;shapes&lt;/code&gt; argument must be specified; each component of a queue element must have the respective shape. Shapes of fixed rank but variable size are allowed by setting any shape dimension to None. In this case, the inputs' shape may vary along the given dimension, and &lt;code&gt;dequeue_many&lt;/code&gt; will pad the given dimension with zeros up to the maximum shape of all elements in the given batch.</source>
          <target state="translated">&lt;code&gt;shapes&lt;/code&gt; 인수를 지정해야합니다; 큐 요소의 각 구성 요소는 각각의 모양을 가져야합니다. 임의의 모양 치수를 없음으로 설정하면 고정 순위이지만 가변 크기의 모양이 허용됩니다. 이 경우 입력의 모양은 주어진 차원에 따라 다를 수 있으며 &lt;code&gt;dequeue_many&lt;/code&gt; 는 주어진 배치에서 모든 요소의 최대 모양까지 주어진 차원을 0으로 채 웁니다 .</target>
        </trans-unit>
        <trans-unit id="6d1e6359fd2b9322b254250e0bc1bdb6607c603e" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;sizes&lt;/code&gt; tensor specifies repeat counts for each field. The repeat count (last dimension) of a each tensor in &lt;code&gt;values&lt;/code&gt; must be greater than or equal to corresponding repeat count in &lt;code&gt;sizes&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;sizes&lt;/code&gt; 를 지정 텐서는 각 필드에 대해 계산을 반복합니다. &lt;code&gt;values&lt;/code&gt; 에서 각 텐서의 반복 횟수 (마지막 치수)는 &lt;code&gt;sizes&lt;/code&gt; 해당 반복 횟수보다 크거나 같아야 합니다 .</target>
        </trans-unit>
        <trans-unit id="6881b3cf0171ded834c55d240775c14753ca1a7e" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;sparse_combiner&lt;/code&gt; argument works as follows For example, for two features represented as the categorical columns:</source>
          <target state="translated">&lt;code&gt;sparse_combiner&lt;/code&gt; 의 인수는 같은 범주 열로 표현 두 가지 기능, 예를 들어 다음과 작동합니다 :</target>
        </trans-unit>
        <trans-unit id="a8e8fe9df97a94b949937ed1f21ec89b558385be" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;specificity_at_sensitivity&lt;/code&gt; function creates four local variables, &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; that are used to compute the specificity at the given sensitivity value. The threshold for the given sensitivity value is computed and used to evaluate the corresponding specificity.</source>
          <target state="translated">&lt;code&gt;specificity_at_sensitivity&lt;/code&gt; 의 함수 네 로컬 변수 생성 &lt;code&gt;true_positives&lt;/code&gt; , &lt;code&gt;true_negatives&lt;/code&gt; , &lt;code&gt;false_positives&lt;/code&gt; 및 &lt;code&gt;false_negatives&lt;/code&gt; 주어진 감도 값의 특이성을 계산하는데 사용된다. 주어진 감도 값에 대한 임계 값이 계산되어 해당 특이성을 평가하는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="cb73b0594146c19de95fb48de33a2ddca84ec873" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;stride&lt;/code&gt; argument determines the stride of the input elements, and the &lt;code&gt;shift&lt;/code&gt; argument determines the shift of the window.</source>
          <target state="translated">&lt;code&gt;stride&lt;/code&gt; 인수는 입력 요소의 보폭을 결정하고, &lt;code&gt;shift&lt;/code&gt; 인수는 윈도우의 시프트를 판정한다.</target>
        </trans-unit>
        <trans-unit id="7cb863ed936a846c83669117e5a427aa5ac1c932" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;tensors_list&lt;/code&gt; argument is a list of tuples of tensors, or a list of dictionaries of tensors. Each element in the list is treated similarly to the &lt;code&gt;tensors&lt;/code&gt; argument of &lt;a href=&quot;batch&quot;&gt;&lt;code&gt;tf.compat.v1.train.batch()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;tensors_list&lt;/code&gt; 의 인수는 텐서의 튜플의 목록 또는 텐서의 사전의 목록입니다. 목록의 각 요소 는 &lt;a href=&quot;batch&quot;&gt; &lt;code&gt;tf.compat.v1.train.batch()&lt;/code&gt; &lt;/a&gt; 의 &lt;code&gt;tensors&lt;/code&gt; 인수 와 유사하게 취급 됩니다.</target>
        </trans-unit>
        <trans-unit id="410a750f639c5f1de66d97c0804239f72c4604d0" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;tensors_list&lt;/code&gt; argument is a list of tuples of tensors, or a list of dictionaries of tensors. Each element in the list is treated similarly to the &lt;code&gt;tensors&lt;/code&gt; argument of &lt;a href=&quot;shuffle_batch&quot;&gt;&lt;code&gt;tf.compat.v1.train.shuffle_batch()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;tensors_list&lt;/code&gt; 의 인수는 텐서의 튜플의 목록 또는 텐서의 사전의 목록입니다. 목록의 각 요소 는 &lt;a href=&quot;shuffle_batch&quot;&gt; &lt;code&gt;tf.compat.v1.train.shuffle_batch()&lt;/code&gt; &lt;/a&gt; 의 &lt;code&gt;tensors&lt;/code&gt; 인수 와 유사하게 취급 됩니다.</target>
        </trans-unit>
        <trans-unit id="e8643ae6bb3114dbfb70eef96843715bb87d8ebd" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;timeout&lt;/code&gt; argument is the maximum number of seconds to block waiting for a new checkpoint. It is used in combination with the &lt;code&gt;timeout_fn&lt;/code&gt; as follows:</source>
          <target state="translated">&lt;code&gt;timeout&lt;/code&gt; 인수는 새로운 체크 포인트를 기다리고 차단하는 최대 시간 (초)입니다. 다음과 같이 &lt;code&gt;timeout_fn&lt;/code&gt; 과 함께 사용 됩니다.</target>
        </trans-unit>
        <trans-unit id="972185be83406631ec3872d41f4d67b45194a05d" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;value&lt;/code&gt; tensor has shape &lt;code&gt;[batch, in_height, in_width, depth]&lt;/code&gt; and the &lt;code&gt;filters&lt;/code&gt; tensor has shape &lt;code&gt;[filters_height, filters_width, depth]&lt;/code&gt;, i.e., each input channel is processed independently of the others with its own structuring function. The &lt;code&gt;output&lt;/code&gt; tensor has shape &lt;code&gt;[batch, out_height, out_width, depth]&lt;/code&gt;. The spatial dimensions of the output tensor depend on the &lt;code&gt;padding&lt;/code&gt; algorithm. We currently only support the default &quot;NHWC&quot; &lt;code&gt;data_format&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;value&lt;/code&gt; 텐서 형상 갖는다 &lt;code&gt;[batch, in_height, in_width, depth]&lt;/code&gt; 및 &lt;code&gt;filters&lt;/code&gt; 형상을 갖는다 텐서 &lt;code&gt;[filters_height, filters_width, depth]&lt;/code&gt; 즉, 각각의 입력 채널이 독립적으로 자신의 구조 기능 다른 것의 처리된다. &lt;code&gt;output&lt;/code&gt; 텐서 형상 갖는다 &lt;code&gt;[batch, out_height, out_width, depth]&lt;/code&gt; . 출력 텐서의 공간 치수는 &lt;code&gt;padding&lt;/code&gt; 알고리즘 에 따라 다릅니다 . 현재 기본 &quot;NHWC&quot; &lt;code&gt;data_format&lt;/code&gt; 만 지원합니다 .</target>
        </trans-unit>
        <trans-unit id="9754d069f440bf7569706c44c08fdac07bea1efd" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;value&lt;/code&gt; tensor has shape &lt;code&gt;[batch, in_height, in_width, depth]&lt;/code&gt; and the &lt;code&gt;kernel&lt;/code&gt; tensor has shape &lt;code&gt;[kernel_height, kernel_width, depth]&lt;/code&gt;, i.e., each input channel is processed independently of the others with its own structuring function. The &lt;code&gt;output&lt;/code&gt; tensor has shape &lt;code&gt;[batch, out_height, out_width, depth]&lt;/code&gt;. The spatial dimensions of the output tensor depend on the &lt;code&gt;padding&lt;/code&gt; algorithm. We currently only support the default &quot;NHWC&quot; &lt;code&gt;data_format&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;value&lt;/code&gt; 텐서 형상 갖는다 &lt;code&gt;[batch, in_height, in_width, depth]&lt;/code&gt; 및 &lt;code&gt;kernel&lt;/code&gt; 텐서 형상 갖는다 &lt;code&gt;[kernel_height, kernel_width, depth]&lt;/code&gt; 즉, 각각의 입력 채널은 자체 구조 기능과 다른 독립적으로 처리된다. &lt;code&gt;output&lt;/code&gt; 텐서 형상 갖는다 &lt;code&gt;[batch, out_height, out_width, depth]&lt;/code&gt; . 출력 텐서의 공간 치수는 &lt;code&gt;padding&lt;/code&gt; 알고리즘 에 따라 다릅니다 . 현재 기본 &quot;NHWC&quot; &lt;code&gt;data_format&lt;/code&gt; 만 지원합니다 .</target>
        </trans-unit>
        <trans-unit id="0e0b84cabe53e9e5c6c0da1ca87fa0c58be00cc6" translate="yes" xml:space="preserve">
          <source>The &lt;em&gt;EM&lt;/em&gt; algorithm where the &lt;em&gt;M-step&lt;/em&gt; should not involve backpropagation through the output of the &lt;em&gt;E-step&lt;/em&gt;.</source>
          <target state="translated">&lt;em&gt;EM의&lt;/em&gt; 알고리즘 &lt;em&gt;M-단계&lt;/em&gt; 의 출력을 역 전파를 포함 안 &lt;em&gt;E 단계&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="b18ff4b0c03781a21c34b4aa7c91c48fe6607e87" translate="yes" xml:space="preserve">
          <source>The API also assigns ops in tf.compat.v1.trainable_variables() an op type called '_trainable_variables'. The API also logs 'flops' statistics for ops with op.RegisterStatistics() defined. flops calculation depends on Tensor shapes defined in 'graph', which might not be complete. 'run_meta', if provided, completes the shape information with best effort.</source>
          <target state="translated">또한 API는 tf.compat.v1.trainable_variables ()의 op에 '_trainable_variables'라는 op 유형을 할당합니다. 또한 API는 op.RegisterStatistics ()가 정의 된 op에 대한 '플롭'통계를 기록합니다. 플롭 계산은 '그래프'에 정의 된 텐서 모양에 따라 달라지며 완료되지 않을 수 있습니다. 'run_meta'는 제공된 경우 최선의 노력으로 형태 정보를 완성합니다.</target>
        </trans-unit>
        <trans-unit id="6d0fc1f05596c2c92bd92cba556fe327b716c416" translate="yes" xml:space="preserve">
          <source>The Bernoulli distribution with &lt;code&gt;probs&lt;/code&gt; parameter, i.e., the probability of a &lt;code&gt;1&lt;/code&gt; outcome (vs a &lt;code&gt;0&lt;/code&gt; outcome).</source>
          <target state="translated">&lt;code&gt;probs&lt;/code&gt; 모수를 갖는 Bernoulli 분포 , 즉 &lt;code&gt;1&lt;/code&gt; 결과 의 확률 ( &lt;code&gt;0&lt;/code&gt; 결과 대 ).</target>
        </trans-unit>
        <trans-unit id="9353ab8095bc0b0b24b3be126e8e9c7fb1f1ad3d" translate="yes" xml:space="preserve">
          <source>The Beta distribution is defined over the &lt;code&gt;(0, 1)&lt;/code&gt; interval using parameters &lt;code&gt;concentration1&lt;/code&gt; (aka &quot;alpha&quot;) and &lt;code&gt;concentration0&lt;/code&gt; (aka &quot;beta&quot;).</source>
          <target state="translated">베타 분포는 위에 정의된다 &lt;code&gt;(0, 1)&lt;/code&gt; 파라미터를 사용 구간 &lt;code&gt;concentration1&lt;/code&gt; (일명 &quot;알파&quot;)와 &lt;code&gt;concentration0&lt;/code&gt; (일명 &quot;베타&quot;).</target>
        </trans-unit>
        <trans-unit id="abea42cad220fd20eda787ac80e243e2cf47e13d" translate="yes" xml:space="preserve">
          <source>The Categorical distribution is closely related to the &lt;code&gt;OneHotCategorical&lt;/code&gt; and &lt;code&gt;Multinomial&lt;/code&gt; distributions. The Categorical distribution can be intuited as generating samples according to &lt;code&gt;argmax{ OneHotCategorical(probs) }&lt;/code&gt; itself being identical to &lt;code&gt;argmax{ Multinomial(probs, total_count=1) }&lt;/code&gt;.</source>
          <target state="translated">범주 형 분포와 밀접한 관련이 &lt;code&gt;OneHotCategorical&lt;/code&gt; 및 &lt;code&gt;Multinomial&lt;/code&gt; 분포. 범주 형 분포는 &lt;code&gt;argmax{ OneHotCategorical(probs) }&lt;/code&gt; 자체가 &lt;code&gt;argmax{ Multinomial(probs, total_count=1) }&lt;/code&gt; 과 동일하므로 표본을 생성하는 것으로 직관 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="6c2637ba9bb0ae73ad068069b2445eb1bf971490" translate="yes" xml:space="preserve">
          <source>The Categorical distribution is parameterized by either probabilities or log-probabilities of a set of &lt;code&gt;K&lt;/code&gt; classes. It is defined over the integers &lt;code&gt;{0, 1, ..., K}&lt;/code&gt;.</source>
          <target state="translated">범주 형 분포는 &lt;code&gt;K&lt;/code&gt; 클래스 집합의 확률 또는 로그 확률로 매개 변수화됩니다 . 정수 &lt;code&gt;{0, 1, ..., K}&lt;/code&gt; 됩니다.</target>
        </trans-unit>
        <trans-unit id="a66f064277a2e3928ce326dffecdba70543ff622" translate="yes" xml:space="preserve">
          <source>The ClusterResolver will then use the parameters to query the Cloud TPU APIs for the IP addresses and ports of each Cloud TPU listed.</source>
          <target state="translated">그런 다음 ClusterResolver는 매개 변수를 사용하여 나열된 각 Cloud TPU의 IP 주소 및 포트에 대한 Cloud TPU API를 쿼리합니다.</target>
        </trans-unit>
        <trans-unit id="345e361eb29b1a63bf06b68ef8175eed879cd43c" translate="yes" xml:space="preserve">
          <source>The Coordinator can be useful if you want to run multiple threads during your training.</source>
          <target state="translated">코디네이터는 훈련 중에 여러 스레드를 실행하려는 경우 유용 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="762ae5bf9871f156d31ebbf73968a3d2925b8520" translate="yes" xml:space="preserve">
          <source>The Dirichlet distribution is defined over the &lt;a href=&quot;https://en.wikipedia.org/wiki/Simplex&quot;&gt;&lt;code&gt;(k-1)&lt;/code&gt;-simplex&lt;/a&gt; using a positive, length-&lt;code&gt;k&lt;/code&gt; vector &lt;code&gt;concentration&lt;/code&gt; (&lt;code&gt;k &amp;gt; 1&lt;/code&gt;). The Dirichlet is identically the Beta distribution when &lt;code&gt;k = 2&lt;/code&gt;.</source>
          <target state="translated">Dirichlet 분포는 양의 길이 &lt;code&gt;k&lt;/code&gt; 벡터 &lt;code&gt;concentration&lt;/code&gt; 사용하여 &lt;a href=&quot;https://en.wikipedia.org/wiki/Simplex&quot;&gt; &lt;code&gt;(k-1)&lt;/code&gt; -simplex에&lt;/a&gt; 대해 정의됩니다 ( &lt;code&gt;k &amp;gt; 1&lt;/code&gt; ). Dirichlet은 &lt;code&gt;k = 2&lt;/code&gt; 때 베타 분포와 동일합니다 .</target>
        </trans-unit>
        <trans-unit id="e30884de69ccdd0148c69a6e73300256037fabed" translate="yes" xml:space="preserve">
          <source>The Dirichlet is a distribution over the open &lt;code&gt;(k-1)&lt;/code&gt;-simplex, i.e.,</source>
          <target state="translated">Dirichlet은 개방형 &lt;code&gt;(k-1)&lt;/code&gt; -simplex에 대한 분포입니다 .</target>
        </trans-unit>
        <trans-unit id="2e41a41e81118c558d85cbc4587e8d93ce2121bf" translate="yes" xml:space="preserve">
          <source>The Dirichlet-Multinomial distribution is parameterized by a (batch of) length-&lt;code&gt;K&lt;/code&gt;&lt;code&gt;concentration&lt;/code&gt; vectors (&lt;code&gt;K &amp;gt; 1&lt;/code&gt;) and a &lt;code&gt;total_count&lt;/code&gt; number of trials, i.e., the number of trials per draw from the DirichletMultinomial. It is defined over a (batch of) length-&lt;code&gt;K&lt;/code&gt; vector &lt;code&gt;counts&lt;/code&gt; such that &lt;code&gt;tf.reduce_sum(counts, -1) = total_count&lt;/code&gt;. The Dirichlet-Multinomial is identically the Beta-Binomial distribution when &lt;code&gt;K = 2&lt;/code&gt;.</source>
          <target state="translated">DirichletMultinomial 분포 길이 - A (일괄)에 의해 매개 변수화 &lt;code&gt;K&lt;/code&gt; 의 &lt;code&gt;concentration&lt;/code&gt; 벡터 ( &lt;code&gt;K &amp;gt; 1&lt;/code&gt; ) 및 &lt;code&gt;total_count&lt;/code&gt; 즉 시행 횟수, 상기 DirichletMultinomial에서 연신 당 시도 횟수. &lt;code&gt;tf.reduce_sum(counts, -1) = total_count&lt;/code&gt; 가 되도록 ( 일괄) 길이 &lt;code&gt;K&lt;/code&gt; 벡터 &lt;code&gt;counts&lt;/code&gt; 대해 정의 됩니다. Dirichlet-Multinomial은 &lt;code&gt;K = 2&lt;/code&gt; 때 Beta-Binomial 분포와 동일합니다 .</target>
        </trans-unit>
        <trans-unit id="0e283a7e839668d96942d9fe27b03aceff70e822" translate="yes" xml:space="preserve">
          <source>The Dirichlet-Multinomial is a distribution over &lt;code&gt;K&lt;/code&gt;-class counts, i.e., a length-&lt;code&gt;K&lt;/code&gt; vector of non-negative integer &lt;code&gt;counts = n = [n_0, ..., n_{K-1}]&lt;/code&gt;.</source>
          <target state="translated">Dirichlet-Multinomial은 &lt;code&gt;K&lt;/code&gt; 클래스 수, 즉 음이 아닌 정수 &lt;code&gt;counts = n = [n_0, ..., n_{K-1}]&lt;/code&gt; 의 길이 &lt;code&gt;K&lt;/code&gt; 벡터에 대한 분포 입니다.</target>
        </trans-unit>
        <trans-unit id="f02fcb57d9bed9fe1cb9e26959ca7e29bea23df5" translate="yes" xml:space="preserve">
          <source>The Exponential distribution is a special case of the Gamma distribution, i.e.,</source>
          <target state="translated">지수 분포는 감마 분포의 특별한 경우입니다.</target>
        </trans-unit>
        <trans-unit id="e6f3e5f56915f923971b04b2d769299865559dab" translate="yes" xml:space="preserve">
          <source>The Exponential distribution is parameterized by an event &lt;code&gt;rate&lt;/code&gt; parameter.</source>
          <target state="translated">지수 분포는 이벤트 &lt;code&gt;rate&lt;/code&gt; 매개 변수 로 매개 변수화됩니다.</target>
        </trans-unit>
        <trans-unit id="e2d0890a7adeefe2d23082f4a11de8d57d4d1ed8" translate="yes" xml:space="preserve">
          <source>The Exponential distribution uses a &lt;code&gt;rate&lt;/code&gt; parameter, or &quot;inverse scale&quot;, which can be intuited as,</source>
          <target state="translated">지수 분포는 다음 과 같이 직감 될 수 있는 &lt;code&gt;rate&lt;/code&gt; 매개 변수 또는 &quot;역 척도&quot;를 사용합니다.</target>
        </trans-unit>
        <trans-unit id="609d4d600899851c7fc93aa7a4ce757600207e0c" translate="yes" xml:space="preserve">
          <source>The Gamma distribution is defined over positive real numbers using parameters &lt;code&gt;concentration&lt;/code&gt; (aka &quot;alpha&quot;) and &lt;code&gt;rate&lt;/code&gt; (aka &quot;beta&quot;).</source>
          <target state="translated">감마 분포는 매개 변수 &lt;code&gt;concentration&lt;/code&gt; (일명 &quot;알파&quot;) 및 &lt;code&gt;rate&lt;/code&gt; (일명 &quot;베타&quot;)을 사용하여 양의 실수에 대해 정의됩니다 .</target>
        </trans-unit>
        <trans-unit id="79a61f2d86901aebd84ad8b2d9002905d13b2a9f" translate="yes" xml:space="preserve">
          <source>The Glorot normal initializer, also called Xavier normal initializer.</source>
          <target state="translated">Xavier 일반 이니셜 라이저라고도하는 Glorot 일반 이니셜 라이저.</target>
        </trans-unit>
        <trans-unit id="9d823ca2ee407bbabe7dc4bda0e7dfaa683e7ffd" translate="yes" xml:space="preserve">
          <source>The Glorot uniform initializer, also called Xavier uniform initializer.</source>
          <target state="translated">Xavier 균일 이니셜 라이저라고도하는 Glorot 균일 이니셜 라이저.</target>
        </trans-unit>
        <trans-unit id="10c27f35329e2804c14ef129a0fd65ea4a51e512" translate="yes" xml:space="preserve">
          <source>The GraphDef of the sub-graph.</source>
          <target state="translated">하위 그래프의 GraphDef</target>
        </trans-unit>
        <trans-unit id="216c6a790806834283ef828e6ca13d0147897e6b" translate="yes" xml:space="preserve">
          <source>The GraphDef version information of this graph.</source>
          <target state="translated">이 그래프의 GraphDef 버전 정보입니다.</target>
        </trans-unit>
        <trans-unit id="655c4658cd7a0d63da53a13b211c6ef8e7cc1af3" translate="yes" xml:space="preserve">
          <source>The Hessian is a matrix of second-order partial derivatives of a scalar tensor (see https://en.wikipedia.org/wiki/Hessian_matrix for more details).</source>
          <target state="translated">Hessian은 스칼라 텐서의 2 차 부분 파생물 행렬입니다 (자세한 내용은 https://en.wikipedia.org/wiki/Hessian_matrix 참조).</target>
        </trans-unit>
        <trans-unit id="d81e5e619b3ab76ee0da2d228e26df5c365438e4" translate="yes" xml:space="preserve">
          <source>The Hurwitz zeta function is defined as:</source>
          <target state="translated">Hurwitz zeta 함수는 다음과 같이 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="6ed2ecdaa3bd96954ea77dce173719510eac3340" translate="yes" xml:space="preserve">
          <source>The ID of the module which registered the flag with this name. If no such module exists (i.e. no flag with this name exists), we return default.</source>
          <target state="translated">이 이름으로 플래그를 등록한 모듈의 ID입니다. 그러한 모듈이 존재하지 않으면 (즉,이 이름의 플래그가 존재하지 않는 경우), 기본값을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="87056d72e53edb8e1ee915616502d31a9e2351aa" translate="yes" xml:space="preserve">
          <source>The Keras functional API in TensorFlow</source>
          <target state="translated">TensorFlow의 Keras 기능 API</target>
        </trans-unit>
        <trans-unit id="36e14ec6d1ffdc156a9c3f1daa6d9890ec3b1e0e" translate="yes" xml:space="preserve">
          <source>The L1 regularization penalty is computed as:</source>
          <target state="translated">L1 정규화 페널티는 다음과 같이 계산됩니다.</target>
        </trans-unit>
        <trans-unit id="5c4ad0ec53302f5554ee8c8eb2b239ae6b215ee1" translate="yes" xml:space="preserve">
          <source>The L2 regularization penalty is computed as</source>
          <target state="translated">L2 정규화 페널티는 다음과 같이 계산됩니다.</target>
        </trans-unit>
        <trans-unit id="0f994e1d48c4b2ebd97fc4c0f1abd04009e95050" translate="yes" xml:space="preserve">
          <source>The L2 regularization penalty is computed as:</source>
          <target state="translated">L2 정규화 페널티는 다음과 같이 계산됩니다.</target>
        </trans-unit>
        <trans-unit id="e7557d40db7eef29f9f5cf0c8852c6278d915ffe" translate="yes" xml:space="preserve">
          <source>The Laplace distribution with location &lt;code&gt;loc&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt; parameters.</source>
          <target state="translated">위치와 라플라스 분포 &lt;code&gt;loc&lt;/code&gt; 및 &lt;code&gt;scale&lt;/code&gt; 매개 변수를 설정합니다.</target>
        </trans-unit>
        <trans-unit id="4f02ec145e8b375175cc81c541eb3f581408f36f" translate="yes" xml:space="preserve">
          <source>The Lpalce distribution is a member of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Location-scale_family&quot;&gt;location-scale family&lt;/a&gt;, i.e., it can be constructed as,</source>
          <target state="translated">Lpalce 배포판은 &lt;a href=&quot;https://en.wikipedia.org/wiki/Location-scale_family&quot;&gt;위치 규모 제품군&lt;/a&gt; 의 구성원입니다. 즉, 다음과 같이 구성 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="179fc5d20bec0f4afac4c22aa43296f1c61f1b50" translate="yes" xml:space="preserve">
          <source>The Multinomial is a distribution over &lt;code&gt;K&lt;/code&gt;-class counts, i.e., a length-&lt;code&gt;K&lt;/code&gt; vector of non-negative integer &lt;code&gt;counts = n = [n_0, ..., n_{K-1}]&lt;/code&gt;.</source>
          <target state="translated">다항식은 &lt;code&gt;K&lt;/code&gt; 클래스 개수, 즉 음이 아닌 정수 &lt;code&gt;counts = n = [n_0, ..., n_{K-1}]&lt;/code&gt; 의 길이 &lt;code&gt;K&lt;/code&gt; 벡터에 대한 분포 입니다.</target>
        </trans-unit>
        <trans-unit id="024145881176dd778a381db52296681ba8110801" translate="yes" xml:space="preserve">
          <source>The Normal distribution is a member of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Location-scale_family&quot;&gt;location-scale family&lt;/a&gt;, i.e., it can be constructed as,</source>
          <target state="translated">정규 분포는 &lt;a href=&quot;https://en.wikipedia.org/wiki/Location-scale_family&quot;&gt;위치 규모 패밀리&lt;/a&gt; 의 멤버입니다. 즉, 다음과 같이 구성 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7626aa48ba3874551b7938ac31ee1cdb369fcdfb" translate="yes" xml:space="preserve">
          <source>The Normal distribution with location &lt;code&gt;loc&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt; parameters.</source>
          <target state="translated">위치와 정규 분포 &lt;code&gt;loc&lt;/code&gt; 및 &lt;code&gt;scale&lt;/code&gt; 매개 변수를 설정합니다.</target>
        </trans-unit>
        <trans-unit id="ef840b903d3e772791466fbdbfc1be244accb53f" translate="yes" xml:space="preserve">
          <source>The Python type for values that are compatible with this TypeSpec.</source>
          <target state="translated">이 TypeSpec과 호환되는 값의 Python 유형입니다.</target>
        </trans-unit>
        <trans-unit id="cb43dc4932964141b3fdd553bcbf71855032420a" translate="yes" xml:space="preserve">
          <source>The RNG algorithm.</source>
          <target state="translated">RNG 알고리즘.</target>
        </trans-unit>
        <trans-unit id="930b59a35037eb9f2e4f2e6718a1e37b8aaa1b56" translate="yes" xml:space="preserve">
          <source>The SDCA algorithm was originally introduced in [1] and it was followed by the L1 proximal step [2], a distributed version [3] and adaptive sampling [4]. [1] www.jmlr.org/papers/volume14/shalev-shwartz13a/shalev-shwartz13a.pdf [2] https://arxiv.org/pdf/1309.2375.pdf [3] https://arxiv.org/pdf/1502.03508.pdf [4] https://arxiv.org/pdf/1502.08053.pdf Details specific to this implementation are provided in: https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/canned/linear_optimizer/doc/sdca.ipynb</source>
          <target state="translated">SDCA 알고리즘은 원래 [1]에 도입되었으며 L1 근위 단계 [2], 분산 버전 [3] 및 적응 형 샘플링 [4]이 뒤따 랐습니다. [1] www.jmlr.org/papers/volume14/shalev-shwartz13a/shalev-shwartz13a.pdf [2] https://arxiv.org/pdf/1309.2375.pdf [3] https://arxiv.org/pdf /1502.03508.pdf [4] https://arxiv.org/pdf/1502.08053.pdf이 구현에 대한 자세한 내용은 https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator에 제공됩니다. /canned/linear_optimizer/doc/sdca.ipynb</target>
        </trans-unit>
        <trans-unit id="a77ce4bc58a785318ac8e94fd8eec273d01ff9a4" translate="yes" xml:space="preserve">
          <source>The SavedModel serialization path uses &lt;a href=&quot;../../saved_model/save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt; to save the model and all trackable objects attached to the model (e.g. layers and variables). &lt;code&gt;@tf.function&lt;/code&gt;-decorated methods are also saved. Additional trackable objects and functions are added to the SavedModel to allow the model to be loaded back as a Keras Model object.</source>
          <target state="translated">SavedModel 직렬화 경로는 &lt;a href=&quot;../../saved_model/save&quot;&gt; &lt;code&gt;tf.saved_model.save&lt;/code&gt; &lt;/a&gt; 를 사용하여 모델 및 모델에 연결된 모든 추적 가능한 객체 (예 : 레이어 및 변수)를 저장합니다. &lt;code&gt;@tf.function&lt;/code&gt; 메소드도 저장됩니다. 모델을 Keras 모델 오브젝트로 다시로드 할 수 있도록 추가 추적 가능한 오브젝트 및 기능이 SavedModel에 추가됩니다.</target>
        </trans-unit>
        <trans-unit id="60a134651d9227079722cdc9e74feb1653be5aa4" translate="yes" xml:space="preserve">
          <source>The Scaled Exponential Linear Unit (SELU) activation function is: &lt;code&gt;scale * x&lt;/code&gt; if &lt;code&gt;x &amp;gt; 0&lt;/code&gt; and &lt;code&gt;scale * alpha * (exp(x) - 1)&lt;/code&gt; if &lt;code&gt;x &amp;lt; 0&lt;/code&gt; where &lt;code&gt;alpha&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt; are pre-defined constants (&lt;code&gt;alpha = 1.67326324&lt;/code&gt; and &lt;code&gt;scale = 1.05070098&lt;/code&gt;). The SELU activation function multiplies &lt;code&gt;scale&lt;/code&gt; &amp;gt; 1 with the &lt;code&gt;[elu](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/activations/elu)&lt;/code&gt; (Exponential Linear Unit (ELU)) to ensure a slope larger than one for positive net inputs.</source>
          <target state="translated">스케일링 지수 선형 단위 (SELU) 활성화 함수이다 &lt;code&gt;scale * x&lt;/code&gt; 경우 &lt;code&gt;x &amp;gt; 0&lt;/code&gt; 및 &lt;code&gt;scale * alpha * (exp(x) - 1)&lt;/code&gt; 경우, &lt;code&gt;x &amp;lt; 0&lt;/code&gt; &lt;code&gt;alpha&lt;/code&gt; 및 &lt;code&gt;scale&lt;/code&gt; 미리 정의 된 상수 ( &lt;code&gt;alpha = 1.67326324&lt;/code&gt; 및 &lt;code&gt;scale = 1.05070098&lt;/code&gt; ). SELU 활성화 기능은 &lt;code&gt;scale&lt;/code&gt; &amp;gt; 1에 &lt;code&gt;[elu](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/activations/elu)&lt;/code&gt; (ELU (Exponential Linear Unit))를 곱합니다. 양의 순 입력에 대해 1보다 큰 기울기를 보장합니다.</target>
        </trans-unit>
        <trans-unit id="8c9823ad487742ec2d729142bb77debf58c1e901" translate="yes" xml:space="preserve">
          <source>The SignatureDef will specify outputs as described in this ExportOutput, and will use the provided receiver_tensors as inputs.</source>
          <target state="translated">SignatureDef는이 ExportOutput에 설명 된대로 출력을 지정하고 제공된 receiver_tensors를 입력으로 사용합니다.</target>
        </trans-unit>
        <trans-unit id="4545224fedce8f364aa3fd2d6cac68ea4817f884" translate="yes" xml:space="preserve">
          <source>The SimpleClusterResolver does not do automatic detection of accelerators, so a TensorFlow session will never be created, and thus all arguments are unused and we simply assume that the type of accelerator is a GPU and return the value in provided to us in the constructor.</source>
          <target state="translated">SimpleClusterResolver는 가속기의 자동 감지를 수행하지 않으므로 TensorFlow 세션이 작성되지 않으므로 모든 인수가 사용되지 않으므로 가속기 유형이 GPU라고 가정하고 생성자에서 제공된 값을 리턴합니다.</target>
        </trans-unit>
        <trans-unit id="95d35b03ae5ea7cdb3cc356783df4e423a2dc6c1" translate="yes" xml:space="preserve">
          <source>The StudentT distribution is a member of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Location-scale_family&quot;&gt;location-scale family&lt;/a&gt;, i.e., it can be constructed as,</source>
          <target state="translated">StudentT 분포는 &lt;a href=&quot;https://en.wikipedia.org/wiki/Location-scale_family&quot;&gt;위치 규모 제품군&lt;/a&gt; 의 구성원입니다. 즉, 다음과 같이 구성 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="5c2d5184416b64215504aa1a967e583b20731ca8" translate="yes" xml:space="preserve">
          <source>The Supervisor is a small wrapper around a &lt;code&gt;Coordinator&lt;/code&gt;, a &lt;code&gt;Saver&lt;/code&gt;, and a &lt;code&gt;SessionManager&lt;/code&gt; that takes care of common needs of TensorFlow training programs.</source>
          <target state="translated">Supervisor는 TensorFlow 교육 프로그램의 일반적인 요구를 처리 하는 &lt;code&gt;Coordinator&lt;/code&gt; , &lt;code&gt;Saver&lt;/code&gt; 및 &lt;code&gt;SessionManager&lt;/code&gt; 를 둘러싼 작은 래퍼 입니다.</target>
        </trans-unit>
        <trans-unit id="41bd5ff6b458ccdec0fd96ba0408336a12a70400" translate="yes" xml:space="preserve">
          <source>The TF-TRT converted Function.</source>
          <target state="translated">TF-TRT가 기능을 변환했습니다.</target>
        </trans-unit>
        <trans-unit id="363164ea24b07b74dc51248150c976cfc6c56e68" translate="yes" xml:space="preserve">
          <source>The Tensor or SparseTensor or CompositeTensor in &lt;code&gt;graph&lt;/code&gt; described by &lt;code&gt;tensor_info&lt;/code&gt;.</source>
          <target state="translated">텐서에 또는 SparseTensor 또는 CompositeTensor &lt;code&gt;graph&lt;/code&gt; 설명 &lt;code&gt;tensor_info&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2b213eabf8ccb6ff5bf4ab0a41158ab15e62ff3b" translate="yes" xml:space="preserve">
          <source>The TensorFlow format matches objects and variables by starting at a root object, &lt;code&gt;self&lt;/code&gt; for &lt;code&gt;save_weights&lt;/code&gt;, and greedily matching attribute names. For &lt;a href=&quot;../model#save&quot;&gt;&lt;code&gt;Model.save&lt;/code&gt;&lt;/a&gt; this is the &lt;code&gt;Model&lt;/code&gt;, and for &lt;a href=&quot;../../train/checkpoint#save&quot;&gt;&lt;code&gt;Checkpoint.save&lt;/code&gt;&lt;/a&gt; this is the &lt;code&gt;Checkpoint&lt;/code&gt; even if the &lt;code&gt;Checkpoint&lt;/code&gt; has a model attached. This means saving a &lt;a href=&quot;../model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; using &lt;code&gt;save_weights&lt;/code&gt; and loading into a &lt;a href=&quot;../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; with a &lt;code&gt;Model&lt;/code&gt; attached (or vice versa) will not match the &lt;code&gt;Model&lt;/code&gt;'s variables. See the &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;guide to training checkpoints&lt;/a&gt; for details on the TensorFlow format.</source>
          <target state="translated">TensorFlow 형식은 루트 객체에서 시작하여 객체 및 변수에 일치하는 &lt;code&gt;self&lt;/code&gt; 에 대한 &lt;code&gt;save_weights&lt;/code&gt; , 그리고 탐욕 일치하는 속성 이름. 들어 &lt;a href=&quot;../model#save&quot;&gt; &lt;code&gt;Model.save&lt;/code&gt; &lt;/a&gt; 이것은이다 &lt;code&gt;Model&lt;/code&gt; 및 대한 &lt;a href=&quot;../../train/checkpoint#save&quot;&gt; &lt;code&gt;Checkpoint.save&lt;/code&gt; &lt;/a&gt; 이는 것입니다 &lt;code&gt;Checkpoint&lt;/code&gt; 짝수 경우 &lt;code&gt;Checkpoint&lt;/code&gt; 부착 된 모델을 가지고있다. 즉, &lt;a href=&quot;../model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; &lt;/a&gt; 사용하여 &lt;code&gt;save_weights&lt;/code&gt; 저장하고 &lt;code&gt;Model&lt;/code&gt; 이 첨부 된 (또는 그 반대) &lt;a href=&quot;../../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; 로 로드 하면 &lt;code&gt;Model&lt;/code&gt; 변수 와 일치하지 않습니다 . &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;훈련 체크 포인트 가이드&lt;/a&gt; 참조 TensorFlow 형식에 대한 자세한 내용은</target>
        </trans-unit>
        <trans-unit id="9ab4684c965e60031ddf80734d60fea35c517d3d" translate="yes" xml:space="preserve">
          <source>The TensorFlow format matches objects and variables by starting at a root object, &lt;code&gt;self&lt;/code&gt; for &lt;code&gt;save_weights&lt;/code&gt;, and greedily matching attribute names. For &lt;a href=&quot;model#save&quot;&gt;&lt;code&gt;Model.save&lt;/code&gt;&lt;/a&gt; this is the &lt;code&gt;Model&lt;/code&gt;, and for &lt;a href=&quot;../train/checkpoint#save&quot;&gt;&lt;code&gt;Checkpoint.save&lt;/code&gt;&lt;/a&gt; this is the &lt;code&gt;Checkpoint&lt;/code&gt; even if the &lt;code&gt;Checkpoint&lt;/code&gt; has a model attached. This means saving a &lt;a href=&quot;model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; using &lt;code&gt;save_weights&lt;/code&gt; and loading into a &lt;a href=&quot;../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; with a &lt;code&gt;Model&lt;/code&gt; attached (or vice versa) will not match the &lt;code&gt;Model&lt;/code&gt;'s variables. See the &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;guide to training checkpoints&lt;/a&gt; for details on the TensorFlow format.</source>
          <target state="translated">TensorFlow 형식은 루트 객체에서 시작하여 객체 및 변수에 일치하는 &lt;code&gt;self&lt;/code&gt; 에 대한 &lt;code&gt;save_weights&lt;/code&gt; , 그리고 탐욕 일치하는 속성 이름. 들어 &lt;a href=&quot;model#save&quot;&gt; &lt;code&gt;Model.save&lt;/code&gt; &lt;/a&gt; 이것은이다 &lt;code&gt;Model&lt;/code&gt; 및 대한 &lt;a href=&quot;../train/checkpoint#save&quot;&gt; &lt;code&gt;Checkpoint.save&lt;/code&gt; &lt;/a&gt; 이는 것입니다 &lt;code&gt;Checkpoint&lt;/code&gt; 짝수 경우 &lt;code&gt;Checkpoint&lt;/code&gt; 부착 된 모델을 가지고있다. 즉, &lt;a href=&quot;model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; &lt;/a&gt; 사용하여 &lt;code&gt;save_weights&lt;/code&gt; 저장하고 &lt;code&gt;Model&lt;/code&gt; 이 첨부 된 (또는 그 반대) &lt;a href=&quot;../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; 로 로드 하면 &lt;code&gt;Model&lt;/code&gt; 변수 와 일치하지 않습니다 . &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;훈련 체크 포인트 가이드&lt;/a&gt; 참조 TensorFlow 형식에 대한 자세한 내용은</target>
        </trans-unit>
        <trans-unit id="b7638d4a5c348f022578401c2f1df999594f7eff" translate="yes" xml:space="preserve">
          <source>The TensorFlow process to which this session will connect.</source>
          <target state="translated">이 세션이 연결될 TensorFlow 프로세스.</target>
        </trans-unit>
        <trans-unit id="16a70a758b7ef6d7fd0aad2771edf2a93446ebcd" translate="yes" xml:space="preserve">
          <source>The Tensors returned by computation.</source>
          <target state="translated">텐서는 계산에 의해 반환됩니다.</target>
        </trans-unit>
        <trans-unit id="45ecd5a2e94b407ef5967be01d6aea7e5dfb3bca" translate="yes" xml:space="preserve">
          <source>The Variable has rank &lt;code&gt;P&lt;/code&gt; and &lt;code&gt;indices&lt;/code&gt; is a &lt;code&gt;Tensor&lt;/code&gt; of rank &lt;code&gt;Q&lt;/code&gt;.</source>
          <target state="translated">변수의 순위는 &lt;code&gt;P&lt;/code&gt; 이고 &lt;code&gt;indices&lt;/code&gt; 는 순위 &lt;code&gt;Q&lt;/code&gt; 의 &lt;code&gt;Tensor&lt;/code&gt; 입니다 .</target>
        </trans-unit>
        <trans-unit id="f53a9ea2c1d95dd8b27a8885316c2bc7fb8ad0c0" translate="yes" xml:space="preserve">
          <source>The Y, X coordinates within each block of the input become the high order component of the output channel index.</source>
          <target state="translated">입력의 각 블록 내에서 Y, X 좌표는 출력 채널 인덱스의 상위 컴포넌트가됩니다.</target>
        </trans-unit>
        <trans-unit id="3d6c86d0708bda3da64a9da6d3c863b9ab737231" translate="yes" xml:space="preserve">
          <source>The Y, X coordinates within each block of the output image are determined by the high order component of the input channel index.</source>
          <target state="translated">출력 이미지의 각 블록 내의 Y, X 좌표는 입력 채널 인덱스의 상위 성분에 의해 결정됩니다.</target>
        </trans-unit>
        <trans-unit id="8cd36e977186fec64e8448a96228fbf260cd4605" translate="yes" xml:space="preserve">
          <source>The ZLIB compression level, &lt;code&gt;compression&lt;/code&gt;, can be -1 for the PNG-encoder default or a value from 0 to 9. 9 is the highest compression level, generating the smallest output, but is slower.</source>
          <target state="translated">ZLIB 압축 수준 &lt;code&gt;compression&lt;/code&gt; 은 PNG 인코더 기본값의 경우 -1이거나 0에서 9 사이의 값일 수 있습니다. 9는 가장 높은 압축 수준으로 가장 작은 출력을 생성하지만 느립니다.</target>
        </trans-unit>
        <trans-unit id="ce03da9cead6e86adf2a8009f5862736d75ecdca" translate="yes" xml:space="preserve">
          <source>The [batch] scalar &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;c&lt;/code&gt; in &lt;code&gt;cI&lt;/code&gt;.</source>
          <target state="translated">에서 [배치] 스칼라 &lt;code&gt;Tensor&lt;/code&gt; , &lt;code&gt;c&lt;/code&gt; 의 &lt;code&gt;cI&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="aaf6c09a17773617259c0e894f03f2f3f8ff8317" translate="yes" xml:space="preserve">
          <source>The above changes os.path.exists into a lambda that returns 1. Once the ... part of the code finishes, the CleanUp() looks up the old value of os.path.exists and restores it.</source>
          <target state="translated">위의 코드는 os.path.exists를 1을 반환하는 람다로 변경합니다. 코드의 ... 부분이 완료되면 CleanUp ()은 os.path.exists의 기존 값을 찾아서 복원합니다.</target>
        </trans-unit>
        <trans-unit id="b8bb936a65c3ce409995481c6a4f6df5ec2956c6" translate="yes" xml:space="preserve">
          <source>The activation value.</source>
          <target state="translated">활성화 값.</target>
        </trans-unit>
        <trans-unit id="da7330feac6d473367759d5dd1a21e9334b8d8de" translate="yes" xml:space="preserve">
          <source>The added Keras attribute is: &lt;code&gt;_keras_history&lt;/code&gt;: Last layer applied to the tensor. the entire layer graph is retrievable from that layer, recursively.</source>
          <target state="translated">추가 된 &lt;code&gt;_keras_history&lt;/code&gt; 속성은 다음 과 같습니다 . _keras_history : 텐서에 마지막으로 적용된 레이어. 전체 레이어 그래프는 해당 레이어에서 재귀 적으로 검색 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="f24861cc1a42612e73b3f3665071eeed2c9ea315" translate="yes" xml:space="preserve">
          <source>The additional robustness comes at a cost of roughly 4x higher compute time than &lt;code&gt;tf.string_to_hash_bucket_fast&lt;/code&gt;.</source>
          <target state="translated">추가적인 견고성은 &lt;code&gt;tf.string_to_hash_bucket_fast&lt;/code&gt; 보다 계산 시간이 약 4 배 빠릅니다 .</target>
        </trans-unit>
        <trans-unit id="92d822d5e3a4a473e569254158aeaed3f44c8de9" translate="yes" xml:space="preserve">
          <source>The address of the given task in the given job.</source>
          <target state="translated">주어진 작업에서 주어진 작업의 주소.</target>
        </trans-unit>
        <trans-unit id="1044e0e4428294ca84bc27c7d972e47ecc834421" translate="yes" xml:space="preserve">
          <source>The address of the master.</source>
          <target state="translated">마스터의 주소입니다.</target>
        </trans-unit>
        <trans-unit id="a671b38fc84a246388b74802d7c3903f8c308213" translate="yes" xml:space="preserve">
          <source>The adjoint (a.k.a. Hermitian transpose a.k.a. conjugate transpose) of matrix.</source>
          <target state="translated">매트릭스의 인접 (일명 에르 미트 (Hermitian) 전치 (일명 공역 전치)).</target>
        </trans-unit>
        <trans-unit id="d26f5dd591fe207d72f8bf3767404f30851360da" translate="yes" xml:space="preserve">
          <source>The adjusted &lt;code&gt;min_range&lt;/code&gt; and &lt;code&gt;max_range&lt;/code&gt; are returned as outputs 2 and 3 of this operation. These outputs should be used as the range for any further calculations.</source>
          <target state="translated">조정 된 &lt;code&gt;min_range&lt;/code&gt; 및 &lt;code&gt;max_range&lt;/code&gt; 는이 작업의 출력 2 및 3으로 반환됩니다. 이 출력은 추가 계산을위한 범위로 사용해야합니다.</target>
        </trans-unit>
        <trans-unit id="34a7065e06c55b3339a4e1c47bf34bd00d072e70" translate="yes" xml:space="preserve">
          <source>The algorithm starts by setting the loss scale to an initial value. Every N steps that the gradients are finite, the loss scale is increased by some factor. However, if a NaN or Inf gradient is found, the gradients for that step are not applied, and the loss scale is decreased by the factor. This process tends to keep the loss scale as high as possible without gradients overflowing.</source>
          <target state="translated">알고리즘은 손실 스케일을 초기 값으로 설정하여 시작합니다. 그라디언트가 유한 한 모든 N 단계마다 손실 스케일이 어느 정도 증가합니다. 그러나 NaN 또는 Inf 그래디언트가 발견되면 해당 단계의 그래디언트가 적용되지 않고 손실 스케일이 요인에 의해 감소합니다. 이 프로세스는 그래디언트 오버플로없이 손실 규모를 최대한 높게 유지하는 경향이 있습니다.</target>
        </trans-unit>
        <trans-unit id="ec9f002d6d3b1e71963d9cf73b905f9b84153981" translate="yes" xml:space="preserve">
          <source>The appropriate slice of &quot;tensor&quot;, based on &quot;slice_spec&quot;.</source>
          <target state="translated">&quot;slice_spec&quot;을 기반으로 한 &quot;tensor&quot;의 적절한 슬라이스입니다.</target>
        </trans-unit>
        <trans-unit id="821f24c959536d42cc6fec55c7d0ad6a3d16e3c7" translate="yes" xml:space="preserve">
          <source>The appropriate slice of &quot;tensor&quot;, based on &quot;slice_spec&quot;. As an operator. The operator also has a &lt;code&gt;assign()&lt;/code&gt; method that can be used to generate an assignment operator.</source>
          <target state="translated">&quot;slice_spec&quot;을 기반으로 한 &quot;tensor&quot;의 적절한 슬라이스입니다. 운영자로서. 운영자는 또한 &lt;code&gt;assign()&lt;/code&gt; 에는 할당 연산자를 생성하는 데 사용할 수 assign () 메서드도 있습니다.</target>
        </trans-unit>
        <trans-unit id="23ef91f4c9a43b0bf509fbf539d12c4d114f51e2" translate="yes" xml:space="preserve">
          <source>The area within the interval is (slope / total_pos_weight) times</source>
          <target state="translated">구간 내 면적은 (기울기 / total_pos_weight) 시간입니다</target>
        </trans-unit>
        <trans-unit id="d2d3e064486f4100aead5629a0acce01f2954896" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;normalized&lt;/code&gt; and &lt;code&gt;centered&lt;/code&gt; controls how the windows are built:</source>
          <target state="translated">논쟁은 &lt;code&gt;normalized&lt;/code&gt; 되고 &lt;code&gt;centered&lt;/code&gt; 는 창을 만드는 방법을 제어합니다.</target>
        </trans-unit>
        <trans-unit id="572a6d647b031b519cd29780ad535922e4e59db7" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;shape&lt;/code&gt; is optional. If present, it specifies the dimensions of the resulting tensor. If not present, the shape of &lt;code&gt;value&lt;/code&gt; is used.</source>
          <target state="translated">인수 &lt;code&gt;shape&lt;/code&gt; 는 선택 사항입니다. 존재하는 경우 결과 텐서의 크기를 지정합니다. 존재하지 않으면 &lt;code&gt;value&lt;/code&gt; 의 모양 이 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="13e87601baeedfadd1e05e7b900ecdbd205d0bf6" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;tensors&lt;/code&gt; can be a list or a dictionary of tensors. The value returned by the function will be of the same type as &lt;code&gt;tensors&lt;/code&gt;.</source>
          <target state="translated">인수 &lt;code&gt;tensors&lt;/code&gt; 는 텐서 의 목록 또는 사전 일 수 있습니다. 함수가 반환 한 값은 &lt;code&gt;tensors&lt;/code&gt; 와 동일한 유형 입니다.</target>
        </trans-unit>
        <trans-unit id="a32d0e1dadf3135bed15ded733117d1a197ad906" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;value&lt;/code&gt; can be a constant value, or a list of values of type &lt;code&gt;dtype&lt;/code&gt;. If &lt;code&gt;value&lt;/code&gt; is a list, then the length of the list must be less than or equal to the number of elements implied by the &lt;code&gt;shape&lt;/code&gt; argument (if specified). In the case where the list length is less than the number of elements specified by &lt;code&gt;shape&lt;/code&gt;, the last element in the list will be used to fill the remaining entries.</source>
          <target state="translated">인수 &lt;code&gt;value&lt;/code&gt; 은 상수 값이거나 &lt;code&gt;dtype&lt;/code&gt; 유형의 값 목록 일 수 있습니다 . &lt;code&gt;value&lt;/code&gt; 가 목록 인 경우 목록의 길이는 &lt;code&gt;shape&lt;/code&gt; 인수에 의해 암시 된 요소 수보다 작거나 같아야합니다 (지정된 경우). 목록 길이가 다음에 의해 지정된 요소 수보다 작은 경우 &lt;code&gt;shape&lt;/code&gt; 로 의 마지막 요소가 나머지 항목을 채우는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="4f585d29c2b28791ced3d5b4a780f2d82b9f8bf3" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;value&lt;/code&gt; can be a constant value, or a list of values of type &lt;code&gt;dtype&lt;/code&gt;. If &lt;code&gt;value&lt;/code&gt; is a list, then the length of the list must be less than or equal to the number of elements implied by the desired shape of the tensor. In the case where the total number of elements in &lt;code&gt;value&lt;/code&gt; is less than the number of elements required by the tensor shape, the last element in &lt;code&gt;value&lt;/code&gt; will be used to fill the remaining entries. If the total number of elements in &lt;code&gt;value&lt;/code&gt; is greater than the number of elements required by the tensor shape, the initializer will raise a &lt;code&gt;ValueError&lt;/code&gt;.</source>
          <target state="translated">인수 &lt;code&gt;value&lt;/code&gt; 은 상수 값이거나 &lt;code&gt;dtype&lt;/code&gt; 유형의 값 목록 일 수 있습니다 . &lt;code&gt;value&lt;/code&gt; 가리스트 인 경우 ,리스트의 길이는 원하는 텐서 모양에 의해 암시되는 요소의 수보다 작거나 같아야합니다. &lt;code&gt;value&lt;/code&gt; 의 총 요소 수가 텐서 모양에 필요한 요소의 수보다 적은 경우, &lt;code&gt;value&lt;/code&gt; 의 마지막 요소 가 나머지 항목을 채우는 데 사용됩니다. &lt;code&gt;value&lt;/code&gt; 의 총 요소 수가 텐서 모양에 필요한 요소 수보다 큰 경우 이니셜 라이저는 &lt;code&gt;ValueError&lt;/code&gt; 를 발생 시킵니다.</target>
        </trans-unit>
        <trans-unit id="35b02213c63b22c6aa288eadb099101e8c7a8bb2" translate="yes" xml:space="preserve">
          <source>The argument returned by this function is of the form \(atan2(b, a)\). If &lt;code&gt;input&lt;/code&gt; is real, a tensor of all zeros is returned.</source>
          <target state="translated">이 함수가 반환하는 인수는 \ (atan2 (b, a) \) 형식입니다. &lt;code&gt;input&lt;/code&gt; 하면 진짜, 모두 제로의 텐서가 반환됩니다.</target>
        </trans-unit>
        <trans-unit id="bce43bdee979454925721c507561e0a29cfacb37" translate="yes" xml:space="preserve">
          <source>The attempt is silently dropped if the gradient is stale, i.e., &lt;code&gt;local_step&lt;/code&gt; is less than the accumulator's global time step.</source>
          <target state="translated">그래디언트가 오래된 경우 (즉, &lt;code&gt;local_step&lt;/code&gt; 이 누산기의 글로벌 시간 단계보다 작 으면) 시도가 자동으로 삭제됩니다 .</target>
        </trans-unit>
        <trans-unit id="c2d9f9b7d3b4bc909dac3ec1179989967a68da98" translate="yes" xml:space="preserve">
          <source>The attempt is silently dropped if the gradient is stale, i.e., local_step is less than the accumulator's global time step.</source>
          <target state="translated">그래디언트가 오래된 경우 (즉, local_step이 누산기의 글로벌 시간 단계보다 작 으면) 시도가 자동으로 삭제됩니다.</target>
        </trans-unit>
        <trans-unit id="d8f6f1e67bc16f32d9f24b6bf9dc1327c99b4c20" translate="yes" xml:space="preserve">
          <source>The attr &lt;code&gt;block_size&lt;/code&gt; must be greater than one. It indicates the block size.</source>
          <target state="translated">attr &lt;code&gt;block_size&lt;/code&gt; 는 1보다 커야합니다. 블록 크기를 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="b44ab2abacbb2efdb69194961a5971ce5296193c" translate="yes" xml:space="preserve">
          <source>The attr &lt;code&gt;channels&lt;/code&gt; indicates the desired number of color channels for the decoded image.</source>
          <target state="translated">attr &lt;code&gt;channels&lt;/code&gt; 은 디코딩 된 이미지에 대한 원하는 컬러 채널 수를 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="60563f76a3b65c009555c6aca9d9b0a28f8e6c56" translate="yes" xml:space="preserve">
          <source>The attr &lt;code&gt;format&lt;/code&gt; can be used to override the color format of the encoded output. Values can be:</source>
          <target state="translated">attr &lt;code&gt;format&lt;/code&gt; 을 사용하여 인코딩 된 출력의 색상 형식을 재정의 할 수 있습니다. 값은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="ae606ee2da5f189375721f138e9665ac82e81365" translate="yes" xml:space="preserve">
          <source>The attr &lt;code&gt;ratio&lt;/code&gt; allows downscaling the image by an integer factor during decoding. Allowed values are: 1, 2, 4, and 8. This is much faster than downscaling the image later.</source>
          <target state="translated">attr &lt;code&gt;ratio&lt;/code&gt; 은 디코딩 중에 이미지를 정수로 축소 할 수 있습니다. 허용되는 값은 1, 2, 4 및 8입니다. 이것은 나중에 이미지를 축소하는 것보다 훨씬 빠릅니다.</target>
        </trans-unit>
        <trans-unit id="43192d2acab6f30a3fb88a081e4480c6a4eaf531" translate="yes" xml:space="preserve">
          <source>The base class for all flags errors.</source>
          <target state="translated">모든 플래그 오류의 기본 클래스입니다.</target>
        </trans-unit>
        <trans-unit id="95fac0e9d908797873ec2155df12d61346d3ec3c" translate="yes" xml:space="preserve">
          <source>The base distribution for this operation is an approximately log-uniform or Zipfian distribution:</source>
          <target state="translated">이 작업의 기본 분포는 대략 로그 균일 분포 또는 Zipfian 분포입니다.</target>
        </trans-unit>
        <trans-unit id="e03722f7ec155314d6d64a06632231a0220ddf21" translate="yes" xml:space="preserve">
          <source>The base distribution for this operation is constructed on the fly during training. It is a unigram distribution over the target classes seen so far during training. Every integer in &lt;code&gt;[0, range_max)&lt;/code&gt; begins with a weight of 1, and is incremented by 1 each time it is seen as a target class. The base distribution is not saved to checkpoints, so it is reset when the model is reloaded.</source>
          <target state="translated">이 작업의 기본 분포는 교육 중에 즉시 구성됩니다. 그것은 훈련 중에 지금까지 본 대상 클래스에 대한 유니 그램 분포입니다. &lt;code&gt;[0, range_max)&lt;/code&gt; 모든 정수 는 가중치 1로 시작하며 대상 클래스로 볼 때마다 1 씩 증가합니다. 기본 분포는 검사 점에 저장되지 않으므로 모델을 다시로드하면 재설정됩니다.</target>
        </trans-unit>
        <trans-unit id="9b285a7357154664da97ef50a86143b40cc66c8c" translate="yes" xml:space="preserve">
          <source>The base distribution for this operation is the uniform distribution over the range of integers &lt;code&gt;[0, range_max)&lt;/code&gt;.</source>
          <target state="translated">이 연산의 기본 분포는 정수 범위 &lt;code&gt;[0, range_max)&lt;/code&gt; 대한 균일 분포 입니다.</target>
        </trans-unit>
        <trans-unit id="77b83a8d332ed8aca766d79f4120f4e0ba2ea928" translate="yes" xml:space="preserve">
          <source>The base distribution is read from a file or passed in as an in-memory array. There is also an option to skew the distribution by applying a distortion power to the weights.</source>
          <target state="translated">기본 배포는 파일에서 읽거나 메모리 내 배열로 전달됩니다. 가중치에 왜곡 전력을 적용하여 분포를 왜곡하는 옵션도 있습니다.</target>
        </trans-unit>
        <trans-unit id="7c0a22a2ecdff77c481cab7326fe4aaa0b144cf7" translate="yes" xml:space="preserve">
          <source>The batch dimensions are indexes into independent, non-identical parameterizations of this distribution.</source>
          <target state="translated">배치 차원은이 분포의 독립적이고 동일하지 않은 모수화에 대한 색인입니다.</target>
        </trans-unit>
        <trans-unit id="b55a5f5737af8dc7c66469a674fe7b35b3d67f61" translate="yes" xml:space="preserve">
          <source>The batch dimensions, denoted as &lt;code&gt;...&lt;/code&gt;, must be the same in &lt;code&gt;diagonals&lt;/code&gt; and &lt;code&gt;rhs&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;...&lt;/code&gt; 로 표시된 배치 치수 는 &lt;code&gt;diagonals&lt;/code&gt; 과 &lt;code&gt;rhs&lt;/code&gt; 에서 동일해야합니다. .</target>
        </trans-unit>
        <trans-unit id="b8d1e654d8a3893e3ebd1816b79375a5883dc270" translate="yes" xml:space="preserve">
          <source>The batch of the output tensor is &lt;code&gt;batch * block_size * block_size&lt;/code&gt;.</source>
          <target state="translated">출력 텐서의 &lt;code&gt;batch * block_size * block_size&lt;/code&gt; 는 batch * block_size * block_size 입니다.</target>
        </trans-unit>
        <trans-unit id="d9d6c8abb90d01f2c83046e4ffaae926e1136406" translate="yes" xml:space="preserve">
          <source>The biggest difference between this and MIN_COMBINED is that the minimum range is rounded first, before it's subtracted from the rounded value. With MIN_COMBINED, a small bias is introduced where repeated iterations of quantizing and dequantizing will introduce a larger and larger error.</source>
          <target state="translated">이것과 MIN_COMBINED의 가장 큰 차이점은 반올림 값에서 빼기 전에 최소 범위가 먼저 반올림된다는 것입니다. MIN_COMBINED를 사용하면 반복적 인 양자화 및 역 양자화 반복이 더 큰 오류를 발생시키는 작은 바이어스가 발생합니다.</target>
        </trans-unit>
        <trans-unit id="72445c1ce9af91d1b7756490161ef93a455800a7" translate="yes" xml:space="preserve">
          <source>The binomial distribution with parameters &lt;code&gt;n&lt;/code&gt; and &lt;code&gt;p&lt;/code&gt; is the probability distribution of the number of successful Bernoulli process. Only supports &lt;code&gt;n&lt;/code&gt; = 1 for now.</source>
          <target state="translated">모수 &lt;code&gt;n&lt;/code&gt; 과 &lt;code&gt;p&lt;/code&gt; 를 갖는 이항 분포 는 성공적인 Bernoulli 프로세스 수의 확률 분포입니다. 현재 는 &lt;code&gt;n&lt;/code&gt; = 1 만 지원합니다 .</target>
        </trans-unit>
        <trans-unit id="9046a47f005a317609f27142cf924b36a45d9e12" translate="yes" xml:space="preserve">
          <source>The body of the function (i.e. &lt;code&gt;func&lt;/code&gt;) will not be serialized in a &lt;code&gt;GraphDef&lt;/code&gt;. Therefore, you should not use this function if you need to serialize your model and restore it in a different environment.</source>
          <target state="translated">함수 본문 (예 : &lt;code&gt;func&lt;/code&gt; )은 &lt;code&gt;GraphDef&lt;/code&gt; 에서 직렬화되지 않습니다. . 따라서 모델을 직렬화하고 다른 환경에서 복원해야하는 경우이 기능을 사용하지 마십시오.</target>
        </trans-unit>
        <trans-unit id="794d80e295e24e3ff23cc23c744638ef8dd2ef67" translate="yes" xml:space="preserve">
          <source>The body of the function (i.e. &lt;code&gt;func&lt;/code&gt;) will not be serialized in a &lt;code&gt;tf.SavedModel&lt;/code&gt;. Therefore, you should not use this function if you need to serialize your model and restore it in a different environment.</source>
          <target state="translated">함수의 본문 (예 : &lt;code&gt;func&lt;/code&gt; )은 &lt;code&gt;tf.SavedModel&lt;/code&gt; 에서 직렬화되지 않습니다 . 따라서 모델을 직렬화하고 다른 환경에서 복원해야하는 경우이 기능을 사용하지 마십시오.</target>
        </trans-unit>
        <trans-unit id="4e7703441ddf5ba9641cb1cc0ad74e7c6c58e3a7" translate="yes" xml:space="preserve">
          <source>The brightness-adjusted image(s).</source>
          <target state="translated">밝기 조정 이미지.</target>
        </trans-unit>
        <trans-unit id="d1e48a233423d312fda6e60318a1f77840441ac1" translate="yes" xml:space="preserve">
          <source>The call arguments for this layer are the same as those of the wrapped RNN layer.</source>
          <target state="translated">이 계층의 호출 인수는 랩핑 된 RNN 계층의 호출 인수와 동일합니다.</target>
        </trans-unit>
        <trans-unit id="e327ae814821b8183785f0c019aba0430d092c8e" translate="yes" xml:space="preserve">
          <source>The centered version additionally maintains a moving average of the gradients, and uses that average to estimate the variance:</source>
          <target state="translated">가운데 버전은 그라디언트의 이동 평균을 추가로 유지하고 해당 평균을 사용하여 분산을 추정합니다.</target>
        </trans-unit>
        <trans-unit id="ffd9bc04f2dc35c549a84231faac7f8f675d1f25" translate="yes" xml:space="preserve">
          <source>The checkpoint includes variables created by this object and any trackable objects it depends on at the time &lt;a href=&quot;../../../train/checkpoint#write&quot;&gt;&lt;code&gt;Checkpoint.write()&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="translated">검사 점에는이 개체에 의해 생성 된 변수와 &lt;a href=&quot;../../../train/checkpoint#write&quot;&gt; &lt;code&gt;Checkpoint.write()&lt;/code&gt; &lt;/a&gt; 가 호출 될 때 추적 가능한 개체 가 포함됩니다.</target>
        </trans-unit>
        <trans-unit id="efb4974f19ee7156bcbc2c149c6eb12fbb9c2851" translate="yes" xml:space="preserve">
          <source>The checkpoint includes variables created by this object and any trackable objects it depends on at the time &lt;a href=&quot;checkpoint#write&quot;&gt;&lt;code&gt;Checkpoint.write()&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="translated">검사 점에는이 개체에 의해 생성 된 변수와 &lt;a href=&quot;checkpoint#write&quot;&gt; &lt;code&gt;Checkpoint.write()&lt;/code&gt; &lt;/a&gt; 가 호출 될 때 추적 가능한 개체 가 포함됩니다.</target>
        </trans-unit>
        <trans-unit id="3cf3d251f72fdb454086ef22c80d6dfc9f2a709b" translate="yes" xml:space="preserve">
          <source>The checkpoint prefix. If there are no checkpoints, returns &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">검사 점 접두사 검사 점이 없으면 &lt;code&gt;None&lt;/code&gt; 을 반환합니다 .</target>
        </trans-unit>
        <trans-unit id="54c52716619b24d86f051441e79e67309f282670" translate="yes" xml:space="preserve">
          <source>The class specifies the parameters to configure a &lt;a href=&quot;physicaldevice&quot;&gt;&lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt;&lt;/a&gt; as it is initialized to a &lt;a href=&quot;logicaldevice&quot;&gt;&lt;code&gt;tf.config.LogicalDevice&lt;/code&gt;&lt;/a&gt; during runtime initialization. Not all fields are valid for all device types.</source>
          <target state="translated">이 클래스 는 런타임 초기화 중에 &lt;a href=&quot;physicaldevice&quot;&gt; &lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt; &lt;/a&gt; 로 초기화 될 때 &lt;a href=&quot;logicaldevice&quot;&gt; &lt;code&gt;tf.config.LogicalDevice&lt;/code&gt; &lt;/a&gt; 를 구성하기위한 매개 변수를 지정합니다 . 모든 필드가 모든 장치 유형에 유효한 것은 아닙니다.</target>
        </trans-unit>
        <trans-unit id="8cadabc814bf5f30961f39db7a416141d019058e" translate="yes" xml:space="preserve">
          <source>The class uses optional peep-hole connections, optional cell clipping, and an optional projection layer.</source>
          <target state="translated">이 클래스는 선택적인 구멍 연결, 선택적인 셀 클리핑 및 선택적인 투영 레이어를 사용합니다.</target>
        </trans-unit>
        <trans-unit id="a5550331649ac8852e50082985bc4347ae4ddf34" translate="yes" xml:space="preserve">
          <source>The classes &lt;code&gt;Tensor&lt;/code&gt; must provide string labels, not integer class IDs.</source>
          <target state="translated">클래스 &lt;code&gt;Tensor&lt;/code&gt; 는 정수 클래스 ID가 아닌 문자열 레이블을 제공해야합니다.</target>
        </trans-unit>
        <trans-unit id="8055f38c5a2a613d3b7898156485e396610a7e44" translate="yes" xml:space="preserve">
          <source>The companion method &lt;code&gt;start_queue_runners()&lt;/code&gt; can be used to start threads for all the collected queue runners.</source>
          <target state="translated">컴패니언 메소드 &lt;code&gt;start_queue_runners()&lt;/code&gt; 를 사용하여 수집 된 모든 큐 러너의 스레드를 시작할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="97a9b8c4557a2e822deec22848a2c3bf8b143002" translate="yes" xml:space="preserve">
          <source>The compatibility module also provides the following aliases for common sets of python types:</source>
          <target state="translated">호환성 모듈은 일반적인 파이썬 유형 집합에 대해 다음과 같은 별칭을 제공합니다.</target>
        </trans-unit>
        <trans-unit id="c76eb8b972301e83c208f809121c80f183543a3c" translate="yes" xml:space="preserve">
          <source>The compatibility relation is reflexive and symmetric, but not transitive. For example, TensorShape([32, 784]) is compatible with TensorShape(None), and TensorShape(None) is compatible with TensorShape([4, 4]), but TensorShape([32, 784]) is not compatible with TensorShape([4, 4]).</source>
          <target state="translated">호환성 관계는 반사적이고 대칭이지만 전이는 아닙니다. 예를 들어, TensorShape ([32, 784])는 TensorShape (None)과 호환되고 TensorShape (None)은 TensorShape ([4, 4])와 호환되지만 TensorShape ([32, 784])는 TensorShape와 호환되지 않습니다 ([4, 4]).</target>
        </trans-unit>
        <trans-unit id="bc1fe8d57fc26b638818429d0e0fce300365e0f7" translate="yes" xml:space="preserve">
          <source>The compilation flags.</source>
          <target state="translated">컴파일 플래그.</target>
        </trans-unit>
        <trans-unit id="004ddc3feaeb4999946bd055243271e6c1c5e458" translate="yes" xml:space="preserve">
          <source>The compilation is a hint and only supported on a best-effort basis.</source>
          <target state="translated">컴파일은 힌트이며 최선의 노력으로 만 지원됩니다.</target>
        </trans-unit>
        <trans-unit id="2a97fc9aeef3aac0ee7b0d6fc3913b5f131a8ce4" translate="yes" xml:space="preserve">
          <source>The complex conjugate returned by this operation is of the form \(a - bj\).</source>
          <target state="translated">이 오퍼레이션에 의해 리턴되는 켤레 복소수는 \ (a-bj \) 형식입니다.</target>
        </trans-unit>
        <trans-unit id="9f00bf6687c043d2091a7a6b17f2dcc072382a50" translate="yes" xml:space="preserve">
          <source>The components of the resulting element will have an additional outer dimension, which will be &lt;code&gt;batch_size&lt;/code&gt; (or &lt;code&gt;N % batch_size&lt;/code&gt; for the last element if &lt;code&gt;batch_size&lt;/code&gt; does not divide the number of input elements &lt;code&gt;N&lt;/code&gt; evenly and &lt;code&gt;drop_remainder&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;). If your program depends on the batches having the same outer dimension, you should set the &lt;code&gt;drop_remainder&lt;/code&gt; argument to &lt;code&gt;True&lt;/code&gt; to prevent the smaller batch from being produced.</source>
          <target state="translated">결과 요소의 구성 요소에는 추가 외부 치수가 있습니다. 이는 &lt;code&gt;batch_size&lt;/code&gt; 입니다 (또는 &lt;code&gt;batch_size&lt;/code&gt; 가 입력 요소 수 &lt;code&gt;N&lt;/code&gt; 을 균등하게 &lt;code&gt;drop_remainder&lt;/code&gt; 가 &lt;code&gt;False&lt;/code&gt; 인 경우 마지막 요소에 대한 &lt;code&gt;N % batch_size&lt;/code&gt; 입니다 ). 프로그램이 외부 치수가 동일한 배치에 의존 하는 경우 더 작은 배치가 생성되지 않도록 &lt;code&gt;drop_remainder&lt;/code&gt; 인수를 &lt;code&gt;True&lt;/code&gt; 로 설정해야합니다 .</target>
        </trans-unit>
        <trans-unit id="344c73fb9ddb71179637f498f0b34262b87c80b8" translate="yes" xml:space="preserve">
          <source>The compute dtype of this policy, or None if the compute dtype should be inferred from the inputs.</source>
          <target state="translated">이 정책의 계산 dtype 또는 입력에서 계산 dtype을 유추해야하는 경우 None입니다.</target>
        </trans-unit>
        <trans-unit id="205f439cb062a6f6e02604aa48a1bdc6926c8224" translate="yes" xml:space="preserve">
          <source>The compute dtype of this policy.</source>
          <target state="translated">이 정책의 계산 dtype입니다.</target>
        </trans-unit>
        <trans-unit id="4a56e1ae6d24fcbef9729431047071ed9efb2c36" translate="yes" xml:space="preserve">
          <source>The concatenated rows for this ragged tensor.</source>
          <target state="translated">이 울퉁불퉁 한 텐서의 연결된 행입니다.</target>
        </trans-unit>
        <trans-unit id="2e975fea798f7bc222374c880c42a36989a17b66" translate="yes" xml:space="preserve">
          <source>The concatenated values for all rows in this tensor.</source>
          <target state="translated">이 텐서의 모든 행에 연결된 값입니다.</target>
        </trans-unit>
        <trans-unit id="0f6fe2c98e185c3c57a927e557bcc1cd36a6a7d8" translate="yes" xml:space="preserve">
          <source>The concentration parameters represent mean total counts of a &lt;code&gt;1&lt;/code&gt; or a &lt;code&gt;0&lt;/code&gt;, i.e.,</source>
          <target state="translated">농도 파라미터는 &lt;code&gt;1&lt;/code&gt; 또는 &lt;code&gt;0&lt;/code&gt; 의 평균 총 카운트 , 즉</target>
        </trans-unit>
        <trans-unit id="b10cf771707704e5f421193cabc5bea06bcefd0e" translate="yes" xml:space="preserve">
          <source>The config of a layer does not include connectivity information, nor the layer class name. These are handled by &lt;code&gt;Network&lt;/code&gt; (one layer of abstraction above).</source>
          <target state="translated">계층 구성에는 연결 정보 나 계층 클래스 이름이 포함되지 않습니다. 이것들은 &lt;code&gt;Network&lt;/code&gt; (위의 추상화 계층)에 의해 처리됩니다 .</target>
        </trans-unit>
        <trans-unit id="2e6cabe853a86fe4b25fb9e66ffa23b7c23ff8a8" translate="yes" xml:space="preserve">
          <source>The constraint function that was passed to the variable constructor. Can be &lt;code&gt;None&lt;/code&gt; if no constraint was passed.</source>
          <target state="translated">변수 생성자로 전달 된 제한 조건 함수입니다. 제한 조건이 전달되지 않은 경우 &lt;code&gt;None&lt;/code&gt; 일 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="c73cc83e59c2cc8b75ad073ccf807211d4803200" translate="yes" xml:space="preserve">
          <source>The constraint is validated when flags are initially parsed, and after each change of the corresponding flag's value.</source>
          <target state="translated">제한 조건은 플래그가 처음 구문 분석 될 때 및 해당 플래그 값이 변경 될 때마다 유효성이 검증됩니다.</target>
        </trans-unit>
        <trans-unit id="adc492d7eedfc240429addc422d2a1187a94cf41" translate="yes" xml:space="preserve">
          <source>The constraint is validated when flags are initially parsed, and after each change of the corresponding flag's value. Args: flag_name: str, name of the flag to be checked. checker: callable, a function to validate the flag. input - A single positional argument: The value of the corresponding flag (string, boolean, etc. This value will be passed to checker by the library). output - bool, True if validator constraint is satisfied. If constraint is not satisfied, it should either return False or raise flags.ValidationError(desired_error_message). message: str, error text to be shown to the user if checker returns False. If checker raises flags.ValidationError, message from the raised error will be shown. flag_values: flags.FlagValues, optional FlagValues instance to validate against. Raises: AttributeError: Raised when flag_name is not registered as a valid flag name.</source>
          <target state="translated">제한 조건은 플래그가 처음 구문 분석 될 때 및 해당 플래그 값이 변경 될 때마다 유효성이 검증됩니다. Args : flag_name : str, 검사 할 플래그 이름. 검사기 : 호출 가능, 플래그를 검증하는 함수. input-단일 위치 인수 : 해당 플래그의 값 (문자열, 부울 등).이 값은 라이브러리에 의해 검사기로 전달됩니다. output-bool, 유효성 검사기 제약 조건이 충족되면 True입니다. 제약 조건이 충족되지 않으면 False를 반환하거나 플래그를 발생시켜야합니다 .ValidationError (desired_error_message). 메시지 : str, 검사기가 False를 반환하면 사용자에게 표시되는 오류 텍스트입니다. 검사기가 flags.ValidationError를 발생 시키면 발생한 오류의 메시지가 표시됩니다. flag_values ​​: flags.FlagValues, 검증 할 선택적 FlagValues ​​인스턴스. 발생합니다 : AttributeError :flag_name이 유효한 플래그 이름으로 등록되지 않은 경우 발생합니다.</target>
        </trans-unit>
        <trans-unit id="4dc698ae175b05a09fb4ee349bbc6ecaa1e8c775" translate="yes" xml:space="preserve">
          <source>The constructor adds ops to save and restore variables.</source>
          <target state="translated">생성자는 변수를 저장하고 복원하기 위해 op를 추가합니다.</target>
        </trans-unit>
        <trans-unit id="65be7a0d51d3df0c44e8373ef2d8cce6fba1ba7f" translate="yes" xml:space="preserve">
          <source>The contents of that resource.</source>
          <target state="translated">해당 자원의 내용</target>
        </trans-unit>
        <trans-unit id="b796712e9d45d917e86f476afcbd17188df9e41f" translate="yes" xml:space="preserve">
          <source>The context manager is typically used as follows:</source>
          <target state="translated">컨텍스트 관리자는 일반적으로 다음과 같이 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="b4d7d6dd724445c75543c5c53e6ef9742d69f23b" translate="yes" xml:space="preserve">
          <source>The context manager keeps a reference to the exception as the 'exception' attribute. This allows you to inspect the exception after the assertion::</source>
          <target state="translated">컨텍스트 관리자는 예외에 대한 참조를 '예외'속성으로 유지합니다. 이를 통해 어설 션 후 예외를 검사 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="b36c5f83db5c2031ce81fe755689bacbd226c222" translate="yes" xml:space="preserve">
          <source>The context manager keeps a reference to the first matching warning as the 'warning' attribute; similarly, the 'filename' and 'lineno' attributes give you information about the line of Python code from which the warning was triggered. This allows you to inspect the warning after the assertion::</source>
          <target state="translated">컨텍스트 관리자는 첫 번째 일치 경고를 '경고'속성으로 유지합니다. 마찬가지로 'filename'및 'lineno'속성은 경고가 트리거 된 Python 코드 라인에 대한 정보를 제공합니다. 이를 통해 어설 션 후 경고를 검사 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="3eb98e6489cd882c0c18e1586be464efd5024b02" translate="yes" xml:space="preserve">
          <source>The contracted &lt;code&gt;Tensor&lt;/code&gt;, with shape determined by &lt;code&gt;equation&lt;/code&gt;.</source>
          <target state="translated">계약 &lt;code&gt;Tensor&lt;/code&gt; 와 형상에 의해 결정 &lt;code&gt;equation&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="db43655e2d0d002f7fe5b43dfac52f092c80941c" translate="yes" xml:space="preserve">
          <source>The contrast-adjusted image or images.</source>
          <target state="translated">대비 조정 된 이미지입니다.</target>
        </trans-unit>
        <trans-unit id="d7ed10745c14b330776ee5fc3a5ec88c5d4b915d" translate="yes" xml:space="preserve">
          <source>The contrast-adjusted image(s).</source>
          <target state="translated">대비 조정 된 이미지.</target>
        </trans-unit>
        <trans-unit id="14bfe517dc85759a813f2eb60977041c4d4420dc" translate="yes" xml:space="preserve">
          <source>The conversion function may return &lt;code&gt;NotImplemented&lt;/code&gt; for some inputs. In this case, the conversion process will continue to try subsequent conversion functions.</source>
          <target state="translated">변환 함수는 일부 입력에 대해 &lt;code&gt;NotImplemented&lt;/code&gt; 를 반환 할 수 있습니다 . 이 경우 변환 프로세스는 계속해서 후속 변환 기능을 시도합니다.</target>
        </trans-unit>
        <trans-unit id="993593e7b0bd02f95abe229cbbe58be1069a603a" translate="yes" xml:space="preserve">
          <source>The conversion function must have the following signature:</source>
          <target state="translated">변환 함수에는 다음 서명이 있어야합니다.</target>
        </trans-unit>
        <trans-unit id="62c1d16c5d29bf1d22b745f14080c7842854b090" translate="yes" xml:space="preserve">
          <source>The conversion rules are as follows:</source>
          <target state="translated">변환 규칙은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="e10ca4df9812779b916afce6a1d1c3326adb544f" translate="yes" xml:space="preserve">
          <source>The converted code as string.</source>
          <target state="translated">문자열로 변환 된 코드입니다.</target>
        </trans-unit>
        <trans-unit id="1a4c4fcb504882f83a37ad22c73c28617ce613ed" translate="yes" xml:space="preserve">
          <source>The converted data in serialized format.</source>
          <target state="translated">직렬화 된 형식으로 변환 된 데이터</target>
        </trans-unit>
        <trans-unit id="0f85bd8e5f77e08669b54d651dbd9c3373a46949" translate="yes" xml:space="preserve">
          <source>The converted data in serialized format. Either a TFLite Flatbuffer or a Graphviz graph depending on value in &lt;code&gt;output_format&lt;/code&gt;.</source>
          <target state="translated">직렬화 된 형식으로 변환 된 데이터 &lt;code&gt;output_format&lt;/code&gt; 의 값에 따라 TFLite Flatbuffer 또는 Graphviz 그래프 입니다.</target>
        </trans-unit>
        <trans-unit id="d1373b125f4cfa9b84ebc99ddf4f15c0c28515a5" translate="yes" xml:space="preserve">
          <source>The converted data. For example if TFLite was the destination, then this will be a tflite flatbuffer in a bytes array.</source>
          <target state="translated">변환 된 데이터 예를 들어 TFLite가 대상인 경우 바이트 배열의 tflite 플랫 버퍼가됩니다.</target>
        </trans-unit>
        <trans-unit id="60fb348ae8fb1997effd221344f7a9df143ed5c3" translate="yes" xml:space="preserve">
          <source>The converted grayscale image(s).</source>
          <target state="translated">변환 된 그레이 스케일 이미지.</target>
        </trans-unit>
        <trans-unit id="947c64ff75e26c329d08f9139c4ae882c26c7ee7" translate="yes" xml:space="preserve">
          <source>The copyright for Fashion-MNIST is held by Zalando SE. Fashion-MNIST is licensed under the &lt;a href=&quot;https://github.com/zalandoresearch/fashion-mnist/blob/master/LICENSE&quot;&gt;MIT license&lt;/a&gt;.</source>
          <target state="translated">Fashion-MNIST의 저작권은 Zalando SE가 보유합니다. Fashion-MNIST는 &lt;a href=&quot;https://github.com/zalandoresearch/fashion-mnist/blob/master/LICENSE&quot;&gt;MIT 라이센스에&lt;/a&gt; 따라 라이센스가 부여됩니다 .</target>
        </trans-unit>
        <trans-unit id="1800b9129135de634c28deac11e3c72d5b276b9a" translate="yes" xml:space="preserve">
          <source>The corresponding &lt;code&gt;equation&lt;/code&gt; is:</source>
          <target state="translated">해당 &lt;code&gt;equation&lt;/code&gt; 은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="d08fae5c7558eeecccf8b9086f7da5fad59afff7" translate="yes" xml:space="preserve">
          <source>The corresponding dense tensor satisfies:</source>
          <target state="translated">해당 조밀 한 텐서는 다음을 충족합니다.</target>
        </trans-unit>
        <trans-unit id="25e9a5d7d3994fde2a58974f329ed60d12e01398" translate="yes" xml:space="preserve">
          <source>The covariance between elements in a batch is defined as:</source>
          <target state="translated">배치에서 요소 간 공분산은 다음과 같이 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="3f7c01ee2660f457c23437a997e09405b750c261" translate="yes" xml:space="preserve">
          <source>The covariance for each batch member is defined as the following:</source>
          <target state="translated">각 배치 구성원의 공분산은 다음과 같이 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="ab3d07f930a48f37a430eaef5bc7e0c838a99b3b" translate="yes" xml:space="preserve">
          <source>The created &lt;a href=&quot;../operation&quot;&gt;&lt;code&gt;tf.Operation&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">생성 된 &lt;a href=&quot;../operation&quot;&gt; &lt;code&gt;tf.Operation&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="bf06fef8a51d3d2222f888311b63cf162081ff33" translate="yes" xml:space="preserve">
          <source>The created Operation.</source>
          <target state="translated">생성 된 작업입니다.</target>
        </trans-unit>
        <trans-unit id="bf8da6d42e9abc38af87cab58b26796f2a78e3eb" translate="yes" xml:space="preserve">
          <source>The created or existing &lt;code&gt;Variable&lt;/code&gt; (or &lt;code&gt;PartitionedVariable&lt;/code&gt;, if a partitioner was used).</source>
          <target state="translated">생성되었거나 기존 &lt;code&gt;Variable&lt;/code&gt; (또는 &lt;code&gt;PartitionedVariable&lt;/code&gt; 사용 된 경우 PartitionedVariable )</target>
        </trans-unit>
        <trans-unit id="703c3b3c61be2bbfe2cef58610e4241c0cec208f" translate="yes" xml:space="preserve">
          <source>The created variable. Usually either a &lt;code&gt;Variable&lt;/code&gt; or &lt;code&gt;ResourceVariable&lt;/code&gt; instance. If &lt;code&gt;partitioner&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;, a &lt;code&gt;PartitionedVariable&lt;/code&gt; instance is returned.</source>
          <target state="translated">생성 된 변수 일반적으로 &lt;code&gt;Variable&lt;/code&gt; 또는 &lt;code&gt;ResourceVariable&lt;/code&gt; 인스턴스입니다. 경우 &lt;code&gt;partitioner&lt;/code&gt; 되지 않습니다 &lt;code&gt;None&lt;/code&gt; 하는 &lt;code&gt;PartitionedVariable&lt;/code&gt; 인스턴스가 반환됩니다.</target>
        </trans-unit>
        <trans-unit id="a064f7a86a7da90002c28e35d9ae72e6f6639e8c" translate="yes" xml:space="preserve">
          <source>The creator is supposed to eventually call the next_creator to create a variable if it does want to create a variable and not call Variable or ResourceVariable directly. This helps make creators composable. A creator may choose to create multiple variables, return already existing variables, or simply register that a variable was created and defer to the next creators in line. Creators can also modify the keyword arguments seen by the next creators.</source>
          <target state="translated">변수 또는 ResourceVariable을 직접 호출하지 않고 변수를 작성하려는 경우 작성자는 변수를 작성하기 위해 next_creator를 호출해야합니다. 이렇게하면 제작자가 작곡 할 수 있습니다. 제작자는 여러 변수를 만들거나 기존 변수를 반환하거나 변수가 생성되었음을 등록하고 다음 작성자에게 줄을 지정할 수 있습니다. 제작자는 다음 제작자가 보는 키워드 인수를 수정할 수도 있습니다.</target>
        </trans-unit>
        <trans-unit id="caefb816a5bf9fa47c79fd26eae5407f9e0b0029" translate="yes" xml:space="preserve">
          <source>The cumulative density function (cdf) is,</source>
          <target state="translated">누적 밀도 함수 (cdf)는</target>
        </trans-unit>
        <trans-unit id="1e6cf6bfd84a9de01475c57535a86c638dabf3bb" translate="yes" xml:space="preserve">
          <source>The current &lt;a href=&quot;replicacontext&quot;&gt;&lt;code&gt;tf.distribute.ReplicaContext&lt;/code&gt;&lt;/a&gt; object when in a replica context scope, else &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">현재 &lt;a href=&quot;replicacontext&quot;&gt; &lt;code&gt;tf.distribute.ReplicaContext&lt;/code&gt; 의&lt;/a&gt; 객체 때 복제 상황에 맞는 범위 내에서, 다른 &lt;code&gt;None&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f540e5e4425b87ae1543241ecadb7b9cf3701bab" translate="yes" xml:space="preserve">
          <source>The current &lt;a href=&quot;strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="translated">현재 &lt;a href=&quot;strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; 객체.</target>
        </trans-unit>
        <trans-unit id="7121b0671de74726a9379ae7d9c7f6f65ce0582e" translate="yes" xml:space="preserve">
          <source>The current scope, enabling or disabling compilation.</source>
          <target state="translated">컴파일을 활성화 또는 비활성화하는 현재 범위</target>
        </trans-unit>
        <trans-unit id="f7dbd9f518a88378558ef3aa8f6e9b7c42f12504" translate="yes" xml:space="preserve">
          <source>The data type of this TensorArray.</source>
          <target state="translated">이 TensorArray의 데이터 유형입니다.</target>
        </trans-unit>
        <trans-unit id="a7ba10f144cbc87647590b7009fafb20f1cb2173" translate="yes" xml:space="preserve">
          <source>The data will be looped over (in batches).</source>
          <target state="translated">데이터가 일괄 처리됩니다.</target>
        </trans-unit>
        <trans-unit id="c7f912374554b917dc7b6ee9e848a59b9a0fe71e" translate="yes" xml:space="preserve">
          <source>The datatype of the gradients accumulated by this accumulator.</source>
          <target state="translated">이 누산기에 의해 누적 된 그래디언트의 데이터 유형입니다.</target>
        </trans-unit>
        <trans-unit id="a4e8811eed25239dbc70516d5c5274e75126f7f5" translate="yes" xml:space="preserve">
          <source>The debugging information is dumped to a directory on the file system specified as &lt;code&gt;dump_root&lt;/code&gt;.</source>
          <target state="translated">디버깅 정보는 &lt;code&gt;dump_root&lt;/code&gt; 로 지정된 파일 시스템의 디렉토리에 덤프됩니다 .</target>
        </trans-unit>
        <trans-unit id="af2ff91f6275afef5f274f54f89df6225cefc596" translate="yes" xml:space="preserve">
          <source>The decorated function will return the unbatched computation output Tensors.</source>
          <target state="translated">데코 레이팅 된 함수는 배치되지 않은 계산 출력 텐서를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="6284a54323a552b0a785e97eec39ef3920661508" translate="yes" xml:space="preserve">
          <source>The decorator argument &lt;code&gt;op_type&lt;/code&gt; is the string type of an operation. This corresponds to the &lt;code&gt;OpDef.name&lt;/code&gt; field for the proto that defines the operation.</source>
          <target state="translated">데코레이터 인수 &lt;code&gt;op_type&lt;/code&gt; 은 작업의 문자열 유형입니다. 이는 작업을 정의하는 프로토 타입 의 &lt;code&gt;OpDef.name&lt;/code&gt; 필드에 해당합니다.</target>
        </trans-unit>
        <trans-unit id="f564553c5a97e5c3c841f380324c41f020971604" translate="yes" xml:space="preserve">
          <source>The decorator function must use &lt;code&gt;&amp;lt;decorator name&amp;gt;.__wrapped__&lt;/code&gt; instead of the wrapped function that is normally used:</source>
          <target state="translated">데코레이터 함수 는 일반적으로 사용되는 랩핑 된 함수 대신 &lt;code&gt;&amp;lt;decorator name&amp;gt;.__wrapped__&lt;/code&gt; 를 사용해야합니다.</target>
        </trans-unit>
        <trans-unit id="364632908db2fc42ec644ce9139f9d8cd2996dcc" translate="yes" xml:space="preserve">
          <source>The default &lt;code&gt;Graph&lt;/code&gt; being used in the current thread.</source>
          <target state="translated">현재 스레드에서 사용되는 기본 &lt;code&gt;Graph&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="d6131e418f0fe8f055f5c1a72e6a16e1545b1880" translate="yes" xml:space="preserve">
          <source>The default &lt;code&gt;Session&lt;/code&gt; being used in the current thread.</source>
          <target state="translated">현재 스레드에서 사용중인 기본 &lt;code&gt;Session&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="1f66d887de726d32ad140fa1257a1df52151a3df" translate="yes" xml:space="preserve">
          <source>The default &lt;code&gt;atol&lt;/code&gt; and &lt;code&gt;rtol&lt;/code&gt; is &lt;code&gt;10 * eps&lt;/code&gt;, where &lt;code&gt;eps&lt;/code&gt; is the smallest representable positive number such that &lt;code&gt;1 + eps != 1&lt;/code&gt;. This is about &lt;code&gt;1.2e-6&lt;/code&gt; in &lt;code&gt;32bit&lt;/code&gt;, &lt;code&gt;2.22e-15&lt;/code&gt; in &lt;code&gt;64bit&lt;/code&gt;, and &lt;code&gt;0.00977&lt;/code&gt; in &lt;code&gt;16bit&lt;/code&gt;. See &lt;code&gt;numpy.finfo&lt;/code&gt;.</source>
          <target state="translated">기본 &lt;code&gt;atol&lt;/code&gt; 및 &lt;code&gt;rtol&lt;/code&gt; 은 &lt;code&gt;10 * eps&lt;/code&gt; . 여기서 &lt;code&gt;eps&lt;/code&gt; 는 &lt;code&gt;1 + eps != 1&lt;/code&gt; 과 같이 표시 가능한 가장 작은 양수 입니다. 이것은 관한 &lt;code&gt;1.2e-6&lt;/code&gt; 에서 &lt;code&gt;32bit&lt;/code&gt; , &lt;code&gt;2.22e-15&lt;/code&gt; 의 &lt;code&gt;64bit&lt;/code&gt; 및 &lt;code&gt;0.00977&lt;/code&gt; 에서 &lt;code&gt;16bit&lt;/code&gt; . &lt;code&gt;numpy.finfo&lt;/code&gt; 를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="62dd8de847ac23e7ac8e6762e2b31102b93ee7ae" translate="yes" xml:space="preserve">
          <source>The default Scaffold local init op.</source>
          <target state="translated">기본 스캐 폴드 로컬 초기화 옵션입니다.</target>
        </trans-unit>
        <trans-unit id="113557875e0d10c0495e5968c62aac634844babc" translate="yes" xml:space="preserve">
          <source>The default graph is a property of the current thread. If you create a new thread, and wish to use the default graph in that thread, you must explicitly add a &lt;code&gt;with g.as_default():&lt;/code&gt; in that thread's function.</source>
          <target state="translated">기본 그래프는 현재 스레드의 속성입니다. 새 스레드를 작성하고 해당 스레드에서 기본 그래프를 사용하려는 경우 해당 스레드 함수에서 &lt;code&gt;with g.as_default():&lt;/code&gt; 를 명시 적으로 추가해야합니다 .</target>
        </trans-unit>
        <trans-unit id="b3c4fe416ddd6e4cf097d426615758d9e0a2f0da" translate="yes" xml:space="preserve">
          <source>The default non-peephole implementation is based on:</source>
          <target state="translated">peepohole이 아닌 기본 구현은 다음을 기반으로합니다.</target>
        </trans-unit>
        <trans-unit id="b36d1ca5df94e6636114077cb6330c3dd4eb155f" translate="yes" xml:space="preserve">
          <source>The default type of the returned tensor is &lt;code&gt;'int32'&lt;/code&gt; to match TensorFlow's default.</source>
          <target state="translated">반환 된 텐서의 기본 유형은 &lt;code&gt;'int32'&lt;/code&gt; 이며 TensorFlow의 기본값과 일치합니다.</target>
        </trans-unit>
        <trans-unit id="9c204a6e1f3b1ac9d5e05754cf3c4c6bfcbf5ab6" translate="yes" xml:space="preserve">
          <source>The default value may be either a single value or an iterable of values. A single value is transformed into a single-item list of that value.</source>
          <target state="translated">기본값은 단일 값이거나 반복 가능한 값일 수 있습니다. 단일 값은 해당 값의 단일 항목 목록으로 변환됩니다.</target>
        </trans-unit>
        <trans-unit id="2676c22d8481d2093eb1222e6a62c6e07d9d33bd" translate="yes" xml:space="preserve">
          <source>The default value of 1e-7 for epsilon might not be a good default in general. For example, when training an Inception network on ImageNet a current good choice is 1.0 or 0.1. Note that since AdamOptimizer uses the formulation just before Section 2.1 of the Kingma and Ba paper rather than the formulation in Algorithm 1, the &quot;epsilon&quot; referred to here is &quot;epsilon hat&quot; in the paper.</source>
          <target state="translated">epsilon의 기본값 1e-7은 일반적으로 좋지 않습니다. 예를 들어 ImageNet에서 Inception 네트워크를 교육 할 때 현재 좋은 선택은 1.0 또는 0.1입니다. AdamOptimizer는 알고리즘 1의 공식이 아닌 Kingma 및 Ba 논문의 2.1 절 바로 앞의 공식을 사용하므로 여기서 언급 된 &quot;엡실론&quot;은 논문에서 &quot;엡실론 모자&quot;입니다.</target>
        </trans-unit>
        <trans-unit id="7dce55634f5d3cd5afd750385d4cb7a72c3b4e6e" translate="yes" xml:space="preserve">
          <source>The default value of 1e-8 for epsilon might not be a good default in general. For example, when training an Inception network on ImageNet a current good choice is 1.0 or 0.1. Note that since AdamOptimizer uses the formulation just before Section 2.1 of the Kingma and Ba paper rather than the formulation in Algorithm 1, the &quot;epsilon&quot; referred to here is &quot;epsilon hat&quot; in the paper.</source>
          <target state="translated">epsilon의 기본값 1e-8은 일반적으로 좋지 않습니다. 예를 들어 ImageNet에서 Inception 네트워크를 교육 할 때 현재 좋은 선택은 1.0 또는 0.1입니다. AdamOptimizer는 알고리즘 1의 공식이 아닌 Kingma 및 Ba 논문의 2.1 절 바로 앞의 공식을 사용하므로 여기서 언급 된 &quot;엡실론&quot;은 논문에서 &quot;엡실론 모자&quot;입니다.</target>
        </trans-unit>
        <trans-unit id="615a8ce189d67deb5b00de2e039f587d13916340" translate="yes" xml:space="preserve">
          <source>The default value of the table.</source>
          <target state="translated">테이블의 기본값입니다.</target>
        </trans-unit>
        <trans-unit id="726ed70f0dc33ddfe7a4cc805d63238531bb85eb" translate="yes" xml:space="preserve">
          <source>The dense tensor &lt;code&gt;dense&lt;/code&gt; represented by an &lt;code&gt;IndexedSlices&lt;/code&gt;&lt;code&gt;slices&lt;/code&gt; has</source>
          <target state="translated">&lt;code&gt;IndexedSlices&lt;/code&gt; &lt;code&gt;slices&lt;/code&gt; 표시되는 밀도 텐서 &lt;code&gt;dense&lt;/code&gt; 는</target>
        </trans-unit>
        <trans-unit id="4266ae52077c5b23e390601d308e04d84d60ebbe" translate="yes" xml:space="preserve">
          <source>The deprecated &quot;infer&quot; policy</source>
          <target state="translated">더 이상 사용되지 않는 &quot;추론&quot;정책</target>
        </trans-unit>
        <trans-unit id="47a704b6d6ba8a557d500ba37d0cbd25291c9ff6" translate="yes" xml:space="preserve">
          <source>The depth depends on profiling view. For 'scope' view, it's the depth of name scope hierarchy (tree), for 'op' view, it's the number of operation types (list), etc.</source>
          <target state="translated">깊이는 프로파일 링보기에 따라 다릅니다. '범위'보기의 경우 이름 범위 계층 구조 (트리)의 깊이이고 'op'보기의 경우 작업 유형 (목록)의 수 등입니다.</target>
        </trans-unit>
        <trans-unit id="2137c8c00ab29126bb362981cb4aca8aa9eecd42" translate="yes" xml:space="preserve">
          <source>The depth of the input tensor must be divisible by &lt;code&gt;block_size * block_size&lt;/code&gt;.</source>
          <target state="translated">입력 텐서의 깊이는 &lt;code&gt;block_size * block_size&lt;/code&gt; 로 나눌 수 있어야합니다 .</target>
        </trans-unit>
        <trans-unit id="856f925406c2e2660e650087c5e577d9ef121b34" translate="yes" xml:space="preserve">
          <source>The depth of the output tensor is &lt;code&gt;block_size * block_size * input_depth&lt;/code&gt;.</source>
          <target state="translated">출력 텐서의 깊이는 &lt;code&gt;block_size * block_size * input_depth&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="56afabb9b384a9ae87fad18ee9dbf3881d1ccc16" translate="yes" xml:space="preserve">
          <source>The device of this variable.</source>
          <target state="translated">이 변수의 장치.</target>
        </trans-unit>
        <trans-unit id="98f163e49909ba226b86dab21a009212ea93fb62" translate="yes" xml:space="preserve">
          <source>The device policy controls how operations requiring inputs on a specific device (e.g., on GPU:0) handle inputs on a different device (e.g. GPU:1).</source>
          <target state="translated">장치 정책은 특정 장치 (예 : GPU : 0)에서 입력이 필요한 작업이 다른 장치 (예 : GPU : 1)에서 입력을 처리하는 방법을 제어합니다.</target>
        </trans-unit>
        <trans-unit id="f251515ee7a7da78599205d7a6518a062a6c0f5e" translate="yes" xml:space="preserve">
          <source>The devices this replica is to be executed on, as a tuple of strings.</source>
          <target state="translated">이 복제본을 실행할 장치는 튜플 문자열입니다.</target>
        </trans-unit>
        <trans-unit id="87dd79764107968d1c698ee175a895a731232435" translate="yes" xml:space="preserve">
          <source>The difference between &lt;code&gt;stack&lt;/code&gt; and &lt;code&gt;parallel_stack&lt;/code&gt; is that &lt;code&gt;stack&lt;/code&gt; requires all the inputs be computed before the operation will begin but doesn't require that the input shapes be known during graph construction.</source>
          <target state="translated">차이 &lt;code&gt;stack&lt;/code&gt; 과 &lt;code&gt;parallel_stack&lt;/code&gt; 은 즉 &lt;code&gt;stack&lt;/code&gt; 동작을 시작하기 전에 모든 입력이 계산 될 필요하지만, 입력 도형을 그래프 구조 중에 공지 될 것을 요구하지 않는다.</target>
        </trans-unit>
        <trans-unit id="a741b7f6b1d2304d511eed765b55f2d892e70b1b" translate="yes" xml:space="preserve">
          <source>The dimensions in &lt;code&gt;self&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt; are merged elementwise, according to the rules defined for &lt;code&gt;Dimension.merge_with()&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;Dimension.merge_with()&lt;/code&gt; 대해 정의 된 규칙에 따라 &lt;code&gt;self&lt;/code&gt; 및 &lt;code&gt;other&lt;/code&gt; 차원 이 요소 단위로 병합 됩니다.</target>
        </trans-unit>
        <trans-unit id="7bc7db80b0d2774479326226a4890a6e2d843629" translate="yes" xml:space="preserve">
          <source>The directory as string.</source>
          <target state="translated">문자열 인 디렉토리.</target>
        </trans-unit>
        <trans-unit id="8f003820357db00c0553228e9493dca5bc931d2d" translate="yes" xml:space="preserve">
          <source>The directory where files specified in data attribute of py_test and py_binary are stored.</source>
          <target state="translated">py_test 및 py_binary의 data 속성에 지정된 파일이 저장되는 디렉토리입니다.</target>
        </trans-unit>
        <trans-unit id="3b7ccc3fd24de1a06b23a805fbbf6bc02487c531" translate="yes" xml:space="preserve">
          <source>The distances from each input point to each cluster center.</source>
          <target state="translated">각 입력 지점에서 각 클러스터 중심까지의 거리입니다.</target>
        </trans-unit>
        <trans-unit id="5f58b91125c882dc2a62587a652492f254f94698" translate="yes" xml:space="preserve">
          <source>The distribution functions can be evaluated on counts.</source>
          <target state="translated">분포 함수는 카운트로 평가할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7b6104158da73f015822f02cd6abbe4e2cf5c6cf" translate="yes" xml:space="preserve">
          <source>The distribution strategy options associated with the dataset. See &lt;a href=&quot;experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">데이터 세트와 관련된 배포 전략 옵션. 자세한 내용은 &lt;a href=&quot;experimental/distributeoptions&quot;&gt; &lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt; &lt;/a&gt; 를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="bf743a144dc0600d6b32b4a4db31e72e8fcd7021" translate="yes" xml:space="preserve">
          <source>The distributions have degree of freedom &lt;code&gt;df&lt;/code&gt;, mean &lt;code&gt;loc&lt;/code&gt;, and scale &lt;code&gt;scale&lt;/code&gt;.</source>
          <target state="translated">분포는 자유도 &lt;code&gt;df&lt;/code&gt; , 평균 위치 및 스케일 &lt;code&gt;scale&lt;/code&gt; &lt;code&gt;loc&lt;/code&gt; 집니다.</target>
        </trans-unit>
        <trans-unit id="2de0b5493fea7bb1bb4b3e017251bece76051fd5" translate="yes" xml:space="preserve">
          <source>The drawn samples of shape &lt;code&gt;[batch_size, num_samples]&lt;/code&gt;.</source>
          <target state="translated">모양이 그려진 샘플 &lt;code&gt;[batch_size, num_samples]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="bd52ea2eb7ea5be6e405a118979acc052f206e1b" translate="yes" xml:space="preserve">
          <source>The dtype of the resulting tensor is inferred from the inputs unless it is provided explicitly.</source>
          <target state="translated">결과 텐서의 dtype은 명시 적으로 제공되지 않는 한 입력에서 유추됩니다.</target>
        </trans-unit>
        <trans-unit id="4b69591d001104f8e2eec546d13dfde13802ef40" translate="yes" xml:space="preserve">
          <source>The dumped debugging information can be ingested by debugger UIs.</source>
          <target state="translated">덤프 된 디버깅 정보는 디버거 UI에서 수집 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="1c3bb311f55c44615e851ca1393dedf962117d6f" translate="yes" xml:space="preserve">
          <source>The dynamic calculation performed is, at time &lt;code&gt;t&lt;/code&gt; for batch row &lt;code&gt;b&lt;/code&gt;,</source>
          <target state="translated">수행 된 동적 계산은 배치 행 &lt;code&gt;b&lt;/code&gt; 의 시간 &lt;code&gt;t&lt;/code&gt; 에서</target>
        </trans-unit>
        <trans-unit id="2aae6b9d4f5b2d213b88b3723da3ddb26ced9416" translate="yes" xml:space="preserve">
          <source>The effective spatial dimensions of the zero-padded input tensor will be:</source>
          <target state="translated">제로 패딩 입력 텐서의 유효 공간 치수는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="b9acfbbdfe245ea88de02f1a818fe0b504d8ee2c" translate="yes" xml:space="preserve">
          <source>The eigenvalues and eigenvectors for a non-Hermitian matrix in general are complex. The eigenvectors are not guaranteed to be linearly independent.</source>
          <target state="translated">비 -Hermitian 행렬에 대한 고유 값과 고유 벡터는 일반적으로 복잡합니다. 고유 벡터는 선형 독립성을 보장하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="ee408bc36c08a8eb79de0b041ba288a43ece416b" translate="yes" xml:space="preserve">
          <source>The element-wise value of the x divided by y.</source>
          <target state="translated">x의 요소 별 값을 y로 나눈 값입니다.</target>
        </trans-unit>
        <trans-unit id="ee6f05fbd02c64e68c12a5dd5234049b70dd5c18" translate="yes" xml:space="preserve">
          <source>The element-wise value of the x times y.</source>
          <target state="translated">x의 요소 별 값에 y를 곱한 값입니다.</target>
        </trans-unit>
        <trans-unit id="5056d7193c98ed08aca24d8fed6317ade12de9af" translate="yes" xml:space="preserve">
          <source>The elements are shifted positively (towards larger indices) by the offset of &lt;code&gt;shift&lt;/code&gt; along the dimension of &lt;code&gt;axis&lt;/code&gt;. Negative &lt;code&gt;shift&lt;/code&gt; values will shift elements in the opposite direction. Elements that roll passed the last position will wrap around to the first and vice versa. Multiple shifts along multiple axes may be specified.</source>
          <target state="translated">&lt;code&gt;axis&lt;/code&gt; 치수를 따라 &lt;code&gt;shift&lt;/code&gt; 오프셋에 의해 요소가 양의 방향으로 (더 큰 인덱스를 향해) 이동 됩니다 . 음수 &lt;code&gt;shift&lt;/code&gt; 값은 요소를 반대 방향으로 이동시킵니다. 마지막 위치를 통과 한 롤은 첫 번째 위치로 감싸고 그 반대도 마찬가지입니다. 여러 축을 따라 여러 이동을 지정할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="c40643e8152d969c58abd0946b228718afbfd024" translate="yes" xml:space="preserve">
          <source>The elements in &lt;code&gt;input&lt;/code&gt; are considered to be complex numbers of the form \(a + bj\), where &lt;em&gt;a&lt;/em&gt; is the real part and &lt;em&gt;b&lt;/em&gt; is the imaginary part. If &lt;code&gt;input&lt;/code&gt; is real then &lt;em&gt;b&lt;/em&gt; is zero by definition.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 요소는 \ (a + bj \) 형식의 복소수로 간주됩니다. 여기서 &lt;em&gt;a&lt;/em&gt; 는 실수 부이고 &lt;em&gt;b&lt;/em&gt; 는 허수 부입니다. 경우 &lt;code&gt;input&lt;/code&gt; 진짜 후이고 &lt;em&gt;B는&lt;/em&gt; 정의에 의해 제로이다.</target>
        </trans-unit>
        <trans-unit id="bd6b82f2a01c27554a110fc1c60a8688cc656c5b" translate="yes" xml:space="preserve">
          <source>The elements of &lt;code&gt;result&lt;/code&gt; will be:</source>
          <target state="translated">&lt;code&gt;result&lt;/code&gt; 의 요소 는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="7e5122262788d16dcc2a476a1ccd5d94e319a27e" translate="yes" xml:space="preserve">
          <source>The elements of &lt;code&gt;sampled_candidates&lt;/code&gt; are drawn without replacement (if &lt;code&gt;unique=True&lt;/code&gt;) or with replacement (if &lt;code&gt;unique=False&lt;/code&gt;) from the base distribution.</source>
          <target state="translated">&lt;code&gt;sampled_candidates&lt;/code&gt; 의 요소 는 기본 분포에서 교체하지 않고 ( &lt;code&gt;unique=True&lt;/code&gt; 인 경우 ) 또는 교체 ( &lt;code&gt;unique=False&lt;/code&gt; 인 경우 )로 가져옵니다.</target>
        </trans-unit>
        <trans-unit id="48ab33f1524aaeaed08c07c88c40746479f023b7" translate="yes" xml:space="preserve">
          <source>The elements of &lt;code&gt;seq_lengths&lt;/code&gt; must obey &lt;code&gt;seq_lengths[i] &amp;lt;= input.dims[seq_dim]&lt;/code&gt;, and &lt;code&gt;seq_lengths&lt;/code&gt; must be a vector of length &lt;code&gt;input.dims[batch_dim]&lt;/code&gt;.</source>
          <target state="translated">의 요소 &lt;code&gt;seq_lengths&lt;/code&gt; 가 따라야 &lt;code&gt;seq_lengths[i] &amp;lt;= input.dims[seq_dim]&lt;/code&gt; 및 &lt;code&gt;seq_lengths&lt;/code&gt; 는 길이의 벡터이어야 &lt;code&gt;input.dims[batch_dim]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="39f08dabb4ebd036182bf4e154d99641a60b1bde" translate="yes" xml:space="preserve">
          <source>The elements of the dataset must be scalar strings. To serialize dataset elements as strings, you can use the &lt;a href=&quot;../../io/serialize_tensor&quot;&gt;&lt;code&gt;tf.io.serialize_tensor&lt;/code&gt;&lt;/a&gt; function.</source>
          <target state="translated">데이터 세트의 요소는 스칼라 문자열이어야합니다. 데이터 세트 요소를 문자열로 직렬화하기 위해 &lt;a href=&quot;../../io/serialize_tensor&quot;&gt; &lt;code&gt;tf.io.serialize_tensor&lt;/code&gt; &lt;/a&gt; 함수를 사용할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="3650e19170e124ae92368cff21395feb363f4884" translate="yes" xml:space="preserve">
          <source>The elements of this dataset correspond to records from the file(s). RFC 4180 format is expected for CSV files (https://tools.ietf.org/html/rfc4180) Note that we allow leading and trailing spaces with int or float field.</source>
          <target state="translated">이 데이터 세트의 요소는 파일의 레코드에 해당합니다. CSV 파일에는 RFC 4180 형식이 필요합니다 (https://tools.ietf.org/html/rfc4180) int 또는 float 필드를 사용하여 선행 및 후행 공백을 허용합니다.</target>
        </trans-unit>
        <trans-unit id="c3aeafaf8f36325e7f515de971621d719406107b" translate="yes" xml:space="preserve">
          <source>The end result is that if the input is marked as an explicit endianness the transcoding is faithful to all codepoints in the source. If it is not marked with an explicit endianness, the BOM is not considered part of the string itself but as metadata, and so is not preserved in the output.</source>
          <target state="translated">최종 결과는 입력이 명시 적 엔디안으로 표시되면 트랜스 코딩이 소스의 모든 코드 포인트에 충실하다는 것입니다. 명시 적 엔디안으로 표시되지 않은 경우 BOM은 문자열 자체의 일부가 아니라 메타 데이터로 간주되므로 출력에 유지되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="a7d3c35f0e85c1a6bf781b776ea72d3b7217b57e" translate="yes" xml:space="preserve">
          <source>The entire Python program exits when no alive non-daemon threads are left.</source>
          <target state="translated">살아있는 비 데몬 스레드가 남아 있지 않으면 전체 Python 프로그램이 종료됩니다.</target>
        </trans-unit>
        <trans-unit id="fcab26b6f1d2bad63f4beb447401d7b8916bee05" translate="yes" xml:space="preserve">
          <source>The entire optimizer is currently thread compatible, not thread-safe. The user needs to perform synchronization if necessary.</source>
          <target state="translated">전체 옵티마이 저는 현재 스레드 안전이 아니라 스레드 호환 가능합니다. 필요한 경우 사용자는 동기화를 수행해야합니다.</target>
        </trans-unit>
        <trans-unit id="c33387bb265f08d2eccc0ee4964677edfa18dfee" translate="yes" xml:space="preserve">
          <source>The error message that describes the error.</source>
          <target state="translated">오류를 설명하는 오류 메시지입니다.</target>
        </trans-unit>
        <trans-unit id="3992d2c2ef24613a2edd3a09184b92d4f6c82dcc" translate="yes" xml:space="preserve">
          <source>The estimator uses a user-specified head.</source>
          <target state="translated">추정기는 사용자 지정 헤드를 사용합니다.</target>
        </trans-unit>
        <trans-unit id="c0f4a9f9118713f2c65753167fbc45edc83681df" translate="yes" xml:space="preserve">
          <source>The event shape and the batch shape are properties of a Distribution object, whereas the sample shape is associated with a specific call to &lt;code&gt;sample&lt;/code&gt; or &lt;code&gt;log_prob&lt;/code&gt;.</source>
          <target state="translated">이벤트 셰이프 및 배치 셰이프는 Distribution 객체의 속성 인 반면 샘플 셰이프는 &lt;code&gt;sample&lt;/code&gt; 또는 &lt;code&gt;log_prob&lt;/code&gt; 에 대한 특정 호출과 연결됩니다 .</target>
        </trans-unit>
        <trans-unit id="d89bb90670419b9d3a4b50ee4e20b8624c955245" translate="yes" xml:space="preserve">
          <source>The example has two variables containing parameters, &lt;code&gt;dense.kernel&lt;/code&gt; (2 parameters) and &lt;code&gt;dense.bias&lt;/code&gt; (1 parameter). Considering the training data &lt;code&gt;x&lt;/code&gt; as a constant, this means the Jacobian matrix for the function mapping from parameters to loss has one row and three columns.</source>
          <target state="translated">이 예에는 &lt;code&gt;dense.kernel&lt;/code&gt; (2 개의 매개 변수) 및 &lt;code&gt;dense.bias&lt;/code&gt; (1 개의 매개 변수) 매개 변수가 포함 된 두 개의 변수가 있습니다. 훈련 데이터 &lt;code&gt;x&lt;/code&gt; 를 상수로 고려하면 , 이는 매개 변수에서 손실로의 함수 맵핑을위한 Jacobian 행렬이 1 행 3 열임을 의미합니다.</target>
        </trans-unit>
        <trans-unit id="84c18ab207b5195ffc68356ad590594bcf1dfa71" translate="yes" xml:space="preserve">
          <source>The examples below are for the case when only indices have leading extra dimensions. If both 'params' and 'indices' have leading batch dimensions, use the 'batch_dims' parameter to run gather_nd in batch mode.</source>
          <target state="translated">아래의 예는 지수에만 추가 치수가있는 경우를위한 것입니다. 'params'및 'indices'둘 다 선행 배치 차원을 갖는 경우 'batch_dims'매개 변수를 사용하여 배치 모드에서 gather_nd를 실행하십시오.</target>
        </trans-unit>
        <trans-unit id="78ad8b1f8ab153e6768481eb32292aa26fa61403" translate="yes" xml:space="preserve">
          <source>The expected output of its iterations is:</source>
          <target state="translated">반복의 예상 출력은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="7a97b08c68384c6b725f7994e4ae0a05ba85ecb6" translate="yes" xml:space="preserve">
          <source>The expected return values are: features: A &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string or int to &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt;, specifying the features to be passed to the model. Note: if &lt;code&gt;features&lt;/code&gt; passed is not a dict, it will be wrapped in a dict with a single entry, using 'feature' as the key. Consequently, the model must accept a feature dict of the form {'feature': tensor}. You may use &lt;code&gt;TensorServingInputReceiver&lt;/code&gt; if you want the tensor to be passed as is. receiver_tensors: A &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string to &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt;, specifying input nodes where this receiver expects to be fed by default. Typically, this is a single placeholder expecting serialized &lt;code&gt;tf.Example&lt;/code&gt; protos. receiver_tensors_alternatives: a dict of string to additional groups of receiver tensors, each of which may be a &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string to &lt;code&gt;Tensor&lt;/code&gt; or&lt;code&gt;SparseTensor&lt;/code&gt;. These named receiver tensor alternatives generate additional serving signatures, which may be used to feed inputs at different points within the input receiver subgraph. A typical usage is to allow feeding raw feature &lt;code&gt;Tensor&lt;/code&gt;s &lt;em&gt;downstream&lt;/em&gt; of the tf.parse_example() op. Defaults to None.</source>
          <target state="translated">예상되는 반환 값은 다음과 같습니다. features : &lt;code&gt;Tensor&lt;/code&gt; , &lt;code&gt;SparseTensor&lt;/code&gt; , 또는 string 또는 int dict to &lt;code&gt;Tensor&lt;/code&gt; 또는 &lt;code&gt;SparseTensor&lt;/code&gt; 로 모델에 전달할 기능을 지정합니다. 참고 : 전달 된 &lt;code&gt;features&lt;/code&gt; 이 dict이 아닌 경우 'feature'를 키로 사용하여 단일 항목으로 dict에 래핑됩니다. 결과적으로 모델은 { 'feature': tensor} 형식의 지형 지법을 받아 들여야합니다. 텐서를 그대로 전달 하려면 &lt;code&gt;TensorServingInputReceiver&lt;/code&gt; 를 사용할 수 있습니다 . receiver_tensors : &lt;code&gt;Tensor&lt;/code&gt; , &lt;code&gt;SparseTensor&lt;/code&gt; 또는 &lt;code&gt;Tensor&lt;/code&gt; 또는 &lt;code&gt;SparseTensor&lt;/code&gt; 에 대한 문자열 dict이 수신기가 기본적으로 공급 될 것으로 예상되는 입력 노드를 지정합니다. 일반적으로 이것은 직렬화 된 &lt;code&gt;tf.Example&lt;/code&gt; 프로토 타입을 기대하는 단일 자리 표시 자 입니다. receiver_tensors_alternatives : 추가 그룹의 수신자 텐서에 대한 문자열 dict, 각각 &lt;code&gt;Tensor&lt;/code&gt; , &lt;code&gt;SparseTensor&lt;/code&gt; , 또는 문자열이 &lt;code&gt;Tensor&lt;/code&gt; 또는 &lt;code&gt;SparseTensor&lt;/code&gt; 일 수 있습니다. 이러한 명명 된 수신기 텐서 대안은 추가 서빙 서명을 생성하는데, 이는 입력 수신기 서브 그래프 내의 다른 지점에서 입력을 공급하는데 사용될 수있다. 일반적인 사용법은 tf.parse_example () op 의 &lt;em&gt;다운 스트림&lt;/em&gt; 에 원시 기능 &lt;code&gt;Tensor&lt;/code&gt; 를 공급 하는 것입니다. 기본값은 없음입니다.&lt;em&gt;&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="31f7e12f63f032ea1d264ce969a77506eba82800" translate="yes" xml:space="preserve">
          <source>The expected return values are: features: A single &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt;, representing the feature to be passed to the model. receiver_tensors: A &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string to &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt;, specifying input nodes where this receiver expects to be fed by default. Typically, this is a single placeholder expecting serialized &lt;code&gt;tf.Example&lt;/code&gt; protos. receiver_tensors_alternatives: a dict of string to additional groups of receiver tensors, each of which may be a &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string to &lt;code&gt;Tensor&lt;/code&gt; or&lt;code&gt;SparseTensor&lt;/code&gt;. These named receiver tensor alternatives generate additional serving signatures, which may be used to feed inputs at different points within the input receiver subgraph. A typical usage is to allow feeding raw feature &lt;code&gt;Tensor&lt;/code&gt;s &lt;em&gt;downstream&lt;/em&gt; of the tf.parse_example() op. Defaults to None.</source>
          <target state="translated">예상되는 반환 값은 다음과 같습니다. features : 단일 &lt;code&gt;Tensor&lt;/code&gt; 또는 &lt;code&gt;SparseTensor&lt;/code&gt; . 모델에 전달할 기능을 나타냅니다. receiver_tensors : &lt;code&gt;Tensor&lt;/code&gt; , &lt;code&gt;SparseTensor&lt;/code&gt; , 또는 &lt;code&gt;Tensor&lt;/code&gt; 또는 &lt;code&gt;SparseTensor&lt;/code&gt; 에 대한 문자열 dict .이 수신기가 기본적으로 공급 될 것으로 예상되는 입력 노드를 지정합니다. 일반적으로 이것은 직렬화 된 &lt;code&gt;tf.Example&lt;/code&gt; 프로토 타입을 기대하는 단일 자리 표시 자 입니다. receiver_tensors_alternatives : 추가 그룹의 수신자 텐서에 대한 문자열 dict, 각각 &lt;code&gt;Tensor&lt;/code&gt; , &lt;code&gt;SparseTensor&lt;/code&gt; , 또는 문자열이 &lt;code&gt;Tensor&lt;/code&gt; 또는 &lt;code&gt;SparseTensor&lt;/code&gt; 일 수 있음. 이러한 명명 된 수신기 텐서 대안은 추가 서빙 서명을 생성하는데, 이는 입력 수신기 서브 그래프 내의 다른 지점에서 입력을 공급하는데 사용될 수있다. 일반적인 사용법은 tf.parse_example () op 의 &lt;em&gt;다운 스트림&lt;/em&gt; 에 원시 기능 &lt;code&gt;Tensor&lt;/code&gt; 를 공급 하는 것입니다. 기본값은 없음입니다.&lt;em&gt;&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="a40612bf469e8a522446e66d41d431047e69cf63" translate="yes" xml:space="preserve">
          <source>The expected size of the &lt;code&gt;logits&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;logits&lt;/code&gt; 텐서 의 예상 크기입니다 .</target>
        </trans-unit>
        <trans-unit id="a0f440ff029659182acbea8855f46dd42d2a4e96" translate="yes" xml:space="preserve">
          <source>The expected table key dtype.</source>
          <target state="translated">예상 테이블 키 dtype입니다.</target>
        </trans-unit>
        <trans-unit id="31bcecc626aa91dd2b7d91005cf6117e6bde9f72" translate="yes" xml:space="preserve">
          <source>The expected table value dtype.</source>
          <target state="translated">예상 테이블 값 dtype입니다.</target>
        </trans-unit>
        <trans-unit id="ce7ef07c28defdcd9df2cbeda8fcff1eb3a70cf0" translate="yes" xml:space="preserve">
          <source>The expected values are &lt;a href=&quot;../../../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../../sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.SparseTensor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">예상되는 값은 &lt;a href=&quot;../../../tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;../../../sparse/sparsetensor&quot;&gt; &lt;code&gt;tf.SparseTensor&lt;/code&gt; &lt;/a&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="dec1b3abe2b21793505b8807293f4669331e6f37" translate="yes" xml:space="preserve">
          <source>The experimental_mode parameter can be used to export a single train/eval/predict graph as a &lt;code&gt;SavedModel&lt;/code&gt;. See &lt;code&gt;experimental_export_all_saved_models&lt;/code&gt; for full docs.</source>
          <target state="translated">Experiment_mode 매개 변수를 사용하여 단일 train / eval / predict 그래프를 &lt;code&gt;SavedModel&lt;/code&gt; 로 내보낼 수 있습니다 . 전체 문서는 &lt;code&gt;experimental_export_all_saved_models&lt;/code&gt; 를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="7605e2fe49cffe7e518a9ae0d1ab56de778f3211" translate="yes" xml:space="preserve">
          <source>The exponential is computed using a combination of the scaling and squaring method and the Pade approximation. Details can be found in: Nicholas J. Higham, &quot;The scaling and squaring method for the matrix exponential revisited,&quot; SIAM J. Matrix Anal. Applic., 26:1179-1193, 2005.</source>
          <target state="translated">지수는 스케일링 및 제곱 방법과 Pade 근사값의 조합을 사용하여 계산됩니다. 자세한 내용은 다음을 참조하십시오. Nicholas J. Higham, &quot;매트릭스 지수 재검토를위한 스케일링 및 제곱 방법&quot;SIAM J. Matrix Anal. 출원, 26 : 1179-1193, 2005.</target>
        </trans-unit>
        <trans-unit id="4f5a78bc935e9e08409cbf0ad9095df30519c6ba" translate="yes" xml:space="preserve">
          <source>The exponential linear activation: &lt;code&gt;x&lt;/code&gt; if &lt;code&gt;x &amp;gt; 0&lt;/code&gt; and &lt;code&gt;alpha * (exp(x)-1)&lt;/code&gt; if &lt;code&gt;x &amp;lt; 0&lt;/code&gt;.</source>
          <target state="translated">지수 선형 활성화 : &lt;code&gt;x&lt;/code&gt; 경우 &lt;code&gt;x &amp;gt; 0&lt;/code&gt; 과 &lt;code&gt;alpha * (exp(x)-1)&lt;/code&gt; 의 경우 &lt;code&gt;x &amp;lt; 0&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6a8c6448917add778eb240e31bd6ab87cce7e676" translate="yes" xml:space="preserve">
          <source>The exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;../../../../estimator/export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="translated">내 보낸 &lt;code&gt;MetaGraphDef&lt;/code&gt; 는 하나 제공 &lt;code&gt;SignatureDef&lt;/code&gt; 을 의 각 요소에 대해 &lt;code&gt;export_outputs&lt;/code&gt; 으로부터 반환 DICT &lt;code&gt;model_fn&lt;/code&gt; 같은 키를 사용하여 명명. 이 키 중 하나는 항상 &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt; 이며, 서빙 요청에서 키를 지정하지 않은 경우 어떤 서명이 제공되는지 나타냅니다. 각 서명에 대해 출력은 해당 &lt;a href=&quot;../../../../estimator/export/exportoutput&quot;&gt; &lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt; 에&lt;/a&gt; 의해 제공되며 입력은 항상 &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; 에 의해 제공되는 입력 수신기 입니다.</target>
        </trans-unit>
        <trans-unit id="9e2875cf5dfc1a19c0a389906972c0cc62d32b4f" translate="yes" xml:space="preserve">
          <source>The exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;../../../estimator/export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="translated">내 보낸 &lt;code&gt;MetaGraphDef&lt;/code&gt; 는 하나 제공 &lt;code&gt;SignatureDef&lt;/code&gt; 을 의 각 요소에 대해 &lt;code&gt;export_outputs&lt;/code&gt; 으로부터 반환 DICT &lt;code&gt;model_fn&lt;/code&gt; 같은 키를 사용하여 명명. 이 키 중 하나는 항상 &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt; 이며, 서빙 요청에서 키를 지정하지 않은 경우 어떤 서명이 제공되는지 나타냅니다. 각 서명에 대해 출력은 해당 &lt;a href=&quot;../../../estimator/export/exportoutput&quot;&gt; &lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt; 에&lt;/a&gt; 의해 제공되며 입력은 항상 &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; 에 의해 제공되는 입력 수신기 입니다.</target>
        </trans-unit>
        <trans-unit id="72c1a65a7779ecfbc3e340268769bc17bef0c731" translate="yes" xml:space="preserve">
          <source>The exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;../export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="translated">내 보낸 &lt;code&gt;MetaGraphDef&lt;/code&gt; 는 하나 제공 &lt;code&gt;SignatureDef&lt;/code&gt; 을 의 각 요소에 대해 &lt;code&gt;export_outputs&lt;/code&gt; 으로부터 반환 DICT &lt;code&gt;model_fn&lt;/code&gt; 같은 키를 사용하여 명명. 이 키 중 하나는 항상 &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt; 이며, 서빙 요청에서 키를 지정하지 않은 경우 어떤 서명이 제공되는지 나타냅니다. 각 서명에 대해 출력은 해당 &lt;a href=&quot;../export/exportoutput&quot;&gt; &lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt; 에&lt;/a&gt; 의해 제공되며 입력은 항상 &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; 에 의해 제공되는 입력 수신기 입니다.</target>
        </trans-unit>
        <trans-unit id="f952c6857d4170532f4c4a40882608ceb9fe6cf5" translate="yes" xml:space="preserve">
          <source>The exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="translated">내 보낸 &lt;code&gt;MetaGraphDef&lt;/code&gt; 는 하나 제공 &lt;code&gt;SignatureDef&lt;/code&gt; 을 의 각 요소에 대해 &lt;code&gt;export_outputs&lt;/code&gt; 으로부터 반환 DICT &lt;code&gt;model_fn&lt;/code&gt; 같은 키를 사용하여 명명. 이 키 중 하나는 항상 &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt; 이며, 서빙 요청에서 키를 지정하지 않은 경우 어떤 서명이 제공되는지 나타냅니다. 각 서명에 대해 출력은 해당 &lt;a href=&quot;export/exportoutput&quot;&gt; &lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt; 에&lt;/a&gt; 의해 제공되며 입력은 항상 &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; 에 의해 제공되는 입력 수신기 입니다.</target>
        </trans-unit>
        <trans-unit id="7d89ddec6391085569ef9d73498cfde0f5e37d2b" translate="yes" xml:space="preserve">
          <source>The exported &lt;code&gt;SavedModel&lt;/code&gt; is a standalone serialization of Tensorflow objects, and is supported by TF language APIs and the Tensorflow Serving system. To load the model, use the function &lt;code&gt;tf.keras.experimental.load_from_saved_model&lt;/code&gt;.</source>
          <target state="translated">내 보낸 &lt;code&gt;SavedModel&lt;/code&gt; 은 Tensorflow 오브젝트의 독립형 직렬화이며 TF 언어 API 및 Tensorflow Serving 시스템에서 지원됩니다. 모델을로드하려면 &lt;code&gt;tf.keras.experimental.load_from_saved_model&lt;/code&gt; 함수를 사용하십시오 .</target>
        </trans-unit>
        <trans-unit id="115b43cdf7131901fe589992324081fddba4d32c" translate="yes" xml:space="preserve">
          <source>The factory function &lt;a href=&quot;raggedtensor#from_nested_row_splits&quot;&gt;&lt;code&gt;RaggedTensor.from_nested_row_splits&lt;/code&gt;&lt;/a&gt; may be used to construct a &lt;code&gt;RaggedTensor&lt;/code&gt; with multiple ragged dimensions directly, by providing a list of &lt;code&gt;row_splits&lt;/code&gt; tensors:</source>
          <target state="translated">팩토리 함수 &lt;a href=&quot;raggedtensor#from_nested_row_splits&quot;&gt; &lt;code&gt;RaggedTensor.from_nested_row_splits&lt;/code&gt; &lt;/a&gt; 는 &lt;code&gt;row_splits&lt;/code&gt; 텐서 목록을 제공하여 여러 개의 비정형 치수를 사용하여 &lt;code&gt;RaggedTensor&lt;/code&gt; 를 직접 구성하는 데 사용할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="84412542c638bfe39a033a0e5c516c5c165f7f74" translate="yes" xml:space="preserve">
          <source>The files in the dump directory contain the following information: - TensorFlow Function construction (e.g., compilation of Python functions decorated with @tf.function), the op types, names (if available), context, the input and output tensors, and the associated stack traces. - Execution of TensorFlow operations (ops) and Functions and their stack traces, op types, names (if available) and contexts. In addition, depending on the value of the &lt;code&gt;tensor_debug_mode&lt;/code&gt; argument (see Args section below), the value(s) of the output tensors or more concise summaries of the tensor values will be dumped. - A snapshot of Python source files involved in the execution of the TensorFlow program.</source>
          <target state="translated">덤프 디렉토리의 파일에는 다음 정보가 포함됩니다.-TensorFlow 함수 구성 (예 : @ tf.function으로 장식 된 Python 함수 컴파일), op 유형, 이름 (사용 가능한 경우), 컨텍스트, 입력 및 출력 텐서 및 관련 스택 추적. -TensorFlow 작업 (ops) 및 기능 및 해당 스택 추적, op 유형, 이름 (사용 가능한 경우) 및 컨텍스트 실행 또한 &lt;code&gt;tensor_debug_mode&lt;/code&gt; 인수의 값 (아래 Args 섹션 참조)에 따라 출력 텐서의 값 또는 텐서 값의 간결한 요약이 덤프됩니다. -TensorFlow 프로그램 실행과 관련된 Python 소스 파일의 스냅 샷.</target>
        </trans-unit>
        <trans-unit id="50c753605d6ee518cbe6dced5742e28ec63d5987" translate="yes" xml:space="preserve">
          <source>The first dict contains the context key/values.</source>
          <target state="translated">첫 번째 dict에는 컨텍스트 키 / 값이 포함되어 있습니다.</target>
        </trans-unit>
        <trans-unit id="21b3efb51e905408dc7d30df6c5476374dd7b033" translate="yes" xml:space="preserve">
          <source>The first matching Enum class member in Enum class.</source>
          <target state="translated">Enum 클래스에서 첫 번째로 일치하는 Enum 클래스 멤버</target>
        </trans-unit>
        <trans-unit id="aea8fe33a13a43f1f933680d9ce0f5a2db48535e" translate="yes" xml:space="preserve">
          <source>The first matching element from enum_values.</source>
          <target state="translated">enum_values에서 첫 번째로 일치하는 요소</target>
        </trans-unit>
        <trans-unit id="bf18fd4e6ab37edcfe93bf741aad23fe79581af4" translate="yes" xml:space="preserve">
          <source>The first output contains a Tensor with the content of the audio samples. The lowest dimension will be the number of channels, and the second will be the number of samples. For example, a ten-sample-long stereo WAV file should give an output shape of [10, 2].</source>
          <target state="translated">첫 번째 출력에는 오디오 샘플의 내용이 포함 된 Tensor가 포함됩니다. 가장 낮은 차원은 채널 수이고 두 번째는 샘플 수입니다. 예를 들어, 10 샘플 길이의 스테레오 WAV 파일은 [10, 2]의 출력 형태를 제공해야합니다.</target>
        </trans-unit>
        <trans-unit id="386e01aa23336af9951f682033560f681c83315e" translate="yes" xml:space="preserve">
          <source>The first time the dataset is iterated over, its elements will be cached either in the specified file or in memory. Subsequent iterations will use the cached data.</source>
          <target state="translated">데이터 세트가 처음 반복 될 때, 해당 요소는 지정된 파일이나 메모리에 캐시됩니다. 후속 반복에서는 캐시 된 데이터를 사용합니다.</target>
        </trans-unit>
        <trans-unit id="0f90632e85082c59f117ebff04eaae1a05ddf870" translate="yes" xml:space="preserve">
          <source>The flag value is parsed with a CSV parser.</source>
          <target state="translated">플래그 값은 CSV 파서로 구문 분석됩니다.</target>
        </trans-unit>
        <trans-unit id="96f145cafd13cfdf0d9a0f61a17dd04e31f2f508" translate="yes" xml:space="preserve">
          <source>The flag's current value is also updated if the flag is currently using the default value, i.e. not specified in the command line, and not set by FLAGS.name = value.</source>
          <target state="translated">플래그가 현재 기본값을 사용하는 경우 (예 : 명령 행에 지정되지 않고 FLAGS.name = value로 설정되지 않은 경우) 플래그의 현재 값도 업데이트됩니다.</target>
        </trans-unit>
        <trans-unit id="43c9fd434671ebe599abe72c41c1f1beb298f354" translate="yes" xml:space="preserve">
          <source>The flow &lt;code&gt;Tensor&lt;/code&gt; forcing ops leading to this TensorArray state.</source>
          <target state="translated">흐름 &lt;code&gt;Tensor&lt;/code&gt; 강제 op가이 TensorArray 상태로 연결됩니다.</target>
        </trans-unit>
        <trans-unit id="5802a84878124b124beac42194fc2361ed2f11d6" translate="yes" xml:space="preserve">
          <source>The following &lt;code&gt;DType&lt;/code&gt; objects are defined:</source>
          <target state="translated">다음과 같은 &lt;code&gt;DType&lt;/code&gt; 객체가 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="f23bf2a65eeb471ae91c72707d1429b81ec5054e" translate="yes" xml:space="preserve">
          <source>The following accumulators/queue are created:</source>
          <target state="translated">다음과 같은 누산기 / 큐가 생성됩니다.</target>
        </trans-unit>
        <trans-unit id="591cee6bba7aa3b795b8bd5b56dc88de0c7af0c0" translate="yes" xml:space="preserve">
          <source>The following aggregation methods are experimental and may not be supported in future releases:</source>
          <target state="translated">다음 집계 방법은 실험적이며 이후 릴리스에서 지원되지 않을 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="0a5195ca6a5ce9a55280235bcdfa18337e633d87" translate="yes" xml:space="preserve">
          <source>The following aggregation methods are part of the stable API for aggregating gradients:</source>
          <target state="translated">다음 집계 방법은 그라디언트 집계를위한 안정적인 API의 일부입니다.</target>
        </trans-unit>
        <trans-unit id="2ee6cb9dfe69d9d22f1caaeae67551de61d1e04d" translate="yes" xml:space="preserve">
          <source>The following code examples are equivalent:</source>
          <target state="translated">다음 코드 예제는 동일합니다.</target>
        </trans-unit>
        <trans-unit id="fe70fcf720ef0fde06fcd7d33ac8492a73efc566" translate="yes" xml:space="preserve">
          <source>The following example can be rewritten using a numpy.ndarray instead of the &lt;code&gt;value&lt;/code&gt; list, even reshaped, as shown in the two commented lines below the &lt;code&gt;value&lt;/code&gt; list initialization.</source>
          <target state="translated">다음 예제는 &lt;code&gt;value&lt;/code&gt; 목록 초기화 아래에 주석 처리 된 두 줄에 표시된 것처럼 &lt;code&gt;value&lt;/code&gt; 목록 대신 numpy.ndarray를 사용하여 다시 작성할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="dd2231c4c2e6ac8a925f85e0e3d53aba21ee51d7" translate="yes" xml:space="preserve">
          <source>The following example creates a TensorFlow graph with &lt;code&gt;np.sinh()&lt;/code&gt; as an operation in the graph:</source>
          <target state="translated">다음 예제 는 그래프에서 조작으로 &lt;code&gt;np.sinh()&lt;/code&gt; 를 사용하여 TensorFlow 그래프를 작성합니다 .</target>
        </trans-unit>
        <trans-unit id="96cf93e8858013a75fb44334359039c6f25c846e" translate="yes" xml:space="preserve">
          <source>The following example demonstrates disabling the first GPU on the machine.</source>
          <target state="translated">다음 예제는 머신에서 첫 번째 GPU를 비활성화하는 방법을 보여줍니다.</target>
        </trans-unit>
        <trans-unit id="f5252c999d447d634884b440e481ad68aacf0ae9" translate="yes" xml:space="preserve">
          <source>The following example lists the number of visible GPUs on the host.</source>
          <target state="translated">다음 예제는 호스트에서 보이는 GPU 수를 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="2cdccf83ed29fb9603555106e738bca275fd3c3f" translate="yes" xml:space="preserve">
          <source>The following example splits the CPU into 2 logical devices:</source>
          <target state="translated">다음 예제는 CPU를 2 개의 논리 장치로 분할합니다.</target>
        </trans-unit>
        <trans-unit id="4ace04a5fda844a89c5ee4c9be9654bd7abe4446" translate="yes" xml:space="preserve">
          <source>The following example splits the GPU into 2 logical devices with 100 MB each:</source>
          <target state="translated">다음 예제는 GPU를 각각 100MB의 논리 장치 2 개로 분할합니다.</target>
        </trans-unit>
        <trans-unit id="e92322d00886dec66262eaafdb4b32cf9a853e78" translate="yes" xml:space="preserve">
          <source>The following example verifies all visible GPUs have been disabled:</source>
          <target state="translated">다음 예제는 모든 보이는 GPU가 비활성화되었는지 확인합니다.</target>
        </trans-unit>
        <trans-unit id="4d32c07164d7968452b087497fbdd283446aa73c" translate="yes" xml:space="preserve">
          <source>The following is an example</source>
          <target state="translated">다음은 예입니다</target>
        </trans-unit>
        <trans-unit id="ed38596eeae1ed9d7dcfb7df999c45674415489a" translate="yes" xml:space="preserve">
          <source>The following is an example:</source>
          <target state="translated">다음은 예입니다.</target>
        </trans-unit>
        <trans-unit id="24bdb030bb46a068c505477e8cd1862a69826946" translate="yes" xml:space="preserve">
          <source>The following local variable is created:</source>
          <target state="translated">다음과 같은 지역 변수가 생성됩니다.</target>
        </trans-unit>
        <trans-unit id="6c83149474e8e1bdaa43183ac0053126fc2f29c2" translate="yes" xml:space="preserve">
          <source>The following optional keyword arguments are reserved for specific uses:</source>
          <target state="translated">다음의 선택적 키워드 인수는 특정 용도로 예약되어 있습니다.</target>
        </trans-unit>
        <trans-unit id="6b2e176467ad37b3b7339e39c7c7f1f162f5fc98" translate="yes" xml:space="preserve">
          <source>The following pieces are directly accessible as attributes of the &lt;code&gt;Scaffold&lt;/code&gt; object:</source>
          <target state="translated">다음은 &lt;code&gt;Scaffold&lt;/code&gt; 객체의 속성으로 직접 액세스 할 수있는 부분입니다 .</target>
        </trans-unit>
        <trans-unit id="c2ed2efebe2e500e729949e45ea5460a93f492fe" translate="yes" xml:space="preserve">
          <source>The following snippet initializes a table with the first column as keys and second column as values:</source>
          <target state="translated">다음 코드 조각은 첫 번째 열을 키로, 두 번째 열을 값으로 사용하여 테이블을 초기화합니다.</target>
        </trans-unit>
        <trans-unit id="e6f97267e796a462cd648b32cdaea5e143b3612c" translate="yes" xml:space="preserve">
          <source>The following standard keys are &lt;em&gt;defined&lt;/em&gt;, but their collections are &lt;strong&gt;not&lt;/strong&gt; automatically populated as many of the others are:</source>
          <target state="translated">다음과 같은 표준 키가 &lt;em&gt;정의&lt;/em&gt; 되어 있지만 다른 표준 키와 &lt;em&gt;같이&lt;/em&gt; 해당 컬렉션은 자동으로 채워 &lt;strong&gt;지지 않습니다&lt;/strong&gt; .</target>
        </trans-unit>
        <trans-unit id="99bfb2634af3adab05d0f542c47d1e0966b2dddf" translate="yes" xml:space="preserve">
          <source>The following standard keys are defined:</source>
          <target state="translated">다음과 같은 표준 키가 정의되어 있습니다.</target>
        </trans-unit>
        <trans-unit id="c5b0b8ccd1f0abc3ddefae0423fee59c58a2cd57" translate="yes" xml:space="preserve">
          <source>The fraction of zeros in &lt;code&gt;value&lt;/code&gt;, with type &lt;code&gt;float32&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;float32&lt;/code&gt; 유형의 &lt;code&gt;value&lt;/code&gt; 에서 0의 분수입니다 .</target>
        </trans-unit>
        <trans-unit id="992778fe6a92285eff91d32500db456a86a4fc54" translate="yes" xml:space="preserve">
          <source>The full name of this operation.</source>
          <target state="translated">이 작업의 전체 이름입니다.</target>
        </trans-unit>
        <trans-unit id="743b7a6db57523722e378bc070ddcab709a5ac83" translate="yes" xml:space="preserve">
          <source>The full path to the checkpoint (i.e. &lt;code&gt;file_prefix&lt;/code&gt;).</source>
          <target state="translated">검사 점의 전체 경로 (예 : &lt;code&gt;file_prefix&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="17174d3c9eb2bd17d3031f0d66dc8f9b3b509e75" translate="yes" xml:space="preserve">
          <source>The full path to the checkpoint.</source>
          <target state="translated">검사 점의 전체 경로입니다.</target>
        </trans-unit>
        <trans-unit id="acdec3e98e6b61dcd2da29992ebc62ad6f5bf20c" translate="yes" xml:space="preserve">
          <source>The full path to the latest checkpoint or &lt;code&gt;None&lt;/code&gt; if no checkpoint was found.</source>
          <target state="translated">최신 검사 점의 전체 경로 또는 검사 점이없는 경우 &lt;code&gt;None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="47f2fc665d0afe391e8a43fb1ae4db7142668b97" translate="yes" xml:space="preserve">
          <source>The function &lt;code&gt;grad_grad_fn&lt;/code&gt; will be calculating the first order gradient of &lt;code&gt;grad_fn&lt;/code&gt; with respect to &lt;code&gt;dy&lt;/code&gt;, which is used to generate forward-mode gradient graphs from backward-mode gradient graphs, but is not the same as the second order gradient of &lt;code&gt;op&lt;/code&gt; with respect to &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;grad_grad_fn&lt;/code&gt; 함수 는 &lt;code&gt;dy&lt;/code&gt; 에 대한 &lt;code&gt;grad_fn&lt;/code&gt; 의 1 차 그라디언트를 계산합니다 . 이는 그라디언트 모드 그라디언트 그래프에서 순방향 모드 그라디언트 그래프를 생성하는 데 사용되지만 &lt;code&gt;x&lt;/code&gt; 에 대한 &lt;code&gt;op&lt;/code&gt; 의 2 차 그라디언트와 동일하지 않습니다. .</target>
        </trans-unit>
        <trans-unit id="45872032316d782b7cca27465e024bb311aaa0d6" translate="yes" xml:space="preserve">
          <source>The function arguments use the same convention as Theano's arange: if only one argument is provided, it is in fact the &quot;stop&quot; argument and &quot;start&quot; is 0.</source>
          <target state="translated">함수 인수는 Theano의 배열과 동일한 규칙을 사용합니다. 하나의 인수 만 제공하면 실제로는 &quot;stop&quot;인수이고 &quot;start&quot;는 0입니다.</target>
        </trans-unit>
        <trans-unit id="a54988c5a27bf3df304066330e8659cc62c5ae14" translate="yes" xml:space="preserve">
          <source>The function may use variable scopes and other templates internally to create and reuse variables, but it shouldn't use &lt;a href=&quot;global_variables&quot;&gt;&lt;code&gt;tf.compat.v1.global_variables&lt;/code&gt;&lt;/a&gt; to capture variables that are defined outside of the scope of the function.</source>
          <target state="translated">이 함수는 변수 범위 및 기타 템플릿을 내부적으로 사용하여 변수를 만들고 재사용 할 수 있지만 &lt;a href=&quot;global_variables&quot;&gt; &lt;code&gt;tf.compat.v1.global_variables&lt;/code&gt; &lt;/a&gt; 를 사용 하여 함수 범위 밖에서 정의 된 변수를 캡처 해서는 안됩니다 .</target>
        </trans-unit>
        <trans-unit id="7473045784de1b0d1dced2ea1e88e2739636aca8" translate="yes" xml:space="preserve">
          <source>The function returns a 1-arg callable to compute the piecewise constant when passed the current optimizer step. This can be useful for changing the learning rate value across different invocations of optimizer functions.</source>
          <target state="translated">이 함수는 현재 최적화 단계를 통과 할 때 부분 상수를 계산하기 위해 1-arg 호출 가능을 반환합니다. 이것은 옵티 마이저 함수의 다른 호출에서 학습 속도 값을 변경하는 데 유용 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7935c69bd80f01354e2709843f6b51eb870975aa" translate="yes" xml:space="preserve">
          <source>The function returns the decayed learning rate while taking into account possible warm restarts. The learning rate multiplier first decays from 1 to &lt;code&gt;alpha&lt;/code&gt; for &lt;code&gt;first_decay_steps&lt;/code&gt; steps. Then, a warm restart is performed. Each new warm restart runs for &lt;code&gt;t_mul&lt;/code&gt; times more steps and with &lt;code&gt;m_mul&lt;/code&gt; times smaller initial learning rate.</source>
          <target state="translated">이 함수는 가능한 웜 재시작을 고려하면서 붕괴 된 학습 속도를 반환합니다. 학습 속도 승수 는 &lt;code&gt;first_decay_steps&lt;/code&gt; 단계에 대해 먼저 1에서 &lt;code&gt;alpha&lt;/code&gt; 로 감소 합니다. 그런 다음 웜 재시작이 수행됩니다. 각각의 새로운 웜 리 스타트는 &lt;code&gt;t_mul&lt;/code&gt; 배 더 많은 단계와 &lt;code&gt;m_mul&lt;/code&gt; 배 더 작은 초기 학습 속도로 실행됩니다.</target>
        </trans-unit>
        <trans-unit id="86355e2388af8622a11980472ee114bf3a474b98" translate="yes" xml:space="preserve">
          <source>The function returns the decayed learning rate. It is computed as:</source>
          <target state="translated">이 함수는 학습 속도 감소를 반환합니다. 다음과 같이 계산됩니다.</target>
        </trans-unit>
        <trans-unit id="bbeb4f9954a2b9fb0a88492d0bff2e967c29ba25" translate="yes" xml:space="preserve">
          <source>The function should create all trainable variables and any variables that should be reused by calling &lt;a href=&quot;get_variable&quot;&gt;&lt;code&gt;tf.compat.v1.get_variable&lt;/code&gt;&lt;/a&gt;. If a trainable variable is created using &lt;a href=&quot;../../variable&quot;&gt;&lt;code&gt;tf.Variable&lt;/code&gt;&lt;/a&gt;, then a ValueError will be thrown. Variables that are intended to be locals can be created by specifying &lt;a href=&quot;../../variable&quot;&gt;&lt;code&gt;tf.Variable(..., trainable=false)&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">이 함수는 훈련 가능한 모든 변수와 &lt;a href=&quot;get_variable&quot;&gt; &lt;code&gt;tf.compat.v1.get_variable&lt;/code&gt; &lt;/a&gt; 을 호출하여 재사용해야하는 모든 변수를 작성해야합니다 . 훈련 가능한 변수가 &lt;a href=&quot;../../variable&quot;&gt; &lt;code&gt;tf.Variable&lt;/code&gt; 을&lt;/a&gt; 사용하여 생성 되면 ValueError가 발생합니다. &lt;a href=&quot;../../variable&quot;&gt; &lt;code&gt;tf.Variable(..., trainable=false)&lt;/code&gt; &lt;/a&gt; 를 지정하여 지역 변수로 만들려는 변수를 만들 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="8e1312f2dcf17101a4e17a36133e6bbffe530ce3" translate="yes" xml:space="preserve">
          <source>The function writes the SavedModel protocol buffer to the export directory in serialized format.</source>
          <target state="translated">이 함수는 SavedModel 프로토콜 버퍼를 직렬화 된 형식으로 내보내기 디렉토리에 씁니다.</target>
        </trans-unit>
        <trans-unit id="00cf308c9f40a9f1b859f12fd033e78caa4d14cd" translate="yes" xml:space="preserve">
          <source>The functions &lt;code&gt;f1&lt;/code&gt; and &lt;code&gt;f2&lt;/code&gt; will be executed serially, and updates to &lt;code&gt;v&lt;/code&gt; will be atomic.</source>
          <target state="translated">기능 &lt;code&gt;f1&lt;/code&gt; 및 &lt;code&gt;f2&lt;/code&gt; 는 순차적으로 실행되며 &lt;code&gt;v&lt;/code&gt; 에 대한 업데이트 는 원 자성입니다.</target>
        </trans-unit>
        <trans-unit id="dde4529b22d96c16a9b96a541d58c5d0a1f7056a" translate="yes" xml:space="preserve">
          <source>The generated &lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto&quot;&gt;&lt;code&gt;Summary&lt;/code&gt;&lt;/a&gt; has one summary value containing a histogram for &lt;code&gt;values&lt;/code&gt;.</source>
          <target state="translated">생성 된 &lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto&quot;&gt; &lt;code&gt;Summary&lt;/code&gt; &lt;/a&gt; 에는 값에 대한 히스토그램을 포함하는 하나의 요약 값이 &lt;code&gt;values&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="062e4980e54d60fb22e75f6c9b5206c3bc85ad28" translate="yes" xml:space="preserve">
          <source>The generated Summary has a Tensor.proto containing the input Tensor.</source>
          <target state="translated">생성 된 요약에는 입력 Tensor를 포함하는 Tensor.proto가 있습니다.</target>
        </trans-unit>
        <trans-unit id="2e6c1194a7570536aae2b3653d7c1dba93fd5851" translate="yes" xml:space="preserve">
          <source>The generated values follow a binomial distribution with specified count and probability of success parameters.</source>
          <target state="translated">생성 된 값은 지정된 개수와 성공 확률 매개 변수로 이항 분포를 따릅니다.</target>
        </trans-unit>
        <trans-unit id="34cfd1936eb36f5d55d6eea6019586d8abfd6453" translate="yes" xml:space="preserve">
          <source>The generated values follow a normal distribution with specified mean and standard deviation, except that values whose magnitude is more than 2 standard deviations from the mean are dropped and re-picked.</source>
          <target state="translated">생성 된 값은 평균과 표준 편차가 2보다 큰 표준 편차를 제외하고 지정된 평균 및 표준 편차를 갖는 정규 분포를 따릅니다.</target>
        </trans-unit>
        <trans-unit id="0f713a6a0ff6a46795bef18d9e29d3e2780e55f6" translate="yes" xml:space="preserve">
          <source>The generated values follow a normal distribution with specified mean and standard deviation, except that values whose magnitude is more than two standard deviations from the mean are dropped and re-picked.</source>
          <target state="translated">생성 된 값은 평균과 표준 편차가 2보다 큰 표준 편차를 제외하고 지정된 평균 및 표준 편차를 갖는 정규 분포를 따릅니다.</target>
        </trans-unit>
        <trans-unit id="c4eafca9e4f8c3067d55709b52f16b752c27ed7e" translate="yes" xml:space="preserve">
          <source>The generated values follow a uniform distribution in the range &lt;code&gt;[minval, maxval)&lt;/code&gt;. The lower bound &lt;code&gt;minval&lt;/code&gt; is included in the range, while the upper bound &lt;code&gt;maxval&lt;/code&gt; is excluded.</source>
          <target state="translated">생성 된 값은 &lt;code&gt;[minval, maxval)&lt;/code&gt; 범위의 균일 한 분포를 따릅니다 . 하한 &lt;code&gt;minval&lt;/code&gt; 상한 동안 범위에 포함 &lt;code&gt;maxval&lt;/code&gt; 제외된다.</target>
        </trans-unit>
        <trans-unit id="729a8a331d955e25ac8cf2c6b6a31b0effcb1a59" translate="yes" xml:space="preserve">
          <source>The generated values follow a uniform distribution in the range &lt;code&gt;[minval, maxval)&lt;/code&gt;. The lower bound &lt;code&gt;minval&lt;/code&gt; is included in the range, while the upper bound &lt;code&gt;maxval&lt;/code&gt; is excluded. (For float numbers especially low-precision types like bfloat16, because of rounding, the result may sometimes include &lt;code&gt;maxval&lt;/code&gt;.)</source>
          <target state="translated">생성 된 값은 &lt;code&gt;[minval, maxval)&lt;/code&gt; 범위의 균일 한 분포를 따릅니다 . 하한 &lt;code&gt;minval&lt;/code&gt; 상한 동안 범위에 포함 &lt;code&gt;maxval&lt;/code&gt; 제외된다. (float 숫자 특히 bfloat16과 같은 정밀도가 낮은 유형의 경우 반올림으로 인해 결과에 때때로 &lt;code&gt;maxval&lt;/code&gt; 이 포함될 수 있습니다 .)</target>
        </trans-unit>
        <trans-unit id="3f254b2b1969b3fd6753653a609c42efa67f8dfa" translate="yes" xml:space="preserve">
          <source>The given &lt;a href=&quot;options&quot;&gt;&lt;code&gt;tf.data.Options&lt;/code&gt;&lt;/a&gt; can be merged as long as there does not exist an attribute that is set to different values in &lt;code&gt;self&lt;/code&gt; and &lt;code&gt;options&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; 및 &lt;code&gt;options&lt;/code&gt; 에 다른 값으로 설정된 속성이없는 한 지정된 &lt;a href=&quot;options&quot;&gt; &lt;code&gt;tf.data.Options&lt;/code&gt; &lt;/a&gt; 를 병합 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="0d60ebc741d192476c8f1b6c1be3c6bd74a4d508" translate="yes" xml:space="preserve">
          <source>The given tensors are sliced along their first dimension. This operation preserves the structure of the input tensors, removing the first dimension of each tensor and using it as the dataset dimension. All input tensors must have the same size in their first dimensions.</source>
          <target state="translated">주어진 텐서는 첫 번째 치수를 따라 슬라이스됩니다. 이 작업은 입력 텐서의 구조를 유지하여 각 텐서의 첫 번째 차원을 제거하고이를 데이터 세트 차원으로 사용합니다. 모든 입력 텐서는 첫 번째 치수에서 동일한 크기를 가져야합니다.</target>
        </trans-unit>
        <trans-unit id="ccd566669127e41c5c83f5e51e6e655e2023b466" translate="yes" xml:space="preserve">
          <source>The global Policy.</source>
          <target state="translated">글로벌 정책.</target>
        </trans-unit>
        <trans-unit id="7f44fcbf38635afbe0c45b61c517d01f18c4ad9b" translate="yes" xml:space="preserve">
          <source>The global id in the training cluster.</source>
          <target state="translated">교육 클러스터의 글로벌 ID입니다.</target>
        </trans-unit>
        <trans-unit id="c06234718e1efd425d9fee36736f9c49d1c25446" translate="yes" xml:space="preserve">
          <source>The global policy is the default policy used for layers, if no policy is passed to the layer constructor. If no global policy is set, layers will instead default to a Policy constructed from &lt;a href=&quot;../../backend/floatx&quot;&gt;&lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt;&lt;/a&gt; in TensorFlow 2. In TensorFlow 1, layers default to an &quot;infer&quot; policy.</source>
          <target state="translated">전역 정책은 정책이 계층 생성자에 전달되지 않은 경우 계층에 사용되는 기본 정책입니다. 글로벌 정책이 설정되어 있지 않으면 레이어는 대신 TensorFlow 2의 &lt;a href=&quot;../../backend/floatx&quot;&gt; &lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt; &lt;/a&gt; 로 구성된 정책으로 기본 설정됩니다 . TensorFlow 1에서 레이어는 기본적으로 &quot;추론&quot;정책으로 설정됩니다.</target>
        </trans-unit>
        <trans-unit id="9aa023817c66fefe7d12596fe9f5c2f950738ad5" translate="yes" xml:space="preserve">
          <source>The global policy is the default policy used for layers, if no policy is passed to the layer constructor. If no policy has been set with &lt;a href=&quot;set_policy&quot;&gt;&lt;code&gt;keras.mixed_precision.experimental.set_policy&lt;/code&gt;&lt;/a&gt;, this will return a policy constructed from &lt;a href=&quot;../../backend/floatx&quot;&gt;&lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt;&lt;/a&gt; in TensorFlow 2 (floatx defaults to float32), or an &quot;infer&quot; policy in TensorFlow 1.</source>
          <target state="translated">전역 정책은 정책이 계층 생성자에 전달되지 않은 경우 계층에 사용되는 기본 정책입니다. &lt;a href=&quot;set_policy&quot;&gt; &lt;code&gt;keras.mixed_precision.experimental.set_policy&lt;/code&gt; &lt;/a&gt; 로 설정된 정책이없는 경우 TensorFlow 2의 &lt;a href=&quot;../../backend/floatx&quot;&gt; &lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt; &lt;/a&gt; 에서 구성된 정책 (floatx 기본값은 float32로 설정 됨) 또는 TensorFlow 1의 &quot;추론&quot;정책 이 반환됩니다. .</target>
        </trans-unit>
        <trans-unit id="147a0f3f093ca1fdfeeb131812693ae892afe50f" translate="yes" xml:space="preserve">
          <source>The global step tensor must be an integer variable. We first try to find it in the collection &lt;code&gt;GLOBAL_STEP&lt;/code&gt;, or by name &lt;code&gt;global_step:0&lt;/code&gt;.</source>
          <target state="translated">전역 단계 텐서는 정수 변수 여야합니다. 먼저 &lt;code&gt;GLOBAL_STEP&lt;/code&gt; 컬렉션 에서 또는 &lt;code&gt;global_step:0&lt;/code&gt; 이라는 이름 으로 찾아보십시오 .</target>
        </trans-unit>
        <trans-unit id="1b54d047ac096c3ae7f021822844b86acfbb5227" translate="yes" xml:space="preserve">
          <source>The global step tensor.</source>
          <target state="translated">글로벌 스텝 텐서.</target>
        </trans-unit>
        <trans-unit id="95db374c08adfbc24c444a5e0edf15c6723034b8" translate="yes" xml:space="preserve">
          <source>The global step value.</source>
          <target state="translated">글로벌 단계 값.</target>
        </trans-unit>
        <trans-unit id="27f92d2c600461e2b55ce1161093f706c000d648" translate="yes" xml:space="preserve">
          <source>The global step variable, or &lt;code&gt;None&lt;/code&gt; if none was found.</source>
          <target state="translated">글로벌 단계의 변수 또는 &lt;code&gt;None&lt;/code&gt; 전혀 발견되지 않은 경우.</target>
        </trans-unit>
        <trans-unit id="a2344c5579f4717a0862d524efae16729bc6ed70" translate="yes" xml:space="preserve">
          <source>The gradient computation of this operation will only take advantage of sparsity in the input gradient when that gradient comes from a Relu.</source>
          <target state="translated">이 연산의 그래디언트 계산은 해당 그래디언트가 Relu에서 발생할 때 입력 그래디언트의 희소성을 활용합니다.</target>
        </trans-unit>
        <trans-unit id="d051520aa4dd277f3ed0bb66ae2aa2ab1b266a18" translate="yes" xml:space="preserve">
          <source>The gradient computed for 'op_type' will then propagate zeros.</source>
          <target state="translated">'op_type'에 대해 계산 된 그래디언트는 0을 전파합니다.</target>
        </trans-unit>
        <trans-unit id="71b1d3537cf96813de8a96c3c5f5d393309ab752" translate="yes" xml:space="preserve">
          <source>The gradient expression can be analytically simplified to provide numerical stability:</source>
          <target state="translated">수치 표현을 제공하기 위해 구배 표현을 분석적으로 단순화 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7ab3e3e9ec9dadb6bed29c4d9fadd240cfe53d58" translate="yes" xml:space="preserve">
          <source>The gradient of y with respect to x can be zero in two different ways: there could be no differentiable path in the graph connecting x to y (and so we can statically prove that the gradient is zero) or it could be that runtime values of tensors in a particular execution lead to a gradient of zero (say, if a relu unit happens to not be activated). To allow you to distinguish between these two cases you can choose what value gets returned for the gradient when there is no path in the graph from x to y:</source>
          <target state="translated">x에 대한 y의 기울기는 두 가지 방법으로 0이 될 수 있습니다. x에 y를 연결하는 그래프에 구별 가능한 경로가 없거나 (그래서 우리는 기울기가 0임을 정적으로 증명할 수 있습니다) 또는 다음의 런타임 값일 수 있습니다 특정 실행에서 텐서는 0의 기울기로 이어집니다 (즉, relu 장치가 활성화되지 않은 경우). 이 두 경우를 구별하기 위해 그래프에 x에서 y까지의 경로가 없을 때 그라디언트에 대해 반환되는 값을 선택할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="f5c157361d6bbe7fc68fa055766a81dc3624c016" translate="yes" xml:space="preserve">
          <source>The graph described by the protocol buffer will be displayed by TensorBoard. Most users pass a graph in the constructor instead.</source>
          <target state="translated">프로토콜 버퍼에 의해 설명 된 그래프는 TensorBoard에 의해 표시됩니다. 대부분의 사용자는 대신 생성자에 그래프를 전달합니다.</target>
        </trans-unit>
        <trans-unit id="661d2d430bf12295ddf1be3a1e881f38bccfdb01" translate="yes" xml:space="preserve">
          <source>The graph is written as a text proto unless &lt;code&gt;as_text&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;as_text&lt;/code&gt; 가 &lt;code&gt;False&lt;/code&gt; 가 아닌 한 그래프는 텍스트 프로토 타입으로 작성됩니다 .</target>
        </trans-unit>
        <trans-unit id="ed620881b1cf97ec1349e99d3e7fd253aa216b39" translate="yes" xml:space="preserve">
          <source>The graph rewrite operation changes the &lt;code&gt;dtype&lt;/code&gt; of certain operations in the graph from float32 to float16. There are several categories of operations that are either included or excluded by this rewrite operation. The following categories of Ops are defined inside corresponding functions under the class &lt;code&gt;AutoMixedPrecisionLists&lt;/code&gt; in  auto_mixed_precision_lists.h:</source>
          <target state="translated">그래프 재 작성 조작 은 그래프에서 특정 조작 의 &lt;code&gt;dtype&lt;/code&gt; 을 float32에서 float16으로 변경합니다. 이 다시 쓰기 작업에 포함되거나 제외되는 몇 가지 범주의 작업이 있습니다. 다음 범주의 Ops는 &lt;code&gt;AutoMixedPrecisionLists&lt;/code&gt; 의 AutoMixedPrecisionLists 클래스 아래 해당 기능 내에 정의되어 있습니다 .</target>
        </trans-unit>
        <trans-unit id="ae4960be0391bc0449f500287c2e9601d2d28fb9" translate="yes" xml:space="preserve">
          <source>The graph that was launched in this session.</source>
          <target state="translated">이 세션에서 시작된 그래프입니다.</target>
        </trans-unit>
        <trans-unit id="ff2ceded61c6685a839fd2d7a80fa7375d194758" translate="yes" xml:space="preserve">
          <source>The graph with quantize training done.</source>
          <target state="translated">양자화 훈련이 완료된 그래프.</target>
        </trans-unit>
        <trans-unit id="3e6f6623fe7498e3548d52e61a0b5aeb7212fa47" translate="yes" xml:space="preserve">
          <source>The graph-level random seed of this graph.</source>
          <target state="translated">이 그래프의 그래프 레벨 랜덤 시드입니다.</target>
        </trans-unit>
        <trans-unit id="4ddc50d95cf25f219ea2579cde9bf22435bfdc02" translate="yes" xml:space="preserve">
          <source>The hard sigmoid activation:</source>
          <target state="translated">하드 시그 모이 드 활성화 :</target>
        </trans-unit>
        <trans-unit id="0f4987b71fd23d4d24937f4f99fea76affcae8b1" translate="yes" xml:space="preserve">
          <source>The hash function is deterministic on the content of the string within the process and will never change. However, it is not suitable for cryptography. This function may be used when CPU time is scarce and inputs are trusted or unimportant. There is a risk of adversaries constructing inputs that all hash to the same bucket. To prevent this problem, use a strong hash function with &lt;code&gt;tf.string_to_hash_bucket_strong&lt;/code&gt;.</source>
          <target state="translated">해시 함수는 프로세스 내의 문자열 내용에 결정적이며 절대 변경되지 않습니다. 그러나 암호화에는 적합하지 않습니다. 이 기능은 CPU 시간이 부족하고 입력을 신뢰할 수 있거나 중요하지 않은 경우에 사용할 수 있습니다. 공격자가 모두 동일한 버킷에 해시하는 입력을 구성 할 위험이 있습니다. 이 문제를 방지하려면 &lt;code&gt;tf.string_to_hash_bucket_strong&lt;/code&gt; 과 함께 강력한 해시 함수를 사용 하십시오 .</target>
        </trans-unit>
        <trans-unit id="fd0bfc8db5880e8eee54fb3385531988b2ad4a55" translate="yes" xml:space="preserve">
          <source>The hash function is deterministic on the content of the string within the process.</source>
          <target state="translated">해시 함수는 프로세스 내의 문자열 내용에 결정적입니다.</target>
        </trans-unit>
        <trans-unit id="61f428a10a4305c850461ee00f387b0cacfe0ef7" translate="yes" xml:space="preserve">
          <source>The hash function is deterministic on the content of the string within the process. The hash function is a keyed hash function, where attribute &lt;code&gt;key&lt;/code&gt; defines the key of the hash function. &lt;code&gt;key&lt;/code&gt; is an array of 2 elements.</source>
          <target state="translated">해시 함수는 프로세스 내의 문자열 내용에 결정적입니다. 해시 함수는 키가있는 해시 함수이며, 여기서 속성 &lt;code&gt;key&lt;/code&gt; 는 해시 함수의 키를 정의합니다. &lt;code&gt;key&lt;/code&gt; 는 2 개의 요소로 구성된 배열입니다.</target>
        </trans-unit>
        <trans-unit id="1e7a8b7c173f99d4be181a635239bd0a5322a9de" translate="yes" xml:space="preserve">
          <source>The hash function used for generating out-of-vocabulary buckets ID is Fingerprint64.</source>
          <target state="translated">어휘 외 버킷 ID를 생성하는 데 사용되는 해시 함수는 Fingerprint64입니다.</target>
        </trans-unit>
        <trans-unit id="69a6e09f76ddf4e19a4f8311d3f8fdc0b3c24b22" translate="yes" xml:space="preserve">
          <source>The head can be used with a canned estimator. Example:</source>
          <target state="translated">헤드는 통조림 추정기와 함께 사용할 수 있습니다. 예:</target>
        </trans-unit>
        <trans-unit id="d8faf861d99f75e3ed7e367680c294894cd4fcef" translate="yes" xml:space="preserve">
          <source>The head expects &lt;code&gt;logits&lt;/code&gt; with shape &lt;code&gt;[D0, D1, ... DN, 1]&lt;/code&gt;. In many applications, the shape is &lt;code&gt;[batch_size, 1]&lt;/code&gt;.</source>
          <target state="translated">머리는 &lt;code&gt;[D0, D1, ... DN, 1]&lt;/code&gt; 모양의 &lt;code&gt;logits&lt;/code&gt; 을 예상 합니다. 많은 응용 프로그램에서 모양은 &lt;code&gt;[batch_size, 1]&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="c11316cb9d31dc7288f1ee66c33f5379df0eac90" translate="yes" xml:space="preserve">
          <source>The head expects &lt;code&gt;logits&lt;/code&gt; with shape &lt;code&gt;[D0, D1, ... DN, label_dimension]&lt;/code&gt;. In many applications, the shape is &lt;code&gt;[batch_size, label_dimension]&lt;/code&gt;.</source>
          <target state="translated">머리는 &lt;code&gt;[D0, D1, ... DN, label_dimension]&lt;/code&gt; 모양의 &lt;code&gt;logits&lt;/code&gt; 을 예상 합니다. 많은 응용 프로그램에서 모양은 &lt;code&gt;[batch_size, label_dimension]&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="bfb83e6dd754125ed65384336314d4dfea48278d" translate="yes" xml:space="preserve">
          <source>The head expects &lt;code&gt;logits&lt;/code&gt; with shape &lt;code&gt;[D0, D1, ... DN, n_classes]&lt;/code&gt;. In many applications, the shape is &lt;code&gt;[batch_size, n_classes]&lt;/code&gt;.</source>
          <target state="translated">머리는 &lt;code&gt;[D0, D1, ... DN, n_classes]&lt;/code&gt; 모양의 &lt;code&gt;logits&lt;/code&gt; 을 예상 합니다. 많은 응용 프로그램에서 모양은 &lt;code&gt;[batch_size, n_classes]&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="0d067db23fc00d02a594d5d3f6689549c9f412c9" translate="yes" xml:space="preserve">
          <source>The higher the value, the more important the corresponding feature.</source>
          <target state="translated">값이 클수록 해당 기능이 더 중요합니다.</target>
        </trans-unit>
        <trans-unit id="ec4887ee6136cea3e95782b65b373451d365f518" translate="yes" xml:space="preserve">
          <source>The ids and weights may be multi-dimensional. Embeddings are always aggregated along the last dimension.</source>
          <target state="translated">id 및 가중치는 다차원 일 수있다. 임베드는 항상 마지막 차원을 따라 집계됩니다.</target>
        </trans-unit>
        <trans-unit id="2dedfa9fac99909c847ee188683a18acc13d4781" translate="yes" xml:space="preserve">
          <source>The image sizes must be at least 11x11 because of the filter size.</source>
          <target state="translated">필터 크기로 인해 이미지 크기는 11x11 이상이어야합니다.</target>
        </trans-unit>
        <trans-unit id="7d3ec374ef70a5b15f88b06660be75d304545cf4" translate="yes" xml:space="preserve">
          <source>The implementation is based on: http://arxiv.org/abs/1409.2329.</source>
          <target state="translated">구현은 http://arxiv.org/abs/1409.2329를 기반으로합니다.</target>
        </trans-unit>
        <trans-unit id="4ceeee7cb755fec502e82f78579a1a2aeacda20b" translate="yes" xml:space="preserve">
          <source>The implementation of reduce of &lt;code&gt;per_replica_value&lt;/code&gt; to &lt;code&gt;destinations&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;per_replica_value&lt;/code&gt; 를 &lt;code&gt;destinations&lt;/code&gt; 으로 축소 구현 .</target>
        </trans-unit>
        <trans-unit id="39a73acc3a718d665ade71e6fcdb4d6f64ce1525" translate="yes" xml:space="preserve">
          <source>The index of the closest cluster center for each input point.</source>
          <target state="translated">각 입력 지점에서 가장 가까운 군집 중심의 색인입니다.</target>
        </trans-unit>
        <trans-unit id="bea3fce0b788c98ad4fd4961601d66fd0a86dd08" translate="yes" xml:space="preserve">
          <source>The index of this tensor in the outputs of its &lt;code&gt;Operation&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;Operation&lt;/code&gt; 출력에서이 텐서의 인덱스입니다 .</target>
        </trans-unit>
        <trans-unit id="14e09cd196d124b973e167954c771249f4762ea9" translate="yes" xml:space="preserve">
          <source>The indicator function</source>
          <target state="translated">표시기 기능</target>
        </trans-unit>
        <trans-unit id="e479f7d6722440bc7a24c4b0e9bd9fc43faf862a" translate="yes" xml:space="preserve">
          <source>The indices in &lt;code&gt;argmax&lt;/code&gt; are flattened, so that a maximum value at position &lt;code&gt;[b, y, x, c]&lt;/code&gt; becomes flattened index: &lt;code&gt;(y * width + x) * channels + c&lt;/code&gt; if &lt;code&gt;include_batch_in_index&lt;/code&gt; is False; &lt;code&gt;((b * height + y) * width + x) * channels + c&lt;/code&gt; if &lt;code&gt;include_batch_in_index&lt;/code&gt; is True.</source>
          <target state="translated">있는 인덱스 &lt;code&gt;argmax&lt;/code&gt; 는 제 위치에서 최대 값 것을 평탄화된다 &lt;code&gt;[b, y, x, c]&lt;/code&gt; 평면화 인덱스된다 : &lt;code&gt;(y * width + x) * channels + c&lt;/code&gt; 경우 &lt;code&gt;include_batch_in_index&lt;/code&gt; 가 거짓이고; &lt;code&gt;include_batch_in_index&lt;/code&gt; 가 True 인 경우 &lt;code&gt;((b * height + y) * width + x) * channels + c&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="0c8ef3b2e283d0175df2945495378ccedf137327" translate="yes" xml:space="preserve">
          <source>The indices of any input &lt;code&gt;SparseTensor&lt;/code&gt; are assumed ordered in standard lexicographic order. If this is not the case, before this step run &lt;code&gt;SparseReorder&lt;/code&gt; to restore index ordering.</source>
          <target state="translated">모든 입력 &lt;code&gt;SparseTensor&lt;/code&gt; 의 색인은 표준 사전 순서대로 정렬 된 것으로 가정합니다. 그렇지 않은 경우이 단계 전에 &lt;code&gt;SparseReorder&lt;/code&gt; 를 실행 하여 인덱스 순서를 복원하십시오.</target>
        </trans-unit>
        <trans-unit id="b80ce2ebdd8a066053015d24d2b36c5006bb3c4b" translate="yes" xml:space="preserve">
          <source>The indices of non-zero values in the represented dense tensor.</source>
          <target state="translated">표시된 조밀 한 텐서에서 0이 아닌 값의 인덱스.</target>
        </trans-unit>
        <trans-unit id="6678184e53cf5eab61e8f12ffd050f2da0981541" translate="yes" xml:space="preserve">
          <source>The indices returned are always in &lt;code&gt;[0, height) x [0, width)&lt;/code&gt; before flattening, even if padding is involved and the mathematically correct answer is outside (either negative or too large). This is a bug, but fixing it is difficult to do in a safe backwards compatible way, especially due to flattening.</source>
          <target state="translated">패딩이 관련되어 있고 수학적으로 정답이 외부에 있거나 (음수이거나 너무 큰 경우 &lt;code&gt;[0, height) x [0, width)&lt;/code&gt; 반환 된 인덱스는 전개하기 전에 항상 [0, 높이) x [0, 너비 )입니다. 이것은 버그이지만 수정하는 것은 특히 병합으로 인해 이전 버전과 호환되는 안전한 방법으로 수행하기가 어렵습니다.</target>
        </trans-unit>
        <trans-unit id="982eccddab4c7cb8698248ade435084245e7ba3a" translate="yes" xml:space="preserve">
          <source>The inferred shape of a tensor is used to provide shape information without having to launch the graph in a session. This can be used for debugging, and providing early error messages. For example:</source>
          <target state="translated">텐서의 유추 된 모양은 세션에서 그래프를 시작할 필요없이 모양 정보를 제공하는 데 사용됩니다. 디버깅 및 초기 오류 메시지 제공에 사용할 수 있습니다. 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="d0cd21ff5f1c8bdcbdb1615eade35bd02cd426a1" translate="yes" xml:space="preserve">
          <source>The initial value for every thread's stack is set to the current value of the stack when &lt;code&gt;switch_to_thread_local()&lt;/code&gt; was first called.</source>
          <target state="translated">모든 스레드 스택의 초기 값은 &lt;code&gt;switch_to_thread_local()&lt;/code&gt; 이 처음 호출 될 때 스택의 현재 값으로 설정됩니다 .</target>
        </trans-unit>
        <trans-unit id="1520071416fcbbf59fdfe9d1fb1a38e0c5b7ec1a" translate="yes" xml:space="preserve">
          <source>The initializer operation for this variable.</source>
          <target state="translated">이 변수의 이니셜 라이저 조작.</target>
        </trans-unit>
        <trans-unit id="5fe0073bfbc54ff4aabd7ab72b5b3609d630078b" translate="yes" xml:space="preserve">
          <source>The inner-most 2 dimensions of &lt;code&gt;input&lt;/code&gt; are assumed to be the result of &lt;code&gt;RFFT2D&lt;/code&gt;: The inner-most dimension contains the &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; unique components of the DFT of a real-valued signal. If &lt;code&gt;fft_length&lt;/code&gt; is not provided, it is computed from the size of the inner-most 2 dimensions of &lt;code&gt;input&lt;/code&gt;. If the FFT length used to compute &lt;code&gt;input&lt;/code&gt; is odd, it should be provided since it cannot be inferred properly.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 가장 안쪽 2 차원은 &lt;code&gt;RFFT2D&lt;/code&gt; 의 결과 인 것으로 가정합니다 . 가장 안쪽의 차원은 실수 값 신호의 DFT의 &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; 고유 성분을 포함합니다. 경우 &lt;code&gt;fft_length&lt;/code&gt; 가 제공되지 않고, 그것의 가장 안쪽 2 차원의 사이즈로부터 계산되어 &lt;code&gt;input&lt;/code&gt; . &lt;code&gt;input&lt;/code&gt; 계산에 사용 된 FFT 길이 가 홀수이면 제대로 추론 할 수 없으므로 입력 해야합니다.</target>
        </trans-unit>
        <trans-unit id="577a2328b01f8435a1e76dd0c500fccff4c87199" translate="yes" xml:space="preserve">
          <source>The inner-most 3 dimensions of &lt;code&gt;input&lt;/code&gt; are assumed to be the result of &lt;code&gt;RFFT3D&lt;/code&gt;: The inner-most dimension contains the &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; unique components of the DFT of a real-valued signal. If &lt;code&gt;fft_length&lt;/code&gt; is not provided, it is computed from the size of the inner-most 3 dimensions of &lt;code&gt;input&lt;/code&gt;. If the FFT length used to compute &lt;code&gt;input&lt;/code&gt; is odd, it should be provided since it cannot be inferred properly.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 가장 안쪽 3 차원은 &lt;code&gt;RFFT3D&lt;/code&gt; 의 결과 인 것으로 가정합니다 . 가장 안쪽의 차원은 실수 값 신호의 DFT의 &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; 고유 성분을 포함합니다. 경우 &lt;code&gt;fft_length&lt;/code&gt; 가 제공되지 않고, 그것의 가장 안쪽 3 차원의 사이즈로부터 계산되어 &lt;code&gt;input&lt;/code&gt; . &lt;code&gt;input&lt;/code&gt; 계산에 사용 된 FFT 길이 가 홀수이면 제대로 추론 할 수 없으므로 입력 해야합니다.</target>
        </trans-unit>
        <trans-unit id="66227bf2a70d8c8a13c900791ef88cd485b7b62a" translate="yes" xml:space="preserve">
          <source>The inner-most dimension of &lt;code&gt;input&lt;/code&gt; is assumed to be the result of &lt;code&gt;RFFT&lt;/code&gt;: the &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; unique components of the DFT of a real-valued signal. If &lt;code&gt;fft_length&lt;/code&gt; is not provided, it is computed from the size of the inner-most dimension of &lt;code&gt;input&lt;/code&gt; (&lt;code&gt;fft_length = 2 * (inner - 1)&lt;/code&gt;). If the FFT length used to compute &lt;code&gt;input&lt;/code&gt; is odd, it should be provided since it cannot be inferred properly.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 가장 안쪽 차원은 &lt;code&gt;RFFT&lt;/code&gt; 의 결과 인 것으로 가정합니다 . &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; 실수 값 신호의 DFT 고유 성분. 경우 &lt;code&gt;fft_length&lt;/code&gt; 가 제공되지 않고, 그것의 가장 안쪽 치수의 사이즈로부터 계산되어 &lt;code&gt;input&lt;/code&gt; ( &lt;code&gt;fft_length = 2 * (inner - 1)&lt;/code&gt; ). &lt;code&gt;input&lt;/code&gt; 계산에 사용 된 FFT 길이 가 홀수이면 제대로 추론 할 수 없으므로 입력 해야합니다.</target>
        </trans-unit>
        <trans-unit id="bb19a900483721ea4e289126af04d4611c3ccdec" translate="yes" xml:space="preserve">
          <source>The innermost &lt;code&gt;values&lt;/code&gt; array for this ragged tensor value.</source>
          <target state="translated">이 울퉁불퉁 한 텐서 값 의 가장 안쪽 &lt;code&gt;values&lt;/code&gt; 배열입니다.</target>
        </trans-unit>
        <trans-unit id="be345c7ea127005969c68124a7827e30c5e6f496" translate="yes" xml:space="preserve">
          <source>The innermost &lt;code&gt;values&lt;/code&gt; tensor for this ragged tensor.</source>
          <target state="translated">가장 안쪽 &lt;code&gt;values&lt;/code&gt; 이 너덜 너덜 텐서에 대한 텐서.</target>
        </trans-unit>
        <trans-unit id="f25a7f282e145204d03b73aafeaa7a9ae16b013a" translate="yes" xml:space="preserve">
          <source>The innermost dimension of &lt;code&gt;indices&lt;/code&gt; (with length &lt;code&gt;K&lt;/code&gt;) corresponds to indices into elements (if &lt;code&gt;K = P&lt;/code&gt;) or slices (if &lt;code&gt;K &amp;lt; P&lt;/code&gt;) along the &lt;code&gt;K&lt;/code&gt;th dimension of &lt;code&gt;ref&lt;/code&gt;.</source>
          <target state="translated">가장 긴 &lt;code&gt;indices&lt;/code&gt; 길이 (길이 &lt;code&gt;K&lt;/code&gt; ) 는 &lt;code&gt;ref&lt;/code&gt; 의 &lt;code&gt;K&lt;/code&gt; 번째 차원을 따라 요소 ( &lt;code&gt;K = P&lt;/code&gt; ) 또는 슬라이스 ( &lt;code&gt;K &amp;lt; P&lt;/code&gt; 경우)의 인덱스에 해당합니다 .</target>
        </trans-unit>
        <trans-unit id="5e89d3b63e4cb6ebffdeb167da39f2e0f1f1c9d2" translate="yes" xml:space="preserve">
          <source>The innermost dimension of &lt;code&gt;indices&lt;/code&gt; (with length &lt;code&gt;K&lt;/code&gt;) corresponds to indices into elements (if &lt;code&gt;K = P&lt;/code&gt;) or slices (if &lt;code&gt;K &amp;lt; P&lt;/code&gt;) along the &lt;code&gt;K&lt;/code&gt;th dimension of self.</source>
          <target state="translated">가장 안쪽 치수 &lt;code&gt;indices&lt;/code&gt; (길이와 &lt;code&gt;K&lt;/code&gt; 요소의 인덱스에 대응) (만약 &lt;code&gt;K = P&lt;/code&gt; ) 또는 조각 (경우 &lt;code&gt;K &amp;lt; P&lt;/code&gt; 따라) &lt;code&gt;K&lt;/code&gt; 자기 번째 차원.</target>
        </trans-unit>
        <trans-unit id="7e7a91084b5b310e293a78ea32ab3d511383ccff" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;SparseTensor&lt;/code&gt; must be in row-major order.</source>
          <target state="translated">입력 &lt;code&gt;SparseTensor&lt;/code&gt; 는 행 주요 순서 여야합니다.</target>
        </trans-unit>
        <trans-unit id="559dc2e144980c6b2098537801cec29d9fedba3c" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;SparseTensor&lt;/code&gt; objects' indices are assumed ordered in standard lexicographic order. If this is not the case, after this step run &lt;a href=&quot;../sparse/reorder&quot;&gt;&lt;code&gt;sparse.reorder&lt;/code&gt;&lt;/a&gt; to restore index ordering.</source>
          <target state="translated">입력 &lt;code&gt;SparseTensor&lt;/code&gt; 오브젝트의 색인은 표준 사전 사전 순으로 정렬됩니다. 그렇지 않은 경우이 단계 후에 &lt;a href=&quot;../sparse/reorder&quot;&gt; &lt;code&gt;sparse.reorder&lt;/code&gt; &lt;/a&gt; 를 실행 하여 인덱스 순서를 복원하십시오.</target>
        </trans-unit>
        <trans-unit id="56bbf31df5c3f0a722000a2eadd2da99c153bf4d" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;serialized_sparse&lt;/code&gt; must be a string matrix of shape &lt;code&gt;[N x 3]&lt;/code&gt; where &lt;code&gt;N&lt;/code&gt; is the minibatch size and the rows correspond to packed outputs of &lt;code&gt;serialize_sparse&lt;/code&gt;. The ranks of the original &lt;code&gt;SparseTensor&lt;/code&gt; objects must all match. When the final &lt;code&gt;SparseTensor&lt;/code&gt; is created, it has rank one higher than the ranks of the incoming &lt;code&gt;SparseTensor&lt;/code&gt; objects (they have been concatenated along a new row dimension).</source>
          <target state="translated">입력 &lt;code&gt;serialized_sparse&lt;/code&gt; 는 &lt;code&gt;[N x 3]&lt;/code&gt; 모양의 문자열 행렬이어야합니다 . 여기서 &lt;code&gt;N&lt;/code&gt; 은 미니 배치 크기이고 행은 &lt;code&gt;serialize_sparse&lt;/code&gt; 의 압축 된 출력에 해당합니다 . 원본 &lt;code&gt;SparseTensor&lt;/code&gt; 객체 의 순위 가 모두 일치해야합니다. 최종 &lt;code&gt;SparseTensor&lt;/code&gt; 가 작성 될 때 수신 &lt;code&gt;SparseTensor&lt;/code&gt; 오브젝트 의 순위보다 하나 더 높은 순위를 갖습니다 (새 행 차원을 따라 연결됨).</target>
        </trans-unit>
        <trans-unit id="d39dc101c55542dec858072079860af67df42d8f" translate="yes" xml:space="preserve">
          <source>The input can be supplied in various formats: &lt;code&gt;matrix&lt;/code&gt;, &lt;code&gt;sequence&lt;/code&gt; and &lt;code&gt;compact&lt;/code&gt;, specified by the &lt;code&gt;diagonals_format&lt;/code&gt; arg.</source>
          <target state="translated">입력은 &lt;code&gt;matrix&lt;/code&gt; s , &lt;code&gt;sequence&lt;/code&gt; 및 &lt;code&gt;compact&lt;/code&gt; 의 다양한 형식으로 제공 될 수 있습니다 ( &lt;code&gt;diagonals_format&lt;/code&gt; _ 형식 arg에 의해 지정됨) .</target>
        </trans-unit>
        <trans-unit id="7a3aea890ab7c25d251475a5c0c175df4fead28f" translate="yes" xml:space="preserve">
          <source>The input data can be padded on both the start and end of the sequence, if desired, using the &lt;code&gt;pad_values&lt;/code&gt; argument. If set, &lt;code&gt;pad_values&lt;/code&gt; should contain either a tuple of strings or a single string; the 0th element of the tuple will be used to pad the left side of the sequence and the 1st element of the tuple will be used to pad the right side of the sequence. The &lt;code&gt;padding_width&lt;/code&gt; arg controls how many padding values are added to each side; it defaults to &lt;code&gt;ngram_width-1&lt;/code&gt;.</source>
          <target state="translated">원하는 경우 &lt;code&gt;pad_values&lt;/code&gt; 인수를 사용하여 입력 데이터를 시퀀스의 시작과 끝 모두에 채울 수 있습니다. 설정된 경우 &lt;code&gt;pad_values&lt;/code&gt; 는 튜플 문자열 또는 단일 문자열을 포함해야합니다. 튜플의 0 번째 요소는 시퀀스의 왼쪽을 채우는 데 사용되고 튜플의 첫 번째 요소는 시퀀스의 오른쪽을 채우는 데 사용됩니다. &lt;code&gt;padding_width&lt;/code&gt; 많은 패딩 값은 각면에 첨가하는 방법 ARG 제어; 기본값은 &lt;code&gt;ngram_width-1&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="3483a88e5028197c2c707cc3c8c51e5ba5c5cc43" translate="yes" xml:space="preserve">
          <source>The input has to be invertible.</source>
          <target state="translated">입력은 뒤집을 수 없어야합니다.</target>
        </trans-unit>
        <trans-unit id="6cb547f4554af98d950886c485fb31114efae486" translate="yes" xml:space="preserve">
          <source>The input has to be symmetric and positive definite. Only the lower-triangular part of the input will be used for this operation. The upper-triangular part will not be read.</source>
          <target state="translated">입력은 대칭적이고 양의 한정이어야합니다. 이 작업에는 입력의 삼각 삼각 부분 만 사용됩니다. 상단 삼각 부분은 읽히지 않습니다.</target>
        </trans-unit>
        <trans-unit id="9ab6f7a1383accb84e03cfc01fbf2de71cc3ce58" translate="yes" xml:space="preserve">
          <source>The input is a string tensor of any shape. The output is a string tensor of the same shape containing the transcoded strings. Output strings are always valid unicode. If the input contains invalid encoding positions, the &lt;code&gt;errors&lt;/code&gt; attribute sets the policy for how to deal with them. If the default error-handling policy is used, invalid formatting will be substituted in the output by the &lt;code&gt;replacement_char&lt;/code&gt;. If the errors policy is to &lt;code&gt;ignore&lt;/code&gt;, any invalid encoding positions in the input are skipped and not included in the output. If it set to &lt;code&gt;strict&lt;/code&gt; then any invalid formatting will result in an InvalidArgument error.</source>
          <target state="translated">입력은 모든 모양의 문자열 텐서입니다. 출력은 코드 변환 된 문자열을 포함하는 동일한 모양의 문자열 텐서입니다. 출력 문자열은 항상 유효한 유니 코드입니다. 입력에 유효하지 않은 인코딩 위치가 포함 된 경우 &lt;code&gt;errors&lt;/code&gt; 속성은 해당 위치 를 처리하는 방법에 대한 정책을 설정합니다. 기본 오류 처리 정책을 사용하면 &lt;code&gt;replacement_char&lt;/code&gt; 의 출력에서 ​​유효하지 않은 형식이 대체 됩니다. 오류 정책이 &lt;code&gt;ignore&lt;/code&gt; 인 경우 입력의 유효하지 않은 인코딩 위치는 건너 뛰고 출력에 포함되지 않습니다. &lt;code&gt;strict&lt;/code&gt; 설정 하면 유효하지 않은 형식으로 인해 InvalidArgument 오류가 발생합니다.</target>
        </trans-unit>
        <trans-unit id="f41ed33e18d35e0df944af43170682bbfbe88dab" translate="yes" xml:space="preserve">
          <source>The input is a string tensor of any shape. The pattern is a scalar string tensor which is applied to every element of the input tensor. The boolean values (True or False) of the output tensor indicate if the input matches the regex pattern provided.</source>
          <target state="translated">입력은 모든 모양의 문자열 텐서입니다. 패턴은 입력 텐서의 모든 요소에 적용되는 스칼라 문자열 텐서입니다. 출력 텐서의 부울 값 (True 또는 False)은 입력이 제공된 정규식 패턴과 일치하는지 여부를 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="a49b12f6890eee0fa5006296181dd36a3c0eae12" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices.</source>
          <target state="translated">입력은 &lt;code&gt;[..., M, M]&lt;/code&gt; 모양의 텐서 로 가장 안쪽의 2 차원이 정사각 행렬을 형성합니다.</target>
        </trans-unit>
        <trans-unit id="4a95ccad7688f828b4538240858954215386b157" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices. The output is a tensor containing the determinants for all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;.</source>
          <target state="translated">입력은 &lt;code&gt;[..., M, M]&lt;/code&gt; 모양의 텐서 로 가장 안쪽의 2 차원이 정사각 행렬을 형성합니다. 출력은 모든 입력 하위 행렬 &lt;code&gt;[..., :, :]&lt;/code&gt; 의 결정자를 포함하는 텐서 입니다.</target>
        </trans-unit>
        <trans-unit id="bb52980da5474b532e1e714b4de037ffa27b4127" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices. The output is a tensor of the same shape as the input containing the exponential for all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;.</source>
          <target state="translated">입력은 &lt;code&gt;[..., M, M]&lt;/code&gt; 모양의 텐서 로 가장 안쪽의 2 차원이 정사각 행렬을 형성합니다. 출력은 모든 입력 하위 행렬 &lt;code&gt;[..., :, :]&lt;/code&gt; 의 지수를 포함하는 입력과 동일한 모양의 텐서입니다 .</target>
        </trans-unit>
        <trans-unit id="72c07ff69dfab5a23cee03f8eae86a2093c70b45" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices. The output is a tensor of the same shape as the input containing the inverse for all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;.</source>
          <target state="translated">입력은 &lt;code&gt;[..., M, M]&lt;/code&gt; 모양의 텐서 로 가장 안쪽의 2 차원이 정사각 행렬을 형성합니다. 출력은 모든 입력 하위 행렬 &lt;code&gt;[..., :, :]&lt;/code&gt; 대한 역함수를 포함하는 입력과 동일한 모양의 텐서입니다 .</target>
        </trans-unit>
        <trans-unit id="f84ae4c58a555dd2a241282a825d52ffb2a896e6" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices. The output is a tensor of the same shape as the input containing the matrix square root for all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;.</source>
          <target state="translated">입력은 &lt;code&gt;[..., M, M]&lt;/code&gt; 모양의 텐서 로 가장 안쪽의 2 차원이 정사각 행렬을 형성합니다. 출력은 모든 입력 하위 행렬 &lt;code&gt;[..., :, :]&lt;/code&gt; 대한 행렬 제곱근을 포함하는 입력과 동일한 모양의 텐서입니다 .</target>
        </trans-unit>
        <trans-unit id="a47976575bd700d1896c1a9ad76ef8970d05df43" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[N, M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices. The outputs are two tensors containing the signs and absolute values of the log determinants for all N input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt; such that the determinant = sign&lt;em&gt;exp(log_abs_determinant). The log_abs_determinant is computed as det(P)&lt;/em&gt;sum(log(diag(LU))) where LU is the LU decomposition of the input and P is the corresponding permutation matrix.</source>
          <target state="translated">입력은 가장 안쪽 2 차원이 정사각 행렬을 형성 하는 모양 &lt;code&gt;[N, M, M]&lt;/code&gt; 의 텐서입니다 . 출력은 결정자 = 부호 &lt;em&gt;exp (log_abs_determinant)가되도록&lt;/em&gt; 모든 N 개의 입력 하위 행렬 &lt;code&gt;[..., :, :]&lt;/code&gt; 에 대한 로그 결정자의 부호와 절대 값을 포함하는 두 개의 텐서 &lt;em&gt;입니다. log_abs_determinant는 det (P)&lt;/em&gt; sum (log (diag (LU)))로 &lt;em&gt;계산됩니다.&lt;/em&gt; 여기서 LU는 입력의 LU 분해이고 P는 해당 순열 행렬입니다.</target>
        </trans-unit>
        <trans-unit id="16509370e9a14e359dbc8b8062b8734116aafda6" translate="yes" xml:space="preserve">
          <source>The input matrix should be invertible. If the input matrix is real, it should have no eigenvalues which are real and negative (pairs of complex conjugate eigenvalues are allowed).</source>
          <target state="translated">입력 매트릭스는 뒤집을 수 없어야합니다. 입력 행렬이 실수 인 경우 실수와 음수 인 고유 값이 없어야합니다 (복소수 복소수 고유 값 쌍이 허용됨).</target>
        </trans-unit>
        <trans-unit id="b4fb5738c7b407c21bcad2cacc1ef5ec4dff9b6d" translate="yes" xml:space="preserve">
          <source>The input must be at least a matrix.</source>
          <target state="translated">입력은 적어도 행렬이어야합니다.</target>
        </trans-unit>
        <trans-unit id="3c4f7bbe843d34cb236ccedebe4df570c214e3da" translate="yes" xml:space="preserve">
          <source>The input pipeline checkpoint may be large, if there are large shuffle or prefetch buffers for instance, and may bloat the checkpoint size.</source>
          <target state="translated">예를 들어 큰 셔플 또는 프리 페치 버퍼가있는 경우 입력 파이프 라인 검사 점이 크며 검사 점 크기가 커질 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="0bf2cfde9a379c9cc0a2626ec6eaa414e577c963" translate="yes" xml:space="preserve">
          <source>The input samples are processed batch by batch.</source>
          <target state="translated">입력 샘플은 배치별로 처리됩니다.</target>
        </trans-unit>
        <trans-unit id="db9e617ad287d3e54cdcc5d77f3a84dc0ecefefc" translate="yes" xml:space="preserve">
          <source>The input should be at least 3D, and the dimension of index one will be considered to be the temporal dimension.</source>
          <target state="translated">입력 값은 3D 이상이어야하며 인덱스 1의 차원은 시간 차원으로 간주됩니다.</target>
        </trans-unit>
        <trans-unit id="4a7245281a652bfbac8628bc44c29674340d8332" translate="yes" xml:space="preserve">
          <source>The input signature of &lt;code&gt;map_func&lt;/code&gt; is determined by the structure of each element in this dataset.</source>
          <target state="translated">&lt;code&gt;map_func&lt;/code&gt; 의 입력 서명은 이 데이터 세트의 각 요소 구조에 의해 결정됩니다.</target>
        </trans-unit>
        <trans-unit id="1a4202e509f04a4e2e240929b7033cbd28325042" translate="yes" xml:space="preserve">
          <source>The input tensor (potentially converted to a &lt;code&gt;Tensor&lt;/code&gt;).</source>
          <target state="translated">입력 텐서 (잠재적으로 &lt;code&gt;Tensor&lt;/code&gt; 로 변환 됨 )</target>
        </trans-unit>
        <trans-unit id="f1339cf26956739f44025e7d445e29017a72d735" translate="yes" xml:space="preserve">
          <source>The input tensor can now be quantized by clipping values to the range &lt;code&gt;min_range&lt;/code&gt; to &lt;code&gt;max_range&lt;/code&gt;, then multiplying by scale_factor as follows:</source>
          <target state="translated">입력 텐서는 이제 &lt;code&gt;min_range&lt;/code&gt; ~ &lt;code&gt;max_range&lt;/code&gt; 범위로 값을 클리핑 한 다음 다음과 같이 scale_factor를 곱하여 양자화 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="de4692e0721f2fcc2ac3eb25677f89cdae882775" translate="yes" xml:space="preserve">
          <source>The input tensor's height and width must be divisible by block_size.</source>
          <target state="translated">입력 텐서의 높이와 너비는 block_size로 나눌 수 있어야합니다.</target>
        </trans-unit>
        <trans-unit id="8bd030040de18dc6a388054f2ae79e10c262d194" translate="yes" xml:space="preserve">
          <source>The input tensors &lt;code&gt;real&lt;/code&gt; and &lt;code&gt;imag&lt;/code&gt; must have the same shape.</source>
          <target state="translated">입력 텐서 &lt;code&gt;real&lt;/code&gt; 과 &lt;code&gt;imag&lt;/code&gt; 는 같은 모양이어야합니다.</target>
        </trans-unit>
        <trans-unit id="aa6b1cb251ad12bc98e4df6e1fe21cc0d8438940" translate="yes" xml:space="preserve">
          <source>The input tensors &lt;code&gt;starts&lt;/code&gt;, &lt;code&gt;limits&lt;/code&gt;, and &lt;code&gt;deltas&lt;/code&gt; may be scalars or vectors. The vector inputs must all have the same size. Scalar inputs are broadcast to match the size of the vector inputs.</source>
          <target state="translated">입력 텐서 &lt;code&gt;starts&lt;/code&gt; , &lt;code&gt;limits&lt;/code&gt; 및 &lt;code&gt;deltas&lt;/code&gt; 는 스칼라 또는 벡터 일 수 있습니다. 벡터 입력은 모두 같은 크기 여야합니다. 스칼라 입력은 벡터 입력의 크기와 일치하도록 브로드 캐스트됩니다.</target>
        </trans-unit>
        <trans-unit id="d39bc5c493315c0c2bb73635f284f6d3773b3fe6" translate="yes" xml:space="preserve">
          <source>The inputs and arguments of these functions both use an instance of the class so they can have independent numbering.</source>
          <target state="translated">이 함수의 입력과 인수는 모두 클래스의 인스턴스를 사용하므로 독립적 인 번호 매기기를 가질 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="d0798e60c9a60a309c2780811ed22bf523e44034" translate="yes" xml:space="preserve">
          <source>The inputs are quantized tensors where the lowest value represents the real number of the associated minimum, and the highest represents the maximum. This means that you can only interpret the quantized output in the same way, by taking the returned minimum and maximum values into account.</source>
          <target state="translated">입력 값은 양자화 된 텐서이며, 가장 낮은 값은 연관된 최소값의 실수를 나타내고 가장 높은 값은 최대 값을 나타냅니다. 즉, 반환 된 최소값과 최대 값을 고려하여 양자화 된 출력 만 동일한 방식으로 해석 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="af76f45e776e3f0a5b635d397e36c82661d856e8" translate="yes" xml:space="preserve">
          <source>The inputs must be two-dimensional matrices and the inner dimension of &quot;a&quot; must match the outer dimension of &quot;b&quot;. Both &quot;a&quot; and &quot;b&quot; must be &lt;code&gt;Tensor&lt;/code&gt;s not &lt;code&gt;SparseTensor&lt;/code&gt;s. This op is optimized for the case where at least one of &quot;a&quot; or &quot;b&quot; is sparse, in the sense that they have a large proportion of zero values. The breakeven for using this versus a dense matrix multiply on one platform was 30% zero values in the sparse matrix.</source>
          <target state="translated">입력 값은 2 차원 행렬이어야하고 &quot;a&quot;의 내부 차원은 &quot;b&quot;의 외부 차원과 일치해야합니다. &quot;a&quot;와 &quot;b&quot;는 모두 &lt;code&gt;SparseTensor&lt;/code&gt; 가 아닌 &lt;code&gt;Tensor&lt;/code&gt; 여야합니다 . 이 op는 &quot;a&quot;또는 &quot;b&quot;중 하나 이상이 0 인 값이 크다는 점에서 드문 경우에 최적화됩니다. 하나의 플랫폼에서 이것을 밀도 행렬에 곱하기위한 손익분기는 희소 행렬에서 30 % 0 값이었습니다.</target>
        </trans-unit>
        <trans-unit id="851dd7f69bc57652716eb3a5a344fc6b5525127d" translate="yes" xml:space="preserve">
          <source>The inputs must, following any transpositions, be tensors of rank &amp;gt;= 2 where the inner 2 dimensions specify valid matrix multiplication dimensions, and any further outer dimensions specify matching batch size.</source>
          <target state="translated">입력은 모든 전치 다음에 랭크&amp;gt; = 2의 텐서 여야합니다. 여기서 내부 2 차원은 유효한 행렬 곱셈 차원을 지정하고 추가 외부 차원은 일치하는 배치 크기를 지정합니다.</target>
        </trans-unit>
        <trans-unit id="ea6567bbb82a2153b18593d35fddb52d49ff3e46" translate="yes" xml:space="preserve">
          <source>The inputs represent an N-D SparseTensor with logical shape &lt;code&gt;[..., B, C]&lt;/code&gt; (where &lt;code&gt;N &amp;gt;= 2&lt;/code&gt;), and with indices sorted in the canonical lexicographic order.</source>
          <target state="translated">입력 값은 논리적 모양 &lt;code&gt;[..., B, C]&lt;/code&gt; (여기서 &lt;code&gt;N &amp;gt;= 2&lt;/code&gt; )이며 표준 사전 사전 순으로 정렬 된 ND SparseTensor를 나타냅니다 .</target>
        </trans-unit>
        <trans-unit id="786b18b1428c9b9d0c0ea9b230ad273866de4e7c" translate="yes" xml:space="preserve">
          <source>The integer error code that describes the error.</source>
          <target state="translated">오류를 설명하는 정수 오류 코드입니다.</target>
        </trans-unit>
        <trans-unit id="1f081e7633128ce109e045c67ad35e5e5ed00d6f" translate="yes" xml:space="preserve">
          <source>The intent of this library is that you can write an algorithm in a stylized way and it will be usable with a variety of different &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; implementations. Each descendant will implement a different strategy for distributing the algorithm across multiple devices/machines. Furthermore, these changes can be hidden inside the specific layers and other library classes that need special treatment to run in a distributed setting, so that most users' model definition code can run unchanged. The &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; API works the same way with eager and graph execution.</source>
          <target state="translated">이 라이브러리의 목적은 양식화 된 방식으로 알고리즘을 작성할 수 있으며 다양한 다른 &lt;a href=&quot;../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; 구현에서 사용할 수 있다는 것입니다. 각 자손은 여러 장치 / 기계에 알고리즘을 배포하기위한 다른 전략을 구현합니다. 또한 이러한 변경 사항은 분산 설정에서 실행하기 위해 특별한 처리가 필요한 특정 계층 및 기타 라이브러리 클래스 안에 숨겨져 대부분의 사용자 모델 정의 코드가 변경없이 실행될 수 있습니다. &lt;a href=&quot;../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; API 열망과 그래프 실행과 같은 방식으로 작동합니다.</target>
        </trans-unit>
        <trans-unit id="88afca652283c5de09f863feb56ef262251ef585" translate="yes" xml:space="preserve">
          <source>The intent of this library is that you can write an algorithm in a stylized way and it will be usable with a variety of different &lt;a href=&quot;distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; implementations. Each descendant will implement a different strategy for distributing the algorithm across multiple devices/machines. Furthermore, these changes can be hidden inside the specific layers and other library classes that need special treatment to run in a distributed setting, so that most users' model definition code can run unchanged. The &lt;a href=&quot;distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; API works the same way with eager and graph execution.</source>
          <target state="translated">이 라이브러리의 목적은 양식화 된 방식으로 알고리즘을 작성할 수 있으며 다양한 다른 &lt;a href=&quot;distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; 구현에서 사용할 수 있다는 것입니다. 각 자손은 여러 장치 / 기계에 알고리즘을 배포하기위한 다른 전략을 구현합니다. 또한 이러한 변경 사항은 분산 설정에서 실행하기 위해 특별한 처리가 필요한 특정 계층 및 기타 라이브러리 클래스 안에 숨겨져 대부분의 사용자 모델 정의 코드가 변경없이 실행될 수 있습니다. &lt;a href=&quot;distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; API 열망과 그래프 실행과 같은 방식으로 작동합니다.</target>
        </trans-unit>
        <trans-unit id="bf691a6e4942a79a3eb610931eed1d4815c80c50" translate="yes" xml:space="preserve">
          <source>The internal state of the RNG.</source>
          <target state="translated">RNG의 내부 상태</target>
        </trans-unit>
        <trans-unit id="f4e9fea1c0c7520b3774550dafc300a0edeccb05" translate="yes" xml:space="preserve">
          <source>The inverse of fftshift.</source>
          <target state="translated">fftshift의 역수.</target>
        </trans-unit>
        <trans-unit id="6f58aa3901c7e60d466c168f7dbe6f460db432cc" translate="yes" xml:space="preserve">
          <source>The iterator only checks for new checkpoints when control flow has been reverted to it. This means it can miss checkpoints if your code takes longer to run between iterations than &lt;code&gt;min_interval_secs&lt;/code&gt; or the interval at which new checkpoints are written.</source>
          <target state="translated">반복자는 제어 플로우가 되돌려 졌을 때 새로운 체크 포인트 만 점검합니다. 즉, 코드가 &lt;code&gt;min_interval_secs&lt;/code&gt; 보다 반복 하거나 새 검사 점이 작성되는 간격 동안 실행하는 데 시간이 오래 걸리면 검사 점이 누락 될 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="751b0fbfa4aeea2c579ce7d09f30705a335965fb" translate="yes" xml:space="preserve">
          <source>The key and value content to get from each line is specified by the &lt;code&gt;key_index&lt;/code&gt; and &lt;code&gt;value_index&lt;/code&gt;.</source>
          <target state="translated">각 행에서 가져올 키 및 값 컨텐츠는 &lt;code&gt;key_index&lt;/code&gt; 및 &lt;code&gt;value_index&lt;/code&gt; 로 지정됩니다 .</target>
        </trans-unit>
        <trans-unit id="e732a302356fd06e3da95b03500ebf97f84d0506" translate="yes" xml:space="preserve">
          <source>The key and value content to get from each line is specified either by the following, or a value &lt;code&gt;&amp;gt;=0&lt;/code&gt;.</source>
          <target state="translated">각 줄에서 가져올 키 및 값 내용은 다음에 의해 지정되거나 &lt;code&gt;&amp;gt;=0&lt;/code&gt; 값으로 지정됩니다 .</target>
        </trans-unit>
        <trans-unit id="c0771e36c5a66ef95bdba36fa510d228d752d2d4" translate="yes" xml:space="preserve">
          <source>The key and value content to get from each line.</source>
          <target state="translated">각 줄에서 가져올 키 및 값 내용.</target>
        </trans-unit>
        <trans-unit id="b464317f2f49a3771499c8be27b73752b57cff0e" translate="yes" xml:space="preserve">
          <source>The key and value type of the table to initialize is given by &lt;code&gt;key_dtype&lt;/code&gt; and &lt;code&gt;value_dtype&lt;/code&gt;.</source>
          <target state="translated">초기화 할 테이블의 키 및 값 유형은 &lt;code&gt;key_dtype&lt;/code&gt; 및 &lt;code&gt;value_dtype&lt;/code&gt; 에 의해 제공됩니다 .</target>
        </trans-unit>
        <trans-unit id="f2cb43e5a33cda57c35ab173bdca64268dd6064f" translate="yes" xml:space="preserve">
          <source>The last &lt;code&gt;concentration&lt;/code&gt; dimension parametrizes a single Dirichlet-Multinomial distribution. When calling distribution functions (e.g., &lt;code&gt;dist.prob(counts)&lt;/code&gt;), &lt;code&gt;concentration&lt;/code&gt;, &lt;code&gt;total_count&lt;/code&gt; and &lt;code&gt;counts&lt;/code&gt; are broadcast to the same shape. The last dimension of &lt;code&gt;counts&lt;/code&gt; corresponds single Dirichlet-Multinomial distributions.</source>
          <target state="translated">마지막 &lt;code&gt;concentration&lt;/code&gt; 치수는 단일 Dirichlet-Multinomial 분포를 매개 변수화합니다. 분포 함수 (예 : &lt;code&gt;dist.prob(counts)&lt;/code&gt; )를 호출 할 때 &lt;code&gt;concentration&lt;/code&gt; , &lt;code&gt;total_count&lt;/code&gt; 및 &lt;code&gt;counts&lt;/code&gt; 는 동일한 모양으로 브로드 캐스트됩니다. &lt;code&gt;counts&lt;/code&gt; 의 마지막 차원은 단일 Dirichlet-Multinomial 분포에 해당합니다.</target>
        </trans-unit>
        <trans-unit id="78cc8d00f8e7491129a68b99d8285b81a0423488" translate="yes" xml:space="preserve">
          <source>The last dimension of &lt;code&gt;indices&lt;/code&gt; can be at most the rank of &lt;code&gt;params&lt;/code&gt;:</source>
          <target state="translated">&lt;code&gt;indices&lt;/code&gt; 의 마지막 차원은 최대 &lt;code&gt;params&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ecdf342100af669eb1e5196eae29b7087572c686" translate="yes" xml:space="preserve">
          <source>The last dimension of &lt;code&gt;indices&lt;/code&gt; corresponds to elements (if &lt;code&gt;indices.shape[-1] == params.rank&lt;/code&gt;) or slices (if &lt;code&gt;indices.shape[-1] &amp;lt; params.rank&lt;/code&gt;) along dimension &lt;code&gt;indices.shape[-1]&lt;/code&gt; of &lt;code&gt;params&lt;/code&gt;. The output tensor has shape</source>
          <target state="translated">&lt;code&gt;indices&lt;/code&gt; 의 마지막 차원 은 &lt;code&gt;params&lt;/code&gt; &lt;code&gt;indices.shape[-1]&lt;/code&gt; 차원을 따라 요소 ( &lt;code&gt;indices.shape[-1] == params.rank&lt;/code&gt; ) 또는 슬라이스 ( &lt;code&gt;indices.shape[-1] &amp;lt; params.rank&lt;/code&gt; )에 해당합니다. . 출력 텐서 모양</target>
        </trans-unit>
        <trans-unit id="286ceed5a9e73c8174db8660f8e7395f9150777f" translate="yes" xml:space="preserve">
          <source>The last dimension of &lt;code&gt;indices&lt;/code&gt; corresponds to indices into elements (if &lt;code&gt;indices.shape[-1] = shape.rank&lt;/code&gt;) or slices (if &lt;code&gt;indices.shape[-1] &amp;lt; shape.rank&lt;/code&gt;) along dimension &lt;code&gt;indices.shape[-1]&lt;/code&gt; of &lt;code&gt;shape&lt;/code&gt;. &lt;code&gt;updates&lt;/code&gt; is a tensor with shape</source>
          <target state="translated">마지막의 치수 &lt;code&gt;indices&lt;/code&gt; 요소의 인덱스에 대응한다 (만약 &lt;code&gt;indices.shape[-1] = shape.rank&lt;/code&gt; ) 또는 조각 (만약 &lt;code&gt;indices.shape[-1] &amp;lt; shape.rank&lt;/code&gt; 차원을 따라) &lt;code&gt;indices.shape[-1]&lt;/code&gt; 의 &lt;code&gt;shape&lt;/code&gt; . &lt;code&gt;updates&lt;/code&gt; 는 모양이있는 텐서입니다.</target>
        </trans-unit>
        <trans-unit id="1334749bed79f5a39ed1f5844527d62a1a905c7c" translate="yes" xml:space="preserve">
          <source>The last dimension of &lt;code&gt;sp_input.indices&lt;/code&gt; is discarded and replaced with the values of &lt;code&gt;sp_input&lt;/code&gt;. If &lt;code&gt;sp_input.dense_shape = [D0, D1, ..., Dn, K]&lt;/code&gt;, then &lt;code&gt;output.shape = [D0, D1, ..., Dn, vocab_size]&lt;/code&gt;, where</source>
          <target state="translated">&lt;code&gt;sp_input.indices&lt;/code&gt; 의 마지막 차원 은 버리고 &lt;code&gt;sp_input&lt;/code&gt; 값으로 대체됩니다 . 만약 &lt;code&gt;sp_input.dense_shape = [D0, D1, ..., Dn, K]&lt;/code&gt; 다음 &lt;code&gt;output.shape = [D0, D1, ..., Dn, vocab_size]&lt;/code&gt; 여기서</target>
        </trans-unit>
        <trans-unit id="fbd03a9648fd276c59e057bf5a188513a3c7e179" translate="yes" xml:space="preserve">
          <source>The last three dimensions of input are expected to be [height, width, depth].</source>
          <target state="translated">입력의 마지막 3 차원은 [높이, 너비, 깊이] 일 것으로 예상됩니다.</target>
        </trans-unit>
        <trans-unit id="1d8c5a256ceb0281a5abfd9ab601681d1b6839bc" translate="yes" xml:space="preserve">
          <source>The learning phase flag is a bool tensor (0 = test, 1 = train) to be passed as input to any Keras function that uses a different behavior at train time and test time.</source>
          <target state="translated">학습 단계 플래그는 부울 텐서 (0 = 테스트, 1 = 기차)로, 기차 시간과 테스트 시간에 다른 동작을 사용하는 모든 Keras 함수에 입력으로 전달됩니다.</target>
        </trans-unit>
        <trans-unit id="a0a124fd12c8c65bb6844115fdf183c1b942c532" translate="yes" xml:space="preserve">
          <source>The learning phase gets restored to its original value upon exiting the scope.</source>
          <target state="translated">학습 단계는 범위를 종료하면 원래 값으로 복원됩니다.</target>
        </trans-unit>
        <trans-unit id="1de5c67a1eb0290c7057fa80ed33f8f702db5481" translate="yes" xml:space="preserve">
          <source>The learning rate multiplier first decays from 1 to &lt;code&gt;alpha&lt;/code&gt; for &lt;code&gt;first_decay_steps&lt;/code&gt; steps. Then, a warm restart is performed. Each new warm restart runs for &lt;code&gt;t_mul&lt;/code&gt; times more steps and with &lt;code&gt;m_mul&lt;/code&gt; times smaller initial learning rate.</source>
          <target state="translated">학습 속도 승수 는 &lt;code&gt;first_decay_steps&lt;/code&gt; 단계에 대해 먼저 1에서 &lt;code&gt;alpha&lt;/code&gt; 로 감소 합니다. 그런 다음 웜 재시작이 수행됩니다. 각각의 새로운 웜 리 스타트는 &lt;code&gt;t_mul&lt;/code&gt; 배 더 많은 단계와 &lt;code&gt;m_mul&lt;/code&gt; 배 더 작은 초기 학습 속도로 실행됩니다.</target>
        </trans-unit>
        <trans-unit id="28b092429ddde1497c6f3dfbaf3344b66f15e153" translate="yes" xml:space="preserve">
          <source>The learning rate schedule is also serializable and deserializable using &lt;a href=&quot;serialize&quot;&gt;&lt;code&gt;tf.keras.optimizers.schedules.serialize&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;deserialize&quot;&gt;&lt;code&gt;tf.keras.optimizers.schedules.deserialize&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">학습 속도 일정은 &lt;a href=&quot;serialize&quot;&gt; &lt;code&gt;tf.keras.optimizers.schedules.serialize&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;deserialize&quot;&gt; &lt;code&gt;tf.keras.optimizers.schedules.deserialize&lt;/code&gt; 를&lt;/a&gt; 사용하여 직렬화 가능하고 역 직렬화 가능 합니다.</target>
        </trans-unit>
        <trans-unit id="90bbcad1f9bed80766758a96fdfa14681f8c6dd6" translate="yes" xml:space="preserve">
          <source>The link flags.</source>
          <target state="translated">링크 플래그.</target>
        </trans-unit>
        <trans-unit id="eef29fe89c1421162e4e09274c7ca8daa2971972" translate="yes" xml:space="preserve">
          <source>The list is in arbitrary order. It does not contain the special entries &quot;.&quot; and &quot;..&quot;.</source>
          <target state="translated">목록은 임의의 순서입니다. 특수 항목 &quot;.&quot;을 포함하지 않습니다. 그리고 &quot;..&quot;.</target>
        </trans-unit>
        <trans-unit id="4fe2aa6417d3855190d90b82f9abd178eaf4e42b" translate="yes" xml:space="preserve">
          <source>The list of &lt;code&gt;Tensor&lt;/code&gt; objects representing the outputs of this op.</source>
          <target state="translated">이 op의 출력을 나타내는 &lt;code&gt;Tensor&lt;/code&gt; 객체 의 목록입니다 .</target>
        </trans-unit>
        <trans-unit id="72b9f570910bc85398790d90eea0b57ff816aa6f" translate="yes" xml:space="preserve">
          <source>The list of &lt;code&gt;Tensor&lt;/code&gt; objects unstacked from &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;value&lt;/code&gt; 에서 스택 해제 된 &lt;code&gt;Tensor&lt;/code&gt; 객체 의 목록입니다 .</target>
        </trans-unit>
        <trans-unit id="e1da5ffc250e1d720f6279716c9d6aade88b1077" translate="yes" xml:space="preserve">
          <source>The list of arguments not parsed as options, including argv[0].</source>
          <target state="translated">argv [0]을 포함하여 옵션으로 구문 분석되지 않은 인수 목록.</target>
        </trans-unit>
        <trans-unit id="7a2668eec12c1d3cf3f187776719d83faec8967b" translate="yes" xml:space="preserve">
          <source>The list of concatenated tensors that was dequeued.</source>
          <target state="translated">큐에서 분리 된 연결된 텐서 목록입니다.</target>
        </trans-unit>
        <trans-unit id="70e71f616ed088b5e1a5217c440dcc82210678f0" translate="yes" xml:space="preserve">
          <source>The list of dtypes for each component of a queue element.</source>
          <target state="translated">큐 요소의 각 구성 요소에 대한 dtype 목록입니다.</target>
        </trans-unit>
        <trans-unit id="bfa264d47e9935a6a337f111d8bbcf3f713d945a" translate="yes" xml:space="preserve">
          <source>The list of names for each component of a queue element.</source>
          <target state="translated">큐 요소의 각 구성 요소에 대한 이름 목록입니다.</target>
        </trans-unit>
        <trans-unit id="afc23fa1ddc71634846115e66b755cdfe5e1dce3" translate="yes" xml:space="preserve">
          <source>The list of shapes for each component of a queue element.</source>
          <target state="translated">큐 요소의 각 구성 요소에 대한 모양 목록입니다.</target>
        </trans-unit>
        <trans-unit id="39c799e61ec6d452a92b2f433fe078d01b37f5db" translate="yes" xml:space="preserve">
          <source>The list of threads started for the &lt;code&gt;QueueRunners&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;QueueRunners&lt;/code&gt; 에 대해 시작된 스레드 목록입니다 .</target>
        </trans-unit>
        <trans-unit id="17c761809240285ed679e6893972139bfc169439" translate="yes" xml:space="preserve">
          <source>The list of values in the collection with the given &lt;code&gt;name&lt;/code&gt;, or an empty list if no value has been added to that collection.</source>
          <target state="translated">주어진 &lt;code&gt;name&lt;/code&gt; 을 가진 컬렉션의 값 목록 또는 해당 컬렉션에 값이 추가되지 않은 경우 빈 목록.</target>
        </trans-unit>
        <trans-unit id="88981d3f5cd5ac5b5640b8a47ed0e63488d7e59c" translate="yes" xml:space="preserve">
          <source>The list of values in the collection with the given &lt;code&gt;name&lt;/code&gt;, or an empty list if no value has been added to that collection. Note that this returns the collection list itself, which can be modified in place to change the collection.</source>
          <target state="translated">주어진 &lt;code&gt;name&lt;/code&gt; 을 가진 컬렉션의 값 목록 또는 해당 컬렉션에 값이 추가되지 않은 경우 빈 목록. 이렇게하면 컬렉션 목록 자체가 반환되며 컬렉션을 변경하기 위해 수정 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="d9ede6fcf47022786b23b7b18ee2bcbd80557011" translate="yes" xml:space="preserve">
          <source>The list of values in the collection with the given &lt;code&gt;name&lt;/code&gt;, or an empty list if no value has been added to that collection. The list contains the values in the order under which they were collected.</source>
          <target state="translated">주어진 &lt;code&gt;name&lt;/code&gt; 을 가진 컬렉션의 값 목록 또는 해당 컬렉션에 값이 추가되지 않은 경우 빈 목록. 이 목록에는 수집 된 순서대로 값이 포함됩니다.</target>
        </trans-unit>
        <trans-unit id="7016678a2375c9753e8eaf54d3415095320d885f" translate="yes" xml:space="preserve">
          <source>The locations represented by indices in &lt;code&gt;indices&lt;/code&gt; take value &lt;code&gt;on_value&lt;/code&gt;, while all other locations take value &lt;code&gt;off_value&lt;/code&gt;.</source>
          <target state="translated">인덱스에서 &lt;code&gt;indices&lt;/code&gt; 표시되는 위치는 &lt;code&gt;on_value&lt;/code&gt; 값 을 사용하고 다른 모든 위치는 &lt;code&gt;off_value&lt;/code&gt; 값을 사용 합니다.</target>
        </trans-unit>
        <trans-unit id="3d12a72f932ac01058fe17db625020a638310386" translate="yes" xml:space="preserve">
          <source>The logarithm of \(|Beta(x)|\) reducing along the last dimension.</source>
          <target state="translated">마지막 차원을 따라 감소하는 \ (| Beta (x) | \)의 로그입니다.</target>
        </trans-unit>
        <trans-unit id="bcad86f6653e28bded1ae388b8b9d533057cc10b" translate="yes" xml:space="preserve">
          <source>The logical to physical core mapping.</source>
          <target state="translated">논리적 대 물리적 코어 매핑</target>
        </trans-unit>
        <trans-unit id="53c66b9be9a4d574723adcf23a86e3d3823c9748" translate="yes" xml:space="preserve">
          <source>The loss is the weighted sum over all input dimensions. Namely, if the input labels have shape &lt;code&gt;[batch_size, label_dimension]&lt;/code&gt;, the loss is the weighted sum over both &lt;code&gt;batch_size&lt;/code&gt; and &lt;code&gt;label_dimension&lt;/code&gt;.</source>
          <target state="translated">손실은 모든 입력 차원에 대한 가중치 합계입니다. 즉, 입력 레이블의 모양이 &lt;code&gt;[batch_size, label_dimension]&lt;/code&gt; 인 경우 손실은 &lt;code&gt;batch_size&lt;/code&gt; 및 &lt;code&gt;label_dimension&lt;/code&gt; 에 대한 가중치 합계 입니다.</target>
        </trans-unit>
        <trans-unit id="ed8e3f66cfff153d9268a06149cbecc331a07647" translate="yes" xml:space="preserve">
          <source>The loss is the weighted sum over the input dimensions. Namely, if the input labels have shape &lt;code&gt;[batch_size, 1]&lt;/code&gt;, the loss is the weighted sum over &lt;code&gt;batch_size&lt;/code&gt;.</source>
          <target state="translated">손실은 입력 차원에 대한 가중치 합계입니다. 즉, 입력 레이블의 모양이 &lt;code&gt;[batch_size, 1]&lt;/code&gt; 인 경우 손실은 &lt;code&gt;batch_size&lt;/code&gt; 에 대한 가중치 합계 입니다.</target>
        </trans-unit>
        <trans-unit id="6d3c5f122953381dbc3e40a95fb1e99d6fa1a036" translate="yes" xml:space="preserve">
          <source>The loss scale can either be a fixed constant, chosen by the user, or be dynamically determined. Dynamically determining the loss scale is convenient as a loss scale does not have to be explicitly chosen. However it reduces performance.</source>
          <target state="translated">손실 척도는 고정 상수이거나 사용자가 선택한 상수이거나 동적으로 결정될 수 있습니다. 손실 척도를 명시 적으로 선택할 필요가 없기 때문에 손실 척도를 동적으로 결정하는 것이 편리합니다. 그러나 성능이 저하됩니다.</target>
        </trans-unit>
        <trans-unit id="0f2c12568d11b3b33927e92671eaa159d3a45974" translate="yes" xml:space="preserve">
          <source>The loss scale is not updated for the lifetime of instances of this class. A given instance of this class always returns the same number when called.</source>
          <target state="translated">손실 등급은이 클래스의 인스턴스 수명 동안 업데이트되지 않습니다. 이 클래스의 주어진 인스턴스는 호출 될 때 항상 같은 숫자를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="1c182a3c24f8448fb2c7d3d37bb39bed65ff10d2" translate="yes" xml:space="preserve">
          <source>The loss scale will be potentially updated, based on the value of &lt;code&gt;grads&lt;/code&gt;. The tensor returned by calling this class is only updated when this function is evaluated.</source>
          <target state="translated">손실 척도는 &lt;code&gt;grads&lt;/code&gt; 값에 따라 잠재적으로 업데이트됩니다 . 이 클래스를 호출하여 리턴 된 텐서는이 함수가 평가 될 때만 업데이트됩니다.</target>
        </trans-unit>
        <trans-unit id="90f307f8c8cab35fd072b8a08ea2d9e8126898ba" translate="yes" xml:space="preserve">
          <source>The lower regularized incomplete Gamma function is defined as:</source>
          <target state="translated">정규화되지 않은 불완전한 감마 함수는 다음과 같이 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="f2793511554b8b49f5f134322351c8feaf894969" translate="yes" xml:space="preserve">
          <source>The main reason to subclass &lt;a href=&quot;layer&quot;&gt;&lt;code&gt;tf.keras.layers.Layer&lt;/code&gt;&lt;/a&gt; instead of using a &lt;code&gt;Lambda&lt;/code&gt; layer is saving and inspecting a Model. &lt;code&gt;Lambda&lt;/code&gt; layers are saved by serializing the Python bytecode, whereas subclassed Layers can be saved via overriding their &lt;code&gt;get_config&lt;/code&gt; method. Overriding &lt;code&gt;get_config&lt;/code&gt; improves the portability of Models. Models that rely on subclassed Layers are also often easier to visualize and reason about.</source>
          <target state="translated">&lt;code&gt;Lambda&lt;/code&gt; 레이어 를 사용하는 대신 &lt;a href=&quot;layer&quot;&gt; &lt;code&gt;tf.keras.layers.Layer&lt;/code&gt; &lt;/a&gt; 를 서브 클래 싱하는 주된 이유 는 모델을 저장하고 검사하는 것입니다. &lt;code&gt;Lambda&lt;/code&gt; 레이어는 Python 바이트 코드를 직렬화하여 저장되는 반면 하위 클래스 레이어는 &lt;code&gt;get_config&lt;/code&gt; 메소드 를 재정 의하여 저장할 수 있습니다 . &lt;code&gt;get_config&lt;/code&gt; 를 재정의 하면 모델의 이식성이 향상됩니다. 서브 클래 싱 된 레이어에 의존하는 모델은 종종 시각화하고 추론하기가 더 쉽습니다.</target>
        </trans-unit>
        <trans-unit id="4a2c99d4f1e6d03bbc1af13e3314d300799e01bf" translate="yes" xml:space="preserve">
          <source>The map vectorization options associated with the dataset. See &lt;a href=&quot;mapvectorizationoptions&quot;&gt;&lt;code&gt;tf.data.experimental.MapVectorizationOptions&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">데이터 세트와 관련된지도 벡터화 옵션. 자세한 내용은 &lt;a href=&quot;mapvectorizationoptions&quot;&gt; &lt;code&gt;tf.data.experimental.MapVectorizationOptions&lt;/code&gt; &lt;/a&gt; 를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="f8214e9e9da90e26f5fe7ae19cb9d8f2cd4e068c" translate="yes" xml:space="preserve">
          <source>The masked &lt;code&gt;IndexedSlices&lt;/code&gt; instance.</source>
          <target state="translated">마스크 된 &lt;code&gt;IndexedSlices&lt;/code&gt; 인스턴스입니다.</target>
        </trans-unit>
        <trans-unit id="221a20910838d03246163841206f72d038ef571a" translate="yes" xml:space="preserve">
          <source>The matrix &lt;code&gt;a&lt;/code&gt; must, following any transpositions, be a tensor of rank &amp;gt;= 2, with &lt;code&gt;shape(a)[-1] == shape(b)[-1]&lt;/code&gt;, and &lt;code&gt;shape(a)[:-2]&lt;/code&gt; able to broadcast with &lt;code&gt;shape(b)[:-1]&lt;/code&gt;.</source>
          <target state="translated">모든 전위에 따라 행렬 &lt;code&gt;a&lt;/code&gt; 는 &lt;code&gt;shape(a)[-1] == shape(b)[-1]&lt;/code&gt; 및 &lt;code&gt;shape(a)[:-2]&lt;/code&gt; 수있는 &amp;gt;&amp;gt; 2의 텐서 여야합니다 . &lt;code&gt;shape(b)[:-1]&lt;/code&gt; 브로드 캐스트하십시오 .</target>
        </trans-unit>
        <trans-unit id="fd71aa391cda25307463e674c4cbc2ea6a909c84" translate="yes" xml:space="preserve">
          <source>The matrix can be used with &lt;a href=&quot;../tensordot&quot;&gt;&lt;code&gt;tf.tensordot&lt;/code&gt;&lt;/a&gt; to convert an arbitrary rank &lt;code&gt;Tensor&lt;/code&gt; of linear-scale spectral bins into the mel scale.</source>
          <target state="translated">이 매트릭스는 &lt;a href=&quot;../tensordot&quot;&gt; &lt;code&gt;tf.tensordot&lt;/code&gt; &lt;/a&gt; 과 함께 사용되어 선형 스케일 스펙트럼 빈 의 임의 랭크 &lt;code&gt;Tensor&lt;/code&gt; 를 멜 스케일 로 변환 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="11e987b7f304f6e3dd583d8302496f7bf0e8c7c9" translate="yes" xml:space="preserve">
          <source>The matrix columns represent the prediction labels and the rows represent the real labels. The confusion matrix is always a 2-D array of shape &lt;code&gt;[n, n]&lt;/code&gt;, where &lt;code&gt;n&lt;/code&gt; is the number of valid labels for a given classification task. Both prediction and labels must be 1-D arrays of the same shape in order for this function to work.</source>
          <target state="translated">행렬 열은 예측 레이블을 나타내고 행은 실제 레이블을 나타냅니다. 혼동 행렬은 항상 &lt;code&gt;[n, n]&lt;/code&gt; 모양의 2 차원 배열이며 , 여기서 &lt;code&gt;n&lt;/code&gt; 은 지정된 분류 작업에 유효한 레이블 수입니다. 이 함수가 작동하려면 예측 및 레이블이 동일한 모양의 1 차원 배열이어야합니다.</target>
        </trans-unit>
        <trans-unit id="1b5db825d45e0c9d1dc6abe9745f59c698b3a58a" translate="yes" xml:space="preserve">
          <source>The matrix square root is computed by first reducing the matrix to quasi-triangular form with the real Schur decomposition. The square root of the quasi-triangular matrix is then computed directly. Details of the algorithm can be found in: Nicholas J. Higham, &quot;Computing real square roots of a real matrix&quot;, Linear Algebra Appl., 1987.</source>
          <target state="translated">행렬 제곱근은 먼저 실제 Schur 분해를 통해 행렬을 준 삼각형으로 축소하여 계산됩니다. 그런 다음 준 삼각 행렬의 제곱근이 직접 계산됩니다. 알고리즘에 대한 자세한 내용은 Nicholas J. Higham, &quot;실제 행렬의 실제 제곱근 계산&quot;, Linear Algebra Appl., 1987에서 확인할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="5e52e55f2b2b641c09e44a69eccc168205a706b2" translate="yes" xml:space="preserve">
          <source>The maximum error in between the two Jacobians.</source>
          <target state="translated">두 야곱 인 사이의 최대 오차.</target>
        </trans-unit>
        <trans-unit id="2c20357476750adc337729874b4e2eabc8868c3d" translate="yes" xml:space="preserve">
          <source>The mean and variance are calculated by aggregating the contents of &lt;code&gt;x&lt;/code&gt; across &lt;code&gt;axes&lt;/code&gt;. If &lt;code&gt;x&lt;/code&gt; is 1-D and &lt;code&gt;axes = [0]&lt;/code&gt; this is just the mean and variance of a vector.</source>
          <target state="translated">평균과 분산은 &lt;code&gt;x&lt;/code&gt; 의 내용 을 &lt;code&gt;axes&lt;/code&gt; 걸쳐 집계하여 계산됩니다 . 경우 &lt;code&gt;x&lt;/code&gt; 1-D이고 &lt;code&gt;axes = [0]&lt;/code&gt; 이 단지 평균 벡터 및의 분산이다.</target>
        </trans-unit>
        <trans-unit id="e3746fb2d4eae6a4ec87d65fc23bec2fa55150f2" translate="yes" xml:space="preserve">
          <source>The mean of Student's T equals &lt;code&gt;loc&lt;/code&gt; if &lt;code&gt;df &amp;gt; 1&lt;/code&gt;, otherwise it is &lt;code&gt;NaN&lt;/code&gt;. If &lt;code&gt;self.allow_nan_stats=True&lt;/code&gt;, then an exception will be raised rather than returning &lt;code&gt;NaN&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;df &amp;gt; 1&lt;/code&gt; 인 경우 Student 's T의 평균은 &lt;code&gt;loc&lt;/code&gt; 와 같고 , 그렇지 않으면 &lt;code&gt;NaN&lt;/code&gt; 입니다. 경우 &lt;code&gt;self.allow_nan_stats=True&lt;/code&gt; 는 예외가 리턴하는 대신 발생합니다 &lt;code&gt;NaN&lt;/code&gt; 이를 .</target>
        </trans-unit>
        <trans-unit id="66b167be0f051cc6e8d71c967e67b0309cb7feab" translate="yes" xml:space="preserve">
          <source>The meaning of &lt;code&gt;query&lt;/code&gt;, &lt;code&gt;value&lt;/code&gt; and &lt;code&gt;key&lt;/code&gt; depend on the application. In the case of text similarity, for example, &lt;code&gt;query&lt;/code&gt; is the sequence embeddings of the first piece of text and &lt;code&gt;value&lt;/code&gt; is the sequence embeddings of the second piece of text. &lt;code&gt;key&lt;/code&gt; is usually the same tensor as &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;query&lt;/code&gt; , &lt;code&gt;value&lt;/code&gt; 및 &lt;code&gt;key&lt;/code&gt; 의 의미 는 응용 프로그램에 따라 다릅니다. 텍스트 유사성의 경우, 예를 들어 &lt;code&gt;query&lt;/code&gt; 는 첫 번째 텍스트 조각의 시퀀스 임베딩 이고 &lt;code&gt;value&lt;/code&gt; 은 두 번째 텍스트 조각의 시퀀스 임베딩입니다. &lt;code&gt;key&lt;/code&gt; 는 일반적으로 &lt;code&gt;value&lt;/code&gt; 와 동일한 텐서 입니다.</target>
        </trans-unit>
        <trans-unit id="92510595be575a3f901083a76e505b27be4bea36" translate="yes" xml:space="preserve">
          <source>The meaning of setting &lt;code&gt;layer.trainable = False&lt;/code&gt; is to freeze the layer, i.e. its internal state will not change during training: its trainable weights will not be updated during &lt;code&gt;fit()&lt;/code&gt; or &lt;code&gt;train_on_batch()&lt;/code&gt;, and its state updates will not be run.</source>
          <target state="translated">&lt;code&gt;layer.trainable = False&lt;/code&gt; 설정의 의미는 레이어를 고정하는 것입니다. 즉, 훈련 중 내부 상태가 변경되지 않습니다. 훈련 가능한 가중치는 &lt;code&gt;fit()&lt;/code&gt; 또는 &lt;code&gt;train_on_batch()&lt;/code&gt; 중에 업데이트되지 않으며 상태 업데이트가 실행되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="ae04b245da8a7e16dadcfeccbc7fd1f3884fcfad" translate="yes" xml:space="preserve">
          <source>The method returns the path prefix of the newly created checkpoint files. This string can be passed directly to a call to &lt;code&gt;restore()&lt;/code&gt;.</source>
          <target state="translated">이 메소드는 새로 작성된 체크 포인트 파일의 경로 접 두부를 리턴합니다. 이 문자열은 &lt;code&gt;restore()&lt;/code&gt; 호출로 직접 전달 될 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="3c6e6621d848cf3b840ae66983d6900ad6f06a8b" translate="yes" xml:space="preserve">
          <source>The metric creates two local variables, &lt;code&gt;true_positives&lt;/code&gt; and &lt;code&gt;false_positives&lt;/code&gt; that are used to compute the precision. This value is ultimately returned as &lt;code&gt;precision&lt;/code&gt;, an idempotent operation that simply divides &lt;code&gt;true_positives&lt;/code&gt; by the sum of &lt;code&gt;true_positives&lt;/code&gt; and &lt;code&gt;false_positives&lt;/code&gt;.</source>
          <target state="translated">메트릭은 정밀도를 계산하는 데 사용되는 두 개의 로컬 변수 &lt;code&gt;true_positives&lt;/code&gt; 및 &lt;code&gt;false_positives&lt;/code&gt; 를 만듭니다 . 이 값은 궁극적 으로 &lt;code&gt;true_positives&lt;/code&gt; 를 &lt;code&gt;true_positives&lt;/code&gt; 와 &lt;code&gt;false_positives&lt;/code&gt; 의 합으로 나누는 pot 등식 연산 인 &lt;code&gt;precision&lt;/code&gt; 으로 반환됩니다 .</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
