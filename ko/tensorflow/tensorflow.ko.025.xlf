<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ko" datatype="htmlbody" original="tensorflow">
    <body>
      <group id="tensorflow">
        <trans-unit id="c879ab9978d630c89fff8cae92e9db4343f09490" translate="yes" xml:space="preserve">
          <source>The minibatch size &lt;code&gt;N&lt;/code&gt; is extracted from &lt;code&gt;sparse_shape[0]&lt;/code&gt;.</source>
          <target state="translated">미니 배치 크기 &lt;code&gt;N&lt;/code&gt; 은 sparse_shape &lt;code&gt;sparse_shape[0]&lt;/code&gt; 에서 추출됩니다 .</target>
        </trans-unit>
        <trans-unit id="adafbd0cce3b5754618ae2da17c9902f6cae336a" translate="yes" xml:space="preserve">
          <source>The mode of a gamma distribution is &lt;code&gt;(shape - 1) / rate&lt;/code&gt; when &lt;code&gt;shape &amp;gt; 1&lt;/code&gt;, and &lt;code&gt;NaN&lt;/code&gt; otherwise. If &lt;code&gt;self.allow_nan_stats&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, an exception will be raised rather than returning &lt;code&gt;NaN&lt;/code&gt;.</source>
          <target state="translated">감마 분포의 모드는 &lt;code&gt;shape &amp;gt; 1&lt;/code&gt; 일 때 &lt;code&gt;(shape - 1) / rate&lt;/code&gt; 이고, 그렇지 않으면 &lt;code&gt;NaN&lt;/code&gt; 입니다. 경우 &lt;code&gt;self.allow_nan_stats&lt;/code&gt; 이 있다 &lt;code&gt;False&lt;/code&gt; , 예외가 리턴하는 대신 발생합니다 &lt;code&gt;NaN&lt;/code&gt; 이를 .</target>
        </trans-unit>
        <trans-unit id="ccf3763dcb0dcb0536020350fdb380b642b68362" translate="yes" xml:space="preserve">
          <source>The model architecture, allowing to re-instantiate the model.</source>
          <target state="translated">모델 아키텍처를 통해 모델을 다시 인스턴스화 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="2c5272bf28fc9b4f93ddcbb47262f8771af50748" translate="yes" xml:space="preserve">
          <source>The model weights.</source>
          <target state="translated">모델 가중치.</target>
        </trans-unit>
        <trans-unit id="ff3e822749aa45b217109835dbb8a4c4930f2cb5" translate="yes" xml:space="preserve">
          <source>The most basic RNN cell.</source>
          <target state="translated">가장 기본적인 RNN 셀.</target>
        </trans-unit>
        <trans-unit id="92ef4fa2dcf9047cf590c368e2e76fcb4cd1ce27" translate="yes" xml:space="preserve">
          <source>The most common initialization pattern is to use the convenience function &lt;code&gt;global_variables_initializer()&lt;/code&gt; to add an Op to the graph that initializes all the variables. You then run that Op after launching the graph.</source>
          <target state="translated">가장 일반적인 초기화 패턴은 편의 함수 &lt;code&gt;global_variables_initializer()&lt;/code&gt; 를 사용하여 모든 변수를 초기화하는 그래프에 Op를 추가하는 것입니다. 그런 다음 그래프를 시작한 후 해당 Op를 실행하십시오.</target>
        </trans-unit>
        <trans-unit id="be28bd956ec3dd71f96903bf3e90304d770c19da" translate="yes" xml:space="preserve">
          <source>The most common use case for this function occurs when feature ids and their corresponding values are stored in &lt;code&gt;Example&lt;/code&gt; protos on disk. &lt;code&gt;parse_example&lt;/code&gt; will return a batch of ids and a batch of values, and this function joins them into a single logical &lt;code&gt;SparseTensor&lt;/code&gt; for use in functions such as &lt;code&gt;sparse_tensor_dense_matmul&lt;/code&gt;, &lt;code&gt;sparse_to_dense&lt;/code&gt;, etc.</source>
          <target state="translated">이 기능의 가장 일반적인 사용 사례는 기능 ID와 해당 값이 디스크의 &lt;code&gt;Example&lt;/code&gt; 프로토 타에 저장 될 때 발생합니다 . &lt;code&gt;parse_example&lt;/code&gt; 은 일련의 id와 일련의 값을 반환하며,이 함수는 &lt;code&gt;sparse_tensor_dense_matmul&lt;/code&gt; , &lt;code&gt;sparse_to_dense&lt;/code&gt; 등과 같은 함수에서 사용하기 위해 단일 논리 &lt;code&gt;SparseTensor&lt;/code&gt; 에 결합합니다 .</target>
        </trans-unit>
        <trans-unit id="4c37b111e7c1a2dfc5ac3657ac3eb40f6697f662" translate="yes" xml:space="preserve">
          <source>The moving averages are computed using exponential decay. You specify the decay value when creating the &lt;code&gt;ExponentialMovingAverage&lt;/code&gt; object. The shadow variables are initialized with the same initial values as the trained variables. When you run the ops to maintain the moving averages, each shadow variable is updated with the formula:</source>
          <target state="translated">이동 평균은 지수 붕괴를 사용하여 계산됩니다. &lt;code&gt;ExponentialMovingAverage&lt;/code&gt; 객체를 생성 할 때 소멸 값을 지정 합니다. 새도우 변수는 학습 된 변수와 동일한 초기 값으로 초기화됩니다. 이동 평균을 유지하기 위해 ops를 실행할 때 각 그림자 변수는 다음 공식으로 업데이트됩니다.</target>
        </trans-unit>
        <trans-unit id="94df2d413ae96a0a117fa46769022f06a44e6ff4" translate="yes" xml:space="preserve">
          <source>The name of the &lt;code&gt;TensorArray&lt;/code&gt; (even if passed in) is uniquified: each time a new &lt;code&gt;TensorArray&lt;/code&gt; is created at runtime it is assigned its own name for the duration of the run. This avoids name collisions if a &lt;code&gt;TensorArray&lt;/code&gt; is created within a &lt;code&gt;while_loop&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;TensorArray&lt;/code&gt; 의 이름 (전달 된 경우에도)은 고유합니다. 런타임에 새 &lt;code&gt;TensorArray&lt;/code&gt; 가 작성 될 때마다 실행 기간 동안 고유 한 이름이 지정됩니다. 경우 피합니다는 충돌의 이름을 &lt;code&gt;TensorArray&lt;/code&gt; 이 내에서 생성된다 &lt;code&gt;while_loop&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8fcdbd427dc016b6defe717193d13e8a5ff2954b" translate="yes" xml:space="preserve">
          <source>The name of the device on which &lt;code&gt;values&lt;/code&gt; will be produced, or &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">되는 장치명 &lt;code&gt;values&lt;/code&gt; 생성 될 것이며, 또는 &lt;code&gt;None&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="37ecde1c1b33e8dfdb61f844e3753c1a790bb482" translate="yes" xml:space="preserve">
          <source>The name of the device on which this tensor will be produced, or None.</source>
          <target state="translated">이 텐서가 생성 될 장치의 이름 또는 없음.</target>
        </trans-unit>
        <trans-unit id="513390ceda7c6a57cd491aa38c353737462bdd7c" translate="yes" xml:space="preserve">
          <source>The name of the device to which this op has been assigned, if any.</source>
          <target state="translated">이 op가 할당 된 장치의 이름입니다 (있는 경우).</target>
        </trans-unit>
        <trans-unit id="cf636fc4624183a99bcc4c7c7fbe0a44c0ebb8f7" translate="yes" xml:space="preserve">
          <source>The name of the module which registered the flag with this name. If no such module exists (i.e. no flag with this name exists), we return default.</source>
          <target state="translated">이 이름으로 플래그를 등록한 모듈의 이름입니다. 그러한 모듈이 존재하지 않으면 (즉,이 이름의 플래그가 존재하지 않는 경우), 기본값을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="5d3b4cc387786491f2cb51bc2065fde0324f391f" translate="yes" xml:space="preserve">
          <source>The name of the scope itself can be captured by &lt;code&gt;with g.name_scope(...) as scope:&lt;/code&gt;, which stores the name of the scope in the variable &lt;code&gt;scope&lt;/code&gt;. This value can be used to name an operation that represents the overall result of executing the ops in a scope. For example:</source>
          <target state="translated">범위 자체의 이름은 &lt;code&gt;with g.name_scope(...) as scope:&lt;/code&gt; 캡처 할 수 있습니다 . scope : 는 범위 이름을 변수 &lt;code&gt;scope&lt;/code&gt; 에 저장합니다 . 이 값은 범위에서 ops를 실행 한 전체 결과를 나타내는 작업의 이름을 지정하는 데 사용할 수 있습니다. 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="c5bdc797aad3e657271b859b7dc8d873a1c5776b" translate="yes" xml:space="preserve">
          <source>The name of the table.</source>
          <target state="translated">테이블 이름</target>
        </trans-unit>
        <trans-unit id="4f8f2953a3d445a0fc6a56065d426682fba17223" translate="yes" xml:space="preserve">
          <source>The name of the underlying accumulator.</source>
          <target state="translated">기본 누산기의 이름입니다.</target>
        </trans-unit>
        <trans-unit id="96809ba43c27a83619ec011b30fe50853f001590" translate="yes" xml:space="preserve">
          <source>The name of the underlying queue.</source>
          <target state="translated">기본 대기열의 이름입니다.</target>
        </trans-unit>
        <trans-unit id="f89f168ead7cdce407789bc51f70ca1fc8c5be20" translate="yes" xml:space="preserve">
          <source>The name of this &lt;code&gt;IndexedSlices&lt;/code&gt;.</source>
          <target state="translated">이 &lt;code&gt;IndexedSlices&lt;/code&gt; 의 이름입니다 .</target>
        </trans-unit>
        <trans-unit id="da911221082c7da030b3afee2bb6138d5ed15e00" translate="yes" xml:space="preserve">
          <source>The name of this ExponentialMovingAverage object.</source>
          <target state="translated">이 ExponentialMovingAverage 객체의 이름입니다.</target>
        </trans-unit>
        <trans-unit id="a0b8c507e7f0e7b6a1373421e05579d1965778f3" translate="yes" xml:space="preserve">
          <source>The name of this head.</source>
          <target state="translated">이 머리의 이름.</target>
        </trans-unit>
        <trans-unit id="d713b72d40825a59e98f4bc908a8370877bdd57f" translate="yes" xml:space="preserve">
          <source>The name of this variable.</source>
          <target state="translated">이 변수의 이름입니다.</target>
        </trans-unit>
        <trans-unit id="1d01abc5e97d43035681b7621f742a7e0e4f87f3" translate="yes" xml:space="preserve">
          <source>The name or URL of the session master.</source>
          <target state="translated">세션 마스터의 이름 또는 URL입니다.</target>
        </trans-unit>
        <trans-unit id="947e2daa3bb98d0bc923e5ca008b708b99d1db05" translate="yes" xml:space="preserve">
          <source>The natural log of the determinant of &lt;code&gt;matrix&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;matrix&lt;/code&gt; 결정 요인의 자연 로그입니다 .</target>
        </trans-unit>
        <trans-unit id="e172fe7e51a351d69f78266150cbe93d41a966dd" translate="yes" xml:space="preserve">
          <source>The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution.</source>
          <target state="translated">전치 된 회선의 필요성은 일반적으로 일반 회선의 반대 방향으로 진행하는 변환을 사용하려는 요구, 즉 일부 회선의 출력 형태를 갖는 것에서 입력 형태를 갖는 것까지, 상기 회선과 호환되는 연결 패턴.</target>
        </trans-unit>
        <trans-unit id="e63348dbbced4923128564bd3253cc502100689d" translate="yes" xml:space="preserve">
          <source>The new generator will be initialized by one of the following ways, with decreasing precedence: (1) If &lt;code&gt;copy_from&lt;/code&gt; is not None, the new generator is initialized by copying information from another generator. (3) If &lt;code&gt;state&lt;/code&gt; and &lt;code&gt;alg&lt;/code&gt; are not None (they must be set together), the new generator is initialized by a state.</source>
          <target state="translated">새 생성기는 우선 순위가 감소하면서 다음 방법 중 하나로 초기화됩니다. (1) &lt;code&gt;copy_from&lt;/code&gt; 이 None이 아닌 경우 , 다른 생성기에서 정보를 복사하여 새 생성기가 초기화됩니다. (3) &lt;code&gt;state&lt;/code&gt; 와 &lt;code&gt;alg&lt;/code&gt; 가 None이 아닌 경우 (함께 설정해야 함) 새로운 생성기는 상태에 의해 초기화됩니다.</target>
        </trans-unit>
        <trans-unit id="8cbbc58e1d6e45f7538d48a88e9145ff0816310e" translate="yes" xml:space="preserve">
          <source>The new generator.</source>
          <target state="translated">새로운 발전기.</target>
        </trans-unit>
        <trans-unit id="c92d3a1d88d5bb846fb6922638676753f654e62e" translate="yes" xml:space="preserve">
          <source>The new generators will be put on the current device (possible different from the old generator's), for example:</source>
          <target state="translated">새 발전기는 현재 장치에 배치됩니다 (이전 발전기와 다를 수 있음).</target>
        </trans-unit>
        <trans-unit id="e426c7afe47b5f55c3dfa85e599a773e3d38d777" translate="yes" xml:space="preserve">
          <source>The new variable is added to the graph collections listed in &lt;code&gt;collections&lt;/code&gt;, which defaults to &lt;code&gt;[GraphKeys.GLOBAL_VARIABLES]&lt;/code&gt;.</source>
          <target state="translated">새로운 변수에 표시된 그래프 컬렉션에 추가 &lt;code&gt;collections&lt;/code&gt; , 디폴트 &lt;code&gt;[GraphKeys.GLOBAL_VARIABLES]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b23ad53a08722aede7339ef0814174529ec55158" translate="yes" xml:space="preserve">
          <source>The next element in the queue, i.e. a tuple &lt;code&gt;(inputs, targets)&lt;/code&gt; or &lt;code&gt;(inputs, targets, sample_weights)&lt;/code&gt;.</source>
          <target state="translated">큐에서 다음 요소, 즉 튜플 &lt;code&gt;(inputs, targets)&lt;/code&gt; 또는 &lt;code&gt;(inputs, targets, sample_weights)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8bc3974c53a4bc03fb9e4842cff39c86a0d8870a" translate="yes" xml:space="preserve">
          <source>The non-zero values in the represented dense tensor.</source>
          <target state="translated">표시된 조밀 한 텐서에서 0이 아닌 값.</target>
        </trans-unit>
        <trans-unit id="a794ea3a692cf3249d1fcc991ee60c5b4cf01417" translate="yes" xml:space="preserve">
          <source>The normal &lt;code&gt;ServingInputReceiver&lt;/code&gt; always returns a feature dict, even if it contains only one entry, and so can be used only with models that accept such a dict. For models that accept only a single raw feature, the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; provided to &lt;a href=&quot;../../compat/v1/estimator/estimator#export_saved_model&quot;&gt;&lt;code&gt;Estimator.export_saved_model()&lt;/code&gt;&lt;/a&gt; should return this &lt;code&gt;TensorServingInputReceiver&lt;/code&gt; instead. See: https://github.com/tensorflow/tensorflow/issues/11674</source>
          <target state="translated">일반적인 &lt;code&gt;ServingInputReceiver&lt;/code&gt; 는 하나의 항목 만 포함하더라도 항상 기능 dict를 리턴하므로 해당 dict를 허용하는 모델에만 사용할 수 있습니다. 단 하나의 원시 기능의 수용 모델의 &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; 제공 &lt;a href=&quot;../../compat/v1/estimator/estimator#export_saved_model&quot;&gt; &lt;code&gt;Estimator.export_saved_model()&lt;/code&gt; &lt;/a&gt; 이 반환해야 &lt;code&gt;TensorServingInputReceiver&lt;/code&gt; 을 대신. 참조 : https://github.com/tensorflow/tensorflow/issues/11674</target>
        </trans-unit>
        <trans-unit id="61b02be5d26057c5d50879cdbf7a93b5057253da" translate="yes" xml:space="preserve">
          <source>The number of batches in the Sequence.</source>
          <target state="translated">시퀀스의 배치 수입니다.</target>
        </trans-unit>
        <trans-unit id="1e8251a908793c7f7ac158d55fc205bd7b475f75" translate="yes" xml:space="preserve">
          <source>The number of classes, &lt;code&gt;K&lt;/code&gt;, must not exceed:</source>
          <target state="translated">클래스 수 &lt;code&gt;K&lt;/code&gt; 는 다음을 초과하지 않아야합니다.</target>
        </trans-unit>
        <trans-unit id="26bbe52e7e5ab91d858fdf92eb9164c22baffaaa" translate="yes" xml:space="preserve">
          <source>The number of cores per replica.</source>
          <target state="translated">복제 본당 코어 수</target>
        </trans-unit>
        <trans-unit id="f1fb954517b208177e2433a3bd0d5008bff1f85f" translate="yes" xml:space="preserve">
          <source>The number of devices attached to this input pipeline. This will be automatically set by MultiDeviceIterator.</source>
          <target state="translated">이 입력 파이프 라인에 연결된 장치의 수입니다. 이것은 MultiDeviceIterator에 의해 자동으로 설정됩니다.</target>
        </trans-unit>
        <trans-unit id="a4e68945735abb3b2e9d8c11a95d91c8a876e87a" translate="yes" xml:space="preserve">
          <source>The number of dimensions of the input tensors must match, and all dimensions except &lt;code&gt;axis&lt;/code&gt; must be equal.</source>
          <target state="translated">입력 텐서의 치수 수는 일치 해야하며 &lt;code&gt;axis&lt;/code&gt; 제외한 모든 치수 는 같아야합니다.</target>
        </trans-unit>
        <trans-unit id="516b803f18d035a65572fcbdfc2900dc7b8d516a" translate="yes" xml:space="preserve">
          <source>The number of ragged dimensions in this ragged tensor value.</source>
          <target state="translated">이 비정형 텐서 값의 비정형 치수 수입니다.</target>
        </trans-unit>
        <trans-unit id="04f639280f7ec10513cb4839cfeda1135a578887" translate="yes" xml:space="preserve">
          <source>The number of ragged dimensions in this ragged tensor.</source>
          <target state="translated">이 울퉁불퉁 한 텐서의 울퉁불퉁 한 치수 수입니다.</target>
        </trans-unit>
        <trans-unit id="87460175f8c6b31c8d362f42e4ca508e7497ab37" translate="yes" xml:space="preserve">
          <source>The number of replicas of the computation.</source>
          <target state="translated">계산의 복제본 수입니다.</target>
        </trans-unit>
        <trans-unit id="605dc8d4d33374c29a7f650a9b0f5eab0e0e6145" translate="yes" xml:space="preserve">
          <source>The number of tasks defined in the given job.</source>
          <target state="translated">주어진 작업에 정의 된 작업 수</target>
        </trans-unit>
        <trans-unit id="1a2d5e323b8ac2af372dafbb2ccb4f737135220d" translate="yes" xml:space="preserve">
          <source>The numerics checking mechanism will cause any TensorFlow eager execution or graph execution to error out as soon as an op's output tensor contains infinity or NaN.</source>
          <target state="translated">숫자 검사 메커니즘으로 인해 op의 출력 텐서에 무한대 또는 NaN이 포함되면 TensorFlow 열성적인 실행 또는 그래프 실행이 오류가 발생합니다.</target>
        </trans-unit>
        <trans-unit id="4302dccd839f803738d3151980944012f9528e1e" translate="yes" xml:space="preserve">
          <source>The numpy dtype of values in this tensor.</source>
          <target state="translated">이 텐서의 값이 numpy dtype입니다.</target>
        </trans-unit>
        <trans-unit id="10073c85f700d07cd9e27b920a2bb28c0e1e6aa0" translate="yes" xml:space="preserve">
          <source>The object will be registered under the key 'package&amp;gt;name' where &lt;code&gt;name&lt;/code&gt;, defaults to the object name if not passed.</source>
          <target state="translated">객체는 키 'package&amp;gt; name'에 등록됩니다. 여기서 &lt;code&gt;name&lt;/code&gt; 은 전달되지 않은 경우 기본적으로 객체 이름으로 설정됩니다.</target>
        </trans-unit>
        <trans-unit id="ceae2a98903e4e9554b3ffa1be72b116c87afeec" translate="yes" xml:space="preserve">
          <source>The one-hot tensor.</source>
          <target state="translated">원핫 텐서.</target>
        </trans-unit>
        <trans-unit id="2214e2794dfd82c41f2566b3dfe3c682d8ae3fc2" translate="yes" xml:space="preserve">
          <source>The only change you have to do to the single program code is to indicate if the program is running as the &lt;em&gt;chief&lt;/em&gt;.</source>
          <target state="translated">당신은 하나의 프로그램 코드에해야 할 유일한 변화는 프로그램으로 실행하는 경우 표시하는 것입니다 &lt;em&gt;최고&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="2ac713e042499abe0ad5ad2caf8a0b3b2c0f1068" translate="yes" xml:space="preserve">
          <source>The only difference with a regular &lt;code&gt;Session&lt;/code&gt; is that an &lt;code&gt;InteractiveSession&lt;/code&gt; installs itself as the default session on construction. The methods &lt;a href=&quot;../../tensor#eval&quot;&gt;&lt;code&gt;tf.Tensor.eval&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../operation#run&quot;&gt;&lt;code&gt;tf.Operation.run&lt;/code&gt;&lt;/a&gt; will use that session to run ops.</source>
          <target state="translated">일반 &lt;code&gt;Session&lt;/code&gt; 과의 유일한 차이점 은 &lt;code&gt;InteractiveSession&lt;/code&gt; 이 구성시 기본 세션으로 설치 된다는 것 입니다. &lt;a href=&quot;../../tensor#eval&quot;&gt; &lt;code&gt;tf.Tensor.eval&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;../../operation#run&quot;&gt; &lt;code&gt;tf.Operation.run&lt;/code&gt; &lt;/a&gt; 메소드 는 해당 세션을 사용하여 ops를 실행합니다.</target>
        </trans-unit>
        <trans-unit id="31601f998aa3aad1333ec413e01d618a81800515" translate="yes" xml:space="preserve">
          <source>The only public method of a 'Flag' object is parse(), but it is typically only called by a 'FlagValues' object. The parse() method is a thin wrapper around the 'ArgumentParser' parse() method. The parsed value is saved in .value, and the .present attribute is updated. If this flag was already present, an Error is raised.</source>
          <target state="translated">'Flag'객체의 유일한 공용 메소드는 parse ()이지만 일반적으로 'FlagValues'객체에 의해서만 호출됩니다. parse () 메소드는 'ArgumentParser'parse () 메소드 주위의 얇은 랩퍼입니다. 구문 분석 된 값이 .value에 저장되고 .present 속성이 업데이트됩니다. 이 플래그가 이미 존재하면 오류가 발생합니다.</target>
        </trans-unit>
        <trans-unit id="f0ab6e564ddbe98c027618ff7ffc593086f5c97a" translate="yes" xml:space="preserve">
          <source>The op extracts fields from a serialized protocol buffers message into tensors.</source>
          <target state="translated">op는 직렬화 된 프로토콜 버퍼 메시지에서 텐서로 필드를 추출합니다.</target>
        </trans-unit>
        <trans-unit id="4524786c0641258f1c43ff84a36d1e64fc7c7b2a" translate="yes" xml:space="preserve">
          <source>The op isn't guaranteed to raise an error if the input matrix is not invertible. &lt;a href=&quot;../debugging/check_numerics&quot;&gt;&lt;code&gt;tf.debugging.check_numerics&lt;/code&gt;&lt;/a&gt; can be applied to the output to detect invertibility problems.</source>
          <target state="translated">입력 행렬이 반전 불가능한 경우 op가 오류를 발생시킬 수 없습니다. &lt;a href=&quot;../debugging/check_numerics&quot;&gt; &lt;code&gt;tf.debugging.check_numerics&lt;/code&gt; &lt;/a&gt; 를 출력에 적용하여 가역성 문제를 감지 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="fb943cd0e3db6ad9fffc66a537388998786a4519" translate="yes" xml:space="preserve">
          <source>The op serializes protobuf messages provided in the input tensors.</source>
          <target state="translated">op는 입력 텐서에 제공된 프로토 부프 메시지를 직렬화합니다.</target>
        </trans-unit>
        <trans-unit id="f4c5664cfd278d67f9bbf9eb0ae9656ce1cd8f8e" translate="yes" xml:space="preserve">
          <source>The op uses LU decomposition with partial pivoting to compute the inverses.</source>
          <target state="translated">op는 부분 피벗과 함께 LU 분해를 사용하여 역을 계산합니다.</target>
        </trans-unit>
        <trans-unit id="47e700a39a6284fa854225b8729284d0f8f18e3a" translate="yes" xml:space="preserve">
          <source>The operation blocks until sufficient number of gradients have been successfully applied to the accumulator.</source>
          <target state="translated">충분한 수의 그래디언트가 누산기에 성공적으로 적용될 때까지 작업이 차단됩니다.</target>
        </trans-unit>
        <trans-unit id="8790d3057b1a7dc53661bb4f237b850fe1057d19" translate="yes" xml:space="preserve">
          <source>The operation casts &lt;code&gt;x&lt;/code&gt; (in case of &lt;code&gt;Tensor&lt;/code&gt;) or &lt;code&gt;x.values&lt;/code&gt; (in case of &lt;code&gt;SparseTensor&lt;/code&gt; or &lt;code&gt;IndexedSlices&lt;/code&gt;) to &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="translated">동작 캐스트 &lt;code&gt;x&lt;/code&gt; (경우 &lt;code&gt;Tensor&lt;/code&gt; 또는) &lt;code&gt;x.values&lt;/code&gt; (경우 &lt;code&gt;SparseTensor&lt;/code&gt; 또는 &lt;code&gt;IndexedSlices&lt;/code&gt; 행) &lt;code&gt;dtype&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="93211cf6300703e21c3cdf804cff040a7b2a55a6" translate="yes" xml:space="preserve">
          <source>The operation logs a warning if we attempt to set to a time step that is lower than the accumulator's own time step.</source>
          <target state="translated">누적 기 자체의 시간 단계보다 낮은 시간 단계로 설정하려고하면 작업이 경고를 기록합니다.</target>
        </trans-unit>
        <trans-unit id="ec87d8afa16231d11efcb471f5e52a7d2a894559" translate="yes" xml:space="preserve">
          <source>The operation must run in the same address space as the Python program that calls &lt;a href=&quot;numpy_function&quot;&gt;&lt;code&gt;tf.numpy_function()&lt;/code&gt;&lt;/a&gt;. If you are using distributed TensorFlow, you must run a &lt;a href=&quot;distribute/server&quot;&gt;&lt;code&gt;tf.distribute.Server&lt;/code&gt;&lt;/a&gt; in the same process as the program that calls &lt;a href=&quot;numpy_function&quot;&gt;&lt;code&gt;tf.numpy_function&lt;/code&gt;&lt;/a&gt; you must pin the created operation to a device in that server (e.g. using &lt;code&gt;with tf.device():&lt;/code&gt;).</source>
          <target state="translated">작업은 &lt;a href=&quot;numpy_function&quot;&gt; &lt;code&gt;tf.numpy_function()&lt;/code&gt; &lt;/a&gt; 을 호출하는 Python 프로그램과 동일한 주소 공간에서 실행해야합니다 . 당신이 TensorFlow 분산 사용하는 경우에는 실행해야합니다 &lt;a href=&quot;distribute/server&quot;&gt; &lt;code&gt;tf.distribute.Server&lt;/code&gt; &lt;/a&gt; 호출하는 프로그램과 동일한 과정을 &lt;a href=&quot;numpy_function&quot;&gt; &lt;code&gt;tf.numpy_function&lt;/code&gt; &lt;/a&gt; 당신이 (예를 들어, 사용하여 해당 서버에서 장치에 생성 된 작업을 고정합니다 &lt;code&gt;with tf.device():&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="2eb160b49a8c0e9200d47f580c46000b2caec03e" translate="yes" xml:space="preserve">
          <source>The operation must run in the same address space as the Python program that calls &lt;a href=&quot;py_func&quot;&gt;&lt;code&gt;tf.compat.v1.py_func()&lt;/code&gt;&lt;/a&gt;. If you are using distributed TensorFlow, you must run a &lt;a href=&quot;../../distribute/server&quot;&gt;&lt;code&gt;tf.distribute.Server&lt;/code&gt;&lt;/a&gt; in the same process as the program that calls &lt;a href=&quot;py_func&quot;&gt;&lt;code&gt;tf.compat.v1.py_func()&lt;/code&gt;&lt;/a&gt; and you must pin the created operation to a device in that server (e.g. using &lt;code&gt;with tf.device():&lt;/code&gt;).</source>
          <target state="translated">작업은 &lt;a href=&quot;py_func&quot;&gt; &lt;code&gt;tf.compat.v1.py_func()&lt;/code&gt; &lt;/a&gt; 를 호출하는 Python 프로그램과 동일한 주소 공간에서 실행해야합니다 . 분산 TensorFlow를 사용하는 경우 &lt;a href=&quot;py_func&quot;&gt; &lt;code&gt;tf.compat.v1.py_func()&lt;/code&gt; &lt;/a&gt; 를 호출하는 프로그램과 동일한 프로세스에서 &lt;a href=&quot;../../distribute/server&quot;&gt; &lt;code&gt;tf.distribute.Server&lt;/code&gt; &lt;/a&gt; 를 실행 해야하며 작성된 조작을 해당 서버의 디바이스에 고정해야합니다 (예 : &lt;code&gt;with tf.device():&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3cd48c99e2e66fcb5c484164b2f3d03eb702bcd9" translate="yes" xml:space="preserve">
          <source>The operation must run in the same address space as the Python program that calls &lt;a href=&quot;py_function&quot;&gt;&lt;code&gt;tf.py_function()&lt;/code&gt;&lt;/a&gt;. If you are using distributed TensorFlow, you must run a &lt;a href=&quot;distribute/server&quot;&gt;&lt;code&gt;tf.distribute.Server&lt;/code&gt;&lt;/a&gt; in the same process as the program that calls &lt;a href=&quot;py_function&quot;&gt;&lt;code&gt;tf.py_function()&lt;/code&gt;&lt;/a&gt; and you must pin the created operation to a device in that server (e.g. using &lt;code&gt;with tf.device():&lt;/code&gt;).</source>
          <target state="translated">작업은 &lt;a href=&quot;py_function&quot;&gt; &lt;code&gt;tf.py_function()&lt;/code&gt; &lt;/a&gt; 을 호출하는 Python 프로그램과 동일한 주소 공간에서 실행해야합니다 . 분산 TensorFlow를 사용하는 경우 &lt;a href=&quot;py_function&quot;&gt; &lt;code&gt;tf.py_function()&lt;/code&gt; &lt;/a&gt; 을 호출하는 프로그램과 동일한 프로세스에서 &lt;a href=&quot;distribute/server&quot;&gt; &lt;code&gt;tf.distribute.Server&lt;/code&gt; &lt;/a&gt; 를 실행 해야하며 생성 된 조작을 해당 서버의 디바이스에 고정해야합니다 (예 : &lt;code&gt;with tf.device():&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="12a018d5761a73fb797a8185b603d78340c9da47" translate="yes" xml:space="preserve">
          <source>The operation of &lt;code&gt;raw_rnn&lt;/code&gt;, in pseudo-code, is basically the following:</source>
          <target state="translated">의사 코드에서 &lt;code&gt;raw_rnn&lt;/code&gt; 의 작업 은 기본적으로 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="666e744ea2e81d27484651c5a90d39fe7463b5f8" translate="yes" xml:space="preserve">
          <source>The operation returns the cardinality of &lt;code&gt;dataset&lt;/code&gt;. The operation may return &lt;a href=&quot;../experimental#INFINITE_CARDINALITY&quot;&gt;&lt;code&gt;tf.data.experimental.INFINITE_CARDINALITY&lt;/code&gt;&lt;/a&gt; if &lt;code&gt;dataset&lt;/code&gt; contains an infinite number of elements or &lt;a href=&quot;../experimental#UNKNOWN_CARDINALITY&quot;&gt;&lt;code&gt;tf.data.experimental.UNKNOWN_CARDINALITY&lt;/code&gt;&lt;/a&gt; if the analysis fails to determine the number of elements in &lt;code&gt;dataset&lt;/code&gt; (e.g. when the dataset source is a file).</source>
          <target state="translated">이 작업은 &lt;code&gt;dataset&lt;/code&gt; 의 카디널리티를 반환합니다 . &lt;code&gt;dataset&lt;/code&gt; 에 무한한 수의 요소가 포함 된 경우 작업에서 &lt;a href=&quot;../experimental#INFINITE_CARDINALITY&quot;&gt; &lt;code&gt;tf.data.experimental.INFINITE_CARDINALITY&lt;/code&gt; 를&lt;/a&gt; 반환 하거나 분석에서 &lt;code&gt;dataset&lt;/code&gt; 의 요소 수를 결정하지 못한 경우 (예 : 데이터 세트 소스가 파일 인 경우) &lt;a href=&quot;../experimental#UNKNOWN_CARDINALITY&quot;&gt; &lt;code&gt;tf.data.experimental.UNKNOWN_CARDINALITY&lt;/code&gt; 를&lt;/a&gt; 반환 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="b1aa4d33454ed3399a3f83fe0b47437e589dd1db" translate="yes" xml:space="preserve">
          <source>The operation supports data types (for &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;dtype&lt;/code&gt;) of &lt;code&gt;uint8&lt;/code&gt;, &lt;code&gt;uint16&lt;/code&gt;, &lt;code&gt;uint32&lt;/code&gt;, &lt;code&gt;uint64&lt;/code&gt;, &lt;code&gt;int8&lt;/code&gt;, &lt;code&gt;int16&lt;/code&gt;, &lt;code&gt;int32&lt;/code&gt;, &lt;code&gt;int64&lt;/code&gt;, &lt;code&gt;float16&lt;/code&gt;, &lt;code&gt;float32&lt;/code&gt;, &lt;code&gt;float64&lt;/code&gt;, &lt;code&gt;complex64&lt;/code&gt;, &lt;code&gt;complex128&lt;/code&gt;, &lt;code&gt;bfloat16&lt;/code&gt;. In case of casting from complex types (&lt;code&gt;complex64&lt;/code&gt;, &lt;code&gt;complex128&lt;/code&gt;) to real types, only the real part of &lt;code&gt;x&lt;/code&gt; is returned. In case of casting from real types to complex types (&lt;code&gt;complex64&lt;/code&gt;, &lt;code&gt;complex128&lt;/code&gt;), the imaginary part of the returned value is set to &lt;code&gt;0&lt;/code&gt;. The handling of complex types here matches the behavior of numpy.</source>
          <target state="translated">(동작의 지원 데이터 타입 &lt;code&gt;x&lt;/code&gt; 및 &lt;code&gt;dtype&lt;/code&gt; 의) &lt;code&gt;uint8&lt;/code&gt; , &lt;code&gt;uint16&lt;/code&gt; , &lt;code&gt;uint32&lt;/code&gt; , &lt;code&gt;uint64&lt;/code&gt; , &lt;code&gt;int8&lt;/code&gt; , &lt;code&gt;int16&lt;/code&gt; , &lt;code&gt;int32&lt;/code&gt; , &lt;code&gt;int64&lt;/code&gt; , &lt;code&gt;float16&lt;/code&gt; 과 , &lt;code&gt;float32&lt;/code&gt; , &lt;code&gt;float64&lt;/code&gt; , &lt;code&gt;complex64&lt;/code&gt; , &lt;code&gt;complex128&lt;/code&gt; , &lt;code&gt;bfloat16&lt;/code&gt; . 복잡한 유형 (에서 전송할 경우 &lt;code&gt;complex64&lt;/code&gt; , &lt;code&gt;complex128&lt;/code&gt; 실제 유형의 실수 부분) &lt;code&gt;x&lt;/code&gt; 반환된다. 실제 유형에서 복합 유형으로 캐스트하는 경우 ( &lt;code&gt;complex64&lt;/code&gt; , &lt;code&gt;complex128&lt;/code&gt; 은)에서 반환 된 값의 허수 부분은 &lt;code&gt;0&lt;/code&gt; 으로 설정됩니다 . 여기서 복잡한 유형의 처리는 numpy의 동작과 일치합니다.</target>
        </trans-unit>
        <trans-unit id="633cea8689c5cf5392fe403777889735793f4042" translate="yes" xml:space="preserve">
          <source>The operation that (conditionally) applies a gradient to the accumulator.</source>
          <target state="translated">조건부로 누적기에 기울기를 적용하는 작업입니다.</target>
        </trans-unit>
        <trans-unit id="be412a34e6685ca321b38fae5794bdc3419b0f98" translate="yes" xml:space="preserve">
          <source>The operation that closes the queue.</source>
          <target state="translated">큐를 닫는 작업입니다.</target>
        </trans-unit>
        <trans-unit id="b2e5f0ceeecca2686d84b94bc3fa75e7225fc1f4" translate="yes" xml:space="preserve">
          <source>The operation that enqueues a batch of tuples of tensors to the queue.</source>
          <target state="translated">튜플의 배치를 큐에 큐에 넣는 조작입니다.</target>
        </trans-unit>
        <trans-unit id="59123e207e4121d978f651d18670cf600162571e" translate="yes" xml:space="preserve">
          <source>The operation that enqueues a new tuple of tensors to the queue.</source>
          <target state="translated">큐에 새로운 튜플 튜플을 큐에 넣는 작업입니다.</target>
        </trans-unit>
        <trans-unit id="99898763428cef52c27daa776a42aecf7741168c" translate="yes" xml:space="preserve">
          <source>The operation that failed, if known.</source>
          <target state="translated">알려진 작업이 실패했습니다.</target>
        </trans-unit>
        <trans-unit id="21259fcd1f38c739e8e877f9049101d45ed6faeb" translate="yes" xml:space="preserve">
          <source>The operation that initializes the table.</source>
          <target state="translated">테이블을 초기화하는 작업입니다.</target>
        </trans-unit>
        <trans-unit id="7d4203f69addf4215a9f75fa10050cf92a106167" translate="yes" xml:space="preserve">
          <source>The operation was aborted, typically due to a concurrent action.</source>
          <target state="translated">일반적으로 동시 작업으로 인해 작업이 중단되었습니다.</target>
        </trans-unit>
        <trans-unit id="8d2fbee8f6406df6777f5eab458e89a6b6c00fa3" translate="yes" xml:space="preserve">
          <source>The operator before inversion.</source>
          <target state="translated">반전 전의 연산자.</target>
        </trans-unit>
        <trans-unit id="dca167c313a3afe14fe0a9adc69f0f5e8d1c9afb" translate="yes" xml:space="preserve">
          <source>The operator before taking the adjoint.</source>
          <target state="translated">인접하기 전에 연산자.</target>
        </trans-unit>
        <trans-unit id="dd77aed70dd9284b7d6c31fc643a9815d5df72eb" translate="yes" xml:space="preserve">
          <source>The optimization options associated with the dataset. See &lt;a href=&quot;experimental/optimizationoptions&quot;&gt;&lt;code&gt;tf.data.experimental.OptimizationOptions&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">데이터 세트와 관련된 최적화 옵션. 자세한 내용은 &lt;a href=&quot;experimental/optimizationoptions&quot;&gt; &lt;code&gt;tf.data.experimental.OptimizationOptions&lt;/code&gt; &lt;/a&gt; 를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="d41bfab8487c080f4a52aaa4180a3c960ee957f3" translate="yes" xml:space="preserve">
          <source>The optimizer adds nodes to the graph to collect gradients and pause the trainers until variables are updated. For the Parameter Server job:</source>
          <target state="translated">옵티마이 저는 그래프에 노드를 추가하여 그라디언트를 수집하고 변수가 업데이트 될 때까지 트레이너를 일시 중지합니다. 매개 변수 서버 작업의 경우 :</target>
        </trans-unit>
        <trans-unit id="54fde7cedba37819ea597c67bd03d0eccd830d20" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;feed_dict&lt;/code&gt; argument allows the caller to override the value of tensors in the graph. Each key in &lt;code&gt;feed_dict&lt;/code&gt; can be one of the following types:</source>
          <target state="translated">선택적 &lt;code&gt;feed_dict&lt;/code&gt; 인수를 사용하면 호출자가 그래프의 텐서 값을 대체 할 수 있습니다. &lt;code&gt;feed_dict&lt;/code&gt; 의 각 키 는 다음 유형 중 하나 일 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="802a640d90b4b6b27f2c21f94a40f0d9fba6af8f" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;feed_dict&lt;/code&gt; argument allows the caller to override the value of tensors in the graph. See run() for more information.</source>
          <target state="translated">선택적 &lt;code&gt;feed_dict&lt;/code&gt; 인수를 사용하면 호출자가 그래프의 텐서 값을 대체 할 수 있습니다. 자세한 내용은 run ()을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="eacc79006fb44e1fd531dba67ace0548202f07d4" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;num_updates&lt;/code&gt; parameter allows one to tweak the decay rate dynamically. It is typical to pass the count of training steps, usually kept in a variable that is incremented at each step, in which case the decay rate is lower at the start of training. This makes moving averages move faster. If passed, the actual decay rate used is:</source>
          <target state="translated">선택적 &lt;code&gt;num_updates&lt;/code&gt; 매개 변수를 사용하면 감쇠율을 동적으로 조정할 수 있습니다. 일반적으로 각 단계에서 증가하는 변수로 유지되는 훈련 단계 수를 통과하는 것이 일반적이며,이 경우 훈련 시작시 붕괴율이 낮아집니다. 이것은 이동 평균이 더 빠르게 움직입니다. 통과하면 실제 붕괴율은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="4d5f2024e82b1f112cdc773a7a0d099d108bab47" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;options&lt;/code&gt; argument expects a [&lt;code&gt;RunOptions&lt;/code&gt;] proto. The options allow controlling the behavior of this particular step (e.g. turning tracing on).</source>
          <target state="translated">선택적 &lt;code&gt;options&lt;/code&gt; 인수에는 [ &lt;code&gt;RunOptions&lt;/code&gt; ] 프로토 타입이 필요합니다. 옵션을 사용하면이 특정 단계의 동작을 제어 할 수 있습니다 (예 : 추적 설정).</target>
        </trans-unit>
        <trans-unit id="5dd8b71d547dc1502ab3faa2f08ccf41ba7e8b18" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;reshape&lt;/code&gt; argument, if &lt;code&gt;True&lt;/code&gt;, allows restoring a variable from a save file where the variable had a different shape, but the same number of elements and type. This is useful if you have reshaped a variable and want to reload it from an older checkpoint.</source>
          <target state="translated">선택적 &lt;code&gt;reshape&lt;/code&gt; 인수는 &lt;code&gt;True&lt;/code&gt; 인 경우 변수의 모양은 다르지만 요소 및 유형은 동일한 저장 파일에서 변수를 복원 할 수 있습니다. 변수를 재 형성하고 이전 체크 포인트에서 변수를 다시로드하려는 경우에 유용합니다.</target>
        </trans-unit>
        <trans-unit id="e970942946ff441e315a637342ca6559423698ca" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;run_metadata&lt;/code&gt; argument expects a [&lt;code&gt;RunMetadata&lt;/code&gt;] proto. When appropriate, the non-Tensor output of this step will be collected there. For example, when users turn on tracing in &lt;code&gt;options&lt;/code&gt;, the profiled info will be collected into this argument and passed back.</source>
          <target state="translated">선택적 &lt;code&gt;run_metadata&lt;/code&gt; 인수에는 [ &lt;code&gt;RunMetadata&lt;/code&gt; ] 프로토 타입이 필요합니다. 적절한 경우이 단계의 텐서가 아닌 출력이 여기에 수집됩니다. 예를 들어, 사용자가 &lt;code&gt;options&lt;/code&gt; 에서 추적을 켜면 프로파일 링 된 정보가이 인수로 수집되어 다시 전달됩니다.</target>
        </trans-unit>
        <trans-unit id="4463c9db10422ab0ce9fc83cbdf23e0b400b34c3" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;sharded&lt;/code&gt; argument, if &lt;code&gt;True&lt;/code&gt;, instructs the saver to shard checkpoints per device.</source>
          <target state="translated">선택적 &lt;code&gt;sharded&lt;/code&gt; 인수는 &lt;code&gt;True&lt;/code&gt; 이면 세이버가 장치 당 샤드 체크 포인트를 지시하도록 지시합니다.</target>
        </trans-unit>
        <trans-unit id="9211a71d92ea323063ffa11455da47bbb168e612" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;signatures&lt;/code&gt; argument controls which methods in &lt;code&gt;obj&lt;/code&gt; will be available to programs which consume &lt;code&gt;SavedModel&lt;/code&gt;s, for example serving APIs. Python functions may be decorated with &lt;code&gt;@tf.function(input_signature=...)&lt;/code&gt; and passed as signatures directly, or lazily with a call to &lt;code&gt;get_concrete_function&lt;/code&gt; on the method decorated with &lt;code&gt;@tf.function&lt;/code&gt;.</source>
          <target state="translated">선택적 &lt;code&gt;signatures&lt;/code&gt; 인수는 &lt;code&gt;SavedModel&lt;/code&gt; 을 소비하는 프로그램 ( 예 : API 제공) 에서 &lt;code&gt;obj&lt;/code&gt; 의 어떤 메소드를 사용할 수 있는지 제어합니다 . 파이썬 함수는 &lt;code&gt;@tf.function(input_signature=...)&lt;/code&gt; 로 장식 될 수 있으며 서명으로 직접 전달되거나 &lt;code&gt;@tf.function&lt;/code&gt; 장식 된 메소드 에서 &lt;code&gt;get_concrete_function&lt;/code&gt; 호출로 게으르게 전달 될 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="5eb10eb93ba6242a60bc81190f01e4562cc7c7f2" translate="yes" xml:space="preserve">
          <source>The options are &quot;global&quot; in the sense they apply to the entire dataset. If options are set multiple times, they are merged as long as different options do not use different non-default values.</source>
          <target state="translated">옵션은 전체 데이터 세트에 적용되는 의미에서 &quot;전역&quot;입니다. 옵션이 여러 번 설정된 경우 다른 옵션이 기본값이 아닌 다른 값을 사용하지 않는 한 병합됩니다.</target>
        </trans-unit>
        <trans-unit id="af401239a74cc22bb0656ceab277ae88265e81dd" translate="yes" xml:space="preserve">
          <source>The original method wrapped such that it enters the module's name scope.</source>
          <target state="translated">원래의 메소드는 모듈의 이름 범위에 들어가도록 랩핑되었습니다.</target>
        </trans-unit>
        <trans-unit id="f891d19803fb509490762be082d2f8ade6148c86" translate="yes" xml:space="preserve">
          <source>The original registered Flag objects can be retrieved through the use of the dictionary-like operator, &lt;strong&gt;getitem&lt;/strong&gt;: x = FLAGS['longname'] # access the registered Flag object</source>
          <target state="translated">사전 등록 된 Flag 객체는 사전과 같은 연산자 &lt;strong&gt;getitem을&lt;/strong&gt; 사용하여 검색 할 수 있습니다 . x = FLAGS [ 'longname'] # 등록 된 Flag 객체에 액세스</target>
        </trans-unit>
        <trans-unit id="b71549bb8296bfb172b0e5fa059a19b9055f4136" translate="yes" xml:space="preserve">
          <source>The other method &lt;code&gt;uniform&lt;/code&gt; only covers the range [minval, maxval), which cannot be &lt;code&gt;dtype&lt;/code&gt;'s full range because &lt;code&gt;maxval&lt;/code&gt; is of type &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="translated">다른 방법 &lt;code&gt;uniform&lt;/code&gt; 만 될 수 없다) MINVAL, MAXVAL 범위 커버 &lt;code&gt;dtype&lt;/code&gt; 때문에 S '전체 범위 &lt;code&gt;maxval&lt;/code&gt; 유형이다 &lt;code&gt;dtype&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8d650eca6a136e51fc7375e0969bc2ea1115b2e2" translate="yes" xml:space="preserve">
          <source>The output &lt;code&gt;SparseTensor&lt;/code&gt; object's shape values for all dimensions but the first are the max across the input &lt;code&gt;SparseTensor&lt;/code&gt; objects' shape values for the corresponding dimensions. Its first shape value is &lt;code&gt;N&lt;/code&gt;, the minibatch size.</source>
          <target state="translated">모든 치수에 대한 출력 &lt;code&gt;SparseTensor&lt;/code&gt; 객체의 모양 값이지만 첫 번째는 해당 치수에 대한 입력 &lt;code&gt;SparseTensor&lt;/code&gt; 객체의 모양 값에 대한 최대 값입니다. 첫 번째 도형 값은 미니 배치 크기 인 &lt;code&gt;N&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="27cd935b967006cc01a667a4b3f9d0444d7da4c5" translate="yes" xml:space="preserve">
          <source>The output &lt;code&gt;SparseTensor&lt;/code&gt; will be in row-major order and will have the same shape as the input.</source>
          <target state="translated">출력 &lt;code&gt;SparseTensor&lt;/code&gt; 는 행 주요 순서이며 입력과 동일한 모양을 갖습니다.</target>
        </trans-unit>
        <trans-unit id="25a24380035e136d9ea98af6a346f119051ef56c" translate="yes" xml:space="preserve">
          <source>The output Tensor as described above, dimensions will vary based on the op provided.</source>
          <target state="translated">위에서 설명한 출력 텐서, 치수는 제공된 op에 따라 다릅니다.</target>
        </trans-unit>
        <trans-unit id="47c4d6134bd40a175fa44afa8f9b377d5850de3c" translate="yes" xml:space="preserve">
          <source>The output consists of two tensors LU and P containing the LU decomposition of all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;. LU encodes the lower triangular and upper triangular factors.</source>
          <target state="translated">출력은 모든 입력 하위 행렬 &lt;code&gt;[..., :, :]&lt;/code&gt; 의 LU 분해를 포함하는 두 개의 텐서 LU 및 P로 구성됩니다 . LU는 하부 삼각 및 상부 삼각 계수를 인코딩합니다.</target>
        </trans-unit>
        <trans-unit id="048c6e1cfd308f6012ab77e90cbc674670b136c0" translate="yes" xml:space="preserve">
          <source>The output elements are taken from the input at intervals given by the &lt;code&gt;rate&lt;/code&gt; argument, as in dilated convolutions.</source>
          <target state="translated">출력 요소는 확장 된 회선에서와 같이 &lt;code&gt;rate&lt;/code&gt; 인수에 의해 주어진 간격으로 입력에서 가져옵니다 .</target>
        </trans-unit>
        <trans-unit id="01cfec4a29cc69f6abe94502062c73070782ab76" translate="yes" xml:space="preserve">
          <source>The output elements will be resorted to preserve the sort order along increasing dimension number.</source>
          <target state="translated">치수 요소가 증가함에 따라 정렬 순서를 유지하기 위해 출력 요소가 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="38c8f8944795768b987abf44161bc29810671bc1" translate="yes" xml:space="preserve">
          <source>The output is a tensor of rank &lt;code&gt;k+1&lt;/code&gt; with dimensions &lt;code&gt;[I, J, ..., L, M, N]&lt;/code&gt;. If &lt;code&gt;k&lt;/code&gt; is scalar or &lt;code&gt;k[0] == k[1]&lt;/code&gt;:</source>
          <target state="translated">출력은 크기가 &lt;code&gt;[I, J, ..., L, M, N]&lt;/code&gt; 인 순위 &lt;code&gt;k+1&lt;/code&gt; 의 텐서입니다 . 경우 &lt;code&gt;k&lt;/code&gt; 는 스칼라이거나 &lt;code&gt;k[0] == k[1]&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="b9f3b180f0596bc470d2fb79c1dedac7776f93d9" translate="yes" xml:space="preserve">
          <source>The output is a tensor of shape &lt;code&gt;[..., M, K]&lt;/code&gt;. If &lt;code&gt;adjoint&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; then the innermost matrices in &lt;code&gt;output&lt;/code&gt; satisfy matrix equations &lt;code&gt;matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]&lt;/code&gt;. If &lt;code&gt;adjoint&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; then the strictly then the innermost matrices in &lt;code&gt;output&lt;/code&gt; satisfy matrix equations &lt;code&gt;adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]&lt;/code&gt;.</source>
          <target state="translated">출력은 모양 &lt;code&gt;[..., M, K]&lt;/code&gt; 의 텐서입니다 . 경우 &lt;code&gt;adjoint&lt;/code&gt; 인 &lt;code&gt;True&lt;/code&gt; 다음의 최 행렬 &lt;code&gt;output&lt;/code&gt; 만족 행렬 방정식을 &lt;code&gt;matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]&lt;/code&gt; . 경우 &lt;code&gt;adjoint&lt;/code&gt; 인 &lt;code&gt;False&lt;/code&gt; 후 엄격 다음의 최 행렬 &lt;code&gt;output&lt;/code&gt; 행렬 방정식을 만족 &lt;code&gt;adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="24258a9b3cf1537928d726a4c142766d14a612d5" translate="yes" xml:space="preserve">
          <source>The output is a tensor of the same shape as &lt;code&gt;rhs&lt;/code&gt;: either &lt;code&gt;[..., M]&lt;/code&gt; or &lt;code&gt;[..., M, K]&lt;/code&gt;.</source>
          <target state="translated">출력은 &lt;code&gt;rhs&lt;/code&gt; 와 동일한 모양의 텐서입니다 : &lt;code&gt;[..., M]&lt;/code&gt; 또는 &lt;code&gt;[..., M, K]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7d3db7f6f2ef07d73508fa555433bf8d83a75eaa" translate="yes" xml:space="preserve">
          <source>The output is a tensor of the same shape as the input containing the Cholesky decompositions for all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;.</source>
          <target state="translated">출력은 모든 입력 하위 행렬 &lt;code&gt;[..., :, :]&lt;/code&gt; 대한 Cholesky 분해를 포함하는 입력과 동일한 모양의 텐서입니다 .</target>
        </trans-unit>
        <trans-unit id="02cc9038a532f36829ca3735f949f57712e9a776" translate="yes" xml:space="preserve">
          <source>The output locations corresponding to the implicitly zero elements in the sparse tensor will be zero (i.e., will not take up storage space), regardless of the contents of the dense tensor (even if it's +/-INF and that INF*0 == NaN).</source>
          <target state="translated">희박한 텐서의 암시 적으로 0 요소에 해당하는 출력 위치는 밀도 텐서의 내용에 관계없이 0입니다 (즉, 저장 공간을 차지하지 않습니다) (+/- INF이고 INF * 0 == 인 경우에도) NaN).</target>
        </trans-unit>
        <trans-unit id="b30d98674beeba8558b72dc407638d1340b74552" translate="yes" xml:space="preserve">
          <source>The output of the 1-arg function that takes the &lt;code&gt;step&lt;/code&gt; is &lt;code&gt;values[0]&lt;/code&gt; when &lt;code&gt;step &amp;lt;= boundaries[0]&lt;/code&gt;, &lt;code&gt;values[1]&lt;/code&gt; when &lt;code&gt;step &amp;gt; boundaries[0]&lt;/code&gt; and &lt;code&gt;step &amp;lt;= boundaries[1]&lt;/code&gt;, ..., and values[-1] when &lt;code&gt;step &amp;gt; boundaries[-1]&lt;/code&gt;.</source>
          <target state="translated">걸리는 1 인수 함수의 출력 &lt;code&gt;step&lt;/code&gt; 인 &lt;code&gt;values[0]&lt;/code&gt; 때 &lt;code&gt;step &amp;lt;= boundaries[0]&lt;/code&gt; , &lt;code&gt;values[1]&lt;/code&gt; 때 &lt;code&gt;step &amp;gt; boundaries[0]&lt;/code&gt; 및 &lt;code&gt;step &amp;lt;= boundaries[1]&lt;/code&gt; , ..., 및 &lt;code&gt;step &amp;gt; boundaries[-1]&lt;/code&gt; 값 [-1] 일 때의 값 [ -1] .</target>
        </trans-unit>
        <trans-unit id="d04584f160db196293c2030ae17c2dacfbfcd30d" translate="yes" xml:space="preserve">
          <source>The output of this Op is a single bounding box that may be used to crop the original image. The output is returned as 3 tensors: &lt;code&gt;begin&lt;/code&gt;, &lt;code&gt;size&lt;/code&gt; and &lt;code&gt;bboxes&lt;/code&gt;. The first 2 tensors can be fed directly into &lt;a href=&quot;../../../slice&quot;&gt;&lt;code&gt;tf.slice&lt;/code&gt;&lt;/a&gt; to crop the image. The latter may be supplied to &lt;a href=&quot;../../../image/draw_bounding_boxes&quot;&gt;&lt;code&gt;tf.image.draw_bounding_boxes&lt;/code&gt;&lt;/a&gt; to visualize what the bounding box looks like.</source>
          <target state="translated">이 Op의 출력은 원본 이미지를 자르는 데 사용할 수있는 단일 경계 상자입니다. 결과는 3 개의 텐서 ( &lt;code&gt;begin&lt;/code&gt; , &lt;code&gt;size&lt;/code&gt; 및 &lt;code&gt;bboxes&lt;/code&gt; )로 반환됩니다 . 처음 2 개의 텐서는 이미지를 자르기 위해 &lt;a href=&quot;../../../slice&quot;&gt; &lt;code&gt;tf.slice&lt;/code&gt; &lt;/a&gt; 에 직접 공급 될 수 있습니다 . 후자는 &lt;a href=&quot;../../../image/draw_bounding_boxes&quot;&gt; &lt;code&gt;tf.image.draw_bounding_boxes&lt;/code&gt; &lt;/a&gt; 에 제공되어 경계 상자의 모양을 시각화 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="5e995a951ce7a3cd16e04e8cd70419e327350a30" translate="yes" xml:space="preserve">
          <source>The output of this Op is a single bounding box that may be used to crop the original image. The output is returned as 3 tensors: &lt;code&gt;begin&lt;/code&gt;, &lt;code&gt;size&lt;/code&gt; and &lt;code&gt;bboxes&lt;/code&gt;. The first 2 tensors can be fed directly into &lt;a href=&quot;../slice&quot;&gt;&lt;code&gt;tf.slice&lt;/code&gt;&lt;/a&gt; to crop the image. The latter may be supplied to &lt;a href=&quot;draw_bounding_boxes&quot;&gt;&lt;code&gt;tf.image.draw_bounding_boxes&lt;/code&gt;&lt;/a&gt; to visualize what the bounding box looks like.</source>
          <target state="translated">이 Op의 출력은 원본 이미지를 자르는 데 사용할 수있는 단일 경계 상자입니다. 결과는 3 개의 텐서 ( &lt;code&gt;begin&lt;/code&gt; , &lt;code&gt;size&lt;/code&gt; 및 &lt;code&gt;bboxes&lt;/code&gt; )로 반환됩니다 . 처음 2 개의 텐서는 이미지를 자르기 위해 &lt;a href=&quot;../slice&quot;&gt; &lt;code&gt;tf.slice&lt;/code&gt; &lt;/a&gt; 에 직접 공급 될 수 있습니다 . 후자는 &lt;a href=&quot;draw_bounding_boxes&quot;&gt; &lt;code&gt;tf.image.draw_bounding_boxes&lt;/code&gt; &lt;/a&gt; 에 제공되어 경계 상자의 모양을 시각화 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="867a41c15dc52766b0de85d04ee44344a9063866" translate="yes" xml:space="preserve">
          <source>The output of this method is a 3D &lt;code&gt;Tensor&lt;/code&gt; of shape &lt;code&gt;[batch_size, T, D]&lt;/code&gt;. &lt;code&gt;T&lt;/code&gt; is the maximum sequence length for this batch, which could differ from batch to batch.</source>
          <target state="translated">이 방법의 출력은 모양이 &lt;code&gt;[batch_size, T, D]&lt;/code&gt; 3D &lt;code&gt;Tensor&lt;/code&gt; 입니다 . &lt;code&gt;T&lt;/code&gt; 는이 배치의 최대 시퀀스 길이이며 배치마다 다를 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="eac10a40d7ace5a75143c2fbccbd028ece77a9fb" translate="yes" xml:space="preserve">
          <source>The output slice &lt;code&gt;i&lt;/code&gt; along dimension &lt;code&gt;batch_axis&lt;/code&gt; is then given by input slice &lt;code&gt;i&lt;/code&gt;, with the first &lt;code&gt;seq_lengths[i]&lt;/code&gt; slices along dimension &lt;code&gt;seq_axis&lt;/code&gt; reversed.</source>
          <target state="translated">출력 슬라이스 &lt;code&gt;i&lt;/code&gt; 사이즈에 따라 &lt;code&gt;batch_axis&lt;/code&gt; 가 다음 입력 슬라이스 주어진다 &lt;code&gt;i&lt;/code&gt; 처음으로 &lt;code&gt;seq_lengths[i]&lt;/code&gt; 사이즈에 따라 분할 &lt;code&gt;seq_axis&lt;/code&gt; 는 반대로.</target>
        </trans-unit>
        <trans-unit id="d0270145e0963e3fa6b4466fddef88fdbf60e481" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[1, 2, 2, 1]&lt;/code&gt; and value:</source>
          <target state="translated">출력 텐서는 모양 &lt;code&gt;[1, 2, 2, 1]&lt;/code&gt; 과 값을 갖습니다 :</target>
        </trans-unit>
        <trans-unit id="aff644b1606cf977042c3f329c0b44912b343d5f" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[1, 2, 2, 3]&lt;/code&gt; and value:</source>
          <target state="translated">출력 텐서는 모양 &lt;code&gt;[1, 2, 2, 3]&lt;/code&gt; 과 값을 갖습니다 :</target>
        </trans-unit>
        <trans-unit id="26ecc2d485656620c8ddae36c3377b136f2c8ef6" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[1, 4, 4, 1]&lt;/code&gt; and value:</source>
          <target state="translated">출력 텐서는 모양 &lt;code&gt;[1, 4, 4, 1]&lt;/code&gt; 과 값을 갖습니다 :</target>
        </trans-unit>
        <trans-unit id="413cce56d7e73e0557f6955da012eeb198f78207" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[2, 2, 4, 1]&lt;/code&gt; and value:</source>
          <target state="translated">출력 텐서는 모양 &lt;code&gt;[2, 2, 4, 1]&lt;/code&gt; 과 값을 갖습니다 :</target>
        </trans-unit>
        <trans-unit id="580524501d7754a464d140a489afd8a69565b7e8" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[4, 1, 1, 1]&lt;/code&gt; and value:</source>
          <target state="translated">출력 텐서는 모양 &lt;code&gt;[4, 1, 1, 1]&lt;/code&gt; 과 값을 갖습니다 :</target>
        </trans-unit>
        <trans-unit id="43b93cea1c5beede2692779450404b22ddd16414" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[4, 1, 1, 3]&lt;/code&gt; and value:</source>
          <target state="translated">출력 텐서는 모양 &lt;code&gt;[4, 1, 1, 3]&lt;/code&gt; 과 값을 갖습니다 :</target>
        </trans-unit>
        <trans-unit id="863590a97a6747705662d02c1d09d524c465ba85" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[4, 2, 2, 1]&lt;/code&gt; and value:</source>
          <target state="translated">출력 텐서는 모양 &lt;code&gt;[4, 2, 2, 1]&lt;/code&gt; 과 값을 갖습니다 :</target>
        </trans-unit>
        <trans-unit id="951a2f1acb5ea54cd01c5c69fad552b3af0398ec" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[8, 1, 2, 1]&lt;/code&gt; and value:</source>
          <target state="translated">출력 텐서는 모양 &lt;code&gt;[8, 1, 2, 1]&lt;/code&gt; 과 값을 갖습니다 :</target>
        </trans-unit>
        <trans-unit id="b991f9c184601aa1cf79a030dce35cd2e1811686" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[8, 1, 3, 1]&lt;/code&gt; and value:</source>
          <target state="translated">출력 텐서는 모양 &lt;code&gt;[8, 1, 3, 1]&lt;/code&gt; 과 값을 갖습니다 :</target>
        </trans-unit>
        <trans-unit id="018a92a28c57571fe5c1edcfb924689c52abc4b8" translate="yes" xml:space="preserve">
          <source>The output tensor, of rank 3.</source>
          <target state="translated">순위 3의 출력 텐서.</target>
        </trans-unit>
        <trans-unit id="f156d1cf6b13fd91d5c1751333de4bfa7481e5ec" translate="yes" xml:space="preserve">
          <source>The output tensors for the loop variables after the loop. If &lt;code&gt;return_same_structure&lt;/code&gt; is True, the return value has the same structure as &lt;code&gt;loop_vars&lt;/code&gt;. If &lt;code&gt;return_same_structure&lt;/code&gt; is False, the return value is a Tensor, TensorArray or IndexedSlice if the length of &lt;code&gt;loop_vars&lt;/code&gt; is 1, or a list otherwise.</source>
          <target state="translated">루프 뒤의 루프 변수에 대한 출력 텐서. 경우 &lt;code&gt;return_same_structure&lt;/code&gt; 이 사실 인 경우, 반환 값은 같은 구조가 &lt;code&gt;loop_vars&lt;/code&gt; 를 . 경우 &lt;code&gt;return_same_structure&lt;/code&gt; 이 False 인의 길이 경우, 반환 값은 텐서, TensorArray 또는 IndexedSlice입니다 &lt;code&gt;loop_vars&lt;/code&gt; 은 1, 또는 목록이 없습니다.</target>
        </trans-unit>
        <trans-unit id="0bda5fbd6b0783b500c1218ac7c4c0e7746a4905" translate="yes" xml:space="preserve">
          <source>The output tensors for the loop variables after the loop. The return value has the same structure as &lt;code&gt;loop_vars&lt;/code&gt;.</source>
          <target state="translated">루프 뒤의 루프 변수에 대한 출력 텐서. 리턴 값은 &lt;code&gt;loop_vars&lt;/code&gt; 와 동일한 구조를 갖습니다 .</target>
        </trans-unit>
        <trans-unit id="1bcada90c4c3eacc21413e8c1e200a0e90b07ffc" translate="yes" xml:space="preserve">
          <source>The output will then have shape &lt;code&gt;(32, 10, 32)&lt;/code&gt;.</source>
          <target state="translated">그러면 출력은 shape &lt;code&gt;(32, 10, 32)&lt;/code&gt; 됩니다.</target>
        </trans-unit>
        <trans-unit id="6d23cb786d0f9d1271884eaa7c1f7cc8c8a656c8" translate="yes" xml:space="preserve">
          <source>The output will then have shape &lt;code&gt;(32, 10, 8)&lt;/code&gt;.</source>
          <target state="translated">그러면 출력은 shape &lt;code&gt;(32, 10, 8)&lt;/code&gt; 됩니다.</target>
        </trans-unit>
        <trans-unit id="262b53d310948dd3d4d6f3d1b24c8027dcc78d4c" translate="yes" xml:space="preserve">
          <source>The outputs from all shards are concatenated back together along their 0-th dimension.</source>
          <target state="translated">모든 샤드의 출력은 0 차원을 따라 다시 연결됩니다.</target>
        </trans-unit>
        <trans-unit id="fec5d02e1747f7a22db33ab6777959dc638f2020" translate="yes" xml:space="preserve">
          <source>The outputs of functions used as &lt;code&gt;signatures&lt;/code&gt; must either be flat lists, in which case outputs will be numbered, or a dictionary mapping string keys to &lt;code&gt;Tensor&lt;/code&gt;, in which case the keys will be used to name outputs.</source>
          <target state="translated">&lt;code&gt;signatures&lt;/code&gt; 사용되는 함수의 출력은 플랫리스트 (출력의 경우 번호가 매겨 짐) 또는 사전에 문자열 키를 &lt;code&gt;Tensor&lt;/code&gt; 에 매핑해야 하며,이 경우 키를 사용하여 출력의 이름을 지정합니다.</target>
        </trans-unit>
        <trans-unit id="f4fe37226e907ad6b84032ccb7a1a60c428d9656" translate="yes" xml:space="preserve">
          <source>The padded size of each dimension D of the output is:</source>
          <target state="translated">출력의 각 차원 D의 패딩 크기는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="d91e185b3ec2b95e4e28b058fb7de6ed54c4f63d" translate="yes" xml:space="preserve">
          <source>The parameters &lt;code&gt;concentration&lt;/code&gt; and &lt;code&gt;rate&lt;/code&gt; must be shaped in a way that supports broadcasting (e.g. &lt;code&gt;concentration + rate&lt;/code&gt; is a valid operation).</source>
          <target state="translated">매개 변수 &lt;code&gt;concentration&lt;/code&gt; 및 &lt;code&gt;rate&lt;/code&gt; 는 방송을 지원하는 방식으로 형성되어야합니다 (예 : &lt;code&gt;concentration + rate&lt;/code&gt; 는 유효한 작업입니다).</target>
        </trans-unit>
        <trans-unit id="c4bf0f9162b85380657aa85a48762d0989942eac" translate="yes" xml:space="preserve">
          <source>The parameters &lt;code&gt;df&lt;/code&gt;, &lt;code&gt;loc&lt;/code&gt;, and &lt;code&gt;scale&lt;/code&gt; must be shaped in a way that supports broadcasting (e.g. &lt;code&gt;df + loc + scale&lt;/code&gt; is a valid operation).</source>
          <target state="translated">매개 변수 &lt;code&gt;df&lt;/code&gt; , &lt;code&gt;loc&lt;/code&gt; 및 &lt;code&gt;scale&lt;/code&gt; 은 브로드 캐스트를 지원하는 방식으로 형성되어야합니다 (예 : &lt;code&gt;df + loc + scale&lt;/code&gt; 은 유효한 작업입니다).</target>
        </trans-unit>
        <trans-unit id="f624db393a0283cdff3712a3c4bd723d749a30a5" translate="yes" xml:space="preserve">
          <source>The parameters &lt;code&gt;loc&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt; must be shaped in a way that supports broadcasting (e.g. &lt;code&gt;loc + scale&lt;/code&gt; is a valid operation).</source>
          <target state="translated">매개 변수 &lt;code&gt;loc&lt;/code&gt; 및 &lt;code&gt;scale&lt;/code&gt; 은 브로드 캐스트를 지원하는 방식으로 형성되어야합니다 (예 : &lt;code&gt;loc + scale&lt;/code&gt; 은 유효한 작업입니다).</target>
        </trans-unit>
        <trans-unit id="a2bb7ef60bf0239928d550799fd1318ab8a8e22c" translate="yes" xml:space="preserve">
          <source>The parameters &lt;code&gt;loc&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt; must be shaped in a way that supports broadcasting (e.g., &lt;code&gt;loc / scale&lt;/code&gt; is a valid operation).</source>
          <target state="translated">파라미터 &lt;code&gt;loc&lt;/code&gt; 및 &lt;code&gt;scale&lt;/code&gt; 은 브로드 캐스트를 지원하는 방식으로 형성되어야합니다 (예 : &lt;code&gt;loc / scale&lt;/code&gt; 은 유효한 작업입니다).</target>
        </trans-unit>
        <trans-unit id="caea2d657314fc74a3b4c82a6b1a8e2927d4e265" translate="yes" xml:space="preserve">
          <source>The parameters &lt;code&gt;low&lt;/code&gt; and &lt;code&gt;high&lt;/code&gt; must be shaped in a way that supports broadcasting (e.g., &lt;code&gt;high - low&lt;/code&gt; is a valid operation).</source>
          <target state="translated">&lt;code&gt;low&lt;/code&gt; 및 &lt;code&gt;high&lt;/code&gt; 매개 변수 는 브로드 캐스트를 지원하는 방식으로 형성되어야합니다 (예 : &lt;code&gt;high - low&lt;/code&gt; 이 유효한 작업).</target>
        </trans-unit>
        <trans-unit id="f861e09ace62d9cf6a436ce61f90b0514dff3612" translate="yes" xml:space="preserve">
          <source>The parameters can be intuited via their relationship to mean and stddev,</source>
          <target state="translated">매개 변수는 mean 및 stddev와의 관계를 통해 직관 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="78832ff2cd51fc67f3284e123b0a8c7a1096d66b" translate="yes" xml:space="preserve">
          <source>The parent could be a module when the child is a function at module scope. Or the parent could be a class when a class' method is being replaced. The named child is set to new_child, while the prior definition is saved away for later, when UnsetAll() is called.</source>
          <target state="translated">자식이 모듈 범위에서 함수일 때 부모는 모듈 일 수 있습니다. 또는 클래스의 메서드를 교체 할 때 부모가 클래스가 될 수 있습니다. 명명 된 자식은 new_child로 설정되고 UnsetAll ()이 호출 될 때 이전 정의는 나중에 저장됩니다.</target>
        </trans-unit>
        <trans-unit id="cc13d476090ccb6ba884188ddcc28a81f62b0726" translate="yes" xml:space="preserve">
          <source>The parse() method checks to make sure that the string argument is a legal value and convert it to a native type. If the value cannot be converted, it should throw a 'ValueError' exception with a human readable explanation of why the value is illegal.</source>
          <target state="translated">parse () 메서드는 문자열 인수가 올바른 값인지 확인하고 기본 형식으로 변환합니다. 값을 변환 할 수 없으면 값이 잘못된 이유에 대한 사람이 읽을 수있는 설명과 함께 'ValueError'예외가 발생해야합니다.</target>
        </trans-unit>
        <trans-unit id="cf0794be97523b0be42896e118da1be5a61ff4da" translate="yes" xml:space="preserve">
          <source>The parsed value in native type.</source>
          <target state="translated">기본 유형의 구문 분석 된 값입니다.</target>
        </trans-unit>
        <trans-unit id="8cff8c184992ecf7d79d6a190fc8e2ad81b8dd10" translate="yes" xml:space="preserve">
          <source>The partitioned embedding in &lt;code&gt;embedding_weights&lt;/code&gt; must all be the same shape except for the first dimension. The first dimension is allowed to vary as the vocabulary size is not necessarily a multiple of &lt;code&gt;P&lt;/code&gt;. &lt;code&gt;embedding_weights&lt;/code&gt; may be a &lt;code&gt;PartitionedVariable&lt;/code&gt; as returned by using &lt;a href=&quot;../compat/v1/get_variable&quot;&gt;&lt;code&gt;tf.compat.v1.get_variable()&lt;/code&gt;&lt;/a&gt; with a partitioner.</source>
          <target state="translated">분할에 매립 &lt;code&gt;embedding_weights&lt;/code&gt; 는 모든 제 치수 제외한 같은 형상이어야한다. 어휘 크기가 반드시 &lt;code&gt;P&lt;/code&gt; 의 배수 일 필요는 없으므로 첫 번째 차원을 변경할 수 있습니다 . &lt;code&gt;embedding_weights&lt;/code&gt; 는 &lt;code&gt;PartitionedVariable&lt;/code&gt; &lt;a href=&quot;../compat/v1/get_variable&quot;&gt; &lt;code&gt;tf.compat.v1.get_variable()&lt;/code&gt; &lt;/a&gt; 함께 tf.compat.v1.get_variable () 을 사용하여 반환 된 PartitionedVariable 일 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="8e157288a667a186f035deba918682c801fa1abf" translate="yes" xml:space="preserve">
          <source>The partitioned embedding in &lt;code&gt;embedding_weights&lt;/code&gt; must all be the same shape except for the first dimension. The first dimension is allowed to vary as the vocabulary size is not necessarily a multiple of &lt;code&gt;P&lt;/code&gt;. &lt;code&gt;embedding_weights&lt;/code&gt; may be a &lt;code&gt;PartitionedVariable&lt;/code&gt; as returned by using &lt;a href=&quot;../get_variable&quot;&gt;&lt;code&gt;tf.compat.v1.get_variable()&lt;/code&gt;&lt;/a&gt; with a partitioner.</source>
          <target state="translated">분할에 매립 &lt;code&gt;embedding_weights&lt;/code&gt; 는 모든 제 치수 제외한 같은 형상이어야한다. 어휘 크기가 반드시 &lt;code&gt;P&lt;/code&gt; 의 배수 일 필요는 없으므로 첫 번째 차원을 변경할 수 있습니다 . &lt;code&gt;embedding_weights&lt;/code&gt; 는 &lt;code&gt;PartitionedVariable&lt;/code&gt; &lt;a href=&quot;../get_variable&quot;&gt; &lt;code&gt;tf.compat.v1.get_variable()&lt;/code&gt; &lt;/a&gt; 함께 tf.compat.v1.get_variable () 을 사용하여 반환 된 PartitionedVariable 일 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="b3b7bcbb761db59d963bb51839f46a4b29f4af4e" translate="yes" xml:space="preserve">
          <source>The path is relative to tensorflow/</source>
          <target state="translated">경로는 tensorflow /</target>
        </trans-unit>
        <trans-unit id="f48baa97e568a9b9e3b5f52a6ab7e866fecd8550" translate="yes" xml:space="preserve">
          <source>The path of the output proto file.</source>
          <target state="translated">출력 프로토 파일의 경로입니다.</target>
        </trans-unit>
        <trans-unit id="2c6d384388d19ed3fa790b1769ea860a0e6be8d0" translate="yes" xml:space="preserve">
          <source>The path to the new checkpoint. It is also recorded in the &lt;code&gt;checkpoints&lt;/code&gt; and &lt;code&gt;latest_checkpoint&lt;/code&gt; properties.</source>
          <target state="translated">새 체크 포인트의 경로입니다. &lt;code&gt;checkpoints&lt;/code&gt; 및 &lt;code&gt;latest_checkpoint&lt;/code&gt; 속성 에도 기록됩니다 .</target>
        </trans-unit>
        <trans-unit id="0ee0e0b9b831848f3b4065f81ba73b2d7593c0f8" translate="yes" xml:space="preserve">
          <source>The path to the specified file present in the data attribute of py_test or py_binary.</source>
          <target state="translated">py_test 또는 py_binary의 데이터 속성에 지정된 파일의 경로입니다.</target>
        </trans-unit>
        <trans-unit id="c28b39685fa19f5fe1fe963ce50d396e16dbe87f" translate="yes" xml:space="preserve">
          <source>The path to the specified file present in the data attribute of py_test or py_binary. Falls back to returning the same as get_data_files_path if it fails to detect a bazel runfiles directory.</source>
          <target state="translated">py_test 또는 py_binary의 데이터 속성에 지정된 파일의 경로입니다. bazel runfiles 디렉토리를 감지하지 못하면 get_data_files_path와 동일하게 리턴합니다.</target>
        </trans-unit>
        <trans-unit id="87756ef48ceb2a46a88324fa1e20a23d5ed02a12" translate="yes" xml:space="preserve">
          <source>The path to which the SavedModel protocol buffer was written.</source>
          <target state="translated">SavedModel 프로토콜 버퍼가 작성된 경로입니다.</target>
        </trans-unit>
        <trans-unit id="c7281e72ad08903abeb2bd587c7c0dfd0d8772e6" translate="yes" xml:space="preserve">
          <source>The pattern follows the re2 syntax (https://github.com/google/re2/wiki/Syntax)</source>
          <target state="translated">패턴은 re2 구문 (https://github.com/google/re2/wiki/Syntax)을 따릅니다.</target>
        </trans-unit>
        <trans-unit id="5c52ca33f774b534fe80a4db87092be76893e002" translate="yes" xml:space="preserve">
          <source>The peephole implementation is based on:</source>
          <target state="translated">들여다 보는 구멍 구현은 다음을 기반으로합니다.</target>
        </trans-unit>
        <trans-unit id="baf8710cc0a85723dd8aa2526d303f0863e63136" translate="yes" xml:space="preserve">
          <source>The performance of &lt;code&gt;LinearOperatorAdjoint&lt;/code&gt; depends on the underlying operators performance.</source>
          <target state="translated">&lt;code&gt;LinearOperatorAdjoint&lt;/code&gt; 의 성능은 기본 연산자 성능에 따라 다릅니다.</target>
        </trans-unit>
        <trans-unit id="80d488d70fd1fbe1594d7c6c118ae3795bd1145d" translate="yes" xml:space="preserve">
          <source>The performance of &lt;code&gt;LinearOperatorBlockDiag&lt;/code&gt; on any operation is equal to the sum of the individual operators' operations.</source>
          <target state="translated">모든 작업 에서 &lt;code&gt;LinearOperatorBlockDiag&lt;/code&gt; 의 성능은 개별 운영자 작업의 합계와 같습니다.</target>
        </trans-unit>
        <trans-unit id="9b2ab24a37ac3d66ce6ff090c15ce4c8f5b1d480" translate="yes" xml:space="preserve">
          <source>The performance of &lt;code&gt;LinearOperatorComposition&lt;/code&gt; on any operation is equal to the sum of the individual operators' operations.</source>
          <target state="translated">모든 작업 에서 &lt;code&gt;LinearOperatorComposition&lt;/code&gt; 의 성능은 개별 연산자 작업의 합계와 같습니다.</target>
        </trans-unit>
        <trans-unit id="f94bad31467a9ea9f4b4d537674d8e77b0cf1a22" translate="yes" xml:space="preserve">
          <source>The performance of &lt;code&gt;LinearOperatorInversion&lt;/code&gt; depends on the underlying operators performance: &lt;code&gt;solve&lt;/code&gt; and &lt;code&gt;matmul&lt;/code&gt; are swapped, and determinant is inverted.</source>
          <target state="translated">&lt;code&gt;LinearOperatorInversion&lt;/code&gt; 의 성능은 기본 연산자 성능에 따라 다릅니다. &lt;code&gt;solve&lt;/code&gt; 및 &lt;code&gt;matmul&lt;/code&gt; 이 스왑되고 결정자가 반전됩니다.</target>
        </trans-unit>
        <trans-unit id="bc0efd32d22cd6d37162492744eb9c09073101ec" translate="yes" xml:space="preserve">
          <source>The performance of &lt;code&gt;LinearOperatorKronecker&lt;/code&gt; on any operation is equal to the sum of the individual operators' operations.</source>
          <target state="translated">모든 작업 에서 &lt;code&gt;LinearOperatorKronecker&lt;/code&gt; 의 성능은 개별 운영자 작업의 합계와 같습니다.</target>
        </trans-unit>
        <trans-unit id="3adcc83502b5bf35b4db3b88505bc6feb67f24c9" translate="yes" xml:space="preserve">
          <source>The polygamma function is defined as:</source>
          <target state="translated">폴리 감마 함수는 다음과 같이 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="692359d83812b544d928c04fadf8b5c3c2df67a0" translate="yes" xml:space="preserve">
          <source>The possible values are: &lt;code&gt;GATE_NONE&lt;/code&gt;, &lt;code&gt;GATE_OP&lt;/code&gt;, and &lt;code&gt;GATE_GRAPH&lt;/code&gt;.</source>
          <target state="translated">가능한 값은 &lt;code&gt;GATE_NONE&lt;/code&gt; , &lt;code&gt;GATE_OP&lt;/code&gt; 및 &lt;code&gt;GATE_GRAPH&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="d5d3e18deacf1c7ef93bee6d5b865603caff1a2a" translate="yes" xml:space="preserve">
          <source>The potentially support list contains a list of ops that are partially or fully supported, which is derived by simply scanning op names to check whether they can be handled without real conversion and specific parameters.</source>
          <target state="translated">잠재적으로 지원되는 목록에는 부분적으로 또는 완전히 지원되는 op 목록이 포함되어 있습니다. op 목록을 검색하여 실제 변환 및 특정 매개 변수없이 처리 할 수 ​​있는지 여부를 확인하면됩니다.</target>
        </trans-unit>
        <trans-unit id="aaf184bbd1e736ec9f0efcfa8ff77fd74b286f9f" translate="yes" xml:space="preserve">
          <source>The prefix of the most recent checkpoint in &lt;code&gt;directory&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;directory&lt;/code&gt; 에서 가장 최근의 검사 점의 접두사 .</target>
        </trans-unit>
        <trans-unit id="0cdbe0557abf05d8c31ba3846734c76d96d3bcc3" translate="yes" xml:space="preserve">
          <source>The primary usecase for this API is to put tensors in a set/dictionary. We can't put tensors in a set/dictionary as &lt;code&gt;tensor.__hash__()&lt;/code&gt; is no longer available starting Tensorflow 2.0.</source>
          <target state="translated">이 API의 기본 사용 사례는 텐서를 세트 / 사전에 배치하는 것입니다. &lt;code&gt;tensor.__hash__()&lt;/code&gt; 는 더 이상 Tensorflow 2.0부터 사용할 수 없으므로 세트 / 사전에 텐서를 넣을 수 없습니다 .</target>
        </trans-unit>
        <trans-unit id="14c5ca1e155e62f217839df947a76604aa7befe7" translate="yes" xml:space="preserve">
          <source>The primary usecase for this API is to put variables in a set/dictionary. We can't put variables in a set/dictionary as &lt;code&gt;variable.__hash__()&lt;/code&gt; is no longer available starting Tensorflow 2.0.</source>
          <target state="translated">이 API의 주요 사용 사례는 변수를 세트 / 사전에 넣는 것입니다. 변수를 set / dictionary에 넣을 수 없으므로 &lt;code&gt;variable.__hash__()&lt;/code&gt; 는 더 이상 Tensorflow 2.0부터 사용할 수 없습니다.</target>
        </trans-unit>
        <trans-unit id="bfffea38233a7f94cfc568cf11eefdfb38392417" translate="yes" xml:space="preserve">
          <source>The probability density function (pdf) is,</source>
          <target state="translated">확률 밀도 함수 (pdf)는</target>
        </trans-unit>
        <trans-unit id="d639692ffbb24f5fe23fd0cf8f29f9ea56836d74" translate="yes" xml:space="preserve">
          <source>The probability density function (pdf) of this distribution is,</source>
          <target state="translated">이 분포의 확률 밀도 함수 (pdf)는</target>
        </trans-unit>
        <trans-unit id="c2092fccabcd3a2abdef73412d545365899001b8" translate="yes" xml:space="preserve">
          <source>The probability mass function (pmf) is,</source>
          <target state="translated">확률 질량 함수 (pmf)는</target>
        </trans-unit>
        <trans-unit id="b1597763a35d57db9c807276fa76fead0e6bf3d7" translate="yes" xml:space="preserve">
          <source>The processing of each sample contains the following steps: 1) standardize each sample (usually lowercasing + punctuation stripping) 2) split each sample into substrings (usually words) 3) recombine substrings into tokens (usually ngrams) 4) index tokens (associate a unique int value with each token) 5) transform each sample using this index, either into a vector of ints or a dense float vector.</source>
          <target state="translated">각 샘플의 처리에는 다음 단계가 포함됩니다. 1) 각 샘플 표준화 (일반적으로 소문자 + 구두점 제거) 2) 각 샘플을 하위 문자열 (일반적으로 단어)로 분할 3) 하위 문자열을 토큰 (일반적으로 ngram)으로 재결합 4) 인덱스 토큰 ( 각 토큰으로 고유 한 int 값) 5)이 인덱스를 사용하여 각 샘플을 정수 벡터 또는 밀도가 높은 부동 벡터로 변환합니다.</target>
        </trans-unit>
        <trans-unit id="5e9c7a33590d968d1c4d2adb1f14e30ca9d6e013" translate="yes" xml:space="preserve">
          <source>The provided generator can be finite in which case the class will throw a &lt;code&gt;StopIteration&lt;/code&gt; exception.</source>
          <target state="translated">제공된 생성기는 유한 할 수 있으며이 경우 클래스에서 &lt;code&gt;StopIteration&lt;/code&gt; 예외가 발생합니다.</target>
        </trans-unit>
        <trans-unit id="8129f9559f62303b98c598e584d99bb1465d425d" translate="yes" xml:space="preserve">
          <source>The provided value can be a python boolean, a scalar boolean Tensor, or or a callable providing such a value; if a callable is passed it will be invoked on-demand to determine whether summary writing will occur.</source>
          <target state="translated">제공된 값은 파이썬 부울, 스칼라 부울 텐서 또는 이러한 값을 제공하는 호출 가능일 수 있습니다. 호출 가능 항목이 전달되면 요청시 요약 호출이 발생하는지 여부를 판별하기 위해 호출됩니다.</target>
        </trans-unit>
        <trans-unit id="d84a7589708b247ba11ef0a6241d0276fd1c0415" translate="yes" xml:space="preserve">
          <source>The pseudo-inverse of a matrix &lt;code&gt;A&lt;/code&gt;, is defined as: 'the matrix that 'solves' [the least-squares problem] &lt;code&gt;A @ x = b&lt;/code&gt;,' i.e., if &lt;code&gt;x_hat&lt;/code&gt; is a solution, then &lt;code&gt;A_pinv&lt;/code&gt; is the matrix such that &lt;code&gt;x_hat = A_pinv @ b&lt;/code&gt;. It can be shown that if &lt;code&gt;U @ Sigma @ V.T = A&lt;/code&gt; is the singular value decomposition of &lt;code&gt;A&lt;/code&gt;, then &lt;code&gt;A_pinv = V @ inv(Sigma) U^T&lt;/code&gt;. [(Strang, 1980)][1]</source>
          <target state="translated">행렬의 역행렬 &lt;code&gt;A&lt;/code&gt; 를 다음과 같이 정의한다 : &quot;매트릭스를 그 '로 해결할'[최소 제곱 문제] &lt;code&gt;A @ x = b&lt;/code&gt; '경우 즉 &lt;code&gt;x_hat&lt;/code&gt; 는 용액이고, 다음 &lt;code&gt;A_pinv&lt;/code&gt; 가 인 행렬되도록 &lt;code&gt;x_hat = A_pinv @ b&lt;/code&gt; . 이 표시 될 수있는 경우 &lt;code&gt;U @ Sigma @ V.T = A&lt;/code&gt; 의 특이 값 분해이다 다음 &lt;code&gt;A_pinv = V @ inv(Sigma) U^T&lt;/code&gt; . [(Strang, 1980)] [1] &lt;code&gt;A&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="9b22641be848196f7d9c02ba6fc3610602324007" translate="yes" xml:space="preserve">
          <source>The purpose of this function is to allow users of existing layers to slowly transition to Keras layers API without breaking existing functionality.</source>
          <target state="translated">이 기능의 목적은 기존 레이어 사용자가 기존 기능을 중단하지 않고 Keras 레이어 API로 천천히 전환 할 수 있도록하는 것입니다.</target>
        </trans-unit>
        <trans-unit id="d088d5e5d63d8b56ec540e3afc689671a1995e6f" translate="yes" xml:space="preserve">
          <source>The purpose of this scope is to allow users of existing layers to slowly transition to a Keras layers API without breaking existing functionality.</source>
          <target state="translated">이 범위의 목적은 기존 계층의 사용자가 기존 기능을 중단하지 않고 Keras 계층 API로 천천히 전환 할 수 있도록하는 것입니다.</target>
        </trans-unit>
        <trans-unit id="7c5cb70c5a3b792465bd5ce774c8ea2af3bb85e3" translate="yes" xml:space="preserve">
          <source>The python function &lt;code&gt;fn&lt;/code&gt; will be called once with symbolic arguments specified in the &lt;code&gt;signature&lt;/code&gt;, traced, and turned into a graph function. Any variables created by &lt;code&gt;fn&lt;/code&gt; will be owned by the object returned by &lt;code&gt;wrap_function&lt;/code&gt;. The resulting graph function can be called with tensors which match the signature.</source>
          <target state="translated">python 함수 &lt;code&gt;fn&lt;/code&gt; 은 &lt;code&gt;signature&lt;/code&gt; 에 지정된 기호 인수를 사용하여 한 번 호출 되고 추적되며 그래프 함수로 바뀝니다. &lt;code&gt;fn&lt;/code&gt; 에 의해 작성된 모든 변수 는 &lt;code&gt;wrap_function&lt;/code&gt; 에 의해 리턴 된 오브젝트가 소유합니다 . 결과 그래프 함수는 서명과 일치하는 텐서로 호출 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="b20ff491ff5822812275688511b761f22476aa65" translate="yes" xml:space="preserve">
          <source>The range of pixel values for the output image might be slightly different from the range for the input image because of limited numerical precision. To guarantee an output range, for example &lt;code&gt;[0.0, 1.0]&lt;/code&gt;, apply &lt;a href=&quot;../../../clip_by_value&quot;&gt;&lt;code&gt;tf.clip_by_value&lt;/code&gt;&lt;/a&gt; to the output.</source>
          <target state="translated">출력 이미지의 픽셀 값 범위는 제한된 숫자 정밀도로 인해 입력 이미지의 범위와 약간 다를 수 있습니다. 출력 범위 (예 : &lt;code&gt;[0.0, 1.0]&lt;/code&gt; 를 보장하려면 &lt;a href=&quot;../../../clip_by_value&quot;&gt; &lt;code&gt;tf.clip_by_value&lt;/code&gt; &lt;/a&gt; 를 출력에 적용 하십시오.</target>
        </trans-unit>
        <trans-unit id="afabff9ee6287914682ddea57965fb5330ae1825" translate="yes" xml:space="preserve">
          <source>The reason we get 'A2' instead 'A1' on the second call of &lt;a href=&quot;uniform&quot;&gt;&lt;code&gt;tf.random.uniform&lt;/code&gt;&lt;/a&gt; above is because the same &lt;a href=&quot;uniform&quot;&gt;&lt;code&gt;tf.random.uniform&lt;/code&gt;&lt;/a&gt; kernel (i.e. internel representation) is used by TensorFlow for all calls of it with the same arguments, and the kernel maintains an internal counter which is incremented every time it is executed, generating different results.</source>
          <target state="translated">위 의 &lt;a href=&quot;uniform&quot;&gt; &lt;code&gt;tf.random.uniform&lt;/code&gt; &lt;/a&gt; 의 두 번째 호출에서 'A1'대신 'A2'를 얻는 이유는 동일한 인수를 가진 모든 호출에 대해 동일한 &lt;a href=&quot;uniform&quot;&gt; &lt;code&gt;tf.random.uniform&lt;/code&gt; &lt;/a&gt; 커널 (즉, 인터 널 표현)이 TensorFlow에서 사용되기 때문입니다. 커널은 실행될 때마다 증가하는 내부 카운터를 유지하여 다른 결과를 생성합니다.</target>
        </trans-unit>
        <trans-unit id="466c31e39da78ea430b94cdcadf9fd7405e0f0cf" translate="yes" xml:space="preserve">
          <source>The reason we get 'A2' instead 'A1' on the second call of &lt;a href=&quot;uniform&quot;&gt;&lt;code&gt;tf.random.uniform&lt;/code&gt;&lt;/a&gt; above is because the secand call uses a different operation seed.</source>
          <target state="translated">위 의 &lt;a href=&quot;uniform&quot;&gt; &lt;code&gt;tf.random.uniform&lt;/code&gt; &lt;/a&gt; 의 두 번째 호출에서 'A1'대신 'A2'를 얻는 이유는 secand 호출이 다른 연산 시드를 사용하기 때문입니다.</target>
        </trans-unit>
        <trans-unit id="1280cfc6968446075563e60ad83288d637db87ba" translate="yes" xml:space="preserve">
          <source>The reconstruct one or more matrices from their LU decomposition(s).</source>
          <target state="translated">LU 분해로부터 하나 이상의 매트릭스를 재구성한다.</target>
        </trans-unit>
        <trans-unit id="39397157700bab61929a7d8ce8314e15144efa4b" translate="yes" xml:space="preserve">
          <source>The reduced SparseTensor.</source>
          <target state="translated">감소 된 SparseTensor.</target>
        </trans-unit>
        <trans-unit id="162a81b2ee639009df98d0138880fb964fcbc8fc" translate="yes" xml:space="preserve">
          <source>The reduced Tensor or the reduced SparseTensor if &lt;code&gt;output_is_sparse&lt;/code&gt; is True.</source>
          <target state="translated">&lt;code&gt;output_is_sparse&lt;/code&gt; 가 True 인 경우 감소 된 Tensor 또는 감소 된 SparseTensor 입니다.</target>
        </trans-unit>
        <trans-unit id="1e34999a75a17ec65b85f93cb20fe03874e9d9e8" translate="yes" xml:space="preserve">
          <source>The reduced Tensor.</source>
          <target state="translated">줄어든 텐서.</target>
        </trans-unit>
        <trans-unit id="fa52820210f038254236a33cd72deaaa4f2921cc" translate="yes" xml:space="preserve">
          <source>The reduced tensor (number of nonzero values).</source>
          <target state="translated">감소 된 텐서 (0이 아닌 값의 수).</target>
        </trans-unit>
        <trans-unit id="5089f15002ac696c728750d278b7a2bb4b8292fd" translate="yes" xml:space="preserve">
          <source>The reduced tensor, of the same dtype as the input_tensor.</source>
          <target state="translated">input_tensor와 동일한 dtype의 축소 된 텐서.</target>
        </trans-unit>
        <trans-unit id="377005a84a788fcaae09139342bfe31ee6c3e407" translate="yes" xml:space="preserve">
          <source>The reduced tensor.</source>
          <target state="translated">줄어든 텐서.</target>
        </trans-unit>
        <trans-unit id="32126f130f539d8b348c3776e0d288e0eb3023ae" translate="yes" xml:space="preserve">
          <source>The reference to the TensorArray.</source>
          <target state="translated">TensorArray에 대한 참조입니다.</target>
        </trans-unit>
        <trans-unit id="626421317b8daa7c4481578d7b1400cbc817027c" translate="yes" xml:space="preserve">
          <source>The regularized incomplete beta integral is defined as:</source>
          <target state="translated">정규화 된 불완전 베타 통합은 다음과 같이 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="08f7982eae76c3d1b8d5c546c5c6087586c14c26" translate="yes" xml:space="preserve">
          <source>The request does not have valid authentication credentials.</source>
          <target state="translated">요청에 유효한 인증 자격 증명이 없습니다.</target>
        </trans-unit>
        <trans-unit id="11fac311a887cb1b94b956ea27985cb8f91c9eab" translate="yes" xml:space="preserve">
          <source>The requirements to use the cuDNN implementation are:</source>
          <target state="translated">cuDNN 구현을 사용하기위한 요구 사항은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="d06ff612c69fb3df1f3d794bb785e13f8da40620" translate="yes" xml:space="preserve">
          <source>The result is a 4-D tensor of shape &lt;code&gt;[batch_size, glimpse_height, glimpse_width, channels]&lt;/code&gt;. The channels and batch dimensions are the same as that of the input tensor. The height and width of the output windows are specified in the &lt;code&gt;size&lt;/code&gt; parameter.</source>
          <target state="translated">결과는 모양의 4 차원 텐서입니다 &lt;code&gt;[batch_size, glimpse_height, glimpse_width, channels]&lt;/code&gt; . 채널 및 배치 치수는 입력 텐서와 동일합니다. 출력 창의 높이와 너비는 &lt;code&gt;size&lt;/code&gt; 매개 변수에 지정되어 있습니다.</target>
        </trans-unit>
        <trans-unit id="af8e15d374bd08a8ea2bebed96d25f27af99cc58" translate="yes" xml:space="preserve">
          <source>The result is a 4D tensor which is indexed by batch, row, and column. &lt;code&gt;output[i, x, y]&lt;/code&gt; contains a flattened patch of size &lt;code&gt;sizes[1], sizes[2]&lt;/code&gt; which is taken from the input starting at &lt;code&gt;images[i, x*strides[1], y*strides[2]]&lt;/code&gt;.</source>
          <target state="translated">결과는 배치, 행 및 열별로 색인이 생성 된 4D 텐서입니다. &lt;code&gt;output[i, x, y]&lt;/code&gt; 에는 크기 &lt;code&gt;sizes[1], sizes[2]&lt;/code&gt; 의 평탄화 된 패치가 포함됩니다 . &lt;code&gt;images[i, x*strides[1], y*strides[2]]&lt;/code&gt; 에서 시작하는 입력에서 가져온 .</target>
        </trans-unit>
        <trans-unit id="cc0fc847805d05865dd1fc80479599ef10e030da" translate="yes" xml:space="preserve">
          <source>The result of calling parse_example on these examples will produce a dictionary with entries for &quot;ids&quot; and &quot;values&quot;. Passing those two objects to this function along with vocab_size=6, will produce a &lt;code&gt;SparseTensor&lt;/code&gt; that sparsely represents all three instances. Namely, the &lt;code&gt;indices&lt;/code&gt; property will contain the coordinates of the non-zero entries in the feature matrix (the first dimension is the row number in the matrix, i.e., the index within the batch, and the second dimension is the column number, i.e., the feature id); &lt;code&gt;values&lt;/code&gt; will contain the actual values. &lt;code&gt;shape&lt;/code&gt; will be the shape of the original matrix, i.e., (3, 6). For our example above, the output will be equal to:</source>
          <target state="translated">이 예제에서 parse_example을 호출하면 &quot;ids&quot;및 &quot;values&quot;에 대한 항목이있는 사전이 생성됩니다. vocab_size = 6과 함께이 두 객체를이 함수에 전달하면 세 인스턴스를 모두 희소하게 나타내는 &lt;code&gt;SparseTensor&lt;/code&gt; 가 생성됩니다 . 즉, &lt;code&gt;indices&lt;/code&gt; 속성은 피처 매트릭스에서 0이 아닌 항목의 좌표를 포함합니다 (첫 번째 차원은 매트릭스의 행 번호, 즉 배치 내 인덱스이고 두 번째 차원은 열 번호입니다. 기능 ID); &lt;code&gt;values&lt;/code&gt; 은 실제 값 을 포함합니다. &lt;code&gt;shape&lt;/code&gt; 는 원래 행렬의 모양, 즉 (3, 6)입니다. 위의 예에서 출력은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="a7181bf7e73106c9b2b97d9fffba14ef65fbf1f8" translate="yes" xml:space="preserve">
          <source>The result of this op should be passed through a &lt;code&gt;sparse_to_dense&lt;/code&gt; operation, then added to the logits of the sampled classes. This removes the contradictory effect of accidentally sampling the true target classes as noise classes for the same example.</source>
          <target state="translated">이 op의 결과는 &lt;code&gt;sparse_to_dense&lt;/code&gt; 작업을 통과 한 다음 샘플링 된 클래스의 로그에 추가되어야합니다. 이것은 동일한 예제에서 실제 대상 클래스를 노이즈 클래스로 실수로 샘플링 한 모순 된 효과를 제거합니다.</target>
        </trans-unit>
        <trans-unit id="01298564c21aafdba5ad8531a719b0b62528e9fe" translate="yes" xml:space="preserve">
          <source>The result will have those bits set, that are different in &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. The computation is performed on the underlying representations of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">결과는 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 에서 다른 비트 세트를 갖게됩니다 . 계산은 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 의 기본 표현에 대해 수행됩니다 .</target>
        </trans-unit>
        <trans-unit id="685b62e5962fffb0313c314fe8766a83e91dc7ce" translate="yes" xml:space="preserve">
          <source>The result will have those bits set, that are set in &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt; or both. The computation is performed on the underlying representations of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">결과는 &lt;code&gt;x&lt;/code&gt; , &lt;code&gt;y&lt;/code&gt; 또는 둘 다에 설정된 비트를 갖게됩니다 . 계산은 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 의 기본 표현에 대해 수행됩니다 .</target>
        </trans-unit>
        <trans-unit id="b74f37adc87a210e3154c60f498551da0c0a3084" translate="yes" xml:space="preserve">
          <source>The result will have those bits set, that are set in both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. The computation is performed on the underlying representations of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">결과는 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 모두에 설정된 비트를 갖게됩니다 . 계산은 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 의 기본 표현에 대해 수행됩니다 .</target>
        </trans-unit>
        <trans-unit id="a454b218545175a81109283a1b62827f2751cc1d" translate="yes" xml:space="preserve">
          <source>The resulting &lt;code&gt;Tensor&lt;/code&gt; of parsing a single &lt;code&gt;SequenceExample&lt;/code&gt; or &lt;code&gt;Example&lt;/code&gt; has a static &lt;code&gt;shape&lt;/code&gt; of &lt;code&gt;[None] + shape&lt;/code&gt; and the specified &lt;code&gt;dtype&lt;/code&gt;. The resulting &lt;code&gt;Tensor&lt;/code&gt; of parsing a &lt;code&gt;batch_size&lt;/code&gt; many &lt;code&gt;Example&lt;/code&gt;s has a static &lt;code&gt;shape&lt;/code&gt; of &lt;code&gt;[batch_size, None] + shape&lt;/code&gt; and the specified &lt;code&gt;dtype&lt;/code&gt;. The entries in the &lt;code&gt;batch&lt;/code&gt; from different &lt;code&gt;Examples&lt;/code&gt; will be padded with &lt;code&gt;default_value&lt;/code&gt; to the maximum length present in the &lt;code&gt;batch&lt;/code&gt;.</source>
          <target state="translated">단일 &lt;code&gt;SequenceExample&lt;/code&gt; 또는 &lt;code&gt;Example&lt;/code&gt; 을 구문 분석하는 결과 &lt;code&gt;Tensor&lt;/code&gt; 는 정적 &lt;code&gt;shape&lt;/code&gt; 이 &lt;code&gt;[None] + shape&lt;/code&gt; 이고 지정된 &lt;code&gt;dtype&lt;/code&gt; 입니다. &lt;code&gt;batch_size&lt;/code&gt; many &lt;code&gt;Example&lt;/code&gt; 을 구문 분석하는 결과 &lt;code&gt;Tensor&lt;/code&gt; 의 정적 &lt;code&gt;shape&lt;/code&gt; 은 &lt;code&gt;[batch_size, None] + shape&lt;/code&gt; 및 지정된 &lt;code&gt;dtype&lt;/code&gt; 입니다. 의 항목 &lt;code&gt;batch&lt;/code&gt; 다른 행 &lt;code&gt;Examples&lt;/code&gt; 패딩 될 &lt;code&gt;default_value&lt;/code&gt; 최대 길이로 본 &lt;code&gt;batch&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3a538e992c4e715c1f91b7c40110e2510e29c989" translate="yes" xml:space="preserve">
          <source>The resulting SavedModel is then servable with an input named &quot;x&quot;, its value having any shape and dtype float32.</source>
          <target state="translated">결과 SavedModel은 &quot;x&quot;라는 이름의 입력으로 서비스 가능하며 그 값은 모양과 dtype float32입니다.</target>
        </trans-unit>
        <trans-unit id="9ef25e64d2e423f7de1f3a02ba7a25085c38c8a1" translate="yes" xml:space="preserve">
          <source>The resulting tensor is populated with values of type &lt;code&gt;dtype&lt;/code&gt;, as specified by arguments &lt;code&gt;value&lt;/code&gt; and (optionally) &lt;code&gt;shape&lt;/code&gt; (see examples below).</source>
          <target state="translated">결과 텐서는 인수 &lt;code&gt;value&lt;/code&gt; 및 (선택적) 으로 지정된대로 &lt;code&gt;dtype&lt;/code&gt; 유형의 값으로 채워집니다. &lt;code&gt;shape&lt;/code&gt; (아래 예 참조).</target>
        </trans-unit>
        <trans-unit id="0b674f3072695f2111704701dbc3947bfb383f3f" translate="yes" xml:space="preserve">
          <source>The resulting tensor is populated with values of type &lt;code&gt;dtype&lt;/code&gt;, as specified by arguments &lt;code&gt;value&lt;/code&gt; following the desired &lt;code&gt;shape&lt;/code&gt; of the new tensor (see examples below).</source>
          <target state="translated">결과 텐서는 원하는 다음 인수 &lt;code&gt;value&lt;/code&gt; 으로 지정된 &lt;code&gt;dtype&lt;/code&gt; 유형의 값으로 채워집니다. &lt;code&gt;shape&lt;/code&gt; 새로운 텐서 모양 에 따라 (아래 예 참조).</target>
        </trans-unit>
        <trans-unit id="ef74e8f16df07a307babda0cfa120db0e980020d" translate="yes" xml:space="preserve">
          <source>The resulting tensor would look like this:</source>
          <target state="translated">결과 텐서는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="381b1e6543678db4ed459c1cba156ecc8ca01172" translate="yes" xml:space="preserve">
          <source>The resulting update to ref would look like this:</source>
          <target state="translated">ref에 대한 결과 업데이트는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="cbbd169c06c5469910e771887e06b5ed0c01b738" translate="yes" xml:space="preserve">
          <source>The resulting update to v would look like this:</source>
          <target state="translated">v에 대한 결과 업데이트는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="5cc6293ac412a772df6f0e78ca55482c98eb64a2" translate="yes" xml:space="preserve">
          <source>The results of the lookup are concatenated into a dense tensor. The returned tensor has shape &lt;code&gt;shape(ids) + shape(params)[1:]&lt;/code&gt;.</source>
          <target state="translated">조회 결과는 조밀 한 텐서로 연결됩니다. 반환 된 텐서는 모양 &lt;code&gt;shape(ids) + shape(params)[1:]&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="2f1f40e1bca978cc7aa38e548317ee19cb7dfd8c" translate="yes" xml:space="preserve">
          <source>The return value has the same type as &lt;code&gt;images&lt;/code&gt; if &lt;code&gt;method&lt;/code&gt; is &lt;a href=&quot;../../../image/resizemethod#NEAREST_NEIGHBOR&quot;&gt;&lt;code&gt;ResizeMethod.NEAREST_NEIGHBOR&lt;/code&gt;&lt;/a&gt;. It will also have the same type as &lt;code&gt;images&lt;/code&gt; if the size of &lt;code&gt;images&lt;/code&gt; can be statically determined to be the same as &lt;code&gt;size&lt;/code&gt;, because &lt;code&gt;images&lt;/code&gt; is returned in this case. Otherwise, the return value has type &lt;code&gt;float32&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;method&lt;/code&gt; 가 &lt;a href=&quot;../../../image/resizemethod#NEAREST_NEIGHBOR&quot;&gt; &lt;code&gt;ResizeMethod.NEAREST_NEIGHBOR&lt;/code&gt; 인&lt;/a&gt; 경우 리턴 값은 &lt;code&gt;images&lt;/code&gt; 와 유형이 동일합니다 . 또한, 같은 유형의 것 &lt;code&gt;images&lt;/code&gt; 의 크기 경우 &lt;code&gt;images&lt;/code&gt; 정적으로 동일한 것으로 결정될 수있다 &lt;code&gt;size&lt;/code&gt; 때문에, &lt;code&gt;images&lt;/code&gt; 이 경우에 반환된다. 그렇지 않으면 반환 값의 유형은 &lt;code&gt;float32&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="90335752084dfbdd6479bc3425e07c2c184fac03" translate="yes" xml:space="preserve">
          <source>The return value has the same type as &lt;code&gt;images&lt;/code&gt; if &lt;code&gt;method&lt;/code&gt; is &lt;a href=&quot;resizemethod#NEAREST_NEIGHBOR&quot;&gt;&lt;code&gt;ResizeMethod.NEAREST_NEIGHBOR&lt;/code&gt;&lt;/a&gt;. Otherwise, the return value has type &lt;code&gt;float32&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;method&lt;/code&gt; 가 &lt;a href=&quot;resizemethod#NEAREST_NEIGHBOR&quot;&gt; &lt;code&gt;ResizeMethod.NEAREST_NEIGHBOR&lt;/code&gt; 인&lt;/a&gt; 경우 리턴 값은 &lt;code&gt;images&lt;/code&gt; 와 유형이 동일합니다 . 그렇지 않으면 반환 값의 유형은 &lt;code&gt;float32&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="3e3b67eed807726677126c856d0a6214fa8f8e4a" translate="yes" xml:space="preserve">
          <source>The return value of &lt;code&gt;merge_fn&lt;/code&gt;, except for &lt;code&gt;PerReplica&lt;/code&gt; values which are unpacked.</source>
          <target state="translated">압축 해제 된 &lt;code&gt;PerReplica&lt;/code&gt; 값을 제외하고 &lt;code&gt;merge_fn&lt;/code&gt; 의 반환 값 .</target>
        </trans-unit>
        <trans-unit id="111bba19cc7fb0062ed6fe66a53428292ab2ad62" translate="yes" xml:space="preserve">
          <source>The returned &lt;code&gt;RaggedTensor&lt;/code&gt; corresponds with the python list defined by:</source>
          <target state="translated">반환 된 &lt;code&gt;RaggedTensor&lt;/code&gt; 는 다음에 의해 정의 된 python 목록과 일치합니다.</target>
        </trans-unit>
        <trans-unit id="ecbcae5eb984661e7de2445f57c60c5e40e3d894" translate="yes" xml:space="preserve">
          <source>The returned &lt;code&gt;Session&lt;/code&gt; will be the innermost session on which a &lt;code&gt;Session&lt;/code&gt; or &lt;code&gt;Session.as_default()&lt;/code&gt; context has been entered.</source>
          <target state="translated">반환 된 &lt;code&gt;Session&lt;/code&gt; 은 &lt;code&gt;Session&lt;/code&gt; 또는 &lt;code&gt;Session.as_default()&lt;/code&gt; 컨텍스트가 입력 된 가장 안쪽의 세션입니다 .</target>
        </trans-unit>
        <trans-unit id="95a65357f0f57659490bed4f233c4a4d8fc08588" translate="yes" xml:space="preserve">
          <source>The returned &lt;code&gt;Tensor&lt;/code&gt; will be close to an exact solution if &lt;code&gt;A&lt;/code&gt; is well conditioned. Otherwise closeness will vary. See class docstring for details.</source>
          <target state="translated">반환 된 &lt;code&gt;Tensor&lt;/code&gt; 는 &lt;code&gt;A&lt;/code&gt; 인 경우 정확한 솔루션에 가깝습니다 . 가 잘 조절 . 그렇지 않으면 친밀감이 달라질 수 있습니다. 자세한 내용은 클래스 docstring을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="210a2253a38d62adf49c231834e4374a228751a1" translate="yes" xml:space="preserve">
          <source>The returned callable will have the same return type as &lt;code&gt;tf.Session.run(fetches, ...)&lt;/code&gt;. For example, if &lt;code&gt;fetches&lt;/code&gt; is a &lt;a href=&quot;../../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt;, the callable will return a numpy ndarray; if &lt;code&gt;fetches&lt;/code&gt; is a &lt;a href=&quot;../../operation&quot;&gt;&lt;code&gt;tf.Operation&lt;/code&gt;&lt;/a&gt;, it will return &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">리턴 된 콜 &lt;code&gt;tf.Session.run(fetches, ...)&lt;/code&gt; 은 tf.Session.run (fetches, ...) 와 동일한 리턴 유형을 갖습니다 . 예를 들어, &lt;code&gt;fetches&lt;/code&gt; 가 &lt;a href=&quot;../../tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; 인 경우 호출 가능 항목은 numpy ndarray를 반환합니다. 경우 &lt;code&gt;fetches&lt;/code&gt; A는 &lt;a href=&quot;../../operation&quot;&gt; &lt;code&gt;tf.Operation&lt;/code&gt; 이&lt;/a&gt; , 그것은 반환하지 않습니다 &lt;code&gt;None&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="bfdda7d94aac832546a913098111bedb3a5af104" translate="yes" xml:space="preserve">
          <source>The returned callable will take &lt;code&gt;len(feed_list)&lt;/code&gt; arguments whose types must be compatible feed values for the respective elements of &lt;code&gt;feed_list&lt;/code&gt;. For example, if element &lt;code&gt;i&lt;/code&gt; of &lt;code&gt;feed_list&lt;/code&gt; is a &lt;a href=&quot;../../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt;, the &lt;code&gt;i&lt;/code&gt;th argument to the returned callable must be a numpy ndarray (or something convertible to an ndarray) with matching element type and shape. See &lt;code&gt;tf.Session.run&lt;/code&gt; for details of the allowable feed key and value types.</source>
          <target state="translated">리턴 된 호출 가능은 유형이 &lt;code&gt;feed_list&lt;/code&gt; 의 각 요소에 대해 호환 가능한 피드 값이어야하는 &lt;code&gt;len(feed_list)&lt;/code&gt; 인수를 사용합니다 . 예를 들어, 소자 경우 &lt;code&gt;i&lt;/code&gt; 의 &lt;code&gt;feed_list&lt;/code&gt; 는 A는 &lt;a href=&quot;../../tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; 상기 &lt;code&gt;i&lt;/code&gt; 에 번째 인수 반환 매칭 소자 종류와 형상의 NumPy와 ndarray (또는 ndarray로 전환 일) 여야 호출. 허용 가능한 피드 키 및 값 유형에 대한 자세한 내용은 &lt;code&gt;tf.Session.run&lt;/code&gt; 을 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="5ae9baaba07ae2a863bb456cb56b210b15bfeca4" translate="yes" xml:space="preserve">
          <source>The returned dataset is a wrapped strategy dataset which creates a multidevice iterator under the hood. It prefetches the input data to the specified devices on the worker. The returned distributed dataset can be iterated over similar to how regular datasets can.</source>
          <target state="translated">리턴 된 데이터 세트는 랩된 전략 데이터 세트이며 후드 아래에서 다중 디바이스 반복자를 작성합니다. 작업자의 지정된 장치로 입력 데이터를 프리 페치합니다. 리턴 된 분산 데이터 세트는 일반 데이터 세트와 유사한 방식으로 반복 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="6f7e2363fe125c1a5cdb798835abe8de5ac8aef0" translate="yes" xml:space="preserve">
          <source>The returned dictionary can be used as arg 'features' in &lt;a href=&quot;../../../io/parse_example&quot;&gt;&lt;code&gt;tf.io.parse_example&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">반환 된 사전은 &lt;a href=&quot;../../../io/parse_example&quot;&gt; &lt;code&gt;tf.io.parse_example&lt;/code&gt; &lt;/a&gt; 에서 arg 'features'로 사용될 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="27148d9610fe5857a584045bc355cd08d4ce68b2" translate="yes" xml:space="preserve">
          <source>The returned dictionary can be used as arg 'features' in &lt;a href=&quot;../io/parse_example&quot;&gt;&lt;code&gt;tf.io.parse_example&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">반환 된 사전은 &lt;a href=&quot;../io/parse_example&quot;&gt; &lt;code&gt;tf.io.parse_example&lt;/code&gt; &lt;/a&gt; 에서 arg 'features'로 사용될 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="e41cdf1dd9ec5b48c6c1a627e04bc9cd0f5646ec" translate="yes" xml:space="preserve">
          <source>The returned distributed dataset can be iterated over similar to how regular datasets can. NOTE: Currently, the user cannot add any more transformations to a distributed dataset.</source>
          <target state="translated">리턴 된 분산 데이터 세트는 일반 데이터 세트와 유사한 방식으로 반복 될 수 있습니다. 참고 : 현재 사용자는 분산 데이터 집합에 더 이상 변환을 추가 할 수 없습니다.</target>
        </trans-unit>
        <trans-unit id="8e5c9b1714c669dc39fd802e652891ab6982a58a" translate="yes" xml:space="preserve">
          <source>The returned graph will be the innermost graph on which a &lt;a href=&quot;../../graph#as_default&quot;&gt;&lt;code&gt;Graph.as_default()&lt;/code&gt;&lt;/a&gt; context has been entered, or a global default graph if none has been explicitly created.</source>
          <target state="translated">반환 된 그래프는 &lt;a href=&quot;../../graph#as_default&quot;&gt; &lt;code&gt;Graph.as_default()&lt;/code&gt; &lt;/a&gt; 컨텍스트가 입력 된 가장 안쪽 그래프 이거나 명시 적으로 생성되지 않은 경우 전역 기본 그래프입니다.</target>
        </trans-unit>
        <trans-unit id="6b38dad137146b9ef38ba7c509e2c0442b75c1f0" translate="yes" xml:space="preserve">
          <source>The returned iterator implements the Python iterator protocol and therefore can only be used in eager mode.</source>
          <target state="translated">리턴 된 반복기는 Python 반복기 프로토콜을 구현하므로 열성 모드에서만 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7e0593141fa29e4d333dddf121d2181c125317c5" translate="yes" xml:space="preserve">
          <source>The returned iterator is not bound to a particular dataset, and it has no &lt;code&gt;initializer&lt;/code&gt;. To initialize the iterator, run the operation returned by &lt;code&gt;Iterator.make_initializer(dataset)&lt;/code&gt;.</source>
          <target state="translated">리턴 된 반복자는 특정 데이터 세트에 바인드되지 않으며 &lt;code&gt;initializer&lt;/code&gt; 프로그램이 없습니다 . 반복자를 초기화하려면 &lt;code&gt;Iterator.make_initializer(dataset)&lt;/code&gt; 반환 한 작업을 실행하십시오 .</target>
        </trans-unit>
        <trans-unit id="35c004b6fa1c65f47bcd7047f0f10a1978a605f3" translate="yes" xml:space="preserve">
          <source>The returned operation is a dequeue operation and will throw &lt;a href=&quot;../../../errors/outofrangeerror&quot;&gt;&lt;code&gt;tf.errors.OutOfRangeError&lt;/code&gt;&lt;/a&gt; if the input queue is exhausted. If this operation is feeding another input queue, its queue runner will catch this exception, however, if this operation is used in your main thread you are responsible for catching this yourself.</source>
          <target state="translated">리턴 된 오퍼레이션은 큐 제거 조작이며 입력 큐가 소진되면 &lt;a href=&quot;../../../errors/outofrangeerror&quot;&gt; &lt;code&gt;tf.errors.OutOfRangeError&lt;/code&gt; 를&lt;/a&gt; 발생시킵니다. 이 오퍼레이션이 다른 입력 큐를 공급하는 경우 큐 러너가이 예외를 포착하지만이 오퍼레이션이 기본 스레드에서 사용되는 경우이를 직접 처리해야합니다.</target>
        </trans-unit>
        <trans-unit id="283d98979ab1e70cde916469a5e89b9e786cbb6c" translate="yes" xml:space="preserve">
          <source>The returned status object has the following methods:</source>
          <target state="translated">리턴 된 상태 오브젝트에는 다음 메소드가 있습니다.</target>
        </trans-unit>
        <trans-unit id="76a9be24217f14af8b4e90ac374a00f3e69a4114" translate="yes" xml:space="preserve">
          <source>The returned tensor will contain a serialized &lt;a href=&quot;../../summary&quot;&gt;&lt;code&gt;tf.compat.v1.summary.Summary&lt;/code&gt;&lt;/a&gt; protocol buffer, which can be used with the standard TensorBoard logging facilities.</source>
          <target state="translated">반환 된 텐서는 표준 TensorBoard 로깅 기능과 함께 사용할 수 있는 직렬화 된 &lt;a href=&quot;../../summary&quot;&gt; &lt;code&gt;tf.compat.v1.summary.Summary&lt;/code&gt; &lt;/a&gt; 프로토콜 버퍼를 포함합니다 .</target>
        </trans-unit>
        <trans-unit id="82d1c361e6f8f0d84bf0a1bcea9214b49e8cf3d3" translate="yes" xml:space="preserve">
          <source>The returned tensor's dimension i will correspond to the input dimension &lt;code&gt;perm[i]&lt;/code&gt;. If &lt;code&gt;perm&lt;/code&gt; is not given, it is set to (n-1...0), where n is the rank of the input tensor. Hence by default, this operation performs a regular matrix transpose on 2-D input Tensors.</source>
          <target state="translated">반환 된 텐서의 치수 i는 입력 치수 &lt;code&gt;perm[i]&lt;/code&gt; 합니다. 경우 &lt;code&gt;perm&lt;/code&gt; 부여되지 않으며, 그것은 (1 ... N-0)로 설정, 여기서 n은 입력 텐서의 계수이다. 따라서 기본적으로이 작업은 2 차원 입력 텐서에서 규칙적인 행렬 조옮김을 수행합니다.</target>
        </trans-unit>
        <trans-unit id="d9c115cc2d00147127224aefb2bd6a8e1bbe0c5c" translate="yes" xml:space="preserve">
          <source>The returned tensor's dimension i will correspond to the input dimension &lt;code&gt;perm[i]&lt;/code&gt;. If &lt;code&gt;perm&lt;/code&gt; is not given, it is set to (n-1...0), where n is the rank of the input tensor. Hence by default, this operation performs a regular matrix transpose on 2-D input Tensors. If conjugate is True and &lt;code&gt;a.dtype&lt;/code&gt; is either &lt;code&gt;complex64&lt;/code&gt; or &lt;code&gt;complex128&lt;/code&gt; then the values of &lt;code&gt;a&lt;/code&gt; are conjugated and transposed.</source>
          <target state="translated">반환 된 텐서의 치수 i는 입력 치수 &lt;code&gt;perm[i]&lt;/code&gt; 합니다. 경우 &lt;code&gt;perm&lt;/code&gt; 부여되지 않으며, 그것은 (1 ... N-0)로 설정, 여기서 n은 입력 텐서의 계수이다. 따라서 기본적으로이 작업은 2 차원 입력 텐서에서 규칙적인 행렬 조옮김을 수행합니다. 복합은 True입니다 및 경우 &lt;code&gt;a.dtype&lt;/code&gt; 는 중입니다 &lt;code&gt;complex64&lt;/code&gt; 또는 &lt;code&gt;complex128&lt;/code&gt; 다음의 값 &lt;code&gt;a&lt;/code&gt; 결합하고 전치된다.</target>
        </trans-unit>
        <trans-unit id="838e6e70eeb12ce61fde540b38b4044a46a8f134" translate="yes" xml:space="preserve">
          <source>The returned tensors are &lt;a href=&quot;../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt;s if &lt;code&gt;input&lt;/code&gt; is a scalar, or &lt;a href=&quot;../raggedtensor&quot;&gt;&lt;code&gt;tf.RaggedTensor&lt;/code&gt;&lt;/a&gt;s otherwise.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 이 스칼라 이면 반환 된 텐서는 &lt;a href=&quot;../tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; 이고, 그렇지 않으면 &lt;a href=&quot;../raggedtensor&quot;&gt; &lt;code&gt;tf.RaggedTensor&lt;/code&gt; &lt;/a&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="85216d0bd898c6d1680f5aac974d5348d1d96c2f" translate="yes" xml:space="preserve">
          <source>The row-split indices for this ragged tensor's &lt;code&gt;values&lt;/code&gt;.</source>
          <target state="translated">이 울퉁불퉁 한 텐서의 &lt;code&gt;values&lt;/code&gt; 대한 행 분할 인덱스 .</target>
        </trans-unit>
        <trans-unit id="5854e78835764512ec754b4ac011bb9b48f7d380" translate="yes" xml:space="preserve">
          <source>The row_splits for all ragged dimensions in this ragged tensor value.</source>
          <target state="translated">이 비정형 텐서 값의 모든 비정형 치수에 대해 row_splits입니다.</target>
        </trans-unit>
        <trans-unit id="5158c81c5ea5bb74de68daed2eacbf5dc32d4ad8" translate="yes" xml:space="preserve">
          <source>The runtime is then free to make optimizations based on this.</source>
          <target state="translated">그런 다음 런타임은이를 기반으로 최적화 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="ca5cdf682a9605ca998129dd4a854da399041aba" translate="yes" xml:space="preserve">
          <source>The same array (Numpy array if &lt;code&gt;x&lt;/code&gt; was a Numpy array, or TensorFlow tensor if &lt;code&gt;x&lt;/code&gt; was a tensor), cast to its new type.</source>
          <target state="translated">동일한 배열 ( &lt;code&gt;x&lt;/code&gt; 가 Numpy 배열 인 경우 Numpy 배열 또는 &lt;code&gt;x&lt;/code&gt; 가 텐서 인 경우 TensorFlow 텐서)은 새 유형으로 캐스트됩니다.</target>
        </trans-unit>
        <trans-unit id="e4b3e7c37b806fc9d4b600343aa28d9179c53706" translate="yes" xml:space="preserve">
          <source>The same as &lt;a href=&quot;../../raggedtensor#__div__&quot;&gt;&lt;code&gt;tf.compat.v1.div(x,y)&lt;/code&gt;&lt;/a&gt; for integers, but uses &lt;code&gt;tf.floor(tf.compat.v1.div(x,y))&lt;/code&gt; for floating point arguments so that the result is always an integer (though possibly an integer represented as floating point). This op is generated by &lt;code&gt;x // y&lt;/code&gt; floor division in Python 3 and in Python 2.7 with &lt;code&gt;from __future__ import division&lt;/code&gt;.</source>
          <target state="translated">정수의 경우 &lt;a href=&quot;../../raggedtensor#__div__&quot;&gt; &lt;code&gt;tf.compat.v1.div(x,y)&lt;/code&gt; &lt;/a&gt; 와 동일 하지만 부동 소수점 인수에 &lt;code&gt;tf.floor(tf.compat.v1.div(x,y))&lt;/code&gt; 를 사용하므로 결과는 항상 정수 ( 부동 소수점으로 표시되는 정수). 이 연산은 &lt;code&gt;from __future__ import division&lt;/code&gt; 하여 Python 3 및 Python 2.7의 &lt;code&gt;x // y&lt;/code&gt; 층 분할에 의해 생성됩니다 .</target>
        </trans-unit>
        <trans-unit id="07525f9495ce7a62b86179e9f6083e34f20d8d8b" translate="yes" xml:space="preserve">
          <source>The same as &lt;a href=&quot;../raggedtensor#__div__&quot;&gt;&lt;code&gt;tf.compat.v1.div(x,y)&lt;/code&gt;&lt;/a&gt; for integers, but uses &lt;code&gt;tf.floor(tf.compat.v1.div(x,y))&lt;/code&gt; for floating point arguments so that the result is always an integer (though possibly an integer represented as floating point). This op is generated by &lt;code&gt;x // y&lt;/code&gt; floor division in Python 3 and in Python 2.7 with &lt;code&gt;from __future__ import division&lt;/code&gt;.</source>
          <target state="translated">정수의 경우 &lt;a href=&quot;../raggedtensor#__div__&quot;&gt; &lt;code&gt;tf.compat.v1.div(x,y)&lt;/code&gt; &lt;/a&gt; 와 동일 하지만 부동 소수점 인수에 &lt;code&gt;tf.floor(tf.compat.v1.div(x,y))&lt;/code&gt; 를 사용하므로 결과는 항상 정수 ( 부동 소수점으로 표시되는 정수). 이 연산은 &lt;code&gt;from __future__ import division&lt;/code&gt; 하여 Python 3 및 Python 2.7의 &lt;code&gt;x // y&lt;/code&gt; 층 분할에 의해 생성됩니다 .</target>
        </trans-unit>
        <trans-unit id="3240798db52d492b4a5e0a4f1101b0ce22e5dea6" translate="yes" xml:space="preserve">
          <source>The same as &lt;a href=&quot;raggedtensor#__div__&quot;&gt;&lt;code&gt;tf.compat.v1.div(x,y)&lt;/code&gt;&lt;/a&gt; for integers, but uses &lt;code&gt;tf.floor(tf.compat.v1.div(x,y))&lt;/code&gt; for floating point arguments so that the result is always an integer (though possibly an integer represented as floating point). This op is generated by &lt;code&gt;x // y&lt;/code&gt; floor division in Python 3 and in Python 2.7 with &lt;code&gt;from __future__ import division&lt;/code&gt;.</source>
          <target state="translated">정수의 경우 &lt;a href=&quot;raggedtensor#__div__&quot;&gt; &lt;code&gt;tf.compat.v1.div(x,y)&lt;/code&gt; &lt;/a&gt; 와 동일 하지만 부동 소수점 인수에 &lt;code&gt;tf.floor(tf.compat.v1.div(x,y))&lt;/code&gt; 를 사용하므로 결과는 항상 정수 ( 부동 소수점으로 표시되는 정수). 이 연산은 &lt;code&gt;from __future__ import division&lt;/code&gt; 하여 Python 3 및 Python 2.7의 &lt;code&gt;x // y&lt;/code&gt; 층 분할에 의해 생성됩니다 .</target>
        </trans-unit>
        <trans-unit id="d6016fab50d93b1e77917677d258e0e003f237e6" translate="yes" xml:space="preserve">
          <source>The same tensor &lt;code&gt;x&lt;/code&gt;, unchanged.</source>
          <target state="translated">변경되지 않은 동일한 텐서 &lt;code&gt;x&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="2c3935638fc889928b31f22a28b40af71a593afd" translate="yes" xml:space="preserve">
          <source>The samples are differentiable w.r.t. alpha and beta. The derivatives are computed using the approach described in the paper</source>
          <target state="translated">샘플은 구별 가능한 wrt 알파 및 베타이다. 파생 상품은 논문에 설명 된 접근 방식을 사용하여 계산됩니다.</target>
        </trans-unit>
        <trans-unit id="92952659dac1bf101ab8c26a5fd0e7570c899948" translate="yes" xml:space="preserve">
          <source>The sampling probabilities are generated according to the sampling distribution used in word2vec:</source>
          <target state="translated">샘플링 확률은 word2vec에 사용 된 샘플링 분포에 따라 생성됩니다.</target>
        </trans-unit>
        <trans-unit id="7e70c09e21b733e9d2a808af0f600268962663fb" translate="yes" xml:space="preserve">
          <source>The save counter variable.</source>
          <target state="translated">저장 카운터 변수</target>
        </trans-unit>
        <trans-unit id="ab43a8a642f72175fe828def8c8d03e9a692fe7b" translate="yes" xml:space="preserve">
          <source>The saved checkpoint includes variables created by this object and any trackable objects it depends on at the time &lt;a href=&quot;../../../train/checkpoint#save&quot;&gt;&lt;code&gt;Checkpoint.save()&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="translated">저장된 검사 점에는이 개체에 의해 생성 된 변수와 &lt;a href=&quot;../../../train/checkpoint#save&quot;&gt; &lt;code&gt;Checkpoint.save()&lt;/code&gt; &lt;/a&gt; 가 호출 될 때이 개체에 따라 추적 가능한 개체 가 포함됩니다.</target>
        </trans-unit>
        <trans-unit id="21ba0881308b74c027819f31603cfc6647b52c80" translate="yes" xml:space="preserve">
          <source>The saved checkpoint includes variables created by this object and any trackable objects it depends on at the time &lt;a href=&quot;checkpoint#save&quot;&gt;&lt;code&gt;Checkpoint.save()&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="translated">저장된 검사 점에는이 개체에 의해 생성 된 변수와 &lt;a href=&quot;checkpoint#save&quot;&gt; &lt;code&gt;Checkpoint.save()&lt;/code&gt; &lt;/a&gt; 가 호출 될 때이 개체에 따라 추적 가능한 개체 가 포함됩니다.</target>
        </trans-unit>
        <trans-unit id="d3b7070f1ecc16e817793f6b5d01b2b53b58703e" translate="yes" xml:space="preserve">
          <source>The saved model contains: - the model's configuration (topology) - the model's weights - the model's optimizer's state (if any)</source>
          <target state="translated">저장된 모델에는 다음이 포함됩니다.-모델 구성 (토폴로지)-모델 가중치-모델의 옵티 마이저 상태 (있는 경우)</target>
        </trans-unit>
        <trans-unit id="eeb866c0e9b8a790b2b06bb4bf72fe83fcf3b7fd" translate="yes" xml:space="preserve">
          <source>The savefile includes:</source>
          <target state="translated">저장 파일에는 다음이 포함됩니다.</target>
        </trans-unit>
        <trans-unit id="ff3fd5f27f08bbd84c446309ecdaecd1825d0b40" translate="yes" xml:space="preserve">
          <source>The scalar PSNR between a and b. The returned tensor has type &lt;a href=&quot;../../tf#float32&quot;&gt;&lt;code&gt;tf.float32&lt;/code&gt;&lt;/a&gt; and shape [batch_size, 1].</source>
          <target state="translated">a와 b 사이의 스칼라 PSNR 반환 된 텐서는 유형이 &lt;a href=&quot;../../tf#float32&quot;&gt; &lt;code&gt;tf.float32&lt;/code&gt; &lt;/a&gt; 이고 모양은 [batch_size, 1]입니다.</target>
        </trans-unit>
        <trans-unit id="dd78e4034ea5bbefe47a5585f3fa965bc5acaa8e" translate="yes" xml:space="preserve">
          <source>The scaled exponential unit activation: &lt;code&gt;scale * elu(x, alpha)&lt;/code&gt;.</source>
          <target state="translated">스케일 된 지수 단위 활성화 : &lt;code&gt;scale * elu(x, alpha)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d7cdf9b27ca1dd2bbd540e30d82d6f1126674d88" translate="yes" xml:space="preserve">
          <source>The scaling_factor is determined from &lt;code&gt;min_range&lt;/code&gt;, &lt;code&gt;max_range&lt;/code&gt;, and &lt;code&gt;narrow_range&lt;/code&gt; in a way that is compatible with &lt;code&gt;QuantizeAndDequantize{V2|V3}&lt;/code&gt; and &lt;code&gt;QuantizeV2&lt;/code&gt;, using the following algorithm:</source>
          <target state="translated">scaling_factor는 다음 알고리즘을 사용하여 &lt;code&gt;QuantizeAndDequantize{V2|V3}&lt;/code&gt; 및 &lt;code&gt;QuantizeV2&lt;/code&gt; 와 호환되는 방식으로 &lt;code&gt;min_range&lt;/code&gt; , &lt;code&gt;max_range&lt;/code&gt; 및 &lt;code&gt;narrow_range&lt;/code&gt; 에서 결정됩니다 .</target>
        </trans-unit>
        <trans-unit id="d82c0e384909c0dd188de5ead9b2872459677ae8" translate="yes" xml:space="preserve">
          <source>The schedule a 1-arg callable that produces a decayed learning rate when passed the current optimizer step. This can be useful for changing the learning rate value across different invocations of optimizer functions.</source>
          <target state="translated">현재 옵티 마이저 단계를 통과하면 학습 속도가 저하되는 1-arg 호출 가능 일정입니다. 이것은 옵티 마이저 함수의 다른 호출에서 학습 속도 값을 변경하는 데 유용 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="c2ad88fa788374ec95b4583696db082a634b18eb" translate="yes" xml:space="preserve">
          <source>The schedule a 1-arg callable that produces a decayed learning rate when passed the current optimizer step. This can be useful for changing the learning rate value across different invocations of optimizer functions. It is computed as:</source>
          <target state="translated">현재 옵티 마이저 단계를 통과하면 학습 속도가 저하되는 1-arg 호출 가능 일정입니다. 이것은 옵티 마이저 함수의 다른 호출에서 학습 속도 값을 변경하는 데 유용 할 수 있습니다. 다음과 같이 계산됩니다.</target>
        </trans-unit>
        <trans-unit id="71d2993ed1ad7b32ffe04dab2486da899c3f2739" translate="yes" xml:space="preserve">
          <source>The schedule is a 1-arg callable that produces a decayed learning rate when passed the current optimizer step. This can be useful for changing the learning rate value across different invocations of optimizer functions. It is computed as:</source>
          <target state="translated">일정은 현재 최적화 단계를 통과 할 때 학습 속도가 저하되는 1-arg 호출 가능입니다. 이것은 옵티 마이저 함수의 다른 호출에서 학습 속도 값을 변경하는 데 유용 할 수 있습니다. 다음과 같이 계산됩니다.</target>
        </trans-unit>
        <trans-unit id="2bf5542bf013cf2cd0c7e2cee3c5c6cd6c529ad0" translate="yes" xml:space="preserve">
          <source>The scope name.</source>
          <target state="translated">범위 이름</target>
        </trans-unit>
        <trans-unit id="50f230356c528b135a5e5c8be0185503e716f9b3" translate="yes" xml:space="preserve">
          <source>The second call of &lt;code&gt;foo&lt;/code&gt; returns '(A2, A2)' instead of '(A1, A1)' because &lt;a href=&quot;uniform&quot;&gt;&lt;code&gt;tf.random.uniform&lt;/code&gt;&lt;/a&gt; maintains an internal counter. If you want &lt;code&gt;foo&lt;/code&gt; to return '(A1, A1)' every time, use the stateless random ops such as &lt;a href=&quot;stateless_uniform&quot;&gt;&lt;code&gt;tf.random.stateless_uniform&lt;/code&gt;&lt;/a&gt;. Also see &lt;a href=&quot;experimental/generator&quot;&gt;&lt;code&gt;tf.random.experimental.Generator&lt;/code&gt;&lt;/a&gt; for a new set of stateful random ops that use external variables to manage their states.</source>
          <target state="translated">&lt;a href=&quot;uniform&quot;&gt; &lt;code&gt;tf.random.uniform&lt;/code&gt; &lt;/a&gt; 은 내부 카운터를 유지 하므로 &lt;code&gt;foo&lt;/code&gt; 의 두 번째 호출은 '(A1, A1)'대신 '(A2, A2)'를 반환합니다 . 당신이 원하는 경우 &lt;code&gt;foo&lt;/code&gt; 는 '(A1, A1)'반환에 모든 시간을, 같은 상태 비 무작위 작전을 사용 &lt;a href=&quot;stateless_uniform&quot;&gt; &lt;code&gt;tf.random.stateless_uniform&lt;/code&gt; &lt;/a&gt; . 외부 변수를 사용하여 상태를 관리하는 새로운 상태 저장 랜덤 연산 세트에 대해서는 &lt;a href=&quot;experimental/generator&quot;&gt; &lt;code&gt;tf.random.experimental.Generator&lt;/code&gt; &lt;/a&gt; 도 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="08568c721bd015f102f6c3ec1b535d6153171292" translate="yes" xml:space="preserve">
          <source>The second dict contains the feature_list key/values.</source>
          <target state="translated">두 번째 dict에는 feature_list 키 / 값이 포함되어 있습니다.</target>
        </trans-unit>
        <trans-unit id="73916e07f6ea34c81abd799027349571045df1c6" translate="yes" xml:space="preserve">
          <source>The second innermost dimension of &lt;code&gt;diagonal&lt;/code&gt; has double meaning. When &lt;code&gt;k&lt;/code&gt; is scalar or &lt;code&gt;k[0] == k[1]&lt;/code&gt;, &lt;code&gt;M&lt;/code&gt; is part of the batch size [I, J, ..., M], and the output tensor is:</source>
          <target state="translated">&lt;code&gt;diagonal&lt;/code&gt; 의 두 번째 가장 안쪽 치수 는 이중 의미를 갖습니다. 되면 &lt;code&gt;k&lt;/code&gt; 는 스칼라이거나 &lt;code&gt;k[0] == k[1]&lt;/code&gt; , &lt;code&gt;M&lt;/code&gt; 은 배치 크기 [I, J, ..., M]의 일부이며, 상기 출력 텐서이다 :</target>
        </trans-unit>
        <trans-unit id="b310dae88696133dc7ed85369e494d665ee6beaf" translate="yes" xml:space="preserve">
          <source>The second variant is compatible with CuDNNGRU (GPU-only) and allows inference on CPU. Thus it has separate biases for &lt;code&gt;kernel&lt;/code&gt; and &lt;code&gt;recurrent_kernel&lt;/code&gt;. To use this variant, set &lt;code&gt;'reset_after'=True&lt;/code&gt; and &lt;code&gt;recurrent_activation='sigmoid'&lt;/code&gt;.</source>
          <target state="translated">두 번째 변형은 CuDNNGRU (GPU 전용)와 호환되며 CPU에 대한 추론을 허용합니다. 따라서 &lt;code&gt;kernel&lt;/code&gt; 과 &lt;code&gt;recurrent_kernel&lt;/code&gt; 에 대한 별도의 바이어스가 있습니다. 이 변형을 사용하려면 &lt;code&gt;'reset_after'=True&lt;/code&gt; 및 &lt;code&gt;recurrent_activation='sigmoid'&lt;/code&gt; 를 설정하십시오 .</target>
        </trans-unit>
        <trans-unit id="44fd41a3b2fd550cb5e331da22b4349e8495f086" translate="yes" xml:space="preserve">
          <source>The second variant is compatible with CuDNNGRU (GPU-only) and allows inference on CPU. Thus it has separate biases for &lt;code&gt;kernel&lt;/code&gt; and &lt;code&gt;recurrent_kernel&lt;/code&gt;. Use &lt;code&gt;'reset_after'=True&lt;/code&gt; and &lt;code&gt;recurrent_activation='sigmoid'&lt;/code&gt;.</source>
          <target state="translated">두 번째 변형은 CuDNNGRU (GPU 전용)와 호환되며 CPU에 대한 추론을 허용합니다. 따라서 &lt;code&gt;kernel&lt;/code&gt; 과 &lt;code&gt;recurrent_kernel&lt;/code&gt; 에 대한 별도의 바이어스가 있습니다. 사용 &lt;code&gt;'reset_after'=True&lt;/code&gt; 과 &lt;code&gt;recurrent_activation='sigmoid'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="9b1ff7b195e25bb1e934a1faddac3cb31e9dda14" translate="yes" xml:space="preserve">
          <source>The selected tensor.</source>
          <target state="translated">선택된 텐서.</target>
        </trans-unit>
        <trans-unit id="14448741add9013596276b373f9b2b4fe8b71b2b" translate="yes" xml:space="preserve">
          <source>The sequence of &lt;code&gt;Tensor&lt;/code&gt; objects representing the data inputs of this op.</source>
          <target state="translated">이 op의 데이터 입력을 나타내는 &lt;code&gt;Tensor&lt;/code&gt; 객체 의 시퀀스입니다 .</target>
        </trans-unit>
        <trans-unit id="9c721fd10cd508d808b1312a2194dc7e4890a7fc" translate="yes" xml:space="preserve">
          <source>The serialized &lt;code&gt;GraphDef&lt;/code&gt; can be imported into another &lt;code&gt;Graph&lt;/code&gt; (using &lt;a href=&quot;graph_util/import_graph_def&quot;&gt;&lt;code&gt;tf.import_graph_def&lt;/code&gt;&lt;/a&gt;) or used with the &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/cc/index&quot;&gt;C++ Session API&lt;/a&gt;.</source>
          <target state="translated">직렬화 된 &lt;code&gt;GraphDef&lt;/code&gt; 를 다른 &lt;code&gt;Graph&lt;/code&gt; 로 가져 오거나 ( &lt;a href=&quot;graph_util/import_graph_def&quot;&gt; &lt;code&gt;tf.import_graph_def&lt;/code&gt; &lt;/a&gt; 사용 ) &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/cc/index&quot;&gt;C ++ 세션 API&lt;/a&gt; 와 함께 사용할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="ec73351af802bdf6746d29fb3d40b6d4c532bba4" translate="yes" xml:space="preserve">
          <source>The set of absent/default values may be specified using a vector of lengths or a padding value (but not both). If &lt;code&gt;lengths&lt;/code&gt; is specified, then the output tensor will satisfy &lt;code&gt;output[row] = tensor[row][:lengths[row]]&lt;/code&gt;. If 'lengths' is a list of lists or tuple of lists, those lists will be used as nested row lengths. If &lt;code&gt;padding&lt;/code&gt; is specified, then any row &lt;em&gt;suffix&lt;/em&gt; consisting entirely of &lt;code&gt;padding&lt;/code&gt; will be excluded from the returned &lt;code&gt;RaggedTensor&lt;/code&gt;. If neither &lt;code&gt;lengths&lt;/code&gt; nor &lt;code&gt;padding&lt;/code&gt; is specified, then the returned &lt;code&gt;RaggedTensor&lt;/code&gt; will have no absent/default values.</source>
          <target state="translated">부재 / 기본 값 세트는 길이 벡터 또는 패딩 값 (둘다는 아님)을 사용하여 지정할 수 있습니다. 경우 &lt;code&gt;lengths&lt;/code&gt; 지정되어, 출력 텐서 만족 &lt;code&gt;output[row] = tensor[row][:lengths[row]]&lt;/code&gt; . 'lengths'가 목록의 목록 또는 튜플 목록 인 경우 해당 목록은 중첩 행 길이로 사용됩니다. 경우 &lt;code&gt;padding&lt;/code&gt; 지정하면 모든 행 &lt;em&gt;접미사&lt;/em&gt; 완전히 구성된 &lt;code&gt;padding&lt;/code&gt; 반환에서 제외됩니다 &lt;code&gt;RaggedTensor&lt;/code&gt; . &lt;code&gt;lengths&lt;/code&gt; 와 &lt;code&gt;padding&lt;/code&gt; 이 모두 지정 되지 않으면 반환 된 &lt;code&gt;RaggedTensor&lt;/code&gt; 에 결근 값 / 기본값이 없습니다.</target>
        </trans-unit>
        <trans-unit id="0c1258f12879c9bd1b917a210f7db35cdd522088" translate="yes" xml:space="preserve">
          <source>The set of ops to be run as part of the main op upon the load operation.</source>
          <target state="translated">로드 작업시 기본 op의 일부로 실행되는 op 세트입니다.</target>
        </trans-unit>
        <trans-unit id="7bc1bd93e711b8be01e066d838cfcf34409f0c38" translate="yes" xml:space="preserve">
          <source>The shape is computed using shape inference functions that are registered in the Op for each &lt;code&gt;Operation&lt;/code&gt;. See &lt;a href=&quot;tensorshape&quot;&gt;&lt;code&gt;tf.TensorShape&lt;/code&gt;&lt;/a&gt; for more details of what a shape represents.</source>
          <target state="translated">셰이프는 각 &lt;code&gt;Operation&lt;/code&gt; 에 대해 Op에 등록 된 셰이프 유추 함수를 사용하여 계산됩니다 . 참조 &lt;a href=&quot;tensorshape&quot;&gt; &lt;code&gt;tf.TensorShape&lt;/code&gt; 을&lt;/a&gt; 모양이 무엇을 나타내는 자세한 내용.</target>
        </trans-unit>
        <trans-unit id="5319f783b1231c02b92342d27602eef300f0a629" translate="yes" xml:space="preserve">
          <source>The shape of arguments to &lt;code&gt;__init__&lt;/code&gt;, &lt;code&gt;cdf&lt;/code&gt;, &lt;code&gt;log_cdf&lt;/code&gt;, &lt;code&gt;prob&lt;/code&gt;, and &lt;code&gt;log_prob&lt;/code&gt; reflect this broadcasting, as does the return value of &lt;code&gt;sample&lt;/code&gt; and &lt;code&gt;sample_n&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;__init__&lt;/code&gt; , &lt;code&gt;cdf&lt;/code&gt; , &lt;code&gt;log_cdf&lt;/code&gt; , &lt;code&gt;prob&lt;/code&gt; 및 &lt;code&gt;log_prob&lt;/code&gt; 의 인수 모양은 &lt;code&gt;sample&lt;/code&gt; 및 &lt;code&gt;sample_n&lt;/code&gt; 의 반환 값 과 마찬가지로이 브로드 캐스트를 반영합니다 .</target>
        </trans-unit>
        <trans-unit id="3720998b3d73539e8c9661d288914e2cdaa82ba7" translate="yes" xml:space="preserve">
          <source>The shape of the output tensor is:</source>
          <target state="translated">출력 텐서의 모양은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="b54a3296d32e764f7303629c8f4e133de6a9a7b0" translate="yes" xml:space="preserve">
          <source>The shape of the output will be:</source>
          <target state="translated">출력 형태는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="b04d4e03100c6f081b5e785ea772cca017db1933" translate="yes" xml:space="preserve">
          <source>The shapes of the two operands must match: broadcasting is not supported.</source>
          <target state="translated">두 피연산자의 모양이 일치해야합니다. 브로드 캐스트는 지원되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="348113de328d02812f9ca2ed7f6d52b929c19ce9" translate="yes" xml:space="preserve">
          <source>The simplest form of RNN network generated is:</source>
          <target state="translated">생성 된 가장 간단한 형태의 RNN 네트워크는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="ff2f171ddc511ae06abeb2ff57b6d8a5b4678a63" translate="yes" xml:space="preserve">
          <source>The simplest form of scatter is to insert individual elements in a tensor by index. For example, say we want to insert 4 scattered elements in a rank-1 tensor with 8 elements.</source>
          <target state="translated">분산의 가장 간단한 형태는 인덱스로 텐서에 개별 요소를 삽입하는 것입니다. 예를 들어, 4 개의 산란 된 요소를 8 개의 요소가있는 랭크 -1 텐서에 삽입하려고합니다.</target>
        </trans-unit>
        <trans-unit id="f366cdfba69e2fc90954206f2645c89f45fbcd17" translate="yes" xml:space="preserve">
          <source>The simplest form of tensor_scatter_add is to add individual elements to a tensor by index. For example, say we want to add 4 elements in a rank-1 tensor with 8 elements.</source>
          <target state="translated">tensor_scatter_add의 가장 간단한 형식은 인덱스별로 개별 요소를 텐서에 추가하는 것입니다. 예를 들어 8 개의 요소가있는 순위 1 텐서에 4 개의 요소를 추가한다고 가정합니다.</target>
        </trans-unit>
        <trans-unit id="3af9f04f82cbb797b19d70da5fb65e10e6f6ef91" translate="yes" xml:space="preserve">
          <source>The simplest form of tensor_scatter_sub is to subtract individual elements from a tensor by index. For example, say we want to insert 4 scattered elements in a rank-1 tensor with 8 elements.</source>
          <target state="translated">tensor_scatter_sub의 가장 간단한 형식은 인덱스로 텐서에서 개별 요소를 빼는 것입니다. 예를 들어, 4 개의 산란 된 요소를 8 개의 요소가있는 랭크 -1 텐서에 삽입하려고합니다.</target>
        </trans-unit>
        <trans-unit id="802d517fc471afa54d770d15cdbc678a89e0c7a9" translate="yes" xml:space="preserve">
          <source>The simplest version of &lt;code&gt;map_fn&lt;/code&gt; repeatedly applies the callable &lt;code&gt;fn&lt;/code&gt; to a sequence of elements from first to last. The elements are made of the tensors unpacked from &lt;code&gt;elems&lt;/code&gt;. &lt;code&gt;dtype&lt;/code&gt; is the data type of the return value of &lt;code&gt;fn&lt;/code&gt;. Users must provide &lt;code&gt;dtype&lt;/code&gt; if it is different from the data type of &lt;code&gt;elems&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;map_fn&lt;/code&gt; 의 가장 간단한 버전은 호출 가능한 &lt;code&gt;fn&lt;/code&gt; 을 처음부터 끝까지 일련의 요소에 반복적으로 적용합니다 . 요소는 &lt;code&gt;elems&lt;/code&gt; 에서 압축이 풀린 텐서로 만들어집니다 . &lt;code&gt;dtype&lt;/code&gt; 은 &lt;code&gt;fn&lt;/code&gt; 반환 값의 데이터 유형입니다 . 사용자가 제공해야 &lt;code&gt;dtype&lt;/code&gt; 그것의 데이터 유형과 다른 경우 &lt;code&gt;elems&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d7f6d20e0852a13ae739990f6fedc34688b995c0" translate="yes" xml:space="preserve">
          <source>The simplest version of &lt;code&gt;scan&lt;/code&gt; repeatedly applies the callable &lt;code&gt;fn&lt;/code&gt; to a sequence of elements from first to last. The elements are made of the tensors unpacked from &lt;code&gt;elems&lt;/code&gt; on dimension 0. The callable fn takes two tensors as arguments. The first argument is the accumulated value computed from the preceding invocation of fn, and the second is the value at the current position of &lt;code&gt;elems&lt;/code&gt;. If &lt;code&gt;initializer&lt;/code&gt; is None, &lt;code&gt;elems&lt;/code&gt; must contain at least one element, and its first element is used as the initializer.</source>
          <target state="translated">가장 간단한 &lt;code&gt;scan&lt;/code&gt; 버전은 호출 가능한 &lt;code&gt;fn&lt;/code&gt; 을 처음부터 끝까지 일련의 요소에 반복적으로 적용합니다 . 이 요소에서 압축 해제 텐서 이루어지는 &lt;code&gt;elems&lt;/code&gt; : 호출 FN 인수로 두 텐서 소요 치수에 0. 첫 번째 인수는 이전의 fn 호출에서 계산 된 누적 값이고 두 번째 인수는 현재 위치의 값입니다. &lt;code&gt;elems&lt;/code&gt; 입니다. 경우 &lt;code&gt;initializer&lt;/code&gt; 없음입니다, &lt;code&gt;elems&lt;/code&gt; 는 적어도 하나 개의 요소를 포함해야하고, 첫 번째 요소는 초기화로 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="7a38981091aad7a606ea4d4d2a567d64ac905976" translate="yes" xml:space="preserve">
          <source>The simplest way to create a dataset is to create it from a python &lt;code&gt;list&lt;/code&gt;:</source>
          <target state="translated">데이터 셋을 생성하는 가장 간단한 방법은 파이썬 &lt;code&gt;list&lt;/code&gt; 에서 생성하는 것입니다 .</target>
        </trans-unit>
        <trans-unit id="017e6c560666c8b8adcda856df4242248fd294ae" translate="yes" xml:space="preserve">
          <source>The sizes of the pooling regions are generated randomly but are fairly uniform. For example, let's look at the height dimension, and the constraints on the list of rows that will be pool boundaries.</source>
          <target state="translated">풀링 영역의 크기는 무작위로 생성되지만 상당히 균일합니다. 예를 들어, 높이 차원과 풀 경계가 될 행 목록의 제약 조건을 살펴 보겠습니다.</target>
        </trans-unit>
        <trans-unit id="50a231b5d401442573df3e17bbb0c7335e8e5d44" translate="yes" xml:space="preserve">
          <source>The softmax of each vector x is calculated by &lt;code&gt;exp(x)/tf.reduce_sum(exp(x))&lt;/code&gt;. The input values in are the log-odds of the resulting probability.</source>
          <target state="translated">각 벡터 x의 소프트 맥스는 &lt;code&gt;exp(x)/tf.reduce_sum(exp(x))&lt;/code&gt; . 입력 값은 결과 확률의 로그 홀수입니다.</target>
        </trans-unit>
        <trans-unit id="b6d8793457c083f0d11acb319bb58de8dcf61657" translate="yes" xml:space="preserve">
          <source>The softplus activation: &lt;code&gt;log(exp(x) + 1)&lt;/code&gt;.</source>
          <target state="translated">softplus 활성화 : &lt;code&gt;log(exp(x) + 1)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a35f61726860bd793a42b2269f7f12bfff5f5061" translate="yes" xml:space="preserve">
          <source>The softplus activation: &lt;code&gt;x / (abs(x) + 1)&lt;/code&gt;.</source>
          <target state="translated">softplus 활성화 : &lt;code&gt;x / (abs(x) + 1)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6542d7e39f0c310801daa6538837ad6138ffae82" translate="yes" xml:space="preserve">
          <source>The solution is to ensure any access to the underlying resource &lt;code&gt;v&lt;/code&gt; is only processed through a critical section:</source>
          <target state="translated">해결책은 기본 리소스에 대한 액세스를 보장하는 것입니다 &lt;code&gt;v&lt;/code&gt; 에 중요한 섹션을 통해서만 처리되도록하는 것입니다.</target>
        </trans-unit>
        <trans-unit id="8a9c87c3bbd16608d71f6244bf102c899fcfe323" translate="yes" xml:space="preserve">
          <source>The solution is to wrap the model construction and execution in a keras-style scope:</source>
          <target state="translated">해결책은 모델 구성 및 실행을 keras 스타일 범위로 감싸는 것입니다.</target>
        </trans-unit>
        <trans-unit id="e590f462584ca8d9fda3b6ea3ab70cb8db99fef3" translate="yes" xml:space="preserve">
          <source>The source of the non-determinism will be platform- and time-dependent.</source>
          <target state="translated">비결정론의 근원은 플랫폼 및 시간에 따라 다릅니다.</target>
        </trans-unit>
        <trans-unit id="7b94d68698f376ae68caf545ac2ad9ff65451535" translate="yes" xml:space="preserve">
          <source>The sparse implementation of this algorithm (used when the gradient is an IndexedSlices object, typically because of &lt;a href=&quot;../../../gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt; or an embedding lookup in the forward pass) does apply momentum to variable slices even if they were not used in the forward pass (meaning they have a gradient equal to zero). Momentum decay (beta1) is also applied to the entire momentum accumulator. This means that the sparse behavior is equivalent to the dense behavior (in contrast to some momentum implementations which ignore momentum unless a variable slice was actually used).</source>
          <target state="translated">이 알고리즘의 희소 한 구현 (그라디언트가 일반적으로 &lt;a href=&quot;../../../gather&quot;&gt; &lt;code&gt;tf.gather&lt;/code&gt; &lt;/a&gt; 또는 포워드 패스의 임베딩 조회로 인해 IndexedSlices 객체 인 경우 사용)은 포워드 패스에서 사용되지 않더라도 변수 슬라이스에 운동량을 적용합니다 (즉, 0과 같은 기울기를 가짐). 운동량 붕괴 (beta1)는 또한 전체 운동량 누산기에 적용됩니다. 이는 희박한 동작이 조밀 한 동작과 동일 함을 의미합니다 (가변 슬라이스가 실제로 사용되지 않는 한 운동량을 무시하는 일부 운동량 구현과 달리).</target>
        </trans-unit>
        <trans-unit id="2c28505e1992f5a2d21a399d52aaf1d49a6228f7" translate="yes" xml:space="preserve">
          <source>The sparse implementation of this algorithm (used when the gradient is an IndexedSlices object, typically because of &lt;a href=&quot;../../gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt; or an embedding lookup in the forward pass) does apply momentum to variable slices even if they were not used in the forward pass (meaning they have a gradient equal to zero). Momentum decay (beta1) is also applied to the entire momentum accumulator. This means that the sparse behavior is equivalent to the dense behavior (in contrast to some momentum implementations which ignore momentum unless a variable slice was actually used).</source>
          <target state="translated">이 알고리즘의 희소 한 구현 (그라디언트가 일반적으로 &lt;a href=&quot;../../gather&quot;&gt; &lt;code&gt;tf.gather&lt;/code&gt; &lt;/a&gt; 또는 포워드 패스의 임베딩 조회로 인해 IndexedSlices 객체 인 경우 사용)은 포워드 패스에서 사용되지 않더라도 변수 슬라이스에 운동량을 적용합니다 (즉, 0과 같은 기울기를 가짐). 운동량 붕괴 (beta1)는 또한 전체 운동량 누산기에 적용됩니다. 이는 희박한 동작이 조밀 한 동작과 동일 함을 의미합니다 (가변 슬라이스가 실제로 사용되지 않는 한 운동량을 무시하는 일부 운동량 구현과 달리).</target>
        </trans-unit>
        <trans-unit id="8b88004b19728b58b00753256fbdb980b735e8d2" translate="yes" xml:space="preserve">
          <source>The split indices for the ragged tensor value.</source>
          <target state="translated">비정형 텐서 값의 분할 인덱스입니다.</target>
        </trans-unit>
        <trans-unit id="b29667fc1f908940634484906fb6441d097a55ad" translate="yes" xml:space="preserve">
          <source>The standard &lt;code&gt;segment_*&lt;/code&gt; functions assert that the segment indices are sorted. If you have unsorted indices use the equivalent &lt;code&gt;unsorted_segment_&lt;/code&gt; function. Thses functions take an additional argument &lt;code&gt;num_segments&lt;/code&gt; so that the output tensor can be efficiently allocated.</source>
          <target state="translated">표준 &lt;code&gt;segment_*&lt;/code&gt; 함수는 세그먼트 인덱스가 정렬되도록합니다. 정렬되지 않은 인덱스가있는 경우 동등한 &lt;code&gt;unsorted_segment_&lt;/code&gt; 함수를 사용하십시오 . 이 함수는 추가 인수 &lt;code&gt;num_segments&lt;/code&gt; 를 사용합니다. 는 출력 텐서를 효율적으로 할당 할 수 있도록 를 사용합니다.</target>
        </trans-unit>
        <trans-unit id="6cf74e13a5dc987612c9d705626f37de29ad545f" translate="yes" xml:space="preserve">
          <source>The standard library uses various well-known names to collect and retrieve values associated with a graph. For example, the &lt;code&gt;tf.Optimizer&lt;/code&gt; subclasses default to optimizing the variables collected under &lt;code&gt;tf.GraphKeys.TRAINABLE_VARIABLES&lt;/code&gt; if none is specified, but it is also possible to pass an explicit list of variables.</source>
          <target state="translated">표준 라이브러리는 잘 알려진 다양한 이름을 사용하여 그래프와 관련된 값을 수집하고 검색합니다. 예를 들어, &lt;code&gt;tf.Optimizer&lt;/code&gt; 서브 클래스는 기본값 이 지정되지 않은 경우 &lt;code&gt;tf.GraphKeys.TRAINABLE_VARIABLES&lt;/code&gt; 에서 수집 된 변수를 최적화하도록 기본 설정 되지만 명시적인 변수 목록을 전달할 수도 있습니다.</target>
        </trans-unit>
        <trans-unit id="ce8c36f190ecab29f1604c69bb1fdd2396d6f9bd" translate="yes" xml:space="preserve">
          <source>The standard pattern for updating variables is to:</source>
          <target state="translated">변수 업데이트의 표준 패턴은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="1df550e9ac2ff1efc86381fe4007d40151e6c36c" translate="yes" xml:space="preserve">
          <source>The started thread is added to the list of threads managed by the supervisor so it does not need to be passed to the &lt;code&gt;stop()&lt;/code&gt; method.</source>
          <target state="translated">시작된 스레드는 수퍼바이저가 관리하는 스레드 목록에 추가되므로 &lt;code&gt;stop()&lt;/code&gt; 메소드 로 전달할 필요가 없습니다 .</target>
        </trans-unit>
        <trans-unit id="22b0c0a61720b2b49f3bdb46b68ab2ffe3bd7116" translate="yes" xml:space="preserve">
          <source>The started thread.</source>
          <target state="translated">시작된 스레드.</target>
        </trans-unit>
        <trans-unit id="dd546c154f1294509a35cef6daf7e05272419f55" translate="yes" xml:space="preserve">
          <source>The state of the optimizer, allowing to resume training exactly where you left off.</source>
          <target state="translated">최적화의 상태로, 중단 한 곳에서 훈련을 재개 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="712f8a6f55bf7c5b4fd684dab030efe40f46ccee" translate="yes" xml:space="preserve">
          <source>The statically known shape of this ragged tensor.</source>
          <target state="translated">이 울퉁불퉁 한 텐서의 정적으로 알려진 모양.</target>
        </trans-unit>
        <trans-unit id="05eef5966a4733b45681c7bb2c1cfa7fcd7e3ded" translate="yes" xml:space="preserve">
          <source>The statistics options associated with the dataset. See &lt;a href=&quot;experimental/statsoptions&quot;&gt;&lt;code&gt;tf.data.experimental.StatsOptions&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">데이터 세트와 관련된 통계 옵션. 자세한 내용은 &lt;a href=&quot;experimental/statsoptions&quot;&gt; &lt;code&gt;tf.data.experimental.StatsOptions&lt;/code&gt; &lt;/a&gt; 를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="a8c6e46a80c3223660eded889659ea2c4138b476" translate="yes" xml:space="preserve">
          <source>The step set by &lt;a href=&quot;set_step&quot;&gt;&lt;code&gt;tf.summary.experimental.set_step()&lt;/code&gt;&lt;/a&gt; if one has been set, otherwise None.</source>
          <target state="translated">&lt;a href=&quot;set_step&quot;&gt; &lt;code&gt;tf.summary.experimental.set_step()&lt;/code&gt; &lt;/a&gt; 의해 설정된 단계 (설정된 경우 ) , 그렇지 않은 경우 없음.</target>
        </trans-unit>
        <trans-unit id="5dff7b910b7ad17251b2c5a9c0f91aaacc64e975" translate="yes" xml:space="preserve">
          <source>The str() operator of a 'FlagValues' object provides help for all of the registered 'Flag' objects.</source>
          <target state="translated">'FlagValues'객체의 str () 연산자는 등록 된 모든 'Flag'객체에 대한 도움말을 제공합니다.</target>
        </trans-unit>
        <trans-unit id="13be6068510e1bba9bcaba7458adf0809e711454" translate="yes" xml:space="preserve">
          <source>The strategy may choose to put the variable on multiple devices, like mirrored variables, but unlike mirrored variables we don't synchronize the updates to them to make sure they have the same value. Instead, the synchronization is performed when reading in cross-replica context. In a replica context, reads and writes are performed on the local copy (we allow reads so you can write code like &lt;code&gt;v = 0.9*v + 0.1*update&lt;/code&gt;). We don't allow operations like &lt;code&gt;v.assign_add&lt;/code&gt; in a cross-replica context for sync on read variables; right now we don't have a use case for such updates and depending on the aggregation mode such updates may not be sensible.</source>
          <target state="translated">이 전략은 변수를 미러링 된 변수와 같은 여러 장치에 배치하도록 선택할 수 있지만 미러링 된 변수와 달리 업데이트를 동기화하여 동일한 값을 갖지 않도록합니다. 대신, 교차 복제 컨텍스트에서 읽을 때 동기화가 수행됩니다. 복제본 컨텍스트에서 로컬 복사에 대해 읽기 및 쓰기가 수행됩니다 ( &lt;code&gt;v = 0.9*v + 0.1*update&lt;/code&gt; 와 같은 코드를 작성할 수 있도록 읽기 허용 ). 읽기 변수에 대한 동기화를 위해 교차 복제 컨텍스트에서 &lt;code&gt;v.assign_add&lt;/code&gt; 와 같은 작업을 허용하지 않습니다 . 현재로서는 이러한 업데이트에 대한 사용 사례가 없으며 집계 모드에 따라 이러한 업데이트가 감지되지 않을 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="644f3a81fca55d1677b34a373591148f236e0ab3" translate="yes" xml:space="preserve">
          <source>The string &quot;tensorflow&quot;.</source>
          <target state="translated">문자열 &quot;tensorflow&quot;.</target>
        </trans-unit>
        <trans-unit id="56132600b50269345758de3a44957eaf5ba36a10" translate="yes" xml:space="preserve">
          <source>The string name of the device to which this op has been assigned, or an empty string if it has not been assigned to a device.</source>
          <target state="translated">이 op가 할당 된 장치의 문자열 이름이거나 장치에 할당되지 않은 경우 빈 문자열입니다.</target>
        </trans-unit>
        <trans-unit id="8992e1dfe2880c9a4de6beb1ac8e0230422a7a79" translate="yes" xml:space="preserve">
          <source>The string name of the underlying Queue.</source>
          <target state="translated">기본 큐의 문자열 이름입니다.</target>
        </trans-unit>
        <trans-unit id="a96aa4c9d9595a33bb0f9789d55b573d138edebb" translate="yes" xml:space="preserve">
          <source>The string name of this tensor.</source>
          <target state="translated">이 텐서의 문자열 이름입니다.</target>
        </trans-unit>
        <trans-unit id="c67de356b037fd5e8be6d855afae37205aa00794" translate="yes" xml:space="preserve">
          <source>The string path to the exported directory or &lt;code&gt;None&lt;/code&gt; if export is skipped.</source>
          <target state="translated">내 보낸 디렉토리에 대한 문자열 경로 또는 내보내기를 건너 뛰는 경우 &lt;code&gt;None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e5efe1c4c830550f08c9bea1e979d7c9a7668a12" translate="yes" xml:space="preserve">
          <source>The string path to the exported directory.</source>
          <target state="translated">내 보낸 디렉토리의 문자열 경로입니다.</target>
        </trans-unit>
        <trans-unit id="bb20559dca432fe77c06ffe1211357d7726b77ab" translate="yes" xml:space="preserve">
          <source>The structure of the components of this optional.</source>
          <target state="translated">이 옵션의 구성 요소 구조.</target>
        </trans-unit>
        <trans-unit id="10e607f82b834bedf8082612b2f31785cf1834ed" translate="yes" xml:space="preserve">
          <source>The stubbing is using the builtin getattr and setattr. So, the &lt;strong&gt;get&lt;/strong&gt; and &lt;strong&gt;set&lt;/strong&gt; will be called when stubbing (TODO: A better idea would probably be to manipulate obj.&lt;strong&gt;dict&lt;/strong&gt; instead of getattr() and setattr()).</source>
          <target state="translated">스터 빙은 내장 getattr 및 setattr을 사용하고 있습니다. 그래서, &lt;strong&gt;GET&lt;/strong&gt; 및 &lt;strong&gt;세트&lt;/strong&gt; 스텁 때 호출됩니다 (TODO를 :. 더 나은 아이디어는 아마 OBJ 조작하는 것입니다 &lt;strong&gt;DICT&lt;/strong&gt; 대신 getattr ()와 않은 setattr (의)).</target>
        </trans-unit>
        <trans-unit id="0b87677b2e7091b18f84e0a5a53ce47bf2fbc17a" translate="yes" xml:space="preserve">
          <source>The sum of the squared distance from each point in the first batch of inputs to its nearest cluster center.</source>
          <target state="translated">첫 번째 입력 배치의 각 점에서 가장 가까운 군집 중심까지의 제곱 거리의 합입니다.</target>
        </trans-unit>
        <trans-unit id="fa003ab56e1eb5342f9795fdbfba586bfe2f1900" translate="yes" xml:space="preserve">
          <source>The supervisor is notified of any exception raised by one of the services. After an exception is raised, &lt;code&gt;should_stop()&lt;/code&gt; returns &lt;code&gt;True&lt;/code&gt;. In that case the training loop should also stop. This is why the training loop has to check for &lt;code&gt;sv.should_stop()&lt;/code&gt;.</source>
          <target state="translated">서비스 중 하나에서 발생한 예외에 대해 감독자에게 알립니다. 예외가 발생하면 &lt;code&gt;should_stop()&lt;/code&gt; 은 &lt;code&gt;True&lt;/code&gt; 를 반환합니다 . 이 경우 훈련 루프도 중지해야합니다. 이것이 훈련 루프가 &lt;code&gt;sv.should_stop()&lt;/code&gt; 을 확인 해야하는 이유 입니다.</target>
        </trans-unit>
        <trans-unit id="b372ddff28f44f63c6e232f1c30d44e36e67c586" translate="yes" xml:space="preserve">
          <source>The table key dtype.</source>
          <target state="translated">테이블 키 dtype.</target>
        </trans-unit>
        <trans-unit id="45ea7c0740084e6be8859e3f6c6a5a25999322a4" translate="yes" xml:space="preserve">
          <source>The table value dtype.</source>
          <target state="translated">테이블 값 dtype.</target>
        </trans-unit>
        <trans-unit id="39fc3d1afa951ce1fc0c6acdffe30bf9d05aaa6f" translate="yes" xml:space="preserve">
          <source>The task of an Enqueuer is to use parallelism to speed up preprocessing. This is done with processes or threads.</source>
          <target state="translated">Enqueuer의 임무는 병렬 처리를 사용하여 전처리 속도를 높이는 것입니다. 이것은 프로세스 또는 스레드로 수행됩니다.</target>
        </trans-unit>
        <trans-unit id="8d203e324545cf312d1311ac6ed39dbe8533902e" translate="yes" xml:space="preserve">
          <source>The temporary directory.</source>
          <target state="translated">임시 디렉토리.</target>
        </trans-unit>
        <trans-unit id="ba8d97a1a9f6a392dad767f9f5f935fc3b942c5f" translate="yes" xml:space="preserve">
          <source>The tensor at index &lt;code&gt;index&lt;/code&gt;.</source>
          <target state="translated">인덱스에서 텐서 &lt;code&gt;index&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1b8bac0316b66126d9a5f3d03ead635dc9c4e503" translate="yes" xml:space="preserve">
          <source>The tensor is shuffled along dimension 0, such that each &lt;code&gt;value[j]&lt;/code&gt; is mapped to one and only one &lt;code&gt;output[i]&lt;/code&gt;. For example, a mapping that might occur for a 3x2 tensor is:</source>
          <target state="translated">텐서는 각각의 &lt;code&gt;value[j]&lt;/code&gt; 이 하나의 &lt;code&gt;output[i]&lt;/code&gt; 에만 매핑되도록 차원 0을 따라 섞 입니다. 예를 들어 3x2 텐서에서 발생할 수있는 매핑은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="263280cf1684ff5fb9dc90aff492167c49c357e8" translate="yes" xml:space="preserve">
          <source>The tensors in the &lt;code&gt;TensorArray&lt;/code&gt; selected by &lt;code&gt;indices&lt;/code&gt;, packed into one tensor.</source>
          <target state="translated">&lt;code&gt;indices&lt;/code&gt; 선택된 &lt;code&gt;TensorArray&lt;/code&gt; 의 텐서는 하나의 텐서로 압축됩니다.</target>
        </trans-unit>
        <trans-unit id="14d5f93ad26c02d132da873b0983deda8cc5ede0" translate="yes" xml:space="preserve">
          <source>The tensors returned by the callable identified by &lt;code&gt;branch_index&lt;/code&gt;, or those returned by &lt;code&gt;default&lt;/code&gt; if no key matches and &lt;code&gt;default&lt;/code&gt; was provided, or those returned by the max-keyed &lt;code&gt;branch_fn&lt;/code&gt; if no &lt;code&gt;default&lt;/code&gt; is provided.</source>
          <target state="translated">호출 가능한 의해 반환 된 텐서에 의해 확인 &lt;code&gt;branch_index&lt;/code&gt; , 또는 이들에 의해 반환 된 &lt;code&gt;default&lt;/code&gt; 키와 일치하고있는 경우 &lt;code&gt;default&lt;/code&gt; 제공되지 않았거나 사람들이 최대 - 키 입력에 의해 반환 &lt;code&gt;branch_fn&lt;/code&gt; 어떤 경우 &lt;code&gt;default&lt;/code&gt; 제공되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="0ea9d9d23c406f164fd2c56245bf91a63b2aa423" translate="yes" xml:space="preserve">
          <source>The tensors returned by the first pair whose predicate evaluated to True, or those returned by &lt;code&gt;default&lt;/code&gt; if none does.</source>
          <target state="translated">술어가 True로 평가 된 첫 번째 쌍에서 리턴 된 텐서 또는 없는 경우 &lt;code&gt;default&lt;/code&gt; 리턴 된 텐서 입니다.</target>
        </trans-unit>
        <trans-unit id="62c909c71b66d6f5bfc11fa3e5279c6761971045" translate="yes" xml:space="preserve">
          <source>The tensors returned from &lt;code&gt;fn()&lt;/code&gt;.</source>
          <target state="translated">텐서는 &lt;code&gt;fn()&lt;/code&gt; 에서 반환되었습니다 .</target>
        </trans-unit>
        <trans-unit id="2f38446647c9bdb5f6c17c4098bf60d7f38504af" translate="yes" xml:space="preserve">
          <source>The tensors will be printed to the log, with &lt;code&gt;INFO&lt;/code&gt; severity. If you are not seeing the logs, you might want to add the following line after your imports:</source>
          <target state="translated">텐서는 &lt;code&gt;INFO&lt;/code&gt; 심각도 와 함께 로그에 인쇄됩니다 . 로그가 표시되지 않으면 가져 오기 후에 다음 행을 추가 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="11bfdd9c3d39d4a32c1a375c3ce8bfd375bd0b18" translate="yes" xml:space="preserve">
          <source>The tf.tpu.Topology object for the topology of the TPU cluster.</source>
          <target state="translated">TPU 클러스터의 토폴로지에 대한 tf.tpu.Topology 오브젝트입니다.</target>
        </trans-unit>
        <trans-unit id="befdc8701902b7376e60ef81bed3d724c3bb2879" translate="yes" xml:space="preserve">
          <source>The the elements of the output vector are in range (0, 1) and sum to 1.</source>
          <target state="translated">출력 벡터의 요소는 (0, 1) 범위에 있고 합은 1입니다.</target>
        </trans-unit>
        <trans-unit id="e8a1b74b382d4bec7d008b052874fc8efea06387" translate="yes" xml:space="preserve">
          <source>The threading options associated with the dataset. See &lt;a href=&quot;experimental/threadingoptions&quot;&gt;&lt;code&gt;tf.data.experimental.ThreadingOptions&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">데이터 세트와 관련된 스레딩 옵션입니다. 자세한 내용은 &lt;a href=&quot;experimental/threadingoptions&quot;&gt; &lt;code&gt;tf.data.experimental.ThreadingOptions&lt;/code&gt; &lt;/a&gt; 를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="d3e4fd90c9e18807d72bafd4f4716080dd6bc34f" translate="yes" xml:space="preserve">
          <source>The total number of dimensions in a &lt;code&gt;RaggedTensor&lt;/code&gt; is called its &lt;em&gt;rank&lt;/em&gt;, and the number of ragged dimensions in a &lt;code&gt;RaggedTensor&lt;/code&gt; is called its &lt;em&gt;ragged-rank&lt;/em&gt;. A &lt;code&gt;RaggedTensor&lt;/code&gt;'s ragged-rank is fixed at graph creation time: it can't depend on the runtime values of &lt;code&gt;Tensor&lt;/code&gt;s, and can't vary dynamically for different session runs.</source>
          <target state="translated">A의 크기의 총계 &lt;code&gt;RaggedTensor&lt;/code&gt; 는 그 호출 &lt;em&gt;순위&lt;/em&gt; 및 비정형의 차원 수 &lt;code&gt;RaggedTensor&lt;/code&gt; 는 그 호출 &lt;em&gt;울퉁불퉁 랭크를&lt;/em&gt; . &lt;code&gt;RaggedTensor&lt;/code&gt; 그것의 실행 값에 의존하지 수의 그래프 작성시에 고정되고, 랭크 - 울퉁불퉁 &lt;code&gt;Tensor&lt;/code&gt; 들 및 다른 세션 실행 동적으로 변화 할 수 없다.</target>
        </trans-unit>
        <trans-unit id="7366f216b0f07a06f98c4cfb72b6efd8edad2b69" translate="yes" xml:space="preserve">
          <source>The total variation is the sum of the absolute differences for neighboring pixel-values in the input images. This measures how much noise is in the images.</source>
          <target state="translated">총 변동은 입력 이미지에서 인접 픽셀 값의 절대 차이의 합입니다. 이미지의 노이즈 량을 측정합니다.</target>
        </trans-unit>
        <trans-unit id="4cd5555b6721cf29a977af9cf8bb6114222ca75d" translate="yes" xml:space="preserve">
          <source>The total variation of &lt;code&gt;images&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;images&lt;/code&gt; 의 총 변형입니다 .</target>
        </trans-unit>
        <trans-unit id="b1be006e04763947d6204304381da8047ab403c6" translate="yes" xml:space="preserve">
          <source>The trace of input tensor.</source>
          <target state="translated">입력 텐서의 흔적.</target>
        </trans-unit>
        <trans-unit id="e883a1ea41a9a9c563ecd15d66e0cea02e0fd475" translate="yes" xml:space="preserve">
          <source>The transformation calls &lt;code&gt;reduce_func&lt;/code&gt; successively on every element of the input dataset until the dataset is exhausted, aggregating information in its internal state. The &lt;code&gt;initial_state&lt;/code&gt; argument is used for the initial state and the final state is returned as the result.</source>
          <target state="translated">변환 은 데이터 세트가 소진 될 때까지 입력 데이터 세트의 모든 요소에 대해 &lt;code&gt;reduce_func&lt;/code&gt; 를 연속적으로 호출 하여 내부 상태로 정보를 집계합니다. &lt;code&gt;initial_state&lt;/code&gt; 인자는 초기 상태에 대해 사용되며, 최종 상태의 결과로서 반환된다.</target>
        </trans-unit>
        <trans-unit id="a76374d8db32ee668d78ea0cbd0b4fb2bd9d2baf" translate="yes" xml:space="preserve">
          <source>The transpose of &lt;code&gt;atrous_conv2d&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;atrous_conv2d&lt;/code&gt; 의 전치입니다 .</target>
        </trans-unit>
        <trans-unit id="24fae844f58c6b39229d2519fcdd2125a204111b" translate="yes" xml:space="preserve">
          <source>The transpose of &lt;code&gt;conv1d&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;conv1d&lt;/code&gt; 의 전치입니다 .</target>
        </trans-unit>
        <trans-unit id="e5584a45278a21e44f011bf21c57aa5501a09482" translate="yes" xml:space="preserve">
          <source>The transpose of &lt;code&gt;conv2d&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;conv2d&lt;/code&gt; 의 전치입니다 .</target>
        </trans-unit>
        <trans-unit id="88458abd7b78099fd74249ee9fe81104261b47e7" translate="yes" xml:space="preserve">
          <source>The transpose of &lt;code&gt;conv3d&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;conv3d&lt;/code&gt; 의 전치입니다 .</target>
        </trans-unit>
        <trans-unit id="4974672a5f0bdf2f1f4a3ac2ea5cc95568047305" translate="yes" xml:space="preserve">
          <source>The transpose of &lt;code&gt;convolution&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;convolution&lt;/code&gt; 의 전치 .</target>
        </trans-unit>
        <trans-unit id="1519a20ef4fe586180643d48497a05b2e0fad92f" translate="yes" xml:space="preserve">
          <source>The tuple of concatenated tensors that was dequeued.</source>
          <target state="translated">연결 해제 된 연결된 텐서의 튜플입니다.</target>
        </trans-unit>
        <trans-unit id="947a12be95ae913828fb29965c58acb416f681d0" translate="yes" xml:space="preserve">
          <source>The tuple of tensors that was dequeued.</source>
          <target state="translated">큐어 링 된 텐서의 튜플.</target>
        </trans-unit>
        <trans-unit id="fcce8e7308a1f27fd06f367ce630638c93d290a0" translate="yes" xml:space="preserve">
          <source>The two arguments should be data trees consisting of trees of dicts and lists. They will be deeply compared by walking into the contents of dicts and lists; other items will be compared using the == operator. If the two structures differ in content, the failure message will indicate the location within the structures where the first difference is found. This may be helpful when comparing large structures.</source>
          <target state="translated">두 가지 주장은 dicts와 list의 트리로 구성된 데이터 트리 여야합니다. 그것들은 dicts와 list의 내용으로 들어가서 깊이 비교 될 것입니다. 다른 항목은 == 연산자를 사용하여 비교됩니다. 두 구조의 내용이 다른 경우 실패 메시지는 첫 번째 차이점이 발견 된 구조 내의 위치를 ​​나타냅니다. 큰 구조를 비교할 때 도움이 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="c63ea59f28eeb3c5ef7f12904295f5acd2abba7d" translate="yes" xml:space="preserve">
          <source>The two optional lists, &lt;code&gt;shapes&lt;/code&gt; and &lt;code&gt;names&lt;/code&gt;, must be of the same length as &lt;code&gt;dtypes&lt;/code&gt; if provided. The values at a given index &lt;code&gt;i&lt;/code&gt; indicate the shape and name to use for the corresponding queue component in &lt;code&gt;dtypes&lt;/code&gt;.</source>
          <target state="translated">두 개의 선택적 목록 인 &lt;code&gt;shapes&lt;/code&gt; 및 &lt;code&gt;names&lt;/code&gt; 는 제공된 경우 &lt;code&gt;dtypes&lt;/code&gt; 과 길이가 같아야 합니다. 지정된 인덱스 &lt;code&gt;i&lt;/code&gt; 의 값 은 &lt;code&gt;dtypes&lt;/code&gt; 의 해당 큐 구성 요소에 사용할 모양과 이름을 나타냅니다 .</target>
        </trans-unit>
        <trans-unit id="8cccbb2c85e31880b8682b2d0adfb113b78b64da" translate="yes" xml:space="preserve">
          <source>The type of compression for the record.</source>
          <target state="translated">레코드 압축 유형입니다.</target>
        </trans-unit>
        <trans-unit id="0e39ef94a4f11a83b4f0f2df2ede7e0ef31ede65" translate="yes" xml:space="preserve">
          <source>The type of loss reduction used in the head.</source>
          <target state="translated">헤드에서 사용되는 손실 감소 유형입니다.</target>
        </trans-unit>
        <trans-unit id="9e1c8635c975f4590fc90901ef34444f7e5713cc" translate="yes" xml:space="preserve">
          <source>The type of sharding that auto-shard should attempt. If this is set to FILE, then we will attempt to shard by files (each worker will get a set of files to process). If we cannot find a set of files to shard for at least one file per worker, we will error out. When this option is selected, make sure that you have enough files so that each worker gets at least one file. There will be a runtime error thrown if there are insufficient files. If this is set to DATA, then we will shard by elements produced by the dataset, and each worker will process the whole dataset and discard the portion that is not for itself. If this is set to OFF, then we will not autoshard, and each worker will receive a copy of the full dataset. This option is set to AUTO by default, AUTO will attempt to first shard by FILE, and fall back to sharding by DATA if we cannot find a set of files to shard.</source>
          <target state="translated">자동 샤드가 시도해야하는 샤딩 유형입니다. 이것이 FILE로 설정되면 파일별로 샤드를 시도합니다 (각 작업자가 처리 할 파일 세트를 얻습니다). 작업 자당 최소 하나의 파일을 파쇄 할 파일 세트를 찾을 수 없으면 오류가 발생합니다. 이 옵션을 선택하면 각 작업자가 하나 이상의 파일을받을 수 있도록 충분한 파일이 있는지 확인하십시오. 파일이 충분하지 않으면 런타임 오류가 발생합니다. 이것이 DATA로 설정되면, 우리는 데이터 세트에 의해 생성 된 요소들에 의해 샤드 될 것이고, 각 작업자는 전체 데이터 세트를 처리하고 그 자체가 아닌 부분을 폐기 할 것입니다. 이것이 OFF로 설정되면 자동 파쇄되지 않으며 각 작업자는 전체 데이터 세트의 사본을받습니다. 이 옵션은 기본적으로 AUTO로 설정되어 있으며 AUTO는 먼저 FILE로 샤드를 시도합니다.샤드 할 파일 세트를 찾을 수 없으면 DATA에 의한 샤딩으로 폴백합니다.</target>
        </trans-unit>
        <trans-unit id="e5ac8c9ef31246fab5b3b784f6fdb5ffec2b2eba" translate="yes" xml:space="preserve">
          <source>The type of the op (e.g. &lt;code&gt;&quot;MatMul&quot;&lt;/code&gt;).</source>
          <target state="translated">op의 유형입니다 (예 : &lt;code&gt;&quot;MatMul&quot;&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="9f4d546108b4584207f8473dd28294356ddeede5" translate="yes" xml:space="preserve">
          <source>The type specification of an element of this dataset.</source>
          <target state="translated">이 데이터 세트의 요소의 형태 사양입니다.</target>
        </trans-unit>
        <trans-unit id="31f5cdd5cadead57bcfc00f19cdc637b778a8dfa" translate="yes" xml:space="preserve">
          <source>The type specification of an element of this iterator.</source>
          <target state="translated">이 이터레이터의 요소의 타입 사양.</target>
        </trans-unit>
        <trans-unit id="bce40406c73aa0072207096be99446cc37cd3334" translate="yes" xml:space="preserve">
          <source>The types of the tensors in &lt;code&gt;values&lt;/code&gt; must match the schema for the fields specified in &lt;code&gt;field_names&lt;/code&gt;. All the tensors in &lt;code&gt;values&lt;/code&gt; must have a common shape prefix, &lt;em&gt;batch_shape&lt;/em&gt;.</source>
          <target state="translated">&lt;code&gt;values&lt;/code&gt; 의 텐서 유형은 &lt;code&gt;field_names&lt;/code&gt; 에 지정된 필드의 스키마와 일치해야합니다 . &lt;code&gt;values&lt;/code&gt; 모든 텐서 에는 공통 모양 접두어 &lt;em&gt;batch_shape가 있어야&lt;/em&gt; 합니다.</target>
        </trans-unit>
        <trans-unit id="e5381b2e579e07c748270f78ee35dd566e3eb442" translate="yes" xml:space="preserve">
          <source>The typical scenario for &lt;code&gt;ExponentialMovingAverage&lt;/code&gt; is to compute moving averages of variables during training, and restore the variables from the computed moving averages during evaluations.</source>
          <target state="translated">&lt;code&gt;ExponentialMovingAverage&lt;/code&gt; 의 일반적인 시나리오 는 학습 중에 변수의 이동 평균을 계산하고 평가 중에 계산 된 이동 평균에서 변수를 복원하는 것입니다.</target>
        </trans-unit>
        <trans-unit id="3da77fbceb0e840441ce8c39192555e97fa2928b" translate="yes" xml:space="preserve">
          <source>The underlying accumulator reference.</source>
          <target state="translated">기본 누산기 참조</target>
        </trans-unit>
        <trans-unit id="c25ef637b6290d9c594d8a4f22f2ec949aa1bd01" translate="yes" xml:space="preserve">
          <source>The underlying queue reference.</source>
          <target state="translated">기본 큐 참조</target>
        </trans-unit>
        <trans-unit id="d25a2d45745d4308947942d9bddb3fe51f90e219" translate="yes" xml:space="preserve">
          <source>The update rule for &lt;code&gt;variable&lt;/code&gt; with gradient &lt;code&gt;g&lt;/code&gt; uses an optimization described at the end of section 2 of the paper:</source>
          <target state="translated">그래디언트 &lt;code&gt;g&lt;/code&gt; 가있는 &lt;code&gt;variable&lt;/code&gt; 에 대한 업데이트 규칙 은 논문의 섹션 2 끝에 설명 된 최적화를 사용합니다.</target>
        </trans-unit>
        <trans-unit id="dcaa87717690c893cddcbb06c2774de0d640ef88" translate="yes" xml:space="preserve">
          <source>The update rule for &lt;code&gt;variable&lt;/code&gt; with gradient &lt;code&gt;g&lt;/code&gt; uses an optimization described at the end of section 7.1 of the paper:</source>
          <target state="translated">그래디언트 &lt;code&gt;g&lt;/code&gt; 가있는 &lt;code&gt;variable&lt;/code&gt; 의 업데이트 규칙 은 본 논문의 7.1 절 끝에 설명 된 최적화를 사용합니다.</target>
        </trans-unit>
        <trans-unit id="1a9901f8d5a239b98ad1f04b6bbdac6a25b5dbe0" translate="yes" xml:space="preserve">
          <source>The updated config has something needed to run a strategy, e.g. configuration to run collective ops, or device filters to improve distributed training performance.</source>
          <target state="translated">업데이트 된 구성에는 전략을 실행하는 데 필요한 것이 있습니다 (예 : 집단 작전을 실행하기위한 구성 또는 분산 된 훈련 성능을 향상시키기위한 장치 필터).</target>
        </trans-unit>
        <trans-unit id="60dd7fe2afadb5341f05d411ef207c2859229807" translate="yes" xml:space="preserve">
          <source>The updated copy of the &lt;code&gt;config_proto&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;config_proto&lt;/code&gt; 의 업데이트 된 사본 .</target>
        </trans-unit>
        <trans-unit id="7d9e39fd60700bb347ed0039e54d9af3ef5a5100" translate="yes" xml:space="preserve">
          <source>The updated decorator. If decorator_func is not a tf_decorator, new_target is returned.</source>
          <target state="translated">업데이트 된 데코레이터. decorator_func가 tf_decorator가 아닌 경우 new_target이 리턴됩니다.</target>
        </trans-unit>
        <trans-unit id="5d8daec55baf3c813ce2f2fc4a5eab596ea78fbf" translate="yes" xml:space="preserve">
          <source>The upper regularized incomplete Gamma function is defined as:</source>
          <target state="translated">정규화 된 불완전한 상위 감마 함수는 다음과 같이 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="a16fb2ccec6d9e76f7b18eacf6123674146710e7" translate="yes" xml:space="preserve">
          <source>The user could also use &lt;code&gt;make_input_fn_iterator&lt;/code&gt; if they want to customize which input is fed to which replica/worker etc.</source>
          <target state="translated">사용자는 어떤 입력이 어떤 복제본 / 작업자 등에 공급되는지 사용자 정의하려는 경우 &lt;code&gt;make_input_fn_iterator&lt;/code&gt; 를 사용할 수도 있습니다 .</target>
        </trans-unit>
        <trans-unit id="ab789081815c49957f21bd695c2a3924b82c20ff" translate="yes" xml:space="preserve">
          <source>The user is given the option of raising an exception or returning &lt;code&gt;NaN&lt;/code&gt;.</source>
          <target state="translated">사용자에게는 예외를 발생 시키거나 &lt;code&gt;NaN&lt;/code&gt; 을 반환하는 옵션이 제공 됩니다.</target>
        </trans-unit>
        <trans-unit id="2d78e502adf2b1729b9f368b8135c69dbb97bac0" translate="yes" xml:space="preserve">
          <source>The usual cross-entropy cost is defined as:</source>
          <target state="translated">일반적인 교차 엔트로피 비용은 다음과 같이 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="55894b0693429bc52d5ca851ab5e7e50a45cb526" translate="yes" xml:space="preserve">
          <source>The valid keyword arguments in kwds are:</source>
          <target state="translated">kwds의 ​​유효한 키워드 인수는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="2e9dcb12c3ec9343c2b4d76ebee61442f18c708d" translate="yes" xml:space="preserve">
          <source>The value &lt;code&gt;delta&lt;/code&gt; is added to all components of the tensor &lt;code&gt;image&lt;/code&gt;. &lt;code&gt;image&lt;/code&gt; is converted to &lt;code&gt;float&lt;/code&gt; and scaled appropriately if it is in fixed-point representation, and &lt;code&gt;delta&lt;/code&gt; is converted to the same data type. For regular images, &lt;code&gt;delta&lt;/code&gt; should be in the range &lt;code&gt;[0,1)&lt;/code&gt;, as it is added to the image in floating point representation, where pixel values are in the &lt;code&gt;[0,1)&lt;/code&gt; range.</source>
          <target state="translated">&lt;code&gt;delta&lt;/code&gt; 값 은 텐서 &lt;code&gt;image&lt;/code&gt; 의 모든 구성 요소에 추가됩니다 . &lt;code&gt;image&lt;/code&gt; 가 고정 소수점 표현 인 경우 이미지 는 &lt;code&gt;float&lt;/code&gt; 으로 변환 되고 크기가 적절하게 조정되고 &lt;code&gt;delta&lt;/code&gt; 는 동일한 데이터 유형으로 변환됩니다. 일반적인 이미지를 들어 &lt;code&gt;delta&lt;/code&gt; 범위 내에 있어야 &lt;code&gt;[0,1)&lt;/code&gt; 이 픽셀 값은에 부동 소수점 표현으로 화상에 추가로, &lt;code&gt;[0,1)&lt;/code&gt; 범위.</target>
        </trans-unit>
        <trans-unit id="a0cc40289aaf5ca63368c701a28edf746620f686" translate="yes" xml:space="preserve">
          <source>The value of &lt;code&gt;self.value &amp;gt; other.value&lt;/code&gt; if both are known, otherwise None.</source>
          <target state="translated">&lt;code&gt;self.value &amp;gt; other.value&lt;/code&gt; 의 값을 모두 알고 있으면 그렇지 않으면 None입니다.</target>
        </trans-unit>
        <trans-unit id="28eee150e3c68dabbd6edcffc1df83846a31e392" translate="yes" xml:space="preserve">
          <source>The value of &lt;code&gt;self.value &amp;gt;= other.value&lt;/code&gt; if both are known, otherwise None.</source>
          <target state="translated">&lt;code&gt;self.value &amp;gt;= other.value&lt;/code&gt; 의 값을 모두 알고 있으면 그렇지 않으면 None입니다.</target>
        </trans-unit>
        <trans-unit id="1ac388cf68a7917e640172de08cfda57213cf191" translate="yes" xml:space="preserve">
          <source>The value of &lt;code&gt;self.value &amp;lt; other.value&lt;/code&gt; if both are known, otherwise None.</source>
          <target state="translated">&lt;code&gt;self.value &amp;lt; other.value&lt;/code&gt; 둘 다 알려진 경우 값 , 그렇지 않으면 None</target>
        </trans-unit>
        <trans-unit id="b01cea77304d81c49aa6bfe991a86b9994cc913b" translate="yes" xml:space="preserve">
          <source>The value of &lt;code&gt;self.value &amp;lt;= other.value&lt;/code&gt; if both are known, otherwise None.</source>
          <target state="translated">&lt;code&gt;self.value &amp;lt;= other.value&lt;/code&gt; 의 값을 모두 알고 있으면 그렇지 않으면 None입니다.</target>
        </trans-unit>
        <trans-unit id="97a93b3e6e5220aba9e50c43c510d2bbbc1a87e0" translate="yes" xml:space="preserve">
          <source>The value of such a flag is a list that contains the individual values from all the appearances of that flag on the command-line.</source>
          <target state="translated">이러한 플래그의 값은 명령 행에서 해당 플래그의 모든 모양의 개별 값을 포함하는 목록입니다.</target>
        </trans-unit>
        <trans-unit id="a54451b41292d69deaf5cd8ce0771065680d134d" translate="yes" xml:space="preserve">
          <source>The value of the attr, as a Python object.</source>
          <target state="translated">Python 객체 인 attr의 값입니다.</target>
        </trans-unit>
        <trans-unit id="6e7716dffe6353c157e4a2c3f2e655d155be6b4b" translate="yes" xml:space="preserve">
          <source>The value of the flag is always a list, even if the option was only supplied once, and even if the default value is a single value</source>
          <target state="translated">옵션이 한 번만 제공되고 기본값이 단일 값인 경우에도 플래그 값은 항상 목록입니다.</target>
        </trans-unit>
        <trans-unit id="bf8b3cb3b48dec54fd1680c59ba7cefb3dfc3602" translate="yes" xml:space="preserve">
          <source>The value of the variable after the update.</source>
          <target state="translated">업데이트 후 변수의 값입니다.</target>
        </trans-unit>
        <trans-unit id="d29c684e1056225784225bef1dc61fddd3c411d6" translate="yes" xml:space="preserve">
          <source>The value of this dimension, or None if it is unknown.</source>
          <target state="translated">이 차원의 값이거나 알 수없는 경우 없음입니다.</target>
        </trans-unit>
        <trans-unit id="dc40d49743dfe15cf0fa34edb80ecfa5afa70d65" translate="yes" xml:space="preserve">
          <source>The value or values returned by &lt;code&gt;map_func&lt;/code&gt; determine the structure of each element in the returned dataset.</source>
          <target state="translated">&lt;code&gt;map_func&lt;/code&gt; 에 의해 리턴 된 값 은 리턴 된 데이터 세트에서 각 요소의 구조를 결정합니다.</target>
        </trans-unit>
        <trans-unit id="27a9bdb78e692ccca6e6eeacfe9cf8259c37e6d7" translate="yes" xml:space="preserve">
          <source>The value returned by &lt;code&gt;run()&lt;/code&gt; has the same shape as the &lt;code&gt;fetches&lt;/code&gt; argument, where the leaves are replaced by the corresponding values returned by TensorFlow.</source>
          <target state="translated">&lt;code&gt;run()&lt;/code&gt; 의해 리턴 된 값 은 &lt;code&gt;fetches&lt;/code&gt; 인수 와 동일한 모양을 가지며 , 여기서 리프는 TensorFlow에 의해 리턴 된 해당 값으로 대체됩니다.</target>
        </trans-unit>
        <trans-unit id="6455c45d9b49b1bb8f4ec9b5dff00531b9342ec2" translate="yes" xml:space="preserve">
          <source>The value returned by the &lt;code&gt;activity_regularizer&lt;/code&gt; is divided by the input batch size so that the relative weighting between the weight regularizers and the activity regularizers does not change with the batch size.</source>
          <target state="translated">&lt;code&gt;activity_regularizer&lt;/code&gt; 에 의해 반환 된 값 은 입력 배치 크기로 나뉘어 가중치 정규화 기와 활동 정규화 기 간의 상대적 가중치가 배치 크기에 따라 변경되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="c61a71eb4077cf30110803e381657708b49ae932" translate="yes" xml:space="preserve">
          <source>The values must include 0. There can be no duplicate values or negative values.</source>
          <target state="translated">값은 0을 포함해야합니다. 중복 값이나 음수 값은있을 수 없습니다.</target>
        </trans-unit>
        <trans-unit id="1050986413ba8aa09be08e1ada6c99bfa286c827" translate="yes" xml:space="preserve">
          <source>The values not defined in &lt;code&gt;sp_input&lt;/code&gt; don't participate in the reduce max, as opposed to be implicitly assumed 0 -- hence it can return negative values for sparse &lt;code&gt;axis&lt;/code&gt;. But, in case there are no values in &lt;code&gt;axis&lt;/code&gt;, it will reduce to 0. See second example below.</source>
          <target state="translated">&lt;code&gt;sp_input&lt;/code&gt; 에 정의되지 않은 값 은 암시 적으로 0으로 가정되는 것과 달리 reduce max에 참여하지 않으므로 스파 스 &lt;code&gt;axis&lt;/code&gt; 대해 음수 값을 반환 할 수 있습니다 . 그러나 &lt;code&gt;axis&lt;/code&gt; 에 값이 없으면 0으로 줄어 듭니다. 아래 두 번째 예를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="15f0cbbec41c8cec7a1600faa3fd0ba6c8267aeb" translate="yes" xml:space="preserve">
          <source>The values not defined in &lt;code&gt;sp_input&lt;/code&gt; don't participate in the reduce max, as opposed to be implicitly assumed 0 -- hence it can return negative values for sparse &lt;code&gt;reduction_axes&lt;/code&gt;. But, in case there are no values in &lt;code&gt;reduction_axes&lt;/code&gt;, it will reduce to 0. See second example below.</source>
          <target state="translated">&lt;code&gt;sp_input&lt;/code&gt; 에 정의되지 않은 값 은 암시 적으로 0으로 가정되는 것과 달리 reduce max에 참여하지 않으므로 sparse &lt;code&gt;reduction_axes&lt;/code&gt; 에 대해 음수 값을 반환 할 수 있습니다 . 그러나 &lt;code&gt;reduction_axes&lt;/code&gt; 에 값이 없으면 0으로 줄어 듭니다. 아래 두 번째 예를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="01b28056c2bd0c58a2e89c42fd350d1a9e497580" translate="yes" xml:space="preserve">
          <source>The values of &lt;code&gt;alpha&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt; are chosen so that the mean and variance of the inputs are preserved between two consecutive layers as long as the weights are initialized correctly (see &lt;a href=&quot;../initializers/lecun_normal&quot;&gt;&lt;code&gt;lecun_normal&lt;/code&gt; initialization&lt;/a&gt;) and the number of inputs is &quot;large enough&quot; (see references for more information).</source>
          <target state="translated">&lt;code&gt;alpha&lt;/code&gt; 및 &lt;code&gt;scale&lt;/code&gt; 값은 가중치가 올바르게 초기화되고 ( &lt;a href=&quot;../initializers/lecun_normal&quot;&gt; &lt;code&gt;lecun_normal&lt;/code&gt; 초기화&lt;/a&gt; 참조 ) 입력 수가 &quot;충분히&quot;(입력 참조)하는 한 두 개의 연속 레이어간에 입력의 평균 및 분산이 유지되도록 선택됩니다. 추가 정보).</target>
        </trans-unit>
        <trans-unit id="340b53ddcc61e1600456fa6a942b3a9db9dcd7f4" translate="yes" xml:space="preserve">
          <source>The variable &lt;code&gt;x&lt;/code&gt; updated.</source>
          <target state="translated">변수 &lt;code&gt;x&lt;/code&gt; 가 업데이트되었습니다.</target>
        </trans-unit>
        <trans-unit id="b58067393f30493e389388e4808eed6d24490c13" translate="yes" xml:space="preserve">
          <source>The variable dtype of this policy, or None if the variable dtype should be inferred from the inputs.</source>
          <target state="translated">이 정책의 변수 dtype 또는 입력에서 변수 dtype을 유추해야하는 경우 None입니다.</target>
        </trans-unit>
        <trans-unit id="bb822034c75bacc81fb53dec6e4b25c54f49ac48" translate="yes" xml:space="preserve">
          <source>The variable dtype of this policy.</source>
          <target state="translated">이 정책의 변수 dtype</target>
        </trans-unit>
        <trans-unit id="cf801794eaaba6ef2f8f7f433ed37a63d7d2327d" translate="yes" xml:space="preserve">
          <source>The variance for Student's T equals</source>
          <target state="translated">스튜던트 T의 분산은</target>
        </trans-unit>
        <trans-unit id="15e91da427b6cf2b2fbc5ac9447fe8b24dd8aa82" translate="yes" xml:space="preserve">
          <source>The width the output tensor is &lt;code&gt;input_depth * block_size&lt;/code&gt;, whereas the height is &lt;code&gt;input_height * block_size&lt;/code&gt;.</source>
          <target state="translated">출력 텐서의 너비는 &lt;code&gt;input_depth * block_size&lt;/code&gt; &lt;code&gt;input_height * block_size&lt;/code&gt; 이고 높이는 input_height * block_size 입니다.</target>
        </trans-unit>
        <trans-unit id="78fda38eef982ddecbfd2142c00746b57a76815b" translate="yes" xml:space="preserve">
          <source>The word index dictionary.</source>
          <target state="translated">단어 색인 사전.</target>
        </trans-unit>
        <trans-unit id="273384d93f6363b2a2a4c34767e0268890f5d5af" translate="yes" xml:space="preserve">
          <source>The wrapped input tensor.</source>
          <target state="translated">랩핑 된 입력 텐서.</target>
        </trans-unit>
        <trans-unit id="e4a82e3bb086ae7e63715facddf72f40e0765006" translate="yes" xml:space="preserve">
          <source>The wrapped output tensor.</source>
          <target state="translated">랩핑 된 출력 텐서.</target>
        </trans-unit>
        <trans-unit id="52457270e7a01e13ee00378b3108ea8fc12315e0" translate="yes" xml:space="preserve">
          <source>The wrapped value.</source>
          <target state="translated">랩핑 된 값.</target>
        </trans-unit>
        <trans-unit id="0c29d607aec40364caa8044d1b086cb311bf2d17" translate="yes" xml:space="preserve">
          <source>Theano-like behavior example</source>
          <target state="translated">테 아노 같은 행동 예제</target>
        </trans-unit>
        <trans-unit id="d073abde2a1df4b5c62a21448d955ee1c50a80df" translate="yes" xml:space="preserve">
          <source>Then the output is a dictionary:</source>
          <target state="translated">그런 다음 출력은 사전입니다.</target>
        </trans-unit>
        <trans-unit id="f77a2ae4d69da67530e4f97b9e84f16f29f79cdf" translate="yes" xml:space="preserve">
          <source>Then,</source>
          <target state="translated">Then,</target>
        </trans-unit>
        <trans-unit id="18c6dda9e31a83fdb5a90169c27005c658e8056f" translate="yes" xml:space="preserve">
          <source>Then, row_pooling_sequence should satisfy:</source>
          <target state="translated">그런 다음 row_pooling_sequence는 다음을 충족해야합니다.</target>
        </trans-unit>
        <trans-unit id="3debd4416d24691c45dc01b19b3489468194d8c2" translate="yes" xml:space="preserve">
          <source>There are a number of questions to ask in the decision process, including:</source>
          <target state="translated">의사 결정 과정에서 다음과 같은 여러 가지 질문이 있습니다.</target>
        </trans-unit>
        <trans-unit id="372d16d9e0a1868251f75c59e5f513839dddd179" translate="yes" xml:space="preserve">
          <source>There are many different ways to implement atrous convolution (see the refs above). The implementation here reduces</source>
          <target state="translated">거친 컨볼 루션을 구현하는 방법에는 여러 가지가 있습니다 (위 참조 참조). 여기서 구현은 줄입니다.</target>
        </trans-unit>
        <trans-unit id="4b4c86e082be3a02799da3aa4833e74149042874" translate="yes" xml:space="preserve">
          <source>There are nodes like Identity and CheckNumerics that are only useful during training, and can be removed in graphs that will be used for nothing but inference. Here we identify and remove them, returning an equivalent graph. To be specific, CheckNumerics nodes are always removed, and Identity nodes that aren't involved in control edges are spliced out so that their input and outputs are directly connected.</source>
          <target state="translated">Identity 및 CheckNumerics와 같은 노드는 훈련 중에 만 유용하며 추론에만 사용되는 그래프에서 제거 할 수 있습니다. 여기서 우리는 그것들을 식별하고 제거하여 동등한 그래프를 반환합니다. 구체적으로 CheckNumerics 노드는 항상 제거되고 제어 에지에 포함되지 않은 Identity 노드는 연결되어 입력과 출력이 직접 연결됩니다.</target>
        </trans-unit>
        <trans-unit id="a4fe5597954ba439b4679d614be0e1e5164b606b" translate="yes" xml:space="preserve">
          <source>There are several delicate issues when running multiple threads that way: closing the queues in sequence as the input is exhausted, correctly catching and reporting exceptions, etc.</source>
          <target state="translated">여러 스레드를 실행하는 경우 몇 가지 섬세한 문제가 있습니다. 입력이 소진 될 때 순서대로 큐를 닫고, 예외를 정확하게 포착하고보고하는 등입니다.</target>
        </trans-unit>
        <trans-unit id="20bc80fe9d0b075a12bc0575d2ba4a5d5fe1269d" translate="yes" xml:space="preserve">
          <source>There are several ways to run the conversion:</source>
          <target state="translated">변환을 실행하는 방법에는 여러 가지가 있습니다.</target>
        </trans-unit>
        <trans-unit id="9a0c34e11b24dd273612b5e842b9ca3db6c2dc5f" translate="yes" xml:space="preserve">
          <source>There are three important concepts associated with TensorFlow Distributions shapes:</source>
          <target state="translated">TensorFlow Distributions 모양과 관련된 세 가지 중요한 개념이 있습니다.</target>
        </trans-unit>
        <trans-unit id="3536015a851856ea989836d31de530e9b064da8c" translate="yes" xml:space="preserve">
          <source>There are two means to control the logging verbosity:</source>
          <target state="translated">로깅 세부 정보를 제어하는 ​​두 가지 방법이 있습니다.</target>
        </trans-unit>
        <trans-unit id="cfe77a90ab442852a7e0e410775f1f4aa154097a" translate="yes" xml:space="preserve">
          <source>There are two possible return values, &quot;google&quot; (when TensorFlow is running in a Google-internal environment) or an empty string (when TensorFlow is running elsewhere).</source>
          <target state="translated">&quot;google&quot;(TensorFlow가 Google 내부 환경에서 실행될 때) 또는 빈 문자열 (TensorFlow가 다른 곳에서 실행될 때)의 두 가지 반환 값이 있습니다.</target>
        </trans-unit>
        <trans-unit id="c121ae8dd46f0cedd4d9939e53220e70d1795c85" translate="yes" xml:space="preserve">
          <source>There are two questions to ask in the decision process: Do you need gradients computed as sparse too? Is your sparse data represented as two &lt;code&gt;SparseTensor&lt;/code&gt;s: ids and values? There is more explanation about data format below. If you answer any of these questions as yes, consider using &lt;a href=&quot;../nn/embedding_lookup_sparse&quot;&gt;&lt;code&gt;tf.nn.embedding_lookup_sparse&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">의사 결정 과정에서 두 가지 질문이 있습니다. 희소로 계산 된 그래디언트가 필요합니까? 희소 데이터가 두 개의 &lt;code&gt;SparseTensor&lt;/code&gt; 로 표시 됩니까? id와 값입니까? 아래에 데이터 형식에 대한 자세한 설명이 있습니다. 이 질문에 예라고 대답하면 &lt;a href=&quot;../nn/embedding_lookup_sparse&quot;&gt; &lt;code&gt;tf.nn.embedding_lookup_sparse&lt;/code&gt; &lt;/a&gt; 사용을 고려 하십시오 .</target>
        </trans-unit>
        <trans-unit id="0878716bd35f31f600ff16927cc66d2e1bdcca8d" translate="yes" xml:space="preserve">
          <source>There are two variants of the GRU implementation. The default one is based on &lt;a href=&quot;https://arxiv.org/abs/1406.1078v3&quot;&gt;v3&lt;/a&gt; and has reset gate applied to hidden state before matrix multiplication. The other one is based on &lt;a href=&quot;https://arxiv.org/abs/1406.1078v1&quot;&gt;original&lt;/a&gt; and has the order reversed.</source>
          <target state="translated">GRU 구현에는 두 가지 변형이 있습니다. 기본 값은 &lt;a href=&quot;https://arxiv.org/abs/1406.1078v3&quot;&gt;v3을&lt;/a&gt; 기반으로 하며 행렬 곱하기 전에 숨겨진 상태에 재설정 게이트가 적용됩니다. 다른 하나는 &lt;a href=&quot;https://arxiv.org/abs/1406.1078v1&quot;&gt;원본을&lt;/a&gt; 기반으로 하며 순서가 반대입니다.</target>
        </trans-unit>
        <trans-unit id="f3d0da97f844d09b6bac8339000119f443c41934" translate="yes" xml:space="preserve">
          <source>There are two variants. The default one is based on 1406.1078v3 and has reset gate applied to hidden state before matrix multiplication. The other one is based on original 1406.1078v1 and has the order reversed.</source>
          <target state="translated">두 가지 변형이 있습니다. 기본 값은 1406.1078v3을 기반으로하며 행렬 곱하기 전에 숨겨진 상태에 적용된 게이트 재설정을 가지고 있습니다. 다른 하나는 원본 1406.1078v1을 기반으로하며 순서가 반대입니다.</target>
        </trans-unit>
        <trans-unit id="19c11322b50f362088a37650ccaf3b2e479b115a" translate="yes" xml:space="preserve">
          <source>There are two versions of the API: ExportSavedModelApiVersion.V1 and V2.</source>
          <target state="translated">API에는 ExportSavedModelApiVersion.V1과 V2의 두 가지 버전이 있습니다.</target>
        </trans-unit>
        <trans-unit id="c409af06e5c37c31d5d6e63ae53409968bb739b2" translate="yes" xml:space="preserve">
          <source>There are two ways to create decorators that TensorFlow can introspect into. This is important for documentation generation purposes, so that function signatures aren't obscured by the (*args, **kwds) signature that decorators often provide.</source>
          <target state="translated">TensorFlow가 조사 할 수있는 데코레이터를 만드는 방법에는 두 가지가 있습니다. 이것은 문서 생성 목적에 중요하므로, 데코레이터가 종종 제공하는 (* args, ** kwds) 서명으로 함수 서명이 가려지지 않습니다.</target>
        </trans-unit>
        <trans-unit id="49196c8dfb0588201d8b9733a14917623170a741" translate="yes" xml:space="preserve">
          <source>There are two ways to instantiate a &lt;code&gt;Model&lt;/code&gt;:</source>
          <target state="translated">&lt;code&gt;Model&lt;/code&gt; 을 인스턴스화하는 방법에는 두 가지가 있습니다 .</target>
        </trans-unit>
        <trans-unit id="a3e498654dcff830e5be467e55fbbbbc20e2910f" translate="yes" xml:space="preserve">
          <source>There are two ways to use the moving averages for evaluations:</source>
          <target state="translated">평가에 이동 평균을 사용하는 두 가지 방법이 있습니다.</target>
        </trans-unit>
        <trans-unit id="14b50269ad70f1441184d03f5b9e983ae0e09462" translate="yes" xml:space="preserve">
          <source>There is a special node with &lt;code&gt;task_type&lt;/code&gt; as &lt;code&gt;evaluator&lt;/code&gt;, which is not part of the (training) &lt;code&gt;cluster_spec&lt;/code&gt;. It handles the distributed evaluation job.</source>
          <target state="translated">(훈련) &lt;code&gt;cluster_spec&lt;/code&gt; 의 일부가 아닌 &lt;code&gt;evaluator&lt;/code&gt; 로 &lt;code&gt;task_type&lt;/code&gt; 을 가진 특수 노드가 있습니다. 분산 평가 작업을 처리합니다.</target>
        </trans-unit>
        <trans-unit id="c0a273890eb3544a6c0002e05e862f10bbfd245d" translate="yes" xml:space="preserve">
          <source>There is an equivalent description in terms of the [batch] spectrum &lt;code&gt;H&lt;/code&gt; and Fourier transforms. Here we consider &lt;code&gt;A.shape = [N, N]&lt;/code&gt; and ignore batch dimensions.</source>
          <target state="translated">[배치] 스펙트럼 &lt;code&gt;H&lt;/code&gt; 및 푸리에 변환과 관련하여 동등한 설명이 있습니다 . 여기서는 &lt;code&gt;A.shape = [N, N]&lt;/code&gt; 을 고려 하고 배치 차원을 무시합니다.</target>
        </trans-unit>
        <trans-unit id="34b53209d83711d378deaa8b481a2f90355eb0e3" translate="yes" xml:space="preserve">
          <source>There is an equivalent description in terms of the [batch] spectrum &lt;code&gt;H&lt;/code&gt; and Fourier transforms. Here we consider &lt;code&gt;A.shape = [N, N]&lt;/code&gt; and ignore batch dimensions. Define the discrete Fourier transform (DFT) and its inverse by</source>
          <target state="translated">[배치] 스펙트럼 &lt;code&gt;H&lt;/code&gt; 및 푸리에 변환과 관련하여 동등한 설명이 있습니다 . 여기서는 &lt;code&gt;A.shape = [N, N]&lt;/code&gt; 을 고려 하고 배치 차원을 무시합니다. 이산 푸리에 변환 (DFT)과 그 역을</target>
        </trans-unit>
        <trans-unit id="70db84bf8987013d7aeb820bf2eec70af7a073ca" translate="yes" xml:space="preserve">
          <source>There is no need to delete the directory after the test.</source>
          <target state="translated">테스트 후 디렉토리를 삭제할 필요가 없습니다.</target>
        </trans-unit>
        <trans-unit id="b246461630b3c81ed498d37ca7dc4b93263133aa" translate="yes" xml:space="preserve">
          <source>There is often a need to lift variable initialization ops out of control-flow scopes, function-building graphs, and gradient tapes. Entering an &lt;code&gt;init_scope&lt;/code&gt; is a mechanism for satisfying these desiderata. In particular, entering an &lt;code&gt;init_scope&lt;/code&gt; has three effects:</source>
          <target state="translated">제어 흐름 범위, 함수 작성 그래프 및 그래디언트 테이프에서 변수 초기화 작업을 해제해야하는 경우가 종종 있습니다. &lt;code&gt;init_scope&lt;/code&gt; 를 입력하는 것은 이러한 desiderata를 만족시키기위한 메커니즘입니다. 특히 &lt;code&gt;init_scope&lt;/code&gt; 를 입력하면 세 가지 효과가 있습니다.</target>
        </trans-unit>
        <trans-unit id="9600bed3adf3351d3b6785f43a000c7d51f5ddee" translate="yes" xml:space="preserve">
          <source>There is one exception: if the final (i.e., innermost) element(s) of &lt;code&gt;partitions&lt;/code&gt; are &lt;code&gt;UniformRowLength&lt;/code&gt;s, then the values are simply reshaped (as a higher-dimensional &lt;a href=&quot;../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt;), rather than being wrapped in a &lt;a href=&quot;../raggedtensor&quot;&gt;&lt;code&gt;tf.RaggedTensor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;partitions&lt;/code&gt; 의 마지막 (즉, 가장 안쪽) 요소 가 &lt;code&gt;UniformRowLength&lt;/code&gt; 이면 예외 는 tf.RaggedTensor로 감싸지 않고 단순히 더 높은 차원의 &lt;a href=&quot;../tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; 로 모양 이 &lt;a href=&quot;../raggedtensor&quot;&gt; &lt;code&gt;tf.RaggedTensor&lt;/code&gt; &lt;/a&gt; 됩니다.</target>
        </trans-unit>
        <trans-unit id="69f7128e30301479f7dbfc0ac8f483f3d6d00a4d" translate="yes" xml:space="preserve">
          <source>Therefore we introduce some decoupling using a queue. The queue contains the work units and the Reader dequeues from the queue when it is asked to produce a record (via Read()) but it has finished the last work unit.</source>
          <target state="translated">따라서 큐를 사용하여 몇 가지 디커플링을 소개합니다. 대기열에는 작업 단위가 포함되며 Reader는 읽기 ()를 통해 레코드를 생성하라는 요청을 받으면 대기열에서 대기열에서 제외하지만 마지막 작업 단위를 완료했습니다.</target>
        </trans-unit>
        <trans-unit id="86cd25893d67c9049a975fb7c203728b1fcc6c8b" translate="yes" xml:space="preserve">
          <source>These are arguments passed to the optimizer subclass constructor (the &lt;code&gt;__init__&lt;/code&gt; method), and then passed to &lt;code&gt;self._set_hyper()&lt;/code&gt;. They can be either regular Python values (like 1.0), tensors, or callables. If they are callable, the callable will be called during &lt;code&gt;apply_gradients()&lt;/code&gt; to get the value for the hyper parameter.</source>
          <target state="translated">이들은 옵티 마이저 서브 클래스 생성자 ( &lt;code&gt;__init__&lt;/code&gt; 메소드)에 전달 된 다음 &lt;code&gt;self._set_hyper()&lt;/code&gt; 전달되는 인수 입니다. 정규 Python 값 (예 : 1.0), 텐서 또는 호출 가능일 수 있습니다. 호출 가능하면 &lt;code&gt;apply_gradients()&lt;/code&gt; 중에 호출 가능 매개 변수 가 호출 되어 하이퍼 매개 변수의 값을 가져옵니다.</target>
        </trans-unit>
        <trans-unit id="d1eefae8eebd09f04dd361373c7c577f0cf1144d" translate="yes" xml:space="preserve">
          <source>These conversion options are experimental. They are subject to change without notice and offer no guarantees.</source>
          <target state="translated">이러한 전환 옵션은 실험적입니다. 사전 통지없이 변경 될 수 있으며 보장 할 수 없습니다.</target>
        </trans-unit>
        <trans-unit id="c291964ed47da0b87e8a53387f07ca95b28e890c" translate="yes" xml:space="preserve">
          <source>These indices specify where the values for each row begin in &lt;code&gt;self.values&lt;/code&gt;. &lt;code&gt;rt.row_starts()&lt;/code&gt; is equal to &lt;code&gt;rt.row_splits[:-1]&lt;/code&gt;.</source>
          <target state="translated">이 색인은 각 행의 값이 &lt;code&gt;self.values&lt;/code&gt; 로 시작하는 위치를 지정합니다 . &lt;code&gt;rt.row_starts()&lt;/code&gt; 는 &lt;code&gt;rt.row_splits[:-1]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="99b0058dc30c77b214aebabddab907af2da4a216" translate="yes" xml:space="preserve">
          <source>These indices specify where the values for each row end in &lt;code&gt;self.values&lt;/code&gt;. &lt;code&gt;rt.row_limits(self)&lt;/code&gt; is equal to &lt;code&gt;rt.row_splits[:-1]&lt;/code&gt;.</source>
          <target state="translated">이 색인은 각 행의 값이 &lt;code&gt;self.values&lt;/code&gt; 로 끝나는 위치를 지정 합니다. &lt;code&gt;rt.row_limits(self)&lt;/code&gt; 는 &lt;code&gt;rt.row_splits[:-1]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="23fdcaa94183d818b1595f88d3e5484cc7528a37" translate="yes" xml:space="preserve">
          <source>These layers expose 3 keyword arguments:</source>
          <target state="translated">이 레이어는 3 개의 키워드 인수를 노출합니다.</target>
        </trans-unit>
        <trans-unit id="76c2c66d43654cd0b29da8b2ca646058c82ed16b" translate="yes" xml:space="preserve">
          <source>These might be stored sparsely in the following Example protos by storing only the feature ids (column number if the vectors are treated as a matrix) of the non-zero elements and the corresponding values:</source>
          <target state="translated">이들은 0이 아닌 요소의 특징 ID (벡터가 행렬로 처리되는 경우 열 번호)와 해당 값만 저장하여 다음 예제 프로토스에 드물게 저장 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="df0616278e0670c1f8a838c05616c2906a5ad628" translate="yes" xml:space="preserve">
          <source>These sufficient statistics are computed using the one pass algorithm on an input that's optionally shifted. See: https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Computing_shifted_data</source>
          <target state="translated">이러한 충분한 통계는 선택적으로 이동 된 입력에서 원 패스 알고리즘을 사용하여 계산됩니다. 참조 : https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Computing_shifted_data</target>
        </trans-unit>
        <trans-unit id="5c983cdacd0a0593413a5e4ab438ec1b6414a3f5" translate="yes" xml:space="preserve">
          <source>These typically correspond to model heads.</source>
          <target state="translated">이들은 일반적으로 모델 헤드에 해당합니다.</target>
        </trans-unit>
        <trans-unit id="a2e13849b656ad081d144e8fb21e76af2be31973" translate="yes" xml:space="preserve">
          <source>These values are similar to values from a &lt;code&gt;random_normal_initializer&lt;/code&gt; except that values more than two standard deviations from the mean are discarded and re-drawn. This is the recommended initializer for neural network weights and filters.</source>
          <target state="translated">이 값은 평균과의 표준 편차가 둘 이상인 값을 버리고 다시 그린다는 점을 제외하고 &lt;code&gt;random_normal_initializer&lt;/code&gt; 의 값과 비슷합니다 . 신경망 가중치 및 필터에 권장되는 초기화 프로그램입니다.</target>
        </trans-unit>
        <trans-unit id="035fa9e40dd64ae60fe7c5634de4cc5ea73a82db" translate="yes" xml:space="preserve">
          <source>This &lt;code&gt;LinearOperator&lt;/code&gt; is initialized to have shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; by providing &lt;code&gt;spectrum&lt;/code&gt;, a &lt;code&gt;[B1,...,Bb, N0, N1, N2]&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; with &lt;code&gt;N0*N1*N2 = N&lt;/code&gt;.</source>
          <target state="translated">이 &lt;code&gt;LinearOperator&lt;/code&gt; 는 &lt;code&gt;N0*N1*N2 = N&lt;/code&gt; &lt;code&gt;spectrum&lt;/code&gt; , &lt;code&gt;[B1,...,Bb, N0, N1, N2]&lt;/code&gt; &lt;code&gt;Tensor&lt;/code&gt; 를 제공하여 모양 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 으로 초기화됩니다 .</target>
        </trans-unit>
        <trans-unit id="7dc76893f409505eb4af8e3ca9d9b50f0907d32c" translate="yes" xml:space="preserve">
          <source>This &lt;code&gt;LinearOperator&lt;/code&gt; is initialized to have shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; by providing &lt;code&gt;spectrum&lt;/code&gt;, a &lt;code&gt;[B1,...,Bb, N0, N1]&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; with &lt;code&gt;N0*N1 = N&lt;/code&gt;.</source>
          <target state="translated">이 &lt;code&gt;LinearOperator&lt;/code&gt; 는 형상을 갖도록 초기화된다 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 제공함으로써 &lt;code&gt;spectrum&lt;/code&gt; 하는 &lt;code&gt;[B1,...,Bb, N0, N1]&lt;/code&gt; &lt;code&gt;Tensor&lt;/code&gt; 와 &lt;code&gt;N0*N1 = N&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="45faa2260146699c38e2dafd91d1b8425180a30a" translate="yes" xml:space="preserve">
          <source>This &lt;code&gt;LinearOperator&lt;/code&gt; is initialized to have shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; by providing &lt;code&gt;spectrum&lt;/code&gt;, a &lt;code&gt;[B1,...,Bb, N]&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="translated">이 &lt;code&gt;LinearOperator&lt;/code&gt; 는 형상이 초기화된다 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 제공함으로써 &lt;code&gt;spectrum&lt;/code&gt; 하는 &lt;code&gt;[B1,...,Bb, N]&lt;/code&gt; &lt;code&gt;Tensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="14d38c8190663bcf5aee0e569e1c9fa815f97d9a" translate="yes" xml:space="preserve">
          <source>This &lt;code&gt;LinearOperator&lt;/code&gt; is initialized with boolean flags of the form &lt;code&gt;is_X&lt;/code&gt;, for &lt;code&gt;X = non_singular, self_adjoint, positive_definite, square&lt;/code&gt;. These have the following meaning</source>
          <target state="translated">이 &lt;code&gt;LinearOperator&lt;/code&gt; 는 형태의 부울 플래그로 초기화됩니다 &lt;code&gt;is_X&lt;/code&gt; 를 들어, &lt;code&gt;X = non_singular, self_adjoint, positive_definite, square&lt;/code&gt; . 이들은 다음과 같은 의미가 있습니다</target>
        </trans-unit>
        <trans-unit id="59e2aeacdf121218eb0206f7223d277271e20ff4" translate="yes" xml:space="preserve">
          <source>This &lt;code&gt;LinearOperator&lt;/code&gt; is initialized with boolean flags of the form &lt;code&gt;is_X&lt;/code&gt;, for &lt;code&gt;X = non_singular, self_adjoint, positive_definite, square&lt;/code&gt;. These have the following meaning:</source>
          <target state="translated">이 &lt;code&gt;LinearOperator&lt;/code&gt; 는 형태의 부울 플래그로 초기화됩니다 &lt;code&gt;is_X&lt;/code&gt; 를 들어, &lt;code&gt;X = non_singular, self_adjoint, positive_definite, square&lt;/code&gt; . 다음과 같은 의미가 있습니다.</target>
        </trans-unit>
        <trans-unit id="c893a77a5cadc49b62c18f0fba68970cb1dcbaf6" translate="yes" xml:space="preserve">
          <source>This &lt;code&gt;LinearOperator&lt;/code&gt; is initialized with boolean flags of the form &lt;code&gt;is_X&lt;/code&gt;, for &lt;code&gt;X = non_singular&lt;/code&gt;, &lt;code&gt;self_adjoint&lt;/code&gt;, &lt;code&gt;positive_definite&lt;/code&gt;, &lt;code&gt;diag_update_positive&lt;/code&gt; and &lt;code&gt;square&lt;/code&gt;. These have the following meaning:</source>
          <target state="translated">이 &lt;code&gt;LinearOperator&lt;/code&gt; 는 형태의 부울 플래그로 초기화됩니다 &lt;code&gt;is_X&lt;/code&gt; 를 들어, &lt;code&gt;X = non_singular&lt;/code&gt; , &lt;code&gt;self_adjoint&lt;/code&gt; , &lt;code&gt;positive_definite&lt;/code&gt; , &lt;code&gt;diag_update_positive&lt;/code&gt; 및 &lt;code&gt;square&lt;/code&gt; . 다음과 같은 의미가 있습니다.</target>
        </trans-unit>
        <trans-unit id="1af767d14077ff11d4e7fc9b014e22bbf1d448de" translate="yes" xml:space="preserve">
          <source>This &lt;code&gt;Model&lt;/code&gt; has a dependency named &quot;input_transform&quot; on its &lt;code&gt;Dense&lt;/code&gt; layer, which in turn depends on its variables. As a result, saving an instance of &lt;code&gt;Regress&lt;/code&gt; using &lt;a href=&quot;../../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; will also save all the variables created by the &lt;code&gt;Dense&lt;/code&gt; layer.</source>
          <target state="translated">이 &lt;code&gt;Model&lt;/code&gt; 은 &lt;code&gt;Dense&lt;/code&gt; 계층 에 &quot;input_transform&quot;이라는 종속성 이 있으며 변수에 따라 달라집니다. 결과적으로 &lt;code&gt;Regress&lt;/code&gt; 사용하여 &lt;a href=&quot;../../../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; 인스턴스를 저장하면 &lt;code&gt;Dense&lt;/code&gt; 계층에서 생성 된 모든 변수도 저장됩니다 .</target>
        </trans-unit>
        <trans-unit id="6bb0cfce4d3ef61c634cae7fd40aef46d6d26e65" translate="yes" xml:space="preserve">
          <source>This &lt;code&gt;Model&lt;/code&gt; has a dependency named &quot;input_transform&quot; on its &lt;code&gt;Dense&lt;/code&gt; layer, which in turn depends on its variables. As a result, saving an instance of &lt;code&gt;Regress&lt;/code&gt; using &lt;a href=&quot;checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; will also save all the variables created by the &lt;code&gt;Dense&lt;/code&gt; layer.</source>
          <target state="translated">이 &lt;code&gt;Model&lt;/code&gt; 은 &lt;code&gt;Dense&lt;/code&gt; 계층 에 &quot;input_transform&quot;이라는 종속성 이 있으며 변수에 따라 달라집니다. 결과적으로 &lt;code&gt;Regress&lt;/code&gt; 사용하여 &lt;a href=&quot;checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; 인스턴스를 저장하면 &lt;code&gt;Dense&lt;/code&gt; 계층에서 생성 된 모든 변수도 저장됩니다 .</target>
        </trans-unit>
        <trans-unit id="b5871012b5796b5a485fbd2ea90e6e96dc8a6361" translate="yes" xml:space="preserve">
          <source>This API allows querying the physical hardware resources prior to runtime initialization. Thus, giving an opportunity to call any additional configuration APIs. This is in contrast to &lt;a href=&quot;list_logical_devices&quot;&gt;&lt;code&gt;tf.config.list_logical_devices&lt;/code&gt;&lt;/a&gt;, which triggers runtime initialization in order to list the configured devices.</source>
          <target state="translated">이 API를 사용하면 런타임 초기화 전에 실제 하드웨어 리소스를 쿼리 할 수 ​​있습니다. 따라서 추가 구성 API를 호출 할 수 있습니다. 이는 구성된 장치를 나열하기 위해 런타임 초기화를 트리거 하는 &lt;a href=&quot;list_logical_devices&quot;&gt; &lt;code&gt;tf.config.list_logical_devices&lt;/code&gt; &lt;/a&gt; 와 대조됩니다 .</target>
        </trans-unit>
        <trans-unit id="fb9102764cadc1d75fc4b0e80481d3d9ed63d68c" translate="yes" xml:space="preserve">
          <source>This Estimator implements the following variants of the K-means algorithm:</source>
          <target state="translated">이 추정기는 K- 평균 알고리즘의 다음 변형을 구현합니다.</target>
        </trans-unit>
        <trans-unit id="80c1b7fb2eecacd5d699b9ee230de5704ca37c8d" translate="yes" xml:space="preserve">
          <source>This Multinomial distribution is parameterized by &lt;code&gt;probs&lt;/code&gt;, a (batch of) length-&lt;code&gt;K&lt;/code&gt;&lt;code&gt;prob&lt;/code&gt; (probability) vectors (&lt;code&gt;K &amp;gt; 1&lt;/code&gt;) such that &lt;code&gt;tf.reduce_sum(probs, -1) = 1&lt;/code&gt;, and a &lt;code&gt;total_count&lt;/code&gt; number of trials, i.e., the number of trials per draw from the Multinomial. It is defined over a (batch of) length-&lt;code&gt;K&lt;/code&gt; vector &lt;code&gt;counts&lt;/code&gt; such that &lt;code&gt;tf.reduce_sum(counts, -1) = total_count&lt;/code&gt;. The Multinomial is identically the Binomial distribution when &lt;code&gt;K = 2&lt;/code&gt;.</source>
          <target state="translated">이 다항 분포가 매개 변수화되는 &lt;code&gt;probs&lt;/code&gt; A (일괄) 길이 - &lt;code&gt;K&lt;/code&gt; 의 &lt;code&gt;prob&lt;/code&gt; (확률) 벡터 ( &lt;code&gt;K &amp;gt; 1&lt;/code&gt; )이되도록 &lt;code&gt;tf.reduce_sum(probs, -1) = 1&lt;/code&gt; , 및 &lt;code&gt;total_count&lt;/code&gt; , 실험의 수 즉, 다항식에서 뽑기 당 시행 횟수. &lt;code&gt;tf.reduce_sum(counts, -1) = total_count&lt;/code&gt; 가 되도록 ( 일괄) 길이 &lt;code&gt;K&lt;/code&gt; 벡터 &lt;code&gt;counts&lt;/code&gt; 대해 정의 됩니다. &lt;code&gt;K = 2&lt;/code&gt; 때 다항식은 이항 분포 입니다.</target>
        </trans-unit>
        <trans-unit id="d0c42e63acc7dcc7eea605a766b11674d1c53e82" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] != y[i]&lt;/code&gt; holds for every pair of (possibly broadcast) elements of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] != y[i]&lt;/code&gt; 가 &lt;code&gt;x&lt;/code&gt; 및 &lt;code&gt;y&lt;/code&gt; 의 모든 요소 쌍 (방송 가능)을 보유 하는지 확인합니다 . 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="74ec1aa4f8491ea53037a0fc532d4741eb9218bd" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] &amp;gt; 0&lt;/code&gt; holds for every element of &lt;code&gt;x&lt;/code&gt;. If &lt;code&gt;x&lt;/code&gt; is empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] &amp;gt; 0&lt;/code&gt; 이 &lt;code&gt;x&lt;/code&gt; 의 모든 요소를 ​​보유 하는지 확인합니다 . 경우 &lt;code&gt;x&lt;/code&gt; 는 비어,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="64284c5803db04a210d1a9048bfe82459a849a9d" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] &amp;gt; y[i]&lt;/code&gt; holds for every pair of (possibly broadcast) elements of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] &amp;gt; y[i]&lt;/code&gt; 가 &lt;code&gt;x&lt;/code&gt; 및 &lt;code&gt;y&lt;/code&gt; 의 모든 요소 쌍 (방송 가능)을 보유 하는지 확인합니다 . 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="382c384f5bde2874efffdf9480af145ba234b875" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] &amp;gt;= 0&lt;/code&gt; holds for every element of &lt;code&gt;x&lt;/code&gt;. If &lt;code&gt;x&lt;/code&gt; is empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] &amp;gt;= 0&lt;/code&gt; 이 &lt;code&gt;x&lt;/code&gt; 의 모든 요소를 ​​보유 하는지 확인합니다 . 경우 &lt;code&gt;x&lt;/code&gt; 는 비어,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="501dbba0dad9772b46dd6dbe6d32dfc34b3073e4" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] &amp;gt;= y[i]&lt;/code&gt; holds for every pair of (possibly broadcast) elements of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] &amp;gt;= y[i]&lt;/code&gt; 가 &lt;code&gt;x&lt;/code&gt; 및 &lt;code&gt;y&lt;/code&gt; 의 모든 요소 쌍 (방송 가능)을 보유 하는지 확인합니다 . 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="86a98c771b136d5122e127f8b045988c2c9039d5" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] &amp;lt; 0&lt;/code&gt; holds for every element of &lt;code&gt;x&lt;/code&gt;. If &lt;code&gt;x&lt;/code&gt; is empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] &amp;lt; 0&lt;/code&gt; 이 &lt;code&gt;x&lt;/code&gt; 의 모든 요소를 ​​보유 하는지 확인합니다 . 경우 &lt;code&gt;x&lt;/code&gt; 는 비어,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="a26f9f0c29e64714922c2bda7e956bffe84f5c0c" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] &amp;lt; y[i]&lt;/code&gt; holds for every pair of (possibly broadcast) elements of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] &amp;lt; y[i]&lt;/code&gt; 가 &lt;code&gt;x&lt;/code&gt; 및 &lt;code&gt;y&lt;/code&gt; 의 모든 요소 쌍 (방송 가능)을 보유 하는지 확인합니다 . 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="c63795d0aad1b74648e6a4624d3ec74f6c7d4a1e" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] &amp;lt;= 0&lt;/code&gt; holds for every element of &lt;code&gt;x&lt;/code&gt;. If &lt;code&gt;x&lt;/code&gt; is empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] &amp;lt;= 0&lt;/code&gt; 이 &lt;code&gt;x&lt;/code&gt; 의 모든 요소를 ​​보유 하는지 확인합니다 . 경우 &lt;code&gt;x&lt;/code&gt; 는 비어,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="52d38297a91871d25885ecc0eb75b01217f176df" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] &amp;lt;= y[i]&lt;/code&gt; holds for every pair of (possibly broadcast) elements of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] &amp;lt;= y[i]&lt;/code&gt; 가 &lt;code&gt;x&lt;/code&gt; 및 &lt;code&gt;y&lt;/code&gt; 의 모든 요소 쌍 (방송 가능)을 보유 하는지 확인합니다 . 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="a274dbd07debbab7fc4511fde87c45ce7dd5f11a" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] - y[i] &amp;lt; atol + rtol * tf.abs(y[i])&lt;/code&gt; holds for every pair of (possibly broadcast) elements of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] - y[i] &amp;lt; atol + rtol * tf.abs(y[i])&lt;/code&gt; 가 &lt;code&gt;x&lt;/code&gt; 및 &lt;code&gt;y&lt;/code&gt; 의 모든 요소 (브로드 캐스트) 요소에 대해 유지 되는지 확인 합니다. 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="afe67f7444ede4a73d34ba9ae37a78f686f755dd" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] == y[i]&lt;/code&gt; holds for every pair of (possibly broadcast) elements of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] == y[i]&lt;/code&gt; 가 &lt;code&gt;x&lt;/code&gt; 및 &lt;code&gt;y&lt;/code&gt; 의 모든 요소 쌍 (방송 가능)을 보유 하는지 확인합니다 . 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="47fcdf77a806254f145cef6045f72f7418b87096" translate="yes" xml:space="preserve">
          <source>This Op checks that a collection of tensors shape relationships satisfies given constraints.</source>
          <target state="translated">이 Op는 텐서 모음의 관계가 주어진 제약 조건을 충족하는지 확인합니다.</target>
        </trans-unit>
        <trans-unit id="70d8b32973294baa04c2b6c2343f69d0d35b251b" translate="yes" xml:space="preserve">
          <source>This Op checks that the rank of &lt;code&gt;x&lt;/code&gt; is equal to &lt;code&gt;rank&lt;/code&gt;.</source>
          <target state="translated">이 조작 검사의 순위를 &lt;code&gt;x&lt;/code&gt; 동일하다 &lt;code&gt;rank&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="45bf526016d2ed135926c16509b05dd90dd8b920" translate="yes" xml:space="preserve">
          <source>This Op checks that the rank of &lt;code&gt;x&lt;/code&gt; is greater or equal to &lt;code&gt;rank&lt;/code&gt;.</source>
          <target state="translated">이 조작 검사의 순위를 &lt;code&gt;x&lt;/code&gt; 크거나 같은지 &lt;code&gt;rank&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ef8abcb7ef7c82e56e48acf10aee7a915b661e8e" translate="yes" xml:space="preserve">
          <source>This Op checks that the rank of &lt;code&gt;x&lt;/code&gt; is in &lt;code&gt;ranks&lt;/code&gt;.</source>
          <target state="translated">이 Op는 &lt;code&gt;x&lt;/code&gt; 의 순위 가 &lt;code&gt;ranks&lt;/code&gt; 인지 확인 합니다.</target>
        </trans-unit>
        <trans-unit id="1956a13a2a0626040a0d05adca12d21c39b428f4" translate="yes" xml:space="preserve">
          <source>This Op takes a SparseTensor and is the sparse counterpart to &lt;a href=&quot;../../math/reduce_max&quot;&gt;&lt;code&gt;tf.reduce_max()&lt;/code&gt;&lt;/a&gt;. In contrast to SparseReduceSum, this Op returns a SparseTensor.</source>
          <target state="translated">이 Op는 SparseTensor를 사용하며 &lt;a href=&quot;../../math/reduce_max&quot;&gt; &lt;code&gt;tf.reduce_max()&lt;/code&gt; &lt;/a&gt; 대한 스파 스 대응 입니다. SparseReduceSum과 달리이 Op는 SparseTensor를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="21543202b1cccf9199ac85ba0b6367bb37a43438" translate="yes" xml:space="preserve">
          <source>This Op takes a SparseTensor and is the sparse counterpart to &lt;a href=&quot;../../math/reduce_max&quot;&gt;&lt;code&gt;tf.reduce_max()&lt;/code&gt;&lt;/a&gt;. In particular, this Op also returns a dense &lt;code&gt;Tensor&lt;/code&gt; instead of a sparse one.</source>
          <target state="translated">이 Op는 SparseTensor를 사용하며 &lt;a href=&quot;../../math/reduce_max&quot;&gt; &lt;code&gt;tf.reduce_max()&lt;/code&gt; &lt;/a&gt; 대한 스파 스 대응 입니다. 특히,이 Op는 희박한 &lt;code&gt;Tensor&lt;/code&gt; 대신에 조밀 한 텐서 를 반환합니다 .</target>
        </trans-unit>
        <trans-unit id="a92cf7c266fad63ba2ede16d013a7954c0a3ed23" translate="yes" xml:space="preserve">
          <source>This Op takes a SparseTensor and is the sparse counterpart to &lt;a href=&quot;../../math/reduce_sum&quot;&gt;&lt;code&gt;tf.reduce_sum()&lt;/code&gt;&lt;/a&gt;. In contrast to SparseReduceSum, this Op returns a SparseTensor.</source>
          <target state="translated">이 Op는 SparseTensor를 사용하며 &lt;a href=&quot;../../math/reduce_sum&quot;&gt; &lt;code&gt;tf.reduce_sum()&lt;/code&gt; &lt;/a&gt; 대한 스파 스 대응 입니다. SparseReduceSum과 달리이 Op는 SparseTensor를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="eff3316c87e58a0e09844e295d654acad826f230" translate="yes" xml:space="preserve">
          <source>This Op takes a SparseTensor and is the sparse counterpart to &lt;a href=&quot;../../math/reduce_sum&quot;&gt;&lt;code&gt;tf.reduce_sum()&lt;/code&gt;&lt;/a&gt;. In particular, this Op also returns a dense &lt;code&gt;Tensor&lt;/code&gt; instead of a sparse one.</source>
          <target state="translated">이 Op는 SparseTensor를 사용하며 &lt;a href=&quot;../../math/reduce_sum&quot;&gt; &lt;code&gt;tf.reduce_sum()&lt;/code&gt; &lt;/a&gt; 대한 스파 스 대응 입니다. 특히,이 Op는 희박한 &lt;code&gt;Tensor&lt;/code&gt; 대신에 조밀 한 텐서 를 반환합니다 .</target>
        </trans-unit>
        <trans-unit id="7321159b3f380865d8a3ddbbd1ea9288e20a93c6" translate="yes" xml:space="preserve">
          <source>This Op takes a SparseTensor and is the sparse counterpart to &lt;a href=&quot;../math/reduce_max&quot;&gt;&lt;code&gt;tf.reduce_max()&lt;/code&gt;&lt;/a&gt;. In particular, this Op also returns a dense &lt;code&gt;Tensor&lt;/code&gt; if &lt;code&gt;output_is_sparse&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, or a &lt;code&gt;SparseTensor&lt;/code&gt; if &lt;code&gt;output_is_sparse&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">이 Op는 SparseTensor를 사용하며 &lt;a href=&quot;../math/reduce_max&quot;&gt; &lt;code&gt;tf.reduce_max()&lt;/code&gt; &lt;/a&gt; 대한 스파 스 대응 입니다. 특히,이 Op는 &lt;code&gt;output_is_sparse&lt;/code&gt; 가 &lt;code&gt;False&lt;/code&gt; 이면 밀도가 높은 &lt;code&gt;Tensor&lt;/code&gt; 를 , &lt;code&gt;output_is_sparse&lt;/code&gt; 가 &lt;code&gt;True&lt;/code&gt; 이면 SparseTensor를 &lt;code&gt;SparseTensor&lt;/code&gt; 합니다 .</target>
        </trans-unit>
        <trans-unit id="a574e60c745da5b56aeabab5fc189ca97095b4e6" translate="yes" xml:space="preserve">
          <source>This Op takes a SparseTensor and is the sparse counterpart to &lt;a href=&quot;../math/reduce_sum&quot;&gt;&lt;code&gt;tf.reduce_sum()&lt;/code&gt;&lt;/a&gt;. In particular, this Op also returns a dense &lt;code&gt;Tensor&lt;/code&gt; if &lt;code&gt;output_is_sparse&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, or a &lt;code&gt;SparseTensor&lt;/code&gt; if &lt;code&gt;output_is_sparse&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">이 Op는 SparseTensor를 사용하며 &lt;a href=&quot;../math/reduce_sum&quot;&gt; &lt;code&gt;tf.reduce_sum()&lt;/code&gt; &lt;/a&gt; 대한 스파 스 대응 입니다. 특히,이 Op는 &lt;code&gt;output_is_sparse&lt;/code&gt; 가 &lt;code&gt;False&lt;/code&gt; 이면 밀도가 높은 &lt;code&gt;Tensor&lt;/code&gt; 를 , &lt;code&gt;output_is_sparse&lt;/code&gt; 가 &lt;code&gt;True&lt;/code&gt; 이면 SparseTensor를 &lt;code&gt;SparseTensor&lt;/code&gt; 합니다 .</target>
        </trans-unit>
        <trans-unit id="9513360fe89de6564516b0de822250d992516167" translate="yes" xml:space="preserve">
          <source>This adjusts the dynamic range of the gradient evaluation by scaling up the &lt;code&gt;loss&lt;/code&gt; value. The gradient values are then scaled back down by the recipricol of the loss scale. This is useful in reduced precision training where small gradient values would otherwise underflow the representable range.</source>
          <target state="translated">&lt;code&gt;loss&lt;/code&gt; 값 을 확대하여 그래디언트 평가의 동적 범위를 조정합니다 . 그래디언트 값은 손실 스케일의 역수에 따라 축소됩니다. 이것은 작은 기울기 값이 표현 가능한 범위를 넘치게하는 정밀 훈련에 유용합니다.</target>
        </trans-unit>
        <trans-unit id="4742c30308cfd6082fa96c4df5f33b7fbb5afa83" translate="yes" xml:space="preserve">
          <source>This allows communication and coordination when there are multiple calls to the step_fn triggered by a call to &lt;code&gt;strategy.experimental_run_v2(step_fn, ...)&lt;/code&gt;.</source>
          <target state="translated">이는 &lt;code&gt;strategy.experimental_run_v2(step_fn, ...)&lt;/code&gt; 에 대한 호출에 의해 트리거 된 step_fn에 대한 여러 호출이있을 때 통신 및 조정을 허용합니다 .experimental_run_v2 (step_fn, ...) .</target>
        </trans-unit>
        <trans-unit id="6406854276bccf2ce7a8330ff5c67c7e93bc6f24" translate="yes" xml:space="preserve">
          <source>This allows creating a sub-tensor from part of the current contents of a variable. See &lt;a href=&quot;../../tensor#__getitem__&quot;&gt;&lt;code&gt;tf.Tensor.&lt;strong&gt;getitem&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt; for detailed examples of slicing.</source>
          <target state="translated">이를 통해 변수의 현재 내용의 일부에서 하위 텐서를 만들 수 있습니다. &lt;a href=&quot;../../tensor#__getitem__&quot;&gt; &lt;code&gt;tf.Tensor.&lt;strong&gt;getitem&lt;/strong&gt;&lt;/code&gt; &lt;/a&gt; 참조하십시오 . 슬라이스의 자세한 예는 &lt;strong&gt;getitem&lt;/strong&gt; 을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="3f9bd14a03a5b9808d578e330775308ae0518e1f" translate="yes" xml:space="preserve">
          <source>This allows creating a sub-tensor from part of the current contents of a variable. See &lt;a href=&quot;tensor#__getitem__&quot;&gt;&lt;code&gt;tf.Tensor.&lt;strong&gt;getitem&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt; for detailed examples of slicing.</source>
          <target state="translated">이를 통해 변수의 현재 내용의 일부에서 하위 텐서를 만들 수 있습니다. &lt;a href=&quot;tensor#__getitem__&quot;&gt; &lt;code&gt;tf.Tensor.&lt;strong&gt;getitem&lt;/strong&gt;&lt;/code&gt; &lt;/a&gt; 참조하십시오 . 슬라이스의 자세한 예는 &lt;strong&gt;getitem&lt;/strong&gt; 을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="4a0031976f29ed8ed5b38f0545ffe09ca05a84a3" translate="yes" xml:space="preserve">
          <source>This allows reading and writing to this tensors w/o copies. This more closely mirrors the C++ Interpreter class interface's tensor() member, hence the name. Be careful to not hold these output references through calls to &lt;code&gt;allocate_tensors()&lt;/code&gt; and &lt;code&gt;invoke()&lt;/code&gt;. This function cannot be used to read intermediate results.</source>
          <target state="translated">이를 통해 사본없이이 텐서에 읽고 쓸 수 있습니다. 이것은 C ++ 인터프리터 클래스 인터페이스의 tensor () 멤버를 더 밀접하게 반영하므로 이름입니다. assign_tensors &lt;code&gt;allocate_tensors()&lt;/code&gt; 및 &lt;code&gt;invoke()&lt;/code&gt; 호출을 통해 이러한 출력 참조를 보유하지 않도록주의하십시오 . 이 기능은 중간 결과를 읽는 데 사용할 수 없습니다.</target>
        </trans-unit>
        <trans-unit id="aab58add7bb75e6c4119bf13ecc09894979d960d" translate="yes" xml:space="preserve">
          <source>This allows you to save the entirety of the state of a model in a single file.</source>
          <target state="translated">이를 통해 모델 상태 전체를 단일 파일로 저장할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="083c822ae2751294f6b801ab1aec618144643d76" translate="yes" xml:space="preserve">
          <source>This also supports either output striding via the optional &lt;code&gt;strides&lt;/code&gt; parameter or atrous convolution (also known as convolution with holes or dilated convolution, based on the French word &quot;trous&quot; meaning holes in English) via the optional &lt;code&gt;dilation_rate&lt;/code&gt; parameter. Currently, however, output striding is not supported for atrous convolutions.</source>
          <target state="translated">또한 선택적 &lt;code&gt;strides&lt;/code&gt; 매개 변수 를 통한 출력 보폭 또는 선택적 &lt;code&gt;dilation_rate&lt;/code&gt; 매개 변수 를 통해 거친 구 (또는 영어로 구멍을 의미하는 프랑스어 단어 &quot;trous&quot;를 기반으로하는 확장 된 회선으로도 알려져 있음) 또는 거친 컨볼 루션을 지원합니다 . 그러나 현재 출력 보폭은 격렬한 회선에 지원되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="0282c5f56f860d1be334e321248ec8429b6f156d" translate="yes" xml:space="preserve">
          <source>This also supports either output striding via the optional &lt;code&gt;strides&lt;/code&gt; parameter or atrous convolution (also known as convolution with holes or dilated convolution, based on the French word &quot;trous&quot; meaning holes in English) via the optional &lt;code&gt;dilations&lt;/code&gt; parameter. Currently, however, output striding is not supported for atrous convolutions.</source>
          <target state="translated">또한이 옵션을 통해 월쯤 중 출력 지원 &lt;code&gt;strides&lt;/code&gt; 옵션을 통해 (프랑스어 단어 영어로 &quot;trous&quot;를 의미하는 구멍을 기준으로도 구멍이나 팽창 회선과 회선으로 알려진) 매개 변수 또는 atrous 회선 &lt;code&gt;dilations&lt;/code&gt; 매개 변수를. 그러나 현재 출력 보폭은 격렬한 회선에 지원되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="40ecf12ea54cbb9c03cee235c92870bdadc05d0e" translate="yes" xml:space="preserve">
          <source>This assumes the input dictionary contains a &lt;code&gt;SparseTensor&lt;/code&gt; for key 'terms', and a &lt;code&gt;SparseTensor&lt;/code&gt; for key 'frequencies'. These 2 tensors must have the same indices and dense shape.</source>
          <target state="translated">이는 입력 사전 에 키 'terms'에 대한 &lt;code&gt;SparseTensor&lt;/code&gt; 와 키 'frequencies'에 대한 &lt;code&gt;SparseTensor&lt;/code&gt; 가 포함되어 있다고 가정합니다 . 이 2 개의 텐서는 동일한 인덱스와 밀도가 있어야합니다.</target>
        </trans-unit>
        <trans-unit id="ec5e01502dedce9b5506d5284b5d16bed3dce6f8" translate="yes" xml:space="preserve">
          <source>This avoids adding &lt;code&gt;numpy_input&lt;/code&gt; as a large constant in the graph, and copies the data to the machine or machines that will be processing the input.</source>
          <target state="translated">이렇게하면 그래프에서 &lt;code&gt;numpy_input&lt;/code&gt; 을 큰 상수로 추가하지 않고 입력을 처리 할 기계에 데이터를 복사합니다.</target>
        </trans-unit>
        <trans-unit id="542cdf0657b556d7d4f13254bf996896da1af7f2" translate="yes" xml:space="preserve">
          <source>This behaves similarly to &lt;a href=&quot;../../name_scope&quot;&gt;&lt;code&gt;tf.name_scope&lt;/code&gt;&lt;/a&gt;, except that it returns a generated summary tag in addition to the scope name. The tag is structurally similar to the scope name - derived from the user-provided name, prefixed with enclosing name scopes if any - but we relax the constraint that it be uniquified, as well as the character set limitation (so the user-provided name can contain characters not legal for scope names; in the scope name these are removed).</source>
          <target state="translated">이것은 &lt;a href=&quot;../../name_scope&quot;&gt; &lt;code&gt;tf.name_scope&lt;/code&gt; &lt;/a&gt; 와 유사하게 동작 하지만 범위 이름 외에 생성 된 요약 태그를 반환한다는 점이 다릅니다. 이 태그는 범위 이름과 구조적으로 유사합니다 (사용자가 제공 한 이름에서 파생되고 접두어가있는 이름 범위가있는 경우 접두어가 있음). 그러나 문자 집합 제한 (사용자 설정 이름과 같이)으로 제한되어야한다는 제약 조건을 완화합니다. 범위 이름에 유효하지 않은 문자를 포함 할 수 있습니다 (범위 이름에서 제거됨).</target>
        </trans-unit>
        <trans-unit id="5d690c9d397a6da08fd08939e695a0fb6ea89e4b" translate="yes" xml:space="preserve">
          <source>This behavior gives control to callers on what to do if checkpoints do not come fast enough or stop being generated. For example, if callers have a way to detect that the training has stopped and know that no new checkpoints will be generated, they can provide a &lt;code&gt;timeout_fn&lt;/code&gt; that returns &lt;code&gt;True&lt;/code&gt; when the training has stopped. If they know that the training is still going on they return &lt;code&gt;False&lt;/code&gt; instead.</source>
          <target state="translated">이 동작은 체크 포인트가 충분히 빠르지 않거나 생성이 중지 될 경우 수행 할 작업을 호출자에게 제어합니다. 예를 들어, 호출자가 훈련이 중지되었음을 감지하고 새로운 검사 점이 생성되지 않음을 알 수있는 경우 훈련이 중지되면 &lt;code&gt;True&lt;/code&gt; 를 반환 하는 &lt;code&gt;timeout_fn&lt;/code&gt; 을 제공 할 수 있습니다 . 교육이 계속 진행되고 있음을 알고 있으면 대신 &lt;code&gt;False&lt;/code&gt; 를 반환 합니다.</target>
        </trans-unit>
        <trans-unit id="5d87911d57456c793352550a56288318dbdc2112" translate="yes" xml:space="preserve">
          <source>This behavior has been introduced in TensorFlow 2.0, in order to enable &lt;code&gt;layer.trainable = False&lt;/code&gt; to produce the most commonly expected behavior in the convnet fine-tuning use case.</source>
          <target state="translated">convnet 미세 조정 사용 사례에서 가장 일반적으로 예상되는 동작을 생성하기 위해 &lt;code&gt;layer.trainable = False&lt;/code&gt; 를 활성화하기 위해이 동작이 TensorFlow 2.0에 도입되었습니다 .</target>
        </trans-unit>
        <trans-unit id="566da943133ad9f7ff89e0ae58ccee97f0942cd9" translate="yes" xml:space="preserve">
          <source>This behavior only occurs as of TensorFlow 2.0. In 1.*, setting &lt;code&gt;layer.trainable = False&lt;/code&gt; would freeze the layer but would not switch it to inference mode.</source>
          <target state="translated">이 동작은 TensorFlow 2.0에서만 발생합니다. 1. *에서 &lt;code&gt;layer.trainable = False&lt;/code&gt; 설정 하면 레이어가 고정되지만 추론 모드로 전환하지는 않습니다.</target>
        </trans-unit>
        <trans-unit id="947e43a536a4f632b306b7d5c3e4805a08d13eec" translate="yes" xml:space="preserve">
          <source>This blocks the calling thread until the thread whose join() method is called terminates -- either normally or through an unhandled exception or until the optional timeout occurs.</source>
          <target state="translated">이것은 join () 메소드가 호출 된 스레드가 정상적으로 또는 처리되지 않은 예외를 통해 종료되거나 선택적 시간 종료가 발생할 때까지 호출 스레드를 차단합니다.</target>
        </trans-unit>
        <trans-unit id="f576e406288a87f269b5d6306d3d486ac32d4798" translate="yes" xml:space="preserve">
          <source>This boolean flag determines whether variables should be initialized as they are instantiated (default), or if the user should handle the initialization (e.g. via &lt;a href=&quot;../../compat/v1/initialize_all_variables&quot;&gt;&lt;code&gt;tf.compat.v1.initialize_all_variables()&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">이 부울 플래그는 변수를 인스턴스화 할 때 초기화해야하는지 (기본값) 또는 사용자가 초기화를 처리 &lt;a href=&quot;../../compat/v1/initialize_all_variables&quot;&gt; &lt;code&gt;tf.compat.v1.initialize_all_variables()&lt;/code&gt; &lt;/a&gt; 예 : tf.compat.v1.initialize_all_variables () 를 통해 ) 결정합니다.</target>
        </trans-unit>
        <trans-unit id="0d320c46f5814a56c1f3f60058177b848b6fe981" translate="yes" xml:space="preserve">
          <source>This call blocks until a set of threads have terminated. The set of thread is the union of the threads passed in the &lt;code&gt;threads&lt;/code&gt; argument and the list of threads that registered with the coordinator by calling &lt;a href=&quot;coordinator#register_thread&quot;&gt;&lt;code&gt;Coordinator.register_thread()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">이 호출은 일련의 스레드가 종료 될 때까지 차단됩니다. 스레드 세트는 &lt;code&gt;threads&lt;/code&gt; 인수에 전달 된 스레드 와 &lt;a href=&quot;coordinator#register_thread&quot;&gt; &lt;code&gt;Coordinator.register_thread()&lt;/code&gt; &lt;/a&gt; 를 호출하여 코디네이터에 등록 된 스레드 목록의 결합 입니다.</target>
        </trans-unit>
        <trans-unit id="51c54c7d5726811d44822079b16e485771669c24" translate="yes" xml:space="preserve">
          <source>This call is ignored when eager execution is enabled (in that case, variable updates are run on the fly and thus do not need to be tracked for later execution).</source>
          <target state="translated">열망하는 실행이 활성화되면이 호출이 무시됩니다 (이 경우 변수 업데이트가 즉시 실행되므로 나중에 실행하기 위해 추적 할 필요가 없습니다).</target>
        </trans-unit>
        <trans-unit id="062df39159f4972c7eb0c0bbc3c621a80385af7d" translate="yes" xml:space="preserve">
          <source>This callback is automatically applied to every Keras model.</source>
          <target state="translated">이 콜백은 모든 Keras 모델에 자동으로 적용됩니다.</target>
        </trans-unit>
        <trans-unit id="4a2209138c3b99588918296a296e9d5cba348ee9" translate="yes" xml:space="preserve">
          <source>This callback is automatically applied to every Keras model. The &lt;code&gt;History&lt;/code&gt; object gets returned by the &lt;code&gt;fit&lt;/code&gt; method of models.</source>
          <target state="translated">이 콜백은 모든 Keras 모델에 자동으로 적용됩니다. &lt;code&gt;History&lt;/code&gt; 객체에 의해 반환됩니다 &lt;code&gt;fit&lt;/code&gt; 모델의 방법.</target>
        </trans-unit>
        <trans-unit id="9a8fccab0666eafd61c1fb78dee506da35fb92ce" translate="yes" xml:space="preserve">
          <source>This callback is constructed with anonymous functions that will be called at the appropriate time. Note that the callbacks expects positional arguments, as:</source>
          <target state="translated">이 콜백은 적절한 시간에 호출되는 익명 함수로 구성됩니다. 콜백에는 다음과 같은 위치 인수가 필요합니다.</target>
        </trans-unit>
        <trans-unit id="d2fd53cd69211c630c172b830b110ef6741f78e7" translate="yes" xml:space="preserve">
          <source>This callback logs events for TensorBoard, including:</source>
          <target state="translated">이 콜백은 다음을 포함하여 TensorBoard에 대한 이벤트를 기록합니다.</target>
        </trans-unit>
        <trans-unit id="6c4d9ff06bd1c217d75cb9a57ebc28626f964add" translate="yes" xml:space="preserve">
          <source>This can always be checked statically, so this method returns nothing.</source>
          <target state="translated">항상 정적으로 확인할 수 있으므로이 메소드는 아무 것도 반환하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="6f195f030f5d6a3952c927a303c10a3d51f131c5" translate="yes" xml:space="preserve">
          <source>This can be faster than multiple individual &lt;code&gt;reduce&lt;/code&gt;s because we can fuse several tensors into one or multiple packs before reduction.</source>
          <target state="translated">이 빠른 개별 다중보다이 될 수 &lt;code&gt;reduce&lt;/code&gt; 우리가 감소하기 전에 하나 개 또는 여러 개의 팩으로 여러 텐서를 융합 할 수 있기 때문에들.</target>
        </trans-unit>
        <trans-unit id="f4c1e8ee1a694edb65fdf5329eae65afdec683d9" translate="yes" xml:space="preserve">
          <source>This can be used as a &quot;join&quot; mechanism for parallel computations: all the argument tensors can be computed in parallel, but the values of any tensor returned by &lt;code&gt;tuple&lt;/code&gt; are only available after all the parallel computations are done.</source>
          <target state="translated">이것은 병렬 계산을위한 &quot;결합&quot;메커니즘으로 사용될 수 있습니다. 모든 인수 텐서는 병렬로 계산 될 수 있지만 &lt;code&gt;tuple&lt;/code&gt; 에 의해 반환 된 텐서의 값은 모든 병렬 계산이 완료된 후에 만 ​​사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="66b08400383b183cc1cba0b591ec90b5fe85d73d" translate="yes" xml:space="preserve">
          <source>This can be used as a loss-function during optimization so as to suppress noise in images. If you have a batch of images, then you should calculate the scalar loss-value as the sum: &lt;code&gt;loss = tf.reduce_sum(tf.image.total_variation(images))&lt;/code&gt;</source>
          <target state="translated">이것은 이미지에서 노이즈를 억제하기 위해 최적화 중에 손실 함수로 사용될 수 있습니다. 이미지 배치가있는 경우 스칼라 손실 값을 합으로 계산해야합니다. &lt;code&gt;loss = tf.reduce_sum(tf.image.total_variation(images))&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="ff61da80eb1038583fadf6e588b06357b27a55d8" translate="yes" xml:space="preserve">
          <source>This can be useful for debugging or profiling. For example, let's say you implemented a simple iterative sqrt function, and you want to collect the intermediate values and plot the convergence. Appending the values to a list in &lt;code&gt;@tf.function&lt;/code&gt; normally wouldn't work since it will just record the Tensors being traced, not the values. Instead, you can do the following.</source>
          <target state="translated">디버깅 또는 프로파일 링에 유용 할 수 있습니다. 예를 들어 간단한 반복 sqrt 함수를 구현했으며 중간 값을 수집하고 수렴을 플로팅하려고한다고 가정 해 보겠습니다. &lt;code&gt;@tf.function&lt;/code&gt; 의 목록에 값을 추가하면 값 이 아닌 추적되는 텐서를 기록하기 때문에 일반적으로 작동하지 않습니다. 대신 다음을 수행 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="5bc85a9ecd105989dec28b806afbbe4faa69f248" translate="yes" xml:space="preserve">
          <source>This can be useful if you want to log debug a training algorithm, report stats about the slots, etc.</source>
          <target state="translated">훈련 알고리즘을 디버그 디버그하고 슬롯에 대한 통계를보고하려는 경우에 유용합니다.</target>
        </trans-unit>
        <trans-unit id="de803dd8ed0f3487c59166443a170b97850a2c8d" translate="yes" xml:space="preserve">
          <source>This class allows to vectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary) or into a vector where the coefficient for each token could be binary, based on word count, based on tf-idf...</source>
          <target state="translated">이 클래스를 사용하면 각 텍스트를 정수 시퀀스 (각 정수는 사전의 토큰 색인 임) 또는 단어 수를 기준으로 각 토큰의 계수가 이진일 수있는 벡터로 변환하여 텍스트 코퍼스를 벡터화 할 수 있습니다. tf-idf를 기반으로 ...</target>
        </trans-unit>
        <trans-unit id="c35c7cb7e9df11039724d697524b210395fe269e" translate="yes" xml:space="preserve">
          <source>This class assumes each worker is running the same code independently, but parameter servers are running a standard server. This means that while each worker will synchronously compute a single gradient update across all GPUs, updates between workers proceed asynchronously. Operations that occur only on the first replica (such as incrementing the global step), will occur on the first replica &lt;em&gt;of every worker&lt;/em&gt;.</source>
          <target state="translated">이 클래스는 각 작업자가 동일한 코드를 독립적으로 실행하지만 매개 변수 서버는 표준 서버를 실행한다고 가정합니다. 즉, 각 작업자가 모든 GPU에서 단일 그라디언트 업데이트를 동 기적으로 계산하지만 작업자 간의 업데이트는 비동기 적으로 진행됩니다. 첫 번째 복제본에서만 발생하는 작업 (예 : 전역 단계 증가) &lt;em&gt;은 모든 작업자&lt;/em&gt; 의 첫 번째 복제본 &lt;em&gt;에서&lt;/em&gt; 발생합니다 .</target>
        </trans-unit>
        <trans-unit id="1ea4dadc6d5580b6a9567a54f238c77dab3d0a06" translate="yes" xml:space="preserve">
          <source>This class caches file writers, one per directory.</source>
          <target state="translated">이 클래스는 파일 작성자를 디렉토리 당 하나씩 캐시합니다.</target>
        </trans-unit>
        <trans-unit id="e9243b860278b8d7215f95a8eb101fc7a883ab5b" translate="yes" xml:space="preserve">
          <source>This class can create placeholders for tf.Tensors, tf.SparseTensors, and tf.RaggedTensors by choosing 'sparse=True' or 'ragged=True'.</source>
          <target state="translated">이 클래스는 'sparse = True'또는 'ragged = True'를 선택하여 tf.Tensors, tf.SparseTensors 및 tf.RaggedTensors에 대한 플레이스 홀더를 작성할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="b93eb86d4b8b199ed8de190972226d76d3ddbda5" translate="yes" xml:space="preserve">
          <source>This class defines the API to add Ops to train a model. You never use this class directly, but instead instantiate one of its subclasses such as &lt;a href=&quot;sgd&quot;&gt;&lt;code&gt;tf.keras.optimizers.SGD&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;adam&quot;&gt;&lt;code&gt;tf.keras.optimizers.Adam&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">이 클래스는 모델 학습을 위해 Ops를 추가하는 API를 정의합니다. 이 클래스를 직접 사용하지 말고 대신 &lt;a href=&quot;sgd&quot;&gt; &lt;code&gt;tf.keras.optimizers.SGD&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;adam&quot;&gt; &lt;code&gt;tf.keras.optimizers.Adam&lt;/code&gt; &lt;/a&gt; 과 같은 서브 클래스 중 하나를 인스턴스화 하십시오 .</target>
        </trans-unit>
        <trans-unit id="1921ba1f544676f9bbcb9030a711c397087751d1" translate="yes" xml:space="preserve">
          <source>This class defines the API to add Ops to train a model. You never use this class directly, but instead instantiate one of its subclasses such as &lt;code&gt;GradientDescentOptimizer&lt;/code&gt;, &lt;code&gt;AdagradOptimizer&lt;/code&gt;, or &lt;code&gt;MomentumOptimizer&lt;/code&gt;.</source>
          <target state="translated">이 클래스는 모델 학습을 위해 Ops를 추가하는 API를 정의합니다. 이 클래스를 직접 사용하지 말고 &lt;code&gt;GradientDescentOptimizer&lt;/code&gt; , &lt;code&gt;AdagradOptimizer&lt;/code&gt; 또는 &lt;code&gt;MomentumOptimizer&lt;/code&gt; 와 같은 하위 클래스 중 하나를 인스턴스화하십시오 .</target>
        </trans-unit>
        <trans-unit id="f1b4934ebc6e87e946a8327b096ccaba6f902fbb" translate="yes" xml:space="preserve">
          <source>This class defines the key and value used for tf.lookup.TextFileInitializer.</source>
          <target state="translated">이 클래스는 tf.lookup.TextFileInitializer에 사용되는 키와 값을 정의합니다.</target>
        </trans-unit>
        <trans-unit id="bbef232ee84dd43e03ff0bb31e2fff3d62ddb086" translate="yes" xml:space="preserve">
          <source>This class exports the serving graph and checkpoints at the end.</source>
          <target state="translated">이 클래스는 마지막에 검색 그래프와 검사 점을 내 보냅니다.</target>
        </trans-unit>
        <trans-unit id="2398f265a0682e91ce8fc30c31cc00a32b85cf94" translate="yes" xml:space="preserve">
          <source>This class exports the serving graph and checkpoints of the best models.</source>
          <target state="translated">이 클래스는 최상의 모델의 검색 그래프 및 검사 점을 내 보냅니다.</target>
        </trans-unit>
        <trans-unit id="f378b5fe5691dc39f9cd3d236136a8685104c4fd" translate="yes" xml:space="preserve">
          <source>This class has been deprecated. Please use &lt;a href=&quot;../../../lite/tfliteconverter&quot;&gt;&lt;code&gt;lite.TFLiteConverter&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="translated">이 클래스는 더 이상 사용되지 않습니다. 사용하십시오 &lt;a href=&quot;../../../lite/tfliteconverter&quot;&gt; &lt;code&gt;lite.TFLiteConverter&lt;/code&gt; 을&lt;/a&gt; 대신.</target>
        </trans-unit>
        <trans-unit id="8616741a1ce86b957920807cdf7bdf7cd9ce000e" translate="yes" xml:space="preserve">
          <source>This class has two primary purposes:</source>
          <target state="translated">이 수업에는 두 가지 주요 목적이 있습니다.</target>
        </trans-unit>
        <trans-unit id="e41eb7b59b50f02eb388655630751957c627b643" translate="yes" xml:space="preserve">
          <source>This class implements &lt;code&gt;__enter__&lt;/code&gt; and &lt;code&gt;__exit__&lt;/code&gt;, and can be used in &lt;code&gt;with&lt;/code&gt; blocks like a normal file.</source>
          <target state="translated">이 클래스는 &lt;code&gt;__enter__&lt;/code&gt; 및 &lt;code&gt;__exit__&lt;/code&gt; 을 구현 하며 일반 파일처럼 블록과 &lt;code&gt;with&lt;/code&gt; 사용할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="61d78e6233b72d451051551f631a8d253b9c0d10" translate="yes" xml:space="preserve">
          <source>This class implements a simple mechanism to coordinate the termination of a set of threads.</source>
          <target state="translated">이 클래스는 일련의 스레드 종료를 조정하는 간단한 메커니즘을 구현합니다.</target>
        </trans-unit>
        <trans-unit id="2c453470b9fb7d2dd4c8372805a2c5b45dcafe1a" translate="yes" xml:space="preserve">
          <source>This class in stateful and thread-compatible.</source>
          <target state="translated">이 클래스는 상태 저장 및 스레드 호환이 가능합니다.</target>
        </trans-unit>
        <trans-unit id="b6c71f2399c238428100228254e29a64f6c45e19" translate="yes" xml:space="preserve">
          <source>This class is a simple wrapper for a pair of &lt;code&gt;Tensor&lt;/code&gt; objects:</source>
          <target state="translated">이 클래스는 한 쌍의 &lt;code&gt;Tensor&lt;/code&gt; 객체에 대한 간단한 래퍼입니다 .</target>
        </trans-unit>
        <trans-unit id="aaddfb846b1d90d727149969bb3d79f9de0c7466" translate="yes" xml:space="preserve">
          <source>This class is a small wrapper that takes care of session creation and checkpoint recovery. It also provides functions that to facilitate coordination among multiple training threads or processes.</source>
          <target state="translated">이 클래스는 세션 작성 및 검사 점 복구를 처리하는 작은 래퍼입니다. 또한 여러 교육 스레드 또는 프로세스 간의 조정을 용이하게하는 기능을 제공합니다.</target>
        </trans-unit>
        <trans-unit id="17463f3d93317c6b5e6f0cc508b2a6f39e7358ea" translate="yes" xml:space="preserve">
          <source>This class is deprecated. For synchrononous training, please use &lt;a href=&quot;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute&quot;&gt;Distribution Strategies&lt;/a&gt;.</source>
          <target state="translated">이 클래스는 더 이상 사용되지 않습니다. 동기식 교육의 경우 &lt;a href=&quot;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute&quot;&gt;배포 전략을&lt;/a&gt; 사용하십시오. .</target>
        </trans-unit>
        <trans-unit id="4616d8f2e476585f5e22705937707332b5baeb5b" translate="yes" xml:space="preserve">
          <source>This class is deprecated. Please use &lt;a href=&quot;monitoredtrainingsession&quot;&gt;&lt;code&gt;tf.compat.v1.train.MonitoredTrainingSession&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="translated">이 클래스는 더 이상 사용되지 않습니다. &lt;a href=&quot;monitoredtrainingsession&quot;&gt; &lt;code&gt;tf.compat.v1.train.MonitoredTrainingSession&lt;/code&gt; 을&lt;/a&gt; 사용 하십시오 대신.</target>
        </trans-unit>
        <trans-unit id="42d3bc86be52a8736e6d7aa317815110401307ef" translate="yes" xml:space="preserve">
          <source>This class is heavily overloaded:</source>
          <target state="translated">이 클래스는 과도하게 오버로드되었습니다.</target>
        </trans-unit>
        <trans-unit id="22170de053f3420fc08a96260e613e3fa8486018" translate="yes" xml:space="preserve">
          <source>This class is meant to be used with dynamic iteration primitives such as &lt;code&gt;while_loop&lt;/code&gt; and &lt;code&gt;map_fn&lt;/code&gt;. It supports gradient back-propagation via special &quot;flow&quot; control flow dependencies.</source>
          <target state="translated">이 클래스는 &lt;code&gt;while_loop&lt;/code&gt; 및 &lt;code&gt;map_fn&lt;/code&gt; 과 같은 동적 반복 기본 요소와 함께 사용됩니다 . 특수한 &quot;흐름&quot;제어 흐름 종속성을 통한 그라디언트 역 전파를 지원합니다.</target>
        </trans-unit>
        <trans-unit id="121c6274230c0f7d1b806b54f9d580ba8e2d228a" translate="yes" xml:space="preserve">
          <source>This class merges the output of multiple &lt;code&gt;Head&lt;/code&gt; objects. Specifically:</source>
          <target state="translated">이 클래스는 여러 &lt;code&gt;Head&lt;/code&gt; 의 출력을 병합합니다. 객체 합니다. 구체적으로 특별히:</target>
        </trans-unit>
        <trans-unit id="7cd980fdc04e7da43f8abb3e3be6ffdf25b7685d" translate="yes" xml:space="preserve">
          <source>This class performs a model export everytime the new model is better than any existing model.</source>
          <target state="translated">이 클래스는 새 모델이 기존 모델보다 낫을 때마다 모델 내보내기를 수행합니다.</target>
        </trans-unit>
        <trans-unit id="391aed511e9154256ca236f23d6877cb0f9d37db" translate="yes" xml:space="preserve">
          <source>This class performs a single export at the end of training.</source>
          <target state="translated">이 클래스는 교육이 끝나면 단일 내보내기를 수행합니다.</target>
        </trans-unit>
        <trans-unit id="b83c252083ca3edbed9d1168a0ed9755da22c25f" translate="yes" xml:space="preserve">
          <source>This class performs a union given two or more existing ClusterResolvers. It merges the underlying ClusterResolvers, and returns one unified ClusterSpec when cluster_spec is called. The details of the merge function is documented in the cluster_spec function.</source>
          <target state="translated">이 클래스는 둘 이상의 기존 ClusterResolvers가 제공되는 통합을 수행합니다. 기본 ClusterResolvers를 병합하고 cluster_spec이 호출 될 때 하나의 통합 된 ClusterSpec을 반환합니다. 병합 함수의 세부 사항은 cluster_spec 함수에 문서화되어 있습니다.</target>
        </trans-unit>
        <trans-unit id="631d6a58bb184da4fc166c1a1dbaf36a0e45d9c8" translate="yes" xml:space="preserve">
          <source>This class performs the softmax operation for you, so inputs should be e.g. linear projections of outputs by an LSTM.</source>
          <target state="translated">이 클래스는 softmax 연산을 수행하므로 입력은 LSTM에 의한 출력의 선형 투영이어야합니다.</target>
        </trans-unit>
        <trans-unit id="d2810b13f641fd9987b2ce8b38f939b3369079e3" translate="yes" xml:space="preserve">
          <source>This class processes one step within the whole time sequence input, whereas &lt;code&gt;tf.keras.layer.GRU&lt;/code&gt; processes the whole sequence.</source>
          <target state="translated">이 클래스는 전체 시간 시퀀스 입력 내에서 한 단계를 처리하는 반면 &lt;code&gt;tf.keras.layer.GRU&lt;/code&gt; 는 전체 시퀀스를 처리합니다.</target>
        </trans-unit>
        <trans-unit id="9a1d5a35670a2cc4cfac2401e85535a1c8acffb8" translate="yes" xml:space="preserve">
          <source>This class processes one step within the whole time sequence input, whereas &lt;code&gt;tf.keras.layer.LSTM&lt;/code&gt; processes the whole sequence.</source>
          <target state="translated">이 클래스는 전체 시간 시퀀스 입력 내에서 한 단계를 처리하는 반면 &lt;code&gt;tf.keras.layer.LSTM&lt;/code&gt; 은 전체 시퀀스를 처리합니다.</target>
        </trans-unit>
        <trans-unit id="85aecc3ec7757c0f4286579ce3ab5119031dd197" translate="yes" xml:space="preserve">
          <source>This class processes one step within the whole time sequence input, whereas &lt;code&gt;tf.keras.layer.SimpleRNN&lt;/code&gt; processes the whole sequence.</source>
          <target state="translated">이 클래스는 전체 시간 시퀀스 입력 내에서 한 단계를 처리하는 반면 &lt;code&gt;tf.keras.layer.SimpleRNN&lt;/code&gt; 은 전체 시퀀스를 처리합니다.</target>
        </trans-unit>
        <trans-unit id="c2cd1ab18438d633073fa2c3300d94950ce386b5" translate="yes" xml:space="preserve">
          <source>This class regularly exports the serving graph and checkpoints.</source>
          <target state="translated">이 클래스는 정기적으로 검색 그래프와 검사 점을 내 보냅니다.</target>
        </trans-unit>
        <trans-unit id="44829f1dbd5fa6ec4b7c405e96fb0cb7473fedd5" translate="yes" xml:space="preserve">
          <source>This class specifies the configurations for an &lt;code&gt;Estimator&lt;/code&gt; run.</source>
          <target state="translated">이 클래스는 &lt;code&gt;Estimator&lt;/code&gt; 실행 구성을 지정합니다 .</target>
        </trans-unit>
        <trans-unit id="349b70f1528f5d483fc48af054599841c5669982" translate="yes" xml:space="preserve">
          <source>This class takes in a sequence of data-points gathered at equal intervals, along with time series parameters such as stride, length of history, etc., to produce batches for training/validation.</source>
          <target state="translated">이 클래스는 보폭, 히스토리 길이 등과 같은 시계열 매개 변수와 함께 동일한 간격으로 수집 된 일련의 데이터 포인트를 사용하여 훈련 / 검증을위한 배치를 생성합니다.</target>
        </trans-unit>
        <trans-unit id="45bad515b0c24287a7857bc49730849b980995da" translate="yes" xml:space="preserve">
          <source>This classifier ignores feature values and will learn to predict the average value of each label. For single-label problems, this will predict the probability distribution of the classes as seen in the labels. For multi-label problems, this will predict the fraction of examples that are positive for each class.</source>
          <target state="translated">이 분류기는 기능 값을 무시하고 각 레이블의 평균 값을 예측하는 방법을 배웁니다. 단일 레이블 문제의 경우 레이블에 표시된대로 클래스의 확률 분포를 예측합니다. 다중 레이블 문제의 경우 각 클래스에 긍정적 인 예제의 비율을 예측합니다.</target>
        </trans-unit>
        <trans-unit id="1203741987f9f009e5e86b580142b5f23085017c" translate="yes" xml:space="preserve">
          <source>This computes the internal data stats related to the data-dependent transformations, based on an array of sample data.</source>
          <target state="translated">샘플 데이터 배열을 기반으로 데이터 종속 변환과 관련된 내부 데이터 통계를 계산합니다.</target>
        </trans-unit>
        <trans-unit id="38619017d4eec4e645fa2f91a523c788477cd3cb" translate="yes" xml:space="preserve">
          <source>This condition holds if for every pair of (possibly broadcast) elements &lt;code&gt;x[i]&lt;/code&gt;, &lt;code&gt;y[i]&lt;/code&gt;, we have</source>
          <target state="translated">이 조건은 모든 요소 쌍 (가능한 방송) &lt;code&gt;x[i]&lt;/code&gt; , &lt;code&gt;y[i]&lt;/code&gt; 에 대해</target>
        </trans-unit>
        <trans-unit id="462aa0ba39503de33a78d3a4ed1c72d0eb71fa77" translate="yes" xml:space="preserve">
          <source>This condition holds if for every pair of (possibly broadcast) elements &lt;code&gt;x[i]&lt;/code&gt;, &lt;code&gt;y[i]&lt;/code&gt;, we have &lt;code&gt;x[i] != y[i]&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 조건은 모든 요소 쌍 (가능한 브로드 캐스트) &lt;code&gt;x[i]&lt;/code&gt; , &lt;code&gt;y[i]&lt;/code&gt; 에 대해 &lt;code&gt;x[i] != y[i]&lt;/code&gt; 됩니다. 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="e25b6ae62c3ffc2ef4953d25e9698856f0a3b77a" translate="yes" xml:space="preserve">
          <source>This condition holds if for every pair of (possibly broadcast) elements &lt;code&gt;x[i]&lt;/code&gt;, &lt;code&gt;y[i]&lt;/code&gt;, we have &lt;code&gt;x[i] &amp;gt; y[i]&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 조건은 모든 요소 쌍 (가능한 브로드 캐스트) &lt;code&gt;x[i]&lt;/code&gt; , &lt;code&gt;y[i]&lt;/code&gt; 에 대해 &lt;code&gt;x[i] &amp;gt; y[i]&lt;/code&gt; 됩니다. 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="ad801aabcdd92fbf94ec233e05dfeadd68d460b3" translate="yes" xml:space="preserve">
          <source>This condition holds if for every pair of (possibly broadcast) elements &lt;code&gt;x[i]&lt;/code&gt;, &lt;code&gt;y[i]&lt;/code&gt;, we have &lt;code&gt;x[i] &amp;gt;= y[i]&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 조건은 모든 요소 쌍 (가능한 브로드 캐스트) &lt;code&gt;x[i]&lt;/code&gt; , &lt;code&gt;y[i]&lt;/code&gt; 에 대해 &lt;code&gt;x[i] &amp;gt;= y[i]&lt;/code&gt; 됩니다. 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="512ed74cbec98906ad1a4d1866d9484e4d2ad504" translate="yes" xml:space="preserve">
          <source>This condition holds if for every pair of (possibly broadcast) elements &lt;code&gt;x[i]&lt;/code&gt;, &lt;code&gt;y[i]&lt;/code&gt;, we have &lt;code&gt;x[i] &amp;lt; y[i]&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 조건은 모든 요소 쌍 (가능한 브로드 캐스트) &lt;code&gt;x[i]&lt;/code&gt; , &lt;code&gt;y[i]&lt;/code&gt; 에 대해 &lt;code&gt;x[i] &amp;lt; y[i]&lt;/code&gt; 됩니다. 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="81434868d39629bbc35c170df36a994a92015b46" translate="yes" xml:space="preserve">
          <source>This condition holds if for every pair of (possibly broadcast) elements &lt;code&gt;x[i]&lt;/code&gt;, &lt;code&gt;y[i]&lt;/code&gt;, we have &lt;code&gt;x[i] &amp;lt;= y[i]&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 조건은 모든 요소 쌍 (가능한 브로드 캐스트) &lt;code&gt;x[i]&lt;/code&gt; , &lt;code&gt;y[i]&lt;/code&gt; 에 대해 &lt;code&gt;x[i] &amp;lt;= y[i]&lt;/code&gt; 됩니다. 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="93ee9d4d5438fdc7dae43626edce4fb33cefa73b" translate="yes" xml:space="preserve">
          <source>This condition holds if for every pair of (possibly broadcast) elements &lt;code&gt;x[i]&lt;/code&gt;, &lt;code&gt;y[i]&lt;/code&gt;, we have &lt;code&gt;x[i] == y[i]&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 조건은 모든 요소 쌍 (가능한 브로드 캐스트) &lt;code&gt;x[i]&lt;/code&gt; , &lt;code&gt;y[i]&lt;/code&gt; 에 대해 &lt;code&gt;x[i] == y[i]&lt;/code&gt; 됩니다. 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="1107421e32062956898c5a66e60e49bd95c7ed45" translate="yes" xml:space="preserve">
          <source>This constraint can be applied to any &lt;code&gt;Conv2D&lt;/code&gt; layer version, including &lt;code&gt;Conv2DTranspose&lt;/code&gt; and &lt;code&gt;SeparableConv2D&lt;/code&gt;, and with either &lt;code&gt;&quot;channels_last&quot;&lt;/code&gt; or &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; data format. The method assumes the weight tensor is of shape &lt;code&gt;(rows, cols, input_depth, output_depth)&lt;/code&gt;.</source>
          <target state="translated">이 제약은 적용 할 수있다 &lt;code&gt;Conv2D&lt;/code&gt; 을 포함한 층 버전 &lt;code&gt;Conv2DTranspose&lt;/code&gt; 및 &lt;code&gt;SeparableConv2D&lt;/code&gt; 및 하나와 &lt;code&gt;&quot;channels_last&quot;&lt;/code&gt; 또는 &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; 데이터 포맷. 이 방법은 가중치 텐서가 모양 &lt;code&gt;(rows, cols, input_depth, output_depth)&lt;/code&gt; 이라고 가정합니다 .</target>
        </trans-unit>
        <trans-unit id="e5e140df8d55549c17df75f17763f4c88b908cd9" translate="yes" xml:space="preserve">
          <source>This constructor creates both a &lt;code&gt;variable&lt;/code&gt; Op and an &lt;code&gt;assign&lt;/code&gt; Op to set the variable to its initial value.</source>
          <target state="translated">이 생성자는 &lt;code&gt;variable&lt;/code&gt; Op와 &lt;code&gt;assign&lt;/code&gt; Op를 모두 생성 하여 변수를 초기 값으로 설정합니다.</target>
        </trans-unit>
        <trans-unit id="0853b5f1d96849514913dcea4715e205fe7e9be9" translate="yes" xml:space="preserve">
          <source>This constructor is private -- please use one of the following ops to build &lt;code&gt;RaggedTensor&lt;/code&gt;s:</source>
          <target state="translated">이 생성자는 비공개입니다. &lt;code&gt;RaggedTensor&lt;/code&gt; 를 빌드하려면 다음 작업 중 하나를 사용하십시오 .</target>
        </trans-unit>
        <trans-unit id="fa9706d28ea0bf76646310aace552e8f79dee4fd" translate="yes" xml:space="preserve">
          <source>This constructor only applies if the algorithm is a counter-based algorithm. See method &lt;code&gt;key&lt;/code&gt; for the meaning of &quot;key&quot; and &quot;counter&quot;.</source>
          <target state="translated">이 생성자는 알고리즘이 카운터 기반 알고리즘 인 경우에만 적용됩니다. &quot;키&quot;및 &quot;카운터&quot;의 의미는 메소드 &lt;code&gt;key&lt;/code&gt; 를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="abd1f92b92080f9534139ad50b5578924ec063f6" translate="yes" xml:space="preserve">
          <source>This contains most of the synchronization implementation and also wraps the apply_gradients() from the real optimizer.</source>
          <target state="translated">여기에는 대부분의 동기화 구현이 포함되어 있으며 실제 최적화 프로그램에서 apply_gradients ()를 래핑합니다.</target>
        </trans-unit>
        <trans-unit id="dac62a0f0dbdc3c6a9231598871c80876ac21c3b" translate="yes" xml:space="preserve">
          <source>This context handler simplifies the exception handling. Use it as follows:</source>
          <target state="translated">이 컨텍스트 핸들러는 예외 처리를 단순화합니다. 다음과 같이 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="92e2326270a118c9b1678bb4952443a859f4c559" translate="yes" xml:space="preserve">
          <source>This context manager can be used to override the gradient function that will be used for ops within the scope of the context.</source>
          <target state="translated">이 컨텍스트 관리자를 사용하여 컨텍스트 범위 내에서 작업에 사용될 그라디언트 함수를 재정의 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="790e879037e30f5e5546c1be4c06bf6476dca2dd" translate="yes" xml:space="preserve">
          <source>This context manager captures all writes to a given stream inside of a &lt;code&gt;CapturedWrites&lt;/code&gt; object. When this context manager is created, it yields the &lt;code&gt;CapturedWrites&lt;/code&gt; object. The captured contents can be accessed by calling &lt;code&gt;.contents()&lt;/code&gt; on the &lt;code&gt;CapturedWrites&lt;/code&gt;.</source>
          <target state="translated">이 컨텍스트 관리자는 &lt;code&gt;CapturedWrites&lt;/code&gt; 객체 내부의 지정된 스트림에 대한 모든 쓰기를 캡처 합니다. 이 컨텍스트 관리자가 작성되면 &lt;code&gt;CapturedWrites&lt;/code&gt; 오브젝트 가 생성 됩니다. 캡처 된 컨텐츠는 &lt;code&gt;CapturedWrites&lt;/code&gt; 에서 &lt;code&gt;.contents()&lt;/code&gt; 를 호출하여 액세스 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="41c375fab79db6dca2a3052fe26a3bb1f0a48127" translate="yes" xml:space="preserve">
          <source>This context manager creates and automatically recovers a session. It optionally starts the standard services that handle checkpoints and summaries. It monitors exceptions raised from the &lt;code&gt;with&lt;/code&gt; block or from the services and stops the supervisor as needed.</source>
          <target state="translated">이 컨텍스트 관리자는 세션을 작성하고 자동으로 복구합니다. 선택적으로 검사 점 및 요약을 처리하는 표준 서비스를 시작합니다. &lt;code&gt;with&lt;/code&gt; 블록 또는 서비스에서 발생한 예외를 모니터링하고 필요에 따라 감독자를 중지합니다.</target>
        </trans-unit>
        <trans-unit id="1dfc6367da2112861ba5a19ab74136e2bfa59bd7" translate="yes" xml:space="preserve">
          <source>This context manager pushes a name scope, which will make the name of all operations added within it have a prefix.</source>
          <target state="translated">이 컨텍스트 관리자는 이름 범위를 푸시하여 이름 범위에 추가 된 모든 오퍼레이션의 이름에 접 두부를 붙입니다.</target>
        </trans-unit>
        <trans-unit id="cadf2e29564a69f6d9e78e18436e128fc8603a09" translate="yes" xml:space="preserve">
          <source>This context manager validates that the (optional) &lt;code&gt;values&lt;/code&gt; are from the same graph, ensures that graph is the default graph, and pushes a name scope and a variable scope.</source>
          <target state="translated">이 컨텍스트 관리자는 (선택적) &lt;code&gt;values&lt;/code&gt; 이 동일한 그래프에 있는지 확인하고 그래프가 기본 그래프인지 확인하고 이름 범위와 변수 범위를 푸시합니다.</target>
        </trans-unit>
        <trans-unit id="9fe8f8972b4d68b13082f0d96ff8de4b430acf3b" translate="yes" xml:space="preserve">
          <source>This context manager validates that the given &lt;code&gt;values&lt;/code&gt; are from the same graph, makes that graph the default graph, and pushes a name scope in that graph (see &lt;a href=&quot;../../../../graph#name_scope&quot;&gt;&lt;code&gt;tf.Graph.name_scope&lt;/code&gt;&lt;/a&gt; for more details on that).</source>
          <target state="translated">이 컨텍스트 관리자는 제공된 &lt;code&gt;values&lt;/code&gt; 이 동일한 그래프에 있는지 확인하고 해당 그래프를 기본 그래프로 만들고 해당 그래프에서 이름 범위를 푸시합니다 ( 자세한 내용 은 &lt;a href=&quot;../../../../graph#name_scope&quot;&gt; &lt;code&gt;tf.Graph.name_scope&lt;/code&gt; &lt;/a&gt; 참조 ).</target>
        </trans-unit>
        <trans-unit id="8bc9405ecd91e0aa7f29a32f0b001ccc17dfce1e" translate="yes" xml:space="preserve">
          <source>This convenience method requires a session where the graph containing this variable has been launched. If no session is passed, the default session is used. See &lt;a href=&quot;compat/v1/session&quot;&gt;&lt;code&gt;tf.compat.v1.Session&lt;/code&gt;&lt;/a&gt; for more information on launching a graph and on sessions.</source>
          <target state="translated">이 편리한 방법을 사용하려면이 변수를 포함하는 그래프가 시작된 세션이 필요합니다. 세션이 전달되지 않으면 기본 세션이 사용됩니다. 그래프 시작 및 세션에 대한 자세한 내용 은 &lt;a href=&quot;compat/v1/session&quot;&gt; &lt;code&gt;tf.compat.v1.Session&lt;/code&gt; &lt;/a&gt; 을 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="69597b8afaecf26bf780e17dbe96db99a176f9db" translate="yes" xml:space="preserve">
          <source>This convenience method requires a session where the graph containing this variable has been launched. If no session is passed, the default session is used. See &lt;a href=&quot;session&quot;&gt;&lt;code&gt;tf.compat.v1.Session&lt;/code&gt;&lt;/a&gt; for more information on launching a graph and on sessions.</source>
          <target state="translated">이 편리한 방법을 사용하려면이 변수를 포함하는 그래프가 시작된 세션이 필요합니다. 세션이 전달되지 않으면 기본 세션이 사용됩니다. 그래프 시작 및 세션에 대한 자세한 내용 은 &lt;a href=&quot;session&quot;&gt; &lt;code&gt;tf.compat.v1.Session&lt;/code&gt; &lt;/a&gt; 을 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="049bd1098346a19ff3fab486ff6a7b47c3fd7819" translate="yes" xml:space="preserve">
          <source>This creates a &lt;code&gt;LinearOperator&lt;/code&gt; of the form &lt;code&gt;A = L + U D V^H&lt;/code&gt;, with &lt;code&gt;L&lt;/code&gt; a &lt;code&gt;LinearOperator&lt;/code&gt;, &lt;code&gt;U, V&lt;/code&gt; both [batch] matrices, and &lt;code&gt;D&lt;/code&gt; a [batch] diagonal matrix.</source>
          <target state="translated">이렇게하면 &lt;code&gt;A = L + U D V^H&lt;/code&gt; 형식 의 &lt;code&gt;LinearOperator&lt;/code&gt; 가 생성되고 , &lt;code&gt;L&lt;/code&gt; 은 &lt;code&gt;LinearOperator&lt;/code&gt; , &lt;code&gt;U, V&lt;/code&gt; 는 [일괄 처리] 행렬이고 &lt;code&gt;D&lt;/code&gt; 는 [일괄 처리] 대각선 행렬입니다.</target>
        </trans-unit>
        <trans-unit id="20e733fb47526c81e38b7224224a075d45127bb0" translate="yes" xml:space="preserve">
          <source>This creates a named directory on disk that is isolated to this test, and will be properly cleaned up by the test. This avoids several pitfalls of creating temporary directories for test purposes, as well as makes it easier to setup directories and verify their contents.</source>
          <target state="translated">이렇게하면이 테스트와 격리 된 디스크에 명명 된 디렉토리가 생성되고 테스트에 의해 올바르게 정리됩니다. 이를 통해 테스트 목적으로 임시 디렉토리를 작성하는 데 따르는 함정을 피할 수있을뿐만 아니라 디렉토리를 쉽게 설정하고 내용을 확인할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="75714df8d9550841d3043fbd62dad500169275e6" translate="yes" xml:space="preserve">
          <source>This creates a named file on disk that is isolated to this test, and will be properly cleaned up by the test. This avoids several pitfalls of creating temporary files for test purposes, as well as makes it easier to setup files, their data, read them back, and inspect them when a test fails.</source>
          <target state="translated">이렇게하면이 테스트와 격리 된 명명 된 파일이 디스크에 만들어지고 테스트에 의해 올바르게 정리됩니다. 이를 통해 테스트 목적으로 임시 파일을 작성하는 데 따르는 함정을 피할 수있을뿐만 아니라 파일, 데이터를 설정하고 다시 읽고 테스트에 실패 할 때 파일을 쉽게 검사 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="42646afd71d42ede988399add1a74a5f6b4c93c2" translate="yes" xml:space="preserve">
          <source>This creates a tuple of tensors with the same values as the &lt;code&gt;tensors&lt;/code&gt; argument, except that the value of each tensor is only returned after the values of all tensors have been computed.</source>
          <target state="translated">이렇게하면 모든 텐서의 값이 계산 된 후에 만 ​​각 텐서의 값이 반환된다는 점을 제외하고 &lt;code&gt;tensors&lt;/code&gt; 인수 와 동일한 값으로 텐서의 튜플이 생성 됩니다.</target>
        </trans-unit>
        <trans-unit id="f9dc1c4d1a56233dc4a8e886da12f3f0a495623a" translate="yes" xml:space="preserve">
          <source>This dataset fills a buffer with &lt;code&gt;buffer_size&lt;/code&gt; elements, then randomly samples elements from this buffer, replacing the selected elements with new elements. For perfect shuffling, a buffer size greater than or equal to the full size of the dataset is required.</source>
          <target state="translated">이 데이터 세트는 &lt;code&gt;buffer_size&lt;/code&gt; 요소 로 버퍼를 채우고이 버퍼에서 요소를 무작위로 샘플링하여 선택한 요소를 새 요소로 바꿉니다. 완벽한 셔플 링을 위해서는 데이터 세트의 전체 크기보다 크거나 같은 버퍼 크기가 필요합니다.</target>
        </trans-unit>
        <trans-unit id="97fff19a84ee410a08999fab8be4d199f9066fdc" translate="yes" xml:space="preserve">
          <source>This dataset operator is very useful when running distributed training, as it allows each worker to read a unique subset.</source>
          <target state="translated">이 데이터 세트 연산자는 각 작업자가 고유 한 하위 집합을 읽을 수 있도록 분산 교육을 실행할 때 매우 유용합니다.</target>
        </trans-unit>
        <trans-unit id="38966f21ae4fd315566bc2e9e41902f2d11ad1fd" translate="yes" xml:space="preserve">
          <source>This decorator allows fine grained control over the gradients of a sequence for operations. This may be useful for multiple reasons, including providing a more efficient or numerically stable gradient for a sequence of operations.</source>
          <target state="translated">이 데코레이터를 사용하면 작업 시퀀스의 그래디언트를 세밀하게 제어 할 수 있습니다. 이는 일련의 연산에 대해보다 효율적이거나 수치 적으로 안정적인 구배를 제공하는 것을 포함하여 여러 가지 이유로 유용 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="507c4c48f689d10862643a9c65b8ad1497b61251" translate="yes" xml:space="preserve">
          <source>This decorator injects the decorated class or function into the Keras custom object dictionary, so that it can be serialized and deserialized without needing an entry in the user-provided custom object dict. It also injects a function that Keras will call to get the object's serializable string key.</source>
          <target state="translated">이 데코레이터는 데코 레이팅 된 클래스 나 함수를 Keras 커스텀 객체 딕셔너리에 삽입하여 사용자가 제공 한 커스텀 객체 dict에 항목을 입력하지 않고도 직렬화 및 역 직렬화 할 수 있습니다. 또한 Keras가 객체의 직렬화 가능 문자열 키를 얻기 위해 호출하는 함수를 주입합니다.</target>
        </trans-unit>
        <trans-unit id="99ba7a22516d6648f4353818a77d3239c06fe661" translate="yes" xml:space="preserve">
          <source>This decorator is only used when defining a new op type. For an op with &lt;code&gt;m&lt;/code&gt; inputs and &lt;code&gt;n&lt;/code&gt; outputs, the gradient function is a function that takes the original &lt;code&gt;Operation&lt;/code&gt; and &lt;code&gt;n&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; objects (representing the gradients with respect to each output of the op), and returns &lt;code&gt;m&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; objects (representing the partial gradients with respect to each input of the op).</source>
          <target state="translated">이 데코레이터는 새로운 op 유형을 정의 할 때만 사용됩니다. &lt;code&gt;m&lt;/code&gt; 개의 입력과 &lt;code&gt;n&lt;/code&gt; 개의 출력을 갖는 op의 경우, 그래디언트 기능은 원래의 &lt;code&gt;Operation&lt;/code&gt; 및 &lt;code&gt;n&lt;/code&gt; 개의 &lt;code&gt;Tensor&lt;/code&gt; 객체 (op의 각 출력에 대한 그래디언트를 나타냄)를 가져오고 &lt;code&gt;m&lt;/code&gt; 개의 &lt;code&gt;Tensor&lt;/code&gt; 객체 ( op의 각 입력에 대해).</target>
        </trans-unit>
        <trans-unit id="31c4ff795b26f67c26110ef2a390028f451d7769" translate="yes" xml:space="preserve">
          <source>This defines the skeleton for all implementations of ClusterResolvers. ClusterResolvers are a way for TensorFlow to communicate with various cluster management systems (e.g. GCE, AWS, etc...).</source>
          <target state="translated">이는 ClusterResolvers의 모든 구현에 대한 골격을 정의합니다. ClusterResolvers는 TensorFlow가 다양한 클러스터 관리 시스템 (예 : GCE, AWS 등)과 통신 할 수있는 방법입니다.</target>
        </trans-unit>
        <trans-unit id="0df31e40439c17db3321616e25b535cdb0316252" translate="yes" xml:space="preserve">
          <source>This definition of cell differs from the definition used in the literature. In the literature, 'cell' refers to an object with a single scalar output. This definition refers to a horizontal array of such units.</source>
          <target state="translated">이러한 세포 정의는 문헌에 사용 된 정의와 다릅니다. 문헌에서 '셀'은 단일 스칼라 출력을 가진 객체를 나타냅니다. 이 정의는 이러한 단위의 수평 배열을 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="0725a72c209eb53df1440f5a39a25dbf2ab21a14" translate="yes" xml:space="preserve">
          <source>This distribution has parameters: degree of freedom &lt;code&gt;df&lt;/code&gt;, location &lt;code&gt;loc&lt;/code&gt;, and &lt;code&gt;scale&lt;/code&gt;.</source>
          <target state="translated">이 분포에는 자유도 &lt;code&gt;df&lt;/code&gt; , 위치 &lt;code&gt;loc&lt;/code&gt; 및 &lt;code&gt;scale&lt;/code&gt; 매개 변수가 있습니다.</target>
        </trans-unit>
        <trans-unit id="11a222f9738197dadd6eb7c453e22ae24d0f3567" translate="yes" xml:space="preserve">
          <source>This does not close the session.</source>
          <target state="translated">세션이 닫히지 않습니다.</target>
        </trans-unit>
        <trans-unit id="e3bddf2a09aebf2b7d2bb27cde671e8328a7dc27" translate="yes" xml:space="preserve">
          <source>This does not undo the effects of loss scaling. Any optimizers wrapped with a LossScaleOptimizer will continue to do loss scaling, although this loss scaling will no longer be useful if the optimizer is used in new Sessions, as the graph rewrite no longer converts the graph to use float16.</source>
          <target state="translated">이것은 손실 스케일링의 영향을 취소하지 않습니다. 그래프 다시 쓰기가 더 이상 float16을 사용하도록 그래프를 변환하지 않기 때문에 LossScaleOptimizer로 랩핑 된 옵티마이 저는 계속해서 손실 스케일링을 수행하지만 옵티마이 저가 새 세션에서 사용되는 경우이 손실 스케일링은 더 이상 유용하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="02c54112c729e547b6e3e03e55cab5ced9766b9c" translate="yes" xml:space="preserve">
          <source>This does not undo the effects of loss scaling. Any optimizers wrapped with a LossScaleOptimizer will continue to do loss scaling, although this loss scaling will no longer be useful, as the graph rewrite no longer converts tf.functions to use float16.</source>
          <target state="translated">이것은 손실 스케일링의 영향을 취소하지 않습니다. 그래프 재 작성이 더 이상 tf.functions를 float16을 사용하도록 변환하지 않기 때문에 LossScaleOptimizer로 랩핑 된 옵티마이 저는 손실 스케일링을 계속 수행하지만이 손실 스케일링은 더 이상 유용하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="3bfa5300d7e625917e03fb074107ed12abbdcbbe" translate="yes" xml:space="preserve">
          <source>This eliminates the overhead of &lt;code&gt;k-1&lt;/code&gt; calls to &lt;code&gt;space_to_batch_nd&lt;/code&gt; and &lt;code&gt;batch_to_space_nd&lt;/code&gt;.</source>
          <target state="translated">이것은 &lt;code&gt;space_to_batch_nd&lt;/code&gt; 및 &lt;code&gt;batch_to_space_nd&lt;/code&gt; 에 대한 &lt;code&gt;k-1&lt;/code&gt; 호출 의 오버 헤드를 제거합니다 .</target>
        </trans-unit>
        <trans-unit id="4c1542adb4efbb08745cf8660782eb015be7e9a8" translate="yes" xml:space="preserve">
          <source>This enables the new behavior.</source>
          <target state="translated">이것은 새로운 행동을 가능하게합니다.</target>
        </trans-unit>
        <trans-unit id="b70309885ebd2feded30214b2bff057bfcef522b" translate="yes" xml:space="preserve">
          <source>This enables variables to be read as bfloat16 type when using get_variable.</source>
          <target state="translated">이를 통해 get_variable을 사용할 때 변수를 bfloat16 유형으로 읽을 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="9b4ec5604b14a4a73674990062864327b53e189b" translate="yes" xml:space="preserve">
          <source>This enumeration represents optional conversion options.</source>
          <target state="translated">이 열거는 선택적 변환 옵션을 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="26d8315a3de6d7adfdf3bbd23a3ef83e0e870212" translate="yes" xml:space="preserve">
          <source>This estimator ignores feature values and will learn to predict the average value of each label. E.g. for single-label classification problems, this will predict the probability distribution of the classes as seen in the labels. For multi-label classification problems, it will predict the ratio of examples that contain each class.</source>
          <target state="translated">이 추정기는 피처 값을 무시하고 각 레이블의 평균값을 예측하는 방법을 배웁니다. 예를 들어 단일 레이블 분류 문제의 경우 레이블에 표시된대로 클래스의 확률 분포를 예측합니다. 다중 레이블 분류 문제의 경우 각 클래스를 포함하는 예제의 비율을 예측합니다.</target>
        </trans-unit>
        <trans-unit id="3f03708fe58a6d112475001cb64ef56af4e257ac" translate="yes" xml:space="preserve">
          <source>This example instantiates a TextVectorization layer that lowercases text, splits on whitespace, strips punctuation, and outputs integer vocab indices.</source>
          <target state="translated">이 예제에서는 텍스트를 소문자로 바꾸고 공백으로 나누고 문장 부호를 제거하고 정수 어휘 색인을 출력하는 TextVectorization 레이어를 인스턴스화합니다.</target>
        </trans-unit>
        <trans-unit id="3b8a0001b21c834c94ffc58110b29147780ed1bc" translate="yes" xml:space="preserve">
          <source>This exception is most commonly raised when running an operation that reads a &lt;a href=&quot;../variable&quot;&gt;&lt;code&gt;tf.Variable&lt;/code&gt;&lt;/a&gt; before it has been initialized.</source>
          <target state="translated">이 예외는 초기화되기 전에 &lt;a href=&quot;../variable&quot;&gt; &lt;code&gt;tf.Variable&lt;/code&gt; &lt;/a&gt; 을 읽는 작업을 실행할 때 가장 일반적으로 발생 합니다.</target>
        </trans-unit>
        <trans-unit id="5c5a8c57c6d5ff0bef6c24b2e2bd3f673907515f" translate="yes" xml:space="preserve">
          <source>This exception is not currently used.</source>
          <target state="translated">이 예외는 현재 사용되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="f99d6b607eb42d98eb52dda612321114e3e91d9d" translate="yes" xml:space="preserve">
          <source>This exception is raised in &quot;end-of-file&quot; conditions, such as when a &lt;code&gt;tf.QueueBase.dequeue&lt;/code&gt; operation is blocked on an empty queue, and a &lt;code&gt;tf.QueueBase.close&lt;/code&gt; operation executes.</source>
          <target state="translated">이 예외 이러한 경우와 같이 &quot;파일 끝&quot;상태에서 발생 &lt;code&gt;tf.QueueBase.dequeue&lt;/code&gt; 의 동작이 비어있는 큐에서 차단되고, &lt;code&gt;tf.QueueBase.close&lt;/code&gt; 의 동작 실행한다.</target>
        </trans-unit>
        <trans-unit id="78d71c0636a2aa1fd087c8298d2d2e031276f9b2" translate="yes" xml:space="preserve">
          <source>This exception is raised when some invariant expected by the runtime has been broken. Catching this exception is not recommended.</source>
          <target state="translated">이 예외는 런타임에 예상되는 일부 불변이 깨졌을 때 발생합니다. 이 예외를 잡는 것은 권장되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="7057b737e9dfe1ba0218e510ec51533edf1eab95" translate="yes" xml:space="preserve">
          <source>This exists primarily to support the definition of type-specific summary ops like scalar() and image(), and is not intended for direct use unless defining a new type-specific summary op.</source>
          <target state="translated">이는 주로 scalar () 및 image ()와 같은 유형별 요약 연산의 정의를 지원하기 위해 존재하며 새로운 유형별 요약 연산을 정의하지 않으면 직접 사용하기위한 것이 아닙니다.</target>
        </trans-unit>
        <trans-unit id="b7cea24b85385b2c626baad7c000ac087d0ac17d" translate="yes" xml:space="preserve">
          <source>This file includes functions and constants from core (model_utils) and export.py</source>
          <target state="translated">이 파일에는 코어 (model_utils) 및 export.py의 함수 및 상수가 포함됩니다.</target>
        </trans-unit>
        <trans-unit id="1ed5997b223ee14f22d4d6301133fe48a3becd70" translate="yes" xml:space="preserve">
          <source>This flag will have a value of None, True or False. None is possible if default=None and the user does not specify the flag on the command line.</source>
          <target state="translated">이 플래그의 값은 None, True 또는 False입니다. default = None이고 사용자가 명령 행에 플래그를 지정하지 않으면 사용할 수 없습니다.</target>
        </trans-unit>
        <trans-unit id="edc3e42fb098d2f82cf52f313f0a2bbc39d59acf" translate="yes" xml:space="preserve">
          <source>This foldl operator repeatedly applies the callable &lt;code&gt;fn&lt;/code&gt; to a sequence of elements from first to last. The elements are made of the tensors unpacked from &lt;code&gt;elems&lt;/code&gt; on dimension 0. The callable fn takes two tensors as arguments. The first argument is the accumulated value computed from the preceding invocation of fn, and the second is the value at the current position of &lt;code&gt;elems&lt;/code&gt;. If &lt;code&gt;initializer&lt;/code&gt; is None, &lt;code&gt;elems&lt;/code&gt; must contain at least one element, and its first element is used as the initializer.</source>
          <target state="translated">이 폴더 연산자는 호출 가능한 &lt;code&gt;fn&lt;/code&gt; 을 처음부터 끝까지 일련의 요소에 반복적으로 적용합니다 . 이 요소에서 압축 해제 텐서 이루어지는 &lt;code&gt;elems&lt;/code&gt; : 호출 FN 인수로 두 텐서 소요 치수에 0. 첫 번째 인수는 fn의 이전 호출에서 계산 된 누적 값이고 두 번째 인수는 &lt;code&gt;elems&lt;/code&gt; 의 현재 위치에있는 값 입니다. 경우 &lt;code&gt;initializer&lt;/code&gt; 없음입니다, &lt;code&gt;elems&lt;/code&gt; 는 적어도 하나 개의 요소를 포함해야하고, 첫 번째 요소는 초기화로 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="5c9efc4e60690682d054976cd526187b0ec74f90" translate="yes" xml:space="preserve">
          <source>This foldr operator repeatedly applies the callable &lt;code&gt;fn&lt;/code&gt; to a sequence of elements from last to first. The elements are made of the tensors unpacked from &lt;code&gt;elems&lt;/code&gt;. The callable fn takes two tensors as arguments. The first argument is the accumulated value computed from the preceding invocation of fn, and the second is the value at the current position of &lt;code&gt;elems&lt;/code&gt;. If &lt;code&gt;initializer&lt;/code&gt; is None, &lt;code&gt;elems&lt;/code&gt; must contain at least one element, and its first element is used as the initializer.</source>
          <target state="translated">이 폴더 연산자는 호출 가능한 &lt;code&gt;fn&lt;/code&gt; 을 마지막부터 처음까지 일련의 요소에 반복적으로 적용합니다 . 요소는 &lt;code&gt;elems&lt;/code&gt; 에서 압축이 풀린 텐서로 만들어집니다 . 호출 가능한 fn은 두 개의 텐서를 인수로 사용합니다. 첫 번째 인수는 fn의 이전 호출에서 계산 된 누적 값이고 두 번째 인수는 &lt;code&gt;elems&lt;/code&gt; 의 현재 위치에있는 값 입니다. 경우 &lt;code&gt;initializer&lt;/code&gt; 없음입니다, &lt;code&gt;elems&lt;/code&gt; 는 적어도 하나 개의 요소를 포함해야하고, 첫 번째 요소는 초기화로 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="e47bc5be6551c40b285b99814572b5e2b249a8b5" translate="yes" xml:space="preserve">
          <source>This function adds operations to the current session. To compute the error using a particular device, such as a GPU, use the standard methods for setting a device (e.g. using with sess.graph.device() or setting a device function in the session constructor).</source>
          <target state="translated">이 기능은 현재 세션에 작업을 추가합니다. GPU와 같은 특정 장치를 사용하여 오류를 계산하려면 장치를 설정하는 표준 방법 (예 : sess.graph.device () 사용 또는 세션 생성자에서 장치 기능 설정)을 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="b1c988623a891fbccad5b0fbb3db51dcb83f9a90" translate="yes" xml:space="preserve">
          <source>This function adds the following to the current &lt;code&gt;Graph&lt;/code&gt;:</source>
          <target state="translated">이 함수는 현재 &lt;code&gt;Graph&lt;/code&gt; 다음을 추가합니다 .</target>
        </trans-unit>
        <trans-unit id="7391056d9f36003196c437fbb04f6186eed40dde" translate="yes" xml:space="preserve">
          <source>This function allows expressing computations in a TensorFlow graph as Python functions. In particular, it wraps a Python function &lt;code&gt;func&lt;/code&gt; in a once-differentiable TensorFlow operation that executes it with eager execution enabled. As a consequence, &lt;a href=&quot;py_function&quot;&gt;&lt;code&gt;tf.py_function&lt;/code&gt;&lt;/a&gt; makes it possible to express control flow using Python constructs (&lt;code&gt;if&lt;/code&gt;, &lt;code&gt;while&lt;/code&gt;, &lt;code&gt;for&lt;/code&gt;, etc.), instead of TensorFlow control flow constructs (&lt;a href=&quot;cond&quot;&gt;&lt;code&gt;tf.cond&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;while_loop&quot;&gt;&lt;code&gt;tf.while_loop&lt;/code&gt;&lt;/a&gt;). For example, you might use &lt;a href=&quot;py_function&quot;&gt;&lt;code&gt;tf.py_function&lt;/code&gt;&lt;/a&gt; to implement the log huber function:</source>
          <target state="translated">이 함수를 사용하면 TensorFlow 그래프에서 계산을 파이썬 함수로 표현할 수 있습니다. 특히, 파이썬 함수 &lt;code&gt;func&lt;/code&gt; 을 한 번만 구분할 수있는 TensorFlow 작업으로 래핑하여 실행을 열망으로 실행합니다. 결과적으로 &lt;a href=&quot;py_function&quot;&gt; &lt;code&gt;tf.py_function&lt;/code&gt; 을&lt;/a&gt; 사용하면 TensorFlow 제어 흐름 구문 ( &lt;a href=&quot;cond&quot;&gt; &lt;code&gt;tf.cond&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;while_loop&quot;&gt; &lt;code&gt;tf.while_loop&lt;/code&gt; &lt;/a&gt; ) 대신 Python 구문 ( &lt;code&gt;if&lt;/code&gt; , &lt;code&gt;while&lt;/code&gt; , &lt;code&gt;for&lt;/code&gt; 등)을 사용하여 제어 흐름을 표현할 수 있습니다 . 예를 들어, &lt;a href=&quot;py_function&quot;&gt; &lt;code&gt;tf.py_function&lt;/code&gt; &lt;/a&gt; 을 사용 하여 로그 허브 기능을 구현할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="fa49b9c5fb3cc27a08b15ff4c8fbc286bffc2bb3" translate="yes" xml:space="preserve">
          <source>This function allows replacing a function wrapped by &lt;code&gt;decorator_func&lt;/code&gt;, assuming the decorator that wraps the function is written as described below.</source>
          <target state="translated">이 함수는 함수를 랩핑하는 &lt;code&gt;decorator_func&lt;/code&gt; 가 아래와 같이 작성되었다고 가정하고 decorator_func에 의해 랩핑 된 함수를 대체 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="f1af1fe4443bcb9edf1df9ce5ca5cc1b073069a3" translate="yes" xml:space="preserve">
          <source>This function also returns a &lt;code&gt;should_apply_gradients&lt;/code&gt; bool. If False, gradients should not be applied to the variables that step, as nonfinite gradients were found, and the loss scale has been be updated to reduce the chance of finding nonfinite gradients in the next step. Some loss scale classes will always return True, as they cannot adjust themselves in response to nonfinite gradients.</source>
          <target state="translated">이 함수는 &lt;code&gt;should_apply_gradients&lt;/code&gt; bool 도 반환합니다 . False 인 경우 비정규 그라디언트가 발견되었으므로 그 단계에 변수에 그라디언트를 적용해서는 안되며 다음 단계에서 비정규 그라디언트를 찾을 가능성을 줄이기 위해 손실 스케일이 업데이트되었습니다. 일부 손실 스케일 클래스는 무한 그라데이션에 응답하여 스스로 조정할 수 없기 때문에 항상 True를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="a970dd1ee86d1ed9e7a0f4a5fcb3e14f9903fdf2" translate="yes" xml:space="preserve">
          <source>This function assumes that &lt;code&gt;img1&lt;/code&gt; and &lt;code&gt;img2&lt;/code&gt; are image batches, i.e. the last three dimensions are [height, width, channels].</source>
          <target state="translated">이 함수는 &lt;code&gt;img1&lt;/code&gt; 과 &lt;code&gt;img2&lt;/code&gt; 가 이미지 배치 라고 가정합니다 . 즉, 마지막 3 차원은 [높이, 너비, 채널]입니다.</target>
        </trans-unit>
        <trans-unit id="05e4418b517bd473a485966680131f4c4c444d83" translate="yes" xml:space="preserve">
          <source>This function attempts to partially evaluate the given tensor, and returns its value as a numpy ndarray if this succeeds.</source>
          <target state="translated">이 함수는 주어진 텐서를 부분적으로 평가하려고 시도하고 이것이 성공하면 그 값을 numpy ndarray로 반환합니다.</target>
        </trans-unit>
        <trans-unit id="cf86c424c057435bb07a468ed262a1bc87e5ff48" translate="yes" xml:space="preserve">
          <source>This function can be called at the beginning of the program (before &lt;code&gt;Tensors&lt;/code&gt;, &lt;code&gt;Graphs&lt;/code&gt; or other structures have been created, and before devices have been initialized. It switches all global behaviors that are different between TensorFlow 1.x and 2.x to behave as intended for 1.x.</source>
          <target state="translated">이 함수는 프로그램 시작시 ( &lt;code&gt;Tensors&lt;/code&gt; , &lt;code&gt;Graphs&lt;/code&gt; 또는 기타 구조가 생성되기 전과 장치가 초기화되기 전에) 호출 될 수 있습니다 . TensorFlow 1.x와 2.x 사이에 다른 모든 전역 동작이 다음과 같이 작동하도록 전환됩니다. 1.x를위한 것입니다.</target>
        </trans-unit>
        <trans-unit id="10057d11c28687d408d56022580e8ea6fe2a793b" translate="yes" xml:space="preserve">
          <source>This function can be called at the beginning of the program (before &lt;code&gt;Tensors&lt;/code&gt;, &lt;code&gt;Graphs&lt;/code&gt; or other structures have been created, and before devices have been initialized. It switches all global behaviors that are different between TensorFlow 1.x and 2.x to behave as intended for 2.x.</source>
          <target state="translated">이 함수는 프로그램 시작시 ( &lt;code&gt;Tensors&lt;/code&gt; , &lt;code&gt;Graphs&lt;/code&gt; 또는 기타 구조가 생성되기 전과 장치가 초기화되기 전에) 호출 될 수 있습니다 . TensorFlow 1.x와 2.x 사이에 다른 모든 전역 동작이 다음과 같이 작동하도록 전환됩니다. 2.x 용입니다.</target>
        </trans-unit>
        <trans-unit id="b42e569daa67e0a1534f20b78d521ba43e71fa0e" translate="yes" xml:space="preserve">
          <source>This function can be used to calculate a suitable paddings argument for use with space_to_batch_nd and batch_to_space_nd.</source>
          <target state="translated">이 함수는 space_to_batch_nd 및 batch_to_space_nd와 함께 사용하기에 적합한 패딩 인수를 계산하는 데 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="c744362e6d55098ce01656aff7353b51e78a3f8e" translate="yes" xml:space="preserve">
          <source>This function can be useful when composing a new operation in Python (such as &lt;code&gt;my_func&lt;/code&gt; in the example above). All standard Python op constructors apply this function to each of their Tensor-valued inputs, which allows those ops to accept numpy arrays, Python lists, and scalars in addition to &lt;code&gt;Tensor&lt;/code&gt; objects.</source>
          <target state="translated">이 함수는 Python에서 새 작업을 작성할 때 유용합니다 (예 : &lt;code&gt;my_func&lt;/code&gt; ). 모든 표준 Python op 생성자는이 함수를 각 텐서 값 입력에 적용합니다.이를 통해 해당 op가 &lt;code&gt;Tensor&lt;/code&gt; 객체 외에도 numpy 배열, Python 목록 및 스칼라를 허용 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="217d0b2441a5002feaf4d45bd68846f61852099e" translate="yes" xml:space="preserve">
          <source>This function can compute several different vector norms (the 1-norm, the Euclidean or 2-norm, the inf-norm, and in general the p-norm for p &amp;gt; 0) and matrix norms (Frobenius, 1-norm, 2-norm and inf-norm).</source>
          <target state="translated">이 함수는 여러 가지 다른 벡터 규범 (1- 노름, 유클리드 또는 2- 노름, inf- 노름, 일반적으로 p&amp;gt; 0의 p- 노름)과 행렬 규범 (Frobenius, 1-norm, 2- 규범과 inf-norm).</target>
        </trans-unit>
        <trans-unit id="3ea434ce2125739c9300b55f884e2363f68836bb" translate="yes" xml:space="preserve">
          <source>This function can only be called before any Graphs, Ops, or Tensors have been created. It can be used at the beginning of the program for complex migration projects from TensorFlow 1.x to 2.x.</source>
          <target state="translated">이 함수는 그래프, 연산 또는 텐서가 생성되기 전에 만 호출 할 수 있습니다. 프로그램 시작 부분에서 TensorFlow 1.x에서 2.x로 복잡한 마이그레이션 프로젝트를 위해 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="588718f27309c0577e10569b211613b30b1126d6" translate="yes" xml:space="preserve">
          <source>This function casts the input to &lt;code&gt;dtype&lt;/code&gt; without applying any scaling. If there is a danger that values would over or underflow in the cast, this op applies the appropriate clamping before the cast.</source>
          <target state="translated">이 함수는 스케일링을 적용하지 않고 입력을 &lt;code&gt;dtype&lt;/code&gt; 으로 캐스팅합니다 . 캐스트에서 값이 오버플로 또는 언더 플로 될 위험이있는 경우이 op는 캐스트 전에 적절한 클램핑을 적용합니다.</target>
        </trans-unit>
        <trans-unit id="09decee67bf539dd150a70f2c58935c601acb068" translate="yes" xml:space="preserve">
          <source>This function computes the exponential of every element in the input tensor. i.e. &lt;code&gt;exp(x)&lt;/code&gt; or &lt;code&gt;e^(x)&lt;/code&gt;, where &lt;code&gt;x&lt;/code&gt; is the input tensor. &lt;code&gt;e&lt;/code&gt; denotes Euler's number and is approximately equal to 2.718281. Output is positive for any real input.</source>
          <target state="translated">이 함수는 입력 텐서의 모든 요소에 대한 지수를 계산합니다. 즉 &lt;code&gt;exp(x)&lt;/code&gt; 또는 &lt;code&gt;e^(x)&lt;/code&gt; . 여기서 &lt;code&gt;x&lt;/code&gt; 는 입력 텐서입니다. &lt;code&gt;e&lt;/code&gt; 는 오일러의 수를 나타내며 대략 2.718281과 같습니다. 실제 입력에 대해 출력이 양수입니다.</target>
        </trans-unit>
        <trans-unit id="7c0a191a50e5e9af59c01d8569f306fc43d930b1" translate="yes" xml:space="preserve">
          <source>This function computes the matrix logarithm using the Schur-Parlett algorithm. Details of the algorithm can be found in Section 11.6.2 of: Nicholas J. Higham, Functions of Matrices: Theory and Computation, SIAM 2008. ISBN 978-0-898716-46-7.</source>
          <target state="translated">이 함수는 Schur-Parlett 알고리즘을 사용하여 행렬 로그를 계산합니다. 알고리즘에 대한 자세한 내용은 11.6.2 절 : Nicholas J. Higham, 행렬의 함수 : 이론 및 계산, SIAM 2008에 있습니다. ISBN 978-0-898716-46-7.</target>
        </trans-unit>
        <trans-unit id="be1f544dd8e61bda50e9ba11ee30c7fa32e6f8ea" translate="yes" xml:space="preserve">
          <source>This function converts Python objects of various types to &lt;code&gt;Tensor&lt;/code&gt; objects. It accepts &lt;code&gt;Tensor&lt;/code&gt; objects, numpy arrays, Python lists, and Python scalars. For example:</source>
          <target state="translated">이 함수는 다양한 유형의 Python 객체를 &lt;code&gt;Tensor&lt;/code&gt; 객체 로 변환 합니다. 그것은 받아 &lt;code&gt;Tensor&lt;/code&gt; 개체, NumPy와 배열, 파이썬 목록 및 파이썬 스칼라. 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="e487da37eb7d13adb8d956491efcafe1ed6b6abd" translate="yes" xml:space="preserve">
          <source>This function creates a new Generator object (and the Variable object within), which does not work well with tf.function because (1) tf.function puts restrictions on Variable creation thus reset_global_generator can't be freely used inside tf.function; (2) redirecting a global variable to a new object is problematic with tf.function because the old object may be captured by a 'tf.function'ed function and still be used by it. A 'tf.function'ed function only keeps weak references to variables, so deleting a variable and then calling that function again may raise an error, as demonstrated by random_test.py/RandomTest.testResetGlobalGeneratorBadWithDefun .</source>
          <target state="translated">이 함수는 (1) tf.function이 변수 생성을 제한하므로 reset_global_generator를 tf.function 내에서 자유롭게 사용할 수 없기 때문에 tf.function에서 제대로 작동하지 않는 새로운 Generator 객체 (및 그 안에있는 Variable 객체)를 만듭니다. (2) 전역 변수를 새 객체로 리디렉션하는 것은 tf.function에 문제가 있습니다. 이전 객체는 'tf.function'ed 함수에 의해 캡처되어 여전히 사용될 수 있기 때문입니다. 'tf.function'ed 함수는 변수에 대한 약한 참조 만 유지하므로 random_test.py/RandomTest.testResetGlobalGeneratorBadWithDefun에 표시된 것처럼 변수를 삭제 한 다음 해당 함수를 다시 호출하면 오류가 발생할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7bd8be377fdf00edb4e98ffd4a0d17d3f66c21a2" translate="yes" xml:space="preserve">
          <source>This function divides &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;, forcing Python 2 semantics. That is, if &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are both integers then the result will be an integer. This is in contrast to Python 3, where division with &lt;code&gt;/&lt;/code&gt; is always a float while division with &lt;code&gt;//&lt;/code&gt; is always an integer.</source>
          <target state="translated">이 함수는 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 를 나누고 파이썬 2 의미를 강제합니다. 즉, &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 가 모두 정수이면 결과는 정수입니다. 이와 부문 파이썬 3에 대조적이다 &lt;code&gt;/&lt;/code&gt; 이 와 분열 동안 항상 부동이다 &lt;code&gt;//&lt;/code&gt; 이 항상 정수입니다.</target>
        </trans-unit>
        <trans-unit id="d24aa00a66ce40fc5a2092349ae7643f400f331a" translate="yes" xml:space="preserve">
          <source>This function enables you to use a &lt;a href=&quot;../dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; in a stateless &quot;tensor-in tensor-out&quot; expression, without creating a &lt;a href=&quot;../../compat/v1/data/iterator&quot;&gt;&lt;code&gt;tf.compat.v1.data.Iterator&lt;/code&gt;&lt;/a&gt;. This can be useful when your preprocessing transformations are expressed as a &lt;code&gt;Dataset&lt;/code&gt;, and you want to use the transformation at serving time. For example:</source>
          <target state="translated">이 기능을 사용하면 사용할 수 있습니다 &lt;a href=&quot;../dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; 을&lt;/a&gt; &quot;텐서-에서 텐서 아웃&quot;표현하는 만들지 않고 무에서 &lt;a href=&quot;../../compat/v1/data/iterator&quot;&gt; &lt;code&gt;tf.compat.v1.data.Iterator&lt;/code&gt; 을&lt;/a&gt; . 이는 전처리 변환이 &lt;code&gt;Dataset&lt;/code&gt; 으로 표시되고 서비스 제공시 변환을 사용하려는 경우에 유용 할 수 있습니다 . 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="af17991dd15e2b7fa7774cc8e8187690043ab3dd" translate="yes" xml:space="preserve">
          <source>This function exists only for backwards compatibility purposes; new code should use &lt;code&gt;__floordiv__&lt;/code&gt; via the syntax &lt;code&gt;x // y&lt;/code&gt;. Using &lt;code&gt;x // y&lt;/code&gt; communicates clearly that the result rounds down, and is forward compatible to Python 3.</source>
          <target state="translated">이 기능은 이전 버전과의 호환성을 위해서만 존재합니다. 새 코드는 구문 &lt;code&gt;x // y&lt;/code&gt; 를 통해 &lt;code&gt;__floordiv__&lt;/code&gt; 를 사용해야합니다 . &lt;code&gt;x // y&lt;/code&gt; 사용 하면 결과가 반올림되고 명확하게 전달되며 Python 3과 호환됩니다.</target>
        </trans-unit>
        <trans-unit id="1a2f6439e571c218e4f990c2f6f9f31b011962aa" translate="yes" xml:space="preserve">
          <source>This function exists only to have a better error message. Instead of: &lt;code&gt;TypeError: unsupported operand type(s) for /: 'Dimension' and 'int'&lt;/code&gt;, this function will explicitly call for usage of &lt;code&gt;//&lt;/code&gt; instead.</source>
          <target state="translated">이 기능은 더 나은 오류 메시지를 표시하기 위해 존재합니다. 대신 : &lt;code&gt;TypeError: unsupported operand type(s) for /: 'Dimension' and 'int'&lt;/code&gt; 이 대신 이 함수는 &lt;code&gt;//&lt;/code&gt; 대신 사용을 명시 적으로 호출 합니다.</target>
        </trans-unit>
        <trans-unit id="6bf09410a9b47558afad7eb9fc6a9929885c6dd9" translate="yes" xml:space="preserve">
          <source>This function exists only to have a better error message. Instead of: &lt;code&gt;TypeError: unsupported operand type(s) for /: 'int' and 'Dimension'&lt;/code&gt;, this function will explicitly call for usage of &lt;code&gt;//&lt;/code&gt; instead.</source>
          <target state="translated">이 기능은 더 나은 오류 메시지를 표시하기 위해 존재합니다. 대신 : &lt;code&gt;TypeError: unsupported operand type(s) for /: 'int' and 'Dimension'&lt;/code&gt; 이 대신 이 함수는 &lt;code&gt;//&lt;/code&gt; 대신 사용을 명시 적으로 호출 합니다.</target>
        </trans-unit>
        <trans-unit id="7046a2ab2d223422699f2f1db88f8efbcff064ed" translate="yes" xml:space="preserve">
          <source>This function exports the graph, saver, and collection objects into &lt;code&gt;MetaGraphDef&lt;/code&gt; protocol buffer with the intention of it being imported at a later time or location to restart training, run inference, or be a subgraph.</source>
          <target state="translated">이 기능 은 나중에 다시 시작하거나 훈련을 시작하거나 추론을 실행하거나 하위 그래프가 될 수 있도록 그래프, 보호기 및 수집 객체를 &lt;code&gt;MetaGraphDef&lt;/code&gt; 프로토콜 버퍼 로 내 보냅니다 .</target>
        </trans-unit>
        <trans-unit id="6a27fb60b44269b202e3c908e7cb802642c2ac28" translate="yes" xml:space="preserve">
          <source>This function forces Python 3 division operator semantics where all integer arguments are cast to floating types first. This op is generated by normal &lt;code&gt;x / y&lt;/code&gt; division in Python 3 and in Python 2.7 with &lt;code&gt;from __future__ import division&lt;/code&gt;. If you want integer division that rounds down, use &lt;code&gt;x // y&lt;/code&gt; or &lt;code&gt;tf.math.floordiv&lt;/code&gt;.</source>
          <target state="translated">이 함수는 모든 정수 인수가 부동 유형으로 먼저 캐스팅되는 Python 3 나누기 연산자 시맨틱을 강제합니다. 이 연산은 파이썬 3과 파이썬 2.7 &lt;code&gt;from __future__ import division&lt;/code&gt; 으로 일반 &lt;code&gt;x / y&lt;/code&gt; 나누기에 의해 생성됩니다 . 반올림하는 정수 나누기를 원하면 &lt;code&gt;x // y&lt;/code&gt; 또는 &lt;code&gt;tf.math.floordiv&lt;/code&gt; 를 사용하십시오 .</target>
        </trans-unit>
        <trans-unit id="b139bf71180b25aa620a27f39c22f066fe31fcf7" translate="yes" xml:space="preserve">
          <source>This function generalizes the &lt;a href=&quot;non_max_suppression&quot;&gt;&lt;code&gt;tf.image.non_max_suppression&lt;/code&gt;&lt;/a&gt; op by also supporting a Soft-NMS (with Gaussian weighting) mode (c.f. Bodla et al, https://arxiv.org/abs/1704.04503) where boxes reduce the score of other overlapping boxes instead of directly causing them to be pruned. Consequently, in contrast to &lt;a href=&quot;non_max_suppression&quot;&gt;&lt;code&gt;tf.image.non_max_suppression&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;tf.image.non_max_suppression_v2&lt;/code&gt; returns the new scores of each input box in the second output, &lt;code&gt;selected_scores&lt;/code&gt;.</source>
          <target state="translated">이 함수 는 상자가 다른 겹치는 상자의 점수를 줄이는 Soft-NMS (가우시안 가중) 모드 (cf Bodla et al, https://arxiv.org/abs/1704.04503)도 지원 하여 &lt;a href=&quot;non_max_suppression&quot;&gt; &lt;code&gt;tf.image.non_max_suppression&lt;/code&gt; &lt;/a&gt; op를 일반화합니다. 직접 잘라내는 대신 따라서, 달리 &lt;a href=&quot;non_max_suppression&quot;&gt; &lt;code&gt;tf.image.non_max_suppression&lt;/code&gt; &lt;/a&gt; , &lt;code&gt;tf.image.non_max_suppression_v2&lt;/code&gt; , 상기 제 2 출력의 각 입력 박스의 새로운 스코어를 반환 &lt;code&gt;selected_scores&lt;/code&gt; 를 .</target>
        </trans-unit>
        <trans-unit id="1f78cfdbddd70d6ebd322125da902964ca2c0221" translate="yes" xml:space="preserve">
          <source>This function generates a weighted sum based on output dimension &lt;code&gt;units&lt;/code&gt;. Weighted sum refers to logits in classification problems. It refers to the prediction itself for linear regression problems.</source>
          <target state="translated">이 함수는 출력 차원 &lt;code&gt;units&lt;/code&gt; 기반으로 가중치 합계를 생성합니다 . 가중 합은 분류 문제의 로짓을 나타냅니다. 선형 회귀 문제에 대한 예측 자체를 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="b7164aa4227947230adf26e333ecf50d207f9d4e" translate="yes" xml:space="preserve">
          <source>This function ignores flags whose value is None. Each flag assignment is separated by a newline.</source>
          <target state="translated">이 함수는 값이 None 인 플래그를 무시합니다. 각 플래그 할당은 개행으로 구분됩니다.</target>
        </trans-unit>
        <trans-unit id="0c81aeff7442b1d7f71d30de1b5da89dfe187de7" translate="yes" xml:space="preserve">
          <source>This function in addition also allows assignment to a sliced range. This is similar to &lt;code&gt;__setitem__&lt;/code&gt; functionality in Python. However, the syntax is different so that the user can capture the assignment operation for grouping or passing to &lt;code&gt;sess.run()&lt;/code&gt;. For example,</source>
          <target state="translated">이 기능은 또한 슬라이스 범위에 할당 할 수 있습니다. 이것은 파이썬의 &lt;code&gt;__setitem__&lt;/code&gt; 기능 과 비슷합니다 . 그러나 사용자가 그룹화하거나 &lt;code&gt;sess.run()&lt;/code&gt; 전달하기위한 할당 작업을 캡처 할 수 있도록 구문이 다릅니다 . 예를 들어</target>
        </trans-unit>
        <trans-unit id="f477dc6f411c004d0b07e1741886385a8bad1741" translate="yes" xml:space="preserve">
          <source>This function is a more primitive version of &lt;code&gt;dynamic_rnn&lt;/code&gt; that provides more direct access to the inputs each iteration. It also provides more control over when to start and finish reading the sequence, and what to emit for the output.</source>
          <target state="translated">이 함수는 각 반복마다 입력에 더 직접 액세스 할 수 있는보다 원시적 인 &lt;code&gt;dynamic_rnn&lt;/code&gt; 버전입니다 . 또한 시퀀스 읽기 시작 및 완료시기와 출력을 위해 무엇을 방출해야하는지에 대한 더 많은 제어 기능을 제공합니다.</target>
        </trans-unit>
        <trans-unit id="b35cb926e7e56c5e0bb4984bfdd19c6c71696446" translate="yes" xml:space="preserve">
          <source>This function is a simpler wrapper around the more general &lt;a href=&quot;convolution&quot;&gt;&lt;code&gt;tf.nn.convolution&lt;/code&gt;&lt;/a&gt;, and exists only for backwards compatibility. You can use &lt;a href=&quot;convolution&quot;&gt;&lt;code&gt;tf.nn.convolution&lt;/code&gt;&lt;/a&gt; to perform 1-D, 2-D, or 3-D atrous convolution.</source>
          <target state="translated">이 함수는보다 일반적인 &lt;a href=&quot;convolution&quot;&gt; &lt;code&gt;tf.nn.convolution&lt;/code&gt; 에&lt;/a&gt; 대한 간단한 래퍼 이며 이전 버전과의 호환성을 위해서만 존재합니다. &lt;a href=&quot;convolution&quot;&gt; &lt;code&gt;tf.nn.convolution&lt;/code&gt; &lt;/a&gt; 을 사용하여 1-D, 2D 또는 3D 집중 컨볼 루션을 수행 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="1fde94a598e8772eaea3cc47dd741a3aa23b5c85" translate="yes" xml:space="preserve">
          <source>This function is analogous to &lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.pinv.html&quot;&gt;&lt;code&gt;numpy.linalg.pinv&lt;/code&gt;&lt;/a&gt;. It differs only in default value of &lt;code&gt;rcond&lt;/code&gt;. In &lt;code&gt;numpy.linalg.pinv&lt;/code&gt;, the default &lt;code&gt;rcond&lt;/code&gt; is &lt;code&gt;1e-15&lt;/code&gt;. Here the default is &lt;code&gt;10. * max(num_rows, num_cols) * np.finfo(dtype).eps&lt;/code&gt;.</source>
          <target state="translated">이 함수는 &lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.pinv.html&quot;&gt; &lt;code&gt;numpy.linalg.pinv&lt;/code&gt; 와&lt;/a&gt; 유사합니다 . &lt;code&gt;rcond&lt;/code&gt; 의 기본값 만 다릅니다 . 에서 &lt;code&gt;numpy.linalg.pinv&lt;/code&gt; , 기본 &lt;code&gt;rcond&lt;/code&gt; 은 입니다 &lt;code&gt;1e-15&lt;/code&gt; . 여기서, 디폴트는 &lt;code&gt;10. * max(num_rows, num_cols) * np.finfo(dtype).eps&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c82b17de9fe920f72f7a5369e74c77b8a5f75d81" translate="yes" xml:space="preserve">
          <source>This function is based on the standard SSIM implementation from: Wang, Z., Bovik, A. C., Sheikh, H. R., &amp;amp; Simoncelli, E. P. (2004). Image quality assessment: from error visibility to structural similarity. IEEE transactions on image processing.</source>
          <target state="translated">이 기능은 Wang, Z., Bovik, AC, Sheikh, HR 및 Simoncelli, EP (2004)의 표준 SSIM 구현을 기반으로합니다. 이미지 품질 평가 : 오류 가시성에서 구조적 유사성까지. 이미지 처리에 관한 IEEE 트랜잭션.</target>
        </trans-unit>
        <trans-unit id="ecacc04269db8f28f91780c2b346f24c2d101704" translate="yes" xml:space="preserve">
          <source>This function is called between epochs/steps, when a metric is evaluated during training.</source>
          <target state="translated">이 기능은 훈련 중에 메트릭을 평가할 때 에포크 / 스텝간에 호출됩니다.</target>
        </trans-unit>
        <trans-unit id="a75cbe1aa934dcb50e2537aae264b28dbab09250" translate="yes" xml:space="preserve">
          <source>This function is called by FLAGS(argv). It scans the input list for a flag that looks like: --flagfile=</source>
          <target state="translated">이 함수는 FLAGS (argv)에 의해 호출됩니다. 다음과 같은 플래그에 대한 입력 목록을 스캔합니다. --flagfile =</target>
        </trans-unit>
        <trans-unit id="e57b5dff2b7e230f6a359d3b07cb810778cc3047" translate="yes" xml:space="preserve">
          <source>This function is called in the main TensorFlow &lt;code&gt;__init__.py&lt;/code&gt; file, user should not need to call it, except during complex migrations.</source>
          <target state="translated">이 함수는 기본 TensorFlow &lt;code&gt;__init__.py&lt;/code&gt; 파일에서 호출되므로 복잡한 마이그레이션을 제외하고 사용자가 호출 할 필요가 없습니다.</target>
        </trans-unit>
        <trans-unit id="0831cfa041ba84a9c1bb953a8575728ee9dbe8bf" translate="yes" xml:space="preserve">
          <source>This function is faster and numerically stabler than &lt;code&gt;bessel_i0(x)&lt;/code&gt;.</source>
          <target state="translated">이 함수는 &lt;code&gt;bessel_i0(x)&lt;/code&gt; 보다 빠르고 수치 적으로 안정적 입니다.</target>
        </trans-unit>
        <trans-unit id="1f2e499db54e57708a372078c16af5df37036099" translate="yes" xml:space="preserve">
          <source>This function is faster and numerically stabler than &lt;code&gt;bessel_i1(x)&lt;/code&gt;.</source>
          <target state="translated">이 함수는 &lt;code&gt;bessel_i1(x)&lt;/code&gt; 보다 빠르고 수치 적으로 안정적 입니다.</target>
        </trans-unit>
        <trans-unit id="d7e374cf0f52d98689ddb22ec7b9e2a428cd4956" translate="yes" xml:space="preserve">
          <source>This function is implemented using a queue. A &lt;code&gt;QueueRunner&lt;/code&gt; for the queue is added to the current &lt;code&gt;Graph&lt;/code&gt;'s &lt;code&gt;QUEUE_RUNNER&lt;/code&gt; collection.</source>
          <target state="translated">이 기능은 대기열을 사용하여 구현됩니다. &lt;code&gt;QueueRunner&lt;/code&gt; 큐의 현재에 첨가 &lt;code&gt;Graph&lt;/code&gt; 의 &lt;code&gt;QUEUE_RUNNER&lt;/code&gt; 의 컬렉션.</target>
        </trans-unit>
        <trans-unit id="4c4c3026638168daaa4ab1a3c114680f01d9d246" translate="yes" xml:space="preserve">
          <source>This function is more numerically stable than log(sum(exp(input))). It avoids overflows caused by taking the exp of large inputs and underflows caused by taking the log of small inputs.</source>
          <target state="translated">이 함수는 log (sum (exp (input)))보다 수치 적으로 안정적입니다. 큰 입력의 소비로 인한 오버플로와 작은 입력의 로그로 인한 언더 플로를 방지합니다.</target>
        </trans-unit>
        <trans-unit id="80c0f02cfab4a0ee1574d2a1145f5fca28f12b11" translate="yes" xml:space="preserve">
          <source>This function is only available with the TensorFlow backend for the time being.</source>
          <target state="translated">이 기능은 당분간 TensorFlow 백엔드에서만 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="11a7ac7f028baf06c483242a158777b17ee8b353" translate="yes" xml:space="preserve">
          <source>This function is only used when defining a new op type. It may be used for ops such as &lt;a href=&quot;size&quot;&gt;&lt;code&gt;tf.size()&lt;/code&gt;&lt;/a&gt; that are not differentiable. For example:</source>
          <target state="translated">이 기능은 새로운 op 유형을 정의 할 때만 사용됩니다. 차별화 할 수없는 &lt;a href=&quot;size&quot;&gt; &lt;code&gt;tf.size()&lt;/code&gt; &lt;/a&gt; 와 같은 연산에 사용될 수 있습니다 . 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="577a32736f43471cd2cd1266738343fb80596d48" translate="yes" xml:space="preserve">
          <source>This function is the canonical way to get/validate an object of one of the allowed types from an external argument reference in the Session API.</source>
          <target state="translated">이 함수는 세션 API의 외부 인수 참조에서 허용 된 유형 중 하나의 객체를 가져 오거나 확인하는 표준 방법입니다.</target>
        </trans-unit>
        <trans-unit id="691cc7f8251e205cf948be38afb6e034f26a2e72" translate="yes" xml:space="preserve">
          <source>This function is used to perform parallel lookups on the list of tensors in &lt;code&gt;params&lt;/code&gt;. It is a generalization of &lt;a href=&quot;../../../gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt;, where &lt;code&gt;params&lt;/code&gt; is interpreted as a partitioning of a large embedding tensor. &lt;code&gt;params&lt;/code&gt; may be a &lt;code&gt;PartitionedVariable&lt;/code&gt; as returned by using &lt;a href=&quot;../get_variable&quot;&gt;&lt;code&gt;tf.compat.v1.get_variable()&lt;/code&gt;&lt;/a&gt; with a partitioner.</source>
          <target state="translated">이 함수는 &lt;code&gt;params&lt;/code&gt; 의 텐서 목록에서 병렬 조회를 수행하는 데 사용됩니다 . &lt;a href=&quot;../../../gather&quot;&gt; &lt;code&gt;tf.gather&lt;/code&gt; &lt;/a&gt; 의 일반화로 , &lt;code&gt;params&lt;/code&gt; 는 큰 임베딩 텐서의 분할로 해석됩니다. &lt;code&gt;params&lt;/code&gt; 는 &lt;code&gt;PartitionedVariable&lt;/code&gt; &lt;a href=&quot;../get_variable&quot;&gt; &lt;code&gt;tf.compat.v1.get_variable()&lt;/code&gt; &lt;/a&gt; 함께 tf.compat.v1.get_variable () 을 사용하여 반환 된 PartitionedVariable 일 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="237e26d699d02ce05b0e4079a36fba68db8a8789" translate="yes" xml:space="preserve">
          <source>This function is used to perform parallel lookups on the list of tensors in &lt;code&gt;params&lt;/code&gt;. It is a generalization of &lt;a href=&quot;../gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt;, where &lt;code&gt;params&lt;/code&gt; is interpreted as a partitioning of a large embedding tensor. &lt;code&gt;params&lt;/code&gt; may be a &lt;code&gt;PartitionedVariable&lt;/code&gt; as returned by using &lt;a href=&quot;../compat/v1/get_variable&quot;&gt;&lt;code&gt;tf.compat.v1.get_variable()&lt;/code&gt;&lt;/a&gt; with a partitioner.</source>
          <target state="translated">이 함수는 &lt;code&gt;params&lt;/code&gt; 의 텐서 목록에서 병렬 조회를 수행하는 데 사용됩니다 . &lt;a href=&quot;../gather&quot;&gt; &lt;code&gt;tf.gather&lt;/code&gt; &lt;/a&gt; 의 일반화로 , &lt;code&gt;params&lt;/code&gt; 는 큰 임베딩 텐서의 분할로 해석됩니다. &lt;code&gt;params&lt;/code&gt; 는 &lt;code&gt;PartitionedVariable&lt;/code&gt; &lt;a href=&quot;../compat/v1/get_variable&quot;&gt; &lt;code&gt;tf.compat.v1.get_variable()&lt;/code&gt; &lt;/a&gt; 함께 tf.compat.v1.get_variable () 을 사용하여 반환 된 PartitionedVariable 일 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="f577da20d8fc0c2379f7e51688987afe782aa9c2" translate="yes" xml:space="preserve">
          <source>This function is useful for unit testing. A unit test can test using the mixed precision graph rewrite, then disable it so future unit tests continue using float32.</source>
          <target state="translated">이 기능은 단위 테스트에 유용합니다. 단위 테스트는 혼합 정밀도 그래프 다시 쓰기를 사용하여 테스트 한 다음 비활성화하여 향후 단위 테스트에서 float32를 계속 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="d61d06f477fe487d45a847bca66c249257c10fe4" translate="yes" xml:space="preserve">
          <source>This function is useful for unit testing. A unit tests can test using the mixed precision graph rewrite, then disable it so future unit tests continue using float32. If this is done, unit tests should not share a single session, as &lt;code&gt;enable_mixed_precision_graph_rewrite&lt;/code&gt; and &lt;code&gt;disable_mixed_precision_graph_rewrite&lt;/code&gt; have no effect on existing sessions.</source>
          <target state="translated">이 기능은 단위 테스트에 유용합니다. 단위 테스트는 혼합 정밀도 그래프 다시 쓰기를 사용하여 테스트 한 다음 비활성화하여 향후 단위 테스트에서 float32를 계속 사용할 수 있습니다. 이것이 완료되면 &lt;code&gt;enable_mixed_precision_graph_rewrite&lt;/code&gt; 및 &lt;code&gt;disable_mixed_precision_graph_rewrite&lt;/code&gt; 는 기존 세션에 영향을 미치지 않으므로 단위 테스트는 단일 세션을 공유하지 않아야 합니다.</target>
        </trans-unit>
        <trans-unit id="d4e537bea1c76cb2cbcdaeafa3c9baedcb0e335e" translate="yes" xml:space="preserve">
          <source>This function may be used in the &lt;code&gt;options&lt;/code&gt; argument in functions that save a SavedModel (&lt;a href=&quot;save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../keras/models/save_model&quot;&gt;&lt;code&gt;tf.keras.models.save_model&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">이 함수는 SavedModel ( &lt;a href=&quot;save&quot;&gt; &lt;code&gt;tf.saved_model.save&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;../keras/models/save_model&quot;&gt; &lt;code&gt;tf.keras.models.save_model&lt;/code&gt; &lt;/a&gt; ) 을 저장하는 함수 의 &lt;code&gt;options&lt;/code&gt; 인수에 사용될 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="23d4449e48af4e4a9efae86d49cf037eac266df3" translate="yes" xml:space="preserve">
          <source>This function only gets the device policy for the current thread. Any subsequently started thread will again use the default policy.</source>
          <target state="translated">이 함수는 현재 스레드에 대한 장치 정책 만 가져옵니다. 이후에 시작된 스레드는 기본 정책을 다시 사용합니다.</target>
        </trans-unit>
        <trans-unit id="69c8cb582945069c7d9496b069e6902700fc7e3d" translate="yes" xml:space="preserve">
          <source>This function only sets the device policy for the current thread. Any subsequently started thread will again use the default policy.</source>
          <target state="translated">이 기능은 현재 스레드에 대한 장치 정책 만 설정합니다. 이후에 시작된 스레드는 기본 정책을 다시 사용합니다.</target>
        </trans-unit>
        <trans-unit id="128baaf391e006514e7e2e442ed3dbb64e14a3c9" translate="yes" xml:space="preserve">
          <source>This function performs the equivalent of</source>
          <target state="translated">이 기능은</target>
        </trans-unit>
        <trans-unit id="fac08ba1f46139129a2f42247910a712f1085f49" translate="yes" xml:space="preserve">
          <source>This function prefixes the name with the current variable scope and performs reuse checks. See the &lt;a href=&quot;https://tensorflow.org/guide/variables&quot;&gt;Variable Scope How To&lt;/a&gt; for an extensive description of how reusing works. Here is a basic example:</source>
          <target state="translated">이 함수는 이름 앞에 현재 변수 범위를 붙이고 재사용 검사를 수행합니다. 재사용 작동 방법에 대한 자세한 설명은 &lt;a href=&quot;https://tensorflow.org/guide/variables&quot;&gt;변수 범위&lt;/a&gt; 사용법 을 참조하십시오 . 기본 예는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="85bc4aa7e8b39b071c3a83bcd2bcb628b96948b5" translate="yes" xml:space="preserve">
          <source>This function produces signatures intended for use with the TensorFlow Serving Classify API (tensorflow_serving/apis/prediction_service.proto), and so constrains the input and output types to those allowed by TensorFlow Serving.</source>
          <target state="translated">이 함수는 TensorFlow Serving Classify API (tensorflow_serving / apis / prediction_service.proto)와 함께 사용하도록 서명을 생성하므로 입력 및 출력 유형을 TensorFlow Serving에서 허용하는 유형으로 제한합니다.</target>
        </trans-unit>
        <trans-unit id="795898cb16fc0e553ecaa87cbe16e8417edef412" translate="yes" xml:space="preserve">
          <source>This function produces signatures intended for use with the TensorFlow Serving Predict API (tensorflow_serving/apis/prediction_service.proto). This API imposes no constraints on the input and output types.</source>
          <target state="translated">이 함수는 TensorFlow Serving Predict API (tensorflow_serving / apis / prediction_service.proto)와 함께 사용하도록 서명을 생성합니다. 이 API는 입력 및 출력 유형에 제한을 두지 않습니다.</target>
        </trans-unit>
        <trans-unit id="0bd91f24173f9c6c06caccaa86fb2987286936b9" translate="yes" xml:space="preserve">
          <source>This function produces signatures intended for use with the TensorFlow Serving Regress API (tensorflow_serving/apis/prediction_service.proto), and so constrains the input and output types to those allowed by TensorFlow Serving.</source>
          <target state="translated">이 함수는 TensorFlow Serving Regress API (tensorflow_serving / apis / prediction_service.proto)와 함께 사용하도록 서명을 생성하므로 입력 및 출력 유형을 TensorFlow Serving에서 허용하는 유형으로 제한합니다.</target>
        </trans-unit>
        <trans-unit id="da2207550b053f2e41ed03fce80a539629a65e2e" translate="yes" xml:space="preserve">
          <source>This function provides a way to import a serialized TensorFlow &lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto&quot;&gt;&lt;code&gt;GraphDef&lt;/code&gt;&lt;/a&gt; protocol buffer, and extract individual objects in the &lt;code&gt;GraphDef&lt;/code&gt; as &lt;a href=&quot;../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../operation&quot;&gt;&lt;code&gt;tf.Operation&lt;/code&gt;&lt;/a&gt; objects. Once extracted, these objects are placed into the current default &lt;code&gt;Graph&lt;/code&gt;. See &lt;a href=&quot;../graph#as_graph_def&quot;&gt;&lt;code&gt;tf.Graph.as_graph_def&lt;/code&gt;&lt;/a&gt; for a way to create a &lt;code&gt;GraphDef&lt;/code&gt; proto.</source>
          <target state="translated">이 함수는, 직렬화 TensorFlow 가져올 수있는 방법 제공 &lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto&quot;&gt; &lt;code&gt;GraphDef&lt;/code&gt; 의&lt;/a&gt; 프로토콜 버퍼를, 상기 개별 개체를 추출 &lt;code&gt;GraphDef&lt;/code&gt; 같은 &lt;a href=&quot;../tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;../operation&quot;&gt; &lt;code&gt;tf.Operation&lt;/code&gt; &lt;/a&gt; 개체. 추출 된 객체는 현재 기본 &lt;code&gt;Graph&lt;/code&gt; 에 배치됩니다 . &lt;code&gt;GraphDef&lt;/code&gt; 프로토 를 생성하는 방법 은 &lt;a href=&quot;../graph#as_graph_def&quot;&gt; &lt;code&gt;tf.Graph.as_graph_def&lt;/code&gt; &lt;/a&gt; 를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="59bf9d9f9818c530570cd3baaed9172f0b655e0a" translate="yes" xml:space="preserve">
          <source>This function raises &lt;code&gt;ValueError&lt;/code&gt; unless it can be certain that the given &lt;code&gt;tensor&lt;/code&gt; is a scalar. &lt;code&gt;ValueError&lt;/code&gt; is also raised if the shape of &lt;code&gt;tensor&lt;/code&gt; is unknown.</source>
          <target state="translated">이 함수 는 주어진 &lt;code&gt;tensor&lt;/code&gt; 가 스칼라인지 확실하지 않은 경우 &lt;code&gt;ValueError&lt;/code&gt; 를 발생시킵니다 . &lt;code&gt;tensor&lt;/code&gt; 의 모양을 알 수없는 경우에도 &lt;code&gt;ValueError&lt;/code&gt; 가 발생합니다 .</target>
        </trans-unit>
        <trans-unit id="a733b4ff78c36cb4d261221c5118416ce8061d8e" translate="yes" xml:space="preserve">
          <source>This function reinstantiates model state by: 1) loading model topology from json (this will eventually come from metagraph). 2) loading model weights from checkpoint.</source>
          <target state="translated">이 함수는 다음과 같이 모델 상태를 초기화합니다. 1) json에서 모델 토폴로지를로드합니다 (이는 결국 메타 그래프에서 가져옵니다). 2) 검사 점에서 모델 가중치로드.</target>
        </trans-unit>
        <trans-unit id="ff0b45b19346e757b8eb62e1bc7385c9d06f1d69" translate="yes" xml:space="preserve">
          <source>This function returns a tensor whose elements are defined by &lt;code&gt;equation&lt;/code&gt;, which is written in a shorthand form inspired by the Einstein summation convention. As an example, consider multiplying two matrices A and B to form a matrix C. The elements of C are given by:</source>
          <target state="translated">이 함수는 요소가 &lt;code&gt;equation&lt;/code&gt; 으로 정의 된 텐서를 반환하며 ,이 형식은 아인슈타인 합산 규칙에서 영감을 얻은 속기 형식으로 작성됩니다. 예를 들어, 두 개의 행렬 A와 B를 곱하여 행렬 C를 형성하는 것을 고려하십시오. C의 요소는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="0b7b7a286f6486a214583e48df98d413e08472ce" translate="yes" xml:space="preserve">
          <source>This function should &lt;em&gt;not&lt;/em&gt; be used for operations that have a well-defined gradient that is not yet implemented.</source>
          <target state="translated">아직 구현되지 않은 잘 정의 된 그래디언트가있는 작업 &lt;em&gt;에는&lt;/em&gt; 이 기능을 사용 &lt;em&gt;하지&lt;/em&gt; 않아야합니다.</target>
        </trans-unit>
        <trans-unit id="c538dca8aca927a7d8bbd1b0bb2e590f6c5ad3a5" translate="yes" xml:space="preserve">
          <source>This function supports a subset of tf.gather, see tf.gather for details on usage.</source>
          <target state="translated">이 함수는 tf.gather의 서브셋을 지원합니다. 사용법에 대한 자세한 내용은 tf.gather를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="e857d76db9c7bac209f1715cec1437cf523540d8" translate="yes" xml:space="preserve">
          <source>This function swaps half-spaces for all axes listed (defaults to all). Note that &lt;code&gt;y[0]&lt;/code&gt; is the Nyquist component only if &lt;code&gt;len(x)&lt;/code&gt; is even.</source>
          <target state="translated">이 기능은 나열된 모든 축에 대해 반 공백을 바꿉니다 (기본값은 모두). 참고로 &lt;code&gt;y[0]&lt;/code&gt; 에만 성분 인 나이키 스트 &lt;code&gt;len(x)&lt;/code&gt; 짝수이다.</target>
        </trans-unit>
        <trans-unit id="700dee7b88966a0547c5ef0b6e43b47147bea1dd" translate="yes" xml:space="preserve">
          <source>This function takes a &lt;code&gt;MetaGraphDef&lt;/code&gt; protocol buffer as input. If the argument is a file containing a &lt;code&gt;MetaGraphDef&lt;/code&gt; protocol buffer , it constructs a protocol buffer from the file content. The function then adds all the nodes from the &lt;code&gt;graph_def&lt;/code&gt; field to the current graph, recreates all the collections, and returns a saver constructed from the &lt;code&gt;saver_def&lt;/code&gt; field.</source>
          <target state="translated">이 함수는 &lt;code&gt;MetaGraphDef&lt;/code&gt; 프로토콜 버퍼를 입력으로 사용합니다. 인수가 &lt;code&gt;MetaGraphDef&lt;/code&gt; 프로토콜 버퍼를 포함하는 파일 인 경우 파일 컨텐츠에서 프로토콜 버퍼를 구성합니다. 그런 다음이 함수는 &lt;code&gt;graph_def&lt;/code&gt; 필드 의 모든 노드를 현재 그래프에 추가하고 모든 콜렉션을 다시 작성하며 &lt;code&gt;saver_def&lt;/code&gt; 필드 에서 구성된 세이버를 리턴 합니다.</target>
        </trans-unit>
        <trans-unit id="94fc01032dc6978adba1e0b4d64fc3f4b8d2c710" translate="yes" xml:space="preserve">
          <source>This function transforms a list of &lt;code&gt;num_samples&lt;/code&gt; sequences (lists of integers) into a 2D Numpy array of shape &lt;code&gt;(num_samples, num_timesteps)&lt;/code&gt;. &lt;code&gt;num_timesteps&lt;/code&gt; is either the &lt;code&gt;maxlen&lt;/code&gt; argument if provided, or the length of the longest sequence otherwise.</source>
          <target state="translated">이 함수는 &lt;code&gt;num_samples&lt;/code&gt; 시퀀스 (정수 목록) 목록을 2D Numpy 배열 모양 &lt;code&gt;(num_samples, num_timesteps)&lt;/code&gt; 합니다. &lt;code&gt;num_timesteps&lt;/code&gt; 는 제공된 경우 &lt;code&gt;maxlen&lt;/code&gt; 인수이거나 그렇지 않은 경우 가장 긴 시퀀스의 길이입니다.</target>
        </trans-unit>
        <trans-unit id="c60464500521000032d7d0dd44fb1270d9c6691c" translate="yes" xml:space="preserve">
          <source>This function transforms a sequence of word indexes (list of integers) into tuples of words of the form:</source>
          <target state="translated">이 함수는 일련의 단어 색인 (정수 목록)을 다음 형식의 단어 튜플로 변환합니다.</target>
        </trans-unit>
        <trans-unit id="0cf6cff1a07ce3f9dd6dd3457b8400fd6ba9faf8" translate="yes" xml:space="preserve">
          <source>This function uses substring matching, i.e. the matching succeeds if &lt;em&gt;any&lt;/em&gt; substring of the error message matches &lt;em&gt;any&lt;/em&gt; regex in the list. This is more convenient for the user than full-string matching.</source>
          <target state="translated">경우이 기능을 사용하는 하위 문자열 매칭, 즉 일치하는 성공 &lt;em&gt;어떤&lt;/em&gt; 오류 메시지의 문자열이 일치하는 &lt;em&gt;모든&lt;/em&gt; 목록에서 정규식. 이것은 전체 문자열 일치보다 사용자에게 더 편리합니다.</target>
        </trans-unit>
        <trans-unit id="6ea3c37a0724be70d72aba9456ec479ad3e1efd0" translate="yes" xml:space="preserve">
          <source>This function validates that &lt;code&gt;obj&lt;/code&gt; represents an element of this graph, and gives an informative error message if it is not.</source>
          <target state="translated">이 함수는 &lt;code&gt;obj&lt;/code&gt; 가이 그래프의 요소를 나타내는 지 확인하고 그렇지 않은 경우 유익한 오류 메시지를 제공합니다.</target>
        </trans-unit>
        <trans-unit id="89bde45a9d6e8e699bac43f2a09b2f06fe6c3d12" translate="yes" xml:space="preserve">
          <source>This function will modify the tensors passed in as it adds more operations and hence changing the consumers of the operations of the input tensors.</source>
          <target state="translated">이 함수는 더 많은 작업을 추가하고 입력 텐서 작업의 소비자를 변경함에 따라 전달 된 텐서를 수정합니다.</target>
        </trans-unit>
        <trans-unit id="e4e12e3274ef470af1606308b5afb5383f0e4373" translate="yes" xml:space="preserve">
          <source>This function works on either a single image (&lt;code&gt;image&lt;/code&gt; is a 3-D Tensor), or a batch of images (&lt;code&gt;image&lt;/code&gt; is a 4-D Tensor).</source>
          <target state="translated">이 기능은 단일 이미지 ( &lt;code&gt;image&lt;/code&gt; 는 3 차원 텐서) 또는 이미지 묶음 ( &lt;code&gt;image&lt;/code&gt; 는 4 차원 텐서)에서 작동합니다.</target>
        </trans-unit>
        <trans-unit id="3bc4d91f81e39f3ea54e11412256f8f82c2a442a" translate="yes" xml:space="preserve">
          <source>This function wraps tensor placeholders in a supervised_receiver_fn with the expectation that the features and labels appear precisely as the model_fn expects them. Features and labels can therefore be dicts of tensors, or raw tensors.</source>
          <target state="translated">이 함수는 기능 및 레이블이 model_fn에서 예상 한대로 정확하게 표시 될 것으로 예상하여 supervised_receiver_fn에서 텐서 자리 표시자를 랩핑합니다. 따라서 기능 및 레이블은 텐서 또는 원시 텐서의 기준이 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="061aef760e659c96c1579128f6e2913f90a85e0a" translate="yes" xml:space="preserve">
          <source>This has the effect of transforming sliding window operations into the corresponding &quot;atrous&quot; operation in which the input is sampled at the specified &lt;code&gt;dilation_rate&lt;/code&gt;.</source>
          <target state="translated">이는 슬라이딩 윈도우 작업을 입력이 지정된 &lt;code&gt;dilation_rate&lt;/code&gt; 로 샘플링되는 해당 &quot;atrous&quot;작업으로 변환하는 효과가 있습니다.</target>
        </trans-unit>
        <trans-unit id="10c41b6251ef0bcbec27e5d4c8ebb2292ccebcaa" translate="yes" xml:space="preserve">
          <source>This helper method provides a higher-level alternative to using &lt;code&gt;tf.contrib.summary.summary_writer_initializer_op&lt;/code&gt; and &lt;code&gt;tf.contrib.summary.graph&lt;/code&gt;.</source>
          <target state="translated">이 헬퍼 메소드는 &lt;code&gt;tf.contrib.summary.summary_writer_initializer_op&lt;/code&gt; 및 &lt;code&gt;tf.contrib.summary.graph&lt;/code&gt; 사용에 대한 상위 레벨 대안을 제공합니다 .</target>
        </trans-unit>
        <trans-unit id="671c9eb768ee498e26815ceb625e7ee7c309f7e7" translate="yes" xml:space="preserve">
          <source>This hook delays execution until global step reaches to &lt;code&gt;wait_until_step&lt;/code&gt;. It is used to gradually start workers in distributed settings. One example usage would be setting &lt;code&gt;wait_until_step=int(K*log(task_id+1))&lt;/code&gt; assuming that task_id=0 is the chief.</source>
          <target state="translated">이 후크는 글로벌 단계가 &lt;code&gt;wait_until_step&lt;/code&gt; 에 도달 할 때까지 실행을 지연 시킵니다 . 분산 설정에서 작업자를 점진적으로 시작하는 데 사용됩니다. 한 가지 사용법의 예 는 task_id = 0이 최고라고 가정하고 wait_until_step = &lt;code&gt;wait_until_step=int(K*log(task_id+1))&lt;/code&gt; 하는 것입니다.</target>
        </trans-unit>
        <trans-unit id="1a0fa0f63117915fa2c817fa42b4c67a4f5c8b33" translate="yes" xml:space="preserve">
          <source>This hook requests stop after either a number of steps have been executed or a last step has been reached. Only one of the two options can be specified.</source>
          <target state="translated">이 후크 요청은 여러 단계가 실행되었거나 마지막 단계에 도달 한 후에 중지됩니다. 두 옵션 중 하나만 지정할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="29326e19d0dc3f4c325692b2b9f948f424da0e4f" translate="yes" xml:space="preserve">
          <source>This hook saves the state of the iterators in the &lt;code&gt;Graph&lt;/code&gt; so that when training is resumed the input pipeline continues from where it left off. This could potentially avoid overfitting in certain pipelines where the number of training steps per eval are small compared to the dataset size or if the training pipeline is pre-empted.</source>
          <target state="translated">이 후크는 훈련이 재개 될 때 입력 파이프 라인이 중단 된 지점부터 계속되도록 &lt;code&gt;Graph&lt;/code&gt; 반복기의 상태를 저장합니다 . 이는 데이터 세트 크기에 비해 평가 당 교육 단계 수가 적거나 교육 파이프 라인이 선점 된 경우 특정 파이프 라인에서 과적 합을 피할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="362202ba29e8d6beed9c2059ae03ede13f3cd76f" translate="yes" xml:space="preserve">
          <source>This hook should be used if the input pipeline state needs to be saved separate from the model checkpoint. Doing so may be useful for a few reasons:</source>
          <target state="translated">입력 파이프 라인 상태를 모델 체크 포인트와 별도로 저장해야하는 경우이 후크를 사용해야합니다. 그렇게하는 것이 몇 가지 이유로 유용 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="b6ae1f6a6bb162ce4153046b8500ec1c1479c758" translate="yes" xml:space="preserve">
          <source>This identifies the replica that is part of a sync group. Currently we assume that all sync groups contain the same number of replicas. The value of the replica id can range from 0 to &lt;code&gt;num_replica_in_sync&lt;/code&gt; - 1.</source>
          <target state="translated">동기화 그룹의 일부인 복제본을 식별합니다. 현재 모든 동기화 그룹에 동일한 수의 복제본이 있다고 가정합니다. 복제본 ID 값의 범위는 0에서 &lt;code&gt;num_replica_in_sync&lt;/code&gt; -1입니다.</target>
        </trans-unit>
        <trans-unit id="ecd5efd797cabcd540fdce983afef271dcb8292a" translate="yes" xml:space="preserve">
          <source>This implementation of RMSprop uses plain momentum, not Nesterov momentum.</source>
          <target state="translated">이 RMSprop 구현은 Nesterov 모멘텀이 아닌 일반 모멘텀을 사용합니다.</target>
        </trans-unit>
        <trans-unit id="69398f914b35c5353b93476810576462db6eec45" translate="yes" xml:space="preserve">
          <source>This implements the anisotropic 2-D version of the formula described here:</source>
          <target state="translated">여기에 설명 된 이방성 2-D 버전의 수식이 구현됩니다.</target>
        </trans-unit>
        <trans-unit id="eaa40933c0c7c31f3c54363539d17de16903a6ff" translate="yes" xml:space="preserve">
          <source>This includes ops from TF 2.0 tf.summary and TF 1.x tf.contrib.summary (except for &lt;code&gt;tf.contrib.summary.graph&lt;/code&gt; and &lt;code&gt;tf.contrib.summary.import_event&lt;/code&gt;), but does &lt;em&gt;not&lt;/em&gt; include TF 1.x tf.summary ops.</source>
          <target state="translated">여기에는 TF 2.0 tf.summary 및 TF 1.x tf.contrib.summary ( &lt;code&gt;tf.contrib.summary.graph&lt;/code&gt; 및 &lt;code&gt;tf.contrib.summary.import_event&lt;/code&gt; 제외 )의 op 가 포함 되지만 TF 1.x는 포함 되지 &lt;em&gt;않습니다.&lt;/em&gt; 작전.</target>
        </trans-unit>
        <trans-unit id="2cbffbf5b87e7d08406cd7f76d2f7936c22b5d07" translate="yes" xml:space="preserve">
          <source>This includes the operations to synchronize replicas: aggregate gradients, apply to variables, increment global step, insert tokens to token queue.</source>
          <target state="translated">여기에는 복제본 동기화 작업 (그라데이션 집계, 변수에 적용, 전역 단계 증가, 토큰을 토큰 대기열에 삽입)이 포함됩니다.</target>
        </trans-unit>
        <trans-unit id="dc77baa2dba67576cde30b92064b3afa6abe84f1" translate="yes" xml:space="preserve">
          <source>This induces quasi-linear speedup on up to 8 GPUs.</source>
          <target state="translated">이는 최대 8 개의 GPU에서 준 선형 속도 향상을 유도합니다.</target>
        </trans-unit>
        <trans-unit id="9e91bcd2748922b865fbdb3c28f16a3f92c87b0e" translate="yes" xml:space="preserve">
          <source>This initializer assigns one entry in the table for each line in the file.</source>
          <target state="translated">이 이니셜 라이저는 파일의 각 줄에 대해 하나의 항목을 테이블에 할당합니다.</target>
        </trans-unit>
        <trans-unit id="93a30392533a2023857f78a57a8100de69db56b7" translate="yes" xml:space="preserve">
          <source>This initializes a new Kubernetes ClusterResolver. The ClusterResolver will attempt to talk to the Kubernetes master to retrieve all the instances of pods matching a label selector.</source>
          <target state="translated">새로운 Kubernetes ClusterResolver가 초기화됩니다. ClusterResolver는 Kubernetes 마스터와 대화하여 레이블 선택기와 일치하는 모든 포드 인스턴스를 검색합니다.</target>
        </trans-unit>
        <trans-unit id="ded15c2fc6dc030fcd9627bdc75c00460c2cb65d" translate="yes" xml:space="preserve">
          <source>This is (mostly) a special case of &lt;a href=&quot;../math/add&quot;&gt;&lt;code&gt;tf.add&lt;/code&gt;&lt;/a&gt; where &lt;code&gt;bias&lt;/code&gt; is restricted to 1-D. Broadcasting is supported, so &lt;code&gt;value&lt;/code&gt; may have any number of dimensions. Unlike &lt;a href=&quot;../math/add&quot;&gt;&lt;code&gt;tf.add&lt;/code&gt;&lt;/a&gt;, the type of &lt;code&gt;bias&lt;/code&gt; is allowed to differ from &lt;code&gt;value&lt;/code&gt; in the case where both types are quantized.</source>
          <target state="translated">이 (주로)의 특별한 경우이다 &lt;a href=&quot;../math/add&quot;&gt; &lt;code&gt;tf.add&lt;/code&gt; &lt;/a&gt; &lt;code&gt;bias&lt;/code&gt; 1-D로 제한된다. 브로드 캐스팅이 지원되므로 &lt;code&gt;value&lt;/code&gt; 은 여러 차원을 가질 수 있습니다. 달리 &lt;a href=&quot;../math/add&quot;&gt; &lt;code&gt;tf.add&lt;/code&gt; &lt;/a&gt; 의 입력 &lt;code&gt;bias&lt;/code&gt; 다를 수있다 &lt;code&gt;value&lt;/code&gt; 두 종류가 양자화되는 경우.</target>
        </trans-unit>
        <trans-unit id="9f67d123191520f4a8994999dc8cd88f7fe320b7" translate="yes" xml:space="preserve">
          <source>This is EXPERIMENTAL and subject to change.</source>
          <target state="translated">이것은 실험적인 것이며 변경 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="02f8d625292f24a8f6fa6d8a843ae5c003159e97" translate="yes" xml:space="preserve">
          <source>This is a class method that describes what key/value arguments are required to instantiate the given &lt;code&gt;Distribution&lt;/code&gt; so that a particular shape is returned for that instance's call to &lt;code&gt;sample()&lt;/code&gt;.</source>
          <target state="translated">이것은 주어진 &lt;code&gt;Distribution&lt;/code&gt; 을 인스턴스화하기 위해 어떤 키 / 값 인수가 필요한지를 설명하는 클래스 메소드 로, &lt;code&gt;sample()&lt;/code&gt; 대한 해당 인스턴스 호출에 대해 특정 형태가 리턴됩니다 .</target>
        </trans-unit>
        <trans-unit id="012a7836bd88d1e3c2c595506564d4812be83ba5" translate="yes" xml:space="preserve">
          <source>This is a class method that describes what key/value arguments are required to instantiate the given &lt;code&gt;Distribution&lt;/code&gt; so that a particular shape is returned for that instance's call to &lt;code&gt;sample()&lt;/code&gt;. Assumes that the sample's shape is known statically.</source>
          <target state="translated">이것은 주어진 &lt;code&gt;Distribution&lt;/code&gt; 을 인스턴스화하기 위해 어떤 키 / 값 인수가 필요한지를 설명하는 클래스 메소드 로, &lt;code&gt;sample()&lt;/code&gt; 대한 해당 인스턴스 호출에 대해 특정 형태가 리턴됩니다 . 샘플의 모양이 정적으로 알려져 있다고 가정합니다.</target>
        </trans-unit>
        <trans-unit id="fead40a760af2fb3753f3e33415c41be437e055a" translate="yes" xml:space="preserve">
          <source>This is a companion method to &lt;code&gt;add_queue_runner()&lt;/code&gt;. It just starts threads for all queue runners collected in the graph. It returns the list of all threads.</source>
          <target state="translated">이것은 &lt;code&gt;add_queue_runner()&lt;/code&gt; 대한 동반 메소드 입니다. 그래프에서 수집 된 모든 큐 러너의 스레드 만 시작합니다. 모든 스레드 목록을 리턴합니다.</target>
        </trans-unit>
        <trans-unit id="309ae6e7b107ea04158b03fa5671cc2764a5cdf7" translate="yes" xml:space="preserve">
          <source>This is a context class that is passed to the user's input function and contains information about the compute replicas and input pipelines. The number of compute replicas (in sync training) helps compute the local batch size from the desired global batch size for each replica. The input pipeline information can be used to return a different subset of the input in each replica (for e.g. shard the input pipeline, use a different input source etc).</source>
          <target state="translated">이는 사용자의 입력 함수에 전달되는 컨텍스트 클래스이며 계산 복제본 및 입력 파이프 라인에 대한 정보를 포함합니다. 계산 복제본의 수 (동기 훈련)는 각 복제본에 대해 원하는 전역 배치 크기에서 로컬 배치 크기를 계산하는 데 도움이됩니다. 입력 파이프 라인 정보는 각 복제본에서 입력의 다른 서브 세트를 리턴하는 데 사용될 수 있습니다 (예 : 입력 파이프 라인의 샤드, 다른 입력 소스 사용 등).</target>
        </trans-unit>
        <trans-unit id="1659a3286a3bedb8cf721b60523b4bfde4d51caf" translate="yes" xml:space="preserve">
          <source>This is a convenience method that converts RGB images to float representation, adjusts their brightness, and then converts them back to the original data type. If several adjustments are chained, it is advisable to minimize the number of redundant conversions.</source>
          <target state="translated">이것은 RGB 이미지를 부동 표현으로 변환하고 밝기를 조정 한 다음 다시 원래 데이터 형식으로 변환하는 편리한 방법입니다. 여러 조정이 연결되어있는 경우 중복 변환 수를 최소화하는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="7bcc711030b8e6b303b05fbb2eadad7a51295960" translate="yes" xml:space="preserve">
          <source>This is a convenience method that converts RGB images to float representation, adjusts their contrast, and then converts them back to the original data type. If several adjustments are chained, it is advisable to minimize the number of redundant conversions.</source>
          <target state="translated">이것은 RGB 이미지를 부동 표현으로 변환하고 대비를 조정 한 다음 다시 원래 데이터 형식으로 변환하는 편리한 방법입니다. 여러 조정이 연결되어있는 경우 중복 변환 수를 최소화하는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="689582a22623e8b58ba6e0ed65682c48dc03d8f0" translate="yes" xml:space="preserve">
          <source>This is a convenience method that converts RGB images to float representation, converts them to HSV, add an offset to the saturation channel, converts back to RGB and then back to the original data type. If several adjustments are chained it is advisable to minimize the number of redundant conversions.</source>
          <target state="translated">이것은 RGB 이미지를 부동 표현으로 변환하고, HSV로 변환하고, 채도 채널에 오프셋을 추가하고, 다시 RGB로 변환 한 다음 원래 데이터 유형으로 다시 변환하는 편리한 방법입니다. 여러 조정이 연결되어있는 경우 중복 변환 수를 최소화하는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="157983bd7b4bf865fccf95ec9e2bc8ddd381392d" translate="yes" xml:space="preserve">
          <source>This is a convenience method that converts an RGB image to float representation, converts it to HSV, add an offset to the hue channel, converts back to RGB and then back to the original data type. If several adjustments are chained it is advisable to minimize the number of redundant conversions.</source>
          <target state="translated">이것은 RGB 이미지를 부동 표현으로 변환하고, HSV로 변환하고, 색조 채널에 오프셋을 추가하고, 다시 RGB로 변환 한 다음 원래 데이터 유형으로 다시 변환하는 편리한 방법입니다. 여러 조정이 연결되어있는 경우 중복 변환 수를 최소화하는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="8b85cb6fb2b17c1cfe1f8becbb4b4eeadf576adb" translate="yes" xml:space="preserve">
          <source>This is a convenience method that converts an image to uint8 representation, encodes it to jpeg with &lt;code&gt;jpeg_quality&lt;/code&gt;, decodes it, and then converts back to the original data type.</source>
          <target state="translated">이것은 이미지를 uint8 표현으로 변환하고 &lt;code&gt;jpeg_quality&lt;/code&gt; 를 사용하여 jpeg로 인코딩 한 다음 디코딩 한 다음 원래 데이터 유형으로 다시 변환하는 편리한 방법입니다 .</target>
        </trans-unit>
        <trans-unit id="ab28ad9476b59e4ae1d47c731d1e80592c84261d" translate="yes" xml:space="preserve">
          <source>This is a deprecated version of &lt;code&gt;fractional_avg_pool&lt;/code&gt;.</source>
          <target state="translated">이것은 사용되지 않는 &lt;code&gt;fractional_avg_pool&lt;/code&gt; 버전입니다 .</target>
        </trans-unit>
        <trans-unit id="89fac60f109fd0365fd768e5b0c1efda980aac29" translate="yes" xml:space="preserve">
          <source>This is a deprecated version of &lt;code&gt;fractional_max_pool&lt;/code&gt;.</source>
          <target state="translated">이것은 사용되지 않는 &lt;code&gt;fractional_max_pool&lt;/code&gt; 버전입니다 .</target>
        </trans-unit>
        <trans-unit id="066f7ab7935722a8bd3e79702ee438f7b2aad916" translate="yes" xml:space="preserve">
          <source>This is a difference between DatasetV1 and DatasetV2. DatasetV1 does not take anything in its constructor whereas in the DatasetV2, we expect subclasses to create a variant_tensor and pass it in to the super() call.</source>
          <target state="translated">이것은 DatasetV1과 DatasetV2의 차이점입니다. DatasetV1은 생성자에서 아무것도 가져 오지 않지만 DatasetV2에서는 하위 클래스가 variant_tensor를 만들어 super () 호출에 전달할 것으로 예상합니다.</target>
        </trans-unit>
        <trans-unit id="e7c85e6a460e7ff32a9089528b0d0f38042adaa0" translate="yes" xml:space="preserve">
          <source>This is a faster way to train a softmax classifier over a huge number of classes.</source>
          <target state="translated">이것은 많은 수의 클래스에서 softmax 분류기를 훈련시키는 가장 빠른 방법입니다.</target>
        </trans-unit>
        <trans-unit id="d7e11ee2edab133ca8b8374faafd78e7821ed539" translate="yes" xml:space="preserve">
          <source>This is a legacy behaviour of TensorFlow and is highly discouraged.</source>
          <target state="translated">이것은 TensorFlow의 레거시 동작이며 사용하지 않는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="a3be19c517fb6a6f6742dcaed9be8bb79e5a6a4d" translate="yes" xml:space="preserve">
          <source>This is a legacy version of the more general BatchToSpaceND.</source>
          <target state="translated">이것은보다 일반적인 BatchToSpaceND의 레거시 버전입니다.</target>
        </trans-unit>
        <trans-unit id="c2584be3bd38ee90f3ac17e87b40fd5fb1908bdb" translate="yes" xml:space="preserve">
          <source>This is a legacy version of the more general SpaceToBatchND.</source>
          <target state="translated">이것은 일반적인 SpaceToBatchND의 레거시 버전입니다.</target>
        </trans-unit>
        <trans-unit id="c0ae3cb7ef651d4c8fb957d4b4823d4c0713533f" translate="yes" xml:space="preserve">
          <source>This is a low-level interface for creating an &lt;code&gt;Operation&lt;/code&gt;. Most programs will not call this method directly, and instead use the Python op constructors, such as &lt;a href=&quot;constant&quot;&gt;&lt;code&gt;tf.constant()&lt;/code&gt;&lt;/a&gt;, which add ops to the default graph.</source>
          <target state="translated">이것은 &lt;code&gt;Operation&lt;/code&gt; 을 작성하기위한 저수준 인터페이스입니다 . 대부분의 프로그램은이 메소드를 직접 호출하지 않고 대신 기본 그래프에 op를 추가하는 &lt;a href=&quot;constant&quot;&gt; &lt;code&gt;tf.constant()&lt;/code&gt; &lt;/a&gt; 와 같은 Python op 생성자를 사용합니다 .</target>
        </trans-unit>
        <trans-unit id="1cd850dc655362d680df73debd3d92a42edd1883" translate="yes" xml:space="preserve">
          <source>This is a method that implementers of subclasses of &lt;code&gt;Layer&lt;/code&gt; or &lt;code&gt;Model&lt;/code&gt; can override if they need a state-creation step in-between layer instantiation and layer call.</source>
          <target state="translated">&lt;code&gt;Layer&lt;/code&gt; 또는 &lt;code&gt;Model&lt;/code&gt; 의 서브 클래스 구현자가 레이어 인스턴스화와 레이어 호출 사이에 상태 생성 단계가 필요한 경우 재정의 할 수 있는 방법입니다 .</target>
        </trans-unit>
        <trans-unit id="62c4042c7b665a4296b8d1a943304048eb64aec7" translate="yes" xml:space="preserve">
          <source>This is a nonzero integer. See the get_ident() function. Thread identifiers may be recycled when a thread exits and another thread is created. The identifier is available even after the thread has exited.</source>
          <target state="translated">이것은 0이 아닌 정수입니다. get_ident () 함수를 참조하십시오. 스레드 식별자는 스레드가 종료되고 다른 스레드가 작성 될 때 재활용 될 수 있습니다. 스레드가 종료 된 후에도 식별자를 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="31eb573dcb4f05e127842ce7a2c523b4f9fd2e61" translate="yes" xml:space="preserve">
          <source>This is a reduction created for Nvidia DGX-1 which assumes GPUs connects like that on DGX-1 machine. If you have different GPU inter-connections, it is likely that it would be slower than &lt;a href=&quot;reductiontoonedevice&quot;&gt;&lt;code&gt;tf.distribute.ReductionToOneDevice&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">이것은 GPU가 DGX-1 시스템에서와 같이 연결되는 것으로 가정하는 Nvidia DGX-1을 위해 작성된 축소입니다. 다른 GPU 상호 연결이있는 경우 &lt;a href=&quot;reductiontoonedevice&quot;&gt; &lt;code&gt;tf.distribute.ReductionToOneDevice&lt;/code&gt; &lt;/a&gt; 보다 느릴 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="81cb44c6cca42a31a07fbae208fd1a7a56619cfa" translate="yes" xml:space="preserve">
          <source>This is a stateless version of &lt;a href=&quot;../../../random/categorical&quot;&gt;&lt;code&gt;tf.random.categorical&lt;/code&gt;&lt;/a&gt;: if run twice with the same seeds, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</source>
          <target state="translated">이것은 &lt;a href=&quot;../../../random/categorical&quot;&gt; &lt;code&gt;tf.random.categorical&lt;/code&gt; &lt;/a&gt; 의 상태 비 저장 버전입니다 . 동일한 시드로 두 번 실행하면 동일한 의사 난수가 생성됩니다. 출력은 동일한 하드웨어 (및 CPU와 GPU 간)의 여러 실행에서 일관되지만 TensorFlow 버전 또는 비 CPU / GPU 하드웨어간에 변경 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="812a072511f22cc831859b50e28ff4fe62133693" translate="yes" xml:space="preserve">
          <source>This is a stateless version of &lt;a href=&quot;normal&quot;&gt;&lt;code&gt;tf.random.normal&lt;/code&gt;&lt;/a&gt;: if run twice with the same seeds, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</source>
          <target state="translated">이것은 &lt;a href=&quot;normal&quot;&gt; &lt;code&gt;tf.random.normal&lt;/code&gt; &lt;/a&gt; 의 상태 비 저장 버전입니다 . 동일한 시드로 두 번 실행하면 동일한 의사 난수가 생성됩니다. 출력은 동일한 하드웨어 (및 CPU와 GPU 간)의 여러 실행에서 일관되지만 TensorFlow 버전 또는 비 CPU / GPU 하드웨어간에 변경 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="dd6096e0d7eff9f42170cc05a1fe61ba85be91f4" translate="yes" xml:space="preserve">
          <source>This is a stateless version of &lt;a href=&quot;truncated_normal&quot;&gt;&lt;code&gt;tf.random.truncated_normal&lt;/code&gt;&lt;/a&gt;: if run twice with the same seeds, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</source>
          <target state="translated">이것은 &lt;a href=&quot;truncated_normal&quot;&gt; &lt;code&gt;tf.random.truncated_normal&lt;/code&gt; &lt;/a&gt; 의 상태 비 저장 버전입니다 . 동일한 시드로 두 번 실행하면 동일한 의사 난수가 생성됩니다. 출력은 동일한 하드웨어 (및 CPU와 GPU 간)의 여러 실행에서 일관되지만 TensorFlow 버전 또는 비 CPU / GPU 하드웨어간에 변경 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7b120804ac2994699c2b37663ac0990fd63dfd70" translate="yes" xml:space="preserve">
          <source>This is a stateless version of &lt;a href=&quot;uniform&quot;&gt;&lt;code&gt;tf.random.uniform&lt;/code&gt;&lt;/a&gt;: if run twice with the same seeds, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</source>
          <target state="translated">이것은 &lt;a href=&quot;uniform&quot;&gt; &lt;code&gt;tf.random.uniform&lt;/code&gt; &lt;/a&gt; 의 상태 비 저장 버전입니다 . 동일한 시드로 두 번 실행하면 동일한 의사 난수가 생성됩니다. 출력은 동일한 하드웨어 (및 CPU와 GPU 간)의 여러 실행에서 일관되지만 TensorFlow 버전 또는 비 CPU / GPU 하드웨어간에 변경 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="ada11b1aaca11d67319d958bd7d1da13f15ebb7f" translate="yes" xml:space="preserve">
          <source>This is a stateless version of &lt;code&gt;tf.categorical&lt;/code&gt;: if run twice with the same seeds, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</source>
          <target state="translated">이것은 &lt;code&gt;tf.categorical&lt;/code&gt; 의 상태 비 저장 버전입니다 . 동일한 시드로 두 번 실행하면 동일한 의사 난수가 생성됩니다. 출력은 동일한 하드웨어 (및 CPU와 GPU 간)의 여러 실행에서 일관되지만 TensorFlow 버전 또는 비 CPU / GPU 하드웨어간에 변경 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="9603abb8f073d177d05702e0bc2ac4de5a04a74c" translate="yes" xml:space="preserve">
          <source>This is a wrapper to the &lt;code&gt;hashing_trick&lt;/code&gt; function using &lt;code&gt;hash&lt;/code&gt; as the hashing function; unicity of word to index mapping non-guaranteed.</source>
          <target state="translated">해시 함수로 &lt;code&gt;hash&lt;/code&gt; 를 사용 하는 &lt;code&gt;hashing_trick&lt;/code&gt; 함수 의 래퍼입니다 . 보장되지 않은 단어 대 인덱스 매핑의 단일성.</target>
        </trans-unit>
        <trans-unit id="ac7a813777192ceaa721f12e2b167eefa5ce19d7" translate="yes" xml:space="preserve">
          <source>This is always checked statically, so this method returns nothing.</source>
          <target state="translated">항상 정적으로 검사되므로이 메소드는 아무 것도 반환하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="acb8330008d86d94ea39351a6992d0b396765e55" translate="yes" xml:space="preserve">
          <source>This is an abstract class which allows extensions to TensorFlow's object-based checkpointing (see &lt;a href=&quot;../checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt;). For example a wrapper for NumPy arrays:</source>
          <target state="translated">이 클래스는 TensorFlow의 객체 기반 검사 점에 대한 확장을 허용하는 추상 클래스입니다 ( &lt;a href=&quot;../checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; 참조 ). 예를 들어 NumPy 배열의 래퍼는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="8bbaa33b6f8b11a0355ba861cdf03d3e08622a92" translate="yes" xml:space="preserve">
          <source>This is an identity op (behaves like &lt;a href=&quot;../../identity&quot;&gt;&lt;code&gt;tf.identity&lt;/code&gt;&lt;/a&gt;) with the side effect of printing &lt;code&gt;data&lt;/code&gt; when evaluating.</source>
          <target state="translated">이것은 평가할 때 &lt;code&gt;data&lt;/code&gt; 를 인쇄하는 부작용 이있는 ID op ( &lt;a href=&quot;../../identity&quot;&gt; &lt;code&gt;tf.identity&lt;/code&gt; &lt;/a&gt; 와 동일 함 )입니다 .</target>
        </trans-unit>
        <trans-unit id="04be17d14e8556e45ddfd971016c00de8c4f5796" translate="yes" xml:space="preserve">
          <source>This is an implementation of cluster resolvers for Kubernetes. When given the the Kubernetes namespace and label selector for pods, we will retrieve the pod IP addresses of all running pods matching the selector, and return a ClusterSpec based on that information.</source>
          <target state="translated">이것은 Kubernetes에 대한 클러스터 리졸버의 구현입니다. 포드에 대한 Kubernetes 네임 스페이스 및 레이블 선택기가 제공되면 선택기와 일치하는 모든 실행중인 포드의 포드 IP 주소를 검색하고 해당 정보를 기반으로 ClusterSpec을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="fbfdd6a723bd3e94666f26590d4249971ef2fb48" translate="yes" xml:space="preserve">
          <source>This is an implementation of cluster resolvers for Slurm clusters. This allows the specification of jobs and task counts, number of tasks per node, number of GPUs on each node and number of GPUs for each task. It retrieves system attributes by Slurm environment variables, resolves allocated computing node names, constructs a cluster and returns a ClusterResolver object which can be use for distributed TensorFlow.</source>
          <target state="translated">이것은 Slurm 클러스터에 대한 클러스터 리졸버의 구현입니다. 이를 통해 작업 및 작업 수, 노드 당 작업 수, 각 노드의 GPU 수 및 각 작업의 GPU 수를 지정할 수 있습니다. Slurm 환경 변수로 시스템 속성을 검색하고 할당 된 컴퓨팅 노드 이름을 확인하며 클러스터를 구성하고 분산 TensorFlow에 사용할 수있는 ClusterResolver 객체를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="71688349367e3a46bf633affe83f7f67a539cf79" translate="yes" xml:space="preserve">
          <source>This is an implementation of cluster resolvers for the Google Cloud TPU service. As Cloud TPUs are in alpha, you will need to specify a API definition file for this to consume, in addition to a list of Cloud TPUs in your Google Cloud Platform project.</source>
          <target state="translated">Google Cloud TPU 서비스에 대한 클러스터 확인 자의 구현입니다. Cloud TPU가 알파이므로 Google Cloud Platform 프로젝트의 Cloud TPU 목록과 함께 사용할 API 정의 파일을 지정해야합니다.</target>
        </trans-unit>
        <trans-unit id="ad683e8f469fc31a1a6f2ec923965536267cfedf" translate="yes" xml:space="preserve">
          <source>This is an implementation of cluster resolvers for the Google Compute Engine instance group platform. By specifying a project, zone, and instance group, this will retrieve the IP address of all the instances within the instance group and return a ClusterResolver object suitable for use for distributed TensorFlow.</source>
          <target state="translated">Google Compute Engine 인스턴스 그룹 플랫폼을위한 클러스터 리졸버 구현입니다. 프로젝트, 영역 및 인스턴스 그룹을 지정하면 인스턴스 그룹 내의 모든 인스턴스의 IP 주소를 검색하고 분산 TensorFlow에 사용하기 적합한 ClusterResolver 객체를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="a371677e8e3150f82fcdcb41fbdf4b2aece50db2" translate="yes" xml:space="preserve">
          <source>This is an implementation of cluster resolvers when using TF_CONFIG to set information about the cluster. The cluster spec returned will be initialized from the TF_CONFIG environment variable.</source>
          <target state="translated">이것은 TF_CONFIG를 사용하여 클러스터에 대한 정보를 설정할 때 클러스터 확인 자의 구현입니다. 리턴 된 클러스터 스펙은 TF_CONFIG 환경 변수에서 초기화됩니다.</target>
        </trans-unit>
        <trans-unit id="f2e4a40b99bc22ad76a6b8d488160787266d96b7" translate="yes" xml:space="preserve">
          <source>This is because evaluating the gradient graph does not require evaluating the constant(1) op created in the forward pass.</source>
          <target state="translated">그래디언트 그래프를 평가할 때는 정방향 패스에서 생성 된 constant (1) op를 평가할 필요가 없기 때문입니다.</target>
        </trans-unit>
        <trans-unit id="b402b2ea93d17cfe8814c2e2dd9513661013af48" translate="yes" xml:space="preserve">
          <source>This is called to signal the hooks that a new session has been created. This has two essential differences with the situation in which &lt;code&gt;begin&lt;/code&gt; is called:</source>
          <target state="translated">새 세션이 작성되었음을 알리기 위해 호출됩니다. 여기에는 &lt;code&gt;begin&lt;/code&gt; 이라는 상황과 두 가지 근본적인 차이점이 있습니다 .</target>
        </trans-unit>
        <trans-unit id="e53a92d847e73238072fa6528b3217c26234a931" translate="yes" xml:space="preserve">
          <source>This is completely equivalent to the slightly longer code:</source>
          <target state="translated">이것은 약간 긴 코드와 완전히 같습니다.</target>
        </trans-unit>
        <trans-unit id="bb94386b1c4a4c290298db5397c611953054ddc2" translate="yes" xml:space="preserve">
          <source>This is convenient in interactive shells and &lt;a href=&quot;http://ipython.org&quot;&gt;IPython notebooks&lt;/a&gt;, as it avoids having to pass an explicit &lt;code&gt;Session&lt;/code&gt; object to run ops.</source>
          <target state="translated">이것은 ops를 실행하기 위해 명시적인 &lt;code&gt;Session&lt;/code&gt; 객체를 전달할 필요가 &lt;a href=&quot;http://ipython.org&quot;&gt;없으므로&lt;/a&gt; 대화식 쉘 및 IPython 노트북 에서 편리합니다 .</target>
        </trans-unit>
        <trans-unit id="9c4ed05585b78549393533536c5eaedd31668459" translate="yes" xml:space="preserve">
          <source>This is different from &lt;code&gt;get_collection()&lt;/code&gt; which always returns a copy of the collection list if it exists and never creates an empty collection.</source>
          <target state="translated">이것은 콜렉션리스트가 존재하는 경우 항상 콜렉션리스트의 사본을 리턴하고 빈 콜렉션을 작성하지 않는 &lt;code&gt;get_collection()&lt;/code&gt; 과 다릅니다 .</target>
        </trans-unit>
        <trans-unit id="6e7866f4c4c548ff00d81ad9995e04b7c1f8a6da" translate="yes" xml:space="preserve">
          <source>This is different from &lt;code&gt;get_collection_ref()&lt;/code&gt; which always returns the actual collection list if it exists in that it returns a new list each time it is called.</source>
          <target state="translated">이것은 &lt;code&gt;get_collection_ref()&lt;/code&gt; 와는 다릅니다. get_collection_ref () 는 호출 할 때마다 새 목록을 반환한다는 점에서 항상 실제 컬렉션 목록을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="731ffc6237ea1b1cd740ef79a9e5ef7a26a2d7c5" translate="yes" xml:space="preserve">
          <source>This is essentially a shortcut for &lt;code&gt;assign(self, value)&lt;/code&gt;.</source>
          <target state="translated">이것은 본질적으로 &lt;code&gt;assign(self, value)&lt;/code&gt; 의 지름길입니다 .</target>
        </trans-unit>
        <trans-unit id="0bbe53c86ac89d70d42d35929c4d3967934b3af3" translate="yes" xml:space="preserve">
          <source>This is essentially a shortcut for &lt;code&gt;assign_add(self, delta)&lt;/code&gt;.</source>
          <target state="translated">이것은 본질적으로 &lt;code&gt;assign_add(self, delta)&lt;/code&gt; 의 지름길입니다 .</target>
        </trans-unit>
        <trans-unit id="13da478f41797a8113b6021c13a3264c6404bfc3" translate="yes" xml:space="preserve">
          <source>This is essentially a shortcut for &lt;code&gt;assign_sub(self, delta)&lt;/code&gt;.</source>
          <target state="translated">이것은 본질적으로 &lt;code&gt;assign_sub(self, delta)&lt;/code&gt; 의 지름길입니다 .</target>
        </trans-unit>
        <trans-unit id="e2b79a6063d963599f65675c034b474bb3cf4380" translate="yes" xml:space="preserve">
          <source>This is essentially a shortcut for &lt;code&gt;count_up_to(self, limit)&lt;/code&gt;.</source>
          <target state="translated">이것은 본질적으로 &lt;code&gt;count_up_to(self, limit)&lt;/code&gt; 의 지름길입니다 .</target>
        </trans-unit>
        <trans-unit id="1f513c169143d5db244b63790e45478adc90df06" translate="yes" xml:space="preserve">
          <source>This is expected to return a constant value that will not be changed throughout its life cycle.</source>
          <target state="translated">이는 수명주기 내내 변경되지 않는 일정한 값을 반환 할 것으로 예상됩니다.</target>
        </trans-unit>
        <trans-unit id="cbd5047389c2714c42e18e715b6900b97495f191" translate="yes" xml:space="preserve">
          <source>This is for use with models that expect a single &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt; as an input feature, as opposed to a dict of features.</source>
          <target state="translated">이는 기능에 반대되는 것이 아니라 단일 &lt;code&gt;Tensor&lt;/code&gt; 또는 &lt;code&gt;SparseTensor&lt;/code&gt; 를 입력 기능으로 예상하는 모델에 사용됩니다 .</target>
        </trans-unit>
        <trans-unit id="4f78d4311c49702fc3e064ee729929a77dc6e0a0" translate="yes" xml:space="preserve">
          <source>This is implemented as a generalized linear model, see https://en.wikipedia.org/wiki/Generalized_linear_model.</source>
          <target state="translated">이것은 일반화 된 선형 모델로 구현됩니다 (https://en.wikipedia.org/wiki/Generalized_linear_model 참조).</target>
        </trans-unit>
        <trans-unit id="b5e2c7b524f309c97d9b307ab3f360df187084ea" translate="yes" xml:space="preserve">
          <source>This is intended to be used on signals (or images). Produces a PSNR value for each image in batch.</source>
          <target state="translated">신호 (또는 이미지)에 사용됩니다. 배치별로 각 이미지에 대한 PSNR 값을 생성합니다.</target>
        </trans-unit>
        <trans-unit id="5c8364ff06f44a0d2f95291cd9a883d7572dfead" translate="yes" xml:space="preserve">
          <source>This is just a shortcut for &lt;code&gt;variables_initializer(global_variables())&lt;/code&gt;</source>
          <target state="translated">이것은 &lt;code&gt;variables_initializer(global_variables())&lt;/code&gt; 의 바로 가기입니다.</target>
        </trans-unit>
        <trans-unit id="df7f814ad895f2447cfabb704fb289f9c5058c9f" translate="yes" xml:space="preserve">
          <source>This is just a shortcut for &lt;code&gt;variables_initializer(local_variables())&lt;/code&gt;</source>
          <target state="translated">이것은 &lt;code&gt;variables_initializer(local_variables())&lt;/code&gt; 의 바로 가기입니다.</target>
        </trans-unit>
        <trans-unit id="3f6a76852476cdaa13e9bdd3f2afe687e9e8f273" translate="yes" xml:space="preserve">
          <source>This is like &lt;code&gt;sigmoid_cross_entropy_with_logits()&lt;/code&gt; except that &lt;code&gt;pos_weight&lt;/code&gt;, allows one to trade off recall and precision by up- or down-weighting the cost of a positive error relative to a negative error.</source>
          <target state="translated">이처럼 &lt;code&gt;sigmoid_cross_entropy_with_logits()&lt;/code&gt; 것을 제외 &lt;code&gt;pos_weight&lt;/code&gt; , 위쪽으로 또는 아래쪽 가중치 네거티브 에러 포지티브 에러 상대적인 비용을 회수하고 정확도 트레이드 오프를 허용한다.</target>
        </trans-unit>
        <trans-unit id="45f8d315bd404d0acf0d22377d0fcd8dbfde7b6a" translate="yes" xml:space="preserve">
          <source>This is mathematically equivalent to the classic formula below, but the use of an &lt;code&gt;assign_sub&lt;/code&gt; op (the &lt;code&gt;&quot;-=&quot;&lt;/code&gt; in the formula) allows concurrent lockless updates to the variables:</source>
          <target state="translated">이는 수학적으로 아래의 고전적인 공식과 동일하지만 &lt;code&gt;assign_sub&lt;/code&gt; op ( 공식 의 &lt;code&gt;&quot;-=&quot;&lt;/code&gt; )를 사용하면 변수에 대한 동시 잠금없는 업데이트가 가능합니다.</target>
        </trans-unit>
        <trans-unit id="8c5b780da30371ec04532fe08dfb27ab4f7f20a6" translate="yes" xml:space="preserve">
          <source>This is more efficient than using separate &lt;a href=&quot;../reverse&quot;&gt;&lt;code&gt;tf.reverse&lt;/code&gt;&lt;/a&gt; ops.</source>
          <target state="translated">이것은 별도의 &lt;a href=&quot;../reverse&quot;&gt; &lt;code&gt;tf.reverse&lt;/code&gt; &lt;/a&gt; ops를 사용하는 것보다 효율적 입니다.</target>
        </trans-unit>
        <trans-unit id="eabc0e8c9ba11bd382b9ff6e31e4cc504e020ab9" translate="yes" xml:space="preserve">
          <source>This is more efficient than using separate &lt;a href=&quot;../reverse&quot;&gt;&lt;code&gt;tf.reverse&lt;/code&gt;&lt;/a&gt; ops. The &lt;code&gt;reverse&lt;/code&gt; and &lt;code&gt;exclusive&lt;/code&gt; kwargs can also be combined:</source>
          <target state="translated">이것은 별도의 &lt;a href=&quot;../reverse&quot;&gt; &lt;code&gt;tf.reverse&lt;/code&gt; &lt;/a&gt; ops를 사용하는 것보다 효율적 입니다. &lt;code&gt;reverse&lt;/code&gt; 및 &lt;code&gt;exclusive&lt;/code&gt; kwargs로도 결합 될 수있다 :</target>
        </trans-unit>
        <trans-unit id="80ea1c276768e8dc61eb8fd686066ffd896d6dd9" translate="yes" xml:space="preserve">
          <source>This is not a graph construction method, it does not add ops to the graph.</source>
          <target state="translated">이것은 그래프 생성 방법이 아니며 그래프에 op를 추가하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="be0ccfef7a257148d1bd487cc01dfdee2f9dcbb7" translate="yes" xml:space="preserve">
          <source>This is similar to &lt;code&gt;embedding_column&lt;/code&gt;, except that it produces a list of embedding columns that share the same embedding weights.</source>
          <target state="translated">이는 동일한 포함 가중치를 공유하는 포함 열 목록을 생성한다는 점을 제외하면 &lt;code&gt;embedding_column&lt;/code&gt; 과 유사합니다 .</target>
        </trans-unit>
        <trans-unit id="16ef5940d98e86cc048c2b1d955cc28ebe55e81d" translate="yes" xml:space="preserve">
          <source>This is supposed to be executed in the beginning of the chief/sync thread so that even if the total_num_replicas is less than replicas_to_aggregate, the model can still proceed as the replicas can compute multiple steps per variable update. Make sure: &lt;code&gt;num_tokens &amp;gt;= replicas_to_aggregate - total_num_replicas&lt;/code&gt;.</source>
          <target state="translated">이는 total / num_replicas가 replicas_to_aggregate보다 작더라도 복제본이 변수 업데이트 당 여러 단계를 계산할 수 있으므로 모델이 계속 진행될 수 있도록 chief / sync 스레드의 시작 부분에서 실행되어야합니다. &lt;code&gt;num_tokens &amp;gt;= replicas_to_aggregate - total_num_replicas&lt;/code&gt; 확인하십시오 .</target>
        </trans-unit>
        <trans-unit id="b0eb2e902e8ddf903b8c32989be7bc5b84650328" translate="yes" xml:space="preserve">
          <source>This is the Python 2.x counterpart to &lt;code&gt;__bool__()&lt;/code&gt; above.</source>
          <target state="translated">위의 &lt;code&gt;__bool__()&lt;/code&gt; 해당하는 Python 2.x 입니다.</target>
        </trans-unit>
        <trans-unit id="8d8b6a8f2029ea1fc60a937a0c43797bc06e4fc9" translate="yes" xml:space="preserve">
          <source>This is the V1 version of this layer that uses variable_scope's to create variables which works well with PartitionedVariables. Variable scopes are deprecated in V2, so the V2 version uses name_scopes instead. But currently that lacks support for partitioned variables. Use this if you need partitioned variables.</source>
          <target state="translated">이것은 variable_scope를 사용하여 PartitionedVariables와 잘 작동하는 변수를 만드는이 계층의 V1 버전입니다. 변수 범위는 V2에서 더 이상 사용되지 않으므로 V2 버전은 대신 name_scopes를 사용합니다. 그러나 현재는 분할 변수에 대한 지원이 부족합니다. 파티션 된 변수가 필요한 경우이를 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="f355bc341013b9a7925572a2dcb6ac68143ef849" translate="yes" xml:space="preserve">
          <source>This is the V2 version of this layer that uses name_scopes to create variables instead of variable_scopes. But this approach currently lacks support for partitioned variables. In that case, use the V1 version instead.</source>
          <target state="translated">이 레이어의 V2 버전은 name_scopes를 사용하여 variable_scopes 대신 변수를 만듭니다. 그러나이 방법에는 현재 분할 된 변수에 대한 지원이 없습니다. 이 경우 대신 V1 버전을 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="45048f38a2e249e88fc3cdaca3ce8480b40e2329" translate="yes" xml:space="preserve">
          <source>This is the angle ( \theta \in [-\pi, \pi] ) such that [ x = r \cos(\theta) ] and [ y = r \sin(\theta) ] where (r = \sqrt(x^2 + y^2) ).</source>
          <target state="translated">이것은 [x = r \ cos (\ theta)] 및 [y = r \ sin (\ theta)]와 같이 각도 (\ theta \ in [-\ pi, \ pi])입니다. 여기서 (r = \ sqrt ( x ^ 2 + y ^ 2)).</target>
        </trans-unit>
        <trans-unit id="d2e50218603262fb1a544e117d169f38db78b601" translate="yes" xml:space="preserve">
          <source>This is the base class for implementing RNN cells with custom behavior.</source>
          <target state="translated">이것은 커스텀 행동으로 RNN 셀을 구현하기위한 기본 클래스입니다.</target>
        </trans-unit>
        <trans-unit id="9e013372239f70ba2378635884ba4bb573e7d626" translate="yes" xml:space="preserve">
          <source>This is the class from which all layers inherit.</source>
          <target state="translated">이것은 모든 레이어가 상속하는 클래스입니다.</target>
        </trans-unit>
        <trans-unit id="8fa4ff7f2578477f255b6f02a47ae45758b90edc" translate="yes" xml:space="preserve">
          <source>This is the correct way to perform gradient clipping (for example, see &lt;a href=&quot;http://arxiv.org/abs/1211.5063&quot;&gt;Pascanu et al., 2012&lt;/a&gt; (&lt;a href=&quot;http://arxiv.org/pdf/1211.5063.pdf&quot;&gt;pdf&lt;/a&gt;)).</source>
          <target state="translated">그래디언트 클리핑을 수행하는 올바른 방법입니다 (예 : &lt;a href=&quot;http://arxiv.org/abs/1211.5063&quot;&gt;Pascanu et al., 2012&lt;/a&gt; ( &lt;a href=&quot;http://arxiv.org/pdf/1211.5063.pdf&quot;&gt;pdf&lt;/a&gt; ) 참조).</target>
        </trans-unit>
        <trans-unit id="76694ede23dda167a78335c0c1bd3e85284fad75" translate="yes" xml:space="preserve">
          <source>This is the crossentropy metric class to be used when there are multiple label classes (2 or more). Here we assume that labels are given as a &lt;code&gt;one_hot&lt;/code&gt; representation. eg., When labels values are [2, 0, 1], &lt;code&gt;y_true&lt;/code&gt; = [[0, 0, 1], [1, 0, 0], [0, 1, 0]].</source>
          <target state="translated">여러 레이블 클래스 (2 이상)가있을 때 사용되는 교차 엔트로피 메트릭 클래스입니다. 여기서 레이블은 &lt;code&gt;one_hot&lt;/code&gt; 표현으로 제공된다고 가정합니다 . 예를 들어, 라벨 값이 [2, 0, 1] 인 경우 &lt;code&gt;y_true&lt;/code&gt; = [[0, 0, 1], [1, 0, 0], [0, 1, 0]]입니다.</target>
        </trans-unit>
        <trans-unit id="d187cef3999e110bfd14733d1bc7141db46b4d0d" translate="yes" xml:space="preserve">
          <source>This is the crossentropy metric class to be used when there are only two label classes (0 and 1).</source>
          <target state="translated">이것은 두 개의 레이블 클래스 (0 및 1)가있을 때 사용되는 교차 엔트로피 메트릭 클래스입니다.</target>
        </trans-unit>
        <trans-unit id="fb90fff0e52ece653003dbcf512572b6437c5795" translate="yes" xml:space="preserve">
          <source>This is the dtype layers will create their variables in, unless a layer explicitly chooses a different dtype. If this is different than &lt;a href=&quot;policy#compute_dtype&quot;&gt;&lt;code&gt;Policy.compute_dtype&lt;/code&gt;&lt;/a&gt;, Layers will cast variables to the compute dtype to avoid type errors.</source>
          <target state="translated">레이어가 명시 적으로 다른 dtype을 선택하지 않는 한 이것은 dtype 레이어가 변수를 생성합니다. 이것이 &lt;a href=&quot;policy#compute_dtype&quot;&gt; &lt;code&gt;Policy.compute_dtype&lt;/code&gt; &lt;/a&gt; 와 다른 경우 과 레이어는 유형 오류를 피하기 위해 변수를 계산 dtype으로 캐스팅합니다.</target>
        </trans-unit>
        <trans-unit id="08b035fd1ef991c0ac17661834339a93b3d11556" translate="yes" xml:space="preserve">
          <source>This is the dtype layers will do their computations in.</source>
          <target state="translated">이것은 dtype 레이어가 계산을 수행하는 것입니다.</target>
        </trans-unit>
        <trans-unit id="5e888c610bf02b0ac69c58288afbe898eebab389" translate="yes" xml:space="preserve">
          <source>This is the first part of &lt;code&gt;minimize()&lt;/code&gt;. It returns a list of (gradient, variable) pairs where &quot;gradient&quot; is the gradient for &quot;variable&quot;. Note that &quot;gradient&quot; can be a &lt;code&gt;Tensor&lt;/code&gt;, an &lt;code&gt;IndexedSlices&lt;/code&gt;, or &lt;code&gt;None&lt;/code&gt; if there is no gradient for the given variable.</source>
          <target state="translated">이것은 &lt;code&gt;minimize()&lt;/code&gt; 의 첫 번째 부분입니다 . &quot;gradient&quot;가 &quot;variable&quot;에 대한 기울기 인 (gradient, variable) 쌍의 목록을 리턴합니다. &quot;gradient&quot;는 &lt;code&gt;Tensor&lt;/code&gt; , &lt;code&gt;IndexedSlices&lt;/code&gt; 또는 지정된 변수에 대한 기울기가없는 경우 &lt;code&gt;None&lt;/code&gt; 일 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="b03c235347a9cd23cdcbcc99319938e9531d2ad0" translate="yes" xml:space="preserve">
          <source>This is the opposite of stack.</source>
          <target state="translated">이것은 스택의 반대입니다.</target>
        </trans-unit>
        <trans-unit id="2e4bca768b327e659a826ca7018b5b658cdefd12" translate="yes" xml:space="preserve">
          <source>This is the opposite of unstack. The numpy equivalent is</source>
          <target state="translated">언 스택의 반대입니다. numpy에 해당하는 것은</target>
        </trans-unit>
        <trans-unit id="40e4198c7947cb171a27f0f2b96b5e41f088c377" translate="yes" xml:space="preserve">
          <source>This is the opposite of unstack. The numpy equivalent is &lt;code&gt;np.stack&lt;/code&gt;</source>
          <target state="translated">언 스택의 반대입니다. numpy에 해당하는 것은 &lt;code&gt;np.stack&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="97cb38281f3bf589012ea6423fb54fdf27897538" translate="yes" xml:space="preserve">
          <source>This is the recommended way to check if a checkpoint exists, since it takes into account the naming difference between V1 and V2 formats.</source>
          <target state="translated">이것은 체크 포인트가 존재하는지 확인하기 위해 권장되는 방법입니다. V1과 V2 형식의 이름 차이를 고려하기 때문입니다.</target>
        </trans-unit>
        <trans-unit id="1ffa5c6451bfed59ad42e7f927c856cf80634c8e" translate="yes" xml:space="preserve">
          <source>This is the recommended way to get the mtimes, since it takes into account the naming difference between V1 and V2 formats.</source>
          <target state="translated">V1과 V2 형식의 이름 차이를 고려하므로 mtimes를 얻는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="e10b2d35c35f3fc21ee9a235cd260123a0e63325" translate="yes" xml:space="preserve">
          <source>This is the same as the number of Read executions that have succeeded.</source>
          <target state="translated">성공한 읽기 실행 횟수와 동일합니다.</target>
        </trans-unit>
        <trans-unit id="f339ca988bca6265b32a0422f47f6bd298db3ffc" translate="yes" xml:space="preserve">
          <source>This is the second part of &lt;code&gt;minimize()&lt;/code&gt;. It returns an &lt;code&gt;Operation&lt;/code&gt; that applies gradients.</source>
          <target state="translated">이것은 &lt;code&gt;minimize()&lt;/code&gt; 의 두 번째 부분입니다 . &lt;code&gt;Operation&lt;/code&gt; 반환합니다그라디언트를 적용 을 합니다.</target>
        </trans-unit>
        <trans-unit id="929a719e4fd77bb16e29532f382d40f922f3c1e7" translate="yes" xml:space="preserve">
          <source>This is the second part of &lt;code&gt;minimize()&lt;/code&gt;. It returns an &lt;code&gt;Operation&lt;/code&gt; that conditionally applies gradients if all gradient values are finite. Otherwise no update is performed (nor is &lt;code&gt;global_step&lt;/code&gt; incremented).</source>
          <target state="translated">이것은 &lt;code&gt;minimize()&lt;/code&gt; 의 두 번째 부분입니다 . 모든 그래디언트 값이 유한 한 경우 조건부 그래디언트를 적용 하는 &lt;code&gt;Operation&lt;/code&gt; 을 반환합니다 . 그렇지 않으면 업데이트가 수행되지 않습니다 ( &lt;code&gt;global_step&lt;/code&gt; 도 아닙니다) 증가 ).</target>
        </trans-unit>
        <trans-unit id="e8ee3ea42d612b02e009f45c4fa84d1cc896a5de" translate="yes" xml:space="preserve">
          <source>This is true if the variable dtype is not the same as the compute dtype.</source>
          <target state="translated">변수 dtype이 계산 dtype과 동일하지 않은 경우에 해당됩니다.</target>
        </trans-unit>
        <trans-unit id="599e1941b7c0f4f9a0022f3bce79b85ba3adcf41" translate="yes" xml:space="preserve">
          <source>This is typically used to create the weights of &lt;code&gt;Layer&lt;/code&gt; subclasses.</source>
          <target state="translated">이것은 일반적으로 &lt;code&gt;Layer&lt;/code&gt; 의 가중치를 만드는 데 사용됩니다 서브 클래스 .</target>
        </trans-unit>
        <trans-unit id="05a2eba266c663d9424df49b8db51e4cc8c2df9e" translate="yes" xml:space="preserve">
          <source>This is used only for TfLite, it provides hints and it also makes the variables in the desired for the tflite ops (transposed and seaparated).</source>
          <target state="translated">이것은 TfLite에만 사용되며 힌트를 제공하며 tflite ops (transpose 및 seaparated)에 원하는 변수를 만듭니다.</target>
        </trans-unit>
        <trans-unit id="ad15eb7677663d9a7242cb23213706bc03ee0734" translate="yes" xml:space="preserve">
          <source>This is used only for TfLite, it provides hints and it also makes the variables in the desired for the tflite ops.</source>
          <target state="translated">이것은 TfLite에만 사용되며 힌트를 제공하며 tflite ops에 원하는 변수를 만듭니다.</target>
        </trans-unit>
        <trans-unit id="aa63c8ad524a0fffe274fd0f59f47f9f37029b1b" translate="yes" xml:space="preserve">
          <source>This is used to convert from a TensorFlow GraphDef, SavedModel or tf.keras model into either a TFLite FlatBuffer or graph visualization.</source>
          <target state="translated">TensorFlow GraphDef, SavedModel 또는 tf.keras 모델에서 TFLite FlatBuffer 또는 그래프 시각화로 변환하는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="42aa887e1a89f1c6a2cebd74bb895f76b927be77" translate="yes" xml:space="preserve">
          <source>This is used to decide whether loss should be scaled in optimizer (used only for estimator + v1 optimizer use case).</source>
          <target state="translated">이는 옵티 마이저에서 손실을 조정해야하는지 여부를 결정하는 데 사용됩니다 (추정기 + v1 옵티 마이저 사용 사례에만 사용).</target>
        </trans-unit>
        <trans-unit id="b17cf82d54ada528ca921a0efa90b52815fa4b91" translate="yes" xml:space="preserve">
          <source>This is used to prepare for toco conversion of complex intrinsic usages. Note: only one of session or graph_def should be used, not both.</source>
          <target state="translated">복잡한 고유 사용의 토코 변환을 준비하는 데 사용됩니다. 참고 : session 또는 graph_def 중 하나만 사용해야합니다.</target>
        </trans-unit>
        <trans-unit id="c7bb1bcc7e14a92bfe2b3cdc7e1ae060a3c52e44" translate="yes" xml:space="preserve">
          <source>This is useful any time you want to compute a value with TensorFlow but need to pretend that the value was a constant. Some examples include:</source>
          <target state="translated">이것은 TensorFlow로 값을 계산하려고하지만 값이 상수 인 척해야 할 때 유용합니다. 몇 가지 예는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="615f9e8a59ff4f1c3fc7f3ec9b1dd3650508efec" translate="yes" xml:space="preserve">
          <source>This is useful as a placeholder in code that expects a context manager.</source>
          <target state="translated">컨텍스트 관리자가 필요한 코드의 자리 표시 자로 유용합니다.</target>
        </trans-unit>
        <trans-unit id="b9563699660ae889442bbf807a27eb9beba27100" translate="yes" xml:space="preserve">
          <source>This is useful for separating training updates and state updates, e.g. when we need to update a layer's internal state during prediction.</source>
          <target state="translated">예를 들어 예측 중에 레이어의 내부 상태를 업데이트해야하는 경우 훈련 업데이트와 상태 업데이트를 분리하는 데 유용합니다.</target>
        </trans-unit>
        <trans-unit id="946e89dc12a7c9a5e1ede20576867301b896367c" translate="yes" xml:space="preserve">
          <source>This is useful for sequence tasks in which the elements have variable length. Grouping together elements that have similar lengths reduces the total fraction of padding in a batch which increases training step efficiency.</source>
          <target state="translated">이는 요소의 길이가 가변적 인 시퀀스 작업에 유용합니다. 길이가 비슷한 요소를 그룹화하면 배치에서 패딩의 총 비율이 줄어 훈련 단계 효율성이 향상됩니다.</target>
        </trans-unit>
        <trans-unit id="750a87642623af70551e01a6394d91315e9bfbb7" translate="yes" xml:space="preserve">
          <source>This is useful if you don't want to exit the context manager for the tape, or can't because the desired reset point is inside a control flow construct:</source>
          <target state="translated">테이프의 컨텍스트 관리자를 종료하지 않으려는 경우 또는 원하는 재설정 지점이 제어 플로우 구성 내에 있기 때문에 종료 할 수없는 경우에 유용합니다.</target>
        </trans-unit>
        <trans-unit id="1c4209d707783ab42b6537361cd0e771e2838f9d" translate="yes" xml:space="preserve">
          <source>This is useful in summaries to measure and report sparsity. For example,</source>
          <target state="translated">희소성을 측정하고보고하는 요약에 유용합니다. 예를 들어</target>
        </trans-unit>
        <trans-unit id="af423eb943d44142b4ba2df380bb45f9370ab357" translate="yes" xml:space="preserve">
          <source>This is useful to eliminate per-test boilerplate when context managers are used. For example, instead of decorating every test with &lt;code&gt;@mock.patch&lt;/code&gt;, simply do &lt;code&gt;self.foo = self.enter_context(mock.patch(...))' in&lt;/code&gt;setUp()`.</source>
          <target state="translated">컨텍스트 관리자를 사용할 때 테스트 별 상용구를 제거하는 데 유용합니다. 예를 들어, 대신에 모든 테스트를 장식의 &lt;code&gt;@mock.patch&lt;/code&gt; , 단순히 수행 &lt;code&gt;self.foo = self.enter_context(mock.patch(...))' in&lt;/code&gt; `) (설정.</target>
        </trans-unit>
        <trans-unit id="2f67d0f15d4bd847d95e4812f46c68a7b2ce669c" translate="yes" xml:space="preserve">
          <source>This is useful to mitigate overfitting (you could see it as a form of random data augmentation). Gaussian Noise (GS) is a natural choice as corruption process for real valued inputs.</source>
          <target state="translated">이는 과적 합을 완화하는 데 유용합니다 (임의의 데이터 증가 형태로 볼 수 있음). 가우시안 잡음 (GS)은 실제 가치있는 입력에 대한 손상 프로세스로 자연스럽게 선택됩니다.</target>
        </trans-unit>
        <trans-unit id="d38a2f7346a2a0766d59c6174961d13ece4817fb" translate="yes" xml:space="preserve">
          <source>This is useful when validating the result of a broadcasting operation when the tensors do not have statically known shapes.</source>
          <target state="translated">이것은 텐서가 정적으로 알려진 모양을 가지고 있지 않을 때 방송 작업의 결과를 검증 할 때 유용합니다.</target>
        </trans-unit>
        <trans-unit id="50937613d6e3934b243fbeba16769c301a7b4618" translate="yes" xml:space="preserve">
          <source>This is useful when validating the result of a broadcasting operation when the tensors have statically known shapes.</source>
          <target state="translated">이것은 텐서가 정적으로 알려진 모양을 가질 때 방송 작업의 결과를 검증 할 때 유용합니다.</target>
        </trans-unit>
        <trans-unit id="d56f48520fc92b32fe411b251279af631392c0d0" translate="yes" xml:space="preserve">
          <source>This is useful when you need to extract a subset of slices in an &lt;code&gt;IndexedSlices&lt;/code&gt; object.</source>
          <target state="translated">&lt;code&gt;IndexedSlices&lt;/code&gt; 에서 슬라이스 하위 집합을 추출해야 할 때 유용합니다 객체 합니다.</target>
        </trans-unit>
        <trans-unit id="7324163610c415fe69e9edf14d1514614e0096c2" translate="yes" xml:space="preserve">
          <source>This is where the layer's logic lives.</source>
          <target state="translated">이것이 계층의 논리가있는 곳입니다.</target>
        </trans-unit>
        <trans-unit id="51b266b637bd972731e9b8ded931808387760c03" translate="yes" xml:space="preserve">
          <source>This iterator-constructing method can be used to create an iterator that is reusable with many different datasets.</source>
          <target state="translated">이 반복자 구성 방법을 사용하면 다양한 데이터 집합에서 재사용 할 수있는 반복자를 만들 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="6651501cdbb63552c7881c732a891c9b596e4cd4" translate="yes" xml:space="preserve">
          <source>This layer can add rows and columns of zeros at the top, bottom, left and right side of an image tensor.</source>
          <target state="translated">이 레이어는 이미지 텐서의 위쪽, 아래쪽, 왼쪽 및 오른쪽에 0의 행과 열을 추가 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="c8f7de7a90e40a1acb832cfeb3e997b1fdd42909" translate="yes" xml:space="preserve">
          <source>This layer can be called multiple times with different features.</source>
          <target state="translated">이 레이어는 다른 기능으로 여러 번 호출 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="b23ebdf3426b29c2bb4017b933209c527b0b2eaf" translate="yes" xml:space="preserve">
          <source>This layer can only be used as the first layer in a model.</source>
          <target state="translated">이 레이어는 모델의 첫 번째 레이어로만 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="fbd759fae81bda98338ee6eb24eac5b449a08594" translate="yes" xml:space="preserve">
          <source>This layer creates a convolution kernel that is convolved (actually cross-correlated) with the layer input to produce a tensor of outputs. If &lt;code&gt;use_bias&lt;/code&gt; is True (and a &lt;code&gt;bias_initializer&lt;/code&gt; is provided), a bias vector is created and added to the outputs. Finally, if &lt;code&gt;activation&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;, it is applied to the outputs as well.</source>
          <target state="translated">이 레이어는 출력 텐서를 생성하기 위해 레이어 입력과 관련되어 (실제로 상호 상관 된) 컨볼 루션 커널을 만듭니다. &lt;code&gt;use_bias&lt;/code&gt; 가 True 이면 ( &lt;code&gt;bias_initializer&lt;/code&gt; 가 제공됨) 바이어스 벡터가 생성되어 출력에 추가됩니다. 마지막으로 &lt;code&gt;activation&lt;/code&gt; 가 &lt;code&gt;None&lt;/code&gt; 이 아닌 경우 출력에도 적용됩니다.</target>
        </trans-unit>
        <trans-unit id="a9977284bd794456f41f5d8f8d36aed1d3801d36" translate="yes" xml:space="preserve">
          <source>This layer creates a convolution kernel that is convolved with the layer input over a single spatial (or temporal) dimension to produce a tensor of outputs. If &lt;code&gt;use_bias&lt;/code&gt; is True, a bias vector is created and added to the outputs. Finally, if &lt;code&gt;activation&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;, it is applied to the outputs as well.</source>
          <target state="translated">이 레이어는 단일 공간 (또는 시간) 차원에 걸쳐 레이어 입력과 함께 컨벌루션 커널을 생성하여 출력 텐서를 생성합니다. 경우 &lt;code&gt;use_bias&lt;/code&gt; 가 True 인 바이어스 벡터 생성 및 출력에 추가된다. 마지막으로 &lt;code&gt;activation&lt;/code&gt; 가 &lt;code&gt;None&lt;/code&gt; 이 아닌 경우 출력에도 적용됩니다.</target>
        </trans-unit>
        <trans-unit id="d01bf01ba17a42cbf8ad8412a4cd7bfe52f00c78" translate="yes" xml:space="preserve">
          <source>This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If &lt;code&gt;use_bias&lt;/code&gt; is True, a bias vector is created and added to the outputs. Finally, if &lt;code&gt;activation&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;, it is applied to the outputs as well.</source>
          <target state="translated">이 레이어는 출력 텐서를 생성하기 위해 레이어 입력과 관련된 컨볼 루션 커널을 만듭니다. 경우 &lt;code&gt;use_bias&lt;/code&gt; 가 True 인 바이어스 벡터 생성 및 출력에 추가된다. 마지막으로 &lt;code&gt;activation&lt;/code&gt; 가 &lt;code&gt;None&lt;/code&gt; 이 아닌 경우 출력에도 적용됩니다.</target>
        </trans-unit>
        <trans-unit id="884d29443e655c08f257cc412193f76628fd846b" translate="yes" xml:space="preserve">
          <source>This layer has basic options for managing text in a Keras model. It transforms a batch of strings (one sample = one string) into either a list of token indices (one sample = 1D tensor of integer token indices) or a dense representation (one sample = 1D tensor of float values representing data about the sample's tokens).</source>
          <target state="translated">이 레이어에는 Keras 모델에서 텍스트를 관리하기위한 기본 옵션이 있습니다. 일련의 문자열 (하나의 샘플 = 하나의 문자열)을 토큰 인덱스 목록 (하나의 샘플 = 정수 토큰 인덱스의 1D 텐서) 또는 조밀 한 표현 (하나의 샘플 = 샘플의 토큰에 대한 데이터를 나타내는 부동 소수점 값의 1D 텐서)으로 변환합니다. ).</target>
        </trans-unit>
        <trans-unit id="bca79ddc4abf3d361de2fa2d5bdf3c1e02faac7e" translate="yes" xml:space="preserve">
          <source>This layer implements the operation: &lt;code&gt;outputs = activation(inputs * kernel + bias)&lt;/code&gt; Where &lt;code&gt;activation&lt;/code&gt; is the activation function passed as the &lt;code&gt;activation&lt;/code&gt; argument (if not &lt;code&gt;None&lt;/code&gt;), &lt;code&gt;kernel&lt;/code&gt; is a weights matrix created by the layer, and &lt;code&gt;bias&lt;/code&gt; is a bias vector created by the layer (only if &lt;code&gt;use_bias&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;).</source>
          <target state="translated">이 레이어는 다음과 같은 연산을 구현합니다. &lt;code&gt;outputs = activation(inputs * kernel + bias)&lt;/code&gt; 여기서 &lt;code&gt;activation&lt;/code&gt; 은 &lt;code&gt;activation&lt;/code&gt; 인수 로 전달 된 활성화 함수 ( &lt;code&gt;None&lt;/code&gt; 이 아닌 경우 )이고, &lt;code&gt;kernel&lt;/code&gt; 은 레이어에 의해 생성 된 가중치 행렬이며, &lt;code&gt;bias&lt;/code&gt; 는 생성 된 바이어스 벡터입니다. 레이어에 의해 ( &lt;code&gt;use_bias&lt;/code&gt; 가 &lt;code&gt;True&lt;/code&gt; 인 경우에만 ).</target>
        </trans-unit>
        <trans-unit id="35e71e883bb0be18fa94fd4d0a457376805923f0" translate="yes" xml:space="preserve">
          <source>This layer performs a depthwise convolution that acts separately on channels, followed by a pointwise convolution that mixes channels. If &lt;code&gt;use_bias&lt;/code&gt; is True and a bias initializer is provided, it adds a bias vector to the output. It then optionally applies an activation function to produce the final output.</source>
          <target state="translated">이 레이어는 채널에서 개별적으로 작동하는 깊이 컨벌루션을 수행 한 다음 채널을 혼합하는 포인트 컨벌루션을 수행합니다. &lt;code&gt;use_bias&lt;/code&gt; 인 경우 참이고 바이어스 초기화가 제공되고, 상기 출력에 대한 바이어스 벡터를 추가한다. 그런 다음 선택적으로 활성화 기능을 적용하여 최종 출력을 생성합니다.</target>
        </trans-unit>
        <trans-unit id="344f6b570b33a446c2eb6dc9ce40efd08ad87ee8" translate="yes" xml:space="preserve">
          <source>This layer supports masking for input data with a variable number of timesteps. To introduce masks to your data, use an [tf.keras.layers.Embedding] layer with the &lt;code&gt;mask_zero&lt;/code&gt; parameter set to &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">이 계층은 다양한 시간 간격으로 입력 데이터에 대한 마스킹을 지원합니다. 데이터에 마스크를 도입하려면 &lt;code&gt;mask_zero&lt;/code&gt; 매개 변수가 &lt;code&gt;True&lt;/code&gt; 로 설정된 [tf.keras.layers.Embedding] 레이어를 사용하십시오 .</target>
        </trans-unit>
        <trans-unit id="fe1b0f3431a8ec7d138b525163f2ad9cf543ffa7" translate="yes" xml:space="preserve">
          <source>This layer will coerce its inputs into a normal distribution centered around 0 with standard deviation 1. It accomplishes this by precomputing the mean and variance of the data, and calling (input-mean)/sqrt(var) at runtime.</source>
          <target state="translated">이 계층은 표준 편차 1을 사용하여 0을 중심으로하는 정규 분포로 입력을 강제합니다. 데이터의 평균과 분산을 사전 계산하고 런타임에 (입력-평균) / sqrt (var)를 호출하여이를 수행합니다.</target>
        </trans-unit>
        <trans-unit id="fbf50d844249a2e7240d57251d949994666050a2" translate="yes" xml:space="preserve">
          <source>This library contains all implementations of ClusterResolvers. ClusterResolvers are a way of specifying cluster information for distributed execution. Built on top of existing &lt;code&gt;ClusterSpec&lt;/code&gt; framework, ClusterResolvers are a way for TensorFlow to communicate with various cluster management systems (e.g. GCE, AWS, etc...).</source>
          <target state="translated">이 라이브러리에는 모든 ClusterResolvers 구현이 포함되어 있습니다. ClusterResolvers는 분산 실행을 위해 클러스터 정보를 지정하는 방법입니다. 기존 &lt;code&gt;ClusterSpec&lt;/code&gt; 을 기반으로 구축 프레임 워크 ClusterResolvers는 TensorFlow가 다양한 클러스터 관리 시스템 (예 : GCE, AWS 등)과 통신 할 수있는 방법입니다.</target>
        </trans-unit>
        <trans-unit id="b6b2d72a41e6a38bd121d03e086a0c141b5bab2a" translate="yes" xml:space="preserve">
          <source>This makes the TensorFlow Lite interpreter accessible in Python. It is possible to use this interpreter in a multithreaded Python environment, but you must be sure to call functions of a particular instance from only one thread at a time. So if you want to have 4 threads running different inferences simultaneously, create an interpreter for each one as thread-local data. Similarly, if you are calling invoke() in one thread on a single interpreter but you want to use tensor() on another thread once it is done, you must use a synchronization primitive between the threads to ensure invoke has returned before calling tensor().</source>
          <target state="translated">이를 통해 Python에서 TensorFlow Lite 인터프리터에 액세스 할 수 있습니다. 다중 스레드 Python 환경에서이 인터프리터를 사용할 수 있지만 한 번에 하나의 스레드에서만 특정 인스턴스의 함수를 호출해야합니다. 따라서 서로 다른 추론을 동시에 실행하는 4 개의 스레드를 가지려면 각 스레드에 대한 인터프리터를 스레드 로컬 데이터로 작성하십시오. 마찬가지로 단일 인터프리터의 한 스레드에서 invoke ()를 호출하고 있지만 일단 다른 스레드에서 tensor ()를 사용하려면 스레드 사이에 동기화 프리미티브를 사용하여 tensor ( ).</target>
        </trans-unit>
        <trans-unit id="6846fc96931fb6bb57a7f6152c9caf47e33ab2da" translate="yes" xml:space="preserve">
          <source>This makes the summary tag more predictable and consistent for the user.</source>
          <target state="translated">이것은 사용자에게 요약 태그를보다 예측 가능하고 일관성있게 만듭니다.</target>
        </trans-unit>
        <trans-unit id="99fc0b3a4e959624cfdd7190647db3380c4e327c" translate="yes" xml:space="preserve">
          <source>This may be useful for checking HTML output.</source>
          <target state="translated">HTML 출력을 확인하는 데 유용 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="381d4e4134c335f7e7e4d713df90044462182059" translate="yes" xml:space="preserve">
          <source>This may occur, for example, if an operation receives an input tensor that has an invalid value or shape. For example, the &lt;a href=&quot;../linalg/matmul&quot;&gt;&lt;code&gt;tf.matmul&lt;/code&gt;&lt;/a&gt; op will raise this error if it receives an input that is not a matrix, and the &lt;a href=&quot;../reshape&quot;&gt;&lt;code&gt;tf.reshape&lt;/code&gt;&lt;/a&gt; op will raise this error if the new shape does not match the number of elements in the input tensor.</source>
          <target state="translated">예를 들어, 조작이 유효하지 않은 값 또는 모양의 입력 텐서를 수신하는 경우에 발생할 수 있습니다. 예를 들어, &lt;a href=&quot;../linalg/matmul&quot;&gt; &lt;code&gt;tf.matmul&lt;/code&gt; &lt;/a&gt; op는 행렬이 아닌 입력을 수신하면 이 오류를 발생시키고, 새로운 모양이 입력 텐서의 요소 수와 일치하지 않으면 &lt;a href=&quot;../reshape&quot;&gt; &lt;code&gt;tf.reshape&lt;/code&gt; &lt;/a&gt; op가이 오류를 발생시킵니다.</target>
        </trans-unit>
        <trans-unit id="5c451c9f3d5af265bc5daacf860461f46903194b" translate="yes" xml:space="preserve">
          <source>This may only be used inside &lt;code&gt;self.scope()&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;self.scope()&lt;/code&gt; 내부에서만 사용할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="8407349f1434fe18f1d4f684e5cf94ad12755be8" translate="yes" xml:space="preserve">
          <source>This means that the result of matrix multiplication &lt;code&gt;v = Au&lt;/code&gt; has &lt;code&gt;Lth&lt;/code&gt; column given circular convolution between &lt;code&gt;h&lt;/code&gt; with the &lt;code&gt;Lth&lt;/code&gt; column of &lt;code&gt;u&lt;/code&gt;.</source>
          <target state="translated">행렬 곱셈 결과한다는 수단이 &lt;code&gt;v = Au&lt;/code&gt; 갖는 &lt;code&gt;Lth&lt;/code&gt; 열 사이 순환 컨벌루션 주어진 &lt;code&gt;h&lt;/code&gt; 과 &lt;code&gt;Lth&lt;/code&gt; 의 열의 &lt;code&gt;u&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7bac1b11600b86163afb8ed50f9d2fd7c08c803e" translate="yes" xml:space="preserve">
          <source>This method allows you to define a &quot;feedable&quot; iterator where you can choose between concrete iterators by feeding a value in a &lt;code&gt;tf.Session.run&lt;/code&gt; call. In that case, &lt;code&gt;string_handle&lt;/code&gt; would be a &lt;a href=&quot;../placeholder&quot;&gt;&lt;code&gt;tf.compat.v1.placeholder&lt;/code&gt;&lt;/a&gt;, and you would feed it with the value of &lt;code&gt;tf.data.Iterator.string_handle&lt;/code&gt; in each step.</source>
          <target state="translated">이 메소드를 사용하면 &lt;code&gt;tf.Session.run&lt;/code&gt; 호출 에서 값을 제공하여 콘크리트 반복자 중에서 선택할 수있는 &quot;공급 가능&quot;반복자를 정의 할 수 있습니다 . 이 경우, &lt;code&gt;string_handle&lt;/code&gt; 는 것 &lt;a href=&quot;../placeholder&quot;&gt; &lt;code&gt;tf.compat.v1.placeholder&lt;/code&gt; &lt;/a&gt; , 당신은의 값으로 공급 것 &lt;code&gt;tf.data.Iterator.string_handle&lt;/code&gt; 각 단계에있다.</target>
        </trans-unit>
        <trans-unit id="3ed29b40d37b37daebb7172d60a5cb7452fb1937" translate="yes" xml:space="preserve">
          <source>This method also allows multi-arity &lt;code&gt;elems&lt;/code&gt; and accumulator. If &lt;code&gt;elems&lt;/code&gt; is a (possibly nested) list or tuple of tensors, then each of these tensors must have a matching first (unpack) dimension. The second argument of &lt;code&gt;fn&lt;/code&gt; must match the structure of &lt;code&gt;elems&lt;/code&gt;.</source>
          <target state="translated">이 방법은 또한 다중 &lt;code&gt;elems&lt;/code&gt; 와 누산기를 허용합니다. 경우 &lt;code&gt;elems&lt;/code&gt; 은 텐서의 (아마도 중첩) 목록 또는 튜플이며, 이들 텐서의 각이 일치하는 첫 번째 (압축 풀기) 차원이 있어야합니다. &lt;code&gt;fn&lt;/code&gt; 의 두 번째 인수 는 &lt;code&gt;elems&lt;/code&gt; 의 구조와 일치해야합니다 .</target>
        </trans-unit>
        <trans-unit id="11d1041ad958b2d24d55eb0ab2e6d83f39085f6b" translate="yes" xml:space="preserve">
          <source>This method also allows multi-arity &lt;code&gt;elems&lt;/code&gt; and output of &lt;code&gt;fn&lt;/code&gt;. If &lt;code&gt;elems&lt;/code&gt; is a (possibly nested) list or tuple of tensors, then each of these tensors must have a matching first (unpack) dimension. The signature of &lt;code&gt;fn&lt;/code&gt; may match the structure of &lt;code&gt;elems&lt;/code&gt;. That is, if &lt;code&gt;elems&lt;/code&gt; is &lt;code&gt;(t1, [t2, t3, [t4, t5]])&lt;/code&gt;, then an appropriate signature for &lt;code&gt;fn&lt;/code&gt; is: &lt;code&gt;fn = lambda (t1, [t2, t3, [t4, t5]]):&lt;/code&gt;.</source>
          <target state="translated">이 방법을 사용하면 다중 &lt;code&gt;elems&lt;/code&gt; 와 &lt;code&gt;fn&lt;/code&gt; 출력 도 허용 됩니다. 경우 &lt;code&gt;elems&lt;/code&gt; 은 텐서의 (아마도 중첩) 목록 또는 튜플이며, 이들 텐서의 각이 일치하는 첫 번째 (압축 풀기) 차원이 있어야합니다. &lt;code&gt;fn&lt;/code&gt; 의 서명은 &lt;code&gt;elems&lt;/code&gt; 의 구조와 일치 할 수 있습니다 . 즉, &lt;code&gt;elems&lt;/code&gt; 가 &lt;code&gt;(t1, [t2, t3, [t4, t5]])&lt;/code&gt; 인 경우 &lt;code&gt;fn&lt;/code&gt; 에 대한 적절한 서명 은 다음과 같습니다. &lt;code&gt;fn = lambda (t1, [t2, t3, [t4, t5]]):&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="766a4862e3d658751f25e8ca0813b9af0856b88d" translate="yes" xml:space="preserve">
          <source>This method behaves differently than self.session(): for performance reasons &lt;code&gt;cached_session&lt;/code&gt; will by default reuse the same session within the same test. The session returned by this function will only be closed at the end of the test (in the TearDown function).</source>
          <target state="translated">이 메소드는 self.session ()과 다르게 작동합니다. 성능상의 이유로 &lt;code&gt;cached_session&lt;/code&gt; 은 기본적으로 동일한 테스트 내에서 동일한 세션을 재사용합니다. 이 함수에 의해 반환 된 세션은 테스트가 끝날 때만 (TearDown 함수에서) 닫힙니다.</target>
        </trans-unit>
        <trans-unit id="c7294d73f60860f63726337f7edc669a47fd434f" translate="yes" xml:space="preserve">
          <source>This method builds a new graph by first calling the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; to obtain feature &lt;code&gt;Tensor&lt;/code&gt;s, and then calling this &lt;code&gt;Estimator&lt;/code&gt;'s &lt;code&gt;model_fn&lt;/code&gt; to generate the model graph based on those features. It restores the given checkpoint (or, lacking that, the most recent checkpoint) into this graph in a fresh session. Finally it creates a timestamped export directory below the given &lt;code&gt;export_dir_base&lt;/code&gt;, and writes a &lt;code&gt;SavedModel&lt;/code&gt; into it containing a single &lt;code&gt;tf.MetaGraphDef&lt;/code&gt; saved from this session.</source>
          <target state="translated">이 메소드는 먼저 &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; 을 호출하여 기능 &lt;code&gt;Tensor&lt;/code&gt; 를 확보 한 다음이 &lt;code&gt;Estimator&lt;/code&gt; 의 &lt;code&gt;model_fn&lt;/code&gt; 을 호출 하여 해당 기능을 기반으로 모델 그래프를 생성하여 새 그래프를 작성합니다. 새로운 세션에서 주어진 체크 포인트 (또는 가장 최근의 체크 포인트가없는)를이 그래프로 복원합니다. 마지막으로 주어진 &lt;code&gt;export_dir_base&lt;/code&gt; 아래에 타임 스탬프 된 내보내기 디렉토리를 생성 하고이 세션에서 저장된 단일 &lt;code&gt;tf.MetaGraphDef&lt;/code&gt; 를 포함하는 &lt;code&gt;SavedModel&lt;/code&gt; 을 작성합니다 .</target>
        </trans-unit>
        <trans-unit id="c6ee7778196b7d2b41326a073f8b56a7c8a9a62d" translate="yes" xml:space="preserve">
          <source>This method can also be called directly on a Functional Model during construction. In this case, any loss Tensors passed to this Model must be symbolic and be able to be traced back to the model's &lt;code&gt;Input&lt;/code&gt;s. These losses become part of the model's topology and are tracked in &lt;code&gt;get_config&lt;/code&gt;.</source>
          <target state="translated">이 방법은 구성하는 동안 기능 모델에서 직접 호출 할 수도 있습니다. 이 경우이 모델에 전달 된 손실 텐서는 반드시 상징적이어야하며 모델의 &lt;code&gt;Input&lt;/code&gt; 다시 추적 할 수 있어야합니다 . 이러한 손실은 모델 토폴로지의 일부가되며 &lt;code&gt;get_config&lt;/code&gt; 에서 추적됩니다 .</target>
        </trans-unit>
        <trans-unit id="72b1f5316c49fd45d1ca1593424ee77777a4e789" translate="yes" xml:space="preserve">
          <source>This method can be called multiple times, and will merge the given &lt;code&gt;shape&lt;/code&gt; with the current shape of this tensor. It can be used to provide additional information about the shape of this tensor that cannot be inferred from the graph alone. For example, this can be used to provide additional information about the shapes of images:</source>
          <target state="translated">이 방법은 여러 번 호출 할 수 있으며, 주어진 병합합니다 &lt;code&gt;shape&lt;/code&gt; 이 텐서의 현재 모양. 그래프에서만 유추 할 수없는이 텐서의 모양에 대한 추가 정보를 제공하는 데 사용할 수 있습니다. 예를 들어, 이미지 모양에 대한 추가 정보를 제공하는 데 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7667fea48f6e7bf7add0c54e02f390885694a1d8" translate="yes" xml:space="preserve">
          <source>This method can be used after a call to &lt;a href=&quot;enable_check_numerics&quot;&gt;&lt;code&gt;tf.debugging.enable_check_numerics()&lt;/code&gt;&lt;/a&gt; to disable the numerics-checking mechanism that catches inifnity and NaN values output by ops executed eagerly or in tf.function-compiled graphs.</source>
          <target state="translated">이 메소드는 &lt;a href=&quot;enable_check_numerics&quot;&gt; &lt;code&gt;tf.debugging.enable_check_numerics()&lt;/code&gt; &lt;/a&gt; 를 호출 한 후 열성적으로 또는 tf.function-compiled graphs에서 실행 된 op에 의해 출력되는 inifnity 및 NaN 값을 포착하는 숫자 확인 메커니즘을 비활성화 하기 위해 사용할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="ab134bc99ff08cb5e34c3578ec66ab8ee325437d" translate="yes" xml:space="preserve">
          <source>This method can be used for several purposes. For example, where &lt;code&gt;experimental_distribute_dataset&lt;/code&gt; is unable to shard the input files, this method might be used to manually shard the dataset (avoiding the slow fallback behavior in &lt;code&gt;experimental_distribute_dataset&lt;/code&gt;). In cases where the dataset is infinite, this sharding can be done by creating dataset replicas that differ only in their random seed. &lt;code&gt;experimental_distribute_dataset&lt;/code&gt; may also sometimes fail to split the batch across replicas on a worker. In that case, this method can be used where that limitation does not exist.</source>
          <target state="translated">이 방법은 여러 가지 목적으로 사용될 수 있습니다. 예를 들어, &lt;code&gt;experimental_distribute_dataset&lt;/code&gt; 가 입력 파일을 샤딩 할 수없는 경우,이 방법을 사용하여 수동으로 데이터 세트를 샤딩 할 수 있습니다 ( &lt;code&gt;experimental_distribute_dataset&lt;/code&gt; 의 느린 폴백 동작 방지 ). 데이터 세트가 무한한 경우 임의의 시드에서만 다른 데이터 세트 복제본을 만들어이 샤딩을 수행 할 수 있습니다. &lt;code&gt;experimental_distribute_dataset&lt;/code&gt; 는 때때로 작업자의 복제본간에 배치를 분할하지 못할 수도 있습니다. 이 경우이 방법은 해당 제한이없는 경우에 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="4d445a1a8ccfc13d2cbb47a0cd8852bd14137cba" translate="yes" xml:space="preserve">
          <source>This method can be used inside a subclassed layer or model's &lt;code&gt;call&lt;/code&gt; function, in which case &lt;code&gt;losses&lt;/code&gt; should be a Tensor or list of Tensors.</source>
          <target state="translated">이 방법은 서브 클래스 계층 또는 모델의 &lt;code&gt;call&lt;/code&gt; 함수 내에서 사용될 수 있으며 ,이 경우 &lt;code&gt;losses&lt;/code&gt; 은 텐서 또는 텐서 목록이어야합니다.</target>
        </trans-unit>
        <trans-unit id="0a08143c632d6d9a6c3bb58abdfe351796aa7d61" translate="yes" xml:space="preserve">
          <source>This method can be used to assert that there exists a shape that both &lt;code&gt;self&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt; represent.</source>
          <target state="translated">이 방법은 &lt;code&gt;self&lt;/code&gt; 과 &lt;code&gt;other&lt;/code&gt; 이 모두 나타내는 모양이 있다고 주장하는 데 사용할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="311f5dd67cb7916aeab132002e12e94284e8fdb8" translate="yes" xml:space="preserve">
          <source>This method can be used to create &lt;code&gt;RaggedTensor&lt;/code&gt;s with multiple uniform outer dimensions. For example, a &lt;code&gt;RaggedTensor&lt;/code&gt; with shape &lt;code&gt;[2, 2, None]&lt;/code&gt; can be constructed with this method from a &lt;code&gt;RaggedTensor&lt;/code&gt; values with shape &lt;code&gt;[4, None]&lt;/code&gt;:</source>
          <target state="translated">이 메소드는 여러 개의 균일 한 외부 치수로 &lt;code&gt;RaggedTensor&lt;/code&gt; 를 작성하는 데 사용할 수 있습니다 . 예를 들어, &lt;code&gt;RaggedTensor&lt;/code&gt; 형상 &lt;code&gt;[2, 2, None]&lt;/code&gt; (A)로부터이 방법으로 구성 될 수 &lt;code&gt;RaggedTensor&lt;/code&gt; 의 형상과 값 &lt;code&gt;[4, None]&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="53a52d98446448532e361c5ab0b1a6a4bc35f1f2" translate="yes" xml:space="preserve">
          <source>This method can be used to merge partitions created by &lt;code&gt;dynamic_partition&lt;/code&gt; as illustrated on the following example:</source>
          <target state="translated">이 방법을 사용 하면 다음 예제와 같이 &lt;code&gt;dynamic_partition&lt;/code&gt; 으로 만든 파티션을 병합 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="d34cdddad9212e7710a82e27967cd30b8fc5e14d" translate="yes" xml:space="preserve">
          <source>This method can be used to run a step function for training a number of times using input from a dataset.</source>
          <target state="translated">이 방법을 사용하면 데이터 세트의 입력을 사용하여 여러 번 훈련하기위한 단계 함수를 실행할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="9c709bdcba30505f75d83241dd8ba3817ec876a1" translate="yes" xml:space="preserve">
          <source>This method currently blocks forever.</source>
          <target state="translated">이 방법은 현재 영원히 차단됩니다.</target>
        </trans-unit>
        <trans-unit id="a08e7549042177e7c94f4230a7e19c5cac25a2de" translate="yes" xml:space="preserve">
          <source>This method generalizes to higher-dimensions by simply providing a list for both the sp_ids as well as the vocab_size. In this case the resulting &lt;code&gt;SparseTensor&lt;/code&gt; has the following properties: - &lt;code&gt;indices&lt;/code&gt; is equivalent to &lt;code&gt;sp_ids[0].indices&lt;/code&gt; with the last dimension discarded and concatenated with &lt;code&gt;sp_ids[0].values, sp_ids[1].values, ...&lt;/code&gt;. - &lt;code&gt;values&lt;/code&gt; is simply &lt;code&gt;sp_values.values&lt;/code&gt;. - If &lt;code&gt;sp_ids.dense_shape = [D0, D1, ..., Dn, K]&lt;/code&gt;, then &lt;code&gt;output.shape = [D0, D1, ..., Dn] + vocab_size&lt;/code&gt;.</source>
          <target state="translated">이 방법은 sp_id와 vocab_size에 대한 목록을 제공하여보다 높은 차원으로 일반화합니다. 이 경우 결과 &lt;code&gt;SparseTensor&lt;/code&gt; 의 속성은 다음과 같습니다.- &lt;code&gt;indices&lt;/code&gt; 는 &lt;code&gt;sp_ids[0].indices&lt;/code&gt; 과 같습니다. 마지막 차원은 버리고 연결됩니다. &lt;code&gt;sp_ids[0].values, sp_ids[1].values, ...&lt;/code&gt; . - &lt;code&gt;values&lt;/code&gt; 단순히 &lt;code&gt;sp_values.values&lt;/code&gt; . - 만약 &lt;code&gt;sp_ids.dense_shape = [D0, D1, ..., Dn, K]&lt;/code&gt; 다음 &lt;code&gt;output.shape = [D0, D1, ..., Dn] + vocab_size&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e7e44aa7677b60789a9ebef54c74a9714ec4de2a" translate="yes" xml:space="preserve">
          <source>This method has similar semantics to the built-in &lt;code&gt;zip()&lt;/code&gt; function in Python, with the main difference being that the &lt;code&gt;datasets&lt;/code&gt; argument can be an arbitrary nested structure of &lt;code&gt;Dataset&lt;/code&gt; objects.</source>
          <target state="translated">이 메소드는 파이썬 의 내장 &lt;code&gt;zip()&lt;/code&gt; 함수 와 비슷한 의미를 가지는데 , 주요 차이점은 &lt;code&gt;datasets&lt;/code&gt; 인수가 &lt;code&gt;Dataset&lt;/code&gt; 객체 의 임의의 중첩 구조가 될 수 있다는 것 입니다.</target>
        </trans-unit>
        <trans-unit id="1925370323ce05b6dc0cdc8787e9c0d6ebf8403a" translate="yes" xml:space="preserve">
          <source>This method is a convenience wrapper for creating a &lt;a href=&quot;server&quot;&gt;&lt;code&gt;tf.distribute.Server&lt;/code&gt;&lt;/a&gt; with a &lt;a href=&quot;../train/serverdef&quot;&gt;&lt;code&gt;tf.train.ServerDef&lt;/code&gt;&lt;/a&gt; that specifies a single-process cluster containing a single task in a job called &lt;code&gt;&quot;local&quot;&lt;/code&gt;.</source>
          <target state="translated">이 메소드는 &lt;a href=&quot;server&quot;&gt; &lt;code&gt;tf.distribute.Server&lt;/code&gt; &lt;/a&gt; 를 작성하기위한 편리한 랩퍼입니다. 로모그래퍼 &lt;a href=&quot;../train/serverdef&quot;&gt; &lt;code&gt;tf.train.ServerDef&lt;/code&gt; &lt;/a&gt; 지정이라는 작업에서 하나의 작업을 포함하는 단일 프로세스 클러스터 &lt;code&gt;&quot;local&quot;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="05c81c4b69f5f8cdea4eba6f7d8bb00b2d7cd37f" translate="yes" xml:space="preserve">
          <source>This method is automatically called when the StubOutForTesting() object is deleted; there is no need to call it explicitly.</source>
          <target state="translated">이 메소드는 StubOutForTesting () 오브젝트가 삭제 될 때 자동으로 호출됩니다. 명시 적으로 호출 할 필요가 없습니다.</target>
        </trans-unit>
        <trans-unit id="992fe7b39731079182b90eaf498e1ed5e5a20148" translate="yes" xml:space="preserve">
          <source>This method is completely compatible with the &lt;code&gt;tf.Session.run()&lt;/code&gt; method.</source>
          <target state="translated">이 메소드는 &lt;code&gt;tf.Session.run()&lt;/code&gt; 메소드 와 완전히 호환됩니다 .</target>
        </trans-unit>
        <trans-unit id="a7dd7ea7386a00c65842a1da48fad6c58e2f712f" translate="yes" xml:space="preserve">
          <source>This method is for use by TestCase subclasses that need to register their own type equality functions to provide nicer error messages.</source>
          <target state="translated">이 메소드는 더 나은 오류 메시지를 제공하기 위해 자체 유형 평등 함수를 등록해야하는 TestCase 서브 클래스에서 사용합니다.</target>
        </trans-unit>
        <trans-unit id="66283121e6883c956c7613fffa84d220528690f4" translate="yes" xml:space="preserve">
          <source>This method is idempotent. Calling it multiple times has the same effect as calling it once.</source>
          <target state="translated">이 방법은 dem 등원입니다. 여러 번 호출하면 한 번 호출하는 것과 같은 효과가 있습니다.</target>
        </trans-unit>
        <trans-unit id="d1d2fc5aba91c121cb755ded927621c464c711dd" translate="yes" xml:space="preserve">
          <source>This method is only needed if you compute gradients manually, e.g. with &lt;a href=&quot;../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;. In that case, call this method to scale the loss before passing the loss to &lt;a href=&quot;../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;. If you use &lt;a href=&quot;../../optimizers/optimizer#minimize&quot;&gt;&lt;code&gt;LossScaleOptimizer.minimize&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;lossscaleoptimizer#get_gradients&quot;&gt;&lt;code&gt;LossScaleOptimizer.get_gradients&lt;/code&gt;&lt;/a&gt;, loss scaling is automatically applied and this method is unneeded.</source>
          <target state="translated">이 방법은 &lt;a href=&quot;../../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; 와 같이 그라디언트를 수동으로 계산하는 경우에만 필요합니다 . 이 경우 손실을 &lt;a href=&quot;../../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; 로&lt;/a&gt; 전달하기 전에 손실을 스케일링하려면이 메소드를 호출하십시오 . &lt;a href=&quot;../../optimizers/optimizer#minimize&quot;&gt; &lt;code&gt;LossScaleOptimizer.minimize&lt;/code&gt; &lt;/a&gt; 또는 &lt;a href=&quot;lossscaleoptimizer#get_gradients&quot;&gt; &lt;code&gt;LossScaleOptimizer.get_gradients&lt;/code&gt; &lt;/a&gt; 를 사용하는 경우 손실 스케일링이 자동으로 적용 메소드는 필요하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="2ffe062127379160c3973cd4f84270b4f4f8ccf9" translate="yes" xml:space="preserve">
          <source>This method is only needed if you compute gradients manually, e.g. with &lt;a href=&quot;../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;. In that case, call this method to unscale the gradients after computing them with &lt;a href=&quot;../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;. If you use &lt;a href=&quot;../../optimizers/optimizer#minimize&quot;&gt;&lt;code&gt;LossScaleOptimizer.minimize&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;lossscaleoptimizer#get_gradients&quot;&gt;&lt;code&gt;LossScaleOptimizer.get_gradients&lt;/code&gt;&lt;/a&gt;, loss scaling is automatically applied and this method is unneeded.</source>
          <target state="translated">이 방법은 &lt;a href=&quot;../../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; 와 같이 그라디언트를 수동으로 계산하는 경우에만 필요합니다 . 이 경우, 그들을 계산 후 그라디언트 unscale이 메소드를 호출 &lt;a href=&quot;../../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; . &lt;a href=&quot;../../optimizers/optimizer#minimize&quot;&gt; &lt;code&gt;LossScaleOptimizer.minimize&lt;/code&gt; &lt;/a&gt; 또는 &lt;a href=&quot;lossscaleoptimizer#get_gradients&quot;&gt; &lt;code&gt;LossScaleOptimizer.get_gradients&lt;/code&gt; &lt;/a&gt; 를 사용하면 손실 스케일링이 자동으로 적용 되며이 메소드는 필요하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="2d15ade5009ad723801c2c48bded790a3845587f" translate="yes" xml:space="preserve">
          <source>This method is optional if you are just training and executing models, exporting to and from SavedModels, or using weight checkpoints.</source>
          <target state="translated">이 방법은 모델을 교육 및 실행하거나 저장된 모델로 내보내거나 저장된 모델에서 또는 중량 검사 점을 사용하는 경우 선택 사항입니다.</target>
        </trans-unit>
        <trans-unit id="2ed4e772dabffd01cfde2b74159ef69c9f3e04f5" translate="yes" xml:space="preserve">
          <source>This method is required for Keras &lt;code&gt;model_to_estimator&lt;/code&gt;, saving and loading models to HDF5 formats, Keras model cloning, some visualization utilities, and exporting models to and from JSON.</source>
          <target state="translated">이 방법은 &lt;code&gt;model_to_estimator&lt;/code&gt; 필요하며 모델을 HDF5 형식으로 저장 및로드, Keras 모델 복제, 일부 시각화 유틸리티 및 JSON과 모델을 내보내는 데 필요합니다.</target>
        </trans-unit>
        <trans-unit id="6fdad9c5ed22f16c319e244d8261ea4ee3d279dd" translate="yes" xml:space="preserve">
          <source>This method is smart and works at the module, class, and instance level while preserving proper inheritance. It will not stub out C types however unless that has been explicitly allowed by the type.</source>
          <target state="translated">이 방법은 똑똑하며 적절한 상속을 유지하면서 모듈, 클래스 및 인스턴스 수준에서 작동합니다. 그러나 C 유형에서 명시 적으로 허용하지 않는 한 C 유형을 스텁 아웃하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="feecb6a599cedcf2305768be36a750d8591e9329" translate="yes" xml:space="preserve">
          <source>This method is the reverse of &lt;code&gt;get_config&lt;/code&gt;, capable of instantiating the same layer from the config dictionary. It does not handle layer connectivity (handled by Network), nor weights (handled by &lt;code&gt;set_weights&lt;/code&gt;).</source>
          <target state="translated">이 메소드는 &lt;code&gt;get_config&lt;/code&gt; 와 반대로 구성 사전에서 동일한 계층을 인스턴스화 할 수 있습니다. 계층 연결 (네트워크에서 처리) 또는 가중치 ( &lt;code&gt;set_weights&lt;/code&gt; 로 처리)를 처리하지 않습니다 .</target>
        </trans-unit>
        <trans-unit id="422559cd09a8b37855dfa1becf9159996c55a88c" translate="yes" xml:space="preserve">
          <source>This method is the reverse of &lt;code&gt;get_config&lt;/code&gt;, capable of instantiating the same optimizer from the config dictionary.</source>
          <target state="translated">이 메소드는 &lt;code&gt;get_config&lt;/code&gt; 와 반대로 구성 사전에서 동일한 최적화 프로그램을 인스턴스화 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="c7d6ed78b790787a16f4abeccc0ecd949df6cc2b" translate="yes" xml:space="preserve">
          <source>This method is the reverse of &lt;code&gt;get_config&lt;/code&gt;, capable of instantiating the same regularizer from the config dictionary.</source>
          <target state="translated">이 메소드는 &lt;code&gt;get_config&lt;/code&gt; 와 반대로 구성 사전에서 동일한 정규화 프로그램을 인스턴스화 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="188de6cc0c368ed4ab40eeabc0c2f0a4587200cc" translate="yes" xml:space="preserve">
          <source>This method is thread-safe.</source>
          <target state="translated">이 방법은 스레드로부터 안전합니다.</target>
        </trans-unit>
        <trans-unit id="430e31afd2b8ce36dbd30c0726de058dc4716f34" translate="yes" xml:space="preserve">
          <source>This method is used by Keras &lt;code&gt;model_to_estimator&lt;/code&gt;, saving and loading models to HDF5 formats, Keras model cloning, some visualization utilities, and exporting models to and from JSON.</source>
          <target state="translated">이 방법은 &lt;code&gt;model_to_estimator&lt;/code&gt; 에서 모델을 HDF5 형식으로 저장 및로드, 모델 복제, 일부 시각화 유틸리티 및 JSON과 모델을 내보내는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="457bbe494ff8a7cc3168e5b2acb3fc1d7df09a01" translate="yes" xml:space="preserve">
          <source>This method is used to convert a dictionary into a sequence of parameters for a binary that parses arguments using this module.</source>
          <target state="translated">이 메소드는 사전을이 모듈을 사용하여 인수를 구문 분석하는 2 진의 매개 변수 시퀀스로 변환하는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="5f40fabbeaa1bcaea8e9654a487713070e7848ee" translate="yes" xml:space="preserve">
          <source>This method is useful for recovering the &quot;self._last_checkpoints&quot; state.</source>
          <target state="translated">이 방법은 &quot;self._last_checkpoints&quot;상태를 복구하는 데 유용합니다.</target>
        </trans-unit>
        <trans-unit id="5eb2940a1b8924b3a2b4c6c370fcb87bd404d70c" translate="yes" xml:space="preserve">
          <source>This method may be called concurrently from multiple threads.</source>
          <target state="translated">이 메소드는 여러 스레드에서 동시에 호출 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="879b4ac0bfff915fe8733219e840864c530b0386" translate="yes" xml:space="preserve">
          <source>This method must be used as a context manager, and will yield a recording object with two attributes: &lt;code&gt;output&lt;/code&gt; and &lt;code&gt;records&lt;/code&gt;. At the end of the context manager, the &lt;code&gt;output&lt;/code&gt; attribute will be a list of the matching formatted log messages and the &lt;code&gt;records&lt;/code&gt; attribute will be a list of the corresponding LogRecord objects.</source>
          <target state="translated">이 메소드는 컨텍스트 관리자로 사용해야하며 &lt;code&gt;output&lt;/code&gt; 및 &lt;code&gt;records&lt;/code&gt; 속성이있는 레코딩 오브젝트를 생성 합니다 . 컨텍스트 관리자의 끝에서 &lt;code&gt;output&lt;/code&gt; 속성은 일치하는 형식화 된 로그 메시지 목록이고 &lt;code&gt;records&lt;/code&gt; 속성은 해당 LogRecord 객체의 목록입니다.</target>
        </trans-unit>
        <trans-unit id="45b78faa33c30a4ca2de4d4a2a7e0ea54433a6aa" translate="yes" xml:space="preserve">
          <source>This method overrides unittest.TestCase.shortDescription(), which only returns the first line of the docstring, obscuring the name of the test upon failure.</source>
          <target state="translated">이 메소드는 unittest.TestCase.shortDescription ()을 대체합니다.이 메소드는 docstring의 첫 번째 행만 리턴하고 실패시 테스트 이름을 숨 깁니다.</target>
        </trans-unit>
        <trans-unit id="ee5a67ef5f4ab3abd49e8e0aa6ab37b4c495718e" translate="yes" xml:space="preserve">
          <source>This method promotes a completely unknown shape to one with a known rank.</source>
          <target state="translated">이 방법은 완전히 알려지지 않은 모양을 알려진 순위의 모양으로 승격시킵니다.</target>
        </trans-unit>
        <trans-unit id="f08536c5c4bd5b0bf81a621ac1af31ff012f949c" translate="yes" xml:space="preserve">
          <source>This method requires a session in which the graph was launched. It creates a list of threads, optionally starting them. There is one thread for each op passed in &lt;code&gt;enqueue_ops&lt;/code&gt;.</source>
          <target state="translated">이 방법에는 그래프가 시작된 세션이 필요합니다. 스레드 목록을 작성하고 선택적으로 시작합니다. &lt;code&gt;enqueue_ops&lt;/code&gt; 에 전달 된 각 op에 대해 하나의 스레드가 있습니다 .</target>
        </trans-unit>
        <trans-unit id="ed37572237615338abb9afe9f97f9e51444c9050" translate="yes" xml:space="preserve">
          <source>This method requires that you are running in eager mode and the dataset's element_spec contains only &lt;code&gt;TensorSpec&lt;/code&gt; components.</source>
          <target state="translated">이 방법을 사용하려면 열망 모드에서 실행 중이고 데이터 세트의 element_spec에 &lt;code&gt;TensorSpec&lt;/code&gt; 구성 요소 만 포함되어 있어야 합니다.</target>
        </trans-unit>
        <trans-unit id="df938127180a900a9c0ee2c326f70990ca05bad0" translate="yes" xml:space="preserve">
          <source>This method returns True just before the run() method starts until just after the run() method terminates. The module function enumerate() returns a list of all alive threads.</source>
          <target state="translated">이 메소드는 run () 메소드가 종료되기 직전까지 run () 메소드가 시작되기 직전에 True를 리턴합니다. 모듈 함수 enumerate ()는 모든 활성 스레드 목록을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="67c5a6af4d2a477a788bf93645d98e3fc1667925" translate="yes" xml:space="preserve">
          <source>This method runs one &quot;step&quot; of TensorFlow computation, by running the necessary graph fragment to execute every &lt;code&gt;Operation&lt;/code&gt; and evaluate every &lt;code&gt;Tensor&lt;/code&gt; in &lt;code&gt;fetches&lt;/code&gt;, substituting the values in &lt;code&gt;feed_dict&lt;/code&gt; for the corresponding input values.</source>
          <target state="translated">이 메소드는 필요한 그래프 단편을 실행하여 모든 &lt;code&gt;Operation&lt;/code&gt; 을 실행 하고 &lt;code&gt;fetches&lt;/code&gt; 에서 모든 &lt;code&gt;Tensor&lt;/code&gt; 를 평가 하여 해당 입력 값에 대해 &lt;code&gt;feed_dict&lt;/code&gt; 의 값을 대체하여 TensorFlow 계산의 한 단계를 실행 합니다.</target>
        </trans-unit>
        <trans-unit id="7ef4f95365ffd49356edce6309d3da564feb3d3b" translate="yes" xml:space="preserve">
          <source>This method runs the ops added by the constructor for restoring variables. It requires a session in which the graph was launched. The variables to restore do not have to have been initialized, as restoring is itself a way to initialize variables.</source>
          <target state="translated">이 메소드는 변수를 복원하기 위해 생성자가 추가 한 op를 실행합니다. 그래프가 시작된 세션이 필요합니다. 복원 자체는 변수를 초기화하는 방법이므로 복원 할 변수를 초기화하지 않아도됩니다.</target>
        </trans-unit>
        <trans-unit id="6a0628c028c0b695f5ff3c6935b2aad50149fac6" translate="yes" xml:space="preserve">
          <source>This method runs the ops added by the constructor for saving variables. It requires a session in which the graph was launched. The variables to save must also have been initialized.</source>
          <target state="translated">이 메소드는 변수를 저장하기 위해 생성자가 추가 한 op를 실행합니다. 그래프가 시작된 세션이 필요합니다. 저장할 변수도 초기화해야합니다.</target>
        </trans-unit>
        <trans-unit id="9df50570004b7fc9f261d6b98cab329e6a66afe0" translate="yes" xml:space="preserve">
          <source>This method sets the vocabulary and DF data for this layer directly, instead of analyzing a dataset through 'adapt'. It should be used whenever the vocab (and optionally document frequency) information is already known. If vocabulary data is already present in the layer, this method will either replace it, if 'append' is set to False, or append to it (if 'append' is set to True).</source>
          <target state="translated">이 방법은 'adapt'를 통해 데이터 세트를 분석하는 대신이 레이어의 어휘 및 DF 데이터를 직접 설정합니다. vocab (및 선택적으로 문서 빈도) 정보가 이미 알려질 때마다 사용해야합니다. 어휘 데이터가 이미 계층에 존재하는 경우이 방법은 'append'가 False로 설정되어 있으면 추가하거나 추가합니다 ( 'append'가 True로 설정되어있는 경우).</target>
        </trans-unit>
        <trans-unit id="381d5d74ef1ba876c849eaf0c748814799df311b" translate="yes" xml:space="preserve">
          <source>This method should be used if you want to create multiple graphs in the same process. For convenience, a global default graph is provided, and all ops will be added to this graph if you do not create a new graph explicitly.</source>
          <target state="translated">동일한 프로세스에서 여러 그래프를 작성하려는 경우이 방법을 사용해야합니다. 편의상 전역 기본 그래프가 제공되며 새 그래프를 명시 적으로 만들지 않으면 모든 작업이이 그래프에 추가됩니다.</target>
        </trans-unit>
        <trans-unit id="801d04a3f8f77fe9f713a4af6184910c6103cec6" translate="yes" xml:space="preserve">
          <source>This method should be used to create all threads in test cases, as otherwise there is a risk that a thread will silently fail, and/or assertions made in the thread will not be respected.</source>
          <target state="translated">이 방법은 테스트 케이스에서 모든 스레드를 작성하는 데 사용해야합니다. 그렇지 않으면 스레드가 자동으로 실패 할 수 있으며 스레드에서 작성된 어설 션이 존중되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="84ddde0d41fb950f979365b1dd4b04e51a4464b1" translate="yes" xml:space="preserve">
          <source>This method simply combines calls &lt;code&gt;compute_gradients()&lt;/code&gt; and &lt;code&gt;apply_gradients()&lt;/code&gt;. If you want to process the gradient before applying them call &lt;code&gt;compute_gradients()&lt;/code&gt; and &lt;code&gt;apply_gradients()&lt;/code&gt; explicitly instead of using this function.</source>
          <target state="translated">이 메소드는 단순히 &lt;code&gt;compute_gradients()&lt;/code&gt; 및 &lt;code&gt;apply_gradients()&lt;/code&gt; 호출을 결합합니다 . 그라디언트를 적용하기 전에 그라디언트를 처리하려면 이 함수를 사용하는 대신 명시 적으로 &lt;code&gt;compute_gradients()&lt;/code&gt; 및 &lt;code&gt;apply_gradients()&lt;/code&gt; 호출하십시오.</target>
        </trans-unit>
        <trans-unit id="5f6d383158cc853c41c5bc430e4c2e31944ed6aa" translate="yes" xml:space="preserve">
          <source>This method simply computes gradient using &lt;a href=&quot;../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt; and calls &lt;code&gt;apply_gradients()&lt;/code&gt;. If you want to process the gradient before applying then call &lt;a href=&quot;../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt; and &lt;code&gt;apply_gradients()&lt;/code&gt; explicitly instead of using this function.</source>
          <target state="translated">이 메소드는 단순히 &lt;a href=&quot;../../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; 를&lt;/a&gt; 사용하여 그래디언트를 계산 하고 &lt;code&gt;apply_gradients()&lt;/code&gt; 호출합니다 . 적용하기 전에 그라디언트를 처리하려면 이 함수를 사용하는 대신 &lt;a href=&quot;../../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; 및 &lt;code&gt;apply_gradients()&lt;/code&gt; 명시 적으로 호출 하십시오 .</target>
        </trans-unit>
        <trans-unit id="7c45540d5f88e8d63143978a302ef3be7b4897a3" translate="yes" xml:space="preserve">
          <source>This method simply computes gradient using &lt;a href=&quot;../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt; and calls &lt;code&gt;apply_gradients()&lt;/code&gt;. If you want to process the gradient before applying then call &lt;a href=&quot;../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt; and &lt;code&gt;apply_gradients()&lt;/code&gt; explicitly instead of using this function.</source>
          <target state="translated">이 메소드는 단순히 &lt;a href=&quot;../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; 를&lt;/a&gt; 사용하여 그래디언트를 계산 하고 &lt;code&gt;apply_gradients()&lt;/code&gt; 호출합니다 . 적용하기 전에 그라디언트를 처리하려면 이 함수를 사용하는 대신 &lt;a href=&quot;../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; 및 &lt;code&gt;apply_gradients()&lt;/code&gt; 명시 적으로 호출 하십시오 .</target>
        </trans-unit>
        <trans-unit id="9fbf54940adbbc3b34153fb181199a19b56bd888" translate="yes" xml:space="preserve">
          <source>This method supports the case where attr_name is a staticmethod or a classmethod of obj.</source>
          <target state="translated">이 메소드는 attr_name이 정적 메소드이거나 obj의 클래스 메소드 인 경우를 지원합니다.</target>
        </trans-unit>
        <trans-unit id="b1e95fe0c7a12cd011cb442b54315c64dbbef85c" translate="yes" xml:space="preserve">
          <source>This method supports the case where child_name is a staticmethod or a classmethod of parent.</source>
          <target state="translated">이 메소드는 child_name이 정적 메소드이거나 상위 클래스 메소드 인 경우를 지원합니다.</target>
        </trans-unit>
        <trans-unit id="3c5357e5e49a58f1873923787332f7877e186b5d" translate="yes" xml:space="preserve">
          <source>This method takes effect only on the thread in which it is called.</source>
          <target state="translated">이 메소드는 호출 된 스레드에만 적용됩니다.</target>
        </trans-unit>
        <trans-unit id="7cd6047c37611c4ef1b1add7ec4d3db22681db24" translate="yes" xml:space="preserve">
          <source>This method will also be called as a result of recovering a wrapped session, not only at the beginning of the overall session.</source>
          <target state="translated">이 메소드는 전체 세션의 시작뿐만 아니라 랩핑 된 세션을 복구 한 결과로도 호출됩니다.</target>
        </trans-unit>
        <trans-unit id="72f0ec32b5d6b0d5f31ec5a44977c2b73ae22a24" translate="yes" xml:space="preserve">
          <source>This method will raise a RuntimeError if called more than once on the same thread object.</source>
          <target state="translated">이 메소드는 같은 스레드 객체에서 두 번 이상 호출되면 RuntimeError를 발생시킵니다.</target>
        </trans-unit>
        <trans-unit id="218a6eaea58d633bb4c07cebec2cce2a54164fc8" translate="yes" xml:space="preserve">
          <source>This method works similar to tf.map_fn but is optimized to run much faster, possibly with a much larger memory footprint. The speedups are obtained by vectorization (see https://arxiv.org/pdf/1903.04243.pdf). The idea behind vectorization is to semantically launch all the invocations of &lt;code&gt;fn&lt;/code&gt; in parallel and fuse corresponding operations across all these invocations. This fusion is done statically at graph generation time and the generated code is often similar in performance to a manually fused version.</source>
          <target state="translated">이 방법은 tf.map_fn과 유사하게 작동하지만 훨씬 더 큰 메모리 풋 프린트로 훨씬 빠르게 실행되도록 최적화되었습니다. 속도는 벡터화를 통해 얻을 수 있습니다 (https://arxiv.org/pdf/1903.04243.pdf 참조). 벡터화의 기본 개념은 의미 적으로 &lt;code&gt;fn&lt;/code&gt; 의 모든 호출을 병렬로 시작하고 이러한 모든 호출에서 해당 작업을 통합하는 것입니다. 이 융합은 그래프 생성시 정적으로 수행되며 생성 된 코드는 성능이 수동으로 융합 된 버전과 종종 유사합니다.</target>
        </trans-unit>
        <trans-unit id="fe5b3fca46a696592f5d3933d9a6c2e14a59d105" translate="yes" xml:space="preserve">
          <source>This method wraps the provided session in an &lt;code&gt;Event&lt;/code&gt; protocol buffer and adds it to the event file.</source>
          <target state="translated">이 메소드는 제공된 세션을 &lt;code&gt;Event&lt;/code&gt; 프로토콜 버퍼로 랩핑 하여 이벤트 파일에 추가합니다.</target>
        </trans-unit>
        <trans-unit id="0b654fd9b9bcfd951b8584e5c172fdf88b6f87e9" translate="yes" xml:space="preserve">
          <source>This method wraps the provided summary in an &lt;code&gt;Event&lt;/code&gt; protocol buffer and adds it to the event file.</source>
          <target state="translated">이 메소드는 제공된 요약을 &lt;code&gt;Event&lt;/code&gt; 프로토콜 버퍼 에 랩하여 이를 이벤트 파일에 추가합니다.</target>
        </trans-unit>
        <trans-unit id="e573192331e3d216aaf00fffe24f089e83e9c9ad" translate="yes" xml:space="preserve">
          <source>This method, unlike assertCountEqual, doesn't care about any duplicates in the expected and actual sequences.</source>
          <target state="translated">assertCountEqual과 달리이 메소드는 예상 및 실제 시퀀스의 중복에 대해서는 신경 쓰지 않습니다.</target>
        </trans-unit>
        <trans-unit id="0b693febd3a0c9fc69fb14a0f914449cb9729097" translate="yes" xml:space="preserve">
          <source>This metric creates four local variables, &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; that are used to compute the AUC. To discretize the AUC curve, a linearly spaced set of thresholds is used to compute pairs of recall and precision values. The area under the ROC-curve is therefore computed using the height of the recall values by the false positive rate, while the area under the PR-curve is the computed using the height of the precision values by the recall.</source>
          <target state="translated">이 메트릭은 AUC를 계산하는 데 사용되는 네 가지 로컬 변수 인 &lt;code&gt;true_positives&lt;/code&gt; , &lt;code&gt;true_negatives&lt;/code&gt; , &lt;code&gt;false_positives&lt;/code&gt; 및 &lt;code&gt;false_negatives&lt;/code&gt; 를 작성 합니다. AUC 곡선을 이산화시키기 위해 선형 간격의 임계 값 세트를 사용하여 리콜 및 정밀 값 쌍을 계산합니다. 따라서 ROC- 커브 아래 영역은 리콜 값의 높이를 가양 성 비율로 사용하여 계산되는 반면 PR- 커브 아래 영역은 리콜에 의해 정밀도 값의 높이를 사용하여 계산됩니다.</target>
        </trans-unit>
        <trans-unit id="8310e01ff09f3ad784585cc77cdb8fe7f1ac0213" translate="yes" xml:space="preserve">
          <source>This metric creates four local variables, &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; that are used to compute the precision at the given recall. The threshold for the given recall value is computed and used to evaluate the corresponding precision.</source>
          <target state="translated">이 메트릭은 지정된 리콜에서 정밀도를 계산하는 데 사용되는 네 개의 로컬 변수 &lt;code&gt;true_positives&lt;/code&gt; , &lt;code&gt;true_negatives&lt;/code&gt; , &lt;code&gt;false_positives&lt;/code&gt; 및 &lt;code&gt;false_negatives&lt;/code&gt; 를 작성합니다. 주어진 리콜 값의 임계 값이 계산되어 해당 정밀도를 평가하는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="a469d6ce618a21614949a4828cde8383fb0456e0" translate="yes" xml:space="preserve">
          <source>This metric creates four local variables, &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; that are used to compute the sensitivity at the given specificity. The threshold for the given specificity value is computed and used to evaluate the corresponding sensitivity.</source>
          <target state="translated">이 메트릭은 주어진 특이성에서 민감도를 계산하는 데 사용되는 네 개의 로컬 변수 인 &lt;code&gt;true_positives&lt;/code&gt; , &lt;code&gt;true_negatives&lt;/code&gt; , &lt;code&gt;false_positives&lt;/code&gt; 및 &lt;code&gt;false_negatives&lt;/code&gt; 를 작성 합니다. 주어진 특이성 값에 대한 임계 값이 계산되어 해당 감도를 평가하는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="ff9252130946c80b57ae4c5ee9b47938ca02b839" translate="yes" xml:space="preserve">
          <source>This metric creates four local variables, &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; that are used to compute the specificity at the given sensitivity. The threshold for the given sensitivity value is computed and used to evaluate the corresponding specificity.</source>
          <target state="translated">이 메트릭은 주어진 감도에서 특이성을 계산하는 데 사용되는 네 가지 로컬 변수 인 &lt;code&gt;true_positives&lt;/code&gt; , &lt;code&gt;true_negatives&lt;/code&gt; , &lt;code&gt;false_positives&lt;/code&gt; 및 &lt;code&gt;false_negatives&lt;/code&gt; 를 작성합니다. 주어진 감도 값에 대한 임계 값이 계산되어 해당 특이성을 평가하는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="fb652b4471c79604ae7dfb8ff87ca222abc482c6" translate="yes" xml:space="preserve">
          <source>This metric creates one variable, &lt;code&gt;total&lt;/code&gt;, that is used to compute the sum of &lt;code&gt;values&lt;/code&gt;. This is ultimately returned as &lt;code&gt;sum&lt;/code&gt;.</source>
          <target state="translated">이 메트릭은 &lt;code&gt;values&lt;/code&gt; 의 합계를 계산하는 데 사용되는 하나의 변수 &lt;code&gt;total&lt;/code&gt; 을 만듭니다 . 이것은 궁극적으로 &lt;code&gt;sum&lt;/code&gt; 로 반환됩니다 .</target>
        </trans-unit>
        <trans-unit id="77a69992763ecf548ab84fef5482d353d7a9cba3" translate="yes" xml:space="preserve">
          <source>This metric creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the frequency with which &lt;code&gt;y_pred&lt;/code&gt; matches &lt;code&gt;y_true&lt;/code&gt;. This frequency is ultimately returned as &lt;code&gt;binary accuracy&lt;/code&gt;: an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="translated">이 통계는 두 지역 변수 생성 &lt;code&gt;total&lt;/code&gt; 과 &lt;code&gt;count&lt;/code&gt; 되는 빈도를 계산하는 데 사용되는 &lt;code&gt;y_pred&lt;/code&gt; 일치 &lt;code&gt;y_true&lt;/code&gt; 를 . 이 주파수는 궁극적으로 반환된다 &lt;code&gt;binary accuracy&lt;/code&gt; : 단순히 분할가 멱등 동작 &lt;code&gt;total&lt;/code&gt; 로 &lt;code&gt;count&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="10a549b6038018b3cebc025343c39cb24e67e040" translate="yes" xml:space="preserve">
          <source>This metric creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the frequency with which &lt;code&gt;y_pred&lt;/code&gt; matches &lt;code&gt;y_true&lt;/code&gt;. This frequency is ultimately returned as &lt;code&gt;categorical accuracy&lt;/code&gt;: an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="translated">이 통계는 두 지역 변수 생성 &lt;code&gt;total&lt;/code&gt; 과 &lt;code&gt;count&lt;/code&gt; 되는 빈도를 계산하는 데 사용되는 &lt;code&gt;y_pred&lt;/code&gt; 일치 &lt;code&gt;y_true&lt;/code&gt; 를 . 이 주파수는 궁극적으로 반환된다 &lt;code&gt;categorical accuracy&lt;/code&gt; : 단순히 분할가 멱등 동작 &lt;code&gt;total&lt;/code&gt; 로 &lt;code&gt;count&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2d4e9dd5712eaf45fc10b998b8c6d4caf2e34bae" translate="yes" xml:space="preserve">
          <source>This metric creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the frequency with which &lt;code&gt;y_pred&lt;/code&gt; matches &lt;code&gt;y_true&lt;/code&gt;. This frequency is ultimately returned as &lt;code&gt;sparse categorical accuracy&lt;/code&gt;: an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="translated">이 통계는 두 지역 변수 생성 &lt;code&gt;total&lt;/code&gt; 과 &lt;code&gt;count&lt;/code&gt; 되는 빈도를 계산하는 데 사용되는 &lt;code&gt;y_pred&lt;/code&gt; 일치 &lt;code&gt;y_true&lt;/code&gt; 를 . 이 주파수는 궁극적으로 반환된다 &lt;code&gt;sparse categorical accuracy&lt;/code&gt; : 단순히 분할가 멱등 동작 &lt;code&gt;total&lt;/code&gt; 로 &lt;code&gt;count&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="300536328f19b08910251bd6b961009b9a37a3b7" translate="yes" xml:space="preserve">
          <source>This metric creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the mean relative absolute error. This average is weighted by &lt;code&gt;sample_weight&lt;/code&gt;, and it is ultimately returned as &lt;code&gt;mean_relative_error&lt;/code&gt;: an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="translated">이 메트릭은 평균 상대 절대 오차를 계산하는 데 사용되는 &lt;code&gt;total&lt;/code&gt; 와 &lt;code&gt;count&lt;/code&gt; 라는 두 개의 로컬 변수를 만듭니다 . 이 평균에 의해 가중된다 &lt;code&gt;sample_weight&lt;/code&gt; 하고, 궁극적으로 반환된다 &lt;code&gt;mean_relative_error&lt;/code&gt; : 단순히 분할가 멱등 동작 &lt;code&gt;total&lt;/code&gt; 로 &lt;code&gt;count&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0bf885c318184cc4d7f8536f5a3a6cfc0be45917" translate="yes" xml:space="preserve">
          <source>This metric creates two local variables, &lt;code&gt;true_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt;, that are used to compute the recall. This value is ultimately returned as &lt;code&gt;recall&lt;/code&gt;, an idempotent operation that simply divides &lt;code&gt;true_positives&lt;/code&gt; by the sum of &lt;code&gt;true_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt;.</source>
          <target state="translated">이 메트릭은 재 호출을 계산하는 데 사용되는 두 개의 로컬 변수 &lt;code&gt;true_positives&lt;/code&gt; 및 &lt;code&gt;false_negatives&lt;/code&gt; 를 작성합니다. 이 값은 궁극적 으로 &lt;code&gt;true_positives&lt;/code&gt; 를 &lt;code&gt;true_positives&lt;/code&gt; 와 &lt;code&gt;false_negatives&lt;/code&gt; 의 합으로 나누는 dem 등원 연산 인 &lt;code&gt;recall&lt;/code&gt; 으로 반환됩니다 .</target>
        </trans-unit>
        <trans-unit id="093560f8538560280d9ed1cd9a3cab29a6cbb355" translate="yes" xml:space="preserve">
          <source>This metric creates two variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the average of &lt;code&gt;values&lt;/code&gt;. This average is ultimately returned as &lt;code&gt;mean&lt;/code&gt; which is an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="translated">이 메트릭은 &lt;code&gt;values&lt;/code&gt; 의 평균을 계산하는 데 사용되는 &lt;code&gt;total&lt;/code&gt; 와 &lt;code&gt;count&lt;/code&gt; 두 가지 변수를 만듭니다 . 이 평균은 궁극적으로 반환 &lt;code&gt;mean&lt;/code&gt; 단순히 분할가 멱등 동작되는 &lt;code&gt;total&lt;/code&gt; 의해 &lt;code&gt;count&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0c9b94b35f1d2e4eb96d2ecbbedfd0249ca4dde6" translate="yes" xml:space="preserve">
          <source>This metric keeps the average cosine similarity between &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt; over a stream of data.</source>
          <target state="translated">이 메트릭 은 데이터 스트림에 대한 &lt;code&gt;predictions&lt;/code&gt; 과 &lt;code&gt;labels&lt;/code&gt; 간의 평균 코사인 유사성을 유지합니다 .</target>
        </trans-unit>
        <trans-unit id="418d70f20044dbd3397385f2c468b1eaa3216144" translate="yes" xml:space="preserve">
          <source>This model accepts sparse float inputs as well:</source>
          <target state="translated">이 모델은 스파 스 플로트 입력도 허용합니다.</target>
        </trans-unit>
        <trans-unit id="3a4737a2c04c7eb94694e1e82664a0b0d934f20d" translate="yes" xml:space="preserve">
          <source>This model approximates the following function:</source>
          <target state="translated">이 모델은 다음 기능과 유사합니다.</target>
        </trans-unit>
        <trans-unit id="82e7fe60bedc5bc6c52d1131a24d660c1d1e5baf" translate="yes" xml:space="preserve">
          <source>This model jointly train a linear and a dnn model.</source>
          <target state="translated">이 모델은 선형 및 dnn 모델을 공동으로 학습합니다.</target>
        </trans-unit>
        <trans-unit id="e8ea575479c33e1d3b54efb7336850606e620ed3" translate="yes" xml:space="preserve">
          <source>This module contains experimental &lt;code&gt;Dataset&lt;/code&gt; sources and transformations that can be used in conjunction with the &lt;a href=&quot;../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; API. Note that the &lt;a href=&quot;../../../data/experimental&quot;&gt;&lt;code&gt;tf.data.experimental&lt;/code&gt;&lt;/a&gt; API is not subject to the same backwards compatibility guarantees as &lt;a href=&quot;../../../data&quot;&gt;&lt;code&gt;tf.data&lt;/code&gt;&lt;/a&gt;, but we will provide deprecation advice in advance of removing existing functionality.</source>
          <target state="translated">이 모듈에는 &lt;a href=&quot;../../../data/dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; &lt;/a&gt; API 와 함께 사용할 수있는 실험 &lt;code&gt;Dataset&lt;/code&gt; 소스 및 변환 이 포함되어 있습니다 . 참고는 것을 &lt;a href=&quot;../../../data/experimental&quot;&gt; &lt;code&gt;tf.data.experimental&lt;/code&gt; &lt;/a&gt; API는 같은 이전 버전과의 호환성 보장이 적용되지 않습니다 &lt;a href=&quot;../../../data&quot;&gt; &lt;code&gt;tf.data&lt;/code&gt; &lt;/a&gt; , 그러나 우리는 기존 기능을 제거 사전에 중단 조언을 제공 할 것입니다.</target>
        </trans-unit>
        <trans-unit id="048da49888cbf092642d30c4a165ddde49bb4a0b" translate="yes" xml:space="preserve">
          <source>This module contains experimental &lt;code&gt;Dataset&lt;/code&gt; sources and transformations that can be used in conjunction with the &lt;a href=&quot;dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; API. Note that the &lt;a href=&quot;experimental&quot;&gt;&lt;code&gt;tf.data.experimental&lt;/code&gt;&lt;/a&gt; API is not subject to the same backwards compatibility guarantees as &lt;a href=&quot;../data&quot;&gt;&lt;code&gt;tf.data&lt;/code&gt;&lt;/a&gt;, but we will provide deprecation advice in advance of removing existing functionality.</source>
          <target state="translated">이 모듈에는 &lt;a href=&quot;dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; &lt;/a&gt; API 와 함께 사용할 수있는 실험 &lt;code&gt;Dataset&lt;/code&gt; 소스 및 변환 이 포함되어 있습니다 . 참고는 것을 &lt;a href=&quot;experimental&quot;&gt; &lt;code&gt;tf.data.experimental&lt;/code&gt; &lt;/a&gt; API는 같은 이전 버전과의 호환성 보장이 적용되지 않습니다 &lt;a href=&quot;../data&quot;&gt; &lt;code&gt;tf.data&lt;/code&gt; &lt;/a&gt; , 그러나 우리는 기존 기능을 제거 사전에 중단 조언을 제공 할 것입니다.</target>
        </trans-unit>
        <trans-unit id="458fef549ca5bb1cdd37d04e9f0b5b8e3b96d46e" translate="yes" xml:space="preserve">
          <source>This must be called by the constructors of subclasses.</source>
          <target state="translated">서브 클래스의 생성자가 호출해야합니다.</target>
        </trans-unit>
        <trans-unit id="b854be37a7975d22746ea61f4632ebd3ee101333" translate="yes" xml:space="preserve">
          <source>This must be called by the constructors of subclasses. Note that Optimizer instances should not bind to a single graph, and so shouldn't keep Tensors as member variables. Generally you should be able to use the _set_hyper()/state.get_hyper() facility instead.</source>
          <target state="translated">서브 클래스의 생성자가 호출해야합니다. Optimizer 인스턴스는 단일 그래프에 바인딩되지 않아야하므로 Tensor를 멤버 변수로 유지해서는 안됩니다. 일반적으로 _set_hyper () / state.get_hyper () 기능을 대신 사용할 수 있어야합니다.</target>
        </trans-unit>
        <trans-unit id="10ca194e65aab7cdbd21fa158a845dc67377d2ce" translate="yes" xml:space="preserve">
          <source>This must be set before start() is called, otherwise RuntimeError is raised. Its initial value is inherited from the creating thread; the main thread is not a daemon thread and therefore all threads created in the main thread default to daemon = False.</source>
          <target state="translated">start ()를 호출하기 전에 설정해야하며, 그렇지 않으면 RuntimeError가 발생합니다. 초기 값은 작성 스레드에서 상속됩니다. 기본 스레드는 데몬 스레드가 아니므로 기본 스레드에서 작성된 모든 스레드의 기본값은 daemon = False입니다.</target>
        </trans-unit>
        <trans-unit id="0329801ef1692f0ddc2ae7e5af20ed6a131c6c7c" translate="yes" xml:space="preserve">
          <source>This only ensures that the data has made its way out of the process without any guarantees on whether it's written to disk. This means that the data would survive an application crash but not necessarily an OS crash.</source>
          <target state="translated">이렇게하면 데이터가 디스크에 기록되는지 여부에 대한 보장없이 데이터가 프로세스에서 벗어날 수 있습니다. 이는 데이터가 응용 프로그램 충돌에도 불구하고 OS 충돌 일 필요는 없음을 의미합니다.</target>
        </trans-unit>
        <trans-unit id="93e1dc6b2d1103564814280c522ceb3f62da8aaa" translate="yes" xml:space="preserve">
          <source>This op adds entries with the specified &lt;code&gt;default_value&lt;/code&gt; at index &lt;code&gt;[row, 0]&lt;/code&gt; for any row in the input that does not already have a value.</source>
          <target state="translated">이 op는 값이없는 입력의 행에 대해 인덱스 &lt;code&gt;[row, 0]&lt;/code&gt; 에서 지정된 &lt;code&gt;default_value&lt;/code&gt; 를 가진 항목을 추가합니다 .</target>
        </trans-unit>
        <trans-unit id="9c96c116d1d672bbaf2e116ec518227e07309624" translate="yes" xml:space="preserve">
          <source>This op also returns an indicator vector such that</source>
          <target state="translated">이 op는 또한 지표 벡터를 반환하여</target>
        </trans-unit>
        <trans-unit id="f0a295b7a7559c4062aef820bad409706b47254e" translate="yes" xml:space="preserve">
          <source>This op also supports decoding JPEGs and PNGs, though it is cleaner to use &lt;a href=&quot;decode_image&quot;&gt;&lt;code&gt;tf.image.decode_image&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">이 연산은 JPEG 및 PNG 디코딩도 지원하지만 &lt;a href=&quot;decode_image&quot;&gt; &lt;code&gt;tf.image.decode_image&lt;/code&gt; &lt;/a&gt; 를 사용하는 것이 더 깨끗합니다 .</target>
        </trans-unit>
        <trans-unit id="7b09a5c52da344b1eb6cdb8c06bc391b1939c62f" translate="yes" xml:space="preserve">
          <source>This op also supports decoding JPEGs and non-animated GIFs since the interface is the same, though it is cleaner to use &lt;a href=&quot;decode_image&quot;&gt;&lt;code&gt;tf.image.decode_image&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">인터페이스는 동일하지만 &lt;a href=&quot;decode_image&quot;&gt; &lt;code&gt;tf.image.decode_image&lt;/code&gt; &lt;/a&gt; 를 사용하는 것이 더 깨끗하기 때문에이 연산은 JPEG 및 애니메이션이없는 GIF 디코딩도 지원합니다 .</target>
        </trans-unit>
        <trans-unit id="42b9c8de7bcd9a44756c5acb1ef87661725abb7d" translate="yes" xml:space="preserve">
          <source>This op also supports decoding PNGs and non-animated GIFs since the interface is the same, though it is cleaner to use &lt;a href=&quot;decode_image&quot;&gt;&lt;code&gt;tf.image.decode_image&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">인터페이스는 동일하지만 &lt;a href=&quot;decode_image&quot;&gt; &lt;code&gt;tf.image.decode_image&lt;/code&gt; &lt;/a&gt; 를 사용하는 것이 더 깨끗하므로 PNG 및 애니메이션이 아닌 GIF의 디코딩도 지원합니다 .</target>
        </trans-unit>
        <trans-unit id="fd4491d1a6601d1e84570bcd363e85b0e7d5c12e" translate="yes" xml:space="preserve">
          <source>This op assumes that there is at least one id for each row in the dense tensor represented by sp_ids (i.e. there are no rows with empty features), and that all the indices of sp_ids are in canonical row-major order.</source>
          <target state="translated">이 op는 sp_ids로 표시되는 조밀 한 텐서의 각 행에 대해 하나 이상의 id가 있고 (즉, 빈 피처가있는 행이 없음) sp_ids의 모든 인덱스가 표준 행 주요 순서에 있다고 가정합니다.</target>
        </trans-unit>
        <trans-unit id="ff99bdd028bae5711c127316ae24a743c30a9349" translate="yes" xml:space="preserve">
          <source>This op can be substantially more efficient than &lt;a href=&quot;case&quot;&gt;&lt;code&gt;tf.case&lt;/code&gt;&lt;/a&gt; when exactly one branch will be selected. &lt;a href=&quot;switch_case&quot;&gt;&lt;code&gt;tf.switch_case&lt;/code&gt;&lt;/a&gt; is more like a C++ switch/case statement than &lt;a href=&quot;case&quot;&gt;&lt;code&gt;tf.case&lt;/code&gt;&lt;/a&gt;, which is more like an if/elif/elif/else chain.</source>
          <target state="translated">이 연산은 정확히 하나의 브랜치를 선택할 때 &lt;a href=&quot;case&quot;&gt; &lt;code&gt;tf.case&lt;/code&gt; &lt;/a&gt; 보다 훨씬 효율적일 수 있습니다 . &lt;a href=&quot;switch_case&quot;&gt; &lt;code&gt;tf.switch_case&lt;/code&gt; 은&lt;/a&gt; 이상 C ++ 스위치 / case 문처럼 &lt;a href=&quot;case&quot;&gt; &lt;code&gt;tf.case&lt;/code&gt; &lt;/a&gt; 더는 IF / ELIF / ELIF / 다른 체인과 같다.</target>
        </trans-unit>
        <trans-unit id="88d4e65ada667e4924bd61aa913d0b719a3489bc" translate="yes" xml:space="preserve">
          <source>This op can be used to override the gradient for complicated functions. For example, suppose y = f(x) and we wish to apply a custom function g for backprop such that dx = g(dy). In Python,</source>
          <target state="translated">이 op는 복잡한 기능에 대한 그래디언트를 재정의하는 데 사용할 수 있습니다. 예를 들어, y = f (x)라고 가정하고 dx = g (dy)와 같은 백프로 프에 사용자 정의 함수 g를 적용하려고합니다. 파이썬에서</target>
        </trans-unit>
        <trans-unit id="a70d4bf94e1aa31fec2daa089308a302909ea19e" translate="yes" xml:space="preserve">
          <source>This op collects patches from the input image, as if applying a convolution. All extracted patches are stacked in the depth (last) dimension of the output.</source>
          <target state="translated">이 연산은 컨볼 루션을 적용하는 것처럼 입력 이미지에서 패치를 수집합니다. 추출 된 모든 패치는 출력의 깊이 (마지막) 치수에 쌓입니다.</target>
        </trans-unit>
        <trans-unit id="6c18dad5d5d6899466a10670d53475ca56625c85" translate="yes" xml:space="preserve">
          <source>This op converts between data types, scaling the values appropriately before casting.</source>
          <target state="translated">이 op는 데이터 유형간에 변환하여 캐스팅 전에 값을 적절하게 조정합니다.</target>
        </trans-unit>
        <trans-unit id="cc622534ae3fa62514818ea7bebb60dccd64c26d" translate="yes" xml:space="preserve">
          <source>This op creates a &lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto&quot;&gt;&lt;code&gt;Summary&lt;/code&gt;&lt;/a&gt; protocol buffer that contains the union of all the values in the input summaries.</source>
          <target state="translated">이 op 는 입력 요약에있는 모든 값의 합집합을 포함 하는 &lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto&quot;&gt; &lt;code&gt;Summary&lt;/code&gt; &lt;/a&gt; 프로토콜 버퍼를 만듭니다 .</target>
        </trans-unit>
        <trans-unit id="26981876c06a781e2a944a631697cc4482c0e90e" translate="yes" xml:space="preserve">
          <source>This op cuts a rectangular part out of &lt;code&gt;image&lt;/code&gt;. The top-left corner of the returned image is at &lt;code&gt;offset_height, offset_width&lt;/code&gt; in &lt;code&gt;image&lt;/code&gt;, and its lower-right corner is at &lt;code&gt;offset_height + target_height, offset_width + target_width&lt;/code&gt;.</source>
          <target state="translated">이 op는 &lt;code&gt;image&lt;/code&gt; 에서 직사각형 부분을 잘라냅니다 . 반환 된 이미지의 왼쪽 상단 모서리는 &lt;code&gt;offset_height, offset_width&lt;/code&gt; in &lt;code&gt;image&lt;/code&gt; 이며 오른쪽 하단 모서리는 &lt;code&gt;offset_height + target_height, offset_width + target_width&lt;/code&gt; 있습니다.</target>
        </trans-unit>
        <trans-unit id="b6b4a71613ffb1856f3dff1fb3fb7c9c68b7515a" translate="yes" xml:space="preserve">
          <source>This op decompresses each element of the &lt;code&gt;bytes&lt;/code&gt; input &lt;code&gt;Tensor&lt;/code&gt;, which is assumed to be compressed using the given &lt;code&gt;compression_type&lt;/code&gt;.</source>
          <target state="translated">이 op는 &lt;code&gt;bytes&lt;/code&gt; 입력 &lt;code&gt;Tensor&lt;/code&gt; 의 각 요소를 압축 해제 하는데, 이는 주어진 &lt;code&gt;compression_type&lt;/code&gt; 을 사용하여 압축 된 것으로 가정합니다 .</target>
        </trans-unit>
        <trans-unit id="9e56e06059315b7dda1620664824a84ff8d7bc3c" translate="yes" xml:space="preserve">
          <source>This op does not &lt;a href=&quot;https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html&quot;&gt;broadcast&lt;/a&gt; its inputs. If you need broadcasting, use &lt;a href=&quot;add&quot;&gt;&lt;code&gt;tf.math.add&lt;/code&gt;&lt;/a&gt; (or the &lt;code&gt;+&lt;/code&gt; operator) instead.</source>
          <target state="translated">이 op는 입력을 &lt;a href=&quot;https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html&quot;&gt;브로드 캐스트&lt;/a&gt; 하지 않습니다 . 브로드 캐스트가 필요한 경우 &lt;a href=&quot;add&quot;&gt; &lt;code&gt;tf.math.add&lt;/code&gt; &lt;/a&gt; (또는 &lt;code&gt;+&lt;/code&gt; 연산자)를 대신 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="32ac8411f8421961cf71053e4e574031251a142f" translate="yes" xml:space="preserve">
          <source>This op does nothing if &lt;code&gt;offset_*&lt;/code&gt; is zero and the image already has size &lt;code&gt;target_height&lt;/code&gt; by &lt;code&gt;target_width&lt;/code&gt;.</source>
          <target state="translated">이 op는 &lt;code&gt;offset_*&lt;/code&gt; 가 0이고 이미지의 크기가 &lt;code&gt;target_height&lt;/code&gt; by &lt;code&gt;target_width&lt;/code&gt; 인 경우 아무 것도 수행하지 않습니다 .</target>
        </trans-unit>
        <trans-unit id="25438ddc9615e500386687f63662f19536c3cd65" translate="yes" xml:space="preserve">
          <source>This op first slices &lt;code&gt;input&lt;/code&gt; along the dimension &lt;code&gt;batch_axis&lt;/code&gt;, and for each slice &lt;code&gt;i&lt;/code&gt;, reverses the first &lt;code&gt;seq_lengths[i]&lt;/code&gt; elements along the dimension &lt;code&gt;seq_axis&lt;/code&gt;.</source>
          <target state="translated">이 op 우선 슬라이스 는 &lt;code&gt;batch_axis&lt;/code&gt; 차원을 따라 &lt;code&gt;input&lt;/code&gt; 을 분할 하고 각 슬라이스 &lt;code&gt;i&lt;/code&gt; 에 대해 차원 seq_axis를 따라 첫 번째 &lt;code&gt;seq_lengths[i]&lt;/code&gt; 요소를 반전 &lt;code&gt;seq_axis&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d7225b3ea22ec4deb1adfd4a695bd1a7623e154b" translate="yes" xml:space="preserve">
          <source>This op implements the CTC loss as presented in the article:</source>
          <target state="translated">이 op는 기사에 제시된대로 CTC 손실을 구현합니다.</target>
        </trans-unit>
        <trans-unit id="2221b86f1776b0a82d12fa22eaebb9f19fcdaeda" translate="yes" xml:space="preserve">
          <source>This op is a convenience wrapper around &lt;code&gt;sparse_to_dense&lt;/code&gt; for &lt;code&gt;SparseTensor&lt;/code&gt;s.</source>
          <target state="translated">이 연산은 약 래퍼 편의입니다 &lt;code&gt;sparse_to_dense&lt;/code&gt; 에 대한 &lt;code&gt;SparseTensor&lt;/code&gt; 의.</target>
        </trans-unit>
        <trans-unit id="498581ecde1f847b44ae5faacdf090686c5a82aa" translate="yes" xml:space="preserve">
          <source>This op is conceptually identical to,</source>
          <target state="translated">이 op는 개념적으로 동일합니다.</target>
        </trans-unit>
        <trans-unit id="d1fddd748b0417b58ea1729816edada8cf15be10" translate="yes" xml:space="preserve">
          <source>This op is deprecated. See &lt;a href=&quot;../../../nn/batch_normalization&quot;&gt;&lt;code&gt;tf.nn.batch_normalization&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">이 op는 더 이상 사용되지 않습니다. &lt;a href=&quot;../../../nn/batch_normalization&quot;&gt; &lt;code&gt;tf.nn.batch_normalization&lt;/code&gt; 을&lt;/a&gt; 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="350e179bf73709c36862e34c13946cb30d6be41a" translate="yes" xml:space="preserve">
          <source>This op is deprecated. See &lt;a href=&quot;batch_normalization&quot;&gt;&lt;code&gt;tf.nn.batch_normalization&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">이 op는 더 이상 사용되지 않습니다. &lt;a href=&quot;batch_normalization&quot;&gt; &lt;code&gt;tf.nn.batch_normalization&lt;/code&gt; 을&lt;/a&gt; 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="bfe73bfb3165baeb1cd799227e5df39e5edc40e8" translate="yes" xml:space="preserve">
          <source>This op is equivalent to applying the normal &lt;a href=&quot;../nn/softmax&quot;&gt;&lt;code&gt;tf.nn.softmax()&lt;/code&gt;&lt;/a&gt; to each innermost logical submatrix with shape &lt;code&gt;[B, C]&lt;/code&gt;, but with the catch that &lt;em&gt;the implicitly zero elements do not participate&lt;/em&gt;. Specifically, the algorithm is equivalent to:</source>
          <target state="translated">이 op는 모양이 &lt;code&gt;[B, C]&lt;/code&gt; 인 각 가장 안쪽의 논리 서브 매트릭스에 일반 &lt;a href=&quot;../nn/softmax&quot;&gt; &lt;code&gt;tf.nn.softmax()&lt;/code&gt; &lt;/a&gt; 를 적용하는 것과 동일 하지만 &lt;em&gt;내재적으로 0 개의 요소가 참여하지 않는&lt;/em&gt; 캐치가 있습니다. 특히 알고리즘은 다음과 같습니다.&lt;em&gt;&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="cf3e5eda158a5f12c2f2da1b9b93833d5ff71185" translate="yes" xml:space="preserve">
          <source>This op is only defined for complex matrices. If A is positive-definite and real, then casting to a complex matrix, taking the logarithm and casting back to a real matrix will give the correct result.</source>
          <target state="translated">이 op는 복잡한 행렬에 대해서만 정의됩니다. A가 양의 정답이고 실수 인 경우 복잡한 행렬로 캐스팅하고 로그를 취하고 실제 행렬로 다시 캐스팅하면 올바른 결과를 얻을 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="b4088dd89f372d9134efcda4f21dccb2a4e43e51" translate="yes" xml:space="preserve">
          <source>This op is similar to &lt;code&gt;tf.strings.decode(...)&lt;/code&gt;, but it also returns the start offset for each character in its respective string. This information can be used to align the characters with the original byte sequence.</source>
          <target state="translated">이 op는 &lt;code&gt;tf.strings.decode(...)&lt;/code&gt; 와 비슷 하지만 각 문자열에서 각 문자의 시작 오프셋을 반환합니다. 이 정보를 사용하여 문자를 원래 바이트 순서에 맞출 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="30dc65726d5913cc5cf094798e27be8207b68832" translate="yes" xml:space="preserve">
          <source>This op is used during session initialization when a Scaffold is initialized without specifying the local_init_op arg. It includes &lt;a href=&quot;../local_variables_initializer&quot;&gt;&lt;code&gt;tf.compat.v1.local_variables_initializer&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../tables_initializer&quot;&gt;&lt;code&gt;tf.compat.v1.tables_initializer&lt;/code&gt;&lt;/a&gt;, and also initializes local session resources.</source>
          <target state="translated">이 op는 local_init_op arg를 지정하지 않고 스캐 폴드를 초기화 할 때 세션 초기화 중에 사용됩니다. &lt;a href=&quot;../local_variables_initializer&quot;&gt; &lt;code&gt;tf.compat.v1.local_variables_initializer&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;../tables_initializer&quot;&gt; &lt;code&gt;tf.compat.v1.tables_initializer&lt;/code&gt; 를&lt;/a&gt; 포함 하고 로컬 세션 자원을 초기화합니다.</target>
        </trans-unit>
        <trans-unit id="7494eb2e4d00b6f1a2a80a896b2a97c11ea84bbb" translate="yes" xml:space="preserve">
          <source>This op only parses the image header, so it is much faster than DecodeJpeg.</source>
          <target state="translated">이 op는 이미지 헤더 만 구문 분석하므로 DecodeJpeg보다 훨씬 빠릅니다.</target>
        </trans-unit>
        <trans-unit id="256678fd9ba7a89e98c94dad29bebb27865a6123" translate="yes" xml:space="preserve">
          <source>This op parses a serialized sequence example into a tuple of dictionaries, each mapping keys to &lt;code&gt;Tensor&lt;/code&gt; and &lt;code&gt;SparseTensor&lt;/code&gt; objects. The first dictionary contains mappings for keys appearing in &lt;code&gt;context_features&lt;/code&gt;, and the second dictionary contains mappings for keys appearing in &lt;code&gt;sequence_features&lt;/code&gt;.</source>
          <target state="translated">이 op는 직렬화 된 시퀀스 예제를 사전의 튜플로 구문 분석합니다. 각 &lt;code&gt;SparseTensor&lt;/code&gt; 는 &lt;code&gt;Tensor&lt;/code&gt; 및 SparseTensor 객체에 매핑 됩니다. 첫 번째 사전에는 &lt;code&gt;context_features&lt;/code&gt; 에 나타나는 키에 대한 매핑이 포함되고 두 번째 사전에는 &lt;code&gt;sequence_features&lt;/code&gt; 에 나타나는 키에 대한 매핑이 포함 됩니다 .</target>
        </trans-unit>
        <trans-unit id="b74d19b6cde7e379b7fc76473e78e58968efe064" translate="yes" xml:space="preserve">
          <source>This op parses serialized examples into a dictionary mapping keys to &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, and &lt;code&gt;RaggedTensor&lt;/code&gt; objects. &lt;code&gt;features&lt;/code&gt; is a dict from keys to &lt;code&gt;VarLenFeature&lt;/code&gt;, &lt;code&gt;RaggedFeature&lt;/code&gt;, &lt;code&gt;SparseFeature&lt;/code&gt;, and &lt;code&gt;FixedLenFeature&lt;/code&gt; objects. Each &lt;code&gt;VarLenFeature&lt;/code&gt; and &lt;code&gt;SparseFeature&lt;/code&gt; is mapped to a &lt;code&gt;SparseTensor&lt;/code&gt;; each &lt;code&gt;RaggedFeature&lt;/code&gt; is mapped to a &lt;code&gt;RaggedTensor&lt;/code&gt;; and each &lt;code&gt;FixedLenFeature&lt;/code&gt; is mapped to a &lt;code&gt;Tensor&lt;/code&gt;. See &lt;a href=&quot;../../io/parse_example&quot;&gt;&lt;code&gt;tf.io.parse_example&lt;/code&gt;&lt;/a&gt; for more details about feature dictionaries.</source>
          <target state="translated">이 op는 직렬화 된 예제를 &lt;code&gt;Tensor&lt;/code&gt; , &lt;code&gt;SparseTensor&lt;/code&gt; 및 &lt;code&gt;RaggedTensor&lt;/code&gt; 오브젝트 에 대한 사전 맵핑 키로 구문 분석 합니다. &lt;code&gt;features&lt;/code&gt; 은 키에서 &lt;code&gt;VarLenFeature&lt;/code&gt; , &lt;code&gt;RaggedFeature&lt;/code&gt; , &lt;code&gt;SparseFeature&lt;/code&gt; 및 &lt;code&gt;FixedLenFeature&lt;/code&gt; 객체에 대한 사전입니다 . 각 &lt;code&gt;VarLenFeature&lt;/code&gt; 및 &lt;code&gt;SparseFeature&lt;/code&gt; 는 A와 매핑되는 &lt;code&gt;SparseTensor&lt;/code&gt; ; 각 &lt;code&gt;RaggedFeature&lt;/code&gt; 는 (A)에 맵핑된다 &lt;code&gt;RaggedTensor&lt;/code&gt; ; 각 &lt;code&gt;FixedLenFeature&lt;/code&gt; 는 &lt;code&gt;Tensor&lt;/code&gt; 에 매핑됩니다 . &lt;a href=&quot;../../io/parse_example&quot;&gt; &lt;code&gt;tf.io.parse_example&lt;/code&gt; &lt;/a&gt; 참조 기능 사전에 대한 자세한 내용은</target>
        </trans-unit>
        <trans-unit id="845b399d2e9c5818b169dacff650d84da1b8a72a" translate="yes" xml:space="preserve">
          <source>This op parses serialized examples into a dictionary mapping keys to &lt;code&gt;Tensor&lt;/code&gt;&lt;code&gt;SparseTensor&lt;/code&gt;, and &lt;code&gt;RaggedTensor&lt;/code&gt; objects. &lt;code&gt;features&lt;/code&gt; is a dict from keys to &lt;code&gt;VarLenFeature&lt;/code&gt;, &lt;code&gt;SparseFeature&lt;/code&gt;, &lt;code&gt;RaggedFeature&lt;/code&gt;, and &lt;code&gt;FixedLenFeature&lt;/code&gt; objects. Each &lt;code&gt;VarLenFeature&lt;/code&gt; and &lt;code&gt;SparseFeature&lt;/code&gt; is mapped to a &lt;code&gt;SparseTensor&lt;/code&gt;; each &lt;code&gt;FixedLenFeature&lt;/code&gt; is mapped to a &lt;code&gt;Tensor&lt;/code&gt;; and each &lt;code&gt;RaggedFeature&lt;/code&gt; is mapped to a &lt;code&gt;RaggedTensor&lt;/code&gt;.</source>
          <target state="translated">이 op는 직렬화 된 예제를 &lt;code&gt;Tensor&lt;/code&gt; &lt;code&gt;SparseTensor&lt;/code&gt; 및 &lt;code&gt;RaggedTensor&lt;/code&gt; 오브젝트 에 대한 사전 맵핑 키로 구문 분석 합니다. &lt;code&gt;features&lt;/code&gt; 은 키에서 &lt;code&gt;VarLenFeature&lt;/code&gt; , &lt;code&gt;SparseFeature&lt;/code&gt; , &lt;code&gt;RaggedFeature&lt;/code&gt; 및 &lt;code&gt;FixedLenFeature&lt;/code&gt; 객체에 대한 사전입니다 . 각 &lt;code&gt;VarLenFeature&lt;/code&gt; 및 &lt;code&gt;SparseFeature&lt;/code&gt; 는 A와 매핑되는 &lt;code&gt;SparseTensor&lt;/code&gt; ; 각 &lt;code&gt;FixedLenFeature&lt;/code&gt; 는 &lt;code&gt;Tensor&lt;/code&gt; 에 맵핑됩니다 . 각 &lt;code&gt;RaggedFeature&lt;/code&gt; 는 A와 매핑되는 &lt;code&gt;RaggedTensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="787b46fef668ea2442d8cf59e886173e8f1beeb1" translate="yes" xml:space="preserve">
          <source>This op parses serialized sequence examples into a tuple of dictionaries, each mapping keys to &lt;code&gt;Tensor&lt;/code&gt; and &lt;code&gt;SparseTensor&lt;/code&gt; objects. The first dictionary contains mappings for keys appearing in &lt;code&gt;context_features&lt;/code&gt;, and the second dictionary contains mappings for keys appearing in &lt;code&gt;sequence_features&lt;/code&gt;.</source>
          <target state="translated">이 op는 직렬화 된 시퀀스 예제를 튜플 사전으로 구문 분석 합니다. 각 &lt;code&gt;SparseTensor&lt;/code&gt; 는 &lt;code&gt;Tensor&lt;/code&gt; 및 SparseTensor 객체에 매핑 됩니다. 첫 번째 사전에는 &lt;code&gt;context_features&lt;/code&gt; 에 나타나는 키에 대한 매핑이 포함되고 두 번째 사전에는 &lt;code&gt;sequence_features&lt;/code&gt; 에 나타나는 키에 대한 매핑이 포함 됩니다 .</target>
        </trans-unit>
        <trans-unit id="4ca1b1701aa5c064253c44ce1aad741cb653df7b" translate="yes" xml:space="preserve">
          <source>This op reports an &lt;code&gt;InvalidArgument&lt;/code&gt; error if any value is not finite.</source>
          <target state="translated">이 op는 값이 유한하지 않은 경우 &lt;code&gt;InvalidArgument&lt;/code&gt; 오류를 보고합니다 .</target>
        </trans-unit>
        <trans-unit id="a524bdef26722689a646035ff3a30a89b59c896f" translate="yes" xml:space="preserve">
          <source>This op runs in &lt;code&gt;O(M log M)&lt;/code&gt; time, where &lt;code&gt;M&lt;/code&gt; is the total number of non-empty values across all inputs. This is due to the need for an internal sort in order to concatenate efficiently across an arbitrary dimension.</source>
          <target state="translated">이 op는 &lt;code&gt;O(M log M)&lt;/code&gt; 시간으로 실행되며 여기서 &lt;code&gt;M&lt;/code&gt; 은 모든 입력에서 비어 있지 않은 값의 총 수입니다. 이는 임의의 차원에서 효율적으로 연결하기 위해 내부 정렬이 필요하기 때문입니다.</target>
        </trans-unit>
        <trans-unit id="edecba4e86376242d273ba622ca63b2965a5a438" translate="yes" xml:space="preserve">
          <source>This op translates a tensor containing Example records, encoded using the &lt;a href=&quot;https://developers.google.com/protocol-buffers/docs/proto3#json&quot;&gt;standard JSON mapping&lt;/a&gt;, into a tensor containing the same records encoded as binary protocol buffers. The resulting tensor can then be fed to any of the other Example-parsing ops.</source>
          <target state="translated">이 op는 &lt;a href=&quot;https://developers.google.com/protocol-buffers/docs/proto3#json&quot;&gt;표준 JSON 매핑을&lt;/a&gt; 사용하여 인코딩 된 Example 레코드를 포함 하는 텐서를 이진 프로토콜 버퍼와 인코딩 된 동일한 레코드를 포함하는 텐서로 변환합니다. 그런 다음 결과 텐서는 다른 예제 구문 분석 작업에 제공 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="49b534f6ddaaf2bd4e7772b31b4be9cf92fcfbd7" translate="yes" xml:space="preserve">
          <source>This operation blocks until that finishes.</source>
          <target state="translated">이 작업은 완료 될 때까지 차단됩니다.</target>
        </trans-unit>
        <trans-unit id="14d876872d62a220ab5753fd3b852a5a6bcb76ef" translate="yes" xml:space="preserve">
          <source>This operation can be used with &lt;code&gt;output_encoding = input_encoding&lt;/code&gt; to enforce correct formatting for inputs even if they are already in the desired encoding.</source>
          <target state="translated">이 연산은 &lt;code&gt;output_encoding = input_encoding&lt;/code&gt; 과 함께 사용하여 입력이 이미 원하는 인코딩으로되어 있어도 입력에 올바른 형식을 적용 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="bf8af72c7ec5c03a0a302901ae0b02f8840934f4" translate="yes" xml:space="preserve">
          <source>This operation computes</source>
          <target state="translated">이 작업은 계산</target>
        </trans-unit>
        <trans-unit id="df2c8f127a35805203dd552ccd88657669212f89" translate="yes" xml:space="preserve">
          <source>This operation computes the inverse of an index permutation. It takes a 1-D integer tensor &lt;code&gt;x&lt;/code&gt;, which represents the indices of a zero-based array, and swaps each value with its index position. In other words, for an output tensor &lt;code&gt;y&lt;/code&gt; and an input tensor &lt;code&gt;x&lt;/code&gt;, this operation computes the following:</source>
          <target state="translated">이 연산은 인덱스 순열의 역수를 계산합니다. 0부터 시작하는 배열의 인덱스를 나타내는 1 차원 정수 텐서 &lt;code&gt;x&lt;/code&gt; 를 취하고 각 값을 인덱스 위치로 바꿉니다. 다시 말해, 출력 텐서 &lt;code&gt;y&lt;/code&gt; 및 입력 텐서 &lt;code&gt;x&lt;/code&gt; 의 경우이 작업은 다음을 계산합니다.</target>
        </trans-unit>
        <trans-unit id="d8b4d24b16bc4a84c7216a06caa8665f602e4b2d" translate="yes" xml:space="preserve">
          <source>This operation concatenates queue-element component tensors along the 0th dimension to make a single component tensor. All of the components in the dequeued tuple will have size &lt;code&gt;n&lt;/code&gt; in the 0th dimension.</source>
          <target state="translated">이 작업은 단일 요소 텐서를 만들기 위해 0 차원을 따라 큐 요소 구성 요소 텐서를 연결합니다. 디큐 튜플의 모든 구성 요소는 크기가됩니다 &lt;code&gt;n&lt;/code&gt; 은 0 번째 차원을.</target>
        </trans-unit>
        <trans-unit id="50e9d3be55bb6834daac8ca12d0b390851428378" translate="yes" xml:space="preserve">
          <source>This operation concatenates queue-element component tensors along the 0th dimension to make a single component tensor. If the queue has not been closed, all of the components in the dequeued tuple will have size &lt;code&gt;n&lt;/code&gt; in the 0th dimension.</source>
          <target state="translated">이 작업은 단일 요소 텐서를 만들기 위해 0 차원을 따라 큐 요소 구성 요소 텐서를 연결합니다. 큐가 폐쇄되지 않은 경우, 대기열 튜플의 모든 구성 요소는 크기가됩니다 &lt;code&gt;n&lt;/code&gt; 은 0 번째 차원을.</target>
        </trans-unit>
        <trans-unit id="45295c6769989505efcf8c49b52125eb620acebf" translate="yes" xml:space="preserve">
          <source>This operation converts Unicode code points to script codes corresponding to each code point. Script codes correspond to International Components for Unicode (ICU) UScriptCode values. See http://icu-project.org/apiref/icu4c/uscript_8h.html. Returns -1 (USCRIPT_INVALID_CODE) for invalid codepoints. Output shape will match input shape.</source>
          <target state="translated">이 작업은 유니 코드 코드 포인트를 각 코드 포인트에 해당하는 스크립트 코드로 변환합니다. 스크립트 코드는 ICU (International Components for Unicode) UScriptCode 값에 해당합니다. http://icu-project.org/apiref/icu4c/uscript_8h.html을 참조하십시오. 유효하지 않은 코드 포인트에 대해 -1 (USCRIPT_INVALID_CODE)을 반환합니다. 출력 형태는 입력 형태와 일치합니다.</target>
        </trans-unit>
        <trans-unit id="46e590d89bb172f52098449de9dab107e8dbb7d2" translate="yes" xml:space="preserve">
          <source>This operation corresponds to &lt;code&gt;numpy.tensordot(a, b, axes)&lt;/code&gt;.</source>
          <target state="translated">이 연산은 &lt;code&gt;numpy.tensordot(a, b, axes)&lt;/code&gt; 합니다.</target>
        </trans-unit>
        <trans-unit id="11cc84360970a3caa94b4965487c085edd1841b7" translate="yes" xml:space="preserve">
          <source>This operation creates a new tensor by adding sparse &lt;code&gt;updates&lt;/code&gt; to the passed in &lt;code&gt;tensor&lt;/code&gt;. This operation is very similar to &lt;code&gt;tf.scatter_nd_add&lt;/code&gt;, except that the updates are added onto an existing tensor (as opposed to a variable). If the memory for the existing tensor cannot be re-used, a copy is made and updated.</source>
          <target state="translated">이 작업은 전달 된 &lt;code&gt;tensor&lt;/code&gt; 스파 스 &lt;code&gt;updates&lt;/code&gt; 를 추가하여 새 텐서를 만듭니다 . 이 작업은 변수가 아닌 기존 텐서에 업데이트가 추가된다는 점을 제외하고 &lt;code&gt;tf.scatter_nd_add&lt;/code&gt; 와 매우 유사합니다 . 기존 텐서의 메모리를 재사용 할 수 없으면 사본이 만들어지고 업데이트됩니다.</target>
        </trans-unit>
        <trans-unit id="c390e65b4cc57f97f7e73aea3a4e81f629906485" translate="yes" xml:space="preserve">
          <source>This operation creates a new tensor by applying sparse &lt;code&gt;updates&lt;/code&gt; to the passed in &lt;code&gt;tensor&lt;/code&gt;. This operation is very similar to &lt;a href=&quot;scatter_nd&quot;&gt;&lt;code&gt;tf.scatter_nd&lt;/code&gt;&lt;/a&gt;, except that the updates are scattered onto an existing tensor (as opposed to a zero-tensor). If the memory for the existing tensor cannot be re-used, a copy is made and updated.</source>
          <target state="translated">이 작업은 전달 된 &lt;code&gt;tensor&lt;/code&gt; 스파 스 &lt;code&gt;updates&lt;/code&gt; 를 적용하여 새 텐서를 만듭니다 . 이 작업은 &lt;a href=&quot;scatter_nd&quot;&gt; &lt;code&gt;tf.scatter_nd&lt;/code&gt; &lt;/a&gt; 와 매우 유사합니다. 단 , 업데이트는 기존 텐서에 흩어져 있습니다 (제로 텐서가 아님). 기존 텐서의 메모리를 재사용 할 수 없으면 사본이 만들어지고 업데이트됩니다.</target>
        </trans-unit>
        <trans-unit id="35ada26abd351b9c5bf627e9862c2252c700b1b5" translate="yes" xml:space="preserve">
          <source>This operation creates a new tensor by replicating &lt;code&gt;input&lt;/code&gt;&lt;code&gt;multiples&lt;/code&gt; times. The output tensor's i'th dimension has &lt;code&gt;input.dims(i) * multiples[i]&lt;/code&gt; elements, and the values of &lt;code&gt;input&lt;/code&gt; are replicated &lt;code&gt;multiples[i]&lt;/code&gt; times along the 'i'th dimension. For example, tiling &lt;code&gt;[a b c d]&lt;/code&gt; by &lt;code&gt;[2]&lt;/code&gt; produces &lt;code&gt;[a b c d a b c d]&lt;/code&gt;.</source>
          <target state="translated">이 작업은 &lt;code&gt;input&lt;/code&gt; &lt;code&gt;multiples&lt;/code&gt; 번 복제하여 새 텐서를 만듭니다 . 출력 텐서의 i 번째 차원에는 &lt;code&gt;input.dims(i) * multiples[i]&lt;/code&gt; 요소가 있으며 &lt;code&gt;input&lt;/code&gt; 값은 'i'번째 차원을 따라 &lt;code&gt;multiples[i]&lt;/code&gt; 회 복제 됩니다. 예를 들어, &lt;code&gt;[2]&lt;/code&gt; 에 의해 &lt;code&gt;[a b c d]&lt;/code&gt; 를 타일링 하면 &lt;code&gt;[a b c d a b c d]&lt;/code&gt; 생성 됩니다.</target>
        </trans-unit>
        <trans-unit id="5c90c8c96fbb8b355bef6addc97e2ca668679eab" translate="yes" xml:space="preserve">
          <source>This operation creates a new tensor by subtracting sparse &lt;code&gt;updates&lt;/code&gt; from the passed in &lt;code&gt;tensor&lt;/code&gt;. This operation is very similar to &lt;code&gt;tf.scatter_nd_sub&lt;/code&gt;, except that the updates are subtracted from an existing tensor (as opposed to a variable). If the memory for the existing tensor cannot be re-used, a copy is made and updated.</source>
          <target state="translated">이 작업은 전달 된 &lt;code&gt;tensor&lt;/code&gt; 에서 스파 스 &lt;code&gt;updates&lt;/code&gt; 를 빼서 새 텐서를 만듭니다 . 이 작업은 변수가 아닌 기존 텐서에서 업데이트를 뺀다는 점을 제외하고 &lt;code&gt;tf.scatter_nd_sub&lt;/code&gt; 와 매우 유사합니다 . 기존 텐서의 메모리를 재사용 할 수 없으면 사본이 만들어지고 업데이트됩니다.</target>
        </trans-unit>
        <trans-unit id="0aaf5e994752ce058c39711d4638a06e40443f56" translate="yes" xml:space="preserve">
          <source>This operation creates a tensor of shape &lt;code&gt;dims&lt;/code&gt; and fills it with &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="translated">이 작업은 모양이 &lt;code&gt;dims&lt;/code&gt; 텐서를 만들고 &lt;code&gt;value&lt;/code&gt; 채 웁니다 .</target>
        </trans-unit>
        <trans-unit id="2acd7b755c2b5e055f5081527ae8768ab15af691" translate="yes" xml:space="preserve">
          <source>This operation divides &quot;spatial&quot; dimensions &lt;code&gt;[1, ..., M]&lt;/code&gt; of the input into a grid of blocks of shape &lt;code&gt;block_shape&lt;/code&gt;, and interleaves these blocks with the &quot;batch&quot; dimension (0) such that in the output, the spatial dimensions &lt;code&gt;[1, ..., M]&lt;/code&gt; correspond to the position within the grid, and the batch dimension combines both the position within a spatial block and the original batch position. Prior to division into blocks, the spatial dimensions of the input are optionally zero padded according to &lt;code&gt;paddings&lt;/code&gt;. See below for a precise description.</source>
          <target state="translated">이 연산 은 입력의 &quot;공간&quot;치수 &lt;code&gt;[1, ..., M]&lt;/code&gt; 을 블록 블록 모양의 블록 격자로 &lt;code&gt;block_shape&lt;/code&gt; 출력에서 공간 치수가되도록 &quot;배치&quot;치수 (0)로 이러한 블록을 인터리브합니다. &lt;code&gt;[1, ..., M]&lt;/code&gt; 은 그리드 내의 위치에 해당하며 배치 차원은 공간 블록 내의 위치와 원래 배치 위치를 모두 결합합니다. 블록으로 분할하기 전에, 입력의 공간적 차원에있어서 선택적으로 제로 패딩되어 &lt;code&gt;paddings&lt;/code&gt; . 자세한 설명은 아래를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="5d3e7305e25146c306e9ca9dac7912d7b2d4ded2" translate="yes" xml:space="preserve">
          <source>This operation extracts a slice of size &lt;code&gt;size&lt;/code&gt; from a tensor &lt;code&gt;input_&lt;/code&gt; starting at the location specified by &lt;code&gt;begin&lt;/code&gt;. The slice &lt;code&gt;size&lt;/code&gt; is represented as a tensor shape, where &lt;code&gt;size[i]&lt;/code&gt; is the number of elements of the 'i'th dimension of &lt;code&gt;input_&lt;/code&gt; that you want to slice. The starting location (&lt;code&gt;begin&lt;/code&gt;) for the slice is represented as an offset in each dimension of &lt;code&gt;input_&lt;/code&gt;. In other words, &lt;code&gt;begin[i]&lt;/code&gt; is the offset into the i'th dimension of &lt;code&gt;input_&lt;/code&gt; that you want to slice from.</source>
          <target state="translated">이 작업 은 &lt;code&gt;begin&lt;/code&gt; 에 지정된 위치에서 시작 하는 텐서 &lt;code&gt;input_&lt;/code&gt; 에서 크기 &lt;code&gt;size&lt;/code&gt; 의 슬라이스를 추출 합니다 . 슬라이스 &lt;code&gt;size&lt;/code&gt; 는 텐서 모양으로 표시됩니다. 여기서 &lt;code&gt;size[i]&lt;/code&gt; 는 슬라이스하려는 'i'차원의 &lt;code&gt;input_&lt;/code&gt; 요소 수입니다 . 슬라이스 의 시작 위치 ( &lt;code&gt;begin&lt;/code&gt; )는 &lt;code&gt;input_&lt;/code&gt; 의 각 차원에서 오프셋으로 표시됩니다 . 즉, &lt;code&gt;begin[i]&lt;/code&gt; 는 슬라이스하려는 &lt;code&gt;input_&lt;/code&gt; 의 i 번째 차원에 대한 오프셋 입니다.</target>
        </trans-unit>
        <trans-unit id="29ab911f3d597d49d14cf454f1533a4b19e5e15b" translate="yes" xml:space="preserve">
          <source>This operation extracts the specified region from the tensor. The notation is similar to NumPy with the restriction that currently only support basic indexing. That means that using a non-scalar tensor as input is not currently allowed.</source>
          <target state="translated">이 작업은 텐서에서 지정된 영역을 추출합니다. 이 표기법은 현재 기본 색인 만 지원하는 제한 사항이있는 NumPy와 유사합니다. 즉, 스칼라 이외의 텐서를 입력으로 사용하는 것은 현재 허용되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="2d3ec2c39ae0a5c24c1de4e22eea70e184fc371a" translate="yes" xml:space="preserve">
          <source>This operation has a gradient and thus allows for training &lt;code&gt;min&lt;/code&gt; and &lt;code&gt;max&lt;/code&gt; values.</source>
          <target state="translated">이 작업에는 기울기가 있으므로 &lt;code&gt;min&lt;/code&gt; 과 &lt;code&gt;max&lt;/code&gt; 값 을 학습 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="b78d17d35c34babe04bca7ab5360f7b9d4aad4d2" translate="yes" xml:space="preserve">
          <source>This operation has the same semantics as &lt;code&gt;reshape&lt;/code&gt; on the represented dense tensor. The indices of non-empty values in &lt;code&gt;sp_input&lt;/code&gt; are recomputed based on the new dense shape, and a new &lt;code&gt;SparseTensor&lt;/code&gt; is returned containing the new indices and new shape. The order of non-empty values in &lt;code&gt;sp_input&lt;/code&gt; is unchanged.</source>
          <target state="translated">이 작업은 대표 밀도 텐서의 &lt;code&gt;reshape&lt;/code&gt; 과 동일한 의미를 갖습니다 . &lt;code&gt;sp_input&lt;/code&gt; 에서 비어 있지 않은 값의 인덱스는 새로운 조밀 한 모양을 기반으로 다시 계산 되며 새 인덱스와 새로운 모양을 포함 하는 새로운 &lt;code&gt;SparseTensor&lt;/code&gt; 가 반환됩니다. &lt;code&gt;sp_input&lt;/code&gt; 에서 비어 있지 않은 값의 순서 는 변경되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="1bd3f36c5bf6b7e281276b8f3d298543774510a1" translate="yes" xml:space="preserve">
          <source>This operation is a no-op when executing eagerly.</source>
          <target state="translated">이 작업은 간절히 실행할 때 작동하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="c77c133cb2aa87b66c50cea9b24338cf94df91e2" translate="yes" xml:space="preserve">
          <source>This operation is equivalent to the following steps:</source>
          <target state="translated">이 작업은 다음 단계와 같습니다.</target>
        </trans-unit>
        <trans-unit id="a85336f9b64b0941e75fed8873dd343470ffb664" translate="yes" xml:space="preserve">
          <source>This operation is for training only. It is generally an underestimate of the full softmax loss.</source>
          <target state="translated">이 작업은 훈련 전용입니다. 일반적으로 전체 최대 손실을 과소 평가합니다.</target>
        </trans-unit>
        <trans-unit id="6db0a8622252241b3dd8e4da9fc3d6ba84977a9c" translate="yes" xml:space="preserve">
          <source>This operation is related to &lt;code&gt;squeeze()&lt;/code&gt;, which removes dimensions of size 1.</source>
          <target state="translated">이 작업은 크기 1의 크기를 제거 하는 &lt;code&gt;squeeze()&lt;/code&gt; 와 관련이 있습니다 .</target>
        </trans-unit>
        <trans-unit id="49c94ac01402b2bd4ac870cdfc937202b7e69050" translate="yes" xml:space="preserve">
          <source>This operation is related to:</source>
          <target state="translated">이 작업은 다음과 관련이 있습니다.</target>
        </trans-unit>
        <trans-unit id="f8a4568939439baca88acb2c04e8494963c44c55" translate="yes" xml:space="preserve">
          <source>This operation is significantly more numerically stable than the equivalent tensorflow operation &lt;code&gt;tf.math.log(tf.math.cumsum(tf.math.exp(x)))&lt;/code&gt;, although computes the same result given infinite numerical precision. However, note that in some cases, it may be less stable than &lt;a href=&quot;reduce_logsumexp&quot;&gt;&lt;code&gt;tf.math.reduce_logsumexp&lt;/code&gt;&lt;/a&gt; for a given element, as it applies the &quot;log-sum-exp trick&quot; in a different way.</source>
          <target state="translated">이 연산은 등가 tensorflow 연산 &lt;code&gt;tf.math.log(tf.math.cumsum(tf.math.exp(x)))&lt;/code&gt; 보다 훨씬 수치 적으로 안정적 이지만, 무한한 수치 정밀도로 동일한 결과를 계산합니다. 그러나 어떤 경우 에는 &quot;log-sum-exp exp trick&quot;을 다른 방식으로 적용하기 때문에 주어진 요소에 대해 &lt;a href=&quot;reduce_logsumexp&quot;&gt; &lt;code&gt;tf.math.reduce_logsumexp&lt;/code&gt; &lt;/a&gt; 보다 덜 안정적 일 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="0cce4836efcc5d3f1c90cad3d4974cf4b16512f4" translate="yes" xml:space="preserve">
          <source>This operation is similar to tensor_scatter_add, except that the tensor is zero-initialized. Calling &lt;a href=&quot;scatter_nd&quot;&gt;&lt;code&gt;tf.scatter_nd(indices, values, shape)&lt;/code&gt;&lt;/a&gt; is identical to &lt;code&gt;tensor_scatter_add(tf.zeros(shape, values.dtype), indices, values)&lt;/code&gt;</source>
          <target state="translated">이 작업은 tensor가 0으로 초기화된다는 점을 제외하고 tensor_scatter_add와 유사합니다. &lt;a href=&quot;scatter_nd&quot;&gt; &lt;code&gt;tf.scatter_nd(indices, values, shape)&lt;/code&gt; &lt;/a&gt; 호출 은 &lt;code&gt;tensor_scatter_add(tf.zeros(shape, values.dtype), indices, values)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="50f836730593fffe361ee867e1bf79d15e8af917" translate="yes" xml:space="preserve">
          <source>This operation is sometimes called &quot;deconvolution&quot; after &lt;a href=&quot;http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt;, but is actually the transpose (gradient) of &lt;code&gt;conv2d&lt;/code&gt; rather than an actual deconvolution.</source>
          <target state="translated">이 작업은 &lt;a href=&quot;http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt; 이후 &quot;deconvolution&quot;이라고도 하지만 실제로 실제 deconvolution이 아니라 &lt;code&gt;conv2d&lt;/code&gt; 의 조옮김 (그라데이션)입니다 .</target>
        </trans-unit>
        <trans-unit id="cdd40bbfb18d0876cdd3d1bf655721101051d082" translate="yes" xml:space="preserve">
          <source>This operation is sometimes called &quot;deconvolution&quot; after &lt;a href=&quot;http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt;, but is actually the transpose (gradient) of &lt;code&gt;convolution&lt;/code&gt; rather than an actual deconvolution.</source>
          <target state="translated">이 작업은 &lt;a href=&quot;http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt; 이후 &quot;deconvolution&quot;이라고도 하지만 실제로 실제 디컨 볼 &lt;code&gt;convolution&lt;/code&gt; 아닌 컨볼 루션 의 조옮김 (그라데이션)입니다 .</target>
        </trans-unit>
        <trans-unit id="a80e63d8e3617ef22a7c11bc4ac5ce2aac92b83c" translate="yes" xml:space="preserve">
          <source>This operation is sometimes called &quot;deconvolution&quot; after &lt;a href=&quot;https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt;, but is really the transpose (gradient) of &lt;code&gt;atrous_conv2d&lt;/code&gt; rather than an actual deconvolution.</source>
          <target state="translated">이 작업은 &lt;a href=&quot;https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt; 이후 &quot;deconvolution&quot;이라고도 하지만 실제로 실제 deconvolution이 아닌 &lt;code&gt;atrous_conv2d&lt;/code&gt; 의 조옮김 (그라데이션)입니다 .</target>
        </trans-unit>
        <trans-unit id="3e16e89f92d27118cbc90336d321edbdccabf257" translate="yes" xml:space="preserve">
          <source>This operation is sometimes called &quot;deconvolution&quot; after &lt;a href=&quot;https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt;, but is really the transpose (gradient) of &lt;code&gt;conv1d&lt;/code&gt; rather than an actual deconvolution.</source>
          <target state="translated">이 작업은 &lt;a href=&quot;https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt; 이후 &quot;deconvolution&quot;이라고도 하지만 실제로 실제 deconvolution이 아니라 &lt;code&gt;conv1d&lt;/code&gt; 의 조옮김 (그라데이션)입니다 .</target>
        </trans-unit>
        <trans-unit id="74c54a1240dd3ebac671477622bdae5730c68b14" translate="yes" xml:space="preserve">
          <source>This operation is sometimes called &quot;deconvolution&quot; after &lt;a href=&quot;https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt;, but is really the transpose (gradient) of &lt;code&gt;conv2d&lt;/code&gt; rather than an actual deconvolution.</source>
          <target state="translated">이 작업은 &lt;a href=&quot;https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt; 이후 &quot;deconvolution&quot;이라고도 하지만 실제로 실제 deconvolution이 아니라 &lt;code&gt;conv2d&lt;/code&gt; 의 조옮김 (그라데이션)입니다 .</target>
        </trans-unit>
        <trans-unit id="78632da26e5444bf46256b6e1c192a603e6c3c00" translate="yes" xml:space="preserve">
          <source>This operation is sometimes called &quot;deconvolution&quot; after &lt;a href=&quot;https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt;, but is really the transpose (gradient) of &lt;code&gt;conv3d&lt;/code&gt; rather than an actual deconvolution.</source>
          <target state="translated">이 작업은 &lt;a href=&quot;https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt; 이후 &quot;deconvolution&quot;이라고도 하지만 실제로 실제 deconvolution이 아니라 &lt;code&gt;conv3d&lt;/code&gt; 의 조옮김 (그라데이션)입니다 .</target>
        </trans-unit>
        <trans-unit id="20f728b5bb5e16f6250024eb3cf614e43cfbbe07" translate="yes" xml:space="preserve">
          <source>This operation is typically used to clip gradients before applying them with an optimizer.</source>
          <target state="translated">이 작업은 일반적으로 옵티 마이저로 그라디언트를 적용하기 전에 그라디언트를 클리핑하는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="5397809ea0e6b96d049101c13960159515304d67" translate="yes" xml:space="preserve">
          <source>This operation is useful for resizing the activations between convolutions (but keeping all data), e.g. instead of pooling. It is also useful for training purely convolutional models.</source>
          <target state="translated">이 작업은 풀링 대신 컨볼 루션 간의 활성화 크기를 조정하지만 모든 데이터를 유지하는 데 유용합니다. 순전히 컨볼 루션 모델을 훈련하는 데에도 유용합니다.</target>
        </trans-unit>
        <trans-unit id="e6cbba91c74639c8cb40de16428e2bef0563e905" translate="yes" xml:space="preserve">
          <source>This operation is useful if you want to add a batch dimension to a single element. For example, if you have a single image of shape &lt;code&gt;[height, width, channels]&lt;/code&gt;, you can make it a batch of 1 image with &lt;code&gt;expand_dims(image, 0)&lt;/code&gt;, which will make the shape &lt;code&gt;[1, height, width, channels]&lt;/code&gt;.</source>
          <target state="translated">이 작업은 단일 요소에 배치 차원을 추가하려는 경우에 유용합니다. 예를 들어, 모양 &lt;code&gt;[height, width, channels]&lt;/code&gt; 의 단일 이미지가있는 경우 &lt;code&gt;expand_dims(image, 0)&lt;/code&gt; 을 사용하여 모양이 &lt;code&gt;[1, height, width, channels]&lt;/code&gt; 인 1 개의 이미지를 일괄 적으로 만들 수 있습니다 . .</target>
        </trans-unit>
        <trans-unit id="6316e455129ed9fa859e28aacc9886a66315035c" translate="yes" xml:space="preserve">
          <source>This operation is useful if you want to add a batch dimension to a single element. For example, if you have a single image of shape &lt;code&gt;[height, width, channels]&lt;/code&gt;, you can make it a batch of one image with &lt;code&gt;expand_dims(image, 0)&lt;/code&gt;, which will make the shape &lt;code&gt;[1, height, width, channels]&lt;/code&gt;.</source>
          <target state="translated">이 작업은 단일 요소에 배치 차원을 추가하려는 경우에 유용합니다. 예를 들어, &lt;code&gt;[height, width, channels]&lt;/code&gt; 모양의 단일 이미지가있는 경우 &lt;code&gt;expand_dims(image, 0)&lt;/code&gt; 하여 하나의 이미지를 일괄 처리 하여 모양을 &lt;code&gt;[1, height, width, channels]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7d1d3aca1842cf510032065cfce3509b5c793096" translate="yes" xml:space="preserve">
          <source>This operation outputs &quot;ref&quot; after the update is done. This makes it easier to chain operations that need to use the reset value. Unlike &lt;a href=&quot;../../math/add&quot;&gt;&lt;code&gt;tf.math.add&lt;/code&gt;&lt;/a&gt;, this op does not broadcast. &lt;code&gt;ref&lt;/code&gt; and &lt;code&gt;value&lt;/code&gt; must have the same shape.</source>
          <target state="translated">이 작업은 업데이트가 완료된 후 &quot;ref&quot;를 출력합니다. 따라서 재설정 값을 사용해야하는 작업을보다 쉽게 ​​연결할 수 있습니다. &lt;a href=&quot;../../math/add&quot;&gt; &lt;code&gt;tf.math.add&lt;/code&gt; &lt;/a&gt; 와 달리이 op는 브로드 캐스트되지 않습니다. &lt;code&gt;ref&lt;/code&gt; 과 &lt;code&gt;value&lt;/code&gt; 는 같은 모양이어야합니다.</target>
        </trans-unit>
        <trans-unit id="7e16eef80cf37c2d9c02fad5e714a6e559684854" translate="yes" xml:space="preserve">
          <source>This operation outputs &lt;code&gt;ref&lt;/code&gt; after the update is done. This makes it easier to chain operations that need to use the reset value.</source>
          <target state="translated">이 작업 은 업데이트가 완료된 후 &lt;code&gt;ref&lt;/code&gt; 을 출력 합니다. 따라서 재설정 값을 사용해야하는 작업을 쉽게 연결할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="80080e1227c1f588b580293eb11f01d8754cc2fa" translate="yes" xml:space="preserve">
          <source>This operation outputs &lt;code&gt;ref&lt;/code&gt; after the update is done. This makes it easier to chain operations that need to use the reset value. Unlike &lt;a href=&quot;../../math/subtract&quot;&gt;&lt;code&gt;tf.math.subtract&lt;/code&gt;&lt;/a&gt;, this op does not broadcast. &lt;code&gt;ref&lt;/code&gt; and &lt;code&gt;value&lt;/code&gt; must have the same shape.</source>
          <target state="translated">이 작업 은 업데이트가 완료된 후 &lt;code&gt;ref&lt;/code&gt; 을 출력 합니다. 따라서 재설정 값을 사용해야하는 작업을보다 쉽게 ​​연결할 수 있습니다. &lt;a href=&quot;../../math/subtract&quot;&gt; &lt;code&gt;tf.math.subtract&lt;/code&gt; &lt;/a&gt; 와 달리이 op는 브로드 캐스트되지 않습니다. &lt;code&gt;ref&lt;/code&gt; 과 &lt;code&gt;value&lt;/code&gt; 는 같은 모양이어야합니다.</target>
        </trans-unit>
        <trans-unit id="211cf88f878719f0fdbc3eba7700cfd25f62b94c" translate="yes" xml:space="preserve">
          <source>This operation outputs &lt;code&gt;ref&lt;/code&gt; after the update is done. This makes it easier to chain operations that need to use the updated value. Duplicate entries are handled correctly: if multiple &lt;code&gt;indices&lt;/code&gt; reference the same location, their contributions add.</source>
          <target state="translated">이 작업 은 업데이트가 완료된 후 &lt;code&gt;ref&lt;/code&gt; 을 출력 합니다. 따라서 업데이트 된 값을 사용해야하는 작업을보다 쉽게 ​​연결할 수 있습니다. 중복 항목이 올바르게 처리됩니다. 여러 &lt;code&gt;indices&lt;/code&gt; 가 동일한 위치를 참조하는 경우 기여가 추가됩니다.</target>
        </trans-unit>
        <trans-unit id="f7141134307e0a174b2d64cd3ba50899cf746d15" translate="yes" xml:space="preserve">
          <source>This operation outputs a Tensor that holds the new value of &lt;code&gt;ref&lt;/code&gt; after the value has been assigned. This makes it easier to chain operations that need to use the reset value.</source>
          <target state="translated">이 작업 은 값이 할당 된 후 새로운 &lt;code&gt;ref&lt;/code&gt; 값을 유지하는 Tensor를 출력합니다 . 따라서 재설정 값을 사용해야하는 작업을보다 쉽게 ​​연결할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="d8dcb952f1fd946dc8a99ab12f18c6c9f3bad230" translate="yes" xml:space="preserve">
          <source>This operation pads a &lt;code&gt;tensor&lt;/code&gt; according to the &lt;code&gt;paddings&lt;/code&gt; you specify. &lt;code&gt;paddings&lt;/code&gt; is an integer tensor with shape &lt;code&gt;[n, 2]&lt;/code&gt;, where n is the rank of &lt;code&gt;tensor&lt;/code&gt;. For each dimension D of &lt;code&gt;input&lt;/code&gt;, &lt;code&gt;paddings[D, 0]&lt;/code&gt; indicates how many values to add before the contents of &lt;code&gt;tensor&lt;/code&gt; in that dimension, and &lt;code&gt;paddings[D, 1]&lt;/code&gt; indicates how many values to add after the contents of &lt;code&gt;tensor&lt;/code&gt; in that dimension. If &lt;code&gt;mode&lt;/code&gt; is &quot;REFLECT&quot; then both &lt;code&gt;paddings[D, 0]&lt;/code&gt; and &lt;code&gt;paddings[D, 1]&lt;/code&gt; must be no greater than &lt;code&gt;tensor.dim_size(D) - 1&lt;/code&gt;. If &lt;code&gt;mode&lt;/code&gt; is &quot;SYMMETRIC&quot; then both &lt;code&gt;paddings[D, 0]&lt;/code&gt; and &lt;code&gt;paddings[D, 1]&lt;/code&gt; must be no greater than &lt;code&gt;tensor.dim_size(D)&lt;/code&gt;.</source>
          <target state="translated">이 작업은 지정한 &lt;code&gt;paddings&lt;/code&gt; 에 따라 &lt;code&gt;tensor&lt;/code&gt; 를 채 웁니다 . &lt;code&gt;paddings&lt;/code&gt; 은 모양 &lt;code&gt;[n, 2]&lt;/code&gt; 의 정수 텐서이며 , 여기서 n은 &lt;code&gt;tensor&lt;/code&gt; 의 순위입니다 . 각각의 치수 D의 경우 &lt;code&gt;input&lt;/code&gt; , &lt;code&gt;paddings[D, 0]&lt;/code&gt; 의 내용 전에 추가하는 방법은 많은 값 나타내는 &lt;code&gt;tensor&lt;/code&gt; 그 치수 및 &lt;code&gt;paddings[D, 1]&lt;/code&gt; 의 내용을 후에 추가하는 방법은 많은 값 나타내는 &lt;code&gt;tensor&lt;/code&gt; 그 사이즈에있다. 경우 &lt;code&gt;mode&lt;/code&gt; 이며 다음 모두 &quot;REFLECT&quot; &lt;code&gt;paddings[D, 0]&lt;/code&gt; 및 &lt;code&gt;paddings[D, 1]&lt;/code&gt; 보다 크지 않아야 &lt;code&gt;tensor.dim_size(D) - 1&lt;/code&gt; . 경우 &lt;code&gt;mode&lt;/code&gt; &quot;대칭 적&quot;이다 후 양쪽 &lt;code&gt;paddings[D, 0]&lt;/code&gt; 및 &lt;code&gt;paddings[D, 1]&lt;/code&gt; 보다 크지 않아야 &lt;code&gt;tensor.dim_size(D)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ece6bb1bca3b5a4f71fcb2a4c7bb7def98bb6471" translate="yes" xml:space="preserve">
          <source>This operation performs non_max_suppression on the inputs per batch, across all classes. Prunes away boxes that have high intersection-over-union (IOU) overlap with previously selected boxes. Bounding boxes are supplied as [y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any diagonal pair of box corners and the coordinates can be provided as normalized (i.e., lying in the interval [0, 1]) or absolute. Note that this algorithm is agnostic to where the origin is in the coordinate system. Also note that this algorithm is invariant to orthogonal transformations and translations of the coordinate system; thus translating or reflections of the coordinate system result in the same boxes being selected by the algorithm. The output of this operation is the final boxes, scores and classes tensor returned after performing non_max_suppression.</source>
          <target state="translated">이 작업은 모든 클래스에서 배치 당 입력에 대해 non_max_suppression을 수행합니다. 높은 IOU (교집합 교차)가있는 상자를 이전에 선택한 상자와 겹치십시오. 경계 상자는 [y1, x1, y2, x2]로 제공되며, 여기서 (y1, x1) 및 (y2, x2)는 상자 모서리의 대각선 쌍의 좌표이며 좌표는 정규화 된대로 제공 할 수 있습니다 (즉, 간격 [0, 1]) 또는 절대 값. 이 알고리즘은 원점이 좌표계의 위치와 관계가 없습니다. 또한이 알고리즘은 좌표계의 직교 변환 및 변환에 변하지 않습니다. 따라서 좌표계의 변환 또는 반사는 알고리즘에 의해 동일한 박스가 선택되게한다. 이 작업의 결과는 마지막 상자입니다.non_max_suppression을 수행 한 후 점수 및 클래스 텐서가 반환됩니다.</target>
        </trans-unit>
        <trans-unit id="92bf8506361b0c3190382a71e7f126a1495f07cd" translate="yes" xml:space="preserve">
          <source>This operation randomly samples a tensor of sampled classes (&lt;code&gt;sampled_candidates&lt;/code&gt;) from the range of integers &lt;code&gt;[0, range_max)&lt;/code&gt;.</source>
          <target state="translated">이 연산 은 정수 범위 &lt;code&gt;[0, range_max)&lt;/code&gt; 에서 샘플링 된 클래스 ( &lt;code&gt;sampled_candidates&lt;/code&gt; ) 의 텐서를 무작위로 샘플링합니다 .</target>
        </trans-unit>
        <trans-unit id="2656ea13a552cbb0836e0031c2afa8bfe371a2e1" translate="yes" xml:space="preserve">
          <source>This operation requires that:</source>
          <target state="translated">이 작업에는 다음이 필요합니다.</target>
        </trans-unit>
        <trans-unit id="85455e262fab5e8f9fc55d0016d69887ed46e6fb" translate="yes" xml:space="preserve">
          <source>This operation reshapes the &quot;batch&quot; dimension 0 into &lt;code&gt;M + 1&lt;/code&gt; dimensions of shape &lt;code&gt;block_shape + [batch]&lt;/code&gt;, interleaves these blocks back into the grid defined by the spatial dimensions &lt;code&gt;[1, ..., M]&lt;/code&gt;, to obtain a result with the same rank as the input. The spatial dimensions of this intermediate result are then optionally cropped according to &lt;code&gt;crops&lt;/code&gt; to produce the output. This is the reverse of SpaceToBatch. See below for a precise description.</source>
          <target state="translated">이 작업은 &quot;일괄 처리&quot;차원 0을 형태 &lt;code&gt;block_shape + [batch]&lt;/code&gt; 의 &lt;code&gt;M + 1&lt;/code&gt; 차원으로 재구성 하고 공간 블록 &lt;code&gt;[1, ..., M]&lt;/code&gt; 의해 정의 된 그리드로이 블록을 인터리브 하여 입력과 같은 순위입니다. 이어서,이 중간 결과의 공간 치수는 &lt;code&gt;crops&lt;/code&gt; 에 따라 선택적으로 크롭 되어 출력을 생성한다. 이것은 SpaceToBatch의 반대입니다. 자세한 설명은 아래를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="fe8665b789d92e174b87e3b8d8b3131e0c5a95d4" translate="yes" xml:space="preserve">
          <source>This operation returns a 1-D integer tensor representing the shape of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">이 연산은 &lt;code&gt;input&lt;/code&gt; 의 모양을 나타내는 1 차원 정수 텐서를 반환합니다 .</target>
        </trans-unit>
        <trans-unit id="7a59463d2fe92b4018e2beec28525b7ad3bbf202" translate="yes" xml:space="preserve">
          <source>This operation returns a tensor &lt;code&gt;y&lt;/code&gt; containing all of the unique elements of &lt;code&gt;x&lt;/code&gt; sorted in the same order that they occur in &lt;code&gt;x&lt;/code&gt;. This operation also returns a tensor &lt;code&gt;idx&lt;/code&gt; the same size as &lt;code&gt;x&lt;/code&gt; that contains the index of each value of &lt;code&gt;x&lt;/code&gt; in the unique output &lt;code&gt;y&lt;/code&gt;. Finally, it returns a third tensor &lt;code&gt;count&lt;/code&gt; that contains the count of each element of &lt;code&gt;y&lt;/code&gt; in &lt;code&gt;x&lt;/code&gt;. In other words:</source>
          <target state="translated">이 조작은 텐서 반환 &lt;code&gt;y&lt;/code&gt; 의 고유 한 모든 요소를 포함하는 &lt;code&gt;x&lt;/code&gt; 그들이 발생하는 것과 동일한 순서로 정렬 &lt;code&gt;x&lt;/code&gt; . 이 연산은 또한 고유 출력 &lt;code&gt;y&lt;/code&gt; 에 &lt;code&gt;x&lt;/code&gt; 의 각 값 인덱스를 포함하는 &lt;code&gt;x&lt;/code&gt; 와 동일한 크기 의 텐서 &lt;code&gt;idx&lt;/code&gt; 를 반환합니다 . 마지막으로, 제 텐서 반환 &lt;code&gt;count&lt;/code&gt; 의 각 요소의 카운트가 포함 &lt;code&gt;y&lt;/code&gt; 에서 &lt;code&gt;x&lt;/code&gt; . 다시 말해:</target>
        </trans-unit>
        <trans-unit id="536871e049e74061332eb50e7568b95429f16ba6" translate="yes" xml:space="preserve">
          <source>This operation returns a tensor &lt;code&gt;y&lt;/code&gt; containing all of the unique elements of &lt;code&gt;x&lt;/code&gt; sorted in the same order that they occur in &lt;code&gt;x&lt;/code&gt;; &lt;code&gt;x&lt;/code&gt; does not need to be sorted. This operation also returns a tensor &lt;code&gt;idx&lt;/code&gt; the same size as &lt;code&gt;x&lt;/code&gt; that contains the index of each value of &lt;code&gt;x&lt;/code&gt; in the unique output &lt;code&gt;y&lt;/code&gt;. In other words:</source>
          <target state="translated">이 조작은 텐서 반환 &lt;code&gt;y&lt;/code&gt; 의 고유 한 모든 요소를 포함하는 &lt;code&gt;x&lt;/code&gt; 그들이 발생하는 것과 동일한 순서로 정렬 &lt;code&gt;x&lt;/code&gt; ; &lt;code&gt;x&lt;/code&gt; 는 정렬 할 필요가 없습니다. 이 연산은 또한 고유 출력 &lt;code&gt;y&lt;/code&gt; 에 &lt;code&gt;x&lt;/code&gt; 의 각 값 인덱스를 포함하는 &lt;code&gt;x&lt;/code&gt; 와 동일한 크기 의 텐서 &lt;code&gt;idx&lt;/code&gt; 를 반환합니다 . 다시 말해:</target>
        </trans-unit>
        <trans-unit id="08bfd9d4b0608003900efe52523c1412fe2e10f1" translate="yes" xml:space="preserve">
          <source>This operation returns a tensor of type &lt;code&gt;dtype&lt;/code&gt; with shape &lt;code&gt;shape&lt;/code&gt; and all elements set to one.</source>
          <target state="translated">이 연산은 모양 &lt;code&gt;shape&lt;/code&gt; 과 모든 요소가 1로 설정된 &lt;code&gt;dtype&lt;/code&gt; 유형의 텐서를 반환합니다 .</target>
        </trans-unit>
        <trans-unit id="46403ed383d4150a23258a456b0faa0e79d56dbe" translate="yes" xml:space="preserve">
          <source>This operation returns a tensor of type &lt;code&gt;dtype&lt;/code&gt; with shape &lt;code&gt;shape&lt;/code&gt; and all elements set to zero.</source>
          <target state="translated">이 연산은 모양 &lt;code&gt;shape&lt;/code&gt; 과 모든 요소가 0으로 설정된 &lt;code&gt;dtype&lt;/code&gt; 유형의 텐서를 반환 합니다.</target>
        </trans-unit>
        <trans-unit id="476cbc978c015f266a3353221077ac3bad3036de" translate="yes" xml:space="preserve">
          <source>This operation returns a tensor with the &lt;code&gt;diagonal&lt;/code&gt; part of the &lt;code&gt;input&lt;/code&gt;. The &lt;code&gt;diagonal&lt;/code&gt; part is computed as follows:</source>
          <target state="translated">이 작업은 &lt;code&gt;input&lt;/code&gt; 의 &lt;code&gt;diagonal&lt;/code&gt; 부분이 있는 텐서를 반환합니다 . &lt;code&gt;diagonal&lt;/code&gt; 다음 부분이 계산된다 :</target>
        </trans-unit>
        <trans-unit id="e2b8bbf455ec7dda7bf033c368dcb34b158ee06e" translate="yes" xml:space="preserve">
          <source>This operation returns the same result as the C++ std::nextafter function.</source>
          <target state="translated">이 작업은 C ++ std :: nextafter 함수와 동일한 결과를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="cba2fef602700f559d54f64ca39679c7fe5a39cf" translate="yes" xml:space="preserve">
          <source>This operation returns true if the queue is closed and false if the queue is open.</source>
          <target state="translated">이 작업은 큐가 닫혀 있으면 true를, 큐가 열려 있으면 false를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="dc131f95b04b052706f9dc5a2e0863ccce212278" translate="yes" xml:space="preserve">
          <source>This operation signals that no more elements will be enqueued in the given queue. Subsequent &lt;code&gt;enqueue&lt;/code&gt; and &lt;code&gt;enqueue_many&lt;/code&gt; operations will fail. Subsequent &lt;code&gt;dequeue&lt;/code&gt; and &lt;code&gt;dequeue_many&lt;/code&gt; operations will continue to succeed if sufficient elements remain in the queue. Subsequently dequeue and dequeue_many operations that would otherwise block waiting for more elements (if close hadn't been called) will now fail immediately.</source>
          <target state="translated">이 작업은 주어진 큐에 더 이상 요소가 큐에 들어 가지 않음을 나타냅니다. 후속 &lt;code&gt;enqueue&lt;/code&gt; 및 &lt;code&gt;enqueue_many&lt;/code&gt; 작업이 실패합니다. &lt;code&gt;dequeue&lt;/code&gt; 충분한 요소가 남아 있으면 후속 dequeue 및 &lt;code&gt;dequeue_many&lt;/code&gt; 작업이 계속 성공합니다. 결과적으로 더 많은 요소 (닫지 않은 경우)를 기다리는 것을 차단하는 dequeue 및 dequeue_many 작업이 즉시 실패합니다.</target>
        </trans-unit>
        <trans-unit id="ed8ef290710f5b794405ab349bc8048a526b3051" translate="yes" xml:space="preserve">
          <source>This operation slices each component tensor along the 0th dimension to make multiple queue elements. All of the tensors in &lt;code&gt;vals&lt;/code&gt; must have the same size in the 0th dimension.</source>
          <target state="translated">이 작업은 각 구성 요소 텐서를 0 차원을 따라 슬라이스하여 여러 큐 요소를 만듭니다. 에서 텐서의 모든 &lt;code&gt;vals&lt;/code&gt; 0 번째 차원의 크기가 동일해야합니다.</target>
        </trans-unit>
        <trans-unit id="b06acef6473406f9a6972f0bdd65c856a80109e7" translate="yes" xml:space="preserve">
          <source>This operation takes variable-length sequences (&lt;code&gt;hypothesis&lt;/code&gt; and &lt;code&gt;truth&lt;/code&gt;), each provided as a &lt;code&gt;SparseTensor&lt;/code&gt;, and computes the Levenshtein distance. You can normalize the edit distance by length of &lt;code&gt;truth&lt;/code&gt; by setting &lt;code&gt;normalize&lt;/code&gt; to true.</source>
          <target state="translated">이 연산은 각각 &lt;code&gt;SparseTensor&lt;/code&gt; 로 제공되는 가변 길이 시퀀스 ( &lt;code&gt;hypothesis&lt;/code&gt; 및 &lt;code&gt;truth&lt;/code&gt; )를 취하고 Levenshtein 거리를 계산합니다. &lt;code&gt;normalize&lt;/code&gt; 를 true 로 설정 하여 &lt;code&gt;truth&lt;/code&gt; 길이별로 편집 거리를 정규화 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="4b844fb17a610af4c2dfbda43ce1ac8c2ea894a7" translate="yes" xml:space="preserve">
          <source>This operation tends to perform well when &lt;code&gt;A&lt;/code&gt; is more sparse, if the column size of the product is small (e.g. matrix-vector multiplication), if &lt;code&gt;sp_a.dense_shape&lt;/code&gt; takes on large values.</source>
          <target state="translated">&lt;code&gt;sp_a.dense_shape&lt;/code&gt; 가 큰 값을 사용하는 경우 곱의 열 크기가 작은 경우 (예 : 행렬-벡터 곱셈) &lt;code&gt;A&lt;/code&gt; 가 더 희소 한 경우이 연산이 잘 수행되는 경향이 있습니다.</target>
        </trans-unit>
        <trans-unit id="1051e1cb11d005837380c93974db8cb36d834ab5" translate="yes" xml:space="preserve">
          <source>This operation will generate a string suitable to be saved out to create a .wav audio file. It will be encoded in the 16-bit PCM format. It takes in float values in the range -1.0f to 1.0f, and any outside that value will be clamped to that range.</source>
          <target state="translated">이 작업은 .wav 오디오 파일을 만들기 위해 저장하기에 적합한 문자열을 생성합니다. 16 비트 PCM 형식으로 인코딩됩니다. -1.0f ~ 1.0f 범위의 부동 소수점 값을 취하며 해당 값 이외의 값은 해당 범위에 고정됩니다.</target>
        </trans-unit>
        <trans-unit id="bf6b9f0d6051cd83422b6ad2cb1617b5b6c44a65" translate="yes" xml:space="preserve">
          <source>This operation will output a tensor of shape &lt;code&gt;[1, 1, 1, 4]&lt;/code&gt;:</source>
          <target state="translated">이 작업은 모양 &lt;code&gt;[1, 1, 1, 4]&lt;/code&gt; 의 텐서를 출력합니다 .</target>
        </trans-unit>
        <trans-unit id="01c0abdcd1d63eef5d525eb4d621b9072cafca4f" translate="yes" xml:space="preserve">
          <source>This operation will output a tensor of shape &lt;code&gt;[1, 2, 2, 1]&lt;/code&gt;:</source>
          <target state="translated">이 작업은 모양 &lt;code&gt;[1, 2, 2, 1]&lt;/code&gt; 의 텐서를 출력합니다 .</target>
        </trans-unit>
        <trans-unit id="f9c1bb170834121c155816075bc30535b34c3026" translate="yes" xml:space="preserve">
          <source>This operation would return the following:</source>
          <target state="translated">이 작업은 다음을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="c09d355015c640623e774187c625203da78fb3a6" translate="yes" xml:space="preserve">
          <source>This operation would return:</source>
          <target state="translated">이 작업은 다음을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="6585b279d1753d7936601f5ce821925656bfd5b2" translate="yes" xml:space="preserve">
          <source>This operation, for block size of 2, will return the following tensor of shape &lt;code&gt;[1, 2, 2, 3]&lt;/code&gt;</source>
          <target state="translated">블록 크기가 2 인 경우이 작업은 다음 모양의 텐서를 반환합니다. &lt;code&gt;[1, 2, 2, 3]&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="123e5c864ddc20e423825601cb576b64af53b67e" translate="yes" xml:space="preserve">
          <source>This operation, for block_size of 2, will return the following tensor of shape &lt;code&gt;[1, 1, 1, 12]&lt;/code&gt;</source>
          <target state="translated">이 작업은 block_size가 2 인 경우 다음 모양 &lt;code&gt;[1, 1, 1, 12]&lt;/code&gt; 텐서를 반환합니다 .</target>
        </trans-unit>
        <trans-unit id="2a0a130eb7e8314a609a2db135e21936c4a0de8b" translate="yes" xml:space="preserve">
          <source>This operator acts like a (batch) matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, M, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;m x n&lt;/code&gt; matrix. Again, this matrix &lt;code&gt;A&lt;/code&gt; may not be materialized, but for purposes of identifying and working with compatible arguments the shape is relevant.</source>
          <target state="translated">이것은 운영자가 (배치) 매트릭스와 같은 역할을 형상 &lt;code&gt;[B1,...,Bb, M, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;m x n&lt;/code&gt; 행렬입니다. 다시,이 행렬 &lt;code&gt;A&lt;/code&gt; 는 구체화되지 않을 수 있지만, 호환 가능한 인수를 식별하고 작업하기 위해 형태가 관련이 있습니다. &lt;code&gt;A&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="9624d2140d2af8604c19c56292430ec7141d96ff" translate="yes" xml:space="preserve">
          <source>This operator acts like a [batch] Toeplitz matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;N x N&lt;/code&gt; matrix. This matrix &lt;code&gt;A&lt;/code&gt; is not materialized, but for purposes of broadcasting this shape will be relevant.</source>
          <target state="translated">이것은 오퍼레이터가 [배치]처럼 퇴 플리츠 행렬 작용 &lt;code&gt;A&lt;/code&gt; 형상 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;N x N&lt;/code&gt; 행렬입니다. 이 행렬 &lt;code&gt;A&lt;/code&gt; 는 구체화되지 않았지만 브로드 캐스팅 목적으로이 모양이 적합합니다.</target>
        </trans-unit>
        <trans-unit id="ae991b61103c038a5ab6e26593ecbc7152e117f2" translate="yes" xml:space="preserve">
          <source>This operator acts like a [batch] diagonal matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;N x N&lt;/code&gt; matrix. This matrix &lt;code&gt;A&lt;/code&gt; is not materialized, but for purposes of broadcasting this shape will be relevant.</source>
          <target state="translated">이것은 오퍼레이터가 [배치] 대각 매트릭스와 같은 역할을 형상 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;N x N&lt;/code&gt; 행렬입니다. 이 행렬 &lt;code&gt;A&lt;/code&gt; 는 구체화되지 않았지만 브로드 캐스팅 목적으로이 모양이 적합합니다. &lt;code&gt;A&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="5eea0437af7326077ca375b7627f553585750e30" translate="yes" xml:space="preserve">
          <source>This operator acts like a [batch] identity matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;N x N&lt;/code&gt; matrix. This matrix &lt;code&gt;A&lt;/code&gt; is not materialized, but for purposes of broadcasting this shape will be relevant.</source>
          <target state="translated">이것은 오퍼레이터가 [배치] 아이덴티티 매트릭스와 같은 역할을 형상 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;N x N&lt;/code&gt; 행렬입니다. 이 행렬 &lt;code&gt;A&lt;/code&gt; 는 구체화되지 않았지만 브로드 캐스팅 목적으로이 모양이 적합합니다. &lt;code&gt;A&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7036bf9c433fed406d0eb267aee69b2fb875c75f" translate="yes" xml:space="preserve">
          <source>This operator acts like a [batch] lower triangular matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;N x N&lt;/code&gt; matrix.</source>
          <target state="translated">이것은 운영자가 삼각 행렬 낮은 [배치]처럼 행동 &lt;code&gt;A&lt;/code&gt; 형상 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;N x N&lt;/code&gt; 행렬입니다.</target>
        </trans-unit>
        <trans-unit id="0d5825859d807d72eb10161ef6b5b940c6fe0b9b" translate="yes" xml:space="preserve">
          <source>This operator acts like a [batch] matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, M, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;M x N&lt;/code&gt; matrix.</source>
          <target state="translated">이것은 오퍼레이터가 [배치] 매트릭스와 같은 역할을 형상 &lt;code&gt;[B1,...,Bb, M, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;M x N&lt;/code&gt; 행렬입니다. &lt;code&gt;A&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="6f99131310964b3eb6cd5147dace10a254e9fff2" translate="yes" xml:space="preserve">
          <source>This operator acts like a [batch] of householder reflections with shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;N x N&lt;/code&gt; matrix. This matrix &lt;code&gt;A&lt;/code&gt; is not materialized, but for purposes of broadcasting this shape will be relevant.</source>
          <target state="translated">이 연산자 형상 호주 반사의 [배치]처럼 행동 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;N x N&lt;/code&gt; 행렬입니다. 이 행렬 &lt;code&gt;A&lt;/code&gt; 는 구체화되지 않았지만 브로드 캐스팅 목적으로이 모양이 적합합니다.</target>
        </trans-unit>
        <trans-unit id="2c9497726784db48f14f606b75baa3af89ad92c3" translate="yes" xml:space="preserve">
          <source>This operator acts like a [batch] of permutations with shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;N x N&lt;/code&gt; matrix. This matrix &lt;code&gt;A&lt;/code&gt; is not materialized, but for purposes of broadcasting this shape will be relevant.</source>
          <target state="translated">이 연산자 형상으로 치환 한 [배치]처럼 행동 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;N x N&lt;/code&gt; 행렬입니다. 이 행렬 &lt;code&gt;A&lt;/code&gt; 는 구체화되지 않았지만 브로드 캐스팅 목적으로이 모양이 적합합니다.</target>
        </trans-unit>
        <trans-unit id="400eb5597c413c726e34a9f1e1bb7b69ea62bb78" translate="yes" xml:space="preserve">
          <source>This operator acts like a [batch] zero matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, N, M]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;N x M&lt;/code&gt; matrix. This matrix &lt;code&gt;A&lt;/code&gt; is not materialized, but for purposes of broadcasting this shape will be relevant.</source>
          <target state="translated">이것은 오퍼레이터가 [배치]와 같은 영 행렬이 작용 &lt;code&gt;A&lt;/code&gt; 형상 &lt;code&gt;[B1,...,Bb, N, M]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;N x M&lt;/code&gt; 행렬입니다. 이 행렬 &lt;code&gt;A&lt;/code&gt; 는 구체화되지 않았지만 브로드 캐스팅 목적으로이 모양이 적합합니다.</target>
        </trans-unit>
        <trans-unit id="b7102c53ecb6c13af874ea168315014a6e7dc84b" translate="yes" xml:space="preserve">
          <source>This operator acts like a block circulant matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;N x N&lt;/code&gt; matrix. This matrix &lt;code&gt;A&lt;/code&gt; is not materialized, but for purposes of broadcasting this shape will be relevant.</source>
          <target state="translated">이 연산자 블록 순환 행렬 같은 역할 형상 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;N x N&lt;/code&gt; 행렬입니다. 이 행렬 &lt;code&gt;A&lt;/code&gt; 는 구체화되지 않았지만 브로드 캐스팅 목적으로이 모양이 적합합니다. &lt;code&gt;A&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="4c216274d20b8ffa480f3dfffdabad95ff0cda74" translate="yes" xml:space="preserve">
          <source>This operator acts like a circulant matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;N x N&lt;/code&gt; matrix. This matrix &lt;code&gt;A&lt;/code&gt; is not materialized, but for purposes of broadcasting this shape will be relevant.</source>
          <target state="translated">이것은 조작자가 순환 매트릭스와 같은 역할을 형상 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;N x N&lt;/code&gt; 행렬입니다. 이 행렬 &lt;code&gt;A&lt;/code&gt; 는 구체화되지 않았지만 브로드 캐스팅 목적으로이 모양이 적합합니다. &lt;code&gt;A&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="0f0a750eb3c4adb095723453eef766bb4bcd89f8" translate="yes" xml:space="preserve">
          <source>This operator acts like a scaled [batch] identity matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is a scaled version of the &lt;code&gt;N x N&lt;/code&gt; identity matrix.</source>
          <target state="translated">이 연산자 스케일링 [배치] 아이덴티티 매트릭스와 같은 역할을 형상 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;N x N&lt;/code&gt; 항등 행렬 의 스케일 된 버전입니다 . &lt;code&gt;A&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="8b1442fc44774d80a4540791883d0146d00de836" translate="yes" xml:space="preserve">
          <source>This operator acts on [batch] matrix with compatible shape. &lt;code&gt;x&lt;/code&gt; is a batch matrix with compatible shape for &lt;code&gt;matmul&lt;/code&gt; and &lt;code&gt;solve&lt;/code&gt; if</source>
          <target state="translated">이 연산자는 호환 가능한 모양의 [일괄 처리] 매트릭스에서 작동합니다. &lt;code&gt;x&lt;/code&gt; 호환 형상으로 배치 행렬 &lt;code&gt;matmul&lt;/code&gt; 은 및 &lt;code&gt;solve&lt;/code&gt; 한다면</target>
        </trans-unit>
        <trans-unit id="a4840abea8050987eeb44a958dc938a96dc5772f" translate="yes" xml:space="preserve">
          <source>This operator acts on batch matrices with compatible shape. FILL IN WHAT IS MEANT BY COMPATIBLE SHAPE</source>
          <target state="translated">이 연산자는 모양이 호환되는 배치 매트릭스에서 작동합니다. 호환 가능한 쉐이프의 의미</target>
        </trans-unit>
        <trans-unit id="53228a3fac3cf2f50966b1ada24ef3b0466deb1e" translate="yes" xml:space="preserve">
          <source>This operator combines one or more linear operators &lt;code&gt;[op1,...,opJ]&lt;/code&gt;, building a new &lt;code&gt;LinearOperator&lt;/code&gt;, whose underlying matrix representation is square and has each operator &lt;code&gt;opi&lt;/code&gt; on the main diagonal, and zero's elsewhere.</source>
          <target state="translated">이 조작을 결합하는 하나 이상의 선형 연산자 &lt;code&gt;[op1,...,opJ]&lt;/code&gt; , 새로운 건물 &lt;code&gt;LinearOperator&lt;/code&gt; 그 기본 행렬 표현 정사각형 각 오퍼레이터 가지고 &lt;code&gt;opi&lt;/code&gt; 주 대각선을 다른 곳의 제로한다.</target>
        </trans-unit>
        <trans-unit id="564367f646774e8a861547adb060150a45779d5f" translate="yes" xml:space="preserve">
          <source>This operator composes one or more linear operators &lt;code&gt;[op1,...,opJ]&lt;/code&gt;, building a new &lt;code&gt;LinearOperator&lt;/code&gt; representing the Kronecker product: &lt;code&gt;op1 x op2 x .. opJ&lt;/code&gt; (we omit parentheses as the Kronecker product is associative).</source>
          <target state="translated">이 연산자는 하나 이상의 선형 연산자 &lt;code&gt;[op1,...,opJ]&lt;/code&gt; 를 구성 하여 Kronecker 제품을 나타내는 새로운 &lt;code&gt;LinearOperator&lt;/code&gt; 를 작성합니다. &lt;code&gt;op1 x op2 x .. opJ&lt;/code&gt; (Kronecker 제품이 연관되어 있으므로 괄호는 생략합니다).</target>
        </trans-unit>
        <trans-unit id="0c0d85ebac206e74618bf7317ca7c96fff15c835" translate="yes" xml:space="preserve">
          <source>This operator composes one or more linear operators &lt;code&gt;[op1,...,opJ]&lt;/code&gt;, building a new &lt;code&gt;LinearOperator&lt;/code&gt; with action defined by:</source>
          <target state="translated">이 연산자는 하나 이상의 선형 연산자 &lt;code&gt;[op1,...,opJ]&lt;/code&gt; 를 &lt;code&gt;LinearOperator&lt;/code&gt; 하여 다음에 의해 정의 된 동작 으로 새 LinearOperator 를 작성합니다.</target>
        </trans-unit>
        <trans-unit id="8e7241eaa8846c5c4338cb18a140b07ab3b606ae" translate="yes" xml:space="preserve">
          <source>This operator corresponds to a real matrix if and only if &lt;code&gt;H&lt;/code&gt; is Hermitian.</source>
          <target state="translated">이 연산자 는 &lt;code&gt;H&lt;/code&gt; 가 Hermitian 인 경우에만 실제 행렬에 해당합니다 .</target>
        </trans-unit>
        <trans-unit id="6f9242e838252063460c0276fd01dfac0ef01ff4" translate="yes" xml:space="preserve">
          <source>This operator corresponds to a real-valued matrix if and only if its spectrum is Hermitian.</source>
          <target state="translated">이 연산자는 스펙트럼이 에르 미트 인 경우에만 실수 값 행렬에 해당합니다.</target>
        </trans-unit>
        <trans-unit id="c618e51b272c823eef5139b9cc3a948f981f98e8" translate="yes" xml:space="preserve">
          <source>This operator is able to broadcast the leading (batch) dimensions, which sometimes requires copying data. If &lt;code&gt;batch_shape&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt;, the operator can take arguments of any batch shape without copying. See examples.</source>
          <target state="translated">이 연산자는 선행 (일괄 처리) 차원을 브로드 캐스트 할 수 있으며 때로는 데이터를 복사해야합니다. 경우 &lt;code&gt;batch_shape&lt;/code&gt; 가 없습니다 &lt;code&gt;None&lt;/code&gt; , 운영자는 복사하지 않고 임의의 배치 형태의 인수를 취할 수 있습니다. 예를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="66cb218ad1e2e8f68e038b90d3bfb45bd6e74e63" translate="yes" xml:space="preserve">
          <source>This operator is able to broadcast the leading (batch) dimensions.</source>
          <target state="translated">이 연산자는 선행 (일괄) 차원을 브로드 캐스트 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="348a23cb6559c85829c515ac4244685e0efb46f2" translate="yes" xml:space="preserve">
          <source>This operator is considered non-singular if</source>
          <target state="translated">이 연산자는 다음과 같은 경우 단수로 간주됩니다</target>
        </trans-unit>
        <trans-unit id="d06a5054c0e8f5a488a0e50140ca1317d8ee8b76" translate="yes" xml:space="preserve">
          <source>This operator is positive definite if and only if &lt;code&gt;Real{H} &amp;gt; 0&lt;/code&gt;.</source>
          <target state="translated">이 연산자는 &lt;code&gt;Real{H} &amp;gt; 0&lt;/code&gt; 인 경우에만 양수 입니다.</target>
        </trans-unit>
        <trans-unit id="fa787331edbdbf77b6543a837e62e8acfa555fdd" translate="yes" xml:space="preserve">
          <source>This operator is self-adjoint if and only if &lt;code&gt;H&lt;/code&gt; is real.</source>
          <target state="translated">이 연산자는 &lt;code&gt;H&lt;/code&gt; 가 실수 인 경우에만 자체 인접합니다 .</target>
        </trans-unit>
        <trans-unit id="0434efb4cb6fe37aceabe23ccb563dea7d82d49a" translate="yes" xml:space="preserve">
          <source>This operator is similar to the unsorted segment sum operator found &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;(here)&lt;/a&gt;. Instead of computing the sum over segments, it computes the maximum such that:</source>
          <target state="translated">이 연산자는 분류되지 않은 세그먼트 합계 연산자 found &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;(here)&lt;/a&gt; 와 유사합니다 . 세그먼트에 대한 합계를 계산하는 대신 다음과 같은 최대 값을 계산합니다.</target>
        </trans-unit>
        <trans-unit id="f0203b5b1fedf802a969aad64e740ba2ad439f1c" translate="yes" xml:space="preserve">
          <source>This operator is similar to the unsorted segment sum operator found &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;(here)&lt;/a&gt;. Instead of computing the sum over segments, it computes the minimum such that:</source>
          <target state="translated">이 연산자는 분류되지 않은 세그먼트 합계 연산자 found &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;(here)&lt;/a&gt; 와 유사합니다 . 세그먼트에 대한 합계를 계산하는 대신 다음과 같은 최소값을 계산합니다.</target>
        </trans-unit>
        <trans-unit id="9b525fce235ebc8f800bcb2ded78049fa74f120a" translate="yes" xml:space="preserve">
          <source>This operator is similar to the unsorted segment sum operator found &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;(here)&lt;/a&gt;. Instead of computing the sum over segments, it computes the product of all entries belonging to a segment such that:</source>
          <target state="translated">이 연산자는 분류되지 않은 세그먼트 합계 연산자 found &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;(here)&lt;/a&gt; 와 유사합니다 . 세그먼트에 대한 합계를 계산하는 대신 세그먼트에 속하는 모든 항목의 곱을 계산합니다.</target>
        </trans-unit>
        <trans-unit id="59fd9e153dcbd12bffedb241b5f88000e9237c11" translate="yes" xml:space="preserve">
          <source>This operator is similar to the unsorted segment sum operator found &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;here&lt;/a&gt;. Additionally to computing the sum over segments, it divides the results by sqrt(N).</source>
          <target state="translated">이 연산자는 &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;여기&lt;/a&gt; 에있는 분류되지 않은 세그먼트 합계 연산자와 유사합니다 . 또한 세그먼트에 대한 합계를 계산할 때 결과를 sqrt (N)로 나눕니다.</target>
        </trans-unit>
        <trans-unit id="a4a7cb1afea6269197bd76bbd4732c1dbecdf7fc" translate="yes" xml:space="preserve">
          <source>This operator is similar to the unsorted segment sum operator found &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;here&lt;/a&gt;. Instead of computing the sum over segments, it computes the mean of all entries belonging to a segment such that:</source>
          <target state="translated">이 연산자는 &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;여기&lt;/a&gt; 에있는 분류되지 않은 세그먼트 합계 연산자와 유사합니다 . 세그먼트에 대한 합계를 계산하는 대신 세그먼트에 속하는 모든 항목의 평균을 다음과 같이 계산합니다.</target>
        </trans-unit>
        <trans-unit id="83929e057e5aae77fa1c5e82493e5f81ffd7c7d5" translate="yes" xml:space="preserve">
          <source>This operator represents the adjoint of another operator.</source>
          <target state="translated">이 연산자는 다른 연산자의 인접자를 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="011faa1fcbdac7f7db43d7798ee8f420d25df1c3" translate="yes" xml:space="preserve">
          <source>This operator represents the inverse of another operator.</source>
          <target state="translated">이 연산자는 다른 연산자의 역수를 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="caac5d3bbf4d0945a7bd985970cd4106cce90915" translate="yes" xml:space="preserve">
          <source>This operator wraps a [batch] matrix &lt;code&gt;A&lt;/code&gt; (which is a &lt;code&gt;Tensor&lt;/code&gt;) with shape &lt;code&gt;[B1,...,Bb, M, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;M x N&lt;/code&gt; matrix.</source>
          <target state="translated">이 연산자 는 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; 대해 &lt;code&gt;[B1,...,Bb, M, N]&lt;/code&gt; 모양 의 [일괄 처리] 행렬 &lt;code&gt;A&lt;/code&gt; ( &lt;code&gt;Tensor&lt;/code&gt; )를 래핑합니다 . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;M x N&lt;/code&gt; 행렬입니다.</target>
        </trans-unit>
        <trans-unit id="b7a64029550dddacbaa84a5c9b1e8fcd91b9538b" translate="yes" xml:space="preserve">
          <source>This optimizer class is &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; aware, which means it automatically sums gradients across all replicas. To average gradients, you divide your loss by the global batch size, which is done automatically if you use &lt;a href=&quot;../../keras&quot;&gt;&lt;code&gt;tf.keras&lt;/code&gt;&lt;/a&gt; built-in training or evaluation loops. See the &lt;code&gt;reduction&lt;/code&gt; argument of your loss which should be set to &lt;a href=&quot;../losses/reduction#SUM_OVER_BATCH_SIZE&quot;&gt;&lt;code&gt;tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE&lt;/code&gt;&lt;/a&gt; for averaging or &lt;a href=&quot;../losses/reduction#SUM&quot;&gt;&lt;code&gt;tf.keras.losses.Reduction.SUM&lt;/code&gt;&lt;/a&gt; for not.</source>
          <target state="translated">이 최적화 프로그램 클래스는 &lt;a href=&quot;../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; 를&lt;/a&gt; 인식하므로 모든 복제본에서 그라디언트를 자동으로 합합니다. 그라디언트를 평균화하려면 손실을 전역 배치 크기로 &lt;a href=&quot;../../keras&quot;&gt; &lt;code&gt;tf.keras&lt;/code&gt; &lt;/a&gt; 기본 제공 교육 또는 평가 루프 를 사용하면 자동으로 수행됩니다 . 참고 항목 &lt;code&gt;reduction&lt;/code&gt; 로 설정해야합니다 귀하의 손실의 인수 &lt;a href=&quot;../losses/reduction#SUM_OVER_BATCH_SIZE&quot;&gt; &lt;code&gt;tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE&lt;/code&gt; &lt;/a&gt; 평균 또는 대한 &lt;a href=&quot;../losses/reduction#SUM&quot;&gt; &lt;code&gt;tf.keras.losses.Reduction.SUM&lt;/code&gt; &lt;/a&gt; 하지 않는합니다.</target>
        </trans-unit>
        <trans-unit id="f9ca3ab79a1177cb06784d426253ffabbbc2a6a4" translate="yes" xml:space="preserve">
          <source>This optimizer takes care of regularization of unseen features in a mini batch by updating them when they are seen with a closed form update rule that is equivalent to having updated them on every mini-batch.</source>
          <target state="translated">이 옵티마이 저는 미니 배치에서 보이지 않는 기능을 모든 미니 배치에서 업데이트 한 것과 동일한 닫힌 양식 업데이트 규칙으로 표시 될 때 업데이트함으로써 정규화를 처리합니다.</target>
        </trans-unit>
        <trans-unit id="9a8b5c268bde39d241894c5b95721103ebdbc425" translate="yes" xml:space="preserve">
          <source>This optimizer wraps another optimizer and applies loss scaling to it via a &lt;code&gt;LossScale&lt;/code&gt;. Loss scaling is applied whenever gradients are computed, either through &lt;code&gt;minimize()&lt;/code&gt; or &lt;code&gt;get_gradients()&lt;/code&gt;. The loss scale is updated via &lt;a href=&quot;../../../mixed_precision/experimental/lossscale#update&quot;&gt;&lt;code&gt;LossScale.update()&lt;/code&gt;&lt;/a&gt; whenever gradients are applied, either through &lt;code&gt;minimize()&lt;/code&gt; or &lt;code&gt;apply_gradients()&lt;/code&gt;. For example:</source>
          <target state="translated">이 옵티마이 저는 다른 옵티 마이저를 감싸고 &lt;code&gt;LossScale&lt;/code&gt; 을 통해 손실 스케일링을 적용 합니다. 손실 스케일링은 &lt;code&gt;minimize()&lt;/code&gt; 또는 &lt;code&gt;get_gradients()&lt;/code&gt; 통해 그래디언트가 계산 될 때마다 적용됩니다 . 손실 스케일은 &lt;code&gt;minimize()&lt;/code&gt; 또는 &lt;code&gt;apply_gradients()&lt;/code&gt; 통해 그래디언트가 적용될 때마다 &lt;a href=&quot;../../../mixed_precision/experimental/lossscale#update&quot;&gt; &lt;code&gt;LossScale.update()&lt;/code&gt; &lt;/a&gt; 를 통해 업데이트됩니다 . 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="a13f36128710145f1603618c3c0bcd6462911f2d" translate="yes" xml:space="preserve">
          <source>This optimizer wraps another optimizer and applies loss scaling to it via a &lt;code&gt;LossScale&lt;/code&gt;. Loss scaling is applied whenever gradients are computed, such as through &lt;code&gt;minimize()&lt;/code&gt;.</source>
          <target state="translated">이 옵티마이 저는 다른 옵티 마이저를 감싸고 &lt;code&gt;LossScale&lt;/code&gt; 을 통해 손실 스케일링을 적용 합니다. 그래디언트가 계산 될 때마다 감소 스케일링 등을 통해 같은인가 &lt;code&gt;minimize()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="43b5cb445e044712f2e69a5344f02f5be0ddda93" translate="yes" xml:space="preserve">
          <source>This outputs a &lt;code&gt;batch_size&lt;/code&gt; bool array, an entry &lt;code&gt;out[i]&lt;/code&gt; is &lt;code&gt;true&lt;/code&gt; if the prediction for the target class is finite (not inf, -inf, or nan) and among the top &lt;code&gt;k&lt;/code&gt; predictions among all predictions for example &lt;code&gt;i&lt;/code&gt;. Note that the behavior of &lt;code&gt;InTopK&lt;/code&gt; differs from the &lt;code&gt;TopK&lt;/code&gt; op in its handling of ties; if multiple classes have the same prediction value and straddle the top-&lt;code&gt;k&lt;/code&gt; boundary, all of those classes are considered to be in the top &lt;code&gt;k&lt;/code&gt;.</source>
          <target state="translated">이것은 &lt;code&gt;batch_size&lt;/code&gt; bool 배열을 출력합니다 . 대상 클래스에 대한 예측이 유한 한 경우 (inf, -inf 또는 nan 아님) 모든 예측 중 예를 들어 &lt;code&gt;i&lt;/code&gt; &lt;code&gt;k&lt;/code&gt; 중 최상위 k 예측 중 하나 인 경우 &lt;code&gt;out[i]&lt;/code&gt; 은 &lt;code&gt;true&lt;/code&gt; 입니다. &lt;code&gt;InTopK&lt;/code&gt; 의 동작 은 관계 처리에서 &lt;code&gt;TopK&lt;/code&gt; op 와 다릅니다 . 여러 클래스가 동일한 예측 값을 갖고 상위 &lt;code&gt;k&lt;/code&gt; 경계에 걸치면 모든 클래스가 상위 &lt;code&gt;k&lt;/code&gt; 에있는 것으로 간주됩니다 .</target>
        </trans-unit>
        <trans-unit id="345380820e023cc35c074a4e6039205226041719" translate="yes" xml:space="preserve">
          <source>This overload raises a &lt;code&gt;TypeError&lt;/code&gt; when the user inadvertently treats a &lt;code&gt;Tensor&lt;/code&gt; as a boolean (most commonly in an &lt;code&gt;if&lt;/code&gt; or &lt;code&gt;while&lt;/code&gt; statement), in code that was not converted by AutoGraph. For example:</source>
          <target state="translated">이 오버로드 는 사용자 가 AutoGraph에 의해 변환되지 않은 코드 에서 사용자가 실수로 &lt;code&gt;Tensor&lt;/code&gt; 를 부울 (대부분 &lt;code&gt;if&lt;/code&gt; 또는 &lt;code&gt;while&lt;/code&gt; 문에서) 로 취급 할 때 &lt;code&gt;TypeError&lt;/code&gt; 를 발생시킵니다 . 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="5f63c68c6b6d06032eeae666e8d05a28d8b6e750" translate="yes" xml:space="preserve">
          <source>This package defines ops for manipulating ragged tensors (&lt;a href=&quot;../../raggedtensor&quot;&gt;&lt;code&gt;tf.RaggedTensor&lt;/code&gt;&lt;/a&gt;), which are tensors with non-uniform shapes. In particular, each &lt;code&gt;RaggedTensor&lt;/code&gt; has one or more &lt;em&gt;ragged dimensions&lt;/em&gt;, which are dimensions whose slices may have different lengths. For example, the inner (column) dimension of &lt;code&gt;rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []]&lt;/code&gt; is ragged, since the column slices (&lt;code&gt;rt[0, :]&lt;/code&gt;, ..., &lt;code&gt;rt[4, :]&lt;/code&gt;) have different lengths. For a more detailed description of ragged tensors, see the &lt;a href=&quot;../../raggedtensor&quot;&gt;&lt;code&gt;tf.RaggedTensor&lt;/code&gt;&lt;/a&gt; class documentation and the &lt;a href=&quot;https://www.tensorflow.org/guide/ragged_tensors&quot;&gt;Ragged Tensor Guide&lt;/a&gt;.</source>
          <target state="translated">이 패키지는 비정형 모양의 텐서 인 비정형 텐서 ( &lt;a href=&quot;../../raggedtensor&quot;&gt; &lt;code&gt;tf.RaggedTensor&lt;/code&gt; &lt;/a&gt; ) 조작을위한 ops를 정의합니다 . 특히, 각각의 &lt;code&gt;RaggedTensor&lt;/code&gt; 는 하나 이상의 &lt;em&gt;비정형 치수를 가지며&lt;/em&gt; , 이는 슬라이스의 길이가 다를 수있는 치수이다. 예를 들면, 내측 (열) 치수 &lt;code&gt;rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []]&lt;/code&gt; 울퉁불퉁하고, 열 슬라이스 사람 ( &lt;code&gt;rt[0, :]&lt;/code&gt; , ..., &lt;code&gt;rt[4, :]&lt;/code&gt; )는 길이가 다릅니다. 비정형 텐서에 대한 자세한 설명은 &lt;a href=&quot;../../raggedtensor&quot;&gt; &lt;code&gt;tf.RaggedTensor&lt;/code&gt; &lt;/a&gt; 클래스 문서 및 &lt;a href=&quot;https://www.tensorflow.org/guide/ragged_tensors&quot;&gt;Ragged Tensor Guide를 참조하십시오&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="3e4f0989d73eb8b679bcdf7fff408eece47a531f" translate="yes" xml:space="preserve">
          <source>This package defines ops for manipulating ragged tensors (&lt;a href=&quot;raggedtensor&quot;&gt;&lt;code&gt;tf.RaggedTensor&lt;/code&gt;&lt;/a&gt;), which are tensors with non-uniform shapes. In particular, each &lt;code&gt;RaggedTensor&lt;/code&gt; has one or more &lt;em&gt;ragged dimensions&lt;/em&gt;, which are dimensions whose slices may have different lengths. For example, the inner (column) dimension of &lt;code&gt;rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []]&lt;/code&gt; is ragged, since the column slices (&lt;code&gt;rt[0, :]&lt;/code&gt;, ..., &lt;code&gt;rt[4, :]&lt;/code&gt;) have different lengths. For a more detailed description of ragged tensors, see the &lt;a href=&quot;raggedtensor&quot;&gt;&lt;code&gt;tf.RaggedTensor&lt;/code&gt;&lt;/a&gt; class documentation and the &lt;a href=&quot;https://www.tensorflow.org/guide/ragged_tensors&quot;&gt;Ragged Tensor Guide&lt;/a&gt;.</source>
          <target state="translated">이 패키지는 비정형 모양의 텐서 인 비정형 텐서 ( &lt;a href=&quot;raggedtensor&quot;&gt; &lt;code&gt;tf.RaggedTensor&lt;/code&gt; &lt;/a&gt; ) 조작을위한 ops를 정의합니다 . 특히, 각각의 &lt;code&gt;RaggedTensor&lt;/code&gt; 는 하나 이상의 &lt;em&gt;비정형 치수를 가지며&lt;/em&gt; , 이는 슬라이스의 길이가 다를 수있는 치수이다. 예를 들면, 내측 (열) 치수 &lt;code&gt;rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []]&lt;/code&gt; 울퉁불퉁하고, 열 슬라이스 사람 ( &lt;code&gt;rt[0, :]&lt;/code&gt; , ..., &lt;code&gt;rt[4, :]&lt;/code&gt; )는 길이가 다릅니다. 비정형 텐서에 대한 자세한 설명은 &lt;a href=&quot;raggedtensor&quot;&gt; &lt;code&gt;tf.RaggedTensor&lt;/code&gt; &lt;/a&gt; 클래스 문서 및 &lt;a href=&quot;https://www.tensorflow.org/guide/ragged_tensors&quot;&gt;Ragged Tensor Guide를 참조하십시오&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="ca381bc7587c1d86ccea71cf77a3f51f18c01785" translate="yes" xml:space="preserve">
          <source>This partitioner will shard a Variable along one axis, attempting to keep the maximum shard size below &lt;code&gt;max_shard_bytes&lt;/code&gt;. In practice, this is not always possible when sharding along only one axis. When this happens, this axis is sharded as much as possible (i.e., every dimension becomes a separate shard).</source>
          <target state="translated">이 파티 &lt;code&gt;max_shard_bytes&lt;/code&gt; 최대 샤드 크기를 max_shard_bytes 미만으로 유지하려고 한 축을 따라 변수를 샤딩합니다 . 실제로, 이것은 하나의 축만을 따라 샤딩 할 때 항상 가능하지는 않습니다. 이 경우이 축은 가능한 한 샤드됩니다 (즉, 모든 치수가 별도의 샤드가 됨).</target>
        </trans-unit>
        <trans-unit id="fd457ac6c886ad4d6a9b1c2c9ed70e07ea8ad467" translate="yes" xml:space="preserve">
          <source>This produces files called &quot;timeline-</source>
          <target state="translated">&quot;타임 라인-</target>
        </trans-unit>
        <trans-unit id="650852868a3688b5e43945d526af2b7a7abb7659" translate="yes" xml:space="preserve">
          <source>This regressor ignores feature values and will learn to predict the average value of each label.</source>
          <target state="translated">이 회귀 분석에서는 피처 값을 무시하고 각 레이블의 평균값을 예측하는 방법을 배웁니다.</target>
        </trans-unit>
        <trans-unit id="6b4e11e2fc93d180cb8cb79e60f96113138df290" translate="yes" xml:space="preserve">
          <source>This returns a ClusterSpec object for use based on information from the specified initialization parameters and Slurm environment variables. The cluster specification is resolved each time this function is called. The resolver extract hostnames of nodes by scontrol and pack tasks in that order until a node a has number of tasks that is equal to specification. GPUs on nodes are allocated to tasks by specification through setting CUDA_VISIBLE_DEVICES environment variable.</source>
          <target state="translated">지정된 초기화 매개 변수 및 Slurm 환경 변수의 정보를 기반으로 사용할 ClusterSpec 객체를 반환합니다. 이 기능이 호출 될 때마다 클러스터 사양이 해결됩니다. 리졸버는 노드 a가 스펙과 동일한 수의 태스크를 가질 때까지 scontrol에 의해 노드의 호스트 이름을 추출하고 순서대로 태스크를 압축합니다. CUDA_VISIBLE_DEVICES 환경 변수 설정을 통해 사양에 따라 노드의 GPU가 작업에 할당됩니다.</target>
        </trans-unit>
        <trans-unit id="ce42bdd47f55adee51dc4ae146a85efc32785746" translate="yes" xml:space="preserve">
          <source>This returns a ClusterSpec object for use based on information from the specified instance group. We will retrieve the information from the GCE APIs every time this method is called.</source>
          <target state="translated">지정된 인스턴스 그룹의 정보를 기반으로 사용할 ClusterSpec 객체를 반환합니다. 이 메소드가 호출 될 때마다 GCE API에서 정보를 검색합니다.</target>
        </trans-unit>
        <trans-unit id="d4e36425f3d932370ce3f31b5b37e6bd2c5dbb8b" translate="yes" xml:space="preserve">
          <source>This returns a function outputting &lt;code&gt;features&lt;/code&gt; and &lt;code&gt;targets&lt;/code&gt; based on the dict of numpy arrays. The dict &lt;code&gt;features&lt;/code&gt; has the same keys as the &lt;code&gt;x&lt;/code&gt;. The dict &lt;code&gt;targets&lt;/code&gt; has the same keys as the &lt;code&gt;y&lt;/code&gt; if &lt;code&gt;y&lt;/code&gt; is a dict.</source>
          <target state="translated">이것은 numpy 배열의 dict를 기반으로 &lt;code&gt;features&lt;/code&gt; 및 &lt;code&gt;targets&lt;/code&gt; 출력하는 함수를 반환 합니다. dict &lt;code&gt;features&lt;/code&gt; 은 &lt;code&gt;x&lt;/code&gt; 와 동일한 키를 갖습니다 . 딕셔너리의 &lt;code&gt;targets&lt;/code&gt; 은 AS 동일한 키를 가지고 &lt;code&gt;y&lt;/code&gt; 경우 &lt;code&gt;y&lt;/code&gt; 는 사전인가된다.</target>
        </trans-unit>
        <trans-unit id="091f487524e5d0cdc7f2f7122f0e27fecc0512d2" translate="yes" xml:space="preserve">
          <source>This returns the job name and task index for the process which calls this function according to its rank and cluster specification. The job name and task index are set after a cluster is constructed by cluster_spec otherwise defaults to None.</source>
          <target state="translated">순위 및 클러스터 스펙에 따라이 함수를 호출하는 프로세스의 작업 이름 및 작업 색인을 리턴합니다. 작업 이름 및 작업 색인은 cluster_spec에 의해 클러스터가 구성된 후에 설정되며 그렇지 않으면 기본값은 없음입니다.</target>
        </trans-unit>
        <trans-unit id="9e86e167f9dfaedec2287e6304deddcf9a677504" translate="yes" xml:space="preserve">
          <source>This returns the number of accelerator cores (such as GPUs and TPUs) available per worker.</source>
          <target state="translated">이렇게하면 작업 자당 사용 가능한 가속기 코어 (GPU 및 TPU 등) 수가 반환됩니다.</target>
        </trans-unit>
        <trans-unit id="43f97f599a6e5c9f5b6d870e441e77232b9c4ee2" translate="yes" xml:space="preserve">
          <source>This sampler is useful when the target classes approximately follow such a distribution - for example, if the classes represent words in a lexicon sorted in decreasing order of frequency. If your classes are not ordered by decreasing frequency, do not use this op.</source>
          <target state="translated">이 샘플러는 대상 클래스가 대략 같은 분포를 따르는 경우에 유용합니다 (예를 들어 클래스가 어휘의 단어를 빈도의 내림차순으로 정렬 한 경우). 수업 횟수를 줄이면서 수업을 주문하지 않으면이 op를 사용하지 마십시오.</target>
        </trans-unit>
        <trans-unit id="f4116f5a13b723775fce909b3d142c6ace24a3f4" translate="yes" xml:space="preserve">
          <source>This set may grow over time, so it's important the signature of creators is as mentioned above.</source>
          <target state="translated">이 세트는 시간이 지남에 따라 커질 수 있으므로 제작자의 서명이 위에 언급 된대로 중요합니다.</target>
        </trans-unit>
        <trans-unit id="6fe6f784df295b3702cbf845894c09377130127e" translate="yes" xml:space="preserve">
          <source>This simply wraps &lt;code&gt;compute_gradients()&lt;/code&gt; from the real optimizer. The gradients will be aggregated in &lt;code&gt;apply_gradients()&lt;/code&gt; so that user can modify the gradients like clipping with per replica global norm if needed. The global norm with aggregated gradients can be bad as one replica's huge gradients can hurt the gradients from other replicas.</source>
          <target state="translated">이것은 단순히 실제 최적화 프로그램에서 &lt;code&gt;compute_gradients()&lt;/code&gt; 를 래핑 합니다. 그라디언트는 &lt;code&gt;apply_gradients()&lt;/code&gt; 집계 되므로 사용자는 필요한 경우 복제본 전역 표준을 사용한 클리핑과 같은 그라디언트를 수정할 수 있습니다. 하나의 복제본의 거대한 그라디언트가 다른 복제본의 그라디언트를 손상시킬 수 있으므로 집계 된 그라디언트가있는 전역 표준은 나쁠 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="8231e710a02b190ee62057d8ce9e6843f584733f" translate="yes" xml:space="preserve">
          <source>This simply wraps the compute_gradients() from the real optimizer. The gradients will be aggregated in the apply_gradients() so that user can modify the gradients like clipping with per replica global norm if needed. The global norm with aggregated gradients can be bad as one replica's huge gradients can hurt the gradients from other replicas.</source>
          <target state="translated">이것은 단순히 실제 최적화 프로그램에서 compute_gradients ()를 래핑합니다. apply_gradients ()에서 그라디언트가 집계되므로 사용자는 필요한 경우 복제본 전역 표준을 사용한 클리핑과 같은 그라디언트를 수정할 수 있습니다. 하나의 복제본의 거대한 그라디언트가 다른 복제본의 그라디언트를 손상시킬 수 있으므로 집계 된 그라디언트가있는 전역 표준은 나쁠 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="9535c2c156931877173be6ce0ef4fcc7c39ade4d" translate="yes" xml:space="preserve">
          <source>This simply wraps the get_slot() from the actual optimizer.</source>
          <target state="translated">이것은 단순히 실제 최적화 프로그램에서 get_slot ()을 래핑합니다.</target>
        </trans-unit>
        <trans-unit id="627b6a914c45360f47c7270bf7239e5630834ac1" translate="yes" xml:space="preserve">
          <source>This simply wraps the get_slot_names() from the actual optimizer.</source>
          <target state="translated">이것은 단순히 실제 최적화 프로그램에서 get_slot_names ()를 래핑합니다.</target>
        </trans-unit>
        <trans-unit id="481aba790f7180557002a29e34e41b2834d82d24" translate="yes" xml:space="preserve">
          <source>This starts services in the background. The services started depend on the parameters to the constructor and may include:</source>
          <target state="translated">백그라운드에서 서비스를 시작합니다. 시작된 서비스는 생성자에 대한 매개 변수에 따라 다음을 포함 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="61ba97b856d34fcc84e3cd4a4201db78d7018540" translate="yes" xml:space="preserve">
          <source>This strategy implements synchronous distributed training across multiple workers, each with potentially multiple GPUs. Similar to &lt;a href=&quot;../../../../distribute/mirroredstrategy&quot;&gt;&lt;code&gt;tf.distribute.MirroredStrategy&lt;/code&gt;&lt;/a&gt;, it creates copies of all variables in the model on each device across all workers.</source>
          <target state="translated">이 전략은 잠재적으로 여러 GPU가있는 여러 작업자에게 동기식 분산 교육을 구현합니다. &lt;a href=&quot;../../../../distribute/mirroredstrategy&quot;&gt; &lt;code&gt;tf.distribute.MirroredStrategy&lt;/code&gt; &lt;/a&gt; 와 유사하게 모든 작업자의 각 장치에서 모델의 모든 변수 사본을 작성합니다.</target>
        </trans-unit>
        <trans-unit id="f19046d3b0cb6c64ecb2b4f8764cc9d33c4854f1" translate="yes" xml:space="preserve">
          <source>This strategy implements synchronous distributed training across multiple workers, each with potentially multiple GPUs. Similar to &lt;a href=&quot;../mirroredstrategy&quot;&gt;&lt;code&gt;tf.distribute.MirroredStrategy&lt;/code&gt;&lt;/a&gt;, it creates copies of all variables in the model on each device across all workers.</source>
          <target state="translated">이 전략은 잠재적으로 여러 GPU가있는 여러 작업자에게 동기식 분산 교육을 구현합니다. &lt;a href=&quot;../mirroredstrategy&quot;&gt; &lt;code&gt;tf.distribute.MirroredStrategy&lt;/code&gt; &lt;/a&gt; 와 유사하게 모든 작업자의 각 장치에서 모델의 모든 변수 사본을 작성합니다.</target>
        </trans-unit>
        <trans-unit id="648f5d6b8ceebd17f689c7c0ab8ef16660a7747c" translate="yes" xml:space="preserve">
          <source>This strategy requires two jobs: workers and parameter servers. Variables and updates to those variables will be assigned to parameter servers and other operations are assigned to workers.</source>
          <target state="translated">이 전략에는 작업자와 매개 변수 서버라는 두 가지 작업이 필요합니다. 변수 및 해당 변수에 대한 업데이트는 매개 변수 서버에 지정되고 다른 작업은 작업자에게 지정됩니다.</target>
        </trans-unit>
        <trans-unit id="609b539c1ba8e5fb73c25fa137b65336a8f05b90" translate="yes" xml:space="preserve">
          <source>This strategy uses one replica per device and sync replication for its multi-GPU version.</source>
          <target state="translated">이 전략은 장치 당 하나의 복제본을 사용하고 다중 GPU 버전에 대해 복제 복제를 사용합니다.</target>
        </trans-unit>
        <trans-unit id="f77a1c7f27ca177eb5967fdc02f021a08479ef96" translate="yes" xml:space="preserve">
          <source>This symbol is also exported to v2 in tf.estimator namespace. See https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/hooks/basic_session_run_hooks.py</source>
          <target state="translated">이 기호는 tf.estimator 네임 스페이스의 v2로도 내보내집니다. https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/hooks/basic_session_run_hooks.py를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="ee30a785484036470f77ee9c09ff132832518ed4" translate="yes" xml:space="preserve">
          <source>This takes an ordinary &lt;code&gt;dataset&lt;/code&gt; and &lt;code&gt;replica_fn&lt;/code&gt; and runs it distributed using a particular &lt;a href=&quot;strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; named &lt;code&gt;my_strategy&lt;/code&gt; above. Any variables created in &lt;code&gt;replica_fn&lt;/code&gt; are created using &lt;code&gt;my_strategy&lt;/code&gt;'s policy, and library functions called by &lt;code&gt;replica_fn&lt;/code&gt; can use the &lt;code&gt;get_replica_context()&lt;/code&gt; API to implement distributed-specific behavior.</source>
          <target state="translated">이것은 보통 소요 &lt;code&gt;dataset&lt;/code&gt; 및 &lt;code&gt;replica_fn&lt;/code&gt; 을 하고 특정 사용하여 분산 실행 &lt;a href=&quot;strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; 이름 &lt;code&gt;my_strategy&lt;/code&gt; 위. 에서 만든 모든 변수 &lt;code&gt;replica_fn&lt;/code&gt; 를 사용하여 만들어집니다 &lt;code&gt;my_strategy&lt;/code&gt; 의 정책 및 호출 라이브러리 함수 &lt;code&gt;replica_fn&lt;/code&gt; 사용 할 수 &lt;code&gt;get_replica_context()&lt;/code&gt; 분산 특정 동작을 구현하기 위해 API를.</target>
        </trans-unit>
        <trans-unit id="f43e50d6d041bdda53ec0ccc184fa3940b822601" translate="yes" xml:space="preserve">
          <source>This takes in a few parameters and creates a GCEClusterResolver project. It will then use these parameters to query the GCE API for the IP addresses of each instance in the instance group.</source>
          <target state="translated">몇 가지 매개 변수를 사용하고 GCEClusterResolver 프로젝트를 만듭니다. 그런 다음이 매개 변수를 사용하여 인스턴스 그룹에있는 각 인스턴스의 IP 주소에 대한 GCE API를 쿼리합니다.</target>
        </trans-unit>
        <trans-unit id="dcbb15c135f93b202dd4afc6d928c452a899b686" translate="yes" xml:space="preserve">
          <source>This takes in parameters and creates a SlurmClusterResolver object. It uses those parameters to check which nodes will processes reside on and resolves their hostnames. With the number of the GPUs on each node and number of GPUs for each task it offsets the port number for each process and allocates GPUs to tasks by setting environment variables. The resolver currently supports homogeneous tasks and default Slurm process allocation.</source>
          <target state="translated">매개 변수를 사용하여 SlurmClusterResolver 개체를 만듭니다. 이 매개 변수를 사용하여 프로세스가 상주 할 노드를 확인하고 호스트 이름을 분석합니다. 각 노드의 GPU 수와 각 작업의 GPU 수를 통해 각 프로세스의 포트 번호를 오프셋하고 환경 변수를 설정하여 작업에 GPU를 할당합니다. 리졸버는 현재 동종 작업 및 기본 Slurm 프로세스 할당을 지원합니다.</target>
        </trans-unit>
        <trans-unit id="c32e52f6772f69af41778414a120795e360f2147" translate="yes" xml:space="preserve">
          <source>This thread class is intended to be used with a &lt;code&gt;Coordinator&lt;/code&gt;. It repeatedly runs code specified either as &lt;code&gt;target&lt;/code&gt; and &lt;code&gt;args&lt;/code&gt; or by the &lt;code&gt;run_loop()&lt;/code&gt; method.</source>
          <target state="translated">이 스레드 클래스는 &lt;code&gt;Coordinator&lt;/code&gt; 와 함께 사용하기위한 것 입니다. &lt;code&gt;target&lt;/code&gt; 및 &lt;code&gt;args&lt;/code&gt; 또는 &lt;code&gt;run_loop()&lt;/code&gt; 메소드 로 지정된 코드를 반복적으로 실행합니다 .</target>
        </trans-unit>
        <trans-unit id="cbe44aae232eb7beccd1bb717d150f53dfed09d2" translate="yes" xml:space="preserve">
          <source>This tracking then allows saving variable values to &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;training checkpoints&lt;/a&gt;, or to &lt;a href=&quot;https://www.tensorflow.org/guide/saved_model&quot;&gt;SavedModels&lt;/a&gt; which include serialized TensorFlow graphs.</source>
          <target state="translated">이 추적을 통해 변수 값을 &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;훈련 체크 포인트&lt;/a&gt; 또는 직렬화 된 TensorFlow 그래프를 포함 하는 &lt;a href=&quot;https://www.tensorflow.org/guide/saved_model&quot;&gt;저장된 모델에 저장할&lt;/a&gt; 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="84d3d178d35882538e5cb6113338132ed1567a47" translate="yes" xml:space="preserve">
          <source>This transformation applies &lt;code&gt;map_func&lt;/code&gt; to each element of this dataset, and returns a new dataset containing the transformed elements, in the same order as they appeared in the input. &lt;code&gt;map_func&lt;/code&gt; can be used to change both the values and the structure of a dataset's elements. For example, adding 1 to each element, or projecting a subset of element components.</source>
          <target state="translated">이 변환은 &lt;code&gt;map_func&lt;/code&gt; 를이 데이터 세트의 각 요소에 적용 하고 변환 된 요소를 포함하는 새 데이터 세트를 입력에 표시된 순서대로 반환합니다. &lt;code&gt;map_func&lt;/code&gt; 를 사용하여 데이터 세트 요소의 값과 구조를 모두 변경할 수 있습니다. 예를 들어, 각 요소에 1을 추가하거나 요소 구성 요소의 서브 세트를 투영합니다.</target>
        </trans-unit>
        <trans-unit id="b91ea223c9ec8adff0faaecc5c9b88a252c4af69" translate="yes" xml:space="preserve">
          <source>This transformation combines multiple consecutive elements of the input dataset into a single element.</source>
          <target state="translated">이 변환은 입력 데이터 집합의 여러 연속 요소를 단일 요소로 결합합니다.</target>
        </trans-unit>
        <trans-unit id="35f6c3c6efa792b9215faf94c8c00f35d19886a0" translate="yes" xml:space="preserve">
          <source>This transformation is a stateful relative of &lt;a href=&quot;../dataset#map&quot;&gt;&lt;code&gt;tf.data.Dataset.map&lt;/code&gt;&lt;/a&gt;. In addition to mapping &lt;code&gt;scan_func&lt;/code&gt; across the elements of the input dataset, &lt;code&gt;scan()&lt;/code&gt; accumulates one or more state tensors, whose initial values are &lt;code&gt;initial_state&lt;/code&gt;.</source>
          <target state="translated">이 변환은 &lt;a href=&quot;../dataset#map&quot;&gt; &lt;code&gt;tf.data.Dataset.map&lt;/code&gt; &lt;/a&gt; 의 상태 저장 상대입니다 . &lt;code&gt;scan()&lt;/code&gt; 은 입력 데이터 집합의 요소에 걸쳐 &lt;code&gt;scan_func&lt;/code&gt; 를 매핑하는 것 외에도 초기 값이 &lt;code&gt;initial_state&lt;/code&gt; 인 하나 이상의 상태 텐서를 누적 합니다.</target>
        </trans-unit>
        <trans-unit id="8e7258027c5f693626ed2b2e68a04576c8a8c285" translate="yes" xml:space="preserve">
          <source>This transformation maps each consecutive element in a dataset to a key using &lt;code&gt;key_func&lt;/code&gt; and groups the elements by key. It then applies &lt;code&gt;reduce_func&lt;/code&gt; to at most &lt;code&gt;window_size_func(key)&lt;/code&gt; elements matching the same key. All except the final window for each key will contain &lt;code&gt;window_size_func(key)&lt;/code&gt; elements; the final window may be smaller.</source>
          <target state="translated">이 변환은 &lt;code&gt;key_func&lt;/code&gt; 를 사용하여 데이터 집합의 각 연속 요소를 키에 매핑 하고 요소를 키별로 그룹화합니다. 그런 다음 &lt;code&gt;reduce_func&lt;/code&gt; 를 동일한 키와 일치하는 최대 &lt;code&gt;window_size_func(key)&lt;/code&gt; 요소에 적용합니다. 각 키의 마지막 창을 제외한 모든 창에는 &lt;code&gt;window_size_func(key)&lt;/code&gt; 요소 가 포함됩니다 . 최종 창이 더 작을 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="a21aaa6c0a7b4d11f0bde650d661805100a01ad7" translate="yes" xml:space="preserve">
          <source>This transformation maps element of a dataset to a key using &lt;code&gt;key_func&lt;/code&gt; and groups the elements by key. The &lt;code&gt;reducer&lt;/code&gt; is used to process each group; its &lt;code&gt;init_func&lt;/code&gt; is used to initialize state for each group when it is created, the &lt;code&gt;reduce_func&lt;/code&gt; is used to update the state every time an element is mapped to the matching group, and the &lt;code&gt;finalize_func&lt;/code&gt; is used to map the final state to an output value.</source>
          <target state="translated">이 변환은 &lt;code&gt;key_func&lt;/code&gt; 를 사용하여 데이터 집합 의 요소를 키에 매핑 하고 요소를 키별로 그룹화합니다. &lt;code&gt;reducer&lt;/code&gt; 각 그룹을 처리하는 데 사용된다; 그 &lt;code&gt;init_func&lt;/code&gt; 가 생성 될 때, 각 그룹의 상태를 초기화하는데 사용되는 상기 &lt;code&gt;reduce_func&lt;/code&gt; 는 상태에게 요소가 일치하는 그룹에 매핑 될 때마다 갱신하는데 사용되며, &lt;code&gt;finalize_func&lt;/code&gt; 은 출력값에 최종 상태를 매핑하는데 사용된다.</target>
        </trans-unit>
        <trans-unit id="24ab6194aaa04fc157672b906f20ba2e1b1ec8cc" translate="yes" xml:space="preserve">
          <source>This updates the checkpoint file containing a CheckpointState proto.</source>
          <target state="translated">CheckpointState 프로토가 포함 된 검사 점 파일을 업데이트합니다.</target>
        </trans-unit>
        <trans-unit id="5bb7cb617dbb67bdd4c7f55f6d436fa2f1b33e3c" translate="yes" xml:space="preserve">
          <source>This uses &lt;a href=&quot;../norm&quot;&gt;&lt;code&gt;tf.linalg.norm&lt;/code&gt;&lt;/a&gt; to compute the norm along &lt;code&gt;axis&lt;/code&gt;.</source>
          <target state="translated">이것은 &lt;a href=&quot;../norm&quot;&gt; &lt;code&gt;tf.linalg.norm&lt;/code&gt; &lt;/a&gt; 을 사용하여 &lt;code&gt;axis&lt;/code&gt; 따라 규범을 계산합니다 .</target>
        </trans-unit>
        <trans-unit id="7945ebd1b4ae121cdd796a53759129e7e59a0846" translate="yes" xml:space="preserve">
          <source>This usually returns the master from the first ClusterResolver passed in, but you can override this by specifying the task_type and task_id.</source>
          <target state="translated">일반적으로 전달 된 첫 번째 ClusterResolver에서 마스터를 반환하지만 task_type 및 task_id를 지정하여이를 무시할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="4285af5e3616d9c051e0b5382ab0649693cc39b6" translate="yes" xml:space="preserve">
          <source>This utility function provides consistent behavior for both local (non-distributed) and distributed configurations. The default distribution configuration is parameter server-based between-graph replication. For other types of distribution configurations such as all-reduce training, please use &lt;a href=&quot;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute&quot;&gt;DistributionStrategies&lt;/a&gt;.</source>
          <target state="translated">이 유틸리티 기능은 로컬 (비 분산) 및 분산 구성 모두에 일관된 동작을 제공합니다. 기본 배포 구성은 매개 변수 서버 기반 그래프 간 복제입니다. 전체 감소 교육과 같은 다른 유형의 배포 구성의 경우 &lt;a href=&quot;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute&quot;&gt;DistributionStrategies&lt;/a&gt; 를 사용하십시오 .</target>
        </trans-unit>
        <trans-unit id="50e5c41b60a6dacb228de3d2a27ac083ca26570e" translate="yes" xml:space="preserve">
          <source>This utility function trains, evaluates, and (optionally) exports the model by using the given &lt;code&gt;estimator&lt;/code&gt;. All training related specification is held in &lt;code&gt;train_spec&lt;/code&gt;, including training &lt;code&gt;input_fn&lt;/code&gt; and training max steps, etc. All evaluation and export related specification is held in &lt;code&gt;eval_spec&lt;/code&gt;, including evaluation &lt;code&gt;input_fn&lt;/code&gt;, steps, etc.</source>
          <target state="translated">이 유틸리티 함수는 주어진 &lt;code&gt;estimator&lt;/code&gt; 를 사용하여 모델을 학습, 평가 및 선택적으로 내 보냅니다 . 훈련 &lt;code&gt;input_fn&lt;/code&gt; 및 훈련 최대 단계 등을 포함하여 모든 훈련 관련 사양은 &lt;code&gt;train_spec&lt;/code&gt; 에 보관됩니다 . 모든 평가 및 수출 관련 사양은 평가 &lt;code&gt;input_fn&lt;/code&gt; , 단계 등을 포함하여 &lt;code&gt;eval_spec&lt;/code&gt; 에 보관됩니다 .</target>
        </trans-unit>
        <trans-unit id="370bf5deaf68ca405b51cda0b005ed741251919f" translate="yes" xml:space="preserve">
          <source>This utility method replaces the deprecated-in-V2 &lt;code&gt;tf.compat.v1.Dataset.output_classes&lt;/code&gt; property.</source>
          <target state="translated">이 유틸리티 메소드는 더 이상 사용되지 않는 V2 &lt;code&gt;tf.compat.v1.Dataset.output_classes&lt;/code&gt; 특성을 대체합니다 .</target>
        </trans-unit>
        <trans-unit id="46213afe2d7d2a75cd43b97252d79901207a3be4" translate="yes" xml:space="preserve">
          <source>This utility method replaces the deprecated-in-V2 &lt;code&gt;tf.compat.v1.Dataset.output_shapes&lt;/code&gt; property.</source>
          <target state="translated">이 유틸리티 메소드는 더 이상 사용되지 않는 V2 &lt;code&gt;tf.compat.v1.Dataset.output_shapes&lt;/code&gt; 특성을 대체합니다 .</target>
        </trans-unit>
        <trans-unit id="917e4af53cd9619ae0480dec3aee8643df47493a" translate="yes" xml:space="preserve">
          <source>This utility method replaces the deprecated-in-V2 &lt;code&gt;tf.compat.v1.Dataset.output_types&lt;/code&gt; property.</source>
          <target state="translated">이 유틸리티 메소드는 더 이상 사용되지 않는 V2 &lt;code&gt;tf.compat.v1.Dataset.output_types&lt;/code&gt; 특성을 대체합니다 .</target>
        </trans-unit>
        <trans-unit id="e1997fea43a5c765a33c5bb8c3d18f8bd998811c" translate="yes" xml:space="preserve">
          <source>This value is ultimately returned as &lt;code&gt;auc&lt;/code&gt;, an idempotent operation that computes the area under a discretized curve of precision versus recall values (computed using the aforementioned variables). The &lt;code&gt;num_thresholds&lt;/code&gt; variable controls the degree of discretization with larger numbers of thresholds more closely approximating the true AUC. The quality of the approximation may vary dramatically depending on &lt;code&gt;num_thresholds&lt;/code&gt;.</source>
          <target state="translated">이 값은 궁극적으로 &lt;code&gt;auc&lt;/code&gt; pot 으로 반환 되는데 , 이는 위와 같은 변수를 사용하여 계산 된 이산 정밀도 곡선과 리콜 값 곡선 아래 면적을 계산하는 dem 등원 연산입니다. &lt;code&gt;num_thresholds&lt;/code&gt; 의 변수 컨트롤보다 밀접하게 진정한 AUC를 근사 임계 값의 큰 숫자 이산화 정도. 근사치의 품질은 &lt;code&gt;num_thresholds&lt;/code&gt; 에 따라 크게 달라질 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="65677d697851bf6819d55d4ff4251a12696e0771" translate="yes" xml:space="preserve">
          <source>This value is ultimately returned as &lt;code&gt;auc&lt;/code&gt;, an idempotent operation that computes the area under a discretized curve of precision versus recall values (computed using the aforementioned variables). The &lt;code&gt;num_thresholds&lt;/code&gt; variable controls the degree of discretization with larger numbers of thresholds more closely approximating the true AUC. The quality of the approximation may vary dramatically depending on &lt;code&gt;num_thresholds&lt;/code&gt;. The &lt;code&gt;thresholds&lt;/code&gt; parameter can be used to manually specify thresholds which split the predictions more evenly.</source>
          <target state="translated">이 값은 궁극적으로 &lt;code&gt;auc&lt;/code&gt; pot 으로 반환 되는데 , 이는 위와 같은 변수를 사용하여 계산 된 이산 정밀도 곡선과 리콜 값 곡선 아래 면적을 계산하는 dem 등원 연산입니다. &lt;code&gt;num_thresholds&lt;/code&gt; 의 변수 컨트롤보다 밀접하게 진정한 AUC를 근사 임계 값의 큰 숫자 이산화 정도. 근사치의 품질은 &lt;code&gt;num_thresholds&lt;/code&gt; 에 따라 크게 달라질 수 있습니다 . &lt;code&gt;thresholds&lt;/code&gt; 수동 균등 예측 분할 임계치를 지정할 수있는 파라미터.</target>
        </trans-unit>
        <trans-unit id="ca17fcf3f560f3e845deeb7ae0f38bd32e476e10" translate="yes" xml:space="preserve">
          <source>This version enqueues a different list of tensors in different threads. It adds the following to the current &lt;code&gt;Graph&lt;/code&gt;:</source>
          <target state="translated">이 버전은 다른 스레드에서 다른 텐서 목록을 큐에 넣습니다. 현재 &lt;code&gt;Graph&lt;/code&gt; 다음을 추가합니다 .</target>
        </trans-unit>
        <trans-unit id="56d946ffec0b3da9d0ec8b7171e5c9d7eac7532e" translate="yes" xml:space="preserve">
          <source>This version performs the same function as Dropout, however it drops entire 1D feature maps instead of individual elements. If adjacent frames within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout1D will help promote independence between feature maps and should be used instead.</source>
          <target state="translated">이 버전은 Dropout과 동일한 기능을 수행하지만 개별 요소 대신 전체 1D 기능 맵을 삭제합니다. 피처 맵 내의 인접 프레임이 (초기 컨볼 루션 레이어의 경우와 같이) 밀접하게 상관되어 있으면 규칙적인 드롭 아웃이 활성화를 정규화하지 않고 효과적인 학습 속도 감소를 초래합니다. 이 경우 SpatialDropout1D는 기능 맵 간의 독립성을 높이는 데 도움이되므로 대신 사용해야합니다.</target>
        </trans-unit>
        <trans-unit id="a36f7273ef31d9cbeb00b22a3f221c68cd1e40a0" translate="yes" xml:space="preserve">
          <source>This version performs the same function as Dropout, however it drops entire 2D feature maps instead of individual elements. If adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout2D will help promote independence between feature maps and should be used instead.</source>
          <target state="translated">이 버전은 Dropout과 동일한 기능을 수행하지만 개별 요소 대신 전체 2D 기능 맵을 삭제합니다. 피쳐 맵 내의 인접 픽셀이 초기 컨볼 루션 레이어에서와 같이 강한 상관 관계가있는 경우 규칙적인 드롭 아웃이 활성화를 정규화하지 않고 효과적인 학습 속도 감소를 초래합니다. 이 경우 SpatialDropout2D는 기능 맵 간의 독립성을 높이는 데 도움이되므로 대신 사용해야합니다.</target>
        </trans-unit>
        <trans-unit id="d0ef991814863883d725a0aaf896bf4a46fb3d16" translate="yes" xml:space="preserve">
          <source>This version performs the same function as Dropout, however it drops entire 3D feature maps instead of individual elements. If adjacent voxels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout3D will help promote independence between feature maps and should be used instead.</source>
          <target state="translated">이 버전은 Dropout과 동일한 기능을 수행하지만 개별 요소 대신 전체 3D 기능 맵을 삭제합니다. 특징 맵 내의 인접 복셀이 (초기 컨볼 루션 레이어의 경우와 같이) 밀접하게 상관되어 있으면 규칙적인 드롭 아웃이 활성화를 정규화하지 않고 효과적인 학습 속도 감소를 초래합니다. 이 경우 SpatialDropout3D는 기능 맵 간의 독립성을 높이는 데 도움이되므로 대신 사용해야합니다.</target>
        </trans-unit>
        <trans-unit id="4d54f43064a89a76630348aa955f910392f5b82d" translate="yes" xml:space="preserve">
          <source>This will clear all caches, even those that are maintained through sequential calls to tf.tpu.experimental.initialize_tpu_system, such as the compilation cache.</source>
          <target state="translated">이렇게하면 컴파일 캐시와 같이 tf.tpu.experimental.initialize_tpu_system에 대한 순차적 호출을 통해 유지 관리되는 캐시까지도 모든 캐시가 지워집니다.</target>
        </trans-unit>
        <trans-unit id="d1d5a90de0626fc107829e4415b87374a7e5143d" translate="yes" xml:space="preserve">
          <source>This wrapper allows to apply a layer to every temporal slice of an input.</source>
          <target state="translated">이 랩퍼는 입력의 모든 시간적 슬라이스에 레이어를 적용 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="e4911cf935e00a37c587b392c63c4d1259cd5359" translate="yes" xml:space="preserve">
          <source>This wraps &lt;code&gt;func_&lt;/code&gt; in a Template and partially evaluates it. Templates are functions that create variables the first time they are called and reuse them thereafter. In order for &lt;code&gt;func_&lt;/code&gt; to be compatible with a &lt;code&gt;Template&lt;/code&gt; it must have the following properties:</source>
          <target state="translated">이것은 &lt;code&gt;func_&lt;/code&gt; 를 Template에 싸서 부분적으로 평가합니다. 템플릿은 변수를 처음 호출 할 때 변수를 생성 한 다음 재사용합니다. 위해에 대한 &lt;code&gt;func_&lt;/code&gt; 는 A를 호환하는 &lt;code&gt;Template&lt;/code&gt; 은 다음과 같은 속성이 있어야합니다</target>
        </trans-unit>
        <trans-unit id="9934a34210519520663a7f89fe0d027dd3ebea0c" translate="yes" xml:space="preserve">
          <source>This wraps &lt;code&gt;variables()&lt;/code&gt; from the actual optimizer. It does not include the &lt;code&gt;SyncReplicasOptimizer&lt;/code&gt;'s local step.</source>
          <target state="translated">실제 옵티마이 저의 &lt;code&gt;variables()&lt;/code&gt; 를 래핑 합니다 . &lt;code&gt;SyncReplicasOptimizer&lt;/code&gt; 의 로컬 단계 는 포함되지 않습니다 .</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
