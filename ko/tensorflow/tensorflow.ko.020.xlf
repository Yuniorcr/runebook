<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ko" datatype="htmlbody" original="tensorflow">
    <body>
      <group id="tensorflow">
        <trans-unit id="146f00a85b68b92b896f97b975828e18300e6475" translate="yes" xml:space="preserve">
          <source>For 0-D (scalar) &lt;code&gt;indices&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93086c1250897fa853eb236163fc696ad9b7ad7a" translate="yes" xml:space="preserve">
          <source>For 1-D (vector) &lt;code&gt;indices&lt;/code&gt; with &lt;code&gt;batch_dims=0&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="defba424886a691f2ba7bcc4056171fb0d0e0d47" translate="yes" xml:space="preserve">
          <source>For &lt;code&gt;SparseTensor&lt;/code&gt;s, the first (batch) column of the indices matrix is removed (the indices matrix is a column vector), the values vector is unchanged, and the first (&lt;code&gt;batch_size&lt;/code&gt;) entry of the shape vector is removed (it is now a single element vector).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44ae4bb96a98281ba7a5f41018a3c0cf10c4dea5" translate="yes" xml:space="preserve">
          <source>For &lt;code&gt;mode == ModeKeys.EVAL&lt;/code&gt;: required field is &lt;code&gt;loss&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa798daa39c957c071f1ef2d8ef9c584caee3af3" translate="yes" xml:space="preserve">
          <source>For &lt;code&gt;mode == ModeKeys.PREDICT&lt;/code&gt;: required fields are &lt;code&gt;predictions&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c1da15aacc237948a45719180b4b1f05786246a" translate="yes" xml:space="preserve">
          <source>For &lt;code&gt;mode == ModeKeys.TRAIN&lt;/code&gt;: required fields are &lt;code&gt;loss&lt;/code&gt; and &lt;code&gt;train_op&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66bd7f5eecabe99afa580fb13d864a7f7973624c" translate="yes" xml:space="preserve">
          <source>For &lt;code&gt;x&lt;/code&gt; with more dimensions, independently normalizes each 1-D slice along dimension &lt;code&gt;axis&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43544e8b815a7d32d165c045ffe8994b597cc573" translate="yes" xml:space="preserve">
          <source>For AMSGrad see &lt;a href=&quot;https://openreview.net/pdf?id=ryQu7f-RZ&quot;&gt;On The Convergence Of Adam And Beyond. Reddi et al., 5-8&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13ebc2a0e8c090e78de3fad9e601fded772c3334" translate="yes" xml:space="preserve">
          <source>For DNN model, &lt;code&gt;indicator_column&lt;/code&gt; can be used to wrap any &lt;code&gt;categorical_column_*&lt;/code&gt; (e.g., to feed to DNN). Consider to Use &lt;code&gt;embedding_column&lt;/code&gt; if the number of buckets/unique(values) are large.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="358d84aa8148063b462186c221ef88a0bda8ec99" translate="yes" xml:space="preserve">
          <source>For Example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12448879835e54272469ca384e2db601805a9b6d" translate="yes" xml:space="preserve">
          <source>For NVIDIA GPUs with Tensor cores, as a general performance guide, dimensions (such as batch size, input size, output size, and channel counts) should be powers of two if under 256, or otherwise divisible by 8 if above 256. For more information, check out the &lt;a href=&quot;https://docs.nvidia.com/deeplearning/sdk/dl-performance-guide/index.html&quot;&gt;NVIDIA Deep Learning Performance Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6c57b61b2025e89cc1b96b3f8c44dc568631574" translate="yes" xml:space="preserve">
          <source>For RaggedTensors with multiple ragged dimensions, the &lt;code&gt;row_splits&lt;/code&gt; for all nested &lt;code&gt;RaggedTensor&lt;/code&gt; objects are cast to the given dtype.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="680d2331fce0b7a83d542b4d1de0958158b6ff5b" translate="yes" xml:space="preserve">
          <source>For Tensor arguments, &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; instantiates a separate graph for every unique set of input shapes and datatypes. The example below creates two separate graphs, each specialized to a different shape:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="affb3fda9deede559b712893d926e23f939195d8" translate="yes" xml:space="preserve">
          <source>For Unicode, see the &lt;a href=&quot;working%20with%20unicode%20text&quot;&gt;https://www.tensorflow.org/tutorials/representation/unicode&lt;/a&gt; tutorial.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="438450c314656d91b7eb58ac47d34990ac07e0e9" translate="yes" xml:space="preserve">
          <source>For Wide (aka linear) model, &lt;code&gt;indicator_column&lt;/code&gt; is the internal representation for categorical column when passing categorical column directly (as any element in feature_columns) to &lt;code&gt;linear_model&lt;/code&gt;. See &lt;code&gt;linear_model&lt;/code&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1809fcc8df392d7ea85c0ac28ccfcbd2a81ee6c" translate="yes" xml:space="preserve">
          <source>For a 1-D tensor with &lt;code&gt;axis = 0&lt;/code&gt;, computes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb040fc5b017a63cdc59b792f1488c8b7f490212" translate="yes" xml:space="preserve">
          <source>For a 1D tensor, &lt;code&gt;tf.gather(values, tf.argsort(values))&lt;/code&gt; is equivalent to &lt;a href=&quot;sort&quot;&gt;&lt;code&gt;tf.sort(values)&lt;/code&gt;&lt;/a&gt;. For higher dimensions, the output has the same shape as &lt;code&gt;values&lt;/code&gt;, but along the given axis, values represent the index of the sorted element in that slice of the tensor at the given position.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb2c582ee71ccd0dae80f698e01ac135396f67ca" translate="yes" xml:space="preserve">
          <source>For a chief, this utility sets proper session initializer/restorer. It also creates hooks related to checkpoint and summary saving. For workers, this utility sets proper session creator which waits for the chief to initialize/restore. Please check &lt;a href=&quot;monitoredsession&quot;&gt;&lt;code&gt;tf.compat.v1.train.MonitoredSession&lt;/code&gt;&lt;/a&gt; for more information.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e685a37c8c58056e8f3530b78115d9f73810c25" translate="yes" xml:space="preserve">
          <source>For a complete example showing the speed-up on training an image classification task on CIFAR10, check out this Colab notebook.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0f028ef007ecbff710e7dba8c5a5dabc991f9c1" translate="yes" xml:space="preserve">
          <source>For a counter-base RNG algorithm such as Philox and ThreeFry (as described in paper 'Parallel Random Numbers: As Easy as 1, 2, 3' [https://www.thesalmons.org/john/random123/papers/random123sc11.pdf]), the RNG state consists of two parts: counter and key. The output is generated via the formula: output=hash(key, counter), i.e. a hashing of the counter parametrized by the key. Two RNGs with two different keys can be thought as generating two independent random-number streams (a stream is formed by increasing the counter).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9459e940f5730676b9001d651d28cb51b42d969c" translate="yes" xml:space="preserve">
          <source>For a description of atrous convolution and how it can be used for dense feature extraction, please see: &lt;a href=&quot;http://arxiv.org/abs/1412.7062&quot;&gt;Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs&lt;/a&gt;. The same operation is investigated further in &lt;a href=&quot;http://arxiv.org/abs/1511.07122&quot;&gt;Multi-Scale Context Aggregation by Dilated Convolutions&lt;/a&gt;. Previous works that effectively use atrous convolution in different ways are, among others, &lt;a href=&quot;http://arxiv.org/abs/1312.6229&quot;&gt;OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks&lt;/a&gt; and &lt;a href=&quot;http://arxiv.org/abs/1302.1700&quot;&gt;Fast Image Scanning with Deep Max-Pooling Convolutional Neural Networks&lt;/a&gt;. Atrous convolution is also closely related to the so-called noble identities in multi-rate signal processing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="faf1eab5a6b813e3139fd4358594343e9ec1b061" translate="yes" xml:space="preserve">
          <source>For a detailed guide, see &lt;a href=&quot;https://tensorflow.org/guide/saved_model#using_savedmodel_with_estimators&quot;&gt;Using SavedModel with Estimators&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="220ccd8b164a992646be9626d306ae4431c07d07" translate="yes" xml:space="preserve">
          <source>For a profile data structure, profiler first finds the profiler nodes matching 'start_name_regexes', and starts displaying profiler nodes from there. Then, if a node matches 'show_name_regexes' and doesn't match 'hide_name_regexes', it's displayed. If a node matches 'trim_name_regexes', profiler stops further searching that branch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9939180266b3d93448c8fea23d0f6dfa98cc31b6" translate="yes" xml:space="preserve">
          <source>For a tutorial, see the &lt;a href=&quot;https://www.tensorflow.org/guide/function&quot;&gt;tf.function and AutoGraph guide&lt;/a&gt;. For more detailed information, see the &lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/index.md&quot;&gt;AutoGraph reference documentation&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3961b8c97504a885300108217230a73b23f20c07" translate="yes" xml:space="preserve">
          <source>For additional ClusterResolver properties such as task type, task index, rpc layer, environment, etc..., we will return the value from the first ClusterResolver in the union.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ba9a27fb906c20b62b7961623bd63a85b7a2467" translate="yes" xml:space="preserve">
          <source>For additional information about specificity and sensitivity, see the following: https://en.wikipedia.org/wiki/Sensitivity_and_specificity</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63527db3074c5cfec63b6889a3a6425bedc1846b" translate="yes" xml:space="preserve">
          <source>For advanced models, please use the full &lt;a href=&quot;lstmcell&quot;&gt;&lt;code&gt;tf.compat.v1.nn.rnn_cell.LSTMCell&lt;/code&gt;&lt;/a&gt; that follows.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58bdfb47c0eae123b4f1b48443620758180eb094" translate="yes" xml:space="preserve">
          <source>For an input tensor with larger depth, here of shape &lt;code&gt;[1, 1, 1, 12]&lt;/code&gt;, e.g.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73c52c9278ce524597d2c5b7b688185a99fdfc11" translate="yes" xml:space="preserve">
          <source>For an input tensor with larger depth, here of shape &lt;code&gt;[1, 2, 2, 3]&lt;/code&gt;, e.g.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3bbf0e36ec059b3f4c0f63308a870c314c931ac4" translate="yes" xml:space="preserve">
          <source>For best results, &lt;code&gt;predictions&lt;/code&gt; should be distributed approximately uniformly in the range [0, 1] and not peaked around 0 or 1. The quality of the AUC approximation may be poor if this is not the case. Setting &lt;code&gt;summation_method&lt;/code&gt; to 'minoring' or 'majoring' can help quantify the error in the approximation by providing lower or upper bound estimate of the AUC.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f78743990c17f9299a8953827006e26051a5a3fd" translate="yes" xml:space="preserve">
          <source>For best results, &lt;code&gt;predictions&lt;/code&gt; should be distributed approximately uniformly in the range [0, 1] and not peaked around 0 or 1. The quality of the AUC approximation may be poor if this is not the case. Setting &lt;code&gt;summation_method&lt;/code&gt; to 'minoring' or 'majoring' can help quantify the error in the approximation by providing lower or upper bound estimate of the AUC. The &lt;code&gt;thresholds&lt;/code&gt; parameter can be used to manually specify thresholds which split the predictions more evenly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="daff1b722d0fb127a20bad0fd4ebd0412bf72bd5" translate="yes" xml:space="preserve">
          <source>For brevity, let &lt;code&gt;c = log(x) = log_input&lt;/code&gt;, &lt;code&gt;z = targets&lt;/code&gt;. The log Poisson loss is</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6219a532f9c408cd0729ad6b959c0bbe42f179a" translate="yes" xml:space="preserve">
          <source>For brevity, let &lt;code&gt;x = logits&lt;/code&gt;, &lt;code&gt;z = labels&lt;/code&gt;, &lt;code&gt;q = pos_weight&lt;/code&gt;. The loss is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff9d01f67c929c82f2ffed8b81b820d23e32b1da" translate="yes" xml:space="preserve">
          <source>For brevity, let &lt;code&gt;x = logits&lt;/code&gt;, &lt;code&gt;z = labels&lt;/code&gt;. The logistic loss is</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1301e2ab85c859b04f71a10ca5d0a61ed66dc9bc" translate="yes" xml:space="preserve">
          <source>For classification: binary label.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e22a3f22d875842280028907e515e5b1ceef3a59" translate="yes" xml:space="preserve">
          <source>For complex numbers, &lt;code&gt;y = sign(x) = x / |x|&lt;/code&gt; if &lt;code&gt;x != 0&lt;/code&gt;, otherwise &lt;code&gt;y = 0&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb5d4419a8e723474e43b51cd45a962afee640c2" translate="yes" xml:space="preserve">
          <source>For complex numbers, the exponential value is calculated as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="49462dde41ed51282a18f24b9ae73b7df90a2ba4" translate="yes" xml:space="preserve">
          <source>For convenience, The requested number of partitions does not have to divide the corresponding dimension evenly. If it does not, the shapes of the partitions are incremented by 1 starting from partition 0 until all slack is absorbed. The adjustment rules may change in the future, but as you can save/restore these variables with different slicing specifications this should not be a problem.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1350aabb6a166b4a9adc5331f9bfc6c8e1f4e703" translate="yes" xml:space="preserve">
          <source>For convenience, this function sets a default value for the &lt;code&gt;step&lt;/code&gt; parameter used in summary-writing functions elsewhere in the API so that it need not be explicitly passed in every such invocation. The value can be a constant or a variable, and can be retrieved via &lt;a href=&quot;get_step&quot;&gt;&lt;code&gt;tf.summary.experimental.get_step()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4334d314960569ae2e72fe3de9077256f0d3ba99" translate="yes" xml:space="preserve">
          <source>For correctness, &lt;a href=&quot;../../while_loop&quot;&gt;&lt;code&gt;tf.while_loop()&lt;/code&gt;&lt;/a&gt; strictly enforces shape invariants for the loop variables. A shape invariant is a (possibly partial) shape that is unchanged across the iterations of the loop. An error will be raised if the shape of a loop variable after an iteration is determined to be more general than or incompatible with its shape invariant. For example, a shape of [11, None] is more general than a shape of [11, 17], and [11, 21] is not compatible with [11, 17]. By default (if the argument &lt;code&gt;shape_invariants&lt;/code&gt; is not specified), it is assumed that the initial shape of each tensor in &lt;code&gt;loop_vars&lt;/code&gt; is the same in every iteration. The &lt;code&gt;shape_invariants&lt;/code&gt; argument allows the caller to specify a less specific shape invariant for each loop variable, which is needed if the shape varies between iterations. The &lt;a href=&quot;../../tensor#set_shape&quot;&gt;&lt;code&gt;tf.Tensor.set_shape&lt;/code&gt;&lt;/a&gt; function may also be used in the &lt;code&gt;body&lt;/code&gt; function to indicate that the output loop variable has a particular shape. The shape invariant for SparseTensor and IndexedSlices are treated specially as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d86798b077ac794a34c4729b8903d92155fb358" translate="yes" xml:space="preserve">
          <source>For correctness, &lt;a href=&quot;while_loop&quot;&gt;&lt;code&gt;tf.while_loop()&lt;/code&gt;&lt;/a&gt; strictly enforces shape invariants for the loop variables. A shape invariant is a (possibly partial) shape that is unchanged across the iterations of the loop. An error will be raised if the shape of a loop variable after an iteration is determined to be more general than or incompatible with its shape invariant. For example, a shape of [11, None] is more general than a shape of [11, 17], and [11, 21] is not compatible with [11, 17]. By default (if the argument &lt;code&gt;shape_invariants&lt;/code&gt; is not specified), it is assumed that the initial shape of each tensor in &lt;code&gt;loop_vars&lt;/code&gt; is the same in every iteration. The &lt;code&gt;shape_invariants&lt;/code&gt; argument allows the caller to specify a less specific shape invariant for each loop variable, which is needed if the shape varies between iterations. The &lt;a href=&quot;tensor#set_shape&quot;&gt;&lt;code&gt;tf.Tensor.set_shape&lt;/code&gt;&lt;/a&gt; function may also be used in the &lt;code&gt;body&lt;/code&gt; function to indicate that the output loop variable has a particular shape. The shape invariant for SparseTensor and IndexedSlices are treated specially as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cbc00d3ab4b824f23aa4250f9ca61bea7ee84f1a" translate="yes" xml:space="preserve">
          <source>For dense results in two serialized &lt;code&gt;Example&lt;/code&gt;s:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="260832edfc6e827a99bc3598303ea1cef15de510" translate="yes" xml:space="preserve">
          <source>For dense tensors, the returned &lt;code&gt;Tensor&lt;/code&gt; is identical to the output of &lt;code&gt;parse_example&lt;/code&gt;, except there is no batch dimension, the output shape is the same as the shape given in &lt;code&gt;dense_shape&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4cd4bd6d5ebf6a3540e2292e02f738b12afb9ed8" translate="yes" xml:space="preserve">
          <source>For detailed usage examples of TensorFlow Distributions shapes, see &lt;a href=&quot;https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Understanding_TensorFlow_Distributions_Shapes.ipynb&quot;&gt;this tutorial&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="868bc9411021e63ffd85c6f1e5eb98ca3d3b255f" translate="yes" xml:space="preserve">
          <source>For details on how the graph-level seed interacts with op seeds, see &lt;a href=&quot;set_random_seed&quot;&gt;&lt;code&gt;tf.compat.v1.random.set_random_seed&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5b62bcdafb111a4f348589cf96332ab6f0a487b" translate="yes" xml:space="preserve">
          <source>For details on the meaning of each version, see &lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto&quot;&gt;&lt;code&gt;GraphDef&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c866dd9eacd53156ef05bb3168960ebd7b5e18a3" translate="yes" xml:space="preserve">
          <source>For details, see &lt;a href=&quot;http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks&quot;&gt;Krizhevsky et al., ImageNet classification with deep convolutional neural networks (NIPS 2012)&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11f72ea95f4d5434f57a9675d8fca114eb68909d" translate="yes" xml:space="preserve">
          <source>For each 3-D image &lt;code&gt;x&lt;/code&gt; in &lt;code&gt;image&lt;/code&gt;, computes &lt;code&gt;(x - mean) / adjusted_stddev&lt;/code&gt;, where</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3227496e32cef4b95ac21bbcfb379b6c8563c22f" translate="yes" xml:space="preserve">
          <source>For each batch &lt;code&gt;i&lt;/code&gt; and class &lt;code&gt;j&lt;/code&gt; we have</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38ee7d6b0b564eb41b147c9865f0b162072dea3f" translate="yes" xml:space="preserve">
          <source>For each batch of counts, &lt;code&gt;value = [n_0, ... ,n_{k-1}]&lt;/code&gt;, &lt;code&gt;P[value]&lt;/code&gt; is the probability that after sampling &lt;code&gt;self.total_count&lt;/code&gt; draws from this Multinomial distribution, the number of draws falling in class &lt;code&gt;j&lt;/code&gt; is &lt;code&gt;n_j&lt;/code&gt;. Since this definition is &lt;a href=&quot;https://en.wikipedia.org/wiki/Exchangeable_random_variables&quot;&gt;exchangeable&lt;/a&gt;; different sequences have the same counts so the probability includes a combinatorial coefficient.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62e6f600d1795850660493678c7d313f17bb03f6" translate="yes" xml:space="preserve">
          <source>For each batch of counts, &lt;code&gt;value = [n_0, ..., n_{K-1}]&lt;/code&gt;, &lt;code&gt;P[value]&lt;/code&gt; is the probability that after sampling &lt;code&gt;self.total_count&lt;/code&gt; draws from this Dirichlet-Multinomial distribution, the number of draws falling in class &lt;code&gt;j&lt;/code&gt; is &lt;code&gt;n_j&lt;/code&gt;. Since this definition is &lt;a href=&quot;https://en.wikipedia.org/wiki/Exchangeable_random_variables&quot;&gt;exchangeable&lt;/a&gt;; different sequences have the same counts so the probability includes a combinatorial coefficient.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b564f7dfac5634b944029ff0a934eb0322773539" translate="yes" xml:space="preserve">
          <source>For each channel, this Op computes the mean of the image pixels in the channel and then adjusts each component &lt;code&gt;x&lt;/code&gt; of each pixel to &lt;code&gt;(x - mean) * contrast_factor + mean&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e51add3cb58cbf81d2d2183dae647c67c4f8839c" translate="yes" xml:space="preserve">
          <source>For each element of &lt;code&gt;x&lt;/code&gt;, with probability &lt;code&gt;rate&lt;/code&gt;, outputs &lt;code&gt;0&lt;/code&gt;, and otherwise scales up the input by &lt;code&gt;1 / (1-rate)&lt;/code&gt;. The scaling is such that the expected sum is unchanged.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28ab9495d8c09b2b7b1ceee1fc8792b4dada3fe0" translate="yes" xml:space="preserve">
          <source>For each index tuple &lt;code&gt;js&lt;/code&gt; of size &lt;code&gt;partitions.ndim&lt;/code&gt;, the slice &lt;code&gt;data[js, ...]&lt;/code&gt; becomes part of &lt;code&gt;outputs[partitions[js]]&lt;/code&gt;. The slices with &lt;code&gt;partitions[js] = i&lt;/code&gt; are placed in &lt;code&gt;outputs[i]&lt;/code&gt; in lexicographic order of &lt;code&gt;js&lt;/code&gt;, and the first dimension of &lt;code&gt;outputs[i]&lt;/code&gt; is the number of entries in &lt;code&gt;partitions&lt;/code&gt; equal to &lt;code&gt;i&lt;/code&gt;. In detail,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f890fa1a354ef3fc8ec0c534b58bd8321503214" translate="yes" xml:space="preserve">
          <source>For each input submatrix of shape &lt;code&gt;[M, M]&lt;/code&gt;, L is a lower triangular matrix of shape &lt;code&gt;[M, M]&lt;/code&gt; with unit diagonal whose entries correspond to the strictly lower triangular part of LU. U is a upper triangular matrix of shape &lt;code&gt;[M, M]&lt;/code&gt; whose entries correspond to the upper triangular part, including the diagonal, of LU.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c00b7a881865ff1e4e2196d95bae3abcdc4cd784" translate="yes" xml:space="preserve">
          <source>For each job, if the task index space is dense, the corresponding value will be a list of network addresses; otherwise it will be a dictionary mapping (sparse) task indices to the corresponding addresses.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="487d8b92f2cc03f24f4ba27c6c59fe187e5d7046" translate="yes" xml:space="preserve">
          <source>For each mode passed in via the &lt;code&gt;input_receiver_fn_map&lt;/code&gt;, this method builds a new graph by calling the &lt;code&gt;input_receiver_fn&lt;/code&gt; to obtain feature and label &lt;code&gt;Tensor&lt;/code&gt;s. Next, this method calls the &lt;code&gt;Estimator&lt;/code&gt;'s &lt;code&gt;model_fn&lt;/code&gt; in the passed mode to generate the model graph based on those features and labels, and restores the given checkpoint (or, lacking that, the most recent checkpoint) into the graph. Only one of the modes is used for saving variables to the &lt;code&gt;SavedModel&lt;/code&gt; (order of preference: &lt;a href=&quot;../../../../estimator/modekeys#TRAIN&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.TRAIN&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../../../estimator/modekeys#EVAL&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.EVAL&lt;/code&gt;&lt;/a&gt;, then &lt;a href=&quot;../../../../estimator/modekeys#PREDICT&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.PREDICT&lt;/code&gt;&lt;/a&gt;), such that up to three &lt;code&gt;tf.MetaGraphDefs&lt;/code&gt; are saved with a single set of variables in a single &lt;code&gt;SavedModel&lt;/code&gt; directory.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="894633909e50b7d3307fbbac8ff5cae1f413ff86" translate="yes" xml:space="preserve">
          <source>For each mode passed in via the &lt;code&gt;input_receiver_fn_map&lt;/code&gt;, this method builds a new graph by calling the &lt;code&gt;input_receiver_fn&lt;/code&gt; to obtain feature and label &lt;code&gt;Tensor&lt;/code&gt;s. Next, this method calls the &lt;code&gt;Estimator&lt;/code&gt;'s &lt;code&gt;model_fn&lt;/code&gt; in the passed mode to generate the model graph based on those features and labels, and restores the given checkpoint (or, lacking that, the most recent checkpoint) into the graph. Only one of the modes is used for saving variables to the &lt;code&gt;SavedModel&lt;/code&gt; (order of preference: &lt;a href=&quot;../../../estimator/modekeys#TRAIN&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.TRAIN&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../../estimator/modekeys#EVAL&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.EVAL&lt;/code&gt;&lt;/a&gt;, then &lt;a href=&quot;../../../estimator/modekeys#PREDICT&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.PREDICT&lt;/code&gt;&lt;/a&gt;), such that up to three &lt;code&gt;tf.MetaGraphDefs&lt;/code&gt; are saved with a single set of variables in a single &lt;code&gt;SavedModel&lt;/code&gt; directory.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84ad1b7c0e6d676b66b6c0000beb81f60843b517" translate="yes" xml:space="preserve">
          <source>For each mode passed in via the &lt;code&gt;input_receiver_fn_map&lt;/code&gt;, this method builds a new graph by calling the &lt;code&gt;input_receiver_fn&lt;/code&gt; to obtain feature and label &lt;code&gt;Tensor&lt;/code&gt;s. Next, this method calls the &lt;code&gt;Estimator&lt;/code&gt;'s &lt;code&gt;model_fn&lt;/code&gt; in the passed mode to generate the model graph based on those features and labels, and restores the given checkpoint (or, lacking that, the most recent checkpoint) into the graph. Only one of the modes is used for saving variables to the &lt;code&gt;SavedModel&lt;/code&gt; (order of preference: &lt;a href=&quot;../modekeys#TRAIN&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.TRAIN&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../modekeys#EVAL&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.EVAL&lt;/code&gt;&lt;/a&gt;, then &lt;a href=&quot;../modekeys#PREDICT&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.PREDICT&lt;/code&gt;&lt;/a&gt;), such that up to three &lt;code&gt;tf.MetaGraphDefs&lt;/code&gt; are saved with a single set of variables in a single &lt;code&gt;SavedModel&lt;/code&gt; directory.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b412fda993e08f3c91f400db4d8146e4d0f5bc5f" translate="yes" xml:space="preserve">
          <source>For each mode passed in via the &lt;code&gt;input_receiver_fn_map&lt;/code&gt;, this method builds a new graph by calling the &lt;code&gt;input_receiver_fn&lt;/code&gt; to obtain feature and label &lt;code&gt;Tensor&lt;/code&gt;s. Next, this method calls the &lt;code&gt;Estimator&lt;/code&gt;'s &lt;code&gt;model_fn&lt;/code&gt; in the passed mode to generate the model graph based on those features and labels, and restores the given checkpoint (or, lacking that, the most recent checkpoint) into the graph. Only one of the modes is used for saving variables to the &lt;code&gt;SavedModel&lt;/code&gt; (order of preference: &lt;a href=&quot;modekeys#TRAIN&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.TRAIN&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;modekeys#EVAL&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.EVAL&lt;/code&gt;&lt;/a&gt;, then &lt;a href=&quot;modekeys#PREDICT&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.PREDICT&lt;/code&gt;&lt;/a&gt;), such that up to three &lt;code&gt;tf.MetaGraphDefs&lt;/code&gt; are saved with a single set of variables in a single &lt;code&gt;SavedModel&lt;/code&gt; directory.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36b982fc21506a7f2190761f16a3f5fcc9ede9c0" translate="yes" xml:space="preserve">
          <source>For each patch, right-multiplies the filter matrix and the image patch vector.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c15a30d01baef30188c69bc7ff85b21e3e935e7" translate="yes" xml:space="preserve">
          <source>For each step, calls &lt;code&gt;input_fn&lt;/code&gt;, which returns one batch of data. Evaluates until:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76eabb6e369edfcf348e56ad957e852ddec0f36e" translate="yes" xml:space="preserve">
          <source>For each string in the input &lt;code&gt;Tensor&lt;/code&gt;, creates a substring starting at index &lt;code&gt;pos&lt;/code&gt; with a total length of &lt;code&gt;len&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad124c85b4e4ed2992f3d2d7226cc6682efb0d10" translate="yes" xml:space="preserve">
          <source>For each timestep in the input tensor (dimension #1 in the tensor), if all values in the input tensor at that timestep are equal to &lt;code&gt;mask_value&lt;/code&gt;, then the timestep will be masked (skipped) in all downstream layers (as long as they support masking).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2370b2414271135ef1678cb23ef39f45a5fc2cb3" translate="yes" xml:space="preserve">
          <source>For each value x in &lt;code&gt;error = y_true - y_pred&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b30a7e920276e3b902f956f91fd308b9a443509f" translate="yes" xml:space="preserve">
          <source>For each value x in &lt;code&gt;error=labels-predictions&lt;/code&gt;, the following is calculated:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e81aa8da6e2ca9d6903d446870611925fa37da7" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates the accuracy of each class and returns them.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbcc260a82187cfff98a34fb724a50f62fa1bb51" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;accuracy&lt;/code&gt;. Internally, an &lt;code&gt;is_correct&lt;/code&gt; operation computes a &lt;code&gt;Tensor&lt;/code&gt; with elements 1.0 where the corresponding elements of &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt; match and 0.0 otherwise. Then &lt;code&gt;update_op&lt;/code&gt; increments &lt;code&gt;total&lt;/code&gt; with the reduced sum of the product of &lt;code&gt;weights&lt;/code&gt; and &lt;code&gt;is_correct&lt;/code&gt;, and it increments &lt;code&gt;count&lt;/code&gt; with the reduced sum of &lt;code&gt;weights&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dad08a503e11b5156a4a3427dfc7515950a48e4f" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;auc&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e6ad6df8adaafa9f6c503da039855e65bd9b58e" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;mean&lt;/code&gt;. &lt;code&gt;update_op&lt;/code&gt; increments &lt;code&gt;total&lt;/code&gt; with the reduced sum of the product of &lt;code&gt;values&lt;/code&gt; and &lt;code&gt;weights&lt;/code&gt;, and it increments &lt;code&gt;count&lt;/code&gt; with the reduced sum of &lt;code&gt;weights&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4ab931d2efc0e42b3a757d047bf7f98096c2b78" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;mean_absolute_error&lt;/code&gt;. Internally, an &lt;code&gt;absolute_errors&lt;/code&gt; operation computes the absolute value of the differences between &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt;. Then &lt;code&gt;update_op&lt;/code&gt; increments &lt;code&gt;total&lt;/code&gt; with the reduced sum of the product of &lt;code&gt;weights&lt;/code&gt; and &lt;code&gt;absolute_errors&lt;/code&gt;, and it increments &lt;code&gt;count&lt;/code&gt; with the reduced sum of &lt;code&gt;weights&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="614a1783a568ced9d248f52d9352d35b40792a7a" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;mean_distance&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7bdad2b2535c192103954072920dd86f8d7f97e" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;mean_iou&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21a28b15071e2e3057222499cce4c758670a6204" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;mean_reative_error&lt;/code&gt;. Internally, a &lt;code&gt;relative_errors&lt;/code&gt; operation divides the absolute value of the differences between &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt; by the &lt;code&gt;normalizer&lt;/code&gt;. Then &lt;code&gt;update_op&lt;/code&gt; increments &lt;code&gt;total&lt;/code&gt; with the reduced sum of the product of &lt;code&gt;weights&lt;/code&gt; and &lt;code&gt;relative_errors&lt;/code&gt;, and it increments &lt;code&gt;count&lt;/code&gt; with the reduced sum of &lt;code&gt;weights&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2622e71a2a20b6c576fe07f66c3861f4ae1d6554" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;mean_squared_error&lt;/code&gt;. Internally, a &lt;code&gt;squared_error&lt;/code&gt; operation computes the element-wise square of the difference between &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt;. Then &lt;code&gt;update_op&lt;/code&gt; increments &lt;code&gt;total&lt;/code&gt; with the reduced sum of the product of &lt;code&gt;weights&lt;/code&gt; and &lt;code&gt;squared_error&lt;/code&gt;, and it increments &lt;code&gt;count&lt;/code&gt; with the reduced sum of &lt;code&gt;weights&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="482044def86d900d6f880303c2541fe53cd45fe2" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;percentage&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11887ce5609f24f245ab19a0dae14981801f1e03" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;precision&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2073b65f678bcea68507c8aced29c54089672a4c" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;precision&lt;/code&gt;. &lt;code&gt;update_op&lt;/code&gt; weights each prediction by the corresponding value in &lt;code&gt;weights&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fa9d8aac2d1f3e8b41e5f969b7c9069f2763710" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;precision_at_&amp;lt;k&amp;gt;&lt;/code&gt;. Internally, a &lt;code&gt;top_k&lt;/code&gt; operation computes a &lt;code&gt;Tensor&lt;/code&gt; indicating the top &lt;code&gt;k&lt;/code&gt;&lt;code&gt;predictions&lt;/code&gt;. Set operations applied to &lt;code&gt;top_k&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt; calculate the true positives and false positives weighted by &lt;code&gt;weights&lt;/code&gt;. Then &lt;code&gt;update_op&lt;/code&gt; increments &lt;code&gt;true_positive_at_&amp;lt;k&amp;gt;&lt;/code&gt; and &lt;code&gt;false_positive_at_&amp;lt;k&amp;gt;&lt;/code&gt; using these values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d641bbb0bd1f36939980470649afd513c5fe109" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;recall&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e926696bf238fa1af7b7fd153c6b149672d0579" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;recall_at_&amp;lt;k&amp;gt;&lt;/code&gt;. Internally, a &lt;code&gt;top_k&lt;/code&gt; operation computes a &lt;code&gt;Tensor&lt;/code&gt; indicating the top &lt;code&gt;k&lt;/code&gt;&lt;code&gt;predictions&lt;/code&gt;. Set operations applied to &lt;code&gt;top_k&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt; calculate the true positives and false negatives weighted by &lt;code&gt;weights&lt;/code&gt;. Then &lt;code&gt;update_op&lt;/code&gt; increments &lt;code&gt;true_positive_at_&amp;lt;k&amp;gt;&lt;/code&gt; and &lt;code&gt;false_negative_at_&amp;lt;k&amp;gt;&lt;/code&gt; using these values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e592409ad4457c95b12184bde9fb30acffe72920" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;root_mean_squared_error&lt;/code&gt;. Internally, a &lt;code&gt;squared_error&lt;/code&gt; operation computes the element-wise square of the difference between &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt;. Then &lt;code&gt;update_op&lt;/code&gt; increments &lt;code&gt;total&lt;/code&gt; with the reduced sum of the product of &lt;code&gt;weights&lt;/code&gt; and &lt;code&gt;squared_error&lt;/code&gt;, and it increments &lt;code&gt;count&lt;/code&gt; with the reduced sum of &lt;code&gt;weights&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a7f0bed98595b5568f1d9ffe04c5cc4a5ca7387" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;sensitivity&lt;/code&gt;. &lt;code&gt;update_op&lt;/code&gt; increments the &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; counts with the weight of each case found in the &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b07e75d0103c0e548428284e5efc113eab68537b" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;specificity&lt;/code&gt;. &lt;code&gt;update_op&lt;/code&gt; increments the &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; counts with the weight of each case found in the &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84f3ab8b259e10c767171cb16e1ed0bedcdf7bd6" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; that updates these variables and returns the &lt;code&gt;recall&lt;/code&gt;. &lt;code&gt;update_op&lt;/code&gt; weights each prediction by the corresponding value in &lt;code&gt;weights&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16fe84732ca0277f0c85a01f97b90cbe49eed312" translate="yes" xml:space="preserve">
          <source>For eval, merges metrics by adding &lt;code&gt;head.name&lt;/code&gt; suffix to the keys in eval metrics, such as &lt;code&gt;precision/head1.name&lt;/code&gt;, &lt;code&gt;precision/head2.name&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="096f439eadd884160cca18be357dd236e0d9b954" translate="yes" xml:space="preserve">
          <source>For evaluation and prediction, &lt;code&gt;model_fn&lt;/code&gt; gets per-core batch size and &lt;code&gt;input_fn&lt;/code&gt; get per-host batch size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9aaddffdb76b42aacd2bb37b2bc66b758d2d660a" translate="yes" xml:space="preserve">
          <source>For evaluation, &lt;code&gt;eval_metrics&lt;/code&gt;is a tuple of &lt;code&gt;metric_fn&lt;/code&gt; and &lt;code&gt;tensors&lt;/code&gt;, where &lt;code&gt;metric_fn&lt;/code&gt; runs on CPU to generate metrics and &lt;code&gt;tensors&lt;/code&gt; represents the &lt;code&gt;Tensor&lt;/code&gt;s transferred from TPU system to CPU host and passed to &lt;code&gt;metric_fn&lt;/code&gt;. To be precise, TPU evaluation expects a slightly different signature from the &lt;a href=&quot;../../../../estimator/estimator&quot;&gt;&lt;code&gt;tf.estimator.Estimator&lt;/code&gt;&lt;/a&gt;. While &lt;a href=&quot;../../../../estimator/estimatorspec#eval_metric_ops&quot;&gt;&lt;code&gt;EstimatorSpec.eval_metric_ops&lt;/code&gt;&lt;/a&gt; expects a dict, &lt;code&gt;TPUEstimatorSpec.eval_metrics&lt;/code&gt; is a tuple of &lt;code&gt;metric_fn&lt;/code&gt; and &lt;code&gt;tensors&lt;/code&gt;. The &lt;code&gt;tensors&lt;/code&gt; could be a list of &lt;code&gt;Tensor&lt;/code&gt;s or dict of names to &lt;code&gt;Tensor&lt;/code&gt;s. The &lt;code&gt;tensors&lt;/code&gt; usually specify the model logits, which are transferred back from TPU system to CPU host. All tensors must have be batch-major, i.e., the batch size is the first dimension. Once all tensors are available at CPU host from all shards, they are concatenated (on CPU) and passed as positional arguments to the &lt;code&gt;metric_fn&lt;/code&gt; if &lt;code&gt;tensors&lt;/code&gt; is list or keyword arguments if &lt;code&gt;tensors&lt;/code&gt; is a dict. &lt;code&gt;metric_fn&lt;/code&gt; takes the &lt;code&gt;tensors&lt;/code&gt; and returns a dict from metric string name to the result of calling a metric function, namely a &lt;code&gt;(metric_tensor, update_op)&lt;/code&gt; tuple. See &lt;code&gt;TPUEstimator&lt;/code&gt; for MNIST example how to specify the &lt;code&gt;eval_metrics&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="177050bf0b29fb3f08398a12bddac7a0a078af5e" translate="yes" xml:space="preserve">
          <source>For example &lt;code&gt;foo[3:5,...,4:5]&lt;/code&gt; on a shape 10x3x3x10 tensor is equivalent to &lt;code&gt;foo[3:5,:,:,4:5]&lt;/code&gt; and &lt;code&gt;foo[3:5,...]&lt;/code&gt; is equivalent to &lt;code&gt;foo[3:5,:,:,:]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4dd7ff6a28b3c8f6de1619b3709d89a90256ca48" translate="yes" xml:space="preserve">
          <source>For example if we have a file with the following content:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6db6725e9e7d5c088630e348048d1e73fc7657d3" translate="yes" xml:space="preserve">
          <source>For example,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7cb3885a2d5b333dd84f8883e526c3c627d832d" translate="yes" xml:space="preserve">
          <source>For example, &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;'s &lt;code&gt;input_signature&lt;/code&gt; argument accepts a list (or nested structure) of &lt;code&gt;TypeSpec&lt;/code&gt;s.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e0fb3305e7269deaf00a94f40306ad8dc3b8739" translate="yes" xml:space="preserve">
          <source>For example, &lt;code&gt;foo[:4, tf.newaxis, :2]&lt;/code&gt; would produce a shape &lt;code&gt;(4, 1, 2)&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4cb0994aab88328f91b6706a654056d092b65ec9" translate="yes" xml:space="preserve">
          <source>For example, a &lt;a href=&quot;../../layers/dense&quot;&gt;&lt;code&gt;tf.keras.layers.Dense&lt;/code&gt;&lt;/a&gt; layer, when run on a GPU with a float16 compute dtype, will pass float16 inputs to tf.matmul. But, tf.matmul will do use float32 intermediate math. The performance benefit of float16 is still apparent, due to increased memory bandwidth and the fact modern GPUs have specialized hardware for computing matmuls on float16 while still keeping intermediate computations in float32.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcebdd5340244173df800627bd1fd4d61eafaaf9" translate="yes" xml:space="preserve">
          <source>For example, a long-running operation (e.g. &lt;code&gt;tf.QueueBase.enqueue&lt;/code&gt; may be cancelled by running another operation (e.g. &lt;code&gt;tf.QueueBase.close&lt;/code&gt;, or by &lt;code&gt;tf.Session.close&lt;/code&gt;. A step that is running such a long-running operation will fail by raising &lt;code&gt;CancelledError&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef45f8f5ea52443b495bf1c4d1f242d4e99b9f14" translate="yes" xml:space="preserve">
          <source>For example, assuming that operations of type &lt;code&gt;&quot;Sub&quot;&lt;/code&gt; take two inputs &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;, and return a single output &lt;code&gt;x - y&lt;/code&gt;, the following gradient function would be registered:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="180f2ef709a54a11af8fe0feb0049ea09edaa93b" translate="yes" xml:space="preserve">
          <source>For example, consider the case where a new operation &lt;code&gt;MyNewAwesomeAdd&lt;/code&gt; is created with the intent of replacing the implementation of an existing Python wrapper - &lt;a href=&quot;../math/add&quot;&gt;&lt;code&gt;tf.add&lt;/code&gt;&lt;/a&gt;. The Python wrapper implementation should change from something like:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5485292a2195c6dfb3a48825eb198beefa168928" translate="yes" xml:space="preserve">
          <source>For example, consider the following feature vectors:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ebe2904fc13a0afda0a0801fae06da9da930550" translate="yes" xml:space="preserve">
          <source>For example, consider the following function that commonly occurs in the computation of cross entropy and log likelihoods:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36b3d8f67113dade2a57685778931fd4aac40c92" translate="yes" xml:space="preserve">
          <source>For example, consider the function &lt;code&gt;y = x * x&lt;/code&gt;. The gradient at &lt;code&gt;x = 3.0&lt;/code&gt; can be computed as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="623e0c89de281259a4a76c11ecbd4f9ce138793a" translate="yes" xml:space="preserve">
          <source>For example, for a length-&lt;code&gt;k&lt;/code&gt;, vector-valued distribution, it is calculated as,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6368f536fbdc467faaf091386024de7a14c3cdc" translate="yes" xml:space="preserve">
          <source>For example, for a vocabulary containing 3 labels &lt;code&gt;[a, b, c]&lt;/code&gt;, &lt;code&gt;num_classes = 4&lt;/code&gt; and the labels indexing is &lt;code&gt;{a: 0, b: 1, c: 2, blank: 3}&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04995a90d2cbb2770c2b48eb75173d51eb847e39" translate="yes" xml:space="preserve">
          <source>For example, given a tensor of shape &lt;code&gt;(A, B, C, D)&lt;/code&gt;;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1b94d04ee53deb5a3f4899863cd8936a9a93808" translate="yes" xml:space="preserve">
          <source>For example, given an input of shape &lt;code&gt;[1, 1, 1, 4]&lt;/code&gt;, data_format = &quot;NHWC&quot; and block_size = 2:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73901e6b47ecbf656dbf0c63bc23506a1582b4f9" translate="yes" xml:space="preserve">
          <source>For example, given an input of shape &lt;code&gt;[1, 2, 2, 1]&lt;/code&gt;, data_format = &quot;NHWC&quot; and block_size = 2:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e72f264d4068a89cde912a017b35e1218d4d07d" translate="yes" xml:space="preserve">
          <source>For example, given the following datasets:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36e6a7cc02c6b3197df385da6bc03f401a87598e" translate="yes" xml:space="preserve">
          <source>For example, given the following input:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72fef8ba715160aa4ba1e8d1a7eac5b78987feac" translate="yes" xml:space="preserve">
          <source>For example, given this input:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ccbd1974587f66c012f3ce45843b4a9f5f326074" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;axis = 1&lt;/code&gt; and the inputs are</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12db4e70afdf1bc3643b5acdc6bad82dd0e10f2e" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;elems&lt;/code&gt; is &lt;code&gt;(t1, [t2, t3])&lt;/code&gt; and &lt;code&gt;initializer&lt;/code&gt; is &lt;code&gt;[i1, i2]&lt;/code&gt; then an appropriate signature for &lt;code&gt;fn&lt;/code&gt; in &lt;code&gt;python2&lt;/code&gt; is: &lt;code&gt;fn = lambda (acc_p1, acc_p2), (t1, [t2, t3]):&lt;/code&gt; and &lt;code&gt;fn&lt;/code&gt; must return a list, &lt;code&gt;[acc_n1, acc_n2]&lt;/code&gt;. An alternative correct signature for &lt;code&gt;fn&lt;/code&gt;, and the one that works in &lt;code&gt;python3&lt;/code&gt;, is: &lt;code&gt;fn = lambda a, t:&lt;/code&gt;, where &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;t&lt;/code&gt; correspond to the input tuples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc61fc022fbf77e9b491b661c7505399625f7c88" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;labels&lt;/code&gt;=[a, b, c] and &lt;code&gt;predictions&lt;/code&gt;=[x, y, z], there are three pairs of differences are summed to compute the loss: loss = [ ((a-b) - (x-y)).^2 + ((a-c) - (x-z)).^2 + ((b-c) - (y-z)).^2 ] / 3</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2baa9bbc1cf6bd691324f3eac32cd3df8cf8cd10" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;sp_input.dense_shape = [2, 3, 4]&lt;/code&gt; with non-empty values:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82ef36e97447aa968dcbc0b94c3a5abad62654fd" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;sp_input&lt;/code&gt; has shape &lt;code&gt;[2, 3, 6]&lt;/code&gt; and &lt;code&gt;indices&lt;/code&gt; / &lt;code&gt;values&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fbb93d3efe7c28e2cd5aae402bb6c00323fbb4c" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;sp_input&lt;/code&gt; has shape &lt;code&gt;[3, 5]&lt;/code&gt; and non-empty string values:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48e9053195f85a37348bd311aa5312c62f0d464f" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;sp_input&lt;/code&gt; has shape &lt;code&gt;[4, 5]&lt;/code&gt; and 4 non-empty string values:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8378e24e7a2aa8a60e4c9f1dd742f0e0c198be9" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;sp_input&lt;/code&gt; has shape &lt;code&gt;[4, 5]&lt;/code&gt; and &lt;code&gt;indices&lt;/code&gt; / &lt;code&gt;values&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="079ce847d3f4ddf3969ea935f3da66bee264e67a" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;values&lt;/code&gt; is [1, 3, 5, 7] and reduction=SUM_OVER_BATCH_SIZE, then the value of &lt;code&gt;result()&lt;/code&gt; is 4. If the &lt;code&gt;sample_weight&lt;/code&gt; is specified as [1, 1, 0, 0] then value of &lt;code&gt;result()&lt;/code&gt; would be 2.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="74c85d63fadaf2c9b5598258a9c06918b60fbc1f" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [-1., 1., 1.], and &lt;code&gt;y_pred&lt;/code&gt; is [0.6, -0.7, -0.5] the hinge metric value is 1.6.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="042aca995b0f38a90ddefbc3e2a8e393512784fe" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [-1., 1., 1.], and &lt;code&gt;y_pred&lt;/code&gt; is [0.6, -0.7, -0.5] the squared hinge metric value is 2.6.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d39413a8be385331298ca5abd733969e733cbbd9" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0, 1, 0, 0] and &lt;code&gt;y_pred&lt;/code&gt; is [0, 0, 1, 1] then the false positives value is 2. If the weights were specified as [0, 0, 1, 0] then the false positives value would be 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01fe7d4a63a14b4e23db71a05868b30fb525abd1" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0, 1, 0, 0] and &lt;code&gt;y_pred&lt;/code&gt; is [1, 1, 0, 0] then the true negatives value is 2. If the weights were specified as [0, 0, 1, 0] then the true negatives value would be 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ef6e2ca3f9a644f49c6e0ccb7b4d3c7a6db0fc4" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0, 1, 1, 1] and &lt;code&gt;y_pred&lt;/code&gt; is [0, 1, 0, 0] then the false negatives value is 2. If the weights were specified as [0, 0, 1, 0] then the false negatives value would be 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c8c09a433fcd3271d82f0d4f5f64556a950bbfa" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0, 1, 1, 1] and &lt;code&gt;y_pred&lt;/code&gt; is [1, 0, 1, 1] then the precision value is 2/(2+1) ie. 0.66. If the weights were specified as [0, 0, 1, 0] then the precision value would be 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd7f6e92310398a605f77c3bad5f5cad2b0e6794" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0, 1, 1, 1] and &lt;code&gt;y_pred&lt;/code&gt; is [1, 0, 1, 1] then the recall value is 2/(2+1) ie. 0.66. If the weights were specified as [0, 0, 1, 0] then the recall value would be 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="878e23bb2323f6b8fb30fbec08a976993f265dc2" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0, 1, 1, 1] and &lt;code&gt;y_pred&lt;/code&gt; is [1, 0, 1, 1] then the true positives value is 2. If the weights were specified as [0, 0, 1, 0] then the true positives value would be 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32b3cccbb70066b6b335a50381cd94d294b3c189" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0, 1, 1], and &lt;code&gt;y_pred&lt;/code&gt; is [1, 0, 1], the cosine similarity is 0.5.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c5ba23e60dac33d6e6ff20e271aa3704cc01f45" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0., 0., 1., 1.], and &lt;code&gt;y_pred&lt;/code&gt; is [1., 1., 1., 0.] the mean absolute error is 3/4 (0.75).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10a6bddbd7d48d043bb0ce687f4965fd964d600b" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0., 0., 1., 1.], and &lt;code&gt;y_pred&lt;/code&gt; is [1., 1., 1., 0.] the mean absolute percentage error is 5e+08.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1db7dfad0c8212945bcb0be81f790e3411e18049" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0., 0., 1., 1.], and &lt;code&gt;y_pred&lt;/code&gt; is [1., 1., 1., 0.] the mean squared error is 3/4 (0.75).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="352820f40271575204f969d93b9125b9211bb111" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0., 0., 1., 1.], and &lt;code&gt;y_pred&lt;/code&gt; is [1., 1., 1., 0.] the mean squared logarithmic error is 0.36034.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92f9d133578d098af3f012a74c5de6af734aaac1" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0., 1., 1.], and &lt;code&gt;y_pred&lt;/code&gt; is [1., 0., 1.] the categorical hinge metric value is 1.0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="332538af5696bac076f524f2b4f5a405f689fdfc" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [1, 1, 0, 0] and &lt;code&gt;y_pred&lt;/code&gt; is [0.98, 1, 0, 0.6] then the binary accuracy is 3/4 or .75. If the weights were specified as [1, 0, 0, 1] then the binary accuracy would be 1/2 or .5.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="302da67695947e6cae183abb786ed1ed93793986" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [1, 2, 3, 4] and &lt;code&gt;y_pred&lt;/code&gt; is [0, 2, 3, 4] then the accuracy is 3/4 or .75. If the weights were specified as [1, 1, 0, 0] then the accuracy would be 1/2 or .5.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63dd4aed6e3f523156f4cc8450148bc3eb7f33cb" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [[0, 0, 1], [0, 1, 0]] and &lt;code&gt;y_pred&lt;/code&gt; is [[0.1, 0.9, 0.8], [0.05, 0.95, 0]] then the categorical accuracy is 1/2 or .5. If the weights were specified as [0.7, 0.3] then the categorical accuracy would be .3. You can provide logits of classes as &lt;code&gt;y_pred&lt;/code&gt;, since argmax of logits and probabilities are same.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03b61c36d51ef6615cbd7e2f828167a558e16b95" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [[2], [1]] and &lt;code&gt;y_pred&lt;/code&gt; is [[0.1, 0.9, 0.8], [0.05, 0.95, 0]] then the categorical accuracy is 1/2 or .5. If the weights were specified as [0.7, 0.3] then the categorical accuracy would be .3. You can provide logits of classes as &lt;code&gt;y_pred&lt;/code&gt;, since argmax of logits and probabilities are same.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f13a7bb3ba4ef5812b22736a0c5aa5e4b5379d5" translate="yes" xml:space="preserve">
          <source>For example, if a Boolean flag was created whose long name was 'update' and whose short name was 'x', then this flag could be explicitly unset through either --noupdate or --nox.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="159c6f90d773fa258aa2ceb1607894f00e000d7c" translate="yes" xml:space="preserve">
          <source>For example, if an image is 100 x 200 pixels (height x width) and the bounding box is &lt;code&gt;[0.1, 0.2, 0.5, 0.9]&lt;/code&gt;, the upper-left and bottom-right coordinates of the bounding box will be &lt;code&gt;(40, 10)&lt;/code&gt; to &lt;code&gt;(180, 50)&lt;/code&gt; (in (x,y) coordinates).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07684173fdbd40bd293343faca9d012ab8c45162" translate="yes" xml:space="preserve">
          <source>For example, if an instance of &lt;code&gt;StaticVocabularyTable&lt;/code&gt; is initialized with a string-to-id initializer that maps:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb86a4b81dfbe2a8d5b118b66c9ce83f3cdff0cb" translate="yes" xml:space="preserve">
          <source>For example, if each &lt;code&gt;indices[m]&lt;/code&gt; is scalar or vector, we have</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14f0ac91df308245997c838649986de3acfa389b" translate="yes" xml:space="preserve">
          <source>For example, if elements of the dataset are shaped &lt;code&gt;[B, a0, a1, ...]&lt;/code&gt;, where &lt;code&gt;B&lt;/code&gt; may vary for each input element, then for each element in the dataset, the unbatched dataset will contain &lt;code&gt;B&lt;/code&gt; consecutive elements of shape &lt;code&gt;[a0, a1, ...]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b758388605970f47c42af062f7d7168a335bbc88" translate="yes" xml:space="preserve">
          <source>For example, if one expects a &lt;a href=&quot;../../../tf#float32&quot;&gt;&lt;code&gt;tf.float32&lt;/code&gt;&lt;/a&gt;&lt;code&gt;VarLenFeature&lt;/code&gt;&lt;code&gt;ft&lt;/code&gt; and three serialized &lt;code&gt;Example&lt;/code&gt;s are provided:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb05669fcc3c2a0884538e3c5dcbdcad42ac9ef3" translate="yes" xml:space="preserve">
          <source>For example, if one expects a &lt;a href=&quot;../../tf#float32&quot;&gt;&lt;code&gt;tf.float32&lt;/code&gt;&lt;/a&gt;&lt;code&gt;VarLenFeature&lt;/code&gt;&lt;code&gt;ft&lt;/code&gt; and three serialized &lt;code&gt;Example&lt;/code&gt;s are provided:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f8bdd2413e1c95149871ce390e2fbfac69482604" translate="yes" xml:space="preserve">
          <source>For example, if shape_x is [1, 2, 3] and shape_y is [5, 1, 3], the result is a Tensor whose value is [5, 2, 3].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e1dfee76a0dd69d101ca2f4608dd28751a60789" translate="yes" xml:space="preserve">
          <source>For example, if shape_x is [1, 2, 3] and shape_y is [5, 1, 3], the result is a TensorShape whose value is [5, 2, 3].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e2db8bec254cdfb9c2b8d35134ff51a3f64cd250" translate="yes" xml:space="preserve">
          <source>For example, if the input features are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0176458490bbd6de268b72418c42500856f34603" translate="yes" xml:space="preserve">
          <source>For example, if the input is</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f37e7a6ce06d95b7008768ab5281188eb588a5d" translate="yes" xml:space="preserve">
          <source>For example, if the inputs are</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec19dc8fbf4a531cb12fa3311a36ebe61ce15eb0" translate="yes" xml:space="preserve">
          <source>For example, if the serialized input is a &lt;code&gt;[2, 3]&lt;/code&gt; matrix representing two original &lt;code&gt;SparseTensor&lt;/code&gt; objects:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a70f738ece73b26c4269166b69c29af52453cd5b" translate="yes" xml:space="preserve">
          <source>For example, if values is [1, 3, 5, 7] then the mean is 4. If the weights were specified as [1, 1, 0, 0] then the mean would be 2.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8911ee7c4d9c2878cc8d50831034ed815f5e1c3" translate="yes" xml:space="preserve">
          <source>For example, if values is [1, 3, 5, 7] then the sum is 16. If the weights were specified as [1, 1, 0, 0] then the sum would be 4.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e1df8c42c0b9b864ddf4232778a736fd6146a8f" translate="yes" xml:space="preserve">
          <source>For example, if you had two iterators that marked the current position in a training dataset and a test dataset, you could choose which to use in each step as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa532f960a2ce1a036579c69315203f6c2651d89" translate="yes" xml:space="preserve">
          <source>For example, it can be used to implement the dynamic decoder of a seq2seq model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e782088c1d829573c59eb47813c6583133dd6bf0" translate="yes" xml:space="preserve">
          <source>For example, running a &lt;code&gt;tf.QueueBase.enqueue&lt;/code&gt; operation may raise &lt;code&gt;AbortedError&lt;/code&gt; if a &lt;code&gt;tf.QueueBase.close&lt;/code&gt; operation previously ran.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6fb766e4eb77cad3c4ed3c20934b9966a924fe5a" translate="yes" xml:space="preserve">
          <source>For example, running an operation that saves a file (e.g. &lt;code&gt;tf.train.Saver.save&lt;/code&gt;) could potentially raise this exception if an explicit filename for an existing file was passed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="18f700fd2ce897b85fe0dede4441f3a1eacfcf00" translate="yes" xml:space="preserve">
          <source>For example, running the &lt;code&gt;tf.WholeFileReader.read&lt;/code&gt; operation could raise &lt;code&gt;NotFoundError&lt;/code&gt; if it receives the name of a file that does not exist.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfa313373d48902517bbb0ec4668f45e63a5050e" translate="yes" xml:space="preserve">
          <source>For example, running the &lt;code&gt;tf.WholeFileReader.read&lt;/code&gt; operation could raise &lt;code&gt;PermissionDeniedError&lt;/code&gt; if it receives the name of a file for which the user does not have the read file permission.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f9fc30c26c26b9c0cc0d112a519a99605e0e840" translate="yes" xml:space="preserve">
          <source>For example, running the same function in two separate critical sections will not ensure serial execution:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bef67e884ee584f664d6ae2ff6b50fa0e2467597" translate="yes" xml:space="preserve">
          <source>For example, say we want to add 4 scattered elements to a rank-1 tensor to 8 elements. In Python, that addition would look like this:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1465860225753881464cf1173eca6c9061ef5e4f" translate="yes" xml:space="preserve">
          <source>For example, say we want to add 4 scattered elements to a rank-1 tensor to 8 elements. In Python, that update would look like this:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="debc3020545312e69c35338b60b8ad1a5d0f1fc6" translate="yes" xml:space="preserve">
          <source>For example, say we want to subtract 4 scattered elements from a rank-1 tensor with 8 elements. In Python, that update would look like this:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56ffaf4007daaf44f9fa50fd0b3fcda03d228d5e" translate="yes" xml:space="preserve">
          <source>For example, say we want to update 4 scattered elements to a rank-1 tensor to 8 elements. In Python, that update would look like this:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9818c958e44ded80c1b979231b05b2b1e699a832" translate="yes" xml:space="preserve">
          <source>For example, say you have a class A that compares only on its attribute x. Comparators other than &lt;strong&gt;lt&lt;/strong&gt; are omitted for brevity.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b868a0b995363e52f99179ab5b2eb1da4495ee3" translate="yes" xml:space="preserve">
          <source>For example, suppose &lt;code&gt;sp_input&lt;/code&gt; has shape &lt;code&gt;[5, 6]&lt;/code&gt; and non-empty values:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4b8890d00c239dfe3d4938b6c67d2e0e8fe86301" translate="yes" xml:space="preserve">
          <source>For example, suppose that &lt;code&gt;data&lt;/code&gt; has data type &lt;a href=&quot;../tf#int32&quot;&gt;&lt;code&gt;tf.int32&lt;/code&gt;&lt;/a&gt; and shape (2, 3, 4), and that the fingerprint method is &lt;code&gt;farmhash64&lt;/code&gt;. In this case, the output shape is (2, 8), where 2 is the batch dimension size of &lt;code&gt;data&lt;/code&gt;, and 8 is the size of each fingerprint value in bytes. &lt;code&gt;output[0, :]&lt;/code&gt; is generated from 12 integers in &lt;code&gt;data[0, :, :]&lt;/code&gt; and similarly &lt;code&gt;output[1, :]&lt;/code&gt; is generated from other 12 integers in &lt;code&gt;data[1, :, :]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb886fc90913d3858a07b6c81699df2c93cbae46" translate="yes" xml:space="preserve">
          <source>For example, suppose the logical sum of two sparse operands is (densified):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e241e14b323a360c93e117165ee51f625869bb65" translate="yes" xml:space="preserve">
          <source>For example, suppose we have a file 'my_file0.csv' with four CSV columns of different data types:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0636239203f94658f87029781558265ccc3966ab" translate="yes" xml:space="preserve">
          <source>For example, the desired output for the following 4-by-4 kernel::</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd21ccc094cad8a87d4c4eacb04b552c571f6bf7" translate="yes" xml:space="preserve">
          <source>For example, the returned matrix &lt;code&gt;A&lt;/code&gt; can be used to right-multiply a spectrogram &lt;code&gt;S&lt;/code&gt; of shape &lt;code&gt;[frames, num_spectrogram_bins]&lt;/code&gt; of linear scale spectrum values (e.g. STFT magnitudes) to generate a &quot;mel spectrogram&quot; &lt;code&gt;M&lt;/code&gt; of shape &lt;code&gt;[frames, num_mel_bins]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db3131b06d6d3d95a5212d36111977d0f86b08dc" translate="yes" xml:space="preserve">
          <source>For example, this error might be raised if a per-user quota is exhausted, or perhaps the entire file system is out of space.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54823754fbaf34b915d76fccb6e9c1dc44f28481" translate="yes" xml:space="preserve">
          <source>For example, this may be raised by running a &lt;code&gt;tf.WholeFileReader.read&lt;/code&gt; operation, if the file is truncated while it is being read.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abbb5690c25366ae4f227979e99899132fb6b656" translate="yes" xml:space="preserve">
          <source>For example, to define a new Python op called &lt;code&gt;my_op&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72eb7a551315d06a0972d21f1c1b460b5d38b044" translate="yes" xml:space="preserve">
          <source>For example, to define a new summary op called &lt;code&gt;my_op&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66fdf1bdfa059fe195251be30a7a3ab0c36ff0bc" translate="yes" xml:space="preserve">
          <source>For example, user can select profiler nodes placed on gpu:0 with: &lt;code&gt;account_type_regexes=['.*gpu:0.*']&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="386f9efb3adea5d954835eac08e3b8fcac5cfc82" translate="yes" xml:space="preserve">
          <source>For example, we can represent the following 2D &lt;code&gt;SparseTensor&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47f6cacac9bb0941442b9ab6365d7dd1f22cf231" translate="yes" xml:space="preserve">
          <source>For example, with &lt;code&gt;W&lt;/code&gt;, &lt;code&gt;X&lt;/code&gt;, &lt;code&gt;Y&lt;/code&gt;, &lt;code&gt;Z&lt;/code&gt; each block circulant,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b91edd5cdc9ee891969b8b38deeabdcc71594122" translate="yes" xml:space="preserve">
          <source>For example, with &lt;code&gt;W&lt;/code&gt;, &lt;code&gt;X&lt;/code&gt;, &lt;code&gt;Y&lt;/code&gt;, &lt;code&gt;Z&lt;/code&gt; each circulant,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="59bbe6de1d6b96b3f8288dbb5f70eca92be21e1f" translate="yes" xml:space="preserve">
          <source>For example, within a &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;c = tf.matmul(a, b)&lt;/code&gt; creates an &lt;code&gt;Operation&lt;/code&gt; of type &quot;MatMul&quot; that takes tensors &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; as input, and produces &lt;code&gt;c&lt;/code&gt; as output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="798a25ee68143b917f057d252e6a3be788b95a21" translate="yes" xml:space="preserve">
          <source>For example, you can use &lt;a href=&quot;../../../../data/dataset#interleave&quot;&gt;&lt;code&gt;Dataset.interleave()&lt;/code&gt;&lt;/a&gt; to process many input files concurrently:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62bc270e8147fe9b0d27fc9ede5facea85ba5170" translate="yes" xml:space="preserve">
          <source>For example, you can use &lt;a href=&quot;../../../data/dataset#interleave&quot;&gt;&lt;code&gt;Dataset.interleave()&lt;/code&gt;&lt;/a&gt; to process many input files concurrently:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a8cdf19717ec8bf5f04585f7d033f7a2610e6d2" translate="yes" xml:space="preserve">
          <source>For example, you can use &lt;a href=&quot;../dataset#interleave&quot;&gt;&lt;code&gt;Dataset.interleave()&lt;/code&gt;&lt;/a&gt; to process many input files concurrently:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5898266aaebf0c43713533e3d18bf9ec4db717f3" translate="yes" xml:space="preserve">
          <source>For example, you can use &lt;a href=&quot;dataset#interleave&quot;&gt;&lt;code&gt;Dataset.interleave()&lt;/code&gt;&lt;/a&gt; to process many input files concurrently:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="059c3e8cce263b2945a18ac90b2637e10a8026b1" translate="yes" xml:space="preserve">
          <source>For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a925ece6d9c348c8aa9316dcdeed531900dee368" translate="yes" xml:space="preserve">
          <source>For example: if &lt;code&gt;filepath&lt;/code&gt; is &lt;code&gt;weights.{epoch:02d}-{val_loss:.2f}.hdf5&lt;/code&gt;, then the model checkpoints will be saved with the epoch number and the validation loss in the filename.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e701a0677a91df738cbd270184ad84b85cb6a3f" translate="yes" xml:space="preserve">
          <source>For f(*args, **kwargs), this supports gradients with respect to args, or to gradients with respect to any variables residing in the kwarg 'variables'. Note that for keras layer and model objects, this is handled automatically.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4b53b836d997d79180b7e3d91c8e783a2730a27" translate="yes" xml:space="preserve">
          <source>For floats, the default range is &lt;code&gt;[0, 1)&lt;/code&gt;. For ints, at least &lt;code&gt;maxval&lt;/code&gt; must be specified explicitly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e111c995974685355c526b35bd247aea54214a0f" translate="yes" xml:space="preserve">
          <source>For gamma greater than 1, the histogram will shift towards left and the output image will be darker than the input image. For gamma less than 1, the histogram will shift towards right and the output image will be brighter than the input image.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a9f804d2c5657eeaad57f76da30d8419d9f80b2" translate="yes" xml:space="preserve">
          <source>For information about the valid syntax of device name strings, see the documentation in &lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/util/device_name_utils.h&quot;&gt;&lt;code&gt;DeviceNameUtils&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e34ec3911430ce7f98ae14651feabc2f68db9179" translate="yes" xml:space="preserve">
          <source>For input dictionary &lt;code&gt;features&lt;/code&gt;, &lt;code&gt;features[key]&lt;/code&gt; is either &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt;. If &lt;code&gt;Tensor&lt;/code&gt;, missing values can be represented by &lt;code&gt;-1&lt;/code&gt; for int and &lt;code&gt;''&lt;/code&gt; for string, which will be dropped by this feature column.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d566a2f8f613dd39800087ce7bc50e2d5f86120" translate="yes" xml:space="preserve">
          <source>For instance, if a, b and c are Keras tensors, it becomes possible to do: &lt;code&gt;model = Model(input=[a, b], output=c)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e53703556bacc5b9f2dd5c8a308f65648989002" translate="yes" xml:space="preserve">
          <source>For instance, if params is a 10x20 matrix, and sp_ids / sp_weights are</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc75bd8580ca757aae48910bd54d05e3c0b7bbe2" translate="yes" xml:space="preserve">
          <source>For instance, if your dataset contains 10,000 elements but &lt;code&gt;buffer_size&lt;/code&gt; is set to 1,000, then &lt;code&gt;shuffle&lt;/code&gt; will initially select a random element from only the first 1,000 elements in the buffer. Once an element is selected, its space in the buffer is replaced by the next (i.e. 1,001-st) element, maintaining the 1,000 element buffer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abc897209b2f98b7966665fa36a5eddbbc44f66d" translate="yes" xml:space="preserve">
          <source>For instance:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f9023a39798cc65b443278b72b316a68e41f333" translate="yes" xml:space="preserve">
          <source>For many models, each layer's policy will have the same compute dtype and variable dtype, which will typically be float32. In this case, we refer to the singular dtype as the layer's dtype, which can be queried by the property &lt;a href=&quot;../../layers/layer#dtype&quot;&gt;&lt;code&gt;tf.keras.layers.Layer.dtype&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a9115e76a0ba9659e12e140504c8f7f39148287" translate="yes" xml:space="preserve">
          <source>For matrices (resp. higher rank input), computes the top &lt;code&gt;k&lt;/code&gt; entries in each row (resp. vector along the last dimension). Thus,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6f81428f9faf616b5f58bf1dfb8c2ee23290062" translate="yes" xml:space="preserve">
          <source>For more details on fractional max pooling, see this paper: &lt;a href=&quot;http://arxiv.org/abs/1412.6071&quot;&gt;Benjamin Graham, Fractional Max-Pooling&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bdc341899055084bcb94f72be25a2efd912ef0ce" translate="yes" xml:space="preserve">
          <source>For more details on warm-start configuration, see &lt;a href=&quot;../../../estimator/warmstartsettings&quot;&gt;&lt;code&gt;tf.estimator.WarmStartSettings&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e3c977af7155e901bdef759f3dc14b55e9fc4b7" translate="yes" xml:space="preserve">
          <source>For more details on warm-start configuration, see &lt;a href=&quot;warmstartsettings&quot;&gt;&lt;code&gt;tf.estimator.WarmStartSettings&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13a2417d18055bf8846c48234727817863de443c" translate="yes" xml:space="preserve">
          <source>For more details, see the documentation for &lt;code&gt;keras_style_scope&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="152f8ea26d1cff79ab2d01228bf1bdbd0f39e953" translate="yes" xml:space="preserve">
          <source>For more information on eager execution, see the &lt;a href=&quot;https://tensorflow.org/guide/eager&quot;&gt;Eager guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a3c4bae8cff17665d7c40bbc999f6a1d5c25c78" translate="yes" xml:space="preserve">
          <source>For more information see: https://github.com/catapult-project/catapult/blob/master/tracing/README.md</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b43d393bddf0580f867617eb6c2e2f89c938fa23" translate="yes" xml:space="preserve">
          <source>For more information, see the &lt;a href=&quot;https://www.tensorflow.org/guide/autograph&quot;&gt;AutoGraph guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ec21b841a665c40f4c5e83efe27648e19e46e51" translate="yes" xml:space="preserve">
          <source>For ops such as matrix multiplication, inputs and weights must be of the same float type. This function validates that all &lt;code&gt;tensors&lt;/code&gt; are the same type, validates that type is &lt;code&gt;dtype&lt;/code&gt; (if supplied), and returns the type. Type must be a floating point type. If neither &lt;code&gt;tensors&lt;/code&gt; nor &lt;code&gt;dtype&lt;/code&gt; is supplied, the function will return &lt;a href=&quot;../dtypes#float32&quot;&gt;&lt;code&gt;dtypes.float32&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="825adbf912a447d1f0e6ca8ee392497c694816b6" translate="yes" xml:space="preserve">
          <source>For ops that have a well-defined gradient but are not yet implemented, no declaration should be made, and an error &lt;em&gt;must&lt;/em&gt; be thrown if an attempt to request its gradient is made.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c54552d8b9297a0500954f1e7088d433c083309" translate="yes" xml:space="preserve">
          <source>For positive numbers, this function computes log((input - 1)!) for every element in the tensor. &lt;code&gt;lgamma(5) = log((5-1)!) = log(4!) = log(24) = 3.1780539&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17614033a9da90968bc5248bce2e63241d0b5eef" translate="yes" xml:space="preserve">
          <source>For prediction, merges predictions and updates keys in prediction dict to a 2-tuple, &lt;code&gt;(head.name, prediction_key)&lt;/code&gt;. Merges &lt;code&gt;export_outputs&lt;/code&gt; such that by default the first head is served.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="367d3134a5e071179a22d4af24a5885a46b948f8" translate="yes" xml:space="preserve">
          <source>For prediction, the exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;../../../../estimator/export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d910d10e5e5c18870b7b9be467a883825361a57a" translate="yes" xml:space="preserve">
          <source>For prediction, the exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;../../../estimator/export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85e499998a4aff01940823b0150823a9caaab4eb" translate="yes" xml:space="preserve">
          <source>For prediction, the exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;../export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f2dca7789ee2c5012c2ae28c6f51ef0341736b8" translate="yes" xml:space="preserve">
          <source>For prediction, the exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51b640d64056e8e41f482c3d3c805d8ad85d361d" translate="yes" xml:space="preserve">
          <source>For python 2.x.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6616ed4ca65ec91b81df8451d8cc7918059964cb" translate="yes" xml:space="preserve">
          <source>For regression: one-dimensional label.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebc60d85f1c75542a5be8407d74123940e50f678" translate="yes" xml:space="preserve">
          <source>For saving the input pipeline checkpoint alongside the model weights use &lt;a href=&quot;make_saveable_from_iterator&quot;&gt;&lt;code&gt;tf.data.experimental.make_saveable_from_iterator&lt;/code&gt;&lt;/a&gt; directly to create a &lt;code&gt;SaveableObject&lt;/code&gt; and add to the &lt;code&gt;SAVEABLE_OBJECTS&lt;/code&gt; collection. Note, however, that you will need to be careful not to restore the training iterator during eval. You can do that by not adding the iterator to the SAVEABLE_OBJECTS collector when building the eval graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4040772dee03e98d438db586092ddda710d40777" translate="yes" xml:space="preserve">
          <source>For string data, one should expect &lt;code&gt;tf.fingerprint(data) != tf.fingerprint(tf.string.reduce_join(data))&lt;/code&gt; in general.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1aee93356a8ac03609dbb2efcc3b9bc6ffc3cf8f" translate="yes" xml:space="preserve">
          <source>For the above example, make_parse_example_spec would return the dict:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0235be247e65fa625cc59d166e2a6820d050e19f" translate="yes" xml:space="preserve">
          <source>For the content in &lt;code&gt;TF_CONFIG&lt;/code&gt;, assume that the training cluster spec looks like:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f06a3bf9b1afd83f2dc01b9bce2b59a3031f004" translate="yes" xml:space="preserve">
          <source>For the idea of warm starts here controlled by &lt;code&gt;num_periods&lt;/code&gt;, see [Loshchilov &amp;amp; Hutter, ICLR2016] SGDR: Stochastic Gradient Descent with Warm Restarts. https://arxiv.org/abs/1608.03983</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd1f2c4cb29e01e87b19426efdde9e0733dd9a05" translate="yes" xml:space="preserve">
          <source>For the most part, the mapping between Proto field types and TensorFlow dtypes is straightforward. However, there are a few special cases:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c23aedef4b8e055530a87dad6ff1b4b7682cb7a9" translate="yes" xml:space="preserve">
          <source>For the purposes of this function, a valid ordered sequence type is one which can be indexed, has a length, and has an equality operator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="277400dd8bda8642b7e25a7ed51e2ae99e733ee3" translate="yes" xml:space="preserve">
          <source>For the replicas:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a61ac4581750cc1861ea15aab1f318fa5e0885d" translate="yes" xml:space="preserve">
          <source>For the variables and &lt;code&gt;tf.MetaGraphDefs&lt;/code&gt;, a timestamped export directory below &lt;code&gt;export_dir_base&lt;/code&gt;, and writes a &lt;code&gt;SavedModel&lt;/code&gt; into it containing the &lt;code&gt;tf.MetaGraphDef&lt;/code&gt; for the given mode and its associated signatures.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56c86fc9affcdc3686a615c6369da410c6e71b43" translate="yes" xml:space="preserve">
          <source>For this function to work, the stream must have a file descriptor that can be modified using &lt;code&gt;os.dup&lt;/code&gt; and &lt;code&gt;os.dup2&lt;/code&gt;, and the stream must support a &lt;code&gt;.flush()&lt;/code&gt; method. The default python sys.stdout and sys.stderr are examples of this. Note that this does not work in Colab or Jupyter notebooks, because those use alternate stdout streams.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac41fbab77768e9b6192dc00dfce9e8a5ab1aa29" translate="yes" xml:space="preserve">
          <source>For training and evaluation, the &lt;code&gt;train_op&lt;/code&gt; is stored in an extra collection, and loss, metrics, and predictions are included in a &lt;code&gt;SignatureDef&lt;/code&gt; for the mode in question.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8cb90deddea49c5d8ea800cc7d640f23ce709e57" translate="yes" xml:space="preserve">
          <source>For training, &lt;code&gt;model_fn&lt;/code&gt; gets per-core batch size; &lt;code&gt;input_fn&lt;/code&gt; may get per-core or per-host batch size depending on &lt;code&gt;per_host_input_for_training&lt;/code&gt; in &lt;code&gt;TPUConfig&lt;/code&gt; (See docstring for TPUConfig for details).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="851eb999d65883da2e108c88c201473ef5f90761" translate="yes" xml:space="preserve">
          <source>For training, TensorFlow stores the tensors that are produced in the forward inference and are needed in back propagation. These tensors are a main source of memory consumption and often cause OOM errors when training on GPUs. When the flag swap_memory is true, we swap out these tensors from GPU to CPU. This for example allows us to train RNN models with very long sequences and large batches.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="686652c961bb116ce8005add3ae7ed8c5b4c585b" translate="yes" xml:space="preserve">
          <source>For training, sums losses of each head, calls &lt;code&gt;train_op_fn&lt;/code&gt; with this final loss.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="249a8fecba276e5537d5687430c7832f6a097905" translate="yes" xml:space="preserve">
          <source>For tutorial on the options, see https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/g3doc/options.md</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0250883f7e36fe46e791c49d58341332e74601a" translate="yes" xml:space="preserve">
          <source>For usage example, please see: &lt;a href=&quot;https://www.tensorflow.org/guide/estimators#creating_estimators_from_keras_models&quot;&gt;Creating estimators from Keras Models&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af78702967e9ea264023f8fbaf663f2a1adc42b5" translate="yes" xml:space="preserve">
          <source>For use with &lt;a href=&quot;ctc_loss&quot;&gt;&lt;code&gt;tf.nn.ctc_loss&lt;/code&gt;&lt;/a&gt; optional argument &lt;code&gt;unique&lt;/code&gt;: This op can be used to preprocess labels in input pipeline to for better speed/memory use computing the ctc loss on TPU.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="740b2ee4e4d8bf4808f11e53b605666e73b665e3" translate="yes" xml:space="preserve">
          <source>For variables placed in TPU device, which includes variables created inside TPUStrategy scope, outside compilation logic must not include variable read/write. For variables placed on host, which is the case when variables created via TPUEstimator, variable read/write is only allowed if the variable is not accessed by any other ops in the TPU computation. Variable read/write from outside compilation cluster is not visible from TPU computation and vice versa. Therefore, if outside compilation logic contains such host variables read/write ops and if the variables are accessed by TPU computation as well, then this may lead to deadlock.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34cca35024442a2daa7b2b0c02c66c45e14c3cb9" translate="yes" xml:space="preserve">
          <source>For x &amp;lt; 0, to avoid overflow in exp(-x), we reformulate the above</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8dfe58b9051d5a627bc446c6f93be3012efd4568" translate="yes" xml:space="preserve">
          <source>Forces summary writer to send any buffered data to storage.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9f17deb03f3afa151a329975529588281686220" translate="yes" xml:space="preserve">
          <source>Formats a string template using a list of tensors, abbreviating tensors by only printing the first and last &lt;code&gt;summarize&lt;/code&gt; elements of each dimension (recursively). If formatting only one tensor into a template, the tensor does not have to be wrapped in a list.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="239f72546128721c29c8c3274ac9f9554ba33807" translate="yes" xml:space="preserve">
          <source>Formats a string template using a list of tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aab407c990b5dd2317ab563c02f7afc3c37496b1" translate="yes" xml:space="preserve">
          <source>Formats both the test method name and the first line of its docstring.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="30411971a5c7c0c65716d7a2276bc0753edc1090" translate="yes" xml:space="preserve">
          <source>Formatting a multi-tensor template:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e8e20d914a22b13e7830695a5885972e5f7dd9c" translate="yes" xml:space="preserve">
          <source>Formatting a single-tensor template:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c50d21ebeb5eb1221d5f8c11b87f7e8ba73b2e5f" translate="yes" xml:space="preserve">
          <source>Forward-compatibility refers to scenarios where the producer of a TensorFlow model (a GraphDef or SavedModel) is compiled against a version of the TensorFlow library newer than what the consumer was compiled against. The &quot;producer&quot; is typically a Python program that constructs and trains a model while the &quot;consumer&quot; is typically another program that loads and serves the model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d85bd4cd5990fd7543a86021751d93d42f1357b3" translate="yes" xml:space="preserve">
          <source>Forwarding the variables from the underlying optimizer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c89a9afa7f5354e4a63edd2e6c0d0b4901dd765" translate="yes" xml:space="preserve">
          <source>Four &lt;code&gt;Tensor&lt;/code&gt; objects of the same type as &lt;code&gt;x&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40d7d8597b074e3ac7474d10a611c554ad7fa982" translate="yes" xml:space="preserve">
          <source>Fractional average pooling is similar to Fractional max pooling in the pooling region generation step. The only difference is that after pooling regions are generated, a mean operation is performed instead of a max operation in each pooling region.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5041cde3f1a2533e4659d2586c2ffe569e1d7dcf" translate="yes" xml:space="preserve">
          <source>Fractional max pooling is slightly different than regular max pooling. In regular max pooling, you downsize an input set by taking the maximum value of smaller N x N subsections of the set (often 2x2), and try to reduce the set by a factor of N, where N is an integer. Fractional max pooling, as you might expect from the word &quot;fractional&quot;, means that the overall reduction ratio N does not have to be an integer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd28230ef13373337ce1949fe5af0d799f846337" translate="yes" xml:space="preserve">
          <source>From &lt;a href=&quot;http://www.jmlr.org/papers/volume3/gers02a/gers02a.pdf&quot;&gt;Gers et al.&lt;/a&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4cdba04d7a9eac83a97bc8f1d7ed1afaf3de99f7" translate="yes" xml:space="preserve">
          <source>From these definitions, we see that</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3aca6a2cadbde9796176b9f2bdc4ddaa5883a4b4" translate="yes" xml:space="preserve">
          <source>Fully-connected RNN where the output is to be fed back to input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04613c353330a3b030cda37163970b74de725fdc" translate="yes" xml:space="preserve">
          <source>Function builder for a dnn logit_fn.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80bb380683226de01695aa870f90690f020ccf39" translate="yes" xml:space="preserve">
          <source>Function builder for a linear logit_fn.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="961134f334d4e3d099fd3b88ec79f66049e02609" translate="yes" xml:space="preserve">
          <source>Function corresponding to the input string or input function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84942f5d7faa1848468aa47bc1832cb4ffceb2fa" translate="yes" xml:space="preserve">
          <source>Function for &lt;code&gt;decode_bmp&lt;/code&gt;, &lt;code&gt;decode_gif&lt;/code&gt;, &lt;code&gt;decode_jpeg&lt;/code&gt;, and &lt;code&gt;decode_png&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b46ccb902892f13f107bf66a75f9bf8327cbae4d" translate="yes" xml:space="preserve">
          <source>Function, that has signature of ()-&amp;gt;(dict of &lt;code&gt;features&lt;/code&gt;, &lt;code&gt;target&lt;/code&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52f2894799ccb50c7b33084828e4f3851ea4df75" translate="yes" xml:space="preserve">
          <source>Function, that has signature of ()-&amp;gt;(dict of &lt;code&gt;features&lt;/code&gt;, &lt;code&gt;targets&lt;/code&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88fcd90125004d28567d342c9f3165809fb40cbc" translate="yes" xml:space="preserve">
          <source>Functional interface for the batch normalization layer. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3008e201e4f95d586e2d708853592636025c56ec" translate="yes" xml:space="preserve">
          <source>Functional interface for the depthwise separable 1D convolution layer. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="843524e6eccb65e6f3f97379f7de26c2a2f2da67" translate="yes" xml:space="preserve">
          <source>Functional interface for the depthwise separable 2D convolution layer. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55f27b3100890ca22fc05334143ec1799a0365f4" translate="yes" xml:space="preserve">
          <source>Functional interface for transposed 2D convolution layer. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc0e25ff898bc600b9c3b618d6944b678eac556b" translate="yes" xml:space="preserve">
          <source>Functional interface for transposed 3D convolution layer. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b961dea1dc0c60ddf9a2c8e9d090f6f7d082483" translate="yes" xml:space="preserve">
          <source>Functions</source>
          <target state="translated">Functions</target>
        </trans-unit>
        <trans-unit id="abc7c3058aaf16961ae99141267b62b102b7362a" translate="yes" xml:space="preserve">
          <source>Functions are converted into new functions with converted code.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f53929fbbbf3598a8477b3e21c530968bf2b1e4" translate="yes" xml:space="preserve">
          <source>Functions used to extract and analyze stacks. Faster than Python libs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1088f52ee06b617e019df677ae2d985ea8367ee8" translate="yes" xml:space="preserve">
          <source>Further, each thread starts with an empty variable scope. So if you wish to preserve name prefixes from a scope from the main thread, you should capture the main thread's scope and re-enter it in each thread. For e.g.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17d43e06d288fdecd9a150c3bd7e9213832b2bda" translate="yes" xml:space="preserve">
          <source>Furthermore, &lt;code&gt;fn&lt;/code&gt; may emit a different structure than its input. For example, &lt;code&gt;fn&lt;/code&gt; may look like: &lt;code&gt;fn = lambda t1: return (t1 + 1, t1 - 1)&lt;/code&gt;. In this case, the &lt;code&gt;dtype&lt;/code&gt; parameter is not optional: &lt;code&gt;dtype&lt;/code&gt; must be a type or (possibly nested) tuple of types matching the output of &lt;code&gt;fn&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cac9ee53753b3ccba19a58872a949a03e0ed0a6d" translate="yes" xml:space="preserve">
          <source>Fused implementation of &lt;code&gt;map&lt;/code&gt; and &lt;code&gt;batch&lt;/code&gt;. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="754a365f8fd6b9ceb366bc46267e7e7fae2e01b8" translate="yes" xml:space="preserve">
          <source>Future major versions of TensorFlow will allow gradients to flow into the labels input on backprop by default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51e841ad3b27b555240bd3208409784776b78d91" translate="yes" xml:space="preserve">
          <source>GIF images with frame or transparency compression are not supported. On Linux and MacOS systems, convert animated GIFs from compressed to uncompressed by running:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc2cb7021c13ea83cc3e049d7402c76b692e0416" translate="yes" xml:space="preserve">
          <source>GNU style allows mixing of flag and non-flag arguments. See http://docs.python.org/library/getopt.html#getopt.gnu_getopt</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c8a873ea949d50ad1aac033a294a578fd5c4e69" translate="yes" xml:space="preserve">
          <source>Gamma distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f031510b482abd8e720846e8669696f7e91ec56" translate="yes" xml:space="preserve">
          <source>Gated Recurrent Unit - Cho et al. 2014.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69e499dfe689408aae1f951c32b8c1bbc6c2faf0" translate="yes" xml:space="preserve">
          <source>Gated Recurrent Unit cell (cf.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d20e4a3a201cb2fbb73307001cac40611d72da6" translate="yes" xml:space="preserve">
          <source>Gather slices from &lt;code&gt;params&lt;/code&gt; into a Tensor with shape specified by &lt;code&gt;indices&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="299d0ae5001a60c54f445823747df39bdc8fe265" translate="yes" xml:space="preserve">
          <source>Gather slices from params according to indices with leading batch dims. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f262790bfae9447f613388f0f2dfc06ee3e6e9af" translate="yes" xml:space="preserve">
          <source>Gather slices from params axis &lt;code&gt;axis&lt;/code&gt; according to &lt;code&gt;indices&lt;/code&gt;. &lt;code&gt;indices&lt;/code&gt; must be an integer tensor of any dimension (usually 0-D or 1-D).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f385f50f48df2546a7fa47ac7842fb6cb974b02" translate="yes" xml:space="preserve">
          <source>Gather slices from params axis &lt;code&gt;axis&lt;/code&gt; according to indices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e17db4db1be26624736cd7163c7e0a82b1dfd230" translate="yes" xml:space="preserve">
          <source>Gather slices from params axis axis according to indices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b380773b6f24a5afe663b7e22de6423bb935598" translate="yes" xml:space="preserve">
          <source>Gating Gradients</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f72dabec415cca8805069ec0515ea199976c6048" translate="yes" xml:space="preserve">
          <source>General case:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6368188d3687992a62f99d6b7334f52aaac43948" translate="yes" xml:space="preserve">
          <source>Generalization of &lt;a href=&quot;scatter_update&quot;&gt;&lt;code&gt;tf.compat.v1.scatter_update&lt;/code&gt;&lt;/a&gt; to axis different than 0. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb11ae4a716352e80393f10cd2fbf3c5ef996fc6" translate="yes" xml:space="preserve">
          <source>Generally a single example in training data is described with FeatureColumns. At the first layer of the model, this column oriented data should be converted to a single &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8de3a173a70a93846ce03fd16984e4335207f7a1" translate="yes" xml:space="preserve">
          <source>Generally it is best if the shard operator is used early in the dataset pipeline. For example, when reading from a set of TFRecord files, shard before converting the dataset to input samples. This avoids reading every file on every worker. The following is an example of an efficient sharding strategy within a complete pipeline:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34347d3edc6f1c3feaba292295a44f85ae9283b4" translate="yes" xml:space="preserve">
          <source>Generate a &lt;a href=&quot;https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows&quot;&gt;Hamming&lt;/a&gt; window.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="279c13b7205ad932f6fc77bc4c11a570af2e0643" translate="yes" xml:space="preserve">
          <source>Generate a &lt;a href=&quot;https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows&quot;&gt;Hann window&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac32a415109d1780683dc87c835b4bf44b9e214f" translate="yes" xml:space="preserve">
          <source>Generate a SignatureDef proto for inclusion in a MetaGraphDef.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b79e30cedbd9d694f0b8690f5c2126451ebafb1" translate="yes" xml:space="preserve">
          <source>Generate a pprof profile gzip file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a1371c069157738d08a42f8452b9b9196d90ec61" translate="yes" xml:space="preserve">
          <source>Generate a single randomly distorted bounding box for an image.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac024cfebf615ec9550fa9639992f999e3b2ee72" translate="yes" xml:space="preserve">
          <source>Generate a single randomly distorted bounding box for an image. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a513f309f426925500e16fda01716dda1ec01c9d" translate="yes" xml:space="preserve">
          <source>Generate a timeline json file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4b61b9eadd182e79e8d7ca8f5436072061f5cd0" translate="yes" xml:space="preserve">
          <source>Generate batches of tensor image data with real-time data augmentation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e985d2b987cc5cfe48af402ebd8ddad192ec795" translate="yes" xml:space="preserve">
          <source>Generate bounding box proposals from encoded bounding boxes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0ad06dc54e9b19d8f565750f7f75ca4b2cfa07b" translate="yes" xml:space="preserve">
          <source>Generate class predictions for the input samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7093df80f13988f753b4ffb41362fefaef5f111" translate="yes" xml:space="preserve">
          <source>Generate samples of the specified shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e9203d473bfc408cbd4f794fe904486104787f9" translate="yes" xml:space="preserve">
          <source>Generate the set of all classes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="377bb61844f7989feb179e9255bc056adafe1698" translate="yes" xml:space="preserve">
          <source>Generates a &lt;code&gt;SaverDef&lt;/code&gt; representation of this saver.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45ca970a93e98f0a96c6dd41425b7de72d75abbf" translate="yes" xml:space="preserve">
          <source>Generates a checkpoint state proto.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="825f6429255ba775713386b0d2f3a17166359e07" translate="yes" xml:space="preserve">
          <source>Generates a window function that can be used in &lt;code&gt;inverse_stft&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47b0fd38944f765d01ecdf4f5dde5c9129216b79" translate="yes" xml:space="preserve">
          <source>Generates a word rank-based probabilistic sampling table.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1eaf3ef20aca17d2ddd855b709da877935b5c644" translate="yes" xml:space="preserve">
          <source>Generates class probability predictions for the input samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2e65b80cc8c5def122f20b61b5d83b821ccc7ce" translate="yes" xml:space="preserve">
          <source>Generates fingerprint values of &lt;code&gt;data&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e89a59f26ad8f607008d022c7aae25b086f3ec9e" translate="yes" xml:space="preserve">
          <source>Generates fingerprint values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ecd2cd43082dd2fa1d698670c924b8a9339f3115" translate="yes" xml:space="preserve">
          <source>Generates hashed sparse cross from a list of sparse and dense tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d830604723f094db9bc24fb88a7e02736a2c3056" translate="yes" xml:space="preserve">
          <source>Generates output predictions for the input samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b249d65bf0f914d4110d91f913e1300c01aa2889" translate="yes" xml:space="preserve">
          <source>Generates parsing spec for tf.parse_example to be used with classifiers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1aae58a59256b1fc205171c419f649a6e0c1ac2c" translate="yes" xml:space="preserve">
          <source>Generates parsing spec for tf.parse_example to be used with regressors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2df3b2c3bfd14ecb54ef8d497e84f89bbccb46c" translate="yes" xml:space="preserve">
          <source>Generates predictions for the input samples from a data generator. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0b782326dc1552a60227a419a223dd58df3f275" translate="yes" xml:space="preserve">
          <source>Generates random parameters for a transformation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29c08e7ff9dc1d9fd5830b7df9e2c9f201d13165" translate="yes" xml:space="preserve">
          <source>Generates seeds for stateless random ops.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="929055b21af18b1410a5ef9e6f627e2fe967eded" translate="yes" xml:space="preserve">
          <source>Generates skipgram word pairs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c717f055df49ec5bd1aa8121ba707a81fd38bcab" translate="yes" xml:space="preserve">
          <source>Generates sparse cross from a list of sparse and dense tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eee7e06216ccc809aac0d41b4d65812d7279baab" translate="yes" xml:space="preserve">
          <source>Generates the RaggedTensor &lt;code&gt;row_splits&lt;/code&gt; corresponding to a segmentation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c8ebc23fb3d11a9fa1612cc64fdaa5515b59f5b" translate="yes" xml:space="preserve">
          <source>Generates the segmentation corresponding to a RaggedTensor &lt;code&gt;row_splits&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="847054fadb60634ee2f52424f471fb76a80ae831" translate="yes" xml:space="preserve">
          <source>Generates values in an interval.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd2f789a1badf7c47aa6e96fdc59fb1ae83e7fe2" translate="yes" xml:space="preserve">
          <source>Generic entry point script.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d7e04da7f8fb8474d86e3fc36734ea9ac641c99" translate="yes" xml:space="preserve">
          <source>Get a direct path to the data files colocated with the script.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25e90702cc2a6266a80ebe5d73070c2394a2d997" translate="yes" xml:space="preserve">
          <source>Get a partitioner for VariableScope to keep shards below &lt;code&gt;max_shard_bytes&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="59040295d5cb452ad25fbe2e72127aba826b97ef" translate="yes" xml:space="preserve">
          <source>Get a root directory containing all the data attributes in the build rule.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb88a5384f5bc20bdadfdbaa3c133110e4b6085f" translate="yes" xml:space="preserve">
          <source>Get experimental optimizer options.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2113882a890fee2c46d1a70f2c5138bd06f0eb7" translate="yes" xml:space="preserve">
          <source>Get from cache or create a default operation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b670781c96420a037469ad0934765b418deb4d2f" translate="yes" xml:space="preserve">
          <source>Get if JIT compilation is enabled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69a0067636164f576df746229abb6b9aaceb5ae6" translate="yes" xml:space="preserve">
          <source>Get if device placements are logged.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="498721b0192fabfcd02ce495785bf7613c9f7cee" translate="yes" xml:space="preserve">
          <source>Get if memory growth is enabled for a &lt;code&gt;PhysicalDevice&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58ef7dbc31c00f8af4807e08acd0430c855e1d84" translate="yes" xml:space="preserve">
          <source>Get if soft device placement is enabled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9c7c6ec42a6b32f83fcca563a931ba4fbe0ed3b" translate="yes" xml:space="preserve">
          <source>Get number of threads used for parallelism between independent operations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80b95985b48aaafa3e792986341c8b4ff88eead6" translate="yes" xml:space="preserve">
          <source>Get number of threads used within an individual op for parallelism.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6fc794e6fd1f995204b4b699515f189ad3b79ac8" translate="yes" xml:space="preserve">
          <source>Get the &lt;code&gt;TensorShape&lt;/code&gt; representing the shape of the dense tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53ea60d80b4295960ae12cbdab1a207aed855693" translate="yes" xml:space="preserve">
          <source>Get the KL-divergence KL(distribution_a || distribution_b). (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0bf696fef5a21374d09e8355388763caa023a426" translate="yes" xml:space="preserve">
          <source>Get the Master string to be used for the session.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="108dacf621a6cd835ace3ba57aa80d2b5e19236d" translate="yes" xml:space="preserve">
          <source>Get the compilation flags for custom operators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ae51f237cd7e7c81a09e6f89ce59cb258772427" translate="yes" xml:space="preserve">
          <source>Get the directory containing the TensorFlow C++ header files.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="359b660afd7e217497634736e8bd4bb55153be9c" translate="yes" xml:space="preserve">
          <source>Get the directory containing the TensorFlow framework library.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="650bdecea08ce6ef81b38eabb82f7de00f8d7991" translate="yes" xml:space="preserve">
          <source>Get the global step tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc3b1d0c5d3365a3eaff90c6cf36385cdaa1ba29" translate="yes" xml:space="preserve">
          <source>Get the link flags for custom operators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5b8a3ccddd79a33c1a86a133a701f8165f54b2b" translate="yes" xml:space="preserve">
          <source>Get the list of visible physical devices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="921a66e34ee4a58c84a0efa213945cee146717d6" translate="yes" xml:space="preserve">
          <source>Get the path to the specified file in the data dependencies.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c31cddaa67a87523e9d1624fa98876319984d178" translate="yes" xml:space="preserve">
          <source>Get the tensor of type &lt;code&gt;dtype&lt;/code&gt; by feeding a tensor handle.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3cd44016bc9caf57517296a543e5f07cc70b58f" translate="yes" xml:space="preserve">
          <source>Get the value of the tensor from a tensor handle. The tensor is produced in a previous run() and stored in the state of the session.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35948203feb263f7dc9fb059f6619c9f87908726" translate="yes" xml:space="preserve">
          <source>Get the virtual device configuration for a &lt;a href=&quot;physicaldevice&quot;&gt;&lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0644eda96e6748128f29f7007c63dd9693a38f23" translate="yes" xml:space="preserve">
          <source>Get this scope's global variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="887d65a3c67be69818d4fa832142026519a1083d" translate="yes" xml:space="preserve">
          <source>Get this scope's local variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a308585ffe5c9c1e87f02af3bd65c090f3a450c2" translate="yes" xml:space="preserve">
          <source>Get this scope's trainable variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="057e2633d0656b1fb510dea575a522fc49d9405f" translate="yes" xml:space="preserve">
          <source>Get this scope's variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5795bd8bcbae0c5fe909ec39b6d58c353b7d8911" translate="yes" xml:space="preserve">
          <source>Get unique labels and indices for batched labels for &lt;a href=&quot;ctc_loss&quot;&gt;&lt;code&gt;tf.nn.ctc_loss&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5f58f3a07d14b9e0032e44d6a23fe568ceffa8e" translate="yes" xml:space="preserve">
          <source>Gets a numpy-style shape tuple giving the dataset dimensions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16edd56dc8f500661a54f70ff8aa5d3642a74f3d" translate="yes" xml:space="preserve">
          <source>Gets an existing &lt;em&gt;local&lt;/em&gt; variable or creates a new one.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8363344ba8552991690effa2b825a04c73499304" translate="yes" xml:space="preserve">
          <source>Gets an existing variable with these parameters or create a new one.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c705ed15a7fab0aed052398593737c16839589c3" translate="yes" xml:space="preserve">
          <source>Gets an existing variable with this name or create a new one.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6eb4b621d4c64dca0de29b3b8a401e1cd6303ba" translate="yes" xml:space="preserve">
          <source>Gets batch at position &lt;code&gt;index&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9241f5d7bcc0a690cd669562fcda23fde5204e95" translate="yes" xml:space="preserve">
          <source>Gets model input details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cb340e682cc8a13364fea269654750b9f7ffa8f" translate="yes" xml:space="preserve">
          <source>Gets model output details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1176b88ed9f974924ce3c2aed58b5efc5abf028f" translate="yes" xml:space="preserve">
          <source>Gets parameters for this estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf1b6d34570c76b9b641b4a8fdf7b56eacc074a4" translate="yes" xml:space="preserve">
          <source>Gets tensor details for every tensor with valid tensor details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f6f5f2772b01d65cdb20576211da5d66d43f685" translate="yes" xml:space="preserve">
          <source>Gets the &lt;a href=&quot;tensorshape&quot;&gt;&lt;code&gt;tf.TensorShape&lt;/code&gt;&lt;/a&gt; representing the shape of the dense tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0911c623c2e60904843307f59585e7a371b0bc73" translate="yes" xml:space="preserve">
          <source>Gets the current device policy.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84ad69761c8ff8c302a3208721f28483a943e063" translate="yes" xml:space="preserve">
          <source>Gets the datatype of the dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0ad71d1c926ecf4a236b3b9ed68592ba6894254" translate="yes" xml:space="preserve">
          <source>Gets the list of losses from the loss_collection.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d33e19f642cb6ca8f7cdb89e56c9383004a73014" translate="yes" xml:space="preserve">
          <source>Gets the list of regularization losses.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="994bf13750cf00f44f9b6b4c9dfb6f0028020c70" translate="yes" xml:space="preserve">
          <source>Gets the number of dimensions (rank) of the dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f23647c68125a7ba22ae0e3518d064d1d05de6f2" translate="yes" xml:space="preserve">
          <source>Gets the total dataset size (number of elements).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e0adaeaa293d7d6a42173107240437868052b8a" translate="yes" xml:space="preserve">
          <source>Gets the total regularization loss.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73109b21436d1124b271c6807ebab80e82f19d20" translate="yes" xml:space="preserve">
          <source>Gets the value of the input tensor (get a copy).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0a97ae528a9e344d85b2bc74d446d4af8965e0a" translate="yes" xml:space="preserve">
          <source>Gets whether operations are executed synchronously or asynchronously.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d3e28aa7a51ffcbb882909d4507c0ef3ff3db70" translate="yes" xml:space="preserve">
          <source>Given &lt;code&gt;A&lt;/code&gt; representing this &lt;code&gt;LinearOperator&lt;/code&gt;, if &lt;code&gt;A&lt;/code&gt; is positive definite self-adjoint, return &lt;code&gt;L&lt;/code&gt;, where &lt;code&gt;A = L L^T&lt;/code&gt;, i.e. the cholesky decomposition.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3011b88138f555206a8d8637777584fc499f20df" translate="yes" xml:space="preserve">
          <source>Given &lt;code&gt;A&lt;/code&gt; representing this &lt;code&gt;LinearOperator&lt;/code&gt;, return &lt;code&gt;A*&lt;/code&gt;. Note that calling &lt;code&gt;self.adjoint()&lt;/code&gt; and &lt;code&gt;self.H&lt;/code&gt; are equivalent.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7004a0f51e6bcd7306d7fdb592b0811cb1a57ee7" translate="yes" xml:space="preserve">
          <source>Given &lt;code&gt;A&lt;/code&gt; representing this &lt;code&gt;LinearOperator&lt;/code&gt;, return a &lt;code&gt;LinearOperator&lt;/code&gt; representing &lt;code&gt;A^-1&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d4eddf991c1d74f9a5d1d05bd85b438f60be0df" translate="yes" xml:space="preserve">
          <source>Given &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;diagonal&lt;/code&gt;, this operation returns a tensor with the same shape and values as &lt;code&gt;input&lt;/code&gt;, except for the specified diagonals of the innermost matrices. These will be overwritten by the values in &lt;code&gt;diagonal&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4667868493e23c5d3be9c3d6e074ce011a1f942" translate="yes" xml:space="preserve">
          <source>Given &lt;code&gt;tensor&lt;/code&gt;, this operation returns a new &lt;a href=&quot;tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; that has the same values as &lt;code&gt;tensor&lt;/code&gt; in the same order, except with a new shape given by &lt;code&gt;shape&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="270b80b5a40e2baf3fc36e77aed5580f95129897" translate="yes" xml:space="preserve">
          <source>Given &lt;code&gt;x&lt;/code&gt;, compute the inverse error function of &lt;code&gt;x&lt;/code&gt;. This function is the inverse of &lt;a href=&quot;erf&quot;&gt;&lt;code&gt;tf.math.erf&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9bd6c98f31a6efc0f5ca49049729b234a4e076d8" translate="yes" xml:space="preserve">
          <source>Given N one-dimensional coordinate arrays &lt;code&gt;*args&lt;/code&gt;, returns a list &lt;code&gt;outputs&lt;/code&gt; of N-D coordinate arrays for evaluating expressions on an N-D grid.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3b95972a12a7881c9c9398cac9152e479d5c1ef" translate="yes" xml:space="preserve">
          <source>Given a 4D input tensor ('NHWC' or 'NCHW' data formats) and a filter tensor of shape &lt;code&gt;[filter_height, filter_width, in_channels, channel_multiplier]&lt;/code&gt; containing &lt;code&gt;in_channels&lt;/code&gt; convolutional filters of depth 1, &lt;code&gt;depthwise_conv2d&lt;/code&gt; applies a different filter to each input channel (expanding from 1 channel to &lt;code&gt;channel_multiplier&lt;/code&gt; channels for each), then concatenates the results together. The output has &lt;code&gt;in_channels * channel_multiplier&lt;/code&gt; channels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="094ea9bf18f0c36eba450800d4c1f7a06e4be90d" translate="yes" xml:space="preserve">
          <source>Given a &lt;code&gt;diagonal&lt;/code&gt;, this operation returns a tensor with the &lt;code&gt;diagonal&lt;/code&gt; and everything else padded with zeros. The diagonal is computed as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6147dea94829076776f7d46f24eec459f66088a0" translate="yes" xml:space="preserve">
          <source>Given a &lt;code&gt;tensor&lt;/code&gt;, and a &lt;code&gt;int32&lt;/code&gt; tensor &lt;code&gt;axis&lt;/code&gt; representing the set of dimensions of &lt;code&gt;tensor&lt;/code&gt; to reverse. This operation reverses each dimension &lt;code&gt;i&lt;/code&gt; for which there exists &lt;code&gt;j&lt;/code&gt; s.t. &lt;code&gt;axis[j] == i&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e040c53a91fa31be95603ab52d19f7c9b3eda7f" translate="yes" xml:space="preserve">
          <source>Given a Python slice &lt;code&gt;input[spec0, spec1, ..., specn]&lt;/code&gt;, this function will be called as follows.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8cc9f63fb42e045b295452edd4ecb68aa07a8d87" translate="yes" xml:space="preserve">
          <source>Given a TensorSummary node_def, retrieve its SummaryDescription.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9dd17d0fb7fb4fa3b12e4e69ca28248800ac81b7" translate="yes" xml:space="preserve">
          <source>Given a list &lt;code&gt;x&lt;/code&gt; and a list &lt;code&gt;y&lt;/code&gt;, this operation returns a list &lt;code&gt;out&lt;/code&gt; that represents all values that are in &lt;code&gt;x&lt;/code&gt; but not in &lt;code&gt;y&lt;/code&gt;. The returned list &lt;code&gt;out&lt;/code&gt; is sorted in the same order that the numbers appear in &lt;code&gt;x&lt;/code&gt; (duplicates are preserved). This operation also returns a list &lt;code&gt;idx&lt;/code&gt; that represents the position of each &lt;code&gt;out&lt;/code&gt; element in &lt;code&gt;x&lt;/code&gt;. In other words:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f469b77293ed1ff9f0eb63bb9dae24362157619" translate="yes" xml:space="preserve">
          <source>Given a list of tensors or ragged tensors with the same rank &lt;code&gt;R&lt;/code&gt; (&lt;code&gt;R &amp;gt;= axis&lt;/code&gt;), returns a rank-&lt;code&gt;R+1&lt;/code&gt;&lt;code&gt;RaggedTensor&lt;/code&gt;&lt;code&gt;result&lt;/code&gt; such that &lt;code&gt;result[i0...iaxis]&lt;/code&gt; is &lt;code&gt;[value[i0...iaxis] for value in values]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68c5f2c079927408ee33cb3fc0df6461ed870433" translate="yes" xml:space="preserve">
          <source>Given a per-replica value returned by &lt;code&gt;experimental_run_v2&lt;/code&gt;, say a per-example loss, the batch will be divided across all the replicas. This function allows you to aggregate across replicas and optionally also across batch elements. For example, if you have a global batch size of 8 and 2 replicas, values for examples &lt;code&gt;[0, 1, 2, 3]&lt;/code&gt; will be on replica 0 and &lt;code&gt;[4, 5, 6, 7]&lt;/code&gt; will be on replica 1. By default, &lt;code&gt;reduce&lt;/code&gt; will just aggregate across replicas, returning &lt;code&gt;[0+4, 1+5, 2+6, 3+7]&lt;/code&gt;. This is useful when each replica is computing a scalar or some other value that doesn't have a &quot;batch&quot; dimension (like a gradient). More often you will want to aggregate across the global batch, which you can get by specifying the batch dimension as the &lt;code&gt;axis&lt;/code&gt;, typically &lt;code&gt;axis=0&lt;/code&gt;. In this case it would return a scalar &lt;code&gt;0+1+2+3+4+5+6+7&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d356be63c806d4a57d873a70be815c506a549419" translate="yes" xml:space="preserve">
          <source>Given a python function &lt;code&gt;func&lt;/code&gt; wrap this function as an operation in a TensorFlow function. &lt;code&gt;func&lt;/code&gt; must take numpy arrays as its arguments and return numpy arrays as its outputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a5b52f136266fe244292b77181eab18685d5599" translate="yes" xml:space="preserve">
          <source>Given a python function &lt;code&gt;func&lt;/code&gt;, which takes numpy arrays as its arguments and returns numpy arrays as its outputs, wrap this function as an operation in a TensorFlow graph. The following snippet constructs a simple TensorFlow graph that invokes the &lt;code&gt;np.sinh()&lt;/code&gt; NumPy function as a operation in the graph:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3da234c855426da94c463431671a4c43997129c" translate="yes" xml:space="preserve">
          <source>Given a single tensor (&lt;code&gt;tensor&lt;/code&gt;), this operation returns a tensor of the same type and shape as &lt;code&gt;tensor&lt;/code&gt; with all elements set to 1. Optionally, you can specify a new type (&lt;code&gt;dtype&lt;/code&gt;) for the returned tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cef540646f64962527a87cdc8b09906dde5432ac" translate="yes" xml:space="preserve">
          <source>Given a single tensor (&lt;code&gt;tensor&lt;/code&gt;), this operation returns a tensor of the same type and shape as &lt;code&gt;tensor&lt;/code&gt; with all elements set to 1. Optionally, you can use &lt;code&gt;dtype&lt;/code&gt; to specify a new type for the returned tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f197c0d34900084408842c4f3cb206307ffb52c6" translate="yes" xml:space="preserve">
          <source>Given a single tensor (&lt;code&gt;tensor&lt;/code&gt;), this operation returns a tensor of the same type and shape as &lt;code&gt;tensor&lt;/code&gt; with all elements set to zero. Optionally, you can use &lt;code&gt;dtype&lt;/code&gt; to specify a new type for the returned tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10b69b4dd5bbe2b5280497f7bc6c2252eeb11d35" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;input&lt;/code&gt; of complex numbers, this operation returns a tensor of complex numbers that are the complex conjugate of each element in &lt;code&gt;input&lt;/code&gt;. The complex numbers in &lt;code&gt;input&lt;/code&gt; must be of the form \(a + bj\), where &lt;em&gt;a&lt;/em&gt; is the real part and &lt;em&gt;b&lt;/em&gt; is the imaginary part.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="806e510667c18a0441a9ae34cf672593b9c2613d" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;input&lt;/code&gt;, this operation inserts a dimension of 1 at the dimension index &lt;code&gt;axis&lt;/code&gt; of &lt;code&gt;input&lt;/code&gt;'s shape. The dimension index &lt;code&gt;axis&lt;/code&gt; starts at zero; if you specify a negative number for &lt;code&gt;axis&lt;/code&gt; it is counted backward from the end.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c286503b096f71983bf3319ebce75fc3df581ded" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;input&lt;/code&gt;, this operation inserts a dimension of size 1 at the dimension index &lt;code&gt;axis&lt;/code&gt; of &lt;code&gt;input&lt;/code&gt;'s shape. The dimension index &lt;code&gt;axis&lt;/code&gt; starts at zero; if you specify a negative number for &lt;code&gt;axis&lt;/code&gt; it is counted backward from the end.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a1fb94877fc4770061be1a2b9c38bdc7f0532ee" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;input&lt;/code&gt;, this operation returns a tensor of the same type with all dimensions of size 1 removed. If you don't want to remove all size 1 dimensions, you can remove specific size 1 dimensions by specifying &lt;code&gt;axis&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbca199d5d5cd792b1dd02ead4c9b8f3ef441f45" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;input&lt;/code&gt;, this operation returns a tensor of type &lt;code&gt;float&lt;/code&gt; that is the argument of each element in &lt;code&gt;input&lt;/code&gt; considered as a complex number.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3c9874b7bb8857da64e590211bda623bc98b5d1" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;input&lt;/code&gt;, this operation returns a tensor of type &lt;code&gt;float&lt;/code&gt; that is the imaginary part of each element in &lt;code&gt;input&lt;/code&gt; considered as a complex number. If &lt;code&gt;input&lt;/code&gt; is real, a tensor of all zeros is returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="becaf7789b114f2fb84f8a1c908f9499f6b0068e" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;input&lt;/code&gt;, this operation returns a tensor of type &lt;code&gt;float&lt;/code&gt; that is the real part of each element in &lt;code&gt;input&lt;/code&gt; considered as a complex number.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4adc764f5b83b917078bf968adc81577aa08658" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;input&lt;/code&gt;, this operation returns a tensor that has the same buffer data as &lt;code&gt;input&lt;/code&gt; with datatype &lt;code&gt;type&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b01a7ab9f6ce08221630a8a12ac493ef6aa5e0f2" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;real&lt;/code&gt; representing the real part of a complex number, and a tensor &lt;code&gt;imag&lt;/code&gt; representing the imaginary part of a complex number, this operation returns complex numbers elementwise of the form \(a + bj\), where &lt;em&gt;a&lt;/em&gt; represents the &lt;code&gt;real&lt;/code&gt; part and &lt;em&gt;b&lt;/em&gt; represents the &lt;code&gt;imag&lt;/code&gt; part.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4cde684e0bf3170cd69db48357176ad6f8be05bf" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;sp_input&lt;/code&gt;, this operation inserts a dimension of 1 at the dimension index &lt;code&gt;axis&lt;/code&gt; of &lt;code&gt;sp_input&lt;/code&gt;'s shape. The dimension index &lt;code&gt;axis&lt;/code&gt; starts at zero; if you specify a negative number for &lt;code&gt;axis&lt;/code&gt; it is counted backwards from the end.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7e431d8c1e8a94cc9f6ddda87a3198f535026e6" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;t&lt;/code&gt;, and a maximum clip value &lt;code&gt;clip_norm&lt;/code&gt;, this operation normalizes &lt;code&gt;t&lt;/code&gt; so that its L2-norm is less than or equal to &lt;code&gt;clip_norm&lt;/code&gt;, along the dimensions given in &lt;code&gt;axes&lt;/code&gt;. Specifically, in the default case where all dimensions are used for calculation, if the L2-norm of &lt;code&gt;t&lt;/code&gt; is already less than or equal to &lt;code&gt;clip_norm&lt;/code&gt;, then &lt;code&gt;t&lt;/code&gt; is not modified. If the L2-norm is greater than &lt;code&gt;clip_norm&lt;/code&gt;, then this operation returns a tensor of the same type and shape as &lt;code&gt;t&lt;/code&gt; with its values set to:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fb66188586afb5dfa9ed28d0d11ecbbd9aa6324" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;t&lt;/code&gt;, and a maximum clip value &lt;code&gt;clip_norm&lt;/code&gt;, this operation normalizes &lt;code&gt;t&lt;/code&gt; so that its average L2-norm is less than or equal to &lt;code&gt;clip_norm&lt;/code&gt;. Specifically, if the average L2-norm is already less than or equal to &lt;code&gt;clip_norm&lt;/code&gt;, then &lt;code&gt;t&lt;/code&gt; is not modified. If the average L2-norm is greater than &lt;code&gt;clip_norm&lt;/code&gt;, then this operation returns a tensor of the same type and shape as &lt;code&gt;t&lt;/code&gt; with its values set to:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7007bafda729e071b7b16ae3d3a78dcbb3100276" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;t&lt;/code&gt;, this operation returns a tensor of the same type and shape as &lt;code&gt;t&lt;/code&gt; with its values clipped to &lt;code&gt;clip_value_min&lt;/code&gt; and &lt;code&gt;clip_value_max&lt;/code&gt;. Any values less than &lt;code&gt;clip_value_min&lt;/code&gt; are set to &lt;code&gt;clip_value_min&lt;/code&gt;. Any values greater than &lt;code&gt;clip_value_max&lt;/code&gt; are set to &lt;code&gt;clip_value_max&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d793504d9a2641fdc838d8a324aa0f0d9bef081" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;x&lt;/code&gt; and a tensor &lt;code&gt;y&lt;/code&gt;, this operation computes \(x^y\) for corresponding elements in &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d97acda758edb9bf66a685f144f3b117ce1c753" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;x&lt;/code&gt; of complex numbers, this operation returns a tensor of type &lt;code&gt;float32&lt;/code&gt; or &lt;code&gt;float64&lt;/code&gt; that is the absolute value of each element in &lt;code&gt;x&lt;/code&gt;. All elements in &lt;code&gt;x&lt;/code&gt; must be complex numbers of the form \(a + bj\). The absolute value is computed as \( \sqrt{a^2 + b^2}\). For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd81862ba7b8de323d4dc65742b6a0e0fc609451" translate="yes" xml:space="preserve">
          <source>Given a tensor of integer or floating-point values, this operation returns a tensor of the same type, where each element contains the absolute value of the corresponding element in the input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="322b12c73859d8a9e4e7944b435ecab925a5124e" translate="yes" xml:space="preserve">
          <source>Given a tuple or list of tensors &lt;code&gt;t_list&lt;/code&gt;, and a clipping ratio &lt;code&gt;clip_norm&lt;/code&gt;, this operation returns a list of clipped tensors &lt;code&gt;list_clipped&lt;/code&gt; and the global norm (&lt;code&gt;global_norm&lt;/code&gt;) of all tensors in &lt;code&gt;t_list&lt;/code&gt;. Optionally, if you've already computed the global norm for &lt;code&gt;t_list&lt;/code&gt;, you can specify the global norm with &lt;code&gt;use_norm&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb5b0e16debf84a9c22080f3acaefe368e00fdb9" translate="yes" xml:space="preserve">
          <source>Given a tuple or list of tensors &lt;code&gt;t_list&lt;/code&gt;, this operation returns the global norm of the elements in all tensors in &lt;code&gt;t_list&lt;/code&gt;. The global norm is computed as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73d8bb2fac3b21f66c499488e5209e33bb02392c" translate="yes" xml:space="preserve">
          <source>Given an &lt;code&gt;IndexedSlices&lt;/code&gt; instance &lt;code&gt;a&lt;/code&gt;, returns another &lt;code&gt;IndexedSlices&lt;/code&gt; that contains a subset of the slices of &lt;code&gt;a&lt;/code&gt;. Only the slices at indices not specified in &lt;code&gt;mask_indices&lt;/code&gt; are returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6eb4a575261e442800cb08021cae257d7dca9d5e" translate="yes" xml:space="preserve">
          <source>Given an arbitrary function, wrap it so that it does variable sharing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="18296fc4ebda93cac42fe65939317a047745ed5f" translate="yes" xml:space="preserve">
          <source>Given an input tensor of shape &lt;code&gt;[batch, in_height, in_width, in_channels]&lt;/code&gt; and a filter / kernel tensor of shape &lt;code&gt;[filter_height, filter_width, in_channels, channel_multiplier]&lt;/code&gt;, containing &lt;code&gt;in_channels&lt;/code&gt; convolutional filters of depth 1, &lt;code&gt;depthwise_conv2d&lt;/code&gt; applies a different filter to each input channel (expanding from 1 channel to &lt;code&gt;channel_multiplier&lt;/code&gt; channels for each), then concatenates the results together. Thus, the output has &lt;code&gt;in_channels * channel_multiplier&lt;/code&gt; channels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e370c68e5555d480a5c4df80fb0a1826a44057c" translate="yes" xml:space="preserve">
          <source>Given an input tensor of shape &lt;code&gt;[batch, in_height, in_width, in_channels]&lt;/code&gt; and a filter / kernel tensor of shape &lt;code&gt;[filter_height, filter_width, in_channels, out_channels]&lt;/code&gt;, this op performs the following:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1c915a4b13f35d33a94d06e3847c2365262d62c" translate="yes" xml:space="preserve">
          <source>Given an input tensor of shape [batch, in_width, in_channels] if data_format is &quot;NWC&quot;, or [batch, in_channels, in_width] if data_format is &quot;NCW&quot;, and a filter / kernel tensor of shape [filter_width, in_channels, out_channels], this op reshapes the arguments to pass them to conv2d to perform the equivalent convolution operation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2eb289cc3c5755f35510bd201bb3c7ba0da0f131" translate="yes" xml:space="preserve">
          <source>Given an input tensor, the function computes inverse hyperbolic cosine of every element. Input range is &lt;code&gt;[1, inf]&lt;/code&gt;. It returns &lt;code&gt;nan&lt;/code&gt; if the input lies outside the range.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2276090897040e0aeeaafa324236781f22316e6" translate="yes" xml:space="preserve">
          <source>Given an input tensor, this function computes cosine of every element in the tensor. Input range is &lt;code&gt;(-inf, inf)&lt;/code&gt; and output range is &lt;code&gt;[-1,1]&lt;/code&gt;. If input lies outside the boundary, &lt;code&gt;nan&lt;/code&gt; is returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d70ae953868ca523f92404dffa44551095f71ef" translate="yes" xml:space="preserve">
          <source>Given an input tensor, this function computes hyperbolic cosine of every element in the tensor. Input range is &lt;code&gt;[-inf, inf]&lt;/code&gt; and output range is &lt;code&gt;[1, inf]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b488ce799eb3a33791cfbd59693b393988e595b" translate="yes" xml:space="preserve">
          <source>Given an input tensor, this function computes hyperbolic sine of every element in the tensor. Input range is &lt;code&gt;[-inf,inf]&lt;/code&gt; and output range is &lt;code&gt;[-inf,inf]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="59df85e0619df189d8729fee687f600a54d01480" translate="yes" xml:space="preserve">
          <source>Given an input tensor, this function computes hyperbolic tangent of every element in the tensor. Input range is &lt;code&gt;[-inf, inf]&lt;/code&gt; and output range is &lt;code&gt;[-1,1]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c73b448fa482aa6531301716ace98c25a05fd5d3" translate="yes" xml:space="preserve">
          <source>Given an input tensor, this function computes inverse hyperbolic sine for every element in the tensor. Both input and output has a range of &lt;code&gt;[-inf, inf]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c25eb5c30ec69042f14f0a07e82e62d1882abacc" translate="yes" xml:space="preserve">
          <source>Given an input tensor, this function computes inverse hyperbolic tangent for every element in the tensor. Input range is &lt;code&gt;[-1,1]&lt;/code&gt; and output range is &lt;code&gt;[-inf, inf]&lt;/code&gt;. If input is &lt;code&gt;-1&lt;/code&gt;, output will be &lt;code&gt;-inf&lt;/code&gt; and if the input is &lt;code&gt;1&lt;/code&gt;, output will be &lt;code&gt;inf&lt;/code&gt;. Values outside the range will have &lt;code&gt;nan&lt;/code&gt; as output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea097a1f54202798e40231d72b57eb14a2329e8c" translate="yes" xml:space="preserve">
          <source>Given an input tensor, this function computes sine of every element in the tensor. Input range is &lt;code&gt;(-inf, inf)&lt;/code&gt; and output range is &lt;code&gt;[-1,1]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d62f8cf300097a0e2129f20828fbd0e2b4cd35f3" translate="yes" xml:space="preserve">
          <source>Given an input tensor, this function computes tangent of every element in the tensor. Input range is &lt;code&gt;(-inf, inf)&lt;/code&gt; and output range is &lt;code&gt;(-inf, inf)&lt;/code&gt;. If input lies outside the boundary, &lt;code&gt;nan&lt;/code&gt; is returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08d07ac5e8ef80d326d4f12521ff24313fbce652" translate="yes" xml:space="preserve">
          <source>Given one-dimensional &lt;code&gt;z = [z_0,...,z_{K-1}]&lt;/code&gt;, we define</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48fec20fa93f6484a4d59eef4d5240def79def02" translate="yes" xml:space="preserve">
          <source>Given operation-specific seed, &lt;code&gt;op_seed&lt;/code&gt;, this helper function returns two seeds derived from graph-level and op-level seeds. Many random operations internally use the two seeds to allow user to change the seed globally for a graph, or for only specific operations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c4cfb563b251c993c875f25d14c9e568e980107" translate="yes" xml:space="preserve">
          <source>Given random variable &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;p in [0, 1]&lt;/code&gt;, the &lt;code&gt;quantile&lt;/code&gt; is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11ff9e9f8b087477a5e4158b4134eac9b64e6878" translate="yes" xml:space="preserve">
          <source>Given random variable &lt;code&gt;X&lt;/code&gt;, the cumulative distribution function &lt;code&gt;cdf&lt;/code&gt; is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa3f3691f019bbd881a265ec5bccfb1211e3ad29" translate="yes" xml:space="preserve">
          <source>Given random variable &lt;code&gt;X&lt;/code&gt;, the survival function is defined:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55eaa8e915c7da17162d07889c59a5355bf928ae" translate="yes" xml:space="preserve">
          <source>Given that some ops may be partially supported, the optimal way to determine if a model's operations are supported is by converting using the TensorFlow Lite converter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0153812f9d215780555e110de846d070c2d1cb32" translate="yes" xml:space="preserve">
          <source>Given the tensor &lt;code&gt;values&lt;/code&gt;, this operation returns a rank 1 &lt;code&gt;Tensor&lt;/code&gt; representing the indices of a histogram into which each element of &lt;code&gt;values&lt;/code&gt; would be binned. The bins are equal width and determined by the arguments &lt;code&gt;value_range&lt;/code&gt; and &lt;code&gt;nbins&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13c5e2fbdbba7fa42de391b57a0a7d1e5d7df7f6" translate="yes" xml:space="preserve">
          <source>Given the tensor &lt;code&gt;values&lt;/code&gt;, this operation returns a rank 1 histogram counting the number of entries in &lt;code&gt;values&lt;/code&gt; that fell into every bin. The bins are equal width and determined by the arguments &lt;code&gt;value_range&lt;/code&gt; and &lt;code&gt;nbins&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54fcfc2408cd2e19b0afb43ec166a6b0b45677c6" translate="yes" xml:space="preserve">
          <source>Given two &lt;code&gt;Example&lt;/code&gt; input protos in &lt;code&gt;serialized&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a71b5320e03ef99e09301587e5062ffa0d505637" translate="yes" xml:space="preserve">
          <source>Gives a guarantee to the TF runtime that the input tensor is a constant.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="802a77a26d08463b8d182d4841500cc36b1bdeb1" translate="yes" xml:space="preserve">
          <source>Gives the log-likelihood loss between the prediction and the target under the assumption that the target has a Poisson distribution. Caveat: By default, this is not the exact loss, but the loss minus a constant term [log(z!)]. That has no effect for optimization, but does not play well with relative loss comparisons. To compute an approximation of the log factorial term, specify compute_full_loss=True to enable Stirling's Approximation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b375b50d76db2f1ab6e919b12e87eb3c07c7837" translate="yes" xml:space="preserve">
          <source>Global Average pooling operation for 3D data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="490733d038a485e20b685885b26cd8e1c21ac8a1" translate="yes" xml:space="preserve">
          <source>Global Max pooling operation for 3D data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c372dfcc5aacad73c8ba932360de7dad2d1ce972" translate="yes" xml:space="preserve">
          <source>Global average pooling operation for spatial data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc8c9db4015232abf19ef2f9a55435d1ea95b1de" translate="yes" xml:space="preserve">
          <source>Global average pooling operation for temporal data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="167efa62c3642366c4057325e9b1f061b9517117" translate="yes" xml:space="preserve">
          <source>Global dictionary of names to classes (&lt;code&gt;_GLOBAL_CUSTOM_OBJECTS&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b675d73c44ef2c3b5ff3ee1aee82f62c38a94d3" translate="yes" xml:space="preserve">
          <source>Global id, i.e., this field, is tracking the index of the node among ALL nodes in the cluster. It is uniquely assigned. For example, for the cluster spec given above, the global ids are assigned as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbaffaa9e612328e1415352ab08beb6396bb657c" translate="yes" xml:space="preserve">
          <source>Global max pooling operation for spatial data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0f40685c4fd8079767cd3b5779589f20e7497c4" translate="yes" xml:space="preserve">
          <source>Global max pooling operation for temporal data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d590e8790e10ef3fdf0c5c3d8ed595c657758ce9" translate="yes" xml:space="preserve">
          <source>Global step tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa3649b2772ac1189dcef2f8c64d20be93fd805b" translate="yes" xml:space="preserve">
          <source>Global variables are variables that are shared across machines in a distributed environment. The &lt;code&gt;Variable()&lt;/code&gt; constructor or &lt;code&gt;get_variable()&lt;/code&gt; automatically adds new variables to the graph collection &lt;code&gt;GraphKeys.GLOBAL_VARIABLES&lt;/code&gt;. This convenience function returns the contents of that collection.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e368decdd07f40f158c5a306bc7f03b270de34b" translate="yes" xml:space="preserve">
          <source>Globs for the checkpoints pointed to by &lt;code&gt;checkpoint_paths&lt;/code&gt;. If the files exist, use their mtime as the checkpoint timestamp.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9111e714242062acf83be49c369c220ccfcf860" translate="yes" xml:space="preserve">
          <source>Globs for the checkpoints pointed to by &lt;code&gt;checkpoint_prefixes&lt;/code&gt;. If the files exist, collect their mtime. Both V2 and V1 checkpoints are considered, in that priority.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01cc712ba5777037862cf425ce81901fb067f024" translate="yes" xml:space="preserve">
          <source>Grace period for stopping:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="adb359f1f87c794c325871e029c1af140effe5ec" translate="yes" xml:space="preserve">
          <source>Grace period handling: When &lt;code&gt;request_stop()&lt;/code&gt; is called, threads are given 'stop_grace_period_secs' seconds to terminate. If any of them is still alive after that period expires, a &lt;code&gt;RuntimeError&lt;/code&gt; is raised. Note that if an &lt;code&gt;exc_info&lt;/code&gt; was passed to &lt;code&gt;request_stop()&lt;/code&gt; then it is raised instead of that &lt;code&gt;RuntimeError&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c61a1c122223903dabaecda115cd172b19ae575" translate="yes" xml:space="preserve">
          <source>Gradient Boosted Trees: Model understanding</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="194bbc5ad5da84e49dad69cbb4f32f23b69a3786" translate="yes" xml:space="preserve">
          <source>GradientTapes can be nested to compute higher-order derivatives. For example,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c2ad4a85cafc13c2d1c2d3a2971b83be82a10c3" translate="yes" xml:space="preserve">
          <source>GraphDef containing a simplified version of the original.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88f6daec0a60e7783e784d139db2e8caa801c093" translate="yes" xml:space="preserve">
          <source>Graphically the output tensors are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29346dfd9c70ea134e70f14b812447401491ea5b" translate="yes" xml:space="preserve">
          <source>Graphically this is equivalent to doing</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20a2426b7947c82cb1587611210e101486083cc8" translate="yes" xml:space="preserve">
          <source>Graphs are used by &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s to represent the function's computations. Each graph contains a set of &lt;a href=&quot;operation&quot;&gt;&lt;code&gt;tf.Operation&lt;/code&gt;&lt;/a&gt; objects, which represent units of computation; and &lt;a href=&quot;tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; objects, which represent the units of data that flow between operations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58294451a76b10d6330ff549e0a6d209d1f0896b" translate="yes" xml:space="preserve">
          <source>Greedily selects a subset of bounding boxes in descending order of score.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e75eb9da321613dade49081fbb0f38725be295e1" translate="yes" xml:space="preserve">
          <source>Group objects into a training checkpoint.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6115c228a89d1f90769cafcbd1ad268a88285c91" translate="yes" xml:space="preserve">
          <source>Group tensors together.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e354b4454dd166bc154614760aa397bafa913cb1" translate="yes" xml:space="preserve">
          <source>Groups trackable objects, saving and restoring them.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11ef29d704891a60b088172f8178a63b75138495" translate="yes" xml:space="preserve">
          <source>Hard sigmoid activation function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b62d591ef71e520dcc0fd2d5494b2b952c2c9902" translate="yes" xml:space="preserve">
          <source>Hasim Sak, Andrew Senior, and Francoise Beaufays. &quot;Long short-term memory recurrent neural network architectures for large scale acoustic modeling.&quot; INTERSPEECH, 2014.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4021193208114328b08be8cf728a91eb62ae42b" translate="yes" xml:space="preserve">
          <source>He et al., 2015</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2579614b073edd33dff24698cc0ed7a9d8d9b2ff" translate="yes" xml:space="preserve">
          <source>He normal initializer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c820b6e271aeb8c0992aef844f7e9688ee27c3ff" translate="yes" xml:space="preserve">
          <source>He uniform variance scaling initializer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2a0825f5cf85b0813ba4a932833d3b427e828d7" translate="yes" xml:space="preserve">
          <source>Head sits on top of the model network and handles computing the outputs of the network. Given logits (or output of a hidden layer), a Head knows how to compute predictions, loss, train_op, metrics and export outputs. It is meant to:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="724391cae7df3c6f2f078aa757c3203246f50dfa" translate="yes" xml:space="preserve">
          <source>Helpers to manipulate a tensor graph in python.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9a20ef1cc1f4b45d357341f3d6bf25221e22949" translate="yes" xml:space="preserve">
          <source>Hence, the &lt;code&gt;SparseTensor&lt;/code&gt; result has exactly the same non-zero indices and shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67314232dbebd248ae3b761c240375d141928549" translate="yes" xml:space="preserve">
          <source>Hence, to ensure stability and avoid overflow, the implementation uses this equivalent formulation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15496dff970b77a7dd905044c63378f4105e5937" translate="yes" xml:space="preserve">
          <source>Here is a code example for using &lt;code&gt;AdditiveAttention&lt;/code&gt; in a CNN+Attention network:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af1e9525f99564803e6dc214d93b54de55e718e8" translate="yes" xml:space="preserve">
          <source>Here is a code example for using &lt;code&gt;Attention&lt;/code&gt; in a CNN+Attention network:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2e3cf832e96b3ad2b7cfe3cb8d1e7045a255de6" translate="yes" xml:space="preserve">
          <source>Here is a table of the (roughly) expected first order behavior:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0dcb732b904f60bb8f4fb4132ab1bc7ce4c1dc40" translate="yes" xml:space="preserve">
          <source>Here is an example embedding of two features for a DNNClassifier model:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5a139c16bbbe2e00002f4ebb6bf2d7cf0a12e13" translate="yes" xml:space="preserve">
          <source>Here is an example to create a linear model with crosses of string features:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="464c6369ff2a08fe078373832f4183bb8de964e9" translate="yes" xml:space="preserve">
          <source>Here is an example using &lt;code&gt;embedding_column&lt;/code&gt; with model_fn:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd511335f37b0684a350a25bab28497fe427dcb9" translate="yes" xml:space="preserve">
          <source>Here is an example using &lt;code&gt;shared_embedding_columns&lt;/code&gt; with model_fn:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0362ba3fd11b51dc2dbcaf3363290ca8a7b99e6" translate="yes" xml:space="preserve">
          <source>Here is simplified model_fn to build a DNN regression model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb290e88257943f8b204cd2522934a4d03f0b94a" translate="yes" xml:space="preserve">
          <source>Here the expectation is that the &lt;code&gt;input_fn_*&lt;/code&gt; functions passed to train and evaluate return a pair (dict, label_tensor) where dict has &lt;code&gt;example_id_column&lt;/code&gt; as &lt;code&gt;key&lt;/code&gt; whose value is a &lt;code&gt;Tensor&lt;/code&gt; of shape [batch_size] and dtype string. num_loss_partitions defines sigma' in eq (11) of [3]. Convergence of (global) loss is guaranteed if &lt;code&gt;num_loss_partitions&lt;/code&gt; is larger or equal to the product &lt;code&gt;(#concurrent train ops/per worker) x (#workers)&lt;/code&gt;. Larger values for &lt;code&gt;num_loss_partitions&lt;/code&gt; lead to slower convergence. The recommended value for &lt;code&gt;num_loss_partitions&lt;/code&gt; in &lt;a href=&quot;../../estimator&quot;&gt;&lt;code&gt;tf.estimator&lt;/code&gt;&lt;/a&gt; (where currently there is one process per worker) is the number of workers running the train steps. It defaults to 1 (single machine). &lt;code&gt;num_table_shards&lt;/code&gt; defines the number of shards for the internal state table, typically set to match the number of parameter servers for large data sets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6fd075a1cf6908e13f7823aaaf120524aec476bf" translate="yes" xml:space="preserve">
          <source>Here the partial derivatives &lt;code&gt;g&lt;/code&gt; evaluate to &lt;code&gt;[1.0, 1.0]&lt;/code&gt;, compared to the total derivatives &lt;code&gt;tf.gradients(a + b, [a, b])&lt;/code&gt;, which take into account the influence of &lt;code&gt;a&lt;/code&gt; on &lt;code&gt;b&lt;/code&gt; and evaluate to &lt;code&gt;[3.0, 1.0]&lt;/code&gt;. Note that the above is equivalent to:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="49c2e9085ffe62b7af2e00831b5211eb57d553ec" translate="yes" xml:space="preserve">
          <source>Here we check that this operator is &lt;em&gt;exactly&lt;/em&gt; equal to its hermitian transpose.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66a65bf97c24fbc1825d0d9c6cb98cb1aafb52a0" translate="yes" xml:space="preserve">
          <source>Here, 'types' means the profiler nodes' properties. Profiler by default consider device name (e.g. /job:xx/.../device:GPU:0) and operation type (e.g. MatMul) as profiler nodes' properties. User can also associate customized 'types' to profiler nodes through OpLogProto proto.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17b2af2adfe30a3aef16e7ccfa94f34d6e4b3818" translate="yes" xml:space="preserve">
          <source>Here, a snapshot of &lt;code&gt;v&lt;/code&gt; is captured in &lt;code&gt;value&lt;/code&gt;; and then &lt;code&gt;v&lt;/code&gt; is updated. The snapshot value is returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ece63641c90490d540658510825631e924c7c84b" translate="yes" xml:space="preserve">
          <source>Here, adding &lt;code&gt;use_resource=True&lt;/code&gt; when constructing the variable will fix any nondeterminism issues:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94f786d71b2cb60eeb24aa9948d9d1f390afdf17" translate="yes" xml:space="preserve">
          <source>Here, positive definite means that the quadratic form &lt;code&gt;x^H A x&lt;/code&gt; has positive real part for all nonzero &lt;code&gt;x&lt;/code&gt;. Note that we do not require the operator to be self-adjoint to be positive definite.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51f5cbd0286b6bc2be5272d73eef56b1e6b7773c" translate="yes" xml:space="preserve">
          <source>Here, the input has a batch of 1 and each batch element has shape &lt;code&gt;[1, 1, 4]&lt;/code&gt;, the corresponding output will have 2x2 elements and will have a depth of 1 channel (1 = &lt;code&gt;4 / (block_size * block_size)&lt;/code&gt;). The output element shape is &lt;code&gt;[2, 2, 1]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2cace8ea6c5a3f6f36376df736083d35d45c704d" translate="yes" xml:space="preserve">
          <source>Here, the input has a batch of 1 and each batch element has shape &lt;code&gt;[2, 2, 1]&lt;/code&gt;, the corresponding output will have a single element (i.e. width and height are both 1) and will have a depth of 4 channels (1 * block_size * block_size). The output element shape is &lt;code&gt;[1, 1, 4]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f41c0836949b26db8a72f139bb0d93a63f27a5d8" translate="yes" xml:space="preserve">
          <source>Holds a list of enqueue operations for a queue, each to be run in a thread.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7ec66187a04150d0757954c1018dca525f600f5" translate="yes" xml:space="preserve">
          <source>Hook method for deconstructing the class fixture after running all tests in the class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aed79b3c251b0477f07982fb328ebad89154bf47" translate="yes" xml:space="preserve">
          <source>Hook method for deconstructing the test fixture after testing it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3376d91b293e2ef0e2b7a2f9d722cde34fcb75c" translate="yes" xml:space="preserve">
          <source>Hook method for setting up class fixture before running tests in the class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f3856f3bee2218da00682ea5300db8d8a163355" translate="yes" xml:space="preserve">
          <source>Hook method for setting up the test fixture before exercising it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b036bc6887a5488ae47380e1e40457b96130270" translate="yes" xml:space="preserve">
          <source>Hook that counts steps per second.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c583828ba4633b5282cbe15aa8308cd7a4ae402f" translate="yes" xml:space="preserve">
          <source>Hook that requests stop at a specified step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="694af7941c3209602c7a59e4452f1ab6fd0ed608" translate="yes" xml:space="preserve">
          <source>Hook to extend calls to MonitoredSession.run().</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e1bd302daecf16d1f3450073dcb3bb5f7b9e87f" translate="yes" xml:space="preserve">
          <source>Hook to run evaluation in training without a checkpoint.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="094e7dc095dce31db8b2d945d9b4e16d81e5603c" translate="yes" xml:space="preserve">
          <source>Hooks can use this function to request stop of iterations. &lt;code&gt;MonitoredSession&lt;/code&gt; checks whether this is called or not.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a54dcdd14e5ce50144dff46fc76cb90c2aac998a" translate="yes" xml:space="preserve">
          <source>How a layer uses its policy's compute dtype</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2d47c5b2670b24370374b073fdcc8981f93f9f3" translate="yes" xml:space="preserve">
          <source>How to choose:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b43d30453d0ca08342c32b5bf9b8ce3e75e7c394" translate="yes" xml:space="preserve">
          <source>How to set &lt;a href=&quot;../session&quot;&gt;&lt;code&gt;tf.compat.v1.Session&lt;/code&gt;&lt;/a&gt; arguments:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16612609ea0121d74a2ebf85615c5cd0d97d528b" translate="yes" xml:space="preserve">
          <source>How to use float64 in a Keras model</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5207d3c1fa3b2863bdee0225b56cf4e73f598a8c" translate="yes" xml:space="preserve">
          <source>How to use mixed precision in a Keras model</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95c24f970b239a2e8ff2902447bb8c0e66d29239" translate="yes" xml:space="preserve">
          <source>However, a few other options are available:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="906c66a75c112f0781943a37770b2aadd044fd08" translate="yes" xml:space="preserve">
          <source>However, in the case of the &lt;code&gt;BatchNormalization&lt;/code&gt; layer, &lt;strong&gt;setting &lt;code&gt;trainable = False&lt;/code&gt; on the layer means that the layer will be subsequently run in inference mode&lt;/strong&gt; (meaning that it will use the moving mean and the moving variance to normalize the current batch, rather than using the mean and variance of the current batch).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66a412ca5b09706643cf60849a60f29942f3b139" translate="yes" xml:space="preserve">
          <source>However, it is slower than &lt;code&gt;clip_by_norm()&lt;/code&gt; because all the parameters must be ready before the clipping operation can be performed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a7bc5ae946d568d89cd6bbe9faf1d5289b758f4" translate="yes" xml:space="preserve">
          <source>However, reducing using the above operator leads to a different computation tree (logs are taken repeatedly instead of only at the end), and the maximum is only computed pairwise instead of over the entire prefix. In general, this leads to a different and slightly less precise computation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee99d120cbadc6a5aa63deb6ecfc26724317acd1" translate="yes" xml:space="preserve">
          <source>However, the number of GPUs available to the runtime may change during runtime initialization due to marking certain devices as not visible or configuring multiple logical devices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f330c6ff1769454cb3a71f75c7d58d68fb24630a" translate="yes" xml:space="preserve">
          <source>However, when adding new features, one may want to unittest it before the forward compatibility window expires. This context manager enables such tests. For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0583a3e5e448e8509f2cf39238e0ea21adde84e" translate="yes" xml:space="preserve">
          <source>Hyper parameters</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c1ccbcd79a014503a1fc750addadaf475655020" translate="yes" xml:space="preserve">
          <source>Hyper parameters can be overwritten through user code:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dfe3cc7ab7e1d07c07d6f364735a8a458edbcaf8" translate="yes" xml:space="preserve">
          <source>Hyperbolic tangent activation function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="caae1c164e99fd3cee75315d0e4ac958059c8bec" translate="yes" xml:space="preserve">
          <source>I.e. returns: &lt;code&gt;output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebc94333451747193def37a773f19cfc358efe8b" translate="yes" xml:space="preserve">
          <source>I.e., \(y = -x\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d175ea7778bab88b107391a5a5e9565e50febd2b" translate="yes" xml:space="preserve">
          <source>I.e., \(y = 1 / \sqrt{x}\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c2e39388106824c1d86c17eb18e27d101f691e9" translate="yes" xml:space="preserve">
          <source>I.e., \(y = 1 / x\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="311b2c8a6cdecac50bdfa3324556c4c9ed69923b" translate="yes" xml:space="preserve">
          <source>I.e., \(y = \log_e (1 + x)\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa71ce7ff4ae1b412d0ee6bf849a4d32aa4d9b69" translate="yes" xml:space="preserve">
          <source>I.e., \(y = \log_e x\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8fbd8a894d77699447894ea0b5205e8c3734a34e" translate="yes" xml:space="preserve">
          <source>I.e., \(y = \sqrt{x} = x^{1/2}\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86e7c2902521071ed978a52a237380dc3ce4ceb1" translate="yes" xml:space="preserve">
          <source>I.e., \(y = x * x = x^2\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="568335e65a798d6ef3d2eab1d09d072f51075401" translate="yes" xml:space="preserve">
          <source>I.e., the size of the outermost dimension of the tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8e744aedc2c7c5589c77a5398c1f0d6581e556f" translate="yes" xml:space="preserve">
          <source>IMDB sentiment classification dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd887c07fd5e921ac521a8f68bba0d58f4244bf2" translate="yes" xml:space="preserve">
          <source>IMPORTANT: Depending on the &lt;a href=&quot;../../../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; implementation being used, and whether eager execution is enabled, &lt;code&gt;fn&lt;/code&gt; may be called one or more times (once for each replica).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ed0fee938570d32f30307cc8d274895cf578884" translate="yes" xml:space="preserve">
          <source>IMPORTANT: Depending on the &lt;a href=&quot;../../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; implementation being used, and whether eager execution is enabled, &lt;code&gt;fn&lt;/code&gt; may be called one or more times (once for each replica).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0b212e63aab3a82a290c7dc71cb4e212928f7d0" translate="yes" xml:space="preserve">
          <source>IMPORTANT: Depending on the implementation of &lt;a href=&quot;../../../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; and whether eager execution is enabled, &lt;code&gt;fn&lt;/code&gt; may be called one or more times ( once for each replica).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a856b464d5ae55c9c4b023a3135a60ea8e61e4aa" translate="yes" xml:space="preserve">
          <source>IMPORTANT: Depending on the implementation of &lt;a href=&quot;../../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; and whether eager execution is enabled, &lt;code&gt;fn&lt;/code&gt; may be called one or more times ( once for each replica).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="115e1c114d9f3681f99e56d6543c4b81c3fc3d32" translate="yes" xml:space="preserve">
          <source>IMPORTANT: Depending on the implementation of &lt;a href=&quot;../strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; and whether eager execution is enabled, &lt;code&gt;fn&lt;/code&gt; may be called one or more times ( once for each replica).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89f04e8da8a966a33aa44bfaa2ea3036d7113c48" translate="yes" xml:space="preserve">
          <source>IMPORTANT: Depending on the implementation of &lt;a href=&quot;strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; and whether eager execution is enabled, &lt;code&gt;fn&lt;/code&gt; may be called one or more times ( once for each replica).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3af46570ffb6dae63862cdf22039cbe1fe550b02" translate="yes" xml:space="preserve">
          <source>IMPORTANT: The &lt;a href=&quot;../../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; returned by &lt;code&gt;dataset_fn&lt;/code&gt; should have a per-replica batch size, unlike &lt;code&gt;experimental_distribute_dataset&lt;/code&gt;, which uses the global batch size. This may be computed using &lt;code&gt;input_context.get_per_replica_batch_size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="387e6943d94be6545861c405c7eedd2b318559f0" translate="yes" xml:space="preserve">
          <source>IMPORTANT: The &lt;a href=&quot;../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; returned by &lt;code&gt;dataset_fn&lt;/code&gt; should have a per-replica batch size, unlike &lt;code&gt;experimental_distribute_dataset&lt;/code&gt;, which uses the global batch size. This may be computed using &lt;code&gt;input_context.get_per_replica_batch_size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="371527ec937092bce8c5302761968a912dfa40b4" translate="yes" xml:space="preserve">
          <source>IMPORTANT: The &lt;a href=&quot;../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; returned by &lt;code&gt;dataset_fn&lt;/code&gt; should have a per-replica batch size, unlike &lt;code&gt;experimental_distribute_dataset&lt;/code&gt;, which uses the global batch size. This may be computed using &lt;code&gt;input_context.get_per_replica_batch_size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ad1bd30c735d96ef3bf70ea7676440f0a17a75f" translate="yes" xml:space="preserve">
          <source>IMPORTANT: The &lt;a href=&quot;../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; returned by &lt;code&gt;dataset_fn&lt;/code&gt; should have a per-replica batch size, unlike &lt;code&gt;experimental_distribute_dataset&lt;/code&gt;, which uses the global batch size. This may be computed using &lt;code&gt;input_context.get_per_replica_batch_size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6a0418b361073a5e7f1934efa7924dff3340f39" translate="yes" xml:space="preserve">
          <source>IMPORTANT: The ordering of communications must be identical in all replicas.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94ef35d6e06d69b9a685928876f94b41c52dc1b8" translate="yes" xml:space="preserve">
          <source>INT8 precision and calibration with pre-built engines</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b472357b902f890e4087773a365cdaed808b715" translate="yes" xml:space="preserve">
          <source>If &quot;shape&quot; is None, the resulting tensor proto represents the numpy array precisely.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94418d02e3456ba7719cd5581956e1dd1bf97adf" translate="yes" xml:space="preserve">
          <source>If &quot;values&quot; is a python scalar or a python list, make_tensor_proto first convert it to numpy ndarray. If dtype is None, the conversion tries its best to infer the right numpy data type. Otherwise, the resulting numpy array has a compatible data type with the given dtype.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2291e4d4d0493fe7acb48d2007a3752b8f7b2d33" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;A&lt;/code&gt; is block circulant, with block sizes &lt;code&gt;N0, N1&lt;/code&gt; (&lt;code&gt;N0 * N1 = N&lt;/code&gt;): &lt;code&gt;A&lt;/code&gt; has a block circulant structure, composed of &lt;code&gt;N0 x N0&lt;/code&gt; blocks, with each block an &lt;code&gt;N1 x N1&lt;/code&gt; circulant matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3f8efbf3d9e6147ecaa064f2b05f3a2250d33f3" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;A&lt;/code&gt; is nested block circulant, with block sizes &lt;code&gt;N0, N1, N2&lt;/code&gt; (&lt;code&gt;N0 * N1 * N2 = N&lt;/code&gt;): &lt;code&gt;A&lt;/code&gt; has a block structure, composed of &lt;code&gt;N0 x N0&lt;/code&gt; blocks, with each block an &lt;code&gt;N1 x N1&lt;/code&gt; block circulant matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25587966a8e2f216b6da2cdce4060125a4291eb7" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;H.shape = [N0, N1, N2]&lt;/code&gt;, (&lt;code&gt;N0 * N1 * N2 = N&lt;/code&gt;): Loosely speaking, matrix multiplication is equal to the action of a Fourier multiplier: &lt;code&gt;A u = IDFT3[ H DFT3[u] ]&lt;/code&gt;. Precisely speaking, given &lt;code&gt;[N, R]&lt;/code&gt; matrix &lt;code&gt;u&lt;/code&gt;, let &lt;code&gt;DFT3[u]&lt;/code&gt; be the &lt;code&gt;[N0, N1, N2, R]&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; defined by re-shaping &lt;code&gt;u&lt;/code&gt; to &lt;code&gt;[N0, N1, N2, R]&lt;/code&gt; and taking a three dimensional DFT across the first three dimensions. Let &lt;code&gt;IDFT3&lt;/code&gt; be the inverse of &lt;code&gt;DFT3&lt;/code&gt;. Matrix multiplication may be expressed columnwise:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e381afea75d47e56f3608744fb4bdb4a6e5cfdf" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;H.shape = [N0, N1]&lt;/code&gt;, (&lt;code&gt;N0 * N1 = N&lt;/code&gt;): Loosely speaking, matrix multiplication is equal to the action of a Fourier multiplier: &lt;code&gt;A u = IDFT2[ H DFT2[u] ]&lt;/code&gt;. Precisely speaking, given &lt;code&gt;[N, R]&lt;/code&gt; matrix &lt;code&gt;u&lt;/code&gt;, let &lt;code&gt;DFT2[u]&lt;/code&gt; be the &lt;code&gt;[N0, N1, R]&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; defined by re-shaping &lt;code&gt;u&lt;/code&gt; to &lt;code&gt;[N0, N1, R]&lt;/code&gt; and taking a two dimensional DFT across the first two dimensions. Let &lt;code&gt;IDFT2&lt;/code&gt; be the inverse of &lt;code&gt;DFT2&lt;/code&gt;. Matrix multiplication may be expressed columnwise:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4bbcbab5946b02f4bd8339afde5bc909bf23760f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;L&lt;/code&gt; is non-singular, solves and determinants are available. Solves/determinants both involve a solve/determinant of a &lt;code&gt;K x K&lt;/code&gt; system. In the event that L and D are self-adjoint positive-definite, and U = V, this can be done using a Cholesky factorization. The user should set the &lt;code&gt;is_X&lt;/code&gt; matrix property hints, which will trigger the appropriate code path.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9426460040356d10df11f6a515a1e8a979f481d4" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;M = N&lt;/code&gt;, determinants and solves are done using the matrix determinant lemma and Woodbury identities, and thus require L and D to be non-singular.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad6839f42ef3ffc050c2206365782e56e109f3df" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;M=N&lt;/code&gt;, &lt;code&gt;operator.determinant()&lt;/code&gt; is &lt;code&gt;O(N^3)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d2680f7f302962db3beec63891212a96a0cde62" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;M=N&lt;/code&gt;, &lt;code&gt;operator.solve(x)&lt;/code&gt; is &lt;code&gt;O(N^3 * R)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e41171d0e9385cb32976695c17de0293dfc81335" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;T&lt;/code&gt; is smaller than &lt;code&gt;type&lt;/code&gt;, the operator requires that the rightmost dimension be equal to sizeof(&lt;code&gt;type&lt;/code&gt;)/sizeof(&lt;code&gt;T&lt;/code&gt;). The shape then goes from [..., sizeof(&lt;code&gt;type&lt;/code&gt;)/sizeof(&lt;code&gt;T&lt;/code&gt;)] to [...].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c7a904e6acee7cc058932afbbd9186b0a891454" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;adjoint_a == false&lt;/code&gt;: &lt;code&gt;A&lt;/code&gt; should be sorted in lexicographically increasing order. Use &lt;a href=&quot;reorder&quot;&gt;&lt;code&gt;sparse.reorder&lt;/code&gt;&lt;/a&gt; if you're not sure.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07af4a9ac21faf4286799bc8a4a85745861cc3f1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;adjoint_a == true&lt;/code&gt;: &lt;code&gt;A&lt;/code&gt; should be sorted in order of increasing dimension 1 (i.e., &quot;column major&quot; order instead of &quot;row major&quot; order).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="110ff3780b3515c9d733eede8bbe4c3bc9825cee" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;all_reduce&lt;/code&gt; is called in any replica, it must be called in all replicas. The nested structure and &lt;code&gt;Tensor&lt;/code&gt; shapes must be identical in all replicas.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17b9b3019bf6883d5abf33ab706045e5053f610a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;allow_smaller_final_batch&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, a smaller batch value than &lt;code&gt;batch_size&lt;/code&gt; is returned when the queue is closed and there are not enough elements to fill the batch, otherwise the pending elements are discarded. In addition, all output tensors' static shapes, as accessed via the &lt;code&gt;shape&lt;/code&gt; property will have a first &lt;code&gt;Dimension&lt;/code&gt; value of &lt;code&gt;None&lt;/code&gt;, and operations that depend on fixed batch_size would fail.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd7fbda9d4e5df2aaf326a8208be66bf6fd7816b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;as_ref&lt;/code&gt; is true, the function must return a &lt;code&gt;Tensor&lt;/code&gt; reference, such as a &lt;code&gt;Variable&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebdc4f6453f07fa10351f671954a8d9cfc7adb0f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis == 0&lt;/code&gt; then the i'th tensor in &lt;code&gt;output&lt;/code&gt; is the slice &lt;code&gt;value[i, :, :, :]&lt;/code&gt; and each tensor in &lt;code&gt;output&lt;/code&gt; will have shape &lt;code&gt;(B, C, D)&lt;/code&gt;. (Note that the dimension unpacked along is gone, unlike &lt;code&gt;split&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88a0b065f0f00041a252be5ef4e010c2b3761be1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis == 1&lt;/code&gt; then the i'th tensor in &lt;code&gt;output&lt;/code&gt; is the slice &lt;code&gt;value[:, i, :, :]&lt;/code&gt; and each tensor in &lt;code&gt;output&lt;/code&gt; will have shape &lt;code&gt;(A, C, D)&lt;/code&gt;. Etc.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82c15a867116f27864f6d455e86bfd0be8b87837" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis&lt;/code&gt; has no entries, all dimensions are reduced, and a tensor with a single element is returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a8ec21ac4d58f6a8479a92f2f74cef6e393ea5c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis&lt;/code&gt; has no entries, all dimensions are reduced, and a tensor with a single element is returned. Additionally, the axes can be negative, similar to the indexing rules in Python.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c3c0b53459dfc2bb4beb0a0adb6072980b26e14" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis&lt;/code&gt; is None, all dimensions are reduced, and a tensor with a single element is returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4602049d19408d9325e5ff8f12f74035055b93a7" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;backward_layer&lt;/code&gt; has mismatched properties compared to &lt;code&gt;layer&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1210be14982a956118b83d39f36a2c3bc225338" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;batch_shape&lt;/code&gt; initialization arg is &lt;code&gt;None&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b34f5f9c6902112fe4d7b168dfca4894759e293" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;batch_shape&lt;/code&gt; initialization arg is provided, and static checks cannot rule out the need to broadcast:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e0014fe3e6f4ed6ff2b3d6fdd0d4f70bafb4a1a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;by_name&lt;/code&gt; is False weights are loaded based on the network's topology. This means the architecture should be the same as when the weights were saved. Note that layers that don't have weights are not taken into account in the topological ordering, so adding or removing layers is fine as long as they don't have weights.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15a8bafdca0abb98187bac49dd0616a9d631c410" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;by_name&lt;/code&gt; is True, weights are loaded into layers only if they share the same name. This is useful for fine-tuning or transfer-learning models where some of the layers have changed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8eec2900c2fb0f0251b678a361ecad074ba0af19" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;cancel_pending_enqueues&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, all pending requests will also be canceled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d24f152ba9fe436f35ebbbc28f22afb95d7ac755" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ckpt_dir_or_file&lt;/code&gt; resolves to a directory with multiple checkpoints, reader for the latest checkpoint is returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20bd49990b5cf72ae3b08662dd38487aaacb7b14" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;class_id&lt;/code&gt; is specified, we calculate precision by considering only the entries in the batch for which &lt;code&gt;class_id&lt;/code&gt; is above the threshold and/or in the top-k highest predictions, and computing the fraction of them for which &lt;code&gt;class_id&lt;/code&gt; is indeed a correct label.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="594da24c877b56fce6dcc330d36e921550f67631" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;class_id&lt;/code&gt; is specified, we calculate precision by considering only the entries in the batch for which &lt;code&gt;class_id&lt;/code&gt; is in the top-k highest &lt;code&gt;predictions&lt;/code&gt;, and computing the fraction of them for which &lt;code&gt;class_id&lt;/code&gt; is indeed a correct label. If &lt;code&gt;class_id&lt;/code&gt; is not specified, we'll calculate precision as how often on average a class among the top-k classes with the highest predicted values of a batch entry is correct and can be found in the label for that entry.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2fed35668157bd216f9480f06ebfb465420b146" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;class_id&lt;/code&gt; is specified, we calculate recall by considering only the entries in the batch for which &lt;code&gt;class_id&lt;/code&gt; is in the label, and computing the fraction of them for which &lt;code&gt;class_id&lt;/code&gt; is above the threshold and/or in the top-k predictions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0598665208e329d2285f13959a4c8a0be2108783" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;class_id&lt;/code&gt; is specified, we calculate recall by considering only the entries in the batch for which &lt;code&gt;class_id&lt;/code&gt; is in the label, and computing the fraction of them for which &lt;code&gt;class_id&lt;/code&gt; is in the top-k &lt;code&gt;predictions&lt;/code&gt;. If &lt;code&gt;class_id&lt;/code&gt; is not specified, we'll calculate recall as how often on average a class among the labels of a batch entry is in the top-k &lt;code&gt;predictions&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ed0b9e3e88d8fb4c9485f67ff031b4dbc5fc2f1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;clip_norm &amp;gt; global_norm&lt;/code&gt; then the entries in &lt;code&gt;t_list&lt;/code&gt; remain as they are, otherwise they're all shrunk by the global ratio.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e9530f81d1e38f5cf65209f508156d9b6769612" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;cluster&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt;, and &lt;code&gt;ps_tasks&lt;/code&gt; is 0, the returned function is a no-op. Otherwise, the value of &lt;code&gt;ps_tasks&lt;/code&gt; is derived from &lt;code&gt;cluster&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="065bbd8103d747b51b68745d23b95f48f33acad0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;condition&lt;/code&gt; evaluates to false, print the list of tensors in &lt;code&gt;data&lt;/code&gt;. &lt;code&gt;summarize&lt;/code&gt; determines how many entries of the tensors to print.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc7c3e5a0b26f7d25559f77e68ccbfaa5c98f33a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;condition&lt;/code&gt; is a vector and &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are higher rank matrices, then it chooses which row (outer dimension) to copy from &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. If &lt;code&gt;condition&lt;/code&gt; has the same shape as &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;, then it chooses which element to copy from &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85cf61e910d69324c4a7ef790c66d6a2dfd03048" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ctc_merge_repeated&lt;/code&gt; is set False, then deep within the CTC calculation, repeated non-blank labels will not be merged and are interpreted as individual labels. This is a simplified (non-standard) version of CTC.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47f2aad48c2d0f196f9ea6e64ee4554117907144" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;cycle&lt;/code&gt; is True then a multiple of &lt;code&gt;decay_steps&lt;/code&gt; is used, the first one that is bigger than &lt;code&gt;global_steps&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e96124e7a04b42a83269b91d81e7e32583e381c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;cycle&lt;/code&gt; is True then a multiple of &lt;code&gt;decay_steps&lt;/code&gt; is used, the first one that is bigger than &lt;code&gt;step&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed08d044f4ced3eb43b5b5b9c435daedbc9bccbf" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch, channels, cropped_rows, cropped_cols)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c5b04849f3239ff7f2aed6311abff3cbd6b35af1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch, channels, dim1, dim2, dim3)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f34c9b34734b9df20fbf8e979f546c9c4cc5baf4" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch, channels, padded_rows, padded_cols)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="18824f32ee3435a0aaf0ab5c308c42f192295a0b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch, channels, rows, cols)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d97ca997b91aa66ba4112051e89b9fd1d11e0319" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch, channels, upsampled_dim1, upsampled_dim2, upsampled_dim3)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6ed1bb95109cbf4e1521d123414f77ee773a64c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch, channels, upsampled_rows, upsampled_cols)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4b398a294c2ee1defa640c1a2420cb9d283d80b8" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch, depth, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfcc85522ec5786f0f0111cb911348fd3d60aa41" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch, depth, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b26f95b56877033c8096f8c21ee90b92dfad7a9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch, depth, first_cropped_axis, second_cropped_axis, third_cropped_axis)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40a4fb20ae2e104be54b9c38059d00d6af133ad2" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch, depth, first_padded_axis, second_padded_axis, third_axis_to_pad)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83ec0b7162cfee960e285831df5e57e17a03a60e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_last&quot;&lt;/code&gt;: &lt;code&gt;(batch, cropped_rows, cropped_cols, channels)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3080e83cbbe1150d4ffe3e63f9f6d620396eedd3" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_last&quot;&lt;/code&gt;: &lt;code&gt;(batch, dim1, dim2, dim3, channels)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="003ead137d3f3851640c5a5a4a06d578ee1562e8" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_last&quot;&lt;/code&gt;: &lt;code&gt;(batch, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop, depth)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d5b3587001e70040c247fd7de822807f24ae9ff" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_last&quot;&lt;/code&gt;: &lt;code&gt;(batch, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad, depth)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="483c2efe5b6618e7f64dde6715f4895ce351e56e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_last&quot;&lt;/code&gt;: &lt;code&gt;(batch, first_cropped_axis, second_cropped_axis, third_cropped_axis, depth)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df33090fd8aa7bd86d0ae1a9759ce56513b08b8e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_last&quot;&lt;/code&gt;: &lt;code&gt;(batch, first_padded_axis, second_padded_axis, third_axis_to_pad, depth)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eed95b4a9ed8b9aeb9fdbd8e1b9803e00bf2766e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_last&quot;&lt;/code&gt;: &lt;code&gt;(batch, padded_rows, padded_cols, channels)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f64e4bcccce433c9566b78b8afa1f94c8c04fcef" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_last&quot;&lt;/code&gt;: &lt;code&gt;(batch, rows, cols, channels)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44f47dd0c8b0b06a1527506e0b470b0131115a5f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_last&quot;&lt;/code&gt;: &lt;code&gt;(batch, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="830a8a4e419a5e596ab42fcfe1067a6cadcf5b6c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_last&quot;&lt;/code&gt;: &lt;code&gt;(batch, upsampled_rows, upsampled_cols, channels)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3403ab76bb64e92cbc1ce947dc55b8c2f4c83858" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format='channels_first'&lt;/code&gt;: 3D tensor with shape &lt;code&gt;(batch_size, features, downsampled_steps)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76789aedd1e1b30e65c811b2313b49f5abac81bd" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format='channels_first'&lt;/code&gt;: 3D tensor with shape &lt;code&gt;(batch_size, features, steps)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2c87816275e01f135bb9300e7a0edc16061dbaa" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format='channels_first'&lt;/code&gt;: 3D tensor with shape: &lt;code&gt;(batch_size, features, steps)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d125d22c952d5e837dfbc3985718e658b08de7f8" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format='channels_first'&lt;/code&gt;: 4D tensor with shape &lt;code&gt;(batch_size, channels, pooled_rows, pooled_cols)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="efeffd222f25920652324c590da7090efc77a88f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format='channels_first'&lt;/code&gt;: 4D tensor with shape &lt;code&gt;(batch_size, channels, rows, cols)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="769dedd8ac289e52c4aa08f01592146935aca265" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format='channels_first'&lt;/code&gt;: 5D tensor with shape: &lt;code&gt;(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64af7dda1bd74417607c23dcca4549eb64eaf842" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format='channels_first'&lt;/code&gt;: 5D tensor with shape: &lt;code&gt;(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f181cb0cca921d90a9528a5b16866d3bc2e4a31" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format='channels_last'&lt;/code&gt;: 3D tensor with shape &lt;code&gt;(batch_size, downsampled_steps, features)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e79cfe731a2022565e9ce98c413ff3d4fea639e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format='channels_last'&lt;/code&gt;: 3D tensor with shape &lt;code&gt;(batch_size, steps, features)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c23ac2b777982bd7858d1585dca6d0af455ce47" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format='channels_last'&lt;/code&gt;: 3D tensor with shape: &lt;code&gt;(batch_size, steps, features)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b5eae7be09c8d4e03880f99d1ad2a8a783e7aad" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format='channels_last'&lt;/code&gt;: 4D tensor with shape &lt;code&gt;(batch_size, pooled_rows, pooled_cols, channels)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ddca25a45ba996ea23fba4bf6ca17bee3cfae493" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format='channels_last'&lt;/code&gt;: 4D tensor with shape &lt;code&gt;(batch_size, rows, cols, channels)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8233b6c3273cec342b518aa2c3dfc2e35e020b9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format='channels_last'&lt;/code&gt;: 5D tensor with shape: &lt;code&gt;(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ec7e00c511e46673a4884a5b2f092291c4ad275" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format='channels_last'&lt;/code&gt;: 5D tensor with shape: &lt;code&gt;(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad1d1c40df2fea11227db382ded54071f270ecec" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;dtype&lt;/code&gt; is not provided, it will attempt to assume the data type of &lt;code&gt;on_value&lt;/code&gt; or &lt;code&gt;off_value&lt;/code&gt;, if one or both are passed in. If none of &lt;code&gt;on_value&lt;/code&gt;, &lt;code&gt;off_value&lt;/code&gt;, or &lt;code&gt;dtype&lt;/code&gt; are provided, &lt;code&gt;dtype&lt;/code&gt; will default to the value &lt;a href=&quot;../tf#float32&quot;&gt;&lt;code&gt;tf.float32&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25b80e47772b0bfc696fbf3b5bb5ff69641199ce" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;dtype&lt;/code&gt; is real, and &lt;code&gt;is_self_adjoint&lt;/code&gt; and &lt;code&gt;is_positive_definite&lt;/code&gt;, a Cholesky factorization is used for the determinant and solve.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87728c1899322de33a9ed090ef422757a31d60b9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;dtype&lt;/code&gt; is specified the resulting tensor values are cast to the requested &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6bf0dabc06d37338f301de3b7a000a236395058" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;dynamic_pad&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, it is sufficient that the &lt;em&gt;rank&lt;/em&gt; of the tensors is known, but individual dimensions may have shape &lt;code&gt;None&lt;/code&gt;. In this case, for each enqueue the dimensions with value &lt;code&gt;None&lt;/code&gt; may have a variable length; upon dequeue, the output tensors will be padded on the right to the maximum shape of the tensors in the current minibatch. For numbers, this padding takes value 0. For strings, this padding is the empty string. See &lt;code&gt;PaddingFIFOQueue&lt;/code&gt; for more info.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7154051f64e09243a5e2742d4bb8fb6d037dddc" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;dynamic_pad&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, it is sufficient that the &lt;em&gt;rank&lt;/em&gt; of the tensors is known, but individual dimensions may have value &lt;code&gt;None&lt;/code&gt;. In this case, for each enqueue the dimensions with value &lt;code&gt;None&lt;/code&gt; may have a variable length; upon dequeue, the output tensors will be padded on the right to the maximum shape of the tensors in the current minibatch. For numbers, this padding takes value 0. For strings, this padding is the empty string. See &lt;code&gt;PaddingFIFOQueue&lt;/code&gt; for more info.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c4b65a0810a67f6df4062a29da66142c0346f29" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;enqueue_many&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, &lt;code&gt;tensors&lt;/code&gt; is assumed to represent a single example. An input tensor with shape &lt;code&gt;[x, y, z]&lt;/code&gt; will be output as a tensor with shape &lt;code&gt;[batch_size, x, y, z]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f53d0408f26222dd6e2cb6b512d5cf383ecb0db" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;enqueue_many&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, each &lt;code&gt;tensors_list[i]&lt;/code&gt; is assumed to represent a single example. An input tensor &lt;code&gt;x&lt;/code&gt; will be output as a tensor with shape &lt;code&gt;[batch_size] + x.shape&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c84e3f51d2a96b8ae5c34258f3f8f20e2f9061c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;enqueue_many&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, each &lt;code&gt;tensors_list[i]&lt;/code&gt; is assumed to represent a single example. An input tensor with shape &lt;code&gt;[x, y, z]&lt;/code&gt; will be output as a tensor with shape &lt;code&gt;[batch_size, x, y, z]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="341111f29e74aa8ef96f30f69cc9494a535fcfdc" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;enqueue_many&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;tensors&lt;/code&gt; is assumed to represent a batch of examples, where the first dimension is indexed by example, and all members of &lt;code&gt;tensors&lt;/code&gt; should have the same size in the first dimension. If an input tensor has shape &lt;code&gt;[*, x, y, z]&lt;/code&gt;, the output will have shape &lt;code&gt;[batch_size, x, y, z]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cdc2ab5b45f000da1295bb1b0a336e2b463d4530" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;enqueue_many&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;tensors&lt;/code&gt; is assumed to represent a batch of examples, where the first dimension is indexed by example, and all members of &lt;code&gt;tensors&lt;/code&gt; should have the same size in the first dimension. If an input tensor has shape &lt;code&gt;[*, x, y, z]&lt;/code&gt;, the output will have shape &lt;code&gt;[batch_size, x, y, z]&lt;/code&gt;. The &lt;code&gt;capacity&lt;/code&gt; argument controls the how long the prefetching is allowed to grow the queues.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26d498f25d2a64c1fed1145d08fdecc587420e5c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;enqueue_many&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;tensors_list[i]&lt;/code&gt; is assumed to represent a batch of examples, where the first dimension is indexed by example, and all members of &lt;code&gt;tensors_list[i]&lt;/code&gt; should have the same size in the first dimension. If an input tensor has shape &lt;code&gt;[*, x, y, z]&lt;/code&gt;, the output will have shape &lt;code&gt;[batch_size, x, y, z]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b55a60b064830f9883032828fbe6f4b068812e2f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;enqueue_many&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;tensors_list[i]&lt;/code&gt; is assumed to represent a batch of examples, where the first dimension is indexed by example, and all members of &lt;code&gt;tensors_list[i]&lt;/code&gt; should have the same size in the first dimension. The slices of any input tensor &lt;code&gt;x&lt;/code&gt; are treated as examples, and the output tensors will have shape &lt;code&gt;[batch_size] + x.shape[1:]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6738e0e3984368cde96a4a476d2cdaa918be36c1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;exclusive==True&lt;/code&gt;, all predicates are evaluated, and an exception is thrown if more than one of the predicates evaluates to &lt;code&gt;True&lt;/code&gt;. If &lt;code&gt;exclusive==False&lt;/code&gt;, execution stops at the first predicate which evaluates to True, and the tensors generated by the corresponding function are returned immediately. If none of the predicates evaluate to True, this operation returns the tensors generated by &lt;code&gt;default&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03bdec9947eaedf4bdce7a6822bddea8728620a0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;f&lt;/code&gt; uses &lt;code&gt;Variable&lt;/code&gt;s (that are not part of the inputs), i.e. through &lt;code&gt;get_variable&lt;/code&gt;, then &lt;code&gt;grad_fn&lt;/code&gt; should have signature &lt;code&gt;g(*grad_ys, variables=None)&lt;/code&gt;, where &lt;code&gt;variables&lt;/code&gt; is a list of the &lt;code&gt;Variable&lt;/code&gt;s, and return a 2-tuple &lt;code&gt;(grad_xs, grad_vars)&lt;/code&gt;, where &lt;code&gt;grad_xs&lt;/code&gt; is the same as above, and &lt;code&gt;grad_vars&lt;/code&gt; is a &lt;code&gt;list&amp;lt;Tensor&amp;gt;&lt;/code&gt; with the derivatives of &lt;code&gt;Tensor&lt;/code&gt;s in &lt;code&gt;y&lt;/code&gt; with respect to the variables (that is, grad_vars has one Tensor per variable in variables).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="372309d6842fa4a199f338a43c95a0cfee85deea" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;fast&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; an algorithm based on the numerically robust complete orthogonal decomposition is used. This computes the minimum-norm least-squares solution, even when \(A\) is rank deficient. This path is typically 6-7 times slower than the fast path. If &lt;code&gt;fast&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; then &lt;code&gt;l2_regularizer&lt;/code&gt; is ignored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27049f19ad9a7d096760e3d9b009bb4362edc6f5" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;fast&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then the solution is computed by solving the normal equations using Cholesky decomposition. Specifically, if \(m \ge n\) then \(X = (A^T A + \lambda I)^{-1} A^T B\), which solves the least-squares problem \(X = \mathrm{argmin}_{Z \in \Re^{n \times k}} ||A Z - B||_F^2 + \lambda ||Z||_F^2\). If \(m \lt n\) then &lt;code&gt;output&lt;/code&gt; is computed as \(X = A^T (A A^T + \lambda I)^{-1} B\), which (for \(\lambda = 0\)) is the minimum-norm solution to the under-determined linear system, i.e. \(X = \mathrm{argmin}_{Z \in \Re^{n \times k}} ||Z||_F^2 \), subject to \(A Z = B\). Notice that the fast path is only numerically stable when \(A\) is numerically full rank and has a condition number \(\mathrm{cond}(A) \lt \frac{1}{\sqrt{\epsilon_{mach}}}\) or\(\lambda\) is sufficiently large.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac46406112566e4c8d7fd9007e8f023b0bb2d1e1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;format&lt;/code&gt; is not specified or is the empty string, a default format is picked in function of the number of channels in &lt;code&gt;image&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57b26f5a78e8c279b178b9ade3dd5bc6d06da127" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;func&lt;/code&gt; is not None, returns a &lt;code&gt;Callable&lt;/code&gt; which is equivalent to &lt;code&gt;func&lt;/code&gt;, but is not converted by AutoGraph. If &lt;code&gt;func&lt;/code&gt; is None, returns a decorator that, when invoked with a single &lt;code&gt;func&lt;/code&gt; argument, returns a &lt;code&gt;Callable&lt;/code&gt; equivalent to the above case.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f898cef9866995880d01892817ec2175fe439d2e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;func&lt;/code&gt; is not None, returns a callable that will execute the compiled function (and return zero or more &lt;code&gt;tf.Tensor&lt;/code&gt; objects). If &lt;code&gt;func&lt;/code&gt; is None, returns a decorator that, when invoked with a single &lt;code&gt;func&lt;/code&gt; argument, returns a callable equivalent to the case above.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62acbfcfb14ee0a398f34c8b9aa49c710246709d" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;global_norm == infinity&lt;/code&gt; then the entries in &lt;code&gt;t_list&lt;/code&gt; are all set to &lt;code&gt;NaN&lt;/code&gt; to signal that an error occurred.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8202744147fe643212bcfe0c85cc04cbaa3a7c42" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;image&lt;/code&gt; was 4-D, a 4-D float Tensor of shape &lt;code&gt;[batch, target_height, target_width, channels]&lt;/code&gt; If &lt;code&gt;image&lt;/code&gt; was 3-D, a 3-D float Tensor of shape &lt;code&gt;[target_height, target_width, channels]&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e92f8fb84781c3e7b4d7c52dbb4a1a2a181a567" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;image&lt;/code&gt; was 4-D, a 4-D float Tensor of shape &lt;code&gt;[batch, width, height, channels]&lt;/code&gt; If &lt;code&gt;image&lt;/code&gt; was 3-D, a 3-D float Tensor of shape &lt;code&gt;[width, height, channels]&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b22ec650a9bcf3dbd00caf73b8addae20e1363f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;images&lt;/code&gt; was 4-D, a 4-D float Tensor of shape &lt;code&gt;[batch, new_height, new_width, channels]&lt;/code&gt;. If &lt;code&gt;images&lt;/code&gt; was 3-D, a 3-D float Tensor of shape &lt;code&gt;[new_height, new_width, channels]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2952b0ed613f675460838f4f741f5f9164c5ef5" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;images&lt;/code&gt; was 4-D, return a 1-D float Tensor of shape &lt;code&gt;[batch]&lt;/code&gt; with the total variation for each image in the batch. If &lt;code&gt;images&lt;/code&gt; was 3-D, return a scalar float with the total variation for that image.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eda69d01cfcf1f44ffd4da2f558f423b426b0614" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;indices&lt;/code&gt; contains duplicates, then their updates are accumulated (summed).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a94358a58fd92ac955695f20a84f5c03cc0dc2c8" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;indices&lt;/code&gt; is a RaggedTensor, the 'axis' argument must be positive and refer to a non-ragged axis. The output will be equivalent to applying 'one_hot' on the values of the RaggedTensor, and creating a new RaggedTensor from the result.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b6eba702090dea64afc7969a9f079a18321fa1e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;indices&lt;/code&gt; is a matrix (batch) with shape &lt;code&gt;[batch, features]&lt;/code&gt;, the output shape will be:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7efb1cc16c63ea7b0aac3e018a11b41a9ddc9ed" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;indices&lt;/code&gt; is a scalar the output shape will be a vector of length &lt;code&gt;depth&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a13c16c0eff3a5bb88de38a8d8307ec6511d293" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;indices&lt;/code&gt; is a vector of length &lt;code&gt;features&lt;/code&gt;, the output shape will be:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c438e9ba6fd98b2384d247334493173a26303ad" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;initializer&lt;/code&gt; is None, only out-of-vocabulary buckets are used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d93109613b12250a30b715aa9a4045da0bba426f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is already real, it is returned unchanged.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c620f70974120bd9cb3db4d33f50222f323be76" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input_output_dtype = DTYPE&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ce85c6dd49fe3b8c73feae72b7f6738cadc8bb8" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;is_X == False&lt;/code&gt;, callers should expect the operator to not have &lt;code&gt;X&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0afbb1278c738c0d57964d82ebe25d5d9dff4ba" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;is_X == None&lt;/code&gt; (the default), callers should have no expectation either way.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd1b93088ca4115b8f08bd9ab8fb507c261ccce5" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;is_X == True&lt;/code&gt;, callers should expect the operator to have the property &lt;code&gt;X&lt;/code&gt;. This is a promise that should be fulfilled, but is &lt;em&gt;not&lt;/em&gt; a runtime assert. For example, finite floating point precision may result in these promises being violated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96697908c1dc3e043634cbbd44dc5cfb701b564b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;is_tensor(x)&lt;/code&gt; returns &lt;code&gt;True&lt;/code&gt;, it is safe to assume that &lt;code&gt;x&lt;/code&gt; is a tensor or can be converted to a tensor using &lt;code&gt;ops.convert_to_tensor(x)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a212a196f90ac2693f3cbfad3f8cd8e36d111b25" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;iterator&lt;/code&gt; has reached the end of the sequence, the returned &lt;code&gt;Optional&lt;/code&gt; will have no value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99d5159794e9527572e582d5291c29b2551e8bac" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;label_smoothing&lt;/code&gt; is nonzero, smooth the labels towards 1/2:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4fc91aecf4a1093b877f40965090f1148dd8d17" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;label_smoothing&lt;/code&gt; is nonzero, smooth the labels towards 1/num_classes: new_onehot_labels = onehot_labels * (1 - label_smoothing) + label_smoothing / num_classes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9535e210890193a55032b616d005eda7ed94d172" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;label_vocabulary&lt;/code&gt; is given, a string &lt;code&gt;SparseTensor&lt;/code&gt;. The &lt;code&gt;dense_shape&lt;/code&gt; must be &lt;code&gt;[D0, D1, ... DN, ?]&lt;/code&gt; and the values within &lt;code&gt;label_vocabulary&lt;/code&gt; or a multi-hot tensor of shape &lt;code&gt;[D0, D1, ... DN, n_classes]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84e776cdbcc3444233893bed8e8a175d8a296b35" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;len(params) &amp;gt; 1&lt;/code&gt;, each element &lt;code&gt;id&lt;/code&gt; of &lt;code&gt;ids&lt;/code&gt; is partitioned between the elements of &lt;code&gt;params&lt;/code&gt; according to the &lt;code&gt;partition_strategy&lt;/code&gt;. In all strategies, if the id space does not evenly divide the number of partitions, each of the first &lt;code&gt;(max_id + 1) % len(params)&lt;/code&gt; partitions will be assigned one more id.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d08097191b4f17f118cbfefba6aecf799282429" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;len(partitions) &amp;gt; 1&lt;/code&gt;, then:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f370b423121a48298eb43a3a0c878f9941513c9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;len(partitions) == 0&lt;/code&gt; (the default), then:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cf134dcb33104f575f6a123d3a075fe42f5e61f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;len(partitions) == 1&lt;/code&gt;, then:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7d16e6c5a371d846babf4540ef4a499f5ff7e85" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;len&lt;/code&gt; defines a substring that would extend beyond the length of the input string, or if &lt;code&gt;len&lt;/code&gt; is negative, then as many characters as possible are used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58c0544760219e22513b48eb9e261f94e98a41ad" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;lengths&lt;/code&gt; has shape &lt;code&gt;[d_1, d_2, ..., d_n]&lt;/code&gt; the resulting tensor &lt;code&gt;mask&lt;/code&gt; has dtype &lt;code&gt;dtype&lt;/code&gt; and shape &lt;code&gt;[d_1, d_2, ..., d_n, maxlen]&lt;/code&gt;, with</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="495c5ec6c6d28f35484c4fc66c26cf6d9595cae1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;mark_as_used&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, which is the default, a new unique name is created and marked as in use. If it's set to &lt;code&gt;False&lt;/code&gt;, the unique name is returned without actually being marked as used. This is useful when the caller simply wants to know what the name to be created will be.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71e15c8d0da73bb687041dfc28fe499db780dc07" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;merge_repeated&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, merge repeated classes in output. This means that if consecutive logits' maximum indices are the same, only the first of these is emitted. The sequence &lt;code&gt;A B B * B * B&lt;/code&gt; (where '*' is the blank label) becomes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bac502b4b4499617b3003913f73281a64e6d6e7" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;merge_repeated&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, merge repeated classes in the output beams. This means that if consecutive entries in a beam are the same, only the first of these is emitted. That is, when the sequence is &lt;code&gt;A B B * B * B&lt;/code&gt; (where '*' is the blank label), the return value is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0984202fa4f5e645b2c5a40e37b9b5a9dd3c9893" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;minlength&lt;/code&gt; and &lt;code&gt;maxlength&lt;/code&gt; are not given, returns a vector with length &lt;code&gt;tf.reduce_max(arr) + 1&lt;/code&gt; if &lt;code&gt;arr&lt;/code&gt; is non-empty, and length 0 otherwise. If &lt;code&gt;weights&lt;/code&gt; are non-None, then index &lt;code&gt;i&lt;/code&gt; of the output stores the sum of the value in &lt;code&gt;weights&lt;/code&gt; at each index where the corresponding value in &lt;code&gt;arr&lt;/code&gt; is &lt;code&gt;i&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f6d4550e5a6bf869f60e3fa1a350b466e933f5c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;name&lt;/code&gt; and &lt;code&gt;index&lt;/code&gt; are both provided, &lt;code&gt;index&lt;/code&gt; will take precedence. Indices are based on order of horizontal graph traversal (bottom-up).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72ec307ac7cb35e0dc1e4fe050cb0aec22f90730" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;name_or_scope&lt;/code&gt; is not None, it is used as is. If &lt;code&gt;name_or_scope&lt;/code&gt; is None, then &lt;code&gt;default_name&lt;/code&gt; is used. In that case, if the same name has been previously used in the same scope, it will be made unique by appending &lt;code&gt;_N&lt;/code&gt; to it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad1c2af83bbee922d1c0918f60ae2fcb275044f9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;new_shape&lt;/code&gt; is None, returns a copy of &lt;code&gt;sp_input&lt;/code&gt; with its shape reset to the tight bounding box of &lt;code&gt;sp_input&lt;/code&gt;. This will be a shape consisting of all zeros if sp_input has no values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ca15a59d7a7782d5db584a1d747b2599f5ff187" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;new_shape&lt;/code&gt; is None, the returned SparseTensor will have a shape [2, 3, 4], which is the tight bounding box of &lt;code&gt;sp_input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2be9809aee367331cf17f4bd9c80ab0565a944bf" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;new_shape&lt;/code&gt; is provided, then it must be larger or equal in all dimensions compared to the shape of &lt;code&gt;sp_input&lt;/code&gt;. When this condition is met, the returned SparseTensor will have its shape reset to &lt;code&gt;new_shape&lt;/code&gt; and its indices and values unchanged from that of &lt;code&gt;sp_input.&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e3e0c6e2098ecdeded1338dea9690c0f2076053" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;num_classes&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt;, then &lt;code&gt;num_classes&lt;/code&gt; will be set to one plus the maximum value in either predictions or labels. Class labels are expected to start at 0. For example, if &lt;code&gt;num_classes&lt;/code&gt; is 3, then the possible labels would be &lt;code&gt;[0, 1, 2]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8cd499df460f2dd2f7fc2c6f79c89aefd06f4920" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;num_diags == 1&lt;/code&gt;, the output tensor is of rank &lt;code&gt;r - 1&lt;/code&gt; with shape &lt;code&gt;[I, J, ..., L, max_diag_len]&lt;/code&gt; and values:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c715ccae994cba7abe259313788d2138f8a5aa1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;num_or_size_splits&lt;/code&gt; is a 1-D Tensor (or list), we call it &lt;code&gt;size_splits&lt;/code&gt; and &lt;code&gt;value&lt;/code&gt; is split into &lt;code&gt;len(size_splits)&lt;/code&gt; elements. The shape of the &lt;code&gt;i&lt;/code&gt;-th element has the same size as the &lt;code&gt;value&lt;/code&gt; except along dimension &lt;code&gt;axis&lt;/code&gt; where the size is &lt;code&gt;size_splits[i]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e425839a9eabf146225bfd1f11c4b5874f2adbe8" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;num_or_size_splits&lt;/code&gt; is an integer, then &lt;code&gt;value&lt;/code&gt; is split along dimension &lt;code&gt;axis&lt;/code&gt; into &lt;code&gt;num_split&lt;/code&gt; smaller tensors. This requires that &lt;code&gt;num_split&lt;/code&gt; evenly divides &lt;code&gt;value.shape[axis]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="450b92a44da53848f27208da6d233973284dc0ae" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;num_partitions&lt;/code&gt; is an &lt;code&gt;int&lt;/code&gt; (not a &lt;code&gt;Tensor&lt;/code&gt;), then this is equivalent to &lt;code&gt;tf.ragged.stack(tf.dynamic_partition(data, partitions, num_partitions))&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4931305edfb2d837c5c9e074234ca80b1ec8bcc3" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;off_value&lt;/code&gt; is not provided, it will default to the value &lt;code&gt;0&lt;/code&gt; with type &lt;code&gt;dtype&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f5adee6d1a5e5c25242f126e70ed57f928baf19" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;on_value&lt;/code&gt; is not provided, it will default to the value &lt;code&gt;1&lt;/code&gt; with type &lt;code&gt;dtype&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be75a55bcf9630188e5d84c928dfdd3d3057e4a9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;op&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; then &lt;code&gt;ignore_existing&lt;/code&gt; must be &lt;code&gt;True&lt;/code&gt; and the new scope resets all colocation and device constraints.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2cfd171ea5e20a03c796a10ad68feaaf52cc516f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;opj&lt;/code&gt; acts like [batch] matrix &lt;code&gt;Aj&lt;/code&gt;, then &lt;code&gt;op_composed&lt;/code&gt; acts like the [batch] matrix formed with the multiplication &lt;code&gt;A1 A2...AJ&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56c5724412cb951216de778a1bb8c5e384913867" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;opj&lt;/code&gt; acts like a [batch] square matrix &lt;code&gt;Aj&lt;/code&gt;, then &lt;code&gt;op_combined&lt;/code&gt; acts like the [batch] square matrix formed by having each matrix &lt;code&gt;Aj&lt;/code&gt; on the main diagonal.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70c95e66ca24f2c6cab4d98e44a70b5b962a0ab7" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;opj&lt;/code&gt; has shape &lt;code&gt;batch_shape_j + [M_j, M_j]&lt;/code&gt;, then the combined operator has shape &lt;code&gt;broadcast_batch_shape + [sum M_j, sum M_j]&lt;/code&gt;, where &lt;code&gt;broadcast_batch_shape&lt;/code&gt; is the mutual broadcast of &lt;code&gt;batch_shape_j&lt;/code&gt;, &lt;code&gt;j = 1,...,J&lt;/code&gt;, assuming the intermediate batch shapes broadcast. Even if the combined shape is well defined, the combined operator's methods may fail due to lack of broadcasting ability in the defining operators' methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d412d219703e29a2801725218983e3abe4d8a5e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;opj&lt;/code&gt; has shape &lt;code&gt;batch_shape_j + [M_j, N_j]&lt;/code&gt;, then the composed operator will have shape equal to &lt;code&gt;broadcast_batch_shape + [prod M_j, prod N_j]&lt;/code&gt;, where the product is over all operators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3035e177d8f7c6c99dae97a0ceb7953b26b8092b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;opj&lt;/code&gt; has shape &lt;code&gt;batch_shape_j + [M_j, N_j]&lt;/code&gt;, then we must have &lt;code&gt;N_j = M_{j+1}&lt;/code&gt;, in which case the composed operator has shape equal to &lt;code&gt;broadcast_batch_shape + [M_1, N_J]&lt;/code&gt;, where &lt;code&gt;broadcast_batch_shape&lt;/code&gt; is the mutual broadcast of &lt;code&gt;batch_shape_j&lt;/code&gt;, &lt;code&gt;j = 1,...,J&lt;/code&gt;, assuming the intermediate batch shapes broadcast. Even if the composed shape is well defined, the composed operator's methods may fail due to lack of broadcasting ability in the defining operators' methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c905352aaa38aa4276b9e3ddc88efb6fafdbe603" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;outputs_from_all_shards&lt;/code&gt; is true, the outputs from all shards of &lt;code&gt;computation&lt;/code&gt; are concatenated back together along their &lt;code&gt;output_shard_axes&lt;/code&gt;. Otherwise, each output is taken from an arbitrary shard.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c1db6d79ffe07ebfaf8de704e064c8ef0b35ebe" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;pad_end&lt;/code&gt; is True, window positions that are past the end of the &lt;code&gt;axis&lt;/code&gt; dimension are padded with &lt;code&gt;pad_value&lt;/code&gt; until the window moves fully past the end of the dimension. Otherwise, only window positions that fully overlap the &lt;code&gt;axis&lt;/code&gt; dimension are produced.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25d3dd5a787fb24d03624723b6ac3cb1fb7aafbe" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;padding = &quot;SAME&quot;&lt;/code&gt;, then:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d24b307563d3f47caf57f6854d09c49e17b493e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;padding = &quot;VALID&quot;&lt;/code&gt;, then:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="daf5b935b68f7f3addfed5f414c654714bb029cb" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;partition_strategy&lt;/code&gt; is &lt;code&gt;&quot;div&quot;&lt;/code&gt;, we assign ids to partitions in a contiguous manner. In this case, 13 ids are split across 5 partitions as: &lt;code&gt;[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8acefec1523d308517a865bae60c7cc0aa4b6057" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;partition_strategy&lt;/code&gt; is &lt;code&gt;&quot;mod&quot;&lt;/code&gt;, we assign each id to partition &lt;code&gt;p = id % len(params)&lt;/code&gt;. For instance, 13 ids are split across 5 partitions as: &lt;code&gt;[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32dcb7eb9b33345678e978099f889acba18b6559" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;pos&lt;/code&gt; specifies an index which is out of range for any of the input strings, then an &lt;code&gt;InvalidArgumentError&lt;/code&gt; is thrown.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f7deb2d39051bc835be02d8f59da912bfcce83c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;preprocess_collapse_repeated&lt;/code&gt; is True, then a preprocessing step runs before loss calculation, wherein repeated labels passed to the loss are merged into single labels. This is useful if the training labels come from, e.g., forced alignments and therefore have unnecessary repetitions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3d718c63c1f1f0484423b570fc9531a8eff9cfe" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ready_op&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt;, the model is not checked for readiness.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7957aaf8b9510d63a4030b611485abaa1905453d" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;reduce_op&lt;/code&gt; == &lt;code&gt;MEAN&lt;/code&gt;: Result (on all replicas): {'a': 2, 'b': [21, 49.5]}</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4c642304f745aaea2e1c1147192fb97d8fc30e1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;reduce_op&lt;/code&gt; == &lt;code&gt;SUM&lt;/code&gt;: Result (on all replicas): {'a': 4, 'b': [42, 99]}</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0e30804ebbc33a2fc0166b120175f12f1b8b76b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;reduction_axes&lt;/code&gt; has no entries, all dimensions are reduced, and a tensor with a single element is returned. Additionally, the axes can be negative, similar to the indexing rules in Python.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="482cc696ec3bec581c709c5132a29fbf3c487797" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;reduction_axes&lt;/code&gt; has no entries, all dimensions are reduced, and a tensor with a single element is returned. Additionally, the axes can be negative, which are interpreted according to the indexing rules in Python.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f48379c242cda6f408083ddc4d5f3cb83c5bd03" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;return_sequences&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e96de43a368a04807126c38f92e9d01f46e8303" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;return_sequences&lt;/code&gt;: N-D tensor with shape &lt;code&gt;[batch_size, timesteps, output_size]&lt;/code&gt;, where &lt;code&gt;output_size&lt;/code&gt; could be a high dimension tensor shape, or &lt;code&gt;[timesteps, batch_size, output_size]&lt;/code&gt; when &lt;code&gt;time_major&lt;/code&gt; is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8de50555e0eeebb193b44d9f99c305b469369c4a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;return_state&lt;/code&gt;: a list of tensors. The first tensor is the output. The remaining tensors are the last states, each with shape &lt;code&gt;[batch_size, state_size]&lt;/code&gt;, where &lt;code&gt;state_size&lt;/code&gt; could be a high dimension tensor shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ffb605686f7d9f5fc6c475658638babbcf6232d7" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;sample_weight&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt;, weights default to 1. Use &lt;code&gt;sample_weight&lt;/code&gt; of 0 to mask values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e28d91535a97ad650cc949f37258bb71da692f0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;sample_weight&lt;/code&gt; is given, calculates the sum of the weights of false negatives. This metric creates one local variable, &lt;code&gt;accumulator&lt;/code&gt; that is used to keep track of the number of false negatives.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="255358980ac8b58546dfe37fcb80b61a3fab0190" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;sample_weight&lt;/code&gt; is given, calculates the sum of the weights of false positives. This metric creates one local variable, &lt;code&gt;accumulator&lt;/code&gt; that is used to keep track of the number of false positives.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a327cf38b6bc10153f472fc600865ad7c34dc87" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;sample_weight&lt;/code&gt; is given, calculates the sum of the weights of true negatives. This metric creates one local variable, &lt;code&gt;accumulator&lt;/code&gt; that is used to keep track of the number of true negatives.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="157668b96cb6839360efaa68f2be010a0995a4ca" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;sample_weight&lt;/code&gt; is given, calculates the sum of the weights of true positives. This metric creates one local variable, &lt;code&gt;true_positives&lt;/code&gt; that is used to keep track of the number of true positives.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bffe63db0549b3cd56cefe8885a84cdb4b1bd6c3" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;sep&lt;/code&gt; is an empty string, each element of the &lt;code&gt;source&lt;/code&gt; is split into individual strings, each containing one byte. (This includes splitting multibyte sequences of UTF-8.) If delimiter contains multiple bytes, it is treated as a set of delimiters with each considered a potential split point.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9fdfb5a1f94fc643caca96a1c21220a86e536291" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;sep&lt;/code&gt; is given, consecutive delimiters are not grouped together and are deemed to delimit empty strings. For example, &lt;code&gt;input&lt;/code&gt; of &lt;code&gt;&quot;1&amp;lt;&amp;gt;2&amp;lt;&amp;gt;&amp;lt;&amp;gt;3&quot;&lt;/code&gt; and &lt;code&gt;sep&lt;/code&gt; of &lt;code&gt;&quot;&amp;lt;&amp;gt;&quot;&lt;/code&gt; returns &lt;code&gt;[&quot;1&quot;, &quot;2&quot;, &quot;&quot;, &quot;3&quot;]&lt;/code&gt;. If &lt;code&gt;sep&lt;/code&gt; is None or an empty string, consecutive whitespace are regarded as a single separator, and the result will contain no empty strings at the start or end if the string has leading or trailing whitespace.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="410d562c0da8a3bf9960cfbc34a9467e74826468" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;sequence&lt;/code&gt; format, &lt;code&gt;diagonals&lt;/code&gt; is list or tuple of three tensors: &lt;code&gt;[superdiag, maindiag, subdiag]&lt;/code&gt;, each having shape [..., M]. Last element of &lt;code&gt;superdiag&lt;/code&gt; first element of &lt;code&gt;subdiag&lt;/code&gt; are ignored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7934bc8a2624320349f9c139def414a89ff0e04b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;session.run()&lt;/code&gt; raises any exceptions then &lt;code&gt;after_run()&lt;/code&gt; is not called.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09784c2129ebb38568a3c1d9df7ccc60926fc6ed" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;session.run()&lt;/code&gt; raises exception other than OutOfRangeError or StopIteration then &lt;code&gt;end()&lt;/code&gt; is not called. Note the difference between &lt;code&gt;end()&lt;/code&gt; and &lt;code&gt;after_run()&lt;/code&gt; behavior when &lt;code&gt;session.run()&lt;/code&gt; raises OutOfRangeError or StopIteration. In that case &lt;code&gt;end()&lt;/code&gt; is called but &lt;code&gt;after_run()&lt;/code&gt; is not called.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26186007203a58d8911a11ba346690902e600819" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;shape&lt;/code&gt; is set, the &lt;code&gt;value&lt;/code&gt; is reshaped to match. Scalars are expanded to fill the &lt;code&gt;shape&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69ba8d826fa53cdf396fee409e1ec4f0ecdb1a26" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;shape&lt;/code&gt; is specified, then the result is padded and/or truncated to the specified shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3306aee7110cf653f0faca81ca3e2580c65d51bf" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;sp_ids.dense_shape = [D0, D1, ..., Dn, K]&lt;/code&gt;, then &lt;code&gt;output.shape = [D0, D1, ..., Dn, vocab_size]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8902e3e27b9aa6fb1875d3d80d84c7f114fa6048" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;start[i] &amp;lt; limits[i] and deltas[i] &amp;gt; 0&lt;/code&gt;, then &lt;code&gt;output[i]&lt;/code&gt; will be an empty list. Similarly, if &lt;code&gt;start[i] &amp;gt; limits[i] and deltas[i] &amp;lt; 0&lt;/code&gt;, then &lt;code&gt;output[i]&lt;/code&gt; will be an empty list. This behavior is consistent with the Python &lt;code&gt;range&lt;/code&gt; function, but differs from the &lt;a href=&quot;../range&quot;&gt;&lt;code&gt;tf.range&lt;/code&gt;&lt;/a&gt; op, which returns an error for these cases.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5badd1435f6f82ed12933a662ffbe1ffaf9781d4" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;state_size&lt;/code&gt; is a nested list or tuple, then the return value is a nested list or tuple (of the same structure) of &lt;code&gt;2-D&lt;/code&gt; tensors with the shapes &lt;code&gt;[batch_size, s]&lt;/code&gt; for each s in &lt;code&gt;state_size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07e559f7a73c999870c14a2000e0cc3df988ce1a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;state_size&lt;/code&gt; is an int or TensorShape, then the return value is a &lt;code&gt;N-D&lt;/code&gt; tensor of shape &lt;code&gt;[batch_size, state_size]&lt;/code&gt; filled with zeros.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4532e386d825d27cc0d8910075cfb30bf2a4f779" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;structure&lt;/code&gt; is a scalar, &lt;code&gt;flat_sequence&lt;/code&gt; must be a single-element list; in this case the return value is &lt;code&gt;flat_sequence[0]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b494d6e33a53c7ae07fa0e82931781adc7922732" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;structure&lt;/code&gt; is or contains a dict instance, the keys will be sorted to pack the flat sequence in deterministic order. This is true also for &lt;code&gt;OrderedDict&lt;/code&gt; instances: their sequence order is ignored, the sorting order of keys is used instead. The same convention is followed in &lt;code&gt;flatten&lt;/code&gt;. This correctly repacks dicts and &lt;code&gt;OrderedDict&lt;/code&gt;s after they have been flattened, and also allows flattening an &lt;code&gt;OrderedDict&lt;/code&gt; and then repacking it back using a corresponding plain dict, or vice-versa. Dictionaries with non-sortable keys cannot be flattened.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80e0188994bf5b19fa20e0c1686170da44726237" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;timer_interval_secs&lt;/code&gt; is None the thread calls &lt;code&gt;target(*args, **kwargs)&lt;/code&gt; repeatedly. Otherwise it calls it every &lt;code&gt;timer_interval_secs&lt;/code&gt; seconds. The thread terminates when a stop is requested.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76359a8d4d73a2a3ba1c31d55e4ea69973764917" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;timer_interval_secs&lt;/code&gt; is None the thread calls &lt;code&gt;target(args)&lt;/code&gt; repeatedly. Otherwise &lt;code&gt;target(args)&lt;/code&gt; is called every &lt;code&gt;timer_interval_secs&lt;/code&gt; seconds. The thread terminates when a stop of the coordinator is requested.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39df2528537689a6ff6d7670c2bc27741338adc3" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;top_k&lt;/code&gt; is set, recall will be computed as how often on average a class among the labels of a batch entry is in the top-k predictions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="22ad2e08fc56749566578c3ac9018bef993d749c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;top_k&lt;/code&gt; is set, we'll calculate precision as how often on average a class among the top-k classes with the highest predicted values of a batch entry is correct and can be found in the label for that entry.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b4920d5aadd2fd1903db2747b34401a1a55495e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;trainable&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; the variable is also added to the graph collection &lt;code&gt;GraphKeys.TRAINABLE_VARIABLES&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d94e19ec763d0a214f62d7c38f7e3bd893e8f1e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;use_mini_batch&lt;/code&gt; is False, it runs standard full batch K-means. Each training step runs a single iteration of K-Means and must process the full input at once. To run in this mode, the &lt;code&gt;input_fn&lt;/code&gt; passed to &lt;code&gt;train&lt;/code&gt; must return the entire input dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbda24875bef97bbb29fa5aa5d61e455a7519b95" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;use_mini_batch&lt;/code&gt; is True, it runs a generalization of the mini-batch K-means algorithm. It runs multiple iterations, where each iteration is composed of &lt;code&gt;mini_batch_steps_per_iteration&lt;/code&gt; steps. Each training step accumulates the contribution from one mini-batch into temporary storage. Every &lt;code&gt;mini_batch_steps_per_iteration&lt;/code&gt; steps, the cluster centers are updated and the temporary storage cleared for the next iteration. For example: the entire dataset contains 64k examples, where the batch size is 64. User can choose mini_batch_steps_per_iteration = 100 to run 10% of the entire data every iteration in order to update the cluster centers. Note that: * If &lt;code&gt;mini_batch_steps_per_iteration=1&lt;/code&gt;, the algorithm reduces to the standard K-means mini-batch algorithm. * If &lt;code&gt;mini_batch_steps_per_iteration = num_inputs / batch_size&lt;/code&gt;, the algorithm becomes an asynchronous version of the full-batch algorithm. However, there is no guarantee by this implementation that each input is seen exactly once per iteration. Also, different updates are applied asynchronously without locking. So this asynchronous version may not behave exactly like a full-batch version.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f123d9bcbe68894415e895e218694c01aa94734" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;value&lt;/code&gt; is an &lt;code&gt;IndexedSlices&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt; it is returned unmodified. Otherwise, it is converted to a &lt;code&gt;Tensor&lt;/code&gt; using &lt;code&gt;convert_to_tensor()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f99b9bc1783a763e0074d7f02eada525fcb32905" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;value&lt;/code&gt; is empty, the result is &lt;code&gt;nan&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc11671e327afed930dbaa313b8e03a128124801" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;values&lt;/code&gt; is a &lt;code&gt;TensorProto&lt;/code&gt;, it is immediately returned; &lt;code&gt;dtype&lt;/code&gt; and &lt;code&gt;shape&lt;/code&gt; are ignored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="adcccd399060c3499bb9a842249a7c23159bb96d" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;var&lt;/code&gt; is mirrored across multiple devices, then this implements logic like:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f399b1c4fa48e152a02dd3bfffed24395c183ec" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;var_list&lt;/code&gt; is empty, however, the function still returns an Op that can be run. That Op just has no effect.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42bb3b276bc1fc0235ac461a83cafa45706822f7" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;variational_recurrent&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt; (&lt;strong&gt;NOT&lt;/strong&gt; the default behavior), then the same dropout mask is applied at every step, as described in: &lt;a href=&quot;https://arxiv.org/abs/1512.05287&quot;&gt;A Theoretically Grounded Application of Dropout in Recurrent Neural Networks. Y. Gal, Z. Ghahramani&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="237eb51162671a05da58da5d5961835a0202c7b8" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;weight_column&lt;/code&gt; is specified, weights must be of shape &lt;code&gt;[D0, D1, ... DN]&lt;/code&gt; or &lt;code&gt;[D0, D1, ... DN, 1]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f989491367f7caf9a09da24af74f0b79ec083b91" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;weight_column&lt;/code&gt; is specified, weights must be of shape &lt;code&gt;[D0, D1, ... DN]&lt;/code&gt;, &lt;code&gt;[D0, D1, ... DN, 1]&lt;/code&gt; or &lt;code&gt;[D0, D1, ... DN, label_dimension]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84597725a0c8b36564c590276f692f8221e6d0bc" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;weight_column&lt;/code&gt; is specified, weights must be of shape &lt;code&gt;[D0, D1, ... DN]&lt;/code&gt;, or &lt;code&gt;[D0, D1, ... DN, 1]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4b457250beb9be8c779a4f43124b54d808dbb483" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;weights&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt;, weights default to 1. Use weights of 0 to mask values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ada8b39f6dc45d6686ae7823833c9a7be0ec5faf" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;weights&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;, then each prediction contributes its corresponding weight to the total value of the confusion matrix cell.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34ed67f8fd358a60d4e9d51cdfe3288db982de76" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;width&lt;/code&gt; or &lt;code&gt;height&lt;/code&gt; is greater than the specified &lt;code&gt;target_width&lt;/code&gt; or &lt;code&gt;target_height&lt;/code&gt; respectively, this op centrally crops along that dimension. If &lt;code&gt;width&lt;/code&gt; or &lt;code&gt;height&lt;/code&gt; is smaller than the specified &lt;code&gt;target_width&lt;/code&gt; or &lt;code&gt;target_height&lt;/code&gt; respectively, this op centrally pads with 0 along that dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92ed9d6131464277d99f7646cff60c8796c93393" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x &amp;lt; y&lt;/code&gt;, the &lt;code&gt;tf.add&lt;/code&gt; operation will be executed and &lt;code&gt;tf.square&lt;/code&gt; operation will not be executed. Since &lt;code&gt;z&lt;/code&gt; is needed for at least one branch of the &lt;code&gt;cond&lt;/code&gt;, the &lt;a href=&quot;../../math/multiply&quot;&gt;&lt;code&gt;tf.multiply&lt;/code&gt;&lt;/a&gt; operation is always executed, unconditionally.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f425000aaa59c101d7ba3f9fb85256ac75c9e8e4" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x &amp;lt; y&lt;/code&gt;, the &lt;code&gt;tf.add&lt;/code&gt; operation will be executed and &lt;code&gt;tf.square&lt;/code&gt; operation will not be executed. Since &lt;code&gt;z&lt;/code&gt; is needed for at least one branch of the &lt;code&gt;cond&lt;/code&gt;, the &lt;a href=&quot;math/multiply&quot;&gt;&lt;code&gt;tf.multiply&lt;/code&gt;&lt;/a&gt; operation is always executed, unconditionally.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e96c4fa15a730ffac011c15425ea745071f028e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are not equal, &lt;code&gt;message&lt;/code&gt;, as well as the first &lt;code&gt;summarize&lt;/code&gt; entries of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are printed, and &lt;code&gt;InvalidArgumentError&lt;/code&gt; is raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad1bd6d19f89942e84389e6c169c715ab56481a5" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are reals, this will return the floating-point division.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91834a574113cb46f5aae57836f11c53a2984dba" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; has a different rank, &lt;code&gt;message&lt;/code&gt;, as well as the shape of &lt;code&gt;x&lt;/code&gt; are printed, and &lt;code&gt;InvalidArgumentError&lt;/code&gt; is raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee4c81ef26436a2682343a27498b170ef1bb7eff" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; has a non-integer type, &lt;code&gt;message&lt;/code&gt;, as well as the dtype of &lt;code&gt;x&lt;/code&gt; are printed, and &lt;code&gt;InvalidArgumentError&lt;/code&gt; is raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91d266cfb0782577238e40aae35cafb92819efcb" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; has a rank lower than &lt;code&gt;rank&lt;/code&gt;, &lt;code&gt;message&lt;/code&gt;, as well as the shape of &lt;code&gt;x&lt;/code&gt; are printed, and &lt;code&gt;InvalidArgumentError&lt;/code&gt; is raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0d7c16b1c964db596a362f7e65c837d16f72864" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; has shape &lt;code&gt;(s1, s2, s3)&lt;/code&gt; and &lt;code&gt;axis&lt;/code&gt; is &lt;code&gt;1&lt;/code&gt;, the output will have shape &lt;code&gt;(s1, s2 * rep, s3)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="462b9044715afd0ebdf56bf7fbea531186505184" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; is a &lt;code&gt;SparseTensor&lt;/code&gt;, returns &lt;code&gt;SparseTensor(x.indices, tf.math.abs(x.values, ...), x.dense_shape)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c4aba8143c54e7a6d9e46a577473bf33d777660" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; is a &lt;code&gt;SparseTensor&lt;/code&gt;, returns &lt;code&gt;SparseTensor(x.indices, tf.math.bessel_i0e(x.values, ...), x.dense_shape)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c627df3998e3060d22ab74298fa9d1cd985e9495" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; is a &lt;code&gt;SparseTensor&lt;/code&gt;, returns &lt;code&gt;SparseTensor(x.indices, tf.math.bessel_i1e(x.values, ...), x.dense_shape)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44f9cddabc7760ae0a95bb7dd6468e150137da94" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; is a &lt;code&gt;SparseTensor&lt;/code&gt;, returns &lt;code&gt;SparseTensor(x.indices, tf.math.erf(x.values, ...), x.dense_shape)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c5e7efe72880d19e7af394d00d8433be450c92d" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; is a &lt;code&gt;SparseTensor&lt;/code&gt;, returns &lt;code&gt;SparseTensor(x.indices, tf.math.negative(x.values, ...), x.dense_shape)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e07936dab82ee4885e6d659527e4c5ac457c891" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; is a &lt;code&gt;SparseTensor&lt;/code&gt;, returns &lt;code&gt;SparseTensor(x.indices, tf.math.sign(x.values, ...), x.dense_shape)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42088fc82e406aa5224d738cba01bdcc601c6795" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; is a &lt;code&gt;SparseTensor&lt;/code&gt;, returns &lt;code&gt;SparseTensor(x.indices, tf.math.sqrt(x.values, ...), x.dense_shape)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0e3946f9af72ad0a07071e4e7717e70504b6aaf" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; is a &lt;code&gt;SparseTensor&lt;/code&gt;, returns &lt;code&gt;SparseTensor(x.indices, tf.math.square(x.values, ...), x.dense_shape)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40ba052d0ea61514a5070671f03e1e45a14734d0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; is a &lt;code&gt;SparseTensor&lt;/code&gt;, returns &lt;code&gt;SparseTensor(x.indices, tf.math.tanh(x.values, ...), x.dense_shape)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37f745c2ffe497f380fc665cd9e1671ab1f2a720" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; is a tensor and &lt;code&gt;coeffs&lt;/code&gt; is a list n + 1 tensors, this function returns the value of the n-th order polynomial</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69e057f1302f585f5922f3c3a18b760dc9042871" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; is not &amp;gt;= 0 everywhere, &lt;code&gt;message&lt;/code&gt;, as well as the first &lt;code&gt;summarize&lt;/code&gt; entries of &lt;code&gt;x&lt;/code&gt; are printed, and &lt;code&gt;InvalidArgumentError&lt;/code&gt; is raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9d353171456976e630d0a86d03f725176648c08" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; is not &amp;lt;= 0 everywhere, &lt;code&gt;message&lt;/code&gt;, as well as the first &lt;code&gt;summarize&lt;/code&gt; entries of &lt;code&gt;x&lt;/code&gt; are printed, and &lt;code&gt;InvalidArgumentError&lt;/code&gt; is raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a80fa1fece372f13db8582203c7da75b28f136c8" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; is not greater or equal to &lt;code&gt;y&lt;/code&gt; element-wise, &lt;code&gt;message&lt;/code&gt;, as well as the first &lt;code&gt;summarize&lt;/code&gt; entries of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are printed, and &lt;code&gt;InvalidArgumentError&lt;/code&gt; is raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8945369b8f94d01838a340d55daf17a3d1d0af50" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; is not greater than &lt;code&gt;y&lt;/code&gt; element-wise, &lt;code&gt;message&lt;/code&gt;, as well as the first &lt;code&gt;summarize&lt;/code&gt; entries of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are printed, and &lt;code&gt;InvalidArgumentError&lt;/code&gt; is raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73a28e0a51a5a1358482bd1d2c5d701b270800d0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; is not less or equal than &lt;code&gt;y&lt;/code&gt; element-wise, &lt;code&gt;message&lt;/code&gt;, as well as the first &lt;code&gt;summarize&lt;/code&gt; entries of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are printed, and &lt;code&gt;InvalidArgumentError&lt;/code&gt; is raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50217a1adc5af624b2db0c79520eab9a84830ef9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; is not less than &lt;code&gt;y&lt;/code&gt; element-wise, &lt;code&gt;message&lt;/code&gt;, as well as the first &lt;code&gt;summarize&lt;/code&gt; entries of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are printed, and &lt;code&gt;InvalidArgumentError&lt;/code&gt; is raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6794554e1188cfc1e4c17fab928f93b523433cc" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; is not negative everywhere, &lt;code&gt;message&lt;/code&gt;, as well as the first &lt;code&gt;summarize&lt;/code&gt; entries of &lt;code&gt;x&lt;/code&gt; are printed, and &lt;code&gt;InvalidArgumentError&lt;/code&gt; is raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68a88deab70057f102ed7d4f57ffb05621b00f45" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; is not positive everywhere, &lt;code&gt;message&lt;/code&gt;, as well as the first &lt;code&gt;summarize&lt;/code&gt; entries of &lt;code&gt;x&lt;/code&gt; are printed, and &lt;code&gt;InvalidArgumentError&lt;/code&gt; is raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05ca699d60153153cfb210e0569b848d0973f500" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; is real, it is returned unchanged.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a945f29840dadf91f914c8be913e68d58d4600b8" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt; or &lt;code&gt;y&lt;/code&gt; is complex, the Jacobian will still be real but the corresponding Jacobian dimension(s) will be twice as large. This is required even if both input and output is complex since TensorFlow graphs are not necessarily holomorphic, and may have gradients not expressible as complex numbers. For example, if &lt;code&gt;x&lt;/code&gt; is complex with shape &lt;code&gt;[m]&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; is complex with shape &lt;code&gt;[n]&lt;/code&gt;, each Jacobian &lt;code&gt;J&lt;/code&gt; will have shape &lt;code&gt;[m * 2, n * 2]&lt;/code&gt; with</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b72659759aef98d470e47569f98300becf74fe6a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;, &lt;code&gt;param&lt;/code&gt; or &lt;code&gt;scalar&lt;/code&gt; does not have a shape that satisfies all specified constraints, &lt;code&gt;message&lt;/code&gt;, as well as the first &lt;code&gt;summarize&lt;/code&gt; entries of the first encountered violating tensor are printed, and &lt;code&gt;InvalidArgumentError&lt;/code&gt; is raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb4201e11c9c9b78cc34cdf99933fa6d07a53697" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;y&lt;/code&gt; is negative, or greater than or equal to than the width of &lt;code&gt;x&lt;/code&gt; in bits the result is implementation defined.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01d4e2631b92dda8971f5f7cd4af31e88891e1af" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;y&lt;/code&gt; is negative, or greater than or equal to the width of &lt;code&gt;x&lt;/code&gt; in bits the result is implementation defined.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="630404ed0aa98c724f5f45b2443214bdd9885f07" translate="yes" xml:space="preserve">
          <source>If &lt;em&gt;all&lt;/em&gt; underlying ClusterSpecs expose the set of workers as lists, we will concatenate the lists of workers, starting with the list of workers from the first ClusterResolver passed into the constructor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="271b382563c95b776c249c61da000dbb2aa88697" translate="yes" xml:space="preserve">
          <source>If &lt;em&gt;any&lt;/em&gt; of the ClusterSpecs expose the set of workers as a dict, we will treat all the sets of workers as dicts (even if they are returned as lists) and will only merge them into a dict if there is no conflicting keys. If there is a conflicting key, we will raise a &lt;code&gt;KeyError&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9477cf4113441b48552d8e491777b39b333163eb" translate="yes" xml:space="preserve">
          <source>If JIT compilation is enabled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3e656fc2aac4582c753c4ae45093be443f6a61f" translate="yes" xml:space="preserve">
          <source>If a &lt;a href=&quot;../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt; is used to compute gradients instead of &lt;a href=&quot;../../optimizers/optimizer#minimize&quot;&gt;&lt;code&gt;LossScaleOptimizer.minimize&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;lossscaleoptimizer#get_gradients&quot;&gt;&lt;code&gt;LossScaleOptimizer.get_gradients&lt;/code&gt;&lt;/a&gt;, the loss and gradients must be scaled manually. This can be done by calling &lt;a href=&quot;lossscaleoptimizer#get_scaled_loss&quot;&gt;&lt;code&gt;LossScaleOptimizer.get_scaled_loss&lt;/code&gt;&lt;/a&gt; before passing the loss to &lt;a href=&quot;../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;lossscaleoptimizer#get_unscaled_gradients&quot;&gt;&lt;code&gt;LossScaleOptimizer.get_unscaled_gradients&lt;/code&gt;&lt;/a&gt; after computing the gradients with &lt;a href=&quot;../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;. For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c62a01cf3e585d852286d2db8a969d75001530e3" translate="yes" xml:space="preserve">
          <source>If a &lt;a href=&quot;compat/v1/session&quot;&gt;&lt;code&gt;tf.compat.v1.Session&lt;/code&gt;&lt;/a&gt; is used, an &lt;code&gt;Operation&lt;/code&gt; of a &lt;a href=&quot;graph&quot;&gt;&lt;code&gt;tf.Graph&lt;/code&gt;&lt;/a&gt; can be executed by passing it to &lt;code&gt;tf.Session.run&lt;/code&gt;. &lt;code&gt;op.run()&lt;/code&gt; is a shortcut for calling &lt;code&gt;tf.compat.v1.get_default_session().run(op)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="865785682fb36eb7c051375ddba9ba312f45e409" translate="yes" xml:space="preserve">
          <source>If a &lt;code&gt;CheckpointManager&lt;/code&gt; was previously used in &lt;code&gt;directory&lt;/code&gt;, its state will be restored. This includes the list of managed checkpoints and the timestamp bookkeeping necessary to support &lt;code&gt;keep_checkpoint_every_n_hours&lt;/code&gt;. The behavior of the new &lt;code&gt;CheckpointManager&lt;/code&gt; will be the same as the previous &lt;code&gt;CheckpointManager&lt;/code&gt;, including cleaning up existing checkpoints if appropriate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e64e8f1b8de75ff0a5ee5be594f66e107865c9e" translate="yes" xml:space="preserve">
          <source>If a &lt;code&gt;DeviceSpec&lt;/code&gt; is partially specified, it will be merged with other &lt;code&gt;DeviceSpec&lt;/code&gt;s according to the scope in which it is defined. &lt;code&gt;DeviceSpec&lt;/code&gt; components defined in inner scopes take precedence over those defined in outer scopes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b14ed379de0c6fb8eb346774c644654872622bf9" translate="yes" xml:space="preserve">
          <source>If a &lt;code&gt;timeout_fn&lt;/code&gt; was specified, that function is called and if it returns a true boolean value the iterator stops yielding.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ec58a27134b5cd408fe0ba957abfdf776222edc" translate="yes" xml:space="preserve">
          <source>If a custom &lt;code&gt;window_fn&lt;/code&gt; is used with &lt;a href=&quot;stft&quot;&gt;&lt;code&gt;tf.signal.stft&lt;/code&gt;&lt;/a&gt;, it must be passed to &lt;a href=&quot;inverse_stft_window_fn&quot;&gt;&lt;code&gt;tf.signal.inverse_stft_window_fn&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04707a712ceddb742b3bc71b93c045408830d3e4" translate="yes" xml:space="preserve">
          <source>If a default TensorFlow session is available, we will return it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="213ed962ed066bee6b7b5cbd37c8e4427241d34e" translate="yes" xml:space="preserve">
          <source>If a dimension should not be cropped, pass the full size of that dimension. For example, RGB images can be cropped with &lt;code&gt;size = [crop_height, crop_width, 3]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="505d4a9c3cd6d1154b285ae8ef2d9c20d907de11" translate="yes" xml:space="preserve">
          <source>If a key is not present in the table, it is silently ignored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e8f77e769af992f7a98efcdf6867f7871af8dee" translate="yes" xml:space="preserve">
          <source>If a matrix is not invertible there is no guarantee what the op does. It may detect the condition and raise an exception or it may simply return a garbage result.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b9178c569fd77ec0b3d985f9eb129b9d6a07af9f" translate="yes" xml:space="preserve">
          <source>If a non-TPU name is used when constructing a TPUClusterResolver, that will be returned instead (e.g. If the tpus argument's value when constructing this TPUClusterResolver was 'grpc://10.240.1.2:8470', 'grpc://10.240.1.2:8470' will be returned).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8aa2a02a92b82ba7a81289463203b5673fab674" translate="yes" xml:space="preserve">
          <source>If a particular element is zero, the reciprocal for that element is also set to zero.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d73c24b67d544bb4ac9de98fe14e9ccd643c7a4d" translate="yes" xml:space="preserve">
          <source>If a partitioner is provided, a &lt;code&gt;PartitionedVariable&lt;/code&gt; is returned. Accessing this object as a &lt;code&gt;Tensor&lt;/code&gt; returns the shards concatenated along the partition axis.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2123a41f061b2e74cae724869e7d376295c37aa5" translate="yes" xml:space="preserve">
          <source>If a task_type and task_id is given, this will override the &lt;code&gt;master&lt;/code&gt; string passed into the initialization function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="523e96cfbd593dd2c3baf3ac9053a63ba05d9124" translate="yes" xml:space="preserve">
          <source>If a tensor is produced by an operation of type &lt;code&gt;&quot;Foo&quot;&lt;/code&gt;, its shape may be inferred if there is a registered shape function for &lt;code&gt;&quot;Foo&quot;&lt;/code&gt;. See &lt;a href=&quot;https://tensorflow.org/extend/adding_an_op#shape_functions_in_c&quot;&gt;Shape functions&lt;/a&gt; for details of shape functions and how to register them. Alternatively, the shape may be set explicitly using &lt;a href=&quot;tensor#set_shape&quot;&gt;&lt;code&gt;tf.Tensor.set_shape&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="243834e6c2d91813583c07dbf83d5550f40b05d8" translate="yes" xml:space="preserve">
          <source>If a variable has a moving average, use the moving average variable name as the restore name; otherwise, use the variable name.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f642e4be5d733e10310c09fcad00792974d1e540" translate="yes" xml:space="preserve">
          <source>If all of these are true, then 2 properties are enforced by the template:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5c6117c645e2d99da3c1e80d1e84fe0fe64cc20" translate="yes" xml:space="preserve">
          <source>If amsgrad = False: Initialization:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b404c2a8925caf71a7bb356a68b571d47740e1b" translate="yes" xml:space="preserve">
          <source>If amsgrad = True: Initialization:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5cf3f3e1c44e12d92c5b7fbf8235942d050af3de" translate="yes" xml:space="preserve">
          <source>If an &lt;code&gt;ExponentialMovingAverage&lt;/code&gt; object is created and the &lt;code&gt;apply()&lt;/code&gt; method is called on a list of variables, these variables will be added to the &lt;code&gt;GraphKeys.MOVING_AVERAGE_VARIABLES&lt;/code&gt; collection. This convenience function returns the contents of that collection.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0573b0aef7d01f68ba24860a81d945b1c44866a3" translate="yes" xml:space="preserve">
          <source>If an &lt;code&gt;initializer&lt;/code&gt; is provided, then the output of &lt;code&gt;fn&lt;/code&gt; must have the same structure as &lt;code&gt;initializer&lt;/code&gt;; and the first argument of &lt;code&gt;fn&lt;/code&gt; must match this structure.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f4864ad2daae673720e2d27a04ea8d707ae17bf" translate="yes" xml:space="preserve">
          <source>If an exception has been passed to &lt;code&gt;request_stop&lt;/code&gt;, this raises it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0f250f8ea55b97372b4bf0fcda3313dba275f0b" translate="yes" xml:space="preserve">
          <source>If an input feature is of numeric type, you can use &lt;code&gt;categorical_column_with_identity&lt;/code&gt;, or &lt;code&gt;bucketized_column&lt;/code&gt;, as in the example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86d660c47dfcbd8f8bb7bbe04503dea8a280958f" translate="yes" xml:space="preserve">
          <source>If an unordered dictionary is used for &lt;code&gt;pred_fn_pairs&lt;/code&gt;, the order of the conditional tests is not guaranteed. However, the order is guaranteed to be deterministic, so that variables created in conditional branches are created in fixed order across runs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab7bb5e26ed6f3d67fb39638574da3ab5aaddabc" translate="yes" xml:space="preserve">
          <source>If any downstream layer does not support masking yet receives such an input mask, an exception will be raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="634aed1eed17dfb056b4ad2197a898ad89414116" translate="yes" xml:space="preserve">
          <source>If any elements of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are equal, &lt;code&gt;message&lt;/code&gt;, as well as the first &lt;code&gt;summarize&lt;/code&gt; entries of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are printed, and &lt;code&gt;InvalidArgumentError&lt;/code&gt; is raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7d1ad99b5dd0129899030412bf73fb9c778531c" translate="yes" xml:space="preserve">
          <source>If any elements of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are not close, &lt;code&gt;message&lt;/code&gt;, as well as the first &lt;code&gt;summarize&lt;/code&gt; entries of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are printed, and &lt;code&gt;InvalidArgumentError&lt;/code&gt; is raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7ac540ff691a4908db4956927f427a38b150efe" translate="yes" xml:space="preserve">
          <source>If axis is specified, min_range and max_range</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa72f53d68fdd3e50b946d2a8a64e217e60056c2" translate="yes" xml:space="preserve">
          <source>If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are None, then this operation returns the coordinates of true elements of &lt;code&gt;condition&lt;/code&gt;. The coordinates are returned in a 2-D tensor where the first dimension (rows) represents the number of true elements, and the second dimension (columns) represents the coordinates of the true elements. Keep in mind, the shape of the output tensor can vary depending on how many true values there are in input. Indices are output in row-major order.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4cc42a8c9ad46f8f728657a164104073727b3972" translate="yes" xml:space="preserve">
          <source>If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7eb29e91b27b7529865331e0ce47bff962ea89f5" translate="yes" xml:space="preserve">
          <source>If both arguments are sparse, we perform &quot;clipping&quot; as follows. By default, if two values sum to zero at some index, the output &lt;code&gt;SparseTensor&lt;/code&gt; would still include that particular location in its index, storing a zero in the corresponding value slot. To override this, callers can specify &lt;code&gt;thresh&lt;/code&gt;, indicating that if the sum has a magnitude strictly smaller than &lt;code&gt;thresh&lt;/code&gt;, its corresponding value and index would then not be included. In particular, &lt;code&gt;thresh == 0.0&lt;/code&gt; (default) means everything is kept and actual thresholding happens only for a positive value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="487e5ccf75b74d8c7372b9cbc5feed31632e6692" translate="yes" xml:space="preserve">
          <source>If both arguments are sparse, we perform &quot;clipping&quot; as follows. By default, if two values sum to zero at some index, the output &lt;code&gt;SparseTensor&lt;/code&gt; would still include that particular location in its index, storing a zero in the corresponding value slot. To override this, callers can specify &lt;code&gt;threshold&lt;/code&gt;, indicating that if the sum has a magnitude strictly smaller than &lt;code&gt;threshold&lt;/code&gt;, its corresponding value and index would then not be included. In particular, &lt;code&gt;threshold == 0.0&lt;/code&gt; (default) means everything is kept and actual thresholding happens only for a positive value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c7781516620b3f8fffd28bff7dc8bb9d94e125f" translate="yes" xml:space="preserve">
          <source>If both classes and scores are set, they are interpreted as zipped, so each score corresponds to the class at the same index. Clients should not depend on the order of the entries.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea8fd75dd7d2ee81283a96566ccce43e17dd69df" translate="yes" xml:space="preserve">
          <source>If both non-None, &lt;code&gt;condition&lt;/code&gt;, &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; must be broadcastable to the same shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="97e1ce433328491ec96b5d0ae14362cbabdcecfd" translate="yes" xml:space="preserve">
          <source>If both non-None, &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; must have the same shape. The &lt;code&gt;condition&lt;/code&gt; tensor must be a scalar if &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are scalar. If &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are tensors of higher rank, then &lt;code&gt;condition&lt;/code&gt; must be either a vector with size matching the first dimension of &lt;code&gt;x&lt;/code&gt;, or must have the same shape as &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="acbf49639653cdfa17021b7bac7ebfe7fd55ca8b" translate="yes" xml:space="preserve">
          <source>If both the global and the operation seed are set: Both seeds are used in conjunction to determine the random sequence.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56d176cd1c614313ea4d92304b5919bf83d47ec0" translate="yes" xml:space="preserve">
          <source>If both the graph-level and the operation seed are set: Both seeds are used in conjunction to determine the random sequence.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93f9f6999464c58974327ddd22b42ad2da9c296b" translate="yes" xml:space="preserve">
          <source>If called with the callable and arguments omitted, will return a context object used like this::</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e4f6a9857dccfef8e796c3e4e86b7476649d934" translate="yes" xml:space="preserve">
          <source>If cmd is 'scope' or 'graph', returns GraphNodeProto proto. If cmd is 'op' or 'code', returns MultiGraphNodeProto proto. Side effect: stdout/file/timeline.json depending on options['output']</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fba8fa85c76e287a1fe2de2a680888f41efe3fe" translate="yes" xml:space="preserve">
          <source>If data_format ='channels_first' 4D tensor with shape: &lt;code&gt;(samples, filters, output_row, output_col)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54b8064bacba3ba82e646ea2151170bb26cf1df6" translate="yes" xml:space="preserve">
          <source>If data_format='channels_first' 5D tensor with shape: &lt;code&gt;(samples, time, channels, rows, cols)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6846cfb3158e1bd91d37169c22b71a8ea3739620" translate="yes" xml:space="preserve">
          <source>If data_format='channels_first' 5D tensor with shape: &lt;code&gt;(samples, time, filters, output_row, output_col)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ac99ea61f4e7b17282390b961f6eda2ff80a416" translate="yes" xml:space="preserve">
          <source>If data_format='channels_last' 4D tensor with shape: &lt;code&gt;(samples, output_row, output_col, filters)&lt;/code&gt; where &lt;code&gt;o_row&lt;/code&gt; and &lt;code&gt;o_col&lt;/code&gt; depend on the shape of the filter and the padding</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75fa04bbee972fde32d36caa3e44ea33b4fe50fc" translate="yes" xml:space="preserve">
          <source>If data_format='channels_last' 5D tensor with shape: &lt;code&gt;(samples, time, output_row, output_col, filters)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00479e6d45ac4e2661436ea4b5a406c2b0a2af7a" translate="yes" xml:space="preserve">
          <source>If data_format='channels_last' 5D tensor with shape: &lt;code&gt;(samples, time, rows, cols, channels)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff536a283d0c5634c5bc5433d6ad8c509ee37ad0" translate="yes" xml:space="preserve">
          <source>If desired_samples is set, then the audio will be cropped or padded with zeroes to the requested length.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64e144d6092560a27e1887bcdaf10a00b30d267c" translate="yes" xml:space="preserve">
          <source>If device placements are logged.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9291d64f354b112d4b4f3e8e525fef7cb19907b" translate="yes" xml:space="preserve">
          <source>If device_fn is not &lt;code&gt;None&lt;/code&gt;, it overrides the default device function used in &lt;code&gt;Estimator&lt;/code&gt;. Otherwise the default one is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94bfffa7113c3bf007ae681c0fa31393f368fdc2" translate="yes" xml:space="preserve">
          <source>If eager execution is enabled ops created under this context manager will be added to the graph instead of executed eagerly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e670cc4a3f83ee25d0b6a6e5c98cd6a71ebb20d0" translate="yes" xml:space="preserve">
          <source>If enabled, an op will be placed on CPU if any of the following are true 1. there's no GPU implementation for the OP 2. no GPU devices are known or registered 3. need to co-locate with reftype input(s) which are from CPU</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb053d1301598dac02cff078c183716e72ed8191" translate="yes" xml:space="preserve">
          <source>If expand_nonconcat_dim is False, all inputs' shapes must match, except for the concat dimension. If expand_nonconcat_dim is True, then inputs' shapes are allowed to vary among all inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cae461a693ecc478ea610fcc38768106721e2c8f" translate="yes" xml:space="preserve">
          <source>If expand_nonconcat_dim is False, then the output shape is identical to the inputs', except along the concat dimension, where it is the sum of the inputs' sizes along that dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6cd7aa57520c6214227753ed1c290366a7b241e" translate="yes" xml:space="preserve">
          <source>If expand_nonconcat_dim is True, then the output shape along the non-concat dimensions will be expand to be the largest among all inputs, and it is the sum of the inputs sizes along the concat dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b6cab13cfa666ca9015cb19f120bb30a762f9b4" translate="yes" xml:space="preserve">
          <source>If initializer is &lt;code&gt;None&lt;/code&gt; (the default), the default initializer passed in the variable scope will be used. If that one is &lt;code&gt;None&lt;/code&gt; too, a &lt;code&gt;glorot_uniform_initializer&lt;/code&gt; will be used. The initializer can also be a Tensor, in which case the variable is initialized to this value and shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c9612495d1ea687b814d88c5bccfce311dbb1b1" translate="yes" xml:space="preserve">
          <source>If input value shapes have rank-&lt;code&gt;R&lt;/code&gt;, then the output TensorArray will contain elements whose shapes are rank-&lt;code&gt;(R-1)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c386ea372433836d4288cf5ce90403d9aebc9525" translate="yes" xml:space="preserve">
          <source>If input_tensor is &lt;code&gt;[&quot;emerson&quot;, &quot;lake&quot;, &quot;palmer&quot;, &quot;king&quot;, &quot;crimson&quot;]&lt;/code&gt;, the lookup result is &lt;code&gt;[0, 1, 2, 4, 7]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3cb57fcb38985bdb74f964ec67623f1bd14e689" translate="yes" xml:space="preserve">
          <source>If inputs are shaped &lt;code&gt;(batch,)&lt;/code&gt; without a channel dimension, then flattening adds an extra channel dimension and output shapes are &lt;code&gt;(batch, 1)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="738230ba7fe766eb31fbdde5eb405514647a0533" translate="yes" xml:space="preserve">
          <source>If instead &lt;code&gt;operator&lt;/code&gt; and &lt;code&gt;x&lt;/code&gt; have shape &lt;code&gt;[B1,...,Bb, M, N]&lt;/code&gt; and &lt;code&gt;[B1,...,Bb, N, R]&lt;/code&gt;, every operation increases in complexity by &lt;code&gt;B1*...*Bb&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f96eb77ff2ebfe9cc28cc3c35cc4a7ac58b190bc" translate="yes" xml:space="preserve">
          <source>If instead &lt;code&gt;operator&lt;/code&gt; and &lt;code&gt;x&lt;/code&gt; have shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; and &lt;code&gt;[B1,...,Bb, N, R]&lt;/code&gt;, every operation increases in complexity by &lt;code&gt;B1*...*Bb&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c63a6d67533a63bed1e0240ed43f76ae36414b8" translate="yes" xml:space="preserve">
          <source>If instead a &lt;code&gt;FixedLenSequenceFeature&lt;/code&gt; with &lt;code&gt;default_value = -1.0&lt;/code&gt; and &lt;code&gt;shape=[]&lt;/code&gt; is used then the output will look like:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40adf7e5387b8489f0ffa9f4f324e8e0ce220b98" translate="yes" xml:space="preserve">
          <source>If int: How many zeros to add at the beginning and end of the padding dimension (axis 1).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c440d21ae6487ba9289b79947d47d6f17645dab0" translate="yes" xml:space="preserve">
          <source>If int: the same symmetric cropping is applied to depth, height, and width.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ad0224bfc863947c553eb515cd3685802c8418c" translate="yes" xml:space="preserve">
          <source>If int: the same symmetric cropping is applied to height and width.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4438a656974fdeb329935741ed684baf3991a64c" translate="yes" xml:space="preserve">
          <source>If int: the same symmetric padding is applied to height and width.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5e13d5017f46659d268ce30f514bf0071b12303" translate="yes" xml:space="preserve">
          <source>If it is None, all &lt;code&gt;device()&lt;/code&gt; invocations from the enclosing context will be ignored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dfc30b45f6aa3b5c14c0ae463c80d1818d9e01fe" translate="yes" xml:space="preserve">
          <source>If it is a device name string, all operations constructed in this context will be assigned to the device with that name, unless overridden by a nested &lt;code&gt;device()&lt;/code&gt; context.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c5baf9468ce1d581b9eebf008c02586f0513f4b8" translate="yes" xml:space="preserve">
          <source>If it is a function, it will be treated as a function from Operation objects to device name strings, and invoked each time a new Operation is created. The Operation will be assigned to the device with the returned name.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c7710d3f3b7456252ed02c1f1e66d4f4bf4c6ac" translate="yes" xml:space="preserve">
          <source>If label_key argument is provided, returns a &lt;code&gt;Dataset&lt;/code&gt; of tuple comprising of feature dictionaries and label.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c424513363e598474e7006a1b25045c0bfee1b11" translate="yes" xml:space="preserve">
          <source>If lower_bound or upper_bound are set, then this flag must be within the given range.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c86764cba8090e4b738e2dccdd96c8da3f0010d" translate="yes" xml:space="preserve">
          <source>If lower_bound, or upper_bound are set, then this flag must be within the given range.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b744a1d7c3b92dd76e179f6bd1b1ff66d763286f" translate="yes" xml:space="preserve">
          <source>If memory growth is enabled for a &lt;code&gt;PhysicalDevice&lt;/code&gt;, the runtime initialization will not allocate all memory on the device.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd3fe4729c6c6665ba5d979840f51083f4d41d85" translate="yes" xml:space="preserve">
          <source>If memory growth is enabled for a &lt;code&gt;PhysicalDevice&lt;/code&gt;, the runtime initialization will not allocate all memory on the device. Memory growth cannot be configured on a &lt;code&gt;PhysicalDevice&lt;/code&gt; with virtual devices configured.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fefb38872b3b0a9ef3e5c04bb1786c3ce57d227f" translate="yes" xml:space="preserve">
          <source>If more than one such registered method exists, the method whose registered classes have the shortest sum MRO paths to the input types is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ae06d56729266c936751b0d6b4a49cea1d77595" translate="yes" xml:space="preserve">
          <source>If more than one such shortest path exists, the first method identified in the search is used (favoring a shorter MRO distance to &lt;code&gt;type(distribution_a)&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="722f663586a3c2fd0a85e136dad3e99bf4d7d908" translate="yes" xml:space="preserve">
          <source>If multiple &lt;code&gt;feature_columns&lt;/code&gt; are given with &lt;code&gt;Di&lt;/code&gt;&lt;code&gt;num_elements&lt;/code&gt; each, their outputs are concatenated. So, the final &lt;code&gt;Tensor&lt;/code&gt; has shape &lt;code&gt;[batch_size, T, D0 + D1 + ... + Dn]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03c107a7651f56240affd9bf4b6bd3d81744ad9c" translate="yes" xml:space="preserve">
          <source>If multiple workers or threads all execute &lt;code&gt;count&lt;/code&gt; in parallel, there is no guarantee that access to the variable &lt;code&gt;v&lt;/code&gt; is atomic at any point within any thread's calculation of &lt;code&gt;count&lt;/code&gt;. In fact, even implementing an atomic counter that guarantees that the user will see each value &lt;code&gt;0, 1, ...,&lt;/code&gt; is currently impossible.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67481c8ed92bcb02951bb04ea04056c1ee8ecbc1" translate="yes" xml:space="preserve">
          <source>If needed, the JPEG-encoded image is transformed to match the requested number of color channels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="675d725df0fc2c1253c204b76da4504e0b572994" translate="yes" xml:space="preserve">
          <source>If needed, the PNG-encoded image is transformed to match the requested number of color channels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a4a46df302381b3a15b3175bfe7b5ee7e4f7f3c" translate="yes" xml:space="preserve">
          <source>If neither the global seed nor the operation seed is set, we get different results for every call to the random op and every re-run of the program:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a80f90092a9cdc14926ec279ccf684a91409808f" translate="yes" xml:space="preserve">
          <source>If neither the global seed nor the operation seed is set: A randomly picked seed is used for this op.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb376915a9049b9705726662829e324ea799d8d9" translate="yes" xml:space="preserve">
          <source>If neither the graph-level nor the operation seed is set: A random seed is used for this op.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53a2b49f6fe46128f61f59f18f91203c8cae5da5" translate="yes" xml:space="preserve">
          <source>If nest is not a sequence, tuple (or a namedtuple), dict, or an attrs class, then returns a single-element list: [nest].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f8fa99a78720209af5fdde779900c0982d9d43c7" translate="yes" xml:space="preserve">
          <source>If no &lt;code&gt;graph&lt;/code&gt; argument is specified when constructing the session, the default graph will be launched in the session. If you are using more than one graph (created with &lt;a href=&quot;../../graph&quot;&gt;&lt;code&gt;tf.Graph()&lt;/code&gt;&lt;/a&gt;) in the same process, you will have to use different sessions for each graph, but each graph can be used in multiple sessions. In this case, it is often clearer to pass the graph to be launched explicitly to the session constructor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e03528b8eed8bab907807380295710ea8ffbc199" translate="yes" xml:space="preserve">
          <source>If no &lt;code&gt;initializer&lt;/code&gt; is provided, the output structure and dtypes of &lt;code&gt;fn&lt;/code&gt; are assumed to be the same as its input; and in this case, the first argument of &lt;code&gt;fn&lt;/code&gt; must match the structure of &lt;code&gt;elems&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4db2dd7673a719bd18a4a69659d6bb176d96588c" translate="yes" xml:space="preserve">
          <source>If no docstring is given, only returns the method name.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a269e9e969aae169d3e3205ccb3dae3b6b4e358" translate="yes" xml:space="preserve">
          <source>If no error is raised, the Op outputs the value of the variable before the increment.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="216c8a5f35ff33f04b721aaf62c762669c33d560" translate="yes" xml:space="preserve">
          <source>If no global Keras session exists at this point: we will create a new global session.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b9d82b8205b36e56cf0f7278c52946e01c5133b" translate="yes" xml:space="preserve">
          <source>If no resource containers are provided, all containers are reset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0c82db29e90e42775efa5d5de870d187dc07ca3" translate="yes" xml:space="preserve">
          <source>If no summaries were collected, returns None. Otherwise returns a scalar &lt;code&gt;Tensor&lt;/code&gt; of type &lt;code&gt;string&lt;/code&gt; containing the serialized &lt;code&gt;Summary&lt;/code&gt; protocol buffer resulting from the merging.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9de9fbe1c63a1ea93130c03e9fe3eb64adbc926" translate="yes" xml:space="preserve">
          <source>If none of a node's properties match the specified regexes, the node is not displayed nor accounted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3fd2102800b8c57e0c21e6fddab9285a922daf0b" translate="yes" xml:space="preserve">
          <source>If not inside a distributed scope, this is equivalent to:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cdaea2a087144406be71543156cf54bff456a8e9" translate="yes" xml:space="preserve">
          <source>If obj is an instance, then it is its class that will actually be stubbed. Note that the method Set() does not do that: if obj is an instance, it (and not its class) will be stubbed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ae90fa036abf3772d3d0631e8f4275b836203c5" translate="yes" xml:space="preserve">
          <source>If on the other hand the spectrum is Hermitian, then this operator corresponds to a real-valued matrix, and setting &lt;code&gt;input_output_dtype&lt;/code&gt; to a real type is fine.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3497dacd218f5e562f9d613938110d69a5766635" translate="yes" xml:space="preserve">
          <source>If one &lt;code&gt;SparseTensor&lt;/code&gt; and one &lt;code&gt;Tensor&lt;/code&gt; are passed in, returns a &lt;code&gt;Tensor&lt;/code&gt;. If both arguments are &lt;code&gt;SparseTensor&lt;/code&gt;s, this returns a &lt;code&gt;SparseTensor&lt;/code&gt;. The order of arguments does not matter. Use vanilla &lt;a href=&quot;../../math/add&quot;&gt;&lt;code&gt;tf.add()&lt;/code&gt;&lt;/a&gt; for adding two dense &lt;code&gt;Tensor&lt;/code&gt;s.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="18fe14991d61b8d26bb58197035c8d2daabc8b92" translate="yes" xml:space="preserve">
          <source>If one &lt;code&gt;SparseTensor&lt;/code&gt; and one &lt;code&gt;Tensor&lt;/code&gt; are passed in, returns a &lt;code&gt;Tensor&lt;/code&gt;. If both arguments are &lt;code&gt;SparseTensor&lt;/code&gt;s, this returns a &lt;code&gt;SparseTensor&lt;/code&gt;. The order of arguments does not matter. Use vanilla &lt;a href=&quot;../math/add&quot;&gt;&lt;code&gt;tf.add()&lt;/code&gt;&lt;/a&gt; for adding two dense &lt;code&gt;Tensor&lt;/code&gt;s.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4f0585e78e733116b83480d150410db915cb539" translate="yes" xml:space="preserve">
          <source>If one KL method is registered between any pairs of classes in these two parent hierarchies, it is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea084c2ad5e28df87d0ca52cc75d071fe917e285" translate="yes" xml:space="preserve">
          <source>If one component of &lt;code&gt;shape&lt;/code&gt; is the special value -1, the size of that dimension is computed so that the total dense size remains constant. At most one component of &lt;code&gt;shape&lt;/code&gt; can be -1. The number of dense elements implied by &lt;code&gt;shape&lt;/code&gt; must be the same as the number of dense elements originally represented by &lt;code&gt;sp_input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bafb2065764a06f54947439b6949d0053558bc8a" translate="yes" xml:space="preserve">
          <source>If one component of &lt;code&gt;shape&lt;/code&gt; is the special value -1, the size of that dimension is computed so that the total size remains constant. In particular, a &lt;code&gt;shape&lt;/code&gt; of &lt;code&gt;[-1]&lt;/code&gt; flattens into 1-D. At most one component of &lt;code&gt;shape&lt;/code&gt; can be -1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b262dc519863d0a0c455b46653404b98d409a27" translate="yes" xml:space="preserve">
          <source>If one of the tasks crashes and restarts, &lt;code&gt;managed_session()&lt;/code&gt; checks if the Model is initialized. If yes, it just creates a session and returns it to the training code that proceeds normally. If the model needs to be initialized, the chief task takes care of reinitializing it; the other tasks just wait for the model to have been initialized.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbb12d851ea0d6c46ec595443cab53217c732f23" translate="yes" xml:space="preserve">
          <source>If one or both of the inputs contain a lot of zeros, a more efficient multiplication algorithm can be used by setting the corresponding &lt;code&gt;a_is_sparse&lt;/code&gt; or &lt;code&gt;b_is_sparse&lt;/code&gt; flag to &lt;code&gt;True&lt;/code&gt;. These are &lt;code&gt;False&lt;/code&gt; by default. This optimization is only available for plain matrices/vectors (rank-2/1 tensors) with datatypes &lt;code&gt;bfloat16&lt;/code&gt; or &lt;code&gt;float32&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17b326f6ea020b628ceba1332baab40e28fbf23a" translate="yes" xml:space="preserve">
          <source>If one or both of the matrices contain a lot of zeros, a more efficient multiplication algorithm can be used by setting the corresponding &lt;code&gt;a_is_sparse&lt;/code&gt; or &lt;code&gt;b_is_sparse&lt;/code&gt; flag to &lt;code&gt;True&lt;/code&gt;. These are &lt;code&gt;False&lt;/code&gt; by default. This optimization is only available for plain matrices (rank-2 tensors) with datatypes &lt;code&gt;bfloat16&lt;/code&gt; or &lt;code&gt;float32&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2cec49ea279d810bcec33c21637d3e3e971bbbb" translate="yes" xml:space="preserve">
          <source>If only classes is set, it is interpreted as providing top-k results in descending order.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75620cc03e8dc3221a8a09a86626829819275026" translate="yes" xml:space="preserve">
          <source>If only scores is set, it is interpreted as providing a score for every class in order of class ID.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2e0db46aec01ec30dc1082790031dd6d15b166e" translate="yes" xml:space="preserve">
          <source>If padding = &quot;SAME&quot;: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i])</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcdcd97fe86754396f4eb68d73df8c9d73f8dba1" translate="yes" xml:space="preserve">
          <source>If padding = &quot;VALID&quot;: output_spatial_shape[i] = ceil((input_spatial_shape[i] - (window_shape[i] - 1) * dilation_rate[i]) / strides[i]).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05f33b626808fecfebc52bc856e9c14717da266f" translate="yes" xml:space="preserve">
          <source>If padding == &quot;SAME&quot;: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i])</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="136aa13ad4e629923ef043b74c86f4e39f2b8ae0" translate="yes" xml:space="preserve">
          <source>If padding == &quot;VALID&quot;: output_spatial_shape[i] = ceil((input_spatial_shape[i] - (spatial_filter_shape[i]-1) * dilation_rate[i]) / strides[i]).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb4fb2200f1abc514276162cb92eabdf216c950b" translate="yes" xml:space="preserve">
          <source>If possible you should use &lt;code&gt;assertRegex&lt;/code&gt;, which is a simpler version of this method. &lt;code&gt;assertRegex&lt;/code&gt; takes a single regular expression (a string or re compiled object) instead of a list.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06742f16b6eea52463f3c33907285332cf099a29" translate="yes" xml:space="preserve">
          <source>If possible, you should use assertCountEqual instead of assertSameElements.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="614678e645a7e3d66b077654721dda0404775036" translate="yes" xml:space="preserve">
          <source>If prefix is an empty sequence, it will raise an error unless whole is also an empty sequence.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47be90f234e2dd2a2a123f6a39d9360729095139" translate="yes" xml:space="preserve">
          <source>If prefix is not a sequence, it will raise an error if the first element of whole does not match.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4456cc620a8e8e1b60e289bbd83d6240b8855aef" translate="yes" xml:space="preserve">
          <source>If previously created threads for the given session are still running, no new threads will be created.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55b41a1af83d2a93715620f2355e250fc52515b3" translate="yes" xml:space="preserve">
          <source>If rate is set to &lt;code&gt;0&lt;/code&gt; the input is returned, unchanged:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5a119b1872be8a1e53e996eedc55e37414996ed" translate="yes" xml:space="preserve">
          <source>If regexes is the empty list, the matching will always fail.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f050a1aecaf98e6e971ad7ddbad7946578f6991" translate="yes" xml:space="preserve">
          <source>If set, it overrides the maximum degree of intra-op parallelism.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="406b1726c99d9d0143b0b00beee8d5df87d7ea20" translate="yes" xml:space="preserve">
          <source>If set, the dataset will use a private threadpool of the given size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67c0f7d09583d4af41119ac2d7c50e6404fd2384" translate="yes" xml:space="preserve">
          <source>If shapes are not known during graph construction time, and during run time it is found out that the ranks do not match.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1814dc3de1048c3554d33e04a6570bd1af7a3688" translate="yes" xml:space="preserve">
          <source>If soft placement is enabled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dcba33c2663325e71d7455b176c4a928e4d72364" translate="yes" xml:space="preserve">
          <source>If that attempt is unsuccessful (e.g. the dataset is created from a Dataset.range), we will shard the dataset evenly at the end by appending a &lt;code&gt;.shard&lt;/code&gt; operation to the end of the processing pipeline. This will cause the entire preprocessing pipeline for all the data to be run on every worker, and each worker will do redundant work. We will print a warning if this method of sharding is selected. In this case, consider using &lt;code&gt;experimental_distribute_datasets_from_function&lt;/code&gt; instead.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3358bfa17db34ad277d96d5332d507879fea9dd9" translate="yes" xml:space="preserve">
          <source>If the &quot;checkpoint&quot; file contains a valid CheckpointState proto, returns it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c85f20c0c380f317916cf91653305134b56d70aa" translate="yes" xml:space="preserve">
          <source>If the &lt;code&gt;enable_dump_debug_info()&lt;/code&gt; method under the same Python namespace has been invoked before, calling this method disables it. If no call to &lt;code&gt;enable_dump_debug_info()&lt;/code&gt; has been made, calling this method is a no-op. Calling this method more than once is idempotent.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a32d73aea60310abf91b1e01ff102173ff94bf4c" translate="yes" xml:space="preserve">
          <source>If the &lt;code&gt;shapes&lt;/code&gt; argument is specified, each component of a queue element must have the respective fixed shape. If it is unspecified, different queue elements may have different shapes, but the use of &lt;code&gt;dequeue_many&lt;/code&gt; is disallowed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7226982fe5b09f7a9182c06848094e1377702d50" translate="yes" xml:space="preserve">
          <source>If the &lt;code&gt;signatures&lt;/code&gt; argument is omitted, &lt;code&gt;obj&lt;/code&gt; will be searched for &lt;code&gt;@tf.function&lt;/code&gt;-decorated methods. If exactly one &lt;code&gt;@tf.function&lt;/code&gt; is found, that method will be used as the default signature for the SavedModel. This behavior is expected to change in the future, when a corresponding &lt;a href=&quot;load&quot;&gt;&lt;code&gt;tf.saved_model.load&lt;/code&gt;&lt;/a&gt; symbol is added. At that point signatures will be completely optional, and any &lt;code&gt;@tf.function&lt;/code&gt; attached to &lt;code&gt;obj&lt;/code&gt; or its dependencies will be exported for use with &lt;code&gt;load&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7fd7e686a1dc65c75a2588abd9db94c81edb3064" translate="yes" xml:space="preserve">
          <source>If the &lt;code&gt;sp_input.dense_shape[axis]&lt;/code&gt; is not an integer multiple of &lt;code&gt;num_split&lt;/code&gt; each slice starting from 0:&lt;code&gt;shape[axis] % num_split&lt;/code&gt; gets extra one dimension. For example, if &lt;code&gt;axis = 1&lt;/code&gt; and &lt;code&gt;num_split = 2&lt;/code&gt; and the input is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="112da864d4b1f24e488ea72104bf36a2900d9125" translate="yes" xml:space="preserve">
          <source>If the above batch splitting and dataset sharding logic is undesirable, please use &lt;code&gt;experimental_distribute_datasets_from_function&lt;/code&gt; instead, which does not do any automatic splitting or sharding.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c05cf6d5da583a19c043c4546b8addef87e9dda3" translate="yes" xml:space="preserve">
          <source>If the answer to several of these questions is yes, consider converting the &lt;code&gt;SparseTensor&lt;/code&gt; to a dense one and using &lt;a href=&quot;../linalg/matmul&quot;&gt;&lt;code&gt;tf.matmul&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;a_is_sparse=True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03d4d4ad09e2435c621916ddd6a1d50f3469707d" translate="yes" xml:space="preserve">
          <source>If the argument &lt;code&gt;dtype&lt;/code&gt; is not specified, then the type is inferred from the type of &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7a755586c48ee50759898fa7c989f8e67d40736" translate="yes" xml:space="preserve">
          <source>If the argument &lt;code&gt;staircase&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then &lt;code&gt;global_step / decay_steps&lt;/code&gt; is an integer division and the decayed learning rate follows a staircase function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1f01cc54fa41c0d32fd1e24bafe662f494d520d" translate="yes" xml:space="preserve">
          <source>If the argument &lt;code&gt;staircase&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then &lt;code&gt;step / decay_steps&lt;/code&gt; is an integer division and the decayed learning rate follows a staircase function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a38c88d9d6337fe7cece5f81a29f0e638b688c37" translate="yes" xml:space="preserve">
          <source>If the checkpoint has not been consumed completely, then the list of restore ops will grow as more objects are added to the dependency graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="322354248713025e3d6689fb7a7b7d477c48e541" translate="yes" xml:space="preserve">
          <source>If the code being run raises an exception, that exception is reported to the coordinator and the thread terminates. The coordinator will then request all the other threads it coordinates to stop.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d7979f58f3ff709afb03169a221ab568ed8d0b58" translate="yes" xml:space="preserve">
          <source>If the collection exists, this returns the list itself, which can be modified in place to change the collection. If the collection does not exist, it is created as an empty list and the list is returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16e2e93d9e738ccca07e48ed484e074d5b9423d1" translate="yes" xml:space="preserve">
          <source>If the coordinates are both normalized and centered, they range from -1.0 to 1.0. The coordinates (-1.0, -1.0) correspond to the upper left corner, the lower right corner is located at (1.0, 1.0) and the center is at (0, 0).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ff57f39749c34bbe8fe0401b61997435557e382" translate="yes" xml:space="preserve">
          <source>If the coordinates are normalized but not centered, 0.0 and 1.0 correspond to the minimum and maximum of each height and width dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ccc9ff36ea56cfa9e765b3c8d0c91355e08ae564" translate="yes" xml:space="preserve">
          <source>If the coordinates are not normalized they are interpreted as numbers of pixels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25f2c255dc162a384dc28be1433b4029caea49f5" translate="yes" xml:space="preserve">
          <source>If the dimension is a constant (e.g. &lt;a href=&quot;../../compat/v1/dimension&quot;&gt;&lt;code&gt;tf.compat.v1.Dimension(37)&lt;/code&gt;&lt;/a&gt;), the component will be padded out to that length in that dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="791f44cfdf8ef290ec842dbce59a72390416ce7a" translate="yes" xml:space="preserve">
          <source>If the dimension is a constant (e.g. &lt;a href=&quot;../../dimension&quot;&gt;&lt;code&gt;tf.compat.v1.Dimension(37)&lt;/code&gt;&lt;/a&gt;), the component will be padded out to that length in that dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e002c71d640bbe2622e030008cf7b64978256ffa" translate="yes" xml:space="preserve">
          <source>If the dimension is a constant (e.g. &lt;a href=&quot;../compat/v1/dimension&quot;&gt;&lt;code&gt;tf.compat.v1.Dimension(37)&lt;/code&gt;&lt;/a&gt;), the component will be padded out to that length in that dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="191bc9524d6bf196a57d9a494c82f21595b508cf" translate="yes" xml:space="preserve">
          <source>If the dimension is a constant (e.g. &lt;a href=&quot;../dimension&quot;&gt;&lt;code&gt;tf.compat.v1.Dimension(37)&lt;/code&gt;&lt;/a&gt;), the component will be padded out to that length in that dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="340852a05739f6c28dacec87f71405e50e7f1da1" translate="yes" xml:space="preserve">
          <source>If the dimension is unknown (e.g. &lt;a href=&quot;../../compat/v1/dimension&quot;&gt;&lt;code&gt;tf.compat.v1.Dimension(None)&lt;/code&gt;&lt;/a&gt;), the component will be padded out to the maximum length of all elements in that dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="552f501db3f78e9dbef2993feeab6983fea583c8" translate="yes" xml:space="preserve">
          <source>If the dimension is unknown (e.g. &lt;a href=&quot;../../dimension&quot;&gt;&lt;code&gt;tf.compat.v1.Dimension(None)&lt;/code&gt;&lt;/a&gt;), the component will be padded out to the maximum length of all elements in that dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5bdf9b1d41ce2f6dc0c751ffe579fd03e7de2703" translate="yes" xml:space="preserve">
          <source>If the dimension is unknown (e.g. &lt;a href=&quot;../compat/v1/dimension&quot;&gt;&lt;code&gt;tf.compat.v1.Dimension(None)&lt;/code&gt;&lt;/a&gt;), the component will be padded out to the maximum length of all elements in that dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb0dd7527d5cb7b1a0e894b67170a54d79baca84" translate="yes" xml:space="preserve">
          <source>If the dimension is unknown (e.g. &lt;a href=&quot;../dimension&quot;&gt;&lt;code&gt;tf.compat.v1.Dimension(None)&lt;/code&gt;&lt;/a&gt;), the component will be padded out to the maximum length of all elements in that dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac307030ed380432cc7d8c7f0c1aee738c5a7f19" translate="yes" xml:space="preserve">
          <source>If the exception is an OpError, the op stack is also included in the message predicate search.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcaf8005ea2c08911435025591bcbbf4aad115b1" translate="yes" xml:space="preserve">
          <source>If the file exists, it will be overwritten.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7dfe25f9b58e72feb123504aceee09af71a08930" translate="yes" xml:space="preserve">
          <source>If the first entry of a shape is &lt;code&gt;...&lt;/code&gt; (type &lt;code&gt;Ellipsis&lt;/code&gt;) or '*' that indicates a variable number of outer dimensions of unspecified size, i.e. the constraint applies to the inner-most dimensions only.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71d42c11a5bae209f5c9a583478a2ea75e6c109c" translate="yes" xml:space="preserve">
          <source>If the function returns a false boolean value then the iterator resumes the wait for new checkpoints. At this point the timeout logic applies again.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36167bdd84c2e1b5bd383edebcbb2793bbc3bfe8" translate="yes" xml:space="preserve">
          <source>If the given local job name is not present in the cluster specification, it will be automatically added, using an unused port on the localhost.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebfcc47390b8469a3d9d1e9bff51d80dfd3f6b82" translate="yes" xml:space="preserve">
          <source>If the given segment ID &lt;code&gt;i&lt;/code&gt; is negative, the value is dropped and will not be added to the sum of the segment.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51397e8be959c9339c89ea29fb852fcfaf3a6efa" translate="yes" xml:space="preserve">
          <source>If the given segment ID &lt;code&gt;i&lt;/code&gt; is negative, then the corresponding value is dropped, and will not be included in the result.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05fe8b0760cfbd76be7917dd8b4c1ecc11a9be28" translate="yes" xml:space="preserve">
          <source>If the global seed is set but the operation seed is not set, we get different results for every call to the random op, but the same sequence for every re-run of the program:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bba86599b1172a9ff9081ad6d128cd8a8ab922af" translate="yes" xml:space="preserve">
          <source>If the graph-level seed is not set, but the operation seed is set: A default graph-level seed and the specified operation seed are used to determine the random sequence.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b1abeab43afe5e63d9f398a048dcc795e5cb2b2" translate="yes" xml:space="preserve">
          <source>If the graph-level seed is set, but the operation seed is not: The system deterministically (determined by the current graph size) picks an operation seed in conjunction with the graph-level seed so that it gets a unique random sequence.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05b0de00712b693414eb54609b6c524990f67c51" translate="yes" xml:space="preserve">
          <source>If the input &lt;code&gt;indices&lt;/code&gt; is rank &lt;code&gt;N&lt;/code&gt;, the output will have rank &lt;code&gt;N+1&lt;/code&gt;. The new axis is created at dimension &lt;code&gt;axis&lt;/code&gt; (default: the new axis is appended at the end).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc46517b63dc57aa5b1ac644c2f1d4dc634d82fc" translate="yes" xml:space="preserve">
          <source>If the input arguments contain multiple &lt;code&gt;RaggedTensor&lt;/code&gt;s, then they must have identical &lt;code&gt;nested_row_splits&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2a67481586f4794a55075ae0b8d77938a8ca45c" translate="yes" xml:space="preserve">
          <source>If the input comes from a QuantizedRelu6, the output type is quint8 (range of 0-255) but the possible range of QuantizedRelu6 is 0-6. The min_range and max_range values are therefore 0.0 and 6.0. Dequantize on quint8 will take each value, cast to float, and multiply by 6 / 255. Note that if quantizedtype is qint8, the operation will additionally add each value by 128 prior to casting.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6426b4bfc81de4b1c9b426a44f2ae50a814240f6" translate="yes" xml:space="preserve">
          <source>If the input datatype &lt;code&gt;T&lt;/code&gt; is larger than the output datatype &lt;code&gt;type&lt;/code&gt; then the shape changes from [...] to [..., sizeof(&lt;code&gt;T&lt;/code&gt;)/sizeof(&lt;code&gt;type&lt;/code&gt;)].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d4571fc930ec815d2a6c8980432dbfead6d756c" translate="yes" xml:space="preserve">
          <source>If the input ids are ragged tensors, partition variables are not supported and the partition strategy and the max_norm are ignored. The results of the lookup are concatenated into a dense tensor. The returned tensor has shape &lt;code&gt;shape(ids) + shape(params)[1:]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2000d65cb54af404f075a90dd29fef64452cdfe9" translate="yes" xml:space="preserve">
          <source>If the input is a vector (rank=1), finds the &lt;code&gt;k&lt;/code&gt; largest entries in the vector and outputs their values and indices as vectors. Thus &lt;code&gt;values[j]&lt;/code&gt; is the &lt;code&gt;j&lt;/code&gt;-th largest entry in &lt;code&gt;input&lt;/code&gt;, and its index is &lt;code&gt;indices[j]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25639d61413f3474f585047a2bb63baa71a0472f" translate="yes" xml:space="preserve">
          <source>If the input is prefixed by a Byte Order Mark needed to determine encoding (e.g. if the encoding is UTF-16 and the BOM indicates big-endian), then that BOM will be consumed and not emitted into the output. If the input encoding is marked with an explicit endianness (e.g. UTF-16-BE), then the BOM is interpreted as a non-breaking-space and is preserved in the output (including always for UTF-8).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c4e8d7712b75c855eb7c3cf4d70a0943cb24389" translate="yes" xml:space="preserve">
          <source>If the input pipeline is shared between training and validation, restoring the checkpoint during validation may override the validation input pipeline.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b9ca643cb2629c831ff2614bca40312edb51c292" translate="yes" xml:space="preserve">
          <source>If the ith bit of &lt;code&gt;begin_mask&lt;/code&gt; is set, &lt;code&gt;begin[i]&lt;/code&gt; is ignored and the fullest possible range in that dimension is used instead. &lt;code&gt;end_mask&lt;/code&gt; works analogously, except with the end range.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53b6f32d8b994e08e60c897ec2633fae0ba3393e" translate="yes" xml:space="preserve">
          <source>If the ith bit of &lt;code&gt;ellipsis_mask&lt;/code&gt; is set, as many unspecified dimensions as needed will be inserted between other dimensions. Only one non-zero bit is allowed in &lt;code&gt;ellipsis_mask&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14e0da661bbe2e071831b21ea708a674b65e3553" translate="yes" xml:space="preserve">
          <source>If the ith bit of &lt;code&gt;new_axis_mask&lt;/code&gt; is set, then &lt;code&gt;begin&lt;/code&gt;, &lt;code&gt;end&lt;/code&gt;, and &lt;code&gt;stride&lt;/code&gt; are ignored and a new length 1 dimension is added at this point in the output tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea9295a32ee3d172d0de2b9a21ab6620d9c7aaa3" translate="yes" xml:space="preserve">
          <source>If the ith bit of &lt;code&gt;shrink_axis_mask&lt;/code&gt; is set, it implies that the ith specification shrinks the dimensionality by 1, taking on the value at index &lt;code&gt;begin[i]&lt;/code&gt;. &lt;code&gt;end[i]&lt;/code&gt; and &lt;code&gt;strides[i]&lt;/code&gt; are ignored in this case. For example in Python one might do &lt;code&gt;foo[:, 3, :]&lt;/code&gt; which would result in &lt;code&gt;shrink_axis_mask&lt;/code&gt; equal to 2.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5acffbcc3c0cad783d61073d1795d38ade292db7" translate="yes" xml:space="preserve">
          <source>If the key is a &lt;a href=&quot;../../sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.SparseTensor&lt;/code&gt;&lt;/a&gt;, the value should be a &lt;a href=&quot;sparsetensorvalue&quot;&gt;&lt;code&gt;tf.compat.v1.SparseTensorValue&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0adb28fdab6cc893d9c3156f443e8c35c99d1ae8" translate="yes" xml:space="preserve">
          <source>If the key is a &lt;a href=&quot;../../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt;, the value may be a Python scalar, string, list, or numpy ndarray that can be converted to the same &lt;code&gt;dtype&lt;/code&gt; as that tensor. Additionally, if the key is a &lt;a href=&quot;placeholder&quot;&gt;&lt;code&gt;tf.compat.v1.placeholder&lt;/code&gt;&lt;/a&gt;, the shape of the value will be checked for compatibility with the placeholder.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d4c6296ff5f1ed16700becf51c667373e1f81ef" translate="yes" xml:space="preserve">
          <source>If the key is a nested tuple of &lt;code&gt;Tensor&lt;/code&gt;s or &lt;code&gt;SparseTensor&lt;/code&gt;s, the value should be a nested tuple with the same structure that maps to their corresponding values as above.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0ed05e65efc99254033bbf6b2b8901e04b16293" translate="yes" xml:space="preserve">
          <source>If the last dimension is empty, we follow the convention that the sum over the empty set is zero, and the product is one.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99de0b684ff53cc972b2e916eef8dd972d4a9ba5" translate="yes" xml:space="preserve">
          <source>If the layer has not been built, this method will call &lt;code&gt;build&lt;/code&gt; on the layer. This assumes that the layer will later be used with inputs that match the input shape provided here.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c93baadf61368eb61a32573a61ace4b23530d53" translate="yes" xml:space="preserve">
          <source>If the layer's &lt;code&gt;call&lt;/code&gt; method takes a &lt;code&gt;mask&lt;/code&gt; argument (as some Keras layers do), its default value will be set to the mask generated for &lt;code&gt;inputs&lt;/code&gt; by the previous layer (if &lt;code&gt;input&lt;/code&gt; did come from a layer that generated a corresponding mask, i.e. if it came from a Keras layer with masking support.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9914ccb05442f0fd9eeac8901bc8d04826b15b98" translate="yes" xml:space="preserve">
          <source>If the max is empty for a given segment ID &lt;code&gt;i&lt;/code&gt;, &lt;code&gt;output[i] = 0&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96d2c8a21f840629380501d04af2dc4fe3e1ab06" translate="yes" xml:space="preserve">
          <source>If the maximum is empty for a given segment ID &lt;code&gt;i&lt;/code&gt;, it outputs the smallest possible value for the specific numeric type, &lt;code&gt;output[i] = numeric_limits&amp;lt;T&amp;gt;::lowest()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b06b3bf831b0d35a3637fb432a42854a21f98016" translate="yes" xml:space="preserve">
          <source>If the mean is empty for a given segment ID &lt;code&gt;i&lt;/code&gt;, &lt;code&gt;output[i] = 0&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1140e9402fba81b2c59500e980fdae7cc9b73760" translate="yes" xml:space="preserve">
          <source>If the min is empty for a given segment ID &lt;code&gt;i&lt;/code&gt;, &lt;code&gt;output[i] = 0&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00f33d9bbb883644d8d348d1d1e555c9c61673c2" translate="yes" xml:space="preserve">
          <source>If the minimum is empty for a given segment ID &lt;code&gt;i&lt;/code&gt;, it outputs the largest possible value for the specific numeric type, &lt;code&gt;output[i] = numeric_limits&amp;lt;T&amp;gt;::max()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb66ec88de963b30ef4f8246ae8014a7fd55e5c4" translate="yes" xml:space="preserve">
          <source>If the mode is 'MIN_FIRST', then this approach is used:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ef024d8d4793bf018279248fd541d506ae2395b" translate="yes" xml:space="preserve">
          <source>If the mode is &lt;code&gt;SCALED&lt;/code&gt;, dequantization is performed by multiplying each input value by a scaling_factor. (Thus an input of 0 always maps to 0.0).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db1124a69fc0391f15200d7a79013fb471df1704" translate="yes" xml:space="preserve">
          <source>If the mode is &lt;code&gt;SCALED&lt;/code&gt;, the quantization is performed by multiplying each input value by a scaling_factor. The scaling_factor is determined from &lt;code&gt;min_range&lt;/code&gt; and &lt;code&gt;max_range&lt;/code&gt; to be as large as possible such that the range from &lt;code&gt;min_range&lt;/code&gt; to &lt;code&gt;max_range&lt;/code&gt; is representable within values of type T.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c659fe038e40df626c10048932fee8c629877e2" translate="yes" xml:space="preserve">
          <source>If the model cannot be recovered successfully then it is initialized by running the &lt;code&gt;init_op&lt;/code&gt; and calling &lt;code&gt;init_fn&lt;/code&gt; if they are provided. The &lt;code&gt;local_init_op&lt;/code&gt; is also run after init_op and init_fn, regardless of whether the model was recovered successfully, but only if &lt;code&gt;ready_for_local_init_op&lt;/code&gt; passes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e493d4d88dd6364973cb16adddea7f1d7c9e11b9" translate="yes" xml:space="preserve">
          <source>If the model is recovered from a checkpoint it is assumed that all global variables have been initialized, in particular neither &lt;code&gt;init_op&lt;/code&gt; nor &lt;code&gt;init_fn&lt;/code&gt; will be executed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc6ec351ebdb083f3d17d8e986dd67bae3d01101" translate="yes" xml:space="preserve">
          <source>If the operation seed is not set but the global seed is set: The system picks an operation seed from a stream of seeds determined by the global seed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="150c78cb9921ff6cbc2920415e1cb51a5f161b3f" translate="yes" xml:space="preserve">
          <source>If the operation seed is set, but the global seed is not set: A default global seed and the specified operation seed are used to determine the random sequence.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61786c3241da39066c5d1cad1bbd7d232ac2fec8" translate="yes" xml:space="preserve">
          <source>If the operation seed is set, we get different results for every call to the random op, but the same sequence for every re-run of the program:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7c4d1aa2a7f3d9f64a5d7440278a03c364673f0" translate="yes" xml:space="preserve">
          <source>If the operator is marked as self-adjoint (via &lt;code&gt;is_self_adjoint&lt;/code&gt;) this computation can be more efficient.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62e7cf664c32974cdff913c7188633271cc1c617" translate="yes" xml:space="preserve">
          <source>If the operator is square, this is also the sum of the eigenvalues.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cfb48973a04dbb9b6d9a3a87eb33a91ec4619ce" translate="yes" xml:space="preserve">
          <source>If the output type was qint8 ([-128, 127]), the operation will additionally subtract each value by 128 prior to casting, so that the range of values aligns with the range of qint8.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4dff92bc587fce4bff2b2db8dd6919485f299911" translate="yes" xml:space="preserve">
          <source>If the partitioner hits the &lt;code&gt;max_shards&lt;/code&gt; limit, then each shard may end up larger than &lt;code&gt;max_shard_bytes&lt;/code&gt;. By default &lt;code&gt;max_shards&lt;/code&gt; equals &lt;code&gt;None&lt;/code&gt; and no limit on the number of shards is enforced.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1885aec51a609f73968bad4dfc16b73c835fa1e" translate="yes" xml:space="preserve">
          <source>If the product is empty for a given segment ID &lt;code&gt;i&lt;/code&gt;, &lt;code&gt;output[i] = 1&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14b06ad55e535b3bc2a49abca7c87697d17d429c" translate="yes" xml:space="preserve">
          <source>If the program crashes and is restarted, the managed session automatically reinitialize variables from the most recent checkpoint.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ec15897d06f9071c5e97fa6f104995494c3c020" translate="yes" xml:space="preserve">
          <source>If the queue is closed and there are less than &lt;code&gt;n&lt;/code&gt; elements left, then an &lt;code&gt;OutOfRange&lt;/code&gt; exception is raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2909c49e7094efd16c1e6b533233682195cdca40" translate="yes" xml:space="preserve">
          <source>If the queue is closed and there are more than &lt;code&gt;0&lt;/code&gt; but fewer than &lt;code&gt;n&lt;/code&gt; elements remaining, then instead of raising a &lt;a href=&quot;../errors/outofrangeerror&quot;&gt;&lt;code&gt;tf.errors.OutOfRangeError&lt;/code&gt;&lt;/a&gt; like &lt;code&gt;tf.QueueBase.dequeue_many&lt;/code&gt;, less than &lt;code&gt;n&lt;/code&gt; elements are returned immediately. If the queue is closed and there are &lt;code&gt;0&lt;/code&gt; elements left in the queue, then a &lt;a href=&quot;../errors/outofrangeerror&quot;&gt;&lt;code&gt;tf.errors.OutOfRangeError&lt;/code&gt;&lt;/a&gt; is raised just like in &lt;code&gt;dequeue_many&lt;/code&gt;. Otherwise the behavior is identical to &lt;code&gt;dequeue_many&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dbed72aba5ba28d95f2d72fff5e20ff3a4222092" translate="yes" xml:space="preserve">
          <source>If the queue is empty when this operation executes, it will block until there is an element to dequeue.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90be429384e7a1cfa4ccd2802a141dfd6052e934" translate="yes" xml:space="preserve">
          <source>If the queue is full when this operation executes, it will block until all of the elements have been enqueued.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eabf4447a0d7c1faf56f579f18de2be7b3ff884c" translate="yes" xml:space="preserve">
          <source>If the queue is full when this operation executes, it will block until the element has been enqueued.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55a8dc3be231a05be089bfed8d162468d9d0ecca" translate="yes" xml:space="preserve">
          <source>If the result is midway between two representable values, the even representable is chosen. For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5fe61fb730912ad313c279c46346170b788594e" translate="yes" xml:space="preserve">
          <source>If the scope name already exists, the name will be made unique by appending &lt;code&gt;_n&lt;/code&gt;. For example, calling &lt;code&gt;my_op&lt;/code&gt; the second time will generate &lt;code&gt;MyOp_1/a&lt;/code&gt;, etc.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a54dcf4080998972f139ff7554df53efbf2918b1" translate="yes" xml:space="preserve">
          <source>If the shape of the tensor to initialize is more than two-dimensional, a matrix of shape &lt;code&gt;(shape[0] * ... * shape[n - 2], shape[n - 1])&lt;/code&gt; is initialized, where &lt;code&gt;n&lt;/code&gt; is the length of the shape vector. The matrix is subsequently reshaped to give a tensor of the desired shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8d51b3cc2d47981a522a4c9c34d0625aae79fab" translate="yes" xml:space="preserve">
          <source>If the shape of the tensor to initialize is two-dimensional, it is initialized with an orthogonal matrix obtained from the QR decomposition of a matrix of random numbers drawn from a normal distribution. If the matrix has fewer rows than columns then the output will have orthogonal rows. Otherwise, the output will have orthogonal columns.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ef1c30d1f578546d2ac2a550f76da4a58e33bff" translate="yes" xml:space="preserve">
          <source>If the sum is empty for a given segment ID &lt;code&gt;i&lt;/code&gt;, &lt;code&gt;output[i] = 0&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="873ee7c62a98d7de613cf70bb2470219e6db5cb9" translate="yes" xml:space="preserve">
          <source>If the sum is empty for a given segment ID &lt;code&gt;i&lt;/code&gt;, &lt;code&gt;output[i] = 0&lt;/code&gt;. If the given segment ID &lt;code&gt;i&lt;/code&gt; is negative, the value is dropped and will not be added to the sum of the segment.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20a6d43b61a912e98de11addfc5b73fcd9317a33" translate="yes" xml:space="preserve">
          <source>If the timeout expires and no &lt;code&gt;timeout_fn&lt;/code&gt; was specified, the iterator stops yielding.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ce0283a8891c6dd66c32b4615d78fc780d2dda4" translate="yes" xml:space="preserve">
          <source>If the two objects compare equal then they will automatically compare almost equal.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35ceb4feec8fb5679f604323d53b185248a5db16" translate="yes" xml:space="preserve">
          <source>If the two sequences compare equal then they will automatically compare almost equal.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64507e1140a9c0626ea583b5e87dbd260bda51eb" translate="yes" xml:space="preserve">
          <source>If the value of the &lt;code&gt;trainable&lt;/code&gt; attribute is changed after calling &lt;code&gt;compile()&lt;/code&gt; on a model, the new value doesn't take effect for this model until &lt;code&gt;compile()&lt;/code&gt; is called again.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d869a15febad2f275c04757cafb49397fc0fa415" translate="yes" xml:space="preserve">
          <source>If there is a last partial batch, you will need to specify an axis so that the resulting shape is consistent across replicas. So if the last batch has size 6 and it is divided into [0, 1, 2, 3] and [4, 5], you would get a shape mismatch unless you specify &lt;code&gt;axis=0&lt;/code&gt;. If you specify &lt;a href=&quot;../../../../distribute/reduceop#MEAN&quot;&gt;&lt;code&gt;tf.distribute.ReduceOp.MEAN&lt;/code&gt;&lt;/a&gt;, using &lt;code&gt;axis=0&lt;/code&gt; will use the correct denominator of 6. Contrast this with computing &lt;code&gt;reduce_mean&lt;/code&gt; to get a scalar value on each replica and this function to average those means, which will weigh some values &lt;code&gt;1/8&lt;/code&gt; and others &lt;code&gt;1/4&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c72f727cca64a808cf7c4b7c3edec0a4599f0ee" translate="yes" xml:space="preserve">
          <source>If there is a last partial batch, you will need to specify an axis so that the resulting shape is consistent across replicas. So if the last batch has size 6 and it is divided into [0, 1, 2, 3] and [4, 5], you would get a shape mismatch unless you specify &lt;code&gt;axis=0&lt;/code&gt;. If you specify &lt;a href=&quot;../../../distribute/reduceop#MEAN&quot;&gt;&lt;code&gt;tf.distribute.ReduceOp.MEAN&lt;/code&gt;&lt;/a&gt;, using &lt;code&gt;axis=0&lt;/code&gt; will use the correct denominator of 6. Contrast this with computing &lt;code&gt;reduce_mean&lt;/code&gt; to get a scalar value on each replica and this function to average those means, which will weigh some values &lt;code&gt;1/8&lt;/code&gt; and others &lt;code&gt;1/4&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="611167fb33b99cb5686e6e2a810b98db2c2349ad" translate="yes" xml:space="preserve">
          <source>If there is a last partial batch, you will need to specify an axis so that the resulting shape is consistent across replicas. So if the last batch has size 6 and it is divided into [0, 1, 2, 3] and [4, 5], you would get a shape mismatch unless you specify &lt;code&gt;axis=0&lt;/code&gt;. If you specify &lt;a href=&quot;../reduceop#MEAN&quot;&gt;&lt;code&gt;tf.distribute.ReduceOp.MEAN&lt;/code&gt;&lt;/a&gt;, using &lt;code&gt;axis=0&lt;/code&gt; will use the correct denominator of 6. Contrast this with computing &lt;code&gt;reduce_mean&lt;/code&gt; to get a scalar value on each replica and this function to average those means, which will weigh some values &lt;code&gt;1/8&lt;/code&gt; and others &lt;code&gt;1/4&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9048470fa4efaf23b25ac2170e5cb511464506dc" translate="yes" xml:space="preserve">
          <source>If there is a last partial batch, you will need to specify an axis so that the resulting shape is consistent across replicas. So if the last batch has size 6 and it is divided into [0, 1, 2, 3] and [4, 5], you would get a shape mismatch unless you specify &lt;code&gt;axis=0&lt;/code&gt;. If you specify &lt;a href=&quot;reduceop#MEAN&quot;&gt;&lt;code&gt;tf.distribute.ReduceOp.MEAN&lt;/code&gt;&lt;/a&gt;, using &lt;code&gt;axis=0&lt;/code&gt; will use the correct denominator of 6. Contrast this with computing &lt;code&gt;reduce_mean&lt;/code&gt; to get a scalar value on each replica and this function to average those means, which will weigh some values &lt;code&gt;1/8&lt;/code&gt; and others &lt;code&gt;1/4&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d85ee17d394a0c122c1d9a09f179d26aa5670744" translate="yes" xml:space="preserve">
          <source>If there is no KL method registered specifically for &lt;code&gt;type(distribution_a)&lt;/code&gt; and &lt;code&gt;type(distribution_b)&lt;/code&gt;, then the class hierarchies of these types are searched.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd7912243ede8abeeda54d04f710e447b16a7a2e" translate="yes" xml:space="preserve">
          <source>If there is no entry for a given segment ID &lt;code&gt;i&lt;/code&gt;, it outputs 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf1d14f3c88546018feaf0d39b2b59114e95d67f" translate="yes" xml:space="preserve">
          <source>If there is no entry for a given segment ID &lt;code&gt;i&lt;/code&gt;, it outputs 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bf5400cdc3e4d05bcb2e0233a34376a166c6575" translate="yes" xml:space="preserve">
          <source>If this is not the case for your loss (if, for example, your loss references a &lt;code&gt;Variable&lt;/code&gt; of one of the model's layers), you can wrap your loss in a zero-argument lambda. These losses are not tracked as part of the model's topology since they can't be serialized.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3a84b9a7746118e73d604dc320af07d2b1b6de8" translate="yes" xml:space="preserve">
          <source>If this method is called, &lt;code&gt;get_scaled_loss&lt;/code&gt; should also be called. See the &lt;a href=&quot;lossscaleoptimizer&quot;&gt;&lt;code&gt;tf.keras.mixed_precision.experimental.LossScaleOptimizer&lt;/code&gt;&lt;/a&gt; doc for an example.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90126041d843d207c1a230dd608378fc394de215" translate="yes" xml:space="preserve">
          <source>If this method is called, &lt;code&gt;get_unscaled_gradients&lt;/code&gt; should also be called. See the &lt;a href=&quot;lossscaleoptimizer&quot;&gt;&lt;code&gt;tf.keras.mixed_precision.experimental.LossScaleOptimizer&lt;/code&gt;&lt;/a&gt; doc for an example.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ab5fd845bbcbc69da7d15bc16ce0eb8f62203dd" translate="yes" xml:space="preserve">
          <source>If this op is configured to not have padding, or if it is configured to add padding with &lt;code&gt;padding_width&lt;/code&gt; set to less than ngram_width-1, it is possible that a sequence, or a sequence plus padding, is smaller than the ngram width. In that case, no ngrams will be generated for that sequence. This can be prevented by setting &lt;code&gt;preserve_short_sequences&lt;/code&gt;, which will cause the op to always generate at least one ngram per non-empty sequence.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab839358f55486546d3d029071a450dcaefa7d5b" translate="yes" xml:space="preserve">
          <source>If this operator acts like the batch matrix &lt;code&gt;A&lt;/code&gt; with &lt;code&gt;A.shape = [B1,...,Bb, M, N]&lt;/code&gt;, then this returns &lt;code&gt;M&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ce9f7e3db7531975f11e7f4a68cd88c0d560996" translate="yes" xml:space="preserve">
          <source>If this operator acts like the batch matrix &lt;code&gt;A&lt;/code&gt; with &lt;code&gt;A.shape = [B1,...,Bb, M, N]&lt;/code&gt;, then this returns &lt;code&gt;N&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62e8ab46dc91b8378fc928855066ea5b3d23a6e6" translate="yes" xml:space="preserve">
          <source>If this operator acts like the batch matrix &lt;code&gt;A&lt;/code&gt; with &lt;code&gt;A.shape = [B1,...,Bb, M, N]&lt;/code&gt;, then this returns &lt;code&gt;TensorShape([B1,...,Bb, M, N])&lt;/code&gt;, equivalent to &lt;code&gt;A.shape&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="689aa8d64b08329267dae138eebcb059972cf24c" translate="yes" xml:space="preserve">
          <source>If this operator acts like the batch matrix &lt;code&gt;A&lt;/code&gt; with &lt;code&gt;A.shape = [B1,...,Bb, M, N]&lt;/code&gt;, then this returns &lt;code&gt;TensorShape([B1,...,Bb])&lt;/code&gt;, equivalent to &lt;code&gt;A.shape[:-2]&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e16fa6d80d3c7cfd9673c1871d91dcd51542d167" translate="yes" xml:space="preserve">
          <source>If this operator acts like the batch matrix &lt;code&gt;A&lt;/code&gt; with &lt;code&gt;A.shape = [B1,...,Bb, M, N]&lt;/code&gt;, then this returns &lt;code&gt;b + 2&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03127ec398775f2a4051ba0c818b1ec18cf14baf" translate="yes" xml:space="preserve">
          <source>If this operator acts like the batch matrix &lt;code&gt;A&lt;/code&gt; with &lt;code&gt;A.shape = [B1,...,Bb, M, N]&lt;/code&gt;, then this returns a &lt;code&gt;Tensor&lt;/code&gt; holding &lt;code&gt;[B1,...,Bb, M, N]&lt;/code&gt;, equivalent to &lt;a href=&quot;../shape&quot;&gt;&lt;code&gt;tf.shape(A)&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8ab4fc41b0560bb6a934607949bd5b386ee29f8" translate="yes" xml:space="preserve">
          <source>If this operator acts like the batch matrix &lt;code&gt;A&lt;/code&gt; with &lt;code&gt;A.shape = [B1,...,Bb, M, N]&lt;/code&gt;, then this returns a &lt;code&gt;Tensor&lt;/code&gt; holding &lt;code&gt;[B1,...,Bb]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="921347482b8fd91ee313851ca1cccdafc480cddb" translate="yes" xml:space="preserve">
          <source>If this operator has shape &lt;code&gt;[B1,...,Bb, M, N]&lt;/code&gt;, this returns a &lt;code&gt;Tensor&lt;/code&gt;&lt;code&gt;diagonal&lt;/code&gt;, of shape &lt;code&gt;[B1,...,Bb, min(M, N)]&lt;/code&gt;, where &lt;code&gt;diagonal[b1,...,bb, i] = self.to_dense()[b1,...,bb, i, i]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f17df02cdfdf16ae55ddc38c4d96a43d8d0194c" translate="yes" xml:space="preserve">
          <source>If this operator is &lt;code&gt;A = L + U D V^H&lt;/code&gt;, this hints &lt;code&gt;D &amp;gt; 0&lt;/code&gt; elementwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d7432da8d98b1f600f518b45f152630261f8725" translate="yes" xml:space="preserve">
          <source>If this operator is &lt;code&gt;A = L + U D V^H&lt;/code&gt;, this is &lt;code&gt;D&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac0c26f8d498bda35983c79790cb84038dcc48a1" translate="yes" xml:space="preserve">
          <source>If this operator is &lt;code&gt;A = L + U D V^H&lt;/code&gt;, this is the &lt;code&gt;L&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed4f7079684ac253ddfaf867eaf34bf8cf0aed43" translate="yes" xml:space="preserve">
          <source>If this operator is &lt;code&gt;A = L + U D V^H&lt;/code&gt;, this is the &lt;code&gt;U&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b75fcf71c0a569ab0e4f88a68f9b2ba47762aa34" translate="yes" xml:space="preserve">
          <source>If this operator is &lt;code&gt;A = L + U D V^H&lt;/code&gt;, this is the &lt;code&gt;V&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11a0d778ea7b358f23842e885c1d5a8c5ecc2928" translate="yes" xml:space="preserve">
          <source>If this operator is &lt;code&gt;A = L + U D V^H&lt;/code&gt;, this is the diagonal of &lt;code&gt;D&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac015fe43443b780f0f83ee7a02dba87f69812e3" translate="yes" xml:space="preserve">
          <source>If this optional does not have a value (i.e. &lt;code&gt;self.has_value()&lt;/code&gt; evaluates to &lt;code&gt;False&lt;/code&gt;), this operation will raise &lt;a href=&quot;../../errors/invalidargumenterror&quot;&gt;&lt;code&gt;tf.errors.InvalidArgumentError&lt;/code&gt;&lt;/a&gt; at runtime.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77cdf432873b1c4a434c37672f4c11b50efb424e" translate="yes" xml:space="preserve">
          <source>If time_major == False (default), this will be a &lt;code&gt;Tensor&lt;/code&gt; shaped: &lt;code&gt;[batch_size, max_time, cell.output_size]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4ef8f486f9257f3c609cd71034848e31051aeee" translate="yes" xml:space="preserve">
          <source>If time_major == True, this will be a &lt;code&gt;Tensor&lt;/code&gt; shaped: &lt;code&gt;[max_time, batch_size, cell.output_size]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55d835c5abdde926d74d741995b5b63e74e4a04d" translate="yes" xml:space="preserve">
          <source>If true, &lt;code&gt;MonitoredSession&lt;/code&gt; stops iterations. Returns: A &lt;code&gt;bool&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78bb27a9d56dc099a7acc0da9b42015044430fff" translate="yes" xml:space="preserve">
          <source>If true, we do not use the minimum quantized value. i.e. for int8 the quantized output, it would be restricted to the range -127..127 instead of the full -128..127 range. This is provided for compatibility with certain inference backends. (Only applies to SCALED mode)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83490805bb1f49a5f8bb8f11bf034585aac8c23b" translate="yes" xml:space="preserve">
          <source>If tuple of 2 ints: interpreted as two different symmetric cropping values for height and width: &lt;code&gt;(symmetric_height_crop, symmetric_width_crop)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29288c4cdf42a8a30d0d3b67f8aed321e16ae670" translate="yes" xml:space="preserve">
          <source>If tuple of 2 ints: interpreted as two different symmetric padding values for height and width: &lt;code&gt;(symmetric_height_pad, symmetric_width_pad)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b67c19bd4a86767a2e3f540ca915d81b144b003" translate="yes" xml:space="preserve">
          <source>If tuple of 2 tuples of 2 ints: interpreted as &lt;code&gt;((top_crop, bottom_crop), (left_crop, right_crop))&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="487146df721c523689eaeddaf64885a4a783f231" translate="yes" xml:space="preserve">
          <source>If tuple of 2 tuples of 2 ints: interpreted as &lt;code&gt;((top_pad, bottom_pad), (left_pad, right_pad))&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="812fc65b353a07607726b2966667ffdf62fd3b3c" translate="yes" xml:space="preserve">
          <source>If tuple of 3 ints: interpreted as two different symmetric cropping values for depth, height, and width: &lt;code&gt;(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43b0e46a9dc3a1e8c76f88c379c30be852303e72" translate="yes" xml:space="preserve">
          <source>If tuple of 3 ints: interpreted as two different symmetric padding values for height and width: &lt;code&gt;(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c88b2c00149b3f5340f436ed5d7d8a348e7c720" translate="yes" xml:space="preserve">
          <source>If tuple of 3 tuples of 2 ints: interpreted as &lt;code&gt;((left_dim1_crop, right_dim1_crop), (left_dim2_crop, right_dim2_crop), (left_dim3_crop, right_dim3_crop))&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f527489de1e80e2130364ad7b3746cd24f497905" translate="yes" xml:space="preserve">
          <source>If tuple of 3 tuples of 2 ints: interpreted as &lt;code&gt;((left_dim1_pad, right_dim1_pad), (left_dim2_pad, right_dim2_pad), (left_dim3_pad, right_dim3_pad))&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3faf4c1ccd2136f577d7a0c4205048d0ffd1bdee" translate="yes" xml:space="preserve">
          <source>If tuple of int (length 2): How many zeros to add at the beginning and at the end of the padding dimension (&lt;code&gt;(left_pad, right_pad)&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd5216b9fe5dfaa382d9801ed52c23fb17ea2eda" translate="yes" xml:space="preserve">
          <source>If two elements are equal, the lower-index element appears first.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4bce7b71d5fde27e87108fc2b8f29d9e9dd019f3" translate="yes" xml:space="preserve">
          <source>If user called &lt;code&gt;MonitoredSession.run(fetches=a, feed_dict=b)&lt;/code&gt;, then this field is equal to SessionRunArgs(a, b).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7b2692658ec0f3b0fedbacc5e4dc8afebe62f2f" translate="yes" xml:space="preserve">
          <source>If users keep data in tf.Example format, they need to call tf.parse_example with a proper feature spec. There are two main things that this utility helps:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50cf7138d7b09704383c9338ec705e7ebf6961a1" translate="yes" xml:space="preserve">
          <source>If using exclusive &lt;code&gt;labels&lt;/code&gt; (wherein one and only one class is true at a time), see &lt;code&gt;sparse_softmax_cross_entropy_with_logits&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6f309484c1aebad69e2272b3c3b34b511f44f66" translate="yes" xml:space="preserve">
          <source>If value is False, then only the name prepended with 'no' is emitted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d582533f76f9fbe72b42e141cd8db21e3ebbecb" translate="yes" xml:space="preserve">
          <source>If value is None, then only the name is emitted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d1b932d0c6b9763d6c98a7c7a4f7d4c559674b7" translate="yes" xml:space="preserve">
          <source>If value is True, then only the name is emitted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d4ad20b53a04eec43483216203f6cf47ad97680" translate="yes" xml:space="preserve">
          <source>If value is a collection, this will emit --name=value1,value2,value3.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e94289cc0ab276f55f2d57923859f1b90e55cdac" translate="yes" xml:space="preserve">
          <source>If value is a string then --name=value is emitted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="269bcbd39e8d044a050279a6fd20ff4311dabf60" translate="yes" xml:space="preserve">
          <source>If values in &lt;code&gt;ref&lt;/code&gt; is to be updated more than once, because there are duplicate entries in &lt;code&gt;indices&lt;/code&gt;, the order at which the updates happen for each value is undefined.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bdb844cd4d2f332924e15531b086460f3069fb1e" translate="yes" xml:space="preserve">
          <source>If we had the following files on our filesystem: - /path/to/dir/a.txt - /path/to/dir/b.py - /path/to/dir/c.py If we pass &quot;/path/to/dir/*.py&quot; as the directory, the dataset would produce: - /path/to/dir/b.py - /path/to/dir/c.py</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c56249ff57de445c0d669230b1aed90585bd8f33" translate="yes" xml:space="preserve">
          <source>If we mark the pixels in the input image which are taken for the output with &lt;code&gt;*&lt;/code&gt;, we see the pattern:</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
