<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ko" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="bb1fbbd8149208e44d7920553c652b0349a2e4cb" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#lsa&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../decomposition#lsa&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="4a0ae8aa40ea2e0cf2d9461f2ba205b77de375f1" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#nmf&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../decomposition#nmf&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="523c25ac611714a2884232ed4a3b8ea48f8aba43" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#pca&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../decomposition#pca&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="aa9dad4897d2af823fe726cce306b7009091c965" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#sparsecoder&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../decomposition#sparsecoder&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="424d7bf0d29f09028621f6a77016037f8976dc79" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#sparsepca&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../decomposition#sparsepca&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="bb31f4d810b593c0d4100826896784b7db423e30" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../density#kernel-density&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../density#kernel-density&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="b8cfdd3f6a5935daac5c5163b44a190d819cf3f1" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../ensemble#adaboost&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../ensemble#adaboost&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="86400bc4bac71705c9aa6540ee3b030698a90e10" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../ensemble#bagging&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../ensemble#bagging&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="4a1ed19879f0785835e56a79d9b743e0ec4944b9" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../ensemble#forest&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../ensemble#forest&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="2427849a6d85ac2900e5917cd85e9a8f1e0026db" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../ensemble#gradient-boosting&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../ensemble#gradient-boosting&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="74e27ba8cdd2eee9b3d79708f28f6531b62f6a85" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../ensemble#partial-dependence&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../ensemble#partial-dependence&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="02f069134a44c53391b037c7fc439f82145f4541" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../ensemble#random-trees-embedding&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../ensemble#random-trees-embedding&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="3d0298d7a564e2bdb060a82b98586397ab1093aa" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../ensemble#voting-classifier&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../ensemble#voting-classifier&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="3b3089ffdf7c0064cb924ed3113eedce86da89f9" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../feature_extraction#dict-feature-extraction&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../feature_extraction#dict-feature-extraction&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="2cae87659a2fb17a22e879d82f229f7150133e8d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../feature_extraction#feature-hashing&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../feature_extraction#feature-hashing&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="227f83f3f45691e4e6ac89bd5c4292e7089c18d1" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../feature_extraction#image-feature-extraction&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../feature_extraction#image-feature-extraction&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="10137dbd282e2c34d67ce96d138b644d7e83ce3c" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../feature_extraction#text-feature-extraction&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../feature_extraction#text-feature-extraction&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="eeafc617d896a18852b196d65714fb0cdfa671cc" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../feature_selection#rfe&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../feature_selection#rfe&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="be00e3925bdea52e2671ec8561d266406b87e844" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../feature_selection#univariate-feature-selection&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../feature_selection#univariate-feature-selection&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="9563123917184cb45ca9461f7b3f9e5c290f2dbc" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../feature_selection#variance-threshold&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../feature_selection#variance-threshold&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="ff9cf599736fe4fe2ebfa784747df392a4200f1f" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../gaussian_process#gaussian-process&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../gaussian_process#gaussian-process&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="d75a8b7d85fa84978a0ec8f30777c3a42aed10a4" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../grid_search#grid-search&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../grid_search#grid-search&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="eb887baa2789fddc23d6beef61fca265307ecd58" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../grid_search#randomized-parameter-search&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../grid_search#randomized-parameter-search&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="75601fb7b797d9984583dbb0f5078075298f18d5" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../impute#impute&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../impute#impute&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="4a9d395f2980e33b7a924a6a12c64f75a808110b" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../isotonic#isotonic&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../isotonic#isotonic&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="325f5783b35c73d1ac50a27b5fcba72938048669" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../kernel_approximation#additive-chi-kernel-approx&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../kernel_approximation#additive-chi-kernel-approx&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="17d51749641f3da3ac030955c9fa8c847e6b067d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../kernel_approximation#nystroem-kernel-approx&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../kernel_approximation#nystroem-kernel-approx&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="bd440824c891d3899b71ba7cdd6737fff87f7287" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../kernel_approximation#rbf-kernel-approx&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../kernel_approximation#rbf-kernel-approx&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="332847419e8d0030ef93f1eacfc36a11e92afc2b" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../kernel_approximation#skewed-chi-kernel-approx&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../kernel_approximation#skewed-chi-kernel-approx&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="7d3e13b8d25243ee549b8ac75191bed212dd0367" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../kernel_ridge#kernel-ridge&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../kernel_ridge#kernel-ridge&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="79136184797821e9320982ebefd4fdc6aee8fcc9" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../label_propagation#label-propagation&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../label_propagation#label-propagation&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="9d6cabb3bcc48c8b13d8efcb84b593c5e97fafde" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../lda_qda#lda-qda&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../lda_qda#lda-qda&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="1997cdd51434d666882d1c5e72dafd16763400c2" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../learning_curve#learning-curve&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../learning_curve#learning-curve&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="edab24ce901236778794fa27e9de61a91dd86bcf" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#bayesian-regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../linear_model#bayesian-regression&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="9b98097e17c0cf7837b308d192730df9e81533c5" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#elastic-net&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../linear_model#elastic-net&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="fdea74fa206e7300a798fcdf4878b5477656890b" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#huber-regression&quot;&gt;User Guide&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;../linear_model#huber-regression&quot;&gt;사용자 안내서&lt;/a&gt; 에서 더 읽기</target>
        </trans-unit>
        <trans-unit id="605a6c65b202841b9fab85c42ab592224c31439e" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#lasso&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../linear_model#lasso&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="77dd7df8535c610e7e5f303489e92cf5eb573ae0" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#least-angle-regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../linear_model#least-angle-regression&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="62d4fc4abd6308999d4ddf6145d511c1a64a45f8" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#logistic-regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../linear_model#logistic-regression&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="62892a88a6229192a52c43f399daae6da1dfa9e7" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#multi-task-elastic-net&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../linear_model#multi-task-elastic-net&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="cce4abc31be44b512209a87a8a1310dccdd746ed" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#multi-task-lasso&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../linear_model#multi-task-lasso&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="63d9107930cb198a43c0da98652a54726063c1ca" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#omp&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../linear_model#omp&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="3170770312488b56140f8dbfe00f0d6184e99380" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#passive-aggressive&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../linear_model#passive-aggressive&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="62985a29f77d63fea260e6068599d0e367d6df05" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#perceptron&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../linear_model#perceptron&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="893a899efdba3adbe214f9ea4d308ce1b21b9673" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#ransac-regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../linear_model#ransac-regression&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="a05b7db13932de9fce1579dc368f7c3a0c753b2b" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#ridge-regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../linear_model#ridge-regression&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="423509ee6c18b0afa9860664aaed5d7b2465f60c" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#theil-sen-regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../linear_model#theil-sen-regression&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="0e298c4f51c9646d039f38079ecf13eeb9f51c35" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../manifold#isomap&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../manifold#isomap&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="b6567f6525c87d7835f328b71c58f3e36609854e" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../manifold#locally-linear-embedding&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../manifold#locally-linear-embedding&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="8786aa07e28fcc1b246cbad7ac302288a26cdbb9" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../manifold#multidimensional-scaling&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../manifold#multidimensional-scaling&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="5db81b2394b8868895e638c7228ad4393e95e473" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../manifold#spectral-embedding&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../manifold#spectral-embedding&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="8dc4370c51c018661016d7dc40103661eb969866" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../manifold#t-sne&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../manifold#t-sne&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="12f1f31ea9aa0bf152f42f6e525501d833fa544e" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../metrics#chi2-kernel&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../metrics#chi2-kernel&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="7ca1a0753b9133cba95108bd5cee6b65a7aca9e8" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../metrics#cosine-similarity&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../metrics#cosine-similarity&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="925b0027fe482eafac1c97466fcd8e514af11635" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../metrics#linear-kernel&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../metrics#linear-kernel&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="648de98a69589997eca7c7636b725bd10a74bddc" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../metrics#metrics&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../metrics#metrics&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="3f7fedfde3b7aa468849d2ea9db9146385c44b72" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../metrics#polynomial-kernel&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../metrics#polynomial-kernel&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="35dbd58928fec0c458fe20a80908cd4ec12d274d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../metrics#rbf-kernel&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../metrics#rbf-kernel&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="17512b696dbad66e286c04ad624c1265663ac384" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../metrics#sigmoid-kernel&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../metrics#sigmoid-kernel&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="5de34567070ba5628c050367f9e925100b0fc96a" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../mixture#bgmm&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../mixture#bgmm&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="533014884244f3ba887c95cc1354b3af546d07e6" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../mixture#gmm&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../mixture#gmm&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="4f10a79354f2de579c599d2d8732a298b909fdeb" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#accuracy-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#accuracy-score&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="170be2eccb759dd0330485448ffb52236f29617f" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#balanced-accuracy-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#balanced-accuracy-score&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="1c1624381291de658aadcb0f8bba71ec760477bc" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#classification-report&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#classification-report&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="02442b6427f4449db107842efe6df9bee26b4549" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#cohen-kappa&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#cohen-kappa&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="60633d1944d25d8e42233b17be1ba5b89c87e50d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#confusion-matrix&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#confusion-matrix&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="d8c53077e3f840542fa4d81c9f7eb854a5a66b5d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#coverage-error&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#coverage-error&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="6db1944ec420ba7d264cc277fb06d2041e89b7b3" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#dummy-estimators&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#dummy-estimators&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="d0061f5a7019cedca60fbe5efee87b2b70aafdf2" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#explained-variance-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#explained-variance-score&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="caaad1578fa75a9e67d6c9a942aa5b385b1eddeb" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#hamming-loss&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#hamming-loss&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="d9f1528ff05d947bd2459205b85f7511b2d1d6e3" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#hinge-loss&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#hinge-loss&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="79adced881725d09911672ffa6b1fa3c11470877" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#jaccard-similarity-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#jaccard-similarity-score&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="9c76d43281b705daf6060bc769428acb99df2e1a" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#label-ranking-average-precision&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#label-ranking-average-precision&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="bc1444f7fb419d74ca2fc94b203e3cdd81418e90" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#label-ranking-loss&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#label-ranking-loss&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="179dd1e5ea8f10c789dddd6c308f1168860f6139" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#log-loss&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#log-loss&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="3f5d5754f2137e3a906eef5875232e8fdfc76081" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#matthews-corrcoef&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#matthews-corrcoef&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="8f73fb1cae9461ab9f6400985b32548b8964a1b8" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#mean-absolute-error&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#mean-absolute-error&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="5d1e1b9b31d605369dff3a437a68762e4751f2e8" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#mean-squared-error&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#mean-squared-error&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="0b1b8bb5d6347e658149088fa461b3192cff9640" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#mean-squared-log-error&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#mean-squared-log-error&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="ecf4c4a829a08bf6e6519a0e6067e81b86c62fb2" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#median-absolute-error&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#median-absolute-error&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="b5386b0a93afcac4bca9a0d368219ae5d6677670" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#precision-recall-f-measure-metrics&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#precision-recall-f-measure-metrics&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="ca28351a846df3237d411aafad114a8333d94fec" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#r2-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#r2-score&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="0238aa0a0f95118ffe5b4c380749a69f2c36044d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#roc-metrics&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#roc-metrics&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="a760b80ba54e4f80ac167d73dc67b67466c42dd6" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#scoring&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#scoring&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="a9c28c0d6b12664d980e4a3fb42f49c518447592" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#zero-one-loss&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../model_evaluation#zero-one-loss&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="ce24690cf9d469b3f01a2115acdf5e26e2879d50" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../multiclass#classifierchain&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../multiclass#classifierchain&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="f67013119ba3c3f06184866c4e55f5b0fe15d7b0" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../multiclass#ecoc&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../multiclass#ecoc&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="2b596c84eeef681ee59e6eaa23e2ab0178795fb2" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../multiclass#ovo-classification&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../multiclass#ovo-classification&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="0b84d654de937d7ea19c79ae871825d13809d0ae" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../multiclass#ovr-classification&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../multiclass#ovr-classification&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="4cadbfd6d3a03561ef5fac73ce993b30f95820e4" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../multiclass#regressorchain&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../multiclass#regressorchain&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="20c527e1422efd8cd521fd11a837b8771d68c0ed" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../naive_bayes#bernoulli-naive-bayes&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../naive_bayes#bernoulli-naive-bayes&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="435ca2dc0d648838a00a3b7bef24dac1a7adaa23" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../naive_bayes#complement-naive-bayes&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../naive_bayes#complement-naive-bayes&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="3628821e07ebeec87b4e23e6366df9a20b612431" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../naive_bayes#gaussian-naive-bayes&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../naive_bayes#gaussian-naive-bayes&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="90e0d6fc128f0746c91ba73859829910362f4188" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../naive_bayes#multinomial-naive-bayes&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../naive_bayes#multinomial-naive-bayes&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="bbbfd3536fc48b983c24396bb250b8301c1a1818" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../neighbors#classification&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../neighbors#classification&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="d16dc8c3088a2f09d05b0c673b36bbb65842f4aa" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../neighbors#nearest-centroid-classifier&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../neighbors#nearest-centroid-classifier&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="efd88426b64fbe0e99a3366c9d29085372e0f20c" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../neighbors#regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../neighbors#regression&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="b18180fa58bff344612505155e526d65757d6879" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../neighbors#unsupervised-neighbors&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../neighbors#unsupervised-neighbors&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="f5ca7e934fae58a25ccd73b564917de49755ed2d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../neural_networks_unsupervised#rbm&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../neural_networks_unsupervised#rbm&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="016cc2045fa59f9f6c76ed8dedce6c6a99a77250" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../outlier_detection#isolation-forest&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../outlier_detection#isolation-forest&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="23f7b3cec9a4c9afe4a28977379e61c0109412ee" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../outlier_detection#outlier-detection&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../outlier_detection#outlier-detection&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="c340b4e9171351d4ac97e019f6a473179de82216" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#function-transformer&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../preprocessing#function-transformer&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="76c036a3098b42296deac8a1c5d7290cf1ae1229" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#imputation&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../preprocessing#imputation&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="f405e1ec5f4ad33765a94962e9b33f15dadc4ec0" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#kernel-centering&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../preprocessing#kernel-centering&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="6d6fa8fc54987f399b4367c5904e7df2b83b6932" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#preprocessing-binarization&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../preprocessing#preprocessing-binarization&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="eb8d6e8ece3c81b8a542f9df331060a314e025fd" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#preprocessing-categorical-features&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../preprocessing#preprocessing-categorical-features&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="0f208a23c8504226892516180b238a9e74077793" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#preprocessing-discretization&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../preprocessing#preprocessing-discretization&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="1f62a25e532bfe0603cc7a0c1c845cc880fe024e" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#preprocessing-normalization&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../preprocessing#preprocessing-normalization&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="5dc989f129ad1b4e3e5f3fdd6faa0e98cad51f1a" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#preprocessing-scaler&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../preprocessing#preprocessing-scaler&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="82f3e5bb34c91b65a524bb20b361c49cfb0fb233" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#preprocessing-transformer&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../preprocessing#preprocessing-transformer&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="3cb28cc10f44afc34f1d4c1193f109ecbe0f6a68" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing_targets#preprocessing-targets&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../preprocessing_targets#preprocessing-targets&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="8f8077a63c7a4dbd5d157802c4b7038867dc8b02" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../random_projection#gaussian-random-matrix&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../random_projection#gaussian-random-matrix&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="e575964327dd84831f3a16b64ea31b230d51ed1a" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../random_projection#johnson-lindenstrauss&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../random_projection#johnson-lindenstrauss&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="10155b4478c3cc070907f4a54184b40aecf0a4e1" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../random_projection#sparse-random-matrix&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../random_projection#sparse-random-matrix&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="5272664804ace173fb4cbcbc5ddcfa3fe0afb9ee" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../sgd#sgd&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../sgd#sgd&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="55b58a72c59a271efec6d011a6007ff1a061e751" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../svm#svm-classification&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../svm#svm-classification&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="68050db6d2a4d61c2fe3bdaccce618cf42039304" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../svm#svm-regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../svm#svm-regression&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="fa2ff8d70f29d7b5c10c2ce65368640c95153f3a" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../tree#tree&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../tree#tree&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="bc79a8f7da525c429ee0e5b183036b202a8b9f40" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;http://scikit-learn.org/stable/search.html&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;http://scikit-learn.org/stable/search.html&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="ea9af338459b2450a415084c5bfba27a1289f204" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;https://docs.python.org/3/c-api/memory.html#memory&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;https://docs.python.org/3/c-api/memory.html#memory&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="950c04b3c436731f3c44f5d5621d93d1c15ac31e" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#parallel&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#parallel&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="fbb9f9ef042590ecbd5eb064b421494a6aa64ba3" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;linear_model#perceptron&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;linear_model#perceptron&quot;&gt;사용자 안내서&lt;/a&gt; 에서 자세한 내용을 읽으십시오 .</target>
        </trans-unit>
        <trans-unit id="b3950e2b914b89c31fec890fc3bac839ddc83abb" translate="yes" xml:space="preserve">
          <source>Read-only attribute to access any step parameter by user given name. Keys are step names and values are steps parameters.</source>
          <target state="translated">사용자 이름으로 모든 단계 매개 변수에 액세스하기위한 읽기 전용 속성. 키는 단계 이름이고 값은 단계 매개 변수입니다.</target>
        </trans-unit>
        <trans-unit id="e3cc541a2927d490b1b449fbfcf30124e2ea9571" translate="yes" xml:space="preserve">
          <source>Read-only attribute to access any transformer by given name. Keys are transformer names and values are the fitted transformer objects.</source>
          <target state="translated">주어진 이름으로 변압기에 액세스하기위한 읽기 전용 속성. 키는 변압기 이름이고 값은 장착 된 변압기 개체입니다.</target>
        </trans-unit>
        <trans-unit id="83267413a88047148e04736326566653aabdff91" translate="yes" xml:space="preserve">
          <source>Real data sets are often subject to measurement or recording errors. Regular but uncommon observations may also appear for a variety of reasons. Observations which are very uncommon are called outliers. The empirical covariance estimator and the shrunk covariance estimators presented above are very sensitive to the presence of outliers in the data. Therefore, one should use robust covariance estimators to estimate the covariance of its real data sets. Alternatively, robust covariance estimators can be used to perform outlier detection and discard/downweight some observations according to further processing of the data.</source>
          <target state="translated">실제 데이터 세트는 종종 측정 또는 기록 오류의 영향을받습니다. 정기적이지만 드문 관찰이 여러 가지 이유로 나타날 수 있습니다. 매우 드문 관찰을 이상치라고합니다. 위에 제시된 경험적 공분산 추정기 및 축소 공분산 추정기는 데이터에 특이 치의 존재에 매우 민감합니다. 따라서 실제 데이터 세트의 공분산을 추정하려면 강력한 공분산 추정기를 사용해야합니다. 대안 적으로, 강력한 공분산 추정기는 데이터의 추가 처리에 따라 이상 값 탐지를 수행하고 일부 관측 값을 폐기 / 하중화할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="03d8b77e6b614dc7777dda68e24972906c1421c7" translate="yes" xml:space="preserve">
          <source>Real text may come from a variety of sources that may have used different encodings, or even be sloppily decoded in a different encoding than the one it was encoded with. This is common in text retrieved from the Web. The Python package &lt;a href=&quot;https://github.com/LuminosoInsight/python-ftfy&quot;&gt;ftfy&lt;/a&gt; can automatically sort out some classes of decoding errors, so you could try decoding the unknown text as &lt;code&gt;latin-1&lt;/code&gt; and then using &lt;code&gt;ftfy&lt;/code&gt; to fix errors.</source>
          <target state="translated">실제 텍스트는 다른 인코딩을 사용했을 수도 있고 인코딩 된 것과 다른 인코딩으로 느린 디코딩을하는 다양한 소스에서 나올 수도 있습니다. 이것은 웹에서 검색된 텍스트에서 일반적입니다. Python 패키지 &lt;a href=&quot;https://github.com/LuminosoInsight/python-ftfy&quot;&gt;ftfy&lt;/a&gt; 는 일부 클래스의 디코딩 오류를 자동으로 정렬 할 수 있으므로 알 수없는 텍스트를 &lt;code&gt;latin-1&lt;/code&gt; 로 디코딩 한 다음 &lt;code&gt;ftfy&lt;/code&gt; 를 사용하여 오류를 수정할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="f1cc9e37cbdee25ad27a9a2fdb64bc7fff098c7f" translate="yes" xml:space="preserve">
          <source>Real-world data set</source>
          <target state="translated">실제 데이터 세트</target>
        </trans-unit>
        <trans-unit id="3f7e1fd9149cf557b13e1453c928ae10ffbc6fe9" translate="yes" xml:space="preserve">
          <source>Recall</source>
          <target state="translated">Recall</target>
        </trans-unit>
        <trans-unit id="259d26fcd1552acd4759cfc21f7fa3b52a38a9cd" translate="yes" xml:space="preserve">
          <source>Recall (\(R\)) is defined as the number of true positives (\(T_p\)) over the number of true positives plus the number of false negatives (\(F_n\)).</source>
          <target state="translated">리콜 (\ (R \))은 진양 수에 오음 수 (\ (F_n \))를 더한 진양 수 (\ (T_p \))로 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="2810a64dc1f258f67d5c7c98ab6b2f2d2b737db6" translate="yes" xml:space="preserve">
          <source>Recall is defined as \(\frac{T_p}{T_p+F_n}\), where \(T_p+F_n\) does not depend on the classifier threshold. This means that lowering the classifier threshold may increase recall, by increasing the number of true positive results. It is also possible that lowering the threshold may leave recall unchanged, while the precision fluctuates.</source>
          <target state="translated">리콜은 \ (\ frac {T_p} {T_p + F_n} \)로 정의되며, 여기서 \ (T_p + F_n \)은 분류 자 ​​임계 값에 의존하지 않습니다. 이는 분류기 임계 값을 낮추면 진정한 긍정적 인 결과의 수를 증가시켜 리콜을 증가시킬 수 있습니다. 임계 값을 낮추면 리콜이 변경되지 않고 정밀도가 변동될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="12c28c24975811d7eeb74c51dd4566faa827303c" translate="yes" xml:space="preserve">
          <source>Recall of the positive class in binary classification or weighted average of the recall of each class for the multiclass task.</source>
          <target state="translated">이진 분류에서 양수 클래스의 리콜 또는 멀티 클래스 작업에 대한 각 클래스의 리콜의 가중 평균.</target>
        </trans-unit>
        <trans-unit id="9b0d874ad6f60c8a5546b2d91aee9774c21ade6e" translate="yes" xml:space="preserve">
          <source>Recall that the chi-square test measures dependence between stochastic variables, so using this function &amp;ldquo;weeds out&amp;rdquo; the features that are the most likely to be independent of class and therefore irrelevant for classification.</source>
          <target state="translated">카이-제곱 검정은 확률 변수 간의 종속성을 측정하므로이 함수를 사용하면 클래스와 무관하고 분류와 관련이 없을 가능성이 가장 큰 특징을 &quot;잡아냅니다&quot;.</target>
        </trans-unit>
        <trans-unit id="478b7b045cf681a86e016d3a84881b0be5302b03" translate="yes" xml:space="preserve">
          <source>Receiver Operating Characteristic (ROC)</source>
          <target state="translated">수신기 작동 특성 (ROC)</target>
        </trans-unit>
        <trans-unit id="4e47188effac531b8036f078b2d1c56b3dc650b8" translate="yes" xml:space="preserve">
          <source>Receiver Operating Characteristic (ROC) with cross validation</source>
          <target state="translated">교차 검증 기능을 갖춘 ROC (수신기 동작 특성)</target>
        </trans-unit>
        <trans-unit id="b7f0928f87fcbb2ba15fc48d2fbbcee612b6e0c2" translate="yes" xml:space="preserve">
          <source>Recent theoretical results, however, show that the runtime to get some desired optimization accuracy does not increase as the training set size increases.</source>
          <target state="translated">그러나 최근의 이론적 결과는 훈련 세트 크기가 증가함에 따라 원하는 최적화 정확도를 얻기위한 런타임이 증가하지 않음을 보여줍니다.</target>
        </trans-unit>
        <trans-unit id="5906f3535fa47c9d81e0c2a781b29c5e0d43c1fa" translate="yes" xml:space="preserve">
          <source>Recently deprecated</source>
          <target state="translated">최근 지원 중단</target>
        </trans-unit>
        <trans-unit id="9801ca3e1180905873a07a61b9fbf4250f6ef67b" translate="yes" xml:space="preserve">
          <source>Recognizing hand-written digits</source>
          <target state="translated">손으로 쓴 숫자 인식</target>
        </trans-unit>
        <trans-unit id="6422fcc967f452634a501ffeeec039bbb50d3cbc" translate="yes" xml:space="preserve">
          <source>Recommendation</source>
          <target state="translated">Recommendation</target>
        </trans-unit>
        <trans-unit id="7ae114b4940981c3f59a807902e797cfb8b9ed0c" translate="yes" xml:space="preserve">
          <source>Reconstruct the image from all of its patches.</source>
          <target state="translated">모든 패치에서 이미지를 재구성하십시오.</target>
        </trans-unit>
        <trans-unit id="a69bf0379a492c240c469c84a534a2a64338d098" translate="yes" xml:space="preserve">
          <source>Reconstruction error associated with &lt;code&gt;embedding_&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;embedding_&lt;/code&gt; 와 관련된 재구성 오류</target>
        </trans-unit>
        <trans-unit id="1947f1902face65ec435d917879598dbc8ce6456" translate="yes" xml:space="preserve">
          <source>Reconstruction error for the embedding vectors. Equivalent to &lt;code&gt;norm(Y - W Y, 'fro')**2&lt;/code&gt;, where W are the reconstruction weights.</source>
          <target state="translated">임베딩 벡터에 대한 재구성 오류. 상당 &lt;code&gt;norm(Y - W Y, 'fro')**2&lt;/code&gt; W가 재구성 가중치이다.</target>
        </trans-unit>
        <trans-unit id="ca4afd84f128c746490dc4294009897f387b924c" translate="yes" xml:space="preserve">
          <source>Recover the sources from X (apply the unmixing matrix).</source>
          <target state="translated">X에서 소스를 복구합니다 (믹싱 매트릭스 적용).</target>
        </trans-unit>
        <trans-unit id="5189873de2645d7e9d6e984c2e4dcb87fbddd6b3" translate="yes" xml:space="preserve">
          <source>Recovering a graphical structure from correlations in the data is a challenging thing. If you are interested in such recovery keep in mind that:</source>
          <target state="translated">데이터의 상관 관계에서 그래픽 구조를 복구하는 것은 어려운 일입니다. 그러한 회복에 관심이 있다면 다음을 명심하십시오.</target>
        </trans-unit>
        <trans-unit id="5137c9a2f6442417e8b7aba1873576c030b1a869" translate="yes" xml:space="preserve">
          <source>Recovery is easier from a correlation matrix than a covariance matrix: standardize your observations before running &lt;a href=&quot;generated/sklearn.covariance.graphicallasso#sklearn.covariance.GraphicalLasso&quot;&gt;&lt;code&gt;GraphicalLasso&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">공분산 행렬보다 상관 행렬에서 복구가 더 쉽습니다. &lt;a href=&quot;generated/sklearn.covariance.graphicallasso#sklearn.covariance.GraphicalLasso&quot;&gt; &lt;code&gt;GraphicalLasso&lt;/code&gt; &lt;/a&gt; 를 실행하기 전에 관측치를 표준화하십시오.</target>
        </trans-unit>
        <trans-unit id="c8fe62f88fb932af5ce49e0891e6c0663bd4c78a" translate="yes" xml:space="preserve">
          <source>Recurse for subsets \(Q_{left}(\theta^*)\) and \(Q_{right}(\theta^*)\) until the maximum allowable depth is reached, \(N_m &amp;lt; \min_{samples}\) or \(N_m = 1\).</source>
          <target state="translated">허용되는 최대 깊이에 도달 할 때까지 \ (Q_ {left} (\ theta ^ *) \) 및 \ (Q_ {right} (\ theta ^ *) \) 하위 집합에 대해 반복합니다. \ (N_m &amp;lt;\ min_ {samples} \ ) 또는 \ (N_m = 1 \)입니다.</target>
        </trans-unit>
        <trans-unit id="458090dfd850799fafd4039868e137b6110733d3" translate="yes" xml:space="preserve">
          <source>Recursive feature elimination</source>
          <target state="translated">재귀 기능 제거</target>
        </trans-unit>
        <trans-unit id="876936c1a03ad35aaee4d7c0a210a8b4cbc79636" translate="yes" xml:space="preserve">
          <source>Recursive feature elimination with built-in cross-validated selection of the best number of features</source>
          <target state="translated">내장 된 교차 검증 된 최상의 기능을 선택하여 재귀 기능 제거</target>
        </trans-unit>
        <trans-unit id="b841c9268f6d1867d5de64daddaf5154745ad526" translate="yes" xml:space="preserve">
          <source>Recursive feature elimination with cross-validation</source>
          <target state="translated">교차 유효성 검사를 통한 재귀 기능 제거</target>
        </trans-unit>
        <trans-unit id="f4a79ff0d559c91d907224b612195b949c0dcbb9" translate="yes" xml:space="preserve">
          <source>Recursively merges the pair of clusters that minimally increases a given linkage distance.</source>
          <target state="translated">주어진 연결 거리를 최소화하는 클러스터 쌍을 재귀 적으로 병합합니다.</target>
        </trans-unit>
        <trans-unit id="ddfcf381f764140d92c6bcaa7d2f36dd958b0974" translate="yes" xml:space="preserve">
          <source>Recursively merges the pair of clusters that minimally increases within-cluster variance.</source>
          <target state="translated">클러스터 내 분산을 최소화하는 클러스터 쌍을 재귀 적으로 병합합니다.</target>
        </trans-unit>
        <trans-unit id="cc9db3a795571c7e71f45670a1da7ff49b5f1557" translate="yes" xml:space="preserve">
          <source>Red</source>
          <target state="translated">Red</target>
        </trans-unit>
        <trans-unit id="bc205f81be4a216353df393b38e6e448e3d6f659" translate="yes" xml:space="preserve">
          <source>Reduce X to the selected features and then predict using the</source>
          <target state="translated">선택한 기능으로 X를 줄인 다음</target>
        </trans-unit>
        <trans-unit id="bf9e72d4c986bce41fdc36284d8c696fc7cd1045" translate="yes" xml:space="preserve">
          <source>Reduce X to the selected features and then predict using the underlying estimator.</source>
          <target state="translated">X를 선택된 피처로 줄이고 기본 추정기를 사용하여 예측합니다.</target>
        </trans-unit>
        <trans-unit id="8d212e578de2f7d8cae3e10b6613c11b25d96417" translate="yes" xml:space="preserve">
          <source>Reduce X to the selected features and then return the score of the</source>
          <target state="translated">선택한 지형지 ​​물로 X를 줄인 다음</target>
        </trans-unit>
        <trans-unit id="b2ba56d17af6254814e9e8837c28ebdbfdf3e81f" translate="yes" xml:space="preserve">
          <source>Reduce X to the selected features and then return the score of the underlying estimator.</source>
          <target state="translated">X를 선택된 피처로 줄이고 기본 추정기의 점수를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="5ac8754204592a64bbc9d9c861c2255ccc176581" translate="yes" xml:space="preserve">
          <source>Reduce X to the selected features.</source>
          <target state="translated">선택한 기능으로 X를 줄입니다.</target>
        </trans-unit>
        <trans-unit id="bd16969298621fa8c1f346760a523bd0b16f816f" translate="yes" xml:space="preserve">
          <source>Reduce dimensionality through Gaussian random projection</source>
          <target state="translated">가우스 랜덤 프로젝션을 통한 차원 축소</target>
        </trans-unit>
        <trans-unit id="be0672c3157469863e0dbc2c594e8a7dbae8ea2b" translate="yes" xml:space="preserve">
          <source>Reduce dimensionality through sparse random projection</source>
          <target state="translated">희소 랜덤 프로젝션을 통한 차원 축소</target>
        </trans-unit>
        <trans-unit id="44394b963df355b53266b400bd5efd0a3d98a2e3" translate="yes" xml:space="preserve">
          <source>Reduced version of X. This will always be a dense array.</source>
          <target state="translated">X의 축소 버전. 항상 밀도가 높은 배열입니다.</target>
        </trans-unit>
        <trans-unit id="ee5b3fc2a4bbfe1e0e4647a94f46549e1aa8f492" translate="yes" xml:space="preserve">
          <source>Reducing the tendency to crowd points together at the center</source>
          <target state="translated">중앙에서 포인트를 모으는 경향 감소</target>
        </trans-unit>
        <trans-unit id="4e5aa8a684683e1c180d9009332ba7545707f6be" translate="yes" xml:space="preserve">
          <source>Refer &lt;a href=&quot;../cross_validation#cross-validation&quot;&gt;User Guide&lt;/a&gt; for the various cross-validation strategies that can be used here.</source>
          <target state="translated">여기에서 사용할 수있는 다양한 교차 유효성 검사 전략에 대해서는 사용 &lt;a href=&quot;../cross_validation#cross-validation&quot;&gt;설명서&lt;/a&gt; 를 참조 하십시오.</target>
        </trans-unit>
        <trans-unit id="292c4a00ad1e679d3207ae797de45ae0ac017706" translate="yes" xml:space="preserve">
          <source>Refer the &lt;a href=&quot;../../modules/metrics#metrics&quot;&gt;metrics module&lt;/a&gt; to learn more on the available scoring methods.</source>
          <target state="translated">사용 가능한 스코어링 방법에 대한 자세한 내용 은 &lt;a href=&quot;../../modules/metrics#metrics&quot;&gt;메트릭 모듈&lt;/a&gt; 을 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="0434a1e9c22e391418e05e3fd58acc0ff48a17cd" translate="yes" xml:space="preserve">
          <source>Refer to the &lt;a href=&quot;generated/sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt;&lt;code&gt;KDTree&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; class documentation for more information on the options available for nearest neighbors searches, including specification of query strategies, distance metrics, etc. For a list of available metrics, see the documentation of the &lt;a href=&quot;generated/sklearn.neighbors.distancemetric#sklearn.neighbors.DistanceMetric&quot;&gt;&lt;code&gt;DistanceMetric&lt;/code&gt;&lt;/a&gt; class.</source>
          <target state="translated">쿼리 전략, 거리 메트릭 등의 사양을 포함하여 가장 가까운 이웃 검색에 사용할 수있는 옵션에 대한 자세한 내용 은 &lt;a href=&quot;generated/sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt; &lt;code&gt;KDTree&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; &lt;/a&gt; 클래스 설명서를 참조하십시오. 사용 가능한 메트릭 목록은 &lt;a href=&quot;generated/sklearn.neighbors.distancemetric#sklearn.neighbors.DistanceMetric&quot;&gt; &lt;code&gt;DistanceMetric&lt;/code&gt; &lt;/a&gt; 클래스 설명서를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="45c3dc1c7731c6185824876ed514e54f71bacb64" translate="yes" xml:space="preserve">
          <source>Reference:</source>
          <target state="translated">Reference:</target>
        </trans-unit>
        <trans-unit id="0807ecc3a87cd348151a8742654a4d11738eee42" translate="yes" xml:space="preserve">
          <source>Reference: Brendan J. Frey and Delbert Dueck, &amp;ldquo;Clustering by Passing Messages Between Data Points&amp;rdquo;, Science Feb. 2007</source>
          <target state="translated">참조 : Brendan J. Frey와 Delbert Dueck,&amp;ldquo;데이터 포인트간에 메시지를 전달하여 클러스터링&amp;rdquo;, 과학 2007 년 2 월</target>
        </trans-unit>
        <trans-unit id="5d20d0fee3b91643dd8d272ac33d01ca95179d82" translate="yes" xml:space="preserve">
          <source>References</source>
          <target state="translated">References</target>
        </trans-unit>
        <trans-unit id="70202c45dcdc26b5b6c5b6ae6186520b5dbf9a54" translate="yes" xml:space="preserve">
          <source>References &lt;a href=&quot;#manning2008&quot; id=&quot;id16&quot;&gt;[Manning2008]&lt;/a&gt; and &lt;a href=&quot;#everingham2010&quot; id=&quot;id17&quot;&gt;[Everingham2010]&lt;/a&gt; present alternative variants of AP that interpolate the precision-recall curve. Currently, &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; does not implement any interpolated variant. References &lt;a href=&quot;#davis2006&quot; id=&quot;id18&quot;&gt;[Davis2006]&lt;/a&gt; and &lt;a href=&quot;#flach2015&quot; id=&quot;id19&quot;&gt;[Flach2015]&lt;/a&gt; describe why a linear interpolation of points on the precision-recall curve provides an overly-optimistic measure of classifier performance. This linear interpolation is used when computing area under the curve with the trapezoidal rule in &lt;a href=&quot;generated/sklearn.metrics.auc#sklearn.metrics.auc&quot;&gt;&lt;code&gt;auc&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">참고 문헌 &lt;a href=&quot;#manning2008&quot; id=&quot;id16&quot;&gt;[Manning2008]&lt;/a&gt; 및 &lt;a href=&quot;#everingham2010&quot; id=&quot;id17&quot;&gt;[Everingham2010]&lt;/a&gt; 은 정밀 리콜 곡선을 보간하는 AP의 대체 변형을 제시합니다. 현재 &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt; 는 보간 변형을 구현하지 않습니다. 참고 문헌 &lt;a href=&quot;#davis2006&quot; id=&quot;id18&quot;&gt;[Davis2006]&lt;/a&gt; 및 &lt;a href=&quot;#flach2015&quot; id=&quot;id19&quot;&gt;[Flach2015]&lt;/a&gt; 는 정밀 리콜 곡선에서 점의 선형 보간이 과도하게 낙관적 인 분류기 성능 측정을 제공하는 이유를 설명합니다. 이 선형 보간은 &lt;a href=&quot;generated/sklearn.metrics.auc#sklearn.metrics.auc&quot;&gt; &lt;code&gt;auc&lt;/code&gt; &lt;/a&gt; 에서 사다리꼴 규칙으로 곡선 아래 면적을 계산할 때 사용됩니다 .</target>
        </trans-unit>
        <trans-unit id="9d1e4e7d27b519b1da3d7266c9c87d7861741080" translate="yes" xml:space="preserve">
          <source>References:</source>
          <target state="translated">References:</target>
        </trans-unit>
        <trans-unit id="070e67caa8030cdce21f1126698befb8bcb7259d" translate="yes" xml:space="preserve">
          <source>Refine the implementation and iterate until the exercise is solved.</source>
          <target state="translated">구현을 세분화하고 연습이 해결 될 때까지 반복하십시오.</target>
        </trans-unit>
        <trans-unit id="30293f3d46bf342b7b87609e1d9e2d226b609141" translate="yes" xml:space="preserve">
          <source>Refit an estimator using the best found parameters on the whole dataset.</source>
          <target state="translated">전체 데이터 세트에서 가장 잘 찾은 모수를 사용하여 추정량을 다시 맞 춥니 다.</target>
        </trans-unit>
        <trans-unit id="11dc7769b39c7e2fbfa28c7d6e99d31fbe0999cf" translate="yes" xml:space="preserve">
          <source>Refitting and updating parameters</source>
          <target state="translated">매개 변수 재설정 및 업데이트</target>
        </trans-unit>
        <trans-unit id="2641cb481062942bba2486cbdfe6e29aaa79719f" translate="yes" xml:space="preserve">
          <source>Regarding the Nearest Neighbors algorithms, if it is found that two neighbors, neighbor &lt;code&gt;k+1&lt;/code&gt; and &lt;code&gt;k&lt;/code&gt;, have identical distances but different labels, the results will depend on the ordering of the training data.</source>
          <target state="translated">가장 가까운 이웃 알고리즘과 관련하여 이웃 &lt;code&gt;k+1&lt;/code&gt; 과 &lt;code&gt;k&lt;/code&gt; 두 이웃 이 동일한 거리를 가지지 만 레이블이 다른 경우 결과는 훈련 데이터의 순서에 따라 달라집니다.</target>
        </trans-unit>
        <trans-unit id="3a4e04e41225aa8ff5e407d1e9442425d3914882" translate="yes" xml:space="preserve">
          <source>Regarding the Nearest Neighbors algorithms, if two neighbors \(k+1\) and \(k\) have identical distances but different labels, the result will depend on the ordering of the training data.</source>
          <target state="translated">가장 가까운 이웃 알고리즘과 관련하여 두 이웃 \ (k + 1 \) 및 \ (k \)가 동일한 거리이지만 레이블이 다른 경우 결과는 훈련 데이터의 순서에 따라 달라집니다.</target>
        </trans-unit>
        <trans-unit id="1eb1498dac3539eb922647f7dc4e358f9465b670" translate="yes" xml:space="preserve">
          <source>Regression</source>
          <target state="translated">Regression</target>
        </trans-unit>
        <trans-unit id="6f098a92c565caa36624cdec85935988f88416e5" translate="yes" xml:space="preserve">
          <source>Regression based on k-nearest neighbors.</source>
          <target state="translated">k- 최근 접 이웃에 기반한 회귀.</target>
        </trans-unit>
        <trans-unit id="e52baabe91c57b86ba9b6be948c44c1505083889" translate="yes" xml:space="preserve">
          <source>Regression based on neighbors within a fixed radius.</source>
          <target state="translated">고정 반경 내 이웃을 기반으로 한 회귀</target>
        </trans-unit>
        <trans-unit id="86da186323db03ac887bf6826a44853992a16e47" translate="yes" xml:space="preserve">
          <source>Regression error for each estimator in the boosted ensemble.</source>
          <target state="translated">부스트 앙상블의 각 추정기에 대한 회귀 오류.</target>
        </trans-unit>
        <trans-unit id="681b64b08476ebf3542e41565130a2865d2ad32a" translate="yes" xml:space="preserve">
          <source>Regression metrics</source>
          <target state="translated">회귀 메트릭</target>
        </trans-unit>
        <trans-unit id="b13f44be1a8f68647be5c088688a38c172f2da40" translate="yes" xml:space="preserve">
          <source>Regression targets are cast to &lt;code&gt;float64&lt;/code&gt; and classification targets are maintained:</source>
          <target state="translated">회귀 목표는 &lt;code&gt;float64&lt;/code&gt; 로 캐스트 되고 분류 목표는 유지됩니다.</target>
        </trans-unit>
        <trans-unit id="f3b24a4806e909790a107209c611ee2bc64eea03" translate="yes" xml:space="preserve">
          <source>Regressor chains (see &lt;code&gt;RegressorChain&lt;/code&gt;) is analogous to ClassifierChain as a way of combining a number of regressions into a single multi-target model that is capable of exploiting correlations among targets.</source>
          <target state="translated">회귀 체인 ( &lt;code&gt;RegressorChain&lt;/code&gt; 참조 )은 여러 회귀를 대상 간의 상관 관계를 활용할 수있는 단일 다중 대상 모델로 결합하는 방법으로 ClassifierChain과 유사합니다.</target>
        </trans-unit>
        <trans-unit id="71deff46eadb998974bb5b523046459c4126171b" translate="yes" xml:space="preserve">
          <source>Regressor object such as derived from &lt;code&gt;RegressorMixin&lt;/code&gt;. This regressor will automatically be cloned each time prior to fitting.</source>
          <target state="translated">회귀로부터 유도로는 객체 &lt;code&gt;RegressorMixin&lt;/code&gt; . 이 회귀는 피팅하기 전에 매번 자동으로 복제됩니다.</target>
        </trans-unit>
        <trans-unit id="8ee5e8c1b06e8eb22a8ed00eac909d93542fb00f" translate="yes" xml:space="preserve">
          <source>Regular expression denoting what constitutes a &amp;ldquo;token&amp;rdquo;, only used if &lt;code&gt;analyzer == 'word'&lt;/code&gt;. The default regexp select tokens of 2 or more alphanumeric characters (punctuation is completely ignored and always treated as a token separator).</source>
          <target state="translated">&amp;ldquo;토큰&amp;rdquo;을 구성하는 것을 나타내는 정규식으로 &lt;code&gt;analyzer == 'word'&lt;/code&gt; 경우에만 사용됩니다 . 기본 정규 표현식 선택 토큰은 2 개 이상의 영숫자 문자입니다. 구두점은 완전히 무시되며 항상 토큰 구분 기호로 처리됩니다.</target>
        </trans-unit>
        <trans-unit id="59f33d089250e1e5437cf1a6ee8788463004eb35" translate="yes" xml:space="preserve">
          <source>Regular expression denoting what constitutes a &amp;ldquo;token&amp;rdquo;, only used if &lt;code&gt;analyzer == 'word'&lt;/code&gt;. The default regexp selects tokens of 2 or more alphanumeric characters (punctuation is completely ignored and always treated as a token separator).</source>
          <target state="translated">&amp;ldquo;토큰&amp;rdquo;을 구성하는 것을 나타내는 정규식으로 &lt;code&gt;analyzer == 'word'&lt;/code&gt; 경우에만 사용됩니다 . 기본 정규 표현식은 2 개 이상의 영숫자 토큰을 선택합니다 (구두는 완전히 무시되고 항상 토큰 구분 기호로 처리됨).</target>
        </trans-unit>
        <trans-unit id="be77bc307e84a0aac10925d8f1fc2021108dec7a" translate="yes" xml:space="preserve">
          <source>Regularization parameter.</source>
          <target state="translated">정규화 매개 변수.</target>
        </trans-unit>
        <trans-unit id="9b62127743cd97ba6ad4b32187def42a9377f6f5" translate="yes" xml:space="preserve">
          <source>Regularization path of L1- Logistic Regression</source>
          <target state="translated">L1- 로지스틱 회귀의 정규화 경로</target>
        </trans-unit>
        <trans-unit id="1d2806ac87cdfa838914ff36046d85dada345fed" translate="yes" xml:space="preserve">
          <source>Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to &lt;code&gt;C^-1&lt;/code&gt; in other linear models such as LogisticRegression or LinearSVC.</source>
          <target state="translated">정규화 강도; 양수 부동이어야합니다. 정규화는 문제의 컨디셔닝을 개선하고 추정값의 분산을 줄입니다. 값이 클수록 정규화가 더 강력 해집니다. 알파 는 LogisticRegression 또는 LinearSVC와 같은 다른 선형 모델에서 &lt;code&gt;C^-1&lt;/code&gt; 에 해당합니다 .</target>
        </trans-unit>
        <trans-unit id="be6006907290ebd855d441d8740e427b29c7dba1" translate="yes" xml:space="preserve">
          <source>Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to &lt;code&gt;C^-1&lt;/code&gt; in other linear models such as LogisticRegression or LinearSVC. If an array is passed, penalties are assumed to be specific to the targets. Hence they must correspond in number.</source>
          <target state="translated">정규화 강도; 양수 부동이어야합니다. 정규화는 문제의 컨디셔닝을 개선하고 추정값의 분산을 줄입니다. 값이 클수록 정규화가 더 강력 해집니다. 알파 는 LogisticRegression 또는 LinearSVC와 같은 다른 선형 모델에서 &lt;code&gt;C^-1&lt;/code&gt; 에 해당합니다 . 배열이 전달되면 페널티는 대상에 특정한 것으로 간주됩니다. 따라서 숫자와 일치해야합니다.</target>
        </trans-unit>
        <trans-unit id="b376a08d614180566b427fdacf91c0818ef5efed" translate="yes" xml:space="preserve">
          <source>Regularization:</source>
          <target state="translated">Regularization:</target>
        </trans-unit>
        <trans-unit id="1d68b45d1c0799ca4bfb1c8452cff406beffaec4" translate="yes" xml:space="preserve">
          <source>Regularizes the covariance estimate as &lt;code&gt;(1-reg_param)*Sigma + reg_param*np.eye(n_features)&lt;/code&gt;</source>
          <target state="translated">공분산 추정값을 &lt;code&gt;(1-reg_param)*Sigma + reg_param*np.eye(n_features)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="0dc3de67f15c489785125c5ff202f5bb5c1de138" translate="yes" xml:space="preserve">
          <source>Related links:</source>
          <target state="translated">관련된 링크들:</target>
        </trans-unit>
        <trans-unit id="874f63e18691b726b5a14962b962788a3924c9f2" translate="yes" xml:space="preserve">
          <source>Related packages</source>
          <target state="translated">관련 패키지</target>
        </trans-unit>
        <trans-unit id="752b35a2a37229a8c218e759b56115e98ae4923e" translate="yes" xml:space="preserve">
          <source>Relative or absolute numbers of training examples that will be used to generate the learning curve. If the dtype is float, it is regarded as a fraction of the maximum size of the training set (that is determined by the selected validation method), i.e. it has to be within (0, 1]. Otherwise it is interpreted as absolute sizes of the training sets. Note that for classification the number of samples usually have to be big enough to contain at least one sample from each class. (default: np.linspace(0.1, 1.0, 5))</source>
          <target state="translated">학습 곡선을 생성하는 데 사용될 상대적 또는 절대적 수의 훈련 예. dtype이 float 인 경우 훈련 세트의 최대 크기 (선택한 유효성 검사 방법에 의해 결정됨)의 일부로 간주됩니다 (즉, (0, 1) 이내 여야 함). 그렇지 않으면 절대 크기로 해석됩니다. 분류를 위해 샘플 수는 일반적으로 각 클래스의 샘플을 하나 이상 포함 할 수있을 정도로 커야합니다 (기본값 : np.linspace (0.1, 1.0, 5)).</target>
        </trans-unit>
        <trans-unit id="e736750a2d9c467a89ca7f6403004177eb48ae4d" translate="yes" xml:space="preserve">
          <source>Relative tolerance with regards to inertia to declare convergence</source>
          <target state="translated">수렴을 선언하는 관성 관련 상대 허용 오차</target>
        </trans-unit>
        <trans-unit id="d655bc00f28882b8955bcd0dba64423f1a2a174f" translate="yes" xml:space="preserve">
          <source>Relative tolerance with respect to stress at which to declare convergence.</source>
          <target state="translated">수렴을 선언하는 스트레스에 대한 상대 허용 오차.</target>
        </trans-unit>
        <trans-unit id="d7020f448aaf8aacc8b4d63537e375e865fff9d8" translate="yes" xml:space="preserve">
          <source>Remarks</source>
          <target state="translated">Remarks</target>
        </trans-unit>
        <trans-unit id="781186a9e71c63b13e8ecce5db03573a72d6ea8a" translate="yes" xml:space="preserve">
          <source>Remember that the number of samples required to populate the tree doubles for each additional level the tree grows to. Use &lt;code&gt;max_depth&lt;/code&gt; to control the size of the tree to prevent overfitting.</source>
          <target state="translated">나무를 채우는 데 필요한 샘플 수는 나무가 자라는 각 추가 수준마다 두 배가됩니다. 과적 합을 방지하기 위해 &lt;code&gt;max_depth&lt;/code&gt; 를 사용 하여 트리의 크기를 제어하십시오.</target>
        </trans-unit>
        <trans-unit id="4bf4b976e49f074d117b87d559bb1d8cc83e7f07" translate="yes" xml:space="preserve">
          <source>Remove accents and perform other character normalization during the preprocessing step. &amp;lsquo;ascii&amp;rsquo; is a fast method that only works on characters that have an direct ASCII mapping. &amp;lsquo;unicode&amp;rsquo; is a slightly slower method that works on any characters. None (default) does nothing.</source>
          <target state="translated">전처리 단계에서 악센트를 제거하고 다른 문자 정규화를 수행하십시오. 'ascii'는 직접적인 ASCII 매핑이있는 문자에서만 작동하는 빠른 방법입니다. 'unicode'는 모든 문자에서 작동하는 약간 느린 방법입니다. 없음 (기본값)은 아무것도하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="88db5eb33c691862cae13f32b896f34ad0aa3e75" translate="yes" xml:space="preserve">
          <source>Remove cache elements to make cache size fit in &lt;code&gt;bytes_limit&lt;/code&gt;.</source>
          <target state="translated">캐시 크기를 &lt;code&gt;bytes_limit&lt;/code&gt; 에 맞추 려면 캐시 요소를 제거하십시오 .</target>
        </trans-unit>
        <trans-unit id="c30c90c09b566737e3cadee249c1dbd9a5837ec5" translate="yes" xml:space="preserve">
          <source>Rennie, J. D., Shih, L., Teevan, J., &amp;amp; Karger, D. R. (2003). &lt;a href=&quot;http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf&quot;&gt;Tackling the poor assumptions of naive bayes text classifiers.&lt;/a&gt; In ICML (Vol. 3, pp. 616-623).</source>
          <target state="translated">Rennie, JD, Shih, L., Teevan, J., &amp;amp; Karger, DR (2003). &lt;a href=&quot;http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf&quot;&gt;순진한 베이 텍스트 분류기의 잘못된 가정을 해결합니다. &lt;/a&gt;ICML에서 (Vol. 3, 616-623 페이지)</target>
        </trans-unit>
        <trans-unit id="22cb94c7b65fb89badcb1a01a1bdc2520f86d691" translate="yes" xml:space="preserve">
          <source>Rennie, J. D., Shih, L., Teevan, J., &amp;amp; Karger, D. R. (2003). Tackling the poor assumptions of naive bayes text classifiers. In ICML (Vol. 3, pp. 616-623). &lt;a href=&quot;http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf&quot;&gt;http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf&lt;/a&gt;</source>
          <target state="translated">Rennie, JD, Shih, L., Teevan, J., &amp;amp; Karger, DR (2003). 순진한 베이 텍스트 분류기의 잘못된 가정을 해결합니다. ICML에서 (Vol. 3, 616-623 페이지) &lt;a href=&quot;http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf&quot;&gt;http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7b2b956f64f931ba5071d16804050c6a770b0f6c" translate="yes" xml:space="preserve">
          <source>Repeated K-Fold cross validator.</source>
          <target state="translated">K-Fold 교차 검사기를 반복했습니다.</target>
        </trans-unit>
        <trans-unit id="09e61edee3c3dd07d459f8a0d674aecb9abdd36c" translate="yes" xml:space="preserve">
          <source>Repeated Stratified K-Fold cross validator.</source>
          <target state="translated">층화 된 K- 폴드 교차 검증기 반복.</target>
        </trans-unit>
        <trans-unit id="31147e137d241747c95bb952e4b6d40c9dd15695" translate="yes" xml:space="preserve">
          <source>Repeatedly calling fit or partial_fit when warm_start is True can result in a different solution than when calling fit a single time because of the way the data is shuffled.</source>
          <target state="translated">warm_start가 True 일 때 fit 또는 partial_fit을 반복해서 호출하면 데이터가 셔플되는 방식으로 인해 한 번만 fit을 호출 할 때와 다른 솔루션을 얻을 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="98c452fea3cbd269dd6ec70d0b5da29305d91d54" translate="yes" xml:space="preserve">
          <source>Repeatedly calling fit or partial_fit when warm_start is True can result in a different solution than when calling fit a single time because of the way the data is shuffled. If a dynamic learning rate is used, the learning rate is adapted depending on the number of samples already seen. Calling &lt;code&gt;fit&lt;/code&gt; resets this counter, while &lt;code&gt;partial_fit&lt;/code&gt; will result in increasing the existing counter.</source>
          <target state="translated">warm_start가 True 일 때 fit 또는 partial_fit을 반복해서 호출하면 데이터가 셔플되는 방식으로 인해 한 번만 fit을 호출 할 때와 다른 솔루션을 얻을 수 있습니다. 동적 학습 속도가 사용되는 경우 이미 본 샘플 수에 따라 학습 속도가 조정됩니다. &lt;code&gt;fit&lt;/code&gt; 을 호출 하면이 카운터가 재설정되지만 &lt;code&gt;partial_fit&lt;/code&gt; 은 기존 카운터를 증가시킵니다.</target>
        </trans-unit>
        <trans-unit id="c18fbe130422cbff11ad7c343bcdf981b3d72016" translate="yes" xml:space="preserve">
          <source>Repeats K-Fold n times with different randomization in each repetition.</source>
          <target state="translated">각 반복마다 다른 무작위 화로 K-Fold를 n 번 반복합니다.</target>
        </trans-unit>
        <trans-unit id="0f002866f53e9f1a3ed61e5e1fba772693ba8260" translate="yes" xml:space="preserve">
          <source>Repeats K-Fold n times.</source>
          <target state="translated">K- 폴드를 n 번 반복합니다.</target>
        </trans-unit>
        <trans-unit id="93875d4dd14cbae6916c80c9b56a2c66c78d91d4" translate="yes" xml:space="preserve">
          <source>Repeats Stratified K-Fold n times with different randomization in each repetition.</source>
          <target state="translated">각 반복에서 다른 무작위 화로 Stratified K-Fold를 n 번 반복합니다.</target>
        </trans-unit>
        <trans-unit id="bc3191276b0777bd1786ea11e208ca1193541dc8" translate="yes" xml:space="preserve">
          <source>Repeats Stratified K-Fold n times.</source>
          <target state="translated">층화 된 K- 폴드를 n 번 반복합니다.</target>
        </trans-unit>
        <trans-unit id="42a28d56095848fa739cd4170b90db72e0e3fba6" translate="yes" xml:space="preserve">
          <source>Representation of a Gaussian mixture model probability distribution. This class allows to estimate the parameters of a Gaussian mixture distribution.</source>
          <target state="translated">가우스 혼합 모델 확률 분포의 표현. 이 클래스는 가우스 혼합 분포의 모수를 추정 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7d32f20eabeb1b1b733ce2ae647c966b645ae539" translate="yes" xml:space="preserve">
          <source>Representation of weight vector(s) in kernel space</source>
          <target state="translated">커널 공간에서 가중치 벡터 표현</target>
        </trans-unit>
        <trans-unit id="685e526ebada5eb1618a4fc73ea62f4b94674dc7" translate="yes" xml:space="preserve">
          <source>Representing ICA in the feature space gives the view of &amp;lsquo;geometric ICA&amp;rsquo;: ICA is an algorithm that finds directions in the feature space corresponding to projections with high non-Gaussianity. These directions need not be orthogonal in the original feature space, but they are orthogonal in the whitened feature space, in which all directions correspond to the same variance.</source>
          <target state="translated">지형 공간에 ICA를 표시하면 '형상 ICA'가 표시됩니다. ICA는 비 가우시안이 높은 투영에 해당하는 지형 공간의 방향을 찾는 알고리즘입니다. 이러한 방향은 원래 형상 공간에서 직교 할 필요는 없지만 모든 방향이 동일한 분산에 해당하는 희게 된 형상 공간에서 직교합니다.</target>
        </trans-unit>
        <trans-unit id="c1838eb2b67d8c8494f46e5efb4e3cfa915b4c40" translate="yes" xml:space="preserve">
          <source>Representing data as sparse combinations of atoms from an overcomplete dictionary is suggested to be the way the mammalian primary visual cortex works. Consequently, dictionary learning applied on image patches has been shown to give good results in image processing tasks such as image completion, inpainting and denoising, as well as for supervised recognition tasks.</source>
          <target state="translated">과 완전 사전에서 나온 원자의 희소 조합으로 데이터를 나타내는 것은 포유류의 1 차 시각 피질이 작동하는 방식으로 제안됩니다. 결과적으로 이미지 패치에 적용된 사전 학습은 이미지 인식, 페인트 칠 및 노이즈 제거와 같은 이미지 처리 작업뿐만 아니라 감독 된 인식 작업에서도 좋은 결과를 제공하는 것으로 나타났습니다.</target>
        </trans-unit>
        <trans-unit id="ae4349c55f1ba2f99a753bd1f91ea54bfb7944a6" translate="yes" xml:space="preserve">
          <source>Represents the type of the target data as evaluated by utils.multiclass.type_of_target. Possible type are &amp;lsquo;continuous&amp;rsquo;, &amp;lsquo;continuous-multioutput&amp;rsquo;, &amp;lsquo;binary&amp;rsquo;, &amp;lsquo;multiclass&amp;rsquo;, &amp;lsquo;multiclass-multioutput&amp;rsquo;, &amp;lsquo;multilabel-indicator&amp;rsquo;, and &amp;lsquo;unknown&amp;rsquo;.</source>
          <target state="translated">utils.multiclass.type_of_target에 의해 평가 된 대상 데이터의 유형을 나타냅니다. 가능한 유형은 '연속', '연속 다중 출력', '이진', '멀티 클래스', '멀티 클래스 멀티 출력', '멀티 라벨 표시기'및 '알 수 없음'입니다.</target>
        </trans-unit>
        <trans-unit id="20fa62ad1345bc75375b53f86b5eb2c26d718a95" translate="yes" xml:space="preserve">
          <source>Requires little data preparation. Other techniques often require data normalisation, dummy variables need to be created and blank values to be removed. Note however that this module does not support missing values.</source>
          <target state="translated">데이터 준비가 거의 필요하지 않습니다. 다른 기술은 종종 데이터 정규화, 더미 변수 생성 및 공백 값 제거가 필요합니다. 그러나이 모듈은 결 측값을 지원하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="fb71177a5a5b56c5ebee3cf20f44c503add01c10" translate="yes" xml:space="preserve">
          <source>Resample arrays or sparse matrices in a consistent way</source>
          <target state="translated">일관된 방식으로 배열 또는 희소 행렬 리샘플링</target>
        </trans-unit>
        <trans-unit id="2e8f725f5911194d74f9dab654d27796744b8361" translate="yes" xml:space="preserve">
          <source>Reshape a 2D image into a collection of patches</source>
          <target state="translated">2D 이미지를 패치 모음으로 재구성</target>
        </trans-unit>
        <trans-unit id="8fa86d755254fa7609fa763e5412d46d718d125d" translate="yes" xml:space="preserve">
          <source>Reshaping the output when the function has several return values:</source>
          <target state="translated">함수에 여러 개의 반환 값이있을 때 출력 형태 변경 :</target>
        </trans-unit>
        <trans-unit id="29b6020807e8bc7f4d853b727bb5a844490062e9" translate="yes" xml:space="preserve">
          <source>Restrict coefficients to be &amp;gt;= 0. Be aware that you might want to remove fit_intercept which is set True by default.</source>
          <target state="translated">계수를&amp;gt; = 0으로 제한하십시오. 기본적으로 True로 설정된 fit_intercept를 제거 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="29979c4d4208dffcb3ff52bc6862f5032a097531" translate="yes" xml:space="preserve">
          <source>Restrict coefficients to be &amp;gt;= 0. Be aware that you might want to remove fit_intercept which is set True by default. Under the positive restriction the model coefficients do not converge to the ordinary-least-squares solution for small values of alpha. Only coefficients up to the smallest alpha value (&lt;code&gt;alphas_[alphas_ &amp;gt;
0.].min()&lt;/code&gt; when fit_path=True) reached by the stepwise Lars-Lasso algorithm are typically in congruence with the solution of the coordinate descent Lasso estimator. As a consequence using LassoLarsCV only makes sense for problems where a sparse solution is expected and/or reached.</source>
          <target state="translated">계수를&amp;gt; = 0으로 제한하십시오. 기본적으로 True로 설정된 fit_intercept를 제거 할 수 있습니다. 양의 제한 하에서, 모델 계수는 작은 알파 값에 대해 일반 최소 제곱 솔루션으로 수렴하지 않습니다. 단계적 Lars-Lasso 알고리즘에 의해 도달되는 fit_path = True 일 때 가장 작은 알파 값 ( &lt;code&gt;alphas_[alphas_ &amp;gt; 0.].min()&lt;/code&gt; 까지의 계수 만 일반적으로 좌표 하강 올가미 추정기의 해와 일치합니다. 결과적으로 LassoLarsCV를 사용하면 스파 스 솔루션이 예상되거나 도달하는 문제에 대해서만 의미가 있습니다.</target>
        </trans-unit>
        <trans-unit id="39ff48ef2c581a13fca510ce558fecfc50f8d1b9" translate="yes" xml:space="preserve">
          <source>Restrict coefficients to be &amp;gt;= 0. Be aware that you might want to remove fit_intercept which is set True by default. Under the positive restriction the model coefficients do not converge to the ordinary-least-squares solution for small values of alpha. Only coefficients up to the smallest alpha value (&lt;code&gt;alphas_[alphas_ &amp;gt;
0.].min()&lt;/code&gt; when fit_path=True) reached by the stepwise Lars-Lasso algorithm are typically in congruence with the solution of the coordinate descent Lasso estimator. As a consequence using LassoLarsIC only makes sense for problems where a sparse solution is expected and/or reached.</source>
          <target state="translated">계수를&amp;gt; = 0으로 제한하십시오. 기본적으로 True로 설정된 fit_intercept를 제거 할 수 있습니다. 양의 제한 하에서, 모델 계수는 작은 알파 값에 대해 일반 최소 제곱 솔루션으로 수렴하지 않습니다. 단계적 Lars-Lasso 알고리즘에 의해 도달되는 fit_path = True 일 때 가장 작은 알파 값 ( &lt;code&gt;alphas_[alphas_ &amp;gt; 0.].min()&lt;/code&gt; 까지의 계수 만 일반적으로 좌표 하강 올가미 추정기의 해와 일치합니다. 결과적으로 LassoLarsIC를 사용하면 스파 스 솔루션이 예상되거나 도달하는 문제에 대해서만 의미가 있습니다.</target>
        </trans-unit>
        <trans-unit id="82cf2cea5bace9dd3550046c8448d1e4ee78cc0a" translate="yes" xml:space="preserve">
          <source>Restrict coefficients to be &amp;gt;= 0. Be aware that you might want to remove fit_intercept which is set True by default. Under the positive restriction the model coefficients will not converge to the ordinary-least-squares solution for small values of alpha. Only coefficients up to the smallest alpha value (&lt;code&gt;alphas_[alphas_ &amp;gt;
0.].min()&lt;/code&gt; when fit_path=True) reached by the stepwise Lars-Lasso algorithm are typically in congruence with the solution of the coordinate descent Lasso estimator.</source>
          <target state="translated">계수를&amp;gt; = 0으로 제한하십시오. 기본적으로 True로 설정된 fit_intercept를 제거 할 수 있습니다. 양의 제한 하에서, 모델 계수는 작은 알파 값에 대한 일반 최소 제곱 솔루션으로 수렴되지 않습니다. 단계적 Lars-Lasso 알고리즘에 의해 도달되는 fit_path = True 일 때 가장 작은 알파 값 ( &lt;code&gt;alphas_[alphas_ &amp;gt; 0.].min()&lt;/code&gt; 까지의 계수 만 일반적으로 좌표 하강 올가미 추정기의 해와 일치합니다.</target>
        </trans-unit>
        <trans-unit id="cc4c23115ff5f9103869f3c0fe7331685f096b59" translate="yes" xml:space="preserve">
          <source>Restrict coefficients to be &amp;gt;= 0. This option is only allowed with method &amp;lsquo;lasso&amp;rsquo;. Note that the model coefficients will not converge to the ordinary-least-squares solution for small values of alpha. Only coefficients up to the smallest alpha value (&lt;code&gt;alphas_[alphas_ &amp;gt; 0.].min()&lt;/code&gt; when fit_path=True) reached by the stepwise Lars-Lasso algorithm are typically in congruence with the solution of the coordinate descent lasso_path function.</source>
          <target state="translated">계수를&amp;gt; = 0으로 제한하십시오.이 옵션은 'lasso'메소드에서만 허용됩니다. 모델 계수는 작은 알파 값에 대한 일반 최소 제곱 솔루션으로 수렴되지 않습니다. 단계적 Lars-Lasso 알고리즘에 의해 도달되는 fit_path = True 일 때 가장 작은 알파 값 ( &lt;code&gt;alphas_[alphas_ &amp;gt; 0.].min()&lt;/code&gt; 까지의 계수 만 일반적으로 좌표 하강 lasso_path 함수의 솔루션과 일치합니다.</target>
        </trans-unit>
        <trans-unit id="4e0abdd8dd5609a60428b9608c1cb689b8074f2a" translate="yes" xml:space="preserve">
          <source>Restrict the features to those in support using feature selection.</source>
          <target state="translated">기능 선택을 사용하여 지원되는 기능으로 기능을 제한하십시오.</target>
        </trans-unit>
        <trans-unit id="241925f53a3e23af00cffc7d748ec3aff26588ad" translate="yes" xml:space="preserve">
          <source>Restricted Boltzmann Machine features for digit classification</source>
          <target state="translated">숫자 분류를위한 제한된 Boltzmann Machine 기능</target>
        </trans-unit>
        <trans-unit id="7f3abfa37f2cf55ceba7590326cacc826953b894" translate="yes" xml:space="preserve">
          <source>Restricted Boltzmann machines (RBM) are unsupervised nonlinear feature learners based on a probabilistic model. The features extracted by an RBM or a hierarchy of RBMs often give good results when fed into a linear classifier such as a linear SVM or a perceptron.</source>
          <target state="translated">RBM (제한된 Boltzmann 기계)은 확률 모델을 기반으로하는 감독되지 않은 비선형 피쳐 학습자입니다. RBM 또는 RBM 계층 구조로 추출한 기능은 선형 SVM 또는 퍼셉트론과 같은 선형 분류기에 공급 될 때 종종 좋은 결과를 제공합니다.</target>
        </trans-unit>
        <trans-unit id="3f490bbf3bdf7bf63209c86a4bdc9ab5af3ad16a" translate="yes" xml:space="preserve">
          <source>Results obtained with LassoLarsIC are based on AIC/BIC criteria.</source>
          <target state="translated">LassoLarsIC으로 얻은 결과는 AIC / BIC 기준을 기반으로합니다.</target>
        </trans-unit>
        <trans-unit id="520127a681e9beff0545f08ff1691745aa6a2355" translate="yes" xml:space="preserve">
          <source>Results of the clustering, like &lt;code&gt;rows&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;rows&lt;/code&gt; 와 같은 클러스터링 결과 .</target>
        </trans-unit>
        <trans-unit id="f81af77a87bd6c53dcd13a31f0c98b93dfbb1730" translate="yes" xml:space="preserve">
          <source>Results of the clustering. &lt;code&gt;rows[i, r]&lt;/code&gt; is True if cluster &lt;code&gt;i&lt;/code&gt; contains row &lt;code&gt;r&lt;/code&gt;. Available only after calling &lt;code&gt;fit&lt;/code&gt;.</source>
          <target state="translated">클러스터링 결과. cluster &lt;code&gt;i&lt;/code&gt; 에 행 &lt;code&gt;r&lt;/code&gt; 이 포함 된 경우 &lt;code&gt;rows[i, r]&lt;/code&gt; 은 True 입니다. &lt;code&gt;fit&lt;/code&gt; 를 호출 한 후에 만 ​​사용할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="09c5e8d3474ffc187ec47434a9de70365f40524a" translate="yes" xml:space="preserve">
          <source>Retrieve all neighbors and average distance within radius r:</source>
          <target state="translated">반경 r 내의 모든 이웃과 평균 거리를 검색합니다.</target>
        </trans-unit>
        <trans-unit id="a21770a0dd9781336c9b39afe4d33a0b9399f538" translate="yes" xml:space="preserve">
          <source>Retrieve current values for configuration set by &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;set_config&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;set_config&lt;/code&gt; 에&lt;/a&gt; 의해 설정된 구성의 현재 값 검색</target>
        </trans-unit>
        <trans-unit id="795a8c10607f69a8d708655e1dfd2bda87866a63" translate="yes" xml:space="preserve">
          <source>Retrieve current values for configuration set by &lt;a href=&quot;sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;set_config&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;set_config&lt;/code&gt; 에&lt;/a&gt; 의해 설정된 구성의 현재 값 검색</target>
        </trans-unit>
        <trans-unit id="7d0b50936a7e8c687a75689a3dad17b7991a85ff" translate="yes" xml:space="preserve">
          <source>Return &lt;code&gt;True&lt;/code&gt;, if &lt;code&gt;y&lt;/code&gt; is in a multilabel format, else &lt;code&gt;`False&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;y&lt;/code&gt; 가 다중 레이블 형식 인 경우 &lt;code&gt;True&lt;/code&gt; 를 , 그렇지 않으면 &lt;code&gt;`False&lt;/code&gt; 를 반환 합니다.</target>
        </trans-unit>
        <trans-unit id="2cbe175cc2b51d30944704c3deb552cd5596a704" translate="yes" xml:space="preserve">
          <source>Return a callable that handles preprocessing and tokenization</source>
          <target state="translated">전처리 및 토큰 화를 처리하는 콜 러블 반환</target>
        </trans-unit>
        <trans-unit id="35ce21f46958d2a4d6fb1e298eab74d1576eefb9" translate="yes" xml:space="preserve">
          <source>Return a function that splits a string into a sequence of tokens</source>
          <target state="translated">문자열을 일련의 토큰으로 나누는 함수를 반환</target>
        </trans-unit>
        <trans-unit id="11d41c098e075f003f9bd2724f42d19606a938aa" translate="yes" xml:space="preserve">
          <source>Return a function to preprocess the text before tokenization</source>
          <target state="translated">토큰 화하기 전에 텍스트를 전처리하는 함수를 반환</target>
        </trans-unit>
        <trans-unit id="6bd61b6b672e63d28fbd6bae4611675d07beef25" translate="yes" xml:space="preserve">
          <source>Return a mask which is safe to use on X.</source>
          <target state="translated">X에서 사용하기에 안전한 마스크를 반환하십시오.</target>
        </trans-unit>
        <trans-unit id="2117f2c8a135db1ec3d7cfe90977838437ebd303" translate="yes" xml:space="preserve">
          <source>Return a node indicator matrix where non zero elements indicates that the samples goes through the nodes.</source>
          <target state="translated">0이 아닌 요소가 샘플이 노드를 통과 함을 나타내는 노드 표시기 행렬을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="00bb62ba59798790184b007f565618b4467e20e2" translate="yes" xml:space="preserve">
          <source>Return class labels or probabilities for X for each estimator.</source>
          <target state="translated">각 추정값에 대해 X에 대한 클래스 레이블 또는 확률을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="cd3438647a868f06b1d86d54754f891a6d1b48d4" translate="yes" xml:space="preserve">
          <source>Return feature names for output features</source>
          <target state="translated">출력 기능에 대한 기능 이름을 반환</target>
        </trans-unit>
        <trans-unit id="5493711c1bb2ce4e5d9065fe8f6089dfdca5aee9" translate="yes" xml:space="preserve">
          <source>Return feature names for output features.</source>
          <target state="translated">출력 기능의 기능 이름을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="f1402e1d8dc357778164e5a8d0f1414de1f7666d" translate="yes" xml:space="preserve">
          <source>Return items or rows from X using indices.</source>
          <target state="translated">인덱스를 사용하여 X에서 항목 또는 행을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="0576952c961c16373284e51db9969a6042ae18da" translate="yes" xml:space="preserve">
          <source>Return log probability estimates for the test vectors X.</source>
          <target state="translated">테스트 벡터 X에 대한 반환 로그 확률 추정치입니다.</target>
        </trans-unit>
        <trans-unit id="72809cd1af29120a326f0c3f682d953d3b6c6e96" translate="yes" xml:space="preserve">
          <source>Return log-probability estimates for the test vector X.</source>
          <target state="translated">테스트 벡터 X에 대한 로그 확률 추정값을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="a7f22acdaa22f15d766147d74260994078d30e7e" translate="yes" xml:space="preserve">
          <source>Return posterior probabilities of classification.</source>
          <target state="translated">분류의 사후 확률을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="5e90634978b3f0ad930c9250eb92f9e0314026f1" translate="yes" xml:space="preserve">
          <source>Return probability estimates for the test data X.</source>
          <target state="translated">테스트 데이터 X에 대한 확률 추정값을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="3cc65811d5c67b9339e5de3fe46c1d36fda147a2" translate="yes" xml:space="preserve">
          <source>Return probability estimates for the test vector X.</source>
          <target state="translated">테스트 벡터 X에 대한 확률 추정값을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="eda641cffe9cac67f3fb260fe22ffd308b7dc69c" translate="yes" xml:space="preserve">
          <source>Return probability estimates for the test vectors X.</source>
          <target state="translated">테스트 벡터 X에 대한 확률 추정값을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="3c1542898f8a4979431ead39d5c15b799d51545e" translate="yes" xml:space="preserve">
          <source>Return squared Euclidean distances.</source>
          <target state="translated">제곱 유클리드 거리를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="b6fe225e3cb643cedd5bc48ac43be276d960cd4f" translate="yes" xml:space="preserve">
          <source>Return staged predictions for X.</source>
          <target state="translated">X에 대한 단계별 예측을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="673aa7cb9999000b961a62897148f368c83b55e3" translate="yes" xml:space="preserve">
          <source>Return staged scores for X, y.</source>
          <target state="translated">X, y에 대한 단계별 점수를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="8cf4d1ff3f261b4818ca6a890ea14f5502b4b54a" translate="yes" xml:space="preserve">
          <source>Return terms per document with nonzero entries in X.</source>
          <target state="translated">X에서 0이 아닌 항목이있는 문서 당 용어를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="5cdf5c1eeea61e59e70be57a77213eebbb153cfb" translate="yes" xml:space="preserve">
          <source>Return the anomaly score of each sample using the IsolationForest algorithm</source>
          <target state="translated">IsolationForest 알고리즘을 사용하여 각 샘플의 이상 점수를 반환</target>
        </trans-unit>
        <trans-unit id="fe499de3a6f88d7210192161e1c6b2449ab1500c" translate="yes" xml:space="preserve">
          <source>Return the average Hamming loss between element of &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;y_true&lt;/code&gt; 와 &lt;code&gt;y_pred&lt;/code&gt; 요소 사이의 평균 해밍 손실을 반환합니다 .</target>
        </trans-unit>
        <trans-unit id="3b6f97194ee8e54eea84870d31851fd35f16981f" translate="yes" xml:space="preserve">
          <source>Return the average log-likelihood of all samples.</source>
          <target state="translated">모든 표본의 평균 로그 우도를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="c76a887a33fc9d47303cbdd34a0e4499db790aff" translate="yes" xml:space="preserve">
          <source>Return the bin identifier encoded as an integer value.</source>
          <target state="translated">정수 식별자로 인코딩 된 빈 식별자를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="2c7fad3d600f9c171ec8dd39485353f247ab50a0" translate="yes" xml:space="preserve">
          <source>Return the decision path in the forest</source>
          <target state="translated">숲에서 결정 경로를 반환</target>
        </trans-unit>
        <trans-unit id="d3a34834571e54a4248033c9eaba5b8e9bb1789f" translate="yes" xml:space="preserve">
          <source>Return the decision path in the tree</source>
          <target state="translated">트리에서 결정 경로를 반환</target>
        </trans-unit>
        <trans-unit id="4e96d8947123569170f97aefff01f74cf9b0a6ca" translate="yes" xml:space="preserve">
          <source>Return the feature importances (the higher, the more important the</source>
          <target state="translated">기능 중요도를 반환합니다 (높을수록</target>
        </trans-unit>
        <trans-unit id="a6dd0a8039005a5293ba64e678b28da7b07a204e" translate="yes" xml:space="preserve">
          <source>Return the feature importances (the higher, the more important the feature).</source>
          <target state="translated">기능 중요도를 리턴하십시오 (높을수록 기능이 중요 함).</target>
        </trans-unit>
        <trans-unit id="94661d32c77cb41c2127232860de2197f7083f9f" translate="yes" xml:space="preserve">
          <source>Return the feature importances.</source>
          <target state="translated">기능의 중요도를 돌려줍니다.</target>
        </trans-unit>
        <trans-unit id="0e8537aa46b4ea8a7cd6323f7580a004a7b06500" translate="yes" xml:space="preserve">
          <source>Return the formatted representation of the object.</source>
          <target state="translated">객체의 서식이 지정된 표현을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="6327801e23aebebbd4be478323001917b9194e97" translate="yes" xml:space="preserve">
          <source>Return the indices and distances of each point from the dataset lying in a ball with size &lt;code&gt;radius&lt;/code&gt; around the points of the query array. Points lying on the boundary are included in the results.</source>
          <target state="translated">쿼리 배열의 점 주위에 크기 &lt;code&gt;radius&lt;/code&gt; 있는 공에있는 데이터 세트에서 각 점의 인덱스와 거리를 반환합니다 . 경계에있는 점이 결과에 포함됩니다.</target>
        </trans-unit>
        <trans-unit id="0abc14c002459b9e0ac66d2f83f45cbf2ac07ca6" translate="yes" xml:space="preserve">
          <source>Return the indices and distances of some points from the dataset lying in a ball with size &lt;code&gt;radius&lt;/code&gt; around the points of the query array. Points lying on the boundary are included in the results.</source>
          <target state="translated">쿼리 배열의 점 주위에 크기 &lt;code&gt;radius&lt;/code&gt; 있는 공에있는 데이터 세트에서 일부 점의 인덱스와 거리를 반환합니다 . 경계에있는 점이 결과에 포함됩니다.</target>
        </trans-unit>
        <trans-unit id="59896f479363f206b5f17c3575cb26dc74dc0030" translate="yes" xml:space="preserve">
          <source>Return the inner statistics A (dictionary covariance) and B (data approximation). Useful to restart the algorithm in an online setting. If return_inner_stats is True, return_code is ignored</source>
          <target state="translated">내부 통계 A (사전 공분산) 및 B (데이터 근사)를 반환합니다. 온라인 설정에서 알고리즘을 다시 시작하는 데 유용합니다. return_inner_stats가 True 인 경우 return_code는 무시됩니다.</target>
        </trans-unit>
        <trans-unit id="71a76752665369a60f6ab1ee2da126886f72e89c" translate="yes" xml:space="preserve">
          <source>Return the kernel k(X, Y) and optionally its gradient.</source>
          <target state="translated">커널 k (X, Y) 및 선택적으로 그레디언트를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="c76fd50f1e2f18eb3de394ebc844504c0bd95a4d" translate="yes" xml:space="preserve">
          <source>Return the log of probability estimates.</source>
          <target state="translated">확률 추정값의 로그를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="ffd6e743e192ad562c49919b7b3f381f35e7b8ab" translate="yes" xml:space="preserve">
          <source>Return the log-likelihood of each sample.</source>
          <target state="translated">각 표본의 로그 우도를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="3b5cedcac6a255d68b2e31008e50600532cc0eda" translate="yes" xml:space="preserve">
          <source>Return the lowest bound for C such that for C in (l1_min_C, infinity) the model is guaranteed not to be empty.</source>
          <target state="translated">(l1_min_C, 무한대)의 C에 대해 모델이 비어 있지 않도록 C에 대한 최저 한계를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="a912065a7d66fe8acf25546053bf0686946ff49b" translate="yes" xml:space="preserve">
          <source>Return the lowest bound for C such that for C in (l1_min_C, infinity) the model is guaranteed not to be empty. This applies to l1 penalized classifiers, such as LinearSVC with penalty=&amp;rsquo;l1&amp;rsquo; and linear_model.LogisticRegression with penalty=&amp;rsquo;l1&amp;rsquo;.</source>
          <target state="translated">(l1_min_C, 무한대)의 C에 대해 모델이 비어 있지 않도록 C에 대한 최저 한계를 반환합니다. 이는 페널티 = 'l1'인 LinearSVC 및 페널티 = 'l1'인 linear_model.LogisticRegression과 같은 l1 페널티 분류기에 적용됩니다.</target>
        </trans-unit>
        <trans-unit id="78a008335b51a1c18596b7219334c44cdd4577a2" translate="yes" xml:space="preserve">
          <source>Return the number of CPUs.</source>
          <target state="translated">CPU 수를 반환하십시오.</target>
        </trans-unit>
        <trans-unit id="a83e61f9ab288a41ba43637db7406ca5b7c5e918" translate="yes" xml:space="preserve">
          <source>Return the path of the scikit-learn data dir.</source>
          <target state="translated">scikit-learn 데이터 디렉토리의 경로를 리턴하십시오.</target>
        </trans-unit>
        <trans-unit id="e508a8be5b82335ceafdbaf1e6ec3bbbf998c2f8" translate="yes" xml:space="preserve">
          <source>Return the shortest path length from source to all reachable nodes.</source>
          <target state="translated">소스에서 도달 가능한 모든 노드까지 최단 경로 길이를 반환하십시오.</target>
        </trans-unit>
        <trans-unit id="f99cff8804146f956c46d41c82ff30a32fcfa0ff" translate="yes" xml:space="preserve">
          <source>Returns -1 for anomalies/outliers and +1 for inliers.</source>
          <target state="translated">예외 / 이상치의 경우 -1을, 특이 치의 경우 +1을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="7411aff2f211ce9f855fdd4f002eb6a53a8bb626" translate="yes" xml:space="preserve">
          <source>Returns -1 for anomalies/outliers and 1 for inliers.</source>
          <target state="translated">예외 / 이상치의 경우 -1을 반환하고, 특이 치의 경우 1을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="414e03f46831714a940e3ebbea4ecf95a3ebf408" translate="yes" xml:space="preserve">
          <source>Returns -1 for outliers and 1 for inliers.</source>
          <target state="translated">특이 치의 경우 -1을, 특이 치의 경우 1을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="505b1feca885daf978e29c8dabb245621a145944" translate="yes" xml:space="preserve">
          <source>Returns True if the given estimator is (probably) a classifier.</source>
          <target state="translated">제공된 추정기가 분류자인 경우 True를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="a673678f28284206e4f771d2c532b3a9bf68458b" translate="yes" xml:space="preserve">
          <source>Returns True if the given estimator is (probably) a regressor.</source>
          <target state="translated">주어진 추정자가 회귀자인 경우 True를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="6877982ee547361eeeaa47d8ae2bb2ebf61437c5" translate="yes" xml:space="preserve">
          <source>Returns a clone of self with given hyperparameters theta.</source>
          <target state="translated">주어진 하이퍼 파라미터 세타를 가진 자기 복제를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="8748a6c3e3b86a33a87860e1f928708591c21db6" translate="yes" xml:space="preserve">
          <source>Returns a dictionary of shortest path lengths keyed by target.</source>
          <target state="translated">대상이 입력 한 최단 경로 길이의 사전을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="01c8da86ba8963c8f5e129fe43566909448c21a8" translate="yes" xml:space="preserve">
          <source>Returns a dynamically generated list of indices identifying the samples used for fitting each member of the ensemble, i.e., the in-bag samples.</source>
          <target state="translated">앙상블의 각 멤버 (즉, 가방 내 샘플)를 피팅하는 데 사용되는 샘플을 식별하는 동적으로 생성 된 인덱스 목록을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="da4e687b702358c2c6b9e13a18e3175368903c06" translate="yes" xml:space="preserve">
          <source>Returns a full set of errors in case of multioutput input.</source>
          <target state="translated">다중 출력 입력의 경우 전체 오류 세트를 리턴합니다.</target>
        </trans-unit>
        <trans-unit id="36c74e5d06437c1c84b60b753285776e0a5a1083" translate="yes" xml:space="preserve">
          <source>Returns a full set of errors when the input is of multioutput format.</source>
          <target state="translated">입력이 다중 출력 형식 인 경우 전체 오류 집합을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="70a672002707e9c7e153c69bb8b9bb04e4527348" translate="yes" xml:space="preserve">
          <source>Returns a full set of scores in case of multioutput input.</source>
          <target state="translated">다중 출력 입력의 경우 전체 점수 세트를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="71c211cc8f7f96892c718bc1f6426bd958810763" translate="yes" xml:space="preserve">
          <source>Returns a huge value if none of the values are positive</source>
          <target state="translated">양수 값이 없으면 큰 값을 반환합니다</target>
        </trans-unit>
        <trans-unit id="c704a97342e188146c3d1b7928d3c17a32957021" translate="yes" xml:space="preserve">
          <source>Returns a list of all hyperparameter specifications.</source>
          <target state="translated">모든 하이퍼 파라미터 사양의 목록을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="f0d7bca3b8b9fe8627158f5f4641022fd8b2f454" translate="yes" xml:space="preserve">
          <source>Returns a list of all hyperparameter.</source>
          <target state="translated">모든 하이퍼 파라미터의 목록을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="bb51cbfb04bccafd184fd622b215d0ec11a12190" translate="yes" xml:space="preserve">
          <source>Returns a list of feature names, ordered by their indices.</source>
          <target state="translated">인덱스별로 정렬 된 기능 이름 목록을 리턴합니다.</target>
        </trans-unit>
        <trans-unit id="34ea8d8a85c45dcfc562bcba86a58c905c99f874" translate="yes" xml:space="preserve">
          <source>Returns a matrix Y = DX, such as D is (n_features, n_components), X is (n_components, n_samples) and each column of X has exactly n_nonzero_coefs non-zero elements.</source>
          <target state="translated">D = (n_features, n_components), X는 (n_components, n_samples), X의 각 열에는 정확히 n_nonzero_coefs가 아닌 요소가있는 행렬 Y = DX를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="cbd0ed4e4005716c4bb4e960f578be5923f377b9" translate="yes" xml:space="preserve">
          <source>Returns an array X_original whose transform would be X.</source>
          <target state="translated">변환이 X 인 배열 X_original을 리턴합니다.</target>
        </trans-unit>
        <trans-unit id="84c9e08b5d96fb6a7f3433674a11022fa61c7b88" translate="yes" xml:space="preserve">
          <source>Returns an array of the weighted modal (most common) value in a</source>
          <target state="translated">가중 모달 (가장 일반적인) 값의 배열을</target>
        </trans-unit>
        <trans-unit id="cafe057316f9911839a97b088931d3f0c5ac396b" translate="yes" xml:space="preserve">
          <source>Returns an instance of self.</source>
          <target state="translated">self의 인스턴스를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="2d37a031c71fcea2fed996bf43e20f28042d6cc2" translate="yes" xml:space="preserve">
          <source>Returns log-marginal likelihood of theta for training data.</source>
          <target state="translated">훈련 데이터에 대한 로그 마진 가능성 세타를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="c002970075885e58132251c6f46e809263939e08" translate="yes" xml:space="preserve">
          <source>Returns n_neighbors of approximate nearest neighbors.</source>
          <target state="translated">근사치에 가장 가까운 이웃의 n_neighbor를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="fb2b7fa44b969b1b6614fbbe40b707fac7d6b54e" translate="yes" xml:space="preserve">
          <source>Returns predicted values.</source>
          <target state="translated">예측 된 값을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="f4e6d32f29d1d2d6a2a4394141451d982c2d35a7" translate="yes" xml:space="preserve">
          <source>Returns self.</source>
          <target state="translated">자기를 돌려줍니다.</target>
        </trans-unit>
        <trans-unit id="f6e9e9452782912bdbe94ae5d3a76dedbe086889" translate="yes" xml:space="preserve">
          <source>Returns the (flattened, log-transformed) non-fixed hyperparameters.</source>
          <target state="translated">(평평하고 로그 변환 된) 고정되지 않은 하이퍼 파라미터를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="19320b32e9aad6f858ca5ff0ef70b9bfebd867d9" translate="yes" xml:space="preserve">
          <source>Returns the (unshifted) scoring function of the samples.</source>
          <target state="translated">샘플의 (쉬프트되지 않은) 스코어링 함수를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="657787f70ef4c51706bb87e28d19c4b31968ad05" translate="yes" xml:space="preserve">
          <source>Returns the &lt;code&gt;rows_&lt;/code&gt; and &lt;code&gt;columns_&lt;/code&gt; members.</source>
          <target state="translated">&lt;code&gt;rows_&lt;/code&gt; 및 &lt;code&gt;columns_&lt;/code&gt; 멤버를 리턴합니다 .</target>
        </trans-unit>
        <trans-unit id="9a7a0a83f8ee3f88fa0c20189c0d4ac30a4fefe0" translate="yes" xml:space="preserve">
          <source>Returns the average of the array elements. The average is taken over the flattened array by default, otherwise over the specified axis. &lt;code&gt;float64&lt;/code&gt; intermediate and return values are used for integer inputs.</source>
          <target state="translated">배열 요소의 평균을 반환합니다. 평균은 기본적으로 병합 된 배열에, 그렇지 않으면 지정된 축에 적용됩니다. &lt;code&gt;float64&lt;/code&gt; 중간 및 반환 값은 정수 입력에 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="eb649861f38c5cc5c11712f4796a00d44a843890" translate="yes" xml:space="preserve">
          <source>Returns the coefficient of determination R^2 of the prediction.</source>
          <target state="translated">예측의 결정 계수 R ^ 2를 구합니다.</target>
        </trans-unit>
        <trans-unit id="b876cb187b297f2f67823973e339ef65d6c6d93d" translate="yes" xml:space="preserve">
          <source>Returns the decision function of the sample for each class in the model. If decision_function_shape=&amp;rsquo;ovr&amp;rsquo;, the shape is (n_samples, n_classes)</source>
          <target state="translated">모델에서 각 클래스에 대한 샘플의 결정 함수를 반환합니다. decision_function_shape = 'ovr'인 경우 모양은 (n_samples, n_classes)입니다.</target>
        </trans-unit>
        <trans-unit id="600321ecf92967e7d8dd43e86b0331fbf58144c8" translate="yes" xml:space="preserve">
          <source>Returns the decision function of the sample for each model in the chain.</source>
          <target state="translated">체인의 각 모델에 대한 샘플의 결정 함수를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="f91d241e5e86a06081e46089c96ee552294a8b33" translate="yes" xml:space="preserve">
          <source>Returns the decision function of the samples.</source>
          <target state="translated">샘플의 결정 함수를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="e78ab037aacacbbe51c5cf862f1aafc8648493d5" translate="yes" xml:space="preserve">
          <source>Returns the diagonal of the kernel k(X, X).</source>
          <target state="translated">커널 k (X, X)의 대각선을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="574020c30b95a24e61673be93c56847aa7847d5e" translate="yes" xml:space="preserve">
          <source>Returns the distance of each sample from the decision boundary for each class.</source>
          <target state="translated">각 클래스의 결정 경계에서 각 샘플의 거리를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="be77bb9a28472ddd253b8a1ae1c648a1964afb4c" translate="yes" xml:space="preserve">
          <source>Returns the distance of each sample from the decision boundary for each class. This can only be used with estimators which implement the decision_function method.</source>
          <target state="translated">각 클래스의 결정 경계에서 각 샘플의 거리를 반환합니다. 이는 decision_function 메소드를 구현하는 추정기에 만 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="b7fd90b44e187b56f57ca6954d88dd8f4e918ac9" translate="yes" xml:space="preserve">
          <source>Returns the distances of neighbors if set to True.</source>
          <target state="translated">True로 설정된 경우 이웃의 거리를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="0736b2ffe9fa12ffc65d7dbeeef31b8086537469" translate="yes" xml:space="preserve">
          <source>Returns the index of the leaf that each sample is predicted as.</source>
          <target state="translated">각 샘플이 예측 된 리프의 인덱스를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="57ddd1698c4b02ed38d78d51bae715493abba55a" translate="yes" xml:space="preserve">
          <source>Returns the instance itself.</source>
          <target state="translated">인스턴스 자체를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="5121a7f65d8a5a923df4edf2decfc8ea51b437d5" translate="yes" xml:space="preserve">
          <source>Returns the log probability of the sample for each class in the model, where classes are ordered arithmetically for each output.</source>
          <target state="translated">모델에서 각 클래스에 대한 샘플의 로그 확률을 반환합니다. 여기서 클래스는 각 출력에 대해 산술적으로 정렬됩니다.</target>
        </trans-unit>
        <trans-unit id="be2a6279ffe3800dbed75602bf2c1d5d359b2ac2" translate="yes" xml:space="preserve">
          <source>Returns the log-probabilities of the sample for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute &lt;code&gt;classes_&lt;/code&gt;.</source>
          <target state="translated">모델에서 각 클래스에 대한 샘플의 로그 확률을 반환합니다. 열은 &lt;code&gt;classes_&lt;/code&gt; 속성에 표시된 대로 정렬 된 순서로 클래스에 해당합니다 .</target>
        </trans-unit>
        <trans-unit id="a5f0cb89d1ff1d82c8d766a8c85156fc08daf322" translate="yes" xml:space="preserve">
          <source>Returns the log-probability of the sample for each class in the model, where classes are ordered as they are in &lt;code&gt;self.classes_&lt;/code&gt;.</source>
          <target state="translated">모델에서 각 클래스에 대한 샘플의 로그 확률을 리턴합니다. 여기서 클래스는 &lt;code&gt;self.classes_&lt;/code&gt; 에서와 같이 정렬됩니다 .</target>
        </trans-unit>
        <trans-unit id="fbd0270f78921c5ba9ddfa30e030482e2f54f42a" translate="yes" xml:space="preserve">
          <source>Returns the log-probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute &lt;code&gt;classes_&lt;/code&gt;.</source>
          <target state="translated">모델에서 각 클래스에 대한 샘플의 로그 확률을 반환합니다. 열은 &lt;code&gt;classes_&lt;/code&gt; 속성에 표시된 대로 정렬 된 순서로 클래스에 해당합니다 .</target>
        </trans-unit>
        <trans-unit id="a88bc22b9f72540c221027a9d39ebb7e5fc56ef0" translate="yes" xml:space="preserve">
          <source>Returns the log-transformed bounds on the theta.</source>
          <target state="translated">세타에서 로그 변환 된 경계를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="97643d048879fe1d9046d0bda61e3506826edf2e" translate="yes" xml:space="preserve">
          <source>Returns the mean accuracy on the given test data and labels.</source>
          <target state="translated">주어진 테스트 데이터 및 레이블의 평균 정확도를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="16bf89209ad0d6f3c40effbaf06ac2b2bd9f54f6" translate="yes" xml:space="preserve">
          <source>Returns the number of non-fixed hyperparameters of the kernel.</source>
          <target state="translated">커널의 고정되지 않은 하이퍼 파라미터 수를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="242d74929fe683a12c5d1964cc2e68959bffb690" translate="yes" xml:space="preserve">
          <source>Returns the number of splitting iterations in the cross-validator</source>
          <target state="translated">교차 유효성 검사기에서 분할 반복 횟수를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="7cfde4bf50ea94882908403c6cfbc382caa0a24b" translate="yes" xml:space="preserve">
          <source>Returns the number of splitting iterations in the cross-validator.</source>
          <target state="translated">교차 유효성 검사기에서 분할 반복 횟수를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="062b49944b8da81fbcccbc3d275c30eb3575a9c8" translate="yes" xml:space="preserve">
          <source>Returns the object itself</source>
          <target state="translated">객체 자체를 반환</target>
        </trans-unit>
        <trans-unit id="a733465cae828526edae8695b9480711c0093299" translate="yes" xml:space="preserve">
          <source>Returns the probability each Gaussian (state) in the model given each sample.</source>
          <target state="translated">각 표본이 주어진 모델에서 각 가우스 (상태) 확률을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="55dd4118273bb853d106f8d3ce6ecf4f148e2ce6" translate="yes" xml:space="preserve">
          <source>Returns the probability of the sample for each class in the model, where classes are ordered arithmetically, for each output.</source>
          <target state="translated">각 출력에 대해 클래스가 산술적으로 정렬 된 모델에서 각 클래스의 샘플 확률을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="169e349ed5581ba23a1b3967826f1082ad70f358" translate="yes" xml:space="preserve">
          <source>Returns the probability of the sample for each class in the model, where classes are ordered as they are in &lt;code&gt;self.classes_&lt;/code&gt;.</source>
          <target state="translated">모델에서 각 클래스에 대한 샘플 확률을 반환합니다. 여기서 클래스는 &lt;code&gt;self.classes_&lt;/code&gt; 와 같이 정렬됩니다 .</target>
        </trans-unit>
        <trans-unit id="3d7831ef98ef99639d4e7e4296f84556b7eba4a8" translate="yes" xml:space="preserve">
          <source>Returns the probability of the sample for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute &lt;code&gt;classes_&lt;/code&gt;.</source>
          <target state="translated">모형의 각 클래스에 대한 표본 확률을 반환합니다. 열은 &lt;code&gt;classes_&lt;/code&gt; 속성에 표시된 대로 정렬 된 순서로 클래스에 해당합니다 .</target>
        </trans-unit>
        <trans-unit id="992c84bb142fb4e9f8a180866eff97d2128f0434" translate="yes" xml:space="preserve">
          <source>Returns the probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute &lt;code&gt;classes_&lt;/code&gt;.</source>
          <target state="translated">모형의 각 클래스에 대한 표본 확률을 반환합니다. 열은 &lt;code&gt;classes_&lt;/code&gt; 속성에 표시된 대로 정렬 된 순서로 클래스에 해당합니다 .</target>
        </trans-unit>
        <trans-unit id="91d445ad5de7a1e173775e4a8269cced0a330589" translate="yes" xml:space="preserve">
          <source>Returns the score of the model on the data X</source>
          <target state="translated">데이터 X에서 모델의 점수를 반환합니다</target>
        </trans-unit>
        <trans-unit id="f46bd5d1c2974b7fae37f8d3dfead452c6f632de" translate="yes" xml:space="preserve">
          <source>Returns the score of the prediction.</source>
          <target state="translated">예측 점수를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="860029a1d62d045e78979ea6dcc0cc94815fbc22" translate="yes" xml:space="preserve">
          <source>Returns the score on the given data, if the estimator has been refit.</source>
          <target state="translated">추정기가 재조정 된 경우 주어진 데이터의 점수를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="ec85c2a1a827e7e3cec445aa44a3ba7f1fb3772b" translate="yes" xml:space="preserve">
          <source>Returns the score using the &lt;code&gt;scoring&lt;/code&gt; option on the given test data and labels.</source>
          <target state="translated">주어진 테스트 데이터 및 레이블 에서 점수 &lt;code&gt;scoring&lt;/code&gt; 옵션을 사용하여 점수를 반환합니다 .</target>
        </trans-unit>
        <trans-unit id="4f35f765fc0b19f20a03c16dab251d424926e332" translate="yes" xml:space="preserve">
          <source>Returns the submatrix corresponding to bicluster &lt;code&gt;i&lt;/code&gt;.</source>
          <target state="translated">bicluster &lt;code&gt;i&lt;/code&gt; 에 해당하는 하위 행렬을 반환합니다 .</target>
        </trans-unit>
        <trans-unit id="054a9a6e8f30544993a8a15fc5be2d4e55b3432a" translate="yes" xml:space="preserve">
          <source>Returns the transformer object.</source>
          <target state="translated">변환기 객체를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="99d4a1b8b2f5f3c702de280e61afe0632ca64c65" translate="yes" xml:space="preserve">
          <source>Returns the transformer.</source>
          <target state="translated">변압기를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="1cf9d50da5b8378604942b3c0df2a2210aa8a416" translate="yes" xml:space="preserve">
          <source>Returns whether the kernel is stationary.</source>
          <target state="translated">커널이 고정되어 있는지 여부를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="7749fcf802c472b6c2f5bd0556805e456ffd5674" translate="yes" xml:space="preserve">
          <source>Returns:</source>
          <target state="translated">Returns:</target>
        </trans-unit>
        <trans-unit id="4cddff2f4be571d7beaa9444607024440a9fab7c" translate="yes" xml:space="preserve">
          <source>Reuters Corpus Volume I (RCV1) is an archive of over 800,000 manually categorized newswire stories made available by Reuters, Ltd. for research purposes. The dataset is extensively described in &lt;a href=&quot;#id9&quot; id=&quot;id7&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="translated">Reuters Corpus Volume I (RCV1)은 연구 목적으로 Reuters, Ltd.에서 제공 한 800,000 개가 넘는 수동으로 분류 된 뉴스 와이어 스토리의 아카이브입니다. 데이터 세트는 &lt;a href=&quot;#id9&quot; id=&quot;id7&quot;&gt;[1]&lt;/a&gt; 에 광범위하게 설명되어 있습니다.</target>
        </trans-unit>
        <trans-unit id="99e73709f3009df888327fcabb8674ce816a184a" translate="yes" xml:space="preserve">
          <source>Reuters Dataset related routines</source>
          <target state="translated">로이터 데이터 셋 관련 루틴</target>
        </trans-unit>
        <trans-unit id="6601972f4e7c617814e4aa25931a1506c8822de1" translate="yes" xml:space="preserve">
          <source>Revealing data that lie in multiple, different, manifolds or clusters</source>
          <target state="translated">여러 개의 다른 매니 폴드 또는 클러스터에있는 데이터 공개</target>
        </trans-unit>
        <trans-unit id="f8d44f2683a18a11847619bb1e3f869a99808298" translate="yes" xml:space="preserve">
          <source>Revealing the structure at many scales on a single map</source>
          <target state="translated">단일 맵에서 다양한 규모로 구조 공개</target>
        </trans-unit>
        <trans-unit id="e69284bfe1901a9177c5faf2810c62e97f3c9a53" translate="yes" xml:space="preserve">
          <source>Reverse the transformation operation</source>
          <target state="translated">변환 작업 반전</target>
        </trans-unit>
        <trans-unit id="c73f8d477c79109041865780eba0a7fa3d48301f" translate="yes" xml:space="preserve">
          <source>Ridge classifier</source>
          <target state="translated">릿지 분류기</target>
        </trans-unit>
        <trans-unit id="2ad4f2cdfdad42fbcf62f66b6cf545d851e2fc3f" translate="yes" xml:space="preserve">
          <source>Ridge classifier with built-in cross validation</source>
          <target state="translated">내장 교차 검증 기능이있는 릿지 분류기</target>
        </trans-unit>
        <trans-unit id="74be3b618f2a083f8a9b4da6cc819c2a6587f706" translate="yes" xml:space="preserve">
          <source>Ridge classifier with built-in cross-validation.</source>
          <target state="translated">교차 검증이 내장 된 릿지 분류기.</target>
        </trans-unit>
        <trans-unit id="ed75d75f775d982f734209b7c7a763a7209d7d4d" translate="yes" xml:space="preserve">
          <source>Ridge regression</source>
          <target state="translated">릿지 회귀</target>
        </trans-unit>
        <trans-unit id="ab3890b5c3a5eec9daaf653c629ead9cfec0f465" translate="yes" xml:space="preserve">
          <source>Ridge regression is basically minimizing a penalised version of the least-squared function. The penalising &lt;code&gt;shrinks&lt;/code&gt; the value of the regression coefficients. Despite the few data points in each dimension, the slope of the prediction is much more stable and the variance in the line itself is greatly reduced, in comparison to that of the standard linear regression</source>
          <target state="translated">릿지 회귀는 기본적으로 최소 제곱 함수의 페널티 된 버전을 최소화합니다. 불이익은 &lt;code&gt;shrinks&lt;/code&gt; 회귀 계수의 값. 각 차원의 데이터 점이 거의 없지만 표준 기울기 회귀 분석에 비해 예측 기울기가 훨씬 안정적이며 선 자체의 편차가 크게 줄어 듭니다.</target>
        </trans-unit>
        <trans-unit id="6f1409ad2637ad7ea4da4ca38bcc785d5bfc9e7b" translate="yes" xml:space="preserve">
          <source>Ridge regression with built-in cross validation</source>
          <target state="translated">내장 된 교차 검증을 통한 릿지 회귀</target>
        </trans-unit>
        <trans-unit id="fd3c67b92ef64e74b0815493290cb7a3bf85e6f3" translate="yes" xml:space="preserve">
          <source>Ridge regression with built-in cross-validation.</source>
          <target state="translated">교차 검증이 내장 된 릿지 회귀 분석.</target>
        </trans-unit>
        <trans-unit id="ee45b6f0ae2d4ed0129b8acfc2869825bd85e481" translate="yes" xml:space="preserve">
          <source>Ridgeway, &amp;ldquo;Generalized Boosted Models: A guide to the gbm package&amp;rdquo;, 2007</source>
          <target state="translated">Ridgeway,&amp;ldquo;일반화 된 부스트 모델 : gbm 패키지 가이드&amp;rdquo;, 2007</target>
        </trans-unit>
        <trans-unit id="8352081cfa5d8a99ae7d273942336fb93f08e6d3" translate="yes" xml:space="preserve">
          <source>Right argument of the returned kernel k(X, Y). If None, k(X, X) if evaluated instead.</source>
          <target state="translated">반환 된 커널 k (X, Y)의 올바른 인수 None이면 k (X, X) 대신 평가됩니다.</target>
        </trans-unit>
        <trans-unit id="2645e9d1a378ec5a701c32478a48af53bc8241e0" translate="yes" xml:space="preserve">
          <source>Roberto Perdisci JBirch - Java implementation of BIRCH clustering algorithm &lt;a href=&quot;https://code.google.com/archive/p/jbirch&quot;&gt;https://code.google.com/archive/p/jbirch&lt;/a&gt;</source>
          <target state="translated">Roberto Perdisci JBirch-BIRCH 클러스터링 알고리즘의 Java 구현 &lt;a href=&quot;https://code.google.com/archive/p/jbirch&quot;&gt;https://code.google.com/archive/p/jbirch&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6cf9f332d60931812bd314aa88e28fabc6bcb34e" translate="yes" xml:space="preserve">
          <source>Robust covariance estimation and Mahalanobis distances relevance</source>
          <target state="translated">강력한 공분산 추정 및 Mahalanobis 거리 관련성</target>
        </trans-unit>
        <trans-unit id="328dcbba68a9846c5e7033a860bdea23249dfaea" translate="yes" xml:space="preserve">
          <source>Robust fitting is demoed in different situations:</source>
          <target state="translated">다양한 상황에서 견고한 피팅이 시연됩니다.</target>
        </trans-unit>
        <trans-unit id="165bec40e6cdbbb5b900c937da314f589c12c4da" translate="yes" xml:space="preserve">
          <source>Robust linear estimator fitting</source>
          <target state="translated">견고한 선형 추정기 피팅</target>
        </trans-unit>
        <trans-unit id="6d0888c61d68e6fb252eed4a871cfde78643505b" translate="yes" xml:space="preserve">
          <source>Robust linear model estimation using RANSAC</source>
          <target state="translated">RANSAC를 사용한 강력한 선형 모델 추정</target>
        </trans-unit>
        <trans-unit id="23aa26f47001b43f39b1c12966fa2eb9a36e10dc" translate="yes" xml:space="preserve">
          <source>Robust regression is interested in fitting a regression model in the presence of corrupt data: either outliers, or error in the model.</source>
          <target state="translated">강력한 회귀 분석은 손상된 데이터가있는 경우 특이 치 또는 모형의 오류가있는 회귀 모형을 적합시키는 데 관심이 있습니다.</target>
        </trans-unit>
        <trans-unit id="e1c857b593e499d6b23d149cc792aa8d43d0a1b9" translate="yes" xml:space="preserve">
          <source>Robust vs Empirical covariance estimate</source>
          <target state="translated">견실 한 vs 경험적 공분산 추정</target>
        </trans-unit>
        <trans-unit id="6a7d1b999eca5ec26d95619619667b3c0bc96c39" translate="yes" xml:space="preserve">
          <source>RobustScaler</source>
          <target state="translated">RobustScaler</target>
        </trans-unit>
        <trans-unit id="cf1505b8a53e6cbb8dc8ba2f11bca53f9b323bb5" translate="yes" xml:space="preserve">
          <source>Robustness to outliers in output space (via robust loss functions)</source>
          <target state="translated">출력 공간에서 특이 치에 대한 견고성 (강력한 손실 기능을 통해)</target>
        </trans-unit>
        <trans-unit id="4e83213080c2899f47c79669335c5a49e2d9bcc2" translate="yes" xml:space="preserve">
          <source>RogersTanimotoDistance</source>
          <target state="translated">RogersTanimotoDistance</target>
        </trans-unit>
        <trans-unit id="fc05bb810ef4352b5a9e6b3b3412f9c1914cad7e" translate="yes" xml:space="preserve">
          <source>Root of the CFTree.</source>
          <target state="translated">CFTree의 뿌리.</target>
        </trans-unit>
        <trans-unit id="b104e71c68c3dfb7b73342e69442ee327c52c9d1" translate="yes" xml:space="preserve">
          <source>Rosenberg and Hirschberg further define &lt;strong&gt;V-measure&lt;/strong&gt; as the &lt;strong&gt;harmonic mean of homogeneity and completeness&lt;/strong&gt;:</source>
          <target state="translated">Rosenberg와 Hirschberg는 &lt;strong&gt;V- 측정 &lt;/strong&gt;&lt;strong&gt;을 균질성과 완전성&lt;/strong&gt; 의 &lt;strong&gt;고조파 평균&lt;/strong&gt; 으로 정의합니다 .</target>
        </trans-unit>
        <trans-unit id="e15211ffc09c4f35527c5b1ce8949f07dae5bb18" translate="yes" xml:space="preserve">
          <source>Ross, J. Lim, R. Lin, M. Yang. Incremental Learning for Robust Visual</source>
          <target state="translated">Ross, J. Lim, R. Lin, M. Yang. 견고한 비주얼을위한 증분 학습</target>
        </trans-unit>
        <trans-unit id="3f65ad777cccbda986726bad67a79a0d4e6952a1" translate="yes" xml:space="preserve">
          <source>Rousseeuw and Van Driessen &lt;a href=&quot;#id12&quot; id=&quot;id10&quot;&gt;[4]&lt;/a&gt; developed the FastMCD algorithm in order to compute the Minimum Covariance Determinant. This algorithm is used in scikit-learn when fitting an MCD object to data. The FastMCD algorithm also computes a robust estimate of the data set location at the same time.</source>
          <target state="translated">Rousseeuw와 Van Driessen &lt;a href=&quot;#id12&quot; id=&quot;id10&quot;&gt;[4]&lt;/a&gt; 은 최소 공분산 결정을 계산하기 위해 FastMCD 알고리즘을 개발했습니다. 이 알고리즘은 MCD 객체를 데이터에 피팅 할 때 scikit-learn에서 사용됩니다. FastMCD 알고리즘은 또한 데이터 세트 위치의 강력한 추정치를 동시에 계산합니다.</target>
        </trans-unit>
        <trans-unit id="ae08282270da387413c613e92da23758e2b46e3a" translate="yes" xml:space="preserve">
          <source>Rousseeuw, P.J., Van Driessen, K. &amp;ldquo;A fast algorithm for the minimum covariance determinant estimator&amp;rdquo; Technometrics 41(3), 212 (1999)</source>
          <target state="translated">Rousseeuw, PJ, Van Driessen, K.&amp;ldquo;최소 공분산 결정 인자 추정기를위한 빠른 알고리즘&amp;rdquo;Technometrics 41 (3), 212 (1999)</target>
        </trans-unit>
        <trans-unit id="a147028da41451d64de65dc97e27ab58134df945" translate="yes" xml:space="preserve">
          <source>Row and column indices of the i&amp;rsquo;th bicluster.</source>
          <target state="translated">i 번째 bicluster의 행 및 열 색인.</target>
        </trans-unit>
        <trans-unit id="dff2cf4a000d72bb07a097b831cbf5d2768a6505" translate="yes" xml:space="preserve">
          <source>Row partition labels.</source>
          <target state="translated">행 파티션 레이블.</target>
        </trans-unit>
        <trans-unit id="173c6825d2552deeb977ce21a1b427b130c7161e" translate="yes" xml:space="preserve">
          <source>Run check_array on X.</source>
          <target state="translated">X에서 check_array를 실행하십시오.</target>
        </trans-unit>
        <trans-unit id="6650ce15c2e2f568588d9785e121ddc90d1aad0a" translate="yes" xml:space="preserve">
          <source>Run cross-validation for single metric evaluation.</source>
          <target state="translated">단일 메트릭 평가를 위해 교차 검증을 실행하십시오.</target>
        </trans-unit>
        <trans-unit id="76efb9e1238b374a0b90938642b1634441ade412" translate="yes" xml:space="preserve">
          <source>Run fit on one set of parameters.</source>
          <target state="translated">하나의 매개 변수 세트에 적합합니다.</target>
        </trans-unit>
        <trans-unit id="b3fa8caf4882a1b3e630b18ced7d9eb65515b91e" translate="yes" xml:space="preserve">
          <source>Run fit with all sets of parameters.</source>
          <target state="translated">모든 매개 변수 세트에 적합합니다.</target>
        </trans-unit>
        <trans-unit id="383d7fee23c4f0d9aff2e3402febc2f06b463f07" translate="yes" xml:space="preserve">
          <source>Run score function on (X, y) and get the appropriate features.</source>
          <target state="translated">(X, y)에서 점수 기능을 실행하고 적절한 기능을 얻습니다.</target>
        </trans-unit>
        <trans-unit id="75c05d3e2177d247ba4a31fbd998a4fb5a5db366" translate="yes" xml:space="preserve">
          <source>Run the clustering and plot</source>
          <target state="translated">클러스터링 및 플롯 실행</target>
        </trans-unit>
        <trans-unit id="5095c28abb8c39013ff6dacae123b7ebc126a8c4" translate="yes" xml:space="preserve">
          <source>Running &lt;code&gt;GridSearchCV&lt;/code&gt; using multiple evaluation metrics</source>
          <target state="translated">여러 평가 지표를 사용하여 &lt;code&gt;GridSearchCV&lt;/code&gt; 실행</target>
        </trans-unit>
        <trans-unit id="0fcbd6be054955e185bc7730125f0a6053dc76b6" translate="yes" xml:space="preserve">
          <source>RussellRaoDistance</source>
          <target state="translated">RussellRaoDistance</target>
        </trans-unit>
        <trans-unit id="3d35c7a842c5951e6e7d27253c473500693538e4" translate="yes" xml:space="preserve">
          <source>S. Marsland, &amp;ldquo;Machine Learning: An Algorithmic Perspective&amp;rdquo;, Chapter 10, 2009. &lt;a href=&quot;http://seat.massey.ac.nz/personal/s.r.marsland/Code/10/lle.py&quot;&gt;http://seat.massey.ac.nz/personal/s.r.marsland/Code/10/lle.py&lt;/a&gt;</source>
          <target state="translated">S. Marsland,&amp;ldquo;기계 학습 : 알고리즘 관점&amp;rdquo;, 2009 년 10 월 10 일. &lt;a href=&quot;http://seat.massey.ac.nz/personal/s.r.marsland/Code/10/lle.py&quot;&gt;http://seat.massey.ac.nz/personal/srmarsland/Code/10/lle.py&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1c12fa511d52194a5681ee8be41a1e398d85f290" translate="yes" xml:space="preserve">
          <source>S1</source>
          <target state="translated">S1</target>
        </trans-unit>
        <trans-unit id="474c9bc027ee3ef22851a5f8bfd976f08b197386" translate="yes" xml:space="preserve">
          <source>S2</source>
          <target state="translated">S2</target>
        </trans-unit>
        <trans-unit id="37a81d7cd2e4b8f7f2a8a35b26aa90c58c80afd8" translate="yes" xml:space="preserve">
          <source>S3</source>
          <target state="translated">S3</target>
        </trans-unit>
        <trans-unit id="69c195a662b9112a35f65e12d131a5b27ca87f2b" translate="yes" xml:space="preserve">
          <source>S4</source>
          <target state="translated">S4</target>
        </trans-unit>
        <trans-unit id="c3371c7d85f3802028519c691cc2d442bd72de40" translate="yes" xml:space="preserve">
          <source>S5</source>
          <target state="translated">S5</target>
        </trans-unit>
        <trans-unit id="69ba3f2fc09a1e00fed9f31e478c0eff5dced9e9" translate="yes" xml:space="preserve">
          <source>S6</source>
          <target state="translated">S6</target>
        </trans-unit>
        <trans-unit id="4c804f5a0904acd450fcddddab0dc632cd582e71" translate="yes" xml:space="preserve">
          <source>SA structure :</source>
          <target state="translated">SA 구조 :</target>
        </trans-unit>
        <trans-unit id="c0d8a0ca44b0696f5feb9dd5b2e501345c937c3c" translate="yes" xml:space="preserve">
          <source>SAG &amp;ndash; Mark Schmidt, Nicolas Le Roux, and Francis Bach</source>
          <target state="translated">SAG &amp;ndash; Mark Schmidt, Nicolas Le Roux 및 Francis Bach</target>
        </trans-unit>
        <trans-unit id="b5f439b003a3f7bf1ca666e889005dbe06e41518" translate="yes" xml:space="preserve">
          <source>SAGA &amp;ndash; Defazio, A., Bach F. &amp;amp; Lacoste-Julien S. (2014).</source>
          <target state="translated">SAGA &amp;ndash; Defazio, A., Bach F. &amp;amp; Lacoste-Julien S. (2014).</target>
        </trans-unit>
        <trans-unit id="5d555084f4d87558b3e1f1e41594c4567a72ffe9" translate="yes" xml:space="preserve">
          <source>SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives &lt;a href=&quot;https://arxiv.org/abs/1407.0202&quot;&gt;https://arxiv.org/abs/1407.0202&lt;/a&gt;</source>
          <target state="translated">SAGA : 강력하지 않은 볼록한 복합 목표를 지원하는 빠른 증분 그라디언트 방법 &lt;a href=&quot;https://arxiv.org/abs/1407.0202&quot;&gt;https://arxiv.org/abs/1407.0202&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="47b0a2b31abf5ad7f508685c420934a3c9ceb224" translate="yes" xml:space="preserve">
          <source>SEuclideanDistance</source>
          <target state="translated">SEuclideanDistance</target>
        </trans-unit>
        <trans-unit id="25a0a10d5e57106efcf106b18fe758dffe61fd61" translate="yes" xml:space="preserve">
          <source>SF structure :</source>
          <target state="translated">SF 구조 :</target>
        </trans-unit>
        <trans-unit id="feee827f58feab6583e46c495c391eeebda8d75f" translate="yes" xml:space="preserve">
          <source>SGD fits a linear model to the training data. The member &lt;code&gt;coef_&lt;/code&gt; holds the model parameters:</source>
          <target state="translated">SGD는 선형 모델을 훈련 데이터에 적합시킵니다. &lt;code&gt;coef_&lt;/code&gt; 멤버 는 모델 매개 변수를 보유합니다.</target>
        </trans-unit>
        <trans-unit id="35603e0805a9ac47c224548952c5bc406f24681d" translate="yes" xml:space="preserve">
          <source>SGD has been successfully applied to large-scale and sparse machine learning problems often encountered in text classification and natural language processing. Given that the data is sparse, the classifiers in this module easily scale to problems with more than 10^5 training examples and more than 10^5 features.</source>
          <target state="translated">SGD는 텍스트 분류 및 자연어 처리에서 자주 발생하는 대규모 및 희소 기계 학습 문제에 성공적으로 적용되었습니다. 데이터가 드문 경우이 모듈의 분류기는 10 ^ 5 개 이상의 교육 예제 및 10 ^ 5 개 이상의 기능 관련 문제로 쉽게 확장 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="56826c4ca309b6e5b6fa33e22889222819ef98da" translate="yes" xml:space="preserve">
          <source>SGD is sensitive to feature scaling.</source>
          <target state="translated">SGD는 기능 스케일링에 민감합니다.</target>
        </trans-unit>
        <trans-unit id="aaaef0a56ff89a9fec86986b723dbc52782459a2" translate="yes" xml:space="preserve">
          <source>SGD requires a number of hyperparameters such as the regularization parameter and the number of iterations.</source>
          <target state="translated">SGD에는 정규화 매개 변수 및 반복 횟수와 같은 여러 하이퍼 파라미터가 필요합니다.</target>
        </trans-unit>
        <trans-unit id="2040a5158079ffce24f8b06ceaf317e6a14bde86" translate="yes" xml:space="preserve">
          <source>SGD stands for Stochastic Gradient Descent: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate).</source>
          <target state="translated">SGD는 확률 적 그라디언트 디센트 (Stochastic Gradient Descent)를 나타냅니다. 손실의 그라디언트는 한 번에 각 샘플을 추정하고 감소하는 일정 (일명 학습 속도)과 함께 모델을 업데이트합니다.</target>
        </trans-unit>
        <trans-unit id="a5409a86e2f59aff11c69a7f4ca4772e4d726f18" translate="yes" xml:space="preserve">
          <source>SGD: Maximum margin separating hyperplane</source>
          <target state="translated">SGD : 초평면 분리 최대 마진</target>
        </trans-unit>
        <trans-unit id="18e5f1878526787df86a80bc190ed115937ff46a" translate="yes" xml:space="preserve">
          <source>SGD: Penalties</source>
          <target state="translated">SGD : 페널티</target>
        </trans-unit>
        <trans-unit id="ba517f5cdbbcd13a216515c00be2b80ddd3cbbe7" translate="yes" xml:space="preserve">
          <source>SGD: Weighted samples</source>
          <target state="translated">SGD : 가중 샘플</target>
        </trans-unit>
        <trans-unit id="641c7150d49f1de3baa1799ce8aa92905ea998a5" translate="yes" xml:space="preserve">
          <source>SGD: convex loss functions</source>
          <target state="translated">SGD : 볼록한 손실 함수</target>
        </trans-unit>
        <trans-unit id="cf02fe82611c518b4850cfb8c1c714a0440b4d08" translate="yes" xml:space="preserve">
          <source>SGDClassifier can optimize the same cost function as LinearSVC by adjusting the penalty and loss parameters. In addition it requires less memory, allows incremental (online) learning, and implements various loss functions and regularization regimes.</source>
          <target state="translated">SGDClassifier는 패널티 및 손실 매개 변수를 조정하여 LinearSVC와 동일한 비용 함수를 최적화 할 수 있습니다. 또한 적은 메모리가 필요하고 증분 (온라인) 학습이 가능하며 다양한 손실 기능 및 정규화 체제를 구현합니다.</target>
        </trans-unit>
        <trans-unit id="bf24393981aae53fe434537eb506bff7add3be48" translate="yes" xml:space="preserve">
          <source>SGDRegressor can optimize the same cost function as LinearSVR by adjusting the penalty and loss parameters. In addition it requires less memory, allows incremental (online) learning, and implements various loss functions and regularization regimes.</source>
          <target state="translated">SGDRegressor는 페널티 및 손실 매개 변수를 조정하여 LinearSVR과 동일한 비용 함수를 최적화 할 수 있습니다. 또한 적은 메모리가 필요하고 증분 (온라인) 학습이 가능하며 다양한 손실 기능 및 정규화 체제를 구현합니다.</target>
        </trans-unit>
        <trans-unit id="176392773f6f864a2cd9bd404f4a47c5c644890a" translate="yes" xml:space="preserve">
          <source>SKLEARN_ASSUME_FINITE:</source>
          <target state="translated">SKLEARN_ASSUME_FINITE:</target>
        </trans-unit>
        <trans-unit id="489eb75f9c6e942df30f531fa00564449214dacd" translate="yes" xml:space="preserve">
          <source>SKLEARN_SEED:</source>
          <target state="translated">SKLEARN_SEED:</target>
        </trans-unit>
        <trans-unit id="fb52c7cf741e16036b16d4758134cf0347d8fc36" translate="yes" xml:space="preserve">
          <source>SKLEARN_SITE_JOBLIB:</source>
          <target state="translated">SKLEARN_SITE_JOBLIB:</target>
        </trans-unit>
        <trans-unit id="182f8430558645ae44ec3e02ca4f97fb187183b5" translate="yes" xml:space="preserve">
          <source>SKLEARN_SKIP_NETWORK_TESTS:</source>
          <target state="translated">SKLEARN_SKIP_NETWORK_TESTS:</target>
        </trans-unit>
        <trans-unit id="ce18ea047ea4320bf80e4467a9a4d6882d0a0c5c" translate="yes" xml:space="preserve">
          <source>SKLEARN_WORKING_MEMORY:</source>
          <target state="translated">SKLEARN_WORKING_MEMORY:</target>
        </trans-unit>
        <trans-unit id="85baaac41fa88b4fe00f7bdceca42996f772a2b4" translate="yes" xml:space="preserve">
          <source>SVD solver to use. Either &amp;ldquo;arpack&amp;rdquo; for the ARPACK wrapper in SciPy (scipy.sparse.linalg.svds), or &amp;ldquo;randomized&amp;rdquo; for the randomized algorithm due to Halko (2009).</source>
          <target state="translated">사용할 SVD 솔버. SciPy의 ARPACK 래퍼 (scipy.sparse.linalg.svds)의 경우 &quot;arpack&quot;이거나 Halko (2009)로 인한 무작위 알고리즘의 경우 &quot;임의 화&quot;입니다.</target>
        </trans-unit>
        <trans-unit id="6af7199e8ddc63c7a75cd98d1b65821ed0efc2bf" translate="yes" xml:space="preserve">
          <source>SVD suffers from a problem called &amp;ldquo;sign indeterminacy&amp;rdquo;, which means the sign of the &lt;code&gt;components_&lt;/code&gt; and the output from transform depend on the algorithm and random state. To work around this, fit instances of this class to data once, then keep the instance around to do transformations.</source>
          <target state="translated">SVD는&amp;ldquo;sign indeterminacy&amp;rdquo;라는 문제로 어려움을 겪습니다. 이는 &lt;code&gt;components_&lt;/code&gt; 의 부호 와 변환의 출력이 알고리즘 및 임의 상태에 따라 달라짐을 의미합니다 . 이 문제를 해결하려면이 클래스의 인스턴스를 데이터에 한 번 맞춘 다음 인스턴스를 유지하여 변환을 수행하십시오.</target>
        </trans-unit>
        <trans-unit id="cbdd2a97d41c59ff884c822b77e5bbe85f9ba90e" translate="yes" xml:space="preserve">
          <source>SVM Exercise</source>
          <target state="translated">SVM 운동</target>
        </trans-unit>
        <trans-unit id="b34d9f0295b39d40cbe5096a7d120f8070675e5a" translate="yes" xml:space="preserve">
          <source>SVM Margins Example</source>
          <target state="translated">SVM 여백 예</target>
        </trans-unit>
        <trans-unit id="9a8ae56c5c075834fc4807237ba47d91cf12057b" translate="yes" xml:space="preserve">
          <source>SVM with custom kernel</source>
          <target state="translated">맞춤형 커널을 갖춘 SVM</target>
        </trans-unit>
        <trans-unit id="9789cc13908fc9d7be883f1548c74adba099c7a4" translate="yes" xml:space="preserve">
          <source>SVM-Anova: SVM with univariate feature selection</source>
          <target state="translated">SVM-Anova : 일 변량 기능 선택이 가능한 SVM</target>
        </trans-unit>
        <trans-unit id="1d60b833a10753cb7a1e8445b24053366a62c2ba" translate="yes" xml:space="preserve">
          <source>SVM-Kernels</source>
          <target state="translated">SVM-Kernels</target>
        </trans-unit>
        <trans-unit id="83aa3a7ffedeffc55020607871a4abaa66f7a1c9" translate="yes" xml:space="preserve">
          <source>SVM: Maximum margin separating hyperplane</source>
          <target state="translated">SVM : 초평면 분리 최대 마진</target>
        </trans-unit>
        <trans-unit id="6eea5ef53cf13552f771a06f957229c9212aa8d7" translate="yes" xml:space="preserve">
          <source>SVM: Separating hyperplane for unbalanced classes</source>
          <target state="translated">SVM : 불평형 클래스를위한 초평면 분리</target>
        </trans-unit>
        <trans-unit id="cf6b9fd9e8253b8b76eff229f07c0360f2de682d" translate="yes" xml:space="preserve">
          <source>SVM: Weighted samples</source>
          <target state="translated">SVM : 가중 샘플</target>
        </trans-unit>
        <trans-unit id="85f0e3e6752e2995f480bc673dc3817c45715958" translate="yes" xml:space="preserve">
          <source>SVMs can be used in regression &amp;ndash;&lt;a href=&quot;../../modules/generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt;&lt;code&gt;SVR&lt;/code&gt;&lt;/a&gt; (Support Vector Regression)&amp;ndash;, or in classification &amp;ndash;&lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; (Support Vector Classification).</source>
          <target state="translated">SVM은 회귀 &amp;ndash; &lt;a href=&quot;../../modules/generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt; &lt;code&gt;SVR&lt;/code&gt; &lt;/a&gt; (Support Vector Regression) &amp;ndash; 또는 분류 &amp;ndash; &lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt; (Support Vector Classification)에서 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7b1be869f06df9c591de1bdf323bb61b2e38d27a" translate="yes" xml:space="preserve">
          <source>SVMs decision function depends on some subset of the training data, called the support vectors. Some properties of these support vectors can be found in members &lt;code&gt;support_vectors_&lt;/code&gt;, &lt;code&gt;support_&lt;/code&gt; and &lt;code&gt;n_support&lt;/code&gt;:</source>
          <target state="translated">SVM의 결정 기능은 지원 벡터라고하는 훈련 데이터의 일부 하위 집합에 따라 다릅니다. 이러한 지원 벡터의 일부 속성은 &lt;code&gt;support_vectors_&lt;/code&gt; , &lt;code&gt;support_&lt;/code&gt; 및 &lt;code&gt;n_support&lt;/code&gt; 멤버에서 찾을 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="798a54068fd4b730861d7008bf329c0c0c2c0e43" translate="yes" xml:space="preserve">
          <source>SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see &lt;a href=&quot;#scores-probabilities&quot;&gt;Scores and probabilities&lt;/a&gt;, below).</source>
          <target state="translated">SVM은 확률 추정치를 직접 제공하지 않으며 값 비싼 5 배 교차 검증을 사용하여 계산됩니다 (아래의 &lt;a href=&quot;#scores-probabilities&quot;&gt;점수 및 확률&lt;/a&gt; 참조).</target>
        </trans-unit>
        <trans-unit id="db6e7e410412f58574f766c3911f49badd42beca" translate="yes" xml:space="preserve">
          <source>Safety</source>
          <target state="translated">Safety</target>
        </trans-unit>
        <trans-unit id="fda84c44a4e30d5cb2a98cb6be80221a0339a2c0" translate="yes" xml:space="preserve">
          <source>Same as K-Fold but preserves the class distribution within each fold.</source>
          <target state="translated">K-Fold와 동일하지만 각 접기 내 클래스 분포를 유지합니다.</target>
        </trans-unit>
        <trans-unit id="3ee571b5564a06c8cd876b67cbf6301868feea05" translate="yes" xml:space="preserve">
          <source>Same as shuffle split but preserves the class distribution within each iteration.</source>
          <target state="translated">셔플 분할과 동일하지만 각 반복 내에서 클래스 분포를 유지합니다.</target>
        </trans-unit>
        <trans-unit id="b7e9bc6c5c66894cda1e66e0aa803e5c89c613cb" translate="yes" xml:space="preserve">
          <source>Same data with dummy feature added as first column.</source>
          <target state="translated">더미 기능이있는 동일한 데이터가 첫 번째 열로 추가되었습니다.</target>
        </trans-unit>
        <trans-unit id="8528afb44e724dea86ccba97d23f6755cfc862fa" translate="yes" xml:space="preserve">
          <source>Sample data, in the form of a numpy array or a precomputed &lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">데이터 샘플하는 NumPy와 배열 또는 사전 계산의 형태 &lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="58a55d6f93d14931521825c7a646b62d82a23f61" translate="yes" xml:space="preserve">
          <source>Sample data, shape = (n_samples, n_features), in the form of a numpy array or a NearestNeighbors object.</source>
          <target state="translated">numpy 배열 또는 NearestNeighbors 객체 형태의 샘플 데이터 shape = (n_samples, n_features).</target>
        </trans-unit>
        <trans-unit id="10ce65324acefea0898135b900280dadfb96fe1c" translate="yes" xml:space="preserve">
          <source>Sample data, shape = (n_samples, n_features), in the form of a numpy array, precomputed tree, or NearestNeighbors object.</source>
          <target state="translated">numpy 배열, 미리 계산 된 트리 또는 NearestNeighbors 객체 형식의 샘플 데이터 shape = (n_samples, n_features).</target>
        </trans-unit>
        <trans-unit id="ea442856bb6f3247c403f5eacbad9d49d9f34166" translate="yes" xml:space="preserve">
          <source>Sample integers without replacement.</source>
          <target state="translated">대체없이 샘플 정수.</target>
        </trans-unit>
        <trans-unit id="4057b3cb6bd141b135fafdb32fce3f5d0c92b8db" translate="yes" xml:space="preserve">
          <source>Sample matrix.</source>
          <target state="translated">샘플 매트릭스.</target>
        </trans-unit>
        <trans-unit id="cc8d82180e352f6e4eb38618a9b77ce032b1c63f" translate="yes" xml:space="preserve">
          <source>Sample pipeline for text feature extraction and evaluation</source>
          <target state="translated">텍스트 기능 추출 및 평가를위한 샘플 파이프 라인</target>
        </trans-unit>
        <trans-unit id="0982f69f498171fb424746f3b46f588b79249d60" translate="yes" xml:space="preserve">
          <source>Sample usage of Nearest Centroid classification. It will plot the decision boundaries for each class.</source>
          <target state="translated">가장 가까운 중심 분류의 샘플 사용법. 각 클래스의 의사 결정 경계를 표시합니다.</target>
        </trans-unit>
        <trans-unit id="f22b9a32693422a5abcec4767410509915bc2f8f" translate="yes" xml:space="preserve">
          <source>Sample usage of Nearest Neighbors classification. It will plot the decision boundaries for each class.</source>
          <target state="translated">가장 가까운 이웃 분류의 샘플 사용법. 각 클래스의 의사 결정 경계를 표시합니다.</target>
        </trans-unit>
        <trans-unit id="b6f1c43a568cbfebecbc9c4a468d534512e56696" translate="yes" xml:space="preserve">
          <source>Sample vectors from which to compute variances.</source>
          <target state="translated">분산을 계산할 표본 벡터입니다.</target>
        </trans-unit>
        <trans-unit id="4701e0099b8ff3338dac13ba80a9fd03a1b4e3e5" translate="yes" xml:space="preserve">
          <source>Sample vectors.</source>
          <target state="translated">샘플 벡터.</target>
        </trans-unit>
        <trans-unit id="e2a418c622901df3ef07f5cc98282eefd0e90959" translate="yes" xml:space="preserve">
          <source>Sample weight</source>
          <target state="translated">샘플 무게</target>
        </trans-unit>
        <trans-unit id="e69657285f6aad82f9a81418454c1c4adb873fb2" translate="yes" xml:space="preserve">
          <source>Sample weight.</source>
          <target state="translated">샘플 무게.</target>
        </trans-unit>
        <trans-unit id="03782597aeab2816675e9752810fe748c242aeef" translate="yes" xml:space="preserve">
          <source>Sample weights.</source>
          <target state="translated">샘플 무게.</target>
        </trans-unit>
        <trans-unit id="516c4850672ccbdd1765de8db9d3606a458e566e" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, the sample weights are initialized to 1 / n_samples.</source>
          <target state="translated">샘플 무게. None이면 샘플 가중치는 1 / n_samples로 초기화됩니다.</target>
        </trans-unit>
        <trans-unit id="06e56dd5257a783cd783e2275240a5cef38438c1" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, the sample weights are initialized to &lt;code&gt;1 / n_samples&lt;/code&gt;.</source>
          <target state="translated">샘플 무게. None이면, 샘플 가중치는 &lt;code&gt;1 / n_samples&lt;/code&gt; 로 초기화됩니다 .</target>
        </trans-unit>
        <trans-unit id="b28026c224fc212b3c8db8d7abcf83fe154d5aba" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted.</source>
          <target state="translated">샘플 무게. None이면 샘플에 동일한 가중치를 적용합니다.</target>
        </trans-unit>
        <trans-unit id="dd4e4922a0bf331287b6e7fdee69023638c0a9c2" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Note that this is supported only if all underlying estimators support sample weights.</source>
          <target state="translated">샘플 무게. None이면 샘플에 동일한 가중치를 적용합니다. 이것은 모든 기본 추정기가 샘플 가중치를 지원하는 경우에만 지원됩니다.</target>
        </trans-unit>
        <trans-unit id="72b5ffbf428e4946121de0a0ea4fb4fa9205e66d" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Note that this is supported only if the base estimator supports sample weighting.</source>
          <target state="translated">샘플 무게. None이면 샘플에 동일한 가중치를 적용합니다. 이는 기본 추정기가 샘플 가중치를 지원하는 경우에만 지원됩니다.</target>
        </trans-unit>
        <trans-unit id="e07f10e1efb6d03970a11a668db91780f97be9f4" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Only supported if the underlying regressor supports sample weights.</source>
          <target state="translated">샘플 무게. None이면 샘플에 동일한 가중치를 적용합니다. 기본 회귀자가 샘플 가중치를 지원하는 경우에만 지원됩니다.</target>
        </trans-unit>
        <trans-unit id="d4811960b5c60cf1d2e21f4adf57777acf8cf860" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node.</source>
          <target state="translated">샘플 무게. None이면 샘플에 동일한 가중치를 적용합니다. 순 제로 또는 음의 가중치로 하위 노드를 생성하는 분할은 각 노드에서 분할을 검색하는 동안 무시됩니다.</target>
        </trans-unit>
        <trans-unit id="76ebb3a0858ee52c5cebb457753ce9dfb9f1fd6e" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. In the case of classification, splits are also ignored if they would result in any single class carrying a negative weight in either child node.</source>
          <target state="translated">샘플 무게. None이면 샘플에 동일한 가중치를 적용합니다. 순 제로 또는 음의 가중치로 하위 노드를 생성하는 분할은 각 노드에서 분할을 검색하는 동안 무시됩니다. 분류의 경우 분할이 하위 노드 중 하나에서 음의 가중치를 갖는 단일 클래스를 생성하는 경우에도 무시됩니다.</target>
        </trans-unit>
        <trans-unit id="317d3738fe42cf9aeb8c2e6052e8dee6f03e55e0" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. Splits are also ignored if they would result in any single class carrying a negative weight in either child node.</source>
          <target state="translated">샘플 무게. None이면 샘플에 동일한 가중치를 적용합니다. 순 제로 또는 음의 가중치로 하위 노드를 생성하는 분할은 각 노드에서 분할을 검색하는 동안 무시됩니다. 분할이 하위 노드 중 하나에서 음의 가중치를 갖는 단일 클래스를 생성하는 경우에도 무시됩니다.</target>
        </trans-unit>
        <trans-unit id="a90c0865394b45b5f31d5c73cc5fa995827fa090" translate="yes" xml:space="preserve">
          <source>Samples a subset of training points, computes kernel on these and computes normalization matrix.</source>
          <target state="translated">트레이닝 포인트의 서브 세트를 샘플링하고, 이것에 대한 커널을 계산하고 정규화 행렬을 계산합니다.</target>
        </trans-unit>
        <trans-unit id="489527d2412e4e73b577f6c6fbbfa5b2fc34f813" translate="yes" xml:space="preserve">
          <source>Samples generator</source>
          <target state="translated">샘플 생성기</target>
        </trans-unit>
        <trans-unit id="984aa7241ddfaa0a1125ba76d49684d954091644" translate="yes" xml:space="preserve">
          <source>Samples may have several labels each (see &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&quot;&gt;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&lt;/a&gt;)</source>
          <target state="translated">샘플에는 각각 여러 개의 레이블이있을 수 있습니다 ( &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&quot;&gt;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html 참조&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="a729b3c883140152c8be9c9b913932e3054a28dd" translate="yes" xml:space="preserve">
          <source>Samples per class</source>
          <target state="translated">수업 당 샘플</target>
        </trans-unit>
        <trans-unit id="72ff32775331fbcdecdd7b50f2f019ca6fd41d2c" translate="yes" xml:space="preserve">
          <source>Samples random projection according to n_features.</source>
          <target state="translated">n_features에 따라 랜덤 프로젝션을 샘플링합니다.</target>
        </trans-unit>
        <trans-unit id="251d1d7b5c7f8793378b7d465a809b22ff0293ea" translate="yes" xml:space="preserve">
          <source>Samples to cluster.</source>
          <target state="translated">클러스터 할 샘플.</target>
        </trans-unit>
        <trans-unit id="1b35c86a656c810d2ffde5bec3bbb5716273c85d" translate="yes" xml:space="preserve">
          <source>Samples total</source>
          <target state="translated">총 샘플</target>
        </trans-unit>
        <trans-unit id="d94a358c32f7a1a8aa072b320513050f66fbf3bb" translate="yes" xml:space="preserve">
          <source>Samples.</source>
          <target state="translated">Samples.</target>
        </trans-unit>
        <trans-unit id="79b4194bd3e79bf7f3c58fb9c6afe5574c4f3465" translate="yes" xml:space="preserve">
          <source>Samples. Each sample must be a text document (either bytes or unicode strings, file name or file object depending on the constructor argument) which will be tokenized and hashed.</source>
          <target state="translated">샘플. 각 샘플은 토큰 화되고 해시 될 텍스트 문서 (바이트 또는 유니 코드 문자열, 생성자 인수에 따라 파일 이름 또는 파일 객체) 여야합니다.</target>
        </trans-unit>
        <trans-unit id="4ecf733dec873b2818a96fff2c4d7137b5e9cce2" translate="yes" xml:space="preserve">
          <source>Samples. Each sample must be iterable an (e.g., a list or tuple) containing/generating feature names (and optionally values, see the input_type constructor argument) which will be hashed. raw_X need not support the len function, so it can be the result of a generator; n_samples is determined on the fly.</source>
          <target state="translated">샘플. 각 샘플은 해시 될 기능 이름 (및 선택적으로 값, input_type 생성자 인수 참조)을 포함 / 생성하는 반복 가능해야합니다 (예 : 목록 또는 튜플). raw_X는 len 함수를 지원할 필요가 없으므로 생성기의 결과 일 수 있습니다. n_samples는 즉시 결정됩니다.</target>
        </trans-unit>
        <trans-unit id="475a3c12e7131d5c7c597d45cbde5d7c042c5697" translate="yes" xml:space="preserve">
          <source>Samples. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead a precomputed kernel matrix, shape = [n_samples, n_samples_fitted], where n_samples_fitted is the number of samples used in the fitting for this estimator.</source>
          <target state="translated">샘플. kernel == &quot;precomputed&quot;인 경우, 이는 사전 계산 된 커널 행렬 대신 shape = [n_samples, n_samples_fitted]입니다. 여기서 n_samples_fitted는이 추정기의 피팅에 사용 된 샘플 수입니다.</target>
        </trans-unit>
        <trans-unit id="786961f4d535734fe86dc46d23d2c4ae6643e27e" translate="yes" xml:space="preserve">
          <source>Sampling interval. Must be specified when sample_steps not in {1,2,3}.</source>
          <target state="translated">샘플링 간격. sample_steps가 {1,2,3}이 아닌 경우 지정해야합니다.</target>
        </trans-unit>
        <trans-unit id="2b1ee52c21297b409f91752fd0536580b7df89b8" translate="yes" xml:space="preserve">
          <source>Sampling more dimensions clearly leads to better classification results, but comes at a greater cost. This means there is a tradeoff between runtime and accuracy, given by the parameter n_components. Note that solving the Linear SVM and also the approximate kernel SVM could be greatly accelerated by using stochastic gradient descent via &lt;a href=&quot;../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt;&lt;/a&gt;. This is not easily possible for the case of the kernelized SVM.</source>
          <target state="translated">더 많은 차원을 샘플링하면 더 나은 분류 결과로 이어지지 만 더 큰 비용이 듭니다. 이는 n_components 매개 변수가 제공하는 런타임과 정확도 사이에 상충 관계가 있음을 의미합니다. &lt;a href=&quot;../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt; &lt;/a&gt; 를 통해 확률 적 그라디언트 디센트 (stochastic gradient descent)를 사용하면 Linear SVM 및 대략적인 커널 SVM을 해결하는 것이 크게 가속화 될 수 있습니다 . 이것은 커널 화 된 SVM의 경우에는 불가능합니다.</target>
        </trans-unit>
        <trans-unit id="3e5ac0adafac21480f1a521f8334d2085c97ee0a" translate="yes" xml:space="preserve">
          <source>Sanjoy Dasgupta and Anupam Gupta, 1999, &amp;ldquo;An elementary proof of the Johnson-Lindenstrauss Lemma.&amp;rdquo; &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&lt;/a&gt;</source>
          <target state="translated">Sanjoy Dasgupta와 Anupam Gupta, 1999,&amp;ldquo;Johnson-Lindenstrauss Lemma의 기본 증거.&amp;rdquo; &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="72e45a031f2d9ef687b450c7dbe04851bc78b888" translate="yes" xml:space="preserve">
          <source>Sanjoy Dasgupta and Anupam Gupta, 1999. &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.39.3334&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;An elementary proof of the Johnson-Lindenstrauss Lemma.&lt;/a&gt;</source>
          <target state="translated">Sanjoy Dasgupta와 Anupam Gupta, 1999. &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.39.3334&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Johnson-Lindenstrauss Lemma의 기본 증거.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="916673b66f20fa78c64c3896647266270d456625" translate="yes" xml:space="preserve">
          <source>Sanjoy Dasgupta. 2000. &lt;a href=&quot;http://cseweb.ucsd.edu/~dasgupta/papers/randomf.pdf&quot;&gt;Experiments with random projection.&lt;/a&gt; In Proceedings of the Sixteenth conference on Uncertainty in artificial intelligence (UAI&amp;lsquo;00), Craig Boutilier and Mois&amp;eacute;s Goldszmidt (Eds.). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 143-151.</source>
          <target state="translated">Sanjoy Dasgupta. 2000 년 &lt;a href=&quot;http://cseweb.ucsd.edu/~dasgupta/papers/randomf.pdf&quot;&gt;임의 투사와 실험. &lt;/a&gt;인공 지능의 불확실성 (UAI'00)에 관한 16 차 회의에서 Craig Boutilier와 Mois&amp;eacute;s Goldszmidt (Eds.). Morgan Kaufmann Publishers Inc., 미국 캘리포니아 주 샌프란시스코, 143-151.</target>
        </trans-unit>
        <trans-unit id="3dc12a8bd942b1cd9b3ab450a012927de384bfa6" translate="yes" xml:space="preserve">
          <source>Save fitted model as best model if number of inlier samples is maximal. In case the current estimated model has the same number of inliers, it is only considered as the best model if it has better score.</source>
          <target state="translated">내부 샘플 수가 최대 인 경우 적합 모델을 최상의 모델로 저장하십시오. 현재 추정 모델에 동일한 수의 이너가 있으면 점수가 더 좋은 경우에만 최상의 모델로 간주됩니다.</target>
        </trans-unit>
        <trans-unit id="94b03c70b196c58604c0a7faf7218bf6901b8e0c" translate="yes" xml:space="preserve">
          <source>Scalability</source>
          <target state="translated">Scalability</target>
        </trans-unit>
        <trans-unit id="199d842d852910d77fdbfb1dc59f0d2885e1b21f" translate="yes" xml:space="preserve">
          <source>Scalability can be boosted by using fewer seeds, for example by using a higher value of min_bin_freq in the get_bin_seeds function.</source>
          <target state="translated">get_bin_seeds 함수에서 더 높은 값의 min_bin_freq를 사용하여 더 적은 시드를 사용하여 확장 성을 향상시킬 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="29f2c344812c53bdbb5e427694d6be2d492aaf47" translate="yes" xml:space="preserve">
          <source>Scalability, due to the sequential nature of boosting it can hardly be parallelized.</source>
          <target state="translated">부스팅의 순차적 특성으로 인해 확장 성이 거의 병렬화 될 수 없습니다.</target>
        </trans-unit>
        <trans-unit id="f6484bee2609587949da674a2bdf0fe83ede7b2a" translate="yes" xml:space="preserve">
          <source>Scalability:</source>
          <target state="translated">Scalability:</target>
        </trans-unit>
        <trans-unit id="61dc05feb549eab6c07b7a94be612c538f71b094" translate="yes" xml:space="preserve">
          <source>Scalable Linear Support Vector Machine for classification implemented using liblinear. Check the See also section of LinearSVC for more comparison element.</source>
          <target state="translated">liblinear를 사용하여 구현 된 분류를위한 확장 가능한 선형 지원 벡터 머신. 자세한 비교 요소는 LinearSVC의 섹션도 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="eecb89d050bc91f7d55354e38239145e4acf15ef" translate="yes" xml:space="preserve">
          <source>Scalable Linear Support Vector Machine for regression implemented using liblinear.</source>
          <target state="translated">liblinear를 사용하여 구현 된 회귀를위한 확장 가능한 선형 지원 벡터 머신.</target>
        </trans-unit>
        <trans-unit id="22b700f6b9ee53c2fb9ac81cf84c12516aa516e1" translate="yes" xml:space="preserve">
          <source>Scalable linear Support Vector Machine for classification using liblinear.</source>
          <target state="translated">liblinear를 사용한 분류를위한 확장 가능한 선형 지원 벡터 머신.</target>
        </trans-unit>
        <trans-unit id="bdabc7bc958d2928d9827e9b54f6956c7bb824f2" translate="yes" xml:space="preserve">
          <source>Scale back the data to the original representation</source>
          <target state="translated">데이터를 원래 표현으로 축소</target>
        </trans-unit>
        <trans-unit id="561dee1ec35178a67790d71472d188769f1e1bd6" translate="yes" xml:space="preserve">
          <source>Scale each feature by its maximum absolute value.</source>
          <target state="translated">각 기능의 최대 절대 값을 조정하십시오.</target>
        </trans-unit>
        <trans-unit id="2d3a1b9b18053dd9fb9c5426f583cf0f7d587a14" translate="yes" xml:space="preserve">
          <source>Scale each feature of the data matrix by multiplying with specific scale provided by the caller assuming a (n_samples, n_features) shape.</source>
          <target state="translated">(n_samples, n_features) 모양을 가정하여 호출자가 제공 한 특정 스케일을 곱하여 데이터 매트릭스의 각 기능을 스케일링하십시오.</target>
        </trans-unit>
        <trans-unit id="c6c81268e0182a1a807ca4c628dc76b97a0fa5dc" translate="yes" xml:space="preserve">
          <source>Scale each feature to the [-1, 1] range without breaking the sparsity.</source>
          <target state="translated">희소성을 해치지 않고 각 기능을 [-1, 1] 범위로 조정하십시오.</target>
        </trans-unit>
        <trans-unit id="5deb9ce023c33b22d107e28507be5494ec70764b" translate="yes" xml:space="preserve">
          <source>Scale each non zero row of X to unit norm</source>
          <target state="translated">X의 0이 아닌 각 행을 단위 규범으로 스케일</target>
        </trans-unit>
        <trans-unit id="617d6ad46bfccaf27b4ba0f374d21f46a99d594e" translate="yes" xml:space="preserve">
          <source>Scale each row of the data matrix by multiplying with specific scale provided by the caller assuming a (n_samples, n_features) shape.</source>
          <target state="translated">(n_samples, n_features) 모양을 가정하고 호출자가 제공 한 특정 스케일을 곱하여 데이터 매트릭스의 각 행을 스케일링하십시오.</target>
        </trans-unit>
        <trans-unit id="2febfe8f8ec8796f6ba7a4455156e82486b6b9ad" translate="yes" xml:space="preserve">
          <source>Scale factor between inner and outer circle.</source>
          <target state="translated">내부 원과 외부 원 사이의 배율.</target>
        </trans-unit>
        <trans-unit id="651dfd0de4ed652c75c33e720387c590f106c0bd" translate="yes" xml:space="preserve">
          <source>Scale features using statistics that are robust to outliers.</source>
          <target state="translated">특이 치에 강력한 통계를 사용하여 기능을 확장합니다.</target>
        </trans-unit>
        <trans-unit id="ea253b52225bff13ccf219a7ede865331cee2a5e" translate="yes" xml:space="preserve">
          <source>Scale input vectors individually to unit norm (vector length).</source>
          <target state="translated">입력 벡터를 개별적으로 단위 규범 (벡터 길이)으로 조정합니다.</target>
        </trans-unit>
        <trans-unit id="3db146d5ef4350db484651a2947cc4449aa1c920" translate="yes" xml:space="preserve">
          <source>Scale mixture parameter</source>
          <target state="translated">스케일 혼합물 파라미터</target>
        </trans-unit>
        <trans-unit id="214cf07e698e140c0ab386ee80be892f7e60d56f" translate="yes" xml:space="preserve">
          <source>Scale the data</source>
          <target state="translated">데이터 스케일</target>
        </trans-unit>
        <trans-unit id="a00231cc0fa6cda008f7de726dc3328122b68e67" translate="yes" xml:space="preserve">
          <source>Scaled data has zero mean and unit variance:</source>
          <target state="translated">스케일링 된 데이터에는 평균 및 단위 분산이 없습니다.</target>
        </trans-unit>
        <trans-unit id="28f5624ffdfd0dbb670e710c5400ff826061c8e3" translate="yes" xml:space="preserve">
          <source>Scalers are linear (or more precisely affine) transformers and differ from each other in the way to estimate the parameters used to shift and scale each feature.</source>
          <target state="translated">스케일러는 선형 (또는보다 정밀한) 변압기이며 각 기능을 이동 및 스케일링하는 데 사용되는 매개 변수를 추정하는 방식에서 서로 다릅니다.</target>
        </trans-unit>
        <trans-unit id="42fb0a5f800741efdeeef6c8d3f6efbb496929e6" translate="yes" xml:space="preserve">
          <source>Scaling a 1D array</source>
          <target state="translated">1D 배열 확장</target>
        </trans-unit>
        <trans-unit id="5e180a611580dedaac6cdcb57565a42487e31efa" translate="yes" xml:space="preserve">
          <source>Scaling features of X according to feature_range.</source>
          <target state="translated">feature_range에 따른 X의 스케일링 기능.</target>
        </trans-unit>
        <trans-unit id="faa375cb6d0913845d11a421f85f4fc1917244d4" translate="yes" xml:space="preserve">
          <source>Scaling inputs to unit norms is a common operation for text classification or clustering for instance. For instance the dot product of two l2-normalized TF-IDF vectors is the cosine similarity of the vectors and is the base similarity metric for the Vector Space Model commonly used by the Information Retrieval community.</source>
          <target state="translated">예를 들어 단위 규범에 대한 입력 스케일링은 텍스트 분류 또는 클러스터링에 대한 일반적인 작업입니다. 예를 들어, 2 개의 l2 정규화 된 TF-IDF 벡터의 내적은 벡터의 코사인 유사성이며 정보 검색 커뮤니티에서 일반적으로 사용하는 벡터 공간 모델의 기본 유사성 메트릭입니다.</target>
        </trans-unit>
        <trans-unit id="c9df043572b1169b126da4f0a95f811ab4322363" translate="yes" xml:space="preserve">
          <source>Scaling of the features in the space spanned by the class centroids.</source>
          <target state="translated">클래스 중심이 차지하는 공간의 기능 스케일링.</target>
        </trans-unit>
        <trans-unit id="f91f363e9d78c82d08c38c5a1dbde0b091a85898" translate="yes" xml:space="preserve">
          <source>Scaling parameter of the chi2 kernel.</source>
          <target state="translated">chi2 커널의 스케일링 매개 변수.</target>
        </trans-unit>
        <trans-unit id="611f59db789837a47c8391146e294e88684d2aac" translate="yes" xml:space="preserve">
          <source>Scaling the regularization parameter for SVCs</source>
          <target state="translated">SVC의 정규화 매개 변수 스케일링</target>
        </trans-unit>
        <trans-unit id="8ca361aee1b505e96263673a562173e09064f7c8" translate="yes" xml:space="preserve">
          <source>Scaling vs Whitening</source>
          <target state="translated">스케일링 및 미백</target>
        </trans-unit>
        <trans-unit id="0b38453e586dafca0c0308eafbfda226dcf7f7c2" translate="yes" xml:space="preserve">
          <source>Scikit-learn also embed a couple of sample JPEG images published under Creative Commons license by their authors. Those image can be useful to test algorithms and pipeline on 2D data.</source>
          <target state="translated">Scikit-learn은 또한 작성자가 Creative Commons 라이센스로 게시 한 몇 가지 샘플 JPEG 이미지도 포함합니다. 이러한 이미지는 2D 데이터에서 알고리즘 및 파이프 라인을 테스트하는 데 유용 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="4f09669bc19a45a6af1925c5dd7e5320d97b9858" translate="yes" xml:space="preserve">
          <source>Scikit-learn also permits evaluation of multiple metrics in &lt;code&gt;GridSearchCV&lt;/code&gt;, &lt;code&gt;RandomizedSearchCV&lt;/code&gt; and &lt;code&gt;cross_validate&lt;/code&gt;.</source>
          <target state="translated">Scikit-learn은 또한 &lt;code&gt;GridSearchCV&lt;/code&gt; , &lt;code&gt;RandomizedSearchCV&lt;/code&gt; 및 &lt;code&gt;cross_validate&lt;/code&gt; 의 여러 메트릭을 평가할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="5427512908da9e885639e4f06d90d3fbb899fa1a" translate="yes" xml:space="preserve">
          <source>Scikit-learn deals with learning information from one or more datasets that are represented as 2D arrays. They can be understood as a list of multi-dimensional observations. We say that the first axis of these arrays is the &lt;strong&gt;samples&lt;/strong&gt; axis, while the second is the &lt;strong&gt;features&lt;/strong&gt; axis.</source>
          <target state="translated">Scikit-learn은 2D 배열로 표시되는 하나 이상의 데이터 집합의 학습 정보를 처리합니다. 그것들은 다차원 관측의 목록으로 이해 될 수 있습니다. 이 배열의 첫 번째 축은 &lt;strong&gt;샘플&lt;/strong&gt; 축이고 두 번째 축은 &lt;strong&gt;피처&lt;/strong&gt; 축이라고합니다.</target>
        </trans-unit>
        <trans-unit id="68787e98ea90825b478bf4a016c311205a6818e9" translate="yes" xml:space="preserve">
          <source>Scikit-learn does some validation on data that increases the overhead per call to &lt;code&gt;predict&lt;/code&gt; and similar functions. In particular, checking that features are finite (not NaN or infinite) involves a full pass over the data. If you ensure that your data is acceptable, you may suppress checking for finiteness by setting the environment variable &lt;code&gt;SKLEARN_ASSUME_FINITE&lt;/code&gt; to a non-empty string before importing scikit-learn, or configure it in Python with &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt;. For more control than these global settings, a &lt;code&gt;config_context&lt;/code&gt; allows you to set this configuration within a specified context:</source>
          <target state="translated">Scikit-learn은 &lt;code&gt;predict&lt;/code&gt; 및 유사한 기능에 대한 호출 당 오버 헤드를 증가시키는 데이터에 대한 일부 유효성 검사를 수행합니다. 특히, 피처가 유한한지 (NaN이 아니거나 무한한지) 확인하면 데이터를 완전히 통과해야합니다. 데이터가 허용 가능한지 확인하는 경우 scikit-learn을 가져 오기 전에 환경 변수 &lt;code&gt;SKLEARN_ASSUME_FINITE&lt;/code&gt; 를 비어 있지 않은 문자열 로 설정하여 유한 검사를 억제 하거나 &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;sklearn.set_config&lt;/code&gt; 를 사용&lt;/a&gt; 하여 Python에서 구성 할 수 있습니다. 이러한 전역 설정보다 더 많은 제어를 위해 &lt;code&gt;config_context&lt;/code&gt; 를 사용하면 지정된 컨텍스트 내에서이 구성을 설정할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="562455165c34b7c83008b571c9bd46eceb879b92" translate="yes" xml:space="preserve">
          <source>Scikit-learn has a collection of classes which can be used to generate lists of train/test indices for popular cross-validation strategies.</source>
          <target state="translated">Scikit-learn에는 인기있는 교차 유효성 검사 전략에 대한 기차 / 테스트 지수 목록을 생성하는 데 사용할 수있는 클래스 모음이 있습니다.</target>
        </trans-unit>
        <trans-unit id="b670925eafc995f1763e66f682772271e15a05e5" translate="yes" xml:space="preserve">
          <source>Scikit-learn implements different classes to estimate Gaussian mixture models, that correspond to different estimation strategies, detailed below.</source>
          <target state="translated">Scikit-learn은 서로 다른 추정 전략에 해당하는 가우시안 혼합 모델을 추정하기 위해 다양한 클래스를 구현합니다 (아래에 자세히 설명 됨).</target>
        </trans-unit>
        <trans-unit id="e9a530527422759264cd84546f6a0bd4a26252b3" translate="yes" xml:space="preserve">
          <source>Scikit-learn implements efficient kernel density estimation using either a Ball Tree or KD Tree structure, through the &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt;&lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt;&lt;/a&gt; estimator. The available kernels are shown in the second figure of this example.</source>
          <target state="translated">Scikit-learn은 &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt; &lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt; &lt;/a&gt; Estimator를 통해 Ball Tree 또는 KD Tree 구조를 사용하여 효율적인 커널 밀도 추정을 구현합니다 . 사용 가능한 커널은이 예제의 두 번째 그림에 나와 있습니다.</target>
        </trans-unit>
        <trans-unit id="b29477e8796624fa3eb37a4b942da5b84d872c57" translate="yes" xml:space="preserve">
          <source>Scikit-learn is a Python module integrating classic machine learning algorithms in the tightly-knit world of scientific Python packages (&lt;a href=&quot;http://www.scipy.org&quot;&gt;NumPy&lt;/a&gt;, &lt;a href=&quot;http://www.scipy.org&quot;&gt;SciPy&lt;/a&gt;, &lt;a href=&quot;http://matplotlib.org&quot;&gt;matplotlib&lt;/a&gt;).</source>
          <target state="translated">Scikit-learn은 밀접하게 짜여진 과학적 파이썬 패키지 ( &lt;a href=&quot;http://www.scipy.org&quot;&gt;NumPy&lt;/a&gt; , &lt;a href=&quot;http://www.scipy.org&quot;&gt;SciPy&lt;/a&gt; , &lt;a href=&quot;http://matplotlib.org&quot;&gt;matplotlib&lt;/a&gt; )에 고전적인 머신 러닝 알고리즘을 통합 한 Python 모듈입니다 .</target>
        </trans-unit>
        <trans-unit id="5244e6b9c3228eb8fcf423888d9d9a31c68e2222" translate="yes" xml:space="preserve">
          <source>Scikit-learn offers a more efficient implementation for the construction of decision trees. A naive implementation (as above) would recompute the class label histograms (for classification) or the means (for regression) at for each new split point along a given feature. Presorting the feature over all relevant samples, and retaining a running label count, will reduce the complexity at each node to \(O(n_{features}\log(n_{samples}))\), which results in a total cost of \(O(n_{features}n_{samples}\log(n_{samples}))\). This is an option for all tree based algorithms. By default it is turned on for gradient boosting, where in general it makes training faster, but turned off for all other algorithms as it tends to slow down training when training deep trees.</source>
          <target state="translated">Scikit-learn은 의사 결정 트리 구성을위한보다 효율적인 구현을 제공합니다. (위와 같이) 순진한 구현은 주어진 지형지 물을 따라 각각의 새로운 분리 점에 대한 클래스 레이블 히스토그램 (분류) 또는 평균 (회귀)을 재 계산합니다. 모든 관련 샘플에 대해 기능을 미리 정렬하고 레이블 수를 유지하면 각 노드의 복잡성이 \ (O (n_ {features} \ log (n_ {samples})) \)로 감소하여 총 비용이 \ (O (n_ {기능} n_ {samples} \ log (n_ {samples})) \). 이것은 모든 트리 기반 알고리즘에 대한 옵션입니다. 기본적으로 그라디언트 부스팅을 위해 켜져 있으며 일반적으로 훈련 속도는 빨라지지만 다른 모든 알고리즘에서는 딥 트리를 훈련 할 때 훈련 속도가 느려질 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="4affb29f4cf970be26e1f3befb3e52980b3745a3" translate="yes" xml:space="preserve">
          <source>Scikit-learn provides 3 robust regression estimators: &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;, &lt;a href=&quot;#theil-sen-regression&quot;&gt;Theil Sen&lt;/a&gt; and &lt;a href=&quot;#huber-regression&quot;&gt;HuberRegressor&lt;/a&gt;</source>
          <target state="translated">Scikit-learn은 &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt; , &lt;a href=&quot;#theil-sen-regression&quot;&gt;Theil Sen&lt;/a&gt; 및 &lt;a href=&quot;#huber-regression&quot;&gt;HuberRegressor의&lt;/a&gt; 3 가지 강력한 회귀 추정값을 제공합니다.</target>
        </trans-unit>
        <trans-unit id="760c9dce2728b87b0e773a2a2023bd5ef6b1ebc6" translate="yes" xml:space="preserve">
          <source>Scikit-learn uses the &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/&quot;&gt;joblib&lt;/a&gt; library to enable parallel computing inside its estimators. See the joblib documentation for the switches to control parallel computing.</source>
          <target state="translated">Scikit-learn은 &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/&quot;&gt;joblib&lt;/a&gt; 라이브러리를 사용하여 추정기 내에서 병렬 컴퓨팅을 가능하게합니다. 병렬 컴퓨팅을 제어하는 ​​스위치에 대해서는 joblib 문서를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="dbdfa5cbcc37d085da70cbad1d49bb4154a25ae3" translate="yes" xml:space="preserve">
          <source>Scipy provides sparse matrix data structures which are optimized for storing sparse data. The main feature of sparse formats is that you don&amp;rsquo;t store zeros so if your data is sparse then you use much less memory. A non-zero value in a sparse (&lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;CSR or CSC&lt;/a&gt;) representation will only take on average one 32bit integer position + the 64 bit floating point value + an additional 32bit per row or column in the matrix. Using sparse input on a dense (or sparse) linear model can speedup prediction by quite a bit as only the non zero valued features impact the dot product and thus the model predictions. Hence if you have 100 non zeros in 1e6 dimensional space, you only need 100 multiply and add operation instead of 1e6.</source>
          <target state="translated">Scipy는 희소 데이터 저장에 최적화 된 희소 행렬 데이터 구조를 제공합니다. 스파 스 형식의 주요 기능은 0을 저장하지 않으므로 데이터가 드문 경우 훨씬 적은 메모리를 사용한다는 것입니다. 희소 ( &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;CSR 또는 CSC&lt;/a&gt; ) 표현 에서 0이 아닌 값은 평균적으로 하나의 32 비트 정수 위치 + 64 비트 부동 소수점 값 + 행렬의 행 또는 열당 추가 32 비트 만 취합니다. 밀도가 높은 (또는 희소 한) 선형 모델에서 희소 입력을 사용하면 값이 0이 아닌 피처 만 내적과 모델 예측에 영향을 미치기 때문에 예측 속도를 약간 높일 수 있습니다. 따라서 1e6 차원 공간에 100이 아닌 0이있는 경우 100을 곱하고 1e6 대신 연산을 추가하면됩니다.</target>
        </trans-unit>
        <trans-unit id="73ff9df76cca7434e9bdc94c5c539e98a711a167" translate="yes" xml:space="preserve">
          <source>Scipy sparse matrix formats documentation</source>
          <target state="translated">Scipy 희소 행렬 형식 설명서</target>
        </trans-unit>
        <trans-unit id="ec44ac6f635d9837f888fea19337ecd3bc1dc78d" translate="yes" xml:space="preserve">
          <source>Score function (or loss function) with signature &lt;code&gt;score_func(y, y_pred, **kwargs)&lt;/code&gt;.</source>
          <target state="translated">서명과 점수 함수 (또는 손실 함수) &lt;code&gt;score_func(y, y_pred, **kwargs)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4106362aa56af5a012e22c8aae43583defb47511" translate="yes" xml:space="preserve">
          <source>Score of self.predict(X) wrt. y.</source>
          <target state="translated">self.predict (X) wrt의 점수 와이.</target>
        </trans-unit>
        <trans-unit id="269ca6f46a2303fa294fd49cbab7d3d725c81bb2" translate="yes" xml:space="preserve">
          <source>Score of the prediction.</source>
          <target state="translated">예측 점수.</target>
        </trans-unit>
        <trans-unit id="fee68e2ae75f4d785b563d7d07175bca2df697af" translate="yes" xml:space="preserve">
          <source>Score of the training dataset obtained using an out-of-bag estimate.</source>
          <target state="translated">가방 외부 견적을 사용하여 얻은 훈련 데이터 세트의 점수.</target>
        </trans-unit>
        <trans-unit id="fdd43514c35f028b5dfc878c7661a274717e7633" translate="yes" xml:space="preserve">
          <source>Score of this parameter setting on given training / test split.</source>
          <target state="translated">주어진 훈련 / 테스트 스플릿에서이 파라미터 설정의 점수.</target>
        </trans-unit>
        <trans-unit id="e14703c8615f59873dec25794c9dae3e6fdaa2e4" translate="yes" xml:space="preserve">
          <source>Score, and cross-validated scores</source>
          <target state="translated">점수 및 교차 검증 된 점수</target>
        </trans-unit>
        <trans-unit id="5ac699be69d4f6f03061e9fdf043eeb8d0ba0ed6" translate="yes" xml:space="preserve">
          <source>Scorer function used on the held out data to choose the best parameters for the model.</source>
          <target state="translated">보류 된 데이터에 사용 된 스코어러 기능은 모델에 가장 적합한 매개 변수를 선택합니다.</target>
        </trans-unit>
        <trans-unit id="dafe5cdb100f4bad5185f8a89151e9de127407db" translate="yes" xml:space="preserve">
          <source>Scores of all outputs are averaged with uniform weight.</source>
          <target state="translated">모든 출력의 점수는 균일 한 가중치로 평균화됩니다.</target>
        </trans-unit>
        <trans-unit id="a879b57711ff565bb3c57b9cbdbf3f09144796d5" translate="yes" xml:space="preserve">
          <source>Scores of all outputs are averaged, weighted by the variances of each individual output.</source>
          <target state="translated">모든 산출물의 점수는 각 개별 산출의 분산에 의해 가중되어 평균화됩니다.</target>
        </trans-unit>
        <trans-unit id="bad96478d4d42d160afd8f51da6516a096f00968" translate="yes" xml:space="preserve">
          <source>Scores of features.</source>
          <target state="translated">기능의 점수.</target>
        </trans-unit>
        <trans-unit id="004421c31cff3e85919b0da3d9213b70c070211e" translate="yes" xml:space="preserve">
          <source>Scores on test set.</source>
          <target state="translated">시험 세트에 대한 점수.</target>
        </trans-unit>
        <trans-unit id="9cb2f72d484e4d0e25f5504cf3cb781f6831387a" translate="yes" xml:space="preserve">
          <source>Scores on training sets.</source>
          <target state="translated">훈련 세트에 대한 점수.</target>
        </trans-unit>
        <trans-unit id="a6e081bd4fc687e97f2a3c1767e01a47d8d0d090" translate="yes" xml:space="preserve">
          <source>Scoring</source>
          <target state="translated">Scoring</target>
        </trans-unit>
        <trans-unit id="88173ba266bcaafd44bc526091a11bf84a691634" translate="yes" xml:space="preserve">
          <source>Second example</source>
          <target state="translated">두 번째 예</target>
        </trans-unit>
        <trans-unit id="e4e2db45443f0fd4ae50799405ca1ddce61eefb7" translate="yes" xml:space="preserve">
          <source>Second, when using a connectivity matrix, single, average and complete linkage are unstable and tend to create a few clusters that grow very quickly. Indeed, average and complete linkage fight this percolation behavior by considering all the distances between two clusters when merging them ( while single linkage exaggerates the behaviour by considering only the shortest distance between clusters). The connectivity graph breaks this mechanism for average and complete linkage, making them resemble the more brittle single linkage. This effect is more pronounced for very sparse graphs (try decreasing the number of neighbors in kneighbors_graph) and with complete linkage. In particular, having a very small number of neighbors in the graph, imposes a geometry that is close to that of single linkage, which is well known to have this percolation instability.</source>
          <target state="translated">둘째, 연결 매트릭스를 사용할 때 단일, 평균 및 전체 연결이 불안정하고 매우 빠르게 성장하는 몇 개의 클러스터를 만드는 경향이 있습니다. 실제로, 평균적이고 완전한 연계는 두 클러스터 사이의 모든 거리를 병합 할 때이 퍼콜 레이션 동작에 맞서 싸 웁니다 (단일 링크는 클러스터 사이의 최단 거리 만 고려하여 동작을 과장합니다). 연결성 그래프는 평균 및 전체 연결에 대해이 메커니즘을 분리하여보다 취약한 단일 연결과 유사합니다. 이 효과는 매우 드문 그래프 (kneighbors_graph의 이웃 수를 줄이십시오)와 완전한 연결에 대해 더욱 두드러집니다. 특히 그래프에 매우 적은 수의 이웃이 있으면 단일 링키지의 형상에 가까운 형상이 적용됩니다.이 침투 불안정성을 갖는 것으로 잘 알려져 있습니다.</target>
        </trans-unit>
        <trans-unit id="53553e63fb4cb7ed1ae88d54b317154b9777e613" translate="yes" xml:space="preserve">
          <source>Seconds used for refitting the best model on the whole dataset.</source>
          <target state="translated">전체 데이터 세트에서 최상의 모델을 다시 계산하는 데 사용되는 초입니다.</target>
        </trans-unit>
        <trans-unit id="fa04a576bd56d584afacdf30a223dc3f1fde4eb3" translate="yes" xml:space="preserve">
          <source>Section 5.4.4, pp. 252-253.</source>
          <target state="translated">섹션 5.4.4, 252-253 페이지.</target>
        </trans-unit>
        <trans-unit id="d4628726ca2b8e9b183e1257c782a69297176123" translate="yes" xml:space="preserve">
          <source>Section contents</source>
          <target state="translated">섹션 내용</target>
        </trans-unit>
        <trans-unit id="978feab4a35a4b897d5316b48dac562d3091d0c5" translate="yes" xml:space="preserve">
          <source>See &amp;ldquo;Random Features for Large-Scale Kernel Machines&amp;rdquo; by A. Rahimi and Benjamin Recht.</source>
          <target state="translated">A. Rahimi와 Benjamin Recht의&amp;ldquo;대규모 커널 시스템의 임의 기능&amp;rdquo;을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="b31673babc80845a872201a18703583634f75350" translate="yes" xml:space="preserve">
          <source>See &amp;ldquo;Random Fourier Approximations for Skewed Multiplicative Histogram Kernels&amp;rdquo; by Fuxin Li, Catalin Ionescu and Cristian Sminchisescu.</source>
          <target state="translated">Fuxin Li, Catalin Ionescu 및 Cristian Sminchisescu의&amp;ldquo;비뚤어진 곱셈 히스토그램 커널에 대한 랜덤 푸리에 근사치&amp;rdquo;를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="0df8f05c9ec568b4cc1c4d54a3085f0ebf794bd9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#rw2006&quot; id=&quot;id6&quot;&gt;[RW2006]&lt;/a&gt;, pp84 for further details regarding the different variants of the Mat&amp;eacute;rn kernel.</source>
          <target state="translated">Mat&amp;eacute;rn 커널의 다양한 변형에 대한 자세한 내용 은 &lt;a href=&quot;#rw2006&quot; id=&quot;id6&quot;&gt;[RW2006]&lt;/a&gt; , pp84를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="dd13548eb92de90d6303ee640236c96cda68888f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#svm-mathematical-formulation&quot;&gt;Mathematical formulation&lt;/a&gt; for a complete description of the decision function.</source>
          <target state="translated">결정 기능에 대한 자세한 설명은 &lt;a href=&quot;#svm-mathematical-formulation&quot;&gt;수학 공식&lt;/a&gt; 을 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="90eaaa0456af60c46de8c81dc16ee15dad424d81" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/compose/plot_transformed_target#sphx-glr-auto-examples-compose-plot-transformed-target-py&quot;&gt;examples/compose/plot_transformed_target.py&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../../auto_examples/compose/plot_transformed_target#sphx-glr-auto-examples-compose-plot-transformed-target-py&quot;&gt;examples / compose / plot_transformed_target.py를&lt;/a&gt; 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="0d70be16f79f29cfb466970ca83989e73f6c00bb" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;examples/linear_model/plot_polynomial_interpolation.py&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;../../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;examples / linear_model / plot_polynomial_interpolation.py를&lt;/a&gt; 참조하십시오</target>
        </trans-unit>
        <trans-unit id="66218b0f5237d32e41f01914713a47022cf20bb9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/model_selection/plot_learning_curve#sphx-glr-auto-examples-model-selection-plot-learning-curve-py&quot;&gt;examples/model_selection/plot_learning_curve.py&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;../../auto_examples/model_selection/plot_learning_curve#sphx-glr-auto-examples-model-selection-plot-learning-curve-py&quot;&gt;examples / model_selection / plot_learning_curve.py를&lt;/a&gt; 참조하십시오</target>
        </trans-unit>
        <trans-unit id="41261fbeb952dd5951bf36801866ce019db00dde" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/model_selection/plot_validation_curve#sphx-glr-auto-examples-model-selection-plot-validation-curve-py&quot;&gt;Plotting Validation Curves&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;../../auto_examples/model_selection/plot_validation_curve#sphx-glr-auto-examples-model-selection-plot-validation-curve-py&quot;&gt;검증 곡선 플로팅&lt;/a&gt; 참조</target>
        </trans-unit>
        <trans-unit id="6a3b0e6c0d79b7c03e9dbb288652a52d5e7d7fd5" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/linear_model#bayesian-ridge-regression&quot;&gt;Bayesian Ridge Regression&lt;/a&gt; for more information on the regressor.</source>
          <target state="translated">&lt;a href=&quot;../../modules/linear_model#bayesian-ridge-regression&quot;&gt;회귀기에&lt;/a&gt; 대한 자세한 내용 은 베이지안 릿지 회귀 를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="824c64b490bd5bd779a22eec474ba042707228d1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/linear_model#theil-sen-regression&quot;&gt;Theil-Sen estimator: generalized-median-based estimator&lt;/a&gt; for more information on the regressor.</source>
          <target state="translated">참조 &lt;a href=&quot;../../modules/linear_model#theil-sen-regression&quot;&gt;Theil-센 추정을 : 일반 - 중간 기반의 추정을&lt;/a&gt; 회귀 변수에 대한 자세한 내용은.</target>
        </trans-unit>
        <trans-unit id="36bf338f19ee54a0199babdefd0eaf5b203f80f4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/mixture#gmm&quot;&gt;Gaussian mixture models&lt;/a&gt; for more information on the estimator.</source>
          <target state="translated">참조 &lt;a href=&quot;../../modules/mixture#gmm&quot;&gt;가우시안 혼합 모델을&lt;/a&gt; 추에 대한 자세한 내용은.</target>
        </trans-unit>
        <trans-unit id="bda58af52a4d947e4c6e336facf5860c69c8478b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/tree#tree&quot;&gt;decision tree&lt;/a&gt; for more information on the estimator.</source>
          <target state="translated">추정기에 대한 자세한 정보는 &lt;a href=&quot;../../modules/tree#tree&quot;&gt;의사 결정 트리&lt;/a&gt; 를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="1876d72641fc6bba23917c9ce1b023a0c5308e82" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;Species distribution modeling&lt;/a&gt; for an example of using ROC to model species distribution.</source>
          <target state="translated">ROC를 사용하여 &lt;a href=&quot;../auto_examples/applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;종 분포를 모델링&lt;/a&gt; 하는 예는 종 분포 모델링 을 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="3ca47154d5f58b185be5af00ff9392b2598d6abf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/calibration/plot_calibration#sphx-glr-auto-examples-calibration-plot-calibration-py&quot;&gt;Probability calibration of classifiers&lt;/a&gt; for an example of Brier score loss usage to perform probability calibration of classifiers.</source>
          <target state="translated">&lt;a href=&quot;../auto_examples/calibration/plot_calibration#sphx-glr-auto-examples-calibration-plot-calibration-py&quot;&gt;분류기의 확률 보정&lt;/a&gt; 을 수행하기위한 Brier 점수 손실 사용의 예 는 분류기의 확률 보정을 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="282928c19fbfe87fe4167148ff3b6058bc018479" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;Recognizing hand-written digits&lt;/a&gt; for an example of classification report usage for hand-written digits.</source>
          <target state="translated">&lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;손으로 쓴 숫자에&lt;/a&gt; 대한 분류 보고서 사용법의 예는 손으로 쓴 숫자 인식을 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="72d62eaa2236b9a2dd2c8a6bb04573291c57c36e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;Recognizing hand-written digits&lt;/a&gt; for an example of using a confusion matrix to classify hand-written digits.</source>
          <target state="translated">혼동 행렬을 사용하여 손으로 쓴 숫자를 분류하는 예는 &lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;손으로 쓴 숫자 인식을&lt;/a&gt; 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="87880060115f16d38cb34f093520114ae1691683" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit a &lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt;&lt;code&gt;LedoitWolf&lt;/code&gt;&lt;/a&gt; object to data and for visualizing the performances of the Ledoit-Wolf estimator in terms of likelihood.</source>
          <target state="translated">보다 &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;&lt;/a&gt;&lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt; &lt;code&gt;LedoitWolf&lt;/code&gt; &lt;/a&gt; 객체를 데이터 에 맞추는 방법 및 Ledoit-Wolf 추정기의 성능을 가능성 측면에서 시각화하는 방법에 대한 예는 수축 공분산 추정 : LedoitWolf 대 OAS 및 최대 가능성 을 .</target>
        </trans-unit>
        <trans-unit id="2209166f8c957bd217f6d5f461ba4322d29b02c2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit a &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance&quot;&gt;&lt;code&gt;ShrunkCovariance&lt;/code&gt;&lt;/a&gt; object to data.</source>
          <target state="translated">보다 &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;&lt;/a&gt;&lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance&quot;&gt; &lt;code&gt;ShrunkCovariance&lt;/code&gt; &lt;/a&gt; 객체를 데이터에 맞추는 방법에 대한 예는 수축 공분산 추정 : LedoitWolf vs OAS 및 최대 가능성 을 .</target>
        </trans-unit>
        <trans-unit id="88a19b944edc191f5f7b057963b65a4e9112c1b2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit an &lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;EmpiricalCovariance&lt;/code&gt;&lt;/a&gt; object to data.</source>
          <target state="translated">보다 &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;&lt;/a&gt;&lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt; &lt;code&gt;EmpiricalCovariance&lt;/code&gt; &lt;/a&gt; 객체를 데이터에 맞추는 방법에 대한 예는 수축 공분산 추정 : LedoitWolf vs OAS 및 최대 가능성 을 .</target>
        </trans-unit>
        <trans-unit id="8a3f5dc7dd1289a56afbdf19c9d4415f754d0c74" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit an &lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt;&lt;code&gt;OAS&lt;/code&gt;&lt;/a&gt; object to data.</source>
          <target state="translated">보다 &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;&lt;/a&gt;&lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt; &lt;code&gt;OAS&lt;/code&gt; &lt;/a&gt; 객체를 데이터에 맞추는 방법에 대한 예는 수축 공분산 추정 : LedoitWolf vs OAS 및 최대 가능성 을 .</target>
        </trans-unit>
        <trans-unit id="a2ce4b68a58fc4d4775fc307d3337bfc6ba95951" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_lw_vs_oas#sphx-glr-auto-examples-covariance-plot-lw-vs-oas-py&quot;&gt;Ledoit-Wolf vs OAS estimation&lt;/a&gt; to visualize the Mean Squared Error difference between a &lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt;&lt;code&gt;LedoitWolf&lt;/code&gt;&lt;/a&gt; and an &lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt;&lt;code&gt;OAS&lt;/code&gt;&lt;/a&gt; estimator of the covariance.</source>
          <target state="translated">참조 &lt;a href=&quot;../auto_examples/covariance/plot_lw_vs_oas#sphx-glr-auto-examples-covariance-plot-lw-vs-oas-py&quot;&gt;OAS 추정 대 LedoitWolf을&lt;/a&gt; 사이의 평균 제곱 오류 차이 시각화 &lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt; &lt;code&gt;LedoitWolf&lt;/code&gt; 을&lt;/a&gt; 와 공분산 의 &lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt; &lt;code&gt;OAS&lt;/code&gt; &lt;/a&gt; 추정기 .</target>
        </trans-unit>
        <trans-unit id="8878b5f91edc950d3f968af54f37c8ec353c6370" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;Robust covariance estimation and Mahalanobis distances relevance&lt;/a&gt; for an illustration of the difference between using a standard (&lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;covariance.EmpiricalCovariance&lt;/code&gt;&lt;/a&gt;) or a robust estimate (&lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt;&lt;code&gt;covariance.MinCovDet&lt;/code&gt;&lt;/a&gt;) of location and covariance to assess the degree of outlyingness of an observation.</source>
          <target state="translated">표준 ( &lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt; &lt;code&gt;covariance.EmpiricalCovariance&lt;/code&gt; &lt;/a&gt; 사용하는 것의 차이에 대한 설명은 &lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;강력한 공분산 추정 및 Mahalanobis 거리 관련성&lt;/a&gt; 을 참조하십시오. ) 또는 강력한 추정치 ( &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt; &lt;code&gt;covariance.MinCovDet&lt;/code&gt; &lt;/a&gt; 관찰 outlyingness의 정도를 평가하기 위해 위치 및 공분산을).</target>
        </trans-unit>
        <trans-unit id="030742fc8b624a6be4238fb99cd9f5a0e364d687" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;Robust covariance estimation and Mahalanobis distances relevance&lt;/a&gt; to visualize the difference between &lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;EmpiricalCovariance&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt;&lt;code&gt;MinCovDet&lt;/code&gt;&lt;/a&gt; covariance estimators in terms of Mahalanobis distance (so we get a better estimate of the precision matrix too).</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt; &lt;code&gt;EmpiricalCovariance&lt;/code&gt; &lt;/a&gt; 의 차이를 시각화하려면 &lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;강력한 공분산 추정 및 Mahalanobis 거리 관련성&lt;/a&gt; 을 참조하십시오. 측면에서 와 &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt; &lt;code&gt;MinCovDet&lt;/code&gt; &lt;/a&gt; 공분산 추정기 (따라서 정밀 행렬의 더 나은 추정값도 얻음).</target>
        </trans-unit>
        <trans-unit id="f9a056a85b47a4a6c1a6d704788263d39761f07a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_robust_vs_empirical_covariance#sphx-glr-auto-examples-covariance-plot-robust-vs-empirical-covariance-py&quot;&gt;Robust vs Empirical covariance estimate&lt;/a&gt; for an example on how to fit a &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt;&lt;code&gt;MinCovDet&lt;/code&gt;&lt;/a&gt; object to data and see how the estimate remains accurate despite the presence of outliers.</source>
          <target state="translated">적합 법에 대한 예는 &lt;a href=&quot;../auto_examples/covariance/plot_robust_vs_empirical_covariance#sphx-glr-auto-examples-covariance-plot-robust-vs-empirical-covariance-py&quot;&gt;견고성 대 경험적 공분산 추정치&lt;/a&gt; 를 참조하십시오 .&lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt; &lt;code&gt;MinCovDet&lt;/code&gt; 의&lt;/a&gt; 추정은 이상치의 존재에도 불구하고 정확한 남아있는 데이터 객체를 볼.</target>
        </trans-unit>
        <trans-unit id="995b452653e2a34828a53fff1225e032a84a1ed7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/ensemble/plot_gradient_boosting_regression#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py&quot;&gt;Gradient Boosting regression&lt;/a&gt; for an example of mean squared error usage to evaluate gradient boosting regression.</source>
          <target state="translated">보다 &lt;a href=&quot;../auto_examples/ensemble/plot_gradient_boosting_regression#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py&quot;&gt;그라디언트 부스팅 회귀&lt;/a&gt; 를 평가하기위한 평균 제곱 오류 사용법의 예는 그라디언트 부스팅 회귀 를 .</target>
        </trans-unit>
        <trans-unit id="c70bb54b9f9c6d372a94de7482636d40519b333f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/ensemble/plot_isolation_forest#sphx-glr-auto-examples-ensemble-plot-isolation-forest-py&quot;&gt;IsolationForest example&lt;/a&gt; for an illustration of the use of IsolationForest.</source>
          <target state="translated">보다 &lt;a href=&quot;../auto_examples/ensemble/plot_isolation_forest#sphx-glr-auto-examples-ensemble-plot-isolation-forest-py&quot;&gt;IsolationForest&lt;/a&gt; 사용에 대한 그림은 IsolationForest 예 를 .</target>
        </trans-unit>
        <trans-unit id="462e8cdc93001fb7a3648b1195482e1f8b22fe44" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/feature_selection/plot_permutation_test_for_classification#sphx-glr-auto-examples-feature-selection-plot-permutation-test-for-classification-py&quot;&gt;Test with permutations the significance of a classification score&lt;/a&gt; for an example of accuracy score usage using permutations of the dataset.</source>
          <target state="translated">보다 &lt;a href=&quot;../auto_examples/feature_selection/plot_permutation_test_for_classification#sphx-glr-auto-examples-feature-selection-plot-permutation-test-for-classification-py&quot;&gt;&lt;/a&gt;데이터 세트의 순열을 사용한 정확도 점수 사용의 예는 순열을 사용한 테스트로 분류 점수의 중요성을 .</target>
        </trans-unit>
        <trans-unit id="39b73a8956b97e37d2a1a56a5487c771ec6755e2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/feature_selection/plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;Recursive feature elimination with cross-validation&lt;/a&gt; for an example of zero one loss usage to perform recursive feature elimination with cross-validation.</source>
          <target state="translated">보다 &lt;a href=&quot;../auto_examples/feature_selection/plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;교차 유효성 검사&lt;/a&gt; 로 재귀 기능 제거를 수행하기위한 무손실 사용의 예는 교차 유효성 검사 로 재귀 기능 제거를 .</target>
        </trans-unit>
        <trans-unit id="92f30204fbfed37d4520688e6847c0f1dec6d444" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/linear_model/plot_lasso_and_elasticnet#sphx-glr-auto-examples-linear-model-plot-lasso-and-elasticnet-py&quot;&gt;Lasso and Elastic Net for Sparse Signals&lt;/a&gt; for an example of R&amp;sup2; score usage to evaluate Lasso and Elastic Net on sparse signals.</source>
          <target state="translated">보다 &lt;a href=&quot;../auto_examples/linear_model/plot_lasso_and_elasticnet#sphx-glr-auto-examples-linear-model-plot-lasso-and-elasticnet-py&quot;&gt;스파 스 신호&lt;/a&gt; 에서 Lasso 및 Elastic Net을 평가하기위한 R&amp;sup2; 점수 사용의 예는 스파 스 신호에 대한 Lasso 및 Elastic Net을 .</target>
        </trans-unit>
        <trans-unit id="01a78f9ef24e4fc8896bfa27a1c142f94096fbf4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;Polynomial interpolation&lt;/a&gt; for Ridge regression using created polynomial features.</source>
          <target state="translated">보다 &lt;a href=&quot;../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;&lt;/a&gt;작성된 다항식 피처를 사용하여 릿지 회귀에 대한 다항식 보간 을 .</target>
        </trans-unit>
        <trans-unit id="6cc1903f7fccc8472139b491e9c35281e331be73" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/manifold/plot_compare_methods#sphx-glr-auto-examples-manifold-plot-compare-methods-py&quot;&gt;Comparison of Manifold Learning methods&lt;/a&gt; for an example of dimensionality reduction on a toy &amp;ldquo;S-curve&amp;rdquo; dataset.</source>
          <target state="translated">보다 &lt;a href=&quot;../auto_examples/manifold/plot_compare_methods#sphx-glr-auto-examples-manifold-plot-compare-methods-py&quot;&gt;&lt;/a&gt;장난감 &quot;S- 곡선&quot;데이터 세트의 차원 축소에 대한 예 는 매니 폴드 학습 방법 비교를 .</target>
        </trans-unit>
        <trans-unit id="c13f7bab27de634fe8533a5ffc3f4d5d442fb940" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/manifold/plot_lle_digits#sphx-glr-auto-examples-manifold-plot-lle-digits-py&quot;&gt;Manifold learning on handwritten digits: Locally Linear Embedding, Isomap&amp;hellip;&lt;/a&gt; for an example of dimensionality reduction on handwritten digits.</source>
          <target state="translated">보다 &lt;a href=&quot;../auto_examples/manifold/plot_lle_digits#sphx-glr-auto-examples-manifold-plot-lle-digits-py&quot;&gt;필기 자릿수&lt;/a&gt; 의 차원 축소에 대한 예는 자필 자릿수에 대한 매니 폴드 학습 : 로컬 선형 임베딩, 아이소 맵&amp;hellip; 을 .</target>
        </trans-unit>
        <trans-unit id="ba387b296d0109ccfdd27d435e72e0bda0b98a94" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_concentration_prior#sphx-glr-auto-examples-mixture-plot-concentration-prior-py&quot;&gt;Concentration Prior Type Analysis of Variation Bayesian Gaussian Mixture&lt;/a&gt; for an example plotting the confidence ellipsoids for the &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt; with different &lt;code&gt;weight_concentration_prior_type&lt;/code&gt; for different values of the parameter &lt;code&gt;weight_concentration_prior&lt;/code&gt;.</source>
          <target state="translated">매개 변수 &lt;code&gt;weight_concentration_prior&lt;/code&gt; 의 다른 값에 대해 다른 &lt;code&gt;weight_concentration_prior_type&lt;/code&gt; 을 갖는 &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt; &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; &lt;/a&gt; 의 신뢰 타원체를 플로팅하는 예제 &lt;a href=&quot;../auto_examples/mixture/plot_concentration_prior#sphx-glr-auto-examples-mixture-plot-concentration-prior-py&quot;&gt;는 변형 베이지안 가우스 혼합의 농도 사전 유형 분석을&lt;/a&gt; 참조하십시오. .</target>
        </trans-unit>
        <trans-unit id="17317cd9be65f918f2c9598fbac39ad346f5db56" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm#sphx-glr-auto-examples-mixture-plot-gmm-py&quot;&gt;Gaussian Mixture Model Ellipsoids&lt;/a&gt; for an example on plotting the confidence ellipsoids for both &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt;&lt;code&gt;GaussianMixture&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt; &lt;code&gt;GaussianMixture&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt; &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; 에&lt;/a&gt; 대한 신뢰 타원체를 플로팅하는 방법에 대한 예제는 &lt;a href=&quot;../auto_examples/mixture/plot_gmm#sphx-glr-auto-examples-mixture-plot-gmm-py&quot;&gt;Gaussian Mixture Model Ellipsoids&lt;/a&gt; 를 참조하십시오. .</target>
        </trans-unit>
        <trans-unit id="a5877cbb374e3dc33496a562d7ff812fdb5db635" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm_covariances#sphx-glr-auto-examples-mixture-plot-gmm-covariances-py&quot;&gt;GMM covariances&lt;/a&gt; for an example of using the Gaussian mixture as clustering on the iris dataset.</source>
          <target state="translated">보다 &lt;a href=&quot;../auto_examples/mixture/plot_gmm_covariances#sphx-glr-auto-examples-mixture-plot-gmm-covariances-py&quot;&gt;&lt;/a&gt;홍채 데이터 세트에서 가우스 혼합을 클러스터링으로 사용하는 예는 GMM 공분산 을 .</target>
        </trans-unit>
        <trans-unit id="235746c777e5faff74a54e9f92e2aa47946dcca8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm_pdf#sphx-glr-auto-examples-mixture-plot-gmm-pdf-py&quot;&gt;Density Estimation for a Gaussian mixture&lt;/a&gt; for an example on plotting the density estimation.</source>
          <target state="translated">&lt;a href=&quot;../auto_examples/mixture/plot_gmm_pdf#sphx-glr-auto-examples-mixture-plot-gmm-pdf-py&quot;&gt;가우스 혼합에 대한 밀도 추정을&lt;/a&gt; 참조하십시오 플롯에 대한 예 대한 .</target>
        </trans-unit>
        <trans-unit id="1f45342ed85fb843511e05db7aa53da9e05cd4c8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm_selection#sphx-glr-auto-examples-mixture-plot-gmm-selection-py&quot;&gt;Gaussian Mixture Model Selection&lt;/a&gt; for an example of model selection performed with classical Gaussian mixture.</source>
          <target state="translated">&lt;a href=&quot;../auto_examples/mixture/plot_gmm_selection#sphx-glr-auto-examples-mixture-plot-gmm-selection-py&quot;&gt;가우스 혼합 모델 선택&lt;/a&gt; 참조고전 가우스 혼합으로 수행 된 모델 선택의 예는 을 .</target>
        </trans-unit>
        <trans-unit id="2675c64adf13cc79a9b07f8da3e0d3af0522fc69" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;Sample pipeline for text feature extraction and evaluation&lt;/a&gt; for an example of Grid Search coupling parameters from a text documents feature extractor (n-gram count vectorizer and TF-IDF transformer) with a classifier (here a linear SVM trained with SGD with either elastic net or L2 penalty) using a &lt;code&gt;pipeline.Pipeline&lt;/code&gt; instance.</source>
          <target state="translated">분류기 (여기서는 탄성 망이있는 SGD로 훈련 된 선형 SVM)의 텍스트 문서 기능 추출기 (n-gram count vectorizer 및 TF-IDF 변환기)의 그리드 검색 커플 링 매개 변수의 예는 &lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;텍스트 기능 추출 및 평가에&lt;/a&gt; 대한 샘플 파이프 라인을 참조 하십시오. 또는 L2 페널티)를 사용하여 &lt;code&gt;pipeline.Pipeline&lt;/code&gt; 인스턴스를 사용 합니다.</target>
        </trans-unit>
        <trans-unit id="da92f3b35d742326e0c71721384ca2aaccbfcbb6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_confusion_matrix#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py&quot;&gt;Confusion matrix&lt;/a&gt; for an example of using a confusion matrix to evaluate classifier output quality.</source>
          <target state="translated">분류기 출력 품질을 평가하기 위해 혼동 행렬을 사용하는 예는 &lt;a href=&quot;../auto_examples/model_selection/plot_confusion_matrix#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py&quot;&gt;혼동 행렬&lt;/a&gt; 을 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="de7b9e4f40b1dbfe2688a95ace15280b606fa175" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Parameter estimation using grid search with cross-validation&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.metrics.precision_score#sklearn.metrics.precision_score&quot;&gt;&lt;code&gt;precision_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.recall_score#sklearn.metrics.recall_score&quot;&gt;&lt;code&gt;recall_score&lt;/code&gt;&lt;/a&gt; usage to estimate parameters using grid search with nested cross-validation.</source>
          <target state="translated">nested cross-validation이있는 그리드 검색을 사용하여 매개 변수를 추정 하는 &lt;a href=&quot;generated/sklearn.metrics.precision_score#sklearn.metrics.precision_score&quot;&gt; &lt;code&gt;precision_score&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;generated/sklearn.metrics.recall_score#sklearn.metrics.recall_score&quot;&gt; &lt;code&gt;recall_score&lt;/code&gt; &lt;/a&gt; 사용법 의 예는 &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;cross-validation&lt;/a&gt; 이있는 그리드 검색을 사용한 매개 변수 추정을 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="907fb39fc7f1b14d7a7b9cc2b05542f6688793e4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Parameter estimation using grid search with cross-validation&lt;/a&gt; for an example of Grid Search computation on the digits dataset.</source>
          <target state="translated">자릿수 데이터 세트에 대한 그리드 검색 계산의 예는 &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;교차 검증&lt;/a&gt; 을 통한 그리드 검색을 사용한 모수 추정을 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="400cd83fcd5e25dceebfea56b549d5be061f5ba4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Parameter estimation using grid search with cross-validation&lt;/a&gt; for an example of classification report usage for grid search with nested cross-validation.</source>
          <target state="translated">중첩 된 교차 유효성 검사를 사용한 그리드 검색에 대한 분류 보고서 사용 예는 &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;교차 유효성 검사&lt;/a&gt; 를 사용한 그리드 검색을 사용한 모수 추정을 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="2735aad85c6c7c554984533b716de0827c908e17" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; being used to evaluate multiple metrics simultaneously.</source>
          <target state="translated">&lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;GridSearchCV&lt;/a&gt; 의 예는 &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt; 및 GridSearchCV에 대한 다중 메트릭 평가 데모를 참조하십시오.여러 메트릭을 동시에 평가하는 데 사용되는 .</target>
        </trans-unit>
        <trans-unit id="c2ffbe0f12938b51592ad9e927a7d22caaeca8af" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV&lt;/a&gt; for an example usage.</source>
          <target state="translated">사용법 예 &lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;는 cross_val_score 및 GridSearchCV에&lt;/a&gt; 대한 다중 메트릭 평가 데모를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="8476e4237a00d9dd8e2ca35734caeb2c23a0697e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_nested_cross_validation_iris#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py&quot;&gt;Nested versus non-nested cross-validation&lt;/a&gt; for an example of Grid Search within a cross validation loop on the iris dataset. This is the best practice for evaluating the performance of a model with grid search.</source>
          <target state="translated">홍채 데이터 세트의 교차 유효성 검사 루프 내에서 그리드 검색의 예는 &lt;a href=&quot;../auto_examples/model_selection/plot_nested_cross_validation_iris#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py&quot;&gt;중첩 된 교차 유효성 검사와 중첩되지 않은 교차 ​​유효성 검사&lt;/a&gt; 를 참조하십시오 . 그리드 검색을 사용하여 모델의 성능을 평가하는 가장 좋은 방법입니다.</target>
        </trans-unit>
        <trans-unit id="e8dfb2ba828b857661aeb6d59ff74f5c4db05d22" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_precision_recall#sphx-glr-auto-examples-model-selection-plot-precision-recall-py&quot;&gt;Precision-Recall&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt;&lt;code&gt;precision_recall_curve&lt;/code&gt;&lt;/a&gt; usage to evaluate classifier output quality.</source>
          <target state="translated">분류기 출력 품질을 평가하기위한 &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt; &lt;code&gt;precision_recall_curve&lt;/code&gt; &lt;/a&gt; 사용법 의 예는 &lt;a href=&quot;../auto_examples/model_selection/plot_precision_recall#sphx-glr-auto-examples-model-selection-plot-precision-recall-py&quot;&gt;Precision-Recall&lt;/a&gt; 을 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="7914d54070b906eba7716c438acf436730af131e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_roc#sphx-glr-auto-examples-model-selection-plot-roc-py&quot;&gt;Receiver Operating Characteristic (ROC)&lt;/a&gt; for an example of using ROC to evaluate the quality of the output of a classifier.</source>
          <target state="translated">참조 &lt;a href=&quot;../auto_examples/model_selection/plot_roc#sphx-glr-auto-examples-model-selection-plot-roc-py&quot;&gt;수신기 작동 특성 (ROC)&lt;/a&gt;ROC를 사용하여 분류기 출력의 품질을 평가하는 예는 을 .</target>
        </trans-unit>
        <trans-unit id="61240d29f349f145d4e8cf44909bfb9cc2f016b2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_roc_crossval#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py&quot;&gt;Receiver Operating Characteristic (ROC) with cross validation&lt;/a&gt; for an example of using ROC to evaluate classifier output quality, using cross-validation.</source>
          <target state="translated">&lt;a href=&quot;../auto_examples/model_selection/plot_roc_crossval#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py&quot;&gt;교차 유효성 검사&lt;/a&gt; 를 사용하여 분류기 출력 품질을 평가하기 위해 ROC를 사용하는 예는 교차 유효성 검사 가있는 ROC (수신기 동작 특성)를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="2194fe880eec73b4ed37b8700c0f77c050a462fc" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/neighbors/plot_lof_outlier_detection#sphx-glr-auto-examples-neighbors-plot-lof-outlier-detection-py&quot;&gt;Outlier detection with Local Outlier Factor (LOF)&lt;/a&gt; for an illustration of the use of &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">보기 &lt;a href=&quot;../auto_examples/neighbors/plot_lof_outlier_detection#sphx-glr-auto-examples-neighbors-plot-lof-outlier-detection-py&quot;&gt;지역 특이점 계수 (LOF)와 아웃 라이어 검출&lt;/a&gt; 의 사용의 그림은 &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="bb13fcb17f205551a70f65831a46478e0af0f276" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison of &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt; with &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt; (tuned to perform like an outlier detection method) and a covariance-based outlier detection with &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt;&lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">참조 &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;장난감 데이터 세트에서 아웃 라이어 검출 용 이상 검출 알고리즘을 비교&lt;/a&gt; 하는 비교 &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt; &lt;code&gt;ensemble.IsolationForest&lt;/code&gt; &lt;/a&gt; 와 &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;svm.OneClassSVM&lt;/code&gt; &lt;/a&gt; (특이점 검출 방법과 같이 수행하도록 조정)와 함께 공분산 기반의 아웃 라이어 검출 &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt; &lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="64196936345ba93c97149a5b0ef386464e9766b9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison of the &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt;, the &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt;, the &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt;&lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">참조 &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;장난감 데이터 세트에 이상치 검출 이상 탐지 알고리즘을 비교&lt;/a&gt; 의 비교에 대한 &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;svm.OneClassSVM&lt;/code&gt; &lt;/a&gt; 의 &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt; &lt;code&gt;ensemble.IsolationForest&lt;/code&gt; &lt;/a&gt; 의 &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt; &lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="34db9fa5546a4563c9e371d735571ffbe05f0c7c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison with other anomaly detection methods.</source>
          <target state="translated">다른 이상 탐지 방법과 비교하려면 &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;장난감 데이터 세트&lt;/a&gt; 에서 이상 치를 탐지하기 위해 이상 탐지 알고리즘 비교를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="624945e6b02bb2ff2c43f28f85ed4813c5cbe96d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_johnson_lindenstrauss_bound#sphx-glr-auto-examples-plot-johnson-lindenstrauss-bound-py&quot;&gt;The Johnson-Lindenstrauss bound for embedding with random projections&lt;/a&gt; for a theoretical explication on the Johnson-Lindenstrauss lemma and an empirical validation using sparse random matrices.</source>
          <target state="translated">Johnson-Lindenstrauss lemma에 대한 이론적 설명과 희소 난수 행렬을 사용한 경험적 검증에 대해서는 &lt;a href=&quot;../auto_examples/plot_johnson_lindenstrauss_bound#sphx-glr-auto-examples-plot-johnson-lindenstrauss-bound-py&quot;&gt;랜덤 프로젝션으로 임베드하는 Johnson-Lindenstrauss 바운드를&lt;/a&gt; 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="9ca7b8e34286a27914e5e700a286fbed9102f4af" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/svm/plot_oneclass#sphx-glr-auto-examples-svm-plot-oneclass-py&quot;&gt;One-class SVM with non-linear kernel (RBF)&lt;/a&gt; for visualizing the frontier learned around some data by a &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;svm.OneClassSVM&lt;/code&gt; &lt;/a&gt; 객체로 일부 데이터에 대해 학습 된 경계를 시각화하려면 &lt;a href=&quot;../auto_examples/svm/plot_oneclass#sphx-glr-auto-examples-svm-plot-oneclass-py&quot;&gt;비선형 커널 (RBF)이있는 1 클래스 SVM을&lt;/a&gt; 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="76c663b6a0471e4c53ba854f9c09becf8ef59fc7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Classification of text documents using sparse features&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt;&lt;code&gt;f1_score&lt;/code&gt;&lt;/a&gt; usage to classify text documents.</source>
          <target state="translated">&lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;텍스트 문서를 분류&lt;/a&gt; 하기위한 &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt; &lt;code&gt;f1_score&lt;/code&gt; &lt;/a&gt; 사용법 의 예는 스파 스 기능 을 사용하여 텍스트 문서 분류를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="188cc26ffe635b802535768a1802c77d30908617" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Classification of text documents using sparse features&lt;/a&gt; for an example of classification report usage for text documents.</source>
          <target state="translated">&lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;텍스트 문서&lt;/a&gt; 의 분류 보고서 사용 예는 스파 스 기능 을 사용하여 텍스트 문서 분류를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="19118774a723324b6225f3d83bcf9761f94d3619" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Classification of text documents using sparse features&lt;/a&gt; for an example of using a confusion matrix to classify text documents.</source>
          <target state="translated">혼동 행렬을 사용하여 텍스트 문서를 분류하는 예는 &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;스파 스 기능&lt;/a&gt; 을 사용하여 텍스트 문서 분류를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="81a2b2d1fb5035ca6b501c666e8a41c6286b60de" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../grid_search#multimetric-grid-search&quot;&gt;Specifying multiple metrics for evaluation&lt;/a&gt; for an example.</source>
          <target state="translated">예를 들어 &lt;a href=&quot;../grid_search#multimetric-grid-search&quot;&gt;평가할 여러 메트릭 지정을&lt;/a&gt; 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="479250f0ad90f3ce8d5fd16594b9c17af606dc2c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../neighbors#neighbors&quot;&gt;Nearest Neighbors&lt;/a&gt; in the online documentation for a discussion of the choice of &lt;code&gt;algorithm&lt;/code&gt; and &lt;code&gt;leaf_size&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;algorithm&lt;/code&gt; 및 &lt;code&gt;leaf_size&lt;/code&gt; 선택에 대한 설명은 온라인 문서에서 &lt;a href=&quot;../neighbors#neighbors&quot;&gt;가장 가까운 이웃&lt;/a&gt; 을 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="91032a83e07b0024745974d4bc72e492c7c9e85a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;compose#combining-estimators&quot;&gt;Pipelines and composite estimators&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;compose#combining-estimators&quot;&gt;파이프 라인 및 복합 추정기를&lt;/a&gt; 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="516b0abd274bf0e8eb7951cfd8d017257e70560d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;feature_extraction#dict-feature-extraction&quot;&gt;Loading features from dicts&lt;/a&gt; for categorical features that are represented as a dict, not as scalars.</source>
          <target state="translated">스칼라가 아닌 dict로 표시되는 범주 형 기능에 대해서는 &lt;a href=&quot;feature_extraction#dict-feature-extraction&quot;&gt;dicts에서 기능로드를&lt;/a&gt; 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="5f5bdda151c122a6b0f331c022a3fe3419eba6e8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits&quot;&gt;here&lt;/a&gt; for more information about this dataset.</source>
          <target state="translated">이 데이터 세트에 대한 자세한 내용은 &lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits&quot;&gt;여기&lt;/a&gt; 를 참조 하십시오 .</target>
        </trans-unit>
        <trans-unit id="59cc7550d6ebef4a36dc7cbd048f831a5c0d0f3a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&quot;&gt;http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&quot;&gt;http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf를&lt;/a&gt; 참조 하십시오</target>
        </trans-unit>
        <trans-unit id="58869cd4ecac8051c9d79dfaa9dbb2a543b85dfe" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;http://www.robots.ox.ac.uk/~vedaldi/assets/pubs/vedaldi11efficient.pdf&quot;&gt;&amp;ldquo;Efficient additive kernels via explicit feature maps&amp;rdquo;&lt;/a&gt; A. Vedaldi and A. Zisserman, Pattern Analysis and Machine Intelligence, 2011</source>
          <target state="translated">&lt;a href=&quot;http://www.robots.ox.ac.uk/~vedaldi/assets/pubs/vedaldi11efficient.pdf&quot;&gt;&quot;명확한 기능 맵을 통한 효율적인 추가 커널&quot;&lt;/a&gt; 참조 A. Vedaldi 및 A. Zisserman, 패턴 분석 및 머신 인텔리전스, 2011</target>
        </trans-unit>
        <trans-unit id="4bdca7573215dd8d9f679d272cb9da9a534f1291" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;here&lt;/a&gt; for more information on this dataset.</source>
          <target state="translated">이 데이터 세트에 대한 자세한 내용 은 &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;여기&lt;/a&gt; 를 참조 하십시오 .</target>
        </trans-unit>
        <trans-unit id="7191cbc48e1c8b07d612d6ecdb398fe05677ce16" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;The scoring parameter: defining model evaluation rules&lt;/a&gt; for details. In the case of the Iris dataset, the samples are balanced across target classes hence the accuracy and the F1-score are almost equal.</source>
          <target state="translated">자세한 내용 &lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;은 스코어링 매개 변수 : 모델 평가 규칙 정의&lt;/a&gt; 를 참조하십시오. Iris 데이터 세트의 경우, 샘플은 대상 클래스에 걸쳐 균형을 유지하므로 정확도와 F1- 점수가 거의 동일합니다.</target>
        </trans-unit>
        <trans-unit id="e083d29e5fc318a8e4c7186d224d71159333e317" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;outlier_detection#outlier-detection&quot;&gt;Novelty and Outlier Detection&lt;/a&gt; for the description and usage of OneClassSVM.</source>
          <target state="translated">&lt;a href=&quot;outlier_detection#outlier-detection&quot;&gt;OneClassSVM&lt;/a&gt; 의 설명 및 사용법은 참신 및 이상 값 탐지 를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="2bf27f073ae6fdc435309a3de7aa195bb3e33f73" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;predict_proba&lt;/code&gt; for details.</source>
          <target state="translated">자세한 내용은 &lt;code&gt;predict_proba&lt;/code&gt; 를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="9a6c19ee072204bfa0caf7b0899caf92ad1a79e0" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;refit&lt;/code&gt; parameter for more information on allowed values.</source>
          <target state="translated">허용되는 값에 대한 자세한 정보는 &lt;code&gt;refit&lt;/code&gt; 매개 변수를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="fcd84460747232330056c00c1a39fd6ed47410b5" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;scoring&lt;/code&gt; parameter to know more about multiple metric evaluation.</source>
          <target state="translated">다중 메트릭 평가에 대한 자세한 내용은 &lt;code&gt;scoring&lt;/code&gt; 매개 변수를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="61a08f389a25b863d0fca5015a2885ff6fd5c8cd" translate="yes" xml:space="preserve">
          <source>See Also:</source>
          <target state="translated">또한보십시오:</target>
        </trans-unit>
        <trans-unit id="dd75486b56d3a12e77b37b7ce59de88eb8618b01" translate="yes" xml:space="preserve">
          <source>See Rasmussen and Williams 2006, pp84 for details regarding the different variants of the Matern kernel.</source>
          <target state="translated">Matern 커널의 다양한 변형에 대한 자세한 내용은 Rasmussen 및 Williams 2006, pp84를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="2d8243a2c0e464492c9d563c4f92c56ae3421bcc" translate="yes" xml:space="preserve">
          <source>See also</source>
          <target state="translated">또한보십시오</target>
        </trans-unit>
        <trans-unit id="00556fb4b47eda5d6ddfa3723da8312c58733ada" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;Recursive feature elimination with cross-validation&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;교차 검증을 통한 재귀 기능 제거&lt;/a&gt; 참조</target>
        </trans-unit>
        <trans-unit id="371a87eafb4de078ff674d69a5a89c186532eb49" translate="yes" xml:space="preserve">
          <source>See also:</source>
          <target state="translated">또한보십시오:</target>
        </trans-unit>
        <trans-unit id="bbbf1c8bb1bb44153dbb121ba5ff682161041559" translate="yes" xml:space="preserve">
          <source>See also: 1988 MLC Proceedings, 54-64. Cheeseman et al&amp;rdquo;s AUTOCLASS II conceptual clustering system finds 3 classes in the data.</source>
          <target state="translated">참조 : 1988 MLC Proceedings, 54-64 Cheeseman 등의 AUTOCLASS II 개념 클러스터링 시스템은 데이터에서 3 개의 클래스를 찾습니다.</target>
        </trans-unit>
        <trans-unit id="6b55a2c7dcbc914b3c4abb672c6103792d08facf" translate="yes" xml:space="preserve">
          <source>See sklearn.svm.predict for a complete list of parameters.</source>
          <target state="translated">전체 매개 변수 목록은 sklearn.svm.predict를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="8c30624bfa9869c6a4a63a1b052f17576abbc1b5" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;../../auto_examples/applications/svm_gui#sphx-glr-auto-examples-applications-svm-gui-py&quot;&gt;SVM GUI&lt;/a&gt; to download &lt;code&gt;svm_gui.py&lt;/code&gt;; add data points of both classes with right and left button, fit the model and change parameters and data.</source>
          <target state="translated">&lt;code&gt;svm_gui.py&lt;/code&gt; 를 다운로드 하려면 &lt;a href=&quot;../../auto_examples/applications/svm_gui#sphx-glr-auto-examples-applications-svm-gui-py&quot;&gt;SVM GUI&lt;/a&gt; 를 참조하십시오 . 오른쪽과 왼쪽 버튼으로 두 클래스의 데이터 포인트를 추가하고, 모델을 맞추고 매개 변수와 데이터를 변경하십시오.</target>
        </trans-unit>
        <trans-unit id="3a7904b44fb635dd1b8e25248a204eaa4fae3a1b" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;biclustering#biclustering-evaluation&quot;&gt;Biclustering evaluation&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">자세한 내용은 사용 설명서 의 &lt;a href=&quot;biclustering#biclustering-evaluation&quot;&gt;Biclustering 평가&lt;/a&gt; 섹션을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="68bd165827c5ef6d955b9032ff7e059af8a91538" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;clustering#clustering-evaluation&quot;&gt;Clustering performance evaluation&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">자세한 내용은 사용 설명서 의 &lt;a href=&quot;clustering#clustering-evaluation&quot;&gt;클러스터링 성능 평가&lt;/a&gt; 섹션을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="8dd9c0a0a464abab54cd5ae3d828ecf303587e8d" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">자세한 내용은 사용자 안내서 의 &lt;a href=&quot;metrics#metrics&quot;&gt;쌍별 메트릭, 선호도 및 커널&lt;/a&gt; 섹션을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="a5b49cc34cb79ec02e159e95ecb887eb0b2cb87b" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#classification-metrics&quot;&gt;Classification metrics&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">자세한 내용은 사용자 안내서 의 &lt;a href=&quot;model_evaluation#classification-metrics&quot;&gt;분류 지표&lt;/a&gt; 섹션을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="9391e01adcbcd6eab5489ba5c5bbde2b34c1c767" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;Model evaluation: quantifying the quality of predictions&lt;/a&gt; section and the &lt;a href=&quot;metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">자세한 내용은 &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;모델 평가 : 예측 품질 수량화&lt;/a&gt; 섹션 및 사용자 안내서 의 &lt;a href=&quot;metrics#metrics&quot;&gt;쌍별 메트릭, 친화도 및 커널&lt;/a&gt; 섹션을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="794b0f5d5def59a318bd787a4fccdd542a21003c" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#multilabel-ranking-metrics&quot;&gt;Multilabel ranking metrics&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">자세한 내용은 사용 설명서 의 &lt;a href=&quot;model_evaluation#multilabel-ranking-metrics&quot;&gt;다중 레이블 순위 메트릭&lt;/a&gt; 섹션을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="2e87795fde7a0f4562bca5bb85f3c7f5918727b2" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#regression-metrics&quot;&gt;Regression metrics&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">자세한 내용은 사용자 안내서 의 &lt;a href=&quot;model_evaluation#regression-metrics&quot;&gt;회귀 메트릭&lt;/a&gt; 섹션을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="e8449bc2e3e9fd1500a092c7a467f1094a642fdf" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;The scoring parameter: defining model evaluation rules&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">자세한 내용은 사용자 안내서 &lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;의 스코어링 매개 변수 : 모델 평가 규칙 정의&lt;/a&gt; 섹션을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="bc10a00d51f81094bb499f5ba451c68f15309214" translate="yes" xml:space="preserve">
          <source>See the console&amp;rsquo;s output for further details about each model.</source>
          <target state="translated">각 모델에 대한 자세한 내용은 콘솔 출력을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="cd81e4d9092f6289f9eb153c5b671f6c9ec59b00" translate="yes" xml:space="preserve">
          <source>See the docstring of DistanceMetric for a list of available metrics.</source>
          <target state="translated">사용 가능한 메트릭 목록은 DistanceMetric의 문서 문자열을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="bf132d2b0dc3be6b88274385f87b0ee3f849742c" translate="yes" xml:space="preserve">
          <source>See the documentation for scipy.spatial.distance for details on these metrics.</source>
          <target state="translated">이러한 메트릭에 대한 자세한 내용은 scipy.spatial.distance 설명서를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="7af63b893a630b06c001dfe05c36e8144bafc593" translate="yes" xml:space="preserve">
          <source>See the documentation for scipy.spatial.distance for details on these metrics: &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/spatial.distance.html&quot;&gt;http://docs.scipy.org/doc/scipy/reference/spatial.distance.html&lt;/a&gt;</source>
          <target state="translated">이러한 메트릭에 대한 자세한 내용은 scipy.spatial.distance 설명서를 참조하십시오. &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/spatial.distance.html&quot;&gt;http://docs.scipy.org/doc/scipy/reference/spatial.distance.html&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c235949c8aa0b531ecb9dfa56db515940237097e" translate="yes" xml:space="preserve">
          <source>See the examples below and the doc string of &lt;a href=&quot;generated/sklearn.neural_network.mlpclassifier#sklearn.neural_network.MLPClassifier.fit&quot;&gt;&lt;code&gt;MLPClassifier.fit&lt;/code&gt;&lt;/a&gt; for further information.</source>
          <target state="translated">자세한 정보는 아래 예제 및 &lt;a href=&quot;generated/sklearn.neural_network.mlpclassifier#sklearn.neural_network.MLPClassifier.fit&quot;&gt; &lt;code&gt;MLPClassifier.fit&lt;/code&gt; &lt;/a&gt; 의 doc 문자열을 참조 하십시오.</target>
        </trans-unit>
        <trans-unit id="0f593defdf84cd9d54340a0b9eb8bdbba2164c5f" translate="yes" xml:space="preserve">
          <source>See the examples below for further information.</source>
          <target state="translated">자세한 내용은 아래 예를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="43e09506578d0fedfc6592860be1e23c1f8ef43b" translate="yes" xml:space="preserve">
          <source>See the examples for such an application.</source>
          <target state="translated">이러한 응용 프로그램의 예를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="e8c17521507d95b1954b9918e527f968af48b835" translate="yes" xml:space="preserve">
          <source>See. &amp;ldquo;Pattern Recognition and Machine Learning&amp;rdquo; by C. Bishop, 12.2.1 p. 574 or &lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdf&lt;/a&gt;</source>
          <target state="translated">보다. C. Bishop의&amp;ldquo;패턴 인식 및 기계 학습&amp;rdquo;, 12.2.1 p. 574 또는 &lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e4871111c8505b7690af20e518e753ae1b90a5ad" translate="yes" xml:space="preserve">
          <source>Seed for the random number generator used for probability estimates. 0 by default.</source>
          <target state="translated">확률 추정에 사용되는 난수 생성기의 시드입니다. 기본적으로 0입니다.</target>
        </trans-unit>
        <trans-unit id="72c84d205a7667dfdb05c6ebaaf98f08a838df92" translate="yes" xml:space="preserve">
          <source>Seeding is performed using a binning technique for scalability.</source>
          <target state="translated">시딩은 확장 성을 위해 비닝 기술을 사용하여 수행됩니다.</target>
        </trans-unit>
        <trans-unit id="f1f3844996349c701e3db8be5a62a8ace310a543" translate="yes" xml:space="preserve">
          <source>Seeds used to initialize kernels. If not set, the seeds are calculated by clustering.get_bin_seeds with bandwidth as the grid size and default values for other parameters.</source>
          <target state="translated">커널을 초기화하는 데 사용되는 씨앗. 설정되지 않은 경우 시드는 그리드 크기 및 다른 매개 변수의 기본값으로 대역폭을 사용하여 clustering.get_bin_seeds에 의해 계산됩니다.</target>
        </trans-unit>
        <trans-unit id="1a053c7e782c53a91d6d509bf6a99224f4b893d2" translate="yes" xml:space="preserve">
          <source>Segmenting the picture of greek coins in regions</source>
          <target state="translated">지역에서 그리스 동전 그림 세분화</target>
        </trans-unit>
        <trans-unit id="05c2c519388dfeab1d2da32ad0c3a55d08148aed" translate="yes" xml:space="preserve">
          <source>Select &lt;code&gt;min_samples&lt;/code&gt; random samples from the original data and check whether the set of data is valid (see &lt;code&gt;is_data_valid&lt;/code&gt;).</source>
          <target state="translated">원본 데이터에서 임의의 샘플을 &lt;code&gt;min_samples&lt;/code&gt; 선택 하고 데이터 세트가 유효한지 확인하십시오 ( &lt;code&gt;is_data_valid&lt;/code&gt; 참조 ).</target>
        </trans-unit>
        <trans-unit id="4c8220c40092a5223a7519a4053e419620df4d58" translate="yes" xml:space="preserve">
          <source>Select eigensolver to use. If n_components is much less than the number of training samples, arpack may be more efficient than the dense eigensolver.</source>
          <target state="translated">사용할 고유 해석기를 선택하십시오. n_components가 학습 샘플 수보다 훨씬 적은 경우 arpack은 밀도가 높은 고유 솔버보다 더 효율적일 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="a8b26e8dd8c57424e2a0ff5f2b02e8bbc7be69eb" translate="yes" xml:space="preserve">
          <source>Select features according to a percentile of the highest scores.</source>
          <target state="translated">최고 점수의 백분위 수에 따라 기능을 선택하십시오.</target>
        </trans-unit>
        <trans-unit id="d20a85a468318484f73da066702f203468ec7eb5" translate="yes" xml:space="preserve">
          <source>Select features according to the k highest scores.</source>
          <target state="translated">k 개의 최고 점수에 따라 기능을 선택하십시오.</target>
        </trans-unit>
        <trans-unit id="c3952e3b9f6e5571ab9a9f69665172397cc254d2" translate="yes" xml:space="preserve">
          <source>Select features based on a false positive rate test.</source>
          <target state="translated">오 탐지 테스트를 기반으로 기능을 선택하십시오.</target>
        </trans-unit>
        <trans-unit id="32515d7cef117ccce44afc2f4f0b98f43d0db807" translate="yes" xml:space="preserve">
          <source>Select features based on an estimated false discovery rate.</source>
          <target state="translated">추정 된 오 탐지 비율에 따라 기능을 선택하십시오.</target>
        </trans-unit>
        <trans-unit id="6d7a0df88fc316c1f019dac960b65ab544487a37" translate="yes" xml:space="preserve">
          <source>Select features based on family-wise error rate.</source>
          <target state="translated">가족 별 오류율에 따라 기능을 선택하십시오.</target>
        </trans-unit>
        <trans-unit id="ba417981f6009fc06cd3596ff9c6cb4c2bd25319" translate="yes" xml:space="preserve">
          <source>Select features based on percentile of the highest scores.</source>
          <target state="translated">최고 점수의 백분위 수를 기준으로 기능을 선택하십시오.</target>
        </trans-unit>
        <trans-unit id="3532493330a0445601f2381a89fe492b8458f964" translate="yes" xml:space="preserve">
          <source>Select features based on the k highest scores.</source>
          <target state="translated">k 개의 최고 점수를 기준으로 기능을 선택하십시오.</target>
        </trans-unit>
        <trans-unit id="fc6cce4211d0c67d4111ac2f86243aa83948ed07" translate="yes" xml:space="preserve">
          <source>Select n_samples integers from the set [0, n_population) without replacement.</source>
          <target state="translated">교체없이 세트 [0, n_population)에서 n_samples 정수를 선택하십시오.</target>
        </trans-unit>
        <trans-unit id="e693da3619bc133d154aaf34e091d4f9f76e8468" translate="yes" xml:space="preserve">
          <source>Select the algorithm to either solve the dual or primal optimization problem. Prefer dual=False when n_samples &amp;gt; n_features.</source>
          <target state="translated">알고리즘을 선택하여 이중 또는 원시 최적화 문제를 해결하십시오. n_samples&amp;gt; n_features 인 경우 dual = False를 선호하십시오.</target>
        </trans-unit>
        <trans-unit id="e09f39accd13c28376a1ebc78d546869197bec0f" translate="yes" xml:space="preserve">
          <source>Select the dataset to load: &amp;lsquo;train&amp;rsquo; for the development training set, &amp;lsquo;test&amp;rsquo; for the development test set, and &amp;lsquo;10_folds&amp;rsquo; for the official evaluation set that is meant to be used with a 10-folds cross validation.</source>
          <target state="translated">로드 할 데이터 세트를 선택하십시오 (개발 훈련 세트의 경우 'train', 개발 테스트 세트의 경우 'test', 10 배 교차 검증에 사용되는 공식 평가 세트의 경우 '10_folds').</target>
        </trans-unit>
        <trans-unit id="da5a2fc4086f03333558c16d8aba6a6ba8f98164" translate="yes" xml:space="preserve">
          <source>Select the dataset to load: &amp;lsquo;train&amp;rsquo; for the training set (23149 samples), &amp;lsquo;test&amp;rsquo; for the test set (781265 samples), &amp;lsquo;all&amp;rsquo; for both, with the training samples first if shuffle is False. This follows the official LYRL2004 chronological split.</source>
          <target state="translated">셔플이 False 인 경우 먼저 훈련 샘플을 사용하여 훈련 세트 (23149 샘플)에 대한 'train', 테스트 세트 (781265 샘플)에 대한 'test', 둘 모두에 대해 'all'을로드 할 데이터 세트를 선택합니다. 이것은 공식 LYRL2004 시간 분할을 따릅니다.</target>
        </trans-unit>
        <trans-unit id="a373737a4d85a4134f237dcaa76f506d35776152" translate="yes" xml:space="preserve">
          <source>Select the dataset to load: &amp;lsquo;train&amp;rsquo; for the training set, &amp;lsquo;test&amp;rsquo; for the test set, &amp;lsquo;all&amp;rsquo; for both, with shuffled ordering.</source>
          <target state="translated">로드 할 데이터 세트를 선택하십시오 (훈련 세트의 경우 'train', 테스트 세트의 경우 'test', 둘 다의 경우 'all').</target>
        </trans-unit>
        <trans-unit id="c5f861c6085a651c0ed9619f5012b02bb9a2d195" translate="yes" xml:space="preserve">
          <source>Select the parameters that minimises the impurity</source>
          <target state="translated">불순물을 최소화하는 파라미터를 선택하십시오</target>
        </trans-unit>
        <trans-unit id="776d7f86c8363c5c583ee4e086a4256b8464f6f6" translate="yes" xml:space="preserve">
          <source>Select the portion to load: &amp;lsquo;train&amp;rsquo;, &amp;lsquo;test&amp;rsquo; or &amp;lsquo;raw&amp;rsquo;</source>
          <target state="translated">로드 할 부분을 선택하십시오 : 'train', 'test'또는 'raw'</target>
        </trans-unit>
        <trans-unit id="09caeaab6645f9fa60776419a39bd350760c6b9f" translate="yes" xml:space="preserve">
          <source>Selecting &lt;code&gt;average=None&lt;/code&gt; will return an array with the score for each class.</source>
          <target state="translated">&lt;code&gt;average=None&lt;/code&gt; 을 선택하면 각 클래스의 점수가 포함 된 배열이 반환됩니다.</target>
        </trans-unit>
        <trans-unit id="09987abb5cb6e00639cc8ad149fcfc0ee4e216e7" translate="yes" xml:space="preserve">
          <source>Selecting dimensionality reduction with Pipeline and GridSearchCV</source>
          <target state="translated">파이프 라인 및 GridSearchCV를 사용하여 차원 축소 선택</target>
        </trans-unit>
        <trans-unit id="b619a7e9444390b8df9ed15ee53211d47286dc3c" translate="yes" xml:space="preserve">
          <source>Selecting the number of clusters with silhouette analysis on KMeans clustering</source>
          <target state="translated">KMeans 클러스터링에서 실루엣 분석으로 클러스터 수 선택</target>
        </trans-unit>
        <trans-unit id="1e3a867140ee60f287b6c8b807e610aee224839f" translate="yes" xml:space="preserve">
          <source>Selects the algorithm for finding singular vectors. May be &amp;lsquo;randomized&amp;rsquo; or &amp;lsquo;arpack&amp;rsquo;. If &amp;lsquo;randomized&amp;rsquo;, use &lt;a href=&quot;sklearn.utils.extmath.randomized_svd#sklearn.utils.extmath.randomized_svd&quot;&gt;&lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt;&lt;/a&gt;, which may be faster for large matrices. If &amp;lsquo;arpack&amp;rsquo;, use &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html#scipy.sparse.linalg.svds&quot;&gt;&lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt;&lt;/a&gt;, which is more accurate, but possibly slower in some cases.</source>
          <target state="translated">특이 벡터를 찾기위한 알고리즘을 선택합니다. '무작위 화'또는 'arpack'일 수 있습니다. '랜덤 화'인 경우 &lt;a href=&quot;sklearn.utils.extmath.randomized_svd#sklearn.utils.extmath.randomized_svd&quot;&gt; &lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt; 를&lt;/a&gt; 사용 하십시오 . 큰 행렬의 경우 더 빠를 수 있습니다. 'arpack'인 경우 &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html#scipy.sparse.linalg.svds&quot;&gt; &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt; 를&lt;/a&gt; 사용하십시오. 보다 정확하지만 경우에 따라 속도가 느려질 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="ba0796ade5894bc55073846864af8524b40634d7" translate="yes" xml:space="preserve">
          <source>Selects the algorithm for finding singular vectors. May be &amp;lsquo;randomized&amp;rsquo; or &amp;lsquo;arpack&amp;rsquo;. If &amp;lsquo;randomized&amp;rsquo;, uses &lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt;, which may be faster for large matrices. If &amp;lsquo;arpack&amp;rsquo;, uses &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt;, which is more accurate, but possibly slower in some cases.</source>
          <target state="translated">특이 벡터를 찾기위한 알고리즘을 선택합니다. '무작위 화'또는 'arpack'일 수 있습니다. '랜덤 화'인 경우 &lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt; 를 사용 하면 큰 행렬의 경우 더 빠를 수 있습니다. 'arpack'인 경우 &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt; 를 사용하면 보다 정확하지만 경우에 따라 속도가 느려질 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="0c634aac4fba33953abfb672747b23d137a6eb94" translate="yes" xml:space="preserve">
          <source>Sepal length</source>
          <target state="translated">분리 길이</target>
        </trans-unit>
        <trans-unit id="fb329e5a4491aa43414f15d76bffc8963ea0de09" translate="yes" xml:space="preserve">
          <source>Sepal width</source>
          <target state="translated">분리 폭</target>
        </trans-unit>
        <trans-unit id="e5dddf892a3efc8978d095e912cc4306a1e49804" translate="yes" xml:space="preserve">
          <source>Separating inliers from outliers using a Mahalanobis distance</source>
          <target state="translated">Mahalanobis 거리를 사용하여 특이 치에서 특이 치 분리</target>
        </trans-unit>
        <trans-unit id="aece656a00e1c7a3f193615a59fc1f63e6e58693" translate="yes" xml:space="preserve">
          <source>Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, &amp;ldquo;Decision Tree Construction Via Linear Programming.&amp;rdquo; Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.</source>
          <target state="translated">전술 한 분리 평면은 다중 표면 방법-트리 (MSM-T) [KP Bennett, &quot;선형 프로그래밍을 통한 의사 결정 트리 구성&quot;을 사용하여 얻어졌다. 4 차 중서부 인공 지능 및인지 과학 협회의 절차, pp. 97-101, 1992], 선형 프로그래밍을 사용하여 의사 결정 트리를 구성하는 분류 방법. 1-4 개의 피쳐와 1-3 개의 분리 평면에서 철저한 검색을 사용하여 관련 피쳐를 선택했습니다.</target>
        </trans-unit>
        <trans-unit id="749810666e6448d7103b8c1ba2bbfef3e451d983" translate="yes" xml:space="preserve">
          <source>Separator string used when constructing new features for one-hot coding.</source>
          <target state="translated">one-hot coding을위한 새로운 기능을 구성 할 때 사용되는 구분자 문자열입니다.</target>
        </trans-unit>
        <trans-unit id="70aafd2a89678b32332fcfe0ff93efd39c5a3c06" translate="yes" xml:space="preserve">
          <source>Sequence of integer labels or multilabel data to encode.</source>
          <target state="translated">인코딩 할 정수 레이블 또는 다중 레이블 데이터 시퀀스.</target>
        </trans-unit>
        <trans-unit id="63145e1c892f5c29b2a500cdc3f15222c0784b14" translate="yes" xml:space="preserve">
          <source>Sequence of resampled copies of the collections. The original arrays are not impacted.</source>
          <target state="translated">컬렉션의 재 샘플링 된 사본 시퀀스. 원래 배열에는 영향을 미치지 않습니다.</target>
        </trans-unit>
        <trans-unit id="22f488ee4fca141470b8e2b188abe2e7275b3dc0" translate="yes" xml:space="preserve">
          <source>Sequence of shuffled copies of the collections. The original arrays are not impacted.</source>
          <target state="translated">컬렉션의 셔플 사본 순서. 원래 배열에는 영향을 미치지 않습니다.</target>
        </trans-unit>
        <trans-unit id="05f31ec9564cc0e3d1b047a8eba0a9e234d2f0b3" translate="yes" xml:space="preserve">
          <source>Sequence of weights (&lt;code&gt;float&lt;/code&gt; or &lt;code&gt;int&lt;/code&gt;) to weight the occurrences of predicted class labels (&lt;code&gt;hard&lt;/code&gt; voting) or class probabilities before averaging (&lt;code&gt;soft&lt;/code&gt; voting). Uses uniform weights if &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">무게 (시퀀스 &lt;code&gt;float&lt;/code&gt; 또는 &lt;code&gt;int&lt;/code&gt; ) 예측 클래스 레이블 (의 발생 무게 &lt;code&gt;hard&lt;/code&gt; 평균 (전 투표) 또는 클래스 확률 &lt;code&gt;soft&lt;/code&gt; 투표). &lt;code&gt;None&lt;/code&gt; 이면 균일 한 가중치를 사용합니다 .</target>
        </trans-unit>
        <trans-unit id="0ea6d0fbbfa7ff1125b3f0dc0d1f0f204d3b725f" translate="yes" xml:space="preserve">
          <source>Sequentially apply a list of transforms and a final estimator. Intermediate steps of the pipeline must be &amp;lsquo;transforms&amp;rsquo;, that is, they must implement fit and transform methods. The final estimator only needs to implement fit. The transformers in the pipeline can be cached using &lt;code&gt;memory&lt;/code&gt; argument.</source>
          <target state="translated">변환 목록과 최종 추정기를 순차적으로 적용하십시오. 파이프 라인의 중간 단계는 '변환'이어야합니다. 즉, 적합 및 변환 방법을 구현해야합니다. 최종 추정기는 적합을 구현하기 만하면됩니다. 파이프 라인의 변환기는 &lt;code&gt;memory&lt;/code&gt; 인수를 사용하여 캐시 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="5d912fff074ca31c7c82b5fde02f4d9656aba0e0" translate="yes" xml:space="preserve">
          <source>Set &lt;code&gt;kernel='precomputed'&lt;/code&gt; and pass the Gram matrix instead of X in the fit method. At the moment, the kernel values between &lt;em&gt;all&lt;/em&gt; training vectors and the test vectors must be provided.</source>
          <target state="translated">&lt;code&gt;kernel='precomputed'&lt;/code&gt; 설정 하고 fit 메소드에서 X 대신 Gram 행렬을 전달하십시오. 현재 &lt;em&gt;모든&lt;/em&gt; 훈련 벡터와 테스트 벡터 사이의 커널 값을 제공해야합니다.</target>
        </trans-unit>
        <trans-unit id="82c89924e3ff5aee8a7d762157ebec36e4bfb77e" translate="yes" xml:space="preserve">
          <source>Set &lt;code&gt;n_clusters&lt;/code&gt; to a required value using &lt;code&gt;brc.set_params(n_clusters=n_clusters)&lt;/code&gt;.</source>
          <target state="translated">집합 &lt;code&gt;n_clusters&lt;/code&gt; 하여 필요한 값 &lt;code&gt;brc.set_params(n_clusters=n_clusters)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="baf739c6d3f3081a673c9a62345f43337d9146af" translate="yes" xml:space="preserve">
          <source>Set an initial start configuration, randomly or not.</source>
          <target state="translated">초기 시작 구성을 임의로 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="7115214e952526d911c94e2c07be9533a4c1bc42" translate="yes" xml:space="preserve">
          <source>Set global scikit-learn configuration</source>
          <target state="translated">전역 scikit-learn 구성 설정</target>
        </trans-unit>
        <trans-unit id="d973ce66011b9fa67c29ae92b31d59e39ce28a97" translate="yes" xml:space="preserve">
          <source>Set of samples, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">샘플 세트. 여기서 n_samples는 샘플 수이고 n_features는 피처 수입니다.</target>
        </trans-unit>
        <trans-unit id="859e800d4c0c95faf85e59d644290b4f9223483a" translate="yes" xml:space="preserve">
          <source>Set the parameter C of class i to &lt;code&gt;class_weight[i]*C&lt;/code&gt; for SVC. If not given, all classes are supposed to have weight one. The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</source>
          <target state="translated">SVC 의 경우 클래스 i의 매개 변수 C를 &lt;code&gt;class_weight[i]*C&lt;/code&gt; 로 설정하십시오. 주어지지 않으면 모든 수업은 1을가집니다. &quot;balanced&quot;모드는 y 값을 사용하여 입력 데이터의 클래스 주파수에 반비례하는 가중치를 &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt; 로 자동 조정합니다.</target>
        </trans-unit>
        <trans-unit id="68197d507e5463b3337bc09b3b9761d9525e528a" translate="yes" xml:space="preserve">
          <source>Set the parameter C of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</source>
          <target state="translated">SVC의 경우 클래스 i의 매개 변수 C를 class_weight [i] * C로 설정하십시오. 주어지지 않으면 모든 수업은 1을가집니다. &amp;ldquo;balanced&amp;rdquo;모드는 y의 값을 사용하여 클래스 주파수에 반비례하는 가중치를 &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt; 로 자동 조정합니다.</target>
        </trans-unit>
        <trans-unit id="7ee0e3c771d52a3f4b21637b50de4b2fa144cadb" translate="yes" xml:space="preserve">
          <source>Set the parameter C of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</source>
          <target state="translated">SVC의 경우 클래스 i의 매개 변수 C를 class_weight [i] * C로 설정하십시오. 주어지지 않으면 모든 수업은 1을가집니다. &quot;balanced&quot;모드는 y 값을 사용하여 입력 데이터의 클래스 주파수에 반비례하는 가중치를 &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt; 로 자동 조정합니다.</target>
        </trans-unit>
        <trans-unit id="02c4dadc552ae2f0292cf77b2c6f20b9175838e2" translate="yes" xml:space="preserve">
          <source>Set the parameters</source>
          <target state="translated">파라미터 설정</target>
        </trans-unit>
        <trans-unit id="72f87d2d27b1f0c322a530ad0dc9b59597d7be5b" translate="yes" xml:space="preserve">
          <source>Set the parameters of this estimator.</source>
          <target state="translated">이 추정기의 매개 변수를 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="57d60e82b45349e99163b5cb25f5c26dc09997fb" translate="yes" xml:space="preserve">
          <source>Set the parameters of this kernel.</source>
          <target state="translated">이 커널의 매개 변수를 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="e51dac5748f92b9a4d95a295db13667c4d900b8f" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace computation during transformation.</source>
          <target state="translated">변환 중에 인플레 이스 계산을 수행하려면 False로 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="c9e442dcb8465293c9e9b1ca26f1df573cbc8a5b" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace computation.</source>
          <target state="translated">전체 계산을 수행하려면 False로 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="66ebe619c3b8004252e57f6a28ff4945f1da8024" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace row normalization and avoid a copy (if the input is already a numpy array).</source>
          <target state="translated">인플레 이스 행 정규화를 수행하고 복사를 피하려면 (입력이 이미 numpy 배열 인 경우) False로 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="00972eb158db00f5dae23773f938b4091d65b472" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace scaling and avoid a copy (if the input is already a numpy array).</source>
          <target state="translated">인플레 이스 스케일링을 수행하고 복사를 피하려면 (입력이 이미 numpy 배열 인 경우) False로 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="08f65c010729649e9d6102eb99a0ed3b76fe0859" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace transformation and avoid a copy (if the input is already a numpy array).</source>
          <target state="translated">인플레 이스 변환을 수행하고 복사를 피하려면 (입력이 이미 numpy 배열 인 경우) False로 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="70773d7b4f76452047259ed8e2e9af7169f13fc0" translate="yes" xml:space="preserve">
          <source>Set to True to apply zero-mean, unit-variance normalization to the transformed output.</source>
          <target state="translated">변환 된 출력에 제로 평균 단위 분산 정규화를 적용하려면 True로 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="a7d505eb35ec97e19208554a83f21f5336e3915d" translate="yes" xml:space="preserve">
          <source>Set to true if output binary array is desired in CSR sparse format</source>
          <target state="translated">CSR 스파 스 형식으로 출력 이진 배열을 원하는 경우 true로 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="e9779b7ab3cf4b478b4bfa7669bfc4f6492ae2ea" translate="yes" xml:space="preserve">
          <source>Sets the default value for the &lt;code&gt;assume_finite&lt;/code&gt; argument of &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">의 기본값으로 설정 &lt;code&gt;assume_finite&lt;/code&gt; 의 인수 &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;sklearn.set_config&lt;/code&gt; 을&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2047224d21bf76be06bd841e22b2f6efe81f5987" translate="yes" xml:space="preserve">
          <source>Sets the default value for the &lt;code&gt;working_memory&lt;/code&gt; argument of &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;sklearn.set_config&lt;/code&gt; &lt;/a&gt; 의 &lt;code&gt;working_memory&lt;/code&gt; 인수에 대한 기본값을 설정합니다 .</target>
        </trans-unit>
        <trans-unit id="8fc661c1feefb08f484398590a9cfaa0d200700d" translate="yes" xml:space="preserve">
          <source>Sets the seed of the global random generator when running the tests, for reproducibility.</source>
          <target state="translated">테스트를 실행할 때 재현성을 위해 글로벌 랜덤 생성기의 시드를 설정합니다.</target>
        </trans-unit>
        <trans-unit id="ceca261ca4bfaf0dac2e7a5f6879bae3049e05bd" translate="yes" xml:space="preserve">
          <source>Sets the verbosity amount</source>
          <target state="translated">상세 량을 설정합니다</target>
        </trans-unit>
        <trans-unit id="41f97bb142955ba403db62394a8510aa45205b7b" translate="yes" xml:space="preserve">
          <source>Setting it to True gets the various classifiers and the parameters of the classifiers as well</source>
          <target state="translated">이를 True로 설정하면 다양한 분류기와 분류기의 매개 변수도 가져옵니다.</target>
        </trans-unit>
        <trans-unit id="2623b7b1ad6f2c3b5492832d70831c56aba6aac8" translate="yes" xml:space="preserve">
          <source>Setting the parameter by cross-validating the likelihood on three folds according to a grid of potential shrinkage parameters.</source>
          <target state="translated">잠재적 수축 매개 변수의 그리드에 따라 가능성을 3 배로 교차 검증하여 매개 변수를 설정합니다.</target>
        </trans-unit>
        <trans-unit id="edca67601d1a75cccde1deb24fddb7bb63088fcb" translate="yes" xml:space="preserve">
          <source>Setting the parameters for the voting classifier</source>
          <target state="translated">투표 분류기의 매개 변수 설정</target>
        </trans-unit>
        <trans-unit id="cb6261b9db86d6920a006098fc7538ed80a40df3" translate="yes" xml:space="preserve">
          <source>Several estimators in the scikit-learn can use connectivity information between features or samples. For instance Ward clustering (&lt;a href=&quot;clustering#hierarchical-clustering&quot;&gt;Hierarchical clustering&lt;/a&gt;) can cluster together only neighboring pixels of an image, thus forming contiguous patches:</source>
          <target state="translated">scikit-learn의 여러 추정기는 기능 또는 샘플간에 연결 정보를 사용할 수 있습니다. 예를 들어 Ward 클러스터링 ( &lt;a href=&quot;clustering#hierarchical-clustering&quot;&gt;계층 클러스터링&lt;/a&gt; )은 이미지의 인접 픽셀 만 함께 클러스터링 하여 연속적인 패치를 형성 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="b2ad224369c25dffec31e32504aa18be16f8d837" translate="yes" xml:space="preserve">
          <source>Several functions allow you to analyze the precision, recall and F-measures score:</source>
          <target state="translated">여러 기능을 통해 정밀도, 리콜 및 F 측정 점수를 분석 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="beccb29e29ebc99080f8c36d4203650a9f29b872" translate="yes" xml:space="preserve">
          <source>Several methods have been developed to compare two sets of biclusters. For now, only &lt;a href=&quot;generated/sklearn.metrics.consensus_score#sklearn.metrics.consensus_score&quot;&gt;&lt;code&gt;consensus_score&lt;/code&gt;&lt;/a&gt; (Hochreiter et. al., 2010) is available:</source>
          <target state="translated">두 세트의 biclusters를 비교하기위한 몇 가지 방법이 개발되었습니다. 현재는 &lt;a href=&quot;generated/sklearn.metrics.consensus_score#sklearn.metrics.consensus_score&quot;&gt; &lt;code&gt;consensus_score&lt;/code&gt; &lt;/a&gt; (Hochreiter et al., 2010) 만 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="bf696ed0c48f638295bdb050d71aac6a4287ef6f" translate="yes" xml:space="preserve">
          <source>Several regression and binary classification algorithms are available in scikit-learn. A simple way to extend these algorithms to the multi-class classification case is to use the so-called one-vs-all scheme.</source>
          <target state="translated">scikit-learn에서 여러 회귀 및 이진 분류 알고리즘을 사용할 수 있습니다. 이러한 알고리즘을 멀티 클래스 분류 사례로 확장하는 간단한 방법은 소위 one-vs-all 체계를 사용하는 것입니다.</target>
        </trans-unit>
        <trans-unit id="e301dd6062f7e9a79975fe8e2d0ba91694c4dbc3" translate="yes" xml:space="preserve">
          <source>Sex</source>
          <target state="translated">Sex</target>
        </trans-unit>
        <trans-unit id="94351e57e5ad4d9a685a9e5e4a3a8ed2b422ed01" translate="yes" xml:space="preserve">
          <source>Shape of the data arrays</source>
          <target state="translated">데이터 배열의 모양</target>
        </trans-unit>
        <trans-unit id="6ce851a20ced87e3a45210428f1caa987910f68a" translate="yes" xml:space="preserve">
          <source>Shape of the i&amp;rsquo;th bicluster.</source>
          <target state="translated">i 번째 bicluster의 모양입니다.</target>
        </trans-unit>
        <trans-unit id="e14b35d505512b3adb2f8997ae35ca2be24040d8" translate="yes" xml:space="preserve">
          <source>Shape will be [n_samples, 1] for binary problems.</source>
          <target state="translated">이진 문제의 경우 형태는 [n_samples, 1]입니다.</target>
        </trans-unit>
        <trans-unit id="f4aa10e40109dde70a9d57a4c3969b16b2895540" translate="yes" xml:space="preserve">
          <source>Shift features by the specified value. If None, then features are shifted by a random value drawn in [-class_sep, class_sep].</source>
          <target state="translated">지정된 값만큼 피처를 이동합니다. None 인 경우 [-class_sep, class_sep]에 그려진 임의의 값으로 기능이 이동됩니다.</target>
        </trans-unit>
        <trans-unit id="89ec1dbbc8f85faf0ad282b8a6481e07a4785260" translate="yes" xml:space="preserve">
          <source>Shifted opposite of the Local Outlier Factor of X.</source>
          <target state="translated">X의 로컬 특이 치 계수와 반대로 이동했습니다.</target>
        </trans-unit>
        <trans-unit id="5433cd73ac014316d0b32695693eab5029601309" translate="yes" xml:space="preserve">
          <source>Shorthand</source>
          <target state="translated">Shorthand</target>
        </trans-unit>
        <trans-unit id="a8178c51c2cc3204c708328447fd16ef389ce9b6" translate="yes" xml:space="preserve">
          <source>Should be used when memory is inefficient to train all data. Chunks of data can be passed in several iteration, where the first call should have an array of all target variables.</source>
          <target state="translated">메모리가 모든 데이터를 훈련시키는 데 비효율적 일 때 사용해야합니다. 데이터 청크는 여러 번 반복하여 전달 될 수 있으며, 첫 번째 호출에는 모든 대상 변수의 배열이 있어야합니다.</target>
        </trans-unit>
        <trans-unit id="12700416ee0fef7fdd5157d1c27acbb9da13d5c9" translate="yes" xml:space="preserve">
          <source>Should be used when memory is inefficient to train all data. Chunks of data can be passed in several iteration.</source>
          <target state="translated">메모리가 모든 데이터를 훈련시키는 데 비효율적 일 때 사용해야합니다. 여러 개의 데이터를 여러 번 반복하여 전달할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="ec934ba88e117c3577f933302800f3ab4b85705a" translate="yes" xml:space="preserve">
          <source>Show below is a logistic-regression classifiers decision boundaries on the first two dimensions (sepal length and width) of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;iris&lt;/a&gt; dataset. The datapoints are colored according to their labels.</source>
          <target state="translated">아래는 &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;홍채&lt;/a&gt; 데이터 세트 의 처음 두 차원 (sepal length 및 width)에 대한 로지스틱 회귀 분류기 결정 경계입니다 . 데이터 포인트는 레이블에 따라 색상이 지정됩니다.</target>
        </trans-unit>
        <trans-unit id="c74e263b32d3703a876a54ba7cc367e3fb1c6bbb" translate="yes" xml:space="preserve">
          <source>Shown in the plot is how the logistic regression would, in this synthetic dataset, classify values as either 0 or 1, i.e. class one or two, using the logistic curve.</source>
          <target state="translated">이 합성 데이터 세트에서 로지스틱 회귀 분석을 사용하여 로지스틱 곡선을 사용하여 값을 0 또는 1, 즉 클래스 1 또는 2로 분류하는 방법이 도표에 표시됩니다.</target>
        </trans-unit>
        <trans-unit id="ca5bc8cbcc9592e82a2ca132c00133d4ad37408e" translate="yes" xml:space="preserve">
          <source>Shows how shrinkage improves classification.</source>
          <target state="translated">수축이 분류를 개선하는 방법을 보여줍니다.</target>
        </trans-unit>
        <trans-unit id="5dc7ad8809a977f328219d536276f520094e2981" translate="yes" xml:space="preserve">
          <source>Shows how to use a function transformer in a pipeline. If you know your dataset&amp;rsquo;s first principle component is irrelevant for a classification task, you can use the FunctionTransformer to select all but the first column of the PCA transformed data.</source>
          <target state="translated">파이프 라인에서 함수 변압기를 사용하는 방법을 보여줍니다. 데이터 집합의 첫 번째 기본 구성 요소가 분류 작업과 관련이 없다는 것을 알고 있으면 FunctionTransformer를 사용하여 PCA 변환 된 데이터의 첫 번째 열을 제외한 모든 열을 선택할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="f535d0d4250bfadc5c1c6932476e7cb22e7db70e" translate="yes" xml:space="preserve">
          <source>Shows the effect of collinearity in the coefficients of an estimator.</source>
          <target state="translated">추정기의 계수에서 공선 성의 효과를 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="1a78e7f7618436a20d69e64d9d5ffb3bc060c908" translate="yes" xml:space="preserve">
          <source>Shrinkage</source>
          <target state="translated">Shrinkage</target>
        </trans-unit>
        <trans-unit id="29ad8c0361eee52379ab28eb86f7303c232b073b" translate="yes" xml:space="preserve">
          <source>Shrinkage and sparsity with logistic regression</source>
          <target state="translated">로지스틱 회귀 분석을 통한 수축 및 희소성</target>
        </trans-unit>
        <trans-unit id="92e7e7782831a32d85f1f4adb6e6848b9931e9f2" translate="yes" xml:space="preserve">
          <source>Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood</source>
          <target state="translated">수축 공분산 추정 : LedoitWolf vs OAS 및 최대 우도</target>
        </trans-unit>
        <trans-unit id="bc56f7d6f334df6e1bf7e25fb6694a2b96d3283e" translate="yes" xml:space="preserve">
          <source>Shrinkage is a tool to improve estimation of covariance matrices in situations where the number of training samples is small compared to the number of features. In this scenario, the empirical sample covariance is a poor estimator. Shrinkage LDA can be used by setting the &lt;code&gt;shrinkage&lt;/code&gt; parameter of the &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt; class to &amp;lsquo;auto&amp;rsquo;. This automatically determines the optimal shrinkage parameter in an analytic way following the lemma introduced by Ledoit and Wolf &lt;a href=&quot;#id5&quot; id=&quot;id3&quot;&gt;[4]&lt;/a&gt;. Note that currently shrinkage only works when setting the &lt;code&gt;solver&lt;/code&gt; parameter to &amp;lsquo;lsqr&amp;rsquo; or &amp;lsquo;eigen&amp;rsquo;.</source>
          <target state="translated">수축은 특징의 수에 비해 훈련 샘플의 수가 적은 상황에서 공분산 행렬의 추정을 향상시키는 도구입니다. 이 시나리오에서 경험적 샘플 공분산은 좋지 않은 추정기입니다. 수축 LDA는 &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt; 클래스 의 &lt;code&gt;shrinkage&lt;/code&gt; 매개 변수 를 'auto' 로 설정하여 사용할 수 있습니다 . 이것은 Ledoit과 Wolf에 의해 도입 된 음모에 따라 분석 방식으로 최적 수축 매개 변수를 자동으로 결정합니다 &lt;a href=&quot;#id5&quot; id=&quot;id3&quot;&gt;[4]&lt;/a&gt; . 현재 수축은 &lt;code&gt;solver&lt;/code&gt; 매개 변수를 'lsqr'또는 'eigen'으로 설정 한 경우에만 작동합니다 .</target>
        </trans-unit>
        <trans-unit id="7e8136e1a5918ee41b1666fa514179c5cb22402c" translate="yes" xml:space="preserve">
          <source>Shrinkage parameter, possible values:</source>
          <target state="translated">수축 매개 변수, 가능한 값 :</target>
        </trans-unit>
        <trans-unit id="b2a27e6ba825492dec9776790877b64e516e75e0" translate="yes" xml:space="preserve">
          <source>Shrunk covariance.</source>
          <target state="translated">축소 공분산.</target>
        </trans-unit>
        <trans-unit id="4dcdf0ff13bd4f7b65e07eadf0216796b5d56197" translate="yes" xml:space="preserve">
          <source>Shuffle arrays or sparse matrices in a consistent way</source>
          <target state="translated">일관된 방식으로 배열 또는 희소 행렬 섞기</target>
        </trans-unit>
        <trans-unit id="c0ccd0261920fa2fccaab512e3420b322d650304" translate="yes" xml:space="preserve">
          <source>Shuffle the samples and the features.</source>
          <target state="translated">샘플과 기능을 섞습니다.</target>
        </trans-unit>
        <trans-unit id="372aba820bed6f2900292d1b119c1b7c02346b33" translate="yes" xml:space="preserve">
          <source>Shuffle the samples.</source>
          <target state="translated">샘플을 섞는다.</target>
        </trans-unit>
        <trans-unit id="bb741d2d7cb4e292767bcf7b4c4d2a7dcedf441d" translate="yes" xml:space="preserve">
          <source>Shuffle-Group(s)-Out cross-validation iterator</source>
          <target state="translated">셔플 그룹-교차 유효성 검사 반복기</target>
        </trans-unit>
        <trans-unit id="04a76dd0a6286b28de9940305c73988458741a00" translate="yes" xml:space="preserve">
          <source>Signed distance is positive for an inlier and negative for an outlier.</source>
          <target state="translated">부호있는 거리는 이너에 대해서는 양수이고 특이 치에 대해서는 음수입니다.</target>
        </trans-unit>
        <trans-unit id="175a8f49ca538859a1536806ea283ecf7546e18e" translate="yes" xml:space="preserve">
          <source>Signed distance to the separating hyperplane.</source>
          <target state="translated">분리 초평면까지의 서명 된 거리.</target>
        </trans-unit>
        <trans-unit id="bdea7e4b3b56af1c4dc44f101507e6d5fde4c3c5" translate="yes" xml:space="preserve">
          <source>Silhouette Coefficient for each samples.</source>
          <target state="translated">각 샘플에 대한 실루엣 계수.</target>
        </trans-unit>
        <trans-unit id="cef2e4d37f21e366fe4348cb5c8e3de442e95913" translate="yes" xml:space="preserve">
          <source>Silhouette analysis can be used to study the separation distance between the resulting clusters. The silhouette plot displays a measure of how close each point in one cluster is to points in the neighboring clusters and thus provides a way to assess parameters like number of clusters visually. This measure has a range of [-1, 1].</source>
          <target state="translated">실루엣 분석을 사용하여 결과 군집 간의 분리 거리를 연구 할 수 있습니다. 실루엣 플롯은 한 군집의 각 점이 인접 군집의 점에 얼마나 가까운 지에 대한 측정 값을 표시하므로 군집 수와 같은 매개 변수를 시각적으로 평가할 수있는 방법을 제공합니다. 이 측정 값의 범위는 [-1, 1]입니다.</target>
        </trans-unit>
        <trans-unit id="f28647d65c56d46a3ca67f993f108ac366d59691" translate="yes" xml:space="preserve">
          <source>Silhouette coefficients (as these values are referred to as) near +1 indicate that the sample is far away from the neighboring clusters. A value of 0 indicates that the sample is on or very close to the decision boundary between two neighboring clusters and negative values indicate that those samples might have been assigned to the wrong cluster.</source>
          <target state="translated">+1 근처의 실루엣 계수 (이러한 값이라고 함)는 샘플이 인접 군집에서 멀리 떨어져 있음을 나타냅니다. 값이 0이면 샘플이 인접한 두 군집 사이의 결정 경계에 있거나 매우 가깝다는 것을 나타내고 음수 값은 해당 샘플이 잘못된 군집에 할당되었을 수 있음을 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="88d328be635604c256d2743bcb180fd1daab0b36" translate="yes" xml:space="preserve">
          <source>Similar feature extractors should be built for other kind of unstructured data input such as images, audio, video, &amp;hellip;</source>
          <target state="translated">이미지, 오디오, 비디오 등과 같은 다른 종류의 비정형 데이터 입력을 위해 유사한 기능 추출기를 구축해야합니다.</target>
        </trans-unit>
        <trans-unit id="319655ff7753a6199642b7bf6692dc2bf99bfe55" translate="yes" xml:space="preserve">
          <source>Similar to AgglomerativeClustering, but recursively merges features instead of samples.</source>
          <target state="translated">AgglomerativeClustering과 유사하지만 샘플 대신 기능을 재귀 적으로 병합합니다.</target>
        </trans-unit>
        <trans-unit id="133d603767b5dc043e4bab49b5255c4ddd0f05fe" translate="yes" xml:space="preserve">
          <source>Similar to NuSVC, for regression, uses a parameter nu to control the number of support vectors. However, unlike NuSVC, where nu replaces C, here nu replaces the parameter epsilon of epsilon-SVR.</source>
          <target state="translated">회귀 분석을 위해 NuSVC와 유사하게 매개 변수 nu를 사용하여 지원 벡터 수를 제어합니다. 그러나 nu가 C를 대체하는 NuSVC와 달리 여기서 nu는 epsilon-SVR의 매개 변수 epsilon을 대체합니다.</target>
        </trans-unit>
        <trans-unit id="d1a2b055f0753742d67fc90d1d4811e0a5d9ab30" translate="yes" xml:space="preserve">
          <source>Similar to SVC but uses a parameter to control the number of support vectors.</source>
          <target state="translated">SVC와 유사하지만 매개 변수를 사용하여 지원 벡터 수를 제어합니다.</target>
        </trans-unit>
        <trans-unit id="367343dd50d61c27ddbb7a06df2fb9885bdf8a5f" translate="yes" xml:space="preserve">
          <source>Similar to SVC with parameter kernel=&amp;rsquo;linear&amp;rsquo;, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.</source>
          <target state="translated">kernel = 'linear'매개 변수를 사용하는 SVC와 유사하지만 libsvm이 아닌 liblinear의 측면에서 구현되므로 페널티 및 손실 함수를 선택할 때 더 많은 유연성을 가지며 많은 수의 샘플로 더 잘 확장되어야합니다.</target>
        </trans-unit>
        <trans-unit id="3ec63304462f4cbac1c3a261d38d9188bcded830" translate="yes" xml:space="preserve">
          <source>Similar to SVR with parameter kernel=&amp;rsquo;linear&amp;rsquo;, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.</source>
          <target state="translated">kernel = 'linear'매개 변수를 사용하는 SVR과 유사하지만 libsvm이 아닌 liblinear의 측면에서 구현되므로 페널티 및 손실 함수를 선택할 때 더 많은 유연성을 가지며 많은 수의 샘플로 더 잘 확장되어야합니다.</target>
        </trans-unit>
        <trans-unit id="997a429b680aeb0ca7576cadadd68b1d30fd4132" translate="yes" xml:space="preserve">
          <source>Similar to other boosting algorithms GBRT builds the additive model in a forward stagewise fashion:</source>
          <target state="translated">다른 부스팅 알고리즘과 유사하게 GBRT는 추가 단계 모델을 단계별로 빌드합니다.</target>
        </trans-unit>
        <trans-unit id="9dba587c665016505432ed3d83545171f96e0b75" translate="yes" xml:space="preserve">
          <source>Similarity between individual biclusters is computed. Then the best matching between sets is found using the Hungarian algorithm. The final score is the sum of similarities divided by the size of the larger set.</source>
          <target state="translated">개별 biclusters 간의 유사성이 계산됩니다. 그런 다음 헝가리어 알고리즘을 사용하여 집합 간의 최상의 일치를 찾습니다. 최종 점수는 유사성의 합을 더 큰 세트의 크기로 나눈 것입니다.</target>
        </trans-unit>
        <trans-unit id="a365c849553e02aafca0dfedfc5010bc90d3ae71" translate="yes" xml:space="preserve">
          <source>Similarity score between -1.0 and 1.0. Random labelings have an ARI close to 0.0. 1.0 stands for perfect match.</source>
          <target state="translated">-1.0과 1.0 사이의 유사성 점수 임의 라벨링의 ARI는 0.0에 가깝습니다. 1.0은 완벽한 일치를 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="186186d91781f080c251077ac03fc20cf1639d0c" translate="yes" xml:space="preserve">
          <source>Similarly, &lt;a href=&quot;generated/sklearn.model_selection.repeatedstratifiedkfold#sklearn.model_selection.RepeatedStratifiedKFold&quot;&gt;&lt;code&gt;RepeatedStratifiedKFold&lt;/code&gt;&lt;/a&gt; repeats Stratified K-Fold n times with different randomization in each repetition.</source>
          <target state="translated">마찬가지로 &lt;a href=&quot;generated/sklearn.model_selection.repeatedstratifiedkfold#sklearn.model_selection.RepeatedStratifiedKFold&quot;&gt; &lt;code&gt;RepeatedStratifiedKFold&lt;/code&gt; &lt;/a&gt; 는 각 반복에서 다른 무작위 화로 Stratified K-Fold를 n 번 반복합니다.</target>
        </trans-unit>
        <trans-unit id="01f578d801e5d1ea722f26bf3985038251d17ab9" translate="yes" xml:space="preserve">
          <source>Similarly, L1 regularized logistic regression solves the following optimization problem</source>
          <target state="translated">마찬가지로 L1 정규화 된 로지스틱 회귀 분석은 다음 최적화 문제를 해결합니다.</target>
        </trans-unit>
        <trans-unit id="33d5515f485c474434afb456d44ce55ecb3a831d" translate="yes" xml:space="preserve">
          <source>Similarly, labels not present in the data sample may be accounted for in macro-averaging.</source>
          <target state="translated">유사하게, 데이터 샘플에 존재하지 않는 라벨은 매크로 평균화에서 설명 될 수있다.</target>
        </trans-unit>
        <trans-unit id="0c868e091c0bbbbc855227dfcc9797f545ef094e" translate="yes" xml:space="preserve">
          <source>Simple 1D Kernel Density Estimation</source>
          <target state="translated">간단한 1D 커널 밀도 추정</target>
        </trans-unit>
        <trans-unit id="f5468d7aca1a86ccbbf784d0772796020bb33f7b" translate="yes" xml:space="preserve">
          <source>Simple to understand and to interpret. Trees can be visualised.</source>
          <target state="translated">이해하고 해석하기 간단합니다. 나무를 시각화 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="954c17f332cbfd66dfa98282859837f21d64fd6a" translate="yes" xml:space="preserve">
          <source>Simple usage of Pipeline that runs successively a univariate feature selection with anova and then a C-SVM of the selected features.</source>
          <target state="translated">anova 및 선택한 기능의 C-SVM을 사용하여 일 변량 기능 선택을 연속적으로 실행하는 파이프 라인의 간단한 사용법.</target>
        </trans-unit>
        <trans-unit id="50f8d26df97413619de7bb6966a9aa041cc32e16" translate="yes" xml:space="preserve">
          <source>Simple usage of Support Vector Machines to classify a sample. It will plot the decision surface and the support vectors.</source>
          <target state="translated">샘플을 분류하기위한 Support Vector Machines의 간단한 사용. 결정 표면과지지 벡터를 플로팅합니다.</target>
        </trans-unit>
        <trans-unit id="5b50d9c69163fc1e922706c7d40ea5de7c4c3507" translate="yes" xml:space="preserve">
          <source>Simple usage of various cross decomposition algorithms: - PLSCanonical - PLSRegression, with multivariate response, a.k.a. PLS2 - PLSRegression, with univariate response, a.k.a. PLS1 - CCA</source>
          <target state="translated">다양한 교차 분해 알고리즘의 간단한 사용법 :-PLSCanonical-PLSRegression, 다변량 반응, 일명 PLS2-PLSRegression, 일 변량 반응, 일명 PLS1-CCA</target>
        </trans-unit>
        <trans-unit id="0cd5c8d669edd41f72cf141b1f653ffc3a8f7d8a" translate="yes" xml:space="preserve">
          <source>Simply perform a svd on the crosscovariance matrix: X&amp;rsquo;Y There are no iterative deflation here.</source>
          <target state="translated">교차 공분산 행렬에서 간단히 svd를 수행하십시오. X'Y 여기에는 반복적 인 수축이 없습니다.</target>
        </trans-unit>
        <trans-unit id="f72f0eda605215d24ff9d1908550395272883fb4" translate="yes" xml:space="preserve">
          <source>Simulations</source>
          <target state="translated">Simulations</target>
        </trans-unit>
        <trans-unit id="2e04b6f26b355099b78d114e001527cec11f01b3" translate="yes" xml:space="preserve">
          <source>Since \(P(x_1, \dots, x_n)\) is constant given the input, we can use the following classification rule:</source>
          <target state="translated">입력이 주어지면 \ (P (x_1, \ dots, x_n) \)는 일정하므로 다음과 같은 분류 규칙을 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="4ed5170dfb2a4a5fe27dc284ef1f79230346d84b" translate="yes" xml:space="preserve">
          <source>Since a model internal representation may be different on two different architectures, dumping a model on one architecture and loading it on another architecture is not supported.</source>
          <target state="translated">두 가지 다른 아키텍처에서는 모델 내부 표현이 다를 수 있으므로 한 아키텍처에서 모델을 덤프하고 다른 아키텍처에로드하는 것은 지원되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="2e7dca0922f252e8bcb5dd7de62f190d029edf35" translate="yes" xml:space="preserve">
          <source>Since a simple modulo is used to transform the hash function to a column index, it is advisable to use a power of two as the &lt;code&gt;n_features&lt;/code&gt; parameter; otherwise the features will not be mapped evenly to the columns.</source>
          <target state="translated">간단한 모듈로가 해시 함수를 열 인덱스로 변환하는 데 사용되므로 &lt;code&gt;n_features&lt;/code&gt; 매개 변수 로 2의 거듭 제곱을 사용하는 것이 좋습니다 . 그렇지 않으면 기능이 열에 균등하게 매핑되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="e94526c23963e4af6db5a385aa61965ac4ba9d0e" translate="yes" xml:space="preserve">
          <source>Since it requires to fit &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; classifiers, this method is usually slower than one-vs-the-rest, due to its O(n_classes^2) complexity. However, this method may be advantageous for algorithms such as kernel algorithms which don&amp;rsquo;t scale well with &lt;code&gt;n_samples&lt;/code&gt;. This is because each individual learning problem only involves a small subset of the data whereas, with one-vs-the-rest, the complete dataset is used &lt;code&gt;n_classes&lt;/code&gt; times.</source>
          <target state="translated">&lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; 분류기 에 맞아야하기 때문에이 방법은 일반적으로 O (n_classes ^ 2) 복잡성으로 인해 1 대 1보다 느립니다. 그러나이 방법은 &lt;code&gt;n_samples&lt;/code&gt; 와 함께 잘 확장되지 않는 커널 알고리즘과 같은 알고리즘에 유리할 수 있습니다 . 각 개별 학습 문제는 데이터의 작은 하위 집합 만 포함하고 나머지는 전체 데이터 세트가 &lt;code&gt;n_classes&lt;/code&gt; 시간 동안 사용 되기 때문 입니다.</target>
        </trans-unit>
        <trans-unit id="885cdc36b68d6b1fe527d22b8af012efa7ee88fc" translate="yes" xml:space="preserve">
          <source>Since our loss function is dependent on the amount of samples, the latter will influence the selected value of &lt;code&gt;C&lt;/code&gt;. The question that arises is &lt;code&gt;How do we optimally adjust C to account for the different amount of training samples?&lt;/code&gt;</source>
          <target state="translated">손실 함수는 샘플의 양에 따라 달라 지므로 후자는 선택한 &lt;code&gt;C&lt;/code&gt; 값에 영향을 미칩니다 . 발생하는 문제 &lt;code&gt;How do we optimally adjust C to account for the different amount of training samples?&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="8414cbee67356c2ab2c8ba5220ad5c2247b09cc6" translate="yes" xml:space="preserve">
          <source>Since recursive partitioning can be represented by a tree structure, the number of splittings required to isolate a sample is equivalent to the path length from the root node to the terminating node.</source>
          <target state="translated">재귀 분할은 트리 구조로 나타낼 수 있으므로 샘플을 분리하는 데 필요한 분할 수는 루트 노드에서 종료 노드까지의 경로 길이와 같습니다.</target>
        </trans-unit>
        <trans-unit id="41606a5be005625c4678c2fc6968d98c5bcdacbb" translate="yes" xml:space="preserve">
          <source>Since the hash function might cause collisions between (unrelated) features, a signed hash function is used and the sign of the hash value determines the sign of the value stored in the output matrix for a feature. This way, collisions are likely to cancel out rather than accumulate error, and the expected mean of any output feature&amp;rsquo;s value is zero. This mechanism is enabled by default with &lt;code&gt;alternate_sign=True&lt;/code&gt; and is particularly useful for small hash table sizes (&lt;code&gt;n_features &amp;lt; 10000&lt;/code&gt;). For large hash table sizes, it can be disabled, to allow the output to be passed to estimators like &lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt;&lt;code&gt;sklearn.naive_bayes.MultinomialNB&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt;&lt;code&gt;sklearn.feature_selection.chi2&lt;/code&gt;&lt;/a&gt; feature selectors that expect non-negative inputs.</source>
          <target state="translated">해시 함수가 (관련되지 않은) 기능간에 충돌을 일으킬 수 있으므로 서명 된 해시 함수가 사용되며 해시 값의 부호가 기능의 출력 행렬에 저장된 값의 부호를 결정합니다. 이런 식으로 충돌이 누적 오류가 아닌 취소 될 수 있으며 출력 기능 값의 예상 평균은 0입니다. 이 메커니즘은 기본적으로 &lt;code&gt;alternate_sign=True&lt;/code&gt; 로 활성화되며 작은 해시 테이블 크기 ( &lt;code&gt;n_features &amp;lt; 10000&lt;/code&gt; )에 특히 유용합니다 . 큰 해시 테이블 크기의 경우, 음이 아닌 입력을 기대하는 &lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt; &lt;code&gt;sklearn.naive_bayes.MultinomialNB&lt;/code&gt; &lt;/a&gt; 또는 &lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt; &lt;code&gt;sklearn.feature_selection.chi2&lt;/code&gt; &lt;/a&gt; 기능 선택기 와 같은 추정기로 출력을 전달할 수 있도록 비활성화 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="91020f655b0d3976000fc58a456fa0d94621c5a6" translate="yes" xml:space="preserve">
          <source>Since the kernel that is to be approximated is additive, the components of the input vectors can be treated separately. Each entry in the original space is transformed into 2*sample_steps+1 features, where sample_steps is a parameter of the method. Typical values of sample_steps include 1, 2 and 3.</source>
          <target state="translated">근사 될 커널은 부가 적이므로, 입력 벡터의 구성 요소는 개별적으로 처리 될 수 있습니다. 원래 공간의 각 항목은 2 * sample_steps + 1 기능으로 변환되며, 여기서 sample_steps는 메소드의 매개 변수입니다. sample_steps의 일반적인 값은 1, 2 및 3입니다.</target>
        </trans-unit>
        <trans-unit id="dac98c213a89fd4774cf1c1f95b63e10c23ed6ab" translate="yes" xml:space="preserve">
          <source>Since the posterior is intractable, variational Bayesian method uses a simpler distribution \(q(z,\theta,\beta | \lambda, \phi, \gamma)\) to approximate it, and those variational parameters \(\lambda\), \(\phi\), \(\gamma\) are optimized to maximize the Evidence Lower Bound (ELBO):</source>
          <target state="translated">후자는 다루기 어렵 기 때문에 변형 베이지안 방법은 더 간단한 분포 \ (q (z, \ theta, \ beta | \ lambda, \ phi, \ gamma) \)를 사용하여 근사값을 구하고 그 변형 매개 변수 \ (\ lambda \) , \ (\ phi \), \ (\ gamma \)는 ELBO (Evidence Lower Bound)를 최대화하도록 최적화되었습니다.</target>
        </trans-unit>
        <trans-unit id="ce93b96a689b29304c626bbff15b3c9ae5662f8f" translate="yes" xml:space="preserve">
          <source>Since the thresholds are sorted from low to high values, they are reversed upon returning them to ensure they correspond to both &lt;code&gt;fpr&lt;/code&gt; and &lt;code&gt;tpr&lt;/code&gt;, which are sorted in reversed order during their calculation.</source>
          <target state="translated">임계 값은 낮은 값에서 높은 값 으로 정렬되므로 계산시 역순으로 정렬 된 &lt;code&gt;fpr&lt;/code&gt; 및 &lt;code&gt;tpr&lt;/code&gt; 에 모두 해당하는지 확인하기 위해 반환시 역순으로 정렬됩니다.</target>
        </trans-unit>
        <trans-unit id="7f69d32984c3b4f143cfa37bb4e60432050ed0eb" translate="yes" xml:space="preserve">
          <source>Since there has not been much empirical work using approximate embeddings, it is advisable to compare results against exact kernel methods when possible.</source>
          <target state="translated">대략적인 임베딩을 사용한 경험적 작업이 많지 않았으므로 가능한 경우 정확한 커널 방법과 결과를 비교하는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="fa984969d0a90a5820c4fc022c64bfc47ca5a084" translate="yes" xml:space="preserve">
          <source>Single estimator versus bagging: bias-variance decomposition</source>
          <target state="translated">단일 추정기 대 배깅 : 바이어스-분산 분해</target>
        </trans-unit>
        <trans-unit id="c2fe1a00c3aef2fdadf0dd5e7ea7933f55e2ab1b" translate="yes" xml:space="preserve">
          <source>Single metric evaluation using &lt;code&gt;cross_validate&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;cross_validate&lt;/code&gt; 를 사용한 단일 메트릭 평가</target>
        </trans-unit>
        <trans-unit id="78a22764fe4a9b48a649589e690300655f65c80d" translate="yes" xml:space="preserve">
          <source>Single, average and complete linkage can be used with a variety of distances (or affinities), in particular Euclidean distance (&lt;em&gt;l2&lt;/em&gt;), Manhattan distance (or Cityblock, or &lt;em&gt;l1&lt;/em&gt;), cosine distance, or any precomputed affinity matrix.</source>
          <target state="translated">하나는 평균 완전 결합은 특히 유클리드 거리 (에서는 거리 (또는 유사성)의 다양한 사용될 수 &lt;em&gt;L2&lt;/em&gt; ), 맨하탄 거리 (또는 Cityblock 또는 &lt;em&gt;L1&lt;/em&gt; ), 코사인 거리, 또는 미리 계산 된 친 화성 기질.</target>
        </trans-unit>
        <trans-unit id="857a843ae0f540aecaddebae91ddc74b518d5cf4" translate="yes" xml:space="preserve">
          <source>Singularities:</source>
          <target state="translated">Singularities:</target>
        </trans-unit>
        <trans-unit id="2df59d349ec07bd33a82cdc2b0c4c3d4152244c6" translate="yes" xml:space="preserve">
          <source>Size of minibatches for stochastic optimizers. If the solver is &amp;lsquo;lbfgs&amp;rsquo;, the classifier will not use minibatch. When set to &amp;ldquo;auto&amp;rdquo;, &lt;code&gt;batch_size=min(200, n_samples)&lt;/code&gt;</source>
          <target state="translated">확률 적 최적화를위한 미니 배치 크기. 솔버가 'lbfgs'인 경우 분류기는 미니 배치를 사용하지 않습니다. &quot;auto&quot;로 설정하면 &lt;code&gt;batch_size=min(200, n_samples)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="fa65aa30a853af1cf81f53119b6649c5aa5e2817" translate="yes" xml:space="preserve">
          <source>Size of the blocks into which the covariance matrix will be split during its Ledoit-Wolf estimation. This is purely a memory optimization and does not affect results.</source>
          <target state="translated">공분산 행렬이 Ledoit-Wolf 추정 중에 분할 될 블록의 크기입니다. 이것은 순전히 메모리 최적화이며 결과에 영향을 미치지 않습니다.</target>
        </trans-unit>
        <trans-unit id="3bdf2049b3b05b0720764317c09e88bc19700eec" translate="yes" xml:space="preserve">
          <source>Size of the blocks into which the covariance matrix will be split. This is purely a memory optimization and does not affect results.</source>
          <target state="translated">공분산 행렬이 분할 될 블록의 크기입니다. 이것은 순전히 메모리 최적화이며 결과에 영향을 미치지 않습니다.</target>
        </trans-unit>
        <trans-unit id="612eb8e8a229547855d2a4c02d66bbe2afb0395a" translate="yes" xml:space="preserve">
          <source>Size of the mini batches.</source>
          <target state="translated">미니 배치의 크기.</target>
        </trans-unit>
        <trans-unit id="aa636a80a54912b13ca3fa6029e0a40e02f80415" translate="yes" xml:space="preserve">
          <source>Size of the return array</source>
          <target state="translated">반환 배열의 크기</target>
        </trans-unit>
        <trans-unit id="08f603d3fe1f30df7982a9a08f592731c9eab73e" translate="yes" xml:space="preserve">
          <source>Size of the test sets.</source>
          <target state="translated">테스트 세트의 크기</target>
        </trans-unit>
        <trans-unit id="1d7d650781fdf69336502b899ccd5c9f80ba4848" translate="yes" xml:space="preserve">
          <source>Skip input validation checks, including the Gram matrix when provided assuming there are handled by the caller when check_input=False.</source>
          <target state="translated">check_input = False 일 때 호출자가 처리한다고 가정 할 때 Gram 매트릭스를 포함하여 입력 유효성 검사를 건너 뜁니다.</target>
        </trans-unit>
        <trans-unit id="119077d89fb1cbe89db9591404feee43530ef290" translate="yes" xml:space="preserve">
          <source>Slides explaining PLS</source>
          <target state="translated">PLS를 설명하는 슬라이드</target>
        </trans-unit>
        <trans-unit id="c3d721c0cfe644c7ca720484ae796856345cb087" translate="yes" xml:space="preserve">
          <source>Small outliers</source>
          <target state="translated">작은 특이 치</target>
        </trans-unit>
        <trans-unit id="6cf8c0d1548c80d5c7b8e80adf89b56b8a30e60f" translate="yes" xml:space="preserve">
          <source>Small positive values of alpha improve the conditioning of the problem and reduce the variance of the estimates. Alpha corresponds to &lt;code&gt;(2*C)^-1&lt;/code&gt; in other linear models such as LogisticRegression or LinearSVC. If an array is passed, penalties are assumed to be specific to the targets. Hence they must correspond in number.</source>
          <target state="translated">작은 양의 알파 값은 문제의 컨디셔닝을 개선하고 추정값의 분산을 줄입니다. 알파 는 LogisticRegression 또는 LinearSVC와 같은 다른 선형 모델에서 &lt;code&gt;(2*C)^-1&lt;/code&gt; 에 해당합니다. 배열이 전달되면 페널티는 대상에 특정한 것으로 간주됩니다. 따라서 숫자와 일치해야합니다.</target>
        </trans-unit>
        <trans-unit id="8e135bd52bd2eb3356a694f0d8575402c5375bb6" translate="yes" xml:space="preserve">
          <source>Smaller values lead to better embedding and higher number of dimensions (n_components) in the target projection space.</source>
          <target state="translated">값이 작을수록 대상 투영 공간에 더 나은 임베딩 및 더 많은 차원 수 (n_components)가 생깁니다.</target>
        </trans-unit>
        <trans-unit id="178a5fd9e6a787566f82c9ecbd118e48b0edcccd" translate="yes" xml:space="preserve">
          <source>Smallest value of alpha / alpha_max considered</source>
          <target state="translated">고려되는 alpha / alpha_max의 최소값</target>
        </trans-unit>
        <trans-unit id="9ec75e4c898141f811f9d6fe4e66f6da7a97bb9c" translate="yes" xml:space="preserve">
          <source>Smooth idf weights by adding one to document frequencies, as if an extra document was seen containing every term in the collection exactly once. Prevents zero divisions.</source>
          <target state="translated">컬렉션의 모든 용어가 정확히 한 번만 포함 된 추가 문서가있는 것처럼 문서 빈도에 1을 추가하여 idf 가중치를 매끄럽게합니다. 제로 나누기를 방지합니다.</target>
        </trans-unit>
        <trans-unit id="8ec8b1649217676578a05802f05dc4dfdec72ebc" translate="yes" xml:space="preserve">
          <source>Smoothed empirical log probability for each class.</source>
          <target state="translated">각 클래스에 대한 경험적 로그 확률이 ​​평활화되었습니다.</target>
        </trans-unit>
        <trans-unit id="d5d952f65cbc310a8284a0aa676904d4b84a635c" translate="yes" xml:space="preserve">
          <source>Smoothed empirical log probability for each class. Only used in edge case with a single class in the training set.</source>
          <target state="translated">각 클래스에 대한 경험적 로그 확률이 ​​평활화되었습니다. 트레이닝 세트에서 단일 클래스가있는 엣지 케이스에서만 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="fb1739757cbc4d2da964b132a46ededacd98a2aa" translate="yes" xml:space="preserve">
          <source>Soft Voting/Majority Rule classifier for unfitted estimators.</source>
          <target state="translated">적합하지 않은 추정량에 대한 소프트 투표 / 주요 규칙 분류기.</target>
        </trans-unit>
        <trans-unit id="a33a62c21ea4043dbf31a4f6ee598307b73aa466" translate="yes" xml:space="preserve">
          <source>Soft hint to choose the default backend if no specific backend was selected with the parallel_backend context manager. The default process-based backend is &amp;lsquo;loky&amp;rsquo; and the default thread-based backend is &amp;lsquo;threading&amp;rsquo;.</source>
          <target state="translated">parallel_backend 컨텍스트 관리자로 특정 백엔드를 선택하지 않은 경우 기본 백엔드를 선택하는 힌트 기본 프로세스 기반 백엔드는 'loky'이고 기본 스레드 기반 백엔드는 'threading'입니다.</target>
        </trans-unit>
        <trans-unit id="9653b7a05f5df3e5d87561ce96e265c541ad8c31" translate="yes" xml:space="preserve">
          <source>SokalMichenerDistance</source>
          <target state="translated">SokalMichenerDistance</target>
        </trans-unit>
        <trans-unit id="01ed2fbc860294634b46d80d008798b47284ef75" translate="yes" xml:space="preserve">
          <source>SokalSneathDistance</source>
          <target state="translated">SokalSneathDistance</target>
        </trans-unit>
        <trans-unit id="0b76645291a4941abead277af175738d7e9485f1" translate="yes" xml:space="preserve">
          <source>Solution: &lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_digits_classification_exercise.py&quot;&gt;&lt;code&gt;../../auto_examples/exercises/plot_digits_classification_exercise.py&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">솔루션 : &lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_digits_classification_exercise.py&quot;&gt; &lt;code&gt;../../auto_examples/exercises/plot_digits_classification_exercise.py&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="97a1e21d1798b81e7cea434e741d7087aa2f4a99" translate="yes" xml:space="preserve">
          <source>Solution: &lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_iris_exercise.py&quot;&gt;&lt;code&gt;../../auto_examples/exercises/plot_iris_exercise.py&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">솔루션 : &lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_iris_exercise.py&quot;&gt; &lt;code&gt;../../auto_examples/exercises/plot_iris_exercise.py&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d31ac38ecaa97cd7ca9cf4223578d60df63f89a9" translate="yes" xml:space="preserve">
          <source>Solve the isotonic regression model:</source>
          <target state="translated">등장 성 회귀 모델을 푸십시오.</target>
        </trans-unit>
        <trans-unit id="48c6334f59edac84435c4184f66b59babd6924b9" translate="yes" xml:space="preserve">
          <source>Solve the ridge equation by the method of normal equations.</source>
          <target state="translated">정규 방정식의 방법으로 릿지 방정식을 풉니 다.</target>
        </trans-unit>
        <trans-unit id="b5fa00edfa7fc06c7e99359e114af78ec006b205" translate="yes" xml:space="preserve">
          <source>Solver to use in the computational routines:</source>
          <target state="translated">계산 루틴에서 사용할 해 찾기 :</target>
        </trans-unit>
        <trans-unit id="5c136e6e68fedeebc5e62ea492bdc13f5c51a357" translate="yes" xml:space="preserve">
          <source>Solver to use, possible values:</source>
          <target state="translated">사용할 해 찾기 가능한 값 :</target>
        </trans-unit>
        <trans-unit id="577db6a48ff5a1db9c02bebc0320d90f752c60ef" translate="yes" xml:space="preserve">
          <source>Solves a dictionary learning matrix factorization problem online.</source>
          <target state="translated">온라인 사전 학습 매트릭스 분해 문제를 해결합니다.</target>
        </trans-unit>
        <trans-unit id="8820b686f5bac3c2f3bf8f93441f10523c0fe031" translate="yes" xml:space="preserve">
          <source>Solves a dictionary learning matrix factorization problem.</source>
          <target state="translated">사전 학습 매트릭스 인수 분해 문제를 해결합니다.</target>
        </trans-unit>
        <trans-unit id="b22d518aabf32cc9c9347bf653295056dc359f7f" translate="yes" xml:space="preserve">
          <source>Solves n_targets Orthogonal Matching Pursuit problems using only the Gram matrix X.T * X and the product X.T * y.</source>
          <target state="translated">그램 행렬 XT * X 및 제품 XT * y 만 사용하여 n_targets 직교 매칭 추구 문제를 해결합니다.</target>
        </trans-unit>
        <trans-unit id="80547cf29da9d4cc131f68d1680f3500976f9f6f" translate="yes" xml:space="preserve">
          <source>Solves n_targets Orthogonal Matching Pursuit problems. An instance of the problem has the form:</source>
          <target state="translated">n_targets 직교 매칭 추구 문제를 해결합니다. 문제의 예는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="8d4fd8866d93aa1260a7a3d03ef9a9a9f9a2fc7d" translate="yes" xml:space="preserve">
          <source>Solves the optimization problem:</source>
          <target state="translated">최적화 문제를 해결합니다.</target>
        </trans-unit>
        <trans-unit id="e29fb180670f8bd6283a93ce616785d39e9b899f" translate="yes" xml:space="preserve">
          <source>Some advantages of decision trees are:</source>
          <target state="translated">의사 결정 트리의 장점은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="2b6f2b5ee645a40c14b49c77184129b10ec1567a" translate="yes" xml:space="preserve">
          <source>Some also work in the multilabel case:</source>
          <target state="translated">일부는 다중 레이블 사례에서도 작동합니다.</target>
        </trans-unit>
        <trans-unit id="8762622dcc16bf1560cb81f69bbd48256b77f9a4" translate="yes" xml:space="preserve">
          <source>Some calculations when implemented using standard numpy vectorized operations involve using a large amount of temporary memory. This may potentially exhaust system memory. Where computations can be performed in fixed-memory chunks, we attempt to do so, and allow the user to hint at the maximum size of this working memory (defaulting to 1GB) using &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt; or &lt;code&gt;config_context&lt;/code&gt;. The following suggests to limit temporary working memory to 128 MiB:</source>
          <target state="translated">표준 numpy 벡터화 된 연산을 사용하여 구현할 때 일부 계산에는 많은 양의 임시 메모리를 사용합니다. 시스템 메모리가 소진 될 수 있습니다. 고정 메모리 청크에서 계산을 수행 할 수있는 경우,이를 시도하고 &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;sklearn.set_config&lt;/code&gt; &lt;/a&gt; 또는 &lt;code&gt;config_context&lt;/code&gt; 를 사용 하여이 작업 메모리의 최대 크기 (기본값은 1GB)를 암시하도록 허용합니다 . 다음은 임시 작업 메모리를 128MiB로 제한하는 것입니다.</target>
        </trans-unit>
        <trans-unit id="f425af2b7289a6eb3b0699842a415a72e1141c04" translate="yes" xml:space="preserve">
          <source>Some classification problems can exhibit a large imbalance in the distribution of the target classes: for instance there could be several times more negative samples than positive samples. In such cases it is recommended to use stratified sampling as implemented in &lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.model_selection.stratifiedshufflesplit#sklearn.model_selection.StratifiedShuffleSplit&quot;&gt;&lt;code&gt;StratifiedShuffleSplit&lt;/code&gt;&lt;/a&gt; to ensure that relative class frequencies is approximately preserved in each train and validation fold.</source>
          <target state="translated">일부 분류 문제는 대상 클래스의 분포에 큰 불균형을 나타낼 수 있습니다. 예를 들어 양성 샘플보다 몇 배 더 많은 음성 샘플이있을 수 있습니다. 이러한 경우 &lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;StratifiedKFold&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;generated/sklearn.model_selection.stratifiedshufflesplit#sklearn.model_selection.StratifiedShuffleSplit&quot;&gt; &lt;code&gt;StratifiedShuffleSplit&lt;/code&gt; &lt;/a&gt; 에 구현 된 계층화 된 샘플링을 사용 하여 각 열차 및 검증 폴드에서 상대 클래스 주파수가 대략 보존되도록하는 것이 좋습니다 .</target>
        </trans-unit>
        <trans-unit id="2ea2f829ceb432ffa0e3b3d420b4273e01e30d41" translate="yes" xml:space="preserve">
          <source>Some cross validation iterators, such as &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt;, have an inbuilt option to shuffle the data indices before splitting them. Note that:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt; 와 같은 일부 교차 유효성 검사 반복자 에는 데이터 인덱스를 셔플 링하기 전에 섞을 수있는 옵션이 내장되어 있습니다. 참고 :</target>
        </trans-unit>
        <trans-unit id="1b7524a4e391762865d52d4ee865a5a389b3ed4f" translate="yes" xml:space="preserve">
          <source>Some estimators expose a &lt;code&gt;transform&lt;/code&gt; method, for instance to reduce the dimensionality of the dataset.</source>
          <target state="translated">예를 들어 일부 추정기 는 데이터 집합의 차원을 줄이기 위해 &lt;code&gt;transform&lt;/code&gt; 방법을 제공합니다.</target>
        </trans-unit>
        <trans-unit id="abe93a33221be53771cefc563a6b553fa747a230" translate="yes" xml:space="preserve">
          <source>Some literature promotes alternative definitions of balanced accuracy. Our definition is equivalent to &lt;a href=&quot;sklearn.metrics.accuracy_score#sklearn.metrics.accuracy_score&quot;&gt;&lt;code&gt;accuracy_score&lt;/code&gt;&lt;/a&gt; with class-balanced sample weights, and shares desirable properties with the binary case. See the &lt;a href=&quot;../model_evaluation#balanced-accuracy-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">일부 문헌은 균형 잡힌 정확도의 대체 정의를 장려합니다. 우리의 정의는 클래스-밸런싱 된 샘플 가중치를 갖는 &lt;a href=&quot;sklearn.metrics.accuracy_score#sklearn.metrics.accuracy_score&quot;&gt; &lt;code&gt;accuracy_score&lt;/code&gt; &lt;/a&gt; _ 점수와 동등 하며, 이진 경우와 바람직한 속성을 공유합니다. 사용 &lt;a href=&quot;../model_evaluation#balanced-accuracy-score&quot;&gt;설명서를&lt;/a&gt; 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="65e1dc1251c858f270c665ff61463afe65f478d7" translate="yes" xml:space="preserve">
          <source>Some metrics are essentially defined for binary classification tasks (e.g. &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt;&lt;code&gt;f1_score&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt;). In these cases, by default only the positive label is evaluated, assuming by default that the positive class is labelled &lt;code&gt;1&lt;/code&gt; (though this may be configurable through the &lt;code&gt;pos_label&lt;/code&gt; parameter).</source>
          <target state="translated">일부 메트릭은 기본적으로 이진 분류 작업 (예 : &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt; &lt;code&gt;f1_score&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;roc_auc_score&lt;/code&gt; &lt;/a&gt; )에 대해 정의됩니다 . 이 경우 기본적으로 양의 클래스가 &lt;code&gt;1&lt;/code&gt; 로 레이블링되어 있다고 가정하면 양의 레이블 만 평가됩니다 ( &lt;code&gt;pos_label&lt;/code&gt; 매개 변수를 통해 구성 할 수 있음 ).</target>
        </trans-unit>
        <trans-unit id="d5ba6b95ba600216ff9982f7a3dbaf94b6802f73" translate="yes" xml:space="preserve">
          <source>Some models allow for specialized, efficient parameter search strategies, &lt;a href=&quot;#alternative-cv&quot;&gt;outlined below&lt;/a&gt;. Two generic approaches to sampling search candidates are provided in scikit-learn: for given values, &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; exhaustively considers all parameter combinations, while &lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt;&lt;code&gt;RandomizedSearchCV&lt;/code&gt;&lt;/a&gt; can sample a given number of candidates from a parameter space with a specified distribution. After describing these tools we detail &lt;a href=&quot;#grid-search-tips&quot;&gt;best practice&lt;/a&gt; applicable to both approaches.</source>
          <target state="translated">일부 모델은 &lt;a href=&quot;#alternative-cv&quot;&gt;아래 설명 된&lt;/a&gt; 특수하고 효율적인 매개 변수 검색 전략을 허용 합니다 . 검색 후보 샘플링에 대한 두 가지 일반적인 접근 방식이 scikit-learn에서 제공됩니다. 주어진 값에 대해 &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt; 는 모든 매개 변수 조합을 철저히 고려하는 반면 &lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt; &lt;code&gt;RandomizedSearchCV&lt;/code&gt; &lt;/a&gt; 는 지정된 분포를 사용하여 매개 변수 공간에서 지정된 수의 후보를 샘플링 할 수 있습니다. 이러한 도구를 설명한 후 두 가지 방법 모두에 적용 할 수있는 &lt;a href=&quot;#grid-search-tips&quot;&gt;모범 사례를&lt;/a&gt; 자세히 설명합니다 .</target>
        </trans-unit>
        <trans-unit id="95196f8314df139319d7b42ff6d7520f5ecc9f1d" translate="yes" xml:space="preserve">
          <source>Some models also have &lt;code&gt;row_labels_&lt;/code&gt; and &lt;code&gt;column_labels_&lt;/code&gt; attributes. These models partition the rows and columns, such as in the block diagonal and checkerboard bicluster structures.</source>
          <target state="translated">일부 모델에는 &lt;code&gt;row_labels_&lt;/code&gt; 및 &lt;code&gt;column_labels_&lt;/code&gt; 속성도 있습니다. 이 모델은 블록 대각선 및 바둑판 bicluster 구조와 같이 행과 열을 분할합니다.</target>
        </trans-unit>
        <trans-unit id="89f290ef487f7e4f63f1b82009e209966dcbe74f" translate="yes" xml:space="preserve">
          <source>Some models can fit data for a range of values of some parameter almost as efficiently as fitting the estimator for a single value of the parameter. This feature can be leveraged to perform a more efficient cross-validation used for model selection of this parameter.</source>
          <target state="translated">일부 모델은 추정값을 단일 매개 변수 값에 적합시키는 것만 큼 효율적으로 일부 매개 변수 값 범위에 대한 데이터를 적합시킬 수 있습니다. 이 기능은이 매개 변수의 모델 선택에 사용되는보다 효율적인 교차 검증을 수행하는 데 활용 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="d786744290bacd9a4dfc207be555be0e40c3853e" translate="yes" xml:space="preserve">
          <source>Some models can offer an information-theoretic closed-form formula of the optimal estimate of the regularization parameter by computing a single regularization path (instead of several when using cross-validation).</source>
          <target state="translated">일부 모델은 단일 교차 경로를 계산하여 교차 검증을 사용하는 경우 대신 여러 정규화 경로를 계산하여 정규화 매개 변수의 최적 추정치에 대한 정보 이론적 폐쇄 형 공식을 제공 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="ad14a182695bef0a4c2fe22edd0961e8db73147c" translate="yes" xml:space="preserve">
          <source>Some of the clusters learned without connectivity constraints do not respect the structure of the swiss roll and extend across different folds of the manifolds. On the opposite, when opposing connectivity constraints, the clusters form a nice parcellation of the swiss roll.</source>
          <target state="translated">연결 제약 조건없이 학습 된 일부 클러스터는 스위스 롤의 구조를 고려하지 않고 매니 폴드의 다른 접힘에 걸쳐 확장됩니다. 반대로, 연결 제약 조건에 반대 할 때, 클러스터는 스위스 롤의 멋진 분할을 형성합니다.</target>
        </trans-unit>
        <trans-unit id="877cbb42097301f5a68339d0d9f55e4ca85ad3c3" translate="yes" xml:space="preserve">
          <source>Some of these are restricted to the binary classification case:</source>
          <target state="translated">이들 중 일부는 이진 분류 사례로 제한됩니다.</target>
        </trans-unit>
        <trans-unit id="bc828cde0b0d5dbd5e8ad77797297d4f6416ab76" translate="yes" xml:space="preserve">
          <source>Some other classifiers cope better with this harder version of the task. Try running &lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;Sample pipeline for text feature extraction and evaluation&lt;/a&gt; with and without the &lt;code&gt;--filter&lt;/code&gt; option to compare the results.</source>
          <target state="translated">다른 분류기는이 어려운 버전의 작업에 더 잘 대처합니다. &lt;code&gt;--filter&lt;/code&gt; 옵션을 사용하거나 사용하지 않고 &lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;텍스트 기능 추출 및 평가&lt;/a&gt; 를 위해 샘플 파이프 라인을 실행 하여 결과를 비교하십시오.</target>
        </trans-unit>
        <trans-unit id="1d754add1306692cb962c5467414be940979d0ab" translate="yes" xml:space="preserve">
          <source>Some parameter settings may result in a failure to &lt;code&gt;fit&lt;/code&gt; one or more folds of the data. By default, this will cause the entire search to fail, even if some parameter settings could be fully evaluated. Setting &lt;code&gt;error_score=0&lt;/code&gt; (or &lt;code&gt;=np.NaN&lt;/code&gt;) will make the procedure robust to such failure, issuing a warning and setting the score for that fold to 0 (or &lt;code&gt;NaN&lt;/code&gt;), but completing the search.</source>
          <target state="translated">일부 매개 변수 설정으로 인해 하나 이상의 데이터 접기에 &lt;code&gt;fit&lt;/code&gt; 않을 수 있습니다 . 기본적으로 일부 매개 변수 설정이 완전히 평가 되더라도 전체 검색이 실패합니다. 설정 &lt;code&gt;error_score=0&lt;/code&gt; (또는 &lt;code&gt;=np.NaN&lt;/code&gt; ) 경고를 발행 0 (또는 해당 배의 점수를 설정, 같은 실패 절차가 강력한 것 &lt;code&gt;NaN&lt;/code&gt; 의 ), 그러나 검색을 완료.</target>
        </trans-unit>
        <trans-unit id="f29c3cd2b5860fb787d236e9a466d0e36eb10659" translate="yes" xml:space="preserve">
          <source>Some tips and tricks:</source>
          <target state="translated">몇 가지 팁과 요령 :</target>
        </trans-unit>
        <trans-unit id="63fe20eae64c7864fd32162af52c1f81421bc7d2" translate="yes" xml:space="preserve">
          <source>Sometimes it may be useful to convert the data back into the original feature space. The &lt;code&gt;inverse_transform&lt;/code&gt; function converts the binned data into the original feature space. Each value will be equal to the mean of the two bin edges.</source>
          <target state="translated">때로는 데이터를 원래 피쳐 공간으로 다시 변환하는 것이 유용 할 수 있습니다. &lt;code&gt;inverse_transform&lt;/code&gt; 의 기능은 원래의 특징 공간으로 비닝 데이터를 변환한다. 각 값은 두 개의 빈 가장자리 평균과 같습니다.</target>
        </trans-unit>
        <trans-unit id="315bc72af841ed152a9aae1c3ac0990cdcb834ed" translate="yes" xml:space="preserve">
          <source>Sometimes looking at the learned coefficients of a neural network can provide insight into the learning behavior. For example if weights look unstructured, maybe some were not used at all, or if very large coefficients exist, maybe regularization was too low or the learning rate too high.</source>
          <target state="translated">때때로 신경망의 학습 계수를 보면 학습 행동에 대한 통찰력을 제공 할 수 있습니다. 예를 들어 가중치가 구조화되지 않은 것으로 보이거나 일부가 전혀 사용되지 않았거나 계수가 매우 큰 경우 정규화가 너무 낮거나 학습 속도가 너무 높을 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="fbff2a8532eac744fd3e459bcddf3fd34f40adee" translate="yes" xml:space="preserve">
          <source>Source URL: &lt;a href=&quot;http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&quot;&gt;http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&lt;/a&gt;</source>
          <target state="translated">소스 URL : &lt;a href=&quot;http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&quot;&gt;http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="bdef929636b0e2d76c9bcc79abe376f450451dd0" translate="yes" xml:space="preserve">
          <source>Sources, where n_samples is the number of samples and n_components is the number of components.</source>
          <target state="translated">소스, 여기서 n_samples는 샘플 수이고 n_components는 구성 요소 수입니다.</target>
        </trans-unit>
        <trans-unit id="dcbe3516134bdf9c59a33ffb1c2e3120ebfb3eac" translate="yes" xml:space="preserve">
          <source>Sparse Principal Components Analysis (SparsePCA)</source>
          <target state="translated">희소 주성분 분석 (SparsePCA)</target>
        </trans-unit>
        <trans-unit id="e06472c25d26cda25191de9da3a114b1e469b208" translate="yes" xml:space="preserve">
          <source>Sparse coding</source>
          <target state="translated">희소 코딩</target>
        </trans-unit>
        <trans-unit id="32c8d921f9e1520199d1db9fe64aa6fb0f91121f" translate="yes" xml:space="preserve">
          <source>Sparse coding with a precomputed dictionary</source>
          <target state="translated">사전 계산 사전을 사용한 희소 코딩</target>
        </trans-unit>
        <trans-unit id="83cd17de4011d58af20829baa72e8c3c15415081" translate="yes" xml:space="preserve">
          <source>Sparse components extracted from the data.</source>
          <target state="translated">데이터에서 추출 된 스파 스 구성 요소.</target>
        </trans-unit>
        <trans-unit id="4aefb6aa7d814b8be3e6d2cb6f2931a1dadb31bc" translate="yes" xml:space="preserve">
          <source>Sparse input</source>
          <target state="translated">스파 스 입력</target>
        </trans-unit>
        <trans-unit id="935bf4a32a6f741a33bb9ac8e725575de63e795c" translate="yes" xml:space="preserve">
          <source>Sparse inverse covariance estimation</source>
          <target state="translated">희소 역공 분산 추정</target>
        </trans-unit>
        <trans-unit id="409d5a415f20eafd9b9f09c6ba22d21458394422" translate="yes" xml:space="preserve">
          <source>Sparse inverse covariance estimation with an l1-penalized estimator.</source>
          <target state="translated">l1 처벌 추정기로 스파 스 역공 분산 추정.</target>
        </trans-unit>
        <trans-unit id="2ee089f1e56c91604e7cab7d40e8b9f34677bb75" translate="yes" xml:space="preserve">
          <source>Sparse inverse covariance w/ cross-validated choice of the l1 penalty</source>
          <target state="translated">l1 페널티의 교차 검증 된 선택과 함께 스파 스 역공 분산</target>
        </trans-unit>
        <trans-unit id="92e371bb810dfdf353c195f32e5335e997df721c" translate="yes" xml:space="preserve">
          <source>Sparse principal components yields a more parsimonious, interpretable representation, clearly emphasizing which of the original features contribute to the differences between samples.</source>
          <target state="translated">주성분이 드물어 질수록 좀 더 이해하기 쉽고 해석하기 쉬운 표현이 만들어지며, 원래의 특징 중 어떤 것이 표본의 차이에 기여하는지 명확하게 강조합니다.</target>
        </trans-unit>
        <trans-unit id="19dbec98d9db7f8dccbc05e595e6dcc554502b17" translate="yes" xml:space="preserve">
          <source>Sparse random matrices are an alternative to dense Gaussian random projection matrix that guarantees similar embedding quality while being much more memory efficient and allowing faster computation of the projected data.</source>
          <target state="translated">희소 랜덤 매트릭스는 밀도가 높은 가우시안 랜덤 프로젝션 매트릭스의 대안으로, 훨씬 더 효율적인 메모리를 제공하고 프로젝션 된 데이터의 빠른 계산을 허용하면서 유사한 임베딩 품질을 보장합니다.</target>
        </trans-unit>
        <trans-unit id="5ad88cbdaa9d7d5c176762a66b957d3aa9661770" translate="yes" xml:space="preserve">
          <source>Sparse random matrix is an alternative to dense random projection matrix that guarantees similar embedding quality while being much more memory efficient and allowing faster computation of the projected data.</source>
          <target state="translated">스파 스 랜덤 매트릭스는 밀도가 높은 랜덤 프로젝션 매트릭스의 대안으로, 훨씬 더 효율적인 메모리를 제공하고 프로젝션 된 데이터의 빠른 계산을 허용하면서 유사한 임베딩 품질을 보장합니다.</target>
        </trans-unit>
        <trans-unit id="a7a844fc75c56ce03e1afce70cb2355152140d0b" translate="yes" xml:space="preserve">
          <source>Sparsity</source>
          <target state="translated">Sparsity</target>
        </trans-unit>
        <trans-unit id="814e5a7e79ded720eafc96bc0232cca516d50079" translate="yes" xml:space="preserve">
          <source>Sparsity Example: Fitting only features 1 and 2</source>
          <target state="translated">희소성 예 : 피처 1과 2 만 피팅</target>
        </trans-unit>
        <trans-unit id="43cddceab3d136418b0e03e98d360e468cf1b8e5" translate="yes" xml:space="preserve">
          <source>Sparsity controlling parameter.</source>
          <target state="translated">희소성 제어 파라미터.</target>
        </trans-unit>
        <trans-unit id="647e2a8c2a361b51e5b69ed284ca76c83752d0f6" translate="yes" xml:space="preserve">
          <source>Sparsity controlling parameter. Higher values lead to sparser components.</source>
          <target state="translated">희소성 제어 파라미터. 값이 클수록 스파 스 구성 요소가 생성됩니다.</target>
        </trans-unit>
        <trans-unit id="1a82be20d822213cd6b317bb5903a0613a76bafa" translate="yes" xml:space="preserve">
          <source>Species distribution modeling</source>
          <target state="translated">종 분포 모델링</target>
        </trans-unit>
        <trans-unit id="37195f9a92f1ed14e524a0ed92aab116b735c4ea" translate="yes" xml:space="preserve">
          <source>Specific parameters using e.g. set_params(parameter_name=new_value) In addition, to setting the parameters of the &lt;code&gt;VotingClassifier&lt;/code&gt;, the individual classifiers of the &lt;code&gt;VotingClassifier&lt;/code&gt; can also be set or replaced by setting them to None.</source>
          <target state="translated">예를 들어 set_params (parameter_name = new_value)를 사용하는 특정 매개 변수 또한 &lt;code&gt;VotingClassifier&lt;/code&gt; 의 매개 변수를 설정하는 것 외에도 VotingClassifier 의 개별 분류 기준 을 None으로 설정하여 설정하거나 &lt;code&gt;VotingClassifier&lt;/code&gt; 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="94e374689a4595b916bcf5e66713548e054c55c6" translate="yes" xml:space="preserve">
          <source>Specific weights can be assigned to each classifier via the &lt;code&gt;weights&lt;/code&gt; parameter. When weights are provided, the predicted class probabilities for each classifier are collected, multiplied by the classifier weight, and averaged. The final class label is then derived from the class label with the highest average probability.</source>
          <target state="translated">&lt;code&gt;weights&lt;/code&gt; 매개 변수 를 통해 각 분류기에 특정 가중치를 지정할 수 있습니다 . 가중치가 제공되면 각 분류 자에 대해 예측 된 클래스 확률이 수집되고 분류 자 ​​가중치를 곱한 후 평균화됩니다. 그런 다음 최종 클래스 레이블은 평균 확률이 가장 높은 클래스 레이블에서 파생됩니다.</target>
        </trans-unit>
        <trans-unit id="8fbbf3fe05797ad1e4c717c36a5a204246056853" translate="yes" xml:space="preserve">
          <source>Specifies how multi-class classification problems are handled. Supported are &amp;ldquo;one_vs_rest&amp;rdquo; and &amp;ldquo;one_vs_one&amp;rdquo;. In &amp;ldquo;one_vs_rest&amp;rdquo;, one binary Gaussian process classifier is fitted for each class, which is trained to separate this class from the rest. In &amp;ldquo;one_vs_one&amp;rdquo;, one binary Gaussian process classifier is fitted for each pair of classes, which is trained to separate these two classes. The predictions of these binary predictors are combined into multi-class predictions. Note that &amp;ldquo;one_vs_one&amp;rdquo; does not support predicting probability estimates.</source>
          <target state="translated">다중 클래스 분류 문제가 처리되는 방법을 지정합니다. &quot;one_vs_rest&quot;및 &quot;one_vs_one&quot;이 지원됩니다. &amp;ldquo;one_vs_rest&amp;rdquo;에서는 각 클래스마다 하나의 이진 가우시안 프로세스 분류 기가 장착되며이 클래스는 나머지 클래스와 분리되도록 훈련됩니다. &amp;ldquo;one_vs_one&amp;rdquo;에서 각 쌍의 클래스에 대해 하나의 이진 가우시안 프로세스 분류 기가 적합하며,이 두 클래스를 분리하도록 훈련됩니다. 이 이진 예측 변수의 예측은 다중 클래스 예측으로 결합됩니다. &amp;ldquo;one_vs_one&amp;rdquo;은 예측 확률 예측을 지원하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="9bddb5670bf596fd4f95945fb300823355f1c46f" translate="yes" xml:space="preserve">
          <source>Specifies if a constant (a.k.a. bias or intercept) should be added to the decision function.</source>
          <target state="translated">결정 함수에 상수 (일명 바이어스 또는 절편)를 추가해야하는지 여부를 지정합니다.</target>
        </trans-unit>
        <trans-unit id="032e8ae2185962af612ef54804c68499bb10a9e0" translate="yes" xml:space="preserve">
          <source>Specifies if the estimated precision is stored.</source>
          <target state="translated">추정 정밀도가 저장되는지 여부를 지정합니다.</target>
        </trans-unit>
        <trans-unit id="d38faf7dee61c2f434029c24d24417f5a7a63648" translate="yes" xml:space="preserve">
          <source>Specifies if the intercept should be fitted by the model. It must match the fit() method parameter.</source>
          <target state="translated">절편을 모형에 맞아야하는지 지정합니다. fit () 메소드 매개 변수와 일치해야합니다.</target>
        </trans-unit>
        <trans-unit id="21164bb750beb75acb9ae9d1f3fb116169b84f4e" translate="yes" xml:space="preserve">
          <source>Specifies the kernel type to be used in the algorithm. It must be one of &amp;lsquo;linear&amp;rsquo;, &amp;lsquo;poly&amp;rsquo;, &amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;sigmoid&amp;rsquo;, &amp;lsquo;precomputed&amp;rsquo; or a callable. If none is given, &amp;lsquo;rbf&amp;rsquo; will be used. If a callable is given it is used to pre-compute the kernel matrix from data matrices; that matrix should be an array of shape &lt;code&gt;(n_samples, n_samples)&lt;/code&gt;.</source>
          <target state="translated">알고리즘에 사용될 커널 유형을 지정합니다. 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'또는 callable 중 하나 여야합니다. 아무 것도 지정하지 않으면 'rbf'가 사용됩니다. 콜 러블이 주어지면 데이터 행렬에서 커널 행렬을 사전 계산하는 데 사용됩니다. 해당 행렬은 모양의 배열이어야합니다 &lt;code&gt;(n_samples, n_samples)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7717364640e0a660ec81dfa33f675030f243fdf0" translate="yes" xml:space="preserve">
          <source>Specifies the kernel type to be used in the algorithm. It must be one of &amp;lsquo;linear&amp;rsquo;, &amp;lsquo;poly&amp;rsquo;, &amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;sigmoid&amp;rsquo;, &amp;lsquo;precomputed&amp;rsquo; or a callable. If none is given, &amp;lsquo;rbf&amp;rsquo; will be used. If a callable is given it is used to precompute the kernel matrix.</source>
          <target state="translated">알고리즘에 사용될 커널 유형을 지정합니다. 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'또는 callable 중 하나 여야합니다. 아무 것도 지정하지 않으면 'rbf'가 사용됩니다. 콜 러블이 주어지면 커널 매트릭스를 사전 계산하는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="b9435d1c3c2633287cc32557661450b6f00ca78e" translate="yes" xml:space="preserve">
          <source>Specifies the loss function. &amp;lsquo;hinge&amp;rsquo; is the standard SVM loss (used e.g. by the SVC class) while &amp;lsquo;squared_hinge&amp;rsquo; is the square of the hinge loss.</source>
          <target state="translated">손실 함수를 지정합니다. 'hinge'는 표준 SVM 손실 (예 : SVC 클래스에서 사용)이며 'squared_hinge'는 힌지 손실의 제곱입니다.</target>
        </trans-unit>
        <trans-unit id="68150facd38948e362a68f70eea508701955b6e7" translate="yes" xml:space="preserve">
          <source>Specifies the loss function. The epsilon-insensitive loss (standard SVR) is the L1 loss, while the squared epsilon-insensitive loss (&amp;lsquo;squared_epsilon_insensitive&amp;rsquo;) is the L2 loss.</source>
          <target state="translated">손실 함수를 지정합니다. 입실론에 둔감 한 손실 (표준 SVR)은 L1 손실이고, 입실론에 둔감 한 제곱 손실 ( 'squared_epsilon_insensitive')은 L2 손실입니다.</target>
        </trans-unit>
        <trans-unit id="1b5fabde85275fd0a5eb3f705ddd6c262b6e1ace" translate="yes" xml:space="preserve">
          <source>Specifies the loss function. With &amp;lsquo;squared_hinge&amp;rsquo; it is the squared hinge loss (a.k.a. L2 loss). With &amp;lsquo;log&amp;rsquo; it is the loss of logistic regression models.</source>
          <target state="translated">손실 함수를 지정합니다. 'squared_hinge'를 사용하면 제곱 된 힌지 손실 (일명 L2 손실)입니다. 'log'를 사용하면 로지스틱 회귀 모델이 손실됩니다.</target>
        </trans-unit>
        <trans-unit id="82fe667ff963f19359a5dba7024bcea48fa12322" translate="yes" xml:space="preserve">
          <source>Specifies the norm used in the penalization. The &amp;lsquo;l2&amp;rsquo; penalty is the standard used in SVC. The &amp;lsquo;l1&amp;rsquo; leads to &lt;code&gt;coef_&lt;/code&gt; vectors that are sparse.</source>
          <target state="translated">벌칙에 사용되는 표준을 지정합니다. 'l2'페널티는 SVC에서 사용되는 표준입니다. '1' 은 희소 한 &lt;code&gt;coef_&lt;/code&gt; 벡터로 이어진다 .</target>
        </trans-unit>
        <trans-unit id="5a337b6de37f25f0ac3016f29ff1f6486795a255" translate="yes" xml:space="preserve">
          <source>Specifies the returned model. Select &lt;code&gt;'lar'&lt;/code&gt; for Least Angle Regression, &lt;code&gt;'lasso'&lt;/code&gt; for the Lasso.</source>
          <target state="translated">반환 된 모델을 지정합니다. 선택 &lt;code&gt;'lar'&lt;/code&gt; 최소위한 각도 회귀, &lt;code&gt;'lasso'&lt;/code&gt; 올가미에 대해.</target>
        </trans-unit>
        <trans-unit id="32ab0cdbec2fd77050a55d02bdf5982ebc80779f" translate="yes" xml:space="preserve">
          <source>Specify a download and cache folder for the datasets. If None, all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="translated">데이터 세트의 다운로드 및 캐시 폴더를 지정하십시오. None 인 경우 모든 scikit-learn 데이터는 '~ / scikit_learn_data'하위 폴더에 저장됩니다.</target>
        </trans-unit>
        <trans-unit id="5a7f883c69415d4b4614ca7ec1c25ea069f17592" translate="yes" xml:space="preserve">
          <source>Specify an download and cache folder for the datasets. If None, all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="translated">데이터 세트의 다운로드 및 캐시 폴더를 지정하십시오. None 인 경우 모든 scikit-learn 데이터는 '~ / scikit_learn_data'하위 폴더에 저장됩니다.</target>
        </trans-unit>
        <trans-unit id="bef377c44b3d810cadc5cf65c208d01924bfa02c" translate="yes" xml:space="preserve">
          <source>Specify another download and cache folder for the data sets. By default all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="translated">데이터 세트에 다른 다운로드 및 캐시 폴더를 지정하십시오. 기본적으로 모든 scikit-learn 데이터는 '~ / scikit_learn_data'하위 폴더에 저장됩니다.</target>
        </trans-unit>
        <trans-unit id="db707a2b2d7445205a990e044438fdad3fa08a72" translate="yes" xml:space="preserve">
          <source>Specify another download and cache folder for the datasets. By default all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="translated">데이터 세트에 다른 다운로드 및 캐시 폴더를 지정하십시오. 기본적으로 모든 scikit-learn 데이터는 '~ / scikit_learn_data'하위 폴더에 저장됩니다.</target>
        </trans-unit>
        <trans-unit id="e0a4c5302feb0239f945ee7ba84757ae55a6d243" translate="yes" xml:space="preserve">
          <source>Specify another download and cache folder for the datasets. By default all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders. .. versionadded:: 0.19</source>
          <target state="translated">데이터 세트에 다른 다운로드 및 캐시 폴더를 지정하십시오. 기본적으로 모든 scikit-learn 데이터는 '~ / scikit_learn_data'하위 폴더에 저장됩니다. .. 버전 추가 :: 0.19</target>
        </trans-unit>
        <trans-unit id="3a104a4391c92d3464c7b1efaf07c449c778bcc9" translate="yes" xml:space="preserve">
          <source>Specify if the estimated precision is stored</source>
          <target state="translated">추정 정밀도가 저장되는지 지정</target>
        </trans-unit>
        <trans-unit id="68d4702fc734cffadd8a1ccf005f0aff7fa648f2" translate="yes" xml:space="preserve">
          <source>Specify if the estimated precision is stored.</source>
          <target state="translated">추정 정밀도가 저장되는지 여부를 지정하십시오.</target>
        </trans-unit>
        <trans-unit id="4984f447cb8f4f521871d2431cae9f4220dfb519" translate="yes" xml:space="preserve">
          <source>Specify the column name in the data to use as target. If &amp;lsquo;default-target&amp;rsquo;, the standard target column a stored on the server is used. If &lt;code&gt;None&lt;/code&gt;, all columns are returned as data and the target is &lt;code&gt;None&lt;/code&gt;. If list (of strings), all columns with these names are returned as multi-target (Note: not all scikit-learn classifiers can handle all types of multi-output combinations)</source>
          <target state="translated">대상으로 사용할 데이터의 열 이름을 지정하십시오. 'default-target'인 경우 서버에 저장된 표준 대상 열 a가 사용됩니다. 경우 &lt;code&gt;None&lt;/code&gt; , 모든 열은 데이터로 반환 대상이 아니다 &lt;code&gt;None&lt;/code&gt; . (문자열) 목록 인 경우 이러한 이름을 가진 모든 열이 다중 대상으로 반환됩니다 (참고 : 모든 scikit-learn 분류 기가 모든 유형의 다중 출력 조합을 처리 할 수있는 것은 아닙니다)</target>
        </trans-unit>
        <trans-unit id="86eb3ad2a989c13695b9d85dcb05b7c45343a61d" translate="yes" xml:space="preserve">
          <source>Specify the desired relative and absolute tolerance of the result. If the true result is K_true, then the returned result K_ret satisfies &lt;code&gt;abs(K_true - K_ret) &amp;lt; atol + rtol * K_ret&lt;/code&gt; The default is zero (i.e. machine precision) for both.</source>
          <target state="translated">결과의 원하는 상대 및 절대 공차를 지정하십시오. 실제 결과가 K_true이면 반환 된 결과 K_ret은 &lt;code&gt;abs(K_true - K_ret) &amp;lt; atol + rtol * K_ret&lt;/code&gt; . 기본값은 모두 0입니다 (예 : 기계 정밀도).</target>
        </trans-unit>
        <trans-unit id="0742682745f85d107eacd49ea30a7e49015c565b" translate="yes" xml:space="preserve">
          <source>Specify the leaf size of the underlying tree. See &lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt;&lt;code&gt;KDTree&lt;/code&gt;&lt;/a&gt; for details. Default is 40.</source>
          <target state="translated">기본 트리의 리프 크기를 지정하십시오. 자세한 내용은 &lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; &lt;/a&gt; 또는 &lt;a href=&quot;sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt; &lt;code&gt;KDTree&lt;/code&gt; &lt;/a&gt; 를 참조하십시오. 기본값은 40입니다.</target>
        </trans-unit>
        <trans-unit id="a3eb34c47a1823aab704036791431543ed289a4a" translate="yes" xml:space="preserve">
          <source>Specify the parallelization backend implementation. Supported backends are:</source>
          <target state="translated">병렬화 백엔드 구현을 지정하십시오. 지원되는 백엔드는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="9ef7e5427d37487b864821803fe9613488fa8ce1" translate="yes" xml:space="preserve">
          <source>Specify the size of the kernel cache (in MB).</source>
          <target state="translated">커널 캐시의 크기를 MB 단위로 지정하십시오.</target>
        </trans-unit>
        <trans-unit id="4329e4ac0b424da2818ac12cc4d13ce3581c4d3d" translate="yes" xml:space="preserve">
          <source>Specify what features are treated as categorical.</source>
          <target state="translated">범주로 취급되는 기능을 지정하십시오.</target>
        </trans-unit>
        <trans-unit id="7d724db10f986282e8a5446f219cdacdbcddece6" translate="yes" xml:space="preserve">
          <source>Specify whether all or any of the given attributes must exist.</source>
          <target state="translated">주어진 속성 중 일부 또는 전부가 존재해야하는지 여부를 지정하십시오.</target>
        </trans-unit>
        <trans-unit id="d079850de1341ae0792b165a2e4c64406a6bf6cd" translate="yes" xml:space="preserve">
          <source>Specifying how parameters should be sampled is done using a dictionary, very similar to specifying parameters for &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt;. Additionally, a computation budget, being the number of sampled candidates or sampling iterations, is specified using the &lt;code&gt;n_iter&lt;/code&gt; parameter. For each parameter, either a distribution over possible values or a list of discrete choices (which will be sampled uniformly) can be specified:</source>
          <target state="translated">매개 변수의 샘플링 방법 지정은 &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; 에&lt;/a&gt; 대한 매개 변수 지정과 매우 유사한 사전을 사용하여 수행됩니다 . 또한 샘플링 된 후보 또는 샘플링 반복의 수인 계산 예산은 &lt;code&gt;n_iter&lt;/code&gt; 매개 변수를 사용하여 지정 됩니다. 각 매개 변수에 대해 가능한 값에 대한 분포 또는 개별 선택 목록 (균일하게 샘플링 됨)을 지정할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="848f2bc6fd9feea5a4bd159161ff60b7b7f1ad05" translate="yes" xml:space="preserve">
          <source>Specifying the dataset by the name &amp;ldquo;iris&amp;rdquo; yields the lowest version, version 1, with the &lt;code&gt;data_id&lt;/code&gt; 61. To make sure you always get this exact dataset, it is safest to specify it by the dataset &lt;code&gt;data_id&lt;/code&gt;. The other dataset, with &lt;code&gt;data_id&lt;/code&gt; 969, is version 3 (version 2 has become inactive), and contains a binarized version of the data:</source>
          <target state="translated">가장 낮은 버전, 버전 1이으로, 이름이 &quot;아이리스&quot;에 의해 데이터 집합을 산출 지정 &lt;code&gt;data_id&lt;/code&gt; 61 것은 당신이 항상 정확한 데이터 세트를 얻을 수 있도록하기 위해, 데이터 집합하여 지정하는 것이 가장 안전 &lt;code&gt;data_id&lt;/code&gt; . &lt;code&gt;data_id&lt;/code&gt; 가 969 인 다른 데이터 세트 는 버전 3 (버전 2는 비활성화 됨)이며 이진화 된 버전의 데이터를 포함합니다.</target>
        </trans-unit>
        <trans-unit id="3df7d54bd992cb63f5a75a6f7de49938e89cdde2" translate="yes" xml:space="preserve">
          <source>Spectral Clustering can also be used to cluster graphs by their spectral embeddings. In this case, the affinity matrix is the adjacency matrix of the graph, and SpectralClustering is initialized with &lt;code&gt;affinity=&amp;rsquo;precomputed&amp;rsquo;&lt;/code&gt;:</source>
          <target state="translated">스펙트럼 클러스터링을 사용하여 스펙트럼 임베딩으로 그래프를 클러스터링 할 수도 있습니다. 이 경우 선호도 행렬은 그래프의 인접 행렬이며 SpectralClustering은 &lt;code&gt;affinity=&amp;rsquo;precomputed&amp;rsquo;&lt;/code&gt; 초기화됩니다 .</target>
        </trans-unit>
        <trans-unit id="943c880ba7aef37194c447e5760436985518b340" translate="yes" xml:space="preserve">
          <source>Spectral Co-Clustering algorithm (Dhillon, 2001).</source>
          <target state="translated">스펙트럼 공동-클러스터링 알고리즘 (Dhillon, 2001).</target>
        </trans-unit>
        <trans-unit id="5c8a907562e6db42ff15e9df5a0d9b0b21be7b5f" translate="yes" xml:space="preserve">
          <source>Spectral Embedding (Laplacian Eigenmaps) is most useful when the graph has one connected component. If there graph has many components, the first few eigenvectors will simply uncover the connected components of the graph.</source>
          <target state="translated">스펙트럼 임베딩 (Laplacian Eigenmaps)은 그래프에 연결된 구성 요소가 하나있을 때 가장 유용합니다. 그래프에 많은 성분이있는 경우 처음 몇 개의 고유 벡터는 단순히 그래프의 연결된 성분을 찾아냅니다.</target>
        </trans-unit>
        <trans-unit id="7ff62a97384e4faf388cb99bbcc076cbdae4a5ec" translate="yes" xml:space="preserve">
          <source>Spectral Embedding is an approach to calculating a non-linear embedding. Scikit-learn implements Laplacian Eigenmaps, which finds a low dimensional representation of the data using a spectral decomposition of the graph Laplacian. The graph generated can be considered as a discrete approximation of the low dimensional manifold in the high dimensional space. Minimization of a cost function based on the graph ensures that points close to each other on the manifold are mapped close to each other in the low dimensional space, preserving local distances. Spectral embedding can be performed with the function &lt;a href=&quot;generated/sklearn.manifold.spectral_embedding#sklearn.manifold.spectral_embedding&quot;&gt;&lt;code&gt;spectral_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.spectralembedding#sklearn.manifold.SpectralEmbedding&quot;&gt;&lt;code&gt;SpectralEmbedding&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">스펙트럼 임베딩은 비선형 임베딩을 계산하는 방법입니다. Scikit-learn은 Laplacian Eigenmaps를 구현합니다. Laplacian Eigenmaps는 Laplacian 그래프의 스펙트럼 분해를 사용하여 데이터의 저 차원 표현을 찾습니다. 생성 된 그래프는 고차원 공간에서 저 차원 매니 폴드의 불연속 근사치로 간주 될 수 있습니다. 그래프를 기반으로 비용 함수를 최소화하면 매니 폴드에서 서로 가까이있는 점이 저 차원 공간에서 서로 가깝게 매핑되어 로컬 거리를 유지합니다. 스펙트럼은 매립 함수로 수행 될 수 &lt;a href=&quot;generated/sklearn.manifold.spectral_embedding#sklearn.manifold.spectral_embedding&quot;&gt; &lt;code&gt;spectral_embedding&lt;/code&gt; &lt;/a&gt; 또는 객체 지향 상대 &lt;a href=&quot;generated/sklearn.manifold.spectralembedding#sklearn.manifold.SpectralEmbedding&quot;&gt; &lt;code&gt;SpectralEmbedding&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="3266962963ccf3ff289e43e7853a5feea31fa6fe" translate="yes" xml:space="preserve">
          <source>Spectral biclustering (Kluger, 2003).</source>
          <target state="translated">스펙트럼 biclustering (Kluger, 2003).</target>
        </trans-unit>
        <trans-unit id="83334448105603952db5b041593dddc0f02ac19b" translate="yes" xml:space="preserve">
          <source>Spectral biclustering algorithms.</source>
          <target state="translated">스펙트럼 바이 블러스터 링 알고리즘.</target>
        </trans-unit>
        <trans-unit id="3fddf3521d69d12bc13710d54a4adc12aa85f512" translate="yes" xml:space="preserve">
          <source>Spectral clustering</source>
          <target state="translated">스펙트럼 클러스터링</target>
        </trans-unit>
        <trans-unit id="453e3a7c69660270eecfb13dabf16149c8b4512b" translate="yes" xml:space="preserve">
          <source>Spectral clustering for image segmentation</source>
          <target state="translated">이미지 세분화를위한 스펙트럼 클러스터링</target>
        </trans-unit>
        <trans-unit id="f9409615dd1103c73760717b8600df9e2157d615" translate="yes" xml:space="preserve">
          <source>Spectral embedding for non-linear dimensionality reduction.</source>
          <target state="translated">비선형 차원 축소를위한 스펙트럼 임베딩.</target>
        </trans-unit>
        <trans-unit id="8a0801a4fb2ecc40bcf6f04aa745ad2e1056e690" translate="yes" xml:space="preserve">
          <source>Spectral embedding of the training matrix.</source>
          <target state="translated">트레이닝 매트릭스의 스펙트럼 임베딩.</target>
        </trans-unit>
        <trans-unit id="063a83567f47ad5f5679accf564d96c923566ee9" translate="yes" xml:space="preserve">
          <source>Speed:</source>
          <target state="translated">Speed:</target>
        </trans-unit>
        <trans-unit id="7d07f6cca3dbed6cdb804f0e2864e093c6647564" translate="yes" xml:space="preserve">
          <source>Split arrays or matrices into random train and test subsets</source>
          <target state="translated">배열 또는 행렬을 임의의 기차 및 테스트 하위 집합으로 분할</target>
        </trans-unit>
        <trans-unit id="5e854ececac820d9fb56cdde854f788365393cf5" translate="yes" xml:space="preserve">
          <source>Splits it into K folds, trains on K-1 and then tests on the left-out.</source>
          <target state="translated">그것을 K 폴드로 나누고 K-1을 훈련시킨 다음 왼쪽에서 테스트합니다.</target>
        </trans-unit>
        <trans-unit id="c2518ac986a45f6943dccb55ec28e7fc9787e8f9" translate="yes" xml:space="preserve">
          <source>Splitter Classes</source>
          <target state="translated">스플리터 클래스</target>
        </trans-unit>
        <trans-unit id="474933f1a999ce205b180d93539f6dbb5b05050e" translate="yes" xml:space="preserve">
          <source>Splitter Functions</source>
          <target state="translated">스플리터 기능</target>
        </trans-unit>
        <trans-unit id="01474e72e0404f40fd189e5ac7233925222e580d" translate="yes" xml:space="preserve">
          <source>Squared L2 norms of the lines of y. Required if tol is not None.</source>
          <target state="translated">y 선의 제곱 된 L2 규범. tol이 None이 아닌 경우 필수입니다.</target>
        </trans-unit>
        <trans-unit id="89cdcd77a950e009dab4164bc976d2f6ebb6b9e7" translate="yes" xml:space="preserve">
          <source>Squared Mahalanobis distances of the observations.</source>
          <target state="translated">관측치의 제곱 된 Mahalanobis 거리.</target>
        </trans-unit>
        <trans-unit id="a0b13f625123904866bd60e38bc7611ba95c992c" translate="yes" xml:space="preserve">
          <source>Squared Sum - Sum of the squared L2 norm of all samples.</source>
          <target state="translated">제곱합-모든 샘플의 제곱 된 L2 규범의 합입니다.</target>
        </trans-unit>
        <trans-unit id="1c1f19010d2ef30728a1e3cec08abc7bd4b0d974" translate="yes" xml:space="preserve">
          <source>Squared norm of the centroids.</source>
          <target state="translated">중심의 제곱 규범.</target>
        </trans-unit>
        <trans-unit id="ff4530f7332d92145f70c600e76bef65d08e2445" translate="yes" xml:space="preserve">
          <source>Stability path based on randomized Lasso estimates</source>
          <target state="translated">무작위 올가미 추정치에 기반한 안정성 경로</target>
        </trans-unit>
        <trans-unit id="9a5fecba5d8d30ecb602724233c6166d767b3036" translate="yes" xml:space="preserve">
          <source>Stability selection Nicolai Meinshausen, Peter Buhlmann Journal of the Royal Statistical Society: Series B Volume 72, Issue 4, pages 417-473, September 2010 DOI: 10.1111/j.1467-9868.2010.00740.x</source>
          <target state="translated">안정성 선택 Nicolai Meinshausen, Peter Buhlmann The Royal Statistical Society : Series B Volume 72, Issue 4, page 417-473, 2010 년 9 월 DOI : 10.1111 / j.1467-9868.2010.00740.x</target>
        </trans-unit>
        <trans-unit id="891f1b1c9f204fa14cf72f5b45193c02a0d262be" translate="yes" xml:space="preserve">
          <source>Standard deviation of Gaussian noise added to the data.</source>
          <target state="translated">데이터에 가우스 잡음의 표준 편차가 추가되었습니다.</target>
        </trans-unit>
        <trans-unit id="f806d5207c92015615b11e0738f918dc0548c864" translate="yes" xml:space="preserve">
          <source>Standard deviation of predictive distribution at query points. Only returned when return_std is True.</source>
          <target state="translated">쿼리 지점에서 예측 분포의 표준 편차입니다. return_std가 True 인 경우에만 반환됩니다.</target>
        </trans-unit>
        <trans-unit id="6edd185d8d7cdfc859bd82ca69e1fcc7af90edcd" translate="yes" xml:space="preserve">
          <source>Standard deviation of predictive distribution of query points.</source>
          <target state="translated">쿼리 지점의 예측 분포에 대한 표준 편차입니다.</target>
        </trans-unit>
        <trans-unit id="ea11cb9dbd7c4fc006fb08938b76124b12688d69" translate="yes" xml:space="preserve">
          <source>StandardScaler</source>
          <target state="translated">StandardScaler</target>
        </trans-unit>
        <trans-unit id="9f96721b99a0217af973cbedbcbf7d1fa7440aeb" translate="yes" xml:space="preserve">
          <source>Standardization of a dataset is a common requirement for many machine learning estimators. Typically this is done by removing the mean and scaling to unit variance. However, outliers can often influence the sample mean / variance in a negative way. In such cases, the median and the interquartile range often give better results.</source>
          <target state="translated">데이터 세트의 표준화는 많은 머신 러닝 추정기의 공통 요구 사항입니다. 일반적으로 이것은 평균을 제거하고 단위 분산으로 스케일링하여 수행됩니다. 그러나 특이 치가 종종 표본 평균 / 분산에 부정적인 영향을 줄 수 있습니다. 이러한 경우, 중앙값과 사 분위수 범위는 종종 더 나은 결과를 제공합니다.</target>
        </trans-unit>
        <trans-unit id="3845481860a037ebc5c39c64e8de0e95fe45e3fb" translate="yes" xml:space="preserve">
          <source>Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance).</source>
          <target state="translated">데이터 셋의 표준화는 많은 머신 러닝 추정기의 공통 요구 사항입니다. 개별 기능이 표준 정규 분포 데이터 (예 : 평균이 0이고 단위 분산이있는 가우시안)와 다소 비슷하지 않은 경우 제대로 작동하지 않을 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="781aef30981524e4bc3b3ab4682d7e1b6f686dcb" translate="yes" xml:space="preserve">
          <source>Standardize a dataset along any axis</source>
          <target state="translated">모든 축을 따라 데이터 세트 표준화</target>
        </trans-unit>
        <trans-unit id="8089cb9b9abb90199844c7f8d2ad6ef5ad6b9827" translate="yes" xml:space="preserve">
          <source>Standardize features by removing the mean and scaling to unit variance</source>
          <target state="translated">평균을 제거하고 단위 분산으로 스케일링하여 기능 표준화</target>
        </trans-unit>
        <trans-unit id="070fc0ca4dc6d3cb17aee36f0432a76e85e66a77" translate="yes" xml:space="preserve">
          <source>Start pointer to all the leaves.</source>
          <target state="translated">모든 나뭇잎에 대한 포인터를 시작하십시오.</target>
        </trans-unit>
        <trans-unit id="08a6668f9a564bddd6d8fa9fd4934eeea4b017c7" translate="yes" xml:space="preserve">
          <source>Starting configuration of the embedding to initialize the SMACOF algorithm. By default, the algorithm is initialized with a randomly chosen array.</source>
          <target state="translated">SMACOF 알고리즘을 초기화하기위한 임베딩 구성 시작 기본적으로 알고리즘은 임의로 선택된 배열로 초기화됩니다.</target>
        </trans-unit>
        <trans-unit id="7252947fdd6406b9475a3bf1b686e53848838289" translate="yes" xml:space="preserve">
          <source>Starting configuration of the embedding to initialize the algorithm. By default, the algorithm is initialized with a randomly chosen array.</source>
          <target state="translated">알고리즘을 초기화하기 위해 임베딩 구성을 시작합니다. 기본적으로 알고리즘은 임의로 선택된 배열로 초기화됩니다.</target>
        </trans-unit>
        <trans-unit id="91cd41feb47c4fc7679dfd69c834b11820027a8b" translate="yes" xml:space="preserve">
          <source>Starting from initial random weights, multi-layer perceptron (MLP) minimizes the loss function by repeatedly updating these weights. After computing the loss, a backward pass propagates it from the output layer to the previous layers, providing each weight parameter with an update value meant to decrease the loss.</source>
          <target state="translated">초기 임의 가중치부터 MLP (Multi-Layer Perceptron)는 이러한 가중치를 반복적으로 업데이트하여 손실 기능을 최소화합니다. 손실을 계산 한 후, 역방향 통과는 출력 계층에서 이전 계층으로 전달하여 각 가중치 매개 변수에 손실을 줄이기위한 업데이트 값을 제공합니다.</target>
        </trans-unit>
        <trans-unit id="fcf350fa97b4ef940922ec2e36ae5accc928bb98" translate="yes" xml:space="preserve">
          <source>Starting node for path</source>
          <target state="translated">경로의 시작 노드</target>
        </trans-unit>
        <trans-unit id="bed5865b6136905da0496b8ae96a4873f78bef72" translate="yes" xml:space="preserve">
          <source>Stat Ass, 79:871, 1984.</source>
          <target state="translated">Stat Ass, 79 : 871, 1984.</target>
        </trans-unit>
        <trans-unit id="6493ce2cca639b99501821839727266114fab06b" translate="yes" xml:space="preserve">
          <source>Statistical learning</source>
          <target state="translated">통계 학습</target>
        </trans-unit>
        <trans-unit id="ff430697ec62291221833385a34a445a9ee9ecdf" translate="yes" xml:space="preserve">
          <source>Statistical learning: the setting and the estimator object in scikit-learn</source>
          <target state="translated">통계 학습 : scikit-learn의 설정 및 추정기 개체</target>
        </trans-unit>
        <trans-unit id="a673f9d4e8314126b08e8f81bb3a33f3d78b1e09" translate="yes" xml:space="preserve">
          <source>Still effective in cases where number of dimensions is greater than the number of samples.</source>
          <target state="translated">치수 수가 샘플 수보다 큰 경우에도 여전히 효과적입니다.</target>
        </trans-unit>
        <trans-unit id="2473d40abe8e9fb2e7f524b8bad4d74240273fa9" translate="yes" xml:space="preserve">
          <source>Stochastic Gradient Descent</source>
          <target state="translated">확률 적 경사 하강</target>
        </trans-unit>
        <trans-unit id="195b32448a080f6c15b39de98057b7fe1bc4693b" translate="yes" xml:space="preserve">
          <source>Stochastic Gradient Descent is an optimization technique which minimizes a loss function in a stochastic fashion, performing a gradient descent step sample by sample. In particular, it is a very efficient method to fit linear models.</source>
          <target state="translated">확률 적 그라디언트 디센트는 확률 적 방식으로 손실 함수를 최소화하여 샘플별로 그라디언트 디센트 단계를 수행하는 최적화 기술입니다. 특히 선형 모델에 맞는 매우 효율적인 방법입니다.</target>
        </trans-unit>
        <trans-unit id="e3aa3ce34d4d1d755f86485089b5a4b4f435a8e2" translate="yes" xml:space="preserve">
          <source>Stochastic Gradient Descent is sensitive to feature scaling, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to [0,1] or [-1,+1], or standardize it to have mean 0 and variance 1. Note that the &lt;em&gt;same&lt;/em&gt; scaling must be applied to the test vector to obtain meaningful results. This can be easily done using &lt;code&gt;StandardScaler&lt;/code&gt;:</source>
          <target state="translated">확률 적 그라데이션 하강은 기능 스케일링에 민감하므로 데이터를 스케일링하는 것이 좋습니다. 예를 들어 입력 벡터 X의 각 속성을 [0,1] 또는 [-1, + 1]로 스케일링 하거나 평균 0과 분산 1을 갖도록 표준화하십시오 . 테스트 벡터에도 &lt;em&gt;동일한&lt;/em&gt; 스케일링을 적용해야합니다. 의미있는 결과를 얻습니다. 이는 &lt;code&gt;StandardScaler&lt;/code&gt; 를 사용하여 쉽게 수행 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="ee01e77469d8f50feb7b1b4735d433d85aa0d812" translate="yes" xml:space="preserve">
          <source>Stochastic gradient boosting allows to compute out-of-bag estimates of the test deviance by computing the improvement in deviance on the examples that are not included in the bootstrap sample (i.e. the out-of-bag examples). The improvements are stored in the attribute &lt;code&gt;oob_improvement_&lt;/code&gt;. &lt;code&gt;oob_improvement_[i]&lt;/code&gt; holds the improvement in terms of the loss on the OOB samples if you add the i-th stage to the current predictions. Out-of-bag estimates can be used for model selection, for example to determine the optimal number of iterations. OOB estimates are usually very pessimistic thus we recommend to use cross-validation instead and only use OOB if cross-validation is too time consuming.</source>
          <target state="translated">확률 적 그래디언트 부스팅을 사용하면 부트 스트랩 샘플에 포함되지 않은 예 (예 : 가방 외부 예)에 대한 편차 개선을 계산하여 테스트 편차의 가방 외부 추정값을 계산할 수 있습니다. 개선 사항은 &lt;code&gt;oob_improvement_&lt;/code&gt; 속성에 저장됩니다 . &lt;code&gt;oob_improvement_[i]&lt;/code&gt; 는 i 번째 단계를 현재 예측에 추가하면 OOB 샘플의 손실 측면에서 개선점을 유지합니다. 최적의 반복 횟수를 결정하기 위해 백 아웃 추정을 모델 선택에 사용할 수 있습니다. OOB 추정치는 일반적으로 매우 비관적이므로 교차 유효성 검사를 대신 사용하고 교차 유효성 검사에 너무 많은 시간이 소요되는 경우에만 OOB를 사용하는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="5823a3f0a9a6ed167c583e77307156305a3e83ac" translate="yes" xml:space="preserve">
          <source>Stochastic gradient descent is a simple yet very efficient approach to fit linear models. It is particularly useful when the number of samples (and the number of features) is very large. The &lt;code&gt;partial_fit&lt;/code&gt; method allows online/out-of-core learning.</source>
          <target state="translated">확률 적 그라디언트 디센트는 선형 모델에 맞는 간단하면서도 매우 효율적인 방법입니다. 샘플 수 (및 피처 수)가 매우 큰 경우에 특히 유용합니다. &lt;code&gt;partial_fit&lt;/code&gt; 의 방법은 온라인으로 할 수 있습니다 / 아웃 - 오브 - 핵심 학습.</target>
        </trans-unit>
        <trans-unit id="88c2b7432b4c70aedd301d6441f9f686fac99afd" translate="yes" xml:space="preserve">
          <source>Stochastic gradient descent is an optimization method for unconstrained optimization problems. In contrast to (batch) gradient descent, SGD approximates the true gradient of \(E(w,b)\) by considering a single training example at a time.</source>
          <target state="translated">확률 적 경사 하강은 제약이없는 최적화 문제에 대한 최적화 방법입니다. (배치) 그래디언트 디센트와 달리 SGD는 한 번에 단일 교육 예제를 고려하여 \ (E (w, b) \)의 실제 그래디언트를 근사합니다.</target>
        </trans-unit>
        <trans-unit id="3bc9b5e942f6c3298a3799e63fea9d4e51700363" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of features. This option is useful only when specifying a connectivity matrix. Note also that when varying the number of clusters and using caching, it may be advantageous to compute the full tree.</source>
          <target state="translated">n_clusters에서 트리 생성을 일찍 중지하십시오. 기능 수에 비해 군집 수가 적지 않은 경우 계산 시간을 줄이는 데 유용합니다. 이 옵션은 연결 매트릭스를 지정할 때만 유용합니다. 또한 클러스터 수를 변경하고 캐싱을 사용하는 경우 전체 트리를 계산하는 것이 유리할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="3dc26590d142d1e5e73aaec1d67524322b86dfd8" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of samples. In this case, the complete tree is not computed, thus the &amp;lsquo;children&amp;rsquo; output is of limited use, and the &amp;lsquo;parents&amp;rsquo; output should rather be used. This option is valid only when specifying a connectivity matrix.</source>
          <target state="translated">n_clusters에서 트리 생성을 일찍 중지하십시오. 이는 클러스터 수가 샘플 수에 비해 작지 않은 경우 계산 시간을 줄이는 데 유용합니다. 이 경우 전체 트리가 계산되지 않으므로 '자식'출력의 사용이 제한적이며 '부모'출력이 사용되어야합니다. 이 옵션은 연결 매트릭스를 지정할 때만 유효합니다.</target>
        </trans-unit>
        <trans-unit id="44e9e4435e20e453549059a3ee4002b032ad438a" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of samples. This option is useful only when specifying a connectivity matrix. Note also that when varying the number of clusters and using caching, it may be advantageous to compute the full tree.</source>
          <target state="translated">n_clusters에서 트리 생성을 일찍 중지하십시오. 이는 클러스터 수가 샘플 수에 비해 작지 않은 경우 계산 시간을 줄이는 데 유용합니다. 이 옵션은 연결 매트릭스를 지정할 때만 유용합니다. 또한 클러스터 수를 변경하고 캐싱을 사용하는 경우 전체 트리를 계산하는 것이 유리할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="84a6e50b1119dc5648f3c425a6b5dee68899e309" translate="yes" xml:space="preserve">
          <source>Stop iteration if at least this number of inliers are found.</source>
          <target state="translated">이 개수 이상의 이너가 발견되면 반복을 중지하십시오.</target>
        </trans-unit>
        <trans-unit id="538193aed5fb2f898d909880cd3e81469e15df67" translate="yes" xml:space="preserve">
          <source>Stop iteration if score is greater equal than this threshold.</source>
          <target state="translated">점수가이 임계 값보다 큰 경우 반복을 중지하십시오.</target>
        </trans-unit>
        <trans-unit id="12517d0c8ade549d252ae4e535d57433e9861479" translate="yes" xml:space="preserve">
          <source>Stop solver after this many iterations regardless of accuracy (XXX Currently there is no API to know whether this kicked in.) -1 by default.</source>
          <target state="translated">정확도에 관계없이이 반복을 많이 수행 한 후에 솔버를 중지하십시오 (XXX 현재이 기능이 시작되었는지 여부를 알 수있는 API는 없습니다) -1 기본적으로.</target>
        </trans-unit>
        <trans-unit id="df6a1587df9722b5b493e30cfc313089ab29220d" translate="yes" xml:space="preserve">
          <source>Stop the algorithm if w has converged. Default is 1.e-3.</source>
          <target state="translated">w가 수렴되면 알고리즘을 중지하십시오. 기본값은 1.e-3입니다.</target>
        </trans-unit>
        <trans-unit id="7cf46a1e9b2d853c73253eb4c96cbe1ea1bb5aa6" translate="yes" xml:space="preserve">
          <source>Stop words are words like &amp;ldquo;and&amp;rdquo;, &amp;ldquo;the&amp;rdquo;, &amp;ldquo;him&amp;rdquo;, which are presumed to be uninformative in representing the content of a text, and which may be removed to avoid them being construed as signal for prediction. Sometimes, however, similar words are useful for prediction, such as in classifying writing style or personality.</source>
          <target state="translated">중지 단어는 &quot;및&quot;, &quot;the&quot;, &quot;him&quot;과 같은 단어로, 텍스트 내용을 나타내는 데 도움이되지 않는 것으로 추정되며 예측을위한 신호로 해석되지 않도록 제거 될 수 있습니다. 그러나 때로는 글쓰기 스타일 또는 성격 분류와 같은 유사한 단어가 예측에 유용합니다.</target>
        </trans-unit>
        <trans-unit id="7eb24af52d1aa9e6b8d6715fd2fd646422f9b535" translate="yes" xml:space="preserve">
          <source>Stopping criteria.</source>
          <target state="translated">기준을 중지합니다.</target>
        </trans-unit>
        <trans-unit id="51b3a0bb0b4d84ebe8a65cc9b8c0c2b3279fba93" translate="yes" xml:space="preserve">
          <source>Stopping criterion for eigendecomposition of the Laplacian matrix when using arpack eigen_solver.</source>
          <target state="translated">arpack eigen_solver를 사용할 때 라플라시안 행렬의 고유 분해 기준을 중지합니다.</target>
        </trans-unit>
        <trans-unit id="68414daf9a6e27622678aff82460baea3a51326c" translate="yes" xml:space="preserve">
          <source>Stopping criterion. For the newton-cg and lbfgs solvers, the iteration will stop when &lt;code&gt;max{|g_i | i = 1, ..., n} &amp;lt;= tol&lt;/code&gt; where &lt;code&gt;g_i&lt;/code&gt; is the i-th component of the gradient.</source>
          <target state="translated">기준을 중지합니다. newton-cg 및 lbfgs 솔버의 경우 &lt;code&gt;max{|g_i | i = 1, ..., n} &amp;lt;= tol&lt;/code&gt; 여기서 &lt;code&gt;g_i&lt;/code&gt; 는 그래디언트의 i 번째 성분입니다.</target>
        </trans-unit>
        <trans-unit id="fe10af6492740b92517388e940d4c53ee7e65f2c" translate="yes" xml:space="preserve">
          <source>Stopping tolerance for EM algorithm.</source>
          <target state="translated">EM 알고리즘에 대한 허용 오차.</target>
        </trans-unit>
        <trans-unit id="3afb8412732c53a6b3ed5f0cf3d5d66e9526d993" translate="yes" xml:space="preserve">
          <source>Stopping tolerance for updating document topic distribution in E-step.</source>
          <target state="translated">E-step에서 문서 주제 분배를 업데이트하기위한 허용 오차를 중지합니다.</target>
        </trans-unit>
        <trans-unit id="5745be1c1a529a40ad5578990283b7d9ed5dfe16" translate="yes" xml:space="preserve">
          <source>Store n output values in leaves, instead of 1;</source>
          <target state="translated">n 대신에 n 개의 출력 값을 잎에 저장하십시오.</target>
        </trans-unit>
        <trans-unit id="8a6ab3415c7252ce3e941fe62193814f0365a625" translate="yes" xml:space="preserve">
          <source>Stores nearest neighbors instance, including BallTree or KDtree if applicable.</source>
          <target state="translated">해당되는 경우 BallTree 또는 KDtree를 포함하여 가장 가까운 인접 인스턴스를 저장합니다.</target>
        </trans-unit>
        <trans-unit id="f9d028499b97399f71598e9bb920fa52d5ec8313" translate="yes" xml:space="preserve">
          <source>Stores the affinity matrix used in &lt;code&gt;fit&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;fit&lt;/code&gt; 에 사용 된 선호도 매트릭스를 저장합니다 .</target>
        </trans-unit>
        <trans-unit id="781b70a9f7d2aabdccb43059620f25863827cacd" translate="yes" xml:space="preserve">
          <source>Stores the embedding vectors</source>
          <target state="translated">임베딩 벡터를 저장합니다</target>
        </trans-unit>
        <trans-unit id="9fe548f57e57cace725aa47be0bac94930f35de7" translate="yes" xml:space="preserve">
          <source>Stores the embedding vectors.</source>
          <target state="translated">임베딩 벡터를 저장합니다.</target>
        </trans-unit>
        <trans-unit id="e7019b0e2126237169f8ccc84f1dacd8599b7b63" translate="yes" xml:space="preserve">
          <source>Stores the geodesic distance matrix of training data.</source>
          <target state="translated">훈련 데이터의 측지 거리 행렬을 저장합니다.</target>
        </trans-unit>
        <trans-unit id="7bfa0d6921b4ff07d4718354c3a4168af9b3a946" translate="yes" xml:space="preserve">
          <source>Stores the position of the dataset in the embedding space.</source>
          <target state="translated">임베드 공간에서 데이터 세트의 위치를 ​​저장합니다.</target>
        </trans-unit>
        <trans-unit id="8197f80c6163117652499db82ad63b22aa5b87b2" translate="yes" xml:space="preserve">
          <source>Stores the training data.</source>
          <target state="translated">훈련 데이터를 저장합니다.</target>
        </trans-unit>
        <trans-unit id="6485fe8179de6b50a8b0db7cf302477ffee4cf50" translate="yes" xml:space="preserve">
          <source>Strategy to use to generate predictions.</source>
          <target state="translated">예측을 생성하는 데 사용할 전략.</target>
        </trans-unit>
        <trans-unit id="9ba291b4721c49cd83c83d224ae746db45b32e1d" translate="yes" xml:space="preserve">
          <source>Strategy used to define the widths of the bins.</source>
          <target state="translated">빈의 너비를 정의하는 데 사용되는 전략.</target>
        </trans-unit>
        <trans-unit id="890ad0feded21dbb4c68bfca3e2d7cdbb498d411" translate="yes" xml:space="preserve">
          <source>Stratified K-Folds cross-validator</source>
          <target state="translated">계층화 된 K- 폴드 교차 검증기</target>
        </trans-unit>
        <trans-unit id="078f2e04c72cf2c2cef672d9cd530d809895796a" translate="yes" xml:space="preserve">
          <source>Stratified ShuffleSplit cross-validator</source>
          <target state="translated">계층화 된 셔플</target>
        </trans-unit>
        <trans-unit id="10ef227c2ccc54bd522a7229f1c708e11ce5e295" translate="yes" xml:space="preserve">
          <source>Strehl, Alexander, and Joydeep Ghosh (2002). &amp;ldquo;Cluster ensembles &amp;ndash; a knowledge reuse framework for combining multiple partitions&amp;rdquo;. Journal of Machine Learning Research 3: 583&amp;ndash;617. &lt;a href=&quot;http://strehl.com/download/strehl-jmlr02.pdf&quot;&gt;doi:10.1162/153244303321897735&lt;/a&gt;.</source>
          <target state="translated">Strehl, Alexander 및 Joydeep Ghosh (2002). &amp;ldquo;클러스터 앙상블 &amp;ndash; 여러 파티션을 결합하기위한 지식 재사용 프레임 워크&amp;rdquo;. 기계 학습 연구 저널 3 : 583&amp;ndash;617. &lt;a href=&quot;http://strehl.com/download/strehl-jmlr02.pdf&quot;&gt;doi : 10.1162 / 153244303321897735&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="8f823045d1b6e6e3e2566fad8b86b9a7f7274035" translate="yes" xml:space="preserve">
          <source>String describing the type of covariance parameters to use. Must be one of:</source>
          <target state="translated">사용할 공분산 모수의 유형을 설명하는 문자열입니다. 다음 중 하나 여야합니다.</target>
        </trans-unit>
        <trans-unit id="24715b349c9d19241a871e75b2e65bf44d424eee" translate="yes" xml:space="preserve">
          <source>String describing the type of the weight concentration prior. Must be one of:</source>
          <target state="translated">이전의 중량 농도 유형을 설명하는 문자열 다음 중 하나 여야합니다.</target>
        </trans-unit>
        <trans-unit id="428566ee279a0d9edb0dac9070b52a231b258cad" translate="yes" xml:space="preserve">
          <source>String identifier for kernel function to use or the kernel function itself. Only &amp;lsquo;rbf&amp;rsquo; and &amp;lsquo;knn&amp;rsquo; strings are valid inputs. The function passed should take two inputs, each of shape [n_samples, n_features], and return a [n_samples, n_samples] shaped weight matrix</source>
          <target state="translated">사용할 커널 함수 또는 커널 함수 자체의 문자열 식별자. 'rbf'및 'knn'문자열 만 유효한 입력입니다. 전달 된 함수는 각각 모양 [n_samples, n_features]의 두 입력을 가져 와서 [n_samples, n_samples] 모양의 가중치 행렬을 반환해야합니다.</target>
        </trans-unit>
        <trans-unit id="af724a0a2167e8652dc92f95eace643e40894f38" translate="yes" xml:space="preserve">
          <source>String identifier for kernel function to use or the kernel function itself. Only &amp;lsquo;rbf&amp;rsquo; and &amp;lsquo;knn&amp;rsquo; strings are valid inputs. The function passed should take two inputs, each of shape [n_samples, n_features], and return a [n_samples, n_samples] shaped weight matrix.</source>
          <target state="translated">사용할 커널 함수 또는 커널 함수 자체의 문자열 식별자. 'rbf'및 'knn'문자열 만 유효한 입력입니다. 전달 된 함수는 각각 모양 [n_samples, n_features]의 두 입력을 가져 와서 [n_samples, n_samples] 모양의 가중치 행렬을 반환해야합니다.</target>
        </trans-unit>
        <trans-unit id="62948e7b4671e9ca0f3cde3750c969c3432c4224" translate="yes" xml:space="preserve">
          <source>String identifier of the dataset. Note that OpenML can have multiple datasets with the same name.</source>
          <target state="translated">데이터 세트의 문자열 식별자입니다. OpenML은 이름이 같은 여러 데이터 세트를 가질 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="df0679bd93bc3d3699b427e726c60dd8e54a8049" translate="yes" xml:space="preserve">
          <source>String inputs, &amp;ldquo;absolute_loss&amp;rdquo; and &amp;ldquo;squared_loss&amp;rdquo; are supported which find the absolute loss and squared loss per sample respectively.</source>
          <target state="translated">샘플 당 절대 손실과 제곱 손실을 각각 찾는 문자열 입력 &quot;absolute_loss&quot;및 &quot;squared_loss&quot;가 지원됩니다.</target>
        </trans-unit>
        <trans-unit id="0e35f8f4354526879dda20784b410a6fffd10219" translate="yes" xml:space="preserve">
          <source>String must be in {&amp;lsquo;frobenius&amp;rsquo;, &amp;lsquo;kullback-leibler&amp;rsquo;, &amp;lsquo;itakura-saito&amp;rsquo;}. Beta divergence to be minimized, measuring the distance between X and the dot product WH. Note that values different from &amp;lsquo;frobenius&amp;rsquo; (or 2) and &amp;lsquo;kullback-leibler&amp;rsquo; (or 1) lead to significantly slower fits. Note that for beta_loss &amp;lt;= 0 (or &amp;lsquo;itakura-saito&amp;rsquo;), the input matrix X cannot contain zeros. Used only in &amp;lsquo;mu&amp;rsquo; solver.</source>
          <target state="translated">문자열은 { 'frobenius', 'kullback-leibler', 'itakura-saito'}에 있어야합니다. X와 내적 WH 사이의 거리를 측정하여 베타 발산을 최소화합니다. 'frobenius'(또는 2) 및 'kullback-leibler'(또는 1)와 다른 값은 피팅 속도가 상당히 느려집니다. beta_loss &amp;lt;= 0 (또는 'itakura-saito')의 경우 입력 행렬 X는 0을 포함 할 수 없습니다. 'mu'솔버에서만 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="9f2d9e288ea5ff4eb7ea1abaab0c518bb3979797" translate="yes" xml:space="preserve">
          <source>String names for input features if available. By default, &amp;ldquo;x0&amp;rdquo;, &amp;ldquo;x1&amp;rdquo;, &amp;hellip; &amp;ldquo;xn_features&amp;rdquo; is used.</source>
          <target state="translated">사용 가능한 경우 입력 기능의 문자열 이름. 기본적으로&amp;ldquo;x0&amp;rdquo;,&amp;ldquo;x1&amp;rdquo;,&amp;hellip;&amp;ldquo;xn_features&amp;rdquo;가 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="6eb302a1a8353d21c585781076747cec5064ac6a" translate="yes" xml:space="preserve">
          <source>String representation of the input tree in GraphViz dot format. Only returned if &lt;code&gt;out_file&lt;/code&gt; is None.</source>
          <target state="translated">GraphViz 도트 형식으로 입력 트리의 문자열 표현. &lt;code&gt;out_file&lt;/code&gt; 이 None 인 경우에만 반환됩니다 .</target>
        </trans-unit>
        <trans-unit id="a25a8a192fb86c92debb43e92001c859f89e3fcf" translate="yes" xml:space="preserve">
          <source>String[s] representing allowed sparse matrix formats, such as &amp;lsquo;csc&amp;rsquo;, &amp;lsquo;csr&amp;rsquo;, etc. If the input is sparse but not in the allowed format, it will be converted to the first listed format. True allows the input to be any format. False means that a sparse matrix input will raise an error.</source>
          <target state="translated">'csc', 'csr'등과 같이 허용 된 희소 행렬 형식을 나타내는 문자열입니다. 입력이 희소하지만 허용 된 형식이 아닌 경우, 첫 번째로 나열된 형식으로 변환됩니다. True는 입력을 모든 형식으로 허용합니다. False는 희소 행렬 입력으로 인해 오류가 발생 함을 의미합니다.</target>
        </trans-unit>
        <trans-unit id="b91b90e5e49a63cce92ec827bcf2ae012d9565f3" translate="yes" xml:space="preserve">
          <source>Subsequently, the object is created as:</source>
          <target state="translated">결과적으로 객체는 다음과 같이 생성됩니다.</target>
        </trans-unit>
        <trans-unit id="d8cf7e7f541f13164e6f0420a446eeb6e92a09d1" translate="yes" xml:space="preserve">
          <source>Subset of X on first axis</source>
          <target state="translated">첫 번째 축에서 X의 하위 집합</target>
        </trans-unit>
        <trans-unit id="6ae596021e773a90882ea646d69c3ae9bc66f60f" translate="yes" xml:space="preserve">
          <source>Subset of target values</source>
          <target state="translated">목표 값의 부분 집합</target>
        </trans-unit>
        <trans-unit id="71578b0f6daa48f798b6ba24f599e04480076227" translate="yes" xml:space="preserve">
          <source>Subset of the target values</source>
          <target state="translated">목표 값의 부분 집합</target>
        </trans-unit>
        <trans-unit id="223f88ba981735506f55650c24adc2c0be541ac7" translate="yes" xml:space="preserve">
          <source>Subset of the training data</source>
          <target state="translated">훈련 데이터의 부분 집합</target>
        </trans-unit>
        <trans-unit id="6bc315a85db741490d46c866dcdf3685f245d4e2" translate="yes" xml:space="preserve">
          <source>Subset of training data</source>
          <target state="translated">교육 데이터의 하위 세트</target>
        </trans-unit>
        <trans-unit id="19abeb39c58b2714170ce5a2488e41705eacf825" translate="yes" xml:space="preserve">
          <source>Subset of training points used to construct the feature map.</source>
          <target state="translated">기능 맵을 구성하는 데 사용되는 교육 지점의 하위 집합입니다.</target>
        </trans-unit>
        <trans-unit id="af82dc274666b6dae18b2b0a4a918322786e1ec9" translate="yes" xml:space="preserve">
          <source>Such a grouping of data is domain specific. An example would be when there is medical data collected from multiple patients, with multiple samples taken from each patient. And such data is likely to be dependent on the individual group. In our example, the patient id for each sample will be its group identifier.</source>
          <target state="translated">이러한 데이터 그룹은 도메인별로 다릅니다. 예를 들어 여러 환자에서 수집 한 의료 데이터가 있고 각 환자에서 여러 개의 샘플을 채취 한 경우가 있습니다. 이러한 데이터는 개별 그룹에 따라 달라질 수 있습니다. 이 예에서 각 샘플의 환자 ID는 그룹 식별자입니다.</target>
        </trans-unit>
        <trans-unit id="116040368f9a04b617abdb5e80205920c1827d88" translate="yes" xml:space="preserve">
          <source>Such integer representation can, however, not be used directly with all scikit-learn estimators, as these expect continuous input, and would interpret the categories as being ordered, which is often not desired (i.e. the set of browsers was ordered arbitrarily).</source>
          <target state="translated">그러나 이러한 정수 표현은 연속적인 입력을 기대하고 범주가 정렬되는 것으로 해석하기 때문에 모든 scikit-learn 추정기와 함께 직접 사용할 수는 없습니다 (예 : 브라우저 세트는 임의로 정렬 됨).</target>
        </trans-unit>
        <trans-unit id="db90c3a55b9a44b531c3ac8e926f4bff46ae5000" translate="yes" xml:space="preserve">
          <source>Sum of squared distances of samples to their closest cluster center.</source>
          <target state="translated">가장 가까운 군집 중심까지의 표본의 제곱 거리의 합.</target>
        </trans-unit>
        <trans-unit id="51853ebee0d0437a819288d394e52f2825e89e10" translate="yes" xml:space="preserve">
          <source>Sum-kernel k1 + k2 of two kernels k1 and k2.</source>
          <target state="translated">두 커널 k1과 k2의 합 커널 k1 + k2.</target>
        </trans-unit>
        <trans-unit id="70ee3e3bff0af30ecffa237a657d140e21c08452" translate="yes" xml:space="preserve">
          <source>Summary Statistics:</source>
          <target state="translated">요약 통계 :</target>
        </trans-unit>
        <trans-unit id="fd64088007de4ee1ec90faddb61b9fabe7591dbe" translate="yes" xml:space="preserve">
          <source>Supervised learning algorithms will require a category label for each document in the training set. In this case the category is the name of the newsgroup which also happens to be the name of the folder holding the individual documents.</source>
          <target state="translated">지도 학습 알고리즘에는 학습 세트의 각 문서에 대한 카테고리 레이블이 필요합니다. 이 경우 범주는 뉴스 그룹의 이름이며 개별 문서가 들어있는 폴더의 이름이기도합니다.</target>
        </trans-unit>
        <trans-unit id="a76d63a44e8696360e974f3be74fa9ede463ccb8" translate="yes" xml:space="preserve">
          <source>Supervised learning: predicting an output variable from high-dimensional observations</source>
          <target state="translated">지도 학습 : 고차원 관측치에서 출력 변수 예측</target>
        </trans-unit>
        <trans-unit id="6eafe7087c2917502cf9a105460eb618a5158ac5" translate="yes" xml:space="preserve">
          <source>Support Vector Classification (SVC) shows an even more sigmoid curve as the RandomForestClassifier, which is typical for maximum-margin methods (compare Niculescu-Mizil and Caruana &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;), which focus on hard samples that are close to the decision boundary (the support vectors).</source>
          <target state="translated">SVC (Support Vector Classification)는 RandomForestClassifier로서 훨씬 더 많은 시그 모이 드 곡선을 보여줍니다. 이는 최대 한계 방법 (Niculescu-Mizil 및 Caruana &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1] 비교&lt;/a&gt; )에서 일반적으로 결정 경계에 가까운 단단한 샘플 ( 지원 벡터).</target>
        </trans-unit>
        <trans-unit id="ed5eaa4e09c1fde40caa79c99d658b1a804b4ecf" translate="yes" xml:space="preserve">
          <source>Support Vector Machine algorithms are not scale invariant, so &lt;strong&gt;it is highly recommended to scale your data&lt;/strong&gt;. For example, scale each attribute on the input vector X to [0,1] or [-1,+1], or standardize it to have mean 0 and variance 1. Note that the &lt;em&gt;same&lt;/em&gt; scaling must be applied to the test vector to obtain meaningful results. See section &lt;a href=&quot;preprocessing#preprocessing&quot;&gt;Preprocessing data&lt;/a&gt; for more details on scaling and normalization.</source>
          <target state="translated">Support Vector Machine 알고리즘은 스케일이 변하지 않으므로 &lt;strong&gt;데이터를 스케일하는 것이 좋습니다&lt;/strong&gt; . 예를 들어 입력 벡터 X의 각 속성을 [0,1] 또는 [-1, + 1]로 스케일링 하거나 평균 0과 분산 1을 갖도록 표준화합니다 . 테스트 벡터에 &lt;em&gt;동일한&lt;/em&gt; 스케일링을 적용하여 의미있는 결과를 얻습니다. 스케일링 및 정규화에 대한 자세한 내용은 &lt;a href=&quot;preprocessing#preprocessing&quot;&gt;전처리 데이터&lt;/a&gt; 섹션을 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="7db4fe2bb2b495808d702cc828d549eda5ecd6dd" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for Regression implemented using libsvm.</source>
          <target state="translated">libsvm을 사용하여 구현 된 회귀 벡터 시스템 지원</target>
        </trans-unit>
        <trans-unit id="f893d85d40edb954e6730df0c490772b3e2a0229" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for classification implemented with libsvm with a parameter to control the number of support vectors.</source>
          <target state="translated">지원 벡터 수를 제어하는 ​​매개 변수와 함께 libsvm으로 구현 된 분류 용 지원 벡터 시스템.</target>
        </trans-unit>
        <trans-unit id="5051cb5a7ebb600b6c87a0405fb53ae2a929b69a" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for classification using libsvm.</source>
          <target state="translated">libsvm을 사용한 분류를위한 Vector Machine을 지원합니다.</target>
        </trans-unit>
        <trans-unit id="c9c0030d3280fdd6faa0de4e8ec40fd895c7cc05" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for regression implemented using libsvm using a parameter to control the number of support vectors.</source>
          <target state="translated">지원 벡터 수를 제어하는 ​​매개 변수를 사용하여 libsvm을 사용하여 구현 된 회귀 용 지원 벡터 머신.</target>
        </trans-unit>
        <trans-unit id="56158ab7bc33e3424017c0101c6f6a1afb88a3a9" translate="yes" xml:space="preserve">
          <source>Support Vector Machines are powerful tools, but their compute and storage requirements increase rapidly with the number of training vectors. The core of an SVM is a quadratic programming problem (QP), separating support vectors from the rest of the training data. The QP solver used by this &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;-based implementation scales between \(O(n_{features} \times n_{samples}^2)\) and \(O(n_{features} \times n_{samples}^3)\) depending on how efficiently the &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; cache is used in practice (dataset dependent). If the data is very sparse \(n_{features}\) should be replaced by the average number of non-zero features in a sample vector.</source>
          <target state="translated">Support Vector Machine은 강력한 도구이지만 훈련 벡터 수에 따라 컴퓨팅 및 스토리지 요구 사항이 빠르게 증가합니다. SVM의 핵심은 2 차 프로그래밍 문제 (QP)로 나머지 훈련 데이터에서 지원 벡터를 분리합니다. 이 &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; 기반 구현에서 사용되는 QP 솔버 는 \ (O (n_ {features} \ times n_ {samples} ^ 2) \)와 \ (O (n_ {features} \ times n_ {samples} ^ 3) \ 사이에서 확장됩니다. ) &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; 캐시가 실제로 얼마나 효율적으로 사용되는지에 따라 (데이터 집합에 따라 다름) 데이터가 매우 드문 경우 \ (n_ {features} \)는 샘플 벡터에서 0이 아닌 평균의 수로 대체해야합니다.</target>
        </trans-unit>
        <trans-unit id="5aeba1d5d3764ce4f342c9f3c5c4d98c95831ef3" translate="yes" xml:space="preserve">
          <source>Support Vector Regression (SVR) using linear and non-linear kernels</source>
          <target state="translated">선형 및 비선형 커널을 사용하여 SVR (Vector Regression) 지원</target>
        </trans-unit>
        <trans-unit id="c38caf86bc0ea77939ed0d559b2d4f17cae05de8" translate="yes" xml:space="preserve">
          <source>Support Vector Regression implemented using libsvm.</source>
          <target state="translated">libsvm을 사용하여 구현 된 벡터 회귀 지원</target>
        </trans-unit>
        <trans-unit id="9f57f9c660b4dd2f0deaa4ba97e0c878c516d5af" translate="yes" xml:space="preserve">
          <source>Support vector machines (SVMs)</source>
          <target state="translated">지원 벡터 머신 (SVM)</target>
        </trans-unit>
        <trans-unit id="bbbf41eb38c0c6ebc14c9776b74f3b7c7223e260" translate="yes" xml:space="preserve">
          <source>Support vectors.</source>
          <target state="translated">지원 벡터.</target>
        </trans-unit>
        <trans-unit id="a54e8408d47bb6e31202d1c04b19dcb2a41dd085" translate="yes" xml:space="preserve">
          <source>Supports sparse matrices, as long as they are nonnegative.</source>
          <target state="translated">음수가 아닌 한 희소 행렬을 지원합니다.</target>
        </trans-unit>
        <trans-unit id="3d69897cfb127444947f0af512011088c32f7842" translate="yes" xml:space="preserve">
          <source>Suppose there are \(n\) training samples, \(m\) features, \(k\) hidden layers, each containing \(h\) neurons - for simplicity, and \(o\) output neurons. The time complexity of backpropagation is \(O(n\cdot m \cdot h^k \cdot o \cdot i)\), where \(i\) is the number of iterations. Since backpropagation has a high time complexity, it is advisable to start with smaller number of hidden neurons and few hidden layers for training.</source>
          <target state="translated">\ (n \) 훈련 샘플, \ (m \) 기능, \ (k \) 숨겨진 레이어 (각각 \ (h \) 뉴런 포함-단순함) 및 \ (o \) 출력 뉴런이 있다고 가정합니다. 역 전파의 시간 복잡도는 \ (O (n \ cdot m \ cdot h ^ k \ cdot o \ cdot i) \)이며 여기서 \ (i \)는 반복 횟수입니다. 역전 파는 시간 복잡성이 높기 때문에 적은 수의 숨겨진 뉴런과 적은 수의 숨겨진 레이어로 시작하는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="717b26aef2df5c03a35ae859cfcbb420ec45f953" translate="yes" xml:space="preserve">
          <source>Swaps two columns of a CSC/CSR matrix in-place.</source>
          <target state="translated">CSC / CSR 매트릭스의 두 열을 제자리에 교환합니다.</target>
        </trans-unit>
        <trans-unit id="1069fce64f91499526a54ca2a920222a7a6a7b20" translate="yes" xml:space="preserve">
          <source>Swaps two rows of a CSC/CSR matrix in-place.</source>
          <target state="translated">CSC / CSR 매트릭스의 두 행을 제자리에 교환합니다.</target>
        </trans-unit>
        <trans-unit id="fe072010fa51f4d65d4b1c57510d1adce13a6e7b" translate="yes" xml:space="preserve">
          <source>Swiss Roll reduction with LLE</source>
          <target state="translated">LLE를 사용한 스위스 롤 감소</target>
        </trans-unit>
        <trans-unit id="2230299d58c6b8fd7778e9806246c78a89ba5d37" translate="yes" xml:space="preserve">
          <source>Symmetrized version of the input array, i.e. the average of array and array.transpose(). If sparse, then duplicate entries are first summed and zeros are eliminated.</source>
          <target state="translated">입력 배열의 대칭 버전, 즉 배열과 array.transpose ()의 평균. 드문 경우 중복 항목을 먼저 합산하고 0을 제거합니다.</target>
        </trans-unit>
        <trans-unit id="5617e20da29f8f9d1be80cd4e8da4f2cca7d87a9" translate="yes" xml:space="preserve">
          <source>Symmetry: d(x, y) = d(y, x)</source>
          <target state="translated">대칭 : d (x, y) = d (y, x)</target>
        </trans-unit>
        <trans-unit id="5c4b58b32e84506455d7badad68c3391e5ed62f8" translate="yes" xml:space="preserve">
          <source>Synthetic example</source>
          <target state="translated">합성 예</target>
        </trans-unit>
        <trans-unit id="a2f05b63d3eed62a3d034f7470902282f6f3879f" translate="yes" xml:space="preserve">
          <source>T. Calinski and J. Harabasz, 1974. &amp;ldquo;A dendrite method for cluster analysis&amp;rdquo;. Communications in Statistics</source>
          <target state="translated">T. Calinski and J. Harabasz, 1974.&amp;ldquo;클러스터 분석을위한 덴 드라이트 방법&amp;rdquo;. 통계 커뮤니케이션</target>
        </trans-unit>
        <trans-unit id="cfd0a0e6ed4317c498cad6dff52fb64a880cf1fc" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman, &amp;ldquo;Elements of Statistical Learning Ed. 2&amp;rdquo;, Springer, 2009.</source>
          <target state="translated">T. Hastie, R. Tibshirani 및 J. Friedman,&amp;ldquo;통계 학습의 요소 Ed. 2&amp;rdquo;, Springer, 2009.</target>
        </trans-unit>
        <trans-unit id="7f7943ebfea41ffafd05b1021989488d98e43338" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman, &amp;ldquo;Elements of Statistical Learning Ed. 2&amp;rdquo;, p592-593, Springer, 2009.</source>
          <target state="translated">T. Hastie, R. Tibshirani 및 J. Friedman,&amp;ldquo;통계 학습의 요소 Ed. 2&amp;rdquo;, p592-593, Springer, 2009.</target>
        </trans-unit>
        <trans-unit id="70c29954ab4c3cb7794dae94a173c1937d4eb172" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman, &amp;ldquo;Elements of Statistical Learning&amp;rdquo;, Springer, 2009.</source>
          <target state="translated">T. Hastie, R. Tibshirani 및 J. Friedman,&amp;ldquo;통계학의 요소&amp;rdquo;, Springer, 2009.</target>
        </trans-unit>
        <trans-unit id="83fcdb4c642340f440ec3c76643b0ff4a3e4d907" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman. &amp;ldquo;Elements of Statistical Learning&amp;rdquo;, Springer, 2009.</source>
          <target state="translated">T. Hastie, R. Tibshirani 및 J. Friedman. &quot;통계학 학습 요소&quot;, Springer, 2009.</target>
        </trans-unit>
        <trans-unit id="cb7835aaacc19565f84e186774c00699f37d4811" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman. Elements of Statistical Learning Ed. 2, Springer, 2009.</source>
          <target state="translated">T. Hastie, R. Tibshirani 및 J. Friedman. 통계 학습의 요소 Ed. 2, Springer, 2009.</target>
        </trans-unit>
        <trans-unit id="d4c99bc2ba4c28ec35fea9e0c8535d7da602917b" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman. Elements of Statistical Learning, Springer, 2009.</source>
          <target state="translated">T. Hastie, R. Tibshirani 및 J. Friedman. 통계 학습의 요소, Springer, 2009.</target>
        </trans-unit>
        <trans-unit id="080b47cb3536b08b8d64a0132c354c0e69235639" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani, J. Friedman, &lt;a href=&quot;https://web.stanford.edu/~hastie/ElemStatLearn/&quot;&gt;The Elements of Statistical Learning&lt;/a&gt;, Springer 2009</source>
          <target state="translated">T. Hastie, R. Tibshirani, J. Friedman, &lt;a href=&quot;https://web.stanford.edu/~hastie/ElemStatLearn/&quot;&gt;통계 학습의 요소&lt;/a&gt; , Springer 2009</target>
        </trans-unit>
        <trans-unit id="caa676716fee5a5c020ff878a7d0616f2b82e015" translate="yes" xml:space="preserve">
          <source>T. Ho, &amp;ldquo;The random subspace method for constructing decision forests&amp;rdquo;, Pattern Analysis and Machine Intelligence, 20(8), 832-844, 1998.</source>
          <target state="translated">T. Ho,&amp;ldquo;의사 결정 포리스트 구성을위한 무작위 부분 공간 방법&amp;rdquo;, 패턴 분석 및 머신 인텔리전스, 20 (8), 832-844, 1998.</target>
        </trans-unit>
        <trans-unit id="12a252b4085c50c08e5600b6a2ace31faa3ef960" translate="yes" xml:space="preserve">
          <source>T. Yang, Y. Li, M. Mahdavi, R. Jin and Z. Zhou &amp;ldquo;Nystroem Method vs Random Fourier Features: A Theoretical and Empirical Comparison&amp;rdquo;, Advances in Neural Information Processing Systems 2012</source>
          <target state="translated">T. Yang, Y. Li, M. Mahdavi, R. Jin 및 Z. Zhou&amp;ldquo;Nystroem 방법 대 랜덤 푸리에 특징 : 이론적 및 경험적 비교&amp;rdquo;, 신경 정보 처리 시스템의 발전 2012</target>
        </trans-unit>
        <trans-unit id="01f0642e8e9ab9a87342728e5ceb8bbd9d2f4ab3" translate="yes" xml:space="preserve">
          <source>TAX full-value property-tax rate per $10,000</source>
          <target state="translated">$ 10,000 당 세금 전체 가치 재산 세율</target>
        </trans-unit>
        <trans-unit id="dd1b5c68340d106d37b309522fe8b393cb21ad39" translate="yes" xml:space="preserve">
          <source>TF-IDF vectors of text documents crawled from the web</source>
          <target state="translated">웹에서 크롤링 된 텍스트 문서의 TF-IDF 벡터</target>
        </trans-unit>
        <trans-unit id="45e8bc91482fcb8372ecf82971819bb3adf7f455" translate="yes" xml:space="preserve">
          <source>TODO: implement zip dataset loading too</source>
          <target state="translated">TODO : zip 데이터 셋 로딩도 구현</target>
        </trans-unit>
        <trans-unit id="8ab0e32d1d047cd892b558c9b2f078b6857615c4" translate="yes" xml:space="preserve">
          <source>Takes a group array to group observations.</source>
          <target state="translated">그룹 배열을 사용하여 관측치를 그룹화합니다.</target>
        </trans-unit>
        <trans-unit id="3fd5fa24212eb9a6093f6fb3922373c2e928c57e" translate="yes" xml:space="preserve">
          <source>Takes group information into account to avoid building folds with imbalanced class distributions (for binary or multiclass classification tasks).</source>
          <target state="translated">불균형 한 클래스 배포 (이진 또는 멀티 클래스 분류 작업)로 폴드를 작성하지 않도록 그룹 정보를 고려합니다.</target>
        </trans-unit>
        <trans-unit id="d9f2745c15759b2e07e7b8ac9dcbd8d3eb7f1df5" translate="yes" xml:space="preserve">
          <source>Talks given, slide-sets and other information relevant to scikit-learn.</source>
          <target state="translated">scikit-learn과 관련된 대화, 슬라이드 세트 및 기타 정보.</target>
        </trans-unit>
        <trans-unit id="61ad50a9b9189cc3cf1874568e35e7901ff4c982" translate="yes" xml:space="preserve">
          <source>Target</source>
          <target state="translated">Target</target>
        </trans-unit>
        <trans-unit id="3566560919d090e98a5bc58e40d68ba478487e60" translate="yes" xml:space="preserve">
          <source>Target number of non-zero coefficients. Use &lt;code&gt;np.inf&lt;/code&gt; for no limit.</source>
          <target state="translated">0이 아닌 계수의 대상 수입니다. &lt;code&gt;np.inf&lt;/code&gt; 를 제한없이 사용하십시오 .</target>
        </trans-unit>
        <trans-unit id="de81f661c0a5f66b2eb62d654cf5ee97c42a462f" translate="yes" xml:space="preserve">
          <source>Target relative to X for classification or regression; None for unsupervised learning.</source>
          <target state="translated">분류 또는 회귀 분석을 위해 X를 기준으로하는 목표; 비지도 학습에는 해당되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="d9d3de45f60123470c229b29def5cf613978229f" translate="yes" xml:space="preserve">
          <source>Target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions (as returned by &amp;ldquo;decision_function&amp;rdquo; on some classifiers).</source>
          <target state="translated">목표 점수는 포지티브 클래스의 확률 추정치, 신뢰도 값 또는 임계 값이 아닌 결정 측정치 (일부 분류기의 &quot;decision_function&quot;에 의해 반환 됨) 일 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="2da36130db1b72e7220423e41225d3cfbecbf96b" translate="yes" xml:space="preserve">
          <source>Target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions (as returned by &amp;ldquo;decision_function&amp;rdquo; on some classifiers). For binary y_true, y_score is supposed to be the score of the class with greater label.</source>
          <target state="translated">목표 점수는 포지티브 클래스의 확률 추정치, 신뢰도 값 또는 임계 값이 아닌 결정 측정치 (일부 분류기의 &quot;decision_function&quot;에 의해 반환 됨) 일 수 있습니다. 이진 y_true의 경우 y_score는 레이블이 더 큰 클래스의 점수 여야합니다.</target>
        </trans-unit>
        <trans-unit id="1c1467eb9fce38ab3f431a143b7b4099a3d2d978" translate="yes" xml:space="preserve">
          <source>Target values</source>
          <target state="translated">목표 값</target>
        </trans-unit>
        <trans-unit id="1eb29851ae3516c30efee3683f12f4c58d29d5ce" translate="yes" xml:space="preserve">
          <source>Target values (class labels in classification, real numbers in regression)</source>
          <target state="translated">목표 값 (분류의 클래스 레이블, 회귀의 실수)</target>
        </trans-unit>
        <trans-unit id="9236c7bb185e41917cc98485dd0c1b72938dc4f1" translate="yes" xml:space="preserve">
          <source>Target values (integers for classification, real numbers for regression).</source>
          <target state="translated">목표 값 (분류를위한 정수, 회귀를위한 실수).</target>
        </trans-unit>
        <trans-unit id="abfa5417a6d6ee53dab20f6c0ef952512e0950c9" translate="yes" xml:space="preserve">
          <source>Target values (integers)</source>
          <target state="translated">목표 값 (정수)</target>
        </trans-unit>
        <trans-unit id="030d74b88e6ada2cc611aa05819c6875ad926cb6" translate="yes" xml:space="preserve">
          <source>Target values (integers). Will be cast to X&amp;rsquo;s dtype if necessary</source>
          <target state="translated">목표 값 (정수). 필요한 경우 X의 dtype으로 캐스팅됩니다.</target>
        </trans-unit>
        <trans-unit id="489913dd1ba6e89f6fe19c6ab73a6d0ba1572bbc" translate="yes" xml:space="preserve">
          <source>Target values (strings or integers in classification, real numbers in regression) For classification, labels must correspond to classes.</source>
          <target state="translated">목표 값 (분류의 문자열 또는 정수, 회귀의 실수) 분류의 경우 레이블은 클래스와 일치해야합니다.</target>
        </trans-unit>
        <trans-unit id="20f1907edd6deff55545e2c6878457953ca23f05" translate="yes" xml:space="preserve">
          <source>Target values in training data (also required for prediction)</source>
          <target state="translated">훈련 데이터의 목표 값 (예측에도 필요)</target>
        </trans-unit>
        <trans-unit id="5698f85443295556a3231f89aa327fa20aab0ad9" translate="yes" xml:space="preserve">
          <source>Target values of shape = [n_samples] or [n_samples, n_outputs]</source>
          <target state="translated">shape의 목표 값 = [n_samples] 또는 [n_samples, n_outputs]</target>
        </trans-unit>
        <trans-unit id="da9e802f308bd36e270eb5bda433836f08ce2390" translate="yes" xml:space="preserve">
          <source>Target values, array of float values, shape = [n_samples]</source>
          <target state="translated">목표 값, 부동 값의 배열, 모양 = [n_samples]</target>
        </trans-unit>
        <trans-unit id="9d4acf064ddb5b23ed0c4bdf7cb1ed1c86e0cce4" translate="yes" xml:space="preserve">
          <source>Target values, must be binary</source>
          <target state="translated">대상 값, 이진이어야합니다</target>
        </trans-unit>
        <trans-unit id="3784ae1e62853f0d4899c1eb47f9d650c50e4292" translate="yes" xml:space="preserve">
          <source>Target values.</source>
          <target state="translated">목표 값.</target>
        </trans-unit>
        <trans-unit id="7a264b43381dcd3fa803548587f56b48ebe73a21" translate="yes" xml:space="preserve">
          <source>Target values. All sparse matrices are converted to CSR before inverse transformation.</source>
          <target state="translated">목표 값. 모든 희소 행렬은 역변환 전에 CSR로 변환됩니다.</target>
        </trans-unit>
        <trans-unit id="338b0342f37ab2a3243f471f75fbb6b8060759e1" translate="yes" xml:space="preserve">
          <source>Target values. Class labels must be an integer or float, or array-like objects of integer or float for multilabel classifications.</source>
          <target state="translated">목표 값. 클래스 레이블은 정수 또는 부동 소수점이거나 다중 레이블 분류의 경우 정수 또는 부동 소수점 배열과 같은 객체 여야합니다.</target>
        </trans-unit>
        <trans-unit id="d95ddd0372c185ada4f873880d8cf72b3e972b79" translate="yes" xml:space="preserve">
          <source>Target values. The 2-d matrix should only contain 0 and 1, represents multilabel classification.</source>
          <target state="translated">목표 값. 2 차원 행렬은 0과 1 만 포함해야하며 다중 레이블 분류를 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="7d68da7045b7713975074def112516b22e3d548e" translate="yes" xml:space="preserve">
          <source>Target values. The 2-d matrix should only contain 0 and 1, represents multilabel classification. Sparse matrix can be CSR, CSC, COO, DOK, or LIL.</source>
          <target state="translated">목표 값. 2 차원 행렬은 0과 1 만 포함해야하며 다중 레이블 분류를 나타냅니다. 희소 행렬은 CSR, CSC, COO, DOK 또는 LIL 일 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="5ca333a3206ea1ae310cc995419dd5b579b0311c" translate="yes" xml:space="preserve">
          <source>Target values. Will be cast to X&amp;rsquo;s dtype if necessary</source>
          <target state="translated">목표 값. 필요한 경우 X의 dtype으로 캐스팅됩니다.</target>
        </trans-unit>
        <trans-unit id="a73f8fffa45e4edde85ae5cfe9a7df8f5b0ddf64" translate="yes" xml:space="preserve">
          <source>Target vector (class labels).</source>
          <target state="translated">대상 벡터 (클래스 레이블)</target>
        </trans-unit>
        <trans-unit id="fbbf7212be6c75614582f7683105e9b145317ffe" translate="yes" xml:space="preserve">
          <source>Target vector relative to X</source>
          <target state="translated">X에 상대적인 목표 벡터</target>
        </trans-unit>
        <trans-unit id="9b9ad2408038efc60fe0697bee9336f5ceee389a" translate="yes" xml:space="preserve">
          <source>Target vector relative to X.</source>
          <target state="translated">X에 상대적인 목표 벡터.</target>
        </trans-unit>
        <trans-unit id="cb81b6b3ab32530c4b31b59fded732e0bc1457db" translate="yes" xml:space="preserve">
          <source>Target vector.</source>
          <target state="translated">목표 벡터.</target>
        </trans-unit>
        <trans-unit id="86747748812222a9af434d10160edcea63797259" translate="yes" xml:space="preserve">
          <source>Target vectors, where n_samples is the number of samples and n_targets is the number of response variables.</source>
          <target state="translated">n_samples는 샘플 수이고 n_targets는 반응 변수 수입니다.</target>
        </trans-unit>
        <trans-unit id="bb444a37f78059e3557a89e3cec7d30ee2a0e255" translate="yes" xml:space="preserve">
          <source>Target. Will be cast to X&amp;rsquo;s dtype if necessary</source>
          <target state="translated">표적. 필요한 경우 X의 dtype으로 캐스팅됩니다.</target>
        </trans-unit>
        <trans-unit id="652ac2cbbafccc62d55637f20bfa949ef565ffbd" translate="yes" xml:space="preserve">
          <source>Target:</source>
          <target state="translated">Target:</target>
        </trans-unit>
        <trans-unit id="d35260a00f655f27edcc35a7eb16da44a4f671a6" translate="yes" xml:space="preserve">
          <source>Targets</source>
          <target state="translated">Targets</target>
        </trans-unit>
        <trans-unit id="bae347ef05fa5719d83860ee11ad8e50b4550a95" translate="yes" xml:space="preserve">
          <source>Targets for input data.</source>
          <target state="translated">입력 데이터의 대상입니다.</target>
        </trans-unit>
        <trans-unit id="25e14b664fd8a2e3008eacd528868e3512f875a8" translate="yes" xml:space="preserve">
          <source>Targets for supervised learning.</source>
          <target state="translated">지도 학습을위한 목표.</target>
        </trans-unit>
        <trans-unit id="e907b7e300146da06f6bd372dfec64398cc10d60" translate="yes" xml:space="preserve">
          <source>Targets used for scoring. Must fulfill label requirements for all steps of the pipeline.</source>
          <target state="translated">득점에 사용되는 목표. 파이프 라인의 모든 단계에 대한 레이블 요구 사항을 충족해야합니다.</target>
        </trans-unit>
        <trans-unit id="12f7c88d38da9108a78eb595ada57372e18cdd00" translate="yes" xml:space="preserve">
          <source>Technically the Lasso model is optimizing the same objective function as the Elastic Net with &lt;code&gt;l1_ratio=1.0&lt;/code&gt; (no L2 penalty).</source>
          <target state="translated">기술적으로 Lasso 모델은 &lt;code&gt;l1_ratio=1.0&lt;/code&gt; (L2 페널티 없음)으로 Elastic Net과 동일한 목적 함수를 최적화합니다 .</target>
        </trans-unit>
        <trans-unit id="7c21757d6dba7765c9b420762d607df44985a57d" translate="yes" xml:space="preserve">
          <source>Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline.</source>
          <target state="translated">n = 442 명의 당뇨병 환자 각각에 대해 10 개의 기준 변수, 연령, 성별, 체질량 지수, 평균 혈압 및 6 개의 혈청 측정 값을 얻었으며, 관심 반응, 기준선 1 년 후 질병 진행의 정량적 척도 .</target>
        </trans-unit>
        <trans-unit id="faacbc438202f94eb51c4c27efecd77f5a804a90" translate="yes" xml:space="preserve">
          <source>Tenenbaum, J.B.; De Silva, V.; &amp;amp; Langford, J.C. A global geometric framework for nonlinear dimensionality reduction. Science 290 (5500)</source>
          <target state="translated">테네 바움, JB; 데 실바, V .; &amp;amp; Langford, JC 비선형 차원 축소를위한 글로벌 기하학적 프레임 워크. 과학 290 (5500)</target>
        </trans-unit>
        <trans-unit id="2a1358959d0f2f819085e4aa4680265c467cbf33" translate="yes" xml:space="preserve">
          <source>Tenenhaus, M. (1998). La regression PLS: theorie et pratique. Paris: Editions Technic.</source>
          <target state="translated">Tenenhaus, M. (1998). La regression PLS : 이론과 실용. 파리 : 에디션 테크닉.</target>
        </trans-unit>
        <trans-unit id="0a268d2f62458299ec67330e170374c2cecaa669" translate="yes" xml:space="preserve">
          <source>Terms that were ignored because they either:</source>
          <target state="translated">다음과 같은 이유로 무시 된 용어 :</target>
        </trans-unit>
        <trans-unit id="9f2d4d3a12b50c0b296af732b3fa3674c7292a32" translate="yes" xml:space="preserve">
          <source>Test data of which we compute the likelihood, where n_samples is the number of samples and n_features is the number of features. X_test is assumed to be drawn from the same distribution than the data used in fit (including centering).</source>
          <target state="translated">우도를 계산할 테스트 데이터. 여기서 n_samples는 샘플 수이고 n_features는 피처 수입니다. X_test는 적합에 사용 된 데이터 (중심 포함)와 동일한 분포에서 도출 된 것으로 가정합니다.</target>
        </trans-unit>
        <trans-unit id="ed7e95a0302971bec5a032415d69927921186679" translate="yes" xml:space="preserve">
          <source>Test data to be transformed, must have the same number of features as the data used to train the model.</source>
          <target state="translated">변환 할 테스트 데이터는 모델 학습에 사용 된 데이터와 동일한 수의 기능을 가져야합니다.</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
