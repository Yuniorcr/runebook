<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ko" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="bb1fbbd8149208e44d7920553c652b0349a2e4cb" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#lsa&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a0ae8aa40ea2e0cf2d9461f2ba205b77de375f1" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#nmf&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="523c25ac611714a2884232ed4a3b8ea48f8aba43" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#pca&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa9dad4897d2af823fe726cce306b7009091c965" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#sparsecoder&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="424d7bf0d29f09028621f6a77016037f8976dc79" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#sparsepca&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb31f4d810b593c0d4100826896784b7db423e30" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../density#kernel-density&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8cfdd3f6a5935daac5c5163b44a190d819cf3f1" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../ensemble#adaboost&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86400bc4bac71705c9aa6540ee3b030698a90e10" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../ensemble#bagging&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a1ed19879f0785835e56a79d9b743e0ec4944b9" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../ensemble#forest&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2427849a6d85ac2900e5917cd85e9a8f1e0026db" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../ensemble#gradient-boosting&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="74e27ba8cdd2eee9b3d79708f28f6531b62f6a85" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../ensemble#partial-dependence&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02f069134a44c53391b037c7fc439f82145f4541" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../ensemble#random-trees-embedding&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d0298d7a564e2bdb060a82b98586397ab1093aa" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../ensemble#voting-classifier&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b3089ffdf7c0064cb924ed3113eedce86da89f9" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../feature_extraction#dict-feature-extraction&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2cae87659a2fb17a22e879d82f229f7150133e8d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../feature_extraction#feature-hashing&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="227f83f3f45691e4e6ac89bd5c4292e7089c18d1" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../feature_extraction#image-feature-extraction&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10137dbd282e2c34d67ce96d138b644d7e83ce3c" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../feature_extraction#text-feature-extraction&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eeafc617d896a18852b196d65714fb0cdfa671cc" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../feature_selection#rfe&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be00e3925bdea52e2671ec8561d266406b87e844" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../feature_selection#univariate-feature-selection&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9563123917184cb45ca9461f7b3f9e5c290f2dbc" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../feature_selection#variance-threshold&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff9cf599736fe4fe2ebfa784747df392a4200f1f" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../gaussian_process#gaussian-process&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d75a8b7d85fa84978a0ec8f30777c3a42aed10a4" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../grid_search#grid-search&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb887baa2789fddc23d6beef61fca265307ecd58" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../grid_search#randomized-parameter-search&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75601fb7b797d9984583dbb0f5078075298f18d5" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../impute#impute&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a9d395f2980e33b7a924a6a12c64f75a808110b" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../isotonic#isotonic&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="325f5783b35c73d1ac50a27b5fcba72938048669" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../kernel_approximation#additive-chi-kernel-approx&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17d51749641f3da3ac030955c9fa8c847e6b067d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../kernel_approximation#nystroem-kernel-approx&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd440824c891d3899b71ba7cdd6737fff87f7287" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../kernel_approximation#rbf-kernel-approx&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="332847419e8d0030ef93f1eacfc36a11e92afc2b" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../kernel_approximation#skewed-chi-kernel-approx&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d3e13b8d25243ee549b8ac75191bed212dd0367" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../kernel_ridge#kernel-ridge&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79136184797821e9320982ebefd4fdc6aee8fcc9" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../label_propagation#label-propagation&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d6cabb3bcc48c8b13d8efcb84b593c5e97fafde" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../lda_qda#lda-qda&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1997cdd51434d666882d1c5e72dafd16763400c2" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../learning_curve#learning-curve&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="edab24ce901236778794fa27e9de61a91dd86bcf" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#bayesian-regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b98097e17c0cf7837b308d192730df9e81533c5" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#elastic-net&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fdea74fa206e7300a798fcdf4878b5477656890b" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#huber-regression&quot;&gt;User Guide&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="605a6c65b202841b9fab85c42ab592224c31439e" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#lasso&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77dd7df8535c610e7e5f303489e92cf5eb573ae0" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#least-angle-regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62d4fc4abd6308999d4ddf6145d511c1a64a45f8" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#logistic-regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62892a88a6229192a52c43f399daae6da1dfa9e7" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#multi-task-elastic-net&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cce4abc31be44b512209a87a8a1310dccdd746ed" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#multi-task-lasso&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63d9107930cb198a43c0da98652a54726063c1ca" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#omp&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3170770312488b56140f8dbfe00f0d6184e99380" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#passive-aggressive&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62985a29f77d63fea260e6068599d0e367d6df05" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#perceptron&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="893a899efdba3adbe214f9ea4d308ce1b21b9673" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#ransac-regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a05b7db13932de9fce1579dc368f7c3a0c753b2b" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#ridge-regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="423509ee6c18b0afa9860664aaed5d7b2465f60c" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#theil-sen-regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e298c4f51c9646d039f38079ecf13eeb9f51c35" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../manifold#isomap&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6567f6525c87d7835f328b71c58f3e36609854e" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../manifold#locally-linear-embedding&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8786aa07e28fcc1b246cbad7ac302288a26cdbb9" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../manifold#multidimensional-scaling&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5db81b2394b8868895e638c7228ad4393e95e473" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../manifold#spectral-embedding&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8dc4370c51c018661016d7dc40103661eb969866" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../manifold#t-sne&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12f1f31ea9aa0bf152f42f6e525501d833fa544e" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../metrics#chi2-kernel&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ca1a0753b9133cba95108bd5cee6b65a7aca9e8" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../metrics#cosine-similarity&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="925b0027fe482eafac1c97466fcd8e514af11635" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../metrics#linear-kernel&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="648de98a69589997eca7c7636b725bd10a74bddc" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../metrics#metrics&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f7fedfde3b7aa468849d2ea9db9146385c44b72" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../metrics#polynomial-kernel&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35dbd58928fec0c458fe20a80908cd4ec12d274d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../metrics#rbf-kernel&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17512b696dbad66e286c04ad624c1265663ac384" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../metrics#sigmoid-kernel&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5de34567070ba5628c050367f9e925100b0fc96a" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../mixture#bgmm&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="533014884244f3ba887c95cc1354b3af546d07e6" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../mixture#gmm&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f10a79354f2de579c599d2d8732a298b909fdeb" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#accuracy-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="170be2eccb759dd0330485448ffb52236f29617f" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#balanced-accuracy-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c1624381291de658aadcb0f8bba71ec760477bc" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#classification-report&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02442b6427f4449db107842efe6df9bee26b4549" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#cohen-kappa&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60633d1944d25d8e42233b17be1ba5b89c87e50d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#confusion-matrix&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8c53077e3f840542fa4d81c9f7eb854a5a66b5d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#coverage-error&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6db1944ec420ba7d264cc277fb06d2041e89b7b3" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#dummy-estimators&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0061f5a7019cedca60fbe5efee87b2b70aafdf2" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#explained-variance-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="caaad1578fa75a9e67d6c9a942aa5b385b1eddeb" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#hamming-loss&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9f1528ff05d947bd2459205b85f7511b2d1d6e3" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#hinge-loss&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79adced881725d09911672ffa6b1fa3c11470877" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#jaccard-similarity-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c76d43281b705daf6060bc769428acb99df2e1a" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#label-ranking-average-precision&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc1444f7fb419d74ca2fc94b203e3cdd81418e90" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#label-ranking-loss&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="179dd1e5ea8f10c789dddd6c308f1168860f6139" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#log-loss&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f5d5754f2137e3a906eef5875232e8fdfc76081" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#matthews-corrcoef&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f73fb1cae9461ab9f6400985b32548b8964a1b8" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#mean-absolute-error&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d1e1b9b31d605369dff3a437a68762e4751f2e8" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#mean-squared-error&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b1b8bb5d6347e658149088fa461b3192cff9640" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#mean-squared-log-error&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ecf4c4a829a08bf6e6519a0e6067e81b86c62fb2" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#median-absolute-error&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5386b0a93afcac4bca9a0d368219ae5d6677670" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#precision-recall-f-measure-metrics&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca28351a846df3237d411aafad114a8333d94fec" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#r2-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0238aa0a0f95118ffe5b4c380749a69f2c36044d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#roc-metrics&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a760b80ba54e4f80ac167d73dc67b67466c42dd6" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#scoring&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9c28c0d6b12664d980e4a3fb42f49c518447592" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#zero-one-loss&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ce24690cf9d469b3f01a2115acdf5e26e2879d50" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../multiclass#classifierchain&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f67013119ba3c3f06184866c4e55f5b0fe15d7b0" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../multiclass#ecoc&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b596c84eeef681ee59e6eaa23e2ab0178795fb2" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../multiclass#ovo-classification&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b84d654de937d7ea19c79ae871825d13809d0ae" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../multiclass#ovr-classification&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4cadbfd6d3a03561ef5fac73ce993b30f95820e4" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../multiclass#regressorchain&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20c527e1422efd8cd521fd11a837b8771d68c0ed" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../naive_bayes#bernoulli-naive-bayes&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="435ca2dc0d648838a00a3b7bef24dac1a7adaa23" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../naive_bayes#complement-naive-bayes&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3628821e07ebeec87b4e23e6366df9a20b612431" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../naive_bayes#gaussian-naive-bayes&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90e0d6fc128f0746c91ba73859829910362f4188" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../naive_bayes#multinomial-naive-bayes&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbbfd3536fc48b983c24396bb250b8301c1a1818" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../neighbors#classification&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d16dc8c3088a2f09d05b0c673b36bbb65842f4aa" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../neighbors#nearest-centroid-classifier&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="efd88426b64fbe0e99a3366c9d29085372e0f20c" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../neighbors#regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b18180fa58bff344612505155e526d65757d6879" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../neighbors#unsupervised-neighbors&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5ca7e934fae58a25ccd73b564917de49755ed2d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../neural_networks_unsupervised#rbm&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="016cc2045fa59f9f6c76ed8dedce6c6a99a77250" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../outlier_detection#isolation-forest&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23f7b3cec9a4c9afe4a28977379e61c0109412ee" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../outlier_detection#outlier-detection&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c340b4e9171351d4ac97e019f6a473179de82216" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#function-transformer&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76c036a3098b42296deac8a1c5d7290cf1ae1229" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#imputation&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f405e1ec5f4ad33765a94962e9b33f15dadc4ec0" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#kernel-centering&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d6fa8fc54987f399b4367c5904e7df2b83b6932" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#preprocessing-binarization&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb8d6e8ece3c81b8a542f9df331060a314e025fd" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#preprocessing-categorical-features&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f208a23c8504226892516180b238a9e74077793" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#preprocessing-discretization&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f62a25e532bfe0603cc7a0c1c845cc880fe024e" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#preprocessing-normalization&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5dc989f129ad1b4e3e5f3fdd6faa0e98cad51f1a" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#preprocessing-scaler&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82f3e5bb34c91b65a524bb20b361c49cfb0fb233" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#preprocessing-transformer&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3cb28cc10f44afc34f1d4c1193f109ecbe0f6a68" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing_targets#preprocessing-targets&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f8077a63c7a4dbd5d157802c4b7038867dc8b02" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../random_projection#gaussian-random-matrix&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e575964327dd84831f3a16b64ea31b230d51ed1a" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../random_projection#johnson-lindenstrauss&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10155b4478c3cc070907f4a54184b40aecf0a4e1" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../random_projection#sparse-random-matrix&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5272664804ace173fb4cbcbc5ddcfa3fe0afb9ee" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../sgd#sgd&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55b58a72c59a271efec6d011a6007ff1a061e751" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../svm#svm-classification&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68050db6d2a4d61c2fe3bdaccce618cf42039304" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../svm#svm-regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa2ff8d70f29d7b5c10c2ce65368640c95153f3a" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../tree#tree&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc79a8f7da525c429ee0e5b183036b202a8b9f40" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;http://scikit-learn.org/stable/search.html&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea9af338459b2450a415084c5bfba27a1289f204" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;https://docs.python.org/3/c-api/memory.html#memory&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="950c04b3c436731f3c44f5d5621d93d1c15ac31e" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#parallel&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbb9f9ef042590ecbd5eb064b421494a6aa64ba3" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;linear_model#perceptron&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3950e2b914b89c31fec890fc3bac839ddc83abb" translate="yes" xml:space="preserve">
          <source>Read-only attribute to access any step parameter by user given name. Keys are step names and values are steps parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3cc541a2927d490b1b449fbfcf30124e2ea9571" translate="yes" xml:space="preserve">
          <source>Read-only attribute to access any transformer by given name. Keys are transformer names and values are the fitted transformer objects.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83267413a88047148e04736326566653aabdff91" translate="yes" xml:space="preserve">
          <source>Real data sets are often subject to measurement or recording errors. Regular but uncommon observations may also appear for a variety of reasons. Observations which are very uncommon are called outliers. The empirical covariance estimator and the shrunk covariance estimators presented above are very sensitive to the presence of outliers in the data. Therefore, one should use robust covariance estimators to estimate the covariance of its real data sets. Alternatively, robust covariance estimators can be used to perform outlier detection and discard/downweight some observations according to further processing of the data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03d8b77e6b614dc7777dda68e24972906c1421c7" translate="yes" xml:space="preserve">
          <source>Real text may come from a variety of sources that may have used different encodings, or even be sloppily decoded in a different encoding than the one it was encoded with. This is common in text retrieved from the Web. The Python package &lt;a href=&quot;https://github.com/LuminosoInsight/python-ftfy&quot;&gt;ftfy&lt;/a&gt; can automatically sort out some classes of decoding errors, so you could try decoding the unknown text as &lt;code&gt;latin-1&lt;/code&gt; and then using &lt;code&gt;ftfy&lt;/code&gt; to fix errors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1cc9e37cbdee25ad27a9a2fdb64bc7fff098c7f" translate="yes" xml:space="preserve">
          <source>Real-world data set</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f7e1fd9149cf557b13e1453c928ae10ffbc6fe9" translate="yes" xml:space="preserve">
          <source>Recall</source>
          <target state="translated">Recall</target>
        </trans-unit>
        <trans-unit id="259d26fcd1552acd4759cfc21f7fa3b52a38a9cd" translate="yes" xml:space="preserve">
          <source>Recall (\(R\)) is defined as the number of true positives (\(T_p\)) over the number of true positives plus the number of false negatives (\(F_n\)).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2810a64dc1f258f67d5c7c98ab6b2f2d2b737db6" translate="yes" xml:space="preserve">
          <source>Recall is defined as \(\frac{T_p}{T_p+F_n}\), where \(T_p+F_n\) does not depend on the classifier threshold. This means that lowering the classifier threshold may increase recall, by increasing the number of true positive results. It is also possible that lowering the threshold may leave recall unchanged, while the precision fluctuates.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12c28c24975811d7eeb74c51dd4566faa827303c" translate="yes" xml:space="preserve">
          <source>Recall of the positive class in binary classification or weighted average of the recall of each class for the multiclass task.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b0d874ad6f60c8a5546b2d91aee9774c21ade6e" translate="yes" xml:space="preserve">
          <source>Recall that the chi-square test measures dependence between stochastic variables, so using this function &amp;ldquo;weeds out&amp;rdquo; the features that are the most likely to be independent of class and therefore irrelevant for classification.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="478b7b045cf681a86e016d3a84881b0be5302b03" translate="yes" xml:space="preserve">
          <source>Receiver Operating Characteristic (ROC)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e47188effac531b8036f078b2d1c56b3dc650b8" translate="yes" xml:space="preserve">
          <source>Receiver Operating Characteristic (ROC) with cross validation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7f0928f87fcbb2ba15fc48d2fbbcee612b6e0c2" translate="yes" xml:space="preserve">
          <source>Recent theoretical results, however, show that the runtime to get some desired optimization accuracy does not increase as the training set size increases.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5906f3535fa47c9d81e0c2a781b29c5e0d43c1fa" translate="yes" xml:space="preserve">
          <source>Recently deprecated</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9801ca3e1180905873a07a61b9fbf4250f6ef67b" translate="yes" xml:space="preserve">
          <source>Recognizing hand-written digits</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6422fcc967f452634a501ffeeec039bbb50d3cbc" translate="yes" xml:space="preserve">
          <source>Recommendation</source>
          <target state="translated">Recommendation</target>
        </trans-unit>
        <trans-unit id="7ae114b4940981c3f59a807902e797cfb8b9ed0c" translate="yes" xml:space="preserve">
          <source>Reconstruct the image from all of its patches.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a69bf0379a492c240c469c84a534a2a64338d098" translate="yes" xml:space="preserve">
          <source>Reconstruction error associated with &lt;code&gt;embedding_&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1947f1902face65ec435d917879598dbc8ce6456" translate="yes" xml:space="preserve">
          <source>Reconstruction error for the embedding vectors. Equivalent to &lt;code&gt;norm(Y - W Y, 'fro')**2&lt;/code&gt;, where W are the reconstruction weights.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca4afd84f128c746490dc4294009897f387b924c" translate="yes" xml:space="preserve">
          <source>Recover the sources from X (apply the unmixing matrix).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5189873de2645d7e9d6e984c2e4dcb87fbddd6b3" translate="yes" xml:space="preserve">
          <source>Recovering a graphical structure from correlations in the data is a challenging thing. If you are interested in such recovery keep in mind that:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5137c9a2f6442417e8b7aba1873576c030b1a869" translate="yes" xml:space="preserve">
          <source>Recovery is easier from a correlation matrix than a covariance matrix: standardize your observations before running &lt;a href=&quot;generated/sklearn.covariance.graphicallasso#sklearn.covariance.GraphicalLasso&quot;&gt;&lt;code&gt;GraphicalLasso&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8fe62f88fb932af5ce49e0891e6c0663bd4c78a" translate="yes" xml:space="preserve">
          <source>Recurse for subsets \(Q_{left}(\theta^*)\) and \(Q_{right}(\theta^*)\) until the maximum allowable depth is reached, \(N_m &amp;lt; \min_{samples}\) or \(N_m = 1\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="458090dfd850799fafd4039868e137b6110733d3" translate="yes" xml:space="preserve">
          <source>Recursive feature elimination</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="876936c1a03ad35aaee4d7c0a210a8b4cbc79636" translate="yes" xml:space="preserve">
          <source>Recursive feature elimination with built-in cross-validated selection of the best number of features</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b841c9268f6d1867d5de64daddaf5154745ad526" translate="yes" xml:space="preserve">
          <source>Recursive feature elimination with cross-validation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4a79ff0d559c91d907224b612195b949c0dcbb9" translate="yes" xml:space="preserve">
          <source>Recursively merges the pair of clusters that minimally increases a given linkage distance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ddfcf381f764140d92c6bcaa7d2f36dd958b0974" translate="yes" xml:space="preserve">
          <source>Recursively merges the pair of clusters that minimally increases within-cluster variance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc9db3a795571c7e71f45670a1da7ff49b5f1557" translate="yes" xml:space="preserve">
          <source>Red</source>
          <target state="translated">Red</target>
        </trans-unit>
        <trans-unit id="bc205f81be4a216353df393b38e6e448e3d6f659" translate="yes" xml:space="preserve">
          <source>Reduce X to the selected features and then predict using the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf9e72d4c986bce41fdc36284d8c696fc7cd1045" translate="yes" xml:space="preserve">
          <source>Reduce X to the selected features and then predict using the underlying estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d212e578de2f7d8cae3e10b6613c11b25d96417" translate="yes" xml:space="preserve">
          <source>Reduce X to the selected features and then return the score of the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2ba56d17af6254814e9e8837c28ebdbfdf3e81f" translate="yes" xml:space="preserve">
          <source>Reduce X to the selected features and then return the score of the underlying estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ac8754204592a64bbc9d9c861c2255ccc176581" translate="yes" xml:space="preserve">
          <source>Reduce X to the selected features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd16969298621fa8c1f346760a523bd0b16f816f" translate="yes" xml:space="preserve">
          <source>Reduce dimensionality through Gaussian random projection</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be0672c3157469863e0dbc2c594e8a7dbae8ea2b" translate="yes" xml:space="preserve">
          <source>Reduce dimensionality through sparse random projection</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44394b963df355b53266b400bd5efd0a3d98a2e3" translate="yes" xml:space="preserve">
          <source>Reduced version of X. This will always be a dense array.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee5b3fc2a4bbfe1e0e4647a94f46549e1aa8f492" translate="yes" xml:space="preserve">
          <source>Reducing the tendency to crowd points together at the center</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e5aa8a684683e1c180d9009332ba7545707f6be" translate="yes" xml:space="preserve">
          <source>Refer &lt;a href=&quot;../cross_validation#cross-validation&quot;&gt;User Guide&lt;/a&gt; for the various cross-validation strategies that can be used here.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="292c4a00ad1e679d3207ae797de45ae0ac017706" translate="yes" xml:space="preserve">
          <source>Refer the &lt;a href=&quot;../../modules/metrics#metrics&quot;&gt;metrics module&lt;/a&gt; to learn more on the available scoring methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0434a1e9c22e391418e05e3fd58acc0ff48a17cd" translate="yes" xml:space="preserve">
          <source>Refer to the &lt;a href=&quot;generated/sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt;&lt;code&gt;KDTree&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; class documentation for more information on the options available for nearest neighbors searches, including specification of query strategies, distance metrics, etc. For a list of available metrics, see the documentation of the &lt;a href=&quot;generated/sklearn.neighbors.distancemetric#sklearn.neighbors.DistanceMetric&quot;&gt;&lt;code&gt;DistanceMetric&lt;/code&gt;&lt;/a&gt; class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45c3dc1c7731c6185824876ed514e54f71bacb64" translate="yes" xml:space="preserve">
          <source>Reference:</source>
          <target state="translated">Reference:</target>
        </trans-unit>
        <trans-unit id="0807ecc3a87cd348151a8742654a4d11738eee42" translate="yes" xml:space="preserve">
          <source>Reference: Brendan J. Frey and Delbert Dueck, &amp;ldquo;Clustering by Passing Messages Between Data Points&amp;rdquo;, Science Feb. 2007</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d20d0fee3b91643dd8d272ac33d01ca95179d82" translate="yes" xml:space="preserve">
          <source>References</source>
          <target state="translated">References</target>
        </trans-unit>
        <trans-unit id="70202c45dcdc26b5b6c5b6ae6186520b5dbf9a54" translate="yes" xml:space="preserve">
          <source>References &lt;a href=&quot;#manning2008&quot; id=&quot;id16&quot;&gt;[Manning2008]&lt;/a&gt; and &lt;a href=&quot;#everingham2010&quot; id=&quot;id17&quot;&gt;[Everingham2010]&lt;/a&gt; present alternative variants of AP that interpolate the precision-recall curve. Currently, &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; does not implement any interpolated variant. References &lt;a href=&quot;#davis2006&quot; id=&quot;id18&quot;&gt;[Davis2006]&lt;/a&gt; and &lt;a href=&quot;#flach2015&quot; id=&quot;id19&quot;&gt;[Flach2015]&lt;/a&gt; describe why a linear interpolation of points on the precision-recall curve provides an overly-optimistic measure of classifier performance. This linear interpolation is used when computing area under the curve with the trapezoidal rule in &lt;a href=&quot;generated/sklearn.metrics.auc#sklearn.metrics.auc&quot;&gt;&lt;code&gt;auc&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d1e4e7d27b519b1da3d7266c9c87d7861741080" translate="yes" xml:space="preserve">
          <source>References:</source>
          <target state="translated">References:</target>
        </trans-unit>
        <trans-unit id="070e67caa8030cdce21f1126698befb8bcb7259d" translate="yes" xml:space="preserve">
          <source>Refine the implementation and iterate until the exercise is solved.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="30293f3d46bf342b7b87609e1d9e2d226b609141" translate="yes" xml:space="preserve">
          <source>Refit an estimator using the best found parameters on the whole dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11dc7769b39c7e2fbfa28c7d6e99d31fbe0999cf" translate="yes" xml:space="preserve">
          <source>Refitting and updating parameters</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2641cb481062942bba2486cbdfe6e29aaa79719f" translate="yes" xml:space="preserve">
          <source>Regarding the Nearest Neighbors algorithms, if it is found that two neighbors, neighbor &lt;code&gt;k+1&lt;/code&gt; and &lt;code&gt;k&lt;/code&gt;, have identical distances but different labels, the results will depend on the ordering of the training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a4e04e41225aa8ff5e407d1e9442425d3914882" translate="yes" xml:space="preserve">
          <source>Regarding the Nearest Neighbors algorithms, if two neighbors \(k+1\) and \(k\) have identical distances but different labels, the result will depend on the ordering of the training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1eb1498dac3539eb922647f7dc4e358f9465b670" translate="yes" xml:space="preserve">
          <source>Regression</source>
          <target state="translated">Regression</target>
        </trans-unit>
        <trans-unit id="6f098a92c565caa36624cdec85935988f88416e5" translate="yes" xml:space="preserve">
          <source>Regression based on k-nearest neighbors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e52baabe91c57b86ba9b6be948c44c1505083889" translate="yes" xml:space="preserve">
          <source>Regression based on neighbors within a fixed radius.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86da186323db03ac887bf6826a44853992a16e47" translate="yes" xml:space="preserve">
          <source>Regression error for each estimator in the boosted ensemble.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="681b64b08476ebf3542e41565130a2865d2ad32a" translate="yes" xml:space="preserve">
          <source>Regression metrics</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b13f44be1a8f68647be5c088688a38c172f2da40" translate="yes" xml:space="preserve">
          <source>Regression targets are cast to &lt;code&gt;float64&lt;/code&gt; and classification targets are maintained:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3b24a4806e909790a107209c611ee2bc64eea03" translate="yes" xml:space="preserve">
          <source>Regressor chains (see &lt;code&gt;RegressorChain&lt;/code&gt;) is analogous to ClassifierChain as a way of combining a number of regressions into a single multi-target model that is capable of exploiting correlations among targets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71deff46eadb998974bb5b523046459c4126171b" translate="yes" xml:space="preserve">
          <source>Regressor object such as derived from &lt;code&gt;RegressorMixin&lt;/code&gt;. This regressor will automatically be cloned each time prior to fitting.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ee5e8c1b06e8eb22a8ed00eac909d93542fb00f" translate="yes" xml:space="preserve">
          <source>Regular expression denoting what constitutes a &amp;ldquo;token&amp;rdquo;, only used if &lt;code&gt;analyzer == 'word'&lt;/code&gt;. The default regexp select tokens of 2 or more alphanumeric characters (punctuation is completely ignored and always treated as a token separator).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="59f33d089250e1e5437cf1a6ee8788463004eb35" translate="yes" xml:space="preserve">
          <source>Regular expression denoting what constitutes a &amp;ldquo;token&amp;rdquo;, only used if &lt;code&gt;analyzer == 'word'&lt;/code&gt;. The default regexp selects tokens of 2 or more alphanumeric characters (punctuation is completely ignored and always treated as a token separator).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be77bc307e84a0aac10925d8f1fc2021108dec7a" translate="yes" xml:space="preserve">
          <source>Regularization parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b62127743cd97ba6ad4b32187def42a9377f6f5" translate="yes" xml:space="preserve">
          <source>Regularization path of L1- Logistic Regression</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d2806ac87cdfa838914ff36046d85dada345fed" translate="yes" xml:space="preserve">
          <source>Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to &lt;code&gt;C^-1&lt;/code&gt; in other linear models such as LogisticRegression or LinearSVC.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be6006907290ebd855d441d8740e427b29c7dba1" translate="yes" xml:space="preserve">
          <source>Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to &lt;code&gt;C^-1&lt;/code&gt; in other linear models such as LogisticRegression or LinearSVC. If an array is passed, penalties are assumed to be specific to the targets. Hence they must correspond in number.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b376a08d614180566b427fdacf91c0818ef5efed" translate="yes" xml:space="preserve">
          <source>Regularization:</source>
          <target state="translated">Regularization:</target>
        </trans-unit>
        <trans-unit id="1d68b45d1c0799ca4bfb1c8452cff406beffaec4" translate="yes" xml:space="preserve">
          <source>Regularizes the covariance estimate as &lt;code&gt;(1-reg_param)*Sigma + reg_param*np.eye(n_features)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0dc3de67f15c489785125c5ff202f5bb5c1de138" translate="yes" xml:space="preserve">
          <source>Related links:</source>
          <target state="translated">관련된 링크들:</target>
        </trans-unit>
        <trans-unit id="874f63e18691b726b5a14962b962788a3924c9f2" translate="yes" xml:space="preserve">
          <source>Related packages</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="752b35a2a37229a8c218e759b56115e98ae4923e" translate="yes" xml:space="preserve">
          <source>Relative or absolute numbers of training examples that will be used to generate the learning curve. If the dtype is float, it is regarded as a fraction of the maximum size of the training set (that is determined by the selected validation method), i.e. it has to be within (0, 1]. Otherwise it is interpreted as absolute sizes of the training sets. Note that for classification the number of samples usually have to be big enough to contain at least one sample from each class. (default: np.linspace(0.1, 1.0, 5))</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e736750a2d9c467a89ca7f6403004177eb48ae4d" translate="yes" xml:space="preserve">
          <source>Relative tolerance with regards to inertia to declare convergence</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d655bc00f28882b8955bcd0dba64423f1a2a174f" translate="yes" xml:space="preserve">
          <source>Relative tolerance with respect to stress at which to declare convergence.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d7020f448aaf8aacc8b4d63537e375e865fff9d8" translate="yes" xml:space="preserve">
          <source>Remarks</source>
          <target state="translated">Remarks</target>
        </trans-unit>
        <trans-unit id="781186a9e71c63b13e8ecce5db03573a72d6ea8a" translate="yes" xml:space="preserve">
          <source>Remember that the number of samples required to populate the tree doubles for each additional level the tree grows to. Use &lt;code&gt;max_depth&lt;/code&gt; to control the size of the tree to prevent overfitting.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4bf4b976e49f074d117b87d559bb1d8cc83e7f07" translate="yes" xml:space="preserve">
          <source>Remove accents and perform other character normalization during the preprocessing step. &amp;lsquo;ascii&amp;rsquo; is a fast method that only works on characters that have an direct ASCII mapping. &amp;lsquo;unicode&amp;rsquo; is a slightly slower method that works on any characters. None (default) does nothing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88db5eb33c691862cae13f32b896f34ad0aa3e75" translate="yes" xml:space="preserve">
          <source>Remove cache elements to make cache size fit in &lt;code&gt;bytes_limit&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c30c90c09b566737e3cadee249c1dbd9a5837ec5" translate="yes" xml:space="preserve">
          <source>Rennie, J. D., Shih, L., Teevan, J., &amp;amp; Karger, D. R. (2003). &lt;a href=&quot;http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf&quot;&gt;Tackling the poor assumptions of naive bayes text classifiers.&lt;/a&gt; In ICML (Vol. 3, pp. 616-623).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="22cb94c7b65fb89badcb1a01a1bdc2520f86d691" translate="yes" xml:space="preserve">
          <source>Rennie, J. D., Shih, L., Teevan, J., &amp;amp; Karger, D. R. (2003). Tackling the poor assumptions of naive bayes text classifiers. In ICML (Vol. 3, pp. 616-623). &lt;a href=&quot;http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf&quot;&gt;http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b2b956f64f931ba5071d16804050c6a770b0f6c" translate="yes" xml:space="preserve">
          <source>Repeated K-Fold cross validator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09e61edee3c3dd07d459f8a0d674aecb9abdd36c" translate="yes" xml:space="preserve">
          <source>Repeated Stratified K-Fold cross validator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31147e137d241747c95bb952e4b6d40c9dd15695" translate="yes" xml:space="preserve">
          <source>Repeatedly calling fit or partial_fit when warm_start is True can result in a different solution than when calling fit a single time because of the way the data is shuffled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98c452fea3cbd269dd6ec70d0b5da29305d91d54" translate="yes" xml:space="preserve">
          <source>Repeatedly calling fit or partial_fit when warm_start is True can result in a different solution than when calling fit a single time because of the way the data is shuffled. If a dynamic learning rate is used, the learning rate is adapted depending on the number of samples already seen. Calling &lt;code&gt;fit&lt;/code&gt; resets this counter, while &lt;code&gt;partial_fit&lt;/code&gt; will result in increasing the existing counter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c18fbe130422cbff11ad7c343bcdf981b3d72016" translate="yes" xml:space="preserve">
          <source>Repeats K-Fold n times with different randomization in each repetition.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f002866f53e9f1a3ed61e5e1fba772693ba8260" translate="yes" xml:space="preserve">
          <source>Repeats K-Fold n times.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93875d4dd14cbae6916c80c9b56a2c66c78d91d4" translate="yes" xml:space="preserve">
          <source>Repeats Stratified K-Fold n times with different randomization in each repetition.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc3191276b0777bd1786ea11e208ca1193541dc8" translate="yes" xml:space="preserve">
          <source>Repeats Stratified K-Fold n times.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42a28d56095848fa739cd4170b90db72e0e3fba6" translate="yes" xml:space="preserve">
          <source>Representation of a Gaussian mixture model probability distribution. This class allows to estimate the parameters of a Gaussian mixture distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d32f20eabeb1b1b733ce2ae647c966b645ae539" translate="yes" xml:space="preserve">
          <source>Representation of weight vector(s) in kernel space</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="685e526ebada5eb1618a4fc73ea62f4b94674dc7" translate="yes" xml:space="preserve">
          <source>Representing ICA in the feature space gives the view of &amp;lsquo;geometric ICA&amp;rsquo;: ICA is an algorithm that finds directions in the feature space corresponding to projections with high non-Gaussianity. These directions need not be orthogonal in the original feature space, but they are orthogonal in the whitened feature space, in which all directions correspond to the same variance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1838eb2b67d8c8494f46e5efb4e3cfa915b4c40" translate="yes" xml:space="preserve">
          <source>Representing data as sparse combinations of atoms from an overcomplete dictionary is suggested to be the way the mammalian primary visual cortex works. Consequently, dictionary learning applied on image patches has been shown to give good results in image processing tasks such as image completion, inpainting and denoising, as well as for supervised recognition tasks.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae4349c55f1ba2f99a753bd1f91ea54bfb7944a6" translate="yes" xml:space="preserve">
          <source>Represents the type of the target data as evaluated by utils.multiclass.type_of_target. Possible type are &amp;lsquo;continuous&amp;rsquo;, &amp;lsquo;continuous-multioutput&amp;rsquo;, &amp;lsquo;binary&amp;rsquo;, &amp;lsquo;multiclass&amp;rsquo;, &amp;lsquo;multiclass-multioutput&amp;rsquo;, &amp;lsquo;multilabel-indicator&amp;rsquo;, and &amp;lsquo;unknown&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20fa62ad1345bc75375b53f86b5eb2c26d718a95" translate="yes" xml:space="preserve">
          <source>Requires little data preparation. Other techniques often require data normalisation, dummy variables need to be created and blank values to be removed. Note however that this module does not support missing values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb71177a5a5b56c5ebee3cf20f44c503add01c10" translate="yes" xml:space="preserve">
          <source>Resample arrays or sparse matrices in a consistent way</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e8f725f5911194d74f9dab654d27796744b8361" translate="yes" xml:space="preserve">
          <source>Reshape a 2D image into a collection of patches</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8fa86d755254fa7609fa763e5412d46d718d125d" translate="yes" xml:space="preserve">
          <source>Reshaping the output when the function has several return values:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29b6020807e8bc7f4d853b727bb5a844490062e9" translate="yes" xml:space="preserve">
          <source>Restrict coefficients to be &amp;gt;= 0. Be aware that you might want to remove fit_intercept which is set True by default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29979c4d4208dffcb3ff52bc6862f5032a097531" translate="yes" xml:space="preserve">
          <source>Restrict coefficients to be &amp;gt;= 0. Be aware that you might want to remove fit_intercept which is set True by default. Under the positive restriction the model coefficients do not converge to the ordinary-least-squares solution for small values of alpha. Only coefficients up to the smallest alpha value (&lt;code&gt;alphas_[alphas_ &amp;gt;
0.].min()&lt;/code&gt; when fit_path=True) reached by the stepwise Lars-Lasso algorithm are typically in congruence with the solution of the coordinate descent Lasso estimator. As a consequence using LassoLarsCV only makes sense for problems where a sparse solution is expected and/or reached.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39ff48ef2c581a13fca510ce558fecfc50f8d1b9" translate="yes" xml:space="preserve">
          <source>Restrict coefficients to be &amp;gt;= 0. Be aware that you might want to remove fit_intercept which is set True by default. Under the positive restriction the model coefficients do not converge to the ordinary-least-squares solution for small values of alpha. Only coefficients up to the smallest alpha value (&lt;code&gt;alphas_[alphas_ &amp;gt;
0.].min()&lt;/code&gt; when fit_path=True) reached by the stepwise Lars-Lasso algorithm are typically in congruence with the solution of the coordinate descent Lasso estimator. As a consequence using LassoLarsIC only makes sense for problems where a sparse solution is expected and/or reached.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82cf2cea5bace9dd3550046c8448d1e4ee78cc0a" translate="yes" xml:space="preserve">
          <source>Restrict coefficients to be &amp;gt;= 0. Be aware that you might want to remove fit_intercept which is set True by default. Under the positive restriction the model coefficients will not converge to the ordinary-least-squares solution for small values of alpha. Only coefficients up to the smallest alpha value (&lt;code&gt;alphas_[alphas_ &amp;gt;
0.].min()&lt;/code&gt; when fit_path=True) reached by the stepwise Lars-Lasso algorithm are typically in congruence with the solution of the coordinate descent Lasso estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc4c23115ff5f9103869f3c0fe7331685f096b59" translate="yes" xml:space="preserve">
          <source>Restrict coefficients to be &amp;gt;= 0. This option is only allowed with method &amp;lsquo;lasso&amp;rsquo;. Note that the model coefficients will not converge to the ordinary-least-squares solution for small values of alpha. Only coefficients up to the smallest alpha value (&lt;code&gt;alphas_[alphas_ &amp;gt; 0.].min()&lt;/code&gt; when fit_path=True) reached by the stepwise Lars-Lasso algorithm are typically in congruence with the solution of the coordinate descent lasso_path function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e0abdd8dd5609a60428b9608c1cb689b8074f2a" translate="yes" xml:space="preserve">
          <source>Restrict the features to those in support using feature selection.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="241925f53a3e23af00cffc7d748ec3aff26588ad" translate="yes" xml:space="preserve">
          <source>Restricted Boltzmann Machine features for digit classification</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f3abfa37f2cf55ceba7590326cacc826953b894" translate="yes" xml:space="preserve">
          <source>Restricted Boltzmann machines (RBM) are unsupervised nonlinear feature learners based on a probabilistic model. The features extracted by an RBM or a hierarchy of RBMs often give good results when fed into a linear classifier such as a linear SVM or a perceptron.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f490bbf3bdf7bf63209c86a4bdc9ab5af3ad16a" translate="yes" xml:space="preserve">
          <source>Results obtained with LassoLarsIC are based on AIC/BIC criteria.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="520127a681e9beff0545f08ff1691745aa6a2355" translate="yes" xml:space="preserve">
          <source>Results of the clustering, like &lt;code&gt;rows&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f81af77a87bd6c53dcd13a31f0c98b93dfbb1730" translate="yes" xml:space="preserve">
          <source>Results of the clustering. &lt;code&gt;rows[i, r]&lt;/code&gt; is True if cluster &lt;code&gt;i&lt;/code&gt; contains row &lt;code&gt;r&lt;/code&gt;. Available only after calling &lt;code&gt;fit&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09c5e8d3474ffc187ec47434a9de70365f40524a" translate="yes" xml:space="preserve">
          <source>Retrieve all neighbors and average distance within radius r:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a21770a0dd9781336c9b39afe4d33a0b9399f538" translate="yes" xml:space="preserve">
          <source>Retrieve current values for configuration set by &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;set_config&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="795a8c10607f69a8d708655e1dfd2bda87866a63" translate="yes" xml:space="preserve">
          <source>Retrieve current values for configuration set by &lt;a href=&quot;sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;set_config&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d0b50936a7e8c687a75689a3dad17b7991a85ff" translate="yes" xml:space="preserve">
          <source>Return &lt;code&gt;True&lt;/code&gt;, if &lt;code&gt;y&lt;/code&gt; is in a multilabel format, else &lt;code&gt;`False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2cbe175cc2b51d30944704c3deb552cd5596a704" translate="yes" xml:space="preserve">
          <source>Return a callable that handles preprocessing and tokenization</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35ce21f46958d2a4d6fb1e298eab74d1576eefb9" translate="yes" xml:space="preserve">
          <source>Return a function that splits a string into a sequence of tokens</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11d41c098e075f003f9bd2724f42d19606a938aa" translate="yes" xml:space="preserve">
          <source>Return a function to preprocess the text before tokenization</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6bd61b6b672e63d28fbd6bae4611675d07beef25" translate="yes" xml:space="preserve">
          <source>Return a mask which is safe to use on X.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2117f2c8a135db1ec3d7cfe90977838437ebd303" translate="yes" xml:space="preserve">
          <source>Return a node indicator matrix where non zero elements indicates that the samples goes through the nodes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00bb62ba59798790184b007f565618b4467e20e2" translate="yes" xml:space="preserve">
          <source>Return class labels or probabilities for X for each estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd3438647a868f06b1d86d54754f891a6d1b48d4" translate="yes" xml:space="preserve">
          <source>Return feature names for output features</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5493711c1bb2ce4e5d9065fe8f6089dfdca5aee9" translate="yes" xml:space="preserve">
          <source>Return feature names for output features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1402e1d8dc357778164e5a8d0f1414de1f7666d" translate="yes" xml:space="preserve">
          <source>Return items or rows from X using indices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0576952c961c16373284e51db9969a6042ae18da" translate="yes" xml:space="preserve">
          <source>Return log probability estimates for the test vectors X.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72809cd1af29120a326f0c3f682d953d3b6c6e96" translate="yes" xml:space="preserve">
          <source>Return log-probability estimates for the test vector X.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7f22acdaa22f15d766147d74260994078d30e7e" translate="yes" xml:space="preserve">
          <source>Return posterior probabilities of classification.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e90634978b3f0ad930c9250eb92f9e0314026f1" translate="yes" xml:space="preserve">
          <source>Return probability estimates for the test data X.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3cc65811d5c67b9339e5de3fe46c1d36fda147a2" translate="yes" xml:space="preserve">
          <source>Return probability estimates for the test vector X.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eda641cffe9cac67f3fb260fe22ffd308b7dc69c" translate="yes" xml:space="preserve">
          <source>Return probability estimates for the test vectors X.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c1542898f8a4979431ead39d5c15b799d51545e" translate="yes" xml:space="preserve">
          <source>Return squared Euclidean distances.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6fe225e3cb643cedd5bc48ac43be276d960cd4f" translate="yes" xml:space="preserve">
          <source>Return staged predictions for X.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="673aa7cb9999000b961a62897148f368c83b55e3" translate="yes" xml:space="preserve">
          <source>Return staged scores for X, y.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8cf4d1ff3f261b4818ca6a890ea14f5502b4b54a" translate="yes" xml:space="preserve">
          <source>Return terms per document with nonzero entries in X.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5cdf5c1eeea61e59e70be57a77213eebbb153cfb" translate="yes" xml:space="preserve">
          <source>Return the anomaly score of each sample using the IsolationForest algorithm</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe499de3a6f88d7210192161e1c6b2449ab1500c" translate="yes" xml:space="preserve">
          <source>Return the average Hamming loss between element of &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b6f97194ee8e54eea84870d31851fd35f16981f" translate="yes" xml:space="preserve">
          <source>Return the average log-likelihood of all samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c76a887a33fc9d47303cbdd34a0e4499db790aff" translate="yes" xml:space="preserve">
          <source>Return the bin identifier encoded as an integer value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c7fad3d600f9c171ec8dd39485353f247ab50a0" translate="yes" xml:space="preserve">
          <source>Return the decision path in the forest</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3a34834571e54a4248033c9eaba5b8e9bb1789f" translate="yes" xml:space="preserve">
          <source>Return the decision path in the tree</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e96d8947123569170f97aefff01f74cf9b0a6ca" translate="yes" xml:space="preserve">
          <source>Return the feature importances (the higher, the more important the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a6dd0a8039005a5293ba64e678b28da7b07a204e" translate="yes" xml:space="preserve">
          <source>Return the feature importances (the higher, the more important the feature).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94661d32c77cb41c2127232860de2197f7083f9f" translate="yes" xml:space="preserve">
          <source>Return the feature importances.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e8537aa46b4ea8a7cd6323f7580a004a7b06500" translate="yes" xml:space="preserve">
          <source>Return the formatted representation of the object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6327801e23aebebbd4be478323001917b9194e97" translate="yes" xml:space="preserve">
          <source>Return the indices and distances of each point from the dataset lying in a ball with size &lt;code&gt;radius&lt;/code&gt; around the points of the query array. Points lying on the boundary are included in the results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0abc14c002459b9e0ac66d2f83f45cbf2ac07ca6" translate="yes" xml:space="preserve">
          <source>Return the indices and distances of some points from the dataset lying in a ball with size &lt;code&gt;radius&lt;/code&gt; around the points of the query array. Points lying on the boundary are included in the results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="59896f479363f206b5f17c3575cb26dc74dc0030" translate="yes" xml:space="preserve">
          <source>Return the inner statistics A (dictionary covariance) and B (data approximation). Useful to restart the algorithm in an online setting. If return_inner_stats is True, return_code is ignored</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71a76752665369a60f6ab1ee2da126886f72e89c" translate="yes" xml:space="preserve">
          <source>Return the kernel k(X, Y) and optionally its gradient.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c76fd50f1e2f18eb3de394ebc844504c0bd95a4d" translate="yes" xml:space="preserve">
          <source>Return the log of probability estimates.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ffd6e743e192ad562c49919b7b3f381f35e7b8ab" translate="yes" xml:space="preserve">
          <source>Return the log-likelihood of each sample.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b5cedcac6a255d68b2e31008e50600532cc0eda" translate="yes" xml:space="preserve">
          <source>Return the lowest bound for C such that for C in (l1_min_C, infinity) the model is guaranteed not to be empty.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a912065a7d66fe8acf25546053bf0686946ff49b" translate="yes" xml:space="preserve">
          <source>Return the lowest bound for C such that for C in (l1_min_C, infinity) the model is guaranteed not to be empty. This applies to l1 penalized classifiers, such as LinearSVC with penalty=&amp;rsquo;l1&amp;rsquo; and linear_model.LogisticRegression with penalty=&amp;rsquo;l1&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78a008335b51a1c18596b7219334c44cdd4577a2" translate="yes" xml:space="preserve">
          <source>Return the number of CPUs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a83e61f9ab288a41ba43637db7406ca5b7c5e918" translate="yes" xml:space="preserve">
          <source>Return the path of the scikit-learn data dir.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e508a8be5b82335ceafdbaf1e6ec3bbbf998c2f8" translate="yes" xml:space="preserve">
          <source>Return the shortest path length from source to all reachable nodes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f99cff8804146f956c46d41c82ff30a32fcfa0ff" translate="yes" xml:space="preserve">
          <source>Returns -1 for anomalies/outliers and +1 for inliers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7411aff2f211ce9f855fdd4f002eb6a53a8bb626" translate="yes" xml:space="preserve">
          <source>Returns -1 for anomalies/outliers and 1 for inliers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="414e03f46831714a940e3ebbea4ecf95a3ebf408" translate="yes" xml:space="preserve">
          <source>Returns -1 for outliers and 1 for inliers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="505b1feca885daf978e29c8dabb245621a145944" translate="yes" xml:space="preserve">
          <source>Returns True if the given estimator is (probably) a classifier.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a673678f28284206e4f771d2c532b3a9bf68458b" translate="yes" xml:space="preserve">
          <source>Returns True if the given estimator is (probably) a regressor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6877982ee547361eeeaa47d8ae2bb2ebf61437c5" translate="yes" xml:space="preserve">
          <source>Returns a clone of self with given hyperparameters theta.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8748a6c3e3b86a33a87860e1f928708591c21db6" translate="yes" xml:space="preserve">
          <source>Returns a dictionary of shortest path lengths keyed by target.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01c8da86ba8963c8f5e129fe43566909448c21a8" translate="yes" xml:space="preserve">
          <source>Returns a dynamically generated list of indices identifying the samples used for fitting each member of the ensemble, i.e., the in-bag samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da4e687b702358c2c6b9e13a18e3175368903c06" translate="yes" xml:space="preserve">
          <source>Returns a full set of errors in case of multioutput input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36c74e5d06437c1c84b60b753285776e0a5a1083" translate="yes" xml:space="preserve">
          <source>Returns a full set of errors when the input is of multioutput format.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70a672002707e9c7e153c69bb8b9bb04e4527348" translate="yes" xml:space="preserve">
          <source>Returns a full set of scores in case of multioutput input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71c211cc8f7f96892c718bc1f6426bd958810763" translate="yes" xml:space="preserve">
          <source>Returns a huge value if none of the values are positive</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c704a97342e188146c3d1b7928d3c17a32957021" translate="yes" xml:space="preserve">
          <source>Returns a list of all hyperparameter specifications.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0d7bca3b8b9fe8627158f5f4641022fd8b2f454" translate="yes" xml:space="preserve">
          <source>Returns a list of all hyperparameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb51cbfb04bccafd184fd622b215d0ec11a12190" translate="yes" xml:space="preserve">
          <source>Returns a list of feature names, ordered by their indices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34ea8d8a85c45dcfc562bcba86a58c905c99f874" translate="yes" xml:space="preserve">
          <source>Returns a matrix Y = DX, such as D is (n_features, n_components), X is (n_components, n_samples) and each column of X has exactly n_nonzero_coefs non-zero elements.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cbd0ed4e4005716c4bb4e960f578be5923f377b9" translate="yes" xml:space="preserve">
          <source>Returns an array X_original whose transform would be X.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84c9e08b5d96fb6a7f3433674a11022fa61c7b88" translate="yes" xml:space="preserve">
          <source>Returns an array of the weighted modal (most common) value in a</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cafe057316f9911839a97b088931d3f0c5ac396b" translate="yes" xml:space="preserve">
          <source>Returns an instance of self.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d37a031c71fcea2fed996bf43e20f28042d6cc2" translate="yes" xml:space="preserve">
          <source>Returns log-marginal likelihood of theta for training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c002970075885e58132251c6f46e809263939e08" translate="yes" xml:space="preserve">
          <source>Returns n_neighbors of approximate nearest neighbors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb2b7fa44b969b1b6614fbbe40b707fac7d6b54e" translate="yes" xml:space="preserve">
          <source>Returns predicted values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4e6d32f29d1d2d6a2a4394141451d982c2d35a7" translate="yes" xml:space="preserve">
          <source>Returns self.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6e9e9452782912bdbe94ae5d3a76dedbe086889" translate="yes" xml:space="preserve">
          <source>Returns the (flattened, log-transformed) non-fixed hyperparameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="19320b32e9aad6f858ca5ff0ef70b9bfebd867d9" translate="yes" xml:space="preserve">
          <source>Returns the (unshifted) scoring function of the samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="657787f70ef4c51706bb87e28d19c4b31968ad05" translate="yes" xml:space="preserve">
          <source>Returns the &lt;code&gt;rows_&lt;/code&gt; and &lt;code&gt;columns_&lt;/code&gt; members.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a7a0a83f8ee3f88fa0c20189c0d4ac30a4fefe0" translate="yes" xml:space="preserve">
          <source>Returns the average of the array elements. The average is taken over the flattened array by default, otherwise over the specified axis. &lt;code&gt;float64&lt;/code&gt; intermediate and return values are used for integer inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb649861f38c5cc5c11712f4796a00d44a843890" translate="yes" xml:space="preserve">
          <source>Returns the coefficient of determination R^2 of the prediction.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b876cb187b297f2f67823973e339ef65d6c6d93d" translate="yes" xml:space="preserve">
          <source>Returns the decision function of the sample for each class in the model. If decision_function_shape=&amp;rsquo;ovr&amp;rsquo;, the shape is (n_samples, n_classes)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="600321ecf92967e7d8dd43e86b0331fbf58144c8" translate="yes" xml:space="preserve">
          <source>Returns the decision function of the sample for each model in the chain.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f91d241e5e86a06081e46089c96ee552294a8b33" translate="yes" xml:space="preserve">
          <source>Returns the decision function of the samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e78ab037aacacbbe51c5cf862f1aafc8648493d5" translate="yes" xml:space="preserve">
          <source>Returns the diagonal of the kernel k(X, X).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="574020c30b95a24e61673be93c56847aa7847d5e" translate="yes" xml:space="preserve">
          <source>Returns the distance of each sample from the decision boundary for each class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be77bb9a28472ddd253b8a1ae1c648a1964afb4c" translate="yes" xml:space="preserve">
          <source>Returns the distance of each sample from the decision boundary for each class. This can only be used with estimators which implement the decision_function method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7fd90b44e187b56f57ca6954d88dd8f4e918ac9" translate="yes" xml:space="preserve">
          <source>Returns the distances of neighbors if set to True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0736b2ffe9fa12ffc65d7dbeeef31b8086537469" translate="yes" xml:space="preserve">
          <source>Returns the index of the leaf that each sample is predicted as.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57ddd1698c4b02ed38d78d51bae715493abba55a" translate="yes" xml:space="preserve">
          <source>Returns the instance itself.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5121a7f65d8a5a923df4edf2decfc8ea51b437d5" translate="yes" xml:space="preserve">
          <source>Returns the log probability of the sample for each class in the model, where classes are ordered arithmetically for each output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be2a6279ffe3800dbed75602bf2c1d5d359b2ac2" translate="yes" xml:space="preserve">
          <source>Returns the log-probabilities of the sample for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute &lt;code&gt;classes_&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5f0cb89d1ff1d82c8d766a8c85156fc08daf322" translate="yes" xml:space="preserve">
          <source>Returns the log-probability of the sample for each class in the model, where classes are ordered as they are in &lt;code&gt;self.classes_&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbd0270f78921c5ba9ddfa30e030482e2f54f42a" translate="yes" xml:space="preserve">
          <source>Returns the log-probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute &lt;code&gt;classes_&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a88bc22b9f72540c221027a9d39ebb7e5fc56ef0" translate="yes" xml:space="preserve">
          <source>Returns the log-transformed bounds on the theta.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="97643d048879fe1d9046d0bda61e3506826edf2e" translate="yes" xml:space="preserve">
          <source>Returns the mean accuracy on the given test data and labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16bf89209ad0d6f3c40effbaf06ac2b2bd9f54f6" translate="yes" xml:space="preserve">
          <source>Returns the number of non-fixed hyperparameters of the kernel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="242d74929fe683a12c5d1964cc2e68959bffb690" translate="yes" xml:space="preserve">
          <source>Returns the number of splitting iterations in the cross-validator</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cfde4bf50ea94882908403c6cfbc382caa0a24b" translate="yes" xml:space="preserve">
          <source>Returns the number of splitting iterations in the cross-validator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="062b49944b8da81fbcccbc3d275c30eb3575a9c8" translate="yes" xml:space="preserve">
          <source>Returns the object itself</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a733465cae828526edae8695b9480711c0093299" translate="yes" xml:space="preserve">
          <source>Returns the probability each Gaussian (state) in the model given each sample.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55dd4118273bb853d106f8d3ce6ecf4f148e2ce6" translate="yes" xml:space="preserve">
          <source>Returns the probability of the sample for each class in the model, where classes are ordered arithmetically, for each output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="169e349ed5581ba23a1b3967826f1082ad70f358" translate="yes" xml:space="preserve">
          <source>Returns the probability of the sample for each class in the model, where classes are ordered as they are in &lt;code&gt;self.classes_&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d7831ef98ef99639d4e7e4296f84556b7eba4a8" translate="yes" xml:space="preserve">
          <source>Returns the probability of the sample for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute &lt;code&gt;classes_&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="992c84bb142fb4e9f8a180866eff97d2128f0434" translate="yes" xml:space="preserve">
          <source>Returns the probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute &lt;code&gt;classes_&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91d445ad5de7a1e173775e4a8269cced0a330589" translate="yes" xml:space="preserve">
          <source>Returns the score of the model on the data X</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f46bd5d1c2974b7fae37f8d3dfead452c6f632de" translate="yes" xml:space="preserve">
          <source>Returns the score of the prediction.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="860029a1d62d045e78979ea6dcc0cc94815fbc22" translate="yes" xml:space="preserve">
          <source>Returns the score on the given data, if the estimator has been refit.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec85c2a1a827e7e3cec445aa44a3ba7f1fb3772b" translate="yes" xml:space="preserve">
          <source>Returns the score using the &lt;code&gt;scoring&lt;/code&gt; option on the given test data and labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f35f765fc0b19f20a03c16dab251d424926e332" translate="yes" xml:space="preserve">
          <source>Returns the submatrix corresponding to bicluster &lt;code&gt;i&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="054a9a6e8f30544993a8a15fc5be2d4e55b3432a" translate="yes" xml:space="preserve">
          <source>Returns the transformer object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99d4a1b8b2f5f3c702de280e61afe0632ca64c65" translate="yes" xml:space="preserve">
          <source>Returns the transformer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1cf9d50da5b8378604942b3c0df2a2210aa8a416" translate="yes" xml:space="preserve">
          <source>Returns whether the kernel is stationary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7749fcf802c472b6c2f5bd0556805e456ffd5674" translate="yes" xml:space="preserve">
          <source>Returns:</source>
          <target state="translated">Returns:</target>
        </trans-unit>
        <trans-unit id="4cddff2f4be571d7beaa9444607024440a9fab7c" translate="yes" xml:space="preserve">
          <source>Reuters Corpus Volume I (RCV1) is an archive of over 800,000 manually categorized newswire stories made available by Reuters, Ltd. for research purposes. The dataset is extensively described in &lt;a href=&quot;#id9&quot; id=&quot;id7&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99e73709f3009df888327fcabb8674ce816a184a" translate="yes" xml:space="preserve">
          <source>Reuters Dataset related routines</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6601972f4e7c617814e4aa25931a1506c8822de1" translate="yes" xml:space="preserve">
          <source>Revealing data that lie in multiple, different, manifolds or clusters</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f8d44f2683a18a11847619bb1e3f869a99808298" translate="yes" xml:space="preserve">
          <source>Revealing the structure at many scales on a single map</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e69284bfe1901a9177c5faf2810c62e97f3c9a53" translate="yes" xml:space="preserve">
          <source>Reverse the transformation operation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c73f8d477c79109041865780eba0a7fa3d48301f" translate="yes" xml:space="preserve">
          <source>Ridge classifier</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ad4f2cdfdad42fbcf62f66b6cf545d851e2fc3f" translate="yes" xml:space="preserve">
          <source>Ridge classifier with built-in cross validation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="74be3b618f2a083f8a9b4da6cc819c2a6587f706" translate="yes" xml:space="preserve">
          <source>Ridge classifier with built-in cross-validation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed75d75f775d982f734209b7c7a763a7209d7d4d" translate="yes" xml:space="preserve">
          <source>Ridge regression</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab3890b5c3a5eec9daaf653c629ead9cfec0f465" translate="yes" xml:space="preserve">
          <source>Ridge regression is basically minimizing a penalised version of the least-squared function. The penalising &lt;code&gt;shrinks&lt;/code&gt; the value of the regression coefficients. Despite the few data points in each dimension, the slope of the prediction is much more stable and the variance in the line itself is greatly reduced, in comparison to that of the standard linear regression</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f1409ad2637ad7ea4da4ca38bcc785d5bfc9e7b" translate="yes" xml:space="preserve">
          <source>Ridge regression with built-in cross validation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd3c67b92ef64e74b0815493290cb7a3bf85e6f3" translate="yes" xml:space="preserve">
          <source>Ridge regression with built-in cross-validation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee45b6f0ae2d4ed0129b8acfc2869825bd85e481" translate="yes" xml:space="preserve">
          <source>Ridgeway, &amp;ldquo;Generalized Boosted Models: A guide to the gbm package&amp;rdquo;, 2007</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8352081cfa5d8a99ae7d273942336fb93f08e6d3" translate="yes" xml:space="preserve">
          <source>Right argument of the returned kernel k(X, Y). If None, k(X, X) if evaluated instead.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2645e9d1a378ec5a701c32478a48af53bc8241e0" translate="yes" xml:space="preserve">
          <source>Roberto Perdisci JBirch - Java implementation of BIRCH clustering algorithm &lt;a href=&quot;https://code.google.com/archive/p/jbirch&quot;&gt;https://code.google.com/archive/p/jbirch&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cf9f332d60931812bd314aa88e28fabc6bcb34e" translate="yes" xml:space="preserve">
          <source>Robust covariance estimation and Mahalanobis distances relevance</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="328dcbba68a9846c5e7033a860bdea23249dfaea" translate="yes" xml:space="preserve">
          <source>Robust fitting is demoed in different situations:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="165bec40e6cdbbb5b900c937da314f589c12c4da" translate="yes" xml:space="preserve">
          <source>Robust linear estimator fitting</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d0888c61d68e6fb252eed4a871cfde78643505b" translate="yes" xml:space="preserve">
          <source>Robust linear model estimation using RANSAC</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23aa26f47001b43f39b1c12966fa2eb9a36e10dc" translate="yes" xml:space="preserve">
          <source>Robust regression is interested in fitting a regression model in the presence of corrupt data: either outliers, or error in the model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1c857b593e499d6b23d149cc792aa8d43d0a1b9" translate="yes" xml:space="preserve">
          <source>Robust vs Empirical covariance estimate</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a7d1b999eca5ec26d95619619667b3c0bc96c39" translate="yes" xml:space="preserve">
          <source>RobustScaler</source>
          <target state="translated">RobustScaler</target>
        </trans-unit>
        <trans-unit id="cf1505b8a53e6cbb8dc8ba2f11bca53f9b323bb5" translate="yes" xml:space="preserve">
          <source>Robustness to outliers in output space (via robust loss functions)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e83213080c2899f47c79669335c5a49e2d9bcc2" translate="yes" xml:space="preserve">
          <source>RogersTanimotoDistance</source>
          <target state="translated">RogersTanimotoDistance</target>
        </trans-unit>
        <trans-unit id="fc05bb810ef4352b5a9e6b3b3412f9c1914cad7e" translate="yes" xml:space="preserve">
          <source>Root of the CFTree.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b104e71c68c3dfb7b73342e69442ee327c52c9d1" translate="yes" xml:space="preserve">
          <source>Rosenberg and Hirschberg further define &lt;strong&gt;V-measure&lt;/strong&gt; as the &lt;strong&gt;harmonic mean of homogeneity and completeness&lt;/strong&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e15211ffc09c4f35527c5b1ce8949f07dae5bb18" translate="yes" xml:space="preserve">
          <source>Ross, J. Lim, R. Lin, M. Yang. Incremental Learning for Robust Visual</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f65ad777cccbda986726bad67a79a0d4e6952a1" translate="yes" xml:space="preserve">
          <source>Rousseeuw and Van Driessen &lt;a href=&quot;#id12&quot; id=&quot;id10&quot;&gt;[4]&lt;/a&gt; developed the FastMCD algorithm in order to compute the Minimum Covariance Determinant. This algorithm is used in scikit-learn when fitting an MCD object to data. The FastMCD algorithm also computes a robust estimate of the data set location at the same time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae08282270da387413c613e92da23758e2b46e3a" translate="yes" xml:space="preserve">
          <source>Rousseeuw, P.J., Van Driessen, K. &amp;ldquo;A fast algorithm for the minimum covariance determinant estimator&amp;rdquo; Technometrics 41(3), 212 (1999)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a147028da41451d64de65dc97e27ab58134df945" translate="yes" xml:space="preserve">
          <source>Row and column indices of the i&amp;rsquo;th bicluster.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dff2cf4a000d72bb07a097b831cbf5d2768a6505" translate="yes" xml:space="preserve">
          <source>Row partition labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="173c6825d2552deeb977ce21a1b427b130c7161e" translate="yes" xml:space="preserve">
          <source>Run check_array on X.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6650ce15c2e2f568588d9785e121ddc90d1aad0a" translate="yes" xml:space="preserve">
          <source>Run cross-validation for single metric evaluation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76efb9e1238b374a0b90938642b1634441ade412" translate="yes" xml:space="preserve">
          <source>Run fit on one set of parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3fa8caf4882a1b3e630b18ced7d9eb65515b91e" translate="yes" xml:space="preserve">
          <source>Run fit with all sets of parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="383d7fee23c4f0d9aff2e3402febc2f06b463f07" translate="yes" xml:space="preserve">
          <source>Run score function on (X, y) and get the appropriate features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75c05d3e2177d247ba4a31fbd998a4fb5a5db366" translate="yes" xml:space="preserve">
          <source>Run the clustering and plot</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5095c28abb8c39013ff6dacae123b7ebc126a8c4" translate="yes" xml:space="preserve">
          <source>Running &lt;code&gt;GridSearchCV&lt;/code&gt; using multiple evaluation metrics</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fcbd6be054955e185bc7730125f0a6053dc76b6" translate="yes" xml:space="preserve">
          <source>RussellRaoDistance</source>
          <target state="translated">RussellRaoDistance</target>
        </trans-unit>
        <trans-unit id="3d35c7a842c5951e6e7d27253c473500693538e4" translate="yes" xml:space="preserve">
          <source>S. Marsland, &amp;ldquo;Machine Learning: An Algorithmic Perspective&amp;rdquo;, Chapter 10, 2009. &lt;a href=&quot;http://seat.massey.ac.nz/personal/s.r.marsland/Code/10/lle.py&quot;&gt;http://seat.massey.ac.nz/personal/s.r.marsland/Code/10/lle.py&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c12fa511d52194a5681ee8be41a1e398d85f290" translate="yes" xml:space="preserve">
          <source>S1</source>
          <target state="translated">S1</target>
        </trans-unit>
        <trans-unit id="474c9bc027ee3ef22851a5f8bfd976f08b197386" translate="yes" xml:space="preserve">
          <source>S2</source>
          <target state="translated">S2</target>
        </trans-unit>
        <trans-unit id="37a81d7cd2e4b8f7f2a8a35b26aa90c58c80afd8" translate="yes" xml:space="preserve">
          <source>S3</source>
          <target state="translated">S3</target>
        </trans-unit>
        <trans-unit id="69c195a662b9112a35f65e12d131a5b27ca87f2b" translate="yes" xml:space="preserve">
          <source>S4</source>
          <target state="translated">S4</target>
        </trans-unit>
        <trans-unit id="c3371c7d85f3802028519c691cc2d442bd72de40" translate="yes" xml:space="preserve">
          <source>S5</source>
          <target state="translated">S5</target>
        </trans-unit>
        <trans-unit id="69ba3f2fc09a1e00fed9f31e478c0eff5dced9e9" translate="yes" xml:space="preserve">
          <source>S6</source>
          <target state="translated">S6</target>
        </trans-unit>
        <trans-unit id="4c804f5a0904acd450fcddddab0dc632cd582e71" translate="yes" xml:space="preserve">
          <source>SA structure :</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0d8a0ca44b0696f5feb9dd5b2e501345c937c3c" translate="yes" xml:space="preserve">
          <source>SAG &amp;ndash; Mark Schmidt, Nicolas Le Roux, and Francis Bach</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5f439b003a3f7bf1ca666e889005dbe06e41518" translate="yes" xml:space="preserve">
          <source>SAGA &amp;ndash; Defazio, A., Bach F. &amp;amp; Lacoste-Julien S. (2014).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d555084f4d87558b3e1f1e41594c4567a72ffe9" translate="yes" xml:space="preserve">
          <source>SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives &lt;a href=&quot;https://arxiv.org/abs/1407.0202&quot;&gt;https://arxiv.org/abs/1407.0202&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47b0a2b31abf5ad7f508685c420934a3c9ceb224" translate="yes" xml:space="preserve">
          <source>SEuclideanDistance</source>
          <target state="translated">SEuclideanDistance</target>
        </trans-unit>
        <trans-unit id="25a0a10d5e57106efcf106b18fe758dffe61fd61" translate="yes" xml:space="preserve">
          <source>SF structure :</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="feee827f58feab6583e46c495c391eeebda8d75f" translate="yes" xml:space="preserve">
          <source>SGD fits a linear model to the training data. The member &lt;code&gt;coef_&lt;/code&gt; holds the model parameters:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35603e0805a9ac47c224548952c5bc406f24681d" translate="yes" xml:space="preserve">
          <source>SGD has been successfully applied to large-scale and sparse machine learning problems often encountered in text classification and natural language processing. Given that the data is sparse, the classifiers in this module easily scale to problems with more than 10^5 training examples and more than 10^5 features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56826c4ca309b6e5b6fa33e22889222819ef98da" translate="yes" xml:space="preserve">
          <source>SGD is sensitive to feature scaling.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aaaef0a56ff89a9fec86986b723dbc52782459a2" translate="yes" xml:space="preserve">
          <source>SGD requires a number of hyperparameters such as the regularization parameter and the number of iterations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2040a5158079ffce24f8b06ceaf317e6a14bde86" translate="yes" xml:space="preserve">
          <source>SGD stands for Stochastic Gradient Descent: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5409a86e2f59aff11c69a7f4ca4772e4d726f18" translate="yes" xml:space="preserve">
          <source>SGD: Maximum margin separating hyperplane</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="18e5f1878526787df86a80bc190ed115937ff46a" translate="yes" xml:space="preserve">
          <source>SGD: Penalties</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba517f5cdbbcd13a216515c00be2b80ddd3cbbe7" translate="yes" xml:space="preserve">
          <source>SGD: Weighted samples</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="641c7150d49f1de3baa1799ce8aa92905ea998a5" translate="yes" xml:space="preserve">
          <source>SGD: convex loss functions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf02fe82611c518b4850cfb8c1c714a0440b4d08" translate="yes" xml:space="preserve">
          <source>SGDClassifier can optimize the same cost function as LinearSVC by adjusting the penalty and loss parameters. In addition it requires less memory, allows incremental (online) learning, and implements various loss functions and regularization regimes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf24393981aae53fe434537eb506bff7add3be48" translate="yes" xml:space="preserve">
          <source>SGDRegressor can optimize the same cost function as LinearSVR by adjusting the penalty and loss parameters. In addition it requires less memory, allows incremental (online) learning, and implements various loss functions and regularization regimes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="176392773f6f864a2cd9bd404f4a47c5c644890a" translate="yes" xml:space="preserve">
          <source>SKLEARN_ASSUME_FINITE:</source>
          <target state="translated">SKLEARN_ASSUME_FINITE:</target>
        </trans-unit>
        <trans-unit id="489eb75f9c6e942df30f531fa00564449214dacd" translate="yes" xml:space="preserve">
          <source>SKLEARN_SEED:</source>
          <target state="translated">SKLEARN_SEED:</target>
        </trans-unit>
        <trans-unit id="fb52c7cf741e16036b16d4758134cf0347d8fc36" translate="yes" xml:space="preserve">
          <source>SKLEARN_SITE_JOBLIB:</source>
          <target state="translated">SKLEARN_SITE_JOBLIB:</target>
        </trans-unit>
        <trans-unit id="182f8430558645ae44ec3e02ca4f97fb187183b5" translate="yes" xml:space="preserve">
          <source>SKLEARN_SKIP_NETWORK_TESTS:</source>
          <target state="translated">SKLEARN_SKIP_NETWORK_TESTS:</target>
        </trans-unit>
        <trans-unit id="ce18ea047ea4320bf80e4467a9a4d6882d0a0c5c" translate="yes" xml:space="preserve">
          <source>SKLEARN_WORKING_MEMORY:</source>
          <target state="translated">SKLEARN_WORKING_MEMORY:</target>
        </trans-unit>
        <trans-unit id="85baaac41fa88b4fe00f7bdceca42996f772a2b4" translate="yes" xml:space="preserve">
          <source>SVD solver to use. Either &amp;ldquo;arpack&amp;rdquo; for the ARPACK wrapper in SciPy (scipy.sparse.linalg.svds), or &amp;ldquo;randomized&amp;rdquo; for the randomized algorithm due to Halko (2009).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6af7199e8ddc63c7a75cd98d1b65821ed0efc2bf" translate="yes" xml:space="preserve">
          <source>SVD suffers from a problem called &amp;ldquo;sign indeterminacy&amp;rdquo;, which means the sign of the &lt;code&gt;components_&lt;/code&gt; and the output from transform depend on the algorithm and random state. To work around this, fit instances of this class to data once, then keep the instance around to do transformations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cbdd2a97d41c59ff884c822b77e5bbe85f9ba90e" translate="yes" xml:space="preserve">
          <source>SVM Exercise</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b34d9f0295b39d40cbe5096a7d120f8070675e5a" translate="yes" xml:space="preserve">
          <source>SVM Margins Example</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a8ae56c5c075834fc4807237ba47d91cf12057b" translate="yes" xml:space="preserve">
          <source>SVM with custom kernel</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9789cc13908fc9d7be883f1548c74adba099c7a4" translate="yes" xml:space="preserve">
          <source>SVM-Anova: SVM with univariate feature selection</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d60b833a10753cb7a1e8445b24053366a62c2ba" translate="yes" xml:space="preserve">
          <source>SVM-Kernels</source>
          <target state="translated">SVM-Kernels</target>
        </trans-unit>
        <trans-unit id="83aa3a7ffedeffc55020607871a4abaa66f7a1c9" translate="yes" xml:space="preserve">
          <source>SVM: Maximum margin separating hyperplane</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6eea5ef53cf13552f771a06f957229c9212aa8d7" translate="yes" xml:space="preserve">
          <source>SVM: Separating hyperplane for unbalanced classes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf6b9fd9e8253b8b76eff229f07c0360f2de682d" translate="yes" xml:space="preserve">
          <source>SVM: Weighted samples</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85f0e3e6752e2995f480bc673dc3817c45715958" translate="yes" xml:space="preserve">
          <source>SVMs can be used in regression &amp;ndash;&lt;a href=&quot;../../modules/generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt;&lt;code&gt;SVR&lt;/code&gt;&lt;/a&gt; (Support Vector Regression)&amp;ndash;, or in classification &amp;ndash;&lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; (Support Vector Classification).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b1be869f06df9c591de1bdf323bb61b2e38d27a" translate="yes" xml:space="preserve">
          <source>SVMs decision function depends on some subset of the training data, called the support vectors. Some properties of these support vectors can be found in members &lt;code&gt;support_vectors_&lt;/code&gt;, &lt;code&gt;support_&lt;/code&gt; and &lt;code&gt;n_support&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="798a54068fd4b730861d7008bf329c0c0c2c0e43" translate="yes" xml:space="preserve">
          <source>SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see &lt;a href=&quot;#scores-probabilities&quot;&gt;Scores and probabilities&lt;/a&gt;, below).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db6e7e410412f58574f766c3911f49badd42beca" translate="yes" xml:space="preserve">
          <source>Safety</source>
          <target state="translated">Safety</target>
        </trans-unit>
        <trans-unit id="fda84c44a4e30d5cb2a98cb6be80221a0339a2c0" translate="yes" xml:space="preserve">
          <source>Same as K-Fold but preserves the class distribution within each fold.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ee571b5564a06c8cd876b67cbf6301868feea05" translate="yes" xml:space="preserve">
          <source>Same as shuffle split but preserves the class distribution within each iteration.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7e9bc6c5c66894cda1e66e0aa803e5c89c613cb" translate="yes" xml:space="preserve">
          <source>Same data with dummy feature added as first column.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8528afb44e724dea86ccba97d23f6755cfc862fa" translate="yes" xml:space="preserve">
          <source>Sample data, in the form of a numpy array or a precomputed &lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58a55d6f93d14931521825c7a646b62d82a23f61" translate="yes" xml:space="preserve">
          <source>Sample data, shape = (n_samples, n_features), in the form of a numpy array or a NearestNeighbors object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10ce65324acefea0898135b900280dadfb96fe1c" translate="yes" xml:space="preserve">
          <source>Sample data, shape = (n_samples, n_features), in the form of a numpy array, precomputed tree, or NearestNeighbors object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea442856bb6f3247c403f5eacbad9d49d9f34166" translate="yes" xml:space="preserve">
          <source>Sample integers without replacement.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4057b3cb6bd141b135fafdb32fce3f5d0c92b8db" translate="yes" xml:space="preserve">
          <source>Sample matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc8d82180e352f6e4eb38618a9b77ce032b1c63f" translate="yes" xml:space="preserve">
          <source>Sample pipeline for text feature extraction and evaluation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0982f69f498171fb424746f3b46f588b79249d60" translate="yes" xml:space="preserve">
          <source>Sample usage of Nearest Centroid classification. It will plot the decision boundaries for each class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f22b9a32693422a5abcec4767410509915bc2f8f" translate="yes" xml:space="preserve">
          <source>Sample usage of Nearest Neighbors classification. It will plot the decision boundaries for each class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6f1c43a568cbfebecbc9c4a468d534512e56696" translate="yes" xml:space="preserve">
          <source>Sample vectors from which to compute variances.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4701e0099b8ff3338dac13ba80a9fd03a1b4e3e5" translate="yes" xml:space="preserve">
          <source>Sample vectors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e2a418c622901df3ef07f5cc98282eefd0e90959" translate="yes" xml:space="preserve">
          <source>Sample weight</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e69657285f6aad82f9a81418454c1c4adb873fb2" translate="yes" xml:space="preserve">
          <source>Sample weight.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03782597aeab2816675e9752810fe748c242aeef" translate="yes" xml:space="preserve">
          <source>Sample weights.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="516c4850672ccbdd1765de8db9d3606a458e566e" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, the sample weights are initialized to 1 / n_samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06e56dd5257a783cd783e2275240a5cef38438c1" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, the sample weights are initialized to &lt;code&gt;1 / n_samples&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b28026c224fc212b3c8db8d7abcf83fe154d5aba" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd4e4922a0bf331287b6e7fdee69023638c0a9c2" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Note that this is supported only if all underlying estimators support sample weights.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72b5ffbf428e4946121de0a0ea4fb4fa9205e66d" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Note that this is supported only if the base estimator supports sample weighting.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e07f10e1efb6d03970a11a668db91780f97be9f4" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Only supported if the underlying regressor supports sample weights.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4811960b5c60cf1d2e21f4adf57777acf8cf860" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76ebb3a0858ee52c5cebb457753ce9dfb9f1fd6e" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. In the case of classification, splits are also ignored if they would result in any single class carrying a negative weight in either child node.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="317d3738fe42cf9aeb8c2e6052e8dee6f03e55e0" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. Splits are also ignored if they would result in any single class carrying a negative weight in either child node.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a90c0865394b45b5f31d5c73cc5fa995827fa090" translate="yes" xml:space="preserve">
          <source>Samples a subset of training points, computes kernel on these and computes normalization matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="489527d2412e4e73b577f6c6fbbfa5b2fc34f813" translate="yes" xml:space="preserve">
          <source>Samples generator</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="984aa7241ddfaa0a1125ba76d49684d954091644" translate="yes" xml:space="preserve">
          <source>Samples may have several labels each (see &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&quot;&gt;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&lt;/a&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a729b3c883140152c8be9c9b913932e3054a28dd" translate="yes" xml:space="preserve">
          <source>Samples per class</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72ff32775331fbcdecdd7b50f2f019ca6fd41d2c" translate="yes" xml:space="preserve">
          <source>Samples random projection according to n_features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="251d1d7b5c7f8793378b7d465a809b22ff0293ea" translate="yes" xml:space="preserve">
          <source>Samples to cluster.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b35c86a656c810d2ffde5bec3bbb5716273c85d" translate="yes" xml:space="preserve">
          <source>Samples total</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d94a358c32f7a1a8aa072b320513050f66fbf3bb" translate="yes" xml:space="preserve">
          <source>Samples.</source>
          <target state="translated">Samples.</target>
        </trans-unit>
        <trans-unit id="79b4194bd3e79bf7f3c58fb9c6afe5574c4f3465" translate="yes" xml:space="preserve">
          <source>Samples. Each sample must be a text document (either bytes or unicode strings, file name or file object depending on the constructor argument) which will be tokenized and hashed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ecf733dec873b2818a96fff2c4d7137b5e9cce2" translate="yes" xml:space="preserve">
          <source>Samples. Each sample must be iterable an (e.g., a list or tuple) containing/generating feature names (and optionally values, see the input_type constructor argument) which will be hashed. raw_X need not support the len function, so it can be the result of a generator; n_samples is determined on the fly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="475a3c12e7131d5c7c597d45cbde5d7c042c5697" translate="yes" xml:space="preserve">
          <source>Samples. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead a precomputed kernel matrix, shape = [n_samples, n_samples_fitted], where n_samples_fitted is the number of samples used in the fitting for this estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="786961f4d535734fe86dc46d23d2c4ae6643e27e" translate="yes" xml:space="preserve">
          <source>Sampling interval. Must be specified when sample_steps not in {1,2,3}.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b1ee52c21297b409f91752fd0536580b7df89b8" translate="yes" xml:space="preserve">
          <source>Sampling more dimensions clearly leads to better classification results, but comes at a greater cost. This means there is a tradeoff between runtime and accuracy, given by the parameter n_components. Note that solving the Linear SVM and also the approximate kernel SVM could be greatly accelerated by using stochastic gradient descent via &lt;a href=&quot;../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt;&lt;/a&gt;. This is not easily possible for the case of the kernelized SVM.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e5ac0adafac21480f1a521f8334d2085c97ee0a" translate="yes" xml:space="preserve">
          <source>Sanjoy Dasgupta and Anupam Gupta, 1999, &amp;ldquo;An elementary proof of the Johnson-Lindenstrauss Lemma.&amp;rdquo; &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72e45a031f2d9ef687b450c7dbe04851bc78b888" translate="yes" xml:space="preserve">
          <source>Sanjoy Dasgupta and Anupam Gupta, 1999. &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.39.3334&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;An elementary proof of the Johnson-Lindenstrauss Lemma.&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="916673b66f20fa78c64c3896647266270d456625" translate="yes" xml:space="preserve">
          <source>Sanjoy Dasgupta. 2000. &lt;a href=&quot;http://cseweb.ucsd.edu/~dasgupta/papers/randomf.pdf&quot;&gt;Experiments with random projection.&lt;/a&gt; In Proceedings of the Sixteenth conference on Uncertainty in artificial intelligence (UAI&amp;lsquo;00), Craig Boutilier and Mois&amp;eacute;s Goldszmidt (Eds.). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 143-151.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3dc12a8bd942b1cd9b3ab450a012927de384bfa6" translate="yes" xml:space="preserve">
          <source>Save fitted model as best model if number of inlier samples is maximal. In case the current estimated model has the same number of inliers, it is only considered as the best model if it has better score.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94b03c70b196c58604c0a7faf7218bf6901b8e0c" translate="yes" xml:space="preserve">
          <source>Scalability</source>
          <target state="translated">Scalability</target>
        </trans-unit>
        <trans-unit id="199d842d852910d77fdbfb1dc59f0d2885e1b21f" translate="yes" xml:space="preserve">
          <source>Scalability can be boosted by using fewer seeds, for example by using a higher value of min_bin_freq in the get_bin_seeds function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29f2c344812c53bdbb5e427694d6be2d492aaf47" translate="yes" xml:space="preserve">
          <source>Scalability, due to the sequential nature of boosting it can hardly be parallelized.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6484bee2609587949da674a2bdf0fe83ede7b2a" translate="yes" xml:space="preserve">
          <source>Scalability:</source>
          <target state="translated">Scalability:</target>
        </trans-unit>
        <trans-unit id="61dc05feb549eab6c07b7a94be612c538f71b094" translate="yes" xml:space="preserve">
          <source>Scalable Linear Support Vector Machine for classification implemented using liblinear. Check the See also section of LinearSVC for more comparison element.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eecb89d050bc91f7d55354e38239145e4acf15ef" translate="yes" xml:space="preserve">
          <source>Scalable Linear Support Vector Machine for regression implemented using liblinear.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="22b700f6b9ee53c2fb9ac81cf84c12516aa516e1" translate="yes" xml:space="preserve">
          <source>Scalable linear Support Vector Machine for classification using liblinear.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bdabc7bc958d2928d9827e9b54f6956c7bb824f2" translate="yes" xml:space="preserve">
          <source>Scale back the data to the original representation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="561dee1ec35178a67790d71472d188769f1e1bd6" translate="yes" xml:space="preserve">
          <source>Scale each feature by its maximum absolute value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d3a1b9b18053dd9fb9c5426f583cf0f7d587a14" translate="yes" xml:space="preserve">
          <source>Scale each feature of the data matrix by multiplying with specific scale provided by the caller assuming a (n_samples, n_features) shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6c81268e0182a1a807ca4c628dc76b97a0fa5dc" translate="yes" xml:space="preserve">
          <source>Scale each feature to the [-1, 1] range without breaking the sparsity.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5deb9ce023c33b22d107e28507be5494ec70764b" translate="yes" xml:space="preserve">
          <source>Scale each non zero row of X to unit norm</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="617d6ad46bfccaf27b4ba0f374d21f46a99d594e" translate="yes" xml:space="preserve">
          <source>Scale each row of the data matrix by multiplying with specific scale provided by the caller assuming a (n_samples, n_features) shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2febfe8f8ec8796f6ba7a4455156e82486b6b9ad" translate="yes" xml:space="preserve">
          <source>Scale factor between inner and outer circle.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="651dfd0de4ed652c75c33e720387c590f106c0bd" translate="yes" xml:space="preserve">
          <source>Scale features using statistics that are robust to outliers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea253b52225bff13ccf219a7ede865331cee2a5e" translate="yes" xml:space="preserve">
          <source>Scale input vectors individually to unit norm (vector length).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3db146d5ef4350db484651a2947cc4449aa1c920" translate="yes" xml:space="preserve">
          <source>Scale mixture parameter</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="214cf07e698e140c0ab386ee80be892f7e60d56f" translate="yes" xml:space="preserve">
          <source>Scale the data</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a00231cc0fa6cda008f7de726dc3328122b68e67" translate="yes" xml:space="preserve">
          <source>Scaled data has zero mean and unit variance:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28f5624ffdfd0dbb670e710c5400ff826061c8e3" translate="yes" xml:space="preserve">
          <source>Scalers are linear (or more precisely affine) transformers and differ from each other in the way to estimate the parameters used to shift and scale each feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42fb0a5f800741efdeeef6c8d3f6efbb496929e6" translate="yes" xml:space="preserve">
          <source>Scaling a 1D array</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e180a611580dedaac6cdcb57565a42487e31efa" translate="yes" xml:space="preserve">
          <source>Scaling features of X according to feature_range.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="faa375cb6d0913845d11a421f85f4fc1917244d4" translate="yes" xml:space="preserve">
          <source>Scaling inputs to unit norms is a common operation for text classification or clustering for instance. For instance the dot product of two l2-normalized TF-IDF vectors is the cosine similarity of the vectors and is the base similarity metric for the Vector Space Model commonly used by the Information Retrieval community.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9df043572b1169b126da4f0a95f811ab4322363" translate="yes" xml:space="preserve">
          <source>Scaling of the features in the space spanned by the class centroids.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f91f363e9d78c82d08c38c5a1dbde0b091a85898" translate="yes" xml:space="preserve">
          <source>Scaling parameter of the chi2 kernel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="611f59db789837a47c8391146e294e88684d2aac" translate="yes" xml:space="preserve">
          <source>Scaling the regularization parameter for SVCs</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ca361aee1b505e96263673a562173e09064f7c8" translate="yes" xml:space="preserve">
          <source>Scaling vs Whitening</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b38453e586dafca0c0308eafbfda226dcf7f7c2" translate="yes" xml:space="preserve">
          <source>Scikit-learn also embed a couple of sample JPEG images published under Creative Commons license by their authors. Those image can be useful to test algorithms and pipeline on 2D data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f09669bc19a45a6af1925c5dd7e5320d97b9858" translate="yes" xml:space="preserve">
          <source>Scikit-learn also permits evaluation of multiple metrics in &lt;code&gt;GridSearchCV&lt;/code&gt;, &lt;code&gt;RandomizedSearchCV&lt;/code&gt; and &lt;code&gt;cross_validate&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5427512908da9e885639e4f06d90d3fbb899fa1a" translate="yes" xml:space="preserve">
          <source>Scikit-learn deals with learning information from one or more datasets that are represented as 2D arrays. They can be understood as a list of multi-dimensional observations. We say that the first axis of these arrays is the &lt;strong&gt;samples&lt;/strong&gt; axis, while the second is the &lt;strong&gt;features&lt;/strong&gt; axis.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68787e98ea90825b478bf4a016c311205a6818e9" translate="yes" xml:space="preserve">
          <source>Scikit-learn does some validation on data that increases the overhead per call to &lt;code&gt;predict&lt;/code&gt; and similar functions. In particular, checking that features are finite (not NaN or infinite) involves a full pass over the data. If you ensure that your data is acceptable, you may suppress checking for finiteness by setting the environment variable &lt;code&gt;SKLEARN_ASSUME_FINITE&lt;/code&gt; to a non-empty string before importing scikit-learn, or configure it in Python with &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt;. For more control than these global settings, a &lt;code&gt;config_context&lt;/code&gt; allows you to set this configuration within a specified context:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="562455165c34b7c83008b571c9bd46eceb879b92" translate="yes" xml:space="preserve">
          <source>Scikit-learn has a collection of classes which can be used to generate lists of train/test indices for popular cross-validation strategies.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b670925eafc995f1763e66f682772271e15a05e5" translate="yes" xml:space="preserve">
          <source>Scikit-learn implements different classes to estimate Gaussian mixture models, that correspond to different estimation strategies, detailed below.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9a530527422759264cd84546f6a0bd4a26252b3" translate="yes" xml:space="preserve">
          <source>Scikit-learn implements efficient kernel density estimation using either a Ball Tree or KD Tree structure, through the &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt;&lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt;&lt;/a&gt; estimator. The available kernels are shown in the second figure of this example.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b29477e8796624fa3eb37a4b942da5b84d872c57" translate="yes" xml:space="preserve">
          <source>Scikit-learn is a Python module integrating classic machine learning algorithms in the tightly-knit world of scientific Python packages (&lt;a href=&quot;http://www.scipy.org&quot;&gt;NumPy&lt;/a&gt;, &lt;a href=&quot;http://www.scipy.org&quot;&gt;SciPy&lt;/a&gt;, &lt;a href=&quot;http://matplotlib.org&quot;&gt;matplotlib&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5244e6b9c3228eb8fcf423888d9d9a31c68e2222" translate="yes" xml:space="preserve">
          <source>Scikit-learn offers a more efficient implementation for the construction of decision trees. A naive implementation (as above) would recompute the class label histograms (for classification) or the means (for regression) at for each new split point along a given feature. Presorting the feature over all relevant samples, and retaining a running label count, will reduce the complexity at each node to \(O(n_{features}\log(n_{samples}))\), which results in a total cost of \(O(n_{features}n_{samples}\log(n_{samples}))\). This is an option for all tree based algorithms. By default it is turned on for gradient boosting, where in general it makes training faster, but turned off for all other algorithms as it tends to slow down training when training deep trees.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4affb29f4cf970be26e1f3befb3e52980b3745a3" translate="yes" xml:space="preserve">
          <source>Scikit-learn provides 3 robust regression estimators: &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;, &lt;a href=&quot;#theil-sen-regression&quot;&gt;Theil Sen&lt;/a&gt; and &lt;a href=&quot;#huber-regression&quot;&gt;HuberRegressor&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="760c9dce2728b87b0e773a2a2023bd5ef6b1ebc6" translate="yes" xml:space="preserve">
          <source>Scikit-learn uses the &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/&quot;&gt;joblib&lt;/a&gt; library to enable parallel computing inside its estimators. See the joblib documentation for the switches to control parallel computing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dbdfa5cbcc37d085da70cbad1d49bb4154a25ae3" translate="yes" xml:space="preserve">
          <source>Scipy provides sparse matrix data structures which are optimized for storing sparse data. The main feature of sparse formats is that you don&amp;rsquo;t store zeros so if your data is sparse then you use much less memory. A non-zero value in a sparse (&lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;CSR or CSC&lt;/a&gt;) representation will only take on average one 32bit integer position + the 64 bit floating point value + an additional 32bit per row or column in the matrix. Using sparse input on a dense (or sparse) linear model can speedup prediction by quite a bit as only the non zero valued features impact the dot product and thus the model predictions. Hence if you have 100 non zeros in 1e6 dimensional space, you only need 100 multiply and add operation instead of 1e6.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73ff9df76cca7434e9bdc94c5c539e98a711a167" translate="yes" xml:space="preserve">
          <source>Scipy sparse matrix formats documentation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec44ac6f635d9837f888fea19337ecd3bc1dc78d" translate="yes" xml:space="preserve">
          <source>Score function (or loss function) with signature &lt;code&gt;score_func(y, y_pred, **kwargs)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4106362aa56af5a012e22c8aae43583defb47511" translate="yes" xml:space="preserve">
          <source>Score of self.predict(X) wrt. y.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="269ca6f46a2303fa294fd49cbab7d3d725c81bb2" translate="yes" xml:space="preserve">
          <source>Score of the prediction.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fee68e2ae75f4d785b563d7d07175bca2df697af" translate="yes" xml:space="preserve">
          <source>Score of the training dataset obtained using an out-of-bag estimate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fdd43514c35f028b5dfc878c7661a274717e7633" translate="yes" xml:space="preserve">
          <source>Score of this parameter setting on given training / test split.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e14703c8615f59873dec25794c9dae3e6fdaa2e4" translate="yes" xml:space="preserve">
          <source>Score, and cross-validated scores</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ac699be69d4f6f03061e9fdf043eeb8d0ba0ed6" translate="yes" xml:space="preserve">
          <source>Scorer function used on the held out data to choose the best parameters for the model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dafe5cdb100f4bad5185f8a89151e9de127407db" translate="yes" xml:space="preserve">
          <source>Scores of all outputs are averaged with uniform weight.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a879b57711ff565bb3c57b9cbdbf3f09144796d5" translate="yes" xml:space="preserve">
          <source>Scores of all outputs are averaged, weighted by the variances of each individual output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bad96478d4d42d160afd8f51da6516a096f00968" translate="yes" xml:space="preserve">
          <source>Scores of features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="004421c31cff3e85919b0da3d9213b70c070211e" translate="yes" xml:space="preserve">
          <source>Scores on test set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9cb2f72d484e4d0e25f5504cf3cb781f6831387a" translate="yes" xml:space="preserve">
          <source>Scores on training sets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a6e081bd4fc687e97f2a3c1767e01a47d8d0d090" translate="yes" xml:space="preserve">
          <source>Scoring</source>
          <target state="translated">Scoring</target>
        </trans-unit>
        <trans-unit id="88173ba266bcaafd44bc526091a11bf84a691634" translate="yes" xml:space="preserve">
          <source>Second example</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4e2db45443f0fd4ae50799405ca1ddce61eefb7" translate="yes" xml:space="preserve">
          <source>Second, when using a connectivity matrix, single, average and complete linkage are unstable and tend to create a few clusters that grow very quickly. Indeed, average and complete linkage fight this percolation behavior by considering all the distances between two clusters when merging them ( while single linkage exaggerates the behaviour by considering only the shortest distance between clusters). The connectivity graph breaks this mechanism for average and complete linkage, making them resemble the more brittle single linkage. This effect is more pronounced for very sparse graphs (try decreasing the number of neighbors in kneighbors_graph) and with complete linkage. In particular, having a very small number of neighbors in the graph, imposes a geometry that is close to that of single linkage, which is well known to have this percolation instability.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53553e63fb4cb7ed1ae88d54b317154b9777e613" translate="yes" xml:space="preserve">
          <source>Seconds used for refitting the best model on the whole dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa04a576bd56d584afacdf30a223dc3f1fde4eb3" translate="yes" xml:space="preserve">
          <source>Section 5.4.4, pp. 252-253.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4628726ca2b8e9b183e1257c782a69297176123" translate="yes" xml:space="preserve">
          <source>Section contents</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="978feab4a35a4b897d5316b48dac562d3091d0c5" translate="yes" xml:space="preserve">
          <source>See &amp;ldquo;Random Features for Large-Scale Kernel Machines&amp;rdquo; by A. Rahimi and Benjamin Recht.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b31673babc80845a872201a18703583634f75350" translate="yes" xml:space="preserve">
          <source>See &amp;ldquo;Random Fourier Approximations for Skewed Multiplicative Histogram Kernels&amp;rdquo; by Fuxin Li, Catalin Ionescu and Cristian Sminchisescu.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0df8f05c9ec568b4cc1c4d54a3085f0ebf794bd9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#rw2006&quot; id=&quot;id6&quot;&gt;[RW2006]&lt;/a&gt;, pp84 for further details regarding the different variants of the Mat&amp;eacute;rn kernel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd13548eb92de90d6303ee640236c96cda68888f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#svm-mathematical-formulation&quot;&gt;Mathematical formulation&lt;/a&gt; for a complete description of the decision function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90eaaa0456af60c46de8c81dc16ee15dad424d81" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/compose/plot_transformed_target#sphx-glr-auto-examples-compose-plot-transformed-target-py&quot;&gt;examples/compose/plot_transformed_target.py&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d70be16f79f29cfb466970ca83989e73f6c00bb" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;examples/linear_model/plot_polynomial_interpolation.py&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66218b0f5237d32e41f01914713a47022cf20bb9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/model_selection/plot_learning_curve#sphx-glr-auto-examples-model-selection-plot-learning-curve-py&quot;&gt;examples/model_selection/plot_learning_curve.py&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41261fbeb952dd5951bf36801866ce019db00dde" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/model_selection/plot_validation_curve#sphx-glr-auto-examples-model-selection-plot-validation-curve-py&quot;&gt;Plotting Validation Curves&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a3b0e6c0d79b7c03e9dbb288652a52d5e7d7fd5" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/linear_model#bayesian-ridge-regression&quot;&gt;Bayesian Ridge Regression&lt;/a&gt; for more information on the regressor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="824c64b490bd5bd779a22eec474ba042707228d1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/linear_model#theil-sen-regression&quot;&gt;Theil-Sen estimator: generalized-median-based estimator&lt;/a&gt; for more information on the regressor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36bf338f19ee54a0199babdefd0eaf5b203f80f4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/mixture#gmm&quot;&gt;Gaussian mixture models&lt;/a&gt; for more information on the estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bda58af52a4d947e4c6e336facf5860c69c8478b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/tree#tree&quot;&gt;decision tree&lt;/a&gt; for more information on the estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1876d72641fc6bba23917c9ce1b023a0c5308e82" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;Species distribution modeling&lt;/a&gt; for an example of using ROC to model species distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ca47154d5f58b185be5af00ff9392b2598d6abf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/calibration/plot_calibration#sphx-glr-auto-examples-calibration-plot-calibration-py&quot;&gt;Probability calibration of classifiers&lt;/a&gt; for an example of Brier score loss usage to perform probability calibration of classifiers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="282928c19fbfe87fe4167148ff3b6058bc018479" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;Recognizing hand-written digits&lt;/a&gt; for an example of classification report usage for hand-written digits.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72d62eaa2236b9a2dd2c8a6bb04573291c57c36e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;Recognizing hand-written digits&lt;/a&gt; for an example of using a confusion matrix to classify hand-written digits.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87880060115f16d38cb34f093520114ae1691683" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit a &lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt;&lt;code&gt;LedoitWolf&lt;/code&gt;&lt;/a&gt; object to data and for visualizing the performances of the Ledoit-Wolf estimator in terms of likelihood.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2209166f8c957bd217f6d5f461ba4322d29b02c2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit a &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance&quot;&gt;&lt;code&gt;ShrunkCovariance&lt;/code&gt;&lt;/a&gt; object to data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88a19b944edc191f5f7b057963b65a4e9112c1b2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit an &lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;EmpiricalCovariance&lt;/code&gt;&lt;/a&gt; object to data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a3f5dc7dd1289a56afbdf19c9d4415f754d0c74" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit an &lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt;&lt;code&gt;OAS&lt;/code&gt;&lt;/a&gt; object to data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2ce4b68a58fc4d4775fc307d3337bfc6ba95951" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_lw_vs_oas#sphx-glr-auto-examples-covariance-plot-lw-vs-oas-py&quot;&gt;Ledoit-Wolf vs OAS estimation&lt;/a&gt; to visualize the Mean Squared Error difference between a &lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt;&lt;code&gt;LedoitWolf&lt;/code&gt;&lt;/a&gt; and an &lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt;&lt;code&gt;OAS&lt;/code&gt;&lt;/a&gt; estimator of the covariance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8878b5f91edc950d3f968af54f37c8ec353c6370" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;Robust covariance estimation and Mahalanobis distances relevance&lt;/a&gt; for an illustration of the difference between using a standard (&lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;covariance.EmpiricalCovariance&lt;/code&gt;&lt;/a&gt;) or a robust estimate (&lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt;&lt;code&gt;covariance.MinCovDet&lt;/code&gt;&lt;/a&gt;) of location and covariance to assess the degree of outlyingness of an observation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="030742fc8b624a6be4238fb99cd9f5a0e364d687" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;Robust covariance estimation and Mahalanobis distances relevance&lt;/a&gt; to visualize the difference between &lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;EmpiricalCovariance&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt;&lt;code&gt;MinCovDet&lt;/code&gt;&lt;/a&gt; covariance estimators in terms of Mahalanobis distance (so we get a better estimate of the precision matrix too).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9a056a85b47a4a6c1a6d704788263d39761f07a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_robust_vs_empirical_covariance#sphx-glr-auto-examples-covariance-plot-robust-vs-empirical-covariance-py&quot;&gt;Robust vs Empirical covariance estimate&lt;/a&gt; for an example on how to fit a &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt;&lt;code&gt;MinCovDet&lt;/code&gt;&lt;/a&gt; object to data and see how the estimate remains accurate despite the presence of outliers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="995b452653e2a34828a53fff1225e032a84a1ed7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/ensemble/plot_gradient_boosting_regression#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py&quot;&gt;Gradient Boosting regression&lt;/a&gt; for an example of mean squared error usage to evaluate gradient boosting regression.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c70bb54b9f9c6d372a94de7482636d40519b333f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/ensemble/plot_isolation_forest#sphx-glr-auto-examples-ensemble-plot-isolation-forest-py&quot;&gt;IsolationForest example&lt;/a&gt; for an illustration of the use of IsolationForest.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="462e8cdc93001fb7a3648b1195482e1f8b22fe44" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/feature_selection/plot_permutation_test_for_classification#sphx-glr-auto-examples-feature-selection-plot-permutation-test-for-classification-py&quot;&gt;Test with permutations the significance of a classification score&lt;/a&gt; for an example of accuracy score usage using permutations of the dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39b73a8956b97e37d2a1a56a5487c771ec6755e2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/feature_selection/plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;Recursive feature elimination with cross-validation&lt;/a&gt; for an example of zero one loss usage to perform recursive feature elimination with cross-validation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92f30204fbfed37d4520688e6847c0f1dec6d444" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/linear_model/plot_lasso_and_elasticnet#sphx-glr-auto-examples-linear-model-plot-lasso-and-elasticnet-py&quot;&gt;Lasso and Elastic Net for Sparse Signals&lt;/a&gt; for an example of R&amp;sup2; score usage to evaluate Lasso and Elastic Net on sparse signals.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01a78f9ef24e4fc8896bfa27a1c142f94096fbf4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;Polynomial interpolation&lt;/a&gt; for Ridge regression using created polynomial features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cc1903f7fccc8472139b491e9c35281e331be73" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/manifold/plot_compare_methods#sphx-glr-auto-examples-manifold-plot-compare-methods-py&quot;&gt;Comparison of Manifold Learning methods&lt;/a&gt; for an example of dimensionality reduction on a toy &amp;ldquo;S-curve&amp;rdquo; dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c13f7bab27de634fe8533a5ffc3f4d5d442fb940" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/manifold/plot_lle_digits#sphx-glr-auto-examples-manifold-plot-lle-digits-py&quot;&gt;Manifold learning on handwritten digits: Locally Linear Embedding, Isomap&amp;hellip;&lt;/a&gt; for an example of dimensionality reduction on handwritten digits.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba387b296d0109ccfdd27d435e72e0bda0b98a94" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_concentration_prior#sphx-glr-auto-examples-mixture-plot-concentration-prior-py&quot;&gt;Concentration Prior Type Analysis of Variation Bayesian Gaussian Mixture&lt;/a&gt; for an example plotting the confidence ellipsoids for the &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt; with different &lt;code&gt;weight_concentration_prior_type&lt;/code&gt; for different values of the parameter &lt;code&gt;weight_concentration_prior&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17317cd9be65f918f2c9598fbac39ad346f5db56" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm#sphx-glr-auto-examples-mixture-plot-gmm-py&quot;&gt;Gaussian Mixture Model Ellipsoids&lt;/a&gt; for an example on plotting the confidence ellipsoids for both &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt;&lt;code&gt;GaussianMixture&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5877cbb374e3dc33496a562d7ff812fdb5db635" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm_covariances#sphx-glr-auto-examples-mixture-plot-gmm-covariances-py&quot;&gt;GMM covariances&lt;/a&gt; for an example of using the Gaussian mixture as clustering on the iris dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="235746c777e5faff74a54e9f92e2aa47946dcca8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm_pdf#sphx-glr-auto-examples-mixture-plot-gmm-pdf-py&quot;&gt;Density Estimation for a Gaussian mixture&lt;/a&gt; for an example on plotting the density estimation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f45342ed85fb843511e05db7aa53da9e05cd4c8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm_selection#sphx-glr-auto-examples-mixture-plot-gmm-selection-py&quot;&gt;Gaussian Mixture Model Selection&lt;/a&gt; for an example of model selection performed with classical Gaussian mixture.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2675c64adf13cc79a9b07f8da3e0d3af0522fc69" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;Sample pipeline for text feature extraction and evaluation&lt;/a&gt; for an example of Grid Search coupling parameters from a text documents feature extractor (n-gram count vectorizer and TF-IDF transformer) with a classifier (here a linear SVM trained with SGD with either elastic net or L2 penalty) using a &lt;code&gt;pipeline.Pipeline&lt;/code&gt; instance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da92f3b35d742326e0c71721384ca2aaccbfcbb6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_confusion_matrix#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py&quot;&gt;Confusion matrix&lt;/a&gt; for an example of using a confusion matrix to evaluate classifier output quality.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de7b9e4f40b1dbfe2688a95ace15280b606fa175" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Parameter estimation using grid search with cross-validation&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.metrics.precision_score#sklearn.metrics.precision_score&quot;&gt;&lt;code&gt;precision_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.recall_score#sklearn.metrics.recall_score&quot;&gt;&lt;code&gt;recall_score&lt;/code&gt;&lt;/a&gt; usage to estimate parameters using grid search with nested cross-validation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="907fb39fc7f1b14d7a7b9cc2b05542f6688793e4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Parameter estimation using grid search with cross-validation&lt;/a&gt; for an example of Grid Search computation on the digits dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="400cd83fcd5e25dceebfea56b549d5be061f5ba4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Parameter estimation using grid search with cross-validation&lt;/a&gt; for an example of classification report usage for grid search with nested cross-validation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2735aad85c6c7c554984533b716de0827c908e17" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; being used to evaluate multiple metrics simultaneously.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2ffbe0f12938b51592ad9e927a7d22caaeca8af" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV&lt;/a&gt; for an example usage.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8476e4237a00d9dd8e2ca35734caeb2c23a0697e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_nested_cross_validation_iris#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py&quot;&gt;Nested versus non-nested cross-validation&lt;/a&gt; for an example of Grid Search within a cross validation loop on the iris dataset. This is the best practice for evaluating the performance of a model with grid search.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8dfb2ba828b857661aeb6d59ff74f5c4db05d22" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_precision_recall#sphx-glr-auto-examples-model-selection-plot-precision-recall-py&quot;&gt;Precision-Recall&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt;&lt;code&gt;precision_recall_curve&lt;/code&gt;&lt;/a&gt; usage to evaluate classifier output quality.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7914d54070b906eba7716c438acf436730af131e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_roc#sphx-glr-auto-examples-model-selection-plot-roc-py&quot;&gt;Receiver Operating Characteristic (ROC)&lt;/a&gt; for an example of using ROC to evaluate the quality of the output of a classifier.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61240d29f349f145d4e8cf44909bfb9cc2f016b2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_roc_crossval#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py&quot;&gt;Receiver Operating Characteristic (ROC) with cross validation&lt;/a&gt; for an example of using ROC to evaluate classifier output quality, using cross-validation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2194fe880eec73b4ed37b8700c0f77c050a462fc" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/neighbors/plot_lof_outlier_detection#sphx-glr-auto-examples-neighbors-plot-lof-outlier-detection-py&quot;&gt;Outlier detection with Local Outlier Factor (LOF)&lt;/a&gt; for an illustration of the use of &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb13fcb17f205551a70f65831a46478e0af0f276" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison of &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt; with &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt; (tuned to perform like an outlier detection method) and a covariance-based outlier detection with &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt;&lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64196936345ba93c97149a5b0ef386464e9766b9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison of the &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt;, the &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt;, the &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt;&lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34db9fa5546a4563c9e371d735571ffbe05f0c7c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison with other anomaly detection methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="624945e6b02bb2ff2c43f28f85ed4813c5cbe96d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_johnson_lindenstrauss_bound#sphx-glr-auto-examples-plot-johnson-lindenstrauss-bound-py&quot;&gt;The Johnson-Lindenstrauss bound for embedding with random projections&lt;/a&gt; for a theoretical explication on the Johnson-Lindenstrauss lemma and an empirical validation using sparse random matrices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ca7b8e34286a27914e5e700a286fbed9102f4af" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/svm/plot_oneclass#sphx-glr-auto-examples-svm-plot-oneclass-py&quot;&gt;One-class SVM with non-linear kernel (RBF)&lt;/a&gt; for visualizing the frontier learned around some data by a &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76c663b6a0471e4c53ba854f9c09becf8ef59fc7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Classification of text documents using sparse features&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt;&lt;code&gt;f1_score&lt;/code&gt;&lt;/a&gt; usage to classify text documents.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="188cc26ffe635b802535768a1802c77d30908617" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Classification of text documents using sparse features&lt;/a&gt; for an example of classification report usage for text documents.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="19118774a723324b6225f3d83bcf9761f94d3619" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Classification of text documents using sparse features&lt;/a&gt; for an example of using a confusion matrix to classify text documents.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="81a2b2d1fb5035ca6b501c666e8a41c6286b60de" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../grid_search#multimetric-grid-search&quot;&gt;Specifying multiple metrics for evaluation&lt;/a&gt; for an example.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="479250f0ad90f3ce8d5fd16594b9c17af606dc2c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../neighbors#neighbors&quot;&gt;Nearest Neighbors&lt;/a&gt; in the online documentation for a discussion of the choice of &lt;code&gt;algorithm&lt;/code&gt; and &lt;code&gt;leaf_size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91032a83e07b0024745974d4bc72e492c7c9e85a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;compose#combining-estimators&quot;&gt;Pipelines and composite estimators&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="516b0abd274bf0e8eb7951cfd8d017257e70560d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;feature_extraction#dict-feature-extraction&quot;&gt;Loading features from dicts&lt;/a&gt; for categorical features that are represented as a dict, not as scalars.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f5bdda151c122a6b0f331c022a3fe3419eba6e8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits&quot;&gt;here&lt;/a&gt; for more information about this dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="59cc7550d6ebef4a36dc7cbd048f831a5c0d0f3a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&quot;&gt;http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58869cd4ecac8051c9d79dfaa9dbb2a543b85dfe" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;http://www.robots.ox.ac.uk/~vedaldi/assets/pubs/vedaldi11efficient.pdf&quot;&gt;&amp;ldquo;Efficient additive kernels via explicit feature maps&amp;rdquo;&lt;/a&gt; A. Vedaldi and A. Zisserman, Pattern Analysis and Machine Intelligence, 2011</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4bdca7573215dd8d9f679d272cb9da9a534f1291" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;here&lt;/a&gt; for more information on this dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7191cbc48e1c8b07d612d6ecdb398fe05677ce16" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;The scoring parameter: defining model evaluation rules&lt;/a&gt; for details. In the case of the Iris dataset, the samples are balanced across target classes hence the accuracy and the F1-score are almost equal.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e083d29e5fc318a8e4c7186d224d71159333e317" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;outlier_detection#outlier-detection&quot;&gt;Novelty and Outlier Detection&lt;/a&gt; for the description and usage of OneClassSVM.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2bf27f073ae6fdc435309a3de7aa195bb3e33f73" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;predict_proba&lt;/code&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a6c19ee072204bfa0caf7b0899caf92ad1a79e0" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;refit&lt;/code&gt; parameter for more information on allowed values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcd84460747232330056c00c1a39fd6ed47410b5" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;scoring&lt;/code&gt; parameter to know more about multiple metric evaluation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61a08f389a25b863d0fca5015a2885ff6fd5c8cd" translate="yes" xml:space="preserve">
          <source>See Also:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd75486b56d3a12e77b37b7ce59de88eb8618b01" translate="yes" xml:space="preserve">
          <source>See Rasmussen and Williams 2006, pp84 for details regarding the different variants of the Matern kernel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d8243a2c0e464492c9d563c4f92c56ae3421bcc" translate="yes" xml:space="preserve">
          <source>See also</source>
          <target state="translated">또한보십시오</target>
        </trans-unit>
        <trans-unit id="00556fb4b47eda5d6ddfa3723da8312c58733ada" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;Recursive feature elimination with cross-validation&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="371a87eafb4de078ff674d69a5a89c186532eb49" translate="yes" xml:space="preserve">
          <source>See also:</source>
          <target state="translated">또한보십시오:</target>
        </trans-unit>
        <trans-unit id="bbbf1c8bb1bb44153dbb121ba5ff682161041559" translate="yes" xml:space="preserve">
          <source>See also: 1988 MLC Proceedings, 54-64. Cheeseman et al&amp;rdquo;s AUTOCLASS II conceptual clustering system finds 3 classes in the data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b55a2c7dcbc914b3c4abb672c6103792d08facf" translate="yes" xml:space="preserve">
          <source>See sklearn.svm.predict for a complete list of parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c30624bfa9869c6a4a63a1b052f17576abbc1b5" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;../../auto_examples/applications/svm_gui#sphx-glr-auto-examples-applications-svm-gui-py&quot;&gt;SVM GUI&lt;/a&gt; to download &lt;code&gt;svm_gui.py&lt;/code&gt;; add data points of both classes with right and left button, fit the model and change parameters and data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a7904b44fb635dd1b8e25248a204eaa4fae3a1b" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;biclustering#biclustering-evaluation&quot;&gt;Biclustering evaluation&lt;/a&gt; section of the user guide for further details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68bd165827c5ef6d955b9032ff7e059af8a91538" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;clustering#clustering-evaluation&quot;&gt;Clustering performance evaluation&lt;/a&gt; section of the user guide for further details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8dd9c0a0a464abab54cd5ae3d828ecf303587e8d" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt; section of the user guide for further details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5b49cc34cb79ec02e159e95ecb887eb0b2cb87b" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#classification-metrics&quot;&gt;Classification metrics&lt;/a&gt; section of the user guide for further details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9391e01adcbcd6eab5489ba5c5bbde2b34c1c767" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;Model evaluation: quantifying the quality of predictions&lt;/a&gt; section and the &lt;a href=&quot;metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt; section of the user guide for further details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="794b0f5d5def59a318bd787a4fccdd542a21003c" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#multilabel-ranking-metrics&quot;&gt;Multilabel ranking metrics&lt;/a&gt; section of the user guide for further details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e87795fde7a0f4562bca5bb85f3c7f5918727b2" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#regression-metrics&quot;&gt;Regression metrics&lt;/a&gt; section of the user guide for further details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8449bc2e3e9fd1500a092c7a467f1094a642fdf" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;The scoring parameter: defining model evaluation rules&lt;/a&gt; section of the user guide for further details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc10a00d51f81094bb499f5ba451c68f15309214" translate="yes" xml:space="preserve">
          <source>See the console&amp;rsquo;s output for further details about each model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd81e4d9092f6289f9eb153c5b671f6c9ec59b00" translate="yes" xml:space="preserve">
          <source>See the docstring of DistanceMetric for a list of available metrics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf132d2b0dc3be6b88274385f87b0ee3f849742c" translate="yes" xml:space="preserve">
          <source>See the documentation for scipy.spatial.distance for details on these metrics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7af63b893a630b06c001dfe05c36e8144bafc593" translate="yes" xml:space="preserve">
          <source>See the documentation for scipy.spatial.distance for details on these metrics: &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/spatial.distance.html&quot;&gt;http://docs.scipy.org/doc/scipy/reference/spatial.distance.html&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c235949c8aa0b531ecb9dfa56db515940237097e" translate="yes" xml:space="preserve">
          <source>See the examples below and the doc string of &lt;a href=&quot;generated/sklearn.neural_network.mlpclassifier#sklearn.neural_network.MLPClassifier.fit&quot;&gt;&lt;code&gt;MLPClassifier.fit&lt;/code&gt;&lt;/a&gt; for further information.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f593defdf84cd9d54340a0b9eb8bdbba2164c5f" translate="yes" xml:space="preserve">
          <source>See the examples below for further information.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43e09506578d0fedfc6592860be1e23c1f8ef43b" translate="yes" xml:space="preserve">
          <source>See the examples for such an application.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8c17521507d95b1954b9918e527f968af48b835" translate="yes" xml:space="preserve">
          <source>See. &amp;ldquo;Pattern Recognition and Machine Learning&amp;rdquo; by C. Bishop, 12.2.1 p. 574 or &lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4871111c8505b7690af20e518e753ae1b90a5ad" translate="yes" xml:space="preserve">
          <source>Seed for the random number generator used for probability estimates. 0 by default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72c84d205a7667dfdb05c6ebaaf98f08a838df92" translate="yes" xml:space="preserve">
          <source>Seeding is performed using a binning technique for scalability.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1f3844996349c701e3db8be5a62a8ace310a543" translate="yes" xml:space="preserve">
          <source>Seeds used to initialize kernels. If not set, the seeds are calculated by clustering.get_bin_seeds with bandwidth as the grid size and default values for other parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a053c7e782c53a91d6d509bf6a99224f4b893d2" translate="yes" xml:space="preserve">
          <source>Segmenting the picture of greek coins in regions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05c2c519388dfeab1d2da32ad0c3a55d08148aed" translate="yes" xml:space="preserve">
          <source>Select &lt;code&gt;min_samples&lt;/code&gt; random samples from the original data and check whether the set of data is valid (see &lt;code&gt;is_data_valid&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c8220c40092a5223a7519a4053e419620df4d58" translate="yes" xml:space="preserve">
          <source>Select eigensolver to use. If n_components is much less than the number of training samples, arpack may be more efficient than the dense eigensolver.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8b26e8dd8c57424e2a0ff5f2b02e8bbc7be69eb" translate="yes" xml:space="preserve">
          <source>Select features according to a percentile of the highest scores.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d20a85a468318484f73da066702f203468ec7eb5" translate="yes" xml:space="preserve">
          <source>Select features according to the k highest scores.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3952e3b9f6e5571ab9a9f69665172397cc254d2" translate="yes" xml:space="preserve">
          <source>Select features based on a false positive rate test.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32515d7cef117ccce44afc2f4f0b98f43d0db807" translate="yes" xml:space="preserve">
          <source>Select features based on an estimated false discovery rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d7a0df88fc316c1f019dac960b65ab544487a37" translate="yes" xml:space="preserve">
          <source>Select features based on family-wise error rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba417981f6009fc06cd3596ff9c6cb4c2bd25319" translate="yes" xml:space="preserve">
          <source>Select features based on percentile of the highest scores.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3532493330a0445601f2381a89fe492b8458f964" translate="yes" xml:space="preserve">
          <source>Select features based on the k highest scores.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc6cce4211d0c67d4111ac2f86243aa83948ed07" translate="yes" xml:space="preserve">
          <source>Select n_samples integers from the set [0, n_population) without replacement.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e693da3619bc133d154aaf34e091d4f9f76e8468" translate="yes" xml:space="preserve">
          <source>Select the algorithm to either solve the dual or primal optimization problem. Prefer dual=False when n_samples &amp;gt; n_features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e09f39accd13c28376a1ebc78d546869197bec0f" translate="yes" xml:space="preserve">
          <source>Select the dataset to load: &amp;lsquo;train&amp;rsquo; for the development training set, &amp;lsquo;test&amp;rsquo; for the development test set, and &amp;lsquo;10_folds&amp;rsquo; for the official evaluation set that is meant to be used with a 10-folds cross validation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da5a2fc4086f03333558c16d8aba6a6ba8f98164" translate="yes" xml:space="preserve">
          <source>Select the dataset to load: &amp;lsquo;train&amp;rsquo; for the training set (23149 samples), &amp;lsquo;test&amp;rsquo; for the test set (781265 samples), &amp;lsquo;all&amp;rsquo; for both, with the training samples first if shuffle is False. This follows the official LYRL2004 chronological split.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a373737a4d85a4134f237dcaa76f506d35776152" translate="yes" xml:space="preserve">
          <source>Select the dataset to load: &amp;lsquo;train&amp;rsquo; for the training set, &amp;lsquo;test&amp;rsquo; for the test set, &amp;lsquo;all&amp;rsquo; for both, with shuffled ordering.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c5f861c6085a651c0ed9619f5012b02bb9a2d195" translate="yes" xml:space="preserve">
          <source>Select the parameters that minimises the impurity</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="776d7f86c8363c5c583ee4e086a4256b8464f6f6" translate="yes" xml:space="preserve">
          <source>Select the portion to load: &amp;lsquo;train&amp;rsquo;, &amp;lsquo;test&amp;rsquo; or &amp;lsquo;raw&amp;rsquo;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09caeaab6645f9fa60776419a39bd350760c6b9f" translate="yes" xml:space="preserve">
          <source>Selecting &lt;code&gt;average=None&lt;/code&gt; will return an array with the score for each class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09987abb5cb6e00639cc8ad149fcfc0ee4e216e7" translate="yes" xml:space="preserve">
          <source>Selecting dimensionality reduction with Pipeline and GridSearchCV</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b619a7e9444390b8df9ed15ee53211d47286dc3c" translate="yes" xml:space="preserve">
          <source>Selecting the number of clusters with silhouette analysis on KMeans clustering</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e3a867140ee60f287b6c8b807e610aee224839f" translate="yes" xml:space="preserve">
          <source>Selects the algorithm for finding singular vectors. May be &amp;lsquo;randomized&amp;rsquo; or &amp;lsquo;arpack&amp;rsquo;. If &amp;lsquo;randomized&amp;rsquo;, use &lt;a href=&quot;sklearn.utils.extmath.randomized_svd#sklearn.utils.extmath.randomized_svd&quot;&gt;&lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt;&lt;/a&gt;, which may be faster for large matrices. If &amp;lsquo;arpack&amp;rsquo;, use &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html#scipy.sparse.linalg.svds&quot;&gt;&lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt;&lt;/a&gt;, which is more accurate, but possibly slower in some cases.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba0796ade5894bc55073846864af8524b40634d7" translate="yes" xml:space="preserve">
          <source>Selects the algorithm for finding singular vectors. May be &amp;lsquo;randomized&amp;rsquo; or &amp;lsquo;arpack&amp;rsquo;. If &amp;lsquo;randomized&amp;rsquo;, uses &lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt;, which may be faster for large matrices. If &amp;lsquo;arpack&amp;rsquo;, uses &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt;, which is more accurate, but possibly slower in some cases.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c634aac4fba33953abfb672747b23d137a6eb94" translate="yes" xml:space="preserve">
          <source>Sepal length</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb329e5a4491aa43414f15d76bffc8963ea0de09" translate="yes" xml:space="preserve">
          <source>Sepal width</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5dddf892a3efc8978d095e912cc4306a1e49804" translate="yes" xml:space="preserve">
          <source>Separating inliers from outliers using a Mahalanobis distance</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aece656a00e1c7a3f193615a59fc1f63e6e58693" translate="yes" xml:space="preserve">
          <source>Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, &amp;ldquo;Decision Tree Construction Via Linear Programming.&amp;rdquo; Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="749810666e6448d7103b8c1ba2bbfef3e451d983" translate="yes" xml:space="preserve">
          <source>Separator string used when constructing new features for one-hot coding.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70aafd2a89678b32332fcfe0ff93efd39c5a3c06" translate="yes" xml:space="preserve">
          <source>Sequence of integer labels or multilabel data to encode.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63145e1c892f5c29b2a500cdc3f15222c0784b14" translate="yes" xml:space="preserve">
          <source>Sequence of resampled copies of the collections. The original arrays are not impacted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="22f488ee4fca141470b8e2b188abe2e7275b3dc0" translate="yes" xml:space="preserve">
          <source>Sequence of shuffled copies of the collections. The original arrays are not impacted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05f31ec9564cc0e3d1b047a8eba0a9e234d2f0b3" translate="yes" xml:space="preserve">
          <source>Sequence of weights (&lt;code&gt;float&lt;/code&gt; or &lt;code&gt;int&lt;/code&gt;) to weight the occurrences of predicted class labels (&lt;code&gt;hard&lt;/code&gt; voting) or class probabilities before averaging (&lt;code&gt;soft&lt;/code&gt; voting). Uses uniform weights if &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ea6d0fbbfa7ff1125b3f0dc0d1f0f204d3b725f" translate="yes" xml:space="preserve">
          <source>Sequentially apply a list of transforms and a final estimator. Intermediate steps of the pipeline must be &amp;lsquo;transforms&amp;rsquo;, that is, they must implement fit and transform methods. The final estimator only needs to implement fit. The transformers in the pipeline can be cached using &lt;code&gt;memory&lt;/code&gt; argument.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d912fff074ca31c7c82b5fde02f4d9656aba0e0" translate="yes" xml:space="preserve">
          <source>Set &lt;code&gt;kernel='precomputed'&lt;/code&gt; and pass the Gram matrix instead of X in the fit method. At the moment, the kernel values between &lt;em&gt;all&lt;/em&gt; training vectors and the test vectors must be provided.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82c89924e3ff5aee8a7d762157ebec36e4bfb77e" translate="yes" xml:space="preserve">
          <source>Set &lt;code&gt;n_clusters&lt;/code&gt; to a required value using &lt;code&gt;brc.set_params(n_clusters=n_clusters)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="baf739c6d3f3081a673c9a62345f43337d9146af" translate="yes" xml:space="preserve">
          <source>Set an initial start configuration, randomly or not.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7115214e952526d911c94e2c07be9533a4c1bc42" translate="yes" xml:space="preserve">
          <source>Set global scikit-learn configuration</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d973ce66011b9fa67c29ae92b31d59e39ce28a97" translate="yes" xml:space="preserve">
          <source>Set of samples, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="859e800d4c0c95faf85e59d644290b4f9223483a" translate="yes" xml:space="preserve">
          <source>Set the parameter C of class i to &lt;code&gt;class_weight[i]*C&lt;/code&gt; for SVC. If not given, all classes are supposed to have weight one. The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68197d507e5463b3337bc09b3b9761d9525e528a" translate="yes" xml:space="preserve">
          <source>Set the parameter C of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ee0e3c771d52a3f4b21637b50de4b2fa144cadb" translate="yes" xml:space="preserve">
          <source>Set the parameter C of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02c4dadc552ae2f0292cf77b2c6f20b9175838e2" translate="yes" xml:space="preserve">
          <source>Set the parameters</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72f87d2d27b1f0c322a530ad0dc9b59597d7be5b" translate="yes" xml:space="preserve">
          <source>Set the parameters of this estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57d60e82b45349e99163b5cb25f5c26dc09997fb" translate="yes" xml:space="preserve">
          <source>Set the parameters of this kernel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e51dac5748f92b9a4d95a295db13667c4d900b8f" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace computation during transformation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9e442dcb8465293c9e9b1ca26f1df573cbc8a5b" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace computation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66ebe619c3b8004252e57f6a28ff4945f1da8024" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace row normalization and avoid a copy (if the input is already a numpy array).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00972eb158db00f5dae23773f938b4091d65b472" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace scaling and avoid a copy (if the input is already a numpy array).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08f65c010729649e9d6102eb99a0ed3b76fe0859" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace transformation and avoid a copy (if the input is already a numpy array).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70773d7b4f76452047259ed8e2e9af7169f13fc0" translate="yes" xml:space="preserve">
          <source>Set to True to apply zero-mean, unit-variance normalization to the transformed output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7d505eb35ec97e19208554a83f21f5336e3915d" translate="yes" xml:space="preserve">
          <source>Set to true if output binary array is desired in CSR sparse format</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9779b7ab3cf4b478b4bfa7669bfc4f6492ae2ea" translate="yes" xml:space="preserve">
          <source>Sets the default value for the &lt;code&gt;assume_finite&lt;/code&gt; argument of &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2047224d21bf76be06bd841e22b2f6efe81f5987" translate="yes" xml:space="preserve">
          <source>Sets the default value for the &lt;code&gt;working_memory&lt;/code&gt; argument of &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8fc661c1feefb08f484398590a9cfaa0d200700d" translate="yes" xml:space="preserve">
          <source>Sets the seed of the global random generator when running the tests, for reproducibility.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ceca261ca4bfaf0dac2e7a5f6879bae3049e05bd" translate="yes" xml:space="preserve">
          <source>Sets the verbosity amount</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41f97bb142955ba403db62394a8510aa45205b7b" translate="yes" xml:space="preserve">
          <source>Setting it to True gets the various classifiers and the parameters of the classifiers as well</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2623b7b1ad6f2c3b5492832d70831c56aba6aac8" translate="yes" xml:space="preserve">
          <source>Setting the parameter by cross-validating the likelihood on three folds according to a grid of potential shrinkage parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="edca67601d1a75cccde1deb24fddb7bb63088fcb" translate="yes" xml:space="preserve">
          <source>Setting the parameters for the voting classifier</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb6261b9db86d6920a006098fc7538ed80a40df3" translate="yes" xml:space="preserve">
          <source>Several estimators in the scikit-learn can use connectivity information between features or samples. For instance Ward clustering (&lt;a href=&quot;clustering#hierarchical-clustering&quot;&gt;Hierarchical clustering&lt;/a&gt;) can cluster together only neighboring pixels of an image, thus forming contiguous patches:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2ad224369c25dffec31e32504aa18be16f8d837" translate="yes" xml:space="preserve">
          <source>Several functions allow you to analyze the precision, recall and F-measures score:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="beccb29e29ebc99080f8c36d4203650a9f29b872" translate="yes" xml:space="preserve">
          <source>Several methods have been developed to compare two sets of biclusters. For now, only &lt;a href=&quot;generated/sklearn.metrics.consensus_score#sklearn.metrics.consensus_score&quot;&gt;&lt;code&gt;consensus_score&lt;/code&gt;&lt;/a&gt; (Hochreiter et. al., 2010) is available:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf696ed0c48f638295bdb050d71aac6a4287ef6f" translate="yes" xml:space="preserve">
          <source>Several regression and binary classification algorithms are available in scikit-learn. A simple way to extend these algorithms to the multi-class classification case is to use the so-called one-vs-all scheme.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e301dd6062f7e9a79975fe8e2d0ba91694c4dbc3" translate="yes" xml:space="preserve">
          <source>Sex</source>
          <target state="translated">Sex</target>
        </trans-unit>
        <trans-unit id="94351e57e5ad4d9a685a9e5e4a3a8ed2b422ed01" translate="yes" xml:space="preserve">
          <source>Shape of the data arrays</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ce851a20ced87e3a45210428f1caa987910f68a" translate="yes" xml:space="preserve">
          <source>Shape of the i&amp;rsquo;th bicluster.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e14b35d505512b3adb2f8997ae35ca2be24040d8" translate="yes" xml:space="preserve">
          <source>Shape will be [n_samples, 1] for binary problems.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4aa10e40109dde70a9d57a4c3969b16b2895540" translate="yes" xml:space="preserve">
          <source>Shift features by the specified value. If None, then features are shifted by a random value drawn in [-class_sep, class_sep].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89ec1dbbc8f85faf0ad282b8a6481e07a4785260" translate="yes" xml:space="preserve">
          <source>Shifted opposite of the Local Outlier Factor of X.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5433cd73ac014316d0b32695693eab5029601309" translate="yes" xml:space="preserve">
          <source>Shorthand</source>
          <target state="translated">Shorthand</target>
        </trans-unit>
        <trans-unit id="a8178c51c2cc3204c708328447fd16ef389ce9b6" translate="yes" xml:space="preserve">
          <source>Should be used when memory is inefficient to train all data. Chunks of data can be passed in several iteration, where the first call should have an array of all target variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12700416ee0fef7fdd5157d1c27acbb9da13d5c9" translate="yes" xml:space="preserve">
          <source>Should be used when memory is inefficient to train all data. Chunks of data can be passed in several iteration.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec934ba88e117c3577f933302800f3ab4b85705a" translate="yes" xml:space="preserve">
          <source>Show below is a logistic-regression classifiers decision boundaries on the first two dimensions (sepal length and width) of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;iris&lt;/a&gt; dataset. The datapoints are colored according to their labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c74e263b32d3703a876a54ba7cc367e3fb1c6bbb" translate="yes" xml:space="preserve">
          <source>Shown in the plot is how the logistic regression would, in this synthetic dataset, classify values as either 0 or 1, i.e. class one or two, using the logistic curve.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca5bc8cbcc9592e82a2ca132c00133d4ad37408e" translate="yes" xml:space="preserve">
          <source>Shows how shrinkage improves classification.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5dc7ad8809a977f328219d536276f520094e2981" translate="yes" xml:space="preserve">
          <source>Shows how to use a function transformer in a pipeline. If you know your dataset&amp;rsquo;s first principle component is irrelevant for a classification task, you can use the FunctionTransformer to select all but the first column of the PCA transformed data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f535d0d4250bfadc5c1c6932476e7cb22e7db70e" translate="yes" xml:space="preserve">
          <source>Shows the effect of collinearity in the coefficients of an estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a78e7f7618436a20d69e64d9d5ffb3bc060c908" translate="yes" xml:space="preserve">
          <source>Shrinkage</source>
          <target state="translated">Shrinkage</target>
        </trans-unit>
        <trans-unit id="29ad8c0361eee52379ab28eb86f7303c232b073b" translate="yes" xml:space="preserve">
          <source>Shrinkage and sparsity with logistic regression</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92e7e7782831a32d85f1f4adb6e6848b9931e9f2" translate="yes" xml:space="preserve">
          <source>Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc56f7d6f334df6e1bf7e25fb6694a2b96d3283e" translate="yes" xml:space="preserve">
          <source>Shrinkage is a tool to improve estimation of covariance matrices in situations where the number of training samples is small compared to the number of features. In this scenario, the empirical sample covariance is a poor estimator. Shrinkage LDA can be used by setting the &lt;code&gt;shrinkage&lt;/code&gt; parameter of the &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt; class to &amp;lsquo;auto&amp;rsquo;. This automatically determines the optimal shrinkage parameter in an analytic way following the lemma introduced by Ledoit and Wolf &lt;a href=&quot;#id5&quot; id=&quot;id3&quot;&gt;[4]&lt;/a&gt;. Note that currently shrinkage only works when setting the &lt;code&gt;solver&lt;/code&gt; parameter to &amp;lsquo;lsqr&amp;rsquo; or &amp;lsquo;eigen&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e8136e1a5918ee41b1666fa514179c5cb22402c" translate="yes" xml:space="preserve">
          <source>Shrinkage parameter, possible values:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2a27e6ba825492dec9776790877b64e516e75e0" translate="yes" xml:space="preserve">
          <source>Shrunk covariance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4dcdf0ff13bd4f7b65e07eadf0216796b5d56197" translate="yes" xml:space="preserve">
          <source>Shuffle arrays or sparse matrices in a consistent way</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0ccd0261920fa2fccaab512e3420b322d650304" translate="yes" xml:space="preserve">
          <source>Shuffle the samples and the features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="372aba820bed6f2900292d1b119c1b7c02346b33" translate="yes" xml:space="preserve">
          <source>Shuffle the samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb741d2d7cb4e292767bcf7b4c4d2a7dcedf441d" translate="yes" xml:space="preserve">
          <source>Shuffle-Group(s)-Out cross-validation iterator</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04a76dd0a6286b28de9940305c73988458741a00" translate="yes" xml:space="preserve">
          <source>Signed distance is positive for an inlier and negative for an outlier.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="175a8f49ca538859a1536806ea283ecf7546e18e" translate="yes" xml:space="preserve">
          <source>Signed distance to the separating hyperplane.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bdea7e4b3b56af1c4dc44f101507e6d5fde4c3c5" translate="yes" xml:space="preserve">
          <source>Silhouette Coefficient for each samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cef2e4d37f21e366fe4348cb5c8e3de442e95913" translate="yes" xml:space="preserve">
          <source>Silhouette analysis can be used to study the separation distance between the resulting clusters. The silhouette plot displays a measure of how close each point in one cluster is to points in the neighboring clusters and thus provides a way to assess parameters like number of clusters visually. This measure has a range of [-1, 1].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f28647d65c56d46a3ca67f993f108ac366d59691" translate="yes" xml:space="preserve">
          <source>Silhouette coefficients (as these values are referred to as) near +1 indicate that the sample is far away from the neighboring clusters. A value of 0 indicates that the sample is on or very close to the decision boundary between two neighboring clusters and negative values indicate that those samples might have been assigned to the wrong cluster.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88d328be635604c256d2743bcb180fd1daab0b36" translate="yes" xml:space="preserve">
          <source>Similar feature extractors should be built for other kind of unstructured data input such as images, audio, video, &amp;hellip;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="319655ff7753a6199642b7bf6692dc2bf99bfe55" translate="yes" xml:space="preserve">
          <source>Similar to AgglomerativeClustering, but recursively merges features instead of samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="133d603767b5dc043e4bab49b5255c4ddd0f05fe" translate="yes" xml:space="preserve">
          <source>Similar to NuSVC, for regression, uses a parameter nu to control the number of support vectors. However, unlike NuSVC, where nu replaces C, here nu replaces the parameter epsilon of epsilon-SVR.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1a2b055f0753742d67fc90d1d4811e0a5d9ab30" translate="yes" xml:space="preserve">
          <source>Similar to SVC but uses a parameter to control the number of support vectors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="367343dd50d61c27ddbb7a06df2fb9885bdf8a5f" translate="yes" xml:space="preserve">
          <source>Similar to SVC with parameter kernel=&amp;rsquo;linear&amp;rsquo;, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ec63304462f4cbac1c3a261d38d9188bcded830" translate="yes" xml:space="preserve">
          <source>Similar to SVR with parameter kernel=&amp;rsquo;linear&amp;rsquo;, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="997a429b680aeb0ca7576cadadd68b1d30fd4132" translate="yes" xml:space="preserve">
          <source>Similar to other boosting algorithms GBRT builds the additive model in a forward stagewise fashion:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9dba587c665016505432ed3d83545171f96e0b75" translate="yes" xml:space="preserve">
          <source>Similarity between individual biclusters is computed. Then the best matching between sets is found using the Hungarian algorithm. The final score is the sum of similarities divided by the size of the larger set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a365c849553e02aafca0dfedfc5010bc90d3ae71" translate="yes" xml:space="preserve">
          <source>Similarity score between -1.0 and 1.0. Random labelings have an ARI close to 0.0. 1.0 stands for perfect match.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="186186d91781f080c251077ac03fc20cf1639d0c" translate="yes" xml:space="preserve">
          <source>Similarly, &lt;a href=&quot;generated/sklearn.model_selection.repeatedstratifiedkfold#sklearn.model_selection.RepeatedStratifiedKFold&quot;&gt;&lt;code&gt;RepeatedStratifiedKFold&lt;/code&gt;&lt;/a&gt; repeats Stratified K-Fold n times with different randomization in each repetition.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01f578d801e5d1ea722f26bf3985038251d17ab9" translate="yes" xml:space="preserve">
          <source>Similarly, L1 regularized logistic regression solves the following optimization problem</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="33d5515f485c474434afb456d44ce55ecb3a831d" translate="yes" xml:space="preserve">
          <source>Similarly, labels not present in the data sample may be accounted for in macro-averaging.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c868e091c0bbbbc855227dfcc9797f545ef094e" translate="yes" xml:space="preserve">
          <source>Simple 1D Kernel Density Estimation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5468d7aca1a86ccbbf784d0772796020bb33f7b" translate="yes" xml:space="preserve">
          <source>Simple to understand and to interpret. Trees can be visualised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="954c17f332cbfd66dfa98282859837f21d64fd6a" translate="yes" xml:space="preserve">
          <source>Simple usage of Pipeline that runs successively a univariate feature selection with anova and then a C-SVM of the selected features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50f8d26df97413619de7bb6966a9aa041cc32e16" translate="yes" xml:space="preserve">
          <source>Simple usage of Support Vector Machines to classify a sample. It will plot the decision surface and the support vectors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b50d9c69163fc1e922706c7d40ea5de7c4c3507" translate="yes" xml:space="preserve">
          <source>Simple usage of various cross decomposition algorithms: - PLSCanonical - PLSRegression, with multivariate response, a.k.a. PLS2 - PLSRegression, with univariate response, a.k.a. PLS1 - CCA</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0cd5c8d669edd41f72cf141b1f653ffc3a8f7d8a" translate="yes" xml:space="preserve">
          <source>Simply perform a svd on the crosscovariance matrix: X&amp;rsquo;Y There are no iterative deflation here.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f72f0eda605215d24ff9d1908550395272883fb4" translate="yes" xml:space="preserve">
          <source>Simulations</source>
          <target state="translated">Simulations</target>
        </trans-unit>
        <trans-unit id="2e04b6f26b355099b78d114e001527cec11f01b3" translate="yes" xml:space="preserve">
          <source>Since \(P(x_1, \dots, x_n)\) is constant given the input, we can use the following classification rule:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ed5170dfb2a4a5fe27dc284ef1f79230346d84b" translate="yes" xml:space="preserve">
          <source>Since a model internal representation may be different on two different architectures, dumping a model on one architecture and loading it on another architecture is not supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e7dca0922f252e8bcb5dd7de62f190d029edf35" translate="yes" xml:space="preserve">
          <source>Since a simple modulo is used to transform the hash function to a column index, it is advisable to use a power of two as the &lt;code&gt;n_features&lt;/code&gt; parameter; otherwise the features will not be mapped evenly to the columns.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e94526c23963e4af6db5a385aa61965ac4ba9d0e" translate="yes" xml:space="preserve">
          <source>Since it requires to fit &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; classifiers, this method is usually slower than one-vs-the-rest, due to its O(n_classes^2) complexity. However, this method may be advantageous for algorithms such as kernel algorithms which don&amp;rsquo;t scale well with &lt;code&gt;n_samples&lt;/code&gt;. This is because each individual learning problem only involves a small subset of the data whereas, with one-vs-the-rest, the complete dataset is used &lt;code&gt;n_classes&lt;/code&gt; times.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="885cdc36b68d6b1fe527d22b8af012efa7ee88fc" translate="yes" xml:space="preserve">
          <source>Since our loss function is dependent on the amount of samples, the latter will influence the selected value of &lt;code&gt;C&lt;/code&gt;. The question that arises is &lt;code&gt;How do we optimally adjust C to account for the different amount of training samples?&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8414cbee67356c2ab2c8ba5220ad5c2247b09cc6" translate="yes" xml:space="preserve">
          <source>Since recursive partitioning can be represented by a tree structure, the number of splittings required to isolate a sample is equivalent to the path length from the root node to the terminating node.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41606a5be005625c4678c2fc6968d98c5bcdacbb" translate="yes" xml:space="preserve">
          <source>Since the hash function might cause collisions between (unrelated) features, a signed hash function is used and the sign of the hash value determines the sign of the value stored in the output matrix for a feature. This way, collisions are likely to cancel out rather than accumulate error, and the expected mean of any output feature&amp;rsquo;s value is zero. This mechanism is enabled by default with &lt;code&gt;alternate_sign=True&lt;/code&gt; and is particularly useful for small hash table sizes (&lt;code&gt;n_features &amp;lt; 10000&lt;/code&gt;). For large hash table sizes, it can be disabled, to allow the output to be passed to estimators like &lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt;&lt;code&gt;sklearn.naive_bayes.MultinomialNB&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt;&lt;code&gt;sklearn.feature_selection.chi2&lt;/code&gt;&lt;/a&gt; feature selectors that expect non-negative inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91020f655b0d3976000fc58a456fa0d94621c5a6" translate="yes" xml:space="preserve">
          <source>Since the kernel that is to be approximated is additive, the components of the input vectors can be treated separately. Each entry in the original space is transformed into 2*sample_steps+1 features, where sample_steps is a parameter of the method. Typical values of sample_steps include 1, 2 and 3.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dac98c213a89fd4774cf1c1f95b63e10c23ed6ab" translate="yes" xml:space="preserve">
          <source>Since the posterior is intractable, variational Bayesian method uses a simpler distribution \(q(z,\theta,\beta | \lambda, \phi, \gamma)\) to approximate it, and those variational parameters \(\lambda\), \(\phi\), \(\gamma\) are optimized to maximize the Evidence Lower Bound (ELBO):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ce93b96a689b29304c626bbff15b3c9ae5662f8f" translate="yes" xml:space="preserve">
          <source>Since the thresholds are sorted from low to high values, they are reversed upon returning them to ensure they correspond to both &lt;code&gt;fpr&lt;/code&gt; and &lt;code&gt;tpr&lt;/code&gt;, which are sorted in reversed order during their calculation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f69d32984c3b4f143cfa37bb4e60432050ed0eb" translate="yes" xml:space="preserve">
          <source>Since there has not been much empirical work using approximate embeddings, it is advisable to compare results against exact kernel methods when possible.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa984969d0a90a5820c4fc022c64bfc47ca5a084" translate="yes" xml:space="preserve">
          <source>Single estimator versus bagging: bias-variance decomposition</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2fe1a00c3aef2fdadf0dd5e7ea7933f55e2ab1b" translate="yes" xml:space="preserve">
          <source>Single metric evaluation using &lt;code&gt;cross_validate&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78a22764fe4a9b48a649589e690300655f65c80d" translate="yes" xml:space="preserve">
          <source>Single, average and complete linkage can be used with a variety of distances (or affinities), in particular Euclidean distance (&lt;em&gt;l2&lt;/em&gt;), Manhattan distance (or Cityblock, or &lt;em&gt;l1&lt;/em&gt;), cosine distance, or any precomputed affinity matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="857a843ae0f540aecaddebae91ddc74b518d5cf4" translate="yes" xml:space="preserve">
          <source>Singularities:</source>
          <target state="translated">Singularities:</target>
        </trans-unit>
        <trans-unit id="2df59d349ec07bd33a82cdc2b0c4c3d4152244c6" translate="yes" xml:space="preserve">
          <source>Size of minibatches for stochastic optimizers. If the solver is &amp;lsquo;lbfgs&amp;rsquo;, the classifier will not use minibatch. When set to &amp;ldquo;auto&amp;rdquo;, &lt;code&gt;batch_size=min(200, n_samples)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa65aa30a853af1cf81f53119b6649c5aa5e2817" translate="yes" xml:space="preserve">
          <source>Size of the blocks into which the covariance matrix will be split during its Ledoit-Wolf estimation. This is purely a memory optimization and does not affect results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3bdf2049b3b05b0720764317c09e88bc19700eec" translate="yes" xml:space="preserve">
          <source>Size of the blocks into which the covariance matrix will be split. This is purely a memory optimization and does not affect results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="612eb8e8a229547855d2a4c02d66bbe2afb0395a" translate="yes" xml:space="preserve">
          <source>Size of the mini batches.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa636a80a54912b13ca3fa6029e0a40e02f80415" translate="yes" xml:space="preserve">
          <source>Size of the return array</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08f603d3fe1f30df7982a9a08f592731c9eab73e" translate="yes" xml:space="preserve">
          <source>Size of the test sets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d7d650781fdf69336502b899ccd5c9f80ba4848" translate="yes" xml:space="preserve">
          <source>Skip input validation checks, including the Gram matrix when provided assuming there are handled by the caller when check_input=False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="119077d89fb1cbe89db9591404feee43530ef290" translate="yes" xml:space="preserve">
          <source>Slides explaining PLS</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3d721c0cfe644c7ca720484ae796856345cb087" translate="yes" xml:space="preserve">
          <source>Small outliers</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cf8c0d1548c80d5c7b8e80adf89b56b8a30e60f" translate="yes" xml:space="preserve">
          <source>Small positive values of alpha improve the conditioning of the problem and reduce the variance of the estimates. Alpha corresponds to &lt;code&gt;(2*C)^-1&lt;/code&gt; in other linear models such as LogisticRegression or LinearSVC. If an array is passed, penalties are assumed to be specific to the targets. Hence they must correspond in number.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e135bd52bd2eb3356a694f0d8575402c5375bb6" translate="yes" xml:space="preserve">
          <source>Smaller values lead to better embedding and higher number of dimensions (n_components) in the target projection space.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="178a5fd9e6a787566f82c9ecbd118e48b0edcccd" translate="yes" xml:space="preserve">
          <source>Smallest value of alpha / alpha_max considered</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ec75e4c898141f811f9d6fe4e66f6da7a97bb9c" translate="yes" xml:space="preserve">
          <source>Smooth idf weights by adding one to document frequencies, as if an extra document was seen containing every term in the collection exactly once. Prevents zero divisions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ec8b1649217676578a05802f05dc4dfdec72ebc" translate="yes" xml:space="preserve">
          <source>Smoothed empirical log probability for each class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5d952f65cbc310a8284a0aa676904d4b84a635c" translate="yes" xml:space="preserve">
          <source>Smoothed empirical log probability for each class. Only used in edge case with a single class in the training set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb1739757cbc4d2da964b132a46ededacd98a2aa" translate="yes" xml:space="preserve">
          <source>Soft Voting/Majority Rule classifier for unfitted estimators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a33a62c21ea4043dbf31a4f6ee598307b73aa466" translate="yes" xml:space="preserve">
          <source>Soft hint to choose the default backend if no specific backend was selected with the parallel_backend context manager. The default process-based backend is &amp;lsquo;loky&amp;rsquo; and the default thread-based backend is &amp;lsquo;threading&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9653b7a05f5df3e5d87561ce96e265c541ad8c31" translate="yes" xml:space="preserve">
          <source>SokalMichenerDistance</source>
          <target state="translated">SokalMichenerDistance</target>
        </trans-unit>
        <trans-unit id="01ed2fbc860294634b46d80d008798b47284ef75" translate="yes" xml:space="preserve">
          <source>SokalSneathDistance</source>
          <target state="translated">SokalSneathDistance</target>
        </trans-unit>
        <trans-unit id="0b76645291a4941abead277af175738d7e9485f1" translate="yes" xml:space="preserve">
          <source>Solution: &lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_digits_classification_exercise.py&quot;&gt;&lt;code&gt;../../auto_examples/exercises/plot_digits_classification_exercise.py&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="97a1e21d1798b81e7cea434e741d7087aa2f4a99" translate="yes" xml:space="preserve">
          <source>Solution: &lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_iris_exercise.py&quot;&gt;&lt;code&gt;../../auto_examples/exercises/plot_iris_exercise.py&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d31ac38ecaa97cd7ca9cf4223578d60df63f89a9" translate="yes" xml:space="preserve">
          <source>Solve the isotonic regression model:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48c6334f59edac84435c4184f66b59babd6924b9" translate="yes" xml:space="preserve">
          <source>Solve the ridge equation by the method of normal equations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5fa00edfa7fc06c7e99359e114af78ec006b205" translate="yes" xml:space="preserve">
          <source>Solver to use in the computational routines:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c136e6e68fedeebc5e62ea492bdc13f5c51a357" translate="yes" xml:space="preserve">
          <source>Solver to use, possible values:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="577db6a48ff5a1db9c02bebc0320d90f752c60ef" translate="yes" xml:space="preserve">
          <source>Solves a dictionary learning matrix factorization problem online.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8820b686f5bac3c2f3bf8f93441f10523c0fe031" translate="yes" xml:space="preserve">
          <source>Solves a dictionary learning matrix factorization problem.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b22d518aabf32cc9c9347bf653295056dc359f7f" translate="yes" xml:space="preserve">
          <source>Solves n_targets Orthogonal Matching Pursuit problems using only the Gram matrix X.T * X and the product X.T * y.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80547cf29da9d4cc131f68d1680f3500976f9f6f" translate="yes" xml:space="preserve">
          <source>Solves n_targets Orthogonal Matching Pursuit problems. An instance of the problem has the form:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d4fd8866d93aa1260a7a3d03ef9a9a9f9a2fc7d" translate="yes" xml:space="preserve">
          <source>Solves the optimization problem:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e29fb180670f8bd6283a93ce616785d39e9b899f" translate="yes" xml:space="preserve">
          <source>Some advantages of decision trees are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b6f2b5ee645a40c14b49c77184129b10ec1567a" translate="yes" xml:space="preserve">
          <source>Some also work in the multilabel case:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8762622dcc16bf1560cb81f69bbd48256b77f9a4" translate="yes" xml:space="preserve">
          <source>Some calculations when implemented using standard numpy vectorized operations involve using a large amount of temporary memory. This may potentially exhaust system memory. Where computations can be performed in fixed-memory chunks, we attempt to do so, and allow the user to hint at the maximum size of this working memory (defaulting to 1GB) using &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt; or &lt;code&gt;config_context&lt;/code&gt;. The following suggests to limit temporary working memory to 128 MiB:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f425af2b7289a6eb3b0699842a415a72e1141c04" translate="yes" xml:space="preserve">
          <source>Some classification problems can exhibit a large imbalance in the distribution of the target classes: for instance there could be several times more negative samples than positive samples. In such cases it is recommended to use stratified sampling as implemented in &lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.model_selection.stratifiedshufflesplit#sklearn.model_selection.StratifiedShuffleSplit&quot;&gt;&lt;code&gt;StratifiedShuffleSplit&lt;/code&gt;&lt;/a&gt; to ensure that relative class frequencies is approximately preserved in each train and validation fold.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ea2f829ceb432ffa0e3b3d420b4273e01e30d41" translate="yes" xml:space="preserve">
          <source>Some cross validation iterators, such as &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt;, have an inbuilt option to shuffle the data indices before splitting them. Note that:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b7524a4e391762865d52d4ee865a5a389b3ed4f" translate="yes" xml:space="preserve">
          <source>Some estimators expose a &lt;code&gt;transform&lt;/code&gt; method, for instance to reduce the dimensionality of the dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abe93a33221be53771cefc563a6b553fa747a230" translate="yes" xml:space="preserve">
          <source>Some literature promotes alternative definitions of balanced accuracy. Our definition is equivalent to &lt;a href=&quot;sklearn.metrics.accuracy_score#sklearn.metrics.accuracy_score&quot;&gt;&lt;code&gt;accuracy_score&lt;/code&gt;&lt;/a&gt; with class-balanced sample weights, and shares desirable properties with the binary case. See the &lt;a href=&quot;../model_evaluation#balanced-accuracy-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65e1dc1251c858f270c665ff61463afe65f478d7" translate="yes" xml:space="preserve">
          <source>Some metrics are essentially defined for binary classification tasks (e.g. &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt;&lt;code&gt;f1_score&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt;). In these cases, by default only the positive label is evaluated, assuming by default that the positive class is labelled &lt;code&gt;1&lt;/code&gt; (though this may be configurable through the &lt;code&gt;pos_label&lt;/code&gt; parameter).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5ba6b95ba600216ff9982f7a3dbaf94b6802f73" translate="yes" xml:space="preserve">
          <source>Some models allow for specialized, efficient parameter search strategies, &lt;a href=&quot;#alternative-cv&quot;&gt;outlined below&lt;/a&gt;. Two generic approaches to sampling search candidates are provided in scikit-learn: for given values, &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; exhaustively considers all parameter combinations, while &lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt;&lt;code&gt;RandomizedSearchCV&lt;/code&gt;&lt;/a&gt; can sample a given number of candidates from a parameter space with a specified distribution. After describing these tools we detail &lt;a href=&quot;#grid-search-tips&quot;&gt;best practice&lt;/a&gt; applicable to both approaches.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95196f8314df139319d7b42ff6d7520f5ecc9f1d" translate="yes" xml:space="preserve">
          <source>Some models also have &lt;code&gt;row_labels_&lt;/code&gt; and &lt;code&gt;column_labels_&lt;/code&gt; attributes. These models partition the rows and columns, such as in the block diagonal and checkerboard bicluster structures.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89f290ef487f7e4f63f1b82009e209966dcbe74f" translate="yes" xml:space="preserve">
          <source>Some models can fit data for a range of values of some parameter almost as efficiently as fitting the estimator for a single value of the parameter. This feature can be leveraged to perform a more efficient cross-validation used for model selection of this parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d786744290bacd9a4dfc207be555be0e40c3853e" translate="yes" xml:space="preserve">
          <source>Some models can offer an information-theoretic closed-form formula of the optimal estimate of the regularization parameter by computing a single regularization path (instead of several when using cross-validation).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad14a182695bef0a4c2fe22edd0961e8db73147c" translate="yes" xml:space="preserve">
          <source>Some of the clusters learned without connectivity constraints do not respect the structure of the swiss roll and extend across different folds of the manifolds. On the opposite, when opposing connectivity constraints, the clusters form a nice parcellation of the swiss roll.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="877cbb42097301f5a68339d0d9f55e4ca85ad3c3" translate="yes" xml:space="preserve">
          <source>Some of these are restricted to the binary classification case:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc828cde0b0d5dbd5e8ad77797297d4f6416ab76" translate="yes" xml:space="preserve">
          <source>Some other classifiers cope better with this harder version of the task. Try running &lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;Sample pipeline for text feature extraction and evaluation&lt;/a&gt; with and without the &lt;code&gt;--filter&lt;/code&gt; option to compare the results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d754add1306692cb962c5467414be940979d0ab" translate="yes" xml:space="preserve">
          <source>Some parameter settings may result in a failure to &lt;code&gt;fit&lt;/code&gt; one or more folds of the data. By default, this will cause the entire search to fail, even if some parameter settings could be fully evaluated. Setting &lt;code&gt;error_score=0&lt;/code&gt; (or &lt;code&gt;=np.NaN&lt;/code&gt;) will make the procedure robust to such failure, issuing a warning and setting the score for that fold to 0 (or &lt;code&gt;NaN&lt;/code&gt;), but completing the search.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f29c3cd2b5860fb787d236e9a466d0e36eb10659" translate="yes" xml:space="preserve">
          <source>Some tips and tricks:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63fe20eae64c7864fd32162af52c1f81421bc7d2" translate="yes" xml:space="preserve">
          <source>Sometimes it may be useful to convert the data back into the original feature space. The &lt;code&gt;inverse_transform&lt;/code&gt; function converts the binned data into the original feature space. Each value will be equal to the mean of the two bin edges.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="315bc72af841ed152a9aae1c3ac0990cdcb834ed" translate="yes" xml:space="preserve">
          <source>Sometimes looking at the learned coefficients of a neural network can provide insight into the learning behavior. For example if weights look unstructured, maybe some were not used at all, or if very large coefficients exist, maybe regularization was too low or the learning rate too high.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbff2a8532eac744fd3e459bcddf3fd34f40adee" translate="yes" xml:space="preserve">
          <source>Source URL: &lt;a href=&quot;http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&quot;&gt;http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bdef929636b0e2d76c9bcc79abe376f450451dd0" translate="yes" xml:space="preserve">
          <source>Sources, where n_samples is the number of samples and n_components is the number of components.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dcbe3516134bdf9c59a33ffb1c2e3120ebfb3eac" translate="yes" xml:space="preserve">
          <source>Sparse Principal Components Analysis (SparsePCA)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e06472c25d26cda25191de9da3a114b1e469b208" translate="yes" xml:space="preserve">
          <source>Sparse coding</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32c8d921f9e1520199d1db9fe64aa6fb0f91121f" translate="yes" xml:space="preserve">
          <source>Sparse coding with a precomputed dictionary</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83cd17de4011d58af20829baa72e8c3c15415081" translate="yes" xml:space="preserve">
          <source>Sparse components extracted from the data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4aefb6aa7d814b8be3e6d2cb6f2931a1dadb31bc" translate="yes" xml:space="preserve">
          <source>Sparse input</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="935bf4a32a6f741a33bb9ac8e725575de63e795c" translate="yes" xml:space="preserve">
          <source>Sparse inverse covariance estimation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="409d5a415f20eafd9b9f09c6ba22d21458394422" translate="yes" xml:space="preserve">
          <source>Sparse inverse covariance estimation with an l1-penalized estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ee089f1e56c91604e7cab7d40e8b9f34677bb75" translate="yes" xml:space="preserve">
          <source>Sparse inverse covariance w/ cross-validated choice of the l1 penalty</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92e371bb810dfdf353c195f32e5335e997df721c" translate="yes" xml:space="preserve">
          <source>Sparse principal components yields a more parsimonious, interpretable representation, clearly emphasizing which of the original features contribute to the differences between samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="19dbec98d9db7f8dccbc05e595e6dcc554502b17" translate="yes" xml:space="preserve">
          <source>Sparse random matrices are an alternative to dense Gaussian random projection matrix that guarantees similar embedding quality while being much more memory efficient and allowing faster computation of the projected data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ad88cbdaa9d7d5c176762a66b957d3aa9661770" translate="yes" xml:space="preserve">
          <source>Sparse random matrix is an alternative to dense random projection matrix that guarantees similar embedding quality while being much more memory efficient and allowing faster computation of the projected data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7a844fc75c56ce03e1afce70cb2355152140d0b" translate="yes" xml:space="preserve">
          <source>Sparsity</source>
          <target state="translated">Sparsity</target>
        </trans-unit>
        <trans-unit id="814e5a7e79ded720eafc96bc0232cca516d50079" translate="yes" xml:space="preserve">
          <source>Sparsity Example: Fitting only features 1 and 2</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43cddceab3d136418b0e03e98d360e468cf1b8e5" translate="yes" xml:space="preserve">
          <source>Sparsity controlling parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="647e2a8c2a361b51e5b69ed284ca76c83752d0f6" translate="yes" xml:space="preserve">
          <source>Sparsity controlling parameter. Higher values lead to sparser components.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a82be20d822213cd6b317bb5903a0613a76bafa" translate="yes" xml:space="preserve">
          <source>Species distribution modeling</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37195f9a92f1ed14e524a0ed92aab116b735c4ea" translate="yes" xml:space="preserve">
          <source>Specific parameters using e.g. set_params(parameter_name=new_value) In addition, to setting the parameters of the &lt;code&gt;VotingClassifier&lt;/code&gt;, the individual classifiers of the &lt;code&gt;VotingClassifier&lt;/code&gt; can also be set or replaced by setting them to None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94e374689a4595b916bcf5e66713548e054c55c6" translate="yes" xml:space="preserve">
          <source>Specific weights can be assigned to each classifier via the &lt;code&gt;weights&lt;/code&gt; parameter. When weights are provided, the predicted class probabilities for each classifier are collected, multiplied by the classifier weight, and averaged. The final class label is then derived from the class label with the highest average probability.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8fbbf3fe05797ad1e4c717c36a5a204246056853" translate="yes" xml:space="preserve">
          <source>Specifies how multi-class classification problems are handled. Supported are &amp;ldquo;one_vs_rest&amp;rdquo; and &amp;ldquo;one_vs_one&amp;rdquo;. In &amp;ldquo;one_vs_rest&amp;rdquo;, one binary Gaussian process classifier is fitted for each class, which is trained to separate this class from the rest. In &amp;ldquo;one_vs_one&amp;rdquo;, one binary Gaussian process classifier is fitted for each pair of classes, which is trained to separate these two classes. The predictions of these binary predictors are combined into multi-class predictions. Note that &amp;ldquo;one_vs_one&amp;rdquo; does not support predicting probability estimates.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9bddb5670bf596fd4f95945fb300823355f1c46f" translate="yes" xml:space="preserve">
          <source>Specifies if a constant (a.k.a. bias or intercept) should be added to the decision function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="032e8ae2185962af612ef54804c68499bb10a9e0" translate="yes" xml:space="preserve">
          <source>Specifies if the estimated precision is stored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d38faf7dee61c2f434029c24d24417f5a7a63648" translate="yes" xml:space="preserve">
          <source>Specifies if the intercept should be fitted by the model. It must match the fit() method parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21164bb750beb75acb9ae9d1f3fb116169b84f4e" translate="yes" xml:space="preserve">
          <source>Specifies the kernel type to be used in the algorithm. It must be one of &amp;lsquo;linear&amp;rsquo;, &amp;lsquo;poly&amp;rsquo;, &amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;sigmoid&amp;rsquo;, &amp;lsquo;precomputed&amp;rsquo; or a callable. If none is given, &amp;lsquo;rbf&amp;rsquo; will be used. If a callable is given it is used to pre-compute the kernel matrix from data matrices; that matrix should be an array of shape &lt;code&gt;(n_samples, n_samples)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7717364640e0a660ec81dfa33f675030f243fdf0" translate="yes" xml:space="preserve">
          <source>Specifies the kernel type to be used in the algorithm. It must be one of &amp;lsquo;linear&amp;rsquo;, &amp;lsquo;poly&amp;rsquo;, &amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;sigmoid&amp;rsquo;, &amp;lsquo;precomputed&amp;rsquo; or a callable. If none is given, &amp;lsquo;rbf&amp;rsquo; will be used. If a callable is given it is used to precompute the kernel matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b9435d1c3c2633287cc32557661450b6f00ca78e" translate="yes" xml:space="preserve">
          <source>Specifies the loss function. &amp;lsquo;hinge&amp;rsquo; is the standard SVM loss (used e.g. by the SVC class) while &amp;lsquo;squared_hinge&amp;rsquo; is the square of the hinge loss.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68150facd38948e362a68f70eea508701955b6e7" translate="yes" xml:space="preserve">
          <source>Specifies the loss function. The epsilon-insensitive loss (standard SVR) is the L1 loss, while the squared epsilon-insensitive loss (&amp;lsquo;squared_epsilon_insensitive&amp;rsquo;) is the L2 loss.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b5fabde85275fd0a5eb3f705ddd6c262b6e1ace" translate="yes" xml:space="preserve">
          <source>Specifies the loss function. With &amp;lsquo;squared_hinge&amp;rsquo; it is the squared hinge loss (a.k.a. L2 loss). With &amp;lsquo;log&amp;rsquo; it is the loss of logistic regression models.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82fe667ff963f19359a5dba7024bcea48fa12322" translate="yes" xml:space="preserve">
          <source>Specifies the norm used in the penalization. The &amp;lsquo;l2&amp;rsquo; penalty is the standard used in SVC. The &amp;lsquo;l1&amp;rsquo; leads to &lt;code&gt;coef_&lt;/code&gt; vectors that are sparse.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a337b6de37f25f0ac3016f29ff1f6486795a255" translate="yes" xml:space="preserve">
          <source>Specifies the returned model. Select &lt;code&gt;'lar'&lt;/code&gt; for Least Angle Regression, &lt;code&gt;'lasso'&lt;/code&gt; for the Lasso.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32ab0cdbec2fd77050a55d02bdf5982ebc80779f" translate="yes" xml:space="preserve">
          <source>Specify a download and cache folder for the datasets. If None, all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a7f883c69415d4b4614ca7ec1c25ea069f17592" translate="yes" xml:space="preserve">
          <source>Specify an download and cache folder for the datasets. If None, all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bef377c44b3d810cadc5cf65c208d01924bfa02c" translate="yes" xml:space="preserve">
          <source>Specify another download and cache folder for the data sets. By default all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db707a2b2d7445205a990e044438fdad3fa08a72" translate="yes" xml:space="preserve">
          <source>Specify another download and cache folder for the datasets. By default all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0a4c5302feb0239f945ee7ba84757ae55a6d243" translate="yes" xml:space="preserve">
          <source>Specify another download and cache folder for the datasets. By default all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders. .. versionadded:: 0.19</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a104a4391c92d3464c7b1efaf07c449c778bcc9" translate="yes" xml:space="preserve">
          <source>Specify if the estimated precision is stored</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68d4702fc734cffadd8a1ccf005f0aff7fa648f2" translate="yes" xml:space="preserve">
          <source>Specify if the estimated precision is stored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4984f447cb8f4f521871d2431cae9f4220dfb519" translate="yes" xml:space="preserve">
          <source>Specify the column name in the data to use as target. If &amp;lsquo;default-target&amp;rsquo;, the standard target column a stored on the server is used. If &lt;code&gt;None&lt;/code&gt;, all columns are returned as data and the target is &lt;code&gt;None&lt;/code&gt;. If list (of strings), all columns with these names are returned as multi-target (Note: not all scikit-learn classifiers can handle all types of multi-output combinations)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86eb3ad2a989c13695b9d85dcb05b7c45343a61d" translate="yes" xml:space="preserve">
          <source>Specify the desired relative and absolute tolerance of the result. If the true result is K_true, then the returned result K_ret satisfies &lt;code&gt;abs(K_true - K_ret) &amp;lt; atol + rtol * K_ret&lt;/code&gt; The default is zero (i.e. machine precision) for both.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0742682745f85d107eacd49ea30a7e49015c565b" translate="yes" xml:space="preserve">
          <source>Specify the leaf size of the underlying tree. See &lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt;&lt;code&gt;KDTree&lt;/code&gt;&lt;/a&gt; for details. Default is 40.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3eb34c47a1823aab704036791431543ed289a4a" translate="yes" xml:space="preserve">
          <source>Specify the parallelization backend implementation. Supported backends are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ef7e5427d37487b864821803fe9613488fa8ce1" translate="yes" xml:space="preserve">
          <source>Specify the size of the kernel cache (in MB).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4329e4ac0b424da2818ac12cc4d13ce3581c4d3d" translate="yes" xml:space="preserve">
          <source>Specify what features are treated as categorical.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d724db10f986282e8a5446f219cdacdbcddece6" translate="yes" xml:space="preserve">
          <source>Specify whether all or any of the given attributes must exist.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d079850de1341ae0792b165a2e4c64406a6bf6cd" translate="yes" xml:space="preserve">
          <source>Specifying how parameters should be sampled is done using a dictionary, very similar to specifying parameters for &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt;. Additionally, a computation budget, being the number of sampled candidates or sampling iterations, is specified using the &lt;code&gt;n_iter&lt;/code&gt; parameter. For each parameter, either a distribution over possible values or a list of discrete choices (which will be sampled uniformly) can be specified:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="848f2bc6fd9feea5a4bd159161ff60b7b7f1ad05" translate="yes" xml:space="preserve">
          <source>Specifying the dataset by the name &amp;ldquo;iris&amp;rdquo; yields the lowest version, version 1, with the &lt;code&gt;data_id&lt;/code&gt; 61. To make sure you always get this exact dataset, it is safest to specify it by the dataset &lt;code&gt;data_id&lt;/code&gt;. The other dataset, with &lt;code&gt;data_id&lt;/code&gt; 969, is version 3 (version 2 has become inactive), and contains a binarized version of the data:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3df7d54bd992cb63f5a75a6f7de49938e89cdde2" translate="yes" xml:space="preserve">
          <source>Spectral Clustering can also be used to cluster graphs by their spectral embeddings. In this case, the affinity matrix is the adjacency matrix of the graph, and SpectralClustering is initialized with &lt;code&gt;affinity=&amp;rsquo;precomputed&amp;rsquo;&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="943c880ba7aef37194c447e5760436985518b340" translate="yes" xml:space="preserve">
          <source>Spectral Co-Clustering algorithm (Dhillon, 2001).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c8a907562e6db42ff15e9df5a0d9b0b21be7b5f" translate="yes" xml:space="preserve">
          <source>Spectral Embedding (Laplacian Eigenmaps) is most useful when the graph has one connected component. If there graph has many components, the first few eigenvectors will simply uncover the connected components of the graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ff62a97384e4faf388cb99bbcc076cbdae4a5ec" translate="yes" xml:space="preserve">
          <source>Spectral Embedding is an approach to calculating a non-linear embedding. Scikit-learn implements Laplacian Eigenmaps, which finds a low dimensional representation of the data using a spectral decomposition of the graph Laplacian. The graph generated can be considered as a discrete approximation of the low dimensional manifold in the high dimensional space. Minimization of a cost function based on the graph ensures that points close to each other on the manifold are mapped close to each other in the low dimensional space, preserving local distances. Spectral embedding can be performed with the function &lt;a href=&quot;generated/sklearn.manifold.spectral_embedding#sklearn.manifold.spectral_embedding&quot;&gt;&lt;code&gt;spectral_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.spectralembedding#sklearn.manifold.SpectralEmbedding&quot;&gt;&lt;code&gt;SpectralEmbedding&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3266962963ccf3ff289e43e7853a5feea31fa6fe" translate="yes" xml:space="preserve">
          <source>Spectral biclustering (Kluger, 2003).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83334448105603952db5b041593dddc0f02ac19b" translate="yes" xml:space="preserve">
          <source>Spectral biclustering algorithms.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3fddf3521d69d12bc13710d54a4adc12aa85f512" translate="yes" xml:space="preserve">
          <source>Spectral clustering</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="453e3a7c69660270eecfb13dabf16149c8b4512b" translate="yes" xml:space="preserve">
          <source>Spectral clustering for image segmentation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9409615dd1103c73760717b8600df9e2157d615" translate="yes" xml:space="preserve">
          <source>Spectral embedding for non-linear dimensionality reduction.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a0801a4fb2ecc40bcf6f04aa745ad2e1056e690" translate="yes" xml:space="preserve">
          <source>Spectral embedding of the training matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="063a83567f47ad5f5679accf564d96c923566ee9" translate="yes" xml:space="preserve">
          <source>Speed:</source>
          <target state="translated">Speed:</target>
        </trans-unit>
        <trans-unit id="7d07f6cca3dbed6cdb804f0e2864e093c6647564" translate="yes" xml:space="preserve">
          <source>Split arrays or matrices into random train and test subsets</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e854ececac820d9fb56cdde854f788365393cf5" translate="yes" xml:space="preserve">
          <source>Splits it into K folds, trains on K-1 and then tests on the left-out.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2518ac986a45f6943dccb55ec28e7fc9787e8f9" translate="yes" xml:space="preserve">
          <source>Splitter Classes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="474933f1a999ce205b180d93539f6dbb5b05050e" translate="yes" xml:space="preserve">
          <source>Splitter Functions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01474e72e0404f40fd189e5ac7233925222e580d" translate="yes" xml:space="preserve">
          <source>Squared L2 norms of the lines of y. Required if tol is not None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89cdcd77a950e009dab4164bc976d2f6ebb6b9e7" translate="yes" xml:space="preserve">
          <source>Squared Mahalanobis distances of the observations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0b13f625123904866bd60e38bc7611ba95c992c" translate="yes" xml:space="preserve">
          <source>Squared Sum - Sum of the squared L2 norm of all samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c1f19010d2ef30728a1e3cec08abc7bd4b0d974" translate="yes" xml:space="preserve">
          <source>Squared norm of the centroids.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff4530f7332d92145f70c600e76bef65d08e2445" translate="yes" xml:space="preserve">
          <source>Stability path based on randomized Lasso estimates</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a5fecba5d8d30ecb602724233c6166d767b3036" translate="yes" xml:space="preserve">
          <source>Stability selection Nicolai Meinshausen, Peter Buhlmann Journal of the Royal Statistical Society: Series B Volume 72, Issue 4, pages 417-473, September 2010 DOI: 10.1111/j.1467-9868.2010.00740.x</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="891f1b1c9f204fa14cf72f5b45193c02a0d262be" translate="yes" xml:space="preserve">
          <source>Standard deviation of Gaussian noise added to the data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f806d5207c92015615b11e0738f918dc0548c864" translate="yes" xml:space="preserve">
          <source>Standard deviation of predictive distribution at query points. Only returned when return_std is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6edd185d8d7cdfc859bd82ca69e1fcc7af90edcd" translate="yes" xml:space="preserve">
          <source>Standard deviation of predictive distribution of query points.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea11cb9dbd7c4fc006fb08938b76124b12688d69" translate="yes" xml:space="preserve">
          <source>StandardScaler</source>
          <target state="translated">StandardScaler</target>
        </trans-unit>
        <trans-unit id="9f96721b99a0217af973cbedbcbf7d1fa7440aeb" translate="yes" xml:space="preserve">
          <source>Standardization of a dataset is a common requirement for many machine learning estimators. Typically this is done by removing the mean and scaling to unit variance. However, outliers can often influence the sample mean / variance in a negative way. In such cases, the median and the interquartile range often give better results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3845481860a037ebc5c39c64e8de0e95fe45e3fb" translate="yes" xml:space="preserve">
          <source>Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="781aef30981524e4bc3b3ab4682d7e1b6f686dcb" translate="yes" xml:space="preserve">
          <source>Standardize a dataset along any axis</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8089cb9b9abb90199844c7f8d2ad6ef5ad6b9827" translate="yes" xml:space="preserve">
          <source>Standardize features by removing the mean and scaling to unit variance</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="070fc0ca4dc6d3cb17aee36f0432a76e85e66a77" translate="yes" xml:space="preserve">
          <source>Start pointer to all the leaves.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08a6668f9a564bddd6d8fa9fd4934eeea4b017c7" translate="yes" xml:space="preserve">
          <source>Starting configuration of the embedding to initialize the SMACOF algorithm. By default, the algorithm is initialized with a randomly chosen array.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7252947fdd6406b9475a3bf1b686e53848838289" translate="yes" xml:space="preserve">
          <source>Starting configuration of the embedding to initialize the algorithm. By default, the algorithm is initialized with a randomly chosen array.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91cd41feb47c4fc7679dfd69c834b11820027a8b" translate="yes" xml:space="preserve">
          <source>Starting from initial random weights, multi-layer perceptron (MLP) minimizes the loss function by repeatedly updating these weights. After computing the loss, a backward pass propagates it from the output layer to the previous layers, providing each weight parameter with an update value meant to decrease the loss.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcf350fa97b4ef940922ec2e36ae5accc928bb98" translate="yes" xml:space="preserve">
          <source>Starting node for path</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bed5865b6136905da0496b8ae96a4873f78bef72" translate="yes" xml:space="preserve">
          <source>Stat Ass, 79:871, 1984.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6493ce2cca639b99501821839727266114fab06b" translate="yes" xml:space="preserve">
          <source>Statistical learning</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff430697ec62291221833385a34a445a9ee9ecdf" translate="yes" xml:space="preserve">
          <source>Statistical learning: the setting and the estimator object in scikit-learn</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a673f9d4e8314126b08e8f81bb3a33f3d78b1e09" translate="yes" xml:space="preserve">
          <source>Still effective in cases where number of dimensions is greater than the number of samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2473d40abe8e9fb2e7f524b8bad4d74240273fa9" translate="yes" xml:space="preserve">
          <source>Stochastic Gradient Descent</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="195b32448a080f6c15b39de98057b7fe1bc4693b" translate="yes" xml:space="preserve">
          <source>Stochastic Gradient Descent is an optimization technique which minimizes a loss function in a stochastic fashion, performing a gradient descent step sample by sample. In particular, it is a very efficient method to fit linear models.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3aa3ce34d4d1d755f86485089b5a4b4f435a8e2" translate="yes" xml:space="preserve">
          <source>Stochastic Gradient Descent is sensitive to feature scaling, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to [0,1] or [-1,+1], or standardize it to have mean 0 and variance 1. Note that the &lt;em&gt;same&lt;/em&gt; scaling must be applied to the test vector to obtain meaningful results. This can be easily done using &lt;code&gt;StandardScaler&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee01e77469d8f50feb7b1b4735d433d85aa0d812" translate="yes" xml:space="preserve">
          <source>Stochastic gradient boosting allows to compute out-of-bag estimates of the test deviance by computing the improvement in deviance on the examples that are not included in the bootstrap sample (i.e. the out-of-bag examples). The improvements are stored in the attribute &lt;code&gt;oob_improvement_&lt;/code&gt;. &lt;code&gt;oob_improvement_[i]&lt;/code&gt; holds the improvement in terms of the loss on the OOB samples if you add the i-th stage to the current predictions. Out-of-bag estimates can be used for model selection, for example to determine the optimal number of iterations. OOB estimates are usually very pessimistic thus we recommend to use cross-validation instead and only use OOB if cross-validation is too time consuming.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5823a3f0a9a6ed167c583e77307156305a3e83ac" translate="yes" xml:space="preserve">
          <source>Stochastic gradient descent is a simple yet very efficient approach to fit linear models. It is particularly useful when the number of samples (and the number of features) is very large. The &lt;code&gt;partial_fit&lt;/code&gt; method allows online/out-of-core learning.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88c2b7432b4c70aedd301d6441f9f686fac99afd" translate="yes" xml:space="preserve">
          <source>Stochastic gradient descent is an optimization method for unconstrained optimization problems. In contrast to (batch) gradient descent, SGD approximates the true gradient of \(E(w,b)\) by considering a single training example at a time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3bc9b5e942f6c3298a3799e63fea9d4e51700363" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of features. This option is useful only when specifying a connectivity matrix. Note also that when varying the number of clusters and using caching, it may be advantageous to compute the full tree.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3dc26590d142d1e5e73aaec1d67524322b86dfd8" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of samples. In this case, the complete tree is not computed, thus the &amp;lsquo;children&amp;rsquo; output is of limited use, and the &amp;lsquo;parents&amp;rsquo; output should rather be used. This option is valid only when specifying a connectivity matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44e9e4435e20e453549059a3ee4002b032ad438a" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of samples. This option is useful only when specifying a connectivity matrix. Note also that when varying the number of clusters and using caching, it may be advantageous to compute the full tree.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84a6e50b1119dc5648f3c425a6b5dee68899e309" translate="yes" xml:space="preserve">
          <source>Stop iteration if at least this number of inliers are found.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="538193aed5fb2f898d909880cd3e81469e15df67" translate="yes" xml:space="preserve">
          <source>Stop iteration if score is greater equal than this threshold.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12517d0c8ade549d252ae4e535d57433e9861479" translate="yes" xml:space="preserve">
          <source>Stop solver after this many iterations regardless of accuracy (XXX Currently there is no API to know whether this kicked in.) -1 by default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df6a1587df9722b5b493e30cfc313089ab29220d" translate="yes" xml:space="preserve">
          <source>Stop the algorithm if w has converged. Default is 1.e-3.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cf46a1e9b2d853c73253eb4c96cbe1ea1bb5aa6" translate="yes" xml:space="preserve">
          <source>Stop words are words like &amp;ldquo;and&amp;rdquo;, &amp;ldquo;the&amp;rdquo;, &amp;ldquo;him&amp;rdquo;, which are presumed to be uninformative in representing the content of a text, and which may be removed to avoid them being construed as signal for prediction. Sometimes, however, similar words are useful for prediction, such as in classifying writing style or personality.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7eb24af52d1aa9e6b8d6715fd2fd646422f9b535" translate="yes" xml:space="preserve">
          <source>Stopping criteria.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51b3a0bb0b4d84ebe8a65cc9b8c0c2b3279fba93" translate="yes" xml:space="preserve">
          <source>Stopping criterion for eigendecomposition of the Laplacian matrix when using arpack eigen_solver.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68414daf9a6e27622678aff82460baea3a51326c" translate="yes" xml:space="preserve">
          <source>Stopping criterion. For the newton-cg and lbfgs solvers, the iteration will stop when &lt;code&gt;max{|g_i | i = 1, ..., n} &amp;lt;= tol&lt;/code&gt; where &lt;code&gt;g_i&lt;/code&gt; is the i-th component of the gradient.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe10af6492740b92517388e940d4c53ee7e65f2c" translate="yes" xml:space="preserve">
          <source>Stopping tolerance for EM algorithm.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3afb8412732c53a6b3ed5f0cf3d5d66e9526d993" translate="yes" xml:space="preserve">
          <source>Stopping tolerance for updating document topic distribution in E-step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5745be1c1a529a40ad5578990283b7d9ed5dfe16" translate="yes" xml:space="preserve">
          <source>Store n output values in leaves, instead of 1;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a6ab3415c7252ce3e941fe62193814f0365a625" translate="yes" xml:space="preserve">
          <source>Stores nearest neighbors instance, including BallTree or KDtree if applicable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9d028499b97399f71598e9bb920fa52d5ec8313" translate="yes" xml:space="preserve">
          <source>Stores the affinity matrix used in &lt;code&gt;fit&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="781b70a9f7d2aabdccb43059620f25863827cacd" translate="yes" xml:space="preserve">
          <source>Stores the embedding vectors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9fe548f57e57cace725aa47be0bac94930f35de7" translate="yes" xml:space="preserve">
          <source>Stores the embedding vectors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7019b0e2126237169f8ccc84f1dacd8599b7b63" translate="yes" xml:space="preserve">
          <source>Stores the geodesic distance matrix of training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bfa0d6921b4ff07d4718354c3a4168af9b3a946" translate="yes" xml:space="preserve">
          <source>Stores the position of the dataset in the embedding space.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8197f80c6163117652499db82ad63b22aa5b87b2" translate="yes" xml:space="preserve">
          <source>Stores the training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6485fe8179de6b50a8b0db7cf302477ffee4cf50" translate="yes" xml:space="preserve">
          <source>Strategy to use to generate predictions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ba291b4721c49cd83c83d224ae746db45b32e1d" translate="yes" xml:space="preserve">
          <source>Strategy used to define the widths of the bins.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="890ad0feded21dbb4c68bfca3e2d7cdbb498d411" translate="yes" xml:space="preserve">
          <source>Stratified K-Folds cross-validator</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="078f2e04c72cf2c2cef672d9cd530d809895796a" translate="yes" xml:space="preserve">
          <source>Stratified ShuffleSplit cross-validator</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10ef227c2ccc54bd522a7229f1c708e11ce5e295" translate="yes" xml:space="preserve">
          <source>Strehl, Alexander, and Joydeep Ghosh (2002). &amp;ldquo;Cluster ensembles &amp;ndash; a knowledge reuse framework for combining multiple partitions&amp;rdquo;. Journal of Machine Learning Research 3: 583&amp;ndash;617. &lt;a href=&quot;http://strehl.com/download/strehl-jmlr02.pdf&quot;&gt;doi:10.1162/153244303321897735&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f823045d1b6e6e3e2566fad8b86b9a7f7274035" translate="yes" xml:space="preserve">
          <source>String describing the type of covariance parameters to use. Must be one of:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24715b349c9d19241a871e75b2e65bf44d424eee" translate="yes" xml:space="preserve">
          <source>String describing the type of the weight concentration prior. Must be one of:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="428566ee279a0d9edb0dac9070b52a231b258cad" translate="yes" xml:space="preserve">
          <source>String identifier for kernel function to use or the kernel function itself. Only &amp;lsquo;rbf&amp;rsquo; and &amp;lsquo;knn&amp;rsquo; strings are valid inputs. The function passed should take two inputs, each of shape [n_samples, n_features], and return a [n_samples, n_samples] shaped weight matrix</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af724a0a2167e8652dc92f95eace643e40894f38" translate="yes" xml:space="preserve">
          <source>String identifier for kernel function to use or the kernel function itself. Only &amp;lsquo;rbf&amp;rsquo; and &amp;lsquo;knn&amp;rsquo; strings are valid inputs. The function passed should take two inputs, each of shape [n_samples, n_features], and return a [n_samples, n_samples] shaped weight matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62948e7b4671e9ca0f3cde3750c969c3432c4224" translate="yes" xml:space="preserve">
          <source>String identifier of the dataset. Note that OpenML can have multiple datasets with the same name.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df0679bd93bc3d3699b427e726c60dd8e54a8049" translate="yes" xml:space="preserve">
          <source>String inputs, &amp;ldquo;absolute_loss&amp;rdquo; and &amp;ldquo;squared_loss&amp;rdquo; are supported which find the absolute loss and squared loss per sample respectively.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e35f8f4354526879dda20784b410a6fffd10219" translate="yes" xml:space="preserve">
          <source>String must be in {&amp;lsquo;frobenius&amp;rsquo;, &amp;lsquo;kullback-leibler&amp;rsquo;, &amp;lsquo;itakura-saito&amp;rsquo;}. Beta divergence to be minimized, measuring the distance between X and the dot product WH. Note that values different from &amp;lsquo;frobenius&amp;rsquo; (or 2) and &amp;lsquo;kullback-leibler&amp;rsquo; (or 1) lead to significantly slower fits. Note that for beta_loss &amp;lt;= 0 (or &amp;lsquo;itakura-saito&amp;rsquo;), the input matrix X cannot contain zeros. Used only in &amp;lsquo;mu&amp;rsquo; solver.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f2d9e288ea5ff4eb7ea1abaab0c518bb3979797" translate="yes" xml:space="preserve">
          <source>String names for input features if available. By default, &amp;ldquo;x0&amp;rdquo;, &amp;ldquo;x1&amp;rdquo;, &amp;hellip; &amp;ldquo;xn_features&amp;rdquo; is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6eb302a1a8353d21c585781076747cec5064ac6a" translate="yes" xml:space="preserve">
          <source>String representation of the input tree in GraphViz dot format. Only returned if &lt;code&gt;out_file&lt;/code&gt; is None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a25a8a192fb86c92debb43e92001c859f89e3fcf" translate="yes" xml:space="preserve">
          <source>String[s] representing allowed sparse matrix formats, such as &amp;lsquo;csc&amp;rsquo;, &amp;lsquo;csr&amp;rsquo;, etc. If the input is sparse but not in the allowed format, it will be converted to the first listed format. True allows the input to be any format. False means that a sparse matrix input will raise an error.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b91b90e5e49a63cce92ec827bcf2ae012d9565f3" translate="yes" xml:space="preserve">
          <source>Subsequently, the object is created as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8cf7e7f541f13164e6f0420a446eeb6e92a09d1" translate="yes" xml:space="preserve">
          <source>Subset of X on first axis</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ae596021e773a90882ea646d69c3ae9bc66f60f" translate="yes" xml:space="preserve">
          <source>Subset of target values</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71578b0f6daa48f798b6ba24f599e04480076227" translate="yes" xml:space="preserve">
          <source>Subset of the target values</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="223f88ba981735506f55650c24adc2c0be541ac7" translate="yes" xml:space="preserve">
          <source>Subset of the training data</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6bc315a85db741490d46c866dcdf3685f245d4e2" translate="yes" xml:space="preserve">
          <source>Subset of training data</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="19abeb39c58b2714170ce5a2488e41705eacf825" translate="yes" xml:space="preserve">
          <source>Subset of training points used to construct the feature map.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af82dc274666b6dae18b2b0a4a918322786e1ec9" translate="yes" xml:space="preserve">
          <source>Such a grouping of data is domain specific. An example would be when there is medical data collected from multiple patients, with multiple samples taken from each patient. And such data is likely to be dependent on the individual group. In our example, the patient id for each sample will be its group identifier.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="116040368f9a04b617abdb5e80205920c1827d88" translate="yes" xml:space="preserve">
          <source>Such integer representation can, however, not be used directly with all scikit-learn estimators, as these expect continuous input, and would interpret the categories as being ordered, which is often not desired (i.e. the set of browsers was ordered arbitrarily).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db90c3a55b9a44b531c3ac8e926f4bff46ae5000" translate="yes" xml:space="preserve">
          <source>Sum of squared distances of samples to their closest cluster center.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51853ebee0d0437a819288d394e52f2825e89e10" translate="yes" xml:space="preserve">
          <source>Sum-kernel k1 + k2 of two kernels k1 and k2.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70ee3e3bff0af30ecffa237a657d140e21c08452" translate="yes" xml:space="preserve">
          <source>Summary Statistics:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd64088007de4ee1ec90faddb61b9fabe7591dbe" translate="yes" xml:space="preserve">
          <source>Supervised learning algorithms will require a category label for each document in the training set. In this case the category is the name of the newsgroup which also happens to be the name of the folder holding the individual documents.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a76d63a44e8696360e974f3be74fa9ede463ccb8" translate="yes" xml:space="preserve">
          <source>Supervised learning: predicting an output variable from high-dimensional observations</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6eafe7087c2917502cf9a105460eb618a5158ac5" translate="yes" xml:space="preserve">
          <source>Support Vector Classification (SVC) shows an even more sigmoid curve as the RandomForestClassifier, which is typical for maximum-margin methods (compare Niculescu-Mizil and Caruana &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;), which focus on hard samples that are close to the decision boundary (the support vectors).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed5eaa4e09c1fde40caa79c99d658b1a804b4ecf" translate="yes" xml:space="preserve">
          <source>Support Vector Machine algorithms are not scale invariant, so &lt;strong&gt;it is highly recommended to scale your data&lt;/strong&gt;. For example, scale each attribute on the input vector X to [0,1] or [-1,+1], or standardize it to have mean 0 and variance 1. Note that the &lt;em&gt;same&lt;/em&gt; scaling must be applied to the test vector to obtain meaningful results. See section &lt;a href=&quot;preprocessing#preprocessing&quot;&gt;Preprocessing data&lt;/a&gt; for more details on scaling and normalization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7db4fe2bb2b495808d702cc828d549eda5ecd6dd" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for Regression implemented using libsvm.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f893d85d40edb954e6730df0c490772b3e2a0229" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for classification implemented with libsvm with a parameter to control the number of support vectors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5051cb5a7ebb600b6c87a0405fb53ae2a929b69a" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for classification using libsvm.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9c0030d3280fdd6faa0de4e8ec40fd895c7cc05" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for regression implemented using libsvm using a parameter to control the number of support vectors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56158ab7bc33e3424017c0101c6f6a1afb88a3a9" translate="yes" xml:space="preserve">
          <source>Support Vector Machines are powerful tools, but their compute and storage requirements increase rapidly with the number of training vectors. The core of an SVM is a quadratic programming problem (QP), separating support vectors from the rest of the training data. The QP solver used by this &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;-based implementation scales between \(O(n_{features} \times n_{samples}^2)\) and \(O(n_{features} \times n_{samples}^3)\) depending on how efficiently the &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; cache is used in practice (dataset dependent). If the data is very sparse \(n_{features}\) should be replaced by the average number of non-zero features in a sample vector.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5aeba1d5d3764ce4f342c9f3c5c4d98c95831ef3" translate="yes" xml:space="preserve">
          <source>Support Vector Regression (SVR) using linear and non-linear kernels</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c38caf86bc0ea77939ed0d559b2d4f17cae05de8" translate="yes" xml:space="preserve">
          <source>Support Vector Regression implemented using libsvm.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f57f9c660b4dd2f0deaa4ba97e0c878c516d5af" translate="yes" xml:space="preserve">
          <source>Support vector machines (SVMs)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbbf41eb38c0c6ebc14c9776b74f3b7c7223e260" translate="yes" xml:space="preserve">
          <source>Support vectors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a54e8408d47bb6e31202d1c04b19dcb2a41dd085" translate="yes" xml:space="preserve">
          <source>Supports sparse matrices, as long as they are nonnegative.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d69897cfb127444947f0af512011088c32f7842" translate="yes" xml:space="preserve">
          <source>Suppose there are \(n\) training samples, \(m\) features, \(k\) hidden layers, each containing \(h\) neurons - for simplicity, and \(o\) output neurons. The time complexity of backpropagation is \(O(n\cdot m \cdot h^k \cdot o \cdot i)\), where \(i\) is the number of iterations. Since backpropagation has a high time complexity, it is advisable to start with smaller number of hidden neurons and few hidden layers for training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="717b26aef2df5c03a35ae859cfcbb420ec45f953" translate="yes" xml:space="preserve">
          <source>Swaps two columns of a CSC/CSR matrix in-place.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1069fce64f91499526a54ca2a920222a7a6a7b20" translate="yes" xml:space="preserve">
          <source>Swaps two rows of a CSC/CSR matrix in-place.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe072010fa51f4d65d4b1c57510d1adce13a6e7b" translate="yes" xml:space="preserve">
          <source>Swiss Roll reduction with LLE</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2230299d58c6b8fd7778e9806246c78a89ba5d37" translate="yes" xml:space="preserve">
          <source>Symmetrized version of the input array, i.e. the average of array and array.transpose(). If sparse, then duplicate entries are first summed and zeros are eliminated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5617e20da29f8f9d1be80cd4e8da4f2cca7d87a9" translate="yes" xml:space="preserve">
          <source>Symmetry: d(x, y) = d(y, x)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c4b58b32e84506455d7badad68c3391e5ed62f8" translate="yes" xml:space="preserve">
          <source>Synthetic example</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2f05b63d3eed62a3d034f7470902282f6f3879f" translate="yes" xml:space="preserve">
          <source>T. Calinski and J. Harabasz, 1974. &amp;ldquo;A dendrite method for cluster analysis&amp;rdquo;. Communications in Statistics</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfd0a0e6ed4317c498cad6dff52fb64a880cf1fc" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman, &amp;ldquo;Elements of Statistical Learning Ed. 2&amp;rdquo;, Springer, 2009.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f7943ebfea41ffafd05b1021989488d98e43338" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman, &amp;ldquo;Elements of Statistical Learning Ed. 2&amp;rdquo;, p592-593, Springer, 2009.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70c29954ab4c3cb7794dae94a173c1937d4eb172" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman, &amp;ldquo;Elements of Statistical Learning&amp;rdquo;, Springer, 2009.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83fcdb4c642340f440ec3c76643b0ff4a3e4d907" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman. &amp;ldquo;Elements of Statistical Learning&amp;rdquo;, Springer, 2009.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb7835aaacc19565f84e186774c00699f37d4811" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman. Elements of Statistical Learning Ed. 2, Springer, 2009.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4c99bc2ba4c28ec35fea9e0c8535d7da602917b" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman. Elements of Statistical Learning, Springer, 2009.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="080b47cb3536b08b8d64a0132c354c0e69235639" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani, J. Friedman, &lt;a href=&quot;https://web.stanford.edu/~hastie/ElemStatLearn/&quot;&gt;The Elements of Statistical Learning&lt;/a&gt;, Springer 2009</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="caa676716fee5a5c020ff878a7d0616f2b82e015" translate="yes" xml:space="preserve">
          <source>T. Ho, &amp;ldquo;The random subspace method for constructing decision forests&amp;rdquo;, Pattern Analysis and Machine Intelligence, 20(8), 832-844, 1998.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12a252b4085c50c08e5600b6a2ace31faa3ef960" translate="yes" xml:space="preserve">
          <source>T. Yang, Y. Li, M. Mahdavi, R. Jin and Z. Zhou &amp;ldquo;Nystroem Method vs Random Fourier Features: A Theoretical and Empirical Comparison&amp;rdquo;, Advances in Neural Information Processing Systems 2012</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01f0642e8e9ab9a87342728e5ceb8bbd9d2f4ab3" translate="yes" xml:space="preserve">
          <source>TAX full-value property-tax rate per $10,000</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd1b5c68340d106d37b309522fe8b393cb21ad39" translate="yes" xml:space="preserve">
          <source>TF-IDF vectors of text documents crawled from the web</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45e8bc91482fcb8372ecf82971819bb3adf7f455" translate="yes" xml:space="preserve">
          <source>TODO: implement zip dataset loading too</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ab0e32d1d047cd892b558c9b2f078b6857615c4" translate="yes" xml:space="preserve">
          <source>Takes a group array to group observations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3fd5fa24212eb9a6093f6fb3922373c2e928c57e" translate="yes" xml:space="preserve">
          <source>Takes group information into account to avoid building folds with imbalanced class distributions (for binary or multiclass classification tasks).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9f2745c15759b2e07e7b8ac9dcbd8d3eb7f1df5" translate="yes" xml:space="preserve">
          <source>Talks given, slide-sets and other information relevant to scikit-learn.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61ad50a9b9189cc3cf1874568e35e7901ff4c982" translate="yes" xml:space="preserve">
          <source>Target</source>
          <target state="translated">Target</target>
        </trans-unit>
        <trans-unit id="3566560919d090e98a5bc58e40d68ba478487e60" translate="yes" xml:space="preserve">
          <source>Target number of non-zero coefficients. Use &lt;code&gt;np.inf&lt;/code&gt; for no limit.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de81f661c0a5f66b2eb62d654cf5ee97c42a462f" translate="yes" xml:space="preserve">
          <source>Target relative to X for classification or regression; None for unsupervised learning.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9d3de45f60123470c229b29def5cf613978229f" translate="yes" xml:space="preserve">
          <source>Target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions (as returned by &amp;ldquo;decision_function&amp;rdquo; on some classifiers).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2da36130db1b72e7220423e41225d3cfbecbf96b" translate="yes" xml:space="preserve">
          <source>Target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions (as returned by &amp;ldquo;decision_function&amp;rdquo; on some classifiers). For binary y_true, y_score is supposed to be the score of the class with greater label.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c1467eb9fce38ab3f431a143b7b4099a3d2d978" translate="yes" xml:space="preserve">
          <source>Target values</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1eb29851ae3516c30efee3683f12f4c58d29d5ce" translate="yes" xml:space="preserve">
          <source>Target values (class labels in classification, real numbers in regression)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9236c7bb185e41917cc98485dd0c1b72938dc4f1" translate="yes" xml:space="preserve">
          <source>Target values (integers for classification, real numbers for regression).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abfa5417a6d6ee53dab20f6c0ef952512e0950c9" translate="yes" xml:space="preserve">
          <source>Target values (integers)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="030d74b88e6ada2cc611aa05819c6875ad926cb6" translate="yes" xml:space="preserve">
          <source>Target values (integers). Will be cast to X&amp;rsquo;s dtype if necessary</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="489913dd1ba6e89f6fe19c6ab73a6d0ba1572bbc" translate="yes" xml:space="preserve">
          <source>Target values (strings or integers in classification, real numbers in regression) For classification, labels must correspond to classes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20f1907edd6deff55545e2c6878457953ca23f05" translate="yes" xml:space="preserve">
          <source>Target values in training data (also required for prediction)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5698f85443295556a3231f89aa327fa20aab0ad9" translate="yes" xml:space="preserve">
          <source>Target values of shape = [n_samples] or [n_samples, n_outputs]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da9e802f308bd36e270eb5bda433836f08ce2390" translate="yes" xml:space="preserve">
          <source>Target values, array of float values, shape = [n_samples]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d4acf064ddb5b23ed0c4bdf7cb1ed1c86e0cce4" translate="yes" xml:space="preserve">
          <source>Target values, must be binary</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3784ae1e62853f0d4899c1eb47f9d650c50e4292" translate="yes" xml:space="preserve">
          <source>Target values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a264b43381dcd3fa803548587f56b48ebe73a21" translate="yes" xml:space="preserve">
          <source>Target values. All sparse matrices are converted to CSR before inverse transformation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="338b0342f37ab2a3243f471f75fbb6b8060759e1" translate="yes" xml:space="preserve">
          <source>Target values. Class labels must be an integer or float, or array-like objects of integer or float for multilabel classifications.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d95ddd0372c185ada4f873880d8cf72b3e972b79" translate="yes" xml:space="preserve">
          <source>Target values. The 2-d matrix should only contain 0 and 1, represents multilabel classification.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d68da7045b7713975074def112516b22e3d548e" translate="yes" xml:space="preserve">
          <source>Target values. The 2-d matrix should only contain 0 and 1, represents multilabel classification. Sparse matrix can be CSR, CSC, COO, DOK, or LIL.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ca333a3206ea1ae310cc995419dd5b579b0311c" translate="yes" xml:space="preserve">
          <source>Target values. Will be cast to X&amp;rsquo;s dtype if necessary</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a73f8fffa45e4edde85ae5cfe9a7df8f5b0ddf64" translate="yes" xml:space="preserve">
          <source>Target vector (class labels).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbbf7212be6c75614582f7683105e9b145317ffe" translate="yes" xml:space="preserve">
          <source>Target vector relative to X</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b9ad2408038efc60fe0697bee9336f5ceee389a" translate="yes" xml:space="preserve">
          <source>Target vector relative to X.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb81b6b3ab32530c4b31b59fded732e0bc1457db" translate="yes" xml:space="preserve">
          <source>Target vector.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86747748812222a9af434d10160edcea63797259" translate="yes" xml:space="preserve">
          <source>Target vectors, where n_samples is the number of samples and n_targets is the number of response variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb444a37f78059e3557a89e3cec7d30ee2a0e255" translate="yes" xml:space="preserve">
          <source>Target. Will be cast to X&amp;rsquo;s dtype if necessary</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="652ac2cbbafccc62d55637f20bfa949ef565ffbd" translate="yes" xml:space="preserve">
          <source>Target:</source>
          <target state="translated">Target:</target>
        </trans-unit>
        <trans-unit id="d35260a00f655f27edcc35a7eb16da44a4f671a6" translate="yes" xml:space="preserve">
          <source>Targets</source>
          <target state="translated">Targets</target>
        </trans-unit>
        <trans-unit id="bae347ef05fa5719d83860ee11ad8e50b4550a95" translate="yes" xml:space="preserve">
          <source>Targets for input data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25e14b664fd8a2e3008eacd528868e3512f875a8" translate="yes" xml:space="preserve">
          <source>Targets for supervised learning.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e907b7e300146da06f6bd372dfec64398cc10d60" translate="yes" xml:space="preserve">
          <source>Targets used for scoring. Must fulfill label requirements for all steps of the pipeline.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12f7c88d38da9108a78eb595ada57372e18cdd00" translate="yes" xml:space="preserve">
          <source>Technically the Lasso model is optimizing the same objective function as the Elastic Net with &lt;code&gt;l1_ratio=1.0&lt;/code&gt; (no L2 penalty).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c21757d6dba7765c9b420762d607df44985a57d" translate="yes" xml:space="preserve">
          <source>Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="faacbc438202f94eb51c4c27efecd77f5a804a90" translate="yes" xml:space="preserve">
          <source>Tenenbaum, J.B.; De Silva, V.; &amp;amp; Langford, J.C. A global geometric framework for nonlinear dimensionality reduction. Science 290 (5500)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a1358959d0f2f819085e4aa4680265c467cbf33" translate="yes" xml:space="preserve">
          <source>Tenenhaus, M. (1998). La regression PLS: theorie et pratique. Paris: Editions Technic.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a268d2f62458299ec67330e170374c2cecaa669" translate="yes" xml:space="preserve">
          <source>Terms that were ignored because they either:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f2d4d3a12b50c0b296af732b3fa3674c7292a32" translate="yes" xml:space="preserve">
          <source>Test data of which we compute the likelihood, where n_samples is the number of samples and n_features is the number of features. X_test is assumed to be drawn from the same distribution than the data used in fit (including centering).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed7e95a0302971bec5a032415d69927921186679" translate="yes" xml:space="preserve">
          <source>Test data to be transformed, must have the same number of features as the data used to train the model.</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
