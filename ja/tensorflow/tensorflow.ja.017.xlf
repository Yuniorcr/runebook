<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ja" datatype="htmlbody" original="tensorflow">
    <body>
      <group id="tensorflow">
        <trans-unit id="7b79ea25b443c6adc7bf49215c2468b862ce0b81" translate="yes" xml:space="preserve">
          <source>A tuple of &lt;code&gt;Tensor&lt;/code&gt; objects (out, idx).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b18d9de3a3b15f761136321357d19850ca4c101" translate="yes" xml:space="preserve">
          <source>A tuple of &lt;code&gt;Tensor&lt;/code&gt; objects (out_example_state_data, out_delta_sparse_weights, out_delta_dense_weights).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8cc1f5457190fbaa38d0fbcc48ddef2bf4fe66dd" translate="yes" xml:space="preserve">
          <source>A tuple of &lt;code&gt;Tensor&lt;/code&gt; objects (output, argmax).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8af6d705600626669964ef96360c72da5d2cc875" translate="yes" xml:space="preserve">
          <source>A tuple of &lt;code&gt;Tensor&lt;/code&gt; objects (output, min_output, max_output).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7152cb50141f5cf2c492d0a9ebd05f21d2d1a61" translate="yes" xml:space="preserve">
          <source>A tuple of &lt;code&gt;Tensor&lt;/code&gt; objects (output, output_min, output_max).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8246d4ab2e2ef88cd118f497e0829c60216214d5" translate="yes" xml:space="preserve">
          <source>A tuple of &lt;code&gt;Tensor&lt;/code&gt; objects (q, r).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a414221325a1e9899d49c7f4c08df31ba679b1f" translate="yes" xml:space="preserve">
          <source>A tuple of &lt;code&gt;Tensor&lt;/code&gt; objects (sign, log_abs_determinant).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="958212df82bdbac2aba0bf74b02ec816df062b9b" translate="yes" xml:space="preserve">
          <source>A tuple of &lt;code&gt;Tensor&lt;/code&gt; objects (sizes, values).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6099af9655b5112f00f7395538ea81b19e40c003" translate="yes" xml:space="preserve">
          <source>A tuple of &lt;code&gt;Tensor&lt;/code&gt; objects (y, idx).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6fe3804ea9d7572a8b46a0130298b9cb4cca18b8" translate="yes" xml:space="preserve">
          <source>A tuple of &lt;code&gt;Tensor&lt;/code&gt; objects (y, idx, count).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bfe2f413cbad9eaa03011a1ad84c3e181f23e7b4" translate="yes" xml:space="preserve">
          <source>A tuple of Tensors (key, value).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cebd2ae8b185424bcb06863358a14a6bb14451ba" translate="yes" xml:space="preserve">
          <source>A tuple of Tensors (keys, values).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed0040208563172a465593f3d78dbb7fa26408ef" translate="yes" xml:space="preserve">
          <source>A tuple of indices, values, and shape representing the average gradient.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b2fab150d886678e8db01948e43bb6c90d963de" translate="yes" xml:space="preserve">
          <source>A tuple of integers (or None entries).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f082110f3be786c0dee8153c3819e9981fd33e8c" translate="yes" xml:space="preserve">
          <source>A tuple of the result of the &lt;code&gt;evaluate&lt;/code&gt; call to the &lt;code&gt;Estimator&lt;/code&gt; and the export results using the specified &lt;code&gt;ExportStrategy&lt;/code&gt;. Currently, the return value is undefined for distributed training mode.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c5ab8e9d6cca0a3b4a47075a827992d6e1fbfb0" translate="yes" xml:space="preserve">
          <source>A tuple of three &lt;code&gt;dict&lt;/code&gt;s, each mapping keys to &lt;code&gt;Tensor&lt;/code&gt;s, &lt;code&gt;SparseTensor&lt;/code&gt;s, and &lt;code&gt;RaggedTensor&lt;/code&gt;. The first dict contains the context key/values, the second dict contains the feature_list key/values, and the final dict contains the lengths of any dense feature_list features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7df41514b7105dad6e7230164f75b93802f9b076" translate="yes" xml:space="preserve">
          <source>A tuple of two &lt;code&gt;dict&lt;/code&gt;s, each mapping keys to &lt;code&gt;Tensor&lt;/code&gt;s and &lt;code&gt;SparseTensor&lt;/code&gt;s and &lt;code&gt;RaggedTensor&lt;/code&gt;s.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ab0350d5c227d97f7a490d799db30d72a2a0820" translate="yes" xml:space="preserve">
          <source>A tuple of two integers that should be used for the local seed of this operation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e86ad3e53eaf00c3d3b16749e050f1576ca9da95" translate="yes" xml:space="preserve">
          <source>A tuple of values contained in &lt;code&gt;value&lt;/code&gt;. If &lt;code&gt;value&lt;/code&gt; represents a single value, this returns &lt;code&gt;(value,).&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf1a5e0c200ae352361a13d399455f15fd4b257c" translate="yes" xml:space="preserve">
          <source>A tuple whose first element is an list of TFDecorator-derived objects that were applied to the final callable target, and whose second element is the final undecorated callable target. If the &lt;code&gt;maybe_tf_decorator&lt;/code&gt; parameter is not decorated by any TFDecorators, the first tuple element will be an empty list. The &lt;code&gt;TFDecorator&lt;/code&gt; list is ordered from outermost to innermost decorators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40e0b19447af71d4ab64397e8054ca2374eecbbe" translate="yes" xml:space="preserve">
          <source>A tuple, &lt;code&gt;(last_output, outputs, new_states)&lt;/code&gt;. last_output: the latest output of the rnn, of shape &lt;code&gt;(samples, ...)&lt;/code&gt; outputs: tensor with shape &lt;code&gt;(samples, time, ...)&lt;/code&gt; where each entry &lt;code&gt;outputs[s, t]&lt;/code&gt; is the output of the step function at time &lt;code&gt;t&lt;/code&gt; for sample &lt;code&gt;s&lt;/code&gt;. new_states: list of tensors, latest states returned by the step function, of shape &lt;code&gt;(samples, ...)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="46715bb9ac2c3fbd51f7bebf212d5321788d23b9" translate="yes" xml:space="preserve">
          <source>A tuple, in which case the first item is extracted as features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9fe226e16343d1b415adaf45e930429d7c587a9c" translate="yes" xml:space="preserve">
          <source>A tuple-specific equality assertion.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99b7ff63e388cbb308508bb3b2bd0313cf775fbd" translate="yes" xml:space="preserve">
          <source>A two-dimensional &lt;code&gt;Tensor&lt;/code&gt; of type &lt;a href=&quot;../tf#uint8&quot;&gt;&lt;code&gt;tf.uint8&lt;/code&gt;&lt;/a&gt;. The first dimension equals to &lt;code&gt;data&lt;/code&gt;'s first dimension, and the second dimension size depends on the fingerprint algorithm.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70b69b4e03f9c444ef5cac8028f0e004471f4d66" translate="yes" xml:space="preserve">
          <source>A typical thread running with a coordinator will do something like:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a9dec1700f46247decbe7b6924fab6b8490e8f7" translate="yes" xml:space="preserve">
          <source>A uint8 tensor (0s and 1s).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac8540c4a92611e432f7c39ff07b605123185973" translate="yes" xml:space="preserve">
          <source>A utility function that calls the provided logit_fn with the relevant subset of provided arguments. Similar to tf.estimator._call_model_fn().</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2db988d7b4e61d74790ab74ee3cf874a140356c2" translate="yes" xml:space="preserve">
          <source>A validated &lt;code&gt;EstimatorSpec&lt;/code&gt; object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa582a6512e81f7f7d65e8a94b909e3cc9e64752" translate="yes" xml:space="preserve">
          <source>A validated &lt;code&gt;EvalSpec&lt;/code&gt; object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d51f65c6136248178195cb244d2f1e7f9a159899" translate="yes" xml:space="preserve">
          <source>A validated &lt;code&gt;TrainSpec&lt;/code&gt; object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86d610f45a29971a171528ff7d87389d7da56ca5" translate="yes" xml:space="preserve">
          <source>A value &amp;gt;=0 means use the index (starting at zero) of the split line based on &lt;code&gt;delimiter&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f9f64f0d50dd16484e58d4ed060f0c9256c4cc4" translate="yes" xml:space="preserve">
          <source>A value &lt;code&gt;&amp;gt;=0&lt;/code&gt; means use the index (starting at zero) of the split line based on &lt;code&gt;delimiter&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5179a7550ff1f415a01835382e7a60083b1558e3" translate="yes" xml:space="preserve">
          <source>A value &lt;code&gt;pos_weight &amp;gt; 1&lt;/code&gt; decreases the false negative count, hence increasing the recall. Conversely setting &lt;code&gt;pos_weight &amp;lt; 1&lt;/code&gt; decreases the false positive count and increases the precision. This can be seen from the fact that &lt;code&gt;pos_weight&lt;/code&gt; is introduced as a multiplicative coefficient for the positive labels term in the loss expression:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20474330e19c225a900d005aab4addd640131c03" translate="yes" xml:space="preserve">
          <source>A value mirrored to &lt;code&gt;destinations&lt;/code&gt; devices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31ec52271ef14871178b92e68a49a15b624b5e58" translate="yes" xml:space="preserve">
          <source>A value of &lt;code&gt;None&lt;/code&gt; or the empty string will reset the current name scope to the top-level (empty) name scope.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8aa1f8724d7e2f955a5123ece39f3b242c7372bd" translate="yes" xml:space="preserve">
          <source>A variable (including Keras metadata), filled with &lt;code&gt;0.0&lt;/code&gt;. Note that if &lt;code&gt;shape&lt;/code&gt; was symbolic, we cannot return a variable, and will return a dynamically-shaped tensor instead.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f04566cf65d18a0e101012ac7fd6fbd753836737" translate="yes" xml:space="preserve">
          <source>A variable instance (with Keras metadata included).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08c687b49c54d6c60351df00288887fadbd39e80" translate="yes" xml:space="preserve">
          <source>A variable maintains shared, persistent state manipulated by a program.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5559881367ed05cd096d5c36e64cb2c871b58d2c" translate="yes" xml:space="preserve">
          <source>A variable maintains state in the graph across calls to &lt;code&gt;run()&lt;/code&gt;. You add a variable to the graph by constructing an instance of the class &lt;code&gt;Variable&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb19880ba4b497fc394585c5a4e9e8a752635141" translate="yes" xml:space="preserve">
          <source>A variable that is initialized to the list of files matching the pattern(s).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="284465f58d143de2aea05e84b971f0bbd72c4491" translate="yes" xml:space="preserve">
          <source>A vector with the same dtype as &lt;code&gt;weights&lt;/code&gt; or the given &lt;code&gt;dtype&lt;/code&gt;. The bin values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5a120502b8bf572637e272814b64531d81fe181" translate="yes" xml:space="preserve">
          <source>A version of &lt;code&gt;opt&lt;/code&gt; that will use loss scaling to prevent underflow.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95e7f276d61cba1476266a59f6dcb104244e87ab" translate="yes" xml:space="preserve">
          <source>A visible &lt;a href=&quot;physicaldevice&quot;&gt;&lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt;&lt;/a&gt; will by default have a single &lt;a href=&quot;logicaldevice&quot;&gt;&lt;code&gt;tf.config.LogicalDevice&lt;/code&gt;&lt;/a&gt; associated with it once the runtime is initialized. Specifying a list of &lt;a href=&quot;logicaldeviceconfiguration&quot;&gt;&lt;code&gt;tf.config.LogicalDeviceConfiguration&lt;/code&gt;&lt;/a&gt; objects allows multiple devices to be created on the same &lt;a href=&quot;physicaldevice&quot;&gt;&lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d8d840db97faee8b1571a5cfe92db21fec3aaed" translate="yes" xml:space="preserve">
          <source>A wrapper for threading.Thread that supports start() and join() methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f035b087f9599d3bdda24c71b05a8c929a772519" translate="yes" xml:space="preserve">
          <source>A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber. Connectionist Temporal Classification: Labeling Unsegmented Sequence Data with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA, pp. 369-376.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="560f9846cdff3276e42508e0b2768ae223f6a54a" translate="yes" xml:space="preserve">
          <source>About Segmentation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="534254b93a2807a1bffcf11334f343717a5f46c4" translate="yes" xml:space="preserve">
          <source>Abstract base class used to build new callbacks.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb974d52c14b8aa3e85a2832e1405e796336176a" translate="yes" xml:space="preserve">
          <source>Abstract class for all implementations of ClusterResolvers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f7013a24f9618e6d8531ba27515ff2371a750bd" translate="yes" xml:space="preserve">
          <source>Abstract class that provides helpers for TensorFlow benchmarks.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a1afcdd6ce07f7f09230d5a30f9e7a9aaa2bfc52" translate="yes" xml:space="preserve">
          <source>Abstract object representing an RNN cell.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bca1b82521b7f8077878f9fe89ddb0f9c09bd06f" translate="yes" xml:space="preserve">
          <source>Abstract wrapper base class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07d5cca1112c7bc2e3a448ecc23813993375501f" translate="yes" xml:space="preserve">
          <source>Abstraction for a locally visible physical device.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eada8561eb80d50b2c5e1d6d027cc07f3617a7b5" translate="yes" xml:space="preserve">
          <source>Abstraction for a logical device initialized by the runtime.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8cec1abe318ec05d3fa170d4ed2072e5178a91e2" translate="yes" xml:space="preserve">
          <source>Accepted values are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ee554725bfe7467413bb393a3521eed74c2893d" translate="yes" xml:space="preserve">
          <source>Accumulates confusion matrix statistics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5407ad0e3fdb1b37ec1c4b9735265aad02b87fc3" translate="yes" xml:space="preserve">
          <source>Accumulates metric statistics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11286b7af88a426aa8f05ba5cd8670c94b3252d1" translate="yes" xml:space="preserve">
          <source>Accumulates root mean squared error statistics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f640357311244565a266edc22580a0583cecb552" translate="yes" xml:space="preserve">
          <source>Accumulates statistics for computing the element-wise mean.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85fbe16fa97c7251ec8add32fe4301be56f08aa9" translate="yes" xml:space="preserve">
          <source>Accumulates statistics for computing the reduction metric.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0bd3ce35be4592b61adffe3ebedb5e672ab154ca" translate="yes" xml:space="preserve">
          <source>Accumulates statistics for the metric.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f4838e94f1f8c26bf124661e0107af7bb1d1928" translate="yes" xml:space="preserve">
          <source>Accumulates the confusion matrix statistics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64795ac67108e0609977cc7f7b13009ebf9b407a" translate="yes" xml:space="preserve">
          <source>Accumulates the given confusion matrix condition statistics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e23cced094e8a041041f4c47228555eb73cd1f3" translate="yes" xml:space="preserve">
          <source>Accumulates true positive and false negative statistics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="376de5bb196d68b8a17bd368634d62fff575102d" translate="yes" xml:space="preserve">
          <source>Accumulates true positive and false positive statistics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b9f70e45c4873c4d0e5bffb06b2d43a9fc48785f" translate="yes" xml:space="preserve">
          <source>Accumulator's internal time step is incremented by 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3cdc87c18c605690a5bf7eed7f75899134712fa" translate="yes" xml:space="preserve">
          <source>Activation function denoted by input:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dbe0768026cbe061827ae27fb07d76c06d6523aa" translate="yes" xml:space="preserve">
          <source>Activation histograms</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c02d8af2bc4077375e31eaf6345ccfeb33617f3a" translate="yes" xml:space="preserve">
          <source>Adadelta is a more robust extension of Adagrad that adapts learning rates based on a moving window of gradient updates, instead of accumulating all past gradients. This way, Adadelta continues learning even when many updates have been done. Compared to Adagrad, in the original version of Adadelta you don't have to set an initial learning rate. In this version, initial learning rate can be set, as in most other Keras optimizers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="495c15194ed74f2a44529abb3800ce9dfd72c0f7" translate="yes" xml:space="preserve">
          <source>Adadelta optimization is a stochastic gradient descent method that is based on adaptive learning rate per dimension to address two drawbacks: 1) the continual decay of learning rates throughout training 2) the need for a manually selected global learning rate</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e5e662375aebd41d9a25bcb34815e6663536d17" translate="yes" xml:space="preserve">
          <source>Adagrad Dual Averaging algorithm for sparse linear models.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e404c0c77de6bae9d6825d5717a3546bc15fb26" translate="yes" xml:space="preserve">
          <source>Adagrad is an optimizer with parameter-specific learning rates, which are adapted relative to how frequently a parameter gets updated during training. The more updates a parameter receives, the smaller the updates.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee100335faaf8e8c56fd521c765995d513d09bb2" translate="yes" xml:space="preserve">
          <source>AdagradDA is typically used when there is a need for large sparsity in the trained model. This optimizer only guarantees sparsity for linear models. Be careful when using AdagradDA for deep networks as it will require careful initialization of the gradient accumulators for it to train.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbb814cb2070acc3a64514b6b0c1af10843f2414" translate="yes" xml:space="preserve">
          <source>Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments. According to the paper &lt;a href=&quot;http://arxiv.org/abs/1412.6980&quot;&gt;Adam: A Method for Stochastic Optimization. Kingma et al., 2014&lt;/a&gt;, the method is &quot;&lt;em&gt;computationally efficient, has little memory requirement, invariant to diagonal rescaling of gradients, and is well suited for problems that are large in terms of data/parameters&lt;/em&gt;&quot;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f944609a3798f05c4f189b12ee8120fa8a83d5c0" translate="yes" xml:space="preserve">
          <source>Add &lt;code&gt;use_resource=True&lt;/code&gt; when constructing &lt;a href=&quot;../../variable&quot;&gt;&lt;code&gt;tf.Variable&lt;/code&gt;&lt;/a&gt;;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1bbefa91baa10ee42a07515ce83bf9cf1c2d672" translate="yes" xml:space="preserve">
          <source>Add a function, with arguments, to be called when the test is completed. Functions added are called on a LIFO basis and are called after tearDown on test failure or success.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27f5ce3a072ac75eb0f5d649bdf0090efeeda50d" translate="yes" xml:space="preserve">
          <source>Add a new slot variable for &lt;code&gt;var&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f835c134ab160141fb0836adbcf048261854f16" translate="yes" xml:space="preserve">
          <source>Add a sequence of inputs to the function invocation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="896348df9f806ffcfa23cf38f5a78d6b72d68e0c" translate="yes" xml:space="preserve">
          <source>Add a sequence of outputs to the function invocation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6bad45d02179268577b0009b65f752398597ae4b" translate="yes" xml:space="preserve">
          <source>Add a type specific assertEqual style function to compare a type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="503958611b13d659211788579edc9eaabba22887" translate="yes" xml:space="preserve">
          <source>Add a wrapped input argument to the hint.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="986881c8690462695e25af8ba0bce3b1fa596eb0" translate="yes" xml:space="preserve">
          <source>Add a wrapped output argument to the hint.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7dae40dc19bca56aa28551611c5f37d8e88927e1" translate="yes" xml:space="preserve">
          <source>Add loss tensor(s), potentially dependent on layer inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cdb7c2a0417a97abec6fc1e6bd7390cb5d622207" translate="yes" xml:space="preserve">
          <source>Add matrix represented by this operator to &lt;code&gt;mat&lt;/code&gt;. Equiv to &lt;code&gt;I + mat&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d224fc44614b950dc18a257861f5357142595c0e" translate="yes" xml:space="preserve">
          <source>Add matrix represented by this operator to &lt;code&gt;x&lt;/code&gt;. Equivalent to &lt;code&gt;A + x&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="571dbeb38634309064f8079316e2b444ed6603a5" translate="yes" xml:space="preserve">
          <source>Add operations to minimize &lt;code&gt;loss&lt;/code&gt; by updating &lt;code&gt;var_list&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77522eb9295528ed081be4e3f76492ca5de4de81" translate="yes" xml:space="preserve">
          <source>Add statistics of a step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="768c7f1f3a53b085781b785a717f529c347bb9a1" translate="yes" xml:space="preserve">
          <source>Add update op(s), potentially dependent on layer inputs. (deprecated arguments)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76c381774ccf3bbed181351113b6878827234844" translate="yes" xml:space="preserve">
          <source>Adding a histogram summary makes it possible to visualize your data's distribution in TensorBoard. You can see a detailed explanation of the TensorBoard histogram dashboard &lt;a href=&quot;https://www.tensorflow.org/get_started/tensorboard_histograms&quot;&gt;here&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ee0580015b46aae5c686fa85e1b88d5dd362ad1" translate="yes" xml:space="preserve">
          <source>Additional APIs for algorithms that need to be distribution-aware.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8876306fe170f1a620f5853376736ab1aff7bed" translate="yes" xml:space="preserve">
          <source>Additional arguments to the inner &lt;code&gt;@tf.custom_gradient&lt;/code&gt;-decorated function control the expected return values of the innermost function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e4d8fc7bae357f0d659d502129a66ff0117f357" translate="yes" xml:space="preserve">
          <source>Additional documentation from &lt;code&gt;Bernoulli&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="013518549caeece5e09d88794a4d212b651d51c9" translate="yes" xml:space="preserve">
          <source>Additional documentation from &lt;code&gt;Beta&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c7b826359310e392dca6ea4f39a3c7f6d0f4245" translate="yes" xml:space="preserve">
          <source>Additional documentation from &lt;code&gt;Dirichlet&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5f8f4b1748488490aade28cf41d8bddfcf50dfc" translate="yes" xml:space="preserve">
          <source>Additional documentation from &lt;code&gt;DirichletMultinomial&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea5c8c5b770f26dc9aee62ed872b5e7fe45d6699" translate="yes" xml:space="preserve">
          <source>Additional documentation from &lt;code&gt;Gamma&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8ebc2b5f2f5872a39da4246ddc845b84ca3adcf" translate="yes" xml:space="preserve">
          <source>Additional documentation from &lt;code&gt;Multinomial&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="313e21df1cd7fecb2f3311c849e1b1c50db65ee9" translate="yes" xml:space="preserve">
          <source>Additional documentation from &lt;code&gt;StudentT&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8faaf5d50ab75d1f987bb48515862865601ca5ae" translate="yes" xml:space="preserve">
          <source>Additional ops that support &lt;code&gt;RaggedTensor&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c5f32132f2f094321e09d306752fbebdb662f44" translate="yes" xml:space="preserve">
          <source>Additionally both 'params' and 'indices' can have M leading batch dimensions that exactly match. In this case 'batch_dims' must be M.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c3c8e005ed39f29d3bc5e8389041b5fb7ca08da" translate="yes" xml:space="preserve">
          <source>Additionally, optional arguments to the &lt;code&gt;Saver()&lt;/code&gt; constructor let you control the proliferation of checkpoint files on disk:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="46070ac3af06d8eaabda7770c06bc32707c89afd" translate="yes" xml:space="preserve">
          <source>Additionally, to use tf.print in python 2.7, users must make sure to import the following:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ca033eecc7e597ae322c44d1403dbbe91d08de9" translate="yes" xml:space="preserve">
          <source>Additive attention layer, a.k.a. Bahdanau-style attention.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0a53adaecb64ed9ea31b1b668c3b16c1fe55b65" translate="yes" xml:space="preserve">
          <source>Adds &lt;a href=&quot;../../indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt; to this variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87bdc9b20652b24f556ad0dbcb067c6945774608" translate="yes" xml:space="preserve">
          <source>Adds &lt;a href=&quot;indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt; to this variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa41c01880f319c685418ded8c0ad86ce8271cf6" translate="yes" xml:space="preserve">
          <source>Adds &lt;code&gt;bias&lt;/code&gt; to &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7209116614f0cbe7cf149560cc1310421aa26109" translate="yes" xml:space="preserve">
          <source>Adds &lt;code&gt;offset_height&lt;/code&gt; rows of zeros on top, &lt;code&gt;offset_width&lt;/code&gt; columns of zeros on the left, and then pads the image on the bottom and right with zeros until it has dimensions &lt;code&gt;target_height&lt;/code&gt;, &lt;code&gt;target_width&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e284f099c4f4b090ef28357958487406e5683656" translate="yes" xml:space="preserve">
          <source>Adds a 1-sized dimension at index &quot;axis&quot;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f14fe9afded732c20f9b81e46bb82ad7a0e00afe" translate="yes" xml:space="preserve">
          <source>Adds a &lt;code&gt;Graph&lt;/code&gt; to the event file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd9ee8ae4840dee5fe707ae07d7f2d931265ee79" translate="yes" xml:space="preserve">
          <source>Adds a &lt;code&gt;MetaGraphDef&lt;/code&gt; to the event file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e26f46ea3502c0b395778b0330b414ffe7cbd840" translate="yes" xml:space="preserve">
          <source>Adds a &lt;code&gt;QueueRunner&lt;/code&gt; to a collection in the graph. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="000b07d4439893325e95274a186a526bd2e57e7e" translate="yes" xml:space="preserve">
          <source>Adds a &lt;code&gt;SessionLog&lt;/code&gt; protocol buffer to the event file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="912ee04a0f76568882219c537e84a44e8cf0e7f8" translate="yes" xml:space="preserve">
          <source>Adds a &lt;code&gt;Summary&lt;/code&gt; protocol buffer to the event file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47916f6bc035ab482379f6430dce6a2737019798" translate="yes" xml:space="preserve">
          <source>Adds a Huber Loss term to the training procedure.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="245750a497a074e7e445d9d05506801d1b143ffa" translate="yes" xml:space="preserve">
          <source>Adds a Log Loss term to the training procedure.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a6c34cd63cb4b86c767a864999495b6a29f37e80" translate="yes" xml:space="preserve">
          <source>Adds a Sum-of-Squares loss to the training procedure.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ada83e13d0ca9e56125923fe7ae71069d69fa5c6" translate="yes" xml:space="preserve">
          <source>Adds a bias vector to a tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69488804454a150ce21127ee37c3d11c5a7a3393" translate="yes" xml:space="preserve">
          <source>Adds a constraint to multiple flags.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cef435adbdaf83137a8ccd895d4705be326d3dcb" translate="yes" xml:space="preserve">
          <source>Adds a constraint, which will be enforced during program execution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38afdbb88a3b38b2b9c3a92c798198fca317e965" translate="yes" xml:space="preserve">
          <source>Adds a cosine-distance loss to the training procedure. (deprecated arguments)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38078590222683177e34b4d11f1db3e38496674e" translate="yes" xml:space="preserve">
          <source>Adds a externally defined loss to the collection of losses.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="642ef03783ec9bdc1f5ec0837e775b50be028311" translate="yes" xml:space="preserve">
          <source>Adds a hinge loss to the training procedure.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3a8719bfbd3c0e5a9494519330d075a230749f2" translate="yes" xml:space="preserve">
          <source>Adds a layer instance on top of the layer stack.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c79e2fd42736602ee213a96a44147e419b4d8ad" translate="yes" xml:space="preserve">
          <source>Adds a metadata information for a single session.run() call.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b512a2bd529bce0b2a58f4db576bf701a3d70f6" translate="yes" xml:space="preserve">
          <source>Adds a new variable to the layer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd6b07d5ce96466dab9830b24af74ed6d59f290d" translate="yes" xml:space="preserve">
          <source>Adds a pairwise-errors-squared loss to the training procedure.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df988889482d0d02d17844a3603d26d4204273a3" translate="yes" xml:space="preserve">
          <source>Adds a value to this variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a44e8f3eb13a1dd5f4510ac8665c5d7db5d75da" translate="yes" xml:space="preserve">
          <source>Adds all input tensors element-wise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66fb2f3ff91cff89535e2c95ed683e0ba90a2c20" translate="yes" xml:space="preserve">
          <source>Adds an Absolute Difference loss to the training procedure.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="535bdeb89b35e4133663de95fc459ab7625f23e3" translate="yes" xml:space="preserve">
          <source>Adds an event to the event file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b5382a03df3bbc98b990da715bff7c9464ed01a" translate="yes" xml:space="preserve">
          <source>Adds metric tensor to the layer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c033b52fdc7c69853df00236fd9f59537947047" translate="yes" xml:space="preserve">
          <source>Adds ops to list the names of uninitialized variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73a82ab7e83b53091a6fc4f1384f3fa160638aff" translate="yes" xml:space="preserve">
          <source>Adds potentially overlapping frames of a signal with shape &lt;code&gt;[..., frames, frame_length]&lt;/code&gt;, offsetting subsequent frames by &lt;code&gt;frame_step&lt;/code&gt;. The resulting tensor has shape &lt;code&gt;[..., output_size]&lt;/code&gt; where</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a61b807c14bd70a74b1fb22924565db1cba46186" translate="yes" xml:space="preserve">
          <source>Adds sparse &lt;code&gt;updates&lt;/code&gt; to an existing tensor according to &lt;code&gt;indices&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05ad660d368493b303fa01e0478b1a5bdf31bd6a" translate="yes" xml:space="preserve">
          <source>Adds sparse updates to the variable referenced by &lt;code&gt;resource&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="946099c5a0970353a5f47ea97a26647cb145223c" translate="yes" xml:space="preserve">
          <source>Adds state variable. Only for use by subclasses.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="530ce18fad38848fcaf86c3c18b10cfa42885ec7" translate="yes" xml:space="preserve">
          <source>Adds the current meta graph to the SavedModel and saves variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ae9c21babeb7e54be528ab849dc335a952e9a35" translate="yes" xml:space="preserve">
          <source>Adds the current meta graph to the SavedModel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d88b7522b1d9ef4de1fd81967adf1b252aa79012" translate="yes" xml:space="preserve">
          <source>Adds two tensors, at least one of each is a &lt;code&gt;SparseTensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c41e9522df4563906d1c5fb00e035d8e61238b30" translate="yes" xml:space="preserve">
          <source>Adds two tensors, at least one of each is a &lt;code&gt;SparseTensor&lt;/code&gt;. (deprecated arguments)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8179839e5e0e944908eb18f10d916b644e38ddb4" translate="yes" xml:space="preserve">
          <source>Adjust contrast of RGB or grayscale images.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67ee8e6b0752a8f09b3af8dd754fa1778491dd19" translate="yes" xml:space="preserve">
          <source>Adjust hue of RGB images.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="912d489a224a66e7a2eec677e95202b3b517f202" translate="yes" xml:space="preserve">
          <source>Adjust jpeg encoding quality of an image.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="33093373c09037124fb6847970525d44a463a705" translate="yes" xml:space="preserve">
          <source>Adjust saturation of RGB images.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b30f2a99a8f5cfdb812422f6f9ffcffb1280114" translate="yes" xml:space="preserve">
          <source>Adjust the brightness of RGB or Grayscale images.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="687dfc87459ac15d5131ecfa13d9c945b01f18f1" translate="yes" xml:space="preserve">
          <source>Adjust the brightness of images by a random factor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="505b87a4a5c672e9b0f356a6e48a3c4d746d10bc" translate="yes" xml:space="preserve">
          <source>Adjust the contrast of an image or images by a random factor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a160ff429bff3740312b1a2591b6c4f875c7196" translate="yes" xml:space="preserve">
          <source>Adjust the hue of RGB images by a random factor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c321ea8d8f7d3931280d0bac17223f44c2d106cc" translate="yes" xml:space="preserve">
          <source>Adjust the saturation of RGB images by a random factor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21fb2eec35680f57fd2d22fab7ba4a9a9b52f99a" translate="yes" xml:space="preserve">
          <source>Adjusted image(s), same shape and DType as &lt;code&gt;image&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b9d0f530eed20cc11e120bface7d953e4a8ce208" translate="yes" xml:space="preserve">
          <source>Adjusted image, same shape and DType as &lt;code&gt;image&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc1859823fba4b44ff08372e3a87536b2d326e3a" translate="yes" xml:space="preserve">
          <source>Advance the counter of a counter-based RNG.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44abf3846c1f88dea20adb7b0cad7f7feb20c65d" translate="yes" xml:space="preserve">
          <source>Advanced usage. Note the following optimization: A sequence of &lt;code&gt;atrous_conv2d&lt;/code&gt; operations with identical &lt;code&gt;rate&lt;/code&gt; parameters, 'SAME' &lt;code&gt;padding&lt;/code&gt;, and filters with odd heights/ widths:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e1b9a638e0422548369e77bf7054e34f6289429" translate="yes" xml:space="preserve">
          <source>Advanced usage. Note the following optimization: A sequence of &lt;code&gt;with_space_to_batch&lt;/code&gt; operations with identical (not uniformly 1) &lt;code&gt;dilation_rate&lt;/code&gt; parameters and &quot;VALID&quot; padding</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0025c9a9e44d8dcfbb71138c2fcd282e5c239d3d" translate="yes" xml:space="preserve">
          <source>Advanced use</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="125446c6bb8a159d3d54ce09c49793cf98cc0921" translate="yes" xml:space="preserve">
          <source>Adversarial example using FGSM</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ce6a191dda9535f2d186119119d95c0b5283611" translate="yes" xml:space="preserve">
          <source>Adversarial training, where no backprop should happen through the adversarial example generation process.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a93b37c5d6acaf1efef36fa9b8a03862ed7cbfa" translate="yes" xml:space="preserve">
          <source>After 'with_accounted_types' is evaluated, 'with_node_names' are evaluated as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2603f9af82b54e116fb4b3bcd4ecd7636baf7486" translate="yes" xml:space="preserve">
          <source>After a thread has called &lt;code&gt;coord.request_stop()&lt;/code&gt; the other threads have a fixed time to stop, this is called the 'stop grace period' and defaults to 2 minutes. If any of the threads is still alive after the grace period expires &lt;code&gt;coord.join()&lt;/code&gt; raises a RuntimeError reporting the laggards.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0f0857e46947b9245d3bb7d0312de77bd47e0d3" translate="yes" xml:space="preserve">
          <source>After calling &lt;code&gt;g.finalize()&lt;/code&gt;, no new operations can be added to &lt;code&gt;g&lt;/code&gt;. This method is used to ensure that no operations are added to a graph when it is shared between multiple threads, for example when using a &lt;a href=&quot;compat/v1/train/queuerunner&quot;&gt;&lt;code&gt;tf.compat.v1.train.QueueRunner&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="272aff3ac083cc6e2a3d7c1d612ca3af2647d4fb" translate="yes" xml:space="preserve">
          <source>After calling this function, the module will not be able to define any more flags. This function will affect all FlagValues objects.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67d8801a9c3bd2eda0073f46196273518155924d" translate="yes" xml:space="preserve">
          <source>After constructing an &lt;code&gt;Options&lt;/code&gt; object, use &lt;code&gt;dataset.with_options(options)&lt;/code&gt; to apply the options to a dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd768800e7344acdcbbc3c5e65256a889f683762" translate="yes" xml:space="preserve">
          <source>After pushing all the gradients, dequeue an updated value of global_step from the token queue and record that step to its local_step variable. Note that this is effectively a barrier.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f07d9bb4cec6913d548250c277d215c0056dfcd" translate="yes" xml:space="preserve">
          <source>After the graph has been launched in a session, the value of the &lt;code&gt;Tensor&lt;/code&gt; can be computed by passing it to &lt;code&gt;tf.Session.run&lt;/code&gt;. &lt;code&gt;t.eval()&lt;/code&gt; is a shortcut for calling &lt;code&gt;tf.compat.v1.get_default_session().run(t)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f0fd29915b432f5b87543cc76189b97279a3fdd" translate="yes" xml:space="preserve">
          <source>After the threads stop, if an &lt;code&gt;exc_info&lt;/code&gt; was passed to &lt;code&gt;request_stop&lt;/code&gt;, that exception is re-raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de06603d8326b25dbe0208c6d8d5b853215e3be8" translate="yes" xml:space="preserve">
          <source>After this is called, calls to &lt;code&gt;should_stop()&lt;/code&gt; will return &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f293c3dd3a23d1f8752d75cdac0e97259f5e1cc3" translate="yes" xml:space="preserve">
          <source>After this is called, calls to &lt;code&gt;should_stop()&lt;/code&gt; will return &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1fb6d3658738279297e3de73a15c600b0eb4771" translate="yes" xml:space="preserve">
          <source>After this is called, the mixed precision graph rewrite will no longer run for new Sessions, and so float32 operations will no longer be converted to float16 in such Sessions. However, any existing Sessions will continue to have the graph rewrite enabled if they were created after &lt;code&gt;enable_mixed_precision_graph_rewrite&lt;/code&gt; was called but before &lt;code&gt;disable_mixed_precision_graph_rewrite&lt;/code&gt; was called.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f905230bdf203f6a31eb04f33a87b12b57bec3d2" translate="yes" xml:space="preserve">
          <source>After this is called, the mixed precision graph rewrite will no longer run for tf.functions, and so float32 operations will no longer be converted to float16.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6afafd003db87977db57e243fb007fa08d5a1352" translate="yes" xml:space="preserve">
          <source>After this method is called, the stacks become thread-local. If multiple threads access them, then the state is not shared. Each thread uses its own value; a thread doesn't affect other threads by mutating such a stack.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7e8914a1950e9a30eff2da7f6534fad0c7fb945" translate="yes" xml:space="preserve">
          <source>After you launch the graph in a session, you can run the returned Op to initialize all the variables in &lt;code&gt;var_list&lt;/code&gt;. This Op runs all the initializers of the variables in &lt;code&gt;var_list&lt;/code&gt; in parallel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb10cbe354b6f5ab581b5de57dc2bdb3552565ed" translate="yes" xml:space="preserve">
          <source>Aggregated gradient is reset to 0 tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe5870f6b60f68e7f5635eb973e99c5b3cf9a5ee" translate="yes" xml:space="preserve">
          <source>Alias of &lt;a href=&quot;../../variable#shape&quot;&gt;&lt;code&gt;Variable.shape&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42b25b787422785bd42f094029e48c42d44d8328" translate="yes" xml:space="preserve">
          <source>Alias of &lt;a href=&quot;variable#shape&quot;&gt;&lt;code&gt;Variable.shape&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f35c60274d30c8558e149b4d78e3d7b3adda1ef2" translate="yes" xml:space="preserve">
          <source>Alias of &lt;code&gt;self.weights&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4eb3cdceebb08de5135751c98d1269b45aa7be8c" translate="yes" xml:space="preserve">
          <source>Alias of Tensor.shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="860fceee324843e1d663275cb79b62a5ee925a2a" translate="yes" xml:space="preserve">
          <source>All &lt;a href=&quot;module&quot;&gt;&lt;code&gt;tf.Module&lt;/code&gt;&lt;/a&gt; classes have an associated &lt;a href=&quot;name_scope&quot;&gt;&lt;code&gt;tf.name_scope&lt;/code&gt;&lt;/a&gt; which can be used to group operations in TensorBoard and create hierarchies for variable names which can help with debugging. We suggest using the name scope when creating nested submodules/parameters or for forward methods whose graph you might want to inspect in TensorBoard. You can enter the name scope explicitly using &lt;code&gt;with self.name_scope:&lt;/code&gt; or you can annotate methods (apart from &lt;code&gt;__init__&lt;/code&gt;) with &lt;code&gt;@tf.Module.with_name_scope&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9316e47f4c6b3d67e889a7e10936424b53a3a429" translate="yes" xml:space="preserve">
          <source>All &lt;code&gt;Operation&lt;/code&gt;s constructed during &lt;code&gt;computation&lt;/code&gt; will be executed when evaluating any of the returned output tensors, not just the ones returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1bec5cc467ca91782a24df96e9f17c27c0abb72f" translate="yes" xml:space="preserve">
          <source>All &lt;code&gt;Operation&lt;/code&gt;s returned from &lt;code&gt;computation&lt;/code&gt; will be executed when evaluating any of the returned output tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4229c13f5303070e61475535ac3ddb8478b06d8" translate="yes" xml:space="preserve">
          <source>All &lt;code&gt;feature_columns&lt;/code&gt; must be sequence dense columns with the same &lt;code&gt;sequence_length&lt;/code&gt;. The output of this method can be fed into sequence networks, such as RNN.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b492b243c955d3154bec47504e35f2e9e599edd9" translate="yes" xml:space="preserve">
          <source>All &lt;code&gt;num_mel_bins&lt;/code&gt; MFCCs are returned and it is up to the caller to select a subset of the MFCCs based on their application. For example, it is typical to only use the first few for speech recognition, as this results in an approximately pitch-invariant representation of the signal.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4cf690b42404e1463efa7ece602e5b66590bae88" translate="yes" xml:space="preserve">
          <source>All Keras optimizers respect variable constraints. If constraint function is passed to any variable, the constraint will be applied to the variable after the gradient has been applied to the variable. Important: If gradient is sparse tensor, variable constraint is not supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0cd768c65748ed04c61a8e8ef017367828ab2ca" translate="yes" xml:space="preserve">
          <source>All arguments in &lt;code&gt;args&lt;/code&gt; or &lt;code&gt;kwargs&lt;/code&gt; should either be nest of tensors or per-replica objects containing tensors or composite tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ba97a6bcb121c3bf2f691e31d187741f2d898d4" translate="yes" xml:space="preserve">
          <source>All but the last dimension of &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; must match.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11c241e13e7f5be6979ab0c57086ee56ad635279" translate="yes" xml:space="preserve">
          <source>All distributed training related properties &lt;code&gt;cluster_spec&lt;/code&gt;, &lt;code&gt;is_chief&lt;/code&gt;, &lt;code&gt;master&lt;/code&gt; , &lt;code&gt;num_worker_replicas&lt;/code&gt;, &lt;code&gt;num_ps_replicas&lt;/code&gt;, &lt;code&gt;task_id&lt;/code&gt;, and &lt;code&gt;task_type&lt;/code&gt; are set based on the &lt;code&gt;TF_CONFIG&lt;/code&gt; environment variable, if the pertinent information is present. The &lt;code&gt;TF_CONFIG&lt;/code&gt; environment variable is a JSON object with attributes: &lt;code&gt;cluster&lt;/code&gt; and &lt;code&gt;task&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="151dc3e0fc3056d3746ca213a5d98347b09e201c" translate="yes" xml:space="preserve">
          <source>All distributions support batches of independent distributions of that type. The batch shape is determined by broadcasting together the parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43368f6d5cf5d389bdf38ca4fcdf4f8239f92855" translate="yes" xml:space="preserve">
          <source>All global ids in the training cluster are assigned from an increasing sequence of consecutive integers. The first id is 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71f2e3a10bfbb8489a04f757a5652d39c5cbdd79" translate="yes" xml:space="preserve">
          <source>All integer tensors are considered constant with respect to all &lt;code&gt;xs&lt;/code&gt;, as if they were included in &lt;code&gt;stop_gradients&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="326372f6d85acb8c360d09752657c813b534d089" translate="yes" xml:space="preserve">
          <source>All layers (including custom layers) expose &lt;code&gt;activity_regularizer&lt;/code&gt; as a settable property, whether or not it is in the constructor arguments.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="686f848076366f3f8a1187aba2985da4bb7b6346" translate="yes" xml:space="preserve">
          <source>All of selected values must have been written and their shapes must all match.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02c6c2afd0abe5c32ee6da67959c828b98470fd3" translate="yes" xml:space="preserve">
          <source>All of the serialized &lt;code&gt;SparseTensor&lt;/code&gt;s must have had the same rank and type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1064c69e05089a2983aae39c8eb3856b4811c035" translate="yes" xml:space="preserve">
          <source>All of the values must have been written and their shapes must all match. If input shapes have rank-&lt;code&gt;R&lt;/code&gt;, then output shape will have rank-&lt;code&gt;(R+1)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ce56c871aa24feffb446c926f5d6269ab87e07f" translate="yes" xml:space="preserve">
          <source>All of the values must have been written, their ranks must match, and and their shapes must all match for all dimensions except the first.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03d7b01fd3d453c4089ae3638bfe76ca9f7a641a" translate="yes" xml:space="preserve">
          <source>All other functionality is identical.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3d97e5193872bfe2db5f33810191f9245cf1cec" translate="yes" xml:space="preserve">
          <source>All other values in &lt;code&gt;dense&lt;/code&gt; are set to &lt;code&gt;default_value&lt;/code&gt;. If &lt;code&gt;sparse_values&lt;/code&gt; is a scalar, all sparse indices are set to this single value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e55be47273e113a66fde174bbb490675a8a2ad19" translate="yes" xml:space="preserve">
          <source>All outputs (checkpoints, event files, etc.) are written to &lt;code&gt;model_dir&lt;/code&gt;, or a subdirectory thereof. If &lt;code&gt;model_dir&lt;/code&gt; is not set, a temporary directory is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca3982e9a11df3d8782f0eb81e410604836945d9" translate="yes" xml:space="preserve">
          <source>All public utility methods for exporting Estimator to SavedModel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75029d9916c74e5a247c9e96e00323a1458079fd" translate="yes" xml:space="preserve">
          <source>All resource objects, including the critical section and any captured variables of functions executed on that critical section, will be colocated to the same device (host and cpu/gpu).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9505aee4fb57ebe7e45f4724f3c4cffc1058fb9" translate="yes" xml:space="preserve">
          <source>All scalar values in &lt;code&gt;pylist&lt;/code&gt; must have the same nesting depth &lt;code&gt;K&lt;/code&gt;, and the returned &lt;code&gt;RaggedTensor&lt;/code&gt; will have rank &lt;code&gt;K&lt;/code&gt;. If &lt;code&gt;pylist&lt;/code&gt; contains no scalar values, then &lt;code&gt;K&lt;/code&gt; is one greater than the maximum depth of empty lists in &lt;code&gt;pylist&lt;/code&gt;. All scalar values in &lt;code&gt;pylist&lt;/code&gt; must be compatible with &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b88d92b0bba244e2ef7c401fdbc669617b1bba75" translate="yes" xml:space="preserve">
          <source>All scalar values in &lt;code&gt;pylist&lt;/code&gt; must have the same nesting depth &lt;code&gt;K&lt;/code&gt;, and the returned &lt;code&gt;RaggedTensorValue&lt;/code&gt; will have rank &lt;code&gt;K&lt;/code&gt;. If &lt;code&gt;pylist&lt;/code&gt; contains no scalar values, then &lt;code&gt;K&lt;/code&gt; is one greater than the maximum depth of empty lists in &lt;code&gt;pylist&lt;/code&gt;. All scalar values in &lt;code&gt;pylist&lt;/code&gt; must be compatible with &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4a39b40cc6d6fba97201d96cd14f59e8e89025b" translate="yes" xml:space="preserve">
          <source>All symbols in TensorFlow 2</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f088619cc06be24913b97623eb5a57fd674a5da" translate="yes" xml:space="preserve">
          <source>All tf.layers and tf RNN cells created after keras style ha been enabled use Keras-style variable management. Creating such layers with a scope= argument is disallowed, and reuse=True is disallowed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c828b3fbcdbd36de429223ab445185761ab3133a" translate="yes" xml:space="preserve">
          <source>All tf.layers and tf RNN cells created in this scope use Keras-style variable management. Creating such layers with a scope= argument is disallowed, and reuse=True is disallowed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee59ffbafaa0e9f724a021fa9b28b13343f7321d" translate="yes" xml:space="preserve">
          <source>All the tensors in the TensorArray concatenated into one tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="188388ed41207d5bac424f993694edc1ba6629f5" translate="yes" xml:space="preserve">
          <source>All the tensors in the TensorArray stacked into one tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf29e0a9dd885d39527c1ed8753d1cef5bab2353" translate="yes" xml:space="preserve">
          <source>All unassigned values of &lt;code&gt;adjusted_dilation_rate&lt;/code&gt; default to 1, while all unassigned values of &lt;code&gt;adjusted_paddings&lt;/code&gt; and &lt;code&gt;adjusted_crops&lt;/code&gt; default to 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="405d42f9c15353167f99a86c3fbbca1b4448c465" translate="yes" xml:space="preserve">
          <source>All unparsed arguments are returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e9f4a454cdb2cfd3112305cec97a77162ffca24" translate="yes" xml:space="preserve">
          <source>All variables are automatically collected in the graph where they are created. By default, the constructor adds the new variable to the graph collection &lt;code&gt;GraphKeys.GLOBAL_VARIABLES&lt;/code&gt;. The convenience function &lt;code&gt;global_variables()&lt;/code&gt; returns the contents of that collection.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55e7f302e1eee9efd619680696e10cd342594c23" translate="yes" xml:space="preserve">
          <source>All-reduces the given &lt;code&gt;value Tensor&lt;/code&gt; nest across replicas.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53e67e9de1ed24ac56b01d140187d6e8a7c6873a" translate="yes" xml:space="preserve">
          <source>Allows filtering traceback information by removing superfluous frames.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ae6f34aaf13ce4cab096719a6578118e9614dce" translate="yes" xml:space="preserve">
          <source>Allows remapping traceback information to different source code.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2a84af38c84d741cee32dc4a7d4e6a095178a42" translate="yes" xml:space="preserve">
          <source>Along each axis &lt;code&gt;IRFFT2D&lt;/code&gt; is computed on, if &lt;code&gt;fft_length&lt;/code&gt; (or &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; for the inner-most dimension) is smaller than the corresponding dimension of &lt;code&gt;input&lt;/code&gt;, the dimension is cropped. If it is larger, the dimension is padded with zeros.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e0bf23368948de13dd5ec4765563ee76839e175" translate="yes" xml:space="preserve">
          <source>Along each axis &lt;code&gt;IRFFT3D&lt;/code&gt; is computed on, if &lt;code&gt;fft_length&lt;/code&gt; (or &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; for the inner-most dimension) is smaller than the corresponding dimension of &lt;code&gt;input&lt;/code&gt;, the dimension is cropped. If it is larger, the dimension is padded with zeros.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e05a36512a089730f2a63589ca725a93d00534bc" translate="yes" xml:space="preserve">
          <source>Along each axis &lt;code&gt;RFFT2D&lt;/code&gt; is computed on, if &lt;code&gt;fft_length&lt;/code&gt; is smaller than the corresponding dimension of &lt;code&gt;input&lt;/code&gt;, the dimension is cropped. If it is larger, the dimension is padded with zeros.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68cae9aefa991315781a8f07154c3fe1670f1a90" translate="yes" xml:space="preserve">
          <source>Along each axis &lt;code&gt;RFFT3D&lt;/code&gt; is computed on, if &lt;code&gt;fft_length&lt;/code&gt; is smaller than the corresponding dimension of &lt;code&gt;input&lt;/code&gt;, the dimension is cropped. If it is larger, the dimension is padded with zeros.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d4c748316899c86ee2553f6d589ce2c123e4b5c" translate="yes" xml:space="preserve">
          <source>Along the axis &lt;code&gt;IRFFT&lt;/code&gt; is computed on, if &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; is smaller than the corresponding dimension of &lt;code&gt;input&lt;/code&gt;, the dimension is cropped. If it is larger, the dimension is padded with zeros.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b470a5318854cf217862f0c374c65e48fe419621" translate="yes" xml:space="preserve">
          <source>Along the axis &lt;code&gt;RFFT&lt;/code&gt; is computed on, if &lt;code&gt;fft_length&lt;/code&gt; is smaller than the corresponding dimension of &lt;code&gt;input&lt;/code&gt;, the dimension is cropped. If it is larger, the dimension is padded with zeros.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4f077ef5e9cf80f8dc7c6c00b8923dd70d0284d" translate="yes" xml:space="preserve">
          <source>Alpha Dropout is a &lt;code&gt;Dropout&lt;/code&gt; that keeps mean and variance of inputs to their original values, in order to ensure the self-normalizing property even after this dropout. Alpha Dropout fits well to Scaled Exponential Linear Units by randomly setting activations to the negative saturation value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f7e1338e11a188966f23f773488d4abb1440db2" translate="yes" xml:space="preserve">
          <source>Also called at the beginning of a validation batch in the &lt;code&gt;fit&lt;/code&gt; methods, if validation data is provided.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51f6996ff038ec74ea0c5054e8450079c12475e7" translate="yes" xml:space="preserve">
          <source>Also called at the end of a validation batch in the &lt;code&gt;fit&lt;/code&gt; methods, if validation data is provided.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be821c918d08aadd876f7afef612e08569dc9007" translate="yes" xml:space="preserve">
          <source>Also known as Power Law Transform. This function converts the input images at first to float representation, then transforms them pixelwise according to the equation &lt;code&gt;Out = gain * In**gamma&lt;/code&gt;, and then converts the back to the original data type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="345174ccd05e61bec2eeb263bca3443b7c5624bc" translate="yes" xml:space="preserve">
          <source>Also note that though execution of ops created under this scope will trigger execution of the dependencies, the ops created under this scope might still be pruned from a normal tensorflow graph. For example, in the following snippet of code the dependencies are never executed:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47ca6ceecb1d73f8d2ad931a7fac873e524078a7" translate="yes" xml:space="preserve">
          <source>Also see &lt;a href=&quot;https://www.tensorflow.org/deploy/distributed&quot;&gt;Distributed TensorFlow&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="afb89484adc531756916d1215da5390894249cbf" translate="yes" xml:space="preserve">
          <source>Also see Section 3 of &lt;a href=&quot;http://arxiv.org/abs/1412.2007&quot;&gt;Jean et al., 2014&lt;/a&gt; (&lt;a href=&quot;http://arxiv.org/pdf/1412.2007.pdf&quot;&gt;pdf&lt;/a&gt;) for the math.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf455fda1a28df4785028df137d0161449674942" translate="yes" xml:space="preserve">
          <source>Also see: &lt;a href=&quot;../../../autograph/to_code&quot;&gt;&lt;code&gt;tf.autograph.to_code&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e627bc29f87e7433e59e006bb23121673f7abf6c" translate="yes" xml:space="preserve">
          <source>Also see: &lt;a href=&quot;../../../autograph/to_graph&quot;&gt;&lt;code&gt;tf.autograph.to_graph&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41ff443c26081c9ef2efbe34635a67c33b1f9588" translate="yes" xml:space="preserve">
          <source>Also see: &lt;a href=&quot;to_code&quot;&gt;&lt;code&gt;tf.autograph.to_code&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ccec37df81f013fff5cc0d1ea1f2c9aa07a536b" translate="yes" xml:space="preserve">
          <source>Also see: &lt;a href=&quot;to_graph&quot;&gt;&lt;code&gt;tf.autograph.to_graph&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55083b84203e837eea4c55f59d317afe3a6455ae" translate="yes" xml:space="preserve">
          <source>Also supports &lt;code&gt;logits&lt;/code&gt; as a &lt;code&gt;Tensor&lt;/code&gt; of shape &lt;code&gt;[D0, D1, ... DN, logits_dimension]&lt;/code&gt;. It will split the &lt;code&gt;Tensor&lt;/code&gt; along the last dimension and distribute it appropriately among the heads. E.g.:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c74fc81eb69c6cd4e94f60d88e08733b99efce1" translate="yes" xml:space="preserve">
          <source>Also supports custom &lt;code&gt;inverse_link_fn&lt;/code&gt;, also known as 'mean function'. &lt;code&gt;inverse_link_fn&lt;/code&gt; is only used in &lt;code&gt;PREDICT&lt;/code&gt; mode. It takes &lt;code&gt;logits&lt;/code&gt; as argument and returns predicted values. This function is the inverse of the link function defined in https://en.wikipedia.org/wiki/Generalized_linear_model#Link_function Namely, for poisson regression, set &lt;code&gt;inverse_link_fn=tf.exp&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e6ec10a757f42976b5b022793e8a9bf6c55c540" translate="yes" xml:space="preserve">
          <source>Also supports custom &lt;code&gt;loss_fn&lt;/code&gt;. &lt;code&gt;loss_fn&lt;/code&gt; takes &lt;code&gt;(labels, logits)&lt;/code&gt; or &lt;code&gt;(labels, logits, features)&lt;/code&gt; as arguments and returns unreduced loss with shape &lt;code&gt;[D0, D1, ... DN, 1]&lt;/code&gt;. &lt;code&gt;loss_fn&lt;/code&gt; must support indicator &lt;code&gt;labels&lt;/code&gt; with shape &lt;code&gt;[D0, D1, ... DN, n_classes]&lt;/code&gt;. Namely, the head applies &lt;code&gt;label_vocabulary&lt;/code&gt; to the input labels before passing them to &lt;code&gt;loss_fn&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b9a1b98ca81b5f230bc6220bdd853573ebea8eb6" translate="yes" xml:space="preserve">
          <source>Also supports custom &lt;code&gt;loss_fn&lt;/code&gt;. &lt;code&gt;loss_fn&lt;/code&gt; takes &lt;code&gt;(labels, logits)&lt;/code&gt; or &lt;code&gt;(labels, logits, features, loss_reduction)&lt;/code&gt; as arguments and returns loss with shape &lt;code&gt;[D0, D1, ... DN, 1]&lt;/code&gt;. &lt;code&gt;loss_fn&lt;/code&gt; must support float &lt;code&gt;labels&lt;/code&gt; with shape &lt;code&gt;[D0, D1, ... DN, 1]&lt;/code&gt;. Namely, the head applies &lt;code&gt;label_vocabulary&lt;/code&gt; to the input labels before passing them to &lt;code&gt;loss_fn&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45dcee7255222ebd9f920e232812d0aa92ae578a" translate="yes" xml:space="preserve">
          <source>Also supports custom &lt;code&gt;loss_fn&lt;/code&gt;. &lt;code&gt;loss_fn&lt;/code&gt; takes &lt;code&gt;(labels, logits)&lt;/code&gt; or &lt;code&gt;(labels, logits, features, loss_reduction)&lt;/code&gt; as arguments and returns unreduced loss with shape &lt;code&gt;[D0, D1, ... DN, 1]&lt;/code&gt;. &lt;code&gt;loss_fn&lt;/code&gt; must support integer &lt;code&gt;labels&lt;/code&gt; with shape &lt;code&gt;[D0, D1, ... DN, 1]&lt;/code&gt;. Namely, the head applies &lt;code&gt;label_vocabulary&lt;/code&gt; to the input labels before passing them to &lt;code&gt;loss_fn&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="229d59e4e5de0786238f4ee378a6e5d838739fd8" translate="yes" xml:space="preserve">
          <source>Also works from TensorFlow to Theano.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ca131a2cb96a6fb5d4e8a759fd3d98663b3905d" translate="yes" xml:space="preserve">
          <source>Also, only &lt;code&gt;padding=&quot;valid&quot;&lt;/code&gt; is supported by &lt;code&gt;implementation=1&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="816e5b2950b25183f72357a8c81052b932a21951" translate="yes" xml:space="preserve">
          <source>Also, the reference object provides &lt;code&gt;.deref()&lt;/code&gt; function that returns the original Tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="885ead26c4dbe77c427e2ca10421db15308f26e4" translate="yes" xml:space="preserve">
          <source>Also, the reference object provides &lt;code&gt;.deref()&lt;/code&gt; function that returns the original Variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d831aa0ba91ae06a94691f6a864e0ae634faf06" translate="yes" xml:space="preserve">
          <source>Alternative Row-Partitioning Schemes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db75295eeb1aa5e6d16107392674384bd1435305" translate="yes" xml:space="preserve">
          <source>Alternatively, for non-vector, multivariate distributions (e.g., matrix-valued, Wishart), &lt;code&gt;Covariance&lt;/code&gt; shall return a (batch of) matrices under some vectorization of the events, i.e.,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="093c4381e3b92a988e092913003ea054b0c4478f" translate="yes" xml:space="preserve">
          <source>Alternatively, model_fn can just populate the arguments appropriate to the given mode. Example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="509bf597db50d3afc9ea5f794becdd1b0326c7f0" translate="yes" xml:space="preserve">
          <source>Alternatively, the policy can be passed to individual layers instead of setting the global policy with &lt;code&gt;set_policy&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87d3758ef894a685be85daf69f35213788ada647" translate="yes" xml:space="preserve">
          <source>Alternatively, you can use &lt;code&gt;with tf.compat.v1.Session():&lt;/code&gt; to create a session that is automatically closed on exiting the context, including when an uncaught exception is raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ce15dd05d71388a6eada06003ba2c376587397a" translate="yes" xml:space="preserve">
          <source>Alternatively, you can write your custom regularizers in an object-oriented way by extending this regularizer base class, e.g.:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad30d068a42d4185df8aea042fc32e515c07581f" translate="yes" xml:space="preserve">
          <source>Although Saver works in some cases when executing eagerly, it is fragile. Please switch to &lt;a href=&quot;../../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../../keras/model#save_weights&quot;&gt;&lt;code&gt;tf.keras.Model.save_weights&lt;/code&gt;&lt;/a&gt;, which perform a more robust object-based saving. These APIs will load checkpoints written by &lt;code&gt;Saver&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29c4ffe6610a4e43395ea387547b03b3bea8a3d3" translate="yes" xml:space="preserve">
          <source>Although identical for even-length x, the functions differ by one sample for odd-length x.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2acf78fcd897b7eb3e995f446fa4ba67865bbee" translate="yes" xml:space="preserve">
          <source>Although in many cases it's not necessary to understand all of the many ways to configure a SavedModel, this method has a few practical implications: - It will be treated as a graph for inference / serving (i.e. uses the tag &lt;a href=&quot;../../../saved_model#SERVING&quot;&gt;&lt;code&gt;saved_model.SERVING&lt;/code&gt;&lt;/a&gt;) - The SavedModel will load in TensorFlow Serving and supports the &lt;a href=&quot;https://github.com/tensorflow/serving/blob/master/tensorflow_serving/apis/predict.proto&quot;&gt;Predict API&lt;/a&gt;. To use the Classify, Regress, or MultiInference APIs, please use either &lt;a href=&quot;../../../estimator/estimator&quot;&gt;tf.Estimator&lt;/a&gt; or the lower level &lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/README.md&quot;&gt;SavedModel APIs&lt;/a&gt;. - Some TensorFlow ops depend on information on disk or other information called &quot;assets&quot;. These are generally handled automatically by adding the assets to the &lt;code&gt;GraphKeys.ASSET_FILEPATHS&lt;/code&gt; collection. Only assets in that collection are exported; if you need more custom behavior, you'll need to use the &lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/builder.py&quot;&gt;SavedModelBuilder&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a26befe8cdbf51a55a23e4d87f4a0c47d25065aa" translate="yes" xml:space="preserve">
          <source>Although this behavior is consistent with the dataflow model of TensorFlow, it has frequently surprised users who expected a lazier semantics. Consider the following simple program:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf01ed5c94d8b0c457fb606bfae47e1f2e6ea0b7" translate="yes" xml:space="preserve">
          <source>Always do reduction to one device first and then do broadcasting.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac4e1157f4ec2373c62b7258a3354deb626cb10b" translate="yes" xml:space="preserve">
          <source>Among others, this operation is useful for reducing atrous convolution into regular convolution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2154ba4b1732a47caec2a23ab72bdcab507344ca" translate="yes" xml:space="preserve">
          <source>An &quot;input signature&quot; can be optionally provided to &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; to control the graphs traced. The input signature specifies the shape and type of each Tensor argument to the function using a &lt;a href=&quot;tensorspec&quot;&gt;&lt;code&gt;tf.TensorSpec&lt;/code&gt;&lt;/a&gt; object. More general shapes can be used. This is useful to avoid creating multiple graphs when Tensors have dynamic shapes. It also restricts the dhape and datatype of Tensors that can be used:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0d21a2ea2a87d6f097e4a6ec2793de44a7f715a" translate="yes" xml:space="preserve">
          <source>An 1-D &lt;code&gt;Tensor&lt;/code&gt; of type &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="703bca512b95b38c57ea4c42801124f6cc112212" translate="yes" xml:space="preserve">
          <source>An &lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/framework/op_def.proto&quot;&gt;&lt;code&gt;OpDef&lt;/code&gt;&lt;/a&gt; protocol buffer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3eb75e744838b505a26045038c585ac604f978ac" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;Assert&lt;/code&gt;&lt;code&gt;Op&lt;/code&gt;, that, when run, will raise an &lt;code&gt;InvalidArgumentError&lt;/code&gt; if the operator is not positive definite.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8cbd0e06cb392fa652d7364528f02255efc26291" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;Assert&lt;/code&gt;&lt;code&gt;Op&lt;/code&gt;, that, when run, will raise an &lt;code&gt;InvalidArgumentError&lt;/code&gt; if the operator is not self-adjoint.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a545e95b473317eec85652508fd04f442161cca" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;Assert&lt;/code&gt;&lt;code&gt;Op&lt;/code&gt;, that, when run, will raise an &lt;code&gt;InvalidArgumentError&lt;/code&gt; if the operator is singular.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75b7e69ff232ae425c73fb2d650ec29886f0ed7c" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;EmbeddingConfigSpec&lt;/code&gt; instance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04c195216ee9d43768d062132510269762e71804" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;IndexedSlices&lt;/code&gt; holding the value of the average gradient.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8033e26af59131d947f486749f6c1d3ea4c9817f" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;IndexedSlices&lt;/code&gt; is typically used to represent a subset of a larger tensor &lt;code&gt;dense&lt;/code&gt; of shape &lt;code&gt;[LARGE0, D1, .. , DN]&lt;/code&gt; where &lt;code&gt;LARGE0 &amp;gt;&amp;gt; D0&lt;/code&gt;. The values in &lt;code&gt;indices&lt;/code&gt; are the indices in the first dimension of the slices that have been extracted from the larger tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff2f8031031b8db661092542012369fb08b6952f" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;IndicatorColumn&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b732939c2e0c038362ba71f46e5aa04012a044b1" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;Iterator&lt;/code&gt; over the elements of this dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aad5fb651e9948989164aa23fc4174350bbe3879" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;Iterator&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ccf75b5adb084438142d6a5a185fe29a3bacaf6d" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;Op&lt;/code&gt; that asserts this operator has Hermitian spectrum.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88bd3da1c31b82c16a4c739cfecfdc33f9e8b24a" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;Operation&lt;/code&gt; is a node in a &lt;a href=&quot;graph&quot;&gt;&lt;code&gt;tf.Graph&lt;/code&gt;&lt;/a&gt; that takes zero or more &lt;code&gt;Tensor&lt;/code&gt; objects as input, and produces zero or more &lt;code&gt;Tensor&lt;/code&gt; objects as output. Objects of type &lt;code&gt;Operation&lt;/code&gt; are created by calling a Python op constructor (such as &lt;a href=&quot;linalg/matmul&quot;&gt;&lt;code&gt;tf.matmul&lt;/code&gt;&lt;/a&gt;) within a &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; or under a &lt;a href=&quot;graph#as_default&quot;&gt;&lt;code&gt;tf.Graph.as_default&lt;/code&gt;&lt;/a&gt; context manager.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="887957539d8d902b158696a18b8b2d1e99d61c61" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;Operation&lt;/code&gt; object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00a5da9443a07ad886fcd13d56cd629ac4273c3e" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;Operation&lt;/code&gt; that applies the gradients. If &lt;code&gt;global_step&lt;/code&gt; was not None, that operation also increments &lt;code&gt;global_step&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89846b6249158bcd78fd7c6269b2a2c0c1ee45ee" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;Operation&lt;/code&gt; that applies the specified gradients. If &lt;code&gt;global_step&lt;/code&gt; was not None, that operation also increments &lt;code&gt;global_step&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fba7fac13399e2b4ea913368e24f4908654c0175" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;Operation&lt;/code&gt; that applies the specified gradients. The &lt;code&gt;iterations&lt;/code&gt; will be automatically increased by 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e27076a3c9d11a3056748a04bba449e21e1ebe1a" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;Operation&lt;/code&gt; that conditionally applies the specified gradients. If &lt;code&gt;global_step&lt;/code&gt; was not None, that operation also increments &lt;code&gt;global_step&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0af8485762eea8a947c0040764fc4ac54f13ca85" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;Operation&lt;/code&gt; that updates the variables in &lt;code&gt;var_list&lt;/code&gt;. The &lt;code&gt;iterations&lt;/code&gt; will be automatically increased by 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f25af9fd9c06f068567b90db2417bd1ff77cf63" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;Optional&lt;/code&gt; can represent the result of an operation that may fail as a value, rather than raising an exception and halting execution. For example, &lt;a href=&quot;get_next_as_optional&quot;&gt;&lt;code&gt;tf.data.experimental.get_next_as_optional&lt;/code&gt;&lt;/a&gt; returns an &lt;code&gt;Optional&lt;/code&gt; that either contains the next value from a &lt;a href=&quot;../../compat/v1/data/iterator&quot;&gt;&lt;code&gt;tf.compat.v1.data.Iterator&lt;/code&gt;&lt;/a&gt; if one exists, or a &quot;none&quot; value that indicates the end of the sequence has been reached.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="538a09736143e9776509c360465920f8fbadbd7d" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;Optional&lt;/code&gt; object representing the next value from the iterator (if it has one) or no value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72dc54c8857582a022284ca9cf8ea73d8c782972" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;Optional&lt;/code&gt; that has no value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d25bf5c8018852663f55eced05bf6613adf51a6" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;Optional&lt;/code&gt; that wraps &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="152a6366c8501e9bf42a00398c54ef42bd577773" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;Options&lt;/code&gt; object can be, for instance, used to control which static optimizations to apply or whether to use performance modeling to dynamically tune the parallelism of operations such as &lt;a href=&quot;dataset#map&quot;&gt;&lt;code&gt;tf.data.Dataset.map&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;dataset#interleave&quot;&gt;&lt;code&gt;tf.data.Dataset.interleave&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="902a87e7182932a9110aae26e24a41b05609d0f9" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;tf.distribute.InputIterator&lt;/code&gt; which returns inputs for each step of the computation. User should call &lt;code&gt;initialize&lt;/code&gt; on the returned iterator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abb7a1a3607f582ebf7cf1d72f10511578b4bc25" translate="yes" xml:space="preserve">
          <source>An Estimator for K-Means clustering.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="442a2ba5f53ec397dbf53c5da6746f99f153ca04" translate="yes" xml:space="preserve">
          <source>An Estimator for TensorFlow RNN models with user-specified head.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e01839b83e8a47991f56a0e4e0c0512fe986459c" translate="yes" xml:space="preserve">
          <source>An Estimator for Tensorflow Boosted Trees models.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3fb99865e648919ea62d1208482aae17c4d07448" translate="yes" xml:space="preserve">
          <source>An Estimator from given keras model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="333fd57c78c7baecf9d804894c434cb5d9e2e360" translate="yes" xml:space="preserve">
          <source>An Initializer instance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c41a159d6f97bd1022a1554734f166de4adbf21f" translate="yes" xml:space="preserve">
          <source>An L1 Regularizer with the given regularization factor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f79256cb9cc69bb360e6f39f280905d4eba75cc" translate="yes" xml:space="preserve">
          <source>An L1L2 Regularizer with the given regularization factors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d09fad452d4b2b2be083e9e40068f0562f47109" translate="yes" xml:space="preserve">
          <source>An L2 Regularizer with the given regularization factor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e373fe37de8b07bd9c5bd1311475882c7572776c" translate="yes" xml:space="preserve">
          <source>An N-D &lt;code&gt;Tensor&lt;/code&gt; the size of values containing the result of applying either lower_bound or upper_bound (depending on side) to each value. The result is not a global index to the entire &lt;code&gt;Tensor&lt;/code&gt;, but the index in the last dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13d7f3e77a50c4d3a2d8ab477189d7a412766c6b" translate="yes" xml:space="preserve">
          <source>An Op or &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c2444fb2fd6590fb9052f135286e8a1a5b1cac6" translate="yes" xml:space="preserve">
          <source>An Op that initializes all local variables in the graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cda2c592918d1918617a0bf94568272bc4f5cdd" translate="yes" xml:space="preserve">
          <source>An Op that initializes all tables. Note that if there are not tables the returned Op is a NoOp.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d82662569eb284bf134b0cb34f3d518d2e2e206" translate="yes" xml:space="preserve">
          <source>An Op that initializes global variables in the graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b9bafc2c917c0724fbaceb03807c73a983d00877" translate="yes" xml:space="preserve">
          <source>An Op that run the initializers of all the specified variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="666deff3792ad3e5ad1ef6441e431cae74f337a6" translate="yes" xml:space="preserve">
          <source>An Op, or None if there are no variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3633a8a16f62b95219202736c3761a2e110eafc3" translate="yes" xml:space="preserve">
          <source>An Operation that executes all its inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a2b9412a9bd48a65acf94c3af92265aa30f1723" translate="yes" xml:space="preserve">
          <source>An Operation that updates the moving averages.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10726b04e493043b3d3a4a48902b701d4ff5d339" translate="yes" xml:space="preserve">
          <source>An Operation that updates the variables in &lt;code&gt;var_list&lt;/code&gt;. If &lt;code&gt;global_step&lt;/code&gt; was not &lt;code&gt;None&lt;/code&gt;, that operation also increments &lt;code&gt;global_step&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1842d03425ebe80ef018f0666d9574fab16c8753" translate="yes" xml:space="preserve">
          <source>An Operation to update the variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf2998992fb3f6ba8bb6d49cbb00b119d117f8ca" translate="yes" xml:space="preserve">
          <source>An RNN cell, in the most abstract setting, is anything that has a state and performs some operation that takes a matrix of inputs. This operation results in an output matrix with &lt;code&gt;self.output_size&lt;/code&gt; columns. If &lt;code&gt;self.state_size&lt;/code&gt; is an integer, this operation also results in a new state matrix with &lt;code&gt;self.state_size&lt;/code&gt; columns. If &lt;code&gt;self.state_size&lt;/code&gt; is a (possibly nested tuple of) TensorShape object(s), then it should return a matching structure of Tensors having shape &lt;code&gt;[batch_size].concatenate(s)&lt;/code&gt; for each &lt;code&gt;s&lt;/code&gt; in &lt;code&gt;self.batch_size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38efe8d188deecf68dd820301ba465eaf235c79a" translate="yes" xml:space="preserve">
          <source>An absolute path to the linked in runfiles.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79d31ec7532c49c54f40438fb6ed8615c4283972" translate="yes" xml:space="preserve">
          <source>An accumulator is created for each variable, and each replica pushes the gradients into the accumulators instead of directly applying them to the variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6aa6af5ff80f497fe46c5c7d095d9c873eeae5f" translate="yes" xml:space="preserve">
          <source>An alternative to &lt;code&gt;VarLenFeature&lt;/code&gt; to obtain a &lt;code&gt;SparseTensor&lt;/code&gt; is &lt;code&gt;SparseFeature&lt;/code&gt;. For example, given two &lt;code&gt;Example&lt;/code&gt; input protos in &lt;code&gt;serialized&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b521335184b0bf04872e8ab6e0574fb92b9baeb1" translate="yes" xml:space="preserve">
          <source>An alternative to global variables are local variables. See &lt;a href=&quot;local_variables&quot;&gt;&lt;code&gt;tf.compat.v1.local_variables&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7af2201c3bb2ce31f09ec9f4c214e2749ec0ac99" translate="yes" xml:space="preserve">
          <source>An alternative to local variables are global variables. See &lt;a href=&quot;global_variables&quot;&gt;&lt;code&gt;tf.compat.v1.global_variables&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb52d3b481a422d842ed677630ce2407187a4ec9" translate="yes" xml:space="preserve">
          <source>An approximate equality assertion for ordered sequences.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0e8a0b21fa51459d04b19972601b596b4059112" translate="yes" xml:space="preserve">
          <source>An array-like HDF5 dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1eba61d435fb8e59a749b77771ceac9115c71a9a" translate="yes" xml:space="preserve">
          <source>An asynchronous multi-worker parameter server tf.distribute strategy.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6a1e23199ba68576b0dd69ec347fadedc89638d" translate="yes" xml:space="preserve">
          <source>An eager-compatible version of recompute_grad.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="febe58e5e1adf30e18bed36dcd6efefd2c650d37" translate="yes" xml:space="preserve">
          <source>An early-stopping hook of type &lt;code&gt;SessionRunHook&lt;/code&gt; that periodically checks if the given metric is higher than specified threshold and initiates early stopping if true.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc7c0ca1ad7a96743dea331f07b42205ddfbced8" translate="yes" xml:space="preserve">
          <source>An early-stopping hook of type &lt;code&gt;SessionRunHook&lt;/code&gt; that periodically checks if the given metric is lower than specified threshold and initiates early stopping if true.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99e2020178da38d76932cef155b4022e00e5a932" translate="yes" xml:space="preserve">
          <source>An early-stopping hook of type &lt;code&gt;SessionRunHook&lt;/code&gt; that periodically checks if the given metric shows no decrease over given maximum number of training steps, and initiates early stopping if true.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60206a9ffd07eaa0f6ee2f0f3cbcdb9abfc612a4" translate="yes" xml:space="preserve">
          <source>An early-stopping hook of type &lt;code&gt;SessionRunHook&lt;/code&gt; that periodically checks if the given metric shows no increase over given maximum number of training steps, and initiates early stopping if true.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="840773f95e89e43f2f56531a9519b0065771989d" translate="yes" xml:space="preserve">
          <source>An empty string or &quot;local://&quot;, in which case protocol descriptors are created for C++ (not Python) proto definitions linked to the binary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8fbcd6b23b0a8678e9dbebf6a3a02d357103d192" translate="yes" xml:space="preserve">
          <source>An equality assertion for ordered sequences (like lists and tuples).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e57293b4acf7f097bb93eeb8e3b0068ae6dc0cc" translate="yes" xml:space="preserve">
          <source>An equality assertion for the beginning of ordered sequences.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3bf9b767b85093ed5c4b47c9027ac4952f14d5b8" translate="yes" xml:space="preserve">
          <source>An estimator for TensorFlow DNN models with user-specified head.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc2a27d1256a3aa819daf54dc6e23bedcdc5c4a0" translate="yes" xml:space="preserve">
          <source>An estimator for TensorFlow Linear and DNN joined classification models.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="804768154fbf9db76ed62d94e58e09d9e814e944" translate="yes" xml:space="preserve">
          <source>An estimator for TensorFlow Linear and DNN joined models for regression.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5983b803cea9eaae144255b314431844da9f15ca" translate="yes" xml:space="preserve">
          <source>An estimator for TensorFlow Linear and DNN joined models with custom head.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48b8b2a429b39b33c63e550a3ef73ad1a321572c" translate="yes" xml:space="preserve">
          <source>An estimator for TensorFlow Linear regression problems.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee18ab446cc2d532a95c1e7f79a689e8900a8e5e" translate="yes" xml:space="preserve">
          <source>An estimator for TensorFlow linear models with user-specified head.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d685d81ed52cd9d6afcacae83c24c3e02d8887c" translate="yes" xml:space="preserve">
          <source>An estimator that can establish a simple baseline.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da4246a8f4aa900255d24a42321d0b375e684b1f" translate="yes" xml:space="preserve">
          <source>An example of where this error may be returned is if a Status value received from another address space belongs to an error-space that is not known to this address space. Also, errors raised by APIs that do not return enough error information may be converted to this error.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7497f38dc488b4b193498a34c0f181f37fc0a37d" translate="yes" xml:space="preserve">
          <source>An exception raised from the &lt;code&gt;with&lt;/code&gt; block or one of the service threads is raised again when the block exits. This is done after stopping all threads and closing the session. For example, an &lt;code&gt;AbortedError&lt;/code&gt; exception, raised in case of preemption of one of the workers in a distributed model, is raised again when the block exits.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cf75f1d58022a7cc4210763abe31b5479fe9982" translate="yes" xml:space="preserve">
          <source>An exception will be raised if any Python objects in the dependency graph were not found in the checkpoint, or if any checkpointed values do not have a matching Python object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5bced1c9a523184f365bd43e5927358bc13dfc6b" translate="yes" xml:space="preserve">
          <source>An exception will be thrown if regexes contains an invalid regex.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a60972340cdca32e8f2ce10b759a88d70a797897" translate="yes" xml:space="preserve">
          <source>An implicit ellipsis is placed at the end of the &lt;code&gt;slice_spec&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c85d624b89706bb14b288acaa4ac6fa07ac95357" translate="yes" xml:space="preserve">
          <source>An in-process TensorFlow server, for use in distributed training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e2bec5a6fa87617f2eec8c30e838f26d2229e85" translate="yes" xml:space="preserve">
          <source>An initial state can be provided. If the sequence_length vector is provided, dynamic calculation is performed. This method of calculation does not compute the RNN steps past the maximum sequence length of the minibatch (thus saving computational time), and properly propagates the state at an example's sequence length to the final state output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bae67168507f394b82b52fdf0714e08938c843f8" translate="yes" xml:space="preserve">
          <source>An initializer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b72709c277c5cac4226f96052b086a86c0708447" translate="yes" xml:space="preserve">
          <source>An input shape tuple.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4eeda0cb14a34563e0664b391112a30860b14668" translate="yes" xml:space="preserve">
          <source>An instance of &lt;code&gt;Model&lt;/code&gt; reproducing the behavior of the original model, on top of new inputs tensors, using newly instantiated weights. The cloned model might behave differently from the original model if a custom clone_function modifies the layer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef4fa2827270f8f7119046220209c1e21c9afc08" translate="yes" xml:space="preserve">
          <source>An instance of &lt;code&gt;ReparameterizationType&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4b5e809764a950903ad4b36b900b2f8915831c0d" translate="yes" xml:space="preserve">
          <source>An instance of DuplicateFlagError.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b19366fd8e0c636505cdee48bf9e51ad9ad6f74" translate="yes" xml:space="preserve">
          <source>An int32 &lt;code&gt;Tensor&lt;/code&gt; with the same shape as &lt;code&gt;values&lt;/code&gt;. The indices that would sort each slice of the given &lt;code&gt;values&lt;/code&gt; along the given &lt;code&gt;axis&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1017def51209cdeafc98ecac507e1022a500fe57" translate="yes" xml:space="preserve">
          <source>An int64 Tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fadc973358bcb5c1223ec4f16357e8a616e60266" translate="yes" xml:space="preserve">
          <source>An integer &lt;code&gt;SparseTensor&lt;/code&gt; of class indices. The &lt;code&gt;dense_shape&lt;/code&gt; must be &lt;code&gt;[D0, D1, ... DN, ?]&lt;/code&gt; and the values within &lt;code&gt;[0, n_classes)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcba7860aca4af3f2b1d88d9a4bb07e285e0d06c" translate="yes" xml:space="preserve">
          <source>An integer &lt;code&gt;Tensor&lt;/code&gt; (&lt;code&gt;dtype=self.row_splits.dtype&lt;/code&gt;). If &lt;code&gt;axis&lt;/code&gt; is not specified, then &lt;code&gt;output&lt;/code&gt; is a vector with &lt;code&gt;output.shape=[self.shape.ndims]&lt;/code&gt;. If &lt;code&gt;axis&lt;/code&gt; is a scalar, then the &lt;code&gt;output&lt;/code&gt; is a scalar. If &lt;code&gt;axis&lt;/code&gt; is a vector, then &lt;code&gt;output&lt;/code&gt; is a vector, where &lt;code&gt;output[i]&lt;/code&gt; is the bounding size for dimension &lt;code&gt;axis[i]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="188f2d71192e8726a1bf7709dabba1bde2b687c4" translate="yes" xml:space="preserve">
          <source>An integer Tensor for the global_step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f169c69e49d6f234be51674bdee49bbfe30ad933" translate="yes" xml:space="preserve">
          <source>An integer count.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96e5ab88026026d8241adec84062b3375ac781e6" translate="yes" xml:space="preserve">
          <source>An integer denoting the number of dimensions (rank) of the dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d95373587d35b9bbca30a259e3b6b634a328e2b9" translate="yes" xml:space="preserve">
          <source>An integer denoting the number of elements in the dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="225c070e63b08b92d1ac153911dba9373d7e08e6" translate="yes" xml:space="preserve">
          <source>An integer id.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b1c867dc30892fc901ea2758ce4e659594290be" translate="yes" xml:space="preserve">
          <source>An integer if &lt;code&gt;key&lt;/code&gt; is an integer, or a &lt;code&gt;TensorShape&lt;/code&gt; if &lt;code&gt;key&lt;/code&gt; is a slice.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3dffb62951cf432529602d96c466ed30c4eb988f" translate="yes" xml:space="preserve">
          <source>An integer numpy array of rank 3, with shape &lt;code&gt;[num_replicas, num_cores_per_replica, topology_rank]&lt;/code&gt;. Maps (replica, logical core) pairs to physical topology coordinates.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf24e07cdb340822fb333f48a047d38bf8e9dc22" translate="yes" xml:space="preserve">
          <source>An integer tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea0a5a49b916a7e43c9d3a768b18949e48154a51" translate="yes" xml:space="preserve">
          <source>An integer variable which starts at zero and is incremented on save.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7485aa01a0eecefe5e6b94ac710059f32364655" translate="yes" xml:space="preserve">
          <source>An integer version that increases as ops are added to the graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8cf51a2206c0b972e8c8da910dda57868c0bc95" translate="yes" xml:space="preserve">
          <source>An iterable over the elements of the dataset, with their tensors converted to numpy arrays.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f961e649d0252c4c127e14975ee87875356a4df5" translate="yes" xml:space="preserve">
          <source>An iterator for reading &lt;code&gt;Event&lt;/code&gt; protocol buffers from an event file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5151c48a2474d7fa974e11c09dabac1744d01dc5" translate="yes" xml:space="preserve">
          <source>An iterator object that should first be &lt;code&gt;.initialize()&lt;/code&gt;-ed. It may then either be passed to &lt;code&gt;strategy.experimental_run()&lt;/code&gt; or you can &lt;code&gt;iterator.get_next()&lt;/code&gt; to get the next value to pass to &lt;code&gt;strategy.extended.call_for_each_replica()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f8f60ffcc528bb61cc7d8ba226ca4a4652b8ef1" translate="yes" xml:space="preserve">
          <source>An iterator that read the records from a TFRecords file. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53236bd7a72b54ebe4237315af252d19c8304b01" translate="yes" xml:space="preserve">
          <source>An offline converter for TF-TRT transformation for TF 2.0 SavedModels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fdae002ee37107ad2ee06d52a6bf8fc2acf612be" translate="yes" xml:space="preserve">
          <source>An op for the chief/sync replica to fill the token queue.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a65e5864da6fe35dc51ffeee35335ae162bd6b4a" translate="yes" xml:space="preserve">
          <source>An operation that writes the content of the specified dataset to the file specified in the constructor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b7bb90dd5acb15516e6b90961d83683aa0ce2c3" translate="yes" xml:space="preserve">
          <source>An optimizer config is a Python dictionary (serializable) containing the configuration of an optimizer. The same optimizer can be reinstantiated later (without any saved state) from this configuration.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c35bc5630a4f22b6ba47b63482db03d57bceb18" translate="yes" xml:space="preserve">
          <source>An optimizer instance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b64fd67fea6b1c125d231391d46cbbfc6338279b" translate="yes" xml:space="preserve">
          <source>An optimizer that applies loss scaling.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c5e2c5583b1f9ba1aae31cc247696892ae7e17c" translate="yes" xml:space="preserve">
          <source>An optimizer that averages gradients across TPU shards.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7db09d3e5bc67828426d7ea158efdec0338d7960" translate="yes" xml:space="preserve">
          <source>An optional &lt;code&gt;axis&lt;/code&gt; attribute can specify a dimension index of the input tensor, such that quantization ranges will be calculated and applied separately for each slice of the tensor along that dimension. This is useful for per-channel quantization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e810e2d0cabddb80a5abfbf49a06cf44a243fa3" translate="yes" xml:space="preserve">
          <source>An optional keyword argument 'msg' can be provided when assertRaises is used as a context object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d724ef8b5ac4713da43866408783f4dfab2df0a6" translate="yes" xml:space="preserve">
          <source>An optional keyword argument 'msg' can be provided when assertWarns is used as a context object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fae9808d38c410051b12143e26717b31e8e8cd4d" translate="yes" xml:space="preserve">
          <source>An regularizer config is a Python dictionary (serializable) containing all configuration parameters of the regularizer. The same regularizer can be reinstantiated later (without any saved state) from this configuration.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54da63bfcb37a536980f5fba55cb96d50015fe10" translate="yes" xml:space="preserve">
          <source>An unordered sequence comparison asserting that the same elements, regardless of order. If the same element occurs more than once, it verifies that the elements occur the same number of times.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5babbe86183ca4a32d45308a3a011c68e1b2b4e7" translate="yes" xml:space="preserve">
          <source>Analogous to &lt;code&gt;batch_gather&lt;/code&gt;. This assumes that &lt;code&gt;ref&lt;/code&gt;, &lt;code&gt;indices&lt;/code&gt; and &lt;code&gt;updates&lt;/code&gt; have a series of leading dimensions that are the same for all of them, and the updates are performed on the last dimension of indices. In other words, the dimensions should be the following:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09726561b53e40cf836389af92359b99b60edc7d" translate="yes" xml:space="preserve">
          <source>Analogous to &lt;code&gt;batch_gather&lt;/code&gt;. This assumes that this variable and the sparse_delta IndexedSlices have a series of leading dimensions that are the same for all of them, and the updates are performed on the last dimension of indices. In other words, the dimensions should be the following:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d08d573ac0dca859ae365ea62edc8d0a6b6a4ddd" translate="yes" xml:space="preserve">
          <source>And arguments</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7000d584314526e7e6afe78bd49a48d66f69ac8" translate="yes" xml:space="preserve">
          <source>And finally (\hat{x}) is linearly transformed by ({\gamma}) and ({\beta}), which are learned parameters:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7735a5a6da4547b3569cfa0c94476d0e3ca1bff2" translate="yes" xml:space="preserve">
          <source>And for &lt;code&gt;n + 1&lt;/code&gt; dimensional &lt;code&gt;x&lt;/code&gt; with shape &lt;code&gt;[N1, ..., Nn, K]&lt;/code&gt;, we define</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69b830fcad03ac8706beb3b01515bd79f090f2ab" translate="yes" xml:space="preserve">
          <source>And the expected output is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f31b5c2f9f361420e82dd042756cbdd55c85bca8" translate="yes" xml:space="preserve">
          <source>And the operation performed can be expressed as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24fd46a63bb5a580ba4e74a1c1ad2c60ade19149" translate="yes" xml:space="preserve">
          <source>And to make an embedding with either:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="856497dd8de7f8b022715e8c39c03a81ee5d5293" translate="yes" xml:space="preserve">
          <source>Another example is a 'differentiable' moving average approximation, where gradients are allowed to flow into the last value fed to the moving average, but the moving average is still used for the forward pass:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e65a659fcc9684bb008f92cfbaf1f26b5f07364" translate="yes" xml:space="preserve">
          <source>Another example, if 'axis = 1' and the inputs are</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6641d3ec47cf779f4f61bc40e91caabfec553b5b" translate="yes" xml:space="preserve">
          <source>Any dimensions added by &lt;code&gt;array_ops.newaxis&lt;/code&gt; will be ragged if the following dimension is ragged.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43768e31b404b4bd65259dd89b743ad3f29d5a24" translate="yes" xml:space="preserve">
          <source>Any dtype name, such as 'float32' or 'float64'. Both the variable and compute dtypes will be that dtype.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cc2abc23cd80c15d70111b2f4f39907e243a4e9" translate="yes" xml:space="preserve">
          <source>Any dtype name, such as 'float32' or 'float64'. Both the variable and compute dtypes will be that dtype. No loss scaling is done by default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4fb306ec91fa48a5fe2e81e7b56b382ce5b1aae4" translate="yes" xml:space="preserve">
          <source>Any entries in &lt;code&gt;t_list&lt;/code&gt; that are of type None are ignored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e6ace33eabfd5d2dd36fd022c6f164055e92e02" translate="yes" xml:space="preserve">
          <source>Any function that takes in a weight matrix and returns a scalar tensor can be used as a regularizer, e.g.:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0ac3b87f59c093fa24996fa010aa20479741927" translate="yes" xml:space="preserve">
          <source>Any of the entries of &lt;code&gt;t_list&lt;/code&gt; that are of type &lt;code&gt;None&lt;/code&gt; are ignored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1dfd11dcc6f696c3404bf35763ad95c6eb65704" translate="yes" xml:space="preserve">
          <source>Any of the threads can call &lt;code&gt;coord.request_stop()&lt;/code&gt; to ask for all the threads to stop. To cooperate with the requests, each thread must check for &lt;code&gt;coord.should_stop()&lt;/code&gt; on a regular basis. &lt;code&gt;coord.should_stop()&lt;/code&gt; returns &lt;code&gt;True&lt;/code&gt; as soon as &lt;code&gt;coord.request_stop()&lt;/code&gt; has been called.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9bc46394aa4a0f5c5b609ae4e0e4287cd596c579" translate="yes" xml:space="preserve">
          <source>Any whitespace can be used as a separator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e731a11b061748546d938062ed828dc02374a93" translate="yes" xml:space="preserve">
          <source>Appends all flags assignments from this FlagInfo object to a file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd3d7766234f16a63c7f60f6ec28017a31b1bc28" translate="yes" xml:space="preserve">
          <source>Appends flags registered in another FlagValues instance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3ea14711baca3f0a3289debffb8689ae0f35ca0" translate="yes" xml:space="preserve">
          <source>Applies &lt;code&gt;func(x[0], x[1], ...)&lt;/code&gt; where x[i] is an entry in &lt;code&gt;structure[i]&lt;/code&gt;. All structures in &lt;code&gt;structure&lt;/code&gt; must have the same arity, and the return value will contain results with the same structure layout.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16bb74d86664622f66d779eea2f15db151899642" translate="yes" xml:space="preserve">
          <source>Applies &lt;code&gt;func&lt;/code&gt; to each entry in &lt;code&gt;structure&lt;/code&gt; and returns a new structure.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f7f6f7b60c6dee64ac8391c8330e31cdbf63ae7" translate="yes" xml:space="preserve">
          <source>Applies &lt;code&gt;op&lt;/code&gt; to the values of one or more RaggedTensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8a01cdcf34886456b8891b8abf57ae574999852" translate="yes" xml:space="preserve">
          <source>Applies Alpha Dropout to the input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee441315c074dbfb730aa9f2af0891d836417b38" translate="yes" xml:space="preserve">
          <source>Applies Dropout to the input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e848937a7ddfd56b1ec5572c7ddd394a9f23ce0e" translate="yes" xml:space="preserve">
          <source>Applies L1 regularization shrink step on the parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d1b53bbb91a80e936db4b947627f59edacfc704" translate="yes" xml:space="preserve">
          <source>Applies a boolean mask to &lt;code&gt;data&lt;/code&gt; without flattening the mask dimensions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b825d3c64659aae8d0036c192e5fa85c507c95f9" translate="yes" xml:space="preserve">
          <source>Applies a polynomial decay to the learning rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7911ba5120125cc72947661dab80dba696110c9" translate="yes" xml:space="preserve">
          <source>Applies a random transformation to an image.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60acd402b359a94751ce9d82f606354c2d9019c9" translate="yes" xml:space="preserve">
          <source>Applies a transformation function to this dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a7d34b3174141a6a19928864df6cbf717f78d7a" translate="yes" xml:space="preserve">
          <source>Applies a transformation to an image according to given parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1e31e91a3590b7de403b46d719ee4ba35e8375b" translate="yes" xml:space="preserve">
          <source>Applies an activation function to an output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1550c5f0bd865d0f9113d0169289f1a69d4fba6a" translate="yes" xml:space="preserve">
          <source>Applies an affine transformation specified by the parameters given.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c40584f3a35536aa56ba79a548b47d4eab5d7c0" translate="yes" xml:space="preserve">
          <source>Applies batch normalization on x given mean, var, beta and gamma.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6fc551e1da71ba31ab28b4b8dde0d2689542edb" translate="yes" xml:space="preserve">
          <source>Applies cosine decay to the learning rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4bd697b1ffc0b4e143beef46319dcc0c5ac06454" translate="yes" xml:space="preserve">
          <source>Applies cosine decay with restarts to the learning rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9dfa1bd4553c4405259d07f3bc916e914643902d" translate="yes" xml:space="preserve">
          <source>Applies exponential decay to the learning rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1248d48f4bd4a7a0f8c84526ce6de7cbe6c9ca74" translate="yes" xml:space="preserve">
          <source>Applies inverse time decay to the initial learning rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29a0b1ad75aefb7d0f5212f7f0184d037dfc3f06" translate="yes" xml:space="preserve">
          <source>Applies linear cosine decay to the learning rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c29ff4ee781cfc8cb030ccac3df7211c245e51f" translate="yes" xml:space="preserve">
          <source>Applies natural exponential decay to the initial learning rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="856d722e05a09b9433074a5d24479abe0a796cda" translate="yes" xml:space="preserve">
          <source>Applies noisy linear cosine decay to the learning rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7321a5fcf04a58f1ef9cac318d7fd813fbb538b4" translate="yes" xml:space="preserve">
          <source>Applies softmax to a batched N-D &lt;code&gt;SparseTensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bccc5a75d0e6858fa48c5859eb31fb21a06bef5d" translate="yes" xml:space="preserve">
          <source>Applies sparse &lt;code&gt;updates&lt;/code&gt; to individual values or slices in a Variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82a3bcad77e766e7c6707709f1146c5e5516e607" translate="yes" xml:space="preserve">
          <source>Applies sparse addition to individual values or slices in a Variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b7c76bc79aa1c241ab4627feeb9ce54653580e5" translate="yes" xml:space="preserve">
          <source>Applies sparse assignment to individual values or slices in a Variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c85eadfb777aa08fe1a62f44f5f0f5abd25b64b4" translate="yes" xml:space="preserve">
          <source>Applies sparse subtraction to individual values or slices in a Variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c32f8a50657579be35620f49c2fa542033ddb641" translate="yes" xml:space="preserve">
          <source>Applies sparse updates to a variable reference.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02ffd5e4fd7f5250fac9cc6472dcfe7297a7c41d" translate="yes" xml:space="preserve">
          <source>Applies the normalization configuration in-place to a batch of inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ac63a3a36407827bb5d0eee7bb134915d1fe7e4" translate="yes" xml:space="preserve">
          <source>Applies the rectified linear unit activation function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87510f2c159c87cfdf0a716eaaac506c09283dde" translate="yes" xml:space="preserve">
          <source>Applies the sigmoid activation function. The sigmoid function is defined as 1 divided by (1 + exp(-x)). It's curve is like an &quot;S&quot; and is like a smoothed version of the Heaviside (Unit Step Function) function. For small values (&amp;lt;-5) the sigmoid returns a value close to zero and for larger values (&amp;gt;5) the result of the function gets close to 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bef49334c7de61f892658d723c2446b198bcdfad" translate="yes" xml:space="preserve">
          <source>Applies weight values to a &lt;code&gt;CategoricalColumn&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02170b153eecb222f4f52c510af18adc444b460d" translate="yes" xml:space="preserve">
          <source>Apply 1D conv with un-shared weights.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="362fa60dda99a9ce0e2b371b494ba0ca2a380582" translate="yes" xml:space="preserve">
          <source>Apply 2D conv with un-shared weights.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64da1c711583c758698fc3ded4f52accff2c61a0" translate="yes" xml:space="preserve">
          <source>Apply a model copy on each sub-batch. Every model copy is executed on a dedicated GPU.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf282f17624b0e4cb65903d39393edb427009a61" translate="yes" xml:space="preserve">
          <source>Apply additive zero-centered Gaussian noise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93f08372a7ac5baf9833bbce9477d433e97bb876" translate="yes" xml:space="preserve">
          <source>Apply boolean mask to tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96a92f931396bd4b28350ddb3ca0745aa8660cc9" translate="yes" xml:space="preserve">
          <source>Apply dataset transformations to preprocess the data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="853324ac0b027968472d8535372b7cd2b6d23dc7" translate="yes" xml:space="preserve">
          <source>Apply gradients to variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="507238ee18ca8c1b85e90f2dd1ee9561dcc10c3b" translate="yes" xml:space="preserve">
          <source>Apply multiplicative 1-centered Gaussian noise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e86435756168ef228f1a566a784a7d7eb134976" translate="yes" xml:space="preserve">
          <source>Apply the averaged gradients to the variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de7c827826bdde447eded62d34167f8efd0b1c22" translate="yes" xml:space="preserve">
          <source>Apply the processed gradients with &lt;code&gt;apply_gradients()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="900d132c213ec4343c6fc0336a260cc881ec45fd" translate="yes" xml:space="preserve">
          <source>Arbitrary, although all dimensions in the input shaped must be fixed. Use the keyword argument &lt;code&gt;input_shape&lt;/code&gt; (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2c166b8f975246ab2963b396822d9310c9f621d" translate="yes" xml:space="preserve">
          <source>Arbitrary. Use the keyword argument &lt;code&gt;input_shape&lt;/code&gt; (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6075aed00d09ffa3057c99d13847e6be9606a66" translate="yes" xml:space="preserve">
          <source>Args:</source>
          <target state="translated">Args:</target>
        </trans-unit>
        <trans-unit id="99273381f137aff4d193bcbf6b294f3762ee5d9d" translate="yes" xml:space="preserve">
          <source>Args: can only have following four arguments in any order:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ed01fb9805bc8c4a695e5dc56bb75484b11c316" translate="yes" xml:space="preserve">
          <source>Args: dataset: &lt;a href=&quot;../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; to be prefetched to device.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fe112de17c85e3571d0874cd9f803299b9de474" translate="yes" xml:space="preserve">
          <source>Args: dataset: &lt;a href=&quot;../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; to be prefetched to device.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aedf1c882006ab95d1314645a164bafa4c4fd954" translate="yes" xml:space="preserve">
          <source>Args: image: 4-D Tensor of shape &lt;code&gt;[batch, height, width, channels]&lt;/code&gt; or 3-D Tensor of shape &lt;code&gt;[height, width, channels]&lt;/code&gt;. k: A scalar integer. The number of times the image is rotated by 90 degrees. name: A name for this operation (optional).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="22b15cbb658daedfac47fd496b831c94bf579b50" translate="yes" xml:space="preserve">
          <source>Args: index: 0-D. int32 scalar with the index to write to. value: N-D. Tensor of type &lt;code&gt;dtype&lt;/code&gt;. The Tensor to write to this index. name: A name for the operation (optional).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c844d37451ea04088a15d9dab260b353e4e942d7" translate="yes" xml:space="preserve">
          <source>Args: indices: A &lt;code&gt;1-D&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; taking values in &lt;code&gt;[0, max_value)&lt;/code&gt;. If the &lt;code&gt;TensorArray&lt;/code&gt; is not dynamic, &lt;code&gt;max_value=size()&lt;/code&gt;. value: (N+1)-D. Tensor of type &lt;code&gt;dtype&lt;/code&gt;. The Tensor to unpack. name: A name for the operation (optional).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f26b500bb18c5a1179d7f87e0d0f67b87c50dfea" translate="yes" xml:space="preserve">
          <source>Args: new_vocab: [Required] A path to the new vocabulary file (used with the model to be trained). new_vocab_size: [Required] An integer indicating how many entries of the new vocabulary will used in training. num_oov_buckets: [Required] An integer indicating how many OOV buckets are associated with the vocabulary. old_vocab: [Required] A path to the old vocabulary file (used with the checkpoint to be warm-started from). old_vocab_size: [Optional] An integer indicating how many entries of the old vocabulary were used in the creation of the checkpoint. If not provided, the entire old vocabulary will be used. backup_initializer: [Optional] A variable initializer used for variables corresponding to new vocabulary entries and OOV. If not provided, these entries will be zero-initialized. axis: [Optional] Denotes what axis the vocabulary corresponds to. The default, 0, corresponds to the most common use case (embeddings or linear weights for binary classification / regression). An axis of 1 could be used for warm-starting output layers with class vocabularies.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7120edd36dda78441c0c29396142b67d6d09a092" translate="yes" xml:space="preserve">
          <source>Args: value: (N+1)-D. Tensor of type &lt;code&gt;dtype&lt;/code&gt;. The Tensor to split. lengths: 1-D. int32 vector with the lengths to use when splitting &lt;code&gt;value&lt;/code&gt; along its first dimension. name: A name for the operation (optional).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8e409c39fb7dfbfe2b8cd9ac2e2b122265dd69d" translate="yes" xml:space="preserve">
          <source>Args: value: (N+1)-D. Tensor of type &lt;code&gt;dtype&lt;/code&gt;. The Tensor to unstack. name: A name for the operation (optional).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c194197772b0e84ad6947e19dc6c2eeee4510a35" translate="yes" xml:space="preserve">
          <source>Argument parser classes must be stateless, since instances are cached and shared between flags. Initializer arguments are allowed, but all member variables must be derived from initializer arguments only.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cbb9fa252e60809efa55a7ad83aea5438ef56753" translate="yes" xml:space="preserve">
          <source>Arguments</source>
          <target state="translated">Arguments</target>
        </trans-unit>
        <trans-unit id="1c0c8a9f198462474b49e918f6a0268a10542dd6" translate="yes" xml:space="preserve">
          <source>Arguments are broadcast when possible.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0518f9d17ce6a281a9a9cc7fd3c8f463d99c3d2" translate="yes" xml:space="preserve">
          <source>Arguments that accept &lt;code&gt;RaggedTensor&lt;/code&gt;s are marked in &lt;strong&gt;bold&lt;/strong&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="18b9c00e61d4ab2fa61c0032b93fb625d273e10d" translate="yes" xml:space="preserve">
          <source>Arguments to methods such as &lt;code&gt;matmul&lt;/code&gt; or &lt;code&gt;solve&lt;/code&gt; must be &lt;code&gt;DTYPE&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0478ca5f4c068ca3ac12f9474f6a15865ce9053" translate="yes" xml:space="preserve">
          <source>Arguments:</source>
          <target state="translated">Arguments:</target>
        </trans-unit>
        <trans-unit id="a616eade29a2a9b3e41fce02304170740b4fc369" translate="yes" xml:space="preserve">
          <source>As a safe-guard, the returned function will raise a &lt;code&gt;ValueError&lt;/code&gt; after the first call if trainable variables are created by calling &lt;a href=&quot;../../variable&quot;&gt;&lt;code&gt;tf.Variable&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17af51d3b4099b8f62a01fceded19338f6f0793d" translate="yes" xml:space="preserve">
          <source>As a special case, exceptions used for control flow, such as &lt;code&gt;OutOfRangeError&lt;/code&gt; which reports that input queues are exhausted, are not raised again from the &lt;code&gt;with&lt;/code&gt; block: they indicate a clean termination of the training loop and are considered normal termination.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b744e75bc2659c2943071819a7f363b71ca17302" translate="yes" xml:space="preserve">
          <source>As another example, if &lt;code&gt;t&lt;/code&gt; is a matrix and &lt;code&gt;axes == [1]&lt;/code&gt;, then each row of the output will have L2-norm less than or equal to &lt;code&gt;clip_norm&lt;/code&gt;. If &lt;code&gt;axes == [0]&lt;/code&gt; instead, each column of the output will be clipped.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57443c33075ad59c1a571c85128ca2ef3752d9b0" translate="yes" xml:space="preserve">
          <source>As in Python, the &lt;code&gt;axis&lt;/code&gt; could also be negative numbers. Negative &lt;code&gt;axis&lt;/code&gt; are interpreted as counting from the end of the rank, i.e., &lt;code&gt;axis + rank(values)&lt;/code&gt;-th dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8765e8c5ac22dec16d9c473cc3f1b1906a1ec80" translate="yes" xml:space="preserve">
          <source>As it is a regularization layer, it is only active at training time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85acd5bb42a06da8f018df776f49554d85e43d71" translate="yes" xml:space="preserve">
          <source>Aside from the &lt;a href=&quot;../v1&quot;&gt;&lt;code&gt;compat.v1&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../v2&quot;&gt;&lt;code&gt;compat.v2&lt;/code&gt;&lt;/a&gt; submodules, &lt;a href=&quot;../../compat&quot;&gt;&lt;code&gt;tf.compat&lt;/code&gt;&lt;/a&gt; also contains a set of helper functions for writing code that works in both:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29caae4b2b26ba94768556b19171003da5ecd02f" translate="yes" xml:space="preserve">
          <source>Aside from the &lt;a href=&quot;compat/v1&quot;&gt;&lt;code&gt;compat.v1&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;compat/v2&quot;&gt;&lt;code&gt;compat.v2&lt;/code&gt;&lt;/a&gt; submodules, &lt;a href=&quot;compat&quot;&gt;&lt;code&gt;tf.compat&lt;/code&gt;&lt;/a&gt; also contains a set of helper functions for writing code that works in both:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d45a488bc737e1d5f6dede5db3709387006d1acf" translate="yes" xml:space="preserve">
          <source>Assert &lt;code&gt;x&lt;/code&gt; has rank equal to &lt;code&gt;rank&lt;/code&gt; or higher.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1af210672fd2e8191d0475081f63889272313458" translate="yes" xml:space="preserve">
          <source>Assert &lt;code&gt;x&lt;/code&gt; has rank equal to &lt;code&gt;rank&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c5ea1557e1f4e48f059d2133985575132b3c30d6" translate="yes" xml:space="preserve">
          <source>Assert &lt;code&gt;x&lt;/code&gt; has rank in &lt;code&gt;ranks&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75a22a7c18253fb409c8efec8464addc96cc3eeb" translate="yes" xml:space="preserve">
          <source>Assert element values are all greater than a target value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b860ff24d74dc7f5a638fa5fa667ec3253009cf3" translate="yes" xml:space="preserve">
          <source>Assert element values are all greater than or equal to a target value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de18e62bc32b196a239950419d1f8388fac532ac" translate="yes" xml:space="preserve">
          <source>Assert element values are all less than a target value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b10013e316156ceb95372fd12600d806c0cb2e0f" translate="yes" xml:space="preserve">
          <source>Assert element values are all less than or equal to a target value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b257d645a0e38e6fdd04fcb4625b59781955891d" translate="yes" xml:space="preserve">
          <source>Assert ndarray data type is equal to expected.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e2dd5e8d4d9ac571495586bb5a8330969a0432c8" translate="yes" xml:space="preserve">
          <source>Assert tensor shapes and dimension size relationships between tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be540434b2bf923639eb1611345e835e54ecc4f0" translate="yes" xml:space="preserve">
          <source>Assert that &lt;code&gt;x&lt;/code&gt; has a rank in &lt;code&gt;ranks&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc41af99ff2c324ddb6b8c0ed6b7224ec606dad3" translate="yes" xml:space="preserve">
          <source>Assert that &lt;code&gt;x&lt;/code&gt; has rank equal to &lt;code&gt;rank&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3b9be6a9f6bf09683fc74472ecfdeea3a9e1521" translate="yes" xml:space="preserve">
          <source>Assert that &lt;code&gt;x&lt;/code&gt; has rank of at least &lt;code&gt;rank&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9cf3fd3f2432582f3d8865f95299b1dfab71da9d" translate="yes" xml:space="preserve">
          <source>Assert that &lt;code&gt;x&lt;/code&gt; is of integer dtype.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65117d3cf865a50fd703edaa53cfc50dad6e01d8" translate="yes" xml:space="preserve">
          <source>Assert that actual.startswith(expected_start) is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eeea1f0d33c3a55ddacefaae856a6434820be341" translate="yes" xml:space="preserve">
          <source>Assert that elements in a Tensor are all in a given range.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7482390025bb1597949bc51945d168ea3f2c96a1" translate="yes" xml:space="preserve">
          <source>Assert that elements of a Tensor are all in a given closed set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f010f67ad78e93d40f92b6415f85b07d94106d7b" translate="yes" xml:space="preserve">
          <source>Assert that the tensor does not contain any NaN's or Inf's.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d7834b2eb7392181a3ea7175d3736e0a21b59528" translate="yes" xml:space="preserve">
          <source>Assert that two numpy arrays, or Tensors, do not have near values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fde1486ea5790a86387babddde8237842342fce6" translate="yes" xml:space="preserve">
          <source>Assert the condition &lt;code&gt;x != y&lt;/code&gt; holds element-wise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10d225bb6dc3e0b0d24bb630a4e31c3ed9981407" translate="yes" xml:space="preserve">
          <source>Assert the condition &lt;code&gt;x != y&lt;/code&gt; holds for all elements.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8ca7a0425a726a137cba91c1cac1cf114013585" translate="yes" xml:space="preserve">
          <source>Assert the condition &lt;code&gt;x &amp;gt; 0&lt;/code&gt; holds element-wise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c6cc4607589d1b19634018c077376c08b85db22" translate="yes" xml:space="preserve">
          <source>Assert the condition &lt;code&gt;x &amp;gt; y&lt;/code&gt; holds element-wise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04007f6eb566ef87ffcc0d4a23b511001e76822a" translate="yes" xml:space="preserve">
          <source>Assert the condition &lt;code&gt;x &amp;gt;= 0&lt;/code&gt; holds element-wise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1486bc5ff53e4ede7835c1d8b94ec8154a23a1ff" translate="yes" xml:space="preserve">
          <source>Assert the condition &lt;code&gt;x &amp;gt;= y&lt;/code&gt; holds element-wise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cee58e8741277ca46d3c4399a608f21457addecf" translate="yes" xml:space="preserve">
          <source>Assert the condition &lt;code&gt;x &amp;lt; 0&lt;/code&gt; holds element-wise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca7e54c653a78bedf703f41bf80dbd025995c05e" translate="yes" xml:space="preserve">
          <source>Assert the condition &lt;code&gt;x &amp;lt; y&lt;/code&gt; holds element-wise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2b12e7baaf664f0c04715097a4e025f58674eed" translate="yes" xml:space="preserve">
          <source>Assert the condition &lt;code&gt;x &amp;lt;= 0&lt;/code&gt; holds element-wise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="feabcb54d482d8c244c83a5ea766c82863cf205f" translate="yes" xml:space="preserve">
          <source>Assert the condition &lt;code&gt;x &amp;lt;= y&lt;/code&gt; holds element-wise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3433a0305e0cee314edfef60291ac38e08138d55" translate="yes" xml:space="preserve">
          <source>Assert the condition &lt;code&gt;x == y&lt;/code&gt; holds element-wise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8599a8fb24f8dfdea5c6ea730c17e898a478f2c2" translate="yes" xml:space="preserve">
          <source>Assert the condition &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are close element-wise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a42441c349b7bd38d1695189fc7bc6bf3aa17236" translate="yes" xml:space="preserve">
          <source>Assertion failed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2fe4e54c0726687ff23e5da4efeaaa0a9f0f4d9d" translate="yes" xml:space="preserve">
          <source>Asserts &lt;code&gt;global_step_tensor&lt;/code&gt; is a scalar int &lt;code&gt;Variable&lt;/code&gt; or &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e10bf0d97856f8fa0eeb141a104b108e5a02e41c" translate="yes" xml:space="preserve">
          <source>Asserts a shell command fails and the error matches a regex in a list.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69f2f4aede977d6431a1b2da061dd5f05949efe4" translate="yes" xml:space="preserve">
          <source>Asserts that &quot;container&quot; contains &quot;subsequence&quot; as a subsequence.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="59d7f6452194bfa31be4848b64d1ee0104b3cda9" translate="yes" xml:space="preserve">
          <source>Asserts that &quot;container&quot; contains &quot;subsequence&quot; as an exact subsequence.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6be7923de285fdec6e7923105446778fce606368" translate="yes" xml:space="preserve">
          <source>Asserts that &quot;container&quot; contains all the elements of &quot;subsequence&quot;, in order, and without other elements interspersed. For example, [1, 2, 3] is an exact subsequence of [0, 0, 1, 2, 3, 0] but not of [0, 0, 1, 2, 0, 3, 0].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3092f417077e5d72f4794a55a87dba46443aadc6" translate="yes" xml:space="preserve">
          <source>Asserts that &quot;container&quot; contains all the elements of &quot;subsequence&quot;, in order, but possibly with other elements interspersed. For example, [1, 2, 3] is a subsequence of [0, 0, 1, 2, 0, 3, 0] but not of [0, 0, 1, 3, 0, 2, 0].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c28cbbb5abec6a4c6b4ffd4da95b8bd15a918eaf" translate="yes" xml:space="preserve">
          <source>Asserts that a Numpy ndarray and a TensorFlow tensor have the same shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ccb81584c212beaa430e6512ec976af3536e8fb3" translate="yes" xml:space="preserve">
          <source>Asserts that a shell command succeeds (i.e. exits with code 0).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df4dac6414ae21eb7bb8fac61abfbe8c3a34962e" translate="yes" xml:space="preserve">
          <source>Asserts that actual.endswith(expected_end) is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67c77c2c54104331cd0d2fd0285ae73e94114232" translate="yes" xml:space="preserve">
          <source>Asserts that actual.endswith(unexpected_end) is False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b76aea4222310f368a71d34488b49a87b39b0f80" translate="yes" xml:space="preserve">
          <source>Asserts that actual.startswith(unexpected_start) is False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3ae16f703d4d758e595b81c433b5df1a027aa49" translate="yes" xml:space="preserve">
          <source>Asserts that an object has non-zero length.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfcbd3a7a3d704f4ed8a5cab9580e989f6bde17a" translate="yes" xml:space="preserve">
          <source>Asserts that an object has the expected length.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84e64b64d6dcaf5e07d90f28654eac37719ba950" translate="yes" xml:space="preserve">
          <source>Asserts that an object has zero length.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b318eda77755b4102ae7fc109f7fe1df5bddbd0" translate="yes" xml:space="preserve">
          <source>Asserts that at least one regex in regexes matches str.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d2674f0f06ac80ca91a3de033393c07763b0eaf" translate="yes" xml:space="preserve">
          <source>Asserts that message is same as parsed expected_message_ascii.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="efc53871b1ae31fa92cc330bd22797036a9e29d2" translate="yes" xml:space="preserve">
          <source>Asserts that the JSON objects defined in two strings are equal.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d18c25f38b57c16cae7f5e69f980cfe6fb25056" translate="yes" xml:space="preserve">
          <source>Asserts that the given &lt;code&gt;Tensor&lt;/code&gt; is of the specified type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62e06e61689a22ac579dcd8134c6a03cdf615eef" translate="yes" xml:space="preserve">
          <source>Asserts that the given &lt;code&gt;tensor&lt;/code&gt; is a scalar (i.e. zero-dimensional).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9552cc7700c29f723bed87989ba67a997ed05a8" translate="yes" xml:space="preserve">
          <source>Asserts that the given &lt;code&gt;tensor&lt;/code&gt; is a scalar.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1945c0aa8211a04b1d39ca505afc23878f03082e" translate="yes" xml:space="preserve">
          <source>Asserts that the given condition is true.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc9d70440cff4fb0f2553d86b5b3c9dd7a6ebdb7" translate="yes" xml:space="preserve">
          <source>Asserts that the message in a raised exception equals the given string.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3c3e9d99715c0a20a4f1e32f289caf0985d5b65" translate="yes" xml:space="preserve">
          <source>Asserts that the message in a raised exception matches a regex.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="024142d4d4a306ca5dc2d7f04946f70cab4a922e" translate="yes" xml:space="preserve">
          <source>Asserts that the message in a triggered warning matches a regexp. Basic functioning is similar to assertWarns() with the addition that only warnings whose messages also match the regular expression are considered successful matches.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64ed6e139b69bab2010db8561d296812d3fcc2a0" translate="yes" xml:space="preserve">
          <source>Asserts that the strings provided are found in the target in order.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="520c64436037ba34dd942c92c1b51f5a9e8b5451" translate="yes" xml:space="preserve">
          <source>Asserts that the two given devices are the same.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d24619fd3be6d0527f469281e097fffb11ba6d9b" translate="yes" xml:space="preserve">
          <source>Asserts that total ordering has been implemented correctly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94eab101a0c591a4056c61189d905f60990fcb77" translate="yes" xml:space="preserve">
          <source>Asserts that two &lt;code&gt;GraphDef&lt;/code&gt;s are (mostly) the same.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21e6a83414cb6873c47b8c7dcb7e2ea497382917" translate="yes" xml:space="preserve">
          <source>Asserts that two float arrays are near each other.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8714ee0dfa3727fb6a0faa59f505f391b10354a7" translate="yes" xml:space="preserve">
          <source>Asserts that two floats are near each other.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="173c361341ab6c7ec8251302259509a11dccfe33" translate="yes" xml:space="preserve">
          <source>Asserts that two multi-line strings are equal.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87f1b29a37d0a5fa4b98c7ff8003240fb16ba9d1" translate="yes" xml:space="preserve">
          <source>Asserts that two numpy arrays have near values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6087803354414efd307f45a4d3825523474a404e" translate="yes" xml:space="preserve">
          <source>Asserts that two numpy arrays or Tensors do not have the same values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8563e4ab597c58334b9dd1f0ddf7499de74e1ac3" translate="yes" xml:space="preserve">
          <source>Asserts that two numpy arrays or Tensors have the same values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="beeb78717d0b6788c5a9502c97bcbc4c4d9b5dde" translate="yes" xml:space="preserve">
          <source>Asserts that two sequences have the same elements (in any order).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d71ad08e0dbb2f2f7a6eddecbbf1432aeec1931b" translate="yes" xml:space="preserve">
          <source>Asserts that two structures are nested in the same way.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43ab885ba56e639e9028c492f6ca84f8a32693c3" translate="yes" xml:space="preserve">
          <source>Asserts that two structures of numpy arrays or Tensors, have near values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8ad9604199233d6f49650754a5f6aa048f8dca3" translate="yes" xml:space="preserve">
          <source>Asserts that two values contain the same structural content.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c119b9699a32942987d2047ad7cfbf051fe61de" translate="yes" xml:space="preserve">
          <source>Asserts that urls are equal, ignoring ordering of query params.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f47b84d85cfc82a0411c324b96808e9b237a2bb" translate="yes" xml:space="preserve">
          <source>Asserts that value is between minv and maxv (inclusive).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ec26f2730dee86065167e3466463fe260673ba3" translate="yes" xml:space="preserve">
          <source>Assignment map supports following syntax:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66f988dfed011799e1ce8edd62edeebbed9781ba" translate="yes" xml:space="preserve">
          <source>Assigns &lt;a href=&quot;../../indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt; to this variable batch-wise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ffea0c7d9fe1b5f4d911a9d928c8e496a309fdf" translate="yes" xml:space="preserve">
          <source>Assigns &lt;a href=&quot;../../indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt; to this variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b58b4608811536fec4da502146b6fc8391861343" translate="yes" xml:space="preserve">
          <source>Assigns &lt;a href=&quot;indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt; to this variable batch-wise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a9623292bc8a42a567c500fd1c657357201bd56" translate="yes" xml:space="preserve">
          <source>Assigns &lt;a href=&quot;indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt; to this variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="59833741942f09d47d6d269c0016820d532ea10b" translate="yes" xml:space="preserve">
          <source>Assigns a new value to the variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3ab79b168a33e48f7f2d1af963384acb24b8505" translate="yes" xml:space="preserve">
          <source>Associates &lt;code&gt;keys&lt;/code&gt; with &lt;code&gt;values&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6972e35f2682c3c47b76ff19583ae8d7aa1684d2" translate="yes" xml:space="preserve">
          <source>Associates a string prefix with an integer counter in a TensorFlow graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e24a1a623a03db282049375fe95f8f3ec9b8b9e8" translate="yes" xml:space="preserve">
          <source>Associates the given statistics aggregator with the dataset pipeline.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef8986471f69df663859a316499adf1546db37ad" translate="yes" xml:space="preserve">
          <source>Assume &lt;code&gt;diagonal&lt;/code&gt; has dimensions [D1,..., Dk], then the output is a tensor of rank 2k with dimensions [D1,..., Dk, D1,..., Dk] where:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d3f2f771a63e5c218fee12e248d4de6a1ccd7a2" translate="yes" xml:space="preserve">
          <source>Assume &lt;code&gt;input&lt;/code&gt; has &lt;code&gt;r&lt;/code&gt; dimensions &lt;code&gt;[I, J, ..., L, M, N]&lt;/code&gt;. Let &lt;code&gt;max_diag_len&lt;/code&gt; be the maximum length among all diagonals to be extracted, &lt;code&gt;max_diag_len = min(M + min(k[1], 0), N + min(-k[0], 0))&lt;/code&gt; Let &lt;code&gt;num_diags&lt;/code&gt; be the number of diagonals to extract, &lt;code&gt;num_diags = k[1] - k[0] + 1&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d937b1330f7e3a7fccf78581cb0ca023983fbb32" translate="yes" xml:space="preserve">
          <source>Assume &lt;code&gt;input&lt;/code&gt; has dimensions &lt;code&gt;[D1,..., Dk, D1,..., Dk]&lt;/code&gt;, then the output is a tensor of rank &lt;code&gt;k&lt;/code&gt; with dimensions &lt;code&gt;[D1,..., Dk]&lt;/code&gt; where:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dbc135573ab1e3d7bd01504214d953191343e542" translate="yes" xml:space="preserve">
          <source>Assume &lt;code&gt;x = [[1, 2], [3, 4]]&lt;/code&gt; and &lt;code&gt;y = [[5, 6], [7, 8]]&lt;/code&gt;&lt;code&gt;batch_dot(x, y, axes=1) = [[17], [53]]&lt;/code&gt; which is the main diagonal of &lt;code&gt;x.dot(y.T)&lt;/code&gt;, although we never have to calculate the off-diagonal elements.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a82fcc1b411c5f4bec45984841441f39fc502ff7" translate="yes" xml:space="preserve">
          <source>Assume the input is type float and has a possible range of [0.0, 6.0] and the output type is quint8 ([0, 255]). The min_range and max_range values should be specified as 0.0 and 6.0. Quantizing from float to quint8 will multiply each value of the input by 255/6 and cast to quint8.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a43de36b03a7d6fa9c2271032015cd9c1887196" translate="yes" xml:space="preserve">
          <source>Assumes that all arguments of the decorated function are Tensors which will be batched along their first dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a07e095c072e16bbf92a14147cf5b22948273245" translate="yes" xml:space="preserve">
          <source>Assumes the two SparseTensors have the same shape, i.e., no broadcasting. Example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a6048755ec3c0b2b81eb6e99c8ef91a13bc46642" translate="yes" xml:space="preserve">
          <source>Assuming the variable has rank &lt;code&gt;P&lt;/code&gt; and &lt;code&gt;indices&lt;/code&gt; is a &lt;code&gt;Tensor&lt;/code&gt; of rank &lt;code&gt;Q&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14299efb36d995924c964a8f3937d4d9dc1117d4" translate="yes" xml:space="preserve">
          <source>At least one of &lt;code&gt;context_features&lt;/code&gt; and &lt;code&gt;sequence_features&lt;/code&gt; must be provided and non-empty.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba42f173911840b373dc352dfed26ea9c9493518" translate="yes" xml:space="preserve">
          <source>At runtime, this operation may raise an error if the queue is &lt;code&gt;tf.QueueBase.close&lt;/code&gt; before or during its execution. If the queue is closed before this operation runs, &lt;a href=&quot;../errors/cancellederror&quot;&gt;&lt;code&gt;tf.errors.CancelledError&lt;/code&gt;&lt;/a&gt; will be raised. If this operation is blocked, and either (i) the queue is closed by a close operation with &lt;code&gt;cancel_pending_enqueues=True&lt;/code&gt;, or (ii) the session is &lt;code&gt;tf.Session.close&lt;/code&gt;, &lt;a href=&quot;../errors/cancellederror&quot;&gt;&lt;code&gt;tf.errors.CancelledError&lt;/code&gt;&lt;/a&gt; will be raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36864f335118b67b813f060a89d4d032543b0391" translate="yes" xml:space="preserve">
          <source>At runtime, this operation may raise an error if the queue is &lt;code&gt;tf.QueueBase.close&lt;/code&gt; before or during its execution. If the queue is closed, the queue contains fewer than &lt;code&gt;n&lt;/code&gt; elements, and there are no pending enqueue operations that can fulfill this request, &lt;a href=&quot;../errors/outofrangeerror&quot;&gt;&lt;code&gt;tf.errors.OutOfRangeError&lt;/code&gt;&lt;/a&gt; will be raised. If the session is &lt;code&gt;tf.Session.close&lt;/code&gt;, &lt;a href=&quot;../errors/cancellederror&quot;&gt;&lt;code&gt;tf.errors.CancelledError&lt;/code&gt;&lt;/a&gt; will be raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="387be58bfc36101fa592ef12e56fa7f1d2c11e77" translate="yes" xml:space="preserve">
          <source>At runtime, this operation may raise an error if the queue is &lt;code&gt;tf.QueueBase.close&lt;/code&gt; before or during its execution. If the queue is closed, the queue is empty, and there are no pending enqueue operations that can fulfill this request, &lt;a href=&quot;../errors/outofrangeerror&quot;&gt;&lt;code&gt;tf.errors.OutOfRangeError&lt;/code&gt;&lt;/a&gt; will be raised. If the session is &lt;code&gt;tf.Session.close&lt;/code&gt;, &lt;a href=&quot;../errors/cancellederror&quot;&gt;&lt;code&gt;tf.errors.CancelledError&lt;/code&gt;&lt;/a&gt; will be raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ca13d7ae60fdd1864898227f95546637d64c6ea" translate="yes" xml:space="preserve">
          <source>At this point graph is finalized and you can not add ops.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7abed489983670c0ae56f77cd92b63574f5eedbb" translate="yes" xml:space="preserve">
          <source>Atrous convolution (a.k.a. convolution with holes or dilated convolution).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bdb5968326d5c0301c96a47d471711fa3a10c0d0" translate="yes" xml:space="preserve">
          <source>Atrous convolution allows us to explicitly control how densely to compute feature responses in fully convolutional networks. Used in conjunction with bilinear interpolation, it offers an alternative to &lt;code&gt;conv2d_transpose&lt;/code&gt; in dense prediction tasks such as semantic image segmentation, optical flow computation, or depth estimation. It also allows us to effectively enlarge the field of view of filters without increasing the number of parameters or the amount of computation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4adb29275d47f57d08f206d05943dc5a5e26e87d" translate="yes" xml:space="preserve">
          <source>Attempts to apply a gradient to the accumulator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b95fa50ffd64d59ed1d0141a776f568b828312a5" translate="yes" xml:space="preserve">
          <source>Attempts to apply a sparse gradient to the accumulator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b79e5f9cf1c14514a9ad635ead08258b3e44d48" translate="yes" xml:space="preserve">
          <source>Attempts to extract the average gradient from the accumulator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebaf9ab6314004c5227148dc3e16b87bef99b8f2" translate="yes" xml:space="preserve">
          <source>Attention outputs of shape &lt;code&gt;[batch_size, Tq, dim]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1af1e2a4fb6a55abbb3d1a896aa3da78a432dec0" translate="yes" xml:space="preserve">
          <source>Attributes &lt;code&gt;[min; max]&lt;/code&gt; define the clamping range for the &lt;code&gt;inputs&lt;/code&gt; data. &lt;code&gt;inputs&lt;/code&gt; values are quantized into the quantization range (&lt;code&gt;[0; 2^num_bits - 1]&lt;/code&gt; when &lt;code&gt;narrow_range&lt;/code&gt; is false and &lt;code&gt;[1; 2^num_bits - 1]&lt;/code&gt; when it is true) and then de-quantized and output as floats in &lt;code&gt;[min; max]&lt;/code&gt; interval. &lt;code&gt;num_bits&lt;/code&gt; is the bitwidth of the quantization; between 2 and 16, inclusive.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8087185e5ee37cef4c337de5697d35d75d909fd" translate="yes" xml:space="preserve">
          <source>Attributes:</source>
          <target state="translated">Attributes:</target>
        </trans-unit>
        <trans-unit id="b5a16386e13db65b47f8784b34e000a063f98641" translate="yes" xml:space="preserve">
          <source>Auto profile and advise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="992cdcf5674bef1a4042c7f10b1a5855b0803528" translate="yes" xml:space="preserve">
          <source>Automatic differentiation and gradient tape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4498b4fc7edf7ae1f2828f7a292f614119808247" translate="yes" xml:space="preserve">
          <source>Automatically detect problems and generate reports.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="948c59e8ec0608333237892aa15f0ee562ca1779" translate="yes" xml:space="preserve">
          <source>Auxiliary function. Normal users should NOT use it directly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d323ce62ebf929f809bb1ffb3aa575874e9f10f1" translate="yes" xml:space="preserve">
          <source>Auxiliary function: clients should use the specialized DEFINE_</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fae75a7c40327ac910df198eff7674249ba6379f" translate="yes" xml:space="preserve">
          <source>Available penalties</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f492455c1faf531411d34599ac5ee635eb1828d9" translate="yes" xml:space="preserve">
          <source>Available properties:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4b7430e84ba2c09911562197af3421f8220100c1" translate="yes" xml:space="preserve">
          <source>Average Pooling layer for 1D inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31d58b4f975c33a092b235af97514c06440a3225" translate="yes" xml:space="preserve">
          <source>Average Pooling layer for 1D inputs. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9027fb82b44f7b9a50a6b6567f51aef5714402d5" translate="yes" xml:space="preserve">
          <source>Average pooling for temporal data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31a7f0022b7553f219fb123d1288878d08e7e6ec" translate="yes" xml:space="preserve">
          <source>Average pooling layer for 2D inputs (e.g. images).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="228467c36d802020e6a50ef423c1d7bee18a3560" translate="yes" xml:space="preserve">
          <source>Average pooling layer for 2D inputs (e.g. images). (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b8f6f49c6edf4fc30624814db77d7aee5858b45" translate="yes" xml:space="preserve">
          <source>Average pooling layer for 3D inputs (e.g. volumes).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9045abb993f9544d925b0ce29daa518f77a198a" translate="yes" xml:space="preserve">
          <source>Average pooling layer for 3D inputs (e.g. volumes). (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d20f4a5b17e69d912c56ea8e6e67f1b868eb143" translate="yes" xml:space="preserve">
          <source>Average pooling operation for 3D data (spatial or spatio-temporal).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cde300f76cb7056d67862c163371ddd3e355beed" translate="yes" xml:space="preserve">
          <source>Average pooling operation for spatial data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6489a3ab471682f593ff67d3e0ed2f8944824d0" translate="yes" xml:space="preserve">
          <source>Backpropagation will happen into both &lt;code&gt;logits&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt;. To disallow backpropagation into &lt;code&gt;labels&lt;/code&gt;, pass label tensors through &lt;a href=&quot;../../../stop_gradient&quot;&gt;&lt;code&gt;tf.stop_gradient&lt;/code&gt;&lt;/a&gt; before feeding it to this function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bfbe94bf3cd74c9e82c8634545237d1925719616" translate="yes" xml:space="preserve">
          <source>Backpropagation will happen into both &lt;code&gt;logits&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt;. To disallow backpropagation into &lt;code&gt;labels&lt;/code&gt;, pass label tensors through &lt;a href=&quot;../stop_gradient&quot;&gt;&lt;code&gt;tf.stop_gradient&lt;/code&gt;&lt;/a&gt; before feeding it to this function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="384bd9f444979908d512542977683954f1e80431" translate="yes" xml:space="preserve">
          <source>Backpropagation will happen only into &lt;code&gt;logits&lt;/code&gt;. To calculate a cross entropy loss that allows backpropagation into both &lt;code&gt;logits&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt;, see &lt;code&gt;tf.nn.softmax_cross_entropy_with_logits_v2&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f411e0d841c5ca3a5c88ff91e6437ff9c34bb547" translate="yes" xml:space="preserve">
          <source>Base TFDecorator class and utility functions for working with decorators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08d7d3e364fabef4a88d9d7d8c44d0d4ee9f639b" translate="yes" xml:space="preserve">
          <source>Base class defining a [batch of] linear operator[s].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c973fbfcf6f1fbe20eefa93bc901103b67dc423" translate="yes" xml:space="preserve">
          <source>Base class for PreprocessingLayers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a379239342de7ee8a8ba5ecd3417480c9b88542a" translate="yes" xml:space="preserve">
          <source>Base class for a parser of lists of strings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcff466bdb76d5cd56301373a6fd447a7707bd69" translate="yes" xml:space="preserve">
          <source>Base class for all TensorFlow decorators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41c0157be9be0927c826272dcb69693b6a8f2f47" translate="yes" xml:space="preserve">
          <source>Base class for cross-device reduction and broadcasting algorithms.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c0969d31a64efd335c23c281572c31f4ebe0dce" translate="yes" xml:space="preserve">
          <source>Base class for different Reader types, that produce a record every step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7209bc777071c54896c4c7d3dbecaf443c76968f" translate="yes" xml:space="preserve">
          <source>Base class for generating string representations of a flag value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="442a74d7ee316026f06f08bb198421bd45cbd736" translate="yes" xml:space="preserve">
          <source>Base class for image data iterators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cbbd31461d2a1dc034f299db7aecef80a1718d78" translate="yes" xml:space="preserve">
          <source>Base class for optimizers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="690066cc91d51598a899ae4209affb789c9cb523" translate="yes" xml:space="preserve">
          <source>Base class for queue implementations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a141f5fe908e5a2754efba45b8e6ea7dbe0c1c48" translate="yes" xml:space="preserve">
          <source>Base class for recurrent layers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="accfd08b9028b06ae9f9025deb6755d1c4348fc2" translate="yes" xml:space="preserve">
          <source>Base class for stack trace transformation functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3cade7141245bc019f7556b700c800818c890e1a" translate="yes" xml:space="preserve">
          <source>Base class for tests that need to test TensorFlow.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="59b263f6c35738c18a2cd12a1d2d972d4531d12e" translate="yes" xml:space="preserve">
          <source>Base class to enqueue inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a173e1a40aeb69111140ddfe7f83615ef9d9082" translate="yes" xml:space="preserve">
          <source>Base class used to parse and convert arguments.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5477b66c0624b86adac8ef6bc5a494c2e99c638" translate="yes" xml:space="preserve">
          <source>Base layer class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d7eed87c6d5c15c15ca5453ef20462da4e2cc9ea" translate="yes" xml:space="preserve">
          <source>Base neural network module class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76abebe07ffc1c33faf38ae547a2788581a0ab3c" translate="yes" xml:space="preserve">
          <source>Base object for fitting to a sequence of data, such as a dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f71c6d2b99647a5453df997e48fcc1fcbbd4f5c4" translate="yes" xml:space="preserve">
          <source>Based on available runtime hardware and constraints, this layer will choose different implementations (cuDNN-based or pure-TensorFlow) to maximize the performance. If a GPU is available and all the arguments to the layer meet the requirement of the CuDNN kernel (see below for details), the layer will use a fast cuDNN implementation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="965255859567ff020b4b4b04f69fbcf4e5fbd545" translate="yes" xml:space="preserve">
          <source>Basic LSTM recurrent network cell.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11aeba230e12e10feea755efa31528967c88652b" translate="yes" xml:space="preserve">
          <source>Basic arithmetic operators and trigonometric functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="169b02041823a1a41517ab92b5b604fa3bcceb49" translate="yes" xml:space="preserve">
          <source>Basic boolean flag.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e5fe395595ce6ea87fa20a363006e4efdc056a3" translate="yes" xml:space="preserve">
          <source>Basic enum flag; its value can be any string from list of enum_values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4900e53840866a1677080e960e64754a54c4358" translate="yes" xml:space="preserve">
          <source>Basic enum flag; its value is an enum class's member.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="18a6ba09f74578bf0981118bd1ccac104e93a645" translate="yes" xml:space="preserve">
          <source>Basic example of sharing a variable AUTO_REUSE:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc711b10f8f37fc7ebbaf588027590a21b7c1aef" translate="yes" xml:space="preserve">
          <source>Basic example of sharing a variable with reuse=True:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2d358bd92c715a1c6d50e28e13bf3dac4175837" translate="yes" xml:space="preserve">
          <source>Basic loop to train a model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a50707dcb44e3cc6a0f0a34b284724230364173" translate="yes" xml:space="preserve">
          <source>Basic regression: Predict fuel efficiency</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72fb61266edb5b0b569c8cbc7f9cdf38679604c8" translate="yes" xml:space="preserve">
          <source>Batch Normalization layer from http://arxiv.org/abs/1502.03167.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58141cf3441de640d9f9874b9119228df26b6c58" translate="yes" xml:space="preserve">
          <source>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a20c9929b1054521c7fd69bb31f38604e8cd28a" translate="yes" xml:space="preserve">
          <source>Batch normalization differs from other layers in several key aspects:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c4d2c2631af3b346e1d1f53c80e33fb55bc9d30" translate="yes" xml:space="preserve">
          <source>Batch normalization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2a8d885a08f8a435ed1af319b8041cd0665c222" translate="yes" xml:space="preserve">
          <source>Batch reduction is done by reduction on each element one by one.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1eb845becc3466807fcb11bf0de305e06e2f51c7" translate="yes" xml:space="preserve">
          <source>Batch shape describes independent, not identically distributed draws, aka a &quot;collection&quot; or &quot;bunch&quot; of distributions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac3439be9f297d92865420cbc7f5771a4b205755" translate="yes" xml:space="preserve">
          <source>BatchToSpace for 4-D tensors of type T.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89cf6d89420e01dc5690feb682f6dcf0b8c08691" translate="yes" xml:space="preserve">
          <source>BatchToSpace for N-D tensors of type T.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0121072773e00d2e0aa74b5252959e4a69a120b3" translate="yes" xml:space="preserve">
          <source>Batched indexing into a 3-tensor:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31ecf9a347c9c1a4178974c0c60cdb506adaf6a0" translate="yes" xml:space="preserve">
          <source>Batched indexing into a matrix:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="539aa4e37b2c424abaa136ce3ad585b11d27d9c2" translate="yes" xml:space="preserve">
          <source>Batched slice indexing into a matrix:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8bddd29bcd2c5dc8ae67a3c0a5fdefd445f5b6e2" translate="yes" xml:space="preserve">
          <source>Batches the computation done by the decorated function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60ed4fdebfb60ae2841512b0bd4ae80f24563f02" translate="yes" xml:space="preserve">
          <source>Batchwise dot product.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3129edc8cc77bcfcaec8e0d8dc0bb967e5958b80" translate="yes" xml:space="preserve">
          <source>Be sure to set the input sizes, allocate tensors and fill values before calling this. Also, note that this function releases the GIL so heavy computation can be done in the background while the Python interpreter continues. No other function on this object should be called while the invoke() call has not finished.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14704ff9c6b1dda614adca922a951420e0f352d1" translate="yes" xml:space="preserve">
          <source>Be sure to shard before you use any randomizing operator (such as shuffle).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d202e1e983a5c7105a4ff47936664330f015606e" translate="yes" xml:space="preserve">
          <source>Because &lt;a href=&quot;../../constant&quot;&gt;&lt;code&gt;tf.constant&lt;/code&gt;&lt;/a&gt; only embeds constant values in the graph, it does not support dynamic shapes based on other runtime Tensors, whereas &lt;a href=&quot;../../fill&quot;&gt;&lt;code&gt;tf.fill&lt;/code&gt;&lt;/a&gt; does.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42c0768bfee03dc7b10a5292ad331efb6146374b" translate="yes" xml:space="preserve">
          <source>Because &lt;a href=&quot;fill&quot;&gt;&lt;code&gt;tf.fill&lt;/code&gt;&lt;/a&gt; evaluates at graph runtime, it supports dynamic shapes based on other runtime Tensors, unlike &lt;a href=&quot;constant&quot;&gt;&lt;code&gt;tf.constant&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ffa9f95c3924abf5eef652797fb754b31af504c" translate="yes" xml:space="preserve">
          <source>Because &lt;a href=&quot;vectorized_map&quot;&gt;&lt;code&gt;tf.vectorized_map&lt;/code&gt;&lt;/a&gt; fully parallelizes the batch, this method will generally be significantly faster than using &lt;a href=&quot;map_fn&quot;&gt;&lt;code&gt;tf.map_fn&lt;/code&gt;&lt;/a&gt;, especially in eager mode. However this is an experimental feature and currently has a lot of limitations: - There should be no data dependency between the different semantic invocations of &lt;code&gt;fn&lt;/code&gt;, i.e. it should be safe to map the elements of the inputs in any order. - Stateful kernels may mostly not be supported since these often imply a data dependency. We do support a limited set of such stateful kernels though (like RandomFoo, Variable operations like reads, etc). - &lt;code&gt;fn&lt;/code&gt; has limited support for control flow operations. &lt;a href=&quot;cond&quot;&gt;&lt;code&gt;tf.cond&lt;/code&gt;&lt;/a&gt; in particular is not supported. - &lt;code&gt;fn&lt;/code&gt; should return nested structure of Tensors or Operations. However if an Operation is returned, it should have zero outputs. - The shape and dtype of any intermediate or output tensors in the computation of &lt;code&gt;fn&lt;/code&gt; should not depend on the input to &lt;code&gt;fn&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="333f1764c386ba0a8da0f6422ba442f736a4680d" translate="yes" xml:space="preserve">
          <source>Because &lt;code&gt;space_to_batch_nd&lt;/code&gt; and &lt;code&gt;batch_to_space_nd&lt;/code&gt; assume that the spatial dimensions are contiguous starting at the second dimension, but the specified &lt;code&gt;spatial_dims&lt;/code&gt; may not be, we must adjust &lt;code&gt;dilation_rate&lt;/code&gt;, &lt;code&gt;paddings&lt;/code&gt; and &lt;code&gt;crops&lt;/code&gt; in order to be usable with these operations. For a given dimension, if the block size is 1, and both the starting and ending padding and crop amounts are 0, then space_to_batch_nd effectively leaves that dimension alone, which is what is needed for dimensions not part of &lt;code&gt;spatial_dims&lt;/code&gt;. Furthermore, &lt;code&gt;space_to_batch_nd&lt;/code&gt; and &lt;code&gt;batch_to_space_nd&lt;/code&gt; handle this case efficiently for any number of leading and trailing dimensions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f357d4f95bd4f90d893517d9633696cf691ebed" translate="yes" xml:space="preserve">
          <source>Because scale_layer does not directly track the &lt;code&gt;scale&lt;/code&gt; variable, it will not appear in &lt;code&gt;scale_layer.trainable_weights&lt;/code&gt; and will therefore not be trained if &lt;code&gt;scale_layer&lt;/code&gt; is used in a Model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="918afe8e4eb37bded09112c699cfd2864f21ea4f" translate="yes" xml:space="preserve">
          <source>Because validation happens at app.run() we want to ensure required-ness is enforced at that time. You generally do not want to force users who import your code to have additional required flags for their own binaries or tests.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cac1071eeb0fa549d93e5ad3404fa9149a632df6" translate="yes" xml:space="preserve">
          <source>Before each run the thread checks if the coordinator has requested stop. In that case the looper thread terminates immediately.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc533b09fcc49b30b51ee5c7bbeec77413bf4ce1" translate="yes" xml:space="preserve">
          <source>Before quantization, &lt;code&gt;min&lt;/code&gt; and &lt;code&gt;max&lt;/code&gt; values are adjusted with the following logic. It is suggested to have &lt;code&gt;min &amp;lt;= 0 &amp;lt;= max&lt;/code&gt;. If &lt;code&gt;0&lt;/code&gt; is not in the range of values, the behavior can be unexpected: If &lt;code&gt;0 &amp;lt; min &amp;lt; max&lt;/code&gt;: &lt;code&gt;min_adj = 0&lt;/code&gt; and &lt;code&gt;max_adj = max - min&lt;/code&gt;. If &lt;code&gt;min &amp;lt; max &amp;lt; 0&lt;/code&gt;: &lt;code&gt;min_adj = min - max&lt;/code&gt; and &lt;code&gt;max_adj = 0&lt;/code&gt;. If &lt;code&gt;min &amp;lt;= 0 &amp;lt;= max&lt;/code&gt;: &lt;code&gt;scale = (max - min) / (2^num_bits - 1)&lt;/code&gt;, &lt;code&gt;min_adj = scale * round(min / scale)&lt;/code&gt; and &lt;code&gt;max_adj = max + min_adj - min&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c215352a2064b7badee93877aca52e6befa7891c" translate="yes" xml:space="preserve">
          <source>Before running the graph on TPU, the TPU system needs to be initialized. If TensorFlow Serving model-server is used, this is done automatically. If not, please use &lt;code&gt;session.run(tpu.initialize_system())&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98b07bd94c22bcb5d52967cf93a063428fa2459f" translate="yes" xml:space="preserve">
          <source>Before this op is executed, TensorFlow will ensure that the operations in &lt;code&gt;self.control_inputs&lt;/code&gt; have finished executing. This mechanism can be used to run ops sequentially for performance reasons, or to ensure that the side effects of an op are observed in the correct order.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf9af489cd12e4ede7a06bfc7ab06b9ecddcae20" translate="yes" xml:space="preserve">
          <source>Behavior is the same as in &lt;code&gt;get_variable&lt;/code&gt;, except that variables are added to the &lt;code&gt;LOCAL_VARIABLES&lt;/code&gt; collection and &lt;code&gt;trainable&lt;/code&gt; is set to &lt;code&gt;False&lt;/code&gt;. This function prefixes the name with the current variable scope and performs reuse checks. See the &lt;a href=&quot;https://tensorflow.org/guide/variables&quot;&gt;Variable Scope How To&lt;/a&gt; for an extensive description of how reusing works. Here is a basic example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7221a2669bbe6dd82d25a4ff51d35581067170d" translate="yes" xml:space="preserve">
          <source>Below is a 4 x 4 example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ba708034a17ec90e5ce69e1a09187b71afe6557" translate="yes" xml:space="preserve">
          <source>Below is a rough speed comparison between &lt;code&gt;sparse_tensor_dense_matmul&lt;/code&gt;, labeled 'sparse', and &lt;code&gt;matmul&lt;/code&gt;(a_is_sparse=True), labeled 'dense'. For purposes of the comparison, the time spent converting from a &lt;code&gt;SparseTensor&lt;/code&gt; to a dense &lt;code&gt;Tensor&lt;/code&gt; is not included, so it is overly conservative with respect to the time ratio.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7fe96ba367761a8535d5db7c2adaedf6e256be25" translate="yes" xml:space="preserve">
          <source>Below is a simple example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26f1f192e698c7ad5ba00a9c0f7254038e0138a2" translate="yes" xml:space="preserve">
          <source>Below is an example of such mapping:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93f725b3ba12879d32708e07d6bfd38fd23147da" translate="yes" xml:space="preserve">
          <source>Below we will use the following notation for each pair of matrix and right-hand sides in the batch:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6a801f4b37a9384f51049649a0b7a90550be15c" translate="yes" xml:space="preserve">
          <source>Benchmark system:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9428353e9aa57ed19a2a32caf5b27489b48d063" translate="yes" xml:space="preserve">
          <source>Bernoulli distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f03a338f7564e4e21a2867be1ad06f686f0be5f" translate="yes" xml:space="preserve">
          <source>Beta distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fdd12ab1a4ebe69be4bb2f17b70bb845d0d5a0a7" translate="yes" xml:space="preserve">
          <source>Better performance with tf.function</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e00808f64da3794423375c99ac4f888f849b578e" translate="yes" xml:space="preserve">
          <source>Better performance with tf.function and AutoGraph</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1f63f137fbcf8eb5b877bc0a5bbcceb3a1fe6a7" translate="yes" xml:space="preserve">
          <source>Better performance with the tf.data API</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f80ddc8371fc02363ef3b4d95e0f42b920820da" translate="yes" xml:space="preserve">
          <source>Bidirectional wrapper for RNNs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23498aef85e286e9d8f09eb213c1b9bb53939251" translate="yes" xml:space="preserve">
          <source>Bin will be incremented by the corresponding weight instead of 1. Here, index 1 in output has a value 6. This is the summation of weights corresponding to the value in &lt;code&gt;values&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9368f86c2aed09a12e0226a9d35288ab290da8cc" translate="yes" xml:space="preserve">
          <source>Binary crossentropy between an output tensor and a target tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0a37377942485fdf764a521fe238c8d0ed7d3cb" translate="yes" xml:space="preserve">
          <source>Bins the given values for use in a histogram.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6d9b186343317e12aa258806d17ad25e06a73f1" translate="yes" xml:space="preserve">
          <source>Bitcasts a tensor from one type to another without copying data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="931427c3d1697302f1b1ed892763576899fefcc7" translate="yes" xml:space="preserve">
          <source>Bitwise reduction (logical AND).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d03b11e77e9c0184173f7a829c9526f625ad046b" translate="yes" xml:space="preserve">
          <source>Bitwise reduction (logical OR).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc3e66bb35a901742662edb6ced928005d59773e" translate="yes" xml:space="preserve">
          <source>Block waiting for the coordinator to stop.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9903bcc52f6f86f49dfafd9e89072761eba18318" translate="yes" xml:space="preserve">
          <source>Blocks until the server has shut down.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05eba176b7d2b92c6a609ef12867053fcfc21bb7" translate="yes" xml:space="preserve">
          <source>Boolean &lt;code&gt;Tensor&lt;/code&gt;, equal to &lt;code&gt;True&lt;/code&gt; iff &lt;code&gt;x&lt;/code&gt; is non-decreasing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31fd2852d73c921d0e612baa59feb570fef287d2" translate="yes" xml:space="preserve">
          <source>Boolean &lt;code&gt;Tensor&lt;/code&gt;, equal to &lt;code&gt;True&lt;/code&gt; iff &lt;code&gt;x&lt;/code&gt; is strictly increasing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff37d99878003a25a62eaef08bda4aa9df374e60" translate="yes" xml:space="preserve">
          <source>Boolean flags do not take any arguments, and their value is either True (1) or False (0). The false value is specified on the command line by prepending the word 'no' to either the long or the short flag name.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eae3640cc3319261aa35401e8de9d2ce8dbb68de" translate="yes" xml:space="preserve">
          <source>Boolean, whether the model should run eagerly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef250cc121f9a0c70737aae619bbcea0e3fca625" translate="yes" xml:space="preserve">
          <source>Boosted trees using Estimators</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff0ada0581dd3fbbbe1171390d862723dfbd3449" translate="yes" xml:space="preserve">
          <source>Boston housing price regression dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="feb5e25e7fdce99170a501d07ae0d2154ec16b8d" translate="yes" xml:space="preserve">
          <source>Both &lt;a href=&quot;wrap_function&quot;&gt;&lt;code&gt;tf.compat.v1.wrap_function&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; create a callable TensorFlow graph. But while &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; runs all stateful operations (e.g. &lt;a href=&quot;../../print&quot;&gt;&lt;code&gt;tf.print&lt;/code&gt;&lt;/a&gt;) and sequences operations to provide the same semantics as eager execution, &lt;code&gt;wrap_function&lt;/code&gt; is closer to the behavior of &lt;code&gt;session.run&lt;/code&gt; in TensorFlow 1.x. It will not run any operations unless they are required to compute the function's outputs, either through a data dependency or a control dependency. Nor will it sequence operations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac6191c51f259d57b885ffa82509d687979531d3" translate="yes" xml:space="preserve">
          <source>Both &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; must be of the same type. The supported types are: &lt;code&gt;float16&lt;/code&gt;, &lt;code&gt;float32&lt;/code&gt;, &lt;code&gt;float64&lt;/code&gt;, &lt;code&gt;int32&lt;/code&gt;, &lt;code&gt;complex64&lt;/code&gt;, &lt;code&gt;complex128&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9a81e4a0b1eb6b1ec5c39bcce26af82dcead000" translate="yes" xml:space="preserve">
          <source>Both &lt;code&gt;minimize()&lt;/code&gt; and &lt;code&gt;compute_gradients()&lt;/code&gt; accept a &lt;code&gt;gate_gradients&lt;/code&gt; argument that controls the degree of parallelism during the application of the gradients.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32285642a5d35e8ca4d67ea0f9881c877081f04b" translate="yes" xml:space="preserve">
          <source>Both binary and text proto serializations are supported, and can be chosen using the &lt;code&gt;format&lt;/code&gt; attribute.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d95c74ccd89522c01a075d7f36b2833c75b192d9" translate="yes" xml:space="preserve">
          <source>Both height_pad and width_pad must be divisible by block_size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ca9a7887996112f8fdb0646a86566daf831335e" translate="yes" xml:space="preserve">
          <source>Both linear and dnn model can be pre-compiled and trained separately before jointly training:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5797b46a520878cf57724cc3e45e1348f3297a2c" translate="yes" xml:space="preserve">
          <source>Both matrices must be of the same type. The supported types are: &lt;code&gt;float16&lt;/code&gt;, &lt;code&gt;float32&lt;/code&gt;, &lt;code&gt;float64&lt;/code&gt;, &lt;code&gt;int32&lt;/code&gt;, &lt;code&gt;complex64&lt;/code&gt;, &lt;code&gt;complex128&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5ffc4d6414ef0b63c3c04545c062dd4133f15bc" translate="yes" xml:space="preserve">
          <source>Both output tensors have the same shape as the input: [batch_size, h, w, d]. The gradient values are organized so that [I(x+1, y) - I(x, y)] is in location (x, y). That means that dy will always have zeros in the last row, and dx will always have zeros in the last column.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06ce25342782f4d4b2d0690e4ff7c595a18f4ea8" translate="yes" xml:space="preserve">
          <source>Bounding box annotations are often supplied in addition to ground-truth labels in image recognition or object localization tasks. A common technique for training such a system is to randomly distort an image while preserving its content, i.e. &lt;em&gt;data augmentation&lt;/em&gt;. This Op outputs a randomly distorted localization of an object, i.e. bounding box, given an &lt;code&gt;image_size&lt;/code&gt;, &lt;code&gt;bounding_boxes&lt;/code&gt; and a series of constraints.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1adecae69fdfae669f1a8e72d2b809e358ed472" translate="yes" xml:space="preserve">
          <source>Bounding boxes are supplied and returned as &lt;code&gt;[y_min, x_min, y_max, x_max]&lt;/code&gt;. The bounding box coordinates are floats in &lt;code&gt;[0.0, 1.0]&lt;/code&gt; relative to the width and height of the underlying image.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28c115e33fb3331843965961459fa506166dfe59" translate="yes" xml:space="preserve">
          <source>Bring in all of the public TensorFlow interface into this module.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8eef34697837232b48914f2f89383688de87c7a9" translate="yes" xml:space="preserve">
          <source>Bringing back the factor (slope / total_pos_weight) we'd put aside, we get</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98379f577b8e3e658fdb00e35fa2023c52bf301d" translate="yes" xml:space="preserve">
          <source>Broadcast an array for a compatible shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9abb36007362f42c1fe25106b6bea68f1613c9f" translate="yes" xml:space="preserve">
          <source>Broadcast the &lt;code&gt;tensor&lt;/code&gt; to destinations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb90ebc3a8a835560398b973e98c1a9a13a91937" translate="yes" xml:space="preserve">
          <source>Broadcasting &lt;code&gt;input&lt;/code&gt; onto &lt;code&gt;pos&lt;/code&gt; and &lt;code&gt;len&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="943c31a23379abf365af65d72589c39fcd016fec" translate="yes" xml:space="preserve">
          <source>Broadcasting &lt;code&gt;pos&lt;/code&gt; and &lt;code&gt;len&lt;/code&gt; onto &lt;code&gt;input&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3a942942774c17612d71c1c519884710dcec289" translate="yes" xml:space="preserve">
          <source>Broadcasting is the process of making arrays to have compatible shapes for arithmetic operations. Two shapes are compatible if for each dimension pair they are either equal or one of them is one. When trying to broadcast a Tensor to a shape, it starts with the trailing dimensions, and works its way forward.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d5feb953132591f2c3382b80ae6c1226404fe89" translate="yes" xml:space="preserve">
          <source>Broadcasting, batching, and shapes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04b9674c62052145d087554385c0c130a156a6e2" translate="yes" xml:space="preserve">
          <source>Broadcasts parameters for evaluation on an N-D grid.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c15084325c5d9cb7f413fbc21edd4488d49d1970" translate="yes" xml:space="preserve">
          <source>Buckets include the left boundary, and exclude the right boundary. Namely, &lt;code&gt;boundaries=[0., 1., 2.]&lt;/code&gt; generates buckets &lt;code&gt;(-inf, 0.)&lt;/code&gt;, &lt;code&gt;[0., 1.)&lt;/code&gt;, &lt;code&gt;[1., 2.)&lt;/code&gt;, and &lt;code&gt;[2., +inf)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6ab21d498a0022ceb7f855fe754302022a7ed5a" translate="yes" xml:space="preserve">
          <source>Build a linear model with Estimators</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff2a9f5725bab9a6ea7b5c1e81c28f481aacf928" translate="yes" xml:space="preserve">
          <source>Build a model normally but load the checkpoint files to evaluate by using the shadow variable names. For this use the &lt;code&gt;average_name()&lt;/code&gt; method. See the &lt;a href=&quot;../compat/v1/train/saver&quot;&gt;&lt;code&gt;tf.compat.v1.train.Saver&lt;/code&gt;&lt;/a&gt; for more information on restoring saved variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f722bbeaa2213782e267bb6a26a2181ed2ba8703" translate="yes" xml:space="preserve">
          <source>Build a model that uses the shadow variables instead of the variables. For this, use the &lt;code&gt;average()&lt;/code&gt; method which returns the shadow variable for a given variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64c278c663f3563c13144609bb45bdcc141bcd77" translate="yes" xml:space="preserve">
          <source>Build a profiling option.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec7e094aaf72e063a3f5d7d2cbe1a66f3d62449e" translate="yes" xml:space="preserve">
          <source>Build a serving_input_receiver_fn expecting feature Tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c131e4deb9009c7f3a553f6c57f420ac357d1c5f" translate="yes" xml:space="preserve">
          <source>Build a serving_input_receiver_fn expecting fed tf.Examples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d2bde1dbc114349b400adb05c05117e45ae5a89" translate="yes" xml:space="preserve">
          <source>Build a supervised_input_receiver_fn for raw features and labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16812acd5eb1dc531c249bce946b941a32f4fa1c" translate="yes" xml:space="preserve">
          <source>Build eval graph and restoring op.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ecbf800615dddf1c54ace6455baf6d5941d2478d" translate="yes" xml:space="preserve">
          <source>Builds a Enqueuer from a Sequence.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b102ae80a796f79d82c5dc85ba6b1e609abb9fe5" translate="yes" xml:space="preserve">
          <source>Builds a graph operator that runs a replicated TPU computation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc99b05847903f68fb148ab37a5818e98ecf68ab" translate="yes" xml:space="preserve">
          <source>Builds a main op that defines the sequence of ops to be run as part of the SavedModel load/restore operations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c30a05610280406cf402115abe9fd5f7f435735d" translate="yes" xml:space="preserve">
          <source>Builds a merged tensor such that</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ffe07e58f47ef6958565c53887d803dc87bb5b9" translate="yes" xml:space="preserve">
          <source>Builds a queue out of a data generator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15c5d101f81c465bab7d306bd8e55c17e8730819" translate="yes" xml:space="preserve">
          <source>Builds an array &lt;code&gt;dense&lt;/code&gt; with shape &lt;code&gt;output_shape&lt;/code&gt; such that</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9632e4e0995fb90efa12673a54fda29754e5429" translate="yes" xml:space="preserve">
          <source>Builds an operator that compiles and runs &lt;code&gt;computation&lt;/code&gt; with XLA.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6376d98330a3672bb454b82c00fa18e84fba77f" translate="yes" xml:space="preserve">
          <source>Builds part of a computation outside any current TPU replicate scope.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3fd3fcf3e892824528f5ae2ab17c6aa9d59e34d4" translate="yes" xml:space="preserve">
          <source>Builds profiles and automatically check anomalies of various aspects. For more details: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/README.md</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dfa4f2a1717e8db9ae3aa9c02537ab9914d76383" translate="yes" xml:space="preserve">
          <source>Builds the &lt;code&gt;SavedModel&lt;/code&gt; protocol buffer and saves variables and assets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9012d788d761fc46b18f58d31c677683facbfc2f" translate="yes" xml:space="preserve">
          <source>Built-in activation functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="262775d46de12a6183c6140c11e7d86a4604a3fb" translate="yes" xml:space="preserve">
          <source>Built-in loss functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="edb0aed2fae062a979cdd99b9dca446a853df798" translate="yes" xml:space="preserve">
          <source>Built-in metrics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b22f8a5c519fc799900fabd83d87b51c7af27dc8" translate="yes" xml:space="preserve">
          <source>Built-in optimizer classes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff5e98bf7dfd1a7c5d7e9874de98d594b8a4a9ae" translate="yes" xml:space="preserve">
          <source>Built-in regularizers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1081359cb305229712d2b1c5666832b73e761d74" translate="yes" xml:space="preserve">
          <source>But, since &lt;a href=&quot;constant&quot;&gt;&lt;code&gt;tf.constant&lt;/code&gt;&lt;/a&gt; embeds the value in the &lt;a href=&quot;graph&quot;&gt;&lt;code&gt;tf.Graph&lt;/code&gt;&lt;/a&gt; this fails for symbolic tensors:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="adb1b37cf3b42e366fdeaf2016d9e0331448b49c" translate="yes" xml:space="preserve">
          <source>By convention, &lt;code&gt;indices&lt;/code&gt; should be sorted in row-major order (or equivalently lexicographic order on the tuples &lt;code&gt;indices[i]&lt;/code&gt;). This is not enforced when &lt;code&gt;SparseTensor&lt;/code&gt; objects are constructed, but most ops assume correct ordering. If the ordering of sparse tensor &lt;code&gt;st&lt;/code&gt; is wrong, a fixed version can be obtained by calling &lt;a href=&quot;reorder&quot;&gt;&lt;code&gt;tf.sparse.reorder(st)&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af07810293f013346697008af715a0eaca0bec21" translate="yes" xml:space="preserve">
          <source>By default GradientTape will automatically watch any trainable variables that are accessed inside the context. If you want fine grained control over which variables are watched you can disable automatic tracking by passing &lt;code&gt;watch_accessed_variables=False&lt;/code&gt; to the tape constructor:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c621e57f34694cb8a708de25f63142961a0f637a" translate="yes" xml:space="preserve">
          <source>By default it returns its argument unmodified.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a718f8918d31025fe1098ec5a3ea6f4cd6585e6e" translate="yes" xml:space="preserve">
          <source>By default it uses &lt;code&gt;TFConfigClusterResolver&lt;/code&gt; to detect configurations for multi-worker training. This requires a 'TF_CONFIG' environment variable and the 'TF_CONFIG' must have a cluster spec.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5de0d0264084ef0f307c0cbac3ea682cb5334c9" translate="yes" xml:space="preserve">
          <source>By default it uses all local GPUs or CPU for single-worker training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1987e34dfcb54a3fbdb5e5ab5253982ad3fcdb7" translate="yes" xml:space="preserve">
          <source>By default the file at the url &lt;code&gt;origin&lt;/code&gt; is downloaded to the cache_dir &lt;code&gt;~/.keras&lt;/code&gt;, placed in the cache_subdir &lt;code&gt;datasets&lt;/code&gt;, and given the filename &lt;code&gt;fname&lt;/code&gt;. The final location of a file &lt;code&gt;example.txt&lt;/code&gt; would therefore be &lt;code&gt;~/.keras/datasets/example.txt&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a6a772beb4a7687852aadfcf02c314923646c2cd" translate="yes" xml:space="preserve">
          <source>By default, all punctuation is removed, turning the texts into space-separated sequences of words (words maybe include the &lt;code&gt;'&lt;/code&gt; character). These sequences are then split into lists of tokens. They will then be indexed or vectorized.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d241385f04f44f60b21e5f9c06e4a1462091c7c" translate="yes" xml:space="preserve">
          <source>By default, each element is kept or dropped independently. If &lt;code&gt;noise_shape&lt;/code&gt; is specified, it must be &lt;a href=&quot;http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html&quot;&gt;broadcastable&lt;/a&gt; to the shape of &lt;code&gt;x&lt;/code&gt;, and only dimensions with &lt;code&gt;noise_shape[i] == shape(x)[i]&lt;/code&gt; will make independent decisions. For example, if &lt;code&gt;shape(x) = [k, l, m, n]&lt;/code&gt; and &lt;code&gt;noise_shape = [k, 1, 1, n]&lt;/code&gt;, each batch and channel component will be kept independently and each row and column will be kept or not kept together.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7887e732a7690043927a4583cd60ee68b2eac824" translate="yes" xml:space="preserve">
          <source>By default, each element is kept or dropped independently. If &lt;code&gt;noise_shape&lt;/code&gt; is specified, it must be &lt;a href=&quot;http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html&quot;&gt;broadcastable&lt;/a&gt; to the shape of &lt;code&gt;x&lt;/code&gt;, and only dimensions with &lt;code&gt;noise_shape[i] == shape(x)[i]&lt;/code&gt; will make independent decisions. This is useful for dropping whole channels from an image or sequence. For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47409e29821e35ebb79068c4e13486cce5c14b3d" translate="yes" xml:space="preserve">
          <source>By default, it shows the call stack from root. To avoid redundant output, you may use options to filter as below options['show_name_regexes'] = ['.&lt;em&gt;my_code.py.&lt;/em&gt;']</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a35c24d2662a7f06f4bffd81e1a58929cc9e73e" translate="yes" xml:space="preserve">
          <source>By default, only Variable ops are placed on ps tasks, and the placement strategy is round-robin over all ps tasks. A custom &lt;code&gt;ps_strategy&lt;/code&gt; may be used to do more intelligent placement, such as &lt;code&gt;tf.contrib.training.GreedyLoadBalancingStrategy&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8372466779aad603b533eb9a6f26dba8cb9d7271" translate="yes" xml:space="preserve">
          <source>By default, tf.data will refuse to serialize a dataset or checkpoint its iterator if the dataset contains a stateful op as the serialization / checkpointing won't be able to capture its state. Users can -- at their own risk -- override this restriction by explicitly specifying that they are fine throwing away the state in these ops. There are three settings available - IGNORE: in which wecompletely ignore any state; WARN: We warn the user that some state might be thrown away; FAIL: We fail if any state is being captured.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bdea5c77ba1bb400b1713d0fdb7979dd52e7b3bd" translate="yes" xml:space="preserve">
          <source>By default, the global FLAGS 'FlagValue' object is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e61b4f6785d4c340eb35a16522a958ef242ddfb7" translate="yes" xml:space="preserve">
          <source>By default, the merged return value of &lt;code&gt;fn&lt;/code&gt; across all replicas. The merged result has dependencies to make sure that if it is evaluated at all, the side effects (updates) will happen on every replica. If instead &quot;group=False&quot; is specified, this function will return a nest of lists where each list has an element per replica, and the caller is responsible for ensuring all elements are executed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17779c22d4b5a57316f7c4077f5ce8fe83d02c4d" translate="yes" xml:space="preserve">
          <source>By default, the resources held by a GradientTape are released as soon as GradientTape.gradient() method is called. To compute multiple gradients over the same computation, create a persistent gradient tape. This allows multiple calls to the gradient() method as resources are released when the tape object is garbage collected. For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2099aaca6ae9eb6d226051b3296d7a8208024aa" translate="yes" xml:space="preserve">
          <source>By default, this op performs an inclusive cumprod, which means that the first element of the input is identical to the first element of the output:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d783c6d968b5f013f3616d67ab93e031d6bafa3" translate="yes" xml:space="preserve">
          <source>By default, this op performs an inclusive cumsum, which means that the first element of the input is identical to the first element of the output:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8a20263253e354c92fa47d4334abadee137d8a8" translate="yes" xml:space="preserve">
          <source>By default, this op performs an inclusive cumulative log-sum-exp, which means that the first element of the input is identical to the first element of the output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0f440b112dc5004493817ed80644708c24ba0e7" translate="yes" xml:space="preserve">
          <source>By default, we will attempt to compile your model to a static graph to deliver the best execution performance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e2b10f680b60588cd4f7e2d1ea146b0dbd9f54c6" translate="yes" xml:space="preserve">
          <source>By equivalent graph code we mean code that generates a TensorFlow graph when run. The generated graph has the same effects as the original code when executed (for example with &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../v1/session#run&quot;&gt;&lt;code&gt;tf.compat.v1.Session.run&lt;/code&gt;&lt;/a&gt;). In other words, using AutoGraph can be thought of as running Python in TensorFlow.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="402cc38fc7ec7c348e185202c0cf0136ca6d1145" translate="yes" xml:space="preserve">
          <source>By equivalent graph code we mean code that generates a TensorFlow graph when run. The generated graph has the same effects as the original code when executed (for example with &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;session#run&quot;&gt;&lt;code&gt;tf.compat.v1.Session.run&lt;/code&gt;&lt;/a&gt;). In other words, using AutoGraph can be thought of as running Python in TensorFlow.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92367bc79fc0d6718bf78c26b61a7d03d0b69c80" translate="yes" xml:space="preserve">
          <source>By equivalent graph code we mean code that generates a TensorFlow graph when run. The generated graph has the same effects as the original code when executed (for example with &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;compat/v1/session#run&quot;&gt;&lt;code&gt;tf.compat.v1.Session.run&lt;/code&gt;&lt;/a&gt;). In other words, using AutoGraph can be thought of as running Python in TensorFlow.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="365a5bbe3fd5bc6347d4823ea4b9c96237585068" translate="yes" xml:space="preserve">
          <source>By letting TensorFlow communicate with these systems, we will be able to automatically discover and resolve IP addresses for various TensorFlow workers. This will eventually allow us to automatically recover from underlying machine failures and scale TensorFlow worker clusters up and down.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9278e1fc0825360b5c57ae50e7726421e874417" translate="yes" xml:space="preserve">
          <source>By setting the &lt;code&gt;exclusive&lt;/code&gt; kwarg to &lt;code&gt;True&lt;/code&gt;, an exclusive cumprod is performed instead:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b9fc8dfe89d8c39b3672e06a4fc0add9305a002" translate="yes" xml:space="preserve">
          <source>By setting the &lt;code&gt;exclusive&lt;/code&gt; kwarg to &lt;code&gt;True&lt;/code&gt;, an exclusive cumsum is performed instead:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f410bd101941906092219520862dc5dca7fd59d" translate="yes" xml:space="preserve">
          <source>By setting the &lt;code&gt;reverse&lt;/code&gt; kwarg to &lt;code&gt;True&lt;/code&gt;, the cumprod is performed in the opposite direction:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5268afdfbe723512d8f613eba89c0d66d4f16289" translate="yes" xml:space="preserve">
          <source>By setting the &lt;code&gt;reverse&lt;/code&gt; kwarg to &lt;code&gt;True&lt;/code&gt;, the cumsum is performed in the opposite direction:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d75b7ce723332c49e3b0dcb78c2e7462c0265b1f" translate="yes" xml:space="preserve">
          <source>By subclassing &lt;a href=&quot;module&quot;&gt;&lt;code&gt;tf.Module&lt;/code&gt;&lt;/a&gt; instead of &lt;code&gt;object&lt;/code&gt; any &lt;a href=&quot;variable&quot;&gt;&lt;code&gt;tf.Variable&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;module&quot;&gt;&lt;code&gt;tf.Module&lt;/code&gt;&lt;/a&gt; instances assigned to object properties can be collected using the &lt;code&gt;variables&lt;/code&gt;, &lt;code&gt;trainable_variables&lt;/code&gt; or &lt;code&gt;submodules&lt;/code&gt; property:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="191830e30338c0e6db1753dc0a6107b6c814af32" translate="yes" xml:space="preserve">
          <source>CIFAR10 small images classification dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f058d6651aace4395be00ea131d0059e135ebd71" translate="yes" xml:space="preserve">
          <source>CIFAR100 small images classification dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd6d161c70c73e0be85ec54ff3d5a2a973fd3da1" translate="yes" xml:space="preserve">
          <source>CPU, GPU and TPU with the same algorithm and seed will generate the same integer random numbers. Float-point results (such as the output of &lt;code&gt;normal&lt;/code&gt;) may have small numerical discrepancies between CPU and GPU.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="325e9e852448a06cd618a5a8470c4afbd03ac01c" translate="yes" xml:space="preserve">
          <source>CPU: Intel Ivybridge with HyperThreading (6 cores) dL1:32KB dL2:256KB dL3:12MB GPU: NVidia Tesla k40c</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d91a4b330c1f122b0b95d755e0bc9066dee8004a" translate="yes" xml:space="preserve">
          <source>Cache for file writers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d00fbe086847cad4f2244cc37108b13b4f29e8e" translate="yes" xml:space="preserve">
          <source>Caches the elements in this dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd7a3dd03780fcad0a12d79e9ffc623efaca0842" translate="yes" xml:space="preserve">
          <source>Calculate and return the total variation for one or more images.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8d5916ff9239e92e0656d344a61532f3756c6c4" translate="yes" xml:space="preserve">
          <source>Calculate padding required to make block_shape divide input_shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5abaeb441d5bd58c1eda10ce44390220e4a3ec8" translate="yes" xml:space="preserve">
          <source>Calculate per-step mean Intersection-Over-Union (mIOU).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c5e6d4768e146bf3b1fba4b2243a95ec1b36efb0" translate="yes" xml:space="preserve">
          <source>Calculate scores with shape &lt;code&gt;[batch_size, Tq, Tv]&lt;/code&gt; as a &lt;code&gt;query&lt;/code&gt;-&lt;code&gt;key&lt;/code&gt; dot product: &lt;code&gt;scores = tf.matmul(query, key, transpose_b=True)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37d6d65a142ce498def031c593a9ad83b886c01d" translate="yes" xml:space="preserve">
          <source>Calculate scores with shape &lt;code&gt;[batch_size, Tq, Tv]&lt;/code&gt; as a non-linear sum: &lt;code&gt;scores = tf.reduce_sum(tf.tanh(query + value), axis=-1)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcf7461386b46444c1996d91e3aa1efa39aa5b1c" translate="yes" xml:space="preserve">
          <source>Calculate the &lt;a href=&quot;https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse&quot;&gt;generalized inverse of a matrix&lt;/a&gt; using its singular-value decomposition (SVD) and including all large singular values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73d9854be25bd752f48364b99e22a3a96d1f8117" translate="yes" xml:space="preserve">
          <source>Calculate the mean and variance of &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72a12401f478a02b1988b98f2aa7a1361382f8c8" translate="yes" xml:space="preserve">
          <source>Calculate the mean and variance of based on the sufficient statistics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2737e0cd49779168366a82d5f13b2cc14c1e434b" translate="yes" xml:space="preserve">
          <source>Calculate the sufficient statistics for the mean and variance of &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="848e1ae7c746bca87b8e43d22c6babacb2647a13" translate="yes" xml:space="preserve">
          <source>Calculates how often &lt;code&gt;predictions&lt;/code&gt; matches &lt;code&gt;labels&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d675edb2cef7a5762d1f17bbedbcb2d11b5de60" translate="yes" xml:space="preserve">
          <source>Calculates how often predictions matches integer labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15cb410c6c1440a05c1cd4de092dbbb38fe40286" translate="yes" xml:space="preserve">
          <source>Calculates how often predictions matches labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d70798b6b817e75b87b21aa8a5b8b13b33e3a89c" translate="yes" xml:space="preserve">
          <source>Calculates the accuracy for each class, then takes the mean of that.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a03c79d23b5e0677609527dedfc3737b8a76ad9" translate="yes" xml:space="preserve">
          <source>Calculates the mean and variance of &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc63af24dfe3f981835b8fcd5fe2da3b6de26bfa" translate="yes" xml:space="preserve">
          <source>Calculates the mean of the per-class accuracies.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dfdefd65513a5d4ce1a13498502bf48f6e06e37e" translate="yes" xml:space="preserve">
          <source>Calculates the number of false negatives.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bca367a8fc1fac3606b7ae07adc8ed3af5b86e7" translate="yes" xml:space="preserve">
          <source>Calculates the number of false positives.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b12e664872b284ed4675ab957a3103976b0a4ce4" translate="yes" xml:space="preserve">
          <source>Calculates the number of true negatives.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c10eb264d5e38988188f81c29b3063e30df03b8a" translate="yes" xml:space="preserve">
          <source>Calculates the number of true positives.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="875500308dfbd4c32a5730c807e271d344bac72d" translate="yes" xml:space="preserve">
          <source>Call &lt;a href=&quot;../../../distribute/strategyextended#reduce_to&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.reduce_to(VariableAggregation.SUM, t, v)&lt;/code&gt;&lt;/a&gt; (for one variable) or &lt;a href=&quot;../../../distribute/strategyextended#batch_reduce_to&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.batch_reduce_to&lt;/code&gt;&lt;/a&gt; (for a list of variables) to sum the updates. and broadcast the result to the variable's devices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ddfcfac0b486aa1e76127af81441c8e49ac2087" translate="yes" xml:space="preserve">
          <source>Call &lt;a href=&quot;../../../distribute/strategyextended#update&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.update(v)&lt;/code&gt;&lt;/a&gt; for each variable to update its value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="30d7ecda8acf000402e6565c0283f7a2ac7bb9ea" translate="yes" xml:space="preserve">
          <source>Call &lt;a href=&quot;strategyextended#reduce_to&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.reduce_to(VariableAggregation.SUM, t, v)&lt;/code&gt;&lt;/a&gt; (for one variable) or &lt;a href=&quot;strategyextended#batch_reduce_to&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.batch_reduce_to&lt;/code&gt;&lt;/a&gt; (for a list of variables) to sum the updates. and broadcast the result to the variable's devices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9e52d5a254f4e26301dcf2d0f6560aaf79ffba0" translate="yes" xml:space="preserve">
          <source>Call &lt;a href=&quot;strategyextended#update&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.update(v)&lt;/code&gt;&lt;/a&gt; for each variable to update its value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f715604f97ac7747ca179f45d7f3b30a005e510e" translate="yes" xml:space="preserve">
          <source>Call &lt;code&gt;tf.compat.v1.get_variable_scope().set_use_resource(True)&lt;/code&gt; inside a &lt;a href=&quot;variable_scope&quot;&gt;&lt;code&gt;tf.compat.v1.variable_scope&lt;/code&gt;&lt;/a&gt; before the &lt;a href=&quot;get_variable&quot;&gt;&lt;code&gt;tf.compat.v1.get_variable()&lt;/code&gt;&lt;/a&gt; call.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7e135534b14630e2a69518e9b10c0d6231cb98e" translate="yes" xml:space="preserve">
          <source>Call &lt;code&gt;tf_decorator.make_decorator&lt;/code&gt; on your wrapper function. If your decorator is stateless, or can capture all of the variables it needs to work with through lexical closure, this is the simplest option. Create your wrapper function as usual, but instead of returning it, return &lt;code&gt;tf_decorator.make_decorator(target, your_wrapper)&lt;/code&gt;. This will attach some decorator introspection metadata onto your wrapper and return it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3083567448921c5f2529595633164952fac4ec2" translate="yes" xml:space="preserve">
          <source>Call Arguments:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a4f48c02ec018b3bb271d70aa450cde1b30add9" translate="yes" xml:space="preserve">
          <source>Call arguments:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eef266f410d282365eeaef6f6541415ad4d67585" translate="yes" xml:space="preserve">
          <source>Call self as a function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03d1af542fa5c12db396e05b38fa8dd8ccde3b5f" translate="yes" xml:space="preserve">
          <source>Call this method to make sure that all pending events have been written to disk.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7899c2370850201587c4e3659030d6e39428abba" translate="yes" xml:space="preserve">
          <source>Call this method when you do not need the summary writer anymore.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="121067c30a8795f487f929ac72d30e4a9dd5f476" translate="yes" xml:space="preserve">
          <source>Callback for creating simple, custom callbacks on-the-fly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e0eb9fb6d91c4971d18a8d7376015b4220302e8" translate="yes" xml:space="preserve">
          <source>Callback that accumulates epoch averages of metrics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66321c6ec42e7fca2e738ed61eacbd27dccf819f" translate="yes" xml:space="preserve">
          <source>Callback that prints metrics to stdout.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61efc9334816b060a5770e93ae57052e74c07c89" translate="yes" xml:space="preserve">
          <source>Callback that records events into a &lt;code&gt;History&lt;/code&gt; object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a59c720a70cb6d984affd924a04b4e39a3cec79e" translate="yes" xml:space="preserve">
          <source>Callback that streams epoch results to a csv file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="950399cc17b66bf0c01f20b0e59e2a7902df91f4" translate="yes" xml:space="preserve">
          <source>Callback that terminates training when a NaN loss is encountered.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4bf97f8f1bd8c45ec05302d47dc589ad41d366eb" translate="yes" xml:space="preserve">
          <source>Callback to deserialize the object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5337b726278610de4f20e92050ab6a49c14c76f" translate="yes" xml:space="preserve">
          <source>Callback to serialize the object. Returns a string.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e296a60c25338ecabb10a3892a39411d7cb48f15" translate="yes" xml:space="preserve">
          <source>Callback used to stream events to a server.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a7e77c42d018e79bff39fae35bcadc22ea5fc5d" translate="yes" xml:space="preserve">
          <source>Callbacks: utilities called at certain points during model training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4324d5aa0868664fb93259dbad337f1d96c233d" translate="yes" xml:space="preserve">
          <source>Called after each call to run().</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b90b0ed6adc825f41468bfb71a1fb07d7b36ce1" translate="yes" xml:space="preserve">
          <source>Called at 'timer_interval_secs' boundaries.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e9623bc7c36dde28962be9fd25834083476b3dd" translate="yes" xml:space="preserve">
          <source>Called at the beginning of a batch in &lt;code&gt;evaluate&lt;/code&gt; methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4b1f84a94769b9a2478c8a0da30e2c0dffcc6077" translate="yes" xml:space="preserve">
          <source>Called at the beginning of a batch in &lt;code&gt;predict&lt;/code&gt; methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="916e6773512343819a27dd0590c9ab56a0806f03" translate="yes" xml:space="preserve">
          <source>Called at the beginning of a training batch in &lt;code&gt;fit&lt;/code&gt; methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1f655fbf0fbc64afb73d0ed76eca9dd61fa781e" translate="yes" xml:space="preserve">
          <source>Called at the beginning of evaluation or validation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e101e25f9a7a0d392e9656f422c112a3a7a231f8" translate="yes" xml:space="preserve">
          <source>Called at the beginning of prediction.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd4a6f042a2dfdb8ed082467b01edcbc092b5f52" translate="yes" xml:space="preserve">
          <source>Called at the beginning of training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d586510c89bc867ca4075c8bab24dcc0505a38fe" translate="yes" xml:space="preserve">
          <source>Called at the end of a batch in &lt;code&gt;evaluate&lt;/code&gt; methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8da9e9f3b9d7ae815c96590fee6b2f62271c778" translate="yes" xml:space="preserve">
          <source>Called at the end of a batch in &lt;code&gt;predict&lt;/code&gt; methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d44906a63d89e06ba5e4bebd95cf6a0957c6b64" translate="yes" xml:space="preserve">
          <source>Called at the end of a training batch in &lt;code&gt;fit&lt;/code&gt; methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d5b83a8f2680f3a24afeb023edca572b82c6cde" translate="yes" xml:space="preserve">
          <source>Called at the end of an epoch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e1371d719791c3dd3ea879c10c5a1955bd19013" translate="yes" xml:space="preserve">
          <source>Called at the end of evaluation or validation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5017b821fec7bc45610a9f5cc9766cb5febe8318" translate="yes" xml:space="preserve">
          <source>Called at the end of prediction.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76760e80b63c958f239d75d5ad4512117f73ad1e" translate="yes" xml:space="preserve">
          <source>Called at the end of session.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="889c44d53e3033b04007c418814f5a7a4fcc5066" translate="yes" xml:space="preserve">
          <source>Called at the end of training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7f31a1b48269efc5dd397e08f92678240e44f5a" translate="yes" xml:space="preserve">
          <source>Called at the start of an epoch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c6c23813f0266497be680fb5405d5f03c2c858a" translate="yes" xml:space="preserve">
          <source>Called before each call to run().</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dcc9f7d48ffe0246e93b693886a961f53e848cae" translate="yes" xml:space="preserve">
          <source>Called once before using the session.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01abf9858061a422328df321eb2847e112b3ef7a" translate="yes" xml:space="preserve">
          <source>Called when new TensorFlow session is created.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aed2191fe4cb3250e557b2441086457b02885576" translate="yes" xml:space="preserve">
          <source>Called when the thread starts.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00ee85febe26fe81ab08ac729cca317ba056773d" translate="yes" xml:space="preserve">
          <source>Called when the thread stops.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f3197e54f59154ea9f0fc2c9205a5a1aa689f77" translate="yes" xml:space="preserve">
          <source>Calling &lt;a href=&quot;experimental_run_functions_eagerly&quot;&gt;&lt;code&gt;tf.config.experimental_run_functions_eagerly(False)&lt;/code&gt;&lt;/a&gt; will undo this behavior.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="556bb63836b4fffb3380b3431afbf99567df827e" translate="yes" xml:space="preserve">
          <source>Calling &lt;a href=&quot;experimental_run_functions_eagerly&quot;&gt;&lt;code&gt;tf.config.experimental_run_functions_eagerly(True)&lt;/code&gt;&lt;/a&gt; will make all invocations of &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; run eagerly instead of running as a traced graph function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45b449a4b38951d304cf3e0c1ff415bd9f99bb89" translate="yes" xml:space="preserve">
          <source>Calling &lt;a href=&quot;list_logical_devices&quot;&gt;&lt;code&gt;tf.config.list_logical_devices&lt;/code&gt;&lt;/a&gt; triggers the runtime to configure any &lt;a href=&quot;physicaldevice&quot;&gt;&lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt;&lt;/a&gt; visible to the runtime, thereby preventing further configuration. To avoid runtime initialization, call &lt;a href=&quot;list_physical_devices&quot;&gt;&lt;code&gt;tf.config.list_physical_devices&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f634641fd2a808e68140b95b50c4dfb312b22d28" translate="yes" xml:space="preserve">
          <source>Calling &lt;a href=&quot;set_seed&quot;&gt;&lt;code&gt;tf.random.set_seed&lt;/code&gt;&lt;/a&gt; will reset any such counters:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fa7fce2a5581bab7496411c79f09da9f57896c3" translate="yes" xml:space="preserve">
          <source>Calling &lt;code&gt;X, Y = meshgrid(x, y)&lt;/code&gt; with the tensors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="edab3bb5ad3dfa8ba8f89a98efc92bd3dabd4ef3" translate="yes" xml:space="preserve">
          <source>Calling &lt;code&gt;enable_mixed_precision_graph_rewrite(opt)&lt;/code&gt; enables the graph rewrite operation before computing gradients. The function additionally returns an &lt;code&gt;Optimizer&lt;/code&gt;(&lt;code&gt;opt&lt;/code&gt;) wrapped with a &lt;code&gt;LossScaleOptimizer&lt;/code&gt;. This prevents underflow in the float16 tensors during the backward pass. An optimizer of type &lt;code&gt;tf.train.Optimizer&lt;/code&gt; or &lt;a href=&quot;../../../../keras/optimizers/optimizer&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt;&lt;/a&gt; must be passed to this function, which will then be wrapped to use loss scaling.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75a4bf44e56da6be246001cf5f0cc4fc29e86198" translate="yes" xml:space="preserve">
          <source>Calling &lt;code&gt;enable_mixed_precision_graph_rewrite(opt)&lt;/code&gt; enables the graph rewrite operation before computing gradients. The function additionally returns an &lt;code&gt;Optimizer&lt;/code&gt;(&lt;code&gt;opt&lt;/code&gt;) wrapped with a &lt;code&gt;LossScaleOptimizer&lt;/code&gt;. This prevents underflow in the float16 tensors during the backward pass. An optimizer of type &lt;code&gt;tf.train.Optimizer&lt;/code&gt; or &lt;a href=&quot;../../keras/optimizers/optimizer&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt;&lt;/a&gt; must be passed to this function, which will then be wrapped to use loss scaling.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2fcc5a2665ea7ba92b116be2e5df10b3a56ca171" translate="yes" xml:space="preserve">
          <source>Calling &lt;code&gt;initialize_variables()&lt;/code&gt; is equivalent to passing the list of initializers to &lt;code&gt;Group()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a6e9108c00a0ab54163a0df197322b5322571b3" translate="yes" xml:space="preserve">
          <source>Calling &lt;code&gt;minimize()&lt;/code&gt; takes care of both computing the gradients and applying them to the variables. If you want to process the gradients before applying them you can instead use the optimizer in three steps:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e1826fa3d3bc093c2ae8a384bf8aede36c617c1" translate="yes" xml:space="preserve">
          <source>Calling methods of &lt;code&gt;Estimator&lt;/code&gt; will work while eager execution is enabled. However, the &lt;code&gt;model_fn&lt;/code&gt; and &lt;code&gt;input_fn&lt;/code&gt; is not executed eagerly, &lt;code&gt;Estimator&lt;/code&gt; will switch to graph mode before calling all user-provided functions (incl. hooks), so their code has to be compatible with graph mode execution. Note that &lt;code&gt;input_fn&lt;/code&gt; code using &lt;a href=&quot;../../../data&quot;&gt;&lt;code&gt;tf.data&lt;/code&gt;&lt;/a&gt; generally works in both graph and eager modes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="374ad568de6f2277ac942e3fbe47ae39586500de" translate="yes" xml:space="preserve">
          <source>Calling methods of &lt;code&gt;Estimator&lt;/code&gt; will work while eager execution is enabled. However, the &lt;code&gt;model_fn&lt;/code&gt; and &lt;code&gt;input_fn&lt;/code&gt; is not executed eagerly, &lt;code&gt;Estimator&lt;/code&gt; will switch to graph mode before calling all user-provided functions (incl. hooks), so their code has to be compatible with graph mode execution. Note that &lt;code&gt;input_fn&lt;/code&gt; code using &lt;a href=&quot;../data&quot;&gt;&lt;code&gt;tf.data&lt;/code&gt;&lt;/a&gt; generally works in both graph and eager modes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73b11118eb4f7c4f5d4cb99890fa4f0b9e7e298a" translate="yes" xml:space="preserve">
          <source>Calling tf.enable_control_flow_v2() lets you opt-in to this TensorFlow 2.0 feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c38ebe6b83ed80cb1f55fbb6c8d38b867ab92e4" translate="yes" xml:space="preserve">
          <source>Calling tf.enable_resource_variables() lets you opt-in to this TensorFlow 2.0 feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af7cf2fd755bb35e1d292d1635b244cfa0ed2568" translate="yes" xml:space="preserve">
          <source>Calling the same template multiple times will share all non-local variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e07e9005aa4c132be57d20c2bc0a93ba16b1fcf7" translate="yes" xml:space="preserve">
          <source>Calling this method frees all resources associated with the session.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ecd5fcddc02d273b420ad9a3a5ca4278e555c264" translate="yes" xml:space="preserve">
          <source>Calling this method will execute all preceding operations that produce the inputs needed for the operation that produces this tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="324600cb53e436db97125dbecc1def22a1d0b5cb" translate="yes" xml:space="preserve">
          <source>Calling this method will execute all preceding operations that produce the inputs needed for this operation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="048799204f4375cc969d7349152d0f4e038ccf4a" translate="yes" xml:space="preserve">
          <source>Calls &lt;code&gt;train_step_fn&lt;/code&gt; in a loop to train a model. The function is called as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64e59806a0c086a7a3885c01fef3ede9cbd5855c" translate="yes" xml:space="preserve">
          <source>Calls logit_fn (experimental).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78db2fbe58ed056ea60b1d9a22b2e0f46efb74ee" translate="yes" xml:space="preserve">
          <source>Calls tpu_ops.cross_replica_sum() to sum gradient contributions across replicas, and then applies the real optimizer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ec329986e07459489e179205a64cb08abcd05ea" translate="yes" xml:space="preserve">
          <source>Can be called after &lt;code&gt;close()&lt;/code&gt; to add more events in the same directory. The events will go into a new events file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2959f6c9ef5108c0632f5948e6849b106619f1d" translate="yes" xml:space="preserve">
          <source>Can be different from value() if it's on another device, with control dependencies, etc.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b371665a1e9a0996d8ede0eab6929eab799777c8" translate="yes" xml:space="preserve">
          <source>Can either fail with exception or just stop training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d121a99e89988292ebdf048595bc83269074e0a8" translate="yes" xml:space="preserve">
          <source>Can only be used when RNN layer is constructed with &lt;code&gt;stateful&lt;/code&gt; = &lt;code&gt;True&lt;/code&gt;. Args: states: Numpy arrays that contains the value for the initial state, which will be feed to cell at the first time step. When the value is None, zero filled numpy array will be created based on the cell state size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f17d8a346c8efb1ee95da5bc62279c544ebd2135" translate="yes" xml:space="preserve">
          <source>Can use either greedy search (also known as best path) or a constrained dictionary search.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b56df0eb545d4bec81deaa2154a209ba005d16f" translate="yes" xml:space="preserve">
          <source>Captures CPU/GPU profiling information every N steps or seconds.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa0bb62dcd2a3a8c61dd14c3cd326e2dc89c532c" translate="yes" xml:space="preserve">
          <source>Cast a Numpy array to the default Keras float type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="334b73efb4a433dedcb554db2bf31b0616c9eada" translate="yes" xml:space="preserve">
          <source>Cast a float32 variable to a float64 tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f41700c03805fde68fc032dd39cf89c0c9987884" translate="yes" xml:space="preserve">
          <source>Casts a tensor to a different dtype and returns it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="280dd75c5fe62dc6408cb2adc7c8b71dc0dd9f58" translate="yes" xml:space="preserve">
          <source>Casts a tensor to a new type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a84160fa12c84721924b091fb190fff7ee8fedb4" translate="yes" xml:space="preserve">
          <source>Casts a tensor to type &lt;code&gt;bfloat16&lt;/code&gt;. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="705ec0dd8476e42a7426b0c30ad678f1035c9e4a" translate="yes" xml:space="preserve">
          <source>Casts a tensor to type &lt;code&gt;complex128&lt;/code&gt;. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="33d6d726c762bff193876d688d6dd7f5f61cd7aa" translate="yes" xml:space="preserve">
          <source>Casts a tensor to type &lt;code&gt;complex64&lt;/code&gt;. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1c3a054ac51d3b629b476ccde190ad463087d19" translate="yes" xml:space="preserve">
          <source>Casts a tensor to type &lt;code&gt;float32&lt;/code&gt;. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2146083c84d0b16b1678b4456163f1bdfe31ac53" translate="yes" xml:space="preserve">
          <source>Casts a tensor to type &lt;code&gt;float64&lt;/code&gt;. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61d8b2839f0934af7a7eae2ce6eaaa779691964a" translate="yes" xml:space="preserve">
          <source>Casts a tensor to type &lt;code&gt;int32&lt;/code&gt;. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc080c2f9bc9ab6b38709b3097e7e8597d6c450d" translate="yes" xml:space="preserve">
          <source>Casts a tensor to type &lt;code&gt;int64&lt;/code&gt;. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d202d5d410c2f1324f24135298e6ae90e7e0adb" translate="yes" xml:space="preserve">
          <source>Catching NaN during eager execution:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c2838369fe9ec7da4939b0fdee1fec8aa9647ad" translate="yes" xml:space="preserve">
          <source>Catching infinity during the execution of a &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; graph:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0166b7d0d6075e9c939ec339eaeb9ed445956b1" translate="yes" xml:space="preserve">
          <source>Categorical crossentropy between an output tensor and a target tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c830adb56fdb07bc05a0cf911dce2ef18b20b2e" translate="yes" xml:space="preserve">
          <source>Categorical crossentropy loss value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1d1c3ecda282db8101cbdcd80b28927419f3f1d" translate="yes" xml:space="preserve">
          <source>Categorical crossentropy with integer targets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7be3f4df5d21b9c1ab88a3aa158d7aca40b676e2" translate="yes" xml:space="preserve">
          <source>Categorical distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec4a3c1492a5887a0912ea9933b69aa8bf5fcb23" translate="yes" xml:space="preserve">
          <source>Causes &lt;code&gt;step_fn&lt;/code&gt; to exit by raising an exception.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab6fca836569f204bcc677ffb51a1984f95344e9" translate="yes" xml:space="preserve">
          <source>Caveat: Current implementation supports early-stopping both training and evaluation in local mode. In distributed mode, training can be stopped but evaluation (where it's a separate job) will indefinitely wait for new model checkpoints to evaluate, so you will need other means to detect and stop it. Early-stopping evaluation in distributed mode requires changes in &lt;code&gt;train_and_evaluate&lt;/code&gt; API and will be addressed in a future revision.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d839f39a4a59e95f2dab1b3e915bcd2a400c9548" translate="yes" xml:space="preserve">
          <source>Cell class for SimpleRNN.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1119828e44e174d79d64ab29f867ffa523c210e0" translate="yes" xml:space="preserve">
          <source>Cell class for the GRU layer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7e6e90071f90e58887144315972c570df65b4d2" translate="yes" xml:space="preserve">
          <source>Cell class for the LSTM layer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23edb4f829652a9d01fa6868430a5263f412ea6b" translate="yes" xml:space="preserve">
          <source>Certain operations like matrix multiplication and reductions can utilize parallel threads for speed ups. A value of 0 means the system picks an appropriate number.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a990eb1806e0ff020baa6147abe66c66ecdb1057" translate="yes" xml:space="preserve">
          <source>Certain policies also have a &lt;a href=&quot;../../../mixed_precision/experimental/lossscale&quot;&gt;&lt;code&gt;tf.mixed_precision.experimental.LossScale&lt;/code&gt;&lt;/a&gt; instance, which is used by &lt;a href=&quot;../../model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt;s to performance loss scaling. Loss scaling is a technique used with mixed precision to avoid numerical underflow in float16 gradients. Loss scaling is only done by Models in &lt;a href=&quot;../../model#fit&quot;&gt;&lt;code&gt;Model.fit&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../model#train_on_batch&quot;&gt;&lt;code&gt;Model.train_on_batch&lt;/code&gt;&lt;/a&gt;, and similar methods. Layers which are not Models ignore the loss scale.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0dbc4f076a883e5ea94065223770666919ef1c18" translate="yes" xml:space="preserve">
          <source>Changes the default value of the named flag object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2effedd39add60ae8be7494c0efc1e48dacf31f6" translate="yes" xml:space="preserve">
          <source>Changing the input separator:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5d31ec693bae296275b7b2864766281e17d3286" translate="yes" xml:space="preserve">
          <source>Check if stop was requested.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f50d4fd1d7eadfeacf0c1c820d0d2b6cd464affa" translate="yes" xml:space="preserve">
          <source>Check if the coordinator was told to stop.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fd77d1324d6bd49b51e3ed42a0127d574db82a8" translate="yes" xml:space="preserve">
          <source>Check if the input matches the regex pattern.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4542e2afa1a18ea89ceeb8900acb7a7305d1f599" translate="yes" xml:space="preserve">
          <source>Check that the expression is false.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e75f331bdc759f92b7d5761a5c7a473f8447e81" translate="yes" xml:space="preserve">
          <source>Check that the expression is true.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29b679a94243e90778e1a211be810bda303991fb" translate="yes" xml:space="preserve">
          <source>Check the documentation for the l2_shrinkage_regularization_strength parameter for more details when shrinkage is enabled, where gradient is replaced with gradient_with_shrinkage.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f0690ea4a3acc60803b310734b83244fd519279" translate="yes" xml:space="preserve">
          <source>CheckpointState proto with model_checkpoint_path and all_model_checkpoint_paths updated to either absolute paths or relative paths to the current save_dir.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df6fe0319358cfda869b0687a1aa44f424c8cf24" translate="yes" xml:space="preserve">
          <source>Checkpointing trained variables as the training progresses.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c5abb9f5c926160489922b816fb9259b397e47e" translate="yes" xml:space="preserve">
          <source>Checkpoints are binary files in a proprietary format which map variable names to tensor values. The best way to examine the contents of a checkpoint is to load it using a &lt;code&gt;Saver&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21d28d0442bf387cb524ee7f2fa02a59f1c717fd" translate="yes" xml:space="preserve">
          <source>Checkpoints are only considered for deletion just after a new checkpoint has been added. At that point, &lt;code&gt;max_to_keep&lt;/code&gt; checkpoints will remain in an &quot;active set&quot;. Once a checkpoint is preserved by &lt;code&gt;keep_checkpoint_every_n_hours&lt;/code&gt; it will not be deleted by this &lt;code&gt;CheckpointManager&lt;/code&gt; or any future &lt;code&gt;CheckpointManager&lt;/code&gt; instantiated in &lt;code&gt;directory&lt;/code&gt; (regardless of the new setting of &lt;code&gt;keep_checkpoint_every_n_hours&lt;/code&gt;). The &lt;code&gt;max_to_keep&lt;/code&gt; checkpoints in the active set may be deleted by this &lt;code&gt;CheckpointManager&lt;/code&gt; or a future &lt;code&gt;CheckpointManager&lt;/code&gt; instantiated in &lt;code&gt;directory&lt;/code&gt; (subject to its &lt;code&gt;max_to_keep&lt;/code&gt; and &lt;code&gt;keep_checkpoint_every_n_hours&lt;/code&gt; settings).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d1fa6eec30bbc58997c3c443bb6be1a170f6bca" translate="yes" xml:space="preserve">
          <source>Checkpoints input pipeline state every N steps or seconds.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68c056b4b93dd6519d0041cce2fa3456b2db6d84" translate="yes" xml:space="preserve">
          <source>Checks a tensor for NaN and Inf values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03b3802d2d574b8aa3cf5dbf69c4a68a33755fe8" translate="yes" xml:space="preserve">
          <source>Checks for user typos in &lt;code&gt;params&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e54fec2de517ab61fb09b3c7770a5828ed597b77" translate="yes" xml:space="preserve">
          <source>Checks if the &lt;code&gt;other&lt;/code&gt; DeviceSpec is same as the current instance, eg have</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10af03d1ce49f737f9b2ce8ba532b3eab851f8a5" translate="yes" xml:space="preserve">
          <source>Checks that for all elements of farray1 and farray2 |f1 - f2| &amp;lt; err. Asserts a test failure if not.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a9a0c747f7d3a04be66c98e057ab74676d88c18" translate="yes" xml:space="preserve">
          <source>Checks that |f1 - f2| &amp;lt; err and asserts a test failure if not.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92163db6500c625db76ce0f05a7a5d4e3db7f4e3" translate="yes" xml:space="preserve">
          <source>Checks whether &lt;code&gt;x&lt;/code&gt; is a tensor or &quot;tensor-like&quot;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e059e52c344fd5ea2c163457327f9087b4bb6a8" translate="yes" xml:space="preserve">
          <source>Checks whether a V1 or V2 checkpoint exists with the specified prefix. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f4de71ed2c8b2e5af9895d98339a40b2e2c1c15" translate="yes" xml:space="preserve">
          <source>Checks whether actual iterable and expected iterable are disjoint.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88f50b688ffeed23fd5a96b8bba490755c44f55c" translate="yes" xml:space="preserve">
          <source>Checks whether actual iterable is a superset of expected iterable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f59c9039e22893963243b8c7ff0dfa78e73c347" translate="yes" xml:space="preserve">
          <source>Checks whether dictionary is a superset of subset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="81653dba6304e52f546386ecd8e46ada482da998" translate="yes" xml:space="preserve">
          <source>Checks whether the current thread has eager execution enabled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a00371c8104eecce11bdda237cd5bab917ed668" translate="yes" xml:space="preserve">
          <source>Checks whether the provided export directory could contain a SavedModel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="081e16e0be1f7308e710a862357dde7b864af3d6" translate="yes" xml:space="preserve">
          <source>Chenxin Ma, Virginia Smith, Martin Jaggi, Michael I. Jordan, Peter Richtarik, Martin Takac. 2015</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e8b545859f486b41feff0d018471a7c548b2a22" translate="yes" xml:space="preserve">
          <source>Child Classes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06d307e8d098b70f7cac84c9d07c001afdc02b48" translate="yes" xml:space="preserve">
          <source>Choose class probabilities: &lt;code&gt;probs = [p_0,...,p_{K-1}] ~ Dir(concentration)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c71102c2bb27ccecc4ad4a34d8d5ce11b4bca31" translate="yes" xml:space="preserve">
          <source>Chunks of data of size &lt;code&gt;block_size * block_size&lt;/code&gt; from depth are rearranged into non-overlapping blocks of size &lt;code&gt;block_size x block_size&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5c72c88d726f3183998c923d493edeea5d34b0b" translate="yes" xml:space="preserve">
          <source>Circulant means the entries of &lt;code&gt;A&lt;/code&gt; are generated by a single vector, the convolution kernel &lt;code&gt;h&lt;/code&gt;: &lt;code&gt;A_{mn} := h_{m-n mod N}&lt;/code&gt;. With &lt;code&gt;h = [w, x, y, z]&lt;/code&gt;,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d91ae8103738faa3c6af39c0a2f441f7d2f9937c" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;AUC&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3949de655640e9c512ec22d0f7d2a40a97c72247" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;AbortedError&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bacec76662ca55a44f49c0890d6984811323cca5" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;AbstractRNNCell&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32bba1a0a506f806da6613aa912e7cb6ed02da2a" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Accuracy&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c3cbef18d2d31390e5ea8f1275ce9197f787655" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Activation&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4150cc7e888940f3e35fb2d48a05c2f5eaa2fde8" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;ActivityRegularization&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d682b6c1fef9a4e91ffd04d3ea90227ff0e24793" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Adadelta&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52667c6d8e0439e28d0aa18c87c5fedc5f0bf623" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;AdadeltaOptimizer&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad2ff8d0bdcbff10a417bc4d044dc9c19e75c694" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Adagrad&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="106906bd8f35c82b8e260390fe2038fe6b36f193" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;AdagradDAOptimizer&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79ec2b05bc4b6a2231fe275241ee95a78064ace3" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;AdagradOptimizer&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abb4f658d97fda457ed52ab415690bcc96f823c8" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;AdagradParameters&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c9b7608366cb6e42f1702ad5a6c373bbf796990" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Adam&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2f8d87eb3a4bcdc93c9010028d700f3601af291" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;AdamOptimizer&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="188785cdfd4d587f73b7a74add249e01c34c934f" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;AdamParameters&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3409195bbd89e13bed6a975292a211ce7300d413" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Adamax&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5efdfc377b9cd6f9ba31430c6ad784a0329af9e" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Add&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="722f2689bea146b3476f7bbff4fb0b4ea39f975f" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;AdditiveAttention&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c069fa9094853728a34f2acbfc33105eaaa0d16" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;AdviceProto&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a007052d6a88801e4ddd1876e290ab5da940b64e" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;AggregationMethod&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa1d8d4d3c7326b06a431004a39a289692089401" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;AlphaDropout&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d7ec5c1c0bf6ef6c138bb97e43a6e6fc5a8b1f0f" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;AlreadyExistsError&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c54337034e447fddc8846a31cd8402ecd7d1cf7" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;ArgumentParser&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb41faa7ad8bbfcfc77e4b0ca324c0e08e284763" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;ArgumentSerializer&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96fd318137691c1bf0eedb8b1dd2ab77073935c9" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Asset&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3c6d910e530e0fa1aa7025b38f1cbf4aeff052b" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Attention&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b635c3bdd026b39ca5592946404ef97c1626a84d" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;AttrEntry&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5cf301802a3efa358c2b7d9ab5646efc0556aab" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;AttrValue&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="145a488bc364287eacc62cc2bd1918bc7ec2fb91" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Audio&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6676ddc6447ea3d7c7de56ef0f9feedd43067fb3" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;AutoShardPolicy&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37529a4c9fb5403381e62535c3792e0d4188c468" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Average&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0370e173ccf4e2b37bf0bb979371bd328593e5d" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;AveragePooling1D&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4af41d7f70d9ae4c1d04f893364786a975e5308c" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;AveragePooling2D&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1376a511804b9dbcd53cef5a1a5d3002ea76649" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;AveragePooling3D&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f5be53a06d7179c574c397e0e3bf97176679330" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;BaseListParser&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dfaad4fc192e676192c711663d42e4c75aee9ba5" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;BaseLogger&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8a7557aad0ba44df757e83222b90606533444b7" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;BaselineClassifier&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="947a09777b5a274c64dcf061e43a9ca43906f212" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;BaselineEstimator&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c18453400eda0696fe04abd391743c9a8e35c9b" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;BaselineRegressor&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ef3d4b4403a6a7517f4cef48fb05a551d489fac" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;BasicLSTMCell&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="315e4a0dd265d12b686a62b40f291c7baa49fab9" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;BasicRNNCell&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="698b254933e1c457256106c679145d67714b29b6" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;BatchNormalization&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16fb080f327a0b43b70477ed0c9de8dd44dff89d" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Benchmark&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4430a57ab4fbb829cfb3425b8ee3ad3fa3c0bd13" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Bernoulli&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4095f9e319a0b3a5243009acfd370178951a0208" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;BestExporter&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1cfe2499805203588a44fd6a07c177a82186555" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Beta&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="baab8a29437b1b771d25da74652542eb131a7e3f" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Bidirectional&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e438fd72d70bc369a807ee93691643ba5a0c9bdf" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;BinaryAccuracy&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="963d5803afc6d79f4d9b15779053baec1ca85dc6" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;BinaryClassHead&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc5bfbf0813687470692e4fbbc3b68f931e6effa" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;BinaryCrossentropy&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d400a6d13e73889f33ae8eb6fde6f78885cec12" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;BooleanFlag&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85aca771a934725fe03a2c21517a14b32a398dd0" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;BooleanParser&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ba91dd39fc59681421960fe1fa018fd94ce7fab" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;BoostedTreesClassifier&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2cd9d432edec3db91b6d8a066536e5b9f6d618f" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;BoostedTreesEstimator&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8feae76c149da0f2d7d6b111a68c3d51bb986b4" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;BoostedTreesRegressor&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="925e8414b49af82c9205833cbbae3c6277f45894" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Builder&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00b5307c125bbbc3637bfe316cf358e7ad149728" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;BytesList&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66c96266aa779f599aa175633268a71d3b7d0f64" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CSVLogger&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="623c12427fbdbdc672fb977f1a830388a55cc0ac" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Callback&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="473594b2b705b4c035e7ca6db0c4fbf5e0d54dfe" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CancelledError&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84b3628a0fbf67cbad7028db4d245ecb654a69a6" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CantOpenFlagFileError&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e794abcecf7ccb2d8b6b8b03b52b3cf699eedaf" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Categorical&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="626931e2c2471759ac90e368849b23fe7b9c4cd5" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CategoricalAccuracy&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4e4435ebd8f7ecb833459b7957c23651535cb2a" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CategoricalCrossentropy&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d28d0bb939b9c7d52fadd90dec41eedd923138a8" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CategoricalHinge&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ac1a466a779989e51e5588e748c6ea10a4d5e22" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CentralStorageStrategy&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d42e85aa00a2dd9bc44690dce11a4f64a6527624" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Checker&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54b1f90a90ccddfd1893fbb4e69917c344fbb780" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CheckersEntry&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="460f3c425fd5ca6f55dee32c477d1b5e840d13e5" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Checkpoint&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3edce4762e8efc221ab4cc07b28e7231041b7edb" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CheckpointInputPipelineHook&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f11ecf424d0152d3d4147b1f5c4d0c96757ecb3e" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CheckpointManager&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c361b6bd85dfd3f7ada9d78acb76c3a08328f128" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CheckpointSaverHook&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc09d8e774b9ad61a24a26143c5ac8ed7cd199ca" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CheckpointSaverListener&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2005a6fe8bd71936dfbcc9a40d54a733958c67d1" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;ChiefSessionCreator&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b63eb22da3c8dbe773591b365adb45c1eab392e7" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;ClassificationOutput&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="22423695d7170ba6d7cf4d5490f7b9ae49892338" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;ClusterDef&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29bd9a531a67b76a8528d4f743be0e53f0f3a0db" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;ClusterResolver&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73d178c6cf816eca87dedfbf81203524ac0ecbad" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;ClusterSpec&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebd95e5e5abbcf7e91594cabfe9461badc6727e7" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CollectionDefEntry&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe3034c377376db7a38ac1f79e1ebedd9a2256c5" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CollectiveCommunication&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07354c8fa2624079756dd60e06f9aaba6476345b" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CompositeTensor&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5cbad8d0152f2ef00b4839799cfbb98ec74ebb82" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Concatenate&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f67df5d774272041c3636994513a6d4bb80fe398" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;ConditionalAccumulator&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e204b981379d518be8cb1a7363de6126327123d" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;ConditionalAccumulatorBase&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15010ae365bd6d65db4300fa168475795f0a4c7f" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;ConfigProto&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26a5b88effd2f0b87d8d7185b51ef4ccf3c75fb4" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Constant&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="130690aeb2378b33d3e6da1956562f91a25f1f34" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Constraint&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35604b3ee64f5d60a8362457ab19fa6a7594a070" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Conv1D&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a0b5db9567cf3bbd54d4d38c520c4ab43f77431" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Conv2D&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c454fc1d64c75297325af2c10e5eb1729ab38a2" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Conv2DTranspose&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aeea94513cb273ccbefe4e8455177f07de64594a" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Conv3D&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="880fd8079c8b090ef2772d658eeadf7da7a1261a" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Conv3DTranspose&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20537a9877e87769161d9e95417a1d656c34290d" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;ConvLSTM2D&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51d2b5da041f35574a132596dc2c6a59ea4885d4" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Converter&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73838f3e3c9c9c03100f63010bc61c9d052ff5ad" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CooSparse&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f2296e920599e75da0714d8a43e7e8b6a6f32f9" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Coordinator&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="639094b9fe34debcb2adc39c04b72a99f3ffe33c" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CosineDecay&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9808eedfb34c5eed7944473fbfbd722d05b0c0a" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CosineDecayRestarts&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f60aee20340565edb302c38e5c461338c1775f35" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CosineSimilarity&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee3e36d3c4673475c8fe09eb182d56fee3d8ba99" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CriticalSection&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35f06aba7231859af4ca77d190a34daeed5dfce1" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Cropping1D&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed0af12014d262a70e1721292d4c2a23bc52e62e" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Cropping2D&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84edf562dc48f0fd6f6bc5603de7b491b40ffe91" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Cropping3D&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8e68e5350146c34d82c03364587c3160ed4a4d8" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CrossDeviceOps&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6c46812e45dd3f6004b8c69f22559963482f19f" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CrossShardOptimizer&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb97b8a6433bb4f7813b090cd945ac1a408498f9" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CsvDataset&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6371a034cc6f8bb5c337114f51a49673e2e8646a" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CsvListSerializer&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53dabbedb4306df239e3ec72ab3e253bd9752eb0" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CuDNNGRU&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f9cc3c9a2acc252da1a8d0cf0783dacf361f3f7" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CuDNNLSTM&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88767e67e12ffce934236067f3a95159b2ad3c94" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CurrentModuleFilter&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64ee8732c6a4da2a4d2d4c5ca4e7177273cf310d" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;CustomObjectScope&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d45d364786349f36e5fc170e2e6234a34e74d363" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;DNNClassifier&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8af05c12f63b0fd3c92a4c86846eee2fcc424b75" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;DNNEstimator&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50c0d58b0ef2d60db424c01d3b5b11d32335dbb6" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;DNNLinearCombinedClassifier&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c468d642f178984ab9adfafa8679dfee53bde730" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;DNNLinearCombinedEstimator&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa95a92fd79dcc3f03cbccbadb44b8ae8e151635" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;DNNLinearCombinedRegressor&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cad338d26fb1f311fd76eca1805694646527f63" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;DNNRegressor&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ba5b25c96f1491a81f71da349138b9df63ed29d" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;DType&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="711cdcd2575c5be490c91247c07fb55681dff698" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;DataLossError&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6015959783e568b5c75a626b3b0e8e4cbd99f5ae" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Dataset&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6abee8ef5c12828c94bdfa435a2f42820dd20f0" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;DatasetSpec&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7340da8eed8cfeeaa03c59e06a7a1bb69c26168" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;DeadlineExceededError&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e05048360c78f1935154fd07698f116060619d0" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Dense&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a40cdf25b5b751ed4860ed13acbc426eeaa58cab" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;DenseFeatures&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="46373c3c5aa4a9a84b58611fb4b76cc36763b026" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;DenseHashTable&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6db261320c5c56ecb535e282c91469ec3d449fe" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;DepthwiseConv2D&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ffd504b18cd56706d872c4a05dc43fc68c154320" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;DeviceAssignment&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2ade4e29cea1d99f99bf826ecf2e7e9d79e9f70" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;DeviceCountEntry&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e686c64878b5f918d044362949f77f2b1be5508b" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;DeviceSpec&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6fa430933e3069aa27572493ab7817ea1b2753ee" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;DeviceWrapper&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24080ba822655c5b934236af09b4ab82e0e9be52" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Dimension&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="edfcb726a3b26da6a5c0939775ccb059fda84969" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;DirectoryIterator&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="359b2f4e410b03b2de8a540faf1a8cbe64a62596" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;Dirichlet&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3937de8b6935b9a076bb9dcb210d61152b43258" translate="yes" xml:space="preserve">
          <source>Class &lt;code&gt;DirichletMultinomial&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
