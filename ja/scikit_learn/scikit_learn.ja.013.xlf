<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ja" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="8b02ae7bd0e5dc3ad9885f92e92e8dfc0759e655" translate="yes" xml:space="preserve">
          <source>Nearest neighbor and the curse of dimensionality</source>
          <target state="translated">近傍の隣人と次元性の呪い</target>
        </trans-unit>
        <trans-unit id="5db95950f32dda99cc2cb722bb90ec8e1106f00f" translate="yes" xml:space="preserve">
          <source>Needless to say, the cross-validation involved in Platt scaling is an expensive operation for large datasets. In addition, the probability estimates may be inconsistent with the scores, in the sense that the &amp;ldquo;argmax&amp;rdquo; of the scores may not be the argmax of the probabilities. (E.g., in binary classification, a sample may be labeled by &lt;code&gt;predict&lt;/code&gt; as belonging to a class that has probability &amp;lt;&amp;frac12; according to &lt;code&gt;predict_proba&lt;/code&gt;.) Platt&amp;rsquo;s method is also known to have theoretical issues. If confidence scores are required, but these do not have to be probabilities, then it is advisable to set &lt;code&gt;probability=False&lt;/code&gt; and use &lt;code&gt;decision_function&lt;/code&gt; instead of &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">言うまでもなく、Plattスケーリングに含まれる相互検証は、大規模なデータセットの場合、負荷の高い操作です。さらに、スコアの「argmax」が確率のargmaxではない場合があるという意味で、確率推定値はスコアと一致しない場合があります。 （例えば、バイナリ分類では、サンプルはによって標識することができる &lt;code&gt;predict&lt;/code&gt; に係る確率&amp;lt;半持つクラスに属するものとして &lt;code&gt;predict_proba&lt;/code&gt; を。）プラットの方法はまた、理論的な問題があることが知られています。信頼スコアが必要であるが、これらが確率である必要はない場合は、 &lt;code&gt;probability=False&lt;/code&gt; を設定し、 &lt;code&gt;predict_proba&lt;/code&gt; の代わりに &lt;code&gt;decision_function&lt;/code&gt; を使用することをお勧めします。</target>
        </trans-unit>
        <trans-unit id="5d2390b5dea0fabfaec001753e4e7ab98989a540" translate="yes" xml:space="preserve">
          <source>Neighborhoods are restricted the points at a distance lower than radius.</source>
          <target state="translated">近所は半径よりも低い距離でポイントが制限されています。</target>
        </trans-unit>
        <trans-unit id="71b4c3c0886885b3bdb78dd9feb31a745b98d96e" translate="yes" xml:space="preserve">
          <source>Neighbors-based classification is a type of &lt;em&gt;instance-based learning&lt;/em&gt; or &lt;em&gt;non-generalizing learning&lt;/em&gt;: it does not attempt to construct a general internal model, but simply stores instances of the training data. Classification is computed from a simple majority vote of the nearest neighbors of each point: a query point is assigned the data class which has the most representatives within the nearest neighbors of the point.</source>
          <target state="translated">近傍ベースの分類は、&lt;em&gt;インスタンスベースの学習&lt;/em&gt;または&lt;em&gt;非一般化学習の&lt;/em&gt;一種です&lt;em&gt;。&lt;/em&gt;一般的な内部モデルを構築しようとするのではなく、トレーニングデータのインスタンスを格納するだけです。分類は、各ポイントの最近傍の単純多数決から計算されます。クエリポイントには、ポイントの最近傍内で最も代表的なデータクラスが割り当てられます。</target>
        </trans-unit>
        <trans-unit id="f556f4d2d6fabe3a4b78772a04d1d08bf693d3a1" translate="yes" xml:space="preserve">
          <source>Neighbors-based regression can be used in cases where the data labels are continuous rather than discrete variables. The label assigned to a query point is computed based on the mean of the labels of its nearest neighbors.</source>
          <target state="translated">隣人ベースの回帰は、データ・ラベルが離散変数ではなく連続変数である場合に使用できます。クエリ点に割り当てられたラベルは、その最も近い隣人のラベルの平均に基づいて計算されます。</target>
        </trans-unit>
        <trans-unit id="f17c48105fdd248ad2de1f1ac3f1cabb43429cec" translate="yes" xml:space="preserve">
          <source>Nested cross-validation</source>
          <target state="translated">入れ子になったクロスバリデーション</target>
        </trans-unit>
        <trans-unit id="029453980f1f56140cec84a6516b88cf4da43353" translate="yes" xml:space="preserve">
          <source>Nested versus non-nested cross-validation</source>
          <target state="translated">入れ子にしたものと非入れ子にしたものの交差検証</target>
        </trans-unit>
        <trans-unit id="8c7edd0d2fdd43b38d35974fe3274794c4023842" translate="yes" xml:space="preserve">
          <source>Never unpickle untrusted data as it could lead to malicious code being executed upon loading.</source>
          <target state="translated">読み込み時に悪意のあるコードが実行される可能性があるため、信頼されていないデータを決してアンピクルしてはいけません。</target>
        </trans-unit>
        <trans-unit id="5a7c69a057920dae02f0ceb2f6458cca465cc67b" translate="yes" xml:space="preserve">
          <source>New data point to be inserted into the LSH Forest.</source>
          <target state="translated">LSHフォレストに挿入される新しいデータポイント。</target>
        </trans-unit>
        <trans-unit id="48ff6f532fccde3a69a322cc1151c107ad295ffd" translate="yes" xml:space="preserve">
          <source>New data to predict.</source>
          <target state="translated">予測するための新しいデータ。</target>
        </trans-unit>
        <trans-unit id="e461db7b42b4e1d723a59598bcca510859163aef" translate="yes" xml:space="preserve">
          <source>New data to transform.</source>
          <target state="translated">新しいデータを変換します。</target>
        </trans-unit>
        <trans-unit id="329a026b697f0ae2b6fcf5ede884e3254ea37650" translate="yes" xml:space="preserve">
          <source>New data, where n_samples in the number of samples and n_features is the number of features.</source>
          <target state="translated">新しいデータで、サンプル数のn_samples、n_featuresは特徴量の数です。</target>
        </trans-unit>
        <trans-unit id="68d214f5c1780f5e1075a93cc2054064839f0ca3" translate="yes" xml:space="preserve">
          <source>New data, where n_samples in the number of samples and n_features is the number of features. All values of X must be strictly greater than &amp;ldquo;-skewedness&amp;rdquo;.</source>
          <target state="translated">新しいデータ。サンプル数はn_samples、n_featuresは特徴の数です。Xのすべての値は、「-歪度」よりも厳密に大きい必要があります。</target>
        </trans-unit>
        <trans-unit id="6e6bacb37aec6214dc7bc345656e9fc6be9d8645" translate="yes" xml:space="preserve">
          <source>New data, where n_samples is the number of samples and n_components is the number of components.</source>
          <target state="translated">新しいデータで、n_samplesはサンプル数、n_componentsはコンポーネント数です。</target>
        </trans-unit>
        <trans-unit id="9774ac05294602db6164b128c08e5838d8dd2c30" translate="yes" xml:space="preserve">
          <source>New data, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">新しいデータで、n_samplesはサンプル数、n_featuresは特徴量の数です。</target>
        </trans-unit>
        <trans-unit id="2cec1d1d13a623e2cead9e687223c0b43410804e" translate="yes" xml:space="preserve">
          <source>New data.</source>
          <target state="translated">新しいデータです。</target>
        </trans-unit>
        <trans-unit id="2dcde8ec0560b6129ac7ceb94e6b76437cebda2e" translate="yes" xml:space="preserve">
          <source>New in version 0.10.</source>
          <target state="translated">バージョン0.10の新機能。</target>
        </trans-unit>
        <trans-unit id="b2a489d3a2d4dc51668c693a83253f531fff88d5" translate="yes" xml:space="preserve">
          <source>New in version 0.16: If the input is sparse, the output will be a &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt;. Else, output type is the same as the input type.</source>
          <target state="translated">バージョン0.16の新機能：入力がスパースの場合、出力は &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; になります。それ以外の場合、出力タイプは入力タイプと同じです。</target>
        </trans-unit>
        <trans-unit id="60b69c65bf1a3241e15d0d894ba32eab25d7cdd7" translate="yes" xml:space="preserve">
          <source>New in version 0.17.</source>
          <target state="translated">バージョン0.17の新機能。</target>
        </trans-unit>
        <trans-unit id="dc470080fe5f5c357c2ad73809b92faa7362d9a9" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;LinearDiscriminantAnalysis&lt;/em&gt;.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;LinearDiscriminantAnalysis&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="abf887094b036a443ef8f8f3b6efb216ee34cd24" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;QuadraticDiscriminantAnalysis&lt;/em&gt;</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;QuadraticDiscriminantAnalysis&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="6b2ff85ecc2a1a01962dd33b1e34753285ca0790" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;alpha&lt;/em&gt; used in the Coordinate Descent solver.</source>
          <target state="translated">バージョン0.17の新機能：座標降下ソルバーで使用される&lt;em&gt;アルファ&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="6808fe2d57e6aeef92c976187ce0a06abf1ebec1" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;cd&lt;/em&gt; coordinate descent method to improve speed.</source>
          <target state="translated">バージョン0.17の新機能：速度を改善する&lt;em&gt;cd&lt;/em&gt;座標降下法。</target>
        </trans-unit>
        <trans-unit id="7b66bf990e4010a15f9d64925c054de502637170" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;class_weight=&amp;rsquo;balanced&amp;rsquo;&lt;/em&gt;</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;class_weight = 'balanced'&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="ea86dc59df4308dd8eeb6d9e2ae15359239ba528" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;data_max_&lt;/em&gt;</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;data_max_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="1f6c1c10d870e8e7d70fedf31cf3a9ee8c7d746d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;data_min_&lt;/em&gt;</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;data_min_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="e853c35f6d282db32a11152441252fd53da7f57f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;data_range_&lt;/em&gt;</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;data_range_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="edb88b5a13c967ddfdc52fb30c87cf6cd8e55cef" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;decision_function_shape=&amp;rsquo;ovr&amp;rsquo;&lt;/em&gt; is recommended.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;Decision_function_shape = 'ovr'&lt;/em&gt;をお勧めします。</target>
        </trans-unit>
        <trans-unit id="18bd409dbab688800dc645ecf6dc2d319b6dc274" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;lasso_cd&lt;/em&gt; coordinate descent method to improve speed.</source>
          <target state="translated">バージョン0.17の新機能：速度を改善する&lt;em&gt;lasso_cd&lt;/em&gt;座標降下法。</target>
        </trans-unit>
        <trans-unit id="5c5696058be6bc7e1f1d8d04441e99d3b67a5a9d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;minmax_scale&lt;/em&gt; function interface to &lt;a href=&quot;sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt;&lt;code&gt;sklearn.preprocessing.MinMaxScaler&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;sklearn.preprocessing.MinMaxScaler&lt;/em&gt;への&lt;a href=&quot;sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt; &lt;code&gt;sklearn.preprocessing.MinMaxScaler&lt;/code&gt; &lt;/a&gt;関数インターフェース。</target>
        </trans-unit>
        <trans-unit id="61491e91a5cc882c8d0472b81b77bf74b7ea4e3d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;presort&lt;/em&gt; parameter.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;presort&lt;/em&gt;パラメータ。</target>
        </trans-unit>
        <trans-unit id="b2b731bdc9bf8dfc47673f8abfcc6c2c7f1f838c" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;random_state&lt;/em&gt; to support Stochastic Average Gradient.</source>
          <target state="translated">バージョン0.17の新機能：確率平均勾配をサポートする&lt;em&gt;random_state&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="727acdfec60aa8d5fe01b0fab35aa36437da02bb" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;sample_weight&lt;/em&gt; support to Classifier.</source>
          <target state="translated">バージョン0.17の新機能：分類&lt;em&gt;子&lt;/em&gt;に対する&lt;em&gt;sample_weight&lt;/em&gt;サポート。</target>
        </trans-unit>
        <trans-unit id="6a9e702e6dde8c5e083d3061949d66f0c1cd0a95" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;sample_weight&lt;/em&gt; support to LogisticRegression.</source>
          <target state="translated">バージョン0.17の新機能：LogisticRegressionの&lt;em&gt;sample_weight&lt;/em&gt;サポート。</target>
        </trans-unit>
        <trans-unit id="8bf7c72c906a46e4bafab411161accafb9f3258f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;scale_&lt;/em&gt;</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;scale_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="26b994b5337cbc66d9e87cecbe064dc645c2d9c5" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;scale_&lt;/em&gt; attribute.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;scale_&lt;/em&gt;属性。</target>
        </trans-unit>
        <trans-unit id="acaea6c314c50f12e63f6a31caa95dae9a93cb16" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;shuffle&lt;/em&gt; parameter used in the Coordinate Descent solver.</source>
          <target state="translated">バージョン0.17の新機能：座標降下ソルバーで使用される&lt;em&gt;シャッフル&lt;/em&gt;パラメーター。</target>
        </trans-unit>
        <trans-unit id="3c9ad8ece37a0ad66c0695ab197f051fc5c4f74b" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;warm_start&lt;/em&gt; constructor parameter.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;warm_start&lt;/em&gt;コンストラクターパラメーター。</target>
        </trans-unit>
        <trans-unit id="5d7ee9d78ae5139184086665f72ad9adc489e60f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;warm_start&lt;/em&gt; to support &lt;em&gt;lbfgs&lt;/em&gt;, &lt;em&gt;newton-cg&lt;/em&gt;, &lt;em&gt;sag&lt;/em&gt;, &lt;em&gt;saga&lt;/em&gt; solvers.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;warm_startは&lt;/em&gt;、&lt;em&gt;lbfgs&lt;/em&gt;、&lt;em&gt;newton-cg&lt;/em&gt;、&lt;em&gt;sag&lt;/em&gt;、&lt;em&gt;saga&lt;/em&gt;ソルバーをサポートします。</target>
        </trans-unit>
        <trans-unit id="6005792b774eeae7e9401b712800c9c602a22ebe" translate="yes" xml:space="preserve">
          <source>New in version 0.17: A function &lt;em&gt;label_ranking_loss&lt;/em&gt;</source>
          <target state="translated">バージョン0.17の新機能：関数&lt;em&gt;label_ranking_loss&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="e93da6946e01b1e23cbc1e7009a23425c993a384" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Approximate optimization &lt;em&gt;method&lt;/em&gt; via the Barnes-Hut.</source>
          <target state="translated">バージョン0.17の新機能：Barnes-Hutによる近似最適化&lt;em&gt;手法&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="9365f66e13f87cb3bbf8aaf0ec5863c643029aff" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Coordinate Descent solver.</source>
          <target state="translated">バージョン0.17の新機能:座標降下ソルバー。</target>
        </trans-unit>
        <trans-unit id="c589f3a156d1562e5e258c1483b29eaa7a3bb671" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Dummy Classifier now supports prior fitting strategy using parameter &lt;em&gt;prior&lt;/em&gt;.</source>
          <target state="translated">バージョン0.17の新機能：ダミー分類子は、パラメーター&lt;em&gt;previous&lt;/em&gt;を使用した以前のフィッティング戦略をサポートするようになり&lt;em&gt;ました&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="4c1ba1a9df4e3f1eda2057a3d8675352ba0c6105" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Gaussian Naive Bayes supports fitting with &lt;em&gt;sample_weight&lt;/em&gt;.</source>
          <target state="translated">バージョン0.17の新機能：Gaussian Naive Bayesは、&lt;em&gt;sample_weightによる&lt;/em&gt;フィッティングをサポートしてい&lt;em&gt;ます&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="b94e1008bb6bd8880b48f9c93c89015eb39cf414" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Parallel Execution using &lt;em&gt;n_jobs&lt;/em&gt;.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;n_jobs&lt;/em&gt;を使用した並列実行。</target>
        </trans-unit>
        <trans-unit id="56295350a01a04673ce10a1274f3f2850857660f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Regularization parameter &lt;em&gt;l1_ratio&lt;/em&gt; used in the Coordinate Descent solver.</source>
          <target state="translated">バージョン0.17の新機能：座標降下ソルバーで使用される正則化パラメーター&lt;em&gt;l1_ratio&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="bfb15daea388e7bc4652a64e3ee368ec3ef32e45" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Stochastic Average Gradient descent solver.</source>
          <target state="translated">バージョン0.17の新機能:確率的平均勾配降下ソルバー。</target>
        </trans-unit>
        <trans-unit id="90ee93ad6b0e53eed26b86779c90b9633cb9848b" translate="yes" xml:space="preserve">
          <source>New in version 0.17: class_weight == &amp;lsquo;balanced&amp;rsquo;</source>
          <target state="translated">バージョン0.17の新機能：class_weight == 'balanced'</target>
        </trans-unit>
        <trans-unit id="db422a34a0885d2d1033db36affb13affc0d2065" translate="yes" xml:space="preserve">
          <source>New in version 0.17: metric &lt;em&gt;precomputed&lt;/em&gt; to accept precomputed sparse matrix.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;事前計算さ&lt;/em&gt;れた疎行列を受け入れるように事前&lt;em&gt;計算さ&lt;/em&gt;れたメトリック。</target>
        </trans-unit>
        <trans-unit id="545f1d599ea32d73544f4951073f7ce5e1f64bf6" translate="yes" xml:space="preserve">
          <source>New in version 0.17: optional parameter &lt;em&gt;presort&lt;/em&gt;.</source>
          <target state="translated">バージョン0.17の新機能：オプションのパラメーター&lt;em&gt;presort&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="1c0b7964a491c4c8234983325c356450f442446c" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;code&gt;dense_output&lt;/code&gt; for dense output.</source>
          <target state="translated">バージョン0.17の新機能：稠密な出力用のパラメーター &lt;code&gt;dense_output&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="46c6419997a8eb39c61c2c50456a363282489838" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;class_weight&lt;/em&gt; to automatically weight samples.</source>
          <target state="translated">バージョン0.17の新機能：サンプルを自動的に重み付けするパラメーター&lt;em&gt;class_weight&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="e8cbf38ab0cedfa95f7fc33391f9602285bd6e17" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;drop_intermediate&lt;/em&gt;.</source>
          <target state="translated">バージョン0.17の新機能：パラメータ&lt;em&gt;drop_intermediate&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="960c43bc8538ca35574a01cc68a5f2b510105d22" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;multilabel&lt;/em&gt; to support multilabel datasets.</source>
          <target state="translated">バージョン0.17の新機能：マルチラベルデータセットをサポートするパラメーター&lt;em&gt;マルチラベル&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="3788b38f2b10aab217952de3365bf7b88f170f8d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;n_iter_without_progress&lt;/em&gt; to control stopping criteria.</source>
          <target state="translated">バージョン0.17の新機能：停止基準を制御するパラメーター&lt;em&gt;n_iter_without_progress&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="8db0c53c524e84f302dbc1a0dbd534321460f08f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;sample_weight&lt;/em&gt; support to LinearRegression.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;LinearRegression&lt;/em&gt;へのパラメーター&lt;em&gt;sample_weight&lt;/em&gt;サポート。</target>
        </trans-unit>
        <trans-unit id="2a05312b3a418ca739af1c2a1750981f3df80101" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter to allow &lt;em&gt;sparse&lt;/em&gt; output.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;スパース&lt;/em&gt;出力を許可するパラメーター。</target>
        </trans-unit>
        <trans-unit id="8550f8dcfdefc5ee2595ff5a932287ae10047927" translate="yes" xml:space="preserve">
          <source>New in version 0.18.</source>
          <target state="translated">バージョン0.18の新機能。</target>
        </trans-unit>
        <trans-unit id="bc1978fea309e92ee1923ea481a6fd1eab915379" translate="yes" xml:space="preserve">
          <source>New in version 0.18.0.</source>
          <target state="translated">バージョン0.18.0の新機能。</target>
        </trans-unit>
        <trans-unit id="11462cefb53316ba0a8e0880815bfa04af36466b" translate="yes" xml:space="preserve">
          <source>New in version 0.18: Mean Absolute Error (MAE) criterion.</source>
          <target state="translated">バージョン0.18の新機能:平均絶対誤差(MAE)基準。</target>
        </trans-unit>
        <trans-unit id="f3588d83291a2be20994392c7201429910c5a8e9" translate="yes" xml:space="preserve">
          <source>New in version 0.18: Stochastic Average Gradient descent solver for &amp;lsquo;multinomial&amp;rsquo; case.</source>
          <target state="translated">バージョン0.18の新機能：「多項式」の場合の確率的平均勾配降下ソルバー。</target>
        </trans-unit>
        <trans-unit id="0eb4d3b4907b28878c6666a16cc5abd9e36f4f00" translate="yes" xml:space="preserve">
          <source>New in version 0.19.</source>
          <target state="translated">バージョン0.19の新機能。</target>
        </trans-unit>
        <trans-unit id="e10489dae5e0fb6aa174b77a26bd312889388c1d" translate="yes" xml:space="preserve">
          <source>New in version 0.19: Multiplicative Update solver.</source>
          <target state="translated">バージョン0.19の新機能:乗算更新ソルバー。</target>
        </trans-unit>
        <trans-unit id="c260a9e7caaac82377fee1bfeace2cf2272b4b1a" translate="yes" xml:space="preserve">
          <source>New in version 0.19: SAGA solver.</source>
          <target state="translated">バージョン0.19の新機能:SAGAソルバー。</target>
        </trans-unit>
        <trans-unit id="d56c2d84411d9a6c91bdf6681efc0b4e653d1de5" translate="yes" xml:space="preserve">
          <source>New in version 0.19: l1 penalty with SAGA solver (allowing &amp;lsquo;multinomial&amp;rsquo; + L1)</source>
          <target state="translated">バージョン0.19の新機能：SAGAソルバーを使用したl1ペナルティ（「多項式」+ L1を許可）</target>
        </trans-unit>
        <trans-unit id="69d687c70a1657bfe591a19056b06b9f07dd4b5e" translate="yes" xml:space="preserve">
          <source>New in version 0.19: parameter &lt;em&gt;average&lt;/em&gt; to use weights averaging in SGD</source>
          <target state="translated">バージョン0.19の新機能：SGDで加重&lt;em&gt;平均&lt;/em&gt;を使用するパラメーター&lt;em&gt;平均&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="e6570e8764c255a027de40e9e3eb2d1c722d495c" translate="yes" xml:space="preserve">
          <source>New in version 0.20.</source>
          <target state="translated">バージョン0.20の新機能。</target>
        </trans-unit>
        <trans-unit id="92da9b59ee8f1aee40e76bd7e7f9a69e15158836" translate="yes" xml:space="preserve">
          <source>New in version 0.20: &lt;code&gt;behaviour&lt;/code&gt; is added in 0.20 for back-compatibility purpose.</source>
          <target state="translated">バージョン0.20の新機能：互換性のために、 &lt;code&gt;behaviour&lt;/code&gt; が0.20に追加されました。</target>
        </trans-unit>
        <trans-unit id="89ff3bd96af64e1a70d0744f65ccf966040b095d" translate="yes" xml:space="preserve">
          <source>New in version 0.20: &lt;code&gt;force_all_finite&lt;/code&gt; accepts the string &lt;code&gt;'allow-nan'&lt;/code&gt;.</source>
          <target state="translated">バージョン0.20の新機能： &lt;code&gt;force_all_finite&lt;/code&gt; は文字列 &lt;code&gt;'allow-nan'&lt;/code&gt; を受け入れます。</target>
        </trans-unit>
        <trans-unit id="1468919e56b56c4ded7ab6dba66d158a1002d5be" translate="yes" xml:space="preserve">
          <source>New in version 0.20: parameter &lt;em&gt;sample_weight&lt;/em&gt; support to BayesianRidge.</source>
          <target state="translated">バージョン0.20の新機能：BayesianRidgeに対するパラメーター&lt;em&gt;sample_weightの&lt;/em&gt;サポート。</target>
        </trans-unit>
        <trans-unit id="7c256855a0d81868bca650e3f1d5676a1f0ae5da" translate="yes" xml:space="preserve">
          <source>New in version 0.20: strategy=&amp;rdquo;constant&amp;rdquo; for fixed value imputation.</source>
          <target state="translated">バージョン0.20の新機能：固定値補完のためのstrategy =&amp;rdquo; constant&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="3dcb523c8b35ef7bba188a1b72a37583d73585c0" translate="yes" xml:space="preserve">
          <source>New in version 1.7.0.</source>
          <target state="translated">バージョン1.7.0の新機能。</target>
        </trans-unit>
        <trans-unit id="58fbaea601eebe84b9d8f8508a33c9a4b3025541" translate="yes" xml:space="preserve">
          <source>New to Scientific Python?</source>
          <target state="translated">Scientific Pythonは初めてですか?</target>
        </trans-unit>
        <trans-unit id="9f6a58e9ea6f2ce3d4a15836e22f7c6b8aed6e50" translate="yes" xml:space="preserve">
          <source>Next we create 10 classifier chains. Each classifier chain contains a logistic regression model for each of the 14 labels. The models in each chain are ordered randomly. In addition to the 103 features in the dataset, each model gets the predictions of the preceding models in the chain as features (note that by default at training time each model gets the true labels as features). These additional features allow each chain to exploit correlations among the classes. The Jaccard similarity score for each chain tends to be greater than that of the set independent logistic models.</source>
          <target state="translated">次に、10個の分類器チェーンを作成します。各分類器チェーンは、14個のラベルのそれぞれについてのロジスティック回帰モデルを含みます。各チェーンのモデルはランダムに順序付けされています。データセットの103個の特徴量に加えて、各モデルは、チェーン内の先行モデルの予測値を特徴量として取得します(学習時のデフォルトでは、各モデルは真のラベルを特徴量として取得することに注意してください)。これらの追加の特徴により、各チェーンはクラス間の相関を利用することができます。各連鎖のJaccard類似度スコアは,集合の独立したロジスティック・モデルの類似度スコアよりも大きくなる傾向があります.</target>
        </trans-unit>
        <trans-unit id="1ae340c010af24c68842322aa72c1a3f11d7dacf" translate="yes" xml:space="preserve">
          <source>Next, let&amp;rsquo;s compare the accuracy of &lt;code&gt;SVC&lt;/code&gt; and &lt;code&gt;most_frequent&lt;/code&gt;:</source>
          <target state="translated">次に、 &lt;code&gt;SVC&lt;/code&gt; と &lt;code&gt;most_frequent&lt;/code&gt; 精度を比較してみましょう。</target>
        </trans-unit>
        <trans-unit id="cedfa60674e3afd543975ecc551b601711fc3043" translate="yes" xml:space="preserve">
          <source>Nick Street</source>
          <target state="translated">ニックストリート</target>
        </trans-unit>
        <trans-unit id="91b4478e43e149a2b1b071a76d13f7593530f726" translate="yes" xml:space="preserve">
          <source>No measurement errors, only modelling errors (fitting a sine with a polynomial)</source>
          <target state="translated">測定誤差はなく,モデリング誤差のみ(多項式を用いた正弦波のフィット</target>
        </trans-unit>
        <trans-unit id="ea249cedbd757dbfa8a8d6da523734c90b706a5c" translate="yes" xml:space="preserve">
          <source>No-op.</source>
          <target state="translated">No-op.</target>
        </trans-unit>
        <trans-unit id="91eb5693ecb00a7deb087fb78e26bb4414167d8c" translate="yes" xml:space="preserve">
          <source>Noisy (non informative) features are added to the iris data and univariate feature selection is applied. For each feature, we plot the p-values for the univariate feature selection and the corresponding weights of an SVM. We can see that univariate feature selection selects the informative features and that these have larger SVM weights.</source>
          <target state="translated">虹彩データにノイズの多い(非情報的な)特徴が追加され、一変量特徴選択が適用される。各特徴について、一変量特徴選択のp値とSVMの対応する重みをプロットします。一変量特徴選択では情報量の多い特徴が選択され、SVMの重みが大きくなることがわかります。</target>
        </trans-unit>
        <trans-unit id="79474361fd46a8f4ede8053ea7e6b01fe3e41cb6" translate="yes" xml:space="preserve">
          <source>Non metric &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; focuses on the ordination of the data. If \(S_{ij} &amp;lt; S_{kl}\), then the embedding should enforce \(d_{ij} &amp;lt; d_{jk}\). A simple algorithm to enforce that is to use a monotonic regression of \(d_{ij}\) on \(S_{ij}\), yielding disparities \(\hat{d}_{ij}\) in the same order as \(S_{ij}\).</source>
          <target state="translated">非メトリック&lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt; &lt;code&gt;MDS&lt;/code&gt; &lt;/a&gt;は、データの順序に焦点を当てています。\（S_ {ij} &amp;lt;S_ {kl} \）の場合、埋め込みは\（d_ {ij} &amp;lt;d_ {jk} \）を強制する必要があります。これを実施する単純なアルゴリズムは、\（S_ {ij} \）で\（d_ {ij} \）の単調回帰を使用し、同じ順序で視差\（\ hat {d} _ {ij} \）を生成することです。 \（S_ {ij} \）として。</target>
        </trans-unit>
        <trans-unit id="cde06657a13db59e2826469e9066556199cf0756" translate="yes" xml:space="preserve">
          <source>Non-Negative Matrix Factorization (NMF)</source>
          <target state="translated">非負行列因数分解(NMF)</target>
        </trans-unit>
        <trans-unit id="68976e33a3c8d43b10cc9525f441a8468ba55fa6" translate="yes" xml:space="preserve">
          <source>Non-adjusted measures such as the V-Measure show a dependency between the number of clusters and the number of samples: the mean V-Measure of random labeling increases significantly as the number of clusters is closer to the total number of samples used to compute the measure.</source>
          <target state="translated">Vメジャーのような非調整メジャーは、クラスタ数とサンプル数の間に依存性を示します:ランダムラベリングの平均Vメジャーは、クラスタ数がメジャーの計算に使用されるサンプル数の合計に近づくにつれて有意に増加します。</target>
        </trans-unit>
        <trans-unit id="f88076515287321d1c6a383215ea60241a35e283" translate="yes" xml:space="preserve">
          <source>Non-categorical features are always stacked to the right of the matrix.</source>
          <target state="translated">カテゴライズされていない特徴は、常に行列の右側に積み上げられています。</target>
        </trans-unit>
        <trans-unit id="24a06b494b2c3f21a83a9f0f9fdd0eb49c7e8dca" translate="yes" xml:space="preserve">
          <source>Non-deterministic iterable over random candidate combinations for hyper- parameter search. If all parameters are presented as a list, sampling without replacement is performed. If at least one parameter is given as a distribution, sampling with replacement is used. It is highly recommended to use continuous distributions for continuous parameters.</source>
          <target state="translated">超パラメータ探索のためのランダムな候補の組み合わせに対する非決定論的な反復可能性。すべてのパラメータがリストとして提示された場合、置換なしのサンプリングが実行されます。少なくとも1つのパラメータが分布として与えられた場合、置換を伴うサンプリングが使用される。連続パラメータには連続分布を使用することが強く推奨されます。</target>
        </trans-unit>
        <trans-unit id="aed22ef611faa3f82d0b12f8491e5be1b5315c9c" translate="yes" xml:space="preserve">
          <source>Non-flat geometry clustering is useful when the clusters have a specific shape, i.e. a non-flat manifold, and the standard euclidean distance is not the right metric. This case arises in the two top rows of the figure above.</source>
          <target state="translated">非平坦形状クラスタリングは、クラスタが特定の形状、すなわち非平坦な多様体を持ち、標準的なユークリッド距離が正しいメトリックではない場合に有用である。このケースは、上の図の上の2つの行に現れます。</target>
        </trans-unit>
        <trans-unit id="d81a98cb7a8247dec56f2cf029b08c2754ab68be" translate="yes" xml:space="preserve">
          <source>Non-flat geometry, uneven cluster sizes</source>
          <target state="translated">非フラット形状、不均一なクラスターサイズ</target>
        </trans-unit>
        <trans-unit id="7b7727887cb8285fcb9cde529e76207a2b5daf47" translate="yes" xml:space="preserve">
          <source>Non-linear SVM</source>
          <target state="translated">非線形SVM</target>
        </trans-unit>
        <trans-unit id="71ce2ef9edaad67f892b761574c731b5860fa36a" translate="yes" xml:space="preserve">
          <source>Non-linear dimensionality reduction through Isometric Mapping</source>
          <target state="translated">アイソメトリックマッピングによる非線形次元削減</target>
        </trans-unit>
        <trans-unit id="ca7d812e2ac6b7f89b19c50d5270fc422c0be019" translate="yes" xml:space="preserve">
          <source>Non-linear dimensionality reduction through the use of kernels (see &lt;a href=&quot;../metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt;).</source>
          <target state="translated">カーネルの使用による非線形の次元削減（&lt;a href=&quot;../metrics#metrics&quot;&gt;ペアワイズメトリック、アフィニティとカーネルを&lt;/a&gt;参照）。</target>
        </trans-unit>
        <trans-unit id="69451865a7cd1607229864b3445a0d944d36c962" translate="yes" xml:space="preserve">
          <source>Non-negative Matrix Factorization is applied with two different objective functions: the Frobenius norm, and the generalized Kullback-Leibler divergence. The latter is equivalent to Probabilistic Latent Semantic Indexing.</source>
          <target state="translated">非負行列因子分解は、2つの異なる目的関数、すなわち、フロベニウスノルムと一般化されたKullback-Leibler発散を用いて適用される。後者は、確率的潜在的意味索引付けに相当する。</target>
        </trans-unit>
        <trans-unit id="049d9a61285421f1af788bdccc4c4d917a5eaaf1" translate="yes" xml:space="preserve">
          <source>Non-negative regularization added to the diagonal of covariance. Allows to assure that the covariance matrices are all positive.</source>
          <target state="translated">共分散の対角線に追加される非負の正則化.共分散行列がすべて正であることを保証することができます.</target>
        </trans-unit>
        <trans-unit id="e703a00863d9d81a02bf7dd7a3e8359867bf5db3" translate="yes" xml:space="preserve">
          <source>Non-negativity: d(x, y) &amp;gt;= 0</source>
          <target state="translated">非負性：d（x、y）&amp;gt; = 0</target>
        </trans-unit>
        <trans-unit id="8ae68d0948137da9bc3c21e9e27af7e4326ecb8c" translate="yes" xml:space="preserve">
          <source>Non-perfect labelings that assign all classes members to the same clusters are still complete:</source>
          <target state="translated">すべてのクラスのメンバーを同じクラスタに割り当てる非完全なラベリングはまだ完成しています。</target>
        </trans-unit>
        <trans-unit id="3eebc1d955c5491410d251396ee4489d9155e3cb" translate="yes" xml:space="preserve">
          <source>Non-perfect labelings that further split classes into more clusters can be perfectly homogeneous:</source>
          <target state="translated">クラスをさらに多くのクラスタに分割する非完全なラベリングは、完全に均質なものにすることができます。</target>
        </trans-unit>
        <trans-unit id="6eef6648406c333a4035cd5e60d0bf2ecf2606d7" translate="yes" xml:space="preserve">
          <source>None</source>
          <target state="translated">None</target>
        </trans-unit>
        <trans-unit id="a7d85d18152a49d1da74509ce25fde6fe11019f7" translate="yes" xml:space="preserve">
          <source>None, in which case all the jobs are immediately created and spawned. Use this for lightweight and fast-running jobs, to avoid delays due to on-demand spawning of the jobs</source>
          <target state="translated">Noneの場合、すべてのジョブが即座に作成され、スポーンされます。軽量で高速に実行されるジョブに使用し、ジョブのオンデマンドスポーンによる遅延を回避します。</target>
        </trans-unit>
        <trans-unit id="bbd7e8e517d8f43bda3aa20760641b5d7e8f9cfa" translate="yes" xml:space="preserve">
          <source>None, to use the default 3-fold cross validation,</source>
          <target state="translated">なし、デフォルトの3つ折りのクロスバリデーションを使用します。</target>
        </trans-unit>
        <trans-unit id="888271bd46afcca7669b4e3985d515e3c7e7f9d8" translate="yes" xml:space="preserve">
          <source>None, to use the default 3-fold cross-validation,</source>
          <target state="translated">なし、デフォルトの3-foldクロスバリデーションを使用します。</target>
        </trans-unit>
        <trans-unit id="701ee91f692f57554848e1c6f0edff54e4f7d839" translate="yes" xml:space="preserve">
          <source>None, to use the efficient Leave-One-Out cross-validation</source>
          <target state="translated">なし、効率的なLeave-One-Outクロスバリデーションを使用するには</target>
        </trans-unit>
        <trans-unit id="64b167835d86e0f7a116b1ea8c9009b09567d9bf" translate="yes" xml:space="preserve">
          <source>None: no shrinkage (default).</source>
          <target state="translated">なし:収縮なし(デフォルト)。</target>
        </trans-unit>
        <trans-unit id="147e773e8ccd784cf7c8200779acc5978ecfc7ee" translate="yes" xml:space="preserve">
          <source>Nonflavanoid Phenols:</source>
          <target state="translated">ノンフラバノイドフェノール類。</target>
        </trans-unit>
        <trans-unit id="906dd4b97159051d3691e718b04ffdc7a18ebb83" translate="yes" xml:space="preserve">
          <source>Nonflavanoid phenols</source>
          <target state="translated">ノンフラバノイドフェノール</target>
        </trans-unit>
        <trans-unit id="c5cf58c1ab6a436b96c0b6790ce2675b3d6917ee" translate="yes" xml:space="preserve">
          <source>Norm used to normalize term vectors. None for no normalization.</source>
          <target state="translated">項ベクトルの正規化に使用されるノルム。正規化を行わない場合は None。</target>
        </trans-unit>
        <trans-unit id="baeabcda0198bd70ffaabb333ee49b38a8e0ee34" translate="yes" xml:space="preserve">
          <source>Normal and Shrinkage Linear Discriminant Analysis for classification</source>
          <target state="translated">分類のための正規および収縮線形判別分析</target>
        </trans-unit>
        <trans-unit id="1c651aee92e671db7fa9048c6cdacbd12ea197da" translate="yes" xml:space="preserve">
          <source>Normalization matrix needed for embedding. Square root of the kernel matrix on &lt;code&gt;components_&lt;/code&gt;.</source>
          <target state="translated">埋め込みに必要な正規化行列。 &lt;code&gt;components_&lt;/code&gt; のカーネル行列の平方根。</target>
        </trans-unit>
        <trans-unit id="b2dd009a742549bee9ad100542b0f67ba3a05708" translate="yes" xml:space="preserve">
          <source>Normalize samples individually to unit norm.</source>
          <target state="translated">サンプルを個別に単位ノルムに正規化します。</target>
        </trans-unit>
        <trans-unit id="1cc78071dce653cdb1a895ced93da41b36798ab2" translate="yes" xml:space="preserve">
          <source>Normalized Mutual Information</source>
          <target state="translated">正規化相互情報</target>
        </trans-unit>
        <trans-unit id="6d15c4ae0d04e936f901929872b9ad476ca9800b" translate="yes" xml:space="preserve">
          <source>Normalized Mutual Information (NMI) is a normalization of the Mutual Information (MI) score to scale the results between 0 (no mutual information) and 1 (perfect correlation). In this function, mutual information is normalized by some generalized mean of &lt;code&gt;H(labels_true)&lt;/code&gt; and &lt;code&gt;H(labels_pred))&lt;/code&gt;, defined by the &lt;code&gt;average_method&lt;/code&gt;.</source>
          <target state="translated">正規化相互情報量（NMI）は、相互情報量（MI）スコアを正規化して、結果を0（相互情報なし）と1（完全相関）の間でスケーリングします。この関数では、相互情報は、 &lt;code&gt;average_method&lt;/code&gt; で定義された &lt;code&gt;H(labels_true)&lt;/code&gt; および &lt;code&gt;H(labels_pred))&lt;/code&gt; のいくつかの一般化された平均によって正規化されます。</target>
        </trans-unit>
        <trans-unit id="2009d38e6ab058cf38d5f44a4aa1fda0316b3372" translate="yes" xml:space="preserve">
          <source>Normalized Mutual Information between two clusterings.</source>
          <target state="translated">2つのクラスタリング間の正規化された相互情報。</target>
        </trans-unit>
        <trans-unit id="4f7979e77b9a0db2d6d4f14823a6b0012cc9a130" translate="yes" xml:space="preserve">
          <source>Normalized cuts and image segmentation, 2000 Jianbo Shi, Jitendra Malik &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&lt;/a&gt;</source>
          <target state="translated">正規化されたカットと画像セグメンテーション、2000 Jianbo Shi、Jitendra Malik &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="bcdc09e5b38e3433007fe04c41bf1718c142c846" translate="yes" xml:space="preserve">
          <source>Normalized input X.</source>
          <target state="translated">正規化された入力X。</target>
        </trans-unit>
        <trans-unit id="cf0305ad6a5172727382b32897870cffde3ce433" translate="yes" xml:space="preserve">
          <source>Normalized probability distributions across class labels</source>
          <target state="translated">クラスラベルにまたがる正規化された確率分布</target>
        </trans-unit>
        <trans-unit id="f4b126cd68b1eba9b799b0ffccc1898e8bfe924f" translate="yes" xml:space="preserve">
          <source>Normalizer</source>
          <target state="translated">Normalizer</target>
        </trans-unit>
        <trans-unit id="a19366221588f526c166820c530dd8f2268ea2b7" translate="yes" xml:space="preserve">
          <source>Not all models benefit from optimized BLAS and Lapack implementations. For instance models based on (randomized) decision trees typically do not rely on BLAS calls in their inner loops, nor do kernel SVMs (&lt;code&gt;SVC&lt;/code&gt;, &lt;code&gt;SVR&lt;/code&gt;, &lt;code&gt;NuSVC&lt;/code&gt;, &lt;code&gt;NuSVR&lt;/code&gt;). On the other hand a linear model implemented with a BLAS DGEMM call (via &lt;code&gt;numpy.dot&lt;/code&gt;) will typically benefit hugely from a tuned BLAS implementation and lead to orders of magnitude speedup over a non-optimized BLAS.</source>
          <target state="translated">すべてのモデルが、最適化されたBLASおよびLapack実装の恩恵を受けるわけではありません。たとえば、（ランダム化された）決定木に基づくインスタンスモデルは、通常、内部ループのBLAS呼び出しに依存せず、カーネルSVM（ &lt;code&gt;SVC&lt;/code&gt; 、 &lt;code&gt;SVR&lt;/code&gt; 、 &lt;code&gt;NuSVC&lt;/code&gt; 、 &lt;code&gt;NuSVR&lt;/code&gt; ）にも依存しません。一方、 &lt;code&gt;numpy.dot&lt;/code&gt; DGEMM呼び出し（numpy.dotを使用）で実装された線形モデルは、通常、調整されたBLAS実装から大きなメリットを得て、最適化されていないBLASよりも桁違いに高速化します。</target>
        </trans-unit>
        <trans-unit id="d1a17af19f5388af9d6596cc0ea7dbb1d739e255" translate="yes" xml:space="preserve">
          <source>Not available</source>
          <target state="translated">利用できません。</target>
        </trans-unit>
        <trans-unit id="2f1306ffef95e5ddbb8f4b2f3a60c6ede1c9a1f3" translate="yes" xml:space="preserve">
          <source>Not scalable</source>
          <target state="translated">スケーラブルではない</target>
        </trans-unit>
        <trans-unit id="6671bcf801635373715efa03216b0f9d13f34c22" translate="yes" xml:space="preserve">
          <source>Not scalable with &lt;code&gt;n_samples&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;n_samples&lt;/code&gt; ではスケーラブルではありません</target>
        </trans-unit>
        <trans-unit id="d70eb56b501fa2ef808df1c818502bbb5b800d19" translate="yes" xml:space="preserve">
          <source>Not scalable with n_samples</source>
          <target state="translated">n_samplesではスケーラブルではない</target>
        </trans-unit>
        <trans-unit id="2c924e3088204ee77ba681f72be3444357932fca" translate="yes" xml:space="preserve">
          <source>Note</source>
          <target state="translated">Note</target>
        </trans-unit>
        <trans-unit id="14ba06ae5f3993adde2848620bcf508016c9c617" translate="yes" xml:space="preserve">
          <source>Note : Laplacian Eigenmaps is the actual algorithm implemented here.</source>
          <target state="translated">注:ラプラシアン固有マップは、ここで実装されている実際のアルゴリズムです。</target>
        </trans-unit>
        <trans-unit id="21546711de316cf946ba53a498f41ae0550616cc" translate="yes" xml:space="preserve">
          <source>Note how some use the group/class information while others do not.</source>
          <target state="translated">グループ/クラス情報を使用している人もいれば、使用していない人もいることに注意してください。</target>
        </trans-unit>
        <trans-unit id="c3c271844b997675d3bb1a8d39599227fbe7b490" translate="yes" xml:space="preserve">
          <source>Note how the optimal value of alpha varies for each fold. This illustrates why nested-cross validation is necessary when trying to evaluate the performance of a method for which a parameter is chosen by cross-validation: this choice of parameter may not be optimal for unseen data.</source>
          <target state="translated">アルファの最適値が、各フォールドについてどのように変化するかに注意してください。これは、クロスバリデーションによってパラメータが選択された手法の性能を評価しようとするときに、なぜ入れ子交差バリデーションが必要なのかを説明しています:このパラメータの選択は、見えないデータに対して最適ではないかもしれません。</target>
        </trans-unit>
        <trans-unit id="92e53ea7bdcc226c7bc1da5197dd56da468b26d1" translate="yes" xml:space="preserve">
          <source>Note on inappropriate usage of cross_val_predict</source>
          <target state="translated">cross_val_predictの不適切な使い方についての注意点</target>
        </trans-unit>
        <trans-unit id="029f2db65bc50c936edb77149f903f8d03abd995" translate="yes" xml:space="preserve">
          <source>Note on the lookup process: depending on the type of name_or_id, will choose between integer id lookup or metadata name lookup by looking at the unzipped archives and metadata file.</source>
          <target state="translated">検索処理に関する注意事項:name_or_id のタイプに応じて、解凍されたアーカイブとメタデータファイルを見て、整数 ID 検索かメタデータ名検索のどちらかを選択します。</target>
        </trans-unit>
        <trans-unit id="637677b94f16fb377d9bcfbae4602956aad7da33" translate="yes" xml:space="preserve">
          <source>Note that &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;saga&amp;rsquo; fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing.</source>
          <target state="translated">「サグ」と「サガ」の高速収束は、ほぼ同じスケールの機能でのみ保証されることに注意してください。sklearn.preprocessingのスケーラーを使用してデータを前処理できます。</target>
        </trans-unit>
        <trans-unit id="fb2d865fbf24560bc423d4932883d3877000a02a" translate="yes" xml:space="preserve">
          <source>Note that &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; does not support &lt;code&gt;predict&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;score_samples&lt;/code&gt; methods by default but only a &lt;code&gt;fit_predict&lt;/code&gt; method, as this estimator was originally meant to be applied for outlier detection. The scores of abnormality of the training samples are accessible through the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute.</source>
          <target state="translated">注意&lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; が&lt;/a&gt;サポートされていない &lt;code&gt;predict&lt;/code&gt; 、 &lt;code&gt;decision_function&lt;/code&gt; と &lt;code&gt;score_samples&lt;/code&gt; デフォルトだけでメソッドを &lt;code&gt;fit_predict&lt;/code&gt; のこの推定は、もともと外れ値検出に適用されることを意図したように、方法。トレーニングサンプルの異常スコアには、 &lt;code&gt;negative_outlier_factor_&lt;/code&gt; 属性を介してアクセスできます。</target>
        </trans-unit>
        <trans-unit id="9cc23e915eab7d76b355d3d788a42c200a9cfa75" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;fit_predict&lt;/code&gt; is not available in this case.</source>
          <target state="translated">この場合、 &lt;code&gt;fit_predict&lt;/code&gt; は使用できません。</target>
        </trans-unit>
        <trans-unit id="05da1e73517821e307ab23620f26a2cb5cf58320" translate="yes" xml:space="preserve">
          <source>Note that Sparse PCA components orthogonality is not enforced as in PCA hence one cannot use a simple linear projection.</source>
          <target state="translated">スパースPCA成分の直交性はPCAのように強制されないので、単純な線形射影を使用できないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="8a36ac6808e625c8a29705bcc1d1fb6cf63760b8" translate="yes" xml:space="preserve">
          <source>Note that before SciPy 0.16, the &lt;code&gt;scipy.stats.distributions&lt;/code&gt; do not accept a custom RNG instance and always use the singleton RNG from &lt;code&gt;numpy.random&lt;/code&gt;. Hence setting &lt;code&gt;random_state&lt;/code&gt; will not guarantee a deterministic iteration whenever &lt;code&gt;scipy.stats&lt;/code&gt; distributions are used to define the parameter search space.</source>
          <target state="translated">SciPy 0.16より前は、 &lt;code&gt;scipy.stats.distributions&lt;/code&gt; はカスタムRNGインスタンスを受け入れず、常に &lt;code&gt;numpy.random&lt;/code&gt; からのシングルトンRNGを使用することに注意してください。したがって、 &lt;code&gt;random_state&lt;/code&gt; を設定しても、 &lt;code&gt;scipy.stats&lt;/code&gt; 分布を使用してパラメーターサーチスペースを定義する場合は、決定的な反復が保証されません。</target>
        </trans-unit>
        <trans-unit id="9a716693e5778e1463e7644515aedc4c9b2a1b82" translate="yes" xml:space="preserve">
          <source>Note that before SciPy 0.16, the &lt;code&gt;scipy.stats.distributions&lt;/code&gt; do not accept a custom RNG instance and always use the singleton RNG from &lt;code&gt;numpy.random&lt;/code&gt;. Hence setting &lt;code&gt;random_state&lt;/code&gt; will not guarantee a deterministic iteration whenever &lt;code&gt;scipy.stats&lt;/code&gt; distributions are used to define the parameter search space. Deterministic behavior is however guaranteed from SciPy 0.16 onwards.</source>
          <target state="translated">SciPy 0.16より前は、 &lt;code&gt;scipy.stats.distributions&lt;/code&gt; はカスタムRNGインスタンスを受け入れず、常に &lt;code&gt;numpy.random&lt;/code&gt; からのシングルトンRNGを使用することに注意してください。したがって、 &lt;code&gt;random_state&lt;/code&gt; を設定しても、 &lt;code&gt;scipy.stats&lt;/code&gt; 分布を使用してパラメーターサーチスペースを定義する場合は、決定的な反復が保証されません。ただし、確定的な動作はSciPy 0.16以降で保証されています。</target>
        </trans-unit>
        <trans-unit id="8c441ea193159e43e5ae4f2f43b7cd455bbc50a0" translate="yes" xml:space="preserve">
          <source>Note that for floating-point input, the mean is computed using the same precision the input has. Depending on the input data, this can cause the results to be inaccurate, especially for &lt;code&gt;float32&lt;/code&gt; (see example below). Specifying a higher-precision accumulator using the &lt;code&gt;dtype&lt;/code&gt; keyword can alleviate this issue.</source>
          <target state="translated">浮動小数点入力の場合、平均は入力と同じ精度を使用して計算されることに注意してください。入力データによっては、特に &lt;code&gt;float32&lt;/code&gt; の場合、結果が不正確になる可能性があります（以下の例を参照）。 &lt;code&gt;dtype&lt;/code&gt; キーワードを使用してより精度の高いアキュムレータを指定すると、この問題を軽減できます。</target>
        </trans-unit>
        <trans-unit id="1c1b3dcae0a3cdb049378b61a52e8a6e218b843e" translate="yes" xml:space="preserve">
          <source>Note that for multioutput (including multilabel) weights should be defined for each class of every column in its own dict. For example, for four-class multilabel classification weights should be [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of [{1:1}, {2:5}, {3:1}, {4:1}].</source>
          <target state="translated">マルチ出力(マルチラベルを含む)では、各列の各クラスごとに重みを定義しなければならないことに注意してください。例えば、4クラスのマルチラベル分類の場合、重みは[{1:1},{2:5},{3:1},{4:1}]ではなく、[{0:1,1:1},{0:1,1:5},{0:1,1},{0:1,1:1}]とする必要があります。</target>
        </trans-unit>
        <trans-unit id="7f057f4a3cfb222efbfc3fdf93e59924824aafce" translate="yes" xml:space="preserve">
          <source>Note that if features have very different scaling or statistical properties, &lt;a href=&quot;generated/sklearn.cluster.featureagglomeration#sklearn.cluster.FeatureAgglomeration&quot;&gt;&lt;code&gt;cluster.FeatureAgglomeration&lt;/code&gt;&lt;/a&gt; may not be able to capture the links between related features. Using a &lt;a href=&quot;generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt;&lt;code&gt;preprocessing.StandardScaler&lt;/code&gt;&lt;/a&gt; can be useful in these settings.</source>
          <target state="translated">フィーチャのスケーリングまたは統計プロパティが大きく異なる場合、&lt;a href=&quot;generated/sklearn.cluster.featureagglomeration#sklearn.cluster.FeatureAgglomeration&quot;&gt; &lt;code&gt;cluster.FeatureAgglomeration&lt;/code&gt; &lt;/a&gt;は関連するフィーチャ間のリンクをキャプチャできない場合があることに注意してください。これらの設定では、&lt;a href=&quot;generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt; &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; &lt;/a&gt;を使用すると便利です。</target>
        </trans-unit>
        <trans-unit id="daa34c655040f11fbac2193226735416d5ff6724" translate="yes" xml:space="preserve">
          <source>Note that if the values of your similarity matrix are not well distributed, e.g. with negative values or with a distance matrix rather than a similarity, the spectral problem will be singular and the problem not solvable. In which case it is advised to apply a transformation to the entries of the matrix. For instance, in the case of a signed distance matrix, is common to apply a heat kernel:</source>
          <target state="translated">類似度行列の値がよく分布していない場合、例えば負の値を持つ場合や、類似度ではなく距離行列を持つ場合、スペクトルの問題は特異であり、解けないことに注意してください。この場合,行列のエントリに変換を適用することをお勧めします.例えば,符号付き距離行列の場合,ヒートカーネルを適用するのが一般的です.</target>
        </trans-unit>
        <trans-unit id="82c5d12dd2770bc5d00d9e0fd296f522b36a2aec" translate="yes" xml:space="preserve">
          <source>Note that in binary classification, recall of the positive class is also known as &amp;ldquo;sensitivity&amp;rdquo;; recall of the negative class is &amp;ldquo;specificity&amp;rdquo;.</source>
          <target state="translated">バイナリ分類では、陽性クラスの再現は「感度」とも呼ばれます。否定的なクラスの想起は「特異性」です。</target>
        </trans-unit>
        <trans-unit id="56700fbea0a4382f56515fac76889ee512c8d3cb" translate="yes" xml:space="preserve">
          <source>Note that in certain cases, the Lars solver may be significantly faster to implement this functionality. In particular, linear interpolation can be used to retrieve model coefficients between the values output by lars_path</source>
          <target state="translated">特定のケースでは、この機能を実装するにはLarsソルバーの方が大幅に高速である可能性があることに注意してください。特に、線形補間を使用して、lars_path</target>
        </trans-unit>
        <trans-unit id="c065b9ad388e273aa3b214ab1297a55e0496eb57" translate="yes" xml:space="preserve">
          <source>Note that in general, robust fitting in high-dimensional setting (large &lt;code&gt;n_features&lt;/code&gt;) is very hard. The robust models here will probably not work in these settings.</source>
          <target state="translated">一般に、高次元の設定（大きな &lt;code&gt;n_features&lt;/code&gt; ）でのロバストフィッティングは非常に難しいことに注意してください。ここでのロバストモデルは、おそらくこれらの設定では機能しません。</target>
        </trans-unit>
        <trans-unit id="64011c56ebca18074907020d8d3e99112269576a" translate="yes" xml:space="preserve">
          <source>Note that in practice, one would not search over this many different parameters simultaneously using grid search, but pick only the ones deemed most important.</source>
          <target state="translated">実際には、グリッド検索を使ってこのように多くの異なるパラメータを同時に検索するのではなく、最も重要と思われるものだけを選択することに注意してください。</target>
        </trans-unit>
        <trans-unit id="b7d16723edd6b0c8a445c16934e7dfaedb2752ae" translate="yes" xml:space="preserve">
          <source>Note that in the case of &amp;lsquo;cityblock&amp;rsquo;, &amp;lsquo;cosine&amp;rsquo; and &amp;lsquo;euclidean&amp;rsquo; (which are valid scipy.spatial.distance metrics), the scikit-learn implementation will be used, which is faster and has support for sparse matrices (except for &amp;lsquo;cityblock&amp;rsquo;). For a verbose description of the metrics from scikit-learn, see the __doc__ of the sklearn.pairwise.distance_metrics function.</source>
          <target state="translated">'cityblock'、 'cosine'、および 'euclidean'（有効なscipy.spatial.distanceメトリック）の場合、scikit-learn実装が使用されることに注意してください。これはより高速で、スパース行列をサポートしています（ただし、 「cityblock」）。scikit-learnからのメトリックの詳細な説明については、sklearn.pairwise.distance_metrics関数の__doc__を参照してください。</target>
        </trans-unit>
        <trans-unit id="81154799705dfac8836df66f3a0269041db1173b" translate="yes" xml:space="preserve">
          <source>Note that in the multilabel case, each sample can have any number of labels. This returns the marginal probability that the given sample has the label in question. For example, it is entirely consistent that two labels both have a 90% probability of applying to a given sample.</source>
          <target state="translated">マルチラベルの場合,各標本は任意の数のラベルを持つことができることに注意してください.これは,与えられた標本が問題のラベルを持つ限界確率を返します.例えば、2つのラベルが与えられた標本に適用される確率が90%であることは完全に一致しています。</target>
        </trans-unit>
        <trans-unit id="01d7bf1a38a1f2f757397967cae9b7d66ce2602c" translate="yes" xml:space="preserve">
          <source>Note that in the previous corpus, the first and the last documents have exactly the same words hence are encoded in equal vectors. In particular we lose the information that the last document is an interrogative form. To preserve some of the local ordering information we can extract 2-grams of words in addition to the 1-grams (individual words):</source>
          <target state="translated">前のコーパスでは、最初の文書と最後の文書は全く同じ単語を持っているので、等しいベクトルでエンコードされていることに注意してください。特に、最後の文書が質問形式であるという情報が失われています。局所的な順序情報の一部を保存するために、1-gram(個々の単語)に加えて、2-gramの単語を抽出することができます。</target>
        </trans-unit>
        <trans-unit id="8dcb354ad6f05344d318f25389a442779bd42bda" translate="yes" xml:space="preserve">
          <source>Note that it is common that a small subset of those parameters can have a large impact on the predictive or computation performance of the model while others can be left to their default values. It is recommended to read the docstring of the estimator class to get a finer understanding of their expected behavior, possibly by reading the enclosed reference to the literature.</source>
          <target state="translated">これらのパラメータの小さなサブセットがモデルの予測性能や計算性能に大きな影響を与える一方で、他のパラメータはデフォルト値のままにしておくのが一般的であることに注意してください。予測クラスのdocstringを読んで、それらの期待される動作をより詳しく理解することをお勧めします。</target>
        </trans-unit>
        <trans-unit id="38e7c6473cb1417f0189c236d54733065555b837" translate="yes" xml:space="preserve">
          <source>Note that it maximizes both the correlations between the scores and the intra-block variances.</source>
          <target state="translated">スコアとブロック内分散の相関を最大化することに注意してください。</target>
        </trans-unit>
        <trans-unit id="7fe083a60697e58d27f138d9ea26d77a87096c53" translate="yes" xml:space="preserve">
          <source>Note that it maximizes only the correlations between the scores.</source>
          <target state="translated">スコア間の相関関係のみを最大化することに注意してください。</target>
        </trans-unit>
        <trans-unit id="9b4460fdb66af9bc149af45e106adc5f1d493bbf" translate="yes" xml:space="preserve">
          <source>Note that noisy data can &amp;ldquo;short-circuit&amp;rdquo; the manifold, in essence acting as a bridge between parts of the manifold that would otherwise be well-separated. Manifold learning on noisy and/or incomplete data is an active area of research.</source>
          <target state="translated">ノイズの多いデータは、本質的にマニホールドの「短絡」につながる可能性があることに注意してください。本質的には、そうでなければ十分に分離されるマニホールドのパーツ間のブリッジとして機能します。ノイズの多いデータや不完全なデータの多様体学習は、活発な研究分野です。</target>
        </trans-unit>
        <trans-unit id="67d5dd89ca82637aa1c574ab8cabbf8ba39e4cb8" translate="yes" xml:space="preserve">
          <source>Note that pickle has some security and maintainability issues. Please refer to section &lt;a href=&quot;../../modules/model_persistence#model-persistence&quot;&gt;Model persistence&lt;/a&gt; for more detailed information about model persistence with scikit-learn.</source>
          <target state="translated">pickleにはセキュリティと保守性の問題があることに注意してください。scikit-learnを使用したモデルの永続化の詳細については、セクション&lt;a href=&quot;../../modules/model_persistence#model-persistence&quot;&gt;モデルの永続化&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="23cd95765d94c327b5282b4a1fe3e5dffe405a3a" translate="yes" xml:space="preserve">
          <source>Note that polynomial features are used implicitly in &lt;a href=&quot;https://en.wikipedia.org/wiki/Kernel_method&quot;&gt;kernel methods&lt;/a&gt; (e.g., &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;sklearn.svm.SVC&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.decomposition.kernelpca#sklearn.decomposition.KernelPCA&quot;&gt;&lt;code&gt;sklearn.decomposition.KernelPCA&lt;/code&gt;&lt;/a&gt;) when using polynomial &lt;a href=&quot;svm#svm-kernels&quot;&gt;Kernel functions&lt;/a&gt;.</source>
          <target state="translated">多項式&lt;a href=&quot;svm#svm-kernels&quot;&gt;カーネル関数&lt;/a&gt;を使用する場合、多項式機能は&lt;a href=&quot;https://en.wikipedia.org/wiki/Kernel_method&quot;&gt;カーネルメソッド&lt;/a&gt;（たとえば、&lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;sklearn.svm.SVC&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.decomposition.kernelpca#sklearn.decomposition.KernelPCA&quot;&gt; &lt;code&gt;sklearn.decomposition.KernelPCA&lt;/code&gt; &lt;/a&gt;）で暗黙的に使用されることに注意してください。</target>
        </trans-unit>
        <trans-unit id="675c6d53180ed2915c2b59bf4a0a0e8fbac69215" translate="yes" xml:space="preserve">
          <source>Note that providing &lt;code&gt;y&lt;/code&gt; is sufficient to generate the splits and hence &lt;code&gt;np.zeros(n_samples)&lt;/code&gt; may be used as a placeholder for &lt;code&gt;X&lt;/code&gt; instead of actual training data.</source>
          <target state="translated">分割を生成するには &lt;code&gt;y&lt;/code&gt; を指定するだけで十分なので、実際のトレーニングデータの代わりに &lt;code&gt;np.zeros(n_samples)&lt;/code&gt; を &lt;code&gt;X&lt;/code&gt; のプレースホルダーとして使用できます。</target>
        </trans-unit>
        <trans-unit id="df4d1f63cde2c26d664594a284ce306040d06cfb" translate="yes" xml:space="preserve">
          <source>Note that shrinkage works only with &amp;lsquo;lsqr&amp;rsquo; and &amp;lsquo;eigen&amp;rsquo; solvers.</source>
          <target state="translated">収縮は「lsqr」および「eigen」ソルバーでのみ機能することに注意してください。</target>
        </trans-unit>
        <trans-unit id="dd7adf0d494ffc5bcd4e70266fd05b000aa00dcc" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt;&lt;code&gt;precision_recall_curve&lt;/code&gt;&lt;/a&gt; function is restricted to the binary case. The &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; function works only in binary classification and multilabel indicator format.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt; &lt;code&gt;precision_recall_curve&lt;/code&gt; &lt;/a&gt;関数はバイナリの場合に制限されていることに注意してください。&lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt;関数は、バイナリ分類とマルチラベル表示形式で動作します。</target>
        </trans-unit>
        <trans-unit id="651372cf76a2e0eca2cd0e2ced075f5cfd44a313" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.preprocessing.binarizer#sklearn.preprocessing.Binarizer&quot;&gt;&lt;code&gt;Binarizer&lt;/code&gt;&lt;/a&gt; is similar to the &lt;a href=&quot;generated/sklearn.preprocessing.kbinsdiscretizer#sklearn.preprocessing.KBinsDiscretizer&quot;&gt;&lt;code&gt;KBinsDiscretizer&lt;/code&gt;&lt;/a&gt; when &lt;code&gt;k = 2&lt;/code&gt;, and when the bin edge is at the value &lt;code&gt;threshold&lt;/code&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.preprocessing.binarizer#sklearn.preprocessing.Binarizer&quot;&gt; &lt;code&gt;Binarizer&lt;/code&gt; &lt;/a&gt;は、 &lt;code&gt;k = 2&lt;/code&gt; とき、およびビンの端が &lt;code&gt;threshold&lt;/code&gt; とき、&lt;a href=&quot;generated/sklearn.preprocessing.kbinsdiscretizer#sklearn.preprocessing.KBinsDiscretizer&quot;&gt; &lt;code&gt;KBinsDiscretizer&lt;/code&gt; &lt;/a&gt;に似ていることに注意してください。</target>
        </trans-unit>
        <trans-unit id="b78ef718e6ed1cb354d8ff189ba4de9e4443cf71" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; also implements an alternative multi-class strategy, the so-called multi-class SVM formulated by Crammer and Singer, by using the option &lt;code&gt;multi_class='crammer_singer'&lt;/code&gt;. This method is consistent, which is not true for one-vs-rest classification. In practice, one-vs-rest classification is usually preferred, since the results are mostly similar, but the runtime is significantly less.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt;は、オプション &lt;code&gt;multi_class='crammer_singer'&lt;/code&gt; を使用して、代替のマルチクラス戦略、CrammerとSingerによって定式化されたいわゆるマルチクラスSVMも実装することに注意してください。この方法は一貫しており、1対休憩の分類には当てはまりません。実際には、結果はほとんど同じなので、通常は1対休憩の分類が推奨されますが、実行時間は大幅に短くなります。</target>
        </trans-unit>
        <trans-unit id="4b2885ce1a0d54c6be5b37dba1e7a9bea3c67ec1" translate="yes" xml:space="preserve">
          <source>Note that the Multiplicative Update (&amp;lsquo;mu&amp;rsquo;) solver cannot update zeros present in the initialization, so it leads to poorer results when used jointly with the basic NNDSVD algorithm which introduces a lot of zeros; in this case, NNDSVDa or NNDSVDar should be preferred.</source>
          <target state="translated">乗算更新（ 'mu'）ソルバーは初期化に存在するゼロを更新できないため、多くのゼロを導入する基本的なNNDSVDアルゴリズムと組み合わせて使用​​すると結果が悪くなることに注意してください。この場合、NNDSVDaまたはNNDSVDarが優先されます。</target>
        </trans-unit>
        <trans-unit id="542b5d2a5a3926264004f7807400969fe48d422d" translate="yes" xml:space="preserve">
          <source>Note that the current implementation only supports regression estimators.</source>
          <target state="translated">現在の実装では、回帰推定子のみをサポートしていることに注意してください。</target>
        </trans-unit>
        <trans-unit id="5878ce2fa9f81f5b0b2794d8ccb7e40e7db1917d" translate="yes" xml:space="preserve">
          <source>Note that the dict values can either be scorer functions or one of the predefined metric strings.</source>
          <target state="translated">dict値はスコアラー関数または定義済みメトリック文字列のいずれかであることに注意してください。</target>
        </trans-unit>
        <trans-unit id="a97f1f4d24f812e6f4b824a150b492f876f8dbe2" translate="yes" xml:space="preserve">
          <source>Note that the dimensionality does not affect the CPU training time of algorithms which operate on CSR matrices (&lt;code&gt;LinearSVC(dual=True)&lt;/code&gt;, &lt;code&gt;Perceptron&lt;/code&gt;, &lt;code&gt;SGDClassifier&lt;/code&gt;, &lt;code&gt;PassiveAggressive&lt;/code&gt;) but it does for algorithms that work with CSC matrices (&lt;code&gt;LinearSVC(dual=False)&lt;/code&gt;, &lt;code&gt;Lasso()&lt;/code&gt;, etc).</source>
          <target state="translated">注次元は（CSR行列を操作するアルゴリズムのCPUのトレーニング時間に影響を与えないこと &lt;code&gt;LinearSVC(dual=True)&lt;/code&gt; 、 &lt;code&gt;Perceptron&lt;/code&gt; 、 &lt;code&gt;SGDClassifier&lt;/code&gt; 、 &lt;code&gt;PassiveAggressive&lt;/code&gt; を）それはアルゴリズムのためにすることCSC行列と仕事（ &lt;code&gt;LinearSVC(dual=False)&lt;/code&gt; 、 &lt;code&gt;Lasso()&lt;/code&gt; など）。</target>
        </trans-unit>
        <trans-unit id="435cce9f843df9a5bdcdf7f7022599966bcaee8d" translate="yes" xml:space="preserve">
          <source>Note that the estimate_bandwidth function is much less scalable than the mean shift algorithm and will be the bottleneck if it is used.</source>
          <target state="translated">estimate_bandwidth関数は、平均シフトアルゴリズムよりもはるかにスケーラブルではなく、使用するとボトルネックになることに注意してください。</target>
        </trans-unit>
        <trans-unit id="bce829a8923d634c66b8b2d36d28916cd48e0ab9" translate="yes" xml:space="preserve">
          <source>Note that the fourth and fifth instances returned all zeroes, indicating that they matched none of the three labels &lt;code&gt;fit&lt;/code&gt; upon. With multilabel outputs, it is similarly possible for an instance to be assigned multiple labels:</source>
          <target state="translated">第四及び第五のインスタンスは、彼らは3つのラベルのどれもマッチしていないことを示す、すべてゼロを返したことをノート &lt;code&gt;fit&lt;/code&gt; するとは。マルチラベル出力では、インスタンスに複数のラベルを割り当てることも同様に可能です。</target>
        </trans-unit>
        <trans-unit id="21f39572b525862541f5e3b74bb03e06aac617ef" translate="yes" xml:space="preserve">
          <source>Note that the heat map plot has a special colorbar with a midpoint value close to the score values of the best performing models so as to make it easy to tell them apart in the blink of an eye.</source>
          <target state="translated">ヒートマッププロットには、最高の性能を持つモデルのスコア値に近い中間点の値を持つ特別なカラーバーがあり、一瞬で見分けがつくようになっていることに注意してください。</target>
        </trans-unit>
        <trans-unit id="3f19bf1a17574ce6b7f5a8199cbb6b2ed04a3916" translate="yes" xml:space="preserve">
          <source>Note that the maximum likelihood estimate corresponds to no shrinkage, and thus performs poorly. The Ledoit-Wolf estimate performs really well, as it is close to the optimal and is computational not costly. In this example, the OAS estimate is a bit further away. Interestingly, both approaches outperform cross-validation, which is significantly most computationally costly.</source>
          <target state="translated">最尤推定値は収縮がないことに対応しているため、パフォーマンスが低いことに注意してください。Ledoit-Wolfの推定値は、最適値に近く、計算コストがかからないため、非常によく動作します。この例では、OAS 推定値はもう少し離れています。興味深いことに、どちらのアプローチもクロス・バリデーションを上回りますが、クロス・バリデーションは最も計算コストがかかります。</target>
        </trans-unit>
        <trans-unit id="be3cea96be539a6f36c7349851efbc1b4f539ceb" translate="yes" xml:space="preserve">
          <source>Note that the number of dimensions is independent of the original number of features but instead depends on the size of the dataset: the larger the dataset, the higher is the minimal dimensionality of an eps-embedding.</source>
          <target state="translated">次元数は,元の特徴量の数に依存せず,データセットのサイズに依存することに注意してください:データセットが大きいほど,EPS-embeddingの最小次元数は高くなります.</target>
        </trans-unit>
        <trans-unit id="1426a0972df2ef3ae4847218faa4ab1a45e2a26b" translate="yes" xml:space="preserve">
          <source>Note that the parameter &lt;code&gt;alpha&lt;/code&gt; is applied as a Tikhonov regularization of the assumed covariance between the training points.</source>
          <target state="translated">パラメータ &lt;code&gt;alpha&lt;/code&gt; は、トレーニングポイント間の仮定された共分散のTikhonov正則化として適用されることに注意してください。</target>
        </trans-unit>
        <trans-unit id="57bfd4549eb4e4a76c8eb0b9ddf20a2f4a52c8d2" translate="yes" xml:space="preserve">
          <source>Note that the precision may not decrease with recall. The definition of precision (\(\frac{T_p}{T_p + F_p}\)) shows that lowering the threshold of a classifier may increase the denominator, by increasing the number of results returned. If the threshold was previously set too high, the new results may all be true positives, which will increase precision. If the previous threshold was about right or too low, further lowering the threshold will introduce false positives, decreasing precision.</source>
          <target state="translated">精度はリコールでは低下しないかもしれないことに注意してください.精度の定義 (\(T_p}{T_p+F_p}\)))は,分類器の閾値を下げると,返される結果の数を増やすことで分母を増やすことができることを示しています.以前の閾値が高すぎた場合,新しい結果はすべて真の陽性であるかもしれません.以前の閾値がほぼ正しいか、低すぎた場合、さらに閾値を下げると偽陽性が発生し、精度が低下します。</target>
        </trans-unit>
        <trans-unit id="07e181d114b5848fdd4cb0661edb49154d99e027" translate="yes" xml:space="preserve">
          <source>Note that the purpose of the &lt;a href=&quot;../../modules/manifold#multidimensional-scaling&quot;&gt;MDS&lt;/a&gt; is to find a low-dimensional representation of the data (here 2D) in which the distances respect well the distances in the original high-dimensional space, unlike other manifold-learning algorithms, it does not seeks an isotropic representation of the data in the low-dimensional space. Here the manifold problem matches fairly that of representing a flat map of the Earth, as with &lt;a href=&quot;https://en.wikipedia.org/wiki/Map_projection&quot;&gt;map projection&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;../../modules/manifold#multidimensional-scaling&quot;&gt;MDS&lt;/a&gt;の目的は、他の多様体学習アルゴリズムとは異なり、距離が元の高次元空間の距離をよく尊重するデータ（ここでは2D）の低次元表現を見つけることであることに注意してください。低次元空間でのデータの等方性表現。ここで、多様体問題は、&lt;a href=&quot;https://en.wikipedia.org/wiki/Map_projection&quot;&gt;地図投影&lt;/a&gt;と同様に、地球の平らな地図を表す問題とかなり一致しています</target>
        </trans-unit>
        <trans-unit id="951ad93c2b6a49b38a3c4a8dabf905c9019bf128" translate="yes" xml:space="preserve">
          <source>Note that the purpose of the MDS is to find a low-dimensional representation of the data (here 2D) in which the distances respect well the distances in the original high-dimensional space, unlike other manifold-learning algorithms, it does not seeks an isotropic representation of the data in the low-dimensional space.</source>
          <target state="translated">MDSの目的は、距離が元の高次元空間の距離をよく尊重するデータの低次元表現(ここでは2次元)を見つけることであり、他のマニホールド学習アルゴリズムとは異なり、低次元空間でのデータの等方性表現を求めないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="faff2f13ccab498a5068027cb2f2891a11c4c2ca" translate="yes" xml:space="preserve">
          <source>Note that the scalers accept both Compressed Sparse Rows and Compressed Sparse Columns format (see &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; and &lt;code&gt;scipy.sparse.csc_matrix&lt;/code&gt;). Any other sparse input will be &lt;strong&gt;converted to the Compressed Sparse Rows representation&lt;/strong&gt;. To avoid unnecessary memory copies, it is recommended to choose the CSR or CSC representation upstream.</source>
          <target state="translated">スケーラーは圧縮スパース行と圧縮スパース列の両方の形式を受け入れることに注意してください（ &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; と &lt;code&gt;scipy.sparse.csc_matrix&lt;/code&gt; を参照）。その他のスパース入力は&lt;strong&gt;、圧縮スパース行表現に変換され&lt;/strong&gt;ます。不要なメモリコピーを回避するために、CSRまたはCSC表現を上流で選択することをお勧めします。</target>
        </trans-unit>
        <trans-unit id="0ac4948c4f86990406e6391d28cab3438b2d6038" translate="yes" xml:space="preserve">
          <source>Note that the transformations successfully map the data to a normal distribution when applied to certain datasets, but are ineffective with others. This highlights the importance of visualizing the data before and after transformation.</source>
          <target state="translated">変換は、特定のデータセットに適用した場合、データを正規分布にマッピングすることに成功しますが、他のデータセットでは効果がないことに注意してください。このことは、変換前と変換後のデータを可視化することの重要性を強調しています。</target>
        </trans-unit>
        <trans-unit id="c025c974076c003b893079ae24539cfe87c45c45" translate="yes" xml:space="preserve">
          <source>Note that the use of &lt;code&gt;memory&lt;/code&gt; to enable caching becomes interesting when the fitting of a transformer is costly.</source>
          <target state="translated">トランスフォーマーの取り付けにコストがかかる場合、キャッシングを有効にするための &lt;code&gt;memory&lt;/code&gt; の使用が興味深いことに注意してください。</target>
        </trans-unit>
        <trans-unit id="e3bd8ce7db50d77dd828df23ba8a7913ea07b656" translate="yes" xml:space="preserve">
          <source>Note that there are many different formulations for the Sparse PCA problem. The one implemented here is based on &lt;a href=&quot;#mrl09&quot; id=&quot;id3&quot;&gt;[Mrl09]&lt;/a&gt; . The optimization problem solved is a PCA problem (dictionary learning) with an \(\ell_1\) penalty on the components:</source>
          <target state="translated">スパースPCA問題にはさまざまな定式化があることに注意してください。ここで実装されたものは&lt;a href=&quot;#mrl09&quot; id=&quot;id3&quot;&gt;[Mrl09]に&lt;/a&gt;基づいています。解決された最適化問題は、コンポーネントに\（\ ell_1 \）ペナルティがあるPCA問題（辞書学習）です。</target>
        </trans-unit>
        <trans-unit id="3533aed52b9c93cbfd7c732492e759ef81f9eff6" translate="yes" xml:space="preserve">
          <source>Note that there exist a lot of different clustering criteria and associated algorithms. The simplest clustering algorithm is &lt;a href=&quot;../../modules/clustering#k-means&quot;&gt;K-means&lt;/a&gt;.</source>
          <target state="translated">多くの異なるクラスタリング基準と関連するアルゴリズムが存在することに注意してください。最も単純なクラスタリングアルゴリズムは&lt;a href=&quot;../../modules/clustering#k-means&quot;&gt;K平均法&lt;/a&gt;です。</target>
        </trans-unit>
        <trans-unit id="7a1a308b56337fe667b4a60765401b66807cafaf" translate="yes" xml:space="preserve">
          <source>Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.</source>
          <target state="translated">sample_weight が指定 さ れている と き は、 こ れ ら の重みは sample_weight と 乗算 さ れます (はめ込み方式で渡されます)。</target>
        </trans-unit>
        <trans-unit id="523c4300803e2407441df32761d9ac234d32f175" translate="yes" xml:space="preserve">
          <source>Note that theta are typically the log-transformed values of the kernel&amp;rsquo;s hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale.</source>
          <target state="translated">シータは通常、カーネルのハイパーパラメーターの対数変換された値であることに注意してください。長さスケールのようなハイパーパラメーターは自然に対数スケールで存在するため、検索スペースのこの表現はハイパーパラメーター検索により適しています。</target>
        </trans-unit>
        <trans-unit id="18d756a791b41973e0843ab0a78a9e37c703da28" translate="yes" xml:space="preserve">
          <source>Note that this accuracy of this l1-penalized linear model is significantly below what can be reached by an l2-penalized linear model or a non-linear multi-layer perceptron model on this dataset.</source>
          <target state="translated">このl1ペナライズされた線形モデルの精度は、このデータセットのl2ペナライズされた線形モデルや非線形多層パーセプトロンモデルの精度を大きく下回っていることに注意してください。</target>
        </trans-unit>
        <trans-unit id="d1586f7c06fc3985d60451a7a19048e48e062430" translate="yes" xml:space="preserve">
          <source>Note that this compound kernel returns the results of all simple kernel stacked along an additional axis.</source>
          <target state="translated">この複合カーネルは、追加の軸に沿ってスタックされたすべての単純なカーネルの結果を返すことに注意してください。</target>
        </trans-unit>
        <trans-unit id="70f8f8292a30b78b7e2885afabc408eef407b785" translate="yes" xml:space="preserve">
          <source>Note that this definition is not valid if \(\beta \in (0; 1)\), yet it can be continuously extended to the definitions of \(d_{KL}\) and \(d_{IS}\) respectively.</source>
          <target state="translated">なお、この定義は、この定義が成立しない場合には、「\(0;1)\)」となりますが、「\(d_{KL})」と「\(d_{IS})」のそれぞれの定義に継続的に拡張することができます。</target>
        </trans-unit>
        <trans-unit id="5472d869ea9e0f8e4cfcc121937d62eb4599c58a" translate="yes" xml:space="preserve">
          <source>Note that this example is, however, only an illustration since for this specific case fitting PCA is not necessarily slower than loading the cache. Hence, use the &lt;code&gt;memory&lt;/code&gt; constructor parameter when the fitting of a transformer is costly.</source>
          <target state="translated">ただし、この特定のケースでは、PCAのフィッティングがキャッシュのロードよりも遅いとは限らないため、この例は単なる図であることに注意してください。したがって、トランスフォーマーの取り付けにコストがかかる場合は、 &lt;code&gt;memory&lt;/code&gt; コンストラクターパラメーターを使用します。</target>
        </trans-unit>
        <trans-unit id="1b5bac58d61d7142976dd586739448ed8787f73e" translate="yes" xml:space="preserve">
          <source>Note that this format is not meant to be used to implicitly store missing values in the matrix because it would densify it at transform time. Missing values encoded by 0 must be used with dense input.</source>
          <target state="translated">このフォーマットは,変換時に行列を高密度化してしまうため,行列の欠損値を暗黙的に格納するためには使用されないことに注意してください.0 でエンコードされた欠損値は,密な入力で使用しなければなりません.</target>
        </trans-unit>
        <trans-unit id="ceed59ec0d8d185c9512413b150620f381e9c0c0" translate="yes" xml:space="preserve">
          <source>Note that this function does not regenerate the original data due to discretization rounding.</source>
          <target state="translated">この関数は離散化丸めのため、元のデータを再生しませんのでご注意ください。</target>
        </trans-unit>
        <trans-unit id="90f3882ef5e6cb2ec08d6d3659b834d53aaa84d9" translate="yes" xml:space="preserve">
          <source>Note that this gives us a different indication than the graph, as the graph reflects conditional relations between variables, while the clustering reflects marginal properties: variables clustered together can be considered as having a similar impact at the level of the full stock market.</source>
          <target state="translated">これは、グラフが変数間の条件付き関係を反映しているのに対し、クラスタリングは限界特性を反映しているので、グラフとは異なる表示を与えていることに注意してください:一緒にクラスタリングされた変数は、株式市場全体のレベルで同様の影響を持っていると考えることができます。</target>
        </trans-unit>
        <trans-unit id="29fe04606c06b888c8ec9e6f0120963e08f606ce" translate="yes" xml:space="preserve">
          <source>Note that this is always a dense array.</source>
          <target state="translated">これは常に密な配列であることに注意してください。</target>
        </trans-unit>
        <trans-unit id="426217e7254990be151f425ed53a8b743a92e13d" translate="yes" xml:space="preserve">
          <source>Note that this two-dimensional example is very degenerate: generally the number of features would be much greater than the &amp;ldquo;document length&amp;rdquo;, while here we have much larger documents than vocabulary. Similarly, with &lt;code&gt;n_classes &amp;gt; n_features&lt;/code&gt;, it is much less likely that a feature distinguishes a particular class.</source>
          <target state="translated">この2次元の例は非常に縮退していることに注意してください。一般に、特徴の数は「ドキュメントの長さ」よりはるかに大きくなりますが、ここではボキャブラリーよりもはるかに大きなドキュメントがあります。同様に、 &lt;code&gt;n_classes &amp;gt; n_features&lt;/code&gt; 場合、機能が特定のクラスを区別する可能性ははるかに低くなります。</target>
        </trans-unit>
        <trans-unit id="dcf3e0855a66eb55e0eddd9daaf862dddfda1dac" translate="yes" xml:space="preserve">
          <source>Note that this type is the most specific type that can be inferred. For example:</source>
          <target state="translated">この型は推論できる最も具体的な型であることに注意してください。例えば</target>
        </trans-unit>
        <trans-unit id="1fefb84f794ce8a86674757b08d8dabfe97347de" translate="yes" xml:space="preserve">
          <source>Note that this will affect all uses of &lt;a href=&quot;generated/sklearn.utils.assert_all_finite#sklearn.utils.assert_all_finite&quot;&gt;&lt;code&gt;sklearn.utils.assert_all_finite&lt;/code&gt;&lt;/a&gt; within the context.</source>
          <target state="translated">これは、コンテキスト内での&lt;a href=&quot;generated/sklearn.utils.assert_all_finite#sklearn.utils.assert_all_finite&quot;&gt; &lt;code&gt;sklearn.utils.assert_all_finite&lt;/code&gt; の&lt;/a&gt;すべての使用に影響することに注意してください。</target>
        </trans-unit>
        <trans-unit id="ab32001c49d58b4f0c9d94bbfb77f7ddeaf05601" translate="yes" xml:space="preserve">
          <source>Note that those results can be highly dependent on the value of &lt;code&gt;learning_rate_init&lt;/code&gt;.</source>
          <target state="translated">これらの結果は &lt;code&gt;learning_rate_init&lt;/code&gt; の値に大きく依存する可能性があることに注意してください。</target>
        </trans-unit>
        <trans-unit id="aa786acd948a782d7b514486d406120e9b9bf46a" translate="yes" xml:space="preserve">
          <source>Note that unlike standard cross-validation methods, successive training sets are supersets of those that come before them.</source>
          <target state="translated">標準的なクロスバリデーション法とは異なり、連続したトレーニングセットは、その前に来るもののスーパーセットであることに注意してください。</target>
        </trans-unit>
        <trans-unit id="b632488ec02d373b59188cfae81036b1d7135a34" translate="yes" xml:space="preserve">
          <source>Note that when using dictionary learning to extract a representation (e.g. for sparse coding) clustering can be a good proxy to learn the dictionary. For instance the &lt;a href=&quot;generated/sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt;&lt;code&gt;MiniBatchKMeans&lt;/code&gt;&lt;/a&gt; estimator is computationally efficient and implements on-line learning with a &lt;code&gt;partial_fit&lt;/code&gt; method.</source>
          <target state="translated">辞書学習を使用して表現を抽出する場合（スパースコーディングなど）、クラスタリングは辞書を学習するための適切なプロキシになることに注意してください。たとえば、&lt;a href=&quot;generated/sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt; &lt;code&gt;MiniBatchKMeans&lt;/code&gt; &lt;/a&gt;推定器は計算効率が高く、 &lt;code&gt;partial_fit&lt;/code&gt; メソッドを使用したオンライン学習を実装しています。</target>
        </trans-unit>
        <trans-unit id="b38cc6be43472cae197ca98a60df5eafaa29d73f" translate="yes" xml:space="preserve">
          <source>Note that with all these strategies, the &lt;code&gt;predict&lt;/code&gt; method completely ignores the input data!</source>
          <target state="translated">これらすべての戦略で、 &lt;code&gt;predict&lt;/code&gt; メソッドは入力データを完全に無視することに注意してください！</target>
        </trans-unit>
        <trans-unit id="75c6be4694b9eabe59018390268fd820a052b7d5" translate="yes" xml:space="preserve">
          <source>Note that, by default, scikit-learn uses its embedded (vendored) version of joblib. A configuration switch (documented below) controls this behavior.</source>
          <target state="translated">デフォルトでは、scikit-learnはjoblibの組み込み版(ベンダー版)を使用することに注意してください。設定スイッチ(以下で説明します)はこの動作を制御します。</target>
        </trans-unit>
        <trans-unit id="ae98ee9bcd2e5d0854b3eaebde47d02a011f815f" translate="yes" xml:space="preserve">
          <source>Note that, in this notation, it&amp;rsquo;s assumed that the observation \(y_i\) takes values in the set \({-1, 1}\) at trial \(i\).</source>
          <target state="translated">この表記では、観測\（y_i \）が試行\（i \）でセット\（{-1、1} ​​\）の値を取ると仮定されていることに注意してください。</target>
        </trans-unit>
        <trans-unit id="79d7c15c2a930f99c60199078ea59a499e19fbc8" translate="yes" xml:space="preserve">
          <source>Note that, the color range of the precision matrices is tweaked to improve readability of the figure. The full range of values of the empirical precision is not displayed.</source>
          <target state="translated">なお、図の読みやすさを向上させるために、精度行列の色の範囲を調整しています。経験的精度の全範囲の値は表示されません。</target>
        </trans-unit>
        <trans-unit id="5bd74df6988f671f3aaedf9864231e7cb14cad2a" translate="yes" xml:space="preserve">
          <source>Note the use of a generator comprehension, which introduces laziness into the feature extraction: tokens are only processed on demand from the hasher.</source>
          <target state="translated">特徴抽出に怠惰さを導入するジェネレータ内包の使用に注意してください。</target>
        </trans-unit>
        <trans-unit id="1984eb2d93c7fabc5820f74c1a6deb67cdefe2d3" translate="yes" xml:space="preserve">
          <source>Note! the synthetic feature weight is subject to l1/l2 regularization as all other features. To lessen the effect of regularization on synthetic feature weight (and therefore on the intercept) intercept_scaling has to be increased.</source>
          <target state="translated">注意!合成特徴量は、他のすべての特徴量と同様にl1/l2正則化の影響を受けます。合成特徴量(したがって切片)に対する正則化の影響を軽減するために、 intercept_scaling を大きくしなければなりません。</target>
        </trans-unit>
        <trans-unit id="83423c198b6099edba08f185f940042d5dba3b79" translate="yes" xml:space="preserve">
          <source>Note:</source>
          <target state="translated">Note:</target>
        </trans-unit>
        <trans-unit id="b85cf8e5cd9762e5dd866d246742bbab950fd9b8" translate="yes" xml:space="preserve">
          <source>Note: &lt;code&gt;LeaveOneOut()&lt;/code&gt; is equivalent to &lt;code&gt;KFold(n_splits=n)&lt;/code&gt; and &lt;code&gt;LeavePOut(p=1)&lt;/code&gt; where &lt;code&gt;n&lt;/code&gt; is the number of samples.</source>
          <target state="translated">注： &lt;code&gt;LeaveOneOut()&lt;/code&gt; は、と等価である &lt;code&gt;KFold(n_splits=n)&lt;/code&gt; と &lt;code&gt;LeavePOut(p=1)&lt;/code&gt; ここで、 &lt;code&gt;n&lt;/code&gt; はサンプル数です。</target>
        </trans-unit>
        <trans-unit id="31e8baf167adcc23a2adc9382a5f1918c617d9e9" translate="yes" xml:space="preserve">
          <source>Note: &lt;code&gt;LeavePOut(p)&lt;/code&gt; is NOT equivalent to &lt;code&gt;KFold(n_splits=n_samples // p)&lt;/code&gt; which creates non-overlapping test sets.</source>
          <target state="translated">注： &lt;code&gt;LeavePOut(p)&lt;/code&gt; は、重複しないテストセットを作成する &lt;code&gt;KFold(n_splits=n_samples // p)&lt;/code&gt; と同等ではありません。</target>
        </trans-unit>
        <trans-unit id="432e1c4e6e288e7db18e2c42d6e410c6adeb71c8" translate="yes" xml:space="preserve">
          <source>Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times &lt;code&gt;n_samples&lt;/code&gt; (i.e. the sum of squares of each column totals 1).</source>
          <target state="translated">注：これらの10個の特徴変数のそれぞれは、平均が中央に配置され、標準偏差 &lt;code&gt;n_samples&lt;/code&gt; （つまり、各列の平方和の合計が1）でスケーリングされています。</target>
        </trans-unit>
        <trans-unit id="02b388a51976f4b3884d316ec9ed343cbbaf27f0" translate="yes" xml:space="preserve">
          <source>Note: Evaluation of eval_gradient is not analytic but numeric and all</source>
          <target state="translated">注意:eval_gradient の評価は解析的なものではなく数値的なものであり、すべての</target>
        </trans-unit>
        <trans-unit id="a5290473efc5984775f303f01f61e6c7775623f5" translate="yes" xml:space="preserve">
          <source>Note: If a lambda is used as the function, then the resulting transformer will not be pickleable.</source>
          <target state="translated">注意:ラムダが関数として使用されている場合、結果として得られる変換器はピクル可能ではありません。</target>
        </trans-unit>
        <trans-unit id="09a1c78e2b9dafeb4ae2773774e2099dbe747a0e" translate="yes" xml:space="preserve">
          <source>Note: Our implementation&amp;rsquo;s score is 1 greater than the one given in Tsoumakas et al., 2010. This extends it to handle the degenerate case in which an instance has 0 true labels.</source>
          <target state="translated">注：実装のスコアはTsoumakas et al。、2010で与えられたスコアよりも1大きくなっています。これにより、インスタンスの真のラベルが0である縮退ケースを処理するように拡張されます。</target>
        </trans-unit>
        <trans-unit id="956d1e2ca58f2ab0bdb4afea5546244c422bc323" translate="yes" xml:space="preserve">
          <source>Note: See the &lt;a href=&quot;../basic/tutorial#introduction&quot;&gt;Introduction to machine learning with scikit-learn Tutorial&lt;/a&gt; for a quick run-through on the basic machine learning vocabulary used within scikit-learn.</source>
          <target state="translated">注：scikit-learnで使用される基本的な機械学習ボキャブラリーの&lt;a href=&quot;../basic/tutorial#introduction&quot;&gt;概要&lt;/a&gt;については、scikit-learnチュートリアルを使用した機械学習の概要を参照してください。</target>
        </trans-unit>
        <trans-unit id="7a9381252d0555984c45c1d913a85b0a19a4797d" translate="yes" xml:space="preserve">
          <source>Note: The default solver &amp;lsquo;adam&amp;rsquo; works pretty well on relatively large datasets (with thousands of training samples or more) in terms of both training time and validation score. For small datasets, however, &amp;lsquo;lbfgs&amp;rsquo; can converge faster and perform better.</source>
          <target state="translated">注：デフォルトのソルバー「adam」は、トレーニング時間と検証スコアの両方の点で、比較的大規模なデータセット（数千以上のトレーニングサンプル以上）でかなりうまく機能します。ただし、小さなデータセットの場合、「lbfgs」は収束が速くなり、パフォーマンスが向上します。</target>
        </trans-unit>
        <trans-unit id="271df9bc769d4f6f6224f70e1c75a6c3d0d4e15f" translate="yes" xml:space="preserve">
          <source>Note: The parameters &lt;code&gt;test_size&lt;/code&gt; and &lt;code&gt;train_size&lt;/code&gt; refer to groups, and not to samples, as in ShuffleSplit.</source>
          <target state="translated">注：パラメーター &lt;code&gt;test_size&lt;/code&gt; および &lt;code&gt;train_size&lt;/code&gt; はグループを参照し、ShuffleSplitのようにサンプルを参照しません。</target>
        </trans-unit>
        <trans-unit id="d9b8539222215de6f9b7a2dc0d47dad55ab9503a" translate="yes" xml:space="preserve">
          <source>Note: a one-hot encoding of y labels should use a LabelBinarizer instead.</source>
          <target state="translated">注意:y ラベルのワンホットエンコーディングでは、代わりに LabelBinarizer を使うべきです。</target>
        </trans-unit>
        <trans-unit id="af48a21921f21ca5ba4feec03dc7cfdb83d643b6" translate="yes" xml:space="preserve">
          <source>Note: as k-means is optimizing a non-convex objective function, it will likely end up in a local optimum. Several runs with independent random init might be necessary to get a good convergence.</source>
          <target state="translated">注意:k-meansは非凸の対物関数を最適化しているので、局所的な最適化になる可能性が高いです。良い収束を得るためには、独立したランダムなinitで数回実行する必要があるかもしれません。</target>
        </trans-unit>
        <trans-unit id="3bb7791854593a3b717f90311f25871cac16570c" translate="yes" xml:space="preserve">
          <source>Note: contrary to other cross-validation strategies, random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets.</source>
          <target state="translated">注意:他のクロスバリデーション戦略とは反対に、ランダム分割はすべてのフォールドが異なることを保証しないが、これはサイズの大きいデータセットではまだ可能性が高い。</target>
        </trans-unit>
        <trans-unit id="ec23f8c549cab8298e97ba96412d8acd5b97a819" translate="yes" xml:space="preserve">
          <source>Note: fitting on sparse input will override the setting of this parameter, using brute force.</source>
          <target state="translated">注意:疎な入力に対するフィッティングは、このパラメータの設定を上書きし、ブルートフォースを使用します。</target>
        </trans-unit>
        <trans-unit id="f2a5a8b06402f76d2a1b1f28ad2e90efb04ea841" translate="yes" xml:space="preserve">
          <source>Note: if you manage your own numerical data it is recommended to use an optimized file format such as HDF5 to reduce data load times. Various libraries such as H5Py, PyTables and pandas provides a Python interface for reading and writing data in that format.</source>
          <target state="translated">注:数値データを自分で管理する場合は、データのロード時間を短縮するためにHDF5などの最適化されたファイル形式を使用することをお勧めします。H5PyやPyTables、pandasなどの各種ライブラリは、そのフォーマットでデータを読み書きするためのPythonインターフェースを提供しています。</target>
        </trans-unit>
        <trans-unit id="cb39d5746d1ab528272657961084b4241cfe3f85" translate="yes" xml:space="preserve">
          <source>Note: in the plot, &amp;ldquo;unlabeled samples&amp;rdquo; does not mean that we don&amp;rsquo;t know the labels (as in semi-supervised learning) but that the samples simply do &lt;em&gt;not&lt;/em&gt; have a label.</source>
          <target state="translated">注：プロットに、「非標識サンプルは、」我々は（半教師付き学習のように）ラベルを知らないという意味ではありませんが、サンプルは単にないこと&lt;em&gt;ではない&lt;/em&gt;ラベルを持っています。</target>
        </trans-unit>
        <trans-unit id="403fd153dcfc1c72561472b5e34372d5de58734f" translate="yes" xml:space="preserve">
          <source>Note: like the ShuffleSplit strategy, stratified random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets.</source>
          <target state="translated">注意:ShuffleSplitストラテジーのように,層別ランダムスプリットは,すべてのフォールドが異なることを保証するものではないが,サイズの大きいデータセットではまだ可能性が高い.</target>
        </trans-unit>
        <trans-unit id="12964c4f090e67fee00edc80b29c8ee9b28b7b3b" translate="yes" xml:space="preserve">
          <source>Note: the implementation of &lt;code&gt;inverse_transform&lt;/code&gt; in &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;svd_solver='randomized'&lt;/code&gt; is not the exact inverse transform of &lt;code&gt;transform&lt;/code&gt; even when &lt;code&gt;whiten=False&lt;/code&gt; (default).</source>
          <target state="translated">注：の実装 &lt;code&gt;inverse_transform&lt;/code&gt; における&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt;と &lt;code&gt;svd_solver='randomized'&lt;/code&gt; 正確な逆の変換ではありません &lt;code&gt;transform&lt;/code&gt; しても &lt;code&gt;whiten=False&lt;/code&gt; （デフォルト）。</target>
        </trans-unit>
        <trans-unit id="f5990a880094bfe59d250a6cb72959923dee6858" translate="yes" xml:space="preserve">
          <source>Note: the list is re-created at each call to the property in order to reduce the object memory footprint by not storing the sampling data. Thus fetching the property may be slower than expected.</source>
          <target state="translated">注意:サンプリングデータを保存しないことでオブジェクトのメモリフットプリントを削減するために、プロパティを呼び出すたびにリストが再作成されます。そのため、プロパティの取得は予想よりも遅くなる可能性があります。</target>
        </trans-unit>
        <trans-unit id="b4fa4a5f4c66fdf91fefb2f5d8a9d04622e730f8" translate="yes" xml:space="preserve">
          <source>Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than &lt;code&gt;max_features&lt;/code&gt; features.</source>
          <target state="translated">注： &lt;code&gt;max_features&lt;/code&gt; 以外の機能を効果的に検査する必要がある場合でも、ノードサンプルの有効なパーティションが少なくとも1つ見つかるまで、分割の検索は停止しません。</target>
        </trans-unit>
        <trans-unit id="5af1722805bd08a73be9d8b2f383c0eb417bbdd9" translate="yes" xml:space="preserve">
          <source>Note: this implementation is restricted to the binary classification task or multilabel classification task in label indicator format.</source>
          <target state="translated">注意:この実装は、ラベルインジケータ形式のバイナリ分類タスクまたはマルチラベル分類タスクに限定されます。</target>
        </trans-unit>
        <trans-unit id="2dab9af505b98147ed8303644f1fce8db17174c7" translate="yes" xml:space="preserve">
          <source>Note: this implementation is restricted to the binary classification task or multilabel classification task.</source>
          <target state="translated">注意:この実装は、バイナリ分類タスクまたはマルチラベル分類タスクに限定されます。</target>
        </trans-unit>
        <trans-unit id="229c71e40bdbb475df5a5f3c46414bb1e9fb11cf" translate="yes" xml:space="preserve">
          <source>Note: this implementation is restricted to the binary classification task.</source>
          <target state="translated">注意:この実装はバイナリ分類タスクに限定されています。</target>
        </trans-unit>
        <trans-unit id="77503a53930a4c6773bcfd9900ee0500aa085f94" translate="yes" xml:space="preserve">
          <source>Note: with the optional parameter &lt;code&gt;svd_solver='randomized'&lt;/code&gt;, we also need to give &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; the size of the lower-dimensional space &lt;code&gt;n_components&lt;/code&gt; as a mandatory input parameter.</source>
          <target state="translated">注：オプションのパラメーター &lt;code&gt;svd_solver='randomized'&lt;/code&gt; を使用して、&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; に&lt;/a&gt;必須の入力パラメーターとして低次元空間 &lt;code&gt;n_components&lt;/code&gt; のサイズを指定する必要もあります。</target>
        </trans-unit>
        <trans-unit id="70440046a3dc2e079f23ee1c57dfa76669b732aa" translate="yes" xml:space="preserve">
          <source>Notes</source>
          <target state="translated">Notes</target>
        </trans-unit>
        <trans-unit id="8365e7c537a7bde197e775fc685e729bf7dcde79" translate="yes" xml:space="preserve">
          <source>Notice that this class does not support sparse input. See &lt;a href=&quot;sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt;&lt;code&gt;TruncatedSVD&lt;/code&gt;&lt;/a&gt; for an alternative with sparse data.</source>
          <target state="translated">このクラスはスパース入力をサポートしていないことに注意してください。スパースデータの代替案については、&lt;a href=&quot;sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt; &lt;code&gt;TruncatedSVD&lt;/code&gt; &lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="24a6d73ad577eece3a7c4a8079ee0685b19c5eef" translate="yes" xml:space="preserve">
          <source>Novelty detection</source>
          <target state="translated">新規性の検出</target>
        </trans-unit>
        <trans-unit id="0c6ce6f3a8c7f0ac9123407bf644e00c93b8a85c" translate="yes" xml:space="preserve">
          <source>Novelty detection with Local Outlier Factor (LOF)</source>
          <target state="translated">局所外れ値因子(LOF)による新規性検出</target>
        </trans-unit>
        <trans-unit id="d039fa812c1beff75961eedb7fd0d56d4bd6cef8" translate="yes" xml:space="preserve">
          <source>Novelty detection with Local Outlier Factor is illustrated below.</source>
          <target state="translated">Local Outlier Factorを用いた新規性検出の例を以下に示します。</target>
        </trans-unit>
        <trans-unit id="0baacee2d29c362912e19aeae2a56e9b5de18251" translate="yes" xml:space="preserve">
          <source>November, 1995</source>
          <target state="translated">1995年11月</target>
        </trans-unit>
        <trans-unit id="f56b60fb36ba6e7108f33fd204674d75974c9ca0" translate="yes" xml:space="preserve">
          <source>Now looking at the computation time of the different parts, we see that the vectorization is much more expensive than learning itself. From the different algorithms, &lt;code&gt;MultinomialNB&lt;/code&gt; is the most expensive, but its overhead can be mitigated by increasing the size of the mini-batches (exercise: change &lt;code&gt;minibatch_size&lt;/code&gt; to 100 and 10000 in the program and compare).</source>
          <target state="translated">さまざまな部分の計算時間を見ると、ベクトル化はそれ自体を学習するよりもはるかに高価であることがわかります。さまざまなアルゴリズムから、 &lt;code&gt;MultinomialNB&lt;/code&gt; は最も高価ですが、そのオーバーヘッドは &lt;code&gt;minibatch_size&lt;/code&gt; のサイズを増やすことで軽減できます（演習：プログラムでminibatch_sizeを100および10000に変更して比較します）。</target>
        </trans-unit>
        <trans-unit id="703648eec6ac2a9ecd5332ac2370f3cbb5d40c50" translate="yes" xml:space="preserve">
          <source>Now that we have our features, we can train a classifier to try to predict the category of a post. Let&amp;rsquo;s start with a &lt;a href=&quot;../../modules/naive_bayes#naive-bayes&quot;&gt;na&amp;iuml;ve Bayes&lt;/a&gt; classifier, which provides a nice baseline for this task. &lt;code&gt;scikit-learn&lt;/code&gt; includes several variants of this classifier; the one most suitable for word counts is the multinomial variant:</source>
          <target state="translated">これで機能が揃ったので、投稿のカテゴリを予測するように分類子をトレーニングできます。まず、このタスクのベースラインを提供する&lt;a href=&quot;../../modules/naive_bayes#naive-bayes&quot;&gt;単純なベイズ&lt;/a&gt;分類器から始めましょう。 &lt;code&gt;scikit-learn&lt;/code&gt; には、この分類子のいくつかのバリアントが含まれています。単語数に最も適したものは多項式バリアントです。</target>
        </trans-unit>
        <trans-unit id="39c382cf98b09c769e0ece49478f8e5a21269790" translate="yes" xml:space="preserve">
          <source>Now you can &lt;em&gt;predict&lt;/em&gt; new values. In this case, you&amp;rsquo;ll predict using the last image from &lt;code&gt;digits.data&lt;/code&gt;. By predicting, you&amp;rsquo;ll determine the image from the training set that best matches the last image.</source>
          <target state="translated">これで、新しい値を&lt;em&gt;予測&lt;/em&gt;できます。この場合、 &lt;code&gt;digits.data&lt;/code&gt; の最後の画像を使用して予測します。予測することで、最後の画像に最もよく一致するトレーニングセットから画像を決定します。</target>
        </trans-unit>
        <trans-unit id="4bde0a1195bac7469e935b78a194104a68da7a29" translate="yes" xml:space="preserve">
          <source>Now, if we repeat this computation for the remaining 2 terms in the document, we get</source>
          <target state="translated">さて、この計算をドキュメントの残りの2つの用語について繰り返すと、次のようになります。</target>
        </trans-unit>
        <trans-unit id="ece88bcd9ec161c2a2872c2fb61e36a0d64c7a18" translate="yes" xml:space="preserve">
          <source>Now, without any further assumptions the idea of having a latent variable \(h\) would be superfluous &amp;ndash; \(x\) can be completely modelled with a mean and a covariance. We need to impose some more specific structure on one of these two parameters. A simple additional assumption regards the structure of the error covariance \(\Psi\):</source>
          <target state="translated">これで、これ以上の仮定がなければ、潜在変数\（h \）を使用するという考えは不要になります。\（x \）は、平均と共分散で完全にモデル化できます。これら2つのパラメーターの1つに、より具体的な構造を課す必要があります。単純な追加の仮定は、エラー共分散\（\ Psi \）の構造に関係します。</target>
        </trans-unit>
        <trans-unit id="a31389fe4ff0ebc6e5c5d38e5dab56436f6bc483" translate="yes" xml:space="preserve">
          <source>Nu Support Vector Regression.</source>
          <target state="translated">ニューサポートベクトル回帰。</target>
        </trans-unit>
        <trans-unit id="a9b51312b4e809b61f7b24f233552372d8a4d343" translate="yes" xml:space="preserve">
          <source>Nu-Support Vector Classification.</source>
          <target state="translated">ニューサポートベクトル分類。</target>
        </trans-unit>
        <trans-unit id="28831313b9efda1fb2d5e62ae541d82eeaf2e628" translate="yes" xml:space="preserve">
          <source>Number of Attributes:</source>
          <target state="translated">属性の数。</target>
        </trans-unit>
        <trans-unit id="2bbc98640e09a456dee6d19b3fcc0a288b212310" translate="yes" xml:space="preserve">
          <source>Number of CPU cores used during the cross-validation loop. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">相互検証ループ中に使用されたCPUコアの数。 &lt;code&gt;None&lt;/code&gt; は、&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="e056a5a70210c137f261290dad04190fbc9ce82b" translate="yes" xml:space="preserve">
          <source>Number of CPU cores used when parallelizing over classes if multi_class=&amp;rsquo;ovr&amp;rsquo;&amp;rdquo;. This parameter is ignored when the &lt;code&gt;solver&lt;/code&gt; is set to &amp;lsquo;liblinear&amp;rsquo; regardless of whether &amp;lsquo;multi_class&amp;rsquo; is specified or not. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">multi_class = 'ovr'&amp;rdquo;の場合、クラスを並列化するときに使用されるCPUコアの数。'multi_class'が指定されているかどうかに関係なく、 &lt;code&gt;solver&lt;/code&gt; が 'liblinear'に設定されている場合、このパラメーターは無視されます。 &lt;code&gt;None&lt;/code&gt; は、&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="044a045266785f2237c066206c338baa3e1d5bb2" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the cross validation. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">相互検証中に使用するCPUの数。 &lt;code&gt;None&lt;/code&gt; は、&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="aaf36da587212084529abec535211c954c2e7c01" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the cross validation. Note that this is used only if multiple values for l1_ratio are given. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">相互検証中に使用するCPUの数。これは、l1_ratioに複数の値が指定されている場合にのみ使用されることに注意してください。 &lt;code&gt;None&lt;/code&gt; は、&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="52783b9f963f3f1690dd5d40572b3875e2a7ade7" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the resampling. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">リサンプリング中に使用するCPUの数。 &lt;code&gt;None&lt;/code&gt; は、&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="a2666336978a0f4e8c547b7534c07249ba6000fd" translate="yes" xml:space="preserve">
          <source>Number of Instances:</source>
          <target state="translated">インスタンス数。</target>
        </trans-unit>
        <trans-unit id="0bc3461e8033920222bec6b216692137eee9c091" translate="yes" xml:space="preserve">
          <source>Number of Monte Carlo samples per original feature. Equals the dimensionality of the computed feature space.</source>
          <target state="translated">元の特徴量あたりのモンテカルロ法のサンプル数.計算された特徴空間の次元数に等しい.</target>
        </trans-unit>
        <trans-unit id="3262f2b1a48253ff0690a8a75cfdd12aae481720" translate="yes" xml:space="preserve">
          <source>Number of active features across every target for the model refit with the best hyperparameters got by cross-validating across all folds.</source>
          <target state="translated">すべてのフォールドでクロスバリデーションを行って得られた最高のハイパーパラメータを持つモデルのリフィットについて、すべてのターゲットでアクティブな特徴の数。</target>
        </trans-unit>
        <trans-unit id="4cbf5cb47ecd9996ec380ef5f0f19c258c9e11e4" translate="yes" xml:space="preserve">
          <source>Number of active features across every target.</source>
          <target state="translated">すべてのターゲットでアクティブな機能の数。</target>
        </trans-unit>
        <trans-unit id="4d39e5d8b3efa9d6f8372f94e39a5395c837b600" translate="yes" xml:space="preserve">
          <source>Number of active features across every target. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">すべてのターゲットにわたるアクティブな機能の数。 &lt;code&gt;return_n_iter&lt;/code&gt; がTrueに設定されている場合にのみ返されます。</target>
        </trans-unit>
        <trans-unit id="e0c8a9190fa0a6b6567e6260a08bbc16ad38e0e1" translate="yes" xml:space="preserve">
          <source>Number of alphas along the regularization path</source>
          <target state="translated">正則化パスに沿ったアルファの数</target>
        </trans-unit>
        <trans-unit id="21389bf92cd8e8648f186478c091bf8c596c9371" translate="yes" xml:space="preserve">
          <source>Number of alphas along the regularization path, used for each l1_ratio.</source>
          <target state="translated">各 l1_ratio に使用される正則化パスに沿ったアルファの数.</target>
        </trans-unit>
        <trans-unit id="cb76f13b1ca274d0ac0509e0599ee9f88692f95e" translate="yes" xml:space="preserve">
          <source>Number of best singular vectors to which to project the data for clustering.</source>
          <target state="translated">クラスタリングのためにデータを投影するための最高の特異ベクトルの数.</target>
        </trans-unit>
        <trans-unit id="669eddc43c369820a90c37333994758dabadb237" translate="yes" xml:space="preserve">
          <source>Number of binary hidden units.</source>
          <target state="translated">2値の隠れた単位の数。</target>
        </trans-unit>
        <trans-unit id="df5056a6b08a72e6eb298ef5a65870b5ddc8c698" translate="yes" xml:space="preserve">
          <source>Number of bins per feature. An ignored feature at index &lt;code&gt;i&lt;/code&gt; will have &lt;code&gt;n_bins_[i] == 0&lt;/code&gt;.</source>
          <target state="translated">機能ごとのビンの数。インデックス &lt;code&gt;i&lt;/code&gt; で無視された機能は &lt;code&gt;n_bins_[i] == 0&lt;/code&gt; ます。</target>
        </trans-unit>
        <trans-unit id="9e19457800c5864e1fbdcc0291b0ef620abfd78c" translate="yes" xml:space="preserve">
          <source>Number of bins. A bigger number requires more data.</source>
          <target state="translated">ビンの数。数が多いと、より多くのデータが必要になります。</target>
        </trans-unit>
        <trans-unit id="f70f556044c9d189136c9439d7b869763e660892" translate="yes" xml:space="preserve">
          <source>Number of clusters after the final clustering step, which treats the subclusters from the leaves as new samples.</source>
          <target state="translated">葉からのサブクラスタを新しいサンプルとして扱う最終クラスタリングステップの後のクラスタ数.</target>
        </trans-unit>
        <trans-unit id="d93f166299b2fe351648697f50539b771bbcab5f" translate="yes" xml:space="preserve">
          <source>Number of clusters to extract.</source>
          <target state="translated">抽出するクラスターの数。</target>
        </trans-unit>
        <trans-unit id="eb68d1899db83f395f515eac11a92a2f39369f2a" translate="yes" xml:space="preserve">
          <source>Number of combinations taken into account from &amp;lsquo;n choose k&amp;rsquo;, where n is the number of samples and k is the number of subsamples.</source>
          <target state="translated">「nはkを選択」から考慮される組み合わせの数。nはサンプルの数、kはサブサンプルの数です。</target>
        </trans-unit>
        <trans-unit id="cd12f5ccc87c2314d1a7462c1838eb4fba879a35" translate="yes" xml:space="preserve">
          <source>Number of components (&amp;lt; n_classes - 1) for dimensionality reduction.</source>
          <target state="translated">次元削減のためのコンポーネント数（&amp;lt;n_classes-1）。</target>
        </trans-unit>
        <trans-unit id="678dcaccd382015a606461223e75a521f8c270e3" translate="yes" xml:space="preserve">
          <source>Number of components to keep</source>
          <target state="translated">保持する部品の数</target>
        </trans-unit>
        <trans-unit id="209051725a6de8e5e1e5fa7a1e74f7eb06a44fec" translate="yes" xml:space="preserve">
          <source>Number of components to keep.</source>
          <target state="translated">残すべき部品の数。</target>
        </trans-unit>
        <trans-unit id="d04623123bcfd2ce2b9c37b5c1e9535768de28a7" translate="yes" xml:space="preserve">
          <source>Number of components to keep. If &lt;code&gt;n_components `` is ``None&lt;/code&gt;, then &lt;code&gt;n_components&lt;/code&gt; is set to &lt;code&gt;min(n_samples, n_features)&lt;/code&gt;.</source>
          <target state="translated">保持するコンポーネントの数。もし &lt;code&gt;n_components `` is ``None&lt;/code&gt; 、その後、 &lt;code&gt;n_components&lt;/code&gt; がに設定されている &lt;code&gt;min(n_samples, n_features)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="864a5ed4a409c99b07b3c02fc85e293c54d58811" translate="yes" xml:space="preserve">
          <source>Number of components to keep. if n_components is not set all components are kept:</source>
          <target state="translated">n_componentsが設定されていない場合、すべてのコンポーネントが保持されます。</target>
        </trans-unit>
        <trans-unit id="b681f0aabf7a4e88ff6e07d02e6d3053416c7e30" translate="yes" xml:space="preserve">
          <source>Number of components to use. If none is passed, all are used.</source>
          <target state="translated">使用するコンポーネントの数。何も渡されない場合は、すべてのコンポーネントが使用されます。</target>
        </trans-unit>
        <trans-unit id="a4c9442f9290e02b19f88b85f02bacea3cfec6f7" translate="yes" xml:space="preserve">
          <source>Number of components, if n_components is not set all features are kept.</source>
          <target state="translated">コンポーネントの数、n_componentsが設定されていない場合はすべての機能が保持されます。</target>
        </trans-unit>
        <trans-unit id="cd25fc9de4a04b081f0b9a2b60926bce89997152" translate="yes" xml:space="preserve">
          <source>Number of components. If None, all non-zero components are kept.</source>
          <target state="translated">コンポーネントの数。Noneの場合、0以外の成分はすべて保持されます。</target>
        </trans-unit>
        <trans-unit id="45f800ea0c8bd716a5f59f6d34dd8fdf95b8f22e" translate="yes" xml:space="preserve">
          <source>Number of components:</source>
          <target state="translated">コンポーネントの数。</target>
        </trans-unit>
        <trans-unit id="08ad46845beb5661bae33c15135ad1635029f790" translate="yes" xml:space="preserve">
          <source>Number of cores to run in parallel while fitting across folds. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">フォールド全体にフィットするときに並列に実行するコアの数。 &lt;code&gt;None&lt;/code&gt; は、&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="0da9d602da12f13ca29bd75af12cc8c869e57a9f" translate="yes" xml:space="preserve">
          <source>Number of dictionary atoms to extract.</source>
          <target state="translated">抽出する辞書の原子数。</target>
        </trans-unit>
        <trans-unit id="5227337d1c8f00f0cc5985a46091828c912745d3" translate="yes" xml:space="preserve">
          <source>Number of digits for formatting output floating point values. When &lt;code&gt;output_dict&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, this will be ignored and the returned values will not be rounded.</source>
          <target state="translated">出力浮動小数点値をフォーマットするための桁数。 &lt;code&gt;output_dict&lt;/code&gt; が &lt;code&gt;True&lt;/code&gt; の場合、これは無視され、戻り値は丸められません。</target>
        </trans-unit>
        <trans-unit id="393e0ab0962f61be4ea05f66f75cf83a58c8acb8" translate="yes" xml:space="preserve">
          <source>Number of digits of precision for floating point in the values of impurity, threshold and value attributes of each node.</source>
          <target state="translated">各ノードの不純物属性、閾値、値属性の値の浮動小数点精度の桁数</target>
        </trans-unit>
        <trans-unit id="857511ca3ff53ac74c7a9a64491518f8a98aa57b" translate="yes" xml:space="preserve">
          <source>Number of dimensions in which to immerse the dissimilarities.</source>
          <target state="translated">異質さに浸る次元の数。</target>
        </trans-unit>
        <trans-unit id="60a7a9ccef477eb7d360b15d4ec93323fc3722cf" translate="yes" xml:space="preserve">
          <source>Number of dimensions in which to immerse the dissimilarities. If an &lt;code&gt;init&lt;/code&gt; array is provided, this option is overridden and the shape of &lt;code&gt;init&lt;/code&gt; is used to determine the dimensionality of the embedding space.</source>
          <target state="translated">非類似度を埋め込む次元の数。場合 &lt;code&gt;init&lt;/code&gt; アレイが提供され、このオプションは無効にされ、形状 &lt;code&gt;init&lt;/code&gt; 埋め込み空間の次元を決定するために使用されます。</target>
        </trans-unit>
        <trans-unit id="f601fdb82b970f8ccae9e3060c9f42a8faed55c3" translate="yes" xml:space="preserve">
          <source>Number of documents to use in each EM iteration. Only used in online learning.</source>
          <target state="translated">EMの各反復で使用する文書の数。オンライン学習でのみ使用。</target>
        </trans-unit>
        <trans-unit id="25fead66533b3559387b2fcbff51a361b6ce623f" translate="yes" xml:space="preserve">
          <source>Number of eigen vectors to use for the spectral embedding</source>
          <target state="translated">スペクトル埋め込みに使用する固有ベクトルの数</target>
        </trans-unit>
        <trans-unit id="70fb7e9ad9dffd747feff757e8b6b2c3b8c3ad21" translate="yes" xml:space="preserve">
          <source>Number of examples per minibatch.</source>
          <target state="translated">ミニバッチあたりの例の数。</target>
        </trans-unit>
        <trans-unit id="f3a87cabcd8ae2a3f47b41980367db8a154ace86" translate="yes" xml:space="preserve">
          <source>Number of features</source>
          <target state="translated">特徴の数</target>
        </trans-unit>
        <trans-unit id="f26773f39b3b679c0daff789f714ad69f2880ea0" translate="yes" xml:space="preserve">
          <source>Number of features to construct. How many data points will be used to construct the mapping.</source>
          <target state="translated">構築する特徴量の数。マッピングを構築するために使用するデータポイントの数。</target>
        </trans-unit>
        <trans-unit id="8bfcb7d61331a9745e723fb4ee723054b5ce91e8" translate="yes" xml:space="preserve">
          <source>Number of folds. Must be at least 2.</source>
          <target state="translated">フォールドの数。2以上である必要があります。</target>
        </trans-unit>
        <trans-unit id="37148505c5ccd477f2cd9888510233bf49ab48d7" translate="yes" xml:space="preserve">
          <source>Number of grid points. The path is linearly reinterpolated on a grid between 0 and 1 before computing the scores.</source>
          <target state="translated">グリッド点の数。スコアを計算する前に、パスは0と1の間のグリッド上で線形に再補間されます。</target>
        </trans-unit>
        <trans-unit id="609fe53affef0db7e95afe01e9b3b2b42cfee225" translate="yes" xml:space="preserve">
          <source>Number of groups (&lt;code&gt;p&lt;/code&gt;) to leave out in the test split.</source>
          <target state="translated">テスト分割で除外するグループの数（ &lt;code&gt;p&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="7836a44e33451a2adc5e90b29cc50de43f4df6df" translate="yes" xml:space="preserve">
          <source>Number of iteration done before the next print.</source>
          <target state="translated">次の印刷までに行われた反復の数。</target>
        </trans-unit>
        <trans-unit id="c7ee7fcff30c38dbe60673fcfaba39d5dcac363e" translate="yes" xml:space="preserve">
          <source>Number of iterations corresponding to the best results. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">最良の結果に対応する反復回数。 &lt;code&gt;return_n_iter&lt;/code&gt; がTrueに設定されている場合にのみ返されます。</target>
        </trans-unit>
        <trans-unit id="b89cf5a40a3578805b3d3e22f18c4e3365baf655" translate="yes" xml:space="preserve">
          <source>Number of iterations for randomized SVD solver. Not used by ARPACK. The default is larger than the default in &lt;code&gt;randomized_svd&lt;/code&gt; to handle sparse matrices that may have large slowly decaying spectrum.</source>
          <target state="translated">ランダム化されたSVDソルバーの反復回数。ARPACKでは使用されません。デフォルトは、 &lt;code&gt;randomized_svd&lt;/code&gt; のデフォルトよりも大きく、ゆっくりと減衰する大きなスペクトルを持つスパース行列を処理します。</target>
        </trans-unit>
        <trans-unit id="b158b03d08af1b718d3d75c350a03244a2d1a76a" translate="yes" xml:space="preserve">
          <source>Number of iterations for the power method computed by svd_solver == &amp;lsquo;randomized&amp;rsquo;.</source>
          <target state="translated">svd_solver == 'randomized'によって計算されたpowerメソッドの反復回数。</target>
        </trans-unit>
        <trans-unit id="ea8482c683ec2d466d38eba89e78f2c408d93dba" translate="yes" xml:space="preserve">
          <source>Number of iterations for the power method. 3 by default. Only used if &lt;code&gt;svd_method&lt;/code&gt; equals &amp;lsquo;randomized&amp;rsquo;</source>
          <target state="translated">べき乗法の反復回数。デフォルトでは3。 &lt;code&gt;svd_method&lt;/code&gt; が 'randomized'に等しい場合にのみ使用されます</target>
        </trans-unit>
        <trans-unit id="e2a3f7897a04130ec9ab6e8a06f184c73a2db962" translate="yes" xml:space="preserve">
          <source>Number of iterations needed for the spatial median.</source>
          <target state="translated">空間中央値に必要な反復回数。</target>
        </trans-unit>
        <trans-unit id="0a6f367644c8353f5e90ff32f9e722b8b3c35762" translate="yes" xml:space="preserve">
          <source>Number of iterations of the EM step.</source>
          <target state="translated">EMステップの反復回数。</target>
        </trans-unit>
        <trans-unit id="ca85b057132e8737cc9bd5d9895d1c2f0a3952a0" translate="yes" xml:space="preserve">
          <source>Number of iterations of the NIPALS inner loop for each component.</source>
          <target state="translated">各コンポーネントのNIPALS内ループの反復回数。</target>
        </trans-unit>
        <trans-unit id="38592412005a60e12235ac166647e6d24941d551" translate="yes" xml:space="preserve">
          <source>Number of iterations of the NIPALS inner loop for each component. Not useful if the algorithm provided is &amp;ldquo;svd&amp;rdquo;.</source>
          <target state="translated">各コンポーネントのNIPALS内部ループの反復回数。提供されたアルゴリズムが「svd」の場合は役に立ちません。</target>
        </trans-unit>
        <trans-unit id="b3f0661f5b6a537d1cfcf27ec4e37f08f53a4a65" translate="yes" xml:space="preserve">
          <source>Number of iterations run for the optimal alpha.</source>
          <target state="translated">最適なアルファのために実行された反復回数.</target>
        </trans-unit>
        <trans-unit id="c9d82135ee15642aa7ae8817dc570334ab80622b" translate="yes" xml:space="preserve">
          <source>Number of iterations run.</source>
          <target state="translated">実行された反復回数。</target>
        </trans-unit>
        <trans-unit id="cc453132656fb5fe083f1f7f5f3c0a7066108d51" translate="yes" xml:space="preserve">
          <source>Number of iterations run. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">実行された反復回数。 &lt;code&gt;return_n_iter&lt;/code&gt; が &lt;code&gt;True&lt;/code&gt; に設定されている場合にのみ返されます。</target>
        </trans-unit>
        <trans-unit id="346838eb1c236609499116f6804a1aeab6029a68" translate="yes" xml:space="preserve">
          <source>Number of iterations run. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">実行された反復回数。 &lt;code&gt;return_n_iter&lt;/code&gt; がTrueに設定されている場合にのみ返されます。</target>
        </trans-unit>
        <trans-unit id="bae285cae0e2d21ef6dbbaa8dd54db30234b47e0" translate="yes" xml:space="preserve">
          <source>Number of iterations run. Returned only if return_n_iter is set to True.</source>
          <target state="translated">実行された反復回数。return_n_iterがTrueに設定されている場合にのみ返されます。</target>
        </trans-unit>
        <trans-unit id="6e040a3af3a9255e0d8c4455bc3543184ccbc3ff" translate="yes" xml:space="preserve">
          <source>Number of iterations skipped due to an invalid model defined by &lt;code&gt;is_model_valid&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;is_model_valid&lt;/code&gt; で定義された無効なモデルのためにスキップされた反復の数。</target>
        </trans-unit>
        <trans-unit id="51f697c488b6017321338ddb492864c9436800d7" translate="yes" xml:space="preserve">
          <source>Number of iterations skipped due to finding zero inliers.</source>
          <target state="translated">インライアがゼロであることが判明したためにスキップされた反復回数。</target>
        </trans-unit>
        <trans-unit id="6eebd535eebcad36fc18ca23295141a0bc8384b3" translate="yes" xml:space="preserve">
          <source>Number of iterations skipped due to invalid data defined by &lt;code&gt;is_data_valid&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;is_data_valid&lt;/code&gt; で定義された無効なデータのためにスキップされた反復の数。</target>
        </trans-unit>
        <trans-unit id="2b48b7f3d47c667152c7041a648c896ae52b12ff" translate="yes" xml:space="preserve">
          <source>Number of iterations taken to converge.</source>
          <target state="translated">収束するまでの反復回数。</target>
        </trans-unit>
        <trans-unit id="e35e76f80d1bcb32a849fe5cd7421a6593683d9d" translate="yes" xml:space="preserve">
          <source>Number of iterations that fmin_l_bfgs_b has run for.</source>
          <target state="translated">fmin_l_bfgs_bが実行した反復回数。</target>
        </trans-unit>
        <trans-unit id="e6fe9562687f3b9f37db26e9dd5d7295821884aa" translate="yes" xml:space="preserve">
          <source>Number of iterations to perform.</source>
          <target state="translated">実行する反復回数。</target>
        </trans-unit>
        <trans-unit id="744edb5cd8af9d3cbdec3cef824f76ed36468258" translate="yes" xml:space="preserve">
          <source>Number of iterations with no change in the number of estimated clusters that stops the convergence.</source>
          <target state="translated">収束が止まる推定クラスター数が変化しない反復回数</target>
        </trans-unit>
        <trans-unit id="1bb6572e9c67b7f2e1d3c0099c8130bc63fa4d36" translate="yes" xml:space="preserve">
          <source>Number of iterations with no improvement to wait before early stopping.</source>
          <target state="translated">早期停止前の待ち時間が改善されていない反復回数</target>
        </trans-unit>
        <trans-unit id="427bd42a1575036c8163feb881b5305713a1194a" translate="yes" xml:space="preserve">
          <source>Number of iterations. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">反復回数。 &lt;code&gt;return_n_iter&lt;/code&gt; がTrueに設定されている場合にのみ返されます。</target>
        </trans-unit>
        <trans-unit id="20dbe7868d12b42e72b8007b758b8aa006423eb6" translate="yes" xml:space="preserve">
          <source>Number of iterations/sweeps over the training dataset to perform during training.</source>
          <target state="translated">訓練中に実行する訓練データセットに対する反復/スイープの数.</target>
        </trans-unit>
        <trans-unit id="805e89de9bc259ba0d4faba86a9892d5aeb2c894" translate="yes" xml:space="preserve">
          <source>Number of jobs to run in parallel. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">並行して実行するジョブの数。 &lt;code&gt;None&lt;/code&gt; は、&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="68e07911a64110ae2d25f4573c1be042d5d1283e" translate="yes" xml:space="preserve">
          <source>Number of label for each output.</source>
          <target state="translated">各出力のラベルの数。</target>
        </trans-unit>
        <trans-unit id="bd419af7c37c78ed35cd8f556746c5d780f24447" translate="yes" xml:space="preserve">
          <source>Number of layers.</source>
          <target state="translated">レイヤーの数。</target>
        </trans-unit>
        <trans-unit id="4192e6479d3e36a298ef5ede4c2274eeba61eb5b" translate="yes" xml:space="preserve">
          <source>Number of leaves in the hierarchical tree.</source>
          <target state="translated">階層木の葉の数。</target>
        </trans-unit>
        <trans-unit id="eff81c828ce86aeb5087b71b68182742b417d4b0" translate="yes" xml:space="preserve">
          <source>Number of nearest neighbors for nearest_neighbors graph building.</source>
          <target state="translated">nearest_neighborsグラフの建物の最寄りの隣人の数。</target>
        </trans-unit>
        <trans-unit id="37fe95cfc748f25efeacf97021fc7a2313be0b5a" translate="yes" xml:space="preserve">
          <source>Number of neighbors for each sample.</source>
          <target state="translated">各サンプルの隣人の数。</target>
        </trans-unit>
        <trans-unit id="51b538d5b2a3f95b9485557e25d620a9a782f3b4" translate="yes" xml:space="preserve">
          <source>Number of neighbors for each sample. (default is value passed to the constructor).</source>
          <target state="translated">各サンプルの隣人の数。(デフォルトはコンストラクタに渡される値)。</target>
        </trans-unit>
        <trans-unit id="d3cee20cf7566ae95a6af940493b4c430f93d3a6" translate="yes" xml:space="preserve">
          <source>Number of neighbors required. If not provided, this will return the number specified at the initialization.</source>
          <target state="translated">必要な隣人の数。指定しない場合は、初期化時に指定した数を返します。</target>
        </trans-unit>
        <trans-unit id="1e55799760cfa2d3bdbd572fe607c1fc4b77b9d7" translate="yes" xml:space="preserve">
          <source>Number of neighbors to be returned from query function when it is not provided to the &lt;a href=&quot;#sklearn.neighbors.LSHForest.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="translated">&lt;a href=&quot;#sklearn.neighbors.LSHForest.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt;メソッドに提供されていない場合にクエリ関数から返されるネイバーの数。</target>
        </trans-unit>
        <trans-unit id="3262363328a422de3ed07567136a319deb9ad271" translate="yes" xml:space="preserve">
          <source>Number of neighbors to get (default is the value passed to the constructor).</source>
          <target state="translated">取得する隣人の数 (デフォルトはコンストラクタに渡される値)。</target>
        </trans-unit>
        <trans-unit id="02076e172db6b5e77d67d9ae83e2b88dc66a094e" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.KNeighborsClassifier.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">&lt;a href=&quot;#sklearn.neighbors.KNeighborsClassifier.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt;クエリにデフォルトで使用するネイバーの数。</target>
        </trans-unit>
        <trans-unit id="e28eb76463a74cc573864c82f5c8b8d60708a92f" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.KNeighborsRegressor.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">&lt;a href=&quot;#sklearn.neighbors.KNeighborsRegressor.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt;クエリにデフォルトで使用するネイバーの数。</target>
        </trans-unit>
        <trans-unit id="4a844d73b7e4afd6cea1487cf59defb5c0385114" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.LocalOutlierFactor.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries. If n_neighbors is larger than the number of samples provided, all samples will be used.</source>
          <target state="translated">&lt;a href=&quot;#sklearn.neighbors.LocalOutlierFactor.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt;クエリにデフォルトで使用するネイバーの数。n_neighborsが提供されたサンプルの数より大きい場合、すべてのサンプルが使用されます。</target>
        </trans-unit>
        <trans-unit id="7e98c15b26d0846d8c1e878d641afc0e3d115b38" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.NearestNeighbors.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">&lt;a href=&quot;#sklearn.neighbors.NearestNeighbors.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt;クエリにデフォルトで使用するネイバーの数。</target>
        </trans-unit>
        <trans-unit id="70cd89c4110a42556e2c733194f1c90f3d647ddb" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use for MI estimation for continuous variables, see &lt;a href=&quot;#r37d39d7589e2-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; and &lt;a href=&quot;#r37d39d7589e2-3&quot; id=&quot;id6&quot;&gt;[3]&lt;/a&gt;. Higher values reduce variance of the estimation, but could introduce a bias.</source>
          <target state="translated">連続変数のMI推定に使用する近傍の数。&lt;a href=&quot;#r37d39d7589e2-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt;および&lt;a href=&quot;#r37d39d7589e2-3&quot; id=&quot;id6&quot;&gt;[3]を&lt;/a&gt;参照してください。値を大きくすると、推定の分散が減少しますが、バイアスが生じる可能性があります。</target>
        </trans-unit>
        <trans-unit id="237e706a6f5317f1b4ad85e94d1e882cb7b24021" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use for MI estimation for continuous variables, see &lt;a href=&quot;#r50b872b699c4-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; and &lt;a href=&quot;#r50b872b699c4-3&quot; id=&quot;id6&quot;&gt;[3]&lt;/a&gt;. Higher values reduce variance of the estimation, but could introduce a bias.</source>
          <target state="translated">連続変数のMI推定に使用する近傍の数。&lt;a href=&quot;#r50b872b699c4-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt;および&lt;a href=&quot;#r50b872b699c4-3&quot; id=&quot;id6&quot;&gt;[3]を&lt;/a&gt;参照してください。値を大きくすると、推定の分散が減少しますが、バイアスが生じる可能性があります。</target>
        </trans-unit>
        <trans-unit id="9f8819cc7687f8afeb7c24c0200033a234d0c39c" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use when constructing the affinity matrix using the nearest neighbors method. Ignored for &lt;code&gt;affinity='rbf'&lt;/code&gt;.</source>
          <target state="translated">最近傍法を使用してアフィニティマトリックスを作成するときに使用する近傍の数。 &lt;code&gt;affinity='rbf'&lt;/code&gt; の場合は無視されます。</target>
        </trans-unit>
        <trans-unit id="c37287ec818bb6dad17b995ed5729153d9a8118d" translate="yes" xml:space="preserve">
          <source>Number of nonzero coefficients to target in each column of the solution. This is only used by &lt;code&gt;algorithm=&amp;rsquo;lars&amp;rsquo;&lt;/code&gt; and &lt;code&gt;algorithm=&amp;rsquo;omp&amp;rsquo;&lt;/code&gt; and is overridden by &lt;code&gt;alpha&lt;/code&gt; in the &lt;code&gt;omp&lt;/code&gt; case.</source>
          <target state="translated">解の各列で対象とする非ゼロ係数の数。これは、 &lt;code&gt;algorithm=&amp;rsquo;lars&amp;rsquo;&lt;/code&gt; および &lt;code&gt;algorithm=&amp;rsquo;omp&amp;rsquo;&lt;/code&gt; でのみ使用され、 &lt;code&gt;omp&lt;/code&gt; の場合は &lt;code&gt;alpha&lt;/code&gt; によってオーバーライドされます。</target>
        </trans-unit>
        <trans-unit id="27f9bf5a85bc89aa70ea3dbacba13e73a444a9f8" translate="yes" xml:space="preserve">
          <source>Number of outputs.</source>
          <target state="translated">出力数。</target>
        </trans-unit>
        <trans-unit id="a01758eccae198371ad1fbda71e0227c6924ab24" translate="yes" xml:space="preserve">
          <source>Number of parallel jobs to run. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">実行する並列ジョブの数。 &lt;code&gt;None&lt;/code&gt; は、&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="89260d16706c6571daecae9b230dfb394e4f8e34" translate="yes" xml:space="preserve">
          <source>Number of parameter settings that are produced.</source>
          <target state="translated">生成されるパラメータ設定の数。</target>
        </trans-unit>
        <trans-unit id="26680dedc0c193794be077118d1d33ec7cee22de" translate="yes" xml:space="preserve">
          <source>Number of parameter settings that are sampled. n_iter trades off runtime vs quality of the solution.</source>
          <target state="translated">サンプリングされるパラメータ設定の数。 n_iterは実行時間とソリューションの品質をトレードオフにします。</target>
        </trans-unit>
        <trans-unit id="9b3af5a87173ff58737497b2a7b2dff4ac22b716" translate="yes" xml:space="preserve">
          <source>Number of passes over the dataset.</source>
          <target state="translated">データセットを通過する回数.</target>
        </trans-unit>
        <trans-unit id="e919298382f2b30ec9254222b02df5121a7447b9" translate="yes" xml:space="preserve">
          <source>Number of points at which to switch to brute-force. Changing leaf_size will not affect the results of a query, but can significantly impact the speed of a query and the memory required to store the constructed tree. The amount of memory needed to store the tree scales as approximately n_samples / leaf_size. For a specified &lt;code&gt;leaf_size&lt;/code&gt;, a leaf node is guaranteed to satisfy &lt;code&gt;leaf_size &amp;lt;= n_points &amp;lt;= 2 * leaf_size&lt;/code&gt;, except in the case that &lt;code&gt;n_samples &amp;lt; leaf_size&lt;/code&gt;.</source>
          <target state="translated">ブルートフォースに切り替えるポイントの数。leaf_sizeを変更してもクエリの結果には影響しませんが、クエリの速度と、構築されたツリーを格納するために必要なメモリに大きな影響を与える可能性があります。ツリーを格納するために必要なメモリ量は、およそn_samples / leaf_sizeとしてスケーリングされます。指定された &lt;code&gt;leaf_size&lt;/code&gt; の場合、リーフノードは、 &lt;code&gt;n_samples &amp;lt; leaf_size&lt;/code&gt; 場合を除いて、 &lt;code&gt;leaf_size &amp;lt;= n_points &amp;lt;= 2 * leaf_size&lt;/code&gt; を満たすことが保証されます。</target>
        </trans-unit>
        <trans-unit id="74f0e4f1324b195e40b6b67840245cc6639acde5" translate="yes" xml:space="preserve">
          <source>Number of power iterations used to stabilize the result</source>
          <target state="translated">結果の安定化に使用したパワー反復回数</target>
        </trans-unit>
        <trans-unit id="3af0fded49ca0f3c99c5f4242edefb1980f1ee1e" translate="yes" xml:space="preserve">
          <source>Number of power iterations. It can be used to deal with very noisy problems. When &amp;lsquo;auto&amp;rsquo;, it is set to 4, unless &lt;code&gt;n_components&lt;/code&gt; is small (&amp;lt; .1 * min(X.shape)) &lt;code&gt;n_iter&lt;/code&gt; in which case is set to 7. This improves precision with few components.</source>
          <target state="translated">パワー反復の数。非常に騒々しい問題を処理するために使用できます。'auto'の場合、 &lt;code&gt;n_components&lt;/code&gt; が小さい場合（&amp;lt;.1 * min（X.shape））の &lt;code&gt;n_iter&lt;/code&gt; が7に設定されている場合を除いて、4に設定されます。</target>
        </trans-unit>
        <trans-unit id="7c2b5ab18e2bf242894b9a2ecca14a388d432f49" translate="yes" xml:space="preserve">
          <source>Number of predispatched jobs for parallel execution (default is all). The option can reduce the allocated memory. The string can be an expression like &amp;lsquo;2*n_jobs&amp;rsquo;.</source>
          <target state="translated">並列実行のための事前ディスパッチされたジョブの数（デフォルトはすべて）。このオプションは、割り当てられたメモリを減らすことができます。文字列は、「2 * n_jobs」のような式にすることができます。</target>
        </trans-unit>
        <trans-unit id="344e1da2c8fa0e4b376ce3e457a99189b911e25a" translate="yes" xml:space="preserve">
          <source>Number of previous iterations completed on the dictionary used for initialization.</source>
          <target state="translated">初期化に使用された辞書で完了した前回の反復回数。</target>
        </trans-unit>
        <trans-unit id="20853d9102158a366a61d28a6b2cb29c20c98681" translate="yes" xml:space="preserve">
          <source>Number of quantiles to be computed. It corresponds to the number of landmarks used to discretize the cumulative density function.</source>
          <target state="translated">計算される量点の数。累積密度関数を離散化するために使用されるランドマークの数に対応する.</target>
        </trans-unit>
        <trans-unit id="e4aaf1e86836dfafd99ac1220487fd647e794f84" translate="yes" xml:space="preserve">
          <source>Number of random initializations that are tried with the k-means algorithm.</source>
          <target state="translated">k-meansアルゴリズムで試行されるランダムな初期化の数。</target>
        </trans-unit>
        <trans-unit id="b43bc8af90e8df6a17a3d2db5f152fc9e0f7509e" translate="yes" xml:space="preserve">
          <source>Number of random initializations that are tried. In contrast to KMeans, the algorithm is only run once, using the best of the &lt;code&gt;n_init&lt;/code&gt; initializations as measured by inertia.</source>
          <target state="translated">試行されたランダムな初期化の数。KMeansとは対照的に、アルゴリズムは1回だけ実行され、慣性によって測定された &lt;code&gt;n_init&lt;/code&gt; の初期化のうち最良のものを使用します。</target>
        </trans-unit>
        <trans-unit id="2a775249dab61ada8ba714fbef3fe2a6cd5e7f9a" translate="yes" xml:space="preserve">
          <source>Number of random selection trials until one of the stop criteria is met. It is always &lt;code&gt;&amp;lt;= max_trials&lt;/code&gt;.</source>
          <target state="translated">停止基準の1つが満たされるまでのランダム選択試行の回数。常に &lt;code&gt;&amp;lt;= max_trials&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="ddb00b53d153c760e3c244cb1587828c964053be" translate="yes" xml:space="preserve">
          <source>Number of randomized models.</source>
          <target state="translated">無作為化モデルの数。</target>
        </trans-unit>
        <trans-unit id="6e7920a40024bb45accfba5d3a9412bad8885ccd" translate="yes" xml:space="preserve">
          <source>Number of re-shuffling &amp;amp; splitting iterations.</source>
          <target state="translated">再シャッフルと分割の反復回数。</target>
        </trans-unit>
        <trans-unit id="8c1de77526ac5586c3170ef35d398449f2b6a01e" translate="yes" xml:space="preserve">
          <source>Number of rows and columns (resp.) in the bicluster.</source>
          <target state="translated">バイクラスター内の行と列の数(レスポンダ)。</target>
        </trans-unit>
        <trans-unit id="ad1b9067ab876b7409a0c802cf769015719aca95" translate="yes" xml:space="preserve">
          <source>Number of samples encountered for each (class, feature) during fitting. This value is weighted by the sample weight when provided.</source>
          <target state="translated">フィッティング中に各(クラス,特徴量)で遭遇したサンプルの数.この値は,指定された場合には,サンプルの重みで重み付けされます.</target>
        </trans-unit>
        <trans-unit id="c92a24738a539e752aec89fe917078bdb81b48d8" translate="yes" xml:space="preserve">
          <source>Number of samples encountered for each class during fitting. This value is weighted by the sample weight when provided.</source>
          <target state="translated">フィッティング中に各クラスで遭遇したサンプルの数。この値は,指定された場合には,サンプルの重みで重み付けされます.</target>
        </trans-unit>
        <trans-unit id="7d9434e4be81d003217d0ff99bec2958d6cf8f1c" translate="yes" xml:space="preserve">
          <source>Number of samples encountered for each feature during fitting. This value is weighted by the sample weight when provided.</source>
          <target state="translated">フィッティング中に各特徴に遭遇したサンプルの数。この値は,指定された場合には,サンプルの重みで重み付けされます.</target>
        </trans-unit>
        <trans-unit id="4189046e920c071a46d31153d30f2c5546e5d75d" translate="yes" xml:space="preserve">
          <source>Number of samples in a subcluster.</source>
          <target state="translated">サブクラスター内のサンプル数。</target>
        </trans-unit>
        <trans-unit id="b1b8d68fdf55246f42bd4140ab8cdd3ea5232e3c" translate="yes" xml:space="preserve">
          <source>Number of samples seen so far, excluded X.</source>
          <target state="translated">これまでに見られたサンプル数、除外されたX.</target>
        </trans-unit>
        <trans-unit id="f3eb4ebcff443a5740a69d115e4c7d66ed2b7058" translate="yes" xml:space="preserve">
          <source>Number of samples to calculate the parameters. This is at least the number of features (plus 1 if fit_intercept=True) and the number of samples as a maximum. A lower number leads to a higher breakdown point and a low efficiency while a high number leads to a low breakdown point and a high efficiency. If None, take the minimum number of subsamples leading to maximal robustness. If n_subsamples is set to n_samples, Theil-Sen is identical to least squares.</source>
          <target state="translated">パラメータを計算するためのサンプル数。これは、 少なくとも特徴量の数(fit_intercept=True の場合はプラス 1)と、 最大値としてのサンプル数です。数値が低い と 破断点が高 く 効率が低 く な り 、 数値が高い と 破断点が低 く 効率が高 く な り ます。None の場合、ロバスト性が最大になるサブサンプル数の最小値を取ります。n_subsamples が n_samples に設定されている場合、Theil-Sen は最小二乗と同じです。</target>
        </trans-unit>
        <trans-unit id="fc350dda13f5c287c8548b6575ceb1d2c780f61c" translate="yes" xml:space="preserve">
          <source>Number of samples to generate. Defaults to 1.</source>
          <target state="translated">生成するサンプル数。デフォルトは1です。</target>
        </trans-unit>
        <trans-unit id="e94e897f1bb653d4e0feaefd5987d4a553f8af8b" translate="yes" xml:space="preserve">
          <source>Number of samples to generate. If left to None this is automatically set to the first dimension of the arrays.</source>
          <target state="translated">生成するサンプル数。Noneのままにしておくと,これは自動的に配列の1次元目に設定されます.</target>
        </trans-unit>
        <trans-unit id="1a167b23f9bb21704b10da0ef2fc738d507dce40" translate="yes" xml:space="preserve">
          <source>Number of samples to generate. If left to None this is automatically set to the first dimension of the arrays. If replace is False it should not be larger than the length of arrays.</source>
          <target state="translated">生成するサンプル数。None のままにしておくと,これは自動的に配列の1次元目に設定されます.replace が False の場合は,配列の長さよりも大きくしてはいけません.</target>
        </trans-unit>
        <trans-unit id="37b65d0e64d2d03034e5f2f5fa109bac79447708" translate="yes" xml:space="preserve">
          <source>Number of samples to randomly sample for speeding up the initialization (sometimes at the expense of accuracy): the only algorithm is initialized by running a batch KMeans on a random subset of the data. This needs to be larger than n_clusters.</source>
          <target state="translated">初期化を高速化するために(時には精度を犠牲にして)ランダムにサンプリングするサンプル数:唯一のアルゴリズムは,データのランダムなサブセットでバッチKMeansを実行することによって初期化される.これは,n_clustersよりも大きくする必要がある.</target>
        </trans-unit>
        <trans-unit id="79fd133ee683290a8c4b438718235e4555547cff" translate="yes" xml:space="preserve">
          <source>Number of samples. If an array is given, it will compute a safe number of components array-wise.</source>
          <target state="translated">サンプル数。配列が与えられた場合,配列ごとに安全な数の成分を計算します.</target>
        </trans-unit>
        <trans-unit id="ea4ca73ab41ec6033a853674e7fbc815a311d3cf" translate="yes" xml:space="preserve">
          <source>Number of samples. Pass n_samples when the slices are to be used for sparse matrix indexing; slicing off-the-end raises an exception, while it works for NumPy arrays.</source>
          <target state="translated">サンプル数.n_samples を渡すと,スライスが疎な行列のインデックス作成に利用される場合に使用されます.</target>
        </trans-unit>
        <trans-unit id="a75d9ceb8c321c78e9909168b2356ee01f06d1c4" translate="yes" xml:space="preserve">
          <source>Number of singular values and vectors to extract.</source>
          <target state="translated">抽出する特異値とベクトルの数。</target>
        </trans-unit>
        <trans-unit id="9259a302604f8c3d052d9766a0665f74598f4a66" translate="yes" xml:space="preserve">
          <source>Number of singular vectors to check.</source>
          <target state="translated">チェックする特異ベクトルの数。</target>
        </trans-unit>
        <trans-unit id="4e03fb606fcab969781bb42da4618d24e54a8291" translate="yes" xml:space="preserve">
          <source>Number of slices to generate.</source>
          <target state="translated">生成するスライスの数。</target>
        </trans-unit>
        <trans-unit id="c55cc369cb9552b44b4a575f3aae7b0b751a97c8" translate="yes" xml:space="preserve">
          <source>Number of sparse atoms to extract.</source>
          <target state="translated">抽出する疎な原子の数。</target>
        </trans-unit>
        <trans-unit id="133c33b7f976c18813a243c5632b24f2c8e81111" translate="yes" xml:space="preserve">
          <source>Number of splits. Must be at least 2.</source>
          <target state="translated">分割数。2以上である必要があります。</target>
        </trans-unit>
        <trans-unit id="a6bce09538dcde7e7ff60020a73de4974cae38ac" translate="yes" xml:space="preserve">
          <source>Number of step used by the best fit of EM to reach the convergence.</source>
          <target state="translated">収束に到達するためにEMのベストフィットで使用されるステップ数。</target>
        </trans-unit>
        <trans-unit id="aec50834e9d4a500ee385c37d29d58bdc624bb7e" translate="yes" xml:space="preserve">
          <source>Number of step used by the best fit of inference to reach the convergence.</source>
          <target state="translated">推論のベストフィットが収束に到達するために使用するステップ数。</target>
        </trans-unit>
        <trans-unit id="ef96b42c053cf6cd51d23012a0a52b84b2a07604" translate="yes" xml:space="preserve">
          <source>Number of support vectors for each class.</source>
          <target state="translated">各クラスのサポートベクトルの数.</target>
        </trans-unit>
        <trans-unit id="abc9da602c481111cdc9cad2b9a2ec618fddfb11" translate="yes" xml:space="preserve">
          <source>Number of test samples in this split.</source>
          <target state="translated">このスプリットのテストサンプル数。</target>
        </trans-unit>
        <trans-unit id="35ccbd0ed91056f0b431a8e36f769a8655c75e9b" translate="yes" xml:space="preserve">
          <source>Number of time the k-means algorithm will be run with different centroid seeds. The final results will be the best output of n_init consecutive runs in terms of inertia.</source>
          <target state="translated">異なるセントロイドシードを用いて k-means アルゴリズムを実行する回数。最終的な結果は,慣性の観点から,n_init 連続実行の最良の出力となります.</target>
        </trans-unit>
        <trans-unit id="f584f00fb96d0392221b2f107adcb2345328d3b9" translate="yes" xml:space="preserve">
          <source>Number of times cross-validator needs to be repeated.</source>
          <target state="translated">クロスバリデータを繰り返す必要がある回数。</target>
        </trans-unit>
        <trans-unit id="5d2e8dfe07ab898c902f4c479175b6b09037f98d" translate="yes" xml:space="preserve">
          <source>Number of times the SMACOF algorithm will be run with different initializations. The final results will be the best output of the runs, determined by the run with the smallest final stress.</source>
          <target state="translated">SMACOFアルゴリズムが異なる初期化で実行される回数。最終的な結果は、最終的な応力が最も小さい実行によって決定され、実行の中で最高の出力となります。</target>
        </trans-unit>
        <trans-unit id="61d47a44584bfde40c1396e5d7fc8603c469e589" translate="yes" xml:space="preserve">
          <source>Number of times the SMACOF algorithm will be run with different initializations. The final results will be the best output of the runs, determined by the run with the smallest final stress. If &lt;code&gt;init&lt;/code&gt; is provided, this option is overridden and a single run is performed.</source>
          <target state="translated">異なる初期化でSMACOFアルゴリズムが実行される回数。最終結果は、最小の最終応力を持つ実行によって決定される実行の最良の出力になります。 &lt;code&gt;init&lt;/code&gt; が指定されている場合、このオプションはオーバーライドされ、単一の実行が実行されます。</target>
        </trans-unit>
        <trans-unit id="279a7d188f8d456ddd160319a5480a2db5aa1c81" translate="yes" xml:space="preserve">
          <source>Number of times to permute &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;y&lt;/code&gt; を置換する回数。</target>
        </trans-unit>
        <trans-unit id="69631a318e07c7e122bb29c914f2e0417bbb3ea3" translate="yes" xml:space="preserve">
          <source>Number of top features to select. The &amp;ldquo;all&amp;rdquo; option bypasses selection, for use in a parameter search.</source>
          <target state="translated">選択する上位機能の数。「すべて」オプションは、パラメーター検索で使用するために、選択をバイパスします。</target>
        </trans-unit>
        <trans-unit id="da4c15da76668749b2d08dac7e93fa89fa01cae3" translate="yes" xml:space="preserve">
          <source>Number of topics.</source>
          <target state="translated">話題の数。</target>
        </trans-unit>
        <trans-unit id="fbddcfb20eac49b636d0567ae2783e45f24d5db9" translate="yes" xml:space="preserve">
          <source>Number of trees in the LSH Forest.</source>
          <target state="translated">LSHの森の木の数。</target>
        </trans-unit>
        <trans-unit id="f59a66952049f5c09c592626a93864184fb52de6" translate="yes" xml:space="preserve">
          <source>Number of trees in the forest.</source>
          <target state="translated">森の木の数。</target>
        </trans-unit>
        <trans-unit id="883143c355bb70d9c124548ac182b0a674cf4c90" translate="yes" xml:space="preserve">
          <source>Number of values per feature.</source>
          <target state="translated">フィーチャーごとの値の数。</target>
        </trans-unit>
        <trans-unit id="3d3c8a841ea2fec708f92a22e6cb69db77e1725b" translate="yes" xml:space="preserve">
          <source>Number of vectors to use in calculating the SVD. Corresponds to &lt;code&gt;ncv&lt;/code&gt; when &lt;code&gt;svd_method=arpack&lt;/code&gt; and &lt;code&gt;n_oversamples&lt;/code&gt; when &lt;code&gt;svd_method&lt;/code&gt; is &amp;lsquo;randomized`.</source>
          <target state="translated">SVDの計算に使用するベクトルの数。対応 &lt;code&gt;ncv&lt;/code&gt; &lt;code&gt;svd_method=arpack&lt;/code&gt; と &lt;code&gt;n_oversamples&lt;/code&gt; &lt;code&gt;svd_method&lt;/code&gt; は「randomized`です。</target>
        </trans-unit>
        <trans-unit id="cfc2be0c624984ee3eedecc63144bb2eb0e00cd3" translate="yes" xml:space="preserve">
          <source>Numbers of training examples that has been used to generate the learning curve. Note that the number of ticks might be less than n_ticks because duplicate entries will be removed.</source>
          <target state="translated">学習曲線を生成するために使用された学習例の数。重複したエントリは削除されるので、tick数はn_ticksよりも少ないかもしれないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="89c43bf4b62114e4d6b82aa7a39bcd64acde71ea" translate="yes" xml:space="preserve">
          <source>Numeric stopping criterion (WRITEME). 1e-3 by default.</source>
          <target state="translated">数値的な停止基準(WRITEME)。デフォルトでは1e-3。</target>
        </trans-unit>
        <trans-unit id="546b4b9a9bb1a271c23a369b5102c7b719bb257b" translate="yes" xml:space="preserve">
          <source>Numerical solver to use.</source>
          <target state="translated">使用する数値ソルバー</target>
        </trans-unit>
        <trans-unit id="1bda3e35c6cc189118f551c9ef807d4c37dc07f6" translate="yes" xml:space="preserve">
          <source>Numerical solver to use: &amp;lsquo;cd&amp;rsquo; is a Coordinate Descent solver. &amp;lsquo;mu&amp;rsquo; is a Multiplicative Update solver.</source>
          <target state="translated">使用する数値ソルバー： 'cd'は座標降下ソルバーです。'mu'は乗法更新ソルバーです。</target>
        </trans-unit>
        <trans-unit id="c42d401e991cba0a784aff1388e26ed9b57a65e8" translate="yes" xml:space="preserve">
          <source>O. Ledoit and M. Wolf, &amp;ldquo;A Well-Conditioned Estimator for Large-Dimensional Covariance Matrices&amp;rdquo;, Journal of Multivariate Analysis, Volume 88, Issue 2, February 2004, pages 365-411.</source>
          <target state="translated">O.レドイトとM.ウルフ、「大規模共分散行列のための適切な推定量」、多変量解析ジャーナル、88巻、2号、2004年2月、ページ365-411。</target>
        </trans-unit>
        <trans-unit id="e39d7c7a6dfc71c75f7fd3b1688e4255ab0569b5" translate="yes" xml:space="preserve">
          <source>O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995.</source>
          <target state="translated">O.L.マンガサリアン、W.N.ストリート、W.H.ウォルバーグ。線形計画法による乳がん診断と予後.オペレーションズリサーチ,43(4),570-577 ページ,1995 年 7-8 月.</target>
        </trans-unit>
        <trans-unit id="dea6ae2f186812bc2bf8114a674ec0e8c8de8039" translate="yes" xml:space="preserve">
          <source>OAS is a particular form of shrinkage described in &amp;ldquo;Shrinkage Algorithms for MMSE Covariance Estimation&amp;rdquo; Chen et al., IEEE Trans. on Sign. Proc., Volume 58, Issue 10, October 2010.</source>
          <target state="translated">OASは、「MMSE共分散推定のための収縮アルゴリズム」Chen et al。、IEEE Trans。サインオン。Proc。、Volume 58、Issue 10、2010年10月。</target>
        </trans-unit>
        <trans-unit id="f3fd8009dd2433d1a63abbabb480a18d05e74108" translate="yes" xml:space="preserve">
          <source>OD280/OD315 of diluted wines</source>
          <target state="translated">希釈ワインのOD280/OD315</target>
        </trans-unit>
        <trans-unit id="2f76e133c144664f6ceed4509b6ad3d9fe14a67d" translate="yes" xml:space="preserve">
          <source>OD280/OD315 of diluted wines:</source>
          <target state="translated">希釈ワインのOD280/OD315。</target>
        </trans-unit>
        <trans-unit id="9ce3bd4224c8c1780db56b4125ecf3f24bf748b7" translate="yes" xml:space="preserve">
          <source>OK</source>
          <target state="translated">OK</target>
        </trans-unit>
        <trans-unit id="8e8565eb895a4e523ac266f2a6f2af45cda869f8" translate="yes" xml:space="preserve">
          <source>OMP is based on a greedy algorithm that includes at each step the atom most highly correlated with the current residual. It is similar to the simpler matching pursuit (MP) method, but better in that at each iteration, the residual is recomputed using an orthogonal projection on the space of the previously chosen dictionary elements.</source>
          <target state="translated">OMPは、各ステップで現在の残差と最も相関の高い原子を含む貪欲なアルゴリズムに基づいています。これは、より単純なマッチング追求(MP)法に似ていますが、各反復で、以前に選択された辞書要素の空間への直交投影を使用して残差が再計算されるという点で優れています。</target>
        </trans-unit>
        <trans-unit id="702567365ae2f6da8d5fc9650aab7f68f2e2b4bd" translate="yes" xml:space="preserve">
          <source>OOB Errors for Random Forests</source>
          <target state="translated">ランダムフォレストのOOB誤差</target>
        </trans-unit>
        <trans-unit id="2b77a29777f0317be507e501f5c60c74e4daaff5" translate="yes" xml:space="preserve">
          <source>OR, if affinity==`precomputed`, a precomputed affinity matrix of shape (n_samples, n_samples)</source>
          <target state="translated">OR,affinity==`precomputed`の場合、事前に計算された形状のアフィニティ行列(n_samples,n_samples)</target>
        </trans-unit>
        <trans-unit id="c8f36dd22506f2db935605e7016ba4725ee8d954" translate="yes" xml:space="preserve">
          <source>OVR + L1 penalty</source>
          <target state="translated">OVR+L1ペナルティ</target>
        </trans-unit>
        <trans-unit id="6fb4b4e4f3901ecb1795e224abe18919de690335" translate="yes" xml:space="preserve">
          <source>OVR + L2 penalty</source>
          <target state="translated">OVR+L2ペナルティ</target>
        </trans-unit>
        <trans-unit id="cb5d65d3f62b5d33c694bb026fc2cc2e2c9008af" translate="yes" xml:space="preserve">
          <source>Object that mocks the urlopen function to fake requests to mldata.</source>
          <target state="translated">urlopen関数をモックしてmldataへのリクエストを偽装するオブジェクト。</target>
        </trans-unit>
        <trans-unit id="04c754a9ec758f22d2ae91b0fe2718c4051ca8ed" translate="yes" xml:space="preserve">
          <source>Object used to transform multiclass labels to binary labels and vice-versa.</source>
          <target state="translated">マルチクラスラベルをバイナリラベルに変換したり、逆にバイナリラベルに変換したりするために使用されるオブジェクトです。</target>
        </trans-unit>
        <trans-unit id="cdd1673e245cacca55f04fb3561b4eb5194072ad" translate="yes" xml:space="preserve">
          <source>Objects that will be checked for consistent length.</source>
          <target state="translated">長さが一貫しているかどうかチェックされるオブジェクト。</target>
        </trans-unit>
        <trans-unit id="ca9385c00c56b402f0d7c8ffd3817a9453089565" translate="yes" xml:space="preserve">
          <source>Obtaining calibrated probability estimates from decision trees and naive Bayesian classifiers, B. Zadrozny &amp;amp; C. Elkan, ICML 2001</source>
          <target state="translated">決定木と素朴なベイズ分類器からの較正済みの確率推定値の取得、B。Zadrozny＆C. Elkan、ICML 2001</target>
        </trans-unit>
        <trans-unit id="e90a2c57a395bd5ca1744a90561d5ec67c512ffb" translate="yes" xml:space="preserve">
          <source>Obviously when the number of features increases so does the memory consumption of each example. Indeed, for a matrix of \(M\) instances with \(N\) features, the space complexity is in \(O(NM)\). From a computing perspective it also means that the number of basic operations (e.g., multiplications for vector-matrix products in linear models) increases too. Here is a graph of the evolution of the prediction latency with the number of features:</source>
          <target state="translated">明らかに、特徴の数が増えれば、各例のメモリ消費量も増える。実際、\(M\(M)instances with \(N\)features の行列の場合、空間の複雑さは、\(O(NM)\)になります。計算の観点からは,基本的な演算(例えば,線形モデルにおけるベクトル行列の積の乗算など)の数が増えることも意味している.以下は、特徴量の増加に伴う予測待ち時間の変化のグラフです。</target>
        </trans-unit>
        <trans-unit id="215c08c61e401481973fc6ab07ef3f7e0eb253cc" translate="yes" xml:space="preserve">
          <source>Obviously, such an exhaustive search can be expensive. If we have multiple CPU cores at our disposal, we can tell the grid searcher to try these eight parameter combinations in parallel with the &lt;code&gt;n_jobs&lt;/code&gt; parameter. If we give this parameter a value of &lt;code&gt;-1&lt;/code&gt;, grid search will detect how many cores are installed and use them all:</source>
          <target state="translated">明らかに、そのような徹底的な検索は高価になる可能性があります。複数のCPUコアを自由に使用できる場合は、グリッドサーチャーにこれらの8つのパラメーターの組み合わせを &lt;code&gt;n_jobs&lt;/code&gt; パラメーターと並行して試すように指示できます。このパラメーターに &lt;code&gt;-1&lt;/code&gt; の値を指定すると、グリッド検索はインストールされているコアの数を検出し、それらすべてを使用します。</target>
        </trans-unit>
        <trans-unit id="b4b9ad57c64718cb6c7c5d4cbab51ee018de2ade" translate="yes" xml:space="preserve">
          <source>Occurrence count is a good start but there is an issue: longer documents will have higher average count values than shorter documents, even though they might talk about the same topics.</source>
          <target state="translated">発生カウントは良いスタートですが、問題があります:同じトピックについて話していても、長い文書は短い文書よりも平均カウント値が高くなります。</target>
        </trans-unit>
        <trans-unit id="64b2af0bc2328de785be4029344182e16e12fcc6" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt;. Assuming behaviour == &amp;lsquo;new&amp;rsquo;, &lt;code&gt;offset_&lt;/code&gt; is defined as follows. When the contamination parameter is set to &amp;ldquo;auto&amp;rdquo;, the offset is equal to -0.5 as the scores of inliers are close to 0 and the scores of outliers are close to -1. When a contamination parameter different than &amp;ldquo;auto&amp;rdquo; is provided, the offset is defined in such a way we obtain the expected number of outliers (samples with decision function &amp;lt; 0) in training. Assuming the behaviour parameter is set to &amp;lsquo;old&amp;rsquo;, we always have &lt;code&gt;offset_ = -0.5&lt;/code&gt;, making the decision function independent from the contamination parameter.</source>
          <target state="translated">生のスコアから決定関数を定義するために使用されるオフセット。次の関係があります &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt; 。動作== 'new'の場合、 &lt;code&gt;offset_&lt;/code&gt; は次のように定義されます。汚染パラメータが「自動」に設定されている場合、インライアのスコアは0に近く、外れ値のスコアは-1に近いため、オフセットは-0.5になります。 「auto」以外の汚染パラメータが指定されている場合、トレーニングで予測される外れ値（決定関数&amp;lt;0のサンプル）の予想数を取得するようにオフセットが定義されます。 &lt;code&gt;offset_ = -0.5&lt;/code&gt; パラメータが 'old'に設定されていると仮定すると、常にoffset_ = -0.5があり、決定関数が汚染パラメータから独立しています。</target>
        </trans-unit>
        <trans-unit id="bbd227107da9d921e8bc12d3a3ca7fd4c0bd101f" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt;. The offset depends on the contamination parameter and is defined in such a way we obtain the expected number of outliers (samples with decision function &amp;lt; 0) in training.</source>
          <target state="translated">生のスコアから決定関数を定義するために使用されるオフセット。次の関係があります &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt; 。オフセットは汚染パラメータに依存し、トレーニングで外れ値（決定関数&amp;lt;0のサンプル）の予想数を取得する方法で定義されます。</target>
        </trans-unit>
        <trans-unit id="4f4356395ebd6023fbdce24e12feab7e5ca80606" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: decision_function = score_samples - &lt;code&gt;offset_&lt;/code&gt;. The offset is the opposite of &lt;code&gt;intercept_&lt;/code&gt; and is provided for consistency with other outlier detection algorithms.</source>
          <target state="translated">生のスコアから決定関数を定義するために使用されるオフセット。次の関係があります。decision_function= score_samples- &lt;code&gt;offset_&lt;/code&gt; 。オフセットは &lt;code&gt;intercept_&lt;/code&gt; の反対であり、他の外れ値検出アルゴリズムとの一貫性のために提供されています。</target>
        </trans-unit>
        <trans-unit id="9195b75fbc020bb9db88d8b131967914e6de2adf" translate="yes" xml:space="preserve">
          <source>Offset used to obtain binary labels from the raw scores. Observations having a negative_outlier_factor smaller than &lt;code&gt;offset_&lt;/code&gt; are detected as abnormal. The offset is set to -1.5 (inliers score around -1), except when a contamination parameter different than &amp;ldquo;auto&amp;rdquo; is provided. In that case, the offset is defined in such a way we obtain the expected number of outliers in training.</source>
          <target state="translated">生のスコアからバイナリラベルを取得するために使用されるオフセット。 negative_outlier_factorが &lt;code&gt;offset_&lt;/code&gt; より小さい観測値は異常として検出されます。 「auto」以外の汚染パラメーターが指定されている場合を除き、オフセットは-1.5（インライアスコアは約-1）に設定されます。その場合、オフセットは、トレーニングで予想される外れ値の数を取得するように定義されます。</target>
        </trans-unit>
        <trans-unit id="36fd88d1882973048dccc0ac8ca74e6c4f6b2ec1" translate="yes" xml:space="preserve">
          <source>Often features are not given as continuous values but categorical. For example a person could have features &lt;code&gt;[&quot;male&quot;, &quot;female&quot;]&lt;/code&gt;, &lt;code&gt;[&quot;from Europe&quot;, &quot;from US&quot;, &quot;from Asia&quot;]&lt;/code&gt;, &lt;code&gt;[&quot;uses Firefox&quot;, &quot;uses Chrome&quot;, &quot;uses Safari&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt;. Such features can be efficiently coded as integers, for instance &lt;code&gt;[&quot;male&quot;, &quot;from US&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt; could be expressed as &lt;code&gt;[0, 1, 3]&lt;/code&gt; while &lt;code&gt;[&quot;female&quot;, &quot;from Asia&quot;, &quot;uses Chrome&quot;]&lt;/code&gt; would be &lt;code&gt;[1, 2, 1]&lt;/code&gt;.</source>
          <target state="translated">多くの場合、特徴は連続的な値としてではなく、カテゴリ型として与えられます。たとえば、人は機能 &lt;code&gt;[&quot;male&quot;, &quot;female&quot;]&lt;/code&gt; 、 &lt;code&gt;[&quot;from Europe&quot;, &quot;from US&quot;, &quot;from Asia&quot;]&lt;/code&gt; 、 &lt;code&gt;[&quot;uses Firefox&quot;, &quot;uses Chrome&quot;, &quot;uses Safari&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt; 。このような機能は整数として効率的にコーディングできます。たとえば、 &lt;code&gt;[&quot;male&quot;, &quot;from US&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt; は &lt;code&gt;[0, 1, 3]&lt;/code&gt; ]と表現できますが、 &lt;code&gt;[&quot;female&quot;, &quot;from Asia&quot;, &quot;uses Chrome&quot;]&lt;/code&gt; は &lt;code&gt;[1, 2, 1]&lt;/code&gt; 1、2、1]になります。</target>
        </trans-unit>
        <trans-unit id="3d1f21e77b74fb7449c1f9b0570088bab1bd6c20" translate="yes" xml:space="preserve">
          <source>Often features do not contribute equally to predict the target response; in many situations the majority of the features are in fact irrelevant. When interpreting a model, the first question usually is: what are those important features and how do they contributing in predicting the target response?</source>
          <target state="translated">多くの場合、特徴はターゲットの反応を予測するのに等しく貢献しないことがあります;多くの状況では、多くの特徴の大部分は実際には無関係です。モデルを解釈するとき、通常、最初の質問は次のようなものです:それらの重要な特徴は何であり、それらは目標応答を予測する際にどのように貢献しているのか?</target>
        </trans-unit>
        <trans-unit id="cd4e41585434180ead957592fb3bbf7ed399aaf1" translate="yes" xml:space="preserve">
          <source>Often it&amp;rsquo;s useful to add complexity to the model by considering nonlinear features of the input data. A simple and common method to use is polynomial features, which can get features&amp;rsquo; high-order and interaction terms. It is implemented in &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt;&lt;code&gt;PolynomialFeatures&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">多くの場合、入力データの非線形特徴を考慮することにより、モデルに複雑さを追加すると便利です。使用するシンプルで一般的な方法は、多項式の特徴です。これは、特徴の高次項と交互作用項を取得できます。&lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt; &lt;code&gt;PolynomialFeatures&lt;/code&gt; に&lt;/a&gt;実装されています。</target>
        </trans-unit>
        <trans-unit id="e408c9080a80cd5dee3de8b66c635dedc13aaef1" translate="yes" xml:space="preserve">
          <source>Often the hardest part of solving a machine learning problem can be finding the right estimator for the job.</source>
          <target state="translated">機械学習の問題を解決するための最も困難な部分は、仕事のための正しい見積もりを見つけることであることがよくあります。</target>
        </trans-unit>
        <trans-unit id="7b3890ce47285c29340d329412b63023825aa83a" translate="yes" xml:space="preserve">
          <source>Often, you will want to convert an existing Python function into a transformer to assist in data cleaning or processing. You can implement a transformer from an arbitrary function with &lt;a href=&quot;generated/sklearn.preprocessing.functiontransformer#sklearn.preprocessing.FunctionTransformer&quot;&gt;&lt;code&gt;FunctionTransformer&lt;/code&gt;&lt;/a&gt;. For example, to build a transformer that applies a log transformation in a pipeline, do:</source>
          <target state="translated">多くの場合、既存のPython関数をトランスフォーマーに変換して、データのクリーンアップまたは処理を支援します。&lt;a href=&quot;generated/sklearn.preprocessing.functiontransformer#sklearn.preprocessing.FunctionTransformer&quot;&gt; &lt;code&gt;FunctionTransformer&lt;/code&gt; を使用&lt;/a&gt;すると、任意の関数からトランスフォーマーを実装できます。たとえば、パイプラインでログ変換を適用するトランスフォーマーを構築するには、次のようにします。</target>
        </trans-unit>
        <trans-unit id="3a99e53e60f11cdf73347e45ac4d6a8ace6059f3" translate="yes" xml:space="preserve">
          <source>Ojala and Garriga. Permutation Tests for Studying Classifier Performance. The Journal of Machine Learning Research (2010) vol. 11</source>
          <target state="translated">OjalaとGarriga.分類器の性能を調べるための順列検定.機械学習研究誌 (2010)vol.11</target>
        </trans-unit>
        <trans-unit id="f9aa2dba7b6fd084ffccc78f5a1359dabe654fd3" translate="yes" xml:space="preserve">
          <source>On &amp;ldquo;small&amp;rdquo; datasets (less than a few hundred points), the quantile transformer is prone to overfitting. The use of the power transform is then recommended.</source>
          <target state="translated">「小さな」データセット（数百ポイント未満）では、変位値変換器は過剰適合しがちです。その後、パワー変換の使用が推奨されます。</target>
        </trans-unit>
        <trans-unit id="d0f97ce49fc19f915019c9855a072a57bec1774a" translate="yes" xml:space="preserve">
          <source>On L2-normalized data, this function is equivalent to linear_kernel.</source>
          <target state="translated">L2正規化されたデータでは、この関数はlinear_kernelと同等です。</target>
        </trans-unit>
        <trans-unit id="d978bf78cd4e4a7f593a82a72e7f97f769b529af" translate="yes" xml:space="preserve">
          <source>On Spectral Clustering: Analysis and an algorithm, 2001 Andrew Y. Ng, Michael I. Jordan, Yair Weiss &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&lt;/a&gt;</source>
          <target state="translated">スペクトルクラスタリングについて：分析とアルゴリズム、2001 Andrew Y. Ng、Michael I. Jordan、Yair Weiss &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c042431c0ae0ab161c8569f0669e312480d87b4b" translate="yes" xml:space="preserve">
          <source>On the combination of forecast probabilities for consecutive precipitation periods. Wea. Forecasting, 5, 640&amp;ndash;650., Wilks, D. S., 1990a</source>
          <target state="translated">連続降水期間の予測確率の組み合わせについて。あぁ。予測、5、640〜650、ウィルクス、DS、1990a</target>
        </trans-unit>
        <trans-unit id="05fe02625303adf1ec7a757f80f079f0cfb615a5" translate="yes" xml:space="preserve">
          <source>On the contrary the classical finite mixture model with a Dirichlet distribution prior will favor more uniformly weighted components and therefore tends to divide natural clusters into unnecessary sub-components.</source>
          <target state="translated">逆に、ディリクレ分布の先行を持つ古典的な有限混合モデルは、より一様に重み付けされた成分を好むため、自然なクラスターを不必要な下位成分に分割する傾向があります。</target>
        </trans-unit>
        <trans-unit id="a881270be1f0c36e65b4d9407272c7539d9eb831" translate="yes" xml:space="preserve">
          <source>On the diabetes dataset, find the optimal regularization parameter alpha.</source>
          <target state="translated">糖尿病データセットについて,最適な正則化パラメータαを求めよ.</target>
        </trans-unit>
        <trans-unit id="d20d94e86b214eba2d2a083bdeb7805cae8a5dbd" translate="yes" xml:space="preserve">
          <source>On the digits dataset, plot the cross-validation score of a &lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; estimator with an linear kernel as a function of parameter &lt;code&gt;C&lt;/code&gt; (use a logarithmic grid of points, from 1 to 10).</source>
          <target state="translated">数値データセットで、パラメーター &lt;code&gt;C&lt;/code&gt; の関数として線形カーネルを使用した&lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt;推定器の交差検定スコアをプロットします（1から10までの点の対数グリッドを使用）。</target>
        </trans-unit>
        <trans-unit id="70934046ec7198c15e5255a457f5b5f8aad47e7d" translate="yes" xml:space="preserve">
          <source>On the flip side, although naive Bayes is known as a decent classifier, it is known to be a bad estimator, so the probability outputs from &lt;code&gt;predict_proba&lt;/code&gt; are not to be taken too seriously.</source>
          <target state="translated">反対に、ナイーブベイズはまともな分類器として知られていますが、悪い推定器であることがわかっているため、 &lt;code&gt;predict_proba&lt;/code&gt; からの確率出力はあまり真剣に受け取られません。</target>
        </trans-unit>
        <trans-unit id="11ff999f3cb9557f779d2d870e0da3265a08df2a" translate="yes" xml:space="preserve">
          <source>On the following figure we are fitting a dataset not well-depicted by a Gaussian mixture. Adjusting the &lt;code&gt;weight_concentration_prior&lt;/code&gt;, parameter of the &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt; controls the number of components used to fit this data. We also present on the last two plots a random sampling generated from the two resulting mixtures.</source>
          <target state="translated">次の図では、ガウス混合では十分に表現されていないデータセットをフィッティングしています。&lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt; &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; の&lt;/a&gt;パラメータである &lt;code&gt;weight_concentration_prior&lt;/code&gt; を調整すると、このデータの近似に使用されるコンポーネントの数が制御されます。最後の2つのプロットには、結果として得られた2つの混合物から生成されたランダムサンプリングも示します。</target>
        </trans-unit>
        <trans-unit id="e0986e74679be65bf8af00d65ae0c2feb9ddbaaf" translate="yes" xml:space="preserve">
          <source>On the graph of webpages and links those values are called the PageRank scores by Google.</source>
          <target state="translated">ウェブページとリンクのグラフ上で、これらの値をGoogleのPageRankスコアと呼びます。</target>
        </trans-unit>
        <trans-unit id="56dda47abffe67d113799c44a62fa9885afd300e" translate="yes" xml:space="preserve">
          <source>On the left side the learning curve of a naive Bayes classifier is shown for the digits dataset. Note that the training score and the cross-validation score are both not very good at the end. However, the shape of the curve can be found in more complex datasets very often: the training score is very high at the beginning and decreases and the cross-validation score is very low at the beginning and increases. On the right side we see the learning curve of an SVM with RBF kernel. We can see clearly that the training score is still around the maximum and the validation score could be increased with more training samples.</source>
          <target state="translated">左側には、数字のデータセットに対するナイーブ・ベイズ分類器の学習曲線が示されています。学習スコアと交差検証スコアの両方が、最後にはあまり良くないことに注意してください。しかし、この曲線の形状は、より複雑なデータセットではよく見られます:学習スコアは最初に非常に高く、その後減少し、交差検証スコアは最初に非常に低く、その後増加します。右側には、RBFカーネルを用いたSVMの学習曲線があります。学習スコアはまだ最大値付近にあり、検証スコアはより多くの学習サンプルで増加させることができることがわかります。</target>
        </trans-unit>
        <trans-unit id="f954522d1ed09b2ae8779aaabe3dfa6c3ae4de4e" translate="yes" xml:space="preserve">
          <source>On the other hand, &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; implements &amp;ldquo;one-vs-the-rest&amp;rdquo; multi-class strategy, thus training n_class models. If there are only two classes, only one model is trained:</source>
          <target state="translated">一方、&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt;は「one-vs-the-rest」マルチクラス戦略を実装し、n_classモデルをトレーニングします。クラスが2つしかない場合、トレーニングされるモデルは1つだけです。</target>
        </trans-unit>
        <trans-unit id="86b28d625cb14fb5485ff23b3eca337a06cecaf2" translate="yes" xml:space="preserve">
          <source>On the plots, train data is shown as dots, while test data is shown as crosses. The iris dataset is four-dimensional. Only the first two dimensions are shown here, and thus some points are separated in other dimensions.</source>
          <target state="translated">プロット上では、訓練データは点で、テストデータは十字で示されている。虹彩のデータセットは4次元である。ここでは最初の2次元のみを示しているため、いくつかの点は他の次元で区切られている。</target>
        </trans-unit>
        <trans-unit id="fc82fddedc10b52f931e2d57575d5196e2c6dd2d" translate="yes" xml:space="preserve">
          <source>On the twenty newsgroups on the other hand the dimensionality can be decreased from 56436 down to 10000 while reasonably preserving pairwise distances.</source>
          <target state="translated">一方、20のニュースグループでは、対の距離を合理的に維持しながら、次元数を56436から10000まで下げることができます。</target>
        </trans-unit>
        <trans-unit id="43f757b33d0dc72835f44fdaffe6492249fea14f" translate="yes" xml:space="preserve">
          <source>On this example, the first two rows represent linearly non-separable datasets (moons and concentric circles) while the third is approximately linearly separable. On the two linearly non-separable datasets, feature discretization largely increases the performance of linear classifiers. On the linearly separable dataset, feature discretization decreases the performance of linear classifiers. Two non-linear classifiers are also shown for comparison.</source>
          <target state="translated">この例では、最初の2行は線形に分離できないデータセット(月と同心円)を表し、3行目はほぼ線形に分離できるデータセットを表しています。線形的に分離できない2つのデータセットでは、特徴量を離散化することで線形分類器の性能が大きく向上します。線形的に分離可能なデータセットでは、特徴量を離散化すると線形分類器の性能は低下する。比較のために、2つの非線形分類器を示します。</target>
        </trans-unit>
        <trans-unit id="07aa293f8032a091371331fd78ad762690098968" translate="yes" xml:space="preserve">
          <source>Once trained, we can export the tree in &lt;a href=&quot;http://www.graphviz.org/&quot;&gt;Graphviz&lt;/a&gt; format using the &lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt;&lt;code&gt;export_graphviz&lt;/code&gt;&lt;/a&gt; exporter. If you use the &lt;a href=&quot;http://conda.io&quot;&gt;conda&lt;/a&gt; package manager, the graphviz binaries and the python package can be installed with</source>
          <target state="translated">トレーニングが完了すると、&lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt; &lt;code&gt;export_graphviz&lt;/code&gt; &lt;/a&gt;エクスポーターを使用して、&lt;a href=&quot;http://www.graphviz.org/&quot;&gt;Graphviz&lt;/a&gt;形式でツリーをエクスポートできます。&lt;a href=&quot;http://conda.io&quot;&gt;conda&lt;/a&gt;パッケージマネージャーを使用する場合、graphvizバイナリとpythonパッケージは次のようにインストールできます。</target>
        </trans-unit>
        <trans-unit id="e1a30cbb2660486e3a34f97fc6f2ebc285138723" translate="yes" xml:space="preserve">
          <source>One can observe here that logistic regression is well calibrated as its curve is nearly diagonal. Linear SVC&amp;rsquo;s calibration curve or reliability diagram has a sigmoid curve, which is typical for an under-confident classifier. In the case of LinearSVC, this is caused by the margin property of the hinge loss, which lets the model focus on hard samples that are close to the decision boundary (the support vectors). Both kinds of calibration can fix this issue and yield nearly identical results. The next figure shows the calibration curve of Gaussian naive Bayes on the same data, with both kinds of calibration and also without calibration.</source>
          <target state="translated">曲線がほぼ対角線であるため、ロジスティック回帰が適切に調整されていることがわかります。線形SVCの検量線または信頼性図には、シグモイド曲線があり、これは信頼性の低い分類器に典型的です。 LinearSVCの場合、これはヒンジ損失のマージンプロパティが原因で発生します。これにより、モデルは決定境界（サポートベクトル）に近いハードサンプルに焦点を合わせることができます。どちらの種類のキャリブレーションでもこの問題を修正でき、ほぼ同じ結果が得られます。次の図は、両方の種類のキャリブレーションがある場合とない場合の、同じデータに対するガウスナイーブベイズのキャリブレーション曲線を示しています。</target>
        </trans-unit>
        <trans-unit id="cce2911ccedb3667eaee804d61905917155ff5c2" translate="yes" xml:space="preserve">
          <source>One can observe that with homoscedastic noise both FA and PCA succeed in recovering the size of the low rank subspace. The likelihood with PCA is higher than FA in this case. However PCA fails and overestimates the rank when heteroscedastic noise is present. Under appropriate circumstances the low rank models are more likely than shrinkage models.</source>
          <target state="translated">同種ノイズでは、FAとPCAの両方が低ランク部分空間のサイズを回復することに成功していることがわかります。この場合、PCAの尤度はFAよりも高い。しかし、異種混合ノイズが存在する場合、PCAは失敗し、ランクを過大評価します。適切な状況下では,低ランクモデルは収縮モデルよりも可能性が高い.</target>
        </trans-unit>
        <trans-unit id="5282642c4183bcd75159c8592f0d08e21bceb6b2" translate="yes" xml:space="preserve">
          <source>One can permute 0 and 1 in the predicted labels, rename 2 to 3 and get the same score:</source>
          <target state="translated">予測されたラベルの0と1をミュートし、2の名前を3に変更して、同じスコアを得ることができます。</target>
        </trans-unit>
        <trans-unit id="f2e197fb258bad312502ac44a4234fe5a6877692" translate="yes" xml:space="preserve">
          <source>One can permute 0 and 1 in the predicted labels, rename 2 to 3, and get the same score:</source>
          <target state="translated">予測されたラベルの0と1をミュートし、2の名前を3に変更し、同じスコアを得ることができます。</target>
        </trans-unit>
        <trans-unit id="e33d3feeafd2b2e6157812f722f3e7fb8358ba7c" translate="yes" xml:space="preserve">
          <source>One can see that Gaussian naive Bayes performs very badly but does so in an other way than linear SVC: While linear SVC exhibited a sigmoid calibration curve, Gaussian naive Bayes&amp;rsquo; calibration curve has a transposed-sigmoid shape. This is typical for an over-confident classifier. In this case, the classifier&amp;rsquo;s overconfidence is caused by the redundant features which violate the naive Bayes assumption of feature-independence.</source>
          <target state="translated">ガウスナイーブベイズのパフォーマンスは非常に悪いが、線形SVCとは異なる方法で実行することがわかります。線形SVCはシグモイド検量線を示しましたが、ガウスナイーブベイズの検量線は転置シグモイド形状をしています。これは、自信過剰の分類器では一般的です。この場合、分類子の自信過剰は、機能に依存しないという単純なベイズの仮定に違反する冗長な機能によって引き起こされます。</target>
        </trans-unit>
        <trans-unit id="82900035fe0f11887cd04ee23edd3ee0d6e6bf18" translate="yes" xml:space="preserve">
          <source>One common pattern within machine learning is to use linear models trained on nonlinear functions of the data. This approach maintains the generally fast performance of linear methods, while allowing them to fit a much wider range of data.</source>
          <target state="translated">機械学習における一般的なパターンの1つは、データの非線形関数で訓練された線形モデルを使用することです。このアプローチは、線形手法の一般的に高速な性能を維持しつつ、より広範囲のデータに適合させることを可能にしています。</target>
        </trans-unit>
        <trans-unit id="fa0690f9f0e7bd840855247cda57999b3e6dd175" translate="yes" xml:space="preserve">
          <source>One common way of performing outlier detection is to assume that the regular data come from a known distribution (e.g. data are Gaussian distributed). From this assumption, we generally try to define the &amp;ldquo;shape&amp;rdquo; of the data, and can define outlying observations as observations which stand far enough from the fit shape.</source>
          <target state="translated">外れ値の検出を実行する一般的な方法の1つは、通常のデータが既知の分布からのものであると想定することです（たとえば、データはガウス分布である）。この仮定から、一般的にデータの「形状」を定義しようとしますが、外れの観測を、適合形状から十分に離れた観測として定義できます。</target>
        </trans-unit>
        <trans-unit id="9d03fc67e51edb11ba912aa95289c786040f1c20" translate="yes" xml:space="preserve">
          <source>One drawback of kernel methods is, that it might be necessary to store many kernel values \(k(x_i, x_j)\) during optimization. If a kernelized classifier is applied to new data \(y_j\), \(k(x_i, y_j)\) needs to be computed to make predictions, possibly for many different \(x_i\) in the training set.</source>
          <target state="translated">カーネル法の欠点としては,最適化の際に多くのカーネル値を記憶しておく必要があることがある.カーネル化された分類器を新しいデータに適用した場合には,予測を行うためには,学習データの中の多くの異なる \(x_i,y_j)を計算しなければならない可能性がある.</target>
        </trans-unit>
        <trans-unit id="cdf9b1d4485b82e7ed1999a3fb7fb5adb4dbca12" translate="yes" xml:space="preserve">
          <source>One efficient way of performing outlier detection in high-dimensional datasets is to use random forests. The &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt; &amp;lsquo;isolates&amp;rsquo; observations by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature.</source>
          <target state="translated">高次元のデータセットで外れ値を検出する効率的な方法の1つは、ランダムフォレストを使用することです。&lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt; &lt;code&gt;ensemble.IsolationForest&lt;/code&gt; &lt;/a&gt;ランダム機能を選択し、ランダムに選択されたフィーチャの最大値と最小値との間の分割値を選択することにより、「単離物」の観測。</target>
        </trans-unit>
        <trans-unit id="b5c13007d70aa1a0e4a2816404f0d61b9e0ac135" translate="yes" xml:space="preserve">
          <source>One important thing to note is that the algorithms implemented in this module can take different kinds of matrix as input. All the methods accept standard data matrices of shape &lt;code&gt;[n_samples, n_features]&lt;/code&gt;. These can be obtained from the classes in the &lt;a href=&quot;classes#module-sklearn.feature_extraction&quot;&gt;&lt;code&gt;sklearn.feature_extraction&lt;/code&gt;&lt;/a&gt; module. For &lt;a href=&quot;generated/sklearn.cluster.affinitypropagation#sklearn.cluster.AffinityPropagation&quot;&gt;&lt;code&gt;AffinityPropagation&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.cluster.spectralclustering#sklearn.cluster.SpectralClustering&quot;&gt;&lt;code&gt;SpectralClustering&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt;&lt;code&gt;DBSCAN&lt;/code&gt;&lt;/a&gt; one can also input similarity matrices of shape &lt;code&gt;[n_samples, n_samples]&lt;/code&gt;. These can be obtained from the functions in the &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt;&lt;/a&gt; module.</source>
          <target state="translated">注意すべき重要な点の1つは、このモジュールに実装されているアルゴリズムは、入力としてさまざまな種類の行列を取ることができるということです。すべてのメソッドは、形状 &lt;code&gt;[n_samples, n_features]&lt;/code&gt; 標準データ行列を受け入れます。これらは、&lt;a href=&quot;classes#module-sklearn.feature_extraction&quot;&gt; &lt;code&gt;sklearn.feature_extraction&lt;/code&gt; &lt;/a&gt;モジュールのクラスから取得できます。用&lt;a href=&quot;generated/sklearn.cluster.affinitypropagation#sklearn.cluster.AffinityPropagation&quot;&gt; &lt;code&gt;AffinityPropagation&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.cluster.spectralclustering#sklearn.cluster.SpectralClustering&quot;&gt; &lt;code&gt;SpectralClustering&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt; &lt;code&gt;DBSCAN&lt;/code&gt; &lt;/a&gt;一つは缶形状の、入力類似性行列 &lt;code&gt;[n_samples, n_samples]&lt;/code&gt; 。これらは、&lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt; &lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt; &lt;/a&gt;モジュールの関数から取得できます。</target>
        </trans-unit>
        <trans-unit id="deab058e87e7d8cac343ed7483a7cf721eca4119" translate="yes" xml:space="preserve">
          <source>One method to address the regularization problem is to use multiple weight vectors in each neighborhood. This is the essence of &lt;em&gt;modified locally linear embedding&lt;/em&gt; (MLLE). MLLE can be performed with function &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt;&lt;code&gt;locally_linear_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt;&lt;code&gt;LocallyLinearEmbedding&lt;/code&gt;&lt;/a&gt;, with the keyword &lt;code&gt;method = 'modified'&lt;/code&gt;. It requires &lt;code&gt;n_neighbors &amp;gt; n_components&lt;/code&gt;.</source>
          <target state="translated">正則化問題に対処する1つの方法は、各近傍で複数の重みベクトルを使用することです。これは、&lt;em&gt;修正されたローカル線形埋め込み&lt;/em&gt;（MLLE）の本質です。 MLLEは関数を用いて行うことができる&lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt; &lt;code&gt;locally_linear_embedding&lt;/code&gt; &lt;/a&gt;またはオブジェクト指向相手&lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt; &lt;code&gt;LocallyLinearEmbedding&lt;/code&gt; &lt;/a&gt;キーワードと、 &lt;code&gt;method = 'modified'&lt;/code&gt; 。 &lt;code&gt;n_neighbors &amp;gt; n_components&lt;/code&gt; が必要です。</target>
        </trans-unit>
        <trans-unit id="8b0abef56ded5ecf131b35733971a4004aa542f0" translate="yes" xml:space="preserve">
          <source>One might alternatively consider a collection of character n-grams, a representation resilient against misspellings and derivations.</source>
          <target state="translated">別の方法として、文字のn-gramのコレクション、スペルミスや派生に強い表現を考えることもできます。</target>
        </trans-unit>
        <trans-unit id="61c492958dc81c1a6d9f632bafd3909d2bb143b8" translate="yes" xml:space="preserve">
          <source>One of the challenges which is faced here is that the solvers can fail to converge to a well-conditioned estimate. The corresponding values of alpha then come out as missing values, but the optimum may be close to these missing values.</source>
          <target state="translated">ここで直面する課題の1つは、ソルバーが条件付きの推定値に収束できないことです。アルファの対応する値は欠損値として出てきますが、最適値はこの欠損値に近いかもしれません。</target>
        </trans-unit>
        <trans-unit id="70a04d887115ca6d6700f00cd1afa9bf1cffed38" translate="yes" xml:space="preserve">
          <source>One of the earliest approaches to manifold learning is the Isomap algorithm, short for Isometric Mapping. Isomap can be viewed as an extension of Multi-dimensional Scaling (MDS) or Kernel PCA. Isomap seeks a lower-dimensional embedding which maintains geodesic distances between all points. Isomap can be performed with the object &lt;a href=&quot;generated/sklearn.manifold.isomap#sklearn.manifold.Isomap&quot;&gt;&lt;code&gt;Isomap&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">多様体学習への最も初期のアプローチの1つは、アイソメトリックマッピングの略であるIsomapアルゴリズムです。Isomapは、多次元スケーリング（MDS）またはカーネルPCAの拡張機能と見なすことができます。Isomapは、すべてのポイント間の測地線距離を維持する低次元の埋め込みを求めます。Isomapは、オブジェクト&lt;a href=&quot;generated/sklearn.manifold.isomap#sklearn.manifold.Isomap&quot;&gt; &lt;code&gt;Isomap&lt;/code&gt; を使用&lt;/a&gt;して実行できます。</target>
        </trans-unit>
        <trans-unit id="8d30b63915c687687af955c31a96ac094f06cb9f" translate="yes" xml:space="preserve">
          <source>One of the most straight-forward concerns one may have when using/choosing a machine learning toolkit is the latency at which predictions can be made in a production environment.</source>
          <target state="translated">機械学習ツールキットを使用/選択する際に最も簡単な懸念事項の1つは、本番環境での予測が可能な待ち時間です。</target>
        </trans-unit>
        <trans-unit id="e3967d3ba22f4ac7f4c1ab09bac9634bd847ca9c" translate="yes" xml:space="preserve">
          <source>One of:</source>
          <target state="translated">の一つです。</target>
        </trans-unit>
        <trans-unit id="d25b0126083dd51df31e94af07b51bd893fc80ee" translate="yes" xml:space="preserve">
          <source>One other useful application of kernel density estimation is to learn a non-parametric generative model of a dataset in order to efficiently draw new samples from this generative model. Here is an example of using this process to create a new set of hand-written digits, using a Gaussian kernel learned on a PCA projection of the data:</source>
          <target state="translated">カーネル密度推定のもう一つの有用なアプリケーションは、この生成モデルから新しいサンプルを効率的に引くために、データセットのノンパラメトリック生成モデルを学習することです。このプロセスを用いて、データのPCA投影で学習したガウスカーネルを用いて、手書きの数字の新しいセットを作成した例を示します。</target>
        </trans-unit>
        <trans-unit id="fee8a97f6bc38e5962a611f176ea8084294905c7" translate="yes" xml:space="preserve">
          <source>One possible difference with the &lt;code&gt;glasso&lt;/code&gt; R package is that the diagonal coefficients are not penalized.</source>
          <target state="translated">&lt;code&gt;glasso&lt;/code&gt; Rパッケージとの考えられる違いの1つは、対角係数にペナルティが課されないことです。</target>
        </trans-unit>
        <trans-unit id="ea6c78b875e9abbb9afb65361c14c4ab4fe517e5" translate="yes" xml:space="preserve">
          <source>One typical use case is to wrap an existing metric function from the library with non-default values for its parameters, such as the &lt;code&gt;beta&lt;/code&gt; parameter for the &lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt;&lt;code&gt;fbeta_score&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">1つの典型的な使用例は、&lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt; &lt;code&gt;fbeta_score&lt;/code&gt; &lt;/a&gt;関数の &lt;code&gt;beta&lt;/code&gt; パラメーターなど、パラメーターの非デフォルト値でライブラリーから既存のメトリック関数をラップすることです。</target>
        </trans-unit>
        <trans-unit id="d21d62671a1a16508e611633019b29f0b4ceb760" translate="yes" xml:space="preserve">
          <source>One way to avoid the query complexity is to pre-compute sparse neighborhoods in chunks using &lt;a href=&quot;sklearn.neighbors.nearestneighbors#sklearn.neighbors.NearestNeighbors.radius_neighbors_graph&quot;&gt;&lt;code&gt;NearestNeighbors.radius_neighbors_graph&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;mode='distance'&lt;/code&gt;, then using &lt;code&gt;metric='precomputed'&lt;/code&gt; here.</source>
          <target state="translated">クエリの複雑さを回避する1つの方法は、 &lt;code&gt;mode='distance'&lt;/code&gt; で&lt;a href=&quot;sklearn.neighbors.nearestneighbors#sklearn.neighbors.NearestNeighbors.radius_neighbors_graph&quot;&gt; &lt;code&gt;NearestNeighbors.radius_neighbors_graph&lt;/code&gt; &lt;/a&gt;を使用し、次に &lt;code&gt;metric='precomputed'&lt;/code&gt; precomputed 'を使用してチャンク内の疎な近傍を事前計算することです。</target>
        </trans-unit>
        <trans-unit id="7904a0df31dead1d3d1a1bdda9b6baa78b3e3ac4" translate="yes" xml:space="preserve">
          <source>One well-known issue with LLE is the regularization problem. When the number of neighbors is greater than the number of input dimensions, the matrix defining each local neighborhood is rank-deficient. To address this, standard LLE applies an arbitrary regularization parameter \(r\), which is chosen relative to the trace of the local weight matrix. Though it can be shown formally that as \(r \to 0\), the solution converges to the desired embedding, there is no guarantee that the optimal solution will be found for \(r &amp;gt; 0\). This problem manifests itself in embeddings which distort the underlying geometry of the manifold.</source>
          <target state="translated">LLEのよく知られた問題の1つは、正則化の問題です。近傍の数が入力次元の数より大きい場合、各局所近傍を定義する行列はランクが不足しています。これに対処するために、標準のLLEは、任意の正則化パラメーター\（r \）を適用します。これは、ローカルの重み行列のトレースに対して相対的に選択されます。正式には\（r \ to 0 \）として解を求めることができますが、解は目的の埋め込みに収束しますが、\（r&amp;gt; 0 \）に対して最適解が見つかる保証はありません。この問題は、多様体の基本的なジオメトリを歪める埋め込みに現れます。</target>
        </trans-unit>
        <trans-unit id="4a89ac2f620199dd99f97fe1ad98300bc4f72269" translate="yes" xml:space="preserve">
          <source>One-class SVM with non-linear kernel (RBF)</source>
          <target state="translated">非線形カーネル(RBF)を用いた1クラスSVM</target>
        </trans-unit>
        <trans-unit id="b4a3aede9df40da523f973c7487f254218f78511" translate="yes" xml:space="preserve">
          <source>One-vs-one multiclass strategy</source>
          <target state="translated">1対1のマルチクラス戦略</target>
        </trans-unit>
        <trans-unit id="ee528cbd4b4f2e2829af351b64b6eb8bfd42a4f6" translate="yes" xml:space="preserve">
          <source>One-vs-the-rest (OvR) multiclass/multilabel strategy</source>
          <target state="translated">ワンバイザレスト(OvR)マルチクラス/マルチラベル戦略</target>
        </trans-unit>
        <trans-unit id="64ecee535f4fdc8be570462551ed8105268af715" translate="yes" xml:space="preserve">
          <source>One-way PDPs tell us about the interaction between the target response and the target feature (e.g. linear, non-linear). The upper left plot in the above Figure shows the effect of the median income in a district on the median house price; we can clearly see a linear relationship among them.</source>
          <target state="translated">一方向PDPは、対象反応と対象特徴との間の相互作用(例えば、線形、非線形)について教えてくれます。上の図の左上のプロットは、ある地区の所得の中央値が住宅価格の中央値に与える影響を示していますが、両者の間には明らかに線形の関係が見られます。</target>
        </trans-unit>
        <trans-unit id="aae2ee6c9851c7a4ce4cd6cfb817bfde607325bf" translate="yes" xml:space="preserve">
          <source>Online Passive-Aggressive Algorithms &amp;lt;&lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&lt;/a&gt;&amp;gt; K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR (2006)</source>
          <target state="translated">オンラインのパッシブアグレッシブアルゴリズム&amp;lt; &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&lt;/a&gt; &amp;gt; K.クランマー、O。デケル、J。ケシャット、S。シャレフシュワルツ、Y。シンガー- JMLR（2006）</target>
        </trans-unit>
        <trans-unit id="59363dcf6a532d4c72655a5346d2c500295612f8" translate="yes" xml:space="preserve">
          <source>Online VB with Mini-Batch update.</source>
          <target state="translated">オンラインVBでミニバッチ更新。</target>
        </trans-unit>
        <trans-unit id="829e73254cb47c834763ade46578341830688d18" translate="yes" xml:space="preserve">
          <source>Online computation of max absolute value of X for later scaling.</source>
          <target state="translated">後でスケーリングするためのXの最大絶対値をオンラインで計算します。</target>
        </trans-unit>
        <trans-unit id="1dffcf7d5a055d764cfb2adb13901c054d8691b3" translate="yes" xml:space="preserve">
          <source>Online computation of max absolute value of X for later scaling. All of X is processed as a single batch. This is intended for cases when &lt;code&gt;fit&lt;/code&gt; is not feasible due to very large number of &lt;code&gt;n_samples&lt;/code&gt; or because X is read from a continuous stream.</source>
          <target state="translated">後でスケーリングするためのXの最大絶対値のオンライン計算。Xはすべて1つのバッチとして処理されます。これは、 &lt;code&gt;n_samples&lt;/code&gt; の数が非常に多いため、またはXが連続ストリームから読み取られるために、 &lt;code&gt;fit&lt;/code&gt; が実現できない場合を対象としています。</target>
        </trans-unit>
        <trans-unit id="5b59fd4b2594ce8e5c7bbe150a07e7588723c96b" translate="yes" xml:space="preserve">
          <source>Online computation of mean and std on X for later scaling.</source>
          <target state="translated">後のスケーリングのためにXの平均値と標準値をオンラインで計算します。</target>
        </trans-unit>
        <trans-unit id="98a787216e7563ac11e03cf3274711f17911c2c2" translate="yes" xml:space="preserve">
          <source>Online computation of mean and std on X for later scaling. All of X is processed as a single batch. This is intended for cases when &lt;code&gt;fit&lt;/code&gt; is not feasible due to very large number of &lt;code&gt;n_samples&lt;/code&gt; or because X is read from a continuous stream.</source>
          <target state="translated">後でスケーリングするためのXでの平均と標準のオンライン計算。Xはすべて1つのバッチとして処理されます。これは、 &lt;code&gt;n_samples&lt;/code&gt; の数が非常に多いため、またはXが連続ストリームから読み取られるために、 &lt;code&gt;fit&lt;/code&gt; が実現できない場合を対象としています。</target>
        </trans-unit>
        <trans-unit id="3a0a40bed8a368eb74567adc0b902d5438bbb233" translate="yes" xml:space="preserve">
          <source>Online computation of min and max on X for later scaling.</source>
          <target state="translated">後のスケーリングのためにXの最小値と最大値をオンラインで計算します。</target>
        </trans-unit>
        <trans-unit id="245a52e0e0da8fa60b8bd0ab73c4b352a71c8d4a" translate="yes" xml:space="preserve">
          <source>Online computation of min and max on X for later scaling. All of X is processed as a single batch. This is intended for cases when &lt;code&gt;fit&lt;/code&gt; is not feasible due to very large number of &lt;code&gt;n_samples&lt;/code&gt; or because X is read from a continuous stream.</source>
          <target state="translated">後でスケーリングするためのXでの最小値と最大値のオンライン計算。Xはすべて1つのバッチとして処理されます。これは、 &lt;code&gt;n_samples&lt;/code&gt; の数が非常に多いため、またはXが連続ストリームから読み取られるために、 &lt;code&gt;fit&lt;/code&gt; が実現できない場合を対象としています。</target>
        </trans-unit>
        <trans-unit id="3bdeb493aeece54b83eea920715d4b7167b710bb" translate="yes" xml:space="preserve">
          <source>Online learning of a dictionary of parts of faces</source>
          <target state="translated">顔のパーツ辞書のオンライン学習</target>
        </trans-unit>
        <trans-unit id="afbac89ba6ac8bba06d8e8f00f8db1d633c505b3" translate="yes" xml:space="preserve">
          <source>Online learning.</source>
          <target state="translated">オンライン学習。</target>
        </trans-unit>
        <trans-unit id="e15bae968fe9434653919edecb56e181cf3bdca0" translate="yes" xml:space="preserve">
          <source>Online learning. Prevents rebuilding of CFTree from scratch.</source>
          <target state="translated">オンライン学習。CFTreeの一からの再構築を防ぎます。</target>
        </trans-unit>
        <trans-unit id="fba366205dda8a9f9c620fa8147677029ec02688" translate="yes" xml:space="preserve">
          <source>Only active when backend=&amp;rdquo;loky&amp;rdquo; or &amp;ldquo;multiprocessing&amp;rdquo;.</source>
          <target state="translated">backend =&amp;rdquo; loky&amp;rdquo;または&amp;ldquo; multiprocessing&amp;rdquo;の場合のみアクティブです。</target>
        </trans-unit>
        <trans-unit id="302203b3b2bd4b6979838ea661e3dedb562a6303" translate="yes" xml:space="preserve">
          <source>Only adjusted measures can hence safely be used as a consensus index to evaluate the average stability of clustering algorithms for a given value of k on various overlapping sub-samples of the dataset.</source>
          <target state="translated">したがって、調整された測定値のみが、データセットの様々なオーバーラップしたサブサンプルにおいて、与えられた値kに対するクラスタリングアルゴリズムの平均安定性を評価するためのコンセンサス指標として安全に使用することができます。</target>
        </trans-unit>
        <trans-unit id="b41ade38f91e30c61b5c1030ad80447ac59509af" translate="yes" xml:space="preserve">
          <source>Only applies to sparse matrices. If True, the sparse entries of the matrix are discarded to compute the quantile statistics. If False, these entries are treated as zeros.</source>
          <target state="translated">疎な行列にのみ適用されます.True の場合,行列の疎なエントリは,分位統計量を計算するために破棄されます.False の場合,これらのエントリはゼロとして扱われます.</target>
        </trans-unit>
        <trans-unit id="6239790ca1ea503b946542f5fd11362f9a8d181e" translate="yes" xml:space="preserve">
          <source>Only available for novelty detection (when novelty is set to True). The argument X is supposed to contain &lt;em&gt;new data&lt;/em&gt;: if X contains a point from training, it considers the later in its own neighborhood. Also, the samples in X are not considered in the neighborhood of any point. The score_samples on training data is available by considering the the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute.</source>
          <target state="translated">新規性検出にのみ使用できます（新規性がTrueに設定されている場合）。引数Xには&lt;em&gt;新しいデータ&lt;/em&gt;が含まれているはずです。Xにトレーニングからのポイントが含まれている場合、Xは自身の近傍にある後者を考慮します。また、Xのサンプルは、どの点の近傍でも考慮されません。トレーニングデータのscore_samplesは、 &lt;code&gt;negative_outlier_factor_&lt;/code&gt; 属性を考慮することで利用できます。</target>
        </trans-unit>
        <trans-unit id="42065a31e81b2581624e9d29e5e9b175fb835b62" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;decision_function&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;refit=True&lt;/code&gt; であり、基になる推定器が &lt;code&gt;decision_function&lt;/code&gt; をサポートしている場合にのみ使用できます。</target>
        </trans-unit>
        <trans-unit id="b5f87bbc5994209afe765ecb3d4b6e3e28348b8b" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;predict&lt;/code&gt;.</source>
          <target state="translated">場合にのみ利用可能 &lt;code&gt;refit=True&lt;/code&gt; 基礎となる推定サポートを &lt;code&gt;predict&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d2e232f30b7c8c685e1c17116e7dcb136df3f8ad" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;predict_log_proba&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;refit=True&lt;/code&gt; で、基になる推定器が &lt;code&gt;predict_log_proba&lt;/code&gt; をサポートしている場合にのみ使用できます。</target>
        </trans-unit>
        <trans-unit id="590883a61b4915ecfb6720c62deaa2c81b9eda84" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;refit=True&lt;/code&gt; で、基になる推定器が &lt;code&gt;predict_proba&lt;/code&gt; をサポートしている場合にのみ使用できます。</target>
        </trans-unit>
        <trans-unit id="3fd90433c474723d07589bf28196170034c8822e" translate="yes" xml:space="preserve">
          <source>Only available if the underlying estimator implements &lt;code&gt;inverse_transform&lt;/code&gt; and &lt;code&gt;refit=True&lt;/code&gt;.</source>
          <target state="translated">基礎となる推定器が &lt;code&gt;inverse_transform&lt;/code&gt; と &lt;code&gt;refit=True&lt;/code&gt; を実装している場合にのみ使用できます。</target>
        </trans-unit>
        <trans-unit id="5b6ee95bb2d64ff7d78caebfb3e0ee07b947d80e" translate="yes" xml:space="preserve">
          <source>Only available if the underlying estimator supports &lt;code&gt;transform&lt;/code&gt; and &lt;code&gt;refit=True&lt;/code&gt;.</source>
          <target state="translated">基になる推定器が &lt;code&gt;transform&lt;/code&gt; および &lt;code&gt;refit=True&lt;/code&gt; をサポートしている場合にのみ使用できます。</target>
        </trans-unit>
        <trans-unit id="91571ddad0f13d4b107795b8172bb8b9e0e57731" translate="yes" xml:space="preserve">
          <source>Only kernels that produce similarity scores (non-negative values that increase with similarity) should be used. This property is not checked by the clustering algorithm.</source>
          <target state="translated">類似度スコア(類似度に応じて増加する非負の値)を生成するカーネルのみを使用する必要があります。このプロパティはクラスタリングアルゴリズムによってチェックされません。</target>
        </trans-unit>
        <trans-unit id="91f57910319c7032022a687ad833db0e0811e172" translate="yes" xml:space="preserve">
          <source>Only report results for the class specified by &lt;code&gt;pos_label&lt;/code&gt;. This is applicable only if targets (&lt;code&gt;y_{true,pred}&lt;/code&gt;) are binary.</source>
          <target state="translated">&lt;code&gt;pos_label&lt;/code&gt; で指定されたクラスの結果のみを報告します。これは、ターゲット（ &lt;code&gt;y_{true,pred}&lt;/code&gt; ）がバイナリの場合にのみ適用されます。</target>
        </trans-unit>
        <trans-unit id="aa7683d2cc754187a7839c7481d51d4e421e244f" translate="yes" xml:space="preserve">
          <source>Only returned if return_distance is set to True (for compatibility). The distances between the centers of the nodes. &lt;code&gt;distances[i]&lt;/code&gt; corresponds to a weighted euclidean distance between the nodes &lt;code&gt;children[i, 1]&lt;/code&gt; and &lt;code&gt;children[i, 2]&lt;/code&gt;. If the nodes refer to leaves of the tree, then &lt;code&gt;distances[i]&lt;/code&gt; is their unweighted euclidean distance. Distances are updated in the following way (from scipy.hierarchy.linkage):</source>
          <target state="translated">return_distanceがTrueに設定されている場合にのみ返されます（互換性のため）。ノードの中心間の距離。 &lt;code&gt;distances[i]&lt;/code&gt; は、ノード &lt;code&gt;children[i, 1]&lt;/code&gt; と &lt;code&gt;children[i, 2]&lt;/code&gt; 間の重み付きユークリッド距離に対応します。ノードがツリーの葉を参照する場合、 &lt;code&gt;distances[i]&lt;/code&gt; は重み付けされていないユークリッド距離です。距離は次の方法で更新されます（scipy.hierarchy.linkageから）：</target>
        </trans-unit>
        <trans-unit id="b2ff6162a14531590c3fe05f5c4da22c170a731e" translate="yes" xml:space="preserve">
          <source>Only the first 4 features are informative. The remaining features are useless.</source>
          <target state="translated">最初の4つの機能だけが参考になります。残りの機能は役に立たない。</target>
        </trans-unit>
        <trans-unit id="ccdb28c17d5d885e725cff4c70b04cf05f415c05" translate="yes" xml:space="preserve">
          <source>Only used if method=&amp;rsquo;barnes_hut&amp;rsquo; This is the trade-off between speed and accuracy for Barnes-Hut T-SNE. &amp;lsquo;angle&amp;rsquo; is the angular size (referred to as theta in [3]) of a distant node as measured from a point. If this size is below &amp;lsquo;angle&amp;rsquo; then it is used as a summary node of all points contained within it. This method is not very sensitive to changes in this parameter in the range of 0.2 - 0.8. Angle less than 0.2 has quickly increasing computation time and angle greater 0.8 has quickly increasing error.</source>
          <target state="translated">method = 'barnes_hut'の場合のみ使用されますこれは、Barnes-Hut T-SNEの速度と精度のトレードオフです。'angle'は、ポイントから測定した遠方ノードの角度サイズ（[3]ではシータと呼ばれます）です。このサイズが「角度」未満の場合、その中に含まれるすべてのポイントのサマリーノードとして使用されます。この方法は、このパラメーターの0.2〜0.8の範囲の変化にあまり敏感ではありません。角度が0.2未満の場合、計算時間が急速に増加し、角度が0.8より大きい場合、エラーが急速に増加します。</target>
        </trans-unit>
        <trans-unit id="feeded53201cd1098b357f2543d3cc3ddaf2bc59" translate="yes" xml:space="preserve">
          <source>Only used in edge case with a single class in the training set.</source>
          <target state="translated">学習セットに単一のクラスがある場合のエッジケースでのみ使用されます。</target>
        </trans-unit>
        <trans-unit id="e51e92f95034c804fc0810fdbc5d315daca2beb0" translate="yes" xml:space="preserve">
          <source>Only used when &lt;code&gt;solver='sgd'&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;solver='sgd'&lt;/code&gt; の場合にのみ使用されます。</target>
        </trans-unit>
        <trans-unit id="3466b805d384e470c3d1ee2beb1b9b317ac5cc22" translate="yes" xml:space="preserve">
          <source>Only used when solver=&amp;rsquo;sgd&amp;rsquo;.</source>
          <target state="translated">solver = 'sgd'の場合にのみ使用されます。</target>
        </trans-unit>
        <trans-unit id="04fb050fa307025a8b877f9d2c83069449f7ca94" translate="yes" xml:space="preserve">
          <source>Only works if &lt;code&gt;rows_&lt;/code&gt; and &lt;code&gt;columns_&lt;/code&gt; attributes exist.</source>
          <target state="translated">&lt;code&gt;rows_&lt;/code&gt; および &lt;code&gt;columns_&lt;/code&gt; 属性が存在する場合にのみ機能します。</target>
        </trans-unit>
        <trans-unit id="516478ad62f05e00111ddd57ddd26de9d50efa29" translate="yes" xml:space="preserve">
          <source>Open problem: Stock Market Structure</source>
          <target state="translated">公開問題:株式市場の構造</target>
        </trans-unit>
        <trans-unit id="988a0621a69f95c126d429edd6ad72b8b9753d30" translate="yes" xml:space="preserve">
          <source>OpenBLAS</source>
          <target state="translated">OpenBLAS</target>
        </trans-unit>
        <trans-unit id="01e06dfe8463084e545b7490a5b6cab212cacc1b" translate="yes" xml:space="preserve">
          <source>OpenML ID of the dataset. The most specific way of retrieving a dataset. If data_id is not given, name (and potential version) are used to obtain a dataset.</source>
          <target state="translated">データセットのOpenML ID。データセットを取得するための最も具体的な方法。data_idが与えられていない場合は、データセットを取得するために名前(および潜在的なバージョン)が用いられる。</target>
        </trans-unit>
        <trans-unit id="3c0cb6e8849966972823d3a411e3fa85cccc3662" translate="yes" xml:space="preserve">
          <source>Opposite of the Local Outlier Factor of X.</source>
          <target state="translated">Xの局所的な外れ要因の反対側。</target>
        </trans-unit>
        <trans-unit id="5e68f725eeef777e12b4d3a454a6208991fd24e6" translate="yes" xml:space="preserve">
          <source>Opposite of the Mahalanobis distances.</source>
          <target state="translated">マハラノビスの距離の反対側。</target>
        </trans-unit>
        <trans-unit id="b5fb56d4ea090bc2e90702500456ef35c8c80910" translate="yes" xml:space="preserve">
          <source>Opposite of the anomaly score defined in the original paper.</source>
          <target state="translated">原著で定義されたアノマリースコアの反対側。</target>
        </trans-unit>
        <trans-unit id="8d0235738e36c010f5cce0e1d51d26583f4fbd2f" translate="yes" xml:space="preserve">
          <source>Opposite of the value of X on the K-means objective.</source>
          <target state="translated">K-means目的語のXの値の反対側。</target>
        </trans-unit>
        <trans-unit id="d4790d7d59a93c4896ec3d473b252d9c8e90d50a" translate="yes" xml:space="preserve">
          <source>Optimal choices for the sampling interval for certain data ranges can be computed (see the reference). The default values should be reasonable.</source>
          <target state="translated">特定のデータ範囲のサンプリング間隔の最適な選択を計算することができます(参考文献を参照)。デフォルト値は妥当な値でなければなりません。</target>
        </trans-unit>
        <trans-unit id="ce024d3ab746293c4c12993e7780e537aaab5bd3" translate="yes" xml:space="preserve">
          <source>Optimized BLAS / LAPACK implementations include:</source>
          <target state="translated">最適化されたBLAS/LAPACKの実装には以下のようなものがあります。</target>
        </trans-unit>
        <trans-unit id="e7a4cb55708bbb7494e2613ab1d6bd3cf5f4ed80" translate="yes" xml:space="preserve">
          <source>Optimizing the KL divergence can be a little bit tricky sometimes. There are five parameters that control the optimization of t-SNE and therefore possibly the quality of the resulting embedding:</source>
          <target state="translated">KLダイバージェンスの最適化は、時として少し厄介なことがあります。t-SNEの最適化を制御する5つのパラメータがあり、結果として得られる埋め込みの品質を制御することができます。</target>
        </trans-unit>
        <trans-unit id="59b7edea35dae0ba7f04b93972cd416b8729437e" translate="yes" xml:space="preserve">
          <source>Option to scale data</source>
          <target state="translated">データのスケーリングオプション</target>
        </trans-unit>
        <trans-unit id="b448cb50c967f57d438352622bd92cc83d5cd21c" translate="yes" xml:space="preserve">
          <source>Optional display names matching the labels (same order).</source>
          <target state="translated">オプションでラベルにマッチする表示名(同じ順番)。</target>
        </trans-unit>
        <trans-unit id="f7746b3179890337eeaaee24d3cefbf3e21f4716" translate="yes" xml:space="preserve">
          <source>Optional list of label indices to include in the report.</source>
          <target state="translated">レポートに含めるラベルインデックスのオプションリスト。</target>
        </trans-unit>
        <trans-unit id="444d0152ba1b6a9d2f83b135dcad3591aef4140b" translate="yes" xml:space="preserve">
          <source>Optionally, weights can be provided for the individual classifiers:</source>
          <target state="translated">オプションとして、個々の分類器に重みを与えることができる。</target>
        </trans-unit>
        <trans-unit id="bdffb8593fdda1fb06f464d41401bd543c75d539" translate="yes" xml:space="preserve">
          <source>Or as a dict mapping scorer name to a predefined or custom scoring function:</source>
          <target state="translated">または、定義済みまたはカスタムのスコアリング関数にスコアラー名をマッピングするディクショナリとしても使用できます。</target>
        </trans-unit>
        <trans-unit id="2919d9f2f1803bd27d88cb6979d8731b9671873d" translate="yes" xml:space="preserve">
          <source>Or, the Itakura-Saito (IS) divergence:</source>
          <target state="translated">あるいは、板倉-斎藤(IS)の発散。</target>
        </trans-unit>
        <trans-unit id="2eae1790c8b18065a4e4be5e643bf49617d7e481" translate="yes" xml:space="preserve">
          <source>Oracle Approximating Shrinkage Estimator</source>
          <target state="translated">オラクル近似収縮推定器</target>
        </trans-unit>
        <trans-unit id="09fb6aaba7940a7b7ffdbc9cbb9b3498303c1bad" translate="yes" xml:space="preserve">
          <source>Orange</source>
          <target state="translated">Orange</target>
        </trans-unit>
        <trans-unit id="61e854a8201b91e00e8fdcbd770fb61bc8a83663" translate="yes" xml:space="preserve">
          <source>Order of the norm used to filter the vectors of coefficients below &lt;code&gt;threshold&lt;/code&gt; in the case where the &lt;code&gt;coef_&lt;/code&gt; attribute of the estimator is of dimension 2.</source>
          <target state="translated">推定器の &lt;code&gt;coef_&lt;/code&gt; 属性が2次元である場合に、 &lt;code&gt;threshold&lt;/code&gt; を下回る係数のベクトルをフィルター処理するために使用されるノルムの次数。</target>
        </trans-unit>
        <trans-unit id="04f01a5d4b5e2de7c5bc38f04fe789073a85e1a0" translate="yes" xml:space="preserve">
          <source>Ordinary Least Squares and Ridge Regression Variance</source>
          <target state="translated">常用最小二乗とリッジ回帰の分散</target>
        </trans-unit>
        <trans-unit id="69dfb38c02d49acfa60317532da350814008c91b" translate="yes" xml:space="preserve">
          <source>Ordinary least squares Linear Regression.</source>
          <target state="translated">普通の最小二乗線形回帰。</target>
        </trans-unit>
        <trans-unit id="c6a26fb9333dc9c04fcf0b8a8d439bec3529ccb6" translate="yes" xml:space="preserve">
          <source>Original Algorithm is detailed in the book &lt;code&gt;Bayesian learning for neural networks&lt;/code&gt; by Radford M. Neal</source>
          <target state="translated">元のアルゴリズムについては、Radford M. Neal 著の本「 &lt;code&gt;Bayesian learning for neural networks&lt;/code&gt; 」で詳しく説明されています。</target>
        </trans-unit>
        <trans-unit id="285a92205b1ae0ee38089b09c3441dcd00669592" translate="yes" xml:space="preserve">
          <source>Original Algorithm is detailed in the paper &lt;a href=&quot;http://www-stat.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;Least Angle Regression&lt;/a&gt; by Hastie et al.</source>
          <target state="translated">元のアルゴリズムについては、Hastie等による論文&lt;a href=&quot;http://www-stat.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;Least Angle Regressionで&lt;/a&gt;詳しく説明されています。</target>
        </trans-unit>
        <trans-unit id="40e1a40682f2197d130d7160c72b099cf6445896" translate="yes" xml:space="preserve">
          <source>Original Owners:</source>
          <target state="translated">元の所有者</target>
        </trans-unit>
        <trans-unit id="7ad091e9d90ec0296b62c3e5e44ac8d89a063912" translate="yes" xml:space="preserve">
          <source>Original data</source>
          <target state="translated">オリジナルデータ</target>
        </trans-unit>
        <trans-unit id="e08c8e7e7ce9b41fa431a10c664db0046193d186" translate="yes" xml:space="preserve">
          <source>Original indices of sorted hashed values in the fitted index.</source>
          <target state="translated">フィットインデックスでソートされたハッシュ化された値の元のインデックス。</target>
        </trans-unit>
        <trans-unit id="d62335c307cfd6338409df5c3eb510c3da387b07" translate="yes" xml:space="preserve">
          <source>Orthogonal Matching Pursuit</source>
          <target state="translated">直交一致追求</target>
        </trans-unit>
        <trans-unit id="4b43e1fc477a65c488f6b885c65608062bcdd067" translate="yes" xml:space="preserve">
          <source>Orthogonal Matching Pursuit (OMP)</source>
          <target state="translated">直交一致追求(OMP)</target>
        </trans-unit>
        <trans-unit id="6f8635fe08116f66d41828127f270123a3daf2dc" translate="yes" xml:space="preserve">
          <source>Orthogonal Matching Pursuit model (OMP)</source>
          <target state="translated">直交マッチング追求モデル(OMP)</target>
        </trans-unit>
        <trans-unit id="b4cea4b2e1d94206efdd2c81ac084782051e04a0" translate="yes" xml:space="preserve">
          <source>Orthogonal matching pursuit (&lt;a href=&quot;linear_model#omp&quot;&gt;Orthogonal Matching Pursuit (OMP)&lt;/a&gt;)</source>
          <target state="translated">直交マッチング追跡（&lt;a href=&quot;linear_model#omp&quot;&gt;Orthogonal Matching Pursuit（OMP）&lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="2d35a4350f19547a1df08de9c97e28d5eb4c4c18" translate="yes" xml:space="preserve">
          <source>Orthogonal matching pursuit was introduced in G. Mallat, Z. Zhang, Matching pursuits with time-frequency dictionaries, IEEE Transactions on Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415. (&lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt;)</source>
          <target state="translated">直交マッチング追跡は、G。Mallat、Z。Zhang、時間周波数辞書によるマッチング追跡、IEEE Transactions on Signal Processing、Vol。41、No。12（1993年12月）、3397-3415ページ。（&lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="5e7d9b3e4cebb5843b9125c6b797beb3832d1f95" translate="yes" xml:space="preserve">
          <source>Orthogonal matching pursuit was introduced in S. Mallat, Z. Zhang, Matching pursuits with time-frequency dictionaries, IEEE Transactions on Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415. (&lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt;)</source>
          <target state="translated">直交マッチング追跡は、S。Mallat、Z。Zhang、時間周波数辞書によるマッチング追跡、IEEE Transactions on Signal Processing、Vol。41、No。12（1993年12月）、3397-3415ページ。（&lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="0faa321ae463cf423d057b0fb19c09b0142f3c2a" translate="yes" xml:space="preserve">
          <source>Other Parameters:</source>
          <target state="translated">その他のパラメータ</target>
        </trans-unit>
        <trans-unit id="f7488409b393eaa19a207155b56a3606cc42d9c5" translate="yes" xml:space="preserve">
          <source>Other Versions</source>
          <target state="translated">その他のバージョン</target>
        </trans-unit>
        <trans-unit id="bf60b2f111b62bfaee7623785937d680b71fe343" translate="yes" xml:space="preserve">
          <source>Other distance functions can be used in NMF as, for example, the (generalized) Kullback-Leibler (KL) divergence, also referred as I-divergence:</source>
          <target state="translated">他の距離関数は、例えば、(一般化された)Kullback-Leibler(KL)発散(I発散とも呼ばれる)としてNMFで使用することができます。</target>
        </trans-unit>
        <trans-unit id="7ba50765d1cae4c4ed89d4ff332ed3b825d08abc" translate="yes" xml:space="preserve">
          <source>Other features match the names and e-mail addresses of particular people who were posting at the time.</source>
          <target state="translated">他にも、その時に投稿していた特定の人の名前やメールアドレスを一致させる機能があります。</target>
        </trans-unit>
        <trans-unit id="51c966edfa7d64a0b7dcf68b92d77cfd5b366772" translate="yes" xml:space="preserve">
          <source>Other machine learning packages for Python and related projects. Also algorithms that are slightly out of scope or not well established enough for scikit-learn.</source>
          <target state="translated">Pythonや関連プロジェクトのための他の機械学習パッケージ。また、scikit-learnとしてはやや範囲外だったり、十分に確立されていないアルゴリズムも。</target>
        </trans-unit>
        <trans-unit id="2ea8bcd548fe9ec11d17cc82aea4ab0fbdf7f8f3" translate="yes" xml:space="preserve">
          <source>Other regression generators generate functions deterministically from randomized features. &lt;a href=&quot;../modules/generated/sklearn.datasets.make_sparse_uncorrelated#sklearn.datasets.make_sparse_uncorrelated&quot;&gt;&lt;code&gt;make_sparse_uncorrelated&lt;/code&gt;&lt;/a&gt; produces a target as a linear combination of four features with fixed coefficients. Others encode explicitly non-linear relations: &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman1#sklearn.datasets.make_friedman1&quot;&gt;&lt;code&gt;make_friedman1&lt;/code&gt;&lt;/a&gt; is related by polynomial and sine transforms; &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman2#sklearn.datasets.make_friedman2&quot;&gt;&lt;code&gt;make_friedman2&lt;/code&gt;&lt;/a&gt; includes feature multiplication and reciprocation; and &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman3#sklearn.datasets.make_friedman3&quot;&gt;&lt;code&gt;make_friedman3&lt;/code&gt;&lt;/a&gt; is similar with an arctan transformation on the target.</source>
          <target state="translated">他の回帰ジェネレーターは、ランダム化された特徴から決定論的に関数を生成します。&lt;a href=&quot;../modules/generated/sklearn.datasets.make_sparse_uncorrelated#sklearn.datasets.make_sparse_uncorrelated&quot;&gt; &lt;code&gt;make_sparse_uncorrelated&lt;/code&gt; &lt;/a&gt;は、固定係数を持つ4つの特徴の線形結合としてターゲットを生成します。その他は、明示的に非線形の関係をエンコードします&lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman1#sklearn.datasets.make_friedman1&quot;&gt; &lt;code&gt;make_friedman1&lt;/code&gt; &lt;/a&gt;は、多項式変換と正弦変換によって関連付けられます。&lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman2#sklearn.datasets.make_friedman2&quot;&gt; &lt;code&gt;make_friedman2&lt;/code&gt; に&lt;/a&gt;は、特徴の乗算と往復が含まれます。そして&lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman3#sklearn.datasets.make_friedman3&quot;&gt; &lt;code&gt;make_friedman3&lt;/code&gt; は、&lt;/a&gt;ターゲット上の逆正接変換と同様です。</target>
        </trans-unit>
        <trans-unit id="756226f83bdd3199110bcb639e6fbe93b81b2b14" translate="yes" xml:space="preserve">
          <source>Others also work in the multiclass case:</source>
          <target state="translated">他にも、マルチクラスのケースで活躍しています。</target>
        </trans-unit>
        <trans-unit id="bce48a0cb0a5e5960a4a35ec10cf25f56bf2f60b" translate="yes" xml:space="preserve">
          <source>Otherwise the input is expected to be the sequence strings or bytes items are expected to be analyzed directly.</source>
          <target state="translated">それ以外の場合は、入力はシーケンス文字列またはバイト項目が直接分析されることが期待されます。</target>
        </trans-unit>
        <trans-unit id="1eb83bd09e16b910ee3986257ed6e80732bc066a" translate="yes" xml:space="preserve">
          <source>Our definition: &lt;a href=&quot;#mosley2013&quot; id=&quot;id5&quot;&gt;[Mosley2013]&lt;/a&gt;, &lt;a href=&quot;#kelleher2015&quot; id=&quot;id6&quot;&gt;[Kelleher2015]&lt;/a&gt; and &lt;a href=&quot;#guyon2015&quot; id=&quot;id7&quot;&gt;[Guyon2015]&lt;/a&gt;, where &lt;a href=&quot;#guyon2015&quot; id=&quot;id8&quot;&gt;[Guyon2015]&lt;/a&gt; adopt the adjusted version to ensure that random predictions have a score of \(0\) and perfect predictions have a score of \(1\)..</source>
          <target state="translated">私たちの定義：&lt;a href=&quot;#mosley2013&quot; id=&quot;id5&quot;&gt;[Mosley2013]&lt;/a&gt;、&lt;a href=&quot;#kelleher2015&quot; id=&quot;id6&quot;&gt;[Kelleher2015]&lt;/a&gt;、&lt;a href=&quot;#guyon2015&quot; id=&quot;id7&quot;&gt;[Guyon2015]&lt;/a&gt;、ここで&lt;a href=&quot;#guyon2015&quot; id=&quot;id8&quot;&gt;[Guyon2015]&lt;/a&gt;は調整されたバージョンを採用して、ランダムな予測のスコアが\（0 \）で完全な予測のスコアが\（1 \）になるようにします。 。</target>
        </trans-unit>
        <trans-unit id="a60ce8fd0b60aee8ad7f5d9f917babe62e72b491" translate="yes" xml:space="preserve">
          <source>Our implementation&amp;rsquo;s score is 1 greater than the one given in Tsoumakas et al., 2010. This extends it to handle the degenerate case in which an instance has 0 true labels.</source>
          <target state="translated">私たちの実装のスコアは、Tsoumakas et al。、2010で与えられたスコアよりも1大きくなっています。これにより、インスタンスの真のラベルが0である縮退ケースを処理するように拡張されます。</target>
        </trans-unit>
        <trans-unit id="c3f0fa9ade6f943d608603fdef87384f7f12b49b" translate="yes" xml:space="preserve">
          <source>Out of the &lt;code&gt;n_features&lt;/code&gt; features, only 5 are actually used to compute &lt;code&gt;y&lt;/code&gt;. The remaining features are independent of &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;n_features&lt;/code&gt; 機能のうち、実際に &lt;code&gt;y&lt;/code&gt; の計算に使用されるのは5つだけです。残りの機能は &lt;code&gt;y&lt;/code&gt; から独立しています。</target>
        </trans-unit>
        <trans-unit id="de345f1c1e8c124d63c9ee465bc413813ba2423e" translate="yes" xml:space="preserve">
          <source>Out-of-bag (OOB) estimates can be a useful heuristic to estimate the &amp;ldquo;optimal&amp;rdquo; number of boosting iterations. OOB estimates are almost identical to cross-validation estimates but they can be computed on-the-fly without the need for repeated model fitting. OOB estimates are only available for Stochastic Gradient Boosting (i.e. &lt;code&gt;subsample &amp;lt; 1.0&lt;/code&gt;), the estimates are derived from the improvement in loss based on the examples not included in the bootstrap sample (the so-called out-of-bag examples). The OOB estimator is a pessimistic estimator of the true test loss, but remains a fairly good approximation for a small number of trees.</source>
          <target state="translated">Out-of-bag（OOB）推定は、ブースティング反復の「最適な」数を推定するための有用なヒューリスティックになります。OOB推定値は交差検証推定値とほぼ同じですが、繰り返しモデルフィッティングを行う必要なくオンザフライで計算できます。OOB推定は確率的勾配ブースティング（つまり、 &lt;code&gt;subsample &amp;lt; 1.0&lt;/code&gt; ）でのみ使用できます。推定は、ブートストラップサンプルに含まれていない例（いわゆるout-of-bagの例）に基づく損失の改善から得られます。OOB推定量は、真のテスト損失の悲観的な推定量ですが、少数のツリーに対してはかなり良い近似値のままです。</target>
        </trans-unit>
        <trans-unit id="0edae687594f6a8a4aaab025d755be89c91cf6e0" translate="yes" xml:space="preserve">
          <source>Out-of-core (or &amp;ldquo;external memory&amp;rdquo;) learning is a technique used to learn from data that cannot fit in a computer&amp;rsquo;s main memory (RAM).</source>
          <target state="translated">コア外（または「外部メモリ」）学習は、コンピュータのメインメモリ（RAM）に収まらないデータから学習するために使用される手法です。</target>
        </trans-unit>
        <trans-unit id="9961951956a78a655327742f08dd6b72dea1283f" translate="yes" xml:space="preserve">
          <source>Out-of-core classification of text documents</source>
          <target state="translated">テキスト文書のアウトオブコア分類</target>
        </trans-unit>
        <trans-unit id="1ee8fea1697e4d708569e4bb179873c92ff19379" translate="yes" xml:space="preserve">
          <source>Out:</source>
          <target state="translated">Out:</target>
        </trans-unit>
        <trans-unit id="5dd0aa388360b95626a38da9b18844d684c8d25b" translate="yes" xml:space="preserve">
          <source>Outlier detection</source>
          <target state="translated">外れ値検出</target>
        </trans-unit>
        <trans-unit id="875f738eb0e68cda4066331e25fac5af4c71d682" translate="yes" xml:space="preserve">
          <source>Outlier detection and novelty detection are both used for anomaly detection, where one is interested in detecting abnormal or unusual observations. Outlier detection is then also known as unsupervised anomaly detection and novelty detection as semi-supervised anomaly detection. In the context of outlier detection, the outliers/anomalies cannot form a dense cluster as available estimators assume that the outliers/anomalies are located in low density regions. On the contrary, in the context of novelty detection, novelties/anomalies can form a dense cluster as long as they are in a low density region of the training data, considered as normal in this context.</source>
          <target state="translated">外れ値検出と新規性検出は、異常または異常な観察を検出することに関心がある場合の異常検出に使用されます。外れ値検出は教師なし異常検出として、新規性検出は半教師付き異常検出としても知られています。外れ値検出の文脈では、利用可能な推定器は外れ値/異常が低密度領域にあると仮定しているため、外れ値/異常は密なクラスターを形成することができません。逆に、新規性検出の文脈では、新規性/異常は、学習データの低密度領域にある限り、密なクラスタを形成することができます(この文脈では正常と考えられます)。</target>
        </trans-unit>
        <trans-unit id="e16ebe52f017c4437fca8210daa352b7f7a34559" translate="yes" xml:space="preserve">
          <source>Outlier detection from covariance estimation may break or not perform well in high-dimensional settings. In particular, one will always take care to work with &lt;code&gt;n_samples &amp;gt; n_features ** 2&lt;/code&gt;.</source>
          <target state="translated">共分散推定からの異常値の検出は、高次元の設定で機能しないか、うまく機能しない可能性があります。特に、 &lt;code&gt;n_samples &amp;gt; n_features ** 2&lt;/code&gt; を使用する場合は常に注意が必要です。</target>
        </trans-unit>
        <trans-unit id="eb5776745abd0907a25a2d19ca27c92845132829" translate="yes" xml:space="preserve">
          <source>Outlier detection is similar to novelty detection in the sense that the goal is to separate a core of regular observations from some polluting ones, called &lt;em&gt;outliers&lt;/em&gt;. Yet, in the case of outlier detection, we don&amp;rsquo;t have a clean data set representing the population of regular observations that can be used to train any tool.</source>
          <target state="translated">外れ値の検出は、定期的な観測のコアを&lt;em&gt;外れ値&lt;/em&gt;と呼ばれるいくつかの汚染された観測から分離することを目的とするという意味で、新規性の検出と似ています。それでも、異常値検出の場合、ツールのトレーニングに使用できる定期的な観測の母集団を表す明確なデータセットはありません。</target>
        </trans-unit>
        <trans-unit id="1d8881b6614c5c1d87283378baf1dfbd30d62aa2" translate="yes" xml:space="preserve">
          <source>Outlier detection on a real data set</source>
          <target state="translated">実データセットでの外れ値検出</target>
        </trans-unit>
        <trans-unit id="4567caf33a07f033c1e56ef9d81272da195ec4e4" translate="yes" xml:space="preserve">
          <source>Outlier detection with Local Outlier Factor (LOF)</source>
          <target state="translated">局所外れ値因子(LOF)による外れ値検出</target>
        </trans-unit>
        <trans-unit id="1d4ae6e212657597b75c35cebf362553af1f6b83" translate="yes" xml:space="preserve">
          <source>Outliers in the X direction</source>
          <target state="translated">X方向の外れ値</target>
        </trans-unit>
        <trans-unit id="1280eb8e6f7378d868cfa7fd24acb5cb10594078" translate="yes" xml:space="preserve">
          <source>Outliers in the y direction</source>
          <target state="translated">y方向の外れ値</target>
        </trans-unit>
        <trans-unit id="fd162763a0f66a902211a2d40da7afdfc74ea634" translate="yes" xml:space="preserve">
          <source>Output a list of n_output arrays of class probabilities upon &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;predict_proba&lt;/code&gt; でクラス確率のn_output配列のリストを出力します。</target>
        </trans-unit>
        <trans-unit id="8298d7fc7f7d06e9b0287b5d9b7af6acdbad01e4" translate="yes" xml:space="preserve">
          <source>Output n_output values upon &lt;code&gt;predict&lt;/code&gt;;</source>
          <target state="translated">&lt;code&gt;predict&lt;/code&gt; 時にn_output値を出力します。</target>
        </trans-unit>
        <trans-unit id="0c950fe98702d8e76b55b31a01ec26c58021324c" translate="yes" xml:space="preserve">
          <source>Output-code based strategies are fairly different from one-vs-the-rest and one-vs-one. With these strategies, each class is represented in a Euclidean space, where each dimension can only be 0 or 1. Another way to put it is that each class is represented by a binary code (an array of 0 and 1). The matrix which keeps track of the location/code of each class is called the code book. The code size is the dimensionality of the aforementioned space. Intuitively, each class should be represented by a code as unique as possible and a good code book should be designed to optimize classification accuracy. In this implementation, we simply use a randomly-generated code book as advocated in &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3]&lt;/a&gt; although more elaborate methods may be added in the future.</source>
          <target state="translated">出力コードベースの戦略は、one-vs-the-restやone-vs-oneとはかなり異なります。これらの戦略では、各クラスはユークリッド空間で表されます。各次元は0または1のみです。別の言い方をすると、各クラスはバイナリコード（0と1の配列）で表されます。各クラスの場所/コードを追跡するマトリックスは、コードブックと呼ばれます。コードサイズは、前述の空間の次元数です。直感的には、各クラスはできるだけ一意のコードで表す必要があり、分類の精度を最適化するように適切なコードブックを設計する必要があります。この実装では、&lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3]で&lt;/a&gt;提唱されているように、ランダムに生成されたコードブックを使用するだけですが、将来、より複雑なメソッドが追加される可能性があります。</target>
        </trans-unit>
        <trans-unit id="ce947ff733c2ff6c4c204d57e36546e6961c8fdc" translate="yes" xml:space="preserve">
          <source>Output-code based strategies consist in representing each class with a binary code (an array of 0s and 1s). At fitting time, one binary classifier per bit in the code book is fitted. At prediction time, the classifiers are used to project new points in the class space and the class closest to the points is chosen. The main advantage of these strategies is that the number of classifiers used can be controlled by the user, either for compressing the model (0 &amp;lt; code_size &amp;lt; 1) or for making the model more robust to errors (code_size &amp;gt; 1). See the documentation for more details.</source>
          <target state="translated">出力コードベースの戦略は、各クラスをバイナリコード（0と1の配列）で表すことです。フィッティング時に、コードブックのビットごとに1つのバイナリ分類器がフィッティングされます。予測時に、分類子を使用してクラス空間に新しいポイントが投影され、ポイントに最も近いクラスが選択されます。これらの戦略の主な利点は、モデルを圧縮する（0 &amp;lt;code_size &amp;lt;1）か、モデルをエラーに対してより堅牢にする（code_size&amp;gt; 1）ために、使用される分類子の数をユーザーが制御できることです。詳細については、ドキュメントを参照してください。</target>
        </trans-unit>
        <trans-unit id="a7e6bae7017e237617a86072aea77d9c980daf13" translate="yes" xml:space="preserve">
          <source>Overall mean.</source>
          <target state="translated">全体の平均値。</target>
        </trans-unit>
        <trans-unit id="39400cd6ec0520b5a4505f75497b844c4371060d" translate="yes" xml:space="preserve">
          <source>Overall you can expect the prediction time to increase at least linearly with the number of features (non-linear cases can happen depending on the global memory footprint and estimator).</source>
          <target state="translated">全体的に、予測時間は特徴量の数に応じて少なくとも線形に増加すると予想できます(グローバルメモリフットプリントと推定器によっては非線形のケースが発生することがあります)。</target>
        </trans-unit>
        <trans-unit id="91bd96083d98dc97930a239b87544217767aceaf" translate="yes" xml:space="preserve">
          <source>Override the preprocessing (string transformation) stage while preserving the tokenizing and n-grams generation steps.</source>
          <target state="translated">トークン化とn-gram生成のステップを維持したまま、前処理(文字列変換)の段階をオーバーライドします。</target>
        </trans-unit>
        <trans-unit id="abd6316e00c26c25837bba2d69b86f216194acd8" translate="yes" xml:space="preserve">
          <source>Override the string tokenization step while preserving the preprocessing and n-grams generation steps. Only applies if &lt;code&gt;analyzer == 'word'&lt;/code&gt;.</source>
          <target state="translated">前処理とn-gram生成ステップを保持しながら、文字列トークン化ステップをオーバーライドします。 &lt;code&gt;analyzer == 'word'&lt;/code&gt; 場合にのみ適用されます。</target>
        </trans-unit>
        <trans-unit id="9ed28a68908d4cdeb1448490b897df73855c6566" translate="yes" xml:space="preserve">
          <source>P. Geurts, D. Ernst., and L. Wehenkel, &amp;ldquo;Extremely randomized trees&amp;rdquo;, Machine Learning, 63(1), 3-42, 2006.</source>
          <target state="translated">P. Geurts、D。Ernst。、およびL. Wehenkel、「Extremely randomized trees」、機械学習、63（1）、3-42、2006。</target>
        </trans-unit>
        <trans-unit id="915eb2720a9af992fe72961a5e439fc3997b7b8e" translate="yes" xml:space="preserve">
          <source>P. J. Rousseeuw. Least median of squares regression. Journal of American Statistical Ass., 79:871, 1984.</source>
          <target state="translated">P.J.Rousseeuw.二乗回帰の最小中央値.Journal of American Statistical Ass.,79:871,1984.</target>
        </trans-unit>
        <trans-unit id="b9c25cc16ba020ea92289241ec3d659cb7a5c1ce" translate="yes" xml:space="preserve">
          <source>P.A. Flach, M. Kull, &lt;a href=&quot;http://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf&quot;&gt;Precision-Recall-Gain Curves: PR Analysis Done Right&lt;/a&gt;, NIPS 2015.</source>
          <target state="translated">PA Flach、M。Kull 、&lt;a href=&quot;http://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf&quot;&gt;Precision-Recall-Gain Curves：PR Analysis Done Right&lt;/a&gt;、NIPS 2015。</target>
        </trans-unit>
        <trans-unit id="492b92fdeb678aa5ea0a0b2e24c313120c5ad6a0" translate="yes" xml:space="preserve">
          <source>PCA example with Iris Data-set</source>
          <target state="translated">アイリスデータセットを用いたPCAの例</target>
        </trans-unit>
        <trans-unit id="e783d8dc6810fed89a1dbeb972c615c5d6fa683c" translate="yes" xml:space="preserve">
          <source>PCA is used to decompose a multivariate dataset in a set of successive orthogonal components that explain a maximum amount of the variance. In scikit-learn, &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; is implemented as a &lt;em&gt;transformer&lt;/em&gt; object that learns \(n\) components in its &lt;code&gt;fit&lt;/code&gt; method, and can be used on new data to project it on these components.</source>
          <target state="translated">PCAは、分散の最大量を説明する一連の直交成分の多変量データセットを分解するために使用されます。scikit-learnでは、&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt;は、 &lt;code&gt;fit&lt;/code&gt; メソッドで\（n \）コンポーネントを学習する&lt;em&gt;トランスフォーマー&lt;/em&gt;オブジェクトとして実装され、新しいデータでこれらのコンポーネントに投影するために使用できます。</target>
        </trans-unit>
        <trans-unit id="a8428e4319c22658665567a92df72d0be42ed589" translate="yes" xml:space="preserve">
          <source>PCA, on the other hand, finds orthogonal directions in the raw feature space that correspond to directions accounting for maximum variance.</source>
          <target state="translated">一方、PCAは、最大分散を占める方向に対応する生の特徴空間の直交方向を見つけます。</target>
        </trans-unit>
        <trans-unit id="daf6b41a17ad64437397807edf4249f5c767d4f8" translate="yes" xml:space="preserve">
          <source>PDF documentation</source>
          <target state="translated">PDFドキュメント</target>
        </trans-unit>
        <trans-unit id="83a2c673c060675dd48fb711d1c30c7deadadba5" translate="yes" xml:space="preserve">
          <source>PDPs with two target features show the interactions among the two features. For example, the two-variable PDP in the above Figure shows the dependence of median house price on joint values of house age and avg. occupants per household. We can clearly see an interaction between the two features: For an avg. occupancy greater than two, the house price is nearly independent of the house age, whereas for values less than two there is a strong dependence on age.</source>
          <target state="translated">2つの対象特徴を持つPDPは,2つの特徴間の相互作用を示している。例えば,上図の2変数PDPは,住宅価格の中央値の築年数と世帯あたりの平均居住者数の共同値への依存性を示しています。この2つの特徴の間には,明らかに相互作用が見てとれる。世帯当たりの平均入居者数が2以上の場合,住宅価格は築年数にほぼ依存しないのに対し,2未満の場合は築年数への強い依存性が見られる。</target>
        </trans-unit>
        <trans-unit id="818b23313a5fe3e3ead33eeac95b3f83aefbbeb6" translate="yes" xml:space="preserve">
          <source>PLS regression</source>
          <target state="translated">PLS回帰</target>
        </trans-unit>
        <trans-unit id="256d47be93e9a1da4b73eeee064926026bfad0da" translate="yes" xml:space="preserve">
          <source>PLSCanonical implements the 2 blocks canonical PLS of the original Wold algorithm [Tenenhaus 1998] p.204, referred as PLS-C2A in [Wegelin 2000].</source>
          <target state="translated">PLSCanonical は、オリジナルの Wold アルゴリズム [Tenenhaus 1998]p.204 の 2 ブロック正準 PLS を実装したもので、 [Wegelin 2000]では PLS-C2A と呼ばれています。</target>
        </trans-unit>
        <trans-unit id="cbfe13649cb0f1ff547f98c2537765f522c1604e" translate="yes" xml:space="preserve">
          <source>PLSRegression implements the PLS 2 blocks regression known as PLS2 or PLS1 in case of one dimensional response. This class inherits from _PLS with mode=&amp;rdquo;A&amp;rdquo;, deflation_mode=&amp;rdquo;regression&amp;rdquo;, norm_y_weights=False and algorithm=&amp;rdquo;nipals&amp;rdquo;.</source>
          <target state="translated">PLSRegressionは、1次元応答の場合にPLS2またはPLS1と呼ばれるPLS 2ブロック回帰を実装します。このクラスは、mode =&amp;rdquo; A&amp;rdquo;、deflation_mode =&amp;rdquo; regression&amp;rdquo;、norm_y_weights = Falseおよびalgorithm =&amp;rdquo; nipals&amp;rdquo;の_PLSから継承します。</target>
        </trans-unit>
        <trans-unit id="5bd004de10b3be3d62af4c772e0a783e4c8d0cf7" translate="yes" xml:space="preserve">
          <source>PTRATIO pupil-teacher ratio by town</source>
          <target state="translated">PTRATIO 町の生徒数と教師数の比率</target>
        </trans-unit>
        <trans-unit id="41c1bb8d3d0929f28ded963b3c507fc9ad31e847" translate="yes" xml:space="preserve">
          <source>Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions, Statistics and Probability Letters, 33 (1997) 291-297</source>
          <target state="translated">Pace,R.Kelley and Ronald Barry,Sparse Spatial Autoregressions,Statistics and Probability Letters,33 (1997)291-297</target>
        </trans-unit>
        <trans-unit id="839107cb8051c220f3fa3546dd66b100d0cfaf46" translate="yes" xml:space="preserve">
          <source>Pairwise Euclidean distances between points in the dataset.</source>
          <target state="translated">データセット内の点間のユークリッド距離を対にしたもの.</target>
        </trans-unit>
        <trans-unit id="91ced6bbdf313e062ca8a5307f468c6f86bd6aab" translate="yes" xml:space="preserve">
          <source>Pairwise dissimilarities between the points. Must be symmetric.</source>
          <target state="translated">点の間のペアワイズ的な非類似性。対称的でなければならない。</target>
        </trans-unit>
        <trans-unit id="d8020c04569a536923cc79cf93520b90edece8e9" translate="yes" xml:space="preserve">
          <source>Pairwise metrics</source>
          <target state="translated">ペアワイズ・メトリクス</target>
        </trans-unit>
        <trans-unit id="0f7f7966f9f80e85baa6445a47b9d7c8941de99f" translate="yes" xml:space="preserve">
          <source>Parameter &lt;code&gt;nu&lt;/code&gt; in &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt;&lt;code&gt;NuSVC&lt;/code&gt;&lt;/a&gt;/&lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;OneClassSVM&lt;/code&gt;&lt;/a&gt;/&lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt;&lt;code&gt;NuSVR&lt;/code&gt;&lt;/a&gt; approximates the fraction of training errors and support vectors.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt; &lt;code&gt;NuSVC&lt;/code&gt; &lt;/a&gt; / &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;OneClassSVM&lt;/code&gt; &lt;/a&gt; / &lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt; &lt;code&gt;NuSVR&lt;/code&gt; の&lt;/a&gt;パラメーター &lt;code&gt;nu&lt;/code&gt; は、トレーニングエラーの割合とサポートベクトルを近似します。</target>
        </trans-unit>
        <trans-unit id="539d705b4d5ce5e51b178019bd7f151f362e066d" translate="yes" xml:space="preserve">
          <source>Parameter controlling the inhomogenity of the kernel. If sigma_0=0, the kernel is homogenous.</source>
          <target state="translated">カーネルの非均質性を制御するパラメータ。sigma_0=0の場合、カーネルは均質である。</target>
        </trans-unit>
        <trans-unit id="2462327ecfe7c5d6548ffb2d6d2c9cd234dbc30c" translate="yes" xml:space="preserve">
          <source>Parameter controlling the noise level</source>
          <target state="translated">ノイズレベルを制御するパラメータ</target>
        </trans-unit>
        <trans-unit id="4958bb8c16cafb2697226165d2c132d7ac8dc77e" translate="yes" xml:space="preserve">
          <source>Parameter estimation using grid search with cross-validation</source>
          <target state="translated">クロスバリデーションを用いたグリッド探索を用いたパラメータ推定</target>
        </trans-unit>
        <trans-unit id="c2428812e57708220766f99c6be2b35f70d17ffd" translate="yes" xml:space="preserve">
          <source>Parameter for knn kernel</source>
          <target state="translated">KNNカーネルのパラメータ</target>
        </trans-unit>
        <trans-unit id="1fe064660ce73ee246b908fe6ec0781ebb1b98a2" translate="yes" xml:space="preserve">
          <source>Parameter for rbf kernel</source>
          <target state="translated">rbfカーネルのパラメータ</target>
        </trans-unit>
        <trans-unit id="79b884107bc3e783bfcd688080df4a673a9117bc" translate="yes" xml:space="preserve">
          <source>Parameter for the Minkowski metric from &lt;code&gt;sklearn.metrics.pairwise.pairwise_distances&lt;/code&gt;. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</source>
          <target state="translated">&lt;code&gt;sklearn.metrics.pairwise.pairwise_distances&lt;/code&gt; からのMinkowskiメトリックのパラメーター。p = 1の場合、これはmanhattan_distance（l1）を使用することと同等であり、p = 2の場合はeuclidean_distance（l2）を使用します。任意のpの場合、minkowski_distance（l_p）が使用されます。</target>
        </trans-unit>
        <trans-unit id="2987673c5e2227c54e84a4c36c70d874959de513" translate="yes" xml:space="preserve">
          <source>Parameter for the Minkowski metric from sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</source>
          <target state="translated">sklearn.metrics.pairwise.pairwise_distancesのミンコフスキーメトリックのパラメータ。p=1の場合はmanhattan_distance (l1)、p=2の場合はeuclidean_distance (l2)を使うのと同じです。任意のpについては、minkowski_distance (l_p)が用いられる。</target>
        </trans-unit>
        <trans-unit id="76b1a424a6610c92a4ff7dfc12b9deaa7fadd9d4" translate="yes" xml:space="preserve">
          <source>Parameter gamma of the pairwise kernel specified by metric</source>
          <target state="translated">メトリックで指定されたペアワイズカーネルのパラメータガンマ</target>
        </trans-unit>
        <trans-unit id="5f182d859d9049c92f489a6a5f8f861f198a0672" translate="yes" xml:space="preserve">
          <source>Parameter names mapped to their values.</source>
          <target state="translated">パラメータ名を値にマッピングしたものです。</target>
        </trans-unit>
        <trans-unit id="6c7eaceb91dd3f01e9a6c5c6273381eb8837898b" translate="yes" xml:space="preserve">
          <source>Parameter of RBF kernel: exp(-gamma * x^2)</source>
          <target state="translated">RBFカーネルのパラメータ:exp(-gamma*x^2)</target>
        </trans-unit>
        <trans-unit id="0a55d1c3b23ce41ff45285111de0d234bf72191c" translate="yes" xml:space="preserve">
          <source>Parameter of the corresponding mode.</source>
          <target state="translated">対応するモードのパラメータ。</target>
        </trans-unit>
        <trans-unit id="bd306dfafa0f09eb6ebeeb4165e12648835ffbc7" translate="yes" xml:space="preserve">
          <source>Parameter setting that gave the best results on the hold out data.</source>
          <target state="translated">ホールドアウトデータで最も良い結果が得られたパラメータ設定</target>
        </trans-unit>
        <trans-unit id="feb33995ff27df7648c2862697f9ab2d916fc6ad" translate="yes" xml:space="preserve">
          <source>Parameter to control the quality of the embedding according to the Johnson-Lindenstrauss lemma when n_components is set to &amp;lsquo;auto&amp;rsquo;.</source>
          <target state="translated">n_componentsが 'auto'に設定されている場合、Johnson-Lindenstrauss補題に従って埋め込みの品質を制御するパラメーター。</target>
        </trans-unit>
        <trans-unit id="9ebea54f905d700d979affa38d92638bb2ef6e53" translate="yes" xml:space="preserve">
          <source>Parameter tuning using grid search</source>
          <target state="translated">グリッドサーチを用いたパラメータ調整</target>
        </trans-unit>
        <trans-unit id="025546b75e4d071d18ff381aef96422930bc33e9" translate="yes" xml:space="preserve">
          <source>Parameter vector (W in the cost function formula). If a 1D y is passed in at fit (non multi-task usage), &lt;code&gt;coef_&lt;/code&gt; is then a 1D array. Note that &lt;code&gt;coef_&lt;/code&gt; stores the transpose of &lt;code&gt;W&lt;/code&gt;, &lt;code&gt;W.T&lt;/code&gt;.</source>
          <target state="translated">パラメータベクトル（コスト関数式のW）。1D yがフィットで渡される場合（マルチタスク以外の使用法）、 &lt;code&gt;coef_&lt;/code&gt; は1D配列になります。 &lt;code&gt;coef_&lt;/code&gt; は &lt;code&gt;W&lt;/code&gt; 、 &lt;code&gt;W.T&lt;/code&gt; 転置を格納することに注意してください。</target>
        </trans-unit>
        <trans-unit id="fe2cd82aa0b85722f1fb3f2651910fd5a1cb8bc3" translate="yes" xml:space="preserve">
          <source>Parameter vector (W in the cost function formula). Note that &lt;code&gt;coef_&lt;/code&gt; stores the transpose of &lt;code&gt;W&lt;/code&gt;, &lt;code&gt;W.T&lt;/code&gt;.</source>
          <target state="translated">パラメータベクトル（コスト関数式のW）。 &lt;code&gt;coef_&lt;/code&gt; は &lt;code&gt;W&lt;/code&gt; 、 &lt;code&gt;W.T&lt;/code&gt; 転置を格納することに注意してください。</target>
        </trans-unit>
        <trans-unit id="40a18e293fedd48b8399b301e107b7d0fd89c55d" translate="yes" xml:space="preserve">
          <source>Parameter vector (w in the cost function formula),</source>
          <target state="translated">パラメータベクトル(コスト関数式ではw)。</target>
        </trans-unit>
        <trans-unit id="f2cc602f72e28952a1109943af93a6b27340c9a5" translate="yes" xml:space="preserve">
          <source>Parameter vector (w in the formulation formula).</source>
          <target state="translated">パラメータベクトル(式中のw)。</target>
        </trans-unit>
        <trans-unit id="b98d4ebc4de7e076498469fbea1e480d774d01d2" translate="yes" xml:space="preserve">
          <source>Parameter vector (w in the problem formulation).</source>
          <target state="translated">パラメータベクトル(問題の定式化ではw)。</target>
        </trans-unit>
        <trans-unit id="a975eea30db9fa05003e3b5097688bd49ec7e01b" translate="yes" xml:space="preserve">
          <source>Parameters</source>
          <target state="translated">Parameters</target>
        </trans-unit>
        <trans-unit id="561ad54783e422872a1f3fe4a9c36ebd61273494" translate="yes" xml:space="preserve">
          <source>Parameters (keyword arguments) and values for kernel passed as callable object. Ignored by other kernels.</source>
          <target state="translated">呼び出し可能なオブジェクトとして渡されるカーネルのパラメータ (キーワード引数)と値。他のカーネルでは無視されます。</target>
        </trans-unit>
        <trans-unit id="89febd358321017f18d670418f2852c0de1ee9c6" translate="yes" xml:space="preserve">
          <source>Parameters of the estimators in the pipeline can be accessed using the &lt;code&gt;&amp;lt;estimator&amp;gt;__&amp;lt;parameter&amp;gt;&lt;/code&gt; syntax:</source>
          <target state="translated">パイプライン内の推定量のパラメーターには、 &lt;code&gt;&amp;lt;estimator&amp;gt;__&amp;lt;parameter&amp;gt;&lt;/code&gt; 構文を使用してアクセスできます。</target>
        </trans-unit>
        <trans-unit id="da0d463840d0f1c86c777dbae23f9ad6731982e6" translate="yes" xml:space="preserve">
          <source>Parameters of the transformers may be set using its name and the parameter name separated by a &amp;lsquo;__&amp;rsquo;. A transformer may be replaced entirely by setting the parameter with its name to another transformer, or removed by setting to &amp;lsquo;drop&amp;rsquo; or &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">トランスフォーマーのパラメーターは、その名前と「__」で区切られたパラメーター名を使用して設定できます。トランスフォーマーは、その名前のパラメーターを別のトランスフォーマーに設定することで完全に置き換えるか、または「drop」または &lt;code&gt;None&lt;/code&gt; に設定することで削除できます。</target>
        </trans-unit>
        <trans-unit id="b076b9abb4a3e4211d375c7fba667486c4754cb9" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;fit&lt;/code&gt; method of each step, where each parameter name is prefixed such that parameter &lt;code&gt;p&lt;/code&gt; for step &lt;code&gt;s&lt;/code&gt; has key &lt;code&gt;s__p&lt;/code&gt;.</source>
          <target state="translated">各ステップの &lt;code&gt;fit&lt;/code&gt; メソッドに渡されるパラメーター。各パラメーター名には、ステップ &lt;code&gt;s&lt;/code&gt; のパラメーター &lt;code&gt;p&lt;/code&gt; がキー &lt;code&gt;s__p&lt;/code&gt; を持つようにプレフィックスが付けられます。</target>
        </trans-unit>
        <trans-unit id="1ab85e076de8886205c489db8ed7843daa19517c" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;fit&lt;/code&gt; method of the estimator</source>
          <target state="translated">推定器の &lt;code&gt;fit&lt;/code&gt; メソッドに渡されるパラメーター</target>
        </trans-unit>
        <trans-unit id="0e8067debf1488481c61a1eaa4a0a76867521e4f" translate="yes" xml:space="preserve">
          <source>Parameters to be set on estimator for this grid point.</source>
          <target state="translated">この格子点の推定器に設定するパラメータ。</target>
        </trans-unit>
        <trans-unit id="191e3e986e6964fefdb746bdbd32d026ac54732c" translate="yes" xml:space="preserve">
          <source>Parameters to pass to the fit method of the estimator.</source>
          <target state="translated">推定子のはめ込み方式に渡すパラメータ。</target>
        </trans-unit>
        <trans-unit id="80e379dd51d34ce2dbedd57a975596631a95d883" translate="yes" xml:space="preserve">
          <source>Parameters to pass to the fit method.</source>
          <target state="translated">はめ込み方式に渡すパラ メーター。</target>
        </trans-unit>
        <trans-unit id="36ccb38b123600d9fbc78ab0cd9b6b307a008e1c" translate="yes" xml:space="preserve">
          <source>Parameters to the &lt;code&gt;predict&lt;/code&gt; called at the end of all transformations in the pipeline. Note that while this may be used to return uncertainties from some models with return_std or return_cov, uncertainties that are generated by the transformations in the pipeline are not propagated to the final estimator.</source>
          <target state="translated">パイプライン内のすべての変換の最後に呼び出される &lt;code&gt;predict&lt;/code&gt; パラメーター。これは、return_stdまたはreturn_covを使用する一部のモデルから不確実性を返すために使用される場合がありますが、パイプラインの変換によって生成された不確実性は、最終的な推定器に伝播されないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="381c775599d6e4185d4410725809e360928357cd" translate="yes" xml:space="preserve">
          <source>Parameters:</source>
          <target state="translated">Parameters:</target>
        </trans-unit>
        <trans-unit id="99be92c9a2dedb3674880d6acb8f2dcdcbd96ff3" translate="yes" xml:space="preserve">
          <source>Parsing a text based source can be expensive. When working on repeatedly on the same dataset, it is recommended to wrap this loader with joblib.Memory.cache to store a memmapped backup of the CSR results of the first call and benefit from the near instantaneous loading of memmapped structures for the subsequent calls.</source>
          <target state="translated">テキストベースのソースを解析するのはコストがかかります。同じデータセットで繰り返し作業する場合、最初の呼び出しのCSR結果のメモマップされたバックアップを保存するために、このローダーをjoblib.Memory.cacheでラップし、その後の呼び出しのためにメモマップされた構造体をほぼ瞬時にロードすることをお勧めします。</target>
        </trans-unit>
        <trans-unit id="f8d5f258416422c57466cd67cc8a02c6b05a80fd" translate="yes" xml:space="preserve">
          <source>Partial Dependence Plots</source>
          <target state="translated">部分依存性プロット</target>
        </trans-unit>
        <trans-unit id="e9c89f964f1a01a36b42f3fe4848b74ccc63e0e6" translate="yes" xml:space="preserve">
          <source>Partial Least Square SVD</source>
          <target state="translated">部分最小二乗SVD</target>
        </trans-unit>
        <trans-unit id="93cbd804a6e8e51bf70182f90134157ea23f1138" translate="yes" xml:space="preserve">
          <source>Partial dependence of &lt;code&gt;target_variables&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;target_variables&lt;/code&gt; の部分的な依存関係。</target>
        </trans-unit>
        <trans-unit id="8a65d01c56b56d7e6904a157392f75eb71dc3b44" translate="yes" xml:space="preserve">
          <source>Partial dependence plots (PDP) show the dependence between the target response and a set of &amp;lsquo;target&amp;rsquo; features, marginalizing over the values of all other features (the &amp;lsquo;complement&amp;rsquo; features). Intuitively, we can interpret the partial dependence as the expected target response &lt;a href=&quot;#id23&quot; id=&quot;id21&quot;&gt;[1]&lt;/a&gt; as a function of the &amp;lsquo;target&amp;rsquo; features &lt;a href=&quot;#id24&quot; id=&quot;id22&quot;&gt;[2]&lt;/a&gt;.</source>
          <target state="translated">部分依存プロット（PDP）は、ターゲット応答と「ターゲット」機能のセットとの間の依存関係を示し、他のすべての機能（「補数」機能）の値を取り除きます。直感的に、部分的な依存関係は、予想されるターゲット応答&lt;a href=&quot;#id23&quot; id=&quot;id21&quot;&gt;[1]&lt;/a&gt;として、「ターゲット」機能&lt;a href=&quot;#id24&quot; id=&quot;id22&quot;&gt;[2]の&lt;/a&gt;関数として解釈できます。</target>
        </trans-unit>
        <trans-unit id="9fe71a24f95abe640c27c0bbf2214ad816fa5b2e" translate="yes" xml:space="preserve">
          <source>Partial dependence plots for &lt;code&gt;features&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;features&lt;/code&gt; 部分依存プロット。</target>
        </trans-unit>
        <trans-unit id="652e656223f58b0f5fc37309adb1b1ac47d155cf" translate="yes" xml:space="preserve">
          <source>Partial dependence plots for tree ensembles.</source>
          <target state="translated">木のアンサンブルの部分依存性プロット。</target>
        </trans-unit>
        <trans-unit id="c1a7be74107eb23fd9bfcd8698a88bc718aa4772" translate="yes" xml:space="preserve">
          <source>Partial dependence plots show the dependence between the joint values of the &lt;code&gt;target_variables&lt;/code&gt; and the function represented by the &lt;code&gt;gbrt&lt;/code&gt;.</source>
          <target state="translated">部分的に依存プロットは、関節の値の間の依存性を示し &lt;code&gt;target_variables&lt;/code&gt; で表される関数 &lt;code&gt;gbrt&lt;/code&gt; を。</target>
        </trans-unit>
        <trans-unit id="04afc172d4359535322f4eeb08a601341437662b" translate="yes" xml:space="preserve">
          <source>Partial dependence plots show the dependence between the target function &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt; and a set of &amp;lsquo;target&amp;rsquo; features, marginalizing over the values of all other features (the complement features). Due to the limits of human perception the size of the target feature set must be small (usually, one or two) thus the target features are usually chosen among the most important features (see &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor.feature_importances_&quot;&gt;&lt;code&gt;feature_importances_&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">部分依存プロットは、ターゲット関数&lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt;と「ターゲット」フィーチャのセット間の依存関係を示し、他のすべてのフィーチャ（補数フィーチャ）の値を取り除きます。人間の知覚の制限により、ターゲットフィーチャセットのサイズは小さくなければならず（通常、1つまたは2つ）、ターゲットフィーチャは通常、最も重要なフィーチャから選択されます（&lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor.feature_importances_&quot;&gt; &lt;code&gt;feature_importances_&lt;/code&gt; を&lt;/a&gt;参照）。</target>
        </trans-unit>
        <trans-unit id="27028d4e93727066aec3e2e83aa74954e7719a8b" translate="yes" xml:space="preserve">
          <source>Partial dependence plots with two target features enable us to visualize interactions among them. The two-way partial dependence plot shows the dependence of median house price on joint values of house age and avg. occupants per household. We can clearly see an interaction between the two features: For an avg. occupancy greater than two, the house price is nearly independent of the house age, whereas for values less than two there is a strong dependence on age.</source>
          <target state="translated">世帯あたりの平均居住者数は,住宅価格の中央値と世帯あたりの平均居住者数との間の相互作用を可視化することができる。このグラフは,住宅価格の中央値の築年数と世帯あたりの平均居住者数の共同値に対する依存性を示している。世帯当たりの平均入居者数が多いほど,住宅価格は上昇する。世帯当たりの平均入居者数が2人以上の場合,住宅価格は年齢とほぼ独立しているのに対し,2人未満の場合は年齢への強い依存性が見られる。</target>
        </trans-unit>
        <trans-unit id="6e99bc5cb78022b1555bc70fa32795dba1ae5f4f" translate="yes" xml:space="preserve">
          <source>Partially fit underlying estimators</source>
          <target state="translated">基礎となる推定量を部分的に適合させる</target>
        </trans-unit>
        <trans-unit id="0a5bfb5dfddbf187589aac0e6c6f726ea3a56e0f" translate="yes" xml:space="preserve">
          <source>Particularly in high-dimensional spaces, data can more easily be separated linearly and the simplicity of classifiers such as naive Bayes and linear SVMs might lead to better generalization than is achieved by other classifiers.</source>
          <target state="translated">特に高次元空間では、データをより簡単に線形に分離することができ、ナイーブベイズや線形SVMのような分類器のシンプルさは、他の分類器で達成されるよりも優れた一般化につながるかもしれません。</target>
        </trans-unit>
        <trans-unit id="ee5c2f652fa0ba7331b6add7547b0b3f663aedd3" translate="yes" xml:space="preserve">
          <source>Partitions rows and columns under the assumption that the data has an underlying checkerboard structure. For instance, if there are two row partitions and three column partitions, each row will belong to three biclusters, and each column will belong to two biclusters. The outer product of the corresponding row and column label vectors gives this checkerboard structure.</source>
          <target state="translated">データが市松模様の構造を持つと仮定して、行と列を分割します。例えば、2つの行の分割と3つの列の分割がある場合、各行は3つのバイクラスタに属し、各列は2つのバイクラスタに属します。対応する行と列のラベルベクトルの外積が、このチェッカーボード構造を与えます。</target>
        </trans-unit>
        <trans-unit id="d9f564dc265e98a01f24f70d1576b62ca3b43bd3" translate="yes" xml:space="preserve">
          <source>Passing a 2D matrix for multilabel classification</source>
          <target state="translated">マルチラベル分類のための2次元行列を渡す</target>
        </trans-unit>
        <trans-unit id="144adab066cd5c92a6778f61a4778ef74c72b2a0" translate="yes" xml:space="preserve">
          <source>Passive Aggressive Classifier</source>
          <target state="translated">受動的攻撃的分類器</target>
        </trans-unit>
        <trans-unit id="d61635eec17c853d9d6e1ff234afe50660f92701" translate="yes" xml:space="preserve">
          <source>Passive Aggressive Regressor</source>
          <target state="translated">パッシブアグレッシブリプレッサー</target>
        </trans-unit>
        <trans-unit id="291afa1da61effaacff4bf3e40a8045b9b8d343b" translate="yes" xml:space="preserve">
          <source>Patches are assumed to overlap and the image is constructed by filling in the patches from left to right, top to bottom, averaging the overlapping regions.</source>
          <target state="translated">パッチは重なっていると仮定して、左から右、上から下にパッチを埋め、重なっている領域を平均化することで画像を構築します。</target>
        </trans-unit>
        <trans-unit id="18a1699e2836ba2addd008ee2015c4e0ca5931f6" translate="yes" xml:space="preserve">
          <source>Path to the main folder holding one subfolder per category</source>
          <target state="translated">カテゴリごとに1つのサブフォルダを保持するメインフォルダへのパス</target>
        </trans-unit>
        <trans-unit id="98ee95181d901b366d1fe1c0df5a309cc7a3de65" translate="yes" xml:space="preserve">
          <source>Penalization parameter selected.</source>
          <target state="translated">ペナルティパラメータを選択しました。</target>
        </trans-unit>
        <trans-unit id="3bbf431b41c522bd1eb1b65ea50fc21584275d87" translate="yes" xml:space="preserve">
          <source>Penalize the intercept (bad) yes no no no no Faster for large datasets no no no yes yes Robust to unscaled datasets yes yes yes no no ============================ =========== ======= =========== ===== ======</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64a00002571bc14aac9e57cf087ec95ea0663632" translate="yes" xml:space="preserve">
          <source>Penalty parameter C of the error term.</source>
          <target state="translated">誤差項のペナルティパラメータC。</target>
        </trans-unit>
        <trans-unit id="78e16aaecb446c766536c888cb2ab681d45d227a" translate="yes" xml:space="preserve">
          <source>Penalty parameter C of the error term. The penalty is a squared l2 penalty. The bigger this parameter, the less regularization is used.</source>
          <target state="translated">誤差項のペナルティパラメータC。ペナルティはl2の2乗のペナルティです。このパラメータが大きいほど、正則化の使用量が少なくなります。</target>
        </trans-unit>
        <trans-unit id="f4b4203fc28ce6d3a674721e39c00d5f8047107a" translate="yes" xml:space="preserve">
          <source>Per default, the &amp;lsquo;fmin_l_bfgs_b&amp;rsquo; algorithm from scipy.optimize is used. If None is passed, the kernel&amp;rsquo;s parameters are kept fixed. Available internal optimizers are:</source>
          <target state="translated">デフォルトでは、scipy.optimizeの「fmin_l_bfgs_b」アルゴリズムが使用されます。Noneが渡されると、カーネルのパラメータは固定されたままになります。利用可能な内部オプティマイザは次のとおりです。</target>
        </trans-unit>
        <trans-unit id="6244b7856d25c3c666d36fccf077f85fa1982ad7" translate="yes" xml:space="preserve">
          <source>Per feature adjustment for minimum.</source>
          <target state="translated">最小限の機能ごとに調整します。</target>
        </trans-unit>
        <trans-unit id="d1fcc9536b36965b70f539451057ec6f4f433503" translate="yes" xml:space="preserve">
          <source>Per feature maximum absolute value.</source>
          <target state="translated">フィーチャーごとの最大絶対値。</target>
        </trans-unit>
        <trans-unit id="c5e7199d590adbeaea5c7d5a6fd8bd4755090a1c" translate="yes" xml:space="preserve">
          <source>Per feature maximum seen in the data</source>
          <target state="translated">データで見た特徴の最大値あたり</target>
        </trans-unit>
        <trans-unit id="102581d144872704eb291cec69ea6b75f7b2f4ae" translate="yes" xml:space="preserve">
          <source>Per feature minimum seen in the data</source>
          <target state="translated">データに見られる最小の特徴あたり</target>
        </trans-unit>
        <trans-unit id="9af0de5bb3d05f02ad6ecd6ef96e244722359bc9" translate="yes" xml:space="preserve">
          <source>Per feature range &lt;code&gt;(data_max_ - data_min_)&lt;/code&gt; seen in the data</source>
          <target state="translated">データ内で見られるフィーチャ範囲ごと &lt;code&gt;(data_max_ - data_min_)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3041c95c2bc4cf499751cc15dcfa6079b79d0c01" translate="yes" xml:space="preserve">
          <source>Per feature relative scaling of the data.</source>
          <target state="translated">フィーチャーごとにデータの相対的なスケーリングを行います。</target>
        </trans-unit>
        <trans-unit id="2aca96873ba30a1f44a2ea13c9cca023c862496e" translate="yes" xml:space="preserve">
          <source>Per feature relative scaling of the data. Equal to &lt;code&gt;None&lt;/code&gt; when &lt;code&gt;with_std=False&lt;/code&gt;.</source>
          <target state="translated">データのフィーチャごとの相対的なスケーリング。 &lt;code&gt;with_std=False&lt;/code&gt; の場合は &lt;code&gt;None&lt;/code&gt; と同じです。</target>
        </trans-unit>
        <trans-unit id="03c5a380bfcbdfa271df31ac8e5033140b3c462f" translate="yes" xml:space="preserve">
          <source>Per-feature empirical mean, aggregate over calls to &lt;code&gt;partial_fit&lt;/code&gt;.</source>
          <target state="translated">機能ごとの経験的平均 &lt;code&gt;partial_fit&lt;/code&gt; 呼び出しを集計します。</target>
        </trans-unit>
        <trans-unit id="9b69855eee3f3bb7b79cdf586195cf71da93449f" translate="yes" xml:space="preserve">
          <source>Per-feature empirical mean, estimated from the training set.</source>
          <target state="translated">訓練セットから推定された特徴毎の経験的平均。</target>
        </trans-unit>
        <trans-unit id="78b2f336c949583f3bdffdc9a030b0f9e6170c47" translate="yes" xml:space="preserve">
          <source>Per-feature empirical mean, estimated from the training set. Equal to &lt;code&gt;X.mean(axis=0)&lt;/code&gt;.</source>
          <target state="translated">トレーニングセットから推定された、機能ごとの経験的平均。 &lt;code&gt;X.mean(axis=0)&lt;/code&gt; と同じです。</target>
        </trans-unit>
        <trans-unit id="a8c85c36120ad4d7e0ffc8553bf9d9bb4f653d40" translate="yes" xml:space="preserve">
          <source>Per-feature empirical variance, aggregate over calls to &lt;code&gt;partial_fit&lt;/code&gt;.</source>
          <target state="translated">機能ごとの経験的分散、 &lt;code&gt;partial_fit&lt;/code&gt; の呼び出しの集計。</target>
        </trans-unit>
        <trans-unit id="bb6e9ff3187e622eed5823426c5d8cc8b9a5e66d" translate="yes" xml:space="preserve">
          <source>Per-sample weights. Rescale C per sample. Higher weights force the classifier to put more emphasis on these points.</source>
          <target state="translated">サンプルごとの重み。サンプルごとにCのスケールを変更します.より高い重みは,分類器がこれらの点をより強調することを強制します.</target>
        </trans-unit>
        <trans-unit id="022818083764d59bc1c545a8df2dfc49cf87ec2a" translate="yes" xml:space="preserve">
          <source>Per-topic word distributions are independently drawn, where in reality all would be affected by a sparse base distribution, and would be correlated.</source>
          <target state="translated">トピックごとの単語分布は独立して描かれていますが、実際にはすべての単語は疎な基底分布の影響を受け、相関関係にあるでしょう。</target>
        </trans-unit>
        <trans-unit id="508100893e29e053d40024965b139e71658b7b80" translate="yes" xml:space="preserve">
          <source>Percent of features to keep.</source>
          <target state="translated">残すべき機能の割合。</target>
        </trans-unit>
        <trans-unit id="510c90c1028713db83438ed3b7d7b97622c046bb" translate="yes" xml:space="preserve">
          <source>Percentage of the number of classes to be used to create the code book. A number between 0 and 1 will require fewer classifiers than one-vs-the-rest. A number greater than 1 will require more classifiers than one-vs-the-rest.</source>
          <target state="translated">コードブックの作成に使用するクラスの数の割合。0から1の間の数値は、1対1よりも少ない分類子を必要とします。1よりも大きい数値は、1対1よりも多くの分類子を必要とします。</target>
        </trans-unit>
        <trans-unit id="ab474311418f716aa90a18ba4aac10d5e0126b01" translate="yes" xml:space="preserve">
          <source>Percentage of variance explained by each of the selected components.</source>
          <target state="translated">選択された各成分によって説明された分散の割合。</target>
        </trans-unit>
        <trans-unit id="6b606c4b3521608268acaf8a83daf1d705edec66" translate="yes" xml:space="preserve">
          <source>Percentage of variance explained by each of the selected components. If &lt;code&gt;n_components&lt;/code&gt; is not set then all components are stored and the sum of explained variances is equal to 1.0. Only available when eigen or svd solver is used.</source>
          <target state="translated">選択した各コンポーネントによって説明される分散のパーセンテージ。 &lt;code&gt;n_components&lt;/code&gt; が設定されていない場合、すべてのコンポーネントが格納され、説明された分散の合計は1.0になります。固有値またはsvdソルバーが使用されている場合にのみ使用できます。</target>
        </trans-unit>
        <trans-unit id="d93d3d6b53ae20e2e020e6bfd5f07bc4328ff552" translate="yes" xml:space="preserve">
          <source>Percentage of variance explained by each of the selected components. If all components are stored, the sum of explained variances is equal to 1.0.</source>
          <target state="translated">選択された成分のそれぞれによって説明された分散の割合。すべての成分が格納されている場合、説明された分散の合計は1.0に等しい。</target>
        </trans-unit>
        <trans-unit id="5ae537dc31ff6e276137ba1f3f08f14e2d75b135" translate="yes" xml:space="preserve">
          <source>Perfect labeling is scored 1.0:</source>
          <target state="translated">パーフェクトラベリングは1.0点です。</target>
        </trans-unit>
        <trans-unit id="e0246cf8e59488c8ec6f2dd495c80e88ab5e2c38" translate="yes" xml:space="preserve">
          <source>Perfect labelings are both homogeneous and complete, hence have score 1.0:</source>
          <target state="translated">完全なラベリングは均質かつ完全であるため、スコアは1.0です。</target>
        </trans-unit>
        <trans-unit id="0b6e6a15e84a2c0c2b67bd408293381d6bde8086" translate="yes" xml:space="preserve">
          <source>Perfect labelings are complete:</source>
          <target state="translated">完璧なラベリングが完成しました。</target>
        </trans-unit>
        <trans-unit id="c929d898b15ba46b39cbe3a578cc048974dbb0f3" translate="yes" xml:space="preserve">
          <source>Perfect labelings are homogeneous:</source>
          <target state="translated">完璧なラベリングは同質です。</target>
        </trans-unit>
        <trans-unit id="158762f0fcedf70ff27743eef2b9fe2391aaecf5" translate="yes" xml:space="preserve">
          <source>Perfectly matching labelings have a score of 1 even</source>
          <target state="translated">完全に一致するラベリングには、1の偶数のスコアがあります。</target>
        </trans-unit>
        <trans-unit id="689d4751e15d0ca03ac4490cb60697622e5a7435" translate="yes" xml:space="preserve">
          <source>Perform Affinity Propagation Clustering of data</source>
          <target state="translated">データの親和伝播クラスタリングを実行する</target>
        </trans-unit>
        <trans-unit id="dee861689c2a0a2296c4bb43119e58f854cfe756" translate="yes" xml:space="preserve">
          <source>Perform Affinity Propagation Clustering of data.</source>
          <target state="translated">データの親和伝播クラスタリングを実行します。</target>
        </trans-unit>
        <trans-unit id="463c2804b4b2c3d108889b17acd479af4436cc72" translate="yes" xml:space="preserve">
          <source>Perform DBSCAN clustering from features or distance matrix.</source>
          <target state="translated">特徴量や距離行列からDBSCANクラスタリングを実行します。</target>
        </trans-unit>
        <trans-unit id="458d7c0c2b90dff326f89ad767c75f6a1812b730" translate="yes" xml:space="preserve">
          <source>Perform DBSCAN clustering from vector array or distance matrix.</source>
          <target state="translated">ベクトル配列や距離行列からDBSCANクラスタリングを実行します。</target>
        </trans-unit>
        <trans-unit id="959d910f7763a2ffdb63e2da58508fc0266c6120" translate="yes" xml:space="preserve">
          <source>Perform Fast Independent Component Analysis.</source>
          <target state="translated">高速な独立成分分析を実行します。</target>
        </trans-unit>
        <trans-unit id="b44047366aaa6bbf25bda0720c2b9955136f4c83" translate="yes" xml:space="preserve">
          <source>Perform a Locally Linear Embedding analysis on the data.</source>
          <target state="translated">データの局所的な線形埋め込み分析を実行します。</target>
        </trans-unit>
        <trans-unit id="ac1255795fd03e9f556426224dcbfbd70ca25e88" translate="yes" xml:space="preserve">
          <source>Perform a shortest-path graph search on a positive directed or undirected graph.</source>
          <target state="translated">正の有向または無向グラフで最短パスのグラフ探索を行います.</target>
        </trans-unit>
        <trans-unit id="5913acb65bcb3cfc0407c274e6a0ae6c08f54988" translate="yes" xml:space="preserve">
          <source>Perform binary classification using non-linear SVC with RBF kernel. The target to predict is a XOR of the inputs.</source>
          <target state="translated">RBFカーネルを用いた非線形SVCを用いて2値分類を行う。予測対象は入力のXORです。</target>
        </trans-unit>
        <trans-unit id="a259ca5c38306ae844a312467fcf634f7a4c4cb8" translate="yes" xml:space="preserve">
          <source>Perform classification on an array of test vectors X.</source>
          <target state="translated">テストベクトルXの配列で分類を行います.</target>
        </trans-unit>
        <trans-unit id="1af0f015c949bd1c16d805fdf5523bbcd5119678" translate="yes" xml:space="preserve">
          <source>Perform classification on samples in X.</source>
          <target state="translated">Xのサンプルで分類を実行します。</target>
        </trans-unit>
        <trans-unit id="b3b3f491b55f8b579a228793b65f99ca8d0d1a92" translate="yes" xml:space="preserve">
          <source>Perform classification on test vectors X.</source>
          <target state="translated">テストベクトルXで分類を行う。</target>
        </trans-unit>
        <trans-unit id="db94ca6613eef6e933177aeabe20672ae9208bdf" translate="yes" xml:space="preserve">
          <source>Perform clustering.</source>
          <target state="translated">クラスタリングを実行します。</target>
        </trans-unit>
        <trans-unit id="f9f7c30d76f5b933404ebf4eb86819fed33be90a" translate="yes" xml:space="preserve">
          <source>Perform dimensionality reduction on X.</source>
          <target state="translated">Xの次元削減を行う。</target>
        </trans-unit>
        <trans-unit id="6d24d9dcbe2141c7b30ceff371628950cd7ca425" translate="yes" xml:space="preserve">
          <source>Perform is_fitted validation for estimator.</source>
          <target state="translated">推計子の is_fitted 検証を実行します。</target>
        </trans-unit>
        <trans-unit id="28c6ac8c77fceae308f63cb91c2fe135b4f5904f" translate="yes" xml:space="preserve">
          <source>Perform mapping to a normal distribution using a power transform.</source>
          <target state="translated">冪変換を用いて正規分布へのマッピングを行います。</target>
        </trans-unit>
        <trans-unit id="f154e55e13cfe215c964ae2fb4c3f06da46b83fe" translate="yes" xml:space="preserve">
          <source>Perform mean shift clustering of data using a flat kernel.</source>
          <target state="translated">フラットカーネルを使用してデータの平均シフトクラスタリングを実行します。</target>
        </trans-unit>
        <trans-unit id="5d74999037a10ebb61d14a38ac3c1f58c8d3eb1c" translate="yes" xml:space="preserve">
          <source>Perform one Gibbs sampling step.</source>
          <target state="translated">ギブスサンプリングを1回行います。</target>
        </trans-unit>
        <trans-unit id="b97c414705aa3f4f9199ddb08da830ac54e8fe97" translate="yes" xml:space="preserve">
          <source>Perform regression on samples in X.</source>
          <target state="translated">Xのサンプルで回帰を実行します。</target>
        </trans-unit>
        <trans-unit id="dd51e0250263d470cb8a4effc410185e24e99d6f" translate="yes" xml:space="preserve">
          <source>Perform robust standardization that removes the influence of outliers but does not put outliers and inliers on the same scale.</source>
          <target state="translated">外れ値の影響を除去しつつ、外れ値と外れ値を同じ尺度にしないロバストな標準化を行う。</target>
        </trans-unit>
        <trans-unit id="ebef79dfac2e65b8c25ad9bb7fdce83cd9513504" translate="yes" xml:space="preserve">
          <source>Perform standardization by centering and scaling</source>
          <target state="translated">センタリングやスケーリングによる標準化を行う</target>
        </trans-unit>
        <trans-unit id="4bc7fa7479a101fbc87b729f92b16086a341ed9e" translate="yes" xml:space="preserve">
          <source>Perform standardization that is faster, but less robust to outliers.</source>
          <target state="translated">標準化を実行すると、より高速になりますが、外れ値にはあまりロバストではありません。</target>
        </trans-unit>
        <trans-unit id="c8a1451466ddb25587dffc5d4da05875ebb74725" translate="yes" xml:space="preserve">
          <source>Performs a pixel-wise Vector Quantization (VQ) of an image of the summer palace (China), reducing the number of colors required to show the image from 96,615 unique colors to 64, while preserving the overall appearance quality.</source>
          <target state="translated">夏の宮殿(中国)の画像をピクセル単位のベクトル量子化(VQ)を行い、全体の外観品質を維持しながら、画像を表示するために必要な色数を96,615色の固有色から64色に削減します。</target>
        </trans-unit>
        <trans-unit id="7945877a79ee9606b9df91e80330316ac1099e28" translate="yes" xml:space="preserve">
          <source>Performs approximate nearest neighbor search using LSH forest.</source>
          <target state="translated">LSHフォレストを用いて近似最近傍探索を行います。</target>
        </trans-unit>
        <trans-unit id="9bab7093aa44c52b527bcacee82e15ab827f7949" translate="yes" xml:space="preserve">
          <source>Performs binarization using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">&lt;code&gt;Transformer&lt;/code&gt; API を使用して2値化を実行します（たとえば、前処理の一部として&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="9334db1899f0bba94453f1ee6fbd171b507e5ed1" translate="yes" xml:space="preserve">
          <source>Performs centering and scaling using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">&lt;code&gt;Transformer&lt;/code&gt; APIを使用して（たとえば、前処理の一部として&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; として&lt;/a&gt;）センタリングとスケーリングを実行します。</target>
        </trans-unit>
        <trans-unit id="506256c7ae18c8053ecaa6445590a98acf36aa0e" translate="yes" xml:space="preserve">
          <source>Performs clustering on X and returns cluster labels.</source>
          <target state="translated">Xのクラスタリングを実行し、クラスタラベルを返します。</target>
        </trans-unit>
        <trans-unit id="38545772bd4529f41bf4bec322ebc7f80ab61f41" translate="yes" xml:space="preserve">
          <source>Performs inductive inference across the model.</source>
          <target state="translated">モデル間で帰納的推論を実行します。</target>
        </trans-unit>
        <trans-unit id="de7dc9fb5a771d54ea7fadc4d86dd2f8269f14e4" translate="yes" xml:space="preserve">
          <source>Performs normalization using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">&lt;code&gt;Transformer&lt;/code&gt; API を使用して正規化を実行します（たとえば、前処理の一部として&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="72f57dd0021b24f09da3fde633d42235df9baa52" translate="yes" xml:space="preserve">
          <source>Performs outlier detection on X.</source>
          <target state="translated">Xの外れ値検出を実行します。</target>
        </trans-unit>
        <trans-unit id="c032681b9d32a5a7daa554f673be122edd3ede2b" translate="yes" xml:space="preserve">
          <source>Performs power transformation using the &lt;code&gt;Transformer&lt;/code&gt; API (as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">&lt;code&gt;Transformer&lt;/code&gt; API を使用して電源変換を実行します（前処理の&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; の&lt;/a&gt;一部として）。</target>
        </trans-unit>
        <trans-unit id="9b0d235575d753630f72f479dd595fb051616b74" translate="yes" xml:space="preserve">
          <source>Performs quantile-based scaling using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">&lt;code&gt;Transformer&lt;/code&gt; API を使用して、&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt;ベースのスケーリングを実行します（たとえば、前処理sklearn.pipeline.Pipelineの一部として）。</target>
        </trans-unit>
        <trans-unit id="b88ebf81bb1a4e07e575709aa3160fcbaf33439c" translate="yes" xml:space="preserve">
          <source>Performs robust standardization that removes the influence of outliers but does not put outliers and inliers on the same scale.</source>
          <target state="translated">外れ値の影響を除去するロバストな標準化を実行しますが、外れ値と外れ値を同じ尺度に置かないようにします。</target>
        </trans-unit>
        <trans-unit id="269796266e3e34d93d181d30bdc48e574f3c9af7" translate="yes" xml:space="preserve">
          <source>Performs scaling to a given range using the``Transformer`` API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">`` Transformer`` APIを使用して、所定の範囲へのスケーリングを実行します（たとえば、前処理の一部として&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="bd68fa80cce73218da8c0d7af21a3e3a79fd9429" translate="yes" xml:space="preserve">
          <source>Performs scaling to the [-1, 1] range using the``Transformer`` API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">`` Transformer`` APIを使用して[-1、1]範囲へのスケーリングを実行します（たとえば、前処理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; の&lt;/a&gt;一部として）。</target>
        </trans-unit>
        <trans-unit id="a6c272533c048656769d2922baf310f99127bfa0" translate="yes" xml:space="preserve">
          <source>Performs scaling to unit variance using the``Transformer`` API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">`` Transformer`` APIを使用して単位分散へのスケーリングを実行します（たとえば、前処理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; の&lt;/a&gt;一部として）。</target>
        </trans-unit>
        <trans-unit id="ac7c14a68907c3e1c4fe02a23cc6348fd68ae158" translate="yes" xml:space="preserve">
          <source>Performs standardization that is faster, but less robust to outliers.</source>
          <target state="translated">標準化を実行することで、より高速になりますが、外れ値にはあまりロバストではありません。</target>
        </trans-unit>
        <trans-unit id="d1ac21bb0cdcd78e01860cf682da905f50be135c" translate="yes" xml:space="preserve">
          <source>Performs well even if its assumptions are somewhat violated by the true model from which the data were generated.</source>
          <target state="translated">データが生成された真のモデルによってその仮定が多少破られていても、十分な性能を発揮します。</target>
        </trans-unit>
        <trans-unit id="1a9a31609b061b9c4c3ea5164d451f2cf664e34b" translate="yes" xml:space="preserve">
          <source>Perplexity is defined as exp(-1. * log-likelihood per word)</source>
          <target state="translated">錯乱度は exp(-1.*単語あたりの対数尤度)として定義されます。</target>
        </trans-unit>
        <trans-unit id="80863d8aea17a1c5fba5bee33e10fcfe3c3b5254" translate="yes" xml:space="preserve">
          <source>Perplexity score.</source>
          <target state="translated">錯乱のスコア。</target>
        </trans-unit>
        <trans-unit id="25e7450397b385690390d4cb490d54af7bb7f613" translate="yes" xml:space="preserve">
          <source>Perplexity tolerance in batch learning. Only used when &lt;code&gt;evaluate_every&lt;/code&gt; is greater than 0.</source>
          <target state="translated">バッチ学習における複雑さの許容度。 &lt;code&gt;evaluate_every&lt;/code&gt; が0より大きい場合にのみ使用されます。</target>
        </trans-unit>
        <trans-unit id="bed69aed128c6d53c076bf23b1786ba34af67dfd" translate="yes" xml:space="preserve">
          <source>Persistent Contrastive Divergence addresses this. Instead of starting a new chain each time the gradient is needed, and performing only one Gibbs sampling step, in PCD we keep a number of chains (fantasy particles) that are updated \(k\) Gibbs steps after each weight update. This allows the particles to explore the space more thoroughly.</source>
          <target state="translated">Persistent Contrastive Divergenceはこれに対応しています。勾配が必要とされるたびに新しいチェーンを開始し、ギブスサンプリングステップを1回だけ実行する代わりに、PCDでは、各ウェイトの更新後にギブスステップを更新するチェーン(ファンタジーパーティクル)をいくつか保持します。これにより、粒子は空間をより徹底的に探索することができる。</target>
        </trans-unit>
        <trans-unit id="d4d9d12e88278335e6c824e88af73f55a763004e" translate="yes" xml:space="preserve">
          <source>Peter J. Huber, Elvezio M. Ronchetti, Robust Statistics Concomitant scale estimates, pg 172</source>
          <target state="translated">Peter J.Huber,Helvetius M.Ronchetti,Robust Statistics Concomitant scale estimates,pg 172</target>
        </trans-unit>
        <trans-unit id="977cdb0f1102753846469a4e3ab78497c359fae5" translate="yes" xml:space="preserve">
          <source>Peter J. Huber, Elvezio M. Ronchetti: Robust Statistics, Concomitant scale estimates, pg 172</source>
          <target state="translated">Peter J.Huber,Helvetius M.Ronchetti:Robust Statistics,Concomitant scale estimates,pg 172</target>
        </trans-unit>
        <trans-unit id="f869e193262fa2d8e1a9ddde0485aa49aaa656aa" translate="yes" xml:space="preserve">
          <source>Peter J. Rousseeuw (1987). &amp;ldquo;Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis&amp;rdquo;. Computational and Applied Mathematics 20: 53&amp;ndash;65. &lt;a href=&quot;https://doi.org/10.1016/0377-0427(87)90125-7&quot;&gt;doi:10.1016/0377-0427(87)90125-7&lt;/a&gt;.</source>
          <target state="translated">Peter J. Rousseeuw（1987）。「シルエット：クラスター分析の解釈と検証に対するグラフィカル支援」。計算および応用数学20：53&amp;ndash;65。&lt;a href=&quot;https://doi.org/10.1016/0377-0427(87)90125-7&quot;&gt;doi：10.1016 / 0377-0427（87）90125-7&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="801ff1e5ba061302f2ef13b831a12ef30f616d52" translate="yes" xml:space="preserve">
          <source>Peter J. Rousseeuw (1987). &amp;ldquo;Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis&amp;rdquo;. Computational and Applied Mathematics 20: 53-65.</source>
          <target state="translated">Peter J. Rousseeuw（1987）。「シルエット：クラスター分析の解釈と検証に対するグラフィカル支援」。計算および応用数学20：53-65。</target>
        </trans-unit>
        <trans-unit id="6884db0930152b7581421b9e7df37cdc709bc0ae" translate="yes" xml:space="preserve">
          <source>Pickle and Unpickle a tree. Note that the state of the tree is saved in the pickle operation: the tree needs not be rebuilt upon unpickling.</source>
          <target state="translated">ツリーのピックルとアンピックル。ツリーの状態は pickle 操作で保存されることに注意してください。</target>
        </trans-unit>
        <trans-unit id="4a6d28315bc21af0edd71a7862fc9db5f7a4917f" translate="yes" xml:space="preserve">
          <source>Ping Li, T. Hastie and K. W. Church, 2006, &amp;ldquo;Very Sparse Random Projections&amp;rdquo;. &lt;a href=&quot;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&lt;/a&gt;</source>
          <target state="translated">Ping Li、T。HastieおよびKW Church、2006年、「Very Sparse Random Projections」。&lt;a href=&quot;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3462e562173cab76115a1fabd23d03498a615dda" translate="yes" xml:space="preserve">
          <source>Ping Li, Trevor J. Hastie, and Kenneth W. Church. 2006. &lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;Very sparse random projections.&lt;/a&gt; In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD &amp;lsquo;06). ACM, New York, NY, USA, 287-296.</source>
          <target state="translated">Ping Li、Trevor J. Hastie、およびKenneth W. Church。2006. &lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;非常にまばらなランダム投影。&lt;/a&gt;第12回ACM SIGKDD国際会議の議事録で、知識の発見とデータマイニング（KDD '06）。ACM、ニューヨーク、ニューヨーク、アメリカ、287-296。</target>
        </trans-unit>
        <trans-unit id="5fcec2c4630ab50971732249756f691f50ae9f29" translate="yes" xml:space="preserve">
          <source>Pipeline Anova SVM</source>
          <target state="translated">パイプライン Anova SVM</target>
        </trans-unit>
        <trans-unit id="a041187d94eb589a1ba5ff98293ef896e00c97e7" translate="yes" xml:space="preserve">
          <source>Pipeline of transforms with a final estimator.</source>
          <target state="translated">最終推定器を用いた変換のパイプライン。</target>
        </trans-unit>
        <trans-unit id="52761af283a0d9e614a4e2ba9d4a353d3fd70a7b" translate="yes" xml:space="preserve">
          <source>Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors.</source>
          <target state="translated">パイプラインは、トランスフォーマと予測子の訓練に同じサンプルが使用されることを保証することで、クロスバリデーションにおいて、テストデータから訓練されたモデルへの統計量の漏れを防ぐのに役立つ。</target>
        </trans-unit>
        <trans-unit id="3d31223cfe1830200469a76812f595efba107474" translate="yes" xml:space="preserve">
          <source>Pipelining</source>
          <target state="translated">Pipelining</target>
        </trans-unit>
        <trans-unit id="04ae27026f61a0e2fe9396849cac7271f4f56e69" translate="yes" xml:space="preserve">
          <source>Pipelining: chaining a PCA and a logistic regression</source>
          <target state="translated">パイプライン:PCAとロジスティック回帰の連結</target>
        </trans-unit>
        <trans-unit id="4d2bb7a399ca2f416aedb250a1c02b6dbddd98f5" translate="yes" xml:space="preserve">
          <source>Pixel importances with a parallel forest of trees</source>
          <target state="translated">並木の森でのピクセルインポータンス</target>
        </trans-unit>
        <trans-unit id="2ca4493c014c6673344a97eb7b5e5aaa17897b68" translate="yes" xml:space="preserve">
          <source>Platt &lt;a href=&quot;http://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf&quot;&gt;&amp;ldquo;Probabilistic outputs for SVMs and comparisons to regularized likelihood methods&amp;rdquo;&lt;/a&gt;.</source>
          <target state="translated">プラット&lt;a href=&quot;http://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf&quot;&gt;「SVMの確率的出力と正則化された尤度法との比較」&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="0765f4dfcff27a39498ebd734357c5eb178852a5" translate="yes" xml:space="preserve">
          <source>Please note that in this example the data is non-noisy, hence it is possible to extract the exact coefficients.</source>
          <target state="translated">この例では、データが非ノイズであるため、正確な係数を抽出することが可能であることに注意してください。</target>
        </trans-unit>
        <trans-unit id="60f5c599778dc38cb8638a819c878af82379b06d" translate="yes" xml:space="preserve">
          <source>Please note that the dataset here is not large enough to show the benefits of kernel approximation, as the exact SVM is still reasonably fast.</source>
          <target state="translated">ここのデータセットはカーネル近似の利点を示すには十分な大きさではないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="580c520b29a7b706c6ee9312d3a6f880fe113df6" translate="yes" xml:space="preserve">
          <source>Please refer to the &lt;a href=&quot;http://scikit-learn.org/stable/install.html#installation-instructions&quot;&gt;installation instructions&lt;/a&gt; page for more information and for system-specific instructions.</source>
          <target state="translated">詳細およびシステム固有の手順については、&lt;a href=&quot;http://scikit-learn.org/stable/install.html#installation-instructions&quot;&gt;インストール手順の&lt;/a&gt;ページを参照してください。</target>
        </trans-unit>
        <trans-unit id="245a16d516483fde4bb90ded88adcf811c9e2c4f" translate="yes" xml:space="preserve">
          <source>Please see &lt;a href=&quot;#mlp-tips&quot;&gt;Tips on Practical Use&lt;/a&gt; section that addresses some of these disadvantages.</source>
          <target state="translated">これらの不利な点のいくつかに対処&lt;a href=&quot;#mlp-tips&quot;&gt;する「実用上のヒント&lt;/a&gt;」セクションを参照してください。</target>
        </trans-unit>
        <trans-unit id="1c1763d18d05bf3f25645375f32837b8195b549b" translate="yes" xml:space="preserve">
          <source>Please take care in choosing a stop word list. Popular stop word lists may include words that are highly informative to some tasks, such as &lt;em&gt;computer&lt;/em&gt;.</source>
          <target state="translated">ストップワードリストの選択には注意してください。一般的なストップワードリストには、&lt;em&gt;コンピュータ&lt;/em&gt;などの一部のタスクに非常に役立つ単語が含まれている場合があります。</target>
        </trans-unit>
        <trans-unit id="8695c6b10616f55d08370738ac83b62df92988cf" translate="yes" xml:space="preserve">
          <source>Plot Precision-Recall curve for each class and iso-f1 curves</source>
          <target state="translated">各クラスの精度-リコール曲線とiso-f1曲線のプロット</target>
        </trans-unit>
        <trans-unit id="74b5d936c6a7142a9d0455e9b6b736449035ae4d" translate="yes" xml:space="preserve">
          <source>Plot ROC curves for the multiclass problem</source>
          <target state="translated">マルチクラス問題のROC曲線のプロット</target>
        </trans-unit>
        <trans-unit id="2b92ac175dbafedc9ebadfa3064fcc8b95d12013" translate="yes" xml:space="preserve">
          <source>Plot Ridge coefficients as a function of the L2 regularization</source>
          <target state="translated">L2正則化の関数としてのリッジ係数のプロット</target>
        </trans-unit>
        <trans-unit id="2786a51af34001a054f667eea5f5427aa4ac1cf2" translate="yes" xml:space="preserve">
          <source>Plot Ridge coefficients as a function of the regularization</source>
          <target state="translated">正則化の関数としてのリッジ係数のプロット</target>
        </trans-unit>
        <trans-unit id="a465ec1964ec6fb41a10c223b00503371b098b22" translate="yes" xml:space="preserve">
          <source>Plot class probabilities calculated by the VotingClassifier</source>
          <target state="translated">VotingClassifier によって計算されたクラス確率をプロットします.</target>
        </trans-unit>
        <trans-unit id="b43d02980e353a273a01e17df2d13e81e7a80aee" translate="yes" xml:space="preserve">
          <source>Plot classification probability</source>
          <target state="translated">分類確率のプロット</target>
        </trans-unit>
        <trans-unit id="c6389911af4059bed3f7dfa408ce8e7c1791da24" translate="yes" xml:space="preserve">
          <source>Plot decision function of a weighted dataset, where the size of points is proportional to its weight.</source>
          <target state="translated">点の大きさが重みに比例する重み付きデータセットの決定関数をプロットします。</target>
        </trans-unit>
        <trans-unit id="2055a202b59cc1d82b030fc80b5879816af6142f" translate="yes" xml:space="preserve">
          <source>Plot decision surface of multi-class SGD on iris dataset. The hyperplanes corresponding to the three one-versus-all (OVA) classifiers are represented by the dashed lines.</source>
          <target state="translated">虹彩データセット上のマルチクラス SGD の決定面をプロットしたもの。3つの一対一分類器(OVA)に対応するハイパープレーンを破線で示す。</target>
        </trans-unit>
        <trans-unit id="327297e49968a75dbce927b0b7ac7371a08d6d35" translate="yes" xml:space="preserve">
          <source>Plot decision surface of multinomial and One-vs-Rest Logistic Regression. The hyperplanes corresponding to the three One-vs-Rest (OVR) classifiers are represented by the dashed lines.</source>
          <target state="translated">多項式とOne-vs-restロジスティック回帰の決定面をプロットしたもの。3つのOne-vs-rest (OVR)分類器に対応する双平面を破線で示す.</target>
        </trans-unit>
        <trans-unit id="da6b79ecce62363042c6b7355c061b1d158cd29e" translate="yes" xml:space="preserve">
          <source>Plot different SVM classifiers in the iris dataset</source>
          <target state="translated">虹彩データセットの異なるSVM分類器のプロット</target>
        </trans-unit>
        <trans-unit id="fec11ecd65159c6aa4dd2ed7bc70c42c80743b33" translate="yes" xml:space="preserve">
          <source>Plot multi-class SGD on the iris dataset</source>
          <target state="translated">虹彩データセットにマルチクラスSGDをプロット</target>
        </trans-unit>
        <trans-unit id="ba32fad35c82296b19217e926ca784f8dc480aa6" translate="yes" xml:space="preserve">
          <source>Plot multinomial and One-vs-Rest Logistic Regression</source>
          <target state="translated">多項式と一対一残差ロジスティック回帰のプロット</target>
        </trans-unit>
        <trans-unit id="4b397af4573c8c3ff6fe276f1d3414d458173eb8" translate="yes" xml:space="preserve">
          <source>Plot of a ROC curve for a specific class</source>
          <target state="translated">特定のクラスのROC曲線のプロット</target>
        </trans-unit>
        <trans-unit id="2e98f97179f7787be7e479df07e8c653a4456c6c" translate="yes" xml:space="preserve">
          <source>Plot randomly generated classification dataset</source>
          <target state="translated">ランダムに生成された分類データセットをプロット</target>
        </trans-unit>
        <trans-unit id="8635886c93f9f7bac9a25109d5aa81af0e2282a3" translate="yes" xml:space="preserve">
          <source>Plot randomly generated multilabel dataset</source>
          <target state="translated">ランダムに生成されたマルチラベルデータセットをプロット</target>
        </trans-unit>
        <trans-unit id="efb6adeaeb9b8fea32241dc4e81af8acb788aff0" translate="yes" xml:space="preserve">
          <source>Plot results</source>
          <target state="translated">プロット結果</target>
        </trans-unit>
        <trans-unit id="7114cafe0c0f8ef1073ae59db6d1ecdd4e9b786a" translate="yes" xml:space="preserve">
          <source>Plot several randomly generated 2D classification datasets. This example illustrates the &lt;code&gt;datasets.make_classification&lt;/code&gt;&lt;code&gt;datasets.make_blobs&lt;/code&gt; and &lt;code&gt;datasets.make_gaussian_quantiles&lt;/code&gt; functions.</source>
          <target state="translated">ランダムに生成されたいくつかの2D分類データセットをプロットします。この例では示し &lt;code&gt;datasets.make_classification&lt;/code&gt; の &lt;code&gt;datasets.make_blobs&lt;/code&gt; と &lt;code&gt;datasets.make_gaussian_quantiles&lt;/code&gt; の機能を。</target>
        </trans-unit>
        <trans-unit id="d93ec4735c14a13d9aac7a26f400c6a70dcf1259" translate="yes" xml:space="preserve">
          <source>Plot the Precision-Recall curve</source>
          <target state="translated">精度-リコール曲線のプロット</target>
        </trans-unit>
        <trans-unit id="56fc4a54784c2e98ce65c0720810139c4d68b5b2" translate="yes" xml:space="preserve">
          <source>Plot the class probabilities of the first sample in a toy dataset predicted by three different classifiers and averaged by the &lt;code&gt;VotingClassifier&lt;/code&gt;.</source>
          <target state="translated">3つの異なる分類子によって予測され、 &lt;code&gt;VotingClassifier&lt;/code&gt; によって平均化されたおもちゃデータセットの最初のサンプルのクラス確率をプロットします。</target>
        </trans-unit>
        <trans-unit id="2b41947dfde5208fe00cac90f2d4dc03f6823202" translate="yes" xml:space="preserve">
          <source>Plot the classification probability for different classifiers. We use a 3 class dataset, and we classify it with a Support Vector classifier, L1 and L2 penalized logistic regression with either a One-Vs-Rest or multinomial setting, and Gaussian process classification.</source>
          <target state="translated">異なる分類器の分類確率をプロットします。3つのクラスのデータセットを使用し、サポートベクター分類器、L1とL2のペナルティ付きロジスティック回帰(One-Vs-Restまたは多項式設定)、ガウス過程分類で分類します。</target>
        </trans-unit>
        <trans-unit id="1cd8aee71b9f3c23870f222d4675d55da346d5dd" translate="yes" xml:space="preserve">
          <source>Plot the confidence ellipsoids of a mixture of two Gaussians obtained with Expectation Maximisation (&lt;code&gt;GaussianMixture&lt;/code&gt; class) and Variational Inference (&lt;code&gt;BayesianGaussianMixture&lt;/code&gt; class models with a Dirichlet process prior).</source>
          <target state="translated">期待値最大化（ &lt;code&gt;GaussianMixture&lt;/code&gt; クラス）と変分推論（事前のディリクレプロセスを使用した &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; クラスモデル）で得られた2つのガウス混合の信頼楕円体をプロットします。</target>
        </trans-unit>
        <trans-unit id="00182c117782c7850baca00bf6cebe8035dd77e1" translate="yes" xml:space="preserve">
          <source>Plot the decision boundaries of a &lt;code&gt;VotingClassifier&lt;/code&gt; for two features of the Iris dataset.</source>
          <target state="translated">アイリスデータセットの2つの特徴に対する &lt;code&gt;VotingClassifier&lt;/code&gt; の決定境界をプロットします。</target>
        </trans-unit>
        <trans-unit id="1dc52c59ef7b06b62b5bf6227f1a878073dd4d70" translate="yes" xml:space="preserve">
          <source>Plot the decision boundaries of a VotingClassifier</source>
          <target state="translated">VotingClassifier の決定境界をプロットします.</target>
        </trans-unit>
        <trans-unit id="55185472d28511bfa0363da45cc5b619cef7f522" translate="yes" xml:space="preserve">
          <source>Plot the decision surface of a decision tree on the iris dataset</source>
          <target state="translated">虹彩データセット上に決定木の決定面をプロットする</target>
        </trans-unit>
        <trans-unit id="d9594e701a87aa1711d08683ce0adfef724ecd27" translate="yes" xml:space="preserve">
          <source>Plot the decision surface of a decision tree trained on pairs of features of the iris dataset.</source>
          <target state="translated">虹彩データセットの特徴のペアで学習した決定木の決定面をプロットします。</target>
        </trans-unit>
        <trans-unit id="f0bf861c9d54040e12c9cc05a6e2089c743c128d" translate="yes" xml:space="preserve">
          <source>Plot the decision surfaces of ensembles of trees on the iris dataset</source>
          <target state="translated">虹彩データセット上での木のアンサンブルの決定面のプロット</target>
        </trans-unit>
        <trans-unit id="f7cdddf773db21703dc8d829a947d9360d2b4b3d" translate="yes" xml:space="preserve">
          <source>Plot the decision surfaces of forests of randomized trees trained on pairs of features of the iris dataset.</source>
          <target state="translated">虹彩データセットの特徴のペアで訓練されたランダム化された木の森の決定面をプロットする。</target>
        </trans-unit>
        <trans-unit id="81590d4bb30da97000d973d7bab58a58c2e64092" translate="yes" xml:space="preserve">
          <source>Plot the density estimation of a mixture of two Gaussians. Data is generated from two Gaussians with different centers and covariance matrices.</source>
          <target state="translated">2つのガウシアンの混合物の密度推定をプロットします。データは、異なる中心と共分散行列を持つ2つのガウシアンから生成されます。</target>
        </trans-unit>
        <trans-unit id="6861c16dbeca1a065533244a96ba3516d1d4c3a8" translate="yes" xml:space="preserve">
          <source>Plot the maximum margin separating hyperplane within a two-class separable dataset using a Support Vector Machine classifier with linear kernel.</source>
          <target state="translated">線形カーネルを持つサポートベクターマシン分類器を用いて、2クラスの分離可能なデータセット内の最大マージンの分離双平面をプロットします。</target>
        </trans-unit>
        <trans-unit id="035aca7881cd7f9aa629a522da62a9cd8a6c5c8b" translate="yes" xml:space="preserve">
          <source>Plot the maximum margin separating hyperplane within a two-class separable dataset using a linear Support Vector Machines classifier trained using SGD.</source>
          <target state="translated">SGD を使用して訓練された線形サポートベクターマシン分類器を使用して、2 つのクラスの分離可能なデータセット内の最大マージンの分離ハイパープレーンをプロットします。</target>
        </trans-unit>
        <trans-unit id="970f17834d8825a63cbdc2d99c8fc1d2edc7990a" translate="yes" xml:space="preserve">
          <source>Plot the micro-averaged Precision-Recall curve</source>
          <target state="translated">微小平均化された精度-リコール曲線をプロットします。</target>
        </trans-unit>
        <trans-unit id="80cbcfd03f5ca970cf63eec27ccbc1b7f85e2ada" translate="yes" xml:space="preserve">
          <source>Plotting Cross-Validated Predictions</source>
          <target state="translated">クロスバリデートされた予測値のプロット</target>
        </trans-unit>
        <trans-unit id="931865770541ce727daa93f7fa28b4bfb7a185e8" translate="yes" xml:space="preserve">
          <source>Plotting Learning Curves</source>
          <target state="translated">学習曲線のプロット</target>
        </trans-unit>
        <trans-unit id="61375fe5074bc7ba726b7585b9c829f7928f0e90" translate="yes" xml:space="preserve">
          <source>Plotting Validation Curves</source>
          <target state="translated">バリデーションカーブのプロット</target>
        </trans-unit>
        <trans-unit id="86755acc87f18891f16b4684ed01b0376a7cdfb2" translate="yes" xml:space="preserve">
          <source>Plotting the result</source>
          <target state="translated">結果のプロット</target>
        </trans-unit>
        <trans-unit id="515260d5ba710a1140cfc8c5e00df3878ade8efb" translate="yes" xml:space="preserve">
          <source>Point used as initial kernel locations. If None and bin_seeding=False, each data point is used as a seed. If None and bin_seeding=True, see bin_seeding.</source>
          <target state="translated">初期カーネル位置として使用されるポイント。Noneおよびbin_seeding=Falseの場合、各データポイントがシードとして使用されます。Noneおよびbin_seeding=Trueの場合は、bin_seedingを参照してください。</target>
        </trans-unit>
        <trans-unit id="f2900dffbacbabbaa3e41fbfbf606af904f4ea9a" translate="yes" xml:space="preserve">
          <source>Points are labeled as follows, where Y means the class is present:</source>
          <target state="translated">ポイントは以下のようにラベル付けされており、Yはクラスが存在することを意味します。</target>
        </trans-unit>
        <trans-unit id="bfa76eceb881251219024aa15126052b423fdc69" translate="yes" xml:space="preserve">
          <source>Points that are neighboring often share the same leaf of a tree and therefore share large parts of their hashed representation. This allows to separate two concentric circles simply based on the principal components of the transformed data with truncated SVD.</source>
          <target state="translated">隣接している点は、多くの場合、木の同じ葉を共有しているため、ハッシュ化された表現の大部分を共有しています。これにより、切り捨てられたSVDで変換されたデータの主成分に基づいて、単純に2つの同心円を分離することができる。</target>
        </trans-unit>
        <trans-unit id="2aa7f739412f96bbef950dc5131b827c8658cc0f" translate="yes" xml:space="preserve">
          <source>Polynomial interpolation</source>
          <target state="translated">多項式補間</target>
        </trans-unit>
        <trans-unit id="ea36423930650d6bde3fdec25656592fdb82be08" translate="yes" xml:space="preserve">
          <source>Popular choices for the regularization term \(R\) include:</source>
          <target state="translated">正則化用語の人気のある選択肢には、以下のものがあります。</target>
        </trans-unit>
        <trans-unit id="5beb1d6b6cca44d23c554e4884a63a14968bd1fc" translate="yes" xml:space="preserve">
          <source>Population block population</source>
          <target state="translated">人口ブロック人口</target>
        </trans-unit>
        <trans-unit id="b6bfeaec43665e5045c5188dc50b287def6848b4" translate="yes" xml:space="preserve">
          <source>Portion of the largest variance of all features that is added to variances for calculation stability.</source>
          <target state="translated">計算の安定性のために分散に加えられる全特徴の中で最大の分散の一部。</target>
        </trans-unit>
        <trans-unit id="71bbec1d0bc4c70d1bf578164b2f035df429e62c" translate="yes" xml:space="preserve">
          <source>Possible examples:</source>
          <target state="translated">可能性のある例。</target>
        </trans-unit>
        <trans-unit id="b62496b0d745ebd826ec5e2a96a59ab92b59997a" translate="yes" xml:space="preserve">
          <source>Possible to validate a model using statistical tests. That makes it possible to account for the reliability of the model.</source>
          <target state="translated">統計的検定を用いてモデルを検証することができる.モデルの信頼性を説明することが可能になる。</target>
        </trans-unit>
        <trans-unit id="1ef096a287ef80019501f0b7658be73c867011a0" translate="yes" xml:space="preserve">
          <source>Posterior log-probabilities of classification per class.</source>
          <target state="translated">クラスごとの分類の事後対数確率。</target>
        </trans-unit>
        <trans-unit id="0167e7e78429608afa3a283f8dc4209c9081db39" translate="yes" xml:space="preserve">
          <source>Posterior probabilities of classification</source>
          <target state="translated">分類の事後確率</target>
        </trans-unit>
        <trans-unit id="eb0cff62f61d9c7621bc439a7c03422a0f7152b0" translate="yes" xml:space="preserve">
          <source>Posterior probabilities of classification per class.</source>
          <target state="translated">クラスごとの分類の事後確率。</target>
        </trans-unit>
        <trans-unit id="75700cecf794e529a76abd7d8bbf40d36053c816" translate="yes" xml:space="preserve">
          <source>Potential users of LOO for model selection should weigh a few known caveats. When compared with \(k\)-fold cross validation, one builds \(n\) models from \(n\) samples instead of \(k\) models, where \(n &amp;gt; k\). Moreover, each is trained on \(n - 1\) samples rather than \((k-1) n / k\). In both ways, assuming \(k\) is not too large and \(k &amp;lt; n\), LOO is more computationally expensive than \(k\)-fold cross validation.</source>
          <target state="translated">モデルを選択するためにLOOを使用する可能性のあるユーザーは、いくつかの既知の警告を比較検討する必要があります。\（k \）分割交差検証と比較すると、\（k \）モデルではなく\（n \）サンプルから\（n \）モデルを構築します。ここで、\（n&amp;gt; k \）です。さらに、それぞれは\（（k-1）n / k \）ではなく\（n-1 \）サンプルでトレーニングされます。どちらの方法でも、\（k \）が大きすぎず、\（k &amp;lt;n \）であると仮定すると、LOOは\（k \）分割交差検証よりも計算コストが高くなります。</target>
        </trans-unit>
        <trans-unit id="a74e80361c78ad66c827d841d2f4673ac4c08e24" translate="yes" xml:space="preserve">
          <source>Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</source>
          <target state="translated">Minkowski metricのパワーパラメータ.p=1の場合、これはmanhattan_distance (l1)、p=2の場合はeuclidean_distance (l2)を使用することと同等である。任意のpについては、minkowski_distance (l_p)が使用されます。</target>
        </trans-unit>
        <trans-unit id="944ca5a7bffc3b53cfa153e37ee8230d3113fab6" translate="yes" xml:space="preserve">
          <source>Power transforms are a family of parametric, monotonic transformations that are applied to make data more Gaussian-like. This is useful for modeling issues related to heteroscedasticity (non-constant variance), or other situations where normality is desired.</source>
          <target state="translated">べき乗変換は,データをよりガウス風にするために適用されるパラメトリックな単調変換の一群である.これは,異種混合性(分散が一定でない)に関連する問題や,正規性が望まれるその他の状況をモデル化するのに有用である.</target>
        </trans-unit>
        <trans-unit id="fdeecbacef0f72dd39653fda27722b303c8b957f" translate="yes" xml:space="preserve">
          <source>PowerTransformer</source>
          <target state="translated">PowerTransformer</target>
        </trans-unit>
        <trans-unit id="87bf6e4911166a71371c673a1c349474b4b6bf5d" translate="yes" xml:space="preserve">
          <source>Pre-computed dissimilarities are passed directly to &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;fit_transform&lt;/code&gt;.</source>
          <target state="translated">事前に計算された相違点は、 &lt;code&gt;fit&lt;/code&gt; および &lt;code&gt;fit_transform&lt;/code&gt; に直接渡されます。</target>
        </trans-unit>
        <trans-unit id="1eedfffdf42945a227f3b7652653d6d5b56201f3" translate="yes" xml:space="preserve">
          <source>Pre-computed dot-products of vectors in X (e.g., &lt;code&gt;(X**2).sum(axis=1)&lt;/code&gt;)</source>
          <target state="translated">Xのベクトルの事前に計算されたドット積（例： &lt;code&gt;(X**2).sum(axis=1)&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="245447283cbdae836e2c3ef586ea5c6ddd53470e" translate="yes" xml:space="preserve">
          <source>Pre-computed dot-products of vectors in Y (e.g., &lt;code&gt;(Y**2).sum(axis=1)&lt;/code&gt;)</source>
          <target state="translated">Yのベクトルの事前に計算されたドット積（例： &lt;code&gt;(Y**2).sum(axis=1)&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="3dd4db5ce7ea626f59e720f0c27096a22aa1ecd0" translate="yes" xml:space="preserve">
          <source>Precision</source>
          <target state="translated">Precision</target>
        </trans-unit>
        <trans-unit id="3cadf6b155ea9cfa34e1c6ff646ed002dc6e267c" translate="yes" xml:space="preserve">
          <source>Precision (\(P\)) is defined as the number of true positives (\(T_p\)) over the number of true positives plus the number of false positives (\(F_p\)).</source>
          <target state="translated">Precision (T\(P\(P)))は、真の陽性数に偽の陽性数を加えたものと定義されます。</target>
        </trans-unit>
        <trans-unit id="48b3bfbc2fc9b1f176694a73c9f60562de8469bc" translate="yes" xml:space="preserve">
          <source>Precision of the positive class in binary classification or weighted average of the precision of each class for the multiclass task.</source>
          <target state="translated">2値分類における正クラスの精度、または多クラスタスクにおける各クラスの精度の加重平均。</target>
        </trans-unit>
        <trans-unit id="c7599672c1de408bde10c556da2d523e0bbc458a" translate="yes" xml:space="preserve">
          <source>Precision of the solution.</source>
          <target state="translated">ソリューションの精度。</target>
        </trans-unit>
        <trans-unit id="145d1275fdbccedcff81a776436f980376926a4b" translate="yes" xml:space="preserve">
          <source>Precision values such that element i is the precision of predictions with score &amp;gt;= thresholds[i] and the last element is 1.</source>
          <target state="translated">要素iがスコア&amp;gt; = thresholds [i]の予測の精度であり、最後の要素が1であるような精度値。</target>
        </trans-unit>
        <trans-unit id="9b8d6b4078699ef62eae215de2112bcae36a779b" translate="yes" xml:space="preserve">
          <source>Precision-Recall</source>
          <target state="translated">Precision-Recall</target>
        </trans-unit>
        <trans-unit id="c4dc9f01a91988c2185e5c4ff4abf1c68a5c776a" translate="yes" xml:space="preserve">
          <source>Precision-Recall is a useful measure of success of prediction when the classes are very imbalanced. In information retrieval, precision is a measure of result relevancy, while recall is a measure of how many truly relevant results are returned.</source>
          <target state="translated">精度-リコールは、クラスが非常に不均衡な場合の予測成功の有用な尺度である。情報検索では、精度は結果の関連性の尺度であり、リコールは本当に関連性のある結果がどれだけ返ってくるかの尺度である。</target>
        </trans-unit>
        <trans-unit id="9d2c44ea940ec9160ea4212eaee48c117c9fec49" translate="yes" xml:space="preserve">
          <source>Precision-recall curves are typically used in binary classification to study the output of a classifier. In order to extend the precision-recall curve and average precision to multi-class or multi-label classification, it is necessary to binarize the output. One curve can be drawn per label, but one can also draw a precision-recall curve by considering each element of the label indicator matrix as a binary prediction (micro-averaging).</source>
          <target state="translated">精度-リコール曲線は,通常,2値分類で分類器の出力を調べるために使用される.精度-リコール曲線と平均精度をマルチクラスまたはマルチラベル分類に拡張するためには,出力を2値化する必要がある.ラベルごとに1つの曲線を描くことができますが、ラベル指標行列の各要素を2値予測(マイクロ平均化)として考慮することで、精度-リコール曲線を描くこともできます。</target>
        </trans-unit>
        <trans-unit id="f9a6c763996d681deabdfef7b8476b0fb69e48e8" translate="yes" xml:space="preserve">
          <source>Precompute distances (faster but takes more memory).</source>
          <target state="translated">距離を事前に計算します(高速ですが、より多くのメモリを必要とします)。</target>
        </trans-unit>
        <trans-unit id="74241dcd8b76a34a71276f4af2e1f247526d8ccf" translate="yes" xml:space="preserve">
          <source>Precomputed Gram matrix (X&amp;rsquo; * X), if &lt;code&gt;'auto'&lt;/code&gt;, the Gram matrix is precomputed from the given X, if there are more samples than features.</source>
          <target state="translated">事前計算されたグラム行列（X '* X）。 &lt;code&gt;'auto'&lt;/code&gt; 場合、機能よりもサンプルが多い場合、指定されたXからグラム行列が事前計算されます。</target>
        </trans-unit>
        <trans-unit id="2a2e45fbf62fedaeebe0c8590ad60ff4174e5ab2" translate="yes" xml:space="preserve">
          <source>Precomputed Gram matrix, dictionary * dictionary&amp;rsquo;</source>
          <target state="translated">事前計算されたグラム行列、辞書*辞書 '</target>
        </trans-unit>
        <trans-unit id="a48847353a3a5d95755a7a73ff3aa46a650e801f" translate="yes" xml:space="preserve">
          <source>Precomputed covariance, dictionary&amp;rsquo; * X</source>
          <target state="translated">事前計算された共分散、辞書 '* X</target>
        </trans-unit>
        <trans-unit id="fa26606f0ded4eeae827a5e13cb6b101bfb1dc41" translate="yes" xml:space="preserve">
          <source>Predefined split cross-validator</source>
          <target state="translated">定義済みのスプリットクロスバリデータ</target>
        </trans-unit>
        <trans-unit id="4cb3beb22c8d3a092f661b0f558220d3851b4f5f" translate="yes" xml:space="preserve">
          <source>Predict class at each stage for X.</source>
          <target state="translated">Xの各ステージでのクラスを予測します。</target>
        </trans-unit>
        <trans-unit id="b37b3a68f8838806941f9d07a55fc66d496734de" translate="yes" xml:space="preserve">
          <source>Predict class for X.</source>
          <target state="translated">Xのクラスを予測します。</target>
        </trans-unit>
        <trans-unit id="110127bb58167b2a44079253e6bdd9fb9d0322a0" translate="yes" xml:space="preserve">
          <source>Predict class labels for X.</source>
          <target state="translated">Xのクラスラベルを予測します.</target>
        </trans-unit>
        <trans-unit id="66f3d65c0d89bdce43ef6cf6e001f4ae1e150fa3" translate="yes" xml:space="preserve">
          <source>Predict class labels for samples in X.</source>
          <target state="translated">Xのサンプルのクラスラベルを予測します.</target>
        </trans-unit>
        <trans-unit id="ff9a33e306cb61b5d46880775730458dbfda1fc5" translate="yes" xml:space="preserve">
          <source>Predict class log-probabilities for X.</source>
          <target state="translated">Xのクラス対数確率を予測します。</target>
        </trans-unit>
        <trans-unit id="90e5301af97afcc90d0c29c15774ada1b78e1932" translate="yes" xml:space="preserve">
          <source>Predict class log-probabilities of the input samples X.</source>
          <target state="translated">入力サンプルXのクラス対数確率を予測する.</target>
        </trans-unit>
        <trans-unit id="b3e79fd1959c8312a9a26cdaea691da2d340b21b" translate="yes" xml:space="preserve">
          <source>Predict class or regression value for X.</source>
          <target state="translated">Xのクラスまたは回帰値を予測します。</target>
        </trans-unit>
        <trans-unit id="ee407700821ff6ce9beed9f4cbb5c1de51181025" translate="yes" xml:space="preserve">
          <source>Predict class probabilities at each stage for X.</source>
          <target state="translated">Xの各段階でのクラス確率を予測します。</target>
        </trans-unit>
        <trans-unit id="d19c8a92fef6e1d8e00a4d018404a4763e36f5ad" translate="yes" xml:space="preserve">
          <source>Predict class probabilities for X.</source>
          <target state="translated">Xのクラス確率を予測します.</target>
        </trans-unit>
        <trans-unit id="09dc322e274a3505c300cc07827d47dfbb399f93" translate="yes" xml:space="preserve">
          <source>Predict class probabilities of the input samples X.</source>
          <target state="translated">入力サンプルXのクラス確率を予測します.</target>
        </trans-unit>
        <trans-unit id="881f47898705d21006122f71ad4ab62a62a462be" translate="yes" xml:space="preserve">
          <source>Predict classes for X.</source>
          <target state="translated">Xのクラスを予測します。</target>
        </trans-unit>
        <trans-unit id="296acbb4c624db7079fa54773a5e0ad84afb010f" translate="yes" xml:space="preserve">
          <source>Predict confidence scores for samples.</source>
          <target state="translated">サンプルの信頼度スコアを予測します。</target>
        </trans-unit>
        <trans-unit id="2494751d3a2d1a42d5313b28fcc4f83bac74cb1a" translate="yes" xml:space="preserve">
          <source>Predict data using the &lt;code&gt;centroids_&lt;/code&gt; of subclusters.</source>
          <target state="translated">サブクラスターの &lt;code&gt;centroids_&lt;/code&gt; を使用してデータを予測します。</target>
        </trans-unit>
        <trans-unit id="92e8a0090ce03f45dfdf289779e466981411d7fa" translate="yes" xml:space="preserve">
          <source>Predict if a particular sample is an outlier or not.</source>
          <target state="translated">特定のサンプルが外れ値であるかどうかを予測します。</target>
        </trans-unit>
        <trans-unit id="015ccebc331620054f423244712d7856284722d0" translate="yes" xml:space="preserve">
          <source>Predict margin (libsvm name for this is predict_values)</source>
          <target state="translated">マージンを予測する (このための libsvm の名前は predict_values)</target>
        </trans-unit>
        <trans-unit id="5363b2c32425812c2bcb3fbaa9bf8cfb2d5164a0" translate="yes" xml:space="preserve">
          <source>Predict multi-class targets using underlying estimators.</source>
          <target state="translated">基礎となる推定器を用いて複数クラスのターゲットを予測する。</target>
        </trans-unit>
        <trans-unit id="236af7da07ddb0d9ed29a089f18dd28b81ac84bd" translate="yes" xml:space="preserve">
          <source>Predict multi-output variable using a model</source>
          <target state="translated">モデルを用いた複数出力変数の予測</target>
        </trans-unit>
        <trans-unit id="440aeb8d451f927f87cd14a1da1e1e06cfe27c30" translate="yes" xml:space="preserve">
          <source>Predict multi-output variable using a model trained for each target variable.</source>
          <target state="translated">各ターゲット変数に対して訓練されたモデルを使用して、マルチ出力変数を予測します。</target>
        </trans-unit>
        <trans-unit id="57d6ee4b63567e7fa514630f74e07b2180223661" translate="yes" xml:space="preserve">
          <source>Predict new data by linear interpolation.</source>
          <target state="translated">線形補間で新しいデータを予測する。</target>
        </trans-unit>
        <trans-unit id="24bee86083d9d8686237dff0aca9e15905f91489" translate="yes" xml:space="preserve">
          <source>Predict on the data matrix X using the ClassifierChain model.</source>
          <target state="translated">ClassifierChainモデルを用いたデータ行列Xの予測。</target>
        </trans-unit>
        <trans-unit id="4966ba27ad7d2bb95b545e975edd2dd7639f0b61" translate="yes" xml:space="preserve">
          <source>Predict output may not match that of standalone liblinear in certain cases. See &lt;a href=&quot;../linear_model#liblinear-differences&quot;&gt;differences from liblinear&lt;/a&gt; in the narrative documentation.</source>
          <target state="translated">特定の場合、予測出力はスタンドアロンliblinearの出力と一致しない場合があります。物語のドキュメントで&lt;a href=&quot;../linear_model#liblinear-differences&quot;&gt;liblinear&lt;/a&gt;との違いを参照してください。</target>
        </trans-unit>
        <trans-unit id="04fbb304d74e3ee1459f16173d84b52205d2990a" translate="yes" xml:space="preserve">
          <source>Predict posterior probability of each component given the data.</source>
          <target state="translated">データを与えられた各成分の事後確率を予測します。</target>
        </trans-unit>
        <trans-unit id="bd6763b250c597082132af1f5682341c5d5ff8a5" translate="yes" xml:space="preserve">
          <source>Predict probabilities</source>
          <target state="translated">確率を予測する</target>
        </trans-unit>
        <trans-unit id="8106d8771f34f5eabc577fcdeb5e96fd7582dc17" translate="yes" xml:space="preserve">
          <source>Predict probability estimates.</source>
          <target state="translated">確率推定値を予測する。</target>
        </trans-unit>
        <trans-unit id="e11ea3d8d0d16dd6b1042fa5aae9ca526b776539" translate="yes" xml:space="preserve">
          <source>Predict probability for each possible outcome.</source>
          <target state="translated">各可能性のある結果について確率を予測します。</target>
        </trans-unit>
        <trans-unit id="cab499225116c6c4381a969a0e7a2827b785a690" translate="yes" xml:space="preserve">
          <source>Predict regression target at each stage for X.</source>
          <target state="translated">Xの各段階での回帰目標を予測する。</target>
        </trans-unit>
        <trans-unit id="723d1df099023f4b7390aaaf6546a09600703da8" translate="yes" xml:space="preserve">
          <source>Predict regression target for X.</source>
          <target state="translated">Xの回帰目標を予測する.</target>
        </trans-unit>
        <trans-unit id="a7c5178b8c5f08e15306c326887476bcc207fa67" translate="yes" xml:space="preserve">
          <source>Predict regression value for X.</source>
          <target state="translated">Xの回帰値を予測します。</target>
        </trans-unit>
        <trans-unit id="11987bdd614b0d45fb0a30378442e5e664ee787f" translate="yes" xml:space="preserve">
          <source>Predict target values of X given a model (low-level method)</source>
          <target state="translated">モデルを与えられたXの目標値を予測する(低レベル手法</target>
        </trans-unit>
        <trans-unit id="1118ec744c70a9ced7c798b3344fa4f80e7f350c" translate="yes" xml:space="preserve">
          <source>Predict the class labels for the provided data</source>
          <target state="translated">提供されたデータのクラスラベルを予測する</target>
        </trans-unit>
        <trans-unit id="0fd38b6b56decb7521e45313caadd70afab49eb9" translate="yes" xml:space="preserve">
          <source>Predict the closest cluster each sample in X belongs to.</source>
          <target state="translated">Xの各サンプルが属する最も近いクラスターを予測します。</target>
        </trans-unit>
        <trans-unit id="d04dc0ca95e918d737a8729bfb93bc4da7747280" translate="yes" xml:space="preserve">
          <source>Predict the labels (1 inlier, -1 outlier) of X according to LOF.</source>
          <target state="translated">LOFに従ってXのラベル(1 inlier,-1 outlier)を予測する.</target>
        </trans-unit>
        <trans-unit id="9d1641b066b242cb2bf0042ad4cd1995e81ab6fa" translate="yes" xml:space="preserve">
          <source>Predict the labels (1 inlier, -1 outlier) of X according to the fitted model.</source>
          <target state="translated">フィットしたモデルにしたがって,X のラベル(1 個の正規分布,-1 個の外れ値)を予測する.</target>
        </trans-unit>
        <trans-unit id="85b48751710a59d1604b478a1cb0fe4558154254" translate="yes" xml:space="preserve">
          <source>Predict the labels for the data samples in X using trained model.</source>
          <target state="translated">訓練されたモデルを用いてXのデータサンプルのラベルを予測します。</target>
        </trans-unit>
        <trans-unit id="6fcf85e4f9a2635469a3bc0f62b0508a0449c9c3" translate="yes" xml:space="preserve">
          <source>Predict the target for the provided data</source>
          <target state="translated">提供されたデータのターゲットを予測する</target>
        </trans-unit>
        <trans-unit id="2071be7e8e1c641fcdd997af2eac5155a95c2002" translate="yes" xml:space="preserve">
          <source>Predict the target of new samples.</source>
          <target state="translated">新しいサンプルのターゲットを予測します。</target>
        </trans-unit>
        <trans-unit id="b036c338c8c7c8b8f3a7f9dfaafcc549ad9379b9" translate="yes" xml:space="preserve">
          <source>Predict the target of new samples. Can be different from the prediction of the uncalibrated classifier.</source>
          <target state="translated">新しいサンプルのターゲットを予測する。校正されていない分類器の予測とは異なる場合があります。</target>
        </trans-unit>
        <trans-unit id="058fb86a189ec6bee9925542c788fb4116728ab0" translate="yes" xml:space="preserve">
          <source>Predict using the Gaussian process regression model</source>
          <target state="translated">ガウス過程回帰モデルを用いた予測</target>
        </trans-unit>
        <trans-unit id="c5fa5a8d6dbf415899a0d8f5dbeeb100342ad788" translate="yes" xml:space="preserve">
          <source>Predict using the base regressor, applying inverse.</source>
          <target state="translated">ベース回帰子を用いて逆数を適用して予測する。</target>
        </trans-unit>
        <trans-unit id="16d6c91bb6247b0e3b2e7c1608acb6c6aaf1c58e" translate="yes" xml:space="preserve">
          <source>Predict using the estimated model.</source>
          <target state="translated">推定モデルを用いて予測する。</target>
        </trans-unit>
        <trans-unit id="6771834342807ce64511b84dad107250034aca9e" translate="yes" xml:space="preserve">
          <source>Predict using the kernel ridge model</source>
          <target state="translated">カーネルリッジモデルを用いた予測</target>
        </trans-unit>
        <trans-unit id="9cc445af0d47cc9e3fe5b5148b7b800c2621abb9" translate="yes" xml:space="preserve">
          <source>Predict using the linear model</source>
          <target state="translated">線形モデルを用いた予測</target>
        </trans-unit>
        <trans-unit id="ea5afc9ecafd018284fd5a8011653647aab370f8" translate="yes" xml:space="preserve">
          <source>Predict using the linear model.</source>
          <target state="translated">線形モデルを使って予測する。</target>
        </trans-unit>
        <trans-unit id="afe2e7622b6e98b5fd3219fbefabf19e5e27c19d" translate="yes" xml:space="preserve">
          <source>Predict using the multi-layer perceptron classifier</source>
          <target state="translated">多層パーセプトロン分類器を用いた予測</target>
        </trans-unit>
        <trans-unit id="418245d3416ded93f91e6f6a7f46db6d2bddb0b8" translate="yes" xml:space="preserve">
          <source>Predict using the multi-layer perceptron model.</source>
          <target state="translated">多層パーセプトロンモデルを用いた予測</target>
        </trans-unit>
        <trans-unit id="bbcfd227a4fd6a52cd15ff04b498dfd37817f646" translate="yes" xml:space="preserve">
          <source>Predicted class (expectation)</source>
          <target state="translated">予測クラス(期待値</target>
        </trans-unit>
        <trans-unit id="c23c0bade8db4a99bdd74a847d85f85436dde8e2" translate="yes" xml:space="preserve">
          <source>Predicted class label per sample.</source>
          <target state="translated">サンプルごとの予測クラスラベル。</target>
        </trans-unit>
        <trans-unit id="6eb2b54a32f8badefb51abd9627abd2f4ed7175d" translate="yes" xml:space="preserve">
          <source>Predicted class labels.</source>
          <target state="translated">予測されたクラスラベル。</target>
        </trans-unit>
        <trans-unit id="1c0fb7806758bcc1e05acba0f3c96fa3d7a5bb0f" translate="yes" xml:space="preserve">
          <source>Predicted decisions, as output by decision_function (floats).</source>
          <target state="translated">予測された決定を、decision_function (float)が出力します。</target>
        </trans-unit>
        <trans-unit id="9d60d7541de11ead40040ebf55656138bfa06e54" translate="yes" xml:space="preserve">
          <source>Predicted labels for each sample.</source>
          <target state="translated">各サンプルの予測ラベル。</target>
        </trans-unit>
        <trans-unit id="bda5186912ec2d3a4c3d985e04325968396dafa6" translate="yes" xml:space="preserve">
          <source>Predicted labels, as returned by a classifier.</source>
          <target state="translated">分類器が返す予測ラベル.</target>
        </trans-unit>
        <trans-unit id="4206066a487d91e230020ac6b49a356a37221536" translate="yes" xml:space="preserve">
          <source>Predicted multi-class targets.</source>
          <target state="translated">予測されるマルチクラスのターゲット。</target>
        </trans-unit>
        <trans-unit id="471345c03a0f6c76e771b685835d34aaa085be6f" translate="yes" xml:space="preserve">
          <source>Predicted probabilities, as returned by a classifier&amp;rsquo;s predict_proba method. If &lt;code&gt;y_pred.shape = (n_samples,)&lt;/code&gt; the probabilities provided are assumed to be that of the positive class. The labels in &lt;code&gt;y_pred&lt;/code&gt; are assumed to be ordered alphabetically, as done by &lt;code&gt;preprocessing.LabelBinarizer&lt;/code&gt;.</source>
          <target state="translated">分類子のpredict_probaメソッドによって返される予測確率。もし &lt;code&gt;y_pred.shape = (n_samples,)&lt;/code&gt; 設け確率を正クラスのものであると仮定されます。ラベル &lt;code&gt;y_pred&lt;/code&gt; は、によって行われるよう、アルファベット順であると仮定されている &lt;code&gt;preprocessing.LabelBinarizer&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="30fa748f60591aa49ffa54b8625d19e6d3fa1caf" translate="yes" xml:space="preserve">
          <source>Predicted target values for X</source>
          <target state="translated">Xの予測目標値</target>
        </trans-unit>
        <trans-unit id="ddfdf29590f8e61e5d8fd1e8af0625d097b22795" translate="yes" xml:space="preserve">
          <source>Predicted target values for X, values are from &lt;code&gt;classes_&lt;/code&gt;</source>
          <target state="translated">Xの予測ターゲット値、値は &lt;code&gt;classes_&lt;/code&gt; からのものです_</target>
        </trans-unit>
        <trans-unit id="0a5193d35f1d0747b0dcd37c2b58098d90dd9dc1" translate="yes" xml:space="preserve">
          <source>Predicted target values for X.</source>
          <target state="translated">Xの予測目標値。</target>
        </trans-unit>
        <trans-unit id="0d4a1c77352b65574731921e931152dc6d67a7e6" translate="yes" xml:space="preserve">
          <source>Predicted target values per element in X.</source>
          <target state="translated">Xの要素ごとの予測目標値。</target>
        </trans-unit>
        <trans-unit id="a63f32ed146dbd0a036e7a6c9007fd28cb724f17" translate="yes" xml:space="preserve">
          <source>Predicted values.</source>
          <target state="translated">予測値。</target>
        </trans-unit>
        <trans-unit id="287963e14d12632f521b827a4e86495105e087d4" translate="yes" xml:space="preserve">
          <source>Predicting Good Probabilities with Supervised Learning, A. Niculescu-Mizil &amp;amp; R. Caruana, ICML 2005</source>
          <target state="translated">教師あり学習による良好な確率の予測、A。Niculescu-MizilおよびR. Caruana、ICML 2005</target>
        </trans-unit>
        <trans-unit id="98782c3c25b19af8f6dafd01baf554b35ff65bf8" translate="yes" xml:space="preserve">
          <source>Prediction Intervals for Gradient Boosting Regression</source>
          <target state="translated">勾配ブースト回帰の予測区間</target>
        </trans-unit>
        <trans-unit id="a5caca0a7f480ab2154877c6274ee9ed2e787327" translate="yes" xml:space="preserve">
          <source>Prediction Latency</source>
          <target state="translated">予測待ち時間</target>
        </trans-unit>
        <trans-unit id="feb11a8226645ea5da9a48d3bfe651df9033d87c" translate="yes" xml:space="preserve">
          <source>Prediction computed with out-of-bag estimate on the training set.</source>
          <target state="translated">学習集合のバッグ外推定値を用いて計算された予測.</target>
        </trans-unit>
        <trans-unit id="fc1fcdf0c524a30639c066dc749abc64a6524c06" translate="yes" xml:space="preserve">
          <source>Prediction computed with out-of-bag estimate on the training set. If n_estimators is small it might be possible that a data point was never left out during the bootstrap. In this case, &lt;code&gt;oob_prediction_&lt;/code&gt; might contain NaN.</source>
          <target state="translated">トレーニングセットのout-of-bag推定を使用して計算された予測。n_estimatorsが小さい場合、ブートストラップ中にデータポイントが除外されなかった可能性があります。この場合、 &lt;code&gt;oob_prediction_&lt;/code&gt; にはNaNが含まれる可能性があります。</target>
        </trans-unit>
        <trans-unit id="a41914a2f37714142ad691edd19c5e43a6241f77" translate="yes" xml:space="preserve">
          <source>Prediction latency is measured as the elapsed time necessary to make a prediction (e.g. in micro-seconds). Latency is often viewed as a distribution and operations engineers often focus on the latency at a given percentile of this distribution (e.g. the 90 percentile).</source>
          <target state="translated">予測待ち時間は、予測を行うのに必要な経過時間として測定されます(例:マイクロ秒)。待ち時間はしばしば分布とみなされ、オペレーション・エンジニアは、この分布の特定のパーセンタイル(例:90パーセンタイル)での待ち時間に注目することがよくあります。</target>
        </trans-unit>
        <trans-unit id="e5f06aeed95b293a7ec0cbb529b2dc2cbbf9b847" translate="yes" xml:space="preserve">
          <source>Prediction throughput is defined as the number of predictions the software can deliver in a given amount of time (e.g. in predictions per second).</source>
          <target state="translated">予測スループットは、ソフトウェアが所定の時間内に提供できる予測の数として定義されます(例:1 秒あたりの予測数)。</target>
        </trans-unit>
        <trans-unit id="adcc2378933b72e3446a85e4fe1b367ed4a8ee49" translate="yes" xml:space="preserve">
          <source>Predictions for input data</source>
          <target state="translated">入力データの予測</target>
        </trans-unit>
        <trans-unit id="ab27a2587edb12bb0d1fda3f488b5135e41df062" translate="yes" xml:space="preserve">
          <source>Predictive power</source>
          <target state="translated">予測力</target>
        </trans-unit>
        <trans-unit id="c883768bdfe473a1aa19e31d78108e10463a6ea5" translate="yes" xml:space="preserve">
          <source>Preferences for each point - points with larger values of preferences are more likely to be chosen as exemplars. The number of exemplars, i.e. of clusters, is influenced by the input preferences value. If the preferences are not passed as arguments, they will be set to the median of the input similarities (resulting in a moderate number of clusters). For a smaller amount of clusters, this can be set to the minimum value of the similarities.</source>
          <target state="translated">各点の選好-選好の値が大きい点は、模範として選ばれる可能性が高い。模範となる点の数、つまりクラスタの数は、入力環境設定の値に影響されます。環境設定を引数として渡さなかった場合は、入力された類似度の中央値が設定されます (結果として、クラスターの数は中程度になります)。クラスタ数が少ない場合は、類似度の最小値に設定することができます。</target>
        </trans-unit>
        <trans-unit id="d950ed84434798aa79b3f6033bd1676939cb0d20" translate="yes" xml:space="preserve">
          <source>Preferences for each point - points with larger values of preferences are more likely to be chosen as exemplars. The number of exemplars, ie of clusters, is influenced by the input preferences value. If the preferences are not passed as arguments, they will be set to the median of the input similarities.</source>
          <target state="translated">各点の環境設定-環境設定の値が大きい点は、模範として選ばれる可能性が高くなります。模範となる点の数 (クラスタ数)は、入力環境設定の値に影響されます。環境設定を引数として渡さなかった場合は、入力された類似度の中央値が設定されます。</target>
        </trans-unit>
        <trans-unit id="14b1d1212d8840ca9f7efb348e45b326762c69cc" translate="yes" xml:space="preserve">
          <source>Prefetch the tasks for the next batch and dispatch them.</source>
          <target state="translated">次のバッチのタスクをプリフェッチしてディスパッチします。</target>
        </trans-unit>
        <trans-unit id="24c93aa4ab33374bb8e7198b2daeff3e433c0fbc" translate="yes" xml:space="preserve">
          <source>Preprocessing</source>
          <target state="translated">Preprocessing</target>
        </trans-unit>
        <trans-unit id="cc3693c3738c6f3fcbe2edd801580161673e54a4" translate="yes" xml:space="preserve">
          <source>Preprocessing programs made available by NIST were used to extract normalized bitmaps of handwritten digits from a preprinted form. From a total of 43 people, 30 contributed to the training set and different 13 to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of 4x4 and the number of on pixels are counted in each block. This generates an input matrix of 8x8 where each element is an integer in the range 0..16. This reduces dimensionality and gives invariance to small distortions.</source>
          <target state="translated">NISTが公開している前処理プログラムを用いて、印刷された用紙から手書きの桁数を正規化したビットマップを抽出した。総勢43名の中から、30名がトレーニングセットに、13名がテストセットに貢献した。32x32のビットマップは4x4の非重複ブロックに分割され、各ブロック内のオンピクセル数がカウントされる。これにより,各要素が0〜16の範囲の整数である8x8の入力行列が生成されます.これにより,次元性が低減され,小さな歪みに対して不変性が得られます.</target>
        </trans-unit>
        <trans-unit id="b0a35de16d2edfd24f40881bf819fae5af7097e5" translate="yes" xml:space="preserve">
          <source>Preset for the class_weight fit parameter.</source>
          <target state="translated">class_weight はめ込みパラ メータのプリセッ ト。</target>
        </trans-unit>
        <trans-unit id="4b557eedfee718637d8501877f5a64be009b5a8b" translate="yes" xml:space="preserve">
          <source>Principal Component Analysis (PCA) applied to this data identifies the combination of attributes (principal components, or directions in the feature space) that account for the most variance in the data. Here we plot the different samples on the 2 first principal components.</source>
          <target state="translated">このデータに適用された主成分分析(PCA)は、データ内で最も分散を占める属性の組み合わせ(主成分、または特徴空間内の方向)を特定します。ここでは、2つの第1主成分の異なるサンプルをプロットしています。</target>
        </trans-unit>
        <trans-unit id="a6b94c1fa1c0329dae275075618af3ec11723e1c" translate="yes" xml:space="preserve">
          <source>Principal Component Analysis applied to the Iris dataset.</source>
          <target state="translated">主成分分析をアイリスデータセットに適用。</target>
        </trans-unit>
        <trans-unit id="d6b546c117ff3cb1540fffde179b8cad5d53ba5e" translate="yes" xml:space="preserve">
          <source>Principal axes in feature space, representing the directions of maximum variance in the data. The components are sorted by &lt;code&gt;explained_variance_&lt;/code&gt;.</source>
          <target state="translated">データの最大分散の方向を表す、特徴空間の主軸。コンポーネントは、 &lt;code&gt;explained_variance_&lt;/code&gt; でソートされます。</target>
        </trans-unit>
        <trans-unit id="30fe9e3940e590621d7f0bb9b0d0469c84793795" translate="yes" xml:space="preserve">
          <source>Principal component analysis (&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt;) has the disadvantage that the components extracted by this method have exclusively dense expressions, i.e. they have non-zero coefficients when expressed as linear combinations of the original variables. This can make interpretation difficult. In many cases, the real underlying components can be more naturally imagined as sparse vectors; for example in face recognition, components might naturally map to parts of faces.</source>
          <target state="translated">主成分分析（&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt;）には、このメソッドによって抽出された成分が排他的に密な表現を持っているという欠点があります。つまり、元の変数の線形結合として表現すると、係数はゼロではありません。これは解釈を困難にする可能性があります。多くの場合、実際の基本的なコンポーネントは、疎なベクトルとしてより自然に想像できます。たとえば、顔認識では、コンポーネントが自然に顔の一部にマッピングされる場合があります。</target>
        </trans-unit>
        <trans-unit id="3c45b66bc9daa13e7d9c72ebcd199759fb365d43" translate="yes" xml:space="preserve">
          <source>Principal component analysis (PCA)</source>
          <target state="translated">主成分分析(PCA</target>
        </trans-unit>
        <trans-unit id="27682a0d321ed3dea37d28f220c82e91ea47e974" translate="yes" xml:space="preserve">
          <source>Principal component analysis is also a latent linear variable model which however assumes equal noise variance for each feature. This extra assumption makes probabilistic PCA faster as it can be computed in closed form.</source>
          <target state="translated">主成分分析は、潜在的な線形変数モデルでもありますが、各特徴に対して等しいノイズ分散を仮定しています。この追加の仮定は、閉形式で計算できるため、確率的PCAを高速化します。</target>
        </trans-unit>
        <trans-unit id="1f6abb25251799b9e41b673896b30d2e7743cd31" translate="yes" xml:space="preserve">
          <source>Principal component analysis: PCA</source>
          <target state="translated">主成分分析。PCA</target>
        </trans-unit>
        <trans-unit id="1b8437a3fa4a1275d1ba1d12ed6963a22fc037c1" translate="yes" xml:space="preserve">
          <source>Principal components analysis (PCA)</source>
          <target state="translated">主成分分析(PCA</target>
        </trans-unit>
        <trans-unit id="5a1174d6931171ffd7d3b357a535b3a3d607a9de" translate="yes" xml:space="preserve">
          <source>Print useful debugging information</source>
          <target state="translated">デバッグに役立つ情報を表示する</target>
        </trans-unit>
        <trans-unit id="c1c5200355e6830b00b9319b71d0145e5b700f71" translate="yes" xml:space="preserve">
          <source>Prior of document topic distribution &lt;code&gt;theta&lt;/code&gt;. If the value is None, defaults to &lt;code&gt;1 / n_components&lt;/code&gt;. In the literature, this is called &lt;code&gt;alpha&lt;/code&gt;.</source>
          <target state="translated">文書トピック配布 &lt;code&gt;theta&lt;/code&gt; 前。値がNoneの場合、デフォルトは &lt;code&gt;1 / n_components&lt;/code&gt; です。文献では、これは &lt;code&gt;alpha&lt;/code&gt; と呼ばれています。</target>
        </trans-unit>
        <trans-unit id="30bbeaea3ad5ae5cca83fd5e61da629080788c50" translate="yes" xml:space="preserve">
          <source>Prior of topic word distribution &lt;code&gt;beta&lt;/code&gt;. If the value is None, defaults to &lt;code&gt;1 / n_components&lt;/code&gt;. In the literature, this is called &lt;code&gt;beta&lt;/code&gt;.</source>
          <target state="translated">トピックワード配布 &lt;code&gt;beta&lt;/code&gt; 前。値がNoneの場合、デフォルトは &lt;code&gt;1 / n_components&lt;/code&gt; です。文献では、これは &lt;code&gt;beta&lt;/code&gt; と呼ばれています。</target>
        </trans-unit>
        <trans-unit id="bdfe015d1be4dfdea1f6788227d664c259407953" translate="yes" xml:space="preserve">
          <source>Prior probabilities of the classes. If specified the priors are not adjusted according to the data.</source>
          <target state="translated">クラスの事前確率.指定された場合,プライオ値はデータに応じて調整されません.</target>
        </trans-unit>
        <trans-unit id="8741a7d95e10089a15bca30c8cec0364251c1317" translate="yes" xml:space="preserve">
          <source>Prior probabilities of the classes. Not used.</source>
          <target state="translated">クラスの事前確率。使用していません。</target>
        </trans-unit>
        <trans-unit id="58369bd54ea62c9c483ab40eb23ad2254e33831b" translate="yes" xml:space="preserve">
          <source>Priors on classes</source>
          <target state="translated">クラスのプリオール</target>
        </trans-unit>
        <trans-unit id="371a276deaa5931894d10a44b79e47fcc68aec68" translate="yes" xml:space="preserve">
          <source>Proanthocyanins</source>
          <target state="translated">Proanthocyanins</target>
        </trans-unit>
        <trans-unit id="dc39071ac278ca69c49e2bb68c5d787fa71da3ba" translate="yes" xml:space="preserve">
          <source>Proanthocyanins:</source>
          <target state="translated">Proanthocyanins:</target>
        </trans-unit>
        <trans-unit id="436d6fac1ff357492b6144d87ad40d402972e325" translate="yes" xml:space="preserve">
          <source>Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods, J. Platt, (1999)</source>
          <target state="translated">サポートベクターマシンの確率的出力と正規化尤度法との比較,J.Platt,(1999)</target>
        </trans-unit>
        <trans-unit id="65884b6f0c144a05ea5bb72b4a5f34604f98727e" translate="yes" xml:space="preserve">
          <source>Probabilistic PCA and Factor Analysis are probabilistic models. The consequence is that the likelihood of new data can be used for model selection and covariance estimation. Here we compare PCA and FA with cross-validation on low rank data corrupted with homoscedastic noise (noise variance is the same for each feature) or heteroscedastic noise (noise variance is the different for each feature). In a second step we compare the model likelihood to the likelihoods obtained from shrinkage covariance estimators.</source>
          <target state="translated">確率的PCAと因子分析は、確率的モデルである。その結果、新しいデータの尤度がモデル選択と共分散推定に使用できる。ここでは、同種ノイズ(ノイズの分散が各特徴に対して同じ)または異種ノイズ(ノイズの分散が各特徴に対して異なる)で破損した低ランクのデータでの交差検証を用いて、PCAとFAを比較します。第2ステップでは、モデル尤度を収縮共分散推定器から得られる尤度と比較する。</target>
        </trans-unit>
        <trans-unit id="a886f2d46c4d856f2d8ffc5bd193a83a0b30c5a7" translate="yes" xml:space="preserve">
          <source>Probabilistic predictions with Gaussian process classification (GPC)</source>
          <target state="translated">ガウスプロセス分類(GPC)を用いた確率的予測</target>
        </trans-unit>
        <trans-unit id="b8c5ce2ac34fb5da2d8b838f429e8648259a8b7d" translate="yes" xml:space="preserve">
          <source>Probabilities of the positive class.</source>
          <target state="translated">正のクラスの確率。</target>
        </trans-unit>
        <trans-unit id="7a72cad0169f2057b1b8004ee1b90363ba0148de" translate="yes" xml:space="preserve">
          <source>Probability Calibration curves</source>
          <target state="translated">確率校正曲線</target>
        </trans-unit>
        <trans-unit id="7900c400e7cdc976660ffa4f0dee105d53367a1d" translate="yes" xml:space="preserve">
          <source>Probability Calibration for 3-class classification</source>
          <target state="translated">3クラス分類のための確率校正</target>
        </trans-unit>
        <trans-unit id="f991b7ba9edae7642f119ae6ef707078bd3066c3" translate="yes" xml:space="preserve">
          <source>Probability calibration of classifiers</source>
          <target state="translated">分類器の確率校正</target>
        </trans-unit>
        <trans-unit id="d2584ee2a9c243a3c860610b53b4c4f8f0422b7b" translate="yes" xml:space="preserve">
          <source>Probability calibration with isotonic regression or sigmoid.</source>
          <target state="translated">等張回帰やシグモイドを用いた確率校正。</target>
        </trans-unit>
        <trans-unit id="7f0eccc6df8627c4942515691dfa00c7351059c0" translate="yes" xml:space="preserve">
          <source>Probability estimates.</source>
          <target state="translated">確率の推定。</target>
        </trans-unit>
        <trans-unit id="d0d52fb38133a888fd3aa915d919f9ed6dbe0e0a" translate="yes" xml:space="preserve">
          <source>Probability estimates. Returns prediction probabilities for each class of each output.</source>
          <target state="translated">確率の推定値。各出力のクラスごとの予測確率を返します。</target>
        </trans-unit>
        <trans-unit id="0be5c62048ae898d969e355c844df7dab0872138" translate="yes" xml:space="preserve">
          <source>Probability of each class for each output.</source>
          <target state="translated">各出力に対する各クラスの確率。</target>
        </trans-unit>
        <trans-unit id="a3469242fe22b27dd5f462fbaa08f5294924374d" translate="yes" xml:space="preserve">
          <source>Proceedings of the National Academy of Sciences of the United States of America, 17, 684-688.</source>
          <target state="translated">全米科学アカデミー紀要、17、684-688。</target>
        </trans-unit>
        <trans-unit id="86eb67953eb5361e43195eeccf42c1fb9d6add56" translate="yes" xml:space="preserve">
          <source>Producing multilabel data as a list of sets of labels may be more intuitive. The &lt;a href=&quot;generated/sklearn.preprocessing.multilabelbinarizer#sklearn.preprocessing.MultiLabelBinarizer&quot;&gt;&lt;code&gt;MultiLabelBinarizer&lt;/code&gt;&lt;/a&gt; transformer can be used to convert between a collection of collections of labels and the indicator format.</source>
          <target state="translated">ラベルのセットのリストとしてマルチラベルデータを作成すると、より直感的になります。&lt;a href=&quot;generated/sklearn.preprocessing.multilabelbinarizer#sklearn.preprocessing.MultiLabelBinarizer&quot;&gt; &lt;code&gt;MultiLabelBinarizer&lt;/code&gt; の&lt;/a&gt;変圧器は、ラベルのコレクションの収集および表示フォーマット間で変換するために使用することができます。</target>
        </trans-unit>
        <trans-unit id="c38ce5d3aa68fdc5564263b0a75294394128f498" translate="yes" xml:space="preserve">
          <source>Product-kernel k1 * k2 of two kernels k1 and k2.</source>
          <target state="translated">2つのカーネルk1、k2のプロダクトカーネルk1*k2。</target>
        </trans-unit>
        <trans-unit id="c68fd05a1da7c4a69a9f93ddd88df0d8f044754a" translate="yes" xml:space="preserve">
          <source>Project data to maximize class separation.</source>
          <target state="translated">クラス分離を最大化するためにデータを投影します。</target>
        </trans-unit>
        <trans-unit id="0deb0c8bb98c410f297f471bfa590b75799342d3" translate="yes" xml:space="preserve">
          <source>Project the data by using matrix product with the random matrix</source>
          <target state="translated">ランダム行列を用いた行列積を用いてデータを投影する</target>
        </trans-unit>
        <trans-unit id="3cafaf1856c5864caddd32d157eb3c94637dffac" translate="yes" xml:space="preserve">
          <source>Project the sample on the first eigenvectors of the graph Laplacian.</source>
          <target state="translated">ラプラシアングラフの第一固有ベクトルにサンプルを投影します。</target>
        </trans-unit>
        <trans-unit id="eeba6a10d868ab69fe1fe32234efb9f05e44d5f7" translate="yes" xml:space="preserve">
          <source>Projected array.</source>
          <target state="translated">投影された配列。</target>
        </trans-unit>
        <trans-unit id="607a04b14a3061b3ee01cf35bf1821ab09c2621b" translate="yes" xml:space="preserve">
          <source>Projection of the fitted data on the kernel principal components. Only available when &lt;code&gt;fit_inverse_transform&lt;/code&gt; is True.</source>
          <target state="translated">カーネルの主成分に当てはめられたデータの投影。 &lt;code&gt;fit_inverse_transform&lt;/code&gt; がTrueの場合にのみ使用できます。</target>
        </trans-unit>
        <trans-unit id="5809589bdde4dffc3b2ba5d27cf1889c0519e160" translate="yes" xml:space="preserve">
          <source>Proline</source>
          <target state="translated">Proline</target>
        </trans-unit>
        <trans-unit id="7277492923bbc0874b58459caf363fcc7aa732fe" translate="yes" xml:space="preserve">
          <source>Proline:</source>
          <target state="translated">Proline:</target>
        </trans-unit>
        <trans-unit id="94bda99c1a5b7a6f489592ddeacfcc207544b838" translate="yes" xml:space="preserve">
          <source>Proper choice of &lt;code&gt;C&lt;/code&gt; and &lt;code&gt;gamma&lt;/code&gt; is critical to the SVM&amp;rsquo;s performance. One is advised to use &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;sklearn.model_selection.GridSearchCV&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;C&lt;/code&gt; and &lt;code&gt;gamma&lt;/code&gt; spaced exponentially far apart to choose good values.</source>
          <target state="translated">&lt;code&gt;C&lt;/code&gt; および &lt;code&gt;gamma&lt;/code&gt; 適切な選択は、SVMのパフォーマンスにとって重要です。適切な値を選択するには、 &lt;code&gt;C&lt;/code&gt; と指数関数的に離れた &lt;code&gt;gamma&lt;/code&gt; 間隔で&lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;sklearn.model_selection.GridSearchCV&lt;/code&gt; &lt;/a&gt;を使用することをお勧めします。</target>
        </trans-unit>
        <trans-unit id="e8c0f82584351898447c0af1ff6fac83767fe6e2" translate="yes" xml:space="preserve">
          <source>Provide a custom 2D slice (height, width) to extract the &amp;lsquo;interesting&amp;rsquo; part of the jpeg files and avoid use statistical correlation from the background</source>
          <target state="translated">カスタム2Dスライス（高さ、幅）を提供して、jpegファイルの「興味深い」部分を抽出し、バックグラウンドからの統計的相関の使用を回避します</target>
        </trans-unit>
        <trans-unit id="401552ccdc1a2b894fefbad77ce746fa94f1502b" translate="yes" xml:space="preserve">
          <source>Provides randomized train/test indices to split data according to a third-party provided group. This group information can be used to encode arbitrary domain specific stratifications of the samples as integers.</source>
          <target state="translated">サードパーティが提供するグループに従ってデータを分割するためのランダム化された訓練/テスト指標を提供します。このグループ情報は、サンプルの任意のドメイン固有の層別を整数としてエンコードするために使用できます。</target>
        </trans-unit>
        <trans-unit id="b95f7cbbc68460952b8007ef379d30753e697620" translate="yes" xml:space="preserve">
          <source>Provides train/test indices to split data according to a third-party provided group. This group information can be used to encode arbitrary domain specific stratifications of the samples as integers.</source>
          <target state="translated">サードパーティが提供するグループに従ってデータを分割するための訓練/テスト指標を提供します。このグループ情報は、サンプルの任意のドメイン固有の層別を整数でエンコードするために使用することができます。</target>
        </trans-unit>
        <trans-unit id="6798759d21441243ae32b56e342e6cf117102678" translate="yes" xml:space="preserve">
          <source>Provides train/test indices to split data in train/test sets.</source>
          <target state="translated">訓練/テストセットでデータを分割するための訓練/テスト指標を提供します。</target>
        </trans-unit>
        <trans-unit id="80c518815627489551da4e7aede124327387378b" translate="yes" xml:space="preserve">
          <source>Provides train/test indices to split data in train/test sets. Each sample is used once as a test set (singleton) while the remaining samples form the training set.</source>
          <target state="translated">データを訓練/テスト セットに分割するための訓練/テスト指標を提供します。各サンプルはテストセット(シングルトン)として一度だけ使用され,残りのサンプルは訓練セットを形成します.</target>
        </trans-unit>
        <trans-unit id="d92edad2bb7b04c8f656b2d3e1cacd4550e6c9b7" translate="yes" xml:space="preserve">
          <source>Provides train/test indices to split data in train/test sets. Split dataset into k consecutive folds (without shuffling by default).</source>
          <target state="translated">訓練/テストセットでデータを分割するための訓練/テスト指標を提供します。データセットを連続したk個の折り目に分割します(デフォルトではシャッフリングなし)。</target>
        </trans-unit>
        <trans-unit id="c17c74386e1c6a7aabe03b07d13a8c489665dcde" translate="yes" xml:space="preserve">
          <source>Provides train/test indices to split data in train/test sets. This results in testing on all distinct samples of size p, while the remaining n - p samples form the training set in each iteration.</source>
          <target state="translated">データを訓練/テストセットに分割するための訓練/テスト指標を提供します.これにより,サイズpの異なるすべてのサンプルでテストが行われ,残りのn-pのサンプルが各反復で訓練セットを形成します.</target>
        </trans-unit>
        <trans-unit id="0b345715ee21f67aa1ac76dcd84f4dd63b2400ec" translate="yes" xml:space="preserve">
          <source>Provides train/test indices to split data into train/test sets using a predefined scheme specified by the user with the &lt;code&gt;test_fold&lt;/code&gt; parameter.</source>
          <target state="translated">ユーザーが &lt;code&gt;test_fold&lt;/code&gt; パラメーターで指定した事前定義のスキームを使用して、データをトレーニング/テストセットに分割するトレーニング/テストインデックスを提供します。</target>
        </trans-unit>
        <trans-unit id="ee8342073c20f61dda821a037809875c94eefda5" translate="yes" xml:space="preserve">
          <source>Provides train/test indices to split time series data samples that are observed at fixed time intervals, in train/test sets. In each split, test indices must be higher than before, and thus shuffling in cross validator is inappropriate.</source>
          <target state="translated">一定の時間間隔で観測された時系列データサンプルを、訓練/検定セットで分割するための訓練/検定指標を提供します。各分割では、テスト指標は以前よりも高くなければならないため、クロスバリデータでのシャッフルは不適切です。</target>
        </trans-unit>
        <trans-unit id="945e7a8384d2da4b225924cb75d10785d215f6cf" translate="yes" xml:space="preserve">
          <source>Pseudo number generator state used for random sampling to use if &lt;code&gt;max_patches&lt;/code&gt; is not None. If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;max_patches&lt;/code&gt; がNoneでない場合に使用するランダムサンプリングに使用される疑似番号ジェネレーターの状態。intの場合、random_stateは乱数ジェネレータによって使用されるシードです。RandomStateインスタンスの場合、random_stateは乱数ジェネレーターです。Noneの場合、乱数ジェネレータはnp.randomによって使用される &lt;code&gt;np.random&lt;/code&gt; インスタンスです。</target>
        </trans-unit>
        <trans-unit id="803474f379c178cad6e69fb90dfcf68b796a35e4" translate="yes" xml:space="preserve">
          <source>Pseudo random number generator state used for random uniform sampling from lists of possible values instead of scipy.stats distributions. If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;.</source>
          <target state="translated">scipy.stats分布ではなく、可能な値のリストからのランダムな一様サンプリングに使用される疑似乱数ジェネレーターの状態。intの場合、random_stateは乱数ジェネレータによって使用されるシードです。RandomStateインスタンスの場合、random_stateは乱数ジェネレーターです。Noneの場合、乱数ジェネレータはnp.randomによって使用される &lt;code&gt;np.random&lt;/code&gt; インスタンスです。</target>
        </trans-unit>
        <trans-unit id="32576f4fedc07f63020353af6a8aac66c4452c4c" translate="yes" xml:space="preserve">
          <source>Purple</source>
          <target state="translated">Purple</target>
        </trans-unit>
        <trans-unit id="c148aded3d47eba6bad059e92b2038d207b0a750" translate="yes" xml:space="preserve">
          <source>Putting it all together</source>
          <target state="translated">まとめてみると</target>
        </trans-unit>
        <trans-unit id="7bde8f50695aefe070915f77203ce68cdd0ec96c" translate="yes" xml:space="preserve">
          <source>PyFuncDistance</source>
          <target state="translated">PyFuncDistance</target>
        </trans-unit>
        <trans-unit id="f784952b2caa6ead69a91bdde883011035968631" translate="yes" xml:space="preserve">
          <source>Q&amp;amp;A communities with Machine Learning practitioners</source>
          <target state="translated">機械学習の実践者がいるQ＆Aコミュニティ</target>
        </trans-unit>
        <trans-unit id="448c1c19b8a6bb6b2012b55ce0301b3d1329f717" translate="yes" xml:space="preserve">
          <source>Quadratic Discriminant Analysis</source>
          <target state="translated">二次判別分析</target>
        </trans-unit>
        <trans-unit id="2b0963d1d3fb9914f2ed8fd196a39ab8fff37584" translate="yes" xml:space="preserve">
          <source>Quantile (&lt;code&gt;'quantile'&lt;/code&gt;): A loss function for quantile regression. Use &lt;code&gt;0 &amp;lt; alpha &amp;lt; 1&lt;/code&gt; to specify the quantile. This loss function can be used to create prediction intervals (see &lt;a href=&quot;../auto_examples/ensemble/plot_gradient_boosting_quantile#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-quantile-py&quot;&gt;Prediction Intervals for Gradient Boosting Regression&lt;/a&gt;).</source>
          <target state="translated">変位値（ &lt;code&gt;'quantile'&lt;/code&gt; 変位値'）：変位値回帰の損失関数。分位数を指定するには、 &lt;code&gt;0 &amp;lt; alpha &amp;lt; 1&lt;/code&gt; を使用します。この損失関数は、予測区間の作成に使用できます（&lt;a href=&quot;../auto_examples/ensemble/plot_gradient_boosting_quantile#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-quantile-py&quot;&gt;勾配ブースティング回帰の予測区間を&lt;/a&gt;参照）。</target>
        </trans-unit>
        <trans-unit id="5a4c3292979c373b2215d627b1f0e779a581f51d" translate="yes" xml:space="preserve">
          <source>QuantileTransformer (Gaussian output)</source>
          <target state="translated">分位変換器(ガウス出力</target>
        </trans-unit>
        <trans-unit id="50891a888ce3bdb733921e829099a1dfa838c084" translate="yes" xml:space="preserve">
          <source>QuantileTransformer (uniform output)</source>
          <target state="translated">分位変換器(一様出力</target>
        </trans-unit>
        <trans-unit id="da4a84c34a00e3e1cb33c39f3ec53c51c9f24633" translate="yes" xml:space="preserve">
          <source>Quantiles of references.</source>
          <target state="translated">参照の定量化。</target>
        </trans-unit>
        <trans-unit id="3048da3a0073f2ccdb93631cd0e0196ff4c577ae" translate="yes" xml:space="preserve">
          <source>Query for k-nearest neighbors</source>
          <target state="translated">k-最近接のクエリ</target>
        </trans-unit>
        <trans-unit id="084cb8b1b8700d8f5e04c594627648c98a813511" translate="yes" xml:space="preserve">
          <source>Query for neighbors within a given radius</source>
          <target state="translated">指定された半径内の隣人を検索する</target>
        </trans-unit>
        <trans-unit id="04d13e86aec7343500316f89a39a673fcfb27484" translate="yes" xml:space="preserve">
          <source>Query points where the GP is evaluated</source>
          <target state="translated">GPが評価されるクエリポイント</target>
        </trans-unit>
        <trans-unit id="3aa6f6433021c4ee60eb31aa3da49dd739b377c2" translate="yes" xml:space="preserve">
          <source>Query points where the GP samples are evaluated</source>
          <target state="translated">GP サンプルを評価するクエリポイント</target>
        </trans-unit>
        <trans-unit id="455083cac2ae96eabe3895762b6080aa09e6afa4" translate="yes" xml:space="preserve">
          <source>Quick Start</source>
          <target state="translated">クイックスタート</target>
        </trans-unit>
        <trans-unit id="a30289e02d2b2cc535be5bc56bf89de1f97250a5" translate="yes" xml:space="preserve">
          <source>Quick utility that wraps input validation and &lt;code&gt;next(ShuffleSplit().split(X, y))&lt;/code&gt; and application to input data into a single call for splitting (and optionally subsampling) data in a oneliner.</source>
          <target state="translated">入力の検証と &lt;code&gt;next(ShuffleSplit().split(X, y))&lt;/code&gt; およびアプリケーションをラップして、1つのライナーでデータを分割（およびオプションでサブサンプリング）するための単一の呼び出しにデータを入力するクイックユーティリティ。</target>
        </trans-unit>
        <trans-unit id="53fd6e58cc2ae2f146db69f1fd015c25bb18c639" translate="yes" xml:space="preserve">
          <source>Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.</source>
          <target state="translated">クインラン、R.(1993).インスタンスベース学習とモデルベース学習の組み合わせ.第10回機械学習国際会議議事録,236-243,マサチューセッツ大学,アマースト.モーガン・カウフマン.</target>
        </trans-unit>
        <trans-unit id="3c95cd07e406f573d2cfd2507858b18867a12835" translate="yes" xml:space="preserve">
          <source>R. Baeza-Yates and B. Ribeiro-Neto (2011). Modern Information Retrieval. Addison Wesley, pp. 327-328.</source>
          <target state="translated">R.我が国の情報検索の現状と今後の課題 現代情報検索.アディソンウェズリー,327-328 頁。</target>
        </trans-unit>
        <trans-unit id="df834b32ec211735af556a020ed4c6c4292bf968" translate="yes" xml:space="preserve">
          <source>R. Bharat Rao, G. Fung, R. Rosales, &lt;a href=&quot;http://people.csail.mit.edu/romer/papers/CrossVal_SDM08.pdf&quot;&gt;On the Dangers of Cross-Validation. An Experimental Evaluation&lt;/a&gt;, SIAM 2008;</source>
          <target state="translated">R. Bharat Rao、&lt;a href=&quot;http://people.csail.mit.edu/romer/papers/CrossVal_SDM08.pdf&quot;&gt;G。Fung、R。Rosales、クロス検証の危険性について。実験的評価&lt;/a&gt;、SIAM 2008;</target>
        </trans-unit>
        <trans-unit id="4a52a977177c4f8d61f3e67f49be99e2f11395f3" translate="yes" xml:space="preserve">
          <source>R. Kohavi, &lt;a href=&quot;http://web.cs.iastate.edu/~jtian/cs573/Papers/Kohavi-IJCAI-95.pdf&quot;&gt;A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection&lt;/a&gt;, Intl. Jnt. Conf. AI</source>
          <target state="translated">R.コハビ、&lt;a href=&quot;http://web.cs.iastate.edu/~jtian/cs573/Papers/Kohavi-IJCAI-95.pdf&quot;&gt;精度推定とモデル選択のための相互検証とブートストラップの研究&lt;/a&gt;、国際。Jnt。会議 AI</target>
        </trans-unit>
        <trans-unit id="f5beb165dbcf077fd6c3c894825f204dec27c8ce" translate="yes" xml:space="preserve">
          <source>R. Salakhutdinov, Lecture notes on Statistical Machine Learning, &lt;a href=&quot;http://www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture2.pdf#page=15&quot;&gt;http://www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture2.pdf#page=15&lt;/a&gt; Their beta is our &lt;code&gt;self.alpha_&lt;/code&gt; Their alpha is our &lt;code&gt;self.lambda_&lt;/code&gt;</source>
          <target state="translated">R. &lt;code&gt;self.alpha_&lt;/code&gt; 、統計的機械学習に関する講義ノート、&lt;a href=&quot;http://www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture2.pdf#page=15&quot;&gt;http：&lt;/a&gt;//www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture2.pdf#page=15彼らのベータは私たちのself.alpha_彼らのアルファは私たちの &lt;code&gt;self.lambda_&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="06a2c6e6810e408b785e7ba0833fdf5208de2658" translate="yes" xml:space="preserve">
          <source>R. Salakhutdinov, Lecture notes on Statistical Machine Learning, &lt;a href=&quot;http://www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture2.pdf#page=15&quot;&gt;http://www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture2.pdf#page=15&lt;/a&gt; Their beta is our &lt;code&gt;self.alpha_&lt;/code&gt; Their alpha is our &lt;code&gt;self.lambda_&lt;/code&gt; ARD is a little different than the slide: only dimensions/features for which &lt;code&gt;self.lambda_ &amp;lt; self.threshold_lambda&lt;/code&gt; are kept and the rest are discarded.</source>
          <target state="translated">R. &lt;code&gt;self.alpha_&lt;/code&gt; 、統計的機械学習に関する講義ノート、&lt;a href=&quot;http://www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture2.pdf#page=15&quot;&gt;http：&lt;/a&gt;//www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture2.pdf#page=15彼らのベータは私たちのself.alpha_彼らのアルファは私たちの &lt;code&gt;self.lambda_&lt;/code&gt; ARDはスライドとは少し異なります &lt;code&gt;self.lambda_ &amp;lt; self.threshold_lambda&lt;/code&gt; が保持され、残りは破棄される寸法/機能のみです。</target>
        </trans-unit>
        <trans-unit id="35207f47d4b817edd2ee6adcf1187c7a288d720f" translate="yes" xml:space="preserve">
          <source>R.A. Fisher</source>
          <target state="translated">アール・エー・フィッシャー</target>
        </trans-unit>
        <trans-unit id="c2cddd6bced899ad676535e0ceef48ff2d428d74" translate="yes" xml:space="preserve">
          <source>RAD index of accessibility to radial highways</source>
          <target state="translated">放射状の高速道路へのアクセス性の指標であるRAD</target>
        </trans-unit>
        <trans-unit id="8eff9a296f9566c8db7b6b5b5fd0f247ff670023" translate="yes" xml:space="preserve">
          <source>RANSAC (RANdom SAmple Consensus) algorithm.</source>
          <target state="translated">RANSAC(RANdom SAmple Consensus)アルゴリズム。</target>
        </trans-unit>
        <trans-unit id="295f973b9a9300cc4103fcf54629f3b800f88e4f" translate="yes" xml:space="preserve">
          <source>RANSAC (RANdom SAmple Consensus) fits a model from random subsets of inliers from the complete data set.</source>
          <target state="translated">RANSAC(RANdom SAmple Consensus)は、完全なデータセットからインライアのランダムなサブセットからモデルをフィットします。</target>
        </trans-unit>
        <trans-unit id="4cf25210dfc0ed0440695332f6a59a107387063c" translate="yes" xml:space="preserve">
          <source>RANSAC is a non-deterministic algorithm producing only a reasonable result with a certain probability, which is dependent on the number of iterations (see &lt;code&gt;max_trials&lt;/code&gt; parameter). It is typically used for linear and non-linear regression problems and is especially popular in the fields of photogrammetric computer vision.</source>
          <target state="translated">RANSACは非決定論的アルゴリズムであり、一定の確率で妥当な結果のみを &lt;code&gt;max_trials&lt;/code&gt; ます。これは反復回数に依存します（max_trialsパラメーターを参照）。これは通常、線形および非線形の回帰問題に使用され、写真測量法のコンピュータビジョンの分野で特に人気があります。</target>
        </trans-unit>
        <trans-unit id="661ac344672202ee8ecff33a0aca47b5e992477c" translate="yes" xml:space="preserve">
          <source>RANSAC is an iterative algorithm for the robust estimation of parameters from a subset of inliers from the complete data set. More information can be found in the general documentation of linear models.</source>
          <target state="translated">RANSACは、完全なデータセットからのインライアのサブセットからのパラメータのロバスト推定のための反復アルゴリズムです。詳細は、線形モデルの一般的なドキュメントを参照してください。</target>
        </trans-unit>
        <trans-unit id="5d2efa163922c4ec9e798ae0634c77ba2e679034" translate="yes" xml:space="preserve">
          <source>RANSAC is good for strong outliers in the y direction</source>
          <target state="translated">RANSACは、y方向の強い外れ値に適しています。</target>
        </trans-unit>
        <trans-unit id="727c2ad1e5500736136b6da9e8482929b66a5466" translate="yes" xml:space="preserve">
          <source>RANSAC iteration stops if at least one outlier-free set of the training data is sampled in RANSAC. This requires to generate at least N samples (iterations):</source>
          <target state="translated">RANSACの反復は,学習データの少なくとも1つの外れ値のない集合がRANSACでサンプリングされた場合に停止します.これには、少なくともN個のサンプル(反復)を生成する必要があります。</target>
        </trans-unit>
        <trans-unit id="a5b4d61d1cab95dc9e6144de1c3f9e94fd26ef69" translate="yes" xml:space="preserve">
          <source>RBF SVM parameters</source>
          <target state="translated">RBF SVMパラメータ</target>
        </trans-unit>
        <trans-unit id="b8891243ca9d81f286f0231789762195095e1f07" translate="yes" xml:space="preserve">
          <source>RM average number of rooms per dwelling</source>
          <target state="translated">RM 1住戸あたりの平均部屋数</target>
        </trans-unit>
        <trans-unit id="98a077cbb4113833d5208bfbafc39182a47953a4" translate="yes" xml:space="preserve">
          <source>ROC curves are typically used in binary classification to study the output of a classifier. In order to extend ROC curve and ROC area to multi-class or multi-label classification, it is necessary to binarize the output. One ROC curve can be drawn per label, but one can also draw a ROC curve by considering each element of the label indicator matrix as a binary prediction (micro-averaging).</source>
          <target state="translated">ROC曲線は,通常,2値分類で分類器の出力を調べるために使用される.ROC曲線とROC面積をマルチクラスまたはマルチラベル分類に拡張するためには、出力を2値化する必要があります。ラベルごとに1つのROC曲線を描くことができますが、ラベル指標行列の各要素を2値予測(マイクロ平均化)として考慮してROC曲線を描くこともできます。</target>
        </trans-unit>
        <trans-unit id="388c7e4d8a2582b488580ddabb4d2fdc26d0d1ba" translate="yes" xml:space="preserve">
          <source>ROC curves typically feature true positive rate on the Y axis, and false positive rate on the X axis. This means that the top left corner of the plot is the &amp;ldquo;ideal&amp;rdquo; point - a false positive rate of zero, and a true positive rate of one. This is not very realistic, but it does mean that a larger area under the curve (AUC) is usually better.</source>
          <target state="translated">ROC曲線は通常、Y軸に真陽性率、X軸に偽陽性率を特徴とします。これは、プロットの左上隅が「理想的な」点であることを意味します-偽陽性率はゼロ、真陽性率は1です。これはあまり現実的ではありませんが、曲線下の領域（AUC）が大きいほど通常は優れていることを意味します。</target>
        </trans-unit>
        <trans-unit id="69dad40e2617c9d14cd69fd75838d06f4d48f71b" translate="yes" xml:space="preserve">
          <source>R^2 (coefficient of determination) regression score function.</source>
          <target state="translated">R^2(決定係数)回帰スコア関数。</target>
        </trans-unit>
        <trans-unit id="b808463e306b97b5a3ff3b44e6d61af7bafdc346" translate="yes" xml:space="preserve">
          <source>R^2 is calculated by weighting all the targets equally using &lt;code&gt;multioutput=&amp;rsquo;uniform_average&amp;rsquo;&lt;/code&gt;.</source>
          <target state="translated">R ^ 2は、 &lt;code&gt;multioutput=&amp;rsquo;uniform_average&amp;rsquo;&lt;/code&gt; を使用してすべてのターゲットに等しく重み付けすることにより計算されます。</target>
        </trans-unit>
        <trans-unit id="51faef534dffb60f7f795741b3c905f12ad6fcd4" translate="yes" xml:space="preserve">
          <source>R^2 of self.predict(X) wrt. y.</source>
          <target state="translated">self.predict(X)のR^2 wrt.</target>
        </trans-unit>
        <trans-unit id="67a54398f816039662fed018be4b060a58e05be0" translate="yes" xml:space="preserve">
          <source>Radial-basis function kernel (aka squared-exponential kernel).</source>
          <target state="translated">放射基底関数カーネル(別名:2乗指数カーネル)。</target>
        </trans-unit>
        <trans-unit id="b1c9a7baa5630e2f9f25e6f54a8403ae874316cf" translate="yes" xml:space="preserve">
          <source>Radius from the data point to its neighbors. This is the parameter space to use by default for the &lt;a href=&quot;#sklearn.neighbors.LSHForest.radius_neighbors&quot;&gt;&lt;code&gt;radius_neighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">データポイントからその近傍までの半径。これは、&lt;a href=&quot;#sklearn.neighbors.LSHForest.radius_neighbors&quot;&gt; &lt;code&gt;radius_neighbors&lt;/code&gt; &lt;/a&gt;クエリにデフォルトで使用するパラメータスペースです。</target>
        </trans-unit>
        <trans-unit id="52546dfd6d7c7fb64ada7c2055d0a73c0acf8a37" translate="yes" xml:space="preserve">
          <source>Radius of neighborhoods.</source>
          <target state="translated">近隣の半径。</target>
        </trans-unit>
        <trans-unit id="18a73d913fa1abfc301eb3a68cafe4343426b8e2" translate="yes" xml:space="preserve">
          <source>Radius of neighborhoods. (default is the value passed to the constructor).</source>
          <target state="translated">近所の半径。(デフォルトはコンストラクタに渡される値)。</target>
        </trans-unit>
        <trans-unit id="d0dee7bedc06eaed94a632203a4c4fa7194bffee" translate="yes" xml:space="preserve">
          <source>Raise DataConversionWarning if the dtype of the input data structure does not match the requested dtype, causing a memory copy.</source>
          <target state="translated">入力データ構造体のdtypeが要求されたdtypeと一致しない場合にDataConversionWarningを発生させ、メモリコピーを引き起こします。</target>
        </trans-unit>
        <trans-unit id="fe6245a65da1996031b65e42c6ba6186170ca87f" translate="yes" xml:space="preserve">
          <source>Raises ValueError if the value is not present.</source>
          <target state="translated">値が存在しない場合、ValueErrorを発生させます。</target>
        </trans-unit>
        <trans-unit id="e0eb5268f437200e3ca42ec2d178bdfb80e8e252" translate="yes" xml:space="preserve">
          <source>Raises:</source>
          <target state="translated">Raises:</target>
        </trans-unit>
        <trans-unit id="d16a67e334dfd48a0a32b29b147c93c066c816a2" translate="yes" xml:space="preserve">
          <source>Rand index adjusted for chance.</source>
          <target state="translated">ランド指数は偶然性で調整されています。</target>
        </trans-unit>
        <trans-unit id="eef943cf5777ab68b59f488d7a530508b73f81f0" translate="yes" xml:space="preserve">
          <source>Random Projection transformers</source>
          <target state="translated">ランダムプロジェクショントランス</target>
        </trans-unit>
        <trans-unit id="7ff48c336307e3c2ce6f2f979b7933b4de524c7a" translate="yes" xml:space="preserve">
          <source>Random Projections are a simple and computationally efficient way to reduce the dimensionality of the data by trading a controlled amount of accuracy (as additional variance) for faster processing times and smaller model sizes.</source>
          <target state="translated">ランダム投影は、制御された量の精度(追加の分散として)を高速な処理時間とより小さなモデルサイズと交換することで、データの次元を減らすためのシンプルで計算効率の良い方法です。</target>
        </trans-unit>
        <trans-unit id="a3f73f31693ddbad455b46a8d17e5abb90516927" translate="yes" xml:space="preserve">
          <source>Random matrix used for the projection.</source>
          <target state="translated">投影に用いられるランダム行列.</target>
        </trans-unit>
        <trans-unit id="08cddbad297e64d14193f5b5d56ff553c1ead4e1" translate="yes" xml:space="preserve">
          <source>Random partitioning produces noticeable shorter paths for anomalies. Hence, when a forest of random trees collectively produce shorter path lengths for particular samples, they are highly likely to be anomalies.</source>
          <target state="translated">ランダム分割では、異常値のパス長が顕著に短くなります。したがって、ランダムな木の森が集合的に特定のサンプルに対して短いパスの長さを生成する場合、それは異常値である可能性が高いです。</target>
        </trans-unit>
        <trans-unit id="cdc045e1f132e01fd79e2d9fde788bc8349e0d53" translate="yes" xml:space="preserve">
          <source>Random partitioning produces noticeably shorter paths for anomalies. Hence, when a forest of random trees collectively produce shorter path lengths for particular samples, they are highly likely to be anomalies.</source>
          <target state="translated">ランダム分割では、異常値のパスの長さが顕著に短くなります。したがって、ランダムな木の森が集合的に特定のサンプルに対してより短いパス長を生成する場合、それは異常値である可能性が高いです。</target>
        </trans-unit>
        <trans-unit id="e902a98b1d56eb80837cfffbe014c142a3c23724" translate="yes" xml:space="preserve">
          <source>Random permutation cross-validator</source>
          <target state="translated">ランダム順列クロスバリデーター</target>
        </trans-unit>
        <trans-unit id="835fe40af3cd4f15aecec9da1e1cbde64b6f2679" translate="yes" xml:space="preserve">
          <source>Random state to be used to generate random state for each repetition.</source>
          <target state="translated">繰り返しごとにランダム状態を発生させるために使用するランダム状態。</target>
        </trans-unit>
        <trans-unit id="e77fd902e1e7bbe038e94aceba57278c27f39882" translate="yes" xml:space="preserve">
          <source>RandomForestClassifier shows the opposite behavior: the histograms show peaks at approx. 0.2 and 0.9 probability, while probabilities close to 0 or 1 are very rare. An explanation for this is given by Niculescu-Mizil and Caruana &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;: &amp;ldquo;Methods such as bagging and random forests that average predictions from a base set of models can have difficulty making predictions near 0 and 1 because variance in the underlying base models will bias predictions that should be near zero or one away from these values. Because predictions are restricted to the interval [0,1], errors caused by variance tend to be one- sided near zero and one. For example, if a model should predict p = 0 for a case, the only way bagging can achieve this is if all bagged trees predict zero. If we add noise to the trees that bagging is averaging over, this noise will cause some trees to predict values larger than 0 for this case, thus moving the average prediction of the bagged ensemble away from 0. We observe this effect most strongly with random forests because the base-level trees trained with random forests have relatively high variance due to feature subsetting.&amp;rdquo; As a result, the calibration curve shows a characteristic sigmoid shape, indicating that the classifier could trust its &amp;ldquo;intuition&amp;rdquo; more and return probabilities closer to 0 or 1 typically.</source>
          <target state="translated">RandomForestClassifierは、反対の動作を示します。ヒストグラムは、ピークのピークを示します。0.2と0.9の確率、0または1に近い確率は非常にまれです。これについての説明はNiculescu-MizilとCaruana &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;によって与えられます：「基本モデルのセットからの予測を平均化するバギングやランダムフォレストなどの方法では、0と1に近い予測を行うことが困難になる可能性があります。予測は区間[0,1]に制限されるため、分散によって引き起こされるエラーは、0と1の近くで片側になる傾向があります。たとえば、モデルがケースのp = 0を予測する必要がある場合、バギングがこれを達成できる唯一の方法は、すべてのバギングされたツリーがゼロを予測することです。バギングが平均化しているツリーにノイズを追加すると、このノイズにより、一部のツリーはこのケースで0より大きい値を予測するため、バギングされた集団の平均予測が0から離れます。ランダムフォレストでトレーニングされたベースレベルツリーは、フィーチャのサブセット化により比較的高い分散を持っているため、この効果はランダムフォレストで最も強く観察されます。」その結果、検量線は特徴的なシグモイド形状を示し、分類子がその「直感」をより信頼して、通常は0または1に近い確率を返すことができることを示しています。</target>
        </trans-unit>
        <trans-unit id="b99b7c8dc6c457a8dec14cbefe28c82d1fdc19eb" translate="yes" xml:space="preserve">
          <source>RandomTreesEmbedding provides a way to map data to a very high-dimensional, sparse representation, which might be beneficial for classification. The mapping is completely unsupervised and very efficient.</source>
          <target state="translated">RandomTreesEmbeddingは、データを非常に高次元で疎な表現にマッピングする方法を提供します。このマッピングは完全に教師なしで非常に効率的です。</target>
        </trans-unit>
        <trans-unit id="fba143cc92cd33e7d750cb7779216504b5193fb4" translate="yes" xml:space="preserve">
          <source>Randomized CV splitters may return different results for each call of split. You can make the results identical by setting &lt;code&gt;random_state&lt;/code&gt; to an integer.</source>
          <target state="translated">ランダム化されたCVスプリッターは、splitの呼び出しごとに異なる結果を返す場合があります。 &lt;code&gt;random_state&lt;/code&gt; を整数に設定することにより、結果を同一にすることができます。</target>
        </trans-unit>
        <trans-unit id="7464de894f093d84c4a6e238c86ee9b0e6ef0d8b" translate="yes" xml:space="preserve">
          <source>Randomized Lasso works by subsampling the training data and computing a Lasso estimate where the penalty of a random subset of coefficients has been scaled. By performing this double randomization several times, the method assigns high scores to features that are repeatedly selected across randomizations. This is known as stability selection. In short, features selected more often are considered good features.</source>
          <target state="translated">ランダム化ラッソは、学習データをサブサンプリングし、係数のランダムなサブセットのペナルティがスケーリングされたラッソ推定値を計算することで動作します。この二重ランダム化を数回実行することで、この手法は、ランダム化の間に繰り返し選択される特徴に高いスコアを割り当てます。これは安定性選択として知られている。つまり、より頻繁に選択された特徴は、良い特徴とみなされます。</target>
        </trans-unit>
        <trans-unit id="46be6112d7c7d476c8b2b96ef46abfdfb711fda9" translate="yes" xml:space="preserve">
          <source>Randomized Lasso.</source>
          <target state="translated">無作為化ラッソ。</target>
        </trans-unit>
        <trans-unit id="e0e91c3b39c638d46ace3d061876a15beae00989" translate="yes" xml:space="preserve">
          <source>Randomized Logistic Regression</source>
          <target state="translated">無作為化ロジスティック回帰</target>
        </trans-unit>
        <trans-unit id="d7cc1de7e1283020198535d0f5589374b5b37f13" translate="yes" xml:space="preserve">
          <source>Randomized Logistic Regression works by subsampling the training data and fitting a L1-penalized LogisticRegression model where the penalty of a random subset of coefficients has been scaled. By performing this double randomization several times, the method assigns high scores to features that are repeatedly selected across randomizations. This is known as stability selection. In short, features selected more often are considered good features.</source>
          <target state="translated">ランダム化ロジスティック回帰は、学習データをサブサンプリングし、係数のランダムなサブセットのペナルティがスケーリングされたL1ペナルティ付きロジスティック回帰モデルを適合させることで動作します。この二重ランダム化を数回実行することで、この手法は、ランダム化の間に繰り返し選択される特徴に高いスコアを割り当てます。これは安定性選択として知られている。つまり、より頻繁に選択された特徴は、良い特徴とみなされます。</target>
        </trans-unit>
        <trans-unit id="9c540f986182775d4f1b2b5266d9f715e8609064" translate="yes" xml:space="preserve">
          <source>Randomized search on hyper parameters.</source>
          <target state="translated">ハイパーパラメータのランダム検索。</target>
        </trans-unit>
        <trans-unit id="727b24e973f7ce53a485ba2d90a0fb546aaa5480" translate="yes" xml:space="preserve">
          <source>RandomizedSearchCV implements a &amp;ldquo;fit&amp;rdquo; and a &amp;ldquo;score&amp;rdquo; method. It also implements &amp;ldquo;predict&amp;rdquo;, &amp;ldquo;predict_proba&amp;rdquo;, &amp;ldquo;decision_function&amp;rdquo;, &amp;ldquo;transform&amp;rdquo; and &amp;ldquo;inverse_transform&amp;rdquo; if they are implemented in the estimator used.</source>
          <target state="translated">RandomizedSearchCVは、「フィット」および「スコア」メソッドを実装します。また、使用する推定器に実装されている場合は、「predict」、「predict_proba」、「decision_function」、「transform」、「inverse_transform」も実装します。</target>
        </trans-unit>
        <trans-unit id="a124e99274671f5884ebb748c86ad3cc6e10ed0a" translate="yes" xml:space="preserve">
          <source>Randomly generated sample</source>
          <target state="translated">ランダムに生成されたサンプル</target>
        </trans-unit>
        <trans-unit id="6bc3f06c954afb75fec23342d87819aaba0adca2" translate="yes" xml:space="preserve">
          <source>Range of parameter space to use by default for &lt;a href=&quot;#sklearn.neighbors.NearestNeighbors.radius_neighbors&quot;&gt;&lt;code&gt;radius_neighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">&lt;a href=&quot;#sklearn.neighbors.NearestNeighbors.radius_neighbors&quot;&gt; &lt;code&gt;radius_neighbors&lt;/code&gt; &lt;/a&gt;クエリにデフォルトで使用するパラメーター空間の範囲。</target>
        </trans-unit>
        <trans-unit id="d69f1c514ebc77e035c833c4b788288dbd9d7d3a" translate="yes" xml:space="preserve">
          <source>Range of parameter space to use by default for &lt;a href=&quot;#sklearn.neighbors.RadiusNeighborsClassifier.radius_neighbors&quot;&gt;&lt;code&gt;radius_neighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">&lt;a href=&quot;#sklearn.neighbors.RadiusNeighborsClassifier.radius_neighbors&quot;&gt; &lt;code&gt;radius_neighbors&lt;/code&gt; &lt;/a&gt;クエリにデフォルトで使用するパラメーター空間の範囲。</target>
        </trans-unit>
        <trans-unit id="ccf6560d01359860d9981044e8888921c69a1ebc" translate="yes" xml:space="preserve">
          <source>Range of parameter space to use by default for &lt;a href=&quot;#sklearn.neighbors.RadiusNeighborsRegressor.radius_neighbors&quot;&gt;&lt;code&gt;radius_neighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">&lt;a href=&quot;#sklearn.neighbors.RadiusNeighborsRegressor.radius_neighbors&quot;&gt; &lt;code&gt;radius_neighbors&lt;/code&gt; &lt;/a&gt;クエリにデフォルトで使用するパラメーター空間の範囲。</target>
        </trans-unit>
        <trans-unit id="f1e258c2a1109b8940bd4b1e4eed34edbe1fde37" translate="yes" xml:space="preserve">
          <source>Ratio of non-zero component in the random projection matrix.</source>
          <target state="translated">ランダム射影行列の非ゼロ成分の比率。</target>
        </trans-unit>
        <trans-unit id="8b08645b475105905425ba5f5c101503a63ea50f" translate="yes" xml:space="preserve">
          <source>Ratio used to resize the each face picture.</source>
          <target state="translated">各顔写真のサイズ変更に使用される比率。</target>
        </trans-unit>
        <trans-unit id="af6620521bd29965067000a75da79809db3afb7f" translate="yes" xml:space="preserve">
          <source>Rational Quadratic kernel.</source>
          <target state="translated">有理二次カーネル。</target>
        </trans-unit>
        <trans-unit id="ea59ceaf3b393b30c1c8d72ec111e141f43eeeef" translate="yes" xml:space="preserve">
          <source>Ravel column or 1d numpy array, else raises an error</source>
          <target state="translated">Ravelカラムまたは1次元のnumpy配列、そうでない場合はエラーになります。</target>
        </trans-unit>
        <trans-unit id="8293b10d1c331b776cfe76bddf88b79c491fcbac" translate="yes" xml:space="preserve">
          <source>Raw estimates can be accessed as &lt;code&gt;raw_location_&lt;/code&gt; and &lt;code&gt;raw_covariance_&lt;/code&gt; attributes of a &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt;&lt;code&gt;MinCovDet&lt;/code&gt;&lt;/a&gt; robust covariance estimator object.</source>
          <target state="translated">生の推定値には、&lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt; &lt;code&gt;MinCovDet&lt;/code&gt; &lt;/a&gt;ロバスト共分散推定子オブジェクトの &lt;code&gt;raw_location_&lt;/code&gt; および &lt;code&gt;raw_covariance_&lt;/code&gt; 属性としてアクセスできます。</target>
        </trans-unit>
        <trans-unit id="7a51ea0e85a0f81236be43da3cb18bbf7d090e93" translate="yes" xml:space="preserve">
          <source>Raw image</source>
          <target state="translated">生の画像</target>
        </trans-unit>
        <trans-unit id="ec15241caecff75c6d32741bba14ecbe2c0152ff" translate="yes" xml:space="preserve">
          <source>Raw scoring function of the samples.</source>
          <target state="translated">サンプルの生のスコアリング関数。</target>
        </trans-unit>
        <trans-unit id="443ae37519752c5de5e0cde248d4844d13b0b355" translate="yes" xml:space="preserve">
          <source>Re-weight observations using Rousseeuw&amp;rsquo;s method (equivalent to deleting outlying observations from the data set before computing location and covariance estimates) described in &lt;a href=&quot;#r9465bad4668c-rvdriessen&quot; id=&quot;id6&quot;&gt;[RVDriessen]&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#r9465bad4668c-rvdriessen&quot; id=&quot;id6&quot;&gt;[RVDriessen]で&lt;/a&gt;説明されているRousseeuwの方法を使用して観測値を再重み付けします（位置と共分散の推定値を計算する前にデータセットから外れている観測値を削除することと同じです）。</target>
        </trans-unit>
        <trans-unit id="811aa24c73d44be5265f8db35e1aba02e43f5167" translate="yes" xml:space="preserve">
          <source>Re-weight observations using Rousseeuw&amp;rsquo;s method (equivalent to deleting outlying observations from the data set before computing location and covariance estimates) described in &lt;a href=&quot;#rd2c89e63f1c9-rvdriessen&quot; id=&quot;id4&quot;&gt;[RVDriessen]&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#rd2c89e63f1c9-rvdriessen&quot; id=&quot;id4&quot;&gt;[RVDriessen]で&lt;/a&gt;説明されているRousseeuwの方法を使用して観測値を再重み付けします（位置と共分散の推定値を計算する前にデータセットから外れている観測値を削除することと同じです）。</target>
        </trans-unit>
        <trans-unit id="1fe70f858d89020443d7d8345c1f02d89d6ccd93" translate="yes" xml:space="preserve">
          <source>Re-weight raw Minimum Covariance Determinant estimates.</source>
          <target state="translated">生の最小共分散決定力推定値を再重み付けします。</target>
        </trans-unit>
        <trans-unit id="6cb1bab89173046e86d32a76aea708a020205876" translate="yes" xml:space="preserve">
          <source>Re-weighted robust covariance estimate.</source>
          <target state="translated">再重み付けされたロバスト共分散推定値。</target>
        </trans-unit>
        <trans-unit id="7c1d2fed66b789c1352f92c94963e51426ea249d" translate="yes" xml:space="preserve">
          <source>Re-weighted robust location estimate.</source>
          <target state="translated">再重み付けされたロバストな位置推定値。</target>
        </trans-unit>
        <trans-unit id="b4cfab0f3b2467caeb2e1bedf3c18c73b01c7da8" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#boston-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../../datasets/index#boston-dataset&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="cb1e120b331b23a9ea1593b6a6404dddbbf78f2a" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#breast-cancer-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../../datasets/index#breast-cancer-dataset&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="45cb9dd939a999d831c07cc2e3e7ed643cf488a4" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#california-housing-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../../datasets/index#california-housing-dataset&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="eccf3b3816b9590ebdeba4771d3acc5f4e159b2e" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#covtype-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../../datasets/index#covtype-dataset&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="d4bb3e966e3f5178d7f7c4a61126a58124c52a9d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#datasets&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../../datasets/index#datasets&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="e4eedc3904e3680ac48f3d5f08f3a25ab49b2093" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#diabetes-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../../datasets/index#diabetes-dataset&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="c9d0dc8f7e9cd1a47f16f6e56a93e432e5e7f1e3" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#digits-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../../datasets/index#digits-dataset&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="782264ebf6818f03e85e8b9bd3386d8a9677a337" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#iris-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../../datasets/index#iris-dataset&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="d52fb8cbe534543faa8555a91b64dff64e3dea0d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#kddcup99-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../../datasets/index#kddcup99-dataset&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="6a4f56eaf393056504ca6ff95442d562e2504be6" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#labeled-faces-in-the-wild-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../../datasets/index#labeled-faces-in-the-wild-dataset&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="4da395463b2e4202f4daff9e84c23d64de9c6f05" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#linnerrud-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../../datasets/index#linnerrud-dataset&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="53a74e4331e38be5dfe4615ecb0251f124a205e3" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#newsgroups-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../../datasets/index#newsgroups-dataset&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="dce5d9eecff0f524d4dec775f90afdf42f5a110a" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#olivetti-faces-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../../datasets/index#olivetti-faces-dataset&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="21a9979f9639169e833f8c2f7d58dccf530dd101" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#openml&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../../datasets/index#openml&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="716aae22fdfaa4b0a01611fc142c61fa672a0972" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#rcv1-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../../datasets/index#rcv1-dataset&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="11adccfb6f94431df3dd0d991fe405585bda6ae8" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#sample-generators&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../../datasets/index#sample-generators&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="35447ff590c92f7b4f003f24713aa2c9a81298a5" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#sample-images&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../../datasets/index#sample-images&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="4853b3528d5b03002784a57acc74b0ef73704bc1" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#wine-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../../datasets/index#wine-dataset&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="ff64d1a0ea7fdf7ff58d5025e9e080a8cec7c72c" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../biclustering#biclustering&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../biclustering#biclustering&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="c316b1ee3fa8c904650e89cb99da69896eccc6a5" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../biclustering#spectral-biclustering&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../biclustering#spectral-biclustering&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="33b53761153553cd62c19c209bb628778cf329c8" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../biclustering#spectral-coclustering&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../biclustering#spectral-coclustering&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="8ad1d496a9fc7afe128ac29316cc3f3116982df6" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../calibration#calibration&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../calibration#calibration&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="266b21640ba75b4def05823d912c707e5b485568" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#adjusted-rand-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../clustering#adjusted-rand-score&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="285800162cfb9496523169f1e324d5ca52f05105" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#affinity-propagation&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../clustering#affinity-propagation&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="bee5e31231b24163a354acd1dc67b01773852fa9" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#birch&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../clustering#birch&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="4601587ee80ec2a86d25242c642e0a55dac8fafc" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#calinski-harabaz-index&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../clustering#calinski-harabaz-index&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="51dc466eb21d20d9b69c9e5f15e9274cedda7156" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#davies-bouldin-index&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../clustering#davies-bouldin-index&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="5ef82ad65b3f026f0caf908c608841a43c0efa75" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#dbscan&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../clustering#dbscan&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="a6e99c3c80faf77fafc0a8d86085180cc6c84922" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#fowlkes-mallows-scores&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../clustering#fowlkes-mallows-scores&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="2deecce3a8534f9e96109e5f8de3632504534434" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#hierarchical-clustering&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../clustering#hierarchical-clustering&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="85746bd6fcaa1b3e9726613bf073ebbc8fc899ee" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#homogeneity-completeness&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../clustering#homogeneity-completeness&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="9388af5c27de2b75bebc64aefce142fa8b7c7d87" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#k-means&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../clustering#k-means&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="f3d022ba3260ebedaf289d3105c309efc9b6efaa" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#mean-shift&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../clustering#mean-shift&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="60456e22d7b43c1be16a5ffd202a73d0404f2ce4" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#mini-batch-kmeans&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../clustering#mini-batch-kmeans&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="b5f4de0554a7bf7d30905012caa1476a3b6b0b7b" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#mutual-info-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../clustering#mutual-info-score&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="a801640f61fb99dac3001902d5642fc23f7f3e77" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#silhouette-coefficient&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../clustering#silhouette-coefficient&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="a2bf3b0c073eb6207b67b1a3e36c83ea6726e488" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#spectral-clustering&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../clustering#spectral-clustering&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="4f8b5ece7223f5057b540fbbb2e0213374db36cc" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../compose#column-transformer&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../compose#column-transformer&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="b3ffa6d59d10581030d8ebaf923b865f27e71b6c" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../compose#feature-union&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../compose#feature-union&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="5cda30dc9a38ecc38c0a084e727bc8f53bfeb83b" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../compose#pipeline&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../compose#pipeline&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="5e5e7bbc971353e91c75e63e500acb2d00125efb" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../covariance#covariance&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../covariance#covariance&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="4fd0b000ed57c1d00035b4f4b9abc2d7e21344ad" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../covariance#robust-covariance&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../covariance#robust-covariance&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="593f740064fd46ca53be3aa05a901df13d8d0214" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../covariance#shrunk-covariance&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../covariance#shrunk-covariance&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="539672df79f8f6a03d60ca9c514700c2198c23e8" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../covariance#sparse-inverse-covariance&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../covariance#sparse-inverse-covariance&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="31cb66e394f44d8290eaed833952db069ac6d5f6" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../cross_decomposition#cross-decomposition&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../cross_decomposition#cross-decomposition&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="73b9c5b0bf3f15999aa7f6cf39a5cf5f9ac28e23" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../cross_validation#cross-validation&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../cross_validation#cross-validation&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="0a6b3a0c6a7adcce79528b7536a4eef927a01b03" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../cross_validation#multimetric-cross-validation&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../cross_validation#multimetric-cross-validation&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="3933407dde4f24717b49d900bb199e83da0af6d6" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#dictionarylearning&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../decomposition#dictionarylearning&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="692c1ee94a7258b331b868686a17925ad7fbb5f7" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#fa&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../decomposition#fa&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="0b7c7e1938dbc6a19025fdf48af1845f47ea0202" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#ica&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../decomposition#ica&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="64bc77c9ae79b3fad979d7f7107dc9933f245093" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#incrementalpca&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../decomposition#incrementalpca&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="6ef55752e42e18cb66d8ffbcf35815ce578503a7" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#kernel-pca&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../decomposition#kernel-pca&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="df1e3b94f33a2daaffb97b3f696d829a9acf5c23" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#latentdirichletallocation&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">詳細については、&lt;a href=&quot;../decomposition#latentdirichletallocation&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
