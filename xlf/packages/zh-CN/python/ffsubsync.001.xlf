<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="zh-CN" datatype="htmlbody" original="https://pypi.org/project/ffsubsync/">
    <body>
      <group id="ffsubsync">
        <trans-unit id="448fa61d60809d27051e5604a1053eafdfc3dbbb" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;http://www.numpy.org/&quot;&gt;numpy&lt;/a&gt; and, indirectly, &lt;a href=&quot;https://www.netlib.org/fftpack/&quot;&gt;FFTPACK&lt;/a&gt;, which powers the FFT-based algorithm for fast scoring of alignments between subtitles (or subtitles and video)</source>
          <target state="translated">&lt;a href=&quot;http://www.numpy.org/&quot;&gt;numpy&lt;/a&gt;和&lt;a href=&quot;https://www.netlib.org/fftpack/&quot;&gt;FFTPACK&lt;/a&gt;（间接地），它支持基于FFT的算法，以快速计分字幕（或字幕和视频）之间的对齐方式</target>
        </trans-unit>
        <trans-unit id="809173aad90d1b10ce189edf1551d1b0699e2f6a" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;https://pypi.org/project/srt/&quot;&gt;srt&lt;/a&gt; for operating on &lt;a href=&quot;https://en.wikipedia.org/wiki/SubRip#SubRip_text_file_format&quot;&gt;SRT files&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;https://pypi.org/project/srt/&quot;&gt;srt&lt;/a&gt;用于操作&lt;a href=&quot;https://en.wikipedia.org/wiki/SubRip#SubRip_text_file_format&quot;&gt;SRT文件&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b1d4e9959623befe0fa4c1f81c6a08d9ec02186a" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;https://www.ffmpeg.org/&quot;&gt;ffmpeg&lt;/a&gt; and the &lt;a href=&quot;https://github.com/kkroening/ffmpeg-python&quot;&gt;ffmpeg-python&lt;/a&gt; wrapper, for extracting raw audio from video</source>
          <target state="translated">&lt;a href=&quot;https://www.ffmpeg.org/&quot;&gt;ffmpeg&lt;/a&gt;和&lt;a href=&quot;https://github.com/kkroening/ffmpeg-python&quot;&gt;ffmpeg-python&lt;/a&gt;包装器，用于从视频中提取原始音频</target>
        </trans-unit>
        <trans-unit id="f402db43144acbb0439ef8edcbe14c9699525da0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;ffs&lt;/code&gt;, &lt;code&gt;subsync&lt;/code&gt; and &lt;code&gt;ffsubsync&lt;/code&gt; all work as entrypoints:</source>
          <target state="translated">&lt;code&gt;ffs&lt;/code&gt; ， &lt;code&gt;subsync&lt;/code&gt; 和 &lt;code&gt;ffsubsync&lt;/code&gt; 都可以用作入口点：</target>
        </trans-unit>
        <trans-unit id="14b64238bfe66703a43272be5c9729b5ca77e61f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;ffsubsync&lt;/code&gt; uses the file extension to decide whether to perform voice activity
detection on the audio or to directly extract speech from an srt file.</source>
          <target state="translated">&lt;code&gt;ffsubsync&lt;/code&gt; 使用文件扩展名来决定是对音频执行语音活动检测还是直接从srt文件提取语音。</target>
        </trans-unit>
        <trans-unit id="00799ba9e026c577347c81635a03c034bba3e14e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;ffsubsync&lt;/code&gt; usually finishes in 20 to 30 seconds, depending on the length of the
video. The most expensive step is actually extraction of raw audio. If you
already have a correctly synchronized &quot;reference&quot; srt file (in which case audio
extraction can be skipped), &lt;code&gt;ffsubsync&lt;/code&gt; typically runs in less than a second.</source>
          <target state="translated">&lt;code&gt;ffsubsync&lt;/code&gt; 通常在20到30秒内完成，具体取决于视频的长度。最昂贵的步骤实际上是提取原始音频。如果您已经有一个正确同步的&amp;ldquo;参考&amp;rdquo; srt文件（在这种情况下可以跳过音频提取），则 &lt;code&gt;ffsubsync&lt;/code&gt; 通常在不到一秒钟的时间内运行。</target>
        </trans-unit>
        <trans-unit id="936db9a8629b6aee1da2ac35146b55e3ac7b77db" translate="yes" xml:space="preserve">
          <source>At the request of some, you can now help cover my coffee expenses using the
Github Sponsors button at the top (recurring monthly payments), or using the below
Paypal Donate button (one-time payment):</source>
          <target state="translated">应一些人的要求,您现在可以使用顶部的Github赞助商按钮(每月定期支付),或使用下面的Paypal捐赠按钮(一次性支付)来帮助我支付咖啡费用。</target>
        </trans-unit>
        <trans-unit id="56f9b02e470ae04f5605651b0ca5cd5920c7d715" translate="yes" xml:space="preserve">
          <source>Besides general stability and usability improvements, one line
of work aims to extend the synchronization algorithm to handle splits
/ breaks in the middle of video not present in subtitles (or vice versa).
Developing a robust solution will take some time (assuming one is possible).
See &lt;a href=&quot;https://github.com/smacke/ffsubsync/issues/10&quot;&gt;#10&lt;/a&gt; for more details.</source>
          <target state="translated">除了总体稳定性和可用性方面的改进之外，一项工作旨在扩展同步算法，以处理字幕中不存在的视频中间的分割/中断（反之亦然）。开发可靠的解决方案将需要一些时间（假设有可能）。有关更多详细信息，请参见&lt;a href=&quot;https://github.com/smacke/ffsubsync/issues/10&quot;&gt;＃10&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="bd217ff4214f14c1a032a45a800183c165249895" translate="yes" xml:space="preserve">
          <source>Code in this project is &lt;a href=&quot;https://opensource.org/licenses/MIT&quot;&gt;MIT licensed&lt;/a&gt;.</source>
          <target state="translated">该项目中的代码已&lt;a href=&quot;https://opensource.org/licenses/MIT&quot;&gt;获得MIT许可&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="bfac50d6424b5166c3ee2808c85ae7c139b5182f" translate="yes" xml:space="preserve">
          <source>Credits</source>
          <target state="translated">学分</target>
        </trans-unit>
        <trans-unit id="1946ed4e6d7a5cdee8942980594304622d5d448e" translate="yes" xml:space="preserve">
          <source>Discretize video and subtitles by time into 10ms windows.</source>
          <target state="translated">将视频和字幕按时间划分为10ms的窗口。</target>
        </trans-unit>
        <trans-unit id="61f87fb699391c08f8809648c3d512e2529450b6" translate="yes" xml:space="preserve">
          <source>FFsubsync</source>
          <target state="translated">FFsubsync</target>
        </trans-unit>
        <trans-unit id="d14e9d216a8814e80e6ada0f122fa233375bf1ab" translate="yes" xml:space="preserve">
          <source>First, make sure ffmpeg is installed. On MacOS, this looks like:</source>
          <target state="translated">首先,确保安装了ffmpeg。在MacOS上,这看起来像。</target>
        </trans-unit>
        <trans-unit id="42edbb52a87cd00061f18e023951cf7cd5c5ef15" translate="yes" xml:space="preserve">
          <source>For each 10ms window, determine whether that window contains speech.  This
is trivial to do for subtitles (we just determine whether any subtitle is
&quot;on&quot; during each time window); for video, use an off-the-shelf voice
activity detector (VAD) like
the one built into &lt;a href=&quot;https://webrtc.org/&quot;&gt;webrtc&lt;/a&gt;.</source>
          <target state="translated">对于每个10毫秒的窗口，请确定该窗口是否包含语音。对于字幕而言，这是微不足道的（我们只需确定每个时间窗口内是否有任何字幕处于&amp;ldquo;打开&amp;rdquo;状态）即可；对于视频，请使用现成的语音活动检测器（VAD），例如内置于&lt;a href=&quot;https://webrtc.org/&quot;&gt;webrtc的&lt;/a&gt;语音活动检测器。</target>
        </trans-unit>
        <trans-unit id="c3cba160fe064a0d9a4fc24f20540221a2aff0ed" translate="yes" xml:space="preserve">
          <source>Future Work</source>
          <target state="translated">今后的工作</target>
        </trans-unit>
        <trans-unit id="ad0a916130b1ffb1194d9d811a12d26d58f8df6c" translate="yes" xml:space="preserve">
          <source>Helping Development</source>
          <target state="translated">帮助发展</target>
        </trans-unit>
        <trans-unit id="90ccd6497400b5576aeca1bd94af74aae1e0a250" translate="yes" xml:space="preserve">
          <source>History</source>
          <target state="translated">历程</target>
        </trans-unit>
        <trans-unit id="8cecc82d72d68f9151cb0901cfe40eeac15bfca6" translate="yes" xml:space="preserve">
          <source>How It Works</source>
          <target state="translated">它是如何工作的</target>
        </trans-unit>
        <trans-unit id="44abaabed373ce699f3a6b3019932545e4158606" translate="yes" xml:space="preserve">
          <source>If you want to live dangerously, you can grab the latest version as follows:</source>
          <target state="translated">如果你想过危险的生活,可以按以下方式抢到最新版本。</target>
        </trans-unit>
        <trans-unit id="ce1d79c980df3c47404d3d29df7c08886649970a" translate="yes" xml:space="preserve">
          <source>In most cases, inconsistencies between video and subtitles occur when starting
or ending segments present in video are not present in subtitles, or vice versa.
This can occur, for example, when a TV episode recap in the subtitles was pruned
from video. FFsubsync typically works well in these cases, and in my experience
this covers &amp;gt;95% of use cases. Handling breaks and splits outside of the beginning
and ending segments is left to future work (see below).</source>
          <target state="translated">在大多数情况下，当字幕中不存在视频中出现的开始或结束片段时，就会发生视频与字幕之间的不一致，反之亦然。例如，当从视频中删除字幕中的电视剧集摘要时，可能会发生这种情况。FFsubsync通常在这些情况下效果很好，以我的经验，这涵盖了超过95％的用例。处理起点和终点之外的中断和拆分留待以后的工作（见下文）。</target>
        </trans-unit>
        <trans-unit id="fd6c3ebf7befca9f8208f86c76e4d4180303745c" translate="yes" xml:space="preserve">
          <source>Install</source>
          <target state="translated">安装</target>
        </trans-unit>
        <trans-unit id="659525747c675f26d0d0761f93182ab5228cbc26" translate="yes" xml:space="preserve">
          <source>Into this:</source>
          <target state="translated">进入这个。</target>
        </trans-unit>
        <trans-unit id="0d05fd8158dba0121b4eac110b20f240f7818b92" translate="yes" xml:space="preserve">
          <source>Language-agnostic automatic synchronization of subtitles with video, so that
subtitles are aligned to the correct starting point within the video.</source>
          <target state="translated">语言无关的字幕与视频的自动同步,使字幕与视频中的正确起点对齐。</target>
        </trans-unit>
        <trans-unit id="420a9347981effc83ba7d1df62790a49716f38bb" translate="yes" xml:space="preserve">
          <source>Language-agnostic synchronization of subtitles with video.</source>
          <target state="translated">视频字幕与语言无关的同步。</target>
        </trans-unit>
        <trans-unit id="3229609e15436ec51bcf00818a69a84dbc58a0c2" translate="yes" xml:space="preserve">
          <source>License</source>
          <target state="translated">许可证</target>
        </trans-unit>
        <trans-unit id="a7c04c64ed3f2a9374590c76c50d3b7f1b18e3da" translate="yes" xml:space="preserve">
          <source>Limitations</source>
          <target state="translated">局限性</target>
        </trans-unit>
        <trans-unit id="beac1d4d9d908d34bbabd5497b31900615c1e739" translate="yes" xml:space="preserve">
          <source>Next, grab the script. It should work with both Python 2 and Python 3:</source>
          <target state="translated">接下来,抓取脚本。它应该同时适用于Python 2和Python 3。</target>
        </trans-unit>
        <trans-unit id="179a4231cbcf797a1ea61865a797b3047681d7b0" translate="yes" xml:space="preserve">
          <source>Now we have two binary strings: one for the subtitles, and one for the
video.  Try to align these strings by matching 0's with 0's and 1's with
1's. We score these alignments as (# video 1's matched w/ subtitle 1's) - (#
video 1's matched with subtitle 0's).</source>
          <target state="translated">现在我们有两个二进制字符串:一个是字幕,一个是视频。试着将这些字符串对齐,将0与0匹配,将1与1匹配。我们将这些排列的结果记为 (#视频1与字幕1的匹配)-(#视频1与字幕0的匹配)。</target>
        </trans-unit>
        <trans-unit id="bc49bcc1bbf9322f0d673c127d5dd1764357aa92" translate="yes" xml:space="preserve">
          <source>Other excellent Python libraries like &lt;a href=&quot;https://docs.python.org/3/library/argparse.html&quot;&gt;argparse&lt;/a&gt; and &lt;a href=&quot;https://tqdm.github.io/&quot;&gt;tqdm&lt;/a&gt;, not related to the core functionality, but which enable much better experiences for developers and users.</source>
          <target state="translated">其他出色的Python库（例如&lt;a href=&quot;https://docs.python.org/3/library/argparse.html&quot;&gt;argparse&lt;/a&gt;和&lt;a href=&quot;https://tqdm.github.io/&quot;&gt;tqdm&lt;/a&gt;）与核心功能无关，但它们为开发人员和用户提供了更好的体验。</target>
        </trans-unit>
        <trans-unit id="2d2cb022bc3d26bd1407c4aa787d5e46e1ad4c3b" translate="yes" xml:space="preserve">
          <source>Speed</source>
          <target state="translated">速度</target>
        </trans-unit>
        <trans-unit id="6d75a7aec098fab5da5f5616cd98e0d6589fb421" translate="yes" xml:space="preserve">
          <source>The best-scoring alignment from step 3 determines how to offset the subtitles
in time so that they are properly synced with the video. Because the binary
strings are fairly long (millions of digits for video longer than an hour), the
naive O(n^2) strategy for scoring all alignments is unacceptable. Instead, we
use the fact that &quot;scoring all alignments&quot; is a convolution operation and can
be implemented with the Fast Fourier Transform (FFT), bringing the complexity
down to O(n log n).</source>
          <target state="translated">第 3 步的最佳得分对齐决定了如何及时偏移字幕,使其与视频正确同步。因为二进制字符串是相当长的(对于超过一小时的视频来说,有数百万位数字),所以对所有排列进行评分的天真的O(n^2)策略是不可接受的。取而代之的是,我们利用 &quot;对所有排列进行评分 &quot;是一种卷积操作,可以用快速傅里叶变换(FFT)来实现,使复杂度降低到O(n log n)。</target>
        </trans-unit>
        <trans-unit id="b6cb2e1a9df05d019e4ce2e098c42168484163b6" translate="yes" xml:space="preserve">
          <source>The implementation for this project was started during HackIllinois 2019, for
which it received an &lt;strong&gt;&lt;em&gt;Honorable Mention&lt;/em&gt;&lt;/strong&gt; (ranked in the top 5 projects,
excluding projects that won company-specific prizes).</source>
          <target state="translated">该项目的实施始于HackIllinois 2019年，为此获得了&lt;strong&gt;&lt;em&gt;荣誉奖&lt;/em&gt;&lt;/strong&gt;（在前5个项目中排名，不包括获得公司特定奖项的项目）。</target>
        </trans-unit>
        <trans-unit id="c24de39b3bb0b16a5df396d44c3f3aebba913c44" translate="yes" xml:space="preserve">
          <source>The synchronization algorithm operates in 3 steps:</source>
          <target state="translated">同步算法的操作分为3个步骤。</target>
        </trans-unit>
        <trans-unit id="94226cd553bfe5c121e7a05322ec2c6041760ba8" translate="yes" xml:space="preserve">
          <source>There may be occasions where you have a correctly synchronized srt file in a
language you are unfamiliar with, as well as an unsynchronized srt file in your
native language. In this case, you can use the correctly synchronized srt file
directly as a reference for synchronization, instead of using the video as the
reference:</source>
          <target state="translated">在某些情况下,您可能有一个您不熟悉的语言的正确同步的 srt 文件,以及一个母语的未同步的 srt 文件。在这种情况下,您可以直接使用正确同步的 srt 文件作为同步的参考,而不是使用视频作为参考。</target>
        </trans-unit>
        <trans-unit id="da9f448081113e5f2aa6a2b4381ed0a353647124" translate="yes" xml:space="preserve">
          <source>This project would not be possible without the following libraries:</source>
          <target state="translated">如果没有下列图书馆,这个项目是不可能的。</target>
        </trans-unit>
        <trans-unit id="7240d4aab825d0799c8f63afc0c0ff0047392b6e" translate="yes" xml:space="preserve">
          <source>Turn this:</source>
          <target state="translated">把这个。</target>
        </trans-unit>
        <trans-unit id="0bb18642b70b9f8a9c12ccf39487328f306b8e19" translate="yes" xml:space="preserve">
          <source>Usage</source>
          <target state="translated">使用方法</target>
        </trans-unit>
        <trans-unit id="75a062ef757a8dddb6401a1ad2fd757ca432ebd9" translate="yes" xml:space="preserve">
          <source>VAD from &lt;a href=&quot;https://webrtc.org/&quot;&gt;webrtc&lt;/a&gt; and the &lt;a href=&quot;https://github.com/wiseman/py-webrtcvad&quot;&gt;py-webrtcvad&lt;/a&gt; wrapper, for speech detection</source>
          <target state="translated">来自&lt;a href=&quot;https://webrtc.org/&quot;&gt;webrtc&lt;/a&gt;和&lt;a href=&quot;https://github.com/wiseman/py-webrtcvad&quot;&gt;py-webrtcvad&lt;/a&gt;包装器的VAD ，用于语音检测</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
