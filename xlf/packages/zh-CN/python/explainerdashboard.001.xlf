<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="zh-CN" datatype="htmlbody" original="https://pypi.org/project/explainerdashboard/">
    <body>
      <group id="explainerdashboard">
        <trans-unit id="9ee5d8eb55b415d7876a91d8495d6c15e33492f6" translate="yes" xml:space="preserve">
          <source>A deployed example can be found at &lt;a href=&quot;http://titanicexplainer.herokuapp.com&quot;&gt;http://titanicexplainer.herokuapp.com&lt;/a&gt;</source>
          <target state="translated">可以在&lt;a href=&quot;http://titanicexplainer.herokuapp.com&quot;&gt;http://titanicexplainer.herokuapp.com&lt;/a&gt;上找到已部署的示例。</target>
        </trans-unit>
        <trans-unit id="9872150fbb680cdfd6947cd74baf88cda51c21b5" translate="yes" xml:space="preserve">
          <source>Alternatively, there is a built-in standard dashboard with pre-built tabs that
you can select individually.</source>
          <target state="translated">另外,还有一个内置的标准仪表板,上面有预埋的标签,你可以单独选择。</target>
        </trans-unit>
        <trans-unit id="1e2438e36f54d0a04883ce24b50410159bbd4e8f" translate="yes" xml:space="preserve">
          <source>Explain the inner workings of the model to the people working with so</source>
          <target state="translated">向工作中的人解释模型的内部运作,所以。</target>
        </trans-unit>
        <trans-unit id="956570964781b8f14ba6fd79bdff8eb328fb4a2b" translate="yes" xml:space="preserve">
          <source>For Random Forests: what is the prediction of each individual decision</source>
          <target state="translated">对于随机森林:每个个体决策的预测是什么?</target>
        </trans-unit>
        <trans-unit id="439a0ee1bffc7d1c05880dacabeb8be72a661d71" translate="yes" xml:space="preserve">
          <source>For regression models: goodness-of-fit plots, residual plots, etc.</source>
          <target state="translated">对于回归模型:拟合度图、残差图等。</target>
        </trans-unit>
        <trans-unit id="0840799b642e4c33daacc261de664ec05f7d0de5" translate="yes" xml:space="preserve">
          <source>In a lot of organizations, especially governmental, but with the GDPR also
increasingly in private sector, it becomes more and more important to be able
to explain the inner workings of your machine learning algorithms. Customers
have to some extent a right to an explanation why they were selected, and
more and more internal and external regulators require it. With recent
innovations in explainable AI (e.g. SHAP values) the old black box trope is
no longer valid, but it can still take quite a bit of data wrangling and
plot manipulation to get the explanations out of a model. This library aims
to make this easy.</source>
          <target state="translated">在很多组织中,尤其是政府部门,但随着GDPR也越来越多地出现在私营部门,能够解释你的机器学习算法的内部运作变得越来越重要。客户在一定程度上有权利要求解释为什么选择他们,越来越多的内部和外部监管机构要求这样做。随着最近在可解释的人工智能方面的创新(例如SHAP值),旧的黑盒子特例不再有效,但仍然需要相当多的数据纠缠和情节操作才能从模型中得到解释。这个库的目的是让这一切变得简单。</target>
        </trans-unit>
        <trans-unit id="ce70797edf8dee737cfb7d76d179588ccb732ee5" translate="yes" xml:space="preserve">
          <source>Make it easy for data scientists to quickly inspect the workings and</source>
          <target state="translated">让数据科学家们可以轻松地快速检查工作原理和</target>
        </trans-unit>
        <trans-unit id="e0e6a091c7b6b769e7751965cef6e0f580e21c3b" translate="yes" xml:space="preserve">
          <source>Make it easy to build an application that explains individual predictions</source>
          <target state="translated">使得建立一个解释个人预测的应用程序变得容易。</target>
        </trans-unit>
        <trans-unit id="570657f59b22d6c0e862f61913d54708b8a28a8f" translate="yes" xml:space="preserve">
          <source>Make it possible for non data scientist stakeholders such as managers,</source>
          <target state="translated">让管理者等非数据科学家的利益相关者能够。</target>
        </trans-unit>
        <trans-unit id="26b432362191b52a44d047ecf7c47f023a7e0b68" translate="yes" xml:space="preserve">
          <source>PR AUC plot, etc</source>
          <target state="translated">PR AUC图等</target>
        </trans-unit>
        <trans-unit id="a99149c1cddd52e5211d6269453b62dcedc91914" translate="yes" xml:space="preserve">
          <source>Partial dependence plots (how does the model prediction change when</source>
          <target state="translated">部分依赖性图(当以下情况发生时,模型预测如何变化?</target>
        </trans-unit>
        <trans-unit id="9637e7845e9550750cca9ca1769f730b707e2044" translate="yes" xml:space="preserve">
          <source>Permutation importances (how much does the model metric deteriorate</source>
          <target state="translated">检验进口量(模型度量的恶化程度)。</target>
        </trans-unit>
        <trans-unit id="843579748436cadd9bdbfc0627b8628600453fd3" translate="yes" xml:space="preserve">
          <source>Plus for classifiers: precision plots, confusion matrix, ROC AUC plot,</source>
          <target state="translated">另外对于分类器:精度图、混淆矩阵、ROC AUC图。</target>
        </trans-unit>
        <trans-unit id="f8457b04b23a18252f07b47186dea82e93d4952f" translate="yes" xml:space="preserve">
          <source>Shap interaction values (decompose the shap value into a direct effect</source>
          <target state="translated">Shap交互值(将shap值分解为直接效应)。</target>
        </trans-unit>
        <trans-unit id="66164421febfee5d4fb5cce72e46352a0b6daeac" translate="yes" xml:space="preserve">
          <source>Shap values (i.e. what is the contributions of each feature to each</source>
          <target state="translated">形状值(即每个特征对每个特征的贡献是什么?</target>
        </trans-unit>
        <trans-unit id="95ae1c4807c1613b9c7e6ecad1a2de74453f8cd2" translate="yes" xml:space="preserve">
          <source>The goal is manyfold:</source>
          <target state="translated">目标是多方面的。</target>
        </trans-unit>
        <trans-unit id="a073373f8b7010ecf9cc4a55639741bd18e0cc97" translate="yes" xml:space="preserve">
          <source>The library includes:</source>
          <target state="translated">该图书馆包括:</target>
        </trans-unit>
        <trans-unit id="b49daba3b2e4c5bc171af30c431b3af215eb8c35" translate="yes" xml:space="preserve">
          <source>The library is designed to be modular so that it should be easy to design your
own interactive dashboards with plotly dash, with most of the work of calculating
and formatting data, and rendering plots and tables handled by explainerdashboard,
so that you can focus on the layout, logic of the interactions, and project specific
textual explanations of the dashboard. (i.e. design it so that it will be interpretable
for business users in your organization, not just data scientists)</source>
          <target state="translated">该库的设计是模块化的,所以应该很容易用plotly dash设计自己的交互式仪表盘,大部分计算和格式化数据的工作,以及渲染图和表的工作由explorerdashboard处理,这样你就可以专注于仪表盘的布局、交互的逻辑和项目具体的文字解释。(即设计得让你的组织中的业务用户,而不仅仅是数据科学家,都能理解)</target>
        </trans-unit>
        <trans-unit id="801688a2692f1470827e8312cc9124f7845acbd4" translate="yes" xml:space="preserve">
          <source>This package makes it convenient to quickly explain the workings of a
(scikit-learn compatible) fitted machine learning model using either
interactive plots in e.g. Jupyter Notebook or deploying an interactive
dashboard (based on Flask/Dash) that allows you to quickly explore the
impact of different features on model predictions.</source>
          <target state="translated">这个包可以方便地快速解释(scikit-learn兼容)拟合的机器学习模型的工作原理,可以使用Jupyter Notebook中的交互式绘图,也可以部署一个交互式仪表盘(基于Flask/Dash),让你快速探索不同特征对模型预测的影响。</target>
        </trans-unit>
        <trans-unit id="0a2fc32ddada3ac82b829f04fe929cc613f1ba0c" translate="yes" xml:space="preserve">
          <source>an interaction effects)</source>
          <target state="translated">(交互效应)</target>
        </trans-unit>
        <trans-unit id="2519d4d3082fac70ef6fc6c7c10a9214f9da3bc3" translate="yes" xml:space="preserve">
          <source>directors, internal and external watchdogs to interactively inspect
the inner workings of the model without having to depend on a data
scientist to generate every plot and table</source>
          <target state="translated">董事、内部和外部监督者可以交互式检查模型的内部运作,而不必依赖数据科学家来生成每一个图和表。</target>
        </trans-unit>
        <trans-unit id="e79a6ae0690566db6288e82ba34ad824fede5564" translate="yes" xml:space="preserve">
          <source>explainerdashboard allows you quickly build an interactive dashboard to explain the inner workings of your machine learning model.</source>
          <target state="translated">explainerdashboard允许你快速建立一个交互式的仪表盘来解释你的机器学习模型的内部工作原理。</target>
        </trans-unit>
        <trans-unit id="06637564d86372e96635657c4d3a6a6b04414b21" translate="yes" xml:space="preserve">
          <source>individual prediction?)</source>
          <target state="translated">个人预测?)</target>
        </trans-unit>
        <trans-unit id="864162c093c84b184f0ca4e126505c4ec91bd7d6" translate="yes" xml:space="preserve">
          <source>of your model for customers that ask for an explanation</source>
          <target state="translated">你的模型的客户要求解释</target>
        </trans-unit>
        <trans-unit id="bf2baac207e13e27a5e50f7eb16658b606b09dcd" translate="yes" xml:space="preserve">
          <source>performance of their model in a few lines of code</source>
          <target state="translated">在几行代码中就能实现其模型的性能。</target>
        </trans-unit>
        <trans-unit id="e635decc0d3aa6cc070cde811548286b8ecde7f9" translate="yes" xml:space="preserve">
          <source>that they gain understanding what the model does and doesn&amp;rsquo;t do.
This is important so that they can gain an intuition for when the
model is likely missing information and may have to be overruled.</source>
          <target state="translated">他们了解模型的作用和不作用。这一点很重要，这样他们就可以对模型何时可能缺少信息并可能被否决获得直觉。</target>
        </trans-unit>
        <trans-unit id="20d4dbe97dffb8e65303926fe068f0e9a21eaee7" translate="yes" xml:space="preserve">
          <source>tree, and what is the path through each tree? (using dtreeviz)</source>
          <target state="translated">树,而每棵树的路径是什么?(使用dtreeviz)</target>
        </trans-unit>
        <trans-unit id="122aeb029a33af06f90e4f9c3d3eaf2783480525" translate="yes" xml:space="preserve">
          <source>when you shuffle a feature?)</source>
          <target state="translated">当你洗牌一个功能?)</target>
        </trans-unit>
        <trans-unit id="89b99cece506de81c6e01cf826280cdffec7642d" translate="yes" xml:space="preserve">
          <source>you vary a single feature?</source>
          <target state="translated">你改变了一个单一的功能?</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
