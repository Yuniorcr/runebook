<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="zh-CN" datatype="htmlbody" original="https://pypi.org/project/musdb/">
    <body>
      <group id="musdb">
        <trans-unit id="eff1ab2217457363930cfd857d03cbe7acecf8d6" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Track.audio&lt;/code&gt;, stereo mixture as an numpy array of shape &lt;code&gt;(nb_samples, 2)&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;Track.audio&lt;/code&gt; ，立体声混合形式，是一个numpy形状的数组 &lt;code&gt;(nb_samples, 2)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="f5d441d75d5493d97701a4791554c53b1ea63127" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Track.name&lt;/code&gt;, the track name, consisting of &lt;code&gt;Track.artist&lt;/code&gt; and &lt;code&gt;Track.title&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;Track.name&lt;/code&gt; ，轨道名称，由 &lt;code&gt;Track.artist&lt;/code&gt; 和 &lt;code&gt;Track.title&lt;/code&gt; 组成。</target>
        </trans-unit>
        <trans-unit id="0c6e8e4571ff73ce2c0cbe03b66cbafbaf85a2bc" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Track.path&lt;/code&gt;, the absolute path of the mixture which might be handy to process with external applications.</source>
          <target state="translated">&lt;code&gt;Track.path&lt;/code&gt; ，混合物的绝对路径，可能易于使用外部应用程序进行处理。</target>
        </trans-unit>
        <trans-unit id="df352bf2c4ef3c71ca9e9bcd5402bdd8c9d7fb0f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Track.rate&lt;/code&gt;, the sample rate of the mixture.</source>
          <target state="translated">&lt;code&gt;Track.rate&lt;/code&gt; ，混合物的采样率。</target>
        </trans-unit>
        <trans-unit id="47fa7f3db16beaa5f69ea7bc866af4f3fc23f69e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Track.sources&lt;/code&gt;, a dictionary of sources used for this track.</source>
          <target state="translated">&lt;code&gt;Track.sources&lt;/code&gt; ，此轨道使用的源字典。</target>
        </trans-unit>
        <trans-unit id="121d66e2807831beba8db486f18ef6989ba57638" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Track.stems&lt;/code&gt;, an numpy tensor of all five stereo sources of shape &lt;code&gt;(5, nb_samples, 2)&lt;/code&gt;. The stems are always in the following order: &lt;code&gt;['mixture', 'drums', 'bass', 'other', 'vocals']&lt;/code&gt;,</source>
          <target state="translated">&lt;code&gt;Track.stems&lt;/code&gt; ，是所有五个形状为 &lt;code&gt;(5, nb_samples, 2)&lt;/code&gt; 立体声源的numpy张量。词根始终按以下顺序排列： &lt;code&gt;['mixture', 'drums', 'bass', 'other', 'vocals']&lt;/code&gt; ，</target>
        </trans-unit>
        <trans-unit id="e36c9a7e880ef463ca80b642aab1c316c0874d54" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Track.targets&lt;/code&gt;, a dictionary of targets provided for this track.
Note that for MUSDB, the sources and targets differ only in the existence of the &lt;code&gt;accompaniment&lt;/code&gt;, which is the sum of all sources, except for the vocals. MUSDB supports the following targets: &lt;code&gt;['mixture', 'drums', 'bass', 'other', 'vocals', 'accompaniment', 'linear_mixture']&lt;/code&gt;. Note that some of the targets (such as &lt;strong&gt;accompaniment&lt;/strong&gt;) are dynamically mixed on the fly.</source>
          <target state="translated">&lt;code&gt;Track.targets&lt;/code&gt; ，为此轨道提供的目标字典。请注意，对于MUSDB，来源和目标的区别仅在于 &lt;code&gt;accompaniment&lt;/code&gt; 的存在，该伴奏是除声音之外的所有来源的总和。MUSDB支持以下目标： &lt;code&gt;['mixture', 'drums', 'bass', 'other', 'vocals', 'accompaniment', 'linear_mixture']&lt;/code&gt; 。请注意，某些目标（例如&lt;strong&gt;伴奏&lt;/strong&gt;）是动态动态混合的。</target>
        </trans-unit>
        <trans-unit id="33e24b937c4ac43e5fcf63232384893b9f40c24f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;musdb&lt;/code&gt; comes with 7 seconds excerpts (automatically downloaded) of the full dataset for quick evaluation or prototyping. The full dataset, however, needs to be downloaded &lt;a href=&quot;https://zenodo.org/record/1117372&quot;&gt;via Zenodo&lt;/a&gt; and stored (unzipped) separately.</source>
          <target state="translated">&lt;code&gt;musdb&lt;/code&gt; 随附完整数据集的7秒摘录（自动下载），用于快速评估或制作原型。但是，完整的数据集需要&lt;a href=&quot;https://zenodo.org/record/1117372&quot;&gt;通过Zenodo&lt;/a&gt;下载并单独存储（解压缩）。</target>
        </trans-unit>
        <trans-unit id="420a4eb2d0665ef680393c5af54d6fcaa6a78172" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;MUSDB18&lt;/em&gt; comes encoded in &lt;a href=&quot;http://www.stems-music.com/&quot;&gt;STEMS&lt;/a&gt; which is a multitrack audio format that uses &lt;em&gt;lossy compression&lt;/em&gt;. The &lt;code&gt;musdb&lt;/code&gt; package, internally, relies on FFMPEG to decode the multi-stream files. For convenience, we developed a python package called &lt;a href=&quot;https://github.com/faroit/stempeg&quot;&gt;stempeg&lt;/a&gt; that allows to easily parse the stem files and decode them on-the-fly.
When you install &lt;em&gt;musdb&lt;/em&gt; (which depends on &lt;em&gt;stempeg&lt;/em&gt;), it is therefore necessary to also install the FFMPEG library. The installation may differ among operating systems and python distributions:</source>
          <target state="translated">&lt;em&gt;MUSDB18&lt;/em&gt;自带编码&lt;a href=&quot;http://www.stems-music.com/&quot;&gt;茎&lt;/a&gt;这是一个多轨的音频格式，使用&lt;em&gt;有损压缩&lt;/em&gt;。内部的 &lt;code&gt;musdb&lt;/code&gt; 包依赖FFMPEG解码多流文件。为方便起见，我们开发了一个名为&lt;a href=&quot;https://github.com/faroit/stempeg&quot;&gt;stempeg&lt;/a&gt;的python程序包，该程序包可轻松解析主文件并即时对其进行解码。当您安装&lt;em&gt;musdb&lt;/em&gt;（取决于&lt;em&gt;stempeg&lt;/em&gt;）时，因此还必须安装FFMPEG库。操作系统和python发行版之间的安装可能有所不同：</target>
        </trans-unit>
        <trans-unit id="ea0ff0a3bd2dd89256f78e68349fac519239ccf9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;When you use the decoded MUSDB, use the &lt;code&gt;is_wav&lt;/code&gt; parameter when initializing the dataset.&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;使用解码的 &lt;code&gt;is_wav&lt;/code&gt; 时，初始化数据集时请使用is_wav参数。&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="3f265a828664515c2a0a69dd5db40e87c516c584" translate="yes" xml:space="preserve">
          <source>A python package to parse and process the &lt;a href=&quot;https://sigsep.github.io/musdb&quot;&gt;MUSDB18 dataset&lt;/a&gt;, the largest open access dataset for music source separation. The tool was originally developed for the &lt;a href=&quot;sisec18.unmix.app&quot;&gt;Music Separation task&lt;/a&gt; as part of the &lt;a href=&quot;https://sisec.inria.fr/&quot;&gt;Signal Separation Evaluation Campaign (SISEC)&lt;/a&gt;.</source>
          <target state="translated">一个用于解析和处理&lt;a href=&quot;https://sigsep.github.io/musdb&quot;&gt;MUSDB18数据集&lt;/a&gt;的python包，MUSDB18数据集是用于音乐源分离的最大的开放式访问数据集。该工具最初是作为&amp;ldquo;&lt;a href=&quot;sisec18.unmix.app&quot;&gt;音乐分离&amp;rdquo;任务&lt;/a&gt;开发的，是&amp;ldquo;&lt;a href=&quot;https://sisec.inria.fr/&quot;&gt;信号分离评估活动&amp;rdquo;（SISEC）的一部分&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="9f672ccf915a39598644ad9a295ffb1dbd62e8d7" translate="yes" xml:space="preserve">
          <source>Alternatively you can install FFMPEG manually as follows:</source>
          <target state="translated">或者你也可以按以下方法手动安装FFMPEG。</target>
        </trans-unit>
        <trans-unit id="323cf9586a360c76d757f761fea4549f8b45d87e" translate="yes" xml:space="preserve">
          <source>Baselines</source>
          <target state="translated">基线</target>
        </trans-unit>
        <trans-unit id="fd328df32af47ff4f34212c8adf3d3fbaf1aea24" translate="yes" xml:space="preserve">
          <source>Citations</source>
          <target state="translated">引用</target>
        </trans-unit>
        <trans-unit id="ff7513853508e7c6e3aa07908df2a450a026eb88" translate="yes" xml:space="preserve">
          <source>Evaluation</source>
          <target state="translated">评价</target>
        </trans-unit>
        <trans-unit id="5f6443a284213415a14df3c85e12378cf8071af9" translate="yes" xml:space="preserve">
          <source>For oracle methods, please check out our &lt;a href=&quot;https://github.com/sigsep/sigsep-mus-oracle&quot;&gt;open unmix oracle separation methods&lt;/a&gt;.
This will show you how oracle performance is computed and gives indications for an upper bound for the quality of the separation.</source>
          <target state="translated">对于oracle方法，请查看我们的&lt;a href=&quot;https://github.com/sigsep/sigsep-mus-oracle&quot;&gt;开放式unmix oracle分离方法&lt;/a&gt;。这将向您展示如何计算oracle性能，并指出分离质量的上限。</target>
        </trans-unit>
        <trans-unit id="d790b402d79ac1a723c790313bcd679999474630" translate="yes" xml:space="preserve">
          <source>Frequently Asked Questions</source>
          <target state="translated">常问问题</target>
        </trans-unit>
        <trans-unit id="765ce65dc57c23ea4b17c61f7adde7d0f903c740" translate="yes" xml:space="preserve">
          <source>Getting the data</source>
          <target state="translated">获取数据</target>
        </trans-unit>
        <trans-unit id="8e9e47310de9555280cd460663c1dbd0a1adba5b" translate="yes" xml:space="preserve">
          <source>If compare your results with SiSEC 2018 Participants - Cite the SiSEC 2018 LVA/ICA Paper</source>
          <target state="translated">如果将您的结果与SiSEC 2018参与者进行比较-引用SiSEC 2018 LVA/ICA论文。</target>
        </trans-unit>
        <trans-unit id="138db4b5382fa4b7773cb8a28fe6e1cf154b3abe" translate="yes" xml:space="preserve">
          <source>If you don't want to use python for this, we also provide &lt;a href=&quot;https://github.com/sigsep/sigsep-mus-io&quot;&gt;docker based scripts&lt;/a&gt; to decode the dataset to WAV files.</source>
          <target state="translated">如果您不想为此使用python，我们还将提供&lt;a href=&quot;https://github.com/sigsep/sigsep-mus-io&quot;&gt;基于docker的脚本&lt;/a&gt;来将数据集解码为WAV文件。</target>
        </trans-unit>
        <trans-unit id="03fccfef108b986a75907475407a3721d977c3dd" translate="yes" xml:space="preserve">
          <source>If you use the MUSDB dataset for your research - Cite the MUSDB18 Dataset</source>
          <target state="translated">如果你在研究中使用MUSDB数据集-引用MUSDB18数据集。</target>
        </trans-unit>
        <trans-unit id="6c98bd4105d83c734465099d92637f2b39cc418a" translate="yes" xml:space="preserve">
          <source>If you want to access individual tracks, you can access the &lt;code&gt;mus&lt;/code&gt; tracks list by its indices, e.g. &lt;code&gt;mus[2:]&lt;/code&gt;. To foster reproducible research, we provide a fixed validation dataset.</source>
          <target state="translated">如果要访问单个轨道，则可以按其索引访问 &lt;code&gt;mus&lt;/code&gt; 轨道列表，例如 &lt;code&gt;mus[2:]&lt;/code&gt; 。为了促进可重复的研究，我们提供了一个固定的验证数据集。</target>
        </trans-unit>
        <trans-unit id="c0aea3c013c4ea85aaf8da01bb7c5c92bd04c515" translate="yes" xml:space="preserve">
          <source>If you want to use WAV files (e.g. for faster audio decoding), &lt;code&gt;musdb&lt;/code&gt; also supports parsing and processing pre-decoded PCM/wav files. &lt;code&gt;musdb&lt;/code&gt; comes with the ability to convert a STEMS dataset into WAV version. This script can be used from the command line by</source>
          <target state="translated">如果要使用WAV文件（例如，用于更快的音频解码），则 &lt;code&gt;musdb&lt;/code&gt; 还支持解析和处理预解码的PCM / wav文件。 &lt;code&gt;musdb&lt;/code&gt; 可以将STEMS数据集转换为WAV版本。可以从命令行通过以下方式使用此脚本：</target>
        </trans-unit>
        <trans-unit id="5770b728fa2eb0839ba0edf415f1f1192785c2f4" translate="yes" xml:space="preserve">
          <source>Import the &lt;code&gt;musdb&lt;/code&gt; package in your main python function and iterate over the 7 seconds &lt;code&gt;musdb&lt;/code&gt; tracks:</source>
          <target state="translated">将 &lt;code&gt;musdb&lt;/code&gt; 包导入您的主要python函数中，并在7秒钟的 &lt;code&gt;musdb&lt;/code&gt; 轨道中进行迭代：</target>
        </trans-unit>
        <trans-unit id="a8f39a0eaff1e31685a2b14797108f08b8c37cd0" translate="yes" xml:space="preserve">
          <source>Installation and Setup</source>
          <target state="translated">安装和设置</target>
        </trans-unit>
        <trans-unit id="370cfaa9b9ac29647dea8e39f6de9fea6cc3a9a7" translate="yes" xml:space="preserve">
          <source>Iterate over MUSDB18 tracks</source>
          <target state="translated">在MUSDB18轨道上迭代</target>
        </trans-unit>
        <trans-unit id="7f47c6de2ebcabbcc56f62559cf85e9a5796a39a" translate="yes" xml:space="preserve">
          <source>Iterating over &lt;code&gt;musdb&lt;/code&gt; and thus accessing the audio data is as simple as. Lets assume, we have a supervised training method &lt;code&gt;train(x, y)&lt;/code&gt; that takes the &lt;strong&gt;mixture&lt;/strong&gt; as input and the &lt;strong&gt;vocals&lt;/strong&gt; as output, we can simple use:</source>
          <target state="translated">遍历 &lt;code&gt;musdb&lt;/code&gt; 并因此访问音频数据非常简单。让我们假设，我们有一个监督训练方法 &lt;code&gt;train(x, y)&lt;/code&gt; ，将&lt;strong&gt;混合&lt;/strong&gt;作为输入，将&lt;strong&gt;人声&lt;/strong&gt;作为输出，我们可以简单地使用：</target>
        </trans-unit>
        <trans-unit id="3229609e15436ec51bcf00818a69a84dbc58a0c2" translate="yes" xml:space="preserve">
          <source>License</source>
          <target state="translated">许可证</target>
        </trans-unit>
        <trans-unit id="89690ac571dcf4c9c40c842efed3f11171d07b29" translate="yes" xml:space="preserve">
          <source>MIT</source>
          <target state="translated">麻省理工学院</target>
        </trans-unit>
        <trans-unit id="132dd629d2322820736b20863649b1dc62f54f40" translate="yes" xml:space="preserve">
          <source>On &lt;a href=&quot;https://anaconda.org&quot;&gt;Anaconda&lt;/a&gt;, you can install FFMPEG using &lt;code&gt;conda install -c conda-forge ffmpeg&lt;/code&gt;.</source>
          <target state="translated">在&lt;a href=&quot;https://anaconda.org&quot;&gt;Anaconda上&lt;/a&gt;，可以使用 &lt;code&gt;conda install -c conda-forge ffmpeg&lt;/code&gt; 安装FFMPEG 。</target>
        </trans-unit>
        <trans-unit id="207215fe0cc1433e1aede28acc2a8073c8c33db1" translate="yes" xml:space="preserve">
          <source>Open-Unmix</source>
          <target state="translated">打开Unmix</target>
        </trans-unit>
        <trans-unit id="2b4abd4e67fec0f3d7112a8e2a392fb3249b9341" translate="yes" xml:space="preserve">
          <source>Oracles</source>
          <target state="translated">Oracles</target>
        </trans-unit>
        <trans-unit id="77ca84718e0ad8247dcc8f32f65ce5736bf1270f" translate="yes" xml:space="preserve">
          <source>Package installation</source>
          <target state="translated">包装安装</target>
        </trans-unit>
        <trans-unit id="2a1b54776f0e80073e212cb5b9ce3350e5c11555" translate="yes" xml:space="preserve">
          <source>Processing training and testing subsets separately</source>
          <target state="translated">分别处理训练和测试子集</target>
        </trans-unit>
        <trans-unit id="df4021359edbeba8382d06ca8f62d6123c1282b1" translate="yes" xml:space="preserve">
          <source>Python parser for the SIGSEP MUSDB18 dataset</source>
          <target state="translated">用于SIGSEP MUSDB18数据集的Python解析器。</target>
        </trans-unit>
        <trans-unit id="9062ad8afd8d0d1be03a86b7244eeb4d7794c02d" translate="yes" xml:space="preserve">
          <source>Setting up musdb</source>
          <target state="translated">设置musdb</target>
        </trans-unit>
        <trans-unit id="ff667ad4912ee7200ee958e9c14cfab32b735028" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Track&lt;/code&gt; objects which makes it easy to process the audio and metadata in a pythonic way:</source>
          <target state="translated">该 &lt;code&gt;Track&lt;/code&gt; 对象，这使得它易于加工的Python的方式音频和元数据：</target>
        </trans-unit>
        <trans-unit id="4e264d7ce32d057a9dd6209d34288c3668929c0f" translate="yes" xml:space="preserve">
          <source>The dataset is hosted on Zenodo and requires that users request access, since the tracks can only be used for academic purposes. We manually check this requests. Please do not fill the form multiple times, it usually takes as less than a day to give you access.</source>
          <target state="translated">该数据集托管在Zenodo上,需要用户申请访问,因为这些轨迹只能用于学术目的。我们会手动检查这个请求。请不要多次填写表格,通常只需要不到一天的时间就可以给你访问。</target>
        </trans-unit>
        <trans-unit id="2da76dfbeac983fa1c791c4b2a7bf221d157c103" translate="yes" xml:space="preserve">
          <source>The list of validation tracks can be edited using the &lt;a href=&quot;https://github.com/sigsep/sigsep-mus-tools/blob/b283da5b8f24e84172a60a06bb8f3dacd57aa6cd/musdb/configs/mus.yaml&quot;&gt;&lt;code&gt;mus.setup['validation_tracks']&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="translated">验证轨道列表可以使用&lt;a href=&quot;https://github.com/sigsep/sigsep-mus-tools/blob/b283da5b8f24e84172a60a06bb8f3dacd57aa6cd/musdb/configs/mus.yaml&quot;&gt; &lt;code&gt;mus.setup['validation_tracks']&lt;/code&gt; &lt;/a&gt;对象进行编辑。</target>
        </trans-unit>
        <trans-unit id="c34bfbcd3c28a179b9c52e7a72bd51dc8961b60b" translate="yes" xml:space="preserve">
          <source>The mixture is not exactly the sum of its sources, is that intended?</source>
          <target state="translated">混合物并不完全是其来源的总和,这是有意为之吗?</target>
        </trans-unit>
        <trans-unit id="78a04588fdb45db6b16aa25b1f9fcab863f71b75" translate="yes" xml:space="preserve">
          <source>This is not a bug. Since we adopted the STEMS format, we used AAC compression. Here the residual noise of the mixture is different from the sum of the residual noises of the sources. This difference does not significantly affect separation performance.</source>
          <target state="translated">这不是一个错误。因为我们采用的是STEMS格式,所以我们使用了AAC压缩。在这里,混合物的残余噪声与声源的残余噪声之和是不同的。这种差异并不会显著影响分离性能。</target>
        </trans-unit>
        <trans-unit id="2e55f986e229905af6c29b05543f574bab642f10" translate="yes" xml:space="preserve">
          <source>This package should nicely integrate with your existing python numpy, tensorflow or pytorch code. Most of the steps to use musdb in your project will probably use the same first steps:</source>
          <target state="translated">这个包可以很好地与你现有的python numpy、tensorflow或pytorch代码集成。在你的项目中使用musdb的大部分步骤可能会使用相同的第一步。</target>
        </trans-unit>
        <trans-unit id="ac5c5d45a33ef62d494dbc071fa4f1cc427b5e30" translate="yes" xml:space="preserve">
          <source>To Evaluate a &lt;code&gt;musdb&lt;/code&gt; track using the popular BSSEval metrics, you can use our &lt;a href=&quot;https://github.com/sigsep/sigsep-mus-eval&quot;&gt;museval&lt;/a&gt; package. After &lt;code&gt;pip install musdb&lt;/code&gt; evaluation of a single &lt;code&gt;track&lt;/code&gt;, can be done by</source>
          <target state="translated">要使用流行的BSSEval指标评估 &lt;code&gt;musdb&lt;/code&gt; 音轨，可以使用我们的&lt;a href=&quot;https://github.com/sigsep/sigsep-mus-eval&quot;&gt;museval&lt;/a&gt;包。在 &lt;code&gt;pip install musdb&lt;/code&gt; 评估 &lt;code&gt;track&lt;/code&gt; ，可以通过</target>
        </trans-unit>
        <trans-unit id="ea9731eda0e95dda5e1d21e3e28bb04a4dfc415c" translate="yes" xml:space="preserve">
          <source>To use the full dataset, set a dataset &lt;code&gt;root&lt;/code&gt; directory</source>
          <target state="translated">要使用完整的数据集，请设置数据集 &lt;code&gt;root&lt;/code&gt; 目录</target>
        </trans-unit>
        <trans-unit id="79adadec10484e80d3f5b6c83e9b25779b6d8976" translate="yes" xml:space="preserve">
          <source>Tracks properties</source>
          <target state="translated">追踪属性</target>
        </trans-unit>
        <trans-unit id="32815e2e57b9b4822b6c51f7ef4021db020cc173" translate="yes" xml:space="preserve">
          <source>Training Deep Neural Networks with &lt;code&gt;musdb&lt;/code&gt;</source>
          <target state="translated">使用 &lt;code&gt;musdb&lt;/code&gt; 训练深度神经网络</target>
        </trans-unit>
        <trans-unit id="0bb18642b70b9f8a9c12ccf39487328f306b8e19" translate="yes" xml:space="preserve">
          <source>Usage</source>
          <target state="translated">使用方法</target>
        </trans-unit>
        <trans-unit id="eed450cf1db8d13dbd7fc62ae850160bb45c4bdf" translate="yes" xml:space="preserve">
          <source>Use train / validation split</source>
          <target state="translated">使用训练/验证分割</target>
        </trans-unit>
        <trans-unit id="ac68f0a7761ade25c5abaadd56f1ede023f14135" translate="yes" xml:space="preserve">
          <source>Using STEMs (Default)</source>
          <target state="translated">使用STEMs(默认)</target>
        </trans-unit>
        <trans-unit id="f9cc14cd4eeb07f9364dc314ab41688001f7bb4f" translate="yes" xml:space="preserve">
          <source>Using WAV files (Optional)</source>
          <target state="translated">使用WAV文件(可选</target>
        </trans-unit>
        <trans-unit id="2a8773c12df6590465cdd18bf29b6de11cc247cf" translate="yes" xml:space="preserve">
          <source>We provide a state-of-the-art deep learning based separation method for PyTorch, Tensorflow and NNable at &lt;a href=&quot;https://open.unmix.app&quot;&gt;open.unmix.app&lt;/a&gt;.</source>
          <target state="translated">我们在&lt;a href=&quot;https://open.unmix.app&quot;&gt;open.unmix.app上&lt;/a&gt;提供了针对PyTorch，Tensorflow和NNable的基于深度学习的最新分离方法。</target>
        </trans-unit>
        <trans-unit id="6d5193e3e0fea752a8d31ef41a4bb6187afbf501" translate="yes" xml:space="preserve">
          <source>We provide subsets for &lt;em&gt;train&lt;/em&gt; and &lt;em&gt;test&lt;/em&gt; for machine learning methods:</source>
          <target state="translated">我们提供&lt;em&gt;训练&lt;/em&gt;和&lt;em&gt;测试&lt;/em&gt;机器学习方法的子集：</target>
        </trans-unit>
        <trans-unit id="0dcca236bff78f18ea9af962b822381d3b2ac79c" translate="yes" xml:space="preserve">
          <source>Writing an efficient dataset generator varies across different deep learning frameworks. A very simple n&amp;auml;ive generator that</source>
          <target state="translated">在不同的深度学习框架中编写高效的数据集生成器会有所不同。一个非常简单的原始生成器</target>
        </trans-unit>
        <trans-unit id="dc1d3adf282845429dfa1766e857fcd094739ae2" translate="yes" xml:space="preserve">
          <source>You can install &lt;code&gt;musdb&lt;/code&gt; using pip:</source>
          <target state="translated">您可以使用pip安装 &lt;code&gt;musdb&lt;/code&gt; ：</target>
        </trans-unit>
        <trans-unit id="3614cadabe7bed2983c8e8197272251e585a99f5" translate="yes" xml:space="preserve">
          <source>can be easily implemented using musdb's &lt;code&gt;track.chunk_start&lt;/code&gt; and &lt;code&gt;track.chunk_duration&lt;/code&gt; properties which efficiently seeks to the start sample (provided in seconds) and does not load the full audio into memory first.</source>
          <target state="translated">可以使用musdb的 &lt;code&gt;track.chunk_start&lt;/code&gt; 和 &lt;code&gt;track.chunk_duration&lt;/code&gt; 属性轻松实现，该属性有效地寻找起始样本（以秒为单位），并且不会首先将完整的音频加载到内存中。</target>
        </trans-unit>
        <trans-unit id="6deb4a1ffc62a2033bb57af15982810cab577408" translate="yes" xml:space="preserve">
          <source>draws random chunks of fixed length with replacement</source>
          <target state="translated">随机抽取固定长度的块状物,并进行替换</target>
        </trans-unit>
        <trans-unit id="9183d0bd96f204b0c69dc98e8bf6007f280b56b3" translate="yes" xml:space="preserve">
          <source>draws random tracks with replacement</source>
          <target state="translated">随机抽取替换轨道</target>
        </trans-unit>
        <trans-unit id="c1207f9aa701dc5352980de4ce83b67a41b3ec7a" translate="yes" xml:space="preserve">
          <source>musdb</source>
          <target state="translated">麝香</target>
        </trans-unit>
        <trans-unit id="29c454a4fe227f88ac6da74e1e1eed3a2ddea509" translate="yes" xml:space="preserve">
          <source>on Ubuntu/Debian: &lt;code&gt;sudo apt-get install ffmpeg&lt;/code&gt;</source>
          <target state="translated">在Ubuntu / Debian上： &lt;code&gt;sudo apt-get install ffmpeg&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="eaf87315e2ddc76ec1da180c3941e6ecadeb8340" translate="yes" xml:space="preserve">
          <source>on macOS, using homebrew: &lt;code&gt;brew install ffmpeg&lt;/code&gt;</source>
          <target state="translated">在MacOS上，使用自制软件： &lt;code&gt;brew install ffmpeg&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="45e057342e222276bab1adc7d9088a6b7b29b3bc" translate="yes" xml:space="preserve">
          <source>where &lt;code&gt;root&lt;/code&gt; is the path to the MUSDB18 dataset root folder. The root parameter can also be overridden using a system environment variable. Just &lt;code&gt;export MUSDB_PATH=/path/to/musdb&lt;/code&gt; inside your bash environment. In that case no arguments would need to passed to &lt;code&gt;DB()&lt;/code&gt;.</source>
          <target state="translated">其中 &lt;code&gt;root&lt;/code&gt; 是MUSDB18数据集根文件夹的路径。根参数也可以使用系统环境变量来覆盖。只需在bash环境中 &lt;code&gt;export MUSDB_PATH=/path/to/musdb&lt;/code&gt; 。在这种情况下，无需将参数传递给 &lt;code&gt;DB()&lt;/code&gt; 。</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
