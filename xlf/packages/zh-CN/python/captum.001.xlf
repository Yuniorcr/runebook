<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="zh-CN" datatype="htmlbody" original="https://pypi.org/project/captum/">
    <body>
      <group id="captum">
        <trans-unit id="7e224d6675fc514ea7defb9516638683fceb2bcc" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Deconvolution&lt;/code&gt;, &lt;code&gt;Neuron Deconvolution&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1311.2901.pdf&quot;&gt;Visualizing and Understanding Convolutional Networks, Matthew D Zeiler et al. 2014&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Deconvolution&lt;/code&gt; ， &lt;code&gt;Neuron Deconvolution&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/pdf/1311.2901.pdf&quot;&gt;可视化和理解卷积网络，Matthew D Zeiler等。2014年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f77c45466355b115b010aa83e3ec5115e53cc011" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;DeepLift&lt;/code&gt; assigns similar attribution scores as &lt;code&gt;IntegratedGradients&lt;/code&gt; to inputs,
however it has lower execution time. Another important thing to remember about
DeepLift is that it currently doesn't support all non-linear activation types.
For more details on limitations of the current implementation, please see the
&lt;a href=&quot;https://arxiv.org/abs/1704.02685&quot;&gt;DeepLift paper&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;DeepLift&lt;/code&gt; 将与 &lt;code&gt;IntegratedGradients&lt;/code&gt; 类似的归因分数分配给输入，但是执行时间较短。有关DeepLift的另一点要记住的是，它目前不支持所有非线性激活类型。有关当前实现限制的更多详细信息，请参阅 &lt;a href=&quot;https://arxiv.org/abs/1704.02685&quot;&gt;DeepLift文件&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="35d8eea45bfc985cc4e9ed2b9f13dcc77a172786" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;DeepLift&lt;/code&gt;, &lt;code&gt;NeuronDeepLift&lt;/code&gt;, &lt;code&gt;LayerDeepLift&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1704.02685.pdf&quot;&gt;Learning Important Features Through Propagating Activation Differences, Avanti Shrikumar et al. 2017&lt;/a&gt; and &lt;a href=&quot;https://openreview.net/pdf?id=Sy21R9JAW&quot;&gt;Towards better understanding of gradient-based attribution methods for deep neural networks, Marco Ancona et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;DeepLift&lt;/code&gt; ， &lt;code&gt;NeuronDeepLift&lt;/code&gt; ， &lt;code&gt;LayerDeepLift&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/pdf/1704.02685.pdf&quot;&gt;通过传播激活差异来学习重要功能，Avanti Shrikumar等人。&lt;/a&gt;&lt;a href=&quot;https://openreview.net/pdf?id=Sy21R9JAW&quot;&gt;Marco Ancona等人（&lt;/a&gt;2017年）和《对深度神经网络基于梯度的归因方法的更好理解》。2018年</target>
        </trans-unit>
        <trans-unit id="0935b98602a2196eb3ce841148929580db331f26" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;DeepLiftShap&lt;/code&gt; uses &lt;code&gt;DeepLift&lt;/code&gt; to compute attribution score for each
input-baseline pair and averages it for each input across all baselines.</source>
          <target state="translated">&lt;code&gt;DeepLiftShap&lt;/code&gt; 使用 &lt;code&gt;DeepLift&lt;/code&gt; 计算每个输入-基线对的归因得分，并将其平均化为所有基线的每个输入。</target>
        </trans-unit>
        <trans-unit id="70f4204e74fbab884413f100ee93ebc43bf69602" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Feature Permutation&lt;/code&gt;: &lt;a href=&quot;https://christophm.github.io/interpretable-ml-book/feature-importance.html&quot;&gt;Permutation Feature Importance&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Feature Permutation&lt;/code&gt; ：&lt;a href=&quot;https://christophm.github.io/interpretable-ml-book/feature-importance.html&quot;&gt;置换特征重要性&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="dfd45f4166b5d1094537f54fcf044b34d5f360af" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;GradCAM&lt;/code&gt;, &lt;code&gt;Guided GradCAM&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1610.02391.pdf&quot;&gt;Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization, Ramprasaath R. Selvaraju et al. 2017&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;GradCAM&lt;/code&gt; ， &lt;code&gt;Guided GradCAM&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/abs/1610.02391.pdf&quot;&gt;Grad-CAM：深度网络通过基于梯度的本地化的视觉解释，Ramprasaath R. Selvaraju等。2017年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9c73c2db449b0b144f4acb50ee0a1570caed5366" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;GradientShap&lt;/code&gt; first chooses a random baseline from baselines' distribution, then
adds gaussian noise with std=0.09 to each input example &lt;code&gt;n_samples&lt;/code&gt; times.
Afterwards, it chooses a random point between each example-baseline pair and
computes the gradients with respect to target class (in this case target=0). Resulting
attribution is the mean of gradients * (inputs - baselines)</source>
          <target state="translated">&lt;code&gt;GradientShap&lt;/code&gt; 首先从基线分布中选择一个随机基线，然后将 &lt;code&gt;n_samples&lt;/code&gt; 次的每个std = 0.09的高斯噪声添加到每个输入示例中。然后，它在每个示例基线对之间选择一个随机点，并计算相对于目标类别的梯度（在这种情况下为target = 0）。结果归因是梯度的平均值*（输入-基线）</target>
        </trans-unit>
        <trans-unit id="745f47441809340b71cc76401a089bf5ad757fd9" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;GradientShap&lt;/code&gt;, &lt;code&gt;NeuronGradientShap&lt;/code&gt;, &lt;code&gt;LayerGradientShap&lt;/code&gt;, &lt;code&gt;DeepLiftShap&lt;/code&gt;, &lt;code&gt;NeuronDeepLiftShap&lt;/code&gt;, &lt;code&gt;LayerDeepLiftShap&lt;/code&gt;: &lt;a href=&quot;http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions&quot;&gt;A Unified Approach to Interpreting Model Predictions, Scott M. Lundberg et al. 2017&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;GradientShap&lt;/code&gt; ， &lt;code&gt;NeuronGradientShap&lt;/code&gt; ， &lt;code&gt;LayerGradientShap&lt;/code&gt; ， &lt;code&gt;DeepLiftShap&lt;/code&gt; ， &lt;code&gt;NeuronDeepLiftShap&lt;/code&gt; ， &lt;code&gt;LayerDeepLiftShap&lt;/code&gt; ：&lt;a href=&quot;http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions&quot;&gt;解释模型预测的统一方法，Scott M. Lundberg等。2017年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="602dfc33d8aba3857725b949b893d500e50a678d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Guided Backpropagation&lt;/code&gt;, &lt;code&gt;Neuron Guided Backpropagation&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1412.6806.pdf&quot;&gt;Striving for Simplicity: The All Convolutional Net, Jost Tobias Springenberg et al. 2015&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Guided Backpropagation&lt;/code&gt; ， &lt;code&gt;Neuron Guided Backpropagation&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/pdf/1412.6806.pdf&quot;&gt;力求简单：全卷积网络，Jost Tobias Springenberg等。2015年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="32d5dd2bb7640e2b606a6084f2cafa2a031b478b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;InputXGradient&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1611.07270&quot;&gt;Investigating the influence of noise and distractors on the interpretation of neural networks, Pieter-Jan Kindermans et al. 2016&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;InputXGradient&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/abs/1611.07270&quot;&gt;研究噪声和干扰物对神经网络解释的影响，Pieter-Jan Kindermans等人。2016年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b69ede686e5d4e904dbf0247c2f663ff896f0a0c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;IntegratedGradients&lt;/code&gt;, &lt;code&gt;LayerIntegratedGradients&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1703.01365&quot;&gt;Axiomatic Attribution for Deep Networks, Mukund Sundararajan et al. 2017&lt;/a&gt; and &lt;a href=&quot;https://arxiv.org/abs/1805.05492&quot;&gt;Did the Model Understand the Question?, Pramod K. Mudrakarta, et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;IntegratedGradients&lt;/code&gt; ， &lt;code&gt;LayerIntegratedGradients&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/abs/1703.01365&quot;&gt;深层网络的公理归因，Mukund Sundararajan等。2017年&lt;/a&gt;，&lt;a href=&quot;https://arxiv.org/abs/1805.05492&quot;&gt;《模型是否理解问题？》，Pramod K.Mudrakarta等人。2018年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1ce041e0904e2eb6fe9e166ae16f4a94c041216f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;InternalInfluence&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1802.03788.pdf&quot;&gt;Influence-Directed Explanations for Deep Convolutional Networks, Klas Leino et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;InternalInfluence&lt;/code&gt; &lt;a href=&quot;https://arxiv.org/pdf/1802.03788.pdf&quot;&gt;影响力&lt;/a&gt;：深度卷积网络的影响力解释，Klas Leino等。2018年</target>
        </trans-unit>
        <trans-unit id="6464d80d482910b859e98e94be43a85d78c92fff" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;LayerConductance&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1807.09946.pdf&quot;&gt;Computationally Efficient Measures of Internal Neuron Importance, Avanti Shrikumar et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;LayerConductance&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/pdf/1807.09946.pdf&quot;&gt;内部神经元重要性的计算有效度量，Avanti Shrikumar等。2018年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a390e01ea3142478285f0168a9d0220de3b869e1" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;NeuronConductance&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1805.12233&quot;&gt;How Important is a neuron?, Kedar Dhamdhere et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;NeuronConductance&lt;/code&gt; &lt;a href=&quot;https://arxiv.org/abs/1805.12233&quot;&gt;神经元&lt;/a&gt;传导：神经元有多重要？，Kedar Dhamdhere等。2018年</target>
        </trans-unit>
        <trans-unit id="7fa53a48f5e924963274d272e5ae392af89f2c41" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;NeuronIntegratedGradients&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1807.09946.pdf&quot;&gt;Computationally Efficient Measures of Internal Neuron Importance, Avanti Shrikumar et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;NeuronIntegratedGradients&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/pdf/1807.09946.pdf&quot;&gt;内部神经元重要性的计算有效度量，Avanti Shrikumar等。2018年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3406337d51997da5374b792bb810c3069f71f625" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;NoiseTunnel&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1810.03292&quot;&gt;Sanity Checks for Saliency Maps, Julius Adebayo et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;NoiseTunnel&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/abs/1810.03292&quot;&gt;Saliency Map的健全性检查，Julius Adebayo等。2018年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="180de40fda30abd90e30c91da063de517cd65e10" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Occlusion&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1311.2901&quot;&gt;Visualizing and Understanding Convolutional Networks&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Occlusion&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/abs/1311.2901&quot;&gt;可视化和理解卷积网络&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="ef3e53fd11ec0ec42f34212a68a5a8f640a980a4" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Saliency&lt;/code&gt;, &lt;code&gt;NeuronGradient&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1312.6034.pdf&quot;&gt;Deep Inside Convolutional Networks: Visualising
Image Classification Models and Saliency Maps, K. Simonyan, et. al. 2014&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Saliency&lt;/code&gt; ， &lt;code&gt;NeuronGradient&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/pdf/1312.6034.pdf&quot;&gt;深度卷积网络：可视化图像分类模型和显着性地图，K. Simonyan等。等 2014年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d72716650eca9202bde62762d848353fd9f89e55" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Shapely Value Sampling&lt;/code&gt;: &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0305054808000804&quot;&gt;Polynomial calculation of the Shapley value based on sampling&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Shapely Value Sampling&lt;/code&gt; ：&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0305054808000804&quot;&gt;基于采样的Shapley值的多项式计算&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2f313a5b98f914e2d22e3666af676c317da1a76c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Shapely Value&lt;/code&gt;: &lt;a href=&quot;https://apps.dtic.mil/dtic/tr/fulltext/u2/604084.pdf&quot;&gt;A value for n-person games. Contributions to the Theory of Games 2.28 (1953): 307-317&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Shapely Value&lt;/code&gt; ：&lt;a href=&quot;https://apps.dtic.mil/dtic/tr/fulltext/u2/604084.pdf&quot;&gt;n人游戏的价值。对游戏理论的贡献2.28（1953）：307-317&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="cc62bf28a6aaadab7c58506486d1282344c4f152" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;SmoothGrad&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1706.03825&quot;&gt;SmoothGrad: removing noise by adding noise, Daniel Smilkov et al. 2017&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;SmoothGrad&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/abs/1706.03825&quot;&gt;SmoothGrad：通过添加噪声消除噪声，Daniel Smilkov等。2017年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="97d9a83b33d1a1e1468782cbf91b17ba820547f9" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;pip install -e .[dev]&lt;/code&gt;: Also installs all tools necessary for development
(testing, linting, docs building; see &lt;a href=&quot;#contributing&quot;&gt;Contributing&lt;/a&gt; below).</source>
          <target state="translated">&lt;code&gt;pip install -e .[dev]&lt;/code&gt; ：同时安装所有必要的开发工具，（测试，掉毛，文档建设;见&lt;a href=&quot;#contributing&quot;&gt;特约&lt;/a&gt;下文）。</target>
        </trans-unit>
        <trans-unit id="5d7c7835d367a7e4679627572238c42726e0601e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;pip install -e .[insights]&lt;/code&gt;: Also installs all packages necessary for running Captum Insights.</source>
          <target state="translated">&lt;code&gt;pip install -e .[insights]&lt;/code&gt; ：还安装运行Captum Insights所需的所有软件包。</target>
        </trans-unit>
        <trans-unit id="d5bb8d5b6fa5ab568327e9ea794621e7ee38d45f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;pip install -e .[tutorials]&lt;/code&gt;: Also installs all packages necessary for running the tutorial notebooks.</source>
          <target state="translated">&lt;code&gt;pip install -e .[tutorials]&lt;/code&gt; ：还安装运行教程笔记本所需的所有软件包。</target>
        </trans-unit>
        <trans-unit id="c641fcc1b80e58fb730b1652c8b6c7fc9b227fd8" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;Captum is currently in beta and under active development!&lt;/em&gt;</source>
          <target state="translated">&lt;em&gt;Captum目前处于测试阶段，并且正在积极开发中！&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="6897acde3a3c220a635980f413f5941e5fc0a6b4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Installation Requirements&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;安装要求&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="2208733c3a7ee98009723d2713bcd61e00a43c9c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Manual / Dev install&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;手动/开发安装&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="c3f76124c7fa391369fe5c7fb44c51cf9d1ed726" translate="yes" xml:space="preserve">
          <source>About Captum</source>
          <target state="translated">关于Captum</target>
        </trans-unit>
        <trans-unit id="d8c0847ea163dcd16d6f2a889df7dce1e95c7176" translate="yes" xml:space="preserve">
          <source>Below is an example of how we can apply &lt;code&gt;DeepLift&lt;/code&gt; and &lt;code&gt;DeepLiftShap&lt;/code&gt; on the
&lt;code&gt;ToyModel&lt;/code&gt; described above. Current implementation of DeepLift supports only
&lt;code&gt;Rescale&lt;/code&gt; rule.
For more details on alternative implementations, please see the &lt;a href=&quot;https://arxiv.org/abs/1704.02685&quot;&gt;DeepLift paper&lt;/a&gt;.</source>
          <target state="translated">以下是我们如何在上述 &lt;code&gt;DeepLiftShap&lt;/code&gt; 上应用 &lt;code&gt;DeepLift&lt;/code&gt; 和DeepLiftShap的 &lt;code&gt;ToyModel&lt;/code&gt; 。DeepLift的当前实现仅支持 &lt;code&gt;Rescale&lt;/code&gt; 规则。有关替代实现的更多详细信息，请参见&lt;a href=&quot;https://arxiv.org/abs/1704.02685&quot;&gt;DeepLift文件&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="021481ec74cf7f851fd8bb8de29f48519b026a55" translate="yes" xml:space="preserve">
          <source>Captum Insights</source>
          <target state="translated">Captum洞察力</target>
        </trans-unit>
        <trans-unit id="b5e6347c0220e027a895cf1796661a4eca041832" translate="yes" xml:space="preserve">
          <source>Captum Insights Jupyter Widget</source>
          <target state="translated">Captum Insights Jupyter小工具</target>
        </trans-unit>
        <trans-unit id="50ea9b39e0ca2b1e147f71e19c8284e932f29b95" translate="yes" xml:space="preserve">
          <source>Captum Insights also has a Jupyter widget providing the same user interface as the web app.
To install and enable the widget, run</source>
          <target state="translated">Captum Insights也有一个Jupyter小工具,提供与Web应用程序相同的用户界面。要安装并启用该小工具,请运行</target>
        </trans-unit>
        <trans-unit id="2284f9438ef0b1f48a107c6a47037d5562ef7a07" translate="yes" xml:space="preserve">
          <source>Captum can also be used by application engineers who are using trained models in production. Captum provides easier troubleshooting through improved model interpretability, and the potential for delivering better explanations to end users on why they&amp;rsquo;re seeing a specific piece of content, such as a movie recommendation.</source>
          <target state="translated">在生产中使用受过训练的模型的应用工程师也可以使用Captum。Captum通过改进模型的可解释性提供了更轻松的故障排除方法，并有可能向最终用户提供有关他们为什么看到特定内容（例如电影推荐）的更好解释。</target>
        </trans-unit>
        <trans-unit id="e072252aa5db22cac92d10e2402e5669eae223d4" translate="yes" xml:space="preserve">
          <source>Captum helps ML researchers more easily implement interpretability algorithms that can interact with PyTorch models. Captum also allows researchers to quickly benchmark their work against other existing algorithms available in the library.</source>
          <target state="translated">Captum 帮助 ML 研究人员更轻松地实现可与 PyTorch 模型交互的可解释性算法。Captum 还允许研究人员将他们的工作与库中现有的其他算法进行快速基准测试。</target>
        </trans-unit>
        <trans-unit id="d26bdb66327c68c373a8e184aae92f50105b84ad" translate="yes" xml:space="preserve">
          <source>Captum helps you interpret and understand predictions of PyTorch models by
exploring features that contribute to a prediction the model makes.
It also helps understand which neurons and layers are important for
model predictions.</source>
          <target state="translated">Captum 通过探索有助于模型做出预测的特征,帮助您解释和理解 PyTorch 模型的预测。它还有助于了解哪些神经元和层对模型预测很重要。</target>
        </trans-unit>
        <trans-unit id="48db440dde81207b626929193aa5ff14516a272f" translate="yes" xml:space="preserve">
          <source>Captum is BSD licensed, as found in the &lt;a href=&quot;LICENSE&quot;&gt;LICENSE&lt;/a&gt; file.</source>
          <target state="translated">Captum已获得BSD许可，如&lt;a href=&quot;LICENSE&quot;&gt;LICENSE&lt;/a&gt;文件中所示。</target>
        </trans-unit>
        <trans-unit id="2b556e02df9343beb45e9c79545ddba2410d2664" translate="yes" xml:space="preserve">
          <source>Captum is a model interpretability and understanding library for PyTorch.
Captum means comprehension in latin and contains general purpose implementations
of integrated gradients, saliency maps, smoothgrad, vargrad and others for
PyTorch models. It has quick integration for models built with domain-specific
libraries such as torchvision, torchtext, and others.</source>
          <target state="translated">Captum是PyTorch的一个模型可解释性和理解性库。Captum在拉丁语中的意思是理解,它包含了PyTorch模型的集成梯度、saliency maps、smoothgrad、vargrad等的通用实现。它可以快速集成与领域特定库(如torchvision、torchtext等)构建的模型。</target>
        </trans-unit>
        <trans-unit id="712c9c0dc955ee835f95d4a0c2e34f430fb91038" translate="yes" xml:space="preserve">
          <source>Captum provides a web interface called Insights for easy visualization and
access to a number of our interpretability algorithms.</source>
          <target state="translated">Captum提供了一个名为Insights的网络界面,可轻松实现可视化并访问我们的一些可解释性算法。</target>
        </trans-unit>
        <trans-unit id="2d82a4b27a4b305690d5ac612046a955778a9fa5" translate="yes" xml:space="preserve">
          <source>Contributing</source>
          <target state="translated">贡献</target>
        </trans-unit>
        <trans-unit id="39703b21af9911d0f81c306612570543015fb4da" translate="yes" xml:space="preserve">
          <source>Currently, the library uses gradient-based interpretability algorithms
and attributes contributions to each input of the model with respect to
different neurons and layers, both intermediate and final.</source>
          <target state="translated">目前,该库采用了基于梯度的可解释性算法,并将模型的每个输入与不同的神经元和层(包括中间层和最终层)的贡献度进行归属。</target>
        </trans-unit>
        <trans-unit id="90ab72c08753cb3eced44073f94e601929bbf4a1" translate="yes" xml:space="preserve">
          <source>Deltas are computed for each &lt;code&gt;n_samples * input.shape[0]&lt;/code&gt; example. The user can,
for instance, average them:</source>
          <target state="translated">为每个 &lt;code&gt;n_samples * input.shape[0]&lt;/code&gt; 示例计算增量。用户可以例如对它们求平均：</target>
        </trans-unit>
        <trans-unit id="c6b820410c0912f7db59b8a701baa4c5631073ed" translate="yes" xml:space="preserve">
          <source>For model developers, Captum can be used to improve and troubleshoot models by facilitating the identification of different features that contribute to a model&amp;rsquo;s output in order to design better models and troubleshoot unexpected model outputs.</source>
          <target state="translated">对于模型开发人员而言，Captum可用于通过帮助识别有助于模型输出的不同功能来改进模型和对模型进行故障排除，以便设计更好的模型并对意外的模型输出进行故障排除。</target>
        </trans-unit>
        <trans-unit id="010b85ad56b34c34c7c2a3b2436c740e30428ed5" translate="yes" xml:space="preserve">
          <source>Getting Started</source>
          <target state="translated">入门</target>
        </trans-unit>
        <trans-unit id="523b5dd24d78e1688f499261e03d11aabe65c0e9" translate="yes" xml:space="preserve">
          <source>Here is an example how we can use &lt;code&gt;NoiseTunnel&lt;/code&gt; with &lt;code&gt;IntegratedGradients&lt;/code&gt;.</source>
          <target state="translated">这是一个示例，说明如何将 &lt;code&gt;NoiseTunnel&lt;/code&gt; 与 &lt;code&gt;IntegratedGradients&lt;/code&gt; 一起使用。</target>
        </trans-unit>
        <trans-unit id="2951f06ff53b46d9157f54d1ddb461c159a670d0" translate="yes" xml:space="preserve">
          <source>If you'd like to try our bleeding edge features (and don't mind potentially
running into the occasional bug here or there), you can install the latest
master directly from GitHub. For a basic install, run:</source>
          <target state="translated">如果你想尝试我们的尖端功能(并且不介意偶尔会遇到这里或那里的错误),你可以直接从GitHub上安装最新的主程序。要进行基本安装,请运行。</target>
        </trans-unit>
        <trans-unit id="748139302b5f33a6af11cc4d8e2c307feed6a61f" translate="yes" xml:space="preserve">
          <source>In order to smooth and improve the quality of the attributions we can run
&lt;code&gt;IntegratedGradients&lt;/code&gt; and other attribution methods through a &lt;code&gt;NoiseTunnel&lt;/code&gt;.
&lt;code&gt;NoiseTunnel&lt;/code&gt; allows us to use &lt;code&gt;SmoothGrad&lt;/code&gt;, &lt;code&gt;SmoothGrad_Sq&lt;/code&gt; and &lt;code&gt;VarGrad&lt;/code&gt; techniques
to smoothen the attributions by aggregating them for multiple noisy
samples that were generated by adding gaussian noise.</source>
          <target state="translated">为了平滑和改善归因的质量，我们可以通过 &lt;code&gt;NoiseTunnel&lt;/code&gt; 运行 &lt;code&gt;IntegratedGradients&lt;/code&gt; 和其他归因方法。 &lt;code&gt;NoiseTunnel&lt;/code&gt; 允许我们使用 &lt;code&gt;SmoothGrad&lt;/code&gt; ， &lt;code&gt;SmoothGrad_Sq&lt;/code&gt; 和 &lt;code&gt;VarGrad&lt;/code&gt; 技术将归因于通过添加高斯噪声而生成的多个噪声样本进行归一化，从而平滑归因。</target>
        </trans-unit>
        <trans-unit id="37e62d8605abf42b9cf777a51788c55a03639d78" translate="yes" xml:space="preserve">
          <source>In this case, we choose to analyze the first neuron in the linear layer.</source>
          <target state="translated">在这种情况下,我们选择分析线性层的第一个神经元。</target>
        </trans-unit>
        <trans-unit id="c81b79df3c6448eae7c4f80428b54cd5692a17d7" translate="yes" xml:space="preserve">
          <source>Installation</source>
          <target state="translated">安装</target>
        </trans-unit>
        <trans-unit id="726495cac31fed46f3681097ea8adbc806081e82" translate="yes" xml:space="preserve">
          <source>Installing the latest release</source>
          <target state="translated">安装最新版本</target>
        </trans-unit>
        <trans-unit id="8e78f6ced3cb3e7a0efd619bef2cccb4fa16b14d" translate="yes" xml:space="preserve">
          <source>It computes deltas for each input example-baseline pair, thus resulting to
&lt;code&gt;input.shape[0] * baseline.shape[0]&lt;/code&gt; delta values.</source>
          <target state="translated">它为每个输入示例基线对计算增量，从而得出 &lt;code&gt;input.shape[0] * baseline.shape[0]&lt;/code&gt; 增量值。</target>
        </trans-unit>
        <trans-unit id="a8a7e2465fdc77cafbda6ce7b7d0e3ab7010ee86" translate="yes" xml:space="preserve">
          <source>It doesn't attribute the contribution scores to the input features
but shows the importance of each neuron in selected layer.</source>
          <target state="translated">它并不将贡献分数归于输入特征,而是显示每个神经元在选定层中的重要性。</target>
        </trans-unit>
        <trans-unit id="45f74c2b886455a20211bc6087c7a981cba8b94d" translate="yes" xml:space="preserve">
          <source>Layer conductance shows the importance of neurons for a layer and given input.
It is an extension of path integrated gradients for hidden layers and holds the
completeness property as well.</source>
          <target state="translated">层导数显示了神经元对于一层和给定输入的重要性。它是路径综合梯度对隐藏层的扩展,也具有完备性。</target>
        </trans-unit>
        <trans-unit id="0022de38b637868d1853d6d090cf915fe72c96d8" translate="yes" xml:space="preserve">
          <source>Let's apply some of those algorithms to a toy model we have created for
demonstration purposes.
For simplicity, we will use the following architecture, but users are welcome
to use any PyTorch model of their choice.</source>
          <target state="translated">让我们将其中的一些算法应用到我们创建的一个玩具模型上,以便进行演示。为了简单起见,我们将使用以下架构,但欢迎用户使用任何他们选择的 PyTorch 模型。</target>
        </trans-unit>
        <trans-unit id="4369c251b91c938021df6f86e075d0f68a6879d5" translate="yes" xml:space="preserve">
          <source>Let's create an instance of our model and set it to eval mode.</source>
          <target state="translated">让我们创建一个模型的实例,并将其设置为评估模式。</target>
        </trans-unit>
        <trans-unit id="b2e5c40eefa02dca2a0399316902a8d9c9094103" translate="yes" xml:space="preserve">
          <source>Let's define our input and baseline tensors. Baselines are used in some
interpretability algorithms such as &lt;code&gt;IntegratedGradients, DeepLift, GradientShap, NeuronConductance, LayerConductance, InternalInfluence&lt;/code&gt; and
&lt;code&gt;NeuronIntegratedGradients&lt;/code&gt;.</source>
          <target state="translated">让我们定义输入和基线张量。在某些可解释性算法中使用了基线，例如 &lt;code&gt;IntegratedGradients, DeepLift, GradientShap, NeuronConductance, LayerConductance, InternalInfluence&lt;/code&gt; 和 &lt;code&gt;NeuronIntegratedGradients&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="a2d21524039206f00133601c7ce2c40fbb2a88ae" translate="yes" xml:space="preserve">
          <source>Let's look into the internals of our network and understand which layers
and neurons are important for the predictions.</source>
          <target state="translated">让我们看看我们的网络内部,了解哪些层和神经元对预测很重要。</target>
        </trans-unit>
        <trans-unit id="3229609e15436ec51bcf00818a69a84dbc58a0c2" translate="yes" xml:space="preserve">
          <source>License</source>
          <target state="translated">许可证</target>
        </trans-unit>
        <trans-unit id="7151ecc0dc7a5120377ab85e7d7eac19fe0502d7" translate="yes" xml:space="preserve">
          <source>Model interpretability for PyTorch</source>
          <target state="translated">PyTorch的模型可解释性</target>
        </trans-unit>
        <trans-unit id="64a7acecc018b0b76e1070ab8d77465d6f66f86e" translate="yes" xml:space="preserve">
          <source>More details about the above mentioned &lt;a href=&quot;https://captum.ai/docs/algorithms&quot;&gt;algorithms&lt;/a&gt; and their pros and cons can be found on our &lt;a href=&quot;https://captum.ai/docs/algorithms_comparison_matrix&quot;&gt;web-site&lt;/a&gt;.</source>
          <target state="translated">有关上述&lt;a href=&quot;https://captum.ai/docs/algorithms&quot;&gt;算法&lt;/a&gt;及其优缺点的更多详细信息，请参见我们&lt;a href=&quot;https://captum.ai/docs/algorithms_comparison_matrix&quot;&gt;的网站&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="c798498ab11132e260e2f04e6a25bc1b01a96272" translate="yes" xml:space="preserve">
          <source>More details on the list of supported algorithms and how to apply
Captum on different types of models can be found in our tutorials.</source>
          <target state="translated">关于支持的算法列表以及如何在不同类型的模型上应用Captum的更多细节可以在我们的教程中找到。</target>
        </trans-unit>
        <trans-unit id="a809e022bfbd247fdef4e8f92c06639a09f2e709" translate="yes" xml:space="preserve">
          <source>Next we will use &lt;code&gt;IntegratedGradients&lt;/code&gt; algorithms to assign attribution
scores to each input feature with respect to the first target output.</source>
          <target state="translated">接下来，我们将使用 &lt;code&gt;IntegratedGradients&lt;/code&gt; 算法针对第一个目标输出为每个输入要素分配归因分数。</target>
        </trans-unit>
        <trans-unit id="e345eb5cbc3af8ba96268dc94160be1d607ed174" translate="yes" xml:space="preserve">
          <source>Next, we need to define simple input and baseline tensors.
Baselines belong to the input space and often carry no predictive signal.
Zero tensor can serve as a baseline for many tasks.
Some interpretability algorithms such as &lt;code&gt;Integrated Gradients&lt;/code&gt;, &lt;code&gt;Deeplift&lt;/code&gt; and &lt;code&gt;GradientShap&lt;/code&gt; are designed to attribute the change
between the input and baseline to a predictive class or a value that the neural
network outputs.</source>
          <target state="translated">接下来，我们需要定义简单的输入和基线张量。基线属于输入空间，通常不携带任何预测信号。零张量可以用作许多任务的基准。一些可解释性算法（例如， &lt;code&gt;Integrated Gradients&lt;/code&gt; ， &lt;code&gt;Deeplift&lt;/code&gt; 和 &lt;code&gt;GradientShap&lt;/code&gt; )旨在将输入和基线之间的变化归因于预测类或神经网络输出的值。</target>
        </trans-unit>
        <trans-unit id="e51de3cf2de9a13ef9bdd27134ba09503e04cca6" translate="yes" xml:space="preserve">
          <source>Now let's look into &lt;code&gt;DeepLiftShap&lt;/code&gt;. Similar to &lt;code&gt;GradientShap&lt;/code&gt;, &lt;code&gt;DeepLiftShap&lt;/code&gt; uses
baseline distribution. In the example below, we use the same baseline distribution
as for &lt;code&gt;GradientShap&lt;/code&gt;.</source>
          <target state="translated">现在让我们看一下 &lt;code&gt;DeepLiftShap&lt;/code&gt; 。与 &lt;code&gt;GradientShap&lt;/code&gt; 相似， &lt;code&gt;DeepLiftShap&lt;/code&gt; 使用基线分布。在下面的示例中，我们使用与 &lt;code&gt;GradientShap&lt;/code&gt; 相同的基线分布。</target>
        </trans-unit>
        <trans-unit id="4bed336194a9a5c86b6a734f03b3570d2aae1a68" translate="yes" xml:space="preserve">
          <source>Output</source>
          <target state="translated">产量</target>
        </trans-unit>
        <trans-unit id="f3c8c95c5e534bcd2ea0034a0d83177efa6923f4" translate="yes" xml:space="preserve">
          <source>Output:</source>
          <target state="translated">产出:</target>
        </trans-unit>
        <trans-unit id="7835db447bc76230b5b0d736b2d78c671d7100a1" translate="yes" xml:space="preserve">
          <source>Outputs</source>
          <target state="translated">产出</target>
        </trans-unit>
        <trans-unit id="b969baf269c9dc13dd2c54d156013b3e06ea3070" translate="yes" xml:space="preserve">
          <source>Positive attribution score means that the input in that particular position
positively contributed to the final prediction and negative means the opposite.
The magnitude of the attribution score signifies the strength of the contribution.
Zero attribution score means no contribution from that particular feature.</source>
          <target state="translated">正向归因得分表示该特定位置的输入对最终的预测有积极的贡献,负向归因得分则表示相反。归因分数的大小标志着贡献的强度。归因得分为零,表示该特定特征没有贡献。</target>
        </trans-unit>
        <trans-unit id="4c0d584e447dd2c5fa55e98d5d7921249c3911f6" translate="yes" xml:space="preserve">
          <source>PyTorch &amp;gt;= 1.2</source>
          <target state="translated">PyTorch&amp;gt; = 1.2</target>
        </trans-unit>
        <trans-unit id="c32b6c1ab053aa1b803595ba447bebbb8760c137" translate="yes" xml:space="preserve">
          <source>Python &amp;gt;= 3.6</source>
          <target state="translated">Python&amp;gt; = 3.6</target>
        </trans-unit>
        <trans-unit id="f00e768dce422689fe65ae881c3b96779cce5814" translate="yes" xml:space="preserve">
          <source>References of Algorithms</source>
          <target state="translated">算法参考</target>
        </trans-unit>
        <trans-unit id="54d440a5db0ab24f40fddf2b795f3716e25774cf" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;CONTRIBUTING.md&quot;&gt;CONTRIBUTING&lt;/a&gt; file for how to help out.</source>
          <target state="translated">请参阅&lt;a href=&quot;CONTRIBUTING.md&quot;&gt;CONTRIBUTING&lt;/a&gt;文件以获取帮助。</target>
        </trans-unit>
        <trans-unit id="9076ccad99e9fe123f5a242ef0d44a11422a0a37" translate="yes" xml:space="preserve">
          <source>Similar to GradientShap in order to compute example-based deltas we can average them per example:</source>
          <target state="translated">与GradientShap类似,为了计算基于实例的三角洲,我们可以对每个实例进行平均。</target>
        </trans-unit>
        <trans-unit id="7c2892f73bdaf8f8b7b55fd520cd5b43f07bb285" translate="yes" xml:space="preserve">
          <source>Similar to integrated gradients, DeepLift returns a convergence delta score
per input example. The approximation error is then the absolute
value of the convergence deltas and can serve as a proxy of how accurate the
algorithm's approximation is.</source>
          <target state="translated">与综合梯度类似,DeepLift 会返回每个输入示例的收敛三角得分。近似误差就是收敛德尔塔的绝对值,可以作为算法近似准确度的代表。</target>
        </trans-unit>
        <trans-unit id="c98898a289abd12ad3663b6492c23d0af933dcbb" translate="yes" xml:space="preserve">
          <source>Similar to other attribution algorithms that return convergence delta, &lt;code&gt;LayerConductance&lt;/code&gt;
returns the deltas for each example. The approximation error is then the absolute
value of the convergence deltas and can serve as a proxy of how accurate integral
approximation for given inputs and baselines is.</source>
          <target state="translated">类似于其他返回收敛增量的归因算法， &lt;code&gt;LayerConductance&lt;/code&gt; 返回每个示例的增量。那么，近似误差是收敛增量的绝对值，并且可以用作给定输入和基线的精确积分近似的精确度的代理。</target>
        </trans-unit>
        <trans-unit id="08641a32adb6073b217892c1d05043cccc5795f7" translate="yes" xml:space="preserve">
          <source>Similarly, we can apply &lt;code&gt;GradientShap&lt;/code&gt;, &lt;code&gt;DeepLift&lt;/code&gt; and other attribution algorithms to the model.</source>
          <target state="translated">同样，我们可以将 &lt;code&gt;GradientShap&lt;/code&gt; ， &lt;code&gt;DeepLift&lt;/code&gt; 和其他归因算法应用于模型。</target>
        </trans-unit>
        <trans-unit id="5dfd03564d68a63c3940a933d7149be86e1b24fc" translate="yes" xml:space="preserve">
          <source>Talks and Papers</source>
          <target state="translated">讲座和论文</target>
        </trans-unit>
        <trans-unit id="5cc6318e21af4a9864dfb66b71e19b22e67f5171" translate="yes" xml:space="preserve">
          <source>Target Audience</source>
          <target state="translated">目标受众</target>
        </trans-unit>
        <trans-unit id="7c09a880f031a61c434b6eea261034d0953ae737" translate="yes" xml:space="preserve">
          <source>The algorithm outputs an attribution score for each input element and a
convergence delta. The lower the absolute value of the convergence delta the better
is the approximation. If we choose not to return delta,
we can simply not provide &lt;code&gt;return_convergence_delta&lt;/code&gt; input
argument. The absolute value of the returned deltas can be interpreted as an
approximation error for each input sample.
It can also serve as a proxy of how accurate the integral approximation for given
inputs and baselines is.
If the approximation error is large, we can try larger number of integral
approximation steps by setting &lt;code&gt;n_steps&lt;/code&gt; to a larger value. Not all algorithms
return approximation error. Those which do, though, compute it based on the
completeness property of the algorithms.</source>
          <target state="translated">该算法输出每个输入元素的归因分数和收敛性增量。收敛增量的绝对值越低，则近似越好。如果选择不返回增量，则根本无法提供 &lt;code&gt;return_convergence_delta&lt;/code&gt; 输入参数。返回的增量的绝对值可以解释为每个输入样本的近似误差。它也可以作为给定输入和基线的积分近似的精确度的代理。如果近似误差很大，我们可以通过将 &lt;code&gt;n_steps&lt;/code&gt; 设置为更大的值来尝试更多的积分近似步骤。并非所有算法都返回近似误差。但是，那些基于算法的完整性属性对其进行计算的人。</target>
        </trans-unit>
        <trans-unit id="9bc5b2cbf539dd2b556b4ee16093e2dd98e5e53f" translate="yes" xml:space="preserve">
          <source>The latest release of Captum is easily installed either via
&lt;a href=&quot;https://www.anaconda.com/distribution/#download-section&quot;&gt;Anaconda&lt;/a&gt; (recommended):</source>
          <target state="translated">可以通过&lt;a href=&quot;https://www.anaconda.com/distribution/#download-section&quot;&gt;Anaconda&lt;/a&gt;轻松安装最新版本的Captum （推荐）：</target>
        </trans-unit>
        <trans-unit id="14456e5d622ffef206d84cb2547dd1292a3e6a4b" translate="yes" xml:space="preserve">
          <source>The number of elements in the &lt;code&gt;delta&lt;/code&gt; tensor is equal to: &lt;code&gt;n_samples * input.shape[0]&lt;/code&gt;
In order to get a example-based delta, we can, for example, average them:</source>
          <target state="translated">&lt;code&gt;delta&lt;/code&gt; 张量中的元素数量等于： &lt;code&gt;n_samples * input.shape[0]&lt;/code&gt; 为了获得基于示例的增量，我们可以例如对它们进行平均：</target>
        </trans-unit>
        <trans-unit id="d97f36b304cf7bf6d19d6ba216bf83da80bc9ca1" translate="yes" xml:space="preserve">
          <source>The primary audiences for Captum are model developers who are looking to improve their models and understand which features are important and interpretability researchers focused on identifying algorithms that can better interpret many types of models.</source>
          <target state="translated">Captum的主要受众是那些希望改进他们的模型并了解哪些特征是重要的模型开发者,以及专注于识别能够更好地解释多种类型模型的算法的可解释性研究人员。</target>
        </trans-unit>
        <trans-unit id="09bb5c690208bfa966db7460586a698914a360bd" translate="yes" xml:space="preserve">
          <source>The slides of our presentation from NeurIPS 2019 can be found &lt;a href=&quot;docs/presentations/Captum_NeurIPS_2019_final.key&quot;&gt;here&lt;/a&gt;</source>
          <target state="translated">可在&lt;a href=&quot;docs/presentations/Captum_NeurIPS_2019_final.key&quot;&gt;此处&lt;/a&gt;找到我们来自NeurIPS 2019的演示文稿的幻灯片</target>
        </trans-unit>
        <trans-unit id="5d0367e1f5fde1ede3db753f108801cb14982eac" translate="yes" xml:space="preserve">
          <source>To analyze a sample model on CIFAR10 via Captum Insights run</source>
          <target state="translated">要通过Captum Insights分析CIFAR10上的样本模型,请运行以下程序。</target>
        </trans-unit>
        <trans-unit id="1b78a188c82782ae0e64234fb5851ce273466f93" translate="yes" xml:space="preserve">
          <source>To build Insights you will need &lt;a href=&quot;https://nodejs.org/en/&quot;&gt;Node&lt;/a&gt; &amp;gt;= 8.x
and &lt;a href=&quot;https://yarnpkg.com/en/&quot;&gt;Yarn&lt;/a&gt; &amp;gt;= 1.5.</source>
          <target state="translated">要构建见解，您将需要&lt;a href=&quot;https://nodejs.org/en/&quot;&gt;Node&lt;/a&gt; &amp;gt; = 8.x和&lt;a href=&quot;https://yarnpkg.com/en/&quot;&gt;Yarn&lt;/a&gt; &amp;gt; = 1.5。</target>
        </trans-unit>
        <trans-unit id="5468c50938c4ec01b3019827d9753bc27eccd242" translate="yes" xml:space="preserve">
          <source>To build and launch from a checkout in a conda environment run</source>
          <target state="translated">要在conda环境下从结帐处建立和启动,请运行以下命令</target>
        </trans-unit>
        <trans-unit id="47d309089702b5779d1249906c184aca6a17334f" translate="yes" xml:space="preserve">
          <source>To build the widget from a checkout in a conda environment run</source>
          <target state="translated">要在conda环境下从结账中构建小部件,请运行以下命令</target>
        </trans-unit>
        <trans-unit id="039a5244d60906d43c5c15a0a20b10397b0bc5f9" translate="yes" xml:space="preserve">
          <source>To customize the installation, you can also run the following variants of the
above:</source>
          <target state="translated">要自定义安装,你也可以运行上述的以下变体。</target>
        </trans-unit>
        <trans-unit id="a39ccefe51118817f1b35b636167cdb3bd9357d8" translate="yes" xml:space="preserve">
          <source>To execute unit tests from a manual install, run:</source>
          <target state="translated">要从手动安装中执行单元测试,请运行。</target>
        </trans-unit>
        <trans-unit id="4ac1cec1a4406720bdada7e35a448ad0dfd20d82" translate="yes" xml:space="preserve">
          <source>To make computations deterministic, let's fix random seeds.</source>
          <target state="translated">为了使计算具有确定性,让我们固定随机种子。</target>
        </trans-unit>
        <trans-unit id="eba414e2b73da649f8d414e82f52b11624820726" translate="yes" xml:space="preserve">
          <source>We will apply model interpretability algorithms on the network
mentioned above in order to understand the importance of individual
neurons/layers and the parts of the input that play an important role in the
final prediction.</source>
          <target state="translated">我们将在上述网络上应用模型可解释性算法,以了解单个神经元/层的重要性以及输入中对最终预测起重要作用的部分。</target>
        </trans-unit>
        <trans-unit id="168626e3b7f39ed35712d4be0f4311e69049dd72" translate="yes" xml:space="preserve">
          <source>We will start with the &lt;code&gt;NeuronConductance&lt;/code&gt;. &lt;code&gt;NeuronConductance&lt;/code&gt; helps us to identify
input features that are important for a particular neuron in a given
layer. It decomposes the computation of integrated gradients via the chain rule by
defining the importance of a neuron as path integral of the derivative of the output
with respect to the neuron times the derivatives of the neuron with respect to the
inputs of the model.</source>
          <target state="translated">我们将从 &lt;code&gt;NeuronConductance&lt;/code&gt; 开始。 &lt;code&gt;NeuronConductance&lt;/code&gt; 帮助我们识别对于给定层中特定神经元重要的输入特征。通过将神经元的重要性定义为输出相对于神经元的导数的路径积分乘以神经元相对于模型输入的导数的路径积分，可通过链规则分解积分梯度的计算。</target>
        </trans-unit>
        <trans-unit id="3aee6cb4b987c6eb98bae057c8033da66b7ba223" translate="yes" xml:space="preserve">
          <source>With the increase in model complexity and the resulting lack of transparency, model interpretability methods have become increasingly important. Model understanding is both an active area of research as well as an area of focus for practical applications across industries using machine learning. Captum provides state-of-the-art algorithms, including Integrated Gradients, to provide researchers and developers with an easy way to understand which features are contributing to a model&amp;rsquo;s output.</source>
          <target state="translated">随着模型复杂性的增加以及由此导致的缺乏透明度，模型可解释性方法变得越来越重要。模型理解既是研究的活跃领域，也是跨行业使用机器学习进行实际应用的重点领域。Captum提供了包括集成渐变在内的最新算法，为研究人员和开发人员提供了一种简单的方法来了解哪些功能对模型的输出有所贡献。</target>
        </trans-unit>
        <trans-unit id="ffc76686099e22242eb4269a3745fa2f6e1ef1d4" translate="yes" xml:space="preserve">
          <source>and navigate to the URL specified in the output.</source>
          <target state="translated">并导航到输出中指定的URL。</target>
        </trans-unit>
        <trans-unit id="2eeef8b3dfe3c6e07456229818d93864ce2c6fe7" translate="yes" xml:space="preserve">
          <source>in order to get per example average delta.</source>
          <target state="translated">为了得到每个例子的平均delta。</target>
        </trans-unit>
        <trans-unit id="d6773e7adcc2adec52348c71e0551f68a9f85abd" translate="yes" xml:space="preserve">
          <source>or via &lt;code&gt;pip&lt;/code&gt;:</source>
          <target state="translated">或通过 &lt;code&gt;pip&lt;/code&gt; ：</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
