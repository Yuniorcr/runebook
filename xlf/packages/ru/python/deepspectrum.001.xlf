<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ru" datatype="htmlbody" original="https://pypi.org/project/deepspectrum/">
    <body>
      <group id="deepspectrum">
        <trans-unit id="da39a3ee5e6b4b0d3255bfef95601890afd80709" translate="yes" xml:space="preserve">
          <source/>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1cb4bd88ddb5a8f0c8fe4b85b749da82d823ae72" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;(c) 2017-2020 Shahin Amiriparian, Maurice Gerczuk, Sandra Ottl, Bj&amp;ouml;rn Schuller: Universit&amp;auml;t Augsburg&lt;/strong&gt;
Published under GPLv3, see the LICENSE.md file for details.</source>
          <target state="translated">&lt;strong&gt;(c) 2017-2020 гг. Шахин Амирипарян, Морис Герчук, Сандра Оттль, Бьёрн Шуллер: Аугсбургский университет&lt;/strong&gt; Опубликовано под GPLv3, подробности см. в файле LICENSE.md.</target>
        </trans-unit>
        <trans-unit id="ebac6302b62dd2f541f0cf3a23c13026bf32bedf" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;DeepSpectrum&lt;/strong&gt; is a Python toolkit for feature extraction from audio data with pre-trained Image Convolutional Neural Networks (CNNs). It features an extraction pipeline which first creates visual representations for audio data - plots of spectrograms or chromagrams - and then feeds them to a pre-trained Image CNN. Activations of a specific layer then form the final feature vectors.</source>
          <target state="translated">&lt;strong&gt;DeepSpectrum&lt;/strong&gt; - это набор инструментов Python для извлечения функций из аудиоданных с помощью предварительно обученных сверточных нейронных сетей изображений (CNN). Он имеет конвейер извлечения, который сначала создает визуальные представления для аудиоданных - графики спектрограмм или хроматограмм - а затем передает их в предварительно обученную CNN изображений. Затем активация определенного слоя формирует окончательные векторы признаков.</target>
        </trans-unit>
        <trans-unit id="a73c505c2793bd025d626af6731d68b4a45269bf" translate="yes" xml:space="preserve">
          <source>Citing</source>
          <target state="translated">Ссылка на</target>
        </trans-unit>
        <trans-unit id="0c895889011b796b94426d854b65030179ae6add" translate="yes" xml:space="preserve">
          <source>If you use DeepSpectrum or any code from DeepSpectrum in your research work, you are kindly asked to acknowledge the use of DeepSpectrum in your publications.</source>
          <target state="translated">Если вы используете DeepSpectrum или любой код DeepSpectrum в своей исследовательской работе,просим вас любезно подтвердить использование DeepSpectrum в ваших публикациях.</target>
        </trans-unit>
        <trans-unit id="6c8bfe5d094dd6fcbf34f0e0a0c079551ad219fd" translate="yes" xml:space="preserve">
          <source>Please direct any questions or requests to Shahin Amiriparian (shahin.amiriparian at tum.de) or Maurice Gercuk (maurice.gerczuk at informatik.uni-augsburg.de).</source>
          <target state="translated">Все вопросы и пожелания можно направлять Шахин Амирипарян (Shahin.amiriparian at tum.de)или Морису Герцук (maurice.gerczuk at informatik.uni-augsburg.de).</target>
        </trans-unit>
        <trans-unit id="171a1e4c9e1f5ec9f1fe0c8e4188ee2bb2b1bb0a" translate="yes" xml:space="preserve">
          <source>S. Amiriparian, M. Gerczuk, S. Ottl, N. Cummins, M. Freitag, S. Pugachevskiy, A. Baird and B. Schuller. Snore Sound Classification using Image-Based Deep Spectrum Features. In Proceedings of INTERSPEECH (Vol. 17, pp. 2017-434)</source>
          <target state="translated">S.Амирипарян,М.Герцук,С.Оттл,Н.Камминс,М.Фрейтаг,С.Пугачевский,А.Баирд,Б.Шуллер.Классификация храпового звука с использованием глубоких спектральных характеристик на основе изображения.В материалах ИНТЕРСПЕЕХ (Том 17,с.2017-434).</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
