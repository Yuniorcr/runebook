<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ru" datatype="htmlbody" original="https://pypi.org/project/ffsubsync/">
    <body>
      <group id="ffsubsync">
        <trans-unit id="448fa61d60809d27051e5604a1053eafdfc3dbbb" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;http://www.numpy.org/&quot;&gt;numpy&lt;/a&gt; and, indirectly, &lt;a href=&quot;https://www.netlib.org/fftpack/&quot;&gt;FFTPACK&lt;/a&gt;, which powers the FFT-based algorithm for fast scoring of alignments between subtitles (or subtitles and video)</source>
          <target state="translated">&lt;a href=&quot;http://www.numpy.org/&quot;&gt;numpy&lt;/a&gt; и, косвенно, &lt;a href=&quot;https://www.netlib.org/fftpack/&quot;&gt;FFTPACK&lt;/a&gt; , который обеспечивает основанный на БПФ алгоритм для быстрой оценки совпадений между субтитрами (или субтитрами и видео)</target>
        </trans-unit>
        <trans-unit id="809173aad90d1b10ce189edf1551d1b0699e2f6a" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;https://pypi.org/project/srt/&quot;&gt;srt&lt;/a&gt; for operating on &lt;a href=&quot;https://en.wikipedia.org/wiki/SubRip#SubRip_text_file_format&quot;&gt;SRT files&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;https://pypi.org/project/srt/&quot;&gt;srt&lt;/a&gt; для работы с &lt;a href=&quot;https://en.wikipedia.org/wiki/SubRip#SubRip_text_file_format&quot;&gt;файлами SRT&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b1d4e9959623befe0fa4c1f81c6a08d9ec02186a" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;https://www.ffmpeg.org/&quot;&gt;ffmpeg&lt;/a&gt; and the &lt;a href=&quot;https://github.com/kkroening/ffmpeg-python&quot;&gt;ffmpeg-python&lt;/a&gt; wrapper, for extracting raw audio from video</source>
          <target state="translated">&lt;a href=&quot;https://www.ffmpeg.org/&quot;&gt;ffmpeg&lt;/a&gt; и оболочка &lt;a href=&quot;https://github.com/kkroening/ffmpeg-python&quot;&gt;ffmpeg-python&lt;/a&gt; для извлечения необработанного звука из видео.</target>
        </trans-unit>
        <trans-unit id="f402db43144acbb0439ef8edcbe14c9699525da0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;ffs&lt;/code&gt;, &lt;code&gt;subsync&lt;/code&gt; and &lt;code&gt;ffsubsync&lt;/code&gt; all work as entrypoints:</source>
          <target state="translated">&lt;code&gt;ffs&lt;/code&gt; , &lt;code&gt;subsync&lt;/code&gt; и &lt;code&gt;ffsubsync&lt;/code&gt; работают как точки входа:</target>
        </trans-unit>
        <trans-unit id="14b64238bfe66703a43272be5c9729b5ca77e61f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;ffsubsync&lt;/code&gt; uses the file extension to decide whether to perform voice activity
detection on the audio or to directly extract speech from an srt file.</source>
          <target state="translated">&lt;code&gt;ffsubsync&lt;/code&gt; использует расширение файла, чтобы решить, следует ли выполнять обнаружение голосовой активности для звука или напрямую извлекать речь из файла srt.</target>
        </trans-unit>
        <trans-unit id="00799ba9e026c577347c81635a03c034bba3e14e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;ffsubsync&lt;/code&gt; usually finishes in 20 to 30 seconds, depending on the length of the
video. The most expensive step is actually extraction of raw audio. If you
already have a correctly synchronized &quot;reference&quot; srt file (in which case audio
extraction can be skipped), &lt;code&gt;ffsubsync&lt;/code&gt; typically runs in less than a second.</source>
          <target state="translated">&lt;code&gt;ffsubsync&lt;/code&gt; обычно завершается через 20&amp;ndash;30 секунд, в зависимости от длины видео. Самым дорогостоящим этапом является извлечение необработанного звука. Если у вас уже есть правильно синхронизированный &amp;laquo;эталонный&amp;raquo; файл srt (в этом случае извлечение звука можно пропустить), &lt;code&gt;ffsubsync&lt;/code&gt; обычно запускается менее чем за секунду.</target>
        </trans-unit>
        <trans-unit id="936db9a8629b6aee1da2ac35146b55e3ac7b77db" translate="yes" xml:space="preserve">
          <source>At the request of some, you can now help cover my coffee expenses using the
Github Sponsors button at the top (recurring monthly payments), or using the below
Paypal Donate button (one-time payment):</source>
          <target state="translated">По просьбе некоторых,теперь вы можете помочь покрыть мои расходы на кофе с помощью кнопки Спонсоры Github в верхней части (повторяющиеся ежемесячные платежи),или с помощью кнопки Paypal Donate внизу (единовременный платеж):</target>
        </trans-unit>
        <trans-unit id="56f9b02e470ae04f5605651b0ca5cd5920c7d715" translate="yes" xml:space="preserve">
          <source>Besides general stability and usability improvements, one line
of work aims to extend the synchronization algorithm to handle splits
/ breaks in the middle of video not present in subtitles (or vice versa).
Developing a robust solution will take some time (assuming one is possible).
See &lt;a href=&quot;https://github.com/smacke/ffsubsync/issues/10&quot;&gt;#10&lt;/a&gt; for more details.</source>
          <target state="translated">Помимо общих улучшений стабильности и удобства использования, одно направление работы направлено на расширение алгоритма синхронизации для обработки разделений / разрывов в середине видео, отсутствующих в субтитрах (или наоборот). Разработка надежного решения займет некоторое время (если такое возможно). См. &lt;a href=&quot;https://github.com/smacke/ffsubsync/issues/10&quot;&gt;# 10&lt;/a&gt; для более подробной информации.</target>
        </trans-unit>
        <trans-unit id="bd217ff4214f14c1a032a45a800183c165249895" translate="yes" xml:space="preserve">
          <source>Code in this project is &lt;a href=&quot;https://opensource.org/licenses/MIT&quot;&gt;MIT licensed&lt;/a&gt;.</source>
          <target state="translated">Код в этом проекте &lt;a href=&quot;https://opensource.org/licenses/MIT&quot;&gt;лицензирован MIT&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="bfac50d6424b5166c3ee2808c85ae7c139b5182f" translate="yes" xml:space="preserve">
          <source>Credits</source>
          <target state="translated">Кредиты</target>
        </trans-unit>
        <trans-unit id="1946ed4e6d7a5cdee8942980594304622d5d448e" translate="yes" xml:space="preserve">
          <source>Discretize video and subtitles by time into 10ms windows.</source>
          <target state="translated">Скриннизируйте видео и субтитры по времени в окнах по 10 мс.</target>
        </trans-unit>
        <trans-unit id="61f87fb699391c08f8809648c3d512e2529450b6" translate="yes" xml:space="preserve">
          <source>FFsubsync</source>
          <target state="translated">FFsubsync</target>
        </trans-unit>
        <trans-unit id="d14e9d216a8814e80e6ada0f122fa233375bf1ab" translate="yes" xml:space="preserve">
          <source>First, make sure ffmpeg is installed. On MacOS, this looks like:</source>
          <target state="translated">Сначала убедитесь,что установлен ffmpeg.На MacOS это выглядит так:</target>
        </trans-unit>
        <trans-unit id="42edbb52a87cd00061f18e023951cf7cd5c5ef15" translate="yes" xml:space="preserve">
          <source>For each 10ms window, determine whether that window contains speech.  This
is trivial to do for subtitles (we just determine whether any subtitle is
&quot;on&quot; during each time window); for video, use an off-the-shelf voice
activity detector (VAD) like
the one built into &lt;a href=&quot;https://webrtc.org/&quot;&gt;webrtc&lt;/a&gt;.</source>
          <target state="translated">Для каждого окна 10 мс определите, содержит ли это окно речь. Это тривиально сделать для субтитров (мы просто определяем, включен ли какой-либо из субтитров в течение каждого временного окна); для видео используйте стандартный детектор голосовой активности (VAD), такой как встроенный в &lt;a href=&quot;https://webrtc.org/&quot;&gt;webrtc&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="c3cba160fe064a0d9a4fc24f20540221a2aff0ed" translate="yes" xml:space="preserve">
          <source>Future Work</source>
          <target state="translated">Будущая работа</target>
        </trans-unit>
        <trans-unit id="ad0a916130b1ffb1194d9d811a12d26d58f8df6c" translate="yes" xml:space="preserve">
          <source>Helping Development</source>
          <target state="translated">Содействие развитию</target>
        </trans-unit>
        <trans-unit id="90ccd6497400b5576aeca1bd94af74aae1e0a250" translate="yes" xml:space="preserve">
          <source>History</source>
          <target state="translated">История</target>
        </trans-unit>
        <trans-unit id="8cecc82d72d68f9151cb0901cfe40eeac15bfca6" translate="yes" xml:space="preserve">
          <source>How It Works</source>
          <target state="translated">Как это работает</target>
        </trans-unit>
        <trans-unit id="44abaabed373ce699f3a6b3019932545e4158606" translate="yes" xml:space="preserve">
          <source>If you want to live dangerously, you can grab the latest version as follows:</source>
          <target state="translated">Если вы хотите жить опасно,вы можете взять последнюю версию следующим образом:</target>
        </trans-unit>
        <trans-unit id="ce1d79c980df3c47404d3d29df7c08886649970a" translate="yes" xml:space="preserve">
          <source>In most cases, inconsistencies between video and subtitles occur when starting
or ending segments present in video are not present in subtitles, or vice versa.
This can occur, for example, when a TV episode recap in the subtitles was pruned
from video. FFsubsync typically works well in these cases, and in my experience
this covers &amp;gt;95% of use cases. Handling breaks and splits outside of the beginning
and ending segments is left to future work (see below).</source>
          <target state="translated">В большинстве случаев несоответствия между видео и субтитрами возникают, когда начальные или конечные сегменты, присутствующие в видео, отсутствуют в субтитрах, или наоборот. Это может произойти, например, когда из видео было удалено резюме эпизода ТВ в субтитрах. FFsubsync обычно хорошо работает в этих случаях, и, по моему опыту, он охватывает&amp;gt; 95% случаев использования. Обработка разрывов и разделений вне начального и конечного сегментов оставлена ​​на будущее (см. Ниже).</target>
        </trans-unit>
        <trans-unit id="fd6c3ebf7befca9f8208f86c76e4d4180303745c" translate="yes" xml:space="preserve">
          <source>Install</source>
          <target state="translated">Установить</target>
        </trans-unit>
        <trans-unit id="659525747c675f26d0d0761f93182ab5228cbc26" translate="yes" xml:space="preserve">
          <source>Into this:</source>
          <target state="translated">В это:</target>
        </trans-unit>
        <trans-unit id="0d05fd8158dba0121b4eac110b20f240f7818b92" translate="yes" xml:space="preserve">
          <source>Language-agnostic automatic synchronization of subtitles with video, so that
subtitles are aligned to the correct starting point within the video.</source>
          <target state="translated">Языковая диагностика автоматическая синхронизация субтитров с видео,так что субтитры выровнены по правильной отправной точке в видео.</target>
        </trans-unit>
        <trans-unit id="420a9347981effc83ba7d1df62790a49716f38bb" translate="yes" xml:space="preserve">
          <source>Language-agnostic synchronization of subtitles with video.</source>
          <target state="translated">Языковая диагностическая синхронизация субтитров с видео.</target>
        </trans-unit>
        <trans-unit id="3229609e15436ec51bcf00818a69a84dbc58a0c2" translate="yes" xml:space="preserve">
          <source>License</source>
          <target state="translated">Лицензия</target>
        </trans-unit>
        <trans-unit id="a7c04c64ed3f2a9374590c76c50d3b7f1b18e3da" translate="yes" xml:space="preserve">
          <source>Limitations</source>
          <target state="translated">Ограничения</target>
        </trans-unit>
        <trans-unit id="beac1d4d9d908d34bbabd5497b31900615c1e739" translate="yes" xml:space="preserve">
          <source>Next, grab the script. It should work with both Python 2 and Python 3:</source>
          <target state="translated">Следующий,возьми сценарий.Он должен работать и с Python 2,и с Python 3:</target>
        </trans-unit>
        <trans-unit id="179a4231cbcf797a1ea61865a797b3047681d7b0" translate="yes" xml:space="preserve">
          <source>Now we have two binary strings: one for the subtitles, and one for the
video.  Try to align these strings by matching 0's with 0's and 1's with
1's. We score these alignments as (# video 1's matched w/ subtitle 1's) - (#
video 1's matched with subtitle 0's).</source>
          <target state="translated">Теперь у нас есть две бинарные строки:одна для субтитров,другая для видео.Попробуйте выровнять эти строки,сопоставляя 0 с 0,а 1 с 1.Мы оцениваем эти выравнивания как (#видео 1 совпадает с w/субтитрами 1)-(#видео 1 совпадает с субтитрами 0).</target>
        </trans-unit>
        <trans-unit id="bc49bcc1bbf9322f0d673c127d5dd1764357aa92" translate="yes" xml:space="preserve">
          <source>Other excellent Python libraries like &lt;a href=&quot;https://docs.python.org/3/library/argparse.html&quot;&gt;argparse&lt;/a&gt; and &lt;a href=&quot;https://tqdm.github.io/&quot;&gt;tqdm&lt;/a&gt;, not related to the core functionality, but which enable much better experiences for developers and users.</source>
          <target state="translated">Другие отличные библиотеки Python, такие как &lt;a href=&quot;https://docs.python.org/3/library/argparse.html&quot;&gt;argparse&lt;/a&gt; и &lt;a href=&quot;https://tqdm.github.io/&quot;&gt;tqdm&lt;/a&gt; , не связанные с основной функциональностью, но которые обеспечивают гораздо лучший опыт для разработчиков и пользователей.</target>
        </trans-unit>
        <trans-unit id="2d2cb022bc3d26bd1407c4aa787d5e46e1ad4c3b" translate="yes" xml:space="preserve">
          <source>Speed</source>
          <target state="translated">Скорость</target>
        </trans-unit>
        <trans-unit id="6d75a7aec098fab5da5f5616cd98e0d6589fb421" translate="yes" xml:space="preserve">
          <source>The best-scoring alignment from step 3 determines how to offset the subtitles
in time so that they are properly synced with the video. Because the binary
strings are fairly long (millions of digits for video longer than an hour), the
naive O(n^2) strategy for scoring all alignments is unacceptable. Instead, we
use the fact that &quot;scoring all alignments&quot; is a convolution operation and can
be implemented with the Fast Fourier Transform (FFT), bringing the complexity
down to O(n log n).</source>
          <target state="translated">Лучшее выравнивание по очкам из шага 3 определяет,как вовремя сместить субтитры,чтобы они были правильно синхронизированы с видео.Поскольку бинарные строки достаточно длинные (миллионы цифр для видео длиннее часа),наивная стратегия O(n^2)для выравнивания всех выравниваний неприемлема.Вместо этого мы используем тот факт,что &quot;выравнивание всех выравниваний&quot; является операцией свертки и может быть реализовано с помощью быстрого преобразования Фурье (FFT),сводя сложность к O(n log n).</target>
        </trans-unit>
        <trans-unit id="b6cb2e1a9df05d019e4ce2e098c42168484163b6" translate="yes" xml:space="preserve">
          <source>The implementation for this project was started during HackIllinois 2019, for
which it received an &lt;strong&gt;&lt;em&gt;Honorable Mention&lt;/em&gt;&lt;/strong&gt; (ranked in the top 5 projects,
excluding projects that won company-specific prizes).</source>
          <target state="translated">Реализация этого проекта началась во время HackIllinois 2019, за что он получил &lt;strong&gt;&lt;em&gt;почетную&lt;/em&gt;&lt;/strong&gt; награду (вошел в пятерку лучших проектов, за исключением проектов, получивших призы от компании).</target>
        </trans-unit>
        <trans-unit id="c24de39b3bb0b16a5df396d44c3f3aebba913c44" translate="yes" xml:space="preserve">
          <source>The synchronization algorithm operates in 3 steps:</source>
          <target state="translated">Алгоритм синхронизации работает в 3 этапа:</target>
        </trans-unit>
        <trans-unit id="94226cd553bfe5c121e7a05322ec2c6041760ba8" translate="yes" xml:space="preserve">
          <source>There may be occasions where you have a correctly synchronized srt file in a
language you are unfamiliar with, as well as an unsynchronized srt file in your
native language. In this case, you can use the correctly synchronized srt file
directly as a reference for synchronization, instead of using the video as the
reference:</source>
          <target state="translated">Могут быть случаи,когда у Вас есть правильно синхронизированный srt-файл на незнакомом Вам языке,а также несинхронизированный srt-файл на Вашем родном языке.В этом случае Вы можете использовать правильно синхронизированный srt-файл непосредственно в качестве ссылки для синхронизации,вместо того,чтобы использовать видео в качестве ссылки:</target>
        </trans-unit>
        <trans-unit id="da9f448081113e5f2aa6a2b4381ed0a353647124" translate="yes" xml:space="preserve">
          <source>This project would not be possible without the following libraries:</source>
          <target state="translated">Этот проект был бы невозможен без следующих библиотек:</target>
        </trans-unit>
        <trans-unit id="7240d4aab825d0799c8f63afc0c0ff0047392b6e" translate="yes" xml:space="preserve">
          <source>Turn this:</source>
          <target state="translated">Поверни это:</target>
        </trans-unit>
        <trans-unit id="0bb18642b70b9f8a9c12ccf39487328f306b8e19" translate="yes" xml:space="preserve">
          <source>Usage</source>
          <target state="translated">Использование</target>
        </trans-unit>
        <trans-unit id="75a062ef757a8dddb6401a1ad2fd757ca432ebd9" translate="yes" xml:space="preserve">
          <source>VAD from &lt;a href=&quot;https://webrtc.org/&quot;&gt;webrtc&lt;/a&gt; and the &lt;a href=&quot;https://github.com/wiseman/py-webrtcvad&quot;&gt;py-webrtcvad&lt;/a&gt; wrapper, for speech detection</source>
          <target state="translated">VAD из &lt;a href=&quot;https://webrtc.org/&quot;&gt;webrtc&lt;/a&gt; и оболочка &lt;a href=&quot;https://github.com/wiseman/py-webrtcvad&quot;&gt;py-webrtcvad&lt;/a&gt; для обнаружения речи</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
