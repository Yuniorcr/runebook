<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ru" datatype="htmlbody" original="https://pypi.org/project/captum/">
    <body>
      <group id="captum">
        <trans-unit id="7e224d6675fc514ea7defb9516638683fceb2bcc" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Deconvolution&lt;/code&gt;, &lt;code&gt;Neuron Deconvolution&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1311.2901.pdf&quot;&gt;Visualizing and Understanding Convolutional Networks, Matthew D Zeiler et al. 2014&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Deconvolution&lt;/code&gt; , &lt;code&gt;Neuron Deconvolution&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/pdf/1311.2901.pdf&quot;&gt;визуализация и понимание сверточных сетей, Мэтью Зейлер и др. 2014 г.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f77c45466355b115b010aa83e3ec5115e53cc011" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;DeepLift&lt;/code&gt; assigns similar attribution scores as &lt;code&gt;IntegratedGradients&lt;/code&gt; to inputs,
however it has lower execution time. Another important thing to remember about
DeepLift is that it currently doesn't support all non-linear activation types.
For more details on limitations of the current implementation, please see the
&lt;a href=&quot;https://arxiv.org/abs/1704.02685&quot;&gt;DeepLift paper&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;DeepLift&lt;/code&gt; присваивает входным параметрам те же оценки атрибуции, что и &lt;code&gt;IntegratedGradients&lt;/code&gt; , но имеет меньшее время выполнения. Еще одна важная вещь, которую следует помнить о DeepLift, заключается в том, что в настоящее время он поддерживает не все типы нелинейной активации. Дополнительные сведения об ограничениях текущей реализации см. &lt;a href=&quot;https://arxiv.org/abs/1704.02685&quot;&gt;В документе DeepLift&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="35d8eea45bfc985cc4e9ed2b9f13dcc77a172786" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;DeepLift&lt;/code&gt;, &lt;code&gt;NeuronDeepLift&lt;/code&gt;, &lt;code&gt;LayerDeepLift&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1704.02685.pdf&quot;&gt;Learning Important Features Through Propagating Activation Differences, Avanti Shrikumar et al. 2017&lt;/a&gt; and &lt;a href=&quot;https://openreview.net/pdf?id=Sy21R9JAW&quot;&gt;Towards better understanding of gradient-based attribution methods for deep neural networks, Marco Ancona et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;DeepLift&lt;/code&gt; , &lt;code&gt;NeuronDeepLift&lt;/code&gt; , &lt;code&gt;LayerDeepLift&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/pdf/1704.02685.pdf&quot;&gt;изучение важных функций через распространение различий активации, Аванти Шрикумар и др. 2017 г.&lt;/a&gt; и &amp;laquo; &lt;a href=&quot;https://openreview.net/pdf?id=Sy21R9JAW&quot;&gt;На пути к лучшему пониманию методов атрибуции на основе градиента для глубоких нейронных сетей&amp;raquo; Марко Анкона и др. 2018 г.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0935b98602a2196eb3ce841148929580db331f26" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;DeepLiftShap&lt;/code&gt; uses &lt;code&gt;DeepLift&lt;/code&gt; to compute attribution score for each
input-baseline pair and averages it for each input across all baselines.</source>
          <target state="translated">&lt;code&gt;DeepLiftShap&lt;/code&gt; использует &lt;code&gt;DeepLift&lt;/code&gt; для вычисления оценки атрибуции для каждой пары исходных данных и базовых показателей и усредняет ее для каждого входа по всем базовым показателям.</target>
        </trans-unit>
        <trans-unit id="70f4204e74fbab884413f100ee93ebc43bf69602" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Feature Permutation&lt;/code&gt;: &lt;a href=&quot;https://christophm.github.io/interpretable-ml-book/feature-importance.html&quot;&gt;Permutation Feature Importance&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Feature Permutation&lt;/code&gt; : &lt;a href=&quot;https://christophm.github.io/interpretable-ml-book/feature-importance.html&quot;&gt;важность перестановки признаков&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="dfd45f4166b5d1094537f54fcf044b34d5f360af" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;GradCAM&lt;/code&gt;, &lt;code&gt;Guided GradCAM&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1610.02391.pdf&quot;&gt;Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization, Ramprasaath R. Selvaraju et al. 2017&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;GradCAM&lt;/code&gt; , &lt;code&gt;Guided GradCAM&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/abs/1610.02391.pdf&quot;&gt;Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization, Ramprasaath R. Selvaraju et al. 2017 г.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9c73c2db449b0b144f4acb50ee0a1570caed5366" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;GradientShap&lt;/code&gt; first chooses a random baseline from baselines' distribution, then
adds gaussian noise with std=0.09 to each input example &lt;code&gt;n_samples&lt;/code&gt; times.
Afterwards, it chooses a random point between each example-baseline pair and
computes the gradients with respect to target class (in this case target=0). Resulting
attribution is the mean of gradients * (inputs - baselines)</source>
          <target state="translated">&lt;code&gt;GradientShap&lt;/code&gt; сначала выбирает случайную базовую линию из распределения базовых линий, затем добавляет гауссовский шум со стандартным значением 0,09 к каждому входному примеру &lt;code&gt;n_samples&lt;/code&gt; раз. После этого он выбирает случайную точку между каждой парой пример-базовый уровень и вычисляет градиенты по отношению к целевому классу (в данном случае target = 0). Результирующая атрибуция - это среднее значение градиентов * (исходные данные - исходные данные)</target>
        </trans-unit>
        <trans-unit id="745f47441809340b71cc76401a089bf5ad757fd9" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;GradientShap&lt;/code&gt;, &lt;code&gt;NeuronGradientShap&lt;/code&gt;, &lt;code&gt;LayerGradientShap&lt;/code&gt;, &lt;code&gt;DeepLiftShap&lt;/code&gt;, &lt;code&gt;NeuronDeepLiftShap&lt;/code&gt;, &lt;code&gt;LayerDeepLiftShap&lt;/code&gt;: &lt;a href=&quot;http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions&quot;&gt;A Unified Approach to Interpreting Model Predictions, Scott M. Lundberg et al. 2017&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;GradientShap&lt;/code&gt; , &lt;code&gt;NeuronGradientShap&lt;/code&gt; , &lt;code&gt;LayerGradientShap&lt;/code&gt; , &lt;code&gt;DeepLiftShap&lt;/code&gt; , &lt;code&gt;NeuronDeepLiftShap&lt;/code&gt; , &lt;code&gt;LayerDeepLiftShap&lt;/code&gt; : &lt;a href=&quot;http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions&quot;&gt;единый подход к интерпретации прогнозов модели, Скотт М. Лундберг и др. 2017 г.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="602dfc33d8aba3857725b949b893d500e50a678d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Guided Backpropagation&lt;/code&gt;, &lt;code&gt;Neuron Guided Backpropagation&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1412.6806.pdf&quot;&gt;Striving for Simplicity: The All Convolutional Net, Jost Tobias Springenberg et al. 2015&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Guided Backpropagation&lt;/code&gt; , &lt;code&gt;Neuron Guided Backpropagation&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/pdf/1412.6806.pdf&quot;&gt;стремление к простоте: вся сверточная сеть, Йост Тобиас Спрингенберг и др. 2015 г.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="32d5dd2bb7640e2b606a6084f2cafa2a031b478b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;InputXGradient&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1611.07270&quot;&gt;Investigating the influence of noise and distractors on the interpretation of neural networks, Pieter-Jan Kindermans et al. 2016&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;InputXGradient&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/abs/1611.07270&quot;&gt;исследование влияния шума и отвлекающих факторов на интерпретацию нейронных сетей, Питер-Ян Киндерманс и др. 2016 г.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b69ede686e5d4e904dbf0247c2f663ff896f0a0c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;IntegratedGradients&lt;/code&gt;, &lt;code&gt;LayerIntegratedGradients&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1703.01365&quot;&gt;Axiomatic Attribution for Deep Networks, Mukund Sundararajan et al. 2017&lt;/a&gt; and &lt;a href=&quot;https://arxiv.org/abs/1805.05492&quot;&gt;Did the Model Understand the Question?, Pramod K. Mudrakarta, et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;IntegratedGradients&lt;/code&gt; , &lt;code&gt;LayerIntegratedGradients&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/abs/1703.01365&quot;&gt;аксиоматическая атрибуция для глубоких сетей, Мукунд Сундарараджан и др. 2017 г.&lt;/a&gt; и &lt;a href=&quot;https://arxiv.org/abs/1805.05492&quot;&gt;&amp;laquo;Поняла ли модель вопрос?&amp;raquo;, Прамод К. Мудракарта и др. 2018 г.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1ce041e0904e2eb6fe9e166ae16f4a94c041216f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;InternalInfluence&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1802.03788.pdf&quot;&gt;Influence-Directed Explanations for Deep Convolutional Networks, Klas Leino et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;InternalInfluence&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/pdf/1802.03788.pdf&quot;&gt;Influence-Directed Explanations for Deep Convolutional Networks, Klas Leino et al. 2018 г.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6464d80d482910b859e98e94be43a85d78c92fff" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;LayerConductance&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1807.09946.pdf&quot;&gt;Computationally Efficient Measures of Internal Neuron Importance, Avanti Shrikumar et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;LayerConductance&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/pdf/1807.09946.pdf&quot;&gt;Computationally Efficient Measures of Internal Neuron Importance, Avanti Shrikumar et al. 2018 г.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a390e01ea3142478285f0168a9d0220de3b869e1" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;NeuronConductance&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1805.12233&quot;&gt;How Important is a neuron?, Kedar Dhamdhere et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;NeuronConductance&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/abs/1805.12233&quot;&gt;насколько &lt;/a&gt;важен нейрон? Кедар Дхамдхере и др. 2018 г.</target>
        </trans-unit>
        <trans-unit id="7fa53a48f5e924963274d272e5ae392af89f2c41" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;NeuronIntegratedGradients&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1807.09946.pdf&quot;&gt;Computationally Efficient Measures of Internal Neuron Importance, Avanti Shrikumar et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;NeuronIntegratedGradients&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/pdf/1807.09946.pdf&quot;&gt;вычислительно эффективные меры важности внутренних нейронов, Avanti Shrikumar et al. 2018 г.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3406337d51997da5374b792bb810c3069f71f625" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;NoiseTunnel&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1810.03292&quot;&gt;Sanity Checks for Saliency Maps, Julius Adebayo et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;NoiseTunnel&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/abs/1810.03292&quot;&gt;проверки работоспособности для карт значимости, Юлиус Адебайо и др. 2018 г.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="180de40fda30abd90e30c91da063de517cd65e10" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Occlusion&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1311.2901&quot;&gt;Visualizing and Understanding Convolutional Networks&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Occlusion&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/abs/1311.2901&quot;&gt;визуализация и понимание сверточных сетей&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="ef3e53fd11ec0ec42f34212a68a5a8f640a980a4" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Saliency&lt;/code&gt;, &lt;code&gt;NeuronGradient&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1312.6034.pdf&quot;&gt;Deep Inside Convolutional Networks: Visualising
Image Classification Models and Saliency Maps, K. Simonyan, et. al. 2014&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Saliency&lt;/code&gt; , &lt;code&gt;NeuronGradient&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/pdf/1312.6034.pdf&quot;&gt;глубоко внутри сверточные сети: визуализация моделей классификации изображений и карт значимости, К. Симонян и др. al. 2014 г.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d72716650eca9202bde62762d848353fd9f89e55" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Shapely Value Sampling&lt;/code&gt;: &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0305054808000804&quot;&gt;Polynomial calculation of the Shapley value based on sampling&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Shapely Value Sampling&lt;/code&gt; : &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0305054808000804&quot;&gt;полиномиальное вычисление значения Шепли на основе выборки&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2f313a5b98f914e2d22e3666af676c317da1a76c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Shapely Value&lt;/code&gt;: &lt;a href=&quot;https://apps.dtic.mil/dtic/tr/fulltext/u2/604084.pdf&quot;&gt;A value for n-person games. Contributions to the Theory of Games 2.28 (1953): 307-317&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Shapely Value&lt;/code&gt; : &lt;a href=&quot;https://apps.dtic.mil/dtic/tr/fulltext/u2/604084.pdf&quot;&gt;ценность для игр с &lt;/a&gt;участием n человек. Вклад в теорию игр 2.28 (1953): 307-317.</target>
        </trans-unit>
        <trans-unit id="cc62bf28a6aaadab7c58506486d1282344c4f152" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;SmoothGrad&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1706.03825&quot;&gt;SmoothGrad: removing noise by adding noise, Daniel Smilkov et al. 2017&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;SmoothGrad&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/abs/1706.03825&quot;&gt;SmoothGrad: удаление шума путем добавления шума, Даниэль Смилков и др. 2017 г.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="97d9a83b33d1a1e1468782cbf91b17ba820547f9" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;pip install -e .[dev]&lt;/code&gt;: Also installs all tools necessary for development
(testing, linting, docs building; see &lt;a href=&quot;#contributing&quot;&gt;Contributing&lt;/a&gt; below).</source>
          <target state="translated">&lt;code&gt;pip install -e .[dev]&lt;/code&gt; : также устанавливает все инструменты, необходимые для разработки (тестирование, анализ, сборка документации; см. &lt;a href=&quot;#contributing&quot;&gt;Содействие&lt;/a&gt; ниже).</target>
        </trans-unit>
        <trans-unit id="5d7c7835d367a7e4679627572238c42726e0601e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;pip install -e .[insights]&lt;/code&gt;: Also installs all packages necessary for running Captum Insights.</source>
          <target state="translated">&lt;code&gt;pip install -e .[insights]&lt;/code&gt; : также устанавливает все пакеты, необходимые для работы Captum Insights.</target>
        </trans-unit>
        <trans-unit id="d5bb8d5b6fa5ab568327e9ea794621e7ee38d45f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;pip install -e .[tutorials]&lt;/code&gt;: Also installs all packages necessary for running the tutorial notebooks.</source>
          <target state="translated">&lt;code&gt;pip install -e .[tutorials]&lt;/code&gt; : также устанавливает все пакеты, необходимые для работы с учебными блокнотами.</target>
        </trans-unit>
        <trans-unit id="c641fcc1b80e58fb730b1652c8b6c7fc9b227fd8" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;Captum is currently in beta and under active development!&lt;/em&gt;</source>
          <target state="translated">&lt;em&gt;Captum в настоящее время находится в стадии бета-тестирования и находится в активной разработке!&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="6897acde3a3c220a635980f413f5941e5fc0a6b4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Installation Requirements&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;Требования к установке&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="2208733c3a7ee98009723d2713bcd61e00a43c9c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Manual / Dev install&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;Установка вручную / для разработчиков&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="c3f76124c7fa391369fe5c7fb44c51cf9d1ed726" translate="yes" xml:space="preserve">
          <source>About Captum</source>
          <target state="translated">О Каптуме</target>
        </trans-unit>
        <trans-unit id="d8c0847ea163dcd16d6f2a889df7dce1e95c7176" translate="yes" xml:space="preserve">
          <source>Below is an example of how we can apply &lt;code&gt;DeepLift&lt;/code&gt; and &lt;code&gt;DeepLiftShap&lt;/code&gt; on the
&lt;code&gt;ToyModel&lt;/code&gt; described above. Current implementation of DeepLift supports only
&lt;code&gt;Rescale&lt;/code&gt; rule.
For more details on alternative implementations, please see the &lt;a href=&quot;https://arxiv.org/abs/1704.02685&quot;&gt;DeepLift paper&lt;/a&gt;.</source>
          <target state="translated">Ниже приведен пример того, как мы можем применить &lt;code&gt;DeepLift&lt;/code&gt; и &lt;code&gt;DeepLiftShap&lt;/code&gt; к &lt;code&gt;ToyModel&lt;/code&gt; , описанной выше. Текущая реализация DeepLift поддерживает только правило &lt;code&gt;Rescale&lt;/code&gt; . Дополнительные сведения об альтернативных реализациях см. &lt;a href=&quot;https://arxiv.org/abs/1704.02685&quot;&gt;В документе DeepLift&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="021481ec74cf7f851fd8bb8de29f48519b026a55" translate="yes" xml:space="preserve">
          <source>Captum Insights</source>
          <target state="translated">Каптум Инсайтс</target>
        </trans-unit>
        <trans-unit id="b5e6347c0220e027a895cf1796661a4eca041832" translate="yes" xml:space="preserve">
          <source>Captum Insights Jupyter Widget</source>
          <target state="translated">Капитан Инсайтс Джупайтер Виджет.</target>
        </trans-unit>
        <trans-unit id="50ea9b39e0ca2b1e147f71e19c8284e932f29b95" translate="yes" xml:space="preserve">
          <source>Captum Insights also has a Jupyter widget providing the same user interface as the web app.
To install and enable the widget, run</source>
          <target state="translated">Captum Insights также имеет виджет Jupyter,предоставляющий тот же пользовательский интерфейс,что и веб-приложение.Чтобы установить и включить виджет,запустите</target>
        </trans-unit>
        <trans-unit id="2284f9438ef0b1f48a107c6a47037d5562ef7a07" translate="yes" xml:space="preserve">
          <source>Captum can also be used by application engineers who are using trained models in production. Captum provides easier troubleshooting through improved model interpretability, and the potential for delivering better explanations to end users on why they&amp;rsquo;re seeing a specific piece of content, such as a movie recommendation.</source>
          <target state="translated">Captum также может использоваться инженерами по приложениям, которые используют обученные модели в производстве. Captum упрощает устранение неполадок за счет улучшенной интерпретируемости модели и возможности предоставления конечным пользователям более точных объяснений того, почему они видят определенный фрагмент контента, например рекомендацию фильма.</target>
        </trans-unit>
        <trans-unit id="e072252aa5db22cac92d10e2402e5669eae223d4" translate="yes" xml:space="preserve">
          <source>Captum helps ML researchers more easily implement interpretability algorithms that can interact with PyTorch models. Captum also allows researchers to quickly benchmark their work against other existing algorithms available in the library.</source>
          <target state="translated">Captum помогает исследователям ML легче реализовывать алгоритмы интерпретации,которые могут взаимодействовать с моделями PyTorch.Captum также позволяет исследователям быстро сравнивать свою работу с другими существующими алгоритмами,доступными в библиотеке.</target>
        </trans-unit>
        <trans-unit id="d26bdb66327c68c373a8e184aae92f50105b84ad" translate="yes" xml:space="preserve">
          <source>Captum helps you interpret and understand predictions of PyTorch models by
exploring features that contribute to a prediction the model makes.
It also helps understand which neurons and layers are important for
model predictions.</source>
          <target state="translated">Captum помогает вам интерпретировать и понимать прогнозы моделей PyTorch,исследуя функции,которые способствуют прогнозированию,которое делает модель.Он также помогает понять,какие нейроны и слои важны для прогнозирования модели.</target>
        </trans-unit>
        <trans-unit id="48db440dde81207b626929193aa5ff14516a272f" translate="yes" xml:space="preserve">
          <source>Captum is BSD licensed, as found in the &lt;a href=&quot;LICENSE&quot;&gt;LICENSE&lt;/a&gt; file.</source>
          <target state="translated">Captum является BSD лицензии, как найдено в &lt;a href=&quot;LICENSE&quot;&gt;ЛИЦЕНЗИИ&lt;/a&gt; файле.</target>
        </trans-unit>
        <trans-unit id="2b556e02df9343beb45e9c79545ddba2410d2664" translate="yes" xml:space="preserve">
          <source>Captum is a model interpretability and understanding library for PyTorch.
Captum means comprehension in latin and contains general purpose implementations
of integrated gradients, saliency maps, smoothgrad, vargrad and others for
PyTorch models. It has quick integration for models built with domain-specific
libraries such as torchvision, torchtext, and others.</source>
          <target state="translated">Captum-это библиотека интерпретации и понимания моделей для PyTorch.Captum означает понимание на латыни и содержит реализации общего назначения интегрированных градиентов,карт saliency,гладкостей,vargrad и других для PyTorch-моделей.Имеет быструю интеграцию для моделей,построенных с доменными библиотеками,такими как torchvision,torchtext и другими.</target>
        </trans-unit>
        <trans-unit id="712c9c0dc955ee835f95d4a0c2e34f430fb91038" translate="yes" xml:space="preserve">
          <source>Captum provides a web interface called Insights for easy visualization and
access to a number of our interpretability algorithms.</source>
          <target state="translated">Captum предоставляет веб-интерфейс под названием Insights для легкой визуализации и доступа к ряду наших алгоритмов интерпретации.</target>
        </trans-unit>
        <trans-unit id="2d82a4b27a4b305690d5ac612046a955778a9fa5" translate="yes" xml:space="preserve">
          <source>Contributing</source>
          <target state="translated">Вклад</target>
        </trans-unit>
        <trans-unit id="39703b21af9911d0f81c306612570543015fb4da" translate="yes" xml:space="preserve">
          <source>Currently, the library uses gradient-based interpretability algorithms
and attributes contributions to each input of the model with respect to
different neurons and layers, both intermediate and final.</source>
          <target state="translated">В настоящее время библиотека использует градиентные алгоритмы интерпретации и вклады атрибутов на каждом входе модели в отношении различных нейронов и слоев,как промежуточных,так и конечных.</target>
        </trans-unit>
        <trans-unit id="90ab72c08753cb3eced44073f94e601929bbf4a1" translate="yes" xml:space="preserve">
          <source>Deltas are computed for each &lt;code&gt;n_samples * input.shape[0]&lt;/code&gt; example. The user can,
for instance, average them:</source>
          <target state="translated">Дельты вычисляются для каждого &lt;code&gt;n_samples * input.shape[0]&lt;/code&gt; . Пользователь может, например, усреднить их:</target>
        </trans-unit>
        <trans-unit id="c6b820410c0912f7db59b8a701baa4c5631073ed" translate="yes" xml:space="preserve">
          <source>For model developers, Captum can be used to improve and troubleshoot models by facilitating the identification of different features that contribute to a model&amp;rsquo;s output in order to design better models and troubleshoot unexpected model outputs.</source>
          <target state="translated">Для разработчиков моделей Captum может использоваться для улучшения и устранения неполадок моделей, облегчая идентификацию различных функций, которые вносят вклад в выходные данные модели, чтобы разрабатывать лучшие модели и устранять непредвиденные выходы модели.</target>
        </trans-unit>
        <trans-unit id="010b85ad56b34c34c7c2a3b2436c740e30428ed5" translate="yes" xml:space="preserve">
          <source>Getting Started</source>
          <target state="translated">Начало работы</target>
        </trans-unit>
        <trans-unit id="523b5dd24d78e1688f499261e03d11aabe65c0e9" translate="yes" xml:space="preserve">
          <source>Here is an example how we can use &lt;code&gt;NoiseTunnel&lt;/code&gt; with &lt;code&gt;IntegratedGradients&lt;/code&gt;.</source>
          <target state="translated">Вот пример того, как мы можем использовать &lt;code&gt;NoiseTunnel&lt;/code&gt; с &lt;code&gt;IntegratedGradients&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2951f06ff53b46d9157f54d1ddb461c159a670d0" translate="yes" xml:space="preserve">
          <source>If you'd like to try our bleeding edge features (and don't mind potentially
running into the occasional bug here or there), you can install the latest
master directly from GitHub. For a basic install, run:</source>
          <target state="translated">Если вы хотите попробовать наши передовые возможности (и не возражаете против того,чтобы столкнуться с редкими ошибками здесь или там),вы можете установить последний мастер прямо с GitHub.Для базовой установки запустите:</target>
        </trans-unit>
        <trans-unit id="748139302b5f33a6af11cc4d8e2c307feed6a61f" translate="yes" xml:space="preserve">
          <source>In order to smooth and improve the quality of the attributions we can run
&lt;code&gt;IntegratedGradients&lt;/code&gt; and other attribution methods through a &lt;code&gt;NoiseTunnel&lt;/code&gt;.
&lt;code&gt;NoiseTunnel&lt;/code&gt; allows us to use &lt;code&gt;SmoothGrad&lt;/code&gt;, &lt;code&gt;SmoothGrad_Sq&lt;/code&gt; and &lt;code&gt;VarGrad&lt;/code&gt; techniques
to smoothen the attributions by aggregating them for multiple noisy
samples that were generated by adding gaussian noise.</source>
          <target state="translated">Чтобы сгладить и улучшить качество атрибуции, мы можем запустить &lt;code&gt;IntegratedGradients&lt;/code&gt; и другие методы атрибуции через &lt;code&gt;NoiseTunnel&lt;/code&gt; . &lt;code&gt;NoiseTunnel&lt;/code&gt; позволяет нам использовать &lt;code&gt;SmoothGrad&lt;/code&gt; , &lt;code&gt;SmoothGrad_Sq&lt;/code&gt; и &lt;code&gt;VarGrad&lt;/code&gt; для сглаживания атрибутов путем их агрегирования для нескольких зашумленных выборок, которые были созданы путем добавления гауссовского шума.</target>
        </trans-unit>
        <trans-unit id="37e62d8605abf42b9cf777a51788c55a03639d78" translate="yes" xml:space="preserve">
          <source>In this case, we choose to analyze the first neuron in the linear layer.</source>
          <target state="translated">В этом случае мы выбираем анализ первого нейрона в линейном слое.</target>
        </trans-unit>
        <trans-unit id="c81b79df3c6448eae7c4f80428b54cd5692a17d7" translate="yes" xml:space="preserve">
          <source>Installation</source>
          <target state="translated">Установка</target>
        </trans-unit>
        <trans-unit id="726495cac31fed46f3681097ea8adbc806081e82" translate="yes" xml:space="preserve">
          <source>Installing the latest release</source>
          <target state="translated">Установка последней версии</target>
        </trans-unit>
        <trans-unit id="8e78f6ced3cb3e7a0efd619bef2cccb4fa16b14d" translate="yes" xml:space="preserve">
          <source>It computes deltas for each input example-baseline pair, thus resulting to
&lt;code&gt;input.shape[0] * baseline.shape[0]&lt;/code&gt; delta values.</source>
          <target state="translated">Он вычисляет дельты для каждой входной пары пример-базовый уровень, в результате чего &lt;code&gt;input.shape[0] * baseline.shape[0]&lt;/code&gt; дельта-значения input.shape [0] * baseline.shape [0] .</target>
        </trans-unit>
        <trans-unit id="a8a7e2465fdc77cafbda6ce7b7d0e3ab7010ee86" translate="yes" xml:space="preserve">
          <source>It doesn't attribute the contribution scores to the input features
but shows the importance of each neuron in selected layer.</source>
          <target state="translated">Он не атрибутирует показатели вклада в входные характеристики,но показывает важность каждого нейрона в выделенном слое.</target>
        </trans-unit>
        <trans-unit id="45f74c2b886455a20211bc6087c7a981cba8b94d" translate="yes" xml:space="preserve">
          <source>Layer conductance shows the importance of neurons for a layer and given input.
It is an extension of path integrated gradients for hidden layers and holds the
completeness property as well.</source>
          <target state="translated">Поведение слоя показывает важность нейронов для слоя и заданного входа.Она является расширением интегральных градиентов траектории для скрытых слоев,а также обладает свойством полноты.</target>
        </trans-unit>
        <trans-unit id="0022de38b637868d1853d6d090cf915fe72c96d8" translate="yes" xml:space="preserve">
          <source>Let's apply some of those algorithms to a toy model we have created for
demonstration purposes.
For simplicity, we will use the following architecture, but users are welcome
to use any PyTorch model of their choice.</source>
          <target state="translated">Давайте применим некоторые из этих алгоритмов к игрушечной модели,которую мы создали для демонстрационных целей.Для простоты мы будем использовать следующую архитектуру,но пользователи могут использовать любую модель PyTorch по своему выбору.</target>
        </trans-unit>
        <trans-unit id="4369c251b91c938021df6f86e075d0f68a6879d5" translate="yes" xml:space="preserve">
          <source>Let's create an instance of our model and set it to eval mode.</source>
          <target state="translated">Создадим экземпляр нашей модели и переведем его в режим оценки.</target>
        </trans-unit>
        <trans-unit id="b2e5c40eefa02dca2a0399316902a8d9c9094103" translate="yes" xml:space="preserve">
          <source>Let's define our input and baseline tensors. Baselines are used in some
interpretability algorithms such as &lt;code&gt;IntegratedGradients, DeepLift, GradientShap, NeuronConductance, LayerConductance, InternalInfluence&lt;/code&gt; and
&lt;code&gt;NeuronIntegratedGradients&lt;/code&gt;.</source>
          <target state="translated">Давайте определим наши входные и базовые тензоры. Базовые показатели используются в некоторых алгоритмах интерпретируемости, таких как &lt;code&gt;IntegratedGradients, DeepLift, GradientShap, NeuronConductance, LayerConductance, InternalInfluence&lt;/code&gt; и &lt;code&gt;NeuronIntegratedGradients&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a2d21524039206f00133601c7ce2c40fbb2a88ae" translate="yes" xml:space="preserve">
          <source>Let's look into the internals of our network and understand which layers
and neurons are important for the predictions.</source>
          <target state="translated">Давайте разберемся во внутренностях нашей сети и поймем,какие слои и нейроны важны для предсказаний.</target>
        </trans-unit>
        <trans-unit id="3229609e15436ec51bcf00818a69a84dbc58a0c2" translate="yes" xml:space="preserve">
          <source>License</source>
          <target state="translated">Лицензия</target>
        </trans-unit>
        <trans-unit id="7151ecc0dc7a5120377ab85e7d7eac19fe0502d7" translate="yes" xml:space="preserve">
          <source>Model interpretability for PyTorch</source>
          <target state="translated">Модель интерпретируемости для PyTorch</target>
        </trans-unit>
        <trans-unit id="64a7acecc018b0b76e1070ab8d77465d6f66f86e" translate="yes" xml:space="preserve">
          <source>More details about the above mentioned &lt;a href=&quot;https://captum.ai/docs/algorithms&quot;&gt;algorithms&lt;/a&gt; and their pros and cons can be found on our &lt;a href=&quot;https://captum.ai/docs/algorithms_comparison_matrix&quot;&gt;web-site&lt;/a&gt;.</source>
          <target state="translated">Более подробную информацию о вышеупомянутых &lt;a href=&quot;https://captum.ai/docs/algorithms&quot;&gt;алгоритмах,&lt;/a&gt; а также об их плюсах и минусах можно найти на нашем &lt;a href=&quot;https://captum.ai/docs/algorithms_comparison_matrix&quot;&gt;сайте&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="c798498ab11132e260e2f04e6a25bc1b01a96272" translate="yes" xml:space="preserve">
          <source>More details on the list of supported algorithms and how to apply
Captum on different types of models can be found in our tutorials.</source>
          <target state="translated">Более подробную информацию о списке поддерживаемых алгоритмов и о том,как применять Captum к различным типам моделей,можно найти в наших учебниках.</target>
        </trans-unit>
        <trans-unit id="a809e022bfbd247fdef4e8f92c06639a09f2e709" translate="yes" xml:space="preserve">
          <source>Next we will use &lt;code&gt;IntegratedGradients&lt;/code&gt; algorithms to assign attribution
scores to each input feature with respect to the first target output.</source>
          <target state="translated">Далее мы будем использовать алгоритмы &lt;code&gt;IntegratedGradients&lt;/code&gt; для присвоения оценок атрибуции каждой входной функции по отношению к первому целевому выходу.</target>
        </trans-unit>
        <trans-unit id="e345eb5cbc3af8ba96268dc94160be1d607ed174" translate="yes" xml:space="preserve">
          <source>Next, we need to define simple input and baseline tensors.
Baselines belong to the input space and often carry no predictive signal.
Zero tensor can serve as a baseline for many tasks.
Some interpretability algorithms such as &lt;code&gt;Integrated Gradients&lt;/code&gt;, &lt;code&gt;Deeplift&lt;/code&gt; and &lt;code&gt;GradientShap&lt;/code&gt; are designed to attribute the change
between the input and baseline to a predictive class or a value that the neural
network outputs.</source>
          <target state="translated">Затем нам нужно определить простые входные и базовые тензоры. Базовые линии относятся к входному пространству и часто не несут прогностического сигнала. Нулевой тензор может служить базой для многих задач. Некоторые алгоритмы интерпретируемости, такие как &lt;code&gt;Integrated Gradients&lt;/code&gt; , &lt;code&gt;Deeplift&lt;/code&gt; и &lt;code&gt;GradientShap&lt;/code&gt; , предназначены для приписывания изменения между входом и базовой линией классу прогнозирования или значению, которое выводит нейронная сеть.</target>
        </trans-unit>
        <trans-unit id="e51de3cf2de9a13ef9bdd27134ba09503e04cca6" translate="yes" xml:space="preserve">
          <source>Now let's look into &lt;code&gt;DeepLiftShap&lt;/code&gt;. Similar to &lt;code&gt;GradientShap&lt;/code&gt;, &lt;code&gt;DeepLiftShap&lt;/code&gt; uses
baseline distribution. In the example below, we use the same baseline distribution
as for &lt;code&gt;GradientShap&lt;/code&gt;.</source>
          <target state="translated">Теперь давайте посмотрим на &lt;code&gt;DeepLiftShap&lt;/code&gt; . Подобно &lt;code&gt;GradientShap&lt;/code&gt; , &lt;code&gt;DeepLiftShap&lt;/code&gt; использует базовое распределение. В приведенном ниже примере мы используем то же базовое распределение, что и для &lt;code&gt;GradientShap&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4bed336194a9a5c86b6a734f03b3570d2aae1a68" translate="yes" xml:space="preserve">
          <source>Output</source>
          <target state="translated">Выход</target>
        </trans-unit>
        <trans-unit id="f3c8c95c5e534bcd2ea0034a0d83177efa6923f4" translate="yes" xml:space="preserve">
          <source>Output:</source>
          <target state="translated">Выход:</target>
        </trans-unit>
        <trans-unit id="7835db447bc76230b5b0d736b2d78c671d7100a1" translate="yes" xml:space="preserve">
          <source>Outputs</source>
          <target state="translated">Выходы</target>
        </trans-unit>
        <trans-unit id="b969baf269c9dc13dd2c54d156013b3e06ea3070" translate="yes" xml:space="preserve">
          <source>Positive attribution score means that the input in that particular position
positively contributed to the final prediction and negative means the opposite.
The magnitude of the attribution score signifies the strength of the contribution.
Zero attribution score means no contribution from that particular feature.</source>
          <target state="translated">Положительный результат оценки означает,что вклад в эту позицию положительно повлиял на прогноз,отрицательный-наоборот.Величина балла за атрибуцию указывает на прочность вклада.Нулевая оценка означает отсутствие вклада со стороны данной особенности.</target>
        </trans-unit>
        <trans-unit id="4c0d584e447dd2c5fa55e98d5d7921249c3911f6" translate="yes" xml:space="preserve">
          <source>PyTorch &amp;gt;= 1.2</source>
          <target state="translated">PyTorch&amp;gt; = 1.2</target>
        </trans-unit>
        <trans-unit id="c32b6c1ab053aa1b803595ba447bebbb8760c137" translate="yes" xml:space="preserve">
          <source>Python &amp;gt;= 3.6</source>
          <target state="translated">Python&amp;gt; = 3.6</target>
        </trans-unit>
        <trans-unit id="f00e768dce422689fe65ae881c3b96779cce5814" translate="yes" xml:space="preserve">
          <source>References of Algorithms</source>
          <target state="translated">Ссылки на алгоритмы</target>
        </trans-unit>
        <trans-unit id="54d440a5db0ab24f40fddf2b795f3716e25774cf" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;CONTRIBUTING.md&quot;&gt;CONTRIBUTING&lt;/a&gt; file for how to help out.</source>
          <target state="translated">См. Файл &lt;a href=&quot;CONTRIBUTING.md&quot;&gt;CONTRIBUTING,&lt;/a&gt; чтобы узнать, как помочь.</target>
        </trans-unit>
        <trans-unit id="9076ccad99e9fe123f5a242ef0d44a11422a0a37" translate="yes" xml:space="preserve">
          <source>Similar to GradientShap in order to compute example-based deltas we can average them per example:</source>
          <target state="translated">По аналогии с GradientShap для вычисления дельт на примере мы можем усреднить их в каждом примере:</target>
        </trans-unit>
        <trans-unit id="7c2892f73bdaf8f8b7b55fd520cd5b43f07bb285" translate="yes" xml:space="preserve">
          <source>Similar to integrated gradients, DeepLift returns a convergence delta score
per input example. The approximation error is then the absolute
value of the convergence deltas and can serve as a proxy of how accurate the
algorithm's approximation is.</source>
          <target state="translated">Аналогично интегрированным градиентам,DeepLift возвращает значение дельты сходимости для каждого входного примера.Ошибка аппроксимации тогда является абсолютным значением дельт сходимости и может служить прокси-сервером точности аппроксимации алгоритма.</target>
        </trans-unit>
        <trans-unit id="c98898a289abd12ad3663b6492c23d0af933dcbb" translate="yes" xml:space="preserve">
          <source>Similar to other attribution algorithms that return convergence delta, &lt;code&gt;LayerConductance&lt;/code&gt;
returns the deltas for each example. The approximation error is then the absolute
value of the convergence deltas and can serve as a proxy of how accurate integral
approximation for given inputs and baselines is.</source>
          <target state="translated">Подобно другим алгоритмам атрибуции, которые возвращают дельту сходимости, &lt;code&gt;LayerConductance&lt;/code&gt; возвращает дельты для каждого примера. Ошибка аппроксимации тогда является абсолютным значением дельт сходимости и может служить показателем того, насколько точным является интегральное приближение для данных входных данных и базовых линий.</target>
        </trans-unit>
        <trans-unit id="08641a32adb6073b217892c1d05043cccc5795f7" translate="yes" xml:space="preserve">
          <source>Similarly, we can apply &lt;code&gt;GradientShap&lt;/code&gt;, &lt;code&gt;DeepLift&lt;/code&gt; and other attribution algorithms to the model.</source>
          <target state="translated">Точно так же мы можем применить к модели &lt;code&gt;GradientShap&lt;/code&gt; , &lt;code&gt;DeepLift&lt;/code&gt; и другие алгоритмы атрибуции.</target>
        </trans-unit>
        <trans-unit id="5dfd03564d68a63c3940a933d7149be86e1b24fc" translate="yes" xml:space="preserve">
          <source>Talks and Papers</source>
          <target state="translated">Беседы и доклады</target>
        </trans-unit>
        <trans-unit id="5cc6318e21af4a9864dfb66b71e19b22e67f5171" translate="yes" xml:space="preserve">
          <source>Target Audience</source>
          <target state="translated">Целевая аудитория</target>
        </trans-unit>
        <trans-unit id="7c09a880f031a61c434b6eea261034d0953ae737" translate="yes" xml:space="preserve">
          <source>The algorithm outputs an attribution score for each input element and a
convergence delta. The lower the absolute value of the convergence delta the better
is the approximation. If we choose not to return delta,
we can simply not provide &lt;code&gt;return_convergence_delta&lt;/code&gt; input
argument. The absolute value of the returned deltas can be interpreted as an
approximation error for each input sample.
It can also serve as a proxy of how accurate the integral approximation for given
inputs and baselines is.
If the approximation error is large, we can try larger number of integral
approximation steps by setting &lt;code&gt;n_steps&lt;/code&gt; to a larger value. Not all algorithms
return approximation error. Those which do, though, compute it based on the
completeness property of the algorithms.</source>
          <target state="translated">Алгоритм выводит оценку атрибуции для каждого входного элемента и дельту сходимости. Чем меньше абсолютное значение дельты сходимости, тем лучше приближение. Если мы &lt;code&gt;return_convergence_delta&lt;/code&gt; не возвращать дельту, мы просто не сможем предоставить входной аргумент return_convergence_delta . Абсолютное значение возвращенных дельт можно интерпретировать как ошибку аппроксимации для каждой входной выборки. Он также может служить индикатором того, насколько точным является интегральное приближение для заданных входных данных и базовых показателей. Если ошибка аппроксимации велика, мы можем попробовать большее количество шагов интегральной аппроксимации, установив &lt;code&gt;n_steps&lt;/code&gt; на большее значение. Не все алгоритмы возвращают ошибку аппроксимации. Однако те, которые это делают, вычисляют его на основе свойства полноты алгоритмов.</target>
        </trans-unit>
        <trans-unit id="9bc5b2cbf539dd2b556b4ee16093e2dd98e5e53f" translate="yes" xml:space="preserve">
          <source>The latest release of Captum is easily installed either via
&lt;a href=&quot;https://www.anaconda.com/distribution/#download-section&quot;&gt;Anaconda&lt;/a&gt; (recommended):</source>
          <target state="translated">Последняя версия Captum легко устанавливается через &lt;a href=&quot;https://www.anaconda.com/distribution/#download-section&quot;&gt;Anaconda&lt;/a&gt; (рекомендуется):</target>
        </trans-unit>
        <trans-unit id="14456e5d622ffef206d84cb2547dd1292a3e6a4b" translate="yes" xml:space="preserve">
          <source>The number of elements in the &lt;code&gt;delta&lt;/code&gt; tensor is equal to: &lt;code&gt;n_samples * input.shape[0]&lt;/code&gt;
In order to get a example-based delta, we can, for example, average them:</source>
          <target state="translated">Количество элементов в &lt;code&gt;delta&lt;/code&gt; тензоре равно: &lt;code&gt;n_samples * input.shape[0]&lt;/code&gt; Чтобы получить дельту на основе примера, мы можем, например, усреднить их:</target>
        </trans-unit>
        <trans-unit id="d97f36b304cf7bf6d19d6ba216bf83da80bc9ca1" translate="yes" xml:space="preserve">
          <source>The primary audiences for Captum are model developers who are looking to improve their models and understand which features are important and interpretability researchers focused on identifying algorithms that can better interpret many types of models.</source>
          <target state="translated">Основной аудиторией Captum являются разработчики моделей,которые хотят улучшить свои модели и понять,какие особенности являются важными,а также исследователи интерпретируемости,сосредоточенные на определении алгоритмов,которые могут лучше интерпретировать многие типы моделей.</target>
        </trans-unit>
        <trans-unit id="09bb5c690208bfa966db7460586a698914a360bd" translate="yes" xml:space="preserve">
          <source>The slides of our presentation from NeurIPS 2019 can be found &lt;a href=&quot;docs/presentations/Captum_NeurIPS_2019_final.key&quot;&gt;here&lt;/a&gt;</source>
          <target state="translated">Слайды нашей презентации с NeurIPS 2019 можно найти &lt;a href=&quot;docs/presentations/Captum_NeurIPS_2019_final.key&quot;&gt;здесь&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5d0367e1f5fde1ede3db753f108801cb14982eac" translate="yes" xml:space="preserve">
          <source>To analyze a sample model on CIFAR10 via Captum Insights run</source>
          <target state="translated">Для анализа модели образца на CIFAR10 с помощью Captum Insights запустите программу</target>
        </trans-unit>
        <trans-unit id="1b78a188c82782ae0e64234fb5851ce273466f93" translate="yes" xml:space="preserve">
          <source>To build Insights you will need &lt;a href=&quot;https://nodejs.org/en/&quot;&gt;Node&lt;/a&gt; &amp;gt;= 8.x
and &lt;a href=&quot;https://yarnpkg.com/en/&quot;&gt;Yarn&lt;/a&gt; &amp;gt;= 1.5.</source>
          <target state="translated">Для создания Insights вам понадобятся &lt;a href=&quot;https://nodejs.org/en/&quot;&gt;Node&lt;/a&gt; &amp;gt; = 8.x и &lt;a href=&quot;https://yarnpkg.com/en/&quot;&gt;Yarn&lt;/a&gt; &amp;gt; = 1.5.</target>
        </trans-unit>
        <trans-unit id="5468c50938c4ec01b3019827d9753bc27eccd242" translate="yes" xml:space="preserve">
          <source>To build and launch from a checkout in a conda environment run</source>
          <target state="translated">Чтобы собрать и запустить с проверки в среде conda.</target>
        </trans-unit>
        <trans-unit id="47d309089702b5779d1249906c184aca6a17334f" translate="yes" xml:space="preserve">
          <source>To build the widget from a checkout in a conda environment run</source>
          <target state="translated">Чтобы построить виджет из проверки в среде conda,выполните следующие действия.</target>
        </trans-unit>
        <trans-unit id="039a5244d60906d43c5c15a0a20b10397b0bc5f9" translate="yes" xml:space="preserve">
          <source>To customize the installation, you can also run the following variants of the
above:</source>
          <target state="translated">Для настройки установки можно также запустить следующие варианты:</target>
        </trans-unit>
        <trans-unit id="a39ccefe51118817f1b35b636167cdb3bd9357d8" translate="yes" xml:space="preserve">
          <source>To execute unit tests from a manual install, run:</source>
          <target state="translated">Для выполнения модульных тестов с ручной установкой,запустите:</target>
        </trans-unit>
        <trans-unit id="4ac1cec1a4406720bdada7e35a448ad0dfd20d82" translate="yes" xml:space="preserve">
          <source>To make computations deterministic, let's fix random seeds.</source>
          <target state="translated">Чтобы вычисления были детерминированными,давайте исправим случайные семена.</target>
        </trans-unit>
        <trans-unit id="eba414e2b73da649f8d414e82f52b11624820726" translate="yes" xml:space="preserve">
          <source>We will apply model interpretability algorithms on the network
mentioned above in order to understand the importance of individual
neurons/layers and the parts of the input that play an important role in the
final prediction.</source>
          <target state="translated">Мы применим алгоритмы интерпретации моделей в сети,упомянутой выше,чтобы понять важность отдельных нейронов/слоёв и тех частей входа,которые играют важную роль в окончательном предсказании.</target>
        </trans-unit>
        <trans-unit id="168626e3b7f39ed35712d4be0f4311e69049dd72" translate="yes" xml:space="preserve">
          <source>We will start with the &lt;code&gt;NeuronConductance&lt;/code&gt;. &lt;code&gt;NeuronConductance&lt;/code&gt; helps us to identify
input features that are important for a particular neuron in a given
layer. It decomposes the computation of integrated gradients via the chain rule by
defining the importance of a neuron as path integral of the derivative of the output
with respect to the neuron times the derivatives of the neuron with respect to the
inputs of the model.</source>
          <target state="translated">Начнем с &lt;code&gt;NeuronConductance&lt;/code&gt; . &lt;code&gt;NeuronConductance&lt;/code&gt; помогает нам идентифицировать входные функции, которые важны для конкретного нейрона в данном слое. Он разлагает вычисление интегрированных градиентов с помощью цепного правила, определяя важность нейрона как интеграл по путям производной выходного сигнала по нейрону, умноженной на производные нейрона по входам модели.</target>
        </trans-unit>
        <trans-unit id="3aee6cb4b987c6eb98bae057c8033da66b7ba223" translate="yes" xml:space="preserve">
          <source>With the increase in model complexity and the resulting lack of transparency, model interpretability methods have become increasingly important. Model understanding is both an active area of research as well as an area of focus for practical applications across industries using machine learning. Captum provides state-of-the-art algorithms, including Integrated Gradients, to provide researchers and developers with an easy way to understand which features are contributing to a model&amp;rsquo;s output.</source>
          <target state="translated">С увеличением сложности модели и, как следствие, отсутствием прозрачности, методы интерпретируемости модели становятся все более важными. Понимание моделей является одновременно активной областью исследований, а также областью практического применения в различных отраслях промышленности с использованием машинного обучения. Captum предоставляет современные алгоритмы, в том числе интегрированные градиенты, чтобы дать исследователям и разработчикам простой способ понять, какие функции вносят вклад в результат модели.</target>
        </trans-unit>
        <trans-unit id="ffc76686099e22242eb4269a3745fa2f6e1ef1d4" translate="yes" xml:space="preserve">
          <source>and navigate to the URL specified in the output.</source>
          <target state="translated">и перейдите к URL,указанному в выводе.</target>
        </trans-unit>
        <trans-unit id="2eeef8b3dfe3c6e07456229818d93864ce2c6fe7" translate="yes" xml:space="preserve">
          <source>in order to get per example average delta.</source>
          <target state="translated">чтобы получить на примере среднюю дельту.</target>
        </trans-unit>
        <trans-unit id="d6773e7adcc2adec52348c71e0551f68a9f85abd" translate="yes" xml:space="preserve">
          <source>or via &lt;code&gt;pip&lt;/code&gt;:</source>
          <target state="translated">или через &lt;code&gt;pip&lt;/code&gt; :</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
