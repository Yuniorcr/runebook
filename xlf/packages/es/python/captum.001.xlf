<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="es" datatype="htmlbody" original="https://pypi.org/project/captum/">
    <body>
      <group id="captum">
        <trans-unit id="7e224d6675fc514ea7defb9516638683fceb2bcc" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Deconvolution&lt;/code&gt;, &lt;code&gt;Neuron Deconvolution&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1311.2901.pdf&quot;&gt;Visualizing and Understanding Convolutional Networks, Matthew D Zeiler et al. 2014&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Deconvolution&lt;/code&gt; , Deconvoluci&amp;oacute;n de &lt;code&gt;Neuron Deconvolution&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/pdf/1311.2901.pdf&quot;&gt;Visualizaci&amp;oacute;n y comprensi&amp;oacute;n de redes convolucionales, Matthew D Zeiler et al. 2014&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f77c45466355b115b010aa83e3ec5115e53cc011" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;DeepLift&lt;/code&gt; assigns similar attribution scores as &lt;code&gt;IntegratedGradients&lt;/code&gt; to inputs,
however it has lower execution time. Another important thing to remember about
DeepLift is that it currently doesn't support all non-linear activation types.
For more details on limitations of the current implementation, please see the
&lt;a href=&quot;https://arxiv.org/abs/1704.02685&quot;&gt;DeepLift paper&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;DeepLift&lt;/code&gt; asigna puntajes de atribuci&amp;oacute;n similares a los &lt;code&gt;IntegratedGradients&lt;/code&gt; a las entradas, sin embargo, tiene un tiempo de ejecuci&amp;oacute;n m&amp;aacute;s bajo. Otra cosa importante para recordar acerca de DeepLift es que actualmente no es compatible con todos los tipos de activaci&amp;oacute;n no lineal. Para obtener m&amp;aacute;s detalles sobre las limitaciones de la implementaci&amp;oacute;n actual, consulte el &lt;a href=&quot;https://arxiv.org/abs/1704.02685&quot;&gt;documento de DeepLift&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="35d8eea45bfc985cc4e9ed2b9f13dcc77a172786" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;DeepLift&lt;/code&gt;, &lt;code&gt;NeuronDeepLift&lt;/code&gt;, &lt;code&gt;LayerDeepLift&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1704.02685.pdf&quot;&gt;Learning Important Features Through Propagating Activation Differences, Avanti Shrikumar et al. 2017&lt;/a&gt; and &lt;a href=&quot;https://openreview.net/pdf?id=Sy21R9JAW&quot;&gt;Towards better understanding of gradient-based attribution methods for deep neural networks, Marco Ancona et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;DeepLift&lt;/code&gt; , &lt;code&gt;NeuronDeepLift&lt;/code&gt; , &lt;code&gt;LayerDeepLift&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/pdf/1704.02685.pdf&quot;&gt;aprendizaje de funciones importantes mediante la propagaci&amp;oacute;n de diferencias de activaci&amp;oacute;n, Avanti Shrikumar et al. 2017&lt;/a&gt; y &lt;a href=&quot;https://openreview.net/pdf?id=Sy21R9JAW&quot;&gt;Hacia una mejor comprensi&amp;oacute;n de los m&amp;eacute;todos de atribuci&amp;oacute;n basados ​​en gradientes para redes neuronales profundas, Marco Ancona et al. 2018&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0935b98602a2196eb3ce841148929580db331f26" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;DeepLiftShap&lt;/code&gt; uses &lt;code&gt;DeepLift&lt;/code&gt; to compute attribution score for each
input-baseline pair and averages it for each input across all baselines.</source>
          <target state="translated">&lt;code&gt;DeepLiftShap&lt;/code&gt; utiliza &lt;code&gt;DeepLift&lt;/code&gt; para calcular la puntuaci&amp;oacute;n de atribuci&amp;oacute;n para cada par de entrada-l&amp;iacute;nea de base y promedia para cada entrada en todas las l&amp;iacute;neas de base.</target>
        </trans-unit>
        <trans-unit id="70f4204e74fbab884413f100ee93ebc43bf69602" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Feature Permutation&lt;/code&gt;: &lt;a href=&quot;https://christophm.github.io/interpretable-ml-book/feature-importance.html&quot;&gt;Permutation Feature Importance&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Feature Permutation&lt;/code&gt; : &lt;a href=&quot;https://christophm.github.io/interpretable-ml-book/feature-importance.html&quot;&gt;Importancia de las caracter&amp;iacute;sticas de permutaci&amp;oacute;n&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="dfd45f4166b5d1094537f54fcf044b34d5f360af" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;GradCAM&lt;/code&gt;, &lt;code&gt;Guided GradCAM&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1610.02391.pdf&quot;&gt;Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization, Ramprasaath R. Selvaraju et al. 2017&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;GradCAM&lt;/code&gt; , GradCAM &lt;code&gt;Guided GradCAM&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/abs/1610.02391.pdf&quot;&gt;Grad-CAM: Explicaciones visuales de las redes profundas a trav&amp;eacute;s de la localizaci&amp;oacute;n basada en gradientes, Ramprasaath R. Selvaraju et al. 2017&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9c73c2db449b0b144f4acb50ee0a1570caed5366" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;GradientShap&lt;/code&gt; first chooses a random baseline from baselines' distribution, then
adds gaussian noise with std=0.09 to each input example &lt;code&gt;n_samples&lt;/code&gt; times.
Afterwards, it chooses a random point between each example-baseline pair and
computes the gradients with respect to target class (in this case target=0). Resulting
attribution is the mean of gradients * (inputs - baselines)</source>
          <target state="translated">&lt;code&gt;GradientShap&lt;/code&gt; primero elige una l&amp;iacute;nea de base aleatoria de la distribuci&amp;oacute;n de l&amp;iacute;neas de base, luego agrega ruido gaussiano con std = 0.09 a cada ejemplo de entrada &lt;code&gt;n_samples&lt;/code&gt; veces. Luego, elige un punto aleatorio entre cada par ejemplo-l&amp;iacute;nea de base y calcula los gradientes con respecto a la clase de destino (en este caso, target = 0). La atribuci&amp;oacute;n resultante es la media de los gradientes * (entradas - l&amp;iacute;neas de base)</target>
        </trans-unit>
        <trans-unit id="745f47441809340b71cc76401a089bf5ad757fd9" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;GradientShap&lt;/code&gt;, &lt;code&gt;NeuronGradientShap&lt;/code&gt;, &lt;code&gt;LayerGradientShap&lt;/code&gt;, &lt;code&gt;DeepLiftShap&lt;/code&gt;, &lt;code&gt;NeuronDeepLiftShap&lt;/code&gt;, &lt;code&gt;LayerDeepLiftShap&lt;/code&gt;: &lt;a href=&quot;http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions&quot;&gt;A Unified Approach to Interpreting Model Predictions, Scott M. Lundberg et al. 2017&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;GradientShap&lt;/code&gt; , &lt;code&gt;NeuronGradientShap&lt;/code&gt; , &lt;code&gt;LayerGradientShap&lt;/code&gt; , &lt;code&gt;DeepLiftShap&lt;/code&gt; , &lt;code&gt;NeuronDeepLiftShap&lt;/code&gt; , &lt;code&gt;LayerDeepLiftShap&lt;/code&gt; : &lt;a href=&quot;http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions&quot;&gt;Un enfoque unificado para interpretar predicciones de modelos, Scott M. Lundberg et al. 2017&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="602dfc33d8aba3857725b949b893d500e50a678d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Guided Backpropagation&lt;/code&gt;, &lt;code&gt;Neuron Guided Backpropagation&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1412.6806.pdf&quot;&gt;Striving for Simplicity: The All Convolutional Net, Jost Tobias Springenberg et al. 2015&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Guided Backpropagation&lt;/code&gt; , retropropagaci&amp;oacute;n &lt;code&gt;Neuron Guided Backpropagation&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/pdf/1412.6806.pdf&quot;&gt;lucha por la simplicidad: la red convolucional total, Jost Tobias Springenberg et al. 2015&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="32d5dd2bb7640e2b606a6084f2cafa2a031b478b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;InputXGradient&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1611.07270&quot;&gt;Investigating the influence of noise and distractors on the interpretation of neural networks, Pieter-Jan Kindermans et al. 2016&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;InputXGradient&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/abs/1611.07270&quot;&gt;Investigando la influencia del ruido y los distractores en la interpretaci&amp;oacute;n de las redes neuronales, Pieter-Jan Kindermans et al. 2016&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b69ede686e5d4e904dbf0247c2f663ff896f0a0c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;IntegratedGradients&lt;/code&gt;, &lt;code&gt;LayerIntegratedGradients&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1703.01365&quot;&gt;Axiomatic Attribution for Deep Networks, Mukund Sundararajan et al. 2017&lt;/a&gt; and &lt;a href=&quot;https://arxiv.org/abs/1805.05492&quot;&gt;Did the Model Understand the Question?, Pramod K. Mudrakarta, et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;IntegratedGradients&lt;/code&gt; , &lt;code&gt;LayerIntegratedGradients&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/abs/1703.01365&quot;&gt;Atribuci&amp;oacute;n axiom&amp;aacute;tica para redes profundas, Mukund Sundararajan et al. 2017&lt;/a&gt; y &lt;a href=&quot;https://arxiv.org/abs/1805.05492&quot;&gt;&amp;iquest;el modelo entendi&amp;oacute; la pregunta ?, Pramod K. Mudrakarta, et al. 2018&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1ce041e0904e2eb6fe9e166ae16f4a94c041216f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;InternalInfluence&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1802.03788.pdf&quot;&gt;Influence-Directed Explanations for Deep Convolutional Networks, Klas Leino et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;InternalInfluence&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/pdf/1802.03788.pdf&quot;&gt;Explicaciones dirigidas por la influencia para redes convolucionales profundas, Klas Leino et al. 2018&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6464d80d482910b859e98e94be43a85d78c92fff" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;LayerConductance&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1807.09946.pdf&quot;&gt;Computationally Efficient Measures of Internal Neuron Importance, Avanti Shrikumar et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;LayerConductance&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/pdf/1807.09946.pdf&quot;&gt;Medidas computacionalmente eficientes de la importancia de la neurona interna, Avanti Shrikumar et al. 2018&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a390e01ea3142478285f0168a9d0220de3b869e1" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;NeuronConductance&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1805.12233&quot;&gt;How Important is a neuron?, Kedar Dhamdhere et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;NeuronConductance&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/abs/1805.12233&quot;&gt;&amp;iquest;Qu&amp;eacute; importancia tiene una neurona ?, Kedar Dhamdhere et al. 2018&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7fa53a48f5e924963274d272e5ae392af89f2c41" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;NeuronIntegratedGradients&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1807.09946.pdf&quot;&gt;Computationally Efficient Measures of Internal Neuron Importance, Avanti Shrikumar et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;NeuronIntegratedGradients&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/pdf/1807.09946.pdf&quot;&gt;Medidas computacionalmente eficientes de la importancia de la neurona interna, Avanti Shrikumar et al. 2018&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3406337d51997da5374b792bb810c3069f71f625" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;NoiseTunnel&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1810.03292&quot;&gt;Sanity Checks for Saliency Maps, Julius Adebayo et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;NoiseTunnel&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/abs/1810.03292&quot;&gt;Sanity Checks for Saliency Maps, Julius Adebayo et al. 2018&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="180de40fda30abd90e30c91da063de517cd65e10" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Occlusion&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1311.2901&quot;&gt;Visualizing and Understanding Convolutional Networks&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Occlusion&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/abs/1311.2901&quot;&gt;visualizaci&amp;oacute;n y comprensi&amp;oacute;n de las redes convolucionales&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="ef3e53fd11ec0ec42f34212a68a5a8f640a980a4" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Saliency&lt;/code&gt;, &lt;code&gt;NeuronGradient&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1312.6034.pdf&quot;&gt;Deep Inside Convolutional Networks: Visualising
Image Classification Models and Saliency Maps, K. Simonyan, et. al. 2014&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Saliency&lt;/code&gt; , &lt;code&gt;NeuronGradient&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/pdf/1312.6034.pdf&quot;&gt;Redes convolucionales profundas: Visualizaci&amp;oacute;n de modelos de clasificaci&amp;oacute;n de im&amp;aacute;genes y mapas de relevancia, K. Simonyan, et. Alabama. 2014&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d72716650eca9202bde62762d848353fd9f89e55" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Shapely Value Sampling&lt;/code&gt;: &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0305054808000804&quot;&gt;Polynomial calculation of the Shapley value based on sampling&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Shapely Value Sampling&lt;/code&gt; : &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0305054808000804&quot;&gt;c&amp;aacute;lculo polinomial del valor de Shapley basado en el muestreo&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2f313a5b98f914e2d22e3666af676c317da1a76c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Shapely Value&lt;/code&gt;: &lt;a href=&quot;https://apps.dtic.mil/dtic/tr/fulltext/u2/604084.pdf&quot;&gt;A value for n-person games. Contributions to the Theory of Games 2.28 (1953): 307-317&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Shapely Value&lt;/code&gt; : &lt;a href=&quot;https://apps.dtic.mil/dtic/tr/fulltext/u2/604084.pdf&quot;&gt;un valor para juegos de n personas. Contribuciones a la teor&amp;iacute;a de los juegos 2.28 (1953): 307-317&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="cc62bf28a6aaadab7c58506486d1282344c4f152" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;SmoothGrad&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1706.03825&quot;&gt;SmoothGrad: removing noise by adding noise, Daniel Smilkov et al. 2017&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;SmoothGrad&lt;/code&gt; : &lt;a href=&quot;https://arxiv.org/abs/1706.03825&quot;&gt;SmoothGrad: eliminar ruido agregando ruido, Daniel Smilkov et al. 2017&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="97d9a83b33d1a1e1468782cbf91b17ba820547f9" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;pip install -e .[dev]&lt;/code&gt;: Also installs all tools necessary for development
(testing, linting, docs building; see &lt;a href=&quot;#contributing&quot;&gt;Contributing&lt;/a&gt; below).</source>
          <target state="translated">&lt;code&gt;pip install -e .[dev]&lt;/code&gt; : tambi&amp;eacute;n instala todas las herramientas necesarias para el desarrollo (pruebas, linting, compilaci&amp;oacute;n de documentos; consulte &lt;a href=&quot;#contributing&quot;&gt;Contribuci&amp;oacute;n a&lt;/a&gt; continuaci&amp;oacute;n).</target>
        </trans-unit>
        <trans-unit id="5d7c7835d367a7e4679627572238c42726e0601e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;pip install -e .[insights]&lt;/code&gt;: Also installs all packages necessary for running Captum Insights.</source>
          <target state="translated">&lt;code&gt;pip install -e .[insights]&lt;/code&gt; : tambi&amp;eacute;n instala todos los paquetes necesarios para ejecutar Captum Insights.</target>
        </trans-unit>
        <trans-unit id="d5bb8d5b6fa5ab568327e9ea794621e7ee38d45f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;pip install -e .[tutorials]&lt;/code&gt;: Also installs all packages necessary for running the tutorial notebooks.</source>
          <target state="translated">&lt;code&gt;pip install -e .[tutorials]&lt;/code&gt; : tambi&amp;eacute;n instala todos los paquetes necesarios para ejecutar los cuadernos de tutoriales.</target>
        </trans-unit>
        <trans-unit id="c641fcc1b80e58fb730b1652c8b6c7fc9b227fd8" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;Captum is currently in beta and under active development!&lt;/em&gt;</source>
          <target state="translated">&lt;em&gt;Captum se encuentra actualmente en fase beta y en desarrollo activo.&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="6897acde3a3c220a635980f413f5941e5fc0a6b4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Installation Requirements&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;requerimientos de instalaci&amp;oacute;n&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="2208733c3a7ee98009723d2713bcd61e00a43c9c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Manual / Dev install&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;Instalaci&amp;oacute;n manual / para desarrolladores&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="c3f76124c7fa391369fe5c7fb44c51cf9d1ed726" translate="yes" xml:space="preserve">
          <source>About Captum</source>
          <target state="translated">Acerca de Captum</target>
        </trans-unit>
        <trans-unit id="d8c0847ea163dcd16d6f2a889df7dce1e95c7176" translate="yes" xml:space="preserve">
          <source>Below is an example of how we can apply &lt;code&gt;DeepLift&lt;/code&gt; and &lt;code&gt;DeepLiftShap&lt;/code&gt; on the
&lt;code&gt;ToyModel&lt;/code&gt; described above. Current implementation of DeepLift supports only
&lt;code&gt;Rescale&lt;/code&gt; rule.
For more details on alternative implementations, please see the &lt;a href=&quot;https://arxiv.org/abs/1704.02685&quot;&gt;DeepLift paper&lt;/a&gt;.</source>
          <target state="translated">A continuaci&amp;oacute;n se muestra un ejemplo de c&amp;oacute;mo podemos aplicar &lt;code&gt;DeepLift&lt;/code&gt; y &lt;code&gt;DeepLiftShap&lt;/code&gt; en el &lt;code&gt;ToyModel&lt;/code&gt; descrito anteriormente. La implementaci&amp;oacute;n actual de DeepLift solo &lt;code&gt;Rescale&lt;/code&gt; regla Rescale . Para obtener m&amp;aacute;s detalles sobre implementaciones alternativas, consulte el &lt;a href=&quot;https://arxiv.org/abs/1704.02685&quot;&gt;documento de DeepLift&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="021481ec74cf7f851fd8bb8de29f48519b026a55" translate="yes" xml:space="preserve">
          <source>Captum Insights</source>
          <target state="translated">Perspectivas del Capitolio</target>
        </trans-unit>
        <trans-unit id="b5e6347c0220e027a895cf1796661a4eca041832" translate="yes" xml:space="preserve">
          <source>Captum Insights Jupyter Widget</source>
          <target state="translated">Captum Insights Jupyter Widget</target>
        </trans-unit>
        <trans-unit id="50ea9b39e0ca2b1e147f71e19c8284e932f29b95" translate="yes" xml:space="preserve">
          <source>Captum Insights also has a Jupyter widget providing the same user interface as the web app.
To install and enable the widget, run</source>
          <target state="translated">Captum Insights también tiene un widget Jupyter que proporciona la misma interfaz de usuario que la aplicación web.Para instalar y habilitar el widget,ejecute</target>
        </trans-unit>
        <trans-unit id="2284f9438ef0b1f48a107c6a47037d5562ef7a07" translate="yes" xml:space="preserve">
          <source>Captum can also be used by application engineers who are using trained models in production. Captum provides easier troubleshooting through improved model interpretability, and the potential for delivering better explanations to end users on why they&amp;rsquo;re seeing a specific piece of content, such as a movie recommendation.</source>
          <target state="translated">Captum tambi&amp;eacute;n puede ser utilizado por ingenieros de aplicaciones que utilizan modelos entrenados en producci&amp;oacute;n. Captum proporciona una soluci&amp;oacute;n de problemas m&amp;aacute;s f&amp;aacute;cil a trav&amp;eacute;s de una mejor interpretaci&amp;oacute;n del modelo y la posibilidad de ofrecer mejores explicaciones a los usuarios finales sobre por qu&amp;eacute; ven un contenido espec&amp;iacute;fico, como una recomendaci&amp;oacute;n de pel&amp;iacute;cula.</target>
        </trans-unit>
        <trans-unit id="e072252aa5db22cac92d10e2402e5669eae223d4" translate="yes" xml:space="preserve">
          <source>Captum helps ML researchers more easily implement interpretability algorithms that can interact with PyTorch models. Captum also allows researchers to quickly benchmark their work against other existing algorithms available in the library.</source>
          <target state="translated">El Captum ayuda a los investigadores de ML a implementar más fácilmente los algoritmos de interpretación que pueden interactuar con los modelos de PyTorch.Captum también permite a los investigadores comparar rápidamente su trabajo con otros algoritmos existentes disponibles en la biblioteca.</target>
        </trans-unit>
        <trans-unit id="d26bdb66327c68c373a8e184aae92f50105b84ad" translate="yes" xml:space="preserve">
          <source>Captum helps you interpret and understand predictions of PyTorch models by
exploring features that contribute to a prediction the model makes.
It also helps understand which neurons and layers are important for
model predictions.</source>
          <target state="translated">Captum le ayuda a interpretar y comprender las predicciones de los modelos de PyTorch explorando las características que contribuyen a una predicción que el modelo hace.También ayuda a entender qué neuronas y capas son importantes para las predicciones del modelo.</target>
        </trans-unit>
        <trans-unit id="48db440dde81207b626929193aa5ff14516a272f" translate="yes" xml:space="preserve">
          <source>Captum is BSD licensed, as found in the &lt;a href=&quot;LICENSE&quot;&gt;LICENSE&lt;/a&gt; file.</source>
          <target state="translated">Captum tiene licencia BSD, como se encuentra en el archivo &lt;a href=&quot;LICENSE&quot;&gt;LICENSE&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2b556e02df9343beb45e9c79545ddba2410d2664" translate="yes" xml:space="preserve">
          <source>Captum is a model interpretability and understanding library for PyTorch.
Captum means comprehension in latin and contains general purpose implementations
of integrated gradients, saliency maps, smoothgrad, vargrad and others for
PyTorch models. It has quick integration for models built with domain-specific
libraries such as torchvision, torchtext, and others.</source>
          <target state="translated">Captum es una biblioteca de interpretación y comprensión de modelos para PyTorch.Captum significa comprensión en latín y contiene implementaciones de propósito general de gradientes integrados,mapas de saliencia,smoothgrad,vargrad y otros para los modelos de PyTorch.Tiene una rápida integración para los modelos construidos con bibliotecas específicas del dominio como torchvision,torchtext y otras.</target>
        </trans-unit>
        <trans-unit id="712c9c0dc955ee835f95d4a0c2e34f430fb91038" translate="yes" xml:space="preserve">
          <source>Captum provides a web interface called Insights for easy visualization and
access to a number of our interpretability algorithms.</source>
          <target state="translated">Captum proporciona una interfaz web llamada Insights para una fácil visualización y acceso a varios de nuestros algoritmos de interpretación.</target>
        </trans-unit>
        <trans-unit id="2d82a4b27a4b305690d5ac612046a955778a9fa5" translate="yes" xml:space="preserve">
          <source>Contributing</source>
          <target state="translated">Contribuyendo</target>
        </trans-unit>
        <trans-unit id="39703b21af9911d0f81c306612570543015fb4da" translate="yes" xml:space="preserve">
          <source>Currently, the library uses gradient-based interpretability algorithms
and attributes contributions to each input of the model with respect to
different neurons and layers, both intermediate and final.</source>
          <target state="translated">Actualmente,la biblioteca utiliza algoritmos de interpretación basados en gradientes y atribuye contribuciones a cada entrada del modelo con respecto a diferentes neuronas y capas,tanto intermedias como finales.</target>
        </trans-unit>
        <trans-unit id="90ab72c08753cb3eced44073f94e601929bbf4a1" translate="yes" xml:space="preserve">
          <source>Deltas are computed for each &lt;code&gt;n_samples * input.shape[0]&lt;/code&gt; example. The user can,
for instance, average them:</source>
          <target state="translated">Los deltas se calculan para cada &lt;code&gt;n_samples * input.shape[0]&lt;/code&gt; . El usuario puede, por ejemplo, promediarlos:</target>
        </trans-unit>
        <trans-unit id="c6b820410c0912f7db59b8a701baa4c5631073ed" translate="yes" xml:space="preserve">
          <source>For model developers, Captum can be used to improve and troubleshoot models by facilitating the identification of different features that contribute to a model&amp;rsquo;s output in order to design better models and troubleshoot unexpected model outputs.</source>
          <target state="translated">Para los desarrolladores de modelos, Captum se puede utilizar para mejorar y solucionar problemas de modelos facilitando la identificaci&amp;oacute;n de diferentes caracter&amp;iacute;sticas que contribuyen a la salida de un modelo para dise&amp;ntilde;ar mejores modelos y solucionar problemas de salidas inesperadas del modelo.</target>
        </trans-unit>
        <trans-unit id="010b85ad56b34c34c7c2a3b2436c740e30428ed5" translate="yes" xml:space="preserve">
          <source>Getting Started</source>
          <target state="translated">Empezando</target>
        </trans-unit>
        <trans-unit id="523b5dd24d78e1688f499261e03d11aabe65c0e9" translate="yes" xml:space="preserve">
          <source>Here is an example how we can use &lt;code&gt;NoiseTunnel&lt;/code&gt; with &lt;code&gt;IntegratedGradients&lt;/code&gt;.</source>
          <target state="translated">Aqu&amp;iacute; hay un ejemplo de c&amp;oacute;mo podemos usar &lt;code&gt;NoiseTunnel&lt;/code&gt; con &lt;code&gt;IntegratedGradients&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2951f06ff53b46d9157f54d1ddb461c159a670d0" translate="yes" xml:space="preserve">
          <source>If you'd like to try our bleeding edge features (and don't mind potentially
running into the occasional bug here or there), you can install the latest
master directly from GitHub. For a basic install, run:</source>
          <target state="translated">Si quieres probar nuestras características más avanzadas (y no te importa que te encuentres con algún que otro bicho de vez en cuando),puedes instalar el último master directamente desde GitHub.Para una instalación básica,ejecuta:</target>
        </trans-unit>
        <trans-unit id="748139302b5f33a6af11cc4d8e2c307feed6a61f" translate="yes" xml:space="preserve">
          <source>In order to smooth and improve the quality of the attributions we can run
&lt;code&gt;IntegratedGradients&lt;/code&gt; and other attribution methods through a &lt;code&gt;NoiseTunnel&lt;/code&gt;.
&lt;code&gt;NoiseTunnel&lt;/code&gt; allows us to use &lt;code&gt;SmoothGrad&lt;/code&gt;, &lt;code&gt;SmoothGrad_Sq&lt;/code&gt; and &lt;code&gt;VarGrad&lt;/code&gt; techniques
to smoothen the attributions by aggregating them for multiple noisy
samples that were generated by adding gaussian noise.</source>
          <target state="translated">Para suavizar y mejorar la calidad de las atribuciones, podemos ejecutar &lt;code&gt;IntegratedGradients&lt;/code&gt; y otros m&amp;eacute;todos de atribuci&amp;oacute;n a trav&amp;eacute;s de &lt;code&gt;NoiseTunnel&lt;/code&gt; . &lt;code&gt;NoiseTunnel&lt;/code&gt; nos permite utilizar las &lt;code&gt;SmoothGrad&lt;/code&gt; , &lt;code&gt;SmoothGrad_Sq&lt;/code&gt; y &lt;code&gt;VarGrad&lt;/code&gt; para suavizar las atribuciones agreg&amp;aacute;ndolas para m&amp;uacute;ltiples muestras ruidosas que se generaron agregando ruido gaussiano.</target>
        </trans-unit>
        <trans-unit id="37e62d8605abf42b9cf777a51788c55a03639d78" translate="yes" xml:space="preserve">
          <source>In this case, we choose to analyze the first neuron in the linear layer.</source>
          <target state="translated">En este caso,elegimos analizar la primera neurona de la capa lineal.</target>
        </trans-unit>
        <trans-unit id="c81b79df3c6448eae7c4f80428b54cd5692a17d7" translate="yes" xml:space="preserve">
          <source>Installation</source>
          <target state="translated">Instalación</target>
        </trans-unit>
        <trans-unit id="726495cac31fed46f3681097ea8adbc806081e82" translate="yes" xml:space="preserve">
          <source>Installing the latest release</source>
          <target state="translated">Instalando la última versión</target>
        </trans-unit>
        <trans-unit id="8e78f6ced3cb3e7a0efd619bef2cccb4fa16b14d" translate="yes" xml:space="preserve">
          <source>It computes deltas for each input example-baseline pair, thus resulting to
&lt;code&gt;input.shape[0] * baseline.shape[0]&lt;/code&gt; delta values.</source>
          <target state="translated">Calcula deltas para cada par de entrada ejemplo-l&amp;iacute;nea base, lo que da como resultado valores delta &lt;code&gt;input.shape[0] * baseline.shape[0]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a8a7e2465fdc77cafbda6ce7b7d0e3ab7010ee86" translate="yes" xml:space="preserve">
          <source>It doesn't attribute the contribution scores to the input features
but shows the importance of each neuron in selected layer.</source>
          <target state="translated">No atribuye las puntuaciones de contribución a las características de entrada,sino que muestra la importancia de cada neurona en la capa seleccionada.</target>
        </trans-unit>
        <trans-unit id="45f74c2b886455a20211bc6087c7a981cba8b94d" translate="yes" xml:space="preserve">
          <source>Layer conductance shows the importance of neurons for a layer and given input.
It is an extension of path integrated gradients for hidden layers and holds the
completeness property as well.</source>
          <target state="translated">La conductancia de la capa muestra la importancia de las neuronas para una capa y una entrada dada.Es una extensión de los gradientes integrados en el camino para las capas ocultas y también tiene la propiedad de integridad.</target>
        </trans-unit>
        <trans-unit id="0022de38b637868d1853d6d090cf915fe72c96d8" translate="yes" xml:space="preserve">
          <source>Let's apply some of those algorithms to a toy model we have created for
demonstration purposes.
For simplicity, we will use the following architecture, but users are welcome
to use any PyTorch model of their choice.</source>
          <target state="translated">Apliquemos algunos de esos algoritmos a un modelo de juguete que hemos creado con fines de demostración.Para simplificar,usaremos la siguiente arquitectura,pero los usuarios son bienvenidos a usar cualquier modelo de PyTorch de su elección.</target>
        </trans-unit>
        <trans-unit id="4369c251b91c938021df6f86e075d0f68a6879d5" translate="yes" xml:space="preserve">
          <source>Let's create an instance of our model and set it to eval mode.</source>
          <target state="translated">Vamos a crear una instancia de nuestro modelo y ponerlo en modo de evaluación.</target>
        </trans-unit>
        <trans-unit id="b2e5c40eefa02dca2a0399316902a8d9c9094103" translate="yes" xml:space="preserve">
          <source>Let's define our input and baseline tensors. Baselines are used in some
interpretability algorithms such as &lt;code&gt;IntegratedGradients, DeepLift, GradientShap, NeuronConductance, LayerConductance, InternalInfluence&lt;/code&gt; and
&lt;code&gt;NeuronIntegratedGradients&lt;/code&gt;.</source>
          <target state="translated">Definamos nuestros tensores de entrada y de referencia. &lt;code&gt;IntegratedGradients, DeepLift, GradientShap, NeuronConductance, LayerConductance, InternalInfluence&lt;/code&gt; base se utilizan en algunos algoritmos de interpretabilidad como IntegratedGradients, DeepLift, GradientShap, NeuronConductance, LayerConductance, InternalInfluence y &lt;code&gt;NeuronIntegratedGradients&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a2d21524039206f00133601c7ce2c40fbb2a88ae" translate="yes" xml:space="preserve">
          <source>Let's look into the internals of our network and understand which layers
and neurons are important for the predictions.</source>
          <target state="translated">Miremos en el interior de nuestra red y entendamos qué capas y neuronas son importantes para las predicciones.</target>
        </trans-unit>
        <trans-unit id="3229609e15436ec51bcf00818a69a84dbc58a0c2" translate="yes" xml:space="preserve">
          <source>License</source>
          <target state="translated">Licencia</target>
        </trans-unit>
        <trans-unit id="7151ecc0dc7a5120377ab85e7d7eac19fe0502d7" translate="yes" xml:space="preserve">
          <source>Model interpretability for PyTorch</source>
          <target state="translated">Interpretación del modelo para PyTorch</target>
        </trans-unit>
        <trans-unit id="64a7acecc018b0b76e1070ab8d77465d6f66f86e" translate="yes" xml:space="preserve">
          <source>More details about the above mentioned &lt;a href=&quot;https://captum.ai/docs/algorithms&quot;&gt;algorithms&lt;/a&gt; and their pros and cons can be found on our &lt;a href=&quot;https://captum.ai/docs/algorithms_comparison_matrix&quot;&gt;web-site&lt;/a&gt;.</source>
          <target state="translated">Puede encontrar m&amp;aacute;s detalles sobre los &lt;a href=&quot;https://captum.ai/docs/algorithms&quot;&gt;algoritmos&lt;/a&gt; mencionados anteriormente y sus pros y contras en nuestro &lt;a href=&quot;https://captum.ai/docs/algorithms_comparison_matrix&quot;&gt;sitio web&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="c798498ab11132e260e2f04e6a25bc1b01a96272" translate="yes" xml:space="preserve">
          <source>More details on the list of supported algorithms and how to apply
Captum on different types of models can be found in our tutorials.</source>
          <target state="translated">Más detalles sobre la lista de algoritmos soportados y cómo aplicar Captum en diferentes tipos de modelos se pueden encontrar en nuestros tutoriales.</target>
        </trans-unit>
        <trans-unit id="a809e022bfbd247fdef4e8f92c06639a09f2e709" translate="yes" xml:space="preserve">
          <source>Next we will use &lt;code&gt;IntegratedGradients&lt;/code&gt; algorithms to assign attribution
scores to each input feature with respect to the first target output.</source>
          <target state="translated">A continuaci&amp;oacute;n, utilizaremos algoritmos de &lt;code&gt;IntegratedGradients&lt;/code&gt; para asignar puntuaciones de atribuci&amp;oacute;n a cada caracter&amp;iacute;stica de entrada con respecto a la primera salida de destino.</target>
        </trans-unit>
        <trans-unit id="e345eb5cbc3af8ba96268dc94160be1d607ed174" translate="yes" xml:space="preserve">
          <source>Next, we need to define simple input and baseline tensors.
Baselines belong to the input space and often carry no predictive signal.
Zero tensor can serve as a baseline for many tasks.
Some interpretability algorithms such as &lt;code&gt;Integrated Gradients&lt;/code&gt;, &lt;code&gt;Deeplift&lt;/code&gt; and &lt;code&gt;GradientShap&lt;/code&gt; are designed to attribute the change
between the input and baseline to a predictive class or a value that the neural
network outputs.</source>
          <target state="translated">A continuaci&amp;oacute;n, necesitamos definir tensores de entrada y de l&amp;iacute;nea de base simples. Las l&amp;iacute;neas de base pertenecen al espacio de entrada y, a menudo, no llevan una se&amp;ntilde;al predictiva. El tensor cero puede servir como base para muchas tareas. Algunos algoritmos de interpretabilidad como &lt;code&gt;Integrated Gradients&lt;/code&gt; , &lt;code&gt;Deeplift&lt;/code&gt; y &lt;code&gt;GradientShap&lt;/code&gt; est&amp;aacute;n dise&amp;ntilde;ados para atribuir el cambio entre la entrada y la l&amp;iacute;nea base a una clase predictiva o un valor que genera la red neuronal.</target>
        </trans-unit>
        <trans-unit id="e51de3cf2de9a13ef9bdd27134ba09503e04cca6" translate="yes" xml:space="preserve">
          <source>Now let's look into &lt;code&gt;DeepLiftShap&lt;/code&gt;. Similar to &lt;code&gt;GradientShap&lt;/code&gt;, &lt;code&gt;DeepLiftShap&lt;/code&gt; uses
baseline distribution. In the example below, we use the same baseline distribution
as for &lt;code&gt;GradientShap&lt;/code&gt;.</source>
          <target state="translated">Ahora echemos un vistazo a &lt;code&gt;DeepLiftShap&lt;/code&gt; . Similar a &lt;code&gt;GradientShap&lt;/code&gt; , &lt;code&gt;DeepLiftShap&lt;/code&gt; usa una distribuci&amp;oacute;n de l&amp;iacute;nea de base. En el siguiente ejemplo, usamos la misma distribuci&amp;oacute;n de l&amp;iacute;nea base que para &lt;code&gt;GradientShap&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4bed336194a9a5c86b6a734f03b3570d2aae1a68" translate="yes" xml:space="preserve">
          <source>Output</source>
          <target state="translated">Salida</target>
        </trans-unit>
        <trans-unit id="f3c8c95c5e534bcd2ea0034a0d83177efa6923f4" translate="yes" xml:space="preserve">
          <source>Output:</source>
          <target state="translated">Salida:</target>
        </trans-unit>
        <trans-unit id="7835db447bc76230b5b0d736b2d78c671d7100a1" translate="yes" xml:space="preserve">
          <source>Outputs</source>
          <target state="translated">Salidas</target>
        </trans-unit>
        <trans-unit id="b969baf269c9dc13dd2c54d156013b3e06ea3070" translate="yes" xml:space="preserve">
          <source>Positive attribution score means that the input in that particular position
positively contributed to the final prediction and negative means the opposite.
The magnitude of the attribution score signifies the strength of the contribution.
Zero attribution score means no contribution from that particular feature.</source>
          <target state="translated">La puntuación de atribución positiva significa que la entrada en esa posición particular contribuyó positivamente a la predicción final y la negativa significa lo contrario.La magnitud de la puntuación de atribución significa la fuerza de la contribución.La puntuación de atribución cero significa que no hay contribución de esa característica en particular.</target>
        </trans-unit>
        <trans-unit id="4c0d584e447dd2c5fa55e98d5d7921249c3911f6" translate="yes" xml:space="preserve">
          <source>PyTorch &amp;gt;= 1.2</source>
          <target state="translated">PyTorch&amp;gt; = 1.2</target>
        </trans-unit>
        <trans-unit id="c32b6c1ab053aa1b803595ba447bebbb8760c137" translate="yes" xml:space="preserve">
          <source>Python &amp;gt;= 3.6</source>
          <target state="translated">Python&amp;gt; = 3.6</target>
        </trans-unit>
        <trans-unit id="f00e768dce422689fe65ae881c3b96779cce5814" translate="yes" xml:space="preserve">
          <source>References of Algorithms</source>
          <target state="translated">Referencias de los algoritmos</target>
        </trans-unit>
        <trans-unit id="54d440a5db0ab24f40fddf2b795f3716e25774cf" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;CONTRIBUTING.md&quot;&gt;CONTRIBUTING&lt;/a&gt; file for how to help out.</source>
          <target state="translated">Vea el archivo &lt;a href=&quot;CONTRIBUTING.md&quot;&gt;CONTRIBUTING&lt;/a&gt; para saber c&amp;oacute;mo ayudar.</target>
        </trans-unit>
        <trans-unit id="9076ccad99e9fe123f5a242ef0d44a11422a0a37" translate="yes" xml:space="preserve">
          <source>Similar to GradientShap in order to compute example-based deltas we can average them per example:</source>
          <target state="translated">De manera similar a GradientShap para calcular deltas basados en ejemplos podemos promediarlos por ejemplo:</target>
        </trans-unit>
        <trans-unit id="7c2892f73bdaf8f8b7b55fd520cd5b43f07bb285" translate="yes" xml:space="preserve">
          <source>Similar to integrated gradients, DeepLift returns a convergence delta score
per input example. The approximation error is then the absolute
value of the convergence deltas and can serve as a proxy of how accurate the
algorithm's approximation is.</source>
          <target state="translated">Similar a los gradientes integrados,DeepLift devuelve una puntuación delta de convergencia por ejemplo de entrada.El error de aproximación es entonces el valor absoluto de los deltas de convergencia y puede servir como una aproximación aproximada de la precisión del algoritmo.</target>
        </trans-unit>
        <trans-unit id="c98898a289abd12ad3663b6492c23d0af933dcbb" translate="yes" xml:space="preserve">
          <source>Similar to other attribution algorithms that return convergence delta, &lt;code&gt;LayerConductance&lt;/code&gt;
returns the deltas for each example. The approximation error is then the absolute
value of the convergence deltas and can serve as a proxy of how accurate integral
approximation for given inputs and baselines is.</source>
          <target state="translated">De manera similar a otros algoritmos de atribuci&amp;oacute;n que devuelven delta de convergencia, &lt;code&gt;LayerConductance&lt;/code&gt; devuelve los deltas para cada ejemplo. El error de aproximaci&amp;oacute;n es entonces el valor absoluto de los deltas de convergencia y puede servir como un proxy de cu&amp;aacute;n precisa es la aproximaci&amp;oacute;n integral para entradas y l&amp;iacute;neas de base dadas.</target>
        </trans-unit>
        <trans-unit id="08641a32adb6073b217892c1d05043cccc5795f7" translate="yes" xml:space="preserve">
          <source>Similarly, we can apply &lt;code&gt;GradientShap&lt;/code&gt;, &lt;code&gt;DeepLift&lt;/code&gt; and other attribution algorithms to the model.</source>
          <target state="translated">Del mismo modo, podemos aplicar &lt;code&gt;GradientShap&lt;/code&gt; , &lt;code&gt;DeepLift&lt;/code&gt; y otros algoritmos de atribuci&amp;oacute;n al modelo.</target>
        </trans-unit>
        <trans-unit id="5dfd03564d68a63c3940a933d7149be86e1b24fc" translate="yes" xml:space="preserve">
          <source>Talks and Papers</source>
          <target state="translated">Charlas y documentos</target>
        </trans-unit>
        <trans-unit id="5cc6318e21af4a9864dfb66b71e19b22e67f5171" translate="yes" xml:space="preserve">
          <source>Target Audience</source>
          <target state="translated">Público objetivo</target>
        </trans-unit>
        <trans-unit id="7c09a880f031a61c434b6eea261034d0953ae737" translate="yes" xml:space="preserve">
          <source>The algorithm outputs an attribution score for each input element and a
convergence delta. The lower the absolute value of the convergence delta the better
is the approximation. If we choose not to return delta,
we can simply not provide &lt;code&gt;return_convergence_delta&lt;/code&gt; input
argument. The absolute value of the returned deltas can be interpreted as an
approximation error for each input sample.
It can also serve as a proxy of how accurate the integral approximation for given
inputs and baselines is.
If the approximation error is large, we can try larger number of integral
approximation steps by setting &lt;code&gt;n_steps&lt;/code&gt; to a larger value. Not all algorithms
return approximation error. Those which do, though, compute it based on the
completeness property of the algorithms.</source>
          <target state="translated">El algoritmo genera una puntuaci&amp;oacute;n de atribuci&amp;oacute;n para cada elemento de entrada y un delta de convergencia. Cuanto menor sea el valor absoluto del delta de convergencia, mejor ser&amp;aacute; la aproximaci&amp;oacute;n. Si elegimos no devolver delta, simplemente no podemos proporcionar el argumento de entrada &lt;code&gt;return_convergence_delta&lt;/code&gt; . El valor absoluto de los deltas devueltos se puede interpretar como un error de aproximaci&amp;oacute;n para cada muestra de entrada. Tambi&amp;eacute;n puede servir como un indicador de cu&amp;aacute;n precisa es la aproximaci&amp;oacute;n integral para entradas y l&amp;iacute;neas de base dadas. Si el error de aproximaci&amp;oacute;n es grande, podemos probar un mayor n&amp;uacute;mero de pasos de aproximaci&amp;oacute;n integral estableciendo &lt;code&gt;n_steps&lt;/code&gt; en un valor mayor. No todos los algoritmos devuelven errores de aproximaci&amp;oacute;n. Aquellos que lo hacen, sin embargo, lo calculan bas&amp;aacute;ndose en la propiedad de completitud de los algoritmos.</target>
        </trans-unit>
        <trans-unit id="9bc5b2cbf539dd2b556b4ee16093e2dd98e5e53f" translate="yes" xml:space="preserve">
          <source>The latest release of Captum is easily installed either via
&lt;a href=&quot;https://www.anaconda.com/distribution/#download-section&quot;&gt;Anaconda&lt;/a&gt; (recommended):</source>
          <target state="translated">La &amp;uacute;ltima versi&amp;oacute;n de Captum se instala f&amp;aacute;cilmente a trav&amp;eacute;s de &lt;a href=&quot;https://www.anaconda.com/distribution/#download-section&quot;&gt;Anaconda&lt;/a&gt; (recomendado):</target>
        </trans-unit>
        <trans-unit id="14456e5d622ffef206d84cb2547dd1292a3e6a4b" translate="yes" xml:space="preserve">
          <source>The number of elements in the &lt;code&gt;delta&lt;/code&gt; tensor is equal to: &lt;code&gt;n_samples * input.shape[0]&lt;/code&gt;
In order to get a example-based delta, we can, for example, average them:</source>
          <target state="translated">El n&amp;uacute;mero de elementos en el tensor &lt;code&gt;delta&lt;/code&gt; es igual a: &lt;code&gt;n_samples * input.shape[0]&lt;/code&gt; Para obtener un delta basado en ejemplos, podemos, por ejemplo, promediarlos:</target>
        </trans-unit>
        <trans-unit id="d97f36b304cf7bf6d19d6ba216bf83da80bc9ca1" translate="yes" xml:space="preserve">
          <source>The primary audiences for Captum are model developers who are looking to improve their models and understand which features are important and interpretability researchers focused on identifying algorithms that can better interpret many types of models.</source>
          <target state="translated">Los principales destinatarios de Captum son los desarrolladores de modelos que buscan mejorar sus modelos y comprender qué características son importantes,y los investigadores de la interpretabilidad centrados en la identificación de algoritmos que puedan interpretar mejor muchos tipos de modelos.</target>
        </trans-unit>
        <trans-unit id="09bb5c690208bfa966db7460586a698914a360bd" translate="yes" xml:space="preserve">
          <source>The slides of our presentation from NeurIPS 2019 can be found &lt;a href=&quot;docs/presentations/Captum_NeurIPS_2019_final.key&quot;&gt;here&lt;/a&gt;</source>
          <target state="translated">Las diapositivas de nuestra presentaci&amp;oacute;n de NeurIPS 2019 se pueden encontrar &lt;a href=&quot;docs/presentations/Captum_NeurIPS_2019_final.key&quot;&gt;aqu&amp;iacute;&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5d0367e1f5fde1ede3db753f108801cb14982eac" translate="yes" xml:space="preserve">
          <source>To analyze a sample model on CIFAR10 via Captum Insights run</source>
          <target state="translated">Para analizar un modelo de muestra en el CIFAR10 a través de Captum Insights ejecutar</target>
        </trans-unit>
        <trans-unit id="1b78a188c82782ae0e64234fb5851ce273466f93" translate="yes" xml:space="preserve">
          <source>To build Insights you will need &lt;a href=&quot;https://nodejs.org/en/&quot;&gt;Node&lt;/a&gt; &amp;gt;= 8.x
and &lt;a href=&quot;https://yarnpkg.com/en/&quot;&gt;Yarn&lt;/a&gt; &amp;gt;= 1.5.</source>
          <target state="translated">Para crear Insights, necesitar&amp;aacute; &lt;a href=&quot;https://nodejs.org/en/&quot;&gt;Node&lt;/a&gt; &amp;gt; = 8.xy &lt;a href=&quot;https://yarnpkg.com/en/&quot;&gt;Yarn&lt;/a&gt; &amp;gt; = 1.5.</target>
        </trans-unit>
        <trans-unit id="5468c50938c4ec01b3019827d9753bc27eccd242" translate="yes" xml:space="preserve">
          <source>To build and launch from a checkout in a conda environment run</source>
          <target state="translated">Para construir y lanzar desde una caja en un entorno de conda ejecutar</target>
        </trans-unit>
        <trans-unit id="47d309089702b5779d1249906c184aca6a17334f" translate="yes" xml:space="preserve">
          <source>To build the widget from a checkout in a conda environment run</source>
          <target state="translated">Para construir el widget desde una caja en un entorno de conda ejecute</target>
        </trans-unit>
        <trans-unit id="039a5244d60906d43c5c15a0a20b10397b0bc5f9" translate="yes" xml:space="preserve">
          <source>To customize the installation, you can also run the following variants of the
above:</source>
          <target state="translated">Para personalizar la instalación,también puede ejecutar las siguientes variantes de lo anterior:</target>
        </trans-unit>
        <trans-unit id="a39ccefe51118817f1b35b636167cdb3bd9357d8" translate="yes" xml:space="preserve">
          <source>To execute unit tests from a manual install, run:</source>
          <target state="translated">Para ejecutar las pruebas de la unidad de una instalación manual,ejecute:</target>
        </trans-unit>
        <trans-unit id="4ac1cec1a4406720bdada7e35a448ad0dfd20d82" translate="yes" xml:space="preserve">
          <source>To make computations deterministic, let's fix random seeds.</source>
          <target state="translated">Para que los cálculos sean deterministas,fijemos semillas al azar.</target>
        </trans-unit>
        <trans-unit id="eba414e2b73da649f8d414e82f52b11624820726" translate="yes" xml:space="preserve">
          <source>We will apply model interpretability algorithms on the network
mentioned above in order to understand the importance of individual
neurons/layers and the parts of the input that play an important role in the
final prediction.</source>
          <target state="translated">Aplicaremos los algoritmos de interpretación de modelos en la red mencionada anteriormente para comprender la importancia de las neuronas/capas individuales y las partes de la entrada que juegan un papel importante en la predicción final.</target>
        </trans-unit>
        <trans-unit id="168626e3b7f39ed35712d4be0f4311e69049dd72" translate="yes" xml:space="preserve">
          <source>We will start with the &lt;code&gt;NeuronConductance&lt;/code&gt;. &lt;code&gt;NeuronConductance&lt;/code&gt; helps us to identify
input features that are important for a particular neuron in a given
layer. It decomposes the computation of integrated gradients via the chain rule by
defining the importance of a neuron as path integral of the derivative of the output
with respect to the neuron times the derivatives of the neuron with respect to the
inputs of the model.</source>
          <target state="translated">Empezaremos por la &lt;code&gt;NeuronConductance&lt;/code&gt; . &lt;code&gt;NeuronConductance&lt;/code&gt; nos ayuda a identificar las caracter&amp;iacute;sticas de entrada que son importantes para una neurona en particular en una capa determinada. Descompone el c&amp;aacute;lculo de gradientes integrados a trav&amp;eacute;s de la regla de la cadena definiendo la importancia de una neurona como integral de trayectoria de la derivada de la salida con respecto a la neurona multiplicada por las derivadas de la neurona con respecto a las entradas del modelo.</target>
        </trans-unit>
        <trans-unit id="3aee6cb4b987c6eb98bae057c8033da66b7ba223" translate="yes" xml:space="preserve">
          <source>With the increase in model complexity and the resulting lack of transparency, model interpretability methods have become increasingly important. Model understanding is both an active area of research as well as an area of focus for practical applications across industries using machine learning. Captum provides state-of-the-art algorithms, including Integrated Gradients, to provide researchers and developers with an easy way to understand which features are contributing to a model&amp;rsquo;s output.</source>
          <target state="translated">Con el aumento de la complejidad del modelo y la falta de transparencia resultante, los m&amp;eacute;todos de interpretaci&amp;oacute;n del modelo se han vuelto cada vez m&amp;aacute;s importantes. La comprensi&amp;oacute;n del modelo es tanto un &amp;aacute;rea activa de investigaci&amp;oacute;n como un &amp;aacute;rea de enfoque para aplicaciones pr&amp;aacute;cticas en todas las industrias que utilizan el aprendizaje autom&amp;aacute;tico. Captum proporciona algoritmos de &amp;uacute;ltima generaci&amp;oacute;n, incluidos gradientes integrados, para proporcionar a los investigadores y desarrolladores una forma sencilla de comprender qu&amp;eacute; caracter&amp;iacute;sticas contribuyen a la salida de un modelo.</target>
        </trans-unit>
        <trans-unit id="ffc76686099e22242eb4269a3745fa2f6e1ef1d4" translate="yes" xml:space="preserve">
          <source>and navigate to the URL specified in the output.</source>
          <target state="translated">y navegar a la URL especificada en la salida.</target>
        </trans-unit>
        <trans-unit id="2eeef8b3dfe3c6e07456229818d93864ce2c6fe7" translate="yes" xml:space="preserve">
          <source>in order to get per example average delta.</source>
          <target state="translated">para obtener por ejemplo el delta medio.</target>
        </trans-unit>
        <trans-unit id="d6773e7adcc2adec52348c71e0551f68a9f85abd" translate="yes" xml:space="preserve">
          <source>or via &lt;code&gt;pip&lt;/code&gt;:</source>
          <target state="translated">o v&amp;iacute;a &lt;code&gt;pip&lt;/code&gt; :</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
