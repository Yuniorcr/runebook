<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ja" datatype="htmlbody" original="https://pypi.org/project/musdb/">
    <body>
      <group id="musdb">
        <trans-unit id="eff1ab2217457363930cfd857d03cbe7acecf8d6" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Track.audio&lt;/code&gt;, stereo mixture as an numpy array of shape &lt;code&gt;(nb_samples, 2)&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;Track.audio&lt;/code&gt; 、形状の多数の配列としてのステレオ混合 &lt;code&gt;(nb_samples, 2)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="f5d441d75d5493d97701a4791554c53b1ea63127" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Track.name&lt;/code&gt;, the track name, consisting of &lt;code&gt;Track.artist&lt;/code&gt; and &lt;code&gt;Track.title&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;Track.name&lt;/code&gt; 、 &lt;code&gt;Track.artist&lt;/code&gt; と &lt;code&gt;Track.title&lt;/code&gt; で構成されるトラック名。</target>
        </trans-unit>
        <trans-unit id="0c6e8e4571ff73ce2c0cbe03b66cbafbaf85a2bc" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Track.path&lt;/code&gt;, the absolute path of the mixture which might be handy to process with external applications.</source>
          <target state="translated">&lt;code&gt;Track.path&lt;/code&gt; 、外部アプリケーションで処理するのに便利な混合物の絶対パス。</target>
        </trans-unit>
        <trans-unit id="df352bf2c4ef3c71ca9e9bcd5402bdd8c9d7fb0f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Track.rate&lt;/code&gt;, the sample rate of the mixture.</source>
          <target state="translated">&lt;code&gt;Track.rate&lt;/code&gt; 、混合物のサンプルレート。</target>
        </trans-unit>
        <trans-unit id="47fa7f3db16beaa5f69ea7bc866af4f3fc23f69e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Track.sources&lt;/code&gt;, a dictionary of sources used for this track.</source>
          <target state="translated">&lt;code&gt;Track.sources&lt;/code&gt; 、このトラックに使用されるソースの辞書。</target>
        </trans-unit>
        <trans-unit id="121d66e2807831beba8db486f18ef6989ba57638" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Track.stems&lt;/code&gt;, an numpy tensor of all five stereo sources of shape &lt;code&gt;(5, nb_samples, 2)&lt;/code&gt;. The stems are always in the following order: &lt;code&gt;['mixture', 'drums', 'bass', 'other', 'vocals']&lt;/code&gt;,</source>
          <target state="translated">&lt;code&gt;Track.stems&lt;/code&gt; 、形状の5つ​​のステレオソースすべての多数のテンソル &lt;code&gt;(5, nb_samples, 2)&lt;/code&gt; 。ステムは常に次の順序になっています： &lt;code&gt;['mixture', 'drums', 'bass', 'other', 'vocals']&lt;/code&gt; 、</target>
        </trans-unit>
        <trans-unit id="e36c9a7e880ef463ca80b642aab1c316c0874d54" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Track.targets&lt;/code&gt;, a dictionary of targets provided for this track.
Note that for MUSDB, the sources and targets differ only in the existence of the &lt;code&gt;accompaniment&lt;/code&gt;, which is the sum of all sources, except for the vocals. MUSDB supports the following targets: &lt;code&gt;['mixture', 'drums', 'bass', 'other', 'vocals', 'accompaniment', 'linear_mixture']&lt;/code&gt;. Note that some of the targets (such as &lt;strong&gt;accompaniment&lt;/strong&gt;) are dynamically mixed on the fly.</source>
          <target state="translated">&lt;code&gt;Track.targets&lt;/code&gt; 、このトラックに提供されるターゲットの辞書。MUSDBの場合、ソースとターゲットは、ボーカルを除くすべてのソースの合計である &lt;code&gt;accompaniment&lt;/code&gt; の存在のみが異なることに注意してください。MUSDBは、次のターゲットをサポートしています： &lt;code&gt;['mixture', 'drums', 'bass', 'other', 'vocals', 'accompaniment', 'linear_mixture']&lt;/code&gt; 。一部のターゲット（&lt;strong&gt;伴奏&lt;/strong&gt;など）は、その場で動的に混合されることに注意してください。</target>
        </trans-unit>
        <trans-unit id="33e24b937c4ac43e5fcf63232384893b9f40c24f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;musdb&lt;/code&gt; comes with 7 seconds excerpts (automatically downloaded) of the full dataset for quick evaluation or prototyping. The full dataset, however, needs to be downloaded &lt;a href=&quot;https://zenodo.org/record/1117372&quot;&gt;via Zenodo&lt;/a&gt; and stored (unzipped) separately.</source>
          <target state="translated">&lt;code&gt;musdb&lt;/code&gt; には、迅速な評価またはプロトタイピングのために、完全なデータセットの7秒の抜粋（自動的にダウンロード）が付属しています。ただし、完全なデータセットは&lt;a href=&quot;https://zenodo.org/record/1117372&quot;&gt;Zenodo経由&lt;/a&gt;でダウンロードし、個別に保存（解凍）する必要があります。</target>
        </trans-unit>
        <trans-unit id="420a4eb2d0665ef680393c5af54d6fcaa6a78172" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;MUSDB18&lt;/em&gt; comes encoded in &lt;a href=&quot;http://www.stems-music.com/&quot;&gt;STEMS&lt;/a&gt; which is a multitrack audio format that uses &lt;em&gt;lossy compression&lt;/em&gt;. The &lt;code&gt;musdb&lt;/code&gt; package, internally, relies on FFMPEG to decode the multi-stream files. For convenience, we developed a python package called &lt;a href=&quot;https://github.com/faroit/stempeg&quot;&gt;stempeg&lt;/a&gt; that allows to easily parse the stem files and decode them on-the-fly.
When you install &lt;em&gt;musdb&lt;/em&gt; (which depends on &lt;em&gt;stempeg&lt;/em&gt;), it is therefore necessary to also install the FFMPEG library. The installation may differ among operating systems and python distributions:</source>
          <target state="translated">&lt;em&gt;MUSDB18&lt;/em&gt;は、&lt;em&gt;不可逆圧縮&lt;/em&gt;を使用するマルチトラックオーディオ形式である&lt;a href=&quot;http://www.stems-music.com/&quot;&gt;STEMS&lt;/a&gt;でエンコードされています。 &lt;code&gt;musdb&lt;/code&gt; のパッケージには、内部的に、マルチストリームファイルをデコードするFFMPEGに依存しています。便宜上、ステムファイルを簡単に解析してオンザフライでデコードできる&lt;a href=&quot;https://github.com/faroit/stempeg&quot;&gt;stempeg&lt;/a&gt;というPythonパッケージを開発しました。あなたがインストールすると&lt;em&gt;musdb&lt;/em&gt;（に依存&lt;em&gt;stempegを&lt;/em&gt;）、また、FFMPEGのライブラリをインストールする必要があります。インストールは、オペレーティングシステムとPythonディストリビューションによって異なる場合があります。&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="ea0ff0a3bd2dd89256f78e68349fac519239ccf9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;When you use the decoded MUSDB, use the &lt;code&gt;is_wav&lt;/code&gt; parameter when initializing the dataset.&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;デコードされたMUSDBを使用する場合は、データセットを初期化するときに &lt;code&gt;is_wav&lt;/code&gt; パラメーターを使用します。&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="3f265a828664515c2a0a69dd5db40e87c516c584" translate="yes" xml:space="preserve">
          <source>A python package to parse and process the &lt;a href=&quot;https://sigsep.github.io/musdb&quot;&gt;MUSDB18 dataset&lt;/a&gt;, the largest open access dataset for music source separation. The tool was originally developed for the &lt;a href=&quot;sisec18.unmix.app&quot;&gt;Music Separation task&lt;/a&gt; as part of the &lt;a href=&quot;https://sisec.inria.fr/&quot;&gt;Signal Separation Evaluation Campaign (SISEC)&lt;/a&gt;.</source>
          <target state="translated">音楽ソース分離のための最大のオープンアクセスデータ&lt;a href=&quot;https://sigsep.github.io/musdb&quot;&gt;セット&lt;/a&gt;であるMUSDB18データセットを解析および処理するためのPythonパッケージ。このツールは元々、&lt;a href=&quot;https://sisec.inria.fr/&quot;&gt;信号分離評価キャンペーン（SISEC）の&lt;/a&gt;一部として&lt;a href=&quot;sisec18.unmix.app&quot;&gt;音楽分離タスク&lt;/a&gt;用に開発されました。</target>
        </trans-unit>
        <trans-unit id="9f672ccf915a39598644ad9a295ffb1dbd62e8d7" translate="yes" xml:space="preserve">
          <source>Alternatively you can install FFMPEG manually as follows:</source>
          <target state="translated">または、以下のように手動でFFMPEGをインストールすることができます。</target>
        </trans-unit>
        <trans-unit id="323cf9586a360c76d757f761fea4549f8b45d87e" translate="yes" xml:space="preserve">
          <source>Baselines</source>
          <target state="translated">ベースライン</target>
        </trans-unit>
        <trans-unit id="fd328df32af47ff4f34212c8adf3d3fbaf1aea24" translate="yes" xml:space="preserve">
          <source>Citations</source>
          <target state="translated">引用</target>
        </trans-unit>
        <trans-unit id="ff7513853508e7c6e3aa07908df2a450a026eb88" translate="yes" xml:space="preserve">
          <source>Evaluation</source>
          <target state="translated">評価</target>
        </trans-unit>
        <trans-unit id="5f6443a284213415a14df3c85e12378cf8071af9" translate="yes" xml:space="preserve">
          <source>For oracle methods, please check out our &lt;a href=&quot;https://github.com/sigsep/sigsep-mus-oracle&quot;&gt;open unmix oracle separation methods&lt;/a&gt;.
This will show you how oracle performance is computed and gives indications for an upper bound for the quality of the separation.</source>
          <target state="translated">オラクルメソッドについては、&lt;a href=&quot;https://github.com/sigsep/sigsep-mus-oracle&quot;&gt;オープンアンミックスオラクル分離メソッド&lt;/a&gt;を確認してください。これにより、オラクルのパフォーマンスがどのように計算されるかが示され、分離の品質の上限が示されます。</target>
        </trans-unit>
        <trans-unit id="d790b402d79ac1a723c790313bcd679999474630" translate="yes" xml:space="preserve">
          <source>Frequently Asked Questions</source>
          <target state="translated">よくある質問</target>
        </trans-unit>
        <trans-unit id="765ce65dc57c23ea4b17c61f7adde7d0f903c740" translate="yes" xml:space="preserve">
          <source>Getting the data</source>
          <target state="translated">データの取得</target>
        </trans-unit>
        <trans-unit id="8e9e47310de9555280cd460663c1dbd0a1adba5b" translate="yes" xml:space="preserve">
          <source>If compare your results with SiSEC 2018 Participants - Cite the SiSEC 2018 LVA/ICA Paper</source>
          <target state="translated">SiSEC 2018参加者と比較するなら-SiSEC 2018 LVA/ICA論文の引用</target>
        </trans-unit>
        <trans-unit id="138db4b5382fa4b7773cb8a28fe6e1cf154b3abe" translate="yes" xml:space="preserve">
          <source>If you don't want to use python for this, we also provide &lt;a href=&quot;https://github.com/sigsep/sigsep-mus-io&quot;&gt;docker based scripts&lt;/a&gt; to decode the dataset to WAV files.</source>
          <target state="translated">これにPythonを使用したくない場合は、データセットをWAVファイルにデコードするための&lt;a href=&quot;https://github.com/sigsep/sigsep-mus-io&quot;&gt;Dockerベースのスクリプト&lt;/a&gt;も提供しています。</target>
        </trans-unit>
        <trans-unit id="03fccfef108b986a75907475407a3721d977c3dd" translate="yes" xml:space="preserve">
          <source>If you use the MUSDB dataset for your research - Cite the MUSDB18 Dataset</source>
          <target state="translated">研究にMUSDBデータセットを使用する場合-MUSDB18データセットの引用</target>
        </trans-unit>
        <trans-unit id="6c98bd4105d83c734465099d92637f2b39cc418a" translate="yes" xml:space="preserve">
          <source>If you want to access individual tracks, you can access the &lt;code&gt;mus&lt;/code&gt; tracks list by its indices, e.g. &lt;code&gt;mus[2:]&lt;/code&gt;. To foster reproducible research, we provide a fixed validation dataset.</source>
          <target state="translated">個々のトラックにアクセスしたい場合は、インデックスによって &lt;code&gt;mus&lt;/code&gt; トラックリストにアクセスできます（例： &lt;code&gt;mus[2:]&lt;/code&gt; 。再現性のある研究を促進するために、固定の検証データセットを提供しています。</target>
        </trans-unit>
        <trans-unit id="c0aea3c013c4ea85aaf8da01bb7c5c92bd04c515" translate="yes" xml:space="preserve">
          <source>If you want to use WAV files (e.g. for faster audio decoding), &lt;code&gt;musdb&lt;/code&gt; also supports parsing and processing pre-decoded PCM/wav files. &lt;code&gt;musdb&lt;/code&gt; comes with the ability to convert a STEMS dataset into WAV version. This script can be used from the command line by</source>
          <target state="translated">WAVファイルを使用する場合（オーディオデコードを高速化する場合など）、 &lt;code&gt;musdb&lt;/code&gt; は事前にデコードされたPCM / wavファイルの解析と処理もサポートしています。 &lt;code&gt;musdb&lt;/code&gt; には、STEMSデータセットをWAVバージョンに変換する機能が付属しています。このスクリプトは、コマンドラインから次の方法で使用できます。</target>
        </trans-unit>
        <trans-unit id="5770b728fa2eb0839ba0edf415f1f1192785c2f4" translate="yes" xml:space="preserve">
          <source>Import the &lt;code&gt;musdb&lt;/code&gt; package in your main python function and iterate over the 7 seconds &lt;code&gt;musdb&lt;/code&gt; tracks:</source>
          <target state="translated">メインのPython関数に &lt;code&gt;musdb&lt;/code&gt; パッケージをインポートし、7秒間の &lt;code&gt;musdb&lt;/code&gt; トラックを繰り返します。</target>
        </trans-unit>
        <trans-unit id="a8f39a0eaff1e31685a2b14797108f08b8c37cd0" translate="yes" xml:space="preserve">
          <source>Installation and Setup</source>
          <target state="translated">インストールとセットアップ</target>
        </trans-unit>
        <trans-unit id="370cfaa9b9ac29647dea8e39f6de9fea6cc3a9a7" translate="yes" xml:space="preserve">
          <source>Iterate over MUSDB18 tracks</source>
          <target state="translated">MUSDB18トラックの繰り返し処理</target>
        </trans-unit>
        <trans-unit id="7f47c6de2ebcabbcc56f62559cf85e9a5796a39a" translate="yes" xml:space="preserve">
          <source>Iterating over &lt;code&gt;musdb&lt;/code&gt; and thus accessing the audio data is as simple as. Lets assume, we have a supervised training method &lt;code&gt;train(x, y)&lt;/code&gt; that takes the &lt;strong&gt;mixture&lt;/strong&gt; as input and the &lt;strong&gt;vocals&lt;/strong&gt; as output, we can simple use:</source>
          <target state="translated">&lt;code&gt;musdb&lt;/code&gt; を反復処理して、オーディオデータにアクセスするのは簡単です。私たちは教師トレーニング方法の持っている、と仮定しましょう &lt;code&gt;train(x, y)&lt;/code&gt; とり&lt;strong&gt;、混合物を&lt;/strong&gt;入力として、そして&lt;strong&gt;ボーカル&lt;/strong&gt;の出力などを、私たちすることができます簡単な使用：</target>
        </trans-unit>
        <trans-unit id="3229609e15436ec51bcf00818a69a84dbc58a0c2" translate="yes" xml:space="preserve">
          <source>License</source>
          <target state="translated">ライセンス</target>
        </trans-unit>
        <trans-unit id="89690ac571dcf4c9c40c842efed3f11171d07b29" translate="yes" xml:space="preserve">
          <source>MIT</source>
          <target state="translated">マサチューセッツ工科大学</target>
        </trans-unit>
        <trans-unit id="132dd629d2322820736b20863649b1dc62f54f40" translate="yes" xml:space="preserve">
          <source>On &lt;a href=&quot;https://anaconda.org&quot;&gt;Anaconda&lt;/a&gt;, you can install FFMPEG using &lt;code&gt;conda install -c conda-forge ffmpeg&lt;/code&gt;.</source>
          <target state="translated">で&lt;a href=&quot;https://anaconda.org&quot;&gt;アナコンダ&lt;/a&gt;、あなたが使用してFFMPEGをインストールすることができ &lt;code&gt;conda install -c conda-forge ffmpeg&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="207215fe0cc1433e1aede28acc2a8073c8c33db1" translate="yes" xml:space="preserve">
          <source>Open-Unmix</source>
          <target state="translated">オープンアンミックス</target>
        </trans-unit>
        <trans-unit id="2b4abd4e67fec0f3d7112a8e2a392fb3249b9341" translate="yes" xml:space="preserve">
          <source>Oracles</source>
          <target state="translated">Oracles</target>
        </trans-unit>
        <trans-unit id="77ca84718e0ad8247dcc8f32f65ce5736bf1270f" translate="yes" xml:space="preserve">
          <source>Package installation</source>
          <target state="translated">パッケージのインストール</target>
        </trans-unit>
        <trans-unit id="2a1b54776f0e80073e212cb5b9ce3350e5c11555" translate="yes" xml:space="preserve">
          <source>Processing training and testing subsets separately</source>
          <target state="translated">トレーニングとテストのサブセットを別々に処理</target>
        </trans-unit>
        <trans-unit id="df4021359edbeba8382d06ca8f62d6123c1282b1" translate="yes" xml:space="preserve">
          <source>Python parser for the SIGSEP MUSDB18 dataset</source>
          <target state="translated">SIGSEP MUSDB18データセット用のPythonパーサー</target>
        </trans-unit>
        <trans-unit id="9062ad8afd8d0d1be03a86b7244eeb4d7794c02d" translate="yes" xml:space="preserve">
          <source>Setting up musdb</source>
          <target state="translated">musdbの設定</target>
        </trans-unit>
        <trans-unit id="ff667ad4912ee7200ee958e9c14cfab32b735028" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Track&lt;/code&gt; objects which makes it easy to process the audio and metadata in a pythonic way:</source>
          <target state="translated">&lt;code&gt;Track&lt;/code&gt; が簡単神託の方法で、オーディオおよびメタデータを処理することができますオブジェクト：</target>
        </trans-unit>
        <trans-unit id="4e264d7ce32d057a9dd6209d34288c3668929c0f" translate="yes" xml:space="preserve">
          <source>The dataset is hosted on Zenodo and requires that users request access, since the tracks can only be used for academic purposes. We manually check this requests. Please do not fill the form multiple times, it usually takes as less than a day to give you access.</source>
          <target state="translated">データセットはZenodoでホストされており、トラックは学術目的でのみ使用できるため、ユーザーはアクセスを要求する必要があります。我々はこの要求を手動でチェックしています。フォームに何度も記入しないでください、それはあなたにアクセスを与えるために通常1日未満としてかかります。</target>
        </trans-unit>
        <trans-unit id="2da76dfbeac983fa1c791c4b2a7bf221d157c103" translate="yes" xml:space="preserve">
          <source>The list of validation tracks can be edited using the &lt;a href=&quot;https://github.com/sigsep/sigsep-mus-tools/blob/b283da5b8f24e84172a60a06bb8f3dacd57aa6cd/musdb/configs/mus.yaml&quot;&gt;&lt;code&gt;mus.setup['validation_tracks']&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="translated">検証トラックのリストは、&lt;a href=&quot;https://github.com/sigsep/sigsep-mus-tools/blob/b283da5b8f24e84172a60a06bb8f3dacd57aa6cd/musdb/configs/mus.yaml&quot;&gt; &lt;code&gt;mus.setup['validation_tracks']&lt;/code&gt; &lt;/a&gt;オブジェクトを使用して編集できます。</target>
        </trans-unit>
        <trans-unit id="c34bfbcd3c28a179b9c52e7a72bd51dc8961b60b" translate="yes" xml:space="preserve">
          <source>The mixture is not exactly the sum of its sources, is that intended?</source>
          <target state="translated">混合物は正確にはその源の総和ではありませんが、それは意図しているのでしょうか?</target>
        </trans-unit>
        <trans-unit id="78a04588fdb45db6b16aa25b1f9fcab863f71b75" translate="yes" xml:space="preserve">
          <source>This is not a bug. Since we adopted the STEMS format, we used AAC compression. Here the residual noise of the mixture is different from the sum of the residual noises of the sources. This difference does not significantly affect separation performance.</source>
          <target state="translated">これはバグではありません。STEMS形式を採用しているので、AAC圧縮を使用しています。ここでは、混合物の残留雑音は、音源の残留雑音の和とは異なります。この違いは分離性能に大きく影響しません。</target>
        </trans-unit>
        <trans-unit id="2e55f986e229905af6c29b05543f574bab642f10" translate="yes" xml:space="preserve">
          <source>This package should nicely integrate with your existing python numpy, tensorflow or pytorch code. Most of the steps to use musdb in your project will probably use the same first steps:</source>
          <target state="translated">このパッケージは、既存の python numpy,tensorflow,pytorch コードとうまく統合する必要があります。プロジェクトで musdb を使用するためのほとんどのステップは、おそらく同じ最初のステップを使用します。</target>
        </trans-unit>
        <trans-unit id="ac5c5d45a33ef62d494dbc071fa4f1cc427b5e30" translate="yes" xml:space="preserve">
          <source>To Evaluate a &lt;code&gt;musdb&lt;/code&gt; track using the popular BSSEval metrics, you can use our &lt;a href=&quot;https://github.com/sigsep/sigsep-mus-eval&quot;&gt;museval&lt;/a&gt; package. After &lt;code&gt;pip install musdb&lt;/code&gt; evaluation of a single &lt;code&gt;track&lt;/code&gt;, can be done by</source>
          <target state="translated">人気のあるBSSEvalメトリックを使用して &lt;code&gt;musdb&lt;/code&gt; トラックを評価するには、&lt;a href=&quot;https://github.com/sigsep/sigsep-mus-eval&quot;&gt;museval&lt;/a&gt;パッケージを使用できます。単一 &lt;code&gt;track&lt;/code&gt; &lt;code&gt;pip install musdb&lt;/code&gt; 評価の後、次の方法で実行できます。</target>
        </trans-unit>
        <trans-unit id="ea9731eda0e95dda5e1d21e3e28bb04a4dfc415c" translate="yes" xml:space="preserve">
          <source>To use the full dataset, set a dataset &lt;code&gt;root&lt;/code&gt; directory</source>
          <target state="translated">完全なデータセットを使用するには、データセットの &lt;code&gt;root&lt;/code&gt; ディレクトリを設定します</target>
        </trans-unit>
        <trans-unit id="79adadec10484e80d3f5b6c83e9b25779b6d8976" translate="yes" xml:space="preserve">
          <source>Tracks properties</source>
          <target state="translated">プロパティを追跡する</target>
        </trans-unit>
        <trans-unit id="32815e2e57b9b4822b6c51f7ef4021db020cc173" translate="yes" xml:space="preserve">
          <source>Training Deep Neural Networks with &lt;code&gt;musdb&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;musdb&lt;/code&gt; を使用したディープニューラルネットワークのトレーニング</target>
        </trans-unit>
        <trans-unit id="0bb18642b70b9f8a9c12ccf39487328f306b8e19" translate="yes" xml:space="preserve">
          <source>Usage</source>
          <target state="translated">使用方法</target>
        </trans-unit>
        <trans-unit id="eed450cf1db8d13dbd7fc62ae850160bb45c4bdf" translate="yes" xml:space="preserve">
          <source>Use train / validation split</source>
          <target state="translated">トレーニング/検証スプリットを使用します。</target>
        </trans-unit>
        <trans-unit id="ac68f0a7761ade25c5abaadd56f1ede023f14135" translate="yes" xml:space="preserve">
          <source>Using STEMs (Default)</source>
          <target state="translated">STEMsの使用(デフォルト</target>
        </trans-unit>
        <trans-unit id="f9cc14cd4eeb07f9364dc314ab41688001f7bb4f" translate="yes" xml:space="preserve">
          <source>Using WAV files (Optional)</source>
          <target state="translated">WAVファイルの使用(オプション</target>
        </trans-unit>
        <trans-unit id="2a8773c12df6590465cdd18bf29b6de11cc247cf" translate="yes" xml:space="preserve">
          <source>We provide a state-of-the-art deep learning based separation method for PyTorch, Tensorflow and NNable at &lt;a href=&quot;https://open.unmix.app&quot;&gt;open.unmix.app&lt;/a&gt;.</source>
          <target state="translated">open.unmix.appで、PyTorch、Tensorflow、NNableの最先端のディープラーニングベースの分離方法を提供してい&lt;a href=&quot;https://open.unmix.app&quot;&gt;ます&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="6d5193e3e0fea752a8d31ef41a4bb6187afbf501" translate="yes" xml:space="preserve">
          <source>We provide subsets for &lt;em&gt;train&lt;/em&gt; and &lt;em&gt;test&lt;/em&gt; for machine learning methods:</source>
          <target state="translated">機械学習手法の&lt;em&gt;トレーニング&lt;/em&gt;と&lt;em&gt;テストの&lt;/em&gt;サブセットを提供します。</target>
        </trans-unit>
        <trans-unit id="0dcca236bff78f18ea9af962b822381d3b2ac79c" translate="yes" xml:space="preserve">
          <source>Writing an efficient dataset generator varies across different deep learning frameworks. A very simple n&amp;auml;ive generator that</source>
          <target state="translated">効率的なデータセットジェネレータの作成は、ディープラーニングフレームワークによって異なります。非常にシンプルなナイーブジェネレーター</target>
        </trans-unit>
        <trans-unit id="dc1d3adf282845429dfa1766e857fcd094739ae2" translate="yes" xml:space="preserve">
          <source>You can install &lt;code&gt;musdb&lt;/code&gt; using pip:</source>
          <target state="translated">pipを使用して &lt;code&gt;musdb&lt;/code&gt; をインストールできます。</target>
        </trans-unit>
        <trans-unit id="3614cadabe7bed2983c8e8197272251e585a99f5" translate="yes" xml:space="preserve">
          <source>can be easily implemented using musdb's &lt;code&gt;track.chunk_start&lt;/code&gt; and &lt;code&gt;track.chunk_duration&lt;/code&gt; properties which efficiently seeks to the start sample (provided in seconds) and does not load the full audio into memory first.</source>
          <target state="translated">musdbの &lt;code&gt;track.chunk_start&lt;/code&gt; プロパティと &lt;code&gt;track.chunk_duration&lt;/code&gt; プロパティを使用して簡単に実装できます。これらのプロパティは、サンプルの開始を効率的にシークし（秒単位で提供）、最初にオーディオ全体をメモリにロードしません。</target>
        </trans-unit>
        <trans-unit id="6deb4a1ffc62a2033bb57af15982810cab577408" translate="yes" xml:space="preserve">
          <source>draws random chunks of fixed length with replacement</source>
          <target state="translated">固定長のランダムなチャンクを置換して描画します。</target>
        </trans-unit>
        <trans-unit id="9183d0bd96f204b0c69dc98e8bf6007f280b56b3" translate="yes" xml:space="preserve">
          <source>draws random tracks with replacement</source>
          <target state="translated">置換されたランダムなトラックを描画します。</target>
        </trans-unit>
        <trans-unit id="c1207f9aa701dc5352980de4ce83b67a41b3ec7a" translate="yes" xml:space="preserve">
          <source>musdb</source>
          <target state="translated">麝香嚢</target>
        </trans-unit>
        <trans-unit id="29c454a4fe227f88ac6da74e1e1eed3a2ddea509" translate="yes" xml:space="preserve">
          <source>on Ubuntu/Debian: &lt;code&gt;sudo apt-get install ffmpeg&lt;/code&gt;</source>
          <target state="translated">Ubuntu / Debianの場合： &lt;code&gt;sudo apt-get install ffmpeg&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="eaf87315e2ddc76ec1da180c3941e6ecadeb8340" translate="yes" xml:space="preserve">
          <source>on macOS, using homebrew: &lt;code&gt;brew install ffmpeg&lt;/code&gt;</source>
          <target state="translated">macOSで、homebrewを使用： &lt;code&gt;brew install ffmpeg&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="45e057342e222276bab1adc7d9088a6b7b29b3bc" translate="yes" xml:space="preserve">
          <source>where &lt;code&gt;root&lt;/code&gt; is the path to the MUSDB18 dataset root folder. The root parameter can also be overridden using a system environment variable. Just &lt;code&gt;export MUSDB_PATH=/path/to/musdb&lt;/code&gt; inside your bash environment. In that case no arguments would need to passed to &lt;code&gt;DB()&lt;/code&gt;.</source>
          <target state="translated">ここで、 &lt;code&gt;root&lt;/code&gt; はMUSDB18データセットのルートフォルダーへのパスです。ルートパラメータは、システム環境変数を使用して上書きすることもできます。bash環境内に &lt;code&gt;export MUSDB_PATH=/path/to/musdb&lt;/code&gt; だけです。その場合、引数を &lt;code&gt;DB()&lt;/code&gt; に渡す必要はありません。</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
