<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ja" datatype="htmlbody" original="https://pypi.org/project/explainerdashboard/">
    <body>
      <group id="explainerdashboard">
        <trans-unit id="9ee5d8eb55b415d7876a91d8495d6c15e33492f6" translate="yes" xml:space="preserve">
          <source>A deployed example can be found at &lt;a href=&quot;http://titanicexplainer.herokuapp.com&quot;&gt;http://titanicexplainer.herokuapp.com&lt;/a&gt;</source>
          <target state="translated">展開された例は&lt;a href=&quot;http://titanicexplainer.herokuapp.com&quot;&gt;http://titanicexplainer.herokuapp.com&lt;/a&gt;で見つけることができます</target>
        </trans-unit>
        <trans-unit id="9872150fbb680cdfd6947cd74baf88cda51c21b5" translate="yes" xml:space="preserve">
          <source>Alternatively, there is a built-in standard dashboard with pre-built tabs that
you can select individually.</source>
          <target state="translated">あるいは、個別に選択できるように、あらかじめ構築されたタブを備えた標準ダッシュボードが組み込まれています。</target>
        </trans-unit>
        <trans-unit id="1e2438e36f54d0a04883ce24b50410159bbd4e8f" translate="yes" xml:space="preserve">
          <source>Explain the inner workings of the model to the people working with so</source>
          <target state="translated">モデルの内部構造を一緒に働いている人に説明してください。</target>
        </trans-unit>
        <trans-unit id="956570964781b8f14ba6fd79bdff8eb328fb4a2b" translate="yes" xml:space="preserve">
          <source>For Random Forests: what is the prediction of each individual decision</source>
          <target state="translated">ランダムフォレストの場合:個々の判断の予測は?</target>
        </trans-unit>
        <trans-unit id="439a0ee1bffc7d1c05880dacabeb8be72a661d71" translate="yes" xml:space="preserve">
          <source>For regression models: goodness-of-fit plots, residual plots, etc.</source>
          <target state="translated">回帰モデルの場合:適合度プロット、残差プロットなど</target>
        </trans-unit>
        <trans-unit id="0840799b642e4c33daacc261de664ec05f7d0de5" translate="yes" xml:space="preserve">
          <source>In a lot of organizations, especially governmental, but with the GDPR also
increasingly in private sector, it becomes more and more important to be able
to explain the inner workings of your machine learning algorithms. Customers
have to some extent a right to an explanation why they were selected, and
more and more internal and external regulators require it. With recent
innovations in explainable AI (e.g. SHAP values) the old black box trope is
no longer valid, but it can still take quite a bit of data wrangling and
plot manipulation to get the explanations out of a model. This library aims
to make this easy.</source>
          <target state="translated">多くの組織、特に政府機関では、GDPRが民間企業にも浸透してきているため、機械学習アルゴリズムの内部の仕組みを説明できることがますます重要になってきています。顧客には、自分が選ばれた理由を説明する権利がある程度あり、社内外の規制当局がそれを要求するケースが増えています。説明可能なAI(SHAP値など)の最近の技術革新により、昔のブラックボックスの話はもはや有効ではありませんが、モデルから説明を引き出すには、データの処理やプロットの操作がかなり必要になります。このライブラリはこれを簡単にすることを目的としています。</target>
        </trans-unit>
        <trans-unit id="ce70797edf8dee737cfb7d76d179588ccb732ee5" translate="yes" xml:space="preserve">
          <source>Make it easy for data scientists to quickly inspect the workings and</source>
          <target state="translated">データサイエンティストが迅速に動作を検査できるようにして</target>
        </trans-unit>
        <trans-unit id="e0e6a091c7b6b769e7751965cef6e0f580e21c3b" translate="yes" xml:space="preserve">
          <source>Make it easy to build an application that explains individual predictions</source>
          <target state="translated">個別の予測を説明するアプリケーションを簡単に構築できるようにする</target>
        </trans-unit>
        <trans-unit id="570657f59b22d6c0e862f61913d54708b8a28a8f" translate="yes" xml:space="preserve">
          <source>Make it possible for non data scientist stakeholders such as managers,</source>
          <target state="translated">管理者などのデータサイエンティスト以外の利害関係者が利用できるようにする。</target>
        </trans-unit>
        <trans-unit id="26b432362191b52a44d047ecf7c47f023a7e0b68" translate="yes" xml:space="preserve">
          <source>PR AUC plot, etc</source>
          <target state="translated">PR AUCプロットなど</target>
        </trans-unit>
        <trans-unit id="a99149c1cddd52e5211d6269453b62dcedc91914" translate="yes" xml:space="preserve">
          <source>Partial dependence plots (how does the model prediction change when</source>
          <target state="translated">部分依存性プロット(以下の場合、モデル予測はどのように変化するか?</target>
        </trans-unit>
        <trans-unit id="9637e7845e9550750cca9ca1769f730b707e2044" translate="yes" xml:space="preserve">
          <source>Permutation importances (how much does the model metric deteriorate</source>
          <target state="translated">順列インポータンス(モデルメトリックがどの程度劣化するか</target>
        </trans-unit>
        <trans-unit id="843579748436cadd9bdbfc0627b8628600453fd3" translate="yes" xml:space="preserve">
          <source>Plus for classifiers: precision plots, confusion matrix, ROC AUC plot,</source>
          <target state="translated">分類器のためのプラス:精度プロット,混同行列,ROC AUC プロット.</target>
        </trans-unit>
        <trans-unit id="f8457b04b23a18252f07b47186dea82e93d4952f" translate="yes" xml:space="preserve">
          <source>Shap interaction values (decompose the shap value into a direct effect</source>
          <target state="translated">シャップ相互作用値(シャップ値を直接効果に分解する</target>
        </trans-unit>
        <trans-unit id="66164421febfee5d4fb5cce72e46352a0b6daeac" translate="yes" xml:space="preserve">
          <source>Shap values (i.e. what is the contributions of each feature to each</source>
          <target state="translated">シャップ値(すなわち、それぞれの特徴がそれぞれの</target>
        </trans-unit>
        <trans-unit id="95ae1c4807c1613b9c7e6ecad1a2de74453f8cd2" translate="yes" xml:space="preserve">
          <source>The goal is manyfold:</source>
          <target state="translated">目的は何重にもあります。</target>
        </trans-unit>
        <trans-unit id="a073373f8b7010ecf9cc4a55639741bd18e0cc97" translate="yes" xml:space="preserve">
          <source>The library includes:</source>
          <target state="translated">ライブラリーには、以下のようなものがあります。</target>
        </trans-unit>
        <trans-unit id="b49daba3b2e4c5bc171af30c431b3af215eb8c35" translate="yes" xml:space="preserve">
          <source>The library is designed to be modular so that it should be easy to design your
own interactive dashboards with plotly dash, with most of the work of calculating
and formatting data, and rendering plots and tables handled by explainerdashboard,
so that you can focus on the layout, logic of the interactions, and project specific
textual explanations of the dashboard. (i.e. design it so that it will be interpretable
for business users in your organization, not just data scientists)</source>
          <target state="translated">このライブラリはモジュール式に設計されているので、plotly dashを使ってインタラクティブなダッシュボードを簡単に設計することができ、データの計算やフォーマット、プロットや表のレンダリングのほとんどの作業はexplanationerdashboardで処理されます。(つまり、データサイエンティストだけでなく、組織内のビジネス・ユーザにも解釈可能なように設計してください)</target>
        </trans-unit>
        <trans-unit id="801688a2692f1470827e8312cc9124f7845acbd4" translate="yes" xml:space="preserve">
          <source>This package makes it convenient to quickly explain the workings of a
(scikit-learn compatible) fitted machine learning model using either
interactive plots in e.g. Jupyter Notebook or deploying an interactive
dashboard (based on Flask/Dash) that allows you to quickly explore the
impact of different features on model predictions.</source>
          <target state="translated">本パッケージは、(scikit-learnと互換性のある)適合した機械学習モデルの動作を、Jupyter Notebookのようなインタラクティブなプロットや、モデルの予測に対するさまざまな特徴の影響を素早く調べることができるインタラクティブなダッシュボード(Flask/Dashをベースにした)を使って素早く説明することを便利にします。</target>
        </trans-unit>
        <trans-unit id="0a2fc32ddada3ac82b829f04fe929cc613f1ba0c" translate="yes" xml:space="preserve">
          <source>an interaction effects)</source>
          <target state="translated">相互作用効果)</target>
        </trans-unit>
        <trans-unit id="2519d4d3082fac70ef6fc6c7c10a9214f9da3bc3" translate="yes" xml:space="preserve">
          <source>directors, internal and external watchdogs to interactively inspect
the inner workings of the model without having to depend on a data
scientist to generate every plot and table</source>
          <target state="translated">データサイエンティストに頼らなくても、すべてのプロットや表を生成することなく、取締役、社内外の監視役がモデルの内部をインタラクティブに検査することができます。</target>
        </trans-unit>
        <trans-unit id="e79a6ae0690566db6288e82ba34ad824fede5564" translate="yes" xml:space="preserve">
          <source>explainerdashboard allows you quickly build an interactive dashboard to explain the inner workings of your machine learning model.</source>
          <target state="translated">explainerdashboardを使用すると、機械学習モデルの内部の仕組みを説明するためのインタラクティブなダッシュボードを素早く構築することができます。</target>
        </trans-unit>
        <trans-unit id="06637564d86372e96635657c4d3a6a6b04414b21" translate="yes" xml:space="preserve">
          <source>individual prediction?)</source>
          <target state="translated">個別予測?)</target>
        </trans-unit>
        <trans-unit id="864162c093c84b184f0ca4e126505c4ec91bd7d6" translate="yes" xml:space="preserve">
          <source>of your model for customers that ask for an explanation</source>
          <target state="translated">説明を求めてくるお客様のために、あなたのモデルの</target>
        </trans-unit>
        <trans-unit id="bf2baac207e13e27a5e50f7eb16658b606b09dcd" translate="yes" xml:space="preserve">
          <source>performance of their model in a few lines of code</source>
          <target state="translated">数行のコードでモデルのパフォーマンスを向上させる</target>
        </trans-unit>
        <trans-unit id="e635decc0d3aa6cc070cde811548286b8ecde7f9" translate="yes" xml:space="preserve">
          <source>that they gain understanding what the model does and doesn&amp;rsquo;t do.
This is important so that they can gain an intuition for when the
model is likely missing information and may have to be overruled.</source>
          <target state="translated">モデルが何をし、何をしないかを理解すること。これは、モデルに情報が不足している可能性が高く、却下する必要がある場合に直感的に理解できるようにするために重要です。</target>
        </trans-unit>
        <trans-unit id="20d4dbe97dffb8e65303926fe068f0e9a21eaee7" translate="yes" xml:space="preserve">
          <source>tree, and what is the path through each tree? (using dtreeviz)</source>
          <target state="translated">のように、それぞれの木を通るパスを教えてください。(dtreevizを使用して)</target>
        </trans-unit>
        <trans-unit id="122aeb029a33af06f90e4f9c3d3eaf2783480525" translate="yes" xml:space="preserve">
          <source>when you shuffle a feature?)</source>
          <target state="translated">機能をシャッフルするとき?)</target>
        </trans-unit>
        <trans-unit id="89b99cece506de81c6e01cf826280cdffec7642d" translate="yes" xml:space="preserve">
          <source>you vary a single feature?</source>
          <target state="translated">あなたは単一の機能を変化させますか?</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
