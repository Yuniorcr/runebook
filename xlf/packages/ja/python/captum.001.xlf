<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ja" datatype="htmlbody" original="https://pypi.org/project/captum/">
    <body>
      <group id="captum">
        <trans-unit id="7e224d6675fc514ea7defb9516638683fceb2bcc" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Deconvolution&lt;/code&gt;, &lt;code&gt;Neuron Deconvolution&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1311.2901.pdf&quot;&gt;Visualizing and Understanding Convolutional Networks, Matthew D Zeiler et al. 2014&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Deconvolution&lt;/code&gt; 、 &lt;code&gt;Neuron Deconvolution&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/pdf/1311.2901.pdf&quot;&gt;畳み込みネットワークの視覚化と理解、マシューDザイラー他 2014年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f77c45466355b115b010aa83e3ec5115e53cc011" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;DeepLift&lt;/code&gt; assigns similar attribution scores as &lt;code&gt;IntegratedGradients&lt;/code&gt; to inputs,
however it has lower execution time. Another important thing to remember about
DeepLift is that it currently doesn't support all non-linear activation types.
For more details on limitations of the current implementation, please see the
&lt;a href=&quot;https://arxiv.org/abs/1704.02685&quot;&gt;DeepLift paper&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;DeepLift&lt;/code&gt; は &lt;code&gt;IntegratedGradients&lt;/code&gt; と同様の属性スコアを入力に割り当てますが、実行時間は短くなります。DeepLiftについて覚えておかなければならないもう1つの重要な点は、現在、すべての非線形アクティベーションタイプをサポートしているわけではないということです。現在の実装の制限の詳細については、&lt;a href=&quot;https://arxiv.org/abs/1704.02685&quot;&gt;DeepLiftペーパー&lt;/a&gt;を参照してください 。</target>
        </trans-unit>
        <trans-unit id="35d8eea45bfc985cc4e9ed2b9f13dcc77a172786" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;DeepLift&lt;/code&gt;, &lt;code&gt;NeuronDeepLift&lt;/code&gt;, &lt;code&gt;LayerDeepLift&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1704.02685.pdf&quot;&gt;Learning Important Features Through Propagating Activation Differences, Avanti Shrikumar et al. 2017&lt;/a&gt; and &lt;a href=&quot;https://openreview.net/pdf?id=Sy21R9JAW&quot;&gt;Towards better understanding of gradient-based attribution methods for deep neural networks, Marco Ancona et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;DeepLift&lt;/code&gt; 、 &lt;code&gt;NeuronDeepLift&lt;/code&gt; 、 &lt;code&gt;LayerDeepLift&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/pdf/1704.02685.pdf&quot;&gt;アクティブ化の違いを伝播することで重要な機能を学習する、Avanti Shrikumarなど。2017年&lt;/a&gt;および&lt;a href=&quot;https://openreview.net/pdf?id=Sy21R9JAW&quot;&gt;ディープニューラルネットワークの勾配ベースのアトリビューション手法のより良い理解に向けて、Marco Ancona et al。2018年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0935b98602a2196eb3ce841148929580db331f26" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;DeepLiftShap&lt;/code&gt; uses &lt;code&gt;DeepLift&lt;/code&gt; to compute attribution score for each
input-baseline pair and averages it for each input across all baselines.</source>
          <target state="translated">&lt;code&gt;DeepLiftShap&lt;/code&gt; は、 &lt;code&gt;DeepLift&lt;/code&gt; を使用して各入力ベースラインペアのアトリビューションスコアを計算し、すべてのベースラインにわたって入力ごとに平均化します。</target>
        </trans-unit>
        <trans-unit id="70f4204e74fbab884413f100ee93ebc43bf69602" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Feature Permutation&lt;/code&gt;: &lt;a href=&quot;https://christophm.github.io/interpretable-ml-book/feature-importance.html&quot;&gt;Permutation Feature Importance&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Feature Permutation&lt;/code&gt; ：&lt;a href=&quot;https://christophm.github.io/interpretable-ml-book/feature-importance.html&quot;&gt;順列特徴の重要性&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="dfd45f4166b5d1094537f54fcf044b34d5f360af" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;GradCAM&lt;/code&gt;, &lt;code&gt;Guided GradCAM&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1610.02391.pdf&quot;&gt;Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization, Ramprasaath R. Selvaraju et al. 2017&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;GradCAM&lt;/code&gt; 、 &lt;code&gt;Guided GradCAM&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/abs/1610.02391.pdf&quot;&gt;Grad-CAM：勾配ベースのローカリゼーションによるディープネットワークからの視覚的説明、Ramprasaath R. Selvaraju et al。2017年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9c73c2db449b0b144f4acb50ee0a1570caed5366" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;GradientShap&lt;/code&gt; first chooses a random baseline from baselines' distribution, then
adds gaussian noise with std=0.09 to each input example &lt;code&gt;n_samples&lt;/code&gt; times.
Afterwards, it chooses a random point between each example-baseline pair and
computes the gradients with respect to target class (in this case target=0). Resulting
attribution is the mean of gradients * (inputs - baselines)</source>
          <target state="translated">&lt;code&gt;GradientShap&lt;/code&gt; は最初にベースラインの分布からランダムなベースラインを選択し、次に各入力例に &lt;code&gt;n_samples&lt;/code&gt; 回std = 0.09のガウスノイズを追加します。その後、各例とベースラインのペアの間でランダムなポイントを選択し、ターゲットクラス（この場合はtarget = 0）に関する勾配を計算します。結果の属性は、勾配の平均値*（​​入力-ベースライン）</target>
        </trans-unit>
        <trans-unit id="745f47441809340b71cc76401a089bf5ad757fd9" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;GradientShap&lt;/code&gt;, &lt;code&gt;NeuronGradientShap&lt;/code&gt;, &lt;code&gt;LayerGradientShap&lt;/code&gt;, &lt;code&gt;DeepLiftShap&lt;/code&gt;, &lt;code&gt;NeuronDeepLiftShap&lt;/code&gt;, &lt;code&gt;LayerDeepLiftShap&lt;/code&gt;: &lt;a href=&quot;http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions&quot;&gt;A Unified Approach to Interpreting Model Predictions, Scott M. Lundberg et al. 2017&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;GradientShap&lt;/code&gt; 、 &lt;code&gt;NeuronGradientShap&lt;/code&gt; 、 &lt;code&gt;LayerGradientShap&lt;/code&gt; 、 &lt;code&gt;DeepLiftShap&lt;/code&gt; 、 &lt;code&gt;NeuronDeepLiftShap&lt;/code&gt; 、 &lt;code&gt;LayerDeepLiftShap&lt;/code&gt; ：&lt;a href=&quot;http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions&quot;&gt;モデル予測を解釈するための統合アプローチ、スコットM.ルンドバーグほか 2017年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="602dfc33d8aba3857725b949b893d500e50a678d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Guided Backpropagation&lt;/code&gt;, &lt;code&gt;Neuron Guided Backpropagation&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1412.6806.pdf&quot;&gt;Striving for Simplicity: The All Convolutional Net, Jost Tobias Springenberg et al. 2015&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Guided Backpropagation&lt;/code&gt; 、 &lt;code&gt;Neuron Guided Backpropagation&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/pdf/1412.6806.pdf&quot;&gt;シンプルさの&lt;/a&gt;追求：全畳み込みネット、Jost Tobias Springenberg et al。2015年</target>
        </trans-unit>
        <trans-unit id="32d5dd2bb7640e2b606a6084f2cafa2a031b478b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;InputXGradient&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1611.07270&quot;&gt;Investigating the influence of noise and distractors on the interpretation of neural networks, Pieter-Jan Kindermans et al. 2016&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;InputXGradient&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/abs/1611.07270&quot;&gt;ニューラルネットワークの解釈に対するノイズとディス&lt;/a&gt;トラクタの影響の調査、Pieter-Jan Kindermans et al。2016年</target>
        </trans-unit>
        <trans-unit id="b69ede686e5d4e904dbf0247c2f663ff896f0a0c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;IntegratedGradients&lt;/code&gt;, &lt;code&gt;LayerIntegratedGradients&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1703.01365&quot;&gt;Axiomatic Attribution for Deep Networks, Mukund Sundararajan et al. 2017&lt;/a&gt; and &lt;a href=&quot;https://arxiv.org/abs/1805.05492&quot;&gt;Did the Model Understand the Question?, Pramod K. Mudrakarta, et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;IntegratedGradients&lt;/code&gt; 、 &lt;code&gt;LayerIntegratedGradients&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/abs/1703.01365&quot;&gt;ディープネットワークの公理的帰属、Mukund Sundararajanなど。2017年&lt;/a&gt;と&lt;a href=&quot;https://arxiv.org/abs/1805.05492&quot;&gt;モデルは質問を理解しましたか？、Pramod K. Mudrakarta、他 2018年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1ce041e0904e2eb6fe9e166ae16f4a94c041216f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;InternalInfluence&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1802.03788.pdf&quot;&gt;Influence-Directed Explanations for Deep Convolutional Networks, Klas Leino et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;InternalInfluence&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/pdf/1802.03788.pdf&quot;&gt;ディープたたみ込みネットワークの影響指向の説明、Klas Leino et al。2018年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6464d80d482910b859e98e94be43a85d78c92fff" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;LayerConductance&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1807.09946.pdf&quot;&gt;Computationally Efficient Measures of Internal Neuron Importance, Avanti Shrikumar et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;LayerConductance&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/pdf/1807.09946.pdf&quot;&gt;内部ニューロンの重要性の計算上効率的な測定、Avanti Shrikumar et al。2018年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a390e01ea3142478285f0168a9d0220de3b869e1" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;NeuronConductance&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1805.12233&quot;&gt;How Important is a neuron?, Kedar Dhamdhere et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;NeuronConductance&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/abs/1805.12233&quot;&gt;ニューロンはどれほど重要ですか？、Kedar Dhamdhere et al。2018年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7fa53a48f5e924963274d272e5ae392af89f2c41" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;NeuronIntegratedGradients&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1807.09946.pdf&quot;&gt;Computationally Efficient Measures of Internal Neuron Importance, Avanti Shrikumar et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;NeuronIntegratedGradients&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/pdf/1807.09946.pdf&quot;&gt;内部ニューロンの重要性の計算上効率的な測定、Avanti Shrikumar et al。2018年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3406337d51997da5374b792bb810c3069f71f625" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;NoiseTunnel&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1810.03292&quot;&gt;Sanity Checks for Saliency Maps, Julius Adebayo et al. 2018&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;NoiseTunnel&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/abs/1810.03292&quot;&gt;顕著性マップのサニティチェック、Julius Adebayo他 2018年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="180de40fda30abd90e30c91da063de517cd65e10" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Occlusion&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1311.2901&quot;&gt;Visualizing and Understanding Convolutional Networks&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Occlusion&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/abs/1311.2901&quot;&gt;畳み込みネットワークの視覚化と理解&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="ef3e53fd11ec0ec42f34212a68a5a8f640a980a4" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Saliency&lt;/code&gt;, &lt;code&gt;NeuronGradient&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/pdf/1312.6034.pdf&quot;&gt;Deep Inside Convolutional Networks: Visualising
Image Classification Models and Saliency Maps, K. Simonyan, et. al. 2014&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Saliency&lt;/code&gt; 、 &lt;code&gt;NeuronGradient&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/pdf/1312.6034.pdf&quot;&gt;ディープインサイド畳み込みネットワーク：可視画像分類モデルと突極マップ、K. Simonyan、ら。al。2014年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d72716650eca9202bde62762d848353fd9f89e55" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Shapely Value Sampling&lt;/code&gt;: &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0305054808000804&quot;&gt;Polynomial calculation of the Shapley value based on sampling&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Shapely Value Sampling&lt;/code&gt; ：&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0305054808000804&quot;&gt;サンプリングに基づくShapley値の多項式計算&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2f313a5b98f914e2d22e3666af676c317da1a76c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Shapely Value&lt;/code&gt;: &lt;a href=&quot;https://apps.dtic.mil/dtic/tr/fulltext/u2/604084.pdf&quot;&gt;A value for n-person games. Contributions to the Theory of Games 2.28 (1953): 307-317&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;Shapely Value&lt;/code&gt; ：&lt;a href=&quot;https://apps.dtic.mil/dtic/tr/fulltext/u2/604084.pdf&quot;&gt;n人ゲームの値。ゲーム理論2.28（1953）への貢献：307-317&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="cc62bf28a6aaadab7c58506486d1282344c4f152" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;SmoothGrad&lt;/code&gt;: &lt;a href=&quot;https://arxiv.org/abs/1706.03825&quot;&gt;SmoothGrad: removing noise by adding noise, Daniel Smilkov et al. 2017&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;SmoothGrad&lt;/code&gt; ：&lt;a href=&quot;https://arxiv.org/abs/1706.03825&quot;&gt;SmoothGrad：ノイズを追加してノイズを除去する、Daniel Smilkovなど。2017年&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="97d9a83b33d1a1e1468782cbf91b17ba820547f9" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;pip install -e .[dev]&lt;/code&gt;: Also installs all tools necessary for development
(testing, linting, docs building; see &lt;a href=&quot;#contributing&quot;&gt;Contributing&lt;/a&gt; below).</source>
          <target state="translated">&lt;code&gt;pip install -e .[dev]&lt;/code&gt; ：開発に必要なすべてのツールもインストールします（テスト、リンティング、ドキュメントの構築。以下の&lt;a href=&quot;#contributing&quot;&gt;貢献を&lt;/a&gt;参照）。</target>
        </trans-unit>
        <trans-unit id="5d7c7835d367a7e4679627572238c42726e0601e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;pip install -e .[insights]&lt;/code&gt;: Also installs all packages necessary for running Captum Insights.</source>
          <target state="translated">&lt;code&gt;pip install -e .[insights]&lt;/code&gt; insights ]：Captum Insightsの実行に必要なすべてのパッケージもインストールします。</target>
        </trans-unit>
        <trans-unit id="d5bb8d5b6fa5ab568327e9ea794621e7ee38d45f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;pip install -e .[tutorials]&lt;/code&gt;: Also installs all packages necessary for running the tutorial notebooks.</source>
          <target state="translated">&lt;code&gt;pip install -e .[tutorials]&lt;/code&gt; ：チュートリアルノートブックの実行に必要なすべてのパッケージもインストールします。</target>
        </trans-unit>
        <trans-unit id="c641fcc1b80e58fb730b1652c8b6c7fc9b227fd8" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;Captum is currently in beta and under active development!&lt;/em&gt;</source>
          <target state="translated">&lt;em&gt;Captumは現在ベータ版で、活発に開発中です！&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="6897acde3a3c220a635980f413f5941e5fc0a6b4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Installation Requirements&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;インストール要件&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="2208733c3a7ee98009723d2713bcd61e00a43c9c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Manual / Dev install&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;手動/開発インストール&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="c3f76124c7fa391369fe5c7fb44c51cf9d1ed726" translate="yes" xml:space="preserve">
          <source>About Captum</source>
          <target state="translated">キャプタムについて</target>
        </trans-unit>
        <trans-unit id="d8c0847ea163dcd16d6f2a889df7dce1e95c7176" translate="yes" xml:space="preserve">
          <source>Below is an example of how we can apply &lt;code&gt;DeepLift&lt;/code&gt; and &lt;code&gt;DeepLiftShap&lt;/code&gt; on the
&lt;code&gt;ToyModel&lt;/code&gt; described above. Current implementation of DeepLift supports only
&lt;code&gt;Rescale&lt;/code&gt; rule.
For more details on alternative implementations, please see the &lt;a href=&quot;https://arxiv.org/abs/1704.02685&quot;&gt;DeepLift paper&lt;/a&gt;.</source>
          <target state="translated">以下は、私たちが適用する方法の一例である &lt;code&gt;DeepLift&lt;/code&gt; と &lt;code&gt;DeepLiftShap&lt;/code&gt; を上 &lt;code&gt;ToyModel&lt;/code&gt; 前述。DeepLiftの現在の実装では、 &lt;code&gt;Rescale&lt;/code&gt; ルールのみがサポートされてい ます。代替実装の詳細については、&lt;a href=&quot;https://arxiv.org/abs/1704.02685&quot;&gt;DeepLiftペーパー&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="021481ec74cf7f851fd8bb8de29f48519b026a55" translate="yes" xml:space="preserve">
          <source>Captum Insights</source>
          <target state="translated">キャプタムインサイト</target>
        </trans-unit>
        <trans-unit id="b5e6347c0220e027a895cf1796661a4eca041832" translate="yes" xml:space="preserve">
          <source>Captum Insights Jupyter Widget</source>
          <target state="translated">Captum Insights Jupyter ウィジェット</target>
        </trans-unit>
        <trans-unit id="50ea9b39e0ca2b1e147f71e19c8284e932f29b95" translate="yes" xml:space="preserve">
          <source>Captum Insights also has a Jupyter widget providing the same user interface as the web app.
To install and enable the widget, run</source>
          <target state="translated">Captum Insights には、Web アプリと同じユーザーインターフェースを提供する Jupyter ウィジェットもあります。ウィジェットをインストールして有効にするには</target>
        </trans-unit>
        <trans-unit id="2284f9438ef0b1f48a107c6a47037d5562ef7a07" translate="yes" xml:space="preserve">
          <source>Captum can also be used by application engineers who are using trained models in production. Captum provides easier troubleshooting through improved model interpretability, and the potential for delivering better explanations to end users on why they&amp;rsquo;re seeing a specific piece of content, such as a movie recommendation.</source>
          <target state="translated">Captumは、本番環境でトレーニング済みモデルを使用しているアプリケーションエンジニアも使用できます。Captumは、モデルの解釈性を改善することでトラブルシューティングを容易にし、映画のおすすめなど、特定のコンテンツが表示される理由についてエンドユーザーに適切な説明を提供する可能性を提供します。</target>
        </trans-unit>
        <trans-unit id="e072252aa5db22cac92d10e2402e5669eae223d4" translate="yes" xml:space="preserve">
          <source>Captum helps ML researchers more easily implement interpretability algorithms that can interact with PyTorch models. Captum also allows researchers to quickly benchmark their work against other existing algorithms available in the library.</source>
          <target state="translated">Captumは、ML研究者がPyTorchモデルと相互作用する解釈可能性アルゴリズムをより簡単に実装できるようにします。また、Captumは、ライブラリ内の他の既存のアルゴリズムと比較して、研究者が自分の研究を迅速にベンチマークすることを可能にします。</target>
        </trans-unit>
        <trans-unit id="d26bdb66327c68c373a8e184aae92f50105b84ad" translate="yes" xml:space="preserve">
          <source>Captum helps you interpret and understand predictions of PyTorch models by
exploring features that contribute to a prediction the model makes.
It also helps understand which neurons and layers are important for
model predictions.</source>
          <target state="translated">Captumは、モデルが行う予測に寄与する特徴を探索することで、PyTorchモデルの予測を解釈し、理解するのに役立ちます。また、モデルの予測に重要なニューロンやレイヤーを理解するのに役立ちます。</target>
        </trans-unit>
        <trans-unit id="48db440dde81207b626929193aa5ff14516a272f" translate="yes" xml:space="preserve">
          <source>Captum is BSD licensed, as found in the &lt;a href=&quot;LICENSE&quot;&gt;LICENSE&lt;/a&gt; file.</source>
          <target state="translated">Captumは&lt;a href=&quot;LICENSE&quot;&gt;LICENSE&lt;/a&gt;ファイルにあるように、BSDライセンスです。</target>
        </trans-unit>
        <trans-unit id="2b556e02df9343beb45e9c79545ddba2410d2664" translate="yes" xml:space="preserve">
          <source>Captum is a model interpretability and understanding library for PyTorch.
Captum means comprehension in latin and contains general purpose implementations
of integrated gradients, saliency maps, smoothgrad, vargrad and others for
PyTorch models. It has quick integration for models built with domain-specific
libraries such as torchvision, torchtext, and others.</source>
          <target state="translated">Captumは、PyTorch用のモデル解釈・理解ライブラリです。Captumはラテン語で理解を意味し、PyTorchモデル用の統合グラディエント、サリエンシーマップ、スムースグラッド、バーグラッドなどの汎用的な実装が含まれています。torchvision,torchtext などのドメイン固有のライブラリを使って構築されたモデルのために迅速に統合されています。</target>
        </trans-unit>
        <trans-unit id="712c9c0dc955ee835f95d4a0c2e34f430fb91038" translate="yes" xml:space="preserve">
          <source>Captum provides a web interface called Insights for easy visualization and
access to a number of our interpretability algorithms.</source>
          <target state="translated">Captumは、インサイトと呼ばれるWebインターフェースを提供しており、簡単に可視化し、当社の解釈可能なアルゴリズムにアクセスすることができます。</target>
        </trans-unit>
        <trans-unit id="2d82a4b27a4b305690d5ac612046a955778a9fa5" translate="yes" xml:space="preserve">
          <source>Contributing</source>
          <target state="translated">貢献</target>
        </trans-unit>
        <trans-unit id="39703b21af9911d0f81c306612570543015fb4da" translate="yes" xml:space="preserve">
          <source>Currently, the library uses gradient-based interpretability algorithms
and attributes contributions to each input of the model with respect to
different neurons and layers, both intermediate and final.</source>
          <target state="translated">現在のところ、このライブラリは勾配ベースの解釈可能アルゴリズムを使用しており、モデルの各入力に対する寄与度を、異なるニューロンと層(中間層と最終層)の両方に関して属性化しています。</target>
        </trans-unit>
        <trans-unit id="90ab72c08753cb3eced44073f94e601929bbf4a1" translate="yes" xml:space="preserve">
          <source>Deltas are computed for each &lt;code&gt;n_samples * input.shape[0]&lt;/code&gt; example. The user can,
for instance, average them:</source>
          <target state="translated">デルタは、 &lt;code&gt;n_samples * input.shape[0]&lt;/code&gt; 例ごとに計算されます。たとえば、ユーザーはそれらを平均化できます。</target>
        </trans-unit>
        <trans-unit id="c6b820410c0912f7db59b8a701baa4c5631073ed" translate="yes" xml:space="preserve">
          <source>For model developers, Captum can be used to improve and troubleshoot models by facilitating the identification of different features that contribute to a model&amp;rsquo;s output in order to design better models and troubleshoot unexpected model outputs.</source>
          <target state="translated">モデル開発者にとって、Captumはモデルの改善とトラブルシューティングに使用でき、モデルの出力に寄与するさまざまな機能の特定を促進して、より優れたモデルを設計し、予期しないモデル出力をトラブルシューティングできます。</target>
        </trans-unit>
        <trans-unit id="010b85ad56b34c34c7c2a3b2436c740e30428ed5" translate="yes" xml:space="preserve">
          <source>Getting Started</source>
          <target state="translated">はじめに</target>
        </trans-unit>
        <trans-unit id="523b5dd24d78e1688f499261e03d11aabe65c0e9" translate="yes" xml:space="preserve">
          <source>Here is an example how we can use &lt;code&gt;NoiseTunnel&lt;/code&gt; with &lt;code&gt;IntegratedGradients&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;IntegratedGradients&lt;/code&gt; で &lt;code&gt;NoiseTunnel&lt;/code&gt; を使用する方法の例を次に示します。</target>
        </trans-unit>
        <trans-unit id="2951f06ff53b46d9157f54d1ddb461c159a670d0" translate="yes" xml:space="preserve">
          <source>If you'd like to try our bleeding edge features (and don't mind potentially
running into the occasional bug here or there), you can install the latest
master directly from GitHub. For a basic install, run:</source>
          <target state="translated">もしあなたが私たちの最先端の機能を試してみたいと思っているのであれば (そして時折バグが発生することを気にしていないのであれば)、GitHub から最新のマスターを直接インストールすることができます。基本的なインストールは以下のように実行してください。</target>
        </trans-unit>
        <trans-unit id="748139302b5f33a6af11cc4d8e2c307feed6a61f" translate="yes" xml:space="preserve">
          <source>In order to smooth and improve the quality of the attributions we can run
&lt;code&gt;IntegratedGradients&lt;/code&gt; and other attribution methods through a &lt;code&gt;NoiseTunnel&lt;/code&gt;.
&lt;code&gt;NoiseTunnel&lt;/code&gt; allows us to use &lt;code&gt;SmoothGrad&lt;/code&gt;, &lt;code&gt;SmoothGrad_Sq&lt;/code&gt; and &lt;code&gt;VarGrad&lt;/code&gt; techniques
to smoothen the attributions by aggregating them for multiple noisy
samples that were generated by adding gaussian noise.</source>
          <target state="translated">アトリビューションの品質を平滑化および改善するために、 &lt;code&gt;NoiseTunnel&lt;/code&gt; を介して &lt;code&gt;IntegratedGradients&lt;/code&gt; およびその他のアトリビューションメソッドを実行できます 。 &lt;code&gt;NoiseTunnel&lt;/code&gt; では、 &lt;code&gt;SmoothGrad&lt;/code&gt; 、 &lt;code&gt;SmoothGrad_Sq&lt;/code&gt; 、 &lt;code&gt;VarGrad&lt;/code&gt; の手法を使用して、ガウスノイズを追加することで生成された複数のノイズの多いサンプルに対して属性を集約することで、属性を平滑化できます。</target>
        </trans-unit>
        <trans-unit id="37e62d8605abf42b9cf777a51788c55a03639d78" translate="yes" xml:space="preserve">
          <source>In this case, we choose to analyze the first neuron in the linear layer.</source>
          <target state="translated">ここでは、線形層の最初のニューロンを解析することにします。</target>
        </trans-unit>
        <trans-unit id="c81b79df3c6448eae7c4f80428b54cd5692a17d7" translate="yes" xml:space="preserve">
          <source>Installation</source>
          <target state="translated">インストール</target>
        </trans-unit>
        <trans-unit id="726495cac31fed46f3681097ea8adbc806081e82" translate="yes" xml:space="preserve">
          <source>Installing the latest release</source>
          <target state="translated">最新リリースのインストール</target>
        </trans-unit>
        <trans-unit id="8e78f6ced3cb3e7a0efd619bef2cccb4fa16b14d" translate="yes" xml:space="preserve">
          <source>It computes deltas for each input example-baseline pair, thus resulting to
&lt;code&gt;input.shape[0] * baseline.shape[0]&lt;/code&gt; delta values.</source>
          <target state="translated">入力例とベースラインのペアごとにデルタを計算し、 &lt;code&gt;input.shape[0] * baseline.shape[0]&lt;/code&gt; delta値を生成します。</target>
        </trans-unit>
        <trans-unit id="a8a7e2465fdc77cafbda6ce7b7d0e3ab7010ee86" translate="yes" xml:space="preserve">
          <source>It doesn't attribute the contribution scores to the input features
but shows the importance of each neuron in selected layer.</source>
          <target state="translated">寄与度スコアを入力特徴量に属性付けるのではなく、選択された層の各ニューロンの重要度を示します。</target>
        </trans-unit>
        <trans-unit id="45f74c2b886455a20211bc6087c7a981cba8b94d" translate="yes" xml:space="preserve">
          <source>Layer conductance shows the importance of neurons for a layer and given input.
It is an extension of path integrated gradients for hidden layers and holds the
completeness property as well.</source>
          <target state="translated">レイヤーコンダクタンスは、あるレイヤーと与えられた入力に対するニューロンの重要性を示します。これは、隠れ層のためのパス積分勾配の拡張であり、完全性の特性も保持しています。</target>
        </trans-unit>
        <trans-unit id="0022de38b637868d1853d6d090cf915fe72c96d8" translate="yes" xml:space="preserve">
          <source>Let's apply some of those algorithms to a toy model we have created for
demonstration purposes.
For simplicity, we will use the following architecture, but users are welcome
to use any PyTorch model of their choice.</source>
          <target state="translated">これらのアルゴリズムのいくつかを、デモンストレーションのために作成したおもちゃのモデルに適用してみましょう。簡単にするために、以下のアーキテクチャを使用しますが、ユーザーは任意のPyTorchモデルを使用することができます。</target>
        </trans-unit>
        <trans-unit id="4369c251b91c938021df6f86e075d0f68a6879d5" translate="yes" xml:space="preserve">
          <source>Let's create an instance of our model and set it to eval mode.</source>
          <target state="translated">モデルのインスタンスを作成してevalモードに設定してみましょう。</target>
        </trans-unit>
        <trans-unit id="b2e5c40eefa02dca2a0399316902a8d9c9094103" translate="yes" xml:space="preserve">
          <source>Let's define our input and baseline tensors. Baselines are used in some
interpretability algorithms such as &lt;code&gt;IntegratedGradients, DeepLift, GradientShap, NeuronConductance, LayerConductance, InternalInfluence&lt;/code&gt; and
&lt;code&gt;NeuronIntegratedGradients&lt;/code&gt;.</source>
          <target state="translated">入力テンソルとベースラインテンソルを定義しましょう。ベースラインは、 &lt;code&gt;IntegratedGradients, DeepLift, GradientShap, NeuronConductance, LayerConductance, InternalInfluence&lt;/code&gt; 、 &lt;code&gt;NeuronIntegratedGradients&lt;/code&gt; などのいくつかの解釈可能性アルゴリズムで使用されます。</target>
        </trans-unit>
        <trans-unit id="a2d21524039206f00133601c7ce2c40fbb2a88ae" translate="yes" xml:space="preserve">
          <source>Let's look into the internals of our network and understand which layers
and neurons are important for the predictions.</source>
          <target state="translated">ネットワークの内部を調べて、どの層やニューロンが予測に重要なのかを理解してみましょう。</target>
        </trans-unit>
        <trans-unit id="3229609e15436ec51bcf00818a69a84dbc58a0c2" translate="yes" xml:space="preserve">
          <source>License</source>
          <target state="translated">ライセンス</target>
        </trans-unit>
        <trans-unit id="7151ecc0dc7a5120377ab85e7d7eac19fe0502d7" translate="yes" xml:space="preserve">
          <source>Model interpretability for PyTorch</source>
          <target state="translated">PyTorch のモデルの解釈性</target>
        </trans-unit>
        <trans-unit id="64a7acecc018b0b76e1070ab8d77465d6f66f86e" translate="yes" xml:space="preserve">
          <source>More details about the above mentioned &lt;a href=&quot;https://captum.ai/docs/algorithms&quot;&gt;algorithms&lt;/a&gt; and their pros and cons can be found on our &lt;a href=&quot;https://captum.ai/docs/algorithms_comparison_matrix&quot;&gt;web-site&lt;/a&gt;.</source>
          <target state="translated">上記の&lt;a href=&quot;https://captum.ai/docs/algorithms&quot;&gt;アルゴリズム&lt;/a&gt;とその長所と短所の詳細については、当社の&lt;a href=&quot;https://captum.ai/docs/algorithms_comparison_matrix&quot;&gt;Webサイトを&lt;/a&gt;ご覧ください。</target>
        </trans-unit>
        <trans-unit id="c798498ab11132e260e2f04e6a25bc1b01a96272" translate="yes" xml:space="preserve">
          <source>More details on the list of supported algorithms and how to apply
Captum on different types of models can be found in our tutorials.</source>
          <target state="translated">サポートされているアルゴリズムのリストや、さまざまなタイプのモデルにCaptumを適用する方法の詳細については、チュートリアルを参照してください。</target>
        </trans-unit>
        <trans-unit id="a809e022bfbd247fdef4e8f92c06639a09f2e709" translate="yes" xml:space="preserve">
          <source>Next we will use &lt;code&gt;IntegratedGradients&lt;/code&gt; algorithms to assign attribution
scores to each input feature with respect to the first target output.</source>
          <target state="translated">次に、 &lt;code&gt;IntegratedGradients&lt;/code&gt; アルゴリズムを使用して、最初のターゲット出力に関して各入力フィーチャに属性スコアを割り当てます。</target>
        </trans-unit>
        <trans-unit id="e345eb5cbc3af8ba96268dc94160be1d607ed174" translate="yes" xml:space="preserve">
          <source>Next, we need to define simple input and baseline tensors.
Baselines belong to the input space and often carry no predictive signal.
Zero tensor can serve as a baseline for many tasks.
Some interpretability algorithms such as &lt;code&gt;Integrated Gradients&lt;/code&gt;, &lt;code&gt;Deeplift&lt;/code&gt; and &lt;code&gt;GradientShap&lt;/code&gt; are designed to attribute the change
between the input and baseline to a predictive class or a value that the neural
network outputs.</source>
          <target state="translated">次に、単純な入力とベースラインテンソルを定義する必要があります。ベースラインは入力空間に属し、多くの場合予測信号を伝達しません。ゼロテンソルは、多くのタスクのベースラインとして機能します。 &lt;code&gt;Integrated Gradients&lt;/code&gt; 、 &lt;code&gt;Deeplift&lt;/code&gt; 、 &lt;code&gt;GradientShap&lt;/code&gt; などのいくつかの解釈可能性アルゴリズムは、入力とベースラインの間の変化を、ニューラルネットワークが出力する予測クラスまたは値に起因するように設計されています。</target>
        </trans-unit>
        <trans-unit id="e51de3cf2de9a13ef9bdd27134ba09503e04cca6" translate="yes" xml:space="preserve">
          <source>Now let's look into &lt;code&gt;DeepLiftShap&lt;/code&gt;. Similar to &lt;code&gt;GradientShap&lt;/code&gt;, &lt;code&gt;DeepLiftShap&lt;/code&gt; uses
baseline distribution. In the example below, we use the same baseline distribution
as for &lt;code&gt;GradientShap&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;DeepLiftShap&lt;/code&gt; 見てみましょう。 &lt;code&gt;GradientShap&lt;/code&gt; と同様に、 &lt;code&gt;DeepLiftShap&lt;/code&gt; はベースライン分布を使用します。以下の例では、 &lt;code&gt;GradientShap&lt;/code&gt; と同じベースライン分布を使用しています。</target>
        </trans-unit>
        <trans-unit id="4bed336194a9a5c86b6a734f03b3570d2aae1a68" translate="yes" xml:space="preserve">
          <source>Output</source>
          <target state="translated">出力</target>
        </trans-unit>
        <trans-unit id="f3c8c95c5e534bcd2ea0034a0d83177efa6923f4" translate="yes" xml:space="preserve">
          <source>Output:</source>
          <target state="translated">出力します。</target>
        </trans-unit>
        <trans-unit id="7835db447bc76230b5b0d736b2d78c671d7100a1" translate="yes" xml:space="preserve">
          <source>Outputs</source>
          <target state="translated">出力</target>
        </trans-unit>
        <trans-unit id="b969baf269c9dc13dd2c54d156013b3e06ea3070" translate="yes" xml:space="preserve">
          <source>Positive attribution score means that the input in that particular position
positively contributed to the final prediction and negative means the opposite.
The magnitude of the attribution score signifies the strength of the contribution.
Zero attribution score means no contribution from that particular feature.</source>
          <target state="translated">帰属スコアが正の場合は、その特定の位置での入力が最終的な予測に正に寄与したことを意味し、負の場合はその逆を意味します。帰属スコアの大きさは、寄与の強さを表します。帰属スコアがゼロの場合は、その特定の特徴からの寄与がないことを意味します。</target>
        </trans-unit>
        <trans-unit id="4c0d584e447dd2c5fa55e98d5d7921249c3911f6" translate="yes" xml:space="preserve">
          <source>PyTorch &amp;gt;= 1.2</source>
          <target state="translated">PyTorch&amp;gt; = 1.2</target>
        </trans-unit>
        <trans-unit id="c32b6c1ab053aa1b803595ba447bebbb8760c137" translate="yes" xml:space="preserve">
          <source>Python &amp;gt;= 3.6</source>
          <target state="translated">Python&amp;gt; = 3.6</target>
        </trans-unit>
        <trans-unit id="f00e768dce422689fe65ae881c3b96779cce5814" translate="yes" xml:space="preserve">
          <source>References of Algorithms</source>
          <target state="translated">アルゴリズムに関する言及</target>
        </trans-unit>
        <trans-unit id="54d440a5db0ab24f40fddf2b795f3716e25774cf" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;CONTRIBUTING.md&quot;&gt;CONTRIBUTING&lt;/a&gt; file for how to help out.</source>
          <target state="translated">支援する方法については、&lt;a href=&quot;CONTRIBUTING.md&quot;&gt;CONTRIBUTING&lt;/a&gt;ファイルを参照してください。</target>
        </trans-unit>
        <trans-unit id="9076ccad99e9fe123f5a242ef0d44a11422a0a37" translate="yes" xml:space="preserve">
          <source>Similar to GradientShap in order to compute example-based deltas we can average them per example:</source>
          <target state="translated">GradientShap と同様に、例題ベースのデルタを計算するために、例題ごとに平均化することができます。</target>
        </trans-unit>
        <trans-unit id="7c2892f73bdaf8f8b7b55fd520cd5b43f07bb285" translate="yes" xml:space="preserve">
          <source>Similar to integrated gradients, DeepLift returns a convergence delta score
per input example. The approximation error is then the absolute
value of the convergence deltas and can serve as a proxy of how accurate the
algorithm's approximation is.</source>
          <target state="translated">積分勾配と同様に、DeepLiftは入力例ごとに収束デルタスコアを返します。近似誤差は、収束デルタの絶対値であり、アルゴリズムの近似がどれだけ正確であるかの代理として機能します。</target>
        </trans-unit>
        <trans-unit id="c98898a289abd12ad3663b6492c23d0af933dcbb" translate="yes" xml:space="preserve">
          <source>Similar to other attribution algorithms that return convergence delta, &lt;code&gt;LayerConductance&lt;/code&gt;
returns the deltas for each example. The approximation error is then the absolute
value of the convergence deltas and can serve as a proxy of how accurate integral
approximation for given inputs and baselines is.</source>
          <target state="translated">収束デルタを返す他の属性アルゴリズムと同様に、 &lt;code&gt;LayerConductance&lt;/code&gt; は各例のデルタを返します。この場合、近似誤差は収束デルタの絶対値であり、特定の入力とベースラインの積分近似がどの程度正確かを示すプロキシとして機能します。</target>
        </trans-unit>
        <trans-unit id="08641a32adb6073b217892c1d05043cccc5795f7" translate="yes" xml:space="preserve">
          <source>Similarly, we can apply &lt;code&gt;GradientShap&lt;/code&gt;, &lt;code&gt;DeepLift&lt;/code&gt; and other attribution algorithms to the model.</source>
          <target state="translated">同様に、 &lt;code&gt;GradientShap&lt;/code&gt; 、 &lt;code&gt;DeepLift&lt;/code&gt; およびその他の属性アルゴリズムをモデルに適用できます。</target>
        </trans-unit>
        <trans-unit id="5dfd03564d68a63c3940a933d7149be86e1b24fc" translate="yes" xml:space="preserve">
          <source>Talks and Papers</source>
          <target state="translated">講演と論文</target>
        </trans-unit>
        <trans-unit id="5cc6318e21af4a9864dfb66b71e19b22e67f5171" translate="yes" xml:space="preserve">
          <source>Target Audience</source>
          <target state="translated">対象者</target>
        </trans-unit>
        <trans-unit id="7c09a880f031a61c434b6eea261034d0953ae737" translate="yes" xml:space="preserve">
          <source>The algorithm outputs an attribution score for each input element and a
convergence delta. The lower the absolute value of the convergence delta the better
is the approximation. If we choose not to return delta,
we can simply not provide &lt;code&gt;return_convergence_delta&lt;/code&gt; input
argument. The absolute value of the returned deltas can be interpreted as an
approximation error for each input sample.
It can also serve as a proxy of how accurate the integral approximation for given
inputs and baselines is.
If the approximation error is large, we can try larger number of integral
approximation steps by setting &lt;code&gt;n_steps&lt;/code&gt; to a larger value. Not all algorithms
return approximation error. Those which do, though, compute it based on the
completeness property of the algorithms.</source>
          <target state="translated">アルゴリズムは、各入力要素の属性スコアと収束デルタを出力します。収束デルタの絶対値が小さいほど、近似が良くなります。デルタを返さないことを選択した場合は、単に &lt;code&gt;return_convergence_delta&lt;/code&gt; 入力引数を提供できません。返されたデルタの絶対値は、各入力サンプルの近似誤差として解釈できます。また、与えられた入力とベースラインの積分近似がどれほど正確かを示すプロキシとしても機能します。近似誤差が大きい場合は、 &lt;code&gt;n_steps&lt;/code&gt; をより大きな値に設定することで、より多くの整数近似ステップを試すことができます。すべてのアルゴリズムが近似エラーを返すわけではありません。ただし、アルゴリズムの完全性プロパティに基づいて計算します。</target>
        </trans-unit>
        <trans-unit id="9bc5b2cbf539dd2b556b4ee16093e2dd98e5e53f" translate="yes" xml:space="preserve">
          <source>The latest release of Captum is easily installed either via
&lt;a href=&quot;https://www.anaconda.com/distribution/#download-section&quot;&gt;Anaconda&lt;/a&gt; (recommended):</source>
          <target state="translated">Captumの最新リリースは、&lt;a href=&quot;https://www.anaconda.com/distribution/#download-section&quot;&gt;Anaconda&lt;/a&gt;を介して簡単にインストールできます （推奨）：</target>
        </trans-unit>
        <trans-unit id="14456e5d622ffef206d84cb2547dd1292a3e6a4b" translate="yes" xml:space="preserve">
          <source>The number of elements in the &lt;code&gt;delta&lt;/code&gt; tensor is equal to: &lt;code&gt;n_samples * input.shape[0]&lt;/code&gt;
In order to get a example-based delta, we can, for example, average them:</source>
          <target state="translated">&lt;code&gt;delta&lt;/code&gt; テンソルの要素数は次のようになります &lt;code&gt;n_samples * input.shape[0]&lt;/code&gt; サンプルベースのデルタを取得するには、たとえば、それらを平均化できます。</target>
        </trans-unit>
        <trans-unit id="d97f36b304cf7bf6d19d6ba216bf83da80bc9ca1" translate="yes" xml:space="preserve">
          <source>The primary audiences for Captum are model developers who are looking to improve their models and understand which features are important and interpretability researchers focused on identifying algorithms that can better interpret many types of models.</source>
          <target state="translated">Captumの主な対象者は、モデルを改善し、どの機能が重要なのかを理解しようとしているモデル開発者と、多くのタイプのモデルをより良く解釈できるアルゴリズムを特定することに焦点を当てている解釈可能性の研究者です。</target>
        </trans-unit>
        <trans-unit id="09bb5c690208bfa966db7460586a698914a360bd" translate="yes" xml:space="preserve">
          <source>The slides of our presentation from NeurIPS 2019 can be found &lt;a href=&quot;docs/presentations/Captum_NeurIPS_2019_final.key&quot;&gt;here&lt;/a&gt;</source>
          <target state="translated">NeurIPS 2019からのプレゼンテーションのスライドは、&lt;a href=&quot;docs/presentations/Captum_NeurIPS_2019_final.key&quot;&gt;こちらにあります&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5d0367e1f5fde1ede3db753f108801cb14982eac" translate="yes" xml:space="preserve">
          <source>To analyze a sample model on CIFAR10 via Captum Insights run</source>
          <target state="translated">Captum Insights を通じて CIFAR10 のサンプルモデルを解析するには、以下のように実行します。</target>
        </trans-unit>
        <trans-unit id="1b78a188c82782ae0e64234fb5851ce273466f93" translate="yes" xml:space="preserve">
          <source>To build Insights you will need &lt;a href=&quot;https://nodejs.org/en/&quot;&gt;Node&lt;/a&gt; &amp;gt;= 8.x
and &lt;a href=&quot;https://yarnpkg.com/en/&quot;&gt;Yarn&lt;/a&gt; &amp;gt;= 1.5.</source>
          <target state="translated">インサイトを構築するには、&lt;a href=&quot;https://nodejs.org/en/&quot;&gt;Node&lt;/a&gt; &amp;gt; = 8.xおよび&lt;a href=&quot;https://yarnpkg.com/en/&quot;&gt;Yarn&lt;/a&gt; &amp;gt; = 1.5 が必要です。</target>
        </trans-unit>
        <trans-unit id="5468c50938c4ec01b3019827d9753bc27eccd242" translate="yes" xml:space="preserve">
          <source>To build and launch from a checkout in a conda environment run</source>
          <target state="translated">コンダ環境でチェックアウトからビルドして起動するには、次のように実行します。</target>
        </trans-unit>
        <trans-unit id="47d309089702b5779d1249906c184aca6a17334f" translate="yes" xml:space="preserve">
          <source>To build the widget from a checkout in a conda environment run</source>
          <target state="translated">conda環境でチェックアウトからウィジェットをビルドするには、次のように実行します。</target>
        </trans-unit>
        <trans-unit id="039a5244d60906d43c5c15a0a20b10397b0bc5f9" translate="yes" xml:space="preserve">
          <source>To customize the installation, you can also run the following variants of the
above:</source>
          <target state="translated">インストールをカスタマイズするには、上記の以下の亜種を実行することもできます。</target>
        </trans-unit>
        <trans-unit id="a39ccefe51118817f1b35b636167cdb3bd9357d8" translate="yes" xml:space="preserve">
          <source>To execute unit tests from a manual install, run:</source>
          <target state="translated">手動インストールからユニットテストを実行するには、実行します。</target>
        </trans-unit>
        <trans-unit id="4ac1cec1a4406720bdada7e35a448ad0dfd20d82" translate="yes" xml:space="preserve">
          <source>To make computations deterministic, let's fix random seeds.</source>
          <target state="translated">計算を決定論的にするために、ランダムな種を固定しましょう。</target>
        </trans-unit>
        <trans-unit id="eba414e2b73da649f8d414e82f52b11624820726" translate="yes" xml:space="preserve">
          <source>We will apply model interpretability algorithms on the network
mentioned above in order to understand the importance of individual
neurons/layers and the parts of the input that play an important role in the
final prediction.</source>
          <target state="translated">個々のニューロン/レイヤーの重要性と、最終的な予測に重要な役割を果たす入力の部分を理解するために、上述のネットワークにモデル解釈可能アルゴリズムを適用します。</target>
        </trans-unit>
        <trans-unit id="168626e3b7f39ed35712d4be0f4311e69049dd72" translate="yes" xml:space="preserve">
          <source>We will start with the &lt;code&gt;NeuronConductance&lt;/code&gt;. &lt;code&gt;NeuronConductance&lt;/code&gt; helps us to identify
input features that are important for a particular neuron in a given
layer. It decomposes the computation of integrated gradients via the chain rule by
defining the importance of a neuron as path integral of the derivative of the output
with respect to the neuron times the derivatives of the neuron with respect to the
inputs of the model.</source>
          <target state="translated">私たちは、始まります &lt;code&gt;NeuronConductance&lt;/code&gt; 。 &lt;code&gt;NeuronConductance&lt;/code&gt; は、特定のレイヤーの特定のニューロンにとって重要な入力機能を識別するのに役立ちます。モデルの入力に関するニューロンの導関数とニューロンに関する出力の導関数の経路積分としてニューロンの重要性を定義することにより、チェーンルールによる統合勾配の計算を分解します。</target>
        </trans-unit>
        <trans-unit id="3aee6cb4b987c6eb98bae057c8033da66b7ba223" translate="yes" xml:space="preserve">
          <source>With the increase in model complexity and the resulting lack of transparency, model interpretability methods have become increasingly important. Model understanding is both an active area of research as well as an area of focus for practical applications across industries using machine learning. Captum provides state-of-the-art algorithms, including Integrated Gradients, to provide researchers and developers with an easy way to understand which features are contributing to a model&amp;rsquo;s output.</source>
          <target state="translated">モデルの複雑さが増し、結果として透明性が失われるにつれて、モデルの解釈可能性の方法がますます重要になっています。モデル理解は、研究の活発な分野であると同時に、機械学習を使用する業界全体の実用的なアプリケーションに焦点を当てている分野でもあります。Captumは、統合勾配を含む最先端のアルゴリズムを提供し、研究者や開発者に、モデルの出力に寄与している機能を簡単に理解できるようにします。</target>
        </trans-unit>
        <trans-unit id="ffc76686099e22242eb4269a3745fa2f6e1ef1d4" translate="yes" xml:space="preserve">
          <source>and navigate to the URL specified in the output.</source>
          <target state="translated">をクリックして、出力で指定したURLに移動します。</target>
        </trans-unit>
        <trans-unit id="2eeef8b3dfe3c6e07456229818d93864ce2c6fe7" translate="yes" xml:space="preserve">
          <source>in order to get per example average delta.</source>
          <target state="translated">例あたりの平均デルタを取得するために。</target>
        </trans-unit>
        <trans-unit id="d6773e7adcc2adec52348c71e0551f68a9f85abd" translate="yes" xml:space="preserve">
          <source>or via &lt;code&gt;pip&lt;/code&gt;:</source>
          <target state="translated">または &lt;code&gt;pip&lt;/code&gt; 経由：</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
