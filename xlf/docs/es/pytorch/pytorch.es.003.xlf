<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="es" datatype="htmlbody" original="pytorch">
    <body>
      <group id="pytorch">
        <trans-unit id="1b9c74bd1fba9cae2375c562757e49b9f3f24764" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;load_state_dict(state_dict: Dict[str, torch.Tensor], strict: bool = True)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.load_state_dict&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62f66bbcb0b08c54e10a39245830a0c3663b3ee0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;local_rank&lt;/code&gt; is NOT globally unique: it is only unique per process on a machine. Thus, don&amp;rsquo;t use it to decide if you should, e.g., write to a networked filesystem. See &lt;a href=&quot;https://github.com/pytorch/pytorch/issues/12042&quot;&gt;https://github.com/pytorch/pytorch/issues/12042&lt;/a&gt; for an example of how things can go wrong if you don&amp;rsquo;t do this correctly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa7c545b613756907a429504c3115615d7789a1a" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;log_prob(input: torch.Tensor) &amp;rarr; torch.Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/adaptive.html#AdaptiveLogSoftmaxWithLoss.log_prob&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc5a71e50b3f16dc1145f31275ba17755e3208f3" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;lu(pivot=True, get_infos=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/tensor.html#Tensor.lu&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd04b20a72f6e3eefecb7fc21edef53df71f8ef7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;matmul(A, V[:, :k])&lt;/code&gt; projects data to the first k principal components</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7139ac5f6d0a956209f36cd92ff11f349707f99e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;method=&amp;rdquo;basic&amp;rdquo;&lt;/code&gt; - the LOBPCG method introduced by Andrew Knyazev, see [Knyazev2001]. A less robust method, may fail when Cholesky is applied to singular input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5cc2c230f41d50cec42c5a73738ea776357df1f2" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;method=&amp;rdquo;ortho&amp;rdquo;&lt;/code&gt; - the LOBPCG method with orthogonal basis selection [StathopoulosEtal2002]. A robust method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31632cd895f74d5feae903615972b9be78a76f37" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;modules() &amp;rarr; Iterator[torch.nn.modules.module.Module]&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.modules&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32e35227c212f090980012e3160ed30e44efafd0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;named_buffers(prefix: str = '', recurse: bool = True) &amp;rarr; Iterator[Tuple[str, torch.Tensor]]&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.named_buffers&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="048db148a1be9becc9e39073dbeb4b604c390c68" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;named_children() &amp;rarr; Iterator[Tuple[str, torch.nn.modules.module.Module]]&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.named_children&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85bacda5665b89ed5cefaace04dda54af89f48fe" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;named_modules(memo: Optional[Set[Module]] = None, prefix: str = '')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.named_modules&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="22a7ee3e0da6af405272a0ed0646ab619f9fb34b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;named_parameters(prefix: str = '', recurse: bool = True) &amp;rarr; Iterator[Tuple[str, torch.Tensor]]&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.named_parameters&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dfec0664bec327f4859fdc164e8ab345ca09035a" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;names[idx]&lt;/code&gt; corresponds to the name of tensor dimension &lt;code&gt;idx&lt;/code&gt;. Names are either a string if the dimension is named or &lt;code&gt;None&lt;/code&gt; if the dimension is unnamed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64961805f0c40621fceb6e60083709ff6fd8c3f7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;nccl&lt;/code&gt; backend is currently the fastest and highly recommended backend when using GPUs. This applies to both single-node and multi-node distributed training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b98aabe4badf856a18d383aa4bbcf3819012f841" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;no_sync()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/parallel/distributed.html#DistributedDataParallel.no_sync&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;no_sync()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/parallel/distributed.html#DistributedDataParallel.no_sync&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="243529964a8f02b21c1cfb5a2cf1416a48cdb560" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;norm(p='fro', dim=None, keepdim=False, dtype=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/tensor.html#Tensor.norm&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67fdf5912494b352e2db89b729e0ae31d14aa6b3" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;optimize_for_mobile&lt;/code&gt; will also invoke freeze_module pass which only preserves &lt;code&gt;forward&lt;/code&gt; method. If you have other method to that needed to be preserved, add them into the preserved method list and pass into the method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6860a3cc1bb85eed802ff8a945080f941221eb86" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;out&lt;/code&gt; can have integral &lt;code&gt;dtype&lt;/code&gt;, but &lt;code&gt;input&lt;/code&gt; must have floating point &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57df9e7349923cce6d85797c07fe7176a04c4730" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;output&lt;/code&gt;: aggregated embedding values of shape &lt;code&gt;(B, embedding_dim)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20bc1b9a285a7d6c1e598719cab22ec2e30a86ed" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;output_padding&lt;/code&gt; controls the additional size added to one side of the output shape. See note below for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c43d9da08c42122b25a623aed7e1ec7d4a1ed5e0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;output_size&lt;/code&gt; (optional): the targeted output size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f9c7a3c6933d1325ba659f80f703c1d21ba8d09" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;output_size&lt;/code&gt; describes the spatial shape of the large containing tensor of the sliding local blocks. It is useful to resolve the ambiguity when multiple input shapes map to same number of sliding blocks, e.g., with &lt;code&gt;stride &amp;gt; 0&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1243c702a5a6e39b0598b1177c888c80420b192" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;p_tensor&lt;/code&gt; should be a tensor containing probabilities to be used for drawing the binary random number.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71d214acd804f5a2164bbac6db12b07145c9f82a" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;pad_mode&lt;/code&gt; determines the padding method used on &lt;code&gt;input&lt;/code&gt; when &lt;code&gt;center&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;. See &lt;a href=&quot;../nn.functional#torch.nn.functional.pad&quot;&gt;&lt;code&gt;torch.nn.functional.pad()&lt;/code&gt;&lt;/a&gt; for all available options. Default is &lt;code&gt;&quot;reflect&quot;&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98da630d9b8562a9fa983197c13c21292635e0d8" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;pad_sequence&lt;/code&gt; stacks a list of Tensors along a new dimension, and pads them to equal length. For example, if the input is list of sequences with size &lt;code&gt;L x *&lt;/code&gt; and if batch_first is False, and &lt;code&gt;T x B x *&lt;/code&gt; otherwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5523aea5f1d24240fad2b5cb687abb71fdd8696c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;padding&lt;/code&gt; controls the amount of implicit zero-paddings on both sides for &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; number of points. See note below for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0965d5762b82b5756e9509e59423399f67ccc74c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;padding&lt;/code&gt; controls the amount of implicit zero-paddings on both sides for &lt;code&gt;padding&lt;/code&gt; number of points for each dimension before reshaping.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87faaf2c7b8606fb40058aa40aed778ec31e990d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;padding&lt;/code&gt; controls the amount of implicit zero-paddings on both sides for &lt;code&gt;padding&lt;/code&gt; number of points for each dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="873aa63cc9ed82344812e9f5d81f5ab1f6110075" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;padding&lt;/code&gt; controls the amount of implicit zero-paddings on both sides for &lt;code&gt;padding&lt;/code&gt; number of points.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e777921c9b14589989930ecd3404d8f890efee0e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;padding_mode=&quot;border&quot;&lt;/code&gt;: use border values for out-of-bound grid locations,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9bf609a621bd6df6b08d69937c59fb9bda6a4e18" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;padding_mode=&quot;reflection&quot;&lt;/code&gt;: use values at locations reflected by the border for out-of-bound grid locations. For location far away from the border, it will keep being reflected until becoming in bound, e.g., (normalized) pixel location &lt;code&gt;x = -3.5&lt;/code&gt; reflects by border &lt;code&gt;-1&lt;/code&gt; and becomes &lt;code&gt;x' = 1.5&lt;/code&gt;, then reflects by border &lt;code&gt;1&lt;/code&gt; and becomes &lt;code&gt;x'' = -0.5&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65643d381010e2d95d811ab0babc2d8ceb40b002" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;padding_mode=&quot;zeros&quot;&lt;/code&gt;: use &lt;code&gt;0&lt;/code&gt; for out-of-bound grid locations,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2fd5be269042a70bd6bfcef4a1beb1fad3f8b126" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;parameters(recurse: bool = True) &amp;rarr; Iterator[torch.nn.parameter.Parameter]&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.parameters&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="389b3925161df2a316dfd68b4bd9f091bc6d9283" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;per_index_weights&lt;/code&gt; (Tensor, optional)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3171c9a0247049dc9a6cc2032a93513a93d4b9e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;per_sample_weights&lt;/code&gt; (Tensor, optional). Has the same shape as &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9bcadfa3ee1d7befc56f0936be4d842be3c16e4" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;pop(key: str) &amp;rarr; Parameter&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/container.html#ParameterDict.pop&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d3bcc0091bf56d060c58f75cf9a87f90235fe42" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;pop(key: str) &amp;rarr; torch.nn.modules.module.Module&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/container.html#ModuleDict.pop&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cecc34a8f924fcf63ac4e86b4df399986ca30840" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;predict(input: torch.Tensor) &amp;rarr; torch.Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/adaptive.html#AdaptiveLogSoftmaxWithLoss.predict&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3feeb93547a40ff63ef93c1edbe8bdb7276b339e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;prune(t, default_mask=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/prune.html#BasePruningMethod.prune&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0006fd153e3e41368ff174db197035583852421" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;reduction&lt;/code&gt; = &lt;code&gt;'mean'&lt;/code&gt; doesn&amp;rsquo;t return the true kl divergence value, please use &lt;code&gt;reduction&lt;/code&gt; = &lt;code&gt;'batchmean'&lt;/code&gt; which aligns with KL math definition. In the next major release, &lt;code&gt;'mean'&lt;/code&gt; will be changed to be the same as &lt;code&gt;'batchmean'&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c40fd54ed9b4a947e07d2d97749d3a5a6960fd4" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;refine_names(*names)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/tensor.html#Tensor.refine_names&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;refine_names(*names)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/tensor.html#Tensor.refine_names&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a26fb9fd98b2c03b3515681e4d92a08a2f7d05f5" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;register_backward_hook(hook: Callable[[Module, Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[None, torch.Tensor]]) &amp;rarr; torch.utils.hooks.RemovableHandle&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.register_backward_hook&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3fc6039af03180c3ab53c4d591ca38e5fab4f39" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;register_buffer(name: str, tensor: Optional[torch.Tensor], persistent: bool = True) &amp;rarr; None&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.register_buffer&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb44a0e61508db210c21280300a86c46e5d6bdf7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;register_forward_hook(hook: Callable[..., None]) &amp;rarr; torch.utils.hooks.RemovableHandle&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.register_forward_hook&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="158c35384b89f58225b64148f33d94a37ef4fc57" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;register_forward_pre_hook(hook: Callable[..., None]) &amp;rarr; torch.utils.hooks.RemovableHandle&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.register_forward_pre_hook&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="936eaf9b14caaa34ea920fae06e38528e4361e53" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;register_hook(hook)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/tensor.html#Tensor.register_hook&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;register_hook(hook)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/tensor.html#Tensor.register_hook&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5292ac761c061e747a376f42b7b666c69eaa24fb" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;register_parameter(name: str, param: Optional[torch.nn.parameter.Parameter]) &amp;rarr; None&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.register_parameter&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b1596aad33a69c18bddd2a50faac7da7dfe74e0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;remove(module)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/prune.html#BasePruningMethod.remove&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;remove(module)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/prune.html#BasePruningMethod.remove&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a7c7a4c7bb3781e3a5ff82b15f960d784474e526" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;rename(*names, **rename_map)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/tensor.html#Tensor.rename&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f56c6acc1a2fd9e54a77cd2f6182d7653e821c2" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;rename_(*names, **rename_map)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/tensor.html#Tensor.rename_&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b78f9895d15f5a907942047841acbda1473e2a92" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;requires_grad_(requires_grad: bool = True) &amp;rarr; T&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.requires_grad_&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a6e3641f634a4bff93ea55f39b2b25ad71a52c4" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;reset()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/quasirandom.html#SobolEngine.reset&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;reset()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/quasirandom.html#SobolEngine.reset&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d5491ec86d7e376ac6bea33efc116ab49c35fa70" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;retain_grad()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/tensor.html#Tensor.retain_grad&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;retain_grad()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/tensor.html#Tensor.retain_grad&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="30afcf2664bfd55bdc73c874505670a40ceba5c5" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;self.bfloat16()&lt;/code&gt; is equivalent to &lt;code&gt;self.to(torch.bfloat16)&lt;/code&gt;. See &lt;a href=&quot;#torch.Tensor.to&quot;&gt;&lt;code&gt;to()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba8b07afb3887e1378823dcb6c0026111669eec7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;self.bool()&lt;/code&gt; is equivalent to &lt;code&gt;self.to(torch.bool)&lt;/code&gt;. See &lt;a href=&quot;#torch.Tensor.to&quot;&gt;&lt;code&gt;to()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="235e528e147f1d69ea9f027ab1d5f71c3e2b6504" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;self.byte()&lt;/code&gt; is equivalent to &lt;code&gt;self.to(torch.uint8)&lt;/code&gt;. See &lt;a href=&quot;#torch.Tensor.to&quot;&gt;&lt;code&gt;to()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="696fbff031feb55dfc6a3f759d73b60530f439b6" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;self.char()&lt;/code&gt; is equivalent to &lt;code&gt;self.to(torch.int8)&lt;/code&gt;. See &lt;a href=&quot;#torch.Tensor.to&quot;&gt;&lt;code&gt;to()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd991c33642a908ee15c44c4567ca13834b6d0e7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;self.double()&lt;/code&gt; is equivalent to &lt;code&gt;self.to(torch.float64)&lt;/code&gt;. See &lt;a href=&quot;#torch.Tensor.to&quot;&gt;&lt;code&gt;to()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb530f2cded8fb18cd0f6bd9e52d044bc47fa9cf" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;self.float()&lt;/code&gt; is equivalent to &lt;code&gt;self.to(torch.float32)&lt;/code&gt;. See &lt;a href=&quot;#torch.Tensor.to&quot;&gt;&lt;code&gt;to()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c39462395fa123a645a00da7f7061280a0d3b20a" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;self.half()&lt;/code&gt; is equivalent to &lt;code&gt;self.to(torch.float16)&lt;/code&gt;. See &lt;a href=&quot;#torch.Tensor.to&quot;&gt;&lt;code&gt;to()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ccde90fcc390e97ee3b4f21b89a8c42e1d03051e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;self.int()&lt;/code&gt; is equivalent to &lt;code&gt;self.to(torch.int32)&lt;/code&gt;. See &lt;a href=&quot;#torch.Tensor.to&quot;&gt;&lt;code&gt;to()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5058cc3abe53f662df7631dd5211dc4a50368575" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;self.long()&lt;/code&gt; is equivalent to &lt;code&gt;self.to(torch.int64)&lt;/code&gt;. See &lt;a href=&quot;#torch.Tensor.to&quot;&gt;&lt;code&gt;to()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b88b4ac2f04fe1799583ed6e4d6bfc76ea2f417" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;self.rename(**rename_map)&lt;/code&gt; returns a view on tensor that has dims renamed as specified in the mapping &lt;code&gt;rename_map&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ee77ff93d503175bd69ae14f8b2767c810fb5f1" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;self.rename(*names)&lt;/code&gt; returns a view on tensor, renaming all dimensions positionally using &lt;a href=&quot;#torch.Tensor.names&quot;&gt;&lt;code&gt;names&lt;/code&gt;&lt;/a&gt;. Use &lt;code&gt;self.rename(None)&lt;/code&gt; to drop names on a tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11363fccfc09fecbbf6487dc95db457ac7c9d1bb" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;self.short()&lt;/code&gt; is equivalent to &lt;code&gt;self.to(torch.int16)&lt;/code&gt;. See &lt;a href=&quot;#torch.Tensor.to&quot;&gt;&lt;code&gt;to()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="745574568faaeba1d561f1e5ae137746578c731c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;self.where(condition, y)&lt;/code&gt; is equivalent to &lt;code&gt;torch.where(condition, self, y)&lt;/code&gt;. See &lt;a href=&quot;generated/torch.where#torch.where&quot;&gt;&lt;code&gt;torch.where()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80d12cdf60b2ebf7897bf33eeda8316c6146ee5e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;self&lt;/code&gt; can have integral &lt;code&gt;dtype&lt;/code&gt;, but &lt;code&gt;p_tensor&lt;/code&gt; must have floating point &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04afe95e87078af73461e45f69231c868514d31c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;self&lt;/code&gt; is a scalar &lt;code&gt;float&lt;/code&gt; value, and &lt;code&gt;exponent&lt;/code&gt; is a tensor. The returned tensor &lt;code&gt;out&lt;/code&gt; is of the same shape as &lt;code&gt;exponent&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f8bc9073599a1c05ac8a8256c20ef81117a207c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;self&lt;/code&gt;, &lt;code&gt;index&lt;/code&gt; and &lt;code&gt;src&lt;/code&gt; (if it is a Tensor) should have same number of dimensions. It is also required that &lt;code&gt;index.size(d) &amp;lt;= src.size(d)&lt;/code&gt; for all dimensions &lt;code&gt;d&lt;/code&gt;, and that &lt;code&gt;index.size(d) &amp;lt;= self.size(d)&lt;/code&gt; for all dimensions &lt;code&gt;d != dim&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84785e3dd4238879d9071b5f542dcf76287afa5f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;self&lt;/code&gt;, &lt;code&gt;index&lt;/code&gt; and &lt;code&gt;src&lt;/code&gt; should have same number of dimensions. It is also required that &lt;code&gt;index.size(d) &amp;lt;= src.size(d)&lt;/code&gt; for all dimensions &lt;code&gt;d&lt;/code&gt;, and that &lt;code&gt;index.size(d) &amp;lt;= self.size(d)&lt;/code&gt; for all dimensions &lt;code&gt;d != dim&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8db8aa8a39114a3bb4d5fd0455bd46f531532d3" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;sequences&lt;/code&gt; should be a list of Tensors of size &lt;code&gt;L x *&lt;/code&gt;, where &lt;code&gt;L&lt;/code&gt; is the length of a sequence and &lt;code&gt;*&lt;/code&gt; is any number of trailing dimensions, including zero.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="735447a30cd08376a5904648fe0520b6748f549e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;set_grad_enabled&lt;/code&gt; will enable or disable grads based on its argument &lt;a href=&quot;torch.mode#torch.mode&quot;&gt;&lt;code&gt;mode&lt;/code&gt;&lt;/a&gt;. It can be used as a context-manager or as a function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a841331f9feb2d5c5159d5c906fc881114af61e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;set_result(result: T) &amp;rarr; None&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/futures.html#Future.set_result&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0fd6f8837947d9dfd2011aecf91b34593d64433" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;share_memory_()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/tensor.html#Tensor.share_memory_&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;share_memory_()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/tensor.html#Tensor.share_memory_&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5ada337e154f8b6156cdfc96e0db2f536f0893f6" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;size&lt;/code&gt; is the number of elements in the storage. If &lt;code&gt;shared&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, then the file must contain at least &lt;code&gt;size * sizeof(Type)&lt;/code&gt; bytes (&lt;code&gt;Type&lt;/code&gt; is the type of storage). If &lt;code&gt;shared&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; the file will be created if needed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="775a9cd83a519b88484214ea6efd0a87345ed211" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;size_average&lt;/code&gt; and &lt;code&gt;reduce&lt;/code&gt; are in the process of being deprecated, and in the meantime, specifying either of those two args will override &lt;code&gt;reduction&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="968d0dce1541ed993d4b1f29fd9e1515b8a4c0e0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;sizes&lt;/code&gt; is the new shape of the unflattened dimension and it can be a &lt;code&gt;Tuple[int]&lt;/code&gt; as well as &lt;code&gt;torch.Size&lt;/code&gt; if &lt;code&gt;self&lt;/code&gt; is a &lt;code&gt;Tensor&lt;/code&gt;, or &lt;code&gt;namedshape&lt;/code&gt; (Tuple[(name: str, size: int)]) if &lt;code&gt;self&lt;/code&gt; is a &lt;code&gt;NamedTensor&lt;/code&gt;. The total number of elements in sizes must match the number of elements in the original dim being unflattened.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e28ebaeabfc2c0d6b3aa7c33dff1b51cdc74c19f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;split(split_size, dim=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/tensor.html#Tensor.split&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d70995f5b7bd944127ae56e30134e1589387bff" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;state_dict(destination=None, prefix='', keep_vars=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.state_dict&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9478657a6bc48f9b2e80d90d60e5b04ab9b9aae2" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;step(context_id)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/optim/optimizer.html#DistributedOptimizer.step&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;step(context_id)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/optim/optimizer.html#DistributedOptimizer.step&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e5a5904fe6a7743321ff5c71f315d635b92b3c9e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;stft(n_fft: int, hop_length: Optional[int] = None, win_length: Optional[int] = None, window: Optional[torch.Tensor] = None, center: bool = True, pad_mode: str = 'reflect', normalized: bool = False, onesided: Optional[bool] = None, return_complex: Optional[bool] = None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/tensor.html#Tensor.stft&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a2d4b82f8a4a08f439941b4fe2cd2f4e127ee11" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;stride&lt;/code&gt; controls the stride for the cross-correlation, a single number or a one-element tuple.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a32aa3c0b68f959b763c5ab1ff65ebd608f9255b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;stride&lt;/code&gt; controls the stride for the cross-correlation, a single number or a tuple.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7cc6339d97b370d095743b2c41bc1edfe10d964" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;stride&lt;/code&gt; controls the stride for the cross-correlation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="742806613e72fcf7d80117cd493eb9ec43cefbce" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;stride&lt;/code&gt; controls the stride for the sliding blocks.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56b9b812f41a06ed4638217119c49e950638afeb" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;tensor&lt;/code&gt; must have the same number of elements in all processes participating in the collective.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="224069f965b222e903606022d10e7a98e065b9ae" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;tensor&lt;/code&gt; must have the same number of elements in all the GPUs from all processes participating in the collective. each tensor in the list must be on a different GPU</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d41bbb307c82a2c9b49f046126aa9c2345c1070" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;then(callback)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/futures.html#Future.then&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;then(callback)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/futures.html#Future.then&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="578af95c3bd45de88eac7fe154557b4d4985f0d0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;to(*args, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.to&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ac5282afe4693a20c19177c7dc6ba853efba47f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;to(*args, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/rnn.html#PackedSequence.to&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3dc0e16d9d7f541291e6dbab067b29c301d2e7ec" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;to(device=None, dtype=None, non_blocking=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.to&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e596c69ad0590b92b57b912529efbcc355b682e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;to(dtype, non_blocking=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.to&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ccfbe77f465473aa1da76dc9c34f89236b6724c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;to(memory_format=torch.channels_last)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.to&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;to(memory_format=torch.channels_last)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.to&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f08eeed12af7805bba2c17a64a2bdeecb1e24711" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;to(tensor, non_blocking=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.to&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eab345e7e4a5581554ed11c71dbb6edfff8c371e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;tol&lt;/code&gt; is the threshold below which the singular values (or the eigenvalues when &lt;code&gt;symmetric&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;) are considered to be 0. If &lt;code&gt;tol&lt;/code&gt; is not specified, &lt;code&gt;tol&lt;/code&gt; is set to &lt;code&gt;S.max() * max(S.size()) * eps&lt;/code&gt; where &lt;code&gt;S&lt;/code&gt; is the singular values (or the eigenvalues when &lt;code&gt;symmetric&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;), and &lt;code&gt;eps&lt;/code&gt; is the epsilon value for the datatype of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="18fe92a88d4b832404cc2dbd206ba724755bd2f8" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.Assert(condition, message)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch.html#Assert&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d791ae567ecad27f4445cb2aaf15f6029d488510" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.atleast_1d(*tensors)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#atleast_1d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.atleast_1d(*tensors)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#atleast_1d&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1656ab860bd5829558905cf483ea11bc0039dbff" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.atleast_2d(*tensors)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#atleast_2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.atleast_2d(*tensors)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#atleast_2d&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="dd52a2bd34a2723d8cb64d098bfcb5aade97fdc1" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.atleast_3d(*tensors)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#atleast_3d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.atleast_3d(*tensors)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#atleast_3d&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="807982babd7e2697d02339a41138a44e111d331f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.backends.cuda.is_built()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/backends/cuda.html#is_built&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.backends.cuda.is_built()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/backends/cuda.html#is_built&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="cad84bdf2432c05fed2fe1958d51387bbc6c0020" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.backends.cudnn.is_available()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/backends/cudnn.html#is_available&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.backends.cudnn.is_available()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/backends/cudnn.html#is_available&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="00b7a3cf7f24c2b2bebb11277acabb7c78d50317" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.backends.cudnn.version()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/backends/cudnn.html#version&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.backends.cudnn.version()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/backends/cudnn.html#version&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9dfbb3781e5878595a4417510d5aae33943c7ef2" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.backends.mkl.is_available()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/backends/mkl.html#is_available&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.backends.mkl.is_available()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/backends/mkl.html#is_available&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="72e4f98e5910cf117b1472f53b8f73df836ca78a" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.backends.mkldnn.is_available()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/backends/mkldnn.html#is_available&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.backends.mkldnn.is_available()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/backends/mkldnn.html#is_available&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7054ed97a3665299406dd42d55c4229d95f96305" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.backends.openmp.is_available()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/backends/openmp.html#is_available&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.backends.openmp.is_available()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/backends/openmp.html#is_available&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="4db6ff3c64dff7c5f1e9ecefcab9b3fe7f8bd5ef" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.backends&lt;/code&gt; controls the behavior of various backends that PyTorch supports.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4798618741fa5295873eda72f10f638e521941e3" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.block_diag(*tensors)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#block_diag&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.block_diag(*tensors)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#block_diag&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="561c4a9dc39238e682070f0062e9aef0052df081" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.broadcast_tensors(*tensors) &amp;rarr; List of Tensors&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#broadcast_tensors&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9abf70758cd66412725ba8672052a7932024490" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.cartesian_prod(*tensors)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#cartesian_prod&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.cartesian_prod(*tensors)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#cartesian_prod&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="eec3865daff49e31eb283e5df540594f2c021646" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.cdist(x1, x2, p=2.0, compute_mode='use_mm_for_euclid_dist_if_necessary')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#cdist&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd3bb7208ad3447bd28402045aaa3520bba00449" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.chain_matmul(*matrices)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#chain_matmul&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.chain_matmul(*matrices)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#chain_matmul&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9b7ede943ebb499689b4fa6f38f84fe9ace9c3ad" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.channels_last&lt;/code&gt;: Tensor is or will be allocated in dense non-overlapping memory. Strides represented by values in &lt;code&gt;strides[0] &amp;gt; strides[2] &amp;gt; strides[3] &amp;gt; strides[1] == 1&lt;/code&gt; aka NHWC order.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7261c6034d86aa2ddc9431902e39f474a13e60a4" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.cholesky_solve(b, u)&lt;/code&gt; can take in 2D inputs &lt;code&gt;b, u&lt;/code&gt; or inputs that are batches of 2D matrices. If the inputs are batches, then returns batched outputs &lt;code&gt;c&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d68363efb3452b6e83ed851d4699a5aa0f779741" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.compiled_with_cxx11_abi()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch.html#compiled_with_cxx11_abi&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.compiled_with_cxx11_abi()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch.html#compiled_with_cxx11_abi&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e126cacbad4b261249efa0e8913738a1877bbdfa" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.complex128&lt;/code&gt; or &lt;code&gt;torch.cdouble&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f39fd8648813e09f8476a9ac8da4abf78e93db3b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.complex64&lt;/code&gt; or &lt;code&gt;torch.cfloat&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dbaed180a18c68c202c3fc91f47ffeb99ac16e81" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.contiguous_format&lt;/code&gt;: Tensor is or will be allocated in dense non-overlapping memory. Strides represented by values in decreasing order.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3684d59244595e52fd2828b50ca6282d62fd4739" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.all_gather(tensor_list, tensor, group=&amp;lt;object object&amp;gt;, async_op=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#all_gather&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="288bfa32c25fcb8306179eca04e736e2a02186b7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.all_gather_multigpu(output_tensor_lists, input_tensor_list, group=&amp;lt;object object&amp;gt;, async_op=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#all_gather_multigpu&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8413a7e854b6ea51eaa6b4f60e55aab063717a94" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.all_reduce(tensor, op=ReduceOp.SUM, group=&amp;lt;object object&amp;gt;, async_op=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#all_reduce&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e54a6af7a1934d02149ec3e7822e2c3aacde8c6" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.all_reduce_multigpu(tensor_list, op=ReduceOp.SUM, group=&amp;lt;object object&amp;gt;, async_op=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#all_reduce_multigpu&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b02380125bbd88799d9b414d91da3147fc32cac4" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.all_to_all(output_tensor_list, input_tensor_list, group=&amp;lt;object object&amp;gt;, async_op=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#all_to_all&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="811431042ba4ac28ba32b7911f195c224a3cc8ed" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.barrier(group=&amp;lt;object object&amp;gt;, async_op=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#barrier&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="972f101974bfb6f5d4198acab57d132de3def05d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.broadcast(tensor, src, group=&amp;lt;object object&amp;gt;, async_op=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#broadcast&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42f137f701d871ed16f93e8f54ccf11f3751a266" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.broadcast_multigpu(tensor_list, src, group=&amp;lt;object object&amp;gt;, async_op=False, src_tensor=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#broadcast_multigpu&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a91a9c5b16b5a59e71ee3db5306f6bfcf11d1b07" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.gather(tensor, gather_list=None, dst=0, group=&amp;lt;object object&amp;gt;, async_op=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#gather&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="469f0c245793ba3173d50a4ba6d0d4b02a50ac40" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.get_backend(group=&amp;lt;object object&amp;gt;)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#get_backend&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9abfee4a0b4cccfc17184dd0b1cc26e5d371ee3" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.get_rank(group=&amp;lt;object object&amp;gt;)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#get_rank&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d2f006f10e722cd486cd5167f1f023ac4348cde" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.get_world_size(group=&amp;lt;object object&amp;gt;)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#get_world_size&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3cd2bdef011082ccaf0f6cdb5ff29f262f1a95e0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.init_process_group(backend, init_method=None, timeout=datetime.timedelta(0, 1800), world_size=-1, rank=-1, store=None, group_name='')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#init_process_group&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be9e65a88a9fe81456b9d46075c4010654d4e9b0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.irecv(tensor, src, group=&amp;lt;object object&amp;gt;, tag=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#irecv&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20f496294e21fb47e152e675602dbf3c461a9b08" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.is_available()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed.html#is_available&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.distributed.is_available()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed.html#is_available&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="223963009f0daaa6463b96377bfe6ba435636eb6" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.is_initialized()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#is_initialized&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.distributed.is_initialized()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#is_initialized&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="cbd076810efd1ed9ebbabe499f72753a91996038" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.is_mpi_available()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#is_mpi_available&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.distributed.is_mpi_available()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#is_mpi_available&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="db46fe559b0d0bbdf0cef5a5524c681f3d238f08" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.is_nccl_available()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#is_nccl_available&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.distributed.is_nccl_available()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#is_nccl_available&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e6b9418c661191c8470ab193315235ef4714a868" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.isend(tensor, dst, group=&amp;lt;object object&amp;gt;, tag=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#isend&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9dd059c98fffcac9f54ce1694e15b99004a8591e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.launch&lt;/code&gt; is a module that spawns up multiple distributed training processes on each of the training nodes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00f170d324ae5b762271dfa97f204b0ab1323083" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.new_group(ranks=None, timeout=datetime.timedelta(0, 1800), backend=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#new_group&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c722cbc71a64e0dc42cb9a9d3c7a5edc03b0d4ef" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.recv(tensor, src=None, group=&amp;lt;object object&amp;gt;, tag=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#recv&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4934f4472f321622371e7a7b50861754714e2974" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.reduce(tensor, dst, op=ReduceOp.SUM, group=&amp;lt;object object&amp;gt;, async_op=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#reduce&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4853070b0ea1c763754c27135933c602998a4e60" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.reduce_multigpu(tensor_list, dst, op=ReduceOp.SUM, group=&amp;lt;object object&amp;gt;, async_op=False, dst_tensor=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#reduce_multigpu&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73023ab881e640865f6cc8d6a5f7e0c4057841ad" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.reduce_scatter(output, input_list, op=ReduceOp.SUM, group=&amp;lt;object object&amp;gt;, async_op=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#reduce_scatter&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2dbd0e9e1283295f2349e8245482b78e102b7f5f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.reduce_scatter_multigpu(output_tensor_list, input_tensor_lists, op=ReduceOp.SUM, group=&amp;lt;object object&amp;gt;, async_op=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#reduce_scatter_multigpu&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="658d9ec010176f539c7002ca6f7244824cf0ff2e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.rpc.functions.async_execution(fn)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/rpc/functions.html#async_execution&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.distributed.rpc.functions.async_execution(fn)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/rpc/functions.html#async_execution&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="11ee0ae675da3185be2d88cf7686272070008035" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.rpc.get_worker_info(worker_name=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/rpc/api.html#get_worker_info&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.distributed.rpc.get_worker_info(worker_name=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/rpc/api.html#get_worker_info&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0ac681363a6df2035cf0af007fbe15e5f40b1313" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.rpc.init_rpc(name, backend=None, rank=-1, world_size=None, rpc_backend_options=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/rpc.html#init_rpc&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a807f1699fa2b1f80a8a85a3c47163cacb1811a" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.rpc.remote(to, func, args=None, kwargs=None, timeout=-1.0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/rpc/api.html#remote&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4298605ee9a8f80fa78f8bafe3d0d10bc0b63530" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.rpc.rpc_async(to, func, args=None, kwargs=None, timeout=-1.0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/rpc/api.html#rpc_async&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ea65440f151425bd963fae7e719909e0e6f7799" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.rpc.rpc_sync(to, func, args=None, kwargs=None, timeout=-1.0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/rpc/api.html#rpc_sync&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1578868b0db95ef02e8c1751bf13334567357d8" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.rpc.shutdown(graceful=True)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/rpc/api.html#shutdown&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.distributed.rpc.shutdown(graceful=True)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/rpc/api.html#shutdown&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="74962bc84981f59ffb46c79d8d0a32c1fa2c88fb" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.scatter(tensor, scatter_list=None, src=0, group=&amp;lt;object object&amp;gt;, async_op=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#scatter&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a91666abb9d1adeac875045b37d1d67269e7268" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed.send(tensor, dst, group=&amp;lt;object object&amp;gt;, tag=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#send&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b242b4c4d95c3dfc78fd815399bf2a8ab4321962" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.distributed&lt;/code&gt; supports three built-in backends, each with different capabilities. The table below shows which functions are available for use with CPU / CUDA tensors. MPI supports CUDA only if the implementation used to build PyTorch supports it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8cbefef3cb884be3385871dce8b2b62386448a14" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.einsum(equation, *operands) &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#einsum&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="640fe0a067d6b473ac9256af65e952ac6dfc3b61" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.float16&lt;/code&gt; or &lt;code&gt;torch.half&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bae15d4af90dddb94594a94fec29f67ac605b467" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.float32&lt;/code&gt; or &lt;code&gt;torch.float&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90d6fe76faa60bedbd01aec13dc05b425977c0c5" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.float64&lt;/code&gt; or &lt;code&gt;torch.double&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="265f8d449a3becac9b19de67b27384583c69e026" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.futures.collect_all(futures: List[torch.jit.Future]) &amp;rarr; torch.futures.Future[List[torch.jit.Future]]&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/futures.html#collect_all&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc976900f35641949861ea9c8ea17e248ec3810f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.futures.wait_all(futures: List[torch.jit.Future]) &amp;rarr; List&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/futures.html#wait_all&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae80701e04934a777dbdb12d87e5a0f70bd523c5" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.get_rng_state() &amp;rarr; torch.Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/random.html#get_rng_state&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3bcc059f1d0a236e31a5f5312334d77b1ac57459" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.hub.download_url_to_file(url, dst, hash_prefix=None, progress=True)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/hub.html#download_url_to_file&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f87f9cf1e2fb7ea9e5ce5d50dcecf4a61cc11583" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.hub.get_dir()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/hub.html#get_dir&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.hub.get_dir()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/hub.html#get_dir&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6f4fba1da5aa27b4afa12ceb8026cb1b5c9a7926" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.hub.help(github, model, force_reload=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/hub.html#help&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="882b251a8fb497576db4d5562fe368823616bfec" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.hub.list(github, force_reload=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/hub.html#list&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5cd79bde08bc8ad0034543204f4d73cd57529deb" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.hub.load(repo_or_dir, model, *args, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/hub.html#load&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79c43b2a087c0324bade258ba72699891cf8e21a" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.hub.load_state_dict_from_url(url, model_dir=None, map_location=None, progress=True, check_hash=False, file_name=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/hub.html#load_state_dict_from_url&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d5ca2b155b44bdba1204740a35f42adbc43fcba" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.hub.set_dir(d)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/hub.html#set_dir&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.hub.set_dir(d)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/hub.html#set_dir&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c5f8c8ccc73401651bfcc5f84e5b8bd9b3b988f2" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.index_add_()&lt;/code&gt; when called on a CUDA tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8c9e450410f2773a3b1ffb535039963fc75b581" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.initial_seed() &amp;rarr; int&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/random.html#initial_seed&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2618a717b800b2250c20f08796353ec5f6174dc" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.int16&lt;/code&gt; or &lt;code&gt;torch.short&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c846dd030e173dece1f667ac83f5f7c89e7ef730" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.int32&lt;/code&gt; or &lt;code&gt;torch.int&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f84a6d005309b8b164f747fff43a7112692349b3" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.int64&lt;/code&gt; or &lt;code&gt;torch.long&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d7902807a818755d110fce5fb71486036a8b000" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.is_deterministic()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch.html#is_deterministic&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.is_deterministic()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch.html#is_deterministic&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b61e78ddb3d215366857032848241968e697c5cf" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.is_storage(obj)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch.html#is_storage&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.is_storage(obj)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch.html#is_storage&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3fba0f4d5b1df772c7aadec0c1a6d0985cd38b1a" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.is_tensor(obj)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch.html#is_tensor&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.is_tensor(obj)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch.html#is_tensor&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e0e4a4b6b75b92120aeb93fcdb25e4b132a47ecd" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.istft(input: torch.Tensor, n_fft: int, hop_length: Optional[int] = None, win_length: Optional[int] = None, window: Optional[torch.Tensor] = None, center: bool = True, normalized: bool = False, onesided: Optional[bool] = None, length: Optional[int] = None, return_complex: bool = False) &amp;rarr; torch.Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#istft&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89e22ec54610807a0b00f1d4c91a1d7ec876f10a" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.jit.export(fn)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/_jit_internal.html#export&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.jit.export(fn)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/_jit_internal.html#export&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b8bbb3f29cb40c5d3ea9776b88cf43c34c1878da" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.jit.fork(func, *args, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/jit/_async.html#fork&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="421559b3abd5edb03900fba11315d83fc334603d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.jit.ignore(drop=False, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/_jit_internal.html#ignore&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eeb12aa66d7656a4ffc0d96d046cf3b6b08a0bde" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.jit.is_scripting()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/_jit_internal.html#is_scripting&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.jit.is_scripting()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/_jit_internal.html#is_scripting&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f88e9a93ad8baaaea0c628df0a8e7ac2c56e5c41" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.jit.load(f, map_location=None, _extra_files=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/jit/_serialization.html#load&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e92c3fdd876652458f659e7da2613f06913984b5" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.jit.save(m, f, _extra_files=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/jit/_serialization.html#save&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6643232796915d1c4cfa96d674412c4c0bb284ea" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.jit.script(obj, optimize=None, _frames_up=0, _rcb=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/jit/_script.html#script&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4db5d8c45560a499d468c5dac1c897f99ebef493" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.jit.script&lt;/code&gt; can be used as a function for modules and functions, and as a decorator &lt;code&gt;@torch.jit.script&lt;/code&gt; for &lt;a href=&quot;../jit_language_reference#id2&quot;&gt;TorchScript Classes&lt;/a&gt; and functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a98b44186e36671ec40c3bdafe708c3fee23035e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.jit.trace(func, example_inputs, optimize=None, check_trace=True, check_inputs=None, check_tolerance=1e-05, strict=True, _force_outplace=False, _module_class=None, _compilation_unit=&amp;lt;torch._C.CompilationUnit object&amp;gt;)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/jit/_trace.html#trace&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9049933bf5baeb51bda091d7ad902658b9ddde4" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.jit.trace_module(mod, inputs, optimize=None, check_trace=True, check_inputs=None, check_tolerance=1e-05, strict=True, _force_outplace=False, _module_class=None, _compilation_unit=&amp;lt;torch._C.CompilationUnit object&amp;gt;)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/jit/_trace.html#trace_module&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="909e5d79046847b4d02782a7a02f0a2ed016af7c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.jit.unused(fn)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/_jit_internal.html#unused&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.jit.unused(fn)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/_jit_internal.html#unused&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f65c9de77cddf9268ba06604577821b9c763e902" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.jit.wait(future)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/jit/_async.html#wait&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.jit.wait(future)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/jit/_async.html#wait&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="fb47c5bcc3ae1dfb1d388e26ba7411471ab097bf" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.load(f, map_location=None, pickle_module=&amp;lt;module 'pickle' from '/opt/conda/lib/python3.6/pickle.py'&amp;gt;, **pickle_load_args)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/serialization.html#load&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f43737887598a9e805be62f92deca699d0575a2" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.lobpcg(A: torch.Tensor, k: Optional[int] = None, B: Optional[torch.Tensor] = None, X: Optional[torch.Tensor] = None, n: Optional[int] = None, iK: Optional[torch.Tensor] = None, niter: Optional[int] = None, tol: Optional[float] = None, largest: Optional[bool] = None, method: Optional[str] = None, tracker: None = None, ortho_iparams: Optional[Dict[str, int]] = None, ortho_fparams: Optional[Dict[str, float]] = None, ortho_bparams: Optional[Dict[str, bool]] = None) &amp;rarr; Tuple[torch.Tensor, torch.Tensor]&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/_lobpcg.html#lobpcg&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0bea827671aef5f3b7eda50b4794348264f9aff5" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.lu_unpack(LU_data, LU_pivots, unpack_data=True, unpack_pivots=True)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#lu_unpack&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d5a6b9339a9ae4c05a5ba1a9d565042e21e439d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.manual_seed(seed) &amp;rarr; torch._C.Generator&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/random.html#manual_seed&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="073d41ae4569e0590b24bb02a2cde22f383b83d9" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.meshgrid(*tensors)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#meshgrid&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.meshgrid(*tensors)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#meshgrid&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a39a57d1a7c56039fc95abb2d9bced03e8b97998" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.FractionalMaxPool3d&lt;/code&gt; when called on a CUDA tensor that requires grad</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2ef2c94f97ed017c925779284bb77ad0ca08325" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.ModuleList&lt;/code&gt; which can be used in a TorchScript for loop</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32366e9745ef65d7bfb28a4d81602df1879fc1f0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.adaptive_avg_pool2d(input, output_size)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#adaptive_avg_pool2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91c0ea25976bc55d2262d00f521746f256fd7d87" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.adaptive_avg_pool3d(input, output_size)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#adaptive_avg_pool3d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1097d0a9532bd8fca9736e541af64e621dd46ea" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.affine_grid(theta, size, align_corners=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#affine_grid&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c10efc3580c8c69cc035cb33b2726bd8f14a73ab" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.alpha_dropout(input, p=0.5, training=False, inplace=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#alpha_dropout&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9e17e7f47d7822e2cc0d473c5d222b14fdb92ae" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.batch_norm(input, running_mean, running_var, weight=None, bias=None, training=False, momentum=0.1, eps=1e-05)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#batch_norm&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f5717edf64a59d5e363eebc9908da8813501fda" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.bilinear(input1, input2, weight, bias=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#bilinear&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="59ddc7997f3b59e0fae45c87ee15abd7cfb5c780" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.binary_cross_entropy(input, target, weight=None, size_average=None, reduce=None, reduction='mean')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#binary_cross_entropy&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d7201823c06556ca24e08ebd1f5fb4265f72f2b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.binary_cross_entropy_with_logits(input, target, weight=None, size_average=None, reduce=None, reduction='mean', pos_weight=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#binary_cross_entropy_with_logits&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f9da1009f60918b558c97a1d7a7e883d1c08ef5" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.celu(input, alpha=1., inplace=False) &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#celu&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="33d37a2b8a8128d94d1481492dac9ef306f0a856" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.cosine_embedding_loss(input1, input2, target, margin=0, size_average=None, reduce=None, reduction='mean') &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#cosine_embedding_loss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57abf7da230c9f41633856a8b01cff56c970873e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.cross_entropy(input, target, weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#cross_entropy&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1407e69c5d1e13d69f6e78ff47b7322aba83bca" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.ctc_loss(log_probs, targets, input_lengths, target_lengths, blank=0, reduction='mean', zero_infinity=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#ctc_loss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f969e2514bd7bfecbf147a73c1d2c27799a7bb5f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.dropout(input, p=0.5, training=True, inplace=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#dropout&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6dc24391ef1a7c85edc1df1e473c9eaf7bb6c02" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.dropout2d(input, p=0.5, training=True, inplace=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#dropout2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="616431983c70ac7b49c82cdf658d71df42a37921" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.dropout3d(input, p=0.5, training=True, inplace=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#dropout3d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6423f00d771b3620d1b3b711d04b3367cc6b7f97" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.elu(input, alpha=1.0, inplace=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#elu&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="066d8804893169dfbca3fe7dd9656b071610464f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.embedding(input, weight, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#embedding&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fe5f0a3587fe920a916a80da67623f5a29b0698" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.embedding_bag(input, weight, offsets=None, max_norm=None, norm_type=2, scale_grad_by_freq=False, mode='mean', sparse=False, per_sample_weights=None, include_last_offset=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#embedding_bag&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8214fa8ec6f51b9ba17070449e398de1a1a749fb" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.feature_alpha_dropout(input, p=0.5, training=False, inplace=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#feature_alpha_dropout&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39356278d3eb3659a3cd4fb5a8875a52d82b1225" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.fold(input, output_size, kernel_size, dilation=1, padding=0, stride=1)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#fold&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89c06fb7800616c516855b4f04ceecdc17518e9f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.gelu(input) &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#gelu&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a218695613bb5a0de8369ed33bfc9afab383391" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.glu(input, dim=-1) &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#glu&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7021625a38b746ce1a39ee32b502f2a6db9c4585" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.grid_sample(input, grid, mode='bilinear', padding_mode='zeros', align_corners=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#grid_sample&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a060aa4e1d34c9907ee63c0b90e99edc50dbbb3" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.gumbel_softmax(logits, tau=1, hard=False, eps=1e-10, dim=-1)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#gumbel_softmax&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5cda7558b3ad9b28cbdef77c8deaf73ae843265e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.hardshrink(input, lambd=0.5) &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#hardshrink&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a7788357e1132c7c9f4fa67b9498a151b9b5344" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.hardsigmoid(input) &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#hardsigmoid&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3d47479a5aaf650bd1b5e35f8569bccb683bc13" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.hardswish(input: torch.Tensor, inplace: bool = False) &amp;rarr; torch.Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#hardswish&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e678c28b805974934fa864eaa15336e3e3c6f449" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.hardtanh(input, min_val=-1., max_val=1., inplace=False) &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#hardtanh&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58d4e43d719885efde48902367d9278eb45afaec" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.hinge_embedding_loss(input, target, margin=1.0, size_average=None, reduce=None, reduction='mean') &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#hinge_embedding_loss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50068fafd498873bbc84c37c079bdad47af2fd62" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.instance_norm(input, running_mean=None, running_var=None, weight=None, bias=None, use_input_stats=True, momentum=0.1, eps=1e-05)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#instance_norm&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51feb15b8eec41004d8f24c92329feec6a5d9a4b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.interpolate(input, size=None, scale_factor=None, mode='nearest', align_corners=None, recompute_scale_factor=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#interpolate&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4604fd22bca040ed4adef631c4303a0928807837" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.kl_div(input, target, size_average=None, reduce=None, reduction='mean', log_target=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#kl_div&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ce8753729c7c13600dbf6967ed8327871c4593f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.l1_loss(input, target, size_average=None, reduce=None, reduction='mean') &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#l1_loss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="042a048fb27abd8cb71530f91c0f8ea35ccf4c3f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.layer_norm(input, normalized_shape, weight=None, bias=None, eps=1e-05)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#layer_norm&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee6d48c9626543647597f538ce12bde573f38c3b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.leaky_relu(input, negative_slope=0.01, inplace=False) &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#leaky_relu&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4cf8df1543c4662c88c825d378daccd8af5cac9" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.linear(input, weight, bias=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#linear&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1894e3d0ea0f07955092bee7408de704155bb002" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.local_response_norm(input, size, alpha=0.0001, beta=0.75, k=1.0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#local_response_norm&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="30f3ecb91a729dbee3572f54bfcb95d8e01f9c7f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.log_softmax(input, dim=None, _stacklevel=3, dtype=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#log_softmax&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="972472a778af86e2cc6ab6c107489a0f2bbf470b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.lp_pool1d(input, norm_type, kernel_size, stride=None, ceil_mode=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#lp_pool1d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fdc0f3b7e0449603fc73493406027c87149dbf3" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.lp_pool2d(input, norm_type, kernel_size, stride=None, ceil_mode=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#lp_pool2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0958859b9ae499a4857d4cd6aaec3f5f14bd2c86" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.margin_ranking_loss(input1, input2, target, margin=0, size_average=None, reduce=None, reduction='mean') &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#margin_ranking_loss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2336c5e17dc37a4bcd303ad18064b289aec7a00" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.max_unpool1d(input, indices, kernel_size, stride=None, padding=0, output_size=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#max_unpool1d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="909e9fe0f0dd81343d67d3049d4157cb713660c2" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.max_unpool2d(input, indices, kernel_size, stride=None, padding=0, output_size=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#max_unpool2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ff10e746b2a75339884b3a9e908991fdf3966f4" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.max_unpool3d(input, indices, kernel_size, stride=None, padding=0, output_size=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#max_unpool3d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="236f40331ff3004b076767f9b10c6574701143b0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.mse_loss(input, target, size_average=None, reduce=None, reduction='mean') &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#mse_loss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8eeb3878caecd3953dc4e0e2c213444e69c755e0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.multi_margin_loss(input, target, p=1, margin=1.0, weight=None, size_average=None, reduce=None, reduction='mean')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#multi_margin_loss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1ee4be3b183fc3aa98b897157f8528b20c0ab5e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.multilabel_margin_loss(input, target, size_average=None, reduce=None, reduction='mean') &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#multilabel_margin_loss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a0ce36944943aeea79ad873bdc50b48d24a9813" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.multilabel_soft_margin_loss(input, target, weight=None, size_average=None) &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#multilabel_soft_margin_loss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf1e6a52728af5a23fdafaff75cb840fbffcb4b7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.nll_loss(input, target, weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#nll_loss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b1d925500bf42746b1b5d13e110a776e5606671" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.normalize(input, p=2, dim=1, eps=1e-12, out=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#normalize&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93db9f8b73ef84aa64b0ef7c4aa681dfd9d1e05b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.pairwise_distance(x1, x2, p=2.0, eps=1e-06, keepdim=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#pairwise_distance&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5170cc63198565dc974ddde740562cc7342b749a" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.poisson_nll_loss(input, target, log_input=True, full=False, size_average=None, eps=1e-08, reduce=None, reduction='mean')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#poisson_nll_loss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d54df6a29bf6ce2dd719fcad0f54888591eb1141" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.prelu(input, weight) &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#prelu&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="414a24a106fc3b57b23f73bd9ef56f10b48b500d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.relu(input, inplace=False) &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#relu&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08c43c85b6fec232c61ab3d0fac43966e9dca202" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.relu6(input, inplace=False) &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#relu6&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="363444915890f651770dba4e0ee139a8bd0e34ad" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.rrelu(input, lower=1./8, upper=1./3, training=False, inplace=False) &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#rrelu&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="988850f057511c9e65c7596f53b05e71f72224e3" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.selu(input, inplace=False) &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#selu&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a67420270ae790a8aafa44865eaff88ba0d203f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.sigmoid(input) &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#sigmoid&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0ba03acac585036f1c75ac22544f646935e1e39" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.silu(input, inplace=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#silu&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8976e3b61e7e02e09db919b7126ee6c1b55242b5" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.smooth_l1_loss(input, target, size_average=None, reduce=None, reduction='mean', beta=1.0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#smooth_l1_loss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b11cb9c00fdb5d5d830ce06235b6b66872822b1a" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.soft_margin_loss(input, target, size_average=None, reduce=None, reduction='mean') &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#soft_margin_loss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d7a1c434aa606493bf190a0bf88a2893392f5f51" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.softmax(input, dim=None, _stacklevel=3, dtype=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#softmax&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="185fc46c45a103fa23ebbf763c968235e69d4f91" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.softmin(input, dim=None, _stacklevel=3, dtype=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#softmin&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d76065e3268c5e424219969024a1ca1d8873a52e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.softsign(input) &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#softsign&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="850af8d2773f3c55122e00b4af5eca41549cfe3a" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.tanh(input) &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#tanh&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1d3cdf7abf7ca22a35e5af528ba4719fba901cb" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.tanhshrink(input) &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#tanhshrink&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10b4e0d06c12b3eca2b5536d2f4dd8e12f1afe63" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.triplet_margin_loss(anchor, positive, negative, margin=1.0, p=2, eps=1e-06, swap=False, size_average=None, reduce=None, reduction='mean')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#triplet_margin_loss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0d87f333f2566c2b6cf4938778c9c85531c6c10" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.triplet_margin_with_distance_loss(anchor, positive, negative, *, distance_function=None, margin=1.0, swap=False, reduction='mean')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#triplet_margin_with_distance_loss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16ab53e73c0ea07934feaf16eb7a2b3412c8c52d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.unfold(input, kernel_size, dilation=1, padding=0, stride=1)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#unfold&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e53c770d65bb0ba2d44ae8c0c45269c018a3cfbe" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.upsample(input, size=None, scale_factor=None, mode='nearest', align_corners=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#upsample&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35c396cdfcf1f7742a14e8fe14ea4839369708d7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.upsample_bilinear(input, size=None, scale_factor=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#upsample_bilinear&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="46210cb9fc54c5c8d19c399913fa6564ee472fa6" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.functional.upsample_nearest(input, size=None, scale_factor=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/functional.html#upsample_nearest&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f6616285fb50e039b0a50f40c8cc182e30b9ad3" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.init.calculate_gain(nonlinearity, param=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#calculate_gain&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5e152873cf5a634ac4fc22712597672cedec772" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.init.constant_(tensor, val)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#constant_&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e07661fc90ed5f8c330b4c199c178b913c9f1c7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.init.dirac_(tensor, groups=1)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#dirac_&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f79be36611abc8d4a155dd9204a72975ac5e4773" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.init.eye_(tensor)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#eye_&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.nn.init.eye_(tensor)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#eye_&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c2bf176e81d0d3dc053d580d4a2bca53d53776a5" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.init.kaiming_normal_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#kaiming_normal_&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="829f255be8c47a0cc32b32e3e7a39b50f03bbb28" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.init.kaiming_uniform_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#kaiming_uniform_&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d74bb441e80c3db03c439b39588a3d7289372829" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.init.normal_(tensor, mean=0.0, std=1.0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#normal_&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cda901e36d8a0dea4c9edd368b65c875ba5b5524" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.init.ones_(tensor)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#ones_&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.nn.init.ones_(tensor)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#ones_&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="76cd921a26c8bc82c432454c6208f7007838adc0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.init.orthogonal_(tensor, gain=1)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#orthogonal_&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d09409fb3770c88ebcd026eab2c58df33a7730e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.init.sparse_(tensor, sparsity, std=0.01)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#sparse_&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6ef0d5afce7bb2d1cbfe668611dc89920c0ae59" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.init.uniform_(tensor, a=0.0, b=1.0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#uniform_&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85278dfd6aeb0f31979ad65f57d07305852e15d6" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.init.xavier_normal_(tensor, gain=1.0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#xavier_normal_&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b21f1cd018490607178af5dd8bf83497f69a9ed" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.init.xavier_uniform_(tensor, gain=1.0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#xavier_uniform_&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a46d62f5de757e1314a9fdb13f301b29dd3064bb" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.init.zeros_(tensor)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#zeros_&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.nn.init.zeros_(tensor)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#zeros_&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="cabbf4b7897497900a45a7b2817218dc42a094a4" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.parallel.data_parallel(module, inputs, device_ids=None, output_device=None, dim=0, module_kwargs=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/parallel/data_parallel.html#data_parallel&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1820a94045081d62850e6015322b8f1bcd529902" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.quantized.functional.adaptive_avg_pool2d(input: torch.Tensor, output_size: None) &amp;rarr; torch.Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/quantized/functional.html#adaptive_avg_pool2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e49a56be44c1c84f8d24fa8b0f0a773df40282a1" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.quantized.functional.avg_pool2d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/quantized/functional.html#avg_pool2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc695b6cf5e70404648a96381625d3b4242dfbc0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.quantized.functional.conv1d(input, weight, bias, stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', scale=1.0, zero_point=0, dtype=torch.quint8)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/quantized/functional.html#conv1d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4fafcb23bac88610267cfd4c65156bfb6814790" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.quantized.functional.conv2d(input, weight, bias, stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', scale=1.0, zero_point=0, dtype=torch.quint8)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/quantized/functional.html#conv2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a1f61a8e9a1e417e172cf9ee69a3ac703666b76c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.quantized.functional.conv3d(input, weight, bias, stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', scale=1.0, zero_point=0, dtype=torch.quint8)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/quantized/functional.html#conv3d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd0daa95478860b380dc09345e82221940cc1573" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.quantized.functional.hardswish(input: torch.Tensor, scale: float, zero_point: int) &amp;rarr; torch.Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/quantized/functional.html#hardswish&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3111ef1fc4e980e9ab5ca9059aba510612419184" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.quantized.functional.interpolate(input, size=None, scale_factor=None, mode='nearest', align_corners=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/quantized/functional.html#interpolate&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a74909e8cec504214450b346ecf69f391517d12" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.quantized.functional.linear(input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None, scale: Optional[float] = None, zero_point: Optional[int] = None) &amp;rarr; torch.Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/quantized/functional.html#linear&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73c3f5a9236c23bb8967520b8b62180ad2c998ea" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.quantized.functional.max_pool2d(input, kernel_size, stride=None, padding=0, dilation=1, ceil_mode=False, return_indices=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/quantized/functional.html#max_pool2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c862b119f84e81983c7b7be77dd88a11b46ed28" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.quantized.functional.relu(input, inplace=False) &amp;rarr; Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/quantized/functional.html#relu&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8d860cd9cbb88773d5c3ccd609b1b067ad8e1ec" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.quantized.functional.upsample(input, size=None, scale_factor=None, mode='nearest', align_corners=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/quantized/functional.html#upsample&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="580dc9c2b76d8a1672544e8ee223a9a9de122d26" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.quantized.functional.upsample_bilinear(input, size=None, scale_factor=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/quantized/functional.html#upsample_bilinear&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a1660fcc28bce5d877097c2d858685ee9ac889c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.quantized.functional.upsample_nearest(input, size=None, scale_factor=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/quantized/functional.html#upsample_nearest&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee48c314ebbb974007123f98f539ecffcf9858aa" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.utils.clip_grad_norm_(parameters: Union[torch.Tensor, Iterable[torch.Tensor]], max_norm: float, norm_type: float = 2.0) &amp;rarr; torch.Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/clip_grad.html#clip_grad_norm_&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c6b682d79cb2d7285847c9284685f7cc01c3e7c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.utils.clip_grad_value_(parameters: Union[torch.Tensor, Iterable[torch.Tensor]], clip_value: float) &amp;rarr; None&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/clip_grad.html#clip_grad_value_&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d2fddcb8f6b20b88995ff4d154426897cebd261" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.utils.parameters_to_vector(parameters: Iterable[torch.Tensor]) &amp;rarr; torch.Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/convert_parameters.html#parameters_to_vector&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="19a161f43edebdc3fe1ed0ffe30c004ecf54c828" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.utils.prune.custom_from_mask(module, name, mask)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/prune.html#custom_from_mask&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db191bbfd3345206e1e35b684c02fd017ba13f9f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.utils.prune.global_unstructured(parameters, pruning_method, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/prune.html#global_unstructured&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc9622697e3c53544bdd5add28b3a2c57c2527ff" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.utils.prune.is_pruned(module)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/prune.html#is_pruned&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.nn.utils.prune.is_pruned(module)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/prune.html#is_pruned&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="96abbe2d8d461fb8bd2ee1faf7eb77f02db4de18" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.utils.prune.l1_unstructured(module, name, amount)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/prune.html#l1_unstructured&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7d651eb7a59a2dc63e2fc226de440a5894c6c35" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.utils.prune.ln_structured(module, name, amount, n, dim)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/prune.html#ln_structured&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd20f8272b0cdf40603ce7846f3ecd5e93a2297d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.utils.prune.random_structured(module, name, amount, dim)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/prune.html#random_structured&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71942a64f4dce21658109edbb7ad07b1ac54058d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.utils.prune.random_unstructured(module, name, amount)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/prune.html#random_unstructured&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1e7eeb03ba5f784fbc103d766bcd491a80e68b6" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.utils.prune.remove(module, name)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/prune.html#remove&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="593e2b8edbe9f814474088519b5d51467a8371e0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.utils.remove_spectral_norm(module: T_module, name: str = 'weight') &amp;rarr; T_module&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/spectral_norm.html#remove_spectral_norm&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28b96908ea924c1b164eb56c90b4f06cbbbb7ac7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.utils.remove_weight_norm(module: T_module, name: str = 'weight') &amp;rarr; T_module&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/weight_norm.html#remove_weight_norm&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f70a4d724e38fb65885f35aa43b8a140dbffcef2" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=False, enforce_sorted=True)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/rnn.html#pack_padded_sequence&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e6fdd6a0dda25c6ab4d31cc62e42257e961a19a" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.utils.rnn.pack_sequence(sequences, enforce_sorted=True)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/rnn.html#pack_sequence&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="044c8f76ea2d98a2cab6ae17546088498a4b752d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.utils.rnn.pad_packed_sequence(sequence, batch_first=False, padding_value=0.0, total_length=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/rnn.html#pad_packed_sequence&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a814f84114cb8c05fa4c22be341926d765e90456" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.utils.rnn.pad_sequence(sequences, batch_first=False, padding_value=0.0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/rnn.html#pad_sequence&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="881e9c21d63a899692b7a30837ad6eba7a8c7f16" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.utils.spectral_norm(module: T_module, name: str = 'weight', n_power_iterations: int = 1, eps: float = 1e-12, dim: Optional[int] = None) &amp;rarr; T_module&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/spectral_norm.html#spectral_norm&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26317539c048e00421573ffe352a58a215f08fe6" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.utils.vector_to_parameters(vec: torch.Tensor, parameters: Iterable[torch.Tensor]) &amp;rarr; None&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/convert_parameters.html#vector_to_parameters&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dcc88b942534bdb73dedece8f4a1cbf8e3e89bb5" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.nn.utils.weight_norm(module: T_module, name: str = 'weight', dim: int = 0) &amp;rarr; T_module&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/weight_norm.html#weight_norm&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2501cdd2c8ea16585c06298503d128b6a0ffd1cd" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.norm(input, p='fro', dim=None, keepdim=False, out=None, dtype=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#norm&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="acdcacd99d319a55aa1c12b5685ea208060bb46d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.onnx.export(model, args, f, export_params=True, verbose=False, training=TrainingMode.EVAL, input_names=None, output_names=None, aten=False, export_raw_ir=False, operator_export_type=None, opset_version=None, _retain_param_name=True, do_constant_folding=True, example_outputs=None, strip_doc_string=True, dynamic_axes=None, keep_initializers_as_inputs=None, custom_opsets=None, enable_onnx_checker=True, use_external_data_format=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/onnx.html#export&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03322601d6585b4a92619debfccba83a650e2502" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.onnx.export_to_pretty_string(*args, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/onnx.html#export_to_pretty_string&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e25b4aec2e26a0048d40d93bf92b951ca79caac4" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.onnx.is_in_onnx_export()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/onnx.html#is_in_onnx_export&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.onnx.is_in_onnx_export()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/onnx.html#is_in_onnx_export&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5a40567375223347d13ca6f163cb9d650229468a" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.onnx.operators.shape_as_tensor(x)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/onnx/operators.html#shape_as_tensor&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.onnx.operators.shape_as_tensor(x)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/onnx/operators.html#shape_as_tensor&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="976d3f529500cdddc27096243ac8d2a42aa02e7a" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.onnx.register_custom_op_symbolic(symbolic_name, symbolic_fn, opset_version)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/onnx.html#register_custom_op_symbolic&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="815d0399a34390b7363b99b8598c5d34a64d4a72" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.onnx.select_model_mode_for_export(model, mode)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/onnx.html#select_model_mode_for_export&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="59d28dfd09f75864c49c9ad2a7227c7d7578174a" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.pca_lowrank(A, q=None, center=True, niter=2)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/_lowrank.html#pca_lowrank&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03de177ec561a49fdd476ac650a4389100c73080" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.preserve_format&lt;/code&gt;: Used in functions like &lt;code&gt;clone&lt;/code&gt; to preserve the memory format of the input tensor. If input tensor is allocated in dense non-overlapping memory, the output tensor strides will be copied from the input. Otherwise output strides will follow &lt;code&gt;torch.contiguous_format&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb81152ea7d6334b6a16b9c3108f06ba82952254" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.save(obj, f: Union[str, os.PathLike, BinaryIO], pickle_module=&amp;lt;module 'pickle' from '/opt/conda/lib/python3.6/pickle.py'&amp;gt;, pickle_protocol=2, _use_new_zipfile_serialization=True) &amp;rarr; None&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/serialization.html#save&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="149a91842a887af3527d7028eea82d5c2bd4684c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.scatter_add_()&lt;/code&gt; when called on a CUDA tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7829623f67d02ddc28ca91d4d4b46f343d79b572" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.seed() &amp;rarr; int&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/random.html#seed&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="145f4576eacb498e971a1e27b7989cde7e848da6" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.set_default_dtype(d)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch.html#set_default_dtype&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.set_default_dtype(d)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch.html#set_default_dtype&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="10d4c72bdc704e59d50cf2910ff7471a3ab49eca" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.set_default_tensor_type(t)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch.html#set_default_tensor_type&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.set_default_tensor_type(t)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch.html#set_default_tensor_type&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="65c48c613ed4b2f78ed6e02a56b179139c405127" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.set_deterministic(d)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch.html#set_deterministic&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.set_deterministic(d)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch.html#set_deterministic&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1a9084271510ec6bbc33b1814e39096e72ad5953" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/_tensor_str.html#set_printoptions&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13ffc0d262be2520fdff6d4a0f52ba63324ddfab" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.set_rng_state(new_state) &amp;rarr; None&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/random.html#set_rng_state&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed79abf5eac107985737d970652704fa05dc0ade" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.solve(B, A)&lt;/code&gt; can take in 2D inputs &lt;code&gt;B, A&lt;/code&gt; or inputs that are batches of 2D matrices. If the inputs are batches, then returns batched outputs &lt;code&gt;solution, LU&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b665df2b2d96bef5eb69cda0cd781918b869fa3b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.sparse.addmm(mat: torch.Tensor, mat1: torch.Tensor, mat2: torch.Tensor, beta: float = 1.0, alpha: float = 1.0) &amp;rarr; torch.Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/sparse.html#addmm&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa2dfd43ccd4a1a35fc8de1d1304f193c8e2a864" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.sparse.mm(mat1: torch.Tensor, mat2: torch.Tensor) &amp;rarr; torch.Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/sparse.html#mm&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7727e69ca5233c84e597b026bcaedcd72dec04d3" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.sparse.sum(input: torch.Tensor, dim: Optional[Tuple[int]] = None, dtype: Optional[int] = None) &amp;rarr; torch.Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/sparse.html#sum&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e65754e6516685feae5bc613180e4719d49f3f8" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.split(tensor, split_size_or_sections, dim=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#split&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e35490d70ccd40103394665a6c8f64a5fda9d8c1" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.stft(input: torch.Tensor, n_fft: int, hop_length: Optional[int] = None, win_length: Optional[int] = None, window: Optional[torch.Tensor] = None, center: bool = True, pad_mode: str = 'reflect', normalized: bool = False, onesided: Optional[bool] = None, return_complex: Optional[bool] = None) &amp;rarr; torch.Tensor&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#stft&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a3816ac7e969e46494429240e45f840ebeb330a" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.strided&lt;/code&gt; represents dense Tensors and is the memory layout that is most commonly used. Each strided tensor has an associated &lt;code&gt;torch.Storage&lt;/code&gt;, which holds its data. These tensors provide multi-dimensional, &lt;a href=&quot;https://en.wikipedia.org/wiki/Stride_of_an_array&quot;&gt;strided&lt;/a&gt; view of a storage. Strides are a list of integers: the k-th stride represents the jump in the memory necessary to go from one element to the next one in the k-th dimension of the Tensor. This concept makes it possible to perform many tensor operations efficiently.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="562d195ae00895df7b44cc1509c8dc7828657990" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.svd_lowrank(A, q=6, niter=2, M=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/_lowrank.html#svd_lowrank&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95d8fe6a396e85b79844a3279acdb3eba5b10f87" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.tensordot(a, b, dims=2)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/functional.html#tensordot&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6a2b543d94504add4daf1a3eaf97669036641b7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.triangular_solve(b, A)&lt;/code&gt; can take in 2D inputs &lt;code&gt;b, A&lt;/code&gt; or inputs that are batches of 2D matrices. If the inputs are batches, then returns batched outputs &lt;code&gt;X&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d3e0234b25f4c9163c86f9066ba6ade5028b7ab" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.utils.bottleneck&lt;/code&gt; is a tool that can be used as an initial step for debugging bottlenecks in your program. It summarizes runs of your script with the Python profiler and PyTorch&amp;rsquo;s autograd profiler.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e9227f91a147c6bfddb1ea807ad178da61c2f01" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.utils.checkpoint.checkpoint(function, *args, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/checkpoint.html#checkpoint&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f35c5fbe34347d80748ad19cf587e88d314a446" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.utils.checkpoint.checkpoint_sequential(functions, segments, input, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/checkpoint.html#checkpoint_sequential&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82743a1bc0d193a8d5c5ef819ec1fa2a75d3a567" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.utils.cpp_extension.BuildExtension(*args, **kwargs) &amp;rarr; None&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/cpp_extension.html#BuildExtension&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1fcb6bd9919299ae2ddc98ca71e5ceaf224bcb1" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.utils.cpp_extension.CUDAExtension(name, sources, *args, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/cpp_extension.html#CUDAExtension&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bacc6afc48e6da0551f4f2b3cb8604b66cb184b0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.utils.cpp_extension.CppExtension(name, sources, *args, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/cpp_extension.html#CppExtension&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa82ce120a2fb2cab4f7a383ceb7f5257beb9cb5" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.utils.cpp_extension.check_compiler_abi_compatibility(compiler) &amp;rarr; bool&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/cpp_extension.html#check_compiler_abi_compatibility&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04175775569bb5f47df2787c65e8108be88d672c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.utils.cpp_extension.include_paths(cuda: bool = False) &amp;rarr; List[str]&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/cpp_extension.html#include_paths&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d2cc603ad32cc623c7afe161c11ea47e80c35fc" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.utils.cpp_extension.is_ninja_available()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/cpp_extension.html#is_ninja_available&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.utils.cpp_extension.is_ninja_available()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/cpp_extension.html#is_ninja_available&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="127692b7ee4252253192d5f2c1ec1661e298d13c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.utils.cpp_extension.load(name, sources: List[str], extra_cflags=None, extra_cuda_cflags=None, extra_ldflags=None, extra_include_paths=None, build_directory=None, verbose=False, with_cuda: Optional[bool] = None, is_python_module=True, keep_intermediates=True)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/cpp_extension.html#load&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc490ba01580aa87b6738971cbd6c2f4a833c59c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.utils.cpp_extension.load_inline(name, cpp_sources, cuda_sources=None, functions=None, extra_cflags=None, extra_cuda_cflags=None, extra_ldflags=None, extra_include_paths=None, build_directory=None, verbose=False, with_cuda=None, is_python_module=True, with_pytorch_error_handling=True, keep_intermediates=True)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/cpp_extension.html#load_inline&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="282b9c63f989793b3e3cc7e3e2e6b74a269f4472" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.utils.cpp_extension.verify_ninja_availability()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/cpp_extension.html#verify_ninja_availability&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;torch.utils.cpp_extension.verify_ninja_availability()&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/cpp_extension.html#verify_ninja_availability&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="87bb3cae7ea056553e89c9188b938e7264f5dd5d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.utils.mobile_optimizer.optimize_for_mobile(script_module, optimization_blocklist: Set[torch._C.MobileOptimizerType] = None, preserved_methods: List[AnyStr] = None, backend: str = 'CPU')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/mobile_optimizer.html#optimize_for_mobile&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0735be3015f610c6bc97e587de840634628e8077" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torch.where(condition)&lt;/code&gt; is identical to &lt;code&gt;torch.nonzero(condition, as_tuple=True)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55e6ef83c7ef85f702c91d8eef5ea0dbd8c749b7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.alexnet(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/alexnet.html#alexnet&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d38d82c4a2980d1cd54f65f24d369937605975c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.densenet121(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/densenet.html#densenet121&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d48becd24b6a141911d63cbcfa4b5388d0e2f2a" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.densenet161(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/densenet.html#densenet161&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c66a106d591302ae9a23564d21b9f0fecca36a45" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.densenet169(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/densenet.html#densenet169&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a4dc470d2c9b1dd63a8b3c3a2f09a2b731ee1ff" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.densenet201(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/densenet.html#densenet201&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d37101a2a2ce0b122b3186b37ea5f3eebbf7af88" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, progress=True, num_classes=91, pretrained_backbone=True, trainable_backbone_layers=3, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/detection/faster_rcnn.html#fasterrcnn_resnet50_fpn&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fddcba641d93f705c38ea5e99e37277ffb808f18" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.detection.keypointrcnn_resnet50_fpn(pretrained=False, progress=True, num_classes=2, num_keypoints=17, pretrained_backbone=True, trainable_backbone_layers=3, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/detection/keypoint_rcnn.html#keypointrcnn_resnet50_fpn&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca21903101f18b0557dcbc8fea49917fe47b38fc" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=False, progress=True, num_classes=91, pretrained_backbone=True, trainable_backbone_layers=3, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/detection/mask_rcnn.html#maskrcnn_resnet50_fpn&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8321d00bdd9e79fbbae3bed723d0da2d8ff44e18" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.detection.retinanet_resnet50_fpn(pretrained=False, progress=True, num_classes=91, pretrained_backbone=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/detection/retinanet.html#retinanet_resnet50_fpn&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e68c6f2f62746247926299a2e294d2b695793904" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.googlenet(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/googlenet.html#googlenet&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c29cab4aa7a85507392da05a8545872aeefa41c6" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.inception_v3(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/inception.html#inception_v3&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0c9417db1439ddf7338a83567afce51a263b5dd" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.mnasnet0_5(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/mnasnet.html#mnasnet0_5&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d47807e0f8165cf93963dfc4dc78e77f742858e1" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.mnasnet0_75(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/mnasnet.html#mnasnet0_75&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5a9e5d5450b4dafb844ae224f4ad180dd226121" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.mnasnet1_0(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/mnasnet.html#mnasnet1_0&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77b69bd7be274f38453186938001d277495a6c2f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.mnasnet1_3(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/mnasnet.html#mnasnet1_3&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="969edc85d9e553749ddbb016e31fdad62783c095" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.mobilenet_v2(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/mobilenet.html#mobilenet_v2&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8bffa4c41d6459f1920f6b09592d01a2d8bed629" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.resnet101(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/resnet.html#resnet101&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f51b7405b05ff1069b3eed30d5d1a4b4a048135" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.resnet152(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/resnet.html#resnet152&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58b4a120cb5b9ef8aa6791731d8b227114babaf4" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.resnet18(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/resnet.html#resnet18&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c548ae7c119869cb346706a64804cd9a2772320" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.resnet34(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/resnet.html#resnet34&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70c0819d42401f678755dd1664c6da919188b89e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.resnet50(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/resnet.html#resnet50&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bcdda78061e32c5045ff0ce9dde8acb096118a2f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.resnext101_32x8d(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/resnet.html#resnext101_32x8d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4cbcacd435d5999826e0ac993eac4f3fc585eeb4" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.resnext50_32x4d(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/resnet.html#resnext50_32x4d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6417c808ce60d23a185910dca6539019af3ba56" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.segmentation.deeplabv3_resnet101(pretrained=False, progress=True, num_classes=21, aux_loss=None, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/segmentation/segmentation.html#deeplabv3_resnet101&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d366590337e483500734a3650d1ef622765c7eb" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.segmentation.deeplabv3_resnet50(pretrained=False, progress=True, num_classes=21, aux_loss=None, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/segmentation/segmentation.html#deeplabv3_resnet50&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69c183fd9ad3fbdedaca14cf2875725c54150e77" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.segmentation.fcn_resnet101(pretrained=False, progress=True, num_classes=21, aux_loss=None, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/segmentation/segmentation.html#fcn_resnet101&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dadae370f707b7834deb997ef740ebf2926cec26" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.segmentation.fcn_resnet50(pretrained=False, progress=True, num_classes=21, aux_loss=None, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/segmentation/segmentation.html#fcn_resnet50&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="985d1d71995c5a858dab5d7f67674d973e8f084d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.shufflenet_v2_x0_5(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/shufflenetv2.html#shufflenet_v2_x0_5&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d06ebbf7a18ac9324d20801b61faff9eb323112e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.shufflenet_v2_x1_0(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/shufflenetv2.html#shufflenet_v2_x1_0&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69605c4002be97c73eb40b6b5dac9238f0a6f129" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.shufflenet_v2_x1_5(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/shufflenetv2.html#shufflenet_v2_x1_5&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2bb85f32d69a2c716a4157554b61ab0a69d223d2" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.shufflenet_v2_x2_0(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/shufflenetv2.html#shufflenet_v2_x2_0&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01dc12333c85efbfdfa76203ff11e0218683f488" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.squeezenet1_0(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/squeezenet.html#squeezenet1_0&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c04456665e568beadaf956c8033bee8db4ce676" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.squeezenet1_1(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/squeezenet.html#squeezenet1_1&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1cd5db2e4fbd76c79a9cd5f06e13284c03c17302" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.vgg11(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/vgg.html#vgg11&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50ac0ac46bd916f5d37b20fddc28e9c32dc160d3" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.vgg11_bn(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/vgg.html#vgg11_bn&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7519bb1b3c7dacdd2e7ab4174d31903bddfe4872" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.vgg13(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/vgg.html#vgg13&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec4029edda490c50f9dfa4eaf54f78b869d1dedb" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.vgg13_bn(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/vgg.html#vgg13_bn&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d89c3bd8e0058098ec4b822cf6070e6491c1046f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.vgg16(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/vgg.html#vgg16&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b33e5eec705427e4d3f1ab25e07ed270b3ac99ea" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.vgg16_bn(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/vgg.html#vgg16_bn&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="563b55e8c50e9495de20d93fa1609d3ca5095650" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.vgg19(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/vgg.html#vgg19&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8d2010441ce8fd04d6bccd5dc17972367f6612e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.vgg19_bn(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/vgg.html#vgg19_bn&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="248d2d3c5cde4f33b37185cfc2f168d45a6085e0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.video.mc3_18(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/video/resnet.html#mc3_18&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="049d72606ad866c4a386e75f3387cf447c24e806" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.video.r2plus1d_18(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/video/resnet.html#r2plus1d_18&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f5b003328cdb0ee7e5456320bb4679a846567da" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.video.r3d_18(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/video/resnet.html#r3d_18&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="976b5b89506d0a20776447fa2c6b030b688bd840" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.wide_resnet101_2(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/resnet.html#wide_resnet101_2&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="883785b05ab2fa730630f3ad88bcabd0f8a7b4f0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;torchvision.models.wide_resnet50_2(pretrained=False, progress=True, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torchvision/models/resnet.html#wide_resnet50_2&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a147531339c74e3b87db4d26b7214df4792298dc" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;total_length&lt;/code&gt; is useful to implement the &lt;code&gt;pack sequence -&amp;gt; recurrent network -&amp;gt; unpack sequence&lt;/code&gt; pattern in a &lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;&lt;code&gt;Module&lt;/code&gt;&lt;/a&gt; wrapped in &lt;a href=&quot;torch.nn.dataparallel#torch.nn.DataParallel&quot;&gt;&lt;code&gt;DataParallel&lt;/code&gt;&lt;/a&gt;. See &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/faq.html#pack-rnn-unpack-with-data-parallelism&quot;&gt;this FAQ section&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7fbb2269f1128397ff52b8755f83fcf30131e444" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;train(mode: bool = True) &amp;rarr; T&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.train&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17490d06aec9bb591bde79be08f472ba510005d3" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;true&lt;/code&gt; if &lt;code&gt;key&lt;/code&gt; was deleted, otherwise &lt;code&gt;false&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73de5004ed63d179d11e7c607cd226ac72fef763" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;type(dst_type: Union[torch.dtype, str]) &amp;rarr; T&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.type&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b726d74ca27828505ae027190d9488e64e8a432c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;unflatten(dim, sizes)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/tensor.html#Tensor.unflatten&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb232cf62834f167804d6c86e5ae22859b7db331" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;unflattened_size&lt;/code&gt; is the new shape of the unflattened dimension of the tensor and it can be a &lt;code&gt;tuple&lt;/code&gt; of ints or &lt;code&gt;torch.Size&lt;/code&gt; for &lt;code&gt;Tensor&lt;/code&gt; input or a &lt;code&gt;NamedShape&lt;/code&gt; (tuple of &lt;code&gt;(name, size)&lt;/code&gt; tuples) for &lt;code&gt;NamedTensor&lt;/code&gt; input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="114ecd93b94acf20f3f824c124da10585acafbf1" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;unify(A, B)&lt;/code&gt; determines which of the names &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;B&lt;/code&gt; to propagate to the outputs. It returns the more &lt;em&gt;specific&lt;/em&gt; of the two names, if they match. If the names do not match, then it errors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f81a8067f75099cdee88dc8df395ee2a70a06955" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;unique(sorted=True, return_inverse=False, return_counts=False, dim=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/tensor.html#Tensor.unique&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f19f4fd7da0a567778731041cc786315cffe617" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;unique_consecutive(return_inverse=False, return_counts=False, dim=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/tensor.html#Tensor.unique_consecutive&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8da2e713f043aee7915ced857730729c9fc23a12" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;update(modules: Mapping[str, torch.nn.modules.module.Module]) &amp;rarr; None&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/container.html#ModuleDict.update&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d3c990fce28e84265072d86fa81e98efcd00c95" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;update(parameters: Mapping[str, Parameter]) &amp;rarr; None&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/container.html#ParameterDict.update&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4d99c2f207829a30f2ddddb647b4a8b864fd17f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;use_external_data_format&lt;/code&gt; argument in export API enables export of models in ONNX external data format. With this option enabled, the exporter stores some model parameters in external binary files, rather than the ONNX file itself. These external binary files are stored in the same location as the ONNX file. Argument &amp;lsquo;f&amp;rsquo; must be a string specifying the location of the model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9356c0eda1c275025f5aa20e4ff2a7158f04f8d7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;use_ninja&lt;/code&gt; (bool): If &lt;code&gt;use_ninja&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; (default), then we attempt to build using the Ninja backend. Ninja greatly speeds up compilation compared to the standard &lt;code&gt;setuptools.build_ext&lt;/code&gt;. Fallbacks to the standard distutils backend if Ninja is not available.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1254a0cf82203e9a1531fc62d7d0d216e9e743f7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;values() &amp;rarr; Iterable[Parameter]&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/container.html#ParameterDict.values&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96bfd43ff7e24163f6d4c88a8036d233913ce8fe" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;values() &amp;rarr; Iterable[torch.nn.modules.module.Module]&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/container.html#ModuleDict.values&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="104e14056b814916b6776efe34cc558abcb82dbd" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;wait() &amp;rarr; T&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/futures.html#Future.wait&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="516fb2fe6efc6e35e85e90b516645bccab59738b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;wait()&lt;/code&gt; - will block the process until the operation is finished.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="941139d436ab4f418d83f1d8c7ec9b9119cbf52b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;wait()&lt;/code&gt; - will block the process until the operation is finished. &lt;code&gt;is_completed()&lt;/code&gt; is guaranteed to return True once it returns.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75193eb58fde7a23d585e351a7da7779cc2d15b2" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;weight&lt;/code&gt; (Tensor): the learnable weights of the module of shape &lt;code&gt;(num_embeddings, embedding_dim)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a60b5944e5c5872c821c93c5da8c56e577b4b1c8" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;window&lt;/code&gt; can be a 1-D tensor of size &lt;code&gt;win_length&lt;/code&gt;, e.g., from &lt;a href=&quot;torch.hann_window#torch.hann_window&quot;&gt;&lt;code&gt;torch.hann_window()&lt;/code&gt;&lt;/a&gt;. If &lt;code&gt;window&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; (default), it is treated as if having</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcb35e51fe3891a319d8cca2cc7d08a9312f5fd0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;zero_grad(set_to_none: bool = False) &amp;rarr; None&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.zero_grad&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e228d56108279e5de96783fa1fcf187bda5858b" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;(string, Module)&lt;/em&gt; &amp;ndash; Tuple containing a name and child module</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fb3c9a95d7120f0c30ae272a854d5feba5d48b6" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;(string, Module)&lt;/em&gt; &amp;ndash; Tuple of name and module</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="319263d4f6bb9e6d32586c5cff620cbc3fa67237" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;(string, Parameter)&lt;/em&gt; &amp;ndash; Tuple containing the name and parameter</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc72ec06d2fb8eafc561c043b35fadba57166206" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;(string, torch.Tensor)&lt;/em&gt; &amp;ndash; Tuple containing the name and buffer</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a754dfd4e3d629d6e648310d555fb7a646535624" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;Beta:&lt;/em&gt; Features are tagged as Beta because the API may change based on user feedback, because the performance needs to improve, or because coverage across operators is not yet complete. For Beta features, we are committing to seeing the feature through to the Stable classification. We are not, however, committing to backwards compatibility.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a298939dfd8866323bf58103d52da9a00fff3eb" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;Module&lt;/em&gt; &amp;ndash; a child module</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55c1945ebbb505a29f113e4158c303559a846bd3" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;Module&lt;/em&gt; &amp;ndash; a module in the network</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7efeeaf6ac232e4e1bd4481ee3ccf55f14e08c1b" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;Parameter&lt;/em&gt; &amp;ndash; module parameter</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1299c276055de8aa531b38f8e62b765ac94d8a5" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;Prototype:&lt;/em&gt; These features are typically not available as part of binary distributions like PyPI or Conda, except sometimes behind run-time flags, and are at an early stage for feedback and testing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4f12aa72178917bae1166015f8ad3889662fd74" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;Stable:&lt;/em&gt; These features will be maintained long-term and there should generally be no major performance limitations or gaps in documentation. We also expect to maintain backwards compatibility (although breaking changes can happen and notice will be given one release ahead of time).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="058a377bedcdaeade66857847812a0e554998ab7" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;returned index satisfies&lt;/em&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2310781c0d4ea448d2442fafbd9795c680825b97" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;script-based&lt;/em&gt; means that the model you are trying to export is a &lt;a href=&quot;jit&quot;&gt;ScriptModule&lt;/a&gt;. &lt;code&gt;ScriptModule&lt;/code&gt; is the core data structure in &lt;code&gt;TorchScript&lt;/code&gt;, and &lt;code&gt;TorchScript&lt;/code&gt; is a subset of Python language, that creates serializable and optimizable models from PyTorch code.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6626f7675f0e61b3b27dbc625972f11d257da92" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;torch.Tensor&lt;/em&gt; &amp;ndash; module buffer</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2908cf8505ca66bca3222f57f081464f869918f4" translate="yes" xml:space="preserve">
          <source>&lt;em&gt;trace-based&lt;/em&gt; means that it operates by executing your model once, and exporting the operators which were actually run during this run. This means that if your model is dynamic, e.g., changes behavior depending on input data, the export won&amp;rsquo;t be accurate. Similarly, a trace is likely to be valid only for a specific input size (which is one reason why we require explicit inputs on tracing.) We recommend examining the model trace and making sure the traced operators look reasonable. If your model contains control flows like for loops and if conditions, &lt;em&gt;trace-based&lt;/em&gt; exporter will unroll the loops and if conditions, exporting a static graph that is exactly the same as this run. If you want to export your model with dynamic control flows, you will need to use the &lt;em&gt;script-based&lt;/em&gt; exporter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3e32b5c7adc9869a8580e1b9e6a76857d105f7c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;**kwargs&lt;/strong&gt; &amp;ndash; For compatibility, may contain the key &lt;code&gt;async&lt;/code&gt; in place of the &lt;code&gt;non_blocking&lt;/code&gt; argument.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65f37625b43f8177a68af42c34ddcf34a3a157c3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;**kwargs&lt;/strong&gt; &amp;ndash; For compatibility, may contain the key &lt;code&gt;async&lt;/code&gt; in place of the &lt;code&gt;non_blocking&lt;/code&gt; argument. The &lt;code&gt;async&lt;/code&gt; arg is deprecated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72bb91ae39a4577d326534e0a366239f4d2f6032" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;**kwargs&lt;/strong&gt; (&lt;em&gt;*args&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;) &amp;ndash; arguments to invoke &lt;code&gt;func&lt;/code&gt; with.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5847a4bbfe6774c5d419725faf44bb56045bd86" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;**kwargs&lt;/strong&gt; (&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the corresponding kwargs for callable &lt;code&gt;model&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06aa7e1e95a236279512459a9af7e6f136714af2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;*args&lt;/strong&gt; (&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the corresponding args for callable &lt;code&gt;model&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4786a01430f5e00df37e0a3c12e05a6d1bccb369" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;*dims&lt;/strong&gt; (&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; The desired ordering of dimensions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3319d9e4baa0f129856cf05f1bd63cb7e15f6a69" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;*sizes&lt;/strong&gt; (&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; the desired expanded size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d88e4c4171034ef9674db627d11a0997babe55fc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;*tensors&lt;/strong&gt; &amp;ndash; One or more tensors with 0, 1, or 2 dimensions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fdd4b81b9fbfd6112e5abe2aed8111a733309e32" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;*tensors&lt;/strong&gt; &amp;ndash; any number of 1 dimensional tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37d44625a57d67ad98c1d08c2860e67b1f2734af" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;*tensors&lt;/strong&gt; &amp;ndash; any number of tensors of the same type</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="542ee1fa5dcd61ea46e6f051760a45f8429629ae" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;A&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; input square matrix of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66a7223a6944ee5be2aaeedb91548f693b323337" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;A&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ff3d5c63e7af23218d3654b0732721e878d975c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;A&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="beaf7caea311d31a62bf35cffe9c4e562b9e1679" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;A&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input triangular coefficient matrix of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a1fd8981c104831012bef0ab84387ae714973280" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;A&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to factor of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11cfe4616774835a1dba4fea5c0a02f4903b11f5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;B&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the input tensor of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1cbcbf4a0ee70b68dac705e32d72b1cc1467e9a2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Check names&lt;/strong&gt;: an operator may perform automatic checks at runtime that check that certain dimension names must match.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e00a3d6d56d0570d3c90d64bf2e85703c34bcf75" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Check names&lt;/strong&gt;: check that the names of the two tensors &lt;em&gt;match&lt;/em&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eaa4895ce797f363fa068fb68e3589cf17ee5901" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Conv packed params hoisting&lt;/strong&gt; (blacklisting option &lt;code&gt;MobileOptimizerType::HOIST_CONV_PACKED_PARAMS&lt;/code&gt;): This optimization pass moves convolution packed params to the root module, so that the convolution structs can be deleted. This decreases model size without impacting numerics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="467e03838e306f1cc9b995f9ab07314a0c223da6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Conv2D + BatchNorm fusion&lt;/strong&gt; (blacklisting option &lt;code&gt;MobileOptimizerType::CONV_BN_FUSION&lt;/code&gt;): This optimization pass folds &lt;code&gt;Conv2d-BatchNorm2d&lt;/code&gt; into &lt;code&gt;Conv2d&lt;/code&gt; in &lt;code&gt;forward&lt;/code&gt; method of this module and all its submodules. The weight and bias of the &lt;code&gt;Conv2d&lt;/code&gt; are correspondingly updated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="797ae6ccf0f3fa0fcbeb9b7b388baedb5b006fbf" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Distributed Autograd&lt;/strong&gt; stitches together local autograd engines on all the workers involved in the forward pass, and automatically reach out to them during the backward pass to compute gradients. This is especially helpful if the forward pass needs to span multiple machines when conducting, e.g., distributed model parallel training, parameter-server training, etc. With this feature, user code no longer needs to worry about how to send gradients across RPC boundaries and in which order should the local autograd engines be launched, which can become quite complicated where there are nested and inter-dependent RPC calls in the forward pass.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1bb7e35d8fadfa0ec492eaeee55b03e9a384fe57" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Distributed Optimizer&lt;/strong&gt;&amp;rsquo;s constructor takes a &lt;a href=&quot;optim#torch.optim.Optimizer&quot;&gt;&lt;code&gt;Optimizer()&lt;/code&gt;&lt;/a&gt; (e.g., &lt;a href=&quot;optim#torch.optim.SGD&quot;&gt;&lt;code&gt;SGD()&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;optim#torch.optim.Adagrad&quot;&gt;&lt;code&gt;Adagrad()&lt;/code&gt;&lt;/a&gt;, etc.) and a list of parameter RRefs, creates an &lt;a href=&quot;optim#torch.optim.Optimizer&quot;&gt;&lt;code&gt;Optimizer()&lt;/code&gt;&lt;/a&gt; instance on each distinct RRef owner, and updates parameters accordingly when running &lt;code&gt;step()&lt;/code&gt;. When you have distributed forward and backward passes, parameters and gradients will be scattered across multiple workers, and hence it requires an optimizer on each of the involved workers. Distributed Optimizer wraps all those local optimizers into one, and provides a concise constructor and &lt;code&gt;step()&lt;/code&gt; API.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d5f8bc4ac56cfd97f97d119eb653f063ce9a8c7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Dropout removal&lt;/strong&gt; (blacklisting option &lt;code&gt;MobileOptimizerType::REMOVE_DROPOUT&lt;/code&gt;): This optimization pass removes &lt;code&gt;dropout&lt;/code&gt; and &lt;code&gt;dropout_&lt;/code&gt; nodes from this module when training is false.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3e372f6656879627d1504382a4b7846f22e788b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;GLOO_SOCKET_IFNAME&lt;/strong&gt;, for example &lt;code&gt;export GLOO_SOCKET_IFNAME=eth0&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f6592a881a64ce2fc84fda7388b35a82d8e09ea" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;How to use this module:&lt;/strong&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f89fecb44ae27dd51a780204df3a0f0d43ccc86" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Important Notices:&lt;/strong&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9e3d7be29b190f07aadef5e37d2c8e47444424a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Important&lt;/strong&gt;: In contrast to the other models the inception_v3 expects tensors with a size of N x 3 x 299 x 299, so ensure your images are sized accordingly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1df66398ad89ce8863dff1901f021a972d0a77b3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Insert and Fold prepacked ops&lt;/strong&gt; (blacklisting option &lt;code&gt;MobileOptimizerType::INSERT_FOLD_PREPACK_OPS&lt;/code&gt;): This optimization pass rewrites the graph to replace 2D convolutions and linear ops with their prepacked counterparts. Prepacked ops are stateful ops in that, they require some state to be created, such as weight prepacking and use this state, i.e. prepacked weights, during op execution. XNNPACK is one such backend that provides prepacked ops, with kernels optimized for mobile platforms (such as ARM CPUs). Prepacking of weight enables efficient memory access and thus faster kernel execution. At the moment &lt;code&gt;optimize_for_mobile&lt;/code&gt; pass rewrites the graph to replace &lt;code&gt;Conv2D/Linear&lt;/code&gt; with 1) op that pre-packs weight for XNNPACK conv2d/linear ops and 2) op that takes pre-packed weight and activation as input and generates output activations. Since 1 needs to be done only once, we fold the weight pre-packing such that it is done only once at model load time. This pass of the &lt;code&gt;optimize_for_mobile&lt;/code&gt; does 1 and 2 and then folds, i.e. removes, weight pre-packing ops.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c203022c4b7e41a789c0850a218035678246aafc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;LU_data&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the packed LU factorization data</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b68de83e526debfd8f4bba73fb2af28a093a044c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;LU_data&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the pivoted LU factorization of A from &lt;a href=&quot;torch.lu#torch.lu&quot;&gt;&lt;code&gt;torch.lu()&lt;/code&gt;&lt;/a&gt; of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c5a7f1d3cffe65ae015e850f4296ab899102cff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;LU_pivots&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the packed LU factorization pivots</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f3d2fa0664b850596925f91912a8226903a5e6a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;LU_pivots&lt;/strong&gt; (&lt;em&gt;IntTensor&lt;/em&gt;) &amp;ndash; the pivots of the LU factorization from &lt;a href=&quot;torch.lu#torch.lu&quot;&gt;&lt;code&gt;torch.lu()&lt;/code&gt;&lt;/a&gt; of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cde0f3c0abde6143690d2cb7605d91fbcc4fe6ec" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;N&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Number of columns in the output. If N is not specified, a square array is returned</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04a56de9a19a514a1fcf10373351c67efd1b49d3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;NCCL_SOCKET_IFNAME&lt;/strong&gt;, for example &lt;code&gt;export NCCL_SOCKET_IFNAME=eth0&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec5bc033e1610e4a75f2543da0a843e4cbbadc81" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Note&lt;/strong&gt; &amp;ndash; if kdim and vdim are None, they will be set to embed_dim such that</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="576aa905938e327a5ed4b8fede98a6c9f70e96e9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Propagate names&lt;/strong&gt;: &lt;em&gt;unify&lt;/em&gt; the names to select which one to propagate. In the case of &lt;code&gt;x + y&lt;/code&gt;, &lt;code&gt;unify('X', None) = 'X'&lt;/code&gt; because &lt;code&gt;'X'&lt;/code&gt; is more specific than &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ee6ef9bb908af00d480a75de89ef5668a859963" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Propagate names&lt;/strong&gt;: name inference propagates names to output tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af407aa1e4067bd772f2d564ff50863c94343551" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;QR&lt;/strong&gt; (&lt;em&gt;Tensor&lt;/em&gt;): the details of the QR factorization</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6af63ab37345973eb43a4a5fd4d33de8547a1e3b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ReLU/Hardtanh fusion&lt;/strong&gt;: XNNPACK ops support fusion of clamping. That is clamping of output activation is done as part of the kernel, including for 2D convolution and linear op kernels. Thus clamping effectively comes for free. Thus any op that can be expressed as clamping op, such as &lt;code&gt;ReLU&lt;/code&gt; or &lt;code&gt;hardtanh&lt;/code&gt;, can be fused with previous &lt;code&gt;Conv2D&lt;/code&gt; or &lt;code&gt;linear&lt;/code&gt; op in XNNPACK. This pass rewrites graph by finding &lt;code&gt;ReLU/hardtanh&lt;/code&gt; ops that follow XNNPACK &lt;code&gt;Conv2D/linear&lt;/code&gt; ops, written by the previous pass, and fuses them together.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa93a38017c6f0838a547724d9c4d119cf4afed6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Remote Procedure Call (RPC)&lt;/strong&gt; supports running a function on the specified destination worker with the given arguments and getting the return value back or creating a reference to the return value. There are three main RPC APIs: &lt;a href=&quot;#torch.distributed.rpc.rpc_sync&quot;&gt;&lt;code&gt;rpc_sync()&lt;/code&gt;&lt;/a&gt; (synchronous), &lt;a href=&quot;#torch.distributed.rpc.rpc_async&quot;&gt;&lt;code&gt;rpc_async()&lt;/code&gt;&lt;/a&gt; (asynchronous), and &lt;a href=&quot;#torch.distributed.rpc.remote&quot;&gt;&lt;code&gt;remote()&lt;/code&gt;&lt;/a&gt; (asynchronous and returns a reference to the remote return value). Use the synchronous API if the user code cannot proceed without the return value. Otherwise, use the asynchronous API to get a future, and wait on the future when the return value is needed on the caller. The &lt;a href=&quot;#torch.distributed.rpc.remote&quot;&gt;&lt;code&gt;remote()&lt;/code&gt;&lt;/a&gt; API is useful when the requirement is to create something remotely but never need to fetch it to the caller. Imagine the case that a driver process is setting up a parameter server and a trainer. The driver can create an embedding table on the parameter server and then share the reference to the embedding table with the trainer, but itself will never use the embedding table locally. In this case, &lt;a href=&quot;#torch.distributed.rpc.rpc_sync&quot;&gt;&lt;code&gt;rpc_sync()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.distributed.rpc.rpc_async&quot;&gt;&lt;code&gt;rpc_async()&lt;/code&gt;&lt;/a&gt; are no longer appropriate, as they always imply that the return value will be returned to the caller immediately or in the future.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5314a5e0f78e161be1308e7f0f36425e0e43560f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Remote Reference (RRef)&lt;/strong&gt; serves as a distributed shared pointer to a local or remote object. It can be shared with other workers and reference counting will be handled transparently. Each RRef only has one owner and the object only lives on that owner. Non-owner workers holding RRefs can get copies of the object from the owner by explicitly requesting it. This is useful when a worker needs to access some data object, but itself is neither the creator (the caller of &lt;a href=&quot;#torch.distributed.rpc.remote&quot;&gt;&lt;code&gt;remote()&lt;/code&gt;&lt;/a&gt;) or the owner of the object. The distributed optimizer, as we will discuss below, is one example of such use cases.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ac1d5992a6fca7da1c35caf72d55ee459b83fab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Same dims as t.&lt;/strong&gt; (&lt;em&gt;applied.&lt;/em&gt;) &amp;ndash;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="962e703212f421c013940c950f0179bcfd7e5558" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Scripting a function&lt;/strong&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8db690c93c292d8d188cd36e3aadd7bd6d0213c5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Scripting an nn.Module&lt;/strong&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f1531884e296514d90d800035577a8e1accf01f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;When&lt;/strong&gt;&lt;code&gt;as_tuple&lt;/code&gt;&lt;strong&gt;is ``False`` (default)&lt;/strong&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ab18d59c167aab4a342a25877738485f51a7096" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;When&lt;/strong&gt;&lt;code&gt;as_tuple&lt;/code&gt;&lt;strong&gt;is ``True``&lt;/strong&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7078285e2211f504ade0f00ffd2f939c57da6bd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;X&lt;/strong&gt; (&lt;em&gt;tensor&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the input tensor of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1b67d6a132e9c963db47428cb2379e1e546861a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;_extra_files&lt;/strong&gt; &amp;ndash; Map from filename to contents which will be stored as part of &lt;code&gt;f&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a683a25cede5c84fac0359282cc1ba91c60e4ca5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;_extra_files&lt;/strong&gt; (&lt;em&gt;dictionary of filename to content&lt;/em&gt;) &amp;ndash; The extra filenames given in the map would be loaded and their content would be stored in the provided map.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e611d50a4e099f661790454d298a621c6db3772" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;a&lt;/strong&gt; &amp;ndash; the lower bound of the uniform distribution</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d6b643d3bc99d8356ba238e8f3bc442ddc42326" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;a&lt;/strong&gt; &amp;ndash; the negative slope of the rectifier used after this layer (only used with &lt;code&gt;'leaky_relu'&lt;/code&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13e08f7f03b31160851ef342f7107a5a0a61cecd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;a&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Left tensor to contract</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48c6d9a7b5991de5ceb0f2f0002b9b581b68e5fe" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;abs&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The absolute value the complex tensor. Must be float or double.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="769675c7e81eef43f6366734f82732784d9c6c35" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;accumulate&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether to accumulate into self</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06c11a2977c3992817e33b18690cf09337f0cacb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;activation&lt;/strong&gt; &amp;ndash; the activation function of encoder/decoder intermediate layer, relu or gelu (default=relu).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="923b9fe69988df8bf8cfd3d90e121105f87077db" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;activation&lt;/strong&gt; &amp;ndash; the activation function of intermediate layer, relu or gelu (default=relu).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="761a00d8ce0801730293c2567fab0839a725bb91" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;add_bias_kv&lt;/strong&gt; &amp;ndash; add bias to the key and value sequences at dim=0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9907f733a01182c1fbfd28915afc66890b30f3df" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;add_zero_attn&lt;/strong&gt; &amp;ndash; add a new batch of zeros to the key and value sequences at dim=1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25e60582f1deda7c8462bf51f20fc8de0b64b938" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;affine&lt;/strong&gt; &amp;ndash; a boolean value that when set to &lt;code&gt;True&lt;/code&gt;, this module has learnable affine parameters, initialized the same way as done for batch normalization. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c8473b78a9df928d3a9e2a5c428e31960781087" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;affine&lt;/strong&gt; &amp;ndash; a boolean value that when set to &lt;code&gt;True&lt;/code&gt;, this module has learnable affine parameters. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="643d4c7ac1c81e9da7cfa09a73aadce98fb242af" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;affine&lt;/strong&gt; &amp;ndash; a boolean value that when set to &lt;code&gt;True&lt;/code&gt;, this module has learnable per-channel affine parameters initialized to ones (for weights) and zeros (for biases). Default: &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="559454a2b31e0657d70c2b51eea7f95541808926" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;align_corners&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Geometrically, we consider the pixels of the input and output as squares rather than points. If set to &lt;code&gt;True&lt;/code&gt;, the input and output tensors are aligned by the center points of their corner pixels, preserving the values at the corner pixels. If set to &lt;code&gt;False&lt;/code&gt;, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation &lt;em&gt;independent&lt;/em&gt; of input size when &lt;code&gt;scale_factor&lt;/code&gt; is kept the same. This only has an effect when &lt;code&gt;mode&lt;/code&gt; is &lt;code&gt;'bilinear'&lt;/code&gt;. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36cb44cb5ed893a7388ab1e5bafec71dbcb4bf49" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;align_corners&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Geometrically, we consider the pixels of the input and output as squares rather than points. If set to &lt;code&gt;True&lt;/code&gt;, the input and output tensors are aligned by the center points of their corner pixels, preserving the values at the corner pixels. If set to &lt;code&gt;False&lt;/code&gt;, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation &lt;em&gt;independent&lt;/em&gt; of input size when &lt;code&gt;scale_factor&lt;/code&gt; is kept the same. This only has an effect when &lt;code&gt;mode&lt;/code&gt; is &lt;code&gt;'linear'&lt;/code&gt;, &lt;code&gt;'bilinear'&lt;/code&gt;, &lt;code&gt;'bicubic'&lt;/code&gt; or &lt;code&gt;'trilinear'&lt;/code&gt;. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9cfac0e91a78176be96ddc6ef793ea60d709b2eb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;align_corners&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Geometrically, we consider the pixels of the input as squares rather than points. If set to &lt;code&gt;True&lt;/code&gt;, the extrema (&lt;code&gt;-1&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt;) are considered as referring to the center points of the input&amp;rsquo;s corner pixels. If set to &lt;code&gt;False&lt;/code&gt;, they are instead considered as referring to the corner points of the input&amp;rsquo;s corner pixels, making the sampling more resolution agnostic. This option parallels the &lt;code&gt;align_corners&lt;/code&gt; option in &lt;a href=&quot;#torch.nn.functional.interpolate&quot;&gt;&lt;code&gt;interpolate()&lt;/code&gt;&lt;/a&gt;, and so whichever option is used here should also be used there to resize the input image before grid sampling. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="18bc31d486c6b3f3dc8b60be043591c427b7d925" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;align_corners&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, consider &lt;code&gt;-1&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt; to refer to the centers of the corner pixels rather than the image corners. Refer to &lt;a href=&quot;#torch.nn.functional.grid_sample&quot;&gt;&lt;code&gt;grid_sample()&lt;/code&gt;&lt;/a&gt; for a more complete description. A grid generated by &lt;a href=&quot;#torch.nn.functional.affine_grid&quot;&gt;&lt;code&gt;affine_grid()&lt;/code&gt;&lt;/a&gt; should be passed to &lt;a href=&quot;#torch.nn.functional.grid_sample&quot;&gt;&lt;code&gt;grid_sample()&lt;/code&gt;&lt;/a&gt; with the same setting for this option. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7e8f77490dec1d2b29fdbb675f0df9b2418c385" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;align_corners&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, the corner pixels of the input and output tensors are aligned, and thus preserving the values at those pixels. This only has effect when &lt;code&gt;mode&lt;/code&gt; is &lt;code&gt;'linear'&lt;/code&gt;, &lt;code&gt;'bilinear'&lt;/code&gt;, or &lt;code&gt;'trilinear'&lt;/code&gt;. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b7ed549d17ccf06c2a73555f8c110d2b2777c64" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;alpha&lt;/strong&gt; &amp;ndash; multiplicative factor. Default: 0.0001</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c7e987f8b1b60db336f8816506d789632b3a056" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;alpha&lt;/strong&gt; &amp;ndash; the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9144dd58af56a7e78f94a1c6d24c0dd775ffa08a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;alpha&lt;/strong&gt; &amp;ndash; the alpha constant</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aaed323126d545c766d6b20c8792516dd1012883" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;alpha&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The coefficient</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bef472f2822264f8844272a566f6ae7e013eac0f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;alpha&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; the scalar multiplier for &lt;code&gt;other&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eafad06cad281ac6182faa727319bec1cdc6e990" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;alpha&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; multiplier for</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0c3d78d14051f159b2c380fbcdbccf7032cc7c1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;alpha&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; multiplier for &lt;code&gt;batch1 @ batch2&lt;/code&gt; (</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01962c7a9caccb6944e0dd97ce4d52d57152f949" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;alpha&lt;/strong&gt; (&lt;em&gt;Scalar&lt;/em&gt;) &amp;ndash; the scalar multiplier for &lt;code&gt;other&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65c245be1540fcaab2e6ed5fa6d61bf7293f1117" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;amount&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The quantity by which the counter will be incremented.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a86a8ab17b48cd324b8df6130d66a8bfdd18e3f5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;amount&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; quantity of channels to prune. If &lt;code&gt;float&lt;/code&gt;, should be between 0.0 and 1.0 and represent the fraction of parameters to prune. If &lt;code&gt;int&lt;/code&gt;, it represents the absolute number of parameters to prune.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a209b964ca3729de2ffee2abca2f378072e01b9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;amount&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; quantity of parameters to prune. If &lt;code&gt;float&lt;/code&gt;, should be between 0.0 and 1.0 and represent the fraction of parameters to prune. If &lt;code&gt;int&lt;/code&gt;, it represents the absolute number of parameters to prune.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="412d2ada083b0f76466ad50fa67e45bff30d28be" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;angle&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The angle of the complex tensor. Must be same dtype as &lt;a href=&quot;torch.abs#torch.abs&quot;&gt;&lt;code&gt;abs&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3296f07398c854ae12376a870bec69a75a03688" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;args&lt;/strong&gt; &amp;ndash; any argument (unused)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58fda4a765460c36ef0809232ca862a52a746df4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;args&lt;/strong&gt; &amp;ndash; arguments passed on to a subclass of &lt;a href=&quot;#torch.nn.utils.prune.BasePruningMethod&quot;&gt;&lt;code&gt;BasePruningMethod&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cf26c4412d3af55e77c722a46e12a3de8c0a087" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;args&lt;/strong&gt; &amp;ndash; arguments passed on to a subclass of &lt;a href=&quot;torch.nn.utils.prune.basepruningmethod#torch.nn.utils.prune.BasePruningMethod&quot;&gt;&lt;code&gt;BasePruningMethod&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06452ebbd4e53eb2a57ca1d68b73dffabe3a9e69" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;args&lt;/strong&gt; &amp;ndash; arguments to pass to the optimizer constructor on each worker.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="527ad6571a32b831a6fa84b982cf26783e444b79" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;args&lt;/strong&gt; &amp;ndash; tuple containing inputs to the &lt;code&gt;function&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbbea77d989716da38960ac97dc3c1b13738a750" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;args&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; the argument tuple for the &lt;code&gt;func&lt;/code&gt; invocation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a6ccd94c0969142ac42560e759fc19e3bb7b28e2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;args&lt;/strong&gt; (&lt;em&gt;tuple of arguments&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; the inputs to the model, e.g., such that &lt;code&gt;model(*args)&lt;/code&gt; is a valid invocation of the model. Any non-Tensor arguments will be hard-coded into the exported model; any Tensor arguments will become inputs of the exported model, in the order they occur in args. If args is a Tensor, this is equivalent to having called it with a 1-ary tuple of that Tensor. (Note: passing keyword arguments to the model is not currently supported. Give us a shout if you need it.)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16fdafe6c67075fc015e420e0bb0f8d630e5f4e5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;as torch.nn.quantized.Conv2d&lt;/strong&gt; (&lt;em&gt;Same&lt;/em&gt;) &amp;ndash;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79c9815e7f5a48dc393a28760411256901b78dc1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;as torch.nn.quantized.Linear&lt;/strong&gt; (&lt;em&gt;Same&lt;/em&gt;) &amp;ndash;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b96cfefc433ac6d54b2e6d75776bf06a2aa2c2ef" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;async_op&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Whether this op should be an async op</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ef0166b6388a4f0216cd0af7040aee2dea01134" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;async_op&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Whether this op should be an async op.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c393f84aad8fa71c90593f9038432da8c10f4ab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;aten&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default False&lt;/em&gt;) &amp;ndash; [DEPRECATED. use operator_export_type] export the model in aten mode. If using aten mode, all the ops original exported by the functions in symbolic_opset&amp;lt;version&amp;gt;.py are exported as ATen ops.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d413d0f3f92358bb21c09129aebaafca7327d9cb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;atol&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; absolute tolerance. Default: 1e-08</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3edeccc3509794121a4c8cbb0c9c3947569f0355" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;attn_mask&lt;/strong&gt; &amp;ndash; 2D or 3D mask that prevents attention to certain positions. A 2D mask will be broadcasted for all the batches while a 3D mask allows to specify a different mask for the entries of each batch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b70ffd8c9aa3ced153863f4307b36931662a4e6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;aux_logits&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If True, add an auxiliary branch that can improve training. Default: &lt;em&gt;True&lt;/em&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7f0d0ce983d8eb3de6cf4b329489cdf94ceff22" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;aux_logits&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If True, adds two auxiliary branches that can improve training. Default: &lt;em&gt;False&lt;/em&gt; when pretrained is True otherwise &lt;em&gt;True&lt;/em&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7ddd6c4129c6131d8812cc22b9dde600a187a20" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;axis&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; dimension on which apply per-channel quantization</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8531d8872ce2920e620f2844e86bbe33088a4efd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;b&lt;/strong&gt; &amp;ndash; the upper bound of the uniform distribution</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8325c83f74f3a97ea28f95055f6ccadb9fe0420" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;b&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Right tensor to contract</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41ffccfc315d025808792ff986c6bf85fc3cfb20" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;b&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the RHS tensor of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bedd1fb2f39140f6b07702dfe6d9850270d68d48" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;backend&lt;/strong&gt; &amp;ndash; Device type to use for running the result model (&amp;lsquo;CPU&amp;rsquo;(default) or &amp;lsquo;Vulkan&amp;rsquo;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="857b931bd7b5bfc52eb0de68ac6430dc390f6af7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;backend&lt;/strong&gt; (&lt;a href=&quot;#torch.distributed.rpc.BackendType&quot;&gt;BackendType&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The type of RPC backend implementation. Supported values include &lt;code&gt;BackendType.TENSORPIPE&lt;/code&gt; (the default) and &lt;code&gt;BackendType.PROCESS_GROUP&lt;/code&gt;. See &lt;a href=&quot;#rpc-backends&quot;&gt;Backends&lt;/a&gt; for more information.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2deecff901759888bdb71ea34d20b18f5d55de46" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;backend&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;#torch.distributed.Backend&quot;&gt;Backend&lt;/a&gt;) &amp;ndash; The backend to use. Depending on build-time configurations, valid values include &lt;code&gt;mpi&lt;/code&gt;, &lt;code&gt;gloo&lt;/code&gt;, and &lt;code&gt;nccl&lt;/code&gt;. This field should be given as a lowercase string (e.g., &lt;code&gt;&quot;gloo&quot;&lt;/code&gt;), which can also be accessed via &lt;a href=&quot;#torch.distributed.Backend&quot;&gt;&lt;code&gt;Backend&lt;/code&gt;&lt;/a&gt; attributes (e.g., &lt;code&gt;Backend.GLOO&lt;/code&gt;). If using multiple processes per machine with &lt;code&gt;nccl&lt;/code&gt; backend, each process must have exclusive access to every GPU it uses, as sharing GPUs between processes can result in deadlocks.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="611838a036cbfc666e9b5fee5ea917b77c462eae" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;backend&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;#torch.distributed.Backend&quot;&gt;Backend&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The backend to use. Depending on build-time configurations, valid values are &lt;code&gt;gloo&lt;/code&gt; and &lt;code&gt;nccl&lt;/code&gt;. By default uses the same backend as the global group. This field should be given as a lowercase string (e.g., &lt;code&gt;&quot;gloo&quot;&lt;/code&gt;), which can also be accessed via &lt;a href=&quot;#torch.distributed.Backend&quot;&gt;&lt;code&gt;Backend&lt;/code&gt;&lt;/a&gt; attributes (e.g., &lt;code&gt;Backend.GLOO&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd1b20b89d2cc0ec5cb752e68d4f7968fe15164e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;base&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; base of the logarithm function. Default: &lt;code&gt;10.0&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d70c00dc7a0b2333944c557a49e48e57f71ef5e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;batch1&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the first batch of matrices to be multiplied</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6f89ac68899abcdeec75e50915476dc96eff70e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;batch2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the second batch of matrices to be multiplied</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cf203097252d2e89f058a192c342938374bbb59" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;batch_first&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, then the input and output tensors are provided as (batch, seq, feature). Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2bb4ed84deb95504a0fd7b72a8e70cbe91a0c79" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;batch_first&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, then the input and output tensors are provided as &lt;code&gt;(batch, seq, feature)&lt;/code&gt;. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb58228cb0588bbf40e1aa70f7aa94c4d87966f6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;batch_first&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, the input is expected in &lt;code&gt;B x T x *&lt;/code&gt; format.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="97878838dd43a3b22c60de0a798485d3232a77f6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;batch_first&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, the output will be in &lt;code&gt;B x T x *&lt;/code&gt; format.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ed5b9e169e5e04e47a2bda761131d2763152218" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;batch_first&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; output will be in &lt;code&gt;B x T x *&lt;/code&gt; if True, or in &lt;code&gt;T x B x *&lt;/code&gt; otherwise</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a9f6fb92330f139eb9547e65e6c72e563c7f9e2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;beta&lt;/strong&gt; &amp;ndash; exponent. Default: 0.75</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef999fec40e863a728ff14d8247d251aee96fa89" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;beta&lt;/strong&gt; &amp;ndash; the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0cf575cbd58c43c32309649550fcd836702cf2fe" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;beta&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies the threshold at which to change between L1 and L2 loss. This value defaults to 1.0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c471f0e5d8fd5619e33288b2fd6dc3e2c59c406" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;beta&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The coefficient</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="842828693822b4d9f2aa884edc9269cce4696288" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;beta&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; shape parameter for the window.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b11887536b01d5ee066bad51f6fc21a475d853cb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;beta&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; multiplier for &lt;code&gt;input&lt;/code&gt; (</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa1cf47ccd539344b4c2e84e2076311ee96e5b1f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;beta&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; multiplier for &lt;code&gt;mat&lt;/code&gt; (</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc78c217f09fc1013e5acbefa8a13316ec9a1fca" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bias&lt;/strong&gt; &amp;ndash; &lt;strong&gt;non-quantized&lt;/strong&gt; bias tensor of shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5cf46533d930efcc3fd64418202381a80648d2fc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bias&lt;/strong&gt; &amp;ndash; If &lt;code&gt;False&lt;/code&gt;, then the layer does not use bias weights &lt;code&gt;b_ih&lt;/code&gt; and &lt;code&gt;b_hh&lt;/code&gt;. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a6cf6d24a3d1d4d2e99d86a09905c2dcc844ee4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bias&lt;/strong&gt; &amp;ndash; If set to &lt;code&gt;False&lt;/code&gt;, the layer will not learn an additive bias. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9166de183aefb5a5420210ed060a3775a566bedc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bias&lt;/strong&gt; &amp;ndash; If set to False, the layer will not learn an additive bias. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="81d19585b9271c2697fbe2d0820cd2cd9a202b52" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bias&lt;/strong&gt; &amp;ndash; add bias as module parameter. Default: True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1d7f9d42640778760e245fa86bc8ea0c619a3a4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bias&lt;/strong&gt; &amp;ndash; optional bias of shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e06c7b1cc26cfb4e243f63f4508fe3ad4aaecc3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bias&lt;/strong&gt; &amp;ndash; optional bias tensor of shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e03a417e197c4f988306955bf8e28f75e1103c81" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bias&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, adds a learnable bias to the output. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c804fd0b8536d52a938e789eaf231e2d8488e976" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bias&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; None or fp32 bias of type &lt;code&gt;torch.float&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a33731aa2d3126a1f9307fbc74003f4b76cba728" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bidirectional&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, becomes a bidirectional GRU. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4d0b0c0ab949b4fb4278979fa4bb9deb02a9fbe" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bidirectional&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, becomes a bidirectional LSTM. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8771da0d807097f9c9e787cd58800e69ca9ba9e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bidirectional&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, becomes a bidirectional RNN. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7eb56a898db0c0dd4ebf0e179f5fd52a33dbbba3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bins&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of histogram bins</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d0079f1170ed85a5972e6fbc1007549726ed554" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bins&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; One of {&amp;lsquo;tensorflow&amp;rsquo;,&amp;rsquo;auto&amp;rsquo;, &amp;lsquo;fd&amp;rsquo;, &amp;hellip;}. This determines how the bins are made. You can find other options in: &lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html&quot;&gt;https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be7c2ee257bfd0c3170743cdce62c675328d09dd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;blank&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Blank label. Default</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98d9784c554d3e6070ecb671487ffb5edf2addb7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;blank&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; blank label. Default</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="124b59c3f64e2d2878e908f98928989224419b13" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;boundaries&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; 1-D tensor, must contain a monotonically increasing sequence.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5da31c2835927c49a7bcd45bbe610fbd0fda6d6a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;broadcast_buffers&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Flag that enables syncing (broadcasting) buffers of the module at beginning of the &lt;code&gt;forward&lt;/code&gt; function. (default: &lt;code&gt;True&lt;/code&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d5abee92111d698306a568507b4404bca34ef32" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bucket_cap_mb&lt;/strong&gt; &amp;ndash; &lt;code&gt;DistributedDataParallel&lt;/code&gt; will bucket parameters into multiple buckets so that gradient reduction of each bucket can potentially overlap with backward computation. &lt;code&gt;bucket_cap_mb&lt;/code&gt; controls the bucket size in MegaBytes (MB). (default: 25)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2fa537aa1114daae5c6231d8a64de02ef3a1e4f3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;build_directory&lt;/strong&gt; &amp;ndash; optional path to use as build workspace.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3141d5b804d7f3a2ff206cba71370ed4fb7cf6b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;c_0&lt;/strong&gt; of shape &lt;code&gt;(batch, hidden_size)&lt;/code&gt;: tensor containing the initial cell state for each element in the batch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2cdfc2f84c394419e5070447dbe32bbe5a849b2c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;c_0&lt;/strong&gt; of shape &lt;code&gt;(num_layers * num_directions, batch, hidden_size)&lt;/code&gt;: tensor containing the initial cell state for each element in the batch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9b02af500b7cb6986cf95c49ee08bafe6ac6c55" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;c_1&lt;/strong&gt; of shape &lt;code&gt;(batch, hidden_size)&lt;/code&gt;: tensor containing the next cell state for each element in the batch</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc8b348167534518488e0ae2031d0338daba2877" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;c_n&lt;/strong&gt; of shape &lt;code&gt;(num_layers * num_directions, batch, hidden_size)&lt;/code&gt;: tensor containing the cell state for &lt;code&gt;t = seq_len&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3afc2463b07a6cb3c6c5f91f7a5a9121d9323c6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;callback&lt;/strong&gt; (&lt;code&gt;Callable&lt;/code&gt;) &amp;ndash; a &lt;code&gt;Callable&lt;/code&gt; that takes this &lt;code&gt;Future&lt;/code&gt; as the only argument.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a50ab6a8fd5d6ca7187e241b339e3ce04e06ad53" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ceil_mode&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, will use &lt;code&gt;ceil&lt;/code&gt; instead of &lt;code&gt;floor&lt;/code&gt; to compute the output shape. This ensures that every element in the input tensor is covered by a sliding window.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8f8c031ecdef7a290512f2d2c0f3fb9843f10ac" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ceil_mode&lt;/strong&gt; &amp;ndash; when True, will use &lt;code&gt;ceil&lt;/code&gt; instead of &lt;code&gt;floor&lt;/code&gt; in the formula to compute the output shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4607006703c79ed95d46d4bdf76b0c53e13b775b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ceil_mode&lt;/strong&gt; &amp;ndash; when True, will use &lt;code&gt;ceil&lt;/code&gt; instead of &lt;code&gt;floor&lt;/code&gt; in the formula to compute the output shape. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11fbe0576979d5cf6a08896bdf3211baf5a56d94" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ceil_mode&lt;/strong&gt; &amp;ndash; when True, will use &lt;code&gt;ceil&lt;/code&gt; instead of &lt;code&gt;floor&lt;/code&gt; to compute the output shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b293b825d6cac1646ea030a31f09a3ccbb476cad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ceil_mode&lt;/strong&gt; &amp;ndash; when True, will use &lt;code&gt;ceil&lt;/code&gt; instead of &lt;code&gt;floor&lt;/code&gt; to compute the output shape. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39ee4edbfa46d12a64c7dc2b9fa7acda768a096e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;center&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether &lt;code&gt;input&lt;/code&gt; was padded on both sides so that the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="554e667848e98458fc2cceae44866e4bc318c449" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;center&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if True, center the input tensor, otherwise, assume that the input is centered.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9f7299f6837ef46cae44a83afb72d7f43c0f17b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;center&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to pad &lt;code&gt;input&lt;/code&gt; on both sides so that the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="901e29d2efd439abae8b39739b45f91fde3c2e1f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;check_hash&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If True, the filename part of the URL should follow the naming convention &lt;code&gt;filename-&amp;lt;sha256&amp;gt;.ext&lt;/code&gt; where &lt;code&gt;&amp;lt;sha256&amp;gt;&lt;/code&gt; is the first eight or more digits of the SHA256 hash of the contents of the file. The hash is used to ensure unique names and to verify the contents of the file. Default: False</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef5504f62a92974b3ed5764b39be00b40da7ec96" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;check_inputs&lt;/strong&gt; (&lt;em&gt;list of dicts&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; A list of dicts of input arguments that should be used to check the trace against what is expected. Each tuple is equivalent to a set of input arguments that would be specified in &lt;code&gt;inputs&lt;/code&gt;. For best results, pass in a set of checking inputs representative of the space of shapes and types of inputs you expect the network to see. If not specified, the original &lt;code&gt;inputs&lt;/code&gt; are used for checking</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c341222b235229269c7fc1f716c9a876b11bd749" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;check_inputs&lt;/strong&gt; (&lt;em&gt;list of tuples&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; A list of tuples of input arguments that should be used to check the trace against what is expected. Each tuple is equivalent to a set of input arguments that would be specified in &lt;code&gt;example_inputs&lt;/code&gt;. For best results, pass in a set of checking inputs representative of the space of shapes and types of inputs you expect the network to see. If not specified, the original &lt;code&gt;example_inputs&lt;/code&gt; are used for checking</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5be047e7257e74bb986cba2cbddd77287afb54a4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;check_reduction&lt;/strong&gt; &amp;ndash; This argument is deprecated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b901bf06f9dd61829b7a11e137cee91046aa7d9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;check_tolerance&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Floating-point comparison tolerance to use in the checker procedure. This can be used to relax the checker strictness in the event that results diverge numerically for a known reason, such as operator fusion.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d4b51194efc0c3988804d99693826828fb517f6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;check_trace&lt;/strong&gt; (&lt;code&gt;bool&lt;/code&gt;, optional) &amp;ndash; Check if the same inputs run through traced code produce the same outputs. Default: &lt;code&gt;True&lt;/code&gt;. You might want to disable this if, for example, your network contains non- deterministic ops or if you are sure that the network is correct despite a checker failure.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b22f20f0f0764fbf8ab51098534c41733587e08" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;chunks&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of chunks to return</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="768622c9f916e93f3f54009c2cae67ec11e32f7c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;clip_value&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; maximum allowed value of the gradients. The gradients are clipped in the range</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="469c227d8924eacf04bdee3cc8cf8084affddf1d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;close&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Flag to automatically close the figure</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf87633936d5aa46fae578ecedd6b3692d516d64" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;col&lt;/strong&gt; (&lt;code&gt;int&lt;/code&gt;) &amp;ndash; number of columns in the 2-D matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a942bb7a89546ea8db2e80c5772f25d6c0dc388d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;colors&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; Colors for each vertex</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af25ed4733fad11d3e062d79140e6b8c23a8a955" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;comment&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; Comment log_dir suffix appended to the default &lt;code&gt;log_dir&lt;/code&gt;. If &lt;code&gt;log_dir&lt;/code&gt; is assigned, this argument has no effect.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88100fd7e4f3c66560dd9b530a7164b8a95efdd5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;compiler&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; The compiler executable name to check (e.g. &lt;code&gt;g++&lt;/code&gt;). Must be executable in a shell process.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1808bd911df345d583c080a56c28591067ce66ed" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;compute_mode&lt;/strong&gt; &amp;ndash; &amp;lsquo;use_mm_for_euclid_dist_if_necessary&amp;rsquo; - will use matrix multiplication approach to calculate euclidean distance (p = 2) if P &amp;gt; 25 or R &amp;gt; 25 &amp;lsquo;use_mm_for_euclid_dist&amp;rsquo; - will always use matrix multiplication approach to calculate euclidean distance (p = 2) &amp;lsquo;donot_use_mm_for_euclid_dist&amp;rsquo; - will never use matrix multiplication approach to calculate euclidean distance (p = 2) Default: use_mm_for_euclid_dist_if_necessary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b7321414a4a3b3cf3f67b84bd0c573e753c0ef0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;compute_uv&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; option whether to compute &lt;code&gt;U&lt;/code&gt; and &lt;code&gt;V&lt;/code&gt; or not</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0d3ed0a4c0c3905d8f35b9489a4566e61f37346" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;condition&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.BoolTensor&quot;&gt;BoolTensor&lt;/a&gt;) &amp;ndash; When True (nonzero), yield x, otherwise yield y</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb57365756ae0cedf43c6c254c4afd0d2edee70b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;config_dict&lt;/strong&gt; &amp;ndash; Dictionary with ThreeJS classes names and configuration.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4a1732a0f202d34ba93b1eb562af5be27bdd650" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;context_id&lt;/strong&gt; &amp;ndash; the autograd context id for which we should run the optimizer step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d5613a1e6301637797b5ae54f8043e61724838c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;context_id&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The autograd context id for which we should retrieve the gradients.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c83c6134b0a9c7b9806c160fd52a9c3b5ea1fc9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;count_include_pad&lt;/strong&gt; &amp;ndash; when True, will include the zero-padding in the averaging calculation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df61d9b0480a95d8ea4a65fcfd105e2c43cf5683" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;count_include_pad&lt;/strong&gt; &amp;ndash; when True, will include the zero-padding in the averaging calculation. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f406dbb58fb0db000240174c73ab3118ad8b663f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;counts&lt;/strong&gt; (&lt;em&gt;Tensor&lt;/em&gt;): (optional) if &lt;code&gt;return_counts&lt;/code&gt; is True, there will be an additional returned tensor (same shape as output or output.size(dim), if dim was specified) representing the number of occurrences for each unique value or tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88193fd13f9166e9983ecc78ecd953269b1f995e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;cpp_sources&lt;/strong&gt; &amp;ndash; A string, or list of strings, containing C++ source code.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1df45c030ada5dacf28732656dae67b769b52be4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;create_graph&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, graph of the derivative will be constructed, allowing to compute higher order derivative products. Defaults to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff1cc36eddc3b5f962bb282dc8359cf8c6757bb3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;cuda&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, includes CUDA-specific include paths.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9cc28cf38c3a669932c9eedb3625ab6b9d7054e3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;cuda_sources&lt;/strong&gt; &amp;ndash; A string, or list of strings, containing CUDA source code.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e54fa7d57ec695fdbf3ba8aa44c0d4c97f847f91" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;custom_decoder&lt;/strong&gt; &amp;ndash; custom decoder (default=None).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ca74733e312c67f2657fe95d1e444ee05127650" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;custom_encoder&lt;/strong&gt; &amp;ndash; custom encoder (default=None).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7780ca36c95ae6da024d6000ca0554d9dfacacc3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;custom_opsets&lt;/strong&gt; (&lt;em&gt;dict&amp;lt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;int&amp;gt;&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default empty dict&lt;/em&gt;) &amp;ndash; A dictionary to indicate custom opset domain and version at export. If model contains a custom opset, it is optional to specify the domain and opset version in the dictionary: - KEY: opset domain name - VALUE: opset version If the custom opset is not provided in this dictionary, opset version is set to 1 by default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9101a0b9856e2d4350718d233a9dcae3bf9c6f6c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;cutoffs&lt;/strong&gt; (&lt;em&gt;Sequence&lt;/em&gt;) &amp;ndash; Cutoffs used to assign targets to their buckets</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52d9d339631301adfaf686280dfd334d7edccba5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;d&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;) &amp;ndash; the floating point dtype to make the default</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13964b8d48f242ad146568039b158f92e2df74ae" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;d&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/a&gt;) &amp;ndash; If True, force operations to be deterministic. If False, allow non-deterministic operations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3da5f1488cc8bd47b1fccb5b95f3073259325116" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;d&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; path to a local folder to save downloaded models &amp;amp; weights.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16b912c0275c25fd63373867599edc3ab633da37" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;d_model&lt;/strong&gt; &amp;ndash; the number of expected features in the encoder/decoder inputs (default=512).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15d1f07b9f1bfeb8b51357949749ed27cc1e3a54" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;d_model&lt;/strong&gt; &amp;ndash; the number of expected features in the input (required).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1751a1c65282c1b2a3f97ccf6353f71f8348524a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;data&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; parameter tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="002b70001aea1b9d2d370c56a295bc0004d40317" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;data&lt;/strong&gt; (&lt;em&gt;array_like&lt;/em&gt;) &amp;ndash; Initial data for the tensor. Can be a list, tuple, NumPy &lt;code&gt;ndarray&lt;/code&gt;, scalar, and other types.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="057f28def548d5eeb6eab40e11d3fc6379b98957" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;data&lt;/strong&gt; (&lt;em&gt;array_like&lt;/em&gt;) &amp;ndash; The returned Tensor copies &lt;code&gt;data&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6cb5164bb06d6da92431aba395fa788fafdd491" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dataformats&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; Image data format specification of the form NCHW, NHWC, CHW, HWC, HW, WH, etc.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8a0c46d88dac2ffef33068f3be232119d9b9ac2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;decoder_layer&lt;/strong&gt; &amp;ndash; an instance of the TransformerDecoderLayer() class (required).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6debf1cc5a394619a93016d7ca366d8f9a4f042f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;default_mask&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; Base mask from previous pruning</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02df0d48c6b8036586e726b50a5fbc9b6e1751a4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;default_mask&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; Base mask from previous pruning iterations, that need to be respected after the new mask is applied. Same dims as &lt;code&gt;t&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5cf70b407f88539d3c6c856333c142253f1a21c7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;default_mask&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; mask from previous pruning iteration.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25982b74713391159075b7c31f6a1999d645d6fa" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;default_mask&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; mask from previous pruning iteration, if any. To be considered when determining what portion of the tensor that pruning should act on. If None, default to a mask of ones.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2c8995ad4fd81b344f11dc7dbecd0ebd8ded8d5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;descending&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls the sorting order (ascending or descending)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de9594f438e4acefd09174ebe985fcf079eb149b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;destination&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; Destination positions for each of the original dims. These must also be unique.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b43c4caf374bfe5b5468766c5d19925926c2fdd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;deterministic&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; flag to choose between a faster non-deterministic calculation, or a slower deterministic calculation. This argument is only available for sparse-dense CUDA bmm. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67ab079c226c54c3f26e4ea0b6f9a1108b087a49" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired device for the generator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a7f07799c9cad3af3cab4816607f53086fcc521" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired device of returned tensor. Default: if &lt;code&gt;None&lt;/code&gt;, defaults to the device of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5aed780ae1f47b9761fbfa7992f19ff1ad4f3e5e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired device of returned tensor. Default: if &lt;code&gt;None&lt;/code&gt;, uses the current device for the default tensor type (see &lt;a href=&quot;torch.set_default_tensor_type#torch.set_default_tensor_type&quot;&gt;&lt;code&gt;torch.set_default_tensor_type()&lt;/code&gt;&lt;/a&gt;). &lt;code&gt;device&lt;/code&gt; will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f17f4ea64a618a5f0fee4c7ea43e579c17cf49f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see &lt;a href=&quot;torch.set_default_tensor_type#torch.set_default_tensor_type&quot;&gt;&lt;code&gt;torch.set_default_tensor_type()&lt;/code&gt;&lt;/a&gt;). &lt;code&gt;device&lt;/code&gt; will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf93823dec63265c654765453f246b1d85c3b014" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The destination GPU id. Defaults to the current device.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d93e973425e80658411f9bf156583443e90dc63" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if specified, all parameters will be copied to that device</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a198ab22b8b6fb2b268e0d3eed8f405f9fdfeffb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt;) &amp;ndash; The destination GPU device. Defaults to the current CUDA device.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f538c82c744a54f89979310b11620a36e4dfdc67" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired device of returned tensor. Default: if None, same &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; as this tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16a3ba684b70277c97f3887a32acb68677e89ab5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;code&gt;torch.device&lt;/code&gt;) &amp;ndash; the desired device of the parameters and buffers in this module</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c13cbea5fe853ad61c4e5b6bdc300c90af893ea8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device_ids&lt;/strong&gt; (&lt;em&gt;list of python:int&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;) &amp;ndash; CUDA devices (default: all devices)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="784500a88b749be8a97a2a8383bb392bde957899" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device_ids&lt;/strong&gt; (&lt;em&gt;list of python:int&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;) &amp;ndash; CUDA devices. This should only be provided when the input module resides on a single CUDA device. For single-device modules, the i&amp;rsquo;th &lt;code&gt;module&lt;/code&gt; replica is placed on &lt;code&gt;device_ids[i]&lt;/code&gt;. For multi-device modules and CPU modules, &lt;code&gt;device_ids&lt;/code&gt; must be &lt;code&gt;None&lt;/code&gt; or an empty list, and input data for the forward pass must be placed on the correct device. (default: all visible devices for single-device modules)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0098733514e18323929fd4ffb49500d3946fa6b3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device_ids&lt;/strong&gt; (&lt;em&gt;list of python:int&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;) &amp;ndash; GPU ids on which to replicate module</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="59e24ff6691679f07576485b92e551a387011363" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;diagonal&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the diagonal to consider</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98d2682d358cdef81c41f9d22f56660c98f0fea5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dilation&lt;/strong&gt; &amp;ndash; The stride between elements within a sliding window, must be &amp;gt; 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a8bcc8e1ce88b2cf0668486e8d5ccbcb8a4d458" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dilation&lt;/strong&gt; &amp;ndash; a parameter that controls the stride of elements in the window</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8745aafd934cfa2f8a27f7eeb58f0f04b1c8c6a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dilation&lt;/strong&gt; &amp;ndash; the spacing between kernel elements. Can be a single number or a one-element tuple &lt;code&gt;(dW,)&lt;/code&gt;. Default: 1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4f0efe675d23b1d986e23b22d467d33af93c1ce" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dilation&lt;/strong&gt; &amp;ndash; the spacing between kernel elements. Can be a single number or a tuple &lt;code&gt;(dD, dH, dW)&lt;/code&gt;. Default: 1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5cc549246c32f7e86fe8237813b71d731de4aeab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dilation&lt;/strong&gt; &amp;ndash; the spacing between kernel elements. Can be a single number or a tuple &lt;code&gt;(dH, dW)&lt;/code&gt;. Default: 1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="717cd865c4cf98b3ffbd6b2307f6f4dbaebad0c8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dilation&lt;/strong&gt; &amp;ndash; the spacing between kernel elements. Can be a single number or a tuple &lt;code&gt;(dT, dH, dW)&lt;/code&gt;. Default: 1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ca358d114492e5781f3c8bd655869b64df6739b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dilation&lt;/strong&gt; &amp;ndash; the spacing between kernel elements. Can be a single number or a tuple &lt;code&gt;(dW,)&lt;/code&gt;. Default: 1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6d5af4910c01ee195d562c6b5a6bb2027740a67" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dilation&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Spacing between kernel elements. Default: 1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abdfdeace9aacba2e41cd643c5ea0e49e917e957" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dilation&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a parameter that controls the stride of elements within the neighborhood. Default: 1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="472af6ce02e71caf282798bb447e00270b529b2e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim0&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the first dimension to be transposed</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f765d8f8c40b94958f1eab1cc37007590593d31d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim1&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the second dimension to be transposed</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba65b006661843062287a94ba12a78ac85885543" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim1&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; first dimension with respect to which to take diagonal. Default: -2.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0dd1507c4f8260c289a9910df29cf487d663e95d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim1&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; first dimension with respect to which to take diagonal. Default: 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83aa8a523aec2c1ab6551640eaf4cb51b830a4c1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim2&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; second dimension with respect to which to take diagonal. Default: -1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a71ef13a1ad5cb6ea968b4d4719be6d5961ef225" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim2&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; second dimension with respect to which to take diagonal. Default: 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9b4a2ca457fba9669e7f8ced2b7ed6c30268fd6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; A dimension along which LogSoftmax will be computed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34032d1dca3a055630ebba7923bebf4f47a22c38" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; A dimension along which Softmax will be computed (so every slice along dim will sum to 1).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01189dd75e2eefc978065b5ff2c0b7f87388d39e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; A dimension along which Softmin will be computed (so every slice along dim will sum to 1).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="842005dbd132f5ef7d384c1fccbadec279da8f7c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; A dimension along which log_softmax will be computed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb8ee0a50b62dc6ae83f365bac143af1c17f1fd6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; A dimension along which softmax will be computed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01b7d7748905016190ad5e2bbe8293a9c597a66c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; A dimension along which softmax will be computed. Default: -1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2777bb64e36f761c1f00ee5be70a591e4cd2145d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; A dimension along which softmin will be computed (so every slice along dim will sum to 1).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88bb112f612fa4c72a0f99f7a672d75b2554455b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The dimension along which to integrate. By default, use the last dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90f0ee8c3c7b4d5b8a5616f19077bcfded77ea98" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; dimension along which to index</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8ce25c1fd3bbad54cc79c92db33a7f9d23196c2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; dimension along which to split the tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a9295ba14ea4badc07f27ea8db556fe8e515b0d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; dimension along which to split the tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a971edb34aad20abc50873c653c145b3af96b2a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; dimension on which to split the input. Default: -1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf3801597d3facaa2cf443350498f58cd1324abb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; dimension to insert. Has to be between 0 and the number of dimensions of concatenated tensors (inclusive)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e66e4cf2db711439adae127683b487fd7e64123" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; dimension to remove</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c917eaab2e1d73b163be73789e03b1bc35b48a89" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; index of the dim along which we define channels to prune.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7285e77d113e976c86c60be543b1f43be38c5bdd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the axis along which to index</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e017cd401e156f255b917cbb7d73173fc5184a9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension along which to narrow</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7415821de8da0f78deed554d7e45d50759c33f0b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension in which we index</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be8bc5d715865fc115635841b9517c75441ff8f3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension to apply unique. If &lt;code&gt;None&lt;/code&gt;, the unique of the flattened input is returned. default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4849740fe6ccbd59b0ec458f024b413bf6df7857" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension to do the operation over</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9dfe268e0c2ab5c49cd99f8395aef6a384d8dd63" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension to reduce</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0cd1da8b56960f63a95d25cf0421a937673e2ed" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension to reduce.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8d7f0790b12bc35fd47df215177efe265599f93" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension to reduce. Default: 1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04661f26e0a90dbee7adeed063722879cc2dbedc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension to reduce. If &lt;code&gt;None&lt;/code&gt;, the argmax of the flattened input is returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="406a26e14fe614e1dacddd572bc1dbd6bd5aa6a9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension to reduce. If &lt;code&gt;None&lt;/code&gt;, the argmin of the flattened input is returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3e09769491b63675c94e11c9dea885116b4a2fa" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension to slice</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8317062bcf63e96ea89234edaf5254e1da5bcb47" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension to slice over to get the sub-tensors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c54f0ef48043a5bec2dfca3a0f530fb8661be4ca" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the index at which to insert the singleton dimension</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d89796e28feb4305a6e51573710dca2759c32ff1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; a dimension or a list of dimensions to reduce. Default: reduce over all dims.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1addd18afe889496111cce39db43031d3782741" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; the dimension or dimensions to reduce.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="74f088f545a1351da755347a9f47abc2c5b4f78d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tuple of python:ints&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Dim or tuple of dims along which to count non-zeros.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ea1a19f10e224b77d5a38dec1768437b4ef777c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;2-tuple of python:ints&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;2-list of python:ints&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;dim&lt;/code&gt; is an int, vector norm will be calculated over the specified dimension. If &lt;code&gt;dim&lt;/code&gt; is a 2-tuple of ints, matrix norm will be calculated over the specified dimensions. If &lt;code&gt;dim&lt;/code&gt; is None, matrix norm will be calculated when the input tensor has two dimensions, and vector norm will be calculated when the input tensor has one dimension. Default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b085e1cc1d870668a83baea40b3506508d9b0a8b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;2-tuple of python:ints&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;2-list of python:ints&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If it is an int, vector norm will be calculated, if it is 2-tuple of ints, matrix norm will be calculated. If the value is None, matrix norm will be calculated when the input tensor only has two dimensions, vector norm will be calculated when the input tensor only has one dimension. If the input tensor has more than two dimensions, the vector norm will be applied to last dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39551d8784237f98effe67d5d4fa079ab6e2d66d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Dimension of vectors. Default: 1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c530107de3a1e8849bcffa15e8fece38f241cc6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Dimension where cosine similarity is computed. Default: 1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9439b0c674bc7c434adc98d580848f39ed9d115e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The dimension along which to repeat values. By default, use the flattened input array, and return a flat output array.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c36ee04034363ccdd358a7c5f8322922bf781fba" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The dimension along which to take the one dimensional FFT.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45818af3fdbc4684e20729f70925408319f7b2e1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The dimension along which to take the one dimensional Hermitian FFT.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e290320ee25d598ee056c54b55e12ed854c6dd23" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The dimension along which to take the one dimensional Hermitian IFFT.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5f98ff50ef003b2c77b0c55e3bf6a58a74600f0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The dimension along which to take the one dimensional IFFT.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4bb3ea939e2fa64fe7995582d47d53ee2e17ec4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The dimension along which to take the one dimensional real FFT.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dea0a42312b17fe5fe3428922ce27d374ec46837" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The dimension along which to take the one dimensional real IFFT.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d32f4b0a48eae0a94c40f8913aaafd8fc5b4e99b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; dimension corresponding to number of outputs, the default is &lt;code&gt;0&lt;/code&gt;, except for modules that are instances of ConvTranspose{1,2,3}d, when it is &lt;code&gt;1&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ff766b40b5bcbfe08f64170324fb2f4d6bf84af" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; dimension over which to compute the norm</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a409409533f64a991397140f0cfeef5685c9fa1d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if given, the input will be squeezed only in this dimension</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05043e9f4aa7115561003ddcb8522351f1c5f51e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; index of the dim along which we define channels to prune. Default: -1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4945ffee136e1eca9138593201351feb8ce974a6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the desired dimension in which stride is required</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd4c3985b4741ed95097721d4f15edc8c371b9f6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the dimension over which the tensors are concatenated</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9ff0c74674eab95e6f6442b562b6f45f41a7a9d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the dimension to find the kth value along</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9422d28d87b196679cbb0c82259c774161568b6b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the dimension to sort along</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28c1fc242c3e6d093897709fa5e6ddd3f6f9dd3b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the dimension to take the cross-product in.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa74b5fd1d3a59aa2fc20f8e622f3d996cbd575d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Dimensions to be transformed. Default: all dimensions, or the last &lt;code&gt;len(s)&lt;/code&gt; dimensions if &lt;code&gt;s&lt;/code&gt; is given.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="714e04567ca514a499d3251ac5bce29de688ec57" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Dimensions to be transformed. The last dimension must be the half-Hermitian compressed dimension. Default: all dimensions, or the last &lt;code&gt;len(s)&lt;/code&gt; dimensions if &lt;code&gt;s&lt;/code&gt; is given.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c73040a5128f371bcddeab377f515339135506e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;em&gt;Union&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; Dimension to be unflattened</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="612979d2207bccfbcbdc71c971749078ecad7740" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;em&gt;Union&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; Dimension to unflatten</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9f96b0e996218b63b5f6697be8d86971ef5ef58" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim_feedforward&lt;/strong&gt; &amp;ndash; the dimension of the feedforward network model (default=2048).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61d8fc5ddd343a37fbd282f3894946f478ef2ebb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dimension&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; dimension in which unfolding happens</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3b04003348060ae8bd467525af95608436f8504" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dimension&lt;/strong&gt; (&lt;em&gt;Int&lt;/em&gt;) &amp;ndash; The dimensionality of the sequence to be drawn</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d084aae186e1378df8faf988ddfde110dfb17385" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dims&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; Axis along which to roll</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c317ee80d0d1d374392208d23e06bdc1d0a08445" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dims&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tuple of two lists of python:integers&lt;/em&gt;) &amp;ndash; number of dimensions to contract or explicit lists of dimensions for &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; respectively</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="391fb595ce6469da76a43990e1b4fedec4415935" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dims&lt;/strong&gt; (&lt;em&gt;a list&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; axis to flip on</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa53309859ad0bb426190a8468616e70a2c2d3ec" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dims&lt;/strong&gt; (&lt;em&gt;a list&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; axis to rotate</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4b48119f623a86e0e73cdb61d4b28812b330622a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;distance_function&lt;/strong&gt; (&lt;em&gt;callable&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; A nonnegative, real-valued function that quantifies the closeness of two tensors. If not specified, &lt;code&gt;nn.PairwiseDistance&lt;/code&gt; will be used. Default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9fdd902ea3281b80f4ee9c58cfabafd6bc9880d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;div_value&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; value used as an exponent to compute sizes of the clusters. Default: 4.0</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ed00f6805ef09c53fd3940b48ac159868ff1969" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;divide_by_initial_world_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, will divide gradients by the initial &lt;code&gt;world_size&lt;/code&gt; DDP training was launched with. If &lt;code&gt;False&lt;/code&gt;, will compute the effective world size (number of ranks that have not depleted their inputs yet) and divide gradients by that during allreduce. Set &lt;code&gt;divide_by_initial_world_size=True&lt;/code&gt; to ensure every input sample including the uneven inputs have equal weight in terms of how much they contribute to the global gradient. This is achieved by always dividing the gradient by the initial &lt;code&gt;world_size&lt;/code&gt; even when we encounter uneven inputs. If you set this to &lt;code&gt;False&lt;/code&gt;, we divide the gradient by the remaining number of nodes. This ensures parity with training on a smaller &lt;code&gt;world_size&lt;/code&gt; although it also means the uneven inputs would contribute more towards the global gradient. Typically, you would want to set this to &lt;code&gt;True&lt;/code&gt; for cases where the last few inputs of your training job are uneven. In extreme cases, where there is a large discrepancy in the number of inputs, setting this to &lt;code&gt;False&lt;/code&gt; might provide better results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="049bcce7df5c629c4fad3f80f7fb581f440c0337" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;divisor_override&lt;/strong&gt; &amp;ndash; if specified, it will be used as divisor, otherwise &lt;code&gt;kernel_size&lt;/code&gt; will be used</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="853252d1cb8e53ec5f6c1f1eee0e317901dfd0af" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;divisor_override&lt;/strong&gt; &amp;ndash; if specified, it will be used as divisor, otherwise size of the pooling region will be used. Default: None</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25dd43997ffb2286d38c5c4ea638d851750fdcd1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dlpack&lt;/strong&gt; &amp;ndash; a PyCapsule object with the dltensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79e803c5014bf096c8b936c68165b4355eadf0c8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;do_constant_folding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default False&lt;/em&gt;) &amp;ndash; If True, the constant-folding optimization is applied to the model during export. Constant-folding optimization will replace some of the ops that have all constant inputs, with pre-computed constant nodes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93e1868e986f20e5fceebb1ba081741a9c11926d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dropout&lt;/strong&gt; &amp;ndash; If non-zero, introduces a &lt;code&gt;Dropout&lt;/code&gt; layer on the outputs of each GRU layer except the last layer, with dropout probability equal to &lt;code&gt;dropout&lt;/code&gt;. Default: 0</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1651899fbda49e6928ea8a0d295e3cfc914c011" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dropout&lt;/strong&gt; &amp;ndash; If non-zero, introduces a &lt;code&gt;Dropout&lt;/code&gt; layer on the outputs of each LSTM layer except the last layer, with dropout probability equal to &lt;code&gt;dropout&lt;/code&gt;. Default: 0</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96b84bd1caf45dc07546855562b7416fae84878a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dropout&lt;/strong&gt; &amp;ndash; If non-zero, introduces a &lt;code&gt;Dropout&lt;/code&gt; layer on the outputs of each RNN layer except the last layer, with dropout probability equal to &lt;code&gt;dropout&lt;/code&gt;. Default: 0</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f96b6d7bf1dc804d0874288692d31f0b71cf772" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dropout&lt;/strong&gt; &amp;ndash; a Dropout layer on attn_output_weights. Default: 0.0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea212a4ef049bb5d0535242d99d1a83d7b9f7d0a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dropout&lt;/strong&gt; &amp;ndash; the dropout value (default=0.1).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16fb29d21cd7a9ad4206efc9c506ce5a9cf98a02" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dst&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Destination rank</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebbff8f7d1835173bbe908168f4d760a0e927d2a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dst&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Destination rank.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c997f09b2bb6f5bbe4285b29caa42aeff58eb4c8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dst&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Destination rank (default is 0)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15d2bdadaa3b397c334c7c569c4166d8c09f9b73" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dst&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; Full path where object will be saved, e.g. &lt;code&gt;/tmp/temporary_file&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1bb062fcb22edc7afbb4e01d163cf5831e179573" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dst_tensor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Destination tensor rank within &lt;code&gt;tensor_list&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="819196b391e0255903f0858db2143983b3dedb91" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dst_type&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#type&quot;&gt;type&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;string&lt;/em&gt;) &amp;ndash; the desired type</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a4c495b44f4761667112255e495ba6d941ec366" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; &amp;ndash; data type of output Quantized Tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1da9e6e49781bd49b10cf164e54cc534c373f2b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; &amp;ndash; quantization data type to use. Default: &lt;code&gt;torch.quint8&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8b67954b83b4c9aa34630f43e704bf025dc94fd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;) &amp;ndash; the desired data type of returned tensor. Has to be one of the quantized dtypes: &lt;code&gt;torch.quint8&lt;/code&gt;, &lt;code&gt;torch.qint8&lt;/code&gt;, &lt;code&gt;torch.qint32&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e55ae84264ba3b49b96fa73c9f49b02e373e50a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired data type of returned Tensor. Default: if &lt;code&gt;None&lt;/code&gt;, defaults to the dtype of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36bd900451348a91ef9ce9e64799f6d5a6c72b59" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired data type of returned tensor. Default: &lt;code&gt;torch.int64&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d58f90cb68e79cff8b96e7dc86dd4a2d5606995" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired data type of returned tensor. Default: if &lt;code&gt;None&lt;/code&gt;, &lt;code&gt;torch.long&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d27c0b19831af56deba70f9352bc038b1e9a426" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired data type of returned tensor. Default: if &lt;code&gt;None&lt;/code&gt;, infers data type from &lt;code&gt;data&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="754f71e33b12e157331fb5bf10e0619a8ecbce0d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired data type of returned tensor. Default: if &lt;code&gt;None&lt;/code&gt;, uses a global default (see &lt;a href=&quot;torch.set_default_tensor_type#torch.set_default_tensor_type&quot;&gt;&lt;code&gt;torch.set_default_tensor_type()&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e1aa8968192882a073c78793ea32a16dd1c21d1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired data type of returned tensor. Default: if &lt;code&gt;None&lt;/code&gt;, uses a global default (see &lt;a href=&quot;torch.set_default_tensor_type#torch.set_default_tensor_type&quot;&gt;&lt;code&gt;torch.set_default_tensor_type()&lt;/code&gt;&lt;/a&gt;). If &lt;code&gt;dtype&lt;/code&gt; is not given, infer the data type from the other input arguments. If any of &lt;code&gt;start&lt;/code&gt;, &lt;code&gt;end&lt;/code&gt;, or &lt;code&gt;stop&lt;/code&gt; are floating-point, the &lt;code&gt;dtype&lt;/code&gt; is inferred to be the default dtype, see &lt;a href=&quot;torch.get_default_dtype#torch.get_default_dtype&quot;&gt;&lt;code&gt;get_default_dtype()&lt;/code&gt;&lt;/a&gt;. Otherwise, the &lt;code&gt;dtype&lt;/code&gt; is inferred to be &lt;code&gt;torch.int64&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b423086bd082fcebc5a428940e93eeaaa4a7025" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired data type of returned tensor. Default: if &lt;code&gt;None&lt;/code&gt;, uses a global default (see &lt;a href=&quot;torch.set_default_tensor_type#torch.set_default_tensor_type&quot;&gt;&lt;code&gt;torch.set_default_tensor_type()&lt;/code&gt;&lt;/a&gt;). Only floating point types are supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f1237018b147643a39f3e093d71d66749f7520f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired data type of returned tensor. Default: if None, infers data type from &lt;code&gt;values&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="242051541efaa2777f5472bfe169a3381046ea24" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired data type of returned tensor. If specified, the input tensor is casted to :attr:&amp;rsquo;dtype&amp;rsquo; while performing the operation. Default: None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="802bfb2cb709fdad8389996e31ce1fc046b7a6a7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired data type of returned tensor. If specified, the input tensor is casted to &lt;code&gt;dtype&lt;/code&gt; before the operation is performed. This is useful for preventing data type overflows. Default: None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf97cc7b5c225fd6d7e718d925da7641ae8dd16c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#type&quot;&gt;type&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;string&lt;/em&gt;) &amp;ndash; The desired type</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="697b78c37ec8949c304299db02bbd09794133985" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired type of returned tensor. Default: if None, same &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; as this tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6ad67e837a7a5413b747672aa87555a7798fda9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;code&gt;torch.dtype&lt;/code&gt;) &amp;ndash; the desired floating point type of the floating point parameters and buffers in this module</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f854a7599c513f55feb63cd3cceed0c39260832a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;code&gt;torch.dtype&lt;/code&gt;, optional) &amp;ndash; If specified, the input tensor is cast to &lt;code&gt;dtype&lt;/code&gt; before performing the operation, and the returned tensor&amp;rsquo;s type will be &lt;code&gt;dtype&lt;/code&gt;. If this argument is used in conjunction with the &lt;code&gt;out&lt;/code&gt; argument, the output tensor&amp;rsquo;s type must match this argument or a RuntimeError will be raised. This argument is not currently supported for &lt;code&gt;ord='nuc'&lt;/code&gt; or &lt;code&gt;ord='fro'&lt;/code&gt;. Default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf0e16ba6689c6aefebe41b2f37216499a3bab49" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;code&gt;torch.dtype&lt;/code&gt;, optional) &amp;ndash; the desired data type of returned Tensor. Default: dtype of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ddf34144bdd895ef81d56a2e64c3a31dcfb71d3f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;code&gt;torch.dtype&lt;/code&gt;, optional) &amp;ndash; the desired data type of returned tensor. If specified, the input tensor is casted to &lt;code&gt;dtype&lt;/code&gt; before the operation is performed. This is useful for preventing data type overflows. Default: None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5aa3ffb5214bb07d706f4bff69889b064a67a58" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;code&gt;torch.dtype&lt;/code&gt;, optional) &amp;ndash; the desired data type of the returned tensor. Default: &lt;code&gt;torch.float32&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c192f6abd14a8034e24d8a96ca7b9be11ad48f2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dx&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; The distance between points at which &lt;code&gt;y&lt;/code&gt; is sampled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="103894978c9b529418b87fd9904f3950e5930d8e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dynamic_axes&lt;/strong&gt; (&lt;em&gt;dict&amp;lt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;dict&amp;lt;python:int&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;string&amp;gt;&amp;gt;&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;dict&amp;lt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;(&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;)&lt;/em&gt;&lt;em&gt;&amp;gt;&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default empty dict&lt;/em&gt;) &amp;ndash;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4fbef8984bd074ea0df43f49dda2d6246584439" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;edgeitems&lt;/strong&gt; &amp;ndash; Number of array items in summary at beginning and end of each dimension (default = 3).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42415c6475a98e0f1fa07ebf4b124d7a8ce2a188" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eigenvalues&lt;/strong&gt; (&lt;em&gt;Tensor&lt;/em&gt;): Shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fdaa0feae05488ebb171b346905c4f5b577cb835" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eigenvectors&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; &lt;code&gt;True&lt;/code&gt; to compute both eigenvalues and eigenvectors; otherwise, only eigenvalues will be computed</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="678dbd774fefa060e069a5a389a8baecab662449" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eigenvectors&lt;/strong&gt; (&lt;em&gt;Tensor&lt;/em&gt;): If &lt;code&gt;eigenvectors=False&lt;/code&gt;, it&amp;rsquo;s an empty tensor. Otherwise, this tensor of shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="850ac1cd20b0b0fc94fb9c8edab9b43e67eaf290" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eigenvectors&lt;/strong&gt; (&lt;em&gt;Tensor&lt;/em&gt;): Shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad4105465a171ee7fcc51139dea5abbe36639f29" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eigenvectors&lt;/strong&gt; (&lt;em&gt;boolean&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether eigenvectors have to be computed</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a63d80190229ce72c85a7e6560054704380577ab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;elementwise_affine&lt;/strong&gt; &amp;ndash; a boolean value that when set to &lt;code&gt;True&lt;/code&gt;, this module has learnable per-element affine parameters initialized to ones (for weights) and zeros (for biases). Default: &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d18cda3fe2834c321ed263a1762695dafaa4d1b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;embed_dim&lt;/strong&gt; &amp;ndash; total dimension of the model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa8b03fcaceb218feac127ba1ed55359bc28eca3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;embedding_dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the size of each embedding vector</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de1af4e04b664f6ae8d83d1e7d608531b740f185" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;embeddings&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; FloatTensor containing weights for the Embedding. First dimension is being passed to Embedding as &lt;code&gt;num_embeddings&lt;/code&gt;, second as &lt;code&gt;embedding_dim&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06e3728c866bf657f051e1739af9167591891b44" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;embeddings&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; FloatTensor containing weights for the EmbeddingBag. First dimension is being passed to EmbeddingBag as &amp;lsquo;num_embeddings&amp;rsquo;, second as &amp;lsquo;embedding_dim&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0ff1217368a5b45df32d944d2dd475690d13d9f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;enable&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether to enable uneven input detection or not. Pass in &lt;code&gt;enable=False&lt;/code&gt; to disable in cases where you know that inputs are even across participating processes. Default is &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7081365cba99386e7771c337648ca106e830b0f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;enable_onnx_checker&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default True&lt;/em&gt;) &amp;ndash; If True the onnx model checker will be run as part of the export, to ensure the exported model is a valid ONNX model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b5bbce56260acf11245d762cd1bb7f8add8801b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;encoder_layer&lt;/strong&gt; &amp;ndash; an instance of the TransformerEncoderLayer() class (required).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d84a97832788a91df32af257307532f9760f3b9c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;end&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor with the ending points</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d5c9c4c24dd3af3a29f20c653c917dfea2df720" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;end&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the ending value for the set of points</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6472482679cdc676a7850881f5d00cc512baada7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;end&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; the ending value for the set of points</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="841fff8e784294f57ea3f8ba62be671371d870ec" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;end_dim&lt;/strong&gt; &amp;ndash; last dim to flatten (default = -1).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c799ddd223af170e7b8eec13d7b2c9d7165d8603" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;end_dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the last dim to flatten</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a6422972f6f1ee1d35eb1fc402a56304ba9816a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;enforce_sorted&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, checks that the input contains sequences sorted by length in a decreasing order. If &lt;code&gt;False&lt;/code&gt;, this condition is not checked. Default: &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f8c91d834d8c02f59864a331664c622e334c3693" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;enforce_sorted&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, the input is expected to contain sequences sorted by length in a decreasing order. If &lt;code&gt;False&lt;/code&gt;, the input will get sorted unconditionally. Default: &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d07cc920f4a588343d52b60256e017a7987131f3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eps&lt;/strong&gt; &amp;ndash; a value added to the denominator for numerical stability. Default: 1e-5</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f8684696132f475ee9f33febf9c44e66f038a87a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eps&lt;/strong&gt; &amp;ndash; a value added to the denominator for numerical stability. Default: &lt;code&gt;1e-5&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac6c5326b4eb0b53657544fec8194ff31859de16" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; small value to avoid division by zero. Default: 1e-12</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3071da796481042a1779ea93a5637a546557315" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Small value to avoid division by zero. Default: 1e-6</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bfa6309f005abf8cb4486bcdb54e88aa5722cf1c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Small value to avoid division by zero. Default: 1e-8</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a35a97bcd21164533c2c178f41069f2aca802198" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Small value to avoid evaluation of</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e84e8770e10ffa80ab0cd44b0a601016d1c45b1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; epsilon for numerical stability in calculating norms</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64bfcd7f406bb75e0a20d11554ef0afad32ae5c2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the epsilon for input clamp bound. Default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7aa30076d7d518c87037ac60ab79f79f7490d2c2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;equal_nan&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, then two &lt;code&gt;NaN&lt;/code&gt; s will be considered equal. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f8913ade12e3dc4c4d8fd9b0228a8bcf2b585f3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;equation&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; The equation is given in terms of lower case letters (indices) to be associated with each dimension of the operands and result. The left hand side lists the operands dimensions, separated by commas. There should be one index letter per tensor dimension. The right hand side follows after &lt;code&gt;-&amp;gt;&lt;/code&gt; and gives the indices for the output. If the &lt;code&gt;-&amp;gt;&lt;/code&gt; and right hand side are omitted, it implicitly defined as the alphabetically sorted list of all indices appearing exactly once in the left hand side. The indices not apprearing in the output are summed over after multiplying the operands entries. If an index appears several times for the same operand, a diagonal is taken. Ellipses &lt;code&gt;&amp;hellip;&lt;/code&gt; represent a fixed number of dimensions. If the right hand side is inferred, the ellipsis dimensions are at the beginning of the output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34f745bd094bd2de883ee47fbf1638e33919faba" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;example_inputs&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; A tuple of example inputs that will be passed to the function while tracing. The resulting trace can be run with inputs of different types and shapes assuming the traced operations support those types and shapes. &lt;code&gt;example_inputs&lt;/code&gt; may also be a single Tensor in which case it is automatically wrapped in a tuple.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="618d999c8d78a9676692412df718e533abdf676f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;example_outputs&lt;/strong&gt; (&lt;em&gt;tuple of Tensors&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default None&lt;/em&gt;) &amp;ndash; Model&amp;rsquo;s example outputs being exported. example_outputs must be provided when exporting a ScriptModule or TorchScript Function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a88c1284ab82b366b962ae9cc9b58fad7708160" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;exponent&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the exponent tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00243251e0e37f0ed072fb8db0c41a52c671837f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;exponent&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tensor&lt;/em&gt;) &amp;ndash; the exponent value</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcb9c92fd7acb8cc56e2900598ba04b5be24aae8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;export_params&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default True&lt;/em&gt;) &amp;ndash; if specified, all parameters will be exported. Set this to False if you want to export an untrained model. In this case, the exported model will first take all of its parameters as arguments, the ordering as specified by &lt;code&gt;model.state_dict().values()&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f60c4eee6ac8bd3b83d115e58f8f9d5c6a1f285a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;export_raw_ir&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default False&lt;/em&gt;) &amp;ndash; [DEPRECATED. use operator_export_type] export the internal IR directly instead of converting it to ONNX ops.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e82a47709effdd4ed45378b2094bb76a83f236b5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;external_data_format&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default False&lt;/em&gt;) &amp;ndash; If True, then the model is exported in ONNX external data format, in which case some of the model parameters are stored in external binary files and not in the ONNX model file itself. See link for format details: &lt;a href=&quot;https://github.com/onnx/onnx/blob/8b3f7e2e7a0f2aba0e629e23d89f07c7fc0e6a5e/onnx/onnx.proto#L423&quot;&gt;https://github.com/onnx/onnx/blob/8b3f7e2e7a0f2aba0e629e23d89f07c7fc0e6a5e/onnx/onnx.proto#L423&lt;/a&gt; Also, in this case, argument &amp;lsquo;f&amp;rsquo; must be a string specifying the location of the model. The external binary files will be stored in the same location specified by the model location &amp;lsquo;f&amp;rsquo;. If False, then the model is stored in regular format, i.e. model and parameters are all in one file. This argument is ignored for all export types other than ONNX.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="778fd667aea6cff6dc8d68bb20cefa3e389d87e6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;extra_cflags&lt;/strong&gt; &amp;ndash; optional list of compiler flags to forward to the build.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcbab5a7fa61c6ed8414a66172d5505acca2751e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;extra_cuda_cflags&lt;/strong&gt; &amp;ndash; optional list of compiler flags to forward to nvcc when building CUDA sources.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5906d2861e5b04548eb15a5d2b6487f486e2e624" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;extra_include_paths&lt;/strong&gt; &amp;ndash; optional list of include directories to forward to the build.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62224af2d822c58c7d8e8fba25c2a2dc1f3ef2cb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;extra_ldflags&lt;/strong&gt; &amp;ndash; optional list of linker flags to forward to the build.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6f0cc911afdf14389ad75575a9c9cbfa3c8ccfb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;f&lt;/strong&gt; &amp;ndash; A file-like object (has to implement write and flush) or a string containing a file name.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0bbf42a4b349b4674d2d35b2fcc87d253370be87" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;f&lt;/strong&gt; &amp;ndash; a file-like object (has to implement &lt;code&gt;read()&lt;/code&gt;, :meth`readline`, :meth`tell`, and :meth`seek`), or a string or os.PathLike object containing a file name</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54a2a51aa44ae289f486330a5f54f09e6f971a65" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;f&lt;/strong&gt; &amp;ndash; a file-like object (has to implement fileno that returns a file descriptor) or a string containing a file name. A binary Protobuf will be written to this file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="677757134bd8309ac15335a18ed7a21b22ef8fdd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;f&lt;/strong&gt; &amp;ndash; a file-like object (has to implement read, readline, tell, and seek), or a string containing a file name</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df677cb77b7f5749b31ae401c7fa92ff2d7e7fe5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;f&lt;/strong&gt; &amp;ndash; a file-like object (has to implement write and flush) or a string or os.PathLike object containing a file name</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="635ef0bc301d974c0ff51acd3ba7ee21d88b4744" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;faces&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; Indices of vertices within each triangle. (Optional)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d42958804dd0465816b20a88c367eef0dbeec80" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;factorization&lt;/strong&gt; (&lt;em&gt;Tensor&lt;/em&gt;): the factorization of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00769844b4ecc2fca40878cb1764ed386aa09fd9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;figure&lt;/strong&gt; (&lt;em&gt;matplotlib.pyplot.figure&lt;/em&gt;) &amp;ndash; Figure or a list of figures</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62d218fbe21b9a87d144357ac35b2f10bb534799" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;file_name&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; path of the file in which to store the key-value pairs</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3c0dee521e2626c0ae3dbbaa2f17cc80f80c2a7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;file_name&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; name for the downloaded file. Filename from &lt;code&gt;url&lt;/code&gt; will be used if not set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57269f4bfae1f1ca10e35c956f9fd6e448de9061" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;filename&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; file name to map</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95d303dabfba56a1b6870b6f2026c68bddc1be2f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;filename_suffix&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; Suffix added to all event filenames in the log_dir directory. More details on filename construction in tensorboard.summary.writer.event_file_writer.EventFileWriter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cdb4a6b44cef668e406b3d993df10539cc0f7054" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;fill_value&lt;/strong&gt; &amp;ndash; the number to fill the output tensor with.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc362ae2525be68e4bb10eb869fbbb29641c9bab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;fill_value&lt;/strong&gt; (&lt;em&gt;Scalar&lt;/em&gt;) &amp;ndash; the fill value</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="81b7336ac76bc7cac5103fa2f7d2fd03ba164f85" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;fill_value&lt;/strong&gt; (&lt;em&gt;Scalar&lt;/em&gt;) &amp;ndash; the value to fill the output tensor with.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2031b6ba05d0b93a6457f0efd37cfe00b19e577a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;fill_value&lt;/strong&gt; (&lt;em&gt;scalar&lt;/em&gt;) &amp;ndash; the number to fill the output tensor with.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9096ebbb1f99e7416acc6998a05334d6d6397c19" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;find_unused_parameters&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Traverse the autograd graph from all tensors contained in the return value of the wrapped module&amp;rsquo;s &lt;code&gt;forward&lt;/code&gt; function. Parameters that don&amp;rsquo;t receive gradients as part of this graph are preemptively marked as being ready to be reduced. Note that all &lt;code&gt;forward&lt;/code&gt; outputs that are derived from module parameters must participate in calculating loss and later the gradient computation. If they don&amp;rsquo;t, this wrapper will hang waiting for autograd to produce gradients for those parameters. Any outputs derived from module parameters that are otherwise unused can be detached from the autograd graph using &lt;code&gt;torch.Tensor.detach&lt;/code&gt;. (default: &lt;code&gt;False&lt;/code&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="355396a4b2ab68b82f509c2d4c2526e2d2ba215d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;flush_secs&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; How often, in seconds, to flush the pending events and summaries to disk. Default is every two minutes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5d2a692102bf116db7e2c67b38b6073ed5ae103" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;fn&lt;/strong&gt; (&lt;a href=&quot;#torch.nn.Module&quot;&gt;&lt;code&gt;Module&lt;/code&gt;&lt;/a&gt; -&amp;gt; None) &amp;ndash; function to be applied to each submodule</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad87b9b261bd0e692ec81745b0251ab69e0c920a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;fn&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;&lt;code&gt;Module&lt;/code&gt;&lt;/a&gt; -&amp;gt; None) &amp;ndash; function to be applied to each submodule</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="053dcf87d7e84dd407dec8695847c296ae6c0c48" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;fn&lt;/strong&gt; (&lt;code&gt;Module&lt;/code&gt; -&amp;gt; None) &amp;ndash; function to be applied to each submodule</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ef37f45041ae6f49569ea35c632856c2fd1d15d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;force_reload&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to discard the existing cache and force a fresh download. Default is &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc70a2bb2f4ed4bcf5ecccaecd8c2e734de9391d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;force_reload&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to force a fresh download of the github repo unconditionally. Does not have any effect if &lt;code&gt;source = 'local'&lt;/code&gt;. Default is &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83c137929bf36e8aef1d6a6cc8426a81216a787f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;fps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Frames per second</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bde664f21923dc747ecb17124d60a563c8fc2b2c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;freeze&lt;/strong&gt; (&lt;em&gt;boolean&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, the tensor does not get updated in the learning process. Equivalent to &lt;code&gt;embedding.weight.requires_grad = False&lt;/code&gt;. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3fd0568363b2aa7dd7b7c7e651d3c4c84a69bed" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;freeze&lt;/strong&gt; (&lt;em&gt;boolean&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, the tensor does not get updated in the learning process. Equivalent to &lt;code&gt;embeddingbag.weight.requires_grad = False&lt;/code&gt;. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ba291fa349a86b63b98c719b0de8e1e3a0b2ccd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;from&lt;/strong&gt; (&lt;em&gt;dpython:type&lt;/em&gt;) &amp;ndash; The original &lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="46bb4df94b1ad85e11557fbf62e5528ed469cf66" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;full&lt;/strong&gt; &amp;ndash; whether to compute full loss, i. e. to add the Stirling approximation term. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75533226793ba470c8b0b1c360399ebe87a93520" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;full&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65a3ef606b557f50e8baa66a8411c285745d744f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;func&lt;/strong&gt; (&lt;em&gt;callable&lt;/em&gt;) &amp;ndash; a callable function, such as Python callables, builtin operators (e.g. &lt;a href=&quot;generated/torch.add#torch.add&quot;&gt;&lt;code&gt;add()&lt;/code&gt;&lt;/a&gt;) and annotated TorchScript functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eab18ced6b9533ad0e16e9973e883f1659631001" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;func&lt;/strong&gt; (&lt;em&gt;callable&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;torch.nn.Module&lt;/a&gt;) &amp;ndash; A Python function or &lt;code&gt;torch.nn.Module&lt;/code&gt; that will be invoked. If executed in TorchScript, it will execute asynchronously, otherwise it will not. Traced invocations of fork will be captured in the IR.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e13542d19949849cdfa6d1ca4a6a3c14a44f62f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;func&lt;/strong&gt; (&lt;em&gt;callable&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;torch.nn.Module&lt;/a&gt;) &amp;ndash; A Python function or &lt;code&gt;torch.nn.Module&lt;/code&gt; that will be run with &lt;code&gt;example_inputs&lt;/code&gt;. &lt;code&gt;func&lt;/code&gt; arguments and return values must be tensors or (possibly nested) tuples that contain tensors. When a module is passed &lt;code&gt;torch.jit.trace&lt;/code&gt;, only the &lt;code&gt;forward&lt;/code&gt; method is run and traced (see &lt;a href=&quot;torch.jit.trace_module#torch.jit.trace_module&quot;&gt;&lt;code&gt;torch.jit.trace&lt;/code&gt;&lt;/a&gt; for details).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76d83916ad9f858f16111887e3f6267b2fca5fed" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;function&lt;/strong&gt; &amp;ndash; describes what to run in the forward pass of the model or part of the model. It should also know how to handle the inputs passed as the tuple. For example, in LSTM, if user passes &lt;code&gt;(activation, hidden)&lt;/code&gt;, &lt;code&gt;function&lt;/code&gt; should correctly use the first input as &lt;code&gt;activation&lt;/code&gt; and the second input as &lt;code&gt;hidden&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1961467ba2825e1c559db8b59ff1bdbcbb0ec039" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;functions&lt;/strong&gt; &amp;ndash; A &lt;a href=&quot;generated/torch.nn.sequential#torch.nn.Sequential&quot;&gt;&lt;code&gt;torch.nn.Sequential&lt;/code&gt;&lt;/a&gt; or the list of modules or functions (comprising the model) to run sequentially.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2fb5cc79b41c4d978a0a328aa05327cc1e203720" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;functions&lt;/strong&gt; &amp;ndash; A list of function names for which to generate function bindings. If a dictionary is given, it should map function names to docstrings (which are otherwise just the function names).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb85d27a8748aad626d3af5de9e7af60b244f74d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;futures&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; a list of &lt;a href=&quot;#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a7221601ceeb930d343f7319c8db14fe03b3e16" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;futures&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; a list of &lt;a href=&quot;#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; objects.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba355c7f4beca0e0d4bf68bb3971593069c56322" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;gain&lt;/strong&gt; &amp;ndash; an optional scaling factor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b04565ecc2229736f50e2b26ed78404ea530d53b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;gain&lt;/strong&gt; &amp;ndash; optional scaling factor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b03754a8da7ef008224ed892c921fb9371f0c076" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;gather_list&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; List of appropriately-sized tensors to use for gathered data (default is None, must be specified on the destination rank)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5579060ab76636341f5dfd97c022a89f302b7cf" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;generator&lt;/strong&gt; (&lt;a href=&quot;torch.generator#torch.Generator&quot;&gt;&lt;code&gt;torch.Generator&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; a pseudorandom number generator for sampling</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06014c6b4c4693a7e3fbaf2b2a37ca8411e8162c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;get_infos&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if set to &lt;code&gt;True&lt;/code&gt;, returns an info IntTensor. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="713f3c8adc9b7748672962092ba1c2254277918b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;github&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; a string with format &amp;ldquo;repo_owner/repo_name[:tag_name]&amp;rdquo; with an optional tag/branch. The default branch is &lt;code&gt;master&lt;/code&gt; if not specified. Example: &amp;lsquo;pytorch/vision[:hub]&amp;rsquo;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="270e6272159af8294641789a5ae5029a0175a0a4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;github&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; a string with format &amp;lt;repo_owner/repo_name[:tag_name]&amp;gt; with an optional tag/branch. The default branch is &lt;code&gt;master&lt;/code&gt; if not specified. Example: &amp;lsquo;pytorch/vision[:hub]&amp;rsquo;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34a7ff872bd23abb0450fda48dac267f7a245b6a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;global_step&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Global step value to record</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="59b52c7e39a474423f9fda9eb51f75f802a681a8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;graceful&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether to do a graceful shutdown or not. If True, this will 1) wait until there is no pending system messages for &lt;code&gt;UserRRefs&lt;/code&gt; and delete them; 2) block until all local and remote RPC processes have reached this method and wait for all outstanding work to complete.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="799013c067a407e423f9d42197eba6a2384dd6a4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;gradient&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/constants.html#None&quot;&gt;None&lt;/a&gt;) &amp;ndash; Gradient w.r.t. the tensor. If it is a tensor, it will be automatically converted to a Tensor that does not require grad unless &lt;code&gt;create_graph&lt;/code&gt; is True. None values can be specified for scalar Tensors or ones that don&amp;rsquo;t require grad. If a None value would be acceptable then this argument is optional.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b29df415efb0eea8f8662bee6b939588b9b78efb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;gradient_as_bucket_view&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; This is a prototype feature and subject to changes. When set to &lt;code&gt;True&lt;/code&gt;, gradients will be views pointing to different offsets of &lt;code&gt;allreduce&lt;/code&gt; communication buckets. This can reduce peak memory usage, where the saved memory size will be equal to the total gradients size. Moreover, it avoids the overhead of copying between gradients and &lt;code&gt;allreduce&lt;/code&gt; communication buckets. When gradients are views, &lt;code&gt;detach_()&lt;/code&gt; cannot be called on the gradients. If hitting such errors, please fix it by referring to the &lt;a href=&quot;../optim#torch.optim.Optimizer.zero_grad&quot;&gt;&lt;code&gt;zero_grad()&lt;/code&gt;&lt;/a&gt; function in &lt;code&gt;torch/optim/optimizer.py&lt;/code&gt; as a solution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2b0bcce70df29844281ac614b0f8a39a0dfcd19" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;grid&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; flow-field of shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4db1041ae201d7e927245f12103bcee3afeae410" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;group&lt;/strong&gt; (&lt;em&gt;ProcessGroup&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The process group to work on</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1110361e162f3be4aa9b1a7cde1a491603596b93" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;group&lt;/strong&gt; (&lt;em&gt;ProcessGroup&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The process group to work on.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6db70a258153314cde5304ac47d562305e99552a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;group&lt;/strong&gt; (&lt;em&gt;ProcessGroup&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The process group to work on. The default is the general main process group. If another specific group is specified, the calling process must be part of &lt;code&gt;group&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85aa3c312919cb9842e6de299fa1fb86a7f7ea49" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;group_name&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;deprecated&lt;/em&gt;) &amp;ndash; Group name.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f26fa12d9d61e6585a36de452da97d2ffce8b34d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;groups&lt;/strong&gt; &amp;ndash; split input into groups,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="81c8b7e8acb12c23d521a687adf35816ef4ff39c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;groups&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Number of blocked connections from input channels to output channels. Default: 1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3936cb9ca5f3782dc3736b1eb2710d73d6c56d73" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;groups&lt;/strong&gt; (&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; number of groups in the conv layer (default: 1)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9313fa876c33968ef38e2bc5ed5adcaf010be99" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;h&amp;rsquo;&lt;/strong&gt; of shape &lt;code&gt;(batch, hidden_size)&lt;/code&gt;: tensor containing the next hidden state for each element in the batch</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1592eedf3bb9a47887176fd782c28510508c7820" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;h_0&lt;/strong&gt; of shape &lt;code&gt;(batch, hidden_size)&lt;/code&gt;: tensor containing the initial hidden state for each element in the batch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfde5becd622ec62656a4cff95b1913fb5911358" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;h_0&lt;/strong&gt; of shape &lt;code&gt;(num_layers * num_directions, batch, hidden_size)&lt;/code&gt;: tensor containing the initial hidden state for each element in the batch. Defaults to zero if not provided. If the RNN is bidirectional, num_directions should be 2, else it should be 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a088baa848abf407fdf324f68a7fc23226f3bfd9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;h_0&lt;/strong&gt; of shape &lt;code&gt;(num_layers * num_directions, batch, hidden_size)&lt;/code&gt;: tensor containing the initial hidden state for each element in the batch. If the LSTM is bidirectional, num_directions should be 2, else it should be 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0e30ccc3d1652af234e0543d06149d194f40bc0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;h_1&lt;/strong&gt; of shape &lt;code&gt;(batch, hidden_size)&lt;/code&gt;: tensor containing the next hidden state for each element in the batch</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1c9ba2b299c711fcc8d467de3dea8569b50a3fa" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;h_n&lt;/strong&gt; of shape &lt;code&gt;(num_layers * num_directions, batch, hidden_size)&lt;/code&gt;: tensor containing the hidden state for &lt;code&gt;t = seq_len&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3525fd2429c6604b476c82ddd74f59209ab301ef" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;h_n&lt;/strong&gt; of shape &lt;code&gt;(num_layers * num_directions, batch, hidden_size)&lt;/code&gt;: tensor containing the hidden state for &lt;code&gt;t = seq_len&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba61e8234e80482584a34f381f7534bd9ba1d290" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;hard&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, the returned samples will be discretized as one-hot vectors, but will be differentiated as if it is the soft sample in autograd</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aaa96a08f23e0f6a631877636b216cb602e637fa" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;hash_prefix&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If not None, the SHA256 downloaded file should start with &lt;code&gt;hash_prefix&lt;/code&gt;. Default: None</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b66c30a2662d014769668efe291e7362c5d7d9db" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;head_bias&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, adds a bias term to the &amp;lsquo;head&amp;rsquo; of the adaptive softmax. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d30e56690f484d3c8d7a2b255db4bcbd77445f68" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;hidden&lt;/strong&gt; of shape &lt;code&gt;(batch, hidden_size)&lt;/code&gt;: tensor containing the initial hidden state for each element in the batch. Defaults to zero if not provided.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e67734f0b9cf7c79bc74ff13156c666a023e5f41" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;hidden_size&lt;/strong&gt; &amp;ndash; The number of features in the hidden state &lt;code&gt;h&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3705e6bc9a6ecd869a7951f814f9fed46d9ff630" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;high&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; One above the highest integer to be drawn from the distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c19ea35377296f18df50a468ab31eff648558a09" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;hop_length&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the distance between neighboring sliding window frames. Default: &lt;code&gt;None&lt;/code&gt; (treated as equal to &lt;code&gt;floor(n_fft / 4)&lt;/code&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1396026b4c7368bc625f59b4932fadbbf084c72" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;hop_length&lt;/strong&gt; (&lt;em&gt;Optional&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; The distance between neighboring sliding window frames. (Default: &lt;code&gt;n_fft // 4&lt;/code&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6876910fda4d6ecccd2051aba33481c94d9368b9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;host_name&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; The hostname or IP Address the server store should run on.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94284103cfc33f19f8a61eebc94176be0db80646" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;hparam_dict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;) &amp;ndash; Each key-value pair in the dictionary is the name of the hyper parameter and it&amp;rsquo;s corresponding value. The type of the value can be one of &lt;code&gt;bool&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;, &lt;code&gt;float&lt;/code&gt;, &lt;code&gt;int&lt;/code&gt;, or &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a1b563f2476f046122b214d6a9600f12ff9315b6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;hparam_domain_discrete&lt;/strong&gt; &amp;ndash; (Optional[Dict[str, List[Any]]]) A dictionary that contains names of the hyperparameters and all discrete values they can hold</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98aaeaa4225400ecd738ec2048d131fe08b1d564" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;iK&lt;/strong&gt; (&lt;em&gt;tensor&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the input tensor of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e423e9ecf3beffc0eedb4329822c8534728b01ad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ignore_index&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies a target value that is ignored and does not contribute to the input gradient. When &lt;code&gt;size_average&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the loss is averaged over non-ignored targets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="607b11f999212773791595ce05953927928c08a6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ignore_index&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies a target value that is ignored and does not contribute to the input gradient. When &lt;code&gt;size_average&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the loss is averaged over non-ignored targets. Default: -100</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c096d38fe26de10e968164a6aecd6f913177ea6e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;imag&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The imaginary part of the complex tensor. Must be same dtype as &lt;a href=&quot;torch.real#torch.real&quot;&gt;&lt;code&gt;real&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3a96d8bd554be6eb7797de17442ad6cb99464a8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;img_tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;numpy.array&lt;/em&gt;&lt;em&gt;, or &lt;/em&gt;&lt;em&gt;string/blobname&lt;/em&gt;) &amp;ndash; Image data</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e075b9a8dfd668778490588e84bb0c9bbb577a8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;in1_features&lt;/strong&gt; &amp;ndash; size of each first input sample</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99c9afda0be0c905049d69c6c60279520769cef1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;in2_features&lt;/strong&gt; &amp;ndash; size of each second input sample</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="054cbce99ed259e05737255fcff3ec1a33f17b30" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;in_channels&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Number of channels in the input image</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="031258926af2ce0c91f35de69ae4829af92fe5cc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;in_features&lt;/strong&gt; &amp;ndash; size of each input sample</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1cd84155beb6cb4e4e554a0fb3f34f7def9bf3d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;in_features&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Number of features in the input tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de92c22d2099710d576bc540cf0e439bfe62dc1b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;include_last_offset&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c77074d3fbe6ed19bba6e5a032d17feba927877" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;include_last_offset&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;offsets&lt;/code&gt; has one additional element, where the last element is equivalent to the size of &lt;code&gt;indices&lt;/code&gt;. This matches the CSR format.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="adc8afe3a34cbeea7690cc1b8d46533e74feca80" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;include_last_offset&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, the size of offsets is equal to the number of bags + 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0058952dc92b6430936a12a9320099bae5295fc6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;increasing&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Order of the powers of the columns. If True, the powers increase from left to right, if False (the default) they are reversed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d624060723fbf002e4598220b5812e19f26a17a7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;index&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; index to insert.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d2ab5af76f511772ee4673ede1ce34b868d76a5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;index&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the index to select with</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35fb618fa2c424e1e9473beb050f9175521a3241" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;index&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; indices of &lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;tensor&lt;/code&gt;&lt;/a&gt; to select from</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67e5b1c26904309bcbc72d6a5206411049f25fa6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;index&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; indices of &lt;code&gt;self&lt;/code&gt; tensor to fill in</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8699c1c42412268aa01357837b44ae957ac901c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;index&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; the 1-D tensor containing the indices to index</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b1088f3894e3a3aade31aa3da2f7cbaa1c7f3c7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;index&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; the indices of elements to gather</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7246e33903dd34811bb50beca86c9f179b0ea261" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;index&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; the indices of elements to scatter and add, can be either empty or the same size of src. When empty, the operation returns identity.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7891bb82e5f646ecc5571231eb40487d6adaedf7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;index&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; the indices of elements to scatter, can be either empty or the same size of src. When empty, the operation returns identity</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4489c58da0a616c049ed6d93d7f17fd55991d97a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;indices&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; the indices into self</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5be31c40930fbda8ef6fadbd69d27440a0a29e3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;indices&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; the indices into tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f340c71c41bf4a8b6f0ee0a633f1e707d60c41e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;indices&lt;/strong&gt; (&lt;em&gt;array_like&lt;/em&gt;) &amp;ndash; Initial data for the tensor. Can be a list, tuple, NumPy &lt;code&gt;ndarray&lt;/code&gt;, scalar, and other types. Will be cast to a &lt;code&gt;torch.LongTensor&lt;/code&gt; internally. The indices are the coordinates of the non-zero values in the matrix, and thus should be two-dimensional where the first dimension is the number of tensor dimensions and the second dimension is the number of non-zero values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bef6961ff826304ba68b7564bb99ad681fdaf697" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;indices&lt;/strong&gt; (&lt;em&gt;tuple of LongTensor&lt;/em&gt;) &amp;ndash; tensors used to index into &lt;code&gt;self&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d19cbf8a68fcf3b4f455172ecef9b16a565a113c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;infos&lt;/strong&gt; (&lt;em&gt;IntTensor&lt;/em&gt;, &lt;em&gt;optional&lt;/em&gt;): if &lt;code&gt;get_infos&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, this is a tensor of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71c1dcc99d861730834f2921fb9ea642ee26387c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;init&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the initial value of</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3387ec2d138470faa0b9b1e76a459e501c664a81" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;init_method&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The URL to initialize &lt;code&gt;ProcessGroupGloo&lt;/code&gt; (default: &lt;code&gt;env://&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da9829504ae0afe64db4aa47b65791dfaa083f83" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;init_method&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The URL to initialize the distributed store used for rendezvous. It takes any value accepted for the same argument of &lt;a href=&quot;distributed#torch.distributed.init_process_group&quot;&gt;&lt;code&gt;init_process_group()&lt;/code&gt;&lt;/a&gt; (default: &lt;code&gt;env://&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f325478530b5cf14071a5c700f82577ec5ba84d8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;init_method&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; URL specifying how to initialize the process group. Default is &amp;ldquo;env://&amp;rdquo; if no &lt;code&gt;init_method&lt;/code&gt; or &lt;code&gt;store&lt;/code&gt; is specified. Mutually exclusive with &lt;code&gt;store&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9fa891f80017cd81f628a35707cc9e6065a280f6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inplace&lt;/strong&gt; &amp;ndash; (Currently not supported) can optionally do the operation in-place.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df1cc134d4a1280a08aae8069753847bc753ab08" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inplace&lt;/strong&gt; &amp;ndash; If set to &lt;code&gt;True&lt;/code&gt;, will do this operation in-place. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a0af1cd98e89baa21a0964493ae5197db8d39c0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inplace&lt;/strong&gt; &amp;ndash; can optionally do the operation in-place. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75aed03563c53dd2d0764eb5453c6ca6e4140d83" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inplace&lt;/strong&gt; &amp;ndash; perform the computation inplace</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fdf58b63be55a4b22c46032d3fd1d61d0bd927a2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inplace&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If set to &lt;code&gt;True&lt;/code&gt;, will do this operation in-place</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2baabf2051ecce4e59ed7868711be86074a1121b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inplace&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; can optionally do the operation in-place. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ca73aff43bbd335b880e2e8b6461721261c7efd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; input matrix</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cb4517ba198e148817291a746b67bb3359b3275" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the &lt;code&gt;tau&lt;/code&gt; from &lt;a href=&quot;torch.geqrf#torch.geqrf&quot;&gt;&lt;code&gt;torch.geqrf()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14436103f8610b62c5af0d3f52320c0e695e6561" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input3&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the matrix to be multiplied.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="189471ee9fd0ae26f96b12a2f14fabdfdb2a55c8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d43b3b03e5e1cc0bc29a4d3ee11d035641542b7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash; A Tensor that is input to &lt;code&gt;functions&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3478ec4abd0f0da74946e0059075f92ae16838f6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash; Tensor of arbitrary shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64075621f7b49ac8cf3466ffee84214ef27b7e0d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash; expectation of underlying Poisson distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5c45d37ad1ca2bfd9ba95fc0c1c9aba750297da" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash; input tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fefd9a33978ca250fb3687e571631fed568e2f69" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash; input tensor of any shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32aa8fde0d3b37a5fd0bf094d226ea96d65d5b3e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash; input tensor of shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e71ece563e570f0828230ce4079bf1d6a1f9bfd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash; quantized input</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="324d485d4d64467111174a180760e99e40ae34f3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash; quantized input tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1052a12b95427668122c4a5782e7d1c6ced7fbb7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash; quantized input tensor of shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="280fc2140640a681bb0a76e2eacb285f4f40a9a9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash; the first input tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c5a3515f7ca1c5139e9f3360aa15d38e06b1c58" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; an input Tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0b781ff3e115b7562060e3796452984aec9e1bc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; 1-D input vector</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e381244bd054e5229323f3fd533dcf76ded11c1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; 1-d int tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="318151f5ec7778ddab17a5a32f68c531c8b678c8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; 1D vector.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="302e5c41a337c972f93ff08bf742872e6882489e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Must be at least 1-dimensional.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9cff6b01a05d93e056d3e7d25e27d95e0d5b44d9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Must be at least 2-dimensional.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="508cdbc779d4073e5eafa0ff8836504797cfe9a3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The input tensor of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11314dbf954d397fca1f11546d1c56bacc29ebd7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The input tensor. Expected to be output of &lt;a href=&quot;torch.stft#torch.stft&quot;&gt;&lt;code&gt;stft()&lt;/code&gt;&lt;/a&gt;, can either be complex (&lt;code&gt;channel&lt;/code&gt;, &lt;code&gt;fft_size&lt;/code&gt;, &lt;code&gt;n_frame&lt;/code&gt;), or real (&lt;code&gt;channel&lt;/code&gt;, &lt;code&gt;fft_size&lt;/code&gt;, &lt;code&gt;n_frame&lt;/code&gt;, 2) where the &lt;code&gt;channel&lt;/code&gt; dimension is optional.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25819484e745b900dfb30d16e53f617750bd99ab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; a minibatch of examples</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8a8643fc96ff022524bbbbcc16e1f74f4d027fc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; first tensor in the dot product. Its conjugate is used if it&amp;rsquo;s complex.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3329ef02c74e5cee67f1ff96ed2733ed78e48c67" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; first tensor to compare</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6c3db01982d7f9c54ac50853d8f1beed2cda65f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; float tensor to quantize</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c7042dc3bf98959f56c246765073fdcc4437d8b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; input matrix</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2add4041984cdf88b12d1f1e2dd5b3c7ef0a1d8c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; matrix to be added</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b95c32681c57401ab545053403e32395835243a1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; matrix to be multiplied</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b1dc1a962b67cc0e0f4fe6ec1e3b9ed6f855288" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; multiple right-hand sides of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd44d464e1aa57b95d0330a7218514f91318409c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; padded batch of variable length sequences.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2df5064f26ed4ff300eeca02d8d23ff3989d592a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the &lt;code&gt;a&lt;/code&gt; from &lt;a href=&quot;torch.geqrf#torch.geqrf&quot;&gt;&lt;code&gt;torch.geqrf()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32b3debabd5244f6f757a0ecbfc2001f87d51061" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the dividend</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc63e66b77eddc23d0480985c434968ab3a3c432" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the first batch of matrices to be multiplied</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8048457126f71ad2252c07afbe21ab1ad62cc0e3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the first input tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40066a22db2f549d0b2b91e1d0653edab74dded7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the first matrix to be multiplied</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d03903d53b2c5ac4f518cd45d6008241190088c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the first multiplicand tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f51f99307491138059682bbbc27c557807591a9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the first tensor to be multiplied</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1accceea4c5085a1b9d5fd922dec4a71a7c24ead" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input 2-D tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6146e5ea09927c514d32a11ed0ac42f33556893d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input matrix</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="708c21e573ae8975fd41f843d793ad7f90dc01c9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ccd5042b98d78e05ed8accf585abbd7c7cd67f8c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor containing probabilities</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8678adfcf46f049849a9950535e8987135ee8c9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor containing the rates of the Poisson distribution</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="19b4b70bbc0703888b4dd081987a664f12caeab6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor of at least &lt;code&gt;signal_ndim&lt;/code&gt; dimensions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a80664bf19108f6871d4d9cc67ea5ec9d65038f3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor of at least &lt;code&gt;signal_ndim&lt;/code&gt;&lt;code&gt;+ 1&lt;/code&gt; dimensions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80ea65a4aaf35f42f84d23c01465ca2ef54bdaad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor of probability values for the Bernoulli distribution</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b642c0b47336e267e577b35820c587126ea9f39a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9159ecc16b63f9802803f1f98dd7cfcc6322e401" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor of size &lt;code&gt;(*, n, n)&lt;/code&gt; where &lt;code&gt;*&lt;/code&gt; is zero or more batch dimensions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7caaa20ec7806018b377988dd677601f3f83e4d9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="121b8ceabf101922601fe3bb8a675692baf2cd6c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor. Must be at least 1-dimensional.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80a6967e7a1bc373747e4ceda61d8eca3bcbe71d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor. Must be at least 2-dimensional.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5176c20efe2b991fb3ef27de42aad8bfff75426" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the matrix</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9ce71bbfa8c25d01c8c318346faac5f3f4407cd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the size of &lt;code&gt;input&lt;/code&gt; will determine size of the output tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bfcd8ed79796b25e26a5e670250a73272dac91fb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the source tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3cad4fa9c4a49fae5b079d14a2bcba4e124c2ab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the square matrix of shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09c118f2812817644cc5b84fc5bc2cef3421e809" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to be added</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="648002a80ff2960290b93380fa5ebeba8bd25668" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to be reshaped</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20715c854d53757985d23efabade3db743a6a166" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to compare</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c1865166964450f22d83f1a28613f076a2e569b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to compute the digamma function on</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2bf2493846223fdc5fbfe54614e402279de1747" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to compute the multivariate log-gamma function</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7fbfb129c11e7747b44805a7b05a9ebc40147948" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to narrow</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55c3c22205a1b70d592dec6666248c82e3690335" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to split</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3219155900c01df3eed96409ef1ed4b22f2fc99a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to unbind</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a48e0ca5030fc4d6af5bdfb8605eaef2755a644" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor with the starting points</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cc211cd1b8495af379d1d59ebf66ec1fb368257" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; vector to be added</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0f2899dfd7408899e467222cd4d0bd1c8b163e8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; the dividend</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e495db7a10b097798f9ab905342091739c99080" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Scalar&lt;/em&gt;) &amp;ndash; N-D tensor or a Scalar containing the search value(s).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54b5b721c1619fe54cfff53778c25cbdce11a2a0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;list of Tensors&lt;/em&gt;) &amp;ndash;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e15a78cbbc8bd023145c6c784e4996207ef9b8e4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b1084c8300aad27ad1784e01fa04c5108343982" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; N-dimensional tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4ba99c5e33ab9d93f9eeb31063659728503213f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Quantized input of type &lt;code&gt;torch.quint8&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e32b4df67a1c6fa976c98f26ed880fe2843dd472" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The input tensor. If dim is None, x must be 1-D or 2-D, unless &lt;code&gt;ord&lt;/code&gt; is None. If both &lt;code&gt;dim&lt;/code&gt; and &lt;code&gt;ord&lt;/code&gt; are None, the 2-norm of the input flattened to 1-D will be returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="750efbed074a69bad5c30928c16477fc2a8db885" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; input</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbba8e02a600f5a44e37f994cfdcf15acf5f5674" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; input of shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71024ef201be154545b2752c7794987629860a82" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; input tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc13ec8f5ecb355720aad713d541718fbcff8ff1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; quantized input</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca4fccfc307fc839f56fcd2935b753c3a675a514" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; quantized input tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16adc05235f86a0bdba3f8d133f8ad24c146c434" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input SparseTensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f15e5e30b2c90290ac32a42b9dde72a1f212a74f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50bc5249b9927187f00659fce46d0556e5580c69" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor representing a half-Hermitian signal</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01ff6678d557f24c8e79e022f907950c5a82aff9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the real input tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="912fbe0aeceffe41c39ef4b4f7a3bd4836fd3f31" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; Tensor containing bags of indices into the embedding matrix</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="062fdb3d419326f615da299be36d7f8d3afff88a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; Tensor containing indices into the embedding matrix</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
