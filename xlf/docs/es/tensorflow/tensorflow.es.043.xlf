<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="es" datatype="htmlbody" original="tensorflow">
    <body>
      <group id="tensorflow">
        <trans-unit id="587ea8c1cdf68f3aaebe6d4c8fb0dc04c9f49662" translate="yes" xml:space="preserve">
          <source>User-written layers and models can achieve the same behavior with code that looks like:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7076897558f527fd7b476c32a2d7999a7bce1794" translate="yes" xml:space="preserve">
          <source>Users can call this method to get some facts of the TPU system, like total number of cores, number of TPU workers and the devices. E.g.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67147ed6d1d38b4f4b015cf112ec870c25df3f0b" translate="yes" xml:space="preserve">
          <source>Users can pass strategy specific options to &lt;code&gt;options&lt;/code&gt; argument. An example to enable bucketizing dynamic shapes in &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/distribute/TPUStrategy#run&quot;&gt;&lt;code&gt;TPUStrategy.run&lt;/code&gt;&lt;/a&gt; is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f72b22db9ab4d4d8bbc6f80831bcd32ed79c81e6" translate="yes" xml:space="preserve">
          <source>Users can specify various options to control the behavior of snapshot, including how snapshots are read from and written to by passing in user-defined functions to the &lt;code&gt;reader_func&lt;/code&gt; and &lt;code&gt;shard_func&lt;/code&gt; parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="157f011efb63e43996c3b578c255e7d5545ba313" translate="yes" xml:space="preserve">
          <source>Users can write it to file for offline analysis by tfprof commandline or graphical interface.</source>
          <target state="translated">Los usuarios pueden escribirlo para archivarlo para su análisis fuera de línea por la línea de comandos de tfprof o la interfaz gráfica.</target>
        </trans-unit>
        <trans-unit id="e5a32aab95198164a5ff787e69d28cbf95af2893" translate="yes" xml:space="preserve">
          <source>Users may want specify this function to control how snapshot files should be read from disk, including the amount of shuffling and parallelism.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6748ccb2ebd37a27cc38d08c0979684dcbf55e30" translate="yes" xml:space="preserve">
          <source>Users may want to specify this function to control how snapshot files should be written to disk. Below is an example of how a potential shard_func could be written.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7108f46888ed24215d4773b328e7e496d911304" translate="yes" xml:space="preserve">
          <source>Users may write the following code to asynchronuously invoke &lt;code&gt;train_step_fn&lt;/code&gt; and log the &lt;code&gt;loss&lt;/code&gt; metric for every &lt;code&gt;num_steps&lt;/code&gt; steps in a training loop. &lt;code&gt;train_step_fn&lt;/code&gt; internally consumes data using &lt;code&gt;iterator.get_next()&lt;/code&gt;, and may throw OutOfRangeError when running out of data. In the case:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0ec32691eaba97311f1cccd2dad97641a499fa1" translate="yes" xml:space="preserve">
          <source>Users must not modify any collections used in nest while this function is running.</source>
          <target state="translated">Los usuarios no deben modificar ninguna de las colecciones utilizadas en el nido mientras esta función esté en funcionamiento.</target>
        </trans-unit>
        <trans-unit id="06b0870bd9d2eea911ba0bf24a44afc23e3b6358" translate="yes" xml:space="preserve">
          <source>Users need to combine parsing spec of features with labels and weights (if any) since they are all parsed from same tf.Example instance. This utility combines these specs.</source>
          <target state="translated">Los usuarios deben combinar el análisis de las especificaciones de las características con las etiquetas y los pesos (si los hay),ya que todos se analizan a partir del mismo ejemplo de tf.Esta utilidad combina estas especificaciones.</target>
        </trans-unit>
        <trans-unit id="182c1f1a391ebf26b9c0b763f027f3059f9e6bd2" translate="yes" xml:space="preserve">
          <source>Users of &lt;code&gt;step_fn&lt;/code&gt; may perform &lt;code&gt;run()&lt;/code&gt; calls without running hooks by accessing the &lt;code&gt;session&lt;/code&gt;. A &lt;code&gt;run()&lt;/code&gt; call with hooks may be performed using &lt;code&gt;run_with_hooks()&lt;/code&gt;. Computation flow can be interrupted using &lt;code&gt;request_stop()&lt;/code&gt;.</source>
          <target state="translated">Los usuarios de &lt;code&gt;step_fn&lt;/code&gt; pueden realizar llamadas &lt;code&gt;run()&lt;/code&gt; sin ejecutar hooks accediendo a la &lt;code&gt;session&lt;/code&gt; . Se puede &lt;code&gt;run()&lt;/code&gt; una llamada a run () con hooks usando &lt;code&gt;run_with_hooks()&lt;/code&gt; . El flujo de c&amp;aacute;lculo se puede interrumpir usando &lt;code&gt;request_stop()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2f188fa1f43efe8bdab97db20fb68ecadd592af6" translate="yes" xml:space="preserve">
          <source>Users will just instantiate a layer and then treat it as a callable.</source>
          <target state="translated">Los usuarios simplemente instanciarán una capa y luego la tratarán como una llamada.</target>
        </trans-unit>
        <trans-unit id="c72c8f3ece626a4705405cb3a7b8af47ef729815" translate="yes" xml:space="preserve">
          <source>Uses &lt;code&gt;sigmoid_cross_entropy&lt;/code&gt; loss average over classes and weighted sum over the batch. Namely, if the input logits have shape &lt;code&gt;[batch_size, n_classes]&lt;/code&gt;, the loss is the average over &lt;code&gt;n_classes&lt;/code&gt; and the weighted sum over &lt;code&gt;batch_size&lt;/code&gt;.</source>
          <target state="translated">Utiliza el promedio de p&amp;eacute;rdida &lt;code&gt;sigmoid_cross_entropy&lt;/code&gt; sobre las clases y la suma ponderada sobre el lote. Es decir, si los logits de entrada tienen forma &lt;code&gt;[batch_size, n_classes]&lt;/code&gt; , la p&amp;eacute;rdida es el promedio sobre &lt;code&gt;n_classes&lt;/code&gt; y la suma ponderada sobre &lt;code&gt;batch_size&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="11a9b701f656adfafd6806eb9e7ef756d209ed2e" translate="yes" xml:space="preserve">
          <source>Uses &lt;code&gt;sigmoid_cross_entropy_with_logits&lt;/code&gt; loss, which is the same as &lt;code&gt;BinaryClassHead&lt;/code&gt;. The differences compared to &lt;code&gt;BinaryClassHead&lt;/code&gt; are:</source>
          <target state="translated">Utiliza &lt;code&gt;sigmoid_cross_entropy_with_logits&lt;/code&gt; loss, que es lo mismo que &lt;code&gt;BinaryClassHead&lt;/code&gt; . Las diferencias en comparaci&amp;oacute;n con &lt;code&gt;BinaryClassHead&lt;/code&gt; son:</target>
        </trans-unit>
        <trans-unit id="3d8209fd0815d68d4830b41bd06d14a5cb947aa2" translate="yes" xml:space="preserve">
          <source>Uses &lt;code&gt;sigmoid_cross_entropy_with_logits&lt;/code&gt; loss.</source>
          <target state="translated">Utiliza &lt;code&gt;sigmoid_cross_entropy_with_logits&lt;/code&gt; loss.</target>
        </trans-unit>
        <trans-unit id="e004400a6e3754313301e3fd9261a2c189b3474a" translate="yes" xml:space="preserve">
          <source>Uses &lt;code&gt;sparse_softmax_cross_entropy&lt;/code&gt; loss.</source>
          <target state="translated">Utiliza la p&amp;eacute;rdida &lt;code&gt;sparse_softmax_cross_entropy&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3e2b61f4b530febb6503deed927b41c373ddaaf3" translate="yes" xml:space="preserve">
          <source>Uses &lt;code&gt;str(value)&lt;/code&gt;, except for &lt;code&gt;bytes&lt;/code&gt; typed inputs, which are converted using &lt;code&gt;as_str&lt;/code&gt;.</source>
          <target state="translated">Utiliza &lt;code&gt;str(value)&lt;/code&gt; , excepto para las entradas con tipo de &lt;code&gt;bytes&lt;/code&gt; , que se convierten utilizando &lt;code&gt;as_str&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2973e6aa554e21daa4adef06a74539c445b14d95" translate="yes" xml:space="preserve">
          <source>Uses utf-8 encoding for text by default.</source>
          <target state="translated">Utiliza la codificación utf-8 para el texto por defecto.</target>
        </trans-unit>
        <trans-unit id="217a51c3037aab24f119676b38ba458afe249401" translate="yes" xml:space="preserve">
          <source>Using &lt;a href=&quot;../nn/embedding_lookup_sparse&quot;&gt;&lt;code&gt;tf.nn.embedding_lookup_sparse&lt;/code&gt;&lt;/a&gt; for sparse multiplication:</source>
          <target state="translated">Usando &lt;a href=&quot;../nn/embedding_lookup_sparse&quot;&gt; &lt;code&gt;tf.nn.embedding_lookup_sparse&lt;/code&gt; &lt;/a&gt; para una multiplicaci&amp;oacute;n dispersa:</target>
        </trans-unit>
        <trans-unit id="159ac66854831fd41477c6614f26e3ff55888f88" translate="yes" xml:space="preserve">
          <source>Using &lt;code&gt;pos&lt;/code&gt; and &lt;code&gt;len&lt;/code&gt; with same shape as &lt;code&gt;input&lt;/code&gt;:</source>
          <target state="translated">Usando &lt;code&gt;pos&lt;/code&gt; y &lt;code&gt;len&lt;/code&gt; con la misma forma que la &lt;code&gt;input&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="20acdd8f39a8fcbb172a5237734f68ee0d2be386" translate="yes" xml:space="preserve">
          <source>Using float64 is similar to mixed precision. Either the global policy can be set to float64, or &lt;code&gt;dtype='float64'&lt;/code&gt; can be passed to individual layers. For example, to set the global policy:</source>
          <target state="translated">El uso de float64 es similar a la precisi&amp;oacute;n mixta. O la pol&amp;iacute;tica global se puede establecer en float64 o &lt;code&gt;dtype='float64'&lt;/code&gt; se puede pasar a capas individuales. Por ejemplo, para establecer la pol&amp;iacute;tica global:</target>
        </trans-unit>
        <trans-unit id="f6b2bb4ba02dab533aac4565623cbaf2d9684521" translate="yes" xml:space="preserve">
          <source>Using graphs directly (deprecated)</source>
          <target state="translated">Usando los gráficos directamente (desaprobado)</target>
        </trans-unit>
        <trans-unit id="45c1897ccbe225e4b4bb0b5776304a91ccc424dd" translate="yes" xml:space="preserve">
          <source>Using scalar &lt;code&gt;pos&lt;/code&gt; and &lt;code&gt;len&lt;/code&gt;:</source>
          <target state="translated">Usando &lt;code&gt;pos&lt;/code&gt; escalar y &lt;code&gt;len&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="55be0948f7db3ef4c4e1ab2c5b8f53c076ac5356" translate="yes" xml:space="preserve">
          <source>Using the &lt;code&gt;TensorBoard&lt;/code&gt; callback will work when eager execution is enabled, with the restriction that outputting histogram summaries of weights and gradients is not supported. Consequently, &lt;code&gt;histogram_freq&lt;/code&gt; will be ignored.</source>
          <target state="translated">El uso de la &lt;code&gt;TensorBoard&lt;/code&gt; llamada de TensorBoard funcionar&amp;aacute; cuando la ejecuci&amp;oacute;n ansiosa est&amp;eacute; habilitada, con la restricci&amp;oacute;n de que no se admite la salida de res&amp;uacute;menes de histogramas de pesos y gradientes. En consecuencia, &lt;code&gt;histogram_freq&lt;/code&gt; se ignorar&amp;aacute;.</target>
        </trans-unit>
        <trans-unit id="10b4feb7db468a7b136fb7eedc7778e772ed7977" translate="yes" xml:space="preserve">
          <source>Using the &lt;code&gt;Uniform&lt;/code&gt; distribution as an example:</source>
          <target state="translated">Usando la distribuci&amp;oacute;n &lt;code&gt;Uniform&lt;/code&gt; como ejemplo:</target>
        </trans-unit>
        <trans-unit id="a70f4ea74dc28a0759892b77d899be11c4a630a4" translate="yes" xml:space="preserve">
          <source>Using the SavedModel format</source>
          <target state="translated">Usando el formato SavedModel</target>
        </trans-unit>
        <trans-unit id="2d5a6c95117b542db8bf88cf405c6beac37d2a3c" translate="yes" xml:space="preserve">
          <source>Using the above module would produce &lt;a href=&quot;variable&quot;&gt;&lt;code&gt;tf.Variable&lt;/code&gt;&lt;/a&gt;s and &lt;a href=&quot;tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt;s whose names included the module name:</source>
          <target state="translated">El uso del m&amp;oacute;dulo anterior producir&amp;iacute;a &lt;a href=&quot;variable&quot;&gt; &lt;code&gt;tf.Variable&lt;/code&gt; &lt;/a&gt; sy &lt;a href=&quot;tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; s cuyos nombres inclu&amp;iacute;an el nombre del m&amp;oacute;dulo:</target>
        </trans-unit>
        <trans-unit id="7ad33ae89a6d279a16ce6134859a442eac2581c4" translate="yes" xml:space="preserve">
          <source>Using the default job_name of worker, you can schedule ops to run remotely as follows:</source>
          <target state="translated">Usando el nombre_de_trabajo predeterminado del trabajador,puede programar operaciones para que se ejecuten remotamente de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="5a6462b40df0780171c71c9fb37d8c4d54d01a02" translate="yes" xml:space="preserve">
          <source>Using this strategy will place any variables created in its scope on the specified device. Input distributed through this strategy will be prefetched to the specified device. Moreover, any functions called via &lt;code&gt;strategy.experimental_run_v2&lt;/code&gt; will also be placed on the specified device as well.</source>
          <target state="translated">El uso de esta estrategia colocar&amp;aacute; las variables creadas en su alcance en el dispositivo especificado. La entrada distribuida a trav&amp;eacute;s de esta estrategia se precargar&amp;aacute; en el dispositivo especificado. Adem&amp;aacute;s, cualquier funci&amp;oacute;n llamada a trav&amp;eacute;s de &lt;code&gt;strategy.experimental_run_v2&lt;/code&gt; tambi&amp;eacute;n se colocar&amp;aacute; en el dispositivo especificado.</target>
        </trans-unit>
        <trans-unit id="0921ab75268541486ce05861f2d20fe9143695fe" translate="yes" xml:space="preserve">
          <source>Using this strategy will place any variables created in its scope on the specified device. Input distributed through this strategy will be prefetched to the specified device. Moreover, any functions called via &lt;code&gt;strategy.run&lt;/code&gt; will also be placed on the specified device as well.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71b01f087dc4062f216f4b3e8e8c06a8b29e198c" translate="yes" xml:space="preserve">
          <source>Usually, this does not necessarily mean that the layer is run in inference mode (which is normally controlled by the &lt;code&gt;training&lt;/code&gt; argument that can be passed when calling a layer). &quot;Frozen state&quot; and &quot;inference mode&quot; are two separate concepts.</source>
          <target state="translated">Por lo general, esto no significa necesariamente que la capa se ejecute en modo de inferencia (que normalmente est&amp;aacute; controlado por el argumento de &lt;code&gt;training&lt;/code&gt; que se puede pasar al llamar a una capa). &quot;Estado congelado&quot; y &quot;modo de inferencia&quot; son dos conceptos separados.</target>
        </trans-unit>
        <trans-unit id="6cf4bb7b1492b783c6bc69633b0fe1693771c5d9" translate="yes" xml:space="preserve">
          <source>Utilities for ImageNet data preprocessing &amp;amp; prediction decoding.</source>
          <target state="translated">Utilidades para preprocesamiento de datos y decodificaci&amp;oacute;n de predicciones de ImageNet.</target>
        </trans-unit>
        <trans-unit id="08fb7be2421c2bdf2a78c1776aba074edf57a478" translate="yes" xml:space="preserve">
          <source>Utilities for preprocessing sequence data.</source>
          <target state="translated">Utilidades para preprocesar los datos de la secuencia.</target>
        </trans-unit>
        <trans-unit id="ae6bf25944794d7df424031b54eed9e8c6e9c537" translate="yes" xml:space="preserve">
          <source>Utilities for text input preprocessing.</source>
          <target state="translated">Utilidades para el preprocesamiento de la entrada de texto.</target>
        </trans-unit>
        <trans-unit id="41900282bff2287f65ac5f2919d6b167c32aa670" translate="yes" xml:space="preserve">
          <source>Utilities for writing compatible code</source>
          <target state="translated">Utilidades para escribir código compatible</target>
        </trans-unit>
        <trans-unit id="4209295b2fe1eb250fb221ec6cd68f34f854faae" translate="yes" xml:space="preserve">
          <source>Utility class for generating batches of temporal data.</source>
          <target state="translated">Clase de utilidad para generar lotes de datos temporales.</target>
        </trans-unit>
        <trans-unit id="3f80dd65b77c781d8eb1f4f65d0db44d5b92a1de" translate="yes" xml:space="preserve">
          <source>Utility function to build TensorInfo proto from a Tensor. (deprecated)</source>
          <target state="translated">Función de utilidad para construir el prototipo de TensorInfo a partir de un Tensor.(desaprobado)</target>
        </trans-unit>
        <trans-unit id="d66171638f7d7dc0d33fb68081060b45caf826a1" translate="yes" xml:space="preserve">
          <source>Utility function to build a SignatureDef protocol buffer.</source>
          <target state="translated">Función de utilidad para construir un buffer de protocolo SignatureDef.</target>
        </trans-unit>
        <trans-unit id="a1fc6fdd2556af786588697b8b4da900e88da0b4" translate="yes" xml:space="preserve">
          <source>Utility functions for building and inspecting SignatureDef protos.</source>
          <target state="translated">Funciones de utilidad para construir e inspeccionar protos de SignatureDef.</target>
        </trans-unit>
        <trans-unit id="41a205ecd48940b5d4f27244d92bd652c4f4f6d1" translate="yes" xml:space="preserve">
          <source>Utility functions to assist with setup and construction of the SavedModel proto.</source>
          <target state="translated">Funciones de utilidad para ayudar en la configuración y construcción del prototipo de SavedModel.</target>
        </trans-unit>
        <trans-unit id="25e1689ca50193bb7593b638ace3275be8fc9300" translate="yes" xml:space="preserve">
          <source>Utility methods to create simple input_fns.</source>
          <target state="translated">Métodos de utilidad para crear simples input_fns.</target>
        </trans-unit>
        <trans-unit id="98c6a5322edf6827b19ea21d2e974ec573fb37d2" translate="yes" xml:space="preserve">
          <source>V2 Compatibility</source>
          <target state="translated">Compatibilidad con V2</target>
        </trans-unit>
        <trans-unit id="b45432e089497cb1e4b6a50a251afeb8f8ec8634" translate="yes" xml:space="preserve">
          <source>V2 format specific: merges the metadata files of sharded checkpoints. The</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f4dce99bbaf012216e610738a930ee809e1a1dd" translate="yes" xml:space="preserve">
          <source>VGG16 model for Keras.</source>
          <target state="translated">Modelo VGG16 para Keras.</target>
        </trans-unit>
        <trans-unit id="16578957bc13d8fcce797647de9c6287bbab95bd" translate="yes" xml:space="preserve">
          <source>VGG19 model for Keras.</source>
          <target state="translated">Modelo VGG19 para Keras.</target>
        </trans-unit>
        <trans-unit id="b2ac8a00dcd90f10a8f8eab14df7c47a44d8bc39" translate="yes" xml:space="preserve">
          <source>Valid keyword args are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b984695d87811bddc59458f1d995336a48f8d61" translate="yes" xml:space="preserve">
          <source>Valid values for whence are: 0: start of the file (default) 1: relative to the current position of the file 2: relative to the end of file. &lt;code&gt;offset&lt;/code&gt; is usually negative.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35d73c1e3e748be7af4094274c7c669844f7b39a" translate="yes" xml:space="preserve">
          <source>Validate and return float type based on &lt;code&gt;tensors&lt;/code&gt; and &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="translated">Valide y devuelva el tipo de flotaci&amp;oacute;n seg&amp;uacute;n los &lt;code&gt;tensors&lt;/code&gt; y el tipo &lt;code&gt;dtype&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7cfbc94b8562d35a1a624063af44283471348553" translate="yes" xml:space="preserve">
          <source>Validated type.</source>
          <target state="translated">Tipo validado.</target>
        </trans-unit>
        <trans-unit id="fbc4d5994f37368bc38796f9fcac6177e5b079ae" translate="yes" xml:space="preserve">
          <source>Value Error: If input contains string value</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b6107bdd0fa4996fbf7660de172ff5a7b7753b6" translate="yes" xml:space="preserve">
          <source>Value convertible to &lt;a href=&quot;dtypes/dtype&quot;&gt;&lt;code&gt;tf.DType&lt;/code&gt;&lt;/a&gt;. The type of the tensor values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15c75ed5285ab847c51c1d1b073c1ffd6af1e2d3" translate="yes" xml:space="preserve">
          <source>Value convertible to &lt;a href=&quot;tensorshape&quot;&gt;&lt;code&gt;tf.TensorShape&lt;/code&gt;&lt;/a&gt;. The shape of the tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe02012fec01937ecf4625a4bb543d51186a14cc" translate="yes" xml:space="preserve">
          <source>Value of new time step. Can be a variable or a constant</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf813cf306f9fe6920d27a32a73e1a8ab0b8ac28" translate="yes" xml:space="preserve">
          <source>Value of tensor to set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0d2a5aeb6f41dd496d2ccf306df13e6658541ae" translate="yes" xml:space="preserve">
          <source>Value to return if flagname is not defined. Defaults to None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4123cacba8af0210e8bc3a45f165b7510fbe81e" translate="yes" xml:space="preserve">
          <source>Value to set for indices not specified in &lt;code&gt;self&lt;/code&gt;. Defaults to zero. &lt;code&gt;default_value&lt;/code&gt; must be broadcastable to &lt;code&gt;self.shape[self.ragged_rank + 1:]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c7617def04f30bf9e69162b03566ab37d2f02c8" translate="yes" xml:space="preserve">
          <source>Value to set the tensor to, as a Numpy array (of the same shape).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44cdd81777401755111de56bb90c9f9e4f31fb50" translate="yes" xml:space="preserve">
          <source>ValueError if &lt;code&gt;num_packs&lt;/code&gt; is negative.</source>
          <target state="translated">ValueError si &lt;code&gt;num_packs&lt;/code&gt; es negativo.</target>
        </trans-unit>
        <trans-unit id="b03333735384a88c2a20365a2ab9d19d0855bf6a" translate="yes" xml:space="preserve">
          <source>ValueError if data format is unrecognized, if &lt;code&gt;value&lt;/code&gt; has less than two dimensions when &lt;code&gt;data_format&lt;/code&gt; is 'N..C'/&lt;code&gt;None&lt;/code&gt; or &lt;code&gt;value&lt;/code&gt; has less then three dimensions when &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;NC..&lt;/code&gt;, if &lt;code&gt;bias&lt;/code&gt; does not have exactly one dimension (is a vector), or if the size of &lt;code&gt;bias&lt;/code&gt; does not match the size of the channel dimension of &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="translated">ValueError si no se reconoce el formato de datos, si el &lt;code&gt;value&lt;/code&gt; tiene menos de dos dimensiones cuando &lt;code&gt;data_format&lt;/code&gt; es 'N..C' / &lt;code&gt;None&lt;/code&gt; o el &lt;code&gt;value&lt;/code&gt; tiene menos de tres dimensiones cuando &lt;code&gt;data_format&lt;/code&gt; es &lt;code&gt;NC..&lt;/code&gt; , si el &lt;code&gt;bias&lt;/code&gt; no tiene exactamente una dimensi&amp;oacute;n (es un vector), o si el tama&amp;ntilde;o del &lt;code&gt;bias&lt;/code&gt; no coincide con el tama&amp;ntilde;o de la dimensi&amp;oacute;n de &lt;code&gt;value&lt;/code&gt; del canal .</target>
        </trans-unit>
        <trans-unit id="28e00764e50e68a9e4b435811b832e1599c2d7ff" translate="yes" xml:space="preserve">
          <source>ValueError when attempting to use experimental_compile, but XLA support is not enabled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7604a24858b57e5b1686ec99368d1d81fb1d5a4" translate="yes" xml:space="preserve">
          <source>ValueError: When set pad_to_max_output_size to False for batched input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1cad1ac50b9d58fe699af8d3719130c04596c12" translate="yes" xml:space="preserve">
          <source>ValueRowIds(key,)</source>
          <target state="translated">ValueRowIds(key,)</target>
        </trans-unit>
        <trans-unit id="2aa729287cefae889cb308c2489e301fd72ddfcc" translate="yes" xml:space="preserve">
          <source>Values are generated when TensorFlow is compiled, and are static for each TensorFlow package. The return value is a dictionary with string keys such as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9989c8b816fd103fa17ba450218cc3f655b85003" translate="yes" xml:space="preserve">
          <source>Values are merged in order, so if an index appears in both &lt;code&gt;indices[m][i]&lt;/code&gt; and &lt;code&gt;indices[n][j]&lt;/code&gt; for &lt;code&gt;(m,i) &amp;lt; (n,j)&lt;/code&gt; the slice &lt;code&gt;data[n][j]&lt;/code&gt; will appear in the merged result. If you do not need this guarantee, ParallelDynamicStitch might perform better on some devices.</source>
          <target state="translated">Los valores se combinan en orden, por lo que si aparece un &amp;iacute;ndice tanto en los &lt;code&gt;indices[m][i]&lt;/code&gt; como en los &lt;code&gt;indices[n][j]&lt;/code&gt; para &lt;code&gt;(m,i) &amp;lt; (n,j)&lt;/code&gt; los &lt;code&gt;data[n][j]&lt;/code&gt; del segmento [n] [j] aparecer&amp;aacute;n aparecen en el resultado combinado. Si no necesita esta garant&amp;iacute;a, ParallelDynamicStitch podr&amp;iacute;a funcionar mejor en algunos dispositivos.</target>
        </trans-unit>
        <trans-unit id="31517cd57e02e0d5266cab70a1c38e47fcd19844" translate="yes" xml:space="preserve">
          <source>Values are not loaded immediately, but when the initializer is run (typically by running a &lt;a href=&quot;../global_variables_initializer&quot;&gt;&lt;code&gt;tf.compat.v1.global_variables_initializer&lt;/code&gt;&lt;/a&gt; op).</source>
          <target state="translated">Los valores no se cargan inmediatamente, sino cuando se ejecuta el inicializador (normalmente ejecutando una &lt;a href=&quot;../global_variables_initializer&quot;&gt; &lt;code&gt;tf.compat.v1.global_variables_initializer&lt;/code&gt; &lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="c7b1102521bf7adb2b3f3d054e8e942970be2d94" translate="yes" xml:space="preserve">
          <source>Values can also have the same locality as a variable, which is a mirrored value but residing on the same devices as the variable (as opposed to the compute devices). Such values may be passed to a call to &lt;a href=&quot;../../../distribute/strategyextended#update&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.update&lt;/code&gt;&lt;/a&gt; to update the value of a variable. You may use &lt;a href=&quot;../../../distribute/strategyextended#colocate_vars_with&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.colocate_vars_with&lt;/code&gt;&lt;/a&gt; to give a variable the same locality as another variable. This is useful, for example, for &quot;slot&quot; variables used by an optimizer for keeping track of statistics used to update a primary/model variable. You may convert a per-replica value to a variable's locality by using &lt;a href=&quot;../../../distribute/strategyextended#reduce_to&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.reduce_to&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../../distribute/strategyextended#batch_reduce_to&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.batch_reduce_to&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Los valores tambi&amp;eacute;n pueden tener la misma localidad que una variable, que es un valor reflejado pero que reside en los mismos dispositivos que la variable (a diferencia de los dispositivos de c&amp;aacute;lculo). Estos valores se pueden pasar a una llamada a &lt;a href=&quot;../../../distribute/strategyextended#update&quot;&gt; &lt;code&gt;tf.distribute.StrategyExtended.update&lt;/code&gt; &lt;/a&gt; para actualizar el valor de una variable. Puede usar &lt;a href=&quot;../../../distribute/strategyextended#colocate_vars_with&quot;&gt; &lt;code&gt;tf.distribute.StrategyExtended.colocate_vars_with&lt;/code&gt; &lt;/a&gt; para dar a una variable la misma localidad que otra variable. Esto es &amp;uacute;til, por ejemplo, para las variables de &quot;ranura&quot; utilizadas por un optimizador para realizar un seguimiento de las estad&amp;iacute;sticas utilizadas para actualizar una variable principal / modelo. Puede convertir un valor por r&amp;eacute;plica en la localidad de una variable utilizando &lt;a href=&quot;../../../distribute/strategyextended#reduce_to&quot;&gt; &lt;code&gt;tf.distribute.StrategyExtended.reduce_to&lt;/code&gt; &lt;/a&gt; o &lt;a href=&quot;../../../distribute/strategyextended#batch_reduce_to&quot;&gt; &lt;code&gt;tf.distribute.StrategyExtended.batch_reduce_to&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2143538d5a76006c2fb34d48a187c9999b4ce092" translate="yes" xml:space="preserve">
          <source>Values can also have the same locality as a variable, which is a mirrored value but residing on the same devices as the variable (as opposed to the compute devices). Such values may be passed to a call to &lt;a href=&quot;strategyextended#update&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.update&lt;/code&gt;&lt;/a&gt; to update the value of a variable. You may use &lt;a href=&quot;strategyextended#colocate_vars_with&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.colocate_vars_with&lt;/code&gt;&lt;/a&gt; to give a variable the same locality as another variable. This is useful, for example, for &quot;slot&quot; variables used by an optimizer for keeping track of statistics used to update a primary/model variable. You may convert a per-replica value to a variable's locality by using &lt;a href=&quot;strategyextended#reduce_to&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.reduce_to&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;strategyextended#batch_reduce_to&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.batch_reduce_to&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Los valores tambi&amp;eacute;n pueden tener la misma localidad que una variable, que es un valor reflejado pero que reside en los mismos dispositivos que la variable (a diferencia de los dispositivos de c&amp;aacute;lculo). Estos valores se pueden pasar a una llamada a &lt;a href=&quot;strategyextended#update&quot;&gt; &lt;code&gt;tf.distribute.StrategyExtended.update&lt;/code&gt; &lt;/a&gt; para actualizar el valor de una variable. Puede usar &lt;a href=&quot;strategyextended#colocate_vars_with&quot;&gt; &lt;code&gt;tf.distribute.StrategyExtended.colocate_vars_with&lt;/code&gt; &lt;/a&gt; para dar a una variable la misma localidad que otra variable. Esto es &amp;uacute;til, por ejemplo, para las variables de &quot;ranura&quot; utilizadas por un optimizador para realizar un seguimiento de las estad&amp;iacute;sticas utilizadas para actualizar una variable principal / modelo. Puede convertir un valor por r&amp;eacute;plica en la localidad de una variable utilizando &lt;a href=&quot;strategyextended#reduce_to&quot;&gt; &lt;code&gt;tf.distribute.StrategyExtended.reduce_to&lt;/code&gt; &lt;/a&gt; o &lt;a href=&quot;strategyextended#batch_reduce_to&quot;&gt; &lt;code&gt;tf.distribute.StrategyExtended.batch_reduce_to&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="ee2d365c74f97141598697d434a691d20762875a" translate="yes" xml:space="preserve">
          <source>Values in &lt;code&gt;arr&lt;/code&gt; outside of the range [0, size) are ignored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93fb0db8d97fc795e57ce06a9fa4d44911eba728" translate="yes" xml:space="preserve">
          <source>Values may be merged in parallel, so if an index appears in both &lt;code&gt;indices[m][i]&lt;/code&gt; and &lt;code&gt;indices[n][j]&lt;/code&gt;, the result may be invalid. This differs from the normal DynamicStitch operator that defines the behavior in that case.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d15a2f51d1f3c105d253f174b82490fef1d2d0a2" translate="yes" xml:space="preserve">
          <source>Values of the sparse gradient to be applied.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="332770f6ea1035cc31b26b51a3ff43d26f36a8a6" translate="yes" xml:space="preserve">
          <source>Values returned by all methods, such as &lt;code&gt;matmul&lt;/code&gt; or &lt;code&gt;determinant&lt;/code&gt; will be cast to &lt;code&gt;DTYPE&lt;/code&gt;.</source>
          <target state="translated">Los valores devueltos por todos los m&amp;eacute;todos, como &lt;code&gt;matmul&lt;/code&gt; o &lt;code&gt;determinant&lt;/code&gt; e , se convertir&amp;aacute;n en &lt;code&gt;DTYPE&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="472814b4275e6a3c35876afc6f85f152eeb4868b" translate="yes" xml:space="preserve">
          <source>Values to be associated with keys. Must be a tensor of the same shape as &lt;code&gt;keys&lt;/code&gt; and match the table's value type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e1d325bbb77e43c2a2a39b8f1ed0e1639c81e61" translate="yes" xml:space="preserve">
          <source>Values to pad with, passed to &lt;a href=&quot;../dataset#padded_batch&quot;&gt;&lt;code&gt;tf.data.Dataset.padded_batch&lt;/code&gt;&lt;/a&gt;. Defaults to padding with 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="152b6b1ae03ca0564ec1afcfa23945d6679fe3af" translate="yes" xml:space="preserve">
          <source>Values to put in the TensorProto.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="771c4420b1aa778f676175f583b791c3f76deedd" translate="yes" xml:space="preserve">
          <source>VarHandleOp</source>
          <target state="translated">VarHandleOp</target>
        </trans-unit>
        <trans-unit id="ff83e8cfb2acccae7a99a5aa63151589e41e200d" translate="yes" xml:space="preserve">
          <source>VarIsInitializedOp</source>
          <target state="translated">VarIsInitializedOp</target>
        </trans-unit>
        <trans-unit id="19de69cb601f53a4ea7af22a65c71ae63251365c" translate="yes" xml:space="preserve">
          <source>Variable</source>
          <target state="translated">Variable</target>
        </trans-unit>
        <trans-unit id="8b550e406a084548380628fd2909bf25b85b7d1f" translate="yes" xml:space="preserve">
          <source>Variable Constraint</source>
          <target state="translated">Restricción variable</target>
        </trans-unit>
        <trans-unit id="dc8c6831002ca69f6ebeab63140354a283153e34" translate="yes" xml:space="preserve">
          <source>Variable Constraints</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87bff689d1fa1dea41f1caabbfa56196f9dac995" translate="yes" xml:space="preserve">
          <source>Variable creation inside &lt;code&gt;scope&lt;/code&gt; is intercepted by the strategy. Each strategy defines how it wants to affect the variable creation. Sync strategies like &lt;code&gt;MirroredStrategy&lt;/code&gt;, &lt;code&gt;TPUStrategy&lt;/code&gt; and &lt;code&gt;MultiWorkerMiroredStrategy&lt;/code&gt; create variables replicated on each replica, whereas &lt;code&gt;ParameterServerStrategy&lt;/code&gt; creates variables on the parameter servers. This is done using a custom &lt;a href=&quot;../../../../variable_creator_scope&quot;&gt;&lt;code&gt;tf.variable_creator_scope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ebe6d40e82094b23daf6be3c6e12b5de702a887" translate="yes" xml:space="preserve">
          <source>Variable creation inside &lt;code&gt;scope&lt;/code&gt; is intercepted by the strategy. Each strategy defines how it wants to affect the variable creation. Sync strategies like &lt;code&gt;MirroredStrategy&lt;/code&gt;, &lt;code&gt;TPUStrategy&lt;/code&gt; and &lt;code&gt;MultiWorkerMiroredStrategy&lt;/code&gt; create variables replicated on each replica, whereas &lt;code&gt;ParameterServerStrategy&lt;/code&gt; creates variables on the parameter servers. This is done using a custom &lt;a href=&quot;../../../variable_creator_scope&quot;&gt;&lt;code&gt;tf.variable_creator_scope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad8c28ec75b4fb97533632feee539c8715d6500d" translate="yes" xml:space="preserve">
          <source>Variable creation inside &lt;code&gt;scope&lt;/code&gt; is intercepted by the strategy. Each strategy defines how it wants to affect the variable creation. Sync strategies like &lt;code&gt;MirroredStrategy&lt;/code&gt;, &lt;code&gt;TPUStrategy&lt;/code&gt; and &lt;code&gt;MultiWorkerMiroredStrategy&lt;/code&gt; create variables replicated on each replica, whereas &lt;code&gt;ParameterServerStrategy&lt;/code&gt; creates variables on the parameter servers. This is done using a custom &lt;a href=&quot;../../variable_creator_scope&quot;&gt;&lt;code&gt;tf.variable_creator_scope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56732160b0c125a3a8776369974b1d8fe83bf273" translate="yes" xml:space="preserve">
          <source>Variable creation inside &lt;code&gt;scope&lt;/code&gt; is intercepted by the strategy. Each strategy defines how it wants to affect the variable creation. Sync strategies like &lt;code&gt;MirroredStrategy&lt;/code&gt;, &lt;code&gt;TPUStrategy&lt;/code&gt; and &lt;code&gt;MultiWorkerMiroredStrategy&lt;/code&gt; create variables replicated on each replica, whereas &lt;code&gt;ParameterServerStrategy&lt;/code&gt; creates variables on the parameter servers. This is done using a custom &lt;a href=&quot;../variable_creator_scope&quot;&gt;&lt;code&gt;tf.variable_creator_scope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7dd58eeb1186ca442949f2a63231fa7bc6934171" translate="yes" xml:space="preserve">
          <source>Variable name to use for the first structure in assertion messages.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4e78d0db2266afd0792266861e4c967b5ab1437" translate="yes" xml:space="preserve">
          <source>Variable name to use for the second structure.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66091c2f5a648f0c372811ab148bd71631287d1d" translate="yes" xml:space="preserve">
          <source>Variable name.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0be93ad0375437f556470057db6cb269fac15f01" translate="yes" xml:space="preserve">
          <source>Variable or tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d982c2fd72628882252beffffe7353608ac38df" translate="yes" xml:space="preserve">
          <source>Variable regularization tensors are created when this property is accessed, so it is eager safe: accessing &lt;code&gt;losses&lt;/code&gt; under a &lt;a href=&quot;../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt; will propagate gradients back to the corresponding variables.</source>
          <target state="translated">Los tensores de regularizaci&amp;oacute;n de variables se crean cuando se accede a esta propiedad, por lo que es muy seguro: acceder a las &lt;code&gt;losses&lt;/code&gt; bajo un &lt;a href=&quot;../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; propagar&amp;aacute; los gradientes de regreso a las variables correspondientes.</target>
        </trans-unit>
        <trans-unit id="9becbe8191297fcb35681c2cb0fd8d5255180628" translate="yes" xml:space="preserve">
          <source>Variable scope allows you to create new variables and to share already created ones while providing checks to not create or share by accident. For details, see the &lt;a href=&quot;https://tensorflow.org/guide/variables&quot;&gt;Variable Scope How To&lt;/a&gt;, here we present only a few basic examples.</source>
          <target state="translated">El alcance variable le permite crear nuevas variables y compartir las ya creadas al tiempo que proporciona comprobaciones para no crearlas o compartirlas por accidente. Para obtener m&amp;aacute;s informaci&amp;oacute;n, consulte las &lt;a href=&quot;https://tensorflow.org/guide/variables&quot;&gt;instrucciones de alcance variable&lt;/a&gt; . Aqu&amp;iacute; presentamos solo algunos ejemplos b&amp;aacute;sicos.</target>
        </trans-unit>
        <trans-unit id="78a94c97c2babdd8664aa38c452645afd7c11def" translate="yes" xml:space="preserve">
          <source>Variable scope object to carry defaults to provide to &lt;code&gt;get_variable&lt;/code&gt;.</source>
          <target state="translated">Objeto de alcance variable para llevar valores predeterminados para proporcionar a &lt;code&gt;get_variable&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="656181555fa5b90a78a2907e7cdc150cdb7d9969" translate="yes" xml:space="preserve">
          <source>Variable semantics in TensorFlow 2 are eager execution friendly. The above code is roughly equivalent to:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31ae50eddd5315630d388c7fc7d3dd4ac0f0c588" translate="yes" xml:space="preserve">
          <source>Variable shape. Defaults to scalar if unspecified.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9c726ae1bb253cefd1f8e18cd504aa6e24e0e2b" translate="yes" xml:space="preserve">
          <source>Variable to set to a new value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2fa42dfef00dd6f5716bd283c68f5a7c3df717eb" translate="yes" xml:space="preserve">
          <source>Variable, possibly mirrored to multiple devices, to operate on.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fad16e163b18a5adad4a6b1f9bafad182b1fc5e8" translate="yes" xml:space="preserve">
          <source>Variable-size shapes are allowed by setting the corresponding shape dimensions to 0 in the shape attr. In this case DequeueMany will pad up to the maximum size of any given element in the minibatch. See below for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f736193c89669392caf0903ec1e19730e643644" translate="yes" xml:space="preserve">
          <source>Variable. The number of training steps this Optimizer has run.</source>
          <target state="translated">Variable.El número de pasos de entrenamiento que este Optimizador ha ejecutado.</target>
        </trans-unit>
        <trans-unit id="fbd24bae4ab2c5fb1757b5c4452669855276459f" translate="yes" xml:space="preserve">
          <source>VariableScope for the created subgraph; defaults to &quot;bidirectional_rnn&quot;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a6f1a6e7f1ea3415ae9f018191ab201ea3b0fac" translate="yes" xml:space="preserve">
          <source>VariableScope for the created subgraph; defaults to &quot;rnn&quot;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3580913cdba362b6cc2d19d6b7d1f9e9219c622d" translate="yes" xml:space="preserve">
          <source>VariableShape</source>
          <target state="translated">VariableShape</target>
        </trans-unit>
        <trans-unit id="751393cca20cc522b2f5c1a18350f77fe8d88bea" translate="yes" xml:space="preserve">
          <source>VariableV2</source>
          <target state="translated">VariableV2</target>
        </trans-unit>
        <trans-unit id="f628de42a66fa9f6ab10a5ed8f37f3bfec4938d4" translate="yes" xml:space="preserve">
          <source>Variables are assigned to local CPU or the only GPU. If there is more than one GPU, compute operations (other than variable update operations) will be replicated across all GPUs.</source>
          <target state="translated">Las variables se asignan a la CPU local o a la única GPU.Si hay más de una GPU,las operaciones de cálculo (que no sean operaciones de actualización de variables)se replicarán en todas las GPU.</target>
        </trans-unit>
        <trans-unit id="70a30a529e57576d822cecd0f271a7b5d39f84b7" translate="yes" xml:space="preserve">
          <source>Variables are automatically tracked when assigned to attributes of types inheriting from &lt;a href=&quot;module&quot;&gt;&lt;code&gt;tf.Module&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Las variables se rastrean autom&amp;aacute;ticamente cuando se asignan a atributos de tipos heredados de &lt;a href=&quot;module&quot;&gt; &lt;code&gt;tf.Module&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="1655acbcc407ca5c5cc17d4daaba10766362006a" translate="yes" xml:space="preserve">
          <source>Variables are often captured and manipulated by &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s. This works the same way the un-decorated function would have:</source>
          <target state="translated">Las variables a menudo son capturadas y manipuladas por &lt;a href=&quot;function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; s. Esto funciona de la misma manera que tendr&amp;iacute;a la funci&amp;oacute;n sin decorar:</target>
        </trans-unit>
        <trans-unit id="9422ebfe912588a94b4db8ceb623ec6943b8ae1a" translate="yes" xml:space="preserve">
          <source>Variables created inside a &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; must be owned outside the function and be created only once:</source>
          <target state="translated">Las variables creadas dentro de una funci&amp;oacute;n &lt;a href=&quot;function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; Deben ser propiedad fuera de la funci&amp;oacute;n y crearse solo una vez:</target>
        </trans-unit>
        <trans-unit id="a4f9c7fa0b18154ca4691caf51f88ee40eea34cb" translate="yes" xml:space="preserve">
          <source>Variables created inside a &lt;code&gt;MirroredStrategy&lt;/code&gt; which is wrapped with a &lt;a href=&quot;../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; are still &lt;code&gt;MirroredVariables&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29e458106bb18014f5f1ce0d551df4f487281340" translate="yes" xml:space="preserve">
          <source>Variables created inside a &lt;code&gt;MirroredStrategy&lt;/code&gt; which is wrapped with a &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; are still &lt;code&gt;MirroredVariables&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="198e5fbedc6e80bc4c09f5cf7cecc37f23ca5651" translate="yes" xml:space="preserve">
          <source>Variables created inside the strategy scope are &quot;owned&quot; by it:</source>
          <target state="translated">Las variables creadas dentro del ámbito de la estrategia son &quot;propiedad&quot; de ella:</target>
        </trans-unit>
        <trans-unit id="ecf6360262e709b4fb787134a5207269f78afa79" translate="yes" xml:space="preserve">
          <source>Variables created outside the strategy are not owned by it:</source>
          <target state="translated">Las variables creadas fuera de la estrategia no son propiedad de ella:</target>
        </trans-unit>
        <trans-unit id="4e85b51c74744b26c07cb066853860450f1f5376" translate="yes" xml:space="preserve">
          <source>Variables must be tracked by assigning them to an attribute of a tracked object or to an attribute of &lt;code&gt;obj&lt;/code&gt; directly. TensorFlow objects (e.g. layers from &lt;a href=&quot;../keras/layers&quot;&gt;&lt;code&gt;tf.keras.layers&lt;/code&gt;&lt;/a&gt;, optimizers from &lt;a href=&quot;../train&quot;&gt;&lt;code&gt;tf.train&lt;/code&gt;&lt;/a&gt;) track their variables automatically. This is the same tracking scheme that &lt;a href=&quot;../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; uses, and an exported &lt;code&gt;Checkpoint&lt;/code&gt; object may be restored as a training checkpoint by pointing &lt;a href=&quot;../train/checkpoint#restore&quot;&gt;&lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt;&lt;/a&gt; to the SavedModel's &quot;variables/&quot; subdirectory. Currently variables are the only stateful objects supported by &lt;a href=&quot;save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt;, but others (e.g. tables) will be supported in the future.</source>
          <target state="translated">Las variables deben ser rastreadas asign&amp;aacute;ndolas a un atributo de un objeto rastreado o directamente a un atributo de &lt;code&gt;obj&lt;/code&gt; . Los objetos de TensorFlow (por ejemplo, capas de &lt;a href=&quot;../keras/layers&quot;&gt; &lt;code&gt;tf.keras.layers&lt;/code&gt; &lt;/a&gt; , optimizadores de &lt;a href=&quot;../train&quot;&gt; &lt;code&gt;tf.train&lt;/code&gt; &lt;/a&gt; ) rastrean sus variables autom&amp;aacute;ticamente. Este es el mismo esquema de seguimiento que usa &lt;a href=&quot;../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; , y un objeto &lt;code&gt;Checkpoint&lt;/code&gt; exportado se puede restaurar como un punto de control de entrenamiento apuntando &lt;a href=&quot;../train/checkpoint#restore&quot;&gt; &lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt; &lt;/a&gt; al subdirectorio &quot;variables /&quot; del modelo guardado. Actualmente, las variables son los &amp;uacute;nicos objetos con estado admitidos por &lt;a href=&quot;save&quot;&gt; &lt;code&gt;tf.saved_model.save&lt;/code&gt; &lt;/a&gt; , pero otros (por ejemplo, tablas) ser&amp;aacute;n admitidos en el futuro.</target>
        </trans-unit>
        <trans-unit id="e84fa29887783568cfad44fb6f314a273a26c8b5" translate="yes" xml:space="preserve">
          <source>Variables must be tracked by assigning them to an attribute of a tracked object or to an attribute of &lt;code&gt;obj&lt;/code&gt; directly. TensorFlow objects (e.g. layers from &lt;a href=&quot;../keras/layers&quot;&gt;&lt;code&gt;tf.keras.layers&lt;/code&gt;&lt;/a&gt;, optimizers from &lt;a href=&quot;../train&quot;&gt;&lt;code&gt;tf.train&lt;/code&gt;&lt;/a&gt;) track their variables automatically. This is the same tracking scheme that &lt;a href=&quot;../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; uses, and an exported &lt;code&gt;Checkpoint&lt;/code&gt; object may be restored as a training checkpoint by pointing &lt;a href=&quot;../train/checkpoint#restore&quot;&gt;&lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt;&lt;/a&gt; to the SavedModel's &quot;variables/&quot; subdirectory. Currently, variables are the only stateful objects supported by &lt;a href=&quot;save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt;, but others (e.g. tables) will be supported in the future.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51a7e747ba069953d31cbdce4de5483d9446f49f" translate="yes" xml:space="preserve">
          <source>Variables, placeholders, and independent operations can also be stored, as shown in the following example.</source>
          <target state="translated">También pueden almacenarse variables,marcadores de posición y operaciones independientes,como se muestra en el siguiente ejemplo.</target>
        </trans-unit>
        <trans-unit id="612d2ee1679ef5637187e20c4629a406547bfef9" translate="yes" xml:space="preserve">
          <source>Variables:</source>
          <target state="translated">Variables:</target>
        </trans-unit>
        <trans-unit id="bb96e64e18e9a621cc7ceb2976a5e75548f771d4" translate="yes" xml:space="preserve">
          <source>Variance is defined as,</source>
          <target state="translated">La variación se define como,</target>
        </trans-unit>
        <trans-unit id="d282722043467708dfd05bebcd66f9f1d34aee3d" translate="yes" xml:space="preserve">
          <source>Variance of a tensor, alongside the specified axis.</source>
          <target state="translated">La variación de un tensor,a lo largo del eje especificado.</target>
        </trans-unit>
        <trans-unit id="547d7dc902ba966407aa0728767694e953ad6b04" translate="yes" xml:space="preserve">
          <source>Variance of batch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99189c611d030a5281d712eaa2b886309eb67a6b" translate="yes" xml:space="preserve">
          <source>Variance.</source>
          <target state="translated">Variance.</target>
        </trans-unit>
        <trans-unit id="108fd2238efb49f633daf84e4120ae9f47cfdec6" translate="yes" xml:space="preserve">
          <source>Various libraries built on top of the core TensorFlow library take care of creating some or all of these pieces and storing them in well known collections in the graph. The &lt;code&gt;Scaffold&lt;/code&gt; class helps pick these pieces from the graph collections, creating and adding them to the collections if needed.</source>
          <target state="translated">Varias bibliotecas creadas sobre la biblioteca principal de TensorFlow se encargan de crear algunas o todas estas piezas y almacenarlas en colecciones bien conocidas en el gr&amp;aacute;fico. La clase &lt;code&gt;Scaffold&lt;/code&gt; ayuda a seleccionar estas piezas de las colecciones de gr&amp;aacute;ficos, crearlas y agregarlas a las colecciones si es necesario.</target>
        </trans-unit>
        <trans-unit id="a6a6801f04fd08c4cf3ed0c985c50e0b3cc573dd" translate="yes" xml:space="preserve">
          <source>Vector length = Maximum element in vector &lt;code&gt;values&lt;/code&gt; is 5. Adding 1, which is 6 will be the vector length.</source>
          <target state="translated">Longitud del vector = El elemento m&amp;aacute;ximo en los &lt;code&gt;values&lt;/code&gt; vectoriales es 5. Sumar 1, que es 6, ser&amp;aacute; la longitud del vector.</target>
        </trans-unit>
        <trans-unit id="f5115b80229d0ab74c010431ae650645a075fb17" translate="yes" xml:space="preserve">
          <source>Vector of coordinatewise logits.</source>
          <target state="translated">Vector de registros de coordenadas.</target>
        </trans-unit>
        <trans-unit id="444c2b1f0bb53e9255195603b2fe9758758fc528" translate="yes" xml:space="preserve">
          <source>Vector of coordinatewise probabilities.</source>
          <target state="translated">Vector de probabilidades de coordenadas.</target>
        </trans-unit>
        <trans-unit id="ce1a5d4c90bdb53d4d10dd069e9eaa942f080fdb" translate="yes" xml:space="preserve">
          <source>Vector or scalar &lt;code&gt;Tensor&lt;/code&gt;. Specifies the exclusive upper limits for each range.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3f9cb652ec383e8e638e09260439b3155ece9c8" translate="yes" xml:space="preserve">
          <source>Vector or scalar &lt;code&gt;Tensor&lt;/code&gt;. Specifies the first entry for each range if &lt;code&gt;limits&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;; otherwise, specifies the range limits, and the first entries default to &lt;code&gt;0&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a78cb729e962d878d29fc681da48899c9408f1c" translate="yes" xml:space="preserve">
          <source>Vector or scalar &lt;code&gt;Tensor&lt;/code&gt;. Specifies the increment for each range. Defaults to &lt;code&gt;1&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca486267fdece68b69e71338f98f70bc8a117412" translate="yes" xml:space="preserve">
          <source>Verbosity mode, 0 (silent), 1 (verbose), 2 (semi-verbose)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89f3f7fe4c1640033ee74781a079e4dad0989210" translate="yes" xml:space="preserve">
          <source>Verbosity mode, 0 or 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec03954e111311ff95bd45ec3b8a12f4f9d9e291" translate="yes" xml:space="preserve">
          <source>Verifies whether all flags pass validation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf8d82dcaf9576f668b800d91e2cd8a9bd872212" translate="yes" xml:space="preserve">
          <source>Vertical coordinate of the top-left corner of the result in the input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3cbf1afdceff80dfc15073d9ab60779a3946f421" translate="yes" xml:space="preserve">
          <source>View aliases</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31a7604a3c742ea454ff128dd267ca1e16472796" translate="yes" xml:space="preserve">
          <source>View source</source>
          <target state="translated">Ver fuente</target>
        </trans-unit>
        <trans-unit id="a11a63ecf581d6810e65e62968e93200e384c05b" translate="yes" xml:space="preserve">
          <source>View source on GitHub</source>
          <target state="translated">Ver fuente en GitHub</target>
        </trans-unit>
        <trans-unit id="6737eca3bba31c47e227cdb4b10d88148b47097b" translate="yes" xml:space="preserve">
          <source>Visit the &lt;a href=&quot;https://www.tensorflow.org/tutorials/distribute/input&quot;&gt;tutorial&lt;/a&gt; on distributed input for more examples and caveats.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d07bb0bd533bc6a8f9cecf11b29b925415f286e8" translate="yes" xml:space="preserve">
          <source>Vocabulary information for warm-starting.</source>
          <target state="translated">Información de vocabulario para el arranque en caliente.</target>
        </trans-unit>
        <trans-unit id="1ec053f91b0e4f43b0ff9856f1f431195070e64b" translate="yes" xml:space="preserve">
          <source>WARNING: Experimental interface, subject to change.</source>
          <target state="translated">ADVERTENCIA:Interfaz experimental,sujeta a cambios.</target>
        </trans-unit>
        <trans-unit id="ec7aa071ac596c65b3d8973549288f00dd9060fe" translate="yes" xml:space="preserve">
          <source>WARNING: If &lt;code&gt;sloppy&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the order of produced elements is not deterministic.</source>
          <target state="translated">ADVERTENCIA: Si &lt;code&gt;sloppy&lt;/code&gt; es &lt;code&gt;True&lt;/code&gt; , el orden de los elementos producidos no es determinista.</target>
        </trans-unit>
        <trans-unit id="20a9fc48c3697f74feddc8ad93eb4c90b0d2bc47" translate="yes" xml:space="preserve">
          <source>WARNING: This function is nondeterministic, since it starts a separate thread for each tensor.</source>
          <target state="translated">ADVERTENCIA:Esta función es no determinista,ya que inicia un hilo separado para cada tensor.</target>
        </trans-unit>
        <trans-unit id="e747855abeb092a18ebf6b91688f8d9d0024a93d" translate="yes" xml:space="preserve">
          <source>WARNING: tf.Variable objects by default have a non-intuitive memory model. A Variable is represented internally as a mutable Tensor which can non-deterministically alias other Tensors in a graph. The set of operations which consume a Variable and can lead to aliasing is undetermined and can change across TensorFlow versions. Avoid writing code which relies on the value of a Variable either changing or not changing as other operations happen. For example, using Variable objects or simple functions thereof as predicates in a &lt;a href=&quot;../../cond&quot;&gt;&lt;code&gt;tf.cond&lt;/code&gt;&lt;/a&gt; is dangerous and error-prone:</source>
          <target state="translated">ADVERTENCIA: tf.Los objetos variables por defecto tienen un modelo de memoria no intuitivo. Una variable se representa internamente como un tensor mutable que puede alias de forma no determinista a otros tensores en un gr&amp;aacute;fico. El conjunto de operaciones que consumen una variable y pueden generar aliasing no est&amp;aacute; determinado y puede cambiar entre las versiones de TensorFlow. Evite escribir c&amp;oacute;digo que se base en el valor de una Variable que cambia o no cambia a medida que ocurren otras operaciones. Por ejemplo, usar objetos Variables o funciones simples de los mismos como predicados en un &lt;a href=&quot;../../cond&quot;&gt; &lt;code&gt;tf.cond&lt;/code&gt; &lt;/a&gt; es peligroso y propenso a errores:</target>
        </trans-unit>
        <trans-unit id="1d2a3e7fd14becda3ad79ab623ee02dcfb3c4815" translate="yes" xml:space="preserve">
          <source>WRONG:</source>
          <target state="translated">WRONG:</target>
        </trans-unit>
        <trans-unit id="b55f8ed036408ccdecc6c75f53cbf2cbe602c833" translate="yes" xml:space="preserve">
          <source>Wait for threads to terminate.</source>
          <target state="translated">Espera a que los hilos se terminen.</target>
        </trans-unit>
        <trans-unit id="480279e397ed207ff6dcb2138e6d19a402c6acab" translate="yes" xml:space="preserve">
          <source>Wait till the Coordinator is told to stop.</source>
          <target state="translated">Espera a que se le diga al Coordinador que se detenga.</target>
        </trans-unit>
        <trans-unit id="fd3c945de3bbe026196979524e2513d29b8047c4" translate="yes" xml:space="preserve">
          <source>Wait until the thread terminates.</source>
          <target state="translated">Espera hasta que el hilo termine.</target>
        </trans-unit>
        <trans-unit id="5fcf196e2d36a225ff59aa7e988a3bab54a62688" translate="yes" xml:space="preserve">
          <source>Warm-start all TRAINABLE variables:</source>
          <target state="translated">Arranque en caliente de todas las variables TRAINABLES:</target>
        </trans-unit>
        <trans-unit id="77a75fce3b44ee7c1b7330f94b51f223f12aced8" translate="yes" xml:space="preserve">
          <source>Warm-start all variables (including non-TRAINABLE):</source>
          <target state="translated">Arranque en caliente de todas las variables (incluyendo las no entrenables):</target>
        </trans-unit>
        <trans-unit id="385cb07f1382ec501efc556d03af6fccd0c3bc88" translate="yes" xml:space="preserve">
          <source>Warm-start all weights but the embedding parameters corresponding to &lt;code&gt;sc_vocab_file&lt;/code&gt; have a different vocab from the one used in the current model:</source>
          <target state="translated">Inicie en caliente todos los pesos, pero los par&amp;aacute;metros de incrustaci&amp;oacute;n correspondientes a &lt;code&gt;sc_vocab_file&lt;/code&gt; tienen un vocabulario diferente al utilizado en el modelo actual:</target>
        </trans-unit>
        <trans-unit id="584c6949a375264781ffa7a3f30012c7d4ac99ba" translate="yes" xml:space="preserve">
          <source>Warm-start all weights but the parameters corresponding to &lt;code&gt;sc_vocab_file&lt;/code&gt; have a different vocab from the one used in current checkpoint and the parameters corresponding to &lt;code&gt;sc_vocab_list&lt;/code&gt; have a different name from the current checkpoint:</source>
          <target state="translated">&lt;code&gt;sc_vocab_file&lt;/code&gt; caliente todos los pesos, pero los par&amp;aacute;metros correspondientes a sc_vocab_file tienen un vocabulario diferente del utilizado en el punto de control actual y los par&amp;aacute;metros correspondientes a &lt;code&gt;sc_vocab_list&lt;/code&gt; tienen un nombre diferente del punto de control actual:</target>
        </trans-unit>
        <trans-unit id="aee3196d9918b3cb93e150d394afe537d71e12b7" translate="yes" xml:space="preserve">
          <source>Warm-start all weights but the parameters corresponding to &lt;code&gt;sc_vocab_file&lt;/code&gt; have a different vocab from the one used in current checkpoint, and only 100 of those entries were used:</source>
          <target state="translated">&lt;code&gt;sc_vocab_file&lt;/code&gt; caliente todos los pesos, pero los par&amp;aacute;metros correspondientes a sc_vocab_file tienen un vocabulario diferente del que se usa en el punto de control actual, y solo se usaron 100 de esas entradas:</target>
        </trans-unit>
        <trans-unit id="cdac2057c8ebeb309f57754501e81125700d9646" translate="yes" xml:space="preserve">
          <source>Warm-start all weights in the model (input layer and hidden weights). Either the directory or a specific checkpoint can be provided (in the case of the former, the latest checkpoint will be used):</source>
          <target state="translated">Arrancar en caliente todos los pesos del modelo (capa de entrada y pesos ocultos).Se puede proporcionar el directorio o un punto de control específico (en el caso del primero,se utilizará el último punto de control):</target>
        </trans-unit>
        <trans-unit id="5b13568e15d19ce108f966610dd72d6f433fdac5" translate="yes" xml:space="preserve">
          <source>Warm-start non-TRAINABLE variables &quot;v1&quot;, &quot;v1/Momentum&quot;, and &quot;v2&quot; but not &quot;v2/momentum&quot;:</source>
          <target state="translated">Las variables no entrenables de arranque en caliente &quot;v1&quot;,&quot;v1/Momentum&quot; y &quot;v2&quot; pero no &quot;v2/momentum&quot;:</target>
        </trans-unit>
        <trans-unit id="a2a6608bb90e8edcca0d24db3c7888d49894818d" translate="yes" xml:space="preserve">
          <source>Warm-start only &lt;code&gt;sc_vocab_file&lt;/code&gt; embeddings (and no other variables), which have a different vocab from the one used in the current model:</source>
          <target state="translated">&lt;code&gt;sc_vocab_file&lt;/code&gt; caliente solo las incrustaciones de sc_vocab_file (y ninguna otra variable), que tienen un vocabulario diferente al utilizado en el modelo actual:</target>
        </trans-unit>
        <trans-unit id="8454c4aaa6884d63b21f47b182bea32dff06b1d9" translate="yes" xml:space="preserve">
          <source>Warm-start only the embeddings (input layer):</source>
          <target state="translated">Arranque en caliente sólo las incrustaciones (capa de entrada):</target>
        </trans-unit>
        <trans-unit id="053dd1f00688a5e1c6f7bb11994384338437241d" translate="yes" xml:space="preserve">
          <source>Warm-starts a model using the given settings.</source>
          <target state="translated">El calentamiento inicia un modelo usando los ajustes dados.</target>
        </trans-unit>
        <trans-unit id="a935669a6f94647cbab43dac31886ff159458161" translate="yes" xml:space="preserve">
          <source>Warning class expected to be triggered.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="005fd2adc416b2f84c9268603969a31365422ae0" translate="yes" xml:space="preserve">
          <source>We add forget_bias (default: 1) to the biases of the forget gate in order to reduce the scale of forgetting in the beginning of the training.</source>
          <target state="translated">Añadimos forget_bias (por defecto:1)a los sesgos de la puerta de olvido para reducir la escala de olvido al principio del entrenamiento.</target>
        </trans-unit>
        <trans-unit id="ea902771c0c609fef23987d09209f89de6ea6624" translate="yes" xml:space="preserve">
          <source>We assume that the word frequencies follow Zipf's law (s=1) to derive a numerical approximation of frequency(rank):</source>
          <target state="translated">Asumimos que la palabra frecuencias sigue la ley de Zipf (s=1)para derivar una aproximación numérica de la frecuencia (rango):</target>
        </trans-unit>
        <trans-unit id="ee7344fa99f19a3db805ed04f05f653d28a573dc" translate="yes" xml:space="preserve">
          <source>We call it an 'accidental hit' when one of the target classes matches one of the sampled classes. This operation reports accidental hits as triples &lt;code&gt;(index, id, weight)&lt;/code&gt;, where &lt;code&gt;index&lt;/code&gt; represents the row number in &lt;code&gt;true_classes&lt;/code&gt;, &lt;code&gt;id&lt;/code&gt; represents the position in &lt;code&gt;sampled_candidates&lt;/code&gt;, and weight is &lt;code&gt;-FLOAT_MAX&lt;/code&gt;.</source>
          <target state="translated">Lo llamamos un 'impacto accidental' cuando una de las clases objetivo coincide con una de las clases muestreadas. Esta operaci&amp;oacute;n informa los aciertos accidentales como triples &lt;code&gt;(index, id, weight)&lt;/code&gt; , donde el &lt;code&gt;index&lt;/code&gt; representa el n&amp;uacute;mero de fila en &lt;code&gt;true_classes&lt;/code&gt; , &lt;code&gt;id&lt;/code&gt; representa la posici&amp;oacute;n en &lt;code&gt;sampled_candidates&lt;/code&gt; y el peso es &lt;code&gt;-FLOAT_MAX&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3e90ccb70a2df6831216576e3e93ad8f84e29aaa" translate="yes" xml:space="preserve">
          <source>We can again draw the effect, this time using the symbols &lt;code&gt;*&lt;/code&gt;, &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;+&lt;/code&gt; and &lt;code&gt;o&lt;/code&gt; to distinguish the patches:</source>
          <target state="translated">De nuevo podemos sacar el efecto, esta vez utilizando los s&amp;iacute;mbolos &lt;code&gt;*&lt;/code&gt; , &lt;code&gt;x&lt;/code&gt; , &lt;code&gt;+&lt;/code&gt; y &lt;code&gt;o&lt;/code&gt; distinguir los parches:</target>
        </trans-unit>
        <trans-unit id="3ec1d6719eaed84adca414b94403fe4b9bce8b6a" translate="yes" xml:space="preserve">
          <source>We can also, insert entire slices of a higher rank tensor all at once. For example, if we wanted to insert two slices in the first dimension of a rank-3 tensor with two matrices of new values.</source>
          <target state="translated">También podemos,insertar rebanadas enteras de un tensor de mayor rango de una sola vez.Por ejemplo,si quisiéramos insertar dos rebanadas en la primera dimensión de un tensor de rango 3 con dos matrices de nuevos valores.</target>
        </trans-unit>
        <trans-unit id="75a6bd3ac0e29b2d99ddde37882f73b9484c4c89" translate="yes" xml:space="preserve">
          <source>We can compute the mean and variance of the batch</source>
          <target state="translated">Podemos calcular la media y la varianza del lote</target>
        </trans-unit>
        <trans-unit id="141a486e547cdd8105ede80b487557001daeacfc" translate="yes" xml:space="preserve">
          <source>We can construct a CsvDataset from it as follows:</source>
          <target state="translated">Podemos construir un conjunto de datos CsvD de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="798032cd2519c55922a86a65a97aa8223721d2bf" translate="yes" xml:space="preserve">
          <source>We can use arguments:</source>
          <target state="translated">Podemos usar argumentos:</target>
        </trans-unit>
        <trans-unit id="bfe0a32bb694084e323bdf39d8ca5b3bf5acf3b4" translate="yes" xml:space="preserve">
          <source>We first define two int64 tensors &lt;code&gt;paddings&lt;/code&gt; and &lt;code&gt;crops&lt;/code&gt; of shape &lt;code&gt;[num_spatial_dims, 2]&lt;/code&gt; based on the value of &lt;code&gt;padding&lt;/code&gt; and the spatial dimensions of the &lt;code&gt;input&lt;/code&gt;:</source>
          <target state="translated">Nos primero definir dos Int64 tensores &lt;code&gt;paddings&lt;/code&gt; y &lt;code&gt;crops&lt;/code&gt; de forma &lt;code&gt;[num_spatial_dims, 2]&lt;/code&gt; bas&amp;aacute;ndose en el valor de &lt;code&gt;padding&lt;/code&gt; y las dimensiones espaciales de la &lt;code&gt;input&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="c362e7cae577801d3a077b086c30ca6fb0a66da0" translate="yes" xml:space="preserve">
          <source>We first solve &lt;code&gt;x_0 = A_00.solve(y_0)&lt;/code&gt;. Proceeding inductively, we solve for &lt;code&gt;x_k&lt;/code&gt;, &lt;code&gt;k = 1..n&lt;/code&gt;, given &lt;code&gt;x_0..x_(k-1)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d6f96925005fe200b4a2292648a063218b208f4" translate="yes" xml:space="preserve">
          <source>We keep track of which flag is defined by which module so that we can later sort the flags by module.</source>
          <target state="translated">Hacemos un seguimiento de qué bandera está definida por qué módulo,para luego clasificar las banderas por módulo.</target>
        </trans-unit>
        <trans-unit id="e09363c49b193f1ac1770f115d6d8136f2ddc43c" translate="yes" xml:space="preserve">
          <source>We next use the scale_factor to adjust min_range and max_range as follows:</source>
          <target state="translated">A continuación utilizamos el scale_factor para ajustar el min_range y el max_range de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="6d1134ee5b3f5d2c7da4505ac717468ba6967616" translate="yes" xml:space="preserve">
          <source>We presuppose that the &lt;code&gt;sampled_candidates&lt;/code&gt; are unique.</source>
          <target state="translated">Suponemos que los &lt;code&gt;sampled_candidates&lt;/code&gt; son &amp;uacute;nicos.</target>
        </trans-unit>
        <trans-unit id="f093997d3edad673438d9d10c06d984c5a8a5f76" translate="yes" xml:space="preserve">
          <source>We recommend that descendants of &lt;code&gt;Layer&lt;/code&gt; implement the following methods:</source>
          <target state="translated">Recomendamos que los descendientes de &lt;code&gt;Layer&lt;/code&gt; implementen los siguientes m&amp;eacute;todos:</target>
        </trans-unit>
        <trans-unit id="bd2045e3591e6b6a7950e1ad85e808c50d3fcbe0" translate="yes" xml:space="preserve">
          <source>We recommend using &lt;a href=&quot;https://github.com/tensorflow/io&quot;&gt;https://github.com/tensorflow/io&lt;/a&gt; to load your HDF5 data into a tf.data Dataset and passing that dataset to Keras.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="664f0b931d5bb248f3df03fa1a45aa162e8bb7fc" translate="yes" xml:space="preserve">
          <source>We recommend using https://github.com/tensorflow/io to load your HDF5 data into a tf.data Dataset and passing that dataset to Keras.</source>
          <target state="translated">Recomendamos usar https://github.com/tensorflow/io para cargar sus datos del HDF5 en un conjunto de datos tf.data y pasar ese conjunto de datos a Keras.</target>
        </trans-unit>
        <trans-unit id="e6b1e174afc80b9d454ce2447d6b106dd858888d" translate="yes" xml:space="preserve">
          <source>We retrieve the information from the GCE APIs every time this method is called.</source>
          <target state="translated">Recuperamos la información de los API de la CME cada vez que se llama a este método.</target>
        </trans-unit>
        <trans-unit id="2e18048f9e04e3012f6199dfe11668988e00f3d9" translate="yes" xml:space="preserve">
          <source>We retrieve the information from the Kubernetes master every time this method is called.</source>
          <target state="translated">Recuperamos la información del maestro de los Kubernetes cada vez que se llama a este método.</target>
        </trans-unit>
        <trans-unit id="ee86e3990a38d113aeda3e686a64aed6a6c21a17" translate="yes" xml:space="preserve">
          <source>We specify the size-related attributes as:</source>
          <target state="translated">Especificamos los atributos relacionados con el tamaño como:</target>
        </trans-unit>
        <trans-unit id="88a4bbb7071448507fb5ea156b09b64279b62233" translate="yes" xml:space="preserve">
          <source>We use the following notation for (complex) matrix and right-hand sides in the batch:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d371d0dcdb3a29109c4aec0bd9662ca4cc225c96" translate="yes" xml:space="preserve">
          <source>We will assume that the input dataset is batched by the global batch size. With this assumption, we will make a best effort to divide each batch across all the replicas (one or more workers).</source>
          <target state="translated">Asumiremos que el conjunto de datos de entrada está agrupado por el tamaño del lote global.Con esta suposición,haremos el mejor esfuerzo para dividir cada lote entre todas las réplicas (uno o más trabajadores).</target>
        </trans-unit>
        <trans-unit id="c1e896bf769945f02ba4270d6713548acfff861f" translate="yes" xml:space="preserve">
          <source>Web-safe means that the encoder uses - and _ instead of + and /.</source>
          <target state="translated">Seguro para la web significa que el codificador usa-y_en lugar de+y /.</target>
        </trans-unit>
        <trans-unit id="a5ecd420b68c6ca62b2880bcb67d127d7527fd45" translate="yes" xml:space="preserve">
          <source>Weight updates (for instance, the updates of the moving mean and variance in a BatchNormalization layer) may be dependent on the inputs passed when calling a layer. Hence, when reusing the same layer on different inputs &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt;, some entries in &lt;code&gt;layer.updates&lt;/code&gt; may be dependent on &lt;code&gt;a&lt;/code&gt; and some on &lt;code&gt;b&lt;/code&gt;. This method automatically keeps track of dependencies.</source>
          <target state="translated">Las actualizaciones de peso (por ejemplo, las actualizaciones de la media m&amp;oacute;vil y la varianza en una capa de BatchNormalization) pueden depender de las entradas pasadas al llamar a una capa. Por lo tanto, cuando la reutilizaci&amp;oacute;n de la misma capa en diferentes entradas de &lt;code&gt;a&lt;/code&gt; y &lt;code&gt;b&lt;/code&gt; , algunas entradas en &lt;code&gt;layer.updates&lt;/code&gt; pueden depender de &lt;code&gt;a&lt;/code&gt; y algunos en &lt;code&gt;b&lt;/code&gt; . Este m&amp;eacute;todo realiza un seguimiento autom&amp;aacute;tico de las dependencias.</target>
        </trans-unit>
        <trans-unit id="012994d31dee39cea10e34d13b123636095aef6d" translate="yes" xml:space="preserve">
          <source>Weighted loss &lt;code&gt;Tensor&lt;/code&gt; of the same type as &lt;code&gt;logits&lt;/code&gt;. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;NONE&lt;/code&gt;, this has shape &lt;code&gt;[batch_size]&lt;/code&gt;; otherwise, it is scalar.</source>
          <target state="translated">&lt;code&gt;Tensor&lt;/code&gt; de p&amp;eacute;rdida ponderada del mismo tipo que &lt;code&gt;logits&lt;/code&gt; . Si la &lt;code&gt;reduction&lt;/code&gt; es &lt;code&gt;NONE&lt;/code&gt; , tiene forma &lt;code&gt;[batch_size]&lt;/code&gt; ; de lo contrario, es escalar.</target>
        </trans-unit>
        <trans-unit id="9d1005c1318b48c01558d66a2ac013b81040339a" translate="yes" xml:space="preserve">
          <source>Weighted loss &lt;code&gt;Tensor&lt;/code&gt; of the same type as &lt;code&gt;logits&lt;/code&gt;. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;NONE&lt;/code&gt;, this has the same shape as &lt;code&gt;labels&lt;/code&gt;; otherwise, it is scalar.</source>
          <target state="translated">&lt;code&gt;Tensor&lt;/code&gt; de p&amp;eacute;rdida ponderada del mismo tipo que &lt;code&gt;logits&lt;/code&gt; . Si la &lt;code&gt;reduction&lt;/code&gt; es &lt;code&gt;NONE&lt;/code&gt; , tiene la misma forma que las &lt;code&gt;labels&lt;/code&gt; ; de lo contrario, es escalar.</target>
        </trans-unit>
        <trans-unit id="834de6c05706f24229c420c387a2f8167f0b45d5" translate="yes" xml:space="preserve">
          <source>Weighted loss &lt;code&gt;Tensor&lt;/code&gt; of the same type as &lt;code&gt;logits&lt;/code&gt;. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;NONE&lt;/code&gt;, this has the same shape as &lt;code&gt;logits&lt;/code&gt;; otherwise, it is scalar.</source>
          <target state="translated">&lt;code&gt;Tensor&lt;/code&gt; de p&amp;eacute;rdida ponderada del mismo tipo que &lt;code&gt;logits&lt;/code&gt; . Si la &lt;code&gt;reduction&lt;/code&gt; es &lt;code&gt;NONE&lt;/code&gt; , tiene la misma forma que &lt;code&gt;logits&lt;/code&gt; ; de lo contrario, es escalar.</target>
        </trans-unit>
        <trans-unit id="b075652dc6120aaf1d41f8a4dc2daf694ffa4a69" translate="yes" xml:space="preserve">
          <source>Weighted loss &lt;code&gt;Tensor&lt;/code&gt; of the same type as &lt;code&gt;losses&lt;/code&gt;. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;NONE&lt;/code&gt;, this has the same shape as &lt;code&gt;losses&lt;/code&gt;; otherwise, it is scalar.</source>
          <target state="translated">&lt;code&gt;Tensor&lt;/code&gt; de p&amp;eacute;rdidas ponderadas del mismo tipo que las &lt;code&gt;losses&lt;/code&gt; . Si la &lt;code&gt;reduction&lt;/code&gt; es &lt;code&gt;NONE&lt;/code&gt; , tiene la misma forma que las &lt;code&gt;losses&lt;/code&gt; ; de lo contrario, es escalar.</target>
        </trans-unit>
        <trans-unit id="f8f11d4c7a3da229788db34932231d37e05fbe0b" translate="yes" xml:space="preserve">
          <source>Weighted loss float &lt;code&gt;Tensor&lt;/code&gt;. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;NONE&lt;/code&gt;, this has shape &lt;code&gt;[batch_size, d0, .. dN-1]&lt;/code&gt;; otherwise, it is scalar. (Note &lt;code&gt;dN-1&lt;/code&gt; because all loss functions reduce by 1 dimension, usually axis=-1.)</source>
          <target state="translated">&lt;code&gt;Tensor&lt;/code&gt; de flotaci&amp;oacute;n de p&amp;eacute;rdida ponderada . Si la &lt;code&gt;reduction&lt;/code&gt; es &lt;code&gt;NONE&lt;/code&gt; , tiene forma &lt;code&gt;[batch_size, d0, .. dN-1]&lt;/code&gt; ; de lo contrario, es escalar. (Tenga en cuenta &lt;code&gt;dN-1&lt;/code&gt; porque todas las funciones de p&amp;eacute;rdida se reducen en 1 dimensi&amp;oacute;n, generalmente eje = -1).</target>
        </trans-unit>
        <trans-unit id="37a14c45a506771a19d570992ffb74e2a8ababd3" translate="yes" xml:space="preserve">
          <source>Weighted loss float &lt;code&gt;Tensor&lt;/code&gt;. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;NONE&lt;/code&gt;, this has the same shape as &lt;code&gt;labels&lt;/code&gt;; otherwise, it is scalar.</source>
          <target state="translated">&lt;code&gt;Tensor&lt;/code&gt; de flotaci&amp;oacute;n de p&amp;eacute;rdida ponderada . Si la &lt;code&gt;reduction&lt;/code&gt; es &lt;code&gt;NONE&lt;/code&gt; , tiene la misma forma que las &lt;code&gt;labels&lt;/code&gt; ; de lo contrario, es escalar.</target>
        </trans-unit>
        <trans-unit id="23f94c92282719a4052aebc7d476aba406e80f05" translate="yes" xml:space="preserve">
          <source>Weights values as a list of numpy arrays.</source>
          <target state="translated">Pondera los valores como una lista de matrices numéricas.</target>
        </trans-unit>
        <trans-unit id="79699365f3dd7ea5c60a1201001103f0e4d8e414" translate="yes" xml:space="preserve">
          <source>What &lt;code&gt;master&lt;/code&gt; string to use</source>
          <target state="translated">Que cadena &lt;code&gt;master&lt;/code&gt; usar</target>
        </trans-unit>
        <trans-unit id="8126fc60320a74dd637a7bb9a583488f0b14222c" translate="yes" xml:space="preserve">
          <source>What happens in &lt;code&gt;adapt&lt;/code&gt;: Compute mean and variance of the data and store them as the layer's weights. &lt;code&gt;adapt&lt;/code&gt; should be called before &lt;code&gt;fit&lt;/code&gt;, &lt;code&gt;evaluate&lt;/code&gt;, or &lt;code&gt;predict&lt;/code&gt;.</source>
          <target state="translated">Qu&amp;eacute; sucede en &lt;code&gt;adapt&lt;/code&gt; : Calcule la media y la varianza de los datos y almac&amp;eacute;nelos como pesos de la capa. &lt;code&gt;adapt&lt;/code&gt; debe llamarse antes de &lt;code&gt;fit&lt;/code&gt; , &lt;code&gt;evaluate&lt;/code&gt; o &lt;code&gt;predict&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f4112aa72544bbd54c25bceb58f7f58b932e32d8" translate="yes" xml:space="preserve">
          <source>What to return in test phase (tensor or callable that returns a tensor).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17f24426650f12852c89205be844ef319f76644b" translate="yes" xml:space="preserve">
          <source>What to return in train phase (tensor or callable that returns a tensor).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="def8b9f5f06fb4c06699fb40ca04320258ae46d4" translate="yes" xml:space="preserve">
          <source>What to return otherwise (tensor or callable that returns a tensor).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e11f03a4f4c3dbc0b65542222647d127c17f0502" translate="yes" xml:space="preserve">
          <source>What's under the hood of this method, when we say the &lt;a href=&quot;../../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; instance - &lt;code&gt;dataset&lt;/code&gt; - gets distributed? It depends on how you set the &lt;a href=&quot;../../../../data/experimental/autoshardpolicy&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy&lt;/code&gt;&lt;/a&gt; through &lt;a href=&quot;../../../../data/experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;. By default, it is set to &lt;a href=&quot;../../../../data/experimental/autoshardpolicy#AUTO&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy.AUTO&lt;/code&gt;&lt;/a&gt;. In a multi-worker setting, we will first attempt to distribute &lt;code&gt;dataset&lt;/code&gt; by detecting whether &lt;code&gt;dataset&lt;/code&gt; is being created out of reader datasets (e.g. &lt;a href=&quot;../../../../data/tfrecorddataset&quot;&gt;&lt;code&gt;tf.data.TFRecordDataset&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../../../data/textlinedataset&quot;&gt;&lt;code&gt;tf.data.TextLineDataset&lt;/code&gt;&lt;/a&gt;, etc.) and if so, try to shard the input files. Note that there has to be at least one input file per worker. If you have less than one input file per worker, we suggest that you disable dataset sharding across workers, by setting the &lt;a href=&quot;../../../../data/experimental/distributeoptions#auto_shard_policy&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions.auto_shard_policy&lt;/code&gt;&lt;/a&gt; to be &lt;a href=&quot;../../../../data/experimental/autoshardpolicy#OFF&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy.OFF&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f8e0522d952680a4b2c6fbddea797a2677b1547" translate="yes" xml:space="preserve">
          <source>What's under the hood of this method, when we say the &lt;a href=&quot;../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; instance - &lt;code&gt;dataset&lt;/code&gt; - gets distributed? It depends on how you set the &lt;a href=&quot;../../../data/experimental/autoshardpolicy&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy&lt;/code&gt;&lt;/a&gt; through &lt;a href=&quot;../../../data/experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;. By default, it is set to &lt;a href=&quot;../../../data/experimental/autoshardpolicy#AUTO&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy.AUTO&lt;/code&gt;&lt;/a&gt;. In a multi-worker setting, we will first attempt to distribute &lt;code&gt;dataset&lt;/code&gt; by detecting whether &lt;code&gt;dataset&lt;/code&gt; is being created out of reader datasets (e.g. &lt;a href=&quot;../../../data/tfrecorddataset&quot;&gt;&lt;code&gt;tf.data.TFRecordDataset&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../../data/textlinedataset&quot;&gt;&lt;code&gt;tf.data.TextLineDataset&lt;/code&gt;&lt;/a&gt;, etc.) and if so, try to shard the input files. Note that there has to be at least one input file per worker. If you have less than one input file per worker, we suggest that you disable dataset sharding across workers, by setting the &lt;a href=&quot;../../../data/experimental/distributeoptions#auto_shard_policy&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions.auto_shard_policy&lt;/code&gt;&lt;/a&gt; to be &lt;a href=&quot;../../../data/experimental/autoshardpolicy#OFF&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy.OFF&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a0d7396d4c78509ccd91f8c0cfaa89f6bac9680" translate="yes" xml:space="preserve">
          <source>What's under the hood of this method, when we say the &lt;a href=&quot;../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; instance - &lt;code&gt;dataset&lt;/code&gt; - gets distributed? It depends on how you set the &lt;a href=&quot;../../data/experimental/autoshardpolicy&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy&lt;/code&gt;&lt;/a&gt; through &lt;a href=&quot;../../data/experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;. By default, it is set to &lt;a href=&quot;../../data/experimental/autoshardpolicy#AUTO&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy.AUTO&lt;/code&gt;&lt;/a&gt;. In a multi-worker setting, we will first attempt to distribute &lt;code&gt;dataset&lt;/code&gt; by detecting whether &lt;code&gt;dataset&lt;/code&gt; is being created out of reader datasets (e.g. &lt;a href=&quot;../../data/tfrecorddataset&quot;&gt;&lt;code&gt;tf.data.TFRecordDataset&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../data/textlinedataset&quot;&gt;&lt;code&gt;tf.data.TextLineDataset&lt;/code&gt;&lt;/a&gt;, etc.) and if so, try to shard the input files. Note that there has to be at least one input file per worker. If you have less than one input file per worker, we suggest that you disable dataset sharding across workers, by setting the &lt;a href=&quot;../../data/experimental/distributeoptions#auto_shard_policy&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions.auto_shard_policy&lt;/code&gt;&lt;/a&gt; to be &lt;a href=&quot;../../data/experimental/autoshardpolicy#OFF&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy.OFF&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e73d3cb0a89b521b7e9847b33f0048e348f89d5" translate="yes" xml:space="preserve">
          <source>What's under the hood of this method, when we say the &lt;a href=&quot;../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; instance - &lt;code&gt;dataset&lt;/code&gt; - gets distributed? It depends on how you set the &lt;a href=&quot;../data/experimental/autoshardpolicy&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy&lt;/code&gt;&lt;/a&gt; through &lt;a href=&quot;../data/experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;. By default, it is set to &lt;a href=&quot;../data/experimental/autoshardpolicy#AUTO&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy.AUTO&lt;/code&gt;&lt;/a&gt;. In a multi-worker setting, we will first attempt to distribute &lt;code&gt;dataset&lt;/code&gt; by detecting whether &lt;code&gt;dataset&lt;/code&gt; is being created out of reader datasets (e.g. &lt;a href=&quot;../data/tfrecorddataset&quot;&gt;&lt;code&gt;tf.data.TFRecordDataset&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../data/textlinedataset&quot;&gt;&lt;code&gt;tf.data.TextLineDataset&lt;/code&gt;&lt;/a&gt;, etc.) and if so, try to shard the input files. Note that there has to be at least one input file per worker. If you have less than one input file per worker, we suggest that you disable dataset sharding across workers, by setting the &lt;a href=&quot;../data/experimental/distributeoptions#auto_shard_policy&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions.auto_shard_policy&lt;/code&gt;&lt;/a&gt; to be &lt;a href=&quot;../data/experimental/autoshardpolicy#OFF&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy.OFF&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4633647d41640957a472ab68c0262290690dfdb" translate="yes" xml:space="preserve">
          <source>When 'TF_CONFIG' environment variable is set, it parses cluster_spec, task_type and task_id from 'TF_CONFIG' and turns into a multi-worker strategy which mirrored models on GPUs of all machines in a cluster. In the current implementation, it uses all GPUs in a cluster and it assumes all workers have the same number of GPUs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="97233c5c3c8d20a5e9ffbdbe3b7ccb6a51db597b" translate="yes" xml:space="preserve">
          <source>When 'TF_CONFIG' environment variable is set, it parses cluster_spec, task_type and task_id from 'TF_CONFIG' and turns into a multi-worker strategy which mirrores models on GPUs of all machines in a cluster. In the current implementation, it uses all GPUs in a cluster and it assumes all workers have the same number of GPUs.</source>
          <target state="translated">Cuando se establece la variable de entorno 'TF_CONFIG',analiza cluster_spec,task_type y task_id de 'TF_CONFIG' y se convierte en una estrategia multitrabajador que refleja los modelos en las GPUs de todas las máquinas de un clúster.En la implementación actual,utiliza todas las GPU de un clúster y asume que todos los trabajadores tienen el mismo número de GPU.</target>
        </trans-unit>
        <trans-unit id="f5e1d55c89f446271b947fe72a857c539201c7dc" translate="yes" xml:space="preserve">
          <source>When 'antialias' is true, the sampling filter will anti-alias the input image as well as interpolate. When downsampling an image with &lt;a href=&quot;https://en.wikipedia.org/wiki/Spatial_anti-aliasing&quot;&gt;anti-aliasing&lt;/a&gt; the sampling filter kernel is scaled in order to properly anti-alias the input image signal. 'antialias' has no effect when upsampling an image.</source>
          <target state="translated">Cuando 'antialias' es verdadero, el filtro de muestreo suavizar&amp;aacute; la imagen de entrada e interpolar&amp;aacute;. Cuando se reduce el muestreo de una imagen con &lt;a href=&quot;https://en.wikipedia.org/wiki/Spatial_anti-aliasing&quot;&gt;suavizado,&lt;/a&gt; el n&amp;uacute;cleo del filtro de muestreo se escala para suavizar adecuadamente la se&amp;ntilde;al de la imagen de entrada. 'antialias' no tiene ning&amp;uacute;n efecto al muestrear una imagen.</target>
        </trans-unit>
        <trans-unit id="a125e391abcaadbe33801ab8eddcf23c35279113" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;True&lt;/code&gt;, additional assertions might be embedded in the graph. Default value: &lt;code&gt;False&lt;/code&gt; (i.e., no graph assertions are added).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="735a581f2af66e2fcb181fd57a9ddb799b2eb257" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;antialias&lt;/code&gt; is true, the sampling filter will anti-alias the input image as well as interpolate. When downsampling an image with &lt;a href=&quot;https://en.wikipedia.org/wiki/Spatial_anti-aliasing&quot;&gt;anti-aliasing&lt;/a&gt; the sampling filter kernel is scaled in order to properly anti-alias the input image signal. &lt;code&gt;antialias&lt;/code&gt; has no effect when upsampling an image:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9aacbccc1a065c95aea812e79f50b9fb0809ae76" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;distribute&lt;/code&gt; or &lt;code&gt;experimental_distribute.train_distribute&lt;/code&gt; and &lt;code&gt;experimental_distribute.remote_cluster&lt;/code&gt; is set, this method will start a client running on the current host which connects to the &lt;code&gt;remote_cluster&lt;/code&gt; for training and evaluation.</source>
          <target state="translated">Cuando se establece &lt;code&gt;distribute&lt;/code&gt; o &lt;code&gt;experimental_distribute.train_distribute&lt;/code&gt; y &lt;code&gt;experimental_distribute.remote_cluster&lt;/code&gt; , este m&amp;eacute;todo iniciar&amp;aacute; la ejecuci&amp;oacute;n de un cliente en el host actual que se conecta a &lt;code&gt;remote_cluster&lt;/code&gt; para entrenamiento y evaluaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="01497840225ce1bb0dcac0f82d53eb47485d512b" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;enable&lt;/code&gt; is set to None, an appropriate value will be picked automatically. The value picked may change between TensorFlow releases.</source>
          <target state="translated">Cuando la &lt;code&gt;enable&lt;/code&gt; se establece en Ninguno, se seleccionar&amp;aacute; autom&amp;aacute;ticamente un valor apropiado. El valor elegido puede cambiar entre las versiones de TensorFlow.</target>
        </trans-unit>
        <trans-unit id="3a92e9802f62e2ea66187929bf4db58022152e26" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;nesterov=False&lt;/code&gt;, this rule becomes:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c64f1c94124dc71ee97e99b0200e5f2b295d3204" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;queues&lt;/code&gt; is not a list of &lt;code&gt;QueueBase&lt;/code&gt; objects, or when the data types of &lt;code&gt;queues&lt;/code&gt; are not all the same.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d965c5a7f6cd6a88315eeacabf229f5d784d0a97" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;rescale&lt;/code&gt; is set to a value, rescaling is applied to sample data before computing the internal data stats.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dda3a421cfde51cef62429c270613980d6f95f4a" translate="yes" xml:space="preserve">
          <source>When True, &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; may generate fewer, graphs that are less specialized on input shapes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2203660cd3c839935256a662d4fa7b611fae192" translate="yes" xml:space="preserve">
          <source>When a &lt;a href=&quot;../../../../keras/model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; is created inside a &lt;code&gt;strategy.scope&lt;/code&gt;, we capture this information. When high level training frameworks methods such as &lt;code&gt;model.compile&lt;/code&gt;, &lt;code&gt;model.fit&lt;/code&gt; etc are then called on this model, we automatically enter the scope, as well as use this strategy to distribute the training etc. See detailed example in &lt;a href=&quot;https://www.tensorflow.org/tutorials/distribute/keras&quot;&gt;distributed keras tutorial&lt;/a&gt;. Note that simply calling the &lt;code&gt;model(..)&lt;/code&gt; is not impacted - only high level training framework APIs are. &lt;code&gt;model.compile&lt;/code&gt;, &lt;code&gt;model.fit&lt;/code&gt;, &lt;code&gt;model.evaluate&lt;/code&gt;, &lt;code&gt;model.predict&lt;/code&gt; and &lt;code&gt;model.save&lt;/code&gt; can all be called inside or outside the scope.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a77de95801a4cff5844b758a2ad8179bb09d2c1a" translate="yes" xml:space="preserve">
          <source>When a &lt;a href=&quot;../../../keras/model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; is created inside a &lt;code&gt;strategy.scope&lt;/code&gt;, we capture this information. When high level training frameworks methods such as &lt;code&gt;model.compile&lt;/code&gt;, &lt;code&gt;model.fit&lt;/code&gt; etc are then called on this model, we automatically enter the scope, as well as use this strategy to distribute the training etc. See detailed example in &lt;a href=&quot;https://www.tensorflow.org/tutorials/distribute/keras&quot;&gt;distributed keras tutorial&lt;/a&gt;. Note that simply calling the &lt;code&gt;model(..)&lt;/code&gt; is not impacted - only high level training framework APIs are. &lt;code&gt;model.compile&lt;/code&gt;, &lt;code&gt;model.fit&lt;/code&gt;, &lt;code&gt;model.evaluate&lt;/code&gt;, &lt;code&gt;model.predict&lt;/code&gt; and &lt;code&gt;model.save&lt;/code&gt; can all be called inside or outside the scope.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5bc23220d2b015520f09eca2cbd06a9bdbef9712" translate="yes" xml:space="preserve">
          <source>When a &lt;a href=&quot;../../keras/model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; is created inside a &lt;code&gt;strategy.scope&lt;/code&gt;, we capture this information. When high level training frameworks methods such as &lt;code&gt;model.compile&lt;/code&gt;, &lt;code&gt;model.fit&lt;/code&gt; etc are then called on this model, we automatically enter the scope, as well as use this strategy to distribute the training etc. See detailed example in &lt;a href=&quot;https://www.tensorflow.org/tutorials/distribute/keras&quot;&gt;distributed keras tutorial&lt;/a&gt;. Note that simply calling the &lt;code&gt;model(..)&lt;/code&gt; is not impacted - only high level training framework APIs are. &lt;code&gt;model.compile&lt;/code&gt;, &lt;code&gt;model.fit&lt;/code&gt;, &lt;code&gt;model.evaluate&lt;/code&gt;, &lt;code&gt;model.predict&lt;/code&gt; and &lt;code&gt;model.save&lt;/code&gt; can all be called inside or outside the scope.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8157664b0c676127bfe8a48270b035a599288e2e" translate="yes" xml:space="preserve">
          <source>When a &lt;a href=&quot;../keras/model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; is created inside a &lt;code&gt;strategy.scope&lt;/code&gt;, we capture this information. When high level training frameworks methods such as &lt;code&gt;model.compile&lt;/code&gt;, &lt;code&gt;model.fit&lt;/code&gt; etc are then called on this model, we automatically enter the scope, as well as use this strategy to distribute the training etc. See detailed example in &lt;a href=&quot;https://www.tensorflow.org/tutorials/distribute/keras&quot;&gt;distributed keras tutorial&lt;/a&gt;. Note that simply calling the &lt;code&gt;model(..)&lt;/code&gt; is not impacted - only high level training framework APIs are. &lt;code&gt;model.compile&lt;/code&gt;, &lt;code&gt;model.fit&lt;/code&gt;, &lt;code&gt;model.evaluate&lt;/code&gt;, &lt;code&gt;model.predict&lt;/code&gt; and &lt;code&gt;model.save&lt;/code&gt; can all be called inside or outside the scope.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d3c29ba7c1915daf444dfa9480a120b9d259cc0" translate="yes" xml:space="preserve">
          <source>When a DistributionStrategy is used, this function may only be called in a cross-replica context.</source>
          <target state="translated">Cuando se utiliza una estrategia de distribución,esta función sólo puede llamarse en un contexto de réplica cruzada.</target>
        </trans-unit>
        <trans-unit id="9ee3d0211a7961d1892863b309bfae8dc55d02c2" translate="yes" xml:space="preserve">
          <source>When a Summary op is instantiated, a SummaryDescription of associated metadata is stored in its NodeDef. This method retrieves the description.</source>
          <target state="translated">Cuando se instanciar una operación de resumen,se almacena una descripción de resumen de los metadatos asociados en su NodeDef.Este método recupera la descripción.</target>
        </trans-unit>
        <trans-unit id="468fae491a93893feb36e0fc65b7a7ac2c612355" translate="yes" xml:space="preserve">
          <source>When a global &lt;a href=&quot;../../../../keras/mixed_precision/experimental/policy&quot;&gt;&lt;code&gt;tf.keras.mixed_precision.experimental.Policy&lt;/code&gt;&lt;/a&gt; is set, a Keras layer's dtype will default to the global policy instead of floatx. Layers will automatically cast inputs to the policy's compute_dtype.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="067c92a0436a2a055b3eb1915882349b4d833f6c" translate="yes" xml:space="preserve">
          <source>When a op's float-type output tensor contains any Infinity or NaN, an &lt;a href=&quot;../errors/invalidargumenterror&quot;&gt;&lt;code&gt;tf.errors.InvalidArgumentError&lt;/code&gt;&lt;/a&gt; will be thrown, with an error message that reveals the following information:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e2c0bd0de968bcd753736a8da6d2db14223d5cf" translate="yes" xml:space="preserve">
          <source>When a op's float-type output tensor contains any Infinity or NaN, an &lt;a href=&quot;../errors/invalidargumenterror&quot;&gt;&lt;code&gt;tf.errors.InvalidArgumentError&lt;/code&gt;&lt;/a&gt; will be thrown, with an error message that reveals the following information: - The type of the op that generated the tensor with bad numerics. - Data type (dtype) of the tensor. - Shape of the tensor (to the extent known at the time of eager execution or graph construction). - Name of the containing graph (if available). - (Graph mode only): The stack trace of the intra-graph op's creation, with a stack-height limit and a path-length limit for visual clarity. The stack frames that belong to the user's code (as opposed to tensorflow's internal code) are highlighted with a text arrow (&quot;-&amp;gt;&quot;). - (Eager mode only): How many of the offending tensor's elements are &lt;code&gt;Infinity&lt;/code&gt; and &lt;code&gt;NaN&lt;/code&gt;, respectively.</source>
          <target state="translated">Cuando el tensor de salida de tipo flotante de una &lt;a href=&quot;../errors/invalidargumenterror&quot;&gt; &lt;code&gt;tf.errors.InvalidArgumentError&lt;/code&gt; &lt;/a&gt; contiene cualquier Infinity o NaN, se lanzar&amp;aacute; un tf.errors.InvalidArgumentError , con un mensaje de error que revela la siguiente informaci&amp;oacute;n: - El tipo de la operaci&amp;oacute;n que gener&amp;oacute; el tensor con n&amp;uacute;meros incorrectos. - Tipo de datos (dtype) del tensor. - Forma del tensor (en la medida conocida en el momento de la ejecuci&amp;oacute;n &amp;aacute;vida o la construcci&amp;oacute;n del gr&amp;aacute;fico). - Nombre del gr&amp;aacute;fico que lo contiene (si est&amp;aacute; disponible). - (Solo en modo gr&amp;aacute;fico): el seguimiento de la pila de la creaci&amp;oacute;n de la operaci&amp;oacute;n dentro del gr&amp;aacute;fico, con un l&amp;iacute;mite de altura de pila y un l&amp;iacute;mite de longitud de ruta para mayor claridad visual. Los marcos de pila que pertenecen al c&amp;oacute;digo del usuario (a diferencia del c&amp;oacute;digo interno de tensorflow) se resaltan con una flecha de texto (&quot;-&amp;gt;&quot;). - (Solo en modo Eager): cu&amp;aacute;ntos del tensor ofensivo 'Los elementos son &lt;code&gt;Infinity&lt;/code&gt; y &lt;code&gt;NaN&lt;/code&gt; , respectivamente.</target>
        </trans-unit>
        <trans-unit id="b898b5ad811100780dad4051c33f639fd70aa1be" translate="yes" xml:space="preserve">
          <source>When a tf.random operation is built with XLA, the implementation doesn't pass the user provided seed to the XLA compiler. As such, the XLA compiler generates a random number and uses it as a seed when compiling the operation. This implementation causes a violation of the Tensorflow defined semantics in two aspects. First, changing the value of the user defined seed doesn't change the numbers generated by the operation. Second, when a seed is not specified, running the program multiple times will generate the same numbers.</source>
          <target state="translated">Cuando se construye una operación tf.random con XLA,la implementación no pasa la semilla proporcionada por el usuario al compilador XLA.Como tal,el compilador XLA genera un número aleatorio y lo utiliza como semilla al compilar la operación.Esta implementación causa una violación de la semántica definida por Tensorflow en dos aspectos.Primero,cambiar el valor de la semilla definida por el usuario no cambia los números generados por la operación.Segundo,cuando una semilla no está especificada,ejecutar el programa varias veces generará los mismos números.</target>
        </trans-unit>
        <trans-unit id="493652c7a3597db99acb0cc5aae0cc36b4d15e47" translate="yes" xml:space="preserve">
          <source>When a trackable object is exported via &lt;a href=&quot;save&quot;&gt;&lt;code&gt;tf.saved_model.save()&lt;/code&gt;&lt;/a&gt;, all the &lt;code&gt;Asset&lt;/code&gt;s reachable from it are copied into the SavedModel assets directory. Upon loading, the assets and the serialized functions that depend on them will refer to the correct filepaths inside the SavedModel directory.</source>
          <target state="translated">Cuando un objeto rastreable se exporta a trav&amp;eacute;s de &lt;a href=&quot;save&quot;&gt; &lt;code&gt;tf.saved_model.save()&lt;/code&gt; &lt;/a&gt; , todos los &lt;code&gt;Asset&lt;/code&gt; accesibles desde &amp;eacute;l se copian en el directorio de activos de SavedModel. Al cargar, los activos y las funciones serializadas que dependen de ellos se referir&amp;aacute;n a las rutas de archivo correctas dentro del directorio SavedModel.</target>
        </trans-unit>
        <trans-unit id="6f1183817b3726ec7266e15fa411e144c4d1a1bb" translate="yes" xml:space="preserve">
          <source>When accessing the value of a TensorShape dimension, use this utility, like this:</source>
          <target state="translated">Cuando acceda al valor de una dimensión TensorShape,use esta utilidad,así:</target>
        </trans-unit>
        <trans-unit id="5eeff351258cc34299c1acc2c35d15d6a807f5fe" translate="yes" xml:space="preserve">
          <source>When arguments have invalid value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e15681c5c4d660d694d5dcc65f824f2819119a6a" translate="yes" xml:space="preserve">
          <source>When attempting to multiply a nD tensor with a nD tensor, it reproduces the Theano behavior. (e.g. &lt;code&gt;(2, 3) * (4, 3, 5) -&amp;gt; (2, 4, 5)&lt;/code&gt;)</source>
          <target state="translated">Al intentar multiplicar un tensor nD con un tensor nD, se reproduce el comportamiento de Theano. (p. ej. &lt;code&gt;(2, 3) * (4, 3, 5) -&amp;gt; (2, 4, 5)&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="c84b6c98a486c1f1ed40714b3413c2d05ebb290e" translate="yes" xml:space="preserve">
          <source>When attempting to normalize on an empty ensemble or an ensemble of trees which have no splits. Or when attempting to normalize and feature importances have negative values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c06f27a3b19deaf8176a82559892b7885f9b161" translate="yes" xml:space="preserve">
          <source>When autotuning is enabled (through &lt;code&gt;autotune&lt;/code&gt;), determines the CPU budget to use. Values greater than the number of schedulable CPU cores are allowed but may result in CPU contention. If None, defaults to the number of schedulable CPU cores.</source>
          <target state="translated">Cuando el autoajuste est&amp;aacute; habilitado (a trav&amp;eacute;s del &lt;code&gt;autotune&lt;/code&gt; ), determina el presupuesto de CPU que se utilizar&amp;aacute;. Se permiten valores mayores que el n&amp;uacute;mero de n&amp;uacute;cleos de CPU programables, pero pueden provocar una contenci&amp;oacute;n de la CPU. Si es Ninguno, el valor predeterminado es el n&amp;uacute;mero de n&amp;uacute;cleos de CPU programables.</target>
        </trans-unit>
        <trans-unit id="aa75a73b6c69b49d6e19ddace76d0dc9e6d20863" translate="yes" xml:space="preserve">
          <source>When autotuning is enabled (through &lt;code&gt;autotune&lt;/code&gt;), determines whether to also autotune buffer sizes for datasets with parallelism. If None, defaults to False.</source>
          <target state="translated">Cuando el autoajuste est&amp;aacute; habilitado (a trav&amp;eacute;s del &lt;code&gt;autotune&lt;/code&gt; ), determina si tambi&amp;eacute;n se autoajustan los tama&amp;ntilde;os de b&amp;uacute;fer para conjuntos de datos con paralelismo. Si es Ninguno, el valor predeterminado es Falso.</target>
        </trans-unit>
        <trans-unit id="283f72551210c9459423ecb79011f0f8519629e6" translate="yes" xml:space="preserve">
          <source>When autotuning is enabled (through &lt;code&gt;autotune&lt;/code&gt;), identifies the algorithm to use for the autotuning optimization.</source>
          <target state="translated">Cuando el autoajuste est&amp;aacute; habilitado (a trav&amp;eacute;s del &lt;code&gt;autotune&lt;/code&gt; ), identifica el algoritmo que se utilizar&amp;aacute; para la optimizaci&amp;oacute;n del autoajuste.</target>
        </trans-unit>
        <trans-unit id="e6deb11b689fcef12dab268b644289f6586fd39c" translate="yes" xml:space="preserve">
          <source>When both &lt;code&gt;squeeze_dims&lt;/code&gt; and &lt;code&gt;axis&lt;/code&gt; are specified.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32eb733d84fe74265b206fb4da02dbc0b66960e1" translate="yes" xml:space="preserve">
          <source>When building a complex model that uses many queues it is often difficult to gather all the queue runners that need to be run. This convenience function allows you to add a queue runner to a well known collection in the graph.</source>
          <target state="translated">Cuando se construye un modelo complejo que utiliza muchas colas,a menudo es difícil reunir a todos los corredores de la cola que necesitan ser corridos.Esta conveniente función permite añadir un corredor de cola a una colección bien conocida en el gráfico.</target>
        </trans-unit>
        <trans-unit id="e5bcf632e0c577d3a09737c01de056496ad7c080" translate="yes" xml:space="preserve">
          <source>When building a machine learning model it is often convenient to distinguish between variables holding the trainable model parameters and other variables such as a &lt;code&gt;global step&lt;/code&gt; variable used to count training steps. To make this easier, the variable constructor supports a &lt;code&gt;trainable=&amp;lt;bool&amp;gt;&lt;/code&gt; parameter. If &lt;code&gt;True&lt;/code&gt;, the new variable is also added to the graph collection &lt;code&gt;GraphKeys.TRAINABLE_VARIABLES&lt;/code&gt;. The convenience function &lt;code&gt;trainable_variables()&lt;/code&gt; returns the contents of this collection. The various &lt;code&gt;Optimizer&lt;/code&gt; classes use this collection as the default list of variables to optimize.</source>
          <target state="translated">Al crear un modelo de aprendizaje autom&amp;aacute;tico, a menudo es conveniente distinguir entre las variables que contienen los par&amp;aacute;metros del modelo entrenable y otras variables, como una variable de &lt;code&gt;global step&lt;/code&gt; utilizada para contar los pasos de entrenamiento. Para facilitar esto, el constructor de variables admite un par&amp;aacute;metro &lt;code&gt;trainable=&amp;lt;bool&amp;gt;&lt;/code&gt; . Si es &lt;code&gt;True&lt;/code&gt; , la nueva variable tambi&amp;eacute;n se agrega a la colecci&amp;oacute;n de gr&amp;aacute;ficos &lt;code&gt;GraphKeys.TRAINABLE_VARIABLES&lt;/code&gt; . La funci&amp;oacute;n de conveniencia &lt;code&gt;trainable_variables()&lt;/code&gt; devuelve el contenido de esta colecci&amp;oacute;n. Las diversas clases de &lt;code&gt;Optimizer&lt;/code&gt; utilizan esta colecci&amp;oacute;n como la lista predeterminada de variables para optimizar.</target>
        </trans-unit>
        <trans-unit id="68a44f742db33e692724433083d54a9691c316e1" translate="yes" xml:space="preserve">
          <source>When building a machine learning model it is often convenient to distinguish between variables holding trainable model parameters and other variables such as a &lt;code&gt;step&lt;/code&gt; variable used to count training steps. To make this easier, the variable constructor supports a &lt;code&gt;trainable=&amp;lt;bool&amp;gt;&lt;/code&gt; parameter. &lt;a href=&quot;gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt; watches trainable variables by default:</source>
          <target state="translated">Al crear un modelo de aprendizaje autom&amp;aacute;tico, a menudo es conveniente distinguir entre variables que contienen par&amp;aacute;metros de modelo entrenables y otras variables, como una variable de &lt;code&gt;step&lt;/code&gt; utilizada para contar los pasos de entrenamiento. Para facilitar esto, el constructor de variables admite un par&amp;aacute;metro &lt;code&gt;trainable=&amp;lt;bool&amp;gt;&lt;/code&gt; . &lt;a href=&quot;gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; observa las variables entrenables de forma predeterminada:</target>
        </trans-unit>
        <trans-unit id="5eef9f253a5e93ec36275a968646b63d028cda2b" translate="yes" xml:space="preserve">
          <source>When building an eager SparseTensor if &lt;code&gt;dense_shape&lt;/code&gt; is unknown or contains unknown elements (None or -1).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13d3fbe26af35daa9bb0d8a47a6e4b1e39a6da13" translate="yes" xml:space="preserve">
          <source>When building ops to compute gradients, the TensorFlow gradient system will return an error when trying to lookup the gradient of this op, because no gradient must ever be registered for this function. This op exists to prevent subtle bugs from silently returning unimplemented gradients in some corner cases.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11e07c6fbcce2a9ab5d49a2c9fc58743be530d36" translate="yes" xml:space="preserve">
          <source>When building ops to compute gradients, this op prevents the contribution of its inputs to be taken into account. Normally, the gradient generator adds ops to a graph to compute the derivatives of a specified 'loss' by recursively finding out inputs that contributed to its computation. If you insert this op in the graph it inputs are masked from the gradient generator. They are not taken into account for computing gradients.</source>
          <target state="translated">Al construir operaciones para calcular los gradientes,esta operación impide que se tenga en cuenta la contribución de sus aportaciones.Normalmente,el generador de gradientes añade operaciones a un gráfico para calcular las derivadas de una &quot;pérdida&quot; determinada,averiguando recursivamente las entradas que contribuyeron a su cálculo.Si se inserta esta operación en el gráfico,las entradas se enmascaran desde el generador de gradientes.No se tienen en cuenta para calcular los gradientes.</target>
        </trans-unit>
        <trans-unit id="0d35f4de41040fd9e01e658fd5001879a66a9c2d" translate="yes" xml:space="preserve">
          <source>When caching to a file, the cached data will persist across runs. Even the first iteration through the data will read from the cache file. Changing the input pipeline before the call to &lt;code&gt;.cache()&lt;/code&gt; will have no effect until the cache file is removed or the filename is changed.</source>
          <target state="translated">Cuando se almacena en cach&amp;eacute; en un archivo, los datos almacenados en cach&amp;eacute; persistir&amp;aacute;n en las ejecuciones. Incluso la primera iteraci&amp;oacute;n a trav&amp;eacute;s de los datos se leer&amp;aacute; del archivo de cach&amp;eacute;. Cambiar la canalizaci&amp;oacute;n de entrada antes de la llamada a &lt;code&gt;.cache()&lt;/code&gt; no tendr&amp;aacute; ning&amp;uacute;n efecto hasta que se elimine el archivo de cach&amp;eacute; o se cambie el nombre del archivo.</target>
        </trans-unit>
        <trans-unit id="b38df97ed344603f1f1650ff0bfe2600641ba555" translate="yes" xml:space="preserve">
          <source>When calculating the gradient of a weighted loss contributions from both &lt;code&gt;losses&lt;/code&gt; and &lt;code&gt;weights&lt;/code&gt; are considered. If your &lt;code&gt;weights&lt;/code&gt; depend on some model parameters but you do not want this to affect the loss gradient, you need to apply &lt;a href=&quot;../../../stop_gradient&quot;&gt;&lt;code&gt;tf.stop_gradient&lt;/code&gt;&lt;/a&gt; to &lt;code&gt;weights&lt;/code&gt; before passing them to &lt;code&gt;compute_weighted_loss&lt;/code&gt;.</source>
          <target state="translated">Al calcular el gradiente de una p&amp;eacute;rdida ponderada, se consideran las contribuciones tanto de &lt;code&gt;losses&lt;/code&gt; como de &lt;code&gt;weights&lt;/code&gt; . Si sus &lt;code&gt;weights&lt;/code&gt; dependen de algunos par&amp;aacute;metros del modelo pero no desea que esto afecte al gradiente de p&amp;eacute;rdida, debe aplicar &lt;a href=&quot;../../../stop_gradient&quot;&gt; &lt;code&gt;tf.stop_gradient&lt;/code&gt; &lt;/a&gt; a las &lt;code&gt;weights&lt;/code&gt; antes de pasarlas a &lt;code&gt;compute_weighted_loss&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="05f81ef4361feddebda74fb8dc805bcdaf94d0cf" translate="yes" xml:space="preserve">
          <source>When called inside a strategy.run call and input is not directly taken from the args of the &lt;code&gt;strategy.run&lt;/code&gt; call. Also if the size of any sequence in &lt;code&gt;features&lt;/code&gt; does not match corresponding sequence in &lt;code&gt;feature_config&lt;/code&gt;. Similarly for &lt;code&gt;weights&lt;/code&gt;, if not &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebd806d2188a9c9df38773d42df546a4427672df" translate="yes" xml:space="preserve">
          <source>When called inside a strategy.run call and inside XLA control flow.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e31beadd763eb7afc2237f8c90a1ca311bfd077a" translate="yes" xml:space="preserve">
          <source>When called, the default graph is the one that will be launched in the session. The hook can modify the graph by adding new operations to it. After the &lt;code&gt;begin()&lt;/code&gt; call the graph will be finalized and the other callbacks can not modify the graph anymore. Second call of &lt;code&gt;begin()&lt;/code&gt; on the same graph, should not change the graph.</source>
          <target state="translated">Cuando se llama, el gr&amp;aacute;fico predeterminado es el que se lanzar&amp;aacute; en la sesi&amp;oacute;n. El gancho puede modificar el gr&amp;aacute;fico a&amp;ntilde;adi&amp;eacute;ndole nuevas operaciones. Despu&amp;eacute;s de la llamada &lt;code&gt;begin()&lt;/code&gt; el gr&amp;aacute;fico se finalizar&amp;aacute; y las otras devoluciones de llamada ya no podr&amp;aacute;n modificar el gr&amp;aacute;fico. La segunda llamada de &lt;code&gt;begin()&lt;/code&gt; en el mismo gr&amp;aacute;fico, no deber&amp;iacute;a cambiar el gr&amp;aacute;fico.</target>
        </trans-unit>
        <trans-unit id="97ac3a446111c899472a5c5300f96b04aabb3a5c" translate="yes" xml:space="preserve">
          <source>When checkpointing your model, you should include your &lt;a href=&quot;tpuembedding&quot;&gt;&lt;code&gt;tf.tpu.experimental.embedding.TPUEmbedding&lt;/code&gt;&lt;/a&gt; object in the checkpoint. It is a trackable object and saving it will save the embedding tables and their optimizer slot variables:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f92e2d94d9415d9d31e53c6519e2640ef5146f3" translate="yes" xml:space="preserve">
          <source>When combining specs, &lt;code&gt;dev&lt;/code&gt; will take precedence over the current spec. So for instance:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d7e4d9de8d529939e37509a2b98e74b3e5ae079" translate="yes" xml:space="preserve">
          <source>When combining specs, &lt;code&gt;dev&lt;/code&gt; will take precidence over the current spec. So for instance:</source>
          <target state="translated">Cuando la combinaci&amp;oacute;n de especificaciones, &lt;code&gt;dev&lt;/code&gt; tomar&amp;aacute; precidence sobre la especificaci&amp;oacute;n actual. Entonces, por ejemplo:</target>
        </trans-unit>
        <trans-unit id="02d1051ddba9ce90040906dafc1d04ba61223ccf" translate="yes" xml:space="preserve">
          <source>When constructed with a &lt;a href=&quot;../session&quot;&gt;&lt;code&gt;tf.compat.v1.Session&lt;/code&gt;&lt;/a&gt; parameter, a &lt;code&gt;FileWriter&lt;/code&gt; instead forms a compatibility layer over new graph-based summaries (&lt;code&gt;tf.contrib.summary&lt;/code&gt;) to facilitate the use of new summary writing with pre-existing code that expects a &lt;code&gt;FileWriter&lt;/code&gt; instance.</source>
          <target state="translated">Cuando se construye con un par&amp;aacute;metro &lt;a href=&quot;../session&quot;&gt; &lt;code&gt;tf.compat.v1.Session&lt;/code&gt; &lt;/a&gt; , un &lt;code&gt;FileWriter&lt;/code&gt; forma una capa de compatibilidad sobre nuevos res&amp;uacute;menes basados ​​en &lt;code&gt;tf.contrib.summary&lt;/code&gt; ( tf.contrib.summary ) para facilitar el uso de una nueva escritura de res&amp;uacute;menes con c&amp;oacute;digo preexistente que espera un &lt;code&gt;FileWriter&lt;/code&gt; ejemplo.</target>
        </trans-unit>
        <trans-unit id="e77d83f8aae8dd347eba34fe1096849a87e1d28d" translate="yes" xml:space="preserve">
          <source>When constructed with a &lt;a href=&quot;../session&quot;&gt;&lt;code&gt;tf.compat.v1.Session&lt;/code&gt;&lt;/a&gt; parameter, a &lt;code&gt;FileWriter&lt;/code&gt; instead forms a compatibility layer over new graph-based summaries to facilitate the use of new summary writing with pre-existing code that expects a &lt;code&gt;FileWriter&lt;/code&gt; instance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa47f312128ac2a3285768f283bc01e3ade90f81" translate="yes" xml:space="preserve">
          <source>When consuming SavedModels asynchronously (the producer is a separate process), the SavedModel directory will appear before all files have been written, and &lt;a href=&quot;load&quot;&gt;&lt;code&gt;tf.saved_model.load&lt;/code&gt;&lt;/a&gt; will fail if pointed at an incomplete SavedModel. Rather than checking for the directory, check for &quot;saved_model_dir/saved_model.pb&quot;. This file is written atomically as the last &lt;a href=&quot;save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt; file operation.</source>
          <target state="translated">Al consumir SavedModels de forma asincr&amp;oacute;nica (el productor es un proceso separado), el directorio SavedModel aparecer&amp;aacute; antes de que se hayan escrito todos los archivos, y &lt;a href=&quot;load&quot;&gt; &lt;code&gt;tf.saved_model.load&lt;/code&gt; &lt;/a&gt; fallar&amp;aacute; si apunta a un SavedModel incompleto. En lugar de buscar el directorio, busque &quot;Saved_model_dir / Saved_model.pb&quot;. Este archivo se escribe at&amp;oacute;micamente como la &amp;uacute;ltima &lt;a href=&quot;save&quot;&gt; &lt;code&gt;tf.saved_model.save&lt;/code&gt; &lt;/a&gt; archivo tf.saved_model.save .</target>
        </trans-unit>
        <trans-unit id="b17afd826ceac8e996a7c85541a3c3196c1b6382" translate="yes" xml:space="preserve">
          <source>When creating a distributed dataset that is to be passed to the enqueue operation a special input option must be specified:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2db902f77ce37ed9d0c7614f639ced1da648ed42" translate="yes" xml:space="preserve">
          <source>When desired_channels is set, if the input contains fewer channels than this then the last channel will be duplicated to give the requested number, else if the input has more channels than requested then the additional channels will be ignored.</source>
          <target state="translated">Cuando se establece desired_channels,si la entrada contiene menos canales que esto entonces el último canal se duplicará para dar el número solicitado,si la entrada tiene más canales que los solicitados entonces los canales adicionales serán ignorados.</target>
        </trans-unit>
        <trans-unit id="87468be68aa798b87299469214116a53bdacd212" translate="yes" xml:space="preserve">
          <source>When documenting the shape of a RaggedTensor, ragged dimensions can be indicated by enclosing them in parentheses. For example, the shape of a 3-D &lt;code&gt;RaggedTensor&lt;/code&gt; that stores the fixed-size word embedding for each word in a sentence, for each sentence in a batch, could be written as &lt;code&gt;[num_sentences, (num_words), embedding_size]&lt;/code&gt;. The parentheses around &lt;code&gt;(num_words)&lt;/code&gt; indicate that dimension is ragged, and that the length of each element list in that dimension may vary for each item.</source>
          <target state="translated">Al documentar la forma de un RaggedTensor, las dimensiones irregulares se pueden indicar encerr&amp;aacute;ndolas entre par&amp;eacute;ntesis. Por ejemplo, la forma de un &lt;code&gt;RaggedTensor&lt;/code&gt; 3-D que almacena la inserci&amp;oacute;n de palabras de tama&amp;ntilde;o fijo para cada palabra en una oraci&amp;oacute;n, para cada oraci&amp;oacute;n en un lote, podr&amp;iacute;a escribirse como &lt;code&gt;[num_sentences, (num_words), embedding_size]&lt;/code&gt; . Los par&amp;eacute;ntesis alrededor de &lt;code&gt;(num_words)&lt;/code&gt; indican que la dimensi&amp;oacute;n est&amp;aacute; irregular, y que la longitud de cada lista de elementos en esa dimensi&amp;oacute;n puede variar para cada elemento.</target>
        </trans-unit>
        <trans-unit id="933ca78b0f0aab236f7c30d0b7d8200f4284ead1" translate="yes" xml:space="preserve">
          <source>When doing broadcasted operations such as multiplying a tensor by a scalar, broadcasting (usually) confers some time or space benefit, as the broadcasted tensor is never materialized.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bac64cb9d33552a3e872e7c5fb90f9f381853ebe" translate="yes" xml:space="preserve">
          <source>When doing log-odds NCE, the result of this op should be passed through a SparseToDense op, then added to the logits of the sampled candidates. This has the effect of 'removing' the sampled labels that match the true labels by making the classifier sure that they are sampled labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd3848450984baae9593cd8c988bd98ec36231eb" translate="yes" xml:space="preserve">
          <source>When each worker has more than one GPU, operations will be replicated on all GPUs. Even though operations may be replicated, variables are not and each worker shares a common view for which parameter server a variable is assigned to.</source>
          <target state="translated">Cuando cada trabajador tenga más de una GPU,las operaciones se replicarán en todas las GPU.Aunque las operaciones puedan ser replicadas,las variables no lo son y cada trabajador comparte una vista común para qué servidor de parámetros se asigna una variable.</target>
        </trans-unit>
        <trans-unit id="1dfe4b0bd2fe2cdea509ee0800c577901d8b6927" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;gate_gradients&lt;/code&gt;, &lt;code&gt;aggregation_method&lt;/code&gt;, and &lt;code&gt;colocate_gradients_with_ops&lt;/code&gt; are ignored.</source>
          <target state="translated">Cuando la ejecuci&amp;oacute;n &amp;aacute;vida est&amp;aacute; habilitada, &lt;code&gt;gate_gradients&lt;/code&gt; , &lt;code&gt;aggregation_method&lt;/code&gt; y &lt;code&gt;colocate_gradients_with_ops&lt;/code&gt; se ignoran.</target>
        </trans-unit>
        <trans-unit id="148b464485213e809e25fd2427e6df10ddb7913a" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;learning_rate&lt;/code&gt; and &lt;code&gt;momentum&lt;/code&gt; can each be a callable that takes no arguments and returns the actual value to use. This can be useful for changing these values across different invocations of optimizer functions.</source>
          <target state="translated">Cuando se habilita la ejecuci&amp;oacute;n ansiosa, &lt;code&gt;learning_rate&lt;/code&gt; y &lt;code&gt;momentum&lt;/code&gt; pueden ser invocables que no toman argumentos y devuelven el valor real para usar. Esto puede resultar &amp;uacute;til para cambiar estos valores en diferentes invocaciones de funciones optimizadoras.</target>
        </trans-unit>
        <trans-unit id="6f483d1759bf06f09369c7c2c6504ed890b4f074" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;learning_rate&lt;/code&gt; can be a callable that takes no arguments and returns the actual value to use. This can be useful for changing these values across different invocations of optimizer functions.</source>
          <target state="translated">Cuando la ejecuci&amp;oacute;n ansiosa est&amp;aacute; habilitada, &lt;code&gt;learning_rate&lt;/code&gt; puede ser un invocable que no toma argumentos y devuelve el valor real para usar. Esto puede resultar &amp;uacute;til para cambiar estos valores en diferentes invocaciones de funciones optimizadoras.</target>
        </trans-unit>
        <trans-unit id="6eb0adbeafdc09876e4693f8ca8e165f9c0c0985" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;learning_rate&lt;/code&gt;, &lt;code&gt;beta_1&lt;/code&gt;, &lt;code&gt;beta_2&lt;/code&gt;, and &lt;code&gt;epsilon&lt;/code&gt; can each be a callable that takes no arguments and returns the actual value to use. This can be useful for changing these values across different invocations of optimizer functions.</source>
          <target state="translated">Cuando la ejecuci&amp;oacute;n ansiosa est&amp;aacute; habilitada, &lt;code&gt;learning_rate&lt;/code&gt; , &lt;code&gt;beta_1&lt;/code&gt; , &lt;code&gt;beta_2&lt;/code&gt; y &lt;code&gt;epsilon&lt;/code&gt; pueden ser invocables que no toman argumentos y devuelven el valor real para usar. Esto puede resultar &amp;uacute;til para cambiar estos valores en diferentes invocaciones de funciones optimizadoras.</target>
        </trans-unit>
        <trans-unit id="88cf25c3162efb5267e479cbb3ca75d9e84020c2" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;learning_rate&lt;/code&gt;, &lt;code&gt;decay&lt;/code&gt;, &lt;code&gt;momentum&lt;/code&gt;, and &lt;code&gt;epsilon&lt;/code&gt; can each be a callable that takes no arguments and returns the actual value to use. This can be useful for changing these values across different invocations of optimizer functions.</source>
          <target state="translated">Cuando se habilita la ejecuci&amp;oacute;n &amp;aacute;vida, &lt;code&gt;learning_rate&lt;/code&gt; , &lt;code&gt;decay&lt;/code&gt; , &lt;code&gt;momentum&lt;/code&gt; y &lt;code&gt;epsilon&lt;/code&gt; pueden ser invocables que no toman argumentos y devuelven el valor real para usar. Esto puede resultar &amp;uacute;til para cambiar estos valores en diferentes invocaciones de funciones optimizadoras.</target>
        </trans-unit>
        <trans-unit id="a51c69c938604c7d227cd40cf800aac6b43df507" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;learning_rate&lt;/code&gt;, &lt;code&gt;rho&lt;/code&gt;, and &lt;code&gt;epsilon&lt;/code&gt; can each be a callable that takes no arguments and returns the actual value to use. This can be useful for changing these values across different invocations of optimizer functions.</source>
          <target state="translated">Cuando la ejecuci&amp;oacute;n ansiosa est&amp;aacute; habilitada, &lt;code&gt;learning_rate&lt;/code&gt; , &lt;code&gt;rho&lt;/code&gt; y &lt;code&gt;epsilon&lt;/code&gt; pueden ser invocables que no toman argumentos y devuelven el valor real para usar. Esto puede resultar &amp;uacute;til para cambiar estos valores en diferentes invocaciones de funciones optimizadoras.</target>
        </trans-unit>
        <trans-unit id="78865de3a670b7422c397c1e12a0d6935fb3e356" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;loss&lt;/code&gt; should be a Python function that takes no arguments and computes the value to be minimized. Minimization (and gradient computation) is done with respect to the elements of &lt;code&gt;var_list&lt;/code&gt; if not None, else with respect to any trainable variables created during the execution of the &lt;code&gt;loss&lt;/code&gt; function. &lt;code&gt;gate_gradients&lt;/code&gt;, &lt;code&gt;aggregation_method&lt;/code&gt;, &lt;code&gt;colocate_gradients_with_ops&lt;/code&gt; and &lt;code&gt;grad_loss&lt;/code&gt; are ignored when eager execution is enabled.</source>
          <target state="translated">Cuando la ejecuci&amp;oacute;n ansiosa est&amp;aacute; habilitada, la &lt;code&gt;loss&lt;/code&gt; debe ser una funci&amp;oacute;n de Python que no toma argumentos y calcula el valor que se va a minimizar. La minimizaci&amp;oacute;n (y el c&amp;aacute;lculo del gradiente) se realiza con respecto a los elementos de &lt;code&gt;var_list&lt;/code&gt; si no es None, de lo contrario con respecto a cualquier variable entrenable creada durante la ejecuci&amp;oacute;n de la funci&amp;oacute;n de &lt;code&gt;loss&lt;/code&gt; . &lt;code&gt;gate_gradients&lt;/code&gt; , &lt;code&gt;aggregation_method&lt;/code&gt; , &lt;code&gt;colocate_gradients_with_ops&lt;/code&gt; y &lt;code&gt;grad_loss&lt;/code&gt; se ignoran cuando se habilita la ejecuci&amp;oacute;n ansiosos.</target>
        </trans-unit>
        <trans-unit id="a739b33250bbc25214beaa9599eadabdb7bb4665" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;var_list&lt;/code&gt; must specify a &lt;code&gt;list&lt;/code&gt; or &lt;code&gt;dict&lt;/code&gt; of variables to save. Otherwise, a &lt;code&gt;RuntimeError&lt;/code&gt; will be raised.</source>
          <target state="translated">Cuando la ejecuci&amp;oacute;n ansiosa est&amp;aacute; habilitada, &lt;code&gt;var_list&lt;/code&gt; debe especificar una &lt;code&gt;list&lt;/code&gt; a o &lt;code&gt;dict&lt;/code&gt; ado de variables para guardar. De lo contrario, se generar&amp;aacute; un &lt;code&gt;RuntimeError&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="58de3a1f5573eceefbc002055806cdf8a10b2832" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, any callable object in the &lt;code&gt;control_inputs&lt;/code&gt; list will be called.</source>
          <target state="translated">Cuando la ejecuci&amp;oacute;n ansiosa est&amp;aacute; habilitada, se llamar&amp;aacute; a cualquier objeto invocable en la lista &lt;code&gt;control_inputs&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="91a58274042c41959ab2122ef94206a6a2a7792d" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, code inside an init_scope block runs with eager execution enabled even when tracing a &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;. For example:</source>
          <target state="translated">Cuando la ejecuci&amp;oacute;n ansiosa est&amp;aacute; habilitada, el c&amp;oacute;digo dentro de un bloque init_scope se ejecuta con la ejecuci&amp;oacute;n ansiosa habilitada incluso cuando se rastrea una funci&amp;oacute;n &lt;a href=&quot;function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; . Por ejemplo:</target>
        </trans-unit>
        <trans-unit id="7644973d82350f411122d3333c3da0b3f33b32bb" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, executes ops specified by &lt;code&gt;fn&lt;/code&gt; on each replica. Otherwise, builds a graph to execute the ops on each replica.</source>
          <target state="translated">Cuando la ejecuci&amp;oacute;n ansiosa est&amp;aacute; habilitada, ejecuta las operaciones especificadas por &lt;code&gt;fn&lt;/code&gt; en cada r&amp;eacute;plica. De lo contrario, crea un gr&amp;aacute;fico para ejecutar las operaciones en cada r&amp;eacute;plica.</target>
        </trans-unit>
        <trans-unit id="f2c02abca5b8ce6f6c1965307850901a9a73db40" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, learning_rate can be a callable that takes no arguments and returns the actual value to use. This can be useful for changing these values across different invocations of optimizer functions.</source>
          <target state="translated">Cuando la ejecución ansiosa está habilitada,learning_rate puede ser un llamable que no toma argumentos y devuelve el valor real a utilizar.Esto puede ser útil para cambiar estos valores a través de diferentes invocaciones de funciones de optimización.</target>
        </trans-unit>
        <trans-unit id="cfdc83fece145a8a3ec7bfd53296a084c4dce787" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, returns &lt;code&gt;True&lt;/code&gt; in most cases. However, this API might return &lt;code&gt;False&lt;/code&gt; in the following use cases.</source>
          <target state="translated">Cuando la ejecuci&amp;oacute;n ansiosa est&amp;aacute; habilitada, devuelve &lt;code&gt;True&lt;/code&gt; en la mayor&amp;iacute;a de los casos. Sin embargo, esta API puede devolver &lt;code&gt;False&lt;/code&gt; en los siguientes casos de uso.</target>
        </trans-unit>
        <trans-unit id="fca6e6a28c0b1d4d30760e6ed2b604579bf812fc" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, the mixed precision graph rewrite is only enabled within &lt;a href=&quot;../../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, as outside &lt;a href=&quot;../../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, there is no graph.</source>
          <target state="translated">Cuando la ejecuci&amp;oacute;n ansiosa est&amp;aacute; habilitada, la reescritura del gr&amp;aacute;fico de precisi&amp;oacute;n mixta solo se habilita dentro de &lt;a href=&quot;../../../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; , ya que fuera de &lt;a href=&quot;../../../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; , no hay gr&amp;aacute;fico.</target>
        </trans-unit>
        <trans-unit id="cd5cd16ed9249edf9d475e4c4f731cb6a6ee674b" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, the mixed precision graph rewrite is only enabled within &lt;a href=&quot;../../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s, as outside &lt;a href=&quot;../../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s, there is no graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6892adfb044f1fdf15d846e00b609e83b202685" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, the mixed precision graph rewrite is only enabled within &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, as outside &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, there is no graph.</source>
          <target state="translated">Cuando la ejecuci&amp;oacute;n ansiosa est&amp;aacute; habilitada, la reescritura del gr&amp;aacute;fico de precisi&amp;oacute;n mixta solo se habilita dentro de &lt;a href=&quot;../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; , ya que fuera de &lt;a href=&quot;../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; , no hay gr&amp;aacute;fico.</target>
        </trans-unit>
        <trans-unit id="530f59ba986dbe23a70377c034d053b8d4dc39ba" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, the mixed precision graph rewrite is only enabled within &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s, as outside &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s, there is no graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4ced4e377065fa4ed9d5e9a06ab2254081c3e07" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, this function returns a function which in turn returns the decayed learning rate Tensor. This can be useful for changing the learning rate value across different invocations of optimizer functions.</source>
          <target state="translated">Cuando se habilita la ejecución ansiosa,esta función devuelve una función que a su vez devuelve el Tensor de tasa de aprendizaje decaído.Esto puede ser útil para cambiar el valor de la tasa de aprendizaje a través de diferentes invocaciones de las funciones del optimizador.</target>
        </trans-unit>
        <trans-unit id="d2e71dc36f6cf8dc4084a1f274669076eb23a06d" translate="yes" xml:space="preserve">
          <source>When enabled, TensorFlow runtime will collection information that can later be exported and consumed by TensorBoard. The trace is activated across the entire TensorFlow runtime and affects all threads of execution.</source>
          <target state="translated">Cuando se activa,el tiempo de ejecución de TensorFlow recogerá la información que más tarde puede ser exportada y consumida por TensorBoard.La traza se activa a través de todo el tiempo de ejecución de TensorFlow y afecta a todos los hilos de ejecución.</target>
        </trans-unit>
        <trans-unit id="4de00d923ffd1999737d2b1cd351b2302e234977" translate="yes" xml:space="preserve">
          <source>When enabled, the dtype of Keras layers defaults to floatx (which is typically float32) instead of None. In addition, layers will automatically cast floating-point inputs to the layer's dtype.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c296a7d5f98201bab11940527df0b91bbde60a8b" translate="yes" xml:space="preserve">
          <source>When enum_class is empty.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="261d0f228aa5675f9d37b49b2a148dd964803430" translate="yes" xml:space="preserve">
          <source>When enum_class is not a subclass of Enum.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2564a8f9143928f594ea2074e98db1c0c92dbe63" translate="yes" xml:space="preserve">
          <source>When enum_values is empty.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4382685a76810fa4eefafb6b927a319a12869925" translate="yes" xml:space="preserve">
          <source>When exactly one of &lt;code&gt;x&lt;/code&gt; or &lt;code&gt;y&lt;/code&gt; is non-None, or the shapes are not all broadcastable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="947feea8d5b04906f82595b03627acd7039c1568" translate="yes" xml:space="preserve">
          <source>When exactly one of &lt;code&gt;x&lt;/code&gt; or &lt;code&gt;y&lt;/code&gt; is non-None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4e19c79dfb2ba307013a448936b4d81569267d0" translate="yes" xml:space="preserve">
          <source>When executed in a graph, this op outputs its input tensor as-is.</source>
          <target state="translated">Cuando se ejecuta en un gráfico,esta operación produce su tensor de entrada tal cual.</target>
        </trans-unit>
        <trans-unit id="4cecfcec22d59fa24fae039affcbd309fee3e65f" translate="yes" xml:space="preserve">
          <source>When executed, the Tensor &lt;code&gt;a&lt;/code&gt; will have the name &lt;code&gt;MyOp/a&lt;/code&gt;.</source>
          <target state="translated">Cuando se ejecuta, el Tensor &lt;code&gt;a&lt;/code&gt; tendr&amp;aacute; el nombre &lt;code&gt;MyOp/a&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ae9202cb150768cbd21e4a56c23a5fe6d721d720" translate="yes" xml:space="preserve">
          <source>When executed, the Tensors &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt;, &lt;code&gt;c&lt;/code&gt;, will have names &lt;code&gt;MyOp/a&lt;/code&gt;, &lt;code&gt;MyOp/b&lt;/code&gt;, and &lt;code&gt;MyOp/c&lt;/code&gt;.</source>
          <target state="translated">Cuando se ejecutan, los tensores &lt;code&gt;a&lt;/code&gt; , &lt;code&gt;b&lt;/code&gt; , &lt;code&gt;c&lt;/code&gt; , tendr&amp;aacute;n los nombres &lt;code&gt;MyOp/a&lt;/code&gt; , &lt;code&gt;MyOp/b&lt;/code&gt; y &lt;code&gt;MyOp/c&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="fe804bdbbf36ce79d174e2e04fa5a4b653cbe404" translate="yes" xml:space="preserve">
          <source>When executing eagerly, &lt;code&gt;map_fn&lt;/code&gt; does not execute in parallel even if &lt;code&gt;parallel_iterations&lt;/code&gt; is set to a value &amp;gt; 1. You can still get the performance benefits of running a function in parallel by using the &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; decorator:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4b0c36f73c370281ff533b8718b05a1bf7fc23a" translate="yes" xml:space="preserve">
          <source>When executing eagerly, &lt;code&gt;map_fn&lt;/code&gt; does not execute in parallel even if &lt;code&gt;parallel_iterations&lt;/code&gt; is set to a value &amp;gt; 1. You can still get the performance benefits of running a function in parallel by using the &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; decorator:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50bb271b7e16cf32dee4edabc5aa3fa56b53275c" translate="yes" xml:space="preserve">
          <source>When executing eagerly, either assigns values immediately if variables to restore have been created already, or defers restoration until the variables are created. Dependencies added after this call will be matched if they have a corresponding object in the checkpoint (the restore request will queue in any trackable object waiting for the expected dependency to be added).</source>
          <target state="translated">Cuando se ejecuta con entusiasmo,o bien se asignan valores inmediatamente si las variables a restaurar ya han sido creadas,o bien se aplaza la restauración hasta que las variables sean creadas.Las dependencias añadidas después de esta llamada se emparejarán si tienen un objeto correspondiente en el punto de control (la solicitud de restauración se pondrá en cola en cualquier objeto rastreable esperando a que se añada la dependencia esperada).</target>
        </trans-unit>
        <trans-unit id="9f2dc68be8f34aeff876ac6aadeee84459d20f11" translate="yes" xml:space="preserve">
          <source>When executing eagerly, map_fn does not execute in parallel even if &lt;code&gt;parallel_iterations&lt;/code&gt; is set to a value &amp;gt; 1. You can still get the performance benefits of running a function in parallel by using the &lt;code&gt;tf.contrib.eager.defun&lt;/code&gt; decorator,</source>
          <target state="translated">Cuando se ejecuta con avidez, map_fn no se ejecuta en paralelo incluso si &lt;code&gt;parallel_iterations&lt;/code&gt; se establece en un valor&amp;gt; 1. A&amp;uacute;n puede obtener los beneficios de rendimiento de ejecutar una funci&amp;oacute;n en paralelo utilizando el decorador &lt;code&gt;tf.contrib.eager.defun&lt;/code&gt; ,</target>
        </trans-unit>
        <trans-unit id="243113db76fb85d3b379322eb6df8fc099c87214" translate="yes" xml:space="preserve">
          <source>When executing in a &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; or building a model using &lt;a href=&quot;keras/input&quot;&gt;&lt;code&gt;tf.keras.Input&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;tensor#shape&quot;&gt;&lt;code&gt;Tensor.shape&lt;/code&gt;&lt;/a&gt; may return a partial shape (including &lt;code&gt;None&lt;/code&gt; for unknown dimensions). See &lt;a href=&quot;tensorshape&quot;&gt;&lt;code&gt;tf.TensorShape&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ce10899f8aee013da9a14ad538ad1fde8148656" translate="yes" xml:space="preserve">
          <source>When executing in a &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, or building a model using &lt;a href=&quot;keras/input&quot;&gt;&lt;code&gt;tf.keras.Input&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;tensor#set_shape&quot;&gt;&lt;code&gt;Tensor.set_shape&lt;/code&gt;&lt;/a&gt; will &lt;em&gt;merge&lt;/em&gt; the given &lt;code&gt;shape&lt;/code&gt; with the current shape of this tensor, and set the tensor's shape to the merged value (see &lt;a href=&quot;tensorshape#merge_with&quot;&gt;&lt;code&gt;tf.TensorShape.merge_with&lt;/code&gt;&lt;/a&gt; for details):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="961e80919c470474bd25500c2cb03aaf480dc1f1" translate="yes" xml:space="preserve">
          <source>When feeding features into &lt;code&gt;embedding.enqueue&lt;/code&gt; they can be &lt;a href=&quot;../../../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt;s, &lt;a href=&quot;../../../sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.SparseTensor&lt;/code&gt;&lt;/a&gt;s or &lt;a href=&quot;../../../raggedtensor&quot;&gt;&lt;code&gt;tf.RaggedTensor&lt;/code&gt;&lt;/a&gt;s. When the argument &lt;code&gt;max_sequence_length&lt;/code&gt; is 0, the default, you should expect a output of &lt;code&gt;embedding.dequeue&lt;/code&gt; for this feature of shape &lt;code&gt;(batch_size, dim)&lt;/code&gt;. If &lt;code&gt;max_sequence_length&lt;/code&gt; is greater than 0, the feature is embedded as a sequence and padded up to the given length. The shape of the output for this feature will be &lt;code&gt;(batch_size, max_sequence_length, dim)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5aadb062c18b16c150d95636430095568153cdb" translate="yes" xml:space="preserve">
          <source>When giving unsupported dtype and no initializer or when trainable has been set to True with synchronization set as &lt;code&gt;ON_READ&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f8e307109474cb2469b10f7555dc21ae2944eac" translate="yes" xml:space="preserve">
          <source>When graph building, &lt;code&gt;assert_consumed()&lt;/code&gt; indicates that all of the restore ops that will be created for this checkpoint have been created. They can be run via the &lt;code&gt;run_restore_ops()&lt;/code&gt; method of the status object:</source>
          <target state="translated">Cuando se &lt;code&gt;assert_consumed()&lt;/code&gt; gr&amp;aacute;fico, assert_consumed () indica que se han creado todas las operaciones de restauraci&amp;oacute;n que se crear&amp;aacute;n para este punto de control. Pueden ejecutarse mediante el m&amp;eacute;todo &lt;code&gt;run_restore_ops()&lt;/code&gt; del objeto de estado:</target>
        </trans-unit>
        <trans-unit id="79f071b74a52cc1dc25696f12242191a62439461" translate="yes" xml:space="preserve">
          <source>When graph building, restoration ops are added to the graph but not run immediately.</source>
          <target state="translated">Cuando se construye un gráfico,las operaciones de restauración se añaden al gráfico pero no se ejecutan inmediatamente.</target>
        </trans-unit>
        <trans-unit id="50bb22b935fa898c607810aea861b6f9cab61dc5" translate="yes" xml:space="preserve">
          <source>When in TF V1 mode (that is, outside &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;) Assert needs a control dependency on the output to ensure the assertion executes:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c8e82ac3193c4ec5ccc1a2ed347b087c3eee96b" translate="yes" xml:space="preserve">
          <source>When indexing keyword argument is not one of &lt;code&gt;xy&lt;/code&gt; or &lt;code&gt;ij&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45d6ec71b2e803e49adc786399511f890dec3b98" translate="yes" xml:space="preserve">
          <source>When indices are not consistent.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3400d0e372dbb4d788999038a1fa59202da9146e" translate="yes" xml:space="preserve">
          <source>When indices is a 1D tensor, this operation is equivalent to &lt;a href=&quot;scatter_update&quot;&gt;&lt;code&gt;tf.compat.v1.scatter_update&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Cuando los &amp;iacute;ndices son un tensor 1D, esta operaci&amp;oacute;n es equivalente a &lt;a href=&quot;scatter_update&quot;&gt; &lt;code&gt;tf.compat.v1.scatter_update&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="d2e52528636ed4172136496c48a5c9c765f21cc1" translate="yes" xml:space="preserve">
          <source>When initializing a deep network, it is in principle advantageous to keep the scale of the input variance constant, so it does not explode or diminish by reaching the final layer. If the input is &lt;code&gt;x&lt;/code&gt; and the operation &lt;code&gt;x * W&lt;/code&gt;, and we want to initialize &lt;code&gt;W&lt;/code&gt; uniformly at random, we need to pick &lt;code&gt;W&lt;/code&gt; from</source>
          <target state="translated">Al inicializar una red profunda, en principio es ventajoso mantener constante la escala de la varianza de entrada, para que no explote ni disminuya al llegar a la capa final. Si la entrada es &lt;code&gt;x&lt;/code&gt; y la operaci&amp;oacute;n &lt;code&gt;x * W&lt;/code&gt; , y queremos inicializar &lt;code&gt;W&lt;/code&gt; uniformemente al azar, debemos elegir &lt;code&gt;W&lt;/code&gt; de</target>
        </trans-unit>
        <trans-unit id="12f77eb406d2a652e408c888d240e8eb2d9cb755" translate="yes" xml:space="preserve">
          <source>When invoking a signature in an exported SavedModel, &lt;code&gt;Tensor&lt;/code&gt; arguments are identified by name. These names will come from the Python function's argument names by default. They may be overridden by specifying a &lt;code&gt;name=...&lt;/code&gt; argument in the corresponding &lt;a href=&quot;../tensorspec&quot;&gt;&lt;code&gt;tf.TensorSpec&lt;/code&gt;&lt;/a&gt; object. Explicit naming is required if multiple &lt;code&gt;Tensor&lt;/code&gt;s are passed through a single argument to the Python function.</source>
          <target state="translated">Cuando se invoca una firma en un modelo guardado exportado, los argumentos de &lt;code&gt;Tensor&lt;/code&gt; se identifican por nombre. Estos nombres provendr&amp;aacute;n de los nombres de los argumentos de la funci&amp;oacute;n Python por defecto. Pueden anularse especificando un argumento &lt;code&gt;name=...&lt;/code&gt; en el objeto &lt;a href=&quot;../tensorspec&quot;&gt; &lt;code&gt;tf.TensorSpec&lt;/code&gt; &lt;/a&gt; correspondiente . Se requiere un nombre expl&amp;iacute;cito si se pasan varios &lt;code&gt;Tensor&lt;/code&gt; a trav&amp;eacute;s de un solo argumento a la funci&amp;oacute;n de Python.</target>
        </trans-unit>
        <trans-unit id="aaecdf3e3e9d1409f6d5971a54eef9da389f9db7" translate="yes" xml:space="preserve">
          <source>When loading a weight file in TensorFlow format, returns the same status object as &lt;a href=&quot;../../train/checkpoint#restore&quot;&gt;&lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt;&lt;/a&gt;. When graph building, restore ops are run automatically as soon as the network is built (on first call for user-defined classes inheriting from &lt;code&gt;Model&lt;/code&gt;, immediately if it is already built).</source>
          <target state="translated">Al cargar un archivo de peso en formato TensorFlow, devuelve el mismo objeto de estado que &lt;a href=&quot;../../train/checkpoint#restore&quot;&gt; &lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt; &lt;/a&gt; . Cuando se crea un gr&amp;aacute;fico, las operaciones de restauraci&amp;oacute;n se ejecutan autom&amp;aacute;ticamente tan pronto como se construye la red (en la primera llamada para las clases definidas por el usuario que heredan del &lt;code&gt;Model&lt;/code&gt; o , inmediatamente si ya est&amp;aacute; construido).</target>
        </trans-unit>
        <trans-unit id="ad0500aa71cc2e13561fbb9f3ccb38e89738eb04" translate="yes" xml:space="preserve">
          <source>When loading a weight file in TensorFlow format, returns the same status object as &lt;a href=&quot;../train/checkpoint#restore&quot;&gt;&lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt;&lt;/a&gt;. When graph building, restore ops are run automatically as soon as the network is built (on first call for user-defined classes inheriting from &lt;code&gt;Model&lt;/code&gt;, immediately if it is already built).</source>
          <target state="translated">Al cargar un archivo de peso en formato TensorFlow, devuelve el mismo objeto de estado que &lt;a href=&quot;../train/checkpoint#restore&quot;&gt; &lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt; &lt;/a&gt; . Cuando se crea un gr&amp;aacute;fico, las operaciones de restauraci&amp;oacute;n se ejecutan autom&amp;aacute;ticamente tan pronto como se construye la red (en la primera llamada para las clases definidas por el usuario que heredan del &lt;code&gt;Model&lt;/code&gt; o , inmediatamente si ya est&amp;aacute; construido).</target>
        </trans-unit>
        <trans-unit id="a3a6d69d15b5f2b1e2641796ab481024196abbd1" translate="yes" xml:space="preserve">
          <source>When loading weights in HDF5 format, returns &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">Al cargar pesos en formato HDF5, devuelve &lt;code&gt;None&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="279df71b03d4f1d2b500da71eaeb34af2e345a5e" translate="yes" xml:space="preserve">
          <source>When many instances of this Op are being run concurrently with the same container/shared_name in the same device, some will output zero-shaped Tensors and others will output Tensors of size up to max_batch_size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="caebbca103b05daa9db25a1f91ee52187b92666d" translate="yes" xml:space="preserve">
          <source>When mixed precision training is used, most layers will instead have a float16 or bfloat16 compute dtype and a float32 variable dtype, and so the layer does not have a single dtype. See &lt;a href=&quot;https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html&quot;&gt;this link&lt;/a&gt; for more information on mixed precision training. When the variable dtype does not match the compute dtype, variables will be automatically casted to the compute dtype to avoid type errors. In this case, &lt;a href=&quot;../../layers/layer#dtype&quot;&gt;&lt;code&gt;tf.keras.layers.Layer.dtype&lt;/code&gt;&lt;/a&gt; refers to the variable dtype, not the compute dtype.</source>
          <target state="translated">Cuando se utiliza el entrenamiento de precisi&amp;oacute;n mixto, la mayor&amp;iacute;a de las capas tendr&amp;aacute;n en su lugar un tipo de c&amp;aacute;lculo float16 o bfloat16 y un tipo de variable float32, por lo que la capa no tiene un solo tipo de d. Consulte &lt;a href=&quot;https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html&quot;&gt;este enlace&lt;/a&gt; para obtener m&amp;aacute;s informaci&amp;oacute;n sobre el entrenamiento de precisi&amp;oacute;n mixto. Cuando la variable dtype no coincide con compute dtype, las variables se convertir&amp;aacute;n autom&amp;aacute;ticamente en compute dtype para evitar errores de tipo. En este caso, &lt;a href=&quot;../../layers/layer#dtype&quot;&gt; &lt;code&gt;tf.keras.layers.Layer.dtype&lt;/code&gt; se&lt;/a&gt; refiere a la variable dtype, no al compute dtype.</target>
        </trans-unit>
        <trans-unit id="31e5d2d74d34d722ae24b0d3557c28c55ecaa6d6" translate="yes" xml:space="preserve">
          <source>When mixed precision training is used, most layers will instead have a float16 or bfloat16 compute dtype and a float32 variable dtype, and so the layer does not have a single dtype. When the variable dtype does not match the compute dtype, variables will be automatically casted to the compute dtype to avoid type errors. In this case, &lt;a href=&quot;../../layers/layer#dtype&quot;&gt;&lt;code&gt;tf.keras.layers.Layer.dtype&lt;/code&gt;&lt;/a&gt; refers to the variable dtype, not the compute dtype. See &lt;a href=&quot;https://www.tensorflow.org/guide/keras/mixed_precision&quot;&gt;the mixed precision guide&lt;/a&gt; for more information on how to use mixed precision.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12dfe9c646058fc3b646723517e40b30a435cf72" translate="yes" xml:space="preserve">
          <source>When mode is not one of &quot;CONSTANT&quot;, &quot;REFLECT&quot;, or &quot;SYMMETRIC&quot;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e594a784be178d46ade99237614f3d81b376cb0c" translate="yes" xml:space="preserve">
          <source>When multiple identical random ops are wrapped in a &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, their behaviors change because the ops no long share the same counter. For example:</source>
          <target state="translated">Cuando m&amp;uacute;ltiples operaciones aleatorias id&amp;eacute;nticas est&amp;aacute;n envueltas en una funci&amp;oacute;n &lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; , Sus comportamientos cambian porque las operaciones ya no comparten el mismo contador. Por ejemplo:</target>
        </trans-unit>
        <trans-unit id="2fdc190461b8260acb4e4a0e40690fe99685019d" translate="yes" xml:space="preserve">
          <source>When multiple steps of profiles are available, select which step's profile to use. If -1, use average of all available steps.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbe07c906de9609ba47c0d5dc628f10d68cc6dd7" translate="yes" xml:space="preserve">
          <source>When no keyword arguments (kwargs) are passed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b5b5298719274d2e99620e5ca7a91daabe32b28" translate="yes" xml:space="preserve">
          <source>When not &lt;code&gt;None&lt;/code&gt;, the probability we will drop out a given coordinate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f319b17be698e68a66d41691883dcc29fc7f9c6" translate="yes" xml:space="preserve">
          <source>When not None, the probability we will drop out a given coordinate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f589095e3d5fab094abecc7eb9696d68f8a9c36d" translate="yes" xml:space="preserve">
          <source>When operating in a v1-style graph context, ops are not executed in the same order as specified in the code; TensorFlow will attempt to execute ops in parallel or in an order convienient to the result it is computing. &lt;a href=&quot;group&quot;&gt;&lt;code&gt;tf.group&lt;/code&gt;&lt;/a&gt; allows you to request that one or more results finish before execution continues.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3fc5b0a3b9961cb77e88c8942ce57281e9ad832" translate="yes" xml:space="preserve">
          <source>When passed &lt;code&gt;trainable=True&lt;/code&gt;, the &lt;code&gt;Variable()&lt;/code&gt; constructor automatically adds new variables to the graph collection &lt;code&gt;GraphKeys.TRAINABLE_VARIABLES&lt;/code&gt;. This convenience function returns the contents of that collection.</source>
          <target state="translated">Cuando se pasa &lt;code&gt;trainable=True&lt;/code&gt; , el constructor &lt;code&gt;Variable()&lt;/code&gt; agrega autom&amp;aacute;ticamente nuevas variables a la colecci&amp;oacute;n de gr&amp;aacute;ficos &lt;code&gt;GraphKeys.TRAINABLE_VARIABLES&lt;/code&gt; . Esta funci&amp;oacute;n de conveniencia devuelve el contenido de esa colecci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="5b6a28f5fad1b02dbaf2abf3b2bcae0d38a29c7b" translate="yes" xml:space="preserve">
          <source>When reading a single input file, you can shard elements as follows:</source>
          <target state="translated">Al leer un solo archivo de entrada,se pueden fragmentar los elementos de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="5d6c412525d35ed49e0a016246bbab95a1ad4343" translate="yes" xml:space="preserve">
          <source>When run, it returns a 1-D tensor containing the names of uninitialized variables if there are any, or an empty array if there are none.</source>
          <target state="translated">Cuando se ejecuta,devuelve un tensor 1-D que contiene los nombres de las variables no inicializadas si las hay,o un array vacío si no las hay.</target>
        </trans-unit>
        <trans-unit id="4cd96e8d064773862a00f08fa46097675a613f49" translate="yes" xml:space="preserve">
          <source>When run, reports an &lt;code&gt;InvalidArgument&lt;/code&gt; error if &lt;code&gt;tensor&lt;/code&gt; has any values that are not a number (NaN) or infinity (Inf). Otherwise, passes &lt;code&gt;tensor&lt;/code&gt; as-is.</source>
          <target state="translated">Cuando se ejecuta, informa un error de &lt;code&gt;InvalidArgument&lt;/code&gt; si el &lt;code&gt;tensor&lt;/code&gt; tiene valores que no son un n&amp;uacute;mero (NaN) o infinito (Inf). De lo contrario, pasa el &lt;code&gt;tensor&lt;/code&gt; como est&amp;aacute;.</target>
        </trans-unit>
        <trans-unit id="9a7fb4ad12e1e9b24a4a905d1465aa8fe6223f81" translate="yes" xml:space="preserve">
          <source>When run, reports an &lt;code&gt;InvalidArgument&lt;/code&gt; error if &lt;code&gt;tensor&lt;/code&gt; has any values that are not a number (NaN) or infinity (Inf). Otherwise, passes &lt;code&gt;tensor&lt;/code&gt; as-is. Unlike CheckNumerics (V1), CheckNumericsV2 distinguishes -Inf and +Inf in the errors it throws.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a08b94134a846722329d59d0e06daaabf9e81c0e" translate="yes" xml:space="preserve">
          <source>When run, the returned Op will raise the exception &lt;code&gt;FailedPreconditionError&lt;/code&gt; if any of the variables has not yet been initialized.</source>
          <target state="translated">Cuando se ejecuta, el Op devuelto generar&amp;aacute; la excepci&amp;oacute;n &lt;code&gt;FailedPreconditionError&lt;/code&gt; si alguna de las variables a&amp;uacute;n no se ha inicializado.</target>
        </trans-unit>
        <trans-unit id="612235a5e3b2319598b46d42d78d5e3939c685ba" translate="yes" xml:space="preserve">
          <source>When running in graph mode, you must evaluate the tensor returned by &lt;code&gt;tf.tables_initializer()&lt;/code&gt; before evaluating the tensor returned by this class's &lt;code&gt;lookup()&lt;/code&gt; method. Example usage in graph mode:</source>
          <target state="translated">Cuando se ejecuta en modo gr&amp;aacute;fico, debe evaluar el tensor devuelto por &lt;code&gt;tf.tables_initializer()&lt;/code&gt; antes de evaluar el tensor devuelto por el m&amp;eacute;todo &lt;code&gt;lookup()&lt;/code&gt; esta clase . Ejemplo de uso en modo gr&amp;aacute;fico:</target>
        </trans-unit>
        <trans-unit id="7eea4af19c3fd0977360ee69dfc63bed5794fb89" translate="yes" xml:space="preserve">
          <source>When running in graph mode, you should add a dependency on this operation to ensure that it runs. Example of adding a dependency to an operation:</source>
          <target state="translated">Cuando se ejecuta en modo gráfico,debe agregar una dependencia de esta operación para asegurar que se ejecute.Ejemplo de agregar una dependencia a una operación:</target>
        </trans-unit>
        <trans-unit id="83f395cc48e2b9d73bdec46f8abf442be27de226" translate="yes" xml:space="preserve">
          <source>When saving in HDF5 format, the weight file has:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23b4a5289feb34fa15683e70f83d2559b44972e8" translate="yes" xml:space="preserve">
          <source>When saving in HDF5 format, the weight file has: - &lt;code&gt;layer_names&lt;/code&gt; (attribute), a list of strings (ordered names of model layers). - For every layer, a &lt;code&gt;group&lt;/code&gt; named &lt;code&gt;layer.name&lt;/code&gt; - For every such layer group, a group attribute &lt;code&gt;weight_names&lt;/code&gt;, a list of strings (ordered names of weights tensor of the layer). - For every weight in the layer, a dataset storing the weight value, named after the weight tensor.</source>
          <target state="translated">Al guardar en formato HDF5, el archivo de peso tiene: - &lt;code&gt;layer_names&lt;/code&gt; (atributo), una lista de cadenas (nombres ordenados de las capas del modelo). - Para cada capa, un &lt;code&gt;group&lt;/code&gt; llamado &lt;code&gt;layer.name&lt;/code&gt; - Para cada grupo de capas, un atributo de grupo &lt;code&gt;weight_names&lt;/code&gt; , una lista de cadenas (nombres ordenados del tensor de pesos de la capa). - Para cada peso en la capa, un conjunto de datos que almacena el valor del peso, llamado as&amp;iacute; por el tensor de peso.</target>
        </trans-unit>
        <trans-unit id="c275f46f84d94fb1e86dc221ba0e2772a4b65944" translate="yes" xml:space="preserve">
          <source>When saving in TensorFlow format, all objects referenced by the network are saved in the same format as &lt;a href=&quot;../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt;, including any &lt;code&gt;Layer&lt;/code&gt; instances or &lt;code&gt;Optimizer&lt;/code&gt; instances assigned to object attributes. For networks constructed from inputs and outputs using &lt;code&gt;tf.keras.Model(inputs, outputs)&lt;/code&gt;, &lt;code&gt;Layer&lt;/code&gt; instances used by the network are tracked/saved automatically. For user-defined classes which inherit from &lt;a href=&quot;../model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;Layer&lt;/code&gt; instances must be assigned to object attributes, typically in the constructor. See the documentation of &lt;a href=&quot;../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">Al guardar en formato TensorFlow, todos los objetos a los que hace referencia la red se guardan en el mismo formato que &lt;a href=&quot;../../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; , incluidas las instancias de &lt;code&gt;Layer&lt;/code&gt; o las instancias de &lt;code&gt;Optimizer&lt;/code&gt; asignadas a los atributos del objeto. Para las redes construidas a partir de entradas y salidas que utilizan &lt;code&gt;tf.keras.Model(inputs, outputs)&lt;/code&gt; , &lt;code&gt;Layer&lt;/code&gt; instancias de capa utilizadas por la red se rastrean / guardan autom&amp;aacute;ticamente. Para las clases definidas por el usuario que heredan de &lt;a href=&quot;../model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; &lt;/a&gt; , &lt;code&gt;Layer&lt;/code&gt; instancias de capa deben asignarse a atributos de objeto, normalmente en el constructor. Consulte la documentaci&amp;oacute;n de &lt;a href=&quot;../../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;../model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; &lt;/a&gt; para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="58ff97a8bb50647c4ab49957faee2741efb3b467" translate="yes" xml:space="preserve">
          <source>When saving in TensorFlow format, all objects referenced by the network are saved in the same format as &lt;a href=&quot;../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt;, including any &lt;code&gt;Layer&lt;/code&gt; instances or &lt;code&gt;Optimizer&lt;/code&gt; instances assigned to object attributes. For networks constructed from inputs and outputs using &lt;code&gt;tf.keras.Model(inputs, outputs)&lt;/code&gt;, &lt;code&gt;Layer&lt;/code&gt; instances used by the network are tracked/saved automatically. For user-defined classes which inherit from &lt;a href=&quot;model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;Layer&lt;/code&gt; instances must be assigned to object attributes, typically in the constructor. See the documentation of &lt;a href=&quot;../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">Al guardar en formato TensorFlow, todos los objetos a los que hace referencia la red se guardan en el mismo formato que &lt;a href=&quot;../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; , incluidas las instancias de &lt;code&gt;Layer&lt;/code&gt; o las instancias de &lt;code&gt;Optimizer&lt;/code&gt; asignadas a los atributos del objeto. Para las redes construidas a partir de entradas y salidas que utilizan &lt;code&gt;tf.keras.Model(inputs, outputs)&lt;/code&gt; , &lt;code&gt;Layer&lt;/code&gt; instancias de capa utilizadas por la red se rastrean / guardan autom&amp;aacute;ticamente. Para las clases definidas por el usuario que heredan de &lt;a href=&quot;model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; &lt;/a&gt; , &lt;code&gt;Layer&lt;/code&gt; instancias de capa deben asignarse a atributos de objeto, normalmente en el constructor. Consulte la documentaci&amp;oacute;n de &lt;a href=&quot;../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; &lt;/a&gt; para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="784c3ca10c1f2c8309f633399d4061eef62d41bd" translate="yes" xml:space="preserve">
          <source>When shape_x and shape_y are Tensors representing shapes (i.e. the result of calling tf.shape on another Tensor) this computes a Tensor which is the shape of the result of a broadcasting op applied in tensors of shapes shape_x and shape_y.</source>
          <target state="translated">Cuando shape_x y shape_y son Tensores que representan formas (es decir,el resultado de llamar tf.shape en otro Tensor)esto calcula un Tensor que es la forma del resultado de una operación de radiodifusión aplicada en tensores de formas shape_x y shape_y.</target>
        </trans-unit>
        <trans-unit id="382f3819ea47b409f9da2d9eacd00a3f2dc7a1b2" translate="yes" xml:space="preserve">
          <source>When shape_x and shape_y are fully known TensorShapes this computes a TensorShape which is the shape of the result of a broadcasting op applied in tensors of shapes shape_x and shape_y.</source>
          <target state="translated">Cuando shape_x y shape_y son TensorShapes completamente conocidos,esto calcula un TensorShape que es la forma del resultado de una operación de difusión aplicada en tensores de formas shape_x y shape_y.</target>
        </trans-unit>
        <trans-unit id="b25a4e208695ca5ecbc4dac0901769cfec692d0d" translate="yes" xml:space="preserve">
          <source>When sparse_delta.indices is a 1D tensor, this operation is equivalent to &lt;code&gt;scatter_update&lt;/code&gt;.</source>
          <target state="translated">Cuando sparse_delta.indices es un tensor 1D, esta operaci&amp;oacute;n es equivalente a &lt;code&gt;scatter_update&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d43e498906b2adf0ec7959c38a4a8cf0f9fa7d0b" translate="yes" xml:space="preserve">
          <source>When starting a dedicated tf.data dispatch process, use join() to block indefinitely after starting up the server.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="934351906a686e71e8e5a944d6c4af715197c11e" translate="yes" xml:space="preserve">
          <source>When starting a dedicated tf.data worker process, use join() to block indefinitely after starting up the server.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fee3dffe2d54b65ce0a85843a0d39fb34dec340" translate="yes" xml:space="preserve">
          <source>When that Op is run it tries to increment the variable by &lt;code&gt;1&lt;/code&gt;. If incrementing the variable would bring it above &lt;code&gt;limit&lt;/code&gt; then the Op raises the exception &lt;code&gt;OutOfRangeError&lt;/code&gt;.</source>
          <target state="translated">Cuando se ejecuta esa operaci&amp;oacute;n, intenta incrementar la variable en &lt;code&gt;1&lt;/code&gt; . Si el incremento de la variable la llevar&amp;iacute;a por encima del &lt;code&gt;limit&lt;/code&gt; , el Op genera la excepci&amp;oacute;n &lt;code&gt;OutOfRangeError&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a324d7f1e796820d05403b217fea01aa17af935a" translate="yes" xml:space="preserve">
          <source>When the &lt;code&gt;GraphDef&lt;/code&gt; is larger than 2GB.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1856bfeda6ff30a3afd3efdbb33b44e8e2b972ce" translate="yes" xml:space="preserve">
          <source>When the &lt;code&gt;LinearOperator&lt;/code&gt; is not hinted to be &lt;code&gt;non_singular&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56cd8af2612b32012d09c54f7e15310ad702ad5c" translate="yes" xml:space="preserve">
          <source>When the &lt;code&gt;LinearOperator&lt;/code&gt; is not hinted to be positive definite and self adjoint.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ae5f82f4e0944c8fdd12da34fb5e45708d0e8f6" translate="yes" xml:space="preserve">
          <source>When the CrossShardOptimizer is constructed with &lt;code&gt;reduction == losses.Reduction.MEAN&lt;/code&gt; (default), this function scales the loss by &lt;code&gt;1.0 / num_shards&lt;/code&gt; before computing the gradients. Assuming the optimizer uses the default implementation of &lt;code&gt;compute_gradients()&lt;/code&gt;, the gradients of the scaled loss are scaled by &lt;code&gt;1.0 / num_shards&lt;/code&gt; compared to the gradients of the original loss. This scaling factor is important because &lt;code&gt;apply_gradients()&lt;/code&gt; sums gradients across shards, rather than averaging them. However, the scaling factor must be taken into account when clipping the norm of the gradients or performing other postprocessing.</source>
          <target state="translated">Cuando el CrossShardOptimizer se construye con &lt;code&gt;reduction == losses.Reduction.MEAN&lt;/code&gt; (predeterminado), esta funci&amp;oacute;n escala la p&amp;eacute;rdida en &lt;code&gt;1.0 / num_shards&lt;/code&gt; antes de calcular los gradientes. Suponiendo que el optimizador usa la implementaci&amp;oacute;n predeterminada de &lt;code&gt;compute_gradients()&lt;/code&gt; , los gradientes de la p&amp;eacute;rdida escalada se escalan en &lt;code&gt;1.0 / num_shards&lt;/code&gt; comparaci&amp;oacute;n con los gradientes de la p&amp;eacute;rdida original. Este factor de escala es importante porque &lt;code&gt;apply_gradients()&lt;/code&gt; suma los gradientes en los fragmentos, en lugar de promediarlos. Sin embargo, el factor de escala debe tenerse en cuenta al recortar la norma de los gradientes o realizar otro posprocesamiento.</target>
        </trans-unit>
        <trans-unit id="62b085231fa47179e1be16442d315153db83ffe4" translate="yes" xml:space="preserve">
          <source>When the Op is run, it reports an &lt;code&gt;InvalidArgument&lt;/code&gt; error if multiple values in the summaries to merge use the same tag.</source>
          <target state="translated">Cuando se ejecuta Op, informa un error de &lt;code&gt;InvalidArgument&lt;/code&gt; si varios valores en los res&amp;uacute;menes para fusionar utilizan la misma etiqueta.</target>
        </trans-unit>
        <trans-unit id="a17f60db047668212c07e424cf0f21e2e8e6e67e" translate="yes" xml:space="preserve">
          <source>When the RNN layer is not stateful.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8b5dd0fb66417bcf00267bf905ed39a50b9ed42" translate="yes" xml:space="preserve">
          <source>When the batch size of the RNN layer is unknown.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04c6456a46e3c6718694244e79e5c206d69bdf28" translate="yes" xml:space="preserve">
          <source>When the file to be loaded is not found.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c426d27facbfbf4fa665efb6cfbd82b969658b0" translate="yes" xml:space="preserve">
          <source>When the input numpy array is not compatible with the RNN layer state, either size wise or dtype wise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3584f2f08e6dde164e436c25cc19bcd86167e861" translate="yes" xml:space="preserve">
          <source>When the timeout argument is not present or None, the operation will block until the thread terminates.</source>
          <target state="translated">Cuando el argumento del tiempo de espera no está presente o ninguno,la operación se bloqueará hasta que el hilo termine.</target>
        </trans-unit>
        <trans-unit id="93008cafbefd82e0878a6b1b3873678eb838ef6d" translate="yes" xml:space="preserve">
          <source>When the timeout argument is present and not None, it should be a floating point number specifying a timeout for the operation in seconds (or fractions thereof). As join() always returns None, you must call isAlive() after join() to decide whether a timeout happened -- if the thread is still alive, the join() call timed out.</source>
          <target state="translated">Cuando el argumento del tiempo de espera está presente y no es ninguno,debe ser un número de punto flotante que especifique un tiempo de espera para la operación en segundos (o fracciones de ellos).Como join()siempre devuelve None,debes llamar a isAlive()después de join()para decidir si se ha producido un timeout --si el hilo sigue vivo,la llamada a join()se ha agotado.</target>
        </trans-unit>
        <trans-unit id="df9a68fd13d29e9ba4462924730a99e7d6cbe88d" translate="yes" xml:space="preserve">
          <source>When the timeout argument is present and not None, it should be a floating point number specifying a timeout for the operation in seconds (or fractions thereof). As join() always returns None, you must call is_alive() after join() to decide whether a timeout happened -- if the thread is still alive, the join() call timed out.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df29949db6d12bcc6440a4ff55b2a3b63f98638c" translate="yes" xml:space="preserve">
          <source>When the underlying interpreter fails raise ValueError.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79079716d44440c95fa5813292d42c940b3c76a3" translate="yes" xml:space="preserve">
          <source>When this function is used, gradients should be computed and applied with the returned optimizer, either by calling &lt;code&gt;opt.minimize()&lt;/code&gt; or &lt;code&gt;opt.compute_gradients()&lt;/code&gt; followed by &lt;code&gt;opt.apply_gradients()&lt;/code&gt;. If gradients are instead computed with &lt;a href=&quot;../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;, loss scaling will not be applied, which will likely cause your model not to converge due to float16 underflow problems. To apply lossing scaling with &lt;a href=&quot;../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../keras/mixed_precision/experimental/lossscaleoptimizer#get_scaled_loss&quot;&gt;&lt;code&gt;LossScaleOptimizer.get_scaled_loss&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../keras/mixed_precision/experimental/lossscaleoptimizer#get_unscaled_gradients&quot;&gt;&lt;code&gt;LossScaleOptimizer.get_unscaled_gradients&lt;/code&gt;&lt;/a&gt;. See &lt;a href=&quot;../../keras/mixed_precision/experimental/lossscaleoptimizer&quot;&gt;&lt;code&gt;keras.mixed_precision.experimental.LossScaleOptimizer&lt;/code&gt;&lt;/a&gt; for details how to do this.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5afcb3cf29a4af014bb340f2f0c516a9732b6d10" translate="yes" xml:space="preserve">
          <source>When this function is used, gradients should only be computed and applied with the returned optimizer, either by calling &lt;code&gt;opt.minimize()&lt;/code&gt; or &lt;code&gt;opt.compute_gradients()&lt;/code&gt; followed by &lt;code&gt;opt.apply_gradients()&lt;/code&gt;. Gradients should not be computed with &lt;a href=&quot;../../../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;. This is because the returned optimizer will apply loss scaling, and &lt;a href=&quot;../../../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt; will not. If you do directly use &lt;a href=&quot;../../../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;, your model may not converge due to float16 underflow problems.</source>
          <target state="translated">Cuando se usa esta funci&amp;oacute;n, los gradientes solo deben calcularse y aplicarse con el optimizador devuelto, ya sea llamando a &lt;code&gt;opt.minimize()&lt;/code&gt; u &lt;code&gt;opt.compute_gradients()&lt;/code&gt; seguido de &lt;code&gt;opt.apply_gradients()&lt;/code&gt; . Los &lt;a href=&quot;../../../../gradients&quot;&gt; &lt;code&gt;tf.gradients&lt;/code&gt; &lt;/a&gt; no deben calcularse con tf.gradients o &lt;a href=&quot;../../../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; . Esto se debe a que el optimizador devuelto aplicar&amp;aacute; la escala de p&amp;eacute;rdida, y &lt;a href=&quot;../../../../gradients&quot;&gt; &lt;code&gt;tf.gradients&lt;/code&gt; &lt;/a&gt; o &lt;a href=&quot;../../../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; no lo har&amp;aacute;. Si usa directamente &lt;a href=&quot;../../../../gradients&quot;&gt; &lt;code&gt;tf.gradients&lt;/code&gt; &lt;/a&gt; o &lt;a href=&quot;../../../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; , es posible que su modelo no converja debido a problemas de subdesbordamiento de float16.</target>
        </trans-unit>
        <trans-unit id="caac8e6b5e9c55ec72ae9a078f806e80238a5f0b" translate="yes" xml:space="preserve">
          <source>When this function is used, gradients should only be computed and applied with the returned optimizer, either by calling &lt;code&gt;opt.minimize()&lt;/code&gt; or &lt;code&gt;opt.compute_gradients()&lt;/code&gt; followed by &lt;code&gt;opt.apply_gradients()&lt;/code&gt;. Gradients should not be computed with &lt;a href=&quot;../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;. This is because the returned optimizer will apply loss scaling, and &lt;a href=&quot;../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt; will not. If you do directly use &lt;a href=&quot;../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;, your model may not converge due to float16 underflow problems.</source>
          <target state="translated">Cuando se usa esta funci&amp;oacute;n, los gradientes solo deben calcularse y aplicarse con el optimizador devuelto, ya sea llamando a &lt;code&gt;opt.minimize()&lt;/code&gt; u &lt;code&gt;opt.compute_gradients()&lt;/code&gt; seguido de &lt;code&gt;opt.apply_gradients()&lt;/code&gt; . Los &lt;a href=&quot;../../gradients&quot;&gt; &lt;code&gt;tf.gradients&lt;/code&gt; &lt;/a&gt; no deben calcularse con tf.gradients o &lt;a href=&quot;../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; . Esto se debe a que el optimizador devuelto aplicar&amp;aacute; la escala de p&amp;eacute;rdida, y &lt;a href=&quot;../../gradients&quot;&gt; &lt;code&gt;tf.gradients&lt;/code&gt; &lt;/a&gt; o &lt;a href=&quot;../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; no lo har&amp;aacute;. Si usa directamente &lt;a href=&quot;../../gradients&quot;&gt; &lt;code&gt;tf.gradients&lt;/code&gt; &lt;/a&gt; o &lt;a href=&quot;../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; , es posible que su modelo no converja debido a problemas de subdesbordamiento de float16.</target>
        </trans-unit>
        <trans-unit id="00a169e018bcf148a01078627fb468a85b4f57d1" translate="yes" xml:space="preserve">
          <source>When this is called, the graph is finalized and ops can no longer be added to the graph.</source>
          <target state="translated">Cuando esto se llama,el gráfico se finaliza y ya no se pueden añadir operaciones al gráfico.</target>
        </trans-unit>
        <trans-unit id="69ace3a238de55ef5f17d0593a3426df7375ca43" translate="yes" xml:space="preserve">
          <source>When this is true, the Adam update formula is changed from &lt;code&gt;m / (sqrt(v) + epsilon)&lt;/code&gt; to &lt;code&gt;m / sqrt(v + epsilon**2)&lt;/code&gt;. This option improves the performance of TPU training and is not expected to harm model quality.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f06429721d1fc01498f2381f4946b62026a0283c" translate="yes" xml:space="preserve">
          <source>When this op finishes, all ops in &lt;code&gt;inputs&lt;/code&gt; have finished. This op has no output.</source>
          <target state="translated">Cuando finaliza esta operaci&amp;oacute;n, todas las operaciones en las &lt;code&gt;inputs&lt;/code&gt; han finalizado. Esta operaci&amp;oacute;n no tiene salida.</target>
        </trans-unit>
        <trans-unit id="e93fcaa76656fcbb53b75ad595ffb1773a2d63ac" translate="yes" xml:space="preserve">
          <source>When tracing a function, no ops are being executed, shapes may be unknown. See the &lt;a href=&quot;https://www.tensorflow.org/guide/concrete_function&quot;&gt;Concrete Functions Guide&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db72b6d879a1722ab8b371aaaee80aaed3e96f22" translate="yes" xml:space="preserve">
          <source>When training a model, it is often beneficial to maintain moving averages of the trained parameters. Evaluations that use averaged parameters sometimes produce significantly better results than the final trained values.</source>
          <target state="translated">Cuando se entrena un modelo,suele ser beneficioso mantener los promedios móviles de los parámetros entrenados.Las evaluaciones que utilizan parámetros promediados a veces producen resultados significativamente mejores que los valores finales entrenados.</target>
        </trans-unit>
        <trans-unit id="927a8a21e9e3520f84a7ae9e37d363926dbaebe1" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This function applies a cosine decay function to a provided initial learning rate. It requires a &lt;code&gt;global_step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">Al entrenar un modelo, a menudo se recomienda reducir la tasa de aprendizaje a medida que avanza el entrenamiento. Esta funci&amp;oacute;n aplica una funci&amp;oacute;n de disminuci&amp;oacute;n del coseno a una tasa de aprendizaje inicial proporcionada. Requiere un valor &lt;code&gt;global_step&lt;/code&gt; para calcular la tasa de aprendizaje deca&amp;iacute;do. Puede simplemente pasar una variable de TensorFlow que incrementa en cada paso de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="8d86dcb91899a78227813e8c0d47037c6ee19dfd" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This function applies a cosine decay function with restarts to a provided initial learning rate. It requires a &lt;code&gt;global_step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">Al entrenar un modelo, a menudo se recomienda reducir la tasa de aprendizaje a medida que avanza el entrenamiento. Esta funci&amp;oacute;n aplica una funci&amp;oacute;n de disminuci&amp;oacute;n del coseno con reinicios a una tasa de aprendizaje inicial proporcionada. Requiere un valor &lt;code&gt;global_step&lt;/code&gt; para calcular la tasa de aprendizaje deca&amp;iacute;do. Puede simplemente pasar una variable de TensorFlow que incrementa en cada paso de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="90010651f41909cacf9403b614efcb8bd58e1369" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This function applies a linear cosine decay function to a provided initial learning rate. It requires a &lt;code&gt;global_step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">Al entrenar un modelo, a menudo se recomienda reducir la tasa de aprendizaje a medida que avanza el entrenamiento. Esta funci&amp;oacute;n aplica una funci&amp;oacute;n de disminuci&amp;oacute;n del coseno lineal a una tasa de aprendizaje inicial proporcionada. Requiere un valor &lt;code&gt;global_step&lt;/code&gt; para calcular la tasa de aprendizaje deca&amp;iacute;do. Puede simplemente pasar una variable de TensorFlow que incrementa en cada paso de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="6a9c3656ff265f4bda198cf8e5dfd044fb933790" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This function applies a noisy linear cosine decay function to a provided initial learning rate. It requires a &lt;code&gt;global_step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">Al entrenar un modelo, a menudo se recomienda reducir la tasa de aprendizaje a medida que avanza el entrenamiento. Esta funci&amp;oacute;n aplica una funci&amp;oacute;n de disminuci&amp;oacute;n de coseno lineal ruidosa a una tasa de aprendizaje inicial proporcionada. Requiere un valor &lt;code&gt;global_step&lt;/code&gt; para calcular la tasa de aprendizaje deca&amp;iacute;do. Puede simplemente pasar una variable de TensorFlow que incrementa en cada paso de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="64048e6ec72e37dd6f4daf26af9d33a56f72d8c7" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This function applies an exponential decay function to a provided initial learning rate. It requires a &lt;code&gt;global_step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">Al entrenar un modelo, a menudo se recomienda reducir la tasa de aprendizaje a medida que avanza el entrenamiento. Esta funci&amp;oacute;n aplica una funci&amp;oacute;n de disminuci&amp;oacute;n exponencial a una tasa de aprendizaje inicial proporcionada. Requiere un valor &lt;code&gt;global_step&lt;/code&gt; para calcular la tasa de aprendizaje deca&amp;iacute;do. Puede simplemente pasar una variable de TensorFlow que incrementa en cada paso de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="d181a155b50eadc32c09739aa94b40b51fe01a65" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This function applies an exponential decay function to a provided initial learning rate. It requires an &lt;code&gt;global_step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">Al entrenar un modelo, a menudo se recomienda reducir la tasa de aprendizaje a medida que avanza el entrenamiento. Esta funci&amp;oacute;n aplica una funci&amp;oacute;n de disminuci&amp;oacute;n exponencial a una tasa de aprendizaje inicial proporcionada. Requiere un valor &lt;code&gt;global_step&lt;/code&gt; para calcular la tasa de aprendizaje deca&amp;iacute;da. Puede simplemente pasar una variable de TensorFlow que incrementa en cada paso de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="4f6fc97dc42e006ec89048c76f7f47de1eeb3d9a" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This function applies an inverse decay function to a provided initial learning rate. It requires an &lt;code&gt;global_step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">Al entrenar un modelo, a menudo se recomienda reducir la tasa de aprendizaje a medida que avanza el entrenamiento. Esta funci&amp;oacute;n aplica una funci&amp;oacute;n de disminuci&amp;oacute;n inversa a una tasa de aprendizaje inicial proporcionada. Requiere un valor &lt;code&gt;global_step&lt;/code&gt; para calcular la tasa de aprendizaje deca&amp;iacute;da. Puede simplemente pasar una variable de TensorFlow que incrementa en cada paso de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="4ddff8c9e5ff83f95e35cc80fb672fdcfe082715" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This schedule applies a cosine decay function to an optimizer step, given a provided initial learning rate. It requires a &lt;code&gt;step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">Al entrenar un modelo, a menudo se recomienda reducir la tasa de aprendizaje a medida que avanza el entrenamiento. Este programa aplica una funci&amp;oacute;n de disminuci&amp;oacute;n del coseno a un paso del optimizador, dada una tasa de aprendizaje inicial proporcionada. Requiere un valor de &lt;code&gt;step&lt;/code&gt; para calcular la tasa de aprendizaje deca&amp;iacute;do. Puede simplemente pasar una variable de TensorFlow que incrementa en cada paso de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="512b0ee6d1762189943ee9ddad5e78bda622dc14" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This schedule applies a cosine decay function with restarts to an optimizer step, given a provided initial learning rate. It requires a &lt;code&gt;step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">Al entrenar un modelo, a menudo se recomienda reducir la tasa de aprendizaje a medida que avanza el entrenamiento. Este programa aplica una funci&amp;oacute;n de disminuci&amp;oacute;n del coseno con reinicios a un paso del optimizador, dada una tasa de aprendizaje inicial proporcionada. Requiere un valor de &lt;code&gt;step&lt;/code&gt; para calcular la tasa de aprendizaje deca&amp;iacute;do. Puede simplemente pasar una variable de TensorFlow que incrementa en cada paso de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="93d56e5e126f6377bdf1a06e2189c730d031c2b4" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This schedule applies a linear cosine decay function to an optimizer step, given a provided initial learning rate. It requires a &lt;code&gt;step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">Al entrenar un modelo, a menudo se recomienda reducir la tasa de aprendizaje a medida que avanza el entrenamiento. Este programa aplica una funci&amp;oacute;n de disminuci&amp;oacute;n del coseno lineal a un paso del optimizador, dada una tasa de aprendizaje inicial proporcionada. Requiere un valor de &lt;code&gt;step&lt;/code&gt; para calcular la tasa de aprendizaje deca&amp;iacute;do. Puede simplemente pasar una variable de TensorFlow que incrementa en cada paso de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="57bf3cf4acea41746a7afc38b8058640564015fe" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This schedule applies a noisy linear cosine decay function to an optimizer step, given a provided initial learning rate. It requires a &lt;code&gt;step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">Al entrenar un modelo, a menudo se recomienda reducir la tasa de aprendizaje a medida que avanza el entrenamiento. Este programa aplica una funci&amp;oacute;n de disminuci&amp;oacute;n de coseno lineal ruidosa a un paso del optimizador, dada una tasa de aprendizaje inicial proporcionada. Requiere un valor de &lt;code&gt;step&lt;/code&gt; para calcular la tasa de aprendizaje deca&amp;iacute;do. Puede simplemente pasar una variable de TensorFlow que incrementa en cada paso de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="94deb77d4f75eb579f72f3db2e455ef2c44c44e1" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This schedule applies an exponential decay function to an optimizer step, given a provided initial learning rate.</source>
          <target state="translated">Cuando se entrena a un modelo,a menudo se recomienda reducir la tasa de aprendizaje a medida que el entrenamiento progresa.Este programa aplica una función de decaimiento exponencial a un paso del optimizador,dada una tasa de aprendizaje inicial proporcionada.</target>
        </trans-unit>
        <trans-unit id="fb18244719acd2825faa9890d721d54e05f0a037" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This schedule applies the inverse decay function to an optimizer step, given a provided initial learning rate. It requires a &lt;code&gt;step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">Al entrenar un modelo, a menudo se recomienda reducir la tasa de aprendizaje a medida que avanza el entrenamiento. Este programa aplica la funci&amp;oacute;n de disminuci&amp;oacute;n inversa a un paso del optimizador, dada una tasa de aprendizaje inicial proporcionada. Requiere un valor de &lt;code&gt;step&lt;/code&gt; para calcular la tasa de aprendizaje deca&amp;iacute;do. Puede simplemente pasar una variable de TensorFlow que incrementa en cada paso de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="0cf6ec8113a82c824118b19bb4f2d871de8f3f5d" translate="yes" xml:space="preserve">
          <source>When used with &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt;, outside of built-in training loops such as &lt;a href=&quot;../../keras&quot;&gt;&lt;code&gt;tf.keras&lt;/code&gt;&lt;/a&gt;&lt;code&gt;compile&lt;/code&gt; and &lt;code&gt;fit&lt;/code&gt;, please use 'SUM' or 'NONE' reduction types, and reduce losses explicitly in your training loop. Using 'AUTO' or 'SUM_OVER_BATCH_SIZE' will raise an error.</source>
          <target state="translated">Cuando se usa con &lt;a href=&quot;../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; , fuera de los bucles de entrenamiento &lt;a href=&quot;../../keras&quot;&gt; &lt;code&gt;tf.keras&lt;/code&gt; &lt;/a&gt; como tf.keras &lt;code&gt;compile&lt;/code&gt; and &lt;code&gt;fit&lt;/code&gt; , use los tipos de reducci&amp;oacute;n 'SUM' o 'NONE' y reduzca las p&amp;eacute;rdidas expl&amp;iacute;citamente en su bucle de entrenamiento. El uso de 'AUTO' o 'SUM_OVER_BATCH_SIZE' generar&amp;aacute; un error.</target>
        </trans-unit>
        <trans-unit id="c6a537963fdbb8e6b3429be0c961e7b0d2a0a449" translate="yes" xml:space="preserve">
          <source>When used, it overrides name_ and is not made unique. If a template of the same scope/unique_name already exists and reuse is false, an error is raised. Defaults to None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58c97e844aea42b09b6f861449f7ea173f99a04f" translate="yes" xml:space="preserve">
          <source>When using InputLayer with Keras Sequential model, it can be skipped by moving the input_shape parameter to the first layer after the InputLayer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ecb7ac1c54db33d719cbd8ca1f72cb0bec98edc" translate="yes" xml:space="preserve">
          <source>When using a custom callable for &lt;code&gt;split&lt;/code&gt;, the data received by the callable will have the 1st dimension squeezed out - instead of &lt;code&gt;[[&quot;string to split&quot;], [&quot;another string to split&quot;]]&lt;/code&gt;, the Callable will see &lt;code&gt;[&quot;string to split&quot;, &quot;another string to split&quot;]&lt;/code&gt;. The callable should return a Tensor with the first dimension containing the split tokens - in this example, we should see something like &lt;code&gt;[[&quot;string&quot;, &quot;to&quot;, &quot;split], [&quot;another&quot;, &quot;string&quot;, &quot;to&quot;, &quot;split&quot;]]&lt;/code&gt;. This makes the callable site natively compatible with &lt;a href=&quot;../../../../strings/split&quot;&gt;&lt;code&gt;tf.strings.split()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4658ae77687cb1c8967c8186bb04e6986f0779aa" translate="yes" xml:space="preserve">
          <source>When using a custom callable for &lt;code&gt;standardize&lt;/code&gt;, the data received by the callable will be exactly as passed to this layer. The callable should return a tensor of the same shape as the input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0724c7bfb29f8f0c6cdcbe1954184f010886b9c" translate="yes" xml:space="preserve">
          <source>When using multiple critical sections on the same resources, there is no guarantee of exclusive access to those resources. This behavior is disallowed by default (but see the kwarg &lt;code&gt;exclusive_resource_access&lt;/code&gt;).</source>
          <target state="translated">Cuando se utilizan varias secciones cr&amp;iacute;ticas en los mismos recursos, no hay garant&amp;iacute;a de acceso exclusivo a esos recursos. Este comportamiento no est&amp;aacute; permitido de forma predeterminada (pero consulte el kwarg &lt;code&gt;exclusive_resource_access&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="005ecd21a6428476fbceb142b210d5384fc2790a" translate="yes" xml:space="preserve">
          <source>When using the default, an appropriate policy will be picked automatically. The default policy may change over time.</source>
          <target state="translated">Cuando se utiliza el valor predeterminado,se elige automáticamente una política apropiada.La política predeterminada puede cambiar con el tiempo.</target>
        </trans-unit>
        <trans-unit id="67d49a53dc96e389873c164cb198f138ecc7ff2f" translate="yes" xml:space="preserve">
          <source>When using these moments for batch normalization (see &lt;a href=&quot;../../../nn/batch_normalization&quot;&gt;&lt;code&gt;tf.nn.batch_normalization&lt;/code&gt;&lt;/a&gt;):</source>
          <target state="translated">Cuando utilice estos momentos para la normalizaci&amp;oacute;n de lotes (consulte &lt;a href=&quot;../../../nn/batch_normalization&quot;&gt; &lt;code&gt;tf.nn.batch_normalization&lt;/code&gt; &lt;/a&gt; ):</target>
        </trans-unit>
        <trans-unit id="591b74326af491d6abfab42a671eba7ebb5be83e" translate="yes" xml:space="preserve">
          <source>When using these moments for batch normalization (see &lt;a href=&quot;batch_normalization&quot;&gt;&lt;code&gt;tf.nn.batch_normalization&lt;/code&gt;&lt;/a&gt;):</source>
          <target state="translated">Cuando utilice estos momentos para la normalizaci&amp;oacute;n de lotes (consulte &lt;a href=&quot;batch_normalization&quot;&gt; &lt;code&gt;tf.nn.batch_normalization&lt;/code&gt; &lt;/a&gt; ):</target>
        </trans-unit>
        <trans-unit id="ea3d2206487c99a74b50234d9380045457ab56b2" translate="yes" xml:space="preserve">
          <source>When using this layer as the first layer in a model, provide an &lt;code&gt;input_shape&lt;/code&gt; argument (tuple of integers or &lt;code&gt;None&lt;/code&gt;, e.g. &lt;code&gt;(10, 128)&lt;/code&gt; for sequences of 10 vectors of 128-dimensional vectors, or &lt;code&gt;(None, 128)&lt;/code&gt; for variable-length sequences of 128-dimensional vectors.</source>
          <target state="translated">Cuando use esta capa como la primera capa en un modelo, proporcione un argumento &lt;code&gt;input_shape&lt;/code&gt; (tupla de enteros o &lt;code&gt;None&lt;/code&gt; , por ejemplo, &lt;code&gt;(10, 128)&lt;/code&gt; para secuencias de 10 vectores de vectores de 128 dimensiones, o &lt;code&gt;(None, 128)&lt;/code&gt; para longitud variable secuencias de vectores de 128 dimensiones.</target>
        </trans-unit>
        <trans-unit id="0a409624f20a1b12afa97b438af1e2c02851ec80" translate="yes" xml:space="preserve">
          <source>When using this layer as the first layer in a model, provide the keyword argument &lt;code&gt;input_shape&lt;/code&gt; (tuple of integers, does not include the sample axis), e.g. &lt;code&gt;input_shape=(128, 128, 128, 1)&lt;/code&gt; for 128x128x128 volumes with a single channel, in &lt;code&gt;data_format=&quot;channels_last&quot;&lt;/code&gt;.</source>
          <target state="translated">Cuando utilice esta capa como la primera capa en un modelo, proporcione el argumento de palabra clave &lt;code&gt;input_shape&lt;/code&gt; (tupla de enteros, no incluye el eje de muestra), por ejemplo, &lt;code&gt;input_shape=(128, 128, 128, 1)&lt;/code&gt; para vol&amp;uacute;menes de 128x128x128 con un solo canal, en &lt;code&gt;data_format=&quot;channels_last&quot;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="14d463d2a8afe47183522c1acdade8296e826653" translate="yes" xml:space="preserve">
          <source>When using this layer as the first layer in a model, provide the keyword argument &lt;code&gt;input_shape&lt;/code&gt; (tuple of integers, does not include the sample axis), e.g. &lt;code&gt;input_shape=(128, 128, 128, 3)&lt;/code&gt; for a 128x128x128 volume with 3 channels if &lt;code&gt;data_format=&quot;channels_last&quot;&lt;/code&gt;.</source>
          <target state="translated">Cuando utilice esta capa como la primera capa en un modelo, proporcione el argumento de palabra clave &lt;code&gt;input_shape&lt;/code&gt; (tupla de enteros, no incluye el eje de muestra), por ejemplo, &lt;code&gt;input_shape=(128, 128, 128, 3)&lt;/code&gt; para un volumen de 128x128x128 con 3 canales si &lt;code&gt;data_format=&quot;channels_last&quot;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b700c0ba9e5af2d79f0ea705fd60f2846a05cd69" translate="yes" xml:space="preserve">
          <source>When using this layer as the first layer in a model, provide the keyword argument &lt;code&gt;input_shape&lt;/code&gt; (tuple of integers, does not include the sample axis), e.g. &lt;code&gt;input_shape=(128, 128, 3)&lt;/code&gt; for 128x128 RGB pictures in &lt;code&gt;data_format=&quot;channels_last&quot;&lt;/code&gt;.</source>
          <target state="translated">Cuando use esta capa como la primera capa en un modelo, proporcione el argumento de palabra clave &lt;code&gt;input_shape&lt;/code&gt; (tupla de enteros, no incluye el eje de muestra), por ejemplo, &lt;code&gt;input_shape=(128, 128, 3)&lt;/code&gt; para im&amp;aacute;genes RGB de 128x128 en &lt;code&gt;data_format=&quot;channels_last&quot;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="39c55fa13fdb10b59035551c9a262071686d849a" translate="yes" xml:space="preserve">
          <source>When using this layer as the first layer in a model, provide the keyword argument &lt;code&gt;input_shape&lt;/code&gt; (tuple of integers, does not include the sample axis), e.g. &lt;code&gt;input_shape=(128, 3)&lt;/code&gt; for data with 128 time steps and 3 channels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90420d916accea41b90f4795021da2ee04f4f6d6" translate="yes" xml:space="preserve">
          <source>When variables are assigned to multiple workers, each worker writes its own section of the checkpoint. These sections are then merged/re-indexed to behave as a single checkpoint. This avoids copying all variables to one worker, but does require that all workers see a common filesystem.</source>
          <target state="translated">Cuando se asignan variables a varios trabajadores,cada trabajador escribe su propia sección del punto de control.Estas secciones son luego fusionadas/reindexadas para que se comporten como un solo punto de control.Esto evita copiar todas las variables a un solo trabajador,pero requiere que todos los trabajadores vean un sistema de archivos común.</target>
        </trans-unit>
        <trans-unit id="d43c37e91c1c99cab60a11a374e0ae141f677fad" translate="yes" xml:space="preserve">
          <source>When writing a TensorFlow program, the main object that is manipulated and passed around is the &lt;a href=&quot;tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5727fc2aeafda851fc9ab281a980ef4c906dc39b" translate="yes" xml:space="preserve">
          <source>When you build a model for training you usually need ops to initialize variables, a &lt;code&gt;Saver&lt;/code&gt; to checkpoint them, an op to collect summaries for the visualizer, and so on.</source>
          <target state="translated">Cuando crea un modelo para el entrenamiento, generalmente necesita operaciones para inicializar variables, un &lt;code&gt;Saver&lt;/code&gt; para controlarlas, una operaci&amp;oacute;n para recopilar res&amp;uacute;menes para el visualizador, etc.</target>
        </trans-unit>
        <trans-unit id="2571f0d8bc64be0b275df26c714df2c7b618a158" translate="yes" xml:space="preserve">
          <source>When you iterate over a dataset containing the &lt;code&gt;distribute&lt;/code&gt; transformation, the tf.data service creates a &quot;job&quot; which produces data for the dataset iteration.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39d490a1a6c041251d0a268b335edd8cf95e7a4b" translate="yes" xml:space="preserve">
          <source>When you later call the &lt;code&gt;create_threads()&lt;/code&gt; method, the &lt;code&gt;QueueRunner&lt;/code&gt; will create one thread for each op in &lt;code&gt;enqueue_ops&lt;/code&gt;. Each thread will run its enqueue op in parallel with the other threads. The enqueue ops do not have to all be the same op, but it is expected that they all enqueue tensors in &lt;code&gt;queue&lt;/code&gt;.</source>
          <target state="translated">Cuando m&amp;aacute;s tarde llame al m&amp;eacute;todo &lt;code&gt;create_threads()&lt;/code&gt; , &lt;code&gt;QueueRunner&lt;/code&gt; crear&amp;aacute; un hilo para cada &lt;code&gt;enqueue_ops&lt;/code&gt; en enqueue_ops . Cada hilo ejecutar&amp;aacute; su operaci&amp;oacute;n de puesta en cola en paralelo con los otros hilos. Las operaciones de puesta en cola no tienen que ser todas la misma operaci&amp;oacute;n, pero se espera que todas pongan tensores en &lt;code&gt;queue&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d3a2e77e985cdd0c4ca04ebfb7ec15ae2eed6e37" translate="yes" xml:space="preserve">
          <source>When you launch the graph, variables have to be explicitly initialized before you can run Ops that use their value. You can initialize a variable by running its &lt;em&gt;initializer op&lt;/em&gt;, restoring the variable from a save file, or simply running an &lt;code&gt;assign&lt;/code&gt; Op that assigns a value to the variable. In fact, the variable &lt;em&gt;initializer op&lt;/em&gt; is just an &lt;code&gt;assign&lt;/code&gt; Op that assigns the variable's initial value to the variable itself.</source>
          <target state="translated">Cuando inicia el gr&amp;aacute;fico, las variables deben inicializarse expl&amp;iacute;citamente antes de poder ejecutar operaciones que usan su valor. Puede inicializar una variable ejecutando su &lt;em&gt;operaci&amp;oacute;n de inicializaci&amp;oacute;n&lt;/em&gt; , restaurando la variable desde un archivo guardado o simplemente ejecutando una operaci&amp;oacute;n de &lt;code&gt;assign&lt;/code&gt; que asigna un valor a la variable. De hecho, el &lt;em&gt;inicializador de&lt;/em&gt; variable &lt;em&gt;op&lt;/em&gt; es solo un Op de &lt;code&gt;assign&lt;/code&gt; que asigna el valor inicial de la variable a la variable en s&amp;iacute;.</target>
        </trans-unit>
        <trans-unit id="36dcf90c997814649120f194530d033746d75e2c" translate="yes" xml:space="preserve">
          <source>Whenever &lt;code&gt;partial_pivoting&lt;/code&gt; is true and the backend is XLA.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e2218d66173c9095f9d7c0c982dd0a7b7b1d0cb" translate="yes" xml:space="preserve">
          <source>Whenever possible, the session will raise a more specific subclass of &lt;code&gt;OpError&lt;/code&gt; from the &lt;a href=&quot;../errors&quot;&gt;&lt;code&gt;tf.errors&lt;/code&gt;&lt;/a&gt; module.</source>
          <target state="translated">Siempre que sea posible, la sesi&amp;oacute;n generar&amp;aacute; una subclase m&amp;aacute;s espec&amp;iacute;fica de &lt;code&gt;OpError&lt;/code&gt; del m&amp;oacute;dulo &lt;a href=&quot;../errors&quot;&gt; &lt;code&gt;tf.errors&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="525f61b6729229b1a8854a9e50bcaa52ea96b131" translate="yes" xml:space="preserve">
          <source>Where</source>
          <target state="translated">Where</target>
        </trans-unit>
        <trans-unit id="a5a5757b0332ab74cd51749fc4f26f2282d43f68" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;j&lt;/code&gt; is the &lt;code&gt;i&lt;/code&gt;th &lt;code&gt;True&lt;/code&gt; entry of &lt;code&gt;mask[a1...aA]&lt;/code&gt;.</source>
          <target state="translated">Donde &lt;code&gt;j&lt;/code&gt; es la &lt;code&gt;i&lt;/code&gt; - &amp;eacute;sima entrada &lt;code&gt;True&lt;/code&gt; de la &lt;code&gt;mask[a1...aA]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a9e5e6939cbf334efa1154ae5d005e3955d0f0b7" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;key&lt;/code&gt; is a feature key whose values are used to partition the values. Partitions are listed from outermost to innermost.</source>
          <target state="translated">Donde &lt;code&gt;key&lt;/code&gt; es una clave de funci&amp;oacute;n cuyos valores se utilizan para dividir los valores. Las particiones se enumeran de la m&amp;aacute;s externa a la m&amp;aacute;s interna.</target>
        </trans-unit>
        <trans-unit id="17e66517ae2fa6c4b3f8472462247a694203eb5e" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;year&lt;/code&gt;, &lt;code&gt;month&lt;/code&gt;, and &lt;code&gt;day&lt;/code&gt; specify the date beyond which binaries that consume a model are expected to have been updated to include the new operations. This date is typically at least 3 weeks beyond the date the code that adds the new operation is committed.</source>
          <target state="translated">Donde &lt;code&gt;year&lt;/code&gt; , &lt;code&gt;month&lt;/code&gt; y &lt;code&gt;day&lt;/code&gt; especifican la fecha a partir de la cual se espera que los binarios que consumen un modelo se actualicen para incluir las nuevas operaciones. Esta fecha suele ser al menos 3 semanas despu&amp;eacute;s de la fecha en que se confirma el c&amp;oacute;digo que agrega la nueva operaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="743987e43173da0b07d4299cc71758449720108f" translate="yes" xml:space="preserve">
          <source>Where &lt;em&gt;N&lt;/em&gt; = &lt;code&gt;ndims(params)&lt;/code&gt;, &lt;em&gt;M&lt;/em&gt; = &lt;code&gt;ndims(indices)&lt;/code&gt;, and &lt;em&gt;B&lt;/em&gt; = &lt;code&gt;batch_dims&lt;/code&gt;. Note that &lt;code&gt;params.shape[:batch_dims]&lt;/code&gt; must be identical to &lt;code&gt;indices.shape[:batch_dims]&lt;/code&gt;.</source>
          <target state="translated">Donde &lt;em&gt;N&lt;/em&gt; = &lt;code&gt;ndims(params)&lt;/code&gt; , &lt;em&gt;M&lt;/em&gt; = &lt;code&gt;ndims(indices)&lt;/code&gt; y &lt;em&gt;B&lt;/em&gt; = &lt;code&gt;batch_dims&lt;/code&gt; . Tenga en cuenta que &lt;code&gt;params.shape[:batch_dims]&lt;/code&gt; debe ser id&amp;eacute;ntico a &lt;code&gt;indices.shape[:batch_dims]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="13aa13f1ced8020c65b238cd2e5743aaab5f6a97" translate="yes" xml:space="preserve">
          <source>Where &lt;em&gt;N&lt;/em&gt; = &lt;code&gt;ndims(params)&lt;/code&gt;.</source>
          <target state="translated">Donde &lt;em&gt;N&lt;/em&gt; = &lt;code&gt;ndims(params)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7e741bc3dcef0123eeda11543758853be2aac149" translate="yes" xml:space="preserve">
          <source>Where:</source>
          <target state="translated">Where:</target>
        </trans-unit>
        <trans-unit id="df5ee0a432194eaf058dafaec560ccdd5751f85a" translate="yes" xml:space="preserve">
          <source>Whereas in &lt;a href=&quot;../../gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt;&lt;code&gt;indices&lt;/code&gt; defines slices into the first dimension of &lt;code&gt;params&lt;/code&gt;, in &lt;a href=&quot;../../gather_nd&quot;&gt;&lt;code&gt;tf.gather_nd&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;indices&lt;/code&gt; defines slices into the first &lt;code&gt;N&lt;/code&gt; dimensions of &lt;code&gt;params&lt;/code&gt;, where &lt;code&gt;N = indices.shape[-1]&lt;/code&gt;.</source>
          <target state="translated">Mientras que en &lt;a href=&quot;../../gather&quot;&gt; &lt;code&gt;tf.gather&lt;/code&gt; &lt;/a&gt; &lt;code&gt;indices&lt;/code&gt; Define rebanadas en la primera dimensi&amp;oacute;n de &lt;code&gt;params&lt;/code&gt; , en &lt;a href=&quot;../../gather_nd&quot;&gt; &lt;code&gt;tf.gather_nd&lt;/code&gt; &lt;/a&gt; , &lt;code&gt;indices&lt;/code&gt; Define rebanadas en los primeros &lt;code&gt;N&lt;/code&gt; dimensiones de &lt;code&gt;params&lt;/code&gt; , donde &lt;code&gt;N = indices.shape[-1]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="db72094af8e11b94ee83cae58cea0ebfb59e1a33" translate="yes" xml:space="preserve">
          <source>Whereas in &lt;a href=&quot;../gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt;&lt;code&gt;indices&lt;/code&gt; defines slices into the &lt;code&gt;axis&lt;/code&gt; dimension of &lt;code&gt;params&lt;/code&gt;, in &lt;a href=&quot;../gather_nd&quot;&gt;&lt;code&gt;tf.gather_nd&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;indices&lt;/code&gt; defines slices into the first &lt;code&gt;N&lt;/code&gt; dimensions of &lt;code&gt;params&lt;/code&gt;, where &lt;code&gt;N = indices.shape[-1]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37006b5e3234b3a81d34b49c1399e20287f6f5fd" translate="yes" xml:space="preserve">
          <source>Whereas in &lt;a href=&quot;gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt;&lt;code&gt;indices&lt;/code&gt; defines slices into the first dimension of &lt;code&gt;params&lt;/code&gt;, in &lt;a href=&quot;gather_nd&quot;&gt;&lt;code&gt;tf.gather_nd&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;indices&lt;/code&gt; defines slices into the first &lt;code&gt;N&lt;/code&gt; dimensions of &lt;code&gt;params&lt;/code&gt;, where &lt;code&gt;N = indices.shape[-1]&lt;/code&gt;.</source>
          <target state="translated">Mientras que en &lt;a href=&quot;gather&quot;&gt; &lt;code&gt;tf.gather&lt;/code&gt; &lt;/a&gt; &lt;code&gt;indices&lt;/code&gt; Define rebanadas en la primera dimensi&amp;oacute;n de &lt;code&gt;params&lt;/code&gt; , en &lt;a href=&quot;gather_nd&quot;&gt; &lt;code&gt;tf.gather_nd&lt;/code&gt; &lt;/a&gt; , &lt;code&gt;indices&lt;/code&gt; Define rebanadas en los primeros &lt;code&gt;N&lt;/code&gt; dimensiones de &lt;code&gt;params&lt;/code&gt; , donde &lt;code&gt;N = indices.shape[-1]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d4b7353826912b9cec703766decc544dcf83f10b" translate="yes" xml:space="preserve">
          <source>Whether &lt;code&gt;output&lt;/code&gt; is expected to be a logits tensor. By default, we consider that &lt;code&gt;output&lt;/code&gt; encodes a probability distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47c0b61274d31e65caf92de4ae562ae2c5114355" translate="yes" xml:space="preserve">
          <source>Whether &lt;code&gt;y_pred&lt;/code&gt; is expected to be a logits tensor. By default, we assume that &lt;code&gt;y_pred&lt;/code&gt; encodes a probability distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe485b5aa69407b2cec559631c713bb745bddf4c" translate="yes" xml:space="preserve">
          <source>Whether &lt;code&gt;y_pred&lt;/code&gt; is expected to be a logits tensor. By default, we assume that &lt;code&gt;y_pred&lt;/code&gt; encodes a probability distribution. **Note - Using from_logits=True may be more numerically stable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8c9ab93a2df9a01da2c64742b40fc42d6c91dfb" translate="yes" xml:space="preserve">
          <source>Whether &lt;code&gt;y_pred&lt;/code&gt; is expected to be a logits tensor. By default, we assume that &lt;code&gt;y_pred&lt;/code&gt; encodes a probability distribution. &lt;strong&gt;Note - Using from_logits=True is more numerically stable.&lt;/strong&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8fd73dec5012589d7460a67d8190f1604f4a14a8" translate="yes" xml:space="preserve">
          <source>Whether GPU-CPU memory swap is enabled for this loop.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6717cbbf5b0f27136d029a9a5a4fe644c3d0bdb" translate="yes" xml:space="preserve">
          <source>Whether a &lt;code&gt;DType&lt;/code&gt; is unsigned.</source>
          <target state="translated">Si un &lt;code&gt;DType&lt;/code&gt; no est&amp;aacute; firmado.</target>
        </trans-unit>
        <trans-unit id="1e01d5432153fe1934c596d7a5942310bb55c381" translate="yes" xml:space="preserve">
          <source>Whether a &lt;code&gt;History&lt;/code&gt; callback should be added, if one does not already exist in the &lt;code&gt;callbacks&lt;/code&gt; list.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="224e3e261d520f419e922338344450c9f2dfc0d7" translate="yes" xml:space="preserve">
          <source>Whether a &lt;code&gt;ProgbarLogger&lt;/code&gt; callback should be added, if one does not already exist in the &lt;code&gt;callbacks&lt;/code&gt; list.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8aa3f3168594096d3d8b8e19131df9c4c2c6f451" translate="yes" xml:space="preserve">
          <source>Whether autograph should be applied on &lt;code&gt;func&lt;/code&gt; before tracing a graph. Data-dependent control flow requires &lt;code&gt;autograph=True&lt;/code&gt;. For more information, see the &lt;a href=&quot;https://www.tensorflow.org/guide/function&quot;&gt;tf.function and AutoGraph guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e52c3c2213cac47314d63bd666108cb982d0a526" translate="yes" xml:space="preserve">
          <source>Whether backprop is enabled for this while loop.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a906b7b12a6aaefca1bb38dbd9c872d24af6915" translate="yes" xml:space="preserve">
          <source>Whether bias centering needs to occur. Bias centering refers to the first node in the very first tree returning the prediction that is aligned with the original labels distribution. For example, for regression problems, the first node will return the mean of the labels. For binary classification problems, it will return a logit for a prior probability of label 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43c8b1e245711e513da5fb3224a94014bfbd2ea6" translate="yes" xml:space="preserve">
          <source>Whether checkpointing is needed.</source>
          <target state="translated">Si es necesario hacer un control.</target>
        </trans-unit>
        <trans-unit id="d4eda7288db97494a48ea76ccf902c7ac0f935a7" translate="yes" xml:space="preserve">
          <source>Whether each tensor in &lt;code&gt;tensor_list&lt;/code&gt; is a single example.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95fd49cdfd4929bef2715197b8eb6fc30ab04a73" translate="yes" xml:space="preserve">
          <source>Whether each tensor in &lt;code&gt;tensor_list_list&lt;/code&gt; is a single example.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ccb1e098286182b19dc3309570dc9cdd8118f6d3" translate="yes" xml:space="preserve">
          <source>Whether each tensor in &lt;code&gt;tensors&lt;/code&gt; is a single example.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6a6ce44ff2b603ee993694c9f88f39e13a58c1f" translate="yes" xml:space="preserve">
          <source>Whether initialization is needed.</source>
          <target state="translated">Si es necesaria la inicialización.</target>
        </trans-unit>
        <trans-unit id="b62856eef3b197086ffc08e6c1915a9c8bdb4a27" translate="yes" xml:space="preserve">
          <source>Whether only account the statistics of displayed profiler nodes.</source>
          <target state="translated">Si sólo se tienen en cuenta las estadísticas de los nodos de los perfiles mostrados.</target>
        </trans-unit>
        <trans-unit id="b2a9b9493710259f1453769c41e2339bd8290c9f" translate="yes" xml:space="preserve">
          <source>Whether only weights are saved, or the whole model is saved.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="369fdea0194aadd9a179680eb99f4f5771059465" translate="yes" xml:space="preserve">
          <source>Whether operations should be dispatched synchronously. Valid values:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="584fa0c419a0180a4a9a48f62c36f8aa85cbba56" translate="yes" xml:space="preserve">
          <source>Whether or not the embedding is trainable. Default is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd70d2454f94f5a5bd23acd3b6d8d74be52ad65b" translate="yes" xml:space="preserve">
          <source>Whether or not the enum is to be case-sensitive.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5af2fcf03aaec3220bccfce000595207f5de5efd" translate="yes" xml:space="preserve">
          <source>Whether or not to clear the device field for an &lt;code&gt;Operation&lt;/code&gt; or &lt;code&gt;Tensor&lt;/code&gt; during export.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="541b0e69634db2eb96093b9893572ce18575fde6" translate="yes" xml:space="preserve">
          <source>Whether or not to clear the device field for an &lt;code&gt;Operation&lt;/code&gt; or &lt;code&gt;Tensor&lt;/code&gt; during import.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2329674feeb4db85ce54cddb74a65691271f9d8" translate="yes" xml:space="preserve">
          <source>Whether or not to close all open fd's in the child after forking.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c16fc5a5fb92977ae5605b686e098e91fe724b8" translate="yes" xml:space="preserve">
          <source>Whether saving summaries is needed.</source>
          <target state="translated">Si es necesario guardar los resúmenes.</target>
        </trans-unit>
        <trans-unit id="a67af11a445e7ad4ad271581ae16018da270fae5" translate="yes" xml:space="preserve">
          <source>Whether shape inference is enabled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="213556493385771188ee3ad68ba9d0c3e3df86d3" translate="yes" xml:space="preserve">
          <source>Whether the &lt;code&gt;TensorArray&lt;/code&gt; can grow past its initial size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b529b545844f1f5f6b86ac51e751e32c783eddaa" translate="yes" xml:space="preserve">
          <source>Whether the &lt;code&gt;input_bytes&lt;/code&gt; data is in little-endian format. Data will be converted into host byte order if necessary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="254e76001f48c136c6f2b62d065c4a944ffb37c6" translate="yes" xml:space="preserve">
          <source>Whether the Reader implementation can serialize its state.</source>
          <target state="translated">Si la implementación del Lector puede serializar su estado.</target>
        </trans-unit>
        <trans-unit id="8e46d69392dfbc82012e7be9a6824ef93b52a84b" translate="yes" xml:space="preserve">
          <source>Whether the layer is dynamic (eager-only); set in the constructor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6e0e7bc8fc1c73b7aaaf3cab72814f4b9d143dc" translate="yes" xml:space="preserve">
          <source>Whether the layer should be trained (boolean), i.e. whether its potentially-trainable weights should be returned as part of &lt;code&gt;layer.trainable_weights&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="decf851b03ac228e9313cade0b5957f7b666dae0" translate="yes" xml:space="preserve">
          <source>Whether the outputs need to be produced in deterministic order. If None, defaults to True.</source>
          <target state="translated">Si los resultados deben producirse en un orden determinante.Si no hay ninguno,por defecto es True.</target>
        </trans-unit>
        <trans-unit id="204afdb37d75d1615b12cbddd4b547cac2445374" translate="yes" xml:space="preserve">
          <source>Whether the resources required by &lt;code&gt;fn&lt;/code&gt; should be exclusive to this &lt;code&gt;CriticalSection&lt;/code&gt;. Default: &lt;code&gt;True&lt;/code&gt;. You may want to set this to &lt;code&gt;False&lt;/code&gt; if you will be accessing a resource in read-only mode in two different CriticalSections.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ca153ec1da7024d082dd6c5ca6490e0c9cc967f" translate="yes" xml:space="preserve">
          <source>Whether the scaling parameter of the layer should be trainable. Defaults to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f124179378e71744cfb3660434035ba0a965f11a" translate="yes" xml:space="preserve">
          <source>Whether the strategy uses between-graph replication or not.</source>
          <target state="translated">Tanto si la estrategia utiliza la replicación entre gráficos como si no.</target>
        </trans-unit>
        <trans-unit id="7b189cbeed35b5f550585a0be2719b6e1b80cbe7" translate="yes" xml:space="preserve">
          <source>Whether the threads should be marked as &lt;code&gt;daemons&lt;/code&gt;, meaning they don't block program exit.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ffa50da689f93e998f89852cb17efdd428d40e8f" translate="yes" xml:space="preserve">
          <source>Whether this is the last update for the progress bar. If &lt;code&gt;None&lt;/code&gt;, defaults to &lt;code&gt;current &amp;gt;= self.target&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="844772b73edafce629bee3e7ae25983a4b946d09" translate="yes" xml:space="preserve">
          <source>Whether this layer supports computing a mask using &lt;code&gt;compute_mask&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc8aa6f730bdacc1ba24ab5a192fd71d34266e12" translate="yes" xml:space="preserve">
          <source>Whether to L2-normalize samples along the dot product axis before taking the dot product. If set to True, then the output of the dot product is the cosine proximity between the two samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25debb8437d8df1e4a47ad52d47cdffdeaed2fdb" translate="yes" xml:space="preserve">
          <source>Whether to add latency measurements on all edges. Defaults to False.</source>
          <target state="translated">Si agregar medidas de latencia en todos los bordes.Por defecto es Falso.</target>
        </trans-unit>
        <trans-unit id="ea1060a10c23d0b7356e53c3f78b04cde7c784c6" translate="yes" xml:space="preserve">
          <source>Whether to add python code trace information. Used to support &quot;code&quot; view.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd79c6c27494dd0eff20142fcddaa9263851ca92" translate="yes" xml:space="preserve">
          <source>Whether to allow the expansion in the non-concat dimensions. Defaulted to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60ffb7d2f619b0cd73858e4eae2a324f1c86a19d" translate="yes" xml:space="preserve">
          <source>Whether to apply decay in a discrete staircase, as opposed to continuous, fashion.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98be7901e41c6f7d3da8e520ead11178c148bd11" translate="yes" xml:space="preserve">
          <source>Whether to apply default graph optimizations. If False, only graph optimizations that have been explicitly enabled will be applied.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04a904d718701877a2e0c411c4fe23b4c4e3dd17" translate="yes" xml:space="preserve">
          <source>Whether to apply default static optimizations. If False, only static optimizations that have been explicitly enabled will be applied.</source>
          <target state="translated">Si aplicar o no optimizaciones estáticas predeterminadas.Si es falso,sólo se aplicarán las optimizaciones estáticas que hayan sido explícitamente habilitadas.</target>
        </trans-unit>
        <trans-unit id="0dfe28cb36c9e4043cc3c258d3d2b5adbf5c6fcb" translate="yes" xml:space="preserve">
          <source>Whether to automatically tune performance knobs. If None, defaults to True.</source>
          <target state="translated">Si ajustar automáticamente las perillas de rendimiento.Si no hay ninguno,el valor predeterminado es Verdadero.</target>
        </trans-unit>
        <trans-unit id="e49bbcda0833c641972e00b20f44fee93023536d" translate="yes" xml:space="preserve">
          <source>Whether to close the &lt;code&gt;summary_writer&lt;/code&gt;. Defaults to &lt;code&gt;True&lt;/code&gt; if the summary writer was created by the supervisor, &lt;code&gt;False&lt;/code&gt; otherwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48089f8ff308f6b2e1f3c7040fd63434bb0bf7a9" translate="yes" xml:space="preserve">
          <source>Whether to close the summary writer when closing the session. Defaults to True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06ba131eb14ad989473a1a1d258716794efd0b30" translate="yes" xml:space="preserve">
          <source>Whether to convert the comparison operators, like equality. This is soon to be deprecated as support is being added to the Tensor class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7f5fb7a744d7e22b32c2f61ab042329f9cf9f1e" translate="yes" xml:space="preserve">
          <source>Whether to eliminate no-op transformations. If None, defaults to True.</source>
          <target state="translated">Si eliminar o no las transformaciones no operativas.Si no hay ninguna,por defecto es Verdadero.</target>
        </trans-unit>
        <trans-unit id="55bb7493c6bec3c764e8919ffd2eed1794554953" translate="yes" xml:space="preserve">
          <source>Whether to enable JIT compilation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c98d9351c340a8a2394b518e7da0cf49c193b3a" translate="yes" xml:space="preserve">
          <source>Whether to enable or disable compilation in the scope. Either a Python bool, or a callable that accepts the parameter &lt;code&gt;node_def&lt;/code&gt; and returns a python bool.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f04c00e059b1defa60bb4eed8c8d8bfc3869da01" translate="yes" xml:space="preserve">
          <source>Whether to enable soft placement.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9d095bc84ce17a933a7edf15d114454108ce476" translate="yes" xml:space="preserve">
          <source>Whether to enabled device placement logging.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa1073b5ec09137db6c46e9a17f5e29476dc90c4" translate="yes" xml:space="preserve">
          <source>Whether to expand nested models into clusters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="593fbed8bd96575db44e786eedbea4f61bf29dd7" translate="yes" xml:space="preserve">
          <source>Whether to follow symlinks inside class subdirectories (default: False).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ccd7cdfaf0055cafb944adeab223f3187d39f6f" translate="yes" xml:space="preserve">
          <source>Whether to fuse filter dataset that predicts random_uniform &amp;lt; rate into a sampling dataset. If None, defaults to False.</source>
          <target state="translated">Ya sea para fusionar un conjunto de datos de filtro que predice random_uniform &amp;lt;rate en un conjunto de datos de muestreo. Si es Ninguno, el valor predeterminado es Falso.</target>
        </trans-unit>
        <trans-unit id="3d46b05c402499222a82d4000612dbe3e69e3543" translate="yes" xml:space="preserve">
          <source>Whether to fuse filter transformations. If None, defaults to False.</source>
          <target state="translated">Si fusionar o no las transformaciones de los filtros.Si no hay ninguno,por defecto es falso.</target>
        </trans-unit>
        <trans-unit id="14622b8d2b800d5545010933d2dce355f7878e20" translate="yes" xml:space="preserve">
          <source>Whether to fuse map and batch transformations. If None, defaults to True.</source>
          <target state="translated">Si se fusionan las transformaciones de mapas y lotes.Si no hay ninguna,por defecto es True.</target>
        </trans-unit>
        <trans-unit id="89d5416ec9ee3bbc766239f06ad6082f104072da" translate="yes" xml:space="preserve">
          <source>Whether to fuse map and filter transformations. If None, defaults to False.</source>
          <target state="translated">Si fusionar transformaciones de mapas y filtros.Si no hay ninguna,el valor por defecto es Falso.</target>
        </trans-unit>
        <trans-unit id="ed238b5a1a92f1cdcc3146430339e440df04eeef" translate="yes" xml:space="preserve">
          <source>Whether to fuse map transformations. If None, defaults to False.</source>
          <target state="translated">Si fusionar o no las transformaciones de los mapas.Si no hay ninguna,por defecto es Falsa.</target>
        </trans-unit>
        <trans-unit id="5bf1515795584c1b97bc7e2ce679a96ff89a3700" translate="yes" xml:space="preserve">
          <source>Whether to fuse shuffle and repeat transformations. If None, defaults to True.</source>
          <target state="translated">Si fusionar o no las transformaciones barajadas y repetidas.Si no hay ninguna,por defecto es Verdadero.</target>
        </trans-unit>
        <trans-unit id="5d8df6452e0ce74559d9d9e2cb01ae9313b462e1" translate="yes" xml:space="preserve">
          <source>Whether to hoist &lt;code&gt;tf.random_uniform()&lt;/code&gt; ops out of map transformations. If None, defaults to False.</source>
          <target state="translated">Ya sea para &lt;code&gt;tf.random_uniform()&lt;/code&gt; ops de las transformaciones del mapa. Si es Ninguno, el valor predeterminado es Falso.</target>
        </trans-unit>
        <trans-unit id="3d0ff5f97e1e7bc8d1a39a62cacd607bcbc343f6" translate="yes" xml:space="preserve">
          <source>Whether to include the constant &lt;code&gt;log(z!)&lt;/code&gt; term in computing the poisson loss. See &lt;a href=&quot;../nn/log_poisson_loss&quot;&gt;&lt;code&gt;tf.nn.log_poisson_loss&lt;/code&gt;&lt;/a&gt; for the full documentation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95573f5b8478c4ff858958db70f9484eb3ff2864" translate="yes" xml:space="preserve">
          <source>Whether to include the fully-connected layer at the top of the network.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b6d4f7d016891ba7c3664590ae67883c943bcc2" translate="yes" xml:space="preserve">
          <source>Whether to include the fully-connected layer at the top of the network. Defaults to True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a96a6b7996a34915e32caf67d322039a64480302" translate="yes" xml:space="preserve">
          <source>Whether to interpret &lt;code&gt;y_pred&lt;/code&gt; as a tensor of &lt;a href=&quot;https://en.wikipedia.org/wiki/Logit&quot;&gt;logit&lt;/a&gt; values. By default, we assume that &lt;code&gt;y_pred&lt;/code&gt; contains probabilities (i.e., values in [0, 1]). **Note - Using from_logits=True may be more numerically stable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c54c4b54df643bc4abc643e55545e0c75e91b663" translate="yes" xml:space="preserve">
          <source>Whether to introduce 'slack' in the last &lt;code&gt;prefetch&lt;/code&gt; of the input pipeline, if it exists. This may reduce CPU contention with accelerator host-side activity at the start of a step. The slack frequency is determined by the number of devices attached to this input pipeline. If None, defaults to False.</source>
          <target state="translated">Ya sea para introducir 'holgura' en la &amp;uacute;ltima &lt;code&gt;prefetch&lt;/code&gt; de la canalizaci&amp;oacute;n de entrada, si existe. Esto puede reducir la contenci&amp;oacute;n de la CPU con la actividad del lado del host del acelerador al comienzo de un paso. La frecuencia de holgura est&amp;aacute; determinada por la cantidad de dispositivos conectados a esta tuber&amp;iacute;a de entrada. Si es Ninguno, el valor predeterminado es Falso.</target>
        </trans-unit>
        <trans-unit id="415f3117867c673985b61a262949466ab1564948" translate="yes" xml:space="preserve">
          <source>Whether to mark this name as being used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d1aefded232219f79087eafa756226ded0158a7" translate="yes" xml:space="preserve">
          <source>Whether to only keep the model that has achieved the &quot;best performance&quot; so far, or whether to save the model at the end of every epoch regardless of performance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="914df09e28d1c64c2b3ad87baeeb42bb6e13c04f" translate="yes" xml:space="preserve">
          <source>Whether to output all intermediates from functional control flow ops.</source>
          <target state="translated">Si se debe dar salida a todos los intermediarios de las operaciones de flujo de control funcional.</target>
        </trans-unit>
        <trans-unit id="1dadddd88645b104b7d6bbaecaa2b1fda6cebd75" translate="yes" xml:space="preserve">
          <source>Whether to pad the end of &lt;code&gt;signal&lt;/code&gt; with &lt;code&gt;pad_value&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b76369cf9f1df3341ba7b7b298f504b7086664d1" translate="yes" xml:space="preserve">
          <source>Whether to pad the end of &lt;code&gt;signals&lt;/code&gt; with zeros when the provided frame length and step produces a frame that lies partially past its end.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02821348292f56a84707e75ec632d05c62475235" translate="yes" xml:space="preserve">
          <source>Whether to parallelize copying of batch elements. If None, defaults to False.</source>
          <target state="translated">Si se debe paralelizar la copia de los elementos del lote.Si no hay ninguno,el valor por defecto es Falso.</target>
        </trans-unit>
        <trans-unit id="735760deb2a9c67ef0c7efaa6a50691fc4a6f0e0" translate="yes" xml:space="preserve">
          <source>Whether to parallelize stateless map transformations. If None, defaults to False.</source>
          <target state="translated">Si se deben paralelizar las transformaciones de los mapas sin estado.Si no hay ninguna,por defecto es Falsa.</target>
        </trans-unit>
        <trans-unit id="8eda9b273c93d039ba7a242609f9446311332c6d" translate="yes" xml:space="preserve">
          <source>Whether to preserve the aspect ratio. If this is set, then &lt;code&gt;images&lt;/code&gt; will be resized to a size that fits in &lt;code&gt;size&lt;/code&gt; while preserving the aspect ratio of the original image. Scales up the image if &lt;code&gt;size&lt;/code&gt; is bigger than the current size of the &lt;code&gt;image&lt;/code&gt;. Defaults to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af633c59d5db9e3af600703e972fa65df59d21b3" translate="yes" xml:space="preserve">
          <source>Whether to recursively convert any functions that the converted function may call.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="331d800dc7aa1366aba63d94549fbc90867f575a" translate="yes" xml:space="preserve">
          <source>Whether to replace the C0 control characters &lt;code&gt;(U+0000 - U+001F)&lt;/code&gt; with the &lt;code&gt;replacement_char&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f08303e15a79462237d5a6f5ab69bc0d741f795" translate="yes" xml:space="preserve">
          <source>Whether to rescale image values to be within &lt;code&gt;[0, 255]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d631ffee25c1c8d5962cb92c91bc7155c1b86dbc" translate="yes" xml:space="preserve">
          <source>Whether to rescale image values to be within &lt;code&gt;[0, 255]&lt;/code&gt;. Defaults to &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af90abadf38a68efbae5eab044cc111e83bae73f" translate="yes" xml:space="preserve">
          <source>Whether to restore model weights from the epoch with the best value of the monitored quantity. If False, the model weights obtained at the last step of training are used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf889dca2e1b92ac166e4e9099cdfdcbbe292012" translate="yes" xml:space="preserve">
          <source>Whether to save the GraphDef and MetaGraphDef to &lt;code&gt;checkpoint_dir&lt;/code&gt;. The GraphDef is saved after the session is created as &lt;code&gt;graph.pbtxt&lt;/code&gt;. MetaGraphDefs are saved out for every checkpoint as &lt;code&gt;model.ckpt-*.meta&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c75f3049cc336ca24bf2e733a248d74d9f9c0730" translate="yes" xml:space="preserve">
          <source>Whether to shuffle output samples, or instead draw them in chronological order.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34ea722ba14f3f99938856c7d83cff00e23dae81" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the data (default: True) If set to False, sorts the data in alphanumeric order.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="248b22a81980263fa482dd9c28f486987117fdb6" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the data. Default: True. If set to False, sorts the data in alphanumeric order.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cbcae28d63feefddbed17928b77788494d83948d" translate="yes" xml:space="preserve">
          <source>Whether to silently overwrite any existing file at the target location, or provide the user with a manual prompt.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="22ee2250a0c89ccf48c596cca64f08347b735454" translate="yes" xml:space="preserve">
          <source>Whether to start the standard services and the queue runners.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfad559685c1e01540d88fa4658891788a35c214" translate="yes" xml:space="preserve">
          <source>Whether to start the standard services, such as checkpoint, summary and step counter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4197ca406a3d4336b3bdffbd1a95b8c81b6a0d1" translate="yes" xml:space="preserve">
          <source>Whether to store intermediate values needed for gradients on the CPU instead of GPU.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f85068103e5372bea510e0ae9c69724c9d066b10" translate="yes" xml:space="preserve">
          <source>Whether to subtract &lt;code&gt;b&lt;/code&gt; from &lt;code&gt;a&lt;/code&gt;, vs vice versa.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10f6a87284583be6f6880d0e9062e36a3a101464" translate="yes" xml:space="preserve">
          <source>Whether to sum gradients from different replicas in the presense of &lt;a href=&quot;../../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt;. If False, it's user responsibility to aggregate the gradients. Default to True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72847fae2b2b235f6c8342af13371de425b6b16d" translate="yes" xml:space="preserve">
          <source>Whether to sum gradients from different replicas in the presense of &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt;. If False, it's user responsibility to aggregate the gradients. Default to True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bcc78610692aa1b78a0b8fce45e7b1a35f60fedd" translate="yes" xml:space="preserve">
          <source>Whether to unroll the RNN or to use a symbolic &lt;code&gt;while_loop&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8319c980207aacd2a41a4c25d0f4519649627a11" translate="yes" xml:space="preserve">
          <source>Whether to use &lt;a href=&quot;https://arxiv.org/abs/1702.03275&quot;&gt;Batch Renormalization&lt;/a&gt;. This adds extra variables during training. The inference is the same for either value of this parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd041b7a31c14b8f4c0154e4f0e31652d226ed84" translate="yes" xml:space="preserve">
          <source>Whether to use &lt;code&gt;ResourceVariable&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b32a3b0296e56c0857535ebb732043e2ca01eb48" translate="yes" xml:space="preserve">
          <source>Whether to use Batch Renormalization (Ioffe, 2017). This adds extra variables during training. The inference is the same for either value of this parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7ceb047bcc05fae84d262bcb0f0a4c42d80112e" translate="yes" xml:space="preserve">
          <source>Whether to use ChooseFastestBranchDataset with this transformation. If True, the pipeline picks between the vectorized and original segment at runtime based on their iterations speed. If None, defaults to False.</source>
          <target state="translated">Si usar o no el ChooseFastBranchDataset con esta transformación.Si es True,la tubería escoge entre el segmento vectorizado y el original en tiempo de ejecución basado en su velocidad de iteración.Si es None,por defecto es False.</target>
        </trans-unit>
        <trans-unit id="b41a583b4e8ecad70d2b783981605d5fb07b5daa" translate="yes" xml:space="preserve">
          <source>Whether to use an anti-aliasing filter when downsampling an image.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d7f954867443ea6a778475601ca4e3cc6e2dabd" translate="yes" xml:space="preserve">
          <source>Whether to use anti-aliasing when resizing. See 'image.resize()'.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c343c5190311c54955a31561f20b178e46089ae4" translate="yes" xml:space="preserve">
          <source>Whether to use autograph to compile python and eager style code for efficient graph-mode execution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ee94bf5c9ec84d6138e0ac95db29424ae3a5d6b" translate="yes" xml:space="preserve">
          <source>Whether to use batch normalization after each hidden layer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66b047600fb7cdf1794d2271af3d1f8a45f50c04" translate="yes" xml:space="preserve">
          <source>Whether to validate the order and range of sparse indices in &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77a0de4187b80648dee2790bc3e0723da8ae8a3a" translate="yes" xml:space="preserve">
          <source>Whether to validate the order and range of sparse indices in &lt;code&gt;a&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4f7ae19a819559a645d06cbc4b8c196628f89ca" translate="yes" xml:space="preserve">
          <source>Whether to vectorize map transformations. If None, defaults to False.</source>
          <target state="translated">Si es necesario vectorizar las transformaciones de los mapas.Si no hay ninguna,el valor por defecto es Falso.</target>
        </trans-unit>
        <trans-unit id="f123cab967534816dc9b84ddbe1b892a217e9a8b" translate="yes" xml:space="preserve">
          <source>Whether to visits subdirectories pointed to by symlinks. Defaults to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="081ce8e1451357f99365d88262e4c58272efd31e" translate="yes" xml:space="preserve">
          <source>Whether to wait for checkpoint to become available.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69219f557de4f53ff935206788ba0bcdb1a1ab26" translate="yes" xml:space="preserve">
          <source>Whether we should overwrite any existing model at the target location, or instead ask the user with a manual prompt.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63419d87417ca59c7ed9321136943312244206c5" translate="yes" xml:space="preserve">
          <source>Whether we should wait for the availability of a checkpoint before creating Session. Defaults to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbe339fdd2ca55a9615f6086f8ab79036c1a5e5d" translate="yes" xml:space="preserve">
          <source>Whether you are running on your machine or in the cluster you can use the following values for the --master flag:</source>
          <target state="translated">Ya sea que esté corriendo en su máquina o en el cúmulo,puede usar los siguientes valores para la bandera --master:</target>
        </trans-unit>
        <trans-unit id="3c232ac685e13a6b93f5f74209d44fc6f31c57d9" translate="yes" xml:space="preserve">
          <source>Which axis to join along. The default behavior is to join all elements, producing a scalar.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f517d8a1e3e3925fb5d9497fd0a8aca7ed0a886e" translate="yes" xml:space="preserve">
          <source>Which profile step to use for profiling.</source>
          <target state="translated">Qué paso de perfil usar para hacer el perfil.</target>
        </trans-unit>
        <trans-unit id="d86a5675cc6478e7030415aaa83cd72801292548" translate="yes" xml:space="preserve">
          <source>While</source>
          <target state="translated">While</target>
        </trans-unit>
        <trans-unit id="1c51ff24d93bea432325c091aee3e33a6598af2c" translate="yes" xml:space="preserve">
          <source>While &lt;a href=&quot;../../../keras/model#save_weights&quot;&gt;&lt;code&gt;tf.keras.Model.save_weights&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../../train/checkpoint#save&quot;&gt;&lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt;&lt;/a&gt; save in the same format, note that the root of the resulting checkpoint is the object the save method is attached to. This means saving a &lt;a href=&quot;../../../keras/model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; using &lt;code&gt;save_weights&lt;/code&gt; and loading into a &lt;a href=&quot;../../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; with a &lt;code&gt;Model&lt;/code&gt; attached (or vice versa) will not match the &lt;code&gt;Model&lt;/code&gt;'s variables. See the &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;guide to training checkpoints&lt;/a&gt; for details. Prefer &lt;a href=&quot;../../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; over &lt;a href=&quot;../../../keras/model#save_weights&quot;&gt;&lt;code&gt;tf.keras.Model.save_weights&lt;/code&gt;&lt;/a&gt; for training checkpoints.</source>
          <target state="translated">Si bien &lt;a href=&quot;../../../keras/model#save_weights&quot;&gt; &lt;code&gt;tf.keras.Model.save_weights&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;../../../train/checkpoint#save&quot;&gt; &lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt; &lt;/a&gt; guardan en el mismo formato, tenga en cuenta que la ra&amp;iacute;z del punto de control resultante es el objeto al que se adjunta el m&amp;eacute;todo de guardado. Esto significa que guardar un &lt;a href=&quot;../../../keras/model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; &lt;/a&gt; usando &lt;code&gt;save_weights&lt;/code&gt; y cargarlo en un &lt;a href=&quot;../../../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; con un &lt;code&gt;Model&lt;/code&gt; adjunto (o viceversa) no coincidir&amp;aacute; con las variables del &lt;code&gt;Model&lt;/code&gt; . Consulte la &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;gu&amp;iacute;a de puntos&lt;/a&gt; de control de entrenamiento para obtener m&amp;aacute;s detalles. Prefiere &lt;a href=&quot;../../../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; sobre &lt;a href=&quot;../../../keras/model#save_weights&quot;&gt; &lt;code&gt;tf.keras.Model.save_weights&lt;/code&gt; &lt;/a&gt; para los puntos de control de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="af5169034174d26fcbbcf3598b642bb6291299f0" translate="yes" xml:space="preserve">
          <source>While &lt;a href=&quot;../keras/model#save_weights&quot;&gt;&lt;code&gt;tf.keras.Model.save_weights&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;checkpoint#save&quot;&gt;&lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt;&lt;/a&gt; save in the same format, note that the root of the resulting checkpoint is the object the save method is attached to. This means saving a &lt;a href=&quot;../keras/model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; using &lt;code&gt;save_weights&lt;/code&gt; and loading into a &lt;a href=&quot;checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; with a &lt;code&gt;Model&lt;/code&gt; attached (or vice versa) will not match the &lt;code&gt;Model&lt;/code&gt;'s variables. See the &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;guide to training checkpoints&lt;/a&gt; for details. Prefer &lt;a href=&quot;checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; over &lt;a href=&quot;../keras/model#save_weights&quot;&gt;&lt;code&gt;tf.keras.Model.save_weights&lt;/code&gt;&lt;/a&gt; for training checkpoints.</source>
          <target state="translated">Si bien &lt;a href=&quot;../keras/model#save_weights&quot;&gt; &lt;code&gt;tf.keras.Model.save_weights&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;checkpoint#save&quot;&gt; &lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt; &lt;/a&gt; guardan en el mismo formato, tenga en cuenta que la ra&amp;iacute;z del punto de control resultante es el objeto al que se adjunta el m&amp;eacute;todo de guardado. Esto significa que guardar un &lt;a href=&quot;../keras/model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; &lt;/a&gt; usando &lt;code&gt;save_weights&lt;/code&gt; y cargarlo en un &lt;a href=&quot;checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; con un &lt;code&gt;Model&lt;/code&gt; adjunto (o viceversa) no coincidir&amp;aacute; con las variables del &lt;code&gt;Model&lt;/code&gt; . Consulte la &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;gu&amp;iacute;a de puntos&lt;/a&gt; de control de entrenamiento para obtener m&amp;aacute;s detalles. Prefiere &lt;a href=&quot;checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; sobre &lt;a href=&quot;../keras/model#save_weights&quot;&gt; &lt;code&gt;tf.keras.Model.save_weights&lt;/code&gt; &lt;/a&gt; para los puntos de control de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="df92ff2e348ec38c9d24bb6a65e3a867cbde6530" translate="yes" xml:space="preserve">
          <source>While &lt;code&gt;fn&lt;/code&gt; is running in the critical section, no other functions which wish to use this critical section may run.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="721826e30de58e9f292f39ea411e1bcf62df9289" translate="yes" xml:space="preserve">
          <source>While it is possible to use Variables with Lambda layers, this practice is discouraged as it can easily lead to bugs. For instance, consider the following layer:</source>
          <target state="translated">Si bien es posible utilizar variables con capas Lambda,esta práctica se desaconseja ya que puede conducir fácilmente a los bichos.Por ejemplo,consideremos la siguiente capa:</target>
        </trans-unit>
        <trans-unit id="b7ab51f21fc0c3654c10e148c98ad2c3c102cbcf" translate="yes" xml:space="preserve">
          <source>While the formats are the same, do not mix &lt;code&gt;save_weights&lt;/code&gt; and &lt;a href=&quot;../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt;. Checkpoints saved by &lt;a href=&quot;../model#save_weights&quot;&gt;&lt;code&gt;Model.save_weights&lt;/code&gt;&lt;/a&gt; should be loaded using &lt;a href=&quot;../model#load_weights&quot;&gt;&lt;code&gt;Model.load_weights&lt;/code&gt;&lt;/a&gt;. Checkpoints saved using &lt;a href=&quot;../../train/checkpoint#save&quot;&gt;&lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt;&lt;/a&gt; should be restored using the corresponding &lt;a href=&quot;../../train/checkpoint#restore&quot;&gt;&lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt;&lt;/a&gt;. Prefer &lt;a href=&quot;../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; over &lt;code&gt;save_weights&lt;/code&gt; for training checkpoints.</source>
          <target state="translated">Si bien los formatos son los mismos, no mezcle &lt;code&gt;save_weights&lt;/code&gt; y &lt;a href=&quot;../../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; . Los puntos de control guardados por &lt;a href=&quot;../model#save_weights&quot;&gt; &lt;code&gt;Model.save_weights&lt;/code&gt; &lt;/a&gt; deben cargarse mediante &lt;a href=&quot;../model#load_weights&quot;&gt; &lt;code&gt;Model.load_weights&lt;/code&gt; &lt;/a&gt; . Los puntos de control guardados usando &lt;a href=&quot;../../train/checkpoint#save&quot;&gt; &lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt; &lt;/a&gt; deben restaurarse usando el &lt;a href=&quot;../../train/checkpoint#restore&quot;&gt; &lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt; &lt;/a&gt; correspondiente . Prefiere &lt;a href=&quot;../../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; sobre &lt;code&gt;save_weights&lt;/code&gt; para los puntos de control de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="4d3c899f37d2d7cda82e12e4a5abbb5d78c486a6" translate="yes" xml:space="preserve">
          <source>While the formats are the same, do not mix &lt;code&gt;save_weights&lt;/code&gt; and &lt;a href=&quot;../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt;. Checkpoints saved by &lt;a href=&quot;model#save_weights&quot;&gt;&lt;code&gt;Model.save_weights&lt;/code&gt;&lt;/a&gt; should be loaded using &lt;a href=&quot;model#load_weights&quot;&gt;&lt;code&gt;Model.load_weights&lt;/code&gt;&lt;/a&gt;. Checkpoints saved using &lt;a href=&quot;../train/checkpoint#save&quot;&gt;&lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt;&lt;/a&gt; should be restored using the corresponding &lt;a href=&quot;../train/checkpoint#restore&quot;&gt;&lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt;&lt;/a&gt;. Prefer &lt;a href=&quot;../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; over &lt;code&gt;save_weights&lt;/code&gt; for training checkpoints.</source>
          <target state="translated">Si bien los formatos son los mismos, no mezcle &lt;code&gt;save_weights&lt;/code&gt; y &lt;a href=&quot;../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; . Los puntos de control guardados por &lt;a href=&quot;model#save_weights&quot;&gt; &lt;code&gt;Model.save_weights&lt;/code&gt; &lt;/a&gt; deben cargarse mediante &lt;a href=&quot;model#load_weights&quot;&gt; &lt;code&gt;Model.load_weights&lt;/code&gt; &lt;/a&gt; . Los puntos de control guardados usando &lt;a href=&quot;../train/checkpoint#save&quot;&gt; &lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt; &lt;/a&gt; deben restaurarse usando el &lt;a href=&quot;../train/checkpoint#restore&quot;&gt; &lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt; &lt;/a&gt; correspondiente . Prefiere &lt;a href=&quot;../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; sobre &lt;code&gt;save_weights&lt;/code&gt; para los puntos de control de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="0b0e77019b80f4349b00c82de8efee158e5fc102" translate="yes" xml:space="preserve">
          <source>While using distribution strategies, all the variable creation should be done within the strategy's scope. This will replicate the variables across all the replicas and keep them in sync using an all-reduce algorithm.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f64f547104eca8ffa08df75b0d127da08fb96ecc" translate="yes" xml:space="preserve">
          <source>While using distribution strategies, the variables created within strategy's scope will be replicated across all the replicas and can be kept in sync using all-reduce algorithms.</source>
          <target state="translated">Al utilizar las estrategias de distribución,las variables creadas dentro del alcance de la estrategia se replicarán en todas las réplicas y pueden mantenerse en sincronía utilizando algoritmos de reducción total.</target>
        </trans-unit>
        <trans-unit id="3d98a83dc2837ad96d068975c35687e2b85ed52c" translate="yes" xml:space="preserve">
          <source>While using distribution strategies, the variables created within the strategy's scope will be replicated across all the replicas and can be kept in sync using all-reduce algorithms.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d21e39cec1dbe57a37b90b0658bf80c4c7b4e18" translate="yes" xml:space="preserve">
          <source>WholeFileReader</source>
          <target state="translated">WholeFileReader</target>
        </trans-unit>
        <trans-unit id="c10e00cc1061d25c1e75d6a6c9f37b8de149d520" translate="yes" xml:space="preserve">
          <source>WholeFileReaderV2</source>
          <target state="translated">WholeFileReaderV2</target>
        </trans-unit>
        <trans-unit id="4bc1c4e835b1b69225a6dcb4af4e28a2c06f52c5" translate="yes" xml:space="preserve">
          <source>Wide &amp;amp; Deep Model for regression and classification problems.</source>
          <target state="translated">Modelo amplio y profundo para problemas de regresi&amp;oacute;n y clasificaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="ce79ee760dc1e0dcf6f5314aeb909e856d4d894b" translate="yes" xml:space="preserve">
          <source>Width Multiplier (alpha) | ImageNet Acc | Multiply-Adds (M) | Params (M)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="681d52e4c1304a1ea24152480eaca88c3ee9ae33" translate="yes" xml:space="preserve">
          <source>Width of output image.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c58a6d122599315399444067e820708cd4baecf" translate="yes" xml:space="preserve">
          <source>Width of the result.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="664add438097fbd4307f814de8e62a10f8905588" translate="yes" xml:space="preserve">
          <source>Wikipedia</source>
          <target state="translated">Wikipedia</target>
        </trans-unit>
        <trans-unit id="f1e4a70a64ee6594b6f0a462b10bce93878f9218" translate="yes" xml:space="preserve">
          <source>Will NOT work in 2.x:</source>
          <target state="translated">NO funcionará en 2.x:</target>
        </trans-unit>
        <trans-unit id="1c0b2946d9427a7aeee307da8f37197ad5dcc849" translate="yes" xml:space="preserve">
          <source>Will dequeue a work unit from queue if necessary (e.g. when the Reader needs to start reading from a new file since it has finished with the previous file).</source>
          <target state="translated">Desconectará una unidad de trabajo de la cola si es necesario (por ejemplo,cuando el Lector necesita empezar a leer de un nuevo archivo ya que ha terminado con el archivo anterior).</target>
        </trans-unit>
        <trans-unit id="a8c3a8bad2b347c018d978650b0ad1f0a7153646" translate="yes" xml:space="preserve">
          <source>Will dequeue a work unit from queue if necessary (e.g., when the Reader needs to start reading from a new file since it has finished with the previous file). It may return less than num_records even before the last batch.</source>
          <target state="translated">Desconectará una unidad de trabajo de la cola si es necesario (por ejemplo,cuando el Lector necesita empezar a leer de un nuevo archivo ya que ha terminado con el archivo anterior).Puede devolver menos que num_records incluso antes del último lote.</target>
        </trans-unit>
        <trans-unit id="4ba78cccf43ec749a3b3f63b99ca41d71764e130" translate="yes" xml:space="preserve">
          <source>Will dequeue from the input queue if necessary (e.g. when the Reader needs to start reading from a new file since it has finished with the previous file).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6ac5cb110e37a221155d9f3ad0cb5d4f454d263" translate="yes" xml:space="preserve">
          <source>Will dequeue from the input queue if necessary (e.g. when the Reader needs to start reading from a new file since it has finished with the previous file). It may return less than &lt;code&gt;num_records&lt;/code&gt; even before the last batch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="261f27a1f3bf63caf50878a078d18d17744de09c" translate="yes" xml:space="preserve">
          <source>Will make devices on the cluster available to use. Note that calling this more than once will work, but will invalidate any tensor handles on the old remote devices.</source>
          <target state="translated">hará que los dispositivos del grupo estén disponibles para su uso.Tengan en cuenta que llamar a esto más de una vez funcionará,pero invalidará los mandos de los tensores de los antiguos dispositivos remotos.</target>
        </trans-unit>
        <trans-unit id="f6897db1eb6c38899798f94d9b426756d03b49e8" translate="yes" xml:space="preserve">
          <source>Will make devices on the remote host available to use. Note that calling this more than once will work, but will invalidate any tensor handles on the old remote devices.</source>
          <target state="translated">hará que los dispositivos en el host remoto estén disponibles para su uso.Tengan en cuenta que llamar a esto más de una vez funcionará,pero invalidará cualquier control de tensor en los dispositivos remotos antiguos.</target>
        </trans-unit>
        <trans-unit id="b4a06c844340471315b54b0dfa65c9f440e60872" translate="yes" xml:space="preserve">
          <source>Will the SparseTensor &lt;code&gt;A&lt;/code&gt; fit in memory if densified?</source>
          <target state="translated">&amp;iquest;Cabr&amp;aacute; el SparseTensor &lt;code&gt;A&lt;/code&gt; en la memoria si se densifica?</target>
        </trans-unit>
        <trans-unit id="0922711fb24b94894ef90c6a73b66b5cfaf62cb6" translate="yes" xml:space="preserve">
          <source>Will work in 1.x and 2.x (though deprecated in 2.x):</source>
          <target state="translated">Funcionará en 1.x y 2.x (aunque depreciado en 2.x):</target>
        </trans-unit>
        <trans-unit id="ce21a08c1a63e9b77f2a1c614615c252ca550863" translate="yes" xml:space="preserve">
          <source>WindowDataset</source>
          <target state="translated">WindowDataset</target>
        </trans-unit>
        <trans-unit id="7969fd6214a6335899a24dac6e8f7bd3aba9e39c" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;A&lt;/code&gt; the dense representation of this &lt;code&gt;Operator&lt;/code&gt;,</source>
          <target state="translated">Con &lt;code&gt;A&lt;/code&gt; la representaci&amp;oacute;n densa de este &lt;code&gt;Operator&lt;/code&gt; ,</target>
        </trans-unit>
        <trans-unit id="ff9e0aefc629ac53bd25ea34ae417e2aeaf0766f" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;distribution=&quot;truncated_normal&quot; or &quot;untruncated_normal&quot;&lt;/code&gt;, samples are drawn from a truncated/untruncated normal distribution with a mean of zero and a standard deviation (after truncation, if used) &lt;code&gt;stddev = sqrt(scale / n)&lt;/code&gt; where n is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="234aca2d96fedfdf359061dabe09edd1bc5db7b3" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;distribution=&quot;truncated_normal&quot; or &quot;untruncated_normal&quot;&lt;/code&gt;, samples are drawn from a truncated/untruncated normal distribution with a mean of zero and a standard deviation (after truncation, if used) &lt;code&gt;stddev = sqrt(scale / n)&lt;/code&gt; where n is: - number of input units in the weight tensor, if mode = &quot;fan_in&quot; - number of output units, if mode = &quot;fan_out&quot; - average of the numbers of input and output units, if mode = &quot;fan_avg&quot;</source>
          <target state="translated">Con &lt;code&gt;distribution=&quot;truncated_normal&quot; or &quot;untruncated_normal&quot;&lt;/code&gt; , las muestras se extraen de una distribuci&amp;oacute;n normal truncada / no truncada con una media de cero y una desviaci&amp;oacute;n est&amp;aacute;ndar (despu&amp;eacute;s del truncamiento, si se usa) &lt;code&gt;stddev = sqrt(scale / n)&lt;/code&gt; donde n es: - n&amp;uacute;mero de unidades de entrada en el tensor de peso, si mode = &quot;fan_in&quot; - n&amp;uacute;mero de unidades de salida, si mode = &quot;fan_out&quot; - promedio del n&amp;uacute;mero de unidades de entrada y salida, si mode = &quot;fan_avg&quot;</target>
        </trans-unit>
        <trans-unit id="4f723d75a7c2fa1bd113ada83e2655f70f9292fe" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;distribution=&quot;truncated_normal&quot; or &quot;untruncated_normal&quot;&lt;/code&gt;, samples are drawn from a truncated/untruncated normal distribution with a mean of zero and a standard deviation (after truncation, if used) &lt;code&gt;stddev = sqrt(scale / n)&lt;/code&gt;, where &lt;code&gt;n&lt;/code&gt; is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ff32194c2a7d6162d325ca83d7afa7acc313404" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;distribution=&quot;uniform&quot;&lt;/code&gt;, samples are drawn from a uniform distribution within &lt;code&gt;[-limit, limit]&lt;/code&gt;, where &lt;code&gt;limit = sqrt(3 * scale / n)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5835e02899f12405b436a06a34c5acc97b07515" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;distribution=&quot;uniform&quot;&lt;/code&gt;, samples are drawn from a uniform distribution within [-limit, limit], with &lt;code&gt;limit = sqrt(3 * scale / n)&lt;/code&gt;.</source>
          <target state="translated">Con &lt;code&gt;distribution=&quot;uniform&quot;&lt;/code&gt; , las muestras se extraen de una distribuci&amp;oacute;n uniforme dentro de [-limit, l&amp;iacute;mite], con &lt;code&gt;limit = sqrt(3 * scale / n)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f8c1f4cf8df7060458ea559fb96747e733cc6916" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;height_shift_range=2&lt;/code&gt; possible values are integers &lt;code&gt;[-1, 0, +1]&lt;/code&gt;, same as with &lt;code&gt;height_shift_range=[-1, 0, +1]&lt;/code&gt;, while with &lt;code&gt;height_shift_range=1.0&lt;/code&gt; possible values are floats in the interval [-1.0, +1.0).</source>
          <target state="translated">Con &lt;code&gt;height_shift_range=2&lt;/code&gt; los valores posibles son enteros &lt;code&gt;[-1, 0, +1]&lt;/code&gt; , igual que con &lt;code&gt;height_shift_range=[-1, 0, +1]&lt;/code&gt; , mientras que con &lt;code&gt;height_shift_range=1.0&lt;/code&gt; los valores posibles son flotantes en el intervalo [-1.0, + 1.0).</target>
        </trans-unit>
        <trans-unit id="8d71d2aae030803f505395187c99c592d13d4623" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;preserve_aspect_ratio=True&lt;/code&gt;, the aspect ratio is preserved, so &lt;code&gt;size&lt;/code&gt; is the maximum for each dimension:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f0be93f34340dbd9dbce5872c897c11744e5be0" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;width_shift_range=2&lt;/code&gt; possible values are integers &lt;code&gt;[-1, 0, +1]&lt;/code&gt;, same as with &lt;code&gt;width_shift_range=[-1, 0, +1]&lt;/code&gt;, while with &lt;code&gt;width_shift_range=1.0&lt;/code&gt; possible values are floats in the interval [-1.0, +1.0).</source>
          <target state="translated">Con &lt;code&gt;width_shift_range=2&lt;/code&gt; valores posibles son n&amp;uacute;meros enteros &lt;code&gt;[-1, 0, +1]&lt;/code&gt; , igual que con &lt;code&gt;width_shift_range=[-1, 0, +1]&lt;/code&gt; , mientras que con &lt;code&gt;width_shift_range=1.0&lt;/code&gt; los valores posibles son flotantes en el intervalo [-1.0, + 1.0).</target>
        </trans-unit>
        <trans-unit id="b3c5ce075d1d1fd6a0d1aad83b3d8c72b5bbfb7b" translate="yes" xml:space="preserve">
          <source>With a 1 in 2 chance, outputs the contents of &lt;code&gt;image&lt;/code&gt; flipped along the first dimension, which is &lt;code&gt;height&lt;/code&gt;. Otherwise output the image as-is. When passing a batch of images, each image will be randomly flipped independent of other images.</source>
          <target state="translated">Con una probabilidad de 1 en 2, genera el contenido de la &lt;code&gt;image&lt;/code&gt; n volteado a lo largo de la primera dimensi&amp;oacute;n, que es la &lt;code&gt;height&lt;/code&gt; . De lo contrario, imprima la imagen tal como est&amp;aacute;. Al pasar un lote de im&amp;aacute;genes, cada imagen se voltear&amp;aacute; aleatoriamente independientemente de otras im&amp;aacute;genes.</target>
        </trans-unit>
        <trans-unit id="40d888cff933beb09db3d4f6596d9067e2878308" translate="yes" xml:space="preserve">
          <source>With a 1 in 2 chance, outputs the contents of &lt;code&gt;image&lt;/code&gt; flipped along the first dimension, which is &lt;code&gt;height&lt;/code&gt;. Otherwise, output the image as-is. When passing a batch of images, each image will be randomly flipped independent of other images.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dafbf9ee96525bc588fdd1a819189c2c04be4c99" translate="yes" xml:space="preserve">
          <source>With a 1 in 2 chance, outputs the contents of &lt;code&gt;image&lt;/code&gt; flipped along the second dimension, which is &lt;code&gt;width&lt;/code&gt;. Otherwise output the image as-is. When passing a batch of images, each image will be randomly flipped independent of other images.</source>
          <target state="translated">Con una probabilidad de 1 en 2, genera el contenido de la &lt;code&gt;image&lt;/code&gt; n volteado a lo largo de la segunda dimensi&amp;oacute;n, que es el &lt;code&gt;width&lt;/code&gt; . De lo contrario, imprima la imagen tal como est&amp;aacute;. Al pasar un lote de im&amp;aacute;genes, cada imagen se voltear&amp;aacute; aleatoriamente independientemente de otras im&amp;aacute;genes.</target>
        </trans-unit>
        <trans-unit id="eb0883b4bf2a7901f51949844c31237c43d86ecb" translate="yes" xml:space="preserve">
          <source>With a &lt;code&gt;Coordinator&lt;/code&gt;, exceptions are reported to the coordinator and forgotten by the &lt;code&gt;QueueRunner&lt;/code&gt;.</source>
          <target state="translated">Con un &lt;code&gt;Coordinator&lt;/code&gt; , las excepciones se informan al coordinador y &lt;code&gt;QueueRunner&lt;/code&gt; las olvida .</target>
        </trans-unit>
        <trans-unit id="bf97c0b53fe731e0899e5aa3d7d1c5c2588e5d9e" translate="yes" xml:space="preserve">
          <source>With default values, it returns element-wise &lt;code&gt;max(x, 0)&lt;/code&gt;.</source>
          <target state="translated">Con los valores predeterminados, devuelve &lt;code&gt;max(x, 0)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="db85e495eb55636b020a2a32657d103899296f2f" translate="yes" xml:space="preserve">
          <source>With default values, this returns the standard ReLU activation: &lt;code&gt;max(x, 0)&lt;/code&gt;, the element-wise maximum of 0 and the input tensor.</source>
          <target state="translated">Con valores predeterminados, esto devuelve la activaci&amp;oacute;n est&amp;aacute;ndar de ReLU: &lt;code&gt;max(x, 0)&lt;/code&gt; , el m&amp;aacute;ximo de elementos de 0 y el tensor de entrada.</target>
        </trans-unit>
        <trans-unit id="8620f83bce4d323fd62431b72a3e3cd320c09979" translate="yes" xml:space="preserve">
          <source>With eager execution disabled (by default in TensorFlow 1.x and by calling disable_eager_execution() in TensorFlow 2.x), the following syntax can be used:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7517aaf4d18e2c4d14a26fcfe70e076851f68b1" translate="yes" xml:space="preserve">
          <source>With eager execution this is a shape assertion, that returns the input:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f568c7dfa8797dfe677f7dd6f0a4ee1b0b5cbdba" translate="yes" xml:space="preserve">
          <source>With eager execution this operates as a shape assertion. Here the shapes match:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b2addb5c48d67261f0b9d05eab9810322d19c59" translate="yes" xml:space="preserve">
          <source>With forwardprop, we specify a length-three vector in advance which multiplies the Jacobian. The &lt;code&gt;primals&lt;/code&gt; constructor argument is the parameter (a &lt;a href=&quot;../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../variable&quot;&gt;&lt;code&gt;tf.Variable&lt;/code&gt;&lt;/a&gt;) we're specifying a vector for, and the &lt;code&gt;tangents&lt;/code&gt; argument is the &quot;vector&quot; in Jacobian-vector product. If our goal is to compute the entire Jacobian matrix, forwardprop computes one column at a time while backprop computes one row at a time. Since the Jacobian in the linear regression example has only one row, backprop requires fewer invocations:</source>
          <target state="translated">Con forwardprop, especificamos de antemano un vector de longitud tres que multiplica el jacobiano. El argumento del constructor &lt;code&gt;primals&lt;/code&gt; es el par&amp;aacute;metro (un &lt;a href=&quot;../tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; o &lt;a href=&quot;../variable&quot;&gt; &lt;code&gt;tf.Variable&lt;/code&gt; &lt;/a&gt; ) para el que estamos especificando un vector, y el argumento de &lt;code&gt;tangents&lt;/code&gt; es el &quot;vector&quot; en el producto de vector jacobiano. Si nuestro objetivo es calcular la matriz jacobiana completa, forwardprop calcula una columna a la vez, mientras que backprop calcula una fila a la vez. Dado que el jacobiano en el ejemplo de regresi&amp;oacute;n lineal tiene solo una fila, backprop requiere menos invocaciones:</target>
        </trans-unit>
        <trans-unit id="81932d1ace29ea95c92392af364f6a28c2c74781" translate="yes" xml:space="preserve">
          <source>With this definition, the gradient at x=100 will be correctly evaluated as 1.0.</source>
          <target state="translated">Con esta definición,el gradiente en x=100 será evaluado correctamente como 1.0.</target>
        </trans-unit>
        <trans-unit id="317a1dfdd7bd7e17378c7a66cabfcee42b3896df" translate="yes" xml:space="preserve">
          <source>With y = f(x), computes the theoretical and numeric Jacobian dy/dx.</source>
          <target state="translated">Con y=f(x),calcula el dy/dx jacobino teórico y numérico.</target>
        </trans-unit>
        <trans-unit id="659abe1496bd7876fc022d3e2b6b9cead33d30d8" translate="yes" xml:space="preserve">
          <source>Within a particular block, exactly one of these two things will be true:</source>
          <target state="translated">Dentro de un bloque en particular,exactamente una de estas dos cosas será verdad:</target>
        </trans-unit>
        <trans-unit id="13fe9d84fb92bd3745e88227dc1de58a44afddd1" translate="yes" xml:space="preserve">
          <source>Within a training loop, this argument sets how often host calls are performed during training. Host calls will be evaluated every n steps within a training loop where n is the value of this argument.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e7aeeddf89020677af5b4472b077bda01df8909" translate="yes" xml:space="preserve">
          <source>Within each worker, we will also split the data among all the worker devices (if more than one a present), and this will happen even if multi-worker sharding is disabled using the method above.</source>
          <target state="translated">Dentro de cada trabajador,también dividiremos los datos entre todos los dispositivos de los trabajadores (si hay más de uno presente),y esto ocurrirá incluso si se desactiva la fragmentación de varios trabajadores utilizando el método anterior.</target>
        </trans-unit>
        <trans-unit id="4d99119d2f84477c4512754d5e0fcbfbe0f69b29" translate="yes" xml:space="preserve">
          <source>Within the &lt;code&gt;with sv.managed_session()&lt;/code&gt; block all variables in the graph have been initialized. In addition, a few services have been started to checkpoint the model and add summaries to the event log.</source>
          <target state="translated">Dentro del &lt;code&gt;with sv.managed_session()&lt;/code&gt; , se han inicializado todas las variables del gr&amp;aacute;fico. Adem&amp;aacute;s, se han iniciado algunos servicios para controlar el modelo y agregar res&amp;uacute;menes al registro de eventos.</target>
        </trans-unit>
        <trans-unit id="ab6e550ba7dbaa5e409cc2c91f32bbe98623ef14" translate="yes" xml:space="preserve">
          <source>Without &lt;a href=&quot;set_seed&quot;&gt;&lt;code&gt;tf.random.set_seed&lt;/code&gt;&lt;/a&gt; but with a &lt;code&gt;seed&lt;/code&gt; argument is specified, small changes to function graphs or previously executed operations will change the returned value. See &lt;a href=&quot;set_seed&quot;&gt;&lt;code&gt;tf.random.set_seed&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">Sin &lt;a href=&quot;set_seed&quot;&gt; &lt;code&gt;tf.random.set_seed&lt;/code&gt; &lt;/a&gt; pero con un argumento &lt;code&gt;seed&lt;/code&gt; especificado, los peque&amp;ntilde;os cambios en los gr&amp;aacute;ficos de funciones o las operaciones ejecutadas previamente cambiar&amp;aacute;n el valor devuelto. Consulte &lt;a href=&quot;set_seed&quot;&gt; &lt;code&gt;tf.random.set_seed&lt;/code&gt; &lt;/a&gt; para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="c8ccb2ad531bd87f8226e54b9b6a39a6b2307357" translate="yes" xml:space="preserve">
          <source>Without a &lt;code&gt;Coordinator&lt;/code&gt;, exceptions are captured by the &lt;code&gt;QueueRunner&lt;/code&gt; and made available in this &lt;code&gt;exceptions_raised&lt;/code&gt; property.</source>
          <target state="translated">Sin un &lt;code&gt;Coordinator&lt;/code&gt; , las excepciones son capturadas por &lt;code&gt;QueueRunner&lt;/code&gt; y est&amp;aacute;n disponibles en esta propiedad &lt;code&gt;exceptions_raised&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e696e263864301b6aa5902a80a4d0bff70cd1786" translate="yes" xml:space="preserve">
          <source>Word embeddings</source>
          <target state="translated">Incrustaciones de palabras</target>
        </trans-unit>
        <trans-unit id="d98a4a13cdc22212a308bf1d89d6b7b049c03e2f" translate="yes" xml:space="preserve">
          <source>Worker devices vs. parameter devices: Most replica computations will happen on worker devices. Since we don't yet support model parallelism, there will be one worker device per replica. When using parameter servers or central storage, the set of devices holding variables may be different, otherwise the parameter devices might match the worker devices.</source>
          <target state="translated">Dispositivos de trabajo vs.dispositivos de parámetros:La mayoría de los cálculos de réplica se realizan en los dispositivos de los trabajadores.Como aún no apoyamos el paralelismo del modelo,habrá un dispositivo trabajador por réplica.Cuando se usan servidores de parámetros o almacenamiento central,el conjunto de dispositivos que contienen variables puede ser diferente,de lo contrario los dispositivos de parámetros podrían coincidir con los dispositivos trabajadores.</target>
        </trans-unit>
        <trans-unit id="e84ec097b7a7143f51f1fbc334ced683171b4c6c" translate="yes" xml:space="preserve">
          <source>Worker heartbeat op.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d20a3ffc32dcd238f452807ec295544fb73ee86b" translate="yes" xml:space="preserve">
          <source>WorkerHeartbeat</source>
          <target state="translated">WorkerHeartbeat</target>
        </trans-unit>
        <trans-unit id="398f69182b10972e971055c07ca464bed84b735b" translate="yes" xml:space="preserve">
          <source>Working with Bounding Boxes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51eeae9fe36f031b9bbc4e7ce891844c997b1b08" translate="yes" xml:space="preserve">
          <source>WrapDatasetVariant</source>
          <target state="translated">WrapDatasetVariant</target>
        </trans-unit>
        <trans-unit id="7a41e51968848ca6ebbc48f555f3248a673bee90" translate="yes" xml:space="preserve">
          <source>Wrapped inputs (identity standins that have additional metadata). These are also are also tf.Tensor's.</source>
          <target state="translated">Entradas envueltas (soportes de identidad que tienen metadatos adicionales).Estos también son también tf.Tensores.</target>
        </trans-unit>
        <trans-unit id="384f837341c0fc0fa71de4eb8e929b11e7daf27f" translate="yes" xml:space="preserve">
          <source>Wrapped outputs (identity standins that have additional metadata). These are also tf.Tensor's.</source>
          <target state="translated">Salidas envueltas (soportes de identidad que tienen metadatos adicionales).Estos también son tf.Tensores.</target>
        </trans-unit>
        <trans-unit id="a298562930ec81f39bad36c204ae1b1059782591" translate="yes" xml:space="preserve">
          <source>Wrapped values: In order to represent values parallel across devices (either replicas or the devices associated with a particular value), we wrap them in a &quot;PerReplica&quot; or &quot;Mirrored&quot; object that contains a map from replica id to values. &quot;PerReplica&quot; is used when the value may be different across replicas, and &quot;Mirrored&quot; when the value are the same.</source>
          <target state="translated">Valores envueltos:Para representar valores paralelos a través de dispositivos (ya sea réplicas o los dispositivos asociados con un valor particular),los envolvemos en un objeto &quot;PerReplica&quot; o &quot;Espejo&quot; que contiene un mapa desde la identificación de la réplica hasta los valores.&quot;PerReplica&quot; se usa cuando el valor puede ser diferente a través de las réplicas,y &quot;Mirrored&quot; cuando el valor es el mismo.</target>
        </trans-unit>
        <trans-unit id="890d066e219e9b18bb1c24edca8341903adbf397" translate="yes" xml:space="preserve">
          <source>Wrapper allowing a stack of RNN cells to behave as a single cell.</source>
          <target state="translated">Envoltura que permite que una pila de células RNN se comporte como una sola célula.</target>
        </trans-unit>
        <trans-unit id="b4013106a25f53b1f217b9c3881270bfb6839489" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;../../graph#add_to_collection&quot;&gt;&lt;code&gt;Graph.add_to_collection()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="translated">Wrapper para &lt;a href=&quot;../../graph#add_to_collection&quot;&gt; &lt;code&gt;Graph.add_to_collection()&lt;/code&gt; &lt;/a&gt; usando el gr&amp;aacute;fico predeterminado.</target>
        </trans-unit>
        <trans-unit id="caa4198da3fc275ac76081f0b3d1bfe03cdd54fe" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;../../graph#add_to_collections&quot;&gt;&lt;code&gt;Graph.add_to_collections()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="translated">Envoltorio para &lt;a href=&quot;../../graph#add_to_collections&quot;&gt; &lt;code&gt;Graph.add_to_collections()&lt;/code&gt; &lt;/a&gt; usando el gr&amp;aacute;fico predeterminado.</target>
        </trans-unit>
        <trans-unit id="264584356d25721fe348ac95a81a23f4cca709f4" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;../../graph#container&quot;&gt;&lt;code&gt;Graph.container()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="translated">Envoltorio para &lt;a href=&quot;../../graph#container&quot;&gt; &lt;code&gt;Graph.container()&lt;/code&gt; &lt;/a&gt; usando el gr&amp;aacute;fico predeterminado.</target>
        </trans-unit>
        <trans-unit id="55f30bd6389eac4a761d1daf54731878db305f29" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;../../graph#device&quot;&gt;&lt;code&gt;Graph.device()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="translated">Wrapper para &lt;a href=&quot;../../graph#device&quot;&gt; &lt;code&gt;Graph.device()&lt;/code&gt; &lt;/a&gt; usando el gr&amp;aacute;fico predeterminado.</target>
        </trans-unit>
        <trans-unit id="0d1e4b32d773cedbb0330530a2382ac0bddfaba8" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;../../graph#get_collection&quot;&gt;&lt;code&gt;Graph.get_collection()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="translated">Envoltorio para &lt;a href=&quot;../../graph#get_collection&quot;&gt; &lt;code&gt;Graph.get_collection()&lt;/code&gt; &lt;/a&gt; usando el gr&amp;aacute;fico predeterminado.</target>
        </trans-unit>
        <trans-unit id="190d7f80a83427a732312702b0799aa4fd4270f6" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;../../graph#get_collection_ref&quot;&gt;&lt;code&gt;Graph.get_collection_ref()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="translated">Envoltorio para &lt;a href=&quot;../../graph#get_collection_ref&quot;&gt; &lt;code&gt;Graph.get_collection_ref()&lt;/code&gt; &lt;/a&gt; usando el gr&amp;aacute;fico predeterminado.</target>
        </trans-unit>
        <trans-unit id="89aa6df88d5fbd573c88df4510194a5615a938d5" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;graph#control_dependencies&quot;&gt;&lt;code&gt;Graph.control_dependencies()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="translated">Envoltorio para &lt;a href=&quot;graph#control_dependencies&quot;&gt; &lt;code&gt;Graph.control_dependencies()&lt;/code&gt; &lt;/a&gt; usando el gr&amp;aacute;fico predeterminado.</target>
        </trans-unit>
        <trans-unit id="495b2dd43c40b93e9963a63ddff35ea9979905aa" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/Graph#add_to_collection&quot;&gt;&lt;code&gt;Graph.add_to_collection()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d79bebe0b09c5426685f0e539708d5d444124cc5" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/Graph#add_to_collections&quot;&gt;&lt;code&gt;Graph.add_to_collections()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="128db28adf836bfc21dd5fc549881d12855001a9" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/Graph#container&quot;&gt;&lt;code&gt;Graph.container()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="189fdde0fe51377c9c7df91b00d623f673fa3f34" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/Graph#device&quot;&gt;&lt;code&gt;Graph.device()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04af0f377456628e691bf3f85dc843ed001f5c1b" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/Graph#get_collection&quot;&gt;&lt;code&gt;Graph.get_collection()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bed252c3eb66e3bb7424c1c2a3122d3cfea4dfb8" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/Graph#get_collection_ref&quot;&gt;&lt;code&gt;Graph.get_collection_ref()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f37a810bede5b1390f81fea4b6be44aec37fbe5" translate="yes" xml:space="preserve">
          <source>Wrapper for using the Scikit-Learn API with Keras models.</source>
          <target state="translated">Envoltura para usar el API de Scikit-Learn con los modelos de Keras.</target>
        </trans-unit>
        <trans-unit id="1fff217e51e30156f66782f095344b6ef97a4794" translate="yes" xml:space="preserve">
          <source>Wrappers for primitive Neural Net (NN) Operations.</source>
          <target state="translated">Envoltorios para operaciones de redes neuronales primitivas (NN).</target>
        </trans-unit>
        <trans-unit id="7837b0cc643e2f001702979a842efc255ca9da70" translate="yes" xml:space="preserve">
          <source>Wrappers take another layer and augment it in various ways. Do not use this class as a layer, it is only an abstract base class. Two usable wrappers are the &lt;code&gt;TimeDistributed&lt;/code&gt; and &lt;code&gt;Bidirectional&lt;/code&gt; wrappers.</source>
          <target state="translated">Los envoltorios toman otra capa y la aumentan de varias maneras. No use esta clase como una capa, es solo una clase base abstracta. Dos envoltorios utilizables son los envoltorios &lt;code&gt;TimeDistributed&lt;/code&gt; y &lt;code&gt;Bidirectional&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3381242ca6a26b413c24d45326c44a72bdf78124" translate="yes" xml:space="preserve">
          <source>Wraps &lt;code&gt;call&lt;/code&gt;, applying pre- and post-processing steps.</source>
          <target state="translated">Envuelve la &lt;code&gt;call&lt;/code&gt; , aplicando los pasos de procesamiento previo y posterior.</target>
        </trans-unit>
        <trans-unit id="c62cdbd485fcae9d06ca69b5b8397cfed846cb17" translate="yes" xml:space="preserve">
          <source>Wraps a given text to a maximum line length and returns it.</source>
          <target state="translated">Envuelve un texto dado a una longitud máxima de línea y lo devuelve.</target>
        </trans-unit>
        <trans-unit id="8829b71bb0967a49348c7e7adf87bb1886403153" translate="yes" xml:space="preserve">
          <source>Wraps a python function and uses it as a TensorFlow op.</source>
          <target state="translated">Envuelve una función pitón y la usa como una operación de TensorFlow.</target>
        </trans-unit>
        <trans-unit id="8abaa30206e6292e5e70829b82947753e40ac335" translate="yes" xml:space="preserve">
          <source>Wraps a python function into a TensorFlow op that executes it eagerly.</source>
          <target state="translated">Envuelve una función pitón en una operación de TensorFlow que la ejecuta con entusiasmo.</target>
        </trans-unit>
        <trans-unit id="82ab6329b627d91bd83e44d4fe219ae9ac70441c" translate="yes" xml:space="preserve">
          <source>Wraps a value that may/may not be present at runtime.</source>
          <target state="translated">Envuelve un valor que puede/no puede estar presente en el tiempo de ejecución.</target>
        </trans-unit>
        <trans-unit id="19c9eb1de0862700ff8502bf5e2ae450855f9133" translate="yes" xml:space="preserve">
          <source>Wraps arbitrary expressions as a &lt;code&gt;Layer&lt;/code&gt; object.</source>
          <target state="translated">Envuelve expresiones arbitrarias como un objeto &lt;code&gt;Layer&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="352659d98f226f42ae5f9c0345757253d7e85e6e" translate="yes" xml:space="preserve">
          <source>Wraps the TF 1.x function fn into a graph function.</source>
          <target state="translated">Envuelve la función TF 1.x fn en una función gráfica.</target>
        </trans-unit>
        <trans-unit id="20b643b52957c38a95449d4001fccba2e0bcd12a" translate="yes" xml:space="preserve">
          <source>Write &lt;code&gt;value&lt;/code&gt; into index &lt;code&gt;index&lt;/code&gt; of the TensorArray.</source>
          <target state="translated">Escribe el &lt;code&gt;value&lt;/code&gt; en el &amp;iacute;ndice de &lt;code&gt;index&lt;/code&gt; de TensorArray.</target>
        </trans-unit>
        <trans-unit id="483cdae75a267d35fd6e83b5653511d5a80cff0f" translate="yes" xml:space="preserve">
          <source>Write a customized optimizer.</source>
          <target state="translated">Escriba un optimizador personalizado.</target>
        </trans-unit>
        <trans-unit id="c8c630765322886f9847c22284b5fa8d2851f2ce" translate="yes" xml:space="preserve">
          <source>Write a histogram summary.</source>
          <target state="translated">Escriba un resumen del histograma.</target>
        </trans-unit>
        <trans-unit id="b0075d853115d3caa9b112367f26a9151c343826" translate="yes" xml:space="preserve">
          <source>Write a scalar summary.</source>
          <target state="translated">Escriba un resumen escalar.</target>
        </trans-unit>
        <trans-unit id="76fe5c36d30ae305e5a6503ba46502eb4a13331d" translate="yes" xml:space="preserve">
          <source>Write a string record to the file.</source>
          <target state="translated">Escriba un registro de cadena en el archivo.</target>
        </trans-unit>
        <trans-unit id="5b53b6d51e993b431470b37c217c59753ff1cc50" translate="yes" xml:space="preserve">
          <source>Write a text summary.</source>
          <target state="translated">Escriba un resumen de texto.</target>
        </trans-unit>
        <trans-unit id="d21f1a898ccfeda0fe2e731850a28cfafae9bb2b" translate="yes" xml:space="preserve">
          <source>Write an audio summary.</source>
          <target state="translated">Escriba un resumen de audio.</target>
        </trans-unit>
        <trans-unit id="21a6eeb1ed26a2be90d3ee27390e8e2bda8c0962" translate="yes" xml:space="preserve">
          <source>Write an image summary.</source>
          <target state="translated">Escriba un resumen de la imagen.</target>
        </trans-unit>
        <trans-unit id="61f330bc93ccdaf24823ff722556ec64642374a9" translate="yes" xml:space="preserve">
          <source>Write data via Write and read via Read or Pack.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b36ad4c95f8d96567af24f9c3edf891e090ad84" translate="yes" xml:space="preserve">
          <source>Write the serialized data to one or more files</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a6db3a59303fe109b5b5137b804a970c912e147" translate="yes" xml:space="preserve">
          <source>Write this:</source>
          <target state="translated">Escriba esto:</target>
        </trans-unit>
        <trans-unit id="6226f3d4ff16e7406bb0cdaedd7746abc5236636" translate="yes" xml:space="preserve">
          <source>WriteAudioSummary</source>
          <target state="translated">WriteAudioSummary</target>
        </trans-unit>
        <trans-unit id="94dee2fafe1d10d5ce6db659eb0c0fcb3d5842be" translate="yes" xml:space="preserve">
          <source>WriteFile</source>
          <target state="translated">WriteFile</target>
        </trans-unit>
        <trans-unit id="1ea63605e83eb910f0b5d75fe28edb99127b24d1" translate="yes" xml:space="preserve">
          <source>WriteGraphSummary</source>
          <target state="translated">WriteGraphSummary</target>
        </trans-unit>
        <trans-unit id="e5637c5d46d26a2b2c82fac03d3b096952d4bf28" translate="yes" xml:space="preserve">
          <source>WriteHistogramSummary</source>
          <target state="translated">WriteHistogramSummary</target>
        </trans-unit>
        <trans-unit id="6b51491885b3d25ccb268be4c798a6b10e3d5b9d" translate="yes" xml:space="preserve">
          <source>WriteImageSummary</source>
          <target state="translated">WriteImageSummary</target>
        </trans-unit>
        <trans-unit id="4a572e40863e9455f5578aec02c3c8842448412b" translate="yes" xml:space="preserve">
          <source>WriteRawProtoSummary</source>
          <target state="translated">WriteRawProtoSummary</target>
        </trans-unit>
        <trans-unit id="88f81acb7e965e0b6b73b00739698ed9296482c6" translate="yes" xml:space="preserve">
          <source>WriteScalarSummary</source>
          <target state="translated">WriteScalarSummary</target>
        </trans-unit>
        <trans-unit id="cb73c41075bf3f01d3eb7791f75623bd77006f1a" translate="yes" xml:space="preserve">
          <source>WriteSummary</source>
          <target state="translated">WriteSummary</target>
        </trans-unit>
        <trans-unit id="29a4cf60a26ded7a2c3aed4855011f0c8495cfe3" translate="yes" xml:space="preserve">
          <source>Writes &lt;code&gt;MetaGraphDef&lt;/code&gt; to save_path/filename.</source>
          <target state="translated">Escribe &lt;code&gt;MetaGraphDef&lt;/code&gt; en save_path / filename.</target>
        </trans-unit>
        <trans-unit id="9fa9b02b6070f8899e280b451f66b6bd6b575f93" translate="yes" xml:space="preserve">
          <source>Writes &lt;code&gt;Summary&lt;/code&gt; protocol buffers to event files.</source>
          <target state="translated">Escribe b&amp;uacute;feres de protocolo de &lt;code&gt;Summary&lt;/code&gt; en archivos de eventos.</target>
        </trans-unit>
        <trans-unit id="babca584f4aae5499f0f80472fec83895337e06c" translate="yes" xml:space="preserve">
          <source>Writes a &lt;code&gt;SavedModel&lt;/code&gt; protocol buffer to disk.</source>
          <target state="translated">Escribe un &lt;code&gt;SavedModel&lt;/code&gt; protocolo SavedModel en el disco.</target>
        </trans-unit>
        <trans-unit id="ec531d54bcd6301e96265e18d2ce6d1e6c9a4e3b" translate="yes" xml:space="preserve">
          <source>Writes a dataset to a TFRecord file.</source>
          <target state="translated">Escribe un conjunto de datos en un archivo TFRecord.</target>
        </trans-unit>
        <trans-unit id="233cc84a3671355de983f6c125f1b2c0c8c7fc01" translate="yes" xml:space="preserve">
          <source>Writes a generic summary to the default SummaryWriter if one exists.</source>
          <target state="translated">Escribe un resumen genérico al SummaryWriter predeterminado,si existe.</target>
        </trans-unit>
        <trans-unit id="d15430e669e23755ec2b520aa11323169d62858a" translate="yes" xml:space="preserve">
          <source>Writes a graph proto to a file.</source>
          <target state="translated">Escribe un prototipo gráfico en un archivo.</target>
        </trans-unit>
        <trans-unit id="9976fe10182472bc6e870e0863e6f6d04fac02a5" translate="yes" xml:space="preserve">
          <source>Writes a set of weights into the opaque params buffer so they can be used in upcoming training or inferences.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0faccf4f9a4005aa59d77d68c1f6677070d11c1f" translate="yes" xml:space="preserve">
          <source>Writes a summary using raw &lt;a href=&quot;../../compat/v1/summary&quot;&gt;&lt;code&gt;tf.compat.v1.Summary&lt;/code&gt;&lt;/a&gt; protocol buffers.</source>
          <target state="translated">Escribe un resumen utilizando &lt;a href=&quot;../../compat/v1/summary&quot;&gt; &lt;code&gt;tf.compat.v1.Summary&lt;/code&gt; &lt;/a&gt; protocolo tf.compat.v1.Summary sin procesar .</target>
        </trans-unit>
        <trans-unit id="5adf0b1064881763cf04269a02e41a3ea90a5906" translate="yes" xml:space="preserve">
          <source>Writes a training checkpoint.</source>
          <target state="translated">Escribe un punto de control de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="f2b611268944160d96a5b9a8fcf79249e74eb83f" translate="yes" xml:space="preserve">
          <source>Writes contents to the file at input filename. Creates file and recursively</source>
          <target state="translated">Escribe el contenido del archivo en el nombre del archivo de entrada.Crea el archivo y recursivamente</target>
        </trans-unit>
        <trans-unit id="7fb1d95dfee1bc896877fefd9cbe8b4b9c44e0bf" translate="yes" xml:space="preserve">
          <source>Writes file_content to the file. Appends to the end of the file.</source>
          <target state="translated">Escribe file_content en el archivo.Se añade al final del archivo.</target>
        </trans-unit>
        <trans-unit id="a2ce6c85367b8678f1f61797d0dc74828b05ea19" translate="yes" xml:space="preserve">
          <source>Writes new value to variable's memory. Doesn't add ops to the graph.</source>
          <target state="translated">Escribe un nuevo valor en la memoria de la variable.No añade operaciones al gráfico.</target>
        </trans-unit>
        <trans-unit id="99b81ac6b0204ef18bee769984926a4ea6b12daf" translate="yes" xml:space="preserve">
          <source>Writes the given dataset to the given file using the TFRecord format.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45f84d521a5351104bc075acf3695dd6bad6898e" translate="yes" xml:space="preserve">
          <source>Writing custom layers and models with Keras</source>
          <target state="translated">Escribir capas y modelos personalizados con Keras</target>
        </trans-unit>
        <trans-unit id="c6a0c4f8b902d47bac80ddaf6bf34b2fbf4f9666" translate="yes" xml:space="preserve">
          <source>Xception V1 model for Keras.</source>
          <target state="translated">Modelo Xception V1 para Keras.</target>
        </trans-unit>
        <trans-unit id="1b60eef1486f042121cb1abb403bfa5983083402" translate="yes" xml:space="preserve">
          <source>Xdivy</source>
          <target state="translated">Xdivy</target>
        </trans-unit>
        <trans-unit id="9ed9396da589e127b120b5abc619086b34774295" translate="yes" xml:space="preserve">
          <source>Xlog1py</source>
          <target state="translated">Xlog1py</target>
        </trans-unit>
        <trans-unit id="12f9191163bb7e9e63172afc062b7b9642ca43a1" translate="yes" xml:space="preserve">
          <source>Xlogy</source>
          <target state="translated">Xlogy</target>
        </trans-unit>
        <trans-unit id="bccf09988d791dbda2da42e387167025b7d54ccb" translate="yes" xml:space="preserve">
          <source>YAML string or open file encoding a model configuration.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dfea80b5fe13bab375ae2dddcdd3dbb43f1a3633" translate="yes" xml:space="preserve">
          <source>Yann LeCun and Corinna Cortes hold the copyright of MNIST dataset, which is a derivative work from original NIST datasets. MNIST dataset is made available under the terms of the &lt;a href=&quot;https://creativecommons.org/licenses/by-sa/3.0/&quot;&gt;Creative Commons Attribution-Share Alike 3.0 license.&lt;/a&gt;</source>
          <target state="translated">Yann LeCun y Corinna Cortes poseen los derechos de autor del conjunto de datos MNIST, que es un trabajo derivado de los conjuntos de datos originales del NIST. El conjunto de datos MNIST est&amp;aacute; disponible bajo los t&amp;eacute;rminos de la &lt;a href=&quot;https://creativecommons.org/licenses/by-sa/3.0/&quot;&gt;licencia Creative Commons Attribution-Share Alike 3.0.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="738a2b66281e5ca4973cbceebc923d1996e03dad" translate="yes" xml:space="preserve">
          <source>Yields</source>
          <target state="translated">Yields</target>
        </trans-unit>
        <trans-unit id="f0d948a8bdb9eb6bb818e3240fb3b2534756d8f7" translate="yes" xml:space="preserve">
          <source>Yields predictions for given features.</source>
          <target state="translated">Hace predicciones para determinadas características.</target>
        </trans-unit>
        <trans-unit id="c970e3f1e790a2a4cd28b40401902501b9bc2d74" translate="yes" xml:space="preserve">
          <source>Yields:</source>
          <target state="translated">Yields:</target>
        </trans-unit>
        <trans-unit id="e930f451f4aa0e180bfec9e3ca9b3c51172a0d23" translate="yes" xml:space="preserve">
          <source>You can access a layer's regularization penalties by calling &lt;code&gt;layer.losses&lt;/code&gt; after calling the layer on inputs.</source>
          <target state="translated">Puede acceder a las penalizaciones de regularizaci&amp;oacute;n de una capa llamando a &lt;code&gt;layer.losses&lt;/code&gt; despu&amp;eacute;s de llamar a la capa en las entradas.</target>
        </trans-unit>
        <trans-unit id="59874a67ef5f7bd864b9ef3d3bb9393f8444ef02" translate="yes" xml:space="preserve">
          <source>You can access the raw &lt;a href=&quot;../session&quot;&gt;&lt;code&gt;tf.compat.v1.Session&lt;/code&gt;&lt;/a&gt; object used by &lt;code&gt;SingularMonitoredSession&lt;/code&gt;, whereas in MonitoredSession the raw session is private. This can be used:</source>
          <target state="translated">Puede acceder al objeto &lt;a href=&quot;../session&quot;&gt; &lt;code&gt;tf.compat.v1.Session&lt;/code&gt; &lt;/a&gt; sin procesar utilizado por &lt;code&gt;SingularMonitoredSession&lt;/code&gt; , mientras que en MonitoredSession la sesi&amp;oacute;n sin procesar es privada. Esto se puede utilizar:</target>
        </trans-unit>
        <trans-unit id="6ccb3baa3a0cbd712e9c239e9968fd1fb9ad400a" translate="yes" xml:space="preserve">
          <source>You can add an outer &lt;code&gt;batch&lt;/code&gt; axis by passing &lt;code&gt;axis=0&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7c18d1ca2444e96db7357ab3243c23ba7a401f2" translate="yes" xml:space="preserve">
          <source>You can also pass a &lt;a href=&quot;../../../../distribute/cluster_resolver/clusterresolver&quot;&gt;&lt;code&gt;distribute.cluster_resolver.ClusterResolver&lt;/code&gt;&lt;/a&gt; instance when instantiating the strategy. The task_type, task_id etc. will be parsed from the resolver instance instead of from the &lt;code&gt;TF_CONFIG&lt;/code&gt; env var.</source>
          <target state="translated">Tambi&amp;eacute;n puede pasar una instancia de &lt;a href=&quot;../../../../distribute/cluster_resolver/clusterresolver&quot;&gt; &lt;code&gt;distribute.cluster_resolver.ClusterResolver&lt;/code&gt; &lt;/a&gt; al crear una instancia de la estrategia. Task_type, task_id, etc. se analizar&amp;aacute;n desde la instancia de resoluci&amp;oacute;n en lugar de desde &lt;code&gt;TF_CONFIG&lt;/code&gt; env var.</target>
        </trans-unit>
        <trans-unit id="6e5fb70392b78f99083230f0a97aa193ef7fda3b" translate="yes" xml:space="preserve">
          <source>You can also pass a &lt;a href=&quot;../cluster_resolver/clusterresolver&quot;&gt;&lt;code&gt;distribute.cluster_resolver.ClusterResolver&lt;/code&gt;&lt;/a&gt; instance when instantiating the strategy. The task_type, task_id etc. will be parsed from the resolver instance instead of from the &lt;code&gt;TF_CONFIG&lt;/code&gt; env var.</source>
          <target state="translated">Tambi&amp;eacute;n puede pasar una instancia de &lt;a href=&quot;../cluster_resolver/clusterresolver&quot;&gt; &lt;code&gt;distribute.cluster_resolver.ClusterResolver&lt;/code&gt; &lt;/a&gt; al crear una instancia de la estrategia. Task_type, task_id, etc. se analizar&amp;aacute;n desde la instancia de resoluci&amp;oacute;n en lugar de desde &lt;code&gt;TF_CONFIG&lt;/code&gt; env var.</target>
        </trans-unit>
        <trans-unit id="5e1ab8575cb5168a5735bdcf646fbc24611fcf94" translate="yes" xml:space="preserve">
          <source>You can also pass a &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/distribute/cluster_resolver/ClusterResolver&quot;&gt;&lt;code&gt;distribute.cluster_resolver.ClusterResolver&lt;/code&gt;&lt;/a&gt; instance when instantiating the strategy. The task_type, task_id etc. will be parsed from the resolver instance instead of from the &lt;code&gt;TF_CONFIG&lt;/code&gt; env var.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea8ecb649a2869edbe22ed0fa4b60b444f6b3240" translate="yes" xml:space="preserve">
          <source>You can also pass the following additional pieces to the constructor:</source>
          <target state="translated">También puede pasar las siguientes piezas adicionales al constructor:</target>
        </trans-unit>
        <trans-unit id="beae5b5e28d39839a95e5dcf5642d815e8f5ff5c" translate="yes" xml:space="preserve">
          <source>You can also specify &lt;code&gt;config&lt;/code&gt; of the loss to this function by passing dict containing &lt;code&gt;class_name&lt;/code&gt; and &lt;code&gt;config&lt;/code&gt; as an identifier. Also note that the &lt;code&gt;class_name&lt;/code&gt; must map to a &lt;code&gt;Loss&lt;/code&gt; class</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c69555354a0bc222fe10d4f7bc39675e8b5f8158" translate="yes" xml:space="preserve">
          <source>You can also specify &lt;code&gt;config&lt;/code&gt; of the metric to this function by passing dict containing &lt;code&gt;class_name&lt;/code&gt; and &lt;code&gt;config&lt;/code&gt; as an identifier. Also note that the &lt;code&gt;class_name&lt;/code&gt; must map to a &lt;code&gt;Metric&lt;/code&gt; class</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52dc5982a3012b85661499626a8a8038241b7ffd" translate="yes" xml:space="preserve">
          <source>You can also use &lt;a href=&quot;py_function&quot;&gt;&lt;code&gt;tf.py_function&lt;/code&gt;&lt;/a&gt; to debug your models at runtime using Python tools, i.e., you can isolate portions of your code that you want to debug, wrap them in Python functions and insert &lt;code&gt;pdb&lt;/code&gt; tracepoints or print statements as desired, and wrap those functions in &lt;a href=&quot;py_function&quot;&gt;&lt;code&gt;tf.py_function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Tambi&amp;eacute;n puede usar &lt;a href=&quot;py_function&quot;&gt; &lt;code&gt;tf.py_function&lt;/code&gt; &lt;/a&gt; para depurar sus modelos en tiempo de ejecuci&amp;oacute;n usando herramientas de Python, es decir, puede aislar partes de su c&amp;oacute;digo que desea depurar, envolverlas en funciones de Python e insertar &lt;code&gt;pdb&lt;/code&gt; rastreo pdb o imprimir declaraciones como desee, y envolverlos funciones en &lt;a href=&quot;py_function&quot;&gt; &lt;code&gt;tf.py_function&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="6039b0dfd851cbc8275eabb888826394ae1b2ab1" translate="yes" xml:space="preserve">
          <source>You can also use the &lt;code&gt;element_spec&lt;/code&gt; property of the &lt;a href=&quot;../../../../distribute/distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; instance returned by this API to query the &lt;a href=&quot;../../../../typespec&quot;&gt;&lt;code&gt;tf.TypeSpec&lt;/code&gt;&lt;/a&gt; of the elements returned by the iterator. This can be used to set the &lt;code&gt;input_signature&lt;/code&gt; property of a &lt;a href=&quot;../../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6714d05f3ec58957845e4e02d40676c59a816f4" translate="yes" xml:space="preserve">
          <source>You can also use the &lt;code&gt;element_spec&lt;/code&gt; property of the &lt;a href=&quot;../../../../distribute/distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; returned by this API to query the &lt;a href=&quot;../../../../typespec&quot;&gt;&lt;code&gt;tf.TypeSpec&lt;/code&gt;&lt;/a&gt; of the elements returned by the iterator. This can be used to set the &lt;code&gt;input_signature&lt;/code&gt; property of a &lt;a href=&quot;../../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="153ea4bbc50ebf5e0a8403f29bb6788447deb11c" translate="yes" xml:space="preserve">
          <source>You can also use the &lt;code&gt;element_spec&lt;/code&gt; property of the &lt;a href=&quot;../../../distribute/distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; instance returned by this API to query the &lt;a href=&quot;../../../typespec&quot;&gt;&lt;code&gt;tf.TypeSpec&lt;/code&gt;&lt;/a&gt; of the elements returned by the iterator. This can be used to set the &lt;code&gt;input_signature&lt;/code&gt; property of a &lt;a href=&quot;../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ac6704fae664e72c4f0645536563ff0de5afe80" translate="yes" xml:space="preserve">
          <source>You can also use the &lt;code&gt;element_spec&lt;/code&gt; property of the &lt;a href=&quot;../../../distribute/distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; returned by this API to query the &lt;a href=&quot;../../../typespec&quot;&gt;&lt;code&gt;tf.TypeSpec&lt;/code&gt;&lt;/a&gt; of the elements returned by the iterator. This can be used to set the &lt;code&gt;input_signature&lt;/code&gt; property of a &lt;a href=&quot;../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dcaf3f8131e1ea14866dcfb7fa41b1b0194e1d80" translate="yes" xml:space="preserve">
          <source>You can also use the &lt;code&gt;element_spec&lt;/code&gt; property of the &lt;a href=&quot;../distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; instance returned by this API to query the &lt;a href=&quot;../../typespec&quot;&gt;&lt;code&gt;tf.TypeSpec&lt;/code&gt;&lt;/a&gt; of the elements returned by the iterator. This can be used to set the &lt;code&gt;input_signature&lt;/code&gt; property of a &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3385c4f6d32325dcf782cc9941db6f2f275241a0" translate="yes" xml:space="preserve">
          <source>You can also use the &lt;code&gt;element_spec&lt;/code&gt; property of the &lt;a href=&quot;../distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; returned by this API to query the &lt;a href=&quot;../../typespec&quot;&gt;&lt;code&gt;tf.TypeSpec&lt;/code&gt;&lt;/a&gt; of the elements returned by the iterator. This can be used to set the &lt;code&gt;input_signature&lt;/code&gt; property of a &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68d5075223b70a3c64aec568d9f4b72b9521b3e8" translate="yes" xml:space="preserve">
          <source>You can also use the &lt;code&gt;element_spec&lt;/code&gt; property of the &lt;a href=&quot;distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; instance returned by this API to query the &lt;a href=&quot;../typespec&quot;&gt;&lt;code&gt;tf.TypeSpec&lt;/code&gt;&lt;/a&gt; of the elements returned by the iterator. This can be used to set the &lt;code&gt;input_signature&lt;/code&gt; property of a &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3234565ee9ebae226cb6498a83d504945b3da8d1" translate="yes" xml:space="preserve">
          <source>You can also use the &lt;code&gt;element_spec&lt;/code&gt; property of the &lt;a href=&quot;distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; returned by this API to query the &lt;a href=&quot;../typespec&quot;&gt;&lt;code&gt;tf.TypeSpec&lt;/code&gt;&lt;/a&gt; of the elements returned by the iterator. This can be used to set the &lt;code&gt;input_signature&lt;/code&gt; property of a &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9bf7e26d5c0cf51e4e4917f1eb23c3d37328691" translate="yes" xml:space="preserve">
          <source>You can cast a Keras variable but it still returns a Keras tensor.</source>
          <target state="translated">Puedes lanzar una variable Keras pero aún así devuelve un tensor Keras.</target>
        </trans-unit>
        <trans-unit id="3a3ea187f9997f3359ee54a5e203867aab3b8b27" translate="yes" xml:space="preserve">
          <source>You can create a &lt;a href=&quot;distributediterator&quot;&gt;&lt;code&gt;tf.distribute.DistributedIterator&lt;/code&gt;&lt;/a&gt; by calling &lt;code&gt;iter&lt;/code&gt; on a &lt;a href=&quot;distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; or creating a python loop over a &lt;a href=&quot;distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c77d6bc9128a9a471ae009d158974ccffab599c2" translate="yes" xml:space="preserve">
          <source>You can disable dataset sharding across workers using the &lt;code&gt;auto_shard&lt;/code&gt; option in &lt;a href=&quot;../../../../data/experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Puede desactivar conjunto de datos sharding trav&amp;eacute;s de los trabajadores que utilizan el &lt;code&gt;auto_shard&lt;/code&gt; opci&amp;oacute;n en &lt;a href=&quot;../../../../data/experimental/distributeoptions&quot;&gt; &lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="abcd404b6ec568dc3b6a192e74ff39fd2a467efc" translate="yes" xml:space="preserve">
          <source>You can disable dataset sharding across workers using the &lt;code&gt;auto_shard&lt;/code&gt; option in &lt;a href=&quot;../../../data/experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Puede desactivar conjunto de datos sharding trav&amp;eacute;s de los trabajadores que utilizan el &lt;code&gt;auto_shard&lt;/code&gt; opci&amp;oacute;n en &lt;a href=&quot;../../../data/experimental/distributeoptions&quot;&gt; &lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="755b5985c40de671a4eb4bfb403b9e1a2cab5a03" translate="yes" xml:space="preserve">
          <source>You can disable dataset sharding across workers using the &lt;code&gt;auto_shard&lt;/code&gt; option in &lt;a href=&quot;../../data/experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Puede desactivar conjunto de datos sharding trav&amp;eacute;s de los trabajadores que utilizan el &lt;code&gt;auto_shard&lt;/code&gt; opci&amp;oacute;n en &lt;a href=&quot;../../data/experimental/distributeoptions&quot;&gt; &lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="823e308b708edca072a13279a53e3cee2ec00199" translate="yes" xml:space="preserve">
          <source>You can disable dataset sharding across workers using the &lt;code&gt;auto_shard&lt;/code&gt; option in &lt;a href=&quot;../data/experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Puede desactivar conjunto de datos sharding trav&amp;eacute;s de los trabajadores que utilizan el &lt;code&gt;auto_shard&lt;/code&gt; opci&amp;oacute;n en &lt;a href=&quot;../data/experimental/distributeoptions&quot;&gt; &lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="77348208b8f388d909966c4b5fc03169d2df6ba3" translate="yes" xml:space="preserve">
          <source>You can find more information about TensorBoard &lt;a href=&quot;https://www.tensorflow.org/get_started/summaries_and_tensorboard&quot;&gt;here&lt;/a&gt;.</source>
          <target state="translated">Puede encontrar m&amp;aacute;s informaci&amp;oacute;n sobre TensorBoard &lt;a href=&quot;https://www.tensorflow.org/get_started/summaries_and_tensorboard&quot;&gt;aqu&amp;iacute;&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0be849f93096dd779e7a88c6ab36a4f32c9e43a7" translate="yes" xml:space="preserve">
          <source>You can implement 'SUM_OVER_BATCH_SIZE' using global batch size like:</source>
          <target state="translated">Puedes implementar 'SUM_OVER_BATCH_SIZE' usando el tamaño del lote global como:</target>
        </trans-unit>
        <trans-unit id="afa5195343dbaa120879b06f025ea84ad87e6a32" translate="yes" xml:space="preserve">
          <source>You can modify the operations in place, but modifications to the list such as inserts/delete have no effect on the list of operations known to the graph.</source>
          <target state="translated">Puede modificar las operaciones en su lugar,pero las modificaciones de la lista como insertar/eliminar no tienen ningún efecto en la lista de operaciones conocida por el gráfico.</target>
        </trans-unit>
        <trans-unit id="1c3d65193eb861cca9fdcde225478e0055db490e" translate="yes" xml:space="preserve">
          <source>You can now use table in functions like &lt;a href=&quot;../../../nn/embedding_lookup&quot;&gt;&lt;code&gt;tf.nn.embedding_lookup&lt;/code&gt;&lt;/a&gt; to perform your embedding lookup and pass to your model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c02260f75018990666dbe2089789cfb29e9e718" translate="yes" xml:space="preserve">
          <source>You can pass None to clear the control dependencies:</source>
          <target state="translated">Puedes pasar Ninguno para despejar las dependencias de control:</target>
        </trans-unit>
        <trans-unit id="215f1df4bc1261bbb6f65d825790eea599447ab5" translate="yes" xml:space="preserve">
          <source>You can pass any of the returned values to &lt;code&gt;restore()&lt;/code&gt;.</source>
          <target state="translated">Puede pasar cualquiera de los valores devueltos a &lt;code&gt;restore()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ac470d84ff347998661ececab5ea81ac9cc6a909" translate="yes" xml:space="preserve">
          <source>You can pass the result of evaluating any summary op, using &lt;code&gt;tf.Session.run&lt;/code&gt; or &lt;a href=&quot;../../../tensor#eval&quot;&gt;&lt;code&gt;tf.Tensor.eval&lt;/code&gt;&lt;/a&gt;, to this function. Alternatively, you can pass a &lt;a href=&quot;../summary&quot;&gt;&lt;code&gt;tf.compat.v1.Summary&lt;/code&gt;&lt;/a&gt; protocol buffer that you populate with your own data. The latter is commonly done to report evaluation results in event files.</source>
          <target state="translated">Puede pasar el resultado de evaluar cualquier &lt;code&gt;tf.Session.run&lt;/code&gt; resumen, usando tf.Session.run o &lt;a href=&quot;../../../tensor#eval&quot;&gt; &lt;code&gt;tf.Tensor.eval&lt;/code&gt; &lt;/a&gt; , a esta funci&amp;oacute;n. Alternativamente, puede pasar un &lt;a href=&quot;../summary&quot;&gt; &lt;code&gt;tf.compat.v1.Summary&lt;/code&gt; &lt;/a&gt; protocolo tf.compat.v1.Summary que llena con sus propios datos. Esto &amp;uacute;ltimo se hace com&amp;uacute;nmente para informar los resultados de la evaluaci&amp;oacute;n en archivos de eventos.</target>
        </trans-unit>
        <trans-unit id="69155a67a44012b4f51b2dc8d0ccd534aa7907a1" translate="yes" xml:space="preserve">
          <source>You can pass this schedule directly into a &lt;a href=&quot;../optimizer&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt;&lt;/a&gt; as the learning rate. Example: Fit a Keras model when decaying 1/t with a rate of 0.5:</source>
          <target state="translated">Puede pasar este horario directamente a un &lt;a href=&quot;../optimizer&quot;&gt; &lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt; &lt;/a&gt; como la tasa de aprendizaje. Ejemplo: ajuste un modelo de Keras cuando decae 1 / t con una tasa de 0,5:</target>
        </trans-unit>
        <trans-unit id="48f5a8f4038134ce54531b0e709a77dbf5681703" translate="yes" xml:space="preserve">
          <source>You can pass this schedule directly into a &lt;a href=&quot;../optimizer&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt;&lt;/a&gt; as the learning rate. Example: Fit a model while decaying from 0.1 to 0.01 in 10000 steps using sqrt (i.e. power=0.5):</source>
          <target state="translated">Puede pasar este horario directamente a un &lt;a href=&quot;../optimizer&quot;&gt; &lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt; &lt;/a&gt; como la tasa de aprendizaje. Ejemplo: ajuste un modelo mientras decae de 0.1 a 0.01 en 10000 pasos usando sqrt (es decir, potencia = 0.5):</target>
        </trans-unit>
        <trans-unit id="40b491f9b541bdf48952295bf5d5a0ca64ae94b3" translate="yes" xml:space="preserve">
          <source>You can pass this schedule directly into a &lt;a href=&quot;../optimizer&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt;&lt;/a&gt; as the learning rate. Example: When fitting a Keras model, decay every 100000 steps with a base of 0.96:</source>
          <target state="translated">Puede pasar este horario directamente a un &lt;a href=&quot;../optimizer&quot;&gt; &lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt; &lt;/a&gt; como la tasa de aprendizaje. Ejemplo: al ajustar un modelo de Keras, decae cada 100000 pasos con una base de 0,96:</target>
        </trans-unit>
        <trans-unit id="573311646e6161dd40916f132e58fdf271d90b7d" translate="yes" xml:space="preserve">
          <source>You can pass this schedule directly into a &lt;a href=&quot;../optimizer&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt;&lt;/a&gt; as the learning rate. The learning rate schedule is also serializable and deserializable using &lt;a href=&quot;serialize&quot;&gt;&lt;code&gt;tf.keras.optimizers.schedules.serialize&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;deserialize&quot;&gt;&lt;code&gt;tf.keras.optimizers.schedules.deserialize&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Puede pasar este horario directamente a un &lt;a href=&quot;../optimizer&quot;&gt; &lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt; &lt;/a&gt; como la tasa de aprendizaje. El programa de velocidad de aprendizaje tambi&amp;eacute;n se puede serializar y deserializar mediante &lt;a href=&quot;serialize&quot;&gt; &lt;code&gt;tf.keras.optimizers.schedules.serialize&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;deserialize&quot;&gt; &lt;code&gt;tf.keras.optimizers.schedules.deserialize&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="5458dcea309d742dc1ae87c297fbd433242a68c9" translate="yes" xml:space="preserve">
          <source>You can pass this schedule directly into a &lt;a href=&quot;../optimizers/optimizer&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt;&lt;/a&gt; as the learning rate. The learning rate schedule is also serializable and deserializable using &lt;a href=&quot;../optimizers/schedules/serialize&quot;&gt;&lt;code&gt;tf.keras.optimizers.schedules.serialize&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../optimizers/schedules/deserialize&quot;&gt;&lt;code&gt;tf.keras.optimizers.schedules.deserialize&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Puede pasar este horario directamente a un &lt;a href=&quot;../optimizers/optimizer&quot;&gt; &lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt; &lt;/a&gt; como la tasa de aprendizaje. El programa de velocidad de aprendizaje tambi&amp;eacute;n se puede serializar y deserializar mediante &lt;a href=&quot;../optimizers/schedules/serialize&quot;&gt; &lt;code&gt;tf.keras.optimizers.schedules.serialize&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;../optimizers/schedules/deserialize&quot;&gt; &lt;code&gt;tf.keras.optimizers.schedules.deserialize&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="154d72e5d23674ce441818a8ed845bb4df350073" translate="yes" xml:space="preserve">
          <source>You can provide logits of classes as &lt;code&gt;y_pred&lt;/code&gt;, since argmax of logits and probabilities are same.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0779a4d81e795874a050ef63a764491cc356c1c7" translate="yes" xml:space="preserve">
          <source>You can return from this call a &lt;code&gt;SessionRunArgs&lt;/code&gt; object indicating ops or tensors to add to the upcoming &lt;code&gt;run()&lt;/code&gt; call. These ops/tensors will be run together with the ops/tensors originally passed to the original run() call. The run args you return can also contain feeds to be added to the run() call.</source>
          <target state="translated">Puede regresar de esta llamada a un objeto &lt;code&gt;SessionRunArgs&lt;/code&gt; que indique ops o tensores para agregar a la pr&amp;oacute;xima llamada &lt;code&gt;run()&lt;/code&gt; . Estos ops / tensors se ejecutar&amp;aacute;n junto con los ops / tensors originalmente pasados ​​a la llamada original run (). Los argumentos de ejecuci&amp;oacute;n que devuelve tambi&amp;eacute;n pueden contener feeds que se agregar&amp;aacute;n a la llamada run ().</target>
        </trans-unit>
        <trans-unit id="9ae0a59fa6ec6a5af526342b6817b045dd0db4e8" translate="yes" xml:space="preserve">
          <source>You can set the distribution options of a dataset through the &lt;code&gt;experimental_distribute&lt;/code&gt; property of &lt;a href=&quot;../options&quot;&gt;&lt;code&gt;tf.data.Options&lt;/code&gt;&lt;/a&gt;; the property is an instance of &lt;a href=&quot;distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Puede configurar las opciones de distribuci&amp;oacute;n de un conjunto de datos mediante la propiedad &lt;code&gt;experimental_distribute&lt;/code&gt; de &lt;a href=&quot;../options&quot;&gt; &lt;code&gt;tf.data.Options&lt;/code&gt; &lt;/a&gt; ; la propiedad es una instancia de &lt;a href=&quot;distributeoptions&quot;&gt; &lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="38287133e2e375cb065b8aff1223591e0429addd" translate="yes" xml:space="preserve">
          <source>You can set the optimization options of a dataset through the &lt;code&gt;experimental_optimization&lt;/code&gt; property of &lt;a href=&quot;../options&quot;&gt;&lt;code&gt;tf.data.Options&lt;/code&gt;&lt;/a&gt;; the property is an instance of &lt;a href=&quot;optimizationoptions&quot;&gt;&lt;code&gt;tf.data.experimental.OptimizationOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Puede configurar las opciones de optimizaci&amp;oacute;n de un conjunto de datos a trav&amp;eacute;s de la propiedad &lt;code&gt;experimental_optimization&lt;/code&gt; de &lt;a href=&quot;../options&quot;&gt; &lt;code&gt;tf.data.Options&lt;/code&gt; &lt;/a&gt; ; la propiedad es una instancia de &lt;a href=&quot;optimizationoptions&quot;&gt; &lt;code&gt;tf.data.experimental.OptimizationOptions&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="a4942db36ae427216d9ed0a514b6b4124827857d" translate="yes" xml:space="preserve">
          <source>You can set the stats options of a dataset through the &lt;code&gt;experimental_stats&lt;/code&gt; property of &lt;a href=&quot;../options&quot;&gt;&lt;code&gt;tf.data.Options&lt;/code&gt;&lt;/a&gt;; the property is an instance of &lt;a href=&quot;statsoptions&quot;&gt;&lt;code&gt;tf.data.experimental.StatsOptions&lt;/code&gt;&lt;/a&gt;. For example, to collect latency stats on all dataset edges, use the following pattern:</source>
          <target state="translated">Puede configurar las opciones de estad&amp;iacute;sticas de un conjunto de datos a trav&amp;eacute;s de la propiedad &lt;code&gt;experimental_stats&lt;/code&gt; de &lt;a href=&quot;../options&quot;&gt; &lt;code&gt;tf.data.Options&lt;/code&gt; &lt;/a&gt; ; la propiedad es una instancia de &lt;a href=&quot;statsoptions&quot;&gt; &lt;code&gt;tf.data.experimental.StatsOptions&lt;/code&gt; &lt;/a&gt; . Por ejemplo, para recopilar estad&amp;iacute;sticas de latencia en todos los bordes del conjunto de datos, use el siguiente patr&amp;oacute;n:</target>
        </trans-unit>
        <trans-unit id="0286d405fc4b694404c86890a3b0233533e44d1a" translate="yes" xml:space="preserve">
          <source>You can set the threading options of a dataset through the &lt;code&gt;experimental_threading&lt;/code&gt; property of &lt;a href=&quot;../options&quot;&gt;&lt;code&gt;tf.data.Options&lt;/code&gt;&lt;/a&gt;; the property is an instance of &lt;a href=&quot;threadingoptions&quot;&gt;&lt;code&gt;tf.data.experimental.ThreadingOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Puede establecer las opciones de subprocesamiento de un conjunto de datos mediante la propiedad &lt;code&gt;experimental_threading&lt;/code&gt; de &lt;a href=&quot;../options&quot;&gt; &lt;code&gt;tf.data.Options&lt;/code&gt; &lt;/a&gt; ; la propiedad es una instancia de &lt;a href=&quot;threadingoptions&quot;&gt; &lt;code&gt;tf.data.experimental.ThreadingOptions&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="5821880102274e82922a0313317c1a0e00262ef7" translate="yes" xml:space="preserve">
          <source>You can specify the initial state of RNN layers numerically by calling &lt;code&gt;reset_states&lt;/code&gt; with the keyword argument &lt;code&gt;states&lt;/code&gt;. The value of &lt;code&gt;states&lt;/code&gt; should be a numpy array or list of numpy arrays representing the initial state of the RNN layer.</source>
          <target state="translated">Puede especificar el estado inicial de las capas RNN num&amp;eacute;ricamente llamando a &lt;code&gt;reset_states&lt;/code&gt; con los &lt;code&gt;states&lt;/code&gt; argumentos de la palabra clave . El valor de los &lt;code&gt;states&lt;/code&gt; debe ser una matriz num&amp;eacute;rica o una lista de matrices num&amp;eacute;ricas que representen el estado inicial de la capa RNN.</target>
        </trans-unit>
        <trans-unit id="7903e8eb7e3c0e1f135ecaca1aabba76f1186224" translate="yes" xml:space="preserve">
          <source>You can then use &lt;code&gt;TimeDistributed&lt;/code&gt; to apply a &lt;code&gt;Conv2D&lt;/code&gt; layer to each of the 10 timesteps, independently:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0934b024d096c8c6f1a29dcdebc76afd185fc96d" translate="yes" xml:space="preserve">
          <source>You can then use &lt;code&gt;TimeDistributed&lt;/code&gt; to apply a &lt;code&gt;Dense&lt;/code&gt; layer to each of the 10 timesteps, independently:</source>
          <target state="translated">Luego, puede usar &lt;code&gt;TimeDistributed&lt;/code&gt; para aplicar una capa &lt;code&gt;Dense&lt;/code&gt; a cada uno de los 10 pasos de tiempo, de forma independiente:</target>
        </trans-unit>
        <trans-unit id="49b9bca1daa199f82797585539058cf0bff378d8" translate="yes" xml:space="preserve">
          <source>You can use &lt;a href=&quot;get_replica_context&quot;&gt;&lt;code&gt;tf.distribute.get_replica_context&lt;/code&gt;&lt;/a&gt; to get an instance of &lt;code&gt;ReplicaContext&lt;/code&gt;. This should be inside your replicated step function, such as in a &lt;a href=&quot;strategy#experimental_run_v2&quot;&gt;&lt;code&gt;tf.distribute.Strategy.experimental_run_v2&lt;/code&gt;&lt;/a&gt; call.</source>
          <target state="translated">Puede usar &lt;a href=&quot;get_replica_context&quot;&gt; &lt;code&gt;tf.distribute.get_replica_context&lt;/code&gt; &lt;/a&gt; para obtener una instancia de &lt;code&gt;ReplicaContext&lt;/code&gt; . Esto deber&amp;iacute;a estar dentro de su funci&amp;oacute;n de paso replicada, como en una llamada &lt;a href=&quot;strategy#experimental_run_v2&quot;&gt; &lt;code&gt;tf.distribute.Strategy.experimental_run_v2&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="f52e741d1756d64c06640ac0efef1ab8aa73c071" translate="yes" xml:space="preserve">
          <source>You can use &lt;a href=&quot;get_replica_context&quot;&gt;&lt;code&gt;tf.distribute.get_replica_context&lt;/code&gt;&lt;/a&gt; to get an instance of &lt;code&gt;ReplicaContext&lt;/code&gt;. This should be inside your replicated step function, such as in a &lt;a href=&quot;strategy#run&quot;&gt;&lt;code&gt;tf.distribute.Strategy.run&lt;/code&gt;&lt;/a&gt; call.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bdb676d9df499211a1b26621113c16cf595d42c7" translate="yes" xml:space="preserve">
          <source>You can use the &lt;code&gt;reduce&lt;/code&gt; API to aggregate results across replicas and use this as a return value from one iteration over a &lt;a href=&quot;distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt;. Or you can use &lt;a href=&quot;../keras/metrics&quot;&gt;&lt;code&gt;tf.keras.metrics&lt;/code&gt;&lt;/a&gt; (such as loss, accuracy, etc.) to accumulate metrics across steps in a given epoch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cbd80087e0ae69c397a70f9c2b3b4a4570f57c0a" translate="yes" xml:space="preserve">
          <source>You can use the &lt;code&gt;reduce&lt;/code&gt; API to aggregate results across replicas and use this as a return value from one iteration over the distributed dataset. Or you can use &lt;a href=&quot;../keras/metrics&quot;&gt;&lt;code&gt;tf.keras.metrics&lt;/code&gt;&lt;/a&gt; (such as loss, accuracy, etc.) to accumulate metrics across steps in a given epoch.</source>
          <target state="translated">Puede usar la API de &lt;code&gt;reduce&lt;/code&gt; para agregar resultados en las r&amp;eacute;plicas y usar esto como un valor de retorno de una iteraci&amp;oacute;n sobre el conjunto de datos distribuidos. O puede usar &lt;a href=&quot;../keras/metrics&quot;&gt; &lt;code&gt;tf.keras.metrics&lt;/code&gt; &lt;/a&gt; (como p&amp;eacute;rdida, precisi&amp;oacute;n, etc.) para acumular m&amp;eacute;tricas en los pasos en una &amp;eacute;poca determinada.</target>
        </trans-unit>
        <trans-unit id="849e0f628a638e3510c8fe215b32ce36d057b4e1" translate="yes" xml:space="preserve">
          <source>You can use the Dense layer as you would expect:</source>
          <target state="translated">Puedes usar la capa densa como esperabas:</target>
        </trans-unit>
        <trans-unit id="ffad7cddd33e66d73417586d2382f64196240d65" translate="yes" xml:space="preserve">
          <source>You can use this function to read events written to an event file. It returns a Python iterator that yields &lt;code&gt;Event&lt;/code&gt; protocol buffers.</source>
          <target state="translated">Puede utilizar esta funci&amp;oacute;n para leer eventos escritos en un archivo de eventos. Devuelve un iterador de Python que produce b&amp;uacute;feres de protocolo de &lt;code&gt;Event&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8746f4908e5bf18e74cecb0263457015fb63a862" translate="yes" xml:space="preserve">
          <source>You could also use vocabulary lookup before crossing:</source>
          <target state="translated">También podrías usar la búsqueda de vocabulario antes de cruzar:</target>
        </trans-unit>
        <trans-unit id="de365a46ec65ae586c7c15b2194ec9eca625cd28" translate="yes" xml:space="preserve">
          <source>You could simply do:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2314a9b2a621f208986f86ed4dc02fe23da32fe1" translate="yes" xml:space="preserve">
          <source>You may override this method in a subclass. The standard run() method invokes the callable object passed to the object's constructor as the target argument, if any, with sequential and keyword arguments taken from the args and kwargs arguments, respectively.</source>
          <target state="translated">Puede anular este método en una subclase.El método estándar run()invoca el objeto llamable pasado al constructor del objeto como argumento de destino,si lo hay,con argumentos secuenciales y de palabra clave tomados de los argumentos args y kwargs,respectivamente.</target>
        </trans-unit>
        <trans-unit id="a9f39d075c01a25e9820f6a67df1a4ab21c825d3" translate="yes" xml:space="preserve">
          <source>You may pass descendant of &lt;a href=&quot;strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; to &lt;a href=&quot;../estimator/runconfig&quot;&gt;&lt;code&gt;tf.estimator.RunConfig&lt;/code&gt;&lt;/a&gt; to specify how a &lt;a href=&quot;../estimator/estimator&quot;&gt;&lt;code&gt;tf.estimator.Estimator&lt;/code&gt;&lt;/a&gt; should distribute its computation. See &lt;a href=&quot;https://www.tensorflow.org/guide/distributed_training#using_tfdistributestrategy_with_estimator_limited_support&quot;&gt;guide&lt;/a&gt;.</source>
          <target state="translated">Puede pasar descendiente de &lt;a href=&quot;strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; a &lt;a href=&quot;../estimator/runconfig&quot;&gt; &lt;code&gt;tf.estimator.RunConfig&lt;/code&gt; &lt;/a&gt; para especificar c&amp;oacute;mo un &lt;a href=&quot;../estimator/estimator&quot;&gt; &lt;code&gt;tf.estimator.Estimator&lt;/code&gt; &lt;/a&gt; debe distribuir su c&amp;aacute;lculo. Ver &lt;a href=&quot;https://www.tensorflow.org/guide/distributed_training#using_tfdistributestrategy_with_estimator_limited_support&quot;&gt;gu&amp;iacute;a&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="4caa6c70be3989fa593907ab37426f9ba5e5385e" translate="yes" xml:space="preserve">
          <source>You may provide either a constant &lt;code&gt;window_size&lt;/code&gt; or a window size determined by the key through &lt;code&gt;window_size_func&lt;/code&gt;.</source>
          <target state="translated">Usted puede proporcionar ya sea una constante &lt;code&gt;window_size&lt;/code&gt; o un tama&amp;ntilde;o de ventana determinada por la clave a trav&amp;eacute;s &lt;code&gt;window_size_func&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="246729df98351fdf262d7a7f6c3229e8ff176c5b" translate="yes" xml:space="preserve">
          <source>You must have set the task_type and task_id object properties before calling this function, or pass in the &lt;code&gt;task_type&lt;/code&gt; and &lt;code&gt;task_id&lt;/code&gt; parameters when using this function. If you do both, the function parameters will override the object properties.</source>
          <target state="translated">Debe haber establecido las propiedades del objeto task_type y task_id antes de llamar a esta funci&amp;oacute;n, o pasar los par&amp;aacute;metros &lt;code&gt;task_type&lt;/code&gt; y &lt;code&gt;task_id&lt;/code&gt; cuando utilice esta funci&amp;oacute;n. Si hace ambas cosas, los par&amp;aacute;metros de la funci&amp;oacute;n anular&amp;aacute;n las propiedades del objeto.</target>
        </trans-unit>
        <trans-unit id="843e6067b5e147efe5ecbea6ee6b24b54cc1cca5" translate="yes" xml:space="preserve">
          <source>You number checkpoint filenames by passing a value to the optional &lt;code&gt;global_step&lt;/code&gt; argument to &lt;code&gt;save()&lt;/code&gt;:</source>
          <target state="translated">Usted numera los nombres de archivo de los puntos de control pasando un valor al argumento opcional &lt;code&gt;global_step&lt;/code&gt; para &lt;code&gt;save()&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="47945af2dd44ab9b9f3ac220d707a317fa8bb12b" translate="yes" xml:space="preserve">
          <source>You should not use this class directly, but instead instantiate one of its subclasses such as &lt;a href=&quot;sgd&quot;&gt;&lt;code&gt;tf.keras.optimizers.SGD&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;adam&quot;&gt;&lt;code&gt;tf.keras.optimizers.Adam&lt;/code&gt;&lt;/a&gt;, etc.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d943ec0774ebc46f132a6e012d0ef8ae2735a29" translate="yes" xml:space="preserve">
          <source>You should use this instead of the variable itself to initialize another variable with a value that depends on the value of this variable.</source>
          <target state="translated">Debes usar esto en lugar de la propia variable para inicializar otra variable con un valor que depende del valor de esta variable.</target>
        </trans-unit>
        <trans-unit id="5bcb3cc3036b6c1787fd4b43072cd172e65fd9dd" translate="yes" xml:space="preserve">
          <source>You typically pass looper threads to the supervisor &lt;code&gt;Join()&lt;/code&gt; method.</source>
          <target state="translated">Por lo general, pasa subprocesos de bucleador al m&amp;eacute;todo supervisor &lt;code&gt;Join()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="866c1e20e145360ff1c2d3fac51cd421f0959538" translate="yes" xml:space="preserve">
          <source>You usually do not need to call this method as all ops that need the value of the variable call it automatically through a &lt;code&gt;convert_to_tensor()&lt;/code&gt; call.</source>
          <target state="translated">Por lo general, no es necesario llamar a este m&amp;eacute;todo, ya que todas las operaciones que necesitan el valor de la variable lo llaman autom&amp;aacute;ticamente a trav&amp;eacute;s de una llamada &lt;code&gt;convert_to_tensor()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="28b1f658f43504f27e0b8dad06c688c5569a5b43" translate="yes" xml:space="preserve">
          <source>You want os.path.exists() to always return true during testing.</source>
          <target state="translated">Quieres que os.path.exists()siempre vuelva verdadero durante las pruebas.</target>
        </trans-unit>
        <trans-unit id="558865a16feb9f751b8bcebf46a954afbeba0b24" translate="yes" xml:space="preserve">
          <source>YouTube</source>
          <target state="translated">YouTube</target>
        </trans-unit>
        <trans-unit id="743b60db1fe7f2ede7836bb4e7bd6e58b1ef9754" translate="yes" xml:space="preserve">
          <source>Zeiler, 2012</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8cf5dacc30bc54f166bd31cec0b947c674cc3e7e" translate="yes" xml:space="preserve">
          <source>Zero or more tensors to group.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c152968210a9e92278d1a3f141b891e56657c41" translate="yes" xml:space="preserve">
          <source>Zero-pad the start and end of dimensions &lt;code&gt;[1, ..., M]&lt;/code&gt; of the input according to &lt;code&gt;paddings&lt;/code&gt; to produce &lt;code&gt;padded&lt;/code&gt; of shape &lt;code&gt;padded_shape&lt;/code&gt;.</source>
          <target state="translated">Rellene con ceros el inicio y el final de las dimensiones &lt;code&gt;[1, ..., M]&lt;/code&gt; de la entrada de acuerdo con los &lt;code&gt;paddings&lt;/code&gt; para producir un &lt;code&gt;padded&lt;/code&gt; de forma &lt;code&gt;padded_shape&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ec7ae133fd762cea93146fc3c7001608432a59c7" translate="yes" xml:space="preserve">
          <source>Zero-padding layer for 1D input (e.g. temporal sequence).</source>
          <target state="translated">Capa de relleno cero para la entrada 1D (por ejemplo,secuencia temporal).</target>
        </trans-unit>
        <trans-unit id="9b78ee89fd119fbc58af59c013afefa4ada9d7ed" translate="yes" xml:space="preserve">
          <source>Zero-padding layer for 2D input (e.g. picture).</source>
          <target state="translated">Capa de acolchado cero para la entrada 2D (por ejemplo,la imagen).</target>
        </trans-unit>
        <trans-unit id="81f93ad811573d34a01e1dda72548f7bcac0984e" translate="yes" xml:space="preserve">
          <source>Zero-padding layer for 3D data (spatial or spatio-temporal).</source>
          <target state="translated">Capa de relleno cero para datos 3D (espaciales o espacio-temporales).</target>
        </trans-unit>
        <trans-unit id="4650f7edf1724b78bd849b1c2cb32632cbf26f09" translate="yes" xml:space="preserve">
          <source>Zero-pads and then rearranges (permutes) blocks of spatial data into batch. More specifically, this op outputs a copy of the input tensor where values from the &lt;code&gt;height&lt;/code&gt; and &lt;code&gt;width&lt;/code&gt; dimensions are moved to the &lt;code&gt;batch&lt;/code&gt; dimension. After the zero-padding, both &lt;code&gt;height&lt;/code&gt; and &lt;code&gt;width&lt;/code&gt; of the input must be divisible by the block size.</source>
          <target state="translated">Zero-pads y luego reorganiza (permuta) bloques de datos espaciales en lotes. M&amp;aacute;s espec&amp;iacute;ficamente, esta operaci&amp;oacute;n genera una copia del tensor de entrada donde los valores de las dimensiones de &lt;code&gt;height&lt;/code&gt; y &lt;code&gt;width&lt;/code&gt; se mueven a la dimensi&amp;oacute;n de &lt;code&gt;batch&lt;/code&gt; . Despu&amp;eacute;s del relleno con ceros, tanto el &lt;code&gt;height&lt;/code&gt; como el &lt;code&gt;width&lt;/code&gt; de la entrada deben ser divisibles por el tama&amp;ntilde;o del bloque.</target>
        </trans-unit>
        <trans-unit id="dfee31bddce3aa2ae0eb9ab0a81354d098ee985f" translate="yes" xml:space="preserve">
          <source>ZerosLike</source>
          <target state="translated">ZerosLike</target>
        </trans-unit>
        <trans-unit id="d4dde75ca731d6afffc873406bc9b30fd639401e" translate="yes" xml:space="preserve">
          <source>Zeta</source>
          <target state="translated">Zeta</target>
        </trans-unit>
        <trans-unit id="37a40c343b1c25e2aa4647448f2479d812035f3e" translate="yes" xml:space="preserve">
          <source>ZipDataset</source>
          <target state="translated">ZipDataset</target>
        </trans-unit>
        <trans-unit id="cbfaea632aa3eb5b0ee3bf0fe5b02a033aca96d1" translate="yes" xml:space="preserve">
          <source>Zone of the GCE instance group.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b808978f0a72336077098f027b8f727415da270" translate="yes" xml:space="preserve">
          <source>Zone where the TPUs are located. If omitted or empty, we will assume that the zone of the TPU is the same as the zone of the GCE VM, which we will try to discover from the GCE metadata service.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="690066f3139e111a254b9b22702420163ce9e6c3" translate="yes" xml:space="preserve">
          <source>[-128, 127] for signed, num_bits = 8, or</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f0f7b84b517d1011bde2787a1af440ee2991478" translate="yes" xml:space="preserve">
          <source>[0, 255] for unsigned, num_bits = 8.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd22950e542e583caceeef78dc9ae8586fc6a2c9" translate="yes" xml:space="preserve">
          <source>[1] Nicholas J. Higham (2002). Accuracy and Stability of Numerical Algorithms: Second Edition. SIAM. p. 175. ISBN 978-0-89871-802-7.</source>
          <target state="translated">[1] Nicholas J. Higham (2002). Precisi&amp;oacute;n y estabilidad de algoritmos num&amp;eacute;ricos: segunda edici&amp;oacute;n. SIAM. pags. 175. ISBN 978-0-89871-802-7.</target>
        </trans-unit>
        <trans-unit id="b99fc78b4d7545fcd138b54f0e14096e6f4551ca" translate="yes" xml:space="preserve">
          <source>[1] http://en.wikipedia.org/wiki/Gamma_correction</source>
          <target state="translated">[1] http://en.wikipedia.org/wiki/Gamma_correction</target>
        </trans-unit>
        <trans-unit id="8b402dbbbcbda420a8c8a62323dde3dbd63d7a5e" translate="yes" xml:space="preserve">
          <source>[1]: G. Strang. 'Linear Algebra and Its Applications, 2nd Ed.' Academic Press, Inc., 1980, pp. 139-142.</source>
          <target state="translated">[1]: G. Strang. '&amp;Aacute;lgebra lineal y sus aplicaciones, 2&amp;ordf; ed.' Academic Press, Inc., 1980, p&amp;aacute;gs. 139-142.</target>
        </trans-unit>
        <trans-unit id="3431dfde47f5f77802dc8c1e589fe801ed9dd223" translate="yes" xml:space="preserve">
          <source>[Flag], a new list of Flag instances. Caller may update this list as</source>
          <target state="translated">[Bandera], una nueva lista de instancias de Bandera. La persona que llama puede actualizar esta lista como</target>
        </trans-unit>
        <trans-unit id="8a492c08a6fb4ab5ad781dcaefb3c630980c2a92" translate="yes" xml:space="preserve">
          <source>[Optional] Dict of variable names (strings) to &lt;a href=&quot;../../../estimator/vocabinfo&quot;&gt;&lt;code&gt;tf.estimator.VocabInfo&lt;/code&gt;&lt;/a&gt;. The variable names should be &quot;full&quot; variables, not the names of the partitions. If not explicitly provided, the variable is assumed to have no (changes to) vocabulary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="040ab6c4e7ceb839df30c29d661e2122a9ea0ad3" translate="yes" xml:space="preserve">
          <source>[Optional] Dict of variable names (strings) to &lt;a href=&quot;vocabinfo&quot;&gt;&lt;code&gt;tf.estimator.VocabInfo&lt;/code&gt;&lt;/a&gt;. The variable names should be &quot;full&quot; variables, not the names of the partitions. If not explicitly provided, the variable is assumed to have no (changes to) vocabulary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ccfc72b7041b89963d68b36a1571281cdd9debc" translate="yes" xml:space="preserve">
          <source>[Optional] Dict of variable names (strings) to name of the previously-trained variable in &lt;code&gt;ckpt_to_initialize_from&lt;/code&gt;. If not explicitly provided, the name of the variable is assumed to be same between previous checkpoint and current model. Note that this has no effect on the set of variables that is warm-started, and only controls name mapping (use &lt;code&gt;vars_to_warm_start&lt;/code&gt; for controlling what variables to warm-start).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88dac723b45d7ec9ed5d2521d06d37e6754801f3" translate="yes" xml:space="preserve">
          <source>[Optional] One of the following:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56fcc4459de1190d856f1a05d4fa018ace19dfbd" translate="yes" xml:space="preserve">
          <source>[Required] A string specifying the directory with checkpoint file(s) or path to checkpoint from which to warm-start the model parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ee2e7d87ae9f9bdabd7b4bb725a904d7d206cb7" translate="yes" xml:space="preserve">
          <source>[[w(1, 0), w(1, 2), 0.5], [w(0, 0), w(0, 2), -0.5], [0.25, -0.25, 42]]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7fbe9b43ff0aeb17fee44c25d05877c8cdce9b59" translate="yes" xml:space="preserve">
          <source>[batch * prod(block_shape)] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shape</source>
          <target state="translated">[batch * prod (block_shape)] + [padded_shape [1] / block_shape [0], ..., padded_shape [M] / block_shape [M-1]] + forma_restante</target>
        </trans-unit>
        <trans-unit id="cbf73d5213642961c32b5b788775c8bd0559cdc7" translate="yes" xml:space="preserve">
          <source>[batch, height - 2 * (filter_width - 1), width - 2 * (filter_height - 1), out_channels].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f44d9fad75faea26dd9cc4bc783f18b2b9a3245" translate="yes" xml:space="preserve">
          <source>[batch, height, width, out_channels].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69883aca3ab9b1512329fe1f31a31a2297068297" translate="yes" xml:space="preserve">
          <source>[batch&lt;em&gt;block_size&lt;/em&gt;block_size, height_pad/block_size, width_pad/block_size, depth]</source>
          <target state="translated">[batch &lt;em&gt;block_size&lt;/em&gt; block_size, height_pad / block_size, width_pad / block_size, depth]</target>
        </trans-unit>
        <trans-unit id="a99f9eae6edb2aeb1e4c6a1434cfbcae41146183" translate="yes" xml:space="preserve">
          <source>[batch] + [padded_shape[1] / block_shape[0], block_shape[0], ..., padded_shape[M] / block_shape[M-1], block_shape[M-1]] + remaining_shape</source>
          <target state="translated">[batch] + [padded_shape [1] / block_shape [0], block_shape [0], ..., padded_shape [M] / block_shape [M-1], block_shape [M-1]] + forma_restante</target>
        </trans-unit>
        <trans-unit id="a018842c23398495c71954bf778c4b46f8056996" translate="yes" xml:space="preserve">
          <source>[batch_size, num_channels] + output_spatial_shape</source>
          <target state="translated">[batch_size, num_channels] + output_spatial_shape</target>
        </trans-unit>
        <trans-unit id="51a4c96f9f2ac53566fd73823e05a471562bcdfc" translate="yes" xml:space="preserve">
          <source>[filename1, filename2, ... filenameN] as strings</source>
          <target state="translated">[nombre de archivo1, nombre de archivo2, ... nombre de archivoN] como cadenas</target>
        </trans-unit>
        <trans-unit id="d8a02b4024d1f91043f88e51a21c86cf6a2b1f8b" translate="yes" xml:space="preserve">
          <source>[input_min, input_max] are scalar floats that specify the range for the float interpretation of the 'input' data. For example, if input_min is -1.0f and input_max is 1.0f, and we are dealing with quint16 quantized data, then a 0 value in the 16-bit data should be interpreted as -1.0f, and a 65535 means 1.0f.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="143b12af78e15f28dfa0f3a68b2560666f6d5995" translate="yes" xml:space="preserve">
          <source>[min_range, max_range] are scalar floats that specify the range for the 'input' data. The 'mode' attribute controls exactly which calculations are used to convert the float values to their quantized equivalents. The 'round_mode' attribute controls which rounding tie-breaking algorithm is used when rounding float values to their quantized equivalents.</source>
          <target state="translated">[rango_m&amp;iacute;n, rango_m&amp;aacute;x] son ​​flotantes escalares que especifican el rango para los datos de 'entrada'. El atributo 'modo' controla exactamente qu&amp;eacute; c&amp;aacute;lculos se utilizan para convertir los valores flotantes a sus equivalentes cuantificados. El atributo 'round_mode' controla qu&amp;eacute; algoritmo de redondeo de desempate se usa al redondear valores flotantes a sus equivalentes cuantificados.</target>
        </trans-unit>
        <trans-unit id="1fa2da75f60f4f3a22685794db19c7508c0c1baa" translate="yes" xml:space="preserve">
          <source>[min_range, max_range] are scalar floats that specify the range for the output. The 'mode' attribute controls exactly which calculations are used to convert the float values to their quantized equivalents.</source>
          <target state="translated">[rango_m&amp;iacute;n, rango_m&amp;aacute;x] son ​​flotantes escalares que especifican el rango para la salida. El atributo 'modo' controla exactamente qu&amp;eacute; c&amp;aacute;lculos se utilizan para convertir los valores flotantes a sus equivalentes cuantificados.</target>
        </trans-unit>
        <trans-unit id="8bebaab027f4bff5b0c289cd914950701e571abd" translate="yes" xml:space="preserve">
          <source>[num_batches, input_spatial_shape[0], ..., input_spatial_shape[N-1], num_input_channels],</source>
          <target state="translated">[num_batches, input_spatial_shape [0], ..., input_spatial_shape [N-1], num_input_channels],</target>
        </trans-unit>
        <trans-unit id="8f8157d4fe8eda67ef4b3a3b791fa8bb98678ccc" translate="yes" xml:space="preserve">
          <source>[spatial_filter_shape[0], ..., spatial_filter_shape[N-1], num_input_channels, num_output_channels],</source>
          <target state="translated">[forma_filtro_espacial [0], ..., forma_filtro_espacial [N-1], num_input_channels, num_output_channels],</target>
        </trans-unit>
        <trans-unit id="ccfaace27f3147695ce3d29304da376491a69186" translate="yes" xml:space="preserve">
          <source>[str], a list of strings, usually sys.argv[1:], which may contain one or more flagfile directives of the form --flagfile=&quot;./filename&quot;. Note that the name of the program (sys.argv[0]) should be omitted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a05d1e5d9cec162aa920d1c81e7d248fa2814404" translate="yes" xml:space="preserve">
          <source>[str], a list of the flag names to be checked.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c26fe712edb3b507e5043f8b806fc26990923cd" translate="yes" xml:space="preserve">
          <source>[str], a non-empty list of string values in the enum.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3cd81efe3c17628b43be50a6bfd943ed33227190" translate="yes" xml:space="preserve">
          <source>[str], a non-empty list of strings with the possible values for the flag.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7dbf8f891a3cf1f1fcd98f054581759232646314" translate="yes" xml:space="preserve">
          <source>[str], names of the flags.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0305e4e8314312d7aab76df54a2e11f81f096064" translate="yes" xml:space="preserve">
          <source>[str], the parsed flag value.</source>
          <target state="translated">[str], el valor de la bandera analizado.</target>
        </trans-unit>
        <trans-unit id="06a4ee1356819500657e1855f1838410080d3362" translate="yes" xml:space="preserve">
          <source>\( c_{jklm} = \sum_i a_{ijk} b_{lmi} \).</source>
          <target state="translated">\ (c_ {jklm} = \ sum_i a_ {ijk} b_ {lmi} \).</target>
        </trans-unit>
        <trans-unit id="7c88dd9089928bec50c06f1f5a9b847c1bc1189e" translate="yes" xml:space="preserve">
          <source>\(B(x; a, b) = \int_0^x t^{a-1} (1 - t)^{b-1} dt\)</source>
          <target state="translated">\ (B (x; a, b) = \ int_0 ^ xt ^ {a-1} (1 - t) ^ {b-1} dt \)</target>
        </trans-unit>
        <trans-unit id="5dd8170c96a11e0fac54775aa5e03b07d872abb3" translate="yes" xml:space="preserve">
          <source>\(Gamma(a, x) = int_{x}^{\infty} t^{a-1} exp(-t) dt\)</source>
          <target state="translated">\ (Gamma (a, x) = int_ {x} ^ {\ infty} t ^ {a-1} exp (-t) dt \)</target>
        </trans-unit>
        <trans-unit id="a4f68edbf74b4238178695327b403faa736fbba4" translate="yes" xml:space="preserve">
          <source>\(I_x(a, b) = \frac{B(x; a, b)}{B(a, b)}\)</source>
          <target state="translated">\ (I_x (a, b) = \ frac {B (x; a, b)} {B (a, b)} \)</target>
        </trans-unit>
        <trans-unit id="9b977890dfd27609aefecb3c22cf9edc2b5b6c7c" translate="yes" xml:space="preserve">
          <source>\(P(a, x) = gamma(a, x) / Gamma(a) = 1 - Q(a, x)\)</source>
          <target state="translated">\ (P (a, x) = gamma (a, x) / Gamma (a) = 1 - Q (a, x) \)</target>
        </trans-unit>
        <trans-unit id="3c43fa9908d595b3f6dccdce0d125247c097b9f4" translate="yes" xml:space="preserve">
          <source>\(Q(a, x) = Gamma(a, x) / Gamma(a) = 1 - P(a, x)\)</source>
          <target state="translated">\ (Q (a, x) = Gamma (a, x) / Gamma (a) = 1 - P (a, x) \)</target>
        </trans-unit>
        <trans-unit id="37291deb0e6026c081430c96a800990fc3edcaa7" translate="yes" xml:space="preserve">
          <source>\(\beta\)</source>
          <target state="translated">\(\beta\)</target>
        </trans-unit>
        <trans-unit id="ff41b6103716ee7c998d6e81784bdf83320ba7f2" translate="yes" xml:space="preserve">
          <source>\(\ell_1\,\,penalty =\ell_1\sum_{i=0}^n|x_i|\)</source>
          <target state="translated">\ (\ ell_1 \, \, pena = \ ell_1 \ sum_ {i = 0} ^ n | x_i | \)</target>
        </trans-unit>
        <trans-unit id="9335deefcc4fff06a8f47ea88b57b74222c6ee2a" translate="yes" xml:space="preserve">
          <source>\(\ell_2\,\,penalty =\ell_2\sum_{i=0}^nx_i^2\)</source>
          <target state="translated">\ (\ ell_2 \, \, pena = \ ell_2 \ sum_ {i = 0} ^ nx_i ^ 2 \)</target>
        </trans-unit>
        <trans-unit id="c62e7aed7aab85e0bc7679b7b1654447c10071b7" translate="yes" xml:space="preserve">
          <source>\(\frac{\gamma(x-\mu)}{\sigma}+\beta\)</source>
          <target state="translated">\(\frac{\gamma(x-\mu)}{\sigma}+\beta\)</target>
        </trans-unit>
        <trans-unit id="4a0660a89253bc5ba688c6d45badc9f8ddf6380e" translate="yes" xml:space="preserve">
          <source>\(\psi^{(a)}(x) = \frac{d^a}{dx^a} \psi(x)\)</source>
          <target state="translated">\ (\ psi ^ {(a)} (x) = \ frac {d ^ a} {dx ^ a} \ psi (x) \)</target>
        </trans-unit>
        <trans-unit id="57cfcb3ce0118881ab066bb534ef79062b9ae613" translate="yes" xml:space="preserve">
          <source>\(\sigma_{t,i} = (\sqrt{n_{t,i}} - \sqrt{n_{t-1,i}}) / \alpha\)</source>
          <target state="translated">\ (\ sigma_ {t, i} = (\ sqrt {n_ {t, i}} - \ sqrt {n_ {t-1, i}}) / \ alpha \)</target>
        </trans-unit>
        <trans-unit id="c402d7a692489cd97ce624829b28b4af2556f395" translate="yes" xml:space="preserve">
          <source>\(\zeta(x, q) = \sum_{n=0}^{\infty} (q + n)^{-x}\)</source>
          <target state="translated">\ (\ zeta (x, q) = \ sum_ {n = 0} ^ {\ infty} (q + n) ^ {- x} \)</target>
        </trans-unit>
        <trans-unit id="ea1119f555233a8d758e9686e809fbc51e48a520" translate="yes" xml:space="preserve">
          <source>\(gamma(a, x) = \\int_{0}^{x} t^{a-1} exp(-t) dt\)</source>
          <target state="translated">\ (gamma (a, x) = \\ int_ {0} ^ {x} t ^ {a-1} exp (-t) dt \)</target>
        </trans-unit>
        <trans-unit id="553f6c65213b82afcc0c043d8233d0d411b11d70" translate="yes" xml:space="preserve">
          <source>\(i\)</source>
          <target state="translated">\(i\)</target>
        </trans-unit>
        <trans-unit id="cad97ed2e69a3cdad8082dd06f3ff6c16e2928db" translate="yes" xml:space="preserve">
          <source>\(lbeta(x)[i1, ..., in] = Log(|Beta(x[i1, ..., in, :])|)\)</source>
          <target state="translated">\ (lbeta (x) [i1, ..., in] = Log (| Beta (x [i1, ..., in,:]) |) \)</target>
        </trans-unit>
        <trans-unit id="e122b351d32a233056a0dc92eef090ec82833970" translate="yes" xml:space="preserve">
          <source>\(log(exp(A)) = A\)</source>
          <target state="translated">\ (log (exp (A)) = A \)</target>
        </trans-unit>
        <trans-unit id="a6e6475c1d10a33b250fca653ee8cfd040c5e589" translate="yes" xml:space="preserve">
          <source>\(lr_t := \text{learning\_rate} * \sqrt{1 - beta_2^t} / (1 - beta_1^t)\)</source>
          <target state="translated">\ (lr_t: = \ text {aprendizaje \ _rate} * \ sqrt {1 - beta_2 ^ t} / (1 - beta_1 ^ t) \)</target>
        </trans-unit>
        <trans-unit id="9f6d1fd07abb052ec6fac4e52945c2c9c481cefa" translate="yes" xml:space="preserve">
          <source>\(m_0 := 0 \text{(Initialize initial 1st moment vector)}\)</source>
          <target state="translated">\ (m_0: = 0 \ text {(Inicializar vector de primer momento inicial)} \)</target>
        </trans-unit>
        <trans-unit id="e3dada6e7ecd7d65376b81a16036f8e723616d85" translate="yes" xml:space="preserve">
          <source>\(m_t := beta_1 * m_{t-1} + (1 - beta_1) * g\)</source>
          <target state="translated">\ (m_t: = beta_1 * m_ {t-1} + (1 - beta_1) * g \)</target>
        </trans-unit>
        <trans-unit id="36cf9049b0822fc2658dd5393471d4a9bc14521f" translate="yes" xml:space="preserve">
          <source>\(n_{t,i} = n_{t-1,i} + g_{t,i}^{2}\)</source>
          <target state="translated">\ (n_ {t, i} = n_ {t-1, i} + g_ {t, i} ^ {2} \)</target>
        </trans-unit>
        <trans-unit id="e58cad3c2a2e7d2a68a0cec41e11be1d3da882e6" translate="yes" xml:space="preserve">
          <source>\(output_i = 1/N_i \sum_{j...} data[j...]\) where the sum is over tuples &lt;code&gt;j...&lt;/code&gt; such that &lt;code&gt;segment_ids[j...] == i&lt;/code&gt; with \N_i\ being the number of occurrences of id \i\.</source>
          <target state="translated">\ (salida_i = 1 / N_i \ sum_ {j ...} datos [j ...] \) donde la suma est&amp;aacute; sobre tuplas &lt;code&gt;j...&lt;/code&gt; tal que &lt;code&gt;segment_ids[j...] == i&lt;/code&gt; con \ N_i \ siendo el n&amp;uacute;mero de apariciones de id \ i \.</target>
        </trans-unit>
        <trans-unit id="eff44ad7c5ba3196137c591dc7d87b8984229557" translate="yes" xml:space="preserve">
          <source>\(output_i = 1/sqrt(N_i) \sum_{j...} data[j...]\) where the sum is over tuples &lt;code&gt;j...&lt;/code&gt; such that &lt;code&gt;segment_ids[j...] == i&lt;/code&gt; with \N_i\ being the number of occurrences of id \i\.</source>
          <target state="translated">\ (output_i = 1 / sqrt (N_i) \ sum_ {j ...} data [j ...] \) donde la suma est&amp;aacute; sobre tuplas &lt;code&gt;j...&lt;/code&gt; tal que &lt;code&gt;segment_ids[j...] == i&lt;/code&gt; con \ N_i \ es el n&amp;uacute;mero de apariciones de id \ i \.</target>
        </trans-unit>
        <trans-unit id="fd27c9aa6e45dbe63e023f46fe5fdca3d93fbc19" translate="yes" xml:space="preserve">
          <source>\(output_i = \max_{j...} data[j...]\) where max is over tuples &lt;code&gt;j...&lt;/code&gt; such that &lt;code&gt;segment_ids[j...] == i&lt;/code&gt;.</source>
          <target state="translated">\ (output_i = \ max_ {j ...} data [j ...] \) donde max est&amp;aacute; sobre tuplas &lt;code&gt;j...&lt;/code&gt; modo que &lt;code&gt;segment_ids[j...] == i&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="529b95e92276e5f1ac9b067c9474b5798a2da7c5" translate="yes" xml:space="preserve">
          <source>\(output_i = \min_{j...} data_[j...]\) where min is over tuples &lt;code&gt;j...&lt;/code&gt; such that &lt;code&gt;segment_ids[j...] == i&lt;/code&gt;.</source>
          <target state="translated">\ (output_i = \ min_ {j ...} data_ [j ...] \) donde min est&amp;aacute; sobre tuplas &lt;code&gt;j...&lt;/code&gt; modo que &lt;code&gt;segment_ids[j...] == i&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1bf71665be24061201465110b49af7b8c6429f1f" translate="yes" xml:space="preserve">
          <source>\(output_i = \prod_{j...} data[j...]\) where the product is over tuples &lt;code&gt;j...&lt;/code&gt; such that &lt;code&gt;segment_ids[j...] == i&lt;/code&gt;.</source>
          <target state="translated">\ (output_i = \ prod_ {j ...} data [j ...] \) donde el producto est&amp;aacute; sobre tuplas &lt;code&gt;j...&lt;/code&gt; modo que &lt;code&gt;segment_ids[j...] == i&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="bcf88899f36fe32859ba4eebac881718864b3a68" translate="yes" xml:space="preserve">
          <source>\(predictions_i\) be the predictions for all classes for example &lt;code&gt;i&lt;/code&gt;, \(targets_i\) be the target class for example &lt;code&gt;i&lt;/code&gt;, \(out_i\) be the output for example &lt;code&gt;i&lt;/code&gt;,</source>
          <target state="translated">\ (predictions_i \) ser las predicciones para todas las clases, por ejemplo , &lt;code&gt;i&lt;/code&gt; , \ (objetivos_i \), ser la clase de destino, por ejemplo , &lt;code&gt;i&lt;/code&gt; , \ (out_i \), ser la salida, por ejemplo , &lt;code&gt;i&lt;/code&gt; ,</target>
        </trans-unit>
        <trans-unit id="eb6c03745499b6a9eb903031a775345057a8d436" translate="yes" xml:space="preserve">
          <source>\(t := 0 \text{(Initialize timestep)}\)</source>
          <target state="translated">\ (t: = 0 \ text {(Inicializar paso de tiempo)} \)</target>
        </trans-unit>
        <trans-unit id="467d92f4cfe1c3cd183f798d119891376eebfa6b" translate="yes" xml:space="preserve">
          <source>\(t := t + 1\)</source>
          <target state="translated">\ (t: = t + 1 \)</target>
        </trans-unit>
        <trans-unit id="e5334cf7b7c8be8a554d2684840ca9468e2d3597" translate="yes" xml:space="preserve">
          <source>\(t = t + 1\)</source>
          <target state="translated">\ (t = t + 1 \)</target>
        </trans-unit>
        <trans-unit id="1a4815b823d6a6bd996f5174a896a936100c82c4" translate="yes" xml:space="preserve">
          <source>\(v_0 := 0 \text{(Initialize initial 2nd moment vector)}\)</source>
          <target state="translated">\ (v_0: = 0 \ text {(Inicializar vector de segundo momento inicial)} \)</target>
        </trans-unit>
        <trans-unit id="fe2806cab7064b169c451375ea09662f2387835c" translate="yes" xml:space="preserve">
          <source>\(v_hat_0 := 0 \text{(Initialize initial 2nd moment vector)}\)</source>
          <target state="translated">\ (v_hat_0: = 0 \ text {(Inicializar el vector de segundo momento inicial)} \)</target>
        </trans-unit>
        <trans-unit id="95246ed68fccf6f4caddd1734e3779b6b21f4b80" translate="yes" xml:space="preserve">
          <source>\(v_hat_t := max(v_hat_{t-1}, v_t)\)</source>
          <target state="translated">\ (v_hat_t: = max (v_hat_ {t-1}, v_t) \)</target>
        </trans-unit>
        <trans-unit id="4f4d3c48642e5d2288a5d23ba51224f14bb68e11" translate="yes" xml:space="preserve">
          <source>\(v_t := beta_2 * v_{t-1} + (1 - beta_2) * g * g\)</source>
          <target state="translated">\ (v_t: = beta_2 * v_ {t-1} + (1 - beta_2) * g * g \)</target>
        </trans-unit>
        <trans-unit id="ceb29146344acce0db4068ea0c682c74bad08207" translate="yes" xml:space="preserve">
          <source>\(variable := variable - lr_t * m_t / (\sqrt{v_hat_t} + \epsilon)\)</source>
          <target state="translated">\ (variable: = variable - lr_t * m_t / (\ sqrt {v_hat_t} + \ epsilon) \)</target>
        </trans-unit>
        <trans-unit id="2a5065284239af79ffad5fd4634aca805131acd5" translate="yes" xml:space="preserve">
          <source>\(variable := variable - lr_t * m_t / (\sqrt{v_t} + \epsilon)\)</source>
          <target state="translated">\ (variable: = variable - lr_t * m_t / (\ sqrt {v_t} + \ epsilon) \)</target>
        </trans-unit>
        <trans-unit id="9c42d66b235e7446c048f4defb1b795d3ee38b09" translate="yes" xml:space="preserve">
          <source>\(w_{i}\)</source>
          <target state="translated">\(w_{i}\)</target>
        </trans-unit>
        <trans-unit id="3b25b3312f2ef7cacd25276352e73b5ab48846cf" translate="yes" xml:space="preserve">
          <source>\(w_{t,i} = - ((\beta+\sqrt{n+{t}}) / \alpha + \lambda_{2})^{-1} * (z_{i} - sgn(z_{i}) * \lambda_{1}) if \abs{z_{i}} &amp;gt; \lambda_{i} else 0\)</source>
          <target state="translated">\ (w_ {t, i} = - ((\ beta + \ sqrt {n + {t}}) / \ alpha + \ lambda_ {2}) ^ {- 1} * (z_ {i} - sgn (z_ {i }) * \ lambda_ {1}) si \ abs {z_ {i}}&amp;gt; \ lambda_ {i} else 0 \)</target>
        </trans-unit>
        <trans-unit id="ba90f7c8012e09317d8c902b37294fee9c1c8163" translate="yes" xml:space="preserve">
          <source>\(y = \beta + \sum_{i=1}^{N} w_{i} * x_{i}\)</source>
          <target state="translated">\ (y = \ beta + \ sum_ {i = 1} ^ {N} w_ {i} * x_ {i} \)</target>
        </trans-unit>
        <trans-unit id="2dec4db0fcb32e5c79e8ecb6c6414661d0289001" translate="yes" xml:space="preserve">
          <source>\(z_{t,i} = z_{t-1,i} + g_{t,i} - \sigma_{t,i} * w_{t,i}\)</source>
          <target state="translated">\ (z_ {t, i} = z_ {t-1, i} + g_ {t, i} - \ sigma_ {t, i} * w_ {t, i} \)</target>
        </trans-unit>
        <trans-unit id="31d5b9df6c8b26532e6975198879e8066c930cd4" translate="yes" xml:space="preserve">
          <source>], 'bias': [</source>
          <target state="translated">], 'parcialidad': [</target>
        </trans-unit>
        <trans-unit id="ebb0f535eb870cf683880d2973390bc12e206de5" translate="yes" xml:space="preserve">
          <source>], _NumericColumn( key='numeric_feature2', shape=(2,)): [</source>
          <target state="translated">], _NumericColumn (clave = 'numeric_feature2', forma = (2,)): [</target>
        </trans-unit>
        <trans-unit id="a961fbc1cc31eed81a5be94725a3b10dfcfb3f0e" translate="yes" xml:space="preserve">
          <source>]} If a column creates no variables, its value will be an empty list. Note that cols_to_vars will also contain a string key 'bias' that maps to a list of Variables.</source>
          <target state="translated">]} Si una columna no crea variables, su valor ser&amp;aacute; una lista vac&amp;iacute;a. Tenga en cuenta que cols_to_vars tambi&amp;eacute;n contendr&amp;aacute; una clave de cadena 'sesgo' que se asigna a una lista de variables.</target>
        </trans-unit>
        <trans-unit id="82253180c6e96af25f2a21fff7bcfa0218b5a1e9" translate="yes" xml:space="preserve">
          <source>_normal_initializer</source>
          <target state="translated">_normal_initializer</target>
        </trans-unit>
        <trans-unit id="87ea43bbd5b9352fbaeea30b2cc056ed63741cfd" translate="yes" xml:space="preserve">
          <source>_uniform_initializer</source>
          <target state="translated">_uniform_initializer</target>
        </trans-unit>
        <trans-unit id="d5a25e2ec3739e3d8ae17e7c5a3f6cbea4f5abd6" translate="yes" xml:space="preserve">
          <source>a (major,minor) pair that indicates the minimum CUDA compute capability required, or None if no requirement.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd7aed71c0916f4e514b1b87472e1aaec7a3d81c" translate="yes" xml:space="preserve">
          <source>a 1-D numpy array whose size depends on the algorithm.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09cc8a0e53d6d87d6a7d95e6a2118c05a24fa639" translate="yes" xml:space="preserve">
          <source>a 1-D tensor whose size depends on the algorithm.</source>
          <target state="translated">un tensor 1-D cuyo tamaño depende del algoritmo.</target>
        </trans-unit>
        <trans-unit id="93178b091b08f4efbffb2adcc54e5c4fc936daed" translate="yes" xml:space="preserve">
          <source>a 1D tensor. Dimensions: out_units</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60f13d546f38be6d76d9d2976a24c54009d2eb5a" translate="yes" xml:space="preserve">
          <source>a 2D tensor. Dimensions typically: batch, in_units</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abdaa4ef567c5801d72513ba2ff400234446d877" translate="yes" xml:space="preserve">
          <source>a 2D tensor. Dimensions typically: in_units, out_units</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0832663c1e8c4bc4a737a50ba43d01171dfb1b52" translate="yes" xml:space="preserve">
          <source>a &lt;a href=&quot;../dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; whose elements are to be written to a file</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63da673dc60479d55d81b4dac49f99e2addfa764" translate="yes" xml:space="preserve">
          <source>a &lt;a href=&quot;../model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt;, its output must match the output of the linear model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23a2b4256e67b7643d6e462770d9d1ceff2c6a95" translate="yes" xml:space="preserve">
          <source>a &lt;a href=&quot;layer&quot;&gt;&lt;code&gt;tf.keras.layers.Layer&lt;/code&gt;&lt;/a&gt; instance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b7b7f1e42a3452df01c243bc4ff9f9c0a1e957a" translate="yes" xml:space="preserve">
          <source>a &lt;a href=&quot;options&quot;&gt;&lt;code&gt;tf.data.Options&lt;/code&gt;&lt;/a&gt; to merge with</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc2f84a127d1432687ba858bc82ffee5c3694cbb" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;DeviceSpec&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="532617217fec8780a205ebf785c1bcfcd14f51e0" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;DeviceSpec&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a0723a300b3e5a3037c5eec9b6314d294f925e8" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;SavedModel&lt;/code&gt; proto containing the Tensorflow backend graph. Separate graphs are saved for prediction (serving), train, and evaluation. If the model has not been compiled, then only the graph computing predictions will be exported.</source>
          <target state="translated">un proto de &lt;code&gt;SavedModel&lt;/code&gt; que contiene el gr&amp;aacute;fico de backend de Tensorflow. Los gr&amp;aacute;ficos separados se guardan para la predicci&amp;oacute;n (servicio), el entrenamiento y la evaluaci&amp;oacute;n. Si el modelo no se ha compilado, solo se exportar&amp;aacute;n las predicciones de c&amp;aacute;lculo de gr&amp;aacute;ficos.</target>
        </trans-unit>
        <trans-unit id="2fe7e88159041491b684ee0b2eef3649a559ee4b" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;SaverDef&lt;/code&gt; protocol buffer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe9334150fba500e634d08a0fd10f09c0e5c3458" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;SparseTensor&lt;/code&gt; operand whose dtype is real, and indices lexicographically ordered.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89fda5dd98ad8f5391967d857c89af91abadfb1e" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;Tensor&lt;/code&gt; of shape &lt;code&gt;sample_shape(x) + self.batch_shape&lt;/code&gt; with values of type &lt;code&gt;self.dtype&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="814d7841b7f08b3882cd124daea00a4d94c3529b" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;Tensor&lt;/code&gt; of shape &lt;code&gt;tf.concat([shape, tf.shape(alpha + beta)], axis=0)&lt;/code&gt; with values of type &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28f44ad32a3986701c510c4b3dcbe94a32df1ffe" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;Tensor&lt;/code&gt; of shape &lt;code&gt;tf.concat([shape, tf.shape(lam)], axis=0)&lt;/code&gt; with values of type &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a5aa938284d01a870254921f425995a35654dd9" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;Tensor&lt;/code&gt; with prepended dimensions &lt;code&gt;sample_shape&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4c4f77ba88c28c41bf33a3d3025e3b1e6cda5e8" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;Tensor&lt;/code&gt;, or a dict of string to &lt;code&gt;Tensor&lt;/code&gt;, specifying input nodes that will be fed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfb18628ed3de27b4a1a234981f499e9dd433d38" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;str&lt;/code&gt; describing the contraction, in the same format as &lt;code&gt;numpy.einsum&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4f5c14667db94a7f69f7b3c58a35864d1d15ebd" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;tf.ConfigProto&lt;/code&gt; object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd5e709c8e1b6963fd07bdd51f6a8e7d5b1a115e" translate="yes" xml:space="preserve">
          <source>a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3]) a # 2-D tensor</source>
          <target state="translated">a=tf.constante([1,2,3,4,5,6],forma=[2,3])a#tensor 2-D</target>
        </trans-unit>
        <trans-unit id="d3508e6212f2bb1a5bb507a6ad9f56dc1d60653b" translate="yes" xml:space="preserve">
          <source>a = tf.constant([[1, 2], [3, 4]]) tf.reduce_min(a)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b60dce959a5722be8d9ace37f6ea58387cc7a978" translate="yes" xml:space="preserve">
          <source>a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3]) a # 3-D tensor</source>
          <target state="translated">a=tf.constante(np.arange(1,13,dtype=np.int32),shape=[2,2,3])a#tensor 3-D</target>
        </trans-unit>
        <trans-unit id="d5554b43b2c1e709f84d89ff59708b34ac43de5d" translate="yes" xml:space="preserve">
          <source>a ClusterResolver</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12fec67c34e62bc4fe609123ff4e68b7b09d5716" translate="yes" xml:space="preserve">
          <source>a ConfigProto used to set session parameters, or &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cac282a286b145e90bbae0cb74e2d64c49b7f387" translate="yes" xml:space="preserve">
          <source>a GraphNodeProto that records the results.</source>
          <target state="translated">un GraphNodeProto que registra los resultados.</target>
        </trans-unit>
        <trans-unit id="02fdc18cf71e7d138c4670ddd2b89252810f0b7c" translate="yes" xml:space="preserve">
          <source>a Mirrored object.</source>
          <target state="translated">un objeto reflejado.</target>
        </trans-unit>
        <trans-unit id="6a65d1b63a2aa1329f486140387a944abe2d35ab" translate="yes" xml:space="preserve">
          <source>a MultiGraphNodeProto that records the results.</source>
          <target state="translated">un MultiGraphNodeProto que registra los resultados.</target>
        </trans-unit>
        <trans-unit id="3f756fe3a0f877dbf55d583613842de50b650bca" translate="yes" xml:space="preserve">
          <source>a Tensor or list of Tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44a87c17dbe409e98a432e4764a0ca67503ad529" translate="yes" xml:space="preserve">
          <source>a TrtConversionParams instance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6adb18be2c65016a8dd91dcca0917351f5c5ea50" translate="yes" xml:space="preserve">
          <source>a boolean indicating whether the input boxes and scores are sorted in descending order by the score.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae8444bacbe1b98ca2a1d9caa1bde03aa7aa8447" translate="yes" xml:space="preserve">
          <source>a callable taking two parameters, a variable and a list of slot names to create for it. This function should return a dict with the slot names as keys and the created variables as values. When set to None (the default), uses the built-in variable creation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b5462387fade93b713b97cb5dd916b0db334352" translate="yes" xml:space="preserve">
          <source>a callable that takes a single &lt;code&gt;DType&lt;/code&gt; argument and returns a Python &lt;code&gt;boolean&lt;/code&gt; indicating whether the dtype is to be included in the data dumping. Examples:</source>
          <target state="translated">un invocable que toma un &amp;uacute;nico argumento &lt;code&gt;DType&lt;/code&gt; y devuelve un &lt;code&gt;boolean&lt;/code&gt; o de Python que indica si el dtype se incluir&amp;aacute; en el volcado de datos. Ejemplos:</target>
        </trans-unit>
        <trans-unit id="dadf9b05790e565e376db89427e055d3cb91682a" translate="yes" xml:space="preserve">
          <source>a checkpoint containing the model weights.</source>
          <target state="translated">un punto de control que contiene los pesos del modelo.</target>
        </trans-unit>
        <trans-unit id="7cbfb1c56d61348ae16c7cd2face5f9db9cab352" translate="yes" xml:space="preserve">
          <source>a dict of string to &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b740bb539e2724c4812a91601e69e1c90a91fbd" translate="yes" xml:space="preserve">
          <source>a dict of string to &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79c49bc5c338207d05434ecb9d28173a38bb6f68" translate="yes" xml:space="preserve">
          <source>a dict of string to &lt;code&gt;VarLenFeature&lt;/code&gt;/&lt;code&gt;FixedLenFeature&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="813fdedf351b9814fc880a7e57d9c99855ec1cd5" translate="yes" xml:space="preserve">
          <source>a dict of string to additional groups of receiver tensors, each of which may be a &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string to &lt;code&gt;Tensor&lt;/code&gt; or&lt;code&gt;SparseTensor&lt;/code&gt;. These named receiver tensor alternatives generate additional serving signatures, which may be used to feed inputs at different points within the input receiver subgraph. A typical usage is to allow feeding raw feature &lt;code&gt;Tensor&lt;/code&gt;s &lt;em&gt;downstream&lt;/em&gt; of the tf.parse_example() op. Defaults to None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bd9e9cef7c898d18e42b1f2f9c5375410bd03be" translate="yes" xml:space="preserve">
          <source>a dictionary which maps layer name to a file name in which metadata for this embedding layer is saved. &lt;a href=&quot;https://www.tensorflow.org/how_tos/embedding_viz/#metadata_optional&quot;&gt;Here are details&lt;/a&gt; about metadata files format. In case if the same metadata file is used for all embedding layers, string can be passed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c591343285301a08eb1eb57b9c63187b713f4d7" translate="yes" xml:space="preserve">
          <source>a dictionary which maps layer name to a file name in which metadata for this embedding layer is saved. See the &lt;a href=&quot;https://www.tensorflow.org/how_tos/embedding_viz/#metadata_optional&quot;&gt;details&lt;/a&gt; about metadata files format. In case if the same metadata file is used for all embedding layers, string can be passed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8527fc8500abdc7bc32e70d3d9218debeaf5253f" translate="yes" xml:space="preserve">
          <source>a feature with &lt;code&gt;key=column.name&lt;/code&gt; whose &lt;code&gt;value&lt;/code&gt; is a &lt;code&gt;SparseTensor&lt;/code&gt;.</source>
          <target state="translated">una caracter&amp;iacute;stica con &lt;code&gt;key=column.name&lt;/code&gt; cuyo &lt;code&gt;value&lt;/code&gt; es un &lt;code&gt;SparseTensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ded58018cf323ca8b228f31fb7eeecbe3e4bab57" translate="yes" xml:space="preserve">
          <source>a float &lt;code&gt;Tensor&lt;/code&gt; giving the predicted values. Required.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca1e3709c53c6fef2ab454a19e61ce4ffd76640f" translate="yes" xml:space="preserve">
          <source>a float &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8fa1eefb32219e9ccd295492ff2de693d41b5058" translate="yes" xml:space="preserve">
          <source>a float represented as fraction of 2pi, or a tuple of size 2 representing lower and upper bound for rotating clockwise and counter-clockwise. A positive values means rotating counter clock-wise, while a negative value means clock-wise. When represented as a single float, this value is used for both the upper and lower bound. For instance, &lt;code&gt;factor=(-0.2, 0.3)&lt;/code&gt; results in an output rotation by a random amount in the range &lt;code&gt;[-20% * 2pi, 30% * 2pi]&lt;/code&gt;. &lt;code&gt;factor=0.2&lt;/code&gt; results in an output rotating by a random amount in the range &lt;code&gt;[-20% * 2pi, 20% * 2pi]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f704c1b4eddb94e2f57ea74f007a87f33d697ca" translate="yes" xml:space="preserve">
          <source>a float represented as fraction of value, or a tuple of size 2 representing lower and upper bound for shifting horizontally. A negative value means shifting image left, while a positive value means shifting image right. When represented as a single positive float, this value is used for both the upper and lower bound. For instance, &lt;code&gt;width_factor=(-0.2, 0.3)&lt;/code&gt; results in an output shifted left by 20%, and shifted right by 30%. &lt;code&gt;width_factor=0.2&lt;/code&gt; results in an output height shifted left or right by 20%.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91c973265bac7ff051653d0165345d52a97d0e23" translate="yes" xml:space="preserve">
          <source>a float represented as fraction of value, or a tuple of size 2 representing lower and upper bound for shifting vertically. A negative value means shifting image up, while a positive value means shifting image down. When represented as a single positive float, this value is used for both the upper and lower bound. For instance, &lt;code&gt;height_factor=(-0.2, 0.3)&lt;/code&gt; results in an output shifted by a random amount in the range [-20%, +30%]. &lt;code&gt;height_factor=0.2&lt;/code&gt; results in an output height shifted by a random amount in the range [-20%, +20%].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7049c0b7f85f9f5d90a665c9a2c18068cc1f50bb" translate="yes" xml:space="preserve">
          <source>a float represented as fraction of value, or a tuple of size 2 representing lower and upper bound for zooming horizontally. When represented as a single float, this value is used for both the upper and lower bound. For instance, &lt;code&gt;width_factor=(0.2, 0.3)&lt;/code&gt; result in an output zooming out between 20% to 30%. &lt;code&gt;width_factor=(-0.3, -0.2)&lt;/code&gt; result in an output zooming in between 20% to 30%. Defaults to &lt;code&gt;None&lt;/code&gt;, i.e., zooming vertical and horizontal directions by preserving the aspect ratio.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ec50d28cf2adbe8d493bb972ad6ae6b32140707" translate="yes" xml:space="preserve">
          <source>a float represented as fraction of value, or a tuple of size 2 representing lower and upper bound for zooming vertically. When represented as a single float, this value is used for both the upper and lower bound. A positive value means zooming out, while a negative value means zooming in. For instance, &lt;code&gt;height_factor=(0.2, 0.3)&lt;/code&gt; result in an output zoomed out by a random amount in the range [+20%, +30%]. &lt;code&gt;height_factor=(-0.3, -0.2)&lt;/code&gt; result in an output zoomed in by a random amount in the range [+20%, +30%].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="134107ca0c019b55908b80f4021d2430226ea2bd" translate="yes" xml:space="preserve">
          <source>a float representing the threshold for box scores. Boxes with a score that is not larger than this threshold will be suppressed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f94882e30fda2ab68c451ff7e157ffcd9c9395b" translate="yes" xml:space="preserve">
          <source>a float representing the threshold for deciding whether boxes overlap too much with respect to IoU (intersection over union).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb70148942a0d807c9b8eab06234b1263dd9f73d" translate="yes" xml:space="preserve">
          <source>a float value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95a34729e004ba21708276447a0c52f66f075797" translate="yes" xml:space="preserve">
          <source>a float. The maximum absolute difference allowed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8cade3d579ad24100c211eef3761440915ebda65" translate="yes" xml:space="preserve">
          <source>a floating point value. The learning rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96653b90a10cbc5bd2bee44ca5eac4e329ab5a1e" translate="yes" xml:space="preserve">
          <source>a function that compares two evaluation results and returns true if current evaluation result is better. Follows the signature:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9a62fd00059c46a517d9a5d09090fa30f1d118d" translate="yes" xml:space="preserve">
          <source>a function that does accumulation. If None, then &lt;a href=&quot;../math/add_n&quot;&gt;&lt;code&gt;tf.math.add_n&lt;/code&gt;&lt;/a&gt; is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e212799b3b3be2bf8bb202585b8b934660586c8" translate="yes" xml:space="preserve">
          <source>a function that takes an epoch index (integer, indexed from 0) and current learning rate (float) as inputs and returns a new learning rate as output (float).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e12532b57f71320a99fe67d455119ce2516227a2" translate="yes" xml:space="preserve">
          <source>a function that takes no arguments and returns a &lt;code&gt;ServingInputReceiver&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1bd914955f1635d519f5b5015a7943bdbe1e789c" translate="yes" xml:space="preserve">
          <source>a generator function that yields input data as a list or tuple, which will be used to execute the converted signature for calibration. All the returned input data should have the same shape. Example: &lt;code&gt;def input_fn(): yield input1, input2, input3&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b35ea09d187677febf5398dd21d3f485aef04a83" translate="yes" xml:space="preserve">
          <source>a generator function that yields input data as a list or tuple, which will be used to execute the converted signature to generate TRT engines. Example: `def input_fn():</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1862cc4d53bc4e8a702743354cc37627a768a2f8" translate="yes" xml:space="preserve">
          <source>a generator function which yields data</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98c108f990a30bbb49abae38f009c82ac5f3a790" translate="yes" xml:space="preserve">
          <source>a generator to be copied from.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="420880ced69a6abdc0537ffab2bcb1d1ec757577" translate="yes" xml:space="preserve">
          <source>a handle to defined flag.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9fc2e7b4a4a43e13919ca0d29891f8252c3bdeb" translate="yes" xml:space="preserve">
          <source>a keras.Model instance.</source>
          <target state="translated">a keras.model instance.</target>
        </trans-unit>
        <trans-unit id="825f328ed6cb35d3a0907c277ea200144eea6b05" translate="yes" xml:space="preserve">
          <source>a list of Mirrored objects.</source>
          <target state="translated">una lista de objetos reflejados.</target>
        </trans-unit>
        <trans-unit id="8af7fc543dbba60d65534412fdeec31fcf0fd35c" translate="yes" xml:space="preserve">
          <source>a list of Numpy arrays. The number of arrays and their shape must match number of the dimensions of the weights of the layer (i.e. it should match the output of &lt;code&gt;get_weights&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64df7eba5e731a4dc70dbacc22e2fd9fd9e1d032" translate="yes" xml:space="preserve">
          <source>a list of checkpoint paths, typically the results of &lt;code&gt;Saver.save()&lt;/code&gt; or those of &lt;a href=&quot;../../../train/latest_checkpoint&quot;&gt;&lt;code&gt;tf.train.latest_checkpoint()&lt;/code&gt;&lt;/a&gt;, regardless of sharded/non-sharded or V1/V2.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfa77622762529e62cce47be75b5d7ef8f04b09b" translate="yes" xml:space="preserve">
          <source>a list of checkpoint paths.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8652d1441c07c34c2491a5fef88f30f328252a67" translate="yes" xml:space="preserve">
          <source>a list of device strings such as &lt;code&gt;['/gpu:0', '/gpu:1']&lt;/code&gt;. If &lt;code&gt;None&lt;/code&gt;, all available GPUs are used. If no GPUs are found, CPU is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5dd923854fce47fe5a5fbe46663ed04995594696" translate="yes" xml:space="preserve">
          <source>a list of float values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3cae41a96c3b2e908d36cbc657c22fa2a8eb5b02" translate="yes" xml:space="preserve">
          <source>a list of gradients, one for each element of target. Defaults to None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca7a0932035e5c9de07f92110d3540ab4ff578d3" translate="yes" xml:space="preserve">
          <source>a list of loss tensors.</source>
          <target state="translated">una lista de tensores de pérdida.</target>
        </trans-unit>
        <trans-unit id="8466476c20c2b4575b81f48bbef14bb81277fd56" translate="yes" xml:space="preserve">
          <source>a list of names of layers to keep eye on. If None or empty list all the embedding layer will be watched.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f3cccd7e469ea448da74293963e6a99fb093741" translate="yes" xml:space="preserve">
          <source>a list of prediction keys. Key can be either the class variable of prediction_keys.PredictionKeys or its string value, such as: prediction_keys.PredictionKeys.LOGITS or 'logits'.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe1e44e58043e3bac62424bc232c0f828907d045" translate="yes" xml:space="preserve">
          <source>a list of tuples &lt;code&gt;(tensor, value)&lt;/code&gt;. &lt;code&gt;value&lt;/code&gt; should be a Numpy array.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2e03752a3549be3776b9abdbd4707084bba9047" translate="yes" xml:space="preserve">
          <source>a list of variables that need to be averaged. Only needed if variable_averages is passed in.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3eb0f04e7fc6ee40cdb193ac62baee8bb1ca6431" translate="yes" xml:space="preserve">
          <source>a list of variables that require to use of the moving average variable name to be restored. If None, it will default to variables.moving_average_variables() + variables.trainable_variables()</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91a77371e3824445e17865c21a8864e288e638bc" translate="yes" xml:space="preserve">
          <source>a list or nested structure of Tensors (or IndexedSlices, or None), one for each element in &lt;code&gt;sources&lt;/code&gt;. Returned structure is the same as the structure of &lt;code&gt;sources&lt;/code&gt;.</source>
          <target state="translated">una lista o estructura anidada de tensores (o IndexedSlices, o Ninguno), uno para cada elemento en las &lt;code&gt;sources&lt;/code&gt; . La estructura devuelta es la misma que la estructura de las &lt;code&gt;sources&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7c876daa0f22003807573109c8a715b9d71802ff" translate="yes" xml:space="preserve">
          <source>a list or nested structure of Tensors or Variables to be differentiated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4276967efbeb15913c139768efe32fe80016a5bd" translate="yes" xml:space="preserve">
          <source>a list or nested structure of Tensors or Variables. &lt;code&gt;target&lt;/code&gt; will be differentiated against elements in &lt;code&gt;sources&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2b8519688d6e08f0ef3f1f53563b370c82f252c" translate="yes" xml:space="preserve">
          <source>a list or tuple of &lt;code&gt;DType&lt;/code&gt; objects or strings that can be converted to &lt;code&gt;DType&lt;/code&gt; objects via &lt;a href=&quot;../../dtypes/as_dtype&quot;&gt;&lt;code&gt;tf.as_dtype()&lt;/code&gt;&lt;/a&gt;. Examples:</source>
          <target state="translated">una lista o tupla de &lt;code&gt;DType&lt;/code&gt; objetos o cadenas que se pueden convertir en &lt;code&gt;DType&lt;/code&gt; objetos a trav&amp;eacute;s de &lt;a href=&quot;../../dtypes/as_dtype&quot;&gt; &lt;code&gt;tf.as_dtype()&lt;/code&gt; &lt;/a&gt; . Ejemplos:</target>
        </trans-unit>
        <trans-unit id="4a6bdafb64b93a495b672af20865dc481b0ed23a" translate="yes" xml:space="preserve">
          <source>a list or tuple of prediction keys. Each key can be either the class variable of prediction_keys.PredictionKeys or its string value, such as: prediction_keys.PredictionKeys.CLASSES or 'classes'. If not specified, it will return the predictions for all valid keys.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e062962fff519e51826af13e2686d1b25c61f1c" translate="yes" xml:space="preserve">
          <source>a name for the op that creates the writer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82f9e1f9d52a6496cd6e1fbefeba7b546e34e817" translate="yes" xml:space="preserve">
          <source>a nest of NumPy input arrays that will be converted into a dataset. Note that the NumPy arrays are stacked, as that is normal &lt;a href=&quot;../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; behavior.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef8e153138ea9a5535d4306bcbaa35a18fc052c8" translate="yes" xml:space="preserve">
          <source>a nest of NumPy input arrays that will be converted into a dataset. Note that the NumPy arrays are stacked, as that is normal &lt;a href=&quot;../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; behavior.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="beb20ec17e12b3a92d15870c8fb928b39be9384e" translate="yes" xml:space="preserve">
          <source>a new instance of &lt;code&gt;RunConfig&lt;/code&gt;.</source>
          <target state="translated">una nueva instancia de &lt;code&gt;RunConfig&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7ebfcefc6e47ac4ed9512e51f768d3cbe5c823cb" translate="yes" xml:space="preserve">
          <source>a numpy array.</source>
          <target state="translated">...una serie de números.</target>
        </trans-unit>
        <trans-unit id="583166dd6bf07228d6040841ccf402891050a5e4" translate="yes" xml:space="preserve">
          <source>a numpy ndarray.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d253db5a4761b53c7ffde3781cb4f03e7cb07091" translate="yes" xml:space="preserve">
          <source>a path relative to tensorflow root. e.g. &quot;core/platform&quot;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d434acfa4631c87791b616c82b7e6083ce9a28b9" translate="yes" xml:space="preserve">
          <source>a positive float represented as fraction of value, or a tuple of size 2 representing lower and upper bound. When represented as a single float, lower = upper. The contrast factor will be randomly picked between [1.0 - lower, 1.0 + upper].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b17aca81e79c7530a3bc5fdc0659c98cdbd45a6" translate="yes" xml:space="preserve">
          <source>a premade LinearModel, its output must match the output of the dnn model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="259c33a51ca2823379036c66fbe8b38a134e8892" translate="yes" xml:space="preserve">
          <source>a python scalar or a scalar tensor. Mean of the random values to generate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5d4da2cd944c3f7f7ef6b9224fdc61a3e90e225" translate="yes" xml:space="preserve">
          <source>a python scalar or a scalar tensor. Standard deviation of the random values to generate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3267c112f6d4d3c0519780ece91f770b5ea07cc2" translate="yes" xml:space="preserve">
          <source>a rank (N+2) &lt;code&gt;filter&lt;/code&gt; Tensor of shape</source>
          <target state="translated">un &lt;code&gt;filter&lt;/code&gt; de rango (N + 2) Tensor de forma</target>
        </trans-unit>
        <trans-unit id="567bea64cd23153635d3d86fe4dc29e83b999e55" translate="yes" xml:space="preserve">
          <source>a rank (N+2) &lt;code&gt;filters&lt;/code&gt; Tensor of shape</source>
          <target state="translated">un rango (N + 2) &lt;code&gt;filters&lt;/code&gt; Tensor de forma</target>
        </trans-unit>
        <trans-unit id="a9d06e247ca03db1069906ff93f237957d9b8b9a" translate="yes" xml:space="preserve">
          <source>a scalar integer &lt;code&gt;Tensor&lt;/code&gt; representing the maximum number of boxes to be selected by non max suppression.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3fca9faa64f5b46a4d7ce176156b7c88545b1baa" translate="yes" xml:space="preserve">
          <source>a shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e3fab1cb04b3c63a683f54ad32d8e23b5b601ed" translate="yes" xml:space="preserve">
          <source>a single argument or a list of arguments (typically a list of default values); a single argument is converted internally into a list containing one item.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cbfc6ae061d8de0cb83e913ad03f6acad9950c0" translate="yes" xml:space="preserve">
          <source>a single data type (float32, int32, or string, for example)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6b451769762c48595037c2a99820e1960c8d664" translate="yes" xml:space="preserve">
          <source>a single or a list the remote server addr in host-port format.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b5a8f6cdc727f3954a46a20a08afdbba957f018" translate="yes" xml:space="preserve">
          <source>a size entry is interpreted as &lt;em&gt;any&lt;/em&gt; size if it is None or '.'.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1598d219bbf50d48513b4d681ac2e664678a0fb2" translate="yes" xml:space="preserve">
          <source>a size entry is interpreted as an explicit size if it can be parsed as an integer primitive.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc48ba5f69c2b3b1cd2c64475359fd4da8d724e2" translate="yes" xml:space="preserve">
          <source>a string added between each string being joined.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3901c8cf09bba87b3019c11d2d00ae2d940cb1a" translate="yes" xml:space="preserve">
          <source>a string for the name of the executor to be used to execute functions defined by tf.contrib.eager.defun.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f317a91fbf6fd20ea76003a27e77d226e69d5e9f" translate="yes" xml:space="preserve">
          <source>a string of the form /job:</source>
          <target state="translated">una cadena de la forma/trabajo:</target>
        </trans-unit>
        <trans-unit id="592805594d7acec2e035ccb78cd57e76d0c89267" translate="yes" xml:space="preserve">
          <source>a string path indicating where to write the TFRecord data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28879ce16025e8aea78e0eed31c3828842400532" translate="yes" xml:space="preserve">
          <source>a string resource path relative to tensorflow/</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf98d147fdc1a4586c1261348ed08e3ea9d55344" translate="yes" xml:space="preserve">
          <source>a string resource path relative to tensorflow/.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="382e66fb08d6f4af34d47af5189e64c302e25ab8" translate="yes" xml:space="preserve">
          <source>a string specifying the directory in which to write an event file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8d4b27e20cdf3399f6ff473e703a75399bc6632" translate="yes" xml:space="preserve">
          <source>a string specifying the path to an existing SavedModel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c782ca359f58ff03f46b2cba60080dcab6928ea" translate="yes" xml:space="preserve">
          <source>a string specifying the path to the SavedModel directory.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e66ef56dd71685a637ed8bde76e00efab58fe5da" translate="yes" xml:space="preserve">
          <source>a string-type Tensor to summarize.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56c95190656de2a73fe1c13de36287330da4d209" translate="yes" xml:space="preserve">
          <source>a string. The address of the master to use for eval. Defaults to master if not set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2db3d823dea26a64286f31522b26f56802a1985" translate="yes" xml:space="preserve">
          <source>a string. The address of the master to use for training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a00a84ed543b41fac41116a0ecb87c993c7cda7" translate="yes" xml:space="preserve">
          <source>a summary_pb2.SummaryDescription</source>
          <target state="translated">a summary_pb2.SummaryDescription</target>
        </trans-unit>
        <trans-unit id="45f3aa41e8ac0fd197acaacc063a6ad881fe4154" translate="yes" xml:space="preserve">
          <source>a tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4ae58d9fb87a25f2deeed86b25ef281f7e84171" translate="yes" xml:space="preserve">
          <source>a tensor of rank 1 or higher with a shape of [..., num_boxes].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b4fd33d17d7c9e469c896528f1317da39655996" translate="yes" xml:space="preserve">
          <source>a tensor of rank 2 or higher with a shape of [..., num_boxes, 4]. Dimensions except the last two are batch dimensions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb28536b86a99e6d9c4639674cb74b760427a486" translate="yes" xml:space="preserve">
          <source>a tensor or list of tensors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="640aa7ca6a8766d889609357ce01db334a546544" translate="yes" xml:space="preserve">
          <source>a tuple of (&lt;code&gt;sampled_candidates&lt;/code&gt;, &lt;code&gt;true_expected_count&lt;/code&gt;, &lt;code&gt;sampled_expected_count&lt;/code&gt;) returned by a &lt;code&gt;*_candidate_sampler&lt;/code&gt; function. (if None, we default to &lt;code&gt;log_uniform_candidate_sampler&lt;/code&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcfc12d63102b45a3e6037e53f6854edb7f5b381" translate="yes" xml:space="preserve">
          <source>a tuple of 2 integers, specifying the strides of the convolution along the width and height.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d183d11d0d54a060d7009b34542317f6fc714e19" translate="yes" xml:space="preserve">
          <source>a tuple of 2 integers, specifying the width and height of the 2D convolution window.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57a238277396d1dc9a17a850fb1ad6b9aa782459" translate="yes" xml:space="preserve">
          <source>a tuple of a single integer, specifying the length of the 1D convolution window.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="143bed0bba33eacbf68b60d1ca77684c689464bf" translate="yes" xml:space="preserve">
          <source>a tuple of a single integer, specifying the stride length of the convolution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab7dc476556d1061e224a2a7a8aa11501a5707ed" translate="yes" xml:space="preserve">
          <source>a tuple of strings, which describes all the TPU devices in the system.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aea224a6c5fec351ebdbae08e0bd3ba1b0c63d75" translate="yes" xml:space="preserve">
          <source>a tuple with (output_row, output_col).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8afd66969dd06ed1eba4fe64521e14d7727d738b" translate="yes" xml:space="preserve">
          <source>a tuple/list of strings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47ed70eec68109426c23a40515035b914c0da955" translate="yes" xml:space="preserve">
          <source>a value which can either hold 'none' or 'zero' and alters the value which will be returned if the target and sources are unconnected. The possible values and effects are detailed in 'UnconnectedGradients' and it defaults to 'none'.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8ebd3b7d7e693185180008e1a8aaa05435c3d8c" translate="yes" xml:space="preserve">
          <source>a vector of dtype STATE_TYPE representing the initial counter for the RNG, whose length is algorithm-specific.,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0cfcb777f5630e0744dd02bb3be535bf23c0558" translate="yes" xml:space="preserve">
          <source>a vector of dtype STATE_TYPE representing the initial state of the RNG, whose length and semantics are algorithm-specific. If it's a variable, the generator will reuse it instead of creating a new variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af97be5a0dcfe7dd967ed814e5c51b34d26e758a" translate="yes" xml:space="preserve">
          <source>a) If a loop variable is a SparseTensor, the shape invariant must be TensorShape([r]) where r is the rank of the dense tensor represented by the sparse tensor. It means the shapes of the three tensors of the SparseTensor are ([None], [None, r], [r]). NOTE: The shape invariant here is the shape of the SparseTensor.dense_shape property. It must be the shape of a vector.</source>
          <target state="translated">a)Si una variable de bucle es un SparseTensor,la invariante de forma debe ser TensorShape([r])donde r es el rango del tensor denso representado por el tensor disperso.Significa que las formas de los tres tensores del SparseTensor son ([None],[None,r],[r]).NOTA:La invariante de forma aquí es la forma de la propiedad SparseTensor.dense_shape.Debe ser la forma de un vector.</target>
        </trans-unit>
        <trans-unit id="addb12381e6be0fb67d7d9c7e9625d221a558d6e" translate="yes" xml:space="preserve">
          <source>a: A &lt;code&gt;CSRSparseMatrix&lt;/code&gt;. b: A &lt;code&gt;CSRSparseMatrix&lt;/code&gt; with the same type and rank as &lt;code&gt;a&lt;/code&gt;. type: The type of both &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt;. transpose_a: If True, &lt;code&gt;a&lt;/code&gt; transposed before multiplication. transpose_b: If True, &lt;code&gt;b&lt;/code&gt; transposed before multiplication. adjoint_a: If True, &lt;code&gt;a&lt;/code&gt; adjointed before multiplication. adjoint_b: If True, &lt;code&gt;b&lt;/code&gt; adjointed before multiplication.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a35ea6647dc95b90fe453d98f66e284fc5f0c506" translate="yes" xml:space="preserve">
          <source>a[0] = 0 : the first value of the sequence is 0</source>
          <target state="translated">a[0]=0:el primer valor de la secuencia es 0</target>
        </trans-unit>
        <trans-unit id="deda22cbcad48bb3a1413dc8ff28a54f1e5592e8" translate="yes" xml:space="preserve">
          <source>a[end] = input_row_length : the last value of the sequence is the size</source>
          <target state="translated">a[end]=input_row_length:el último valor de la secuencia es el tamaño</target>
        </trans-unit>
        <trans-unit id="eb8f95bc156db1900a569b1735ddc3da656d19bc" translate="yes" xml:space="preserve">
          <source>about sharing states in tensorflow.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0f846898da4ec61cf83b3e2c8495d2978a0200c" translate="yes" xml:space="preserve">
          <source>absolute tolerance for bfloat16.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ae04d0b7afda8def3fdb79e35983e0773b0864f" translate="yes" xml:space="preserve">
          <source>absolute tolerance for float16.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3cfa07cb0663ab1cde306433e352a29097f65419" translate="yes" xml:space="preserve">
          <source>absolute tolerance for float32.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4fd56eead7560ee583f1b8caad28fbd463bee25" translate="yes" xml:space="preserve">
          <source>absolute tolerance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e1f32f51354c2febc7caaaf4ffeef8cbb8f07cf" translate="yes" xml:space="preserve">
          <source>accum += grad * grad prox_v = var - lr * grad * (1 / sqrt(accum)) var = sign(prox_v)/(1+lr*l2) * max{|prox_v|-lr*l1,0}</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26c2261a427773f28da9c962c61401a44f52fafa" translate="yes" xml:space="preserve">
          <source>accum += grad * grad var -= lr * grad * (1 / (sqrt(accum) + epsilon))</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b39d4103e267bfff6b19f03a0c61954510b506e" translate="yes" xml:space="preserve">
          <source>accum += grad * grad var -= lr * grad * (1 / sqrt(accum))</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbdff22455472e83bbec28e270efc5acd84cec93" translate="yes" xml:space="preserve">
          <source>accum = accum * momentum + grad var -= lr * accum</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cabf3744d4cc537b306d1c2d4e5c98eab9321c1c" translate="yes" xml:space="preserve">
          <source>accum = accum * momentum - lr * grad var += accum</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77aa7bbfc2a1935f26fc03cc068c50ab9de9da1b" translate="yes" xml:space="preserve">
          <source>accum = rho() * accum + (1 - rho()) * grad.square(); update = (update_accum + epsilon).sqrt() * (accum + epsilon()).rsqrt() * grad; update_accum = rho() * update_accum + (1 - rho()) * update.square(); var -= update;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e072c3a42e30a463ae763379bfd4971f6786c3db" translate="yes" xml:space="preserve">
          <source>accum_new = accum + grad * grad linear += grad - (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2 var = (sign(linear) * l1 - linear) / quadratic if |linear| &amp;gt; l1 else 0.0 accum = accum_new</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9207a4d89e0769ab8d4e61e6e2f82d2491a3631b" translate="yes" xml:space="preserve">
          <source>actual distribution of the values to maximize the usage of the lower bit depth and adjusting the output min and max ranges accordingly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="336367a90c28a1ba840266e48935292b8c0ec99a" translate="yes" xml:space="preserve">
          <source>add and relu and requantize fusion.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3eebca9963a4e9d6f0fcc02adef3bd6f1fb5966b" translate="yes" xml:space="preserve">
          <source>add and relu fusion.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="577f333710522bc0627398bf6ba75e178aa283d7" translate="yes" xml:space="preserve">
          <source>add.</source>
          <target state="translated">add.</target>
        </trans-unit>
        <trans-unit id="b1b7d0394cceca9bd35a4316061103e356401833" translate="yes" xml:space="preserve">
          <source>additional keyword arguments to be passed to the underlying &lt;code&gt;assertAllClose&lt;/code&gt; call.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d0442ecdcd49f18c5f26a6c7ac65eb7852e6a16" translate="yes" xml:space="preserve">
          <source>adjoints (conjugate transposes).</source>
          <target state="translated">adosados (transposiciones conjugadas).</target>
        </trans-unit>
        <trans-unit id="f0e72c8db0ec39595db76cd9ab3ea0b01fa0a54e" translate="yes" xml:space="preserve">
          <source>adjusted_dilation_rate is an int64 tensor of shape [max(spatial&lt;em&gt;dims)], adjusted&lt;/em&gt;{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2]</source>
          <target state="translated">Adjust_dilation_rate es un tensor de forma int64 [max (atenuaciones espaciales &lt;em&gt;)], los&lt;/em&gt; {paddings, recortes} ajustados son tensores de forma int64 [max (space_dims), 2]</target>
        </trans-unit>
        <trans-unit id="05ab368bb50c30f0ad36866b483ced3c24cef7fa" translate="yes" xml:space="preserve">
          <source>adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i] adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :] adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :]</source>
          <target state="translated">adjusted_dilation_rate[spatial_dims[i]-1]=dilation_rate[i]adjusted_paddings[spatial_dims[i]-1,:]=paddings[i,:]adjusted_crops[spatial_dims[i]-1,:]=crops[i,:]</target>
        </trans-unit>
        <trans-unit id="a4cbf8207b85c3ddcaf0003b5cf461ae49770af7" translate="yes" xml:space="preserve">
          <source>after each call to &lt;code&gt;Saver.save()&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10582f7ebb86265685f2d94ac9bf45194c26c416" translate="yes" xml:space="preserve">
          <source>aggregation: Indicates how a distributed variable will be aggregated. Accepted values are constants defined in the class &lt;a href=&quot;../../variableaggregation&quot;&gt;&lt;code&gt;tf.VariableAggregation&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">agregaci&amp;oacute;n: indica c&amp;oacute;mo se agregar&amp;aacute; una variable distribuida. Los valores aceptados son constantes definidas en la clase &lt;a href=&quot;../../variableaggregation&quot;&gt; &lt;code&gt;tf.VariableAggregation&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="95142e8db6f0e670c6cdd282ebda2a8dc3235286" translate="yes" xml:space="preserve">
          <source>aggregation: Indicates how a distributed variable will be aggregated. Accepted values are constants defined in the class &lt;a href=&quot;variableaggregation&quot;&gt;&lt;code&gt;tf.VariableAggregation&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">agregaci&amp;oacute;n: indica c&amp;oacute;mo se agregar&amp;aacute; una variable distribuida. Los valores aceptados son constantes definidas en la clase &lt;a href=&quot;variableaggregation&quot;&gt; &lt;code&gt;tf.VariableAggregation&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0b9a9b6a555fda3290e62d85d68e6dc900f6aa72" translate="yes" xml:space="preserve">
          <source>alias for &quot;input&quot; argument.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40ab33a302eea4103a7a9fe7699eb8c64bfbebd3" translate="yes" xml:space="preserve">
          <source>alias for expand_nonconcat_dim</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b47a9fb6a6098b56fa005c9bf092d1ede95a90d" translate="yes" xml:space="preserve">
          <source>alpha = input_row_length / output_row_length : our reduction ratio</source>
          <target state="translated">alpha=input_row_length/output_row_length:nuestro ratio de reducción</target>
        </trans-unit>
        <trans-unit id="13c37d0b0868b315be5754e60b93df3ddf6e1515" translate="yes" xml:space="preserve">
          <source>amount of weight decay to apply; None means that the weights are not decayed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="584cfc3585963e88777945fd0c74c8fed91e27d7" translate="yes" xml:space="preserve">
          <source>amount of weight decay to apply; None means that the weights are not decayed. Weights are decayed by multiplying the weight by this factor each step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6be75b3f1c53a534ff3d3d88d27d62dd86a8b144" translate="yes" xml:space="preserve">
          <source>an &lt;code&gt;int32&lt;/code&gt; or &lt;code&gt;int64&lt;/code&gt; scalar representing data to be folded in to the seed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21498301c88a4012ed64c1b4b7225d60e8644258" translate="yes" xml:space="preserve">
          <source>an &lt;code&gt;int&lt;/code&gt; shows until which global step should we wait.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60271ab37cee858c4218f052e21a7603d914d273" translate="yes" xml:space="preserve">
          <source>an OrderedDict, where the keys are the feature column names and the values are importances. It is sorted by importance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e7cd4b2e10dade102ff7156179e9913d87e9c02" translate="yes" xml:space="preserve">
          <source>an RNG seed (a tensor with shape [2] and dtype &lt;code&gt;int32&lt;/code&gt; or &lt;code&gt;int64&lt;/code&gt;). (When using XLA, only &lt;code&gt;int32&lt;/code&gt; is allowed.)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f4a60ab5b3884b1dd6263e0c0406bab2fcc7011" translate="yes" xml:space="preserve">
          <source>an RNNCell, a projection to output_size is added to it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4795fec293585f2b8f245ac28ac09c142cad999f" translate="yes" xml:space="preserve">
          <source>an approximation of the area under the P-R curve.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4d758ce3efd3e79d82b2ead6ef75b7be77f612b" translate="yes" xml:space="preserve">
          <source>an arbitrarily nested structure.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4b9296a58496856781b45283ebf3905a9774cf6" translate="yes" xml:space="preserve">
          <source>an arbitrarily nested structure. Note, numpy arrays are considered atoms and are not flattened.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78bf9b0c50970fcea95462ac064c671c66592d16" translate="yes" xml:space="preserve">
          <source>an enum value of &lt;a href=&quot;../../../../distribute/inputreplicationmode&quot;&gt;&lt;code&gt;tf.distribute.InputReplicationMode&lt;/code&gt;&lt;/a&gt;. Only &lt;code&gt;PER_WORKER&lt;/code&gt; is supported currently, which means there will be a single call to &lt;code&gt;input_fn&lt;/code&gt; per worker. Replicas will dequeue from the local &lt;a href=&quot;../../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; on their worker.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1d9638fbc99061f41f5f1718d95aa9d9b2ba446" translate="yes" xml:space="preserve">
          <source>an enum value of &lt;a href=&quot;../../../distribute/inputreplicationmode&quot;&gt;&lt;code&gt;tf.distribute.InputReplicationMode&lt;/code&gt;&lt;/a&gt;. Only &lt;code&gt;PER_WORKER&lt;/code&gt; is supported currently, which means there will be a single call to &lt;code&gt;input_fn&lt;/code&gt; per worker. Replicas will dequeue from the local &lt;a href=&quot;../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; on their worker.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3759390b842509817496ad6964a87f97c5843a65" translate="yes" xml:space="preserve">
          <source>an input generator that can be used to generate input samples for the model. This must be a callable object that returns an object that supports the &lt;code&gt;iter()&lt;/code&gt; protocol (e.g. a generator function). The elements generated must have same type and shape as inputs to the model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8feb6baf60936cf60390ee049e7a07e3ffd4392a" translate="yes" xml:space="preserve">
          <source>an input sequence.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d46e772e042b91ec9dff778f5110d720bafa374" translate="yes" xml:space="preserve">
          <source>an instance of &lt;a href=&quot;../configproto&quot;&gt;&lt;code&gt;tf.compat.v1.ConfigProto&lt;/code&gt;&lt;/a&gt; proto used to configure the session. It's the &lt;code&gt;config&lt;/code&gt; argument of constructor of &lt;a href=&quot;../session&quot;&gt;&lt;code&gt;tf.compat.v1.Session&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a37f2503f46094f2d360fd3f7fc596a57b2fd3f" translate="yes" xml:space="preserve">
          <source>an instance of &lt;a href=&quot;topology&quot;&gt;&lt;code&gt;tf.tpu.experimental.Topology&lt;/code&gt;&lt;/a&gt;, which describes the physical topology of TPU system.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd841e8ca3fc9c05fb813b0d2f5d9103dc9c0ba8" translate="yes" xml:space="preserve">
          <source>an instance of &lt;code&gt;tf.train.experimental/ClusterDeviceFilters&lt;/code&gt; that specify device filters to the remote tasks in cluster.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e2d70312bfddfcd3ddb72da0a20ed277ffcd67f" translate="yes" xml:space="preserve">
          <source>an integer or 1-D numpy array.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2085d387df6482fce1af122d6acdb0118638ce0b" translate="yes" xml:space="preserve">
          <source>an integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any &lt;code&gt;dilation_rate&lt;/code&gt; value != 1 is incompatible with specifying any stride value != 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12a0347d0bf66b603b4cf339883f33c0d26b06b7" translate="yes" xml:space="preserve">
          <source>an integer or tuple/list of 3 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any &lt;code&gt;dilation_rate&lt;/code&gt; value != 1 is incompatible with specifying any stride value != 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3402e6e4b4d2964f62630d5d955c60e92608fd4" translate="yes" xml:space="preserve">
          <source>an integer or tuple/list of a single integer, specifying the dilation rate to use for dilated convolution. Currently, specifying any &lt;code&gt;dilation_rate&lt;/code&gt; value != 1 is incompatible with specifying any &lt;code&gt;strides&lt;/code&gt; value != 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58266c81cd572b21187fd9645689ccfc5a6f9adf" translate="yes" xml:space="preserve">
          <source>an integer representing the number of boxes in a tile, i.e., the maximum number of boxes per image that can be used to suppress other boxes in parallel; larger tile_size means larger parallelism and potentially more redundant work.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12f87a898c564b834112575d56e2166669cc6140" translate="yes" xml:space="preserve">
          <source>an integer, specifying the dilation rate to use for dilated convolution. Currently, specifying a &lt;code&gt;dilation_rate&lt;/code&gt; value != 1 is incompatible with specifying a stride value != 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36442510bd24021bdca61b0550d53fc4b7f41549" translate="yes" xml:space="preserve">
          <source>an integer: 1 or 2. 1 corresponds to V1, 2 corresponds to V2. (Defaults to V1). With V1, &lt;code&gt;export_saved_model()&lt;/code&gt; adds rewrite() and TPUPartitionedCallOp() for user; while in v2, user is expected to add rewrite(), TPUPartitionedCallOp() etc in their model_fn. A helper function &lt;code&gt;inference_on_tpu&lt;/code&gt; is provided for V2. brn_tpu_estimator.py includes examples for both versions i.e. TPUEstimatorExportTest and TPUEstimatorExportV2Test.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15bd4e656cd87110cb6d06a7f5b3f1e300030cdd" translate="yes" xml:space="preserve">
          <source>an optional &lt;code&gt;dilation_rate&lt;/code&gt; tensor of shape &lt;a href=&quot;defaulting%20to%20%5b1%5d*n&quot;&gt;N&lt;/a&gt; specifying the filter upsampling/input downsampling rate, and an optional list of N &lt;code&gt;strides&lt;/code&gt; (defaulting [1]*N), this computes for each N-D spatial output position (x[0], ..., x[N-1]):</source>
          <target state="translated">un tensor opcional &lt;code&gt;dilation_rate&lt;/code&gt; de forma &lt;a href=&quot;defaulting%20to%20%5b1%5d*n&quot;&gt;N que&lt;/a&gt; especifica la tasa de muestreo ascendente / descendente de entrada del filtro, y una lista opcional de N &lt;code&gt;strides&lt;/code&gt; (por defecto [1] * N), esto calcula para cada posici&amp;oacute;n de salida espacial ND (x [0], ..., x [N-1]):</target>
        </trans-unit>
        <trans-unit id="0ee24f38b8e109fbd5639cc2b47bec50e32475ed" translate="yes" xml:space="preserve">
          <source>an optional &lt;code&gt;dilations&lt;/code&gt; tensor of shape &lt;a href=&quot;defaulting%20to%20%5b1%5d*n&quot;&gt;N&lt;/a&gt; specifying the filter upsampling/input downsampling rate, and an optional list of N &lt;code&gt;strides&lt;/code&gt; (defaulting [1]*N), this computes for each N-D spatial output position (x[0], ..., x[N-1]):</source>
          <target state="translated">un tensor de &lt;code&gt;dilations&lt;/code&gt; opcional de forma &lt;a href=&quot;defaulting%20to%20%5b1%5d*n&quot;&gt;N que&lt;/a&gt; especifica la tasa de muestreo ascendente / descendente de entrada del filtro, y una lista opcional de N &lt;code&gt;strides&lt;/code&gt; (por defecto [1] * N), esto calcula para cada posici&amp;oacute;n de salida espacial ND (x [0], ..., x [N-1]):</target>
        </trans-unit>
        <trans-unit id="ab989fce67e1a28670d6c810e49317fa6212a61a" translate="yes" xml:space="preserve">
          <source>an optional name for the operation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f33599b0487789dd89792f29c86c4b410cef6e4" translate="yes" xml:space="preserve">
          <source>an optional string of the form /job:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cffa50a32cb13a240d705317bcec65dd1f31b6ad" translate="yes" xml:space="preserve">
          <source>and</source>
          <target state="translated">and</target>
        </trans-unit>
        <trans-unit id="ebd46f618c63c3e212b1d778f0a25f4660c23598" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;SparseFeature&lt;/code&gt; config with 2 &lt;code&gt;index_key&lt;/code&gt;s</source>
          <target state="translated">y configuraci&amp;oacute;n de &lt;code&gt;SparseFeature&lt;/code&gt; con 2 &lt;code&gt;index_key&lt;/code&gt; s</target>
        </trans-unit>
        <trans-unit id="6140381926bf0d082343ace25ade2e3cf221f627" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;default_value&lt;/code&gt; is &lt;code&gt;x&lt;/code&gt;, then the output will be a dense &lt;code&gt;[3, 5]&lt;/code&gt; string tensor with values:</source>
          <target state="translated">y &lt;code&gt;default_value&lt;/code&gt; es &lt;code&gt;x&lt;/code&gt; , entonces la salida ser&amp;aacute; un tensor de cadena denso &lt;code&gt;[3, 5]&lt;/code&gt; con valores:</target>
        </trans-unit>
        <trans-unit id="90e193944d6b8498e0257c00b2820369a0de3479" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;ids&lt;/code&gt; is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2d759c667e68226ece3acd5aa4e1cc6620b0ca0" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;max&lt;/code&gt; to 'outputs' tensor of same shape as &lt;code&gt;inputs&lt;/code&gt;.</source>
          <target state="translated">y tensor de &lt;code&gt;max&lt;/code&gt; a 'salidas' de la misma forma que las &lt;code&gt;inputs&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="78fbe88a4e8420d083776e826c4b0cd5bb232375" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;shape&lt;/code&gt; is &lt;code&gt;[9, -1]&lt;/code&gt;, then the output will be a &lt;code&gt;SparseTensor&lt;/code&gt; of shape &lt;code&gt;[9, 4]&lt;/code&gt; and &lt;code&gt;indices&lt;/code&gt; / &lt;code&gt;values&lt;/code&gt;:</source>
          <target state="translated">y la &lt;code&gt;shape&lt;/code&gt; es &lt;code&gt;[9, -1]&lt;/code&gt; , entonces la salida ser&amp;aacute; un &lt;code&gt;SparseTensor&lt;/code&gt; de forma &lt;code&gt;[9, 4]&lt;/code&gt; e &lt;code&gt;indices&lt;/code&gt; / &lt;code&gt;values&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="23cce7bb518f569f4a001bd92a904ee1f95e7599" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;to_retain = [True, False, False, True]&lt;/code&gt;, then the output will be a &lt;code&gt;SparseTensor&lt;/code&gt; of shape &lt;code&gt;[4, 5]&lt;/code&gt; with 2 non-empty values:</source>
          <target state="translated">y &lt;code&gt;to_retain = [True, False, False, True]&lt;/code&gt; , entonces la salida ser&amp;aacute; un &lt;code&gt;SparseTensor&lt;/code&gt; de forma &lt;code&gt;[4, 5]&lt;/code&gt; con 2 valores no vac&amp;iacute;os:</target>
        </trans-unit>
        <trans-unit id="3b2da781f92810fe2701eb25993573d612b9c1c1" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;vocab_size = 200&lt;/code&gt;, then the output will be a &lt;code&gt;[2, 3, 200]&lt;/code&gt; dense bool tensor with False everywhere except at positions</source>
          <target state="translated">y &lt;code&gt;vocab_size = 200&lt;/code&gt; , entonces la salida ser&amp;aacute; un tensor bool denso &lt;code&gt;[2, 3, 200]&lt;/code&gt; con False en todas partes excepto en las posiciones</target>
        </trans-unit>
        <trans-unit id="fb47192727f17143a048825f4ab10f7ac6f7e0a3" translate="yes" xml:space="preserve">
          <source>and False elsewhere in &lt;code&gt;output&lt;/code&gt;.</source>
          <target state="translated">y Falso en otras partes de la &lt;code&gt;output&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="41290a0f5cbc0ce6a4dfe0924ac8b26a039d1f24" translate="yes" xml:space="preserve">
          <source>and concatenates them into a Tensor of shape:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7d1a416a2e3a434f40699d9880f90f9fb160f7e" translate="yes" xml:space="preserve">
          <source>and having size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2223100c859ddb72353f03c35f828882929aa04b" translate="yes" xml:space="preserve">
          <source>and if &lt;code&gt;M = N&lt;/code&gt;,</source>
          <target state="translated">y si &lt;code&gt;M = N&lt;/code&gt; ,</target>
        </trans-unit>
        <trans-unit id="1eb3d95c362b4e4d700bf804104fec0c967f459d" translate="yes" xml:space="preserve">
          <source>and process 2 prints</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ba895928ad073edb53326fb61cbb432a1464bec" translate="yes" xml:space="preserve">
          <source>and that &lt;code&gt;value&lt;/code&gt; has shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34d19665daa7f1410ef46ef88c82079153b1d866" translate="yes" xml:space="preserve">
          <source>and then compute a normalized (x), including a small factor ({\epsilon}) for numerical stability.</source>
          <target state="translated">y luego calcular un normalizado (x),incluyendo un pequeño factor ({\silon})para la estabilidad numérica.</target>
        </trans-unit>
        <trans-unit id="d8047f0fdc4d1e4560c970ac0b82f51065da8044" translate="yes" xml:space="preserve">
          <source>and then compute a normalized &lt;code&gt;x_i_normalized&lt;/code&gt;, including a small factor &lt;code&gt;epsilon&lt;/code&gt; for numerical stability.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cc52111330674297a42724a1642fd203137a2d3" translate="yes" xml:space="preserve">
          <source>and therefore</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78e8b25cc130b65509b44b60a2a5f53ed883a7db" translate="yes" xml:space="preserve">
          <source>append(self: tensorflow.python._tf_stack.StackSummary, x: tensorflow.python._tf_stack.FrameSummary) -&amp;gt; None</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="30ff52b5b667d11b2ffe908d3a6ddb3a80cc4c30" translate="yes" xml:space="preserve">
          <source>arbitrary function</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9aafd247e69aac8e786d351d47d5cdf462d0745f" translate="yes" xml:space="preserve">
          <source>arithmetic_optimization: Simplify arithmetic ops with common sub-expression elimination and arithmetic simplification.</source>
          <target state="translated">aritmética_optimización:Simplificar las operaciones aritméticas con la eliminación de subexpresiones comunes y la simplificación aritmética.</target>
        </trans-unit>
        <trans-unit id="25c002c4154dbe462f9f8f1755f73522b0671750" translate="yes" xml:space="preserve">
          <source>array([[ 0., 0., 0.], [ 0., 0., 0.]], dtype=float32)</source>
          <target state="translated">array([[0.,0.,0.],[0.,0.,0.]],dtype=flotación32)</target>
        </trans-unit>
        <trans-unit id="50893921378b303e1550a97d489bc7de28064118" translate="yes" xml:space="preserve">
          <source>array-like, shape &lt;code&gt;(n_samples, n_features)&lt;/code&gt; Test samples where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the number of features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89cdb649416fd6a0dc9e7f39d49b6ab03d5879e8" translate="yes" xml:space="preserve">
          <source>array-like, shape &lt;code&gt;(n_samples, n_features)&lt;/code&gt; Training samples where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the number of features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="850565e7e77632b17d2cc1ddc239a6bfe2cae1b3" translate="yes" xml:space="preserve">
          <source>array-like, shape &lt;code&gt;(n_samples, n_outputs)&lt;/code&gt; Class probability estimates. In the case of binary classification, to match the scikit-learn API, will return an array of shape &lt;code&gt;(n_samples, 2)&lt;/code&gt; (instead of &lt;code&gt;(n_sample, 1)&lt;/code&gt; as in Keras).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65baf57d96f3cc1470e57342810a1de5f6a27f59" translate="yes" xml:space="preserve">
          <source>array-like, shape &lt;code&gt;(n_samples,)&lt;/code&gt; Class predictions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae0244ecc60195106b25820595b8db35a60ed5ec" translate="yes" xml:space="preserve">
          <source>array-like, shape &lt;code&gt;(n_samples,)&lt;/code&gt; Predictions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3416fc16abdc6956ef8e2ee3753937f82806270c" translate="yes" xml:space="preserve">
          <source>array-like, shape &lt;code&gt;(n_samples,)&lt;/code&gt; True labels for &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4e9940ae53eb744fbac597e70feee59a95b69b8" translate="yes" xml:space="preserve">
          <source>array-like, shape &lt;code&gt;(n_samples,)&lt;/code&gt; or &lt;code&gt;(n_samples, n_outputs)&lt;/code&gt; True labels for &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0c679f2bbcaf59c6d5d58d588516277aa10113f" translate="yes" xml:space="preserve">
          <source>as cpu and gpu are mutually exclusive. All entries are optional.</source>
          <target state="translated">ya que la CPU y la GPU son mutuamente excluyentes.Todas las entradas son opcionales.</target>
        </trans-unit>
        <trans-unit id="d81b6defc8e7983d824c066efff71d103284c806" translate="yes" xml:space="preserve">
          <source>as inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="307d5c7893e1f246cb5e563745a0402addd02464" translate="yes" xml:space="preserve">
          <source>assertSameElements([1, 1, 1, 0, 0, 0], [0, 1]) # Doesn't raise an AssertionError</source>
          <target state="translated">assertSameElements([1,1,1,0,0,0],[0,1])#No plantea un AssertionError</target>
        </trans-unit>
        <trans-unit id="2454abb84d63a230ebc92ebe78cf3aff74dea1e0" translate="yes" xml:space="preserve">
          <source>assertSetEqual uses ducktyping to support different types of sets, and is optimized for sets specifically (parameters must support a difference method).</source>
          <target state="translated">assertSetEqual utiliza la técnica de &quot;ducktyping&quot; para soportar diferentes tipos de conjuntos,y está optimizada para conjuntos específicos (los parámetros deben soportar un método diferente).</target>
        </trans-unit>
        <trans-unit id="223c6148b033dfedd56732627314f568565b952f" translate="yes" xml:space="preserve">
          <source>assertTotallyOrdered will check that instances can be ordered correctly. For example,</source>
          <target state="translated">assertTotallyOrdered comprobará que las instancias pueden ser ordenadas correctamente.Por ejemplo,</target>
        </trans-unit>
        <trans-unit id="260d4f1366ba09adb6172ca8fd634126e0e09014" translate="yes" xml:space="preserve">
          <source>associative container. Elements are ordered by key.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88d718f8abfa216a9d9fcc60c2c44acc25a8cb82" translate="yes" xml:space="preserve">
          <source>at &lt;code&gt;ckpt_path&lt;/code&gt; and potentially reorders its rows and columns using the specified remappings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b644d3d1649aa456171b6c0036601fd209ffbd9d" translate="yes" xml:space="preserve">
          <source>at the end of session</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
