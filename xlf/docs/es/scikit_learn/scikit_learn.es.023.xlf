<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="es" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="21601426cfbdf9a26553c2613d8f13b5c8a0699e" translate="yes" xml:space="preserve">
          <source>Validate scalar parameters type and value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec59a2a93f21b1aa3fbc16cd26b3b2dbab6fa78b" translate="yes" xml:space="preserve">
          <source>Validation curve.</source>
          <target state="translated">Curva de validación.</target>
        </trans-unit>
        <trans-unit id="675b8482a7f9f38fa965a1efe10c6a6ee6ec5cdb" translate="yes" xml:space="preserve">
          <source>Value added to the diagonal of the kernel matrix during fitting. Larger values correspond to increased noise level in the observations. This can also prevent a potential numerical issue during fitting, by ensuring that the calculated values form a positive definite matrix. If an array is passed, it must have the same number of entries as the data used for fitting and is used as datapoint-dependent noise level. Note that this is equivalent to adding a WhiteKernel with c=alpha. Allowing to specify the noise level directly as a parameter is mainly for convenience and for consistency with Ridge.</source>
          <target state="translated">Valor añadido a la diagonal de la matriz del núcleo durante el ajuste.Los valores más grandes corresponden al aumento del nivel de ruido en las observaciones.Esto también puede evitar un posible problema numérico durante el ajuste,asegurando que los valores calculados formen una matriz definitiva positiva.Si se pasa una matriz,ésta debe tener el mismo número de entradas que los datos utilizados para el ajuste y se utiliza como nivel de ruido dependiente del punto de datos.Nótese que esto equivale a añadir un WhiteKernel con c=alfa.Permitir especificar el nivel de ruido directamente como un parámetro es principalmente por conveniencia y por coherencia con Ridge.</target>
        </trans-unit>
        <trans-unit id="cdffc29f88adeffd4bcff100fb7aa53a66956d52" translate="yes" xml:space="preserve">
          <source>Value for numerical stability in adam. Only used when solver=&amp;rsquo;adam&amp;rsquo;</source>
          <target state="translated">Valor de estabilidad num&amp;eacute;rica en ad&amp;aacute;n. Solo se usa cuando solver = 'adam'</target>
        </trans-unit>
        <trans-unit id="c6350d6ef6528ee88ef12a12465bebefd1891dd8" translate="yes" xml:space="preserve">
          <source>Value of the pseudo-likelihood (proxy for likelihood).</source>
          <target state="translated">Valor de la seudoprobabilidad (sustituto de la probabilidad).</target>
        </trans-unit>
        <trans-unit id="7a1b051ea7b4e31aba2ba2519e8c31958f649214" translate="yes" xml:space="preserve">
          <source>Value to assign to the score if an error occurs in estimator fitting. If set to &amp;lsquo;raise&amp;rsquo;, the error is raised. If a numeric value is given, FitFailedWarning is raised. This parameter does not affect the refit step, which will always raise the error.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c9f9f5dcfc8aebd4eea110198ededa32c4b1278" translate="yes" xml:space="preserve">
          <source>Value to assign to the score if an error occurs in estimator fitting. If set to &amp;lsquo;raise&amp;rsquo;, the error is raised. If a numeric value is given, FitFailedWarning is raised. This parameter does not affect the refit step, which will always raise the error. Default is &amp;lsquo;raise&amp;rsquo; but from version 0.22 it will change to np.nan.</source>
          <target state="translated">Valor para asignar a la puntuaci&amp;oacute;n si se produce un error en el ajuste del estimador. Si se establece en 'subir', se genera el error. Si se proporciona un valor num&amp;eacute;rico, se genera FitFailedWarning. Este par&amp;aacute;metro no afecta el paso de reacondicionamiento, que siempre generar&amp;aacute; el error. El valor predeterminado es 'raise' pero a partir de la versi&amp;oacute;n 0.22 cambiar&amp;aacute; a np.nan.</target>
        </trans-unit>
        <trans-unit id="51fe27463b1bbffac6c175b98fff3a09a8ef007a" translate="yes" xml:space="preserve">
          <source>Value to assign to the score if an error occurs in estimator fitting. If set to &amp;lsquo;raise&amp;rsquo;, the error is raised. If set to &amp;lsquo;raise-deprecating&amp;rsquo;, a FutureWarning is printed before the error is raised. If a numeric value is given, FitFailedWarning is raised. This parameter does not affect the refit step, which will always raise the error. Default is &amp;lsquo;raise-deprecating&amp;rsquo; but from version 0.22 it will change to np.nan.</source>
          <target state="translated">Valor para asignar a la puntuaci&amp;oacute;n si se produce un error en el ajuste del estimador. Si se establece en 'subir', se genera el error. Si se establece en 'aumento en desaprobaci&amp;oacute;n', se imprime un FutureWarning antes de que se genere el error. Si se proporciona un valor num&amp;eacute;rico, se genera FitFailedWarning. Este par&amp;aacute;metro no afecta el paso de reacondicionamiento, que siempre generar&amp;aacute; el error. El valor predeterminado es &quot;aumento en desaprobaci&amp;oacute;n&quot;, pero a partir de la versi&amp;oacute;n 0.22 cambiar&amp;aacute; a np.nan.</target>
        </trans-unit>
        <trans-unit id="402a4cfb84a22d3670431b1576518e6587de93b8" translate="yes" xml:space="preserve">
          <source>Value to use for the dummy feature.</source>
          <target state="translated">Valor a utilizar para la función de maniquí.</target>
        </trans-unit>
        <trans-unit id="82321dd8f607145fb8d2875c3e367d82d45dfc71" translate="yes" xml:space="preserve">
          <source>Value with which negative labels must be encoded.</source>
          <target state="translated">Valor con el que deben codificarse las etiquetas negativas.</target>
        </trans-unit>
        <trans-unit id="4e0758fceaa4f106e89501aa7c196eea7d1ad1c2" translate="yes" xml:space="preserve">
          <source>Value with which positive labels must be encoded.</source>
          <target state="translated">Valor con el que deben codificarse las etiquetas positivas.</target>
        </trans-unit>
        <trans-unit id="ca5e1888f7ff9f4679a3377b455596a48d014681" translate="yes" xml:space="preserve">
          <source>ValueError</source>
          <target state="translated">ValueError</target>
        </trans-unit>
        <trans-unit id="6a7ed2e67e56dace630120ac5c7bd01e4d032523" translate="yes" xml:space="preserve">
          <source>Values greater than the threshold map to 1, while values less than or equal to the threshold map to 0. With the default threshold of 0, only positive values map to 1.</source>
          <target state="translated">Los valores superiores al mapa de umbral a 1,mientras que los valores inferiores o iguales al mapa de umbral a 0.Con el umbral por defecto de 0,sólo los valores positivos se asignan a 1.</target>
        </trans-unit>
        <trans-unit id="0a659f48fb09b2c2dd949774cc3bd6b7ffd6fd87" translate="yes" xml:space="preserve">
          <source>Values in each bin have the same nearest center of a 1D k-means cluster.</source>
          <target state="translated">Los valores en cada recipiente tienen el mismo centro más cercano de un cúmulo de 1D k-means.</target>
        </trans-unit>
        <trans-unit id="c67d763b94a97115ba7ee9d49115a272cb508cf6" translate="yes" xml:space="preserve">
          <source>Values of n_samples samples drawn from Gaussian process and evaluated at query points.</source>
          <target state="translated">Valores de n_muestras de muestras extraídas del proceso Gaussiano y evaluadas en puntos de consulta.</target>
        </trans-unit>
        <trans-unit id="1cd1b62dfd3b6a63572d1bf631789bd088451d1d" translate="yes" xml:space="preserve">
          <source>Values of the visible layer after one Gibbs step.</source>
          <target state="translated">Valores de la capa visible después de un paso de Gibbs.</target>
        </trans-unit>
        <trans-unit id="c9500aef779ad4ab4355590ca05b9c0de0aa083a" translate="yes" xml:space="preserve">
          <source>Values of the visible layer to start from.</source>
          <target state="translated">Valores de la capa visible para empezar.</target>
        </trans-unit>
        <trans-unit id="d9ca5115511a5b00d878e1de5b9daa8f530b632c" translate="yes" xml:space="preserve">
          <source>Values of the visible layer. Must be all-boolean (not checked).</source>
          <target state="translated">Valores de la capa visible.Debe ser todo booleano (no comprobado).</target>
        </trans-unit>
        <trans-unit id="35e8d31773dfd80568909d00a3100d73e50de4e1" translate="yes" xml:space="preserve">
          <source>Values predicted by each regressor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="445d09e482944669dc8a6e893591f45bda28254b" translate="yes" xml:space="preserve">
          <source>Vanschoren, van Rijn, Bischl and Torgo &lt;a href=&quot;https://arxiv.org/pdf/1407.7722.pdf&quot;&gt;&amp;ldquo;OpenML: networked science in machine learning&amp;rdquo;&lt;/a&gt;, ACM SIGKDD Explorations Newsletter, 15(2), 49-60, 2014.</source>
          <target state="translated">Vanschoren, van Rijn, Bischl y Torgo &lt;a href=&quot;https://arxiv.org/pdf/1407.7722.pdf&quot;&gt;&quot;OpenML: ciencia en red en el aprendizaje autom&amp;aacute;tico&quot;&lt;/a&gt; , ACM SIGKDD Explorations Newsletter, 15 (2), 49-60, 2014.</target>
        </trans-unit>
        <trans-unit id="ba47c39bbafea14cc75438e6420272a547d1a3e3" translate="yes" xml:space="preserve">
          <source>Variance explained by each of the selected components.</source>
          <target state="translated">Variación explicada por cada uno de los componentes seleccionados.</target>
        </trans-unit>
        <trans-unit id="17b5cb397e6ad9830d59b5fc66bebb45024c7ef4" translate="yes" xml:space="preserve">
          <source>Variances of individual features.</source>
          <target state="translated">Variaciones de las características individuales.</target>
        </trans-unit>
        <trans-unit id="7933f72bf76c6cfbc1dde87498522f5e833878e6" translate="yes" xml:space="preserve">
          <source>Variational Bayesian estimation of a Gaussian mixture.</source>
          <target state="translated">Estimación bayesiana variable de una mezcla gaussiana.</target>
        </trans-unit>
        <trans-unit id="e459652719d6e0edf38bb3c9f14dba040888c62f" translate="yes" xml:space="preserve">
          <source>Variational inference is an extension of expectation-maximization that maximizes a lower bound on model evidence (including priors) instead of data likelihood. The principle behind variational methods is the same as expectation-maximization (that is both are iterative algorithms that alternate between finding the probabilities for each point to be generated by each mixture and fitting the mixture to these assigned points), but variational methods add regularization by integrating information from prior distributions. This avoids the singularities often found in expectation-maximization solutions but introduces some subtle biases to the model. Inference is often notably slower, but not usually as much so as to render usage unpractical.</source>
          <target state="translated">La inferencia variacional es una extensión de la maximización de las expectativas que maximiza un límite más bajo en la evidencia del modelo (incluyendo los antecedentes)en lugar de la probabilidad de los datos.El principio que subyace a los métodos variacionales es el mismo que el de la maximización de la expectativa (es decir,ambos son algoritmos iterativos que alternan entre encontrar las probabilidades de cada punto que debe generar cada mezcla y ajustar la mezcla a estos puntos asignados),pero los métodos variacionales añaden regularización al integrar la información de distribuciones anteriores.Esto evita las singularidades que a menudo se encuentran en las soluciones de maximización de expectativas,pero introduce algunos sutiles sesgos en el modelo.La inferencia suele ser notablemente más lenta,pero no tanto como para que el uso no sea práctico.</target>
        </trans-unit>
        <trans-unit id="009e019794c4b5a288d65b8e0eabe9064e298c81" translate="yes" xml:space="preserve">
          <source>Variational inference techniques for the Dirichlet process still work with a finite approximation to this infinite mixture model, but instead of having to specify a priori how many components one wants to use, one just specifies the concentration parameter and an upper bound on the number of mixture components (this upper bound, assuming it is higher than the &amp;ldquo;true&amp;rdquo; number of components, affects only algorithmic complexity, not the actual number of components used).</source>
          <target state="translated">Las t&amp;eacute;cnicas de inferencia variacional para el proceso de Dirichlet a&amp;uacute;n funcionan con una aproximaci&amp;oacute;n finita a este modelo de mezcla infinita, pero en lugar de tener que especificar a priori cu&amp;aacute;ntos componentes se quieren usar, solo se especifica el par&amp;aacute;metro de concentraci&amp;oacute;n y un l&amp;iacute;mite superior en el n&amp;uacute;mero de mezcla. componentes (este l&amp;iacute;mite superior, asumiendo que es m&amp;aacute;s alto que el n&amp;uacute;mero &quot;verdadero&quot; de componentes, afecta s&amp;oacute;lo la complejidad algor&amp;iacute;tmica, no el n&amp;uacute;mero real de componentes utilizados).</target>
        </trans-unit>
        <trans-unit id="bfc42eb1bb86ce5f62b086e9ffd3c67a080b0730" translate="yes" xml:space="preserve">
          <source>Variational parameters for topic word distribution. Since the complete conditional for topic word distribution is a Dirichlet, &lt;code&gt;components_[i, j]&lt;/code&gt; can be viewed as pseudocount that represents the number of times word &lt;code&gt;j&lt;/code&gt; was assigned to topic &lt;code&gt;i&lt;/code&gt;. It can also be viewed as distribution over the words for each topic after normalization: &lt;code&gt;model.components_ / model.components_.sum(axis=1)[:, np.newaxis]&lt;/code&gt;.</source>
          <target state="translated">Par&amp;aacute;metros variacionales para la distribuci&amp;oacute;n de palabras tem&amp;aacute;ticas. Dado que el condicional completo para la distribuci&amp;oacute;n de palabras del tema es un Dirichlet, los &lt;code&gt;components_[i, j]&lt;/code&gt; se pueden ver como un pseudocontento que representa el n&amp;uacute;mero de veces que la palabra &lt;code&gt;j&lt;/code&gt; se asign&amp;oacute; al tema &lt;code&gt;i&lt;/code&gt; . Tambi&amp;eacute;n se puede ver como una distribuci&amp;oacute;n sobre las palabras de cada tema despu&amp;eacute;s de la normalizaci&amp;oacute;n: &lt;code&gt;model.components_ / model.components_.sum(axis=1)[:, np.newaxis]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="65cb8d21f19957f8f56d7ec3aeccadf0c1efbc6f" translate="yes" xml:space="preserve">
          <source>Various Agglomerative Clustering on a 2D embedding of digits</source>
          <target state="translated">Varios agrupamientos aglomerados en una incrustación de dígitos en 2D</target>
        </trans-unit>
        <trans-unit id="ddbf21d472ec4b83f538c33f12eb263b69f44ca0" translate="yes" xml:space="preserve">
          <source>Various improvements were made to &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt;&lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;. On top of the Poisson loss mentionned above, these estimators now support &lt;a href=&quot;../../modules/ensemble#sw-hgbdt&quot;&gt;sample weights&lt;/a&gt;. Also, an automatic early-stopping criterion was added: early-stopping is enabled by default when the number of samples exceeds 10k. Finally, users can now define &lt;a href=&quot;../../modules/ensemble#monotonic-cst-gbdt&quot;&gt;monotonic constraints&lt;/a&gt; to constrain the predictions based on the variations of specific features. In the following example, we construct a target that is generally positively correlated with the first feature, with some noise. Applying monotoinc constraints allows the prediction to capture the global effect of the first feature, instead of fitting the noise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1e276370580ceeca94d9a25d3b75abf89a69938" translate="yes" xml:space="preserve">
          <source>Varying regularization in Multi-layer Perceptron</source>
          <target state="translated">Regularización variable en el Perceptrón Multicapa</target>
        </trans-unit>
        <trans-unit id="1e178759402bc070ae202c1ae1b1666da0dd6a9c" translate="yes" xml:space="preserve">
          <source>Vector Quantization Example</source>
          <target state="translated">Ejemplo de cuantificación de vectores</target>
        </trans-unit>
        <trans-unit id="ba8b3829eecac2c5ad85a64a161b0e7f2fae54cf" translate="yes" xml:space="preserve">
          <source>Vector of errors at each iteration.</source>
          <target state="translated">Vector de errores en cada iteración.</target>
        </trans-unit>
        <trans-unit id="4e8912fa819c195ed09c153115c88939fa1f2e3c" translate="yes" xml:space="preserve">
          <source>Vector to be scored, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the number of features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf31e021601b7cdd3aba8ca6f6502b2543cdeb94" translate="yes" xml:space="preserve">
          <source>VehAge</source>
          <target state="translated">VehAge</target>
        </trans-unit>
        <trans-unit id="ea3a474961d1b758addd0978141f5ebc1f6f2b70" translate="yes" xml:space="preserve">
          <source>VehBrand</source>
          <target state="translated">VehBrand</target>
        </trans-unit>
        <trans-unit id="fda6c72b6cabb64878498cd55268cca04e8d770b" translate="yes" xml:space="preserve">
          <source>VehGas</source>
          <target state="translated">VehGas</target>
        </trans-unit>
        <trans-unit id="9e0c38e996b000566fa359d3ed449ba796915a3e" translate="yes" xml:space="preserve">
          <source>VehPower</source>
          <target state="translated">VehPower</target>
        </trans-unit>
        <trans-unit id="93c6f0903309fd539ceb7d4710cf07f7db8cb1d8" translate="yes" xml:space="preserve">
          <source>Verbose mode when fitting the model.</source>
          <target state="translated">Modo verboso cuando se ajusta el modelo.</target>
        </trans-unit>
        <trans-unit id="ee5731f921bfe2d1197cd007f006306ad3328112" translate="yes" xml:space="preserve">
          <source>Verbose output during PD computations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eeb343db47ab9124ef417c41d9bdb92839772dc0" translate="yes" xml:space="preserve">
          <source>Verbose output during PD computations. Defaults to 0.</source>
          <target state="translated">La salida de la verbosa durante los cálculos de la DP.El valor por defecto es 0.</target>
        </trans-unit>
        <trans-unit id="65d3f9d357c8217e4b4161cc31c9983e755e9511" translate="yes" xml:space="preserve">
          <source>Verbosity flag, controls the debug messages that are issued as functions are evaluated.</source>
          <target state="translated">El indicador de verbosidad,controla los mensajes de depuración que se emiten a medida que se evalúan las funciones.</target>
        </trans-unit>
        <trans-unit id="66d100e92da285b9102a10ebf1825a4d7ce2d91c" translate="yes" xml:space="preserve">
          <source>Verbosity flag, controls the debug messages that are issued as functions are evaluated. The higher, the more verbose. Can be 0, 1, or 2.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a606460a9db19f2456900341e545d542d386dcd0" translate="yes" xml:space="preserve">
          <source>Verbosity level.</source>
          <target state="translated">Nivel de verbosidad.</target>
        </trans-unit>
        <trans-unit id="9cadb350a887ea26b759cec53fba259b94be0b70" translate="yes" xml:space="preserve">
          <source>Verbosity level. Setting verbose &amp;gt; 0 will display additional information depending on the solver used.</source>
          <target state="translated">Nivel de verbosidad. Si se configura detallado&amp;gt; 0, se mostrar&amp;aacute; informaci&amp;oacute;n adicional seg&amp;uacute;n el solucionador utilizado.</target>
        </trans-unit>
        <trans-unit id="c09635f4883cd7798a06597eead68509e08bef52" translate="yes" xml:space="preserve">
          <source>Verbosity mode.</source>
          <target state="translated">Modo de verbosidad.</target>
        </trans-unit>
        <trans-unit id="4ee9c427e0cc678ca91bc7294708dc43db03512b" translate="yes" xml:space="preserve">
          <source>Versatile: different &lt;a href=&quot;#gp-kernels&quot;&gt;kernels&lt;/a&gt; can be specified. Common kernels are provided, but it is also possible to specify custom kernels.</source>
          <target state="translated">Vers&amp;aacute;til: se pueden especificar diferentes &lt;a href=&quot;#gp-kernels&quot;&gt;n&amp;uacute;cleos&lt;/a&gt; . Se proporcionan kernels comunes, pero tambi&amp;eacute;n es posible especificar kernels personalizados.</target>
        </trans-unit>
        <trans-unit id="4b16fac84e3102257e26d97dc6bcc2775a76c275" translate="yes" xml:space="preserve">
          <source>Versatile: different &lt;a href=&quot;#svm-kernels&quot;&gt;Kernel functions&lt;/a&gt; can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.</source>
          <target state="translated">Vers&amp;aacute;til: se pueden especificar diferentes &lt;a href=&quot;#svm-kernels&quot;&gt;funciones del Kernel&lt;/a&gt; para la funci&amp;oacute;n de decisi&amp;oacute;n. Se proporcionan kernels comunes, pero tambi&amp;eacute;n es posible especificar kernels personalizados.</target>
        </trans-unit>
        <trans-unit id="102caab3d934ebf62d9240e41edbdfb96ec830ff" translate="yes" xml:space="preserve">
          <source>Version of the dataset. Can only be provided if also &lt;code&gt;name&lt;/code&gt; is given. If &amp;lsquo;active&amp;rsquo; the oldest version that&amp;rsquo;s still active is used. Since there may be more than one active version of a dataset, and those versions may fundamentally be different from one another, setting an exact version is highly recommended.</source>
          <target state="translated">Versi&amp;oacute;n del conjunto de datos. Solo se puede proporcionar si tambi&amp;eacute;n se proporciona el &lt;code&gt;name&lt;/code&gt; . Si est&amp;aacute; &quot;activa&quot;, se utiliza la versi&amp;oacute;n m&amp;aacute;s antigua que todav&amp;iacute;a est&amp;aacute; activa. Dado que puede haber m&amp;aacute;s de una versi&amp;oacute;n activa de un conjunto de datos, y esas versiones pueden ser b&amp;aacute;sicamente diferentes entre s&amp;iacute;, se recomienda encarecidamente establecer una versi&amp;oacute;n exacta.</target>
        </trans-unit>
        <trans-unit id="2d0ab9e3d9a896817cdfc684c77fbf9f0c4f1aac" translate="yes" xml:space="preserve">
          <source>Version: RCV1-v2, vectors, full sets, topics multilabels.</source>
          <target state="translated">Versión:RCV1-v2,vectores,conjuntos completos,temas multilabeles.</target>
        </trans-unit>
        <trans-unit id="dfb46f94f7d77a5ddeabfd408748577e450d338b" translate="yes" xml:space="preserve">
          <source>Very large &lt;code&gt;n_samples&lt;/code&gt;, large &lt;code&gt;n_clusters&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3496b8ff284f2499d5b89bafe815a9579d5a779b" translate="yes" xml:space="preserve">
          <source>Very large &lt;code&gt;n_samples&lt;/code&gt;, medium &lt;code&gt;n_clusters&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;n_samples&lt;/code&gt; muy grandes , &lt;code&gt;n_clusters&lt;/code&gt; medianos</target>
        </trans-unit>
        <trans-unit id="90edfe52a065a045edbdd25bf2f2316a234658ac" translate="yes" xml:space="preserve">
          <source>Very large &lt;code&gt;n_samples&lt;/code&gt;, medium &lt;code&gt;n_clusters&lt;/code&gt; with &lt;a href=&quot;#mini-batch-kmeans&quot;&gt;MiniBatch code&lt;/a&gt;</source>
          <target state="translated">Muy grandes &lt;code&gt;n_samples&lt;/code&gt; , medianas &lt;code&gt;n_clusters&lt;/code&gt; con &lt;a href=&quot;#mini-batch-kmeans&quot;&gt;c&amp;oacute;digo MiniBatch&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="56b71e89fb1079caaadefd0889e9a22e8b0560e3" translate="yes" xml:space="preserve">
          <source>Videos</source>
          <target state="translated">Videos</target>
        </trans-unit>
        <trans-unit id="644cc701dadc9ddd9912f1b11b35ead35737260b" translate="yes" xml:space="preserve">
          <source>Vinh et al. (2010) named variants of NMI and AMI by their averaging method &lt;a href=&quot;#veb2010&quot; id=&quot;id15&quot;&gt;[VEB2010]&lt;/a&gt;. Their &amp;lsquo;sqrt&amp;rsquo; and &amp;lsquo;sum&amp;rsquo; averages are the geometric and arithmetic means; we use these more broadly common names.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f74a22805e87ed187a5bf75da0c74d88f9fc4e05" translate="yes" xml:space="preserve">
          <source>Vinh et al. (2010) named variants of NMI and AMI by their averaging method [VEB2010]. Their &amp;lsquo;sqrt&amp;rsquo; and &amp;lsquo;sum&amp;rsquo; averages are the geometric and arithmetic means; we use these more broadly common names.</source>
          <target state="translated">Vinh y col. (2010) nombraron variantes de NMI y AMI por su m&amp;eacute;todo de promediado [VEB2010]. Sus promedios 'sqrt' y 'sum' son los medios geom&amp;eacute;tricos y aritm&amp;eacute;ticos; utilizamos estos nombres m&amp;aacute;s ampliamente comunes.</target>
        </trans-unit>
        <trans-unit id="3e1bb17ff94c0af1df416cfea07d80b830f06013" translate="yes" xml:space="preserve">
          <source>Vinh, Epps, and Bailey, (2009). &amp;ldquo;Information theoretic measures for clusterings comparison&amp;rdquo;. Proceedings of the 26th Annual International Conference on Machine Learning - ICML &amp;lsquo;09. &lt;a href=&quot;https://dl.acm.org/citation.cfm?doid=1553374.1553511&quot;&gt;doi:10.1145/1553374.1553511&lt;/a&gt;. ISBN 9781605585161.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa05fa0b125b1736672a1d80de8273f7659ae9f5" translate="yes" xml:space="preserve">
          <source>Vinh, Epps, and Bailey, (2010). &amp;ldquo;Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance&amp;rdquo;. JMLR &amp;lt;&lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&lt;/a&gt;&amp;gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40fdfddfc4699e8e891d021e6ce4e4252243f9c7" translate="yes" xml:space="preserve">
          <source>Vinh, Epps, and Bailey, (2010). Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance, JMLR</source>
          <target state="translated">Vinh,Epps y Bailey,(2010).Medidas teóricas de información para la comparación de agrupaciones:Variantes,Propiedades,Normalización y Corrección para el azar,JMLR</target>
        </trans-unit>
        <trans-unit id="64eeb8915eff8290b0627c8aa96dd46ee4bda6f1" translate="yes" xml:space="preserve">
          <source>Visualise your tree as you are training by using the &lt;code&gt;export&lt;/code&gt; function. Use &lt;code&gt;max_depth=3&lt;/code&gt; as an initial tree depth to get a feel for how the tree is fitting to your data, and then increase the depth.</source>
          <target state="translated">Visualice su &amp;aacute;rbol mientras entrena utilizando la funci&amp;oacute;n de &lt;code&gt;export&lt;/code&gt; aci&amp;oacute;n . Use &lt;code&gt;max_depth=3&lt;/code&gt; como profundidad inicial del &amp;aacute;rbol para tener una idea de c&amp;oacute;mo el &amp;aacute;rbol se ajusta a sus datos y luego aumente la profundidad.</target>
        </trans-unit>
        <trans-unit id="d175985b87dd9f620aa960059c730b4a35e3bcb5" translate="yes" xml:space="preserve">
          <source>Visualization</source>
          <target state="translated">Visualization</target>
        </trans-unit>
        <trans-unit id="38623835e09f3cd243cdf966707dad9de4ecfeda" translate="yes" xml:space="preserve">
          <source>Visualization of MLP weights on MNIST</source>
          <target state="translated">Visualización de los pesos del MLP en el MNIST</target>
        </trans-unit>
        <trans-unit id="a291ff40a157c9afd67fb01fd3c6b6d368d78978" translate="yes" xml:space="preserve">
          <source>Visualization of predictions obtained from different models.</source>
          <target state="translated">Visualización de las predicciones obtenidas de diferentes modelos.</target>
        </trans-unit>
        <trans-unit id="94a741e26bd8d9bfdacbab90c67da4753dcabca8" translate="yes" xml:space="preserve">
          <source>Visualizations with Display Objects</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a6c65fa336dc53edc04e670583358fb288a99997" translate="yes" xml:space="preserve">
          <source>Visualize cross-validation indices for many CV objects</source>
          <target state="translated">Visualizar los índices de validación cruzada de muchos objetos CV</target>
        </trans-unit>
        <trans-unit id="4a2bddc914855cb9100c33fc5e346e89e1926136" translate="yes" xml:space="preserve">
          <source>Visualize our data</source>
          <target state="translated">Visualizar nuestros datos</target>
        </trans-unit>
        <trans-unit id="28ba2de8813583360eb0588f62cb6dc19a1f4072" translate="yes" xml:space="preserve">
          <source>Visualize the resulting regions</source>
          <target state="translated">Visualizar las regiones resultantes</target>
        </trans-unit>
        <trans-unit id="b77da1f257213eacf5971ec98d2f34c8fe910374" translate="yes" xml:space="preserve">
          <source>Visualizing cross-validation behavior in scikit-learn</source>
          <target state="translated">Visualizar el comportamiento de validación cruzada en scikit-learn</target>
        </trans-unit>
        <trans-unit id="e6614e53d3137ea4329f7b88a52f014060c402bb" translate="yes" xml:space="preserve">
          <source>Visualizing the stock market structure</source>
          <target state="translated">Visualizar la estructura del mercado de valores</target>
        </trans-unit>
        <trans-unit id="3e1e0ef10e7a115946f530e934380438421c5b34" translate="yes" xml:space="preserve">
          <source>Vocabulary: classification and regression</source>
          <target state="translated">Vocabulario:clasificación y regresión</target>
        </trans-unit>
        <trans-unit id="9b3e588521f2631086f0d4ea61248bd80936e042" translate="yes" xml:space="preserve">
          <source>VotingRegressor</source>
          <target state="translated">VotingRegressor</target>
        </trans-unit>
        <trans-unit id="dd7b37acd93acaf11b82a9ebbc3eea819b85e0ef" translate="yes" xml:space="preserve">
          <source>W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) 163-171.</source>
          <target state="translated">W.H.Wolberg,W.N.Street y O.L.Mangasarian.Técnicas de aprendizaje de máquinas para diagnosticar el cáncer de mama a partir de aspirados de aguja fina.Cancer Letters 77 (1994)163-171.</target>
        </trans-unit>
        <trans-unit id="985d7c09beb3a8622b6c063b009de9296fdb89ed" translate="yes" xml:space="preserve">
          <source>W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&amp;amp;T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993.</source>
          <target state="translated">WN Street, WH Wolberg y OL Mangasarian. Extracci&amp;oacute;n de caracter&amp;iacute;sticas nucleares para el diagn&amp;oacute;stico de tumores de mama. IS &amp;amp; T / SPIE 1993 Simposio internacional sobre im&amp;aacute;genes electr&amp;oacute;nicas: ciencia y tecnolog&amp;iacute;a, volumen 1905, p&amp;aacute;ginas 861-870, San Jos&amp;eacute;, CA, 1993.</target>
        </trans-unit>
        <trans-unit id="0525374f4c7331dc5d256feba32a265d327160ed" translate="yes" xml:space="preserve">
          <source>WDBC-Benign</source>
          <target state="translated">WDBC-Benign</target>
        </trans-unit>
        <trans-unit id="fd630df285b07b6076d3b38d88445f6031d3902e" translate="yes" xml:space="preserve">
          <source>WDBC-Malignant</source>
          <target state="translated">WDBC-Malignant</target>
        </trans-unit>
        <trans-unit id="9b852a8108b3e892136da9e7da9f0a5bb56540ea" translate="yes" xml:space="preserve">
          <source>WMinkowskiDistance</source>
          <target state="translated">WMinkowskiDistance</target>
        </trans-unit>
        <trans-unit id="c3600a53fe931326fad0ec5abc0f593830220f56" translate="yes" xml:space="preserve">
          <source>Wang, Y., Wang, L., Li, Y., He, D., Chen, W., &amp;amp; Liu, T. Y. (2013, May). A theoretical analysis of NDCG ranking measures. In Proceedings of the 26th Annual Conference on Learning Theory (COLT 2013)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e8ee595c7db5dd5f284f8fb603cc66c6c8287ae" translate="yes" xml:space="preserve">
          <source>Ward clustering based on a Feature matrix.</source>
          <target state="translated">Agrupación de barrios basada en una matriz de características.</target>
        </trans-unit>
        <trans-unit id="1af684513cf70467c9307765e01677f8970cff6e" translate="yes" xml:space="preserve">
          <source>Ward hierarchical clustering</source>
          <target state="translated">Agrupación jerárquica de distritos</target>
        </trans-unit>
        <trans-unit id="d2173ac976f5809b703436c0de33dab1598b674c" translate="yes" xml:space="preserve">
          <source>Ward is the most effective method for noisy data.</source>
          <target state="translated">Ward es el método más efectivo para datos ruidosos.</target>
        </trans-unit>
        <trans-unit id="e9c45563358e813f157ba81b33143542165ba84e" translate="yes" xml:space="preserve">
          <source>Warning</source>
          <target state="translated">Warning</target>
        </trans-unit>
        <trans-unit id="44d79cfceaac3d6c963709a9f443a7578dfdd3fa" translate="yes" xml:space="preserve">
          <source>Warning class used if there is an error while fitting the estimator.</source>
          <target state="translated">Clase de advertencia utilizada si hay un error al ajustar el estimador.</target>
        </trans-unit>
        <trans-unit id="c56f46b7e83e71f0bcaf54dacd8cfc15c71ef274" translate="yes" xml:space="preserve">
          <source>Warning class used to notify the user of any change in the behavior.</source>
          <target state="translated">Clase de advertencia usada para notificar al usuario de cualquier cambio en el comportamiento.</target>
        </trans-unit>
        <trans-unit id="43a2ad1c4144ef567b3006486da55db4df5bcce7" translate="yes" xml:space="preserve">
          <source>Warning used to notify implicit data conversions happening in the code.</source>
          <target state="translated">Advertencia utilizada para notificar las conversiones de datos implícitas que se producen en el código.</target>
        </trans-unit>
        <trans-unit id="69bb37448a64e3ca58327c210b042b57b19259a7" translate="yes" xml:space="preserve">
          <source>Warning used to notify the user of inefficient computation.</source>
          <target state="translated">Advertencia utilizada para notificar al usuario de un cálculo ineficiente.</target>
        </trans-unit>
        <trans-unit id="95fde5bcc048210bdd2da0e9628c10dadee1ce1e" translate="yes" xml:space="preserve">
          <source>Warning used when the dot operation does not use BLAS.</source>
          <target state="translated">Advertencia utilizada cuando la operación de punto no utiliza BLAS.</target>
        </trans-unit>
        <trans-unit id="77d4a9d6a0a46436c153d66828a62d378a7e1f5d" translate="yes" xml:space="preserve">
          <source>Warning used when the metric is invalid</source>
          <target state="translated">Advertencia utilizada cuando la métrica no es válida</target>
        </trans-unit>
        <trans-unit id="d0aaba5d13d0d7235d440530a46ccfa6343b56ff" translate="yes" xml:space="preserve">
          <source>Warning: Extra-trees should only be used within ensemble methods.</source>
          <target state="translated">Advertencia:Los árboles adicionales sólo deben utilizarse dentro de los métodos de conjunto.</target>
        </trans-unit>
        <trans-unit id="c083bc8548c03dc08f53c7e8a611e5699830557a" translate="yes" xml:space="preserve">
          <source>Warning: impurity-based feature importances can be misleading for high cardinality features (many unique values). See &lt;a href=&quot;../../modules/generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;sklearn.inspection.permutation_importance&lt;/code&gt;&lt;/a&gt; as an alternative.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a70a0040ebdf5db3cf497e998d5844dc921e921b" translate="yes" xml:space="preserve">
          <source>Warning: impurity-based feature importances can be misleading for high cardinality features (many unique values). See &lt;a href=&quot;sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;sklearn.inspection.permutation_importance&lt;/code&gt;&lt;/a&gt; as an alternative.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2eb6fdf9d13ab34884681ef0c66f41e16b52aad" translate="yes" xml:space="preserve">
          <source>Warning: this function is experimental and subject to change in a future version of joblib.</source>
          <target state="translated">Advertencia:esta función es experimental y está sujeta a cambios en una futura versión de joblib.</target>
        </trans-unit>
        <trans-unit id="b33d3bb4e4bfe5e80c2407f4ead429c7fa466ef0" translate="yes" xml:space="preserve">
          <source>We achieved 83.5% accuracy. Let&amp;rsquo;s see if we can do better with a linear &lt;a href=&quot;../../modules/svm#svm&quot;&gt;support vector machine (SVM)&lt;/a&gt;, which is widely regarded as one of the best text classification algorithms (although it&amp;rsquo;s also a bit slower than na&amp;iuml;ve Bayes). We can change the learner by simply plugging a different classifier object into our pipeline:</source>
          <target state="translated">Logramos una precisi&amp;oacute;n del 83,5%. Veamos si podemos hacerlo mejor con una &lt;a href=&quot;../../modules/svm#svm&quot;&gt;m&amp;aacute;quina de vectores de soporte&lt;/a&gt; lineal (SVM) , que es ampliamente considerado como uno de los mejores algoritmos de clasificaci&amp;oacute;n de texto (aunque tambi&amp;eacute;n es un poco m&amp;aacute;s lento que el ingenuo Bayes). Podemos cambiar al alumno simplemente conectando un objeto clasificador diferente en nuestra canalizaci&amp;oacute;n:</target>
        </trans-unit>
        <trans-unit id="5e4234559a6f8eb7829d45ed1528d4d2b014e858" translate="yes" xml:space="preserve">
          <source>We achieved 91.3% accuracy using the SVM. &lt;code&gt;scikit-learn&lt;/code&gt; provides further utilities for more detailed performance analysis of the results:</source>
          <target state="translated">Logramos una precisi&amp;oacute;n del 91,3% utilizando la SVM. &lt;code&gt;scikit-learn&lt;/code&gt; proporciona m&amp;aacute;s utilidades para un an&amp;aacute;lisis de rendimiento m&amp;aacute;s detallado de los resultados:</target>
        </trans-unit>
        <trans-unit id="4073bf855ec3741a8d17116f66549a3127ee1b52" translate="yes" xml:space="preserve">
          <source>We add observation noise to these waveforms. We generate very sparse noise: only 6% of the time points contain noise. As a result, the l1 norm of this noise (ie &amp;ldquo;cityblock&amp;rdquo; distance) is much smaller than it&amp;rsquo;s l2 norm (&amp;ldquo;euclidean&amp;rdquo; distance). This can be seen on the inter-class distance matrices: the values on the diagonal, that characterize the spread of the class, are much bigger for the Euclidean distance than for the cityblock distance.</source>
          <target state="translated">Agregamos ruido de observaci&amp;oacute;n a estas formas de onda. Generamos ruido muy escaso: solo el 6% de los puntos de tiempo contienen ruido. Como resultado, la norma l1 de este ruido (es decir, la distancia de &amp;ldquo;cuadra de la ciudad&amp;rdquo;) es mucho menor que la norma l2 (distancia &amp;ldquo;euclidiana&amp;rdquo;). Esto se puede ver en las matrices de distancia entre clases: los valores en la diagonal, que caracterizan la dispersi&amp;oacute;n de la clase, son mucho mayores para la distancia euclidiana que para la distancia entre bloques de la ciudad.</target>
        </trans-unit>
        <trans-unit id="0408d5d268f82423b1624837fe33bcd8dd7f81b2" translate="yes" xml:space="preserve">
          <source>We also observe that &lt;a href=&quot;../../modules/generated/sklearn.neural_network.mlpregressor#sklearn.neural_network.MLPRegressor&quot;&gt;&lt;code&gt;MLPRegressor&lt;/code&gt;&lt;/a&gt; has much smoother predictions than &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;. For the plots to be comparable, it is necessary to subtract the average value of the target &lt;code&gt;y&lt;/code&gt;: The &amp;lsquo;recursion&amp;rsquo; method, used by default for &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;, does not account for the initial predictor (in our case the average target). Setting the target average to 0 avoids this bias.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fc281c3e8b120a8bce90f392d5367731bdfa8e6" translate="yes" xml:space="preserve">
          <source>We also plot predictions and uncertainties for ARD for one dimensional regression using polynomial feature expansion. Note the uncertainty starts going up on the right side of the plot. This is because these test samples are outside of the range of the training samples.</source>
          <target state="translated">También trazamos predicciones e incertidumbres para la DRA para la regresión unidimensional usando la expansión de los rasgos polinómicos.Observe que la incertidumbre comienza a subir en el lado derecho del gráfico.Esto se debe a que estas muestras de prueba están fuera del rango de las muestras de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="bda5a1ba58eab4f9acd36ef763104051f247918e" translate="yes" xml:space="preserve">
          <source>We also plot predictions and uncertainties for Bayesian Ridge Regression for one dimensional regression using polynomial feature expansion. Note the uncertainty starts going up on the right side of the plot. This is because these test samples are outside of the range of the training samples.</source>
          <target state="translated">También trazamos predicciones e incertidumbres para la Regresión de la Cresta Bayesiana para la regresión unidimensional usando la expansión de los rasgos polinómicos.Nótese que la incertidumbre comienza a subir en el lado derecho del gráfico.Esto se debe a que estas muestras de prueba están fuera del rango de las muestras de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="796db2c0bddee3a97c873bf6deae5d571e22b022" translate="yes" xml:space="preserve">
          <source>We also show the tree structure of a model built on all of the features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b29f4bff482ccd99c1af96e146d78b516ea318aa" translate="yes" xml:space="preserve">
          <source>We also use warm_start=True which means that the coefficients of the models are reused to initialize the next model fit to speed-up the computation of the full-path.</source>
          <target state="translated">También usamos warm_start=True,lo que significa que los coeficientes de los modelos se reutilizan para inicializar el siguiente ajuste del modelo para acelerar el cálculo de la ruta completa.</target>
        </trans-unit>
        <trans-unit id="58db9129e28b6367a4c4b1cf6dbdf62e7e4b259e" translate="yes" xml:space="preserve">
          <source>We are pleased to announce the release of scikit-learn 0.22, which comes with many bug fixes and new features! We detail below a few of the major features of this release. For an exhaustive list of all the changes, please refer to the &lt;a href=&quot;https://scikit-learn.org/0.23/whats_new/v0.22.html#changes-0-22&quot;&gt;release notes&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85e7dd24e85e9c4275de753975b0d57e773f0b77" translate="yes" xml:space="preserve">
          <source>We are pleased to announce the release of scikit-learn 0.23! Many bug fixes and improvements were added, as well as some new key features. We detail below a few of the major features of this release. &lt;strong&gt;For an exhaustive list of all the changes&lt;/strong&gt;, please refer to the &lt;a href=&quot;https://scikit-learn.org/0.23/whats_new/v0.23.html#changes-0-23&quot;&gt;release notes&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f24896ee5efd7713cddd30b90821fa31665d4c0" translate="yes" xml:space="preserve">
          <source>We assume that the observations are independent and identically distributed (i.i.d.).</source>
          <target state="translated">Asumimos que las observaciones son independientes y están distribuidas de forma idéntica (i.i.d.).</target>
        </trans-unit>
        <trans-unit id="1552999210b3502aaea38a27415ef28fc1fbf44a" translate="yes" xml:space="preserve">
          <source>We build an artificial dataset where the target value is in general positively correlated with the first feature (with some random and non-random variations), and in general negatively correlated with the second feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b19a456f973e90e2b4e21cdba9f00b15173fd0ef" translate="yes" xml:space="preserve">
          <source>We call &lt;strong&gt;vectorization&lt;/strong&gt; the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the &lt;strong&gt;Bag of Words&lt;/strong&gt; or &amp;ldquo;Bag of n-grams&amp;rdquo; representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document.</source>
          <target state="translated">Llamamos &lt;strong&gt;vectorizaci&amp;oacute;n&lt;/strong&gt; al proceso general de convertir una colecci&amp;oacute;n de documentos de texto en vectores de caracter&amp;iacute;sticas num&amp;eacute;ricas. Esta estrategia espec&amp;iacute;fica (tokenizaci&amp;oacute;n, recuento y normalizaci&amp;oacute;n) se denomina representaci&amp;oacute;n de &lt;strong&gt;Bolsa de palabras&lt;/strong&gt; o &quot;Bolsa de n-gramas&quot;. Los documentos se describen por apariciones de palabras, ignorando por completo la informaci&amp;oacute;n de posici&amp;oacute;n relativa de las palabras en el documento.</target>
        </trans-unit>
        <trans-unit id="c42f4b562ec41f92f6f2792dcf47013aca7ffcc1" translate="yes" xml:space="preserve">
          <source>We can additionally validate these models by comparing observed and predicted total claim amount over the test and train subsets. We see that, on average, both model tend to underestimate the total claim (but this behavior depends on the amount of regularization).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63503e35b14a81c8aca7c86c612044cbc5b560d3" translate="yes" xml:space="preserve">
          <source>We can also export the tree in &lt;a href=&quot;https://www.graphviz.org/&quot;&gt;Graphviz&lt;/a&gt; format using the &lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt;&lt;code&gt;export_graphviz&lt;/code&gt;&lt;/a&gt; exporter. If you use the &lt;a href=&quot;https://conda.io&quot;&gt;conda&lt;/a&gt; package manager, the graphviz binaries and the python package can be installed with &lt;code&gt;conda install python-graphviz&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="096029ae48dbb08bf7baa8066a510ed0e5cf55ab" translate="yes" xml:space="preserve">
          <source>We can also predict based on an unfitted model by using the GP prior. In addition to the mean of the predictive distribution, also its standard deviation (return_std=True) or covariance (return_cov=True). Note that at most one of the two can be requested.</source>
          <target state="translated">También podemos predecir en base a un modelo no apto usando el GP previo.Además de la media de la distribución predictiva,también su desviación estándar (return_std=True)o covarianza (return_cov=True).Nótese que como máximo se puede solicitar una de las dos.</target>
        </trans-unit>
        <trans-unit id="c4674ccfad638384c25bbb5d0cf26d42218171fa" translate="yes" xml:space="preserve">
          <source>We can check the coefficient variability through cross-validation: it is a form of data perturbation (related to &lt;a href=&quot;https://en.wikipedia.org/wiki/Resampling_(statistics)&quot;&gt;resampling&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f60df7f123136fa11f4ddf222fab31a6a72d17d" translate="yes" xml:space="preserve">
          <source>We can choose &lt;code&gt;alpha&lt;/code&gt; to minimize left out error, this time using the diabetes dataset rather than our synthetic data:</source>
          <target state="translated">Podemos elegir &lt;code&gt;alpha&lt;/code&gt; para minimizar el error omitido, esta vez utilizando el conjunto de datos de diabetes en lugar de nuestros datos sint&amp;eacute;ticos:</target>
        </trans-unit>
        <trans-unit id="a7e4da902c37585f80154c204f27a006746ba8cb" translate="yes" xml:space="preserve">
          <source>We can clearly see that the median house price shows a linear relationship with the median income (top left) and that the house price drops when the average occupants per household increases (top middle). The top right plot shows that the house age in a district does not have a strong influence on the (median) house price; so does the average rooms per household. The tick marks on the x-axis represent the deciles of the feature values in the training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="469d4e6eabf44c56eec1620cbb6087744c30d3f6" translate="yes" xml:space="preserve">
          <source>We can clearly see that the median house price shows a linear relationship with the median income (top left) and that the house price drops when the avg. occupants per household increases (top middle). The top right plot shows that the house age in a district does not have a strong influence on the (median) house price; so does the average rooms per household. The tick marks on the x-axis represent the deciles of the feature values in the training data.</source>
          <target state="translated">Podemos ver claramente que el precio medio de la vivienda muestra una relación lineal con la mediana de los ingresos (arriba a la izquierda)y que el precio de la vivienda baja cuando aumenta la media de ocupantes por hogar (arriba a la mitad).La gráfica superior derecha muestra que la edad de la casa en un distrito no tiene una fuerte influencia en el precio de la casa (mediana);también la media de habitaciones por hogar.Las marcas en el eje x representan los deciles de los valores de las características en los datos de formación.</target>
        </trans-unit>
        <trans-unit id="c32b4a200d58f731852c3f4a8eefb32ef18f31ed" translate="yes" xml:space="preserve">
          <source>We can keep the remaining rating columns by setting &lt;code&gt;remainder='passthrough'&lt;/code&gt;. The values are appended to the end of the transformation:</source>
          <target state="translated">Podemos mantener las columnas de calificaci&amp;oacute;n restantes estableciendo &lt;code&gt;remainder='passthrough'&lt;/code&gt; . Los valores se agregan al final de la transformaci&amp;oacute;n:</target>
        </trans-unit>
        <trans-unit id="a59ff6e4288992e31a9513b51da5a036927e8ec8" translate="yes" xml:space="preserve">
          <source>We can now load the list of files matching those categories as follows:</source>
          <target state="translated">Ahora podemos cargar la lista de archivos que coinciden con esas categorías de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="f1f864cfbdff004081b5667459fd9c49d8fcf703" translate="yes" xml:space="preserve">
          <source>We can now quickly sample a training set while holding out 40% of the data for testing (evaluating) our classifier:</source>
          <target state="translated">Ahora podemos tomar rápidamente una muestra de un conjunto de entrenamiento mientras mantenemos el 40% de los datos para probar (evaluar)nuestro clasificador:</target>
        </trans-unit>
        <trans-unit id="6d11b97d462683ffa27a678189fc90fddb4a8ee5" translate="yes" xml:space="preserve">
          <source>We can observe that the &lt;code&gt;embarked&lt;/code&gt; and &lt;code&gt;sex&lt;/code&gt; columns were tagged as &lt;code&gt;category&lt;/code&gt; columns when loading the data with &lt;code&gt;fetch_openml&lt;/code&gt;. Therefore, we can use this information to dispatch the categorical columns to the &lt;code&gt;categorical_transformer&lt;/code&gt; and the remaining columns to the &lt;code&gt;numerical_transformer&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="850dcea5aea59348ecbdc161cc86fe56ad9b64b5" translate="yes" xml:space="preserve">
          <source>We can reduce the dimension even more, to a chosen \(L\), by projecting onto the linear subspace \(H_L\) which maximizes the variance of the \(\mu^*_k\) after projection (in effect, we are doing a form of PCA for the transformed class means \(\mu^*_k\)). This \(L\) corresponds to the &lt;code&gt;n_components&lt;/code&gt; parameter used in the &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.transform&lt;/code&gt;&lt;/a&gt; method. See &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3]&lt;/a&gt; for more details.</source>
          <target state="translated">Podemos reducir la dimensi&amp;oacute;n a&amp;uacute;n m&amp;aacute;s, a un \ (L \) elegido, proyectando sobre el subespacio lineal \ (H_L \) que maximiza la varianza de \ (\ mu ^ * _ k \) despu&amp;eacute;s de la proyecci&amp;oacute;n (en efecto, est&amp;aacute;n haciendo una forma de PCA para la clase transformada significa \ (\ mu ^ * _ k \)). Este \ (L \) corresponde al par&amp;aacute;metro &lt;code&gt;n_components&lt;/code&gt; utilizado en el m&amp;eacute;todo &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.transform&lt;/code&gt; &lt;/a&gt; . Consulte &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3]&lt;/a&gt; para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="92db19023b735fef317e25e1a918af44df264854" translate="yes" xml:space="preserve">
          <source>We can reduce the dimension even more, to a chosen \(L\), by projecting onto the linear subspace \(H_L\) which maximizes the variance of the \(\mu^*_k\) after projection (in effect, we are doing a form of PCA for the transformed class means \(\mu^*_k\)). This \(L\) corresponds to the &lt;code&gt;n_components&lt;/code&gt; parameter used in the &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt;&lt;code&gt;transform&lt;/code&gt;&lt;/a&gt; method. See &lt;a href=&quot;#id5&quot; id=&quot;id3&quot;&gt;1&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32e64fece84cec61516540c9bc9ea581152251c6" translate="yes" xml:space="preserve">
          <source>We can see that &lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; preserves the class ratios (approximately 1 / 10) in both train and test dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bee45302ee9842b9e6d2e72404b6369d8b7e97cc" translate="yes" xml:space="preserve">
          <source>We can see that for low values of &lt;code&gt;n_components&lt;/code&gt; the distribution is wide with many distorted pairs and a skewed distribution (due to the hard limit of zero ratio on the left as distances are always positives) while for larger values of n_components the distortion is controlled and the distances are well preserved by the random projection.</source>
          <target state="translated">Podemos ver que para valores bajos de &lt;code&gt;n_components&lt;/code&gt; la distribuci&amp;oacute;n es amplia con muchos pares distorsionados y una distribuci&amp;oacute;n sesgada (debido al l&amp;iacute;mite estricto de la relaci&amp;oacute;n cero a la izquierda, ya que las distancias son siempre positivas) mientras que para valores m&amp;aacute;s grandes de n_components la distorsi&amp;oacute;n est&amp;aacute; controlada y las distancias est&amp;aacute;n bien conservadas por la proyecci&amp;oacute;n aleatoria.</target>
        </trans-unit>
        <trans-unit id="d51b2a4e76fb7eb99807202c5234812c15585e4c" translate="yes" xml:space="preserve">
          <source>We can see that if the maximum depth of the tree (controlled by the &lt;code&gt;max_depth&lt;/code&gt; parameter) is set too high, the decision trees learn too fine details of the training data and learn from the noise, i.e. they overfit.</source>
          <target state="translated">Podemos ver que si la profundidad m&amp;aacute;xima del &amp;aacute;rbol (controlada por el par&amp;aacute;metro &lt;code&gt;max_depth&lt;/code&gt; ) se establece demasiado alta, los &amp;aacute;rboles de decisi&amp;oacute;n aprenden detalles demasiado finos de los datos de entrenamiento y aprenden del ruido, es decir, sobreajustan.</target>
        </trans-unit>
        <trans-unit id="5bc27bfd8c709ab5505734b2124db3dbd09e7af4" translate="yes" xml:space="preserve">
          <source>We can see that, although feature 2 has a strong coefficient on the full model, it conveys little information on &lt;code&gt;y&lt;/code&gt; when considered with feature 1.</source>
          <target state="translated">Podemos ver que, aunque la caracter&amp;iacute;stica 2 tiene un coeficiente fuerte en el modelo completo, transmite poca informaci&amp;oacute;n sobre &lt;code&gt;y&lt;/code&gt; cuando se considera con la caracter&amp;iacute;stica 1.</target>
        </trans-unit>
        <trans-unit id="208e5f1f40787dd5dcd62a253128bd90d5a3414b" translate="yes" xml:space="preserve">
          <source>We can turn those concept as scores &lt;a href=&quot;generated/sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt;&lt;code&gt;homogeneity_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt;&lt;code&gt;completeness_score&lt;/code&gt;&lt;/a&gt;. Both are bounded below by 0.0 and above by 1.0 (higher is better):</source>
          <target state="translated">Podemos convertir esos conceptos en puntajes &lt;a href=&quot;generated/sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt; &lt;code&gt;homogeneity_score&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt; &lt;code&gt;completeness_score&lt;/code&gt; &lt;/a&gt; . Ambos est&amp;aacute;n delimitados por debajo de 0.0 y por encima de 1.0 (cuanto m&amp;aacute;s alto, mejor):</target>
        </trans-unit>
        <trans-unit id="592289b1a6fdac7a6256bbd4a62b88701d16e505" translate="yes" xml:space="preserve">
          <source>We can use the function &lt;a href=&quot;generated/sklearn.model_selection.learning_curve#sklearn.model_selection.learning_curve&quot;&gt;&lt;code&gt;learning_curve&lt;/code&gt;&lt;/a&gt; to generate the values that are required to plot such a learning curve (number of samples that have been used, the average scores on the training sets and the average scores on the validation sets):</source>
          <target state="translated">Podemos utilizar la funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.model_selection.learning_curve#sklearn.model_selection.learning_curve&quot;&gt; &lt;code&gt;learning_curve&lt;/code&gt; &lt;/a&gt; para generar los valores que se requieren para trazar dicha curva de aprendizaje (n&amp;uacute;mero de muestras que se han utilizado, las puntuaciones medias en los conjuntos de entrenamiento y las puntuaciones medias en los conjuntos de validaci&amp;oacute;n):</target>
        </trans-unit>
        <trans-unit id="36de20f1638d2356805015f502415f93be57efc5" translate="yes" xml:space="preserve">
          <source>We can visually compare observed and predicted values, aggregated by the drivers age (&lt;code&gt;DrivAge&lt;/code&gt;), vehicle age (&lt;code&gt;VehAge&lt;/code&gt;) and the insurance bonus/malus (&lt;code&gt;BonusMalus&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0507ecbdf9b58dd0986ef6194b95f4c79d58f52" translate="yes" xml:space="preserve">
          <source>We can visually compare observed and predicted values, aggregated for the drivers age (&lt;code&gt;DrivAge&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c55a99ecafce9d11edefa5f7981438b525c546b" translate="yes" xml:space="preserve">
          <source>We classify 8x8 images of digits into two classes: 0-4 against 5-9. The visualization shows coefficients of the models for varying C.</source>
          <target state="translated">Clasificamos las imágenes 8x8 de los dígitos en dos clases:0-4 contra 5-9.La visualización muestra los coeficientes de los modelos para variar C.</target>
        </trans-unit>
        <trans-unit id="523600239bb64c3dc717f02d73255329247ddc08" translate="yes" xml:space="preserve">
          <source>We configured a pipeline to scale the numerical input features and tuned the neural network size and learning rate to get a reasonable compromise between training time and predictive performance on a test set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c2ceff57e3b51d317fe78664f4ea8312ed35966" translate="yes" xml:space="preserve">
          <source>We consider 3 features x_1, x_2, x_3 distributed uniformly over [0, 1], the target depends on them as follows:</source>
          <target state="translated">Consideramos 3 características x_1,x_2,x_3 distribuidas uniformemente sobre [0,1],el objetivo depende de ellas como sigue:</target>
        </trans-unit>
        <trans-unit id="f5f452641b4c7cde04f8f2f3146b6f807ae80e50" translate="yes" xml:space="preserve">
          <source>We construct the freMTPL2 dataset by joining the freMTPL2freq table, containing the number of claims (&lt;code&gt;ClaimNb&lt;/code&gt;), with the freMTPL2sev table, containing the claim amount (&lt;code&gt;ClaimAmount&lt;/code&gt;) for the same policy ids (&lt;code&gt;IDpol&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b738423194ebf355d81c34c5848e446f6f25c86" translate="yes" xml:space="preserve">
          <source>We create a multi-label dataset, to illustrate the precision-recall in multi-label settings</source>
          <target state="translated">Creamos un conjunto de datos multi-etiquetas,para ilustrar la precisión de la recuperación en entornos multi-etiquetas</target>
        </trans-unit>
        <trans-unit id="2b472a5c2bccac31b45ff227b2c9930cbabaf64f" translate="yes" xml:space="preserve">
          <source>We create the preprocessing pipelines for both numeric and categorical data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6395abe83d6b6a4aa4bc2a531d4a8a4bd65d8620" translate="yes" xml:space="preserve">
          <source>We describe here the mathematical details of the SGD procedure. A good overview with convergence rates can be found in &lt;a href=&quot;#id16&quot; id=&quot;id4&quot;&gt;12&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f9ff80fbe7d3d20607821a1978395dad8f7243a" translate="yes" xml:space="preserve">
          <source>We describe these 3 scenarios in the following subsections.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7df3a30efca0a13e3a362147c9be1fa02a3e02fd" translate="yes" xml:space="preserve">
          <source>We don&amp;rsquo;t allow:</source>
          <target state="translated">No permitimos:</target>
        </trans-unit>
        <trans-unit id="484dbca389e5beb12ba95d531ed59ac647119de0" translate="yes" xml:space="preserve">
          <source>We fetch the data from &lt;a href=&quot;http://openml.org/&quot;&gt;OpenML&lt;/a&gt;. Note that setting the parameter &lt;code&gt;as_frame&lt;/code&gt; to True will retrieve the data as a pandas dataframe.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43167795aabd351e0317ac3702c4dd940441044a" translate="yes" xml:space="preserve">
          <source>We filter out &lt;code&gt;ClaimAmount == 0&lt;/code&gt; as the Gamma distribution has support on \((0, \infty)\), not \([0, \infty)\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c17cba12ad6e5c2f931d1de0fcadd712e7bb0a0a" translate="yes" xml:space="preserve">
          <source>We first find the separating plane with a plain SVC and then plot (dashed) the separating hyperplane with automatically correction for unbalanced classes.</source>
          <target state="translated">Primero encontramos el plano de separación con una VCS plana y luego trazamos (punteamos)el hiperplano de separación con corrección automática de las clases desequilibradas.</target>
        </trans-unit>
        <trans-unit id="1b6887ebea04d51a67698037588b0795f4c76e3a" translate="yes" xml:space="preserve">
          <source>We first present GBRT for regression, and then detail the classification case.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="916afde7457af1caed530318ff87e1a7a139918e" translate="yes" xml:space="preserve">
          <source>We found that &lt;code&gt;max_leaf_nodes=k&lt;/code&gt; gives comparable results to &lt;code&gt;max_depth=k-1&lt;/code&gt; but is significantly faster to train at the expense of a slightly higher training error. The parameter &lt;code&gt;max_leaf_nodes&lt;/code&gt; corresponds to the variable &lt;code&gt;J&lt;/code&gt; in the chapter on gradient boosting in &lt;a href=&quot;#f2001&quot; id=&quot;id14&quot;&gt;[F2001]&lt;/a&gt; and is related to the parameter &lt;code&gt;interaction.depth&lt;/code&gt; in R&amp;rsquo;s gbm package where &lt;code&gt;max_leaf_nodes == interaction.depth + 1&lt;/code&gt; .</source>
          <target state="translated">Descubrimos que &lt;code&gt;max_leaf_nodes=k&lt;/code&gt; da resultados comparables a &lt;code&gt;max_depth=k-1&lt;/code&gt; pero es significativamente m&amp;aacute;s r&amp;aacute;pido de entrenar a expensas de un error de entrenamiento ligeramente mayor. El par&amp;aacute;metro &lt;code&gt;max_leaf_nodes&lt;/code&gt; corresponde a la variable &lt;code&gt;J&lt;/code&gt; en el cap&amp;iacute;tulo sobre gradiente de impulsar en &lt;a href=&quot;#f2001&quot; id=&quot;id14&quot;&gt;[F2001]&lt;/a&gt; y se relaciona con el par&amp;aacute;metro &lt;code&gt;interaction.depth&lt;/code&gt; en paquete gbm de R donde &lt;code&gt;max_leaf_nodes == interaction.depth + 1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="9a42cbe6e58382c593ff38ee7701bfc70bcd66e4" translate="yes" xml:space="preserve">
          <source>We found that &lt;code&gt;max_leaf_nodes=k&lt;/code&gt; gives comparable results to &lt;code&gt;max_depth=k-1&lt;/code&gt; but is significantly faster to train at the expense of a slightly higher training error. The parameter &lt;code&gt;max_leaf_nodes&lt;/code&gt; corresponds to the variable &lt;code&gt;J&lt;/code&gt; in the chapter on gradient boosting in &lt;a href=&quot;model_evaluation#f2001&quot; id=&quot;id15&quot;&gt;[F2001]&lt;/a&gt; and is related to the parameter &lt;code&gt;interaction.depth&lt;/code&gt; in R&amp;rsquo;s gbm package where &lt;code&gt;max_leaf_nodes == interaction.depth + 1&lt;/code&gt; .</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72f7189dc223c470430f67b7332d9ced78363339" translate="yes" xml:space="preserve">
          <source>We found that Averaged SGD works best with a larger number of features and a higher eta0</source>
          <target state="translated">Encontramos que el SGD promedio funciona mejor con un mayor número de características y un mayor eta0</target>
        </trans-unit>
        <trans-unit id="2147828a070acc191399f3a8049f6a914fdacd22" translate="yes" xml:space="preserve">
          <source>We further include two random variables that are not correlated in any way with the target variable (&lt;code&gt;survived&lt;/code&gt;):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ecc641e4f0c3be544f8ba1b6978d12b64c778e22" translate="yes" xml:space="preserve">
          <source>We generate data from three groups of waveforms. Two of the waveforms (waveform 1 and waveform 2) are proportional one to the other. The cosine distance is invariant to a scaling of the data, as a result, it cannot distinguish these two waveforms. Thus even with no noise, clustering using this distance will not separate out waveform 1 and 2.</source>
          <target state="translated">Generamos datos de tres grupos de formas de onda.Dos de las formas de onda (forma de onda 1 y forma de onda 2)son proporcionales una a la otra.La distancia del coseno es invariable a una escala de los datos,por lo que no puede distinguir estas dos formas de onda.Por lo tanto,incluso sin ruido,la agrupación utilizando esta distancia no separará la forma de onda 1 y 2.</target>
        </trans-unit>
        <trans-unit id="03835cacd7901d07f747c14f209b80543758c4fd" translate="yes" xml:space="preserve">
          <source>We have seen that some estimators can transform data and that some estimators can predict variables. We can also create combined estimators:</source>
          <target state="translated">Hemos visto que algunos estimadores pueden transformar los datos y que algunos estimadores pueden predecir variables.También podemos crear estimadores combinados:</target>
        </trans-unit>
        <trans-unit id="996013b3c282443801da622c65fee1deca3cef01" translate="yes" xml:space="preserve">
          <source>We have seen that sparsity could be used to mitigate the curse of dimensionality, &lt;em&gt;i.e&lt;/em&gt; an insufficient amount of observations compared to the number of features. Another approach is to merge together similar features: &lt;strong&gt;feature agglomeration&lt;/strong&gt;. This approach can be implemented by clustering in the feature direction, in other words clustering the transposed data.</source>
          <target state="translated">Hemos visto que la escasez podr&amp;iacute;a usarse para mitigar la maldici&amp;oacute;n de la dimensionalidad, &lt;em&gt;es decir&lt;/em&gt; , una cantidad insuficiente de observaciones en comparaci&amp;oacute;n con la cantidad de caracter&amp;iacute;sticas. Otro enfoque es fusionar caracter&amp;iacute;sticas similares: &lt;strong&gt;aglomeraci&amp;oacute;n de caracter&amp;iacute;sticas&lt;/strong&gt; . Este enfoque se puede implementar agrupando en la direcci&amp;oacute;n de la caracter&amp;iacute;stica, en otras palabras agrupando los datos transpuestos.</target>
        </trans-unit>
        <trans-unit id="f70b46435230cf70b0b3d749ceef620b9bcdee9d" translate="yes" xml:space="preserve">
          <source>We have specifically abstained from an optimization used by authors of both papers, a QR decomposition used in specific situations to reduce the algorithmic complexity of the SVD. The source for this technique is &lt;code&gt;Matrix Computations, Third Edition, G. Holub and C. Van Loan, Chapter 5, section 5.4.4, pp 252-253.&lt;/code&gt;. This technique has been omitted because it is advantageous only when decomposing a matrix with &lt;code&gt;n_samples&lt;/code&gt; (rows) &amp;gt;= 5/3 * &lt;code&gt;n_features&lt;/code&gt; (columns), and hurts the readability of the implemented algorithm. This would be a good opportunity for future optimization, if it is deemed necessary.</source>
          <target state="translated">Nos hemos abstenido espec&amp;iacute;ficamente de una optimizaci&amp;oacute;n utilizada por los autores de ambos art&amp;iacute;culos, una descomposici&amp;oacute;n QR utilizada en situaciones espec&amp;iacute;ficas para reducir la complejidad algor&amp;iacute;tmica de la SVD. La fuente de esta t&amp;eacute;cnica es &lt;code&gt;Matrix Computations, Third Edition, G. Holub and C. Van Loan, Chapter 5, section 5.4.4, pp 252-253.&lt;/code&gt; . Esta t&amp;eacute;cnica se ha omitido porque es ventajosa solo cuando se descompone una matriz con &lt;code&gt;n_samples&lt;/code&gt; (filas)&amp;gt; = 5/3 * &lt;code&gt;n_features&lt;/code&gt; (columnas) y perjudica la legibilidad del algoritmo implementado. Esta ser&amp;iacute;a una buena oportunidad para la optimizaci&amp;oacute;n futura, si se considera necesario.</target>
        </trans-unit>
        <trans-unit id="ac54e4e32d1eea16ad8753f857ea27f0962cb421" translate="yes" xml:space="preserve">
          <source>We have specifically abstained from an optimization used by authors of both papers, a QR decomposition used in specific situations to reduce the algorithmic complexity of the SVD. The source for this technique is &lt;em&gt;Matrix Computations, Third Edition, G. Holub and C. Van Loan, Chapter 5, section 5.4.4, pp 252-253.&lt;/em&gt;. This technique has been omitted because it is advantageous only when decomposing a matrix with &lt;code&gt;n_samples&lt;/code&gt; (rows) &amp;gt;= 5/3 * &lt;code&gt;n_features&lt;/code&gt; (columns), and hurts the readability of the implemented algorithm. This would be a good opportunity for future optimization, if it is deemed necessary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db298eced453f06f8efed43be73a03415c98ca01" translate="yes" xml:space="preserve">
          <source>We have to reconstruct model and parameters to make sure we stay in sync with the python object.</source>
          <target state="translated">Tenemos que reconstruir el modelo y los parámetros para asegurarnos de estar en sincronía con el objeto pitón.</target>
        </trans-unit>
        <trans-unit id="ca5f08fcacf0548e5e0c637b82c4414e44704050" translate="yes" xml:space="preserve">
          <source>We introduce a new parameter \(\nu\) (instead of \(C\)) which controls the number of support vectors and &lt;em&gt;margin errors&lt;/em&gt;: \(\nu \in (0, 1]\) is an upper bound on the fraction of margin errors and a lower bound of the fraction of support vectors. A margin error corresponds to a sample that lies on the wrong side of its margin boundary: it is either misclassified, or it is correctly classified but does not lie beyond the margin.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2683785e1f3e3ccb40d3941fed7d5fa67a33cfc" translate="yes" xml:space="preserve">
          <source>We introduce a new parameter \(\nu\) which controls the number of support vectors and training errors. The parameter \(\nu \in (0, 1]\) is an upper bound on the fraction of training errors and a lower bound of the fraction of support vectors.</source>
          <target state="translated">Introducimos un nuevo parámetro que controla el número de vectores de apoyo y los errores de entrenamiento.El parámetro \N \N \N es un límite superior de la fracción de errores de entrenamiento y un límite inferior de la fracción de vectores de apoyo.</target>
        </trans-unit>
        <trans-unit id="60ccb05e0b7446f76670a424f0fabb01d1ca71b3" translate="yes" xml:space="preserve">
          <source>We need a vectorized version of the image. &lt;code&gt;'rescaled_coins'&lt;/code&gt; is a down-scaled version of the coins image to speed up the process:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="284f00654c2880797bacd24e85e3bc2f5ec8be8d" translate="yes" xml:space="preserve">
          <source>We no longer get the collisions, but this comes at the expense of a much larger dimensionality of the output space. Of course, other terms than the 19 used here might still collide with each other.</source>
          <target state="translated">Ya no tenemos las colisiones,pero esto viene a expensas de una dimensionalidad mucho mayor del espacio de salida.Por supuesto,otros términos distintos a los 19 usados aquí podrían seguir colisionando entre sí.</target>
        </trans-unit>
        <trans-unit id="a19ee5584b95e367f6c768452e1c513e3bb433ea" translate="yes" xml:space="preserve">
          <source>We now inspect the coefficients across several cross-validation folds.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d37726e46e38fa3806c6050ccef5f0b5ccde0ad" translate="yes" xml:space="preserve">
          <source>We now provide a &lt;code&gt;pytest&lt;/code&gt; specific decorator which allows &lt;code&gt;pytest&lt;/code&gt; to run all checks independently and report the checks that are failing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b22fff2428986dd4d9e25659e5099f6fa799f31a" translate="yes" xml:space="preserve">
          <source>We now support imputation for completing missing values using k-Nearest Neighbors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b146f434972f2182b845909391decf90277ad41" translate="yes" xml:space="preserve">
          <source>We observe a tendency towards clearer shapes as the perplexity value increases.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e7a6d4d2e128e719f76bf1799c4515162612bfb" translate="yes" xml:space="preserve">
          <source>We observe a tendency towards clearer shapes as the preplexity value increases.</source>
          <target state="translated">Observamos una tendencia hacia formas más claras a medida que aumenta el valor de preplejidad.</target>
        </trans-unit>
        <trans-unit id="3705c31d0fb66694929007b0cdad834fbbaf06c2" translate="yes" xml:space="preserve">
          <source>We plot partial dependence curves for features &amp;ldquo;age&amp;rdquo; and &amp;ldquo;bmi&amp;rdquo; (body mass index) for the decision tree. With two features, &lt;a href=&quot;../../modules/generated/sklearn.inspection.plot_partial_dependence#sklearn.inspection.plot_partial_dependence&quot;&gt;&lt;code&gt;plot_partial_dependence&lt;/code&gt;&lt;/a&gt; expects to plot two curves. Here the plot function place a grid of two plots using the space defined by &lt;code&gt;ax&lt;/code&gt; .</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4e7d2188aa62b346706f6bd2a1ae94095756883" translate="yes" xml:space="preserve">
          <source>We plot predicted labels on both training and held out test data using a variety of GMM covariance types on the iris dataset. We compare GMMs with spherical, diagonal, full, and tied covariance matrices in increasing order of performance. Although one would expect full covariance to perform best in general, it is prone to overfitting on small datasets and does not generalize well to held out test data.</source>
          <target state="translated">Trazamos las etiquetas de predicción en ambos entrenamientos y los datos de las pruebas utilizando una variedad de tipos de covarianza GMM en el conjunto de datos del iris.Comparamos los GMM con matrices de covarianza esférica,diagonal,completa y ligada en orden creciente de rendimiento.Aunque uno esperaría que la covarianza completa tuviera el mejor rendimiento en general,es propensa a sobrecargarse en conjuntos de datos pequeños y no se generaliza bien a los datos de prueba mantenidos.</target>
        </trans-unit>
        <trans-unit id="7ead9de71a0f24e08ddaae8aaa6dd6470443d3a2" translate="yes" xml:space="preserve">
          <source>We recommend &lt;a href=&quot;#id15&quot; id=&quot;id6&quot;&gt;13&lt;/a&gt; and &lt;a href=&quot;#id16&quot; id=&quot;id7&quot;&gt;14&lt;/a&gt; as good references for the theory and practicalities of SVMs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a444360e57dc0870f14b3c959a7b626922e7571" translate="yes" xml:space="preserve">
          <source>We see that &lt;code&gt;SVC&lt;/code&gt; doesn&amp;rsquo;t do much better than a dummy classifier. Now, let&amp;rsquo;s change the kernel:</source>
          <target state="translated">Vemos que &lt;code&gt;SVC&lt;/code&gt; no funciona mucho mejor que un clasificador ficticio. Ahora, cambiemos el kernel:</target>
        </trans-unit>
        <trans-unit id="9619f66671fbeb88bbee2c1b3d850c22bdb6ab25" translate="yes" xml:space="preserve">
          <source>We see that the accuracy was boosted to almost 100%. A cross validation strategy is recommended for a better estimate of the accuracy, if it is not too CPU costly. For more information see the &lt;a href=&quot;cross_validation#cross-validation&quot;&gt;Cross-validation: evaluating estimator performance&lt;/a&gt; section. Moreover if you want to optimize over the parameter space, it is highly recommended to use an appropriate methodology; see the &lt;a href=&quot;grid_search#grid-search&quot;&gt;Tuning the hyper-parameters of an estimator&lt;/a&gt; section for details.</source>
          <target state="translated">Vemos que la precisi&amp;oacute;n se increment&amp;oacute; a casi un 100%. Se recomienda una estrategia de validaci&amp;oacute;n cruzada para una mejor estimaci&amp;oacute;n de la precisi&amp;oacute;n, si no es demasiado costosa para la CPU. Para obtener m&amp;aacute;s informaci&amp;oacute;n, consulte la secci&amp;oacute;n &lt;a href=&quot;cross_validation#cross-validation&quot;&gt;Validaci&amp;oacute;n cruzada: evaluaci&amp;oacute;n del rendimiento del estimador&lt;/a&gt; . Adem&amp;aacute;s, si desea optimizar el espacio de par&amp;aacute;metros, se recomienda encarecidamente utilizar una metodolog&amp;iacute;a adecuada; consulte la secci&amp;oacute;n &lt;a href=&quot;grid_search#grid-search&quot;&gt;Ajuste de los hiperpar&amp;aacute;metros de un estimador&lt;/a&gt; para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="b05b900d7824680be8b5fe4195a1e87507494a4c" translate="yes" xml:space="preserve">
          <source>We see that the resulting &lt;em&gt;polynomial regression&lt;/em&gt; is in the same class of linear models we considered above (i.e. the model is linear in \(w\)) and can be solved by the same techniques. By considering linear fits within a higher-dimensional space built with these basis functions, the model has the flexibility to fit a much broader range of data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d680bb4e5101fe3a9df93911d26cfa982767e679" translate="yes" xml:space="preserve">
          <source>We see that the resulting &lt;em&gt;polynomial regression&lt;/em&gt; is in the same class of linear models we&amp;rsquo;d considered above (i.e. the model is linear in \(w\)) and can be solved by the same techniques. By considering linear fits within a higher-dimensional space built with these basis functions, the model has the flexibility to fit a much broader range of data.</source>
          <target state="translated">Vemos que la &lt;em&gt;regresi&amp;oacute;n polinomial&lt;/em&gt; resultante &lt;em&gt;pertenece&lt;/em&gt; a la misma clase de modelos lineales que hab&amp;iacute;amos considerado anteriormente (es decir, el modelo es lineal en \ (w \)) y puede resolverse mediante las mismas t&amp;eacute;cnicas. Al considerar los ajustes lineales dentro de un espacio de mayor dimensi&amp;oacute;n construido con estas funciones b&amp;aacute;sicas, el modelo tiene la flexibilidad de ajustarse a un rango de datos mucho m&amp;aacute;s amplio.</target>
        </trans-unit>
        <trans-unit id="1a0e7af8231b7a460dcfd9acf44c6323ad1ea844" translate="yes" xml:space="preserve">
          <source>We selected two sets of two variables from the Boston housing data set as an illustration of what kind of analysis can be done with several outlier detection tools. For the purpose of visualization, we are working with two-dimensional examples, but one should be aware that things are not so trivial in high-dimension, as it will be pointed out.</source>
          <target state="translated">Seleccionamos dos conjuntos de dos variables del conjunto de datos de viviendas de Boston como ilustración de qué tipo de análisis se puede hacer con varias herramientas de detección de valores atípicos.Para el propósito de la visualización,estamos trabajando con ejemplos bidimensionales,pero hay que tener en cuenta que las cosas no son tan triviales en alta dimensión,como se señalará.</target>
        </trans-unit>
        <trans-unit id="940e7a9289cb117779f9b0e089fc6f41ec456057" translate="yes" xml:space="preserve">
          <source>We should also note that small differences in scores results from the random splits of the cross-validation procedure. Those spurious variations can be smoothed out by increasing the number of CV iterations &lt;code&gt;n_splits&lt;/code&gt; at the expense of compute time. Increasing the value number of &lt;code&gt;C_range&lt;/code&gt; and &lt;code&gt;gamma_range&lt;/code&gt; steps will increase the resolution of the hyper-parameter heat map.</source>
          <target state="translated">Tambi&amp;eacute;n debemos se&amp;ntilde;alar que las peque&amp;ntilde;as diferencias en las puntuaciones resultan de las divisiones aleatorias del procedimiento de validaci&amp;oacute;n cruzada. Esas variaciones &lt;code&gt;n_splits&lt;/code&gt; pueden suavizarse aumentando el n&amp;uacute;mero de iteraciones CV n_splits a expensas del tiempo de c&amp;aacute;lculo. Aumentar el n&amp;uacute;mero de &lt;code&gt;C_range&lt;/code&gt; pasos C_range y &lt;code&gt;gamma_range&lt;/code&gt; aumentar&amp;aacute; la resoluci&amp;oacute;n del mapa de calor de hiperpar&amp;aacute;metros .</target>
        </trans-unit>
        <trans-unit id="1cbc5d306e08afa1d68b1045fc6a567611cf26d2" translate="yes" xml:space="preserve">
          <source>We show that linear_model.Lasso provides the same results for dense and sparse data and that in the case of sparse data the speed is improved.</source>
          <target state="translated">Mostramos que linear_model.Lasso proporciona los mismos resultados para datos densos y escasos y que en el caso de los datos escasos la velocidad es mejorada.</target>
        </trans-unit>
        <trans-unit id="971fe5258bb92dd314d2f061a23d12526523f329" translate="yes" xml:space="preserve">
          <source>We split the sample into a train and a test dataset. Only the train dataset will be used in the following exploratory analysis. This is a way to emulate a real situation where predictions are performed on an unknown target, and we don&amp;rsquo;t want our analysis and decisions to be biased by our knowledge of the test data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9729e48da1dbe46bc3dec3ab22ad1f98a7a56bb9" translate="yes" xml:space="preserve">
          <source>We start by modeling the target variable with the (l2 penalized) least squares linear regression model, more comonly known as Ridge regression. We use a low penalization &lt;code&gt;alpha&lt;/code&gt;, as we expect such a linear model to under-fit on such a large dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="efbf964638e7ca0fbdc3e1bd2a5029a9cbed6b8c" translate="yes" xml:space="preserve">
          <source>We start by training a label propagation model with only 10 labeled points, then we select the top five most uncertain points to label. Next, we train with 15 labeled points (original 10 + 5 new ones). We repeat this process four times to have a model trained with 30 labeled examples. Note you can increase this to label more than 30 by changing &lt;code&gt;max_iterations&lt;/code&gt;. Labeling more than 30 can be useful to get a sense for the speed of convergence of this active learning technique.</source>
          <target state="translated">Comenzamos entrenando un modelo de propagaci&amp;oacute;n de etiquetas con solo 10 puntos etiquetados, luego seleccionamos los cinco puntos m&amp;aacute;s inciertos para etiquetar. A continuaci&amp;oacute;n, entrenamos con 15 puntos etiquetados (10 originales + 5 nuevos). Repetimos este proceso cuatro veces para tener un modelo entrenado con 30 ejemplos etiquetados. Tenga en cuenta que puede aumentar esto para etiquetar m&amp;aacute;s de 30 cambiando &lt;code&gt;max_iterations&lt;/code&gt; . Etiquetar m&amp;aacute;s de 30 puede ser &amp;uacute;til para tener una idea de la velocidad de convergencia de esta t&amp;eacute;cnica de aprendizaje activo.</target>
        </trans-unit>
        <trans-unit id="b926aa4a7c89ca684b4dc714781356e70fac60ed" translate="yes" xml:space="preserve">
          <source>We thus transform the KDD Data set into two different data sets: SA and SF.</source>
          <target state="translated">Por lo tanto,transformamos el conjunto de datos de KDD en dos conjuntos de datos diferentes:SA y SF.</target>
        </trans-unit>
        <trans-unit id="c5856ddc1b1774be0ac4aef6a043703c4e71a274" translate="yes" xml:space="preserve">
          <source>We train a random forest classifier and create a plot comparing it to the SVC ROC curve. Notice how &lt;code&gt;svc_disp&lt;/code&gt; uses &lt;a href=&quot;../../modules/generated/sklearn.metrics.roccurvedisplay#sklearn.metrics.RocCurveDisplay.plot&quot;&gt;&lt;code&gt;plot&lt;/code&gt;&lt;/a&gt; to plot the SVC ROC curve without recomputing the values of the roc curve itself. Furthermore, we pass &lt;code&gt;alpha=0.8&lt;/code&gt; to the plot functions to adjust the alpha values of the curves.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38d99d5f10e1040b13651031a8f4b3d74d91ef9a" translate="yes" xml:space="preserve">
          <source>We train and test the datasets with 15 different classification models and get performance results for each model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f695efb4e75bb85159c9142762a64409b0330558" translate="yes" xml:space="preserve">
          <source>We use &lt;a href=&quot;../../modules/generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt;&lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt;&lt;/a&gt; to learn an embedding and plot the points after the transformation. We then take the embedding and find the nearest neighbors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b8cd078987f149b454cdac8f89f7fb050617be5" translate="yes" xml:space="preserve">
          <source>We use &lt;code&gt;ClaimNb&lt;/code&gt; as &lt;code&gt;sample_weight&lt;/code&gt; to account for policies that contain more than one claim.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13122bf873819e99a4ec7d32c926bbee95474f9b" translate="yes" xml:space="preserve">
          <source>We use a GridSearchCV to set the dimensionality of the PCA</source>
          <target state="translated">Usamos un GridSearchCV para establecer la dimensionalidad del PCA</target>
        </trans-unit>
        <trans-unit id="61efd119ac2fcb7bb96489a56e2c262d1e964f20" translate="yes" xml:space="preserve">
          <source>We use a biased estimator for the standard deviation, equivalent to &lt;code&gt;numpy.std(x, ddof=0)&lt;/code&gt;. Note that the choice of &lt;code&gt;ddof&lt;/code&gt; is unlikely to affect model performance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83c28baded6fcaa48849ef740f04075945b33344" translate="yes" xml:space="preserve">
          <source>We use clustering to group together quotes that behave similarly. Here, amongst the &lt;a href=&quot;../../modules/clustering#clustering&quot;&gt;various clustering techniques&lt;/a&gt; available in the scikit-learn, we use &lt;a href=&quot;../../modules/clustering#affinity-propagation&quot;&gt;Affinity Propagation&lt;/a&gt; as it does not enforce equal-size clusters, and it can choose automatically the number of clusters from the data.</source>
          <target state="translated">Usamos la agrupaci&amp;oacute;n en cl&amp;uacute;steres para agrupar citas que se comportan de manera similar. Aqu&amp;iacute;, entre las &lt;a href=&quot;../../modules/clustering#clustering&quot;&gt;diversas t&amp;eacute;cnicas de agrupaci&amp;oacute;n&lt;/a&gt; disponibles en scikit-learn, utilizamos la &lt;a href=&quot;../../modules/clustering#affinity-propagation&quot;&gt;Propagaci&amp;oacute;n por afinidad,&lt;/a&gt; ya que no impone agrupaciones de igual tama&amp;ntilde;o y puede elegir autom&amp;aacute;ticamente la cantidad de agrupaciones a partir de los datos.</target>
        </trans-unit>
        <trans-unit id="78d7bc0e66fad92fa188a5bbaa0a7aaa581101c6" translate="yes" xml:space="preserve">
          <source>We use sparse inverse covariance estimation to find which quotes are correlated conditionally on the others. Specifically, sparse inverse covariance gives us a graph, that is a list of connection. For each symbol, the symbols that it is connected too are those useful to explain its fluctuations.</source>
          <target state="translated">Utilizamos la estimación de la covarianza inversa escasa para encontrar qué citas están correlacionadas condicionalmente con las otras.Específicamente,la covarianza inversa escasa nos da un gráfico,que es una lista de conexiones.Para cada símbolo,los símbolos que está conectado también son los útiles para explicar sus fluctuaciones.</target>
        </trans-unit>
        <trans-unit id="0bc034dd2aa1865c002d495e95115e5b8c709a84" translate="yes" xml:space="preserve">
          <source>We validate the above bounds on the 20 newsgroups text document (TF-IDF word frequencies) dataset or on the digits dataset:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e3f49993eefd3c100d45584ffc552355d0d52e7" translate="yes" xml:space="preserve">
          <source>We validate the above bounds on the digits dataset or on the 20 newsgroups text document (TF-IDF word frequencies) dataset:</source>
          <target state="translated">Validamos los límites anteriores en el conjunto de datos de dígitos o en el conjunto de datos de documentos de texto de 20 grupos de noticias (frecuencias de palabras TF-IDF):</target>
        </trans-unit>
        <trans-unit id="63b1da5381eb76c29e4f139b0a4a0f6fa6f76bca" translate="yes" xml:space="preserve">
          <source>We want to calculate the distance between the Ezeiza Airport (Buenos Aires, Argentina) and the Charles de Gaulle Airport (Paris, France)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4bd2e73735072e414ab7c853666f3b851cc359c1" translate="yes" xml:space="preserve">
          <source>We want to compare the performance of the MiniBatchKMeans and KMeans: the MiniBatchKMeans is faster, but gives slightly different results (see &lt;a href=&quot;../../modules/clustering#mini-batch-kmeans&quot;&gt;Mini Batch K-Means&lt;/a&gt;).</source>
          <target state="translated">Queremos comparar el rendimiento de MiniBatchKMeans y KMeans: MiniBatchKMeans es m&amp;aacute;s r&amp;aacute;pido, pero da resultados ligeramente diferentes (ver &lt;a href=&quot;../../modules/clustering#mini-batch-kmeans&quot;&gt;Mini Batch K-Means&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="76b3c7c02e156a1d558e413ab95dd6c124236bdc" translate="yes" xml:space="preserve">
          <source>We will also create a transformer that extracts the length of the text and the number of sentences.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8ae1ec8b6dd301757e7e59be0a9aeff645f7f18" translate="yes" xml:space="preserve">
          <source>We will cluster a set of data, first with KMeans and then with MiniBatchKMeans, and plot the results. We will also plot the points that are labelled differently between the two algorithms.</source>
          <target state="translated">Agruparemos un conjunto de datos,primero con KMeans y luego con MiniBatchKMeans,y graficaremos los resultados.También graficaremos los puntos que están etiquetados de forma diferente entre los dos algoritmos.</target>
        </trans-unit>
        <trans-unit id="de730c276ad64150c605a83740871002db6683ff" translate="yes" xml:space="preserve">
          <source>We will compare the performance of both approaches. To quantify the performance of both models, one can compute the mean deviance of the train and test data assuming a Compound Poisson-Gamma distribution of the total claim amount. This is equivalent to a Tweedie distribution with a &lt;code&gt;power&lt;/code&gt; parameter between 1 and 2.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4cfcf9a2f9d6095c0707be11ca996fe9017bf9d" translate="yes" xml:space="preserve">
          <source>We will probably have to use an estimator or a parametrization of the current estimator that can learn more complex concepts (i.e. has a lower bias). If the training score is much greater than the validation score for the maximum number of training samples, adding more training samples will most likely increase generalization. In the following plot you can see that the SVM could benefit from more training examples.</source>
          <target state="translated">Probablemente tendremos que utilizar un estimador o una parametrización del estimador actual que pueda aprender conceptos más complejos (es decir,que tenga un sesgo menor).Si la puntuación de formación es mucho mayor que la puntuación de validación para el número máximo de muestras de formación,la adición de más muestras de formación probablemente aumentará la generalización.En la siguiente gráfica se puede ver que el SVM podría beneficiarse de más ejemplos de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="3f09acb611dde4d0822059b7dd910a6bf0d4be22" translate="yes" xml:space="preserve">
          <source>We will review here the orders of magnitude you can expect from a number of scikit-learn estimators in different contexts and provide some tips and tricks for overcoming performance bottlenecks.</source>
          <target state="translated">Revisaremos aquí los órdenes de magnitud que pueden esperar de una serie de estimadores de aprendizaje científico en diferentes contextos y proporcionaremos algunos consejos y trucos para superar los cuellos de botella en el rendimiento.</target>
        </trans-unit>
        <trans-unit id="7c06ec0897b21dbb460bd6d56256bf3c61c9d6ea" translate="yes" xml:space="preserve">
          <source>We will train our classifier with the following features:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3be1dd4cfac1d63b4ce361f8740d86e98582c7b5" translate="yes" xml:space="preserve">
          <source>We will use &lt;a href=&quot;http://jse.amstat.org/v19n3/decock.pdf&quot;&gt;Ames Housing&lt;/a&gt; dataset which was first compiled by Dean De Cock and became better known after it was used in Kaggle challenge. It is a set of 1460 residential homes in Ames, Iowa, each described by 80 features. We will use it to predict the final logarithmic price of the houses. In this example we will use only 20 most interesting features chosen using GradientBoostingRegressor() and limit number of entries (here we won&amp;rsquo;t go into the details on how to select the most interesting features).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="037b81bcdb33690797b74b53d8be309b975609a6" translate="yes" xml:space="preserve">
          <source>We will use data from the &lt;a href=&quot;https://www.openml.org/d/534&quot;&gt;&amp;ldquo;Current Population Survey&amp;rdquo;&lt;/a&gt; from 1985 to predict wage as a function of various features such as experience, age, or education.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66b44f9dbf66aa535fbabfa2d804ce4636c53d36" translate="yes" xml:space="preserve">
          <source>We will use the &lt;a href=&quot;../../datasets/index#newsgroups-dataset&quot;&gt;20 newsgroups dataset&lt;/a&gt;, which comprises posts from newsgroups on 20 topics. This dataset is split into train and test subsets based on messages posted before and after a specific date. We will only use posts from 2 categories to speed up running time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="889d3befa932d46595e6941bb656f25678ccbe94" translate="yes" xml:space="preserve">
          <source>We will use two datasets: Diabetes dataset which consists of 10 feature variables collected from diabetes patients with an aim to predict disease progression and California Housing dataset for which the target is the median house value for California districts.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7968cd3ef765f8c808b9f8985bbceb6fcebbccfc" translate="yes" xml:space="preserve">
          <source>We will work with the diabetes dataset which consists of 10 features collected from a cohort of diabetes patients. The target is a quantitative measure of disease progression one year after baseline.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ab95440492dec088ab7d086a3622b86acadc7e7" translate="yes" xml:space="preserve">
          <source>We&amp;rsquo;ll define a function that lets us visualize the behavior of each cross-validation object. We&amp;rsquo;ll perform 4 splits of the data. On each split, we&amp;rsquo;ll visualize the indices chosen for the training set (in blue) and the test set (in red).</source>
          <target state="translated">Definiremos una funci&amp;oacute;n que nos permita visualizar el comportamiento de cada objeto de validaci&amp;oacute;n cruzada. Realizaremos 4 divisiones de los datos. En cada divisi&amp;oacute;n, visualizaremos los &amp;iacute;ndices elegidos para el conjunto de entrenamiento (en azul) y el conjunto de prueba (en rojo).</target>
        </trans-unit>
        <trans-unit id="70c023ae490fc71ae664cdd80527ab708a5db4b9" translate="yes" xml:space="preserve">
          <source>We&amp;rsquo;ve already encountered some parameters such as &lt;code&gt;use_idf&lt;/code&gt; in the &lt;code&gt;TfidfTransformer&lt;/code&gt;. Classifiers tend to have many parameters as well; e.g., &lt;code&gt;MultinomialNB&lt;/code&gt; includes a smoothing parameter &lt;code&gt;alpha&lt;/code&gt; and &lt;code&gt;SGDClassifier&lt;/code&gt; has a penalty parameter &lt;code&gt;alpha&lt;/code&gt; and configurable loss and penalty terms in the objective function (see the module documentation, or use the Python &lt;code&gt;help&lt;/code&gt; function to get a description of these).</source>
          <target state="translated">Ya hemos encontrado algunos par&amp;aacute;metros como &lt;code&gt;use_idf&lt;/code&gt; en &lt;code&gt;TfidfTransformer&lt;/code&gt; . Los clasificadores tambi&amp;eacute;n tienden a tener muchos par&amp;aacute;metros; Por ejemplo, &lt;code&gt;MultinomialNB&lt;/code&gt; incluye un par&amp;aacute;metro de suavizado &lt;code&gt;alpha&lt;/code&gt; y &lt;code&gt;SGDClassifier&lt;/code&gt; tiene un par&amp;aacute;metro de penalizaci&amp;oacute;n &lt;code&gt;alpha&lt;/code&gt; y t&amp;eacute;rminos de penalizaci&amp;oacute;n y p&amp;eacute;rdida configurables en la funci&amp;oacute;n objetivo (consulte la documentaci&amp;oacute;n del m&amp;oacute;dulo o utilice la funci&amp;oacute;n de &lt;code&gt;help&lt;/code&gt; Python para obtener una descripci&amp;oacute;n de estos).</target>
        </trans-unit>
        <trans-unit id="e255008aad692a93735d4b63680bd4a96fdd74f7" translate="yes" xml:space="preserve">
          <source>Weight function used in prediction. Possible values:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96df76d7fa199e301349be570d5ef4d0bb6a7f3d" translate="yes" xml:space="preserve">
          <source>Weight given to each sample.</source>
          <target state="translated">El peso dado a cada muestra.</target>
        </trans-unit>
        <trans-unit id="a7a3ce3e7a16ef99378bfef64690454462da25e9" translate="yes" xml:space="preserve">
          <source>Weight matrix, where n_features in the number of visible units and n_components is the number of hidden units.</source>
          <target state="translated">Matriz de peso,donde n_características en el número de unidades visibles y n_componentes es el número de unidades ocultas.</target>
        </trans-unit>
        <trans-unit id="77c7b393c2f516d7fd42969c3e5ce51aceb4c82c" translate="yes" xml:space="preserve">
          <source>Weight of each sample, such that a sample with a weight of at least &lt;code&gt;min_samples&lt;/code&gt; is by itself a core sample; a sample with a negative weight may inhibit its eps-neighbor from being core. Note that weights are absolute, and default to 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0664e46a183d0a2a2e3afcbc3b6c5ba30a9d4ef" translate="yes" xml:space="preserve">
          <source>Weight of each sample, such that a sample with a weight of at least &lt;code&gt;min_samples&lt;/code&gt; is by itself a core sample; a sample with negative weight may inhibit its eps-neighbor from being core. Note that weights are absolute, and default to 1.</source>
          <target state="translated">Peso de cada muestra, de modo que una muestra con un peso de al menos &lt;code&gt;min_samples&lt;/code&gt; sea ​​en s&amp;iacute; misma una muestra central; una muestra con peso negativo puede inhibir que su vecino eps sea n&amp;uacute;cleo. Tenga en cuenta que los pesos son absolutos y el valor predeterminado es 1.</target>
        </trans-unit>
        <trans-unit id="5cc536fd8cf249ec4c2e295665e0070f1b9cec67" translate="yes" xml:space="preserve">
          <source>Weight of precision in harmonic mean.</source>
          <target state="translated">Peso de precisión en media armónica.</target>
        </trans-unit>
        <trans-unit id="6cd90e03c276712f974984f65620519bcea49500" translate="yes" xml:space="preserve">
          <source>Weight vector(s).</source>
          <target state="translated">Vectores de peso.</target>
        </trans-unit>
        <trans-unit id="ac0d2c9a738f9c54a5d208ddac8f22019ff9c627" translate="yes" xml:space="preserve">
          <source>Weight, Waist and Pulse.</source>
          <target state="translated">Peso,cintura y pulso.</target>
        </trans-unit>
        <trans-unit id="c74e4e7c5caf95682fb65872b5814741f06c7fac" translate="yes" xml:space="preserve">
          <source>Weighted average</source>
          <target state="translated">Promedio ponderado</target>
        </trans-unit>
        <trans-unit id="39392047d0260b6fc1e042825fdae9116d630e28" translate="yes" xml:space="preserve">
          <source>Weighted average probability for each class per sample.</source>
          <target state="translated">Probabilidad media ponderada de cada clase por muestra.</target>
        </trans-unit>
        <trans-unit id="62deefeab258040887cdf6743a94e11a29168c6f" translate="yes" xml:space="preserve">
          <source>Weighted within-class covariance matrix. It corresponds to &lt;code&gt;sum_k prior_k * C_k&lt;/code&gt; where &lt;code&gt;C_k&lt;/code&gt; is the covariance matrix of the samples in class &lt;code&gt;k&lt;/code&gt;. The &lt;code&gt;C_k&lt;/code&gt; are estimated using the (potentially shrunk) biased estimator of covariance. If solver is &amp;lsquo;svd&amp;rsquo;, only exists when &lt;code&gt;store_covariance&lt;/code&gt; is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec852c96538aadaa4b0b959b23f492c546aedd45" translate="yes" xml:space="preserve">
          <source>Weighting type to calculate the score. None means no weighted; &amp;ldquo;linear&amp;rdquo; means linear weighted; &amp;ldquo;quadratic&amp;rdquo; means quadratic weighted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a702ae7f12a23bf0cde9786ae821e6b340d4991" translate="yes" xml:space="preserve">
          <source>Weights applied to individual samples (1. for unweighted).</source>
          <target state="translated">Pesos aplicados a muestras individuales (1.para no ponderados).</target>
        </trans-unit>
        <trans-unit id="0c68217fe30f051f7b997da07ad569653cfdb104" translate="yes" xml:space="preserve">
          <source>Weights applied to individual samples. If not provided, uniform weights are assumed.</source>
          <target state="translated">Pesos aplicados a muestras individuales.Si no se proporcionan,se asumen pesos uniformes.</target>
        </trans-unit>
        <trans-unit id="3070fe087be2b6fbe15f65d4db644297c1112686" translate="yes" xml:space="preserve">
          <source>Weights applied to individual samples. If not provided, uniform weights are assumed. These weights will be multiplied with class_weight (passed through the constructor) if class_weight is specified</source>
          <target state="translated">Pesos aplicados a muestras individuales.Si no se proporcionan,se asumen pesos uniformes.Estos pesos se multiplicarán por el class_weight (pasado por el constructor)si se especifica el class_weight</target>
        </trans-unit>
        <trans-unit id="479d03c6533edea4de55367d8593a7974391f281" translate="yes" xml:space="preserve">
          <source>Weights applied to individual samples. If not provided, uniform weights are assumed. These weights will be multiplied with class_weight (passed through the constructor) if class_weight is specified.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86b1d5826d4836f8e129b6346c9e9e60976aafee" translate="yes" xml:space="preserve">
          <source>Weights assigned to the features (coefficients in the primal problem). This is only available in the case of a linear kernel.</source>
          <target state="translated">Pesos asignados a los rasgos (coeficientes en el problema primario).Esto sólo está disponible en el caso de un núcleo lineal.</target>
        </trans-unit>
        <trans-unit id="4b149f5e057b5bff95048ebeff46bfac0e7a368d" translate="yes" xml:space="preserve">
          <source>Weights assigned to the features.</source>
          <target state="translated">Pesos asignados a las características.</target>
        </trans-unit>
        <trans-unit id="4094f309127a892ba2564eecc3f5264343e18998" translate="yes" xml:space="preserve">
          <source>Weights associated with classes in the form &lt;code&gt;{class_label: weight}&lt;/code&gt;. If None, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8064bf8d5d6b0c15f7ed813823cc0da43a8bc7e6" translate="yes" xml:space="preserve">
          <source>Weights associated with classes in the form &lt;code&gt;{class_label: weight}&lt;/code&gt;. If not given, all classes are supposed to have weight one.</source>
          <target state="translated">Pesos asociados con clases en el formulario &lt;code&gt;{class_label: weight}&lt;/code&gt; . Si no se da, se supone que todas las clases tienen un peso uno.</target>
        </trans-unit>
        <trans-unit id="96f3238c530c2df09403ab213fee9515feb36c99" translate="yes" xml:space="preserve">
          <source>Weights associated with classes in the form &lt;code&gt;{class_label: weight}&lt;/code&gt;. If not given, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y.</source>
          <target state="translated">Pesos asociados con clases en el formulario &lt;code&gt;{class_label: weight}&lt;/code&gt; . Si no se da, se supone que todas las clases tienen un peso uno. Para problemas de m&amp;uacute;ltiples salidas, se puede proporcionar una lista de dictados en el mismo orden que las columnas de y.</target>
        </trans-unit>
        <trans-unit id="4a87f3dd4dfb432aa1a51752552e165c9cc23301" translate="yes" xml:space="preserve">
          <source>Weights associated with classes. If not given, all classes are supposed to have weight one.</source>
          <target state="translated">Pesos asociados a las clases.Si no se da,se supone que todas las clases tienen el peso uno.</target>
        </trans-unit>
        <trans-unit id="4837ab63e8195a91fca82bbd82590df1bbe7fcc4" translate="yes" xml:space="preserve">
          <source>Weights for each estimator in the boosted ensemble.</source>
          <target state="translated">Pesos para cada estimador en el conjunto potenciado.</target>
        </trans-unit>
        <trans-unit id="5f0089227653fec68913be1b7a199c273e750b44" translate="yes" xml:space="preserve">
          <source>Weights of training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55ddc90a49d39d4b40d722b720afa82441019829" translate="yes" xml:space="preserve">
          <source>Weights on each point of the regression. If None, weight is set to 1 (equal weights).</source>
          <target state="translated">Pesos en cada punto de la regresión.Si no hay ninguno,el peso se establece en 1 (pesos iguales).</target>
        </trans-unit>
        <trans-unit id="0946f675292deb36a2ff9f4a33806ccd9e9e1833" translate="yes" xml:space="preserve">
          <source>Weights. If set to None, all weights will be set to 1 (equal weights).</source>
          <target state="translated">Pesos.Si se establece en Ninguno,todos los pesos se establecerán en 1 (pesos iguales).</target>
        </trans-unit>
        <trans-unit id="c1f521c553b00dab458900dd1fb3f949a6ba99ab" translate="yes" xml:space="preserve">
          <source>Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approx. 80% actually belong to the positive class.</source>
          <target state="translated">Los clasificadores bien calibrados son clasificadores probabilísticos para los cuales la salida del método predict_proba puede interpretarse directamente como un nivel de confianza.Por ejemplo,un clasificador bien calibrado (binario)debería clasificar las muestras de tal manera que entre las muestras a las que dio un valor predict_proba cercano a 0,8,aproximadamente el 80% pertenecen en realidad a la clase positiva.</target>
        </trans-unit>
        <trans-unit id="8b629519ceaa09dd1767dbc350008d2ef28e9249" translate="yes" xml:space="preserve">
          <source>Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance, a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approximately 80% actually belong to the positive class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6db2509535d857954c618d97c17994b5d42574ae" translate="yes" xml:space="preserve">
          <source>Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance, a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approximately 80% actually belong to the positive class. The following plot compares how well the probabilistic predictions of different classifiers are calibrated:</source>
          <target state="translated">Los clasificadores bien calibrados son clasificadores probabilísticos para los cuales la salida del método predict_proba puede interpretarse directamente como un nivel de confianza.Por ejemplo,un clasificador bien calibrado (binario)debe clasificar las muestras de tal manera que entre las muestras a las que dio un valor predict_proba cercano a 0,8,aproximadamente el 80% pertenecen en realidad a la clase positiva.En el siguiente gráfico se compara lo bien que están calibradas las predicciones probabilísticas de diferentes clasificadores:</target>
        </trans-unit>
        <trans-unit id="830bc34728ca0799f710b4883d58631c6dfded76" translate="yes" xml:space="preserve">
          <source>Wether to include meta-estimators that are somehow special and can not be default-constructed sensibly. These are currently Pipeline, FeatureUnion and GridSearchCV</source>
          <target state="translated">Incluyendo meta-estimuladores que son de alguna manera especiales y que no pueden ser construidos por defecto de manera sensata.Estos son actualmente Pipeline,FeatureUnion y GridSearchCV</target>
        </trans-unit>
        <trans-unit id="d4f157bc9962e4b0dc2a197ed14e50902555d749" translate="yes" xml:space="preserve">
          <source>What are all the various decision tree algorithms and how do they differ from each other? Which one is implemented in scikit-learn?</source>
          <target state="translated">¿Cuáles son los diferentes algoritmos del árbol de decisión y en qué se diferencian unos de otros? ¿Cuál de ellos está implementado en scikit-learn?</target>
        </trans-unit>
        <trans-unit id="a1f5f9cd3d06157b8582b1ca4000a5bc395e765a" translate="yes" xml:space="preserve">
          <source>What this example shows us is the behavior &amp;ldquo;rich getting richer&amp;rdquo; of agglomerative clustering that tends to create uneven cluster sizes. This behavior is pronounced for the average linkage strategy, that ends up with a couple of singleton clusters, while in the case of single linkage we get a single central cluster with all other clusters being drawn from noise points around the fringes.</source>
          <target state="translated">Lo que este ejemplo nos muestra es el comportamiento de &amp;ldquo;enriquecimiento cada vez m&amp;aacute;s rico&amp;rdquo; de la agrupaci&amp;oacute;n aglomerativa que tiende a crear tama&amp;ntilde;os de agrupaci&amp;oacute;n desiguales. Este comportamiento es pronunciado para la estrategia de vinculaci&amp;oacute;n promedio, que termina con un par de grupos de singleton, mientras que en el caso de un solo v&amp;iacute;nculo obtenemos un grupo central &amp;uacute;nico con todos los dem&amp;aacute;s grupos extra&amp;iacute;dos de puntos de ruido alrededor de las franjas.</target>
        </trans-unit>
        <trans-unit id="32580ac608fcdadc1c2050695a6c24cae1fcef1f" translate="yes" xml:space="preserve">
          <source>What we can see that:</source>
          <target state="translated">Lo que podemos ver que:</target>
        </trans-unit>
        <trans-unit id="bd10ebd98b3e733be938ffeb72efbd3793589a2c" translate="yes" xml:space="preserve">
          <source>When &lt;a href=&quot;generated/sklearn.decomposition.latentdirichletallocation#sklearn.decomposition.LatentDirichletAllocation&quot;&gt;&lt;code&gt;LatentDirichletAllocation&lt;/code&gt;&lt;/a&gt; is applied on a &amp;ldquo;document-term&amp;rdquo; matrix, the matrix will be decomposed into a &amp;ldquo;topic-term&amp;rdquo; matrix and a &amp;ldquo;document-topic&amp;rdquo; matrix. While &amp;ldquo;topic-term&amp;rdquo; matrix is stored as &lt;code&gt;components_&lt;/code&gt; in the model, &amp;ldquo;document-topic&amp;rdquo; matrix can be calculated from &lt;code&gt;transform&lt;/code&gt; method.</source>
          <target state="translated">Cuando &lt;a href=&quot;generated/sklearn.decomposition.latentdirichletallocation#sklearn.decomposition.LatentDirichletAllocation&quot;&gt; &lt;code&gt;LatentDirichletAllocation&lt;/code&gt; &lt;/a&gt; se aplica en una matriz &quot;documento-t&amp;eacute;rmino&quot;, la matriz se descompondr&amp;aacute; en una matriz &quot;tema-t&amp;eacute;rmino&quot; y una matriz &quot;documento-tema&quot;. Mientras que la matriz &quot;tema-t&amp;eacute;rmino&quot; se almacena como &lt;code&gt;components_&lt;/code&gt; en el modelo, la matriz &quot;documento-tema&quot; se puede calcular a partir del m&amp;eacute;todo de &lt;code&gt;transform&lt;/code&gt; aci&amp;oacute;n .</target>
        </trans-unit>
        <trans-unit id="0c7daae89d35601e80a373ec7022d580692d615d" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;False&lt;/code&gt;, checks are evaluated when &lt;code&gt;check_estimator&lt;/code&gt; is called. When &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;check_estimator&lt;/code&gt; returns a generator that yields (estimator, check) tuples. The check is run by calling &lt;code&gt;check(estimator)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d35c02f0322e905eb57e225a27ca83f7c5f6cc47" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;axis=0&lt;/code&gt;, columns which only contained missing values at &lt;code&gt;fit&lt;/code&gt; are discarded upon &lt;code&gt;transform&lt;/code&gt;.</source>
          <target state="translated">Cuando &lt;code&gt;axis=0&lt;/code&gt; , las columnas que solo conten&amp;iacute;an valores faltantes en el &lt;code&gt;fit&lt;/code&gt; se descartan en la &lt;code&gt;transform&lt;/code&gt; aci&amp;oacute;n .</target>
        </trans-unit>
        <trans-unit id="7cf98e7188203ecb0d30e3564b161d5393433799" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;axis=1&lt;/code&gt;, an exception is raised if there are rows for which it is not possible to fill in the missing values (e.g., because they only contain missing values).</source>
          <target state="translated">Cuando &lt;code&gt;axis=1&lt;/code&gt; , se genera una excepci&amp;oacute;n si hay filas para las que no es posible completar los valores faltantes (por ejemplo, porque solo contienen valores faltantes).</target>
        </trans-unit>
        <trans-unit id="efffb9d033635c3e5b63e6f6f527201ab0e206e9" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;ccp_alpha&lt;/code&gt; is set to zero and keeping the other default parameters of &lt;a href=&quot;../../modules/generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt;&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;&lt;/a&gt;, the tree overfits, leading to a 100% training accuracy and 88% testing accuracy. As alpha increases, more of the tree is pruned, thus creating a decision tree that generalizes better. In this example, setting &lt;code&gt;ccp_alpha=0.015&lt;/code&gt; maximizes the testing accuracy.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4bce6b6fbd4b9fe79bfc7468f7df9f938d3ce841" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;fit&lt;/code&gt; does not converge, &lt;code&gt;cluster_centers_&lt;/code&gt; becomes an empty array and all training samples will be labelled as &lt;code&gt;-1&lt;/code&gt;. In addition, &lt;code&gt;predict&lt;/code&gt; will then label every sample as &lt;code&gt;-1&lt;/code&gt;.</source>
          <target state="translated">Cuando el &lt;code&gt;fit&lt;/code&gt; no converge, &lt;code&gt;cluster_centers_&lt;/code&gt; se convierte en una matriz vac&amp;iacute;a y todas las muestras de entrenamiento se etiquetar&amp;aacute;n como &lt;code&gt;-1&lt;/code&gt; . Adem&amp;aacute;s, &lt;code&gt;predict&lt;/code&gt; etiquetar&amp;aacute; cada muestra como &lt;code&gt;-1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f7c77c5939a6b7b3a7ed9ce47827d49725522a57" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;gamma&lt;/code&gt; is very small, the model is too constrained and cannot capture the complexity or &amp;ldquo;shape&amp;rdquo; of the data. The region of influence of any selected support vector would include the whole training set. The resulting model will behave similarly to a linear model with a set of hyperplanes that separate the centers of high density of any pair of two classes.</source>
          <target state="translated">Cuando la &lt;code&gt;gamma&lt;/code&gt; es muy peque&amp;ntilde;a, el modelo est&amp;aacute; demasiado restringido y no puede capturar la complejidad o la &quot;forma&quot; de los datos. La regi&amp;oacute;n de influencia de cualquier vector de apoyo seleccionado incluir&amp;iacute;a todo el conjunto de entrenamiento. El modelo resultante se comportar&amp;aacute; de manera similar a un modelo lineal con un conjunto de hiperplanos que separan los centros de alta densidad de cualquier par de dos clases.</target>
        </trans-unit>
        <trans-unit id="6579a89bba02e2aa5596acf0a356de3285b5831f" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;learning_method&lt;/code&gt; is &amp;lsquo;online&amp;rsquo;, use mini-batch update. Otherwise, use batch update.</source>
          <target state="translated">Cuando &lt;code&gt;learning_method&lt;/code&gt; est&amp;eacute; 'en l&amp;iacute;nea', use la actualizaci&amp;oacute;n por mini lotes. De lo contrario, utilice la actualizaci&amp;oacute;n por lotes.</target>
        </trans-unit>
        <trans-unit id="1789662661fe322dc45828ec3c3eb62749643034" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;novelty&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt; be aware that you must only use &lt;code&gt;predict&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;score_samples&lt;/code&gt; on new unseen data and not on the training samples as this would lead to wrong results. The scores of abnormality of the training samples are always accessible through the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute.</source>
          <target state="translated">Cuando la &lt;code&gt;novelty&lt;/code&gt; se establece en &lt;code&gt;True&lt;/code&gt; , tenga en cuenta que solo debe usar &lt;code&gt;predict&lt;/code&gt; , &lt;code&gt;decision_function&lt;/code&gt; y &lt;code&gt;score_samples&lt;/code&gt; en nuevos datos no vistos y no en las muestras de entrenamiento, ya que esto conducir&amp;iacute;a a resultados incorrectos. Los puntajes de anormalidad de las muestras de entrenamiento son siempre accesibles a trav&amp;eacute;s del atributo &lt;code&gt;negative_outlier_factor_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6539967754248da8802fa11e92b0d1b2532b93b8" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;predict_proba&lt;/code&gt; is used by each estimator (i.e. most of the time for &lt;code&gt;stack_method='auto'&lt;/code&gt; or specifically for &lt;code&gt;stack_method='predict_proba'&lt;/code&gt;), The first column predicted by each estimator will be dropped in the case of a binary classification problem. Indeed, both feature will be perfectly collinear.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="380c86407d2b15e6e735d8a020999525510d4000" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;shuffle&lt;/code&gt; is True, &lt;code&gt;random_state&lt;/code&gt; affects the ordering of the indices, which controls the randomness of each fold for each class. Otherwise, leave &lt;code&gt;random_state&lt;/code&gt; as &lt;code&gt;None&lt;/code&gt;. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dba0ae97777bf9e3aca974d6ebb1591964b94b4e" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;shuffle&lt;/code&gt; is True, &lt;code&gt;random_state&lt;/code&gt; affects the ordering of the indices, which controls the randomness of each fold. Otherwise, this parameter has no effect. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f36c5dece71799d4edbabcfff5ea8ed2f825b4d" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;true positive + false negative == 0&lt;/code&gt;, recall returns 0 and raises &lt;code&gt;UndefinedMetricWarning&lt;/code&gt;. This behavior can be modified with &lt;code&gt;zero_division&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43540f9f914266a4b6caeeeeef53fc90c0648c6e" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;true positive + false positive == 0&lt;/code&gt; or &lt;code&gt;true positive + false negative == 0&lt;/code&gt;, f-score returns 0 and raises &lt;code&gt;UndefinedMetricWarning&lt;/code&gt;. This behavior can be modified with &lt;code&gt;zero_division&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba4ca3b8ef57a04587026d0caa7a41ba81b60463" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;true positive + false positive == 0&lt;/code&gt;, precision is undefined; When &lt;code&gt;true positive + false negative == 0&lt;/code&gt;, recall is undefined. In such cases, by default the metric will be set to 0, as will f-score, and &lt;code&gt;UndefinedMetricWarning&lt;/code&gt; will be raised. This behavior can be modified with &lt;code&gt;zero_division&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c54bb2862f6516891f7056fa35777ac8bd097188" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;true positive + false positive == 0&lt;/code&gt;, precision returns 0 and raises &lt;code&gt;UndefinedMetricWarning&lt;/code&gt;. This behavior can be modified with &lt;code&gt;zero_division&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70168d4d772dfaf9b58be440f7660f3adf7f21be" translate="yes" xml:space="preserve">
          <source>When False, &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; both being sparse will yield sparse output. When True, output will always be a dense array.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3329fe0cead2a208482794593628ff4dce53789" translate="yes" xml:space="preserve">
          <source>When False, either &lt;code&gt;a&lt;/code&gt; or &lt;code&gt;b&lt;/code&gt; being sparse will yield sparse output. When True, output will always be an array.</source>
          <target state="translated">Cuando es False, ya sea que &lt;code&gt;a&lt;/code&gt; o &lt;code&gt;b&lt;/code&gt; sea ​​escaso producir&amp;aacute; una salida escasa. Cuando es verdadero, la salida siempre ser&amp;aacute; una matriz.</target>
        </trans-unit>
        <trans-unit id="1bb4bf21b8d21fdceb61000bf23d6624de5a3ca6" translate="yes" xml:space="preserve">
          <source>When False, only the predictions of estimators will be used as training data for &lt;code&gt;final_estimator&lt;/code&gt;. When True, the &lt;code&gt;final_estimator&lt;/code&gt; is trained on the predictions as well as the original training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0baad85c0e4d647371baa109869739d44cb0f600" translate="yes" xml:space="preserve">
          <source>When True (False by default) the &lt;code&gt;components_&lt;/code&gt; vectors are divided by &lt;code&gt;n_samples&lt;/code&gt; times &lt;code&gt;components_&lt;/code&gt; to ensure uncorrelated outputs with unit component-wise variances.</source>
          <target state="translated">Cuando Verdadero (False por defecto) los &lt;code&gt;components_&lt;/code&gt; vectores est&amp;aacute;n divididos por &lt;code&gt;n_samples&lt;/code&gt; veces &lt;code&gt;components_&lt;/code&gt; para asegurar salidas correlacionadas con las variaciones de los componentes en cuanto a la unidad.</target>
        </trans-unit>
        <trans-unit id="3eaa2881688032030c765cb871d4c787aff03fe7" translate="yes" xml:space="preserve">
          <source>When True (False by default) the &lt;code&gt;components_&lt;/code&gt; vectors are multiplied by the square root of n_samples and then divided by the singular values to ensure uncorrelated outputs with unit component-wise variances.</source>
          <target state="translated">Cuando es Verdadero (Falso por defecto), los &lt;code&gt;components_&lt;/code&gt; se multiplican por la ra&amp;iacute;z cuadrada de n_muestras y luego se dividen por los valores singulares para garantizar resultados no correlacionados con variaciones de componentes unitarios.</target>
        </trans-unit>
        <trans-unit id="afb8087ad0f4a499dd14f72be9807792c351ecd8" translate="yes" xml:space="preserve">
          <source>When True, an absolute value is applied to the features matrix prior to returning it. When used in conjunction with alternate_sign=True, this significantly reduces the inner product preservation property.</source>
          <target state="translated">Cuando es True,se aplica un valor absoluto a la matriz de características antes de devolverla.Cuando se usa en conjunto con alternate_sign=True,esto reduce significativamente la propiedad de preservación del producto interno.</target>
        </trans-unit>
        <trans-unit id="204d5c48d22bd9cd74d36182840231c3ecac4f55" translate="yes" xml:space="preserve">
          <source>When True, an alternating sign is added to the features as to approximately conserve the inner product in the hashed space even for small n_features. This approach is similar to sparse random projection.</source>
          <target state="translated">Cuando es cierto,se añade un signo alternativo a las características para conservar aproximadamente el producto interior en el espacio de hash incluso para las pequeñas n_características.Este enfoque es similar a la proyección aleatoria dispersa.</target>
        </trans-unit>
        <trans-unit id="e4283276989a341cb6ca6bb94564d0f53f92318b" translate="yes" xml:space="preserve">
          <source>When X and/or Y are CSR sparse matrices and they are not already in canonical format, this function modifies them in-place to make them canonical.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e08ec276d8bba6d4be8a6e677715ca1a35d4dd15" translate="yes" xml:space="preserve">
          <source>When a grouped cross-validator is used, the group labels are also passed on to the &lt;code&gt;split&lt;/code&gt; method of the cross-validator. The cross-validator uses them for grouping the samples while splitting the dataset into train/test set.</source>
          <target state="translated">Cuando se utiliza un validador cruzado agrupado, las etiquetas de grupo tambi&amp;eacute;n se pasan al m&amp;eacute;todo de &lt;code&gt;split&lt;/code&gt; del validador cruzado. El validador cruzado los usa para agrupar las muestras mientras divide el conjunto de datos en conjunto de tren / prueba.</target>
        </trans-unit>
        <trans-unit id="96fd8c38f0f9978d89774efb70a7d42aee5d30ee" translate="yes" xml:space="preserve">
          <source>When a specific number of neighbors is queried (using &lt;a href=&quot;generated/sklearn.neighbors.kneighborstransformer#sklearn.neighbors.KNeighborsTransformer&quot;&gt;&lt;code&gt;KNeighborsTransformer&lt;/code&gt;&lt;/a&gt;), the definition of &lt;code&gt;n_neighbors&lt;/code&gt; is ambiguous since it can either include each training point as its own neighbor, or exclude them. Neither choice is perfect, since including them leads to a different number of non-self neighbors during training and testing, while excluding them leads to a difference between &lt;code&gt;fit(X).transform(X)&lt;/code&gt; and &lt;code&gt;fit_transform(X)&lt;/code&gt;, which is against scikit-learn API. In &lt;a href=&quot;generated/sklearn.neighbors.kneighborstransformer#sklearn.neighbors.KNeighborsTransformer&quot;&gt;&lt;code&gt;KNeighborsTransformer&lt;/code&gt;&lt;/a&gt; we use the definition which includes each training point as its own neighbor in the count of &lt;code&gt;n_neighbors&lt;/code&gt;. However, for compatibility reasons with other estimators which use the other definition, one extra neighbor will be computed when &lt;code&gt;mode == 'distance'&lt;/code&gt;. To maximise compatibility with all estimators, a safe choice is to always include one extra neighbor in a custom nearest neighbors estimator, since unnecessary neighbors will be filtered by following estimators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c0f90cdc44694d62adb6ac9bccd5513d6bf148f" translate="yes" xml:space="preserve">
          <source>When all training samples have equal similarities and equal preferences, the assignment of cluster centers and labels depends on the preference. If the preference is smaller than the similarities, &lt;code&gt;fit&lt;/code&gt; will result in a single cluster center and label &lt;code&gt;0&lt;/code&gt; for every sample. Otherwise, every training sample becomes its own cluster center and is assigned a unique label.</source>
          <target state="translated">Cuando todas las muestras de entrenamiento tienen las mismas similitudes y las mismas preferencias, la asignaci&amp;oacute;n de centros y etiquetas de conglomerados depende de la preferencia. Si la preferencia es menor que las similitudes, el &lt;code&gt;fit&lt;/code&gt; dar&amp;aacute; como resultado un centro de grupo &amp;uacute;nico y la etiqueta &lt;code&gt;0&lt;/code&gt; para cada muestra. De lo contrario, cada muestra de capacitaci&amp;oacute;n se convierte en su propio centro de grupo y se le asigna una etiqueta &amp;uacute;nica.</target>
        </trans-unit>
        <trans-unit id="c440a8e563c9cc7b9752f14072284d81697bdfcd" translate="yes" xml:space="preserve">
          <source>When all training samples have equal similarities and equal preferences, the assignment of cluster centers and labels depends on the preference. If the preference is smaller than the similarities, a single cluster center and label &lt;code&gt;0&lt;/code&gt; for every sample will be returned. Otherwise, every training sample becomes its own cluster center and is assigned a unique label.</source>
          <target state="translated">Cuando todas las muestras de entrenamiento tienen las mismas similitudes y las mismas preferencias, la asignaci&amp;oacute;n de centros y etiquetas de conglomerados depende de la preferencia. Si la preferencia es menor que las similitudes, se devolver&amp;aacute; un solo centro de grupo y una etiqueta &lt;code&gt;0&lt;/code&gt; para cada muestra. De lo contrario, cada muestra de capacitaci&amp;oacute;n se convierte en su propio centro de grupo y se le asigna una etiqueta &amp;uacute;nica.</target>
        </trans-unit>
        <trans-unit id="2494d11b03713922afdad3fa1bc52bb7064577b4" translate="yes" xml:space="preserve">
          <source>When alpha is very large, the regularization effect dominates the squared loss function and the coefficients tend to zero. At the end of the path, as alpha tends toward zero and the solution tends towards the ordinary least squares, coefficients exhibit big oscillations. In practise it is necessary to tune alpha in such a way that a balance is maintained between both.</source>
          <target state="translated">Cuando el alfa es muy grande,el efecto de regularización domina la función de pérdida al cuadrado y los coeficientes tienden a cero.Al final del camino,como el alfa tiende hacia cero y la solución tiende hacia los mínimos cuadrados ordinarios,los coeficientes exhiben grandes oscilaciones.En la práctica es necesario afinar el alfa de tal manera que se mantenga un equilibrio entre ambos.</target>
        </trans-unit>
        <trans-unit id="e93a4fdf68d407dc869190eca6cd7dfaf57ad986" translate="yes" xml:space="preserve">
          <source>When applying LOF for outlier detection, there are no &lt;code&gt;predict&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;score_samples&lt;/code&gt; methods but only a &lt;code&gt;fit_predict&lt;/code&gt; method. The scores of abnormality of the training samples are accessible through the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute. Note that &lt;code&gt;predict&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;score_samples&lt;/code&gt; can be used on new unseen data when LOF is applied for novelty detection, i.e. when the &lt;code&gt;novelty&lt;/code&gt; parameter is set to &lt;code&gt;True&lt;/code&gt;. See &lt;a href=&quot;#novelty-with-lof&quot;&gt;Novelty detection with Local Outlier Factor&lt;/a&gt;.</source>
          <target state="translated">Al aplicar LOF para la detecci&amp;oacute;n de valores at&amp;iacute;picos, no hay m&amp;eacute;todos de &lt;code&gt;predict&lt;/code&gt; , funci&amp;oacute;n de &lt;code&gt;decision_function&lt;/code&gt; y &lt;code&gt;score_samples&lt;/code&gt; , sino solo un m&amp;eacute;todo de &lt;code&gt;fit_predict&lt;/code&gt; . Se puede acceder a las puntuaciones de anomal&amp;iacute;a de las muestras de entrenamiento a trav&amp;eacute;s del atributo &lt;code&gt;negative_outlier_factor_&lt;/code&gt; . Tenga en cuenta que &lt;code&gt;predict&lt;/code&gt; , &lt;code&gt;decision_function&lt;/code&gt; y &lt;code&gt;score_samples&lt;/code&gt; se pueden utilizar en nuevos datos no vistos cuando se aplica LOF para la detecci&amp;oacute;n de novedades, es decir, cuando el par&amp;aacute;metro de &lt;code&gt;novelty&lt;/code&gt; se establece en &lt;code&gt;True&lt;/code&gt; . Consulte &lt;a href=&quot;#novelty-with-lof&quot;&gt;Detecci&amp;oacute;n de novedades con factor at&amp;iacute;pico local&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2ec6d5a6d0d8178f2ec5cc1ea59ce167ddd0a98a" translate="yes" xml:space="preserve">
          <source>When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float in range [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="869141a5ff3e1444543cdaec8c9968684d76b66e" translate="yes" xml:space="preserve">
          <source>When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.</source>
          <target state="translated">Al construir el vocabulario,ignore los términos que tienen una frecuencia de documentos estrictamente superior al umbral dado (palabras de parada específicas del corpus).Si flotan,el parámetro representa una proporción de documentos,cuentas absolutas enteras.Este parámetro se ignora si el vocabulario no es Ninguno.</target>
        </trans-unit>
        <trans-unit id="d83f4236f3f25a9891417b446059c6cca3f6ec76" translate="yes" xml:space="preserve">
          <source>When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float in range of [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f13ad80586b74ad6fdc521fde036c051cf6e0e7" translate="yes" xml:space="preserve">
          <source>When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.</source>
          <target state="translated">Al construir el vocabulario ignorar los términos que tienen una frecuencia de documentos estrictamente inferior al umbral dado.Este valor también se llama &quot;cut-off&quot; en la literatura.Si flota,el parámetro representa una proporción de documentos,cuentas absolutas enteras.Este parámetro se ignora si el vocabulario no es Ninguno.</target>
        </trans-unit>
        <trans-unit id="757013c910e6b4628ced11d689b0016d8c17e540" translate="yes" xml:space="preserve">
          <source>When calculating class-wise multilabel confusion matrix \(C\), the count of true negatives for class \(i\) is \(C_{i,0,0}\), false negatives is \(C_{i,1,0}\), true positives is \(C_{i,1,1}\) and false positives is \(C_{i,0,1}\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ed788b8f95069d89dcb15b1bea5b5e7da9a9648" translate="yes" xml:space="preserve">
          <source>When calling &lt;code&gt;fit&lt;/code&gt;, an affinity matrix is constructed using either kernel function such the Gaussian (aka RBF) kernel of the euclidean distanced &lt;code&gt;d(X, X)&lt;/code&gt;:</source>
          <target state="translated">Al llamar a &lt;code&gt;fit&lt;/code&gt; , se construye una matriz de afinidad utilizando cualquiera de las funciones del kernel, como el kernel gaussiano (tambi&amp;eacute;n conocido como RBF) del euclidiano distanciado &lt;code&gt;d(X, X)&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="5c5941b79e3bd733fe2a806a66f459a87c19af32" translate="yes" xml:space="preserve">
          <source>When dealing with a cleaned dataset, the preprocessing can be automatic by using the data types of the column to decide whether to treat a column as a numerical or categorical feature. &lt;a href=&quot;../../modules/generated/sklearn.compose.make_column_selector#sklearn.compose.make_column_selector&quot;&gt;&lt;code&gt;sklearn.compose.make_column_selector&lt;/code&gt;&lt;/a&gt; gives this possibility. First, let&amp;rsquo;s only select a subset of columns to simplify our example.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da9c4333516559f145c3dcae1d1fd9f5e0da891d" translate="yes" xml:space="preserve">
          <source>When doing classification in scikit-learn, &lt;code&gt;y&lt;/code&gt; is a vector of integers or strings.</source>
          <target state="translated">Al hacer clasificaci&amp;oacute;n en scikit-learn, &lt;code&gt;y&lt;/code&gt; es un vector de enteros o cadenas.</target>
        </trans-unit>
        <trans-unit id="fb08dbb1ad477236e66b72b0cef9bccfd1ceec61" translate="yes" xml:space="preserve">
          <source>When doing supervised learning, a simple sanity check consists of comparing one&amp;rsquo;s estimator against simple rules of thumb. &lt;a href=&quot;generated/sklearn.dummy.dummyclassifier#sklearn.dummy.DummyClassifier&quot;&gt;&lt;code&gt;DummyClassifier&lt;/code&gt;&lt;/a&gt; implements several such simple strategies for classification:</source>
          <target state="translated">Al realizar el aprendizaje supervisado, una simple verificaci&amp;oacute;n de cordura consiste en comparar el estimador de uno con reglas simples. &lt;a href=&quot;generated/sklearn.dummy.dummyclassifier#sklearn.dummy.DummyClassifier&quot;&gt; &lt;code&gt;DummyClassifier&lt;/code&gt; &lt;/a&gt; implementa varias estrategias simples de clasificaci&amp;oacute;n:</target>
        </trans-unit>
        <trans-unit id="3bf9748662d1dbe365a15ba24b002d016f11408b" translate="yes" xml:space="preserve">
          <source>When evaluating different settings (&amp;ldquo;hyperparameters&amp;rdquo;) for estimators, such as the &lt;code&gt;C&lt;/code&gt; setting that must be manually set for an SVM, there is still a risk of overfitting &lt;em&gt;on the test set&lt;/em&gt; because the parameters can be tweaked until the estimator performs optimally. This way, knowledge about the test set can &amp;ldquo;leak&amp;rdquo; into the model and evaluation metrics no longer report on generalization performance. To solve this problem, yet another part of the dataset can be held out as a so-called &amp;ldquo;validation set&amp;rdquo;: training proceeds on the training set, after which evaluation is done on the validation set, and when the experiment seems to be successful, final evaluation can be done on the test set.</source>
          <target state="translated">Al evaluar diferentes configuraciones (&quot;hiperpar&amp;aacute;metros&quot;) para estimadores, como la configuraci&amp;oacute;n &lt;code&gt;C&lt;/code&gt; que debe configurarse manualmente para un SVM, todav&amp;iacute;a existe el riesgo de sobreajuste &lt;em&gt;en el conjunto de prueba&lt;/em&gt; porque los par&amp;aacute;metros se pueden ajustar hasta que el estimador funcione de manera &amp;oacute;ptima. De esta forma, el conocimiento sobre el conjunto de pruebas puede &quot;filtrarse&quot; en el modelo y las m&amp;eacute;tricas de evaluaci&amp;oacute;n ya no informan sobre el rendimiento de la generalizaci&amp;oacute;n. Para resolver este problema, se puede presentar otra parte del conjunto de datos como un &quot;conjunto de validaci&amp;oacute;n&quot;: el entrenamiento contin&amp;uacute;a en el conjunto de entrenamiento, despu&amp;eacute;s de lo cual se realiza la evaluaci&amp;oacute;n en el conjunto de validaci&amp;oacute;n y cuando el experimento parece ser exitoso. , la evaluaci&amp;oacute;n final se puede realizar en el equipo de prueba.</target>
        </trans-unit>
        <trans-unit id="b6d52e3adfb55f9048c5ef57545d77d640ae7db4" translate="yes" xml:space="preserve">
          <source>When evaluating text classifiers on the 20 Newsgroups data, you should strip newsgroup-related metadata. In scikit-learn, you can do this by setting &lt;code&gt;remove=('headers', 'footers', 'quotes')&lt;/code&gt;. The F-score will be lower because it is more realistic.</source>
          <target state="translated">Al evaluar clasificadores de texto en los datos de 20 grupos de noticias, debe eliminar los metadatos relacionados con los grupos de noticias. En scikit-learn, puede hacer esto configurando &lt;code&gt;remove=('headers', 'footers', 'quotes')&lt;/code&gt; . La puntuaci&amp;oacute;n F ser&amp;aacute; menor porque es m&amp;aacute;s realista.</target>
        </trans-unit>
        <trans-unit id="b44ace677df67ec762b5f7d213266d4181953b1c" translate="yes" xml:space="preserve">
          <source>When evaluating the resulting model it is important to do it on held-out samples that were not seen during the grid search process: it is recommended to split the data into a &lt;strong&gt;development set&lt;/strong&gt; (to be fed to the &lt;code&gt;GridSearchCV&lt;/code&gt; instance) and an &lt;strong&gt;evaluation set&lt;/strong&gt; to compute performance metrics.</source>
          <target state="translated">Al evaluar el modelo resultante, es importante hacerlo en muestras retenidas que no se vieron durante el proceso de b&amp;uacute;squeda de la cuadr&amp;iacute;cula: se recomienda dividir los datos en un &lt;strong&gt;conjunto de desarrollo&lt;/strong&gt; (para alimentar a la instancia &lt;code&gt;GridSearchCV&lt;/code&gt; ) y un &lt;strong&gt;conjunto de evaluaci&amp;oacute;n&lt;/strong&gt; para calcular m&amp;eacute;tricas de rendimiento.</target>
        </trans-unit>
        <trans-unit id="1a86b5b9ee94c593acad1b7968fd00ab3b487df9" translate="yes" xml:space="preserve">
          <source>When feature values are strings, this transformer will do a binary one-hot (aka one-of-K) coding: one boolean-valued feature is constructed for each of the possible string values that the feature can take on. For instance, a feature &amp;ldquo;f&amp;rdquo; that can take on the values &amp;ldquo;ham&amp;rdquo; and &amp;ldquo;spam&amp;rdquo; will become two features in the output, one signifying &amp;ldquo;f=ham&amp;rdquo;, the other &amp;ldquo;f=spam&amp;rdquo;.</source>
          <target state="translated">Cuando los valores de caracter&amp;iacute;sticas son cadenas, este transformador realizar&amp;aacute; una codificaci&amp;oacute;n binaria one-hot (tambi&amp;eacute;n conocida como una de K): se construye una caracter&amp;iacute;stica con valor booleano para cada uno de los posibles valores de cadena que la caracter&amp;iacute;stica puede asumir. Por ejemplo, una caracter&amp;iacute;stica &quot;f&quot; que puede tomar los valores &quot;ham&quot; y &quot;spam&quot; se convertir&amp;aacute; en dos caracter&amp;iacute;sticas en la salida, una que significa &quot;f = ham&quot; y la otra &quot;f = spam&quot;.</target>
        </trans-unit>
        <trans-unit id="81d685e408d1bc940e50f235a77cb7283ea2909d" translate="yes" xml:space="preserve">
          <source>When features are collinear, permutating one feature will have little effect on the models performance because it can get the same information from a correlated feature. One way to handle multicollinear features is by performing hierarchical clustering on the Spearman rank-order correlations, picking a threshold, and keeping a single feature from each cluster. First, we plot a heatmap of the correlated features:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3d8c3576d6baaf6f77dc4e34223e91a48a8c662" translate="yes" xml:space="preserve">
          <source>When fitting a model to a matrix X_train and evaluating it against a matrix X_test, it is essential that X_train and X_test have the same number of features (X_train.shape[1] == X_test.shape[1]). This may not be the case if you load the files individually with load_svmlight_file.</source>
          <target state="translated">Cuando se ajusta un modelo a una matriz X_train y se evalúa contra una matriz X_test,es esencial que X_train y X_test tengan el mismo número de características (X_train.shape[1]==X_test.shape[1]).Esto puede no ser el caso si se cargan los archivos individualmente con load_svmlight_file.</target>
        </trans-unit>
        <trans-unit id="618912ddd6add9bc398f8cf8343e255bb5f0ac59" translate="yes" xml:space="preserve">
          <source>When in doubt, use &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;</source>
          <target state="translated">En caso de duda, utilice &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="4150d19b2bd7fadd0941f6ca06455157d317e492" translate="yes" xml:space="preserve">
          <source>When in doubt, use &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ebc317e66e94c9c3ce7d1b975021eefa97b880b" translate="yes" xml:space="preserve">
          <source>When individual estimators are fast to train or predict using &lt;code&gt;n_jobs&amp;gt;1&lt;/code&gt; can result in slower performance due to the overhead of spawning processes.</source>
          <target state="translated">Cuando los estimadores individuales son r&amp;aacute;pidos para entrenar o predecir usando &lt;code&gt;n_jobs&amp;gt;1&lt;/code&gt; puede resultar en un desempe&amp;ntilde;o m&amp;aacute;s lento debido a la sobrecarga de los procesos de generaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="5223d409a8ec7650bd8559a52e22ddb32a950ada" translate="yes" xml:space="preserve">
          <source>When loss=&amp;rdquo;modified_huber&amp;rdquo;, probability estimates may be hard zeros and ones, so taking the logarithm is not possible.</source>
          <target state="translated">Cuando loss = &amp;rdquo;modified_huber&amp;rdquo;, las estimaciones de probabilidad pueden ser ceros y unos, por lo que no es posible tomar el logaritmo.</target>
        </trans-unit>
        <trans-unit id="3169e6d4a043a16249e2b124b1d248f9aac1b1e2" translate="yes" xml:space="preserve">
          <source>When modeling text corpora, the model assumes the following generative process for a corpus with \(D\) documents and \(K\) topics, with \(K\) corresponding to &lt;code&gt;n_components&lt;/code&gt; in the API:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63fb46936ec9f0c71e69b897d1f9d91941d422e3" translate="yes" xml:space="preserve">
          <source>When modeling text corpora, the model assumes the following generative process for a corpus with \(D\) documents and \(K\) topics:</source>
          <target state="translated">Cuando se modelan corpúsculos de texto,el modelo asume el siguiente proceso generativo para un corpúsculo con documentos y temas:</target>
        </trans-unit>
        <trans-unit id="744347c999c68da3080dd50ae1b985e4b97e385e" translate="yes" xml:space="preserve">
          <source>When one has insufficiently many points per mixture, estimating the covariance matrices becomes difficult, and the algorithm is known to diverge and find solutions with infinite likelihood unless one regularizes the covariances artificially.</source>
          <target state="translated">Cuando no se tienen suficientes puntos por mezcla,la estimación de las matrices de covarianza se hace difícil,y se sabe que el algoritmo difiere y encuentra soluciones con una probabilidad infinita,a menos que se regularicen las covarianzas artificialmente.</target>
        </trans-unit>
        <trans-unit id="e24f09e860711fd3a63a21415134601f90e4efc0" translate="yes" xml:space="preserve">
          <source>When parametrized by error using the parameter &lt;code&gt;tol&lt;/code&gt;: argmin ||gamma||_0 subject to ||y - Xgamma||^2 &amp;lt;= tol</source>
          <target state="translated">Cuando se parametriza por error usando el par&amp;aacute;metro &lt;code&gt;tol&lt;/code&gt; : argmin || gamma || _0 sujeto a || y - Xgamma || ^ 2 &amp;lt;= tol</target>
        </trans-unit>
        <trans-unit id="70b3334d846e26366c45a04fb1a4a39af8e3ec45" translate="yes" xml:space="preserve">
          <source>When parametrized by the number of non-zero coefficients using &lt;code&gt;n_nonzero_coefs&lt;/code&gt;: argmin ||y - Xgamma||^2 subject to ||gamma||_0 &amp;lt;= n_{nonzero coefs}</source>
          <target state="translated">Cuando se parametriza por el n&amp;uacute;mero de coeficientes distintos de cero usando &lt;code&gt;n_nonzero_coefs&lt;/code&gt; : argmin || y - Xgamma || ^ 2 sujeto a || gamma || _0 &amp;lt;= n_ {coefs distintos de cero}</target>
        </trans-unit>
        <trans-unit id="10d326cee514d3b967129b254954126bcda90793" translate="yes" xml:space="preserve">
          <source>When performing classification one often wants to predict not only the class label, but also the associated probability. This probability gives some kind of confidence on the prediction. This example demonstrates how to display how well calibrated the predicted probabilities are and how to calibrate an uncalibrated classifier.</source>
          <target state="translated">Al realizar la clasificación,a menudo se quiere predecir no sólo la etiqueta de la clase,sino también la probabilidad asociada.Esta probabilidad da algún tipo de confianza en la predicción.Este ejemplo demuestra cómo mostrar lo bien calibradas que están las probabilidades predichas y cómo calibrar un clasificador no calibrado.</target>
        </trans-unit>
        <trans-unit id="533cc79868c5585705042f97bd64dbf9b1c6133f" translate="yes" xml:space="preserve">
          <source>When performing classification you often want not only to predict the class label, but also obtain a probability of the respective label. This probability gives you some kind of confidence on the prediction. Some models can give you poor estimates of the class probabilities and some even do not support probability prediction. The calibration module allows you to better calibrate the probabilities of a given model, or to add support for probability prediction.</source>
          <target state="translated">Cuando se realiza una clasificación,a menudo se quiere no sólo predecir la etiqueta de la clase,sino también obtener una probabilidad de la etiqueta respectiva.Esta probabilidad te da algún tipo de confianza en la predicción.Algunos modelos pueden darte estimaciones pobres de las probabilidades de la clase y algunos incluso no apoyan la predicción de la probabilidad.El módulo de calibración permite calibrar mejor las probabilidades de un modelo dado,o añadir soporte para la predicción de la probabilidad.</target>
        </trans-unit>
        <trans-unit id="ede14543224daf4bd7da97ebebdbcb4bdb8fe514" translate="yes" xml:space="preserve">
          <source>When performing classification you often want to predict not only the class label, but also the associated probability. This probability gives you some kind of confidence on the prediction. However, not all classifiers provide well-calibrated probabilities, some being over-confident while others being under-confident. Thus, a separate calibration of predicted probabilities is often desirable as a postprocessing. This example illustrates two different methods for this calibration and evaluates the quality of the returned probabilities using Brier&amp;rsquo;s score (see &lt;a href=&quot;https://en.wikipedia.org/wiki/Brier_score&quot;&gt;https://en.wikipedia.org/wiki/Brier_score&lt;/a&gt;).</source>
          <target state="translated">Al realizar la clasificaci&amp;oacute;n, a menudo desea predecir no solo la etiqueta de la clase, sino tambi&amp;eacute;n la probabilidad asociada. Esta probabilidad le da alg&amp;uacute;n tipo de confianza en la predicci&amp;oacute;n. Sin embargo, no todos los clasificadores proporcionan probabilidades bien calibradas, algunos tienen demasiada confianza mientras que otros tienen poca confianza. Por lo tanto, a menudo es deseable una calibraci&amp;oacute;n separada de las probabilidades predichas como posprocesamiento. Este ejemplo ilustra dos m&amp;eacute;todos diferentes para esta calibraci&amp;oacute;n y eval&amp;uacute;a la calidad de las probabilidades devueltas utilizando la puntuaci&amp;oacute;n de Brier (consulte &lt;a href=&quot;https://en.wikipedia.org/wiki/Brier_score&quot;&gt;https://en.wikipedia.org/wiki/Brier_score&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="47397daaf8d579706c38eeae4f614a41b7464779" translate="yes" xml:space="preserve">
          <source>When performing cross-validation for the &lt;code&gt;power&lt;/code&gt; parameter of &lt;code&gt;TweedieRegressor&lt;/code&gt;, it is advisable to specify an explicit &lt;code&gt;scoring&lt;/code&gt; function, because the default scorer &lt;a href=&quot;generated/sklearn.linear_model.tweedieregressor#sklearn.linear_model.TweedieRegressor.score&quot;&gt;&lt;code&gt;TweedieRegressor.score&lt;/code&gt;&lt;/a&gt; is a function of &lt;code&gt;power&lt;/code&gt; itself.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e99cb78745b2020137c83400ee3d8d22f37293c0" translate="yes" xml:space="preserve">
          <source>When pre-computing distances it is more numerically accurate to center the data first. If copy_x is True (default), then the original data is not modified, ensuring X is C-contiguous. If False, the original data is modified, and put back before the function returns, but small numerical differences may be introduced by subtracting and then adding the data mean, in this case it will also not ensure that data is C-contiguous which may cause a significant slowdown.</source>
          <target state="translated">Cuando se precomputan las distancias es más preciso numéricamente centrar los datos primero.Si copy_x es True (por defecto),entonces los datos originales no se modifican,asegurando que X es C-contiguo.Si es Falso,los datos originales se modifican,y se vuelven a colocar antes de que vuelva la función,pero se pueden introducir pequeñas diferencias numéricas restando y luego añadiendo la media de los datos,en este caso tampoco se asegurará que los datos sean C-contiguos,lo que puede causar una ralentización significativa.</target>
        </trans-unit>
        <trans-unit id="785dafae54d31c04c4a974bc00da768d9cfae46f" translate="yes" xml:space="preserve">
          <source>When pre-computing distances it is more numerically accurate to center the data first. If copy_x is True (default), then the original data is not modified. If False, the original data is modified, and put back before the function returns, but small numerical differences may be introduced by subtracting and then adding the data mean. Note that if the original data is not C-contiguous, a copy will be made even if copy_x is False. If the original data is sparse, but not in CSR format, a copy will be made even if copy_x is False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55ac178846c6596090a6f8d0133ba62fcd26aebb" translate="yes" xml:space="preserve">
          <source>When predicting, the true labels will not be available. Instead the predictions of each model are passed on to the subsequent models in the chain to be used as features.</source>
          <target state="translated">Al predecir,las etiquetas verdaderas no estarán disponibles.En su lugar,las predicciones de cada modelo se transmiten a los modelos posteriores de la cadena para ser utilizadas como características.</target>
        </trans-unit>
        <trans-unit id="441463f4c28b96b4ca0739417ce251a6d1637336" translate="yes" xml:space="preserve">
          <source>When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces &lt;a href=&quot;#h1998&quot; id=&quot;id3&quot;&gt;[H1998]&lt;/a&gt;.</source>
          <target state="translated">Cuando se extraen subconjuntos aleatorios del conjunto de datos como subconjuntos aleatorios de las caracter&amp;iacute;sticas, el m&amp;eacute;todo se conoce como subespacios aleatorios &lt;a href=&quot;#h1998&quot; id=&quot;id3&quot;&gt;[H1998]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="ed3a388f4c5d9809937b1b2fceecd5d5d41437fc" translate="yes" xml:space="preserve">
          <source>When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting &lt;a href=&quot;#b1999&quot; id=&quot;id1&quot;&gt;[B1999]&lt;/a&gt;.</source>
          <target state="translated">Cuando se extraen subconjuntos aleatorios del conjunto de datos como subconjuntos aleatorios de las muestras, este algoritmo se conoce como &lt;a href=&quot;#b1999&quot; id=&quot;id1&quot;&gt;Pegado [B1999]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="f494cf947867cf3181ff2c5eaa996adc8d0ce783" translate="yes" xml:space="preserve">
          <source>When requesting a dataset with a name that is in mock_datasets, this object creates a fake dataset in a StringIO object and returns it. Otherwise, it raises an HTTPError.</source>
          <target state="translated">Cuando se solicita un conjunto de datos con un nombre que está en mock_datasets,este objeto crea un falso conjunto de datos en un objeto StringIO y lo devuelve.De lo contrario,genera un error HTTPE.</target>
        </trans-unit>
        <trans-unit id="f6f6725ccb736a3cf59a107563029dd1f92b7eb9" translate="yes" xml:space="preserve">
          <source>When sample_weight is provided, the selected hyperparameter may depend on whether we use generalized cross-validation (cv=None or cv=&amp;rsquo;auto&amp;rsquo;) or another form of cross-validation, because only generalized cross-validation takes the sample weights into account when computing the validation score.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d66c9681351cfa02a7cc3145d8e8cc7e7a3877b3" translate="yes" xml:space="preserve">
          <source>When samples are drawn with replacement, then the method is known as Bagging &lt;a href=&quot;#b1996&quot; id=&quot;id2&quot;&gt;[B1996]&lt;/a&gt;.</source>
          <target state="translated">Cuando se extraen muestras con reemplazo, el m&amp;eacute;todo se conoce como ensacado &lt;a href=&quot;#b1996&quot; id=&quot;id2&quot;&gt;[B1996]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="b67d588266cee585b7c0608db5b116728771921f" translate="yes" xml:space="preserve">
          <source>When self.fit_intercept is True, instance vector x becomes &lt;code&gt;[x, self.intercept_scaling]&lt;/code&gt;, i.e. a &amp;ldquo;synthetic&amp;rdquo; feature with constant value equals to intercept_scaling is appended to the instance vector. The intercept becomes intercept_scaling * synthetic feature weight Note! the synthetic feature weight is subject to l1/l2 regularization as all other features. To lessen the effect of regularization on synthetic feature weight (and therefore on the intercept) intercept_scaling has to be increased.</source>
          <target state="translated">Cuando self.fit_intercept es True, el vector de instancia x se convierte en &lt;code&gt;[x, self.intercept_scaling]&lt;/code&gt; , es decir, una caracter&amp;iacute;stica &quot;sint&amp;eacute;tica&quot; con un valor constante igual a intercept_scaling se agrega al vector de instancia. La intersecci&amp;oacute;n se convierte en intercept_scaling * peso de caracter&amp;iacute;stica sint&amp;eacute;tica &amp;iexcl;Nota! el peso de la caracter&amp;iacute;stica sint&amp;eacute;tica est&amp;aacute; sujeto a la regularizaci&amp;oacute;n l1 / l2 como todas las dem&amp;aacute;s caracter&amp;iacute;sticas. Para disminuir el efecto de la regularizaci&amp;oacute;n en el peso de la caracter&amp;iacute;stica sint&amp;eacute;tica (y por lo tanto en la intersecci&amp;oacute;n), se debe aumentar la escala de intercepci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="339fba0d20ce2052ad9daa9e3c6cc55589d832bc" translate="yes" xml:space="preserve">
          <source>When self.fit_intercept is True, instance vector x becomes [x, self.intercept_scaling], i.e. a &amp;ldquo;synthetic&amp;rdquo; feature with constant value equals to intercept_scaling is appended to the instance vector. The intercept becomes intercept_scaling * synthetic feature weight Note! the synthetic feature weight is subject to l1/l2 regularization as all other features. To lessen the effect of regularization on synthetic feature weight (and therefore on the intercept) intercept_scaling has to be increased.</source>
          <target state="translated">Cuando self.fit_intercept es True, el vector de instancia x se convierte en [x, self.intercept_scaling], es decir, una caracter&amp;iacute;stica &quot;sint&amp;eacute;tica&quot; con un valor constante igual a intercept_scaling se agrega al vector de instancia. La intersecci&amp;oacute;n se convierte en intercept_scaling * peso de caracter&amp;iacute;stica sint&amp;eacute;tica &amp;iexcl;Nota! el peso de la caracter&amp;iacute;stica sint&amp;eacute;tica est&amp;aacute; sujeto a la regularizaci&amp;oacute;n l1 / l2 como todas las dem&amp;aacute;s caracter&amp;iacute;sticas. Para disminuir el efecto de la regularizaci&amp;oacute;n en el peso de la caracter&amp;iacute;stica sint&amp;eacute;tica (y por lo tanto en la intersecci&amp;oacute;n), se debe aumentar la escala de intercepci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="ad06c0ce7c1fc91387cf888768a953ddfc43c4b6" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;False&lt;/code&gt;, ignore special characters for PostScript compatibility.</source>
          <target state="translated">Cuando se establece en &lt;code&gt;False&lt;/code&gt; , ignore los caracteres especiales para compatibilidad con PostScript.</target>
        </trans-unit>
        <trans-unit id="d1b93df55570608a785000a0ebdde0c1a478b680" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, change the display of &amp;lsquo;values&amp;rsquo; and/or &amp;lsquo;samples&amp;rsquo; to be proportions and percentages respectively.</source>
          <target state="translated">Cuando se establece en &lt;code&gt;True&lt;/code&gt; , cambia la visualizaci&amp;oacute;n de 'valores' y / o 'muestras' para que sean proporciones y porcentajes respectivamente.</target>
        </trans-unit>
        <trans-unit id="3843d20a53a1ef3b59460be1fa7cb77d3c2ee1f6" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, draw all leaf nodes at the bottom of the tree.</source>
          <target state="translated">Cuando se establece en &lt;code&gt;True&lt;/code&gt; , dibuja todos los nodos de hojas en la parte inferior del &amp;aacute;rbol.</target>
        </trans-unit>
        <trans-unit id="1dd8441b2d9ea649f69d55eb070005c43dff3ea1" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, draw node boxes with rounded corners and use Helvetica fonts instead of Times-Roman.</source>
          <target state="translated">Cuando se establece en &lt;code&gt;True&lt;/code&gt; , dibuja cuadros de nodo con esquinas redondeadas y usa fuentes Helvetica en lugar de Times-Roman.</target>
        </trans-unit>
        <trans-unit id="37e5e7c90dcc2881b20280bd58a636a2601aa0c6" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, forces the coefficients to be positive.</source>
          <target state="translated">Cuando se establece en &lt;code&gt;True&lt;/code&gt; , fuerza a los coeficientes a ser positivos.</target>
        </trans-unit>
        <trans-unit id="a556178389cf10e9a8f97ab94b5cbc137168d877" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, orient tree left to right rather than top-down.</source>
          <target state="translated">Cuando se establece en &lt;code&gt;True&lt;/code&gt; , oriente el &amp;aacute;rbol de izquierda a derecha en lugar de de arriba hacia abajo.</target>
        </trans-unit>
        <trans-unit id="db2d0a81092e78238cdb916143e482a964d5a789" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, paint nodes to indicate majority class for classification, extremity of values for regression, or purity of node for multi-output.</source>
          <target state="translated">Cuando se establece en &lt;code&gt;True&lt;/code&gt; , pinta los nodos para indicar la clase mayoritaria para la clasificaci&amp;oacute;n, la extremidad de los valores para la regresi&amp;oacute;n o la pureza del nodo para la salida m&amp;uacute;ltiple.</target>
        </trans-unit>
        <trans-unit id="387704ecb7f5fc4e8c941c08ae18f72e58104663" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just erase the previous solution. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Cuando se establece en &lt;code&gt;True&lt;/code&gt; , reutiliza la soluci&amp;oacute;n de la llamada anterior para ajustar y agregar m&amp;aacute;s estimadores al conjunto; de lo contrario, simplemente borra la soluci&amp;oacute;n anterior. Consulte &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;el glosario&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="42b61336d9e93453cd22782ddee266aae253af56" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just erase the previous solution. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e08becb1d7f3dabb059c61e3163efbfc5e9d6bd5" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Cuando se establece en &lt;code&gt;True&lt;/code&gt; , reutilice la soluci&amp;oacute;n de la llamada anterior para ajustar y agregar m&amp;aacute;s estimadores al conjunto; de lo contrario, simplemente ajuste un bosque completamente nuevo. Consulte &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;el glosario&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="4ca94f8cc22fb05a614eaf938146928a9cad01e1" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b034ef6cd843a9c71bbf2f16594203b3e34675bd" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble. For results to be valid, the estimator should be re-trained on the same data only. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ddb18c96e1fca0312edb00f224f2db160c80a30" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Cuando se establece en &lt;code&gt;True&lt;/code&gt; , reutiliza la soluci&amp;oacute;n de la llamada anterior para que encaje como inicializaci&amp;oacute;n; de lo contrario, simplemente borra la soluci&amp;oacute;n anterior. Consulte &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;el glosario&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="06f93e3e87621fa903e7cdd20131cea02e9878ba" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="303e5cc9af6656c2592224b864d50a2e7f014b54" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, show the ID number on each node.</source>
          <target state="translated">Cuando se establece en &lt;code&gt;True&lt;/code&gt; , muestra el n&amp;uacute;mero de identificaci&amp;oacute;n en cada nodo.</target>
        </trans-unit>
        <trans-unit id="d19057d05dc608969ed0862b9054b2defc3fb482" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, show the impurity at each node.</source>
          <target state="translated">Cuando se establece en &lt;code&gt;True&lt;/code&gt; , muestra la impureza en cada nodo.</target>
        </trans-unit>
        <trans-unit id="ee8efaddcdb7929ada76230c032dd700897cd47f" translate="yes" xml:space="preserve">
          <source>When set to True, computes the averaged SGD weights accross all updates and stores the result in the &lt;code&gt;coef_&lt;/code&gt; attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches &lt;code&gt;average&lt;/code&gt;. So &lt;code&gt;average=10&lt;/code&gt; will begin averaging after seeing 10 samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0199409f1eeb1aa7581c717d5c23e182af166761" translate="yes" xml:space="preserve">
          <source>When set to True, computes the averaged SGD weights and stores the result in the &lt;code&gt;coef_&lt;/code&gt; attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches average. So &lt;code&gt;average=10&lt;/code&gt; will begin averaging after seeing 10 samples.</source>
          <target state="translated">Cuando se establece en Verdadero, calcula los pesos SGD promediados y almacena el resultado en el atributo &lt;code&gt;coef_&lt;/code&gt; . Si se establece en un int mayor que 1, el promedio comenzar&amp;aacute; una vez que el n&amp;uacute;mero total de muestras vistas alcance el promedio. Entonces, &lt;code&gt;average=10&lt;/code&gt; comenzar&amp;aacute; a promediar despu&amp;eacute;s de ver 10 muestras.</target>
        </trans-unit>
        <trans-unit id="19c4ca669b90d48df2f3aa161b89103ea08c0cbd" translate="yes" xml:space="preserve">
          <source>When set to True, computes the averaged SGD weights and stores the result in the &lt;code&gt;coef_&lt;/code&gt; attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches average. So average=10 will begin averaging after seeing 10 samples.</source>
          <target state="translated">Cuando se establece en Verdadero, calcula los pesos SGD promediados y almacena el resultado en el atributo &lt;code&gt;coef_&lt;/code&gt; . Si se establece en un int mayor que 1, el promedio comenzar&amp;aacute; una vez que el n&amp;uacute;mero total de muestras vistas alcance el promedio. Entonces, average = 10 comenzar&amp;aacute; a promediar despu&amp;eacute;s de ver 10 muestras.</target>
        </trans-unit>
        <trans-unit id="e60b70114bd43f63c876204c608aaaaca2e5c6d2" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new ensemble. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Cuando se establece en True, reutilice la soluci&amp;oacute;n de la llamada anterior para ajustar y agregar m&amp;aacute;s estimadores al conjunto; de lo contrario, simplemente ajuste un conjunto completamente nuevo. Consulte &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;el glosario&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="fb1187119affc46cd36d1e1403f76ef562249b84" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new ensemble. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0615ecfccfe9c12eea86adfdd92570d0b3a6f9cf" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Cuando se establece en True, reutiliza la soluci&amp;oacute;n de la llamada anterior para que encaje como inicializaci&amp;oacute;n; de lo contrario, simplemente borra la soluci&amp;oacute;n anterior. Consulte &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;el glosario&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="b9ddbc0f60da434a4d403c500c89b585a3aeef7d" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="869683b3c71be56286e995de01f21c989fc735d8" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. Useless for liblinear solver. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Cuando se establece en True, reutiliza la soluci&amp;oacute;n de la llamada anterior para que encaje como inicializaci&amp;oacute;n; de lo contrario, simplemente borra la soluci&amp;oacute;n anterior. In&amp;uacute;til para liblinear solver. Consulte &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;el glosario&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="90df9a75b07a1010dc74b460f30a26d769910e81" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. Useless for liblinear solver. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61362ce0a02977970071e88e9dc71d066251fcde" translate="yes" xml:space="preserve">
          <source>When specifying multiple metrics, the &lt;code&gt;refit&lt;/code&gt; parameter must be set to the metric (string) for which the &lt;code&gt;best_params_&lt;/code&gt; will be found and used to build the &lt;code&gt;best_estimator_&lt;/code&gt; on the whole dataset. If the search should not be refit, set &lt;code&gt;refit=False&lt;/code&gt;. Leaving refit to the default value &lt;code&gt;None&lt;/code&gt; will result in an error when using multiple metrics.</source>
          <target state="translated">Cuando se especifican varias m&amp;eacute;tricas, el par&amp;aacute;metro de &lt;code&gt;refit&lt;/code&gt; debe establecerse en la m&amp;eacute;trica (cadena) para la cual se encontrar&amp;aacute;n los &lt;code&gt;best_params_&lt;/code&gt; y se usar&amp;aacute;n para construir el &lt;code&gt;best_estimator_&lt;/code&gt; en todo el conjunto de datos. Si la b&amp;uacute;squeda no debe reajustarse, configure &lt;code&gt;refit=False&lt;/code&gt; . Si deja el reajuste en el valor predeterminado &lt;code&gt;None&lt;/code&gt; se producir&amp;aacute; un error al utilizar varias m&amp;eacute;tricas.</target>
        </trans-unit>
        <trans-unit id="8303fa1cd1689a65bba6fc9b59c3502d4f370e6f" translate="yes" xml:space="preserve">
          <source>When starting from the default values (alpha_init = 1.90, lambda_init = 1.), the bias of the resulting curve is large, and the variance is small. So, lambda_init should be relatively small (1.e-3) so as to reduce the bias.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="765386eefc1dd2e9ed203024ee007c99e07f6618" translate="yes" xml:space="preserve">
          <source>When strategy == &amp;ldquo;constant&amp;rdquo;, fill_value is used to replace all occurrences of missing_values. If left to the default, fill_value will be 0 when imputing numerical data and &amp;ldquo;missing_value&amp;rdquo; for strings or object data types.</source>
          <target state="translated">Cuando la estrategia == &amp;ldquo;constante&amp;rdquo;, fill_value se usa para reemplazar todas las apariciones de missing_values. Si se deja en el valor predeterminado, fill_value ser&amp;aacute; 0 cuando se imputen datos num&amp;eacute;ricos y &quot;missing_value&quot; para cadenas o tipos de datos de objeto.</target>
        </trans-unit>
        <trans-unit id="234c27f3e17ce7a8cf496679483a69e65bcabb05" translate="yes" xml:space="preserve">
          <source>When the &lt;code&gt;Pipeline&lt;/code&gt; is printed out in a jupyter notebook an HTML representation of the estimator is displayed as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3973bbeeefced2bd7eb8aaa05fcc0fadc5e600b" translate="yes" xml:space="preserve">
          <source>When the &lt;code&gt;cv&lt;/code&gt; argument is an integer, &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;cross_val_score&lt;/code&gt;&lt;/a&gt; uses the &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; strategies by default, the latter being used if the estimator derives from &lt;a href=&quot;generated/sklearn.base.classifiermixin#sklearn.base.ClassifierMixin&quot;&gt;&lt;code&gt;ClassifierMixin&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Cuando el argumento &lt;code&gt;cv&lt;/code&gt; es un n&amp;uacute;mero entero, &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt; &lt;code&gt;cross_val_score&lt;/code&gt; &lt;/a&gt; usa las estrategias &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt; o &lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;StratifiedKFold&lt;/code&gt; &lt;/a&gt; por defecto, esta &amp;uacute;ltima se usa si el estimador se deriva de &lt;a href=&quot;generated/sklearn.base.classifiermixin#sklearn.base.ClassifierMixin&quot;&gt; &lt;code&gt;ClassifierMixin&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="c7d238875ff93bafa2620f7a2d7675b937a2183b" translate="yes" xml:space="preserve">
          <source>When the algorithm does not converge, it returns an empty array as &lt;code&gt;cluster_center_indices&lt;/code&gt; and &lt;code&gt;-1&lt;/code&gt; as label for each training sample.</source>
          <target state="translated">Cuando el algoritmo no converge, devuelve una matriz vac&amp;iacute;a como &lt;code&gt;cluster_center_indices&lt;/code&gt; y &lt;code&gt;-1&lt;/code&gt; como etiqueta para cada muestra de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="b4fdfb364ee084bf57bd04a0f7c8f0c41739edf4" translate="yes" xml:space="preserve">
          <source>When the data is not initially in the &lt;code&gt;(n_samples, n_features)&lt;/code&gt; shape, it needs to be preprocessed in order to be used by scikit-learn.</source>
          <target state="translated">Cuando los datos no tienen inicialmente la forma &lt;code&gt;(n_samples, n_features)&lt;/code&gt; , es necesario preprocesarlos para que scikit-learn pueda utilizarlos.</target>
        </trans-unit>
        <trans-unit id="4b1639b675f158aa2d42c71150242e159f59e266" translate="yes" xml:space="preserve">
          <source>When the missingness pattern is predictive, the splits can be done on whether the feature value is missing or not:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90e4401cde0f238342524a25385b7071cd57b4a0" translate="yes" xml:space="preserve">
          <source>When the underlying implementation uses joblib, the number of workers (threads or processes) that are spawned in parallel can be controlled via the &lt;code&gt;n_jobs&lt;/code&gt; parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aaeec02a52e8579f06c37808c9e18fa50d637a08" translate="yes" xml:space="preserve">
          <source>When there are more than two labels, the value of the MCC will no longer range between -1 and +1. Instead the minimum value will be somewhere between -1 and 0 depending on the number and distribution of ground true labels. The maximum value is always +1.</source>
          <target state="translated">Cuando haya más de dos etiquetas,el valor del MCC ya no oscilará entre -1 y +1.En su lugar,el valor mínimo estará entre -1 y 0 dependiendo del número y distribución de las etiquetas de tierra verdadera.El valor máximo es siempre +1.</target>
        </trans-unit>
        <trans-unit id="5c69ffd1e0dc71befa67c00726bc6370582b5df5" translate="yes" xml:space="preserve">
          <source>When there is no correlation between the outputs, a very simple way to solve this kind of problem is to build n independent models, i.e. one for each output, and then to use those models to independently predict each one of the n outputs. However, because it is likely that the output values related to the same input are themselves correlated, an often better way is to build a single model capable of predicting simultaneously all n outputs. First, it requires lower training time since only a single estimator is built. Second, the generalization accuracy of the resulting estimator may often be increased.</source>
          <target state="translated">Cuando no existe una correlación entre los resultados,una forma muy sencilla de resolver este tipo de problemas es construir n modelos independientes,es decir,uno para cada resultado,y luego utilizar esos modelos para predecir independientemente cada uno de los n resultados.Sin embargo,como es probable que los valores de salida relacionados con la misma entrada estén en sí mismos correlacionados,una forma a menudo mejor es construir un único modelo capaz de predecir simultáneamente todas las n salidas.En primer lugar,requiere un menor tiempo de capacitación,ya que sólo se construye un único estimador.En segundo lugar,la precisión de la generalización del estimador resultante puede a menudo aumentar.</target>
        </trans-unit>
        <trans-unit id="ebcc7b732996f47559f9fb2cca7527f873584d5f" translate="yes" xml:space="preserve">
          <source>When this environment variable is set to a non zero value, scikit-learn uses the site joblib rather than its vendored version. Consequently, joblib must be installed for scikit-learn to run. Note that using the site joblib is at your own risks: the versions of scikit-learn and joblib need to be compatible. Currently, joblib 0.11+ is supported. In addition, dumps from joblib.Memory might be incompatible, and you might loose some caches and have to redownload some datasets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c7fa59e2b8c1ce3abb542d1d5f76caddd1816f1" translate="yes" xml:space="preserve">
          <source>When this environment variable is set to a non zero value, scikit-learn uses the site joblib rather than its vendored version. Consequently, joblib must be installed for scikit-learn to run. Note that using the site joblib is at your own risks: the versions of scikt-learn and joblib need to be compatible. In addition, dumps from joblib.Memory might be incompatible, and you might loose some caches and have to redownload some datasets.</source>
          <target state="translated">Cuando esta variable de entorno se establece en un valor no cero,scikit-learn utiliza el sitio joblib en lugar de su versión vendida.En consecuencia,joblib debe ser instalado para que scikit-learn funcione.Tenga en cuenta que el uso del sitio joblib es bajo su propio riesgo:las versiones de scikt-learn y joblib deben ser compatibles.Además,los volcados de joblib.Memory podrían ser incompatibles,y podrías perder algunas cachés y tener que volver a descargar algunos conjuntos de datos.</target>
        </trans-unit>
        <trans-unit id="743d4762d28a3d61488ddf12d10bce762b152657" translate="yes" xml:space="preserve">
          <source>When this environment variable is set to a non zero value, the tests that need network access are skipped.</source>
          <target state="translated">Cuando esta variable de entorno se establece en un valor no cero,se saltan las pruebas que necesitan acceso a la red.</target>
        </trans-unit>
        <trans-unit id="beb3490e0a85d3bcf9f4888cb75a6b1ea2e1e6a8" translate="yes" xml:space="preserve">
          <source>When training an SVM with the &lt;em&gt;Radial Basis Function&lt;/em&gt; (RBF) kernel, two parameters must be considered: &lt;code&gt;C&lt;/code&gt; and &lt;code&gt;gamma&lt;/code&gt;. The parameter &lt;code&gt;C&lt;/code&gt;, common to all SVM kernels, trades off misclassification of training examples against simplicity of the decision surface. A low &lt;code&gt;C&lt;/code&gt; makes the decision surface smooth, while a high &lt;code&gt;C&lt;/code&gt; aims at classifying all training examples correctly. &lt;code&gt;gamma&lt;/code&gt; defines how much influence a single training example has. The larger &lt;code&gt;gamma&lt;/code&gt; is, the closer other examples must be to be affected.</source>
          <target state="translated">Al entrenar una SVM con el kernel de &lt;em&gt;funci&amp;oacute;n de base radial&lt;/em&gt; (RBF), se deben considerar dos par&amp;aacute;metros: &lt;code&gt;C&lt;/code&gt; y &lt;code&gt;gamma&lt;/code&gt; . El par&amp;aacute;metro &lt;code&gt;C&lt;/code&gt; , com&amp;uacute;n a todos los kernels de SVM, compensa la clasificaci&amp;oacute;n err&amp;oacute;nea de los ejemplos de entrenamiento con la simplicidad de la superficie de decisi&amp;oacute;n. Una &lt;code&gt;C&lt;/code&gt; baja suaviza la superficie de decisi&amp;oacute;n, mientras que una &lt;code&gt;C&lt;/code&gt; alta apunta a clasificar correctamente todos los ejemplos de entrenamiento. &lt;code&gt;gamma&lt;/code&gt; define cu&amp;aacute;nta influencia tiene un solo ejemplo de entrenamiento. Cuanto mayor sea la &lt;code&gt;gamma&lt;/code&gt; , m&amp;aacute;s cercanos deben estar otros ejemplos para verse afectados.</target>
        </trans-unit>
        <trans-unit id="4f5d7a3d8a7ab119798fbec5ead8471db219e63d" translate="yes" xml:space="preserve">
          <source>When true, the result is adjusted for chance, so that random performance would score 0, and perfect performance scores 1.</source>
          <target state="translated">Cuando es cierto,el resultado se ajusta al azar,de modo que la actuación aleatoria tendría una puntuación de 0,y la actuación perfecta una puntuación de 1.</target>
        </trans-unit>
        <trans-unit id="7dbd1175230450ef2444fe8de9e5557001f2473c" translate="yes" xml:space="preserve">
          <source>When truncated SVD is applied to term-document matrices (as returned by &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt;&lt;code&gt;TfidfVectorizer&lt;/code&gt;&lt;/a&gt;), this transformation is known as &lt;a href=&quot;https://nlp.stanford.edu/IR-book/pdf/18lsi.pdf&quot;&gt;latent semantic analysis&lt;/a&gt; (LSA), because it transforms such matrices to a &amp;ldquo;semantic&amp;rdquo; space of low dimensionality. In particular, LSA is known to combat the effects of synonymy and polysemy (both of which roughly mean there are multiple meanings per word), which cause term-document matrices to be overly sparse and exhibit poor similarity under measures such as cosine similarity.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a756308318fb23f07be0498c8c83a0d088f9279a" translate="yes" xml:space="preserve">
          <source>When truncated SVD is applied to term-document matrices (as returned by &lt;code&gt;CountVectorizer&lt;/code&gt; or &lt;code&gt;TfidfVectorizer&lt;/code&gt;), this transformation is known as &lt;a href=&quot;http://nlp.stanford.edu/IR-book/pdf/18lsi.pdf&quot;&gt;latent semantic analysis&lt;/a&gt; (LSA), because it transforms such matrices to a &amp;ldquo;semantic&amp;rdquo; space of low dimensionality. In particular, LSA is known to combat the effects of synonymy and polysemy (both of which roughly mean there are multiple meanings per word), which cause term-document matrices to be overly sparse and exhibit poor similarity under measures such as cosine similarity.</source>
          <target state="translated">Cuando se aplica SVD truncado a matrices de documentos de t&amp;eacute;rmino (como lo devuelve &lt;code&gt;CountVectorizer&lt;/code&gt; o &lt;code&gt;TfidfVectorizer&lt;/code&gt; ), esta transformaci&amp;oacute;n se conoce como &lt;a href=&quot;http://nlp.stanford.edu/IR-book/pdf/18lsi.pdf&quot;&gt;an&amp;aacute;lisis sem&amp;aacute;ntico latente&lt;/a&gt; (LSA), porque transforma dichas matrices en un espacio &quot;sem&amp;aacute;ntico&quot; de baja dimensionalidad. En particular, se sabe que LSA combate los efectos de la sinonimia y la polisemia (los cuales significan aproximadamente que hay m&amp;uacute;ltiples significados por palabra), que hacen que las matrices de documentos de t&amp;eacute;rminos sean demasiado escasas y exhiban una escasa similitud en medidas como la similitud de coseno.</target>
        </trans-unit>
        <trans-unit id="38dbd2ff8901fd68988a77a08c59409f80468575" translate="yes" xml:space="preserve">
          <source>When two features are correlated and one of the features is permuted, the model will still have access to the feature through its correlated feature. This will result in a lower importance value for both features, where they might &lt;em&gt;actually&lt;/em&gt; be important.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="726430099b436b4edbed2772b4e46aec59296fe0" translate="yes" xml:space="preserve">
          <source>When used for text classification with tf-idf vectors, this classifier is also known as the Rocchio classifier.</source>
          <target state="translated">Cuando se utiliza para la clasificación de textos con vectores tf-idf,este clasificador también se conoce como el clasificador Rocchio.</target>
        </trans-unit>
        <trans-unit id="b1373e66b4937bbac8defef2fa925bed61a8d596" translate="yes" xml:space="preserve">
          <source>When used to &lt;em&gt;transform&lt;/em&gt; data, PCA can reduce the dimensionality of the data by projecting on a principal subspace.</source>
          <target state="translated">Cuando se usa para &lt;em&gt;transformar&lt;/em&gt; datos, PCA puede reducir la dimensionalidad de los datos proyectando en un subespacio principal.</target>
        </trans-unit>
        <trans-unit id="93429c223efcd8d6622a4c8e5f0e71f13358e226" translate="yes" xml:space="preserve">
          <source>When using &lt;a href=&quot;../../modules/classes#module-sklearn.multiclass&quot;&gt;&lt;code&gt;multiclass classifiers&lt;/code&gt;&lt;/a&gt;, the learning and prediction task that is performed is dependent on the format of the target data fit upon:</source>
          <target state="translated">Cuando se utilizan &lt;a href=&quot;../../modules/classes#module-sklearn.multiclass&quot;&gt; &lt;code&gt;multiclass classifiers&lt;/code&gt; &lt;/a&gt; , la tarea de aprendizaje y predicci&amp;oacute;n que se realiza depende del formato de los datos de destino que se ajustan a:</target>
        </trans-unit>
        <trans-unit id="bf430655a414d830d0ddbbfedf78ab7c208919a9" translate="yes" xml:space="preserve">
          <source>When using Averaged SGD (with the &lt;code&gt;average&lt;/code&gt; parameter), &lt;code&gt;coef_&lt;/code&gt; is set to the average weight across all updates: &lt;code&gt;coef_&lt;/code&gt;\(= \frac{1}{T} \sum_{t=0}^{T-1} w^{(t)}\), where \(T\) is the total number of updates, found in the &lt;code&gt;t_&lt;/code&gt; attribute.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb56aa339cbb48c9a75d42d2c7bf7e7858b3170b" translate="yes" xml:space="preserve">
          <source>When using ensemble methods base upon bagging, i.e. generating new training sets using sampling with replacement, part of the training set remains unused. For each classifier in the ensemble, a different part of the training set is left out.</source>
          <target state="translated">Cuando se utilizan métodos de conjunto basados en el embolsamiento,es decir,la generación de nuevos conjuntos de entrenamiento utilizando el muestreo con reemplazo,parte del conjunto de entrenamiento permanece sin utilizar.Para cada clasificador del conjunto,una parte diferente del equipo de entrenamiento queda fuera.</target>
        </trans-unit>
        <trans-unit id="7a60d247990a32a468cae00d5ed7b0c825a81e35" translate="yes" xml:space="preserve">
          <source>When using the &lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt; in a &lt;code&gt;Pipeline&lt;/code&gt;, be sure to use the &lt;code&gt;FeatureUnion&lt;/code&gt; or &lt;code&gt;ColumnTransformer&lt;/code&gt; to add the indicator features to the regular features. First we obtain the &lt;code&gt;iris&lt;/code&gt; dataset, and add some missing values to it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9696826aefafecc5b32845bc270f3c2cabe6664" translate="yes" xml:space="preserve">
          <source>When using these images, please give credit to AT&amp;amp;T Laboratories Cambridge.</source>
          <target state="translated">Cuando utilice estas im&amp;aacute;genes, d&amp;eacute; cr&amp;eacute;dito a AT&amp;amp;T Laboratories Cambridge.</target>
        </trans-unit>
        <trans-unit id="5a6f9e7437ff7d6762455e24a46c4771dc2e0a37" translate="yes" xml:space="preserve">
          <source>When using, for example, &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;cross validation&lt;/a&gt;, to set the amount of regularization with &lt;code&gt;C&lt;/code&gt;, there will be a different amount of samples between the main problem and the smaller problems within the folds of the cross validation.</source>
          <target state="translated">Al utilizar, por ejemplo, &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;la validaci&amp;oacute;n cruzada&lt;/a&gt; , para establecer la cantidad de regularizaci&amp;oacute;n con &lt;code&gt;C&lt;/code&gt; , habr&amp;aacute; una cantidad diferente de muestras entre el problema principal y los problemas m&amp;aacute;s peque&amp;ntilde;os dentro de los pliegues de la validaci&amp;oacute;n cruzada.</target>
        </trans-unit>
        <trans-unit id="5dae0cb2a4d8c33bb8e68ee9ffd452db73e27eb2" translate="yes" xml:space="preserve">
          <source>When we apply clustering to the data, we find that the clustering reflects what was in the distance matrices. Indeed, for the Euclidean distance, the classes are ill-separated because of the noise, and thus the clustering does not separate the waveforms. For the cityblock distance, the separation is good and the waveform classes are recovered. Finally, the cosine distance does not separate at all waveform 1 and 2, thus the clustering puts them in the same cluster.</source>
          <target state="translated">Cuando aplicamos la agrupación a los datos,encontramos que la agrupación refleja lo que había en las matrices de distancia.De hecho,para la distancia euclidiana,las clases están mal separadas debido al ruido,y por lo tanto la agrupación no separa las formas de onda.Para la distancia de la manzana de la ciudad,la separación es buena y las clases de formas de onda se recuperan.Finalmente,la distancia coseno no separa en absoluto las formas de onda 1 y 2,por lo que la agrupación las pone en el mismo grupo.</target>
        </trans-unit>
        <trans-unit id="8975b7dd097c19a6af3c2b4b090f357f96aab52d" translate="yes" xml:space="preserve">
          <source>When working with covariance estimation, the usual approach is to use a maximum likelihood estimator, such as the &lt;a href=&quot;../../modules/generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;sklearn.covariance.EmpiricalCovariance&lt;/code&gt;&lt;/a&gt;. It is unbiased, i.e. it converges to the true (population) covariance when given many observations. However, it can also be beneficial to regularize it, in order to reduce its variance; this, in turn, introduces some bias. This example illustrates the simple regularization used in &lt;a href=&quot;../../modules/covariance#shrunk-covariance&quot;&gt;Shrunk Covariance&lt;/a&gt; estimators. In particular, it focuses on how to set the amount of regularization, i.e. how to choose the bias-variance trade-off.</source>
          <target state="translated">Cuando se trabaja con la estimaci&amp;oacute;n de covarianza, el enfoque habitual es utilizar un estimador de m&amp;aacute;xima verosimilitud, como &lt;a href=&quot;../../modules/generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt; &lt;code&gt;sklearn.covariance.EmpiricalCovariance&lt;/code&gt; &lt;/a&gt; . Es insesgado, es decir, converge a la covarianza (de la poblaci&amp;oacute;n) verdadera cuando se le dan muchas observaciones. Sin embargo, tambi&amp;eacute;n puede ser beneficioso regularizarlo para reducir su varianza; esto, a su vez, introduce cierto sesgo. Este ejemplo ilustra la regularizaci&amp;oacute;n simple utilizada en los estimadores de &lt;a href=&quot;../../modules/covariance#shrunk-covariance&quot;&gt;covarianza&lt;/a&gt; encogida. En particular, se centra en c&amp;oacute;mo establecer la cantidad de regularizaci&amp;oacute;n, es decir, c&amp;oacute;mo elegir la compensaci&amp;oacute;n entre sesgo y varianza.</target>
        </trans-unit>
        <trans-unit id="17b704aa73a46ef6f9edddecff620d33c0b705d7" translate="yes" xml:space="preserve">
          <source>When you want to apply different transformations to each field of the data, see the related class &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt;&lt;/a&gt; (see &lt;a href=&quot;#column-transformer&quot;&gt;user guide&lt;/a&gt;).</source>
          <target state="translated">Cuando desee aplicar diferentes transformaciones a cada campo de los datos, consulte la clase relacionada &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt; &lt;/a&gt; (consulte &lt;a href=&quot;#column-transformer&quot;&gt;la gu&amp;iacute;a del usuario&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="8d5450715de6c511faca4e5034a6c5d189b2299d" translate="yes" xml:space="preserve">
          <source>Where (and how) parallelization happens in the estimators is currently poorly documented. Please help us by improving our docs and tackle &lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/14228&quot;&gt;issue 14228&lt;/a&gt;!</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ffd889b6ef09600260c419603787a00c67ae551d" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;TP&lt;/code&gt; is the number of &lt;strong&gt;True Positive&lt;/strong&gt; (i.e. the number of pair of points that belong to the same clusters in both the true labels and the predicted labels), &lt;code&gt;FP&lt;/code&gt; is the number of &lt;strong&gt;False Positive&lt;/strong&gt; (i.e. the number of pair of points that belong to the same clusters in the true labels and not in the predicted labels) and &lt;code&gt;FN&lt;/code&gt; is the number of &lt;strong&gt;False Negative&lt;/strong&gt; (i.e the number of pair of points that belongs in the same clusters in the predicted labels and not in the true labels).</source>
          <target state="translated">Donde &lt;code&gt;TP&lt;/code&gt; es el n&amp;uacute;mero de &lt;strong&gt;Positivos Verdaderos&lt;/strong&gt; (es decir, el n&amp;uacute;mero de pares de puntos que pertenecen a los mismos grupos en las etiquetas verdaderas y las etiquetas predichas), &lt;code&gt;FP&lt;/code&gt; es el n&amp;uacute;mero de &lt;strong&gt;Positivos falsos&lt;/strong&gt; (es decir, el n&amp;uacute;mero de pares de puntos que pertenecen a los mismos grupos en las etiquetas verdaderas y no en las etiquetas predichas) y &lt;code&gt;FN&lt;/code&gt; es el n&amp;uacute;mero de &lt;strong&gt;Falso Negativo&lt;/strong&gt; (es decir, el n&amp;uacute;mero de pares de puntos que pertenecen a los mismos grupos en las etiquetas predichas y no en las etiquetas verdaderas).</target>
        </trans-unit>
        <trans-unit id="276f699fa82da6208d110c0a23b40d61550922dd" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;TP&lt;/code&gt; is the number of &lt;strong&gt;True Positive&lt;/strong&gt; (i.e. the number of pair of points that belongs in the same clusters in both &lt;code&gt;labels_true&lt;/code&gt; and &lt;code&gt;labels_pred&lt;/code&gt;), &lt;code&gt;FP&lt;/code&gt; is the number of &lt;strong&gt;False Positive&lt;/strong&gt; (i.e. the number of pair of points that belongs in the same clusters in &lt;code&gt;labels_true&lt;/code&gt; and not in &lt;code&gt;labels_pred&lt;/code&gt;) and &lt;code&gt;FN&lt;/code&gt; is the number of &lt;strong&gt;False Negative&lt;/strong&gt; (i.e the number of pair of points that belongs in the same clusters in &lt;code&gt;labels_pred&lt;/code&gt; and not in &lt;code&gt;labels_True&lt;/code&gt;).</source>
          <target state="translated">Donde &lt;code&gt;TP&lt;/code&gt; es el n&amp;uacute;mero de &lt;strong&gt;Positivos Verdaderos&lt;/strong&gt; (es decir, el n&amp;uacute;mero de pares de puntos que pertenecen a los mismos grupos en las &lt;code&gt;labels_true&lt;/code&gt; y en las &lt;code&gt;labels_pred&lt;/code&gt; ), &lt;code&gt;FP&lt;/code&gt; es el n&amp;uacute;mero de &lt;strong&gt;Positivos falsos&lt;/strong&gt; (es decir, el n&amp;uacute;mero de pares de puntos que pertenecen a los mismos grupos en &lt;code&gt;labels_true&lt;/code&gt; y no en &lt;code&gt;labels_pred&lt;/code&gt; ) y &lt;code&gt;FN&lt;/code&gt; es el n&amp;uacute;mero de &lt;strong&gt;Falso Negativo&lt;/strong&gt; (es decir, el n&amp;uacute;mero de pares de puntos que pertenecen a los mismos grupos en &lt;code&gt;labels_pred&lt;/code&gt; y no en &lt;code&gt;labels_True&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="e78195e2eb2711f3bb8a0d7f4e3c56eea492c48d" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;delta&lt;/code&gt; is a free parameter representing the width of the Gaussian kernel.</source>
          <target state="translated">Donde &lt;code&gt;delta&lt;/code&gt; es un par&amp;aacute;metro libre que representa el ancho del kernel gaussiano.</target>
        </trans-unit>
        <trans-unit id="6d88fb8179777bb060d39d8e880a1a6ec89efb59" translate="yes" xml:space="preserve">
          <source>Where C is the number of permutations whose score &amp;gt;= the true score.</source>
          <target state="translated">Donde C es el n&amp;uacute;mero de permutaciones cuya puntuaci&amp;oacute;n&amp;gt; = la puntuaci&amp;oacute;n verdadera.</target>
        </trans-unit>
        <trans-unit id="0426d1b8d26623c0079356962f68cf2595f6d67a" translate="yes" xml:space="preserve">
          <source>Where D is the matrix of distances for the input data X, D_fit is the matrix of distances for the output embedding X_fit, and K is the isomap kernel:</source>
          <target state="translated">Donde D es la matriz de distancias para los datos de entrada X,D_fit es la matriz de distancias para la incrustación de salida X_fit,y K es el núcleo del isomapa:</target>
        </trans-unit>
        <trans-unit id="77844a8258430d31f41a5c27fd5c3c817a4c46f5" translate="yes" xml:space="preserve">
          <source>Where \(C_2^{n_{samples}}\) is the total number of possible pairs in the dataset (without ordering).</source>
          <target state="translated">Donde \(C_2^{{n_{muestras}}\)es el número total de pares posibles en el conjunto de datos (sin ordenar).</target>
        </trans-unit>
        <trans-unit id="45f9706f8e40bfee3b8f4082279b7c1694d8aead" translate="yes" xml:space="preserve">
          <source>Where \(K\) is the precision matrix to be estimated, and \(S\) is the sample covariance matrix. \(\|K\|_1\) is the sum of the absolute values of off-diagonal coefficients of \(K\). The algorithm employed to solve this problem is the GLasso algorithm, from the Friedman 2008 Biostatistics paper. It is the same algorithm as in the R &lt;code&gt;glasso&lt;/code&gt; package.</source>
          <target state="translated">Donde \ (K \) es la matriz de precisi&amp;oacute;n que se va a estimar y \ (S \) es la matriz de covarianza muestral. \ (\ | K \ | _1 \) es la suma de los valores absolutos de los coeficientes fuera de la diagonal de \ (K \). El algoritmo empleado para resolver este problema es el algoritmo GLasso, del art&amp;iacute;culo Friedman 2008 Biostatistics. Es el mismo algoritmo que en el paquete R &lt;code&gt;glasso&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="23038cc6fb25ab648004d5485267f6db76cb9eda" translate="yes" xml:space="preserve">
          <source>Where \(N(x_i)\) is the neighborhood of samples within a given distance around \(x_i\) and \(m\) is the &lt;em&gt;mean shift&lt;/em&gt; vector that is computed for each centroid that points towards a region of the maximum increase in the density of points. This is computed using the following equation, effectively updating a centroid to be the mean of the samples within its neighborhood:</source>
          <target state="translated">Donde \ (N (x_i) \) es la vecindad de muestras dentro de una distancia dada alrededor de \ (x_i \) y \ (m \) es el vector de &lt;em&gt;desplazamiento medio&lt;/em&gt; que se calcula para cada centroide que apunta hacia una regi&amp;oacute;n de aumento m&amp;aacute;ximo en la densidad de puntos. Esto se calcula usando la siguiente ecuaci&amp;oacute;n, actualizando efectivamente un centroide para que sea la media de las muestras dentro de su vecindad:</target>
        </trans-unit>
        <trans-unit id="c4be16a40b65a723b122e1219966e4db066c1f56" translate="yes" xml:space="preserve">
          <source>Where \(R\) is the diagonal matrix with entry \(i\) equal to \(\sum_{j} A_{ij}\) and \(C\) is the diagonal matrix with entry \(j\) equal to \(\sum_{i} A_{ij}\).</source>
          <target state="translated">Donde \ ~-R es la matriz diagonal con la entrada \ ~-i igual a la suma de Aij y C es la matriz diagonal con la entrada \ ~-j igual a la suma de Aij.</target>
        </trans-unit>
        <trans-unit id="06bd15907339a321f45a7707ee037e3bf4bb294c" translate="yes" xml:space="preserve">
          <source>Where \(\langle \cdot, \cdot \rangle\) denotes the inner product in the Hilbert space.</source>
          <target state="translated">Donde &quot;ángulo&quot;,&quot;punto&quot;,&quot;ángulo&quot;,denota el producto interno en el espacio de Hilbert.</target>
        </trans-unit>
        <trans-unit id="b505305e3f68e0055136674f6671623549265da7" translate="yes" xml:space="preserve">
          <source>Where \(\log_e (x)\) means the natural logarithm of \(x\). This metric is best to use when targets having exponential growth, such as population counts, average sales of a commodity over a span of years etc. Note that this metric penalizes an under-predicted estimate greater than an over-predicted estimate.</source>
          <target state="translated">Donde \ ~ \ ~-(x)\ ~ significa el logaritmo natural de \ ~-(x).Esta métrica es mejor para usar cuando los objetivos tienen un crecimiento exponencial,como el recuento de la población,las ventas medias de una mercancía en un periodo de años,etc.Nótese que esta métrica penaliza una estimación subestimada mayor que una estimación sobreestimada.</target>
        </trans-unit>
        <trans-unit id="dc652afd01d2a671ac597240d27fcb8fb6f2cb88" translate="yes" xml:space="preserve">
          <source>Where \(s(i, k)\) is the similarity between samples \(i\) and \(k\). The availability of sample \(k\) to be the exemplar of sample \(i\) is given by:</source>
          <target state="translated">Donde &quot;s(i,k)&quot; es la similitud entre las muestras y &quot;k&quot;.La disponibilidad de la muestra (k)para ser el ejemplo de la muestra (i)está dada por:</target>
        </trans-unit>
        <trans-unit id="9fa1e5b532b4ed4720d23061371103281dda3d83" translate="yes" xml:space="preserve">
          <source>Where r is defined per sample, we need to make use of &lt;code&gt;start&lt;/code&gt;:</source>
          <target state="translated">Donde r se define por muestra, necesitamos hacer uso de &lt;code&gt;start&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="c16b06fa7e959786262fbf5823a1d1a66514be0c" translate="yes" xml:space="preserve">
          <source>Where the step length \(\gamma_m\) is chosen using line search:</source>
          <target state="translated">Donde la longitud del paso se elige usando la búsqueda de líneas:</target>
        </trans-unit>
        <trans-unit id="096f899281fbd2d32d659004bce326784eacf79e" translate="yes" xml:space="preserve">
          <source>Where there are considerations other than maximum score in choosing a best estimator, &lt;code&gt;refit&lt;/code&gt; can be set to a function which returns the selected &lt;code&gt;best_index_&lt;/code&gt; given &lt;code&gt;cv_results_&lt;/code&gt;. In that case, the &lt;code&gt;best_estimator_&lt;/code&gt; and &lt;code&gt;best_params_&lt;/code&gt; will be set according to the returned &lt;code&gt;best_index_&lt;/code&gt; while the &lt;code&gt;best_score_&lt;/code&gt; attribute will not be available.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be446fd5f2cab9d9132f73b7df79724fa271f7f8" translate="yes" xml:space="preserve">
          <source>Where there are considerations other than maximum score in choosing a best estimator, &lt;code&gt;refit&lt;/code&gt; can be set to a function which returns the selected &lt;code&gt;best_index_&lt;/code&gt; given the &lt;code&gt;cv_results&lt;/code&gt;. In that case, the &lt;code&gt;best_estimator_&lt;/code&gt; and &lt;code&gt;best_params_&lt;/code&gt; will be set according to the returned &lt;code&gt;best_index_&lt;/code&gt; while the &lt;code&gt;best_score_&lt;/code&gt; attribute will not be available.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e4c7785f80a06d28d2e2b965c377764abc1c026" translate="yes" xml:space="preserve">
          <source>Where to from here</source>
          <target state="translated">¿A dónde vamos desde aquí?</target>
        </trans-unit>
        <trans-unit id="17eb390ca1dec9880beb722610077dafb8edc9ac" translate="yes" xml:space="preserve">
          <source>Where u and v are any rows taken from a dataset of shape [n_samples, n_features] and p is a projection by a random Gaussian N(0, 1) matrix with shape [n_components, n_features] (or a sparse Achlioptas matrix).</source>
          <target state="translated">Donde u y v son filas tomadas de un conjunto de datos de forma [n_muestras,n_características]y p es una proyección por una matriz gaussiana aleatoria N(0,1)con forma [n_componentes,n_características](o una escasa matriz de Achlioptas).</target>
        </trans-unit>
        <trans-unit id="c5759c4abe89df832c23e0269eba38e4f1ad0ad7" translate="yes" xml:space="preserve">
          <source>Where u and v are any rows taken from a dataset of shape [n_samples, n_features], eps is in ]0, 1[ and p is a projection by a random Gaussian N(0, 1) matrix with shape [n_components, n_features] (or a sparse Achlioptas matrix).</source>
          <target state="translated">Donde u y v son filas tomadas de un conjunto de datos de forma [n_muestras,n_características],eps está en ]0,1[y p es una proyección por una matriz gaussiana aleatoria N(0,1)con forma [n_componentes,n_características](o una escasa matriz de Achlioptas).</target>
        </trans-unit>
        <trans-unit id="7e741bc3dcef0123eeda11543758853be2aac149" translate="yes" xml:space="preserve">
          <source>Where:</source>
          <target state="translated">Where:</target>
        </trans-unit>
        <trans-unit id="16270a9447d061ffaba6de4c25d0370619ae5579" translate="yes" xml:space="preserve">
          <source>Whether &lt;code&gt;feature_names_&lt;/code&gt; and &lt;code&gt;vocabulary_&lt;/code&gt; should be sorted when fitting.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07f1abf8acdb3dcd49bde3ee8a201c3421831b31" translate="yes" xml:space="preserve">
          <source>Whether &lt;code&gt;feature_names_&lt;/code&gt; and &lt;code&gt;vocabulary_&lt;/code&gt; should be sorted when fitting. True by default.</source>
          <target state="translated">Si &lt;code&gt;feature_names_&lt;/code&gt; y &lt;code&gt;vocabulary_&lt;/code&gt; deben ordenarse al ajustar. Verdadero por defecto.</target>
        </trans-unit>
        <trans-unit id="e61b5eefa6a0d8caaa65c0cf06600523e6eded8c" translate="yes" xml:space="preserve">
          <source>Whether a forced copy will be triggered. If copy=False, a copy might be triggered by a conversion.</source>
          <target state="translated">Si una copia forzada será activada.Si copia=Falso,una copia podría ser activada por una conversión.</target>
        </trans-unit>
        <trans-unit id="6817dee267fec06b200988a35092c9fafdb28df4" translate="yes" xml:space="preserve">
          <source>Whether a prefit model is expected to be passed into the constructor directly or not. If True, &lt;code&gt;transform&lt;/code&gt; must be called directly and SelectFromModel cannot be used with &lt;code&gt;cross_val_score&lt;/code&gt;, &lt;code&gt;GridSearchCV&lt;/code&gt; and similar utilities that clone the estimator. Otherwise train the model using &lt;code&gt;fit&lt;/code&gt; and then &lt;code&gt;transform&lt;/code&gt; to do feature selection.</source>
          <target state="translated">Si se espera que un modelo de ajuste previo se pase directamente al constructor o no. Si es True, &lt;code&gt;transform&lt;/code&gt; se debe llamar directamente y SelectFromModel no se puede usar con &lt;code&gt;cross_val_score&lt;/code&gt; , &lt;code&gt;GridSearchCV&lt;/code&gt; y utilidades similares que clonan el estimador. De lo contrario, entrene el modelo usando el &lt;code&gt;fit&lt;/code&gt; y luego &lt;code&gt;transform&lt;/code&gt; para realizar la selecci&amp;oacute;n de caracter&amp;iacute;sticas.</target>
        </trans-unit>
        <trans-unit id="e67f675f1639113224879739e0229eb2671df0d3" translate="yes" xml:space="preserve">
          <source>Whether an array will be forced to be fortran or c-style.</source>
          <target state="translated">Si una matriz será forzada a ser fortran o estilo C.</target>
        </trans-unit>
        <trans-unit id="57d1f88164d54372295bc307285273118c662089" translate="yes" xml:space="preserve">
          <source>Whether an array will be forced to be fortran or c-style. When order is None (default), then if copy=False, nothing is ensured about the memory layout of the output array; otherwise (copy=True) the memory layout of the returned array is kept as close as possible to the original array.</source>
          <target state="translated">Si una matriz será forzada a ser fortran o estilo C.Cuando el orden es None (por defecto),entonces si copy=False,no se asegura nada sobre la distribución de la memoria de la matriz de salida;de lo contrario (copy=True)la distribución de la memoria de la matriz devuelta se mantiene lo más cerca posible de la matriz original.</target>
        </trans-unit>
        <trans-unit id="f6541283616583040ce3e73f070cbb436dbc5da9" translate="yes" xml:space="preserve">
          <source>Whether bootstrap samples are used when building trees.</source>
          <target state="translated">Si se usan muestras de bootstrap cuando se construyen árboles.</target>
        </trans-unit>
        <trans-unit id="1349327857b1cdc30e7f508422cffd4b74a570bf" translate="yes" xml:space="preserve">
          <source>Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="344e324f858395af07d0534305d3cd485a522869" translate="yes" xml:space="preserve">
          <source>Whether column indices in f are zero-based (True) or one-based (False). If column indices are one-based, they are transformed to zero-based to match Python/NumPy conventions. If set to &amp;ldquo;auto&amp;rdquo;, a heuristic check is applied to determine this from the file contents. Both kinds of files occur &amp;ldquo;in the wild&amp;rdquo;, but they are unfortunately not self-identifying. Using &amp;ldquo;auto&amp;rdquo; or True should always be safe when no &lt;code&gt;offset&lt;/code&gt; or &lt;code&gt;length&lt;/code&gt; is passed. If &lt;code&gt;offset&lt;/code&gt; or &lt;code&gt;length&lt;/code&gt; are passed, the &amp;ldquo;auto&amp;rdquo; mode falls back to &lt;code&gt;zero_based=True&lt;/code&gt; to avoid having the heuristic check yield inconsistent results on different segments of the file.</source>
          <target state="translated">Si los &amp;iacute;ndices de columna en f son de base cero (Verdadero) o de uno (Falso). Si los &amp;iacute;ndices de columna est&amp;aacute;n basados ​​en uno, se transforman en cero para que coincidan con las convenciones de Python / NumPy. Si se establece en &quot;auto&quot;, se aplica una verificaci&amp;oacute;n heur&amp;iacute;stica para determinar esto a partir del contenido del archivo. Ambos tipos de archivos ocurren &quot;en la naturaleza&quot;, pero desafortunadamente no son autoidentificables. Usar &quot;auto&quot; o True siempre debe ser seguro cuando no se pasa ning&amp;uacute;n &lt;code&gt;offset&lt;/code&gt; o &lt;code&gt;length&lt;/code&gt; . Si se pasa el &lt;code&gt;offset&lt;/code&gt; o la &lt;code&gt;length&lt;/code&gt; , el modo &quot;autom&amp;aacute;tico&quot; vuelve a &lt;code&gt;zero_based=True&lt;/code&gt; para evitar que la verificaci&amp;oacute;n heur&amp;iacute;stica produzca resultados inconsistentes en diferentes segmentos del archivo.</target>
        </trans-unit>
        <trans-unit id="f00bfe1387e4927051573cb3d574287560206c66" translate="yes" xml:space="preserve">
          <source>Whether column indices in f are zero-based (True) or one-based (False). If column indices are one-based, they are transformed to zero-based to match Python/NumPy conventions. If set to &amp;ldquo;auto&amp;rdquo;, a heuristic check is applied to determine this from the file contents. Both kinds of files occur &amp;ldquo;in the wild&amp;rdquo;, but they are unfortunately not self-identifying. Using &amp;ldquo;auto&amp;rdquo; or True should always be safe when no offset or length is passed. If offset or length are passed, the &amp;ldquo;auto&amp;rdquo; mode falls back to zero_based=True to avoid having the heuristic check yield inconsistent results on different segments of the file.</source>
          <target state="translated">Si los &amp;iacute;ndices de columna en f son de base cero (Verdadero) o de uno (Falso). Si los &amp;iacute;ndices de columna est&amp;aacute;n basados ​​en uno, se transforman en cero para que coincidan con las convenciones de Python / NumPy. Si se establece en &quot;auto&quot;, se aplica una verificaci&amp;oacute;n heur&amp;iacute;stica para determinar esto a partir del contenido del archivo. Ambos tipos de archivos ocurren &quot;en la naturaleza&quot;, pero desafortunadamente no son autoidentificables. Usar &quot;auto&quot; o True siempre debe ser seguro cuando no se pasa ning&amp;uacute;n desplazamiento o longitud. Si se pasa el desplazamiento o la longitud, el modo &amp;ldquo;autom&amp;aacute;tico&amp;rdquo; vuelve a zero_based = True para evitar que la verificaci&amp;oacute;n heur&amp;iacute;stica produzca resultados inconsistentes en diferentes segmentos del archivo.</target>
        </trans-unit>
        <trans-unit id="be05ee9a303aba9073e602f5af4606db8dba467c" translate="yes" xml:space="preserve">
          <source>Whether column indices should be written zero-based (True) or one-based (False).</source>
          <target state="translated">Si los índices de las columnas deben escribirse en base cero (Verdadero)o en base uno (Falso).</target>
        </trans-unit>
        <trans-unit id="426c392bb98aa08b186e867710abfa024378fa01" translate="yes" xml:space="preserve">
          <source>Whether features are drawn with replacement.</source>
          <target state="translated">Si los rasgos se dibujan con el reemplazo.</target>
        </trans-unit>
        <trans-unit id="b1153e9c8e50c0d286811aaf218a31fa047ae93d" translate="yes" xml:space="preserve">
          <source>Whether or not a second normalization of the weights is performed. The default behavior mirrors the implementations found in Mahout and Weka, which do not follow the full algorithm described in Table 9 of the paper.</source>
          <target state="translated">Si se realiza o no una segunda normalización de los pesos.El comportamiento por defecto refleja las implementaciones encontradas en Mahout y Weka,que no siguen el algoritmo completo descrito en la Tabla 9 del documento.</target>
        </trans-unit>
        <trans-unit id="1500a013d74d8899d6c67c8489e35470d425474d" translate="yes" xml:space="preserve">
          <source>Whether or not the model should use an intercept, i.e. a biased hyperplane, is controlled by the parameter &lt;code&gt;fit_intercept&lt;/code&gt;.</source>
          <target state="translated">Si el modelo debe utilizar o no una intersecci&amp;oacute;n, es decir, un hiperplano sesgado, se controla mediante el par&amp;aacute;metro &lt;code&gt;fit_intercept&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c17699d69c93a1c9674665b22c836f689e7a71a8" translate="yes" xml:space="preserve">
          <source>Whether or not the training data should be shuffled after each epoch.</source>
          <target state="translated">Si los datos de entrenamiento deben o no ser barajados después de cada época.</target>
        </trans-unit>
        <trans-unit id="2f96d4cd24a907c94c91a597b369db5ae9d183fe" translate="yes" xml:space="preserve">
          <source>Whether or not the training data should be shuffled after each epoch. Defaults to True.</source>
          <target state="translated">Si los datos de entrenamiento deben o no ser barajados después de cada época.Por defecto es Verdadero.</target>
        </trans-unit>
        <trans-unit id="21e287c040da0ab9f7612eda4a9df397d21447be" translate="yes" xml:space="preserve">
          <source>Whether or not to compute labels for each fit.</source>
          <target state="translated">Si se calculan o no las etiquetas para cada ajuste.</target>
        </trans-unit>
        <trans-unit id="ae7627e3aed47d9187a8dde354d4bd8908f66e18" translate="yes" xml:space="preserve">
          <source>Whether or not to consider raw Mahalanobis distances as the decision function. Must be False (default) for compatibility with the others outlier detection tools.</source>
          <target state="translated">Si considerar o no las distancias de Mahalanobis en bruto como la función de decisión.Debe ser Falso (por defecto)para la compatibilidad con las otras herramientas de detección de valores atípicos.</target>
        </trans-unit>
        <trans-unit id="d7d36162415efc2dece0359749393df764e8f212" translate="yes" xml:space="preserve">
          <source>Whether or not to fit the intercept. This can be set to False if the data is already centered around the origin.</source>
          <target state="translated">Si se ajusta o no a la intercepción.Se puede establecer como Falso si los datos ya están centrados en el origen.</target>
        </trans-unit>
        <trans-unit id="99ecd63bc30b233e173e08d6a58d2b609112b08a" translate="yes" xml:space="preserve">
          <source>Whether or not to make a copy of the given data. If set to False, the initial data will be overwritten.</source>
          <target state="translated">Si hacer o no una copia de los datos dados.Si se establece como Falso,los datos iniciales serán sobrescritos.</target>
        </trans-unit>
        <trans-unit id="95950f270865da71d578c03fd7275708de2f1edb" translate="yes" xml:space="preserve">
          <source>Whether or not to mark each sample as the first nearest neighbor to itself. If &amp;lsquo;auto&amp;rsquo;, then True is used for mode=&amp;rsquo;connectivity&amp;rsquo; and False for mode=&amp;rsquo;distance&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d8aa347bdbdfa6dd79051c8fee2f95fc5666522" translate="yes" xml:space="preserve">
          <source>Whether or not to mark each sample as the first nearest neighbor to itself. If &lt;code&gt;None&lt;/code&gt;, then True is used for mode=&amp;rsquo;connectivity&amp;rsquo; and False for mode=&amp;rsquo;distance&amp;rsquo; as this will preserve backwards compatibility.</source>
          <target state="translated">Si marcar o no cada muestra como el primer vecino m&amp;aacute;s cercano a s&amp;iacute; mismo. Si &lt;code&gt;None&lt;/code&gt; , entonces True se usa para mode = 'conectividad' y False para mode = 'distancia' ya que esto preservar&amp;aacute; la compatibilidad con versiones anteriores.</target>
        </trans-unit>
        <trans-unit id="a1d6eb056f01f6a77d40d6f787612d8008f1be4b" translate="yes" xml:space="preserve">
          <source>Whether or not to return a sparse CSR matrix, as default behavior, or to return a dense array compatible with dense pipeline operators.</source>
          <target state="translated">Si devolver o no una matriz de CSR escasa,como comportamiento por defecto,o devolver una matriz densa compatible con los operadores de oleoductos densos.</target>
        </trans-unit>
        <trans-unit id="8f592bf838896fb605ecc15c063970bf58250eab" translate="yes" xml:space="preserve">
          <source>Whether or not to return the number of iterations.</source>
          <target state="translated">Si devolver o no el número de iteraciones.</target>
        </trans-unit>
        <trans-unit id="3433b032133d6a741db0a6ccce9ce8005a84877d" translate="yes" xml:space="preserve">
          <source>Whether or not to shuffle the data before splitting. If shuffle=False then stratify must be None.</source>
          <target state="translated">Si se deben mezclar o no los datos antes de dividirlos.Si barajar=Falso entonces estratificar debe ser Ninguno.</target>
        </trans-unit>
        <trans-unit id="d797771ee8d7ac8a664344b3d1655c54bf4a7c5a" translate="yes" xml:space="preserve">
          <source>Whether or not to shuffle the data: might be important for models that make the assumption that the samples are independent and identically distributed (i.i.d.), such as stochastic gradient descent.</source>
          <target state="translated">El hecho de barajar o no los datos:podría ser importante para los modelos que asumen que las muestras son independientes y están distribuidas de forma idéntica (i.i.d.),como el descenso de gradiente estocástico.</target>
        </trans-unit>
        <trans-unit id="169aa17090e9b82766c818a4a09acd1cb51fcb24" translate="yes" xml:space="preserve">
          <source>Whether samples are drawn with replacement.</source>
          <target state="translated">Si las muestras se extraen con reemplazo.</target>
        </trans-unit>
        <trans-unit id="11994582207268a83009eceee1185d13dd22bd86" translate="yes" xml:space="preserve">
          <source>Whether samples are drawn with replacement. If False, sampling without replacement is performed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b61c81ce74fc75ce6a90c790bfafe984d14c7994" translate="yes" xml:space="preserve">
          <source>Whether score_func is a score function (default), meaning high is good, or a loss function, meaning low is good. In the latter case, the scorer object will sign-flip the outcome of the score_func.</source>
          <target state="translated">Si score_func es una función de puntuación (por defecto),lo que significa que la alta es buena,o una función de pérdida,lo que significa que la baja es buena.En este último caso,el objeto puntuador dará la vuelta al resultado de score_func.</target>
        </trans-unit>
        <trans-unit id="01c7a3b4947bb7aed2272a78dd753a14b9e24fdc" translate="yes" xml:space="preserve">
          <source>Whether score_func requires predict_proba to get probability estimates out of a classifier.</source>
          <target state="translated">Si score_func requiere predict_proba para obtener estimaciones de probabilidad de un clasificador.</target>
        </trans-unit>
        <trans-unit id="e86601bb1c2db478564381eb9b1a33fc72f3ad69" translate="yes" xml:space="preserve">
          <source>Whether score_func takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method.</source>
          <target state="translated">Si score_func toma una continua certeza de decisión.Esto sólo funciona para la clasificación binaria utilizando estimadores que tienen un método decision_function o predict_proba.</target>
        </trans-unit>
        <trans-unit id="62e384e32324c7d8c05ac06534cda98d3cbc0def" translate="yes" xml:space="preserve">
          <source>Whether support is a list of indices.</source>
          <target state="translated">Si el apoyo es una lista de índices.</target>
        </trans-unit>
        <trans-unit id="970ea0e030e6e4be6469b0282edfb558e0e9066d" translate="yes" xml:space="preserve">
          <source>Whether the algorithm should be applied to M.T instead of M. The result should approximately be the same. The &amp;lsquo;auto&amp;rsquo; mode will trigger the transposition if M.shape[1] &amp;gt; M.shape[0] since this implementation of randomized SVD tend to be a little faster in that case.</source>
          <target state="translated">Si el algoritmo deber&amp;iacute;a aplicarse a MT en lugar de M. El resultado deber&amp;iacute;a ser aproximadamente el mismo. El modo 'auto' activar&amp;aacute; la transposici&amp;oacute;n si M.shape [1]&amp;gt; M.shape [0] ya que esta implementaci&amp;oacute;n de SVD aleatoria tiende a ser un poco m&amp;aacute;s r&amp;aacute;pida en ese caso.</target>
        </trans-unit>
        <trans-unit id="3226951d2ead1297a694651602f8538f5e93757c" translate="yes" xml:space="preserve">
          <source>Whether the covariance vector Xy must be copied by the algorithm. If False, it may be overwritten.</source>
          <target state="translated">Si el vector de covarianza Xy debe ser copiado por el algoritmo.Si es falso,puede ser sobrescrito.</target>
        </trans-unit>
        <trans-unit id="d2b667c3b7746e3e678455d8b2d703997aeb5e60" translate="yes" xml:space="preserve">
          <source>Whether the deflation be done on a copy. Let the default value to True unless you don&amp;rsquo;t care about side effects</source>
          <target state="translated">Si la deflaci&amp;oacute;n se har&amp;aacute; en una copia. Deje que el valor predeterminado sea Verdadero a menos que no le importen los efectos secundarios</target>
        </trans-unit>
        <trans-unit id="1cba92780e42c1ebe55ada467260206516898de8" translate="yes" xml:space="preserve">
          <source>Whether the deflation should be done on a copy. Let the default value to True unless you don&amp;rsquo;t care about side effect</source>
          <target state="translated">Si la deflaci&amp;oacute;n debe hacerse en una copia. Deje que el valor predeterminado sea Verdadero a menos que no le importe el efecto secundario</target>
        </trans-unit>
        <trans-unit id="99f0df0508624fcfafef99671905c951f197a398" translate="yes" xml:space="preserve">
          <source>Whether the design matrix X must be copied by the algorithm. A false value is only helpful if X is already Fortran-ordered, otherwise a copy is made anyway.</source>
          <target state="translated">Si la matriz de diseño X debe ser copiada por el algoritmo.Un valor falso sólo es útil si X ya está ordenada por Fortran,de lo contrario se hace una copia de todos modos.</target>
        </trans-unit>
        <trans-unit id="6f829dc8dcc41b94f325536e7999d7feb34a89f1" translate="yes" xml:space="preserve">
          <source>Whether the feature should be made of word n-gram or character n-grams. Option &amp;lsquo;char_wb&amp;rsquo; creates character n-grams only from text inside word boundaries; n-grams at the edges of words are padded with space.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f62ef19aafedabcbf9aa2a6c1cbcccaa900e840f" translate="yes" xml:space="preserve">
          <source>Whether the feature should be made of word or character n-grams.</source>
          <target state="translated">Si el rasgo debe ser hecho de palabra o de carácter n-gramas.</target>
        </trans-unit>
        <trans-unit id="9c1354d44a66effd212e821b1aba74fe08612248" translate="yes" xml:space="preserve">
          <source>Whether the feature should be made of word or character n-grams. Option &amp;lsquo;char_wb&amp;rsquo; creates character n-grams only from text inside word boundaries; n-grams at the edges of words are padded with space.</source>
          <target state="translated">Si la caracter&amp;iacute;stica debe estar compuesta de n-gramas de palabras o de caracteres. La opci&amp;oacute;n 'char_wb' crea n-gramas de caracteres solo a partir del texto dentro de los l&amp;iacute;mites de las palabras; Los n-gramas en los bordes de las palabras se rellenan con espacio.</target>
        </trans-unit>
        <trans-unit id="824ad07968fefbc8aa1fba0ade7c849f0d099562" translate="yes" xml:space="preserve">
          <source>Whether the gram matrix must be copied by the algorithm. A false value is only helpful if it is already Fortran-ordered, otherwise a copy is made anyway.</source>
          <target state="translated">Si la matriz gramatical debe ser copiada por el algoritmo.Un valor falso sólo es útil si ya está ordenado por Fortran,de lo contrario se hace una copia de todos modos.</target>
        </trans-unit>
        <trans-unit id="23571fa5c9f0e8d5b2ce0915807aa480e23639d3" translate="yes" xml:space="preserve">
          <source>Whether the imputer mask format should be sparse or dense.</source>
          <target state="translated">Si el formato de la máscara de impurezas debe ser escaso o denso.</target>
        </trans-unit>
        <trans-unit id="b70758cdff0513f8822d9fb7393f16dda3f13af9" translate="yes" xml:space="preserve">
          <source>Whether the imputer mask should represent all or a subset of features.</source>
          <target state="translated">Si la máscara imputadora debe representar todos o un subconjunto de características.</target>
        </trans-unit>
        <trans-unit id="11709e37813efd2480c1d891188cf0d8201c8a69" translate="yes" xml:space="preserve">
          <source>Whether the intercept should be estimated or not. If &lt;code&gt;False&lt;/code&gt;, the data is assumed to be already centered.</source>
          <target state="translated">Si la intersecci&amp;oacute;n debe estimarse o no. Si es &lt;code&gt;False&lt;/code&gt; , se supone que los datos ya est&amp;aacute;n centrados.</target>
        </trans-unit>
        <trans-unit id="0ccd5f6458ed970eecf03c787120d2831e50f140" translate="yes" xml:space="preserve">
          <source>Whether the intercept should be estimated or not. If False, the data is assumed to be already centered.</source>
          <target state="translated">Si la interceptación debe ser estimada o no.Si es falsa,se supone que los datos ya están centrados.</target>
        </trans-unit>
        <trans-unit id="2fafec857734808cd372cb104d91a568d25acbf6" translate="yes" xml:space="preserve">
          <source>Whether the intercept should be estimated or not. If False, the data is assumed to be already centered. Defaults to True.</source>
          <target state="translated">Si la interceptación debe ser estimada o no.Si es falsa,se supone que los datos ya están centrados.Por defecto es Verdadero.</target>
        </trans-unit>
        <trans-unit id="1369ea0f90c1ab8c31f4e5d5e2b327950f322e67" translate="yes" xml:space="preserve">
          <source>Whether the kernel works only on fixed-length feature vectors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="efe887a2120302f3ddf508ce39115dacb905298c" translate="yes" xml:space="preserve">
          <source>Whether the parameter was found to be a named parameter of the estimator&amp;rsquo;s fit method.</source>
          <target state="translated">Si se encontr&amp;oacute; que el par&amp;aacute;metro era un par&amp;aacute;metro con nombre del m&amp;eacute;todo de ajuste del estimador.</target>
        </trans-unit>
        <trans-unit id="e3e6070e7b1bf06bd46c63ade906ee83f84569ff" translate="yes" xml:space="preserve">
          <source>Whether the power iterations are normalized with step-by-step QR factorization (the slowest but most accurate), &amp;lsquo;none&amp;rsquo; (the fastest but numerically unstable when &lt;code&gt;n_iter&lt;/code&gt; is large, e.g. typically 5 or larger), or &amp;lsquo;LU&amp;rsquo; factorization (numerically stable but can lose slightly in accuracy). The &amp;lsquo;auto&amp;rsquo; mode applies no normalization if &lt;code&gt;n_iter&lt;/code&gt; &amp;lt;= 2 and switches to LU otherwise.</source>
          <target state="translated">Si las iteraciones de potencia se normalizan con factorizaci&amp;oacute;n QR paso a paso (la m&amp;aacute;s lenta pero m&amp;aacute;s precisa), 'ninguna' (la m&amp;aacute;s r&amp;aacute;pida pero num&amp;eacute;ricamente inestable cuando &lt;code&gt;n_iter&lt;/code&gt; es grande, por ejemplo, t&amp;iacute;picamente 5 o m&amp;aacute;s), o factorizaci&amp;oacute;n 'LU' (num&amp;eacute;ricamente estable pero puede perder levemente la precisi&amp;oacute;n). El modo 'auto' no aplica normalizaci&amp;oacute;n si &lt;code&gt;n_iter&lt;/code&gt; &amp;lt;= 2 y cambia a LU en caso contrario.</target>
        </trans-unit>
        <trans-unit id="00c2bc5048e0182a905dad0c4dec40740dd521b8" translate="yes" xml:space="preserve">
          <source>Whether the relationship is increasing or decreasing.</source>
          <target state="translated">Si la relación está aumentando o disminuyendo.</target>
        </trans-unit>
        <trans-unit id="dc0314689b038e45038d5534e1499b2766f8b916" translate="yes" xml:space="preserve">
          <source>Whether the return value is an array of sparse matrix depends on the type of the input X.</source>
          <target state="translated">El hecho de que el valor de retorno sea un conjunto de matriz dispersa depende del tipo de la entrada X.</target>
        </trans-unit>
        <trans-unit id="ed44b1dc96dab239fb6ac2dc375f2ee5fe3ae793" translate="yes" xml:space="preserve">
          <source>Whether the target values y are normalized, i.e., the mean of the observed target values become zero. This parameter should be set to True if the target values&amp;rsquo; mean is expected to differ considerable from zero. When enabled, the normalization effectively modifies the GP&amp;rsquo;s prior based on the data, which contradicts the likelihood principle; normalization is thus disabled per default.</source>
          <target state="translated">Si los valores objetivo y est&amp;aacute;n normalizados, es decir, la media de los valores objetivo observados se vuelve cero. Este par&amp;aacute;metro debe establecerse en Verdadero si se espera que la media de los valores objetivo difiera considerablemente de cero. Cuando est&amp;aacute; habilitada, la normalizaci&amp;oacute;n modifica efectivamente el previo del GP en funci&amp;oacute;n de los datos, lo que contradice el principio de probabilidad; Por tanto, la normalizaci&amp;oacute;n est&amp;aacute; desactivada por defecto.</target>
        </trans-unit>
        <trans-unit id="cb8d2af32f6e15f6d8381b5609652e77d17356c4" translate="yes" xml:space="preserve">
          <source>Whether the target values y are normalized, the mean and variance of the target values are set equal to 0 and 1 respectively. This is recommended for cases where zero-mean, unit-variance priors are used. Note that, in this implementation, the normalisation is reversed before the GP predictions are reported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d56de522c2f2c8fa83698a0d6921644d35a5428" translate="yes" xml:space="preserve">
          <source>Whether the task is a classification task, in which case stratified KFold will be used.</source>
          <target state="translated">Si se trata de una tarea de clasificación,en cuyo caso se utilizará KFold estratificado.</target>
        </trans-unit>
        <trans-unit id="667f96156fffe3e4c7c8342ead32f8ae00d3d84f" translate="yes" xml:space="preserve">
          <source>Whether the value of this hyperparameter is fixed, i.e., cannot be changed during hyperparameter tuning. If None is passed, the &amp;ldquo;fixed&amp;rdquo; is derived based on the given bounds.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cb255093bce0eff775d5414b35fcd6fbd07931b" translate="yes" xml:space="preserve">
          <source>Whether this is a multilabel classifier</source>
          <target state="translated">Si se trata de un clasificador de múltiples etiquetas</target>
        </trans-unit>
        <trans-unit id="b1be5efdade94da8e67722b4ba2f983efa0225c5" translate="yes" xml:space="preserve">
          <source>Whether to allow 2-d y (array or sparse matrix). If false, y will be validated as a vector. y cannot have np.nan or np.inf values if multi_output=True.</source>
          <target state="translated">Si permitir 2-d y (matriz o matriz dispersa).Si es falsa,y será validada como vector.y no puede tener valores np.nan o np.inf si multi_output=True.</target>
        </trans-unit>
        <trans-unit id="110cd422886570c5a4fe2834aa70ff221b2cdcaf" translate="yes" xml:space="preserve">
          <source>Whether to allow 2D y (array or sparse matrix). If false, y will be validated as a vector. y cannot have np.nan or np.inf values if multi_output=True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ecc2d4e014d3f2172c25597969963bd34e18f05" translate="yes" xml:space="preserve">
          <source>Whether to allow X.ndim &amp;gt; 2.</source>
          <target state="translated">Si permitir X.ndim&amp;gt; 2.</target>
        </trans-unit>
        <trans-unit id="7a4a847db3917eeca38ca476c1ad3e57930cf992" translate="yes" xml:space="preserve">
          <source>Whether to allow array.ndim &amp;gt; 2.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5dcbf9253f384309cfbc4a594ef7b057c1cb7e6" translate="yes" xml:space="preserve">
          <source>Whether to also return the code U or just the dictionary V.</source>
          <target state="translated">Si devolver también el código U o sólo el diccionario V.</target>
        </trans-unit>
        <trans-unit id="c6289192e1f815e2a760fe289e8841e73f51c42c" translate="yes" xml:space="preserve">
          <source>Whether to be verbose.</source>
          <target state="translated">Si ser verboso.</target>
        </trans-unit>
        <trans-unit id="ccada94fe77cfa7bf4094a2aaa2265ce9f9f4e5f" translate="yes" xml:space="preserve">
          <source>Whether to cache downloaded datasets using joblib.</source>
          <target state="translated">Si se debe almacenar en caché los conjuntos de datos descargados usando joblib.</target>
        </trans-unit>
        <trans-unit id="86614eccba121d18979d29b5e6a1aceed9dc9343" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (e.g. data is expected to be already centered).</source>
          <target state="translated">Si calcular la intercepción para este modelo.Si se establece en Falso,no se utilizará ninguna intercepción en los cálculos (por ejemplo,se espera que los datos ya estén centrados).</target>
        </trans-unit>
        <trans-unit id="7285fa12a56fc9f408db5bd27934d6f0654e6093" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (i.e. data is expected to be centered).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="943768cddf06aea5cdead26cd3dff69cb74196ef" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (e.g. data is expected to be already centered).</source>
          <target state="translated">Si calcular la intercepción para este modelo.Si se establece en falso,no se utilizará ninguna intercepción en los cálculos (por ejemplo,se espera que los datos ya estén centrados).</target>
        </trans-unit>
        <trans-unit id="27f8a383f138130dd1f45baee7b1d68ad4ce59f4" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be already centered).</source>
          <target state="translated">Si calcular la intercepción para este modelo.Si se establece en falso,no se utilizará ninguna intercepción en los cálculos (es decir,se espera que los datos ya estén centrados).</target>
        </trans-unit>
        <trans-unit id="34dd726eec26b92f0d7e507bd65e8b16cfaec4c8" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0336ff17d311b84566800e5cf35b415ab2b27f38" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations.</source>
          <target state="translated">Si calcular la intercepción para este modelo.Si se establece en falso,no se usará ninguna intercepción en los cálculos.</target>
        </trans-unit>
        <trans-unit id="7c201504f17506a2291f5d939998458e72428d3b" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. The intercept is not treated as a probabilistic parameter and thus has no associated variance. If set to False, no intercept will be used in calculations (i.e. data is expected to be centered).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="471ed2aff4494fad57e380482ee0a58232333b20" translate="yes" xml:space="preserve">
          <source>Whether to check that &lt;code&gt;transform&lt;/code&gt; followed by &lt;code&gt;inverse_transform&lt;/code&gt; or &lt;code&gt;func&lt;/code&gt; followed by &lt;code&gt;inverse_func&lt;/code&gt; leads to the original targets.</source>
          <target state="translated">Si comprobar que &lt;code&gt;transform&lt;/code&gt; seguida de &lt;code&gt;inverse_transform&lt;/code&gt; o &lt;code&gt;func&lt;/code&gt; seguido de &lt;code&gt;inverse_func&lt;/code&gt; conduce a los objetivos originales.</target>
        </trans-unit>
        <trans-unit id="3c61d748141856e990caff79c0b01fd8a4086321" translate="yes" xml:space="preserve">
          <source>Whether to check that or &lt;code&gt;func&lt;/code&gt; followed by &lt;code&gt;inverse_func&lt;/code&gt; leads to the original inputs. It can be used for a sanity check, raising a warning when the condition is not fulfilled.</source>
          <target state="translated">Ya sea para verificar eso o &lt;code&gt;func&lt;/code&gt; seguido de &lt;code&gt;inverse_func&lt;/code&gt; conduce a las entradas originales. Se puede utilizar para comprobar la cordura y generar una advertencia cuando no se cumple la condici&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="50850a0df7fa2328560b0d7ebe31ee1142901517" translate="yes" xml:space="preserve">
          <source>Whether to compute &lt;code&gt;y_&lt;/code&gt; is increasing (if set to True) or decreasing (if set to False)</source>
          <target state="translated">Si calcular &lt;code&gt;y_&lt;/code&gt; aumenta (si se establece en Verdadero) o disminuye (si se establece en Falso)</target>
        </trans-unit>
        <trans-unit id="5fbe7e9ef9385d70942ace9201de11e6cead8f8d" translate="yes" xml:space="preserve">
          <source>Whether to compute the squared error norm or the error norm. If True (default), the squared error norm is returned. If False, the error norm is returned.</source>
          <target state="translated">Ya sea para calcular la norma de error al cuadrado o la norma de error.Si es True (por defecto),se devuelve la norma de error al cuadrado.Si es Falso,se devuelve la norma de error.</target>
        </trans-unit>
        <trans-unit id="01086dba4779bb032a62d90a9f9152dc1b833baf" translate="yes" xml:space="preserve">
          <source>Whether to copy X and Y, or perform in-place computations.</source>
          <target state="translated">Ya sea para copiar X e Y,o para realizar cálculos in situ.</target>
        </trans-unit>
        <trans-unit id="725302de0fd34aabdbfc0e0affbd4f4fb754127c" translate="yes" xml:space="preserve">
          <source>Whether to copy X and Y, or perform in-place normalization.</source>
          <target state="translated">Si copiar X y Y,o realizar una normalización en el lugar.</target>
        </trans-unit>
        <trans-unit id="7462b314a4fe2fff7847f10014abb6b1183fa84f" translate="yes" xml:space="preserve">
          <source>Whether to copy X and operate on the copy or perform in-place operations.</source>
          <target state="translated">Si copiar X y operar en la copia o realizar operaciones en el lugar.</target>
        </trans-unit>
        <trans-unit id="3692936737114d51a6bb410cb3531454c9ad1d68" translate="yes" xml:space="preserve">
          <source>Whether to copy the precomputed covariance matrix; if False, it may be overwritten.</source>
          <target state="translated">Si se copia la matriz de covarianza precalculada;si es falsa,puede ser sobrescrita.</target>
        </trans-unit>
        <trans-unit id="324d6fe1307968790ddbb142ded331e1979517da" translate="yes" xml:space="preserve">
          <source>Whether to create a copy of X and operate on it or to perform inplace computation (default behaviour).</source>
          <target state="translated">Ya sea para crear una copia de X y operar en ella o para realizar un cálculo in situ (comportamiento por defecto).</target>
        </trans-unit>
        <trans-unit id="62527ff1b5ed50e080e833b6d4fd94a862b78590" translate="yes" xml:space="preserve">
          <source>Whether to drop some suboptimal thresholds which would not appear on a plotted ROC curve. This is useful in order to create lighter ROC curves.</source>
          <target state="translated">Si bajar algunos umbrales subóptimos que no aparecerían en una curva ROC trazada.Esto es útil para crear curvas ROC más ligeras.</target>
        </trans-unit>
        <trans-unit id="9851e7fdf1748b99ff7c24c940b7ce5f334a6a27" translate="yes" xml:space="preserve">
          <source>Whether to drop the first eigenvector. For spectral embedding, this should be True as the first eigenvector should be constant vector for connected graph, but for spectral clustering, this should be kept as False to retain the first eigenvector.</source>
          <target state="translated">Si dejar caer el primer eigenvector.Para la incrustación espectral,esto debería ser Verdadero,ya que el primer vector propio debería ser un vector constante para el gráfico conectado,pero para la agrupación espectral,esto debería mantenerse como Falso para retener el primer vector propio.</target>
        </trans-unit>
        <trans-unit id="5f99ffcc1bc3b15acf95363130c37cd5b381a91e" translate="yes" xml:space="preserve">
          <source>Whether to enable probability estimates. This must be enabled prior to calling &lt;code&gt;fit&lt;/code&gt;, and will slow down that method.</source>
          <target state="translated">Ya sea para habilitar estimaciones de probabilidad. Esto debe estar habilitado antes de llamar a &lt;code&gt;fit&lt;/code&gt; y ralentizar&amp;aacute; ese m&amp;eacute;todo.</target>
        </trans-unit>
        <trans-unit id="1a58ce6c20ca7e5e36327e21b19b4ffc278a0174" translate="yes" xml:space="preserve">
          <source>Whether to enable probability estimates. This must be enabled prior to calling &lt;code&gt;fit&lt;/code&gt;, will slow down that method as it internally uses 5-fold cross-validation, and &lt;code&gt;predict_proba&lt;/code&gt; may be inconsistent with &lt;code&gt;predict&lt;/code&gt;. Read more in the &lt;a href=&quot;../svm#scores-probabilities&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a4497ffca40d00ae7a4f4bda08e5dece2337700" translate="yes" xml:space="preserve">
          <source>Whether to enforce positivity when finding the code.</source>
          <target state="translated">Si hacer cumplir la positividad al encontrar el código.</target>
        </trans-unit>
        <trans-unit id="2920a1115fbc090ce8de93fb299e0d53a98e0404" translate="yes" xml:space="preserve">
          <source>Whether to enforce positivity when finding the dictionary</source>
          <target state="translated">Si hacer cumplir la positividad al encontrar el diccionario</target>
        </trans-unit>
        <trans-unit id="cc323427a6369f3d4c345df0c7eab9b613a4b184" translate="yes" xml:space="preserve">
          <source>Whether to enforce positivity when finding the dictionary.</source>
          <target state="translated">Si hacer cumplir la positividad al encontrar el diccionario.</target>
        </trans-unit>
        <trans-unit id="0c86815e9d15a8d79f49100b7de99ab0894ffb4b" translate="yes" xml:space="preserve">
          <source>Whether to enforce positivity when finding the encoding.</source>
          <target state="translated">Si se debe imponer la positividad al encontrar la codificación.</target>
        </trans-unit>
        <trans-unit id="67962e408072673f64867d41053d2df5bd8ffd92" translate="yes" xml:space="preserve">
          <source>Whether to ensure that y has a numeric type. If dtype of y is object, it is converted to float64. Should only be used for regression algorithms.</source>
          <target state="translated">Si asegurarse de que y tiene un tipo numérico.Si el tipo de y es un objeto,se convierte en float64.Sólo debe ser usado para algoritmos de regresión.</target>
        </trans-unit>
        <trans-unit id="a89a89f1fbc0cff73f883e4748e4c43034f0361e" translate="yes" xml:space="preserve">
          <source>Whether to filter invalid parameters or not.</source>
          <target state="translated">Si filtrar o no los parámetros inválidos.</target>
        </trans-unit>
        <trans-unit id="8bd7eb051fe8793acf6505d7ff57ac8a40be3e89" translate="yes" xml:space="preserve">
          <source>Whether to fit an intercept for the model. In this case the shape of the returned array is (n_cs, n_features + 1).</source>
          <target state="translated">Si se ajusta a una intercepción para el modelo.En este caso la forma de la matriz devuelta es (n_cs,n_funciones+1).</target>
        </trans-unit>
        <trans-unit id="86604814c1d6f6dc79ece6e1aa0e214e981e58a5" translate="yes" xml:space="preserve">
          <source>Whether to fit the intercept for this model. If set to false, no intercept will be used in calculations (i.e. &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are expected to be centered).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e39ad37924100e174516b8fe05585ae0c11a660" translate="yes" xml:space="preserve">
          <source>Whether to include &amp;ldquo;special&amp;rdquo; label estimator or test processors.</source>
          <target state="translated">Ya sea para incluir estimador de etiquetas &quot;especial&quot; o procesadores de prueba.</target>
        </trans-unit>
        <trans-unit id="84818ba086581abd044063f9dd3c5b2beb12eda7" translate="yes" xml:space="preserve">
          <source>Whether to include meta-estimators that can be constructed using an estimator as their first argument. These are currently BaseEnsemble, OneVsOneClassifier, OutputCodeClassifier, OneVsRestClassifier, RFE, RFECV.</source>
          <target state="translated">Si incluir o no meta-estimadores que puedan ser construidos usando un estimador como su primer argumento.Estos son actualmente BaseEnsemble,OneVsOneClassifier,OutputCodeClassifier,OneVsRestClassifier,RFE,RFECV.</target>
        </trans-unit>
        <trans-unit id="74d7014a87bc3e04b7cb4d5881013af41aaf9d5f" translate="yes" xml:space="preserve">
          <source>Whether to include train scores.</source>
          <target state="translated">Si incluir o no las puntuaciones de los trenes.</target>
        </trans-unit>
        <trans-unit id="5a33027c8dd2a3a26ddc387706fe4e97d00f5eae" translate="yes" xml:space="preserve">
          <source>Whether to include train scores. Computing training scores is used to get insights on how different parameter settings impact the overfitting/underfitting trade-off. However computing the scores on the training set can be computationally expensive and is not strictly required to select the parameters that yield the best generalization performance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b770fc1f2ccfc02ef3107a2ecac741b2276c37e8" translate="yes" xml:space="preserve">
          <source>Whether to learn class prior probabilities or not. If false, a uniform prior will be used.</source>
          <target state="translated">Si aprender las probabilidades previas de la clase o no.Si son falsas,se usará un prior uniforme.</target>
        </trans-unit>
        <trans-unit id="8606bf192804810fba78c6bd2b8805fda4483156" translate="yes" xml:space="preserve">
          <source>Whether to load only 10 percent of the data.</source>
          <target state="translated">Si cargar sólo el 10 por ciento de los datos.</target>
        </trans-unit>
        <trans-unit id="3156faf4c491e77c08d3500dd2b8c76947137632" translate="yes" xml:space="preserve">
          <source>Whether to load or not the content of the different files. If true a &amp;lsquo;data&amp;rsquo; attribute containing the text information is present in the data structure returned. If not, a filenames attribute gives the path to the files.</source>
          <target state="translated">Si cargar o no el contenido de los diferentes archivos. Si es verdadero, un atributo de 'datos' que contiene la informaci&amp;oacute;n de texto est&amp;aacute; presente en la estructura de datos devuelta. Si no es as&amp;iacute;, un atributo de nombre de archivo proporciona la ruta a los archivos.</target>
        </trans-unit>
        <trans-unit id="81f8d6a01f7cffb7f53496e9cfd84f1ce27de740" translate="yes" xml:space="preserve">
          <source>Whether to make X at least 2d.</source>
          <target state="translated">Si hacer X por lo menos 2d.</target>
        </trans-unit>
        <trans-unit id="2a578215f5e1bceb4eddd518c894532f84a10916" translate="yes" xml:space="preserve">
          <source>Whether to make a copy of X. If &lt;code&gt;False&lt;/code&gt;, the input X gets overwritten during fitting.</source>
          <target state="translated">Ya sea para hacer una copia de X. Si es &lt;code&gt;False&lt;/code&gt; , la entrada X se sobrescribe durante el ajuste.</target>
        </trans-unit>
        <trans-unit id="e2abdc017941ef25090c0789fe34541086dc5677" translate="yes" xml:space="preserve">
          <source>Whether to make a copy of the given data. If set to False, the initial data will be overwritten.</source>
          <target state="translated">Si hacer una copia de los datos dados.Si se establece como Falso,los datos iniciales serán sobrescritos.</target>
        </trans-unit>
        <trans-unit id="df62a350cab30808585d28e267100de2daf97811" translate="yes" xml:space="preserve">
          <source>Whether to normalize the output matrix to make the leading diagonal elements all 1</source>
          <target state="translated">Si normalizar la matriz de salida para hacer que los elementos diagonales principales todos 1</target>
        </trans-unit>
        <trans-unit id="ba6415e4db38e5cea33cf7fab1a514fcf5285867" translate="yes" xml:space="preserve">
          <source>Whether to perform precomputations. Improves performance when n_targets or n_samples is very large.</source>
          <target state="translated">Si realizar precalculos.Mejora el rendimiento cuando n_objetivos o n_muestras es muy grande.</target>
        </trans-unit>
        <trans-unit id="4010b2bff9133aaf08486f7fb645e8e39634583e" translate="yes" xml:space="preserve">
          <source>Whether to presort the data to speed up the finding of best splits in fitting. Auto mode by default will use presorting on dense data and default to normal sorting on sparse data. Setting presort to true on sparse data will raise an error.</source>
          <target state="translated">Si preclasificar los datos para acelerar la búsqueda de las mejores divisiones en el ajuste.El modo automático por defecto utilizará la preclasificación en los datos densos y por defecto la clasificación normal en los datos escasos.Si se establece la preclasificación a verdadero en los datos dispersos,se producirá un error.</target>
        </trans-unit>
        <trans-unit id="29f75c6794195c888ce8399680c96d5b14e65048" translate="yes" xml:space="preserve">
          <source>Whether to presort the data to speed up the finding of best splits in fitting. For the default settings of a decision tree on large datasets, setting this to true may slow down the training process. When using either a smaller dataset or a restricted depth, this may speed up the training.</source>
          <target state="translated">Si preclasificar los datos para acelerar la búsqueda de las mejores divisiones en el ajuste.En el caso de los ajustes predeterminados de un árbol de decisión en grandes conjuntos de datos,ajustarlo a la realidad puede ralentizar el proceso de adaptación.Cuando se utiliza un conjunto de datos más pequeño o una profundidad restringida,esto puede acelerar el entrenamiento.</target>
        </trans-unit>
        <trans-unit id="cc4d3f96c9bc487e50b4fc4701212f323c65bca6" translate="yes" xml:space="preserve">
          <source>Whether to print progress messages to stdout.</source>
          <target state="translated">Si imprimir mensajes de progreso a stdout.</target>
        </trans-unit>
        <trans-unit id="1ef1345441f84cbc6b06cbfc2b69b730789a6079" translate="yes" xml:space="preserve">
          <source>Whether to raise a value error if X is not 2D.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b44ea19ee67df3ef30c54f3be25f24e67c4f3a60" translate="yes" xml:space="preserve">
          <source>Whether to raise a value error if X is not 2d.</source>
          <target state="translated">Si aumentar un error de valor si X no es 2d.</target>
        </trans-unit>
        <trans-unit id="64b755e00dbefa679127012ca837c554b0c217d7" translate="yes" xml:space="preserve">
          <source>Whether to raise a value error if array is not 2D.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5d06b3c83946e2cd2c05192b834ad6e01c6a1d5" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf and np.nan in X. The possibilities are:</source>
          <target state="translated">Si plantear un error en np.inf y np.nan en X.Las posibilidades son:</target>
        </trans-unit>
        <trans-unit id="eaa329f6263ead71ba810671bba1e6a99379040d" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf and np.nan in X. This parameter does not influence whether y can have np.inf or np.nan values. The possibilities are:</source>
          <target state="translated">Si se plantea un error en np.inf y np.nan en X.Este parámetro no influye en si y puede tener valores np.inf o np.nan.Las posibilidades son:</target>
        </trans-unit>
        <trans-unit id="ec8573b1162223970fd6725eca010725203428e3" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf, np.nan, pd.NA in X. The possibilities are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68ace26fa0c8880f45dfa331c844e7939329fec1" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf, np.nan, pd.NA in X. This parameter does not influence whether y can have np.inf, np.nan, pd.NA values. The possibilities are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3bbeec18546bd2f3b8cccf2897d9a3a9aee68173" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf, np.nan, pd.NA in array. The possibilities are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c551edd4edb4cf1081c3e3d3eb3a36ad8f839a51" translate="yes" xml:space="preserve">
          <source>Whether to raise an error or ignore if an unknown categorical feature is present during transform (default is to raise). When this parameter is set to &amp;lsquo;ignore&amp;rsquo; and an unknown category is encountered during transform, the resulting one-hot encoded columns for this feature will be all zeros. In the inverse transform, an unknown category will be denoted as None.</source>
          <target state="translated">Ya sea para generar un error o ignorar si una caracter&amp;iacute;stica categ&amp;oacute;rica desconocida est&amp;aacute; presente durante la transformaci&amp;oacute;n (el valor predeterminado es aumentar). Cuando este par&amp;aacute;metro se establece en 'ignorar' y se encuentra una categor&amp;iacute;a desconocida durante la transformaci&amp;oacute;n, las columnas codificadas one-hot resultantes para esta caracter&amp;iacute;stica ser&amp;aacute;n todas ceros. En la transformada inversa, una categor&amp;iacute;a desconocida se indicar&amp;aacute; como Ninguna.</target>
        </trans-unit>
        <trans-unit id="55b5cf4021bca4319afc6cff07e1e1c5a8e21c80" translate="yes" xml:space="preserve">
          <source>Whether to return a one-vs-rest (&amp;lsquo;ovr&amp;rsquo;) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (&amp;lsquo;ovo&amp;rsquo;) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2).</source>
          <target state="translated">Ya sea para devolver una funci&amp;oacute;n de decisi&amp;oacute;n one-vs-rest ('ovr') de shape (n_samples, n_classes) como todos los dem&amp;aacute;s clasificadores, o la funci&amp;oacute;n de decisi&amp;oacute;n original one-vs-one ('ovo') de libsvm que tiene shape (n_samples , n_clases * (n_clases - 1) / 2).</target>
        </trans-unit>
        <trans-unit id="3e008ca3901c2f4656b69b334cd2bbf88df838cc" translate="yes" xml:space="preserve">
          <source>Whether to return a one-vs-rest (&amp;lsquo;ovr&amp;rsquo;) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (&amp;lsquo;ovo&amp;rsquo;) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one (&amp;lsquo;ovo&amp;rsquo;) is always used as multi-class strategy.</source>
          <target state="translated">Ya sea para devolver una funci&amp;oacute;n de decisi&amp;oacute;n one-vs-rest ('ovr') de shape (n_samples, n_classes) como todos los dem&amp;aacute;s clasificadores, o la funci&amp;oacute;n de decisi&amp;oacute;n original one-vs-one ('ovo') de libsvm que tiene shape (n_samples , n_clases * (n_clases - 1) / 2). Sin embargo, uno contra uno ('ovo') siempre se usa como estrategia de clases m&amp;uacute;ltiples.</target>
        </trans-unit>
        <trans-unit id="7af50893420dd3e6c393c168dece6ee3ddea82a0" translate="yes" xml:space="preserve">
          <source>Whether to return a one-vs-rest (&amp;lsquo;ovr&amp;rsquo;) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (&amp;lsquo;ovo&amp;rsquo;) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one (&amp;lsquo;ovo&amp;rsquo;) is always used as multi-class strategy. The parameter is ignored for binary classification.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebccc28d7f21db5d9325894eec5fc9e6d02d15c3" translate="yes" xml:space="preserve">
          <source>Whether to return dense output even when the input is sparse. If &lt;code&gt;False&lt;/code&gt;, the output is sparse if both input arrays are sparse.</source>
          <target state="translated">Si devolver una salida densa incluso cuando la entrada es escasa. Si es &lt;code&gt;False&lt;/code&gt; , la salida es escasa si ambas matrices de entrada son escasas.</target>
        </trans-unit>
        <trans-unit id="12da7a3ff0421b885caca94ef2caa65b1b016c5f" translate="yes" xml:space="preserve">
          <source>Whether to return every value of the nonzero coefficients along the forward path. Useful for cross-validation.</source>
          <target state="translated">Si devolver cada valor de los coeficientes no nulos a lo largo del camino hacia adelante.Útil para la validación cruzada.</target>
        </trans-unit>
        <trans-unit id="6a16a084b2e44866fb8e9c04ea892f46ef9407d0" translate="yes" xml:space="preserve">
          <source>Whether to return the estimators fitted on each split.</source>
          <target state="translated">Si devolver los estimadores ajustados en cada división.</target>
        </trans-unit>
        <trans-unit id="5e04c1a3b3a800f3b607834e4028e06fab1a7b16" translate="yes" xml:space="preserve">
          <source>Whether to return the fit and score times.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0296def7d7feccd7f063d12d572b0bb6de2b0cd" translate="yes" xml:space="preserve">
          <source>Whether to return the number of iterations or not.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="642c6fa9e4316671c7770b59f9d72b6641ef628f" translate="yes" xml:space="preserve">
          <source>Whether to return the number of iterations.</source>
          <target state="translated">Si devolver el número de iteraciones.</target>
        </trans-unit>
        <trans-unit id="b549a24da790409f4ec3623e7b38a8b83191c416" translate="yes" xml:space="preserve">
          <source>Whether to return the standard deviation of posterior prediction.</source>
          <target state="translated">Si devolver la desviación estándar de la predicción posterior.</target>
        </trans-unit>
        <trans-unit id="b33ff2a27948731af021590a907c614a500fc29d" translate="yes" xml:space="preserve">
          <source>Whether to return the standard deviation of posterior prediction. All zeros in this case.</source>
          <target state="translated">Si devolver la desviación estándar de la predicción posterior.Todos los ceros en este caso.</target>
        </trans-unit>
        <trans-unit id="7f1c62ca9183e80a5d93cc97ae0f6b09aa7ca43f" translate="yes" xml:space="preserve">
          <source>Whether to sample from the (Gaussian) predictive posterior of the fitted estimator for each imputation. Estimator must support &lt;code&gt;return_std&lt;/code&gt; in its &lt;code&gt;predict&lt;/code&gt; method if set to &lt;code&gt;True&lt;/code&gt;. Set to &lt;code&gt;True&lt;/code&gt; if using &lt;code&gt;IterativeImputer&lt;/code&gt; for multiple imputations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef9a1d5fe208dc604ffba3d0e60394e32f61bdb0" translate="yes" xml:space="preserve">
          <source>Whether to scale X and Y.</source>
          <target state="translated">Si la escala es X e Y.</target>
        </trans-unit>
        <trans-unit id="06ccde346dfb7273af2d0810793b1fb5e47df0dc" translate="yes" xml:space="preserve">
          <source>Whether to show informative labels for impurity, etc. Options include &amp;lsquo;all&amp;rsquo; to show at every node, &amp;lsquo;root&amp;rsquo; to show only at the top root node, or &amp;lsquo;none&amp;rsquo; to not show at any node.</source>
          <target state="translated">Ya sea para mostrar etiquetas informativas para impurezas, etc. Las opciones incluyen 'todos' para mostrar en cada nodo, 'ra&amp;iacute;z' para mostrar solo en el nodo ra&amp;iacute;z superior o 'ninguno' para no mostrar en ning&amp;uacute;n nodo.</target>
        </trans-unit>
        <trans-unit id="bcd035c2f558018eebfd4e5534f5df5bef89069a" translate="yes" xml:space="preserve">
          <source>Whether to shuffle dataset.</source>
          <target state="translated">Si hay que barajar el conjunto de datos.</target>
        </trans-unit>
        <trans-unit id="9ebdad6142b719150be2c8f67618dba47007c5fd" translate="yes" xml:space="preserve">
          <source>Whether to shuffle each class&amp;rsquo;s samples before splitting into batches. Note that the samples within each split will not be shuffled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8704d580bb26c2f6617363a0297f26abfb9fda30" translate="yes" xml:space="preserve">
          <source>Whether to shuffle each stratification of the data before splitting into batches.</source>
          <target state="translated">Si hay que barajar cada estratificación de los datos antes de dividirlos en lotes.</target>
        </trans-unit>
        <trans-unit id="5de7b9303caa771da78304a93ebeac224ba77f9b" translate="yes" xml:space="preserve">
          <source>Whether to shuffle samples in each iteration. Only used when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;.</source>
          <target state="translated">Ya sea para mezclar muestras en cada iteraci&amp;oacute;n. Solo se usa cuando solver = 'sgd' o 'adam'.</target>
        </trans-unit>
        <trans-unit id="3558a0c3a77b9ce3c242cc621a2d776c46a133af" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the data before splitting into batches.</source>
          <target state="translated">Si hay que mezclar los datos antes de dividirlos en lotes.</target>
        </trans-unit>
        <trans-unit id="2b23f04bb0d66dad8fab9e868398f1780b26b6ed" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the data before splitting into batches. Note that the samples within each split will not be shuffled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ddc8f26baf73b311e3fd82ce49af7a5449330660" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the data before splitting it in batches.</source>
          <target state="translated">Si hay que mezclar los datos antes de dividirlos en lotes.</target>
        </trans-unit>
        <trans-unit id="f23a63355a4e388bf6ee14cbad5c7c9c8b8c8007" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the samples.</source>
          <target state="translated">Si hay que mezclar las muestras.</target>
        </trans-unit>
        <trans-unit id="a5c75421672ae29d738aa02687f5d9f3ec0cf20c" translate="yes" xml:space="preserve">
          <source>Whether to shuffle training data before taking prefixes of it based on``train_sizes``.</source>
          <target state="translated">Si barajar los datos de entrenamiento antes de tomar los prefijos de los mismos basados en el tamaño del entrenamiento.</target>
        </trans-unit>
        <trans-unit id="ce33fd98a79a5db67d420efb6fcabed70acb96c4" translate="yes" xml:space="preserve">
          <source>Whether to sort x before computing. If False, assume that x must be either monotonic increasing or monotonic decreasing. If True, y is used to break ties when sorting x. Make sure that y has a monotonic relation to x when setting reorder to True.</source>
          <target state="translated">Si clasificar x antes de la computación.Si es falso,asume que x debe ser monótona aumentando o monótona disminuyendo.Si es Verdadero,y se utiliza para romper los lazos al clasificar x.Asegúrese de que y tiene una relación monótona con x al establecer el reordenamiento en Verdadero.</target>
        </trans-unit>
        <trans-unit id="5091491cac888f3972a1197cfef1256978c18b5f" translate="yes" xml:space="preserve">
          <source>Whether to split the sparse feature vector into the concatenation of its negative part and its positive part. This can improve the performance of downstream classifiers.</source>
          <target state="translated">Si dividir el vector de rasgos escasos en la concatenación de su parte negativa y su parte positiva.Esto puede mejorar el rendimiento de los clasificadores posteriores.</target>
        </trans-unit>
        <trans-unit id="8b58e41338c55eaf50346244bd6082e4f3c1a628" translate="yes" xml:space="preserve">
          <source>Whether to use Nesterov&amp;rsquo;s momentum. Only used when solver=&amp;rsquo;sgd&amp;rsquo; and momentum &amp;gt; 0.</source>
          <target state="translated">Ya sea para utilizar el impulso de Nesterov. Solo se usa cuando solver = 'sgd' y momentum&amp;gt; 0.</target>
        </trans-unit>
        <trans-unit id="6cb6c1fd9950933ec2b1bd309d3cbc04da69eccd" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram and Xy matrix to speed up calculations. Improves performance when &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-targets&quot;&gt;n_targets&lt;/a&gt; or &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-samples&quot;&gt;n_samples&lt;/a&gt; is very large. Note that if you already have such matrices, you can pass them directly to the fit method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d97545296a16ed9ee24e38ded3551b9344d66c64" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram and Xy matrix to speed up calculations. Improves performance when &lt;code&gt;n_targets&lt;/code&gt; or &lt;code&gt;n_samples&lt;/code&gt; is very large. Note that if you already have such matrices, you can pass them directly to the fit method.</source>
          <target state="translated">Ya sea para utilizar una matriz Gram y Xy precalculada para acelerar los c&amp;aacute;lculos. Mejora el rendimiento cuando &lt;code&gt;n_targets&lt;/code&gt; o &lt;code&gt;n_samples&lt;/code&gt; es muy grande. Tenga en cuenta que si ya tiene dichas matrices, puede pasarlas directamente al m&amp;eacute;todo de ajuste.</target>
        </trans-unit>
        <trans-unit id="7dc600168d6ae4c500452eb14badcdfddafb11ff" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. If set to &amp;lsquo;auto&amp;rsquo; let us decide. The Gram matrix can also be passed as argument, but it will be used only for the selection of parameter alpha, if alpha is &amp;lsquo;aic&amp;rsquo; or &amp;lsquo;bic&amp;rsquo;.</source>
          <target state="translated">Si utilizar una matriz Gram precalculada para acelerar los c&amp;aacute;lculos. Si se establece en 'auto', decidiremos. La matriz de Gram tambi&amp;eacute;n se puede pasar como argumento, pero se usar&amp;aacute; solo para la selecci&amp;oacute;n del par&amp;aacute;metro alfa, si alfa es 'aic' o 'bic'.</target>
        </trans-unit>
        <trans-unit id="0057a82fcc5e3ed086a2d1961e27e45b3f58597f" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. If set to &lt;code&gt;'auto'&lt;/code&gt; let us decide. The Gram matrix can also be passed as argument.</source>
          <target state="translated">Si utilizar una matriz Gram precalculada para acelerar los c&amp;aacute;lculos. Si se establece en &lt;code&gt;'auto'&lt;/code&gt; , decidiremos. La matriz de Gram tambi&amp;eacute;n se puede pasar como argumento.</target>
        </trans-unit>
        <trans-unit id="419f7e60c7c4f4f84360a1078ab4b36ce5bf208a" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. If set to &lt;code&gt;'auto'&lt;/code&gt; let us decide. The Gram matrix can also be passed as argument. For sparse input this option is always &lt;code&gt;True&lt;/code&gt; to preserve sparsity.</source>
          <target state="translated">Si utilizar una matriz Gram precalculada para acelerar los c&amp;aacute;lculos. Si se establece en &lt;code&gt;'auto'&lt;/code&gt; , decidiremos. La matriz de Gram tambi&amp;eacute;n se puede pasar como argumento. Para una entrada escasa, esta opci&amp;oacute;n siempre es &lt;code&gt;True&lt;/code&gt; para preservar la escasez.</target>
        </trans-unit>
        <trans-unit id="18cfe378dd4d6390fca460de4e70af73f097cdf4" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. If set to &lt;code&gt;'auto'&lt;/code&gt; let us decide. The Gram matrix cannot be passed as argument since we will use only subsets of X.</source>
          <target state="translated">Si utilizar una matriz Gram precalculada para acelerar los c&amp;aacute;lculos. Si se establece en &lt;code&gt;'auto'&lt;/code&gt; , decidiremos. La matriz de Gram no se puede pasar como argumento ya que solo usaremos subconjuntos de X.</target>
        </trans-unit>
        <trans-unit id="2bc24bd08e69b99e2a7b63ee3e5ac92e16a75bc1" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. The Gram matrix can also be passed as argument. For sparse input this option is always &lt;code&gt;True&lt;/code&gt; to preserve sparsity.</source>
          <target state="translated">Si utilizar una matriz Gram precalculada para acelerar los c&amp;aacute;lculos. La matriz de Gram tambi&amp;eacute;n se puede pasar como argumento. Para una entrada escasa, esta opci&amp;oacute;n siempre es &lt;code&gt;True&lt;/code&gt; para preservar la escasez.</target>
        </trans-unit>
        <trans-unit id="1efc80d653c0b8715eb15bdf1b19f3becd74a957" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to True, it will automatically set aside a fraction of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs.</source>
          <target state="translated">Si utilizar la parada temprana para terminar el entrenamiento cuando la puntuación de la validación no está mejorando.Si se establece en True,automáticamente dejará de lado una fracción de los datos de entrenamiento como validación y terminará el entrenamiento cuando la puntuación de validación no mejore por lo menos tol para n_iter_no_cambiar épocas consecutivas.</target>
        </trans-unit>
        <trans-unit id="46750b1ddce70e8be53fc930ce5b9a753b67b8f6" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to True, it will automatically set aside a fraction of training data as validation and terminate training when validation score returned by the &lt;code&gt;score&lt;/code&gt; method is not improving by at least &lt;code&gt;tol&lt;/code&gt; for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive epochs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="febff6e36a4dd65c498e48c75789d34dc34067ef" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to True, it will automatically set aside a stratified fraction of training data as validation and terminate training when validation score returned by the &lt;code&gt;score&lt;/code&gt; method is not improving by at least tol for n_iter_no_change consecutive epochs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9af303ba091050935df1b1843777cae63d69ca4c" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically set aside 10% of training data as validation and terminate training when validation score is not improving by at least &lt;code&gt;tol&lt;/code&gt; for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive epochs. Only effective when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;</source>
          <target state="translated">Si se debe utilizar la parada anticipada para finalizar el entrenamiento cuando la puntuaci&amp;oacute;n de validaci&amp;oacute;n no mejora. Si se establece en verdadero, autom&amp;aacute;ticamente reservar&amp;aacute; el 10% de los datos de entrenamiento como validaci&amp;oacute;n y finalizar&amp;aacute; el entrenamiento cuando la puntuaci&amp;oacute;n de validaci&amp;oacute;n no mejore al menos en &lt;code&gt;tol&lt;/code&gt; durante &lt;code&gt;n_iter_no_change&lt;/code&gt; &amp;eacute;pocas consecutivas. Solo es efectivo cuando solver = 'sgd' o 'adam'</target>
        </trans-unit>
        <trans-unit id="998484dc55c21823abb36e2b54f5b8f623a0a41f" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically set aside 10% of training data as validation and terminate training when validation score is not improving by at least tol for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive epochs. Only effective when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;</source>
          <target state="translated">Si se debe utilizar la parada anticipada para finalizar el entrenamiento cuando la puntuaci&amp;oacute;n de validaci&amp;oacute;n no mejora. Si se establece en verdadero, autom&amp;aacute;ticamente reservar&amp;aacute; el 10% de los datos de entrenamiento como validaci&amp;oacute;n y finalizar&amp;aacute; el entrenamiento cuando la puntuaci&amp;oacute;n de validaci&amp;oacute;n no mejore al menos en tol durante &lt;code&gt;n_iter_no_change&lt;/code&gt; &amp;eacute;pocas consecutivas. Solo es efectivo cuando solver = 'sgd' o 'adam'</target>
        </trans-unit>
        <trans-unit id="87617bcbcc672722844a1d3a57de3b252ff02aa0" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically set aside 10% of training data as validation and terminate training when validation score is not improving by at least tol for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive epochs. The split is stratified, except in a multilabel setting. Only effective when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cec695b146ca339e70be6934dce1a5005aa741f4" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation. score is not improving. If set to True, it will automatically set aside a fraction of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs.</source>
          <target state="translated">Si usar la parada temprana para terminar el entrenamiento cuando la validación.La puntuación no está mejorando.Si se establece en True,automáticamente dejará de lado una fracción de los datos de entrenamiento como validación y terminará el entrenamiento cuando la puntuación de la validación no mejore por lo menos tol para n_iter_no_cambiar épocas consecutivas.</target>
        </trans-unit>
        <trans-unit id="09b2b6c8cb36dc98a800b35af81d1805bc50fee1" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation. score is not improving. If set to True, it will automatically set aside a stratified fraction of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aad0324e5e5b11eda436b08ef9513e34456be6fd" translate="yes" xml:space="preserve">
          <source>Whether to use mini-batch k-means, which is faster but may get different results.</source>
          <target state="translated">Si usar o no el mini-batch k-means,que es más rápido pero puede obtener resultados diferentes.</target>
        </trans-unit>
        <trans-unit id="098e9f05a9707c21daca2709c375c5f67a6fc326" translate="yes" xml:space="preserve">
          <source>Whether to use out-of-bag samples to estimate the R^2 on unseen data.</source>
          <target state="translated">Si usar muestras fuera de la bolsa para estimar el R^2 en datos no vistos.</target>
        </trans-unit>
        <trans-unit id="cf1378e2f07c46392b05b68a8d3fb4a1b87de256" translate="yes" xml:space="preserve">
          <source>Whether to use out-of-bag samples to estimate the generalization accuracy.</source>
          <target state="translated">Si utilizar muestras fuera de la bolsa para estimar la precisión de la generalización.</target>
        </trans-unit>
        <trans-unit id="b9d7a8d80bd713aecc3b75a6342d626d4ac28b69" translate="yes" xml:space="preserve">
          <source>Whether to use out-of-bag samples to estimate the generalization error.</source>
          <target state="translated">Si utilizar muestras fuera de la bolsa para estimar el error de generalización.</target>
        </trans-unit>
        <trans-unit id="3aa24f38e2caae33363ee03e7cecc2915d7b4a6e" translate="yes" xml:space="preserve">
          <source>Whether to use the shrinking heuristic.</source>
          <target state="translated">Si usar o no el heurístico encogimiento.</target>
        </trans-unit>
        <trans-unit id="f030250afefd9a8186bdcbf55c79f9c30e8d6a17" translate="yes" xml:space="preserve">
          <source>Whether to use the shrinking heuristic. See the &lt;a href=&quot;../svm#shrinking-svm&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fcee6cb3493ee9e39e4cf5b70ffc63bc5b7fc72" translate="yes" xml:space="preserve">
          <source>Whether to zip the stored data on disk. If an integer is given, it should be between 1 and 9, and sets the amount of compression. Note that compressed arrays cannot be read by memmapping.</source>
          <target state="translated">Si se debe cerrar los datos almacenados en el disco.Si se da un número entero,debería estar entre 1 y 9,y establece la cantidad de compresión.Tenga en cuenta que las matrices comprimidas no pueden ser leídas por el memmapping.</target>
        </trans-unit>
        <trans-unit id="67c666eda0eb6c9f89cf06ca0fe8ba3d19260935" translate="yes" xml:space="preserve">
          <source>Whether transform should produce scipy.sparse matrices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8c18609d5573425cb13e22e1562611896bad931" translate="yes" xml:space="preserve">
          <source>Whether transform should produce scipy.sparse matrices. True by default.</source>
          <target state="translated">Si la transformación debe producir matrices scipy.sparse.Cierto por defecto.</target>
        </trans-unit>
        <trans-unit id="a2a2f7408a4ab356f12406498e7b656415a8f8e4" translate="yes" xml:space="preserve">
          <source>Whether y_prob needs to be normalized into the [0, 1] interval, i.e. is not a proper probability. If True, the smallest value in y_prob is linearly mapped onto 0 and the largest one onto 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96e3c213b0373954a6f42c2953a288bf58e9c8e1" translate="yes" xml:space="preserve">
          <source>Whether y_prob needs to be normalized into the bin [0, 1], i.e. is not a proper probability. If True, the smallest value in y_prob is mapped onto 0 and the largest one onto 1.</source>
          <target state="translated">Si y_prob necesita ser normalizado en el bin [0,1],es decir,no es una probabilidad adecuada.Si es True,el valor más pequeño de y_prob se asigna a 0 y el más grande a 1.</target>
        </trans-unit>
        <trans-unit id="673ccf9c3156ee120e948d124a09a8f79d0986df" translate="yes" xml:space="preserve">
          <source>Which SVD method to use. If &amp;lsquo;lapack&amp;rsquo; use standard SVD from scipy.linalg, if &amp;lsquo;randomized&amp;rsquo; use fast &lt;code&gt;randomized_svd&lt;/code&gt; function. Defaults to &amp;lsquo;randomized&amp;rsquo;. For most applications &amp;lsquo;randomized&amp;rsquo; will be sufficiently precise while providing significant speed gains. Accuracy can also be improved by setting higher values for &lt;code&gt;iterated_power&lt;/code&gt;. If this is not sufficient, for maximum precision you should choose &amp;lsquo;lapack&amp;rsquo;.</source>
          <target state="translated">Qu&amp;eacute; m&amp;eacute;todo de SVD utilizar. Si 'lapack' usa SVD est&amp;aacute;ndar de scipy.linalg, si 'randomized' usa la funci&amp;oacute;n r&amp;aacute;pida &lt;code&gt;randomized_svd&lt;/code&gt; . El valor predeterminado es &quot;aleatorio&quot;. Para la mayor&amp;iacute;a de las aplicaciones, &quot;aleatorio&quot; ser&amp;aacute; lo suficientemente preciso al tiempo que proporcionar&amp;aacute; importantes ganancias de velocidad. La precisi&amp;oacute;n tambi&amp;eacute;n se puede mejorar estableciendo valores m&amp;aacute;s altos para &lt;code&gt;iterated_power&lt;/code&gt; . Si esto no es suficiente, para obtener la m&amp;aacute;xima precisi&amp;oacute;n, debe elegir 'lapack'.</target>
        </trans-unit>
        <trans-unit id="3f4bd36722594cddb9c4f04fa1feac290cb2c703" translate="yes" xml:space="preserve">
          <source>Which affinity to use. At the moment &amp;lsquo;precomputed&amp;rsquo; and &lt;code&gt;euclidean&lt;/code&gt; are supported. &amp;lsquo;euclidean&amp;rsquo; uses the negative squared euclidean distance between points.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f51286fa5438dabdb2fdc9e6a35c79244bd208d2" translate="yes" xml:space="preserve">
          <source>Which affinity to use. At the moment &lt;code&gt;precomputed&lt;/code&gt; and &lt;code&gt;euclidean&lt;/code&gt; are supported. &lt;code&gt;euclidean&lt;/code&gt; uses the negative squared euclidean distance between points.</source>
          <target state="translated">Qu&amp;eacute; afinidad usar. Actualmente se soportan &lt;code&gt;precomputed&lt;/code&gt; y &lt;code&gt;euclidean&lt;/code&gt; . &lt;code&gt;euclidean&lt;/code&gt; utiliza la distancia euclidiana al cuadrado negativo entre puntos.</target>
        </trans-unit>
        <trans-unit id="0a291d7f5d694ce4dae77d370f938e385f2f41cf" translate="yes" xml:space="preserve">
          <source>Which kind of estimators should be returned. If None, no filter is applied and all estimators are returned. Possible values are &amp;lsquo;classifier&amp;rsquo;, &amp;lsquo;regressor&amp;rsquo;, &amp;lsquo;cluster&amp;rsquo; and &amp;lsquo;transformer&amp;rsquo; to get estimators only of these specific types, or a list of these to get the estimators that fit at least one of the types.</source>
          <target state="translated">Qu&amp;eacute; tipo de estimadores deben devolverse. Si es Ninguno, no se aplica ning&amp;uacute;n filtro y se devuelven todos los estimadores. Los valores posibles son 'clasificador', 'regresor', 'agrupaci&amp;oacute;n' y 'transformador' para obtener estimadores solo de estos tipos espec&amp;iacute;ficos, o una lista de estos para obtener los estimadores que se ajustan al menos a uno de los tipos.</target>
        </trans-unit>
        <trans-unit id="9ab873abc046d5e79c6628d1e73d15a9a8c8a011" translate="yes" xml:space="preserve">
          <source>Which linkage criterion to use. The linkage criterion determines which distance to use between sets of features. The algorithm will merge the pairs of cluster that minimize this criterion.</source>
          <target state="translated">Qué criterio de vinculación utilizar.El criterio de vinculación determina qué distancia usar entre los conjuntos de características.El algoritmo fusionará los pares de cúmulos que minimizan este criterio.</target>
        </trans-unit>
        <trans-unit id="17ba6fc895d15866ea1e60a4db791726755dc58f" translate="yes" xml:space="preserve">
          <source>Which linkage criterion to use. The linkage criterion determines which distance to use between sets of observation. The algorithm will merge the pairs of cluster that minimize this criterion.</source>
          <target state="translated">Qué criterio de vinculación utilizar.El criterio de vinculación determina qué distancia usar entre los conjuntos de observación.El algoritmo fusionará los pares de cúmulos que minimizan este criterio.</target>
        </trans-unit>
        <trans-unit id="7c032065ee1e199d65a12de581955d2510001155" translate="yes" xml:space="preserve">
          <source>Which metric to use for computing pairwise distances between samples from the original input space. If metric is &amp;lsquo;precomputed&amp;rsquo;, X must be a matrix of pairwise distances or squared distances. Otherwise, see the documentation of argument metric in sklearn.pairwise.pairwise_distances for a list of available metrics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ca40022d1c5dcd68056f855d9cb29fbb48c9062" translate="yes" xml:space="preserve">
          <source>Which model is the best is a matter of subjective judgement: do we want to favor models that only capture the big picture to summarize and explain most of the structure of the data while ignoring the details or do we prefer models that closely follow the high density regions of the signal?</source>
          <target state="translated">Qué modelo es el mejor es una cuestión de juicio subjetivo:¿Queremos favorecer los modelos que sólo captan el panorama general para resumir y explicar la mayor parte de la estructura de los datos ignorando los detalles o preferimos los modelos que siguen de cerca las regiones de alta densidad de la señal?</target>
        </trans-unit>
        <trans-unit id="3bad9460d63c46d91cb72ce5e70c801fdf7d8e5b" translate="yes" xml:space="preserve">
          <source>Which model is the best is a matter of subjective judgment: do we want to favor models that only capture the big picture to summarize and explain most of the structure of the data while ignoring the details or do we prefer models that closely follow the high density regions of the signal?</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9b07db46ccf2aab5a3f471f9311e28ace0c3658" translate="yes" xml:space="preserve">
          <source>Which strategy to use to initialize the missing values. Same as the &lt;code&gt;strategy&lt;/code&gt; parameter in &lt;a href=&quot;sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;sklearn.impute.SimpleImputer&lt;/code&gt;&lt;/a&gt; Valid values: {&amp;ldquo;mean&amp;rdquo;, &amp;ldquo;median&amp;rdquo;, &amp;ldquo;most_frequent&amp;rdquo;, or &amp;ldquo;constant&amp;rdquo;}.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8cddae54ed0b1b16ee030ff58543e83ff547ded" translate="yes" xml:space="preserve">
          <source>While Isomap, LLE and variants are best suited to unfold a single continuous low dimensional manifold, t-SNE will focus on the local structure of the data and will tend to extract clustered local groups of samples as highlighted on the S-curve example. This ability to group samples based on the local structure might be beneficial to visually disentangle a dataset that comprises several manifolds at once as is the case in the digits dataset.</source>
          <target state="translated">Mientras que el Isomap,el LLE y sus variantes son los más adecuados para desplegar un único colector continuo de baja dimensión,el t-SNE se centrará en la estructura local de los datos y tenderá a extraer grupos locales agrupados de muestras,como se destaca en el ejemplo de la curva S.Esta capacidad de agrupar muestras en función de la estructura local podría ser beneficiosa para desentrañar visualmente un conjunto de datos que comprende varios colectores a la vez,como ocurre en el conjunto de datos de los dígitos.</target>
        </trans-unit>
        <trans-unit id="d80a7676bafb31f5f9bcb99f7aed7e1817a9d535" translate="yes" xml:space="preserve">
          <source>While SVM models derived from &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; and &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; use &lt;code&gt;C&lt;/code&gt; as regularization parameter, most other estimators use &lt;code&gt;alpha&lt;/code&gt;. The exact equivalence between the amount of regularization of two models depends on the exact objective function optimized by the model. For example, when the estimator used is &lt;code&gt;sklearn.linear_model.Ridge&lt;/code&gt; regression, the relation between them is given as \(C = \frac{1}{alpha}\).</source>
          <target state="translated">Mientras que los modelos SVM derivados de &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; y &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; usan &lt;code&gt;C&lt;/code&gt; como par&amp;aacute;metro de regularizaci&amp;oacute;n, la mayor&amp;iacute;a de los dem&amp;aacute;s estimadores usan &lt;code&gt;alpha&lt;/code&gt; . La equivalencia exacta entre la cantidad de regularizaci&amp;oacute;n de dos modelos depende de la funci&amp;oacute;n objetivo exacta optimizada por el modelo. Por ejemplo, cuando el estimador utilizado es &lt;code&gt;sklearn.linear_model.Ridge&lt;/code&gt; regression, la relaci&amp;oacute;n entre ellos se da como \ (C = \ frac {1} {alpha} \).</target>
        </trans-unit>
        <trans-unit id="e19b90ac75c89776c8025a4fe5ef49998061f2d2" translate="yes" xml:space="preserve">
          <source>While SVM models derived from &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; and &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; use &lt;code&gt;C&lt;/code&gt; as regularization parameter, most other estimators use &lt;code&gt;alpha&lt;/code&gt;. The exact equivalence between the amount of regularization of two models depends on the exact objective function optimized by the model. For example, when the estimator used is &lt;code&gt;sklearn.linear_model.Ridge&lt;/code&gt; regression, the relation between them is given as \(C = \frac{1}{alpha}\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b688dd0a76a7a11c780bc8304b263ca13e9c529b" translate="yes" xml:space="preserve">
          <source>While both methods should be close in general, they might differ in some specific settings. The &amp;lsquo;brute&amp;rsquo; method assumes the existence of the data points \((x_S, x_C^{(i)})\). When the features are correlated, such artificial samples may have a very low probability mass. The &amp;lsquo;brute&amp;rsquo; and &amp;lsquo;recursion&amp;rsquo; methods will likely disagree regarding the value of the partial dependence, because they will treat these unlikely samples differently. Remember, however, that the primary assumption for interpreting PDPs is that the features should be independent.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb6c7d447c33735b14bfab3f939085b49d50d551" translate="yes" xml:space="preserve">
          <source>While defining the custom scoring function alongside the calling function should work out of the box with the default joblib backend (loky), importing it from another module will be a more robust approach and work independently of the joblib backend.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c20daeb41107431c48223b43ad4fe138aa4845d5" translate="yes" xml:space="preserve">
          <source>While experimenting with any learning algorithm, it is important not to test the prediction of an estimator on the data used to fit the estimator as this would not be evaluating the performance of the estimator on &lt;strong&gt;new data&lt;/strong&gt;. This is why datasets are often split into &lt;em&gt;train&lt;/em&gt; and &lt;em&gt;test&lt;/em&gt; data.</source>
          <target state="translated">Al experimentar con cualquier algoritmo de aprendizaje, es importante no probar la predicci&amp;oacute;n de un estimador en los datos utilizados para ajustar el estimador, ya que esto no estar&amp;iacute;a evaluando el rendimiento del estimador en &lt;strong&gt;datos nuevos&lt;/strong&gt; . Esta es la raz&amp;oacute;n por la que los conjuntos de datos a menudo se dividen en datos de &lt;em&gt;prueba&lt;/em&gt; y de &lt;em&gt;tren&lt;/em&gt; .&lt;em&gt;&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="f8808630553e3f4de197fcbd8d96757a9a769400" translate="yes" xml:space="preserve">
          <source>While i.i.d. data is a common assumption in machine learning theory, it rarely holds in practice. If one knows that the samples have been generated using a time-dependent process, it is safer to use a &lt;a href=&quot;#timeseries-cv&quot;&gt;time-series aware cross-validation scheme&lt;/a&gt;. Similarly, if we know that the generative process has a group structure (samples collected from different subjects, experiments, measurement devices), it is safer to use &lt;a href=&quot;#group-cv&quot;&gt;group-wise cross-validation&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d04cd5b9d0463d9bc89f841d571873fec4953569" translate="yes" xml:space="preserve">
          <source>While i.i.d. data is a common assumption in machine learning theory, it rarely holds in practice. If one knows that the samples have been generated using a time-dependent process, it&amp;rsquo;s safer to use a &lt;a href=&quot;#timeseries-cv&quot;&gt;time-series aware cross-validation scheme&lt;/a&gt; Similarly if we know that the generative process has a group structure (samples from collected from different subjects, experiments, measurement devices) it safer to use &lt;a href=&quot;#group-cv&quot;&gt;group-wise cross-validation&lt;/a&gt;.</source>
          <target state="translated">Si bien los datos iid son una suposici&amp;oacute;n com&amp;uacute;n en la teor&amp;iacute;a del aprendizaje autom&amp;aacute;tico, rara vez se cumplen en la pr&amp;aacute;ctica. Si uno sabe que las muestras se han generado mediante un proceso dependiente del tiempo, es m&amp;aacute;s seguro utilizar un &lt;a href=&quot;#timeseries-cv&quot;&gt;esquema de validaci&amp;oacute;n cruzada consciente de series de tiempo.De&lt;/a&gt; manera similar, si sabemos que el proceso generativo tiene una estructura de grupo (muestras de diferentes sujetos, experimentos , dispositivos de medici&amp;oacute;n) es m&amp;aacute;s seguro utilizar la &lt;a href=&quot;#group-cv&quot;&gt;validaci&amp;oacute;n cruzada por grupos&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0526a7a936d1a8c691dcdaa23691304fc8ebc7ef" translate="yes" xml:space="preserve">
          <source>While in the spirit of an online algorithm, the class &lt;a href=&quot;generated/sklearn.decomposition.minibatchsparsepca#sklearn.decomposition.MiniBatchSparsePCA&quot;&gt;&lt;code&gt;MiniBatchSparsePCA&lt;/code&gt;&lt;/a&gt; does not implement &lt;code&gt;partial_fit&lt;/code&gt; because the algorithm is online along the features direction, not the samples direction.</source>
          <target state="translated">Mientras que en el esp&amp;iacute;ritu de un algoritmo en l&amp;iacute;nea, la clase &lt;a href=&quot;generated/sklearn.decomposition.minibatchsparsepca#sklearn.decomposition.MiniBatchSparsePCA&quot;&gt; &lt;code&gt;MiniBatchSparsePCA&lt;/code&gt; &lt;/a&gt; no implementa &lt;code&gt;partial_fit&lt;/code&gt; porque el algoritmo es en l&amp;iacute;nea a lo largo de la direcci&amp;oacute;n caracter&amp;iacute;sticas, no la direcci&amp;oacute;n muestras.</target>
        </trans-unit>
        <trans-unit id="c8d4a37562dd2bb8e9910fd82f43df80f682c63a" translate="yes" xml:space="preserve">
          <source>While many algorithms (such as SVM, K-nearest neighbors, and logistic regression) require features to be normalized, intuitively we can think of Principle Component Analysis (PCA) as being a prime example of when normalization is important. In PCA we are interested in the components that maximize the variance. If one component (e.g. human height) varies less than another (e.g. weight) because of their respective scales (meters vs. kilos), PCA might determine that the direction of maximal variance more closely corresponds with the &amp;lsquo;weight&amp;rsquo; axis, if those features are not scaled. As a change in height of one meter can be considered much more important than the change in weight of one kilogram, this is clearly incorrect.</source>
          <target state="translated">Si bien muchos algoritmos (como SVM, K vecinos m&amp;aacute;s cercanos y regresi&amp;oacute;n log&amp;iacute;stica) requieren que las caracter&amp;iacute;sticas se normalicen, intuitivamente podemos pensar en el An&amp;aacute;lisis de componentes principales (PCA) como un excelente ejemplo de cu&amp;aacute;ndo la normalizaci&amp;oacute;n es importante. En PCA estamos interesados ​​en los componentes que maximizan la varianza. Si un componente (por ejemplo, la altura humana) var&amp;iacute;a menos que otro (por ejemplo, el peso) debido a sus respectivas escalas (metros frente a kilos), la PCA podr&amp;iacute;a determinar que la direcci&amp;oacute;n de la varianza m&amp;aacute;xima se corresponde m&amp;aacute;s estrechamente con el eje de 'peso', si esas caracter&amp;iacute;sticas no est&amp;aacute;n escalados. Como un cambio de altura de un metro puede considerarse mucho m&amp;aacute;s importante que el cambio de peso de un kilogramo, esto es claramente incorrecto.</target>
        </trans-unit>
        <trans-unit id="3e272f5577ff59f34cc0835d41b4f8bd0e7fa207" translate="yes" xml:space="preserve">
          <source>While models saved using one version of scikit-learn might load in other versions, this is entirely unsupported and inadvisable. It should also be kept in mind that operations performed on such data could give different and unexpected results.</source>
          <target state="translated">Aunque los modelos guardados con una versión de scikit-learn pueden cargarse en otras versiones,esto no tiene ningún soporte y no es aconsejable.También hay que tener en cuenta que las operaciones realizadas con esos datos podrían dar resultados diferentes e inesperados.</target>
        </trans-unit>
        <trans-unit id="5cdd1c0f02e03a5a1b156076678017404f8561ab" translate="yes" xml:space="preserve">
          <source>While multiclass data is provided to the metric, like binary targets, as an array of class labels, multilabel data is specified as an indicator matrix, in which cell &lt;code&gt;[i, j]&lt;/code&gt; has value 1 if sample &lt;code&gt;i&lt;/code&gt; has label &lt;code&gt;j&lt;/code&gt; and value 0 otherwise.</source>
          <target state="translated">Mientras que los datos multiclase se proporcionan a la m&amp;eacute;trica, como los objetivos binarios, como una matriz de etiquetas de clase, los datos de varias etiquetas se especifican como una matriz de indicador, en la que la celda &lt;code&gt;[i, j]&lt;/code&gt; tiene el valor 1 si la muestra &lt;code&gt;i&lt;/code&gt; tiene la etiqueta &lt;code&gt;j&lt;/code&gt; y el valor 0 en caso contrario .</target>
        </trans-unit>
        <trans-unit id="ed422f68a65d31027201e13d55d1a7c59ba06f45" translate="yes" xml:space="preserve">
          <source>While not particularly fast to process, Python&amp;rsquo;s &lt;code&gt;dict&lt;/code&gt; has the advantages of being convenient to use, being sparse (absent features need not be stored) and storing feature names in addition to values.</source>
          <target state="translated">Si bien no es particularmente r&amp;aacute;pido de procesar, el &lt;code&gt;dict&lt;/code&gt; ado de Python tiene las ventajas de ser c&amp;oacute;modo de usar, ser escaso (no es necesario almacenar las caracter&amp;iacute;sticas ausentes) y almacenar nombres de caracter&amp;iacute;sticas adem&amp;aacute;s de valores.</target>
        </trans-unit>
        <trans-unit id="6575e62afd8d9d86f5e5759f0c1f4bf12add49e4" translate="yes" xml:space="preserve">
          <source>While some local positioning information can be preserved by extracting n-grams instead of individual words, bag of words and bag of n-grams destroy most of the inner structure of the document and hence most of the meaning carried by that internal structure.</source>
          <target state="translated">Mientras que cierta información de posicionamiento local puede preservarse extrayendo n-gramas en lugar de palabras individuales,el saco de palabras y el saco de n-gramas destruyen la mayor parte de la estructura interna del documento y,por lo tanto,la mayor parte del significado que lleva esa estructura interna.</target>
        </trans-unit>
        <trans-unit id="f9eb71a899b2efe02a5e86463ae919f1b60ed0f7" translate="yes" xml:space="preserve">
          <source>While the &lt;a href=&quot;generated/sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt;&lt;code&gt;TruncatedSVD&lt;/code&gt;&lt;/a&gt; transformer works with any (sparse) feature matrix, using it on tf&amp;ndash;idf matrices is recommended over raw frequency counts in an LSA/document processing setting. In particular, sublinear scaling and inverse document frequency should be turned on (&lt;code&gt;sublinear_tf=True, use_idf=True&lt;/code&gt;) to bring the feature values closer to a Gaussian distribution, compensating for LSA&amp;rsquo;s erroneous assumptions about textual data.</source>
          <target state="translated">Si bien el transformador &lt;a href=&quot;generated/sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt; &lt;code&gt;TruncatedSVD&lt;/code&gt; &lt;/a&gt; funciona con cualquier matriz de caracter&amp;iacute;sticas (escasa), se recomienda su uso en matrices tf-idf sobre los conteos de frecuencia sin procesar en una configuraci&amp;oacute;n de procesamiento de documentos / LSA. En particular, la escala sublineal y la frecuencia inversa del documento deben &lt;code&gt;sublinear_tf=True, use_idf=True&lt;/code&gt; ( sublinear_tf = True, use_idf = True ) para acercar los valores de las caracter&amp;iacute;sticas a una distribuci&amp;oacute;n gaussiana, compensando las suposiciones err&amp;oacute;neas de LSA sobre los datos textuales.</target>
        </trans-unit>
        <trans-unit id="f9e8e04743afddc659f8d58efbc124813976ac9e" translate="yes" xml:space="preserve">
          <source>While the &lt;a href=&quot;generated/sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt;&lt;code&gt;TruncatedSVD&lt;/code&gt;&lt;/a&gt; transformer works with any feature matrix, using it on tf&amp;ndash;idf matrices is recommended over raw frequency counts in an LSA/document processing setting. In particular, sublinear scaling and inverse document frequency should be turned on (&lt;code&gt;sublinear_tf=True, use_idf=True&lt;/code&gt;) to bring the feature values closer to a Gaussian distribution, compensating for LSA&amp;rsquo;s erroneous assumptions about textual data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29a2650e25fbd5181744282ce886a2b96e4ac93d" translate="yes" xml:space="preserve">
          <source>While the above example sets the &lt;code&gt;standardize&lt;/code&gt; option to &lt;code&gt;False&lt;/code&gt;, &lt;a href=&quot;generated/sklearn.preprocessing.powertransformer#sklearn.preprocessing.PowerTransformer&quot;&gt;&lt;code&gt;PowerTransformer&lt;/code&gt;&lt;/a&gt; will apply zero-mean, unit-variance normalization to the transformed output by default.</source>
          <target state="translated">Mientras que el ejemplo anterior establece la opci&amp;oacute;n de &lt;code&gt;standardize&lt;/code&gt; en &lt;code&gt;False&lt;/code&gt; , &lt;a href=&quot;generated/sklearn.preprocessing.powertransformer#sklearn.preprocessing.PowerTransformer&quot;&gt; &lt;code&gt;PowerTransformer&lt;/code&gt; &lt;/a&gt; aplicar&amp;aacute; la normalizaci&amp;oacute;n de varianza unitaria de media cero a la salida transformada de forma predeterminada.</target>
        </trans-unit>
        <trans-unit id="e50cabfff84e84e9590f53c8299406f023e4e46d" translate="yes" xml:space="preserve">
          <source>While the hyperparameters chosen by optimizing LML have a considerable larger LML, they perform slightly worse according to the log-loss on test data. The figure shows that this is because they exhibit a steep change of the class probabilities at the class boundaries (which is good) but have predicted probabilities close to 0.5 far away from the class boundaries (which is bad) This undesirable effect is caused by the Laplace approximation used internally by GPC.</source>
          <target state="translated">Si bien los hiperparámetros elegidos al optimizar la LML tienen una LML considerablemente mayor,su rendimiento es ligeramente peor según el registro de pérdida de datos de las pruebas.La figura muestra que esto se debe a que exhiben un cambio pronunciado de las probabilidades de clase en los límites de la clase (lo cual es bueno)pero tienen probabilidades pronosticadas cercanas a 0,5 lejos de los límites de la clase (lo cual es malo)Este efecto indeseable es causado por la aproximación de Laplace utilizada internamente por GPC.</target>
        </trans-unit>
        <trans-unit id="2c9458b61e67bda12a1df752c0cc6921b6ff30dd" translate="yes" xml:space="preserve">
          <source>While the parameter &lt;code&gt;min_samples&lt;/code&gt; primarily controls how tolerant the algorithm is towards noise (on noisy and large data sets it may be desirable to increase this parameter), the parameter &lt;code&gt;eps&lt;/code&gt; is &lt;em&gt;crucial to choose appropriately&lt;/em&gt; for the data set and distance function and usually cannot be left at the default value. It controls the local neighborhood of the points. When chosen too small, most data will not be clustered at all (and labeled as &lt;code&gt;-1&lt;/code&gt; for &amp;ldquo;noise&amp;rdquo;). When chosen too large, it causes close clusters to be merged into one cluster, and eventually the entire data set to be returned as a single cluster. Some heuristics for choosing this parameter have been discussed in the literature, for example based on a knee in the nearest neighbor distances plot (as discussed in the references below).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17e6df329175ba9fee759ed839a4afe469b184fd" translate="yes" xml:space="preserve">
          <source>While the tf&amp;ndash;idf normalization is often very useful, there might be cases where the binary occurrence markers might offer better features. This can be achieved by using the &lt;code&gt;binary&lt;/code&gt; parameter of &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;. In particular, some estimators such as &lt;a href=&quot;naive_bayes#bernoulli-naive-bayes&quot;&gt;Bernoulli Naive Bayes&lt;/a&gt; explicitly model discrete boolean random variables. Also, very short texts are likely to have noisy tf&amp;ndash;idf values while the binary occurrence info is more stable.</source>
          <target state="translated">Si bien la normalizaci&amp;oacute;n tf-idf suele ser muy &amp;uacute;til, puede haber casos en los que los marcadores de ocurrencia binarios ofrezcan mejores caracter&amp;iacute;sticas. Esto se puede lograr utilizando el par&amp;aacute;metro &lt;code&gt;binary&lt;/code&gt; de &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; . En particular, algunos estimadores como &lt;a href=&quot;naive_bayes#bernoulli-naive-bayes&quot;&gt;Bernoulli Naive Bayes&lt;/a&gt; modelan expl&amp;iacute;citamente variables aleatorias booleanas discretas. Adem&amp;aacute;s, es probable que los textos muy cortos tengan valores tf-idf ruidosos mientras que la informaci&amp;oacute;n binaria de ocurrencia es m&amp;aacute;s estable.</target>
        </trans-unit>
        <trans-unit id="ed181b0221327c005991b804ef6da84808fa6b75" translate="yes" xml:space="preserve">
          <source>While these examples give some intuition about the algorithms, this intuition might not apply to very high dimensional data.</source>
          <target state="translated">Aunque estos ejemplos dan cierta intuición sobre los algoritmos,esta intuición podría no aplicarse a datos dimensionales muy elevados.</target>
        </trans-unit>
        <trans-unit id="20e141fdf1f5d5d16051f029790d3b9e841c723d" translate="yes" xml:space="preserve">
          <source>While using a grid of parameter settings is currently the most widely used method for parameter optimization, other search methods have more favourable properties. &lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt;&lt;code&gt;RandomizedSearchCV&lt;/code&gt;&lt;/a&gt; implements a randomized search over parameters, where each setting is sampled from a distribution over possible parameter values. This has two main benefits over an exhaustive search:</source>
          <target state="translated">Si bien el uso de una cuadr&amp;iacute;cula de configuraciones de par&amp;aacute;metros es actualmente el m&amp;eacute;todo m&amp;aacute;s utilizado para la optimizaci&amp;oacute;n de par&amp;aacute;metros, otros m&amp;eacute;todos de b&amp;uacute;squeda tienen propiedades m&amp;aacute;s favorables. &lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt; &lt;code&gt;RandomizedSearchCV&lt;/code&gt; &lt;/a&gt; implementa una b&amp;uacute;squeda aleatoria de par&amp;aacute;metros, donde cada configuraci&amp;oacute;n se muestrea a partir de una distribuci&amp;oacute;n de posibles valores de par&amp;aacute;metros. Esto tiene dos ventajas principales sobre una b&amp;uacute;squeda exhaustiva:</target>
        </trans-unit>
        <trans-unit id="37619fc13053f82b7cb7da3d24ceb1598ab6d05c" translate="yes" xml:space="preserve">
          <source>White</source>
          <target state="translated">White</target>
        </trans-unit>
        <trans-unit id="ae7c1638fd1917cb535ca7c68b4bd5f19a47ea30" translate="yes" xml:space="preserve">
          <source>White kernel.</source>
          <target state="translated">Núcleo blanco.</target>
        </trans-unit>
        <trans-unit id="6eaf9e8193566018ccba0d72a95d7647c23f2585" translate="yes" xml:space="preserve">
          <source>Whitening will remove some information from the transformed signal (the relative variance scales of the components) but can sometime improve the predictive accuracy of the downstream estimators by making their data respect some hard-wired assumptions.</source>
          <target state="translated">El blanqueamiento eliminará parte de la información de la señal transformada (las escalas de varianza relativa de los componentes)pero a veces puede mejorar la exactitud de la predicción de los estimadores posteriores al hacer que sus datos respeten algunas suposiciones bien fundamentadas.</target>
        </trans-unit>
        <trans-unit id="07aaa00ad7b994406ce70b8bd7598f7e15e6859a" translate="yes" xml:space="preserve">
          <source>Whitening will remove some information from the transformed signal (the relative variance scales of the components) but can sometimes improve the predictive accuracy of the downstream estimators by making data respect some hard-wired assumptions.</source>
          <target state="translated">El blanqueamiento eliminará parte de la información de la señal transformada (las escalas de varianza relativa de los componentes)pero a veces puede mejorar la exactitud de la predicción de los estimadores posteriores al hacer que los datos respeten algunas suposiciones bien fundadas.</target>
        </trans-unit>
        <trans-unit id="c6caecec2578a0de52910be667f4fa7e322f3d31" translate="yes" xml:space="preserve">
          <source>Why does the plot above suggest that an increase in age leads to a decrease in wage? Why the &lt;a href=&quot;#marginal-dependencies&quot;&gt;initial pairplot&lt;/a&gt; is telling the opposite?</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5ed864ec9d16ad31c6639d1d4c3bf64e3372001" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for Davies-Bouldin index.</source>
          <target state="translated">Entrada de Wikipedia para el índice de Davies-Bouldin.</target>
        </trans-unit>
        <trans-unit id="3ce8e9b9f756deae78c09a314c4cf49a1aacdb66" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for Discounted Cumulative Gain</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0184957526e21d06d99d8f077fe30eb4aaec4f9" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for contingency matrix</source>
          <target state="translated">Entrada de Wikipedia para la matriz de contingencia</target>
        </trans-unit>
        <trans-unit id="55a3b17abc1268c1d436ba897c97b456b993b4ea" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the (normalized) Mutual Information</source>
          <target state="translated">Entrada de Wikipedia para la Información Mutua (normalizada)</target>
        </trans-unit>
        <trans-unit id="1f069c9fec7504cb4f8a493de2e1b54ffc547081" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Adjusted Mutual Information</source>
          <target state="translated">La entrada de Wikipedia para la Información Mutua Ajustada</target>
        </trans-unit>
        <trans-unit id="8030a2f6eb81271b3b56dfad08af7aaea7fcfc10" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Average precision</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca2fe3eff096e2c0ff94d3c0f6ce61af74cc646f" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Brier score.</source>
          <target state="translated">Entrada de Wikipedia para la puntuación de Brier.</target>
        </trans-unit>
        <trans-unit id="ffd655e9eb3a21416da69aac696bc5ce043a000f" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Cohen&amp;rsquo;s kappa.</source>
          <target state="translated">Entrada de Wikipedia para el kappa de Cohen.</target>
        </trans-unit>
        <trans-unit id="8d8ae14fc3bcf00321ca2d4b9c37c609195c6275" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the F1-score</source>
          <target state="translated">La entrada de Wikipedia para el puntaje de F1</target>
        </trans-unit>
        <trans-unit id="0d85777073541b6f8aecb3488f1962f6903fd77c" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Fowlkes-Mallows Index</source>
          <target state="translated">Entrada de Wikipedia para el índice Fowlkes-Mallows</target>
        </trans-unit>
        <trans-unit id="738fb31d9583a6207339f58c0335e89437aa096f" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Jaccard index</source>
          <target state="translated">Entrada de Wikipedia para el índice Jaccard</target>
        </trans-unit>
        <trans-unit id="d69dce297a7e32abae3549494346594b424875bc" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Matthews Correlation Coefficient</source>
          <target state="translated">Entrada de Wikipedia para el Coeficiente de Correlación de Matthews</target>
        </trans-unit>
        <trans-unit id="d1c0692994293b3fef98ac5de7dd74e23175c8d1" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Precision and recall</source>
          <target state="translated">La entrada de Wikipedia para la precisión y la retirada</target>
        </trans-unit>
        <trans-unit id="6c2dd7ccbd3afed766d1ee6ce92b068445c27bbb" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Receiver operating characteristic</source>
          <target state="translated">Entrada de Wikipedia para la característica de funcionamiento del receptor</target>
        </trans-unit>
        <trans-unit id="caae1d529b64ebeb0d4804273e9107122a389ac6" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the adjusted Rand index</source>
          <target state="translated">Entrada de Wikipedia para el índice Rand ajustado</target>
        </trans-unit>
        <trans-unit id="ccc412d2bb1bb2397fbce7363889e5816eda01a2" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on Neighborhood Components Analysis</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b36309de0386ff9491f5f72624bcd77d6a05e19" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on Neighborhood Components Analysis &lt;a href=&quot;https://en.wikipedia.org/wiki/Neighbourhood_components_analysis&quot;&gt;https://en.wikipedia.org/wiki/Neighbourhood_components_analysis&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af0472efa729237e92d89bb05e9ca0c8e7f37b5f" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Coefficient of determination</source>
          <target state="translated">Entrada de Wikipedia sobre el Coeficiente de determinación</target>
        </trans-unit>
        <trans-unit id="e345be5719f19335870d8d3a8cdd20b6bd307aa0" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Hamming distance</source>
          <target state="translated">La entrada de Wikipedia sobre la distancia de Hamming</target>
        </trans-unit>
        <trans-unit id="1857fa6b095ad66d104ea60f4be3df45f12529a3" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Hinge loss</source>
          <target state="translated">La entrada de Wikipedia sobre la pérdida de Hinge</target>
        </trans-unit>
        <trans-unit id="d4ccd1b47442c7552ebe73794cdd38515c5ffdef" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Lasso</source>
          <target state="translated">La entrada de Wikipedia sobre el Lazo</target>
        </trans-unit>
        <trans-unit id="8751f23b19110bb289e70c6d8c900548f6c9b761" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Least-angle regression</source>
          <target state="translated">Entrada de Wikipedia sobre la regresión del ángulo menor</target>
        </trans-unit>
        <trans-unit id="ed8f4a303fe71f9ad0ec1e1b74ef6fe644dad80d" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Silhouette Coefficient</source>
          <target state="translated">Entrada de Wikipedia sobre el Coeficiente de Silueta</target>
        </trans-unit>
        <trans-unit id="0b665174747365aef367583fb0c32fb021d06a22" translate="yes" xml:space="preserve">
          <source>Wikipedia principal eigenvector</source>
          <target state="translated">Wikipedia main eigenvector</target>
        </trans-unit>
        <trans-unit id="713348b23d025b202ea7f033591c046a82a1973b" translate="yes" xml:space="preserve">
          <source>Will be ignored when &lt;code&gt;y_true&lt;/code&gt; is binary.</source>
          <target state="translated">Se ignorar&amp;aacute; cuando &lt;code&gt;y_true&lt;/code&gt; sea ​​binario.</target>
        </trans-unit>
        <trans-unit id="af498f4dd6f24dbc1f93745e77fe6ed29d0b9d0c" translate="yes" xml:space="preserve">
          <source>Will return sparse matrix if set True else will return an array.</source>
          <target state="translated">Devolverá la matriz dispersa si se establece True,si no,devolverá una matriz.</target>
        </trans-unit>
        <trans-unit id="f02c359862a5df44abc185413e06bdb77cfc5770" translate="yes" xml:space="preserve">
          <source>Williams, C.K.I. and Seeger, M. &amp;ldquo;Using the Nystroem method to speed up kernel machines&amp;rdquo;, Advances in neural information processing systems 2001</source>
          <target state="translated">Williams, CKI y Seeger, M. &quot;Uso del m&amp;eacute;todo Nystroem para acelerar las m&amp;aacute;quinas del n&amp;uacute;cleo&quot;, Avances en los sistemas de procesamiento de informaci&amp;oacute;n neuronal 2001</target>
        </trans-unit>
        <trans-unit id="a20af0cf6ba0496377888d152bfba536fcfdefc1" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;adjusted=True&lt;/code&gt;, balanced accuracy reports the relative increase from \(\texttt{balanced-accuracy}(y, \mathbf{0}, w) = \frac{1}{\text{n\_classes}}\). In the binary case, this is also known as &lt;a href=&quot;https://en.wikipedia.org/wiki/Youden%27s_J_statistic&quot;&gt;*Youden&amp;rsquo;s J statistic*&lt;/a&gt;, or &lt;em&gt;informedness&lt;/em&gt;.</source>
          <target state="translated">Con &lt;code&gt;adjusted=True&lt;/code&gt; , la precisi&amp;oacute;n equilibrada informa el aumento relativo de \ (\ texttt {precisi&amp;oacute;n equilibrada} (y, \ mathbf {0}, w) = \ frac {1} {\ text {n \ _classes}} \). En el caso binario, esto tambi&amp;eacute;n se conoce como &lt;a href=&quot;https://en.wikipedia.org/wiki/Youden%27s_J_statistic&quot;&gt;* estad&amp;iacute;stica J de Youden *&lt;/a&gt; o &lt;em&gt;informaci&amp;oacute;n&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="ad0e52061072794be72972cbf40b994abb34f953" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;adjusted=True&lt;/code&gt;, balanced accuracy reports the relative increase from \(\texttt{balanced-accuracy}(y, \mathbf{0}, w) = \frac{1}{n\_classes}\). In the binary case, this is also known as &lt;a href=&quot;https://en.wikipedia.org/wiki/Youden%27s_J_statistic&quot;&gt;*Youden&amp;rsquo;s J statistic*&lt;/a&gt;, or &lt;em&gt;informedness&lt;/em&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a7d860e7dc8979710329f97e747eaff0d3415d3" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;early_stopping=False&lt;/code&gt;, the model is fitted on the entire input data and the stopping criterion is based on the objective function computed on the input data.</source>
          <target state="translated">Con &lt;code&gt;early_stopping=False&lt;/code&gt; , el modelo se ajusta a todos los datos de entrada y el criterio de parada se basa en la funci&amp;oacute;n objetivo calculada en los datos de entrada.</target>
        </trans-unit>
        <trans-unit id="3fe735414475494b49457f76f31eea3026d08560" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;early_stopping=False&lt;/code&gt;, the model is fitted on the entire input data and the stopping criterion is based on the objective function computed on the training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5515c693f110557bb04dd8dc133e8927dc9c68e0" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;early_stopping=True&lt;/code&gt;, the input data is split into a training set and a validation set. The model is then fitted on the training set, and the stopping criterion is based on the prediction score (using the &lt;code&gt;score&lt;/code&gt; method) computed on the validation set. The size of the validation set can be changed with the parameter &lt;code&gt;validation_fraction&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ceb9e226f3e04a8a66252e3801eed93f740afd9" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;early_stopping=True&lt;/code&gt;, the input data is split into a training set and a validation set. The model is then fitted on the training set, and the stopping criterion is based on the prediction score computed on the validation set. The size of the validation set can be changed with the parameter &lt;code&gt;validation_fraction&lt;/code&gt;.</source>
          <target state="translated">Con &lt;code&gt;early_stopping=True&lt;/code&gt; , los datos de entrada se dividen en un conjunto de entrenamiento y un conjunto de validaci&amp;oacute;n. Luego, el modelo se ajusta al conjunto de entrenamiento y el criterio de parada se basa en la puntuaci&amp;oacute;n de predicci&amp;oacute;n calculada en el conjunto de validaci&amp;oacute;n. El tama&amp;ntilde;o del conjunto de validaci&amp;oacute;n se puede cambiar con el par&amp;aacute;metro &lt;code&gt;validation_fraction&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="318aced6d4dfc924ad223bd54e79ede301143b06" translate="yes" xml:space="preserve">
          <source>With SGD or Adam, training supports online and mini-batch learning.</source>
          <target state="translated">Con SGD o Adam,el entrenamiento apoya el aprendizaje en línea y en mini-batch.</target>
        </trans-unit>
        <trans-unit id="bebfaf6a5f7ee4311c7425773ef87a0b1b61dcc0" translate="yes" xml:space="preserve">
          <source>With SVMs and logistic-regression, the parameter C controls the sparsity: the smaller C the fewer features selected. With Lasso, the higher the alpha parameter, the fewer features selected.</source>
          <target state="translated">Con los SVM y la regresión logística,el parámetro C controla la dispersión:cuanto más pequeño sea C,menos características se seleccionan.Con Lasso,cuanto más alto es el parámetro alfa,menos características se seleccionan.</target>
        </trans-unit>
        <trans-unit id="2e07775067fbbb8cee792ed1d4b4b0282fd223be" translate="yes" xml:space="preserve">
          <source>With \(P'(j) = |V_j| / N\). The mutual information (MI) between \(U\) and \(V\) is calculated by:</source>
          <target state="translated">Con \ ~-P'(j)=|V_j|/N\).La información mutua (MI)entre \N \N \N y \N \N Viene calculada por:</target>
        </trans-unit>
        <trans-unit id="2042997590ba0f656467c3f6df43427a875d6409" translate="yes" xml:space="preserve">
          <source>With agglomerative clustering, it is possible to specify which samples can be clustered together by giving a connectivity graph. Graphs in scikit-learn are represented by their adjacency matrix. Often, a sparse matrix is used. This can be useful, for instance, to retrieve connected regions (sometimes also referred to as connected components) when clustering an image.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5313dd287c9c493fc21b86c81282cea7d0608304" translate="yes" xml:space="preserve">
          <source>With agglomerative clustering, it is possible to specify which samples can be clustered together by giving a connectivity graph. Graphs in scikit-learn are represented by their adjacency matrix. Often, a sparse matrix is used. This can be useful, for instance, to retrieve connected regions (sometimes also referred to as connected components) when clustering an image:</source>
          <target state="translated">Con la agrupación aglomerada,es posible especificar qué muestras pueden agruparse dando un gráfico de conectividad.Los gráficos en scikit-learn están representados por su matriz de adyacencia.A menudo,se utiliza una matriz dispersa.Esto puede ser útil,por ejemplo,para recuperar regiones conectadas (a veces también denominadas componentes conectados)cuando se agrupa una imagen:</target>
        </trans-unit>
        <trans-unit id="ebae629f7af13ae26b867ab75161458173d10bdc" translate="yes" xml:space="preserve">
          <source>With regard to decision trees, this strategy can readily be used to support multi-output problems. This requires the following changes:</source>
          <target state="translated">En lo que respecta a los árboles de decisión,esta estrategia puede utilizarse fácilmente para apoyar los problemas de salida múltiple.Esto requiere los siguientes cambios:</target>
        </trans-unit>
        <trans-unit id="d6eab2b8513179355ba20cab88473d0665849027" translate="yes" xml:space="preserve">
          <source>With such an abundance of clues that distinguish newsgroups, the classifiers barely have to identify topics from text at all, and they all perform at the same high level.</source>
          <target state="translated">Con tal abundancia de pistas que distinguen a los grupos de noticias,los clasificadores apenas tienen que identificar los temas a partir del texto en absoluto,y todos actúan al mismo alto nivel.</target>
        </trans-unit>
        <trans-unit id="ba25a12704b8225df22eb5cee35ebe73afb76c8b" translate="yes" xml:space="preserve">
          <source>With sum_over_features equal to False it returns the componentwise distances.</source>
          <target state="translated">Con la suma de las características igual a False,devuelve las distancias de los componentes.</target>
        </trans-unit>
        <trans-unit id="54cc29b6387240d37c6717d5c94b33d650c1152c" translate="yes" xml:space="preserve">
          <source>With the &amp;lsquo;brute&amp;rsquo; method, the parameter &lt;code&gt;X&lt;/code&gt; is used both for generating the grid of values \(x_S\) and the complement feature values \(x_C\). However with the &amp;lsquo;recursion&amp;rsquo; method, &lt;code&gt;X&lt;/code&gt; is only used for the grid values: implicitly, the \(x_C\) values are those of the training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67616371d2f2a0ec7fd27c8038627dc9ef441900" translate="yes" xml:space="preserve">
          <source>With the fitted model, we compute the predictions of the model on the test dataset. These predictions are used to compute the confustion matrix which is plotted with the &lt;a href=&quot;../../modules/generated/sklearn.metrics.confusionmatrixdisplay#sklearn.metrics.ConfusionMatrixDisplay&quot;&gt;&lt;code&gt;ConfusionMatrixDisplay&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03d84c3da120d3c6633bcd8017a1f00e1bb6dad8" translate="yes" xml:space="preserve">
          <source>With this class, the base_estimator is fit on the train set of the cross-validation generator and the test set is used for calibration. The probabilities for each of the folds are then averaged for prediction. In case that cv=&amp;rdquo;prefit&amp;rdquo; is passed to __init__, it is assumed that base_estimator has been fitted already and all data is used for calibration. Note that data for fitting the classifier and for calibrating it must be disjoint.</source>
          <target state="translated">Con esta clase, el base_estimator se ajusta al conjunto de trenes del generador de validaci&amp;oacute;n cruzada y el conjunto de prueba se utiliza para la calibraci&amp;oacute;n. Las probabilidades de cada uno de los pliegues se promedian para la predicci&amp;oacute;n. En caso de que cv = &amp;rdquo;prefit&amp;rdquo; se pase a __init__, se supone que base_estimator ya se ha ajustado y todos los datos se utilizan para la calibraci&amp;oacute;n. Tenga en cuenta que los datos para ajustar el clasificador y calibrarlo deben estar separados.</target>
        </trans-unit>
        <trans-unit id="07ec442186310e3d4d8de1ef730f033183a12d2a" translate="yes" xml:space="preserve">
          <source>With this re-labeling of the data, our problem can be written</source>
          <target state="translated">Con este re-etiquetado de los datos,nuestro problema puede ser escrito</target>
        </trans-unit>
        <trans-unit id="bb9dc2936468de0109f9958206c68ba68552df6f" translate="yes" xml:space="preserve">
          <source>With this setup, a single distance calculation between a test point and the centroid is sufficient to determine a lower and upper bound on the distance to all points within the node. Because of the spherical geometry of the ball tree nodes, it can out-perform a &lt;em&gt;KD-tree&lt;/em&gt; in high dimensions, though the actual performance is highly dependent on the structure of the training data. In scikit-learn, ball-tree-based neighbors searches are specified using the keyword &lt;code&gt;algorithm = 'ball_tree'&lt;/code&gt;, and are computed using the class &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;sklearn.neighbors.BallTree&lt;/code&gt;&lt;/a&gt;. Alternatively, the user can work with the &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; class directly.</source>
          <target state="translated">Con esta configuraci&amp;oacute;n, un c&amp;aacute;lculo de distancia &amp;uacute;nico entre un punto de prueba y el centroide es suficiente para determinar un l&amp;iacute;mite superior e inferior en la distancia a todos los puntos dentro del nodo. Debido a la geometr&amp;iacute;a esf&amp;eacute;rica de los nodos del &amp;aacute;rbol de bolas, puede &lt;em&gt;superar a un &amp;aacute;rbol KD&lt;/em&gt; en grandes dimensiones, aunque el rendimiento real depende en gran medida de la estructura de los datos de entrenamiento. En scikit-learn, las b&amp;uacute;squedas de vecinos basadas en &amp;aacute;rboles de bolas se especifican mediante el &lt;code&gt;algorithm = 'ball_tree'&lt;/code&gt; palabra clave = 'ball_tree' , y se calculan mediante la clase &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;sklearn.neighbors.BallTree&lt;/code&gt; &lt;/a&gt; . Alternativamente, el usuario puede trabajar con la clase &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; &lt;/a&gt; directamente.</target>
        </trans-unit>
        <trans-unit id="c5b891d6db4b2b53f2c329c62187e665d9759f8a" translate="yes" xml:space="preserve">
          <source>Without any prior information on the sample, the number of projections required to reconstruct the image is of the order of the linear size &lt;code&gt;l&lt;/code&gt; of the image (in pixels). For simplicity we consider here a sparse image, where only pixels on the boundary of objects have a non-zero value. Such data could correspond for example to a cellular material. Note however that most images are sparse in a different basis, such as the Haar wavelets. Only &lt;code&gt;l/7&lt;/code&gt; projections are acquired, therefore it is necessary to use prior information available on the sample (its sparsity): this is an example of &lt;strong&gt;compressive sensing&lt;/strong&gt;.</source>
          <target state="translated">Sin ninguna informaci&amp;oacute;n previa sobre la muestra, el n&amp;uacute;mero de proyecciones necesarias para reconstruir la imagen es del orden del tama&amp;ntilde;o lineal &lt;code&gt;l&lt;/code&gt; de la imagen (en p&amp;iacute;xeles). Por simplicidad, consideramos aqu&amp;iacute; una imagen dispersa, donde solo los p&amp;iacute;xeles en el l&amp;iacute;mite de los objetos tienen un valor distinto de cero. Dichos datos podr&amp;iacute;an corresponder, por ejemplo, a un material celular. Sin embargo, tenga en cuenta que la mayor&amp;iacute;a de las im&amp;aacute;genes son escasas en una base diferente, como las ondas de Haar. S&amp;oacute;lo &lt;code&gt;l/7&lt;/code&gt; proyecciones se adquieren, por lo tanto es necesario el uso de informaci&amp;oacute;n previa disponible en la muestra (su escasez): Este es un ejemplo de &lt;strong&gt;detecci&amp;oacute;n de la compresi&amp;oacute;n&lt;/strong&gt; .</target>
        </trans-unit>
        <trans-unit id="087783a9ac4373b41b03a4f66d5eaf61d7d47ff1" translate="yes" xml:space="preserve">
          <source>Without reduce_func:</source>
          <target state="translated">Sin reducir_func:</target>
        </trans-unit>
        <trans-unit id="e6002e635270be50830b0534ba0aafc304922d8b" translate="yes" xml:space="preserve">
          <source>Without shuffling, &lt;code&gt;X&lt;/code&gt; horizontally stacks features in the following order: the primary &lt;code&gt;n_informative&lt;/code&gt; features, followed by &lt;code&gt;n_redundant&lt;/code&gt; linear combinations of the informative features, followed by &lt;code&gt;n_repeated&lt;/code&gt; duplicates, drawn randomly with replacement from the informative and redundant features. The remaining features are filled with random noise. Thus, without shuffling, all useful features are contained in the columns &lt;code&gt;X[:, :n_informative + n_redundant + n_repeated]&lt;/code&gt;.</source>
          <target state="translated">Sin barajar, &lt;code&gt;X&lt;/code&gt; apila horizontalmente las caracter&amp;iacute;sticas en el siguiente orden: las &lt;code&gt;n_informative&lt;/code&gt; caracter&amp;iacute;sticas informativas primarias , seguidas de &lt;code&gt;n_redundant&lt;/code&gt; combinaciones lineales redundantes de las caracter&amp;iacute;sticas informativas, seguidas de &lt;code&gt;n_repeated&lt;/code&gt; duplicados repetidos , extra&amp;iacute;dos aleatoriamente con reemplazo de las caracter&amp;iacute;sticas informativas y redundantes. Las funciones restantes est&amp;aacute;n llenas de ruido aleatorio. Por lo tanto, sin barajar, todas las caracter&amp;iacute;sticas &amp;uacute;tiles est&amp;aacute;n contenidas en las columnas &lt;code&gt;X[:, :n_informative + n_redundant + n_repeated]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6943d5826611d6c30be0d7d32e8882ddb2f3e560" translate="yes" xml:space="preserve">
          <source>Wolpert, David H. &amp;ldquo;Stacked generalization.&amp;rdquo; Neural networks 5.2 (1992): 241-259.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2a146386973596d64e5c0f348ec45ab36bab658" translate="yes" xml:space="preserve">
          <source>Working With Text Data</source>
          <target state="translated">Trabajando con datos de texto</target>
        </trans-unit>
        <trans-unit id="61f49f0587c5992cc8f414bbf22889f09b8f3976" translate="yes" xml:space="preserve">
          <source>Working with text documents</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b5ef6667bd92ea247084ea267c265251f4aa7de" translate="yes" xml:space="preserve">
          <source>Works with sparse matrices. Only works if &lt;code&gt;rows_&lt;/code&gt; and &lt;code&gt;columns_&lt;/code&gt; attributes exist.</source>
          <target state="translated">Funciona con matrices dispersas. Solo funciona si existen atributos de &lt;code&gt;rows_&lt;/code&gt; y &lt;code&gt;columns_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="926da419b9cc98b9060a6d00fb8d48cd55be86f9" translate="yes" xml:space="preserve">
          <source>Wrapper for kernels in sklearn.metrics.pairwise.</source>
          <target state="translated">Envoltura para los núcleos en sklearn.metrics.pairwise.</target>
        </trans-unit>
        <trans-unit id="f986c2ac1f7dce99239d5b1ba2c2c97de265f3fa" translate="yes" xml:space="preserve">
          <source>Write a text classification pipeline to classify movie reviews as either positive or negative.</source>
          <target state="translated">Escriba una clasificación de texto para clasificar las críticas de películas como positivas o negativas.</target>
        </trans-unit>
        <trans-unit id="c1b32a0493a32a44864910f6b6b9c9398af4b20e" translate="yes" xml:space="preserve">
          <source>Write a text classification pipeline using a custom preprocessor and &lt;code&gt;CharNGramAnalyzer&lt;/code&gt; using data from Wikipedia articles as training set.</source>
          <target state="translated">Escriba una canalizaci&amp;oacute;n de clasificaci&amp;oacute;n de texto usando un preprocesador personalizado y &lt;code&gt;CharNGramAnalyzer&lt;/code&gt; usando datos de art&amp;iacute;culos de Wikipedia como conjunto de entrenamiento</target>
        </trans-unit>
        <trans-unit id="c72e193d2469d6cfb2918ba7a00dbc8ed1d451d6" translate="yes" xml:space="preserve">
          <source>Wu, Lin and Weng, &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/papers/svmprob/svmprob.pdf&quot;&gt;&amp;ldquo;Probability estimates for multi-class classification by pairwise coupling&amp;rdquo;&lt;/a&gt;, JMLR 5:975-1005, 2004.</source>
          <target state="translated">Wu, Lin y Weng, &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/papers/svmprob/svmprob.pdf&quot;&gt;&quot;Estimaciones de probabilidad para clasificaci&amp;oacute;n de clases m&amp;uacute;ltiples por acoplamiento por pares&quot;&lt;/a&gt; , JMLR 5: 975-1005, 2004.</target>
        </trans-unit>
        <trans-unit id="11ab439af4c255f5f8d3594c0dad27bd31f9055a" translate="yes" xml:space="preserve">
          <source>Wu, Lin and Weng, &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/papers/svmprob/svmprob.pdf&quot;&gt;&amp;ldquo;Probability estimates for multi-class classification by pairwise coupling&amp;rdquo;&lt;/a&gt;, JMLR 5:975-1005, 2004.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8c1574205d07b839af62817660ba2b78f320cd0" translate="yes" xml:space="preserve">
          <source>X block loadings vectors.</source>
          <target state="translated">Bloque X de vectores de carga.</target>
        </trans-unit>
        <trans-unit id="b8076ad410e1a569012d16107ff003e5d358439f" translate="yes" xml:space="preserve">
          <source>X block to latents rotations.</source>
          <target state="translated">Bloqueo X a rotaciones latentes.</target>
        </trans-unit>
        <trans-unit id="a6b8640132f42899bc713ee5acc307439a5b7049" translate="yes" xml:space="preserve">
          <source>X block weights vectors.</source>
          <target state="translated">Bloque X vectores de peso.</target>
        </trans-unit>
        <trans-unit id="51ee8a5ebc2ecb45284445a844d1c86426452ff9" translate="yes" xml:space="preserve">
          <source>X is projected on the first principal components previously extracted from a training set, using minibatches of size batch_size if X is sparse.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6bc2e58339df2a473a9897261f25e31780f738c" translate="yes" xml:space="preserve">
          <source>X is projected on the first principal components previously extracted from a training set.</source>
          <target state="translated">X se proyecta sobre los primeros componentes principales previamente extraídos de un conjunto de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="81850902f59e77236b068c4b29af3fcf5c8ba36f" translate="yes" xml:space="preserve">
          <source>X is stored for future use, as &lt;a href=&quot;#sklearn.isotonic.IsotonicRegression.transform&quot;&gt;&lt;code&gt;transform&lt;/code&gt;&lt;/a&gt; needs X to interpolate new input data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7228d382c859d348525ccb5bce51e5752c38bc04" translate="yes" xml:space="preserve">
          <source>X is stored for future use, as &lt;code&gt;transform&lt;/code&gt; needs X to interpolate new input data.</source>
          <target state="translated">X se almacena para uso futuro, ya que la &lt;code&gt;transform&lt;/code&gt; aci&amp;oacute;n necesita X para interpolar nuevos datos de entrada.</target>
        </trans-unit>
        <trans-unit id="3074bef8d8da5f206ce501f5438e3d5abb038064" translate="yes" xml:space="preserve">
          <source>X must have been produced by this DictVectorizer&amp;rsquo;s transform or fit_transform method; it may only have passed through transformers that preserve the number of features and their order.</source>
          <target state="translated">X debe haber sido producido por el m&amp;eacute;todo transform o fit_transform de este DictVectorizer; puede que solo haya pasado por transformadores que conservan el n&amp;uacute;mero de caracter&amp;iacute;sticas y su orden.</target>
        </trans-unit>
        <trans-unit id="d0ad8e13f68af13dec8ad59c4f3a6a0df7a4de08" translate="yes" xml:space="preserve">
          <source>X scores.</source>
          <target state="translated">X resultados.</target>
        </trans-unit>
        <trans-unit id="28a3e4c54c0fde2f1aaa67a11fe405d430c2fe41" translate="yes" xml:space="preserve">
          <source>X transformed in the new space.</source>
          <target state="translated">X transformado en el nuevo espacio.</target>
        </trans-unit>
        <trans-unit id="ae3643384dc9ac54889b85ea1da357f34b173e6e" translate="yes" xml:space="preserve">
          <source>X_embedded: ndarray of shape (n_samples, n_components)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d925cac037a82cae915e8a0893b59ac5a4590490" translate="yes" xml:space="preserve">
          <source>X_new array, shape (n_samples, n_components)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0e804c93132e5ef73393b841ae090d872aa2191" translate="yes" xml:space="preserve">
          <source>X_original array-like, shape (n_samples, n_features)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="feedfda54d7431e28acb98075b2c2bd9cf8331f2" translate="yes" xml:space="preserve">
          <source>Xiaojin Zhu and Zoubin Ghahramani. Learning from labeled and unlabeled data with label propagation. Technical Report CMU-CALD-02-107, Carnegie Mellon University, 2002 &lt;a href=&quot;http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf&quot;&gt;http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf&lt;/a&gt;</source>
          <target state="translated">Xiaojin Zhu y Zoubin Ghahramani. Aprender de datos etiquetados y no etiquetados con propagaci&amp;oacute;n de etiquetas. Informe t&amp;eacute;cnico CMU-CALD-02-107, Universidad Carnegie Mellon, 2002 &lt;a href=&quot;http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf&quot;&gt;http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5c986ee528dd9bdf7a6c8d0101f77976c47ae9d2" translate="yes" xml:space="preserve">
          <source>Xin Dang, Hanxiang Peng, Xueqin Wang and Heping Zhang: &lt;a href=&quot;http://home.olemiss.edu/~xdang/papers/MTSE.pdf&quot;&gt;Theil-Sen Estimators in a Multiple Linear Regression Model.&lt;/a&gt;</source>
          <target state="translated">Xin Dang, Hanxiang Peng, Xueqin Wang y Heping Zhang: &lt;a href=&quot;http://home.olemiss.edu/~xdang/papers/MTSE.pdf&quot;&gt;estimadores de Theil-Sen en un modelo de regresi&amp;oacute;n lineal m&amp;uacute;ltiple.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3674e6b71697b8f4a5e14e694db26daa53371e84" translate="yes" xml:space="preserve">
          <source>Xt[i, j] is assigned the weight of edge that connects i to j. Only the neighbors have an explicit value. The diagonal is always explicit. The matrix is of CSR format.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c93217dd923de34853280b8058e56203ef9ee737" translate="yes" xml:space="preserve">
          <source>Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the Gram matrix is precomputed.</source>
          <target state="translated">Xy=np.punto(X.T,y)que puede ser precalculado.Sólo es útil cuando la matriz de Gram está precalculada.</target>
        </trans-unit>
        <trans-unit id="700502aa71883c1784c7b4df71f7526cabc3833b" translate="yes" xml:space="preserve">
          <source>Xy = np.dot(X.T, y).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23eb4d3f4155395a74e9d534f97ff4c1908f5aac" translate="yes" xml:space="preserve">
          <source>Y</source>
          <target state="translated">Y</target>
        </trans-unit>
        <trans-unit id="aac13ced89d2b311880e53ba16f36f4513402a98" translate="yes" xml:space="preserve">
          <source>Y block loadings vectors.</source>
          <target state="translated">Bloque Y de vectores de carga.</target>
        </trans-unit>
        <trans-unit id="148708c0aec99251158277d2fc4d038d62f32551" translate="yes" xml:space="preserve">
          <source>Y block to latents rotations.</source>
          <target state="translated">Bloqueo Y a rotaciones latentes.</target>
        </trans-unit>
        <trans-unit id="8f4ded8aca1a84f4452774f8bc622751045ade48" translate="yes" xml:space="preserve">
          <source>Y block weights vectors.</source>
          <target state="translated">Bloque Y de vectores de pesos.</target>
        </trans-unit>
        <trans-unit id="780dd8f1641062cfc0af001d2fcfedba3262be26" translate="yes" xml:space="preserve">
          <source>Y scores.</source>
          <target state="translated">Y anota.</target>
        </trans-unit>
        <trans-unit id="93b5936ef31b077aecad8b961838c412166e9fd0" translate="yes" xml:space="preserve">
          <source>Y. Freund, R. Schapire, &amp;ldquo;A Decision-Theoretic Generalization of on-Line Learning and an Application to Boosting&amp;rdquo;, 1995.</source>
          <target state="translated">Y. Freund, R. Schapire, &quot;Una generalizaci&amp;oacute;n te&amp;oacute;rica de decisiones del aprendizaje en l&amp;iacute;nea y una aplicaci&amp;oacute;n para impulsar&quot;, 1995.</target>
        </trans-unit>
        <trans-unit id="bf931371fe813e68af145bc28f1f0c59ead42876" translate="yes" xml:space="preserve">
          <source>Y. Freund, and R. Schapire, &amp;ldquo;A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting&amp;rdquo;, 1997.</source>
          <target state="translated">Y. Freund y R. Schapire, &quot;Una generalizaci&amp;oacute;n te&amp;oacute;rica de decisiones del aprendizaje en l&amp;iacute;nea y una aplicaci&amp;oacute;n para impulsar&quot;, 1997.</target>
        </trans-unit>
        <trans-unit id="982b5c305af507a5853864a0280fe0330e5fb9d9" translate="yes" xml:space="preserve">
          <source>Y[argmin[i], :] is the row in Y that is closest to X[i, :].</source>
          <target state="translated">Y[argmin[i],:]es la fila de Y que está más cerca de X[i,:].</target>
        </trans-unit>
        <trans-unit id="6cc2acee87fd2b4d368d7294a14e1666de3c66f0" translate="yes" xml:space="preserve">
          <source>Yang, Algesheimer, and Tessone, (2016). &amp;ldquo;A comparative analysis of community detection algorithms on artificial networks&amp;rdquo;. Scientific Reports 6: 30750. &lt;a href=&quot;https://www.nature.com/articles/srep30750&quot;&gt;doi:10.1038/srep30750&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3526f607bcd4f51ad0bc05f814579a42c2c0ba57" translate="yes" xml:space="preserve">
          <source>Yellow</source>
          <target state="translated">Yellow</target>
        </trans-unit>
        <trans-unit id="738a2b66281e5ca4973cbceebc923d1996e03dad" translate="yes" xml:space="preserve">
          <source>Yields</source>
          <target state="translated">Yields</target>
        </trans-unit>
        <trans-unit id="44e848b37858df8125129ee3d3911783b05fb21f" translate="yes" xml:space="preserve">
          <source>Yields indices to split data into training and test sets.</source>
          <target state="translated">Produce índices para dividir los datos en conjuntos de entrenamiento y pruebas.</target>
        </trans-unit>
        <trans-unit id="c970e3f1e790a2a4cd28b40401902501b9bc2d74" translate="yes" xml:space="preserve">
          <source>Yields:</source>
          <target state="translated">Yields:</target>
        </trans-unit>
        <trans-unit id="e285a8203a02b899c727c909bb971f8a5290d1a9" translate="yes" xml:space="preserve">
          <source>You can &lt;a href=&quot;grid_search#grid-search&quot;&gt;grid search&lt;/a&gt; over parameters of all estimators in the pipeline at once.</source>
          <target state="translated">Puede realizar &lt;a href=&quot;grid_search#grid-search&quot;&gt;b&amp;uacute;squedas&lt;/a&gt; en cuadr&amp;iacute;culas sobre los par&amp;aacute;metros de todos los estimadores en la tuber&amp;iacute;a a la vez.</target>
        </trans-unit>
        <trans-unit id="afc09f41b74c7e769c70223fd4fc6ea043be4f9a" translate="yes" xml:space="preserve">
          <source>You can access the newly created figure and Axes objects using &lt;code&gt;plt.gcf()&lt;/code&gt; and &lt;code&gt;plt.gca()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4f0eb08d1e594cb4ba39dda583b2124c29e8d3e" translate="yes" xml:space="preserve">
          <source>You can adjust the number of categories by giving their names to the dataset loader or setting them to None to get the 20 of them.</source>
          <target state="translated">Puedes ajustar el número de categorías dándole sus nombres al cargador de datos o poniéndolas en Ninguno para obtener las 20 de ellas.</target>
        </trans-unit>
        <trans-unit id="d6a91645b832623d5d5110588ef04aebdc451880" translate="yes" xml:space="preserve">
          <source>You can already copy the skeletons into a new folder somewhere on your hard-drive named &lt;code&gt;sklearn_tut_workspace&lt;/code&gt; where you will edit your own files for the exercises while keeping the original skeletons intact:</source>
          <target state="translated">Ya puede copiar los esqueletos en una nueva carpeta en alg&amp;uacute;n lugar de su disco duro llamado &lt;code&gt;sklearn_tut_workspace&lt;/code&gt; donde editar&amp;aacute; sus propios archivos para los ejercicios mientras mantiene intactos los esqueletos originales:</target>
        </trans-unit>
        <trans-unit id="1cf0d94595a131d36f8236532aeafb049eaa6dbc" translate="yes" xml:space="preserve">
          <source>You can also specify both the name and the version, which also uniquely identifies the dataset:</source>
          <target state="translated">También se puede especificar tanto el nombre como la versión,que también identifica de forma exclusiva el conjunto de datos:</target>
        </trans-unit>
        <trans-unit id="ae5f0da778f6ff8c0d5d1c2ccd6f86bebea3d9e0" translate="yes" xml:space="preserve">
          <source>You can also use your own defined kernels by passing a function to the keyword &lt;code&gt;kernel&lt;/code&gt; in the constructor.</source>
          <target state="translated">Tambi&amp;eacute;n puede usar sus propios n&amp;uacute;cleos definidos pasando una funci&amp;oacute;n a la palabra clave &lt;code&gt;kernel&lt;/code&gt; en el constructor.</target>
        </trans-unit>
        <trans-unit id="c90fd70bc9584ad72350fadce865213cd8c472be" translate="yes" xml:space="preserve">
          <source>You can combine &lt;code&gt;KBinsDiscretizer&lt;/code&gt; with &lt;a href=&quot;sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt;&lt;/a&gt; if you only want to preprocess part of the features.</source>
          <target state="translated">Puede combinar &lt;code&gt;KBinsDiscretizer&lt;/code&gt; con &lt;a href=&quot;sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt; &lt;/a&gt; si solo desea preprocesar parte de las funciones.</target>
        </trans-unit>
        <trans-unit id="b37a62ca838923df55452889a68156ed8900e3e5" translate="yes" xml:space="preserve">
          <source>You can control the exact number of threads that are used via the &lt;code&gt;OMP_NUM_THREADS&lt;/code&gt; environment variable:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="579522a3d8d5bf3b4958e7c2d681266388521dce" translate="yes" xml:space="preserve">
          <source>You can define your own kernels by either giving the kernel as a python function or by precomputing the Gram matrix.</source>
          <target state="translated">Puedes definir tus propios núcleos dándole al núcleo una función pitón o precomputando la matriz Gram.</target>
        </trans-unit>
        <trans-unit id="5a14b3f83e3bd81fa3adef5b677dc7c591d450db" translate="yes" xml:space="preserve">
          <source>You can display the BLAS / LAPACK implementation used by your NumPy / SciPy / scikit-learn install with the following commands:</source>
          <target state="translated">Puedes mostrar la implementación de BLAS/LAPACK utilizada por tu instalación de NumPy/SciPy/scikit-learn con los siguientes comandos:</target>
        </trans-unit>
        <trans-unit id="929abd63168ac2d721d4708b8ef8be3cd51b08a0" translate="yes" xml:space="preserve">
          <source>You can ensure that &lt;code&gt;func&lt;/code&gt; and &lt;code&gt;inverse_func&lt;/code&gt; are the inverse of each other by setting &lt;code&gt;check_inverse=True&lt;/code&gt; and calling &lt;code&gt;fit&lt;/code&gt; before &lt;code&gt;transform&lt;/code&gt;. Please note that a warning is raised and can be turned into an error with a &lt;code&gt;filterwarnings&lt;/code&gt;:</source>
          <target state="translated">Puede asegurarse de que &lt;code&gt;func&lt;/code&gt; e &lt;code&gt;inverse_func&lt;/code&gt; sean inversos entre s&amp;iacute; estableciendo &lt;code&gt;check_inverse=True&lt;/code&gt; y llamando a &lt;code&gt;fit&lt;/code&gt; before &lt;code&gt;transform&lt;/code&gt; . Tenga en cuenta que se &lt;code&gt;filterwarnings&lt;/code&gt; una advertencia y se puede convertir en un error con advertencias de filtro :</target>
        </trans-unit>
        <trans-unit id="8fe8cd91261eb27750ae7b2f82fa15c24077f346" translate="yes" xml:space="preserve">
          <source>You can generate even more flexible model scorers by constructing your own scoring object from scratch, without using the &lt;a href=&quot;generated/sklearn.metrics.make_scorer#sklearn.metrics.make_scorer&quot;&gt;&lt;code&gt;make_scorer&lt;/code&gt;&lt;/a&gt; factory. For a callable to be a scorer, it needs to meet the protocol specified by the following two rules:</source>
          <target state="translated">Puede generar marcadores de modelo a&amp;uacute;n m&amp;aacute;s flexibles construyendo su propio objeto de puntuaci&amp;oacute;n desde cero, sin usar la f&amp;aacute;brica &lt;a href=&quot;generated/sklearn.metrics.make_scorer#sklearn.metrics.make_scorer&quot;&gt; &lt;code&gt;make_scorer&lt;/code&gt; &lt;/a&gt; . Para que un llamante sea un anotador, debe cumplir con el protocolo especificado por las siguientes dos reglas:</target>
        </trans-unit>
        <trans-unit id="cb07d258c61c328d902779de990b642f82ba2beb" translate="yes" xml:space="preserve">
          <source>You can get more information on the dataset by looking at the &lt;code&gt;DESCR&lt;/code&gt; and &lt;code&gt;details&lt;/code&gt; attributes:</source>
          <target state="translated">Puede obtener m&amp;aacute;s informaci&amp;oacute;n sobre el conjunto de datos mirando &lt;code&gt;DESCR&lt;/code&gt; y los atributos de &lt;code&gt;details&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="316dc294ff0e2890db335b30189c691f1a723809" translate="yes" xml:space="preserve">
          <source>You can now see many things that these features have overfit to:</source>
          <target state="translated">Ahora puedes ver muchas cosas a las que estas características se han adaptado:</target>
        </trans-unit>
        <trans-unit id="e2cf6b0ce385c4e9fb3f4b5189c83feb905d92cf" translate="yes" xml:space="preserve">
          <source>You can pass pre-computed kernels by using the &lt;code&gt;kernel='precomputed'&lt;/code&gt; option. You should then pass Gram matrix instead of X to the &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt; methods. The kernel values between &lt;em&gt;all&lt;/em&gt; training vectors and the test vectors must be provided:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee86b8b814976ee239ecfc8e86907133be9d3afc" translate="yes" xml:space="preserve">
          <source>You can see that 16 non-zero feature tokens were extracted in the vector output: this is less than the 19 non-zeros extracted previously by the &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt; on the same toy corpus. The discrepancy comes from hash function collisions because of the low value of the &lt;code&gt;n_features&lt;/code&gt; parameter.</source>
          <target state="translated">Puede ver que se extrajeron 16 tokens de caracter&amp;iacute;sticas distintas de cero en la salida del vector: esto es menos que los 19 no ceros extra&amp;iacute;dos previamente por &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; en el mismo corpus de juguetes. La discrepancia proviene de colisiones de funciones hash debido al bajo valor del par&amp;aacute;metro &lt;code&gt;n_features&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6b3885cd10ec182cb98af7964ed686cdd6c77762" translate="yes" xml:space="preserve">
          <source>You can specify a monotonic constraint on each feature using the &lt;code&gt;monotonic_cst&lt;/code&gt; parameter. For each feature, a value of 0 indicates no constraint, while -1 and 1 indicate a negative and positive constraint, respectively:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c31033fd31d22147ea7534b97a7d63f646fe3e48" translate="yes" xml:space="preserve">
          <source>You can then edit the content of the workspace without fear of losing the original exercise instructions.</source>
          <target state="translated">Entonces puedes editar el contenido del espacio de trabajo sin temor a perder las instrucciones originales del ejercicio.</target>
        </trans-unit>
        <trans-unit id="bc5b6b055370779ded34375c059372bbad8d8da3" translate="yes" xml:space="preserve">
          <source>You can use your own defined kernels by passing a function to the &lt;code&gt;kernel&lt;/code&gt; parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e21dcf7dc4d8353d8949b3e6ddc2c35c364a9b4a" translate="yes" xml:space="preserve">
          <source>You cannot nest objects with parallel computing (&lt;code&gt;n_jobs&lt;/code&gt; different than 1).</source>
          <target state="translated">No puede anidar objetos con computaci&amp;oacute;n paralela ( &lt;code&gt;n_jobs&lt;/code&gt; diferentes a 1).</target>
        </trans-unit>
        <trans-unit id="d086a1b811e8ad563a3cd7d98758c535aff811c7" translate="yes" xml:space="preserve">
          <source>You could try UTF-8 and disregard the errors. You can decode byte strings with &lt;code&gt;bytes.decode(errors='replace')&lt;/code&gt; to replace all decoding errors with a meaningless character, or set &lt;code&gt;decode_error='replace'&lt;/code&gt; in the vectorizer. This may damage the usefulness of your features.</source>
          <target state="translated">Puede probar UTF-8 e ignorar los errores. Puede decodificar cadenas de bytes con &lt;code&gt;bytes.decode(errors='replace')&lt;/code&gt; para reemplazar todos los errores de decodificaci&amp;oacute;n con un car&amp;aacute;cter sin sentido, o establecer &lt;code&gt;decode_error='replace'&lt;/code&gt; en el vectorizador. Esto puede da&amp;ntilde;ar la utilidad de sus funciones.</target>
        </trans-unit>
        <trans-unit id="c0d5a5afa92ed6aa301d13299623473f530c94ba" translate="yes" xml:space="preserve">
          <source>You may also load two (or more) datasets at once:</source>
          <target state="translated">También puede cargar dos (o más)conjuntos de datos a la vez:</target>
        </trans-unit>
        <trans-unit id="a822ec525f0ce269b9b885feec474e1f8b512e04" translate="yes" xml:space="preserve">
          <source>You may also retain the estimator fitted on each training set by setting &lt;code&gt;return_estimator=True&lt;/code&gt;.</source>
          <target state="translated">Tambi&amp;eacute;n puede conservar el estimador ajustado en cada conjunto de entrenamiento configurando &lt;code&gt;return_estimator=True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c9bcd37e9efb4d07a927274f7ad017afc3f094c8" translate="yes" xml:space="preserve">
          <source>You may be able to find out what kind of encoding it is in general using the UNIX command &lt;code&gt;file&lt;/code&gt;. The Python &lt;code&gt;chardet&lt;/code&gt; module comes with a script called &lt;code&gt;chardetect.py&lt;/code&gt; that will guess the specific encoding, though you cannot rely on its guess being correct.</source>
          <target state="translated">Es posible que pueda averiguar qu&amp;eacute; tipo de codificaci&amp;oacute;n es en general utilizando el &lt;code&gt;file&lt;/code&gt; comandos de UNIX . El m&amp;oacute;dulo &lt;code&gt;chardet&lt;/code&gt; de Python viene con un script llamado &lt;code&gt;chardetect.py&lt;/code&gt; que adivinar&amp;aacute; la codificaci&amp;oacute;n espec&amp;iacute;fica, aunque no puede confiar en que su conjetura sea correcta.</target>
        </trans-unit>
        <trans-unit id="04405b99190799597dab92e2ef615219d1447404" translate="yes" xml:space="preserve">
          <source>You may load a dataset like as follows:</source>
          <target state="translated">Puedes cargar un conjunto de datos como el siguiente:</target>
        </trans-unit>
        <trans-unit id="f9f71500b978e09c529098f893f05269c79caaff" translate="yes" xml:space="preserve">
          <source>You may want to include the parameters of the preprocessors in a &lt;a href=&quot;grid_search#grid-search&quot;&gt;parameter search&lt;/a&gt;.</source>
          <target state="translated">Es posible que desee incluir los par&amp;aacute;metros de los preprocesadores en una &lt;a href=&quot;grid_search#grid-search&quot;&gt;b&amp;uacute;squeda de par&amp;aacute;metros&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="4cbe0908270a3a4effe7f03ed10c6fc1b573bdb1" translate="yes" xml:space="preserve">
          <source>You might get slightly different results with the solver liblinear than with the others since this uses LIBLINEAR which penalizes the intercept.</source>
          <target state="translated">Puede que obtengas resultados ligeramente diferentes con el solucionador liblineal que con los otros ya que este usa LIBLINEAR que penaliza la intercepción.</target>
        </trans-unit>
        <trans-unit id="eacc5e93bbce61c3d762f60af9c0b85d6ab90006" translate="yes" xml:space="preserve">
          <source>You might have noticed that the samples were shuffled randomly when we called &lt;code&gt;fetch_20newsgroups(..., shuffle=True, random_state=42)&lt;/code&gt;: this is useful if you wish to select only a subset of samples to quickly train a model and get a first idea of the results before re-training on the complete dataset later.</source>
          <target state="translated">Es posible que haya notado que las muestras se barajaron aleatoriamente cuando llamamos a &lt;code&gt;fetch_20newsgroups(..., shuffle=True, random_state=42)&lt;/code&gt; : esto es &amp;uacute;til si desea seleccionar solo un subconjunto de muestras para entrenar r&amp;aacute;pidamente un modelo y obtener una primera idea de los resultados antes de volver a entrenar en el conjunto de datos completo m&amp;aacute;s tarde.</target>
        </trans-unit>
        <trans-unit id="c8c03561e45bae9c49c8b8f096417e119a986f38" translate="yes" xml:space="preserve">
          <source>You only have to call &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fit&quot;&gt;fit&lt;/a&gt; and &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict&quot;&gt;predict&lt;/a&gt; once on your data to fit a whole sequence of estimators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c0c1bb33d891f47deca1c516d19aa08bd8443b9" translate="yes" xml:space="preserve">
          <source>You only have to call &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt; once on your data to fit a whole sequence of estimators.</source>
          <target state="translated">Solo tiene que llamar a &lt;code&gt;fit&lt;/code&gt; y &lt;code&gt;predict&lt;/code&gt; una vez en sus datos para ajustar una secuencia completa de estimadores.</target>
        </trans-unit>
        <trans-unit id="8f00f0e599f4c3a7b71dcab47e41c43fc685f526" translate="yes" xml:space="preserve">
          <source>You should also make sure that the stop word list has had the same preprocessing and tokenization applied as the one used in the vectorizer. The word &lt;em&gt;we&amp;rsquo;ve&lt;/em&gt; is split into &lt;em&gt;we&lt;/em&gt; and &lt;em&gt;ve&lt;/em&gt; by CountVectorizer&amp;rsquo;s default tokenizer, so if &lt;em&gt;we&amp;rsquo;ve&lt;/em&gt; is in &lt;code&gt;stop_words&lt;/code&gt;, but &lt;em&gt;ve&lt;/em&gt; is not, &lt;em&gt;ve&lt;/em&gt; will be retained from &lt;em&gt;we&amp;rsquo;ve&lt;/em&gt; in transformed text. Our vectorizers will try to identify and warn about some kinds of inconsistencies.</source>
          <target state="translated">Tambi&amp;eacute;n debe asegurarse de que se haya aplicado el mismo preprocesamiento y tokenizaci&amp;oacute;n a la lista de palabras de detenci&amp;oacute;n que se utiliz&amp;oacute; en el vectorizador. La palabra &lt;em&gt;que hemos&lt;/em&gt; se divide en &lt;em&gt;nosotros&lt;/em&gt; y &lt;em&gt;ve&lt;/em&gt; por defecto de tokenizer CountVectorizer, por lo que si &lt;em&gt;hemos&lt;/em&gt; est&amp;aacute; en &lt;code&gt;stop_words&lt;/code&gt; , pero &lt;em&gt;hemos&lt;/em&gt; no es, &lt;em&gt;hemos&lt;/em&gt; ser&amp;aacute; retenido desde &lt;em&gt;que hemos&lt;/em&gt; de texto transformado. Nuestros vectorizadores intentar&amp;aacute;n identificar y advertir sobre algunos tipos de inconsistencias.</target>
        </trans-unit>
        <trans-unit id="c05eee82bc79ecab0104c0f165ab54dde97d70eb" translate="yes" xml:space="preserve">
          <source>You will find additional details about joblib mitigation of oversubscription in &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#avoiding-over-subscription-of-cpu-ressources&quot;&gt;joblib documentation&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03e4dbf3891b38cb2bcd04772f91e994b5e9c01b" translate="yes" xml:space="preserve">
          <source>Your dataset consists of heterogeneous data types (e.g. raster images and text captions)</source>
          <target state="translated">Su conjunto de datos consiste en tipos de datos heterogéneos (por ejemplo,imágenes rasterizadas y leyendas de texto)</target>
        </trans-unit>
        <trans-unit id="7b0a68e70dc900bed821b4c342a07edfa667e451" translate="yes" xml:space="preserve">
          <source>Your dataset is stored in a Pandas DataFrame and different columns require different processing pipelines.</source>
          <target state="translated">Su conjunto de datos se almacena en un Pandas DataFrame y las diferentes columnas requieren diferentes tuberías de procesamiento.</target>
        </trans-unit>
        <trans-unit id="cf246e4fd612425ede440737acf49a3220f42916" translate="yes" xml:space="preserve">
          <source>Your kernel must take as arguments two matrices of shape &lt;code&gt;(n_samples_1, n_features)&lt;/code&gt;, &lt;code&gt;(n_samples_2, n_features)&lt;/code&gt; and return a kernel matrix of shape &lt;code&gt;(n_samples_1, n_samples_2)&lt;/code&gt;.</source>
          <target state="translated">Su kernel debe tomar como argumentos dos matrices de forma &lt;code&gt;(n_samples_1, n_features)&lt;/code&gt; , &lt;code&gt;(n_samples_2, n_features)&lt;/code&gt; y devolver una matriz de kernel de forma &lt;code&gt;(n_samples_1, n_samples_2)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a97cec9f16597107c699027a6e02cf1c0426b74a" translate="yes" xml:space="preserve">
          <source>ZN proportion of residential land zoned for lots over 25,000 sq.ft.</source>
          <target state="translated">ZN proporción de tierra residencial zonificada para lotes de más de 25.000 pies cuadrados.</target>
        </trans-unit>
        <trans-unit id="712d097b167e76a6e9d59b3e5e274cb4dc4edfe4" translate="yes" xml:space="preserve">
          <source>Zadrozny and Elkan, &amp;ldquo;Transforming classifier scores into multiclass probability estimates&amp;rdquo;, SIGKDD&amp;lsquo;02, &lt;a href=&quot;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&quot;&gt;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&lt;/a&gt;</source>
          <target state="translated">Zadrozny y Elkan, &quot;Transformaci&amp;oacute;n de las puntuaciones del clasificador en estimaciones de probabilidad multiclase&quot;, SIGKDD'02, &lt;a href=&quot;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&quot;&gt;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2a3a7f6ae69d75cdee1953a2daa7e044766fcafc" translate="yes" xml:space="preserve">
          <source>Zadrozny and Elkan, &amp;ldquo;Transforming classifier scores into multiclass probability estimates&amp;rdquo;, SIGKDD&amp;rsquo;02, &lt;a href=&quot;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&quot;&gt;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="100bba0bbb404bee5dfe86694ccdaa4c87071002" translate="yes" xml:space="preserve">
          <source>Zadrozny and Elkan, &amp;ldquo;Transforming classifier scores into multiclass probability estimates&amp;rdquo;, SIGKDD&amp;rsquo;02, &lt;a href=&quot;https://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&quot;&gt;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f05a65af97509516c00dcac126500e3f1415b5be" translate="yes" xml:space="preserve">
          <source>Zero coefficient for polynomial and sigmoid kernels. Ignored by other kernels.</source>
          <target state="translated">Coeficiente cero para los núcleos polinómicos y sigmoides.Ignorado por otros núcleos.</target>
        </trans-unit>
        <trans-unit id="e35caa5ca631cf4323249c1e10ca37b600a29376" translate="yes" xml:space="preserve">
          <source>Zero is the lowest possible score. Values closer to zero indicate a better partition.</source>
          <target state="translated">Cero es la puntuación más baja posible.Valores más cercanos a cero indican una mejor partición.</target>
        </trans-unit>
        <trans-unit id="4196df3003bc4705f3359c145eca39ac9042a13b" translate="yes" xml:space="preserve">
          <source>Zero-one classification loss.</source>
          <target state="translated">Pérdida de clasificación cero uno.</target>
        </trans-unit>
        <trans-unit id="ee137211a128584365e4b492f8f1e31e317a831d" translate="yes" xml:space="preserve">
          <source>Zhang, J. and Marszalek, M. and Lazebnik, S. and Schmid, C. Local features and kernels for classification of texture and object categories: A comprehensive study International Journal of Computer Vision 2007 &lt;a href=&quot;http://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&quot;&gt;http://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&lt;/a&gt;</source>
          <target state="translated">Zhang, J. y Marszalek, M. y Lazebnik, S. y Schmid, C.Caracter&amp;iacute;sticas locales y n&amp;uacute;cleos para la clasificaci&amp;oacute;n de texturas y categor&amp;iacute;as de objetos: un estudio integral International Journal of Computer Vision 2007 &lt;a href=&quot;http://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&quot;&gt;http://research.microsoft.com/ es-us / um / people / manik / projects / trade-off / papers / ZhangIJCV06.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="78f8c38e7e05f7b4f27cc97ecbaeea34135ce110" translate="yes" xml:space="preserve">
          <source>Zhang, J. and Marszalek, M. and Lazebnik, S. and Schmid, C. Local features and kernels for classification of texture and object categories: A comprehensive study International Journal of Computer Vision 2007 &lt;a href=&quot;https://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&quot;&gt;https://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c6fefb0786b59f4ca28434a9adf73a14f912b16" translate="yes" xml:space="preserve">
          <source>Zhang, Z. &amp;amp; Wang, J. MLLE: Modified Locally Linear Embedding Using Multiple Weights. &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.382&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.382&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e40887e48b748aeda9c07d81d6206e919ed1f726" translate="yes" xml:space="preserve">
          <source>Zhang, Z. &amp;amp; Zha, H. Principal manifolds and nonlinear dimensionality reduction via tangent space alignment. Journal of Shanghai Univ. 8:406 (2004)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f2ef1b5180fd57b17245a5c505519733d35270d" translate="yes" xml:space="preserve">
          <source>Zhu, H. Zou, S. Rosset, T. Hastie, &amp;ldquo;Multi-class AdaBoost&amp;rdquo;, 2009.</source>
          <target state="translated">Zhu, H. Zou, S. Rosset, T. Hastie, &amp;ldquo;Multi-class AdaBoost&amp;rdquo;, 2009.</target>
        </trans-unit>
        <trans-unit id="8ce45cc584babf565a133f667c041638840fdfd3" translate="yes" xml:space="preserve">
          <source>Zoubir A., Koivunen V., Chakhchoukh Y. and Muma M. (2012). Robust estimation in signal processing: A tutorial-style treatment of fundamental concepts. IEEE Signal Processing Magazine 29(4), 61-80.</source>
          <target state="translated">Zoubir A.,Koivunen V.,Chakhchoukh Y.y Muma M.(2012).Estimación robusta en el procesamiento de la señal:Un tratamiento de estilo tutorial de los conceptos fundamentales.Revista de procesamiento de señales del IEEE 29(4),61-80.</target>
        </trans-unit>
        <trans-unit id="e2b89a96fcf50192e8235c2260c291f63c7f4fa9" translate="yes" xml:space="preserve">
          <source>[&amp;lsquo;additive_chi2&amp;rsquo;, &amp;lsquo;chi2&amp;rsquo;, &amp;lsquo;linear&amp;rsquo;, &amp;lsquo;poly&amp;rsquo;, &amp;lsquo;polynomial&amp;rsquo;, &amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;laplacian&amp;rsquo;, &amp;lsquo;sigmoid&amp;rsquo;, &amp;lsquo;cosine&amp;rsquo;]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd3417b4282b09dc45879fe7c77bee8859983780" translate="yes" xml:space="preserve">
          <source>[&amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;sigmoid&amp;rsquo;, &amp;lsquo;polynomial&amp;rsquo;, &amp;lsquo;poly&amp;rsquo;, &amp;lsquo;linear&amp;rsquo;, &amp;lsquo;cosine&amp;rsquo;]</source>
          <target state="translated">['rbf', 'sigmoide', 'polinomio', 'poli', 'lineal', 'coseno']</target>
        </trans-unit>
        <trans-unit id="7c0453b88eaf6a5b1a0ac2faa1dec6c20e0dda6a" translate="yes" xml:space="preserve">
          <source>[1, x_2, x_2 ** 2, x_2 ** 3, &amp;hellip;], &amp;hellip;]</source>
          <target state="translated">[1, x_2, x_2 ** 2, x_2 ** 3,&amp;hellip;],&amp;hellip;]</target>
        </trans-unit>
        <trans-unit id="af237073ca841ce40d3b1c3f9ec3b84ba9e8c1ce" translate="yes" xml:space="preserve">
          <source>[1] &amp;ldquo;Online Learning for Latent Dirichlet Allocation&amp;rdquo;, Matthew D. Hoffman,</source>
          <target state="translated">[1] &amp;ldquo;Aprendizaje en l&amp;iacute;nea para la asignaci&amp;oacute;n de Dirichlet latente&amp;rdquo;, Matthew D. Hoffman,</target>
        </trans-unit>
        <trans-unit id="a5828c16246e11e0eda2596d27fdd402ee57d009" translate="yes" xml:space="preserve">
          <source>[1] &amp;ldquo;Shrinkage Algorithms for MMSE Covariance Estimation&amp;rdquo; Chen et al., IEEE Trans. on Sign. Proc., Volume 58, Issue 10, October 2010.</source>
          <target state="translated">[1] &amp;ldquo;Algoritmos de contracci&amp;oacute;n para la estimaci&amp;oacute;n de covarianza MMSE&amp;rdquo; Chen et al., IEEE Trans. al firmar. Proc., Volumen 58, N&amp;uacute;mero 10, octubre de 2010.</target>
        </trans-unit>
        <trans-unit id="c5ae55965c66d78c700f954c5d28c9832964e702" translate="yes" xml:space="preserve">
          <source>[1] &amp;ldquo;Weighted Sums of Random Kitchen Sinks: Replacing minimization with randomization in learning&amp;rdquo; by A. Rahimi and Benjamin Recht. (&lt;a href=&quot;http://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&quot;&gt;http://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&lt;/a&gt;)</source>
          <target state="translated">[1] &amp;ldquo;Sumas ponderadas de fregaderos de cocina aleatorios: Reemplazo de la minimizaci&amp;oacute;n con la aleatorizaci&amp;oacute;n en el aprendizaje&amp;rdquo; por A. Rahimi y Benjamin Recht. ( &lt;a href=&quot;http://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&quot;&gt;http://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="4bdc516c4c0b901726d527e6df8200cdc4a8acc8" translate="yes" xml:space="preserve">
          <source>[1] &amp;ldquo;Weighted Sums of Random Kitchen Sinks: Replacing minimization with randomization in learning&amp;rdquo; by A. Rahimi and Benjamin Recht. (&lt;a href=&quot;https://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&quot;&gt;https://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&lt;/a&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="066cf0134c1716b5ce53bcaba6c6b8d7e86263f5" translate="yes" xml:space="preserve">
          <source>[1] Hastie, T., Tibshirani, R.,, Friedman, J. (2001). Model Assessment and Selection. The Elements of Statistical Learning (pp. 219-260). New York, NY, USA: Springer New York Inc..</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="851ede0920efe80a8308115ddfdc22058d99b224" translate="yes" xml:space="preserve">
          <source>[1] Hinton, G. E., Osindero, S. and Teh, Y. A fast learning algorithm for</source>
          <target state="translated">[1] Hinton, GE, Osindero, S. y Teh, Y. Un algoritmo de aprendizaje r&amp;aacute;pido para</target>
        </trans-unit>
        <trans-unit id="3208128766e3298f0714b3eacb4e2ecfc88475e9" translate="yes" xml:space="preserve">
          <source>[1] L. Breiman, &amp;ldquo;Random Forests&amp;rdquo;, Machine Learning, 45(1), 5-32,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4ab6918e1971671fbb440a7f8e61bfcc4315791" translate="yes" xml:space="preserve">
          <source>[1] P. J. Rousseeuw. Least median of squares regression. J. Am</source>
          <target state="translated">[1] PJ Rousseeuw. Mediana m&amp;iacute;nima de regresi&amp;oacute;n de cuadrados. Mermelada</target>
        </trans-unit>
        <trans-unit id="4becf43125cdaf0ec29f63ac1f954b679ab8e6bc" translate="yes" xml:space="preserve">
          <source>[1] Yoshua Bengio, Olivier Delalleau, Nicolas Le Roux. In Semi-Supervised Learning (2006), pp. 193-216</source>
          <target state="translated">[1] Yoshua Bengio, Olivier Delalleau, Nicolas Le Roux. En Aprendizaje semi-supervisado (2006), p&amp;aacute;gs. 193-216</target>
        </trans-unit>
        <trans-unit id="9a201577697a06c9ac689a946ae70d44d48c0e7c" translate="yes" xml:space="preserve">
          <source>[1] van der Maaten, L.J.P.; Hinton, G.E. Visualizing High-Dimensional Data</source>
          <target state="translated">[1] van der Maaten, LJP; Hinton, GE Visualizaci&amp;oacute;n de datos de alta dimensi&amp;oacute;n</target>
        </trans-unit>
        <trans-unit id="8eeff125eef3cfca1ff3f8b3157054b95e0b3509" translate="yes" xml:space="preserve">
          <source>[2] &amp;ldquo;Stochastic Variational Inference&amp;rdquo;, Matthew D. Hoffman, David M. Blei,</source>
          <target state="translated">[2] &amp;ldquo;Inferencia Variacional Estoc&amp;aacute;stica&amp;rdquo;, Matthew D. Hoffman, David M. Blei,</target>
        </trans-unit>
        <trans-unit id="ea3c887d7b7624a41f686043b166f388d3617ff3" translate="yes" xml:space="preserve">
          <source>[2] Olivier Delalleau, Yoshua Bengio, Nicolas Le Roux. Efficient Non-Parametric Function Induction in Semi-Supervised Learning. AISTAT 2005 &lt;a href=&quot;http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&quot;&gt;http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&lt;/a&gt;</source>
          <target state="translated">[2] Olivier Delalleau, Yoshua Bengio, Nicolas Le Roux. Inducci&amp;oacute;n eficiente de funciones no param&amp;eacute;tricas en aprendizaje semi-supervisado. AISTAT 2005 &lt;a href=&quot;http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&quot;&gt;http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="73434047889c8334ffffe648547654fa2862e107" translate="yes" xml:space="preserve">
          <source>[2] Olivier Delalleau, Yoshua Bengio, Nicolas Le Roux. Efficient Non-Parametric Function Induction in Semi-Supervised Learning. AISTAT 2005 &lt;a href=&quot;https://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&quot;&gt;https://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="390f7912993134abee39b500fe8ff987c558bcc7" translate="yes" xml:space="preserve">
          <source>[2] Tieleman, T. Training Restricted Boltzmann Machines using</source>
          <target state="translated">[2] Tieleman, T. Capacitaci&amp;oacute;n de m&amp;aacute;quinas Boltzmann restringidas usando</target>
        </trans-unit>
        <trans-unit id="936e8131576c3002ff436671f77d81f6c95e71d7" translate="yes" xml:space="preserve">
          <source>[2] Wilson, E. B., &amp;amp; Hilferty, M. M. (1931). The distribution of chi-square.</source>
          <target state="translated">[2] Wilson, EB y Hilferty, MM (1931). La distribuci&amp;oacute;n de chi-cuadrado.</target>
        </trans-unit>
        <trans-unit id="5cccbf6c7fe7c1f50410b68e37c12f00b67f9330" translate="yes" xml:space="preserve">
          <source>[2] van der Maaten, L.J.P. t-Distributed Stochastic Neighbor Embedding</source>
          <target state="translated">[2] van der Maaten, LJP Integraci&amp;oacute;n de vecinos estoc&amp;aacute;sticos distribuidos en t</target>
        </trans-unit>
        <trans-unit id="740947d1c8302c56dc8a9209234aab173f75acad" translate="yes" xml:space="preserve">
          <source>[3] L.J.P. van der Maaten. Accelerating t-SNE using Tree-Based Algorithms.</source>
          <target state="translated">[3] LJP van der Maaten. Aceleraci&amp;oacute;n de t-SNE mediante algoritmos basados ​​en &amp;aacute;rboles.</target>
        </trans-unit>
        <trans-unit id="a16dde9090b3c419b1ba6d8027b90785ddf73263" translate="yes" xml:space="preserve">
          <source>[3] Matthew D. Hoffman&amp;rsquo;s onlineldavb code. Link:</source>
          <target state="translated">[3] C&amp;oacute;digo onlineldavb de Matthew D. Hoffman. Enlace:</target>
        </trans-unit>
        <trans-unit id="2091fb37b7afd77ae2e8e60855d4cad2538ba378" translate="yes" xml:space="preserve">
          <source>[B1996]</source>
          <target state="translated">[B1996]</target>
        </trans-unit>
        <trans-unit id="66fa89cedf249bba6f8bbd7ca59a6edba1eb2520" translate="yes" xml:space="preserve">
          <source>[B1998]</source>
          <target state="translated">[B1998]</target>
        </trans-unit>
        <trans-unit id="7665023d9511c3ea5a7a3e7baca06057eba900d6" translate="yes" xml:space="preserve">
          <source>[B1999]</source>
          <target state="translated">[B1999]</target>
        </trans-unit>
        <trans-unit id="5c075f95c1e65a7e49dec5ad30ee36d1fb13b2b6" translate="yes" xml:space="preserve">
          <source>[B2001]</source>
          <target state="translated">[B2001]</target>
        </trans-unit>
        <trans-unit id="04bec92cc809290da2bf608da574e1877293633f" translate="yes" xml:space="preserve">
          <source>[B2011]</source>
          <target state="translated">[B2011]</target>
        </trans-unit>
        <trans-unit id="2b6c9f7f2623b948c281da789073abc37bb7f8fa" translate="yes" xml:space="preserve">
          <source>[ButlerDavies]</source>
          <target state="translated">[ButlerDavies]</target>
        </trans-unit>
        <trans-unit id="1d442f2d1661e89f1bc869a582a8d649d24881e4" translate="yes" xml:space="preserve">
          <source>[D1997]</source>
          <target state="translated">[D1997]</target>
        </trans-unit>
        <trans-unit id="20e70caf2f764d35f0c5f51eb6c2cc52a6f947f2" translate="yes" xml:space="preserve">
          <source>[Davis2006]</source>
          <target state="translated">[Davis2006]</target>
        </trans-unit>
        <trans-unit id="3b0f17e8250c1e7b54512123b77c31bb0899ae7a" translate="yes" xml:space="preserve">
          <source>[Everingham2010]</source>
          <target state="translated">[Everingham2010]</target>
        </trans-unit>
        <trans-unit id="e5ff04dac92d8d5710e2d4ade54a4899d9a01662" translate="yes" xml:space="preserve">
          <source>[F1999]</source>
          <target state="translated">[F1999]</target>
        </trans-unit>
        <trans-unit id="ddfaba8b68f822d387eefcc49dbcf89bee83fcbe" translate="yes" xml:space="preserve">
          <source>[F2001]</source>
          <target state="translated">[F2001]</target>
        </trans-unit>
        <trans-unit id="5712ff07224dea2f09976ad1b5f9060cea098ee8" translate="yes" xml:space="preserve">
          <source>[FS1995]</source>
          <target state="translated">[FS1995]</target>
        </trans-unit>
        <trans-unit id="111b120f6e2f3a7d9723c16133fcfb1ce7b7557b" translate="yes" xml:space="preserve">
          <source>[Flach2015]</source>
          <target state="translated">[Flach2015]</target>
        </trans-unit>
        <trans-unit id="0be1b91bf292e6f295e73f8ba1626aa315ca1709" translate="yes" xml:space="preserve">
          <source>[Guyon2015]</source>
          <target state="translated">[Guyon2015]</target>
        </trans-unit>
        <trans-unit id="16deff704a4f867ca18d98b22e63afcb70ec96d2" translate="yes" xml:space="preserve">
          <source>[H1998]</source>
          <target state="translated">[H1998]</target>
        </trans-unit>
        <trans-unit id="346ddc10d1a23f1ff0ba05ea1da881f4666595c5" translate="yes" xml:space="preserve">
          <source>[HTF2009]</source>
          <target state="translated">[HTF2009]</target>
        </trans-unit>
        <trans-unit id="2b6bce181ae06e6796d39628b4dc12ca65767e20" translate="yes" xml:space="preserve">
          <source>[HTF]</source>
          <target state="translated">[HTF]</target>
        </trans-unit>
        <trans-unit id="8f4756ba18c793a637ad7568fd4450479f47b718" translate="yes" xml:space="preserve">
          <source>[Hubert1985]</source>
          <target state="translated">[Hubert1985]</target>
        </trans-unit>
        <trans-unit id="1c2acae56920363d695dc395b30aa0dac0656aa7" translate="yes" xml:space="preserve">
          <source>[Jen09]</source>
          <target state="translated">[Jen09]</target>
        </trans-unit>
        <trans-unit id="52833f723be6af6645b6622da4d471b65e89d942" translate="yes" xml:space="preserve">
          <source>[Kelleher2015]</source>
          <target state="translated">[Kelleher2015]</target>
        </trans-unit>
        <trans-unit id="8d63f432cd9715591fb04662784fbed01426124f" translate="yes" xml:space="preserve">
          <source>[L2014]</source>
          <target state="translated">[L2014]</target>
        </trans-unit>
        <trans-unit id="e6f810474b9d9bf1966e66d024bfd2d0d9af7983" translate="yes" xml:space="preserve">
          <source>[LG2012]</source>
          <target state="translated">[LG2012]</target>
        </trans-unit>
        <trans-unit id="4108a351bec333bc41371d8be81bbf1f0bd216a0" translate="yes" xml:space="preserve">
          <source>[LS2010]</source>
          <target state="translated">[LS2010]</target>
        </trans-unit>
        <trans-unit id="36c1f9470816b8da81a8ed80471ace8df2456c31" translate="yes" xml:space="preserve">
          <source>[M2012]</source>
          <target state="translated">[M2012]</target>
        </trans-unit>
        <trans-unit id="536dc6f43e65eedbc7dcd92d64ef850b0a7951d3" translate="yes" xml:space="preserve">
          <source>[MRS2008]</source>
          <target state="translated">[MRS2008]</target>
        </trans-unit>
        <trans-unit id="350f14f810397ce0cd7520f35f0fae7d54d72023" translate="yes" xml:space="preserve">
          <source>[Manning2008]</source>
          <target state="translated">[Manning2008]</target>
        </trans-unit>
        <trans-unit id="0cc214a1564fbbf90b4daa0b0972b6f8408e3afc" translate="yes" xml:space="preserve">
          <source>[Mosley2013]</source>
          <target state="translated">[Mosley2013]</target>
        </trans-unit>
        <trans-unit id="73be0b37b87d3c88f49438b3a7ca251dc3d3c1d2" translate="yes" xml:space="preserve">
          <source>[Mrl09]</source>
          <target state="translated">[Mrl09]</target>
        </trans-unit>
        <trans-unit id="690e639d5d468ec30ab9e54cb03287a1d07d286f" translate="yes" xml:space="preserve">
          <source>[NQY18]</source>
          <target state="translated">[NQY18]</target>
        </trans-unit>
        <trans-unit id="95849b59dfe0de62fa4f930bc19ca3b64ad51c5b" translate="yes" xml:space="preserve">
          <source>[R2007]</source>
          <target state="translated">[R2007]</target>
        </trans-unit>
        <trans-unit id="d27f89b25dd2806ef3b69d37ac341ea761b1f775" translate="yes" xml:space="preserve">
          <source>[RR2007]</source>
          <target state="translated">[RR2007]</target>
        </trans-unit>
        <trans-unit id="99aae3a9e5135b3c3c9e6f81c5583f53ea54b161" translate="yes" xml:space="preserve">
          <source>[RVD]</source>
          <target state="translated">[RVD]</target>
        </trans-unit>
        <trans-unit id="7fc4fd0834c6c78f63966f47416f1e672a05b032" translate="yes" xml:space="preserve">
          <source>[RVDriessen]</source>
          <target state="translated">[RVDriessen]</target>
        </trans-unit>
        <trans-unit id="9a3d290ec7e0cf466e2e530b732c430fd93742e5" translate="yes" xml:space="preserve">
          <source>[RW2006]</source>
          <target state="translated">[RW2006]</target>
        </trans-unit>
        <trans-unit id="ab40883d6ce3b576febad86ad20a220ae60fc722" translate="yes" xml:space="preserve">
          <source>[Rouseeuw1984]</source>
          <target state="translated">[Rouseeuw1984]</target>
        </trans-unit>
        <trans-unit id="f4ff5aad65e1461e94ef70a659337011d0c58126" translate="yes" xml:space="preserve">
          <source>[Rousseeuw]</source>
          <target state="translated">[Rousseeuw]</target>
        </trans-unit>
        <trans-unit id="74f2d2c5b044f5dc96afc1e0482d2495c57d5370" translate="yes" xml:space="preserve">
          <source>[Urbanowicz2015]</source>
          <target state="translated">[Urbanowicz2015]</target>
        </trans-unit>
        <trans-unit id="34cb3f1593778c84c25ed6665ee9a323140a68d9" translate="yes" xml:space="preserve">
          <source>[VEB2009] Vinh, Epps, and Bailey, (2009). &amp;ldquo;Information theoretic measures for clusterings comparison&amp;rdquo;. Proceedings of the 26th Annual International Conference on Machine Learning - ICML &amp;lsquo;09. &lt;a href=&quot;https://dl.acm.org/citation.cfm?doid=1553374.1553511&quot;&gt;doi:10.1145/1553374.1553511&lt;/a&gt;. ISBN 9781605585161.</source>
          <target state="translated">[VEB2009] Vinh, Epps y Bailey, (2009). &amp;ldquo;Medidas te&amp;oacute;ricas de la informaci&amp;oacute;n para la comparaci&amp;oacute;n de agrupaciones&amp;rdquo;. Actas de la 26a Conferencia Internacional Anual sobre Aprendizaje Autom&amp;aacute;tico - ICML '09. &lt;a href=&quot;https://dl.acm.org/citation.cfm?doid=1553374.1553511&quot;&gt;doi: 10.1145 / 1553374.1553511&lt;/a&gt; . ISBN 9781605585161.</target>
        </trans-unit>
        <trans-unit id="48a5d15f42b24744d500812bf01a83ad55ecae83" translate="yes" xml:space="preserve">
          <source>[VEB2010] Vinh, Epps, and Bailey, (2010). &amp;ldquo;Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance&amp;rdquo;. JMLR &amp;lt;&lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&lt;/a&gt;&amp;gt;</source>
          <target state="translated">[VEB2010] Vinh, Epps y Bailey, (2010). &amp;ldquo;Medidas te&amp;oacute;ricas de la informaci&amp;oacute;n para la comparaci&amp;oacute;n de agrupaciones: variantes, propiedades, normalizaci&amp;oacute;n y correcci&amp;oacute;n por azar&amp;rdquo;. JMLR &amp;lt; &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&lt;/a&gt; &amp;gt;</target>
        </trans-unit>
        <trans-unit id="0cb878c6eb08bc32d947d6ddc4baaa42377cefd9" translate="yes" xml:space="preserve">
          <source>[VVZ2010]</source>
          <target state="translated">[VVZ2010]</target>
        </trans-unit>
        <trans-unit id="3db6db2379703ce194c034f1bb123b847f702832" translate="yes" xml:space="preserve">
          <source>[VZ2010]</source>
          <target state="translated">[VZ2010]</target>
        </trans-unit>
        <trans-unit id="4f385f25921c7c64a43d9b5e0a8904686fbad4ed" translate="yes" xml:space="preserve">
          <source>[X1, y1, &amp;hellip;, Xn, yn]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70b15e6dab0cb6917fd158eac29a9ddf08fcef21" translate="yes" xml:space="preserve">
          <source>[YAT2016] Yang, Algesheimer, and Tessone, (2016). &amp;ldquo;A comparative analysis of community detection algorithms on artificial networks&amp;rdquo;. Scientific Reports 6: 30750. &lt;a href=&quot;https://www.nature.com/articles/srep30750&quot;&gt;doi:10.1038/srep30750&lt;/a&gt;.</source>
          <target state="translated">[YAT2016] Yang, Algesheimer y Tessone, (2016). &amp;ldquo;Un an&amp;aacute;lisis comparativo de algoritmos de detecci&amp;oacute;n de comunidades en redes artificiales&amp;rdquo;. Scientific Reports 6: 30750. &lt;a href=&quot;https://www.nature.com/articles/srep30750&quot;&gt;doi: 10.1038 / srep30750&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="652e235b7dc2f3d75c7f909152b3819c6c97a6ec" translate="yes" xml:space="preserve">
          <source>[Yates2011]</source>
          <target state="translated">[Yates2011]</target>
        </trans-unit>
        <trans-unit id="e3b9ec6790a1b2a9d7bcca67037f67b282ccc4ee" translate="yes" xml:space="preserve">
          <source>[ZZRH2009]</source>
          <target state="translated">[ZZRH2009]</target>
        </trans-unit>
        <trans-unit id="96b76160e0ad993ba5f0d18a67c96f386933b35a" translate="yes" xml:space="preserve">
          <source>[[1, x_1, x_1 ** 2, x_1 ** 3, &amp;hellip;],</source>
          <target state="translated">[[1, x_1, x_1 ** 2, x_1 ** 3,&amp;hellip;],</target>
        </trans-unit>
        <trans-unit id="2eab98aedd6e4787cc1b6ed7c5288a5a2279237c" translate="yes" xml:space="preserve">
          <source>[callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.</source>
          <target state="translated">[invocable]: una funci&amp;oacute;n definida por el usuario que acepta una matriz de distancias y devuelve una matriz de la misma forma que contiene los pesos.</target>
        </trans-unit>
        <trans-unit id="b622702bcf4592f09f68d731f0a4b9f486da53eb" translate="yes" xml:space="preserve">
          <source>[n_samples_a, n_features] otherwise Array of pairwise distances between samples, or a feature array.</source>
          <target state="translated">[n_samples_a, n_features] de lo contrario Matriz de distancias por pares entre muestras o una matriz de caracter&amp;iacute;sticas.</target>
        </trans-unit>
        <trans-unit id="361169bda90a02e4e54f39ff838115b39a75d83d" translate="yes" xml:space="preserve">
          <source>[wk]</source>
          <target state="translated">[wk]</target>
        </trans-unit>
        <trans-unit id="a4fcb5a87f4e322ea14fa74b5213a00a6d8c1551" translate="yes" xml:space="preserve">
          <source>\((y-\hat{y})^2\)</source>
          <target state="translated">\((y-\hat{y})^2\)</target>
        </trans-unit>
        <trans-unit id="b66b6613ed1a2db616d592d66bc160b7abcc7139" translate="yes" xml:space="preserve">
          <source>\(2(\log\frac{\hat{y}}{y}+\frac{y}{\hat{y}}-1)\)</source>
          <target state="translated">\(2(\log\frac{\hat{y}}{y}+\frac{y}{\hat{y}}-1)\)</target>
        </trans-unit>
        <trans-unit id="764bb49b144ee69e8d51ad0d7a5cedd15acf75d9" translate="yes" xml:space="preserve">
          <source>\(2(y\log\frac{y}{\hat{y}}-y+\hat{y})\)</source>
          <target state="translated">\(2(y\log\frac{y}{\hat{y}}-y+\hat{y})\)</target>
        </trans-unit>
        <trans-unit id="cade30b6baa03b8bc431f6cb3586bc5b1d642a6f" translate="yes" xml:space="preserve">
          <source>\(C\) is used to set the amount of regularization</source>
          <target state="translated">\ (C \) se usa para establecer la cantidad de regularizaci&amp;oacute;n</target>
        </trans-unit>
        <trans-unit id="ad93e4d23ea1b4d81a2b3f3c3d29dff7d49b5d27" translate="yes" xml:space="preserve">
          <source>\(D\) : input dimension</source>
          <target state="translated">\ (D \): dimensi&amp;oacute;n de entrada</target>
        </trans-unit>
        <trans-unit id="a32e93d880aaba8a860e59edd1cb39f288e59537" translate="yes" xml:space="preserve">
          <source>\(F1 = 2\frac{P \times R}{P+R}\)</source>
          <target state="translated">\ (F1 = 2 \ frac {P \ veces R} {P + R} \)</target>
        </trans-unit>
        <trans-unit id="6e8b3587e80a2131c2360cdeb81572614017e523" translate="yes" xml:space="preserve">
          <source>\(F_\beta(A, B) := \left(1 + \beta^2\right) \frac{P(A, B) \times R(A, B)}{\beta^2 P(A, B) + R(A, B)}\)</source>
          <target state="translated">\ (F_ \ beta (A, B): = \ left (1 + \ beta ^ 2 \ right) \ frac {P (A, B) \ times R (A, B)} {\ beta ^ 2 P (A , B) + R (A, B)} \)</target>
        </trans-unit>
        <trans-unit id="9a350d9475f7eafeffa8a9835bca28d431bee93e" translate="yes" xml:space="preserve">
          <source>\(F_\beta(y, \hat{y})\)</source>
          <target state="translated">\ (F_ \ beta (y, \ hat {y}) \)</target>
        </trans-unit>
        <trans-unit id="09eb5f139bd0c207766706ffe3b5d171a556d4ec" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto 1 - \frac{x^2}{h^2}\)</source>
          <target state="translated">\ (K (x; h) \ propto 1 - \ frac {x ^ 2} {h ^ 2} \)</target>
        </trans-unit>
        <trans-unit id="95dfc8e81899d8cb940cb0df0bfaa1052ffb36d2" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto 1 - x/h\) if \(x &amp;lt; h\)</source>
          <target state="translated">\ (K (x; h) \ propto 1 - x / h \) si \ (x &amp;lt;h \)</target>
        </trans-unit>
        <trans-unit id="2a910118bdbf495d82747952ba6971367b93dfac" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto 1\) if \(x &amp;lt; h\)</source>
          <target state="translated">\ (K (x; h) \ propto 1 \) si \ (x &amp;lt;h \)</target>
        </trans-unit>
        <trans-unit id="4b298d5bd2fdf7182db10bf076925db3745527a8" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto \cos(\frac{\pi x}{2h})\) if \(x &amp;lt; h\)</source>
          <target state="translated">\ (K (x; h) \ propto \ cos (\ frac {\ pi x} {2h}) \) si \ (x &amp;lt;h \)</target>
        </trans-unit>
        <trans-unit id="a4443829e2c48ab72daedb9b74f9dc8debc9681a" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto \exp(- \frac{x^2}{2h^2} )\)</source>
          <target state="translated">\ (K (x; h) \ propto \ exp (- \ frac {x ^ 2} {2h ^ 2}) \)</target>
        </trans-unit>
        <trans-unit id="c70853c06adf6986de8dcbc5a8f801fc0502ae1b" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto \exp(-x/h)\)</source>
          <target state="translated">\ (K (x; h) \ propto \ exp (-x / h) \)</target>
        </trans-unit>
        <trans-unit id="7d9776eac061dd7f197e8155c6784a047082de92" translate="yes" xml:space="preserve">
          <source>\(L\) the set of labels</source>
          <target state="translated">\ (L \) el conjunto de etiquetas</target>
        </trans-unit>
        <trans-unit id="f0f78908f9cef66c5c39e39b004aba794a24d223" translate="yes" xml:space="preserve">
          <source>\(N\) : number of training data points</source>
          <target state="translated">\ (N \): n&amp;uacute;mero de puntos de datos de entrenamiento</target>
        </trans-unit>
        <trans-unit id="85d811223bbd2564d928a5184adabae9693a9903" translate="yes" xml:space="preserve">
          <source>\(P = \frac{T_p}{T_p+F_p}\)</source>
          <target state="translated">\ (P = \ frac {T_p} {T_p + F_p} \)</target>
        </trans-unit>
        <trans-unit id="5c7b5d8ee367861eab9617a9df8debede099fe4a" translate="yes" xml:space="preserve">
          <source>\(P(A, B) := \frac{\left| A \cap B \right|}{\left|A\right|}\)</source>
          <target state="translated">\ (P (A, B): = \ frac {\ left | A \ cap B \ right |} {\ left | A \ right |} \)</target>
        </trans-unit>
        <trans-unit id="b2e10949fc710189ed8a464185eb0fbad995ab8d" translate="yes" xml:space="preserve">
          <source>\(P(A, B) := \frac{\left| A \cap B \right|}{\left|A\right|}\) for some sets \(A\) and \(B\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c180cdb6205e02ec243b8a0c392cb71991d0a3d0" translate="yes" xml:space="preserve">
          <source>\(P(y, \hat{y})\)</source>
          <target state="translated">\ (P (y, \ hat {y}) \)</target>
        </trans-unit>
        <trans-unit id="c753c8fc287915fbc16c3d512099716031e38eb4" translate="yes" xml:space="preserve">
          <source>\(R = \frac{T_p}{T_p + F_n}\)</source>
          <target state="translated">\ (R = \ frac {T_p} {T_p + F_n} \)</target>
        </trans-unit>
        <trans-unit id="2d1e6161821a7c78dd1e8cc86ac7329f67bfcf0c" translate="yes" xml:space="preserve">
          <source>\(R(A, B) := \frac{\left| A \cap B \right|}{\left|B\right|}\) (Conventions vary on handling \(B = \emptyset\); this implementation uses \(R(A, B):=0\), and similar for \(P\).)</source>
          <target state="translated">\ (R (A, B): = \ frac {\ left | A \ cap B \ right |} {\ left | B \ right |} \) (Las convenciones var&amp;iacute;an en el manejo de \ (B = \ emptyset \); esto la implementaci&amp;oacute;n usa \ (R (A, B): = 0 \), y similar para \ (P \).)</target>
        </trans-unit>
        <trans-unit id="76e12b53dc747a452508648de37b3bbf1292886a" translate="yes" xml:space="preserve">
          <source>\(R(y, \hat{y})\)</source>
          <target state="translated">\ (R (y, \ hat {y}) \)</target>
        </trans-unit>
        <trans-unit id="fe30e7d28d145393d116de8ccfdb95f1930cc647" translate="yes" xml:space="preserve">
          <source>\(S\) the set of samples</source>
          <target state="translated">\ (S \) el conjunto de muestras</target>
        </trans-unit>
        <trans-unit id="4d975b6c5632f1c81d6cf8cc9f674c8e0d143548" translate="yes" xml:space="preserve">
          <source>\(X\): data</source>
          <target state="translated">\ (X \): datos</target>
        </trans-unit>
        <trans-unit id="59b5b0f07758a431bbb7dbf6ebe63bc98b0cd7dd" translate="yes" xml:space="preserve">
          <source>\(\Omega\) is a &lt;code&gt;penalty&lt;/code&gt; function of our model parameters</source>
          <target state="translated">\ (\ Omega \) es una funci&amp;oacute;n de &lt;code&gt;penalty&lt;/code&gt; de los par&amp;aacute;metros de nuestro modelo</target>
        </trans-unit>
        <trans-unit id="d82693345c0acee22512b8f82f5807d2eafe4d72" translate="yes" xml:space="preserve">
          <source>\(\Psi = \mathrm{diag}(\psi_1, \psi_2, \dots, \psi_n)\): This model is called &lt;a href=&quot;generated/sklearn.decomposition.factoranalysis#sklearn.decomposition.FactorAnalysis&quot;&gt;&lt;code&gt;FactorAnalysis&lt;/code&gt;&lt;/a&gt;, a classical statistical model. The matrix W is sometimes called the &amp;ldquo;factor loading matrix&amp;rdquo;.</source>
          <target state="translated">\ (\ Psi = \ mathrm {diag} (\ psi_1, \ psi_2, \ dots, \ psi_n) \): Este modelo se llama &lt;a href=&quot;generated/sklearn.decomposition.factoranalysis#sklearn.decomposition.FactorAnalysis&quot;&gt; &lt;code&gt;FactorAnalysis&lt;/code&gt; &lt;/a&gt; , un modelo estad&amp;iacute;stico cl&amp;aacute;sico. La matriz W a veces se denomina &quot;matriz de carga factorial&quot;.</target>
        </trans-unit>
        <trans-unit id="fbd9ea497a59df8b22d9aee98766b15298f6f7b0" translate="yes" xml:space="preserve">
          <source>\(\Psi = \sigma^2 \mathbf{I}\): This assumption leads to the probabilistic model of &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">\ (\ Psi = \ sigma ^ 2 \ mathbf {I} \): Esta suposici&amp;oacute;n conduce al modelo probabil&amp;iacute;stico de &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="01f8f0e3a7f60922aad934db70b43f4626579a4f" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{0,1}\)</source>
          <target state="translated">\(\alpha^{0}_{0,1}\)</target>
        </trans-unit>
        <trans-unit id="51f4c7f6d4e230692f7f7ca95d3a951f2ccb6900" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{0,2}\)</source>
          <target state="translated">\(\alpha^{0}_{0,2}\)</target>
        </trans-unit>
        <trans-unit id="fc59eea930c0650810949c61616237e10d7608e7" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{1,0}\)</source>
          <target state="translated">\(\alpha^{0}_{1,0}\)</target>
        </trans-unit>
        <trans-unit id="b7a1987ec2f1ae255445b9203ba76dab46f8180e" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{1,2}\)</source>
          <target state="translated">\(\alpha^{0}_{1,2}\)</target>
        </trans-unit>
        <trans-unit id="ddda7bd4dda2cccb6220d08cd96b97d2564703fc" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{2,0}\)</source>
          <target state="translated">\(\alpha^{0}_{2,0}\)</target>
        </trans-unit>
        <trans-unit id="cd76d3a6ac27cf4608fdba8c1bcefea98e40a082" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{2,1}\)</source>
          <target state="translated">\(\alpha^{0}_{2,1}\)</target>
        </trans-unit>
        <trans-unit id="670a0c506ecd80ad22241edc90899b4ca5a65063" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{0,1}\)</source>
          <target state="translated">\(\alpha^{1}_{0,1}\)</target>
        </trans-unit>
        <trans-unit id="715b85177f34a3aec41f1d6aca5ea943c045452d" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{0,2}\)</source>
          <target state="translated">\(\alpha^{1}_{0,2}\)</target>
        </trans-unit>
        <trans-unit id="9bafd2e8e2343917301e41ef344db246b60c40d3" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{1,0}\)</source>
          <target state="translated">\(\alpha^{1}_{1,0}\)</target>
        </trans-unit>
        <trans-unit id="bd6409137f75a05bb280bc5000840c3e16f9d850" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{1,2}\)</source>
          <target state="translated">\(\alpha^{1}_{1,2}\)</target>
        </trans-unit>
        <trans-unit id="e31f66e6ca63dbde84a383e5d61ebb97f39d2fa6" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{2,0}\)</source>
          <target state="translated">\(\alpha^{1}_{2,0}\)</target>
        </trans-unit>
        <trans-unit id="603e33877eb24d9878fa7efb61a9c926fb80dd71" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{2,1}\)</source>
          <target state="translated">\(\alpha^{1}_{2,1}\)</target>
        </trans-unit>
        <trans-unit id="9ffe8c9fb6dee2771ab0ca39575e1df479c8a1ca" translate="yes" xml:space="preserve">
          <source>\(\alpha^{2}_{0,1}\)</source>
          <target state="translated">\(\alpha^{2}_{0,1}\)</target>
        </trans-unit>
        <trans-unit id="7f0fc3efbc7900034a8626635972b65d78e7a257" translate="yes" xml:space="preserve">
          <source>\(\alpha^{2}_{0,2}\)</source>
          <target state="translated">\(\alpha^{2}_{0,2}\)</target>
        </trans-unit>
        <trans-unit id="69166f5380836f7b04cceea34acce5263efbceff" translate="yes" xml:space="preserve">
          <source>\(\beta\): Coefficients</source>
          <target state="translated">\ (\ beta \): Coeficientes</target>
        </trans-unit>
        <trans-unit id="fec074bbf7d22c3b3d841bc5e89270a0a2f32779" translate="yes" xml:space="preserve">
          <source>\(\epsilon\): Observation noise</source>
          <target state="translated">\ (\ epsilon \): ruido de observaci&amp;oacute;n</target>
        </trans-unit>
        <trans-unit id="12791ef36495d018e1daf82140fd4c3db8180c28" translate="yes" xml:space="preserve">
          <source>\(\frac{(y-\hat{y})^2}{y\hat{y}^2}\)</source>
          <target state="translated">\(\frac{(y-\hat{y})^2}{y\hat{y}^2}\)</target>
        </trans-unit>
        <trans-unit id="08cc56772d86f4dfece03ec8003aba4f776d2aab" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|L\right|} \sum_{l \in L} F_\beta(y_l, \hat{y}_l)\)</source>
          <target state="translated">\ (\ frac {1} {\ left | L \ right |} \ sum_ {l \ in L} F_ \ beta (y_l, \ hat {y} _l) \)</target>
        </trans-unit>
        <trans-unit id="8c4693b66d3ba7a40d8a9abfe000616818f55aaf" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|L\right|} \sum_{l \in L} P(y_l, \hat{y}_l)\)</source>
          <target state="translated">\ (\ frac {1} {\ left | L \ right |} \ sum_ {l \ in L} P (y_l, \ hat {y} _l) \)</target>
        </trans-unit>
        <trans-unit id="52e6ce52e9b8ae2877c124e769de40084f5638d9" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|L\right|} \sum_{l \in L} R(y_l, \hat{y}_l)\)</source>
          <target state="translated">\ (\ frac {1} {\ left | L \ right |} \ sum_ {l \ in L} R (y_l, \ hat {y} _l) \)</target>
        </trans-unit>
        <trans-unit id="7f2d1bc16a43e60170cc4d3e4429f1eaefb3b9b2" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|S\right|} \sum_{s \in S} F_\beta(y_s, \hat{y}_s)\)</source>
          <target state="translated">\ (\ frac {1} {\ left | S \ right |} \ sum_ {s \ in S} F_ \ beta (y_s, \ hat {y} _s) \)</target>
        </trans-unit>
        <trans-unit id="301209259a59426be923af21027651f698a1adbb" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|S\right|} \sum_{s \in S} P(y_s, \hat{y}_s)\)</source>
          <target state="translated">\ (\ frac {1} {\ left | S \ right |} \ sum_ {s \ in S} P (y_s, \ hat {y} _s) \)</target>
        </trans-unit>
        <trans-unit id="76d3b6c7bb7266c85c29df970c85d63d00762934" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|S\right|} \sum_{s \in S} R(y_s, \hat{y}_s)\)</source>
          <target state="translated">\ (\ frac {1} {\ left | S \ right |} \ sum_ {s \ in S} R (y_s, \ hat {y} _s) \)</target>
        </trans-unit>
        <trans-unit id="771a76dcfeccc7d1c5c81729270313804a1579cd" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\sum_{l \in L} \left|\hat{y}_l\right|} \sum_{l \in L} \left|\hat{y}_l\right| F_\beta(y_l, \hat{y}_l)\)</source>
          <target state="translated">\ (\ frac {1} {\ sum_ {l \ in L} \ left | \ hat {y} _l \ right |} \ sum_ {l \ in L} \ left | \ hat {y} _l \ right | F_ \ beta (y_l, \ hat {y} _l) \)</target>
        </trans-unit>
        <trans-unit id="8c17ed8e7ab856a74c9c5ce2466ffe22f7bfd45b" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\sum_{l \in L} \left|\hat{y}_l\right|} \sum_{l \in L} \left|\hat{y}_l\right| P(y_l, \hat{y}_l)\)</source>
          <target state="translated">\ (\ frac {1} {\ sum_ {l \ in L} \ left | \ hat {y} _l \ right |} \ sum_ {l \ in L} \ left | \ hat {y} _l \ right | P (y_l, \ hat {y} _l) \)</target>
        </trans-unit>
        <trans-unit id="084995f248284e6186e09f61b6402476e717eb20" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\sum_{l \in L} \left|\hat{y}_l\right|} \sum_{l \in L} \left|\hat{y}_l\right| R(y_l, \hat{y}_l)\)</source>
          <target state="translated">\ (\ frac {1} {\ sum_ {l \ in L} \ left | \ hat {y} _l \ right |} \ sum_ {l \ in L} \ left | \ hat {y} _l \ right | R (y_l, \ hat {y} _l) \)</target>
        </trans-unit>
        <trans-unit id="6e89e30113ce1a3053ff34b9257e3d282abe2f88" translate="yes" xml:space="preserve">
          <source>\(\frac{[3, 0, 1.8473]}{\sqrt{\big(3^2 + 0^2 + 1.8473^2\big)}} = [0.8515, 0, 0.5243]\):</source>
          <target state="translated">\ (\ frac {[3, 0, 1.8473]} {\ sqrt {\ big (3 ^ 2 + 0 ^ 2 + 1.8473 ^ 2 \ big)}} = [0.8515, 0, 0.5243] \):</target>
        </trans-unit>
        <trans-unit id="673551b6d125b3cd94d7674f49f994c6afdd6f65" translate="yes" xml:space="preserve">
          <source>\(\frac{[3, 0, 2.0986]}{\sqrt{\big(3^2 + 0^2 + 2.0986^2\big)}} = [ 0.819, 0, 0.573].\)</source>
          <target state="translated">\ (\ frac {[3, 0, 2.0986]} {\ sqrt {\ big (3 ^ 2 + 0 ^ 2 + 2.0986 ^ 2 \ big)}} = [0.819, 0, 0.573]. \)</target>
        </trans-unit>
        <trans-unit id="1a5082b9d05f10e66dae95fed7849c72d0a8cfc1" translate="yes" xml:space="preserve">
          <source>\(\gamma\) is known as slope</source>
          <target state="translated">\ (\ gamma \) se conoce como pendiente</target>
        </trans-unit>
        <trans-unit id="126898e7757cd77e4cefb87e42f683763bf54571" translate="yes" xml:space="preserve">
          <source>\(\hat{y}\) the set of &lt;em&gt;true&lt;/em&gt;\((sample, label)\) pairs</source>
          <target state="translated">\ (\ hat {y} \) el conjunto de pares \ ((muestra, etiqueta) \) &lt;em&gt;verdaderos&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="9f39f60cd1f2428420af5f2dec2780245432c521" translate="yes" xml:space="preserve">
          <source>\(\langle F_\beta(y_l, \hat{y}_l) | l \in L \rangle\)</source>
          <target state="translated">\ (\ langle F_ \ beta (y_l, \ hat {y} _l) | l \ in L \ rangle \)</target>
        </trans-unit>
        <trans-unit id="f3dc3b8f8243a37f6cfc63694bfee10bbc8dbb16" translate="yes" xml:space="preserve">
          <source>\(\langle P(y_l, \hat{y}_l) | l \in L \rangle\)</source>
          <target state="translated">\ (\ langle P (y_l, \ hat {y} _l) | l \ in L \ rangle \)</target>
        </trans-unit>
        <trans-unit id="1c6337bdf58558dfa45a337181a8da415d8b489c" translate="yes" xml:space="preserve">
          <source>\(\langle R(y_l, \hat{y}_l) | l \in L \rangle\)</source>
          <target state="translated">\ (\ langle R (y_l, \ hat {y} _l) | l \ in L \ rangle \)</target>
        </trans-unit>
        <trans-unit id="825ca6208fb0c99a89fb31d3479b162477b3c1b6" translate="yes" xml:space="preserve">
          <source>\(\mathcal{L}\) is a &lt;code&gt;loss&lt;/code&gt; function of our samples and our model parameters.</source>
          <target state="translated">\ (\ mathcal {L} \) es una funci&amp;oacute;n de &lt;code&gt;loss&lt;/code&gt; de nuestras muestras y par&amp;aacute;metros de nuestro modelo.</target>
        </trans-unit>
        <trans-unit id="2a02f90f2b2001d6562373a7ae2a2e1dfb4565e2" translate="yes" xml:space="preserve">
          <source>\(\text{AP} = \sum_n (R_n - R_{n-1}) P_n\)</source>
          <target state="translated">\ (\ text {AP} = \ sum_n (R_n - R_ {n-1}) P_n \)</target>
        </trans-unit>
        <trans-unit id="db505c609ecce8b6164765bd7848f3b41ea35f0d" translate="yes" xml:space="preserve">
          <source>\(\text{df}(d, t)_{\text{term1}} = 6\)</source>
          <target state="translated">\ (\ text {df} (d, t) _ {\ text {term1}} = 6 \)</target>
        </trans-unit>
        <trans-unit id="e0997db48a8d87bf8ee1c7a8fcaa36916a54e707" translate="yes" xml:space="preserve">
          <source>\(\text{df}(t)_{\text{term1}} = 6\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3761c41a5e61f125696abaab3d6ab5e6c9467a9a" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(d, t)_{\text{term1}} = log \frac{n_d}{\text{df}(d, t)} + 1 = log(1)+1 = 1\)</source>
          <target state="translated">\ (\ text {idf} (d, t) _ {\ text {term1}} = log \ frac {n_d} {\ text {df} (d, t)} + 1 = log (1) +1 = 1 \)</target>
        </trans-unit>
        <trans-unit id="aa5a67b1ed0374bd72cf6f0e10b3fe3a74615260" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = \log{\frac{1 + n}{1+\text{df}(t)}} + 1\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="528e4287e895ebbf7910677616d1f6077d104040" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = \log{\frac{1 + n}{1+\text{df}(t)}} + 1\),</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61843849cf83ac9cc60022c827bcec315d11ec03" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = \log{\frac{n}{1+\text{df}(t)}}.\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3943a22b1a933b8cec2e621f9da837d0f8e0bccb" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = \log{\frac{n}{\text{df}(t)}} + 1\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="418ed87bb3a9ff83d64cef6c0afed152e2ce9063" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = log{\frac{1 + n_d}{1+\text{df}(d,t)}} + 1\)</source>
          <target state="translated">\ (\ text {idf} (t) = log {\ frac {1 + n_d} {1+ \ text {df} (d, t)}} + 1 \)</target>
        </trans-unit>
        <trans-unit id="cbf2fa82ddd1456d42b5d1023dd8e97cfb8e3a89" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = log{\frac{1 + n_d}{1+\text{df}(d,t)}} + 1\),</source>
          <target state="translated">\ (\ text {idf} (t) = log {\ frac {1 + n_d} {1+ \ text {df} (d, t)}} + 1 \),</target>
        </trans-unit>
        <trans-unit id="4b7b756caf347e71181dfa1202016ab8356f261a" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = log{\frac{n_d}{1+\text{df}(d,t)}}.\)</source>
          <target state="translated">\ (\ text {idf} (t) = log {\ frac {n_d} {1+ \ text {df} (d, t)}}. \)</target>
        </trans-unit>
        <trans-unit id="4034a1550b8c7d630dbd8eba4c06d1a4f1d30dc5" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = log{\frac{n_d}{\text{df}(d,t)}} + 1\)</source>
          <target state="translated">\ (\ text {idf} (t) = log {\ frac {n_d} {\ text {df} (d, t)}} + 1 \)</target>
        </trans-unit>
        <trans-unit id="96edf4cb5b96d644ba339f4099a39ef286ca85fb" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t)_{\text{term1}} = \log \frac{n}{\text{df}(t)} + 1 = \log(1)+1 = 1\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f18c6689111b29d4354e7fffcee7cc0802b481a5" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{raw}} = [3, 0, 2.0986].\)</source>
          <target state="translated">\ (\ text {tf-idf} _ {\ text {raw}} = [3, 0, 2.0986]. \)</target>
        </trans-unit>
        <trans-unit id="80aba8c317a078e4609ae8bd36660d65edad7083" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term1}} = \text{tf} \times \text{idf} = 3 \times 1 = 3\)</source>
          <target state="translated">\ (\ text {tf-idf} _ {\ text {term1}} = \ text {tf} \ times \ text {idf} = 3 \ times 1 = 3 \)</target>
        </trans-unit>
        <trans-unit id="1d70946637e51aace1378ca1a204825107f21cdf" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term2}} = 0 \times (\log(6/1)+1) = 0\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f8322f95350f60ce08c7cdd3032f22e074bd2b1" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term2}} = 0 \times (log(6/1)+1) = 0\)</source>
          <target state="translated">\ (\ text {tf-idf} _ {\ text {term2}} = 0 \ veces (log (6/1) +1) = 0 \)</target>
        </trans-unit>
        <trans-unit id="a326be18c218e6683afc2f56f1612584e40eaa79" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term3}} = 1 \times (\log(6/2)+1) \approx 2.0986\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dcd228feb463195495d0b530544c87a8f5f36307" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term3}} = 1 \times (log(6/2)+1) \approx 2.0986\)</source>
          <target state="translated">\ (\ text {tf-idf} _ {\ text {term3}} = 1 \ times (log (6/2) +1) \ approx 2.0986 \)</target>
        </trans-unit>
        <trans-unit id="9c4af8e7df634860beafeba835d8777813396030" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term3}} = 1 \times \log(7/3)+1 \approx 1.8473\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8c4b99bd2ff2af3e5f2b8ace2008c6e0a9ef2e7" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term3}} = 1 \times log(7/3)+1 \approx 1.8473\)</source>
          <target state="translated">\ (\ text {tf-idf} _ {\ text {term3}} = 1 \ times log (7/3) +1 \ approx 1.8473 \)</target>
        </trans-unit>
        <trans-unit id="b1e424267dd17efa4321c87fe24219eaad1c3249" translate="yes" xml:space="preserve">
          <source>\(a\), the number of pairs of elements that are in the same set in C and in the same set in K</source>
          <target state="translated">\ (a \), el n&amp;uacute;mero de pares de elementos que est&amp;aacute;n en el mismo conjunto en C y en el mismo conjunto en K</target>
        </trans-unit>
        <trans-unit id="ffa07cceebbfadc52e2be9cdf6b9599e34083b82" translate="yes" xml:space="preserve">
          <source>\(b\), the number of pairs of elements that are in different sets in C and in different sets in K</source>
          <target state="translated">\ (b \), el n&amp;uacute;mero de pares de elementos que est&amp;aacute;n en diferentes conjuntos en C y en diferentes conjuntos en K</target>
        </trans-unit>
        <trans-unit id="9634b82eb2f3a1a53f10d0105fa96b96683012b1" translate="yes" xml:space="preserve">
          <source>\(c=\sum_{k}^{K} C_{kk}\) the total number of samples correctly predicted,</source>
          <target state="translated">\ (c = \ sum_ {k} ^ {K} C_ {kk} \) el n&amp;uacute;mero total de muestras predichas correctamente,</target>
        </trans-unit>
        <trans-unit id="e0b006e0f953d2967208fad0e101db9a95b1773e" translate="yes" xml:space="preserve">
          <source>\(c_0\) is known as intercept</source>
          <target state="translated">\ (c_0 \) se conoce como intersecci&amp;oacute;n</target>
        </trans-unit>
        <trans-unit id="20f463b5231561db0d1529b308e8cd1a67579869" translate="yes" xml:space="preserve">
          <source>\(d\) : output dimension</source>
          <target state="translated">\ (d \): dimensi&amp;oacute;n de salida</target>
        </trans-unit>
        <trans-unit id="3c2644dcb6baee3a2f0954ec1f4febb35c2c968e" translate="yes" xml:space="preserve">
          <source>\(d_{ij}\), the distance between cluster centroids \(i\) and \(j\).</source>
          <target state="translated">\ (d_ {ij} \), la distancia entre los centroides del cl&amp;uacute;ster \ (i \) y \ (j \).</target>
        </trans-unit>
        <trans-unit id="464de6af9c88cdb5c8c4a2137401febf7a5e41c7" translate="yes" xml:space="preserve">
          <source>\(k\) : number of nearest neighbors</source>
          <target state="translated">\ (k \): n&amp;uacute;mero de vecinos m&amp;aacute;s cercanos</target>
        </trans-unit>
        <trans-unit id="ded29692d567c68006b5e22274ae992999727d77" translate="yes" xml:space="preserve">
          <source>\(n = 6\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f8783323f752c7593ada8acf8c4d67282a83607" translate="yes" xml:space="preserve">
          <source>\(n_{d} = 6\)</source>
          <target state="translated">\ (n_ {d} = 6 \)</target>
        </trans-unit>
        <trans-unit id="13e265f7db3a9509d50f014f7170db211a73f394" translate="yes" xml:space="preserve">
          <source>\(p_k=\sum_{i}^{K} C_{ki}\) the number of times class \(k\) was predicted,</source>
          <target state="translated">\ (p_k = \ sum_ {i} ^ {K} C_ {ki} \) el n&amp;uacute;mero de veces que se predijo la clase \ (k \),</target>
        </trans-unit>
        <trans-unit id="cc4e2c50ba94767cc02eead7002753560f0219c2" translate="yes" xml:space="preserve">
          <source>\(s=\sum_{i}^{K} \sum_{j}^{K} C_{ij}\) the total number of samples.</source>
          <target state="translated">\ (s = \ sum_ {i} ^ {K} \ sum_ {j} ^ {K} C_ {ij} \) el n&amp;uacute;mero total de muestras.</target>
        </trans-unit>
        <trans-unit id="6eb93fac640cf512d1e63922116e7722c92fabe0" translate="yes" xml:space="preserve">
          <source>\(s_i\), the average distance between each point of cluster \(i\) and the centroid of that cluster &amp;ndash; also know as cluster diameter.</source>
          <target state="translated">\ (s_i \), la distancia promedio entre cada punto del grupo \ (i \) y el centroide de ese grupo, tambi&amp;eacute;n conocido como di&amp;aacute;metro del grupo.</target>
        </trans-unit>
        <trans-unit id="2904d711734ca668dfddae3cff9c273e4d482636" translate="yes" xml:space="preserve">
          <source>\(t_k=\sum_{i}^{K} C_{ik}\) the number of times class \(k\) truly occurred,</source>
          <target state="translated">\ (t_k = \ sum_ {i} ^ {K} C_ {ik} \) el n&amp;uacute;mero de veces que realmente ocurri&amp;oacute; la clase \ (k \),</target>
        </trans-unit>
        <trans-unit id="0a59d79c97bec565e1c47b5aab7109c37d7376fa" translate="yes" xml:space="preserve">
          <source>\(v_{norm} = \frac{v}{||v||_2} = \frac{v}{\sqrt{v{_1}^2 + v{_2}^2 + \dots + v{_n}^2}}\)</source>
          <target state="translated">\ (v_ {norma} = \ frac {v} {|| v || _2} = \ frac {v} {\ sqrt {v {_1} ^ 2 + v {_2} ^ 2 + \ dots + v {_n } ^ 2}} \)</target>
        </trans-unit>
        <trans-unit id="ef3a9e22b14c74ec22385c615853f9e45898420d" translate="yes" xml:space="preserve">
          <source>\(v_{norm} = \frac{v}{||v||_2} = \frac{v}{\sqrt{v{_1}^2 + v{_2}^2 + \dots + v{_n}^2}}\).</source>
          <target state="translated">\ (v_ {norma} = \ frac {v} {|| v || _2} = \ frac {v} {\ sqrt {v {_1} ^ 2 + v {_2} ^ 2 + \ dots + v {_n } ^ 2}} \).</target>
        </trans-unit>
        <trans-unit id="e9fe36499695707a4fa25e6312e0decc4b5ce11a" translate="yes" xml:space="preserve">
          <source>\(x_1 \leq x_1' \implies F(x_1, x_2) \geq F(x_1', x_2)\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12ab6bd6cdfcad92f2c8d9cd45d8531fb50b8225" translate="yes" xml:space="preserve">
          <source>\(x_1 \leq x_1' \implies F(x_1, x_2) \leq F(x_1', x_2)\), where \(F\) is the predictor with two features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d224f9dd671e9669fa16b0ba657459625c42e63b" translate="yes" xml:space="preserve">
          <source>\(y \in (-\infty, \infty)\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7fb9264ce64cd7d5e1a33f2fcf663917cc9226ab" translate="yes" xml:space="preserve">
          <source>\(y \in (0, \infty)\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ffefe23f049210303238c3770c5a3a8cbf9ad47" translate="yes" xml:space="preserve">
          <source>\(y \in [0, \infty)\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f32f66d76e16029cdb54470231bf86f45c56290" translate="yes" xml:space="preserve">
          <source>\(y\) the set of &lt;em&gt;predicted&lt;/em&gt;\((sample, label)\) pairs</source>
          <target state="translated">\ (y \) el conjunto de pares \ ((muestra, etiqueta) \) &lt;em&gt;predichos&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="84dbf0f25232d7453b4b36e6d3fffb9c5594408b" translate="yes" xml:space="preserve">
          <source>\(y\): target variable</source>
          <target state="translated">\ (y \): variable de destino</target>
        </trans-unit>
        <trans-unit id="29655c66149656107eee3658832dbefda0f10f88" translate="yes" xml:space="preserve">
          <source>\(y_l\) the subset of \(y\) with label \(l\)</source>
          <target state="translated">\ (y_l \) el subconjunto de \ (y \) con etiqueta \ (l \)</target>
        </trans-unit>
        <trans-unit id="2e082165475a8fcee912e7d794c4b87072c02854" translate="yes" xml:space="preserve">
          <source>\(y_s\) the subset of \(y\) with sample \(s\), i.e. \(y_s := \left\{(s', l) \in y | s' = s\right\}\)</source>
          <target state="translated">\ (y_s \) el subconjunto de \ (y \) con muestra \ (s \), es decir, \ (y_s: = \ left \ {(s ', l) \ in y | s' = s \ right \} \ )</target>
        </trans-unit>
        <trans-unit id="83a2c7fcc781f513174d7284ba894e2de571456a" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}P(y \mid x_1, \dots, x_n) \propto P(y) \prod_{i=1}^{n} P(x_i \mid y)\\\Downarrow\\\hat{y} = \arg\max_y P(y) \prod_{i=1}^{n} P(x_i \mid y),\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {alineado} P (y \ mid x_1, \ dots, x_n) \ propto P (y) \ prod_ {i = 1} ^ {n} P (x_i \ mid y) \\ \ Flecha hacia abajo \\\ sombrero {y} = \ arg \ max_y P (y) \ prod_ {i = 1} ^ {n} P (x_i \ mid y), \ end {alineado} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="c500aca02db178fd925a59974dd45ddee8face02" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}Q_{left}(\theta) = {(x, y) | x_j &amp;lt;= t_m}\\Q_{right}(\theta) = Q \setminus Q_{left}(\theta)\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {alineado} Q_ {izquierda} (\ theta) = {(x, y) | x_j &amp;lt;= t_m} \\ Q_ {derecha} (\ theta) = Q \ setminus Q_ {izquierda} (\ theta) \ end {alineado} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="6d63d132be650c44cbd8191fea374d6099c68415" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\bar{y}_m = \frac{1}{N_m} \sum_{i \in N_m} y_i\\H(X_m) = \frac{1}{N_m} \sum_{i \in N_m} (y_i - \bar{y}_m)^2\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {alineado} \ bar {y} _m = \ frac {1} {N_m} \ sum_ {i \ in N_m} y_i \\ H (X_m) = \ frac {1} {N_m } \ sum_ {i \ in N_m} (y_i - \ bar {y} _m) ^ 2 \ end {alineado} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="09657abb97474afe531f716bc21393139a923381" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\bar{y}_m = \frac{1}{N_m} \sum_{i \in N_m} y_i\\H(X_m) = \frac{1}{N_m} \sum_{i \in N_m} |y_i - \bar{y}_m|\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {alineado} \ bar {y} _m = \ frac {1} {N_m} \ sum_ {i \ in N_m} y_i \\ H (X_m) = \ frac {1} {N_m } \ sum_ {i \ in N_m} | y_i - \ bar {y} _m | \ end {alineado} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="a6a013161b26d9345009bc657a0fa52bacc545a7" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\hat{\theta}_{ci} = \frac{\alpha_i + \sum_{j:y_j \neq c} d_{ij}} {\alpha + \sum_{j:y_j \neq c} \sum_{k} d_{kj}}\\w_{ci} = \log \hat{\theta}_{ci}\\w_{ci} = \frac{w_{ci}}{\sum_{j} |w_{cj}|}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {alineado} \ hat {\ theta} _ {ci} = \ frac {\ alpha_i + \ sum_ {j: y_j \ neq c} d_ {ij}} {\ alpha + \ sum_ {j: y_j \ neq c} \ sum_ {k} d_ {kj}} \\ w_ {ci} = \ log \ hat {\ theta} _ {ci} \\ w_ {ci} = \ frac {w_ {ci }} {\ sum_ {j} | w_ {cj} |} \ end {alineado} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="3d5da4b9043141ddac28de63232838abbbe5a18b" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\log\left(\frac{P(y=k|X)}{P(y=l|X)}\right)= \log\left(\frac{P(X|y=k)P(y=k)}{P(X|y=l)P(y=l)}\right)=0 \Leftrightarrow\\(\mu_k-\mu_l)^t\Sigma^{-1} X = \frac{1}{2} (\mu_k^t \Sigma^{-1} \mu_k - \mu_l^t \Sigma^{-1} \mu_l) - \log\frac{P(y=k)}{P(y=l)}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {alineado} \ log \ left (\ frac {P (y = k | X)} ​​{P (y = l | X)} ​​\ right) = \ log \ left (\ frac {P (X | y = k) P (y = k)} {P (X | y = l) P (y = l)} \ right) = 0 \ Leftrightarrow \\ (\ mu_k- \ mu_l) ^ t \ Sigma ^ {- 1} X = \ frac {1} {2} (\ mu_k ^ t \ Sigma ^ {- 1} \ mu_k - \ mu_l ^ t \ Sigma ^ {- 1} \ mu_l) - \ log \ frac {P (y = k)} {P (y = l)} \ end {alineado} \ end {alinear} \]</target>
        </trans-unit>
        <trans-unit id="970228f13e58c5000f67243636530c2e6768a476" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\min_ {w, b, \zeta, \zeta^*} \frac{1}{2} w^T w + C \sum_{i=1}^{n} (\zeta_i + \zeta_i^*)\\\begin{split}\textrm {subject to } &amp;amp; y_i - w^T \phi (x_i) - b \leq \varepsilon + \zeta_i,\\ &amp;amp; w^T \phi (x_i) + b - y_i \leq \varepsilon + \zeta_i^*,\\ &amp;amp; \zeta_i, \zeta_i^* \geq 0, i=1, ..., n\end{split}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {alineado} \ min_ {w, b, \ zeta, \ zeta ^ *} \ frac {1} {2} w ^ T w + C \ sum_ {i = 1} ^ { n} (\ zeta_i + \ zeta_i ^ *) \\\ begin {split} \ textrm {sujeto a} &amp;amp; y_i - w ^ T \ phi (x_i) - b \ leq \ varepsilon + \ zeta_i, \\ &amp;amp; w ^ T \ phi (x_i) + b - y_i \ leq \ varepsilon + \ zeta_i ^ *, \\ &amp;amp; \ zeta_i, \ zeta_i ^ * \ geq 0, i = 1, ..., n \ end {split} \ end {alineado} \ end {alinear} \]</target>
        </trans-unit>
        <trans-unit id="e7cf54257feefa3a1cdfa65288e5d1230916a9ce" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\min_ {w, b, \zeta} \frac{1}{2} w^T w + C \sum_{i=1}^{n} \zeta_i\\\begin{split}\textrm {subject to } &amp;amp; y_i (w^T \phi (x_i) + b) \geq 1 - \zeta_i,\\ &amp;amp; \zeta_i \geq 0, i=1, ..., n\end{split}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {alineado} \ min_ {w, b, \ zeta} \ frac {1} {2} w ^ T w + C \ sum_ {i = 1} ^ {n} \ zeta_i \ \\ begin {split} \ textrm {sujeto a} &amp;amp; y_i (w ^ T \ phi (x_i) + b) \ geq 1 - \ zeta_i, \\ &amp;amp; \ zeta_i \ geq 0, i = 1, ..., n \ end {dividir} \ end {alineado} \ end {alinear} \]</target>
        </trans-unit>
        <trans-unit id="80291068f9bc632282f639938cf37593076f7e40" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\min_{\alpha, \alpha^*} \frac{1}{2} (\alpha - \alpha^*)^T Q (\alpha - \alpha^*) + \varepsilon e^T (\alpha + \alpha^*) - y^T (\alpha - \alpha^*)\\\begin{split} \textrm {subject to } &amp;amp; e^T (\alpha - \alpha^*) = 0\\ &amp;amp; 0 \leq \alpha_i, \alpha_i^* \leq C, i=1, ..., n\end{split}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {alineado} \ min _ {\ alpha, \ alpha ^ *} \ frac {1} {2} (\ alpha - \ alpha ^ *) ^ TQ (\ alpha - \ alpha ^ * ) + \ varepsilon e ^ T (\ alpha + \ alpha ^ *) - y ^ T (\ alpha - \ alpha ^ *) \\\ begin {split} \ textrm {sujeto a} &amp;amp; e ^ T (\ alpha - \ alpha ^ *) = 0 \\ &amp;amp; 0 \ leq \ alpha_i, \ alpha_i ^ * \ leq C, i = 1, ..., n \ end {split} \ end {alineado} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="6c7b70ef69da1a978d3d70eb6e72d1cfe185904a" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\min_{\alpha} \frac{1}{2} \alpha^T Q \alpha - e^T \alpha\\\begin{split} \textrm {subject to } &amp;amp; y^T \alpha = 0\\ &amp;amp; 0 \leq \alpha_i \leq C, i=1, ..., n\end{split}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {alineado} \ min _ {\ alpha} \ frac {1} {2} \ alpha ^ TQ \ alpha - e ^ T \ alpha \\\ begin {split} \ textrm {sujeto a } &amp;amp; y ^ T \ alpha = 0 \\ &amp;amp; 0 \ leq \ alpha_i \ leq C, i = 1, ..., n \ end {split} \ end {alineado} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="b61ecb24510d037b2f103f5394b305a25a58f23a" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}median(y)_m = \underset{i \in N_m}{\mathrm{median}}(y_i)\\H(X_m) = \frac{1}{N_m} \sum_{i \in N_m} |y_i - median(y)_m|\end{aligned}\end{align} \]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6188a7c021d3288e439ea7246a74358b63a884c" translate="yes" xml:space="preserve">
          <source>\[(1 - eps) \|u - v\|^2 &amp;lt; \|p(u) - p(v)\|^2 &amp;lt; (1 + eps) \|u - v\|^2\]</source>
          <target state="translated">\ [(1 - eps) \ | u - v \ | ^ 2 &amp;lt;\ | p (u) - p (v) \ | ^ 2 &amp;lt;(1 + eps) \ | u - v \ | ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="c4407dbb151e2710b04032ff6939f68ed3c7179c" translate="yes" xml:space="preserve">
          <source>\[A_n = R^{-1/2} A C^{-1/2}\]</source>
          <target state="translated">\ [A_n = R ^ {- 1/2} AC ^ {- 1/2} \]</target>
        </trans-unit>
        <trans-unit id="f6b0d9bcf51ca0db910abd2831694b2e6df3d3e4" translate="yes" xml:space="preserve">
          <source>\[BS = \frac{1}{N} \sum_{t=1}^{N}(f_t - o_t)^2\]</source>
          <target state="translated">\ [BS = \ frac {1} {N} \ sum_ {t = 1} ^ {N} (f_t - o_t) ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="c92a9c50030567e1c914fdb60f6f36c624d7857a" translate="yes" xml:space="preserve">
          <source>\[B_k = \sum_q n_q (c_q - c) (c_q - c)^T\]</source>
          <target state="translated">\ [B_k = \ sum_q n_q (c_q - c) (c_q - c) ^ T \]</target>
        </trans-unit>
        <trans-unit id="ba2a7d3bd989e0c77672451c8ebf6d95f02e79e3" translate="yes" xml:space="preserve">
          <source>\[B_k = \sum_{q=1}^k n_q (c_q - c_E) (c_q - c_E)^T\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7004892a8adf03dbfdffcdcf3787b7ebb419e77" translate="yes" xml:space="preserve">
          <source>\[C \sum_{i=1, n} \mathcal{L} (f(x_i), y_i) + \Omega (w)\]</source>
          <target state="translated">\ [C \ sum_ {i = 1, n} \ mathcal {L} (f (x_i), y_i) + \ Omega (w) \]</target>
        </trans-unit>
        <trans-unit id="cdd0300688de915acfc1a115df5a69adf7a6197d" translate="yes" xml:space="preserve">
          <source>\[D(x, y) = 2\arcsin[\sqrt{\sin^2((x1 - y1) / 2) + \cos(x1)\cos(y1)\sin^2((x2 - y2) / 2)}]\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24e7ca264d5b1b5ecf81452a44a55176b2008b8c" translate="yes" xml:space="preserve">
          <source>\[DB = \frac{1}{k} \sum_{i=1}^k \max_{i \neq j} R_{ij}\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69d401f524d7e967afe2dcb64dc99487200dfcd8" translate="yes" xml:space="preserve">
          <source>\[DB = \frac{1}{k} \sum{i=1}^k \max_{i \neq j} R_{ij}\]</source>
          <target state="translated">\ [DB = \ frac {1} {k} \ sum {i = 1} ^ k \ max_ {i \ neq j} R_ {ij} \]</target>
        </trans-unit>
        <trans-unit id="0e40c0ff9b9201b3e6cc8ee7f729672fe6ce4c93" translate="yes" xml:space="preserve">
          <source>\[E(\mathbf{v}, \mathbf{h}) = -\sum_i \sum_j w_{ij}v_ih_j - \sum_i b_iv_i - \sum_j c_jh_j\]</source>
          <target state="translated">\ [E (\ mathbf {v}, \ mathbf {h}) = - \ sum_i \ sum_j w_ {ij} v_ih_j - \ sum_i b_iv_i - \ sum_j c_jh_j \]</target>
        </trans-unit>
        <trans-unit id="783de3e797180d6f4ba6c3e9379606ecef2ead2a" translate="yes" xml:space="preserve">
          <source>\[E(w,b) = \frac{1}{n}\sum_{i=1}^{n} L(y_i, f(x_i)) + \alpha R(w)\]</source>
          <target state="translated">\ [E (w, b) = \ frac {1} {n} \ sum_ {i = 1} ^ {n} L (y_i, f (x_i)) + \ alpha R (w) \]</target>
        </trans-unit>
        <trans-unit id="365f54944565346973bba6038073efb7e313ed11" translate="yes" xml:space="preserve">
          <source>\[E[\text{MI}(U,V)]=\sum_{i=1}^{|U|} \sum_{j=1}^{|V|} \sum_{n_{ij}=(a_i+b_j-N)^+ }^{\min(a_i, b_j)} \frac{n_{ij}}{N}\log \left( \frac{ N.n_{ij}}{a_i b_j}\right) \frac{a_i!b_j!(N-a_i)!(N-b_j)!}{N!n_{ij}!(a_i-n_{ij})!(b_j-n_{ij})! (N-a_i-b_j+n_{ij})!}\]</source>
          <target state="translated">\ [E [\ text {MI} (U, V)] = \ sum_ {i = 1} ^ {| U |} \ sum_ {j = 1} ^ {| V |} \ sum_ {n_ {ij} = (a_i + b_j-N) ^ +} ^ {\ min (a_i, b_j)} \ frac {n_ {ij}} {N} \ log \ left (\ frac {N.n_ {ij}} {a_i b_j} \ right) \ frac {a_i! b_j! (N-a_i)! (N-b_j)!} {N! n_ {ij}! (a_i-n_ {ij})! (b_j-n_ {ij})! (N-a_i-b_j + n_ {ij})!} \]</target>
        </trans-unit>
        <trans-unit id="fa1ff8faa81d9e66252f62a095f5cf70ca1078c1" translate="yes" xml:space="preserve">
          <source>\[F(x) = \sum_{m=1}^{M} \gamma_m h_m(x)\]</source>
          <target state="translated">\ [F (x) = \ sum_ {m = 1} ^ {M} \ gamma_m h_m (x) \]</target>
        </trans-unit>
        <trans-unit id="8b0368e365c0b4ab2c5226a46b2b8384821b7abd" translate="yes" xml:space="preserve">
          <source>\[F_\beta = (1 + \beta^2) \frac{\text{precision} \times \text{recall}}{\beta^2 \text{precision} + \text{recall}}.\]</source>
          <target state="translated">\ [F_ \ beta = (1 + \ beta ^ 2) \ frac {\ text {precisi&amp;oacute;n} \ times \ text {recordar}} {\ beta ^ 2 \ text {precisi&amp;oacute;n} + \ text {recordar}}. \]</target>
        </trans-unit>
        <trans-unit id="c9eeb87b260c2954980548a507a8b1393c039854" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) + \arg\min_{h} \sum_{i=1}^{n} L(y_i, F_{m-1}(x_i) + h(x))\]</source>
          <target state="translated">\ [F_m (x) = F_ {m-1} (x) + \ arg \ min_ {h} \ sum_ {i = 1} ^ {n} L (y_i, F_ {m-1} (x_i) + h (X))\]</target>
        </trans-unit>
        <trans-unit id="c3b959c536d9b51ce676e93f30895d0c6d681eae" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) + \gamma_m h_m(x)\]</source>
          <target state="translated">\ [F_m (x) = F_ {m-1} (x) + \ gamma_m h_m (x) \]</target>
        </trans-unit>
        <trans-unit id="9b119698c7b1cbf47db5678415973bc69f053f0c" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) + \nu \gamma_m h_m(x)\]</source>
          <target state="translated">\ [F_m (x) = F_ {m-1} (x) + \ nu \ gamma_m h_m (x) \]</target>
        </trans-unit>
        <trans-unit id="f67ac5f779f99408bbddee5aabe3119d85a325aa" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) + \nu h_m(x)\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53cc4ef6b492c65482e59fea0173cd005acf6ca7" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) + h_m(x),\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79620d3f64f3ecc0a5f216eb6a57691d801c15cd" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) - \gamma_m \sum_{i=1}^{n} \nabla_F L(y_i, F_{m-1}(x_i))\]</source>
          <target state="translated">\ [F_m (x) = F_ {m-1} (x) - \ gamma_m \ sum_ {i = 1} ^ {n} \ nabla_F L (y_i, F_ {m-1} (x_i)) \]</target>
        </trans-unit>
        <trans-unit id="90cafad385d21b4d4db9860dff7480af31e6cc3a" translate="yes" xml:space="preserve">
          <source>\[G(Q, \theta) = \frac{n_{left}}{N_m} H(Q_{left}(\theta)) + \frac{n_{right}}{N_m} H(Q_{right}(\theta))\]</source>
          <target state="translated">\ [G (Q, \ theta) = \ frac {n_ {izquierda}} {N_m} H (Q_ {izquierda} (\ theta)) + \ frac {n_ {derecha}} {N_m} H (Q_ {derecha} (\ theta)) \]</target>
        </trans-unit>
        <trans-unit id="a3b30c3461532826adfe7425f51daed9aaf98e97" translate="yes" xml:space="preserve">
          <source>\[H(C) = - \sum_{c=1}^{|C|} \frac{n_c}{n} \cdot \log\left(\frac{n_c}{n}\right)\]</source>
          <target state="translated">\ [H (C) = - \ sum_ {c = 1} ^ {| C |} \ frac {n_c} {n} \ cdot \ log \ left (\ frac {n_c} {n} \ right) \]</target>
        </trans-unit>
        <trans-unit id="672f9873cccc012ff842c8c7fce069ac5cd92675" translate="yes" xml:space="preserve">
          <source>\[H(C|K) = - \sum_{c=1}^{|C|} \sum_{k=1}^{|K|} \frac{n_{c,k}}{n} \cdot \log\left(\frac{n_{c,k}}{n_k}\right)\]</source>
          <target state="translated">\ [H (C | K) = - \ sum_ {c = 1} ^ {| C |} \ sum_ {k = 1} ^ {| K |} \ frac {n_ {c, k}} {n} \ cdot \ log \ left (\ frac {n_ {c, k}} {n_k} \ right) \]</target>
        </trans-unit>
        <trans-unit id="9dcc776906a998f47112457373d3636e82b5c382" translate="yes" xml:space="preserve">
          <source>\[H(U) = - \sum_{i=1}^{|U|}P(i)\log(P(i))\]</source>
          <target state="translated">\ [H (U) = - \ sum_ {i = 1} ^ {| U |} P (i) \ log (P (i)) \]</target>
        </trans-unit>
        <trans-unit id="bf873d01bafa66fa00d4a9abe244e71c3ad5c483" translate="yes" xml:space="preserve">
          <source>\[H(V) = - \sum_{j=1}^{|V|}P'(j)\log(P'(j))\]</source>
          <target state="translated">\ [H (V) = - \ sum_ {j = 1} ^ {| V |} P '(j) \ log (P' (j)) \]</target>
        </trans-unit>
        <trans-unit id="825bd8051092a0ff4da11fbb8a018da499318440" translate="yes" xml:space="preserve">
          <source>\[H(X_m) = - \sum_k p_{mk} \log(p_{mk})\]</source>
          <target state="translated">\ [H (X_m) = - \ sum_k p_ {mk} \ log (p_ {mk}) \]</target>
        </trans-unit>
        <trans-unit id="86fb9fbe52343d6db8c412062ca26e8b3a61d7f8" translate="yes" xml:space="preserve">
          <source>\[H(X_m) = 1 - \max(p_{mk})\]</source>
          <target state="translated">\ [H (X_m) = 1 - \ max (p_ {mk}) \]</target>
        </trans-unit>
        <trans-unit id="471e679a9a1baa18ae5b83f786849ce5561bcf62" translate="yes" xml:space="preserve">
          <source>\[H(X_m) = \sum_k p_{mk} (1 - p_{mk})\]</source>
          <target state="translated">\ [H (X_m) = \ sum_k p_ {mk} (1 - p_ {mk}) \]</target>
        </trans-unit>
        <trans-unit id="d07612141f923e53a5d822ae265800fc511ebfa2" translate="yes" xml:space="preserve">
          <source>\[J(A, B) = \frac{|A \cap B|}{|A| + |B| - |A \cap B|}\]</source>
          <target state="translated">\ [J (A, B) = \ frac {| A \ cap B |} {| A | + | B | - | A \ cap B |} \]</target>
        </trans-unit>
        <trans-unit id="b38d8ccb5f6105408ebebb5c4de384f0bcc0244c" translate="yes" xml:space="preserve">
          <source>\[J(y_i, \hat{y}_i) = \frac{|y_i \cap \hat{y}_i|}{|y_i \cup \hat{y}_i|}.\]</source>
          <target state="translated">\ [J (y_i, \ hat {y} _i) = \ frac {| y_i \ cap \ hat {y} _i |} {| y_i \ cup \ hat {y} _i |}. \]</target>
        </trans-unit>
        <trans-unit id="d318f9ea1800cd74dd7a27a0e7aa26e39a217efa" translate="yes" xml:space="preserve">
          <source>\[K_{ij} = L_{ij} - \overline{L_{i \cdot}} - \overline{L_{\cdot j}} + \overline{L_{\cdot \cdot}}\]</source>
          <target state="translated">\ [K_ {ij} = L_ {ij} - \ overline {L_ {i \ cdot}} - \ overline {L _ {\ cdot j}} + \ overline {L _ {\ cdot \ cdot}} \]</target>
        </trans-unit>
        <trans-unit id="4f142a1b3f1a25b7844f5bd577802840d9086424" translate="yes" xml:space="preserve">
          <source>\[LRAP(y, \hat{f}) = \frac{1}{n_{\text{samples}}} \sum_{i=0}^{n_{\text{samples}} - 1} \frac{1}{||y_i||_0} \sum_{j:y_{ij} = 1} \frac{|\mathcal{L}_{ij}|}{\text{rank}_{ij}}\]</source>
          <target state="translated">\ [LRAP (y, \ hat {f}) = \ frac {1} {n _ {\ text {samples}}} \ sum_ {i = 0} ^ {n _ {\ text {samples}} - 1} \ frac {1} {|| y_i || _0} \ sum_ {j: y_ {ij} = 1} \ frac {| \ mathcal {L} _ {ij} |} {\ text {rango} _ {ij}} \ ]</target>
        </trans-unit>
        <trans-unit id="ce318e5aa62c88285e6dbc3450ddc43884867d96" translate="yes" xml:space="preserve">
          <source>\[L_\text{Hinge}(y, w) = \max\left\{1 - wy, 0\right\} = \left|1 - wy\right|_+\]</source>
          <target state="translated">\ [L_ \ text {Hinge} (y, w) = \ max \ left \ {1 - wy, 0 \ right \} = \ left | 1 - wy \ right | _ + \]</target>
        </trans-unit>
        <trans-unit id="ba42e2e6c73e49cc69262971d98739da8f3de127" translate="yes" xml:space="preserve">
          <source>\[L_\text{Hinge}(y_w, y_t) = \max\left\{1 + y_t - y_w, 0\right\}\]</source>
          <target state="translated">\ [L_ \ text {Hinge} (y_w, y_t) = \ max \ left \ {1 + y_t - y_w, 0 \ right \} \]</target>
        </trans-unit>
        <trans-unit id="7d42c3e71601b07673f2ff67be6498a9b9b5b660" translate="yes" xml:space="preserve">
          <source>\[L_{0-1}(y_i, \hat{y}_i) = 1(\hat{y}_i \not= y_i)\]</source>
          <target state="translated">\ [L_ {0-1} (y_i, \ hat {y} _i) = 1 (\ hat {y} _i \ not = y_i) \]</target>
        </trans-unit>
        <trans-unit id="2d55be0d74f5ef605272bd6c32e6867b2bf3e8e6" translate="yes" xml:space="preserve">
          <source>\[L_{Hamming}(y, \hat{y}) = \frac{1}{n_\text{labels}} \sum_{j=0}^{n_\text{labels} - 1} 1(\hat{y}_j \not= y_j)\]</source>
          <target state="translated">\ [L_ {Hamming} (y, \ hat {y}) = \ frac {1} {n_ \ text {etiquetas}} \ sum_ {j = 0} ^ {n_ \ text {etiquetas} - 1} 1 (\ sombrero {y} _j \ not = y_j) \]</target>
        </trans-unit>
        <trans-unit id="b3092c91dac051243dcdc2b0e51b2cc71f3f1851" translate="yes" xml:space="preserve">
          <source>\[L_{\log}(Y, P) = -\log \operatorname{Pr}(Y|P) = - \frac{1}{N} \sum_{i=0}^{N-1} \sum_{k=0}^{K-1} y_{i,k} \log p_{i,k}\]</source>
          <target state="translated">\ [L _ {\ log} (Y, P) = - \ log \ operatorname {Pr} (Y | P) = - \ frac {1} {N} \ sum_ {i = 0} ^ {N-1} \ suma_ {k = 0} ^ {K-1} y_ {i, k} \ log p_ {i, k} \]</target>
        </trans-unit>
        <trans-unit id="253a9ad7d14147f9b4d52f808d7adc29f4f1d369" translate="yes" xml:space="preserve">
          <source>\[L_{\log}(y, p) = -\log \operatorname{Pr}(y|p) = -(y \log (p) + (1 - y) \log (1 - p))\]</source>
          <target state="translated">\ [L _ {\ log} (y, p) = - \ log \ operatorname {Pr} (y | p) = - (y \ log (p) + (1 - y) \ log (1 - p)) \ ]</target>
        </trans-unit>
        <trans-unit id="2efbeda9bdd157cc2d7a3c7780634a18e9cf252c" translate="yes" xml:space="preserve">
          <source>\[Loss(\hat{y},y,W) = -y \ln {\hat{y}} - (1-y) \ln{(1-\hat{y})} + \alpha ||W||_2^2\]</source>
          <target state="translated">\ [P&amp;eacute;rdida (\ hat {y}, y, W) = -y \ ln {\ hat {y}} - (1-y) \ ln {(1- \ hat {y})} + \ alpha || W || _2 ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="ad216be468be053e061c385b7f1c21d710fe84a9" translate="yes" xml:space="preserve">
          <source>\[Loss(\hat{y},y,W) = \frac{1}{2}||\hat{y} - y ||_2^2 + \frac{\alpha}{2} ||W||_2^2\]</source>
          <target state="translated">\ [P&amp;eacute;rdida (\ hat {y}, y, W) = \ frac {1} {2} || \ hat {y} - y || _2 ^ 2 + \ frac {\ alpha} {2} || W || _2 ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="3d4d43e0aa8af2572cd4c7afaa27772d600c52ba" translate="yes" xml:space="preserve">
          <source>\[MCC = \frac{ c \times s - \sum_{k}^{K} p_k \times t_k }{\sqrt{ (s^2 - \sum_{k}^{K} p_k^2) \times (s^2 - \sum_{k}^{K} t_k^2) }}\]</source>
          <target state="translated">\ [MCC = \ frac {c \ times s - \ sum_ {k} ^ {K} p_k \ times t_k} {\ sqrt {(s ^ 2 - \ sum_ {k} ^ {K} p_k ^ 2) \ times (s ^ 2 - \ sum_ {k} ^ {K} t_k ^ 2)}} \]</target>
        </trans-unit>
        <trans-unit id="f5497e39840904c9cb7d2472c1ab3621a66cd485" translate="yes" xml:space="preserve">
          <source>\[MCC = \frac{tp \times tn - fp \times fn}{\sqrt{(tp + fp)(tp + fn)(tn + fp)(tn + fn)}}.\]</source>
          <target state="translated">\ [MCC = \ frac {tp \ times tn - fp \ times fn} {\ sqrt {(tp + fp) (tp + fn) (tn + fp) (tn + fn)}}. \]</target>
        </trans-unit>
        <trans-unit id="a3da3c85336ea30ff991df5f7886c792d671d3d1" translate="yes" xml:space="preserve">
          <source>\[MI(U,V)=\sum_{i=1}^{|U|} \sum_{j=1}^{|V|} \frac{|U_i\cap V_j|}{N} \log\frac{N|U_i \cap V_j|}{|U_i||V_j|}\]</source>
          <target state="translated">\ [MI (U, V) = \ sum_ {i = 1} ^ {| U |} \ sum_ {j = 1} ^ {| V |} \ frac {| U_i \ cap V_j |} {N} \ log \ frac {N | U_i \ cap V_j |} {| U_i || V_j |} \]</target>
        </trans-unit>
        <trans-unit id="c94cfec038c55c60afa9fef476e0a1aad2563170" translate="yes" xml:space="preserve">
          <source>\[P(X | y=k) = \frac{1}{(2\pi)^{d/2} |\Sigma_k|^{1/2}}\exp\left(-\frac{1}{2} (X-\mu_k)^t \Sigma_k^{-1} (X-\mu_k)\right)\]</source>
          <target state="translated">\ [P (X | y = k) = \ frac {1} {(2 \ pi) ^ {d / 2} | \ Sigma_k | ^ {1/2}} \ exp \ left (- \ frac {1} {2} (X- \ mu_k) ^ t \ Sigma_k ^ {- 1} (X- \ mu_k) \ right) \]</target>
        </trans-unit>
        <trans-unit id="cd893dbc741157abd91341aed411a740724f85fa" translate="yes" xml:space="preserve">
          <source>\[P(\mathbf{v}, \mathbf{h}) = \frac{e^{-E(\mathbf{v}, \mathbf{h})}}{Z}\]</source>
          <target state="translated">\ [P (\ mathbf {v}, \ mathbf {h}) = \ frac {e ^ {- E (\ mathbf {v}, \ mathbf {h})}} {Z} \]</target>
        </trans-unit>
        <trans-unit id="7e8396a93e6bd3272f4718e7de218023882d7d31" translate="yes" xml:space="preserve">
          <source>\[P(x | y=k) = \frac{1}{(2\pi)^{d/2} |\Sigma_k|^{1/2}}\exp\left(-\frac{1}{2} (x-\mu_k)^t \Sigma_k^{-1} (x-\mu_k)\right)\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f84acbf7827b429f5edf701fe90ef79259a19956" translate="yes" xml:space="preserve">
          <source>\[P(x_i = t \mid y = c \: ;\, \alpha) = \frac{ N_{tic} + \alpha}{N_{c} + \alpha n_i},\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a8ab66c6ea03a89651facccbd08d5f0c9be8c6d" translate="yes" xml:space="preserve">
          <source>\[P(x_i \mid y) = P(i \mid y) x_i + (1 - P(i \mid y)) (1 - x_i)\]</source>
          <target state="translated">\ [P (x_i \ mid y) = P (i \ mid y) x_i + (1 - P (i \ mid y)) (1 - x_i) \]</target>
        </trans-unit>
        <trans-unit id="33b093ce0e5d6e386417ef609cc2f6a855343cc3" translate="yes" xml:space="preserve">
          <source>\[P(x_i \mid y) = \frac{1}{\sqrt{2\pi\sigma^2_y}} \exp\left(-\frac{(x_i - \mu_y)^2}{2\sigma^2_y}\right)\]</source>
          <target state="translated">\ [P (x_i \ mid y) = \ frac {1} {\ sqrt {2 \ pi \ sigma ^ 2_y}} \ exp \ left (- \ frac {(x_i - \ mu_y) ^ 2} {2 \ sigma ^ 2_y} \ right) \]</target>
        </trans-unit>
        <trans-unit id="1f013d2ae1dd46efa06019f68c7849dc72ce7f4e" translate="yes" xml:space="preserve">
          <source>\[P(x_i | y, x_1, \dots, x_{i-1}, x_{i+1}, \dots, x_n) = P(x_i | y),\]</source>
          <target state="translated">\ [P (x_i | y, x_1, \ dots, x_ {i-1}, x_ {i + 1}, \ dots, x_n) = P (x_i | y), \]</target>
        </trans-unit>
        <trans-unit id="c732ad1752bec3f2371482df4bfec3ce784d1ec4" translate="yes" xml:space="preserve">
          <source>\[P(y \mid x_1, \dots, x_n) = \frac{P(y) P(x_1, \dots x_n \mid y)} {P(x_1, \dots, x_n)}\]</source>
          <target state="translated">\ [P (y \ mid x_1, \ dots, x_n) = \ frac {P (y) P (x_1, \ dots x_n \ mid y)} {P (x_1, \ dots, x_n)} \]</target>
        </trans-unit>
        <trans-unit id="facd455c5147b9177420e6f465438d2ec052942b" translate="yes" xml:space="preserve">
          <source>\[P(y \mid x_1, \dots, x_n) = \frac{P(y) P(x_1, \dots, x_n \mid y)} {P(x_1, \dots, x_n)}\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84c8d40000ffaabc15011af6c72fc5efaa03e40c" translate="yes" xml:space="preserve">
          <source>\[P(y \mid x_1, \dots, x_n) = \frac{P(y) \prod_{i=1}^{n} P(x_i \mid y)} {P(x_1, \dots, x_n)}\]</source>
          <target state="translated">\ [P (y \ mid x_1, \ dots, x_n) = \ frac {P (y) \ prod_ {i = 1} ^ {n} P (x_i \ mid y)} {P (x_1, \ dots, x_n )} \]</target>
        </trans-unit>
        <trans-unit id="edcd72a09735a7f6adceea22c0b30c20fbfbd80a" translate="yes" xml:space="preserve">
          <source>\[P(y=k | X) = \frac{P(X | y=k) P(y=k)}{P(X)} = \frac{P(X | y=k) P(y = k)}{ \sum_{l} P(X | y=l) \cdot P(y=l)}\]</source>
          <target state="translated">\ [P (y = k | X) = \ frac {P (X | y = k) P (y = k)} {P (X)} = \ frac {P (X | y = k) P (y = k)} {\ sum_ {l} P (X | y = l) \ cdot P (y = l)} \]</target>
        </trans-unit>
        <trans-unit id="d0d051ebe8e5f14c78017b6beb24cfde6b45cc0c" translate="yes" xml:space="preserve">
          <source>\[P(y=k | x) = \frac{P(x | y=k) P(y=k)}{P(x)} = \frac{P(x | y=k) P(y = k)}{ \sum_{l} P(x | y=l) \cdot P(y=l)}\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5a07827e49a88167851d8970eaa9edda3b99d65" translate="yes" xml:space="preserve">
          <source>\[R^2(y, \hat{y}) = 1 - \frac{\sum_{i=0}^{n_{\text{samples}} - 1} (y_i - \hat{y}_i)^2}{\sum_{i=0}^{n_\text{samples} - 1} (y_i - \bar{y})^2}\]</source>
          <target state="translated">\ [R ^ 2 (y, \ hat {y}) = 1 - \ frac {\ sum_ {i = 0} ^ {n _ {\ text {samples}} - 1} (y_i - \ hat {y} _i) ^ 2} {\ sum_ {i = 0} ^ {n_ \ text {muestras} - 1} (y_i - \ bar {y}) ^ 2} \]</target>
        </trans-unit>
        <trans-unit id="75a581e81c894ca3d5a39bbe361df977932542f2" translate="yes" xml:space="preserve">
          <source>\[R^2(y, \hat{y}) = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9b98e0db2ea75d1dfbeda81f631985feb91e53a" translate="yes" xml:space="preserve">
          <source>\[R_\alpha(T) = R(T) + \alpha|T|\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4a8061b9eb9628b02ec75d4e5fc5a21d09cd880" translate="yes" xml:space="preserve">
          <source>\[R_{ij} = \frac{s_i + s_j}{d_{ij}}\]</source>
          <target state="translated">\ [R_ {ij} = \ frac {s_i + s_j} {d_ {ij}} \]</target>
        </trans-unit>
        <trans-unit id="a0fa8b8fb90971dc259d470e1011abda5608da98" translate="yes" xml:space="preserve">
          <source>\[T(k) = 1 - \frac{2}{nk (2n - 3k - 1)} \sum^n_{i=1} \sum_{j \in \mathcal{N}_{i}^{k}} \max(0, (r(i, j) - k))\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7faa52dada966b566ea53656a8bd94425e2b50a6" translate="yes" xml:space="preserve">
          <source>\[W^{i+1} = W^i - \epsilon \nabla {Loss}_{W}^{i}\]</source>
          <target state="translated">\ [W ^ {i + 1} = W ^ i - \ epsilon \ nabla {P&amp;eacute;rdida} _ {W} ^ {i} \]</target>
        </trans-unit>
        <trans-unit id="e598814b9bd2e3db200ccff196ebf646bf738ec7" translate="yes" xml:space="preserve">
          <source>\[W_k = \sum_{q=1}^k \sum_{x \in C_q} (x - c_q) (x - c_q)^T\]</source>
          <target state="translated">\ [W_k = \ sum_ {q = 1} ^ k \ sum_ {x \ in C_q} (x - c_q) (x - c_q) ^ T \]</target>
        </trans-unit>
        <trans-unit id="7eb30be4ba7f05878cf003c46dfa54b35d57c946" translate="yes" xml:space="preserve">
          <source>\[X \approx X_k = U_k \Sigma_k V_k^\top\]</source>
          <target state="translated">\ [X \ approx X_k = U_k \ Sigma_k V_k ^ \ top \]</target>
        </trans-unit>
        <trans-unit id="c7c03179d6deebc1c581ff68076935c59051f655" translate="yes" xml:space="preserve">
          <source>\[X' = X V_k\]</source>
          <target state="translated">\ [X '= X V_k \]</target>
        </trans-unit>
        <trans-unit id="1b12fce875e4a7610479762a7e27b3b69634b6af" translate="yes" xml:space="preserve">
          <source>\[X^* = D^{-1/2}U^t X\text{ with }\Sigma = UDU^t\]</source>
          <target state="translated">\ [X ^ * = D ^ {- 1/2} U ^ t X \ text {con} \ Sigma = UDU ^ t \]</target>
        </trans-unit>
        <trans-unit id="15463a9b27ce80c407246ad66ee390a5bc003068" translate="yes" xml:space="preserve">
          <source>\[\alpha \rho ||W||_1 + \alpha \rho ||H||_1 + \frac{\alpha(1-\rho)}{2} ||W||_{\mathrm{Fro}} ^ 2 + \frac{\alpha(1-\rho)}{2} ||H||_{\mathrm{Fro}} ^ 2\]</source>
          <target state="translated">\ [\ alpha \ rho || W || _1 + \ alpha \ rho || H || _1 + \ frac {\ alpha (1- \ rho)} {2} || W || _ {\ mathrm {Fro }} ^ 2 + \ frac {\ alpha (1- \ rho)} {2} || H || _ {\ mathrm {Fro}} ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="ecb4b9fe8fc24f73a20eeac8e7781ad331ab3cc6" translate="yes" xml:space="preserve">
          <source>\[\begin{split}(U^*, V^*) = \underset{U, V}{\operatorname{arg\,min\,}} &amp;amp; \frac{1}{2} ||X-UV||_2^2+\alpha||U||_1 \\ \text{subject to } &amp;amp; ||V_k||_2 = 1 \text{ for all } 0 \leq k &amp;lt; n_{\mathrm{atoms}}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} (U ^ *, V ^ *) = \ underset {U, V} {\ operatorname {arg \, min \,}} &amp;amp; \ frac {1} {2} || X-UV || _2 ^ 2 + \ alpha || U || _1 \\ \ text {sujeto a} &amp;amp; || V_k || _2 = 1 \ text {para todos} 0 \ leq k &amp;lt;n _ {\ mathrm {&amp;aacute;tomos}} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="113192b0908b5ad7f78568d56440ab2d30ef92e9" translate="yes" xml:space="preserve">
          <source>\[\begin{split}(U^*, V^*) = \underset{U, V}{\operatorname{arg\,min\,}} &amp;amp; \frac{1}{2} ||X-UV||_2^2+\alpha||V||_1 \\ \text{subject to } &amp;amp; ||U_k||_2 = 1 \text{ for all } 0 \leq k &amp;lt; n_{components}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} (U ^ *, V ^ *) = \ underset {U, V} {\ operatorname {arg \, min \,}} &amp;amp; \ frac {1} {2} || X-UV || _2 ^ 2 + \ alpha || V || _1 \\ \ text {sujeto a} &amp;amp; || U_k || _2 = 1 \ text {para todos} 0 \ leq k &amp;lt;n_ {componentes} \ end {split } \]</target>
        </trans-unit>
        <trans-unit id="3136579a6b2a85a0be46315eb9cbc3ba1e261551" translate="yes" xml:space="preserve">
          <source>\[\begin{split}H_{\epsilon}(z) = \begin{cases} z^2, &amp;amp; \text {if } |z| &amp;lt; \epsilon, \\ 2\epsilon|z| - \epsilon^2, &amp;amp; \text{otherwise} \end{cases}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} H _ {\ epsilon} (z) = \ begin {cases} z ^ 2, &amp;amp; \ text {if} | z | &amp;lt;\ epsilon, \\ 2 \ epsilon | z | - \ epsilon ^ 2, &amp;amp; \ text {de lo contrario} \ end {cases} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="b46cf81ba2e913dc611a985b07c8255c093eef0a" translate="yes" xml:space="preserve">
          <source>\[\begin{split}P(v_i=1|\mathbf{h}) = \sigma(\sum_j w_{ij}h_j + b_i) \\ P(h_i=1|\mathbf{v}) = \sigma(\sum_i w_{ij}v_i + c_j)\end{split}\]</source>
          <target state="translated">\ [\ begin {split} P (v_i = 1 | \ mathbf {h}) = \ sigma (\ sum_j w_ {ij} h_j + b_i) \\ P (h_i = 1 | \ mathbf {v}) = \ sigma (\ sum_i w_ {ij} v_i + c_j) \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="2a61de83e06a531ec76671fed3f61a04aabc9bf7" translate="yes" xml:space="preserve">
          <source>\[\begin{split}Z = \begin{bmatrix} R^{-1/2} U \\\\ C^{-1/2} V \end{bmatrix}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} Z = \ begin {bmatrix} R ^ {- 1/2} U \\\\ C ^ {- 1/2} V \ end {bmatrix} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="8fd5d1a7323dcc269879eaa3da3604856f3eb3a0" translate="yes" xml:space="preserve">
          <source>\[\begin{split}\left\{ \begin{array}{c c l} -\sqrt{\frac{s}{n_{\text{components}}}} &amp;amp; &amp;amp; 1 / 2s\\ 0 &amp;amp;\text{with probability} &amp;amp; 1 - 1 / s \\ +\sqrt{\frac{s}{n_{\text{components}}}} &amp;amp; &amp;amp; 1 / 2s\\ \end{array} \right.\end{split}\]</source>
          <target state="translated">\ [\ begin {split} \ left \ {\ begin {array} {ccl} - \ sqrt {\ frac {s} {n _ {\ text {components}}}} &amp;amp; &amp;amp; 1 / 2s \\ 0 &amp;amp; \ text {con probabilidad} &amp;amp; 1 - 1 / s \\ + \ sqrt {\ frac {s} {n _ {\ text {componentes}}}} &amp;amp; &amp;amp; 1 / 2s \\ \ end {matriz} \ right. \ end { divisi&amp;oacute;n}\]</target>
        </trans-unit>
        <trans-unit id="240e6564ced61b1bc331dcf97a462834371b6641" translate="yes" xml:space="preserve">
          <source>\[\begin{split}\log P(y=k | x) &amp;amp;= \log P(x | y=k) + \log P(y = k) + Cst \\ &amp;amp;= -\frac{1}{2} \log |\Sigma_k| -\frac{1}{2} (x-\mu_k)^t \Sigma_k^{-1} (x-\mu_k) + \log P(y = k) + Cst,\end{split}\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cce5812b4c3daf727144c68d463e8caf50c7bfbb" translate="yes" xml:space="preserve">
          <source>\[\begin{split}\text{D}(y, \hat{y}) = \frac{1}{n_\text{samples}} \sum_{i=0}^{n_\text{samples} - 1} \begin{cases} (y_i-\hat{y}_i)^2, &amp;amp; \text{for }p=0\text{ (Normal)}\\ 2(y_i \log(y/\hat{y}_i) + \hat{y}_i - y_i), &amp;amp; \text{for}p=1\text{ (Poisson)}\\ 2(\log(\hat{y}_i/y_i) + y_i/\hat{y}_i - 1), &amp;amp; \text{for}p=2\text{ (Gamma)}\\ 2\left(\frac{\max(y_i,0)^{2-p}}{(1-p)(2-p)}- \frac{y\,\hat{y}^{1-p}_i}{1-p}+\frac{\hat{y}^{2-p}_i}{2-p}\right), &amp;amp; \text{otherwise} \end{cases}\end{split}\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64d0ec223c44ca16fb23a31d32e7c757a5e38ba8" translate="yes" xml:space="preserve">
          <source>\[\begin{split}h_i \bot h_j | \mathbf{v} \\ v_i \bot v_j | \mathbf{h}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} h_i \ bot h_j | \ mathbf {v} \\ v_i \ bot v_j | \ mathbf {h} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="3a84b3b0085920a5dafc19e08421419f997fff14" translate="yes" xml:space="preserve">
          <source>\[\begin{split}pd_{X_S}(x_S) &amp;amp;\overset{def}{=} \mathbb{E}_{X_C}\left[ f(x_S, X_C) \right]\\ &amp;amp;= \int f(x_S, x_C) p(x_C) dx_C,\end{split}\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6675ac3debfec98638ba1f9b136883988a6a0c0b" translate="yes" xml:space="preserve">
          <source>\[\begin{split}x_i^{(\lambda)} = \begin{cases} [(x_i + 1)^\lambda - 1] / \lambda &amp;amp; \text{if } \lambda \neq 0, x_i \geq 0, \\[8pt] \ln{(x_i + 1)} &amp;amp; \text{if } \lambda = 0, x_i \geq 0 \\[8pt] -[(-x_i + 1)^{2 - \lambda} - 1] / (2 - \lambda) &amp;amp; \text{if } \lambda \neq 2, x_i &amp;lt; 0, \\[8pt] - \ln (- x_i + 1) &amp;amp; \text{if } \lambda = 2, x_i &amp;lt; 0 \end{cases}\end{split}\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3198bb38407bb1554dc0d1959561349fcfcad349" translate="yes" xml:space="preserve">
          <source>\[\begin{split}x_i^{(\lambda)} = \begin{cases} [(x_i + 1)^\lambda - 1] / \lambda &amp;amp; \text{if } \lambda \neq 0, x_i \geq 0, \\[8pt] \ln{(x_i) + 1} &amp;amp; \text{if } \lambda = 0, x_i \geq 0 \\[8pt] -[(-x_i + 1)^{2 - \lambda} - 1] / (2 - \lambda) &amp;amp; \text{if } \lambda \neq 2, x_i &amp;lt; 0, \\[8pt] - \ln (- x_i + 1) &amp;amp; \text{if } \lambda = 2, x_i &amp;lt; 0 \end{cases}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} x_i ^ {(\ lambda)} = \ begin {cases} [(x_i + 1) ^ \ lambda - 1] / \ lambda &amp;amp; \ text {if} \ lambda \ neq 0, x_i \ geq 0, \\ [8pt] \ ln {(x_i) + 1} &amp;amp; \ text {if} \ lambda = 0, x_i \ geq 0 \\ [8pt] - [(- x_i + 1) ^ {2 - \ lambda} - 1] / (2 - \ lambda) &amp;amp; \ text {if} \ lambda \ neq 2, x_i &amp;lt;0, \\ [8pt] - \ ln (- x_i + 1) &amp;amp; \ text {if} \ lambda = 2, x_i &amp;lt;0 \ end {cases} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="dc87ecfd4801e13673bdd8bb567f720368f1d00c" translate="yes" xml:space="preserve">
          <source>\[\begin{split}x_i^{(\lambda)} = \begin{cases} \dfrac{x_i^\lambda - 1}{\lambda} &amp;amp; \text{if } \lambda \neq 0, \\[8pt] \ln{(x_i)} &amp;amp; \text{if } \lambda = 0, \end{cases}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} x_i ^ {(\ lambda)} = \ begin {cases} \ dfrac {x_i ^ \ lambda - 1} {\ lambda} &amp;amp; \ text {if} \ lambda \ neq 0, \\ [ 8pt] \ ln {(x_i)} &amp;amp; \ text {if} \ lambda = 0, \ end {cases} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="4537e01f403cf1db6a1704e87011ad05c2900083" translate="yes" xml:space="preserve">
          <source>\[\binom{n_{\text{samples}}}{n_{\text{subsamples}}}\]</source>
          <target state="translated">\[\binom{n_{\text{samples}}}{n_{\text{subsamples}}}\]</target>
        </trans-unit>
        <trans-unit id="a73d653ad8356da32b64d5107d59910b4574da8f" translate="yes" xml:space="preserve">
          <source>\[\binom{n_{samples}}{n_{subsamples}}\]</source>
          <target state="translated">\[\binom{n_{samples}}{n_{subsamples}}\]</target>
        </trans-unit>
        <trans-unit id="ac1ff82d2bb9be7a891279ff19e58ef9606ac1e2" translate="yes" xml:space="preserve">
          <source>\[\eta^{(t)} = \frac {1}{\alpha (t_0 + t)}\]</source>
          <target state="translated">\ [\ eta ^ {(t)} = \ frac {1} {\ alpha (t_0 + t)} \]</target>
        </trans-unit>
        <trans-unit id="94fa32af9a54520431e5e0db6110f5f4be3adb89" translate="yes" xml:space="preserve">
          <source>\[\eta^{(t)} = \frac{eta_0}{t^{power\_t}}\]</source>
          <target state="translated">\ [\ eta ^ {(t)} = \ frac {eta_0} {t ^ {poder \ _t}} \]</target>
        </trans-unit>
        <trans-unit id="5914d3325cfa1135b23fa0bc1a30756771d61bd1" translate="yes" xml:space="preserve">
          <source>\[\frac{2}{c(c-1)}\sum_{j=1}^{c}\sum_{k &amp;gt; j}^c (\text{AUC}(j | k) + \text{AUC}(k | j))\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23f7d8421e9f7d86dc62315499303963443744dd" translate="yes" xml:space="preserve">
          <source>\[\frac{2}{c(c-1)}\sum_{j=1}^{c}\sum_{k &amp;gt; j}^c p(j \cup k)( \text{AUC}(j | k) + \text{AUC}(k | j))\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ab74fa9a47831af7bc26708f2eb4bb36eb7c478" translate="yes" xml:space="preserve">
          <source>\[\gamma_m = \arg\min_{\gamma} \sum_{i=1}^{n} L(y_i, F_{m-1}(x_i) - \gamma \frac{\partial L(y_i, F_{m-1}(x_i))}{\partial F_{m-1}(x_i)})\]</source>
          <target state="translated">\ [\ gamma_m = \ arg \ min _ {\ gamma} \ sum_ {i = 1} ^ {n} L (y_i, F_ {m-1} (x_i) - \ gamma \ frac {\ parcial L (y_i, F_ {m-1} (x_i))} {\ parcial F_ {m-1} (x_i)}) \]</target>
        </trans-unit>
        <trans-unit id="03488d7aa371e338e3a792b1ee0314e7750d1c23" translate="yes" xml:space="preserve">
          <source>\[\hat{K} = \mathrm{argmin}_K \big( \mathrm{tr} S K - \mathrm{log} \mathrm{det} K + \alpha \|K\|_1 \big)\]</source>
          <target state="translated">\ [\ hat {K} = \ mathrm {argmin} _K \ big (\ mathrm {tr} SK - \ mathrm {log} \ mathrm {det} K + \ alpha \ | K \ | _1 \ big) \]</target>
        </trans-unit>
        <trans-unit id="9d564db2d54a230e005c20037b5a37d139fd79dd" translate="yes" xml:space="preserve">
          <source>\[\hat{\theta}_{yi} = \frac{ N_{yi} + \alpha}{N_y + \alpha n}\]</source>
          <target state="translated">\ [\ hat {\ theta} _ {yi} = \ frac {N_ {yi} + \ alpha} {N_y + \ alpha n} \]</target>
        </trans-unit>
        <trans-unit id="c11c6e06d183bd2451c8cb2b3112bec0b1bc1ee8" translate="yes" xml:space="preserve">
          <source>\[\hat{c} = \arg\min_c \sum_{i} t_i w_{ci}\]</source>
          <target state="translated">\ [\ hat {c} = \ arg \ min_c \ sum_ {i} t_i w_ {ci} \]</target>
        </trans-unit>
        <trans-unit id="0d0878697ede61cc2d8e8a17d350fedc4b3570ca" translate="yes" xml:space="preserve">
          <source>\[\hat{w}_i = \frac{w_i}{\sum_j{1(y_j = y_i) w_j}}\]</source>
          <target state="translated">\ [\ hat {w} _i = \ frac {w_i} {\ sum_j {1 (y_j = y_i) w_j}} \]</target>
        </trans-unit>
        <trans-unit id="2a9f64bd46b89b26f87a73f822e103df8215fc20" translate="yes" xml:space="preserve">
          <source>\[\hat{y_i} = F_M(x_i) = \sum_{m=1}^{M} h_m(x_i)\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4cf751319dcee1f0c7d13ac626ea9ed7a5bb6a9" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, X) = h(Xw).\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="463125ace329bbcbe2634beaad2a87856ea8f696" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, x) = w_0 + w_1 x_1 + ... + w_p x_p\]</source>
          <target state="translated">\ [\ hat {y} (w, x) = w_0 + w_1 x_1 + ... + w_p x_p \]</target>
        </trans-unit>
        <trans-unit id="d7104cc52e967d53cc9bb7db2f89101bc8dd84a8" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, x) = w_0 + w_1 x_1 + w_2 x_2 + w_3 x_1 x_2 + w_4 x_1^2 + w_5 x_2^2\]</source>
          <target state="translated">\ [\ hat {y} (w, x) = w_0 + w_1 x_1 + w_2 x_2 + w_3 x_1 x_2 + w_4 x_1 ^ 2 + w_5 x_2 ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="658832cb765efda37a6b6c541d565e8e7abeaf9e" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, x) = w_0 + w_1 x_1 + w_2 x_2\]</source>
          <target state="translated">\ [\ hat {y} (w, x) = w_0 + w_1 x_1 + w_2 x_2 \]</target>
        </trans-unit>
        <trans-unit id="e16dea6416d3f9e94f0e5c1b50c7914fc96699e9" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, x) = w_0 + w_1 z_1 + w_2 z_2 + w_3 z_3 + w_4 z_4 + w_5 z_5\]</source>
          <target state="translated">\ [\ hat {y} (w, x) = w_0 + w_1 z_1 + w_2 z_2 + w_3 z_3 + w_4 z_4 + w_5 z_5 \]</target>
        </trans-unit>
        <trans-unit id="1ef6664dd57ac85f53b0ac082bd4ac87b3d1bc48" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, z) = w_0 + w_1 z_1 + w_2 z_2 + w_3 z_3 + w_4 z_4 + w_5 z_5\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ee9d5e754305261d56bc754281eac2d4bc47e43" translate="yes" xml:space="preserve">
          <source>\[\kappa = (p_o - p_e) / (1 - p_e)\]</source>
          <target state="translated">\ [\ kappa = (p_o - p_e) / (1 - p_e) \]</target>
        </trans-unit>
        <trans-unit id="167a98e04ab5b59774a90feac289ea3a97af6579" translate="yes" xml:space="preserve">
          <source>\[\log P(v) = \log \sum_h e^{-E(v, h)} - \log \sum_{x, y} e^{-E(x, y)}\]</source>
          <target state="translated">\ [\ log P (v) = \ log \ sum_h e ^ {- E (v, h)} - \ log \ sum_ {x, y} e ^ {- E (x, y)} \]</target>
        </trans-unit>
        <trans-unit id="3615a8591ff789e7148f8d4eaedd232d6f832187" translate="yes" xml:space="preserve">
          <source>\[\log P(y=k | x) = -\frac{1}{2} (x-\mu_k)^t \Sigma^{-1} (x-\mu_k) + \log P(y = k) + Cst.\]</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
