<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="es" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="21ade7db23177cbafdee1241d820ab218814e247" translate="yes" xml:space="preserve">
          <source>There are two ways to specify multiple scoring metrics for the &lt;code&gt;scoring&lt;/code&gt; parameter:</source>
          <target state="translated">Hay dos formas de especificar varias m&amp;eacute;tricas de puntuaci&amp;oacute;n para el par&amp;aacute;metro de &lt;code&gt;scoring&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="c9e248c64205afb9beabc74d09eccb0781bdceea" translate="yes" xml:space="preserve">
          <source>There exist several strategies to perform Bayesian ridge regression. This implementation is based on the algorithm described in Appendix A of (Tipping, 2001) where updates of the regularization parameters are done as suggested in (MacKay, 1992). Note that according to A New View of Automatic Relevance Determination (Wipf and Nagarajan, 2008) these update rules do not guarantee that the marginal likelihood is increasing between two consecutive iterations of the optimization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cdf4947857438b0c51097ba679415b8309e576f2" translate="yes" xml:space="preserve">
          <source>There exists two types of MDS algorithm: metric and non metric. In the scikit-learn, the class &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; implements both. In Metric MDS, the input similarity matrix arises from a metric (and thus respects the triangular inequality), the distances between output two points are then set to be as close as possible to the similarity or dissimilarity data. In the non-metric version, the algorithms will try to preserve the order of the distances, and hence seek for a monotonic relationship between the distances in the embedded space and the similarities/dissimilarities.</source>
          <target state="translated">Existen dos tipos de algoritmo MDS: m&amp;eacute;trico y no m&amp;eacute;trico. En scikit-learn, la clase &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt; &lt;code&gt;MDS&lt;/code&gt; &lt;/a&gt; implementa ambos. En Metric MDS, la matriz de similitud de entrada surge de una m&amp;eacute;trica (y, por lo tanto, respeta la desigualdad triangular), las distancias entre dos puntos de salida se establecen para que est&amp;eacute;n lo m&amp;aacute;s cerca posible de los datos de similitud o disimilitud. En la versi&amp;oacute;n no m&amp;eacute;trica, los algoritmos intentar&amp;aacute;n preservar el orden de las distancias y, por lo tanto, buscar&amp;aacute;n una relaci&amp;oacute;n mon&amp;oacute;tona entre las distancias en el espacio incrustado y las similitudes / disimilitudes.</target>
        </trans-unit>
        <trans-unit id="9e945ec56932f8495741411aac1ef0391f41ea70" translate="yes" xml:space="preserve">
          <source>There is absolutely no guarantee of recovering a ground truth. First, choosing the right number of clusters is hard. Second, the algorithm is sensitive to initialization, and can fall into local minima, although scikit-learn employs several tricks to mitigate this issue.</source>
          <target state="translated">No hay absolutamente ninguna garantía de recuperar una verdad fundamental.Primero,elegir el número correcto de grupos es difícil.Segundo,el algoritmo es sensible a la inicialización,y puede caer en los mínimos locales,aunque scikit-learn emplea varios trucos para mitigar este problema.</target>
        </trans-unit>
        <trans-unit id="a5fa0b690cccf03ea1d32deadc1c15c3039ee96d" translate="yes" xml:space="preserve">
          <source>There is built-in support for sparse data given in any matrix in a format supported by &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;scipy.sparse&lt;/a&gt;. For maximum efficiency, however, use the CSR matrix format as defined in &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html&quot;&gt;scipy.sparse.csr_matrix&lt;/a&gt;.</source>
          <target state="translated">Hay soporte incorporado para datos dispersos proporcionados en cualquier matriz en un formato compatible con &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;scipy.sparse&lt;/a&gt; . Sin embargo, para una m&amp;aacute;xima eficiencia, use el formato de matriz CSR como se define en &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html&quot;&gt;scipy.sparse.csr_matrix&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="46a0af0f073c85f45d179011b96dd0c21ed6963a" translate="yes" xml:space="preserve">
          <source>There is built-in support for sparse data given in any matrix in a format supported by &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;scipy.sparse&lt;/a&gt;. For maximum efficiency, however, use the CSR matrix format as defined in &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html&quot;&gt;scipy.sparse.csr_matrix&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bf90eed7a42877d9e674dd4cae64f5ef3af07a9" translate="yes" xml:space="preserve">
          <source>There is no general rule to select an alpha parameter for recovery of non-zero coefficients. It can by set by cross-validation (&lt;code&gt;LassoCV&lt;/code&gt; or &lt;code&gt;LassoLarsCV&lt;/code&gt;), though this may lead to under-penalized models: including a small number of non-relevant variables is not detrimental to prediction score. BIC (&lt;code&gt;LassoLarsIC&lt;/code&gt;) tends, on the opposite, to set high values of alpha.</source>
          <target state="translated">No existe una regla general para seleccionar un par&amp;aacute;metro alfa para la recuperaci&amp;oacute;n de coeficientes distintos de cero. Puede establecerse mediante validaci&amp;oacute;n cruzada ( &lt;code&gt;LassoCV&lt;/code&gt; o &lt;code&gt;LassoLarsCV&lt;/code&gt; ), aunque esto puede conducir a modelos poco penalizados: incluir una peque&amp;ntilde;a cantidad de variables no relevantes no es perjudicial para la puntuaci&amp;oacute;n de predicci&amp;oacute;n. BIC ( &lt;code&gt;LassoLarsIC&lt;/code&gt; ) tiende, por el contrario, a establecer valores altos de alfa.</target>
        </trans-unit>
        <trans-unit id="ff0ab54a4c7a8a1cf35484dbae4d9dce95d5c026" translate="yes" xml:space="preserve">
          <source>There might be a difference in the scores obtained between &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;solver=liblinear&lt;/code&gt; or &lt;code&gt;LinearSVC&lt;/code&gt; and the external liblinear library directly, when &lt;code&gt;fit_intercept=False&lt;/code&gt; and the fit &lt;code&gt;coef_&lt;/code&gt; (or) the data to be predicted are zeroes. This is because for the sample(s) with &lt;code&gt;decision_function&lt;/code&gt; zero, &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; and &lt;code&gt;LinearSVC&lt;/code&gt; predict the negative class, while liblinear predicts the positive class. Note that a model with &lt;code&gt;fit_intercept=False&lt;/code&gt; and having many samples with &lt;code&gt;decision_function&lt;/code&gt; zero, is likely to be a underfit, bad model and you are advised to set &lt;code&gt;fit_intercept=True&lt;/code&gt; and increase the intercept_scaling.</source>
          <target state="translated">Puede haber una diferencia en las puntuaciones obtenidas entre &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt; con &lt;code&gt;solver=liblinear&lt;/code&gt; o &lt;code&gt;LinearSVC&lt;/code&gt; y la biblioteca liblinear externa directamente, cuando &lt;code&gt;fit_intercept=False&lt;/code&gt; y el &lt;code&gt;coef_&lt;/code&gt; (o) los datos a predecir son ceros. Esto se debe a que para las muestras con &lt;code&gt;decision_function&lt;/code&gt; cero, &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt; y &lt;code&gt;LinearSVC&lt;/code&gt; predicen la clase negativa, mientras que liblinear predice la clase positiva. Tenga en cuenta que un modelo con &lt;code&gt;fit_intercept=False&lt;/code&gt; y que tiene muchas muestras con &lt;code&gt;decision_function&lt;/code&gt; cero, es probable que sea un modelo incorrecto y no apto, y se recomienda configurar &lt;code&gt;fit_intercept=True&lt;/code&gt; y aumente el intercept_scaling.</target>
        </trans-unit>
        <trans-unit id="4a4216d2986ca1c413a45927f7f8dc07ca811204" translate="yes" xml:space="preserve">
          <source>Therefore, a logarithmic (&lt;code&gt;np.log1p&lt;/code&gt;) and an exponential function (&lt;code&gt;np.expm1&lt;/code&gt;) will be used to transform the targets before training a linear regression model and using it for prediction.</source>
          <target state="translated">Por lo tanto, se &lt;code&gt;np.log1p&lt;/code&gt; una funci&amp;oacute;n logar&amp;iacute;tmica ( np.log1p ) y una exponencial ( &lt;code&gt;np.expm1&lt;/code&gt; ) para transformar los objetivos antes de entrenar un modelo de regresi&amp;oacute;n lineal y usarlo para la predicci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="6912f2dbecf0d873a7ad1021b00fc015a0232427" translate="yes" xml:space="preserve">
          <source>These are transformers that are not intended to be used on features, only on supervised learning targets. See also &lt;a href=&quot;compose#transformed-target-regressor&quot;&gt;Transforming target in regression&lt;/a&gt; if you want to transform the prediction target for learning, but evaluate the model in the original (untransformed) space.</source>
          <target state="translated">Estos son transformadores que no est&amp;aacute;n dise&amp;ntilde;ados para usarse en funciones, solo en objetivos de aprendizaje supervisado. Consulte tambi&amp;eacute;n &lt;a href=&quot;compose#transformed-target-regressor&quot;&gt;Transformaci&amp;oacute;n del objetivo en regresi&amp;oacute;n&lt;/a&gt; si desea transformar el objetivo de predicci&amp;oacute;n para el aprendizaje, pero eval&amp;uacute;e el modelo en el espacio original (sin transformar).</target>
        </trans-unit>
        <trans-unit id="9c615abfdf912d61f49e70314e0bacb6d3789d48" translate="yes" xml:space="preserve">
          <source>These classifiers are attractive because they have closed-form solutions that can be easily computed, are inherently multiclass, have proven to work well in practice, and have no hyperparameters to tune.</source>
          <target state="translated">Estos clasificadores son atractivos porque tienen soluciones de forma cerrada que se pueden computar fácilmente,son inherentemente multiclases,han demostrado funcionar bien en la práctica y no tienen hiperparámetros que afinar.</target>
        </trans-unit>
        <trans-unit id="fde55c65b8197fd0cbaa58300d107768af9ed389" translate="yes" xml:space="preserve">
          <source>These constraint are useful to impose a certain local structure, but they also make the algorithm faster, especially when the number of the samples is high.</source>
          <target state="translated">Estas limitaciones son útiles para imponer una cierta estructura local,pero también hacen que el algoritmo sea más rápido,especialmente cuando el número de muestras es elevado.</target>
        </trans-unit>
        <trans-unit id="ebd210a6b7ae21f6cafc3c41203edaaa46e25728" translate="yes" xml:space="preserve">
          <source>These datasets are useful to quickly illustrate the behavior of the various algorithms implemented in scikit-learn. They are however often too small to be representative of real world machine learning tasks.</source>
          <target state="translated">Estos conjuntos de datos son útiles para ilustrar rápidamente el comportamiento de los diversos algoritmos implementados en scikit-learn.Sin embargo,a menudo son demasiado pequeños para ser representativos de las tareas de aprendizaje de la máquina en el mundo real.</target>
        </trans-unit>
        <trans-unit id="8d2ab26191aa60fb366e6a03a6fce9c7d01208ba" translate="yes" xml:space="preserve">
          <source>These environment variables should be set before importing scikit-learn.</source>
          <target state="translated">Estas variables de entorno deben fijarse antes de importar Scikit-learn.</target>
        </trans-unit>
        <trans-unit id="b821932825baa77bb11f8b1f95c8cc38b1d75bf5" translate="yes" xml:space="preserve">
          <source>These estimators are called similarly to their counterparts, with &amp;lsquo;CV&amp;rsquo; appended to their name.</source>
          <target state="translated">Estos estimadores se denominan de manera similar a sus contrapartes, con 'CV' adjunto a su nombre.</target>
        </trans-unit>
        <trans-unit id="4895efc31f112ba17d5e8de5c88b9b84cbaac29a" translate="yes" xml:space="preserve">
          <source>These estimators are described in more detail below in &lt;a href=&quot;#histogram-based-gradient-boosting&quot;&gt;Histogram-Based Gradient Boosting&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31d7d129bfc794bb111166051ddf1fbfd1e21090" translate="yes" xml:space="preserve">
          <source>These estimators are still &lt;strong&gt;experimental&lt;/strong&gt;: their predictions and their API might change without any deprecation cycle. To use them, you need to explicitly import &lt;code&gt;enable_hist_gradient_boosting&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd57beb09d61462992a46fc07ecdff56e4d9c660" translate="yes" xml:space="preserve">
          <source>These estimators fit multiple regression problems (or tasks) jointly, while inducing sparse coefficients. While the inferred coefficients may differ between the tasks, they are constrained to agree on the features that are selected (non-zero coefficients).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fac22fa1718df2cc93fd78246f559caa4e598cf3" translate="yes" xml:space="preserve">
          <source>These examples illustrate the main features of the releases of scikit-learn.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8bef6d4f1ba3e716c219b98d63998eb428a7438d" translate="yes" xml:space="preserve">
          <source>These families of algorithms are useful to find linear relations between two multivariate datasets: the &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;Y&lt;/code&gt; arguments of the &lt;code&gt;fit&lt;/code&gt; method are 2D arrays.</source>
          <target state="translated">Estas familias de algoritmos son &amp;uacute;tiles para encontrar relaciones lineales entre dos conjuntos de datos multivariados: los argumentos &lt;code&gt;X&lt;/code&gt; e &lt;code&gt;Y&lt;/code&gt; del m&amp;eacute;todo de &lt;code&gt;fit&lt;/code&gt; son matrices 2D.</target>
        </trans-unit>
        <trans-unit id="1f2f0c6c7df23095dba3fa00aa5227521de2ff47" translate="yes" xml:space="preserve">
          <source>These fast estimators first bin the input samples &lt;code&gt;X&lt;/code&gt; into integer-valued bins (typically 256 bins) which tremendously reduces the number of splitting points to consider, and allows the algorithm to leverage integer-based data structures (histograms) instead of relying on sorted continuous values when building the trees. The API of these estimators is slightly different, and some of the features from &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; are not yet supported, for instance some loss functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e90c7c20b495d718d6ee1761b52661a07d31f2ac" translate="yes" xml:space="preserve">
          <source>These figures aid in illustrating how a point cloud can be very flat in one direction&amp;ndash;which is where PCA comes in to choose a direction that is not flat.</source>
          <target state="translated">Estas cifras ayudan a ilustrar c&amp;oacute;mo una nube de puntos puede ser muy plana en una direcci&amp;oacute;n, que es donde entra PCA para elegir una direcci&amp;oacute;n que no sea plana.</target>
        </trans-unit>
        <trans-unit id="5b3c06102d71e9aa21ce3635f214fb7544bfe93e" translate="yes" xml:space="preserve">
          <source>These functions have an &lt;code&gt;multioutput&lt;/code&gt; keyword argument which specifies the way the scores or losses for each individual target should be averaged. The default is &lt;code&gt;'uniform_average'&lt;/code&gt;, which specifies a uniformly weighted mean over outputs. If an &lt;code&gt;ndarray&lt;/code&gt; of shape &lt;code&gt;(n_outputs,)&lt;/code&gt; is passed, then its entries are interpreted as weights and an according weighted average is returned. If &lt;code&gt;multioutput&lt;/code&gt; is &lt;code&gt;'raw_values'&lt;/code&gt; is specified, then all unaltered individual scores or losses will be returned in an array of shape &lt;code&gt;(n_outputs,)&lt;/code&gt;.</source>
          <target state="translated">Estas funciones tienen un argumento de palabra clave de &lt;code&gt;multioutput&lt;/code&gt; que especifica la forma en que se deben promediar las puntuaciones o p&amp;eacute;rdidas para cada objetivo individual. El valor predeterminado es &lt;code&gt;'uniform_average'&lt;/code&gt; , que especifica una media ponderada uniformemente sobre las salidas. Si se &lt;code&gt;ndarray&lt;/code&gt; un ndarray de forma &lt;code&gt;(n_outputs,)&lt;/code&gt; , sus entradas se interpretan como pesos y se devuelve un promedio ponderado correspondiente. Si se especifica &lt;code&gt;multioutput&lt;/code&gt; es &lt;code&gt;'raw_values'&lt;/code&gt; , entonces todos los puntajes o p&amp;eacute;rdidas individuales inalterados se devolver&amp;aacute;n en una matriz de forma &lt;code&gt;(n_outputs,)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8f744234c4fef479ca52103694dddbbb39569d67" translate="yes" xml:space="preserve">
          <source>These functions return a tuple &lt;code&gt;(X, y)&lt;/code&gt; consisting of a &lt;code&gt;n_samples&lt;/code&gt; * &lt;code&gt;n_features&lt;/code&gt; numpy array &lt;code&gt;X&lt;/code&gt; and an array of length &lt;code&gt;n_samples&lt;/code&gt; containing the targets &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">Estas funciones devuelven una tupla &lt;code&gt;(X, y)&lt;/code&gt; consta de &lt;code&gt;n_samples&lt;/code&gt; * &lt;code&gt;n_features&lt;/code&gt; numpy array &lt;code&gt;X&lt;/code&gt; y una matriz de longitud &lt;code&gt;n_samples&lt;/code&gt; que contiene los objetivos &lt;code&gt;y&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7ea4b087a47ece8eb67eda1c13d069b3e5f40d70" translate="yes" xml:space="preserve">
          <source>These generators produce a matrix of features and corresponding discrete targets.</source>
          <target state="translated">Estos generadores producen una matriz de características y los correspondientes objetivos discretos.</target>
        </trans-unit>
        <trans-unit id="ff830f502c3a30a0f4f3f842eff62f7849f20cad" translate="yes" xml:space="preserve">
          <source>These histogram-based estimators can be &lt;strong&gt;orders of magnitude faster&lt;/strong&gt; than &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; when the number of samples is larger than tens of thousands of samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7870342f67a34d74383fe781d3e91593569275ef" translate="yes" xml:space="preserve">
          <source>These images how similar features are merged together using feature agglomeration.</source>
          <target state="translated">Estas imágenes muestran cómo se fusionan características similares utilizando la aglomeración de características.</target>
        </trans-unit>
        <trans-unit id="2f6550a6d877a222d311c7f7d2e4efbab68b15f3" translate="yes" xml:space="preserve">
          <source>These matrices can be used to impose connectivity in estimators that use connectivity information, such as Ward clustering (&lt;a href=&quot;clustering#hierarchical-clustering&quot;&gt;Hierarchical clustering&lt;/a&gt;), but also to build precomputed kernels, or similarity matrices.</source>
          <target state="translated">Estas matrices se pueden utilizar para imponer conectividad en estimadores que utilizan informaci&amp;oacute;n de conectividad, como el agrupamiento de Ward ( &lt;a href=&quot;clustering#hierarchical-clustering&quot;&gt;agrupamiento jer&amp;aacute;rquico&lt;/a&gt; ), pero tambi&amp;eacute;n para construir n&amp;uacute;cleos precalculados o matrices de similitud.</target>
        </trans-unit>
        <trans-unit id="f1476efa19922a5a7b34be362fc1e06a3ae81118" translate="yes" xml:space="preserve">
          <source>These metrics &lt;strong&gt;require the knowledge of the ground truth classes&lt;/strong&gt; while almost never available in practice or requires manual assignment by human annotators (as in the supervised learning setting).</source>
          <target state="translated">Estas m&amp;eacute;tricas &lt;strong&gt;requieren el conocimiento de las clases de verdad b&amp;aacute;sica,&lt;/strong&gt; mientras que casi nunca est&amp;aacute;n disponibles en la pr&amp;aacute;ctica o requieren una asignaci&amp;oacute;n manual por parte de anotadores humanos (como en el entorno de aprendizaje supervisado).</target>
        </trans-unit>
        <trans-unit id="102278a50cfd01c3d7a2cbdc18b76a5ce6b39772" translate="yes" xml:space="preserve">
          <source>These models allow for response variables to have error distributions other than a normal distribution:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b78634dcd7b938ef7f64bb3d2756751845f06a1" translate="yes" xml:space="preserve">
          <source>These objects take as input a scoring function that returns univariate scores and p-values (or only scores for &lt;a href=&quot;generated/sklearn.feature_selection.selectkbest#sklearn.feature_selection.SelectKBest&quot;&gt;&lt;code&gt;SelectKBest&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.feature_selection.selectpercentile#sklearn.feature_selection.SelectPercentile&quot;&gt;&lt;code&gt;SelectPercentile&lt;/code&gt;&lt;/a&gt;):</source>
          <target state="translated">Estos objetos toman como entrada una funci&amp;oacute;n de puntuaci&amp;oacute;n que devuelve puntuaciones univariadas y valores p (o solo puntuaciones para &lt;a href=&quot;generated/sklearn.feature_selection.selectkbest#sklearn.feature_selection.SelectKBest&quot;&gt; &lt;code&gt;SelectKBest&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.feature_selection.selectpercentile#sklearn.feature_selection.SelectPercentile&quot;&gt; &lt;code&gt;SelectPercentile&lt;/code&gt; &lt;/a&gt; ):</target>
        </trans-unit>
        <trans-unit id="7d570e698357345b9d25fb0f909251adbc540e40" translate="yes" xml:space="preserve">
          <source>These parameters can be accessed through the attributes &lt;code&gt;dual_coef_&lt;/code&gt; which holds the difference \(\alpha_i - \alpha_i^*\), &lt;code&gt;support_vectors_&lt;/code&gt; which holds the support vectors, and &lt;code&gt;intercept_&lt;/code&gt; which holds the independent term \(b\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc9887aaf0c2ed20eb0f603451b50a8d7e26af7c" translate="yes" xml:space="preserve">
          <source>These parameters can be accessed through the attributes &lt;code&gt;dual_coef_&lt;/code&gt; which holds the product \(y_i \alpha_i\), &lt;code&gt;support_vectors_&lt;/code&gt; which holds the support vectors, and &lt;code&gt;intercept_&lt;/code&gt; which holds the independent term \(b\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3403571e1d1dd77b054e08b8e749a4d9b5c4d316" translate="yes" xml:space="preserve">
          <source>These parameters can be accessed through the members &lt;code&gt;dual_coef_&lt;/code&gt; which holds the difference \(\alpha_i - \alpha_i^*\), &lt;code&gt;support_vectors_&lt;/code&gt; which holds the support vectors, and &lt;code&gt;intercept_&lt;/code&gt; which holds the independent term \(\rho\)</source>
          <target state="translated">Se puede acceder a estos par&amp;aacute;metros a trav&amp;eacute;s de los miembros &lt;code&gt;dual_coef_&lt;/code&gt; que contiene la diferencia \ (\ alpha_i - \ alpha_i ^ * \), &lt;code&gt;support_vectors_&lt;/code&gt; que contiene los vectores de soporte e &lt;code&gt;intercept_&lt;/code&gt; que contiene el t&amp;eacute;rmino independiente \ (\ rho \)</target>
        </trans-unit>
        <trans-unit id="9254aef96f1c8727db185406da2727e74822dda9" translate="yes" xml:space="preserve">
          <source>These quantities are also related to the (\(F_1\)) score, which is defined as the harmonic mean of precision and recall.</source>
          <target state="translated">Estas cantidades también están relacionadas con la puntuación (\(F_1\)),que se define como la media armónica de precisión y recuerdo.</target>
        </trans-unit>
        <trans-unit id="8ec6209edcb97e57d934d74900289c4f7467ca16" translate="yes" xml:space="preserve">
          <source>These represent the 14 features measured at each point of the map grid. The latitude/longitude values for the grid are discussed below. Missing data is represented by the value -9999.</source>
          <target state="translated">Estos representan los 14 rasgos medidos en cada punto de la cuadrícula del mapa.Los valores de latitud y longitud de la cuadrícula se examinan a continuación.Los datos que faltan están representados por el valor -9999.</target>
        </trans-unit>
        <trans-unit id="e11ef00d62661e429b4b798a345a9c8d62a348e6" translate="yes" xml:space="preserve">
          <source>These steps are performed either a maximum number of times (&lt;code&gt;max_trials&lt;/code&gt;) or until one of the special stop criteria are met (see &lt;code&gt;stop_n_inliers&lt;/code&gt; and &lt;code&gt;stop_score&lt;/code&gt;). The final model is estimated using all inlier samples (consensus set) of the previously determined best model.</source>
          <target state="translated">Estos pasos se llevan a cabo un n&amp;uacute;mero m&amp;aacute;ximo de veces ( &lt;code&gt;max_trials&lt;/code&gt; ) o hasta que se cumpla uno de los criterios especiales de parada (consulte &lt;code&gt;stop_n_inliers&lt;/code&gt; y &lt;code&gt;stop_score&lt;/code&gt; ). El modelo final se estima utilizando todas las muestras internas (conjunto de consenso) del mejor modelo previamente determinado.</target>
        </trans-unit>
        <trans-unit id="ffccb4ceb37928160a8178b1e93c390573c106cb" translate="yes" xml:space="preserve">
          <source>These three distances are special cases of the beta-divergence family, with \(\beta = 2, 1, 0\) respectively &lt;a href=&quot;#id15&quot; id=&quot;id8&quot;&gt;6&lt;/a&gt;. The beta-divergence are defined by :</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eff89650d9905b662c6df80228e926f2f144c91b" translate="yes" xml:space="preserve">
          <source>These three distances are special cases of the beta-divergence family, with \(\beta = 2, 1, 0\) respectively &lt;a href=&quot;#id15&quot; id=&quot;id8&quot;&gt;[6]&lt;/a&gt;. The beta-divergence are defined by :</source>
          <target state="translated">Estas tres distancias son casos especiales de la familia de divergencia beta, con \ (\ beta = 2, 1, 0 \) respectivamente &lt;a href=&quot;#id15&quot; id=&quot;id8&quot;&gt;[6]&lt;/a&gt; . La beta-divergencia se define por:</target>
        </trans-unit>
        <trans-unit id="100dafc268c3e9d0b628da1715aed2440b14ba32" translate="yes" xml:space="preserve">
          <source>These throughputs are achieved on a single process. An obvious way to increase the throughput of your application is to spawn additional instances (usually processes in Python because of the &lt;a href=&quot;https://wiki.python.org/moin/GlobalInterpreterLock&quot;&gt;GIL&lt;/a&gt;) that share the same model. One might also add machines to spread the load. A detailed explanation on how to achieve this is beyond the scope of this documentation though.</source>
          <target state="translated">Estos rendimientos se logran en un solo proceso. Una forma obvia de aumentar el rendimiento de su aplicaci&amp;oacute;n es generar instancias adicionales (generalmente procesos en Python debido a &lt;a href=&quot;https://wiki.python.org/moin/GlobalInterpreterLock&quot;&gt;GIL&lt;/a&gt; ) que comparten el mismo modelo. Tambi&amp;eacute;n se pueden agregar m&amp;aacute;quinas para distribuir la carga. Sin embargo, una explicaci&amp;oacute;n detallada sobre c&amp;oacute;mo lograr esto est&amp;aacute; m&amp;aacute;s all&amp;aacute; del alcance de esta documentaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="b826ad64b72daa0458c9fdfb2862fce60b4db70b" translate="yes" xml:space="preserve">
          <source>They also have built-in support for missing values, which avoids the need for an imputer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e63971597c4df5f2dc150f90b566e1219b6a632a" translate="yes" xml:space="preserve">
          <source>They are not sparse, i.e., they use the whole samples/features information to perform the prediction.</source>
          <target state="translated">No son escasos,es decir,utilizan toda la información de las muestras/funciones para realizar la predicción.</target>
        </trans-unit>
        <trans-unit id="26f84bd6fe103542912ebb1fb588d29515a2fd6d" translate="yes" xml:space="preserve">
          <source>They can be loaded using the following functions:</source>
          <target state="translated">Pueden ser cargados usando las siguientes funciones:</target>
        </trans-unit>
        <trans-unit id="f7ddbd9f45ee3f137b5eb656135dce7584351da0" translate="yes" xml:space="preserve">
          <source>They expose a &lt;code&gt;split&lt;/code&gt; method which accepts the input dataset to be split and yields the train/test set indices for each iteration of the chosen cross-validation strategy.</source>
          <target state="translated">Exponen un m&amp;eacute;todo &lt;code&gt;split&lt;/code&gt; que acepta que el conjunto de datos de entrada se divida y produce los &amp;iacute;ndices del conjunto de tren / prueba para cada iteraci&amp;oacute;n de la estrategia de validaci&amp;oacute;n cruzada elegida.</target>
        </trans-unit>
        <trans-unit id="03bbcc98e1d567dd0afc112fe378a99851c98226" translate="yes" xml:space="preserve">
          <source>They lose efficiency in high dimensional spaces &amp;ndash; namely when the number of features exceeds a few dozens.</source>
          <target state="translated">Pierden eficacia en espacios de gran dimensi&amp;oacute;n, es decir, cuando el n&amp;uacute;mero de funciones supera unas pocas docenas.</target>
        </trans-unit>
        <trans-unit id="a673690dbc33eee17ee6f3995f817097918876ff" translate="yes" xml:space="preserve">
          <source>This Scaler removes the median and scales the data according to the quantile range (defaults to IQR: Interquartile Range). The IQR is the range between the 1st quartile (25th quantile) and the 3rd quartile (75th quantile).</source>
          <target state="translated">Este escalador elimina la mediana y escala los datos de acuerdo con el rango de cuantiles (por defecto es IQR:Interquartile Range).El IQR es el rango entre el 1er cuartil (25º cuantil)y el 3er cuartil (75º cuantil).</target>
        </trans-unit>
        <trans-unit id="d9994b645c162ae9e80a2c6bc1c81390f2e92325" translate="yes" xml:space="preserve">
          <source>This Warning is used in meta estimators GridSearchCV and RandomizedSearchCV and the cross-validation helper function cross_val_score to warn when there is an error while fitting the estimator.</source>
          <target state="translated">Esta advertencia se utiliza en los metaestimuladores GridSearchCV y RandomizedSearchCV y en la función de ayuda de validación cruzada cross_val_score para advertir cuando hay un error al ajustar el estimador.</target>
        </trans-unit>
        <trans-unit id="7f5e3d23312509826c13f1663d34b7e7912ac4af" translate="yes" xml:space="preserve">
          <source>This algorithm can be viewed as an instance or data reduction method, since it reduces the input data to a set of subclusters which are obtained directly from the leaves of the CFT. This reduced data can be further processed by feeding it into a global clusterer. This global clusterer can be set by &lt;code&gt;n_clusters&lt;/code&gt;. If &lt;code&gt;n_clusters&lt;/code&gt; is set to None, the subclusters from the leaves are directly read off, otherwise a global clustering step labels these subclusters into global clusters (labels) and the samples are mapped to the global label of the nearest subcluster.</source>
          <target state="translated">Este algoritmo puede verse como una instancia o un m&amp;eacute;todo de reducci&amp;oacute;n de datos, ya que reduce los datos de entrada a un conjunto de subclusters que se obtienen directamente de las hojas del CFT. Estos datos reducidos pueden procesarse a&amp;uacute;n m&amp;aacute;s introduci&amp;eacute;ndolos en un agrupador global. Este agrupador global se puede configurar mediante &lt;code&gt;n_clusters&lt;/code&gt; . Si &lt;code&gt;n_clusters&lt;/code&gt; se establece en None, los subclusters de las hojas se leen directamente; de ​​lo contrario, un paso de agrupaci&amp;oacute;n global etiqueta estos subclusters en agrupaciones globales (etiquetas) y las muestras se asignan a la etiqueta global del subcluster m&amp;aacute;s cercano.</target>
        </trans-unit>
        <trans-unit id="895ec6bb1e64f58ea59b9ae781fa620e703125a9" translate="yes" xml:space="preserve">
          <source>This algorithm encompasses several works from the literature. When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting &lt;a href=&quot;#r4d113ba76fc0-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;. If samples are drawn with replacement, then the method is known as Bagging &lt;a href=&quot;#r4d113ba76fc0-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt;. When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces &lt;a href=&quot;#r4d113ba76fc0-3&quot; id=&quot;id3&quot;&gt;[3]&lt;/a&gt;. Finally, when base estimators are built on subsets of both samples and features, then the method is known as Random Patches &lt;a href=&quot;#r4d113ba76fc0-4&quot; id=&quot;id4&quot;&gt;[4]&lt;/a&gt;.</source>
          <target state="translated">Este algoritmo engloba varios trabajos de la literatura. Cuando se extraen subconjuntos aleatorios del conjunto de datos como subconjuntos aleatorios de las muestras, este algoritmo se conoce como Pegado &lt;a href=&quot;#r4d113ba76fc0-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; . Si las muestras se extraen con reemplazo, el m&amp;eacute;todo se conoce como ensacado &lt;a href=&quot;#r4d113ba76fc0-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt; . Cuando se extraen subconjuntos aleatorios del conjunto de datos como subconjuntos aleatorios de las caracter&amp;iacute;sticas, el m&amp;eacute;todo se conoce como subespacios aleatorios &lt;a href=&quot;#r4d113ba76fc0-3&quot; id=&quot;id3&quot;&gt;[3]&lt;/a&gt; . Finalmente, cuando los estimadores base se construyen sobre subconjuntos de muestras y caracter&amp;iacute;sticas, el m&amp;eacute;todo se conoce como Parches aleatorios &lt;a href=&quot;#r4d113ba76fc0-4&quot; id=&quot;id4&quot;&gt;[4]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="870122c945d57891e89c2ba931542331f1b4afdb" translate="yes" xml:space="preserve">
          <source>This algorithm encompasses several works from the literature. When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting &lt;a href=&quot;#rb1846455d0e5-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;. If samples are drawn with replacement, then the method is known as Bagging &lt;a href=&quot;#rb1846455d0e5-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt;. When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces &lt;a href=&quot;#rb1846455d0e5-3&quot; id=&quot;id3&quot;&gt;[3]&lt;/a&gt;. Finally, when base estimators are built on subsets of both samples and features, then the method is known as Random Patches &lt;a href=&quot;#rb1846455d0e5-4&quot; id=&quot;id4&quot;&gt;[4]&lt;/a&gt;.</source>
          <target state="translated">Este algoritmo engloba varios trabajos de la literatura. Cuando se extraen subconjuntos aleatorios del conjunto de datos como subconjuntos aleatorios de las muestras, este algoritmo se conoce como Pegado &lt;a href=&quot;#rb1846455d0e5-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; . Si las muestras se extraen con reemplazo, el m&amp;eacute;todo se conoce como ensacado &lt;a href=&quot;#rb1846455d0e5-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt; . Cuando se extraen subconjuntos aleatorios del conjunto de datos como subconjuntos aleatorios de las caracter&amp;iacute;sticas, el m&amp;eacute;todo se conoce como subespacios aleatorios &lt;a href=&quot;#rb1846455d0e5-3&quot; id=&quot;id3&quot;&gt;[3]&lt;/a&gt; . Finalmente, cuando los estimadores base se construyen sobre subconjuntos de muestras y caracter&amp;iacute;sticas, el m&amp;eacute;todo se conoce como Parches aleatorios &lt;a href=&quot;#rb1846455d0e5-4&quot; id=&quot;id4&quot;&gt;[4]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="866e774dfaaba96a720c3090067c49c13cac935f" translate="yes" xml:space="preserve">
          <source>This algorithm finds a (usually very good) approximate truncated singular value decomposition using randomization to speed up the computations. It is particularly fast on large matrices on which you wish to extract only a small number of components. In order to obtain further speed up, &lt;code&gt;n_iter&lt;/code&gt; can be set &amp;lt;=2 (at the cost of loss of precision).</source>
          <target state="translated">Este algoritmo encuentra una descomposici&amp;oacute;n de valor singular truncado aproximado (generalmente muy buena) utilizando la aleatorizaci&amp;oacute;n para acelerar los c&amp;aacute;lculos. Es particularmente r&amp;aacute;pido en matrices grandes en las que desea extraer solo una peque&amp;ntilde;a cantidad de componentes. Para obtener una mayor velocidad, &lt;code&gt;n_iter&lt;/code&gt; se puede establecer &amp;lt;= 2 (a costa de la p&amp;eacute;rdida de precisi&amp;oacute;n).</target>
        </trans-unit>
        <trans-unit id="c5eff13aab5e02ba6e328f932a803b28ba41ee60" translate="yes" xml:space="preserve">
          <source>This algorithm has constant memory complexity, on the order of &lt;code&gt;batch_size * n_features&lt;/code&gt;, enabling use of np.memmap files without loading the entire file into memory. For sparse matrices, the input is converted to dense in batches (in order to be able to subtract the mean) which avoids storing the entire dense matrix at any one time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77977d31f5357c834112cbb27bbc98b5c64c10d7" translate="yes" xml:space="preserve">
          <source>This algorithm has constant memory complexity, on the order of &lt;code&gt;batch_size&lt;/code&gt;, enabling use of np.memmap files without loading the entire file into memory.</source>
          <target state="translated">Este algoritmo tiene una complejidad de memoria constante, del orden del &lt;code&gt;batch_size&lt;/code&gt; de lote , lo que permite el uso de archivos np.memmap sin cargar el archivo completo en la memoria.</target>
        </trans-unit>
        <trans-unit id="f443979a9a019e4d6947465617b7828e98c7b59f" translate="yes" xml:space="preserve">
          <source>This algorithm is illustrated below.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9586aed3b1a5b6a2c44b32af5cc0558b6ad496a6" translate="yes" xml:space="preserve">
          <source>This algorithm solves the normalized cut for k=2: it is a normalized spectral clustering.</source>
          <target state="translated">Este algoritmo resuelve el corte normalizado para k=2:es una agrupación espectral normalizada.</target>
        </trans-unit>
        <trans-unit id="01c65a021c885e4e00baaaa5c6652a314a97daa3" translate="yes" xml:space="preserve">
          <source>This algorithm will always use all the components it has access to, needing held-out data or information theoretical criteria to decide how many components to use in the absence of external cues.</source>
          <target state="translated">Este algoritmo utilizará siempre todos los componentes a los que tenga acceso,necesitando datos retenidos o criterios teóricos de información para decidir cuántos componentes utilizar en ausencia de pistas externas.</target>
        </trans-unit>
        <trans-unit id="ddf04fe856314e7dd4ddddf49f4086029e04d842" translate="yes" xml:space="preserve">
          <source>This allows better model selection than probabilistic PCA in the presence of heteroscedastic noise:</source>
          <target state="translated">Esto permite una mejor selección del modelo que el PCA probabilístico en presencia de ruido heteroscedástico:</target>
        </trans-unit>
        <trans-unit id="3307a2458ebbefda8ea7fe8b898077ec4cadcf2c" translate="yes" xml:space="preserve">
          <source>This also works where final estimator is &lt;code&gt;None&lt;/code&gt;: all prior transformations are applied.</source>
          <target state="translated">Esto tambi&amp;eacute;n funciona cuando el estimador final es &lt;code&gt;None&lt;/code&gt; : se aplican todas las transformaciones anteriores.</target>
        </trans-unit>
        <trans-unit id="c63b80512d8853cd76b24210ee07543da5c60fc4" translate="yes" xml:space="preserve">
          <source>This assumption is the base of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Vector_Space_Model&quot;&gt;Vector Space Model&lt;/a&gt; often used in text classification and clustering contexts.</source>
          <target state="translated">Esta suposici&amp;oacute;n es la base del &lt;a href=&quot;https://en.wikipedia.org/wiki/Vector_Space_Model&quot;&gt;modelo de espacio vectorial que&lt;/a&gt; se utiliza a menudo en contextos de clasificaci&amp;oacute;n y agrupaci&amp;oacute;n de texto.</target>
        </trans-unit>
        <trans-unit id="a8d2386009078ecaad8deb62662ebfbef6798072" translate="yes" xml:space="preserve">
          <source>This attribute is not available if &lt;code&gt;refit&lt;/code&gt; is a function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8142b653ecd3322ad782e8a8807635d6c4c0325e" translate="yes" xml:space="preserve">
          <source>This calibration results in a lower log-loss. Note that an alternative would have been to increase the number of base estimators which would have resulted in a similar decrease in log-loss.</source>
          <target state="translated">Esta calibración da como resultado una menor pérdida de registros.Nótese que una alternativa habría sido aumentar el número de estimadores de base,lo que habría resultado en una disminución similar de la pérdida de logaritmos.</target>
        </trans-unit>
        <trans-unit id="3ba422e075fa10216e381bf46530abda4e719fab" translate="yes" xml:space="preserve">
          <source>This call requires the estimation of a p x q matrix, which may be an issue in high dimensional space.</source>
          <target state="translated">Esta llamada requiere la estimación de una matriz p x q,que puede ser un problema en el espacio de altas dimensiones.</target>
        </trans-unit>
        <trans-unit id="345a3bd30c8553d3251f728b344d1bd100958670" translate="yes" xml:space="preserve">
          <source>This can be confirmed on a independent testing set with similar remarks:</source>
          <target state="translated">Esto puede confirmarse en un conjunto de pruebas independientes con observaciones similares:</target>
        </trans-unit>
        <trans-unit id="e60927eda9d0f07135f56fa39eaa1a8f1f9c2813" translate="yes" xml:space="preserve">
          <source>This can be done by introducing &lt;a href=&quot;https://en.wikipedia.org/wiki/Non-informative_prior#Uninformative_priors&quot;&gt;uninformative priors&lt;/a&gt; over the hyper parameters of the model. The \(\ell_{2}\) regularization used in &lt;a href=&quot;#id2&quot;&gt;Ridge Regression&lt;/a&gt; is equivalent to finding a maximum a posteriori estimation under a Gaussian prior over the parameters \(w\) with precision \(\lambda^{-1}\). Instead of setting &lt;code&gt;lambda&lt;/code&gt; manually, it is possible to treat it as a random variable to be estimated from the data.</source>
          <target state="translated">Esto se puede hacer introduciendo a &lt;a href=&quot;https://en.wikipedia.org/wiki/Non-informative_prior#Uninformative_priors&quot;&gt;priori no informativos&lt;/a&gt; sobre los hiperpar&amp;aacute;metros del modelo. La regularizaci&amp;oacute;n \ (\ ell_ {2} \) usada en &lt;a href=&quot;#id2&quot;&gt;Ridge Regression&lt;/a&gt; es equivalente a encontrar una estimaci&amp;oacute;n m&amp;aacute;xima a posteriori bajo un gaussiano anterior sobre los par&amp;aacute;metros \ (w \) con precisi&amp;oacute;n \ (\ lambda ^ {- 1} \). En lugar de configurar &lt;code&gt;lambda&lt;/code&gt; manualmente, es posible tratarlo como una variable aleatoria para estimar a partir de los datos.</target>
        </trans-unit>
        <trans-unit id="bdd26b00d9d2e1f23dcd81c9f002391507919ff9" translate="yes" xml:space="preserve">
          <source>This can be done by introducing &lt;a href=&quot;https://en.wikipedia.org/wiki/Non-informative_prior#Uninformative_priors&quot;&gt;uninformative priors&lt;/a&gt; over the hyper parameters of the model. The \(\ell_{2}\) regularization used in &lt;a href=&quot;#ridge-regression&quot;&gt;Ridge regression and classification&lt;/a&gt; is equivalent to finding a maximum a posteriori estimation under a Gaussian prior over the coefficients \(w\) with precision \(\lambda^{-1}\). Instead of setting &lt;code&gt;lambda&lt;/code&gt; manually, it is possible to treat it as a random variable to be estimated from the data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa181018cfeb3219e1e67073f9c58ca90a0c4faa" translate="yes" xml:space="preserve">
          <source>This can be done by using the &lt;a href=&quot;generated/sklearn.model_selection.train_test_split#sklearn.model_selection.train_test_split&quot;&gt;&lt;code&gt;train_test_split&lt;/code&gt;&lt;/a&gt; utility function.</source>
          <target state="translated">Esto se puede hacer usando la funci&amp;oacute;n de utilidad &lt;a href=&quot;generated/sklearn.model_selection.train_test_split#sklearn.model_selection.train_test_split&quot;&gt; &lt;code&gt;train_test_split&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="821e5435b62e56a883478da64d6731f6479103d5" translate="yes" xml:space="preserve">
          <source>This can be set to a higher value than the actual number of features in any of the input files, but setting it to a lower value will cause an exception to be raised.</source>
          <target state="translated">Se puede ajustar a un valor más alto que el número real de características en cualquiera de los archivos de entrada,pero ajustarlo a un valor más bajo hará que aumente la excepción.</target>
        </trans-unit>
        <trans-unit id="4a0bd36c1ccd6d51b38a900236d58695657d5aff" translate="yes" xml:space="preserve">
          <source>This class allows to infer an approximate posterior distribution over the parameters of a Gaussian mixture distribution. The effective number of components can be inferred from the data.</source>
          <target state="translated">Esta clase permite inferir una distribución posterior aproximada sobre los parámetros de una distribución de mezcla gaussiana.A partir de los datos se puede inferir el número efectivo de componentes.</target>
        </trans-unit>
        <trans-unit id="6130cf2c7564234b715447525f16ff596ebe842e" translate="yes" xml:space="preserve">
          <source>This class can be used to cross-validate time series data samples that are observed at fixed time intervals.</source>
          <target state="translated">Esta clase puede utilizarse para validar de forma cruzada las muestras de datos de series temporales que se observan en intervalos de tiempo fijos.</target>
        </trans-unit>
        <trans-unit id="88afb4091eb2a25b2e2017ee8508b1ff5c5ae125" translate="yes" xml:space="preserve">
          <source>This class implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.</source>
          <target state="translated">Esta clase implementa un metaestimulador que se ajusta a un número de árboles de decisión aleatorios (también conocidos como árboles extra)en varias submuestras del conjunto de datos y utiliza el promediado para mejorar la precisión de la predicción y controlar el exceso de ajuste.</target>
        </trans-unit>
        <trans-unit id="dd60f6580be8e1908408c4fbfd8d3915f46e55b1" translate="yes" xml:space="preserve">
          <source>This class implements logistic regression using liblinear, newton-cg, sag of lbfgs optimizer. The newton-cg, sag and lbfgs solvers support only L2 regularization with primal formulation. The liblinear solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty.</source>
          <target state="translated">Esta clase implementa la regresión logística usando el optimizador liblinear,newton-cg,sag de lbfgs.Los solucionadores newton-cg,sag y lbfgs sólo admiten la regularización L2 con la formulación primaria.El solucionador liblineal soporta tanto la regularización L1 como la L2,con una formulación dual sólo para la penalización L2.</target>
        </trans-unit>
        <trans-unit id="44487ffdb33876a6a42d281dea9cfa59f8e7af24" translate="yes" xml:space="preserve">
          <source>This class implements logistic regression using liblinear, newton-cg, sag of lbfgs optimizer. The newton-cg, sag and lbfgs solvers support only L2 regularization with primal formulation. The liblinear solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty. Elastic-Net penalty is only supported by the saga solver.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="350693d0493245dcbd676a8f10e001d5020f745e" translate="yes" xml:space="preserve">
          <source>This class implements regularized logistic regression using the &amp;lsquo;liblinear&amp;rsquo; library, &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers. It can handle both dense and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit floats for optimal performance; any other input format will be converted (and copied).</source>
          <target state="translated">Esta clase implementa regresi&amp;oacute;n log&amp;iacute;stica regularizada usando la biblioteca 'liblinear', los solucionadores 'newton-cg', 'sag' y 'lbfgs'. Puede manejar entradas densas y dispersas. Utilice matrices ordenadas en C o matrices CSR que contengan flotantes de 64 bits para un rendimiento &amp;oacute;ptimo; cualquier otro formato de entrada ser&amp;aacute; convertido (y copiado).</target>
        </trans-unit>
        <trans-unit id="7a8a7622df62d8a1b619a206bf179dc5e9e851ab" translate="yes" xml:space="preserve">
          <source>This class implements regularized logistic regression using the &amp;lsquo;liblinear&amp;rsquo; library, &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo;, &amp;lsquo;saga&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers. &lt;strong&gt;Note that regularization is applied by default&lt;/strong&gt;. It can handle both dense and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit floats for optimal performance; any other input format will be converted (and copied).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c107aea4a3526193efe1f31d97ccab92891d87f" translate="yes" xml:space="preserve">
          <source>This class implements the Graphical Lasso algorithm.</source>
          <target state="translated">Esta clase implementa el algoritmo del Lazo Gráfico.</target>
        </trans-unit>
        <trans-unit id="456e7e6f7be68de425401d6f66fe28d8a1090538" translate="yes" xml:space="preserve">
          <source>This class implements the algorithm known as AdaBoost-SAMME [2].</source>
          <target state="translated">Esta clase implementa el algoritmo conocido como AdaBoost-SAMME [2].</target>
        </trans-unit>
        <trans-unit id="003b6bf538c58eeda3c6fd28b21967bfd8b6c40e" translate="yes" xml:space="preserve">
          <source>This class implements the algorithm known as AdaBoost.R2 [2].</source>
          <target state="translated">Esta clase implementa el algoritmo conocido como AdaBoost.R2 [2].</target>
        </trans-unit>
        <trans-unit id="63c4b52b10df12140782204ea7cf58fe0edab9de" translate="yes" xml:space="preserve">
          <source>This class implements two types of prior for the weights distribution: a finite mixture model with Dirichlet distribution and an infinite mixture model with the Dirichlet Process. In practice Dirichlet Process inference algorithm is approximated and uses a truncated distribution with a fixed maximum number of components (called the Stick-breaking representation). The number of components actually used almost always depends on the data.</source>
          <target state="translated">Esta clase implementa dos tipos de previos para la distribución de pesos:un modelo de mezcla finita con la distribución Dirichlet y un modelo de mezcla infinita con el Proceso Dirichlet.En la práctica,el algoritmo de inferencia del Proceso de Dirichlet es aproximado y utiliza una distribución truncada con un número máximo fijo de componentes (llamada la representación de la ruptura del palo).El número de componentes realmente utilizado casi siempre depende de los datos.</target>
        </trans-unit>
        <trans-unit id="e15e7e7d8d04d41fdd2a4f34183baa0366e86dea" translate="yes" xml:space="preserve">
          <source>This class inherits from PLS with mode=&amp;rdquo;A&amp;rdquo; and deflation_mode=&amp;rdquo;canonical&amp;rdquo;, norm_y_weights=True and algorithm=&amp;rdquo;nipals&amp;rdquo;, but svd should provide similar results up to numerical errors.</source>
          <target state="translated">Esta clase hereda de PLS con mode = &amp;rdquo;A&amp;rdquo; y deflation_mode = &amp;rdquo;canonical&amp;rdquo;, norm_y_weights = True y algor&amp;iacute;tm = &amp;rdquo;nipals&amp;rdquo;, pero svd deber&amp;iacute;a proporcionar resultados similares hasta errores num&amp;eacute;ricos.</target>
        </trans-unit>
        <trans-unit id="a0a1d1daa83e6ad727cb13fd589f28f37b44df20" translate="yes" xml:space="preserve">
          <source>This class inherits from both ValueError and AttributeError to help with exception handling and backward compatibility.</source>
          <target state="translated">Esta clase hereda tanto de ValueError como de AttributeError para ayudar con el manejo de excepciones y la compatibilidad retroactiva.</target>
        </trans-unit>
        <trans-unit id="d34b4e0a14d3a494edeba399329a47fb49b3ee6c" translate="yes" xml:space="preserve">
          <source>This class is a low-memory alternative to DictVectorizer and CountVectorizer, intended for large-scale (online) learning and situations where memory is tight, e.g. when running prediction code on embedded devices.</source>
          <target state="translated">Esta clase es una alternativa de baja memoria a DictVectorizer y CountVectorizer,destinada al aprendizaje a gran escala (en línea)y a situaciones en las que la memoria es escasa,por ejemplo,cuando se ejecuta el código de predicción en dispositivos incorporados.</target>
        </trans-unit>
        <trans-unit id="8e34d865883b535f68990f01a240eaab9f87f080" translate="yes" xml:space="preserve">
          <source>This class is hence suitable for use in the early steps of a &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">Por lo tanto, esta clase es adecuada para su uso en los primeros pasos de un &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="eef0760dd6d25fd731b9abce61656453bb690cee" translate="yes" xml:space="preserve">
          <source>This class is useful when the behavior of &lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt;&lt;code&gt;LeavePGroupsOut&lt;/code&gt;&lt;/a&gt; is desired, but the number of groups is large enough that generating all possible partitions with \(P\) groups withheld would be prohibitively expensive. In such a scenario, &lt;a href=&quot;generated/sklearn.model_selection.groupshufflesplit#sklearn.model_selection.GroupShuffleSplit&quot;&gt;&lt;code&gt;GroupShuffleSplit&lt;/code&gt;&lt;/a&gt; provides a random sample (with replacement) of the train / test splits generated by &lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt;&lt;code&gt;LeavePGroupsOut&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Esta clase es &amp;uacute;til cuando se desea el comportamiento de &lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt; &lt;code&gt;LeavePGroupsOut&lt;/code&gt; &lt;/a&gt; , pero el n&amp;uacute;mero de grupos es lo suficientemente grande como para generar todas las particiones posibles con grupos \ (P \) retenidos ser&amp;iacute;a prohibitivamente costoso. En tal escenario, &lt;a href=&quot;generated/sklearn.model_selection.groupshufflesplit#sklearn.model_selection.GroupShuffleSplit&quot;&gt; &lt;code&gt;GroupShuffleSplit&lt;/code&gt; &lt;/a&gt; proporciona una muestra aleatoria (con reemplazo) de las divisiones de tren / prueba generadas por &lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt; &lt;code&gt;LeavePGroupsOut&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="9d924f7a026f05763f1c88ce464db057fdea146c" translate="yes" xml:space="preserve">
          <source>This class provides a uniform interface to fast distance metric functions. The various metrics can be accessed via the &lt;a href=&quot;#sklearn.neighbors.DistanceMetric.get_metric&quot;&gt;&lt;code&gt;get_metric&lt;/code&gt;&lt;/a&gt; class method and the metric string identifier (see below).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="edf4c29bfa2afe43016dc0b6660ad50132bd51ec" translate="yes" xml:space="preserve">
          <source>This class provides a uniform interface to fast distance metric functions. The various metrics can be accessed via the &lt;code&gt;get_metric&lt;/code&gt; class method and the metric string identifier (see below). For example, to use the Euclidean distance:</source>
          <target state="translated">Esta clase proporciona una interfaz uniforme para funciones m&amp;eacute;tricas de distancia r&amp;aacute;pida. Se puede acceder a las diversas m&amp;eacute;tricas a trav&amp;eacute;s del m&amp;eacute;todo de clase &lt;code&gt;get_metric&lt;/code&gt; y el identificador de cadena de m&amp;eacute;tricas (ver m&amp;aacute;s abajo). Por ejemplo, para usar la distancia euclidiana:</target>
        </trans-unit>
        <trans-unit id="336f533fd7cf96bc18f597ff7211d31f0cd62386" translate="yes" xml:space="preserve">
          <source>This class supports both dense and sparse input and the multiclass support is handled according to a one-vs-the-rest scheme.</source>
          <target state="translated">Esta clase soporta tanto la entrada densa como la dispersa y el soporte multiclase se maneja según un esquema de uno contra uno.</target>
        </trans-unit>
        <trans-unit id="aebcf6792861578bf4b4a69a0be71898d4023b6a" translate="yes" xml:space="preserve">
          <source>This class supports both dense and sparse input.</source>
          <target state="translated">Esta clase soporta tanto la entrada densa como la escasa.</target>
        </trans-unit>
        <trans-unit id="4042c6697e9df3310aa51f4f2bbe289c3d222c6e" translate="yes" xml:space="preserve">
          <source>This class turns sequences of symbolic feature names (strings) into scipy.sparse matrices, using a hash function to compute the matrix column corresponding to a name. The hash function employed is the signed 32-bit version of Murmurhash3.</source>
          <target state="translated">Esta clase convierte secuencias de nombres de rasgos simbólicos (cuerdas)en matrices scipy.sparse,utilizando una función hash para calcular la columna de la matriz correspondiente a un nombre.La función hash empleada es la versión firmada de 32 bits de Murmurhash3.</target>
        </trans-unit>
        <trans-unit id="afb2ca6e635ea8a6abf9d5cec38428c8ecdc147c" translate="yes" xml:space="preserve">
          <source>This classification dataset is constructed by taking a multi-dimensional standard normal distribution and defining classes separated by nested concentric multi-dimensional spheres such that roughly equal numbers of samples are in each class (quantiles of the \(\chi^2\) distribution).</source>
          <target state="translated">Este conjunto de datos de clasificación se construye tomando una distribución normal estándar multidimensional y definiendo clases separadas por esferas multidimensionales concéntricas anidadas,de tal manera que en cada clase hay un número aproximadamente igual de muestras (cuantiles de la distribución \(\chi^2\)).</target>
        </trans-unit>
        <trans-unit id="db081d4f3b8473550c6831dd235016867584f8ea" translate="yes" xml:space="preserve">
          <source>This classifier first converts the target values into &lt;code&gt;{-1, 1}&lt;/code&gt; and then treats the problem as a regression task (multi-output regression in the multiclass case).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c043eb0cb49ef78462962da4adb4099e130c09c" translate="yes" xml:space="preserve">
          <source>This classifier is sometimes referred to as a &lt;a href=&quot;https://en.wikipedia.org/wiki/Least-squares_support-vector_machine&quot;&gt;Least Squares Support Vector Machines&lt;/a&gt; with a linear kernel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a35e593acabc67ebdf8fae8d0484d5f85056d4a7" translate="yes" xml:space="preserve">
          <source>This classifier is useful as a simple baseline to compare with other (real) classifiers. Do not use it for real problems.</source>
          <target state="translated">Este clasificador es útil como una simple línea de base para comparar con otros clasificadores (reales).No lo use para problemas reales.</target>
        </trans-unit>
        <trans-unit id="4ceac36d1efc9bb429dd84350330a84101bb5c8c" translate="yes" xml:space="preserve">
          <source>This classifier lost over a lot of its F-score, just because we removed metadata that has little to do with topic classification. It loses even more if we also strip this metadata from the training data:</source>
          <target state="translated">Este clasificador perdió gran parte de su puntuación F,sólo porque eliminamos metadatos que tienen poco que ver con la clasificación de los temas.Pierde aún más si también quitamos estos metadatos de los datos de formación:</target>
        </trans-unit>
        <trans-unit id="064e5da463cfecd3ca166c4023a79d0a6500160d" translate="yes" xml:space="preserve">
          <source>This combination is implementing in &lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt;&lt;code&gt;HashingVectorizer&lt;/code&gt;&lt;/a&gt;, a transformer class that is mostly API compatible with &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;. &lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt;&lt;code&gt;HashingVectorizer&lt;/code&gt;&lt;/a&gt; is stateless, meaning that you don&amp;rsquo;t have to call &lt;code&gt;fit&lt;/code&gt; on it:</source>
          <target state="translated">Esta combinaci&amp;oacute;n se implementa en &lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt; &lt;code&gt;HashingVectorizer&lt;/code&gt; &lt;/a&gt; , una clase de transformador que es principalmente compatible con API con &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; . &lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt; &lt;code&gt;HashingVectorizer&lt;/code&gt; no&lt;/a&gt; tiene estado, lo que significa que no tiene que llamar a &lt;code&gt;fit&lt;/code&gt; en &amp;eacute;l:</target>
        </trans-unit>
        <trans-unit id="1d56591f4aa7f0ebb864c2d8835af7dfb7f8f26b" translate="yes" xml:space="preserve">
          <source>This combines the values of agglomerated features into a single value, and should accept an array of shape [M, N] and the keyword argument &lt;code&gt;axis=1&lt;/code&gt;, and reduce it to an array of size [M].</source>
          <target state="translated">Esto combina los valores de las caracter&amp;iacute;sticas aglomeradas en un solo valor y debe aceptar una matriz de forma [M, N] y el argumento de palabra clave &lt;code&gt;axis=1&lt;/code&gt; , y reducirlo a una matriz de tama&amp;ntilde;o [M].</target>
        </trans-unit>
        <trans-unit id="26c788fe31e79bd1bbf24fbba8a1b8342ff15ce1" translate="yes" xml:space="preserve">
          <source>This consumes less memory than shuffling the data directly.</source>
          <target state="translated">Esto consume menos memoria que barajar los datos directamente.</target>
        </trans-unit>
        <trans-unit id="9c8cf431c4f1299ae41612f84a50a597aa4a1059" translate="yes" xml:space="preserve">
          <source>This creates binary hashes of input data points by getting the dot product of input points and hash_function then transforming the projection into a binary string array based on the sign (positive/negative) of the projection. A sorted array of binary hashes is created.</source>
          <target state="translated">Esto crea hashes binarios de puntos de datos de entrada obteniendo el producto puntual de los puntos de entrada y la función hash_función y luego transformando la proyección en una matriz de cadenas binarias basada en el signo (positivo/negativo)de la proyección.Se crea una matriz ordenada de hashes binarios.</target>
        </trans-unit>
        <trans-unit id="75f340063df2a6996986c297d7d4423dc4417e05" translate="yes" xml:space="preserve">
          <source>This cross-validation object is a merge of StratifiedKFold and ShuffleSplit, which returns stratified randomized folds. The folds are made by preserving the percentage of samples for each class.</source>
          <target state="translated">Este objeto de validación cruzada es una fusión de StratifiedKFold y ShuffleSplit,que devuelve pliegues aleatorios estratificados.Los pliegues se hacen preservando el porcentaje de muestras de cada clase.</target>
        </trans-unit>
        <trans-unit id="ab90d891a9b7f61040a0bd2fc78eae2488d53a3a" translate="yes" xml:space="preserve">
          <source>This cross-validation object is a variation of &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt;. In the kth split, it returns first k folds as train set and the (k+1)th fold as test set.</source>
          <target state="translated">Este objeto de validaci&amp;oacute;n cruzada es una variaci&amp;oacute;n de &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt; . En la divisi&amp;oacute;n k, devuelve los primeros k pliegues como conjunto de tren y el (k + 1) pliegue como conjunto de prueba.</target>
        </trans-unit>
        <trans-unit id="c3d6a6171342c06e134b7087a7e83e3f80ba8a79" translate="yes" xml:space="preserve">
          <source>This cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for each class.</source>
          <target state="translated">Este objeto de validación cruzada es una variación de KFold que devuelve pliegues estratificados.Los pliegues se hacen preservando el porcentaje de muestras de cada clase.</target>
        </trans-unit>
        <trans-unit id="2c34ca372157ddad0d3d18ffb66a8717775276f6" translate="yes" xml:space="preserve">
          <source>This data sets consists of 3 different types of irises&amp;rsquo; (Setosa, Versicolour, and Virginica) petal and sepal length, stored in a 150x4 numpy.ndarray</source>
          <target state="translated">Este conjunto de datos consta de 3 tipos diferentes de iris (Setosa, Versicolour y Virginica) de longitud de p&amp;eacute;talos y s&amp;eacute;palos, almacenados en un numpy.ndarray de 150x4.</target>
        </trans-unit>
        <trans-unit id="158d23b76a72fb850a277110200a4b319b51d7f5" translate="yes" xml:space="preserve">
          <source>This database is also available through the UW CS ftp server:</source>
          <target state="translated">Esta base de datos también está disponible a través del servidor ftp UW CS:</target>
        </trans-unit>
        <trans-unit id="8f0ed5f875aa21e65ca9d6116dc0e918ff34c0ff" translate="yes" xml:space="preserve">
          <source>This dataset consists of 20,640 samples and 9 features.</source>
          <target state="translated">Este conjunto de datos consta de 20.640 muestras y 9 características.</target>
        </trans-unit>
        <trans-unit id="2e15d3adbea56bdf31e76cb4ee55fcf6dfb7c05f" translate="yes" xml:space="preserve">
          <source>This dataset is a collection of JPEG pictures of famous people collected over the internet, all details are available on the official website:</source>
          <target state="translated">Este conjunto de datos es una colección de fotos JPEG de personajes famosos recogidas en Internet,todos los detalles están disponibles en la página web oficial:</target>
        </trans-unit>
        <trans-unit id="1c0b9129c637e05601004735cb7bfdbdba431796" translate="yes" xml:space="preserve">
          <source>This dataset is described in Celeux et al [1]. as:</source>
          <target state="translated">Este conjunto de datos se describe en Celeux et al [1].como:</target>
        </trans-unit>
        <trans-unit id="e92704f97c6e77c413a0405e7cf7dd2e32191660" translate="yes" xml:space="preserve">
          <source>This dataset is described in Friedman [1] and Breiman [2].</source>
          <target state="translated">Este conjunto de datos se describe en Friedman [1]y Breiman [2].</target>
        </trans-unit>
        <trans-unit id="473d3b557a1c23b381f633c2c2acf0c38c2a328f" translate="yes" xml:space="preserve">
          <source>This dataset is made up of 1797 8x8 images. Each image, like the one shown below, is of a hand-written digit. In order to utilize an 8x8 figure like this, we&amp;rsquo;d have to first transform it into a feature vector with length 64.</source>
          <target state="translated">Este conjunto de datos se compone de 1797 im&amp;aacute;genes de 8x8. Cada imagen, como la que se muestra a continuaci&amp;oacute;n, es de un d&amp;iacute;gito escrito a mano. Para utilizar una figura de 8x8 como esta, primero tendr&amp;iacute;amos que transformarla en un vector de caracter&amp;iacute;sticas con una longitud de 64.</target>
        </trans-unit>
        <trans-unit id="39a3f4ca0d0c444ed57d3ff159dafbaf0cf5d2c9" translate="yes" xml:space="preserve">
          <source>This dataset is suitable for multi-ouput regression tasks.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73cdbbbbdb25af126933f658f4b065e86b9c1a55" translate="yes" xml:space="preserve">
          <source>This dataset represents the geographic distribution of species. The dataset is provided by Phillips et. al. (2006).</source>
          <target state="translated">Este conjunto de datos representa la distribución geográfica de las especies.El conjunto de datos es proporcionado por Phillips et.al.(2006).</target>
        </trans-unit>
        <trans-unit id="e72397d5f7691c5c60df49442bb007cee4717786" translate="yes" xml:space="preserve">
          <source>This dataset was derived from the 1990 U.S. census, using one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people).</source>
          <target state="translated">Este conjunto de datos se derivó del censo de los EE.UU.de 1990,utilizando una fila por grupo de bloques censales.Un grupo de bloques es la unidad geográfica más pequeña para la que la Oficina del Censo de los Estados Unidos publica datos de muestra (un grupo de bloques suele tener una población de 600 a 3.000 personas).</target>
        </trans-unit>
        <trans-unit id="47bf559cf1abc9fb33a96a120f583ad0bcd0f9f8" translate="yes" xml:space="preserve">
          <source>This dataset was obtained from the StatLib repository. &lt;a href=&quot;http://lib.stat.cmu.edu/datasets/&quot;&gt;http://lib.stat.cmu.edu/datasets/&lt;/a&gt;</source>
          <target state="translated">Este conjunto de datos se obtuvo del repositorio StatLib. &lt;a href=&quot;http://lib.stat.cmu.edu/datasets/&quot;&gt;http://lib.stat.cmu.edu/datasets/&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="4668c093fae272aec3196fc6d39e4e5a4eede980" translate="yes" xml:space="preserve">
          <source>This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.</source>
          <target state="translated">Este conjunto de datos fue tomado de la biblioteca StatLib que se mantiene en la Universidad Carnegie Mellon.</target>
        </trans-unit>
        <trans-unit id="9b1b90be23e0adb200134bcc2570822a79ae6e88" translate="yes" xml:space="preserve">
          <source>This demonstrates Label Propagation learning a good boundary even with a small amount of labeled data.</source>
          <target state="translated">Esto demuestra que la Propagación de Etiquetas aprende un buen límite incluso con una pequeña cantidad de datos etiquetados.</target>
        </trans-unit>
        <trans-unit id="33d36bf521beb70b7b2f4b7e5d24d58f96f46c86" translate="yes" xml:space="preserve">
          <source>This description can be vectorized into a sparse two-dimensional matrix suitable for feeding into a classifier (maybe after being piped into a &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt;&lt;code&gt;text.TfidfTransformer&lt;/code&gt;&lt;/a&gt; for normalization):</source>
          <target state="translated">Esta descripci&amp;oacute;n se puede vectorizar en una matriz bidimensional dispersa adecuada para alimentar a un clasificador (tal vez despu&amp;eacute;s de ser canalizada en un &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt; &lt;code&gt;text.TfidfTransformer&lt;/code&gt; &lt;/a&gt; para normalizaci&amp;oacute;n):</target>
        </trans-unit>
        <trans-unit id="12f7e332bc936dbb460a17349dda07780cab7782" translate="yes" xml:space="preserve">
          <source>This determines which warnings will be made in the case that this function is being used to return only one of its metrics.</source>
          <target state="translated">Esto determina qué advertencias se harán en caso de que esta función se utilice para devolver sólo una de sus métricas.</target>
        </trans-unit>
        <trans-unit id="a1a66d0ad9255f63c11b93170b95da4e6eeaea4f" translate="yes" xml:space="preserve">
          <source>This downscaling is called &lt;a href=&quot;https://en.wikipedia.org/wiki/Tf-idf&quot;&gt;tf&amp;ndash;idf&lt;/a&gt; for &amp;ldquo;Term Frequency times Inverse Document Frequency&amp;rdquo;.</source>
          <target state="translated">Esta reducci&amp;oacute;n de escala se denomina &lt;a href=&quot;https://en.wikipedia.org/wiki/Tf-idf&quot;&gt;tf-idf&lt;/a&gt; para &quot;Frecuencia de t&amp;eacute;rminos multiplicada por frecuencia de documento inversa&quot;.</target>
        </trans-unit>
        <trans-unit id="edeebc499fdf886cf2b1fe82f9cc25a148384f70" translate="yes" xml:space="preserve">
          <source>This early stopping strategy is activated if &lt;code&gt;early_stopping=True&lt;/code&gt;; otherwise the stopping criterion only uses the training loss on the entire input data. To better control the early stopping strategy, we can specify a parameter &lt;code&gt;validation_fraction&lt;/code&gt; which set the fraction of the input dataset that we keep aside to compute the validation score. The optimization will continue until the validation score did not improve by at least &lt;code&gt;tol&lt;/code&gt; during the last &lt;code&gt;n_iter_no_change&lt;/code&gt; iterations. The actual number of iterations is available at the attribute &lt;code&gt;n_iter_&lt;/code&gt;.</source>
          <target state="translated">Esta estrategia de parada anticipada se activa si &lt;code&gt;early_stopping=True&lt;/code&gt; ; de lo contrario, el criterio de detenci&amp;oacute;n solo utiliza la p&amp;eacute;rdida de entrenamiento en todos los datos de entrada. Para controlar mejor la estrategia de detenci&amp;oacute;n temprana, podemos especificar un par&amp;aacute;metro &lt;code&gt;validation_fraction&lt;/code&gt; que establece la fracci&amp;oacute;n del conjunto de datos de entrada que mantenemos a un lado para calcular la puntuaci&amp;oacute;n de validaci&amp;oacute;n. La optimizaci&amp;oacute;n continuar&amp;aacute; hasta que la puntuaci&amp;oacute;n de validaci&amp;oacute;n no mejore en al menos &lt;code&gt;tol&lt;/code&gt; durante las &amp;uacute;ltimas &lt;code&gt;n_iter_no_change&lt;/code&gt; iteraciones. El n&amp;uacute;mero real de iteraciones est&amp;aacute; disponible en el atributo &lt;code&gt;n_iter_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6528dcf2523991bd357ca56474b42d537ada09b8" translate="yes" xml:space="preserve">
          <source>This embedding can also &amp;lsquo;work&amp;rsquo; even if the &lt;code&gt;adjacency&lt;/code&gt; variable is not strictly the adjacency matrix of a graph but more generally an affinity or similarity matrix between samples (for instance the heat kernel of a euclidean distance matrix or a k-NN matrix).</source>
          <target state="translated">Esta incrustaci&amp;oacute;n tambi&amp;eacute;n puede 'funcionar' incluso si la variable de &lt;code&gt;adjacency&lt;/code&gt; no es estrictamente la matriz de adyacencia de un gr&amp;aacute;fico, sino m&amp;aacute;s generalmente una matriz de afinidad o similitud entre muestras (por ejemplo, el n&amp;uacute;cleo de calor de una matriz de distancia euclidiana o una matriz k-NN).</target>
        </trans-unit>
        <trans-unit id="ac8e43e8e0acd749c6d9f51af67c9e65cc70e9b4" translate="yes" xml:space="preserve">
          <source>This enables ducktyping by hasattr returning True according to the sub-estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="662188aeeffeee289aab2f0d97150266d90c022d" translate="yes" xml:space="preserve">
          <source>This encoding is needed for feeding categorical data to many scikit-learn estimators, notably linear models and SVMs with the standard kernels.</source>
          <target state="translated">Esta codificación es necesaria para alimentar con datos categóricos a muchos estimadores de aprendizaje científico,especialmente modelos lineales y SVM con los núcleos estándar.</target>
        </trans-unit>
        <trans-unit id="752036d9bd5ae374e975c046f504e0b38de39538" translate="yes" xml:space="preserve">
          <source>This estimator</source>
          <target state="translated">Este estimador</target>
        </trans-unit>
        <trans-unit id="f8a8301fe86e970315ab1f664d0852d178958868" translate="yes" xml:space="preserve">
          <source>This estimator allows different columns or column subsets of the input to be transformed separately and the features generated by each transformer will be concatenated to form a single feature space. This is useful for heterogeneous or columnar data, to combine several feature extraction mechanisms or transformations into a single transformer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36ceeb9f387752a577aeb048b3f21cd319ecfb48" translate="yes" xml:space="preserve">
          <source>This estimator allows different columns or column subsets of the input to be transformed separately and the results combined into a single feature space. This is useful for heterogeneous or columnar data, to combine several feature extraction mechanisms or transformations into a single transformer.</source>
          <target state="translated">Este estimador permite transformar por separado diferentes columnas o subconjuntos de columnas de la entrada y combinar los resultados en un único espacio de características.Esto es útil para datos heterogéneos o columnares,para combinar varios mecanismos de extracción de características o transformaciones en un solo transformador.</target>
        </trans-unit>
        <trans-unit id="02199e2b9b2bd941c7464261eedf68a6fd2d82e2" translate="yes" xml:space="preserve">
          <source>This estimator applies a list of transformer objects in parallel to the input data, then concatenates the results. This is useful to combine several feature extraction mechanisms into a single transformer.</source>
          <target state="translated">Este estimador aplica una lista de objetos transformadores en paralelo a los datos de entrada,y luego concatena los resultados.Esto es útil para combinar varios mecanismos de extracción de características en un solo transformador.</target>
        </trans-unit>
        <trans-unit id="a93ab3d6ae360c030a56bd4fabca46c42abdaf54" translate="yes" xml:space="preserve">
          <source>This estimator approximates a slightly different version of the additive chi squared kernel then &lt;code&gt;metric.additive_chi2&lt;/code&gt; computes.</source>
          <target state="translated">Este estimador se aproxima a una versi&amp;oacute;n ligeramente diferente del n&amp;uacute;cleo de chi cuadrado aditivo, luego &lt;code&gt;metric.additive_chi2&lt;/code&gt; calcula.</target>
        </trans-unit>
        <trans-unit id="53ea424698dba4ed1ec741d2d0ce2fbd09225a41" translate="yes" xml:space="preserve">
          <source>This estimator can be used to model different GLMs depending on the &lt;code&gt;power&lt;/code&gt; parameter, which determines the underlying distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57f1dab8dd3e838e06f9128461ff865667eb2891" translate="yes" xml:space="preserve">
          <source>This estimator has built-in support for multi-variate regression (i.e., when y is a 2d-array of shape [n_samples, n_targets]).</source>
          <target state="translated">Este estimador tiene incorporado el soporte para la regresión multivariante (es decir,cuando y es un conjunto de dos formas [n_muestras,n_objetivos]).</target>
        </trans-unit>
        <trans-unit id="534f21211e3056d3896d05b949c661c4f992dd5f" translate="yes" xml:space="preserve">
          <source>This estimator has native support for missing values (NaNs). During training, the tree grower learns at each split point whether samples with missing values should go to the left or right child, based on the potential gain. When predicting, samples with missing values are assigned to the left or right child consequently. If no missing values were encountered for a given feature during training, then samples with missing values are mapped to whichever child has the most samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7130a824407818977c24f15960ee70da6f59d9ca" translate="yes" xml:space="preserve">
          <source>This estimator implements regularized linear models with stochastic gradient descent (SGD) learning: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate). SGD allows minibatch (online/out-of-core) learning via the &lt;code&gt;partial_fit&lt;/code&gt; method. For best results using the default learning rate schedule, the data should have zero mean and unit variance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab45bcef3fd31ebffe9c4724334c2d64921dae44" translate="yes" xml:space="preserve">
          <source>This estimator implements regularized linear models with stochastic gradient descent (SGD) learning: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate). SGD allows minibatch (online/out-of-core) learning, see the partial_fit method. For best results using the default learning rate schedule, the data should have zero mean and unit variance.</source>
          <target state="translated">Este estimador implementa modelos lineales regularizados con aprendizaje de gradiente de descenso estocástico (SGD):el gradiente de la pérdida se estima en cada muestra a la vez y el modelo se actualiza a lo largo del camino con un programa de fuerza decreciente (también conocido como tasa de aprendizaje).El SGD permite el aprendizaje minibatch (en línea/fuera del núcleo),ver el método partial_fit.Para obtener los mejores resultados utilizando el esquema de tasa de aprendizaje predeterminado,los datos deben tener una media cero y una varianza unitaria.</target>
        </trans-unit>
        <trans-unit id="7005478518d9bca348fcae966cb157ede91131ca" translate="yes" xml:space="preserve">
          <source>This estimator is much faster than &lt;a href=&quot;sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; for big datasets (n_samples &amp;gt;= 10 000).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="505ce7903463cb2537c439b476cf7830c59f9934" translate="yes" xml:space="preserve">
          <source>This estimator is much faster than &lt;a href=&quot;sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; for big datasets (n_samples &amp;gt;= 10 000).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fdb17bfdb14f498d9377f8ca9b7cc2199a41d7f" translate="yes" xml:space="preserve">
          <source>This estimator is stateless (besides constructor parameters), the fit method does nothing but is useful when used in a pipeline.</source>
          <target state="translated">Este estimador es apátrida (además de los parámetros de construcción),el método de ajuste no hace nada pero es útil cuando se utiliza en una tubería.</target>
        </trans-unit>
        <trans-unit id="b10e025b81eb3a8b5b21ad615292ad7338f1e2a3" translate="yes" xml:space="preserve">
          <source>This estimator is still &lt;strong&gt;experimental&lt;/strong&gt; for now: default parameters or details of behaviour might change without any deprecation cycle. Resolving the following issues would help stabilize &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt;: convergence criteria (&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/14338&quot;&gt;#14338&lt;/a&gt;), default estimators (&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/13286&quot;&gt;#13286&lt;/a&gt;), and use of random state (&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/15611&quot;&gt;#15611&lt;/a&gt;). To use it, you need to explicitly import &lt;code&gt;enable_iterative_imputer&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ba8a49b5a7145a75b81ed477df1577dc2f0d079" translate="yes" xml:space="preserve">
          <source>This estimator is still &lt;strong&gt;experimental&lt;/strong&gt; for now: the predictions and the API might change without any deprecation cycle. To use it, you need to explicitly import &lt;code&gt;enable_hist_gradient_boosting&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c7878b26bf7f32e88e4f83c2d2d772f7f3023cd" translate="yes" xml:space="preserve">
          <source>This estimator is still &lt;strong&gt;experimental&lt;/strong&gt; for now: the predictions and the API might change without any deprecation cycle. To use it, you need to explicitly import &lt;code&gt;enable_iterative_imputer&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8c9fb1adc7eae2561c12b442ef315ae822391e8" translate="yes" xml:space="preserve">
          <source>This estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42d08f109b32ce107e9f058e7449521b0b6eab28" translate="yes" xml:space="preserve">
          <source>This estimator scales and translates each feature individually such that it is in the given range on the training set, i.e. between zero and one.</source>
          <target state="translated">Este estimador escala y traduce cada característica individualmente de tal manera que está en el rango dado en el conjunto de entrenamiento,es decir,entre cero y uno.</target>
        </trans-unit>
        <trans-unit id="ce7850baf5a7a3e7ef75716db2d2e4af71c92137" translate="yes" xml:space="preserve">
          <source>This estimator scales and translates each feature individually such that the maximal absolute value of each feature in the training set will be 1.0. It does not shift/center the data, and thus does not destroy any sparsity.</source>
          <target state="translated">Este estimador escala y traduce cada característica individualmente de tal manera que el valor absoluto máximo de cada característica en el conjunto de entrenamiento será 1.0.No cambia/centro los datos,y por lo tanto no destruye ninguna escasez.</target>
        </trans-unit>
        <trans-unit id="0ff92b3f8e56701f386ccbc5279ec5fdb2974bc0" translate="yes" xml:space="preserve">
          <source>This estimator scales each feature individually such that the maximal absolute value of each feature in the training set will be 1.0.</source>
          <target state="translated">Este estimador escala cada característica individualmente de tal manera que el valor absoluto máximo de cada característica en el conjunto de entrenamiento será 1.0.</target>
        </trans-unit>
        <trans-unit id="354214ed410106228bbb593cd82a49f32a2508f8" translate="yes" xml:space="preserve">
          <source>This estimator supports two algorithms: a fast randomized SVD solver, and a &amp;ldquo;naive&amp;rdquo; algorithm that uses ARPACK as an eigensolver on (X * X.T) or (X.T * X), whichever is more efficient.</source>
          <target state="translated">Este estimador admite dos algoritmos: un solucionador de SVD aleatorio r&amp;aacute;pido y un algoritmo &amp;ldquo;ingenuo&amp;rdquo; que usa ARPACK como un solucionador propio en (X * XT) o (XT * X), ​​el que sea m&amp;aacute;s eficiente.</target>
        </trans-unit>
        <trans-unit id="0a991e8d6eff0a5b7f5a276b54be6da66c4dae45" translate="yes" xml:space="preserve">
          <source>This estimator supports two algorithms: a fast randomized SVD solver, and a &amp;ldquo;naive&amp;rdquo; algorithm that uses ARPACK as an eigensolver on &lt;code&gt;X * X.T&lt;/code&gt; or &lt;code&gt;X.T * X&lt;/code&gt;, whichever is more efficient.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="438c738ad18e280c91d7884cd24490873bfed375" translate="yes" xml:space="preserve">
          <source>This estimator will run an extensive test-suite for input validation, shapes, etc, making sure that the estimator complies with &lt;code&gt;scikit-learn&lt;/code&gt; conventions as detailed in &lt;a href=&quot;https://scikit-learn.org/0.23/developers/develop.html#rolling-your-own-estimator&quot;&gt;Rolling your own estimator&lt;/a&gt;. Additional tests for classifiers, regressors, clustering or transformers will be run if the Estimator class inherits from the corresponding mixin from sklearn.base.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ed5861f671a7b7a1c102cd9c37c8bf2e273de13" translate="yes" xml:space="preserve">
          <source>This estimator will run an extensive test-suite for input validation, shapes, etc. Additional tests for classifiers, regressors, clustering or transformers will be run if the Estimator class inherits from the corresponding mixin from sklearn.base.</source>
          <target state="translated">Este estimador ejecutará un extenso conjunto de pruebas para la validación de entradas,formas,etc.Se realizarán pruebas adicionales para clasificadores,regresores,agrupaciones o transformadores si la clase del Estimador hereda de la correspondiente mezcla de sklearn.base.</target>
        </trans-unit>
        <trans-unit id="7011f5e2b484f266188acd0aba4f3d3175f11ed0" translate="yes" xml:space="preserve">
          <source>This example also shows the usefulness of applying Ridge regression to highly ill-conditioned matrices. For such matrices, a slight change in the target variable can cause huge variances in the calculated weights. In such cases, it is useful to set a certain regularization (alpha) to reduce this variation (noise).</source>
          <target state="translated">Este ejemplo también muestra la utilidad de aplicar la regresión de Ridge a matrices muy mal acondicionadas.Para tales matrices,un ligero cambio en la variable objetivo puede causar enormes variaciones en los pesos calculados.En tales casos,es útil establecer una cierta regularización (alfa)para reducir esta variación (ruido).</target>
        </trans-unit>
        <trans-unit id="66087b50dbc537ea3a892d00ee467bc12eeadd33" translate="yes" xml:space="preserve">
          <source>This example applies to &lt;a href=&quot;../../datasets/index#olivetti-faces-dataset&quot;&gt;The Olivetti faces dataset&lt;/a&gt; different unsupervised matrix decomposition (dimension reduction) methods from the module &lt;a href=&quot;../../modules/classes#module-sklearn.decomposition&quot;&gt;&lt;code&gt;sklearn.decomposition&lt;/code&gt;&lt;/a&gt; (see the documentation chapter &lt;a href=&quot;../../modules/decomposition#decompositions&quot;&gt;Decomposing signals in components (matrix factorization problems)&lt;/a&gt;) .</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f82721c4674480adff4241dbcac8e543f16c868" translate="yes" xml:space="preserve">
          <source>This example applies to olivetti_faces different unsupervised matrix decomposition (dimension reduction) methods from the module &lt;a href=&quot;../../modules/classes#module-sklearn.decomposition&quot;&gt;&lt;code&gt;sklearn.decomposition&lt;/code&gt;&lt;/a&gt; (see the documentation chapter &lt;a href=&quot;../../modules/decomposition#decompositions&quot;&gt;Decomposing signals in components (matrix factorization problems)&lt;/a&gt;) .</source>
          <target state="translated">Este ejemplo se aplica a olivetti_faces diferentes m&amp;eacute;todos de descomposici&amp;oacute;n matricial no supervisada (reducci&amp;oacute;n de dimensi&amp;oacute;n) del m&amp;oacute;dulo &lt;a href=&quot;../../modules/classes#module-sklearn.decomposition&quot;&gt; &lt;code&gt;sklearn.decomposition&lt;/code&gt; &lt;/a&gt; (consulte el cap&amp;iacute;tulo de documentaci&amp;oacute;n &lt;a href=&quot;../../modules/decomposition#decompositions&quot;&gt;Descomposici&amp;oacute;n de se&amp;ntilde;ales en componentes (problemas de factorizaci&amp;oacute;n matricial)&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="209229078f7e258d4985eec4947d8dca83616df9" translate="yes" xml:space="preserve">
          <source>This example balances model complexity and cross-validated score by finding a decent accuracy within 1 standard deviation of the best accuracy score while minimising the number of PCA components [1].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="33924f5409489cd3edd1b22f28ee011b17a585da" translate="yes" xml:space="preserve">
          <source>This example compares 2 dimensionality reduction strategies:</source>
          <target state="translated">En este ejemplo se comparan dos estrategias de reducción de la dimensionalidad:</target>
        </trans-unit>
        <trans-unit id="d2a9de2244899372ce613f7320d0c8868284b849" translate="yes" xml:space="preserve">
          <source>This example compares different (linear) dimensionality reduction methods applied on the Digits data set. The data set contains images of digits from 0 to 9 with approximately 180 samples of each class. Each image is of dimension 8x8 = 64, and is reduced to a two-dimensional data point.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ba8c26b14d0dc5555ed6b18d75cbed15c385668" translate="yes" xml:space="preserve">
          <source>This example compares non-nested and nested cross-validation strategies on a classifier of the iris data set. Nested cross-validation (CV) is often used to train a model in which hyperparameters also need to be optimized. Nested CV estimates the generalization error of the underlying model and its (hyper)parameter search. Choosing the parameters that maximize non-nested CV biases the model to the dataset, yielding an overly-optimistic score.</source>
          <target state="translated">En este ejemplo se comparan las estrategias de validación cruzada no anidadas y anidadas en un clasificador del conjunto de datos del iris.La validación cruzada anidada (CV)se utiliza a menudo para entrenar un modelo en el que también hay que optimizar los hiperparámetros.La CV anidada estima el error de generalización del modelo subyacente y su búsqueda de (hiper)parámetros.La elección de los parámetros que maximizan la CV no anidada predispone el modelo al conjunto de datos,lo que produce una puntuación demasiado optimista.</target>
        </trans-unit>
        <trans-unit id="7ef1cb506f6769f9ea8f57cc850c6090d62898eb" translate="yes" xml:space="preserve">
          <source>This example compares the timing of Birch (with and without the global clustering step) and MiniBatchKMeans on a synthetic dataset having 100,000 samples and 2 features generated using make_blobs.</source>
          <target state="translated">Este ejemplo compara el tiempo de Birch (con y sin el paso de agrupación global)y MiniBatchKMeans en un conjunto de datos sintéticos que tiene 100.000 muestras y 2 características generadas usando make_blobs.</target>
        </trans-unit>
        <trans-unit id="8901e1f5225dc1b7e06d2fabb8f06f19a3753c45" translate="yes" xml:space="preserve">
          <source>This example constructs a pipeline that does dimensionality reduction followed by prediction with a support vector classifier. It demonstrates the use of &lt;code&gt;GridSearchCV&lt;/code&gt; and &lt;code&gt;Pipeline&lt;/code&gt; to optimize over different classes of estimators in a single CV run &amp;ndash; unsupervised &lt;code&gt;PCA&lt;/code&gt; and &lt;code&gt;NMF&lt;/code&gt; dimensionality reductions are compared to univariate feature selection during the grid search.</source>
          <target state="translated">Este ejemplo construye una canalizaci&amp;oacute;n que realiza una reducci&amp;oacute;n de dimensionalidad seguida de una predicci&amp;oacute;n con un clasificador de vectores de soporte. Demuestra el uso de &lt;code&gt;GridSearchCV&lt;/code&gt; y &lt;code&gt;Pipeline&lt;/code&gt; para optimizar diferentes clases de estimadores en una sola ejecuci&amp;oacute;n de CV: las reducciones de dimensionalidad de &lt;code&gt;PCA&lt;/code&gt; y &lt;code&gt;NMF&lt;/code&gt; no supervisadas se comparan con la selecci&amp;oacute;n de caracter&amp;iacute;sticas univariadas durante la b&amp;uacute;squeda de la cuadr&amp;iacute;cula.</target>
        </trans-unit>
        <trans-unit id="ebd831df4448cf766c6eb0e33a12d358fbfa3057" translate="yes" xml:space="preserve">
          <source>This example demonstrates Gradient Boosting to produce a predictive model from an ensemble of weak predictive models. Gradient boosting can be used for regression and classification problems. Here, we will train a model to tackle a diabetes regression task. We will obtain the results from &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; with least squares loss and 500 regression trees of depth 4.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b084d11db0bc218128b35a7afe55ac9fa7c4daf1" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to approximate a function with a polynomial of degree n_degree by using ridge regression. Concretely, from n_samples 1d points, it suffices to build the Vandermonde matrix, which is n_samples x n_degree+1 and has the following form:</source>
          <target state="translated">Este ejemplo demuestra cómo aproximar una función con un polinomio de grado n_grado utilizando la regresión de cresta.Concretamente,a partir de n_muestras 1d puntos,basta con construir la matriz de Vandermonde,que es n_muestras x n_grado+1 y tiene la siguiente forma:</target>
        </trans-unit>
        <trans-unit id="8509d7895b98e9b3d2d07ed03eae90baa68f1c72" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to generate a checkerboard dataset and bicluster it using the Spectral Biclustering algorithm.</source>
          <target state="translated">Este ejemplo demuestra cómo generar un conjunto de datos de tablero de ajedrez y ponerlo en bicluster usando el algoritmo de Biclustering Espectral.</target>
        </trans-unit>
        <trans-unit id="fb9a20a0b6ffdb624c38c357324f211d180af27f" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to generate a dataset and bicluster it using the Spectral Co-Clustering algorithm.</source>
          <target state="translated">Este ejemplo demuestra cómo generar un conjunto de datos y hacer un bicluster con el algoritmo de Co-Clustering Espectral.</target>
        </trans-unit>
        <trans-unit id="9b609f5368296ac180488994b6106bba8395b9b3" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to use &lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; on a dataset containing different types of features. The choice of features is not particularly helpful, but serves to illustrate the technique.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e024e96a6e8109f327c2d890a3a85ee374e03bd" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to use &lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt;&lt;/a&gt; on a dataset containing different types of features. We use the 20-newsgroups dataset and compute standard bag-of-words features for the subject line and body in separate pipelines as well as ad hoc features on the body. We combine them (with weights) using a ColumnTransformer and finally train a classifier on the combined set of features.</source>
          <target state="translated">Este ejemplo demuestra c&amp;oacute;mo usar &lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt; &lt;/a&gt; en un conjunto de datos que contiene diferentes tipos de caracter&amp;iacute;sticas. Usamos el conjunto de datos de 20 grupos de noticias y calculamos funciones est&amp;aacute;ndar de bolsa de palabras para la l&amp;iacute;nea de asunto y el cuerpo en canales separados, as&amp;iacute; como funciones ad hoc en el cuerpo. Los combinamos (con pesos) usando un ColumnTransformer y finalmente entrenamos un clasificador en el conjunto combinado de caracter&amp;iacute;sticas.</target>
        </trans-unit>
        <trans-unit id="76d491fec0fed042e6d7927f2dc124b698f9bded" translate="yes" xml:space="preserve">
          <source>This example demonstrates the Spectral Co-clustering algorithm on the twenty newsgroups dataset. The &amp;lsquo;comp.os.ms-windows.misc&amp;rsquo; category is excluded because it contains many posts containing nothing but data.</source>
          <target state="translated">Este ejemplo demuestra el algoritmo de agrupaci&amp;oacute;n conjunta espectral en el conjunto de datos de veinte grupos de noticias. La categor&amp;iacute;a 'comp.os.ms-windows.misc' est&amp;aacute; excluida porque contiene muchas publicaciones que solo contienen datos.</target>
        </trans-unit>
        <trans-unit id="6186f51b55d8cba756254a15fe651e5e8504791a" translate="yes" xml:space="preserve">
          <source>This example demonstrates the behavior of Gaussian mixture models fit on data that was not sampled from a mixture of Gaussian random variables. The dataset is formed by 100 points loosely spaced following a noisy sine curve. There is therefore no ground truth value for the number of Gaussian components.</source>
          <target state="translated">Este ejemplo demuestra el comportamiento de los modelos de mezcla gaussiana ajustados a datos que no fueron muestreados a partir de una mezcla de variables aleatorias gaussianas.El conjunto de datos está formado por 100 puntos vagamente espaciados siguiendo una ruidosa curva sinusoidal.Por lo tanto,no hay un valor de verdad de base para el número de componentes gausianos.</target>
        </trans-unit>
        <trans-unit id="a1949f51dde2d60d7d4d1e707d145c1301537434" translate="yes" xml:space="preserve">
          <source>This example demonstrates the power of semisupervised learning by training a Label Spreading model to classify handwritten digits with sets of very few labels.</source>
          <target state="translated">Este ejemplo demuestra el poder del aprendizaje semisupervisado al entrenar un modelo de difusión de etiquetas para clasificar los dígitos escritos a mano con conjuntos de muy pocas etiquetas.</target>
        </trans-unit>
        <trans-unit id="c6020c6a7334e89ced3b2c5f4b02f4ed9989e37f" translate="yes" xml:space="preserve">
          <source>This example demonstrates the problems of underfitting and overfitting and how we can use linear regression with polynomial features to approximate nonlinear functions. The plot shows the function that we want to approximate, which is a part of the cosine function. In addition, the samples from the real function and the approximations of different models are displayed. The models have polynomial features of different degrees. We can see that a linear function (polynomial with degree 1) is not sufficient to fit the training samples. This is called &lt;strong&gt;underfitting&lt;/strong&gt;. A polynomial of degree 4 approximates the true function almost perfectly. However, for higher degrees the model will &lt;strong&gt;overfit&lt;/strong&gt; the training data, i.e. it learns the noise of the training data. We evaluate quantitatively &lt;strong&gt;overfitting&lt;/strong&gt; / &lt;strong&gt;underfitting&lt;/strong&gt; by using cross-validation. We calculate the mean squared error (MSE) on the validation set, the higher, the less likely the model generalizes correctly from the training data.</source>
          <target state="translated">Este ejemplo demuestra los problemas de desajuste y sobreajuste y c&amp;oacute;mo podemos usar la regresi&amp;oacute;n lineal con caracter&amp;iacute;sticas polinomiales para aproximar funciones no lineales. La gr&amp;aacute;fica muestra la funci&amp;oacute;n que queremos aproximar, que es parte de la funci&amp;oacute;n coseno. Adem&amp;aacute;s, se muestran las muestras de la funci&amp;oacute;n real y las aproximaciones de diferentes modelos. Los modelos tienen caracter&amp;iacute;sticas polinomiales de diferentes grados. Podemos ver que una funci&amp;oacute;n lineal (polinomio con grado 1) no es suficiente para ajustar las muestras de entrenamiento. Esto se llama &lt;strong&gt;desajuste&lt;/strong&gt; . Un polinomio de grado 4 se aproxima a la funci&amp;oacute;n verdadera casi a la perfecci&amp;oacute;n. Sin embargo, para grados m&amp;aacute;s altos, el modelo &lt;strong&gt;sobreajustar&amp;aacute;&lt;/strong&gt; los datos de entrenamiento, es decir, aprende el ruido de los datos de entrenamiento. Evaluamos cuantitativamente&lt;strong&gt;overfitting&lt;/strong&gt; / &lt;strong&gt;underfitting&lt;/strong&gt; mediante el uso de validaci&amp;oacute;n cruzada. Calculamos el error cuadr&amp;aacute;tico medio (MSE) en el conjunto de validaci&amp;oacute;n, cuanto m&amp;aacute;s alto, menos probable es que el modelo se generalice correctamente a partir de los datos de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="a2d558b6f5e9fa98f7c27a3a7352d216289c9012" translate="yes" xml:space="preserve">
          <source>This example demonstrates the use of the Box-Cox and Yeo-Johnson transforms through &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.powertransformer#sklearn.preprocessing.PowerTransformer&quot;&gt;&lt;code&gt;PowerTransformer&lt;/code&gt;&lt;/a&gt; to map data from various distributions to a normal distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab8d51c9ac9762c2930c84a5a03c1c12345a6627" translate="yes" xml:space="preserve">
          <source>This example demonstrates the use of the Box-Cox and Yeo-Johnson transforms through &lt;code&gt;preprocessing.PowerTransformer&lt;/code&gt; to map data from various distributions to a normal distribution.</source>
          <target state="translated">Este ejemplo demuestra el uso de las transformaciones de Box-Cox y Yeo-Johnson a trav&amp;eacute;s del &lt;code&gt;preprocessing.PowerTransformer&lt;/code&gt; para mapear datos de varias distribuciones a una distribuci&amp;oacute;n normal.</target>
        </trans-unit>
        <trans-unit id="9b62ef0be0bf7ce49acab00a23e04164c0becf9d" translate="yes" xml:space="preserve">
          <source>This example does not perform any learning over the data (see &lt;a href=&quot;../applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;Species distribution modeling&lt;/a&gt; for an example of classification based on the attributes in this dataset). It simply shows the kernel density estimate of observed data points in geospatial coordinates.</source>
          <target state="translated">Este ejemplo no realiza ning&amp;uacute;n aprendizaje sobre los datos (consulte &lt;a href=&quot;../applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;Modelado de distribuci&amp;oacute;n de especies&lt;/a&gt; para ver un ejemplo de clasificaci&amp;oacute;n basada en los atributos de este conjunto de datos). Simplemente muestra la estimaci&amp;oacute;n de la densidad del n&amp;uacute;cleo de los puntos de datos observados en coordenadas geoespaciales.</target>
        </trans-unit>
        <trans-unit id="03eea75ae69c05ca0f9dc1a13d89bbd210d48145" translate="yes" xml:space="preserve">
          <source>This example doesn&amp;rsquo;t show it, as we&amp;rsquo;re in a low-dimensional space, but another advantage of the Dirichlet process model is that it can fit full covariance matrices effectively even when there are less examples per cluster than there are dimensions in the data, due to regularization properties of the inference algorithm.</source>
          <target state="translated">Este ejemplo no lo muestra, ya que estamos en un espacio de baja dimensi&amp;oacute;n, pero otra ventaja del modelo de proceso de Dirichlet es que puede ajustarse a matrices de covarianza total de manera efectiva incluso cuando hay menos ejemplos por grupo que dimensiones en el datos, debido a las propiedades de regularizaci&amp;oacute;n del algoritmo de inferencia.</target>
        </trans-unit>
        <trans-unit id="7b398c0b1dbb0f3edb9cc17097a9c9f8696a24cc" translate="yes" xml:space="preserve">
          <source>This example employs several unsupervised learning techniques to extract the stock market structure from variations in historical quotes.</source>
          <target state="translated">Este ejemplo emplea varias técnicas de aprendizaje no supervisadas para extraer la estructura del mercado de valores de las variaciones de las cotizaciones históricas.</target>
        </trans-unit>
        <trans-unit id="41937f256baaea1198c4d043d4bb81b61df0d50b" translate="yes" xml:space="preserve">
          <source>This example fits a Gradient Boosting model with least squares loss and 500 regression trees of depth 4.</source>
          <target state="translated">Este ejemplo se ajusta a un modelo de Gradient Boosting con la menor pérdida de cuadrados y 500 árboles de regresión de profundidad 4.</target>
        </trans-unit>
        <trans-unit id="e8121408498cf6fb8c886d50eef2580465ff3307" translate="yes" xml:space="preserve">
          <source>This example fits an AdaBoosted decision stump on a non-linearly separable classification dataset composed of two &amp;ldquo;Gaussian quantiles&amp;rdquo; clusters (see &lt;a href=&quot;../../modules/generated/sklearn.datasets.make_gaussian_quantiles#sklearn.datasets.make_gaussian_quantiles&quot;&gt;&lt;code&gt;sklearn.datasets.make_gaussian_quantiles&lt;/code&gt;&lt;/a&gt;) and plots the decision boundary and decision scores. The distributions of decision scores are shown separately for samples of class A and B. The predicted class label for each sample is determined by the sign of the decision score. Samples with decision scores greater than zero are classified as B, and are otherwise classified as A. The magnitude of a decision score determines the degree of likeness with the predicted class label. Additionally, a new dataset could be constructed containing a desired purity of class B, for example, by only selecting samples with a decision score above some value.</source>
          <target state="translated">Este ejemplo se ajusta a un mu&amp;ntilde;&amp;oacute;n de decisi&amp;oacute;n AdaBoosted en un conjunto de datos de clasificaci&amp;oacute;n no linealmente separables compuesto por dos grupos de &quot;cuantiles gaussianos&quot; (ver &lt;a href=&quot;../../modules/generated/sklearn.datasets.make_gaussian_quantiles#sklearn.datasets.make_gaussian_quantiles&quot;&gt; &lt;code&gt;sklearn.datasets.make_gaussian_quantiles&lt;/code&gt; &lt;/a&gt; ) y traza el l&amp;iacute;mite de decisi&amp;oacute;n y las puntuaciones de decisi&amp;oacute;n. Las distribuciones de las puntuaciones de decisi&amp;oacute;n se muestran por separado para las muestras de clase A y B. La etiqueta de clase predicha para cada muestra est&amp;aacute; determinada por el signo de la puntuaci&amp;oacute;n de decisi&amp;oacute;n. Las muestras con puntuaciones de decisi&amp;oacute;n superiores a cero se clasifican como B y, de lo contrario, se clasifican como A. La magnitud de una puntuaci&amp;oacute;n de decisi&amp;oacute;n determina el grado de semejanza con la etiqueta de clase predicha. Adem&amp;aacute;s, se podr&amp;iacute;a construir un nuevo conjunto de datos que contenga una pureza deseada de clase B, por ejemplo, seleccionando solo muestras con una puntuaci&amp;oacute;n de decisi&amp;oacute;n por encima de alg&amp;uacute;n valor.</target>
        </trans-unit>
        <trans-unit id="02c230a18f98a72777c5f2652062014b16511fe8" translate="yes" xml:space="preserve">
          <source>This example has a fair amount of visualization-related code, as visualization is crucial here to display the graph. One of the challenge is to position the labels minimizing overlap. For this we use an heuristic based on the direction of the nearest neighbor along each axis.</source>
          <target state="translated">Este ejemplo tiene una buena cantidad de código relacionado con la visualización,ya que la visualización es crucial aquí para mostrar el gráfico.Uno de los retos es posicionar las etiquetas minimizando la superposición.Para ello utilizamos una heurística basada en la dirección del vecino más cercano a lo largo de cada eje.</target>
        </trans-unit>
        <trans-unit id="6aeec4c0fd48150be3eb10918e11b6fbb03261c5" translate="yes" xml:space="preserve">
          <source>This example illustrates GPC on XOR data. Compared are a stationary, isotropic kernel (&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt;) and a non-stationary kernel (&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt;&lt;code&gt;DotProduct&lt;/code&gt;&lt;/a&gt;). On this particular dataset, the &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt;&lt;code&gt;DotProduct&lt;/code&gt;&lt;/a&gt; kernel obtains considerably better results because the class-boundaries are linear and coincide with the coordinate axes. In practice, however, stationary kernels such as &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt; often obtain better results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="259139974bd9ca7304e763dff02af979bb7908e6" translate="yes" xml:space="preserve">
          <source>This example illustrates GPC on XOR data. Compared are a stationary, isotropic kernel (&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt;) and a non-stationary kernel (&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt;&lt;code&gt;DotProduct&lt;/code&gt;&lt;/a&gt;). On this particular dataset, the &lt;code&gt;DotProduct&lt;/code&gt; kernel obtains considerably better results because the class-boundaries are linear and coincide with the coordinate axes. In practice, however, stationary kernels such as &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt; often obtain better results.</source>
          <target state="translated">Este ejemplo ilustra GPC en datos XOR. Se comparan un kernel isotr&amp;oacute;pico estacionario ( &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt; &lt;code&gt;RBF&lt;/code&gt; &lt;/a&gt; ) y un kernel no estacionario ( &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt; &lt;code&gt;DotProduct&lt;/code&gt; &lt;/a&gt; ). En este conjunto de datos en particular, el n&amp;uacute;cleo &lt;code&gt;DotProduct&lt;/code&gt; obtiene resultados considerablemente mejores porque los l&amp;iacute;mites de clase son lineales y coinciden con los ejes de coordenadas. En la pr&amp;aacute;ctica, sin embargo, los granos estacionarios como el &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt; &lt;code&gt;RBF&lt;/code&gt; &lt;/a&gt; suelen obtener mejores resultados.</target>
        </trans-unit>
        <trans-unit id="a467b781e30c272f4f5e4645f1261bd726b14e8d" translate="yes" xml:space="preserve">
          <source>This example illustrates GPC on XOR data. Compared are a stationary, isotropic kernel (RBF) and a non-stationary kernel (DotProduct). On this particular dataset, the DotProduct kernel obtains considerably better results because the class-boundaries are linear and coincide with the coordinate axes. In general, stationary kernels often obtain better results.</source>
          <target state="translated">Este ejemplo ilustra el GPC en los datos de XOR.Se comparan un núcleo estacionario e isotrópico (RBF)y un núcleo no estacionario (DotProduct).En este conjunto de datos en particular,el núcleo DotProduct obtiene resultados considerablemente mejores porque los límites de la clase son lineales y coinciden con los ejes de coordenadas.En general,los núcleos estacionarios suelen obtener mejores resultados.</target>
        </trans-unit>
        <trans-unit id="722f803000769d905ffb0b191f686c49464dc23e" translate="yes" xml:space="preserve">
          <source>This example illustrates a generic implementation of a meta-estimator which extends clustering by inducing a classifier from the cluster labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="397c051adb668f2e353216b8af31fde49c4b91b4" translate="yes" xml:space="preserve">
          <source>This example illustrates a learned distance metric that maximizes the nearest neighbors classification accuracy. It provides a visual representation of this metric compared to the original point space. Please refer to the &lt;a href=&quot;../../modules/neighbors#nca&quot;&gt;User Guide&lt;/a&gt; for more information.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b43f5231cb55a1a95a64bd8afe5472e7955fc98b" translate="yes" xml:space="preserve">
          <source>This example illustrates and compares the bias-variance decomposition of the expected mean squared error of a single estimator against a bagging ensemble.</source>
          <target state="translated">Este ejemplo ilustra y compara la descomposición del sesgo-varianza del error cuadrático medio esperado de un solo estimador contra un conjunto de empaquetamiento.</target>
        </trans-unit>
        <trans-unit id="0a3450a632d656139c95a4f138b569cec22ba6ef" translate="yes" xml:space="preserve">
          <source>This example illustrates both methods on an artificial dataset, which consists of a sinusoidal target function and strong noise added to every fifth datapoint. The first figure compares the learned model of KRR and SVR when both complexity/regularization and bandwidth of the RBF kernel are optimized using grid-search. The learned functions are very similar; however, fitting KRR is approx. seven times faster than fitting SVR (both with grid-search). However, prediction of 100000 target values is more than tree times faster with SVR since it has learned a sparse model using only approx. 1/3 of the 100 training datapoints as support vectors.</source>
          <target state="translated">Este ejemplo ilustra ambos métodos en un conjunto de datos artificial,que consiste en una función de objetivo sinusoidal y un fuerte ruido añadido a cada quinto punto de datos.La primera figura compara el modelo aprendido de la RBC y la RVS cuando tanto la complejidad/regularización como el ancho de banda del núcleo de la RBC se optimizan mediante la búsqueda en cuadrículas.Las funciones aprendidas son muy similares;sin embargo,ajustar la RBC es aproximadamente siete veces más rápido que ajustar la SVR (ambas con la búsqueda en la cuadrícula).Sin embargo,la predicción de 100000 valores objetivo es más de tres veces más rápida con la SVR,ya que ha aprendido un modelo escaso utilizando sólo aproximadamente 1/3 de los 100 puntos de datos de entrenamiento como vectores de apoyo.</target>
        </trans-unit>
        <trans-unit id="bdbaaa805869c3c13d157f267aeffaf332ff1284" translate="yes" xml:space="preserve">
          <source>This example illustrates both methods on an artificial dataset, which consists of a sinusoidal target function and strong noise. The figure compares the learned model of KRR and GPR based on a ExpSineSquared kernel, which is suited for learning periodic functions. The kernel&amp;rsquo;s hyperparameters control the smoothness (l) and periodicity of the kernel (p). Moreover, the noise level of the data is learned explicitly by GPR by an additional WhiteKernel component in the kernel and by the regularization parameter alpha of KRR.</source>
          <target state="translated">Este ejemplo ilustra ambos m&amp;eacute;todos en un conjunto de datos artificial, que consta de una funci&amp;oacute;n objetivo sinusoidal y ruido fuerte. La figura compara el modelo aprendido de KRR y GPR basado en un kernel ExpSineSquared, que es adecuado para aprender funciones peri&amp;oacute;dicas. Los hiperpar&amp;aacute;metros del kernel controlan la suavidad (l) y la periodicidad del kernel (p). Adem&amp;aacute;s, el nivel de ruido de los datos se aprende expl&amp;iacute;citamente mediante GPR mediante un componente adicional de WhiteKernel en el kernel y mediante el par&amp;aacute;metro de regularizaci&amp;oacute;n alfa de KRR.</target>
        </trans-unit>
        <trans-unit id="745a420beb7d4cfe3dcb516bc28a36f2576e5395" translate="yes" xml:space="preserve">
          <source>This example illustrates how sigmoid calibration changes predicted probabilities for a 3-class classification problem. Illustrated is the standard 2-simplex, where the three corners correspond to the three classes. Arrows point from the probability vectors predicted by an uncalibrated classifier to the probability vectors predicted by the same classifier after sigmoid calibration on a hold-out validation set. Colors indicate the true class of an instance (red: class 1, green: class 2, blue: class 3).</source>
          <target state="translated">Este ejemplo ilustra cómo los cambios en la calibración del sigmoide predijeron las probabilidades de un problema de clasificación de 3 clases.Se ilustra el estándar 2-simplex,donde las tres esquinas corresponden a las tres clases.Las flechas apuntan desde los vectores de probabilidad predichos por un clasificador no calibrado hasta los vectores de probabilidad predichos por el mismo clasificador después de la calibración del sigmoide en un conjunto de validación de retención.Los colores indican la verdadera clase de una instancia (rojo:clase 1,verde:clase 2,azul:clase 3).</target>
        </trans-unit>
        <trans-unit id="12c733d8527ccd2c1862324a52d9d453fa3717b9" translate="yes" xml:space="preserve">
          <source>This example illustrates how the Mahalanobis distances are affected by outlying data: observations drawn from a contaminating distribution are not distinguishable from the observations coming from the real, Gaussian distribution that one may want to work with. Using MCD-based Mahalanobis distances, the two populations become distinguishable. Associated applications are outliers detection, observations ranking, clustering, &amp;hellip; For visualization purpose, the cubic root of the Mahalanobis distances are represented in the boxplot, as Wilson and Hilferty suggest [2]</source>
          <target state="translated">Este ejemplo ilustra c&amp;oacute;mo las distancias de Mahalanobis se ven afectadas por los datos perif&amp;eacute;ricos: las observaciones extra&amp;iacute;das de una distribuci&amp;oacute;n contaminante no se pueden distinguir de las observaciones que provienen de la distribuci&amp;oacute;n gaussiana real con la que uno puede querer trabajar. Usando distancias de Mahalanobis basadas en MCD, las dos poblaciones se vuelven distinguibles. Las aplicaciones asociadas son detecci&amp;oacute;n de valores at&amp;iacute;picos, clasificaci&amp;oacute;n de observaciones, agrupamiento,&amp;hellip; Para fines de visualizaci&amp;oacute;n, la ra&amp;iacute;z c&amp;uacute;bica de las distancias de Mahalanobis se representa en el diagrama de caja, como sugieren Wilson y Hilferty [2]</target>
        </trans-unit>
        <trans-unit id="e6c2656adbcd3c5e59b375bc18300061f72c931d" translate="yes" xml:space="preserve">
          <source>This example illustrates how the early stopping can used in the &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;sklearn.ensemble.GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; model to achieve almost the same accuracy as compared to a model built without early stopping using many fewer estimators. This can significantly reduce training time, memory usage and prediction latency.</source>
          <target state="translated">Este ejemplo ilustra c&amp;oacute;mo se puede utilizar la detenci&amp;oacute;n anticipada en el modelo &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt; &lt;code&gt;sklearn.ensemble.GradientBoostingClassifier&lt;/code&gt; &lt;/a&gt; para lograr casi la misma precisi&amp;oacute;n en comparaci&amp;oacute;n con un modelo creado sin la detenci&amp;oacute;n anticipada utilizando muchos menos estimadores. Esto puede reducir significativamente el tiempo de entrenamiento, el uso de memoria y la latencia de predicci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="c9534999032b13d85edbba90f8420279af14435d" translate="yes" xml:space="preserve">
          <source>This example illustrates how the early stopping can used in the &lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt;&lt;/a&gt; model to achieve almost the same accuracy as compared to a model built without early stopping. This can significantly reduce training time. Note that scores differ between the stopping criteria even from early iterations because some of the training data is held out with the validation stopping criterion.</source>
          <target state="translated">Este ejemplo ilustra c&amp;oacute;mo se puede utilizar la detenci&amp;oacute;n anticipada en el modelo &lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt; &lt;/a&gt; para lograr casi la misma precisi&amp;oacute;n en comparaci&amp;oacute;n con un modelo creado sin detenci&amp;oacute;n anticipada. Esto puede reducir significativamente el tiempo de entrenamiento. Tenga en cuenta que las puntuaciones difieren entre los criterios de detenci&amp;oacute;n incluso desde las primeras iteraciones porque algunos de los datos de entrenamiento se mantienen con el criterio de detenci&amp;oacute;n de validaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="c861b8fa50d5165e1e9cdc8044114c0ba76be7f1" translate="yes" xml:space="preserve">
          <source>This example illustrates how to apply different preprocessing and feature extraction pipelines to different subsets of features, using &lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt;&lt;/a&gt;. This is particularly handy for the case of datasets that contain heterogeneous data types, since we may want to scale the numeric features and one-hot encode the categorical ones.</source>
          <target state="translated">Este ejemplo ilustra c&amp;oacute;mo aplicar diferentes canalizaciones de extracci&amp;oacute;n de caracter&amp;iacute;sticas y preprocesamiento a diferentes subconjuntos de caracter&amp;iacute;sticas, utilizando &lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt; &lt;/a&gt; . Esto es particularmente &amp;uacute;til para el caso de conjuntos de datos que contienen tipos de datos heterog&amp;eacute;neos, ya que es posible que deseemos escalar las caracter&amp;iacute;sticas num&amp;eacute;ricas y codificar de forma directa las categ&amp;oacute;ricas.</target>
        </trans-unit>
        <trans-unit id="7688b615fac5133028d275260a50b4a9e7d6a213" translate="yes" xml:space="preserve">
          <source>This example illustrates that GPR with a sum-kernel including a WhiteKernel can estimate the noise level of data. An illustration of the log-marginal-likelihood (LML) landscape shows that there exist two local maxima of LML.</source>
          <target state="translated">Este ejemplo ilustra que el GPR con un núcleo de suma que incluye un núcleo blanco puede estimar el nivel de ruido de los datos.Una ilustración del paisaje de probabilidad logarítmica-marginal (LML)muestra que existen dos máximos locales de LML.</target>
        </trans-unit>
        <trans-unit id="aab3b4258aabcd6bfe55c7c5adf04622c59229dc" translate="yes" xml:space="preserve">
          <source>This example illustrates that GPR with a sum-kernel including a WhiteKernel can estimate the noise level of data. An illustration of the log-marginal-likelihood (LML) landscape shows that there exist two local maxima of LML. The first corresponds to a model with a high noise level and a large length scale, which explains all variations in the data by noise. The second one has a smaller noise level and shorter length scale, which explains most of the variation by the noise-free functional relationship. The second model has a higher likelihood; however, depending on the initial value for the hyperparameters, the gradient-based optimization might also converge to the high-noise solution. It is thus important to repeat the optimization several times for different initializations.</source>
          <target state="translated">Este ejemplo ilustra que el GPR con un núcleo de suma que incluye un núcleo blanco puede estimar el nivel de ruido de los datos.Una ilustración del paisaje de probabilidad logarítmica-marginal (LML)muestra que existen dos máximos locales de LML.El primero corresponde a un modelo con un alto nivel de ruido y una gran escala de longitud,que explica todas las variaciones de los datos por el ruido.El segundo tiene un nivel de ruido más bajo y una escala de longitud menor,lo que explica la mayor parte de la variación por la relación funcional libre de ruido.El segundo modelo tiene una mayor probabilidad;sin embargo,dependiendo del valor inicial de los hiperparámetros,la optimización basada en el gradiente podría también converger hacia la solución de alto ruido.Por consiguiente,es importante repetir la optimización varias veces para diferentes inicializaciones.</target>
        </trans-unit>
        <trans-unit id="d19a1528c92e37a37fb4fd9cad2cad1ac3d91123" translate="yes" xml:space="preserve">
          <source>This example illustrates the differences between univariate F-test statistics and mutual information.</source>
          <target state="translated">Este ejemplo ilustra las diferencias entre las estadísticas de pruebas F univariadas y la información mutua.</target>
        </trans-unit>
        <trans-unit id="7867032d06fe0e647e7865e3d58419806006e425" translate="yes" xml:space="preserve">
          <source>This example illustrates the effect of monotonic constraints on a gradient boosting estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b411e019157b9b0953b37eb36e27bc6a8ffb3f5f" translate="yes" xml:space="preserve">
          <source>This example illustrates the effect of the parameters &lt;code&gt;gamma&lt;/code&gt; and &lt;code&gt;C&lt;/code&gt; of the Radial Basis Function (RBF) kernel SVM.</source>
          <target state="translated">Este ejemplo ilustra el efecto de los par&amp;aacute;metros &lt;code&gt;gamma&lt;/code&gt; y &lt;code&gt;C&lt;/code&gt; del kernel SVM de la funci&amp;oacute;n de base radial (RBF).</target>
        </trans-unit>
        <trans-unit id="0f49634dcf1598fde3c403bd7ddd702e3816c634" translate="yes" xml:space="preserve">
          <source>This example illustrates the need for robust covariance estimation on a real data set. It is useful both for outlier detection and for a better understanding of the data structure.</source>
          <target state="translated">Este ejemplo ilustra la necesidad de una estimación robusta de covarianza en un conjunto de datos reales.Es útil tanto para la detección de valores atípicos como para una mejor comprensión de la estructura de los datos.</target>
        </trans-unit>
        <trans-unit id="dc09ff23a3cae32be328d47d0a0a7e64185cd75a" translate="yes" xml:space="preserve">
          <source>This example illustrates the predicted probability of GPC for an RBF kernel with different choices of the hyperparameters. The first figure shows the predicted probability of GPC with arbitrarily chosen hyperparameters and with the hyperparameters corresponding to the maximum log-marginal-likelihood (LML).</source>
          <target state="translated">Este ejemplo ilustra la probabilidad prevista de GPC para un núcleo RBF con diferentes opciones de los hiperparámetros.La primera figura muestra la probabilidad prevista de GPC con hiperparámetros elegidos arbitrariamente y con los hiperparámetros correspondientes a la máxima probabilidad logarítmica-marginal (LML).</target>
        </trans-unit>
        <trans-unit id="d49b62c58d1a1ad4b52cfdb4df97043fcb25dfc7" translate="yes" xml:space="preserve">
          <source>This example illustrates the predicted probability of GPC for an isotropic and anisotropic RBF kernel on a two-dimensional version for the iris-dataset. The anisotropic RBF kernel obtains slightly higher log-marginal-likelihood by assigning different length-scales to the two feature dimensions.</source>
          <target state="translated">Este ejemplo ilustra la probabilidad prevista de GPC para un núcleo RBF isotrópico y anisotrópico en una versión bidimensional para el conjunto de datos del iris.El núcleo RBF anisotrópico obtiene una probabilidad logarítmica-marginal ligeramente más alta asignando diferentes escalas de longitud a las dos dimensiones de los rasgos.</target>
        </trans-unit>
        <trans-unit id="f8e8b4dfa6bc8bbc237c34d26328609c3561c0d3" translate="yes" xml:space="preserve">
          <source>This example illustrates the predicted probability of GPC for an isotropic and anisotropic RBF kernel on a two-dimensional version for the iris-dataset. This illustrates the applicability of GPC to non-binary classification. The anisotropic RBF kernel obtains slightly higher log-marginal-likelihood by assigning different length-scales to the two feature dimensions.</source>
          <target state="translated">Este ejemplo ilustra la probabilidad prevista de GPC para un núcleo RBF isotrópico y anisotrópico en una versión bidimensional para el conjunto de datos del iris.Esto ilustra la aplicabilidad de la GPC a la clasificación no binaria.El núcleo RBF anisotrópico obtiene una probabilidad logarítmica-marginal ligeramente más alta asignando diferentes escalas de longitud a las dos dimensiones de los rasgos.</target>
        </trans-unit>
        <trans-unit id="d60d503f722a9b87495f756d071794c2e2c52164" translate="yes" xml:space="preserve">
          <source>This example illustrates the prior and posterior of a GPR with different kernels. Mean, standard deviation, and 10 samples are shown for both prior and posterior.</source>
          <target state="translated">Este ejemplo ilustra el anterior y posterior de un GPR con diferentes núcleos.Se muestra la media,la desviación estándar y 10 muestras tanto para el anterior como para el posterior.</target>
        </trans-unit>
        <trans-unit id="404891c56bd0f5f01fae61c2e12336745bf204d5" translate="yes" xml:space="preserve">
          <source>This example illustrates the use of Gaussian processes for regression and classification tasks on data that are not in fixed-length feature vector form. This is achieved through the use of kernel functions that operates directly on discrete structures such as variable-length sequences, trees, and graphs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b759d3b33b67e0716b08ee9d527244bce9326eed" translate="yes" xml:space="preserve">
          <source>This example illustrates the use of Poisson, Gamma and Tweedie regression on the &lt;a href=&quot;https://www.openml.org/d/41214&quot;&gt;French Motor Third-Party Liability Claims dataset&lt;/a&gt;, and is inspired by an R tutorial &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d658c6dcc61e946966ad0e8390aa06974df82a41" translate="yes" xml:space="preserve">
          <source>This example illustrates the use of log-linear Poisson regression on the &lt;a href=&quot;https://www.openml.org/d/41214&quot;&gt;French Motor Third-Party Liability Claims dataset&lt;/a&gt; from &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt; and compares it with a linear model fitted with the usual least squared error and a non-linear GBRT model fitted with the Poisson loss (and a log-link).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e4f09a45ae58596e6f6f82a5f372f88442c0679" translate="yes" xml:space="preserve">
          <source>This example illustrates the use of the &lt;a href=&quot;../../modules/multiclass#multiclass&quot;&gt;multioutput.MultiOutputRegressor&lt;/a&gt; meta-estimator to perform multi-output regression. A random forest regressor is used, which supports multi-output regression natively, so the results can be compared.</source>
          <target state="translated">Este ejemplo ilustra el uso del &lt;a href=&quot;../../modules/multiclass#multiclass&quot;&gt;metaestimador multioutput.MultiOutputRegressor&lt;/a&gt; para realizar una regresi&amp;oacute;n de m&amp;uacute;ltiples salidas. Se utiliza un regresor de bosque aleatorio, que admite la regresi&amp;oacute;n de m&amp;uacute;ltiples salidas de forma nativa, por lo que los resultados se pueden comparar.</target>
        </trans-unit>
        <trans-unit id="b7cdc524f76e4e3da39b555dc7fb49145ad1abf9" translate="yes" xml:space="preserve">
          <source>This example illustrates the use of the print_changed_only global parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a4413b8994df2fb3a9be31d12e5c3eff453a657" translate="yes" xml:space="preserve">
          <source>This example illustrates visually in the feature space a comparison by results using two different component analysis techniques.</source>
          <target state="translated">Este ejemplo ilustra visualmente en el espacio de las características una comparación por resultados utilizando dos técnicas diferentes de análisis de componentes.</target>
        </trans-unit>
        <trans-unit id="a61e83a5c393fe6eb13b5e3a4d37f5a941d5abef" translate="yes" xml:space="preserve">
          <source>This example is based on Figure 10.2 from Hastie et al 2009 &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt; and illustrates the difference in performance between the discrete SAMME &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;2&lt;/a&gt; boosting algorithm and real SAMME.R boosting algorithm. Both algorithms are evaluated on a binary classification task where the target Y is a non-linear function of 10 input features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2cd2616385e5968100e838cea35843639b5d4649" translate="yes" xml:space="preserve">
          <source>This example is based on Figure 10.2 from Hastie et al 2009 &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; and illustrates the difference in performance between the discrete SAMME &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt; boosting algorithm and real SAMME.R boosting algorithm. Both algorithms are evaluated on a binary classification task where the target Y is a non-linear function of 10 input features.</source>
          <target state="translated">Este ejemplo se basa en la Figura 10.2 de Hastie et al 2009 &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; e ilustra la diferencia en el rendimiento entre el algoritmo de impulso discreto SAMME &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt; y el algoritmo real de impulso SAMME.R. Ambos algoritmos se eval&amp;uacute;an en una tarea de clasificaci&amp;oacute;n binaria donde el objetivo Y es una funci&amp;oacute;n no lineal de 10 caracter&amp;iacute;sticas de entrada.</target>
        </trans-unit>
        <trans-unit id="f74f72b73b7f5fc12f50525ee3a073668f796ed6" translate="yes" xml:space="preserve">
          <source>This example is based on Section 5.4.3 of &amp;ldquo;Gaussian Processes for Machine Learning&amp;rdquo; [RW2006]. It illustrates an example of complex kernel engineering and hyperparameter optimization using gradient ascent on the log-marginal-likelihood. The data consists of the monthly average atmospheric CO2 concentrations (in parts per million by volume (ppmv)) collected at the Mauna Loa Observatory in Hawaii, between 1958 and 2001. The objective is to model the CO2 concentration as a function of the time t.</source>
          <target state="translated">Este ejemplo se basa en la Secci&amp;oacute;n 5.4.3 de &amp;ldquo;Procesos gaussianos para el aprendizaje autom&amp;aacute;tico&amp;rdquo; [RW2006]. Ilustra un ejemplo de ingenier&amp;iacute;a de kernel compleja y optimizaci&amp;oacute;n de hiperpar&amp;aacute;metros usando el ascenso de gradiente en la probabilidad log-marginal. Los datos consisten en las concentraciones de CO2 atmosf&amp;eacute;rico promedio mensuales (en partes por mill&amp;oacute;n por volumen (ppmv)) recolectadas en el Observatorio Mauna Loa en Hawai, entre 1958 y 2001. El objetivo es modelar la concentraci&amp;oacute;n de CO2 en funci&amp;oacute;n del tiempo t .</target>
        </trans-unit>
        <trans-unit id="b3b5741f90375b259727a574f2a0488e7637e5bc" translate="yes" xml:space="preserve">
          <source>This example is based on Section 5.4.3 of &lt;a href=&quot;#rw2006&quot; id=&quot;id2&quot;&gt;[RW2006]&lt;/a&gt;. It illustrates an example of complex kernel engineering and hyperparameter optimization using gradient ascent on the log-marginal-likelihood. The data consists of the monthly average atmospheric CO2 concentrations (in parts per million by volume (ppmv)) collected at the Mauna Loa Observatory in Hawaii, between 1958 and 1997. The objective is to model the CO2 concentration as a function of the time t.</source>
          <target state="translated">Este ejemplo se basa en la Secci&amp;oacute;n 5.4.3 de &lt;a href=&quot;#rw2006&quot; id=&quot;id2&quot;&gt;[RW2006]&lt;/a&gt; . Ilustra un ejemplo de ingenier&amp;iacute;a de kernel compleja y optimizaci&amp;oacute;n de hiperpar&amp;aacute;metros usando el ascenso de gradiente en la probabilidad log-marginal. Los datos consisten en las concentraciones de CO2 atmosf&amp;eacute;rico promedio mensuales (en partes por mill&amp;oacute;n por volumen (ppmv)) recolectadas en el Observatorio Mauna Loa en Hawai, entre 1958 y 1997. El objetivo es modelar la concentraci&amp;oacute;n de CO2 en funci&amp;oacute;n del tiempo t .</target>
        </trans-unit>
        <trans-unit id="9ecc1c02a68f38d70271669af08df8c1497b1d98" translate="yes" xml:space="preserve">
          <source>This example is commented in the &lt;a href=&quot;../../tutorial/basic/tutorial#introduction&quot;&gt;tutorial section of the user manual&lt;/a&gt;.</source>
          <target state="translated">Este ejemplo se comenta en la &lt;a href=&quot;../../tutorial/basic/tutorial#introduction&quot;&gt;secci&amp;oacute;n de tutoriales del manual de usuario&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="9143eb314f05280f157b4081755ef4be5d0d1857" translate="yes" xml:space="preserve">
          <source>This example is meant to illustrate situations where k-means will produce unintuitive and possibly unexpected clusters. In the first three plots, the input data does not conform to some implicit assumption that k-means makes and undesirable clusters are produced as a result. In the last plot, k-means returns intuitive clusters despite unevenly sized blobs.</source>
          <target state="translated">Este ejemplo tiene por objeto ilustrar situaciones en las que los medios &quot;k&quot; producirán agrupaciones poco intuitivas y posiblemente inesperadas.En los tres primeros gráficos,los datos de entrada no se ajustan a ninguna suposición implícita de que k-means hace y se producen clusters no deseados como resultado.En la última parcela,k-means devuelve cúmulos intuitivos a pesar de las manchas de tamaño desigual.</target>
        </trans-unit>
        <trans-unit id="0549792fdb7404b1799803948805283b1004db4d" translate="yes" xml:space="preserve">
          <source>This example plots several randomly generated classification datasets. For easy visualization, all datasets have 2 features, plotted on the x and y axis. The color of each point represents its class label.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="301c1da5ab62941da3ba93fb4d30f8869ad9b8b5" translate="yes" xml:space="preserve">
          <source>This example plots the corresponding dendrogram of a hierarchical clustering using AgglomerativeClustering and the dendrogram method available in scipy.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb84e7488212d58818869cb1a848aafb46dc6573" translate="yes" xml:space="preserve">
          <source>This example plots the covariance ellipsoids of each class and decision boundary learned by LDA and QDA. The ellipsoids display the double standard deviation for each class. With LDA, the standard deviation is the same for all the classes, while each class has its own standard deviation with QDA.</source>
          <target state="translated">En este ejemplo se trazan los elipsoides de covarianza de cada clase y límite de decisión aprendidos por LDA y QDA.Los elipsoides muestran la doble desviación estándar de cada clase.Con LDA,la desviación estándar es la misma para todas las clases,mientras que cada clase tiene su propia desviación estándar con QDA.</target>
        </trans-unit>
        <trans-unit id="61cf8846c08926de131cab630666b0d7a1ff4033" translate="yes" xml:space="preserve">
          <source>This example plots the ellipsoids obtained from a toy dataset (mixture of three Gaussians) fitted by the &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; class models with a Dirichlet distribution prior (&lt;code&gt;weight_concentration_prior_type='dirichlet_distribution'&lt;/code&gt;) and a Dirichlet process prior (&lt;code&gt;weight_concentration_prior_type='dirichlet_process'&lt;/code&gt;). On each figure, we plot the results for three different values of the weight concentration prior.</source>
          <target state="translated">Este ejemplo traza los elipsoides obtenidos de un conjunto de datos de juguete (mezcla de tres gaussianos) ajustados por los modelos de clase &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; con una distribuci&amp;oacute;n de Dirichlet anterior ( &lt;code&gt;weight_concentration_prior_type='dirichlet_distribution'&lt;/code&gt; ) y un proceso de Dirichlet anterior ( &lt;code&gt;weight_concentration_prior_type='dirichlet_process'&lt;/code&gt; ). En cada figura, graficamos los resultados para tres valores diferentes de la concentraci&amp;oacute;n de peso antes.</target>
        </trans-unit>
        <trans-unit id="e769643d14b1851635097bc926523b99ade21d56" translate="yes" xml:space="preserve">
          <source>This example presents how to chain KNeighborsTransformer and TSNE in a pipeline. It also shows how to wrap the packages &lt;code&gt;annoy&lt;/code&gt; and &lt;code&gt;nmslib&lt;/code&gt; to replace KNeighborsTransformer and perform approximate nearest neighbors. These packages can be installed with &lt;code&gt;pip install annoy nmslib&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0d46d4faf4d4d45c7ba844c05b8ff931d890d6c" translate="yes" xml:space="preserve">
          <source>This example presents the different strategies implemented in KBinsDiscretizer:</source>
          <target state="translated">Este ejemplo presenta las diferentes estrategias implementadas en KBinsDiscretizer:</target>
        </trans-unit>
        <trans-unit id="83f4e337d08dbc1524d014ed0118fe74e8fd5454" translate="yes" xml:space="preserve">
          <source>This example reproduces Figure 1 of Zhu et al &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt; and shows how boosting can improve prediction accuracy on a multi-class problem. The classification dataset is constructed by taking a ten-dimensional standard normal distribution and defining three classes separated by nested concentric ten-dimensional spheres such that roughly equal numbers of samples are in each class (quantiles of the \(\chi^2\) distribution).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aff95617011fc0f39a1d4573107679df90fa3c83" translate="yes" xml:space="preserve">
          <source>This example reproduces Figure 1 of Zhu et al &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; and shows how boosting can improve prediction accuracy on a multi-class problem. The classification dataset is constructed by taking a ten-dimensional standard normal distribution and defining three classes separated by nested concentric ten-dimensional spheres such that roughly equal numbers of samples are in each class (quantiles of the \(\chi^2\) distribution).</source>
          <target state="translated">Este ejemplo reproduce la Figura 1 de Zhu et al &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; y muestra c&amp;oacute;mo el impulso puede mejorar la precisi&amp;oacute;n de la predicci&amp;oacute;n en un problema de varias clases. El conjunto de datos de clasificaci&amp;oacute;n se construye tomando una distribuci&amp;oacute;n normal est&amp;aacute;ndar de diez dimensiones y definiendo tres clases separadas por esferas conc&amp;eacute;ntricas de diez dimensiones anidadas, de modo que haya aproximadamente el mismo n&amp;uacute;mero de muestras en cada clase (cuantiles de la distribuci&amp;oacute;n \ (\ chi ^ 2 \) ).</target>
        </trans-unit>
        <trans-unit id="f0193d5eae04ea4c45d1272eb8f24ceb76514e1e" translate="yes" xml:space="preserve">
          <source>This example serves as a visual check that IPCA is able to find a similar projection of the data to PCA (to a sign flip), while only processing a few samples at a time. This can be considered a &amp;ldquo;toy example&amp;rdquo;, as IPCA is intended for large datasets which do not fit in main memory, requiring incremental approaches.</source>
          <target state="translated">Este ejemplo sirve como una verificaci&amp;oacute;n visual de que IPCA puede encontrar una proyecci&amp;oacute;n similar de los datos a PCA (a un cambio de signo), mientras que solo procesa algunas muestras a la vez. Esto puede considerarse un &quot;ejemplo de juguete&quot;, ya que IPCA est&amp;aacute; dise&amp;ntilde;ado para grandes conjuntos de datos que no caben en la memoria principal, lo que requiere enfoques incrementales.</target>
        </trans-unit>
        <trans-unit id="3dfa9a56451c107730b94ff094ad060fe6660b05" translate="yes" xml:space="preserve">
          <source>This example should be taken with a grain of salt, as the intuition conveyed does not necessarily carry over to real datasets. Particularly in high-dimensional spaces, data can more easily be separated linearly. Moreover, using feature discretization and one-hot encoding increases the number of features, which easily lead to overfitting when the number of samples is small.</source>
          <target state="translated">Este ejemplo debe tomarse con un grano de sal,ya que la intuición que se transmite no se transmite necesariamente a los conjuntos de datos reales.Particularmente en espacios de altas dimensiones,los datos pueden ser separados más fácilmente de forma lineal.Además,la utilización de la discretización de las características y la codificación de una sola vez aumenta el número de características,lo que fácilmente conduce a la sobrecarga cuando el número de muestras es pequeño.</target>
        </trans-unit>
        <trans-unit id="ad21e470ff2bffe875ca12e50c6f8a883eaa0515" translate="yes" xml:space="preserve">
          <source>This example shows an example usage of the &lt;code&gt;split&lt;/code&gt; method.</source>
          <target state="translated">Este ejemplo muestra un ejemplo de uso del m&amp;eacute;todo &lt;code&gt;split&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="05321a1b8964aa5eaada463be8f8b6ab44686817" translate="yes" xml:space="preserve">
          <source>This example shows characteristics of different anomaly detection algorithms on 2D datasets. Datasets contain one or two modes (regions of high density) to illustrate the ability of algorithms to cope with multimodal data.</source>
          <target state="translated">Este ejemplo muestra las características de los diferentes algoritmos de detección de anomalías en conjuntos de datos 2D.Los conjuntos de datos contienen uno o dos modos (regiones de alta densidad)para ilustrar la capacidad de los algoritmos de hacer frente a los datos multimodales.</target>
        </trans-unit>
        <trans-unit id="9671740bdc9e0f010272719df08d61d30b070724" translate="yes" xml:space="preserve">
          <source>This example shows characteristics of different clustering algorithms on datasets that are &amp;ldquo;interesting&amp;rdquo; but still in 2D. With the exception of the last dataset, the parameters of each of these dataset-algorithm pairs has been tuned to produce good clustering results. Some algorithms are more sensitive to parameter values than others.</source>
          <target state="translated">Este ejemplo muestra caracter&amp;iacute;sticas de diferentes algoritmos de agrupamiento en conjuntos de datos que son &quot;interesantes&quot; pero a&amp;uacute;n en 2D. Con la excepci&amp;oacute;n del &amp;uacute;ltimo conjunto de datos, los par&amp;aacute;metros de cada uno de estos pares de algoritmo y conjunto de datos se han ajustado para producir buenos resultados de agrupaci&amp;oacute;n. Algunos algoritmos son m&amp;aacute;s sensibles a los valores de los par&amp;aacute;metros que otros.</target>
        </trans-unit>
        <trans-unit id="408c25df8162bc85c75adf89aefb6c4283aab313" translate="yes" xml:space="preserve">
          <source>This example shows characteristics of different linkage methods for hierarchical clustering on datasets that are &amp;ldquo;interesting&amp;rdquo; but still in 2D.</source>
          <target state="translated">Este ejemplo muestra las caracter&amp;iacute;sticas de diferentes m&amp;eacute;todos de vinculaci&amp;oacute;n para la agrupaci&amp;oacute;n jer&amp;aacute;rquica en conjuntos de datos que son &quot;interesantes&quot; pero a&amp;uacute;n en 2D.</target>
        </trans-unit>
        <trans-unit id="ee904b77cbf769dbe7d1093eb852f864329f4bb5" translate="yes" xml:space="preserve">
          <source>This example shows how kernel density estimation (KDE), a powerful non-parametric density estimation technique, can be used to learn a generative model for a dataset. With this generative model in place, new samples can be drawn. These new samples reflect the underlying model of the data.</source>
          <target state="translated">Este ejemplo muestra cómo la estimación de la densidad del núcleo (KDE),una potente técnica de estimación de la densidad no paramétrica,puede utilizarse para aprender un modelo generativo para un conjunto de datos.Con este modelo generativo en su lugar,se pueden dibujar nuevas muestras.Estas nuevas muestras reflejan el modelo subyacente de los datos.</target>
        </trans-unit>
        <trans-unit id="54102d8f78c42d496181e5bcdf5a40bdaee3e42d" translate="yes" xml:space="preserve">
          <source>This example shows how quantile regression can be used to create prediction intervals.</source>
          <target state="translated">Este ejemplo muestra cómo la regresión de cuantiles puede utilizarse para crear intervalos de predicción.</target>
        </trans-unit>
        <trans-unit id="682ea376dc5fd413204f119c7903367cc1b71149" translate="yes" xml:space="preserve">
          <source>This example shows how to build a classification pipeline with a BernoulliRBM feature extractor and a &lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; classifier. The hyperparameters of the entire model (learning rate, hidden layer size, regularization) were optimized by grid search, but the search is not reproduced here because of runtime constraints.</source>
          <target state="translated">Este ejemplo muestra c&amp;oacute;mo crear una canalizaci&amp;oacute;n de clasificaci&amp;oacute;n con un extractor de caracter&amp;iacute;sticas BernoulliRBM y un clasificador &lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt; . Los hiperpar&amp;aacute;metros de todo el modelo (tasa de aprendizaje, tama&amp;ntilde;o de capa oculta, regularizaci&amp;oacute;n) se optimizaron mediante la b&amp;uacute;squeda de cuadr&amp;iacute;cula, pero la b&amp;uacute;squeda no se reproduce aqu&amp;iacute; debido a restricciones de tiempo de ejecuci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="e6287a37f5ab2f7e58b3aa65bfc9b371f8d2e434" translate="yes" xml:space="preserve">
          <source>This example shows how to obtain partial dependence plots from a &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; trained on the California housing dataset. The example is taken from &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="translated">Este ejemplo muestra c&amp;oacute;mo obtener parcelas de dependencia parcial de un &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt; &lt;code&gt;GradientBoostingRegressor&lt;/code&gt; &lt;/a&gt; capacitado en el conjunto de datos de vivienda de California. El ejemplo se toma de &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="acf93c17a79b2f475e2915043f3e806cbddc60a2" translate="yes" xml:space="preserve">
          <source>This example shows how to obtain partial dependence plots from a &lt;a href=&quot;../../modules/generated/sklearn.neural_network.mlpregressor#sklearn.neural_network.MLPRegressor&quot;&gt;&lt;code&gt;MLPRegressor&lt;/code&gt;&lt;/a&gt; and a &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; trained on the California housing dataset. The example is taken from &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;1&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd4b844c3488b502b915a6b11d22b13911beaa74" translate="yes" xml:space="preserve">
          <source>This example shows how to perform univariate feature selection before running a SVC (support vector classifier) to improve the classification scores.</source>
          <target state="translated">Este ejemplo muestra cómo realizar una selección univariante de características antes de ejecutar un SVC (clasificador de vectores de apoyo)para mejorar los resultados de la clasificación.</target>
        </trans-unit>
        <trans-unit id="f7865c444403c29f04e970d66c2c5367cc834a8b" translate="yes" xml:space="preserve">
          <source>This example shows how to perform univariate feature selection before running a SVC (support vector classifier) to improve the classification scores. We use the iris dataset (4 features) and add 36 non-informative features. We can find that our model achieves best performance when we select around 10% of features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47a26e628df959c3e5ed3ffe4f4f3490e8927a8d" translate="yes" xml:space="preserve">
          <source>This example shows how to plot some of the first layer weights in a MLPClassifier trained on the MNIST dataset.</source>
          <target state="translated">Este ejemplo muestra cómo trazar algunos de los primeros pesos de las capas en un clasificador MLPC entrenado en el conjunto de datos del MNIST.</target>
        </trans-unit>
        <trans-unit id="dd07bd7e7afed03f3c2a3c74458c42dc14028dfe" translate="yes" xml:space="preserve">
          <source>This example shows how to plot the decision surface for four SVM classifiers with different kernels.</source>
          <target state="translated">Este ejemplo muestra cómo trazar la superficie de decisión para cuatro clasificadores SVM con diferentes núcleos.</target>
        </trans-unit>
        <trans-unit id="981971245cdda71fb264be7304dc1e201a08b23b" translate="yes" xml:space="preserve">
          <source>This example shows how to use &lt;a href=&quot;../../modules/generated/sklearn.model_selection.cross_val_predict#sklearn.model_selection.cross_val_predict&quot;&gt;&lt;code&gt;cross_val_predict&lt;/code&gt;&lt;/a&gt; to visualize prediction errors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52dcf2b8bf47a153b3ba3beca30c9af85b850fad" translate="yes" xml:space="preserve">
          <source>This example shows how to use &lt;code&gt;cross_val_predict&lt;/code&gt; to visualize prediction errors.</source>
          <target state="translated">Este ejemplo muestra c&amp;oacute;mo usar &lt;code&gt;cross_val_predict&lt;/code&gt; para visualizar errores de predicci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="42d1610b65eff631d96069dbbdf35236afd1d573" translate="yes" xml:space="preserve">
          <source>This example shows how to use Permutation Importances as an alternative that can mitigate those limitations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="351c02b1031f149a08df70cbeed39cd2a6bb9ec7" translate="yes" xml:space="preserve">
          <source>This example shows that Kernel PCA is able to find a projection of the data that makes data linearly separable.</source>
          <target state="translated">Este ejemplo muestra que el núcleo PCA es capaz de encontrar una proyección de los datos que hace que los datos sean linealmente separables.</target>
        </trans-unit>
        <trans-unit id="607fdb6fda0285694fd1dd982f83082f2f9a6687" translate="yes" xml:space="preserve">
          <source>This example shows that imputing the missing values can give better results than discarding the samples containing any missing value. Imputing does not always improve the predictions, so please check via cross-validation. Sometimes dropping rows or using marker values is more effective.</source>
          <target state="translated">Este ejemplo muestra que la imputación de los valores perdidos puede dar mejores resultados que el descarte de las muestras que contienen cualquier valor perdido.La imputación no siempre mejora las predicciones,así que por favor compruébelo mediante una validación cruzada.A veces,el descarte de filas o el uso de valores de marcadores es más efectivo.</target>
        </trans-unit>
        <trans-unit id="b6045a3110197ccfd64402c3c879acac73bdaadb" translate="yes" xml:space="preserve">
          <source>This example shows that model selection can be performed with Gaussian Mixture Models using information-theoretic criteria (BIC). Model selection concerns both the covariance type and the number of components in the model. In that case, AIC also provides the right result (not shown to save time), but BIC is better suited if the problem is to identify the right model. Unlike Bayesian procedures, such inferences are prior-free.</source>
          <target state="translated">Este ejemplo muestra que la selección de modelos puede realizarse con los modelos de mezcla gaussiana utilizando criterios de información-teórica (BIC).La selección del modelo se refiere tanto al tipo de covarianza como al número de componentes del modelo.En ese caso,el AIC también proporciona el resultado correcto (no se muestra para ahorrar tiempo),pero el BIC es más adecuado si el problema es identificar el modelo correcto.A diferencia de los procedimientos bayesianos,esas inferencias no tienen antecedentes.</target>
        </trans-unit>
        <trans-unit id="7ed4db944a196b1cb5ab23d8834c95cd5421c757" translate="yes" xml:space="preserve">
          <source>This example shows that you can do non-linear regression with a linear model, using a pipeline to add non-linear features. Kernel methods extend this idea and can induce very high (even infinite) dimensional feature spaces.</source>
          <target state="translated">Este ejemplo muestra que se puede hacer una regresión no lineal con un modelo lineal,usando una tubería para añadir características no lineales.Los métodos del núcleo extienden esta idea y pueden inducir espacios de características dimensionales muy altos (incluso infinitos).</target>
        </trans-unit>
        <trans-unit id="48dcc848c2d6e1561f6c336d60b0fb518f9ab59a" translate="yes" xml:space="preserve">
          <source>This example shows the ROC response of different datasets, created from K-fold cross-validation. Taking all of these curves, it is possible to calculate the mean area under curve, and see the variance of the curve when the training set is split into different subsets. This roughly shows how the classifier output is affected by changes in the training data, and how different the splits generated by K-fold cross-validation are from one another.</source>
          <target state="translated">Este ejemplo muestra la respuesta ROC de diferentes conjuntos de datos,creados a partir de la validación cruzada de la carpeta K.Tomando todas estas curvas,es posible calcular el área media bajo la curva,y ver la variación de la curva cuando el conjunto de entrenamiento se divide en diferentes subconjuntos.Esto muestra a grandes rasgos cómo la salida del clasificador se ve afectada por los cambios en los datos de entrenamiento,y cuán diferentes son las divisiones generadas por la validación cruzada de la curva K entre sí.</target>
        </trans-unit>
        <trans-unit id="7b92e840bf44fca60c7edc394c5ccf3da0546857" translate="yes" xml:space="preserve">
          <source>This example shows the effect of imposing a connectivity graph to capture local structure in the data. The graph is simply the graph of 20 nearest neighbors.</source>
          <target state="translated">Este ejemplo muestra el efecto de imponer un gráfico de conectividad para captar la estructura local en los datos.El gráfico es simplemente el gráfico de los 20 vecinos más cercanos.</target>
        </trans-unit>
        <trans-unit id="a122bd5b47879a72d10715b2e2741901d74ebd5f" translate="yes" xml:space="preserve">
          <source>This example shows the reconstruction of an image from a set of parallel projections, acquired along different angles. Such a dataset is acquired in &lt;strong&gt;computed tomography&lt;/strong&gt; (CT).</source>
          <target state="translated">Este ejemplo muestra la reconstrucci&amp;oacute;n de una imagen a partir de un conjunto de proyecciones paralelas, adquiridas a lo largo de diferentes &amp;aacute;ngulos. Dicho conjunto de datos se adquiere en &lt;strong&gt;tomograf&amp;iacute;a computarizada&lt;/strong&gt; (TC).</target>
        </trans-unit>
        <trans-unit id="277c7e399c7f521a9367c3279ba6605ffa32bb5b" translate="yes" xml:space="preserve">
          <source>This example shows the use of forests of trees to evaluate the importance of the pixels in an image classification task (faces). The hotter the pixel, the more important.</source>
          <target state="translated">Este ejemplo muestra el uso de bosques de árboles para evaluar la importancia de los píxeles en una tarea de clasificación de imágenes (caras).Cuanto más caliente el píxel,más importante.</target>
        </trans-unit>
        <trans-unit id="1fc99c46b3490d43b644ebffe104cba9573e1195" translate="yes" xml:space="preserve">
          <source>This example shows the use of forests of trees to evaluate the impurity-based importance of the pixels in an image classification task (faces). The hotter the pixel, the more important.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="181df9c721e88b620fbcd3038af372d2bc17958d" translate="yes" xml:space="preserve">
          <source>This example shows the use of multi-output estimator to complete images. The goal is to predict the lower half of a face given its upper half.</source>
          <target state="translated">Este ejemplo muestra el uso de un estimador multi-salida para completar las imágenes.El objetivo es predecir la mitad inferior de una cara dada su mitad superior.</target>
        </trans-unit>
        <trans-unit id="c194d9ad3fd820ff97a5b60a54a77ad5e096ac46" translate="yes" xml:space="preserve">
          <source>This example simulates a multi-label document classification problem. The dataset is generated randomly based on the following process:</source>
          <target state="translated">Este ejemplo simula un problema de clasificación de documentos de múltiples etiquetas.El conjunto de datos se genera aleatoriamente en base al siguiente proceso:</target>
        </trans-unit>
        <trans-unit id="beca62f6aeebe1ac71c16bdf04b277689fc51da6" translate="yes" xml:space="preserve">
          <source>This example uses &lt;a href=&quot;../../modules/clustering#spectral-clustering&quot;&gt;Spectral clustering&lt;/a&gt; on a graph created from voxel-to-voxel difference on an image to break this image into multiple partly-homogeneous regions.</source>
          <target state="translated">Este ejemplo utiliza &lt;a href=&quot;../../modules/clustering#spectral-clustering&quot;&gt;agrupaci&amp;oacute;n espectral&lt;/a&gt; en un gr&amp;aacute;fico creado a partir de la diferencia de v&amp;oacute;xeles a v&amp;oacute;xeles en una imagen para dividir esta imagen en varias regiones parcialmente homog&amp;eacute;neas.</target>
        </trans-unit>
        <trans-unit id="b1b3f16a0bb367262a72b24da0008ca16f86a096" translate="yes" xml:space="preserve">
          <source>This example uses a large dataset of faces to learn a set of 20 x 20 images patches that constitute faces.</source>
          <target state="translated">Este ejemplo utiliza un gran conjunto de datos de rostros para aprender un conjunto de parches de imágenes de 20 x 20 que constituyen los rostros.</target>
        </trans-unit>
        <trans-unit id="0ad2a4281006cf2ce3833b3619a37abf58d678e0" translate="yes" xml:space="preserve">
          <source>This example uses different scalers, transformers, and normalizers to bring the data within a pre-defined range.</source>
          <target state="translated">Este ejemplo utiliza diferentes escaladores,transformadores y normalizadores para llevar los datos dentro de un rango predefinido.</target>
        </trans-unit>
        <trans-unit id="e1bfbae38c6acd2b8b362eacb6ca0227cf12cdc6" translate="yes" xml:space="preserve">
          <source>This example uses the &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt;&lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt;&lt;/a&gt; class to demonstrate the principles of Kernel Density Estimation in one dimension.</source>
          <target state="translated">Este ejemplo utiliza la clase &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt; &lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt; &lt;/a&gt; para demostrar los principios de la estimaci&amp;oacute;n de la densidad del n&amp;uacute;cleo en una dimensi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="a99077db11e6455dfdf5d225265c8630cb316352" translate="yes" xml:space="preserve">
          <source>This example uses the &lt;code&gt;scipy.stats&lt;/code&gt; module, which contains many useful distributions for sampling parameters, such as &lt;code&gt;expon&lt;/code&gt;, &lt;code&gt;gamma&lt;/code&gt;, &lt;code&gt;uniform&lt;/code&gt; or &lt;code&gt;randint&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c91a9c343e9d52fecff06520d2432c55d78e2a0" translate="yes" xml:space="preserve">
          <source>This example uses the &lt;code&gt;scipy.stats&lt;/code&gt; module, which contains many useful distributions for sampling parameters, such as &lt;code&gt;expon&lt;/code&gt;, &lt;code&gt;gamma&lt;/code&gt;, &lt;code&gt;uniform&lt;/code&gt; or &lt;code&gt;randint&lt;/code&gt;. In principle, any function can be passed that provides a &lt;code&gt;rvs&lt;/code&gt; (random variate sample) method to sample a value. A call to the &lt;code&gt;rvs&lt;/code&gt; function should provide independent random samples from possible parameter values on consecutive calls.</source>
          <target state="translated">Este ejemplo utiliza el m&amp;oacute;dulo &lt;code&gt;scipy.stats&lt;/code&gt; , que contiene muchas distribuciones &amp;uacute;tiles para los par&amp;aacute;metros de muestreo, como &lt;code&gt;expon&lt;/code&gt; , &lt;code&gt;gamma&lt;/code&gt; , &lt;code&gt;uniform&lt;/code&gt; o &lt;code&gt;randint&lt;/code&gt; . En principio, se puede pasar cualquier funci&amp;oacute;n que proporcione un m&amp;eacute;todo &lt;code&gt;rvs&lt;/code&gt; (muestra variable aleatoria) para muestrear un valor. Una llamada a la funci&amp;oacute;n &lt;code&gt;rvs&lt;/code&gt; deber&amp;iacute;a proporcionar muestras aleatorias independientes de posibles valores de par&amp;aacute;metros en llamadas consecutivas.</target>
        </trans-unit>
        <trans-unit id="d9381762b80079a0275cf5384c50652951b2c3b8" translate="yes" xml:space="preserve">
          <source>This example uses the only the first feature of the &lt;code&gt;diabetes&lt;/code&gt; dataset, in order to illustrate a two-dimensional plot of this regression technique. The straight line can be seen in the plot, showing how linear regression attempts to draw a straight line that will best minimize the residual sum of squares between the observed responses in the dataset, and the responses predicted by the linear approximation.</source>
          <target state="translated">Este ejemplo utiliza la &amp;uacute;nica primera caracter&amp;iacute;stica del conjunto de datos de &lt;code&gt;diabetes&lt;/code&gt; , con el fin de ilustrar un gr&amp;aacute;fico bidimensional de esta t&amp;eacute;cnica de regresi&amp;oacute;n. La l&amp;iacute;nea recta se puede ver en el gr&amp;aacute;fico, mostrando c&amp;oacute;mo la regresi&amp;oacute;n lineal intenta dibujar una l&amp;iacute;nea recta que minimizar&amp;aacute; mejor la suma de cuadrados residual entre las respuestas observadas en el conjunto de datos y las respuestas predichas por la aproximaci&amp;oacute;n lineal.</target>
        </trans-unit>
        <trans-unit id="c6bb5d76743a81844f0fc5afc16345d399cae103" translate="yes" xml:space="preserve">
          <source>This example visualizes some training loss curves for different stochastic learning strategies, including SGD and Adam. Because of time-constraints, we use several small datasets, for which L-BFGS might be more suitable. The general trend shown in these examples seems to carry over to larger datasets, however.</source>
          <target state="translated">Este ejemplo visualiza algunas curvas de pérdida de entrenamiento para diferentes estrategias de aprendizaje estocástico,incluyendo SGD y Adam.Debido a las limitaciones de tiempo,usamos varios pequeños conjuntos de datos,para los cuales L-BFGS podría ser más adecuado.Sin embargo,la tendencia general que se muestra en estos ejemplos parece trasladarse a conjuntos de datos más grandes.</target>
        </trans-unit>
        <trans-unit id="65646a35859e04e16667e59a0e282463725f9c9e" translate="yes" xml:space="preserve">
          <source>This example visualizes the behavior of several common scikit-learn objects for comparison.</source>
          <target state="translated">Este ejemplo visualiza el comportamiento de varios objetos comunes de aprendizaje de ciencias para compararlos.</target>
        </trans-unit>
        <trans-unit id="49dcb9492cd2c3de6ca468ca869fddbd4adf1109" translate="yes" xml:space="preserve">
          <source>This example visualizes the partitions given by several trees and shows how the transformation can also be used for non-linear dimensionality reduction or non-linear classification.</source>
          <target state="translated">En este ejemplo se visualizan las particiones dadas por varios árboles y se muestra cómo la transformación también puede utilizarse para la reducción de la dimensionalidad no lineal o la clasificación no lineal.</target>
        </trans-unit>
        <trans-unit id="6942c7999112e031e7e9f390f17a63a6ea65b8dd" translate="yes" xml:space="preserve">
          <source>This example was inspired by the &lt;a href=&quot;https://xgboost.readthedocs.io/en/latest/tutorials/monotonic.html&quot;&gt;XGBoost documentation&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6888e16176d5ba984d30e5b2aecac9e36e3202eb" translate="yes" xml:space="preserve">
          <source>This example will also work by replacing &lt;code&gt;SVC(kernel=&quot;linear&quot;)&lt;/code&gt; with &lt;code&gt;SGDClassifier(loss=&quot;hinge&quot;)&lt;/code&gt;. Setting the &lt;code&gt;loss&lt;/code&gt; parameter of the &lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;SGDClassifier&lt;/code&gt;&lt;/a&gt; equal to &lt;code&gt;hinge&lt;/code&gt; will yield behaviour such as that of a SVC with a linear kernel.</source>
          <target state="translated">Este ejemplo tambi&amp;eacute;n funcionar&amp;aacute; reemplazando &lt;code&gt;SVC(kernel=&quot;linear&quot;)&lt;/code&gt; con &lt;code&gt;SGDClassifier(loss=&quot;hinge&quot;)&lt;/code&gt; . Establecer el par&amp;aacute;metro de &lt;code&gt;loss&lt;/code&gt; del &lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;SGDClassifier&lt;/code&gt; &lt;/a&gt; igual a la &lt;code&gt;hinge&lt;/code&gt; producir&amp;aacute; un comportamiento como el de un SVC con un kernel lineal.</target>
        </trans-unit>
        <trans-unit id="b7e7228e1bc6d35fed471b6c3015699404cca0fb" translate="yes" xml:space="preserve">
          <source>This example will generate three figures.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d6705d9213c8c7167b6f8a12276b073092deeca" translate="yes" xml:space="preserve">
          <source>This example will provide some hints in interpreting coefficient in linear models, pointing at problems that arise when either the linear model is not appropriate to describe the dataset, or when features are correlated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08633b59361c5b4332dffd09b9ac681bbe920080" translate="yes" xml:space="preserve">
          <source>This example, inspired from Chen&amp;rsquo;s publication [1], shows a comparison of the estimated MSE of the LW and OAS methods, using Gaussian distributed data.</source>
          <target state="translated">Este ejemplo, inspirado en la publicaci&amp;oacute;n de Chen [1], muestra una comparaci&amp;oacute;n del MSE estimado de los m&amp;eacute;todos LW y OAS, utilizando datos distribuidos en Gauss.</target>
        </trans-unit>
        <trans-unit id="8aeed7fa163e961c6e7fadbb3ef8c5a658c9cc15" translate="yes" xml:space="preserve">
          <source>This examples demonstrates how to precompute the k nearest neighbors before using them in KNeighborsClassifier. KNeighborsClassifier can compute the nearest neighbors internally, but precomputing them can have several benefits, such as finer parameter control, caching for multiple use, or custom implementations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9260a90e6c35e520398765702d07497fe04f1a8" translate="yes" xml:space="preserve">
          <source>This examples shows how a classifier is optimized by cross-validation, which is done using the &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;sklearn.model_selection.GridSearchCV&lt;/code&gt;&lt;/a&gt; object on a development set that comprises only half of the available labeled data.</source>
          <target state="translated">Este ejemplo muestra c&amp;oacute;mo se optimiza un clasificador mediante la validaci&amp;oacute;n cruzada, que se realiza utilizando el objeto &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;sklearn.model_selection.GridSearchCV&lt;/code&gt; &lt;/a&gt; en un conjunto de desarrollo que comprende solo la mitad de los datos etiquetados disponibles.</target>
        </trans-unit>
        <trans-unit id="e16048c7f7cf75798d53fe7e675cc81cd1d6af8b" translate="yes" xml:space="preserve">
          <source>This examples shows the use of forests of trees to evaluate the importance of features on an artificial classification task. The red bars are the feature importances of the forest, along with their inter-trees variability.</source>
          <target state="translated">Este ejemplo muestra el uso de los bosques de árboles para evaluar la importancia de las características en una tarea de clasificación artificial.Las barras rojas son la importancia de los rasgos del bosque,junto con su variabilidad entre los árboles.</target>
        </trans-unit>
        <trans-unit id="cdab1575e5f24de85ab913b14f241e0bd17fea2d" translate="yes" xml:space="preserve">
          <source>This examples shows the use of forests of trees to evaluate the importance of features on an artificial classification task. The red bars are the impurity-based feature importances of the forest, along with their inter-trees variability.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4fb4f14900902539137295018be0a0c7a07b1094" translate="yes" xml:space="preserve">
          <source>This exercise is used in the &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#cv-estimators-tut&quot;&gt;Cross-validated estimators&lt;/a&gt; part of the &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#model-selection-tut&quot;&gt;Model selection: choosing estimators and their parameters&lt;/a&gt; section of the &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;A tutorial on statistical-learning for scientific data processing&lt;/a&gt;.</source>
          <target state="translated">Este ejercicio se utiliza en la parte de &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#cv-estimators-tut&quot;&gt;Estimadores con validaci&amp;oacute;n cruzada&lt;/a&gt; de la secci&amp;oacute;n &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#model-selection-tut&quot;&gt;Selecci&amp;oacute;n&lt;/a&gt; del modelo: elecci&amp;oacute;n de estimadores y sus par&amp;aacute;metros del &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;tutorial sobre aprendizaje estad&amp;iacute;stico para el procesamiento de datos cient&amp;iacute;ficos&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="621b0c8349abb129c7bc150bd9745f46f49af3ab" translate="yes" xml:space="preserve">
          <source>This exercise is used in the &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#cv-generators-tut&quot;&gt;Cross-validation generators&lt;/a&gt; part of the &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#model-selection-tut&quot;&gt;Model selection: choosing estimators and their parameters&lt;/a&gt; section of the &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;A tutorial on statistical-learning for scientific data processing&lt;/a&gt;.</source>
          <target state="translated">Este ejercicio se utiliza en la secci&amp;oacute;n &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#cv-generators-tut&quot;&gt;Generadores de validaci&amp;oacute;n cruzada&lt;/a&gt; de la secci&amp;oacute;n &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#model-selection-tut&quot;&gt;Selecci&amp;oacute;n de modelos: elecci&amp;oacute;n de estimadores y sus par&amp;aacute;metros&lt;/a&gt; del &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;tutorial sobre aprendizaje estad&amp;iacute;stico para el procesamiento de datos cient&amp;iacute;ficos&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="6915ba6643fea2f9e387885428a6e6189c7df3bf" translate="yes" xml:space="preserve">
          <source>This exercise is used in the &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#clf-tut&quot;&gt;Classification&lt;/a&gt; part of the &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#supervised-learning-tut&quot;&gt;Supervised learning: predicting an output variable from high-dimensional observations&lt;/a&gt; section of the &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;A tutorial on statistical-learning for scientific data processing&lt;/a&gt;.</source>
          <target state="translated">Este ejercicio se utiliza en la parte de &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#clf-tut&quot;&gt;Clasificaci&amp;oacute;n&lt;/a&gt; del &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#supervised-learning-tut&quot;&gt;aprendizaje supervisado: predicci&amp;oacute;n de una variable de salida a partir de la&lt;/a&gt; secci&amp;oacute;n de observaciones de alta dimensi&amp;oacute;n del &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;tutorial A sobre aprendizaje estad&amp;iacute;stico para el procesamiento de datos cient&amp;iacute;ficos&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="421684adc1a996556d28fe46ff4c101c2f3063ef" translate="yes" xml:space="preserve">
          <source>This exercise is used in the &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#using-kernels-tut&quot;&gt;Using kernels&lt;/a&gt; part of the &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#supervised-learning-tut&quot;&gt;Supervised learning: predicting an output variable from high-dimensional observations&lt;/a&gt; section of the &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;A tutorial on statistical-learning for scientific data processing&lt;/a&gt;.</source>
          <target state="translated">Este ejercicio se utiliza en la secci&amp;oacute;n &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#using-kernels-tut&quot;&gt;Uso de n&amp;uacute;cleos&lt;/a&gt; de &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#supervised-learning-tut&quot;&gt;Aprendizaje supervisado: predicci&amp;oacute;n de una variable de salida a partir de observaciones de alta dimensi&amp;oacute;n&lt;/a&gt; del &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;tutorial A sobre aprendizaje estad&amp;iacute;stico para el procesamiento de datos cient&amp;iacute;ficos&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="dadb46eeaf7a2bf2f8f61dc107ba2d3f5d55d33a" translate="yes" xml:space="preserve">
          <source>This extends to the multiclass case as follows. Let the true labels for a set of samples be encoded as a 1-of-K binary indicator matrix \(Y\), i.e., \(y_{i,k} = 1\) if sample \(i\) has label \(k\) taken from a set of \(K\) labels. Let \(P\) be a matrix of probability estimates, with \(p_{i,k} = \operatorname{Pr}(t_{i,k} = 1)\). Then the log loss of the whole set is</source>
          <target state="translated">Esto se extiende al caso de las multiclases como sigue.Dejemos que las etiquetas verdaderas de un conjunto de muestras se codifiquen como una matriz indicadora binaria 1-de-K \N-es decir,\N si la muestra tiene una etiqueta \N tomada de un conjunto de etiquetas \N-K.Sea una matriz de estimaciones de probabilidad,con &quot;p_{i,k}=nombre del operador&quot; (Pr}(t_{i,k}=1)).Entonces la pérdida de registro de todo el conjunto es</target>
        </trans-unit>
        <trans-unit id="826a67cf49f96f56e23921af61e52712fab61d33" translate="yes" xml:space="preserve">
          <source>This factory function wraps scoring functions for use in GridSearchCV and cross_val_score. It takes a score function, such as &lt;code&gt;accuracy_score&lt;/code&gt;, &lt;code&gt;mean_squared_error&lt;/code&gt;, &lt;code&gt;adjusted_rand_index&lt;/code&gt; or &lt;code&gt;average_precision&lt;/code&gt; and returns a callable that scores an estimator&amp;rsquo;s output.</source>
          <target state="translated">Esta funci&amp;oacute;n de f&amp;aacute;brica envuelve las funciones de puntuaci&amp;oacute;n para su uso en GridSearchCV y cross_val_score. Se necesita una funci&amp;oacute;n de puntuaci&amp;oacute;n, como &lt;code&gt;accuracy_score&lt;/code&gt; , &lt;code&gt;mean_squared_error&lt;/code&gt; , &lt;code&gt;adjusted_rand_index&lt;/code&gt; o &lt;code&gt;average_precision&lt;/code&gt; y devuelve una salida que las puntuaciones de un estimador exigible.</target>
        </trans-unit>
        <trans-unit id="5eb7a4eb6e2161d3d9f2a7b4c7010506ccf35ad1" translate="yes" xml:space="preserve">
          <source>This feature corresponds to the sepal length in cm. Once the quantile transformation applied, those landmarks approach closely the percentiles previously defined:</source>
          <target state="translated">Esta característica corresponde a la longitud del sépalo en cm.Una vez aplicada la transformación del cuantil,esos puntos de referencia se acercan mucho a los percentiles previamente definidos:</target>
        </trans-unit>
        <trans-unit id="18a1d2c5a41fd4d57af7a6bb802060cade230322" translate="yes" xml:space="preserve">
          <source>This feature selection algorithm looks only at the features (X), not the desired outputs (y), and can thus be used for unsupervised learning.</source>
          <target state="translated">Este algoritmo de selección de características sólo mira las características (X),no las salidas deseadas (y),por lo que puede utilizarse para el aprendizaje no supervisado.</target>
        </trans-unit>
        <trans-unit id="677c582ff4a458e9dc8e636909bbbb985fe5cce6" translate="yes" xml:space="preserve">
          <source>This figure is created using the &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt;&lt;code&gt;PolynomialFeatures&lt;/code&gt;&lt;/a&gt; preprocessor. This preprocessor transforms an input data matrix into a new data matrix of a given degree. It can be used as follows:</source>
          <target state="translated">Esta figura se crea utilizando el preprocesador &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt; &lt;code&gt;PolynomialFeatures&lt;/code&gt; &lt;/a&gt; . Este preprocesador transforma una matriz de datos de entrada en una nueva matriz de datos de un grado determinado. Se puede utilizar de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="6faa801ac2c09333248247cbfc3515a179a790a8" translate="yes" xml:space="preserve">
          <source>This figure is created using the &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt;&lt;code&gt;PolynomialFeatures&lt;/code&gt;&lt;/a&gt; transformer, which transforms an input data matrix into a new data matrix of a given degree. It can be used as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="adbd1df9acbf84e51fe5dc83e34aca6a9423eabf" translate="yes" xml:space="preserve">
          <source>This figure shows an example of such an ROC curve:</source>
          <target state="translated">Esta figura muestra un ejemplo de tal curva ROC:</target>
        </trans-unit>
        <trans-unit id="e1207da0df5038f5f29891db83b7d5022ead8471" translate="yes" xml:space="preserve">
          <source>This folder is used by some large dataset loaders to avoid downloading the data several times.</source>
          <target state="translated">Esta carpeta es utilizada por algunos grandes cargadores de datos para evitar descargar los datos varias veces.</target>
        </trans-unit>
        <trans-unit id="697a12fdadac01e298b3e16a8634659c2b054014" translate="yes" xml:space="preserve">
          <source>This format is a text-based format, with one sample per line. It does not store zero valued features hence is suitable for sparse dataset.</source>
          <target state="translated">Este formato es un formato basado en texto,con una muestra por línea.No almacena características de valor cero,por lo que es adecuado para conjuntos de datos escasos.</target>
        </trans-unit>
        <trans-unit id="a2fe6f0ee6734c2a60bcbb1d0d95dc9dfd886002" translate="yes" xml:space="preserve">
          <source>This format is used as the default format for both svmlight and the libsvm command line programs.</source>
          <target state="translated">Este formato se utiliza como el formato por defecto tanto para svmlight como para los programas de línea de comandos libsvm.</target>
        </trans-unit>
        <trans-unit id="a2e505f490185afab8e1242d5832b6872eb9a667" translate="yes" xml:space="preserve">
          <source>This formulation has two advantages over other ways of computing distances. First, it is computationally efficient when dealing with sparse data. Second, if one argument varies but the other remains unchanged, then &lt;code&gt;dot(x, x)&lt;/code&gt; and/or &lt;code&gt;dot(y, y)&lt;/code&gt; can be pre-computed.</source>
          <target state="translated">Esta formulaci&amp;oacute;n tiene dos ventajas sobre otras formas de calcular distancias. Primero, es computacionalmente eficiente cuando se trata de datos escasos. En segundo lugar, si un argumento var&amp;iacute;a pero el otro permanece sin cambios, entonces el &lt;code&gt;dot(x, x)&lt;/code&gt; y / o el &lt;code&gt;dot(y, y)&lt;/code&gt; pueden calcularse previamente.</target>
        </trans-unit>
        <trans-unit id="fd76e45c139161a6c2340aa524dcf0429afb583e" translate="yes" xml:space="preserve">
          <source>This function computes Cohen&amp;rsquo;s kappa &lt;a href=&quot;#r219a3b9132e1-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;, a score that expresses the level of agreement between two annotators on a classification problem. It is defined as</source>
          <target state="translated">Esta funci&amp;oacute;n calcula el kappa de Cohen &lt;a href=&quot;#r219a3b9132e1-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; , una puntuaci&amp;oacute;n que expresa el nivel de acuerdo entre dos anotadores en un problema de clasificaci&amp;oacute;n. Se define como</target>
        </trans-unit>
        <trans-unit id="1a26f30c64bc915159ba37349551edb033f8db68" translate="yes" xml:space="preserve">
          <source>This function computes for each row in X, the index of the row of Y which is closest (according to the specified distance).</source>
          <target state="translated">Esta función calcula para cada fila de X,el índice de la fila de Y que está más cerca (según la distancia especificada).</target>
        </trans-unit>
        <trans-unit id="40ca8ec3788866f2480b1619115207e644d05cac" translate="yes" xml:space="preserve">
          <source>This function computes for each row in X, the index of the row of Y which is closest (according to the specified distance). The minimal distances are also returned.</source>
          <target state="translated">Esta función calcula para cada fila de X,el índice de la fila de Y que está más cerca (según la distancia especificada).También se devuelven las distancias mínimas.</target>
        </trans-unit>
        <trans-unit id="6e14f241e1c03d6b67a6c0f22515d375ae432487" translate="yes" xml:space="preserve">
          <source>This function crawls the module and gets all classes that inherit from BaseEstimator. Classes that are defined in test-modules are not included. By default meta_estimators such as GridSearchCV are also not included.</source>
          <target state="translated">Esta función rastrea el módulo y obtiene todas las clases que hereda del BaseEstimator.Las clases que se definen en los módulos de prueba no están incluidas.Por defecto,los meta_estimadores como GridSearchCV tampoco están incluidos.</target>
        </trans-unit>
        <trans-unit id="311d27372cf5315019acfac7480657777c623446" translate="yes" xml:space="preserve">
          <source>This function does not try to extract features into a numpy array or scipy sparse matrix. In addition, if load_content is false it does not try to load the files in memory.</source>
          <target state="translated">Esta función no trata de extraer características en una matriz numérica o una matriz de scipy sparse.Además,si load_content es falso no intenta cargar los archivos en la memoria.</target>
        </trans-unit>
        <trans-unit id="28042729acf4bf75d343c82f013b112dad91f4c8" translate="yes" xml:space="preserve">
          <source>This function generates a GraphViz representation of the decision tree, which is then written into &lt;code&gt;out_file&lt;/code&gt;. Once exported, graphical renderings can be generated using, for example:</source>
          <target state="translated">Esta funci&amp;oacute;n genera una representaci&amp;oacute;n GraphViz del &amp;aacute;rbol de decisiones, que luego se escribe en &lt;code&gt;out_file&lt;/code&gt; . Una vez exportados, se pueden generar representaciones gr&amp;aacute;ficas utilizando, por ejemplo:</target>
        </trans-unit>
        <trans-unit id="90af5dc07a0d6b1b987fbe6284966c35b8f7dbed" translate="yes" xml:space="preserve">
          <source>This function implements Test 1 in:</source>
          <target state="translated">Esta función implementa la prueba 1 en:</target>
        </trans-unit>
        <trans-unit id="51510777ab8c25d02b45243629e172250d646e40" translate="yes" xml:space="preserve">
          <source>This function is called with the estimated model and the randomly selected data: &lt;code&gt;is_model_valid(model, X, y)&lt;/code&gt;. If its return value is False the current randomly chosen sub-sample is skipped. Rejecting samples with this function is computationally costlier than with &lt;code&gt;is_data_valid&lt;/code&gt;. &lt;code&gt;is_model_valid&lt;/code&gt; should therefore only be used if the estimated model is needed for making the rejection decision.</source>
          <target state="translated">Esta funci&amp;oacute;n se llama con el modelo estimado y los datos seleccionados aleatoriamente: &lt;code&gt;is_model_valid(model, X, y)&lt;/code&gt; . Si su valor de retorno es Falso, se omite la submuestra seleccionada al azar actual. Rechazar muestras con esta funci&amp;oacute;n es computacionalmente m&amp;aacute;s costoso que con &lt;code&gt;is_data_valid&lt;/code&gt; . &lt;code&gt;is_model_valid&lt;/code&gt; lo tanto, is_model_valid solo debe usarse si el modelo estimado es necesario para tomar la decisi&amp;oacute;n de rechazo.</target>
        </trans-unit>
        <trans-unit id="a4283f593950d3e9c84617d07a78fd011e78bfa4" translate="yes" xml:space="preserve">
          <source>This function is called with the randomly selected data before the model is fitted to it: &lt;code&gt;is_data_valid(X, y)&lt;/code&gt;. If its return value is False the current randomly chosen sub-sample is skipped.</source>
          <target state="translated">Esta funci&amp;oacute;n se llama con los datos seleccionados al azar antes de que el modelo se &lt;code&gt;is_data_valid(X, y)&lt;/code&gt; a ella: is_data_valid (X, y) . Si su valor de retorno es Falso, se omite la submuestra seleccionada al azar actual.</target>
        </trans-unit>
        <trans-unit id="7289fd594a0de96a89a572bf0a7bd6e9501fda52" translate="yes" xml:space="preserve">
          <source>This function is equivalent to mapping load_svmlight_file over a list of files, except that the results are concatenated into a single, flat list and the samples vectors are constrained to all have the same number of features.</source>
          <target state="translated">Esta función equivale a mapear load_svmlight_file sobre una lista de archivos,excepto que los resultados se concatenan en una única lista plana y los vectores de las muestras se limitan a que todos tengan el mismo número de características.</target>
        </trans-unit>
        <trans-unit id="828fa7414b6e6676bd49f6624bf5ec1232d13777" translate="yes" xml:space="preserve">
          <source>This function makes it possible to compute this transformation for a fixed set of class labels known ahead of time.</source>
          <target state="translated">Esta función permite calcular esta transformación para un conjunto fijo de etiquetas de clase conocidas de antemano.</target>
        </trans-unit>
        <trans-unit id="910452d7cd5e91358a13a185cadee882cea17632" translate="yes" xml:space="preserve">
          <source>This function modifies the estimator in-place.</source>
          <target state="translated">Esta función modifica el estimador en el lugar.</target>
        </trans-unit>
        <trans-unit id="3e0bd9f3948e27380d0112f277598d80d17269d2" translate="yes" xml:space="preserve">
          <source>This function requires the true binary value and the target scores, which can either be probability estimates of the positive class, confidence values, or binary decisions. Here is a small example of how to use the &lt;a href=&quot;generated/sklearn.metrics.roc_curve#sklearn.metrics.roc_curve&quot;&gt;&lt;code&gt;roc_curve&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Esta funci&amp;oacute;n requiere el valor binario verdadero y las puntuaciones objetivo, que pueden ser estimaciones de probabilidad de la clase positiva, valores de confianza o decisiones binarias. Aqu&amp;iacute; hay un peque&amp;ntilde;o ejemplo de c&amp;oacute;mo usar la funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.roc_curve#sklearn.metrics.roc_curve&quot;&gt; &lt;code&gt;roc_curve&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="2ddc8c678c75b432a0f0fafa6490a9a69a784bf8" translate="yes" xml:space="preserve">
          <source>This function returns a score of the mean square difference between the actual outcome and the predicted probability of the possible outcome. The actual outcome has to be 1 or 0 (true or false), while the predicted probability of the actual outcome can be a value between 0 and 1.</source>
          <target state="translated">Esta función devuelve una puntuación de la diferencia cuadrada media entre el resultado real y la probabilidad prevista del posible resultado.El resultado real tiene que ser 1 ó 0 (verdadero o falso),mientras que la probabilidad prevista del resultado real puede ser un valor entre 0 y 1.</target>
        </trans-unit>
        <trans-unit id="fbdeef434a34fee928d2d9974f81cfc54768558d" translate="yes" xml:space="preserve">
          <source>This function returns posterior probabilities of classification according to each class on an array of test vectors X.</source>
          <target state="translated">Esta función devuelve probabilidades posteriores de clasificación según cada clase en un conjunto de vectores de prueba X.</target>
        </trans-unit>
        <trans-unit id="f7adc46ef6325367984cfe5d6cabca879706d70d" translate="yes" xml:space="preserve">
          <source>This function returns the Silhouette Coefficient for each sample.</source>
          <target state="translated">Esta función devuelve el Coeficiente de Silueta para cada muestra.</target>
        </trans-unit>
        <trans-unit id="30221178098fdd3682a8c91454092d6226b25e4f" translate="yes" xml:space="preserve">
          <source>This function returns the mean Silhouette Coefficient over all samples. To obtain the values for each sample, use &lt;a href=&quot;sklearn.metrics.silhouette_samples#sklearn.metrics.silhouette_samples&quot;&gt;&lt;code&gt;silhouette_samples&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Esta funci&amp;oacute;n devuelve el coeficiente de silueta medio de todas las muestras. Para obtener los valores de cada muestra, use &lt;a href=&quot;sklearn.metrics.silhouette_samples#sklearn.metrics.silhouette_samples&quot;&gt; &lt;code&gt;silhouette_samples&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="bd812dc35d867d7152375e5009e2698c8db08fc0" translate="yes" xml:space="preserve">
          <source>This function simply returns the valid pairwise distance metrics. It exists to allow for a description of the mapping for each of the valid strings.</source>
          <target state="translated">Esta función simplemente devuelve las métricas de distancia válidas de los pares.Existe para permitir una descripción del mapeo de cada una de las cadenas válidas.</target>
        </trans-unit>
        <trans-unit id="fa4705a70e55596dcf2ace89a6d2a8d09a9fcccf" translate="yes" xml:space="preserve">
          <source>This function simply returns the valid pairwise distance metrics. It exists, however, to allow for a verbose description of the mapping for each of the valid strings.</source>
          <target state="translated">Esta función simplemente devuelve las métricas de distancia válidas de los pares.Existe,sin embargo,para permitir una descripción verbosa del mapeo para cada una de las cadenas válidas.</target>
        </trans-unit>
        <trans-unit id="d1a7a45215b31f0644d6e686c87b329e59419299" translate="yes" xml:space="preserve">
          <source>This function won&amp;rsquo;t compute the intercept.</source>
          <target state="translated">Esta funci&amp;oacute;n no calcular&amp;aacute; la intersecci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="a808622a520f852134a2d8734b9e29ce0a669efe" translate="yes" xml:space="preserve">
          <source>This function works with dense 2D arrays only.</source>
          <target state="translated">Esta función funciona sólo con matrices 2D densas.</target>
        </trans-unit>
        <trans-unit id="19a23bf41918ee91955f633ce4d818d45490ef26" translate="yes" xml:space="preserve">
          <source>This function&amp;rsquo;s formula is as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7541ac358f5bb3bc5dcdfc1193ff72d6ac233a66" translate="yes" xml:space="preserve">
          <source>This generator method yields the ensemble predicted class probabilities after each iteration of boosting and therefore allows monitoring, such as to determine the predicted class probabilities on a test set after each boost.</source>
          <target state="translated">Este método generador produce el conjunto de probabilidades de clase pronosticadas después de cada iteración de impulso y,por lo tanto,permite la supervisión,como para determinar las probabilidades de clase pronosticadas en un conjunto de pruebas después de cada impulso.</target>
        </trans-unit>
        <trans-unit id="7c1ad29f5d19940cf714626cd821b0934b5bc400" translate="yes" xml:space="preserve">
          <source>This generator method yields the ensemble prediction after each iteration of boosting and therefore allows monitoring, such as to determine the prediction on a test set after each boost.</source>
          <target state="translated">Este método generador produce la predicción de conjunto después de cada iteración de impulso y,por lo tanto,permite el seguimiento,como para determinar la predicción en un conjunto de pruebas después de cada impulso.</target>
        </trans-unit>
        <trans-unit id="acc74c06c673308a3e484c230b5ff2c8348cfe79" translate="yes" xml:space="preserve">
          <source>This generator method yields the ensemble score after each iteration of boosting and therefore allows monitoring, such as to determine the score on a test set after each boost.</source>
          <target state="translated">Este método generador produce la puntuación del conjunto después de cada iteración de refuerzo y,por lo tanto,permite el seguimiento,como para determinar la puntuación en un conjunto de pruebas después de cada refuerzo.</target>
        </trans-unit>
        <trans-unit id="1fe14f98435d58bb1786320c156e4b531f66e48b" translate="yes" xml:space="preserve">
          <source>This illustrates the &lt;a href=&quot;../../modules/generated/sklearn.datasets.make_multilabel_classification#sklearn.datasets.make_multilabel_classification&quot;&gt;&lt;code&gt;make_multilabel_classification&lt;/code&gt;&lt;/a&gt; dataset generator. Each sample consists of counts of two features (up to 50 in total), which are differently distributed in each of two classes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb7462acd1f1e763247c87d170997bea5c436272" translate="yes" xml:space="preserve">
          <source>This illustrates the &lt;code&gt;datasets.make_multilabel_classification&lt;/code&gt; dataset generator. Each sample consists of counts of two features (up to 50 in total), which are differently distributed in each of two classes.</source>
          <target state="translated">Esto ilustra el generador de conjuntos de &lt;code&gt;datasets.make_multilabel_classification&lt;/code&gt; datasets.make_multilabel_classification. Cada muestra consta de recuentos de dos caracter&amp;iacute;sticas (hasta 50 en total), que se distribuyen de manera diferente en cada una de las dos clases.</target>
        </trans-unit>
        <trans-unit id="b80113eed9b4b9668cc4e8b638bede5d1f2cf638" translate="yes" xml:space="preserve">
          <source>This implementation bulk-computes all neighborhood queries, which increases the memory complexity to O(n.d) where d is the average number of neighbors, while original DBSCAN had memory complexity O(n). It may attract a higher memory complexity when querying these nearest neighborhoods, depending on the &lt;code&gt;algorithm&lt;/code&gt;.</source>
          <target state="translated">Esta implementaci&amp;oacute;n calcula de forma masiva todas las consultas de vecindad, lo que aumenta la complejidad de la memoria a O (nd) donde d es el n&amp;uacute;mero promedio de vecinos, mientras que el DBSCAN original ten&amp;iacute;a una complejidad de memoria O (n). Puede atraer una mayor complejidad de memoria al consultar estos vecindarios m&amp;aacute;s cercanos, seg&amp;uacute;n el &lt;code&gt;algorithm&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="48627963240be2350bc0acdc732c6b5348961a90" translate="yes" xml:space="preserve">
          <source>This implementation deviates from the original OPTICS by first performing k-nearest-neighborhood searches on all points to identify core sizes, then computing only the distances to unprocessed points when constructing the cluster order. Note that we do not employ a heap to manage the expansion candidates, so the time complexity will be O(n^2).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aed3668d0e58719270c1129ddb01322705c078e7" translate="yes" xml:space="preserve">
          <source>This implementation follows what is explained in the original paper &lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;1&lt;/a&gt;. For the optimisation method, it currently uses scipy&amp;rsquo;s L-BFGS-B with a full gradient computation at each iteration, to avoid to tune the learning rate and provide stable learning.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92eb61902d4dfd6571a464d87feff72fe7b32901" translate="yes" xml:space="preserve">
          <source>This implementation is based on Rubinstein, R., Zibulevsky, M. and Elad, M., Efficient Implementation of the K-SVD Algorithm using Batch Orthogonal Matching Pursuit Technical Report - CS Technion, April 2008. &lt;a href=&quot;http://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&quot;&gt;http://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&lt;/a&gt;</source>
          <target state="translated">Esta implementaci&amp;oacute;n se basa en Rubinstein, R., Zibulevsky, M. y Elad, M., Efficient Implementation of the K-SVD Algorithm using Batch Orthogonal Matching Pursuit Technical Report - CS Technion, abril de 2008. &lt;a href=&quot;http://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&quot;&gt;http: //www.cs. technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="12813af32368fc3d74f568cdec1c9e38f408115a" translate="yes" xml:space="preserve">
          <source>This implementation is based on Rubinstein, R., Zibulevsky, M. and Elad, M., Efficient Implementation of the K-SVD Algorithm using Batch Orthogonal Matching Pursuit Technical Report - CS Technion, April 2008. &lt;a href=&quot;https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&quot;&gt;https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6fb112845601277f8931b295b857e73c1428c8fb" translate="yes" xml:space="preserve">
          <source>This implementation is by default not memory efficient because it constructs a full pairwise similarity matrix in the case where kd-trees or ball-trees cannot be used (e.g. with sparse matrices). This matrix will consume n^2 floats. A couple of mechanisms for getting around this are:</source>
          <target state="translated">Esta implementación no es por defecto eficiente en cuanto a la memoria porque construye una matriz de similitud completa por pares en el caso de que los árboles kd o los árboles bola no puedan utilizarse (por ejemplo,con matrices escasas).Esta matriz consumirá n^2 flotadores.Un par de mecanismos para evitar esto son:</target>
        </trans-unit>
        <trans-unit id="34d2660e23d61d989853bcf418296ddcc27d9606" translate="yes" xml:space="preserve">
          <source>This implementation is by default not memory efficient because it constructs a full pairwise similarity matrix in the case where kd-trees or ball-trees cannot be used (e.g., with sparse matrices). This matrix will consume n^2 floats. A couple of mechanisms for getting around this are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e691dc0883398091a16d8a17daee0ec7cd95f29" translate="yes" xml:space="preserve">
          <source>This implementation is inspired by &lt;a href=&quot;https://github.com/Microsoft/LightGBM&quot;&gt;LightGBM&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc51c30dcd01f51cada4be15777f17eb95eb7cbd" translate="yes" xml:space="preserve">
          <source>This implementation is not intended for large-scale applications. In particular, scikit-learn offers no GPU support. For much faster, GPU-based implementations, as well as frameworks offering much more flexibility to build deep learning architectures, see &lt;a href=&quot;http://scikit-learn.org/stable/related_projects.html#related-projects&quot;&gt;Related Projects&lt;/a&gt;.</source>
          <target state="translated">Esta implementaci&amp;oacute;n no est&amp;aacute; destinada a aplicaciones a gran escala. En particular, scikit-learn no ofrece soporte para GPU. Para implementaciones mucho m&amp;aacute;s r&amp;aacute;pidas basadas en GPU, as&amp;iacute; como marcos que ofrecen mucha m&amp;aacute;s flexibilidad para construir arquitecturas de aprendizaje profundo, consulte &lt;a href=&quot;http://scikit-learn.org/stable/related_projects.html#related-projects&quot;&gt;Proyectos relacionados&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="228da043cb5452c21accbc429ac2d994bed0f4a9" translate="yes" xml:space="preserve">
          <source>This implementation is not intended for large-scale applications. In particular, scikit-learn offers no GPU support. For much faster, GPU-based implementations, as well as frameworks offering much more flexibility to build deep learning architectures, see &lt;a href=&quot;https://scikit-learn.org/0.23/related_projects.html#related-projects&quot;&gt;Related Projects&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e30a130e6449e6025aca5fcf59ecb737e97cb91" translate="yes" xml:space="preserve">
          <source>This implementation is written in Cython and is reasonably fast. However, a faster API-compatible loader is also available at:</source>
          <target state="translated">Esta implementación está escrita en Cython y es razonablemente rápida.Sin embargo,un cargador más rápido compatible con la API también está disponible en:</target>
        </trans-unit>
        <trans-unit id="b488dd9d3cb1238d47d93805595214963db6dd0c" translate="yes" xml:space="preserve">
          <source>This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix.</source>
          <target state="translated">Esta implementación produce una representación dispersa de los recuentos utilizando scipy.sparse.csr_matrix.</target>
        </trans-unit>
        <trans-unit id="42bc7bbc3f5bd0df8efbfbad62976f6ec6db583b" translate="yes" xml:space="preserve">
          <source>This implementation provides the same results that 3 PLS packages provided in the R language (R-project):</source>
          <target state="translated">Esta implementación proporciona los mismos resultados que los 3 paquetes de PLS proporcionados en el lenguaje R (R-proyecto):</target>
        </trans-unit>
        <trans-unit id="09c013dbb84b7e3d406ea0732bc3a8236ed37cbd" translate="yes" xml:space="preserve">
          <source>This implementation provides the same results that the &amp;ldquo;plspm&amp;rdquo; package provided in the R language (R-project), using the function plsca(X, Y). Results are equal or collinear with the function &lt;code&gt;pls(..., mode = &quot;canonical&quot;)&lt;/code&gt; of the &amp;ldquo;mixOmics&amp;rdquo; package. The difference relies in the fact that mixOmics implementation does not exactly implement the Wold algorithm since it does not normalize y_weights to one.</source>
          <target state="translated">Esta implementaci&amp;oacute;n proporciona los mismos resultados que el paquete &amp;ldquo;plspm&amp;rdquo; proporcionado en el lenguaje R (proyecto R), utilizando la funci&amp;oacute;n plsca (X, Y). Los resultados son iguales o colineales con la funci&amp;oacute;n &lt;code&gt;pls(..., mode = &quot;canonical&quot;)&lt;/code&gt; del paquete &quot;mixOmics&quot;. La diferencia radica en el hecho de que la implementaci&amp;oacute;n de mixOmics no implementa exactamente el algoritmo de Wold ya que no normaliza y_weights a uno.</target>
        </trans-unit>
        <trans-unit id="36e4a374c505873717456a086d5c9ed44e5157f6" translate="yes" xml:space="preserve">
          <source>This implementation will refuse to center scipy.sparse matrices since it would make them non-sparse and would potentially crash the program with memory exhaustion problems.</source>
          <target state="translated">Esta implementación se negará a centrar las matrices scipy.sparse ya que las haría no dispersas y potencialmente bloquearía el programa con problemas de agotamiento de memoria.</target>
        </trans-unit>
        <trans-unit id="6684c1532df5f751b6b61c242ea952621dc3f4e8" translate="yes" xml:space="preserve">
          <source>This implementation works with data represented as dense and sparse numpy arrays of floating point values.</source>
          <target state="translated">Esta implementación funciona con datos representados como matrices numéricas densas y dispersas de valores de punto flotante.</target>
        </trans-unit>
        <trans-unit id="b0df3cb22108e4cd0ed0fcd534ed03e427412c64" translate="yes" xml:space="preserve">
          <source>This implementation works with data represented as dense numpy arrays of floating point values for the features.</source>
          <target state="translated">Esta implementación funciona con datos representados como matrices numéricas densas de valores de punto flotante para las características.</target>
        </trans-unit>
        <trans-unit id="4abb3ee00da8e0ef45c7b10f884f8d272712ca81" translate="yes" xml:space="preserve">
          <source>This implementation works with data represented as dense numpy arrays or sparse scipy arrays of floating point values.</source>
          <target state="translated">Esta implementación funciona con datos representados como matrices numéricas densas o matrices de scipy dispersas de valores de punto flotante.</target>
        </trans-unit>
        <trans-unit id="c3c22c958df17cff584f8c572beeb762a9a0290e" translate="yes" xml:space="preserve">
          <source>This implementation works with data represented as dense or sparse arrays of floating point values for the features. The model it fits can be controlled with the loss parameter; by default, it fits a linear support vector machine (SVM).</source>
          <target state="translated">Esta implementación funciona con datos representados como conjuntos densos o escasos de valores de punto flotante para las características.El modelo al que se ajusta puede ser controlado con el parámetro de pérdida;por defecto,se ajusta a una máquina vectorial de soporte lineal (SVM).</target>
        </trans-unit>
        <trans-unit id="c43a7d8bb7931a79100804db2f074a29d45e4b6b" translate="yes" xml:space="preserve">
          <source>This improvement is not visible in the Silhouette Coefficient which is small for both as this measure seem to suffer from the phenomenon called &amp;ldquo;Concentration of Measure&amp;rdquo; or &amp;ldquo;Curse of Dimensionality&amp;rdquo; for high dimensional datasets such as text data. Other measures such as V-measure and Adjusted Rand Index are information theoretic based evaluation scores: as they are only based on cluster assignments rather than distances, hence not affected by the curse of dimensionality.</source>
          <target state="translated">Esta mejora no es visible en el coeficiente de silueta, que es peque&amp;ntilde;o para ambos, ya que esta medida parece sufrir el fen&amp;oacute;meno llamado &quot;concentraci&amp;oacute;n de medida&quot; o &quot;maldici&amp;oacute;n de dimensionalidad&quot; para conjuntos de datos de alta dimensi&amp;oacute;n, como datos de texto. Otras medidas, como la medida V y el &amp;iacute;ndice Rand ajustado, son puntuaciones de evaluaci&amp;oacute;n basadas en la teor&amp;iacute;a de la informaci&amp;oacute;n: ya que solo se basan en asignaciones de grupos en lugar de distancias, por lo que no se ven afectadas por la maldici&amp;oacute;n de la dimensionalidad.</target>
        </trans-unit>
        <trans-unit id="18d0a71ee91c72fbdd2b834782dff2f0f441f1d5" translate="yes" xml:space="preserve">
          <source>This index signifies the average &amp;lsquo;similarity&amp;rsquo; between clusters, where the similarity is a measure that compares the distance between clusters with the size of the clusters themselves.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0d4ffe805942e66e32866a4eb458e728074d78e" translate="yes" xml:space="preserve">
          <source>This initially creates clusters of points normally distributed (std=1) about vertices of an &lt;code&gt;n_informative&lt;/code&gt;-dimensional hypercube with sides of length &lt;code&gt;2*class_sep&lt;/code&gt; and assigns an equal number of clusters to each class. It introduces interdependence between these features and adds various types of further noise to the data.</source>
          <target state="translated">Esto crea inicialmente grupos de puntos distribuidos normalmente (std = 1) sobre los v&amp;eacute;rtices de un hipercubo &lt;code&gt;n_informative&lt;/code&gt; dimensional con lados de longitud &lt;code&gt;2*class_sep&lt;/code&gt; y asigna un n&amp;uacute;mero igual de grupos a cada clase. Introduce la interdependencia entre estas caracter&amp;iacute;sticas y agrega varios tipos de ruido adicional a los datos.</target>
        </trans-unit>
        <trans-unit id="57108bb9f4ef70d6ebe6d73913a67e52e844d200" translate="yes" xml:space="preserve">
          <source>This interface is &lt;strong&gt;experimental&lt;/strong&gt; and subsequent releases may change attributes without notice (although there should only be minor changes to &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b14c6be212126cf2e3bdc1fe1c6fe8f3c7dc46d" translate="yes" xml:space="preserve">
          <source>This interface is &lt;strong&gt;experimental&lt;/strong&gt; as at version 0.20 and subsequent releases may change attributes without notice (although there should only be minor changes to &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt;).</source>
          <target state="translated">Esta interfaz es &lt;strong&gt;experimental&lt;/strong&gt; en la versi&amp;oacute;n 0.20 y las versiones posteriores pueden cambiar los atributos sin previo aviso (aunque solo debe haber cambios menores en los &lt;code&gt;data&lt;/code&gt; y el &lt;code&gt;target&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="7f6be37b4617684744b3ccc169d2c583b6e3ddc1" translate="yes" xml:space="preserve">
          <source>This is a convenience alias to &lt;code&gt;resample(*arrays, replace=False)&lt;/code&gt; to do random permutations of the collections.</source>
          <target state="translated">Este es un alias conveniente para &lt;code&gt;resample(*arrays, replace=False)&lt;/code&gt; a muestrear (* matrices, replace = False) para realizar permutaciones aleatorias de las colecciones.</target>
        </trans-unit>
        <trans-unit id="4632bc2ee98a17257db1d248b06f38b79a53d4ef" translate="yes" xml:space="preserve">
          <source>This is a convenience function; the transformation is done using the default settings for &lt;a href=&quot;sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt;&lt;/a&gt;. For more advanced usage (stopword filtering, n-gram extraction, etc.), combine fetch_20newsgroups with a custom &lt;a href=&quot;sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.HashingVectorizer&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.TfidfTransformer&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.TfidfVectorizer&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Esta es una funci&amp;oacute;n de conveniencia; la transformaci&amp;oacute;n se realiza utilizando la configuraci&amp;oacute;n predeterminada para &lt;a href=&quot;sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt; &lt;/a&gt; . Para un uso m&amp;aacute;s avanzado (filtrado de palabras vac&amp;iacute;as, extracci&amp;oacute;n de n-gramas, etc.), combine fetch_20newsgroups con &lt;a href=&quot;sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.HashingVectorizer&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.TfidfTransformer&lt;/code&gt; &lt;/a&gt; o &lt;a href=&quot;sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.TfidfVectorizer&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2b3dbf5e1c5e08d66c77786f2bcbc632afc0312a" translate="yes" xml:space="preserve">
          <source>This is a convenience routine for the sake of testing. For many metrics, the utilities in scipy.spatial.distance.cdist and scipy.spatial.distance.pdist will be faster.</source>
          <target state="translated">Esta es una rutina de conveniencia por el bien de la prueba.Para muchas métricas,las utilidades en cdist de distancia espacial de scipy y pdist de distancia espacial de scipy serán más rápidas.</target>
        </trans-unit>
        <trans-unit id="7a67e0a846a2ab3c88cb06fc2b7950cd30914abe" translate="yes" xml:space="preserve">
          <source>This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets. &lt;a href=&quot;https://goo.gl/U2Uwz2&quot;&gt;https://goo.gl/U2Uwz2&lt;/a&gt;</source>
          <target state="translated">&amp;Eacute;sta es una copia de los conjuntos de datos de UCI ML Breast Cancer Wisconsin (Diagnostic). &lt;a href=&quot;https://goo.gl/U2Uwz2&quot;&gt;https://goo.gl/U2Uwz2&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="22bae61d9be3213577df5087cb01b12cfdf8dff4" translate="yes" xml:space="preserve">
          <source>This is a copy of UCI ML Wine recognition datasets. &lt;a href=&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&quot;&gt;https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&lt;/a&gt;</source>
          <target state="translated">Esta es una copia de los conjuntos de datos de reconocimiento de UCI ML Wine. &lt;a href=&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&quot;&gt;https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c52f45448ee0e84b694b7c38bdbed7fd0e586461" translate="yes" xml:space="preserve">
          <source>This is a copy of UCI ML housing dataset. &lt;a href=&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/housing/&quot;&gt;https://archive.ics.uci.edu/ml/machine-learning-databases/housing/&lt;/a&gt;</source>
          <target state="translated">Esta es una copia del conjunto de datos de viviendas de UCI ML. &lt;a href=&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/housing/&quot;&gt;https://archive.ics.uci.edu/ml/machine-learning-databases/housing/&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a6d742ac48191eb71d1c4aabf6003187f0d21a9d" translate="yes" xml:space="preserve">
          <source>This is a copy of the test set of the UCI ML hand-written digits datasets</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3dee2146876159a5a0b048cd24a612fae4a810ca" translate="yes" xml:space="preserve">
          <source>This is a copy of the test set of the UCI ML hand-written digits datasets &lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&quot;&gt;http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&lt;/a&gt;</source>
          <target state="translated">Esta es una copia del conjunto de prueba de los conjuntos de datos de d&amp;iacute;gitos escritos a mano de UCI ML &lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&quot;&gt;http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="60177910f782c7923853f8284b0287f57e3bf220" translate="yes" xml:space="preserve">
          <source>This is a copy of the test set of the UCI ML hand-written digits datasets &lt;a href=&quot;https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&quot;&gt;https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd4a60c08b29c6d6af237f8cfa14740252c7d04a" translate="yes" xml:space="preserve">
          <source>This is a general function, given points on a curve. For computing the area under the ROC-curve, see &lt;a href=&quot;sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt;. For an alternative way to summarize a precision-recall curve, see &lt;a href=&quot;sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Esta es una funci&amp;oacute;n general, dados puntos en una curva. Para calcular el &amp;aacute;rea bajo la curva ROC, consulte &lt;a href=&quot;sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;roc_auc_score&lt;/code&gt; &lt;/a&gt; . Para obtener una forma alternativa de resumir una curva de recuperaci&amp;oacute;n de precisi&amp;oacute;n, consulte &lt;a href=&quot;sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="3944e3eb8c8ea1f918637d2548f35fa74cd97d2a" translate="yes" xml:space="preserve">
          <source>This is a shorthand for the ColumnTransformer constructor; it does not require, and does not permit, naming the transformers. Instead, they will be given names automatically based on their types. It also does not allow weighting with &lt;code&gt;transformer_weights&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37510c6c60985c0ea76b5bcc4364db965e5a12fd" translate="yes" xml:space="preserve">
          <source>This is a shorthand for the ColumnTransformer constructor; it does not require, and does not permit, naming the transformers. Instead, they will be given names automatically based on their types. It also does not allow weighting.</source>
          <target state="translated">Esta es una abreviatura para el constructor del Transformador de Columna;no requiere,ni permite,nombrar a los transformadores.En su lugar,se les dará un nombre automáticamente basado en sus tipos.Tampoco permite la ponderación.</target>
        </trans-unit>
        <trans-unit id="022d95ed0540e35ea0bdce867e9a502603bc5f51" translate="yes" xml:space="preserve">
          <source>This is a shorthand for the FeatureUnion constructor; it does not require, and does not permit, naming the transformers. Instead, they will be given names automatically based on their types. It also does not allow weighting.</source>
          <target state="translated">Esta es una abreviatura para el constructor de FeatureUnion;no requiere,ni permite,nombrar a los transformadores.En su lugar,se les dará un nombre automáticamente basado en sus tipos.Tampoco permite la ponderación.</target>
        </trans-unit>
        <trans-unit id="52a890ca0cc5d284d366294db21e8c380349733e" translate="yes" xml:space="preserve">
          <source>This is a shorthand for the Pipeline constructor; it does not require, and does not permit, naming the estimators. Instead, their names will be set to the lowercase of their types automatically.</source>
          <target state="translated">Esta es una abreviatura para el constructor del oleoducto;no requiere,ni permite,nombrar a los estimadores.En su lugar,sus nombres serán puestos en minúsculas de sus tipos automáticamente.</target>
        </trans-unit>
        <trans-unit id="bcbf4cb6d3eb7ea12d02241a9a60f7a4e6044f4d" translate="yes" xml:space="preserve">
          <source>This is a wrapper for &lt;code&gt;estimator_.predict(X)&lt;/code&gt;.</source>
          <target state="translated">Este es un contenedor para &lt;code&gt;estimator_.predict(X)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="17ebe8027dbbfba976bb150f0e9172e06d0c02ec" translate="yes" xml:space="preserve">
          <source>This is a wrapper for &lt;code&gt;estimator_.score(X, y)&lt;/code&gt;.</source>
          <target state="translated">Este es un contenedor para &lt;code&gt;estimator_.score(X, y)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="602675ab661ad893c615b29b13c1d56146fcfa0b" translate="yes" xml:space="preserve">
          <source>This is an alternative to passing a &lt;code&gt;backend='backend_name'&lt;/code&gt; argument to the &lt;code&gt;Parallel&lt;/code&gt; class constructor. It is particularly useful when calling into library code that uses joblib internally but does not expose the backend argument in its own API.</source>
          <target state="translated">Esta es una alternativa a pasar un argumento &lt;code&gt;backend='backend_name'&lt;/code&gt; al constructor de la clase &lt;code&gt;Parallel&lt;/code&gt; . Es particularmente &amp;uacute;til cuando se llama al c&amp;oacute;digo de la biblioteca que usa joblib internamente pero no expone el argumento de backend en su propia API.</target>
        </trans-unit>
        <trans-unit id="47f9c3947e84bb8a914aa6f2f19cb2c5e42e970f" translate="yes" xml:space="preserve">
          <source>This is an example of &lt;strong&gt;bias/variance tradeoff&lt;/strong&gt;: the larger the ridge &lt;code&gt;alpha&lt;/code&gt; parameter, the higher the bias and the lower the variance.</source>
          <target state="translated">Este es un ejemplo de &lt;strong&gt;compensaci&amp;oacute;n&lt;/strong&gt; de &lt;strong&gt;sesgo / varianza&lt;/strong&gt; : cuanto mayor sea el par&amp;aacute;metro &lt;code&gt;alpha&lt;/code&gt; la cresta , mayor ser&amp;aacute; el sesgo y menor la varianza.</target>
        </trans-unit>
        <trans-unit id="d75c7c933c17fefbabe7c2e292b885d0ecac3a21" translate="yes" xml:space="preserve">
          <source>This is an example of applying &lt;a href=&quot;../../modules/generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;sklearn.decomposition.NMF&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../modules/generated/sklearn.decomposition.latentdirichletallocation#sklearn.decomposition.LatentDirichletAllocation&quot;&gt;&lt;code&gt;sklearn.decomposition.LatentDirichletAllocation&lt;/code&gt;&lt;/a&gt; on a corpus of documents and extract additive models of the topic structure of the corpus. The output is a list of topics, each represented as a list of terms (weights are not shown).</source>
          <target state="translated">Este es un ejemplo de &lt;a href=&quot;../../modules/generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt; &lt;code&gt;sklearn.decomposition.NMF&lt;/code&gt; &lt;/a&gt; aplicar sklearn.decomposition.NMF y &lt;a href=&quot;../../modules/generated/sklearn.decomposition.latentdirichletallocation#sklearn.decomposition.LatentDirichletAllocation&quot;&gt; &lt;code&gt;sklearn.decomposition.LatentDirichletAllocation&lt;/code&gt; &lt;/a&gt; en un corpus de documentos y extraer modelos aditivos de la estructura tem&amp;aacute;tica del corpus. El resultado es una lista de temas, cada uno representado como una lista de t&amp;eacute;rminos (no se muestran los pesos).</target>
        </trans-unit>
        <trans-unit id="53176f2993974522405fa17c9a80a84e38a4969c" translate="yes" xml:space="preserve">
          <source>This is an example showing how scikit-learn can be used for classification using an out-of-core approach: learning from data that doesn&amp;rsquo;t fit into main memory. We make use of an online classifier, i.e., one that supports the partial_fit method, that will be fed with batches of examples. To guarantee that the features space remains the same over time we leverage a HashingVectorizer that will project each example into the same feature space. This is especially useful in the case of text classification where new features (words) may appear in each batch.</source>
          <target state="translated">Este es un ejemplo que muestra c&amp;oacute;mo se puede usar scikit-learn para la clasificaci&amp;oacute;n usando un enfoque fuera del n&amp;uacute;cleo: aprender de datos que no caben en la memoria principal. Hacemos uso de un clasificador en l&amp;iacute;nea, es decir, uno que admita el m&amp;eacute;todo de ajuste parcial, que ser&amp;aacute; alimentado con lotes de ejemplos. Para garantizar que el espacio de funciones siga siendo el mismo a lo largo del tiempo, aprovechamos un HashingVectorizer que proyectar&amp;aacute; cada ejemplo en el mismo espacio de funciones. Esto es especialmente &amp;uacute;til en el caso de la clasificaci&amp;oacute;n de texto donde pueden aparecer nuevas caracter&amp;iacute;sticas (palabras) en cada lote.</target>
        </trans-unit>
        <trans-unit id="1620bf9fc1f7795235eabc8e2a67657eca16390d" translate="yes" xml:space="preserve">
          <source>This is an example showing how scikit-learn can be used to classify documents by topics using a bag-of-words approach. This example uses a scipy.sparse matrix to store the features and demonstrates various classifiers that can efficiently handle sparse matrices.</source>
          <target state="translated">Se trata de un ejemplo que muestra cómo se puede utilizar scikit-learn para clasificar documentos por temas utilizando un enfoque de bolsa de palabras.Este ejemplo utiliza una matriz scipy.sparse para almacenar las características y demuestra varios clasificadores que pueden manejar eficientemente las matrices sparse.</target>
        </trans-unit>
        <trans-unit id="687fdb042e4ef171de769c4722977550577ec678" translate="yes" xml:space="preserve">
          <source>This is an example showing how the scikit-learn can be used to cluster documents by topics using a bag-of-words approach. This example uses a scipy.sparse matrix to store the features instead of standard numpy arrays.</source>
          <target state="translated">Se trata de un ejemplo que muestra cómo se puede utilizar el scikit-learn para agrupar documentos por temas utilizando un enfoque de bolsa de palabras.Este ejemplo utiliza una matriz scipy.sparse para almacenar las características en lugar de las matrices numéricas estándar.</target>
        </trans-unit>
        <trans-unit id="c505c2f7b70a5aa0d5582bdc56a7d9627b32a4d8" translate="yes" xml:space="preserve">
          <source>This is an example showing the prediction latency of various scikit-learn estimators.</source>
          <target state="translated">Este es un ejemplo que muestra la latencia de la predicción de varios estimadores de la ciencia.</target>
        </trans-unit>
        <trans-unit id="9e4f7a05490ee1267f03d9980bace7147baa0b76" translate="yes" xml:space="preserve">
          <source>This is an extension of the algorithm in scipy.stats.mode.</source>
          <target state="translated">Esta es una extensión del algoritmo en modo scipy.stats.</target>
        </trans-unit>
        <trans-unit id="375819c22c211b4c7fc97205acd724c3a575f620" translate="yes" xml:space="preserve">
          <source>This is an implementation that uses the result of the previous model to speed up computations along the set of solutions, making it faster than sequentially calling LogisticRegression for the different parameters. Note that there will be no speedup with liblinear solver, since it does not handle warm-starting.</source>
          <target state="translated">Se trata de una implementación que utiliza el resultado del modelo anterior para acelerar los cómputos a lo largo del conjunto de soluciones,haciéndolo más rápido que llamando secuencialmente a LogisticRegression para los diferentes parámetros.Tenga en cuenta que no habrá aceleración con el solucionador liblineal,ya que no maneja el arranque en caliente.</target>
        </trans-unit>
        <trans-unit id="89098058da4c55a1db96b87aadaa162a0a15baba" translate="yes" xml:space="preserve">
          <source>This is assumed to implement the scikit-learn estimator interface. Either estimator needs to provide a &lt;code&gt;score&lt;/code&gt; function, or &lt;code&gt;scoring&lt;/code&gt; must be passed.</source>
          <target state="translated">Se supone que esto implementa la interfaz del estimador scikit-learn. Cualquiera de los estimadores debe proporcionar una funci&amp;oacute;n de &lt;code&gt;score&lt;/code&gt; o se debe aprobar la &lt;code&gt;scoring&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a9f1a5b0fa7d00ad69170d1ab81bf1031dee11a2" translate="yes" xml:space="preserve">
          <source>This is called a &lt;a href=&quot;../../modules/generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; cross-validation.</source>
          <target state="translated">Esto se denomina &lt;a href=&quot;../../modules/generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt; cruzada de KFold .</target>
        </trans-unit>
        <trans-unit id="2e974743bc0fdffbf7238debaf0ee76bb5a5d9b2" translate="yes" xml:space="preserve">
          <source>This is called cosine similarity, because Euclidean (L2) normalization projects the vectors onto the unit sphere, and their dot product is then the cosine of the angle between the points denoted by the vectors.</source>
          <target state="translated">Esto se denomina similitud de coseno,porque la normalización euclidiana (L2)proyecta los vectores sobre la esfera unitaria,y su producto de puntos es entonces el coseno del ángulo entre los puntos denotados por los vectores.</target>
        </trans-unit>
        <trans-unit id="9b01365512b47448f649e450ddd111360a73cfc3" translate="yes" xml:space="preserve">
          <source>This is called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Curse_of_dimensionality&quot;&gt;curse of dimensionality&lt;/a&gt; and is a core problem that machine learning addresses.</source>
          <target state="translated">Esto se denomina la &lt;a href=&quot;https://en.wikipedia.org/wiki/Curse_of_dimensionality&quot;&gt;maldici&amp;oacute;n de la dimensionalidad&lt;/a&gt; y es un problema central que aborda el aprendizaje autom&amp;aacute;tico.</target>
        </trans-unit>
        <trans-unit id="25e5e11d6a0e13a60841f1cb72db59989d03472f" translate="yes" xml:space="preserve">
          <source>This is currently implemented in the following classes:</source>
          <target state="translated">Esto se aplica actualmente en las siguientes clases:</target>
        </trans-unit>
        <trans-unit id="a774a1be5070f83615f896d6d2ec16ebfbe92e4e" translate="yes" xml:space="preserve">
          <source>This is done in 2 steps:</source>
          <target state="translated">Esto se hace en dos pasos:</target>
        </trans-unit>
        <trans-unit id="0c564a0d4cfad247ff47792f5a12558130a84f0c" translate="yes" xml:space="preserve">
          <source>This is equivalent to fit followed by transform, but more efficiently implemented.</source>
          <target state="translated">Esto equivale a un ajuste seguido de una transformación,pero con una aplicación más eficiente.</target>
        </trans-unit>
        <trans-unit id="831022bba18e9ed70a7a762cd8243e7523afeddb" translate="yes" xml:space="preserve">
          <source>This is especially useful when the whole dataset is too big to fit in memory at once.</source>
          <target state="translated">Esto es especialmente útil cuando el conjunto de datos es demasiado grande para caber en la memoria a la vez.</target>
        </trans-unit>
        <trans-unit id="75c0bef753e28aecf63e47221c52fe362a027981" translate="yes" xml:space="preserve">
          <source>This is implemented as &lt;code&gt;argmax(decision_function(X), axis=1)&lt;/code&gt; which will return the label of the class with most votes by estimators predicting the outcome of a decision for each possible class pair.</source>
          <target state="translated">Esto se implementa como &lt;code&gt;argmax(decision_function(X), axis=1)&lt;/code&gt; que devolver&amp;aacute; la etiqueta de la clase con m&amp;aacute;s votos mediante estimadores que predicen el resultado de una decisi&amp;oacute;n para cada posible par de clases.</target>
        </trans-unit>
        <trans-unit id="9b2a6723fed7b2d139e18e341020f963dc7f8450" translate="yes" xml:space="preserve">
          <source>This is implemented by linking the points X into the graph of geodesic distances of the training data. First the &lt;code&gt;n_neighbors&lt;/code&gt; nearest neighbors of X are found in the training data, and from these the shortest geodesic distances from each point in X to each point in the training data are computed in order to construct the kernel. The embedding of X is the projection of this kernel onto the embedding vectors of the training set.</source>
          <target state="translated">Esto se implementa vinculando los puntos X en el gr&amp;aacute;fico de distancias geod&amp;eacute;sicas de los datos de entrenamiento. Primero, los &lt;code&gt;n_neighbors&lt;/code&gt; vecinos m&amp;aacute;s cercanos de X se encuentran en los datos de entrenamiento, y a partir de estos, se calculan las distancias geod&amp;eacute;sicas m&amp;aacute;s cortas desde cada punto en X a cada punto en los datos de entrenamiento para construir el n&amp;uacute;cleo. La incrustaci&amp;oacute;n de X es la proyecci&amp;oacute;n de este n&amp;uacute;cleo en los vectores de incrustaci&amp;oacute;n del conjunto de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="51ae8a82b3eff6fb295f70aa28171d41c73ac3db" translate="yes" xml:space="preserve">
          <source>This is implemented in &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.transform&lt;/code&gt;&lt;/a&gt;. The desired dimensionality can be set using the &lt;code&gt;n_components&lt;/code&gt; constructor parameter. This parameter has no influence on &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.fit&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.predict&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Esto se implementa en &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.transform&lt;/code&gt; &lt;/a&gt; . La dimensionalidad deseada se puede establecer utilizando el par&amp;aacute;metro constructor &lt;code&gt;n_components&lt;/code&gt; . Este par&amp;aacute;metro no tiene influencia en &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.fit&lt;/code&gt; &lt;/a&gt; o &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.predict&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="8989f9efb82b77a4f24da08f40263dc49964cf0b" translate="yes" xml:space="preserve">
          <source>This is implemented in the &lt;code&gt;transform&lt;/code&gt; method. The desired dimensionality can be set using the &lt;code&gt;n_components&lt;/code&gt; parameter. This parameter has no influence on the &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt; methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de8220f3c95931fc4241bdd5334e66fca04da2f0" translate="yes" xml:space="preserve">
          <source>This is known as &lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Esto se conoce como &lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="1c0b6d6227299e9452904f2af6316a83adba923a" translate="yes" xml:space="preserve">
          <source>This is minimized if \(h(x_i)\) is fitted to predict a value that is proportional to the negative gradient \(-g_i\). Therefore, at each iteration, &lt;strong&gt;the estimator&lt;/strong&gt;\(h_m\)&lt;strong&gt;is fitted to predict the negative gradients of the samples&lt;/strong&gt;. The gradients are updated at each iteration. This can be considered as some kind of gradient descent in a functional space.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d1ef16c8ffe6df8c7a1a81b132f67cdda1b92ea" translate="yes" xml:space="preserve">
          <source>This is more efficient than calling fit followed by transform.</source>
          <target state="translated">Esto es más eficiente que el llamado ajuste seguido de la transformación.</target>
        </trans-unit>
        <trans-unit id="1dfb3afc660617ced3002fefa24847b5bb1a14dd" translate="yes" xml:space="preserve">
          <source>This is mostly equivalent to calling:</source>
          <target state="translated">Esto es mayormente equivalente a llamar:</target>
        </trans-unit>
        <trans-unit id="bbd51f304b678a157464ff7ab03c52123d04218d" translate="yes" xml:space="preserve">
          <source>This is not a symmetric function.</source>
          <target state="translated">Esta no es una función simétrica.</target>
        </trans-unit>
        <trans-unit id="0b5c42967b0e34c52656dd80a4e659c6f0fa2181" translate="yes" xml:space="preserve">
          <source>This is not exactly the same as &lt;code&gt;sklearn.metrics.additive_chi2_kernel&lt;/code&gt;. The authors of &lt;a href=&quot;#vz2010&quot; id=&quot;id4&quot;&gt;[VZ2010]&lt;/a&gt; prefer the version above as it is always positive definite. Since the kernel is additive, it is possible to treat all components \(x_i\) separately for embedding. This makes it possible to sample the Fourier transform in regular intervals, instead of approximating using Monte Carlo sampling.</source>
          <target state="translated">Esto no es exactamente lo mismo que &lt;code&gt;sklearn.metrics.additive_chi2_kernel&lt;/code&gt; . Los autores de &lt;a href=&quot;#vz2010&quot; id=&quot;id4&quot;&gt;[VZ2010]&lt;/a&gt; prefieren la versi&amp;oacute;n anterior ya que siempre es positiva definida. Dado que el n&amp;uacute;cleo es aditivo, es posible tratar todos los componentes \ (x_i \) por separado para la incrustaci&amp;oacute;n. Esto hace posible muestrear la transformada de Fourier en intervalos regulares, en lugar de realizar una aproximaci&amp;oacute;n utilizando el muestreo de Monte Carlo.</target>
        </trans-unit>
        <trans-unit id="f7f802fcac19c1c8ed1c55f673312d761a2c94a7" translate="yes" xml:space="preserve">
          <source>This is not the case for &lt;a href=&quot;generated/sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt;&lt;code&gt;completeness_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt;&lt;code&gt;homogeneity_score&lt;/code&gt;&lt;/a&gt;: both are bound by the relationship:</source>
          <target state="translated">Este no es el caso de &lt;a href=&quot;generated/sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt; &lt;code&gt;completeness_score&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt; &lt;code&gt;homogeneity_score&lt;/code&gt; &lt;/a&gt; : ambos est&amp;aacute;n vinculados por la relaci&amp;oacute;n:</target>
        </trans-unit>
        <trans-unit id="5d73f5b087f2ecb2dadb8778d3d18cfc19507034" translate="yes" xml:space="preserve">
          <source>This is not true for &lt;code&gt;mutual_info_score&lt;/code&gt;, which is therefore harder to judge:</source>
          <target state="translated">Esto no es cierto para &lt;code&gt;mutual_info_score&lt;/code&gt; , que por lo tanto es m&amp;aacute;s dif&amp;iacute;cil de juzgar:</target>
        </trans-unit>
        <trans-unit id="982101a3d677907e48e034c807cde26531a0468b" translate="yes" xml:space="preserve">
          <source>This is only available if no vocabulary was given.</source>
          <target state="translated">Esto sólo está disponible si no se ha dado ningún vocabulario.</target>
        </trans-unit>
        <trans-unit id="0ca1a333516e3b52907835d092958662636ea528" translate="yes" xml:space="preserve">
          <source>This is particularly important for doing grid searches:</source>
          <target state="translated">Esto es particularmente importante para hacer búsquedas de cuadrículas:</target>
        </trans-unit>
        <trans-unit id="2413be66af5e312ff97e484aff33c56868971fbe" translate="yes" xml:space="preserve">
          <source>This is perhaps the best known database to be found in the pattern recognition literature. Fisher&amp;rsquo;s paper is a classic in the field and is referenced frequently to this day. (See Duda &amp;amp; Hart, for example.) The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other.</source>
          <target state="translated">Esta es quiz&amp;aacute;s la base de datos m&amp;aacute;s conocida que se puede encontrar en la literatura sobre reconocimiento de patrones. El art&amp;iacute;culo de Fisher es un cl&amp;aacute;sico en el campo y se hace referencia con frecuencia hasta el d&amp;iacute;a de hoy. (Ver Duda &amp;amp; Hart, por ejemplo.) El conjunto de datos contiene 3 clases de 50 instancias cada una, donde cada clase se refiere a un tipo de planta de iris. Una clase es linealmente separable de las otras 2; estos &amp;uacute;ltimos NO son linealmente separables entre s&amp;iacute;.</target>
        </trans-unit>
        <trans-unit id="32ef6d8e689e0cbccf726fb7a94339c2864c487f" translate="yes" xml:space="preserve">
          <source>This is present only if &lt;code&gt;refit&lt;/code&gt; is not False.</source>
          <target state="translated">Esto est&amp;aacute; presente solo si el &lt;code&gt;refit&lt;/code&gt; no es Falso.</target>
        </trans-unit>
        <trans-unit id="717414c2af196799a3d1dc1aec1269a995318377" translate="yes" xml:space="preserve">
          <source>This is similar to the error set size, but weighted by the number of relevant and irrelevant labels. The best performance is achieved with a ranking loss of zero.</source>
          <target state="translated">Esto es similar al tamaño del conjunto de errores,pero ponderado por el número de etiquetas relevantes e irrelevantes.El mejor rendimiento se logra con una pérdida de clasificación de cero.</target>
        </trans-unit>
        <trans-unit id="00034266cafd87d919959c8134650d981f2c4466" translate="yes" xml:space="preserve">
          <source>This is the class and function reference of scikit-learn. Please refer to the &lt;a href=&quot;http://scikit-learn.org/stable/user_guide.html#user-guide&quot;&gt;full user guide&lt;/a&gt; for further details, as the class and function raw specifications may not be enough to give full guidelines on their uses. For reference on concepts repeated across the API, see &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#glossary&quot;&gt;Glossary of Common Terms and API Elements&lt;/a&gt;.</source>
          <target state="translated">Esta es la referencia de clase y funci&amp;oacute;n de scikit-learn. Consulte la &lt;a href=&quot;http://scikit-learn.org/stable/user_guide.html#user-guide&quot;&gt;gu&amp;iacute;a del usuario completa&lt;/a&gt; para obtener m&amp;aacute;s detalles, ya que las especificaciones en bruto de la clase y la funci&amp;oacute;n pueden no ser suficientes para brindar pautas completas sobre sus usos. Para obtener referencia sobre conceptos repetidos en la API, consulte &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#glossary&quot;&gt;Glosario de t&amp;eacute;rminos comunes y elementos de API&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0706513e1a92902a9b1d8477404304aebd12678b" translate="yes" xml:space="preserve">
          <source>This is the class and function reference of scikit-learn. Please refer to the &lt;a href=&quot;https://scikit-learn.org/0.23/user_guide.html#user-guide&quot;&gt;full user guide&lt;/a&gt; for further details, as the class and function raw specifications may not be enough to give full guidelines on their uses. For reference on concepts repeated across the API, see &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#glossary&quot;&gt;Glossary of Common Terms and API Elements&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="486cb190a77f54ef106791f7b4834d94d87b42d4" translate="yes" xml:space="preserve">
          <source>This is the loss function used in (multinomial) logistic regression and extensions of it such as neural networks, defined as the negative log-likelihood of a logistic model that returns &lt;code&gt;y_pred&lt;/code&gt; probabilities for its training data &lt;code&gt;y_true&lt;/code&gt;. The log loss is only defined for two or more labels. For a single sample with true label yt in {0,1} and estimated probability yp that yt = 1, the log loss is</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c0b38fb17b983574b86706f2172c4c4bac1c6a5" translate="yes" xml:space="preserve">
          <source>This is the loss function used in (multinomial) logistic regression and extensions of it such as neural networks, defined as the negative log-likelihood of the true labels given a probabilistic classifier&amp;rsquo;s predictions. The log loss is only defined for two or more labels. For a single sample with true label yt in {0,1} and estimated probability yp that yt = 1, the log loss is</source>
          <target state="translated">Esta es la funci&amp;oacute;n de p&amp;eacute;rdida utilizada en la regresi&amp;oacute;n log&amp;iacute;stica (multinomial) y sus extensiones, como las redes neuronales, definida como la probabilidad logar&amp;iacute;tmica negativa de las etiquetas verdaderas dadas las predicciones de un clasificador probabil&amp;iacute;stico. La p&amp;eacute;rdida de registros solo se define para dos o m&amp;aacute;s etiquetas. Para una sola muestra con etiqueta verdadera yt en {0,1} y probabilidad estimada yp de que yt = 1, la p&amp;eacute;rdida logar&amp;iacute;tmica es</target>
        </trans-unit>
        <trans-unit id="a9111de5c7f4d9db0e2dc4faf926c5c47ae0eb12" translate="yes" xml:space="preserve">
          <source>This is the result of calling &lt;code&gt;method&lt;/code&gt;</source>
          <target state="translated">Este es el resultado de llamar al &lt;code&gt;method&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="611492c50f944d397ce592f12eabee4801e28de1" translate="yes" xml:space="preserve">
          <source>This is the structured version, that takes into account some topological structure between samples.</source>
          <target state="translated">Esta es la versión estructurada,que tiene en cuenta cierta estructura topológica entre las muestras.</target>
        </trans-unit>
        <trans-unit id="eb0a6c68cdbb70ef7265210b8b8760243faa6912" translate="yes" xml:space="preserve">
          <source>This is useful for fitting an intercept term with implementations which cannot otherwise fit it directly.</source>
          <target state="translated">Esto es útil para ajustar un término de intercepción con implementaciones que de otra manera no pueden ajustarlo directamente.</target>
        </trans-unit>
        <trans-unit id="1c420e62ce6697ac415dbca5798c0153080b025c" translate="yes" xml:space="preserve">
          <source>This is useful if the stored attributes of a previously used model has to be reused. If set to False, then the coefficients will be rewritten for every call to fit. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Esto es &amp;uacute;til si los atributos almacenados de un modelo usado previamente deben reutilizarse. Si se establece en False, los coeficientes se reescribir&amp;aacute;n para que cada llamada se ajuste. Consulte &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;el glosario&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="036c7996302f5b904a8b61c47c147a7a9733676a" translate="yes" xml:space="preserve">
          <source>This is useful if the stored attributes of a previously used model has to be reused. If set to False, then the coefficients will be rewritten for every call to fit. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2abc93ddea964d3eb32a39867456d5dfe5ef9180" translate="yes" xml:space="preserve">
          <source>This is visible if we compare the standard deviations of different features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42f2c0052d88e51f5df6c26752c192f81040ec01" translate="yes" xml:space="preserve">
          <source>This kernel is a popular choice for computing the similarity of documents represented as tf-idf vectors. &lt;a href=&quot;generated/sklearn.metrics.pairwise.cosine_similarity#sklearn.metrics.pairwise.cosine_similarity&quot;&gt;&lt;code&gt;cosine_similarity&lt;/code&gt;&lt;/a&gt; accepts &lt;code&gt;scipy.sparse&lt;/code&gt; matrices. (Note that the tf-idf functionality in &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; can produce normalized vectors, in which case &lt;a href=&quot;generated/sklearn.metrics.pairwise.cosine_similarity#sklearn.metrics.pairwise.cosine_similarity&quot;&gt;&lt;code&gt;cosine_similarity&lt;/code&gt;&lt;/a&gt; is equivalent to &lt;a href=&quot;generated/sklearn.metrics.pairwise.linear_kernel#sklearn.metrics.pairwise.linear_kernel&quot;&gt;&lt;code&gt;linear_kernel&lt;/code&gt;&lt;/a&gt;, only slower.)</source>
          <target state="translated">Este kernel es una opci&amp;oacute;n popular para calcular la similitud de documentos representados como vectores tf-idf. &lt;a href=&quot;generated/sklearn.metrics.pairwise.cosine_similarity#sklearn.metrics.pairwise.cosine_similarity&quot;&gt; &lt;code&gt;cosine_similarity&lt;/code&gt; &lt;/a&gt; acepta matrices &lt;code&gt;scipy.sparse&lt;/code&gt; . (Tenga en cuenta que la funcionalidad tf-idf en &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; puede producir vectores normalizados, en cuyo caso &lt;a href=&quot;generated/sklearn.metrics.pairwise.cosine_similarity#sklearn.metrics.pairwise.cosine_similarity&quot;&gt; &lt;code&gt;cosine_similarity&lt;/code&gt; &lt;/a&gt; es equivalente a &lt;a href=&quot;generated/sklearn.metrics.pairwise.linear_kernel#sklearn.metrics.pairwise.linear_kernel&quot;&gt; &lt;code&gt;linear_kernel&lt;/code&gt; &lt;/a&gt; , solo que m&amp;aacute;s lento).</target>
        </trans-unit>
        <trans-unit id="f1fbcea40cf4aba903be6eddf36c859a1718e3b8" translate="yes" xml:space="preserve">
          <source>This kernel is infinitely differentiable, which implies that GPs with this kernel as covariance function have mean square derivatives of all orders, and are thus very smooth.</source>
          <target state="translated">Este núcleo es infinitamente diferenciable,lo que implica que los GP con este núcleo como función de covarianza tienen derivados cuadrados medios de todos los órdenes,y por lo tanto son muy suaves.</target>
        </trans-unit>
        <trans-unit id="ffa176d62610a7e6d304ab9efadadddacf7fa00e" translate="yes" xml:space="preserve">
          <source>This kernel is infinitely differentiable, which implies that GPs with this kernel as covariance function have mean square derivatives of all orders, and are thus very smooth. See &lt;a href=&quot;#redc669bcbe98-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt;, Chapter 4, Section 4.2, for further details of the RBF kernel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ad60f9f3ef06c9a3898414b0afc593eaff20c1d" translate="yes" xml:space="preserve">
          <source>This kernel is infinitely differentiable, which implies that GPs with this kernel as covariance function have mean square derivatives of all orders, and are thus very smooth. The prior and posterior of a GP resulting from an RBF kernel are shown in the following figure:</source>
          <target state="translated">Este núcleo es infinitamente diferenciable,lo que implica que los GP con este núcleo como función de covarianza tienen derivados cuadrados medios de todos los órdenes,y por lo tanto son muy suaves.El anterior y posterior de un GP resultante de un núcleo RBF se muestran en la siguiente figura:</target>
        </trans-unit>
        <trans-unit id="6cbded70a18b870dfff7fda8d59e204ebd77900f" translate="yes" xml:space="preserve">
          <source>This kind of singular profiles is often seen in practice, for instance:</source>
          <target state="translated">Este tipo de perfiles singulares se ve a menudo en la práctica,por ejemplo:</target>
        </trans-unit>
        <trans-unit id="30529b10016c80d5c9ab1e213672fabc65487573" translate="yes" xml:space="preserve">
          <source>This last point is expected due to the nature of the problem: the occurrence of accidents is mostly dominated by circumstantial causes that are not captured in the columns of the dataset and can indeed be considered as purely random.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1df4414d1e47e9ea41e98b8c6e13b5eeb49e06ac" translate="yes" xml:space="preserve">
          <source>This left out portion can be used to estimate the generalization error without having to rely on a separate validation set. This estimate comes &amp;ldquo;for free&amp;rdquo; as no additional data is needed and can be used for model selection.</source>
          <target state="translated">Esta parte omitida se puede utilizar para estimar el error de generalizaci&amp;oacute;n sin tener que depender de un conjunto de validaci&amp;oacute;n independiente. Esta estimaci&amp;oacute;n viene &quot;gratis&quot; ya que no se necesitan datos adicionales y se puede utilizar para la selecci&amp;oacute;n del modelo.</target>
        </trans-unit>
        <trans-unit id="4f52c7809ab985057ba93af9b88459b0d10b33a2" translate="yes" xml:space="preserve">
          <source>This makes sure that the loss function is not heavily influenced by the outliers while not completely ignoring their effect.</source>
          <target state="translated">Esto asegura que la función de pérdida no esté fuertemente influenciada por los valores atípicos,sin ignorar completamente su efecto.</target>
        </trans-unit>
        <trans-unit id="2fb338a66a8f54901bcaa2314035cd86710a7d6d" translate="yes" xml:space="preserve">
          <source>This means each coefficient \(w_{i}\) is drawn from a Gaussian distribution, centered on zero and with a precision \(\lambda_{i}\):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4826ff4b754b03a246d73c38aa2c971ffdf335e1" translate="yes" xml:space="preserve">
          <source>This means each weight \(w_{i}\) is drawn from a Gaussian distribution, centered on zero and with a precision \(\lambda_{i}\):</source>
          <target state="translated">Esto significa que cada peso se extrae de una distribución gaussiana,centrada en el cero y con una precisión:</target>
        </trans-unit>
        <trans-unit id="de2308f740624c092eea038ac13deb5af2b1fa80" translate="yes" xml:space="preserve">
          <source>This means that any classifiers handling multi-output multiclass or multi-task classification tasks, support the multi-label classification task as a special case. Multi-task classification is similar to the multi-output classification task with different model formulations. For more information, see the relevant estimator documentation.</source>
          <target state="translated">Esto significa que cualquier clasificador que se ocupe de tareas de clasificación de salida múltiple o de tareas múltiples,apoyará la tarea de clasificación de etiquetas múltiples como un caso especial.La clasificación multitarea es similar a la tarea de clasificación multi-salida con diferentes formulaciones de modelos.Para obtener más información,véase la documentación pertinente del estimador.</target>
        </trans-unit>
        <trans-unit id="6157bc0b8c2f67c8a593bf2d12852c000be43e72" translate="yes" xml:space="preserve">
          <source>This measure is not adjusted for chance. Therefore &lt;a href=&quot;sklearn.metrics.adjusted_mutual_info_score#sklearn.metrics.adjusted_mutual_info_score&quot;&gt;&lt;code&gt;adjusted_mutual_info_score&lt;/code&gt;&lt;/a&gt; might be preferred.</source>
          <target state="translated">Esta medida no se ajusta al azar. Por lo tanto, se podr&amp;iacute;a preferir la puntuaci&amp;oacute;n_informaci&amp;oacute;n_mutual &lt;a href=&quot;sklearn.metrics.adjusted_mutual_info_score#sklearn.metrics.adjusted_mutual_info_score&quot;&gt; &lt;code&gt;adjusted_mutual_info_score&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="cca48ea1404a91d2df7b18cac656df30067cb12b" translate="yes" xml:space="preserve">
          <source>This method allows monitoring (i.e. determine error on testing set) after each boosting iteration.</source>
          <target state="translated">Este método permite la supervisión (es decir,determinar el error en el conjunto de pruebas)después de cada iteración de impulso.</target>
        </trans-unit>
        <trans-unit id="778da8cdceb825f45e49260c13130972c415ba18" translate="yes" xml:space="preserve">
          <source>This method allows monitoring (i.e. determine error on testing set) after each stage.</source>
          <target state="translated">Este método permite la supervisión (es decir,determinar el error en el conjunto de pruebas)después de cada etapa.</target>
        </trans-unit>
        <trans-unit id="893e20b8eaafff147aad0ee519c22b2be0783798" translate="yes" xml:space="preserve">
          <source>This method allows to generalize prediction to &lt;em&gt;new observations&lt;/em&gt; (not in the training set). Only available for novelty detection (when novelty is set to True).</source>
          <target state="translated">Este m&amp;eacute;todo permite generalizar la predicci&amp;oacute;n a &lt;em&gt;nuevas observaciones&lt;/em&gt; (no en el conjunto de entrenamiento). Solo disponible para la detecci&amp;oacute;n de novedades (cuando la novedad se establece en Verdadero).</target>
        </trans-unit>
        <trans-unit id="e13bbab31202d773dbd5b155d7e0b7799ca54f84" translate="yes" xml:space="preserve">
          <source>This method computes the least squares solution using a singular value decomposition of X. If X is a matrix of size (n, p) this method has a cost of \(O(n p^2)\), assuming that \(n \geq p\).</source>
          <target state="translated">Este método calcula la solución de mínimos cuadrados usando un valor de descomposición singular de X.Si X es una matriz de tamaño (n,p)este método tiene un costo de \(O(n p^2)\),asumiendo que \ ~ (n \ ~ geq p).</target>
        </trans-unit>
        <trans-unit id="dc0919b0c811a79ed295c00492df459fa5ab93e8" translate="yes" xml:space="preserve">
          <source>This method doesn&amp;rsquo;t do anything. It exists purely for compatibility with the scikit-learn transformer API.</source>
          <target state="translated">Este m&amp;eacute;todo no hace nada. Existe &amp;uacute;nicamente por compatibilidad con la API del transformador de scikit-learn.</target>
        </trans-unit>
        <trans-unit id="89035c0aee87e0125ffcf7bf5f0dbe56fcfb74a9" translate="yes" xml:space="preserve">
          <source>This method has some performance and numerical stability overhead, hence it is better to call partial_fit on chunks of data that are as large as possible (as long as fitting in the memory budget) to hide the overhead.</source>
          <target state="translated">Este método tiene cierto rendimiento y estabilidad numérica en la sobrecarga,por lo que es mejor llamar a partial_fit en trozos de datos que sean lo más grandes posible (siempre y cuando se ajusten al presupuesto de memoria)para ocultar la sobrecarga.</target>
        </trans-unit>
        <trans-unit id="a344504140059db6f88458066c961354f795c6a7" translate="yes" xml:space="preserve">
          <source>This method has some performance overhead hence it is better to call partial_fit on chunks of data that are as large as possible (as long as fitting in the memory budget) to hide the overhead.</source>
          <target state="translated">Este método tiene cierta sobrecarga de rendimiento,por lo que es mejor llamar a partial_fit en trozos de datos que sean lo más grandes posible (siempre y cuando se ajusten al presupuesto de memoria)para ocultar la sobrecarga.</target>
        </trans-unit>
        <trans-unit id="03d61ee68976e414aa4354d3a63287b0819f990d" translate="yes" xml:space="preserve">
          <source>This method has the same order of complexity as &lt;a href=&quot;#ordinary-least-squares&quot;&gt;Ordinary Least Squares&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ceeeb1e178fb9959d4ffe786c9917a8fc68013bb" translate="yes" xml:space="preserve">
          <source>This method has the same order of complexity than an &lt;a href=&quot;#ordinary-least-squares&quot;&gt;Ordinary Least Squares&lt;/a&gt;.</source>
          <target state="translated">Este m&amp;eacute;todo tiene el mismo orden de complejidad que un &lt;a href=&quot;#ordinary-least-squares&quot;&gt;M&amp;iacute;nimo Cuadrado Ordinario&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="8149d43c4db3023940e20ddee18dfd4caaeb24b1" translate="yes" xml:space="preserve">
          <source>This method is expected to be called several times consecutively on different chunks of a dataset so as to implement out-of-core or online learning.</source>
          <target state="translated">Se espera que se llame a este método varias veces consecutivas en diferentes trozos de un conjunto de datos para poner en práctica el aprendizaje fuera del núcleo o en línea.</target>
        </trans-unit>
        <trans-unit id="7914e16bc2009e2d4fc76b2006a65a031a42eb76" translate="yes" xml:space="preserve">
          <source>This method is just there to implement the usual API and hence work in pipelines.</source>
          <target state="translated">Este método sólo está ahí para implementar el API habitual y,por lo tanto,trabajar en los oleoductos.</target>
        </trans-unit>
        <trans-unit id="53a4e9f6af590018ff1a37b6f68db2405dd79282" translate="yes" xml:space="preserve">
          <source>This method is just there to mark the fact that this transformer can work in a streaming setup.</source>
          <target state="translated">Este método está ahí para marcar el hecho de que este transformador puede funcionar en una configuración de streaming.</target>
        </trans-unit>
        <trans-unit id="1ad1f3e2c791502dcf55d0ea0c930c86843ade76" translate="yes" xml:space="preserve">
          <source>This method is meant to be called concurrently by the multiprocessing callback. We rely on the thread-safety of dispatch_one_batch to protect against concurrent consumption of the unprotected iterator.</source>
          <target state="translated">Este método está pensado para ser llamado simultáneamente por la llamada de multiprocesamiento.Nos basamos en la seguridad de los hilos de dispatch_one_batch para protegerse contra el consumo simultáneo del iterador desprotegido.</target>
        </trans-unit>
        <trans-unit id="4e81340dab29281a8d6b3bd99833383bb408f46c" translate="yes" xml:space="preserve">
          <source>This method is not deterministic: it computes a quantity called the free energy on X, then on a randomly corrupted version of X, and returns the log of the logistic function of the difference.</source>
          <target state="translated">Este método no es determinista:computa una cantidad llamada la energía libre en X,luego en una versión aleatoriamente corrompida de X,y devuelve el registro de la función logística de la diferencia.</target>
        </trans-unit>
        <trans-unit id="483c17ab697933f17e74386d9739e36cf3fc93e7" translate="yes" xml:space="preserve">
          <source>This method is only available for log loss and modified Huber loss.</source>
          <target state="translated">Este método sólo está disponible para la pérdida de registros y la pérdida de Huber modificada.</target>
        </trans-unit>
        <trans-unit id="d7475ebc10f647671bee9a4be7afee1b81279276" translate="yes" xml:space="preserve">
          <source>This method provides a safe way to take a distance matrix as input, while preserving compatibility with many other algorithms that take a vector array.</source>
          <target state="translated">Este método proporciona una forma segura de tomar una matriz de distancia como entrada,a la vez que preserva la compatibilidad con muchos otros algoritmos que toman una matriz vectorial.</target>
        </trans-unit>
        <trans-unit id="b5d8e2fef5ebecb0c66f96f2926a64438412f355" translate="yes" xml:space="preserve">
          <source>This method provides a safe way to take a kernel matrix as input, while preserving compatibility with many other algorithms that take a vector array.</source>
          <target state="translated">Este método proporciona una forma segura de tomar una matriz de núcleo como entrada,a la vez que preserva la compatibilidad con muchos otros algoritmos que toman una matriz de vectores.</target>
        </trans-unit>
        <trans-unit id="c662dd229414f848149c194436efac32b71db4c2" translate="yes" xml:space="preserve">
          <source>This method returns a Fortran-ordered array. To convert it to a C-ordered array, use &amp;lsquo;np.ascontiguousarray&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fc2db598aaa9c1a0947d8f73a1238d30285a532" translate="yes" xml:space="preserve">
          <source>This method takes either a vector array or a distance matrix, and returns a distance matrix. If the input is a vector array, the distances are computed. If the input is a distances matrix, it is returned instead.</source>
          <target state="translated">Este método toma una matriz de vectores o una matriz de distancia y devuelve una matriz de distancia.Si la entrada es una matriz vectorial,se calculan las distancias.Si la entrada es una matriz de distancias,se devuelve en su lugar.</target>
        </trans-unit>
        <trans-unit id="924736c0bae89c3f4376281e6a105fa549739eb4" translate="yes" xml:space="preserve">
          <source>This method takes either a vector array or a kernel matrix, and returns a kernel matrix. If the input is a vector array, the kernels are computed. If the input is a kernel matrix, it is returned instead.</source>
          <target state="translated">Este método toma una matriz vectorial o una matriz de núcleo y devuelve una matriz de núcleo.Si la entrada es una matriz vectorial,se calculan los núcleos.Si la entrada es una matriz de núcleo,se devuelve en su lugar.</target>
        </trans-unit>
        <trans-unit id="b80df7fbbffdde8aff9c30af4a5bee17e602075b" translate="yes" xml:space="preserve">
          <source>This method transforms the features to follow a uniform or a normal distribution. Therefore, for a given feature, this transformation tends to spread out the most frequent values. It also reduces the impact of (marginal) outliers: this is therefore a robust preprocessing scheme.</source>
          <target state="translated">Este método transforma las características para seguir una distribución uniforme o normal.Por lo tanto,para un rasgo dado,esta transformación tiende a extender los valores más frecuentes.También reduce el impacto de los valores atípicos (marginales):se trata,por tanto,de un sólido esquema de preprocesamiento.</target>
        </trans-unit>
        <trans-unit id="88cc56a80a6739c5287afd3119dab66fa95d86a9" translate="yes" xml:space="preserve">
          <source>This method will raise a &lt;code&gt;ValueError&lt;/code&gt; if any of the estimators do not have &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a6448f2646e45809baed97b35289a513191212b" translate="yes" xml:space="preserve">
          <source>This method works similarly to the builtin &lt;code&gt;apply&lt;/code&gt;, except that the function is called only if the cache is not up to date.</source>
          <target state="translated">Este m&amp;eacute;todo funciona de manera similar a la &lt;code&gt;apply&lt;/code&gt; incorporada , excepto que la funci&amp;oacute;n se llama solo si el cach&amp;eacute; no est&amp;aacute; actualizado.</target>
        </trans-unit>
        <trans-unit id="3b270b097c02b54b15c6706faba2a05992e48391" translate="yes" xml:space="preserve">
          <source>This metric is furthermore symmetric: switching &lt;code&gt;label_true&lt;/code&gt; with &lt;code&gt;label_pred&lt;/code&gt; will return the same score value. This can be useful to measure the agreement of two independent label assignments strategies on the same dataset when the real ground truth is not known.</source>
          <target state="translated">Adem&amp;aacute;s, esta m&amp;eacute;trica es sim&amp;eacute;trica: cambiar &lt;code&gt;label_true&lt;/code&gt; con &lt;code&gt;label_pred&lt;/code&gt; devolver&amp;aacute; el mismo valor de puntuaci&amp;oacute;n. Esto puede ser &amp;uacute;til para medir la concordancia de dos estrategias de asignaci&amp;oacute;n de etiquetas independientes en el mismo conjunto de datos cuando no se conoce la verdad del terreno real.</target>
        </trans-unit>
        <trans-unit id="b8da4b4fabd4786b82c03e2c15a17659173e15c8" translate="yes" xml:space="preserve">
          <source>This metric is independent of the absolute values of the labels: a permutation of the class or cluster label values won&amp;rsquo;t change the score value in any way.</source>
          <target state="translated">Esta m&amp;eacute;trica es independiente de los valores absolutos de las etiquetas: una permutaci&amp;oacute;n de los valores de la etiqueta de clase o cl&amp;uacute;ster no cambiar&amp;aacute; el valor de la puntuaci&amp;oacute;n de ninguna manera.</target>
        </trans-unit>
        <trans-unit id="bfbb6fef2be45da43d1153172735208301268ab3" translate="yes" xml:space="preserve">
          <source>This metric is not symmetric: switching &lt;code&gt;label_true&lt;/code&gt; with &lt;code&gt;label_pred&lt;/code&gt; will return the &lt;a href=&quot;sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt;&lt;code&gt;completeness_score&lt;/code&gt;&lt;/a&gt; which will be different in general.</source>
          <target state="translated">Esta m&amp;eacute;trica no es sim&amp;eacute;trica: cambiar &lt;code&gt;label_true&lt;/code&gt; con &lt;code&gt;label_pred&lt;/code&gt; devolver&amp;aacute; el &lt;a href=&quot;sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt; &lt;code&gt;completeness_score&lt;/code&gt; &lt;/a&gt; que ser&amp;aacute; diferente en general.</target>
        </trans-unit>
        <trans-unit id="d6ecae2ce63387462768b5daf2f548b32eba4de4" translate="yes" xml:space="preserve">
          <source>This metric is not symmetric: switching &lt;code&gt;label_true&lt;/code&gt; with &lt;code&gt;label_pred&lt;/code&gt; will return the &lt;a href=&quot;sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt;&lt;code&gt;homogeneity_score&lt;/code&gt;&lt;/a&gt; which will be different in general.</source>
          <target state="translated">Esta m&amp;eacute;trica no es sim&amp;eacute;trica: cambiar &lt;code&gt;label_true&lt;/code&gt; con &lt;code&gt;label_pred&lt;/code&gt; devolver&amp;aacute; el &lt;a href=&quot;sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt; &lt;code&gt;homogeneity_score&lt;/code&gt; &lt;/a&gt; que ser&amp;aacute; diferente en general.</target>
        </trans-unit>
        <trans-unit id="b4ddf27eda44a85481c7034e578198a043591cb2" translate="yes" xml:space="preserve">
          <source>This metric is not well-defined for single samples and will return a NaN value if n_samples is less than two.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3d29b108d9b9b14881da7a1115d336ab614cf19" translate="yes" xml:space="preserve">
          <source>This metric is used in multilabel ranking problem, where the goal is to give better rank to the labels associated to each sample.</source>
          <target state="translated">Esta métrica se utiliza en el problema de la clasificación de etiquetas múltiples,en el que el objetivo es dar una mejor clasificación a las etiquetas asociadas a cada muestra.</target>
        </trans-unit>
        <trans-unit id="aca1523dd1402afa978fd168a95010ba6eea69bb" translate="yes" xml:space="preserve">
          <source>This might be clearer with an example: consider a three class problem with class 0 having three support vectors \(v^{0}_0, v^{1}_0, v^{2}_0\) and class 1 and 2 having two support vectors \(v^{0}_1, v^{1}_1\) and \(v^{0}_2, v^{1}_2\) respectively. For each support vector \(v^{j}_i\), there are two dual coefficients. Let&amp;rsquo;s call the coefficient of support vector \(v^{j}_i\) in the classifier between classes \(i\) and \(k\)\(\alpha^{j}_{i,k}\). Then &lt;code&gt;dual_coef_&lt;/code&gt; looks like this:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70091de439c388c847d5db9bb63c11ef6af9aff3" translate="yes" xml:space="preserve">
          <source>This might be made more clear by an example:</source>
          <target state="translated">Esto podría quedar más claro con un ejemplo:</target>
        </trans-unit>
        <trans-unit id="a18c0c170fadd6145ebf30e97149394844cb89ac" translate="yes" xml:space="preserve">
          <source>This mixin provides a feature selector implementation with &lt;code&gt;transform&lt;/code&gt; and &lt;code&gt;inverse_transform&lt;/code&gt; functionality given an implementation of &lt;code&gt;_get_support_mask&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87c35466b9ea86a2466ad7ff0fff224c499553d9" translate="yes" xml:space="preserve">
          <source>This model has many parameters, however the default values are quite reasonable (please see the &lt;a href=&quot;classes#text-feature-extraction-ref&quot;&gt;reference documentation&lt;/a&gt; for the details):</source>
          <target state="translated">Este modelo tiene muchos par&amp;aacute;metros, sin embargo, los valores predeterminados son bastante razonables (consulte la &lt;a href=&quot;classes#text-feature-extraction-ref&quot;&gt;documentaci&amp;oacute;n de referencia&lt;/a&gt; para obtener m&amp;aacute;s detalles):</target>
        </trans-unit>
        <trans-unit id="a96824cdb923fbde7424d806cedfbff3d185c97a" translate="yes" xml:space="preserve">
          <source>This model is an extension of the Sequential Karhunen-Loeve Transform from: &lt;code&gt;A. Levy and M. Lindenbaum, Sequential Karhunen-Loeve Basis Extraction and its Application to Images, IEEE Transactions on Image Processing, Volume 9, Number 8, pp. 1371-1374, August 2000.&lt;/code&gt; See &lt;a href=&quot;http://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&quot;&gt;http://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&lt;/a&gt;</source>
          <target state="translated">Este modelo es una extensi&amp;oacute;n de la Transformada secuencial de Karhunen-Loeve de: &lt;code&gt;A. Levy and M. Lindenbaum, Sequential Karhunen-Loeve Basis Extraction and its Application to Images, IEEE Transactions on Image Processing, Volume 9, Number 8, pp. 1371-1374, August 2000.&lt;/code&gt; V&amp;eacute;ase &lt;a href=&quot;http://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&quot;&gt;http://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="22862405516241c579b3ee92c4c4e899025ea8d7" translate="yes" xml:space="preserve">
          <source>This model is an extension of the Sequential Karhunen-Loeve Transform from: &lt;em&gt;A. Levy and M. Lindenbaum, Sequential Karhunen-Loeve Basis Extraction and its Application to Images, IEEE Transactions on Image Processing, Volume 9, Number 8, pp. 1371-1374, August 2000.&lt;/em&gt; See &lt;a href=&quot;https://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&quot;&gt;https://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5eaf31e8c5d94894f814f950dadb507546a62c7a" translate="yes" xml:space="preserve">
          <source>This model is similar to the basic Label Propagation algorithm, but uses affinity matrix based on the normalized graph Laplacian and soft clamping across the labels.</source>
          <target state="translated">Este modelo es similar al algoritmo básico de propagación de etiquetas,pero utiliza una matriz de afinidad basada en el gráfico normalizado Laplaciano y una sujeción suave a través de las etiquetas.</target>
        </trans-unit>
        <trans-unit id="31cfc2556e1a899818d23b9328ee0744c892d322" translate="yes" xml:space="preserve">
          <source>This model optimizes the log-loss function using LBFGS or stochastic gradient descent.</source>
          <target state="translated">Este modelo optimiza la función de pérdida de registros usando LBFGS o descenso de gradiente estocástico.</target>
        </trans-unit>
        <trans-unit id="a4064d8d27531f23ac21cbcbd5928e344df2525d" translate="yes" xml:space="preserve">
          <source>This model optimizes the squared-loss using LBFGS or stochastic gradient descent.</source>
          <target state="translated">Este modelo optimiza la pérdida al cuadrado usando LBFGS o descenso de gradiente estocástico.</target>
        </trans-unit>
        <trans-unit id="5bcd7dedd8759fb896822dc89b59d5206ebfcc53" translate="yes" xml:space="preserve">
          <source>This model solves a regression model where the loss function is the linear least squares function and regularization is given by the l2-norm. Also known as Ridge Regression or Tikhonov regularization. This estimator has built-in support for multi-variate regression (i.e., when y is a 2d-array of shape (n_samples, n_targets)).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5745ffae87fdf8e03232a3372f515cd928402ef0" translate="yes" xml:space="preserve">
          <source>This model solves a regression model where the loss function is the linear least squares function and regularization is given by the l2-norm. Also known as Ridge Regression or Tikhonov regularization. This estimator has built-in support for multi-variate regression (i.e., when y is a 2d-array of shape [n_samples, n_targets]).</source>
          <target state="translated">Este modelo resuelve un modelo de regresión en el que la función de pérdida es la función lineal de mínimos cuadrados y la regularización viene dada por la norma l2.También conocida como Regresión de la Cresta o regularización de Tikhonov.Este estimador tiene incorporado el soporte para la regresión multivariante (es decir,cuando y es una matriz de 2d de forma [n_muestras,n_objetivos]).</target>
        </trans-unit>
        <trans-unit id="f19c01936c0bc27e43d782c2c60b0838b0f4894d" translate="yes" xml:space="preserve">
          <source>This module contains both distance metrics and kernels. A brief summary is given on the two here.</source>
          <target state="translated">Este módulo contiene tanto métricas de distancia como núcleos.Aquí se da un breve resumen de ambos.</target>
        </trans-unit>
        <trans-unit id="ea7156035377b3d98062532f66578932992ce326" translate="yes" xml:space="preserve">
          <source>This module contains two loaders. The first one, &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt;&lt;/a&gt;, returns a list of the raw texts that can be fed to text feature extractors such as &lt;a href=&quot;../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt;&lt;/a&gt; with custom parameters so as to extract feature vectors. The second one, &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized#sklearn.datasets.fetch_20newsgroups_vectorized&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_20newsgroups_vectorized&lt;/code&gt;&lt;/a&gt;, returns ready-to-use features, i.e., it is not necessary to use a feature extractor.</source>
          <target state="translated">Este m&amp;oacute;dulo contiene dos cargadores. El primero, &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt; &lt;/a&gt; , devuelve una lista de los textos sin procesar que se pueden alimentar a los extractores de caracter&amp;iacute;sticas de texto como &lt;a href=&quot;../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt; &lt;/a&gt; con par&amp;aacute;metros personalizados para extraer vectores de caracter&amp;iacute;sticas. El segundo, &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized#sklearn.datasets.fetch_20newsgroups_vectorized&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_20newsgroups_vectorized&lt;/code&gt; &lt;/a&gt; , devuelve caracter&amp;iacute;sticas listas para usar, es decir, no es necesario utilizar un extractor de caracter&amp;iacute;sticas.</target>
        </trans-unit>
        <trans-unit id="e5dbda685e3f3b6ebc21c265d6368ea8386c5f03" translate="yes" xml:space="preserve">
          <source>This module implements multiclass learning algorithms:</source>
          <target state="translated">Este módulo implementa algoritmos de aprendizaje multiclase:</target>
        </trans-unit>
        <trans-unit id="40fee252ae7de928b5fc80e9416986beafe64ef4" translate="yes" xml:space="preserve">
          <source>This module implements multioutput regression and classification.</source>
          <target state="translated">Este módulo implementa una regresión y clasificación multi-salida.</target>
        </trans-unit>
        <trans-unit id="f4b5a1fcc345642615c5317116147407ee22511b" translate="yes" xml:space="preserve">
          <source>This module offers support for multi-output problems by implementing this strategy in both &lt;a href=&quot;generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt;&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.tree.decisiontreeregressor#sklearn.tree.DecisionTreeRegressor&quot;&gt;&lt;code&gt;DecisionTreeRegressor&lt;/code&gt;&lt;/a&gt;. If a decision tree is fit on an output array Y of size &lt;code&gt;[n_samples, n_outputs]&lt;/code&gt; then the resulting estimator will:</source>
          <target state="translated">Este m&amp;oacute;dulo ofrece soporte para problemas de m&amp;uacute;ltiples salidas al implementar esta estrategia tanto en &lt;a href=&quot;generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt; &lt;code&gt;DecisionTreeClassifier&lt;/code&gt; &lt;/a&gt; como en &lt;a href=&quot;generated/sklearn.tree.decisiontreeregressor#sklearn.tree.DecisionTreeRegressor&quot;&gt; &lt;code&gt;DecisionTreeRegressor&lt;/code&gt; &lt;/a&gt; . Si un &amp;aacute;rbol de decisi&amp;oacute;n se ajusta a una matriz de salida Y de tama&amp;ntilde;o &lt;code&gt;[n_samples, n_outputs]&lt;/code&gt; , el estimador resultante:</target>
        </trans-unit>
        <trans-unit id="69b4d83c7d3d58178d932db005c229bef475361e" translate="yes" xml:space="preserve">
          <source>This normalization is implemented by the &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt;&lt;code&gt;TfidfTransformer&lt;/code&gt;&lt;/a&gt; class:</source>
          <target state="translated">Esta normalizaci&amp;oacute;n es implementada por la clase &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt; &lt;code&gt;TfidfTransformer&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="36bde3d3011eb8df53f7587f509f261b5588364f" translate="yes" xml:space="preserve">
          <source>This object uses workers to compute in parallel the application of a function to many different arguments. The main functionality it brings in addition to using the raw multiprocessing or concurrent.futures API are (see examples for details):</source>
          <target state="translated">Este objeto utiliza trabajadores para calcular en paralelo la aplicación de una función a muchos argumentos diferentes.La principal funcionalidad que aporta,además de utilizar la API de multiprocesamiento en bruto o concurrent.futures,son (véanse los ejemplos para más detalles):</target>
        </trans-unit>
        <trans-unit id="43f85d31a1122b5ce913b6ac1587dc97b9fac8c9" translate="yes" xml:space="preserve">
          <source>This package also features helpers to fetch larger datasets commonly used by the machine learning community to benchmark algorithms on data that comes from the &amp;lsquo;real world&amp;rsquo;.</source>
          <target state="translated">Este paquete tambi&amp;eacute;n cuenta con ayudantes para obtener conjuntos de datos m&amp;aacute;s grandes que la comunidad de aprendizaje autom&amp;aacute;tico usa com&amp;uacute;nmente para comparar algoritmos con datos que provienen del &quot;mundo real&quot;.</target>
        </trans-unit>
        <trans-unit id="8291d2ecf0ae6621cc55dbf9132ec6413177dbb1" translate="yes" xml:space="preserve">
          <source>This parameter does not have any effect. The components are always normalized.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f678792533c8ea573ae326139ccc463721df5e43" translate="yes" xml:space="preserve">
          <source>This parameter has been renamed to n_components and will be removed in version 0.21. .. deprecated:: 0.19</source>
          <target state="translated">Este parámetro ha sido renombrado a n_componentes y será eliminado en la versión 0.21...depreciado::0.19</target>
        </trans-unit>
        <trans-unit id="b9bd887348c693f73ff73c188c30554ec63931d0" translate="yes" xml:space="preserve">
          <source>This parameter has no effect on the matplotlib tree visualisation and it is kept here for backward compatibility.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95ab9404db52634d7b16f5cf223dc53c5df9617b" translate="yes" xml:space="preserve">
          <source>This parameter has no effect, is deprecated, and will be removed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3803345bcca4c293ec436fd5df6e0af3703aedc" translate="yes" xml:space="preserve">
          <source>This parameter is deprecated and will be removed in v0.24.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2008376a104f1f0d722babab4554d9900556a331" translate="yes" xml:space="preserve">
          <source>This parameter is ignored if vocabulary is not None.</source>
          <target state="translated">Este parámetro es ignorado si el vocabulario no es Ninguno.</target>
        </trans-unit>
        <trans-unit id="4896edc233b2b945e9bfe76cd7c644f9b147f395" translate="yes" xml:space="preserve">
          <source>This parameter is ignored when &lt;code&gt;fit_intercept&lt;/code&gt; is set to False. If True, the regressors X will be normalized before regression by subtracting the mean and dividing by the l2-norm. If you wish to standardize, please use &lt;a href=&quot;sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt;&lt;code&gt;sklearn.preprocessing.StandardScaler&lt;/code&gt;&lt;/a&gt; before calling &lt;code&gt;fit&lt;/code&gt; on an estimator with &lt;code&gt;normalize=False&lt;/code&gt;.</source>
          <target state="translated">Este par&amp;aacute;metro se ignora cuando &lt;code&gt;fit_intercept&lt;/code&gt; se establece en False. Si es verdadero, los regresores X se normalizar&amp;aacute;n antes de la regresi&amp;oacute;n restando la media y dividiendo por la norma l2. Si desea estandarizar, use &lt;a href=&quot;sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt; &lt;code&gt;sklearn.preprocessing.StandardScaler&lt;/code&gt; &lt;/a&gt; antes de llamar a &lt;code&gt;fit&lt;/code&gt; en un estimador con &lt;code&gt;normalize=False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a954f8a244020c9f424e9822cfad5459a2f5fec4" translate="yes" xml:space="preserve">
          <source>This parameter is ignored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="74de1b86fb436972ff8b47352593daa33d35779f" translate="yes" xml:space="preserve">
          <source>This parameter is not needed to compute tfidf.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="18c6fb9267c5496a0a4415bd237b294d4f877c13" translate="yes" xml:space="preserve">
          <source>This parameter is required for multiclass/multilabel targets. If &lt;code&gt;None&lt;/code&gt;, the scores for each class are returned. Otherwise, this determines the type of averaging performed on the data:</source>
          <target state="translated">Este par&amp;aacute;metro es necesario para destinos multiclase / multilabel. Si &lt;code&gt;None&lt;/code&gt; , se devuelven las puntuaciones de cada clase. De lo contrario, esto determina el tipo de promediado realizado en los datos:</target>
        </trans-unit>
        <trans-unit id="4b54c5323e385131687ecd8fe6362000ef5ec12b" translate="yes" xml:space="preserve">
          <source>This parameters can be accessed through the members &lt;code&gt;dual_coef_&lt;/code&gt; which holds the product \(y_i \alpha_i\), &lt;code&gt;support_vectors_&lt;/code&gt; which holds the support vectors, and &lt;code&gt;intercept_&lt;/code&gt; which holds the independent term \(\rho\) :</source>
          <target state="translated">Se puede acceder a estos par&amp;aacute;metros a trav&amp;eacute;s de los miembros &lt;code&gt;dual_coef_&lt;/code&gt; que contiene el producto \ (y_i \ alpha_i \), &lt;code&gt;support_vectors_&lt;/code&gt; que contiene los vectores de soporte e &lt;code&gt;intercept_&lt;/code&gt; que contiene el t&amp;eacute;rmino independiente \ (\ rho \):</target>
        </trans-unit>
        <trans-unit id="f0e92a41ff311d2df395e780ee2f06d2a63e9cbc" translate="yes" xml:space="preserve">
          <source>This path length, averaged over a forest of such random trees, is a measure of normality and our decision function.</source>
          <target state="translated">Esta longitud del camino,promediada sobre un bosque de árboles tan aleatorios,es una medida de la normalidad y nuestra función de decisión.</target>
        </trans-unit>
        <trans-unit id="80dec09fc285dd6f9c561fc2931162bad1982cdb" translate="yes" xml:space="preserve">
          <source>This plot compares the decision surfaces learned by a decision tree classifier (first column), by a random forest classifier (second column), by an extra- trees classifier (third column) and by an AdaBoost classifier (fourth column).</source>
          <target state="translated">Este gráfico compara las superficies de decisión aprendidas por un clasificador de árboles de decisión (primera columna),por un clasificador de bosques aleatorios (segunda columna),por un clasificador de árboles extra (tercera columna)y por un clasificador AdaBoost (cuarta columna).</target>
        </trans-unit>
        <trans-unit id="3b15144cc63de75145bd9b8c8333a27bef49a738" translate="yes" xml:space="preserve">
          <source>This plot is called a Lorenz curve and can be summarized by the Gini index:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e05dc7c1a0ec44a96abb884d1ce621cca93db4e" translate="yes" xml:space="preserve">
          <source>This problem can safely be ignored when the number of samples is more than a thousand and the number of clusters is less than 10. &lt;strong&gt;For smaller sample sizes or larger number of clusters it is safer to use an adjusted index such as the Adjusted Rand Index (ARI)&lt;/strong&gt;.</source>
          <target state="translated">Este problema se puede ignorar con seguridad cuando el n&amp;uacute;mero de muestras es superior a mil y el n&amp;uacute;mero de conglomerados es inferior a 10. &lt;strong&gt;Para tama&amp;ntilde;os de muestra m&amp;aacute;s peque&amp;ntilde;os o mayor n&amp;uacute;mero de conglomerados, es m&amp;aacute;s seguro utilizar un &amp;iacute;ndice ajustado como el &amp;Iacute;ndice Rand Ajustado ( ARI)&lt;/strong&gt; .</target>
        </trans-unit>
        <trans-unit id="432c2ac32bcc01f0466fb33da0cfef7067b741ad" translate="yes" xml:space="preserve">
          <source>This problem stems from two limitations of impurity-based feature importances:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcd7e110cbbcbd004685bcd45cf928dd3da1b5b1" translate="yes" xml:space="preserve">
          <source>This procedure (spectral clustering on an image) is an efficient approximate solution for finding normalized graph cuts.</source>
          <target state="translated">Este procedimiento (agrupación espectral en una imagen)es una solución aproximada eficiente para encontrar cortes de gráficos normalizados.</target>
        </trans-unit>
        <trans-unit id="f7d25c0cd20cd8cb8daa937c60ac3edd0b2b2f75" translate="yes" xml:space="preserve">
          <source>This ranking metric yields a high value if true labels are ranked high by &lt;code&gt;y_score&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a8651d966c336f363771d222433438f229cb5c2" translate="yes" xml:space="preserve">
          <source>This regressor is useful as a simple baseline to compare with other (real) regressors. Do not use it for real problems.</source>
          <target state="translated">Este regresor es útil como una simple línea de base para comparar con otros regresores (reales).No lo use para problemas reales.</target>
        </trans-unit>
        <trans-unit id="566769fe300350777b617d7ceed39620171814da" translate="yes" xml:space="preserve">
          <source>This scaler can also be applied to sparse CSR or CSC matrices by passing &lt;code&gt;with_mean=False&lt;/code&gt; to avoid breaking the sparsity structure of the data.</source>
          <target state="translated">Este escalador tambi&amp;eacute;n se puede aplicar a matrices CSR o CSC &lt;code&gt;with_mean=False&lt;/code&gt; pasando with_mean = False para evitar romper la estructura de dispersi&amp;oacute;n de los datos.</target>
        </trans-unit>
        <trans-unit id="bf350412f5695ebe05a62d114269ff308d8edf9f" translate="yes" xml:space="preserve">
          <source>This scaler can also be applied to sparse CSR or CSC matrices.</source>
          <target state="translated">Este escalador también puede ser aplicado a matrices de CSR o CSC dispersas.</target>
        </trans-unit>
        <trans-unit id="096cae15373bbc176ca80052b34794345347f334" translate="yes" xml:space="preserve">
          <source>This score can be used to select the n_features features with the highest values for the test chi-squared statistic from X, which must contain only non-negative features such as booleans or frequencies (e.g., term counts in document classification), relative to the classes.</source>
          <target state="translated">Esta puntuación puede utilizarse para seleccionar las características n_características con los valores más altos para la estadística de ji cuadrado de prueba de X,que debe contener sólo características no negativas como los booleanos o las frecuencias (por ejemplo,recuentos de términos en la clasificación de documentos),en relación con las clases.</target>
        </trans-unit>
        <trans-unit id="bc67f7a4c884a57cb8d65e3051862bc296a2adb5" translate="yes" xml:space="preserve">
          <source>This score is identical to &lt;a href=&quot;sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt;&lt;code&gt;normalized_mutual_info_score&lt;/code&gt;&lt;/a&gt; with the &lt;code&gt;'arithmetic'&lt;/code&gt; option for averaging.</source>
          <target state="translated">Esta puntuaci&amp;oacute;n es id&amp;eacute;ntica a &lt;a href=&quot;sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt; &lt;code&gt;normalized_mutual_info_score&lt;/code&gt; &lt;/a&gt; con la opci&amp;oacute;n &lt;code&gt;'arithmetic'&lt;/code&gt; para promediar.</target>
        </trans-unit>
        <trans-unit id="81b377dd4306b3470c7efb10edcaa8d55b57210b" translate="yes" xml:space="preserve">
          <source>This section illustrates the use of a &lt;code&gt;Pipeline&lt;/code&gt; with &lt;code&gt;GridSearchCV&lt;/code&gt;</source>
          <target state="translated">Esta secci&amp;oacute;n ilustra el uso de una &lt;code&gt;Pipeline&lt;/code&gt; con &lt;code&gt;GridSearchCV&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="929a45e65dc1a0cd0b685d6194be9ae4708eb857" translate="yes" xml:space="preserve">
          <source>This should make it possible to check that the cross-validation score is in the same range as before.</source>
          <target state="translated">Esto debería permitir comprobar que la puntuación de validación cruzada está en el mismo rango que antes.</target>
        </trans-unit>
        <trans-unit id="08af461e03baea2ad13f22a738ff3dde29c2a50f" translate="yes" xml:space="preserve">
          <source>This shows an example of a neighbors-based query (in particular a kernel density estimate) on geospatial data, using a Ball Tree built upon the Haversine distance metric &amp;ndash; i.e. distances over points in latitude/longitude. The dataset is provided by Phillips et. al. (2006). If available, the example uses &lt;a href=&quot;http://matplotlib.org/basemap&quot;&gt;basemap&lt;/a&gt; to plot the coast lines and national boundaries of South America.</source>
          <target state="translated">Esto muestra un ejemplo de una consulta basada en vecinos (en particular, una estimaci&amp;oacute;n de densidad de kernel) sobre datos geoespaciales, utilizando un &amp;aacute;rbol de bolas construido sobre la m&amp;eacute;trica de distancia de Haversine, es decir, distancias sobre puntos en latitud / longitud. El conjunto de datos es proporcionado por Phillips et. Alabama. (2006). Si est&amp;aacute; disponible, el ejemplo utiliza un &lt;a href=&quot;http://matplotlib.org/basemap&quot;&gt;mapa base&lt;/a&gt; para trazar las l&amp;iacute;neas costeras y los l&amp;iacute;mites nacionales de Am&amp;eacute;rica del Sur.</target>
        </trans-unit>
        <trans-unit id="d9d5278cf29981ffe0af23942c116e835acd3587" translate="yes" xml:space="preserve">
          <source>This shows an example of a neighbors-based query (in particular a kernel density estimate) on geospatial data, using a Ball Tree built upon the Haversine distance metric &amp;ndash; i.e. distances over points in latitude/longitude. The dataset is provided by Phillips et. al. (2006). If available, the example uses &lt;a href=&quot;https://matplotlib.org/basemap/&quot;&gt;basemap&lt;/a&gt; to plot the coast lines and national boundaries of South America.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38716491ad409e2f991bc1db8f7b1d944921bf99" translate="yes" xml:space="preserve">
          <source>This sort of preprocessing can be streamlined with the &lt;a href=&quot;compose#pipeline&quot;&gt;Pipeline&lt;/a&gt; tools. A single object representing a simple polynomial regression can be created and used as follows:</source>
          <target state="translated">Este tipo de preprocesamiento se puede optimizar con las herramientas &lt;a href=&quot;compose#pipeline&quot;&gt;Pipeline&lt;/a&gt; . Un &amp;uacute;nico objeto que representa una regresi&amp;oacute;n polinomial simple se puede crear y utilizar de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="4e6050ab2083fb67a848ffe7f83ae292a8f60f62" translate="yes" xml:space="preserve">
          <source>This strategy can also be used for multilabel learning, where a classifier is used to predict multiple labels for instance, by fitting on a 2-d matrix in which cell [i, j] is 1 if sample i has label j and 0 otherwise.</source>
          <target state="translated">Esta estrategia también puede utilizarse para el aprendizaje de etiquetas múltiples,en el que se utiliza un clasificador para predecir las etiquetas múltiples,por ejemplo,encajando en una matriz bidimensional en la que la celda [i,j]es 1 si la muestra i tiene la etiqueta j y 0 en caso contrario.</target>
        </trans-unit>
        <trans-unit id="8cd6a64f79d725ef1cdd342315685305aab51887" translate="yes" xml:space="preserve">
          <source>This strategy consists in fitting one classifier per class pair. At prediction time, the class which received the most votes is selected. Since it requires to fit &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; classifiers, this method is usually slower than one-vs-the-rest, due to its O(n_classes^2) complexity. However, this method may be advantageous for algorithms such as kernel algorithms which don&amp;rsquo;t scale well with &lt;code&gt;n_samples&lt;/code&gt;. This is because each individual learning problem only involves a small subset of the data whereas, with one-vs-the-rest, the complete dataset is used &lt;code&gt;n_classes&lt;/code&gt; times.</source>
          <target state="translated">Esta estrategia consiste en ajustar un clasificador por par de clases. En el momento de la predicci&amp;oacute;n, se selecciona la clase que recibi&amp;oacute; m&amp;aacute;s votos. Dado que requiere adaptarse a &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; clasificadores, este m&amp;eacute;todo suele ser m&amp;aacute;s lento que uno contra el resto, debido a su complejidad O (n_classes ^ 2). Sin embargo, este m&amp;eacute;todo puede resultar ventajoso para algoritmos como los del kernel que no escalan bien con &lt;code&gt;n_samples&lt;/code&gt; . Esto se debe a que cada problema de aprendizaje individual solo involucra un peque&amp;ntilde;o subconjunto de los datos mientras que, con uno contra el resto, el conjunto de datos completo se usa &lt;code&gt;n_classes&lt;/code&gt; veces.</target>
        </trans-unit>
        <trans-unit id="de640b51f281cc0046c1a9e652c58d4e96ebef0b" translate="yes" xml:space="preserve">
          <source>This strategy consists of fitting one classifier per target. This is a simple strategy for extending classifiers that do not natively support multi-target classification</source>
          <target state="translated">Esta estrategia consiste en colocar un clasificador por cada objetivo.Esta es una estrategia simple para extender los clasificadores que no soportan de forma nativa la clasificación multiobjetivo</target>
        </trans-unit>
        <trans-unit id="7d6fb6c6a7f2b79b31f4627b09bbb93dcc2f3bc4" translate="yes" xml:space="preserve">
          <source>This strategy consists of fitting one regressor per target. This is a simple strategy for extending regressors that do not natively support multi-target regression.</source>
          <target state="translated">Esta estrategia consiste en colocar un regresor por cada objetivo.Es una estrategia simple para extender los regresores que no soportan de forma nativa la regresión de múltiples objetivos.</target>
        </trans-unit>
        <trans-unit id="27cbaceed22a6f90d5ae07c700825d27bfca1f78" translate="yes" xml:space="preserve">
          <source>This strategy has several advantages:</source>
          <target state="translated">Esta estrategia tiene varias ventajas:</target>
        </trans-unit>
        <trans-unit id="91d49a77db9793bc904e6dbf1c0dda029b6c110b" translate="yes" xml:space="preserve">
          <source>This strategy is illustrated below.</source>
          <target state="translated">Esta estrategia se ilustra a continuación.</target>
        </trans-unit>
        <trans-unit id="02849272fb07ed52ea9b00f7ccc02a748c971372" translate="yes" xml:space="preserve">
          <source>This strategy, also known as &lt;strong&gt;one-vs-all&lt;/strong&gt;, is implemented in &lt;a href=&quot;generated/sklearn.multiclass.onevsrestclassifier#sklearn.multiclass.OneVsRestClassifier&quot;&gt;&lt;code&gt;OneVsRestClassifier&lt;/code&gt;&lt;/a&gt;. The strategy consists in fitting one classifier per class. For each classifier, the class is fitted against all the other classes. In addition to its computational efficiency (only &lt;code&gt;n_classes&lt;/code&gt; classifiers are needed), one advantage of this approach is its interpretability. Since each class is represented by one and only one classifier, it is possible to gain knowledge about the class by inspecting its corresponding classifier. This is the most commonly used strategy and is a fair default choice.</source>
          <target state="translated">Esta estrategia, tambi&amp;eacute;n conocida como &lt;strong&gt;uno contra todos&lt;/strong&gt; , se implementa en &lt;a href=&quot;generated/sklearn.multiclass.onevsrestclassifier#sklearn.multiclass.OneVsRestClassifier&quot;&gt; &lt;code&gt;OneVsRestClassifier&lt;/code&gt; &lt;/a&gt; . La estrategia consiste en ajustar un clasificador por clase. Para cada clasificador, la clase se ajusta a todas las dem&amp;aacute;s clases. Adem&amp;aacute;s de su eficiencia computacional (solo se necesitan clasificadores &lt;code&gt;n_classes&lt;/code&gt; ), una ventaja de este enfoque es su interpretabilidad. Dado que cada clase est&amp;aacute; representada por un solo clasificador, es posible obtener conocimientos sobre la clase inspeccionando su clasificador correspondiente. Esta es la estrategia m&amp;aacute;s utilizada y es una opci&amp;oacute;n justa por defecto.</target>
        </trans-unit>
        <trans-unit id="27ac94ab878e8b852843daf6fdc6644656d86a0e" translate="yes" xml:space="preserve">
          <source>This submodule contains functions that approximate the feature mappings that correspond to certain kernels, as they are used for example in support vector machines (see &lt;a href=&quot;svm#svm&quot;&gt;Support Vector Machines&lt;/a&gt;). The following feature functions perform non-linear transformations of the input, which can serve as a basis for linear classification or other algorithms.</source>
          <target state="translated">Este subm&amp;oacute;dulo contiene funciones que se aproximan a las asignaciones de caracter&amp;iacute;sticas que corresponden a ciertos kernels, ya que se utilizan, por ejemplo, en m&amp;aacute;quinas de vectores de soporte (consulte &lt;a href=&quot;svm#svm&quot;&gt;M&amp;aacute;quinas de vectores de soporte&lt;/a&gt; ). Las siguientes funciones de caracter&amp;iacute;sticas realizan transformaciones no lineales de la entrada, que pueden servir como base para la clasificaci&amp;oacute;n lineal u otros algoritmos.</target>
        </trans-unit>
        <trans-unit id="fcbae9cfcf0bd03c252edbce0ec54b00175fa149" translate="yes" xml:space="preserve">
          <source>This test can be applied to classes or instances. Classes currently have some additional tests that related to construction, while passing instances allows the testing of multiple options.</source>
          <target state="translated">Esta prueba puede aplicarse a clases o instancias.Las clases actualmente tienen algunas pruebas adicionales que se relacionan con la construcción,mientras que pasar las instancias permite probar múltiples opciones.</target>
        </trans-unit>
        <trans-unit id="1df76b4b8062cdd31b59f7b7a96f694c7a4a84f4" translate="yes" xml:space="preserve">
          <source>This test can be applied to classes or instances. Classes currently have some additional tests that related to construction, while passing instances allows the testing of multiple options. However, support for classes is deprecated since version 0.23 and will be removed in version 0.24 (class checks will still be run on the instances).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe4512e0330ee3f9d4d908b10acadfb35dcb4b46" translate="yes" xml:space="preserve">
          <source>This text vectorizer implementation uses the hashing trick to find the token string name to feature integer index mapping.</source>
          <target state="translated">Esta implementación del vectorizador de texto utiliza el truco del hash para encontrar el nombre de la cadena del token para presentar el mapeo del índice entero.</target>
        </trans-unit>
        <trans-unit id="90704510327932a48fb3c52155398163f97475e2" translate="yes" xml:space="preserve">
          <source>This transformation is often used as an alternative to zero mean, unit variance scaling.</source>
          <target state="translated">Esta transformación se utiliza a menudo como alternativa a la media cero,la escala de variación unitaria.</target>
        </trans-unit>
        <trans-unit id="6539f7aec79b7dc39bdc0281525ed4d20f3ca8db" translate="yes" xml:space="preserve">
          <source>This transformation will only be exact if n_components=n_features</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f720ce11fea82f150f2e1314efc3b6e74d2aa65" translate="yes" xml:space="preserve">
          <source>This transformer is able to work both with dense numpy arrays and scipy.sparse matrix (use CSR format if you want to avoid the burden of a copy / conversion).</source>
          <target state="translated">Este transformador es capaz de trabajar tanto con matrices numéricas densas como con matrices scipy.sparse (utilice el formato CSR si quiere evitar la carga de una copia/conversión).</target>
        </trans-unit>
        <trans-unit id="22f51ce5936d304512713b7c2d6420a9339ed07c" translate="yes" xml:space="preserve">
          <source>This transformer performs linear dimensionality reduction by means of truncated singular value decomposition (SVD). Contrary to PCA, this estimator does not center the data before computing the singular value decomposition. This means it can work with scipy.sparse matrices efficiently.</source>
          <target state="translated">Este transformador realiza una reducción lineal de la dimensionalidad por medio de la descomposición de valor singular truncado (SVD).Al contrario que el PCA,este estimador no centra los datos antes de computar la descomposición del valor singular.Esto significa que puede trabajar con matrices scipy.sparse de manera eficiente.</target>
        </trans-unit>
        <trans-unit id="548ea059334e4b91f9c90aef5db25d9def754336" translate="yes" xml:space="preserve">
          <source>This transformer performs linear dimensionality reduction by means of truncated singular value decomposition (SVD). Contrary to PCA, this estimator does not center the data before computing the singular value decomposition. This means it can work with sparse matrices efficiently.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cbf82199a6ba754f7c0185042f3f4e595a8e8525" translate="yes" xml:space="preserve">
          <source>This transformer should be used to encode target values, &lt;em&gt;i.e.&lt;/em&gt;&lt;code&gt;y&lt;/code&gt;, and not the input &lt;code&gt;X&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c058bdf39166834e7b3e02bee2a3dc32df1bea5c" translate="yes" xml:space="preserve">
          <source>This transformer turns lists of mappings (dict-like objects) of feature names to feature values into Numpy arrays or scipy.sparse matrices for use with scikit-learn estimators.</source>
          <target state="translated">Este transformador convierte las listas de mapeo (objetos en forma de dictado)de nombres de características en valores de características en matrices Numpy o scipy.sparse para su uso con estimadores scikit-learn.</target>
        </trans-unit>
        <trans-unit id="6fa17f9065133747f6dee2c04fd6c387874c04ab" translate="yes" xml:space="preserve">
          <source>This tutorial will explore &lt;em&gt;statistical learning&lt;/em&gt;, the use of machine learning techniques with the goal of &lt;a href=&quot;https://en.wikipedia.org/wiki/Statistical_inference&quot;&gt;statistical inference&lt;/a&gt;: drawing conclusions on the data at hand.</source>
          <target state="translated">Este tutorial explorar&amp;aacute; &lt;em&gt;el aprendizaje estad&amp;iacute;stico&lt;/em&gt; , el uso de t&amp;eacute;cnicas de aprendizaje autom&amp;aacute;tico con el objetivo de &lt;a href=&quot;https://en.wikipedia.org/wiki/Statistical_inference&quot;&gt;la inferencia estad&amp;iacute;stica&lt;/a&gt; : sacar conclusiones sobre los datos disponibles.</target>
        </trans-unit>
        <trans-unit id="d770164eec068c2686e18d9f67f7678a7fe3d2ab" translate="yes" xml:space="preserve">
          <source>This uses the Benjamini-Hochberg procedure. &lt;code&gt;alpha&lt;/code&gt; is an upper bound on the expected false discovery rate.</source>
          <target state="translated">Esto utiliza el procedimiento Benjamini-Hochberg. &lt;code&gt;alpha&lt;/code&gt; es un l&amp;iacute;mite superior en la tasa esperada de falsos descubrimientos.</target>
        </trans-unit>
        <trans-unit id="25630de50e6415b67bb72ea47abf6e457ed32d31" translate="yes" xml:space="preserve">
          <source>This uses the score defined by &lt;code&gt;scoring&lt;/code&gt; where provided, and the &lt;code&gt;best_estimator_.score&lt;/code&gt; method otherwise.</source>
          <target state="translated">Esto utiliza la puntuaci&amp;oacute;n definida por &lt;code&gt;scoring&lt;/code&gt; donde se proporciona, y el m&amp;eacute;todo &lt;code&gt;best_estimator_.score&lt;/code&gt; en caso contrario.</target>
        </trans-unit>
        <trans-unit id="28c90b747be44784ef68312c004db0e8049cba2c" translate="yes" xml:space="preserve">
          <source>This utility is documented, but &lt;strong&gt;private&lt;/strong&gt;. This means that backward compatibility might be broken without any deprecation cycle.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6f06f080d161d82167224fa4f5455a90c3bc7e3" translate="yes" xml:space="preserve">
          <source>This utility is meant to be used internally by estimators themselves, typically in their own predict / transform methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57e78bad29e459afb6f7e8e9a46e0b5e6e5f4fa9" translate="yes" xml:space="preserve">
          <source>This value is valid if class_weight parameter in fit() is not set.</source>
          <target state="translated">Este valor es válido si el parámetro class_weight en fit()no está establecido.</target>
        </trans-unit>
        <trans-unit id="0973d55bbbd406d7d050b325e278935eae6a368e" translate="yes" xml:space="preserve">
          <source>This value of the mutual information and also the normalized variant is not adjusted for chance and will tend to increase as the number of different labels (clusters) increases, regardless of the actual amount of &amp;ldquo;mutual information&amp;rdquo; between the label assignments.</source>
          <target state="translated">Este valor de la informaci&amp;oacute;n mutua y tambi&amp;eacute;n la variante normalizada no se ajusta al azar y tender&amp;aacute; a aumentar a medida que aumenta el n&amp;uacute;mero de etiquetas diferentes (grupos), independientemente de la cantidad real de &quot;informaci&amp;oacute;n mutua&quot; entre las asignaciones de etiquetas.</target>
        </trans-unit>
        <trans-unit id="ec27c204380d1bf1bec671104c4e5cc563667983" translate="yes" xml:space="preserve">
          <source>This visualization is an example of a &lt;em&gt;kernel density estimation&lt;/em&gt;, in this case with a top-hat kernel (i.e. a square block at each point). We can recover a smoother distribution by using a smoother kernel. The bottom-right plot shows a Gaussian kernel density estimate, in which each point contributes a Gaussian curve to the total. The result is a smooth density estimate which is derived from the data, and functions as a powerful non-parametric model of the distribution of points.</source>
          <target state="translated">Esta visualizaci&amp;oacute;n es un ejemplo de una &lt;em&gt;estimaci&amp;oacute;n de la densidad del kernel&lt;/em&gt; , en este caso con un kernel de sombrero de copa (es decir, un bloque cuadrado en cada punto). Podemos recuperar una distribuci&amp;oacute;n m&amp;aacute;s suave usando un kernel m&amp;aacute;s suave. El gr&amp;aacute;fico de la parte inferior derecha muestra una estimaci&amp;oacute;n de la densidad del n&amp;uacute;cleo gaussiano, en la que cada punto aporta una curva gaussiana al total. El resultado es una estimaci&amp;oacute;n de densidad uniforme que se deriva de los datos y funciona como un poderoso modelo no param&amp;eacute;trico de la distribuci&amp;oacute;n de puntos.</target>
        </trans-unit>
        <trans-unit id="1cad85e71e9b226b43b5778c8058de4fe70516a7" translate="yes" xml:space="preserve">
          <source>This warning is used to notify the user that BLAS was not used for dot operation and hence the efficiency may be affected.</source>
          <target state="translated">Esta advertencia se utiliza para notificar al usuario que BLAS no se utilizó para el funcionamiento del punto y por lo tanto la eficiencia puede verse afectada.</target>
        </trans-unit>
        <trans-unit id="7b4c8162b5298ba9d922a2200274b38ddddf44e8" translate="yes" xml:space="preserve">
          <source>This warning notifies the user that the efficiency may not be optimal due to some reason which may be included as a part of the warning message. This may be subclassed into a more specific Warning class.</source>
          <target state="translated">Esta advertencia notifica al usuario que la eficiencia puede no ser óptima debido a alguna razón que puede ser incluida como parte del mensaje de advertencia.Esto puede ser subclasificado en una clase de advertencia más específica.</target>
        </trans-unit>
        <trans-unit id="ec79da6e5e29f4afd0662e82ec298c39ed6dbabd" translate="yes" xml:space="preserve">
          <source>This warning occurs when some input data needs to be converted or interpreted in a way that may not match the user&amp;rsquo;s expectations.</source>
          <target state="translated">Esta advertencia ocurre cuando algunos datos de entrada deben convertirse o interpretarse de una manera que puede no coincidir con las expectativas del usuario.</target>
        </trans-unit>
        <trans-unit id="14994b75958434504d6803fa4be46a86d6219fc9" translate="yes" xml:space="preserve">
          <source>This was originally a term weighting scheme developed for information retrieval (as a ranking function for search engines results) that has also found good use in document classification and clustering.</source>
          <target state="translated">Este fue originalmente un esquema de ponderación de términos desarrollado para la recuperación de información (como una función de clasificación de los resultados de los motores de búsqueda)que también ha encontrado un buen uso en la clasificación y agrupación de documentos.</target>
        </trans-unit>
        <trans-unit id="90d00e9f85af52e63288d2fca3d9f513dce9de12" translate="yes" xml:space="preserve">
          <source>This, however, is not the case in the Ledoit-Wolf procedure when the population covariance happens to be a multiple of the identity matrix. In this case, the Ledoit-Wolf shrinkage estimate approaches 1 as the number of samples increases. This indicates that the optimal estimate of the covariance matrix in the Ledoit-Wolf sense is multiple of the identity. Since the population covariance is already a multiple of the identity matrix, the Ledoit-Wolf solution is indeed a reasonable estimate.</source>
          <target state="translated">Sin embargo,no es el caso en el procedimiento Ledoit-Wolf cuando la covarianza de la población resulta ser un múltiplo de la matriz de identidad.En este caso,la estimación de la contracción de Ledoit-Wolf se aproxima a 1 a medida que aumenta el número de muestras.Esto indica que la estimación óptima de la matriz de covarianza en el sentido de Ledoit-Wolf es un múltiplo de la identidad.Dado que la covarianza de la población ya es un múltiplo de la matriz de identidad,la solución de Ledoit-Wolf es de hecho una estimación razonable.</target>
        </trans-unit>
        <trans-unit id="e911226999d28ae4c4eb95cef049955b008548cf" translate="yes" xml:space="preserve">
          <source>Those 3 metrics are independent of the absolute values of the labels: a permutation of the class or cluster label values won&amp;rsquo;t change the score values in any way.</source>
          <target state="translated">Esas 3 m&amp;eacute;tricas son independientes de los valores absolutos de las etiquetas: una permutaci&amp;oacute;n de los valores de la etiqueta de clase o cl&amp;uacute;ster no cambiar&amp;aacute; los valores de puntuaci&amp;oacute;n de ninguna manera.</target>
        </trans-unit>
        <trans-unit id="a17151aff3f6e79d6bfb3bc3e7c5d30ff3b77b7d" translate="yes" xml:space="preserve">
          <source>Those metrics are based on normalized conditional entropy measures of the clustering labeling to evaluate given the knowledge of a Ground Truth class labels of the same samples.</source>
          <target state="translated">Esas mediciones se basan en medidas de entropía condicional normalizada del etiquetado de agrupación para evaluar,dado el conocimiento de una clase de verdad de las mismas muestras.</target>
        </trans-unit>
        <trans-unit id="831e093286e91d34e1415d38600e7c8277f14a07" translate="yes" xml:space="preserve">
          <source>Though not technically a variant of LLE, Local tangent space alignment (LTSA) is algorithmically similar enough to LLE that it can be put in this category. Rather than focusing on preserving neighborhood distances as in LLE, LTSA seeks to characterize the local geometry at each neighborhood via its tangent space, and performs a global optimization to align these local tangent spaces to learn the embedding. LTSA can be performed with function &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt;&lt;code&gt;locally_linear_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt;&lt;code&gt;LocallyLinearEmbedding&lt;/code&gt;&lt;/a&gt;, with the keyword &lt;code&gt;method = 'ltsa'&lt;/code&gt;.</source>
          <target state="translated">Aunque t&amp;eacute;cnicamente no es una variante de LLE, la alineaci&amp;oacute;n del espacio tangente local (LTSA) es algor&amp;iacute;tmicamente lo suficientemente similar a LLE que puede incluirse en esta categor&amp;iacute;a. En lugar de centrarse en preservar las distancias del vecindario como en LLE, LTSA busca caracterizar la geometr&amp;iacute;a local en cada vecindario a trav&amp;eacute;s de su espacio tangente y realiza una optimizaci&amp;oacute;n global para alinear estos espacios tangentes locales para aprender la incrustaci&amp;oacute;n. LTSA se puede realizar con la funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt; &lt;code&gt;locally_linear_embedding&lt;/code&gt; &lt;/a&gt; o su contraparte orientada a objetos &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt; &lt;code&gt;LocallyLinearEmbedding&lt;/code&gt; &lt;/a&gt; , con la palabra clave &lt;code&gt;method = 'ltsa'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3dcfc8b5bdf930c1b66451c5dc30f486901100ee" translate="yes" xml:space="preserve">
          <source>Three different types of SVM-Kernels are displayed below. The polynomial and RBF are especially useful when the data-points are not linearly separable.</source>
          <target state="translated">A continuación se muestran tres tipos diferentes de núcleos SVM.El polinomio y el RBF son especialmente útiles cuando los puntos de datos no son linealmente separables.</target>
        </trans-unit>
        <trans-unit id="2eb0d5d5e8d716a06a5bc42a652c1781cf721343" translate="yes" xml:space="preserve">
          <source>Threshold for binarizing (mapping to booleans) of sample features. If None, input is presumed to already consist of binary vectors.</source>
          <target state="translated">Umbral para la binarización (mapeo a booleanos)de las características de la muestra.Si no hay ninguno,se presume que la entrada ya consiste en vectores binarios.</target>
        </trans-unit>
        <trans-unit id="ac359cd376aaf3163dffdc564a92f8f55ebdbfe9" translate="yes" xml:space="preserve">
          <source>Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.</source>
          <target state="translated">Umbral para la detención temprana del crecimiento de los árboles.Un nodo se dividirá si su impureza está por encima del umbral,de lo contrario es una hoja.</target>
        </trans-unit>
        <trans-unit id="d2dde1e4fd07fa9e4ff99bf50a843f5c394281b4" translate="yes" xml:space="preserve">
          <source>Threshold for shrinking centroids to remove features.</source>
          <target state="translated">Umbral para encoger los centroides para eliminar los rasgos.</target>
        </trans-unit>
        <trans-unit id="5b50eca69565a6240c9cb586697767c09ac4525e" translate="yes" xml:space="preserve">
          <source>Threshold on the size of arrays passed to the workers that triggers automated memory mapping in temp_folder. Can be an int in Bytes, or a human-readable string, e.g., &amp;lsquo;1M&amp;rsquo; for 1 megabyte. Use None to disable memmapping of large arrays. Only active when backend=&amp;rdquo;loky&amp;rdquo; or &amp;ldquo;multiprocessing&amp;rdquo;.</source>
          <target state="translated">Umbral en el tama&amp;ntilde;o de las matrices que se pasan a los trabajadores que activa la asignaci&amp;oacute;n de memoria automatizada en temp_folder. Puede ser un int en Bytes, o una cadena legible por humanos, por ejemplo, '1M' para 1 megabyte. Utilice Ninguno para deshabilitar la asignaci&amp;oacute;n de memoria de matrices grandes. Solo activo cuando backend = &quot;loky&quot; o &quot;multiprocesamiento&quot;.</target>
        </trans-unit>
        <trans-unit id="3bf722c4ec04176f091be4d50fbd629d5b754a20" translate="yes" xml:space="preserve">
          <source>Threshold used for rank estimation in SVD solver.</source>
          <target state="translated">Umbral utilizado para la estimación del rango en el solucionador SVD.</target>
        </trans-unit>
        <trans-unit id="0168a115989469a76c56e8c46c0d56b1a01f88c6" translate="yes" xml:space="preserve">
          <source>Threshold used for rank estimation.</source>
          <target state="translated">Umbral utilizado para la estimación del rango.</target>
        </trans-unit>
        <trans-unit id="558232b0add0e7cf1e4001c15b7a509781ecfb59" translate="yes" xml:space="preserve">
          <source>Threshold used in the binary and multi-label cases.</source>
          <target state="translated">Umbral utilizado en los casos binarios y multi-etiquetas.</target>
        </trans-unit>
        <trans-unit id="d260a173cc06214ee3d2352996ea165371c17c29" translate="yes" xml:space="preserve">
          <source>Thresholding</source>
          <target state="translated">Thresholding</target>
        </trans-unit>
        <trans-unit id="8265a18b28c2cb3c5a28ceb45384d9a49c2f7715" translate="yes" xml:space="preserve">
          <source>Thresholding is clearly not useful for denoising, but it is here to show that it can produce a suggestive output with very high speed, and thus be useful for other tasks such as object classification, where performance is not necessarily related to visualisation.</source>
          <target state="translated">Está claro que el umbral no es útil para la denotación,pero está aquí para demostrar que puede producir una salida sugerente con una velocidad muy alta,y por lo tanto ser útil para otras tareas como la clasificación de objetos,donde el rendimiento no está necesariamente relacionado con la visualización.</target>
        </trans-unit>
        <trans-unit id="c4d29a75003891e7d5c5dbb3dea7166bf19f4ab9" translate="yes" xml:space="preserve">
          <source>Thresholding is very fast but it does not yield accurate reconstructions. They have been shown useful in literature for classification tasks. For image reconstruction tasks, orthogonal matching pursuit yields the most accurate, unbiased reconstruction.</source>
          <target state="translated">El umbral es muy rápido,pero no da lugar a reconstrucciones precisas.Se ha demostrado que son útiles en la literatura para las tareas de clasificación.Para las tareas de reconstrucción de imágenes,la búsqueda de coincidencia ortogonal produce la reconstrucción más precisa e imparcial.</target>
        </trans-unit>
        <trans-unit id="3904c870d9e800cc53a98ecb8acef59d010fad3d" translate="yes" xml:space="preserve">
          <source>Throw a ValueError if X contains NaN or infinity.</source>
          <target state="translated">Lanza un ValueError si X contiene NaN o infinito.</target>
        </trans-unit>
        <trans-unit id="8b8612c016401dc529cb09be5ddd6996fe872d9c" translate="yes" xml:space="preserve">
          <source>Thus in binary classification, the count of true negatives is \(C_{0,0}\), false negatives is \(C_{1,0}\), true positives is \(C_{1,1}\) and false positives is \(C_{0,1}\).</source>
          <target state="translated">Por lo tanto,en la clasificación binaria,el conteo de los verdaderos negativos es (C_{0,0}),los falsos negativos es (C_{1,0}),los verdaderos positivos es (C_{1,1})y los falsos positivos es (C_{0,1}).</target>
        </trans-unit>
        <trans-unit id="877864e25b035038afd6bbe5a72ca90fb8e0741e" translate="yes" xml:space="preserve">
          <source>Thus the median of the input becomes the mean of the output, centered at 0. The normal output is clipped so that the input&amp;rsquo;s minimum and maximum &amp;mdash; corresponding to the 1e-7 and 1 - 1e-7 quantiles respectively &amp;mdash; do not become infinite under the transformation.</source>
          <target state="translated">Por lo tanto, la mediana de la entrada se convierte en la media de la salida, centrada en 0. La salida normal se recorta para que el m&amp;iacute;nimo y el m&amp;aacute;ximo de la entrada, correspondientes a los cuantiles 1e-7 y 1 - 1e-7 respectivamente, no se vuelvan infinitos bajo la transformaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="911ea2c24698b41ad1167139365e2f911ee7efcc" translate="yes" xml:space="preserve">
          <source>Thus, among the considered estimators, &lt;code&gt;PoissonRegressor&lt;/code&gt; and &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; are a-priori better suited for modeling the long tail distribution of the non-negative data as compared to the &lt;code&gt;Ridge&lt;/code&gt; model which makes a wrong assumption on the distribution of the target variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0808b4cdf67452766c8c5389635c6458f9990f5b" translate="yes" xml:space="preserve">
          <source>Thus, most of the target signal (34.4ppm) is explained by a long-term rising trend (length-scale 41.8 years). The periodic component has an amplitude of 3.27ppm, a decay time of 180 years and a length-scale of 1.44. The long decay time indicates that we have a locally very close to periodic seasonal component. The correlated noise has an amplitude of 0.197ppm with a length scale of 0.138 years and a white-noise contribution of 0.197ppm. Thus, the overall noise level is very small, indicating that the data can be very well explained by the model. The figure shows also that the model makes very confident predictions until around 2015</source>
          <target state="translated">Así pues,la mayor parte de la señal del objetivo (34,4 ppm)se explica por una tendencia al alza a largo plazo (41,8 años en la escala de longitud).La componente periódica tiene una amplitud de 3,27 ppm,un tiempo de decaimiento de 180 años y una escala de longitud de 1,44.El largo tiempo de decaimiento indica que tenemos un componente estacional local muy cercano al periódico.El ruido correlativo tiene una amplitud de 0,197 ppm con una escala de longitud de 0,138 años y una contribución de ruido blanco de 0,197 ppm.Por lo tanto,el nivel de ruido global es muy pequeño,lo que indica que los datos pueden ser muy bien explicados por el modelo.La figura muestra también que el modelo hace predicciones muy confiables hasta alrededor de 2015</target>
        </trans-unit>
        <trans-unit id="4ab3c0245825ab663f7197647adadf073e4b3e64" translate="yes" xml:space="preserve">
          <source>Thus, most of the target signal (34.4ppm) is explained by a long-term rising trend (length-scale 41.8 years). The periodic component has an amplitude of 3.27ppm, a decay time of 180 years and a length-scale of 1.44. The long decay time indicates that we have a locally very close to periodic seasonal component. The correlated noise has an amplitude of 0.197ppm with a length scale of 0.138 years and a white-noise contribution of 0.197ppm. Thus, the overall noise level is very small, indicating that the data can be very well explained by the model. The figure shows also that the model makes very confident predictions until around 2015.</source>
          <target state="translated">Así pues,la mayor parte de la señal del objetivo (34,4 ppm)se explica por una tendencia al alza a largo plazo (41,8 años en la escala de longitud).La componente periódica tiene una amplitud de 3,27 ppm,un tiempo de decaimiento de 180 años y una escala de longitud de 1,44.El largo tiempo de decaimiento indica que tenemos un componente estacional local muy cercano al periódico.El ruido correlativo tiene una amplitud de 0,197 ppm con una escala de longitud de 0,138 años y una contribución de ruido blanco de 0,197 ppm.Por lo tanto,el nivel de ruido global es muy pequeño,lo que indica que los datos pueden ser muy bien explicados por el modelo.La figura muestra también que el modelo hace predicciones muy confiables hasta alrededor de 2015.</target>
        </trans-unit>
        <trans-unit id="af16f18f91308907d1dd8226e54112fa0bd29044" translate="yes" xml:space="preserve">
          <source>Tian Zhang, Raghu Ramakrishnan, Maron Livny BIRCH: An efficient data clustering method for large databases. &lt;a href=&quot;http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&quot;&gt;http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&lt;/a&gt;</source>
          <target state="translated">Tian Zhang, Raghu Ramakrishnan, Maron Livny BIRCH: un m&amp;eacute;todo de agrupaci&amp;oacute;n de datos eficiente para grandes bases de datos. &lt;a href=&quot;http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&quot;&gt;http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9d89b88657fcb13ceb20c877ea478d701717a393" translate="yes" xml:space="preserve">
          <source>Tian Zhang, Raghu Ramakrishnan, Maron Livny BIRCH: An efficient data clustering method for large databases. &lt;a href=&quot;https://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&quot;&gt;https://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="867d68dbf4c080ab9e706507919b510dbb556be3" translate="yes" xml:space="preserve">
          <source>Tianqi Chen, Carlos Guestrin, &lt;a href=&quot;https://arxiv.org/abs/1603.02754&quot;&gt;&amp;ldquo;XGBoost: A Scalable Tree Boosting System&amp;rdquo;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d53cad37906f55db18b858cf86bfeef9ad9688eb" translate="yes" xml:space="preserve">
          <source>Tibshirani, R., Hastie, T., Narasimhan, B., &amp;amp; Chu, G. (2002). Diagnosis of multiple cancer types by shrunken centroids of gene expression. Proceedings of the National Academy of Sciences of the United States of America, 99(10), 6567-6572. The National Academy of Sciences.</source>
          <target state="translated">Tibshirani, R., Hastie, T., Narasimhan, B. y Chu, G. (2002). Diagn&amp;oacute;stico de m&amp;uacute;ltiples tipos de c&amp;aacute;ncer por centroides reducidos de expresi&amp;oacute;n g&amp;eacute;nica. Actas de la Academia Nacional de Ciencias de los Estados Unidos de Am&amp;eacute;rica, 99 (10), 6567-6572. La Academia Nacional de Ciencias.</target>
        </trans-unit>
        <trans-unit id="54643cfd9d395af8d03ef9fab4df1a2cdb437e0c" translate="yes" xml:space="preserve">
          <source>Tie breaking is costly if &lt;code&gt;decision_function_shape='ovr'&lt;/code&gt;, and therefore it is not enabled by default. This example illustrates the effect of the &lt;code&gt;break_ties&lt;/code&gt; parameter for a multiclass classification problem and &lt;code&gt;decision_function_shape='ovr'&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a297f524f28779281bb4e53d7b6af672dcac3672" translate="yes" xml:space="preserve">
          <source>Ties are broken using the secondary method from Leeuw, 1977.</source>
          <target state="translated">Los lazos se rompen usando el método secundario de Leeuw,1977.</target>
        </trans-unit>
        <trans-unit id="59976e05663a4d82c80a3273030c2c2f87094f4d" translate="yes" xml:space="preserve">
          <source>Ties between features with equal scores will be broken in an unspecified way.</source>
          <target state="translated">Los lazos entre los rasgos con iguales puntuaciones se romperán de forma no especificada.</target>
        </trans-unit>
        <trans-unit id="c41dd9e78b42392c90f4c6ddfb54f7863f5482f1" translate="yes" xml:space="preserve">
          <source>Ties in &lt;code&gt;y_scores&lt;/code&gt; are broken by giving maximal rank that would have been assigned to all tied values.</source>
          <target state="translated">Los empates en &lt;code&gt;y_scores&lt;/code&gt; se rompen dando el rango m&amp;aacute;ximo que se habr&amp;iacute;a asignado a todos los valores empatados.</target>
        </trans-unit>
        <trans-unit id="ba73dffe02601a1abd345b6200b276334877401b" translate="yes" xml:space="preserve">
          <source>Time Series cross-validator</source>
          <target state="translated">Validador cruzado de la serie de tiempo</target>
        </trans-unit>
        <trans-unit id="bbad16d201e3f82cae87bba42e6286ebcef9d190" translate="yes" xml:space="preserve">
          <source>Time series data is characterised by the correlation between observations that are near in time (&lt;em&gt;autocorrelation&lt;/em&gt;). However, classical cross-validation techniques such as &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt;&lt;code&gt;ShuffleSplit&lt;/code&gt;&lt;/a&gt; assume the samples are independent and identically distributed, and would result in unreasonable correlation between training and testing instances (yielding poor estimates of generalisation error) on time series data. Therefore, it is very important to evaluate our model for time series data on the &amp;ldquo;future&amp;rdquo; observations least like those that are used to train the model. To achieve this, one solution is provided by &lt;a href=&quot;generated/sklearn.model_selection.timeseriessplit#sklearn.model_selection.TimeSeriesSplit&quot;&gt;&lt;code&gt;TimeSeriesSplit&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Los datos de series de tiempo se caracterizan por la correlaci&amp;oacute;n entre observaciones cercanas en el tiempo ( &lt;em&gt;autocorrelaci&amp;oacute;n&lt;/em&gt; ). Sin embargo, las t&amp;eacute;cnicas cl&amp;aacute;sicas de validaci&amp;oacute;n cruzada como &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt; &lt;code&gt;ShuffleSplit&lt;/code&gt; &lt;/a&gt; asumen que las muestras son independientes y est&amp;aacute;n distribuidas de manera id&amp;eacute;ntica, y dar&amp;iacute;an como resultado una correlaci&amp;oacute;n irrazonable entre las instancias de entrenamiento y prueba (lo que arroja estimaciones deficientes del error de generalizaci&amp;oacute;n) en los datos de series de tiempo. Por lo tanto, es muy importante evaluar nuestro modelo para los datos de series de tiempo en las observaciones &quot;futuras&quot; menos similares a las que se utilizan para entrenar el modelo. Para lograr esto, &lt;a href=&quot;generated/sklearn.model_selection.timeseriessplit#sklearn.model_selection.TimeSeriesSplit&quot;&gt; &lt;code&gt;TimeSeriesSplit&lt;/code&gt; &lt;/a&gt; proporciona una soluci&amp;oacute;n .</target>
        </trans-unit>
        <trans-unit id="a6268d75d578276d37dec9fce6dea804677e6b49" translate="yes" xml:space="preserve">
          <source>Timeout limit for each task to complete. If any task takes longer a TimeOutError will be raised. Only applied when n_jobs != 1</source>
          <target state="translated">Límite de tiempo para cada tarea a completar.Si alguna tarea toma más tiempo,se elevará un TimeOutError.Sólo se aplica cuando n_jobs !=1</target>
        </trans-unit>
        <trans-unit id="f98ee87f52adb2c6f3aaf1f01bab51d0b9ae3622" translate="yes" xml:space="preserve">
          <source>Times spent for fitting in seconds. Only present if &lt;code&gt;return_times&lt;/code&gt; is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c46532137bb2ae8358c0137ca60928cd3434340" translate="yes" xml:space="preserve">
          <source>Times spent for scoring in seconds. Only present if &lt;code&gt;return_times&lt;/code&gt; is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="22c6faf6f7a1dbffed43da8c3c0a736a2f22b862" translate="yes" xml:space="preserve">
          <source>Timing and accuracy plots</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="834cbd0fedba36c3380f74ce91ef668820820b53" translate="yes" xml:space="preserve">
          <source>To achieve better accuracy, &lt;code&gt;X_norm_squared&lt;/code&gt; and &lt;code&gt;Y_norm_squared&lt;/code&gt; may be unused if they are passed as &lt;code&gt;float32&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8879146d32620a1e603bf26a188c9426e79a5ed0" translate="yes" xml:space="preserve">
          <source>To address the computational inefficiencies of the brute-force approach, a variety of tree-based data structures have been invented. In general, these structures attempt to reduce the required number of distance calculations by efficiently encoding aggregate distance information for the sample. The basic idea is that if point \(A\) is very distant from point \(B\), and point \(B\) is very close to point \(C\), then we know that points \(A\) and \(C\) are very distant, &lt;em&gt;without having to explicitly calculate their distance&lt;/em&gt;. In this way, the computational cost of a nearest neighbors search can be reduced to \(O[D N \log(N)]\) or better. This is a significant improvement over brute-force for large \(N\).</source>
          <target state="translated">Para abordar las ineficiencias computacionales del enfoque de fuerza bruta, se han inventado una variedad de estructuras de datos basadas en &amp;aacute;rboles. En general, estas estructuras intentan reducir el n&amp;uacute;mero requerido de c&amp;aacute;lculos de distancia mediante la codificaci&amp;oacute;n eficiente de informaci&amp;oacute;n de distancia agregada para la muestra. La idea b&amp;aacute;sica es que si el punto \ (A \) est&amp;aacute; muy lejos del punto \ (B \), y el punto \ (B \) est&amp;aacute; muy cerca del punto \ (C \), entonces sabemos que los puntos \ (A \ ) y \ (C \) est&amp;aacute;n muy distantes, &lt;em&gt;sin tener que calcular expl&amp;iacute;citamente su distancia&lt;/em&gt; . De esta manera, el costo computacional de una b&amp;uacute;squeda de vecinos m&amp;aacute;s cercanos puede reducirse a \ (O [DN \ log (N)] \) o mejor. Esta es una mejora significativa sobre la fuerza bruta para grandes \ (N \).</target>
        </trans-unit>
        <trans-unit id="81ec528524d941df99755c9bb7fceaf80c6a8752" translate="yes" xml:space="preserve">
          <source>To address the inefficiencies of KD Trees in higher dimensions, the &lt;em&gt;ball tree&lt;/em&gt; data structure was developed. Where KD trees partition data along Cartesian axes, ball trees partition data in a series of nesting hyper-spheres. This makes tree construction more costly than that of the KD tree, but results in a data structure which can be very efficient on highly structured data, even in very high dimensions.</source>
          <target state="translated">Para abordar las ineficiencias de los &amp;aacute;rboles KD en dimensiones m&amp;aacute;s altas, se desarroll&amp;oacute; la estructura de datos del &lt;em&gt;&amp;aacute;rbol de bolas&lt;/em&gt; . Donde los &amp;aacute;rboles KD dividen los datos a lo largo de ejes cartesianos, los &amp;aacute;rboles de bolas dividen los datos en una serie de hiper-esferas anidadas. Esto hace que la construcci&amp;oacute;n del &amp;aacute;rbol sea m&amp;aacute;s costosa que la del &amp;aacute;rbol KD, pero da como resultado una estructura de datos que puede ser muy eficiente en datos altamente estructurados, incluso en dimensiones muy altas.</target>
        </trans-unit>
        <trans-unit id="a11d5f0b5df4ea3ced24dc7521fb6d9f97740ba3" translate="yes" xml:space="preserve">
          <source>To address this concern, a number of supervised and unsupervised linear dimensionality reduction frameworks have been designed, such as Principal Component Analysis (PCA), Independent Component Analysis, Linear Discriminant Analysis, and others. These algorithms define specific rubrics to choose an &amp;ldquo;interesting&amp;rdquo; linear projection of the data. These methods can be powerful, but often miss important non-linear structure in the data.</source>
          <target state="translated">Para abordar esta preocupaci&amp;oacute;n, se han dise&amp;ntilde;ado una serie de marcos de reducci&amp;oacute;n de dimensionalidad lineal supervisados ​​y no supervisados, como el an&amp;aacute;lisis de componentes principales (PCA), el an&amp;aacute;lisis de componentes independientes, el an&amp;aacute;lisis discriminante lineal y otros. Estos algoritmos definen r&amp;uacute;bricas espec&amp;iacute;ficas para elegir una proyecci&amp;oacute;n lineal &quot;interesante&quot; de los datos. Estos m&amp;eacute;todos pueden ser poderosos, pero a menudo pierden una estructura no lineal importante en los datos.</target>
        </trans-unit>
        <trans-unit id="c134b5f4c4fa3b034f915a1c4077d9f58401c669" translate="yes" xml:space="preserve">
          <source>To address this issue you can use &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;sklearn.decomposition.PCA&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;whiten=True&lt;/code&gt; to further remove the linear correlation across features.</source>
          <target state="translated">Para solucionar este problema, puede usar &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;sklearn.decomposition.PCA&lt;/code&gt; &lt;/a&gt; con whiten &lt;code&gt;whiten=True&lt;/code&gt; para eliminar a&amp;uacute;n m&amp;aacute;s la correlaci&amp;oacute;n lineal entre las caracter&amp;iacute;sticas.</target>
        </trans-unit>
        <trans-unit id="5dfb268e42cc748904256c70f6b80b2da01edce9" translate="yes" xml:space="preserve">
          <source>To also transform a test set \(X\), we multiply it with \(V_k\):</source>
          <target state="translated">Para transformar también un conjunto de pruebas,lo multiplicamos por VK:</target>
        </trans-unit>
        <trans-unit id="6e914d8189fa250ac9b4b7ea3cf2e62431cbcccd" translate="yes" xml:space="preserve">
          <source>To apply an classifier on this data, we need to flatten the image, to turn the data in a (samples, feature) matrix:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ef7600ab8e39fc13b7dc9585804325c8072844d" translate="yes" xml:space="preserve">
          <source>To avoid instability issues in case the system is under-determined, regularization can be applied (Ridge regression) via the &lt;code&gt;ridge_alpha&lt;/code&gt; parameter.</source>
          <target state="translated">Para evitar problemas de inestabilidad en caso de que el sistema est&amp;eacute; &lt;code&gt;ridge_alpha&lt;/code&gt; , se puede aplicar la regularizaci&amp;oacute;n (regresi&amp;oacute;n de Ridge) a trav&amp;eacute;s del par&amp;aacute;metro ridge_alpha .</target>
        </trans-unit>
        <trans-unit id="622754a0a375aafa66f9d8336ffd00fcfc0a1948" translate="yes" xml:space="preserve">
          <source>To avoid memory copy the caller should pass a CSC matrix.</source>
          <target state="translated">Para evitar la copia de la memoria,el que llama debe pasar una matriz CSC.</target>
        </trans-unit>
        <trans-unit id="21a05d95ccb73f51d245c302b02e9a8f32df0276" translate="yes" xml:space="preserve">
          <source>To avoid memory copy the caller should pass a CSR matrix.</source>
          <target state="translated">Para evitar la copia de la memoria,la persona que llama debe pasar una matriz de CSR.</target>
        </trans-unit>
        <trans-unit id="e5ab0a4f687079cc593610e8d8c0f15b79824d4d" translate="yes" xml:space="preserve">
          <source>To avoid memory re-allocation it is advised to allocate the initial data in memory directly using that format.</source>
          <target state="translated">Para evitar la reasignación de la memoria se aconseja asignar los datos iniciales en la memoria directamente utilizando ese formato.</target>
        </trans-unit>
        <trans-unit id="ee93c7e2ac06e08c1567b0ca209ad480ea5f1b80" translate="yes" xml:space="preserve">
          <source>To avoid the computation of global clustering, for every call of &lt;code&gt;partial_fit&lt;/code&gt; the user is advised</source>
          <target state="translated">Para evitar el c&amp;aacute;lculo de la agrupaci&amp;oacute;n en cl&amp;uacute;steres global, se aconseja al usuario por cada llamada de &lt;code&gt;partial_fit&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e81cbf7353acbc69eeae43ca8cf143e58e658d10" translate="yes" xml:space="preserve">
          <source>To avoid these potential discrepancies it suffices to divide the number of occurrences of each word in a document by the total number of words in the document: these new features are called &lt;code&gt;tf&lt;/code&gt; for Term Frequencies.</source>
          <target state="translated">Para evitar estas posibles discrepancias, basta con dividir el n&amp;uacute;mero de ocurrencias de cada palabra en un documento por el n&amp;uacute;mero total de palabras en el documento: estas nuevas caracter&amp;iacute;sticas se denominan &lt;code&gt;tf&lt;/code&gt; para las frecuencias de t&amp;eacute;rminos.</target>
        </trans-unit>
        <trans-unit id="39f01dfdcdf5847fd1935ba52ba9be2bfc80430b" translate="yes" xml:space="preserve">
          <source>To avoid this problem, nested CV effectively uses a series of train/validation/test set splits. In the inner loop (here executed by &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt;), the score is approximately maximized by fitting a model to each training set, and then directly maximized in selecting (hyper)parameters over the validation set. In the outer loop (here in &lt;a href=&quot;../../modules/generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;cross_val_score&lt;/code&gt;&lt;/a&gt;), generalization error is estimated by averaging test set scores over several dataset splits.</source>
          <target state="translated">Para evitar este problema, el CV anidado utiliza de forma eficaz una serie de divisiones de conjuntos de entrenamiento / validaci&amp;oacute;n / prueba. En el ciclo interno (aqu&amp;iacute; ejecutado por &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt; ), la puntuaci&amp;oacute;n se maximiza aproximadamente al ajustar un modelo a cada conjunto de entrenamiento y luego se maximiza directamente al seleccionar (hiper) par&amp;aacute;metros sobre el conjunto de validaci&amp;oacute;n. En el ciclo externo (aqu&amp;iacute; en &lt;a href=&quot;../../modules/generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt; &lt;code&gt;cross_val_score&lt;/code&gt; &lt;/a&gt; ), el error de generalizaci&amp;oacute;n se estima promediando las puntuaciones de los conjuntos de pruebas en varias divisiones de conjuntos de datos.</target>
        </trans-unit>
        <trans-unit id="5ed52a0ba64199519b793ee9dad54a31d6d3eaed" translate="yes" xml:space="preserve">
          <source>To avoid unnecessary memory duplication the X and y arguments of the fit method should be directly passed as Fortran-contiguous numpy arrays.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a37b39aad5fcf98e98548e781cdec5193cfe7b97" translate="yes" xml:space="preserve">
          <source>To avoid unnecessary memory duplication the X argument of the fit method should be directly passed as a Fortran-contiguous numpy array.</source>
          <target state="translated">Para evitar la duplicación innecesaria de la memoria,el argumento X del método de ajuste debe pasarse directamente como una matriz numérica Fortran-contiguo.</target>
        </trans-unit>
        <trans-unit id="d9c2f7485084c926a2f68d8587d615406cc01649" translate="yes" xml:space="preserve">
          <source>To be in favorable recovery conditions, we sample the data from a model with a sparse inverse covariance matrix. In addition, we ensure that the data is not too much correlated (limiting the largest coefficient of the precision matrix) and that there a no small coefficients in the precision matrix that cannot be recovered. In addition, with a small number of observations, it is easier to recover a correlation matrix rather than a covariance, thus we scale the time series.</source>
          <target state="translated">Para estar en condiciones favorables de recuperación,tomamos muestras de los datos de un modelo con una matriz de covarianza inversa escasa.Además,nos aseguramos de que los datos no estén demasiado correlacionados (limitando el mayor coeficiente de la matriz de precisión)y que no haya pequeños coeficientes en la matriz de precisión que no puedan ser recuperados.Además,con un pequeño número de observaciones,es más fácil recuperar una matriz de correlación que una de covarianza,por lo que escalamos las series temporales.</target>
        </trans-unit>
        <trans-unit id="f7fd313aae703eaa110952d34fbc2e74f81a873c" translate="yes" xml:space="preserve">
          <source>To be removed in 0.21</source>
          <target state="translated">Se eliminará en 0,21</target>
        </trans-unit>
        <trans-unit id="b656a9f4366f6cbcc5b1e6914e7bc1a8d099ee57" translate="yes" xml:space="preserve">
          <source>To be removed in 0.22</source>
          <target state="translated">Se eliminará en 0,22</target>
        </trans-unit>
        <trans-unit id="b622879f90e0f79392a411b5be4ae9945d5e85aa" translate="yes" xml:space="preserve">
          <source>To be removed in 0.24</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc387423485c5a73576ae6f9089ec34a8b143ae6" translate="yes" xml:space="preserve">
          <source>To begin with, all values for \(r\) and \(a\) are set to zero, and the calculation of each iterates until convergence. As discussed above, in order to avoid numerical oscillations when updating the messages, the damping factor \(\lambda\) is introduced to iteration process:</source>
          <target state="translated">Para empezar,todos los valores de \N r y a se ponen a cero,y el cálculo de cada uno \N itera hasta la convergencia.Como ya se ha dicho,para evitar las oscilaciones numéricas al actualizar los mensajes,se introduce el factor de amortiguación en el proceso de iteración:</target>
        </trans-unit>
        <trans-unit id="ebc5cb56aa5d3da850d595b902c1384fa4142906" translate="yes" xml:space="preserve">
          <source>To begin, we&amp;rsquo;ll visualize our data.</source>
          <target state="translated">Para empezar, visualizaremos nuestros datos.</target>
        </trans-unit>
        <trans-unit id="57e47e513e200b11a216f9768279c1f81e7b3157" translate="yes" xml:space="preserve">
          <source>To benchmark different estimators for your case you can simply change the &lt;code&gt;n_features&lt;/code&gt; parameter in this example: &lt;a href=&quot;../auto_examples/applications/plot_prediction_latency#sphx-glr-auto-examples-applications-plot-prediction-latency-py&quot;&gt;Prediction Latency&lt;/a&gt;. This should give you an estimate of the order of magnitude of the prediction latency.</source>
          <target state="translated">Para comparar diferentes estimadores para su caso, simplemente puede cambiar el par&amp;aacute;metro &lt;code&gt;n_features&lt;/code&gt; en este ejemplo: &lt;a href=&quot;../auto_examples/applications/plot_prediction_latency#sphx-glr-auto-examples-applications-plot-prediction-latency-py&quot;&gt;Prediction Latency&lt;/a&gt; . Esto deber&amp;iacute;a darle una estimaci&amp;oacute;n del orden de magnitud de la latencia de predicci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="892d831a9e807296347eacb2e8474830ca349663" translate="yes" xml:space="preserve">
          <source>To compare a set of found biclusters to the set of true biclusters, two similarity measures are needed: a similarity measure for individual biclusters, and a way to combine these individual similarities into an overall score.</source>
          <target state="translated">Para comparar un conjunto de bíceps encontrados con el conjunto de bíceps verdaderos,se necesitan dos medidas de similitud:una medida de similitud para los bíceps individuales y una forma de combinar estas similitudes individuales en una puntuación global.</target>
        </trans-unit>
        <trans-unit id="f0ff37a06cd777b22ebe208ab3110388f720b201" translate="yes" xml:space="preserve">
          <source>To compare individual biclusters, several measures have been used. For now, only the Jaccard index is implemented:</source>
          <target state="translated">Para comparar los bíceps individuales,se han utilizado varias medidas.Por ahora,sólo se aplica el índice Jaccard:</target>
        </trans-unit>
        <trans-unit id="658de85a569a63b4d478720bcfaf7adeb72fbb36" translate="yes" xml:space="preserve">
          <source>To compare the 3 models from this perspective, one can plot the cumulative proportion of claims vs the cumulative proportion of exposure for the test samples order by the model predictions, from safest to riskiest according to each model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="30a2aa60dabe3d1d8b8497c6228442c6c55454f4" translate="yes" xml:space="preserve">
          <source>To control display of warnings.</source>
          <target state="translated">Para controlar la visualización de las advertencias.</target>
        </trans-unit>
        <trans-unit id="6c3d05eecff544d238db6888c87daeb42794f44b" translate="yes" xml:space="preserve">
          <source>To control the verbosity of the procedure.</source>
          <target state="translated">Para controlar la verborrea del procedimiento.</target>
        </trans-unit>
        <trans-unit id="d66f891ca7bde7537002ad52d27fc9dd62dd5881" translate="yes" xml:space="preserve">
          <source>To convert categorical features to such integer codes, we can use the &lt;a href=&quot;generated/sklearn.preprocessing.ordinalencoder#sklearn.preprocessing.OrdinalEncoder&quot;&gt;&lt;code&gt;OrdinalEncoder&lt;/code&gt;&lt;/a&gt;. This estimator transforms each categorical feature to one new feature of integers (0 to n_categories - 1):</source>
          <target state="translated">Para convertir caracter&amp;iacute;sticas categ&amp;oacute;ricas en tales c&amp;oacute;digos enteros, podemos usar &lt;a href=&quot;generated/sklearn.preprocessing.ordinalencoder#sklearn.preprocessing.OrdinalEncoder&quot;&gt; &lt;code&gt;OrdinalEncoder&lt;/code&gt; &lt;/a&gt; . Este estimador transforma cada caracter&amp;iacute;stica categ&amp;oacute;rica en una nueva caracter&amp;iacute;stica de enteros (0 a n_categor&amp;iacute;as - 1):</target>
        </trans-unit>
        <trans-unit id="c4d6b75ae9bd1ab8a2aa45db1ede3ed88ee6cb4c" translate="yes" xml:space="preserve">
          <source>To correct this, the list of labels should be passed in as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="693e8d8ca1982fe1e279b5869b2b710976d06558" translate="yes" xml:space="preserve">
          <source>To counter this effect we can discount the expected RI \(E[\text{RI}]\) of random labelings by defining the adjusted Rand index as follows:</source>
          <target state="translated">Para contrarrestar este efecto,podemos descontar el RI esperado de las etiquetas aleatorias definiendo el índice Rand ajustado de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="2ccfac714af4138a2df70ede11b2ff4e1963a414" translate="yes" xml:space="preserve">
          <source>To create positive examples click the left mouse button; to create negative examples click the right button.</source>
          <target state="translated">Para crear ejemplos positivos,haga clic en el botón izquierdo del ratón;para crear ejemplos negativos,haga clic en el botón derecho.</target>
        </trans-unit>
        <trans-unit id="3c7bf94a5fb077c325503613ed6e46ecc0fdb413" translate="yes" xml:space="preserve">
          <source>To decide on the importance of the features we are going to use LassoCV estimator. The features with the highest absolute &lt;code&gt;coef_&lt;/code&gt; value are considered the most important</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91f3b8c70c19596fa3422a68b56ef8a0e44f9e91" translate="yes" xml:space="preserve">
          <source>To describe the dataset as a linear model we use a ridge regressor with a very small regularization and to model the logarithm of the WAGE.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a890a65f7673c36b72863dcfff2db0d979bb71bc" translate="yes" xml:space="preserve">
          <source>To design our machine-learning pipeline, we first manually check the type of data that we are dealing with:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0bfc36f728f01d8f998e7e774b5cc731a5652d7" translate="yes" xml:space="preserve">
          <source>To disable convergence detection based on inertia, set max_no_improvement to None.</source>
          <target state="translated">Para desactivar la detección de convergencia basada en la inercia,establezca max_no_mejora en Ninguno.</target>
        </trans-unit>
        <trans-unit id="644ea86209186f0b63818c18611416bf68aa348b" translate="yes" xml:space="preserve">
          <source>To disable convergence detection based on normalized center change, set tol to 0.0 (default).</source>
          <target state="translated">Para desactivar la detección de convergencia basada en el cambio de centro normalizado,establezca el tol en 0.0 (por defecto).</target>
        </trans-unit>
        <trans-unit id="8f49411326bd4f684fb56ae33f90d4fd9150ab8c" translate="yes" xml:space="preserve">
          <source>To do the exercises, copy the content of the &amp;lsquo;skeletons&amp;rsquo; folder as a new folder named &amp;lsquo;workspace&amp;rsquo;:</source>
          <target state="translated">Para hacer los ejercicios, copie el contenido de la carpeta 'esqueletos' como una nueva carpeta llamada 'espacio de trabajo':</target>
        </trans-unit>
        <trans-unit id="79cf44a84fa8878b10f291a31335b47430451015" translate="yes" xml:space="preserve">
          <source>To each column, a different transformation can be applied, such as preprocessing or a specific feature extraction method:</source>
          <target state="translated">A cada columna se puede aplicar una transformación diferente,como el preprocesamiento o un método específico de extracción de características:</target>
        </trans-unit>
        <trans-unit id="2e998c39435525bfb05b6223ee051590414cf95b" translate="yes" xml:space="preserve">
          <source>To ensure that estimators yield reasonable predictions for different policyholder types, we can bin test samples according to &lt;code&gt;y_pred&lt;/code&gt; returned by each model. Then for each bin, we compare the mean predicted &lt;code&gt;y_pred&lt;/code&gt;, with the mean observed target:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0a5ce85df1e1aafd2ebf61b7efd7098beb62d7b" translate="yes" xml:space="preserve">
          <source>To estimate a probabilistic model (e.g. a Gaussian model), estimating the precision matrix, that is the inverse covariance matrix, is as important as estimating the covariance matrix. Indeed a Gaussian model is parametrized by the precision matrix.</source>
          <target state="translated">Para estimar un modelo probabilístico (por ejemplo,un modelo gaussiano),la estimación de la matriz de precisión,es decir,la matriz de covarianza inversa,es tan importante como la estimación de la matriz de covarianza.De hecho,un modelo gaussiano es parametrizado por la matriz de precisión.</target>
        </trans-unit>
        <trans-unit id="06985e50b51113b200d13cecad3eedd2a07fa798" translate="yes" xml:space="preserve">
          <source>To evaluate the impact of the scale of the dataset (&lt;code&gt;n_samples&lt;/code&gt; and &lt;code&gt;n_features&lt;/code&gt;) while controlling the statistical properties of the data (typically the correlation and informativeness of the features), it is also possible to generate synthetic data.</source>
          <target state="translated">Para evaluar el impacto de la escala del conjunto de datos ( &lt;code&gt;n_samples&lt;/code&gt; y &lt;code&gt;n_features&lt;/code&gt; ) mientras se controlan las propiedades estad&amp;iacute;sticas de los datos (t&amp;iacute;picamente la correlaci&amp;oacute;n e informatividad de las caracter&amp;iacute;sticas), tambi&amp;eacute;n es posible generar datos sint&amp;eacute;ticos.</target>
        </trans-unit>
        <trans-unit id="fa6d485f0cac2ad780f34f2a0f500816dbb434b1" translate="yes" xml:space="preserve">
          <source>To evaluate the pertinence of the used metrics, we will consider as a baseline a &amp;ldquo;dummy&amp;rdquo; estimator that constantly predicts the mean frequency of the training sample.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b81da86f6a51388bf88e8748866dfbc1da10ddb" translate="yes" xml:space="preserve">
          <source>To fully specify a dataset, you need to provide a name and a version, though the version is optional, see &lt;a href=&quot;#openml-versions&quot;&gt;Dataset Versions&lt;/a&gt; below. The dataset contains a total of 1080 examples belonging to 8 different classes:</source>
          <target state="translated">Para especificar completamente un conjunto de datos, debe proporcionar un nombre y una versi&amp;oacute;n, aunque la versi&amp;oacute;n es opcional, consulte &lt;a href=&quot;#openml-versions&quot;&gt;Versiones del conjunto de datos a&lt;/a&gt; continuaci&amp;oacute;n. El conjunto de datos contiene un total de 1080 ejemplos que pertenecen a 8 clases diferentes:</target>
        </trans-unit>
        <trans-unit id="eddbe44ecc236b178d14592239180b4231c2f462" translate="yes" xml:space="preserve">
          <source>To get a better measure of prediction accuracy (which we can use as a proxy for goodness of fit of the model), we can successively split the data in &lt;em&gt;folds&lt;/em&gt; that we use for training and testing:</source>
          <target state="translated">Para obtener una mejor medida de la precisi&amp;oacute;n de la predicci&amp;oacute;n (que podemos usar como un proxy de la bondad de ajuste del modelo), podemos dividir sucesivamente los datos en &lt;em&gt;pliegues&lt;/em&gt; que usamos para entrenamiento y prueba:</target>
        </trans-unit>
        <trans-unit id="8f2c7c86e5d1b0f8592203b4a46517414e54ce05" translate="yes" xml:space="preserve">
          <source>To get identical results for each split, set &lt;code&gt;random_state&lt;/code&gt; to an integer.</source>
          <target state="translated">Para obtener resultados id&amp;eacute;nticos para cada divisi&amp;oacute;n, establezca &lt;code&gt;random_state&lt;/code&gt; en un n&amp;uacute;mero entero.</target>
        </trans-unit>
        <trans-unit id="0228140936e0aced4eaa7c77d90637025c4d0909" translate="yes" xml:space="preserve">
          <source>To get started with this tutorial, you must first install &lt;em&gt;scikit-learn&lt;/em&gt; and all of its required dependencies.</source>
          <target state="translated">Para comenzar con este tutorial, primero debe instalar &lt;em&gt;scikit-learn&lt;/em&gt; y todas sus dependencias requeridas.</target>
        </trans-unit>
        <trans-unit id="8d91bad777aec839541c338ab9f11be081ee54c6" translate="yes" xml:space="preserve">
          <source>To get the signed distance to the hyperplane use &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier.decision_function&quot;&gt;&lt;code&gt;SGDClassifier.decision_function&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">Para obtener la distancia firmada al hiperplano, use &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier.decision_function&quot;&gt; &lt;code&gt;SGDClassifier.decision_function&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="507e34b3976bcfaf958e1f0006102fdd2d8713ea" translate="yes" xml:space="preserve">
          <source>To go further we remove one of the 2 features and check what is the impact on the model stability.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ae2612052e54b7be6598947088a287fffd01403" translate="yes" xml:space="preserve">
          <source>To illustrate &lt;a href=&quot;generated/sklearn.dummy.dummyclassifier#sklearn.dummy.DummyClassifier&quot;&gt;&lt;code&gt;DummyClassifier&lt;/code&gt;&lt;/a&gt;, first let&amp;rsquo;s create an imbalanced dataset:</source>
          <target state="translated">Para ilustrar &lt;a href=&quot;generated/sklearn.dummy.dummyclassifier#sklearn.dummy.DummyClassifier&quot;&gt; &lt;code&gt;DummyClassifier&lt;/code&gt; &lt;/a&gt; , primero creemos un conjunto de datos desequilibrado:</target>
        </trans-unit>
        <trans-unit id="e7a02a8f3e922c68cd6ce64dca33ce54683ffb1b" translate="yes" xml:space="preserve">
          <source>To illustrate this with a simple example, let&amp;rsquo;s assume we have 3 classifiers and a 3-class classification problems where we assign equal weights to all classifiers: w1=1, w2=1, w3=1.</source>
          <target state="translated">Para ilustrar esto con un ejemplo simple, supongamos que tenemos 3 clasificadores y un problema de clasificaci&amp;oacute;n de 3 clases donde asignamos pesos iguales a todos los clasificadores: w1 = 1, w2 = 1, w3 = 1.</target>
        </trans-unit>
        <trans-unit id="27fe4060cc8aa9166cda2609863b9fdd12999baf" translate="yes" xml:space="preserve">
          <source>To illustrate this, PCA is performed comparing the use of data with &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt;&lt;code&gt;StandardScaler&lt;/code&gt;&lt;/a&gt; applied, to unscaled data. The results are visualized and a clear difference noted. The 1st principal component in the unscaled set can be seen. It can be seen that feature #13 dominates the direction, being a whole two orders of magnitude above the other features. This is contrasted when observing the principal component for the scaled version of the data. In the scaled version, the orders of magnitude are roughly the same across all the features.</source>
          <target state="translated">Para ilustrar esto, PCA se realiza comparando el uso de datos con &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt; &lt;code&gt;StandardScaler&lt;/code&gt; &lt;/a&gt; aplicado, con datos sin escala. Los resultados se visualizan y se nota una clara diferencia. Se puede ver el primer componente principal del conjunto sin escalar. Se puede ver que la caracter&amp;iacute;stica # 13 domina la direcci&amp;oacute;n, siendo un total de dos &amp;oacute;rdenes de magnitud por encima de las otras caracter&amp;iacute;sticas. Esto se contrasta cuando se observa el componente principal de la versi&amp;oacute;n escalada de los datos. En la versi&amp;oacute;n escalada, los &amp;oacute;rdenes de magnitud son aproximadamente los mismos en todas las funciones.</target>
        </trans-unit>
        <trans-unit id="952f60109f87198cc4767d483a08ad921abb5966" translate="yes" xml:space="preserve">
          <source>To improve the conditioning of the problem (i.e. mitigating the &lt;a href=&quot;#curse-of-dimensionality&quot;&gt;The curse of dimensionality&lt;/a&gt;), it would be interesting to select only the informative features and set non-informative ones, like feature 2 to 0. Ridge regression will decrease their contribution, but not set them to zero. Another penalization approach, called &lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;Lasso&lt;/a&gt; (least absolute shrinkage and selection operator), can set some coefficients to zero. Such methods are called &lt;strong&gt;sparse method&lt;/strong&gt; and sparsity can be seen as an application of Occam&amp;rsquo;s razor: &lt;em&gt;prefer simpler models&lt;/em&gt;.</source>
          <target state="translated">Para mejorar el condicionamiento del problema (es decir, mitigar la &lt;a href=&quot;#curse-of-dimensionality&quot;&gt;La maldici&amp;oacute;n de la dimensionalidad&lt;/a&gt; ), ser&amp;iacute;a interesante seleccionar solo las caracter&amp;iacute;sticas informativas y establecer las no informativas, como la caracter&amp;iacute;stica 2 en 0. La regresi&amp;oacute;n de crestas disminuir&amp;aacute; su contribuci&amp;oacute;n, pero no establecer&amp;aacute; ellos a cero. Otro enfoque de penalizaci&amp;oacute;n, llamado &lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;Lasso&lt;/a&gt; (operador de selecci&amp;oacute;n y contracci&amp;oacute;n m&amp;iacute;nima absoluta), puede establecer algunos coeficientes en cero. Estos m&amp;eacute;todos se denominan &lt;strong&gt;m&amp;eacute;todo disperso&lt;/strong&gt; y la escasez puede verse como una aplicaci&amp;oacute;n de la navaja de Occam: &lt;em&gt;prefiera modelos m&amp;aacute;s simples&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="172f2bacd24a45cfb82f466d14d1d58833b9ee69" translate="yes" xml:space="preserve">
          <source>To install the latest version (with pip):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f028c20036ea78694db90136b8cb3004f099e0bf" translate="yes" xml:space="preserve">
          <source>To limit the memory consumption, we queue examples up to a fixed amount before feeding them to the learner.</source>
          <target state="translated">Para limitar el consumo de memoria,ponemos en cola los ejemplos hasta una cantidad fija antes de dárselos al alumno.</target>
        </trans-unit>
        <trans-unit id="61f860c325e06c4f97b9f4c7ced3d5279054856d" translate="yes" xml:space="preserve">
          <source>To load from an external dataset, please refer to &lt;a href=&quot;../../datasets/index#external-datasets&quot;&gt;loading external datasets&lt;/a&gt;.</source>
          <target state="translated">Para cargar desde un conjunto de datos externo, consulte &lt;a href=&quot;../../datasets/index#external-datasets&quot;&gt;cargar conjuntos de datos externos&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="d787fd22509da728f07846c2b5d3ecac1d6b4105" translate="yes" xml:space="preserve">
          <source>To load the data and visualize the images:</source>
          <target state="translated">Para cargar los datos y visualizar las imágenes:</target>
        </trans-unit>
        <trans-unit id="b4be4dde535adc435619c6f0e295e0ce05bad72b" translate="yes" xml:space="preserve">
          <source>To make the example run faster, we use very few hidden units, and train only for a very short time. Training longer would result in weights with a much smoother spatial appearance.</source>
          <target state="translated">Para hacer que el ejemplo corra más rápido,usamos muy pocas unidades ocultas,y entrenamos sólo por un tiempo muy corto.Entrenar más tiempo resultaría en pesos con una apariencia espacial mucho más suave.</target>
        </trans-unit>
        <trans-unit id="c413b102ea3791278492eefc26d38700197d19c5" translate="yes" xml:space="preserve">
          <source>To make the example run faster, we use very few hidden units, and train only for a very short time. Training longer would result in weights with a much smoother spatial appearance. The example will throw a warning because it doesn&amp;rsquo;t converge, in this case this is what we want because of CI&amp;rsquo;s time constraints.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96ba992a3c5af68caa74d107191c5a3c32806c93" translate="yes" xml:space="preserve">
          <source>To make the preprocessor, tokenizer and analyzers aware of the model parameters it is possible to derive from the class and override the &lt;code&gt;build_preprocessor&lt;/code&gt;, &lt;code&gt;build_tokenizer&lt;/code&gt; and &lt;code&gt;build_analyzer&lt;/code&gt; factory methods instead of passing custom functions.</source>
          <target state="translated">Para que el preprocesador, el tokenizador y los analizadores conozcan los par&amp;aacute;metros del modelo, es posible derivar de la clase y anular los m&amp;eacute;todos de f&amp;aacute;brica &lt;code&gt;build_preprocessor&lt;/code&gt; , &lt;code&gt;build_tokenizer&lt;/code&gt; y &lt;code&gt;build_analyzer&lt;/code&gt; en lugar de pasar funciones personalizadas.</target>
        </trans-unit>
        <trans-unit id="c0f08b8475e4b67e5147698ce9ccb818f0394d27" translate="yes" xml:space="preserve">
          <source>To make this more explicit, consider the following notation:</source>
          <target state="translated">Para hacerlo más explícito,considere la siguiente anotación:</target>
        </trans-unit>
        <trans-unit id="8ada09feb86f8f3751dffbeeaba0e1e4f69156a7" translate="yes" xml:space="preserve">
          <source>To obtain a fully probabilistic model, the output \(y\) is assumed to be Gaussian distributed around \(X w\):</source>
          <target state="translated">Para obtener un modelo totalmente probabilístico,se supone que la salida es gaussiana distribuida alrededor de X w:</target>
        </trans-unit>
        <trans-unit id="65178eef58b048e690e1c210520e38da80789880" translate="yes" xml:space="preserve">
          <source>To perform classification with generalized linear models, see &lt;a href=&quot;#logistic-regression&quot;&gt;Logistic regression&lt;/a&gt;.</source>
          <target state="translated">Para realizar la clasificaci&amp;oacute;n con modelos lineales generalizados, consulte &lt;a href=&quot;#logistic-regression&quot;&gt;Regresi&amp;oacute;n log&amp;iacute;stica&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="72dc32b7225454e8d7c0ec26f14d95b55df2c79a" translate="yes" xml:space="preserve">
          <source>To quantify estimation error, we plot the likelihood of unseen data for different values of the shrinkage parameter. We also show the choices by cross-validation, or with the LedoitWolf and OAS estimates.</source>
          <target state="translated">Para cuantificar el error de estimación,trazamos la probabilidad de datos no vistos para diferentes valores del parámetro de contracción.También mostramos las opciones por validación cruzada,o con las estimaciones de LedoitWolf y OAS.</target>
        </trans-unit>
        <trans-unit id="397393d3de29d9ed57b4f231bd553afc264bafab" translate="yes" xml:space="preserve">
          <source>To return the corresponding classical subsets of kddcup 99. If None, return the entire kddcup 99 dataset.</source>
          <target state="translated">Para devolver los correspondientes subconjuntos clásicos de la kddcup 99.Si es None,devuelve el conjunto de datos completo de kddcup 99.</target>
        </trans-unit>
        <trans-unit id="b0e502baa68f0434bb574994337b41db58fa07c4" translate="yes" xml:space="preserve">
          <source>To run cross-validation on multiple metrics and also to return train scores, fit times and score times.</source>
          <target state="translated">Para ejecutar la validación cruzada en múltiples métricas y también para devolver las puntuaciones de los trenes,los tiempos de ajuste y los tiempos de puntuación.</target>
        </trans-unit>
        <trans-unit id="2d79b95a40b4d1ea2f276f13509aebc984e2d932" translate="yes" xml:space="preserve">
          <source>To see how this generalizes the binary log loss given above, note that in the binary case, \(p_{i,0} = 1 - p_{i,1}\) and \(y_{i,0} = 1 - y_{i,1}\), so expanding the inner sum over \(y_{i,k} \in \{0,1\}\) gives the binary log loss.</source>
          <target state="translated">Para ver cómo esto generaliza la pérdida de logaritmo binario dada arriba,noten que en el caso binario,\N ¬(p_{i,0}=1-p_{i,1})y \N \N \N \N Ð(y_{i,0}=1-y_{i,1}),así que expandir la suma interna sobre \N \N Ð(y_{i,k}en \N la pérdida de logaritmo binario.</target>
        </trans-unit>
        <trans-unit id="25684d8b1766d360b665e8498a44a626b2b5bd13" translate="yes" xml:space="preserve">
          <source>To set &lt;code&gt;n_clusters=None&lt;/code&gt; initially</source>
          <target state="translated">Para establecer &lt;code&gt;n_clusters=None&lt;/code&gt; inicialmente</target>
        </trans-unit>
        <trans-unit id="78f293aec6a6c458449c6dc3bcd71b696525a449" translate="yes" xml:space="preserve">
          <source>To speed up the algorithm, accept only those bins with at least min_bin_freq points as seeds.</source>
          <target state="translated">Para acelerar el algoritmo,acepten sólo aquellos recipientes con al menos min_bin_freq puntos como semillas.</target>
        </trans-unit>
        <trans-unit id="e1dfcbed698085a7ab462cf760bf24e65a9e8400" translate="yes" xml:space="preserve">
          <source>To speed up the algorithm, accept only those bins with at least min_bin_freq points as seeds. If not defined, set to 1.</source>
          <target state="translated">Para acelerar el algoritmo,acepten sólo aquellos recipientes con al menos min_bin_freq puntos como semillas.Si no está definido,ponlo en 1.</target>
        </trans-unit>
        <trans-unit id="d139a616dfe019ba73a251e6419e9ddac4a94c0f" translate="yes" xml:space="preserve">
          <source>To support imputation in inductive mode we store each feature&amp;rsquo;s estimator during the &lt;code&gt;fit&lt;/code&gt; phase, and predict without refitting (in order) during the &lt;code&gt;transform&lt;/code&gt; phase.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d14a37b58107d5112ea5c1494d2809710215a276" translate="yes" xml:space="preserve">
          <source>To train the &lt;code&gt;estimators&lt;/code&gt; and &lt;code&gt;final_estimator&lt;/code&gt;, the &lt;code&gt;fit&lt;/code&gt; method needs to be called on the training data:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd2f04d7c6e080a2cce0d2e7339e598ba17acac5" translate="yes" xml:space="preserve">
          <source>To try to predict the outcome on a new document we need to extract the features using almost the same feature extracting chain as before. The difference is that we call &lt;code&gt;transform&lt;/code&gt; instead of &lt;code&gt;fit_transform&lt;/code&gt; on the transformers, since they have already been fit to the training set:</source>
          <target state="translated">Para intentar predecir el resultado de un nuevo documento, necesitamos extraer las caracter&amp;iacute;sticas utilizando casi la misma cadena de extracci&amp;oacute;n de caracter&amp;iacute;sticas que antes. La diferencia es que llamamos &lt;code&gt;transform&lt;/code&gt; en lugar de &lt;code&gt;fit_transform&lt;/code&gt; en los transformadores, ya que ya se han adaptado al conjunto de entrenamiento:</target>
        </trans-unit>
        <trans-unit id="5da67914dc5314b6125944bb748e1a3d6c08f736" translate="yes" xml:space="preserve">
          <source>To understand the use of LDA in dimensionality reduction, it is useful to start with a geometric reformulation of the LDA classification rule explained above. We write \(K\) for the total number of target classes. Since in LDA we assume that all classes have the same estimated covariance \(\Sigma\), we can rescale the data so that this covariance is the identity:</source>
          <target state="translated">Para comprender el uso de la LDA en la reducción de la dimensionalidad,es útil comenzar con una reformulación geométrica de la regla de clasificación de la LDA explicada anteriormente.Escribimos \ ~ (K)para el número total de clases de objetivo.Dado que en LDA asumimos que todas las clases tienen la misma covarianza estimada (Sigma),podemos reajustar los datos para que esta covarianza sea la identidad:</target>
        </trans-unit>
        <trans-unit id="6df5e0eab0e1e02def9ae99e68c6ddf1a841d6d1" translate="yes" xml:space="preserve">
          <source>To use &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; for novelty detection, i.e. predict labels or compute the score of abnormality of new unseen data, you need to instantiate the estimator with the &lt;code&gt;novelty&lt;/code&gt; parameter set to &lt;code&gt;True&lt;/code&gt; before fitting the estimator:</source>
          <target state="translated">Para usar &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt; para la detecci&amp;oacute;n de novedades, es decir, predecir etiquetas o calcular la puntuaci&amp;oacute;n de anormalidad de nuevos datos no vistos, debe crear una instancia del estimador con el par&amp;aacute;metro de &lt;code&gt;novelty&lt;/code&gt; establecido en &lt;code&gt;True&lt;/code&gt; antes de ajustar el estimador:</target>
        </trans-unit>
        <trans-unit id="011ed6ad19bc2f123579a7e50ff8b4dad33bf360" translate="yes" xml:space="preserve">
          <source>To use joblib.Memory to cache the svmlight file:</source>
          <target state="translated">Para usar la memoria joblib.Memory para guardar en caché el archivo svmlight:</target>
        </trans-unit>
        <trans-unit id="e88dca9a24e84cd773e046a28a4daa4e8217f9da" translate="yes" xml:space="preserve">
          <source>To use text files in a scikit-learn classification or clustering algorithm, you will need to use the :mod`~sklearn.feature_extraction.text` module to build a feature extraction transformer that suits your problem.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e11936ea84de206f18d8b708b6f4eca9fb6c8b59" translate="yes" xml:space="preserve">
          <source>To use text files in a scikit-learn classification or clustering algorithm, you will need to use the &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; module to build a feature extraction transformer that suits your problem.</source>
          <target state="translated">Para utilizar archivos de texto en una clasificaci&amp;oacute;n de scikit-learn o un algoritmo de agrupaci&amp;oacute;n en cl&amp;uacute;steres, deber&amp;aacute; utilizar el m&amp;oacute;dulo &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; para crear un transformador de extracci&amp;oacute;n de caracter&amp;iacute;sticas que se adapte a su problema.</target>
        </trans-unit>
        <trans-unit id="c7aa2d2ef894f356c354736ecb4235681bee95b2" translate="yes" xml:space="preserve">
          <source>To use this dataset with scikit-learn, we transform each 8x8 image into a feature vector of length 64</source>
          <target state="translated">Para usar este conjunto de datos con scikit-learn,transformamos cada imagen de 8x8 en un vector de características de longitud 64</target>
        </trans-unit>
        <trans-unit id="f5d271c927cff9ea25de07089e51938b7e86a2a7" translate="yes" xml:space="preserve">
          <source>To use this model as a classifier, we just need to estimate from the training data the class priors \(P(y=k)\) (by the proportion of instances of class \(k\)), the class means \(\mu_k\) (by the empirical sample class means) and the covariance matrices (either by the empirical sample class covariance matrices, or by a regularized estimator: see the section on shrinkage below).</source>
          <target state="translated">Para utilizar este modelo como clasificador,sólo necesitamos estimar,a partir de los datos de formación,las clases previas (P(y=k)\)(por la proporción de instancias de la clase \Nk),las medias de la clase \N (por las medias de la clase de la muestra empírica)y las matrices de covarianza (ya sea por las matrices de covarianza de la clase de la muestra empírica,o por un estimador regularizado:véase la sección sobre la contracción más adelante).</target>
        </trans-unit>
        <trans-unit id="54c39e1b5f1a8214dbbbffa4ce79accc0474a39a" translate="yes" xml:space="preserve">
          <source>To use this model for classification, one needs to combine a &lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt;&lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt;&lt;/a&gt; instance that learns the optimal transformation with a &lt;a href=&quot;generated/sklearn.neighbors.kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier&quot;&gt;&lt;code&gt;KNeighborsClassifier&lt;/code&gt;&lt;/a&gt; instance that performs the classification in the projected space. Here is an example using the two classes:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e5117e9f756d52dfb6878a7715bd7c9bf590353" translate="yes" xml:space="preserve">
          <source>To validate a model we need a scoring function (see &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;Metrics and scoring: quantifying the quality of predictions&lt;/a&gt;), for example accuracy for classifiers. The proper way of choosing multiple hyperparameters of an estimator are of course grid search or similar methods (see &lt;a href=&quot;grid_search#grid-search&quot;&gt;Tuning the hyper-parameters of an estimator&lt;/a&gt;) that select the hyperparameter with the maximum score on a validation set or multiple validation sets. Note that if we optimized the hyperparameters based on a validation score the validation score is biased and not a good estimate of the generalization any longer. To get a proper estimate of the generalization we have to compute the score on another test set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d015bfb570917361c4b4abaaa59f5e623d8c463" translate="yes" xml:space="preserve">
          <source>To validate a model we need a scoring function (see &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;Model evaluation: quantifying the quality of predictions&lt;/a&gt;), for example accuracy for classifiers. The proper way of choosing multiple hyperparameters of an estimator are of course grid search or similar methods (see &lt;a href=&quot;grid_search#grid-search&quot;&gt;Tuning the hyper-parameters of an estimator&lt;/a&gt;) that select the hyperparameter with the maximum score on a validation set or multiple validation sets. Note that if we optimized the hyperparameters based on a validation score the validation score is biased and not a good estimate of the generalization any longer. To get a proper estimate of the generalization we have to compute the score on another test set.</source>
          <target state="translated">Para validar un modelo, necesitamos una funci&amp;oacute;n de puntuaci&amp;oacute;n (consulte &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;Evaluaci&amp;oacute;n del modelo: cuantificaci&amp;oacute;n de la calidad de las predicciones&lt;/a&gt; ), por ejemplo, precisi&amp;oacute;n para clasificadores. La forma correcta de elegir m&amp;uacute;ltiples hiperpar&amp;aacute;metros de un estimador es, por supuesto, la b&amp;uacute;squeda en cuadr&amp;iacute;cula o m&amp;eacute;todos similares (consulte &lt;a href=&quot;grid_search#grid-search&quot;&gt;Ajuste de&lt;/a&gt; los hiperpar&amp;aacute;metros de un estimador ) que seleccionan el hiperpar&amp;aacute;metro con la puntuaci&amp;oacute;n m&amp;aacute;xima en un conjunto de validaci&amp;oacute;n o m&amp;uacute;ltiples conjuntos de validaci&amp;oacute;n. Tenga en cuenta que si optimizamos los hiperpar&amp;aacute;metros en funci&amp;oacute;n de una puntuaci&amp;oacute;n de validaci&amp;oacute;n, la puntuaci&amp;oacute;n de validaci&amp;oacute;n est&amp;aacute; sesgada y ya no es una buena estimaci&amp;oacute;n de la generalizaci&amp;oacute;n. Para obtener una estimaci&amp;oacute;n adecuada de la generalizaci&amp;oacute;n, tenemos que calcular la puntuaci&amp;oacute;n en otro conjunto de pruebas.</target>
        </trans-unit>
        <trans-unit id="4f24d3986e58b34af3ea2c4b07af932b987ecc57" translate="yes" xml:space="preserve">
          <source>To verify this interpretation we plot the variability of the AGE and EXPERIENCE coefficient.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="baa10199f999bc30e58b0035ac2f6e51132399ed" translate="yes" xml:space="preserve">
          <source>To visualize the probability weighting, we fit each classifier on the training set and plot the predicted class probabilities for the first sample in this example dataset.</source>
          <target state="translated">Para visualizar la ponderación de la probabilidad,ajustamos cada clasificador en el conjunto de entrenamiento y trazamos las probabilidades de clase pronosticadas para la primera muestra en este conjunto de datos de ejemplo.</target>
        </trans-unit>
        <trans-unit id="ba234a16bb1a2ae4619585ca04988c1afd574060" translate="yes" xml:space="preserve">
          <source>Tokenize the documents and count the occurrences of token and return them as a sparse matrix</source>
          <target state="translated">Fichar los documentos y contar las ocurrencias de las fichas y devolverlas como una matriz dispersa</target>
        </trans-unit>
        <trans-unit id="e89caeb25fc24a274e225b242d49cc6fb7ddfa72" translate="yes" xml:space="preserve">
          <source>Tokenizing text with &lt;code&gt;scikit-learn&lt;/code&gt;</source>
          <target state="translated">Tokenizar texto con &lt;code&gt;scikit-learn&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="45d4a0ebe499a5d042ac0f7bc4284501d3667758" translate="yes" xml:space="preserve">
          <source>Tolerance for &amp;lsquo;arpack&amp;rsquo; method Not used if eigen_solver==&amp;rsquo;dense&amp;rsquo;.</source>
          <target state="translated">Tolerancia para el m&amp;eacute;todo 'arpack' No se utiliza si eigen_solver == 'denso'.</target>
        </trans-unit>
        <trans-unit id="318dfc593e0123f93a8fe309f411532f48eea756" translate="yes" xml:space="preserve">
          <source>Tolerance for ARPACK. 0 means machine precision. Ignored by randomized SVD solver.</source>
          <target state="translated">Tolerancia para ARPACK.0 significa precisión de la máquina.Ignorado por el solucionador SVD aleatorio.</target>
        </trans-unit>
        <trans-unit id="13511570864a98fa2d61f43da929b11b4894937f" translate="yes" xml:space="preserve">
          <source>Tolerance for Hessian eigenmapping method. Only used if &lt;code&gt;method == 'hessian'&lt;/code&gt;</source>
          <target state="translated">Tolerancia para el m&amp;eacute;todo de mapeo propio de Hesse. Solo se usa si el &lt;code&gt;method == 'hessian'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e4c877ba267607a99e62c8b31f7891feda117cf7" translate="yes" xml:space="preserve">
          <source>Tolerance for Hessian eigenmapping method. Only used if method == &amp;lsquo;hessian&amp;rsquo;</source>
          <target state="translated">Tolerancia para el m&amp;eacute;todo de mapeo propio de Hesse. Solo se usa si el m&amp;eacute;todo == 'arpillera'</target>
        </trans-unit>
        <trans-unit id="aeb25ea9c0101939a4336136b4e11db71f1bb1be" translate="yes" xml:space="preserve">
          <source>Tolerance for modified LLE method. Only used if &lt;code&gt;method == 'modified'&lt;/code&gt;</source>
          <target state="translated">Tolerancia para el m&amp;eacute;todo LLE modificado. Solo se usa si el &lt;code&gt;method == 'modified'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="b6502cfb6f414093cd5faf0376953824eae5e86f" translate="yes" xml:space="preserve">
          <source>Tolerance for modified LLE method. Only used if method == &amp;lsquo;modified&amp;rsquo;</source>
          <target state="translated">Tolerancia para el m&amp;eacute;todo LLE modificado. Solo se usa si el m&amp;eacute;todo == 'modificado'</target>
        </trans-unit>
        <trans-unit id="40eaf2d9a188116c07595886d4a67c9121557ecf" translate="yes" xml:space="preserve">
          <source>Tolerance for singular values computed by svd_solver == &amp;lsquo;arpack&amp;rsquo;.</source>
          <target state="translated">Tolerancia para valores singulares calculados por svd_solver == 'arpack'.</target>
        </trans-unit>
        <trans-unit id="a495f50d68c5f0d21905244c442ac1ec46831c6d" translate="yes" xml:space="preserve">
          <source>Tolerance for stopping criteria.</source>
          <target state="translated">Tolerancia para los criterios de detención.</target>
        </trans-unit>
        <trans-unit id="1f900b2be351c5e1d6397b25c9a2e6c5e5c36343" translate="yes" xml:space="preserve">
          <source>Tolerance for stopping criterion.</source>
          <target state="translated">Tolerancia para el criterio de detención.</target>
        </trans-unit>
        <trans-unit id="4d73abe23fd3517118aa70ae58840719c14ae6a0" translate="yes" xml:space="preserve">
          <source>Tolerance for the early stopping. When the loss is not improving by at least tol for &lt;code&gt;n_iter_no_change&lt;/code&gt; iterations (if set to a number), the training stops.</source>
          <target state="translated">Tolerancia a la parada anticipada. Cuando la p&amp;eacute;rdida no mejora en al menos tol para &lt;code&gt;n_iter_no_change&lt;/code&gt; iteraciones (si se establece en un n&amp;uacute;mero), el entrenamiento se detiene.</target>
        </trans-unit>
        <trans-unit id="334a1d6597d473e85cc8725e20828e0c9824ea02" translate="yes" xml:space="preserve">
          <source>Tolerance for the optimization. When the loss or score is not improving by at least &lt;code&gt;tol&lt;/code&gt; for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive iterations, unless &lt;code&gt;learning_rate&lt;/code&gt; is set to &amp;lsquo;adaptive&amp;rsquo;, convergence is considered to be reached and training stops.</source>
          <target state="translated">Tolerancia para la optimizaci&amp;oacute;n. Cuando la p&amp;eacute;rdida o la puntuaci&amp;oacute;n no mejoran en al menos &lt;code&gt;tol&lt;/code&gt; para &lt;code&gt;n_iter_no_change&lt;/code&gt; iteraciones consecutivas, a menos que &lt;code&gt;learning_rate&lt;/code&gt; se establezca en 'adaptativo', se considera que se ha alcanzado la convergencia y el entrenamiento se detiene.</target>
        </trans-unit>
        <trans-unit id="6938a4dcb29969d15aaa6cafefb8f09b830ed305" translate="yes" xml:space="preserve">
          <source>Tolerance for the stopping condition.</source>
          <target state="translated">Tolerancia a la condición de parada.</target>
        </trans-unit>
        <trans-unit id="3a49445cc3e76e8c0deab47f4b10c5bd7dc33960" translate="yes" xml:space="preserve">
          <source>Tolerance of the stopping condition.</source>
          <target state="translated">Tolerancia de la condición de parada.</target>
        </trans-unit>
        <trans-unit id="48a48ded1ae1ed29a7ddaed19c15db301472918d" translate="yes" xml:space="preserve">
          <source>Tolerance on update at each iteration.</source>
          <target state="translated">Tolerancia en la actualización en cada iteración.</target>
        </trans-unit>
        <trans-unit id="a2223ba588ac8a94dc6928512bbe1ae559b46f6b" translate="yes" xml:space="preserve">
          <source>Tolerance used in the iterative algorithm default 1e-06.</source>
          <target state="translated">Tolerancia utilizada en el algoritmo iterativo por defecto 1e-06.</target>
        </trans-unit>
        <trans-unit id="20a2955c412dcae35aa2ef964ce8c2d4b1c07dcb" translate="yes" xml:space="preserve">
          <source>Tolerance when calculating spatial median.</source>
          <target state="translated">Tolerancia en el cálculo de la mediana espacial.</target>
        </trans-unit>
        <trans-unit id="f3d0c54c4b7882f5280f0492c26f2bf33d35d2a2" translate="yes" xml:space="preserve">
          <source>Tony Blair</source>
          <target state="translated">Tony Blair</target>
        </trans-unit>
        <trans-unit id="e1781cb6d03ccb2216639c1d54de7540b9fc2c2b" translate="yes" xml:space="preserve">
          <source>Tools for imputing missing values are discussed at &lt;a href=&quot;impute#impute&quot;&gt;Imputation of missing values&lt;/a&gt;.</source>
          <target state="translated">Las herramientas para imputar valores perdidos se discuten en &lt;a href=&quot;impute#impute&quot;&gt;Imputaci&amp;oacute;n de valores perdidos&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0d184ce2992ee425b9d4cc3d528da94fb4da399d" translate="yes" xml:space="preserve">
          <source>Tophat kernel (&lt;code&gt;kernel = 'tophat'&lt;/code&gt;)</source>
          <target state="translated">Kernel de Tophat ( &lt;code&gt;kernel = 'tophat'&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="0954aa60533f43dc3b2b9a9cbdee11a74f79eada" translate="yes" xml:space="preserve">
          <source>Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation</source>
          <target state="translated">Extracción del tema con Factorización de Matriz No Negativa y Asignación de Dirichlets Latentes</target>
        </trans-unit>
        <trans-unit id="97129616afbfcb01d33b44619c8bf267194395ac" translate="yes" xml:space="preserve">
          <source>Total Phenols:</source>
          <target state="translated">Fenoles totales:</target>
        </trans-unit>
        <trans-unit id="b9c3723a92a74173bb8adb739559660c0010b476" translate="yes" xml:space="preserve">
          <source>Total impurity of leaves vs effective alphas of pruned tree</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24a9e81269d05c734577a89440230faee238f7b2" translate="yes" xml:space="preserve">
          <source>Total log-likelihood of the data in X.</source>
          <target state="translated">Probabilidad logarítmica total de los datos en X.</target>
        </trans-unit>
        <trans-unit id="1861e0049c1f17066ecafccd7b29a27b43a45cf0" translate="yes" xml:space="preserve">
          <source>Total log-likelihood of the data in X. This is normalized to be a probability density, so the value will be low for high-dimensional data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0acc1077bbd3872347f5d4223b32bfa85b2dc24b" translate="yes" xml:space="preserve">
          <source>Total number of documents. Only used in the &lt;a href=&quot;#sklearn.decomposition.LatentDirichletAllocation.partial_fit&quot;&gt;&lt;code&gt;partial_fit&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4055747cee4593e58e4a6dcbfa7d6ccc61845cf0" translate="yes" xml:space="preserve">
          <source>Total number of documents. Only used in the &lt;code&gt;partial_fit&lt;/code&gt; method.</source>
          <target state="translated">N&amp;uacute;mero total de documentos. Solo se usa en el m&amp;eacute;todo de &lt;code&gt;partial_fit&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="aed40ed5719d059f29eba1177189a60b01059871" translate="yes" xml:space="preserve">
          <source>Total phenols</source>
          <target state="translated">Fenoles totales</target>
        </trans-unit>
        <trans-unit id="babba0bc0e9a3e36ce98f362a62519c8eacb94cb" translate="yes" xml:space="preserve">
          <source>Toward the Optimal Preconditioned Eigensolver: Locally Optimal Block Preconditioned Conjugate Gradient Method Andrew V. Knyazev &lt;a href=&quot;https://doi.org/10.1137%2FS1064827500366124&quot;&gt;https://doi.org/10.1137%2FS1064827500366124&lt;/a&gt;</source>
          <target state="translated">Hacia el Eigensolver preacondicionado &amp;oacute;ptimo: M&amp;eacute;todo de gradiente conjugado preacondicionado en bloque localmente &amp;oacute;ptimo Andrew V.Knyazev &lt;a href=&quot;https://doi.org/10.1137%2FS1064827500366124&quot;&gt;https://doi.org/10.1137%2FS1064827500366124&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e3ae1e8d052cc2d0c25bbda7e5d0370ec624b1e8" translate="yes" xml:space="preserve">
          <source>Toy example of 1D regression using linear, polynomial and RBF kernels.</source>
          <target state="translated">Un ejemplo de juguete de regresión 1D usando núcleos lineales,polinómicos y RBF.</target>
        </trans-unit>
        <trans-unit id="264fa08a131d6382d6715d8c951f2b5bea1c373c" translate="yes" xml:space="preserve">
          <source>Traceback example, note how the line of the error is indicated as well as the values of the parameter passed to the function that triggered the exception, even though the traceback happens in the child process:</source>
          <target state="translated">Ejemplo de rastreo,observe cómo se indica la línea del error así como los valores del parámetro pasado a la función que desencadenó la excepción,aunque el rastreo se produzca en el proceso hijo:</target>
        </trans-unit>
        <trans-unit id="8718fa41b5577d15733c0d074d4e6ea2d5f88486" translate="yes" xml:space="preserve">
          <source>Tracking, International Journal of Computer Vision, Volume 77, Issue 1-3, pp. 125-141, May 2008.</source>
          <target state="translated">Tracking,International Journal of Computer Vision,Volume 77,Issue 1-3,pp.125-141,May 2008.</target>
        </trans-unit>
        <trans-unit id="20662c705376209f11480639e3ee11e7bf62f8df" translate="yes" xml:space="preserve">
          <source>Traditional regression metrics such as Mean Squared Error and Mean Absolute Error are hard to meaningfully interpret on count values with many zeros.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e4826fce9da6f5f03d1b11115df13e0bc514c4a" translate="yes" xml:space="preserve">
          <source>Train all data by multiple calls to partial_fit.</source>
          <target state="translated">Entrenar todos los datos mediante múltiples llamadas a partial_fit.</target>
        </trans-unit>
        <trans-unit id="bd98708380c7e60a9c0a687f254abca8478a36f8" translate="yes" xml:space="preserve">
          <source>Train and test sizes may be different in each fold, with a difference of at most &lt;code&gt;n_classes&lt;/code&gt;.</source>
          <target state="translated">Los tama&amp;ntilde;os de &lt;code&gt;n_classes&lt;/code&gt; y prueba pueden ser diferentes en cada pliegue, con una diferencia de como m&amp;aacute;ximo n_classes .</target>
        </trans-unit>
        <trans-unit id="1c08c1bee3835bcafdb50e8cdda68c68d71fa67e" translate="yes" xml:space="preserve">
          <source>Train error vs Test error</source>
          <target state="translated">Error de tren vs.Error de prueba</target>
        </trans-unit>
        <trans-unit id="357c94d50b669e3c60f0758a6140ed17dc81af61" translate="yes" xml:space="preserve">
          <source>Train l1-penalized logistic regression models on a binary classification problem derived from the Iris dataset.</source>
          <target state="translated">Entrenar los modelos de regresión logística l1-penalizada en un problema de clasificación binaria derivado del conjunto de datos del Iris.</target>
        </trans-unit>
        <trans-unit id="5099d1b071bb02f5306e84c9c0e29bbe834adc72" translate="yes" xml:space="preserve">
          <source>Train models on the diabetes dataset</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0cfcb0c276264df865da734aa7faab6c6b43fed6" translate="yes" xml:space="preserve">
          <source>Train the model using libsvm (low-level method)</source>
          <target state="translated">Entrenar el modelo usando libsvm (método de bajo nivel)</target>
        </trans-unit>
        <trans-unit id="b7dd566e0e9177f3a0300b3c2ac1d09a00aaeda2" translate="yes" xml:space="preserve">
          <source>Training a Random Forest and Plotting the ROC Curve</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff5331ad7dc89bf5a9dd23c31ab738af7815c499" translate="yes" xml:space="preserve">
          <source>Training a classifier</source>
          <target state="translated">Entrenamiento de un clasificador</target>
        </trans-unit>
        <trans-unit id="8dcfc4ff7c1f7cc06878c0cf93f4198eb475ff8d" translate="yes" xml:space="preserve">
          <source>Training classifiers</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f0630eb2ecfdd0ed6f7defc6642e6c0143bcbf3" translate="yes" xml:space="preserve">
          <source>Training data</source>
          <target state="translated">Datos de entrenamiento</target>
        </trans-unit>
        <trans-unit id="6c7c988c62ce8a65ab6394bf4f62bdef696bbe60" translate="yes" xml:space="preserve">
          <source>Training data, requires length = n_samples</source>
          <target state="translated">Datos de entrenamiento,requiere longitud=n_muestras</target>
        </trans-unit>
        <trans-unit id="c0c6cec2e93954e8c33880af1baef2b15439d9d5" translate="yes" xml:space="preserve">
          <source>Training data, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the number of features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70fa8e3174eef9a1ccfc0bda8b38c7cfbf09ffd6" translate="yes" xml:space="preserve">
          <source>Training data, where n_samples in the number of samples and n_features is the number of features.</source>
          <target state="translated">Datos de entrenamiento,donde n_muestras en el número de muestras y n_características es el número de características.</target>
        </trans-unit>
        <trans-unit id="1d999bb02f6364cf15c69e5533af993a3fc0fdd8" translate="yes" xml:space="preserve">
          <source>Training data, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">Datos de entrenamiento,donde n_muestras es el número de muestras y n_características es el número de características.</target>
        </trans-unit>
        <trans-unit id="c4f931e6893a5565e07f4500ddfb86c154c8b1a3" translate="yes" xml:space="preserve">
          <source>Training data, which is also required for prediction. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead the precomputed training matrix, of shape (n_samples, n_samples).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f12731d4ed32a02266da09997a2bf0e000555cf6" translate="yes" xml:space="preserve">
          <source>Training data, which is also required for prediction. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead the precomputed training matrix, shape = [n_samples, n_samples].</source>
          <target state="translated">Datos de entrenamiento, que tambi&amp;eacute;n son necesarios para la predicci&amp;oacute;n. Si kernel == &amp;ldquo;precalculado&amp;rdquo;, esta es en cambio la matriz de entrenamiento precalculada, shape = [n_samples, n_samples].</target>
        </trans-unit>
        <trans-unit id="c5441fed149296831061b9151bd71d563327dc0d" translate="yes" xml:space="preserve">
          <source>Training data.</source>
          <target state="translated">Datos de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="4319dec91a5574f9382b1b679ba9c82bf44c0f15" translate="yes" xml:space="preserve">
          <source>Training data. If array or matrix, shape [n_samples, n_features], or [n_samples, n_samples] if metric=&amp;rsquo;precomputed&amp;rsquo;.</source>
          <target state="translated">Datos de entrenamiento. Si es una matriz o matriz, d&amp;eacute; forma a [n_samples, n_features] o [n_samples, n_samples] si metric = 'precalculado'.</target>
        </trans-unit>
        <trans-unit id="744e21c8d62df0575ccae05fe593cde4f20f55b7" translate="yes" xml:space="preserve">
          <source>Training data. If array or matrix, the shape is (n_samples, n_features), or (n_samples, n_samples) if metric=&amp;rsquo;precomputed&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6ee318ff46063d0c81310a68af0a95508a0a339" translate="yes" xml:space="preserve">
          <source>Training data. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead a precomputed kernel matrix, of shape (n_samples, n_samples).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3cc715a75ede17772899f7cc9ab69882475a79bc" translate="yes" xml:space="preserve">
          <source>Training data. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead a precomputed kernel matrix, shape = [n_samples, n_samples].</source>
          <target state="translated">Datos de entrenamiento. Si kernel == &amp;ldquo;precalculado&amp;rdquo;, se trata en cambio de una matriz de kernel precalculada, shape = [n_samples, n_samples].</target>
        </trans-unit>
        <trans-unit id="6ea489741914be2912ee247eeaf800f3ba49e6d8" translate="yes" xml:space="preserve">
          <source>Training data. If using GCV, will be cast to float64 if necessary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b12ede4c226e6e2f235813d30bce55744269c03f" translate="yes" xml:space="preserve">
          <source>Training data. Must fulfill input requirements of first step of the pipeline.</source>
          <target state="translated">Datos de entrenamiento.Debe cumplir con los requisitos de entrada del primer paso de la tubería.</target>
        </trans-unit>
        <trans-unit id="d5044fd4a2ac02d5a0b137f2f3b7fd6b8f65a006" translate="yes" xml:space="preserve">
          <source>Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If &lt;code&gt;y&lt;/code&gt; is mono-output then &lt;code&gt;X&lt;/code&gt; can be sparse.</source>
          <target state="translated">Datos de entrenamiento. Pase directamente como datos contiguos a Fortran para evitar la duplicaci&amp;oacute;n de memoria innecesaria. Si &lt;code&gt;y&lt;/code&gt; es mono-salida, &lt;code&gt;X&lt;/code&gt; puede ser escasa.</target>
        </trans-unit>
        <trans-unit id="8ed7855d8da328d2505a0bcd1c3302665b72cb3d" translate="yes" xml:space="preserve">
          <source>Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If y is mono-output, X can be sparse.</source>
          <target state="translated">Datos de entrenamiento.Pasar directamente como datos Fortran-contiguos para evitar duplicaciones innecesarias de memoria.Si y es una sola salida,X puede ser escasa.</target>
        </trans-unit>
        <trans-unit id="4c004afef287030c2dcb4a937f43adb06e1cdf0e" translate="yes" xml:space="preserve">
          <source>Training data. Shape [n_samples, n_features], or [n_samples, n_samples] if affinity==&amp;rsquo;precomputed&amp;rsquo;.</source>
          <target state="translated">Datos de entrenamiento. Forma [n_samples, n_features], o [n_samples, n_samples] si afinidad == 'precalculada'.</target>
        </trans-unit>
        <trans-unit id="30765b444b768ceb7d6bccc7cc4dd80dd79e1fcb" translate="yes" xml:space="preserve">
          <source>Training instances to cluster, or distances between instances if &lt;code&gt;affinity='precomputed'&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7fd3fb257a793666a84757ce13a7e7b97d84277" translate="yes" xml:space="preserve">
          <source>Training instances to cluster, or distances between instances if &lt;code&gt;metric='precomputed'&lt;/code&gt;. If a sparse matrix is provided, it will be converted into a sparse &lt;code&gt;csr_matrix&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="106fdf378e3c73e01e49b8eb92780c5d664680e0" translate="yes" xml:space="preserve">
          <source>Training instances to cluster, or similarities / affinities between instances if &lt;code&gt;affinity='precomputed'&lt;/code&gt;. If a sparse feature matrix is provided, it will be converted into a sparse &lt;code&gt;csr_matrix&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e31b10426b1248f84a44c65b36e8acd0e5e7589c" translate="yes" xml:space="preserve">
          <source>Training instances to cluster, or similarities / affinities between instances if &lt;code&gt;affinity='precomputed'&lt;/code&gt;. If a sparse matrix is provided in a format other than &lt;code&gt;csr_matrix&lt;/code&gt;, &lt;code&gt;csc_matrix&lt;/code&gt;, or &lt;code&gt;coo_matrix&lt;/code&gt;, it will be converted into a sparse &lt;code&gt;csr_matrix&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be8959fb1d08ac2482d5adecb9cc6d42cd3487ff" translate="yes" xml:space="preserve">
          <source>Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous.</source>
          <target state="translated">Instancias de capacitación para agrupar.Hay que tener en cuenta que los datos se convertirán en ordenamientos C,lo que provocará una copia en memoria si los datos dados no son contiguos C.</target>
        </trans-unit>
        <trans-unit id="eed67f947767b8d48d69b1a746024e52c70765e3" translate="yes" xml:space="preserve">
          <source>Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it&amp;rsquo;s not in CSR format.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1fb973e1446d09c43085a14e14217bfa82f35fac" translate="yes" xml:space="preserve">
          <source>Training set and testing set</source>
          <target state="translated">Set de entrenamiento y set de pruebas</target>
        </trans-unit>
        <trans-unit id="ea59a824d416e7ea0dc63df33b1afa59cdb64566" translate="yes" xml:space="preserve">
          <source>Training set.</source>
          <target state="translated">Juego de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="3c518c488676e60e90ca53bcc0aa7271b669fe4d" translate="yes" xml:space="preserve">
          <source>Training set: only the shape is used to find optimal random matrix dimensions based on the theory referenced in the afore mentioned papers.</source>
          <target state="translated">Juego de entrenamiento:sólo se utiliza la forma para encontrar las dimensiones óptimas de las matrices aleatorias basadas en la teoría a la que se hace referencia en los documentos mencionados.</target>
        </trans-unit>
        <trans-unit id="68d52cda6c0756d21c2527d22eda07d7e45f55d9" translate="yes" xml:space="preserve">
          <source>Training target.</source>
          <target state="translated">Objetivo de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="32e48bd3169f82f98b7879700514da5daba97549" translate="yes" xml:space="preserve">
          <source>Training targets. Must fulfill label requirements for all steps of the pipeline.</source>
          <target state="translated">Objetivos de entrenamiento.Deben cumplir con los requisitos de la etiqueta para todos los pasos del oleoducto.</target>
        </trans-unit>
        <trans-unit id="bc89d708a926da60c1e855065f294a150e4844da" translate="yes" xml:space="preserve">
          <source>Training vector, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the total number of features.</source>
          <target state="translated">Vector de entrenamiento, donde &lt;code&gt;n_samples&lt;/code&gt; es el n&amp;uacute;mero de muestras y &lt;code&gt;n_features&lt;/code&gt; es el n&amp;uacute;mero total de caracter&amp;iacute;sticas.</target>
        </trans-unit>
        <trans-unit id="325dc392b957558d0accbc4c288eabf85d0d476c" translate="yes" xml:space="preserve">
          <source>Training vector, where n_samples in the number of samples and n_features is the number of features.</source>
          <target state="translated">Vector de formación,donde n_muestras en el número de muestras y n_características es el número de características.</target>
        </trans-unit>
        <trans-unit id="01000b19ae19a1d02ea4ceb374852ca509745c92" translate="yes" xml:space="preserve">
          <source>Training vector, where n_samples in the number of samples and n_features is the number of features. Note that centroid shrinking cannot be used with sparse matrices.</source>
          <target state="translated">Vector de formación,donde n_muestras en el número de muestras y n_características es el número de características.Nótese que la contracción del centroide no puede ser usada con matrices dispersas.</target>
        </trans-unit>
        <trans-unit id="6a8354ff2f178d04d8fd18ac8502cba6a9d2e53e" translate="yes" xml:space="preserve">
          <source>Training vector, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">Vector de formación,donde n_muestras es el número de muestras y n_características es el número de características.</target>
        </trans-unit>
        <trans-unit id="d6cf7c60af251621aaa911db11caacf9c4de19a4" translate="yes" xml:space="preserve">
          <source>Training vector, where n_samples is the number of samples and n_features is the number of features. Note that centroid shrinking cannot be used with sparse matrices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23811d7edf5d74f8278700a3182a9d6e499aa68e" translate="yes" xml:space="preserve">
          <source>Training vectors, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the number of features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66e0bce9861c05444da85a9795d5edcc3de5cb5e" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">Vectores de entrenamiento,donde n_muestras es el número de muestras y n_características es el número de características.</target>
        </trans-unit>
        <trans-unit id="f64b8abd734d5648613b346b4bb3c97a56c66bbf" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of features. For kernel=&amp;rdquo;precomputed&amp;rdquo;, the expected shape of X is (n_samples, n_samples).</source>
          <target state="translated">Vectores de entrenamiento, donde n_samples es el n&amp;uacute;mero de muestras y n_features es el n&amp;uacute;mero de caracter&amp;iacute;sticas. Para kernel = &amp;rdquo;precalculado&amp;rdquo;, la forma esperada de X es (n_samples, n_samples).</target>
        </trans-unit>
        <trans-unit id="f07e6c81521ffea6a563851833abed1de8063cb9" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of features. Here, each feature of X is assumed to be from a different categorical distribution. It is further assumed that all categories of each feature are represented by the numbers 0, &amp;hellip;, n - 1, where n refers to the total number of categories for the given feature. This can, for instance, be achieved with the help of OrdinalEncoder.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1d0a9d845fc3b099041b2d0f31be0d050a7001e" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of features. When using GCV, will be cast to float64 if necessary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee5e82a19ba6d9a5b4fc8f431028f4e0ae5cae2a" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of predictors.</source>
          <target state="translated">Vectores de formación,donde n_muestras es el número de muestras y n_características es el número de predictores.</target>
        </trans-unit>
        <trans-unit id="3dbb8cbc3c8d093280069e8e889d1e0c62e1afde" translate="yes" xml:space="preserve">
          <source>Transform X back to its original space.</source>
          <target state="translated">Transformar a X de vuelta a su espacio original.</target>
        </trans-unit>
        <trans-unit id="dbfeebba6e53c937056143e8cf1258378ae1c26d" translate="yes" xml:space="preserve">
          <source>Transform X back to original space.</source>
          <target state="translated">Transformar X en el espacio original.</target>
        </trans-unit>
        <trans-unit id="aad161b5ffd8fb6722cd74d5621a58697eead90e" translate="yes" xml:space="preserve">
          <source>Transform X into a (weighted) graph of k nearest neighbors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="063b3e20cfa017691e75a65bb052691ed38fc79c" translate="yes" xml:space="preserve">
          <source>Transform X into a (weighted) graph of neighbors nearer than a radius</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2fcdcd20eec681f04cc400d1e7a3d3a35f46ced9" translate="yes" xml:space="preserve">
          <source>Transform X into subcluster centroids dimension.</source>
          <target state="translated">Transformar X en la dimensión de los centroides del subclúster.</target>
        </trans-unit>
        <trans-unit id="da3379264043ea94358e5b4b01ce80967c41f1a5" translate="yes" xml:space="preserve">
          <source>Transform X separately by each transformer, concatenate results.</source>
          <target state="translated">Transformar X por separado por cada transformador,concatenar los resultados.</target>
        </trans-unit>
        <trans-unit id="054e9dc484301382a53ef7807c44414f413c3b43" translate="yes" xml:space="preserve">
          <source>Transform X to a cluster-distance space.</source>
          <target state="translated">Transformar X en un espacio de distancia de cúmulo.</target>
        </trans-unit>
        <trans-unit id="9340d4e978871cfc2faf3772609beb4370b76837" translate="yes" xml:space="preserve">
          <source>Transform X to ordinal codes.</source>
          <target state="translated">Transformar X en códigos ordinales.</target>
        </trans-unit>
        <trans-unit id="d750cda6e828d45a370fec4538601ee99b5443be" translate="yes" xml:space="preserve">
          <source>Transform X using one-hot encoding.</source>
          <target state="translated">Transformar X usando una codificación de un solo golpe.</target>
        </trans-unit>
        <trans-unit id="f9e88a65d85f54852f98655b3f250fdbf7750c92" translate="yes" xml:space="preserve">
          <source>Transform X using the forward function.</source>
          <target state="translated">Transformar X usando la función de avance.</target>
        </trans-unit>
        <trans-unit id="fb06535ce9222390887b51d0862f28eec382f495" translate="yes" xml:space="preserve">
          <source>Transform X using the inverse function.</source>
          <target state="translated">Transformar X usando la función inversa.</target>
        </trans-unit>
        <trans-unit id="55b2dc92fd17631d37a113cafae1257246c63b9f" translate="yes" xml:space="preserve">
          <source>Transform X.</source>
          <target state="translated">Transformar X.</target>
        </trans-unit>
        <trans-unit id="df5b966033d10ab5ffd4498c25f3563581fac3a4" translate="yes" xml:space="preserve">
          <source>Transform a count matrix to a normalized tf or tf-idf representation</source>
          <target state="translated">Transformar una matriz de conteo en una representación tf o tf-idf normalizada</target>
        </trans-unit>
        <trans-unit id="c6579300b554475d257c93a2551d1e7ac8d00f29" translate="yes" xml:space="preserve">
          <source>Transform a count matrix to a tf or tf-idf representation</source>
          <target state="translated">Transformar una matriz de conteo en una representación tf o tf-idf</target>
        </trans-unit>
        <trans-unit id="cfe77beec60d283a1ae2557849fffc568b20c2b6" translate="yes" xml:space="preserve">
          <source>Transform a new matrix using the built clustering</source>
          <target state="translated">Transformar una nueva matriz usando la agrupación construida</target>
        </trans-unit>
        <trans-unit id="eb758f2f9f4d3b4a21a0f5aa711d86b7f433cb44" translate="yes" xml:space="preserve">
          <source>Transform a sequence of documents to a document-term matrix.</source>
          <target state="translated">Transformar una secuencia de documentos en una matriz de documentos.</target>
        </trans-unit>
        <trans-unit id="90d7961623626a54873e65ae75f5e5aedaf80a7d" translate="yes" xml:space="preserve">
          <source>Transform a sequence of instances to a scipy.sparse matrix.</source>
          <target state="translated">Transformar una secuencia de instancias en una matriz scipy.sparse.</target>
        </trans-unit>
        <trans-unit id="482237f55f57c5ab1436ea9ad6e0ca3a5497f2c8" translate="yes" xml:space="preserve">
          <source>Transform a signal as a sparse combination of Ricker wavelets. This example visually compares different sparse coding methods using the &lt;a href=&quot;../../modules/generated/sklearn.decomposition.sparsecoder#sklearn.decomposition.SparseCoder&quot;&gt;&lt;code&gt;sklearn.decomposition.SparseCoder&lt;/code&gt;&lt;/a&gt; estimator. The Ricker (also known as Mexican hat or the second derivative of a Gaussian) is not a particularly good kernel to represent piecewise constant signals like this one. It can therefore be seen how much adding different widths of atoms matters and it therefore motivates learning the dictionary to best fit your type of signals.</source>
          <target state="translated">Transforma una se&amp;ntilde;al como una combinaci&amp;oacute;n dispersa de ondas de Ricker. Este ejemplo compara visualmente diferentes m&amp;eacute;todos de codificaci&amp;oacute;n dispersa utilizando el estimador &lt;a href=&quot;../../modules/generated/sklearn.decomposition.sparsecoder#sklearn.decomposition.SparseCoder&quot;&gt; &lt;code&gt;sklearn.decomposition.SparseCoder&lt;/code&gt; &lt;/a&gt; . El Ricker (tambi&amp;eacute;n conocido como sombrero mexicano o la segunda derivada de un gaussiano) no es un n&amp;uacute;cleo particularmente bueno para representar se&amp;ntilde;ales constantes a trozos como este. Por lo tanto, se puede ver cu&amp;aacute;nto importa agregar diferentes anchos de &amp;aacute;tomos y, por lo tanto, motiva a aprender el diccionario para que se ajuste mejor a su tipo de se&amp;ntilde;ales.</target>
        </trans-unit>
        <trans-unit id="3c3158f9e95a76dac9ab046600d246dc683b1322" translate="yes" xml:space="preserve">
          <source>Transform array or sparse matrix X back to feature mappings.</source>
          <target state="translated">Transformar la matriz o la matriz dispersa X en mapeo de características.</target>
        </trans-unit>
        <trans-unit id="43aed443a30ff04a0a7d38cae0c2e3f2c765ad45" translate="yes" xml:space="preserve">
          <source>Transform between iterable of iterables and a multilabel format</source>
          <target state="translated">Transformar entre iterables de iterables y un formato de multi-etiqueta</target>
        </trans-unit>
        <trans-unit id="8428b18b095eb02611727f6a1283e0146f4aea18" translate="yes" xml:space="preserve">
          <source>Transform binary labels back to multi-class labels</source>
          <target state="translated">Transformar las etiquetas binarias en etiquetas multiclase</target>
        </trans-unit>
        <trans-unit id="2d5fb2d774241a80b97c22822072a1cd5822cad7" translate="yes" xml:space="preserve">
          <source>Transform data X according to the fitted model.</source>
          <target state="translated">Transformar los datos X según el modelo ajustado.</target>
        </trans-unit>
        <trans-unit id="e993947ab9336eb409d6a8eb55c55e2b5b858d46" translate="yes" xml:space="preserve">
          <source>Transform data back to its original space.</source>
          <target state="translated">Transformar los datos de vuelta a su espacio original.</target>
        </trans-unit>
        <trans-unit id="b922af176e5b4295d0d766cd496f7523d4754428" translate="yes" xml:space="preserve">
          <source>Transform data to polynomial features</source>
          <target state="translated">Transformar los datos en características polinómicas</target>
        </trans-unit>
        <trans-unit id="f1a4a6b05048c3643e26b0d505b52199b7895296" translate="yes" xml:space="preserve">
          <source>Transform dataset.</source>
          <target state="translated">Transformar el conjunto de datos.</target>
        </trans-unit>
        <trans-unit id="00a7e9f2b3e643cac0fe08c5b1d0d59cfff5c504" translate="yes" xml:space="preserve">
          <source>Transform discretized data back to original feature space.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0146265304f248a8c03f040ea5d584981839ec0b" translate="yes" xml:space="preserve">
          <source>Transform documents to document-term matrix.</source>
          <target state="translated">Transformar los documentos en una matriz de términos de documentos.</target>
        </trans-unit>
        <trans-unit id="778e7579ae52504e167839efee081ba3167de93f" translate="yes" xml:space="preserve">
          <source>Transform feature-&amp;gt;value dicts to array or sparse matrix.</source>
          <target state="translated">Transformar funci&amp;oacute;n-&amp;gt; valor dictados en matriz o matriz dispersa.</target>
        </trans-unit>
        <trans-unit id="8fde1456e50a374e1e8877ac2d0ea9941a580f00" translate="yes" xml:space="preserve">
          <source>Transform features by scaling each feature to a given range.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8f4f5c3bee4bfd8c782321e0d4eb227c2d3191b" translate="yes" xml:space="preserve">
          <source>Transform features using quantiles information.</source>
          <target state="translated">Transformar las características usando la información de los cuantiles.</target>
        </trans-unit>
        <trans-unit id="ace4ae2489dd9688eddb3a58e732664d39d28a92" translate="yes" xml:space="preserve">
          <source>Transform labels back to original encoding.</source>
          <target state="translated">Transformar las etiquetas de nuevo a la codificación original.</target>
        </trans-unit>
        <trans-unit id="76c682df30bb4975f2641f2e89f16cc0b5f2d625" translate="yes" xml:space="preserve">
          <source>Transform labels to normalized encoding.</source>
          <target state="translated">Transformar las etiquetas a una codificación normalizada.</target>
        </trans-unit>
        <trans-unit id="e6d8f7568400d53b2f444fa6cbf018c08b09552e" translate="yes" xml:space="preserve">
          <source>Transform multi-class labels to binary labels</source>
          <target state="translated">Transformar las etiquetas multiclase en etiquetas binarias</target>
        </trans-unit>
        <trans-unit id="ec1f3a72d306387b537de1b3b116fbdf51b17550" translate="yes" xml:space="preserve">
          <source>Transform new data by linear interpolation</source>
          <target state="translated">Transformar los nuevos datos por interpolación lineal</target>
        </trans-unit>
        <trans-unit id="7e25dbc81754715628745ec728c6c249ac9d1737" translate="yes" xml:space="preserve">
          <source>Transform new points into embedding space.</source>
          <target state="translated">Transformar nuevos puntos en el espacio de incrustación.</target>
        </trans-unit>
        <trans-unit id="17e15b65d999776fc7cb047cfc38d87f9b340eec" translate="yes" xml:space="preserve">
          <source>Transform the data X according to the fitted NMF model</source>
          <target state="translated">Transformar los datos X según el modelo de NMF ajustado</target>
        </trans-unit>
        <trans-unit id="28a4737ac1d13b4e451237dc699b89c49f7fb862" translate="yes" xml:space="preserve">
          <source>Transform the given indicator matrix into label sets</source>
          <target state="translated">Transformar la matriz de indicadores dada en conjuntos de etiquetas</target>
        </trans-unit>
        <trans-unit id="38739bda11e07f48ac023acb8323ed328f115bd5" translate="yes" xml:space="preserve">
          <source>Transform the given label sets</source>
          <target state="translated">Transformar los conjuntos de etiquetas dados</target>
        </trans-unit>
        <trans-unit id="92a052e88a019f5aca9bb96a9137d202560617b4" translate="yes" xml:space="preserve">
          <source>Transform the sources back to the mixed data (apply mixing matrix).</source>
          <target state="translated">Transformar las fuentes de nuevo a los datos mezclados (aplicar la matriz de mezcla).</target>
        </trans-unit>
        <trans-unit id="6414c408546f181e607c3ec28647dd72e64872ea" translate="yes" xml:space="preserve">
          <source>Transform your features into a higher dimensional, sparse space. Then train a linear model on these features.</source>
          <target state="translated">Transformar sus características en un espacio de dimensiones más altas y escasas.Luego entrena un modelo lineal sobre estas características.</target>
        </trans-unit>
        <trans-unit id="d3709f378c935401f6b259df9cce5a50135da098" translate="yes" xml:space="preserve">
          <source>Transformed array.</source>
          <target state="translated">Matriz transformada.</target>
        </trans-unit>
        <trans-unit id="4a8a97e010ec7ac27b50257ef7ee542c13ba8846" translate="yes" xml:space="preserve">
          <source>Transformed data</source>
          <target state="translated">Datos transformados</target>
        </trans-unit>
        <trans-unit id="d460e113769e190612a2b959c1c729d7e8676439" translate="yes" xml:space="preserve">
          <source>Transformed data in the binned space.</source>
          <target state="translated">Los datos transformados en el espacio de los contenedores.</target>
        </trans-unit>
        <trans-unit id="14642329121567cf9f5775d8a6512d3b978fccd2" translate="yes" xml:space="preserve">
          <source>Transformed data matrix</source>
          <target state="translated">Matriz de datos transformados</target>
        </trans-unit>
        <trans-unit id="0d3a338b719647431757293955a1513d13c572f4" translate="yes" xml:space="preserve">
          <source>Transformed data.</source>
          <target state="translated">Datos transformados.</target>
        </trans-unit>
        <trans-unit id="08b12f8aaa8632b66a6a22bc4de550a469c3cc9c" translate="yes" xml:space="preserve">
          <source>Transformed dataset.</source>
          <target state="translated">Conjunto de datos transformados.</target>
        </trans-unit>
        <trans-unit id="eeb85e59603c1cea29acb31c92a29204737376ea" translate="yes" xml:space="preserve">
          <source>Transformed input.</source>
          <target state="translated">Entrada transformada.</target>
        </trans-unit>
        <trans-unit id="0a6145f06a4913811002ff339bc5284d2892e790" translate="yes" xml:space="preserve">
          <source>Transformed samples</source>
          <target state="translated">Muestras transformadas</target>
        </trans-unit>
        <trans-unit id="a40fe3e47da3940e6c654b4aca4fd3b4db53b382" translate="yes" xml:space="preserve">
          <source>Transformed values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b6f242e80f2185c5234be3f41a48f40589d58f3" translate="yes" xml:space="preserve">
          <source>Transformer instance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd414e8652819a2c899c58cada9c3dd8cc66e071" translate="yes" xml:space="preserve">
          <source>Transformer mixin that performs feature selection given a support mask</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d517e36599e67ec967c7be2afac6d7777579d1a" translate="yes" xml:space="preserve">
          <source>Transformer used in &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt;.</source>
          <target state="translated">Transformador utilizado para &lt;code&gt;fit&lt;/code&gt; y &lt;code&gt;predict&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="43471a7ace97310a9577002aa9803e00d83e6192" translate="yes" xml:space="preserve">
          <source>Transformers are usually combined with classifiers, regressors or other estimators to build a composite estimator. The most common tool is a &lt;a href=&quot;#pipeline&quot;&gt;Pipeline&lt;/a&gt;. Pipeline is often used in combination with &lt;a href=&quot;#feature-union&quot;&gt;FeatureUnion&lt;/a&gt; which concatenates the output of transformers into a composite feature space. &lt;a href=&quot;#transformed-target-regressor&quot;&gt;TransformedTargetRegressor&lt;/a&gt; deals with transforming the &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-target&quot;&gt;target&lt;/a&gt; (i.e. log-transform &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-171&quot;&gt;y&lt;/a&gt;). In contrast, Pipelines only transform the observed data (&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-x&quot;&gt;X&lt;/a&gt;).</source>
          <target state="translated">Los transformadores generalmente se combinan con clasificadores, regresores u otros estimadores para construir un estimador compuesto. La herramienta m&amp;aacute;s com&amp;uacute;n es una &lt;a href=&quot;#pipeline&quot;&gt;tuber&amp;iacute;a&lt;/a&gt; . Pipeline se usa a menudo en combinaci&amp;oacute;n con &lt;a href=&quot;#feature-union&quot;&gt;FeatureUnion,&lt;/a&gt; que concatena la salida de los transformadores en un espacio de caracter&amp;iacute;sticas compuesto. &lt;a href=&quot;#transformed-target-regressor&quot;&gt;TransformedTargetRegressor se&lt;/a&gt; ocupa de transformar el &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-target&quot;&gt;objetivo&lt;/a&gt; (es decir, log-transform &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-171&quot;&gt;y&lt;/a&gt; ). Por el contrario, las canalizaciones solo transforman los datos observados ( &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-x&quot;&gt;X&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="021fd2002f82b7c8da7b92d01fe659fdcbdaeb82" translate="yes" xml:space="preserve">
          <source>Transformers are usually combined with classifiers, regressors or other estimators to build a composite estimator. The most common tool is a &lt;a href=&quot;#pipeline&quot;&gt;Pipeline&lt;/a&gt;. Pipeline is often used in combination with &lt;a href=&quot;#feature-union&quot;&gt;FeatureUnion&lt;/a&gt; which concatenates the output of transformers into a composite feature space. &lt;a href=&quot;#transformed-target-regressor&quot;&gt;TransformedTargetRegressor&lt;/a&gt; deals with transforming the &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-target&quot;&gt;target&lt;/a&gt; (i.e. log-transform &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-177&quot;&gt;y&lt;/a&gt;). In contrast, Pipelines only transform the observed data (&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-x&quot;&gt;X&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b69fe15775501662a569d2ed632ddbe970e558ef" translate="yes" xml:space="preserve">
          <source>Transformers for missing value imputation</source>
          <target state="translated">Transformadores para la imputación de valores perdidos</target>
        </trans-unit>
        <trans-unit id="4804df5ca1652cab2567ab10e41eae2d30b7e99a" translate="yes" xml:space="preserve">
          <source>Transforming Classifier Scores into Accurate Multiclass Probability Estimates, B. Zadrozny &amp;amp; C. Elkan, (KDD 2002)</source>
          <target state="translated">Transformaci&amp;oacute;n de las puntuaciones del clasificador en estimaciones de probabilidad precisas de varias clases, B. Zadrozny &amp;amp; C. Elkan, (KDD 2002)</target>
        </trans-unit>
        <trans-unit id="74f517360774a680819178109aa2b52b87d4fd99" translate="yes" xml:space="preserve">
          <source>Transforming distance to well-behaved similarities</source>
          <target state="translated">Transformando la distancia en similitudes de buen comportamiento</target>
        </trans-unit>
        <trans-unit id="87156c340b6aec33fafb3545fc791ff4187014aa" translate="yes" xml:space="preserve">
          <source>Transforms between iterable of iterables and a multilabel format, e.g. a (samples x classes) binary matrix indicating the presence of a class label.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dfe17b4b683a10ef2eafef30897d9c629bf96dd6" translate="yes" xml:space="preserve">
          <source>Transforms discretized data back to original feature space.</source>
          <target state="translated">Transforma los datos discretos en el espacio de características original.</target>
        </trans-unit>
        <trans-unit id="5bd7a9a7032f01002afe1d21dc1635e87bd5dbc6" translate="yes" xml:space="preserve">
          <source>Transforms features by scaling each feature to a given range.</source>
          <target state="translated">Transforma las características escalando cada característica a un rango determinado.</target>
        </trans-unit>
        <trans-unit id="45675a7235910659531092f94ca2cac1226cb6a9" translate="yes" xml:space="preserve">
          <source>Transforms lists of feature-value mappings to vectors.</source>
          <target state="translated">Transforma las listas de mapeos de valores de características en vectores.</target>
        </trans-unit>
        <trans-unit id="18a051a7877c1a9e6b194ac68c49193ac689d698" translate="yes" xml:space="preserve">
          <source>Transforms text into a sparse matrix of n-gram counts.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff596a653686d4986dda1851c66682d846f4bf4d" translate="yes" xml:space="preserve">
          <source>Transforms the image samples in X into a matrix of patch data.</source>
          <target state="translated">Transforma las muestras de imagen en X en una matriz de datos de parches.</target>
        </trans-unit>
        <trans-unit id="aff42f13a1dfe3735469a5dd26ab12a5bac4a9ad" translate="yes" xml:space="preserve">
          <source>Tree pruning</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dda8f4221caceb0e1b9d09350500616b39f0c3c5" translate="yes" xml:space="preserve">
          <source>Tree&amp;rsquo;s Feature Importance from Mean Decrease in Impurity (MDI)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6a25d0e3691aa7e7e60fcc1d61ee6046c7d09b3" translate="yes" xml:space="preserve">
          <source>Tree-based estimators (see the &lt;a href=&quot;classes#module-sklearn.tree&quot;&gt;&lt;code&gt;sklearn.tree&lt;/code&gt;&lt;/a&gt; module and forest of trees in the &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt;&lt;code&gt;sklearn.ensemble&lt;/code&gt;&lt;/a&gt; module) can be used to compute feature importances, which in turn can be used to discard irrelevant features (when coupled with the &lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt;&lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt;&lt;/a&gt; meta-transformer):</source>
          <target state="translated">Los estimadores basados ​​en &amp;aacute;rboles (consulte el m&amp;oacute;dulo &lt;a href=&quot;classes#module-sklearn.tree&quot;&gt; &lt;code&gt;sklearn.tree&lt;/code&gt; &lt;/a&gt; y el bosque de &amp;aacute;rboles en el m&amp;oacute;dulo &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt; &lt;code&gt;sklearn.ensemble&lt;/code&gt; &lt;/a&gt; ) se pueden usar para calcular la importancia de las caracter&amp;iacute;sticas, que a su vez se pueden usar para descartar caracter&amp;iacute;sticas irrelevantes (cuando se &lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt; &lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt; &lt;/a&gt; con sklearn.feature_selection.SelectFromModel metatransformador):</target>
        </trans-unit>
        <trans-unit id="ccdf4aec1fccb56109a1e3945469e98a8d62aca9" translate="yes" xml:space="preserve">
          <source>Tree-based estimators (see the &lt;a href=&quot;classes#module-sklearn.tree&quot;&gt;&lt;code&gt;sklearn.tree&lt;/code&gt;&lt;/a&gt; module and forest of trees in the &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt;&lt;code&gt;sklearn.ensemble&lt;/code&gt;&lt;/a&gt; module) can be used to compute impurity-based feature importances, which in turn can be used to discard irrelevant features (when coupled with the &lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt;&lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt;&lt;/a&gt; meta-transformer):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3629b84a13698bd03a810f8a682027a82e4a7e42" translate="yes" xml:space="preserve">
          <source>Tree-based models provide an alternative measure of &lt;a href=&quot;ensemble#random-forest-feature-importance&quot;&gt;feature importances based on the mean decrease in impurity&lt;/a&gt; (MDI). Impurity is quantified by the splitting criterion of the decision trees (Gini, Entropy or Mean Squared Error). However, this method can give high importance to features that may not be predictive on unseen data when the model is overfitting. Permutation-based feature importance, on the other hand, avoids this issue, since it can be computed on unseen data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="81d8ac0c0739336d0bbd6f8053b2fde8039cdb1c" translate="yes" xml:space="preserve">
          <source>Triangle Inequality: d(x, y) + d(y, z) &amp;gt;= d(x, z)</source>
          <target state="translated">Desigualdad del tri&amp;aacute;ngulo: d (x, y) + d (y, z)&amp;gt; = d (x, z)</target>
        </trans-unit>
        <trans-unit id="331d2c199452ae22aa8941c5bcbe6a7fe41c68b5" translate="yes" xml:space="preserve">
          <source>Tristan Fletcher: &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.651.8603&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Relevance Vector Machines explained&lt;/a&gt;</source>
          <target state="translated">Tristan Fletcher: &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.651.8603&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Explicaci&amp;oacute;n de las m&amp;aacute;quinas vectoriales de relevancia&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3b19d80cd81c13647ace615b9d73da08b4d8c61b" translate="yes" xml:space="preserve">
          <source>True : always precompute distances</source>
          <target state="translated">Cierto:siempre precalcular las distancias</target>
        </trans-unit>
        <trans-unit id="27f22be4c5a651c1c27cbdc4b85cf77c839d3ddd" translate="yes" xml:space="preserve">
          <source>True : always precompute distances.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebac1d7d68472a848a069828ba36b6b2dd6227bb" translate="yes" xml:space="preserve">
          <source>True binary labels in binary indicator format.</source>
          <target state="translated">Etiquetas binarias verdaderas en formato de indicador binario.</target>
        </trans-unit>
        <trans-unit id="94ad072572f1b0d8a6896ff3fd5d5269c3006cce" translate="yes" xml:space="preserve">
          <source>True binary labels or binary label indicators.</source>
          <target state="translated">Etiquetas binarias verdaderas o indicadores de etiquetas binarias.</target>
        </trans-unit>
        <trans-unit id="173029937373f6d16ed7438491b1a8131b2bc4cb" translate="yes" xml:space="preserve">
          <source>True binary labels. If labels are not either {-1, 1} or {0, 1}, then pos_label should be explicitly given.</source>
          <target state="translated">Verdaderas etiquetas binarias.Si las etiquetas no son {-1,1}o {0,1},entonces se debe dar explícitamente pos_etiqueta.</target>
        </trans-unit>
        <trans-unit id="394534b1dcaf25753dd90ddcd321d6ef1b441d87" translate="yes" xml:space="preserve">
          <source>True if a fixed vocabulary of term to indices mapping is provided by the user</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cba1cd7ae39f91f6d0e2908d3956200bdf94de07" translate="yes" xml:space="preserve">
          <source>True if estimator is a classifier and False otherwise.</source>
          <target state="translated">Cierto si el estimador es un clasificador y falso si no.</target>
        </trans-unit>
        <trans-unit id="7e34070b9f977933411df9b814860396cade02bb" translate="yes" xml:space="preserve">
          <source>True if estimator is a regressor and False otherwise.</source>
          <target state="translated">Cierto si el estimador es un regresor y falso si no.</target>
        </trans-unit>
        <trans-unit id="d039a95b006860b5b92d23f84015c0458d6fdb1a" translate="yes" xml:space="preserve">
          <source>True if the array returned from predict is to be in sparse CSC format. Is automatically set to True if the input y is passed in sparse format.</source>
          <target state="translated">Cierto si la matriz devuelta de la predicción va a estar en un formato CSC escaso.Se establece automáticamente en True si la entrada y se pasa en formato disperso.</target>
        </trans-unit>
        <trans-unit id="018f28ffd2c7241c63be51b46bba3e8aa528d907" translate="yes" xml:space="preserve">
          <source>True if the input data to transform is given as a sparse matrix, False otherwise.</source>
          <target state="translated">Cierto si los datos de entrada a transformar se dan como una matriz dispersa,falso en caso contrario.</target>
        </trans-unit>
        <trans-unit id="06236e43536e8bd62b7d950e36ddd9dca022a999" translate="yes" xml:space="preserve">
          <source>True if the output at fit is 2d, else false.</source>
          <target state="translated">Cierto si la salida en el ajuste es 2d,si no,falso.</target>
        </trans-unit>
        <trans-unit id="abda54d00232aa3c71419926e38966e372a6e200" translate="yes" xml:space="preserve">
          <source>True if the returned array from transform is desired to be in sparse CSR format.</source>
          <target state="translated">Cierto si se desea que la matriz devuelta de la transformación esté en formato CSR escaso.</target>
        </trans-unit>
        <trans-unit id="b3f5d1c4b9aeea8d97315ada02d3f0f3b6e0dbc5" translate="yes" xml:space="preserve">
          <source>True labels for X.</source>
          <target state="translated">Etiquetas verdaderas para X.</target>
        </trans-unit>
        <trans-unit id="d40646e12c6271d621333c3801ded96344098308" translate="yes" xml:space="preserve">
          <source>True labels or binary label indicators. The binary and multiclass cases expect labels with shape (n_samples,) while the multilabel case expects binary label indicators with shape (n_samples, n_classes).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24a7816a0ae25d0715f83e367246b56738200fc8" translate="yes" xml:space="preserve">
          <source>True mutual information can&amp;rsquo;t be negative. If its estimate turns out to be negative, it is replaced by zero.</source>
          <target state="translated">La verdadera informaci&amp;oacute;n mutua no puede ser negativa. Si su estimaci&amp;oacute;n resulta ser negativa, se reemplaza por cero.</target>
        </trans-unit>
        <trans-unit id="1086f49a3e748a59792d8342e65dffdfa18d8ff5" translate="yes" xml:space="preserve">
          <source>True positive rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e857c90bead41164c28f265fe201e3c7a69f5d75" translate="yes" xml:space="preserve">
          <source>True target, consisting of integers of two values. The positive label must be greater than the negative label.</source>
          <target state="translated">El verdadero objetivo,que consiste en números enteros de dos valores.La etiqueta positiva debe ser mayor que la negativa.</target>
        </trans-unit>
        <trans-unit id="5f6f5563a268706baa91536cfcd1565c453cd8e7" translate="yes" xml:space="preserve">
          <source>True targets of binary classification in range {-1, 1} or {0, 1}.</source>
          <target state="translated">Verdaderos objetivos de clasificación binaria en el rango {-1,1}o {0,1}.</target>
        </trans-unit>
        <trans-unit id="308caeb8e2723647ce2ad06a73f50c7b1bd2b781" translate="yes" xml:space="preserve">
          <source>True targets of multilabel classification, or true scores of entities to be ranked.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e2bbfc40bf0e63b31fb5b0351be961b49cc74be" translate="yes" xml:space="preserve">
          <source>True targets.</source>
          <target state="translated">Verdaderos objetivos.</target>
        </trans-unit>
        <trans-unit id="18dd5ee40d70767a2f6629e8ff8969a87290115e" translate="yes" xml:space="preserve">
          <source>True values for X</source>
          <target state="translated">Los verdaderos valores para X</target>
        </trans-unit>
        <trans-unit id="81e3774c236b4c61a22388a1a822b3e69fb3e5a6" translate="yes" xml:space="preserve">
          <source>True values for X.</source>
          <target state="translated">Valores reales para X.</target>
        </trans-unit>
        <trans-unit id="7e4dee4cabccdb0d80fb65794484e70b177b35d1" translate="yes" xml:space="preserve">
          <source>True values of target.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d7ce48badf2f0a91a36bec7511768633417749f" translate="yes" xml:space="preserve">
          <source>True when convergence was reached in fit(), False otherwise.</source>
          <target state="translated">Cierto cuando la convergencia se alcanzó en fit(),Falso en caso contrario.</target>
        </trans-unit>
        <trans-unit id="d333cd18e174fe06286d776d55b1b9eaf760ce1b" translate="yes" xml:space="preserve">
          <source>True: Force all values of X to be finite.</source>
          <target state="translated">Cierto:Forzar que todos los valores de X sean finitos.</target>
        </trans-unit>
        <trans-unit id="42eef53fc6823568b56bf4bf254799ea2d7766d8" translate="yes" xml:space="preserve">
          <source>True: Force all values of array to be finite.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="260b9ffda14105c1fd2ffa31d36eae7c83268ddd" translate="yes" xml:space="preserve">
          <source>True: the results is casted to an unsigned int</source>
          <target state="translated">Cierto:los resultados se envían a un int sin firmar.</target>
        </trans-unit>
        <trans-unit id="e67782a583f6700ced58a8f740875b4358d4fb58" translate="yes" xml:space="preserve">
          <source>Trustworthiness of the low-dimensional embedding.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00b6f6ebc7b7070cf35772b16b427811573346a1" translate="yes" xml:space="preserve">
          <source>Try classifying classes 1 and 2 from the iris dataset with SVMs, with the 2 first features. Leave out 10% of each class and test prediction performance on these observations.</source>
          <target state="translated">Intenta clasificar las clases 1 y 2 del conjunto de datos del iris con SVM,con las 2 primeras características.Deje fuera el 10% de cada clase y pruebe el rendimiento de la predicción en estas observaciones.</target>
        </trans-unit>
        <trans-unit id="5449ae93c54cf3f8e79ab0ee95bb4ee118bd4f84" translate="yes" xml:space="preserve">
          <source>Try classifying the digits dataset with nearest neighbors and a linear model. Leave out the last 10% and test prediction performance on these observations.</source>
          <target state="translated">Intenta clasificar el conjunto de datos de los dígitos con los vecinos más cercanos y un modelo lineal.Deje fuera el último 10% y pruebe el rendimiento de la predicción en estas observaciones.</target>
        </trans-unit>
        <trans-unit id="7a783eca4388b1c7b8c830f476caa080328ba3c3" translate="yes" xml:space="preserve">
          <source>Try playing around with the &lt;code&gt;analyzer&lt;/code&gt; and &lt;code&gt;token normalisation&lt;/code&gt; under &lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Intente jugar con el &lt;code&gt;analyzer&lt;/code&gt; y la &lt;code&gt;token normalisation&lt;/code&gt; en &lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="b7e468fa3f6cfdfb33fa6bf28dcdf3165bf89507" translate="yes" xml:space="preserve">
          <source>Try to differentiate the two first classes of the iris data</source>
          <target state="translated">Intenta diferenciar las dos primeras clases de datos del iris</target>
        </trans-unit>
        <trans-unit id="1bc09af6523c25787ea3631aac8c3f52f8bc29dc" translate="yes" xml:space="preserve">
          <source>Try using &lt;a href=&quot;../../modules/decomposition#lsa&quot;&gt;Truncated SVD&lt;/a&gt; for &lt;a href=&quot;https://en.wikipedia.org/wiki/Latent_semantic_analysis&quot;&gt;latent semantic analysis&lt;/a&gt;.</source>
          <target state="translated">Intente usar &lt;a href=&quot;../../modules/decomposition#lsa&quot;&gt;SVD truncado&lt;/a&gt; para &lt;a href=&quot;https://en.wikipedia.org/wiki/Latent_semantic_analysis&quot;&gt;an&amp;aacute;lisis sem&amp;aacute;ntico latente&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="126c548fa4d4a4c65c7759b8f0eb82ce5677dab5" translate="yes" xml:space="preserve">
          <source>Tsoumakas, G., Katakis, I., &amp;amp; Vlahavas, I. (2010). Mining multi-label data. In Data mining and knowledge discovery handbook (pp. 667-685). Springer US.</source>
          <target state="translated">Tsoumakas, G., Katakis, I. y Vlahavas, I. (2010). Extracci&amp;oacute;n de datos de m&amp;uacute;ltiples etiquetas. En el manual de miner&amp;iacute;a de datos y descubrimiento de conocimientos (p&amp;aacute;gs. 667-685). Springer EE. UU.</target>
        </trans-unit>
        <trans-unit id="0d016a3ee3141a6ebd01b9c31169fb6ec8d37fd6" translate="yes" xml:space="preserve">
          <source>Tuning the hyper-parameters of an estimator</source>
          <target state="translated">Sintonizar los hiperparámetros de un estimador</target>
        </trans-unit>
        <trans-unit id="2e926727653886b165b872a4b6b2a62bf90f0bd1" translate="yes" xml:space="preserve">
          <source>Tuple of row and column indicators for a set of biclusters.</source>
          <target state="translated">Tupla de indicadores de fila y columna para un conjunto de bíceps.</target>
        </trans-unit>
        <trans-unit id="a813118f879d8793b6336ef94325f8c8d09426be" translate="yes" xml:space="preserve">
          <source>Tuples of the form (transformer, columns) specifying the transformer objects to be applied to subsets of the data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c054700312acf34cbacbc98d115120c76da3a6d5" translate="yes" xml:space="preserve">
          <source>Turn seed into a np.random.RandomState instance</source>
          <target state="translated">Convierte la semilla en una instancia np.random.RandomState</target>
        </trans-unit>
        <trans-unit id="4b18a115e0842d6d0ba3a4ec2ed7b07c665b5f56" translate="yes" xml:space="preserve">
          <source>Tutorial exercises</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="007a671747688cedb01751baca6545483f05de7a" translate="yes" xml:space="preserve">
          <source>Tutorial setup</source>
          <target state="translated">Configuración del tutorial</target>
        </trans-unit>
        <trans-unit id="025f75efad84ed2b985f2818a53e81aa77abca7c" translate="yes" xml:space="preserve">
          <source>Tutorial: A tutorial on statistical-learning for scientific data processing</source>
          <target state="translated">Tutorial:Un tutorial sobre el aprendizaje estadístico para el procesamiento de datos científicos</target>
        </trans-unit>
        <trans-unit id="e7df3b5ebbaf2fd3b4b4579edbd7ce42f46db699" translate="yes" xml:space="preserve">
          <source>Tutorial: An introduction to machine learning with scikit-learn</source>
          <target state="translated">Tutorial:Una introducción al aprendizaje de la máquina con scikit-learn</target>
        </trans-unit>
        <trans-unit id="8682fb6c27e32858369b74e47f829fad6c8d3a68" translate="yes" xml:space="preserve">
          <source>Tutorial: Choosing the right estimator</source>
          <target state="translated">Tutorial:Elegir el estimador correcto</target>
        </trans-unit>
        <trans-unit id="2865c0d93493065de0c34da92792e35a845226d3" translate="yes" xml:space="preserve">
          <source>Tutorial: Model selection</source>
          <target state="translated">Tutorial:Model selection</target>
        </trans-unit>
        <trans-unit id="b7709b919b68974b71489ceb95a00ef31c4eda72" translate="yes" xml:space="preserve">
          <source>Tutorial: Putting it all together</source>
          <target state="translated">Tutorial:Poniendo todo junto</target>
        </trans-unit>
        <trans-unit id="b0b3bc4bbf4e62230750bf24baeb122d7a994298" translate="yes" xml:space="preserve">
          <source>Tutorial: Statistical learning</source>
          <target state="translated">Tutorial:Aprendizaje estadístico</target>
        </trans-unit>
        <trans-unit id="a149365421f01d98250256737c350c42a4cd4b82" translate="yes" xml:space="preserve">
          <source>Tutorial: Supervised learning</source>
          <target state="translated">Tutorial:Aprendizaje supervisado</target>
        </trans-unit>
        <trans-unit id="4353f067a68843e09ae0691ab9f9c44ef2e6db23" translate="yes" xml:space="preserve">
          <source>Tutorial: Unsupervised learning</source>
          <target state="translated">Tutorial:Aprendizaje no supervisado</target>
        </trans-unit>
        <trans-unit id="206fac7baeed5ee14f8990630b6607a7c33e8644" translate="yes" xml:space="preserve">
          <source>Tutorial: Working With Text Data</source>
          <target state="translated">Tutorial:Trabajando con datos de texto</target>
        </trans-unit>
        <trans-unit id="b919de3c63710fd07133db7062fb5a1fbffa0bfe" translate="yes" xml:space="preserve">
          <source>Tutorial: scikit-learn Tutorials</source>
          <target state="translated">Tutorial:scikit-learn Tutoriales</target>
        </trans-unit>
        <trans-unit id="654171647baa6be8557a5d627cf35c7075ebb257" translate="yes" xml:space="preserve">
          <source>Tutorials</source>
          <target state="translated">Tutorials</target>
        </trans-unit>
        <trans-unit id="b9f0efb9bc5f86b33edfdb893732e46d86a776bd" translate="yes" xml:space="preserve">
          <source>Tweedie deviance is a homogeneous function of degree &lt;code&gt;2-power&lt;/code&gt;. Thus, Gamma distribution with &lt;code&gt;power=2&lt;/code&gt; means that simultaneously scaling &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; has no effect on the deviance. For Poisson distribution &lt;code&gt;power=1&lt;/code&gt; the deviance scales linearly, and for Normal distribution (&lt;code&gt;power=0&lt;/code&gt;), quadratically. In general, the higher &lt;code&gt;power&lt;/code&gt; the less weight is given to extreme deviations between true and predicted targets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b534d41a45e4c1bc7da48b9a62fdc9565da97cac" translate="yes" xml:space="preserve">
          <source>Tweedie power parameter. Either power &amp;lt;= 0 or power &amp;gt;= 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25d7747a25958e3f10fc9c93bbab44d13248adbd" translate="yes" xml:space="preserve">
          <source>Tweedie regression on insurance claims</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="995550b74403db560a3a2ea8d3906cd56b901336" translate="yes" xml:space="preserve">
          <source>Two algorithms are demoed: ordinary k-means and its more scalable cousin minibatch k-means.</source>
          <target state="translated">Se demuestran dos algoritmos:el k-means ordinario y su primo más escalable el minibatch k-means.</target>
        </trans-unit>
        <trans-unit id="3b934d458351995534fed7d234de7b14c38f4cd4" translate="yes" xml:space="preserve">
          <source>Two approaches for performing calibration of probabilistic predictions are provided: a parametric approach based on Platt&amp;rsquo;s sigmoid model and a non-parametric approach based on isotonic regression (&lt;a href=&quot;classes#module-sklearn.isotonic&quot;&gt;&lt;code&gt;sklearn.isotonic&lt;/code&gt;&lt;/a&gt;). Probability calibration should be done on new data not used for model fitting. The class &lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt;&lt;code&gt;CalibratedClassifierCV&lt;/code&gt;&lt;/a&gt; uses a cross-validation generator and estimates for each split the model parameter on the train samples and the calibration of the test samples. The probabilities predicted for the folds are then averaged. Already fitted classifiers can be calibrated by &lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt;&lt;code&gt;CalibratedClassifierCV&lt;/code&gt;&lt;/a&gt; via the parameter cv=&amp;rdquo;prefit&amp;rdquo;. In this case, the user has to take care manually that data for model fitting and calibration are disjoint.</source>
          <target state="translated">Se proporcionan dos enfoques para realizar la calibraci&amp;oacute;n de predicciones probabil&amp;iacute;sticas: un enfoque param&amp;eacute;trico basado en el modelo sigmoide de Platt y un enfoque no param&amp;eacute;trico basado en regresi&amp;oacute;n isot&amp;oacute;nica ( &lt;a href=&quot;classes#module-sklearn.isotonic&quot;&gt; &lt;code&gt;sklearn.isotonic&lt;/code&gt; &lt;/a&gt; ). La calibraci&amp;oacute;n de probabilidad debe realizarse con datos nuevos que no se utilicen para el ajuste del modelo. La clase &lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt; &lt;code&gt;CalibratedClassifierCV&lt;/code&gt; &lt;/a&gt; utiliza un generador de validaci&amp;oacute;n cruzada y estima para cada divisi&amp;oacute;n el par&amp;aacute;metro del modelo en las muestras de tren y la calibraci&amp;oacute;n de las muestras de prueba. A continuaci&amp;oacute;n, se promedian las probabilidades predichas para los pliegues. &lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt; &lt;code&gt;CalibratedClassifierCV&lt;/code&gt; &lt;/a&gt; puede calibrar clasificadores ya instalados mediante el par&amp;aacute;metro cv = &amp;rdquo;prefit&amp;rdquo;. En este caso, el usuario debe tener cuidado manualmente de que los datos para el ajuste y la calibraci&amp;oacute;n del modelo sean inconexos.</target>
        </trans-unit>
        <trans-unit id="de7e8d6ad699213a292d0c528c5ddad33bca14ae" translate="yes" xml:space="preserve">
          <source>Two consequences of imposing a connectivity can be seen. First clustering with a connectivity matrix is much faster.</source>
          <target state="translated">Se pueden ver dos consecuencias de la imposición de una conectividad.La primera es que la agrupación con una matriz de conectividad es mucho más rápida.</target>
        </trans-unit>
        <trans-unit id="73ece4ca1e1779fbf5110031e848f2313deac958" translate="yes" xml:space="preserve">
          <source>Two cross-validation loops are performed in parallel: one by the &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; estimator to set &lt;code&gt;gamma&lt;/code&gt; and the other one by &lt;code&gt;cross_val_score&lt;/code&gt; to measure the prediction performance of the estimator. The resulting scores are unbiased estimates of the prediction score on new data.</source>
          <target state="translated">Se realizan dos ciclos de validaci&amp;oacute;n cruzada en paralelo: uno mediante el estimador &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt; para establecer &lt;code&gt;gamma&lt;/code&gt; y el otro mediante &lt;code&gt;cross_val_score&lt;/code&gt; para medir el rendimiento de predicci&amp;oacute;n del estimador. Las puntuaciones resultantes son estimaciones no sesgadas de la puntuaci&amp;oacute;n de predicci&amp;oacute;n sobre nuevos datos.</target>
        </trans-unit>
        <trans-unit id="d467efdd44bf60415fc895b8589d9d81d46d02ec" translate="yes" xml:space="preserve">
          <source>Two families of ensemble methods are usually distinguished:</source>
          <target state="translated">Se suelen distinguir dos familias de métodos de conjunto:</target>
        </trans-unit>
        <trans-unit id="e8ac95de27d48015555c5b981483208d51b8f268" translate="yes" xml:space="preserve">
          <source>Two feature extraction methods can be used in this example:</source>
          <target state="translated">En este ejemplo se pueden utilizar dos métodos de extracción de características:</target>
        </trans-unit>
        <trans-unit id="ebb2ce8305b879c94bfe5ff4f307e7a35d679e99" translate="yes" xml:space="preserve">
          <source>Two plots will be shown for each scaler/normalizer/transformer. The left figure will show a scatter plot of the full data set while the right figure will exclude the extreme values considering only 99 % of the data set, excluding marginal outliers. In addition, the marginal distributions for each feature will be shown on the side of the scatter plot.</source>
          <target state="translated">Se mostrarán dos gráficos para cada escalador/normalizador/transformador.La figura de la izquierda mostrará un gráfico de dispersión del conjunto de datos completo,mientras que la figura de la derecha excluirá los valores extremos considerando sólo el 99% del conjunto de datos,excluyendo los valores atípicos marginales.Además,las distribuciones marginales de cada característica se mostrarán en el lado del diagrama de dispersión.</target>
        </trans-unit>
        <trans-unit id="d08300d20f1b41587441de06b29a0ea2e0345c8c" translate="yes" xml:space="preserve">
          <source>Two regions are populated: when the EXPERIENCE coefficient is positive the AGE one is negative and viceversa.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="348f286c4d7d6b276984cd38d102dc527023a237" translate="yes" xml:space="preserve">
          <source>Two separate datasets are used for the two different plots. The reason behind this is the &lt;code&gt;l1&lt;/code&gt; case works better on sparse data, while &lt;code&gt;l2&lt;/code&gt; is better suited to the non-sparse case.</source>
          <target state="translated">Se utilizan dos conjuntos de datos separados para las dos parcelas diferentes. La raz&amp;oacute;n detr&amp;aacute;s de esto es que el caso &lt;code&gt;l1&lt;/code&gt; funciona mejor con datos dispersos, mientras que &lt;code&gt;l2&lt;/code&gt; se adapta mejor al caso no disperso.</target>
        </trans-unit>
        <trans-unit id="77c4595f573f3df24ff0cb3827f75f6aed496412" translate="yes" xml:space="preserve">
          <source>Two types of transformations are available: quantile transforms and power transforms. Both quantile and power transforms are based on monotonic transformations of the features and thus preserve the rank of the values along each feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32895c2e5eacd1283051e2d5a4f1fd3f826fb6ed" translate="yes" xml:space="preserve">
          <source>Two-class AdaBoost</source>
          <target state="translated">AdaBoost de dos clases</target>
        </trans-unit>
        <trans-unit id="b8fde32df7d701e50fc79883cdf21005c9469e51" translate="yes" xml:space="preserve">
          <source>Type casting</source>
          <target state="translated">El tipo de fundición...</target>
        </trans-unit>
        <trans-unit id="7b90464c9a3a0593a486a1facdfd06e25cac2162" translate="yes" xml:space="preserve">
          <source>Type of SVM: C SVC, nu SVC, one class, epsilon SVR, nu SVR</source>
          <target state="translated">Tipo de SVM:C SVC,nu SVC,una clase,épsilon SVR,nu SVR</target>
        </trans-unit>
        <trans-unit id="fb24034e0a15fdb11753c4c561fec377a847eca1" translate="yes" xml:space="preserve">
          <source>Type of SVM: C_SVC, NuSVC, OneClassSVM, EpsilonSVR or NuSVR respectively. 0 by default.</source>
          <target state="translated">Tipo de SVM:C_SVC,NuSVC,OneClassSVM,EpsilonSVR o NuSVR respectivamente.0 por defecto.</target>
        </trans-unit>
        <trans-unit id="05734831eef4f60aabd73eed1535149e1780b49e" translate="yes" xml:space="preserve">
          <source>Type of kernel.</source>
          <target state="translated">Tipo de núcleo.</target>
        </trans-unit>
        <trans-unit id="7784bde958a1d323776ea14d0478698cc397c040" translate="yes" xml:space="preserve">
          <source>Type of returned matrix: &amp;lsquo;connectivity&amp;rsquo; will return the connectivity matrix with ones and zeros, and &amp;lsquo;distance&amp;rsquo; will return the distances between neighbors according to the given metric.</source>
          <target state="translated">Tipo de matriz devuelta: 'conectividad' devolver&amp;aacute; la matriz de conectividad con unos y ceros, y 'distancia' devolver&amp;aacute; las distancias entre vecinos seg&amp;uacute;n la m&amp;eacute;trica dada.</target>
        </trans-unit>
        <trans-unit id="029a83801426f186d4049ef92d5f3d3590b1d125" translate="yes" xml:space="preserve">
          <source>Type of returned matrix: &amp;lsquo;connectivity&amp;rsquo; will return the connectivity matrix with ones and zeros, in &amp;lsquo;distance&amp;rsquo; the edges are Euclidean distance between points.</source>
          <target state="translated">Tipo de matriz devuelta: 'conectividad' devolver&amp;aacute; la matriz de conectividad con unos y ceros, en 'distancia' los bordes son la distancia euclidiana entre puntos.</target>
        </trans-unit>
        <trans-unit id="e2af4c36790c9137ba49cdb815accc60f6f75311" translate="yes" xml:space="preserve">
          <source>Type of store backend for reading/writing cache files. Default: &amp;lsquo;local&amp;rsquo;. The &amp;lsquo;local&amp;rsquo; backend is using regular filesystem operations to manipulate data (open, mv, etc) in the backend.</source>
          <target state="translated">Tipo de backend de la tienda para leer / escribir archivos de cach&amp;eacute;. Predeterminado: 'local'. El backend 'local' est&amp;aacute; utilizando operaciones regulares del sistema de archivos para manipular datos (open, mv, etc.) en el backend.</target>
        </trans-unit>
        <trans-unit id="858cba7a97e85950fd69a9661ce88f3dff1bf729" translate="yes" xml:space="preserve">
          <source>Type of the matrix returned by fit_transform() or transform().</source>
          <target state="translated">Tipo de la matriz devuelta por fit_transform()o transform().</target>
        </trans-unit>
        <trans-unit id="b6e792a3d08a7bd144dac10e42edb461fd3dd2e3" translate="yes" xml:space="preserve">
          <source>Type to use in computing the mean. For integer inputs, the default is &lt;code&gt;float64&lt;/code&gt;; for floating point inputs, it is the same as the input dtype.</source>
          <target state="translated">Escriba para usar en el c&amp;aacute;lculo de la media. Para entradas enteras, el valor predeterminado es &lt;code&gt;float64&lt;/code&gt; ; para entradas de punto flotante, es lo mismo que el tipo de entrada.</target>
        </trans-unit>
        <trans-unit id="9af8f14bd15271db0f113f7c146e7fa9294b1caa" translate="yes" xml:space="preserve">
          <source>TypeError</source>
          <target state="translated">TypeError</target>
        </trans-unit>
        <trans-unit id="363cb5cb9b015bf8fe75ee8f6f3ad675ca5618cc" translate="yes" xml:space="preserve">
          <source>UNION</source>
          <target state="translated">UNION</target>
        </trans-unit>
        <trans-unit id="d609f86a64dc993cf97b5c1696e70d121d69089c" translate="yes" xml:space="preserve">
          <source>UNION_not_member</source>
          <target state="translated">UNION_not_member</target>
        </trans-unit>
        <trans-unit id="5c8cdf8bfe08e7fa632507cd27d7c4593fc32d5d" translate="yes" xml:space="preserve">
          <source>Under the assumption that the data are Gaussian distributed, Chen et al. &lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;2&lt;/a&gt; derived a formula aimed at choosing a shrinkage coefficient that yields a smaller Mean Squared Error than the one given by Ledoit and Wolf&amp;rsquo;s formula. The resulting estimator is known as the Oracle Shrinkage Approximating estimator of the covariance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f77afa338a167babd59a76b7f498d6550ba586ff" translate="yes" xml:space="preserve">
          <source>Under the assumption that the data are Gaussian distributed, Chen et al. &lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; derived a formula aimed at choosing a shrinkage coefficient that yields a smaller Mean Squared Error than the one given by Ledoit and Wolf&amp;rsquo;s formula. The resulting estimator is known as the Oracle Shrinkage Approximating estimator of the covariance.</source>
          <target state="translated">Bajo el supuesto de que los datos tienen una distribuci&amp;oacute;n gaussiana, Chen et al. &lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; deriv&amp;oacute; una f&amp;oacute;rmula destinada a elegir un coeficiente de contracci&amp;oacute;n que produzca un error cuadr&amp;aacute;tico medio m&amp;aacute;s peque&amp;ntilde;o que el dado por la f&amp;oacute;rmula de Ledoit y Wolf. El estimador resultante se conoce como estimador de covarianza aproximado de contracci&amp;oacute;n de Oracle.</target>
        </trans-unit>
        <trans-unit id="b57ce0246b95ca0ff3d95c499722ea513c24180d" translate="yes" xml:space="preserve">
          <source>Underfitting vs. Overfitting</source>
          <target state="translated">Calentamiento insuficiente vs.Calentamiento excesivo</target>
        </trans-unit>
        <trans-unit id="10dab5fb240281c20bb10ad043cbba82ec3b0bd6" translate="yes" xml:space="preserve">
          <source>Understanding the decision tree structure</source>
          <target state="translated">Comprensión de la estructura del árbol de decisión</target>
        </trans-unit>
        <trans-unit id="a381b476a1bdd0042346ffd8d02655a7131aa344" translate="yes" xml:space="preserve">
          <source>Undo the scaling of X according to feature_range.</source>
          <target state="translated">Deshaga la escala de X según el rango de características.</target>
        </trans-unit>
        <trans-unit id="11b4a2e4a2b6531b9e75ad23f03f25fd4f8ecde0" translate="yes" xml:space="preserve">
          <source>Uniform weights are used by default.</source>
          <target state="translated">Los pesos uniformes se usan por defecto.</target>
        </trans-unit>
        <trans-unit id="9421754583ed6d327fe582bef2d0e2d0f17ba0c4" translate="yes" xml:space="preserve">
          <source>Unique class labels.</source>
          <target state="translated">Etiquetas de clase única.</target>
        </trans-unit>
        <trans-unit id="6efd4cf40567c19c24a13e3421a6d1109a47da44" translate="yes" xml:space="preserve">
          <source>Uniquely holds the label for each class.</source>
          <target state="translated">Tiene una etiqueta única para cada clase.</target>
        </trans-unit>
        <trans-unit id="78bd370935302db3cfb593c9af76aeb130eb71c4" translate="yes" xml:space="preserve">
          <source>Unit Deviance \(d(y, \hat{y})\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15f758514c6db2ef9033ee5636e4d09d40ce9747" translate="yes" xml:space="preserve">
          <source>Univariate Feature Selection</source>
          <target state="translated">Selección de características univariantes</target>
        </trans-unit>
        <trans-unit id="820dda4dd874419c514343cc2737763cc18b33d1" translate="yes" xml:space="preserve">
          <source>Univariate feature selection works by selecting the best features based on univariate statistical tests. It can be seen as a preprocessing step to an estimator. Scikit-learn exposes feature selection routines as objects that implement the &lt;code&gt;transform&lt;/code&gt; method:</source>
          <target state="translated">La selecci&amp;oacute;n de caracter&amp;iacute;sticas univariadas funciona seleccionando las mejores caracter&amp;iacute;sticas basadas en pruebas estad&amp;iacute;sticas univariadas. Puede verse como un paso previo al procesamiento de un estimador. Scikit-learn expone las rutinas de selecci&amp;oacute;n de caracter&amp;iacute;sticas como objetos que implementan el m&amp;eacute;todo de &lt;code&gt;transform&lt;/code&gt; aci&amp;oacute;n :</target>
        </trans-unit>
        <trans-unit id="b943e7c2ae0f248f889b02c7d797d243c0d56e6a" translate="yes" xml:space="preserve">
          <source>Univariate feature selector with configurable mode.</source>
          <target state="translated">Selector de características univariante con modo configurable.</target>
        </trans-unit>
        <trans-unit id="05b44ce5dcc153b8702db1e0eab0c9af1fb62f9c" translate="yes" xml:space="preserve">
          <source>Univariate feature selector with configurable strategy.</source>
          <target state="translated">Selector de características univariante con estrategia configurable.</target>
        </trans-unit>
        <trans-unit id="049ea86cb7534beee7ca7abb3073edcde3e3d399" translate="yes" xml:space="preserve">
          <source>Univariate imputation of missing values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9b7ebeeb7d99a7c69a9087085473be1721215ee" translate="yes" xml:space="preserve">
          <source>Univariate linear regression tests.</source>
          <target state="translated">Pruebas de regresión lineal univariante.</target>
        </trans-unit>
        <trans-unit id="833fdc74927caa030c0f5f51bade98d55541b93d" translate="yes" xml:space="preserve">
          <source>Unlabeled entries in &lt;code&gt;y&lt;/code&gt;</source>
          <target state="translated">Entradas sin etiqueta en &lt;code&gt;y&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="d5f2b47c1710490958929f8f01f5858025c133e1" translate="yes" xml:space="preserve">
          <source>Unless otherwise specified, input will be cast to &lt;code&gt;float64&lt;/code&gt;:</source>
          <target state="translated">A menos que se especifique lo contrario, la entrada se convertir&amp;aacute; en &lt;code&gt;float64&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="6027b38892a9b0df12f36988c98a41a4655ff464" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt;, the representation of a vector is obtained in an additive fashion, by superimposing the components, without subtracting. Such additive models are efficient for representing images and text.</source>
          <target state="translated">A diferencia del &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; , la representaci&amp;oacute;n de un vector se obtiene de forma aditiva, superponiendo los componentes, sin restar. Estos modelos aditivos son eficaces para representar im&amp;aacute;genes y texto.</target>
        </trans-unit>
        <trans-unit id="5817d589292c98298ab95a877d7595e724495088" translate="yes" xml:space="preserve">
          <source>Unlike SVC (based on LIBSVM), LinearSVC (based on LIBLINEAR) does not provide the support vectors. This example demonstrates how to obtain the support vectors in LinearSVC.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f73d55c7488edaa74f7dc85966062a8a5be2b94b" translate="yes" xml:space="preserve">
          <source>Unlike most other scores, R^2 score may be negative (it need not actually be the square of a quantity R).</source>
          <target state="translated">A diferencia de la mayoría de las otras puntuaciones,la puntuación R^2 puede ser negativa (no tiene por qué ser el cuadrado de una cantidad R).</target>
        </trans-unit>
        <trans-unit id="fb0dd07f15380472f302743b85f6d7c3f60efb9d" translate="yes" xml:space="preserve">
          <source>Unlike the previous scalers, the centering and scaling statistics of this scaler are based on percentiles and are therefore not influenced by a few number of very large marginal outliers. Consequently, the resulting range of the transformed feature values is larger than for the previous scalers and, more importantly, are approximately similar: for both features most of the transformed values lie in a [-2, 3] range as seen in the zoomed-in figure. Note that the outliers themselves are still present in the transformed data. If a separate outlier clipping is desirable, a non-linear transformation is required (see below).</source>
          <target state="translated">A diferencia de los anteriores escaladores,las estadísticas de centrado y escalado de este escalador se basan en percentiles y,por lo tanto,no se ven influidas por un número reducido de valores marginales atípicos muy grandes.Por consiguiente,el rango resultante de los valores de las características transformadas es mayor que el de los anteriores escaladores y,lo que es más importante,es aproximadamente similar:para ambas características la mayoría de los valores transformados se encuentran en un rango [-2,3]como se ve en la figura ampliada.Nótese que los valores atípicos en sí siguen presentes en los datos transformados.Si se desea un recorte separado de los valores atípicos,se requiere una transformación no lineal (véase más abajo).</target>
        </trans-unit>
        <trans-unit id="be4091e1f0941887f57bdebf1b1a9b607356f1f1" translate="yes" xml:space="preserve">
          <source>Unlike the previous transformations, normalization refers to a per sample transformation instead of a per feature transformation.</source>
          <target state="translated">A diferencia de las transformaciones anteriores,la normalización se refiere a una transformación por muestra en lugar de una transformación por característica.</target>
        </trans-unit>
        <trans-unit id="1e78af54fb2d86af104fdf7cb3b33ae0e42d69f8" translate="yes" xml:space="preserve">
          <source>Unmarried</source>
          <target state="translated">Unmarried</target>
        </trans-unit>
        <trans-unit id="d6efdeaf0fd8663d7b74628a841a2a21988919e0" translate="yes" xml:space="preserve">
          <source>Unregularized graph based semi-supervised learning</source>
          <target state="translated">Aprendizaje semisupervisado basado en gráficos no regularizados</target>
        </trans-unit>
        <trans-unit id="27bee227769f6c4dd6bbb550e3dab104adba94bb" translate="yes" xml:space="preserve">
          <source>Unsupervised Outlier Detection using Local Outlier Factor (LOF)</source>
          <target state="translated">Detección de valores atípicos sin supervisión usando el Factor Atípico Local (LOF)</target>
        </trans-unit>
        <trans-unit id="3cf71ccf2a88f28c3a0cfcb75adfc8979981d7f4" translate="yes" xml:space="preserve">
          <source>Unsupervised Outlier Detection using Local Outlier Factor (LOF).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b5353048e77b9864be0e146d8fe78c3034a09d3" translate="yes" xml:space="preserve">
          <source>Unsupervised Outlier Detection.</source>
          <target state="translated">Detección de atípicos sin supervisión.</target>
        </trans-unit>
        <trans-unit id="a2eb50b9e0078078696dd41ce50d788a5cac282f" translate="yes" xml:space="preserve">
          <source>Unsupervised Outlier Detection. Estimate the support of a high-dimensional distribution. The implementation is based on libsvm.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="091dbb252c60dafbec16ee540eb9588c7d736a5b" translate="yes" xml:space="preserve">
          <source>Unsupervised learner for implementing neighbor searches.</source>
          <target state="translated">Aprendiz no supervisado para implementar búsquedas de vecinos.</target>
        </trans-unit>
        <trans-unit id="336bcbb510eed89e13ba021c352635cdc0677016" translate="yes" xml:space="preserve">
          <source>Unsupervised learning: seeking representations of the data</source>
          <target state="translated">Aprendizaje no supervisado:buscando representaciones de los datos</target>
        </trans-unit>
        <trans-unit id="568c5820f9e5362ca266c9125e695403019435a8" translate="yes" xml:space="preserve">
          <source>Unused parameter.</source>
          <target state="translated">Parámetro no utilizado.</target>
        </trans-unit>
        <trans-unit id="207a5be036cc811b3313bce86d86c7d5b4302176" translate="yes" xml:space="preserve">
          <source>Update k means estimate on a single mini-batch X.</source>
          <target state="translated">La actualización k significa estimación en un solo mini lote X.</target>
        </trans-unit>
        <trans-unit id="08230ffcab1953eb1050f05815a03e0d48694ae9" translate="yes" xml:space="preserve">
          <source>Update the model with a single iteration over the given data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="718430f889e80a3494a47ee7bec5ca3329673e5e" translate="yes" xml:space="preserve">
          <source>Updated feature-wise means.</source>
          <target state="translated">Actualizado en cuanto a las características.</target>
        </trans-unit>
        <trans-unit id="4f10d24907ba29eca99bd941c7ead98539a4f5b4" translate="yes" xml:space="preserve">
          <source>Updated feature-wise variances.</source>
          <target state="translated">Actualizadas las variaciones de las características.</target>
        </trans-unit>
        <trans-unit id="693a7de21c7466734e7ffa03c5ae997209e7997d" translate="yes" xml:space="preserve">
          <source>Updated number of seen samples.</source>
          <target state="translated">Número actualizado de muestras vistas.</target>
        </trans-unit>
        <trans-unit id="410e0e09369f3d862bca36022b47e478be0933f7" translate="yes" xml:space="preserve">
          <source>Updates the model using the data in X as a mini-batch.</source>
          <target state="translated">Actualiza el modelo usando los datos de X como un mini lote.</target>
        </trans-unit>
        <trans-unit id="93ec1aa11f1be18275b029134004fd1ab02c997f" translate="yes" xml:space="preserve">
          <source>Upper bound on a uniform noise parameter to be added to the &lt;code&gt;y&lt;/code&gt; values, to satisfy the model&amp;rsquo;s assumption of one-at-a-time computations. Might help with stability.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07333ba49211f5c72e60dfd1b7f4f04d69ceed93" translate="yes" xml:space="preserve">
          <source>Upper bound on the highest predicted value (the maximum may still be lower). If not set, defaults to +inf.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48b5dd5eaa54e931a34dd1d6396ec1c9d66da80b" translate="yes" xml:space="preserve">
          <source>Urbanowicz R.J., Moore, J.H. &lt;a href=&quot;https://doi.org/10.1007/s12065-015-0128-8&quot;&gt;ExSTraCS 2.0: description and evaluation of a scalable learning classifier system&lt;/a&gt;, Evol. Intel. (2015) 8: 89.</source>
          <target state="translated">Urbanowicz RJ, Moore, JH &lt;a href=&quot;https://doi.org/10.1007/s12065-015-0128-8&quot;&gt;ExSTraCS 2.0: descripci&amp;oacute;n y evaluaci&amp;oacute;n de un sistema clasificador de aprendizaje escalable&lt;/a&gt; , Evol. Intel. (2015) 8:89.</target>
        </trans-unit>
        <trans-unit id="fec43ce445f974147bd0eb223a50147e7fb7202d" translate="yes" xml:space="preserve">
          <source>Usage example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="173610cb31251b28e80fadc258036215d99d7128" translate="yes" xml:space="preserve">
          <source>Usage examples:</source>
          <target state="translated">Ejemplos de uso:</target>
        </trans-unit>
        <trans-unit id="272998fc40498f57127bf4e7cf71805cd53c9500" translate="yes" xml:space="preserve">
          <source>Use 0 when &lt;code&gt;Y&lt;/code&gt; contains the output of decision_function (classifier). Use 0.5 when &lt;code&gt;Y&lt;/code&gt; contains the output of predict_proba.</source>
          <target state="translated">Utilice 0 cuando &lt;code&gt;Y&lt;/code&gt; contiene la salida de decision_function (clasificador). Utilice 0.5 cuando &lt;code&gt;Y&lt;/code&gt; contenga la salida de predict_proba.</target>
        </trans-unit>
        <trans-unit id="cf1718d68df5d7e88cb5c515bd9f0d9c1cb19546" translate="yes" xml:space="preserve">
          <source>Use &lt;a href=&quot;#optics&quot;&gt;OPTICS&lt;/a&gt; clustering in conjunction with the &lt;code&gt;extract_dbscan&lt;/code&gt; method. OPTICS clustering also calculates the full pairwise matrix, but only keeps one row in memory at a time (memory complexity n).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7e4377e83d25be8830adecce4de8c2384ca00b7" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;ColumnTransformer&lt;/code&gt; by selecting column by data types</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e21d1ee32a85ffa963b44a044a8fb65d4d276f52" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;ColumnTransformer&lt;/code&gt; by selecting column by names</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e620712d1a8872ff21d8a3d8ca61cf7867c4f8c8" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;min_samples_split&lt;/code&gt; or &lt;code&gt;min_samples_leaf&lt;/code&gt; to ensure that multiple samples inform every decision in the tree, by controlling which splits will be considered. A very small number will usually mean the tree will overfit, whereas a large number will prevent the tree from learning the data. Try &lt;code&gt;min_samples_leaf=5&lt;/code&gt; as an initial value. If the sample size varies greatly, a float number can be used as percentage in these two parameters. While &lt;code&gt;min_samples_split&lt;/code&gt; can create arbitrarily small leaves, &lt;code&gt;min_samples_leaf&lt;/code&gt; guarantees that each leaf has a minimum size, avoiding low-variance, over-fit leaf nodes in regression problems. For classification with few classes, &lt;code&gt;min_samples_leaf=1&lt;/code&gt; is often the best choice.</source>
          <target state="translated">Utilice &lt;code&gt;min_samples_split&lt;/code&gt; o &lt;code&gt;min_samples_leaf&lt;/code&gt; para asegurarse de que varias muestras informan cada decisi&amp;oacute;n en el &amp;aacute;rbol, controlando qu&amp;eacute; divisiones se considerar&amp;aacute;n. Un n&amp;uacute;mero muy peque&amp;ntilde;o generalmente significar&amp;aacute; que el &amp;aacute;rbol se ajustar&amp;aacute; en exceso, mientras que un n&amp;uacute;mero grande evitar&amp;aacute; que el &amp;aacute;rbol aprenda los datos. Pruebe &lt;code&gt;min_samples_leaf=5&lt;/code&gt; como valor inicial. Si el tama&amp;ntilde;o de la muestra var&amp;iacute;a mucho, se puede utilizar un n&amp;uacute;mero flotante como porcentaje en estos dos par&amp;aacute;metros. Mientras que &lt;code&gt;min_samples_split&lt;/code&gt; puede crear hojas arbitrariamente peque&amp;ntilde;as, &lt;code&gt;min_samples_leaf&lt;/code&gt; garantiza que cada hoja tenga un tama&amp;ntilde;o m&amp;iacute;nimo, evitando nodos de hojas de baja varianza y sobreajuste en los problemas de regresi&amp;oacute;n. Para la clasificaci&amp;oacute;n con pocas clases, &lt;code&gt;min_samples_leaf=1&lt;/code&gt; suele ser la mejor opci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="3429b333ce93c8bae91a85fe794f080132090825" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;negative_outlier_factor_&lt;/code&gt;</source>
          <target state="translated">Utilice &lt;code&gt;negative_outlier_factor_&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7760fd58346bed0a2b559e055012bd8a21868552" translate="yes" xml:space="preserve">
          <source>Use SelectFromModel meta-transformer along with Lasso to select the best couple of features from the Boston dataset.</source>
          <target state="translated">Utiliza el meta-transformador SelectFromModel junto con Lasso para seleccionar el mejor par de características del conjunto de datos de Boston.</target>
        </trans-unit>
        <trans-unit id="054f12ffb2d5e13349a9508049b7a257d7468dbe" translate="yes" xml:space="preserve">
          <source>Use SelectFromModel meta-transformer along with Lasso to select the best couple of features from the diabetes dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71685d673fcc400f8aa4ec7ef3e4a61bf3bbf5f7" translate="yes" xml:space="preserve">
          <source>Use approximate bound as score.</source>
          <target state="translated">Use el límite aproximado como puntuación.</target>
        </trans-unit>
        <trans-unit id="400d526bc775314ded26ebb1519045ccc0979588" translate="yes" xml:space="preserve">
          <source>Use density = 1 / 3.0 if you want to reproduce the results from Achlioptas, 2001.</source>
          <target state="translated">Use la densidad=1/3.0 si quiere reproducir los resultados de Achlioptas,2001.</target>
        </trans-unit>
        <trans-unit id="38fb3c866f165060e0d95ec1a873c702ff2c91dc" translate="yes" xml:space="preserve">
          <source>Use only on new data</source>
          <target state="translated">Usar sólo en los nuevos datos</target>
        </trans-unit>
        <trans-unit id="0eb6d7f6360fc3b257840e6d0ece909142d961e3" translate="yes" xml:space="preserve">
          <source>Use splitting criteria that compute the average reduction across all n outputs.</source>
          <target state="translated">Utilizar criterios de división que calculen la reducción media en todas las n salidas.</target>
        </trans-unit>
        <trans-unit id="d4a5711bd46bd2a4542a66497bb7f3342ea23a7f" translate="yes" xml:space="preserve">
          <source>Use the Akaike information criterion (AIC), the Bayes Information criterion (BIC) and cross-validation to select an optimal value of the regularization parameter alpha of the &lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;Lasso&lt;/a&gt; estimator.</source>
          <target state="translated">Utilice el criterio de informaci&amp;oacute;n de Akaike (AIC), el criterio de informaci&amp;oacute;n de Bayes (BIC) y la validaci&amp;oacute;n cruzada para seleccionar un valor &amp;oacute;ptimo del par&amp;aacute;metro de regularizaci&amp;oacute;n alfa del estimador de &lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;Lasso&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="35f6c244b8fd2da4794beb17214246bc1c30610f" translate="yes" xml:space="preserve">
          <source>Usecase</source>
          <target state="translated">Usecase</target>
        </trans-unit>
        <trans-unit id="4ea5661d3bd8912bbf2723a42ab4c0cf1ece7994" translate="yes" xml:space="preserve">
          <source>Used during dictionary learning. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1bc010bd367bf6cb9590a9c8e8bd3ff37b7e270c" translate="yes" xml:space="preserve">
          <source>Used during randomized svd. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85ae15952ef1b8cedfa1ed0f0a5091e5742f9b4a" translate="yes" xml:space="preserve">
          <source>Used for NMF initialisation (when &lt;code&gt;init&lt;/code&gt; == &amp;lsquo;nndsvdar&amp;rsquo; or &amp;lsquo;random&amp;rsquo;), and in Coordinate Descent. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15383d0945f438ddc1d77fc1ae0921de1e717777" translate="yes" xml:space="preserve">
          <source>Used for VotingClassifier</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06c1133b6cf5dee9bc1f27b86d9cca1c046fd5c1" translate="yes" xml:space="preserve">
          <source>Used for initialisation (when &lt;code&gt;init&lt;/code&gt; == &amp;lsquo;nndsvdar&amp;rsquo; or &amp;lsquo;random&amp;rsquo;), and in Coordinate Descent. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4845a789add1f32681ae6a68b7dba0e6bdbe2af" translate="yes" xml:space="preserve">
          <source>Used for initializing the dictionary when &lt;code&gt;dict_init&lt;/code&gt; is not specified, randomly shuffling the data when &lt;code&gt;shuffle&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, and updating the dictionary. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d6d1bb4bf090f9031a078f80f81b5cfa346c5fb" translate="yes" xml:space="preserve">
          <source>Used for internal caching. By default, no caching is done. If a string is given, it is the path to the caching directory.</source>
          <target state="translated">Se utiliza para el almacenamiento interno.Por defecto,no se hace ningún caching.Si se da una cadena,es la ruta del directorio de cacheo.</target>
        </trans-unit>
        <trans-unit id="78a755bf17a9d084d2f5bc3468af8892921b3298" translate="yes" xml:space="preserve">
          <source>Used for random shuffling when &lt;code&gt;shuffle&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, during online dictionary learning. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a659f5ae4cfedf0686976ca2f311fa3c53dbc2ce" translate="yes" xml:space="preserve">
          <source>Used for randomizing the singular value decomposition and the k-means initialization. Use an int to make the randomness deterministic. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">Se utiliza para aleatorizar la descomposici&amp;oacute;n del valor singular y la inicializaci&amp;oacute;n de k-medias. Utilice un int para hacer que la aleatoriedad sea determinista. Consulte el &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-random-state&quot;&gt;glosario&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="b3bb1fd38ab7b6b511c90e9e3f961817f7b29fe6" translate="yes" xml:space="preserve">
          <source>Used for randomizing the singular value decomposition and the k-means initialization. Use an int to make the randomness deterministic. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad6bfb2aef10b93bd4ad8fd792d19a69ba0f50a9" translate="yes" xml:space="preserve">
          <source>Used for randomly initializing the dictionary. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0ee2dc12a427741bfbfa29dc3b32d1b1d854da3" translate="yes" xml:space="preserve">
          <source>Used for shuffling the data, when &lt;code&gt;shuffle&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04206996c9eca941c8da97d474cf5a147f4b8713" translate="yes" xml:space="preserve">
          <source>Used to cache the fitted transformers of the pipeline. By default, no caching is performed. If a string is given, it is the path to the caching directory. Enabling caching triggers a clone of the transformers before fitting. Therefore, the transformer instance given to the pipeline cannot be inspected directly. Use the attribute &lt;code&gt;named_steps&lt;/code&gt; or &lt;code&gt;steps&lt;/code&gt; to inspect estimators within the pipeline. Caching the transformers is advantageous when fitting is time consuming.</source>
          <target state="translated">Se utiliza para almacenar en cach&amp;eacute; los transformadores instalados de la tuber&amp;iacute;a. De forma predeterminada, no se realiza el almacenamiento en cach&amp;eacute;. Si se proporciona una cadena, es la ruta al directorio de almacenamiento en cach&amp;eacute;. Habilitar el almacenamiento en cach&amp;eacute; desencadena un clon de los transformadores antes de encajar. Por lo tanto, la instancia de transformador proporcionada a la tuber&amp;iacute;a no se puede inspeccionar directamente. Utilice el atributo &lt;code&gt;named_steps&lt;/code&gt; o &lt;code&gt;steps&lt;/code&gt; para inspeccionar los estimadores dentro de la canalizaci&amp;oacute;n. El almacenamiento en cach&amp;eacute; de los transformadores es ventajoso cuando la instalaci&amp;oacute;n requiere mucho tiempo.</target>
        </trans-unit>
        <trans-unit id="b831b0ccc618367ad6990c063d4f6b68c21b54a0" translate="yes" xml:space="preserve">
          <source>Used to cache the output of the computation of the tree. By default, no caching is done. If a string is given, it is the path to the caching directory.</source>
          <target state="translated">Se utiliza para guardar la salida del cálculo del árbol.Por defecto,no se hace ningún cacheo.Si se da una cadena,es la ruta del directorio de cacheo.</target>
        </trans-unit>
        <trans-unit id="5b58434a86ea5888954537c341361956c0e8c395" translate="yes" xml:space="preserve">
          <source>Used to determine when to &amp;ldquo;early stop&amp;rdquo;. The fitting process is stopped when none of the last &lt;code&gt;n_iter_no_change&lt;/code&gt; scores are better than the &lt;code&gt;n_iter_no_change - 1&lt;/code&gt; -th-to-last one, up to some tolerance. Only used if early stopping is performed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9462556717c7577fff4ef47d9f5dcd20523f1516" translate="yes" xml:space="preserve">
          <source>Used to initialize &lt;code&gt;w_init&lt;/code&gt; when not specified, with a normal distribution. Pass an int, for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f19cda342b4acf0d93861aea53bc9a6ea559de82" translate="yes" xml:space="preserve">
          <source>Used to pick randomly the &lt;code&gt;max_features&lt;/code&gt; used at each split. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="605a4bcc1f5d9a0fe3ef69215d05c4963e05e516" translate="yes" xml:space="preserve">
          <source>Used to shuffle the training data, when &lt;code&gt;shuffle&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec2d1021c796c8396406488bdd5b004de6014166" translate="yes" xml:space="preserve">
          <source>Used to specify the norm used in the penalization. The &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers support only l2 penalties.</source>
          <target state="translated">Se utiliza para especificar la norma utilizada en la penalizaci&amp;oacute;n. Los solucionadores 'newton-cg', 'sag' y 'lbfgs' solo admiten penalizaciones 12.</target>
        </trans-unit>
        <trans-unit id="5860deefa3fd6b4c16483df037c0ad7cd840b1dc" translate="yes" xml:space="preserve">
          <source>Used to specify the norm used in the penalization. The &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers support only l2 penalties. &amp;lsquo;elasticnet&amp;rsquo; is only supported by the &amp;lsquo;saga&amp;rsquo; solver.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2cadba66c38ca766b85abc4b1e03568d1fa6dab" translate="yes" xml:space="preserve">
          <source>Used to specify the norm used in the penalization. The &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers support only l2 penalties. &amp;lsquo;elasticnet&amp;rsquo; is only supported by the &amp;lsquo;saga&amp;rsquo; solver. If &amp;lsquo;none&amp;rsquo; (not supported by the liblinear solver), no regularization is applied.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90efd63a8d51063de92a896b88cf64deaa03a244" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;eigen_solver&lt;/code&gt; == &amp;lsquo;arpack&amp;rsquo;. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27dcb202bde84d98eaa9b02f62b647ecce32aaba" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;shuffle&lt;/code&gt; is True. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8694b55c04737ba18ec4ec98388e9997e16f39ac" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;solver&lt;/code&gt; == &amp;lsquo;sag&amp;rsquo; or &amp;lsquo;saga&amp;rsquo; to shuffle the data. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="59bf45c1d50e7570f6107bdd3616f32c93f002ed" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;solver&lt;/code&gt; == &amp;lsquo;sag&amp;rsquo;, &amp;lsquo;saga&amp;rsquo; or &amp;lsquo;liblinear&amp;rsquo; to shuffle the data. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6070822f60356161845953fee6c5bfe74cf5d59" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;solver='sag'&lt;/code&gt;, &amp;lsquo;saga&amp;rsquo; or &amp;lsquo;liblinear&amp;rsquo; to shuffle the data. Note that this only applies to the solver and not the cross-validation generator. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f152cc191601223884f2e892b0e88e2ae399e550" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;svd_solver&lt;/code&gt; == &amp;lsquo;arpack&amp;rsquo; or &amp;lsquo;randomized&amp;rsquo;. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a789f5832dbb34972e6ab11f85f2125e32dddce" translate="yes" xml:space="preserve">
          <source>Useful for applying a non-linear transformation in regression problems. This transformation can be given as a Transformer such as the QuantileTransformer or as a function and its inverse such as &lt;code&gt;log&lt;/code&gt; and &lt;code&gt;exp&lt;/code&gt;.</source>
          <target state="translated">&amp;Uacute;til para aplicar una transformaci&amp;oacute;n no lineal en problemas de regresi&amp;oacute;n. Esta transformaci&amp;oacute;n se puede dar como un transformador como el QuantileTransformer o como una funci&amp;oacute;n y su inverso como &lt;code&gt;log&lt;/code&gt; y &lt;code&gt;exp&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="74349d111804f80e1a38097923f8879dfbcca7b0" translate="yes" xml:space="preserve">
          <source>Useful for applying a non-linear transformation to the target &lt;code&gt;y&lt;/code&gt; in regression problems. This transformation can be given as a Transformer such as the QuantileTransformer or as a function and its inverse such as &lt;code&gt;log&lt;/code&gt; and &lt;code&gt;exp&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="665be16622d5dce4c265443eced33f5309efed0f" translate="yes" xml:space="preserve">
          <source>Useful only for the newton-cg, sag and lbfgs solvers. Maximum number of iterations taken for the solvers to converge.</source>
          <target state="translated">Útil sólo para los solucionadores de Newton-CG,SAG y LBFGS.Número máximo de iteraciones necesarias para que los solucionadores converjan.</target>
        </trans-unit>
        <trans-unit id="1f7081fc6e8837c157dbcac4dfe150624d77daa3" translate="yes" xml:space="preserve">
          <source>Useful only when the solver &amp;lsquo;liblinear&amp;rsquo; is used and self.fit_intercept is set to True. In this case, x becomes [x, self.intercept_scaling], i.e. a &amp;ldquo;synthetic&amp;rdquo; feature with constant value equal to intercept_scaling is appended to the instance vector. The intercept becomes &lt;code&gt;intercept_scaling * synthetic_feature_weight&lt;/code&gt;.</source>
          <target state="translated">&amp;Uacute;til solo cuando se usa el solucionador 'liblinear' y self.fit_intercept se establece en True. En este caso, x se convierte en [x, self.intercept_scaling], es decir, una caracter&amp;iacute;stica &quot;sint&amp;eacute;tica&quot; con un valor constante igual a intercept_scaling se agrega al vector de instancia. La intersecci&amp;oacute;n se convierte en &lt;code&gt;intercept_scaling * synthetic_feature_weight&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="cb4f9242d2c5bef801309a7b11564e9f2917779f" translate="yes" xml:space="preserve">
          <source>Useful tutorials for developing a feel for some of scikit-learn's applications in the machine learning field.</source>
          <target state="translated">Tutoriales útiles para desarrollar una sensación de algunas de las aplicaciones de scikit-learn en el campo del aprendizaje de la máquina.</target>
        </trans-unit>
        <trans-unit id="bec249e659662f7d5947bf09a1ea1d4a552885b0" translate="yes" xml:space="preserve">
          <source>User Guide</source>
          <target state="translated">Guía del usuario</target>
        </trans-unit>
        <trans-unit id="221a6dc59fa62390ffe53703a42fa985bbe3d0ea" translate="yes" xml:space="preserve">
          <source>Uses &lt;a href=&quot;#sklearn.model_selection.ParameterGrid&quot;&gt;&lt;code&gt;ParameterGrid&lt;/code&gt;&lt;/a&gt; to perform a full parallelized parameter search.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32b4edc9350cb6d93cc0316d635ce26e35fa63d2" translate="yes" xml:space="preserve">
          <source>Uses BLAS GEMM as replacement for numpy.dot where possible to avoid unnecessary copies.</source>
          <target state="translated">Utiliza BLAS GEMM como reemplazo de numpy.dot cuando es posible para evitar copias innecesarias.</target>
        </trans-unit>
        <trans-unit id="ac4bd4f4f631e790604905794abbd6ed09d66803" translate="yes" xml:space="preserve">
          <source>Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.</source>
          <target state="translated">Utiliza un subconjunto de puntos de entrenamiento en la función de decisión (llamados vectores de apoyo),por lo que también es eficiente en la memoria.</target>
        </trans-unit>
        <trans-unit id="4a4b56e0bea50fff706430a1a94289a4e5e03040" translate="yes" xml:space="preserve">
          <source>Uses a white box model. If a given situation is observable in a model, the explanation for the condition is easily explained by boolean logic. By contrast, in a black box model (e.g., in an artificial neural network), results may be more difficult to interpret.</source>
          <target state="translated">Utiliza un modelo de caja blanca.Si una situación dada es observable en un modelo,la explicación de la condición se explica fácilmente por la lógica booleana.Por el contrario,en un modelo de caja negra (por ejemplo,en una red neuronal artificial),los resultados pueden ser más difíciles de interpretar.</target>
        </trans-unit>
        <trans-unit id="ced5d25baa7aaf39837296d764096d52eb67f5ca" translate="yes" xml:space="preserve">
          <source>Uses sampling the fourier transform of the kernel characteristic at regular intervals.</source>
          <target state="translated">Utiliza el muestreo de la transformación de Fourier de la característica del núcleo a intervalos regulares.</target>
        </trans-unit>
        <trans-unit id="2c633fc259072170ae02b4cf8b2266258b09ddc5" translate="yes" xml:space="preserve">
          <source>Uses the vocabulary and document frequencies (df) learned by fit (or fit_transform).</source>
          <target state="translated">Utiliza el vocabulario y las frecuencias de los documentos (df)aprendidas por fit (o fit_transform).</target>
        </trans-unit>
        <trans-unit id="cdea6e25f0fe24b03bf907dbf26253d4f40a11df" translate="yes" xml:space="preserve">
          <source>Using &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; or &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; enables the &lt;code&gt;predict_proba&lt;/code&gt; method, which gives a vector of probability estimates \(P(y|x)\) per sample \(x\):</source>
          <target state="translated">El uso de &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; o &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; habilita el m&amp;eacute;todo &lt;code&gt;predict_proba&lt;/code&gt; , que da un vector de estimaciones de probabilidad \ (P (y | x) \) por muestra \ (x \):</target>
        </trans-unit>
        <trans-unit id="4072d118d17ebbe341d060ec8f347bb287543668" translate="yes" xml:space="preserve">
          <source>Using FunctionTransformer to select columns</source>
          <target state="translated">Usando el FunctionTransformer para seleccionar las columnas</target>
        </trans-unit>
        <trans-unit id="af570039f4e6335c176e5a0ced20f61ade37ec58" translate="yes" xml:space="preserve">
          <source>Using KBinsDiscretizer to discretize continuous features</source>
          <target state="translated">Usar KBinsDiscretizer para discretizar las características continuas</target>
        </trans-unit>
        <trans-unit id="58dd6560cd1dd1ff16a956c31444ffff4530a294" translate="yes" xml:space="preserve">
          <source>Using L1 penalization as provided by &lt;code&gt;LinearSVC(loss='l2', penalty='l1',
dual=False)&lt;/code&gt; yields a sparse solution, i.e. only a subset of feature weights is different from zero and contribute to the decision function. Increasing &lt;code&gt;C&lt;/code&gt; yields a more complex model (more feature are selected). The &lt;code&gt;C&lt;/code&gt; value that yields a &amp;ldquo;null&amp;rdquo; model (all weights equal to zero) can be calculated using &lt;a href=&quot;generated/sklearn.svm.l1_min_c#sklearn.svm.l1_min_c&quot;&gt;&lt;code&gt;l1_min_c&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">El uso de la penalizaci&amp;oacute;n L1 proporcionada por &lt;code&gt;LinearSVC(loss='l2', penalty='l1', dual=False)&lt;/code&gt; produce una soluci&amp;oacute;n escasa, es decir, solo un subconjunto de ponderaciones de caracter&amp;iacute;sticas es diferente de cero y contribuye a la funci&amp;oacute;n de decisi&amp;oacute;n. El aumento de &lt;code&gt;C&lt;/code&gt; produce un modelo m&amp;aacute;s complejo (se seleccionan m&amp;aacute;s funciones). El valor &lt;code&gt;C&lt;/code&gt; que produce un modelo &quot;nulo&quot; (todos los pesos iguales a cero) se puede calcular usando &lt;a href=&quot;generated/sklearn.svm.l1_min_c#sklearn.svm.l1_min_c&quot;&gt; &lt;code&gt;l1_min_c&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="927a462bb89282ccdc19c70530472008783e5ed5" translate="yes" xml:space="preserve">
          <source>Using L1 penalization as provided by &lt;code&gt;LinearSVC(loss='l2', penalty='l1',
dual=False)&lt;/code&gt; yields a sparse solution, i.e. only a subset of feature weights is different from zero and contribute to the decision function. Increasing &lt;code&gt;C&lt;/code&gt; yields a more complex model (more features are selected). The &lt;code&gt;C&lt;/code&gt; value that yields a &amp;ldquo;null&amp;rdquo; model (all weights equal to zero) can be calculated using &lt;a href=&quot;generated/sklearn.svm.l1_min_c#sklearn.svm.l1_min_c&quot;&gt;&lt;code&gt;l1_min_c&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="757f15a3dfafa1d1e98a6f1f457c43151b4efe0d" translate="yes" xml:space="preserve">
          <source>Using LDA and QDA requires computing the log-posterior which depends on the class priors \(P(y=k)\), the class means \(\mu_k\), and the covariance matrices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0033ecf2999fee9c8f71baf5ea186698e26a6aa1" translate="yes" xml:space="preserve">
          <source>Using a &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; without cache enabled, it is possible to inspect the original instance such as:</source>
          <target state="translated">Al usar una &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;Pipeline&lt;/code&gt; &lt;/a&gt; sin cach&amp;eacute; habilitada, es posible inspeccionar la instancia original, como:</target>
        </trans-unit>
        <trans-unit id="8841876aa584e88fcc31f689448303a79af806c4" translate="yes" xml:space="preserve">
          <source>Using a first-order Taylor approximation, the value of \(l\) can be approximated as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4b38a6f3576ed137cc4e9a9f59798fb707d4dde4" translate="yes" xml:space="preserve">
          <source>Using a single underlying feature the model learns both the x and y coordinate as output.</source>
          <target state="translated">Usando una sola característica subyacente,el modelo aprende tanto la coordenada x como la y como resultado.</target>
        </trans-unit>
        <trans-unit id="6d5ea28ea8efb863c08e76177dc50acce9324f64" translate="yes" xml:space="preserve">
          <source>Using a small &lt;code&gt;max_features&lt;/code&gt; value can significantly decrease the runtime.</source>
          <target state="translated">El uso de un valor peque&amp;ntilde;o de &lt;code&gt;max_features&lt;/code&gt; puede reducir significativamente el tiempo de ejecuci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="07d5b2f6d48114d6bc5306f53b2bbecb12f93559" translate="yes" xml:space="preserve">
          <source>Using a sub-pipeline, the fitted coefficients can be mapped back into the original feature space.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03c1a9468c05dba06aec630e70cb3912379c2cb0" translate="yes" xml:space="preserve">
          <source>Using its &lt;code&gt;partial_fit&lt;/code&gt; method on chunks of data fetched sequentially from the local hard drive or a network database.</source>
          <target state="translated">Usando su m&amp;eacute;todo de &lt;code&gt;partial_fit&lt;/code&gt; en fragmentos de datos obtenidos secuencialmente desde el disco duro local o una base de datos de red.</target>
        </trans-unit>
        <trans-unit id="ee5e8e298a940fdf98e8e52d2f16edd9327907f7" translate="yes" xml:space="preserve">
          <source>Using kernels</source>
          <target state="translated">Usando los núcleos</target>
        </trans-unit>
        <trans-unit id="9cfba89ca182507cccdcf4094af12bc5a4c62801" translate="yes" xml:space="preserve">
          <source>Using orthogonal matching pursuit for recovering a sparse signal from a noisy measurement encoded with a dictionary</source>
          <target state="translated">Usar la búsqueda de coincidencia ortogonal para recuperar una señal escasa de una medición ruidosa codificada con un diccionario</target>
        </trans-unit>
        <trans-unit id="24a0ae926e510d4f01c040899e37f954b1d9b717" translate="yes" xml:space="preserve">
          <source>Using pre_dispatch in a producer/consumer situation, where the data is generated on the fly. Note how the producer is first called 3 times before the parallel loop is initiated, and then called to generate new data on the fly:</source>
          <target state="translated">Usando pre_expedición en una situación de productor/consumidor,donde los datos se generan sobre la marcha.Obsérvese cómo el productor es llamado 3 veces antes de que se inicie el bucle paralelo,y luego es llamado para generar nuevos datos sobre la marcha:</target>
        </trans-unit>
        <trans-unit id="efd1182f39233190c4734b5ce34b9cfcf1bbe0bb" translate="yes" xml:space="preserve">
          <source>Using t-SNE. Journal of Machine Learning Research 9:2579-2605, 2008.</source>
          <target state="translated">Usando el T-SNE.Journal of Machine Learning Research 9:2579-2605,2008.</target>
        </trans-unit>
        <trans-unit id="52758be5ab8f6ab028b2bf9ad6db5d2b69896663" translate="yes" xml:space="preserve">
          <source>Using the &lt;code&gt;TfidfTransformer&lt;/code&gt;&amp;rsquo;s default settings, &lt;code&gt;TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)&lt;/code&gt; the term frequency, the number of times a term occurs in a given document, is multiplied with idf component, which is computed as</source>
          <target state="translated">Utilizando el &lt;code&gt;TfidfTransformer&lt;/code&gt; &amp;lsquo;ajustes predeterminados s, &lt;code&gt;TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)&lt;/code&gt; la frecuencia de los t&amp;eacute;rminos, el n&amp;uacute;mero de veces que ocurre un t&amp;eacute;rmino en un documento dado, se multiplica con el componente de la FID, que se calcula como</target>
        </trans-unit>
        <trans-unit id="95d62a973e97428e1fb3d7b86f3a392143b00b8c" translate="yes" xml:space="preserve">
          <source>Using the GraphicalLasso estimator to learn a covariance and sparse precision from a small number of samples.</source>
          <target state="translated">Usando el estimador GraphicalLasso para aprender una covarianza y una precisión escasa de un pequeño número de muestras.</target>
        </trans-unit>
        <trans-unit id="f9e94a3c6c72e38b7c72fe500879db6b6bb31872" translate="yes" xml:space="preserve">
          <source>Using the Iris dataset, we can construct a tree as follows:</source>
          <target state="translated">Usando el conjunto de datos del Iris,podemos construir un árbol de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="99fdc1f5bc1cbf237a61e42fe43157752d29d604" translate="yes" xml:space="preserve">
          <source>Using the Poisson loss with a log-link can correct these problems and lead to a well-calibrated linear model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f990799abb31a15673ef02f50b5506399075290a" translate="yes" xml:space="preserve">
          <source>Using the expected value, the adjusted mutual information can then be calculated using a similar form to that of the adjusted Rand index:</source>
          <target state="translated">Utilizando el valor esperado,la información mutua ajustada puede ser calculada usando una forma similar a la del índice Rand ajustado:</target>
        </trans-unit>
        <trans-unit id="525fdffa79943fda791ea83f2bc571cbb29e45c1" translate="yes" xml:space="preserve">
          <source>Using the naive conditional independence assumption that</source>
          <target state="translated">Utilizando el ingenuo supuesto de independencia condicional que</target>
        </trans-unit>
        <trans-unit id="ded2353583b49d229cc248063161251fcd75da59" translate="yes" xml:space="preserve">
          <source>Using the prediction pipeline in a grid search</source>
          <target state="translated">Usando la tubería de predicción en una búsqueda en la red</target>
        </trans-unit>
        <trans-unit id="4b65de55e2dd198ac6e2aecd67614d2f3e1d68d9" translate="yes" xml:space="preserve">
          <source>Using the results of the previous exercises and the &lt;code&gt;cPickle&lt;/code&gt; module of the standard library, write a command line utility that detects the language of some text provided on &lt;code&gt;stdin&lt;/code&gt; and estimate the polarity (positive or negative) if the text is written in English.</source>
          <target state="translated">Utilizando los resultados de los ejercicios anteriores y el m&amp;oacute;dulo &lt;code&gt;cPickle&lt;/code&gt; de la biblioteca est&amp;aacute;ndar, escriba una utilidad de l&amp;iacute;nea de comandos que detecte el idioma de alg&amp;uacute;n texto proporcionado en &lt;code&gt;stdin&lt;/code&gt; y estime la polaridad (positiva o negativa) si el texto est&amp;aacute; escrito en ingl&amp;eacute;s.</target>
        </trans-unit>
        <trans-unit id="271df6087c1c40487d3dd610dcce2afcb5a005f8" translate="yes" xml:space="preserve">
          <source>Using this modification, the tf-idf of the third term in document 1 changes to 1.8473:</source>
          <target state="translated">Utilizando esta modificación,el tf-idf del tercer término del documento 1 cambia a 1.8473:</target>
        </trans-unit>
        <trans-unit id="a81923715d05cfae1b7290021e8d9f8915c03011" translate="yes" xml:space="preserve">
          <source>Usually the Normalized Discounted Cumulative Gain (NDCG, computed by ndcg_score) is preferred.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35033b7b1c0300bd76803da2e755fdbe07a7c28b" translate="yes" xml:space="preserve">
          <source>Utilities from joblib:</source>
          <target state="translated">Utilidades de joblib:</target>
        </trans-unit>
        <trans-unit id="c9ee5681d3c59f7541c27a38b67edf46259e187b" translate="yes" xml:space="preserve">
          <source>V</source>
          <target state="translated">V</target>
        </trans-unit>
        <trans-unit id="8d1950c14bc870de437b37f806aaa51c635a9ec3" translate="yes" xml:space="preserve">
          <source>V measure</source>
          <target state="translated">V medida</target>
        </trans-unit>
        <trans-unit id="a6ed7787c295565530f8c589d9ab12370f5f5b3d" translate="yes" xml:space="preserve">
          <source>V or VI</source>
          <target state="translated">V o VI</target>
        </trans-unit>
        <trans-unit id="e659ac0cd03fda8c2776727471548e055d6ecaa7" translate="yes" xml:space="preserve">
          <source>V-Measure (NMI with arithmetic mean option.)</source>
          <target state="translated">V-Measure (NMI con opción de media aritmética.)</target>
        </trans-unit>
        <trans-unit id="893c35d89ea6a5c89935fd8eeed462af4410524f" translate="yes" xml:space="preserve">
          <source>V-Measure is furthermore symmetric: swapping &lt;code&gt;labels_true&lt;/code&gt; and &lt;code&gt;label_pred&lt;/code&gt; will give the same score. This does not hold for homogeneity and completeness. V-Measure is identical to &lt;a href=&quot;sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt;&lt;code&gt;normalized_mutual_info_score&lt;/code&gt;&lt;/a&gt; with the arithmetic averaging method.</source>
          <target state="translated">V-Measure es adem&amp;aacute;s sim&amp;eacute;trico: intercambiar &lt;code&gt;labels_true&lt;/code&gt; y &lt;code&gt;label_pred&lt;/code&gt; dar&amp;aacute; la misma puntuaci&amp;oacute;n. Esto no es v&amp;aacute;lido para la homogeneidad y la integridad. V-Measure es id&amp;eacute;ntico a &lt;a href=&quot;sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt; &lt;code&gt;normalized_mutual_info_score&lt;/code&gt; &lt;/a&gt; con el m&amp;eacute;todo de promedio aritm&amp;eacute;tico.</target>
        </trans-unit>
        <trans-unit id="47faeee4990a814efec079e593cccd036ad6778a" translate="yes" xml:space="preserve">
          <source>V-measure cluster labeling given a ground truth.</source>
          <target state="translated">El etiquetado de los cúmulos de V-medida dada una verdad de la tierra.</target>
        </trans-unit>
        <trans-unit id="a4fd517acce42be80ab9791260ae88f5cbdf1a52" translate="yes" xml:space="preserve">
          <source>V. Metsis, I. Androutsopoulos and G. Paliouras (2006). &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.61.5542&quot;&gt;Spam filtering with Naive Bayes &amp;ndash; Which Naive Bayes?&lt;/a&gt; 3rd Conf. on Email and Anti-Spam (CEAS).</source>
          <target state="translated">V. Metsis, I. Androutsopoulos y G. Paliouras (2006). &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.61.5542&quot;&gt;Filtrado de spam con Naive Bayes - &amp;iquest;Qu&amp;eacute; Naive Bayes? &lt;/a&gt;3ra Conf. sobre correo electr&amp;oacute;nico y antispam (CEAS).</target>
        </trans-unit>
        <trans-unit id="942786415758a60976a047b84669d53dbc12ecc2" translate="yes" xml:space="preserve">
          <source>V. Metsis, I. Androutsopoulos and G. Paliouras (2006). Spam filtering with naive Bayes &amp;ndash; Which naive Bayes? 3rd Conf. on Email and Anti-Spam (CEAS).</source>
          <target state="translated">V. Metsis, I. Androutsopoulos y G. Paliouras (2006). Filtrado de spam con Bayes ingenuos - &amp;iquest;Qu&amp;eacute; Bayes ingenuos? 3ra Conf. sobre correo electr&amp;oacute;nico y antispam (CEAS).</target>
        </trans-unit>
        <trans-unit id="a4d9f3d16f166bfe390c3f0be94b7a7169e9ff69" translate="yes" xml:space="preserve">
          <source>Valid &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-multiclass&quot;&gt;multiclass&lt;/a&gt; representations for &lt;code&gt;type_of_target&lt;/code&gt; (&lt;code&gt;y&lt;/code&gt;) are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9c007aafb4123183734854c6075f37be2b0eaac" translate="yes" xml:space="preserve">
          <source>Valid &lt;code&gt;type_of_target&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca4c1a38268237e7698432accf1a9a5a48b6fb08" translate="yes" xml:space="preserve">
          <source>Valid metrics for pairwise_distances.</source>
          <target state="translated">Métricas válidas para distancias_parejas.</target>
        </trans-unit>
        <trans-unit id="26700c8a25eea6fd902a0bb4963f14783c982650" translate="yes" xml:space="preserve">
          <source>Valid metrics for pairwise_kernels</source>
          <target state="translated">Métricas válidas para los pares de núcleos</target>
        </trans-unit>
        <trans-unit id="850c962c3f063b586578621ee12bbb84d6f38bb7" translate="yes" xml:space="preserve">
          <source>Valid options:</source>
          <target state="translated">Opciones válidas:</target>
        </trans-unit>
        <trans-unit id="493108de26f61e3b76acfe363b14fa409e1fdc9a" translate="yes" xml:space="preserve">
          <source>Valid parameter keys can be listed with &lt;code&gt;get_params()&lt;/code&gt;.</source>
          <target state="translated">Las claves de par&amp;aacute;metros v&amp;aacute;lidas se pueden enumerar con &lt;code&gt;get_params()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1a791ec45bdf21e7b9592679ed5472b3c5ab8093" translate="yes" xml:space="preserve">
          <source>Valid parameter keys can be listed with get_params().</source>
          <target state="translated">Las claves de parámetros válidos pueden ser listadas con get_params().</target>
        </trans-unit>
        <trans-unit id="90d9fefcb561047bbbd742b13c3608c6fcf1e657" translate="yes" xml:space="preserve">
          <source>Valid values for metric are:</source>
          <target state="translated">Los valores válidos para la métrica son:</target>
        </trans-unit>
        <trans-unit id="47edea5ff3c24dcb16dc15647447ec5c4a9d77c2" translate="yes" xml:space="preserve">
          <source>Valid values for metric are::</source>
          <target state="translated">Los valores válidos para la métrica son::</target>
        </trans-unit>
        <trans-unit id="21601426cfbdf9a26553c2613d8f13b5c8a0699e" translate="yes" xml:space="preserve">
          <source>Validate scalar parameters type and value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec59a2a93f21b1aa3fbc16cd26b3b2dbab6fa78b" translate="yes" xml:space="preserve">
          <source>Validation curve.</source>
          <target state="translated">Curva de validación.</target>
        </trans-unit>
        <trans-unit id="675b8482a7f9f38fa965a1efe10c6a6ee6ec5cdb" translate="yes" xml:space="preserve">
          <source>Value added to the diagonal of the kernel matrix during fitting. Larger values correspond to increased noise level in the observations. This can also prevent a potential numerical issue during fitting, by ensuring that the calculated values form a positive definite matrix. If an array is passed, it must have the same number of entries as the data used for fitting and is used as datapoint-dependent noise level. Note that this is equivalent to adding a WhiteKernel with c=alpha. Allowing to specify the noise level directly as a parameter is mainly for convenience and for consistency with Ridge.</source>
          <target state="translated">Valor añadido a la diagonal de la matriz del núcleo durante el ajuste.Los valores más grandes corresponden al aumento del nivel de ruido en las observaciones.Esto también puede evitar un posible problema numérico durante el ajuste,asegurando que los valores calculados formen una matriz definitiva positiva.Si se pasa una matriz,ésta debe tener el mismo número de entradas que los datos utilizados para el ajuste y se utiliza como nivel de ruido dependiente del punto de datos.Nótese que esto equivale a añadir un WhiteKernel con c=alfa.Permitir especificar el nivel de ruido directamente como un parámetro es principalmente por conveniencia y por coherencia con Ridge.</target>
        </trans-unit>
        <trans-unit id="cdffc29f88adeffd4bcff100fb7aa53a66956d52" translate="yes" xml:space="preserve">
          <source>Value for numerical stability in adam. Only used when solver=&amp;rsquo;adam&amp;rsquo;</source>
          <target state="translated">Valor de estabilidad num&amp;eacute;rica en ad&amp;aacute;n. Solo se usa cuando solver = 'adam'</target>
        </trans-unit>
        <trans-unit id="c6350d6ef6528ee88ef12a12465bebefd1891dd8" translate="yes" xml:space="preserve">
          <source>Value of the pseudo-likelihood (proxy for likelihood).</source>
          <target state="translated">Valor de la seudoprobabilidad (sustituto de la probabilidad).</target>
        </trans-unit>
        <trans-unit id="7a1b051ea7b4e31aba2ba2519e8c31958f649214" translate="yes" xml:space="preserve">
          <source>Value to assign to the score if an error occurs in estimator fitting. If set to &amp;lsquo;raise&amp;rsquo;, the error is raised. If a numeric value is given, FitFailedWarning is raised. This parameter does not affect the refit step, which will always raise the error.</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
