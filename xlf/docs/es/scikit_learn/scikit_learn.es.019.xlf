<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="es" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="58a55d6f93d14931521825c7a646b62d82a23f61" translate="yes" xml:space="preserve">
          <source>Sample data, shape = (n_samples, n_features), in the form of a numpy array or a NearestNeighbors object.</source>
          <target state="translated">Datos de muestra,forma=(n_muestras,n_características),en forma de una matriz numérica o un objeto NearestNeighbors.</target>
        </trans-unit>
        <trans-unit id="10ce65324acefea0898135b900280dadfb96fe1c" translate="yes" xml:space="preserve">
          <source>Sample data, shape = (n_samples, n_features), in the form of a numpy array, precomputed tree, or NearestNeighbors object.</source>
          <target state="translated">Datos de muestra,forma=(n_muestras,n_características),en forma de una matriz numérica,árbol precalculado,u objeto NearestNeighbors.</target>
        </trans-unit>
        <trans-unit id="40ac2455bae4183af7a973d5cb2e2932b4269896" translate="yes" xml:space="preserve">
          <source>Sample data, shape = (n_samples, n_features), in the form of a numpy array, sparse graph, precomputed tree, or NearestNeighbors object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b207ac8b0144a4f9a4a54998e6acdb3a1a2ce5fc" translate="yes" xml:space="preserve">
          <source>Sample data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea442856bb6f3247c403f5eacbad9d49d9f34166" translate="yes" xml:space="preserve">
          <source>Sample integers without replacement.</source>
          <target state="translated">Muestra de números enteros sin reemplazo.</target>
        </trans-unit>
        <trans-unit id="4057b3cb6bd141b135fafdb32fce3f5d0c92b8db" translate="yes" xml:space="preserve">
          <source>Sample matrix.</source>
          <target state="translated">Matriz de muestras.</target>
        </trans-unit>
        <trans-unit id="04c4511b91c525e2da2ef7db41615c6ca0a3fd2e" translate="yes" xml:space="preserve">
          <source>Sample output:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc8d82180e352f6e4eb38618a9b77ce032b1c63f" translate="yes" xml:space="preserve">
          <source>Sample pipeline for text feature extraction and evaluation</source>
          <target state="translated">Tubería de muestras para la extracción y evaluación de características de texto</target>
        </trans-unit>
        <trans-unit id="0982f69f498171fb424746f3b46f588b79249d60" translate="yes" xml:space="preserve">
          <source>Sample usage of Nearest Centroid classification. It will plot the decision boundaries for each class.</source>
          <target state="translated">Muestra de uso de la clasificación del centroide más cercano.Trazará los límites de decisión para cada clase.</target>
        </trans-unit>
        <trans-unit id="f22b9a32693422a5abcec4767410509915bc2f8f" translate="yes" xml:space="preserve">
          <source>Sample usage of Nearest Neighbors classification. It will plot the decision boundaries for each class.</source>
          <target state="translated">Muestra de uso de la clasificación de Vecinos Más Cercanos.Trazará los límites de decisión para cada clase.</target>
        </trans-unit>
        <trans-unit id="c4ad00c210ac74869e557ad5117f0c17f5204222" translate="yes" xml:space="preserve">
          <source>Sample usage of Neighborhood Components Analysis for dimensionality reduction.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6f1c43a568cbfebecbc9c4a468d534512e56696" translate="yes" xml:space="preserve">
          <source>Sample vectors from which to compute variances.</source>
          <target state="translated">Vectores de muestra a partir de los cuales se calculan las variaciones.</target>
        </trans-unit>
        <trans-unit id="4701e0099b8ff3338dac13ba80a9fd03a1b4e3e5" translate="yes" xml:space="preserve">
          <source>Sample vectors.</source>
          <target state="translated">Vectores de muestra.</target>
        </trans-unit>
        <trans-unit id="e2a418c622901df3ef07f5cc98282eefd0e90959" translate="yes" xml:space="preserve">
          <source>Sample weight</source>
          <target state="translated">Peso de la muestra</target>
        </trans-unit>
        <trans-unit id="e69657285f6aad82f9a81418454c1c4adb873fb2" translate="yes" xml:space="preserve">
          <source>Sample weight.</source>
          <target state="translated">Peso de la muestra.</target>
        </trans-unit>
        <trans-unit id="b0d17c86dbd02471ac25031f76f6b9e62870f2a0" translate="yes" xml:space="preserve">
          <source>Sample weights</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03782597aeab2816675e9752810fe748c242aeef" translate="yes" xml:space="preserve">
          <source>Sample weights.</source>
          <target state="translated">Pesos de muestra.</target>
        </trans-unit>
        <trans-unit id="f828cc5ffdb9cf591696bfda2177ba993eb46afe" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, all samples are given the same weight.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="516c4850672ccbdd1765de8db9d3606a458e566e" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, the sample weights are initialized to 1 / n_samples.</source>
          <target state="translated">Pesos de muestra.Si no hay ninguno,los pesos de las muestras se inicializan a 1/n_muestras.</target>
        </trans-unit>
        <trans-unit id="06e56dd5257a783cd783e2275240a5cef38438c1" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, the sample weights are initialized to &lt;code&gt;1 / n_samples&lt;/code&gt;.</source>
          <target state="translated">Pesos de muestra. Si es Ninguno, los pesos de las muestras se inicializan en &lt;code&gt;1 / n_samples&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b28026c224fc212b3c8db8d7abcf83fe154d5aba" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted.</source>
          <target state="translated">Pesos de muestra.Si no hay ninguno,las muestras tienen el mismo peso.</target>
        </trans-unit>
        <trans-unit id="dd4e4922a0bf331287b6e7fdee69023638c0a9c2" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Note that this is supported only if all underlying estimators support sample weights.</source>
          <target state="translated">Pesos de muestra.Si no hay ninguno,las muestras tienen el mismo peso.Obsérvese que esto sólo se admite si todos los estimadores subyacentes admiten las ponderaciones de las muestras.</target>
        </trans-unit>
        <trans-unit id="72b5ffbf428e4946121de0a0ea4fb4fa9205e66d" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Note that this is supported only if the base estimator supports sample weighting.</source>
          <target state="translated">Pesos de muestra.Si no hay ninguno,las muestras tienen el mismo peso.Tenga en cuenta que esto sólo se admite si el estimador de base admite la ponderación de la muestra.</target>
        </trans-unit>
        <trans-unit id="44004435db67a9bbea489a279598bbde7cadacd2" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Only supported if the underlying classifier supports sample weights.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e07f10e1efb6d03970a11a668db91780f97be9f4" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Only supported if the underlying regressor supports sample weights.</source>
          <target state="translated">Pesos de muestra.Si no hay ninguno,las muestras tienen el mismo peso.Sólo se admite si el regresor subyacente admite pesos de muestra.</target>
        </trans-unit>
        <trans-unit id="d4811960b5c60cf1d2e21f4adf57777acf8cf860" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node.</source>
          <target state="translated">Pesos de muestra.Si no hay ninguno,las muestras tienen el mismo peso.Las divisiones que crearían nodos hijos con peso neto cero o negativo son ignoradas mientras se busca una división en cada nodo.</target>
        </trans-unit>
        <trans-unit id="76ebb3a0858ee52c5cebb457753ce9dfb9f1fd6e" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. In the case of classification, splits are also ignored if they would result in any single class carrying a negative weight in either child node.</source>
          <target state="translated">Pesos de muestra.Si no hay ninguno,las muestras tienen el mismo peso.Las divisiones que crearían nodos hijos con peso neto cero o negativo son ignoradas mientras se busca una división en cada nodo.En el caso de la clasificación,las divisiones también se ignoran si resultan en que una sola clase tenga un peso negativo en cualquiera de los nodos hijos.</target>
        </trans-unit>
        <trans-unit id="317d3738fe42cf9aeb8c2e6052e8dee6f03e55e0" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. Splits are also ignored if they would result in any single class carrying a negative weight in either child node.</source>
          <target state="translated">Pesos de muestra.Si no hay ninguno,las muestras tienen el mismo peso.Las divisiones que crearían nodos hijos con peso neto cero o negativo son ignoradas mientras se busca una división en cada nodo.Las divisiones también se ignoran si resultan en que una sola clase tenga un peso negativo en cualquiera de los nodos hijos.</target>
        </trans-unit>
        <trans-unit id="a6e78b9afd27497df49aade34a36635be33138ac" translate="yes" xml:space="preserve">
          <source>Sample-weight support for Lasso and ElasticNet</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a90c0865394b45b5f31d5c73cc5fa995827fa090" translate="yes" xml:space="preserve">
          <source>Samples a subset of training points, computes kernel on these and computes normalization matrix.</source>
          <target state="translated">Toma muestras de un subconjunto de puntos de entrenamiento,calcula el núcleo en estos y calcula la matriz de normalización.</target>
        </trans-unit>
        <trans-unit id="489527d2412e4e73b577f6c6fbbfa5b2fc34f813" translate="yes" xml:space="preserve">
          <source>Samples generator</source>
          <target state="translated">Generador de muestras</target>
        </trans-unit>
        <trans-unit id="984aa7241ddfaa0a1125ba76d49684d954091644" translate="yes" xml:space="preserve">
          <source>Samples may have several labels each (see &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&quot;&gt;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&lt;/a&gt;)</source>
          <target state="translated">Las muestras pueden tener varias etiquetas cada una (consulte &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&quot;&gt;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="4d0b8d7411b8018b991a89ec2a4d88914d35dbf8" translate="yes" xml:space="preserve">
          <source>Samples may have several labels each (see &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&quot;&gt;https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&lt;/a&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a729b3c883140152c8be9c9b913932e3054a28dd" translate="yes" xml:space="preserve">
          <source>Samples per class</source>
          <target state="translated">Muestras por clase</target>
        </trans-unit>
        <trans-unit id="72ff32775331fbcdecdd7b50f2f019ca6fd41d2c" translate="yes" xml:space="preserve">
          <source>Samples random projection according to n_features.</source>
          <target state="translated">Muestras de proyección aleatoria según n_funciones.</target>
        </trans-unit>
        <trans-unit id="251d1d7b5c7f8793378b7d465a809b22ff0293ea" translate="yes" xml:space="preserve">
          <source>Samples to cluster.</source>
          <target state="translated">Muestras a agrupar.</target>
        </trans-unit>
        <trans-unit id="1b35c86a656c810d2ffde5bec3bbb5716273c85d" translate="yes" xml:space="preserve">
          <source>Samples total</source>
          <target state="translated">Total de muestras</target>
        </trans-unit>
        <trans-unit id="d94a358c32f7a1a8aa072b320513050f66fbf3bb" translate="yes" xml:space="preserve">
          <source>Samples.</source>
          <target state="translated">Samples.</target>
        </trans-unit>
        <trans-unit id="79b4194bd3e79bf7f3c58fb9c6afe5574c4f3465" translate="yes" xml:space="preserve">
          <source>Samples. Each sample must be a text document (either bytes or unicode strings, file name or file object depending on the constructor argument) which will be tokenized and hashed.</source>
          <target state="translated">Muestras.Cada muestra debe ser un documento de texto (ya sea bytes o cadenas unicode,nombre de archivo u objeto de archivo dependiendo del argumento constructor)que será simbólico y hasheado.</target>
        </trans-unit>
        <trans-unit id="4ecf733dec873b2818a96fff2c4d7137b5e9cce2" translate="yes" xml:space="preserve">
          <source>Samples. Each sample must be iterable an (e.g., a list or tuple) containing/generating feature names (and optionally values, see the input_type constructor argument) which will be hashed. raw_X need not support the len function, so it can be the result of a generator; n_samples is determined on the fly.</source>
          <target state="translated">Muestras.Cada muestra debe ser iterable y (por ejemplo,una lista o una tupla)contener/generar nombres de características (y opcionalmente valores,véase el argumento constructor input_type)que se someterán a un hash.raw_X no tiene por qué soportar la función len,por lo que puede ser el resultado de un generador;n_samples se determina sobre la marcha.</target>
        </trans-unit>
        <trans-unit id="475a3c12e7131d5c7c597d45cbde5d7c042c5697" translate="yes" xml:space="preserve">
          <source>Samples. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead a precomputed kernel matrix, shape = [n_samples, n_samples_fitted], where n_samples_fitted is the number of samples used in the fitting for this estimator.</source>
          <target state="translated">Muestras. Si kernel == &amp;ldquo;precalculado&amp;rdquo;, se trata de una matriz de kernel precalculada, shape = [n_samples, n_samples_fitted], donde n_samples_fitted es el n&amp;uacute;mero de muestras utilizadas en el ajuste para este estimador.</target>
        </trans-unit>
        <trans-unit id="786961f4d535734fe86dc46d23d2c4ae6643e27e" translate="yes" xml:space="preserve">
          <source>Sampling interval. Must be specified when sample_steps not in {1,2,3}.</source>
          <target state="translated">Intervalo de muestreo.Debe ser especificado cuando los pasos_de_muestreo no estén en {1,2,3}.</target>
        </trans-unit>
        <trans-unit id="fb8efe38000470eaaa9cdd2c1e100fa22c387ba8" translate="yes" xml:space="preserve">
          <source>Sampling more dimensions clearly leads to better classification results, but comes at a greater cost. This means there is a tradeoff between runtime and accuracy, given by the parameter n_components. Note that solving the Linear SVM and also the approximate kernel SVM could be greatly accelerated by using stochastic gradient descent via &lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt;&lt;/a&gt;. This is not easily possible for the case of the kernelized SVM.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b1ee52c21297b409f91752fd0536580b7df89b8" translate="yes" xml:space="preserve">
          <source>Sampling more dimensions clearly leads to better classification results, but comes at a greater cost. This means there is a tradeoff between runtime and accuracy, given by the parameter n_components. Note that solving the Linear SVM and also the approximate kernel SVM could be greatly accelerated by using stochastic gradient descent via &lt;a href=&quot;../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt;&lt;/a&gt;. This is not easily possible for the case of the kernelized SVM.</source>
          <target state="translated">El muestreo de m&amp;aacute;s dimensiones conduce claramente a mejores resultados de clasificaci&amp;oacute;n, pero tiene un costo mayor. Esto significa que existe una compensaci&amp;oacute;n entre el tiempo de ejecuci&amp;oacute;n y la precisi&amp;oacute;n, dada por el par&amp;aacute;metro n_components. Tenga en cuenta que la resoluci&amp;oacute;n de la SVM lineal y tambi&amp;eacute;n la SVM del kernel aproximada podr&amp;iacute;a acelerarse en gran medida utilizando el descenso de gradiente estoc&amp;aacute;stico a trav&amp;eacute;s de &lt;a href=&quot;../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt; &lt;/a&gt; . Esto no es posible f&amp;aacute;cilmente para el caso de SVM kernelizado.</target>
        </trans-unit>
        <trans-unit id="3e5ac0adafac21480f1a521f8334d2085c97ee0a" translate="yes" xml:space="preserve">
          <source>Sanjoy Dasgupta and Anupam Gupta, 1999, &amp;ldquo;An elementary proof of the Johnson-Lindenstrauss Lemma.&amp;rdquo; &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&lt;/a&gt;</source>
          <target state="translated">Sanjoy Dasgupta y Anupam Gupta, 1999, &quot;Una prueba elemental del Lema de Johnson-Lindenstrauss&quot;. &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="72e45a031f2d9ef687b450c7dbe04851bc78b888" translate="yes" xml:space="preserve">
          <source>Sanjoy Dasgupta and Anupam Gupta, 1999. &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.39.3334&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;An elementary proof of the Johnson-Lindenstrauss Lemma.&lt;/a&gt;</source>
          <target state="translated">Sanjoy Dasgupta y Anupam Gupta, 1999. &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.39.3334&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Una prueba elemental del Lema de Johnson-Lindenstrauss.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="916673b66f20fa78c64c3896647266270d456625" translate="yes" xml:space="preserve">
          <source>Sanjoy Dasgupta. 2000. &lt;a href=&quot;http://cseweb.ucsd.edu/~dasgupta/papers/randomf.pdf&quot;&gt;Experiments with random projection.&lt;/a&gt; In Proceedings of the Sixteenth conference on Uncertainty in artificial intelligence (UAI&amp;lsquo;00), Craig Boutilier and Mois&amp;eacute;s Goldszmidt (Eds.). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 143-151.</source>
          <target state="translated">Sanjoy Dasgupta. 2000. &lt;a href=&quot;http://cseweb.ucsd.edu/~dasgupta/papers/randomf.pdf&quot;&gt;Experimentos con proyecci&amp;oacute;n aleatoria. &lt;/a&gt;En Actas de la Decimosexta conferencia sobre Incertidumbre en inteligencia artificial (UAI'00), Craig Boutilier y Mois&amp;eacute;s Goldszmidt (Eds.). Morgan Kaufmann Publishers Inc., San Francisco, CA, EE. UU., 143-151.</target>
        </trans-unit>
        <trans-unit id="2894bd12dff71a351f3ecafd27a1d2a6b0bda89e" translate="yes" xml:space="preserve">
          <source>Sanjoy Dasgupta. 2000. &lt;a href=&quot;https://cseweb.ucsd.edu/~dasgupta/papers/randomf.pdf&quot;&gt;Experiments with random projection.&lt;/a&gt; In Proceedings of the Sixteenth conference on Uncertainty in artificial intelligence (UAI&amp;rsquo;00), Craig Boutilier and Mois&amp;eacute;s Goldszmidt (Eds.). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 143-151.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3dc12a8bd942b1cd9b3ab450a012927de384bfa6" translate="yes" xml:space="preserve">
          <source>Save fitted model as best model if number of inlier samples is maximal. In case the current estimated model has the same number of inliers, it is only considered as the best model if it has better score.</source>
          <target state="translated">Guarde el modelo ajustado como el mejor modelo si el número de muestras anteriores es máximo.En caso de que el modelo estimado actual tenga el mismo número de inliers,sólo se considera como el mejor modelo si tiene una mejor puntuación.</target>
        </trans-unit>
        <trans-unit id="94b03c70b196c58604c0a7faf7218bf6901b8e0c" translate="yes" xml:space="preserve">
          <source>Scalability</source>
          <target state="translated">Scalability</target>
        </trans-unit>
        <trans-unit id="461b60146605d928fa9b9a5fb416ca167c84c880" translate="yes" xml:space="preserve">
          <source>Scalability and stability improvements to KMeans</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="199d842d852910d77fdbfb1dc59f0d2885e1b21f" translate="yes" xml:space="preserve">
          <source>Scalability can be boosted by using fewer seeds, for example by using a higher value of min_bin_freq in the get_bin_seeds function.</source>
          <target state="translated">La escalabilidad puede aumentarse utilizando menos semillas,por ejemplo,utilizando un valor más alto de min_bin_freq en la función get_bin_seeds.</target>
        </trans-unit>
        <trans-unit id="29f2c344812c53bdbb5e427694d6be2d492aaf47" translate="yes" xml:space="preserve">
          <source>Scalability, due to the sequential nature of boosting it can hardly be parallelized.</source>
          <target state="translated">La escalabilidad,debido a la naturaleza secuencial de la potenciación,difícilmente puede ser paralela.</target>
        </trans-unit>
        <trans-unit id="f6484bee2609587949da674a2bdf0fe83ede7b2a" translate="yes" xml:space="preserve">
          <source>Scalability:</source>
          <target state="translated">Scalability:</target>
        </trans-unit>
        <trans-unit id="61dc05feb549eab6c07b7a94be612c538f71b094" translate="yes" xml:space="preserve">
          <source>Scalable Linear Support Vector Machine for classification implemented using liblinear. Check the See also section of LinearSVC for more comparison element.</source>
          <target state="translated">Máquina Vectorial de Soporte Lineal Escalable para la clasificación implementada usando librea.Ver también la sección de LinearSVC para más elementos de comparación.</target>
        </trans-unit>
        <trans-unit id="eecb89d050bc91f7d55354e38239145e4acf15ef" translate="yes" xml:space="preserve">
          <source>Scalable Linear Support Vector Machine for regression implemented using liblinear.</source>
          <target state="translated">Máquina vectorial de soporte lineal escalable para la regresión implementada mediante el uso de la librea.</target>
        </trans-unit>
        <trans-unit id="22b700f6b9ee53c2fb9ac81cf84c12516aa516e1" translate="yes" xml:space="preserve">
          <source>Scalable linear Support Vector Machine for classification using liblinear.</source>
          <target state="translated">Máquina Vectorial de Soporte Lineal Escalable para la clasificación usando la librea.</target>
        </trans-unit>
        <trans-unit id="bdabc7bc958d2928d9827e9b54f6956c7bb824f2" translate="yes" xml:space="preserve">
          <source>Scale back the data to the original representation</source>
          <target state="translated">Reducir los datos a la representación original</target>
        </trans-unit>
        <trans-unit id="561dee1ec35178a67790d71472d188769f1e1bd6" translate="yes" xml:space="preserve">
          <source>Scale each feature by its maximum absolute value.</source>
          <target state="translated">Escala cada característica por su máximo valor absoluto.</target>
        </trans-unit>
        <trans-unit id="2d3a1b9b18053dd9fb9c5426f583cf0f7d587a14" translate="yes" xml:space="preserve">
          <source>Scale each feature of the data matrix by multiplying with specific scale provided by the caller assuming a (n_samples, n_features) shape.</source>
          <target state="translated">Escala cada característica de la matriz de datos multiplicándola por la escala específica proporcionada por el llamador asumiendo una forma (n_muestras,n_características).</target>
        </trans-unit>
        <trans-unit id="c6c81268e0182a1a807ca4c628dc76b97a0fa5dc" translate="yes" xml:space="preserve">
          <source>Scale each feature to the [-1, 1] range without breaking the sparsity.</source>
          <target state="translated">Escala cada rasgo al rango de [-1,1]sin romper la dispersión.</target>
        </trans-unit>
        <trans-unit id="5deb9ce023c33b22d107e28507be5494ec70764b" translate="yes" xml:space="preserve">
          <source>Scale each non zero row of X to unit norm</source>
          <target state="translated">Escala cada fila no cero de X a la norma de la unidad</target>
        </trans-unit>
        <trans-unit id="617d6ad46bfccaf27b4ba0f374d21f46a99d594e" translate="yes" xml:space="preserve">
          <source>Scale each row of the data matrix by multiplying with specific scale provided by the caller assuming a (n_samples, n_features) shape.</source>
          <target state="translated">Escala cada fila de la matriz de datos multiplicándola por la escala específica proporcionada por el llamador asumiendo una forma (n_muestras,n_características).</target>
        </trans-unit>
        <trans-unit id="2febfe8f8ec8796f6ba7a4455156e82486b6b9ad" translate="yes" xml:space="preserve">
          <source>Scale factor between inner and outer circle.</source>
          <target state="translated">Factor de escala entre el círculo interno y el externo.</target>
        </trans-unit>
        <trans-unit id="c9aadd325b03483aa8cbb4258dd4942f088c00d2" translate="yes" xml:space="preserve">
          <source>Scale features of X according to feature_range.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="651dfd0de4ed652c75c33e720387c590f106c0bd" translate="yes" xml:space="preserve">
          <source>Scale features using statistics that are robust to outliers.</source>
          <target state="translated">Características de escala usando estadísticas que son robustas a los valores atípicos.</target>
        </trans-unit>
        <trans-unit id="ea253b52225bff13ccf219a7ede865331cee2a5e" translate="yes" xml:space="preserve">
          <source>Scale input vectors individually to unit norm (vector length).</source>
          <target state="translated">Escalar los vectores de entrada individualmente a la norma de la unidad (longitud del vector).</target>
        </trans-unit>
        <trans-unit id="3db146d5ef4350db484651a2947cc4449aa1c920" translate="yes" xml:space="preserve">
          <source>Scale mixture parameter</source>
          <target state="translated">Parámetro de la mezcla de la escala</target>
        </trans-unit>
        <trans-unit id="214cf07e698e140c0ab386ee80be892f7e60d56f" translate="yes" xml:space="preserve">
          <source>Scale the data</source>
          <target state="translated">Escalar los datos</target>
        </trans-unit>
        <trans-unit id="a00231cc0fa6cda008f7de726dc3328122b68e67" translate="yes" xml:space="preserve">
          <source>Scaled data has zero mean and unit variance:</source>
          <target state="translated">Los datos escalados tienen una media cero y una varianza unitaria:</target>
        </trans-unit>
        <trans-unit id="28f5624ffdfd0dbb670e710c5400ff826061c8e3" translate="yes" xml:space="preserve">
          <source>Scalers are linear (or more precisely affine) transformers and differ from each other in the way to estimate the parameters used to shift and scale each feature.</source>
          <target state="translated">Los escaladores son transformadores lineales (o más precisamente afines)y difieren entre sí en la forma de estimar los parámetros utilizados para desplazar y escalar cada característica.</target>
        </trans-unit>
        <trans-unit id="42fb0a5f800741efdeeef6c8d3f6efbb496929e6" translate="yes" xml:space="preserve">
          <source>Scaling a 1D array</source>
          <target state="translated">Escalando una matriz 1D</target>
        </trans-unit>
        <trans-unit id="5e180a611580dedaac6cdcb57565a42487e31efa" translate="yes" xml:space="preserve">
          <source>Scaling features of X according to feature_range.</source>
          <target state="translated">Escalando las características de X según el rango de características.</target>
        </trans-unit>
        <trans-unit id="faa375cb6d0913845d11a421f85f4fc1917244d4" translate="yes" xml:space="preserve">
          <source>Scaling inputs to unit norms is a common operation for text classification or clustering for instance. For instance the dot product of two l2-normalized TF-IDF vectors is the cosine similarity of the vectors and is the base similarity metric for the Vector Space Model commonly used by the Information Retrieval community.</source>
          <target state="translated">La ampliación de las entradas a las normas de unidades es una operación común para la clasificación de textos o la agrupación,por ejemplo.Por ejemplo,el producto puntual de dos vectores TF-IDF normalizados en l2 es la similitud de coseno de los vectores y es la métrica de similitud de base para el Modelo Espacial de Vectores que utiliza habitualmente la comunidad de recuperación de información.</target>
        </trans-unit>
        <trans-unit id="c9df043572b1169b126da4f0a95f811ab4322363" translate="yes" xml:space="preserve">
          <source>Scaling of the features in the space spanned by the class centroids.</source>
          <target state="translated">Escalado de los rasgos en el espacio abarcado por los centroides de la clase.</target>
        </trans-unit>
        <trans-unit id="b5c5a5ab3639fcbfa287bfb00c2baa97d840c68a" translate="yes" xml:space="preserve">
          <source>Scaling of the features in the space spanned by the class centroids. Only available for &amp;lsquo;svd&amp;rsquo; and &amp;lsquo;eigen&amp;rsquo; solvers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f91f363e9d78c82d08c38c5a1dbde0b091a85898" translate="yes" xml:space="preserve">
          <source>Scaling parameter of the chi2 kernel.</source>
          <target state="translated">Parámetro de escala del núcleo del chi2.</target>
        </trans-unit>
        <trans-unit id="611f59db789837a47c8391146e294e88684d2aac" translate="yes" xml:space="preserve">
          <source>Scaling the regularization parameter for SVCs</source>
          <target state="translated">Escalado del parámetro de regularización para las CVP</target>
        </trans-unit>
        <trans-unit id="8ca361aee1b505e96263673a562173e09064f7c8" translate="yes" xml:space="preserve">
          <source>Scaling vs Whitening</source>
          <target state="translated">Escalado vs.Blanqueamiento</target>
        </trans-unit>
        <trans-unit id="02ba5e6e4d2072a725717b83a0dcd2c4ccfb8e6e" translate="yes" xml:space="preserve">
          <source>Sch&amp;ouml;lkopf et. al &lt;a href=&quot;https://www.stat.purdue.edu/~yuzhu/stat598m3/Papers/NewSVM.pdf&quot;&gt;New Support Vector Algorithms&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f575a7be2bbae52450cf10acab0f42ab527bed47" translate="yes" xml:space="preserve">
          <source>Schubert, E., Sander, J., Ester, M., Kriegel, H. P., &amp;amp; Xu, X. (2017). DBSCAN revisited, revisited: why and how you should (still) use DBSCAN. ACM Transactions on Database Systems (TODS), 42(3), 19.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35b3e8e65e06fb91614a9faf2b4d8410e9e9072a" translate="yes" xml:space="preserve">
          <source>Schubert, Erich, Michael Gertz. &amp;ldquo;Improving the Cluster Structure Extracted from OPTICS Plots.&amp;rdquo; Proc. of the Conference &amp;ldquo;Lernen, Wissen, Daten, Analysen&amp;rdquo; (LWDA) (2018): 318-329.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ac4d036f5e40e9fc63fcd2b4959a2b29e290cfe" translate="yes" xml:space="preserve">
          <source>Scikit-learn 0.21 introduced two new experimental implementations of gradient boosting trees, namely &lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt;&lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;, inspired by &lt;a href=&quot;https://github.com/Microsoft/LightGBM&quot;&gt;LightGBM&lt;/a&gt; (See &lt;a href=&quot;#lightgbm&quot; id=&quot;id24&quot;&gt;[LightGBM]&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb84d52fa4915e02b24a271ab0aad024c4056d13" translate="yes" xml:space="preserve">
          <source>Scikit-learn 0.21 introduces two new experimental implementations of gradient boosting trees, namely &lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt;&lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;, inspired by &lt;a href=&quot;https://github.com/Microsoft/LightGBM&quot;&gt;LightGBM&lt;/a&gt; (See &lt;a href=&quot;#lightgbm&quot; id=&quot;id14&quot;&gt;[LightGBM]&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b38453e586dafca0c0308eafbfda226dcf7f7c2" translate="yes" xml:space="preserve">
          <source>Scikit-learn also embed a couple of sample JPEG images published under Creative Commons license by their authors. Those image can be useful to test algorithms and pipeline on 2D data.</source>
          <target state="translated">Scikit-learn también incrusta un par de imágenes JPEG de muestra publicadas bajo licencia Creative Commons por sus autores.Esas imágenes pueden ser útiles para probar algoritmos y tuberías en datos 2D.</target>
        </trans-unit>
        <trans-unit id="aad0f03512858b9b99ff0fe8b0c0fddc5ad0d78e" translate="yes" xml:space="preserve">
          <source>Scikit-learn also embed a couple of sample JPEG images published under Creative Commons license by their authors. Those images can be useful to test algorithms and pipeline on 2D data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f09669bc19a45a6af1925c5dd7e5320d97b9858" translate="yes" xml:space="preserve">
          <source>Scikit-learn also permits evaluation of multiple metrics in &lt;code&gt;GridSearchCV&lt;/code&gt;, &lt;code&gt;RandomizedSearchCV&lt;/code&gt; and &lt;code&gt;cross_validate&lt;/code&gt;.</source>
          <target state="translated">Scikit-learn tambi&amp;eacute;n permite la evaluaci&amp;oacute;n de m&amp;uacute;ltiples m&amp;eacute;tricas en &lt;code&gt;GridSearchCV&lt;/code&gt; , &lt;code&gt;RandomizedSearchCV&lt;/code&gt; y &lt;code&gt;cross_validate&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5427512908da9e885639e4f06d90d3fbb899fa1a" translate="yes" xml:space="preserve">
          <source>Scikit-learn deals with learning information from one or more datasets that are represented as 2D arrays. They can be understood as a list of multi-dimensional observations. We say that the first axis of these arrays is the &lt;strong&gt;samples&lt;/strong&gt; axis, while the second is the &lt;strong&gt;features&lt;/strong&gt; axis.</source>
          <target state="translated">Scikit-learn se ocupa de aprender informaci&amp;oacute;n de uno o m&amp;aacute;s conjuntos de datos que se representan como matrices 2D. Pueden entenderse como una lista de observaciones multidimensionales. Decimos que el primer eje de estas matrices es el eje de &lt;strong&gt;muestras&lt;/strong&gt; , mientras que el segundo es el eje de &lt;strong&gt;caracter&amp;iacute;sticas&lt;/strong&gt; .</target>
        </trans-unit>
        <trans-unit id="f9977ec0fe68c8f9bbc6588808c28cd22800a19b" translate="yes" xml:space="preserve">
          <source>Scikit-learn defines a simple API for creating visualizations for machine learning. The key features of this API is to allow for quick plotting and visual adjustments without recalculation. In this example, we will demonstrate how to use the visualization API by comparing ROC curves.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68787e98ea90825b478bf4a016c311205a6818e9" translate="yes" xml:space="preserve">
          <source>Scikit-learn does some validation on data that increases the overhead per call to &lt;code&gt;predict&lt;/code&gt; and similar functions. In particular, checking that features are finite (not NaN or infinite) involves a full pass over the data. If you ensure that your data is acceptable, you may suppress checking for finiteness by setting the environment variable &lt;code&gt;SKLEARN_ASSUME_FINITE&lt;/code&gt; to a non-empty string before importing scikit-learn, or configure it in Python with &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt;. For more control than these global settings, a &lt;code&gt;config_context&lt;/code&gt; allows you to set this configuration within a specified context:</source>
          <target state="translated">Scikit-learn realiza cierta validaci&amp;oacute;n en los datos que aumentan la sobrecarga por llamada para &lt;code&gt;predict&lt;/code&gt; y funciones similares. En particular, verificar que las caracter&amp;iacute;sticas sean finitas (no NaN o infinitas) implica un pase completo sobre los datos. Si se asegura de que sus datos sean aceptables, puede suprimir la verificaci&amp;oacute;n de finitud configurando la variable de entorno &lt;code&gt;SKLEARN_ASSUME_FINITE&lt;/code&gt; en una cadena no vac&amp;iacute;a antes de importar scikit-learn, o configurarla en Python con &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;sklearn.set_config&lt;/code&gt; &lt;/a&gt; . Para obtener m&amp;aacute;s control que estas configuraciones globales, un &lt;code&gt;config_context&lt;/code&gt; le permite establecer esta configuraci&amp;oacute;n dentro de un contexto espec&amp;iacute;fico:</target>
        </trans-unit>
        <trans-unit id="56e4295ba33d7d0b066dcb5a29b6f828761a1e6b" translate="yes" xml:space="preserve">
          <source>Scikit-learn generally relies on the &lt;code&gt;loky&lt;/code&gt; backend, which is joblib&amp;rsquo;s default backend. Loky is a multi-processing backend. When doing multi-processing, in order to avoid duplicating the memory in each process (which isn&amp;rsquo;t reasonable with big datasets), joblib will create a &lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.memmap.html&quot;&gt;memmap&lt;/a&gt; that all processes can share, when the data is bigger than 1MB.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="562455165c34b7c83008b571c9bd46eceb879b92" translate="yes" xml:space="preserve">
          <source>Scikit-learn has a collection of classes which can be used to generate lists of train/test indices for popular cross-validation strategies.</source>
          <target state="translated">Scikit-learn tiene una colección de clases que pueden utilizarse para generar listas de índices de trenes/pruebas para estrategias populares de validación cruzada.</target>
        </trans-unit>
        <trans-unit id="b670925eafc995f1763e66f682772271e15a05e5" translate="yes" xml:space="preserve">
          <source>Scikit-learn implements different classes to estimate Gaussian mixture models, that correspond to different estimation strategies, detailed below.</source>
          <target state="translated">Scikit-learn implementa diferentes clases para estimar los modelos de mezcla gaussiana,que corresponden a diferentes estrategias de estimación,que se detallan a continuación.</target>
        </trans-unit>
        <trans-unit id="e9a530527422759264cd84546f6a0bd4a26252b3" translate="yes" xml:space="preserve">
          <source>Scikit-learn implements efficient kernel density estimation using either a Ball Tree or KD Tree structure, through the &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt;&lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt;&lt;/a&gt; estimator. The available kernels are shown in the second figure of this example.</source>
          <target state="translated">Scikit-learn implementa una estimaci&amp;oacute;n eficiente de la densidad del kernel utilizando una estructura Ball Tree o KD Tree, a trav&amp;eacute;s del estimador &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt; &lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt; &lt;/a&gt; . Los n&amp;uacute;cleos disponibles se muestran en la segunda figura de este ejemplo.</target>
        </trans-unit>
        <trans-unit id="b29477e8796624fa3eb37a4b942da5b84d872c57" translate="yes" xml:space="preserve">
          <source>Scikit-learn is a Python module integrating classic machine learning algorithms in the tightly-knit world of scientific Python packages (&lt;a href=&quot;http://www.scipy.org&quot;&gt;NumPy&lt;/a&gt;, &lt;a href=&quot;http://www.scipy.org&quot;&gt;SciPy&lt;/a&gt;, &lt;a href=&quot;http://matplotlib.org&quot;&gt;matplotlib&lt;/a&gt;).</source>
          <target state="translated">Scikit-learn es un m&amp;oacute;dulo de Python que integra algoritmos cl&amp;aacute;sicos de aprendizaje autom&amp;aacute;tico en el estrecho mundo de los paquetes cient&amp;iacute;ficos de Python ( &lt;a href=&quot;http://www.scipy.org&quot;&gt;NumPy&lt;/a&gt; , &lt;a href=&quot;http://www.scipy.org&quot;&gt;SciPy&lt;/a&gt; , &lt;a href=&quot;http://matplotlib.org&quot;&gt;matplotlib&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="8efe5ffe4058ee23f32fcb7e77b39f35cffa4409" translate="yes" xml:space="preserve">
          <source>Scikit-learn is a Python module integrating classic machine learning algorithms in the tightly-knit world of scientific Python packages (&lt;a href=&quot;https://www.numpy.org/&quot;&gt;NumPy&lt;/a&gt;, &lt;a href=&quot;https://scipy.org/&quot;&gt;SciPy&lt;/a&gt;, &lt;a href=&quot;https://matplotlib.org/&quot;&gt;matplotlib&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5244e6b9c3228eb8fcf423888d9d9a31c68e2222" translate="yes" xml:space="preserve">
          <source>Scikit-learn offers a more efficient implementation for the construction of decision trees. A naive implementation (as above) would recompute the class label histograms (for classification) or the means (for regression) at for each new split point along a given feature. Presorting the feature over all relevant samples, and retaining a running label count, will reduce the complexity at each node to \(O(n_{features}\log(n_{samples}))\), which results in a total cost of \(O(n_{features}n_{samples}\log(n_{samples}))\). This is an option for all tree based algorithms. By default it is turned on for gradient boosting, where in general it makes training faster, but turned off for all other algorithms as it tends to slow down training when training deep trees.</source>
          <target state="translated">Scikit-learn ofrece una implementación más eficiente para la construcción de árboles de decisión.Una implementación ingenua (como la anterior)recompondría los histogramas de las etiquetas de clase (para la clasificación)o los medios (para la regresión)en cada nuevo punto de división a lo largo de una característica dada.Presortando la característica sobre todas las muestras relevantes,y manteniendo un recuento de etiquetas en marcha,se reducirá la complejidad en cada nodo a \ ~ O(n_{características}\ ~ log(n_{muestras}))\ ~,lo que resulta en un costo total de \ ~ O(n_{características}\ ~ n_{muestras}log(n_{muestras})).Esta es una opción para todos los algoritmos basados en árboles.Por defecto está activada para el aumento de gradiente,donde en general hace que el entrenamiento sea más rápido,pero desactivada para el resto de algoritmos ya que tiende a ralentizar el entrenamiento cuando se entrenan árboles profundos.</target>
        </trans-unit>
        <trans-unit id="4affb29f4cf970be26e1f3befb3e52980b3745a3" translate="yes" xml:space="preserve">
          <source>Scikit-learn provides 3 robust regression estimators: &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;, &lt;a href=&quot;#theil-sen-regression&quot;&gt;Theil Sen&lt;/a&gt; and &lt;a href=&quot;#huber-regression&quot;&gt;HuberRegressor&lt;/a&gt;</source>
          <target state="translated">Scikit-learn proporciona 3 estimadores de regresi&amp;oacute;n robustos: &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt; , &lt;a href=&quot;#theil-sen-regression&quot;&gt;Theil Sen&lt;/a&gt; y &lt;a href=&quot;#huber-regression&quot;&gt;HuberRegressor&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="54ef66758fb920f45dd137b20e476f9003566169" translate="yes" xml:space="preserve">
          <source>Scikit-learn provides 3 robust regression estimators: &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;, &lt;a href=&quot;#theil-sen-regression&quot;&gt;Theil Sen&lt;/a&gt; and &lt;a href=&quot;#huber-regression&quot;&gt;HuberRegressor&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf6e9e896240b0867bdae025d2a37105852d3491" translate="yes" xml:space="preserve">
          <source>Scikit-learn relies heavily on NumPy and SciPy, which internally call multi-threaded linear algebra routines implemented in libraries such as MKL, OpenBLAS or BLIS.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="760c9dce2728b87b0e773a2a2023bd5ef6b1ebc6" translate="yes" xml:space="preserve">
          <source>Scikit-learn uses the &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/&quot;&gt;joblib&lt;/a&gt; library to enable parallel computing inside its estimators. See the joblib documentation for the switches to control parallel computing.</source>
          <target state="translated">Scikit-learn usa la biblioteca &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/&quot;&gt;joblib&lt;/a&gt; para habilitar la computaci&amp;oacute;n paralela dentro de sus estimadores. Consulte la documentaci&amp;oacute;n de joblib para conocer los conmutadores para controlar la computaci&amp;oacute;n en paralelo.</target>
        </trans-unit>
        <trans-unit id="dbdfa5cbcc37d085da70cbad1d49bb4154a25ae3" translate="yes" xml:space="preserve">
          <source>Scipy provides sparse matrix data structures which are optimized for storing sparse data. The main feature of sparse formats is that you don&amp;rsquo;t store zeros so if your data is sparse then you use much less memory. A non-zero value in a sparse (&lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;CSR or CSC&lt;/a&gt;) representation will only take on average one 32bit integer position + the 64 bit floating point value + an additional 32bit per row or column in the matrix. Using sparse input on a dense (or sparse) linear model can speedup prediction by quite a bit as only the non zero valued features impact the dot product and thus the model predictions. Hence if you have 100 non zeros in 1e6 dimensional space, you only need 100 multiply and add operation instead of 1e6.</source>
          <target state="translated">Scipy proporciona estructuras de datos matriciales dispersas que est&amp;aacute;n optimizadas para almacenar datos dispersos. La caracter&amp;iacute;stica principal de los formatos dispersos es que no almacena ceros, por lo que si sus datos son escasos, usa mucha menos memoria. Un valor distinto de cero en una representaci&amp;oacute;n escasa ( &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;CSR o CSC&lt;/a&gt; ) solo tomar&amp;aacute; en promedio una posici&amp;oacute;n entera de 32 bits + el valor de coma flotante de 64 bits + 32 bits adicionales por fila o columna en la matriz. El uso de datos dispersos en un modelo lineal denso (o escaso) puede acelerar la predicci&amp;oacute;n bastante, ya que solo las caracter&amp;iacute;sticas con valor distinto de cero afectan el producto escalar y, por lo tanto, las predicciones del modelo. Por lo tanto, si tiene 100 distintos de ceros en el espacio dimensional 1e6, solo necesita 100 multiplicar y agregar operaci&amp;oacute;n en lugar de 1e6.</target>
        </trans-unit>
        <trans-unit id="41590fea612397630e8b90182fcd88974e84be1f" translate="yes" xml:space="preserve">
          <source>Scipy provides sparse matrix data structures which are optimized for storing sparse data. The main feature of sparse formats is that you don&amp;rsquo;t store zeros so if your data is sparse then you use much less memory. A non-zero value in a sparse (&lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;CSR or CSC&lt;/a&gt;) representation will only take on average one 32bit integer position + the 64 bit floating point value + an additional 32bit per row or column in the matrix. Using sparse input on a dense (or sparse) linear model can speedup prediction by quite a bit as only the non zero valued features impact the dot product and thus the model predictions. Hence if you have 100 non zeros in 1e6 dimensional space, you only need 100 multiply and add operation instead of 1e6.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73ff9df76cca7434e9bdc94c5c539e98a711a167" translate="yes" xml:space="preserve">
          <source>Scipy sparse matrix formats documentation</source>
          <target state="translated">Documentación de formatos de matrices dispersas de Scipy</target>
        </trans-unit>
        <trans-unit id="ec44ac6f635d9837f888fea19337ecd3bc1dc78d" translate="yes" xml:space="preserve">
          <source>Score function (or loss function) with signature &lt;code&gt;score_func(y, y_pred, **kwargs)&lt;/code&gt;.</source>
          <target state="translated">Funci&amp;oacute;n de puntuaci&amp;oacute;n (o funci&amp;oacute;n de p&amp;eacute;rdida) con la firma &lt;code&gt;score_func(y, y_pred, **kwargs)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e8a42d4da772627d057fecc9d05d1c5e0de456df" translate="yes" xml:space="preserve">
          <source>Score of base estimator with best alpha.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4106362aa56af5a012e22c8aae43583defb47511" translate="yes" xml:space="preserve">
          <source>Score of self.predict(X) wrt. y.</source>
          <target state="translated">Puntuación de self.predict(X)wrt.y.</target>
        </trans-unit>
        <trans-unit id="269ca6f46a2303fa294fd49cbab7d3d725c81bb2" translate="yes" xml:space="preserve">
          <source>Score of the prediction.</source>
          <target state="translated">Puntuación de la predicción.</target>
        </trans-unit>
        <trans-unit id="fee68e2ae75f4d785b563d7d07175bca2df697af" translate="yes" xml:space="preserve">
          <source>Score of the training dataset obtained using an out-of-bag estimate.</source>
          <target state="translated">Puntuación del conjunto de datos de capacitación obtenida mediante una estimación fuera de la bolsa.</target>
        </trans-unit>
        <trans-unit id="d47762b2bcf100a0eee50ed9f7a0b022146b7037" translate="yes" xml:space="preserve">
          <source>Score of the training dataset obtained using an out-of-bag estimate. This attribute exists only when &lt;code&gt;oob_score&lt;/code&gt; is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a728e01859e5aacfa8054e6c7ac1cbc91bfd77d" translate="yes" xml:space="preserve">
          <source>Score of this parameter setting on given test split.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fdd43514c35f028b5dfc878c7661a274717e7633" translate="yes" xml:space="preserve">
          <source>Score of this parameter setting on given training / test split.</source>
          <target state="translated">Puntuación de este parámetro en una división de entrenamiento/prueba dada.</target>
        </trans-unit>
        <trans-unit id="e14703c8615f59873dec25794c9dae3e6fdaa2e4" translate="yes" xml:space="preserve">
          <source>Score, and cross-validated scores</source>
          <target state="translated">Puntuación,y puntuaciones validadas cruzadas</target>
        </trans-unit>
        <trans-unit id="5ac699be69d4f6f03061e9fdf043eeb8d0ba0ed6" translate="yes" xml:space="preserve">
          <source>Scorer function used on the held out data to choose the best parameters for the model.</source>
          <target state="translated">Función de puntuación utilizada en los datos retenidos para elegir los mejores parámetros para el modelo.</target>
        </trans-unit>
        <trans-unit id="2d120255d84deeb73e3a5484f87eef4818f21119" translate="yes" xml:space="preserve">
          <source>Scorer to use. It can be a single string (see &lt;a href=&quot;../model_evaluation#scoring-parameter&quot;&gt;The scoring parameter: defining model evaluation rules&lt;/a&gt;) or a callable (see &lt;a href=&quot;../model_evaluation#scoring&quot;&gt;Defining your scoring strategy from metric functions&lt;/a&gt;). If None, the estimator&amp;rsquo;s default scorer is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dafe5cdb100f4bad5185f8a89151e9de127407db" translate="yes" xml:space="preserve">
          <source>Scores of all outputs are averaged with uniform weight.</source>
          <target state="translated">Las puntuaciones de todas las salidas se promedian con un peso uniforme.</target>
        </trans-unit>
        <trans-unit id="a879b57711ff565bb3c57b9cbdbf3f09144796d5" translate="yes" xml:space="preserve">
          <source>Scores of all outputs are averaged, weighted by the variances of each individual output.</source>
          <target state="translated">Se promedian las puntuaciones de todos los productos,ponderadas por las variaciones de cada uno de ellos.</target>
        </trans-unit>
        <trans-unit id="bad96478d4d42d160afd8f51da6516a096f00968" translate="yes" xml:space="preserve">
          <source>Scores of features.</source>
          <target state="translated">Partituras de las características.</target>
        </trans-unit>
        <trans-unit id="004421c31cff3e85919b0da3d9213b70c070211e" translate="yes" xml:space="preserve">
          <source>Scores on test set.</source>
          <target state="translated">Puntuaciones en el set de pruebas.</target>
        </trans-unit>
        <trans-unit id="9cb2f72d484e4d0e25f5504cf3cb781f6831387a" translate="yes" xml:space="preserve">
          <source>Scores on training sets.</source>
          <target state="translated">Puntuaciones en los sets de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="a6e081bd4fc687e97f2a3c1767e01a47d8d0d090" translate="yes" xml:space="preserve">
          <source>Scoring</source>
          <target state="translated">Scoring</target>
        </trans-unit>
        <trans-unit id="1d35080d3b512f65a9672a3ec57c49c5c7d18fa7" translate="yes" xml:space="preserve">
          <source>Scoring parameter to use for early stopping. It can be a single string (see &lt;a href=&quot;../model_evaluation#scoring-parameter&quot;&gt;The scoring parameter: defining model evaluation rules&lt;/a&gt;) or a callable (see &lt;a href=&quot;../model_evaluation#scoring&quot;&gt;Defining your scoring strategy from metric functions&lt;/a&gt;). If None, the estimator&amp;rsquo;s default scorer is used. If &lt;code&gt;scoring='loss'&lt;/code&gt;, early stopping is checked w.r.t the loss value. Only used if early stopping is performed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88173ba266bcaafd44bc526091a11bf84a691634" translate="yes" xml:space="preserve">
          <source>Second example</source>
          <target state="translated">Segundo ejemplo</target>
        </trans-unit>
        <trans-unit id="01969fb763d816468d958ddf55fbcfeb6492bbfe" translate="yes" xml:space="preserve">
          <source>Second, precomputing the graph can give finer control on the nearest neighbors estimation, for instance enabling multiprocessing though the parameter &lt;code&gt;n_jobs&lt;/code&gt;, which might not be available in all estimators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4e2db45443f0fd4ae50799405ca1ddce61eefb7" translate="yes" xml:space="preserve">
          <source>Second, when using a connectivity matrix, single, average and complete linkage are unstable and tend to create a few clusters that grow very quickly. Indeed, average and complete linkage fight this percolation behavior by considering all the distances between two clusters when merging them ( while single linkage exaggerates the behaviour by considering only the shortest distance between clusters). The connectivity graph breaks this mechanism for average and complete linkage, making them resemble the more brittle single linkage. This effect is more pronounced for very sparse graphs (try decreasing the number of neighbors in kneighbors_graph) and with complete linkage. In particular, having a very small number of neighbors in the graph, imposes a geometry that is close to that of single linkage, which is well known to have this percolation instability.</source>
          <target state="translated">En segundo lugar,cuando se utiliza una matriz de conectividad,la vinculación única,media y completa es inestable y tiende a crear unos pocos grupos que crecen muy rápidamente.De hecho,la vinculación media y completa combate este comportamiento de percolación al considerar todas las distancias entre dos cúmulos al fusionarlos (mientras que la vinculación única exagera el comportamiento al considerar sólo la distancia más corta entre los cúmulos).El gráfico de conectividad rompe este mecanismo para la vinculación media y completa,haciéndolas parecerse a la vinculación única más frágil.Este efecto es más pronunciado para los gráficos muy escasos (intenta disminuir el número de vecinos en kneighbors_graph)y con vinculación completa.En particular,el hecho de tener un número muy pequeño de vecinos en el gráfico,impone una geometría que se aproxima a la de la unión simple,que es bien conocida por tener esta inestabilidad de percolación.</target>
        </trans-unit>
        <trans-unit id="d90e68437e39bd56831ac8f750d7707399d6fbb2" translate="yes" xml:space="preserve">
          <source>Secondly, the squared loss function is replaced by the unit deviance \(d\) of a distribution in the exponential family (or more precisely, a reproductive exponential dispersion model (EDM) &lt;a href=&quot;#id34&quot; id=&quot;id32&quot;&gt;11&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53553e63fb4cb7ed1ae88d54b317154b9777e613" translate="yes" xml:space="preserve">
          <source>Seconds used for refitting the best model on the whole dataset.</source>
          <target state="translated">Segundos utilizados para reajustar el mejor modelo de todo el conjunto de datos.</target>
        </trans-unit>
        <trans-unit id="a31532b7821dad04a81b3f8844e44fc4c4735bbf" translate="yes" xml:space="preserve">
          <source>Section 3.3 in Christopher M. Bishop: Pattern Recognition and Machine Learning, 2006</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa04a576bd56d584afacdf30a223dc3f1fde4eb3" translate="yes" xml:space="preserve">
          <source>Section 5.4.4, pp. 252-253.</source>
          <target state="translated">Sección 5.4.4,págs.252 y 253.</target>
        </trans-unit>
        <trans-unit id="d4628726ca2b8e9b183e1257c782a69297176123" translate="yes" xml:space="preserve">
          <source>Section contents</source>
          <target state="translated">Contenido de la sección</target>
        </trans-unit>
        <trans-unit id="978feab4a35a4b897d5316b48dac562d3091d0c5" translate="yes" xml:space="preserve">
          <source>See &amp;ldquo;Random Features for Large-Scale Kernel Machines&amp;rdquo; by A. Rahimi and Benjamin Recht.</source>
          <target state="translated">Consulte &amp;ldquo;Funciones aleatorias para m&amp;aacute;quinas de kernel a gran escala&amp;rdquo; de A. Rahimi y Benjamin Recht.</target>
        </trans-unit>
        <trans-unit id="b31673babc80845a872201a18703583634f75350" translate="yes" xml:space="preserve">
          <source>See &amp;ldquo;Random Fourier Approximations for Skewed Multiplicative Histogram Kernels&amp;rdquo; by Fuxin Li, Catalin Ionescu and Cristian Sminchisescu.</source>
          <target state="translated">Consulte &quot;Aproximaciones aleatorias de Fourier para n&amp;uacute;cleos de histogramas multiplicativos sesgados&quot; por Fuxin Li, Catalin Ionescu y Cristian Sminchisescu.</target>
        </trans-unit>
        <trans-unit id="03ac02c3ddabaad90ce0d4962bc965c10cba4eeb" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#r95f74c4622c1-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;, Chapter 4, Section 4.2, for further details regarding the DotProduct kernel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0df8f05c9ec568b4cc1c4d54a3085f0ebf794bd9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#rw2006&quot; id=&quot;id6&quot;&gt;[RW2006]&lt;/a&gt;, pp84 for further details regarding the different variants of the Mat&amp;eacute;rn kernel.</source>
          <target state="translated">Consulte &lt;a href=&quot;#rw2006&quot; id=&quot;id6&quot;&gt;[RW2006]&lt;/a&gt; , p&amp;aacute;g. 84 para obtener m&amp;aacute;s detalles sobre las diferentes variantes del kernel de Mat&amp;eacute;rn.</target>
        </trans-unit>
        <trans-unit id="dc2d327bd01f6b4c26633dc7230267bf2994fc43" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#rw2006&quot; id=&quot;id7&quot;&gt;[RW2006]&lt;/a&gt;, pp84 for further details regarding the different variants of the Mat&amp;eacute;rn kernel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd13548eb92de90d6303ee640236c96cda68888f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#svm-mathematical-formulation&quot;&gt;Mathematical formulation&lt;/a&gt; for a complete description of the decision function.</source>
          <target state="translated">Consulte &lt;a href=&quot;#svm-mathematical-formulation&quot;&gt;Formulaci&amp;oacute;n matem&amp;aacute;tica&lt;/a&gt; para obtener una descripci&amp;oacute;n completa de la funci&amp;oacute;n de decisi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="90eaaa0456af60c46de8c81dc16ee15dad424d81" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/compose/plot_transformed_target#sphx-glr-auto-examples-compose-plot-transformed-target-py&quot;&gt;examples/compose/plot_transformed_target.py&lt;/a&gt;.</source>
          <target state="translated">Vea &lt;a href=&quot;../../auto_examples/compose/plot_transformed_target#sphx-glr-auto-examples-compose-plot-transformed-target-py&quot;&gt;ejemplos / compose / plot_transformed_target.py&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0d70be16f79f29cfb466970ca83989e73f6c00bb" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;examples/linear_model/plot_polynomial_interpolation.py&lt;/a&gt;</source>
          <target state="translated">Ver &lt;a href=&quot;../../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;ejemplos / linear_model / plot_polynomial_interpolation.py&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="66218b0f5237d32e41f01914713a47022cf20bb9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/model_selection/plot_learning_curve#sphx-glr-auto-examples-model-selection-plot-learning-curve-py&quot;&gt;examples/model_selection/plot_learning_curve.py&lt;/a&gt;</source>
          <target state="translated">Ver &lt;a href=&quot;../../auto_examples/model_selection/plot_learning_curve#sphx-glr-auto-examples-model-selection-plot-learning-curve-py&quot;&gt;ejemplos / model_selection / plot_learning_curve.py&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="41261fbeb952dd5951bf36801866ce019db00dde" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/model_selection/plot_validation_curve#sphx-glr-auto-examples-model-selection-plot-validation-curve-py&quot;&gt;Plotting Validation Curves&lt;/a&gt;</source>
          <target state="translated">Consulte &lt;a href=&quot;../../auto_examples/model_selection/plot_validation_curve#sphx-glr-auto-examples-model-selection-plot-validation-curve-py&quot;&gt;Trazado de curvas de validaci&amp;oacute;n&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6a3b0e6c0d79b7c03e9dbb288652a52d5e7d7fd5" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/linear_model#bayesian-ridge-regression&quot;&gt;Bayesian Ridge Regression&lt;/a&gt; for more information on the regressor.</source>
          <target state="translated">Consulte &lt;a href=&quot;../../modules/linear_model#bayesian-ridge-regression&quot;&gt;Regresi&amp;oacute;n de la cresta bayesiana&lt;/a&gt; para obtener m&amp;aacute;s informaci&amp;oacute;n sobre el regresor.</target>
        </trans-unit>
        <trans-unit id="824c64b490bd5bd779a22eec474ba042707228d1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/linear_model#theil-sen-regression&quot;&gt;Theil-Sen estimator: generalized-median-based estimator&lt;/a&gt; for more information on the regressor.</source>
          <target state="translated">Consulte &lt;a href=&quot;../../modules/linear_model#theil-sen-regression&quot;&gt;Estimador de Theil-Sen: estimador basado en la mediana generalizada&lt;/a&gt; para obtener m&amp;aacute;s informaci&amp;oacute;n sobre el regresor.</target>
        </trans-unit>
        <trans-unit id="36bf338f19ee54a0199babdefd0eaf5b203f80f4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/mixture#gmm&quot;&gt;Gaussian mixture models&lt;/a&gt; for more information on the estimator.</source>
          <target state="translated">Consulte &lt;a href=&quot;../../modules/mixture#gmm&quot;&gt;Modelos de mezcla gaussiana&lt;/a&gt; para obtener m&amp;aacute;s informaci&amp;oacute;n sobre el estimador.</target>
        </trans-unit>
        <trans-unit id="bda58af52a4d947e4c6e336facf5860c69c8478b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/tree#tree&quot;&gt;decision tree&lt;/a&gt; for more information on the estimator.</source>
          <target state="translated">Consulte el &lt;a href=&quot;../../modules/tree#tree&quot;&gt;&amp;aacute;rbol de decisiones&lt;/a&gt; para obtener m&amp;aacute;s informaci&amp;oacute;n sobre el estimador.</target>
        </trans-unit>
        <trans-unit id="1876d72641fc6bba23917c9ce1b023a0c5308e82" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;Species distribution modeling&lt;/a&gt; for an example of using ROC to model species distribution.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;Modelado de distribuci&amp;oacute;n de especies&lt;/a&gt; para ver un ejemplo del uso de ROC para modelar la distribuci&amp;oacute;n de especies.</target>
        </trans-unit>
        <trans-unit id="3ca47154d5f58b185be5af00ff9392b2598d6abf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/calibration/plot_calibration#sphx-glr-auto-examples-calibration-plot-calibration-py&quot;&gt;Probability calibration of classifiers&lt;/a&gt; for an example of Brier score loss usage to perform probability calibration of classifiers.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/calibration/plot_calibration#sphx-glr-auto-examples-calibration-plot-calibration-py&quot;&gt;Calibraci&amp;oacute;n de probabilidad de clasificadores&lt;/a&gt; para ver un ejemplo del uso de p&amp;eacute;rdida de puntuaci&amp;oacute;n de Brier para realizar la calibraci&amp;oacute;n de probabilidad de clasificadores.</target>
        </trans-unit>
        <trans-unit id="282928c19fbfe87fe4167148ff3b6058bc018479" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;Recognizing hand-written digits&lt;/a&gt; for an example of classification report usage for hand-written digits.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;Reconocimiento de d&amp;iacute;gitos escritos a mano&lt;/a&gt; para ver un ejemplo del uso del informe de clasificaci&amp;oacute;n para d&amp;iacute;gitos escritos a mano.</target>
        </trans-unit>
        <trans-unit id="72d62eaa2236b9a2dd2c8a6bb04573291c57c36e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;Recognizing hand-written digits&lt;/a&gt; for an example of using a confusion matrix to classify hand-written digits.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;Reconocimiento de d&amp;iacute;gitos escritos a mano&lt;/a&gt; para ver un ejemplo del uso de una matriz de confusi&amp;oacute;n para clasificar d&amp;iacute;gitos escritos a mano.</target>
        </trans-unit>
        <trans-unit id="87880060115f16d38cb34f093520114ae1691683" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit a &lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt;&lt;code&gt;LedoitWolf&lt;/code&gt;&lt;/a&gt; object to data and for visualizing the performances of the Ledoit-Wolf estimator in terms of likelihood.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Estimaci&amp;oacute;n de la covarianza de contracci&amp;oacute;n: LedoitWolf vs OAS y m&amp;aacute;xima verosimilitud&lt;/a&gt; para ver un ejemplo sobre c&amp;oacute;mo ajustar un objeto &lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt; &lt;code&gt;LedoitWolf&lt;/code&gt; &lt;/a&gt; a los datos y para visualizar el rendimiento del estimador Ledoit-Wolf en t&amp;eacute;rminos de probabilidad.</target>
        </trans-unit>
        <trans-unit id="2209166f8c957bd217f6d5f461ba4322d29b02c2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit a &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance&quot;&gt;&lt;code&gt;ShrunkCovariance&lt;/code&gt;&lt;/a&gt; object to data.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Estimaci&amp;oacute;n de covarianza de contracci&amp;oacute;n: LedoitWolf vs OAS y m&amp;aacute;xima verosimilitud&lt;/a&gt; para ver un ejemplo sobre c&amp;oacute;mo ajustar un objeto &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance&quot;&gt; &lt;code&gt;ShrunkCovariance&lt;/code&gt; &lt;/a&gt; a los datos.</target>
        </trans-unit>
        <trans-unit id="88a19b944edc191f5f7b057963b65a4e9112c1b2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit an &lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;EmpiricalCovariance&lt;/code&gt;&lt;/a&gt; object to data.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Estimaci&amp;oacute;n de covarianza de contracci&amp;oacute;n: LedoitWolf vs OAS y m&amp;aacute;xima verosimilitud&lt;/a&gt; para ver un ejemplo sobre c&amp;oacute;mo ajustar un objeto &lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt; &lt;code&gt;EmpiricalCovariance&lt;/code&gt; &lt;/a&gt; a los datos.</target>
        </trans-unit>
        <trans-unit id="8a3f5dc7dd1289a56afbdf19c9d4415f754d0c74" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit an &lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt;&lt;code&gt;OAS&lt;/code&gt;&lt;/a&gt; object to data.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Estimaci&amp;oacute;n de covarianza de contracci&amp;oacute;n: LedoitWolf vs OAS y m&amp;aacute;xima verosimilitud&lt;/a&gt; para ver un ejemplo sobre c&amp;oacute;mo ajustar un objeto &lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt; &lt;code&gt;OAS&lt;/code&gt; &lt;/a&gt; a los datos.</target>
        </trans-unit>
        <trans-unit id="a2ce4b68a58fc4d4775fc307d3337bfc6ba95951" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_lw_vs_oas#sphx-glr-auto-examples-covariance-plot-lw-vs-oas-py&quot;&gt;Ledoit-Wolf vs OAS estimation&lt;/a&gt; to visualize the Mean Squared Error difference between a &lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt;&lt;code&gt;LedoitWolf&lt;/code&gt;&lt;/a&gt; and an &lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt;&lt;code&gt;OAS&lt;/code&gt;&lt;/a&gt; estimator of the covariance.</source>
          <target state="translated">Consulte la &lt;a href=&quot;../auto_examples/covariance/plot_lw_vs_oas#sphx-glr-auto-examples-covariance-plot-lw-vs-oas-py&quot;&gt;estimaci&amp;oacute;n de Ledoit-Wolf vs OAS&lt;/a&gt; para visualizar la diferencia de error cuadr&amp;aacute;tico medio entre un estimador de covarianza de &lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt; &lt;code&gt;LedoitWolf&lt;/code&gt; &lt;/a&gt; y un &lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt; &lt;code&gt;OAS&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="8878b5f91edc950d3f968af54f37c8ec353c6370" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;Robust covariance estimation and Mahalanobis distances relevance&lt;/a&gt; for an illustration of the difference between using a standard (&lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;covariance.EmpiricalCovariance&lt;/code&gt;&lt;/a&gt;) or a robust estimate (&lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt;&lt;code&gt;covariance.MinCovDet&lt;/code&gt;&lt;/a&gt;) of location and covariance to assess the degree of outlyingness of an observation.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;Estimaci&amp;oacute;n robusta de covarianza y relevancia de distancias de Mahalanobis&lt;/a&gt; para obtener una ilustraci&amp;oacute;n de la diferencia entre usar un est&amp;aacute;ndar ( &lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt; &lt;code&gt;covariance.EmpiricalCovariance&lt;/code&gt; &lt;/a&gt; ) o una estimaci&amp;oacute;n s&amp;oacute;lida ( &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt; &lt;code&gt;covariance.MinCovDet&lt;/code&gt; &lt;/a&gt; ) de ubicaci&amp;oacute;n y covarianza para evaluar el grado de at&amp;iacute;pica de una observaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="030742fc8b624a6be4238fb99cd9f5a0e364d687" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;Robust covariance estimation and Mahalanobis distances relevance&lt;/a&gt; to visualize the difference between &lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;EmpiricalCovariance&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt;&lt;code&gt;MinCovDet&lt;/code&gt;&lt;/a&gt; covariance estimators in terms of Mahalanobis distance (so we get a better estimate of the precision matrix too).</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;Estimaci&amp;oacute;n robusta de covarianza y relevancia de distancias de Mahalanobis&lt;/a&gt; para visualizar la diferencia entre los estimadores de covarianza &lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt; &lt;code&gt;EmpiricalCovariance&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt; &lt;code&gt;MinCovDet&lt;/code&gt; &lt;/a&gt; en t&amp;eacute;rminos de distancia de Mahalanobis (para que tambi&amp;eacute;n obtengamos una mejor estimaci&amp;oacute;n de la matriz de precisi&amp;oacute;n).</target>
        </trans-unit>
        <trans-unit id="f9a056a85b47a4a6c1a6d704788263d39761f07a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_robust_vs_empirical_covariance#sphx-glr-auto-examples-covariance-plot-robust-vs-empirical-covariance-py&quot;&gt;Robust vs Empirical covariance estimate&lt;/a&gt; for an example on how to fit a &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt;&lt;code&gt;MinCovDet&lt;/code&gt;&lt;/a&gt; object to data and see how the estimate remains accurate despite the presence of outliers.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/covariance/plot_robust_vs_empirical_covariance#sphx-glr-auto-examples-covariance-plot-robust-vs-empirical-covariance-py&quot;&gt;Estimaci&amp;oacute;n de covarianza robusta frente a emp&amp;iacute;rica&lt;/a&gt; para ver un ejemplo sobre c&amp;oacute;mo ajustar un objeto &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt; &lt;code&gt;MinCovDet&lt;/code&gt; &lt;/a&gt; a los datos y ver c&amp;oacute;mo la estimaci&amp;oacute;n sigue siendo precisa a pesar de la presencia de valores at&amp;iacute;picos.</target>
        </trans-unit>
        <trans-unit id="995b452653e2a34828a53fff1225e032a84a1ed7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/ensemble/plot_gradient_boosting_regression#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py&quot;&gt;Gradient Boosting regression&lt;/a&gt; for an example of mean squared error usage to evaluate gradient boosting regression.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/ensemble/plot_gradient_boosting_regression#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py&quot;&gt;Regresi&amp;oacute;n&lt;/a&gt; de aumento de gradiente para obtener un ejemplo del uso del error cuadr&amp;aacute;tico medio para evaluar la regresi&amp;oacute;n de aumento de gradiente.</target>
        </trans-unit>
        <trans-unit id="c70bb54b9f9c6d372a94de7482636d40519b333f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/ensemble/plot_isolation_forest#sphx-glr-auto-examples-ensemble-plot-isolation-forest-py&quot;&gt;IsolationForest example&lt;/a&gt; for an illustration of the use of IsolationForest.</source>
          <target state="translated">Consulte el &lt;a href=&quot;../auto_examples/ensemble/plot_isolation_forest#sphx-glr-auto-examples-ensemble-plot-isolation-forest-py&quot;&gt;ejemplo de IsolationForest&lt;/a&gt; para ver una ilustraci&amp;oacute;n del uso de IsolationForest.</target>
        </trans-unit>
        <trans-unit id="462e8cdc93001fb7a3648b1195482e1f8b22fe44" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/feature_selection/plot_permutation_test_for_classification#sphx-glr-auto-examples-feature-selection-plot-permutation-test-for-classification-py&quot;&gt;Test with permutations the significance of a classification score&lt;/a&gt; for an example of accuracy score usage using permutations of the dataset.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/feature_selection/plot_permutation_test_for_classification#sphx-glr-auto-examples-feature-selection-plot-permutation-test-for-classification-py&quot;&gt;Probar con permutaciones la importancia de una puntuaci&amp;oacute;n de clasificaci&amp;oacute;n&lt;/a&gt; para obtener un ejemplo del uso de la puntuaci&amp;oacute;n de precisi&amp;oacute;n mediante permutaciones del conjunto de datos.</target>
        </trans-unit>
        <trans-unit id="39b73a8956b97e37d2a1a56a5487c771ec6755e2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/feature_selection/plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;Recursive feature elimination with cross-validation&lt;/a&gt; for an example of zero one loss usage to perform recursive feature elimination with cross-validation.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/feature_selection/plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;Eliminaci&amp;oacute;n de caracter&amp;iacute;sticas recursivas con validaci&amp;oacute;n cruzada&lt;/a&gt; para ver un ejemplo de uso de cero una p&amp;eacute;rdida para realizar la eliminaci&amp;oacute;n de caracter&amp;iacute;sticas recursivas con validaci&amp;oacute;n cruzada.</target>
        </trans-unit>
        <trans-unit id="92f30204fbfed37d4520688e6847c0f1dec6d444" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/linear_model/plot_lasso_and_elasticnet#sphx-glr-auto-examples-linear-model-plot-lasso-and-elasticnet-py&quot;&gt;Lasso and Elastic Net for Sparse Signals&lt;/a&gt; for an example of R&amp;sup2; score usage to evaluate Lasso and Elastic Net on sparse signals.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/linear_model/plot_lasso_and_elasticnet#sphx-glr-auto-examples-linear-model-plot-lasso-and-elasticnet-py&quot;&gt;Lasso y Elastic Net para se&amp;ntilde;ales dispersas&lt;/a&gt; para ver un ejemplo del uso de la puntuaci&amp;oacute;n R&amp;sup2; para evaluar Lasso y Elastic Net en se&amp;ntilde;ales dispersas.</target>
        </trans-unit>
        <trans-unit id="01a78f9ef24e4fc8896bfa27a1c142f94096fbf4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;Polynomial interpolation&lt;/a&gt; for Ridge regression using created polynomial features.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;Interpolaci&amp;oacute;n de polinomios&lt;/a&gt; para la regresi&amp;oacute;n de crestas utilizando caracter&amp;iacute;sticas polinomiales creadas.</target>
        </trans-unit>
        <trans-unit id="6cc1903f7fccc8472139b491e9c35281e331be73" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/manifold/plot_compare_methods#sphx-glr-auto-examples-manifold-plot-compare-methods-py&quot;&gt;Comparison of Manifold Learning methods&lt;/a&gt; for an example of dimensionality reduction on a toy &amp;ldquo;S-curve&amp;rdquo; dataset.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/manifold/plot_compare_methods#sphx-glr-auto-examples-manifold-plot-compare-methods-py&quot;&gt;Comparaci&amp;oacute;n de m&amp;eacute;todos de aprendizaje m&amp;uacute;ltiple&lt;/a&gt; para ver un ejemplo de reducci&amp;oacute;n de dimensionalidad en un conjunto de datos de &quot;curva S&quot; de juguete.</target>
        </trans-unit>
        <trans-unit id="c13f7bab27de634fe8533a5ffc3f4d5d442fb940" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/manifold/plot_lle_digits#sphx-glr-auto-examples-manifold-plot-lle-digits-py&quot;&gt;Manifold learning on handwritten digits: Locally Linear Embedding, Isomap&amp;hellip;&lt;/a&gt; for an example of dimensionality reduction on handwritten digits.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/manifold/plot_lle_digits#sphx-glr-auto-examples-manifold-plot-lle-digits-py&quot;&gt;Aprendizaje m&amp;uacute;ltiple en d&amp;iacute;gitos escritos a mano: incrustaci&amp;oacute;n lineal local, Isomap ...&lt;/a&gt; para ver un ejemplo de reducci&amp;oacute;n de dimensionalidad en d&amp;iacute;gitos escritos a mano.</target>
        </trans-unit>
        <trans-unit id="2a32db7a757930b4f797df7e8d06a3cd21abcff6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/miscellaneous/plot_anomaly_comparison#sphx-glr-auto-examples-miscellaneous-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison of &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt; with &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt; (tuned to perform like an outlier detection method) and a covariance-based outlier detection with &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt;&lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43f0e98d020880753d56a5cecd019501b6cb864a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/miscellaneous/plot_anomaly_comparison#sphx-glr-auto-examples-miscellaneous-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison of the &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt;, the &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt;, the &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt;&lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="add8ccecfab3f9c846b3f2682673366366734b83" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/miscellaneous/plot_anomaly_comparison#sphx-glr-auto-examples-miscellaneous-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison with other anomaly detection methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cee09c79ab5ccf2f8ea1b726ccad8beb5f01cbf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/miscellaneous/plot_johnson_lindenstrauss_bound#sphx-glr-auto-examples-miscellaneous-plot-johnson-lindenstrauss-bound-py&quot;&gt;The Johnson-Lindenstrauss bound for embedding with random projections&lt;/a&gt; for a theoretical explication on the Johnson-Lindenstrauss lemma and an empirical validation using sparse random matrices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba387b296d0109ccfdd27d435e72e0bda0b98a94" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_concentration_prior#sphx-glr-auto-examples-mixture-plot-concentration-prior-py&quot;&gt;Concentration Prior Type Analysis of Variation Bayesian Gaussian Mixture&lt;/a&gt; for an example plotting the confidence ellipsoids for the &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt; with different &lt;code&gt;weight_concentration_prior_type&lt;/code&gt; for different values of the parameter &lt;code&gt;weight_concentration_prior&lt;/code&gt;.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/mixture/plot_concentration_prior#sphx-glr-auto-examples-mixture-plot-concentration-prior-py&quot;&gt;An&amp;aacute;lisis de tipo previo de concentraci&amp;oacute;n de la mezcla Bayesiana Gaussiana de variaci&amp;oacute;n&lt;/a&gt; para ver un ejemplo que traza los elipsoides de confianza para la &lt;code&gt;weight_concentration_prior_type&lt;/code&gt; &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt; &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; &lt;/a&gt; con diferente weight_concentration_prior_type para diferentes valores del par&amp;aacute;metro &lt;code&gt;weight_concentration_prior&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="17317cd9be65f918f2c9598fbac39ad346f5db56" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm#sphx-glr-auto-examples-mixture-plot-gmm-py&quot;&gt;Gaussian Mixture Model Ellipsoids&lt;/a&gt; for an example on plotting the confidence ellipsoids for both &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt;&lt;code&gt;GaussianMixture&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/mixture/plot_gmm#sphx-glr-auto-examples-mixture-plot-gmm-py&quot;&gt;Elipsoides del modelo de mezcla gaussiana&lt;/a&gt; para obtener un ejemplo sobre c&amp;oacute;mo trazar los elipsoides de confianza tanto para &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt; &lt;code&gt;GaussianMixture&lt;/code&gt; &lt;/a&gt; como &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt; &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="a5877cbb374e3dc33496a562d7ff812fdb5db635" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm_covariances#sphx-glr-auto-examples-mixture-plot-gmm-covariances-py&quot;&gt;GMM covariances&lt;/a&gt; for an example of using the Gaussian mixture as clustering on the iris dataset.</source>
          <target state="translated">Consulte las &lt;a href=&quot;../auto_examples/mixture/plot_gmm_covariances#sphx-glr-auto-examples-mixture-plot-gmm-covariances-py&quot;&gt;covarianzas de GMM&lt;/a&gt; para ver un ejemplo del uso de la mezcla gaussiana como agrupaci&amp;oacute;n en el conjunto de datos del iris.</target>
        </trans-unit>
        <trans-unit id="235746c777e5faff74a54e9f92e2aa47946dcca8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm_pdf#sphx-glr-auto-examples-mixture-plot-gmm-pdf-py&quot;&gt;Density Estimation for a Gaussian mixture&lt;/a&gt; for an example on plotting the density estimation.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/mixture/plot_gmm_pdf#sphx-glr-auto-examples-mixture-plot-gmm-pdf-py&quot;&gt;Estimaci&amp;oacute;n de densidad para una mezcla gaussiana&lt;/a&gt; para ver un ejemplo sobre c&amp;oacute;mo trazar la estimaci&amp;oacute;n de densidad.</target>
        </trans-unit>
        <trans-unit id="1f45342ed85fb843511e05db7aa53da9e05cd4c8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm_selection#sphx-glr-auto-examples-mixture-plot-gmm-selection-py&quot;&gt;Gaussian Mixture Model Selection&lt;/a&gt; for an example of model selection performed with classical Gaussian mixture.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/mixture/plot_gmm_selection#sphx-glr-auto-examples-mixture-plot-gmm-selection-py&quot;&gt;Selecci&amp;oacute;n del modelo de mezcla gaussiana&lt;/a&gt; para ver un ejemplo de la selecci&amp;oacute;n del modelo realizada con la mezcla gaussiana cl&amp;aacute;sica.</target>
        </trans-unit>
        <trans-unit id="2675c64adf13cc79a9b07f8da3e0d3af0522fc69" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;Sample pipeline for text feature extraction and evaluation&lt;/a&gt; for an example of Grid Search coupling parameters from a text documents feature extractor (n-gram count vectorizer and TF-IDF transformer) with a classifier (here a linear SVM trained with SGD with either elastic net or L2 penalty) using a &lt;code&gt;pipeline.Pipeline&lt;/code&gt; instance.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;Canal de muestra para la extracci&amp;oacute;n y evaluaci&amp;oacute;n de caracter&amp;iacute;sticas de texto&lt;/a&gt; para obtener un ejemplo de los par&amp;aacute;metros de acoplamiento de b&amp;uacute;squeda de cuadr&amp;iacute;cula de un extractor de caracter&amp;iacute;sticas de documentos de texto (vectorizador de conteo de n-gramos y transformador TF-IDF) con un clasificador (aqu&amp;iacute;, un SVM lineal entrenado con SGD con una red el&amp;aacute;stica o penalizaci&amp;oacute;n L2) utilizando una instancia de &lt;code&gt;pipeline.Pipeline&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="da92f3b35d742326e0c71721384ca2aaccbfcbb6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_confusion_matrix#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py&quot;&gt;Confusion matrix&lt;/a&gt; for an example of using a confusion matrix to evaluate classifier output quality.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/model_selection/plot_confusion_matrix#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py&quot;&gt;Matriz de confusi&amp;oacute;n&lt;/a&gt; para ver un ejemplo del uso de una matriz de confusi&amp;oacute;n para evaluar la calidad de salida del clasificador.</target>
        </trans-unit>
        <trans-unit id="de7b9e4f40b1dbfe2688a95ace15280b606fa175" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Parameter estimation using grid search with cross-validation&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.metrics.precision_score#sklearn.metrics.precision_score&quot;&gt;&lt;code&gt;precision_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.recall_score#sklearn.metrics.recall_score&quot;&gt;&lt;code&gt;recall_score&lt;/code&gt;&lt;/a&gt; usage to estimate parameters using grid search with nested cross-validation.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Estimaci&amp;oacute;n de par&amp;aacute;metros mediante la b&amp;uacute;squeda de cuadr&amp;iacute;cula con validaci&amp;oacute;n cruzada&lt;/a&gt; para ver un ejemplo del uso de &lt;a href=&quot;generated/sklearn.metrics.precision_score#sklearn.metrics.precision_score&quot;&gt; &lt;code&gt;precision_score&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.metrics.recall_score#sklearn.metrics.recall_score&quot;&gt; &lt;code&gt;recall_score&lt;/code&gt; &lt;/a&gt; para estimar los par&amp;aacute;metros mediante la b&amp;uacute;squeda de cuadr&amp;iacute;cula con validaci&amp;oacute;n cruzada anidada.</target>
        </trans-unit>
        <trans-unit id="907fb39fc7f1b14d7a7b9cc2b05542f6688793e4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Parameter estimation using grid search with cross-validation&lt;/a&gt; for an example of Grid Search computation on the digits dataset.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Estimaci&amp;oacute;n de par&amp;aacute;metros mediante b&amp;uacute;squeda de cuadr&amp;iacute;cula con validaci&amp;oacute;n cruzada&lt;/a&gt; para ver un ejemplo de c&amp;aacute;lculo de b&amp;uacute;squeda de cuadr&amp;iacute;cula en el conjunto de datos de d&amp;iacute;gitos.</target>
        </trans-unit>
        <trans-unit id="400cd83fcd5e25dceebfea56b549d5be061f5ba4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Parameter estimation using grid search with cross-validation&lt;/a&gt; for an example of classification report usage for grid search with nested cross-validation.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Estimaci&amp;oacute;n de par&amp;aacute;metros mediante la b&amp;uacute;squeda de cuadr&amp;iacute;cula con validaci&amp;oacute;n cruzada&lt;/a&gt; para ver un ejemplo del uso de informes de clasificaci&amp;oacute;n para la b&amp;uacute;squeda de cuadr&amp;iacute;cula con validaci&amp;oacute;n cruzada anidada.</target>
        </trans-unit>
        <trans-unit id="588e2a7cc51b06cfa971b7f26bd8bf4053207cf1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_refit_callable#sphx-glr-auto-examples-model-selection-plot-grid-search-refit-callable-py&quot;&gt;Balance model complexity and cross-validated score&lt;/a&gt; for an example of using &lt;code&gt;refit=callable&lt;/code&gt; interface in &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt;. The example shows how this interface adds certain amount of flexibility in identifying the &amp;ldquo;best&amp;rdquo; estimator. This interface can also be used in multiple metrics evaluation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2735aad85c6c7c554984533b716de0827c908e17" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; being used to evaluate multiple metrics simultaneously.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;Demostraci&amp;oacute;n de la evaluaci&amp;oacute;n multim&amp;eacute;trica en cross_val_score y GridSearchCV&lt;/a&gt; para ver un ejemplo de &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt; se utiliza para evaluar varias m&amp;eacute;tricas simult&amp;aacute;neamente.</target>
        </trans-unit>
        <trans-unit id="c2ffbe0f12938b51592ad9e927a7d22caaeca8af" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV&lt;/a&gt; for an example usage.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;Demostraci&amp;oacute;n de la evaluaci&amp;oacute;n multim&amp;eacute;trica en cross_val_score y GridSearchCV&lt;/a&gt; para ver un ejemplo de uso.</target>
        </trans-unit>
        <trans-unit id="8476e4237a00d9dd8e2ca35734caeb2c23a0697e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_nested_cross_validation_iris#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py&quot;&gt;Nested versus non-nested cross-validation&lt;/a&gt; for an example of Grid Search within a cross validation loop on the iris dataset. This is the best practice for evaluating the performance of a model with grid search.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/model_selection/plot_nested_cross_validation_iris#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py&quot;&gt;Validaci&amp;oacute;n cruzada anidada versus no anidada&lt;/a&gt; para ver un ejemplo de b&amp;uacute;squeda de cuadr&amp;iacute;cula dentro de un ciclo de validaci&amp;oacute;n cruzada en el conjunto de datos de iris. Esta es la mejor pr&amp;aacute;ctica para evaluar el rendimiento de un modelo con b&amp;uacute;squeda de cuadr&amp;iacute;cula.</target>
        </trans-unit>
        <trans-unit id="e8dfb2ba828b857661aeb6d59ff74f5c4db05d22" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_precision_recall#sphx-glr-auto-examples-model-selection-plot-precision-recall-py&quot;&gt;Precision-Recall&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt;&lt;code&gt;precision_recall_curve&lt;/code&gt;&lt;/a&gt; usage to evaluate classifier output quality.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/model_selection/plot_precision_recall#sphx-glr-auto-examples-model-selection-plot-precision-recall-py&quot;&gt;Precision-Recall&lt;/a&gt; para ver un ejemplo del uso de &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt; &lt;code&gt;precision_recall_curve&lt;/code&gt; &lt;/a&gt; para evaluar la calidad de salida del clasificador.</target>
        </trans-unit>
        <trans-unit id="7914d54070b906eba7716c438acf436730af131e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_roc#sphx-glr-auto-examples-model-selection-plot-roc-py&quot;&gt;Receiver Operating Characteristic (ROC)&lt;/a&gt; for an example of using ROC to evaluate the quality of the output of a classifier.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/model_selection/plot_roc#sphx-glr-auto-examples-model-selection-plot-roc-py&quot;&gt;la Caracter&amp;iacute;stica de funcionamiento del receptor (ROC)&lt;/a&gt; para ver un ejemplo del uso de ROC para evaluar la calidad de la salida de un clasificador.</target>
        </trans-unit>
        <trans-unit id="61240d29f349f145d4e8cf44909bfb9cc2f016b2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_roc_crossval#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py&quot;&gt;Receiver Operating Characteristic (ROC) with cross validation&lt;/a&gt; for an example of using ROC to evaluate classifier output quality, using cross-validation.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/model_selection/plot_roc_crossval#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py&quot;&gt;Receptor Operating Characteristic (ROC) con validaci&amp;oacute;n cruzada&lt;/a&gt; para ver un ejemplo de c&amp;oacute;mo utilizar ROC para evaluar la calidad de salida del clasificador, mediante la validaci&amp;oacute;n cruzada.</target>
        </trans-unit>
        <trans-unit id="2194fe880eec73b4ed37b8700c0f77c050a462fc" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/neighbors/plot_lof_outlier_detection#sphx-glr-auto-examples-neighbors-plot-lof-outlier-detection-py&quot;&gt;Outlier detection with Local Outlier Factor (LOF)&lt;/a&gt; for an illustration of the use of &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/neighbors/plot_lof_outlier_detection#sphx-glr-auto-examples-neighbors-plot-lof-outlier-detection-py&quot;&gt;Detecci&amp;oacute;n de valores at&amp;iacute;picos con factor de valor at&amp;iacute;pico local (LOF)&lt;/a&gt; para obtener una ilustraci&amp;oacute;n del uso de &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="bb13fcb17f205551a70f65831a46478e0af0f276" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison of &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt; with &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt; (tuned to perform like an outlier detection method) and a covariance-based outlier detection with &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt;&lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Comparaci&amp;oacute;n de algoritmos de detecci&amp;oacute;n de anomal&amp;iacute;as para la detecci&amp;oacute;n de valores at&amp;iacute;picos en conjuntos&lt;/a&gt; de datos de juguetes para obtener una comparaci&amp;oacute;n de &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt; &lt;code&gt;ensemble.IsolationForest&lt;/code&gt; &lt;/a&gt; con &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;svm.OneClassSVM&lt;/code&gt; &lt;/a&gt; (ajustado para funcionar como un m&amp;eacute;todo de detecci&amp;oacute;n de valores at&amp;iacute;picos) y una detecci&amp;oacute;n de valores at&amp;iacute;picos basada en &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt; &lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt; &lt;/a&gt; con covariance.EllipticEnvelope .</target>
        </trans-unit>
        <trans-unit id="64196936345ba93c97149a5b0ef386464e9766b9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison of the &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt;, the &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt;, the &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt;&lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Comparaci&amp;oacute;n de algoritmos de detecci&amp;oacute;n de anomal&amp;iacute;as para la detecci&amp;oacute;n de valores at&amp;iacute;picos en conjuntos&lt;/a&gt; de datos de juguetes para obtener una comparaci&amp;oacute;n del &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;svm.OneClassSVM&lt;/code&gt; &lt;/a&gt; , el &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt; &lt;code&gt;ensemble.IsolationForest&lt;/code&gt; &lt;/a&gt; , los &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt; &lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="34db9fa5546a4563c9e371d735571ffbe05f0c7c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison with other anomaly detection methods.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Comparaci&amp;oacute;n de algoritmos de detecci&amp;oacute;n de anomal&amp;iacute;as para la detecci&amp;oacute;n de valores at&amp;iacute;picos en conjuntos&lt;/a&gt; de datos de juguetes para obtener una comparaci&amp;oacute;n con otros m&amp;eacute;todos de detecci&amp;oacute;n de anomal&amp;iacute;as.</target>
        </trans-unit>
        <trans-unit id="624945e6b02bb2ff2c43f28f85ed4813c5cbe96d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_johnson_lindenstrauss_bound#sphx-glr-auto-examples-plot-johnson-lindenstrauss-bound-py&quot;&gt;The Johnson-Lindenstrauss bound for embedding with random projections&lt;/a&gt; for a theoretical explication on the Johnson-Lindenstrauss lemma and an empirical validation using sparse random matrices.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/plot_johnson_lindenstrauss_bound#sphx-glr-auto-examples-plot-johnson-lindenstrauss-bound-py&quot;&gt;El enlace de Johnson-Lindenstrauss para incrustar con proyecciones aleatorias&lt;/a&gt; para obtener una explicaci&amp;oacute;n te&amp;oacute;rica sobre el lema de Johnson-Lindenstrauss y una validaci&amp;oacute;n emp&amp;iacute;rica utilizando matrices aleatorias dispersas.</target>
        </trans-unit>
        <trans-unit id="9ca7b8e34286a27914e5e700a286fbed9102f4af" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/svm/plot_oneclass#sphx-glr-auto-examples-svm-plot-oneclass-py&quot;&gt;One-class SVM with non-linear kernel (RBF)&lt;/a&gt; for visualizing the frontier learned around some data by a &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/svm/plot_oneclass#sphx-glr-auto-examples-svm-plot-oneclass-py&quot;&gt;SVM de una clase con kernel no lineal (RBF)&lt;/a&gt; para visualizar la frontera aprendida alrededor de algunos datos mediante un objeto &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;svm.OneClassSVM&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="76c663b6a0471e4c53ba854f9c09becf8ef59fc7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Classification of text documents using sparse features&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt;&lt;code&gt;f1_score&lt;/code&gt;&lt;/a&gt; usage to classify text documents.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Clasificaci&amp;oacute;n de documentos de texto con caracter&amp;iacute;sticas dispersas&lt;/a&gt; para ver un ejemplo del uso de &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt; &lt;code&gt;f1_score&lt;/code&gt; &lt;/a&gt; para clasificar documentos de texto.</target>
        </trans-unit>
        <trans-unit id="188cc26ffe635b802535768a1802c77d30908617" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Classification of text documents using sparse features&lt;/a&gt; for an example of classification report usage for text documents.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Clasificaci&amp;oacute;n de documentos de texto con funciones dispersas&lt;/a&gt; para ver un ejemplo del uso de informes de clasificaci&amp;oacute;n para documentos de texto.</target>
        </trans-unit>
        <trans-unit id="19118774a723324b6225f3d83bcf9761f94d3619" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Classification of text documents using sparse features&lt;/a&gt; for an example of using a confusion matrix to classify text documents.</source>
          <target state="translated">Consulte &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Clasificaci&amp;oacute;n de documentos de texto con funciones dispersas&lt;/a&gt; para ver un ejemplo del uso de una matriz de confusi&amp;oacute;n para clasificar documentos de texto.</target>
        </trans-unit>
        <trans-unit id="81a2b2d1fb5035ca6b501c666e8a41c6286b60de" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../grid_search#multimetric-grid-search&quot;&gt;Specifying multiple metrics for evaluation&lt;/a&gt; for an example.</source>
          <target state="translated">Consulte &lt;a href=&quot;../grid_search#multimetric-grid-search&quot;&gt;Especificaci&amp;oacute;n de varias m&amp;eacute;tricas para evaluaci&amp;oacute;n&lt;/a&gt; para ver un ejemplo.</target>
        </trans-unit>
        <trans-unit id="479250f0ad90f3ce8d5fd16594b9c17af606dc2c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../neighbors#neighbors&quot;&gt;Nearest Neighbors&lt;/a&gt; in the online documentation for a discussion of the choice of &lt;code&gt;algorithm&lt;/code&gt; and &lt;code&gt;leaf_size&lt;/code&gt;.</source>
          <target state="translated">Consulte &lt;a href=&quot;../neighbors#neighbors&quot;&gt;Vecinos m&amp;aacute;s cercanos&lt;/a&gt; en la documentaci&amp;oacute;n en l&amp;iacute;nea para obtener m&amp;aacute;s informaci&amp;oacute;n sobre la elecci&amp;oacute;n del &lt;code&gt;algorithm&lt;/code&gt; y el &lt;code&gt;leaf_size&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="91bb5f21ad92edefb7cd46dcdff8e31af1c98298" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../tree#minimal-cost-complexity-pruning&quot;&gt;Minimal Cost-Complexity Pruning&lt;/a&gt; for details on the pruning process.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91032a83e07b0024745974d4bc72e492c7c9e85a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;compose#combining-estimators&quot;&gt;Pipelines and composite estimators&lt;/a&gt;.</source>
          <target state="translated">Consulte &lt;a href=&quot;compose#combining-estimators&quot;&gt;Pipelines y estimadores compuestos&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="516b0abd274bf0e8eb7951cfd8d017257e70560d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;feature_extraction#dict-feature-extraction&quot;&gt;Loading features from dicts&lt;/a&gt; for categorical features that are represented as a dict, not as scalars.</source>
          <target state="translated">Consulte &lt;a href=&quot;feature_extraction#dict-feature-extraction&quot;&gt;Carga de caracter&amp;iacute;sticas de dictados&lt;/a&gt; para ver caracter&amp;iacute;sticas categ&amp;oacute;ricas que se representan como un dictado, no como escalares.</target>
        </trans-unit>
        <trans-unit id="5f5bdda151c122a6b0f331c022a3fe3419eba6e8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits&quot;&gt;here&lt;/a&gt; for more information about this dataset.</source>
          <target state="translated">Consulte &lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits&quot;&gt;aqu&amp;iacute;&lt;/a&gt; para obtener m&amp;aacute;s informaci&amp;oacute;n sobre este conjunto de datos.</target>
        </trans-unit>
        <trans-unit id="59cc7550d6ebef4a36dc7cbd048f831a5c0d0f3a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&quot;&gt;http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&lt;/a&gt;</source>
          <target state="translated">Ver &lt;a href=&quot;http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&quot;&gt;http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="58869cd4ecac8051c9d79dfaa9dbb2a543b85dfe" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;http://www.robots.ox.ac.uk/~vedaldi/assets/pubs/vedaldi11efficient.pdf&quot;&gt;&amp;ldquo;Efficient additive kernels via explicit feature maps&amp;rdquo;&lt;/a&gt; A. Vedaldi and A. Zisserman, Pattern Analysis and Machine Intelligence, 2011</source>
          <target state="translated">Consulte &lt;a href=&quot;http://www.robots.ox.ac.uk/~vedaldi/assets/pubs/vedaldi11efficient.pdf&quot;&gt;&quot;N&amp;uacute;cleos aditivos eficientes mediante mapas de caracter&amp;iacute;sticas expl&amp;iacute;citas&quot;&lt;/a&gt; A. Vedaldi y A. Zisserman, Pattern Analysis and Machine Intelligence, 2011</target>
        </trans-unit>
        <trans-unit id="8ccf3f09b07311e149a69a4c5ed81e792cfab2aa" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits&quot;&gt;here&lt;/a&gt; for more information about this dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4bdca7573215dd8d9f679d272cb9da9a534f1291" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;here&lt;/a&gt; for more information on this dataset.</source>
          <target state="translated">Consulte &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;aqu&amp;iacute;&lt;/a&gt; para obtener m&amp;aacute;s informaci&amp;oacute;n sobre este conjunto de datos.</target>
        </trans-unit>
        <trans-unit id="eb3a5aff676c4d5166ca0015430772938f3b0abf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee1e742783ffe82079419a7f74e91fb7300f9192" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&quot;&gt;https://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7191cbc48e1c8b07d612d6ecdb398fe05677ce16" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;The scoring parameter: defining model evaluation rules&lt;/a&gt; for details. In the case of the Iris dataset, the samples are balanced across target classes hence the accuracy and the F1-score are almost equal.</source>
          <target state="translated">Consulte &lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;El par&amp;aacute;metro de puntuaci&amp;oacute;n: definici&amp;oacute;n de reglas de evaluaci&amp;oacute;n del modelo&lt;/a&gt; para obtener m&amp;aacute;s detalles. En el caso del conjunto de datos Iris, las muestras est&amp;aacute;n equilibradas entre las clases objetivo, por lo que la precisi&amp;oacute;n y la puntuaci&amp;oacute;n F1 son casi iguales.</target>
        </trans-unit>
        <trans-unit id="e083d29e5fc318a8e4c7186d224d71159333e317" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;outlier_detection#outlier-detection&quot;&gt;Novelty and Outlier Detection&lt;/a&gt; for the description and usage of OneClassSVM.</source>
          <target state="translated">Consulte &lt;a href=&quot;outlier_detection#outlier-detection&quot;&gt;Detecci&amp;oacute;n de novedades y valores at&amp;iacute;picos&lt;/a&gt; para obtener una descripci&amp;oacute;n y el uso de OneClassSVM.</target>
        </trans-unit>
        <trans-unit id="2bf27f073ae6fdc435309a3de7aa195bb3e33f73" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;predict_proba&lt;/code&gt; for details.</source>
          <target state="translated">Consulte &lt;code&gt;predict_proba&lt;/code&gt; para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="9a6c19ee072204bfa0caf7b0899caf92ad1a79e0" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;refit&lt;/code&gt; parameter for more information on allowed values.</source>
          <target state="translated">Consulte el par&amp;aacute;metro de &lt;code&gt;refit&lt;/code&gt; para obtener m&amp;aacute;s informaci&amp;oacute;n sobre los valores permitidos.</target>
        </trans-unit>
        <trans-unit id="fcd84460747232330056c00c1a39fd6ed47410b5" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;scoring&lt;/code&gt; parameter to know more about multiple metric evaluation.</source>
          <target state="translated">Consulte el par&amp;aacute;metro de &lt;code&gt;scoring&lt;/code&gt; para obtener m&amp;aacute;s informaci&amp;oacute;n sobre la evaluaci&amp;oacute;n de m&amp;eacute;tricas m&amp;uacute;ltiples.</target>
        </trans-unit>
        <trans-unit id="61a08f389a25b863d0fca5015a2885ff6fd5c8cd" translate="yes" xml:space="preserve">
          <source>See Also:</source>
          <target state="translated">Ver también:</target>
        </trans-unit>
        <trans-unit id="dd75486b56d3a12e77b37b7ce59de88eb8618b01" translate="yes" xml:space="preserve">
          <source>See Rasmussen and Williams 2006, pp84 for details regarding the different variants of the Matern kernel.</source>
          <target state="translated">Véase Rasmussen y Williams 2006,pág.84,para detalles sobre las diferentes variantes del núcleo de la Matern.</target>
        </trans-unit>
        <trans-unit id="2d8243a2c0e464492c9d563c4f92c56ae3421bcc" translate="yes" xml:space="preserve">
          <source>See also</source>
          <target state="translated">Ver también</target>
        </trans-unit>
        <trans-unit id="319ca132af6f206834626d4c0565d67f882f0bf4" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;../../modules/tree#minimal-cost-complexity-pruning&quot;&gt;Minimal Cost-Complexity Pruning&lt;/a&gt; for details on pruning.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eddd8dfbe32e6e27a2f2d9692940c76ecde49164" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;neighbors#nca-dim-reduction&quot;&gt;Dimensionality reduction&lt;/a&gt; for dimensionality reduction with Neighborhood Components Analysis.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16d6db1c15da7e05f275e12f2b52c16bcc8dc1f7" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;plot_permutation_importance#sphx-glr-auto-examples-inspection-plot-permutation-importance-py&quot;&gt;Permutation Importance vs Random Forest Feature Importance (MDI)&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00556fb4b47eda5d6ddfa3723da8312c58733ada" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;Recursive feature elimination with cross-validation&lt;/a&gt;</source>
          <target state="translated">Consulte tambi&amp;eacute;n &lt;a href=&quot;plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;Eliminaci&amp;oacute;n de caracter&amp;iacute;sticas recursivas con validaci&amp;oacute;n cruzada&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9232d9babf570066106c095c7f9e14cb2421acee" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;plot_roc_curve_visualization_api#sphx-glr-auto-examples-miscellaneous-plot-roc-curve-visualization-api-py&quot;&gt;ROC Curve with Visualization API&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="371a87eafb4de078ff674d69a5a89c186532eb49" translate="yes" xml:space="preserve">
          <source>See also:</source>
          <target state="translated">Ver también:</target>
        </trans-unit>
        <trans-unit id="bbbf1c8bb1bb44153dbb121ba5ff682161041559" translate="yes" xml:space="preserve">
          <source>See also: 1988 MLC Proceedings, 54-64. Cheeseman et al&amp;rdquo;s AUTOCLASS II conceptual clustering system finds 3 classes in the data.</source>
          <target state="translated">V&amp;eacute;ase tambi&amp;eacute;n: Actas del MLC de 1988, 54-64. El sistema de agrupamiento conceptual AUTOCLASS II de Cheeseman et al encuentra 3 clases en los datos.</target>
        </trans-unit>
        <trans-unit id="96949ffbfe0e5b8e858a6b32bba0567fa5dcf8f9" translate="yes" xml:space="preserve">
          <source>See glossary entry for &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-cross-validation-estimator&quot;&gt;cross-validation estimator&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ce8930e7f553fab96c5eb4cdba6059705f0a1b9" translate="yes" xml:space="preserve">
          <source>See section &lt;a href=&quot;preprocessing#preprocessing&quot;&gt;Preprocessing data&lt;/a&gt; for more details on scaling and normalization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b55a2c7dcbc914b3c4abb672c6103792d08facf" translate="yes" xml:space="preserve">
          <source>See sklearn.svm.predict for a complete list of parameters.</source>
          <target state="translated">Ver sklearn.svm.predict para una lista completa de parámetros.</target>
        </trans-unit>
        <trans-unit id="8c30624bfa9869c6a4a63a1b052f17576abbc1b5" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;../../auto_examples/applications/svm_gui#sphx-glr-auto-examples-applications-svm-gui-py&quot;&gt;SVM GUI&lt;/a&gt; to download &lt;code&gt;svm_gui.py&lt;/code&gt;; add data points of both classes with right and left button, fit the model and change parameters and data.</source>
          <target state="translated">Consulte la &lt;a href=&quot;../../auto_examples/applications/svm_gui#sphx-glr-auto-examples-applications-svm-gui-py&quot;&gt;GUI de SVM&lt;/a&gt; para descargar &lt;code&gt;svm_gui.py&lt;/code&gt; ; agregue puntos de datos de ambas clases con el bot&amp;oacute;n derecho e izquierdo, ajuste el modelo y cambie los par&amp;aacute;metros y los datos.</target>
        </trans-unit>
        <trans-unit id="3a7904b44fb635dd1b8e25248a204eaa4fae3a1b" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;biclustering#biclustering-evaluation&quot;&gt;Biclustering evaluation&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">Consulte la secci&amp;oacute;n de &lt;a href=&quot;biclustering#biclustering-evaluation&quot;&gt;evaluaci&amp;oacute;n de Biclustering&lt;/a&gt; de la gu&amp;iacute;a del usuario para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="68bd165827c5ef6d955b9032ff7e059af8a91538" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;clustering#clustering-evaluation&quot;&gt;Clustering performance evaluation&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">Consulte la secci&amp;oacute;n de &lt;a href=&quot;clustering#clustering-evaluation&quot;&gt;evaluaci&amp;oacute;n del rendimiento de&lt;/a&gt; la agrupaci&amp;oacute;n en cl&amp;uacute;steres de la gu&amp;iacute;a del usuario para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="32e5d32ee9a61e6d932c5ca6a73a2f56a975703b" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;https://scikit-learn.org/0.23/visualizations.html#visualizations&quot;&gt;Visualizations&lt;/a&gt; section of the user guide for further details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8dd9c0a0a464abab54cd5ae3d828ecf303587e8d" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">Consulte la secci&amp;oacute;n &lt;a href=&quot;metrics#metrics&quot;&gt;M&amp;eacute;tricas por pares, afinidades y n&amp;uacute;cleos&lt;/a&gt; de la gu&amp;iacute;a del usuario para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="a5b49cc34cb79ec02e159e95ecb887eb0b2cb87b" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#classification-metrics&quot;&gt;Classification metrics&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">Consulte la secci&amp;oacute;n &lt;a href=&quot;model_evaluation#classification-metrics&quot;&gt;M&amp;eacute;tricas de clasificaci&amp;oacute;n&lt;/a&gt; de la gu&amp;iacute;a del usuario para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="a370028df0ac77d50f24c414c79435536844962d" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;Metrics and scoring: quantifying the quality of predictions&lt;/a&gt; section and the &lt;a href=&quot;metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt; section of the user guide for further details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9391e01adcbcd6eab5489ba5c5bbde2b34c1c767" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;Model evaluation: quantifying the quality of predictions&lt;/a&gt; section and the &lt;a href=&quot;metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">Consulte la secci&amp;oacute;n &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;Evaluaci&amp;oacute;n&lt;/a&gt; del modelo: cuantificaci&amp;oacute;n de la calidad de las predicciones y la secci&amp;oacute;n &lt;a href=&quot;metrics#metrics&quot;&gt;M&amp;eacute;tricas por pares, afinidades y n&amp;uacute;cleos&lt;/a&gt; de la gu&amp;iacute;a del usuario para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="794b0f5d5def59a318bd787a4fccdd542a21003c" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#multilabel-ranking-metrics&quot;&gt;Multilabel ranking metrics&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">Consulte la secci&amp;oacute;n de &lt;a href=&quot;model_evaluation#multilabel-ranking-metrics&quot;&gt;m&amp;eacute;tricas de clasificaci&amp;oacute;n de m&amp;uacute;ltiples etiquetas&lt;/a&gt; de la gu&amp;iacute;a del usuario para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="2e87795fde7a0f4562bca5bb85f3c7f5918727b2" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#regression-metrics&quot;&gt;Regression metrics&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">Consulte la secci&amp;oacute;n &lt;a href=&quot;model_evaluation#regression-metrics&quot;&gt;M&amp;eacute;tricas de regresi&amp;oacute;n&lt;/a&gt; de la gu&amp;iacute;a del usuario para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="e8449bc2e3e9fd1500a092c7a467f1094a642fdf" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;The scoring parameter: defining model evaluation rules&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">Consulte la secci&amp;oacute;n &lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;El par&amp;aacute;metro de puntuaci&amp;oacute;n: definici&amp;oacute;n de reglas de evaluaci&amp;oacute;n del modelo&lt;/a&gt; de la gu&amp;iacute;a del usuario para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="bc10a00d51f81094bb499f5ba451c68f15309214" translate="yes" xml:space="preserve">
          <source>See the console&amp;rsquo;s output for further details about each model.</source>
          <target state="translated">Consulte el resultado de la consola para obtener m&amp;aacute;s detalles sobre cada modelo.</target>
        </trans-unit>
        <trans-unit id="cd81e4d9092f6289f9eb153c5b671f6c9ec59b00" translate="yes" xml:space="preserve">
          <source>See the docstring of DistanceMetric for a list of available metrics.</source>
          <target state="translated">Vea la cadena de documentación de DistanceMetric para una lista de las métricas disponibles.</target>
        </trans-unit>
        <trans-unit id="bf132d2b0dc3be6b88274385f87b0ee3f849742c" translate="yes" xml:space="preserve">
          <source>See the documentation for scipy.spatial.distance for details on these metrics.</source>
          <target state="translated">Vea la documentación de scipy.spatial.distance para más detalles sobre estas métricas.</target>
        </trans-unit>
        <trans-unit id="7af63b893a630b06c001dfe05c36e8144bafc593" translate="yes" xml:space="preserve">
          <source>See the documentation for scipy.spatial.distance for details on these metrics: &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/spatial.distance.html&quot;&gt;http://docs.scipy.org/doc/scipy/reference/spatial.distance.html&lt;/a&gt;</source>
          <target state="translated">Consulte la documentaci&amp;oacute;n de scipy.spatial.distance para obtener detalles sobre estas m&amp;eacute;tricas: &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/spatial.distance.html&quot;&gt;http://docs.scipy.org/doc/scipy/reference/spatial.distance.html&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="26decb2493981e4fa0291aaddd53d2d9f9052651" translate="yes" xml:space="preserve">
          <source>See the documentation for scipy.spatial.distance for details on these metrics: &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/spatial.distance.html&quot;&gt;https://docs.scipy.org/doc/scipy/reference/spatial.distance.html&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c235949c8aa0b531ecb9dfa56db515940237097e" translate="yes" xml:space="preserve">
          <source>See the examples below and the doc string of &lt;a href=&quot;generated/sklearn.neural_network.mlpclassifier#sklearn.neural_network.MLPClassifier.fit&quot;&gt;&lt;code&gt;MLPClassifier.fit&lt;/code&gt;&lt;/a&gt; for further information.</source>
          <target state="translated">Consulte los ejemplos a continuaci&amp;oacute;n y la cadena de documentos de &lt;a href=&quot;generated/sklearn.neural_network.mlpclassifier#sklearn.neural_network.MLPClassifier.fit&quot;&gt; &lt;code&gt;MLPClassifier.fit&lt;/code&gt; &lt;/a&gt; para obtener m&amp;aacute;s informaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="21e6c58453c3a42f9380294c0c23f1e8e3252a3a" translate="yes" xml:space="preserve">
          <source>See the examples below and the docstring of &lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit&quot;&gt;&lt;code&gt;NeighborhoodComponentsAnalysis.fit&lt;/code&gt;&lt;/a&gt; for further information.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3733f36a35b17995708cf55601d9baf4bb2149b" translate="yes" xml:space="preserve">
          <source>See the examples below and the docstring of &lt;a href=&quot;generated/sklearn.neural_network.mlpclassifier#sklearn.neural_network.MLPClassifier.fit&quot;&gt;&lt;code&gt;MLPClassifier.fit&lt;/code&gt;&lt;/a&gt; for further information.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f593defdf84cd9d54340a0b9eb8bdbba2164c5f" translate="yes" xml:space="preserve">
          <source>See the examples below for further information.</source>
          <target state="translated">Véanse los ejemplos que figuran a continuación para obtener más información.</target>
        </trans-unit>
        <trans-unit id="43e09506578d0fedfc6592860be1e23c1f8ef43b" translate="yes" xml:space="preserve">
          <source>See the examples for such an application.</source>
          <target state="translated">Véase los ejemplos de dicha aplicación.</target>
        </trans-unit>
        <trans-unit id="e8c17521507d95b1954b9918e527f968af48b835" translate="yes" xml:space="preserve">
          <source>See. &amp;ldquo;Pattern Recognition and Machine Learning&amp;rdquo; by C. Bishop, 12.2.1 p. 574 or &lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdf&lt;/a&gt;</source>
          <target state="translated">Ver. &amp;ldquo;Reconocimiento de patrones y aprendizaje autom&amp;aacute;tico&amp;rdquo; de C. Bishop, 12.2.1 p. 574 o &lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e4871111c8505b7690af20e518e753ae1b90a5ad" translate="yes" xml:space="preserve">
          <source>Seed for the random number generator used for probability estimates. 0 by default.</source>
          <target state="translated">Semilla para el generador de números aleatorios utilizado para las estimaciones de probabilidad.0 por defecto.</target>
        </trans-unit>
        <trans-unit id="72c84d205a7667dfdb05c6ebaaf98f08a838df92" translate="yes" xml:space="preserve">
          <source>Seeding is performed using a binning technique for scalability.</source>
          <target state="translated">La siembra se realiza mediante una técnica de binning para la escalabilidad.</target>
        </trans-unit>
        <trans-unit id="f1f3844996349c701e3db8be5a62a8ace310a543" translate="yes" xml:space="preserve">
          <source>Seeds used to initialize kernels. If not set, the seeds are calculated by clustering.get_bin_seeds with bandwidth as the grid size and default values for other parameters.</source>
          <target state="translated">Las semillas se usan para inicializar los núcleos.Si no se establece,las semillas se calculan mediante clustering.get_bin_seeds con el ancho de banda como tamaño de la cuadrícula y valores por defecto para otros parámetros.</target>
        </trans-unit>
        <trans-unit id="1a053c7e782c53a91d6d509bf6a99224f4b893d2" translate="yes" xml:space="preserve">
          <source>Segmenting the picture of greek coins in regions</source>
          <target state="translated">Segmentar la imagen de las monedas griegas en las regiones</target>
        </trans-unit>
        <trans-unit id="05c2c519388dfeab1d2da32ad0c3a55d08148aed" translate="yes" xml:space="preserve">
          <source>Select &lt;code&gt;min_samples&lt;/code&gt; random samples from the original data and check whether the set of data is valid (see &lt;code&gt;is_data_valid&lt;/code&gt;).</source>
          <target state="translated">Seleccione &lt;code&gt;min_samples&lt;/code&gt; muestras aleatorias de los datos originales y compruebe si el conjunto de datos es v&amp;aacute;lido (consulte &lt;code&gt;is_data_valid&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="4c8220c40092a5223a7519a4053e419620df4d58" translate="yes" xml:space="preserve">
          <source>Select eigensolver to use. If n_components is much less than the number of training samples, arpack may be more efficient than the dense eigensolver.</source>
          <target state="translated">Seleccione eigensolver para usar.Si n_componentes es mucho menor que el número de muestras de entrenamiento,arpack puede ser más eficiente que el denso eigensolver.</target>
        </trans-unit>
        <trans-unit id="a8b26e8dd8c57424e2a0ff5f2b02e8bbc7be69eb" translate="yes" xml:space="preserve">
          <source>Select features according to a percentile of the highest scores.</source>
          <target state="translated">Selecciona las características según un percentil de las puntuaciones más altas.</target>
        </trans-unit>
        <trans-unit id="d20a85a468318484f73da066702f203468ec7eb5" translate="yes" xml:space="preserve">
          <source>Select features according to the k highest scores.</source>
          <target state="translated">Selecciona las características de acuerdo con las k más altas puntuaciones.</target>
        </trans-unit>
        <trans-unit id="c3952e3b9f6e5571ab9a9f69665172397cc254d2" translate="yes" xml:space="preserve">
          <source>Select features based on a false positive rate test.</source>
          <target state="translated">Selecciona las características en base a una prueba de tasa de falsos positivos.</target>
        </trans-unit>
        <trans-unit id="32515d7cef117ccce44afc2f4f0b98f43d0db807" translate="yes" xml:space="preserve">
          <source>Select features based on an estimated false discovery rate.</source>
          <target state="translated">Seleccione las características en base a una tasa estimada de falsos descubrimientos.</target>
        </trans-unit>
        <trans-unit id="6d7a0df88fc316c1f019dac960b65ab544487a37" translate="yes" xml:space="preserve">
          <source>Select features based on family-wise error rate.</source>
          <target state="translated">Selecciona las características en función de la tasa de error familiar.</target>
        </trans-unit>
        <trans-unit id="ba417981f6009fc06cd3596ff9c6cb4c2bd25319" translate="yes" xml:space="preserve">
          <source>Select features based on percentile of the highest scores.</source>
          <target state="translated">Selecciona las características en base al percentil de las puntuaciones más altas.</target>
        </trans-unit>
        <trans-unit id="3532493330a0445601f2381a89fe492b8458f964" translate="yes" xml:space="preserve">
          <source>Select features based on the k highest scores.</source>
          <target state="translated">Selecciona las características en base a las k más altas puntuaciones.</target>
        </trans-unit>
        <trans-unit id="d3166439a7b0a709dd15d8647b0a1e23526bb82a" translate="yes" xml:space="preserve">
          <source>Select from the model features with the higest score</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc6cce4211d0c67d4111ac2f86243aa83948ed07" translate="yes" xml:space="preserve">
          <source>Select n_samples integers from the set [0, n_population) without replacement.</source>
          <target state="translated">Selecciona n_muestras enteras del conjunto [0,n_población]sin reemplazo.</target>
        </trans-unit>
        <trans-unit id="e693da3619bc133d154aaf34e091d4f9f76e8468" translate="yes" xml:space="preserve">
          <source>Select the algorithm to either solve the dual or primal optimization problem. Prefer dual=False when n_samples &amp;gt; n_features.</source>
          <target state="translated">Seleccione el algoritmo para resolver el problema de optimizaci&amp;oacute;n primaria o dual. Prefiere dual = False cuando n_samples&amp;gt; n_features.</target>
        </trans-unit>
        <trans-unit id="e09f39accd13c28376a1ebc78d546869197bec0f" translate="yes" xml:space="preserve">
          <source>Select the dataset to load: &amp;lsquo;train&amp;rsquo; for the development training set, &amp;lsquo;test&amp;rsquo; for the development test set, and &amp;lsquo;10_folds&amp;rsquo; for the official evaluation set that is meant to be used with a 10-folds cross validation.</source>
          <target state="translated">Seleccione el conjunto de datos para cargar: 'entrenar' para el conjunto de entrenamiento de desarrollo, 'prueba' para el conjunto de pruebas de desarrollo y '10_folds' para el conjunto de evaluaci&amp;oacute;n oficial que debe usarse con una validaci&amp;oacute;n cruzada de 10 pliegues.</target>
        </trans-unit>
        <trans-unit id="da5a2fc4086f03333558c16d8aba6a6ba8f98164" translate="yes" xml:space="preserve">
          <source>Select the dataset to load: &amp;lsquo;train&amp;rsquo; for the training set (23149 samples), &amp;lsquo;test&amp;rsquo; for the test set (781265 samples), &amp;lsquo;all&amp;rsquo; for both, with the training samples first if shuffle is False. This follows the official LYRL2004 chronological split.</source>
          <target state="translated">Seleccione el conjunto de datos para cargar: 'entrenar' para el conjunto de entrenamiento (23149 muestras), 'prueba' para el conjunto de prueba (781265 muestras), 'todos' para ambos, con las muestras de entrenamiento primero si la reproducci&amp;oacute;n aleatoria es False. Esto sigue a la divisi&amp;oacute;n cronol&amp;oacute;gica oficial de LYRL2004.</target>
        </trans-unit>
        <trans-unit id="a373737a4d85a4134f237dcaa76f506d35776152" translate="yes" xml:space="preserve">
          <source>Select the dataset to load: &amp;lsquo;train&amp;rsquo; for the training set, &amp;lsquo;test&amp;rsquo; for the test set, &amp;lsquo;all&amp;rsquo; for both, with shuffled ordering.</source>
          <target state="translated">Seleccione el conjunto de datos para cargar: 'entrenar' para el conjunto de entrenamiento, 'prueba' para el conjunto de prueba, 'todos' para ambos, con orden aleatorio.</target>
        </trans-unit>
        <trans-unit id="c5f861c6085a651c0ed9619f5012b02bb9a2d195" translate="yes" xml:space="preserve">
          <source>Select the parameters that minimises the impurity</source>
          <target state="translated">Seleccione los parámetros que minimizan la impureza</target>
        </trans-unit>
        <trans-unit id="776d7f86c8363c5c583ee4e086a4256b8464f6f6" translate="yes" xml:space="preserve">
          <source>Select the portion to load: &amp;lsquo;train&amp;rsquo;, &amp;lsquo;test&amp;rsquo; or &amp;lsquo;raw&amp;rsquo;</source>
          <target state="translated">Seleccione la porci&amp;oacute;n para cargar: 'entrenar', 'prueba' o 'sin procesar'</target>
        </trans-unit>
        <trans-unit id="b97f498920dc9d14793f9ec22705c51c7828c05e" translate="yes" xml:space="preserve">
          <source>Select whether the regularization affects the components (H), the transformation (W), both or none of them.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09caeaab6645f9fa60776419a39bd350760c6b9f" translate="yes" xml:space="preserve">
          <source>Selecting &lt;code&gt;average=None&lt;/code&gt; will return an array with the score for each class.</source>
          <target state="translated">Si selecciona &lt;code&gt;average=None&lt;/code&gt; se devolver&amp;aacute; una matriz con la puntuaci&amp;oacute;n de cada clase.</target>
        </trans-unit>
        <trans-unit id="09987abb5cb6e00639cc8ad149fcfc0ee4e216e7" translate="yes" xml:space="preserve">
          <source>Selecting dimensionality reduction with Pipeline and GridSearchCV</source>
          <target state="translated">Seleccionando la reducción de la dimensionalidad con Pipeline y GridSearchCV</target>
        </trans-unit>
        <trans-unit id="b619a7e9444390b8df9ed15ee53211d47286dc3c" translate="yes" xml:space="preserve">
          <source>Selecting the number of clusters with silhouette analysis on KMeans clustering</source>
          <target state="translated">Seleccionando el número de cúmulos con análisis de siluetas en el cúmulo de KMeans</target>
        </trans-unit>
        <trans-unit id="1e3a867140ee60f287b6c8b807e610aee224839f" translate="yes" xml:space="preserve">
          <source>Selects the algorithm for finding singular vectors. May be &amp;lsquo;randomized&amp;rsquo; or &amp;lsquo;arpack&amp;rsquo;. If &amp;lsquo;randomized&amp;rsquo;, use &lt;a href=&quot;sklearn.utils.extmath.randomized_svd#sklearn.utils.extmath.randomized_svd&quot;&gt;&lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt;&lt;/a&gt;, which may be faster for large matrices. If &amp;lsquo;arpack&amp;rsquo;, use &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html#scipy.sparse.linalg.svds&quot;&gt;&lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt;&lt;/a&gt;, which is more accurate, but possibly slower in some cases.</source>
          <target state="translated">Selecciona el algoritmo para encontrar vectores singulares. Puede ser &quot;aleatorio&quot; o &quot;arpack&quot;. Si es 'aleatorio', use &lt;a href=&quot;sklearn.utils.extmath.randomized_svd#sklearn.utils.extmath.randomized_svd&quot;&gt; &lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt; &lt;/a&gt; , que puede ser m&amp;aacute;s r&amp;aacute;pido para matrices grandes. Si es 'arpack', use &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html#scipy.sparse.linalg.svds&quot;&gt; &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt; &lt;/a&gt; , que es m&amp;aacute;s preciso, pero posiblemente m&amp;aacute;s lento en algunos casos.</target>
        </trans-unit>
        <trans-unit id="fc3d3604d35f10ba0398acd746e6c18250ce369b" translate="yes" xml:space="preserve">
          <source>Selects the algorithm for finding singular vectors. May be &amp;lsquo;randomized&amp;rsquo; or &amp;lsquo;arpack&amp;rsquo;. If &amp;lsquo;randomized&amp;rsquo;, uses &lt;a href=&quot;sklearn.utils.extmath.randomized_svd#sklearn.utils.extmath.randomized_svd&quot;&gt;&lt;code&gt;randomized_svd&lt;/code&gt;&lt;/a&gt;, which may be faster for large matrices. If &amp;lsquo;arpack&amp;rsquo;, uses &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt;, which is more accurate, but possibly slower in some cases.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba0796ade5894bc55073846864af8524b40634d7" translate="yes" xml:space="preserve">
          <source>Selects the algorithm for finding singular vectors. May be &amp;lsquo;randomized&amp;rsquo; or &amp;lsquo;arpack&amp;rsquo;. If &amp;lsquo;randomized&amp;rsquo;, uses &lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt;, which may be faster for large matrices. If &amp;lsquo;arpack&amp;rsquo;, uses &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt;, which is more accurate, but possibly slower in some cases.</source>
          <target state="translated">Selecciona el algoritmo para encontrar vectores singulares. Puede ser &quot;aleatorio&quot; o &quot;arpack&quot;. Si es 'aleatorio', usa &lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt; , que puede ser m&amp;aacute;s r&amp;aacute;pido para matrices grandes. Si es 'arpack', usa &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt; , que es m&amp;aacute;s preciso, pero posiblemente m&amp;aacute;s lento en algunos casos.</target>
        </trans-unit>
        <trans-unit id="90a62864642c982296e3e801c0e34e5e7f5e23e4" translate="yes" xml:space="preserve">
          <source>Semi Supervised Classification</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c634aac4fba33953abfb672747b23d137a6eb94" translate="yes" xml:space="preserve">
          <source>Sepal length</source>
          <target state="translated">Longitud del septo</target>
        </trans-unit>
        <trans-unit id="fb329e5a4491aa43414f15d76bffc8963ea0de09" translate="yes" xml:space="preserve">
          <source>Sepal width</source>
          <target state="translated">Anchura del septo</target>
        </trans-unit>
        <trans-unit id="e5dddf892a3efc8978d095e912cc4306a1e49804" translate="yes" xml:space="preserve">
          <source>Separating inliers from outliers using a Mahalanobis distance</source>
          <target state="translated">Separar los valores atípicos de los no atípicos usando una distancia de Mahalanobis</target>
        </trans-unit>
        <trans-unit id="aece656a00e1c7a3f193615a59fc1f63e6e58693" translate="yes" xml:space="preserve">
          <source>Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, &amp;ldquo;Decision Tree Construction Via Linear Programming.&amp;rdquo; Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.</source>
          <target state="translated">El plano de separaci&amp;oacute;n descrito anteriormente se obtuvo mediante el m&amp;eacute;todo de &amp;aacute;rbol multisuperficie (MSM-T) [KP Bennett, &quot;Decision Tree Construction Via Linear Programming&quot;. Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, p&amp;aacute;gs. 97-101, 1992], un m&amp;eacute;todo de clasificaci&amp;oacute;n que utiliza programaci&amp;oacute;n lineal para construir un &amp;aacute;rbol de decisiones. Las caracter&amp;iacute;sticas relevantes se seleccionaron mediante una b&amp;uacute;squeda exhaustiva en el espacio de 1-4 caracter&amp;iacute;sticas y 1-3 planos de separaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="749810666e6448d7103b8c1ba2bbfef3e451d983" translate="yes" xml:space="preserve">
          <source>Separator string used when constructing new features for one-hot coding.</source>
          <target state="translated">Cadena separadora usada cuando se construyen nuevas características para la codificación de una sola vez.</target>
        </trans-unit>
        <trans-unit id="70aafd2a89678b32332fcfe0ff93efd39c5a3c06" translate="yes" xml:space="preserve">
          <source>Sequence of integer labels or multilabel data to encode.</source>
          <target state="translated">Secuencia de etiquetas enteras o datos de etiquetas múltiples para codificar.</target>
        </trans-unit>
        <trans-unit id="63145e1c892f5c29b2a500cdc3f15222c0784b14" translate="yes" xml:space="preserve">
          <source>Sequence of resampled copies of the collections. The original arrays are not impacted.</source>
          <target state="translated">Secuencia de copias remuestreadas de las colecciones.Los conjuntos originales no se ven afectados.</target>
        </trans-unit>
        <trans-unit id="22f488ee4fca141470b8e2b188abe2e7275b3dc0" translate="yes" xml:space="preserve">
          <source>Sequence of shuffled copies of the collections. The original arrays are not impacted.</source>
          <target state="translated">Secuencia de copias barajadas de las colecciones.Los conjuntos originales no se ven afectados.</target>
        </trans-unit>
        <trans-unit id="05f31ec9564cc0e3d1b047a8eba0a9e234d2f0b3" translate="yes" xml:space="preserve">
          <source>Sequence of weights (&lt;code&gt;float&lt;/code&gt; or &lt;code&gt;int&lt;/code&gt;) to weight the occurrences of predicted class labels (&lt;code&gt;hard&lt;/code&gt; voting) or class probabilities before averaging (&lt;code&gt;soft&lt;/code&gt; voting). Uses uniform weights if &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">Secuencia de pesos ( &lt;code&gt;float&lt;/code&gt; o &lt;code&gt;int&lt;/code&gt; ) para ponderar las apariciones de etiquetas predichos de clase ( &lt;code&gt;hard&lt;/code&gt; de voto) o probabilidades de clase antes de promediar ( &lt;code&gt;soft&lt;/code&gt; de voto). Usa pesos uniformes si &lt;code&gt;None&lt;/code&gt; hay ninguno .</target>
        </trans-unit>
        <trans-unit id="1b2a96243ee03211fb7854a57171cf92c85f5687" translate="yes" xml:space="preserve">
          <source>Sequence of weights (&lt;code&gt;float&lt;/code&gt; or &lt;code&gt;int&lt;/code&gt;) to weight the occurrences of predicted values before averaging. Uses uniform weights if &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ea6d0fbbfa7ff1125b3f0dc0d1f0f204d3b725f" translate="yes" xml:space="preserve">
          <source>Sequentially apply a list of transforms and a final estimator. Intermediate steps of the pipeline must be &amp;lsquo;transforms&amp;rsquo;, that is, they must implement fit and transform methods. The final estimator only needs to implement fit. The transformers in the pipeline can be cached using &lt;code&gt;memory&lt;/code&gt; argument.</source>
          <target state="translated">Aplicar secuencialmente una lista de transformadas y un estimador final. Los pasos intermedios de la tuber&amp;iacute;a deben ser 'transformaciones', es decir, deben implementar m&amp;eacute;todos de ajuste y transformaci&amp;oacute;n. El estimador final solo necesita implementar el ajuste. Los transformadores de la canalizaci&amp;oacute;n se pueden almacenar en cach&amp;eacute; mediante el argumento de &lt;code&gt;memory&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5d912fff074ca31c7c82b5fde02f4d9656aba0e0" translate="yes" xml:space="preserve">
          <source>Set &lt;code&gt;kernel='precomputed'&lt;/code&gt; and pass the Gram matrix instead of X in the fit method. At the moment, the kernel values between &lt;em&gt;all&lt;/em&gt; training vectors and the test vectors must be provided.</source>
          <target state="translated">Establezca &lt;code&gt;kernel='precomputed'&lt;/code&gt; y pase la matriz Gram en lugar de X en el m&amp;eacute;todo de ajuste. Por el momento, se deben proporcionar los valores del kernel entre &lt;em&gt;todos&lt;/em&gt; los vectores de entrenamiento y los vectores de prueba.</target>
        </trans-unit>
        <trans-unit id="82c89924e3ff5aee8a7d762157ebec36e4bfb77e" translate="yes" xml:space="preserve">
          <source>Set &lt;code&gt;n_clusters&lt;/code&gt; to a required value using &lt;code&gt;brc.set_params(n_clusters=n_clusters)&lt;/code&gt;.</source>
          <target state="translated">Establezca &lt;code&gt;n_clusters&lt;/code&gt; en un valor requerido mediante &lt;code&gt;brc.set_params(n_clusters=n_clusters)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="baf739c6d3f3081a673c9a62345f43337d9146af" translate="yes" xml:space="preserve">
          <source>Set an initial start configuration, randomly or not.</source>
          <target state="translated">Establezca una configuración inicial de inicio,al azar o no.</target>
        </trans-unit>
        <trans-unit id="acdb8317b38cc1be24a0a9627d99a9301a5b666a" translate="yes" xml:space="preserve">
          <source>Set and validate the parameters of estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7115214e952526d911c94e2c07be9533a4c1bc42" translate="yes" xml:space="preserve">
          <source>Set global scikit-learn configuration</source>
          <target state="translated">Establecer la configuración global de aprendizaje científico</target>
        </trans-unit>
        <trans-unit id="d973ce66011b9fa67c29ae92b31d59e39ce28a97" translate="yes" xml:space="preserve">
          <source>Set of samples, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">Conjunto de muestras,donde n_muestras es el número de muestras y n_características es el número de características.</target>
        </trans-unit>
        <trans-unit id="859e800d4c0c95faf85e59d644290b4f9223483a" translate="yes" xml:space="preserve">
          <source>Set the parameter C of class i to &lt;code&gt;class_weight[i]*C&lt;/code&gt; for SVC. If not given, all classes are supposed to have weight one. The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</source>
          <target state="translated">Establezca el par&amp;aacute;metro C de la clase i en &lt;code&gt;class_weight[i]*C&lt;/code&gt; para SVC. Si no se da, se supone que todas las clases tienen un peso uno. El modo &quot;balanceado&quot; utiliza los valores de y para ajustar autom&amp;aacute;ticamente los pesos inversamente proporcionales a las frecuencias de clase en los datos de entrada como &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="291ade590fbb6a8638dd1afb8f1376626f33f6ea" translate="yes" xml:space="preserve">
          <source>Set the parameter C of class i to &lt;code&gt;class_weight[i]*C&lt;/code&gt; for SVC. If not given, all classes are supposed to have weight one. The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68197d507e5463b3337bc09b3b9761d9525e528a" translate="yes" xml:space="preserve">
          <source>Set the parameter C of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</source>
          <target state="translated">Establezca el par&amp;aacute;metro C de la clase i en class_weight [i] * C para SVC. Si no se da, se supone que todas las clases tienen un peso uno. El modo &quot;balanceado&quot; utiliza los valores de y para ajustar autom&amp;aacute;ticamente los pesos inversamente proporcionales a las frecuencias de clase como &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7ee0e3c771d52a3f4b21637b50de4b2fa144cadb" translate="yes" xml:space="preserve">
          <source>Set the parameter C of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</source>
          <target state="translated">Establezca el par&amp;aacute;metro C de la clase i en class_weight [i] * C para SVC. Si no se da, se supone que todas las clases tienen un peso uno. El modo &quot;balanceado&quot; utiliza los valores de y para ajustar autom&amp;aacute;ticamente los pesos inversamente proporcionales a las frecuencias de clase en los datos de entrada como &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="02c4dadc552ae2f0292cf77b2c6f20b9175838e2" translate="yes" xml:space="preserve">
          <source>Set the parameters</source>
          <target state="translated">Establecer los parámetros...</target>
        </trans-unit>
        <trans-unit id="3f30532fe6a7a61216e1f94a622dfc009651d7c9" translate="yes" xml:space="preserve">
          <source>Set the parameters of an estimator from the ensemble.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72f87d2d27b1f0c322a530ad0dc9b59597d7be5b" translate="yes" xml:space="preserve">
          <source>Set the parameters of this estimator.</source>
          <target state="translated">Establezca los parámetros de este estimador.</target>
        </trans-unit>
        <trans-unit id="57d60e82b45349e99163b5cb25f5c26dc09997fb" translate="yes" xml:space="preserve">
          <source>Set the parameters of this kernel.</source>
          <target state="translated">Establezca los parámetros de este núcleo.</target>
        </trans-unit>
        <trans-unit id="e51dac5748f92b9a4d95a295db13667c4d900b8f" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace computation during transformation.</source>
          <target state="translated">Ponga en Falso para realizar el cálculo in situ durante la transformación.</target>
        </trans-unit>
        <trans-unit id="c9e442dcb8465293c9e9b1ca26f1df573cbc8a5b" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace computation.</source>
          <target state="translated">Ponlo en falso para realizar el cálculo in situ.</target>
        </trans-unit>
        <trans-unit id="66ebe619c3b8004252e57f6a28ff4945f1da8024" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace row normalization and avoid a copy (if the input is already a numpy array).</source>
          <target state="translated">Poner en Falso para realizar la normalización de la fila in situ y evitar una copia (si la entrada ya es una matriz numérica).</target>
        </trans-unit>
        <trans-unit id="00972eb158db00f5dae23773f938b4091d65b472" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace scaling and avoid a copy (if the input is already a numpy array).</source>
          <target state="translated">Ponga en Falso para realizar un escalado in situ y evitar una copia (si la entrada ya es una matriz numérica).</target>
        </trans-unit>
        <trans-unit id="08f65c010729649e9d6102eb99a0ed3b76fe0859" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace transformation and avoid a copy (if the input is already a numpy array).</source>
          <target state="translated">Ponga en Falso para realizar una transformación in situ y evitar una copia (si la entrada ya es una matriz numérica).</target>
        </trans-unit>
        <trans-unit id="bbfbd49ae916b95e446b3c89c15541e5023cd4ad" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace transformation and avoid a copy (if the input is already a numpy array). If True, a copy of &lt;code&gt;X&lt;/code&gt; is transformed, leaving the original &lt;code&gt;X&lt;/code&gt; unchanged</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70773d7b4f76452047259ed8e2e9af7169f13fc0" translate="yes" xml:space="preserve">
          <source>Set to True to apply zero-mean, unit-variance normalization to the transformed output.</source>
          <target state="translated">Ponga en True para aplicar la normalización de la media cero y la varianza de la unidad a la salida transformada.</target>
        </trans-unit>
        <trans-unit id="31263c2a03fef7d2c1e558ffe5e1f7ce22d5913e" translate="yes" xml:space="preserve">
          <source>Set to True, both W and H will be estimated from initial guesses. Set to False, only W will be estimated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7d505eb35ec97e19208554a83f21f5336e3915d" translate="yes" xml:space="preserve">
          <source>Set to true if output binary array is desired in CSR sparse format</source>
          <target state="translated">Poner en true si se desea un arreglo binario de salida en formato CSR disperso</target>
        </trans-unit>
        <trans-unit id="e9779b7ab3cf4b478b4bfa7669bfc4f6492ae2ea" translate="yes" xml:space="preserve">
          <source>Sets the default value for the &lt;code&gt;assume_finite&lt;/code&gt; argument of &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Establece el valor por defecto para el &lt;code&gt;assume_finite&lt;/code&gt; argumento de &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;sklearn.set_config&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2047224d21bf76be06bd841e22b2f6efe81f5987" translate="yes" xml:space="preserve">
          <source>Sets the default value for the &lt;code&gt;working_memory&lt;/code&gt; argument of &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Establece el valor por defecto para el &lt;code&gt;working_memory&lt;/code&gt; argumento de &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;sklearn.set_config&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="8fc661c1feefb08f484398590a9cfaa0d200700d" translate="yes" xml:space="preserve">
          <source>Sets the seed of the global random generator when running the tests, for reproducibility.</source>
          <target state="translated">Establece la semilla del generador aleatorio global cuando se realizan las pruebas,para la reproducibilidad.</target>
        </trans-unit>
        <trans-unit id="75bad9ccfc79ab0c0bbe60c8449ed7b0c754d17f" translate="yes" xml:space="preserve">
          <source>Sets the value to return when there is a zero division, i.e. when all predictions and labels are negative. If set to &amp;ldquo;warn&amp;rdquo;, this acts as 0, but warnings are also raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5785bcff96fce8eedf96c87581cbc35bae5756d5" translate="yes" xml:space="preserve">
          <source>Sets the value to return when there is a zero division. If set to &amp;ldquo;warn&amp;rdquo;, this acts as 0, but warnings are also raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e057cbf5e19c7dcf916bf2fe2aa47295c10430c1" translate="yes" xml:space="preserve">
          <source>Sets the value to return when there is a zero division:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ceca261ca4bfaf0dac2e7a5f6879bae3049e05bd" translate="yes" xml:space="preserve">
          <source>Sets the verbosity amount</source>
          <target state="translated">Establece la cantidad de verbosidad</target>
        </trans-unit>
        <trans-unit id="0f757b166230d0f61e44fc2003ab4f4a4d10043d" translate="yes" xml:space="preserve">
          <source>Setting &lt;code&gt;generate_only=True&lt;/code&gt; returns a generator that yields (estimator, check) tuples where the check can be called independently from each other, i.e. &lt;code&gt;check(estimator)&lt;/code&gt;. This allows all checks to be run independently and report the checks that are failing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41f97bb142955ba403db62394a8510aa45205b7b" translate="yes" xml:space="preserve">
          <source>Setting it to True gets the various classifiers and the parameters of the classifiers as well</source>
          <target state="translated">Poniéndolo en True se obtienen los diversos clasificadores y los parámetros de los clasificadores también</target>
        </trans-unit>
        <trans-unit id="924da9eef84794e1bcb0c0c5d50e7650f0dfc881" translate="yes" xml:space="preserve">
          <source>Setting it to True gets the various classifiers and the parameters of the classifiers as well.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e750c0ef44cf143b57f79a94939ea31cd10193d" translate="yes" xml:space="preserve">
          <source>Setting print_changed_only to True will alternate the representation of estimators to only show the parameters that have been set to non-default values. This can be used to have more compact representations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2623b7b1ad6f2c3b5492832d70831c56aba6aac8" translate="yes" xml:space="preserve">
          <source>Setting the parameter by cross-validating the likelihood on three folds according to a grid of potential shrinkage parameters.</source>
          <target state="translated">Estableciendo el parámetro mediante la validación cruzada de la probabilidad en tres pliegues según una cuadrícula de parámetros de contracción potencial.</target>
        </trans-unit>
        <trans-unit id="edca67601d1a75cccde1deb24fddb7bb63088fcb" translate="yes" xml:space="preserve">
          <source>Setting the parameters for the voting classifier</source>
          <target state="translated">Ajustar los parámetros para el clasificador de votos</target>
        </trans-unit>
        <trans-unit id="cb6261b9db86d6920a006098fc7538ed80a40df3" translate="yes" xml:space="preserve">
          <source>Several estimators in the scikit-learn can use connectivity information between features or samples. For instance Ward clustering (&lt;a href=&quot;clustering#hierarchical-clustering&quot;&gt;Hierarchical clustering&lt;/a&gt;) can cluster together only neighboring pixels of an image, thus forming contiguous patches:</source>
          <target state="translated">Varios estimadores de scikit-learn pueden usar informaci&amp;oacute;n de conectividad entre caracter&amp;iacute;sticas o muestras. Por ejemplo, la agrupaci&amp;oacute;n de Ward (agrupaci&amp;oacute;n &lt;a href=&quot;clustering#hierarchical-clustering&quot;&gt;jer&amp;aacute;rquica&lt;/a&gt; ) puede agrupar solo los p&amp;iacute;xeles vecinos de una imagen, formando as&amp;iacute; parches contiguos:</target>
        </trans-unit>
        <trans-unit id="b2ad224369c25dffec31e32504aa18be16f8d837" translate="yes" xml:space="preserve">
          <source>Several functions allow you to analyze the precision, recall and F-measures score:</source>
          <target state="translated">Varias funciones permiten analizar la precisión,la memoria y la puntuación de las medidas F:</target>
        </trans-unit>
        <trans-unit id="beccb29e29ebc99080f8c36d4203650a9f29b872" translate="yes" xml:space="preserve">
          <source>Several methods have been developed to compare two sets of biclusters. For now, only &lt;a href=&quot;generated/sklearn.metrics.consensus_score#sklearn.metrics.consensus_score&quot;&gt;&lt;code&gt;consensus_score&lt;/code&gt;&lt;/a&gt; (Hochreiter et. al., 2010) is available:</source>
          <target state="translated">Se han desarrollado varios m&amp;eacute;todos para comparar dos conjuntos de biclusters. Por ahora, solo est&amp;aacute; disponible la puntuaci&amp;oacute;n de &lt;a href=&quot;generated/sklearn.metrics.consensus_score#sklearn.metrics.consensus_score&quot;&gt; &lt;code&gt;consensus_score&lt;/code&gt; &lt;/a&gt; (Hochreiter et. Al., 2010):</target>
        </trans-unit>
        <trans-unit id="bf696ed0c48f638295bdb050d71aac6a4287ef6f" translate="yes" xml:space="preserve">
          <source>Several regression and binary classification algorithms are available in scikit-learn. A simple way to extend these algorithms to the multi-class classification case is to use the so-called one-vs-all scheme.</source>
          <target state="translated">Varios algoritmos de regresión y clasificación binaria están disponibles en scikit-learn.Una forma sencilla de extender estos algoritmos al caso de la clasificación multiclase es usar el llamado esquema &quot;uno contra todos&quot;.</target>
        </trans-unit>
        <trans-unit id="0ac410486b823defe3030785e8a86edcf2b2b7e4" translate="yes" xml:space="preserve">
          <source>Severity Model - Gamma distribution</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e301dd6062f7e9a79975fe8e2d0ba91694c4dbc3" translate="yes" xml:space="preserve">
          <source>Sex</source>
          <target state="translated">Sex</target>
        </trans-unit>
        <trans-unit id="94351e57e5ad4d9a685a9e5e4a3a8ed2b422ed01" translate="yes" xml:space="preserve">
          <source>Shape of the data arrays</source>
          <target state="translated">La forma de los conjuntos de datos</target>
        </trans-unit>
        <trans-unit id="6ce851a20ced87e3a45210428f1caa987910f68a" translate="yes" xml:space="preserve">
          <source>Shape of the i&amp;rsquo;th bicluster.</source>
          <target state="translated">Forma del i'th bicluster.</target>
        </trans-unit>
        <trans-unit id="e14b35d505512b3adb2f8997ae35ca2be24040d8" translate="yes" xml:space="preserve">
          <source>Shape will be [n_samples, 1] for binary problems.</source>
          <target state="translated">La forma será [n_muestras,1]para los problemas binarios.</target>
        </trans-unit>
        <trans-unit id="f4aa10e40109dde70a9d57a4c3969b16b2895540" translate="yes" xml:space="preserve">
          <source>Shift features by the specified value. If None, then features are shifted by a random value drawn in [-class_sep, class_sep].</source>
          <target state="translated">Cambiar las características por el valor especificado.Si no hay ninguna,entonces las características se desplazan por un valor aleatorio dibujado en [-class_sep,class_sep].</target>
        </trans-unit>
        <trans-unit id="89ec1dbbc8f85faf0ad282b8a6481e07a4785260" translate="yes" xml:space="preserve">
          <source>Shifted opposite of the Local Outlier Factor of X.</source>
          <target state="translated">Se ha desplazado en sentido contrario al Factor Local Atípico de X.</target>
        </trans-unit>
        <trans-unit id="5433cd73ac014316d0b32695693eab5029601309" translate="yes" xml:space="preserve">
          <source>Shorthand</source>
          <target state="translated">Shorthand</target>
        </trans-unit>
        <trans-unit id="a8178c51c2cc3204c708328447fd16ef389ce9b6" translate="yes" xml:space="preserve">
          <source>Should be used when memory is inefficient to train all data. Chunks of data can be passed in several iteration, where the first call should have an array of all target variables.</source>
          <target state="translated">Debe usarse cuando la memoria es ineficiente para entrenar todos los datos.Los trozos de datos pueden ser pasados en varias iteraciones,donde la primera llamada debe tener un arreglo de todas las variables objetivo.</target>
        </trans-unit>
        <trans-unit id="12700416ee0fef7fdd5157d1c27acbb9da13d5c9" translate="yes" xml:space="preserve">
          <source>Should be used when memory is inefficient to train all data. Chunks of data can be passed in several iteration.</source>
          <target state="translated">Debe usarse cuando la memoria es ineficiente para entrenar todos los datos.Se pueden pasar trozos de datos en varias iteraciones.</target>
        </trans-unit>
        <trans-unit id="ec934ba88e117c3577f933302800f3ab4b85705a" translate="yes" xml:space="preserve">
          <source>Show below is a logistic-regression classifiers decision boundaries on the first two dimensions (sepal length and width) of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;iris&lt;/a&gt; dataset. The datapoints are colored according to their labels.</source>
          <target state="translated">A continuaci&amp;oacute;n se muestran los l&amp;iacute;mites de decisi&amp;oacute;n de los clasificadores de regresi&amp;oacute;n log&amp;iacute;stica en las dos primeras dimensiones (longitud y ancho del s&amp;eacute;palo) del conjunto de datos del &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;iris&lt;/a&gt; . Los puntos de datos est&amp;aacute;n coloreados de acuerdo con sus etiquetas.</target>
        </trans-unit>
        <trans-unit id="c74e263b32d3703a876a54ba7cc367e3fb1c6bbb" translate="yes" xml:space="preserve">
          <source>Shown in the plot is how the logistic regression would, in this synthetic dataset, classify values as either 0 or 1, i.e. class one or two, using the logistic curve.</source>
          <target state="translated">En el gráfico se muestra cómo la regresión logística,en este conjunto de datos sintéticos,clasificaría los valores como 0 o 1,es decir,clase uno o dos,utilizando la curva logística.</target>
        </trans-unit>
        <trans-unit id="ca5bc8cbcc9592e82a2ca132c00133d4ad37408e" translate="yes" xml:space="preserve">
          <source>Shows how shrinkage improves classification.</source>
          <target state="translated">Muestra cómo el encogimiento mejora la clasificación.</target>
        </trans-unit>
        <trans-unit id="5dc7ad8809a977f328219d536276f520094e2981" translate="yes" xml:space="preserve">
          <source>Shows how to use a function transformer in a pipeline. If you know your dataset&amp;rsquo;s first principle component is irrelevant for a classification task, you can use the FunctionTransformer to select all but the first column of the PCA transformed data.</source>
          <target state="translated">Muestra c&amp;oacute;mo utilizar un transformador de funci&amp;oacute;n en una canalizaci&amp;oacute;n. Si sabe que el primer componente principal de su conjunto de datos es irrelevante para una tarea de clasificaci&amp;oacute;n, puede usar FunctionTransformer para seleccionar todos los datos transformados de PCA excepto la primera.</target>
        </trans-unit>
        <trans-unit id="f535d0d4250bfadc5c1c6932476e7cb22e7db70e" translate="yes" xml:space="preserve">
          <source>Shows the effect of collinearity in the coefficients of an estimator.</source>
          <target state="translated">Muestra el efecto de la colinealidad en los coeficientes de un estimador.</target>
        </trans-unit>
        <trans-unit id="1a78e7f7618436a20d69e64d9d5ffb3bc060c908" translate="yes" xml:space="preserve">
          <source>Shrinkage</source>
          <target state="translated">Shrinkage</target>
        </trans-unit>
        <trans-unit id="29ad8c0361eee52379ab28eb86f7303c232b073b" translate="yes" xml:space="preserve">
          <source>Shrinkage and sparsity with logistic regression</source>
          <target state="translated">La contracción y la escasez con la regresión logística</target>
        </trans-unit>
        <trans-unit id="92e7e7782831a32d85f1f4adb6e6848b9931e9f2" translate="yes" xml:space="preserve">
          <source>Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood</source>
          <target state="translated">Estimación de la covarianza de la contracción:LedoitWolf vs OAS y probabilidad máxima</target>
        </trans-unit>
        <trans-unit id="2e2068ed5693c53cc14ed41dc7c2ee819779a1f5" translate="yes" xml:space="preserve">
          <source>Shrinkage is a form of regularization used to improve the estimation of covariance matrices in situations where the number of training samples is small compared to the number of features. In this scenario, the empirical sample covariance is a poor estimator, and shrinkage helps improving the generalization performance of the classifier. Shrinkage LDA can be used by setting the &lt;code&gt;shrinkage&lt;/code&gt; parameter of the &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt; class to &amp;lsquo;auto&amp;rsquo;. This automatically determines the optimal shrinkage parameter in an analytic way following the lemma introduced by Ledoit and Wolf &lt;a href=&quot;#id6&quot; id=&quot;id4&quot;&gt;2&lt;/a&gt;. Note that currently shrinkage only works when setting the &lt;code&gt;solver&lt;/code&gt; parameter to &amp;lsquo;lsqr&amp;rsquo; or &amp;lsquo;eigen&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc56f7d6f334df6e1bf7e25fb6694a2b96d3283e" translate="yes" xml:space="preserve">
          <source>Shrinkage is a tool to improve estimation of covariance matrices in situations where the number of training samples is small compared to the number of features. In this scenario, the empirical sample covariance is a poor estimator. Shrinkage LDA can be used by setting the &lt;code&gt;shrinkage&lt;/code&gt; parameter of the &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt; class to &amp;lsquo;auto&amp;rsquo;. This automatically determines the optimal shrinkage parameter in an analytic way following the lemma introduced by Ledoit and Wolf &lt;a href=&quot;#id5&quot; id=&quot;id3&quot;&gt;[4]&lt;/a&gt;. Note that currently shrinkage only works when setting the &lt;code&gt;solver&lt;/code&gt; parameter to &amp;lsquo;lsqr&amp;rsquo; or &amp;lsquo;eigen&amp;rsquo;.</source>
          <target state="translated">La contracci&amp;oacute;n es una herramienta para mejorar la estimaci&amp;oacute;n de matrices de covarianza en situaciones en las que el n&amp;uacute;mero de muestras de entrenamiento es peque&amp;ntilde;o en comparaci&amp;oacute;n con el n&amp;uacute;mero de caracter&amp;iacute;sticas. En este escenario, la covarianza de la muestra emp&amp;iacute;rica es un estimador deficiente. El LDA de contracci&amp;oacute;n se puede utilizar estableciendo el par&amp;aacute;metro de &lt;code&gt;shrinkage&lt;/code&gt; de la clase &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt; en 'auto'. Esto determina autom&amp;aacute;ticamente el par&amp;aacute;metro de contracci&amp;oacute;n &amp;oacute;ptimo de forma anal&amp;iacute;tica siguiendo el lema introducido por Ledoit y Wolf &lt;a href=&quot;#id5&quot; id=&quot;id3&quot;&gt;[4]&lt;/a&gt; . Tenga en cuenta que actualmente la contracci&amp;oacute;n solo funciona cuando se configura el par&amp;aacute;metro del &lt;code&gt;solver&lt;/code&gt; en 'lsqr' o 'eigen'.</target>
        </trans-unit>
        <trans-unit id="7e8136e1a5918ee41b1666fa514179c5cb22402c" translate="yes" xml:space="preserve">
          <source>Shrinkage parameter, possible values:</source>
          <target state="translated">Parámetro de contracción,valores posibles:</target>
        </trans-unit>
        <trans-unit id="b2a27e6ba825492dec9776790877b64e516e75e0" translate="yes" xml:space="preserve">
          <source>Shrunk covariance.</source>
          <target state="translated">Covarianza reducida.</target>
        </trans-unit>
        <trans-unit id="4dcdf0ff13bd4f7b65e07eadf0216796b5d56197" translate="yes" xml:space="preserve">
          <source>Shuffle arrays or sparse matrices in a consistent way</source>
          <target state="translated">Mezclar matrices o matrices dispersas de forma consistente</target>
        </trans-unit>
        <trans-unit id="c0ccd0261920fa2fccaab512e3420b322d650304" translate="yes" xml:space="preserve">
          <source>Shuffle the samples and the features.</source>
          <target state="translated">Mezcle las muestras y las características.</target>
        </trans-unit>
        <trans-unit id="372aba820bed6f2900292d1b119c1b7c02346b33" translate="yes" xml:space="preserve">
          <source>Shuffle the samples.</source>
          <target state="translated">Mezcle las muestras.</target>
        </trans-unit>
        <trans-unit id="bb741d2d7cb4e292767bcf7b4c4d2a7dcedf441d" translate="yes" xml:space="preserve">
          <source>Shuffle-Group(s)-Out cross-validation iterator</source>
          <target state="translated">Grupo(s)de barajado-iterador de validación cruzada</target>
        </trans-unit>
        <trans-unit id="04a76dd0a6286b28de9940305c73988458741a00" translate="yes" xml:space="preserve">
          <source>Signed distance is positive for an inlier and negative for an outlier.</source>
          <target state="translated">La distancia señalada es positiva para un valor atípico y negativa para un valor atípico.</target>
        </trans-unit>
        <trans-unit id="175a8f49ca538859a1536806ea283ecf7546e18e" translate="yes" xml:space="preserve">
          <source>Signed distance to the separating hyperplane.</source>
          <target state="translated">La distancia señalada al hiperplano de separación.</target>
        </trans-unit>
        <trans-unit id="bdea7e4b3b56af1c4dc44f101507e6d5fde4c3c5" translate="yes" xml:space="preserve">
          <source>Silhouette Coefficient for each samples.</source>
          <target state="translated">Coeficiente de Silueta para cada muestra.</target>
        </trans-unit>
        <trans-unit id="cef2e4d37f21e366fe4348cb5c8e3de442e95913" translate="yes" xml:space="preserve">
          <source>Silhouette analysis can be used to study the separation distance between the resulting clusters. The silhouette plot displays a measure of how close each point in one cluster is to points in the neighboring clusters and thus provides a way to assess parameters like number of clusters visually. This measure has a range of [-1, 1].</source>
          <target state="translated">El análisis de siluetas puede utilizarse para estudiar la distancia de separación entre los cúmulos resultantes.El gráfico de silueta muestra una medida de cuán cerca está cada punto de un cúmulo de los puntos de los cúmulos vecinos y por lo tanto proporciona una forma de evaluar visualmente parámetros como el número de cúmulos.Esta medida tiene un rango de [-1,1].</target>
        </trans-unit>
        <trans-unit id="f28647d65c56d46a3ca67f993f108ac366d59691" translate="yes" xml:space="preserve">
          <source>Silhouette coefficients (as these values are referred to as) near +1 indicate that the sample is far away from the neighboring clusters. A value of 0 indicates that the sample is on or very close to the decision boundary between two neighboring clusters and negative values indicate that those samples might have been assigned to the wrong cluster.</source>
          <target state="translated">Los coeficientes de silueta (como se denominan estos valores)cerca de +1 indican que la muestra está lejos de los cúmulos vecinos.Un valor de 0 indica que la muestra está en o muy cerca de la frontera de decisión entre dos cúmulos vecinos y los valores negativos indican que esas muestras podrían haber sido asignadas al cúmulo equivocado.</target>
        </trans-unit>
        <trans-unit id="88d328be635604c256d2743bcb180fd1daab0b36" translate="yes" xml:space="preserve">
          <source>Similar feature extractors should be built for other kind of unstructured data input such as images, audio, video, &amp;hellip;</source>
          <target state="translated">Se deben construir extractores de caracter&amp;iacute;sticas similares para otro tipo de entrada de datos no estructurados, como im&amp;aacute;genes, audio, video, ...</target>
        </trans-unit>
        <trans-unit id="9be20d5d3cad647d5b5693ebaedd1ee1a23948cc" translate="yes" xml:space="preserve">
          <source>Similar to &lt;a href=&quot;sklearn.model_selection.cross_validate#sklearn.model_selection.cross_validate&quot;&gt;&lt;code&gt;cross_validate&lt;/code&gt;&lt;/a&gt; but only a single metric is permitted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="319655ff7753a6199642b7bf6692dc2bf99bfe55" translate="yes" xml:space="preserve">
          <source>Similar to AgglomerativeClustering, but recursively merges features instead of samples.</source>
          <target state="translated">Similar a la Agrupación Aglomerativa,pero fusiona recursivamente características en lugar de muestras.</target>
        </trans-unit>
        <trans-unit id="133d603767b5dc043e4bab49b5255c4ddd0f05fe" translate="yes" xml:space="preserve">
          <source>Similar to NuSVC, for regression, uses a parameter nu to control the number of support vectors. However, unlike NuSVC, where nu replaces C, here nu replaces the parameter epsilon of epsilon-SVR.</source>
          <target state="translated">Similar a NuSVC,para la regresión,utiliza un parámetro nu para controlar el número de vectores de apoyo.Sin embargo,a diferencia de NuSVC,donde nu sustituye a C,aquí nu sustituye al parámetro épsilon de épsilon-SVR.</target>
        </trans-unit>
        <trans-unit id="d1a2b055f0753742d67fc90d1d4811e0a5d9ab30" translate="yes" xml:space="preserve">
          <source>Similar to SVC but uses a parameter to control the number of support vectors.</source>
          <target state="translated">Es similar a la SVC pero utiliza un parámetro para controlar el número de vectores de apoyo.</target>
        </trans-unit>
        <trans-unit id="367343dd50d61c27ddbb7a06df2fb9885bdf8a5f" translate="yes" xml:space="preserve">
          <source>Similar to SVC with parameter kernel=&amp;rsquo;linear&amp;rsquo;, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.</source>
          <target state="translated">Similar a SVC con par&amp;aacute;metro kernel = 'linear', pero implementado en t&amp;eacute;rminos de liblinear en lugar de libsvm, por lo que tiene m&amp;aacute;s flexibilidad en la elecci&amp;oacute;n de penalizaciones y funciones de p&amp;eacute;rdida y deber&amp;iacute;a escalar mejor a un gran n&amp;uacute;mero de muestras.</target>
        </trans-unit>
        <trans-unit id="3ec63304462f4cbac1c3a261d38d9188bcded830" translate="yes" xml:space="preserve">
          <source>Similar to SVR with parameter kernel=&amp;rsquo;linear&amp;rsquo;, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.</source>
          <target state="translated">Similar a SVR con par&amp;aacute;metro kernel = 'linear', pero implementado en t&amp;eacute;rminos de liblinear en lugar de libsvm, por lo que tiene m&amp;aacute;s flexibilidad en la elecci&amp;oacute;n de penalizaciones y funciones de p&amp;eacute;rdida y deber&amp;iacute;a escalar mejor a un gran n&amp;uacute;mero de muestras.</target>
        </trans-unit>
        <trans-unit id="997a429b680aeb0ca7576cadadd68b1d30fd4132" translate="yes" xml:space="preserve">
          <source>Similar to other boosting algorithms GBRT builds the additive model in a forward stagewise fashion:</source>
          <target state="translated">Al igual que otros algoritmos de impulso,el GBRT construye el modelo aditivo de forma escalonada hacia adelante:</target>
        </trans-unit>
        <trans-unit id="76a1a1878f09aac58b35d999b125160a70440000" translate="yes" xml:space="preserve">
          <source>Similar to other boosting algorithms, a GBRT is built in a greedy fashion:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9dba587c665016505432ed3d83545171f96e0b75" translate="yes" xml:space="preserve">
          <source>Similarity between individual biclusters is computed. Then the best matching between sets is found using the Hungarian algorithm. The final score is the sum of similarities divided by the size of the larger set.</source>
          <target state="translated">Se calcula la similitud entre los biclusters individuales.Luego se encuentra la mejor coincidencia entre los conjuntos usando el algoritmo húngaro.La puntuación final es la suma de las similitudes dividida por el tamaño del conjunto mayor.</target>
        </trans-unit>
        <trans-unit id="a365c849553e02aafca0dfedfc5010bc90d3ae71" translate="yes" xml:space="preserve">
          <source>Similarity score between -1.0 and 1.0. Random labelings have an ARI close to 0.0. 1.0 stands for perfect match.</source>
          <target state="translated">Puntaje de similitud entre -1.0 y 1.0.Las etiquetas aleatorias tienen un ARI cercano a 0.0.1.0 significa una coincidencia perfecta.</target>
        </trans-unit>
        <trans-unit id="186186d91781f080c251077ac03fc20cf1639d0c" translate="yes" xml:space="preserve">
          <source>Similarly, &lt;a href=&quot;generated/sklearn.model_selection.repeatedstratifiedkfold#sklearn.model_selection.RepeatedStratifiedKFold&quot;&gt;&lt;code&gt;RepeatedStratifiedKFold&lt;/code&gt;&lt;/a&gt; repeats Stratified K-Fold n times with different randomization in each repetition.</source>
          <target state="translated">De manera similar, &lt;a href=&quot;generated/sklearn.model_selection.repeatedstratifiedkfold#sklearn.model_selection.RepeatedStratifiedKFold&quot;&gt; &lt;code&gt;RepeatedStratifiedKFold&lt;/code&gt; &lt;/a&gt; repite Stratified K-Fold n veces con diferente aleatorizaci&amp;oacute;n en cada repetici&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="01f578d801e5d1ea722f26bf3985038251d17ab9" translate="yes" xml:space="preserve">
          <source>Similarly, L1 regularized logistic regression solves the following optimization problem</source>
          <target state="translated">De manera similar,la regresión logística regularizada de L1 resuelve el siguiente problema de optimización</target>
        </trans-unit>
        <trans-unit id="904046bd05dcb9fe24c66e7942e9a89936649854" translate="yes" xml:space="preserve">
          <source>Similarly, \(\ell_1\) regularized logistic regression solves the following optimization problem:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8ee1f0c1cff57e37c89253984120399103de69b" translate="yes" xml:space="preserve">
          <source>Similarly, a negative monotonic constraint is of the form:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="33d5515f485c474434afb456d44ce55ecb3a831d" translate="yes" xml:space="preserve">
          <source>Similarly, labels not present in the data sample may be accounted for in macro-averaging.</source>
          <target state="translated">Análogamente,las etiquetas no presentes en la muestra de datos pueden contabilizarse en el macropromedio.</target>
        </trans-unit>
        <trans-unit id="de3a0306d5f9d4f628a86437bd31f501c79f2495" translate="yes" xml:space="preserve">
          <source>Similarly, the precision recall curve can be plotted using &lt;code&gt;y_score&lt;/code&gt; from the prevision sections.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c868e091c0bbbbc855227dfcc9797f545ef094e" translate="yes" xml:space="preserve">
          <source>Simple 1D Kernel Density Estimation</source>
          <target state="translated">Estimación simple de la densidad del núcleo 1D</target>
        </trans-unit>
        <trans-unit id="f5468d7aca1a86ccbbf784d0772796020bb33f7b" translate="yes" xml:space="preserve">
          <source>Simple to understand and to interpret. Trees can be visualised.</source>
          <target state="translated">Simple de entender e interpretar.Los árboles pueden ser visualizados.</target>
        </trans-unit>
        <trans-unit id="954c17f332cbfd66dfa98282859837f21d64fd6a" translate="yes" xml:space="preserve">
          <source>Simple usage of Pipeline that runs successively a univariate feature selection with anova and then a C-SVM of the selected features.</source>
          <target state="translated">Uso simple de Pipeline que ejecuta sucesivamente una selección univariante de características con anova y luego un C-SVM de las características seleccionadas.</target>
        </trans-unit>
        <trans-unit id="e7766eb7ad8cfdfa67609d5277fb9ac991ed77ce" translate="yes" xml:space="preserve">
          <source>Simple usage of Pipeline that runs successively a univariate feature selection with anova and then a SVM of the selected features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50f8d26df97413619de7bb6966a9aa041cc32e16" translate="yes" xml:space="preserve">
          <source>Simple usage of Support Vector Machines to classify a sample. It will plot the decision surface and the support vectors.</source>
          <target state="translated">El simple uso de Máquinas Vectoriales de Apoyo para clasificar una muestra.Trazará la superficie de decisión y los vectores de apoyo.</target>
        </trans-unit>
        <trans-unit id="5b50d9c69163fc1e922706c7d40ea5de7c4c3507" translate="yes" xml:space="preserve">
          <source>Simple usage of various cross decomposition algorithms: - PLSCanonical - PLSRegression, with multivariate response, a.k.a. PLS2 - PLSRegression, with univariate response, a.k.a. PLS1 - CCA</source>
          <target state="translated">Uso simple de varios algoritmos de descomposición cruzada:-PLSCanonical-PLSRegresión,con respuesta multivariante,también conocido como PLS2-PLSRegresión,con respuesta univariante,también conocido como PLS1-CCA</target>
        </trans-unit>
        <trans-unit id="da21ac2a81c42a0cc34c3a8c8243f3f710d2f668" translate="yes" xml:space="preserve">
          <source>SimpleImputer</source>
          <target state="translated">SimpleImputer</target>
        </trans-unit>
        <trans-unit id="0cd5c8d669edd41f72cf141b1f653ffc3a8f7d8a" translate="yes" xml:space="preserve">
          <source>Simply perform a svd on the crosscovariance matrix: X&amp;rsquo;Y There are no iterative deflation here.</source>
          <target state="translated">Simplemente realice un svd en la matriz de covarianza cruzada: X'Y Aqu&amp;iacute; no hay deflaci&amp;oacute;n iterativa.</target>
        </trans-unit>
        <trans-unit id="f72f0eda605215d24ff9d1908550395272883fb4" translate="yes" xml:space="preserve">
          <source>Simulations</source>
          <target state="translated">Simulations</target>
        </trans-unit>
        <trans-unit id="2e04b6f26b355099b78d114e001527cec11f01b3" translate="yes" xml:space="preserve">
          <source>Since \(P(x_1, \dots, x_n)\) is constant given the input, we can use the following classification rule:</source>
          <target state="translated">Dado que \ ~ (P(x_1,\ ~ puntos,x_n)\ ~ es constante dada la entrada,podemos utilizar la siguiente regla de clasificación:</target>
        </trans-unit>
        <trans-unit id="4ed5170dfb2a4a5fe27dc284ef1f79230346d84b" translate="yes" xml:space="preserve">
          <source>Since a model internal representation may be different on two different architectures, dumping a model on one architecture and loading it on another architecture is not supported.</source>
          <target state="translated">Dado que la representación interna de un modelo puede ser diferente en dos arquitecturas diferentes,no se admite la descarga de un modelo en una arquitectura y su carga en otra arquitectura.</target>
        </trans-unit>
        <trans-unit id="2e7dca0922f252e8bcb5dd7de62f190d029edf35" translate="yes" xml:space="preserve">
          <source>Since a simple modulo is used to transform the hash function to a column index, it is advisable to use a power of two as the &lt;code&gt;n_features&lt;/code&gt; parameter; otherwise the features will not be mapped evenly to the columns.</source>
          <target state="translated">Dado que se usa un m&amp;oacute;dulo simple para transformar la funci&amp;oacute;n hash en un &amp;iacute;ndice de columna, es aconsejable usar una potencia de dos como par&amp;aacute;metro &lt;code&gt;n_features&lt;/code&gt; ; de lo contrario, las entidades no se asignar&amp;aacute;n uniformemente a las columnas.</target>
        </trans-unit>
        <trans-unit id="e94526c23963e4af6db5a385aa61965ac4ba9d0e" translate="yes" xml:space="preserve">
          <source>Since it requires to fit &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; classifiers, this method is usually slower than one-vs-the-rest, due to its O(n_classes^2) complexity. However, this method may be advantageous for algorithms such as kernel algorithms which don&amp;rsquo;t scale well with &lt;code&gt;n_samples&lt;/code&gt;. This is because each individual learning problem only involves a small subset of the data whereas, with one-vs-the-rest, the complete dataset is used &lt;code&gt;n_classes&lt;/code&gt; times.</source>
          <target state="translated">Dado que requiere adaptarse a &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; clasificadores, este m&amp;eacute;todo suele ser m&amp;aacute;s lento que uno contra el resto, debido a su complejidad O (n_classes ^ 2). Sin embargo, este m&amp;eacute;todo puede resultar ventajoso para algoritmos como los del kernel que no escalan bien con &lt;code&gt;n_samples&lt;/code&gt; . Esto se debe a que cada problema de aprendizaje individual solo involucra un peque&amp;ntilde;o subconjunto de los datos mientras que, con uno contra el resto, el conjunto de datos completo se usa &lt;code&gt;n_classes&lt;/code&gt; veces.</target>
        </trans-unit>
        <trans-unit id="d70a1912c85de6341311b3ee0902966d17cafa41" translate="yes" xml:space="preserve">
          <source>Since it requires to fit &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; classifiers, this method is usually slower than one-vs-the-rest, due to its O(n_classes^2) complexity. However, this method may be advantageous for algorithms such as kernel algorithms which don&amp;rsquo;t scale well with &lt;code&gt;n_samples&lt;/code&gt;. This is because each individual learning problem only involves a small subset of the data whereas, with one-vs-the-rest, the complete dataset is used &lt;code&gt;n_classes&lt;/code&gt; times. The decision function is the result of a monotonic transformation of the one-versus-one classification.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="885cdc36b68d6b1fe527d22b8af012efa7ee88fc" translate="yes" xml:space="preserve">
          <source>Since our loss function is dependent on the amount of samples, the latter will influence the selected value of &lt;code&gt;C&lt;/code&gt;. The question that arises is &lt;code&gt;How do we optimally adjust C to account for the different amount of training samples?&lt;/code&gt;</source>
          <target state="translated">Desde nuestra funci&amp;oacute;n de p&amp;eacute;rdida depende de la cantidad de muestras, &amp;eacute;ste influir&amp;aacute; en el valor seleccionado de &lt;code&gt;C&lt;/code&gt; . La pregunta que surge es &lt;code&gt;How do we optimally adjust C to account for the different amount of training samples?&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="8414cbee67356c2ab2c8ba5220ad5c2247b09cc6" translate="yes" xml:space="preserve">
          <source>Since recursive partitioning can be represented by a tree structure, the number of splittings required to isolate a sample is equivalent to the path length from the root node to the terminating node.</source>
          <target state="translated">Dado que la partición recursiva puede representarse mediante una estructura de árbol,el número de particiones necesarias para aislar una muestra equivale a la longitud del trayecto desde el nodo raíz hasta el nodo terminal.</target>
        </trans-unit>
        <trans-unit id="e0effd5f72f2afc7c618332a9b819d624a406e57" translate="yes" xml:space="preserve">
          <source>Since the L1 norm promotes sparsity of features we might be interested in selecting only a subset of the most interesting features from the dataset. This example shows how to select two the most interesting features from the diabetes dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53564a374f656b4eebc264b9099b9cd10a25ad1a" translate="yes" xml:space="preserve">
          <source>Since the Poisson regressor internally models the log of the expected target value instead of the expected value directly (log vs identity link function), the relationship between X and y is not exactly linear anymore. Therefore the Poisson regressor is called a Generalized Linear Model (GLM) rather than a vanilla linear model as is the case for Ridge regression.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41606a5be005625c4678c2fc6968d98c5bcdacbb" translate="yes" xml:space="preserve">
          <source>Since the hash function might cause collisions between (unrelated) features, a signed hash function is used and the sign of the hash value determines the sign of the value stored in the output matrix for a feature. This way, collisions are likely to cancel out rather than accumulate error, and the expected mean of any output feature&amp;rsquo;s value is zero. This mechanism is enabled by default with &lt;code&gt;alternate_sign=True&lt;/code&gt; and is particularly useful for small hash table sizes (&lt;code&gt;n_features &amp;lt; 10000&lt;/code&gt;). For large hash table sizes, it can be disabled, to allow the output to be passed to estimators like &lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt;&lt;code&gt;sklearn.naive_bayes.MultinomialNB&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt;&lt;code&gt;sklearn.feature_selection.chi2&lt;/code&gt;&lt;/a&gt; feature selectors that expect non-negative inputs.</source>
          <target state="translated">Dado que la funci&amp;oacute;n hash puede causar colisiones entre caracter&amp;iacute;sticas (no relacionadas), se utiliza una funci&amp;oacute;n hash firmada y el signo del valor hash determina el signo del valor almacenado en la matriz de salida para una caracter&amp;iacute;stica. De esta manera, es probable que las colisiones se cancelen en lugar de acumular errores, y la media esperada del valor de cualquier caracter&amp;iacute;stica de salida es cero. Este mecanismo est&amp;aacute; habilitado de forma predeterminada con &lt;code&gt;alternate_sign=True&lt;/code&gt; y es particularmente &amp;uacute;til para tama&amp;ntilde;os de tabla hash peque&amp;ntilde;os ( &lt;code&gt;n_features &amp;lt; 10000&lt;/code&gt; ). Para tama&amp;ntilde;os de tabla hash grandes, se puede deshabilitar para permitir que la salida se pase a estimadores como &lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt; &lt;code&gt;sklearn.naive_bayes.MultinomialNB&lt;/code&gt; &lt;/a&gt; o &lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt; &lt;code&gt;sklearn.feature_selection.chi2&lt;/code&gt; &lt;/a&gt; selectores de funciones que esperan entradas no negativas.</target>
        </trans-unit>
        <trans-unit id="91020f655b0d3976000fc58a456fa0d94621c5a6" translate="yes" xml:space="preserve">
          <source>Since the kernel that is to be approximated is additive, the components of the input vectors can be treated separately. Each entry in the original space is transformed into 2*sample_steps+1 features, where sample_steps is a parameter of the method. Typical values of sample_steps include 1, 2 and 3.</source>
          <target state="translated">Dado que el núcleo que se va a aproximar es aditivo,los componentes de los vectores de entrada pueden tratarse por separado.Cada entrada del espacio original se transforma en 2*sample_steps+1 características,donde sample_steps es un parámetro del método.Los valores típicos de sample_steps incluyen 1,2 y 3.</target>
        </trans-unit>
        <trans-unit id="eab55792648442f25c33ef137afa5ea98f14550a" translate="yes" xml:space="preserve">
          <source>Since the linear predictor \(Xw\) can be negative and Poisson, Gamma and Inverse Gaussian distributions don&amp;rsquo;t support negative values, it is necessary to apply an inverse link function that guarantees the non-negativeness. For example with &lt;code&gt;link='log'&lt;/code&gt;, the inverse link function becomes \(h(Xw)=\exp(Xw)\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dac98c213a89fd4774cf1c1f95b63e10c23ed6ab" translate="yes" xml:space="preserve">
          <source>Since the posterior is intractable, variational Bayesian method uses a simpler distribution \(q(z,\theta,\beta | \lambda, \phi, \gamma)\) to approximate it, and those variational parameters \(\lambda\), \(\phi\), \(\gamma\) are optimized to maximize the Evidence Lower Bound (ELBO):</source>
          <target state="translated">Como la parte posterior es intratable,el método bayesiano variacional utiliza una distribución más simple (q(z,|theta,|beta |lambda,\ ~ -phi,\ ~ -gamma)para aproximarse a ella,y esos parámetros variacionales (\ ~ -lambda),(\ ~ -phi,\ ~ -gamma)están optimizados para maximizar la Evidencia de Límite Inferior (ELBO):</target>
        </trans-unit>
        <trans-unit id="ce93b96a689b29304c626bbff15b3c9ae5662f8f" translate="yes" xml:space="preserve">
          <source>Since the thresholds are sorted from low to high values, they are reversed upon returning them to ensure they correspond to both &lt;code&gt;fpr&lt;/code&gt; and &lt;code&gt;tpr&lt;/code&gt;, which are sorted in reversed order during their calculation.</source>
          <target state="translated">Dado que los umbrales est&amp;aacute;n ordenados de menor a valores elevados, que se invierten al regresar ellos para asegurar que corresponden a ambos &lt;code&gt;fpr&lt;/code&gt; y &lt;code&gt;tpr&lt;/code&gt; , que est&amp;aacute;n ordenadas en orden inverso durante su c&amp;aacute;lculo.</target>
        </trans-unit>
        <trans-unit id="7f69d32984c3b4f143cfa37bb4e60432050ed0eb" translate="yes" xml:space="preserve">
          <source>Since there has not been much empirical work using approximate embeddings, it is advisable to compare results against exact kernel methods when possible.</source>
          <target state="translated">Dado que no se ha realizado mucho trabajo empírico utilizando incrustaciones aproximadas,es aconsejable comparar los resultados con los métodos de núcleo exacto cuando sea posible.</target>
        </trans-unit>
        <trans-unit id="181ed345f14e5249ac33bd9934643c4f9dd72c8f" translate="yes" xml:space="preserve">
          <source>Since v0.21, if &lt;code&gt;input&lt;/code&gt; is &lt;code&gt;filename&lt;/code&gt; or &lt;code&gt;file&lt;/code&gt;, the data is first read from the file and then passed to the given callable analyzer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa984969d0a90a5820c4fc022c64bfc47ca5a084" translate="yes" xml:space="preserve">
          <source>Single estimator versus bagging: bias-variance decomposition</source>
          <target state="translated">Estimador único versus embolsado:Descomposición de sesgo-varianza</target>
        </trans-unit>
        <trans-unit id="c2fe1a00c3aef2fdadf0dd5e7ea7933f55e2ab1b" translate="yes" xml:space="preserve">
          <source>Single metric evaluation using &lt;code&gt;cross_validate&lt;/code&gt;</source>
          <target state="translated">Evaluaci&amp;oacute;n de m&amp;eacute;trica &amp;uacute;nica mediante &lt;code&gt;cross_validate&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="78a22764fe4a9b48a649589e690300655f65c80d" translate="yes" xml:space="preserve">
          <source>Single, average and complete linkage can be used with a variety of distances (or affinities), in particular Euclidean distance (&lt;em&gt;l2&lt;/em&gt;), Manhattan distance (or Cityblock, or &lt;em&gt;l1&lt;/em&gt;), cosine distance, or any precomputed affinity matrix.</source>
          <target state="translated">El enlace simple, medio y completo se puede utilizar con una variedad de distancias (o afinidades), en particular distancia euclidiana ( &lt;em&gt;l2&lt;/em&gt; ), distancia de Manhattan (o Cityblock, o &lt;em&gt;l1&lt;/em&gt; ), distancia de coseno o cualquier matriz de afinidad precalculada.</target>
        </trans-unit>
        <trans-unit id="b1a526a4c2ab5cc879cbcf97bbdfc6e58be65f64" translate="yes" xml:space="preserve">
          <source>Singular values of &lt;code&gt;X&lt;/code&gt;. Only available when &lt;code&gt;X&lt;/code&gt; is dense.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="409f99dea48046b433f18bebd495f19a0bb51787" translate="yes" xml:space="preserve">
          <source>Singularities</source>
          <target state="translated">Singularities</target>
        </trans-unit>
        <trans-unit id="857a843ae0f540aecaddebae91ddc74b518d5cf4" translate="yes" xml:space="preserve">
          <source>Singularities:</source>
          <target state="translated">Singularities:</target>
        </trans-unit>
        <trans-unit id="2df59d349ec07bd33a82cdc2b0c4c3d4152244c6" translate="yes" xml:space="preserve">
          <source>Size of minibatches for stochastic optimizers. If the solver is &amp;lsquo;lbfgs&amp;rsquo;, the classifier will not use minibatch. When set to &amp;ldquo;auto&amp;rdquo;, &lt;code&gt;batch_size=min(200, n_samples)&lt;/code&gt;</source>
          <target state="translated">Tama&amp;ntilde;o de minibatches para optimizadores estoc&amp;aacute;sticos. Si el solucionador es 'lbfgs', el clasificador no usar&amp;aacute; minibatch. Cuando se establece en &quot;auto&quot;, &lt;code&gt;batch_size=min(200, n_samples)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7241ed1ae94944f10d565b9b8502a2569d69bebc" translate="yes" xml:space="preserve">
          <source>Size of text font. If None, determined automatically to fit figure.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa65aa30a853af1cf81f53119b6649c5aa5e2817" translate="yes" xml:space="preserve">
          <source>Size of the blocks into which the covariance matrix will be split during its Ledoit-Wolf estimation. This is purely a memory optimization and does not affect results.</source>
          <target state="translated">Tamaño de los bloques en los que se dividirá la matriz de covarianza durante su estimación de Ledoit-Wolf.Esto es puramente una optimización de la memoria y no afecta a los resultados.</target>
        </trans-unit>
        <trans-unit id="3bdf2049b3b05b0720764317c09e88bc19700eec" translate="yes" xml:space="preserve">
          <source>Size of the blocks into which the covariance matrix will be split. This is purely a memory optimization and does not affect results.</source>
          <target state="translated">El tamaño de los bloques en los que se dividirá la matriz de covarianza.Esto es puramente una optimización de la memoria y no afecta a los resultados.</target>
        </trans-unit>
        <trans-unit id="612eb8e8a229547855d2a4c02d66bbe2afb0395a" translate="yes" xml:space="preserve">
          <source>Size of the mini batches.</source>
          <target state="translated">El tamaño de los mini lotes.</target>
        </trans-unit>
        <trans-unit id="aa636a80a54912b13ca3fa6029e0a40e02f80415" translate="yes" xml:space="preserve">
          <source>Size of the return array</source>
          <target state="translated">El tamaño de la matriz de retorno</target>
        </trans-unit>
        <trans-unit id="08f603d3fe1f30df7982a9a08f592731c9eab73e" translate="yes" xml:space="preserve">
          <source>Size of the test sets.</source>
          <target state="translated">El tamaño de los juegos de prueba.</target>
        </trans-unit>
        <trans-unit id="3ede3a7d9dde54c062e45da23a9dc65bbb39cbbf" translate="yes" xml:space="preserve">
          <source>Size of the test sets. Must be strictly less than the number of samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d7d650781fdf69336502b899ccd5c9f80ba4848" translate="yes" xml:space="preserve">
          <source>Skip input validation checks, including the Gram matrix when provided assuming there are handled by the caller when check_input=False.</source>
          <target state="translated">Saltar las verificaciones de validación de entrada,incluyendo la matriz de Gram cuando se proporciona asumiendo que son manejadas por el llamante cuando check_input=False.</target>
        </trans-unit>
        <trans-unit id="119077d89fb1cbe89db9591404feee43530ef290" translate="yes" xml:space="preserve">
          <source>Slides explaining PLS</source>
          <target state="translated">Diapositivas que explican el PLS</target>
        </trans-unit>
        <trans-unit id="c3d721c0cfe644c7ca720484ae796856345cb087" translate="yes" xml:space="preserve">
          <source>Small outliers</source>
          <target state="translated">Pequeños valores atípicos</target>
        </trans-unit>
        <trans-unit id="6cf8c0d1548c80d5c7b8e80adf89b56b8a30e60f" translate="yes" xml:space="preserve">
          <source>Small positive values of alpha improve the conditioning of the problem and reduce the variance of the estimates. Alpha corresponds to &lt;code&gt;(2*C)^-1&lt;/code&gt; in other linear models such as LogisticRegression or LinearSVC. If an array is passed, penalties are assumed to be specific to the targets. Hence they must correspond in number.</source>
          <target state="translated">Los peque&amp;ntilde;os valores positivos de alfa mejoran el condicionamiento del problema y reducen la varianza de las estimaciones. Alpha corresponde a &lt;code&gt;(2*C)^-1&lt;/code&gt; en otros modelos lineales como LogisticRegression o LinearSVC. Si se pasa una matriz, se supone que las penalizaciones son espec&amp;iacute;ficas de los objetivos. Por tanto, deben corresponder en n&amp;uacute;mero.</target>
        </trans-unit>
        <trans-unit id="8e135bd52bd2eb3356a694f0d8575402c5375bb6" translate="yes" xml:space="preserve">
          <source>Smaller values lead to better embedding and higher number of dimensions (n_components) in the target projection space.</source>
          <target state="translated">Valores más pequeños conducen a una mejor incrustación y un mayor número de dimensiones (n_componentes)en el espacio de proyección del objetivo.</target>
        </trans-unit>
        <trans-unit id="178a5fd9e6a787566f82c9ecbd118e48b0edcccd" translate="yes" xml:space="preserve">
          <source>Smallest value of alpha / alpha_max considered</source>
          <target state="translated">El valor más pequeño de alfa/alfa_máximo considerado</target>
        </trans-unit>
        <trans-unit id="9ec75e4c898141f811f9d6fe4e66f6da7a97bb9c" translate="yes" xml:space="preserve">
          <source>Smooth idf weights by adding one to document frequencies, as if an extra document was seen containing every term in the collection exactly once. Prevents zero divisions.</source>
          <target state="translated">Suaviza los pesos del idf añadiendo uno a las frecuencias de los documentos,como si se viera un documento extra que contiene cada término de la colección exactamente una vez.Evita las divisiones por cero.</target>
        </trans-unit>
        <trans-unit id="8ec8b1649217676578a05802f05dc4dfdec72ebc" translate="yes" xml:space="preserve">
          <source>Smoothed empirical log probability for each class.</source>
          <target state="translated">Suavizó la probabilidad logarítmica empírica de cada clase.</target>
        </trans-unit>
        <trans-unit id="d5d952f65cbc310a8284a0aa676904d4b84a635c" translate="yes" xml:space="preserve">
          <source>Smoothed empirical log probability for each class. Only used in edge case with a single class in the training set.</source>
          <target state="translated">Suavizó la probabilidad logarítmica empírica de cada clase.Sólo se utiliza en caso de borde con una sola clase en el conjunto de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="fb1739757cbc4d2da964b132a46ededacd98a2aa" translate="yes" xml:space="preserve">
          <source>Soft Voting/Majority Rule classifier for unfitted estimators.</source>
          <target state="translated">Clasificador de Voto Suave/Regla de Mayoría para estimadores no aptos.</target>
        </trans-unit>
        <trans-unit id="3c16977f20db1a9e128b2062c246165103dd7921" translate="yes" xml:space="preserve">
          <source>Soft Voting/Majority Rule classifier.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a33a62c21ea4043dbf31a4f6ee598307b73aa466" translate="yes" xml:space="preserve">
          <source>Soft hint to choose the default backend if no specific backend was selected with the parallel_backend context manager. The default process-based backend is &amp;lsquo;loky&amp;rsquo; and the default thread-based backend is &amp;lsquo;threading&amp;rsquo;.</source>
          <target state="translated">Sugerencia suave para elegir el backend predeterminado si no se seleccion&amp;oacute; ning&amp;uacute;n backend espec&amp;iacute;fico con el administrador de contexto paralelo_backend. El backend predeterminado basado en procesos es 'loky' y el backend predeterminado basado en subprocesos es 'threading'.</target>
        </trans-unit>
        <trans-unit id="9653b7a05f5df3e5d87561ce96e265c541ad8c31" translate="yes" xml:space="preserve">
          <source>SokalMichenerDistance</source>
          <target state="translated">SokalMichenerDistance</target>
        </trans-unit>
        <trans-unit id="01ed2fbc860294634b46d80d008798b47284ef75" translate="yes" xml:space="preserve">
          <source>SokalSneathDistance</source>
          <target state="translated">SokalSneathDistance</target>
        </trans-unit>
        <trans-unit id="7472593b6d35821b7f5c4104f85f3418ec74c28e" translate="yes" xml:space="preserve">
          <source>Solution to the non-negative least squares problem.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b76645291a4941abead277af175738d7e9485f1" translate="yes" xml:space="preserve">
          <source>Solution: &lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_digits_classification_exercise.py&quot;&gt;&lt;code&gt;../../auto_examples/exercises/plot_digits_classification_exercise.py&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">Soluci&amp;oacute;n: &lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_digits_classification_exercise.py&quot;&gt; &lt;code&gt;../../auto_examples/exercises/plot_digits_classification_exercise.py&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="97a1e21d1798b81e7cea434e741d7087aa2f4a99" translate="yes" xml:space="preserve">
          <source>Solution: &lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_iris_exercise.py&quot;&gt;&lt;code&gt;../../auto_examples/exercises/plot_iris_exercise.py&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">Soluci&amp;oacute;n: &lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_iris_exercise.py&quot;&gt; &lt;code&gt;../../auto_examples/exercises/plot_iris_exercise.py&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="8dc243287f9af0458afdd79c7e208cb930e6e9d1" translate="yes" xml:space="preserve">
          <source>Solution: &lt;a href=&quot;https://scikit-learn.org/0.23/_downloads/91f0cd01beb5b964a5e1ece5bdd15499/plot_iris_exercise.py&quot;&gt;&lt;code&gt;../../auto_examples/exercises/plot_iris_exercise.py&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5a155c549be47525e0ef469c6ede18a502d5bc6" translate="yes" xml:space="preserve">
          <source>Solution: &lt;a href=&quot;https://scikit-learn.org/0.23/_downloads/bfcebce45024b267e8546d6914acfedc/plot_digits_classification_exercise.py&quot;&gt;&lt;code&gt;../../auto_examples/exercises/plot_digits_classification_exercise.py&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="908bab59b18307a14acc0f3d3e00d2c36c09b88e" translate="yes" xml:space="preserve">
          <source>Solve the isotonic regression model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d31ac38ecaa97cd7ca9cf4223578d60df63f89a9" translate="yes" xml:space="preserve">
          <source>Solve the isotonic regression model:</source>
          <target state="translated">Resuelve el modelo de regresión isotónica:</target>
        </trans-unit>
        <trans-unit id="48c6334f59edac84435c4184f66b59babd6924b9" translate="yes" xml:space="preserve">
          <source>Solve the ridge equation by the method of normal equations.</source>
          <target state="translated">Resuelve la ecuación de la cresta por el método de las ecuaciones normales.</target>
        </trans-unit>
        <trans-unit id="b5fa00edfa7fc06c7e99359e114af78ec006b205" translate="yes" xml:space="preserve">
          <source>Solver to use in the computational routines:</source>
          <target state="translated">Resolver para usar en las rutinas de computación:</target>
        </trans-unit>
        <trans-unit id="5c136e6e68fedeebc5e62ea492bdc13f5c51a357" translate="yes" xml:space="preserve">
          <source>Solver to use, possible values:</source>
          <target state="translated">Resolver para usar,posibles valores:</target>
        </trans-unit>
        <trans-unit id="577db6a48ff5a1db9c02bebc0320d90f752c60ef" translate="yes" xml:space="preserve">
          <source>Solves a dictionary learning matrix factorization problem online.</source>
          <target state="translated">Resuelve un problema de factorización de la matriz de aprendizaje de un diccionario en línea.</target>
        </trans-unit>
        <trans-unit id="8820b686f5bac3c2f3bf8f93441f10523c0fe031" translate="yes" xml:space="preserve">
          <source>Solves a dictionary learning matrix factorization problem.</source>
          <target state="translated">Resuelve un problema de factorización de la matriz de aprendizaje de un diccionario.</target>
        </trans-unit>
        <trans-unit id="b22d518aabf32cc9c9347bf653295056dc359f7f" translate="yes" xml:space="preserve">
          <source>Solves n_targets Orthogonal Matching Pursuit problems using only the Gram matrix X.T * X and the product X.T * y.</source>
          <target state="translated">Resuelve los problemas de n_targets Orthogonal Matching Pursuit usando sólo la matriz de Gram X.T*X y el producto X.T*y.</target>
        </trans-unit>
        <trans-unit id="80547cf29da9d4cc131f68d1680f3500976f9f6f" translate="yes" xml:space="preserve">
          <source>Solves n_targets Orthogonal Matching Pursuit problems. An instance of the problem has the form:</source>
          <target state="translated">Resuelve los problemas de la persecución ortogonal de n_targets.Una instancia del problema tiene la forma:</target>
        </trans-unit>
        <trans-unit id="8d4fd8866d93aa1260a7a3d03ef9a9a9f9a2fc7d" translate="yes" xml:space="preserve">
          <source>Solves the optimization problem:</source>
          <target state="translated">Resuelve el problema de la optimización:</target>
        </trans-unit>
        <trans-unit id="e29fb180670f8bd6283a93ce616785d39e9b899f" translate="yes" xml:space="preserve">
          <source>Some advantages of decision trees are:</source>
          <target state="translated">Algunas ventajas de los árboles de decisión son:</target>
        </trans-unit>
        <trans-unit id="2b6f2b5ee645a40c14b49c77184129b10ec1567a" translate="yes" xml:space="preserve">
          <source>Some also work in the multilabel case:</source>
          <target state="translated">Algunos también trabajan en el caso de las etiquetas múltiples:</target>
        </trans-unit>
        <trans-unit id="8762622dcc16bf1560cb81f69bbd48256b77f9a4" translate="yes" xml:space="preserve">
          <source>Some calculations when implemented using standard numpy vectorized operations involve using a large amount of temporary memory. This may potentially exhaust system memory. Where computations can be performed in fixed-memory chunks, we attempt to do so, and allow the user to hint at the maximum size of this working memory (defaulting to 1GB) using &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt; or &lt;code&gt;config_context&lt;/code&gt;. The following suggests to limit temporary working memory to 128 MiB:</source>
          <target state="translated">Algunos c&amp;aacute;lculos, cuando se implementan utilizando operaciones vectorizadas est&amp;aacute;ndar, implican el uso de una gran cantidad de memoria temporal. Esto puede agotar potencialmente la memoria del sistema. Cuando los c&amp;aacute;lculos se pueden realizar en fragmentos de memoria fija, intentamos hacerlo y permitimos que el usuario sugiera el tama&amp;ntilde;o m&amp;aacute;ximo de esta memoria de trabajo (predeterminado en 1 GB) usando &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;sklearn.set_config&lt;/code&gt; &lt;/a&gt; o &lt;code&gt;config_context&lt;/code&gt; . Lo siguiente sugiere limitar la memoria de trabajo temporal a 128 MiB:</target>
        </trans-unit>
        <trans-unit id="f425af2b7289a6eb3b0699842a415a72e1141c04" translate="yes" xml:space="preserve">
          <source>Some classification problems can exhibit a large imbalance in the distribution of the target classes: for instance there could be several times more negative samples than positive samples. In such cases it is recommended to use stratified sampling as implemented in &lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.model_selection.stratifiedshufflesplit#sklearn.model_selection.StratifiedShuffleSplit&quot;&gt;&lt;code&gt;StratifiedShuffleSplit&lt;/code&gt;&lt;/a&gt; to ensure that relative class frequencies is approximately preserved in each train and validation fold.</source>
          <target state="translated">Algunos problemas de clasificaci&amp;oacute;n pueden presentar un gran desequilibrio en la distribuci&amp;oacute;n de las clases objetivo: por ejemplo, podr&amp;iacute;a haber varias veces m&amp;aacute;s muestras negativas que muestras positivas. En tales casos, se recomienda utilizar el muestreo estratificado como se implement&amp;oacute; en &lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;StratifiedKFold&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.model_selection.stratifiedshufflesplit#sklearn.model_selection.StratifiedShuffleSplit&quot;&gt; &lt;code&gt;StratifiedShuffleSplit&lt;/code&gt; &lt;/a&gt; para garantizar que las frecuencias de clase relativas se conserven aproximadamente en cada tren y pliegue de validaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="2ea2f829ceb432ffa0e3b3d420b4273e01e30d41" translate="yes" xml:space="preserve">
          <source>Some cross validation iterators, such as &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt;, have an inbuilt option to shuffle the data indices before splitting them. Note that:</source>
          <target state="translated">Algunos iteradores de validaci&amp;oacute;n cruzada, como &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt; , tienen una opci&amp;oacute;n incorporada para mezclar los &amp;iacute;ndices de datos antes de dividirlos. Tenga en cuenta que:</target>
        </trans-unit>
        <trans-unit id="1b7524a4e391762865d52d4ee865a5a389b3ed4f" translate="yes" xml:space="preserve">
          <source>Some estimators expose a &lt;code&gt;transform&lt;/code&gt; method, for instance to reduce the dimensionality of the dataset.</source>
          <target state="translated">Algunos estimadores exponen un m&amp;eacute;todo de &lt;code&gt;transform&lt;/code&gt; aci&amp;oacute;n , por ejemplo, para reducir la dimensionalidad del conjunto de datos.</target>
        </trans-unit>
        <trans-unit id="abe93a33221be53771cefc563a6b553fa747a230" translate="yes" xml:space="preserve">
          <source>Some literature promotes alternative definitions of balanced accuracy. Our definition is equivalent to &lt;a href=&quot;sklearn.metrics.accuracy_score#sklearn.metrics.accuracy_score&quot;&gt;&lt;code&gt;accuracy_score&lt;/code&gt;&lt;/a&gt; with class-balanced sample weights, and shares desirable properties with the binary case. See the &lt;a href=&quot;../model_evaluation#balanced-accuracy-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">Alguna literatura promueve definiciones alternativas de precisi&amp;oacute;n equilibrada. Nuestra definici&amp;oacute;n es equivalente a &lt;a href=&quot;sklearn.metrics.accuracy_score#sklearn.metrics.accuracy_score&quot;&gt; &lt;code&gt;accuracy_score&lt;/code&gt; &lt;/a&gt; con pesos de muestra equilibrados por clases y comparte propiedades deseables con el caso binario. Consulte la &lt;a href=&quot;../model_evaluation#balanced-accuracy-score&quot;&gt;Gu&amp;iacute;a&lt;/a&gt; del usuario .</target>
        </trans-unit>
        <trans-unit id="65e1dc1251c858f270c665ff61463afe65f478d7" translate="yes" xml:space="preserve">
          <source>Some metrics are essentially defined for binary classification tasks (e.g. &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt;&lt;code&gt;f1_score&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt;). In these cases, by default only the positive label is evaluated, assuming by default that the positive class is labelled &lt;code&gt;1&lt;/code&gt; (though this may be configurable through the &lt;code&gt;pos_label&lt;/code&gt; parameter).</source>
          <target state="translated">Algunas m&amp;eacute;tricas se definen esencialmente para las tareas de clasificaci&amp;oacute;n binaria (por ejemplo &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt; &lt;code&gt;f1_score&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;roc_auc_score&lt;/code&gt; &lt;/a&gt; ). En estos casos, por defecto solo se eval&amp;uacute;a la etiqueta positiva, asumiendo por defecto que la clase positiva est&amp;aacute; etiquetada como &lt;code&gt;1&lt;/code&gt; (aunque esto puede ser configurable mediante el par&amp;aacute;metro &lt;code&gt;pos_label&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="d5ba6b95ba600216ff9982f7a3dbaf94b6802f73" translate="yes" xml:space="preserve">
          <source>Some models allow for specialized, efficient parameter search strategies, &lt;a href=&quot;#alternative-cv&quot;&gt;outlined below&lt;/a&gt;. Two generic approaches to sampling search candidates are provided in scikit-learn: for given values, &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; exhaustively considers all parameter combinations, while &lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt;&lt;code&gt;RandomizedSearchCV&lt;/code&gt;&lt;/a&gt; can sample a given number of candidates from a parameter space with a specified distribution. After describing these tools we detail &lt;a href=&quot;#grid-search-tips&quot;&gt;best practice&lt;/a&gt; applicable to both approaches.</source>
          <target state="translated">Algunos modelos permiten estrategias de b&amp;uacute;squeda de par&amp;aacute;metros especializadas y eficientes, que se &lt;a href=&quot;#alternative-cv&quot;&gt;describen a continuaci&amp;oacute;n&lt;/a&gt; . En scikit-learn se proporcionan dos enfoques gen&amp;eacute;ricos para muestrear candidatos de b&amp;uacute;squeda: para valores dados, &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt; considera exhaustivamente todas las combinaciones de par&amp;aacute;metros, mientras que &lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt; &lt;code&gt;RandomizedSearchCV&lt;/code&gt; &lt;/a&gt; puede muestrear un n&amp;uacute;mero determinado de candidatos de un espacio de par&amp;aacute;metros con una distribuci&amp;oacute;n espec&amp;iacute;fica. Despu&amp;eacute;s de describir estas herramientas, detallamos las &lt;a href=&quot;#grid-search-tips&quot;&gt;mejores pr&amp;aacute;cticas&lt;/a&gt; aplicables a ambos enfoques.</target>
        </trans-unit>
        <trans-unit id="95196f8314df139319d7b42ff6d7520f5ecc9f1d" translate="yes" xml:space="preserve">
          <source>Some models also have &lt;code&gt;row_labels_&lt;/code&gt; and &lt;code&gt;column_labels_&lt;/code&gt; attributes. These models partition the rows and columns, such as in the block diagonal and checkerboard bicluster structures.</source>
          <target state="translated">Algunos modelos tambi&amp;eacute;n tienen atributos &lt;code&gt;row_labels_&lt;/code&gt; y &lt;code&gt;column_labels_&lt;/code&gt; . Estos modelos dividen las filas y columnas, como en las estructuras bicluster de diagonales de bloque y tablero de ajedrez.</target>
        </trans-unit>
        <trans-unit id="89f290ef487f7e4f63f1b82009e209966dcbe74f" translate="yes" xml:space="preserve">
          <source>Some models can fit data for a range of values of some parameter almost as efficiently as fitting the estimator for a single value of the parameter. This feature can be leveraged to perform a more efficient cross-validation used for model selection of this parameter.</source>
          <target state="translated">Algunos modelos pueden ajustar los datos para un rango de valores de algún parámetro casi tan eficientemente como ajustar el estimador para un solo valor del parámetro.Esta característica puede ser aprovechada para realizar una validación cruzada más eficiente utilizada para la selección del modelo de este parámetro.</target>
        </trans-unit>
        <trans-unit id="d786744290bacd9a4dfc207be555be0e40c3853e" translate="yes" xml:space="preserve">
          <source>Some models can offer an information-theoretic closed-form formula of the optimal estimate of the regularization parameter by computing a single regularization path (instead of several when using cross-validation).</source>
          <target state="translated">Algunos modelos pueden ofrecer una fórmula de información-teórica en forma cerrada de la estimación óptima del parámetro de regularización calculando una sola vía de regularización (en lugar de varias cuando se utiliza la validación cruzada).</target>
        </trans-unit>
        <trans-unit id="ad14a182695bef0a4c2fe22edd0961e8db73147c" translate="yes" xml:space="preserve">
          <source>Some of the clusters learned without connectivity constraints do not respect the structure of the swiss roll and extend across different folds of the manifolds. On the opposite, when opposing connectivity constraints, the clusters form a nice parcellation of the swiss roll.</source>
          <target state="translated">Algunos de los grupos aprendidos sin limitaciones de conectividad no respetan la estructura del rollo suizo y se extienden a través de diferentes pliegues de los colectores.Por el contrario,cuando se oponen a las restricciones de conectividad,los grupos forman una bonita parcelación del rollo suizo.</target>
        </trans-unit>
        <trans-unit id="877cbb42097301f5a68339d0d9f55e4ca85ad3c3" translate="yes" xml:space="preserve">
          <source>Some of these are restricted to the binary classification case:</source>
          <target state="translated">Algunas de ellas se limitan al caso de la clasificación binaria:</target>
        </trans-unit>
        <trans-unit id="bc828cde0b0d5dbd5e8ad77797297d4f6416ab76" translate="yes" xml:space="preserve">
          <source>Some other classifiers cope better with this harder version of the task. Try running &lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;Sample pipeline for text feature extraction and evaluation&lt;/a&gt; with and without the &lt;code&gt;--filter&lt;/code&gt; option to compare the results.</source>
          <target state="translated">Algunos otros clasificadores se adaptan mejor a esta versi&amp;oacute;n m&amp;aacute;s dif&amp;iacute;cil de la tarea. Intente ejecutar &lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;Sample pipeline para la extracci&amp;oacute;n y evaluaci&amp;oacute;n de caracter&amp;iacute;sticas de texto&lt;/a&gt; con y sin la opci&amp;oacute;n &lt;code&gt;--filter&lt;/code&gt; para comparar los resultados.</target>
        </trans-unit>
        <trans-unit id="1d754add1306692cb962c5467414be940979d0ab" translate="yes" xml:space="preserve">
          <source>Some parameter settings may result in a failure to &lt;code&gt;fit&lt;/code&gt; one or more folds of the data. By default, this will cause the entire search to fail, even if some parameter settings could be fully evaluated. Setting &lt;code&gt;error_score=0&lt;/code&gt; (or &lt;code&gt;=np.NaN&lt;/code&gt;) will make the procedure robust to such failure, issuing a warning and setting the score for that fold to 0 (or &lt;code&gt;NaN&lt;/code&gt;), but completing the search.</source>
          <target state="translated">Algunas configuraciones de par&amp;aacute;metros pueden provocar que no se &lt;code&gt;fit&lt;/code&gt; uno o m&amp;aacute;s pliegues de los datos. De forma predeterminada, esto har&amp;aacute; que toda la b&amp;uacute;squeda falle, incluso si algunas configuraciones de par&amp;aacute;metros pudieran evaluarse por completo. Establecer &lt;code&gt;error_score=0&lt;/code&gt; (o &lt;code&gt;=np.NaN&lt;/code&gt; ) har&amp;aacute; que el procedimiento sea robusto ante tal falla, emitiendo una advertencia y estableciendo la puntuaci&amp;oacute;n para ese pliegue en 0 (o &lt;code&gt;NaN&lt;/code&gt; ), pero completando la b&amp;uacute;squeda.</target>
        </trans-unit>
        <trans-unit id="2f1168d7fab23533f7c212613fc87fe5fb99b1b4" translate="yes" xml:space="preserve">
          <source>Some scikit-learn estimators and utilities can parallelize costly operations using multiple CPU cores, thanks to the following components:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f29c3cd2b5860fb787d236e9a466d0e36eb10659" translate="yes" xml:space="preserve">
          <source>Some tips and tricks:</source>
          <target state="translated">Algunos consejos y trucos:</target>
        </trans-unit>
        <trans-unit id="63fe20eae64c7864fd32162af52c1f81421bc7d2" translate="yes" xml:space="preserve">
          <source>Sometimes it may be useful to convert the data back into the original feature space. The &lt;code&gt;inverse_transform&lt;/code&gt; function converts the binned data into the original feature space. Each value will be equal to the mean of the two bin edges.</source>
          <target state="translated">A veces puede resultar &amp;uacute;til volver a convertir los datos en el espacio de caracter&amp;iacute;sticas original. La funci&amp;oacute;n &lt;code&gt;inverse_transform&lt;/code&gt; convierte los datos agrupados en el espacio de caracter&amp;iacute;sticas original. Cada valor ser&amp;aacute; igual a la media de los dos bordes del contenedor.</target>
        </trans-unit>
        <trans-unit id="315bc72af841ed152a9aae1c3ac0990cdcb834ed" translate="yes" xml:space="preserve">
          <source>Sometimes looking at the learned coefficients of a neural network can provide insight into the learning behavior. For example if weights look unstructured, maybe some were not used at all, or if very large coefficients exist, maybe regularization was too low or the learning rate too high.</source>
          <target state="translated">A veces mirar los coeficientes aprendidos de una red neuronal puede proporcionar una visión del comportamiento de aprendizaje.Por ejemplo,si los pesos se ven desestructurados,tal vez algunos no se usaron en absoluto,o si existen coeficientes muy grandes,tal vez la regularización fue demasiado baja o la tasa de aprendizaje demasiado alta.</target>
        </trans-unit>
        <trans-unit id="fbff2a8532eac744fd3e459bcddf3fd34f40adee" translate="yes" xml:space="preserve">
          <source>Source URL: &lt;a href=&quot;http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&quot;&gt;http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&lt;/a&gt;</source>
          <target state="translated">URL de la fuente: &lt;a href=&quot;http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&quot;&gt;http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="8173b56b5b02e6dc31d6c2059fb643537f89144d" translate="yes" xml:space="preserve">
          <source>Source URL: &lt;a href=&quot;https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&quot;&gt;https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bdef929636b0e2d76c9bcc79abe376f450451dd0" translate="yes" xml:space="preserve">
          <source>Sources, where n_samples is the number of samples and n_components is the number of components.</source>
          <target state="translated">Fuentes,donde n_muestras es el número de muestras y n_componentes es el número de componentes.</target>
        </trans-unit>
        <trans-unit id="3af0ce95ad1f86c8c1749c4ae38a0dba87aebcff" translate="yes" xml:space="preserve">
          <source>Sparse Principal Component Analysis.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dcbe3516134bdf9c59a33ffb1c2e3120ebfb3eac" translate="yes" xml:space="preserve">
          <source>Sparse Principal Components Analysis (SparsePCA)</source>
          <target state="translated">Análisis de componentes principales dispersos (SparsePCA)</target>
        </trans-unit>
        <trans-unit id="e06472c25d26cda25191de9da3a114b1e469b208" translate="yes" xml:space="preserve">
          <source>Sparse coding</source>
          <target state="translated">Codificación dispersa</target>
        </trans-unit>
        <trans-unit id="32c8d921f9e1520199d1db9fe64aa6fb0f91121f" translate="yes" xml:space="preserve">
          <source>Sparse coding with a precomputed dictionary</source>
          <target state="translated">Codificación dispersa con un diccionario precalculado</target>
        </trans-unit>
        <trans-unit id="83cd17de4011d58af20829baa72e8c3c15415081" translate="yes" xml:space="preserve">
          <source>Sparse components extracted from the data.</source>
          <target state="translated">Componentes dispersos extraídos de los datos.</target>
        </trans-unit>
        <trans-unit id="4aefb6aa7d814b8be3e6d2cb6f2931a1dadb31bc" translate="yes" xml:space="preserve">
          <source>Sparse input</source>
          <target state="translated">La entrada escasa...</target>
        </trans-unit>
        <trans-unit id="935bf4a32a6f741a33bb9ac8e725575de63e795c" translate="yes" xml:space="preserve">
          <source>Sparse inverse covariance estimation</source>
          <target state="translated">Estimación de covarianza inversa escasa</target>
        </trans-unit>
        <trans-unit id="409d5a415f20eafd9b9f09c6ba22d21458394422" translate="yes" xml:space="preserve">
          <source>Sparse inverse covariance estimation with an l1-penalized estimator.</source>
          <target state="translated">Estimación de covarianza inversa dispersa con un estimador de l1-penalizado.</target>
        </trans-unit>
        <trans-unit id="2ee089f1e56c91604e7cab7d40e8b9f34677bb75" translate="yes" xml:space="preserve">
          <source>Sparse inverse covariance w/ cross-validated choice of the l1 penalty</source>
          <target state="translated">Covarianza inversa dispersa con elección validada cruzada de la pena de l1</target>
        </trans-unit>
        <trans-unit id="0113e7df66bdaa38179e1b6944e6cd1aa2f5ffce" translate="yes" xml:space="preserve">
          <source>Sparse inverse covariance w/ cross-validated choice of the l1 penalty.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92e371bb810dfdf353c195f32e5335e997df721c" translate="yes" xml:space="preserve">
          <source>Sparse principal components yields a more parsimonious, interpretable representation, clearly emphasizing which of the original features contribute to the differences between samples.</source>
          <target state="translated">La dispersión de los componentes principales da lugar a una representación más parsimoniosa e interpretable,destacando claramente cuáles de los rasgos originales contribuyen a las diferencias entre las muestras.</target>
        </trans-unit>
        <trans-unit id="19dbec98d9db7f8dccbc05e595e6dcc554502b17" translate="yes" xml:space="preserve">
          <source>Sparse random matrices are an alternative to dense Gaussian random projection matrix that guarantees similar embedding quality while being much more memory efficient and allowing faster computation of the projected data.</source>
          <target state="translated">Las matrices aleatorias dispersas son una alternativa a la matriz de proyección aleatoria gaussiana densa que garantiza una calidad de incrustación similar,a la vez que es mucho más eficiente en cuanto a la memoria y permite un cálculo más rápido de los datos proyectados.</target>
        </trans-unit>
        <trans-unit id="5ad88cbdaa9d7d5c176762a66b957d3aa9661770" translate="yes" xml:space="preserve">
          <source>Sparse random matrix is an alternative to dense random projection matrix that guarantees similar embedding quality while being much more memory efficient and allowing faster computation of the projected data.</source>
          <target state="translated">La matriz aleatoria dispersa es una alternativa a la matriz de proyección aleatoria densa que garantiza una calidad de incrustación similar,a la vez que es mucho más eficiente en cuanto a la memoria y permite un cálculo más rápido de los datos proyectados.</target>
        </trans-unit>
        <trans-unit id="a7a844fc75c56ce03e1afce70cb2355152140d0b" translate="yes" xml:space="preserve">
          <source>Sparsity</source>
          <target state="translated">Sparsity</target>
        </trans-unit>
        <trans-unit id="814e5a7e79ded720eafc96bc0232cca516d50079" translate="yes" xml:space="preserve">
          <source>Sparsity Example: Fitting only features 1 and 2</source>
          <target state="translated">Ejemplo de la escasez:Sólo las características de ajuste 1 y 2</target>
        </trans-unit>
        <trans-unit id="43cddceab3d136418b0e03e98d360e468cf1b8e5" translate="yes" xml:space="preserve">
          <source>Sparsity controlling parameter.</source>
          <target state="translated">Parámetro de control de la escasez.</target>
        </trans-unit>
        <trans-unit id="647e2a8c2a361b51e5b69ed284ca76c83752d0f6" translate="yes" xml:space="preserve">
          <source>Sparsity controlling parameter. Higher values lead to sparser components.</source>
          <target state="translated">Parámetro de control de la escasez.Los valores más altos llevan a componentes más escasos.</target>
        </trans-unit>
        <trans-unit id="49f74e244eb107a1663f4aabb4f4ff9cbf7f050c" translate="yes" xml:space="preserve">
          <source>Spatial indexing trees are used to avoid calculating the full distance matrix, and allow for efficient memory usage on large sets of samples. Different distance metrics can be supplied via the &lt;code&gt;metric&lt;/code&gt; keyword.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a82be20d822213cd6b317bb5903a0613a76bafa" translate="yes" xml:space="preserve">
          <source>Species distribution modeling</source>
          <target state="translated">Modelos de distribución de especies</target>
        </trans-unit>
        <trans-unit id="57d730dfe1585d0d57e966c58e133370714f1563" translate="yes" xml:space="preserve">
          <source>Specific parameters using e.g. &lt;code&gt;set_params(parameter_name=new_value)&lt;/code&gt;. In addition, to setting the parameters of the stacking estimator, the individual estimator of the stacking estimators can also be set, or can be removed by setting them to &amp;lsquo;drop&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37195f9a92f1ed14e524a0ed92aab116b735c4ea" translate="yes" xml:space="preserve">
          <source>Specific parameters using e.g. set_params(parameter_name=new_value) In addition, to setting the parameters of the &lt;code&gt;VotingClassifier&lt;/code&gt;, the individual classifiers of the &lt;code&gt;VotingClassifier&lt;/code&gt; can also be set or replaced by setting them to None.</source>
          <target state="translated">Par&amp;aacute;metros espec&amp;iacute;ficos usando, por ejemplo, set_params (parameter_name = new_value) Adem&amp;aacute;s de configurar los par&amp;aacute;metros del &lt;code&gt;VotingClassifier&lt;/code&gt; , los clasificadores individuales del &lt;code&gt;VotingClassifier&lt;/code&gt; tambi&amp;eacute;n se pueden configurar o reemplazar estableci&amp;eacute;ndolos en Ninguno.</target>
        </trans-unit>
        <trans-unit id="94e374689a4595b916bcf5e66713548e054c55c6" translate="yes" xml:space="preserve">
          <source>Specific weights can be assigned to each classifier via the &lt;code&gt;weights&lt;/code&gt; parameter. When weights are provided, the predicted class probabilities for each classifier are collected, multiplied by the classifier weight, and averaged. The final class label is then derived from the class label with the highest average probability.</source>
          <target state="translated">Se pueden asignar pesos espec&amp;iacute;ficos a cada clasificador mediante el par&amp;aacute;metro de &lt;code&gt;weights&lt;/code&gt; . Cuando se proporcionan los pesos, se recopilan las probabilidades de clase predichas para cada clasificador, se multiplican por el peso del clasificador y se promedian. La etiqueta de clase final se deriva entonces de la etiqueta de clase con la probabilidad promedio m&amp;aacute;s alta.</target>
        </trans-unit>
        <trans-unit id="68354cd532978d44f7b8a2998caa562af7db6244" translate="yes" xml:space="preserve">
          <source>Specifically, here the input variables are some gene sequences stored as variable-length strings consisting of letters &amp;lsquo;A&amp;rsquo;, &amp;lsquo;T&amp;rsquo;, &amp;lsquo;C&amp;rsquo;, and &amp;lsquo;G&amp;rsquo;, while the output variables are floating point numbers and True/False labels in the regression and classification tasks, respectively.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40c186465110b1329791125cf6cae8eb6f471442" translate="yes" xml:space="preserve">
          <source>Specifies a methodology to use to drop one of the categories per feature. This is useful in situations where perfectly collinear features cause problems, such as when feeding the resulting data into a neural network or an unregularized regression.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8fbbf3fe05797ad1e4c717c36a5a204246056853" translate="yes" xml:space="preserve">
          <source>Specifies how multi-class classification problems are handled. Supported are &amp;ldquo;one_vs_rest&amp;rdquo; and &amp;ldquo;one_vs_one&amp;rdquo;. In &amp;ldquo;one_vs_rest&amp;rdquo;, one binary Gaussian process classifier is fitted for each class, which is trained to separate this class from the rest. In &amp;ldquo;one_vs_one&amp;rdquo;, one binary Gaussian process classifier is fitted for each pair of classes, which is trained to separate these two classes. The predictions of these binary predictors are combined into multi-class predictions. Note that &amp;ldquo;one_vs_one&amp;rdquo; does not support predicting probability estimates.</source>
          <target state="translated">Especifica c&amp;oacute;mo se manejan los problemas de clasificaci&amp;oacute;n de clases m&amp;uacute;ltiples. Se admiten &quot;one_vs_rest&quot; y &quot;one_vs_one&quot;. En &quot;one_vs_rest&quot;, se ajusta un clasificador de proceso gaussiano binario para cada clase, que est&amp;aacute; entrenado para separar esta clase del resto. En &amp;ldquo;one_vs_one&amp;rdquo;, se ajusta un clasificador de proceso gaussiano binario para cada par de clases, que se entrena para separar estas dos clases. Las predicciones de estos predictores binarios se combinan en predicciones de varias clases. Tenga en cuenta que &quot;one_vs_one&quot; no admite la predicci&amp;oacute;n de estimaciones de probabilidad.</target>
        </trans-unit>
        <trans-unit id="e7bd9f102fbfd80a2ad8d309cf0a9504bc2caee0" translate="yes" xml:space="preserve">
          <source>Specifies how multi-class classification problems are handled. Supported are &amp;lsquo;one_vs_rest&amp;rsquo; and &amp;lsquo;one_vs_one&amp;rsquo;. In &amp;lsquo;one_vs_rest&amp;rsquo;, one binary Gaussian process classifier is fitted for each class, which is trained to separate this class from the rest. In &amp;lsquo;one_vs_one&amp;rsquo;, one binary Gaussian process classifier is fitted for each pair of classes, which is trained to separate these two classes. The predictions of these binary predictors are combined into multi-class predictions. Note that &amp;lsquo;one_vs_one&amp;rsquo; does not support predicting probability estimates.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9bddb5670bf596fd4f95945fb300823355f1c46f" translate="yes" xml:space="preserve">
          <source>Specifies if a constant (a.k.a. bias or intercept) should be added to the decision function.</source>
          <target state="translated">Especifica si una constante (también conocida como sesgo o intercepción)debe añadirse a la función de decisión.</target>
        </trans-unit>
        <trans-unit id="9cc5cb93f212cfc9a20617982597c3fd3b14a01a" translate="yes" xml:space="preserve">
          <source>Specifies if a constant (a.k.a. bias or intercept) should be added to the linear predictor (X @ coef + intercept).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="032e8ae2185962af612ef54804c68499bb10a9e0" translate="yes" xml:space="preserve">
          <source>Specifies if the estimated precision is stored.</source>
          <target state="translated">Especifica si se almacena la precisión estimada.</target>
        </trans-unit>
        <trans-unit id="d38faf7dee61c2f434029c24d24417f5a7a63648" translate="yes" xml:space="preserve">
          <source>Specifies if the intercept should be fitted by the model. It must match the fit() method parameter.</source>
          <target state="translated">Especifica si la intercepción debe ser ajustada por el modelo.Debe coincidir con el parámetro del método fit().</target>
        </trans-unit>
        <trans-unit id="21164bb750beb75acb9ae9d1f3fb116169b84f4e" translate="yes" xml:space="preserve">
          <source>Specifies the kernel type to be used in the algorithm. It must be one of &amp;lsquo;linear&amp;rsquo;, &amp;lsquo;poly&amp;rsquo;, &amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;sigmoid&amp;rsquo;, &amp;lsquo;precomputed&amp;rsquo; or a callable. If none is given, &amp;lsquo;rbf&amp;rsquo; will be used. If a callable is given it is used to pre-compute the kernel matrix from data matrices; that matrix should be an array of shape &lt;code&gt;(n_samples, n_samples)&lt;/code&gt;.</source>
          <target state="translated">Especifica el tipo de kernel que se utilizar&amp;aacute; en el algoritmo. Debe ser 'lineal', 'poli', 'rbf', 'sigmoide', 'precalculado' o invocable. Si no se proporciona ninguno, se utilizar&amp;aacute; 'rbf'. Si se proporciona un invocable, se utiliza para calcular previamente la matriz del n&amp;uacute;cleo a partir de matrices de datos; esa matriz debe ser una matriz de forma &lt;code&gt;(n_samples, n_samples)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7717364640e0a660ec81dfa33f675030f243fdf0" translate="yes" xml:space="preserve">
          <source>Specifies the kernel type to be used in the algorithm. It must be one of &amp;lsquo;linear&amp;rsquo;, &amp;lsquo;poly&amp;rsquo;, &amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;sigmoid&amp;rsquo;, &amp;lsquo;precomputed&amp;rsquo; or a callable. If none is given, &amp;lsquo;rbf&amp;rsquo; will be used. If a callable is given it is used to precompute the kernel matrix.</source>
          <target state="translated">Especifica el tipo de kernel que se utilizar&amp;aacute; en el algoritmo. Debe ser 'lineal', 'poli', 'rbf', 'sigmoide', 'precalculado' o invocable. Si no se proporciona ninguno, se utilizar&amp;aacute; 'rbf'. Si se proporciona un invocable, se utiliza para calcular previamente la matriz del n&amp;uacute;cleo.</target>
        </trans-unit>
        <trans-unit id="b9435d1c3c2633287cc32557661450b6f00ca78e" translate="yes" xml:space="preserve">
          <source>Specifies the loss function. &amp;lsquo;hinge&amp;rsquo; is the standard SVM loss (used e.g. by the SVC class) while &amp;lsquo;squared_hinge&amp;rsquo; is the square of the hinge loss.</source>
          <target state="translated">Especifica la funci&amp;oacute;n de p&amp;eacute;rdida. 'bisagra' es la p&amp;eacute;rdida est&amp;aacute;ndar de SVM (usada por ejemplo por la clase SVC) mientras que 'bisagra_cuadrada' es el cuadrado de la p&amp;eacute;rdida de bisagra.</target>
        </trans-unit>
        <trans-unit id="68150facd38948e362a68f70eea508701955b6e7" translate="yes" xml:space="preserve">
          <source>Specifies the loss function. The epsilon-insensitive loss (standard SVR) is the L1 loss, while the squared epsilon-insensitive loss (&amp;lsquo;squared_epsilon_insensitive&amp;rsquo;) is the L2 loss.</source>
          <target state="translated">Especifica la funci&amp;oacute;n de p&amp;eacute;rdida. La p&amp;eacute;rdida insensible a &amp;eacute;psilon (SVR est&amp;aacute;ndar) es la p&amp;eacute;rdida L1, mientras que la p&amp;eacute;rdida insensible a &amp;eacute;psilon al cuadrado ('squared_epsilon_insensitive') es la p&amp;eacute;rdida L2.</target>
        </trans-unit>
        <trans-unit id="1b5fabde85275fd0a5eb3f705ddd6c262b6e1ace" translate="yes" xml:space="preserve">
          <source>Specifies the loss function. With &amp;lsquo;squared_hinge&amp;rsquo; it is the squared hinge loss (a.k.a. L2 loss). With &amp;lsquo;log&amp;rsquo; it is the loss of logistic regression models.</source>
          <target state="translated">Especifica la funci&amp;oacute;n de p&amp;eacute;rdida. Con 'squared_hinge' es la p&amp;eacute;rdida de bisagra al cuadrado (tambi&amp;eacute;n conocida como p&amp;eacute;rdida L2). Con 'log' es la p&amp;eacute;rdida de modelos de regresi&amp;oacute;n log&amp;iacute;stica.</target>
        </trans-unit>
        <trans-unit id="82fe667ff963f19359a5dba7024bcea48fa12322" translate="yes" xml:space="preserve">
          <source>Specifies the norm used in the penalization. The &amp;lsquo;l2&amp;rsquo; penalty is the standard used in SVC. The &amp;lsquo;l1&amp;rsquo; leads to &lt;code&gt;coef_&lt;/code&gt; vectors that are sparse.</source>
          <target state="translated">Especifica la norma utilizada en la penalizaci&amp;oacute;n. La penalizaci&amp;oacute;n 'l2' es el est&amp;aacute;ndar utilizado en SVC. El 'l1' conduce a &lt;code&gt;coef_&lt;/code&gt; vectores que son escasos.</target>
        </trans-unit>
        <trans-unit id="5a337b6de37f25f0ac3016f29ff1f6486795a255" translate="yes" xml:space="preserve">
          <source>Specifies the returned model. Select &lt;code&gt;'lar'&lt;/code&gt; for Least Angle Regression, &lt;code&gt;'lasso'&lt;/code&gt; for the Lasso.</source>
          <target state="translated">Especifica el modelo devuelto. Seleccione &lt;code&gt;'lar'&lt;/code&gt; para Regresi&amp;oacute;n de &amp;aacute;ngulo m&amp;iacute;nimo, &lt;code&gt;'lasso'&lt;/code&gt; para Lazo.</target>
        </trans-unit>
        <trans-unit id="ef557ab8128f60634f92721dd7b48ce0309e1238" translate="yes" xml:space="preserve">
          <source>Specifies whether to use &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt; or &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt; as the target response. For regressors this parameter is ignored and the response is always the output of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict&quot;&gt;predict&lt;/a&gt;. By default, &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt; is tried first and we revert to &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt; if it doesn&amp;rsquo;t exist. If &lt;code&gt;method&lt;/code&gt; is &amp;lsquo;recursion&amp;rsquo;, the response is always the output of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4eb03b762d72883fa3052fd37abd9dd63a6ceb00" translate="yes" xml:space="preserve">
          <source>Specifies whether to use &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt; or &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt; as the target response. If set to &amp;lsquo;auto&amp;rsquo;, &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt; is tried first and if it does not exist &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt; is tried next.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32ab0cdbec2fd77050a55d02bdf5982ebc80779f" translate="yes" xml:space="preserve">
          <source>Specify a download and cache folder for the datasets. If None, all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="translated">Especifique una carpeta de descarga y cach&amp;eacute; para los conjuntos de datos. Si es None, todos los datos de scikit-learn se almacenan en las subcarpetas '~ / scikit_learn_data'.</target>
        </trans-unit>
        <trans-unit id="5a7f883c69415d4b4614ca7ec1c25ea069f17592" translate="yes" xml:space="preserve">
          <source>Specify an download and cache folder for the datasets. If None, all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="translated">Especifique una carpeta de descarga y cach&amp;eacute; para los conjuntos de datos. Si es None, todos los datos de scikit-learn se almacenan en las subcarpetas '~ / scikit_learn_data'.</target>
        </trans-unit>
        <trans-unit id="bef377c44b3d810cadc5cf65c208d01924bfa02c" translate="yes" xml:space="preserve">
          <source>Specify another download and cache folder for the data sets. By default all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="translated">Especifique otra carpeta de descarga y cach&amp;eacute; para los conjuntos de datos. De forma predeterminada, todos los datos de scikit-learn se almacenan en las subcarpetas '~ / scikit_learn_data'.</target>
        </trans-unit>
        <trans-unit id="db707a2b2d7445205a990e044438fdad3fa08a72" translate="yes" xml:space="preserve">
          <source>Specify another download and cache folder for the datasets. By default all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="translated">Especifique otra carpeta de descarga y cach&amp;eacute; para los conjuntos de datos. De forma predeterminada, todos los datos de scikit-learn se almacenan en las subcarpetas '~ / scikit_learn_data'.</target>
        </trans-unit>
        <trans-unit id="e0a4c5302feb0239f945ee7ba84757ae55a6d243" translate="yes" xml:space="preserve">
          <source>Specify another download and cache folder for the datasets. By default all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders. .. versionadded:: 0.19</source>
          <target state="translated">Especifique otra carpeta de descarga y cach&amp;eacute; para los conjuntos de datos. De forma predeterminada, todos los datos de scikit-learn se almacenan en las subcarpetas '~ / scikit_learn_data'. .. versionadded :: 0.19</target>
        </trans-unit>
        <trans-unit id="3a104a4391c92d3464c7b1efaf07c449c778bcc9" translate="yes" xml:space="preserve">
          <source>Specify if the estimated precision is stored</source>
          <target state="translated">Especificar si la precisión estimada se almacena</target>
        </trans-unit>
        <trans-unit id="68d4702fc734cffadd8a1ccf005f0aff7fa648f2" translate="yes" xml:space="preserve">
          <source>Specify if the estimated precision is stored.</source>
          <target state="translated">Especifique si la precisión estimada está almacenada.</target>
        </trans-unit>
        <trans-unit id="4984f447cb8f4f521871d2431cae9f4220dfb519" translate="yes" xml:space="preserve">
          <source>Specify the column name in the data to use as target. If &amp;lsquo;default-target&amp;rsquo;, the standard target column a stored on the server is used. If &lt;code&gt;None&lt;/code&gt;, all columns are returned as data and the target is &lt;code&gt;None&lt;/code&gt;. If list (of strings), all columns with these names are returned as multi-target (Note: not all scikit-learn classifiers can handle all types of multi-output combinations)</source>
          <target state="translated">Especifique el nombre de la columna en los datos para usar como destino. Si es 'destino predeterminado', se utiliza la columna de destino est&amp;aacute;ndar a almacenada en el servidor. Si es &lt;code&gt;None&lt;/code&gt; , todas las columnas se devuelven como datos y el destino es &lt;code&gt;None&lt;/code&gt; . Si es una lista (de cadenas), todas las columnas con estos nombres se devuelven como multi-objetivo (Nota: no todos los clasificadores de scikit-learn pueden manejar todos los tipos de combinaciones de m&amp;uacute;ltiples salidas)</target>
        </trans-unit>
        <trans-unit id="86eb3ad2a989c13695b9d85dcb05b7c45343a61d" translate="yes" xml:space="preserve">
          <source>Specify the desired relative and absolute tolerance of the result. If the true result is K_true, then the returned result K_ret satisfies &lt;code&gt;abs(K_true - K_ret) &amp;lt; atol + rtol * K_ret&lt;/code&gt; The default is zero (i.e. machine precision) for both.</source>
          <target state="translated">Especifique la tolerancia relativa y absoluta deseada del resultado. Si el resultado verdadero es K_true, entonces el resultado devuelto K_ret satisface &lt;code&gt;abs(K_true - K_ret) &amp;lt; atol + rtol * K_ret&lt;/code&gt; El valor predeterminado es cero (es decir, precisi&amp;oacute;n de la m&amp;aacute;quina) para ambos.</target>
        </trans-unit>
        <trans-unit id="0742682745f85d107eacd49ea30a7e49015c565b" translate="yes" xml:space="preserve">
          <source>Specify the leaf size of the underlying tree. See &lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt;&lt;code&gt;KDTree&lt;/code&gt;&lt;/a&gt; for details. Default is 40.</source>
          <target state="translated">Especifique el tama&amp;ntilde;o de la hoja del &amp;aacute;rbol subyacente. Consulte &lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; &lt;/a&gt; o &lt;a href=&quot;sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt; &lt;code&gt;KDTree&lt;/code&gt; &lt;/a&gt; para obtener m&amp;aacute;s detalles. El valor predeterminado es 40.</target>
        </trans-unit>
        <trans-unit id="a3eb34c47a1823aab704036791431543ed289a4a" translate="yes" xml:space="preserve">
          <source>Specify the parallelization backend implementation. Supported backends are:</source>
          <target state="translated">Especificar la implementación del backend de paralelización.Los backends soportados son:</target>
        </trans-unit>
        <trans-unit id="9ef7e5427d37487b864821803fe9613488fa8ce1" translate="yes" xml:space="preserve">
          <source>Specify the size of the kernel cache (in MB).</source>
          <target state="translated">Especifique el tamaño de la caché del núcleo (en MB).</target>
        </trans-unit>
        <trans-unit id="4329e4ac0b424da2818ac12cc4d13ce3581c4d3d" translate="yes" xml:space="preserve">
          <source>Specify what features are treated as categorical.</source>
          <target state="translated">Especifique qué características se tratan como categóricas.</target>
        </trans-unit>
        <trans-unit id="7d724db10f986282e8a5446f219cdacdbcddece6" translate="yes" xml:space="preserve">
          <source>Specify whether all or any of the given attributes must exist.</source>
          <target state="translated">Especifique si todos o algunos de los atributos dados deben existir.</target>
        </trans-unit>
        <trans-unit id="d079850de1341ae0792b165a2e4c64406a6bf6cd" translate="yes" xml:space="preserve">
          <source>Specifying how parameters should be sampled is done using a dictionary, very similar to specifying parameters for &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt;. Additionally, a computation budget, being the number of sampled candidates or sampling iterations, is specified using the &lt;code&gt;n_iter&lt;/code&gt; parameter. For each parameter, either a distribution over possible values or a list of discrete choices (which will be sampled uniformly) can be specified:</source>
          <target state="translated">La especificaci&amp;oacute;n de c&amp;oacute;mo se deben muestrear los par&amp;aacute;metros se realiza mediante un diccionario, muy similar a especificar par&amp;aacute;metros para &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt; . Adem&amp;aacute;s, un presupuesto de c&amp;aacute;lculo, que es el n&amp;uacute;mero de candidatos muestreados o iteraciones de muestreo, se especifica mediante el par&amp;aacute;metro &lt;code&gt;n_iter&lt;/code&gt; . Para cada par&amp;aacute;metro, se puede especificar una distribuci&amp;oacute;n sobre los valores posibles o una lista de opciones discretas (que se muestrear&amp;aacute;n de manera uniforme):</target>
        </trans-unit>
        <trans-unit id="848f2bc6fd9feea5a4bd159161ff60b7b7f1ad05" translate="yes" xml:space="preserve">
          <source>Specifying the dataset by the name &amp;ldquo;iris&amp;rdquo; yields the lowest version, version 1, with the &lt;code&gt;data_id&lt;/code&gt; 61. To make sure you always get this exact dataset, it is safest to specify it by the dataset &lt;code&gt;data_id&lt;/code&gt;. The other dataset, with &lt;code&gt;data_id&lt;/code&gt; 969, is version 3 (version 2 has become inactive), and contains a binarized version of the data:</source>
          <target state="translated">Especificar el conjunto de datos con el nombre &quot;iris&quot; produce la versi&amp;oacute;n m&amp;aacute;s baja, la versi&amp;oacute;n 1, con el &lt;code&gt;data_id&lt;/code&gt; 61. Para asegurarse de obtener siempre este conjunto de datos exacto, es m&amp;aacute;s seguro especificarlo mediante el conjunto de datos &lt;code&gt;data_id&lt;/code&gt; . El otro conjunto de datos, con &lt;code&gt;data_id&lt;/code&gt; 969, es la versi&amp;oacute;n 3 (la versi&amp;oacute;n 2 se ha vuelto inactiva) y contiene una versi&amp;oacute;n binarizada de los datos:</target>
        </trans-unit>
        <trans-unit id="a7781532fac864d69f63a26a8d414fddcb049d3b" translate="yes" xml:space="preserve">
          <source>Specifying the value of the &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-cv&quot;&gt;cv&lt;/a&gt; attribute will trigger the use of cross-validation with &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt;, for example &lt;code&gt;cv=10&lt;/code&gt; for 10-fold cross-validation, rather than Generalized Cross-Validation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3df7d54bd992cb63f5a75a6f7de49938e89cdde2" translate="yes" xml:space="preserve">
          <source>Spectral Clustering can also be used to cluster graphs by their spectral embeddings. In this case, the affinity matrix is the adjacency matrix of the graph, and SpectralClustering is initialized with &lt;code&gt;affinity=&amp;rsquo;precomputed&amp;rsquo;&lt;/code&gt;:</source>
          <target state="translated">La agrupaci&amp;oacute;n espectral tambi&amp;eacute;n se puede utilizar para agrupar gr&amp;aacute;ficos por sus incrustaciones espectrales. En este caso, la matriz de afinidad es la matriz de adyacencia del gr&amp;aacute;fico y SpectralClustering se inicializa con &lt;code&gt;affinity=&amp;rsquo;precomputed&amp;rsquo;&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="e698832cd5821ea0f1db5828f5b72aad63c46c00" translate="yes" xml:space="preserve">
          <source>Spectral Clustering can also be used to partition graphs via their spectral embeddings. In this case, the affinity matrix is the adjacency matrix of the graph, and SpectralClustering is initialized with &lt;code&gt;affinity='precomputed'&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="943c880ba7aef37194c447e5760436985518b340" translate="yes" xml:space="preserve">
          <source>Spectral Co-Clustering algorithm (Dhillon, 2001).</source>
          <target state="translated">Algoritmo de Co-Clusterización Espectral (Dhillon,2001).</target>
        </trans-unit>
        <trans-unit id="5c8a907562e6db42ff15e9df5a0d9b0b21be7b5f" translate="yes" xml:space="preserve">
          <source>Spectral Embedding (Laplacian Eigenmaps) is most useful when the graph has one connected component. If there graph has many components, the first few eigenvectors will simply uncover the connected components of the graph.</source>
          <target state="translated">La incrustación espectral (Eigenmaps Laplacianos)es más útil cuando el gráfico tiene un componente conectado.Si el gráfico tiene muchos componentes,los primeros vectores propios simplemente descubrirán los componentes conectados del gráfico.</target>
        </trans-unit>
        <trans-unit id="7ff62a97384e4faf388cb99bbcc076cbdae4a5ec" translate="yes" xml:space="preserve">
          <source>Spectral Embedding is an approach to calculating a non-linear embedding. Scikit-learn implements Laplacian Eigenmaps, which finds a low dimensional representation of the data using a spectral decomposition of the graph Laplacian. The graph generated can be considered as a discrete approximation of the low dimensional manifold in the high dimensional space. Minimization of a cost function based on the graph ensures that points close to each other on the manifold are mapped close to each other in the low dimensional space, preserving local distances. Spectral embedding can be performed with the function &lt;a href=&quot;generated/sklearn.manifold.spectral_embedding#sklearn.manifold.spectral_embedding&quot;&gt;&lt;code&gt;spectral_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.spectralembedding#sklearn.manifold.SpectralEmbedding&quot;&gt;&lt;code&gt;SpectralEmbedding&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">La incrustaci&amp;oacute;n espectral es un m&amp;eacute;todo para calcular una incrustaci&amp;oacute;n no lineal. Scikit-learn implementa laplacian Eigenmaps, que encuentra una representaci&amp;oacute;n de baja dimensi&amp;oacute;n de los datos utilizando una descomposici&amp;oacute;n espectral del gr&amp;aacute;fico laplaciano. El gr&amp;aacute;fico generado se puede considerar como una aproximaci&amp;oacute;n discreta de la variedad de baja dimensi&amp;oacute;n en el espacio de alta dimensi&amp;oacute;n. La minimizaci&amp;oacute;n de una funci&amp;oacute;n de costo basada en el gr&amp;aacute;fico asegura que los puntos cercanos entre s&amp;iacute; en el colector se mapeen cerca entre s&amp;iacute; en el espacio de baja dimensi&amp;oacute;n, preservando las distancias locales. La incrustaci&amp;oacute;n espectral se puede realizar con la funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.manifold.spectral_embedding#sklearn.manifold.spectral_embedding&quot;&gt; &lt;code&gt;spectral_embedding&lt;/code&gt; &lt;/a&gt; o su contraparte orientada a objetos &lt;a href=&quot;generated/sklearn.manifold.spectralembedding#sklearn.manifold.SpectralEmbedding&quot;&gt; &lt;code&gt;SpectralEmbedding&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="3266962963ccf3ff289e43e7853a5feea31fa6fe" translate="yes" xml:space="preserve">
          <source>Spectral biclustering (Kluger, 2003).</source>
          <target state="translated">Biclustering espectral (Kluger,2003).</target>
        </trans-unit>
        <trans-unit id="83334448105603952db5b041593dddc0f02ac19b" translate="yes" xml:space="preserve">
          <source>Spectral biclustering algorithms.</source>
          <target state="translated">Algoritmos de biclustering espectral.</target>
        </trans-unit>
        <trans-unit id="3fddf3521d69d12bc13710d54a4adc12aa85f512" translate="yes" xml:space="preserve">
          <source>Spectral clustering</source>
          <target state="translated">Agrupación espectral</target>
        </trans-unit>
        <trans-unit id="453e3a7c69660270eecfb13dabf16149c8b4512b" translate="yes" xml:space="preserve">
          <source>Spectral clustering for image segmentation</source>
          <target state="translated">Agrupación espectral para la segmentación de imágenes</target>
        </trans-unit>
        <trans-unit id="f9409615dd1103c73760717b8600df9e2157d615" translate="yes" xml:space="preserve">
          <source>Spectral embedding for non-linear dimensionality reduction.</source>
          <target state="translated">Incrustación espectral para la reducción de la dimensionalidad no lineal.</target>
        </trans-unit>
        <trans-unit id="8a0801a4fb2ecc40bcf6f04aa745ad2e1056e690" translate="yes" xml:space="preserve">
          <source>Spectral embedding of the training matrix.</source>
          <target state="translated">Incrustación espectral de la matriz de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="2d2cb022bc3d26bd1407c4aa787d5e46e1ad4c3b" translate="yes" xml:space="preserve">
          <source>Speed</source>
          <target state="translated">Speed</target>
        </trans-unit>
        <trans-unit id="063a83567f47ad5f5679accf564d96c923566ee9" translate="yes" xml:space="preserve">
          <source>Speed:</source>
          <target state="translated">Speed:</target>
        </trans-unit>
        <trans-unit id="7d07f6cca3dbed6cdb804f0e2864e093c6647564" translate="yes" xml:space="preserve">
          <source>Split arrays or matrices into random train and test subsets</source>
          <target state="translated">Dividir los conjuntos o matrices en trenes aleatorios y subconjuntos de prueba</target>
        </trans-unit>
        <trans-unit id="5e854ececac820d9fb56cdde854f788365393cf5" translate="yes" xml:space="preserve">
          <source>Splits it into K folds, trains on K-1 and then tests on the left-out.</source>
          <target state="translated">Lo divide en pliegues K,entrena en el K-1 y luego prueba en el izquierdo.</target>
        </trans-unit>
        <trans-unit id="c2518ac986a45f6943dccb55ec28e7fc9787e8f9" translate="yes" xml:space="preserve">
          <source>Splitter Classes</source>
          <target state="translated">Clases de división</target>
        </trans-unit>
        <trans-unit id="474933f1a999ce205b180d93539f6dbb5b05050e" translate="yes" xml:space="preserve">
          <source>Splitter Functions</source>
          <target state="translated">Funciones del divisor</target>
        </trans-unit>
        <trans-unit id="01474e72e0404f40fd189e5ac7233925222e580d" translate="yes" xml:space="preserve">
          <source>Squared L2 norms of the lines of y. Required if tol is not None.</source>
          <target state="translated">Normas de L2 cuadradas de las líneas de y.Requerido si el tol no es None.</target>
        </trans-unit>
        <trans-unit id="89cdcd77a950e009dab4164bc976d2f6ebb6b9e7" translate="yes" xml:space="preserve">
          <source>Squared Mahalanobis distances of the observations.</source>
          <target state="translated">Las distancias cuadradas de Mahalanobis de las observaciones.</target>
        </trans-unit>
        <trans-unit id="a0b13f625123904866bd60e38bc7611ba95c992c" translate="yes" xml:space="preserve">
          <source>Squared Sum - Sum of the squared L2 norm of all samples.</source>
          <target state="translated">Suma al cuadrado-Suma de la norma L2 al cuadrado de todas las muestras.</target>
        </trans-unit>
        <trans-unit id="1c1f19010d2ef30728a1e3cec08abc7bd4b0d974" translate="yes" xml:space="preserve">
          <source>Squared norm of the centroids.</source>
          <target state="translated">Norma cuadrada de los centroides.</target>
        </trans-unit>
        <trans-unit id="ff4530f7332d92145f70c600e76bef65d08e2445" translate="yes" xml:space="preserve">
          <source>Stability path based on randomized Lasso estimates</source>
          <target state="translated">Trayectoria de estabilidad basada en estimaciones de Lasso aleatorias</target>
        </trans-unit>
        <trans-unit id="9a5fecba5d8d30ecb602724233c6166d767b3036" translate="yes" xml:space="preserve">
          <source>Stability selection Nicolai Meinshausen, Peter Buhlmann Journal of the Royal Statistical Society: Series B Volume 72, Issue 4, pages 417-473, September 2010 DOI: 10.1111/j.1467-9868.2010.00740.x</source>
          <target state="translated">Selección de estabilidad Nicolai Meinshausen,Peter Buhlmann Diario de la Real Sociedad Estadística:Serie B Volumen 72,Número 4,páginas 417-473,Septiembre 2010 DOI:10.1111/j.1467-9868.2010.00740.x</target>
        </trans-unit>
        <trans-unit id="24ab98f7d3b4687c560036182f11b4e7733b1d68" translate="yes" xml:space="preserve">
          <source>Stack Exchange</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71b2c903e12bff4f98c474e759faf1146ab6ad92" translate="yes" xml:space="preserve">
          <source>Stack of estimators with a final classifier.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8433d8b247979d86acd74f4143c89bb21831f7b9" translate="yes" xml:space="preserve">
          <source>Stack of estimators with a final regressor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a568e00cb92ef139342d099c3bf8234421058e98" translate="yes" xml:space="preserve">
          <source>Stack of predictors on a single data set</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8781e517c304621291a3255c93ced28430f5c0bd" translate="yes" xml:space="preserve">
          <source>Stacked generalization consists in stacking the output of individual estimator and use a classifier to compute the final prediction. Stacking allows to use the strength of each individual estimator by using their output as input of a final estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f5f44a8c7d7cd4102991a0e07afa77f83e823da" translate="yes" xml:space="preserve">
          <source>Stacked generalization consists in stacking the output of individual estimator and use a regressor to compute the final prediction. Stacking allows to use the strength of each individual estimator by using their output as input of a final estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d83774fb1981a771cc887192522bcd1ee8713fc" translate="yes" xml:space="preserve">
          <source>Stacked generalization is a method for combining estimators to reduce their biases &lt;a href=&quot;#w1992&quot; id=&quot;id32&quot;&gt;[W1992]&lt;/a&gt;&lt;a href=&quot;#htf&quot; id=&quot;id33&quot;&gt;[HTF]&lt;/a&gt;. More precisely, the predictions of each individual estimator are stacked together and used as input to a final estimator to compute the prediction. This final estimator is trained through cross-validation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93dcc7ee10b4f7f50030c1b93ea7e60ca7979cd4" translate="yes" xml:space="preserve">
          <source>Stacking Classifier and Regressor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a37a65ea2247a4c331699e362c23755d1370e615" translate="yes" xml:space="preserve">
          <source>Stacking refers to a method to blend estimators. In this strategy, some estimators are individually fitted on some training data while a final estimator is trained using the stacked predictions of these base estimators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="891f1b1c9f204fa14cf72f5b45193c02a0d262be" translate="yes" xml:space="preserve">
          <source>Standard deviation of Gaussian noise added to the data.</source>
          <target state="translated">Se ha añadido a los datos la desviación estándar del ruido gaussiano.</target>
        </trans-unit>
        <trans-unit id="a17025349c0cc77d7292705f3e0aace21538f53e" translate="yes" xml:space="preserve">
          <source>Standard deviation of predictive distribution at query points. Only returned when &lt;code&gt;return_std&lt;/code&gt; is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f806d5207c92015615b11e0738f918dc0548c864" translate="yes" xml:space="preserve">
          <source>Standard deviation of predictive distribution at query points. Only returned when return_std is True.</source>
          <target state="translated">Desviación estándar de la distribución predictiva en los puntos de consulta.Sólo se devuelve cuando return_std es True.</target>
        </trans-unit>
        <trans-unit id="6edd185d8d7cdfc859bd82ca69e1fcc7af90edcd" translate="yes" xml:space="preserve">
          <source>Standard deviation of predictive distribution of query points.</source>
          <target state="translated">Desviación estándar de la distribución predictiva de los puntos de consulta.</target>
        </trans-unit>
        <trans-unit id="c37a2551fc59b4216e7ebb6941b4c543d13c64ce" translate="yes" xml:space="preserve">
          <source>Standard deviation over &lt;code&gt;n_repeats&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea11cb9dbd7c4fc006fb08938b76124b12688d69" translate="yes" xml:space="preserve">
          <source>StandardScaler</source>
          <target state="translated">StandardScaler</target>
        </trans-unit>
        <trans-unit id="9f96721b99a0217af973cbedbcbf7d1fa7440aeb" translate="yes" xml:space="preserve">
          <source>Standardization of a dataset is a common requirement for many machine learning estimators. Typically this is done by removing the mean and scaling to unit variance. However, outliers can often influence the sample mean / variance in a negative way. In such cases, the median and the interquartile range often give better results.</source>
          <target state="translated">La estandarización de un conjunto de datos es un requisito común para muchos estimadores de aprendizaje automático.Típicamente esto se hace eliminando la media y escalando a la varianza unitaria.Sin embargo,los valores atípicos a menudo pueden influir en la media/varianza de la muestra de manera negativa.En esos casos,la mediana y el rango intercuartil suelen dar mejores resultados.</target>
        </trans-unit>
        <trans-unit id="3845481860a037ebc5c39c64e8de0e95fe45e3fb" translate="yes" xml:space="preserve">
          <source>Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance).</source>
          <target state="translated">La normalización de un conjunto de datos es un requisito común para muchos estimadores de aprendizaje automático:pueden comportarse mal si las características individuales no se parecen más o menos a los datos estándar distribuidos normalmente (por ejemplo,Gaussiano con media 0 y varianza unitaria).</target>
        </trans-unit>
        <trans-unit id="781aef30981524e4bc3b3ab4682d7e1b6f686dcb" translate="yes" xml:space="preserve">
          <source>Standardize a dataset along any axis</source>
          <target state="translated">Estandarizar un conjunto de datos a lo largo de cualquier eje</target>
        </trans-unit>
        <trans-unit id="8089cb9b9abb90199844c7f8d2ad6ef5ad6b9827" translate="yes" xml:space="preserve">
          <source>Standardize features by removing the mean and scaling to unit variance</source>
          <target state="translated">Estandarizar las características eliminando la media y escalando a la variación unitaria</target>
        </trans-unit>
        <trans-unit id="070fc0ca4dc6d3cb17aee36f0432a76e85e66a77" translate="yes" xml:space="preserve">
          <source>Start pointer to all the leaves.</source>
          <target state="translated">Empieza a apuntar a todas las hojas.</target>
        </trans-unit>
        <trans-unit id="08a6668f9a564bddd6d8fa9fd4934eeea4b017c7" translate="yes" xml:space="preserve">
          <source>Starting configuration of the embedding to initialize the SMACOF algorithm. By default, the algorithm is initialized with a randomly chosen array.</source>
          <target state="translated">Iniciando la configuración de la incrustación para inicializar el algoritmo SMACOF.Por defecto,el algoritmo se inicializa con una matriz elegida al azar.</target>
        </trans-unit>
        <trans-unit id="7252947fdd6406b9475a3bf1b686e53848838289" translate="yes" xml:space="preserve">
          <source>Starting configuration of the embedding to initialize the algorithm. By default, the algorithm is initialized with a randomly chosen array.</source>
          <target state="translated">Iniciando la configuración de la incrustación para inicializar el algoritmo.Por defecto,el algoritmo se inicializa con una matriz elegida al azar.</target>
        </trans-unit>
        <trans-unit id="08977c4568e04a737e6b3a87f7b6021573de1b1c" translate="yes" xml:space="preserve">
          <source>Starting from &lt;code&gt;joblib &amp;gt;= 0.14&lt;/code&gt;, when the &lt;code&gt;loky&lt;/code&gt; backend is used (which is the default), joblib will tell its child &lt;strong&gt;processes&lt;/strong&gt; to limit the number of threads they can use, so as to avoid oversubscription. In practice the heuristic that joblib uses is to tell the processes to use &lt;code&gt;max_threads
= n_cpus // n_jobs&lt;/code&gt;, via their corresponding environment variable. Back to our example from above, since the joblib backend of &lt;code&gt;GridSearchCV&lt;/code&gt; is &lt;code&gt;loky&lt;/code&gt;, each process will only be able to use 1 thread instead of 8, thus mitigating the oversubscription issue.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91cd41feb47c4fc7679dfd69c834b11820027a8b" translate="yes" xml:space="preserve">
          <source>Starting from initial random weights, multi-layer perceptron (MLP) minimizes the loss function by repeatedly updating these weights. After computing the loss, a backward pass propagates it from the output layer to the previous layers, providing each weight parameter with an update value meant to decrease the loss.</source>
          <target state="translated">A partir de pesos aleatorios iniciales,el perceptrón multicapa (MLP)minimiza la función de pérdida actualizando repetidamente estos pesos.Después de calcular la pérdida,un paso hacia atrás la propaga desde la capa de salida a las capas anteriores,proporcionando a cada parámetro de peso un valor de actualización destinado a disminuir la pérdida.</target>
        </trans-unit>
        <trans-unit id="fcf350fa97b4ef940922ec2e36ae5accc928bb98" translate="yes" xml:space="preserve">
          <source>Starting node for path</source>
          <target state="translated">Nodo de inicio de la ruta</target>
        </trans-unit>
        <trans-unit id="bed5865b6136905da0496b8ae96a4873f78bef72" translate="yes" xml:space="preserve">
          <source>Stat Ass, 79:871, 1984.</source>
          <target state="translated">Stat Ass,79:871,1984.</target>
        </trans-unit>
        <trans-unit id="6493ce2cca639b99501821839727266114fab06b" translate="yes" xml:space="preserve">
          <source>Statistical learning</source>
          <target state="translated">Aprendizaje estadístico</target>
        </trans-unit>
        <trans-unit id="ff430697ec62291221833385a34a445a9ee9ecdf" translate="yes" xml:space="preserve">
          <source>Statistical learning: the setting and the estimator object in scikit-learn</source>
          <target state="translated">Aprendizaje estadístico:el escenario y el objeto estimador en scikit-learn</target>
        </trans-unit>
        <trans-unit id="904a41f7fbe4f76d9e16b8a6416dab74831246a2" translate="yes" xml:space="preserve">
          <source>Stef van Buuren, Karin Groothuis-Oudshoorn (2011). &amp;ldquo;mice: Multivariate Imputation by Chained Equations in R&amp;rdquo;. Journal of Statistical Software 45: 1-67.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a673f9d4e8314126b08e8f81bb3a33f3d78b1e09" translate="yes" xml:space="preserve">
          <source>Still effective in cases where number of dimensions is greater than the number of samples.</source>
          <target state="translated">Sigue siendo eficaz en los casos en que el número de dimensiones es mayor que el número de muestras.</target>
        </trans-unit>
        <trans-unit id="2473d40abe8e9fb2e7f524b8bad4d74240273fa9" translate="yes" xml:space="preserve">
          <source>Stochastic Gradient Descent</source>
          <target state="translated">Descenso de gradiente estocástico</target>
        </trans-unit>
        <trans-unit id="195b32448a080f6c15b39de98057b7fe1bc4693b" translate="yes" xml:space="preserve">
          <source>Stochastic Gradient Descent is an optimization technique which minimizes a loss function in a stochastic fashion, performing a gradient descent step sample by sample. In particular, it is a very efficient method to fit linear models.</source>
          <target state="translated">El descenso de gradiente estocástico es una técnica de optimización que minimiza una función de pérdida de manera estocástica,realizando un descenso de gradiente paso a paso muestra por muestra.En particular,es un método muy eficiente para ajustar modelos lineales.</target>
        </trans-unit>
        <trans-unit id="e3aa3ce34d4d1d755f86485089b5a4b4f435a8e2" translate="yes" xml:space="preserve">
          <source>Stochastic Gradient Descent is sensitive to feature scaling, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to [0,1] or [-1,+1], or standardize it to have mean 0 and variance 1. Note that the &lt;em&gt;same&lt;/em&gt; scaling must be applied to the test vector to obtain meaningful results. This can be easily done using &lt;code&gt;StandardScaler&lt;/code&gt;:</source>
          <target state="translated">El descenso de gradiente estoc&amp;aacute;stico es sensible al escalado de caracter&amp;iacute;sticas, por lo que se recomienda encarecidamente escalar sus datos. Por ejemplo, escale cada atributo en el vector de entrada X a [0,1] o [-1, + 1], o estandar&amp;iacute;celo para que tenga una media 0 y una varianza 1. Tenga en cuenta que se debe aplicar la &lt;em&gt;misma&lt;/em&gt; escala al vector de prueba para obtener resultados significativos. Esto se puede hacer f&amp;aacute;cilmente usando &lt;code&gt;StandardScaler&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="ee01e77469d8f50feb7b1b4735d433d85aa0d812" translate="yes" xml:space="preserve">
          <source>Stochastic gradient boosting allows to compute out-of-bag estimates of the test deviance by computing the improvement in deviance on the examples that are not included in the bootstrap sample (i.e. the out-of-bag examples). The improvements are stored in the attribute &lt;code&gt;oob_improvement_&lt;/code&gt;. &lt;code&gt;oob_improvement_[i]&lt;/code&gt; holds the improvement in terms of the loss on the OOB samples if you add the i-th stage to the current predictions. Out-of-bag estimates can be used for model selection, for example to determine the optimal number of iterations. OOB estimates are usually very pessimistic thus we recommend to use cross-validation instead and only use OOB if cross-validation is too time consuming.</source>
          <target state="translated">El refuerzo de gradiente estoc&amp;aacute;stico permite calcular estimaciones fuera de bolsa de la desviaci&amp;oacute;n de la prueba calculando la mejora en la desviaci&amp;oacute;n en los ejemplos que no est&amp;aacute;n incluidos en la muestra de arranque (es decir, los ejemplos fuera de bolsa). Las mejoras se almacenan en el atributo &lt;code&gt;oob_improvement_&lt;/code&gt; . &lt;code&gt;oob_improvement_[i]&lt;/code&gt; contiene la mejora en t&amp;eacute;rminos de p&amp;eacute;rdida en las muestras OOB si agrega la i-&amp;eacute;sima etapa a las predicciones actuales. Las estimaciones fuera de bolsa se pueden utilizar para la selecci&amp;oacute;n del modelo, por ejemplo, para determinar el n&amp;uacute;mero &amp;oacute;ptimo de iteraciones. Las estimaciones de OOB suelen ser muy pesimistas, por lo que recomendamos utilizar la validaci&amp;oacute;n cruzada en su lugar y solo use OOB si la validaci&amp;oacute;n cruzada consume demasiado tiempo.</target>
        </trans-unit>
        <trans-unit id="5823a3f0a9a6ed167c583e77307156305a3e83ac" translate="yes" xml:space="preserve">
          <source>Stochastic gradient descent is a simple yet very efficient approach to fit linear models. It is particularly useful when the number of samples (and the number of features) is very large. The &lt;code&gt;partial_fit&lt;/code&gt; method allows online/out-of-core learning.</source>
          <target state="translated">El descenso de gradiente estoc&amp;aacute;stico es un enfoque simple pero muy eficiente para adaptarse a modelos lineales. Es particularmente &amp;uacute;til cuando el n&amp;uacute;mero de muestras (y el n&amp;uacute;mero de caracter&amp;iacute;sticas) es muy grande. El m&amp;eacute;todo de &lt;code&gt;partial_fit&lt;/code&gt; permite el aprendizaje en l&amp;iacute;nea / fuera del n&amp;uacute;cleo.</target>
        </trans-unit>
        <trans-unit id="88c2b7432b4c70aedd301d6441f9f686fac99afd" translate="yes" xml:space="preserve">
          <source>Stochastic gradient descent is an optimization method for unconstrained optimization problems. In contrast to (batch) gradient descent, SGD approximates the true gradient of \(E(w,b)\) by considering a single training example at a time.</source>
          <target state="translated">El descenso de gradiente estocástico es un método de optimización para los problemas de optimización sin restricciones.En contraste con el descenso de gradiente (por lotes),el SGD se aproxima al verdadero gradiente de \ ~ (E(w,b)\)considerando un solo ejemplo de entrenamiento a la vez.</target>
        </trans-unit>
        <trans-unit id="3bc9b5e942f6c3298a3799e63fea9d4e51700363" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of features. This option is useful only when specifying a connectivity matrix. Note also that when varying the number of clusters and using caching, it may be advantageous to compute the full tree.</source>
          <target state="translated">Detengan pronto la construcción del árbol en n_clusters.Esto es útil para disminuir el tiempo de cálculo si el número de cúmulos no es pequeño comparado con el número de características.Esta opción es útil sólo cuando se especifica una matriz de conectividad.Observe también que al variar el número de cúmulos y utilizar la caché,puede ser ventajoso calcular el árbol completo.</target>
        </trans-unit>
        <trans-unit id="27fa813a99ee0ee872f0a0fdd316cf176619503c" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of features. This option is useful only when specifying a connectivity matrix. Note also that when varying the number of clusters and using caching, it may be advantageous to compute the full tree. It must be &lt;code&gt;True&lt;/code&gt; if &lt;code&gt;distance_threshold&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;. By default &lt;code&gt;compute_full_tree&lt;/code&gt; is &amp;ldquo;auto&amp;rdquo;, which is equivalent to &lt;code&gt;True&lt;/code&gt; when &lt;code&gt;distance_threshold&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt; or that &lt;code&gt;n_clusters&lt;/code&gt; is inferior to the maximum between 100 or &lt;code&gt;0.02 * n_samples&lt;/code&gt;. Otherwise, &amp;ldquo;auto&amp;rdquo; is equivalent to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3dc26590d142d1e5e73aaec1d67524322b86dfd8" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of samples. In this case, the complete tree is not computed, thus the &amp;lsquo;children&amp;rsquo; output is of limited use, and the &amp;lsquo;parents&amp;rsquo; output should rather be used. This option is valid only when specifying a connectivity matrix.</source>
          <target state="translated">Detenga antes la construcci&amp;oacute;n del &amp;aacute;rbol en n_clusters. Esto es &amp;uacute;til para reducir el tiempo de c&amp;aacute;lculo si el n&amp;uacute;mero de conglomerados no es peque&amp;ntilde;o en comparaci&amp;oacute;n con el n&amp;uacute;mero de muestras. En este caso, no se calcula el &amp;aacute;rbol completo, por lo que la salida de los 'hijos' es de uso limitado y la salida de los 'padres' deber&amp;iacute;a utilizarse. Esta opci&amp;oacute;n es v&amp;aacute;lida solo cuando se especifica una matriz de conectividad.</target>
        </trans-unit>
        <trans-unit id="44e9e4435e20e453549059a3ee4002b032ad438a" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of samples. This option is useful only when specifying a connectivity matrix. Note also that when varying the number of clusters and using caching, it may be advantageous to compute the full tree.</source>
          <target state="translated">Detengan pronto la construcción del árbol en n_clusters.Esto es útil para disminuir el tiempo de cálculo si el número de cúmulos no es pequeño comparado con el número de muestras.Esta opción es útil sólo cuando se especifica una matriz de conectividad.Obsérvese también que cuando se varía el número de cúmulos y se utiliza el almacenamiento en caché,puede ser ventajoso calcular el árbol completo.</target>
        </trans-unit>
        <trans-unit id="cec77383bf3b11f332bd0e653f87f2dc409b1dee" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of samples. This option is useful only when specifying a connectivity matrix. Note also that when varying the number of clusters and using caching, it may be advantageous to compute the full tree. It must be &lt;code&gt;True&lt;/code&gt; if &lt;code&gt;distance_threshold&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;. By default &lt;code&gt;compute_full_tree&lt;/code&gt; is &amp;ldquo;auto&amp;rdquo;, which is equivalent to &lt;code&gt;True&lt;/code&gt; when &lt;code&gt;distance_threshold&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt; or that &lt;code&gt;n_clusters&lt;/code&gt; is inferior to the maximum between 100 or &lt;code&gt;0.02 * n_samples&lt;/code&gt;. Otherwise, &amp;ldquo;auto&amp;rdquo; is equivalent to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84a6e50b1119dc5648f3c425a6b5dee68899e309" translate="yes" xml:space="preserve">
          <source>Stop iteration if at least this number of inliers are found.</source>
          <target state="translated">Detenga la iteración si al menos se encuentra este número de inliers.</target>
        </trans-unit>
        <trans-unit id="538193aed5fb2f898d909880cd3e81469e15df67" translate="yes" xml:space="preserve">
          <source>Stop iteration if score is greater equal than this threshold.</source>
          <target state="translated">Detener la iteración si la puntuación es mayor que este umbral.</target>
        </trans-unit>
        <trans-unit id="12517d0c8ade549d252ae4e535d57433e9861479" translate="yes" xml:space="preserve">
          <source>Stop solver after this many iterations regardless of accuracy (XXX Currently there is no API to know whether this kicked in.) -1 by default.</source>
          <target state="translated">Detener el solucionador después de tantas iteraciones sin tener en cuenta la precisión (XXX Actualmente no existe una API para saber si esto se ha activado.)-1 por defecto.</target>
        </trans-unit>
        <trans-unit id="356700453d0a0d54f3f7d4b7b513913c4b6ecef8" translate="yes" xml:space="preserve">
          <source>Stop the algorithm if w has converged.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df6a1587df9722b5b493e30cfc313089ab29220d" translate="yes" xml:space="preserve">
          <source>Stop the algorithm if w has converged. Default is 1.e-3.</source>
          <target state="translated">Detenga el algoritmo si w ha convergido.El valor por defecto es 1.e-3.</target>
        </trans-unit>
        <trans-unit id="7cf46a1e9b2d853c73253eb4c96cbe1ea1bb5aa6" translate="yes" xml:space="preserve">
          <source>Stop words are words like &amp;ldquo;and&amp;rdquo;, &amp;ldquo;the&amp;rdquo;, &amp;ldquo;him&amp;rdquo;, which are presumed to be uninformative in representing the content of a text, and which may be removed to avoid them being construed as signal for prediction. Sometimes, however, similar words are useful for prediction, such as in classifying writing style or personality.</source>
          <target state="translated">Las palabras vac&amp;iacute;as son palabras como &quot;y&quot;, &quot;el&quot;, &quot;&amp;eacute;l&quot;, que se presume que no son informativas al representar el contenido de un texto y que pueden eliminarse para evitar que se interpreten como una se&amp;ntilde;al de predicci&amp;oacute;n. A veces, sin embargo, palabras similares son &amp;uacute;tiles para la predicci&amp;oacute;n, como para clasificar el estilo de escritura o la personalidad.</target>
        </trans-unit>
        <trans-unit id="7eb24af52d1aa9e6b8d6715fd2fd646422f9b535" translate="yes" xml:space="preserve">
          <source>Stopping criteria.</source>
          <target state="translated">Criterios de parada.</target>
        </trans-unit>
        <trans-unit id="2eda661dab2cf19600424ed9df7c9d0563861dff" translate="yes" xml:space="preserve">
          <source>Stopping criterion for eigendecomposition of the Laplacian matrix when &lt;code&gt;eigen_solver='arpack'&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51b3a0bb0b4d84ebe8a65cc9b8c0c2b3279fba93" translate="yes" xml:space="preserve">
          <source>Stopping criterion for eigendecomposition of the Laplacian matrix when using arpack eigen_solver.</source>
          <target state="translated">Criterio de parada para la eigendecomposición de la matriz lapona cuando se utiliza arpack eigen_solver.</target>
        </trans-unit>
        <trans-unit id="a798cb65fb942fe2386149a92d6481d384d3e392" translate="yes" xml:space="preserve">
          <source>Stopping criterion. For the lbfgs solver, the iteration will stop when &lt;code&gt;max{|g_j|, j = 1, ..., d} &amp;lt;= tol&lt;/code&gt; where &lt;code&gt;g_j&lt;/code&gt; is the j-th component of the gradient (derivative) of the objective function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68414daf9a6e27622678aff82460baea3a51326c" translate="yes" xml:space="preserve">
          <source>Stopping criterion. For the newton-cg and lbfgs solvers, the iteration will stop when &lt;code&gt;max{|g_i | i = 1, ..., n} &amp;lt;= tol&lt;/code&gt; where &lt;code&gt;g_i&lt;/code&gt; is the i-th component of the gradient.</source>
          <target state="translated">Criterio de parada. Para los solucionadores newton-cg y lbfgs, la iteraci&amp;oacute;n se detendr&amp;aacute; cuando &lt;code&gt;max{|g_i | i = 1, ..., n} &amp;lt;= tol&lt;/code&gt; donde &lt;code&gt;g_i&lt;/code&gt; es el i-&amp;eacute;simo componente del gradiente.</target>
        </trans-unit>
        <trans-unit id="fe10af6492740b92517388e940d4c53ee7e65f2c" translate="yes" xml:space="preserve">
          <source>Stopping tolerance for EM algorithm.</source>
          <target state="translated">Detener la tolerancia del algoritmo EM.</target>
        </trans-unit>
        <trans-unit id="54709da56f5bb7c428a618dd7d85fb0e4421bcb5" translate="yes" xml:space="preserve">
          <source>Stopping tolerance for log-likelihood increase.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3afb8412732c53a6b3ed5f0cf3d5d66e9526d993" translate="yes" xml:space="preserve">
          <source>Stopping tolerance for updating document topic distribution in E-step.</source>
          <target state="translated">Detener la tolerancia para la actualización de la distribución de temas de documentos en E-step.</target>
        </trans-unit>
        <trans-unit id="5745be1c1a529a40ad5578990283b7d9ed5dfe16" translate="yes" xml:space="preserve">
          <source>Store n output values in leaves, instead of 1;</source>
          <target state="translated">Almacena n valores de salida en hojas,en lugar de 1;</target>
        </trans-unit>
        <trans-unit id="0fac441919e9594e005f5d0571a0bfbc255133fa" translate="yes" xml:space="preserve">
          <source>Stored sampling interval. Specified as a parameter if sample_steps not in {1,2,3}.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a6ab3415c7252ce3e941fe62193814f0365a625" translate="yes" xml:space="preserve">
          <source>Stores nearest neighbors instance, including BallTree or KDtree if applicable.</source>
          <target state="translated">Tiendas de los vecinos más cercanos,incluyendo BallTree o KDtree si es el caso.</target>
        </trans-unit>
        <trans-unit id="f9d028499b97399f71598e9bb920fa52d5ec8313" translate="yes" xml:space="preserve">
          <source>Stores the affinity matrix used in &lt;code&gt;fit&lt;/code&gt;.</source>
          <target state="translated">Almacena la matriz de afinidad utilizada en el &lt;code&gt;fit&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="781b70a9f7d2aabdccb43059620f25863827cacd" translate="yes" xml:space="preserve">
          <source>Stores the embedding vectors</source>
          <target state="translated">Almacena los vectores de incrustación</target>
        </trans-unit>
        <trans-unit id="9fe548f57e57cace725aa47be0bac94930f35de7" translate="yes" xml:space="preserve">
          <source>Stores the embedding vectors.</source>
          <target state="translated">Almacena los vectores de incrustación.</target>
        </trans-unit>
        <trans-unit id="e7019b0e2126237169f8ccc84f1dacd8599b7b63" translate="yes" xml:space="preserve">
          <source>Stores the geodesic distance matrix of training data.</source>
          <target state="translated">Almacena la matriz de distancia geodésica de los datos de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="7bfa0d6921b4ff07d4718354c3a4168af9b3a946" translate="yes" xml:space="preserve">
          <source>Stores the position of the dataset in the embedding space.</source>
          <target state="translated">Almacena la posición del conjunto de datos en el espacio de incrustación.</target>
        </trans-unit>
        <trans-unit id="8197f80c6163117652499db82ad63b22aa5b87b2" translate="yes" xml:space="preserve">
          <source>Stores the training data.</source>
          <target state="translated">Almacena los datos de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="6485fe8179de6b50a8b0db7cf302477ffee4cf50" translate="yes" xml:space="preserve">
          <source>Strategy to use to generate predictions.</source>
          <target state="translated">Estrategia a utilizar para generar predicciones.</target>
        </trans-unit>
        <trans-unit id="9ba291b4721c49cd83c83d224ae746db45b32e1d" translate="yes" xml:space="preserve">
          <source>Strategy used to define the widths of the bins.</source>
          <target state="translated">Estrategia utilizada para definir el ancho de los contenedores.</target>
        </trans-unit>
        <trans-unit id="890ad0feded21dbb4c68bfca3e2d7cdbb498d411" translate="yes" xml:space="preserve">
          <source>Stratified K-Folds cross-validator</source>
          <target state="translated">Validador cruzado de pliegues K estratificados</target>
        </trans-unit>
        <trans-unit id="078f2e04c72cf2c2cef672d9cd530d809895796a" translate="yes" xml:space="preserve">
          <source>Stratified ShuffleSplit cross-validator</source>
          <target state="translated">Validador cruzado ShuffleSplit estratificado</target>
        </trans-unit>
        <trans-unit id="10ef227c2ccc54bd522a7229f1c708e11ce5e295" translate="yes" xml:space="preserve">
          <source>Strehl, Alexander, and Joydeep Ghosh (2002). &amp;ldquo;Cluster ensembles &amp;ndash; a knowledge reuse framework for combining multiple partitions&amp;rdquo;. Journal of Machine Learning Research 3: 583&amp;ndash;617. &lt;a href=&quot;http://strehl.com/download/strehl-jmlr02.pdf&quot;&gt;doi:10.1162/153244303321897735&lt;/a&gt;.</source>
          <target state="translated">Strehl, Alexander y Joydeep Ghosh (2002). &amp;ldquo;Conjuntos de cl&amp;uacute;steres: un marco de reutilizaci&amp;oacute;n del conocimiento para combinar m&amp;uacute;ltiples particiones&amp;rdquo;. Journal of Machine Learning Research 3: 583&amp;ndash;617. &lt;a href=&quot;http://strehl.com/download/strehl-jmlr02.pdf&quot;&gt;doi: 10.1162 / 153244303321897735&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="738d614dd3bdb5fdb2eecf8a98b676a349ac24fe" translate="yes" xml:space="preserve">
          <source>Strictly speaking, SGD is merely an optimization technique and does not correspond to a specific family of machine learning models. It is only a &lt;em&gt;way&lt;/em&gt; to train a model. Often, an instance of &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;SGDClassifier&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.linear_model.sgdregressor#sklearn.linear_model.SGDRegressor&quot;&gt;&lt;code&gt;SGDRegressor&lt;/code&gt;&lt;/a&gt; will have an equivalent estimator in the scikit-learn API, potentially using a different optimization technique. For example, using &lt;code&gt;SGDClassifier(loss='log')&lt;/code&gt; results in logistic regression, i.e. a model equivalent to &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; which is fitted via SGD instead of being fitted by one of the other solvers in &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt;. Similarly, &lt;code&gt;SGDRegressor(loss='squared_loss', penalty='l2')&lt;/code&gt; and &lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt;&lt;code&gt;Ridge&lt;/code&gt;&lt;/a&gt; solve the same optimization problem, via different means.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f823045d1b6e6e3e2566fad8b86b9a7f7274035" translate="yes" xml:space="preserve">
          <source>String describing the type of covariance parameters to use. Must be one of:</source>
          <target state="translated">Cadena que describe el tipo de parámetros de covarianza a utilizar.Debe ser uno de:</target>
        </trans-unit>
        <trans-unit id="24715b349c9d19241a871e75b2e65bf44d424eee" translate="yes" xml:space="preserve">
          <source>String describing the type of the weight concentration prior. Must be one of:</source>
          <target state="translated">Cadena que describe el tipo de la concentración de peso anterior.Debe ser una de:</target>
        </trans-unit>
        <trans-unit id="8c721819e7f297061a3852981915f8763538ca5d" translate="yes" xml:space="preserve">
          <source>String identifier for kernel function to use or the kernel function itself. Only &amp;lsquo;rbf&amp;rsquo; and &amp;lsquo;knn&amp;rsquo; strings are valid inputs. The function passed should take two inputs, each of shape (n_samples, n_features), and return a (n_samples, n_samples) shaped weight matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="428566ee279a0d9edb0dac9070b52a231b258cad" translate="yes" xml:space="preserve">
          <source>String identifier for kernel function to use or the kernel function itself. Only &amp;lsquo;rbf&amp;rsquo; and &amp;lsquo;knn&amp;rsquo; strings are valid inputs. The function passed should take two inputs, each of shape [n_samples, n_features], and return a [n_samples, n_samples] shaped weight matrix</source>
          <target state="translated">Identificador de cadena para que utilice la funci&amp;oacute;n del n&amp;uacute;cleo o la propia funci&amp;oacute;n del n&amp;uacute;cleo. Solo las cadenas 'rbf' y 'knn' son entradas v&amp;aacute;lidas. La funci&amp;oacute;n pasada debe tomar dos entradas, cada una de forma [n_samples, n_features], y devolver una matriz de peso con forma de [n_samples, n_samples]</target>
        </trans-unit>
        <trans-unit id="af724a0a2167e8652dc92f95eace643e40894f38" translate="yes" xml:space="preserve">
          <source>String identifier for kernel function to use or the kernel function itself. Only &amp;lsquo;rbf&amp;rsquo; and &amp;lsquo;knn&amp;rsquo; strings are valid inputs. The function passed should take two inputs, each of shape [n_samples, n_features], and return a [n_samples, n_samples] shaped weight matrix.</source>
          <target state="translated">Identificador de cadena para que utilice la funci&amp;oacute;n del n&amp;uacute;cleo o la propia funci&amp;oacute;n del n&amp;uacute;cleo. Solo las cadenas 'rbf' y 'knn' son entradas v&amp;aacute;lidas. La funci&amp;oacute;n pasada debe tomar dos entradas, cada una de forma [n_samples, n_features], y devolver una matriz de peso con forma de [n_samples, n_samples].</target>
        </trans-unit>
        <trans-unit id="62948e7b4671e9ca0f3cde3750c969c3432c4224" translate="yes" xml:space="preserve">
          <source>String identifier of the dataset. Note that OpenML can have multiple datasets with the same name.</source>
          <target state="translated">Identificador de cadena del conjunto de datos.Tenga en cuenta que el OpenML puede tener múltiples conjuntos de datos con el mismo nombre.</target>
        </trans-unit>
        <trans-unit id="df0679bd93bc3d3699b427e726c60dd8e54a8049" translate="yes" xml:space="preserve">
          <source>String inputs, &amp;ldquo;absolute_loss&amp;rdquo; and &amp;ldquo;squared_loss&amp;rdquo; are supported which find the absolute loss and squared loss per sample respectively.</source>
          <target state="translated">Se admiten entradas de cadena, &quot;p&amp;eacute;rdida_absoluta&quot; y &quot;p&amp;eacute;rdida_cuadrada&quot; que encuentran la p&amp;eacute;rdida absoluta y la p&amp;eacute;rdida al cuadrado por muestra, respectivamente.</target>
        </trans-unit>
        <trans-unit id="0e35f8f4354526879dda20784b410a6fffd10219" translate="yes" xml:space="preserve">
          <source>String must be in {&amp;lsquo;frobenius&amp;rsquo;, &amp;lsquo;kullback-leibler&amp;rsquo;, &amp;lsquo;itakura-saito&amp;rsquo;}. Beta divergence to be minimized, measuring the distance between X and the dot product WH. Note that values different from &amp;lsquo;frobenius&amp;rsquo; (or 2) and &amp;lsquo;kullback-leibler&amp;rsquo; (or 1) lead to significantly slower fits. Note that for beta_loss &amp;lt;= 0 (or &amp;lsquo;itakura-saito&amp;rsquo;), the input matrix X cannot contain zeros. Used only in &amp;lsquo;mu&amp;rsquo; solver.</source>
          <target state="translated">La cadena debe estar en {'frobenius', 'kullback-leibler', 'itakura-saito'}. Se minimiza la divergencia beta, midiendo la distancia entre X y el producto escalar WH. Tenga en cuenta que los valores diferentes de 'frobenius' (o 2) y 'kullback-leibler' (o 1) conducen a ajustes significativamente m&amp;aacute;s lentos. Tenga en cuenta que para beta_loss &amp;lt;= 0 (o 'itakura-saito'), la matriz de entrada X no puede contener ceros. Se usa solo en el solucionador 'mu'.</target>
        </trans-unit>
        <trans-unit id="9f2d9e288ea5ff4eb7ea1abaab0c518bb3979797" translate="yes" xml:space="preserve">
          <source>String names for input features if available. By default, &amp;ldquo;x0&amp;rdquo;, &amp;ldquo;x1&amp;rdquo;, &amp;hellip; &amp;ldquo;xn_features&amp;rdquo; is used.</source>
          <target state="translated">Nombres de cadenas para las funciones de entrada, si est&amp;aacute;n disponibles. De forma predeterminada, se utiliza &quot;x0&quot;, &quot;x1&quot;, ... &quot;xn_features&quot;.</target>
        </trans-unit>
        <trans-unit id="6eb302a1a8353d21c585781076747cec5064ac6a" translate="yes" xml:space="preserve">
          <source>String representation of the input tree in GraphViz dot format. Only returned if &lt;code&gt;out_file&lt;/code&gt; is None.</source>
          <target state="translated">Representaci&amp;oacute;n de cadena del &amp;aacute;rbol de entrada en formato de puntos GraphViz. Solo se devuelve si &lt;code&gt;out_file&lt;/code&gt; es None.</target>
        </trans-unit>
        <trans-unit id="a25a8a192fb86c92debb43e92001c859f89e3fcf" translate="yes" xml:space="preserve">
          <source>String[s] representing allowed sparse matrix formats, such as &amp;lsquo;csc&amp;rsquo;, &amp;lsquo;csr&amp;rsquo;, etc. If the input is sparse but not in the allowed format, it will be converted to the first listed format. True allows the input to be any format. False means that a sparse matrix input will raise an error.</source>
          <target state="translated">Cadena [s] que representa formatos matriciales dispersos permitidos, como 'csc', 'csr', etc. Si la entrada es dispersa pero no est&amp;aacute; en el formato permitido, se convertir&amp;aacute; al primer formato de la lista. True permite que la entrada tenga cualquier formato. Falso significa que una entrada de matriz dispersa generar&amp;aacute; un error.</target>
        </trans-unit>
        <trans-unit id="5110c05a58c323fc1a90d8e9c2d4e3215bf368fd" translate="yes" xml:space="preserve">
          <source>Strings can reference columns if the input is a DataFrame, integers are always interpreted as the positional columns.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b91b90e5e49a63cce92ec827bcf2ae012d9565f3" translate="yes" xml:space="preserve">
          <source>Subsequently, the object is created as:</source>
          <target state="translated">Posteriormente,el objeto se crea como:</target>
        </trans-unit>
        <trans-unit id="858f5a05f03a44bd2c0d7ffef4c39076939797fb" translate="yes" xml:space="preserve">
          <source>Subset of X on axis 0 or 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8cf7e7f541f13164e6f0420a446eeb6e92a09d1" translate="yes" xml:space="preserve">
          <source>Subset of X on first axis</source>
          <target state="translated">Subconjunto de X en el primer eje</target>
        </trans-unit>
        <trans-unit id="6ae596021e773a90882ea646d69c3ae9bc66f60f" translate="yes" xml:space="preserve">
          <source>Subset of target values</source>
          <target state="translated">Subconjunto de valores objetivo</target>
        </trans-unit>
        <trans-unit id="71578b0f6daa48f798b6ba24f599e04480076227" translate="yes" xml:space="preserve">
          <source>Subset of the target values</source>
          <target state="translated">Subconjunto de los valores objetivo</target>
        </trans-unit>
        <trans-unit id="b6f57836197cd859fcd7456747a897dac9249a7c" translate="yes" xml:space="preserve">
          <source>Subset of the target values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="223f88ba981735506f55650c24adc2c0be541ac7" translate="yes" xml:space="preserve">
          <source>Subset of the training data</source>
          <target state="translated">Subconjunto de los datos de capacitación</target>
        </trans-unit>
        <trans-unit id="a36f00d869bab77d370e6340b596e76174606ee7" translate="yes" xml:space="preserve">
          <source>Subset of the training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6bc315a85db741490d46c866dcdf3685f245d4e2" translate="yes" xml:space="preserve">
          <source>Subset of training data</source>
          <target state="translated">Subconjunto de datos de capacitación</target>
        </trans-unit>
        <trans-unit id="19abeb39c58b2714170ce5a2488e41705eacf825" translate="yes" xml:space="preserve">
          <source>Subset of training points used to construct the feature map.</source>
          <target state="translated">Subconjunto de puntos de entrenamiento utilizados para construir el mapa de características.</target>
        </trans-unit>
        <trans-unit id="af82dc274666b6dae18b2b0a4a918322786e1ec9" translate="yes" xml:space="preserve">
          <source>Such a grouping of data is domain specific. An example would be when there is medical data collected from multiple patients, with multiple samples taken from each patient. And such data is likely to be dependent on the individual group. In our example, the patient id for each sample will be its group identifier.</source>
          <target state="translated">Esa agrupación de datos es específica del dominio.Un ejemplo sería cuando se recogen datos médicos de múltiples pacientes,con múltiples muestras tomadas de cada paciente.Y es probable que esos datos dependan del grupo individual.En nuestro ejemplo,la identificación del paciente para cada muestra será su identificador de grupo.</target>
        </trans-unit>
        <trans-unit id="116040368f9a04b617abdb5e80205920c1827d88" translate="yes" xml:space="preserve">
          <source>Such integer representation can, however, not be used directly with all scikit-learn estimators, as these expect continuous input, and would interpret the categories as being ordered, which is often not desired (i.e. the set of browsers was ordered arbitrarily).</source>
          <target state="translated">Sin embargo,esa representación entera no puede utilizarse directamente con todos los estimadores de aprendizaje científico,ya que éstos esperan un aporte continuo,e interpretarían las categorías como si estuvieran ordenadas,lo que a menudo no se desea (es decir,el conjunto de navegadores se ordenó arbitrariamente).</target>
        </trans-unit>
        <trans-unit id="db90c3a55b9a44b531c3ac8e926f4bff46ae5000" translate="yes" xml:space="preserve">
          <source>Sum of squared distances of samples to their closest cluster center.</source>
          <target state="translated">Suma de las distancias cuadradas de las muestras a su centro de cúmulo más cercano.</target>
        </trans-unit>
        <trans-unit id="854e30e5027349dd68053e9c07e26612b753dfb3" translate="yes" xml:space="preserve">
          <source>Sum of the impurities of the subtree leaves for the corresponding alpha value in &lt;code&gt;ccp_alphas&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d0794742200525b0f1825276d5e113f8014eaee" translate="yes" xml:space="preserve">
          <source>Sum the true scores ranked in the order induced by the predicted scores, after applying a logarithmic discount.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c895953cca3a7be3ad68f35cb10044d9d62303c" translate="yes" xml:space="preserve">
          <source>Sum the true scores ranked in the order induced by the predicted scores, after applying a logarithmic discount. Then divide by the best possible score (Ideal DCG, obtained for a perfect ranking) to obtain a score between 0 and 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51853ebee0d0437a819288d394e52f2825e89e10" translate="yes" xml:space="preserve">
          <source>Sum-kernel k1 + k2 of two kernels k1 and k2.</source>
          <target state="translated">Suma el núcleo k1+k2 de dos núcleos k1 y k2.</target>
        </trans-unit>
        <trans-unit id="bb594232250fde950a53bc755dc305c05d6d4d31" translate="yes" xml:space="preserve">
          <source>Summary Statistics</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70ee3e3bff0af30ecffa237a657d140e21c08452" translate="yes" xml:space="preserve">
          <source>Summary Statistics:</source>
          <target state="translated">Estadísticas resumidas:</target>
        </trans-unit>
        <trans-unit id="fd64088007de4ee1ec90faddb61b9fabe7591dbe" translate="yes" xml:space="preserve">
          <source>Supervised learning algorithms will require a category label for each document in the training set. In this case the category is the name of the newsgroup which also happens to be the name of the folder holding the individual documents.</source>
          <target state="translated">Los algoritmos de aprendizaje supervisado requerirán una etiqueta de categoría para cada documento del conjunto de entrenamiento.En este caso,la categoría es el nombre del grupo de noticias que también resulta ser el nombre de la carpeta que contiene los documentos individuales.</target>
        </trans-unit>
        <trans-unit id="a76d63a44e8696360e974f3be74fa9ede463ccb8" translate="yes" xml:space="preserve">
          <source>Supervised learning: predicting an output variable from high-dimensional observations</source>
          <target state="translated">Aprendizaje supervisado:predicción de una variable de salida de observaciones de alta dimensión</target>
        </trans-unit>
        <trans-unit id="a3f901fb4e96c309b27de60d3fa05a2f6c90ddfd" translate="yes" xml:space="preserve">
          <source>Support Vector Classification (SVC) shows an even more sigmoid curve as the RandomForestClassifier, which is typical for maximum-margin methods (compare Niculescu-Mizil and Caruana &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;1&lt;/a&gt;), which focus on hard samples that are close to the decision boundary (the support vectors).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6eafe7087c2917502cf9a105460eb618a5158ac5" translate="yes" xml:space="preserve">
          <source>Support Vector Classification (SVC) shows an even more sigmoid curve as the RandomForestClassifier, which is typical for maximum-margin methods (compare Niculescu-Mizil and Caruana &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;), which focus on hard samples that are close to the decision boundary (the support vectors).</source>
          <target state="translated">La clasificaci&amp;oacute;n de vectores de soporte (SVC) muestra una curva a&amp;uacute;n m&amp;aacute;s sigmoidea como RandomForestClassifier, que es t&amp;iacute;pica de los m&amp;eacute;todos de margen m&amp;aacute;ximo (compare Niculescu-Mizil y Caruana &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt; ), que se centran en muestras duras que est&amp;aacute;n cerca del l&amp;iacute;mite de decisi&amp;oacute;n (el vectores de soporte).</target>
        </trans-unit>
        <trans-unit id="ed5eaa4e09c1fde40caa79c99d658b1a804b4ecf" translate="yes" xml:space="preserve">
          <source>Support Vector Machine algorithms are not scale invariant, so &lt;strong&gt;it is highly recommended to scale your data&lt;/strong&gt;. For example, scale each attribute on the input vector X to [0,1] or [-1,+1], or standardize it to have mean 0 and variance 1. Note that the &lt;em&gt;same&lt;/em&gt; scaling must be applied to the test vector to obtain meaningful results. See section &lt;a href=&quot;preprocessing#preprocessing&quot;&gt;Preprocessing data&lt;/a&gt; for more details on scaling and normalization.</source>
          <target state="translated">Los algoritmos de Support Vector Machine no son invariantes de escala, por &lt;strong&gt;lo que se recomienda encarecidamente escalar sus datos&lt;/strong&gt; . Por ejemplo, escale cada atributo en el vector de entrada X a [0,1] o [-1, + 1], o estandar&amp;iacute;celo para tener media 0 y varianza 1. Tenga en cuenta que se debe aplicar la &lt;em&gt;misma&lt;/em&gt; escala al vector de prueba para obtener resultados significativos. Consulte la secci&amp;oacute;n &lt;a href=&quot;preprocessing#preprocessing&quot;&gt;Preprocesamiento de datos&lt;/a&gt; para obtener m&amp;aacute;s detalles sobre el escalado y la normalizaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="6759d5fe5cd02546f72e19999514f8d8dd0c2afc" translate="yes" xml:space="preserve">
          <source>Support Vector Machine algorithms are not scale invariant, so &lt;strong&gt;it is highly recommended to scale your data&lt;/strong&gt;. For example, scale each attribute on the input vector X to [0,1] or [-1,+1], or standardize it to have mean 0 and variance 1. Note that the &lt;em&gt;same&lt;/em&gt; scaling must be applied to the test vector to obtain meaningful results. This can be done easily by using a &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7db4fe2bb2b495808d702cc828d549eda5ecd6dd" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for Regression implemented using libsvm.</source>
          <target state="translated">Máquina Vectorial de Apoyo para la Regresión implementada usando libsvm.</target>
        </trans-unit>
        <trans-unit id="f893d85d40edb954e6730df0c490772b3e2a0229" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for classification implemented with libsvm with a parameter to control the number of support vectors.</source>
          <target state="translated">Máquina de Vectores de Apoyo para la clasificación implementada con libsvm con un parámetro para controlar el número de vectores de apoyo.</target>
        </trans-unit>
        <trans-unit id="5051cb5a7ebb600b6c87a0405fb53ae2a929b69a" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for classification using libsvm.</source>
          <target state="translated">Máquina vectorial de apoyo para la clasificación usando libsvm.</target>
        </trans-unit>
        <trans-unit id="c9c0030d3280fdd6faa0de4e8ec40fd895c7cc05" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for regression implemented using libsvm using a parameter to control the number of support vectors.</source>
          <target state="translated">Máquina de vectores de apoyo para la regresión implementada mediante libsvm utilizando un parámetro para controlar el número de vectores de apoyo.</target>
        </trans-unit>
        <trans-unit id="0e9e942139034d62a386d593445cc7ca0b8119c8" translate="yes" xml:space="preserve">
          <source>Support Vector Machines</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09b4534def5c091569acb02092fe6cf8bbcb767a" translate="yes" xml:space="preserve">
          <source>Support Vector Machines are powerful tools, but their compute and storage requirements increase rapidly with the number of training vectors. The core of an SVM is a quadratic programming problem (QP), separating support vectors from the rest of the training data. The QP solver used by the &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;-based implementation scales between \(O(n_{features} \times n_{samples}^2)\) and \(O(n_{features} \times n_{samples}^3)\) depending on how efficiently the &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; cache is used in practice (dataset dependent). If the data is very sparse \(n_{features}\) should be replaced by the average number of non-zero features in a sample vector.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56158ab7bc33e3424017c0101c6f6a1afb88a3a9" translate="yes" xml:space="preserve">
          <source>Support Vector Machines are powerful tools, but their compute and storage requirements increase rapidly with the number of training vectors. The core of an SVM is a quadratic programming problem (QP), separating support vectors from the rest of the training data. The QP solver used by this &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;-based implementation scales between \(O(n_{features} \times n_{samples}^2)\) and \(O(n_{features} \times n_{samples}^3)\) depending on how efficiently the &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; cache is used in practice (dataset dependent). If the data is very sparse \(n_{features}\) should be replaced by the average number of non-zero features in a sample vector.</source>
          <target state="translated">Support Vector Machines son herramientas poderosas, pero sus requisitos de computaci&amp;oacute;n y almacenamiento aumentan r&amp;aacute;pidamente con la cantidad de vectores de entrenamiento. El n&amp;uacute;cleo de una SVM es un problema de programaci&amp;oacute;n cuadr&amp;aacute;tica (QP), que separa los vectores de soporte del resto de los datos de entrenamiento. El solucionador de QP utilizado por esta implementaci&amp;oacute;n basada en &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; escala entre \ (O (n_ {caracter&amp;iacute;sticas} \ veces n_ {muestras} ^ 2) \) y \ (O (n_ {caracter&amp;iacute;sticas} \ veces n_ {muestras} ^ 3) \ ) dependiendo de la eficiencia con la que se &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;utilice la&lt;/a&gt; cach&amp;eacute; libsvm en la pr&amp;aacute;ctica (depende del conjunto de datos). Si los datos son muy escasos \ (n_ {caracter&amp;iacute;sticas} \) deben reemplazarse por el n&amp;uacute;mero promedio de caracter&amp;iacute;sticas distintas de cero en un vector de muestra.</target>
        </trans-unit>
        <trans-unit id="5aeba1d5d3764ce4f342c9f3c5c4d98c95831ef3" translate="yes" xml:space="preserve">
          <source>Support Vector Regression (SVR) using linear and non-linear kernels</source>
          <target state="translated">Apoyar la Regresión Vectorial (SVR)usando núcleos lineales y no lineales</target>
        </trans-unit>
        <trans-unit id="c38caf86bc0ea77939ed0d559b2d4f17cae05de8" translate="yes" xml:space="preserve">
          <source>Support Vector Regression implemented using libsvm.</source>
          <target state="translated">Regresión vectorial de apoyo implementada usando libsvm.</target>
        </trans-unit>
        <trans-unit id="9f57f9c660b4dd2f0deaa4ba97e0c878c516d5af" translate="yes" xml:space="preserve">
          <source>Support vector machines (SVMs)</source>
          <target state="translated">Apoyar las máquinas de vectores (SVM)</target>
        </trans-unit>
        <trans-unit id="bbbf41eb38c0c6ebc14c9776b74f3b7c7223e260" translate="yes" xml:space="preserve">
          <source>Support vectors.</source>
          <target state="translated">Vectores de apoyo.</target>
        </trans-unit>
        <trans-unit id="a54e8408d47bb6e31202d1c04b19dcb2a41dd085" translate="yes" xml:space="preserve">
          <source>Supports sparse matrices, as long as they are nonnegative.</source>
          <target state="translated">Soporta matrices escasas,siempre y cuando no sean negativas.</target>
        </trans-unit>
        <trans-unit id="3d69897cfb127444947f0af512011088c32f7842" translate="yes" xml:space="preserve">
          <source>Suppose there are \(n\) training samples, \(m\) features, \(k\) hidden layers, each containing \(h\) neurons - for simplicity, and \(o\) output neurons. The time complexity of backpropagation is \(O(n\cdot m \cdot h^k \cdot o \cdot i)\), where \(i\) is the number of iterations. Since backpropagation has a high time complexity, it is advisable to start with smaller number of hidden neurons and few hidden layers for training.</source>
          <target state="translated">Supongamos que hay muestras de entrenamiento,características,capas ocultas,cada una de las cuales contiene neuronas,por simplicidad,y neuronas de salida.La complejidad temporal de la retropropagación es la complejidad temporal de la retropropagación,donde el número de iteraciones es el número de iteraciones.Como la retropropagación tiene una gran complejidad temporal,es aconsejable empezar con un número menor de neuronas ocultas y pocas capas ocultas para el entrenamiento.</target>
        </trans-unit>
        <trans-unit id="cd4ffcedd7e0903b657852f1e48effcf51cd6dba" translate="yes" xml:space="preserve">
          <source>Suppose you have a machine with 8 CPUs. Consider a case where you&amp;rsquo;re running a &lt;code&gt;GridSearchCV&lt;/code&gt; (parallelized with joblib) with &lt;code&gt;n_jobs=8&lt;/code&gt; over a &lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt; (parallelized with OpenMP). Each instance of &lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt; will spawn 8 threads (since you have 8 CPUs). That&amp;rsquo;s a total of &lt;code&gt;8 * 8 = 64&lt;/code&gt; threads, which leads to oversubscription of physical CPU resources and to scheduling overhead.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="717b26aef2df5c03a35ae859cfcbb420ec45f953" translate="yes" xml:space="preserve">
          <source>Swaps two columns of a CSC/CSR matrix in-place.</source>
          <target state="translated">Intercambia dos columnas de una matriz CSC/CSR en el lugar.</target>
        </trans-unit>
        <trans-unit id="1069fce64f91499526a54ca2a920222a7a6a7b20" translate="yes" xml:space="preserve">
          <source>Swaps two rows of a CSC/CSR matrix in-place.</source>
          <target state="translated">Cambia dos filas de una matriz CSC/CSR en el lugar.</target>
        </trans-unit>
        <trans-unit id="fe072010fa51f4d65d4b1c57510d1adce13a6e7b" translate="yes" xml:space="preserve">
          <source>Swiss Roll reduction with LLE</source>
          <target state="translated">Reducción del Swiss Roll con LLE</target>
        </trans-unit>
        <trans-unit id="2230299d58c6b8fd7778e9806246c78a89ba5d37" translate="yes" xml:space="preserve">
          <source>Symmetrized version of the input array, i.e. the average of array and array.transpose(). If sparse, then duplicate entries are first summed and zeros are eliminated.</source>
          <target state="translated">Versión simétrica de la matriz de entrada,es decir,el promedio de array y array.transpose().Si son escasos,entonces las entradas duplicadas se suman primero y se eliminan los ceros.</target>
        </trans-unit>
        <trans-unit id="5617e20da29f8f9d1be80cd4e8da4f2cca7d87a9" translate="yes" xml:space="preserve">
          <source>Symmetry: d(x, y) = d(y, x)</source>
          <target state="translated">Simetría:d(x,y)=d(y,x)</target>
        </trans-unit>
        <trans-unit id="5c4b58b32e84506455d7badad68c3391e5ed62f8" translate="yes" xml:space="preserve">
          <source>Synthetic example</source>
          <target state="translated">Ejemplo sintético</target>
        </trans-unit>
        <trans-unit id="a2f05b63d3eed62a3d034f7470902282f6f3879f" translate="yes" xml:space="preserve">
          <source>T. Calinski and J. Harabasz, 1974. &amp;ldquo;A dendrite method for cluster analysis&amp;rdquo;. Communications in Statistics</source>
          <target state="translated">T. Calinski y J. Harabasz, 1974. &amp;ldquo;Un m&amp;eacute;todo de dendrita para el an&amp;aacute;lisis de conglomerados&amp;rdquo;. Comunicaciones en estad&amp;iacute;stica</target>
        </trans-unit>
        <trans-unit id="cfd0a0e6ed4317c498cad6dff52fb64a880cf1fc" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman, &amp;ldquo;Elements of Statistical Learning Ed. 2&amp;rdquo;, Springer, 2009.</source>
          <target state="translated">T. Hastie, R. Tibshirani y J. Friedman, &amp;ldquo;Elements of Statistical Learning Ed. 2 &amp;rdquo;, Springer, 2009.</target>
        </trans-unit>
        <trans-unit id="7f7943ebfea41ffafd05b1021989488d98e43338" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman, &amp;ldquo;Elements of Statistical Learning Ed. 2&amp;rdquo;, p592-593, Springer, 2009.</source>
          <target state="translated">T. Hastie, R. Tibshirani y J. Friedman, &amp;ldquo;Elements of Statistical Learning Ed. 2 &amp;rdquo;, p592-593, Springer, 2009.</target>
        </trans-unit>
        <trans-unit id="70c29954ab4c3cb7794dae94a173c1937d4eb172" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman, &amp;ldquo;Elements of Statistical Learning&amp;rdquo;, Springer, 2009.</source>
          <target state="translated">T. Hastie, R. Tibshirani y J. Friedman, &quot;Elementos del aprendizaje estad&amp;iacute;stico&quot;, Springer, 2009.</target>
        </trans-unit>
        <trans-unit id="1a36ad5ec8c80f7993b9fd82eb2686d2da21883a" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman, &lt;a href=&quot;https://web.stanford.edu/~hastie/ElemStatLearn//&quot;&gt;The Elements of Statistical Learning&lt;/a&gt;, Second Edition, Section 10.13.2, Springer, 2009.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83fcdb4c642340f440ec3c76643b0ff4a3e4d907" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman. &amp;ldquo;Elements of Statistical Learning&amp;rdquo;, Springer, 2009.</source>
          <target state="translated">T. Hastie, R. Tibshirani y J. Friedman. &quot;Elementos del aprendizaje estad&amp;iacute;stico&quot;, Springer, 2009.</target>
        </trans-unit>
        <trans-unit id="cb7835aaacc19565f84e186774c00699f37d4811" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman. Elements of Statistical Learning Ed. 2, Springer, 2009.</source>
          <target state="translated">T.Hastie,R.Tibshirani y J.Friedman.Elements of Statistical Learning Ed.2,Springer,2009.</target>
        </trans-unit>
        <trans-unit id="d4c99bc2ba4c28ec35fea9e0c8535d7da602917b" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman. Elements of Statistical Learning, Springer, 2009.</source>
          <target state="translated">T.Hastie,R.Tibshirani y J.Friedman.Elements of Statistical Learning,Springer,2009.</target>
        </trans-unit>
        <trans-unit id="080b47cb3536b08b8d64a0132c354c0e69235639" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani, J. Friedman, &lt;a href=&quot;https://web.stanford.edu/~hastie/ElemStatLearn/&quot;&gt;The Elements of Statistical Learning&lt;/a&gt;, Springer 2009</source>
          <target state="translated">T. Hastie, R. Tibshirani, J. Friedman, &lt;a href=&quot;https://web.stanford.edu/~hastie/ElemStatLearn/&quot;&gt;Los elementos del aprendizaje estad&amp;iacute;stico&lt;/a&gt; , Springer 2009</target>
        </trans-unit>
        <trans-unit id="caa676716fee5a5c020ff878a7d0616f2b82e015" translate="yes" xml:space="preserve">
          <source>T. Ho, &amp;ldquo;The random subspace method for constructing decision forests&amp;rdquo;, Pattern Analysis and Machine Intelligence, 20(8), 832-844, 1998.</source>
          <target state="translated">T. Ho, &quot;El m&amp;eacute;todo subespacial aleatorio para construir bosques de decisi&amp;oacute;n&quot;, An&amp;aacute;lisis de patrones e inteligencia de m&amp;aacute;quinas, 20 (8), 832-844, 1998.</target>
        </trans-unit>
        <trans-unit id="12a252b4085c50c08e5600b6a2ace31faa3ef960" translate="yes" xml:space="preserve">
          <source>T. Yang, Y. Li, M. Mahdavi, R. Jin and Z. Zhou &amp;ldquo;Nystroem Method vs Random Fourier Features: A Theoretical and Empirical Comparison&amp;rdquo;, Advances in Neural Information Processing Systems 2012</source>
          <target state="translated">T. Yang, Y. Li, M. Mahdavi, R. Jin y Z. Zhou &quot;M&amp;eacute;todo Nystroem vs Caracter&amp;iacute;sticas aleatorias de Fourier: una comparaci&amp;oacute;n te&amp;oacute;rica y emp&amp;iacute;rica&quot;, Avances en sistemas de procesamiento de informaci&amp;oacute;n neuronal 2012</target>
        </trans-unit>
        <trans-unit id="01f0642e8e9ab9a87342728e5ceb8bbd9d2f4ab3" translate="yes" xml:space="preserve">
          <source>TAX full-value property-tax rate per $10,000</source>
          <target state="translated">Tasa del impuesto sobre la propiedad inmobiliaria por 10.000 dólares.</target>
        </trans-unit>
        <trans-unit id="dd1b5c68340d106d37b309522fe8b393cb21ad39" translate="yes" xml:space="preserve">
          <source>TF-IDF vectors of text documents crawled from the web</source>
          <target state="translated">Vectores TF-IDF de documentos de texto arrastrados por la web</target>
        </trans-unit>
        <trans-unit id="45e8bc91482fcb8372ecf82971819bb3adf7f455" translate="yes" xml:space="preserve">
          <source>TODO: implement zip dataset loading too</source>
          <target state="translated">TODO:implementar la carga del conjunto de datos zip también</target>
        </trans-unit>
        <trans-unit id="8ab0e32d1d047cd892b558c9b2f078b6857615c4" translate="yes" xml:space="preserve">
          <source>Takes a group array to group observations.</source>
          <target state="translated">Se necesita un conjunto de grupo para agrupar las observaciones.</target>
        </trans-unit>
        <trans-unit id="3fd5fa24212eb9a6093f6fb3922373c2e928c57e" translate="yes" xml:space="preserve">
          <source>Takes group information into account to avoid building folds with imbalanced class distributions (for binary or multiclass classification tasks).</source>
          <target state="translated">Tiene en cuenta la información de grupo para evitar la construcción de pliegues con distribuciones de clases desequilibradas (para las tareas de clasificación binaria o multiclase).</target>
        </trans-unit>
        <trans-unit id="d9f2745c15759b2e07e7b8ac9dcbd8d3eb7f1df5" translate="yes" xml:space="preserve">
          <source>Talks given, slide-sets and other information relevant to scikit-learn.</source>
          <target state="translated">Charlas dadas,juegos de diapositivas y otra información relevante para el aprendizaje de la ciencia.</target>
        </trans-unit>
        <trans-unit id="61ad50a9b9189cc3cf1874568e35e7901ff4c982" translate="yes" xml:space="preserve">
          <source>Target</source>
          <target state="translated">Target</target>
        </trans-unit>
        <trans-unit id="27a0909e2e214e16b84c188da9b6e36fbb24a75c" translate="yes" xml:space="preserve">
          <source>Target Domain</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0810f8f564f353b71a4c98cca217fcf1b526a4f" translate="yes" xml:space="preserve">
          <source>Target cardinality</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a92a80f8cb5657b9d712fa7c0bc7d1998153a6b8" translate="yes" xml:space="preserve">
          <source>Target names used for plotting. By default, &lt;code&gt;labels&lt;/code&gt; will be used if it is defined, otherwise the unique labels of &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; will be used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3566560919d090e98a5bc58e40d68ba478487e60" translate="yes" xml:space="preserve">
          <source>Target number of non-zero coefficients. Use &lt;code&gt;np.inf&lt;/code&gt; for no limit.</source>
          <target state="translated">N&amp;uacute;mero objetivo de coeficientes distintos de cero. Utilice &lt;code&gt;np.inf&lt;/code&gt; sin l&amp;iacute;mite.</target>
        </trans-unit>
        <trans-unit id="de81f661c0a5f66b2eb62d654cf5ee97c42a462f" translate="yes" xml:space="preserve">
          <source>Target relative to X for classification or regression; None for unsupervised learning.</source>
          <target state="translated">Objetivo relativo a X para la clasificación o la regresión;Ninguno para el aprendizaje no supervisado.</target>
        </trans-unit>
        <trans-unit id="d9d3de45f60123470c229b29def5cf613978229f" translate="yes" xml:space="preserve">
          <source>Target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions (as returned by &amp;ldquo;decision_function&amp;rdquo; on some classifiers).</source>
          <target state="translated">Las puntuaciones objetivo pueden ser estimaciones de probabilidad de la clase positiva, valores de confianza o medidas de decisiones sin umbral (seg&amp;uacute;n lo devuelto por &quot;decision_function&quot; en algunos clasificadores).</target>
        </trans-unit>
        <trans-unit id="2da36130db1b72e7220423e41225d3cfbecbf96b" translate="yes" xml:space="preserve">
          <source>Target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions (as returned by &amp;ldquo;decision_function&amp;rdquo; on some classifiers). For binary y_true, y_score is supposed to be the score of the class with greater label.</source>
          <target state="translated">Las puntuaciones objetivo pueden ser estimaciones de probabilidad de la clase positiva, valores de confianza o medidas de decisiones sin umbral (seg&amp;uacute;n lo devuelto por &quot;decision_function&quot; en algunos clasificadores). Para y_true binario, se supone que y_score es la puntuaci&amp;oacute;n de la clase con una etiqueta m&amp;aacute;s grande.</target>
        </trans-unit>
        <trans-unit id="e311afc7eeab469d8890dd7eea87d765736badbd" translate="yes" xml:space="preserve">
          <source>Target scores, can either be probability estimates, confidence values, or non-thresholded measure of decisions (as returned by &amp;ldquo;decision_function&amp;rdquo; on some classifiers).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b0d9d264d1c088751e6e40c1e8e25db9f44f02f" translate="yes" xml:space="preserve">
          <source>Target scores. In the binary and multilabel cases, these can be either probability estimates or non-thresholded decision values (as returned by &lt;code&gt;decision_function&lt;/code&gt; on some classifiers). In the multiclass case, these must be probability estimates which sum to 1. The binary case expects a shape (n_samples,), and the scores must be the scores of the class with the greater label. The multiclass and multilabel cases expect a shape (n_samples, n_classes). In the multiclass case, the order of the class scores must correspond to the order of &lt;code&gt;labels&lt;/code&gt;, if provided, or else to the numerical or lexicographical order of the labels in &lt;code&gt;y_true&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c1467eb9fce38ab3f431a143b7b4099a3d2d978" translate="yes" xml:space="preserve">
          <source>Target values</source>
          <target state="translated">Valores objetivo</target>
        </trans-unit>
        <trans-unit id="1eb29851ae3516c30efee3683f12f4c58d29d5ce" translate="yes" xml:space="preserve">
          <source>Target values (class labels in classification, real numbers in regression)</source>
          <target state="translated">Valores objetivo (etiquetas de clase en la clasificación,números reales en la regresión)</target>
        </trans-unit>
        <trans-unit id="9236c7bb185e41917cc98485dd0c1b72938dc4f1" translate="yes" xml:space="preserve">
          <source>Target values (integers for classification, real numbers for regression).</source>
          <target state="translated">Valores objetivo (números enteros para la clasificación,números reales para la regresión).</target>
        </trans-unit>
        <trans-unit id="abfa5417a6d6ee53dab20f6c0ef952512e0950c9" translate="yes" xml:space="preserve">
          <source>Target values (integers)</source>
          <target state="translated">Valores objetivo (números enteros)</target>
        </trans-unit>
        <trans-unit id="030d74b88e6ada2cc611aa05819c6875ad926cb6" translate="yes" xml:space="preserve">
          <source>Target values (integers). Will be cast to X&amp;rsquo;s dtype if necessary</source>
          <target state="translated">Valores objetivo (enteros). Se convertir&amp;aacute; en dtype de X si es necesario</target>
        </trans-unit>
        <trans-unit id="489913dd1ba6e89f6fe19c6ab73a6d0ba1572bbc" translate="yes" xml:space="preserve">
          <source>Target values (strings or integers in classification, real numbers in regression) For classification, labels must correspond to classes.</source>
          <target state="translated">Valores objetivo (cadenas o números enteros en la clasificación,números reales en la regresión)Para la clasificación,las etiquetas deben corresponder a las clases.</target>
        </trans-unit>
        <trans-unit id="20f1907edd6deff55545e2c6878457953ca23f05" translate="yes" xml:space="preserve">
          <source>Target values in training data (also required for prediction)</source>
          <target state="translated">Valores objetivo en los datos de capacitación (también requeridos para la predicción)</target>
        </trans-unit>
        <trans-unit id="5698f85443295556a3231f89aa327fa20aab0ad9" translate="yes" xml:space="preserve">
          <source>Target values of shape = [n_samples] or [n_samples, n_outputs]</source>
          <target state="translated">Valores objetivo de la forma=[n_muestras]o [n_muestras,n_salidas]</target>
        </trans-unit>
        <trans-unit id="da9e802f308bd36e270eb5bda433836f08ce2390" translate="yes" xml:space="preserve">
          <source>Target values, array of float values, shape = [n_samples]</source>
          <target state="translated">Valores objetivo,matriz de valores de flotación,forma=[n_muestras]</target>
        </trans-unit>
        <trans-unit id="9d4acf064ddb5b23ed0c4bdf7cb1ed1c86e0cce4" translate="yes" xml:space="preserve">
          <source>Target values, must be binary</source>
          <target state="translated">Los valores objetivo,deben ser binarios</target>
        </trans-unit>
        <trans-unit id="3784ae1e62853f0d4899c1eb47f9d650c50e4292" translate="yes" xml:space="preserve">
          <source>Target values.</source>
          <target state="translated">Valores objetivo.</target>
        </trans-unit>
        <trans-unit id="7a264b43381dcd3fa803548587f56b48ebe73a21" translate="yes" xml:space="preserve">
          <source>Target values. All sparse matrices are converted to CSR before inverse transformation.</source>
          <target state="translated">Valores objetivo.Todas las matrices dispersas se convierten en CSR antes de la transformación inversa.</target>
        </trans-unit>
        <trans-unit id="338b0342f37ab2a3243f471f75fbb6b8060759e1" translate="yes" xml:space="preserve">
          <source>Target values. Class labels must be an integer or float, or array-like objects of integer or float for multilabel classifications.</source>
          <target state="translated">Valores objetivo.Las etiquetas de clase deben ser un número entero o flotante,o objetos similares a una matriz de números enteros o flotantes para las clasificaciones de etiquetas múltiples.</target>
        </trans-unit>
        <trans-unit id="d95ddd0372c185ada4f873880d8cf72b3e972b79" translate="yes" xml:space="preserve">
          <source>Target values. The 2-d matrix should only contain 0 and 1, represents multilabel classification.</source>
          <target state="translated">Valores objetivo.La matriz 2-d debe contener sólo 0 y 1,representa la clasificación de la multi-etiqueta.</target>
        </trans-unit>
        <trans-unit id="7d68da7045b7713975074def112516b22e3d548e" translate="yes" xml:space="preserve">
          <source>Target values. The 2-d matrix should only contain 0 and 1, represents multilabel classification. Sparse matrix can be CSR, CSC, COO, DOK, or LIL.</source>
          <target state="translated">Valores objetivo.La matriz 2-d debe contener sólo 0 y 1,representa la clasificación de la multi-etiqueta.La matriz dispersa puede ser CSR,CSC,COO,DOK o LIL.</target>
        </trans-unit>
        <trans-unit id="5ca333a3206ea1ae310cc995419dd5b579b0311c" translate="yes" xml:space="preserve">
          <source>Target values. Will be cast to X&amp;rsquo;s dtype if necessary</source>
          <target state="translated">Valores objetivo. Se convertir&amp;aacute; en dtype de X si es necesario</target>
        </trans-unit>
        <trans-unit id="26a7504c7e3fd5624ea9f7504b20b691f54baa64" translate="yes" xml:space="preserve">
          <source>Target values. Will be cast to X&amp;rsquo;s dtype if necessary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a73f8fffa45e4edde85ae5cfe9a7df8f5b0ddf64" translate="yes" xml:space="preserve">
          <source>Target vector (class labels).</source>
          <target state="translated">Vector objetivo (etiquetas de clase).</target>
        </trans-unit>
        <trans-unit id="fbbf7212be6c75614582f7683105e9b145317ffe" translate="yes" xml:space="preserve">
          <source>Target vector relative to X</source>
          <target state="translated">Vector del objetivo relativo a X</target>
        </trans-unit>
        <trans-unit id="9b9ad2408038efc60fe0697bee9336f5ceee389a" translate="yes" xml:space="preserve">
          <source>Target vector relative to X.</source>
          <target state="translated">Vector del objetivo relativo a X.</target>
        </trans-unit>
        <trans-unit id="cb81b6b3ab32530c4b31b59fded732e0bc1457db" translate="yes" xml:space="preserve">
          <source>Target vector.</source>
          <target state="translated">Vector del objetivo.</target>
        </trans-unit>
        <trans-unit id="86747748812222a9af434d10160edcea63797259" translate="yes" xml:space="preserve">
          <source>Target vectors, where n_samples is the number of samples and n_targets is the number of response variables.</source>
          <target state="translated">Vectores objetivo,donde n_muestras es el número de muestras y n_objetivos es el número de variables de respuesta.</target>
        </trans-unit>
        <trans-unit id="bb444a37f78059e3557a89e3cec7d30ee2a0e255" translate="yes" xml:space="preserve">
          <source>Target. Will be cast to X&amp;rsquo;s dtype if necessary</source>
          <target state="translated">Objetivo. Se convertir&amp;aacute; en dtype de X si es necesario</target>
        </trans-unit>
        <trans-unit id="652ac2cbbafccc62d55637f20bfa949ef565ffbd" translate="yes" xml:space="preserve">
          <source>Target:</source>
          <target state="translated">Target:</target>
        </trans-unit>
        <trans-unit id="d35260a00f655f27edcc35a7eb16da44a4f671a6" translate="yes" xml:space="preserve">
          <source>Targets</source>
          <target state="translated">Targets</target>
        </trans-unit>
        <trans-unit id="bae347ef05fa5719d83860ee11ad8e50b4550a95" translate="yes" xml:space="preserve">
          <source>Targets for input data.</source>
          <target state="translated">Objetivos de los datos de entrada.</target>
        </trans-unit>
        <trans-unit id="25e14b664fd8a2e3008eacd528868e3512f875a8" translate="yes" xml:space="preserve">
          <source>Targets for supervised learning.</source>
          <target state="translated">Objetivos para el aprendizaje supervisado.</target>
        </trans-unit>
        <trans-unit id="135d4c14ef59d437ba9b3977ff9548aa96a57252" translate="yes" xml:space="preserve">
          <source>Targets for supervised or &lt;code&gt;None&lt;/code&gt; for unsupervised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e907b7e300146da06f6bd372dfec64398cc10d60" translate="yes" xml:space="preserve">
          <source>Targets used for scoring. Must fulfill label requirements for all steps of the pipeline.</source>
          <target state="translated">Objetivos utilizados para la puntuación.Deben cumplir con los requisitos de la etiqueta para todos los pasos de la tubería.</target>
        </trans-unit>
        <trans-unit id="12f7c88d38da9108a78eb595ada57372e18cdd00" translate="yes" xml:space="preserve">
          <source>Technically the Lasso model is optimizing the same objective function as the Elastic Net with &lt;code&gt;l1_ratio=1.0&lt;/code&gt; (no L2 penalty).</source>
          <target state="translated">T&amp;eacute;cnicamente, el modelo Lasso est&amp;aacute; optimizando la misma funci&amp;oacute;n objetivo que Elastic Net con &lt;code&gt;l1_ratio=1.0&lt;/code&gt; (sin penalizaci&amp;oacute;n L2).</target>
        </trans-unit>
        <trans-unit id="7c21757d6dba7765c9b420762d607df44985a57d" translate="yes" xml:space="preserve">
          <source>Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline.</source>
          <target state="translated">Se obtuvieron diez variables de referencia,edad,sexo,índice de masa corporal,presión arterial media y seis mediciones de suero sanguíneo para cada uno de los n=442 pacientes de diabetes,así como la respuesta de interés,una medida cuantitativa de la progresión de la enfermedad un año después de la referencia.</target>
        </trans-unit>
        <trans-unit id="faacbc438202f94eb51c4c27efecd77f5a804a90" translate="yes" xml:space="preserve">
          <source>Tenenbaum, J.B.; De Silva, V.; &amp;amp; Langford, J.C. A global geometric framework for nonlinear dimensionality reduction. Science 290 (5500)</source>
          <target state="translated">Tenenbaum, JB; De Silva, V .; &amp;amp; Langford, JC Un marco geom&amp;eacute;trico global para la reducci&amp;oacute;n de dimensionalidad no lineal. Ciencia 290 (5500)</target>
        </trans-unit>
        <trans-unit id="2a1358959d0f2f819085e4aa4680265c467cbf33" translate="yes" xml:space="preserve">
          <source>Tenenhaus, M. (1998). La regression PLS: theorie et pratique. Paris: Editions Technic.</source>
          <target state="translated">Tenenhaus,M.(1998).Regresión PLS:teoría y práctica.París:Ediciones Technic.</target>
        </trans-unit>
        <trans-unit id="0a268d2f62458299ec67330e170374c2cecaa669" translate="yes" xml:space="preserve">
          <source>Terms that were ignored because they either:</source>
          <target state="translated">Términos que fueron ignorados porque ellos tampoco:</target>
        </trans-unit>
        <trans-unit id="9f2d4d3a12b50c0b296af732b3fa3674c7292a32" translate="yes" xml:space="preserve">
          <source>Test data of which we compute the likelihood, where n_samples is the number of samples and n_features is the number of features. X_test is assumed to be drawn from the same distribution than the data used in fit (including centering).</source>
          <target state="translated">Datos de prueba de los cuales calculamos la probabilidad,donde n_muestras es el número de muestras y n_características es el número de características.Se supone que X_test se extrae de la misma distribución que los datos utilizados en el ajuste (incluido el centrado).</target>
        </trans-unit>
        <trans-unit id="ed7e95a0302971bec5a032415d69927921186679" translate="yes" xml:space="preserve">
          <source>Test data to be transformed, must have the same number of features as the data used to train the model.</source>
          <target state="translated">Los datos de prueba para ser transformados,deben tener el mismo número de características que los datos usados para entrenar el modelo.</target>
        </trans-unit>
        <trans-unit id="65eaa1a409cbf0736a7b1da17a35a153fc9af91f" translate="yes" xml:space="preserve">
          <source>Test samples</source>
          <target state="translated">Muestras de prueba</target>
        </trans-unit>
        <trans-unit id="29446ed524d3e237184352cbcf6e1c5aaeb464e4" translate="yes" xml:space="preserve">
          <source>Test samples with shape = (n_samples, n_features) or None. For some estimators this may be a precomputed kernel matrix instead, shape = (n_samples, n_samples_fitted], where n_samples_fitted is the number of samples used in the fitting for the estimator. Passing None as test samples gives the same result as passing real test samples, since DummyRegressor operates independently of the sampled observations.</source>
          <target state="translated">Muestras de prueba con forma=(n_muestras,n_características)o ninguna.Para algunos estimadores esto puede ser una matriz de núcleo precalculada en su lugar,forma=(n_muestras,n_muestras_ajustadas],donde n_muestras_ajustadas es el número de muestras utilizadas en el ajuste para el estimador.Pasar Ninguno como muestras de prueba da el mismo resultado que pasar muestras de prueba reales,ya que el DummyRegressor funciona independientemente de las observaciones de la muestra.</target>
        </trans-unit>
        <trans-unit id="12cad09d9d4837878fb37fd506e5f7fb71a801c9" translate="yes" xml:space="preserve">
          <source>Test samples with shape = (n_samples, n_features) or None. Passing None as test samples gives the same result as passing real test samples, since DummyClassifier operates independently of the sampled observations.</source>
          <target state="translated">Muestras de prueba con forma=(n_muestras,n_características)o ninguna.Pasar Ninguno como muestras de prueba da el mismo resultado que pasar muestras de prueba reales,ya que el DummyClassifier funciona independientemente de las observaciones de la muestra.</target>
        </trans-unit>
        <trans-unit id="0c1d5bbb82f5cfc66b7e35e84179b02f4b13f8b1" translate="yes" xml:space="preserve">
          <source>Test samples.</source>
          <target state="translated">Muestras de prueba.</target>
        </trans-unit>
        <trans-unit id="bdec5057d32ebe97bd4c525fff2435009f4be0a0" translate="yes" xml:space="preserve">
          <source>Test samples. For some estimators this may be a precomputed kernel matrix instead, shape = (n_samples, n_samples_fitted], where n_samples_fitted is the number of samples used in the fitting for the estimator.</source>
          <target state="translated">Muestras de prueba.Para algunos estimadores esto puede ser una matriz de núcleo precalculada en su lugar,forma=(n_muestras,n_muestras_ajustadas],donde n_muestras_ajustadas es el número de muestras utilizadas en el ajuste para el estimador.</target>
        </trans-unit>
        <trans-unit id="a3c0fad25d001ac0a0589946fd03f6f0be795bec" translate="yes" xml:space="preserve">
          <source>Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead, shape = (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f9baccc70399290d29568f9812594e6335c4ae0" translate="yes" xml:space="preserve">
          <source>Test with permutations the significance of a classification score</source>
          <target state="translated">Pruebe con las permutaciones el significado de una puntuación de clasificación</target>
        </trans-unit>
        <trans-unit id="c67f73aee0c3dc1034cba236cfe8c8526d7a9123" translate="yes" xml:space="preserve">
          <source>Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect numerical feature vectors with a fixed size rather than the raw text documents with variable length.</source>
          <target state="translated">El análisis de texto es un campo de aplicación importante para los algoritmos de aprendizaje de máquinas.Sin embargo,los datos en bruto,una secuencia de símbolos no puede ser alimentada directamente a los propios algoritmos ya que la mayoría de ellos esperan vectores de características numéricas con un tamaño fijo en lugar de los documentos de texto en bruto con longitud variable.</target>
        </trans-unit>
        <trans-unit id="990226708ed5e3f7319c13e5c3e22d22fd438346" translate="yes" xml:space="preserve">
          <source>Text is made of characters, but files are made of bytes. These bytes represent characters according to some &lt;em&gt;encoding&lt;/em&gt;. To work with text files in Python, their bytes must be &lt;em&gt;decoded&lt;/em&gt; to a character set called Unicode. Common encodings are ASCII, Latin-1 (Western Europe), KOI8-R (Russian) and the universal encodings UTF-8 and UTF-16. Many others exist.</source>
          <target state="translated">El texto est&amp;aacute; formado por caracteres, pero los archivos est&amp;aacute;n formados por bytes. Estos bytes representan caracteres seg&amp;uacute;n alguna &lt;em&gt;codificaci&amp;oacute;n&lt;/em&gt; . Para trabajar con archivos de texto en Python, sus bytes deben &lt;em&gt;decodificarse&lt;/em&gt; en un juego de caracteres llamado Unicode. Las codificaciones comunes son ASCII, Latin-1 (Europa occidental), KOI8-R (ruso) y las codificaciones universales UTF-8 y UTF-16. Existen muchos otros.</target>
        </trans-unit>
        <trans-unit id="2a2f9f7e298485c4a85bf6b791046a1b63087cf9" translate="yes" xml:space="preserve">
          <source>Text preprocessing, tokenizing and filtering of stopwords are all included in &lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;, which builds a dictionary of features and transforms documents to feature vectors:</source>
          <target state="translated">El preprocesamiento de texto, la tokenizaci&amp;oacute;n y el filtrado de palabras vac&amp;iacute;as est&amp;aacute;n incluidos en &lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; , que crea un diccionario de caracter&amp;iacute;sticas y transforma documentos en vectores de caracter&amp;iacute;sticas:</target>
        </trans-unit>
        <trans-unit id="81ed5011593c32dbca614ea281c1292f374dff62" translate="yes" xml:space="preserve">
          <source>Text summary of all the rules in the decision tree.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79142cb36f8945e4d341c82cf5dc060dc02c8f0f" translate="yes" xml:space="preserve">
          <source>Text summary of the precision, recall, F1 score for each class. Dictionary returned if output_dict is True. Dictionary has the following structure:</source>
          <target state="translated">Resumen del texto de la precisión,recuerdo,puntuación de la F1 para cada clase.Diccionario devuelto si output_dict es True.El diccionario tiene la siguiente estructura:</target>
        </trans-unit>
        <trans-unit id="f042ff208f7aff2fdebc20ebdcfe3611681222ed" translate="yes" xml:space="preserve">
          <source>Tf is &amp;ldquo;n&amp;rdquo; (natural) by default, &amp;ldquo;l&amp;rdquo; (logarithmic) when &lt;code&gt;sublinear_tf=True&lt;/code&gt;. Idf is &amp;ldquo;t&amp;rdquo; when use_idf is given, &amp;ldquo;n&amp;rdquo; (none) otherwise. Normalization is &amp;ldquo;c&amp;rdquo; (cosine) when &lt;code&gt;norm='l2'&lt;/code&gt;, &amp;ldquo;n&amp;rdquo; (none) when &lt;code&gt;norm=None&lt;/code&gt;.</source>
          <target state="translated">Tf es &quot;n&quot; (natural) por defecto, &quot;l&quot; (logar&amp;iacute;tmico) cuando &lt;code&gt;sublinear_tf=True&lt;/code&gt; . Idf es &quot;t&quot; cuando se proporciona use_idf, &quot;n&quot; (ninguno) en caso contrario. La normalizaci&amp;oacute;n es &quot;c&quot; (coseno) cuando &lt;code&gt;norm='l2'&lt;/code&gt; , &quot;n&quot; (ninguna) cuando &lt;code&gt;norm=None&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="97730bbab5383bbe19dd65de91be719c29295304" translate="yes" xml:space="preserve">
          <source>Tf means &lt;strong&gt;term-frequency&lt;/strong&gt; while tf&amp;ndash;idf means term-frequency times &lt;strong&gt;inverse document-frequency&lt;/strong&gt;: \(\text{tf-idf(t,d)}=\text{tf(t,d)} \times \text{idf(t)}\).</source>
          <target state="translated">Tf significa &lt;strong&gt;t&amp;eacute;rmino-frecuencia&lt;/strong&gt; mientras que tf &amp;ndash; idf significa t&amp;eacute;rmino-frecuencia multiplicado por la frecuencia &lt;strong&gt;inversa del documento&lt;/strong&gt; : \ (\ text {tf-idf (t, d)} = \ text {tf (t, d)} \ times \ text {idf (t)} \).</target>
        </trans-unit>
        <trans-unit id="f1cc0d39fa695e88ce231644990ae2b503602ddb" translate="yes" xml:space="preserve">
          <source>Tf means term-frequency while tf-idf means term-frequency times inverse document-frequency. This is a common term weighting scheme in information retrieval, that has also found good use in document classification.</source>
          <target state="translated">Tf significa término-frecuencia mientras que tf-idf significa término-frecuencia por frecuencia-documento inversa.Se trata de un esquema de ponderación de términos común en la recuperación de información,que también ha encontrado un buen uso en la clasificación de documentos.</target>
        </trans-unit>
        <trans-unit id="771178a448f62a1d367a9045d97d08b26eb6869c" translate="yes" xml:space="preserve">
          <source>Tf-idf-weighted document-term matrix.</source>
          <target state="translated">Matriz de términos de documentos ponderados por Tf.</target>
        </trans-unit>
        <trans-unit id="daaa1c74bc4f107e3ab2cba2520cc29b4809af00" translate="yes" xml:space="preserve">
          <source>TfidfVectorizer uses a in-memory vocabulary (a python dict) to map the most frequent words to features indices and hence compute a word occurrence frequency (sparse) matrix. The word frequencies are then reweighted using the Inverse Document Frequency (IDF) vector collected feature-wise over the corpus.</source>
          <target state="translated">TfidfVectorizer utiliza un vocabulario en memoria (un dictado de la pitón)para mapear las palabras más frecuentes a índices de características y,por lo tanto,calcula una matriz de frecuencia de ocurrencia de palabras (raras).Las frecuencias de las palabras se vuelven a ponderar utilizando el vector de Frecuencia Inversa de Documentos (FID)recogido en el corpus.</target>
        </trans-unit>
        <trans-unit id="2c1e749a66bcce49e10daf1b4a981af3bebb9284" translate="yes" xml:space="preserve">
          <source>That this function takes time at least quadratic in n_samples. For large datasets, it&amp;rsquo;s wise to set that parameter to a small value.</source>
          <target state="translated">Que esta funci&amp;oacute;n lleva tiempo al menos cuadr&amp;aacute;tico en n_samples. Para conjuntos de datos grandes, es aconsejable establecer ese par&amp;aacute;metro en un valor peque&amp;ntilde;o.</target>
        </trans-unit>
        <trans-unit id="fb20b5f965f5eb1a2ab7f1c1219e1e8adbfdfc00" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;balanced&amp;rdquo; heuristic is inspired by Logistic Regression in Rare Events Data, King, Zen, 2001.</source>
          <target state="translated">La heur&amp;iacute;stica &amp;ldquo;equilibrada&amp;rdquo; est&amp;aacute; inspirada en Regresi&amp;oacute;n log&amp;iacute;stica en datos de eventos raros, King, Zen, 2001.</target>
        </trans-unit>
        <trans-unit id="f4d692dace6b9f963c8a80ff6fb54e77b0936bf5" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</source>
          <target state="translated">El modo &quot;balanceado&quot; utiliza los valores de y para ajustar autom&amp;aacute;ticamente los pesos inversamente proporcionales a las frecuencias de clase en los datos de entrada como &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="ef34b0ee7fbdfc2770447dcdf0759da38193f229" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;.</source>
          <target state="translated">El modo &quot;balanceado&quot; utiliza los valores de y para ajustar autom&amp;aacute;ticamente los pesos inversamente proporcionales a las frecuencias de clase en los datos de entrada como &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="66610aa2288acbb0ecf69897c27cb9799d361b2f" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data: &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;.</source>
          <target state="translated">El modo &quot;balanceado&quot; utiliza los valores de y para ajustar autom&amp;aacute;ticamente los pesos inversamente proporcionales a las frecuencias de clase en los datos de entrada: &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ef1bbf84c17d648e39cb34085672c6faaeb47082" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;balanced_subsample&amp;rdquo; mode is the same as &amp;ldquo;balanced&amp;rdquo; except that weights are computed based on the bootstrap sample for every tree grown.</source>
          <target state="translated">El modo &quot;submuestra_equilibrada&quot; es lo mismo que &quot;equilibrado&quot; excepto que los pesos se calculan en funci&amp;oacute;n de la muestra de arranque para cada &amp;aacute;rbol cultivado.</target>
        </trans-unit>
        <trans-unit id="ed963145b52986c215cb0664e22ee6755071701e" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;lbfgs&amp;rdquo; is an optimization algorithm that approximates the Broyden&amp;ndash;Fletcher&amp;ndash;Goldfarb&amp;ndash;Shanno algorithm &lt;a href=&quot;#id28&quot; id=&quot;id23&quot;&gt;8&lt;/a&gt;, which belongs to quasi-Newton methods. The &amp;ldquo;lbfgs&amp;rdquo; solver is recommended for use for small data-sets but for larger datasets its performance suffers. &lt;a href=&quot;#id29&quot; id=&quot;id24&quot;&gt;9&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd9d2df3102671da4d90b6a16223e62bcf13a40d" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;lbfgs&amp;rdquo; solver is used by default for its robustness. For large datasets the &amp;ldquo;saga&amp;rdquo; solver is usually faster. For large dataset, you may also consider using &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;SGDClassifier&lt;/code&gt;&lt;/a&gt; with &amp;lsquo;log&amp;rsquo; loss, which might be even faster but requires more tuning.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9570d1ba54b75e486c6a8fe70ab0af402d1567cc" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;lbfgs&amp;rdquo;, &amp;ldquo;sag&amp;rdquo; and &amp;ldquo;newton-cg&amp;rdquo; solvers only support L2 penalization and are found to converge faster for some high dimensional data. Setting &lt;code&gt;multi_class&lt;/code&gt; to &amp;ldquo;multinomial&amp;rdquo; with these solvers learns a true multinomial logistic regression model &lt;a href=&quot;#id26&quot; id=&quot;id23&quot;&gt;[5]&lt;/a&gt;, which means that its probability estimates should be better calibrated than the default &amp;ldquo;one-vs-rest&amp;rdquo; setting.</source>
          <target state="translated">Los solucionadores &amp;ldquo;lbfgs&amp;rdquo;, &amp;ldquo;sag&amp;rdquo; y &amp;ldquo;newton-cg&amp;rdquo; solo admiten la penalizaci&amp;oacute;n L2 y se encuentra que convergen m&amp;aacute;s r&amp;aacute;pido para algunos datos de alta dimensi&amp;oacute;n. Al establecer &lt;code&gt;multi_class&lt;/code&gt; en &amp;ldquo;multinomial&amp;rdquo; con estos solucionadores se aprende un verdadero modelo de regresi&amp;oacute;n log&amp;iacute;stica multinomial &lt;a href=&quot;#id26&quot; id=&quot;id23&quot;&gt;[5]&lt;/a&gt; , lo que significa que sus estimaciones de probabilidad deben estar mejor calibradas que la configuraci&amp;oacute;n predeterminada de &amp;ldquo;uno frente al resto&amp;rdquo;.</target>
        </trans-unit>
        <trans-unit id="5921538cf9d0b305a04fb55e5723f201454da417" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;lbfgs&amp;rdquo;, &amp;ldquo;sag&amp;rdquo; and &amp;ldquo;newton-cg&amp;rdquo; solvers only support \(\ell_2\) regularization or no regularization, and are found to converge faster for some high-dimensional data. Setting &lt;code&gt;multi_class&lt;/code&gt; to &amp;ldquo;multinomial&amp;rdquo; with these solvers learns a true multinomial logistic regression model &lt;a href=&quot;#id25&quot; id=&quot;id20&quot;&gt;5&lt;/a&gt;, which means that its probability estimates should be better calibrated than the default &amp;ldquo;one-vs-rest&amp;rdquo; setting.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c76cf618fdea0e603c8990092e5d960628df7c0c" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;new&amp;rdquo; data consists of linear combinations of the input data, with weights probabilistically drawn given the KDE model.</source>
          <target state="translated">Los &quot;nuevos&quot; datos consisten en combinaciones lineales de los datos de entrada, con ponderaciones dibujadas probabil&amp;iacute;sticamente dado el modelo KDE.</target>
        </trans-unit>
        <trans-unit id="6e028a15cea05a7ec04768381b1c3e0f7d725291" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;sag&amp;rdquo; solver uses Stochastic Average Gradient descent &lt;a href=&quot;#id26&quot; id=&quot;id21&quot;&gt;6&lt;/a&gt;. It is faster than other solvers for large datasets, when both the number of samples and the number of features are large.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="420229f24d72cfc948f72b9aaf53e46dfcb25b62" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;sag&amp;rdquo; solver uses a Stochastic Average Gradient descent &lt;a href=&quot;#id27&quot; id=&quot;id24&quot;&gt;[6]&lt;/a&gt;. It is faster than other solvers for large datasets, when both the number of samples and the number of features are large.</source>
          <target state="translated">El solucionador de &quot;hundimiento&quot; utiliza un descenso de gradiente medio estoc&amp;aacute;stico &lt;a href=&quot;#id27&quot; id=&quot;id24&quot;&gt;[6]&lt;/a&gt; . Es m&amp;aacute;s r&amp;aacute;pido que otros solucionadores para grandes conjuntos de datos, cuando tanto el n&amp;uacute;mero de muestras como el n&amp;uacute;mero de caracter&amp;iacute;sticas son grandes.</target>
        </trans-unit>
        <trans-unit id="2dbe4d8b05b25b3ecc8447f4c7fa6494b583e905" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;saga&amp;rdquo; solver &lt;a href=&quot;#id27&quot; id=&quot;id22&quot;&gt;7&lt;/a&gt; is a variant of &amp;ldquo;sag&amp;rdquo; that also supports the non-smooth &lt;code&gt;penalty=&quot;l1&quot;&lt;/code&gt;. This is therefore the solver of choice for sparse multinomial logistic regression. It is also the only solver that supports &lt;code&gt;penalty=&quot;elasticnet&quot;&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf55bf4220bbf6e5ad8c38b76c827b53a1e3f193" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;saga&amp;rdquo; solver &lt;a href=&quot;#id28&quot; id=&quot;id25&quot;&gt;[7]&lt;/a&gt; is a variant of &amp;ldquo;sag&amp;rdquo; that also supports the non-smooth &lt;code&gt;penalty=&amp;rdquo;l1&amp;rdquo;&lt;/code&gt; option. This is therefore the solver of choice for sparse multinomial logistic regression.</source>
          <target state="translated">El solucionador &quot;saga&quot; &lt;a href=&quot;#id28&quot; id=&quot;id25&quot;&gt;[7]&lt;/a&gt; es una variante de &quot;sag&quot; que tambi&amp;eacute;n admite la opci&amp;oacute;n de &lt;code&gt;penalty=&amp;rdquo;l1&amp;rdquo;&lt;/code&gt; no suave = &quot;l1&quot; . Por lo tanto, este es el solucionador de elecci&amp;oacute;n para la regresi&amp;oacute;n log&amp;iacute;stica multinomial dispersa.</target>
        </trans-unit>
        <trans-unit id="77bf2f7306c562160b3a78c9199a57470ad6395e" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;saga&amp;rdquo; solver is often the best choice. The &amp;ldquo;liblinear&amp;rdquo; solver is used by default for historical reasons.</source>
          <target state="translated">El solucionador de &quot;saga&quot; suele ser la mejor opci&amp;oacute;n. El solucionador &quot;liblinear&quot; se utiliza por defecto por razones hist&amp;oacute;ricas.</target>
        </trans-unit>
        <trans-unit id="068bc43bd479e1422a1e2139866c2ca587dbb3ad" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;steepness&amp;rdquo; of ROC curves is also important, since it is ideal to maximize the true positive rate while minimizing the false positive rate.</source>
          <target state="translated">La &quot;inclinaci&amp;oacute;n&quot; de las curvas ROC tambi&amp;eacute;n es importante, ya que es ideal para maximizar la tasa de verdaderos positivos y minimizar la tasa de falsos positivos.</target>
        </trans-unit>
        <trans-unit id="0eb5d5532023d8acbeeebff557bc347056c3c6a7" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;target&amp;rdquo; for this database is an integer from 0 to 39 indicating the identity of the person pictured; however, with only 10 examples per class, this relatively small dataset is more interesting from an unsupervised or semi-supervised perspective.</source>
          <target state="translated">El &quot;objetivo&quot; de esta base de datos es un n&amp;uacute;mero entero de 0 a 39 que indica la identidad de la persona en la imagen; sin embargo, con solo 10 ejemplos por clase, este conjunto de datos relativamente peque&amp;ntilde;o es m&amp;aacute;s interesante desde una perspectiva no supervisada o semi-supervisada.</target>
        </trans-unit>
        <trans-unit id="457f2fe1e264c1b033671c931911858da10508e3" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;auto&amp;rsquo; mode is the default and is intended to pick the cheaper option of the two depending on the shape of the training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6893a2ecba3f5b3ceba43b94c7037a23940a0678" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;auto&amp;rsquo; mode is the default and is intended to pick the cheaper option of the two depending upon the shape and format of the training data.</source>
          <target state="translated">El modo 'autom&amp;aacute;tico' es el predeterminado y est&amp;aacute; destinado a elegir la opci&amp;oacute;n m&amp;aacute;s barata de las dos dependiendo de la forma y el formato de los datos de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="c686d2e453ba3e5377730ccb9178f9e3372548ba" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;brute&amp;rsquo; method is a generic method that works with any estimator. It approximates the above integral by computing an average over the data &lt;code&gt;X&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f80449b3a36a9645d51b541d6ac4415080a7df2" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;cd&amp;rsquo; solver can only optimize the Frobenius norm. Due to the underlying non-convexity of NMF, the different solvers may converge to different minima, even when optimizing the same distance function.</source>
          <target state="translated">El solucionador 'cd' solo puede optimizar la norma de Frobenius. Debido a la no convexidad subyacente de NMF, los diferentes solucionadores pueden converger a diferentes m&amp;iacute;nimos, incluso cuando se optimiza la misma funci&amp;oacute;n de distancia.</target>
        </trans-unit>
        <trans-unit id="370b11b6ae177f24cc2d42a049dda5c0d7e30775" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;eigen&amp;rsquo; solver is based on the optimization of the between class scatter to within class scatter ratio. It can be used for both classification and transform, and it supports shrinkage. However, the &amp;lsquo;eigen&amp;rsquo; solver needs to compute the covariance matrix, so it might not be suitable for situations with a high number of features.</source>
          <target state="translated">El solucionador 'eigen' se basa en la optimizaci&amp;oacute;n de la dispersi&amp;oacute;n entre clases a la relaci&amp;oacute;n de dispersi&amp;oacute;n dentro de la clase. Se puede utilizar tanto para clasificaci&amp;oacute;n como para transformaci&amp;oacute;n, y admite la contracci&amp;oacute;n. Sin embargo, el solucionador 'eigen' necesita calcular la matriz de covarianza, por lo que podr&amp;iacute;a no ser adecuado para situaciones con una gran cantidad de caracter&amp;iacute;sticas.</target>
        </trans-unit>
        <trans-unit id="969c56b312ffc26d2c3d7a44ecbd20546b358e11" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;log&amp;rsquo; loss gives logistic regression, a probabilistic classifier. &amp;lsquo;modified_huber&amp;rsquo; is another smooth loss that brings tolerance to outliers as well as probability estimates. &amp;lsquo;squared_hinge&amp;rsquo; is like hinge but is quadratically penalized. &amp;lsquo;perceptron&amp;rsquo; is the linear loss used by the perceptron algorithm. The other losses are designed for regression but can be useful in classification as well; see &lt;a href=&quot;sklearn.linear_model.sgdregressor#sklearn.linear_model.SGDRegressor&quot;&gt;&lt;code&gt;SGDRegressor&lt;/code&gt;&lt;/a&gt; for a description.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ccda076fda793672987d7568e3ca12c3047fb684" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;log&amp;rsquo; loss gives logistic regression, a probabilistic classifier. &amp;lsquo;modified_huber&amp;rsquo; is another smooth loss that brings tolerance to outliers as well as probability estimates. &amp;lsquo;squared_hinge&amp;rsquo; is like hinge but is quadratically penalized. &amp;lsquo;perceptron&amp;rsquo; is the linear loss used by the perceptron algorithm. The other losses are designed for regression but can be useful in classification as well; see SGDRegressor for a description.</source>
          <target state="translated">La p&amp;eacute;rdida 'logar&amp;iacute;tmica' da una regresi&amp;oacute;n log&amp;iacute;stica, un clasificador probabil&amp;iacute;stico. 'modified_huber' es otra p&amp;eacute;rdida suave que aporta tolerancia a valores at&amp;iacute;picos as&amp;iacute; como estimaciones de probabilidad. 'squared_hinge' es como bisagra pero est&amp;aacute; penalizado cuadr&amp;aacute;ticamente. 'perceptr&amp;oacute;n' es la p&amp;eacute;rdida lineal utilizada por el algoritmo del perceptr&amp;oacute;n. Las otras p&amp;eacute;rdidas est&amp;aacute;n dise&amp;ntilde;adas para la regresi&amp;oacute;n, pero tambi&amp;eacute;n pueden ser &amp;uacute;tiles en la clasificaci&amp;oacute;n; consulte SGDRegressor para obtener una descripci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="960f213c3988b3643a9995192d8dbe5d183a7506" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;lsqr&amp;rsquo; solver is an efficient algorithm that only works for classification. It needs to explicitly compute the covariance matrix \(\Sigma\), and supports shrinkage. This solver computes the coefficients \(\omega_k = \Sigma^{-1}\mu_k\) by solving for \(\Sigma \omega = \mu_k\), thus avoiding the explicit computation of the inverse \(\Sigma^{-1}\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5302138e8a256151a982f3c737747f8db1fec2f7" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;lsqr&amp;rsquo; solver is an efficient algorithm that only works for classification. It supports shrinkage.</source>
          <target state="translated">El solucionador 'lsqr' es un algoritmo eficiente que solo funciona para la clasificaci&amp;oacute;n. Apoya la contracci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="920a5500dd530a18d71ed258f87f05c8340a0987" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo;, and &amp;lsquo;lbfgs&amp;rsquo; solvers support only L2 regularization with primal formulation, or no regularization. The &amp;lsquo;liblinear&amp;rsquo; solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty. The Elastic-Net regularization is only supported by the &amp;lsquo;saga&amp;rsquo; solver.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e2a91334301a1b93c477cd479a707ce044fefdf3" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo;, and &amp;lsquo;lbfgs&amp;rsquo; solvers support only L2 regularization with primal formulation. The &amp;lsquo;liblinear&amp;rsquo; solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty.</source>
          <target state="translated">Los solucionadores 'newton-cg', 'sag' y 'lbfgs' solo admiten la regularizaci&amp;oacute;n L2 con formulaci&amp;oacute;n primaria. El solucionador 'liblinear' admite la regularizaci&amp;oacute;n L1 y L2, con una formulaci&amp;oacute;n dual solo para la penalizaci&amp;oacute;n L2.</target>
        </trans-unit>
        <trans-unit id="f2d81bdc600d48b918368b0b02059bc57b808de5" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;recursion&amp;rsquo; method is faster than the &amp;lsquo;brute&amp;rsquo; method, but it is only supported by some tree-based estimators. It is computed as follows. For a given point \(x_S\), a weighted tree traversal is performed: if a split node involves a &amp;lsquo;target&amp;rsquo; feature, the corresponding left or right branch is followed; otherwise both branches are followed, each branch being weighted by the fraction of training samples that entered that branch. Finally, the partial dependence is given by a weighted average of all the visited leaves values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ade2e6c6872bcfb8e63408411f739881d7395764" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;squared_loss&amp;rsquo; refers to the ordinary least squares fit. &amp;lsquo;huber&amp;rsquo; modifies &amp;lsquo;squared_loss&amp;rsquo; to focus less on getting outliers correct by switching from squared to linear loss past a distance of epsilon. &amp;lsquo;epsilon_insensitive&amp;rsquo; ignores errors less than epsilon and is linear past that; this is the loss function used in SVR. &amp;lsquo;squared_epsilon_insensitive&amp;rsquo; is the same but becomes squared loss past a tolerance of epsilon.</source>
          <target state="translated">La 'p&amp;eacute;rdida_cuadrada' se refiere al ajuste ordinario de m&amp;iacute;nimos cuadrados. 'huber' modifica 'squared_loss' para centrarse menos en corregir los valores at&amp;iacute;picos cambiando de p&amp;eacute;rdida cuadrada a lineal m&amp;aacute;s all&amp;aacute; de una distancia de &amp;eacute;psilon. 'epsilon_insensitive' ignora los errores menos que epsilon y es lineal m&amp;aacute;s all&amp;aacute; de eso; esta es la funci&amp;oacute;n de p&amp;eacute;rdida utilizada en SVR. 'squared_epsilon_insensitive' es el mismo pero se convierte en p&amp;eacute;rdida al cuadrado m&amp;aacute;s all&amp;aacute; de la tolerancia de &amp;eacute;psilon.</target>
        </trans-unit>
        <trans-unit id="d846a2b9506766851ba4d72a28fde6b068825be1" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;svd&amp;rsquo; solver is the default solver used for &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;, and it is the only available solver for &lt;a href=&quot;generated/sklearn.discriminant_analysis.quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&quot;&gt;&lt;code&gt;QuadraticDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;. It can perform both classification and transform (for LDA). As it does not rely on the calculation of the covariance matrix, the &amp;lsquo;svd&amp;rsquo; solver may be preferable in situations where the number of features is large. The &amp;lsquo;svd&amp;rsquo; solver cannot be used with shrinkage. For QDA, the use of the SVD solver relies on the fact that the covariance matrix \(\Sigma_k\) is, by definition, equal to \(\frac{1}{n - 1} X_k^tX_k = V S^2 V^t\) where \(V\) comes from the SVD of the (centered) matrix: \(X_k = U S V^t\). It turns out that we can compute the log-posterior above without having to explictly compute \(\Sigma\): computing \(S\) and \(V\) via the SVD of \(X\) is enough. For LDA, two SVDs are computed: the SVD of the centered input matrix \(X\) and the SVD of the class-wise mean vectors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="388443bd992c152f7c80a788085a15982e280e0a" translate="yes" xml:space="preserve">
          <source>The (scaled) interquartile range for each feature in the training set.</source>
          <target state="translated">El rango intercuartílico (escalado)para cada característica del conjunto de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="1db16517be9cf545f06172e2c55188fa78cfa7fa" translate="yes" xml:space="preserve">
          <source>The (sometimes surprising) observation is that this is &lt;em&gt;still a linear model&lt;/em&gt;: to see this, imagine creating a new set of features</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3533a4edec1fdb05f12a2a421dc320606ca77c6" translate="yes" xml:space="preserve">
          <source>The (sometimes surprising) observation is that this is &lt;em&gt;still a linear model&lt;/em&gt;: to see this, imagine creating a new variable</source>
          <target state="translated">La observaci&amp;oacute;n (a veces sorprendente) es que este sigue &lt;em&gt;siendo un modelo lineal&lt;/em&gt; : para ver esto, imagine la creaci&amp;oacute;n de una nueva variable</target>
        </trans-unit>
        <trans-unit id="ae37fbc1863417aba870f086fd7dcb7d12932667" translate="yes" xml:space="preserve">
          <source>The (x,y) position of the lower-left corner, in degrees</source>
          <target state="translated">La posición (x,y)de la esquina inferior izquierda,en grados</target>
        </trans-unit>
        <trans-unit id="bcd6ca42c3472afbe27069a62710b5c531496d9b" translate="yes" xml:space="preserve">
          <source>The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. To the best of our knowledge, it was originally collected by Ken Lang, probably for his paper &amp;ldquo;Newsweeder: Learning to filter netnews,&amp;rdquo; though he does not explicitly mention this collection. The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.</source>
          <target state="translated">El conjunto de datos de 20 grupos de noticias es una colecci&amp;oacute;n de aproximadamente 20.000 documentos de grupos de noticias, divididos (casi) de manera uniforme en 20 grupos de noticias diferentes. Hasta donde sabemos, fue recopilado originalmente por Ken Lang, probablemente para su art&amp;iacute;culo &amp;ldquo;Newsweeder: Learning to filter netnews&amp;rdquo;, aunque no menciona expl&amp;iacute;citamente esta recopilaci&amp;oacute;n. La colecci&amp;oacute;n de 20 grupos de noticias se ha convertido en un conjunto de datos popular para experimentos en aplicaciones de texto de t&amp;eacute;cnicas de aprendizaje autom&amp;aacute;tico, como clasificaci&amp;oacute;n de texto y agrupaci&amp;oacute;n de texto.</target>
        </trans-unit>
        <trans-unit id="4b2a042059fffe007deb9ebabf02d8062c1e6bda" translate="yes" xml:space="preserve">
          <source>The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The split between the train and test set is based upon a messages posted before and after a specific date.</source>
          <target state="translated">El conjunto de datos de los 20 grupos de noticias comprende alrededor de 18.000 publicaciones de grupos de noticias sobre 20 temas,divididos en dos subconjuntos:uno para capacitación (o desarrollo)y otro para pruebas (o para evaluación del rendimiento).La división entre el tren y el conjunto de pruebas se basa en un mensaje publicado antes y después de una fecha específica.</target>
        </trans-unit>
        <trans-unit id="6f66371b5ad2b199bde3ecde676da8dfe31ce717" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#ht2001&quot; id=&quot;id25&quot;&gt;[HT2001]&lt;/a&gt; multiclass AUC metric can be extended to be weighted by the prevalence:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c380ecdb017c04631da3ca1753b6ddf07ce8267f" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.cluster&quot;&gt;&lt;code&gt;sklearn.cluster&lt;/code&gt;&lt;/a&gt; module gathers popular unsupervised clustering algorithms.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.cluster&quot;&gt; &lt;code&gt;sklearn.cluster&lt;/code&gt; &lt;/a&gt; re&amp;uacute;ne populares algoritmos de agrupaci&amp;oacute;n en cl&amp;uacute;steres no supervisados.</target>
        </trans-unit>
        <trans-unit id="6a798b177e574d6ff4ac12be7b93e3b8f8d74b71" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.covariance&quot;&gt;&lt;code&gt;sklearn.covariance&lt;/code&gt;&lt;/a&gt; module includes methods and algorithms to robustly estimate the covariance of features given a set of points. The precision matrix defined as the inverse of the covariance is also estimated. Covariance estimation is closely related to the theory of Gaussian Graphical Models.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.covariance&quot;&gt; &lt;code&gt;sklearn.covariance&lt;/code&gt; &lt;/a&gt; incluye m&amp;eacute;todos y algoritmos para estimar de manera robusta la covarianza de caracter&amp;iacute;sticas dado un conjunto de puntos. Tambi&amp;eacute;n se estima la matriz de precisi&amp;oacute;n definida como la inversa de la covarianza. La estimaci&amp;oacute;n de covarianza est&amp;aacute; estrechamente relacionada con la teor&amp;iacute;a de los modelos gr&amp;aacute;ficos gaussianos.</target>
        </trans-unit>
        <trans-unit id="d1230decfda989b60168bc88df7b70ef79122b2d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.datasets&quot;&gt;&lt;code&gt;sklearn.datasets&lt;/code&gt;&lt;/a&gt; module includes utilities to load datasets, including methods to load and fetch popular reference datasets. It also features some artificial data generators.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.datasets&quot;&gt; &lt;code&gt;sklearn.datasets&lt;/code&gt; &lt;/a&gt; incluye utilidades para cargar conjuntos de datos, incluidos m&amp;eacute;todos para cargar y recuperar conjuntos de datos de referencia populares. Tambi&amp;eacute;n cuenta con algunos generadores de datos artificiales.</target>
        </trans-unit>
        <trans-unit id="94bdb0abc615359801b0dde8f5ed432fa774aae6" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.decomposition&quot;&gt;&lt;code&gt;sklearn.decomposition&lt;/code&gt;&lt;/a&gt; module includes matrix decomposition algorithms, including among others PCA, NMF or ICA. Most of the algorithms of this module can be regarded as dimensionality reduction techniques.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.decomposition&quot;&gt; &lt;code&gt;sklearn.decomposition&lt;/code&gt; &lt;/a&gt; incluye algoritmos de descomposici&amp;oacute;n matricial, incluidos, entre otros, PCA, NMF o ICA. La mayor&amp;iacute;a de los algoritmos de este m&amp;oacute;dulo pueden considerarse t&amp;eacute;cnicas de reducci&amp;oacute;n de dimensionalidad.</target>
        </trans-unit>
        <trans-unit id="cce83af2900332bbe995457713d2e3977e6cea91" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.ensemble&quot;&gt;&lt;code&gt;sklearn.ensemble&lt;/code&gt;&lt;/a&gt; module includes ensemble-based methods for classification, regression and anomaly detection.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.ensemble&quot;&gt; &lt;code&gt;sklearn.ensemble&lt;/code&gt; &lt;/a&gt; incluye m&amp;eacute;todos basados ​​en conjuntos para clasificaci&amp;oacute;n, regresi&amp;oacute;n y detecci&amp;oacute;n de anomal&amp;iacute;as.</target>
        </trans-unit>
        <trans-unit id="a3b34965d608c8571221686c4eaa7dd2128cda34" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.exceptions&quot;&gt;&lt;code&gt;sklearn.exceptions&lt;/code&gt;&lt;/a&gt; module includes all custom warnings and error classes used across scikit-learn.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.exceptions&quot;&gt; &lt;code&gt;sklearn.exceptions&lt;/code&gt; &lt;/a&gt; incluye todas las advertencias personalizadas y las clases de error que se utilizan en scikit-learn.</target>
        </trans-unit>
        <trans-unit id="88149e0dc35a9af4a24d012611fba0cc883c2d66" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.experimental&quot;&gt;&lt;code&gt;sklearn.experimental&lt;/code&gt;&lt;/a&gt; module provides importable modules that enable the use of experimental features or estimators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="953e85b8304fe86126d3f8d4d49e2c347def818a" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.feature_extraction&quot;&gt;&lt;code&gt;sklearn.feature_extraction&lt;/code&gt;&lt;/a&gt; module deals with feature extraction from raw data. It currently includes methods to extract features from text and images.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.feature_extraction&quot;&gt; &lt;code&gt;sklearn.feature_extraction&lt;/code&gt; &lt;/a&gt; se ocupa de la extracci&amp;oacute;n de caracter&amp;iacute;sticas a partir de datos sin procesar. Actualmente incluye m&amp;eacute;todos para extraer caracter&amp;iacute;sticas de texto e im&amp;aacute;genes.</target>
        </trans-unit>
        <trans-unit id="2ff97b1fa019f5f400e3468860cd96aea04f63dc" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.feature_extraction.image&quot;&gt;&lt;code&gt;sklearn.feature_extraction.image&lt;/code&gt;&lt;/a&gt; submodule gathers utilities to extract features from images.</source>
          <target state="translated">El subm&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.feature_extraction.image&quot;&gt; &lt;code&gt;sklearn.feature_extraction.image&lt;/code&gt; &lt;/a&gt; re&amp;uacute;ne utilidades para extraer caracter&amp;iacute;sticas de las im&amp;aacute;genes.</target>
        </trans-unit>
        <trans-unit id="5fb7f21374928a29d973d39c8eed205507941559" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.feature_extraction.text&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt;&lt;/a&gt; submodule gathers utilities to build feature vectors from text documents.</source>
          <target state="translated">El subm&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.feature_extraction.text&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; &lt;/a&gt; re&amp;uacute;ne utilidades para crear vectores de caracter&amp;iacute;sticas a partir de documentos de texto.</target>
        </trans-unit>
        <trans-unit id="f8894b12541a4b0b591ccbf9c1c5e42bf4d0c13b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.feature_selection&quot;&gt;&lt;code&gt;sklearn.feature_selection&lt;/code&gt;&lt;/a&gt; module implements feature selection algorithms. It currently includes univariate filter selection methods and the recursive feature elimination algorithm.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.feature_selection&quot;&gt; &lt;code&gt;sklearn.feature_selection&lt;/code&gt; &lt;/a&gt; implementa algoritmos de selecci&amp;oacute;n de caracter&amp;iacute;sticas. Actualmente incluye m&amp;eacute;todos de selecci&amp;oacute;n de filtros univariados y el algoritmo de eliminaci&amp;oacute;n de caracter&amp;iacute;sticas recursivas.</target>
        </trans-unit>
        <trans-unit id="af392a06a08e896e0c1f9a845ceba81c0151ed14" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.gaussian_process&quot;&gt;&lt;code&gt;sklearn.gaussian_process&lt;/code&gt;&lt;/a&gt; module implements Gaussian Process based regression and classification.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.gaussian_process&quot;&gt; &lt;code&gt;sklearn.gaussian_process&lt;/code&gt; &lt;/a&gt; implementa la clasificaci&amp;oacute;n y regresi&amp;oacute;n basadas en el proceso gaussiano.</target>
        </trans-unit>
        <trans-unit id="385213737ec5d4067fe933c56afb4e9039eb2d7c" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.inspection&quot;&gt;&lt;code&gt;sklearn.inspection&lt;/code&gt;&lt;/a&gt; module includes tools for model inspection.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e25959a779b184ae02a906c2808f68686c73aab5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.kernel_approximation&quot;&gt;&lt;code&gt;sklearn.kernel_approximation&lt;/code&gt;&lt;/a&gt; module implements several approximate kernel feature maps base on Fourier transforms.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.kernel_approximation&quot;&gt; &lt;code&gt;sklearn.kernel_approximation&lt;/code&gt; &lt;/a&gt; implementa varios mapas de caracter&amp;iacute;sticas del kernel aproximados basados en transformadas de Fourier.</target>
        </trans-unit>
        <trans-unit id="311a58f7516f87097f4b239ae388620a5fb8155d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.linear_model&quot;&gt;&lt;code&gt;sklearn.linear_model&lt;/code&gt;&lt;/a&gt; module implements a variety of linear models.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf3dc31fd9ef458aef6de4af32bf51a7e61106a1" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.linear_model&quot;&gt;&lt;code&gt;sklearn.linear_model&lt;/code&gt;&lt;/a&gt; module implements generalized linear models. It includes Ridge regression, Bayesian Regression, Lasso and Elastic Net estimators computed with Least Angle Regression and coordinate descent. It also implements Stochastic Gradient Descent related algorithms.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.linear_model&quot;&gt; &lt;code&gt;sklearn.linear_model&lt;/code&gt; &lt;/a&gt; implementa modelos lineales generalizados. Incluye los estimadores de regresi&amp;oacute;n de cresta, regresi&amp;oacute;n bayesiana, lazo y red el&amp;aacute;stica calculados con regresi&amp;oacute;n de &amp;aacute;ngulo m&amp;iacute;nimo y descenso de coordenadas. Tambi&amp;eacute;n implementa algoritmos relacionados con el descenso de gradiente estoc&amp;aacute;stico.</target>
        </trans-unit>
        <trans-unit id="75e43c84de91a4a1d643ca88db0beef9e86494b8" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.manifold&quot;&gt;&lt;code&gt;sklearn.manifold&lt;/code&gt;&lt;/a&gt; module implements data embedding techniques.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.manifold&quot;&gt; &lt;code&gt;sklearn.manifold&lt;/code&gt; &lt;/a&gt; implementa t&amp;eacute;cnicas de incrustaci&amp;oacute;n de datos.</target>
        </trans-unit>
        <trans-unit id="f55aa3d6c230d41fe62ec5929fa59e00645b5d62" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.metrics&quot;&gt;&lt;code&gt;sklearn.metrics&lt;/code&gt;&lt;/a&gt; module includes score functions, performance metrics and pairwise metrics and distance computations.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.metrics&quot;&gt; &lt;code&gt;sklearn.metrics&lt;/code&gt; &lt;/a&gt; incluye funciones de puntuaci&amp;oacute;n, m&amp;eacute;tricas de rendimiento y m&amp;eacute;tricas por pares y c&amp;aacute;lculos de distancia.</target>
        </trans-unit>
        <trans-unit id="90553131dabe004a613ea2c87be35b6b6db9a1ae" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.metrics.cluster&quot;&gt;&lt;code&gt;sklearn.metrics.cluster&lt;/code&gt;&lt;/a&gt; submodule contains evaluation metrics for cluster analysis results. There are two forms of evaluation:</source>
          <target state="translated">El subm&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.metrics.cluster&quot;&gt; &lt;code&gt;sklearn.metrics.cluster&lt;/code&gt; &lt;/a&gt; contiene m&amp;eacute;tricas de evaluaci&amp;oacute;n para los resultados del an&amp;aacute;lisis de cl&amp;uacute;steres. Hay dos formas de evaluaci&amp;oacute;n:</target>
        </trans-unit>
        <trans-unit id="537333336506a029d4e76c0c5320f3e14636c908" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.mixture&quot;&gt;&lt;code&gt;sklearn.mixture&lt;/code&gt;&lt;/a&gt; module implements mixture modeling algorithms.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.mixture&quot;&gt; &lt;code&gt;sklearn.mixture&lt;/code&gt; &lt;/a&gt; implementa algoritmos de modelado de mezclas.</target>
        </trans-unit>
        <trans-unit id="1b9bcfe9136ee1328197e574e66457c49aa39ded" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.naive_bayes&quot;&gt;&lt;code&gt;sklearn.naive_bayes&lt;/code&gt;&lt;/a&gt; module implements Naive Bayes algorithms. These are supervised learning methods based on applying Bayes&amp;rsquo; theorem with strong (naive) feature independence assumptions.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.naive_bayes&quot;&gt; &lt;code&gt;sklearn.naive_bayes&lt;/code&gt; &lt;/a&gt; implementa algoritmos Naive Bayes. Estos son m&amp;eacute;todos de aprendizaje supervisados ​​basados ​​en la aplicaci&amp;oacute;n del teorema de Bayes con supuestos de independencia de caracter&amp;iacute;sticas fuertes (ingenuos).</target>
        </trans-unit>
        <trans-unit id="31da4b6c2407f749b7e6e441bc1101265b243a97" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.neighbors&quot;&gt;&lt;code&gt;sklearn.neighbors&lt;/code&gt;&lt;/a&gt; module implements the k-nearest neighbors algorithm.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.neighbors&quot;&gt; &lt;code&gt;sklearn.neighbors&lt;/code&gt; &lt;/a&gt; implementa el algoritmo de k vecinos m&amp;aacute;s cercanos.</target>
        </trans-unit>
        <trans-unit id="637db5b82af4c4775ad8c11b2cc086c407ac4adc" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.neural_network&quot;&gt;&lt;code&gt;sklearn.neural_network&lt;/code&gt;&lt;/a&gt; module includes models based on neural networks.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.neural_network&quot;&gt; &lt;code&gt;sklearn.neural_network&lt;/code&gt; &lt;/a&gt; incluye modelos basados ​​en redes neuronales.</target>
        </trans-unit>
        <trans-unit id="97c84f48ddcbce9eff5bb423de61ca9bed7742a5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline&lt;/code&gt;&lt;/a&gt; module implements utilities to build a composite estimator, as a chain of transforms and estimators.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline&lt;/code&gt; &lt;/a&gt; implementa utilidades para construir un estimador compuesto, como una cadena de transformaciones y estimadores.</target>
        </trans-unit>
        <trans-unit id="3e4a3abf94a63259dfe9d5546d6b613a02821c2d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.preprocessing&quot;&gt;&lt;code&gt;sklearn.preprocessing&lt;/code&gt;&lt;/a&gt; module includes scaling, centering, normalization, binarization and imputation methods.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.preprocessing&quot;&gt; &lt;code&gt;sklearn.preprocessing&lt;/code&gt; &lt;/a&gt; incluye m&amp;eacute;todos de escalado, centrado, normalizaci&amp;oacute;n, binarizaci&amp;oacute;n e imputaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="f8f509d37a71bbf7a86f10aff8bf2d2fdd437066" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.preprocessing&quot;&gt;&lt;code&gt;sklearn.preprocessing&lt;/code&gt;&lt;/a&gt; module includes scaling, centering, normalization, binarization methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fd91efb13a21a364a66a195be3f60dbc3429cc3" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.semi_supervised&quot;&gt;&lt;code&gt;sklearn.semi_supervised&lt;/code&gt;&lt;/a&gt; module implements semi-supervised learning algorithms. These algorithms utilized small amounts of labeled data and large amounts of unlabeled data for classification tasks. This module includes Label Propagation.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.semi_supervised&quot;&gt; &lt;code&gt;sklearn.semi_supervised&lt;/code&gt; &lt;/a&gt; implementa algoritmos de aprendizaje semi-supervisados. Estos algoritmos utilizaron peque&amp;ntilde;as cantidades de datos etiquetados y grandes cantidades de datos no etiquetados para tareas de clasificaci&amp;oacute;n. Este m&amp;oacute;dulo incluye la propagaci&amp;oacute;n de etiquetas.</target>
        </trans-unit>
        <trans-unit id="6b1e5de562db4c7ae4499c2a4fcb3f75a3027318" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.svm&quot;&gt;&lt;code&gt;sklearn.svm&lt;/code&gt;&lt;/a&gt; module includes Support Vector Machine algorithms.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.svm&quot;&gt; &lt;code&gt;sklearn.svm&lt;/code&gt; &lt;/a&gt; incluye algoritmos de Support Vector Machine.</target>
        </trans-unit>
        <trans-unit id="ef3c16856f883650f7c10c3b8b62a045804fc7da" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.tree&quot;&gt;&lt;code&gt;sklearn.tree&lt;/code&gt;&lt;/a&gt; module includes decision tree-based models for classification and regression.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.tree&quot;&gt; &lt;code&gt;sklearn.tree&lt;/code&gt; &lt;/a&gt; incluye modelos basados ​​en &amp;aacute;rboles de decisi&amp;oacute;n para clasificaci&amp;oacute;n y regresi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="fd392963cb16a5b60813f22af8246fa4065eb565" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.utils&quot;&gt;&lt;code&gt;sklearn.utils&lt;/code&gt;&lt;/a&gt; module includes various utilities.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.utils&quot;&gt; &lt;code&gt;sklearn.utils&lt;/code&gt; &lt;/a&gt; incluye varias utilidades.</target>
        </trans-unit>
        <trans-unit id="9c614be243d558a71ca4ede548ecf4767e4adc7c" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;simple example on this dataset&lt;/a&gt; illustrates how starting from the original problem one can shape the data for consumption in scikit-learn.</source>
          <target state="translated">El &lt;a href=&quot;../../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;ejemplo simple de este conjunto de datos&lt;/a&gt; ilustra c&amp;oacute;mo, a partir del problema original, se pueden dar forma a los datos para el consumo en scikit-learn.</target>
        </trans-unit>
        <trans-unit id="1173339ea4209f3d2d9f369da23b0882a1bab947" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt;&lt;code&gt;KMeans&lt;/code&gt;&lt;/a&gt; estimator was entirely re-worked, and it is now significantly faster and more stable. In addition, the Elkan algorithm is now compatible with sparse matrices. The estimator uses OpenMP based parallelism instead of relying on joblib, so the &lt;code&gt;n_jobs&lt;/code&gt; parameter has no effect anymore. For more details on how to control the number of threads, please refer to our &lt;a href=&quot;../../modules/computing#parallelism&quot;&gt;Parallelism&lt;/a&gt; notes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="30870f8f1c3b8d652d87325d159164cb4897186f" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt;&lt;code&gt;ensemble.HistGradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;ensemble.HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; now have native support for missing values (NaNs). This means that there is no need for imputing data when training or predicting.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d52c41feb33f6dcb3543db8b050b747b486d3d88" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;sklearn.impute.IterativeImputer&lt;/code&gt;&lt;/a&gt; class is very flexible - it can be used with a variety of estimators to do round-robin regression, treating every variable as an output in turn.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20080456681e7e51efd596990b6fe9c5442d5451" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;inspection.permutation_importance&lt;/code&gt;&lt;/a&gt; can be used to get an estimate of the importance of each feature, for any fitted estimator:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32ce39f7d5e0bf9b7a13f0705f1c0e1a4677070b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.inspection.plot_partial_dependence#sklearn.inspection.plot_partial_dependence&quot;&gt;&lt;code&gt;plot_partial_dependence&lt;/code&gt;&lt;/a&gt; function returns a &lt;a href=&quot;../../modules/generated/sklearn.inspection.partialdependencedisplay#sklearn.inspection.PartialDependenceDisplay&quot;&gt;&lt;code&gt;PartialDependenceDisplay&lt;/code&gt;&lt;/a&gt; object that can be used for plotting without needing to recalculate the partial dependence. In this example, we show how to plot partial dependence plots and how to quickly customize the plot with the visualization API.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa56488b2914a0f1ce166cbc607c029c9e711d0f" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.metrics.mean_tweedie_deviance#sklearn.metrics.mean_tweedie_deviance&quot;&gt;&lt;code&gt;sklearn.metrics.mean_tweedie_deviance&lt;/code&gt;&lt;/a&gt; depends on a &lt;code&gt;power&lt;/code&gt; parameter. As we do not know the true value of the &lt;code&gt;power&lt;/code&gt; parameter, we here compute the mean deviances for a grid of possible values, and compare the models side by side, i.e. we compare them at identical values of &lt;code&gt;power&lt;/code&gt;. Ideally, we hope that one model will be consistently better than the other, regardless of &lt;code&gt;power&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14b4e05e10f859ded14445d95cdfc3e13fffcfe1" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;sklearn.metrics.roc_auc_score&lt;/code&gt;&lt;/a&gt; function can be used for multi-class classification. The multi-class One-vs-One scheme compares every unique pairwise combination of classes. In this section, we calculate the AUC using the OvR and OvO schemes. We report a macro average, and a prevalence-weighted average.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f876970ad7209ceedd7d12cc65c7506766be528" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;sklearn.svm.OneClassSVM&lt;/code&gt;&lt;/a&gt; is known to be sensitive to outliers and thus does not perform very well for outlier detection. This estimator is best suited for novelty detection when the training set is not contaminated by outliers. That said, outlier detection in high-dimension, or without any assumptions on the distribution of the inlying data is very challenging, and a One-class SVM might give useful results in these situations depending on the value of its hyperparameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a4f7d548c6a3daf45cbc9aca2408b6479c48a9f" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt;&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;&lt;/a&gt; provides parameters such as &lt;code&gt;min_samples_leaf&lt;/code&gt; and &lt;code&gt;max_depth&lt;/code&gt; to prevent a tree from overfiting. Cost complexity pruning provides another option to control the size of a tree. In &lt;a href=&quot;../../modules/generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt;&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;&lt;/a&gt;, this pruning technique is parameterized by the cost complexity parameter, &lt;code&gt;ccp_alpha&lt;/code&gt;. Greater values of &lt;code&gt;ccp_alpha&lt;/code&gt; increase the number of nodes pruned. Here we only show the effect of &lt;code&gt;ccp_alpha&lt;/code&gt; on regularizing the trees and how to choose a &lt;code&gt;ccp_alpha&lt;/code&gt; based on validation scores.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="424aa7402b9869b036306a671e3630b4177e36b0" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/tree#tree&quot;&gt;decision trees&lt;/a&gt; is used to fit a sine curve with addition noisy observation. As a result, it learns local linear regressions approximating the sine curve.</source>
          <target state="translated">Los &lt;a href=&quot;../../modules/tree#tree&quot;&gt;&amp;aacute;rboles de decisi&amp;oacute;n&lt;/a&gt; se utilizan para ajustar una curva sinusoidal con una observaci&amp;oacute;n ruidosa adicional. Como resultado, aprende regresiones lineales locales que se aproximan a la curva sinusoidal.</target>
        </trans-unit>
        <trans-unit id="eb2cbae46431d84a4889d55d659950b594e78664" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/tree#tree&quot;&gt;decision trees&lt;/a&gt; is used to predict simultaneously the noisy x and y observations of a circle given a single underlying feature. As a result, it learns local linear regressions approximating the circle.</source>
          <target state="translated">Los &lt;a href=&quot;../../modules/tree#tree&quot;&gt;&amp;aacute;rboles de decisi&amp;oacute;n&lt;/a&gt; se utilizan para predecir simult&amp;aacute;neamente las ruidosas observaciones xey de un c&amp;iacute;rculo dada una &amp;uacute;nica caracter&amp;iacute;stica subyacente. Como resultado, aprende regresiones lineales locales que se aproximan al c&amp;iacute;rculo.</target>
        </trans-unit>
        <trans-unit id="4ea0ad8f51ec5bec92f088b272fa90a6ac2d5b55" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt;&lt;/a&gt; function is a data fetching / caching functions that downloads the data archive from the original &lt;a href=&quot;http://people.csail.mit.edu/jrennie/20Newsgroups/&quot;&gt;20 newsgroups website&lt;/a&gt;, extracts the archive contents in the &lt;code&gt;~/scikit_learn_data/20news_home&lt;/code&gt; folder and calls the &lt;a href=&quot;../modules/generated/sklearn.datasets.load_files#sklearn.datasets.load_files&quot;&gt;&lt;code&gt;sklearn.datasets.load_files&lt;/code&gt;&lt;/a&gt; on either the training or testing set folder, or both of them:</source>
          <target state="translated">La funci&amp;oacute;n &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt; &lt;/a&gt; es una funci&amp;oacute;n de b&amp;uacute;squeda / almacenamiento en cach&amp;eacute; de datos que descarga el archivo de datos del &lt;a href=&quot;http://people.csail.mit.edu/jrennie/20Newsgroups/&quot;&gt;sitio web&lt;/a&gt; original de 20 grupos de noticias , extrae el contenido del archivo en la carpeta &lt;code&gt;~/scikit_learn_data/20news_home&lt;/code&gt; y llama a &lt;a href=&quot;../modules/generated/sklearn.datasets.load_files#sklearn.datasets.load_files&quot;&gt; &lt;code&gt;sklearn.datasets.load_files&lt;/code&gt; &lt;/a&gt; en la capacitaci&amp;oacute;n o la carpeta del conjunto de pruebas, o ambos:</target>
        </trans-unit>
        <trans-unit id="07b834d8b0a1823a99a412f40063a013ad890cda" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt;&lt;/a&gt; function is a data fetching / caching functions that downloads the data archive from the original &lt;a href=&quot;https://people.csail.mit.edu/jrennie/20Newsgroups/&quot;&gt;20 newsgroups website&lt;/a&gt;, extracts the archive contents in the &lt;code&gt;~/scikit_learn_data/20news_home&lt;/code&gt; folder and calls the &lt;a href=&quot;../modules/generated/sklearn.datasets.load_files#sklearn.datasets.load_files&quot;&gt;&lt;code&gt;sklearn.datasets.load_files&lt;/code&gt;&lt;/a&gt; on either the training or testing set folder, or both of them:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26c038b3ea935758dab579b3237ee5588d78f251" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_lfw_pairs#sklearn.datasets.fetch_lfw_pairs&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_lfw_pairs&lt;/code&gt;&lt;/a&gt; datasets is subdivided into 3 subsets: the development &lt;code&gt;train&lt;/code&gt; set, the development &lt;code&gt;test&lt;/code&gt; set and an evaluation &lt;code&gt;10_folds&lt;/code&gt; set meant to compute performance metrics using a 10-folds cross validation scheme.</source>
          <target state="translated">Los &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_lfw_pairs#sklearn.datasets.fetch_lfw_pairs&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_lfw_pairs&lt;/code&gt; &lt;/a&gt; datos sklearn.datasets.fetch_lfw_pairs se subdividen en 3 subconjuntos: el conjunto de &lt;code&gt;train&lt;/code&gt; desarrollo , el conjunto de &lt;code&gt;test&lt;/code&gt; desarrollo y un conjunto de evaluaci&amp;oacute;n de &lt;code&gt;10_folds&lt;/code&gt; destinado a calcular m&amp;eacute;tricas de rendimiento utilizando un esquema de validaci&amp;oacute;n cruzada de 10 pliegues.</target>
        </trans-unit>
        <trans-unit id="d14958ad2582740fd909337c2882b7ba18717e2a" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt;&lt;code&gt;sklearn.ensemble&lt;/code&gt;&lt;/a&gt; module includes two averaging algorithms based on randomized &lt;a href=&quot;tree#tree&quot;&gt;decision trees&lt;/a&gt;: the RandomForest algorithm and the Extra-Trees method. Both algorithms are perturb-and-combine techniques &lt;a href=&quot;#b1998&quot; id=&quot;id5&quot;&gt;[B1998]&lt;/a&gt; specifically designed for trees. This means a diverse set of classifiers is created by introducing randomness in the classifier construction. The prediction of the ensemble is given as the averaged prediction of the individual classifiers.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt; &lt;code&gt;sklearn.ensemble&lt;/code&gt; &lt;/a&gt; incluye dos algoritmos de promediado basados ​​en &lt;a href=&quot;tree#tree&quot;&gt;&amp;aacute;rboles de decisi&amp;oacute;n&lt;/a&gt; aleatorios : el algoritmo RandomForest y el m&amp;eacute;todo Extra-Trees. Ambos algoritmos son t&amp;eacute;cnicas de perturbaci&amp;oacute;n y combinaci&amp;oacute;n &lt;a href=&quot;#b1998&quot; id=&quot;id5&quot;&gt;[B1998]&lt;/a&gt; dise&amp;ntilde;adas espec&amp;iacute;ficamente para &amp;aacute;rboles. Esto significa que se crea un conjunto diverso de clasificadores al introducir aleatoriedad en la construcci&amp;oacute;n del clasificador. La predicci&amp;oacute;n del conjunto se da como la predicci&amp;oacute;n promedio de los clasificadores individuales.</target>
        </trans-unit>
        <trans-unit id="fbeef59e0313a7e281a500dd36152abed677fa2e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.feature_extraction&quot;&gt;&lt;code&gt;sklearn.feature_extraction&lt;/code&gt;&lt;/a&gt; module can be used to extract features in a format supported by machine learning algorithms from datasets consisting of formats such as text and image.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;classes#module-sklearn.feature_extraction&quot;&gt; &lt;code&gt;sklearn.feature_extraction&lt;/code&gt; &lt;/a&gt; se puede utilizar para extraer caracter&amp;iacute;sticas en un formato compatible con algoritmos de aprendizaje autom&amp;aacute;tico de conjuntos de datos que constan de formatos como texto e imagen.</target>
        </trans-unit>
        <trans-unit id="ff270d1b4e640c5be645e763d862de5cbdc56019" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.inspection&quot;&gt;&lt;code&gt;sklearn.inspection&lt;/code&gt;&lt;/a&gt; module provides a convenience function &lt;a href=&quot;generated/sklearn.inspection.plot_partial_dependence#sklearn.inspection.plot_partial_dependence&quot;&gt;&lt;code&gt;plot_partial_dependence&lt;/code&gt;&lt;/a&gt; to create one-way and two-way partial dependence plots. In the below example we show how to create a grid of partial dependence plots: two one-way PDPs for the features &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt; and a two-way PDP between the two features:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="565412031e53246181e593ab56b9ab7f3accb362" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt;&lt;code&gt;sklearn.metrics&lt;/code&gt;&lt;/a&gt; module implements several loss, score, and utility functions to measure classification performance. Some metrics might require probability estimates of the positive class, confidence values, or binary decisions values. Most implementations allow each sample to provide a weighted contribution to the overall score, through the &lt;code&gt;sample_weight&lt;/code&gt; parameter.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt; &lt;code&gt;sklearn.metrics&lt;/code&gt; &lt;/a&gt; implementa varias funciones de p&amp;eacute;rdida, puntuaci&amp;oacute;n y utilidad para medir el rendimiento de la clasificaci&amp;oacute;n. Algunas m&amp;eacute;tricas pueden requerir estimaciones de probabilidad de la clase positiva, valores de confianza o valores de decisiones binarias. La mayor&amp;iacute;a de las implementaciones permiten que cada muestra proporcione una contribuci&amp;oacute;n ponderada a la puntuaci&amp;oacute;n general, a trav&amp;eacute;s del par&amp;aacute;metro &lt;code&gt;sample_weight&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6986be647f522d4ad92a86deccdacfb4588f163b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt;&lt;code&gt;sklearn.metrics&lt;/code&gt;&lt;/a&gt; module implements several loss, score, and utility functions to measure regression performance. Some of those have been enhanced to handle the multioutput case: &lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt;&lt;code&gt;mean_squared_error&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.mean_absolute_error#sklearn.metrics.mean_absolute_error&quot;&gt;&lt;code&gt;mean_absolute_error&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt;&lt;code&gt;explained_variance_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt; &lt;code&gt;sklearn.metrics&lt;/code&gt; &lt;/a&gt; implementa varias funciones de p&amp;eacute;rdida, puntuaci&amp;oacute;n y utilidad para medir el rendimiento de la regresi&amp;oacute;n. Algunos de ellos se han mejorado para manejar el caso de &lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt; &lt;code&gt;mean_squared_error&lt;/code&gt; &lt;/a&gt; : mean_squared_error , &lt;a href=&quot;generated/sklearn.metrics.mean_absolute_error#sklearn.metrics.mean_absolute_error&quot;&gt; &lt;code&gt;mean_absolute_error&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt; &lt;code&gt;explained_variance_score&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt; &lt;code&gt;r2_score&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="e3af9dc32993fb04e5c47da4dea690da48a6baa4" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt;&lt;code&gt;sklearn.metrics&lt;/code&gt;&lt;/a&gt; module implements several loss, score, and utility functions. For more information see the &lt;a href=&quot;clustering#clustering-evaluation&quot;&gt;Clustering performance evaluation&lt;/a&gt; section for instance clustering, and &lt;a href=&quot;biclustering#biclustering-evaluation&quot;&gt;Biclustering evaluation&lt;/a&gt; for biclustering.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt; &lt;code&gt;sklearn.metrics&lt;/code&gt; &lt;/a&gt; implementa varias funciones de p&amp;eacute;rdida, puntuaci&amp;oacute;n y utilidad. Para obtener m&amp;aacute;s informaci&amp;oacute;n, consulte la secci&amp;oacute;n de &lt;a href=&quot;clustering#clustering-evaluation&quot;&gt;evaluaci&amp;oacute;n del rendimiento de&lt;/a&gt; la agrupaci&amp;oacute;n en cl&amp;uacute;steres , por ejemplo, la agrupaci&amp;oacute;n en cl&amp;uacute;steres y la &lt;a href=&quot;biclustering#biclustering-evaluation&quot;&gt;evaluaci&amp;oacute;n&lt;/a&gt; de Biclustering para biclustering.</target>
        </trans-unit>
        <trans-unit id="095cb4e1ad7cf586616a563cdbf95404fbb2310e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt;&lt;/a&gt; submodule implements utilities to evaluate pairwise distances or affinity of sets of samples.</source>
          <target state="translated">El subm&amp;oacute;dulo &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt; &lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt; &lt;/a&gt; implementa utilidades para evaluar distancias por pares o afinidad de conjuntos de muestras.</target>
        </trans-unit>
        <trans-unit id="8e4a825968b52124826a5f75996abc15ec7f1a2c" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.multiclass&quot;&gt;&lt;code&gt;sklearn.multiclass&lt;/code&gt;&lt;/a&gt; module implements &lt;em&gt;meta-estimators&lt;/em&gt; to solve &lt;code&gt;multiclass&lt;/code&gt; and &lt;code&gt;multilabel&lt;/code&gt; classification problems by decomposing such problems into binary classification problems. &lt;code&gt;multioutput&lt;/code&gt; regression is also supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60f0063776d96ccddba5880841f7defdb7f0d5d9" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.multiclass&quot;&gt;&lt;code&gt;sklearn.multiclass&lt;/code&gt;&lt;/a&gt; module implements &lt;em&gt;meta-estimators&lt;/em&gt; to solve &lt;code&gt;multiclass&lt;/code&gt; and &lt;code&gt;multilabel&lt;/code&gt; classification problems by decomposing such problems into binary classification problems. Multitarget regression is also supported.</source>
          <target state="translated">Los &lt;a href=&quot;classes#module-sklearn.multiclass&quot;&gt; &lt;code&gt;sklearn.multiclass&lt;/code&gt; &lt;/a&gt; m&amp;oacute;dulo implementa &lt;em&gt;meta-estimadores&lt;/em&gt; para resolver &lt;code&gt;multiclass&lt;/code&gt; y &lt;code&gt;multilabel&lt;/code&gt; problemas de clasificaci&amp;oacute;n por la descomposici&amp;oacute;n de este tipo de problemas en problemas de clasificaci&amp;oacute;n binaria. Tambi&amp;eacute;n se admite la regresi&amp;oacute;n de objetivos m&amp;uacute;ltiples.</target>
        </trans-unit>
        <trans-unit id="8db5d205727541fd60809b9d143967244bf8e79b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.random_projection&quot;&gt;&lt;code&gt;sklearn.random_projection&lt;/code&gt;&lt;/a&gt; module implements a simple and computationally efficient way to reduce the dimensionality of the data by trading a controlled amount of accuracy (as additional variance) for faster processing times and smaller model sizes. This module implements two types of unstructured random matrix: &lt;a href=&quot;#gaussian-random-matrix&quot;&gt;Gaussian random matrix&lt;/a&gt; and &lt;a href=&quot;#sparse-random-matrix&quot;&gt;sparse random matrix&lt;/a&gt;.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;classes#module-sklearn.random_projection&quot;&gt; &lt;code&gt;sklearn.random_projection&lt;/code&gt; &lt;/a&gt; implementa una forma simple y computacionalmente eficiente de reducir la dimensionalidad de los datos intercambiando una cantidad controlada de precisi&amp;oacute;n (como variaci&amp;oacute;n adicional) por tiempos de procesamiento m&amp;aacute;s r&amp;aacute;pidos y tama&amp;ntilde;os de modelo m&amp;aacute;s peque&amp;ntilde;os. Este m&amp;oacute;dulo implementa dos tipos de matriz aleatoria no estructurada: &lt;a href=&quot;#gaussian-random-matrix&quot;&gt;matriz aleatoria gaussiana&lt;/a&gt; y &lt;a href=&quot;#sparse-random-matrix&quot;&gt;matriz aleatoria dispersa&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="a34e8e8e9bf3ccf9c2fa51aff7ed58e5e45bbffa" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt;&lt;code&gt;CalibratedClassifierCV&lt;/code&gt;&lt;/a&gt; class is used to calibrate a classifier.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aaa03339275413a44471cce8ed9110742f7e29fb" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.agglomerativeclustering#sklearn.cluster.AgglomerativeClustering&quot;&gt;&lt;code&gt;AgglomerativeClustering&lt;/code&gt;&lt;/a&gt; object performs a hierarchical clustering using a bottom up approach: each observation starts in its own cluster, and clusters are successively merged together. The linkage criteria determines the metric used for the merge strategy:</source>
          <target state="translated">El objeto &lt;a href=&quot;generated/sklearn.cluster.agglomerativeclustering#sklearn.cluster.AgglomerativeClustering&quot;&gt; &lt;code&gt;AgglomerativeClustering&lt;/code&gt; &lt;/a&gt; realiza una agrupaci&amp;oacute;n jer&amp;aacute;rquica utilizando un enfoque de abajo hacia arriba: cada observaci&amp;oacute;n comienza en su propio grupo y los grupos se fusionan sucesivamente. Los criterios de vinculaci&amp;oacute;n determinan la m&amp;eacute;trica utilizada para la estrategia de fusi&amp;oacute;n:</target>
        </trans-unit>
        <trans-unit id="913b5a9805377fabb258d2653b5b70e8adeffb2c" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.bicluster.spectralbiclustering#sklearn.cluster.bicluster.SpectralBiclustering&quot;&gt;&lt;code&gt;SpectralBiclustering&lt;/code&gt;&lt;/a&gt; algorithm assumes that the input data matrix has a hidden checkerboard structure. The rows and columns of a matrix with this structure may be partitioned so that the entries of any bicluster in the Cartesian product of row clusters and column clusters are approximately constant. For instance, if there are two row partitions and three column partitions, each row will belong to three biclusters, and each column will belong to two biclusters.</source>
          <target state="translated">El algoritmo &lt;a href=&quot;generated/sklearn.cluster.bicluster.spectralbiclustering#sklearn.cluster.bicluster.SpectralBiclustering&quot;&gt; &lt;code&gt;SpectralBiclustering&lt;/code&gt; &lt;/a&gt; asume que la matriz de datos de entrada tiene una estructura de tablero de ajedrez oculta. Las filas y columnas de una matriz con esta estructura se pueden dividir de modo que las entradas de cualquier bicluster en el producto cartesiano de los grupos de filas y los grupos de columnas sean aproximadamente constantes. Por ejemplo, si hay dos particiones de fila y tres particiones de columna, cada fila pertenecer&amp;aacute; a tres biclusters y cada columna pertenecer&amp;aacute; a dos biclusters.</target>
        </trans-unit>
        <trans-unit id="96812a842015efa920168397038c120e6e957561" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.bicluster.spectralcoclustering#sklearn.cluster.bicluster.SpectralCoclustering&quot;&gt;&lt;code&gt;SpectralCoclustering&lt;/code&gt;&lt;/a&gt; algorithm finds biclusters with values higher than those in the corresponding other rows and columns. Each row and each column belongs to exactly one bicluster, so rearranging the rows and columns to make partitions contiguous reveals these high values along the diagonal:</source>
          <target state="translated">El algoritmo &lt;a href=&quot;generated/sklearn.cluster.bicluster.spectralcoclustering#sklearn.cluster.bicluster.SpectralCoclustering&quot;&gt; &lt;code&gt;SpectralCoclustering&lt;/code&gt; &lt;/a&gt; encuentra biclusters con valores m&amp;aacute;s altos que los de las otras filas y columnas correspondientes. Cada fila y cada columna pertenece exactamente a un bicluster, por lo que reorganizar las filas y columnas para hacer particiones contiguas revela estos valores altos a lo largo de la diagonal:</target>
        </trans-unit>
        <trans-unit id="9debcd56df8be7e32ea091b79dc8e313d63ea1d3" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.birch#sklearn.cluster.Birch&quot;&gt;&lt;code&gt;Birch&lt;/code&gt;&lt;/a&gt; builds a tree called the Characteristic Feature Tree (CFT) for the given data. The data is essentially lossy compressed to a set of Characteristic Feature nodes (CF Nodes). The CF Nodes have a number of subclusters called Characteristic Feature subclusters (CF Subclusters) and these CF Subclusters located in the non-terminal CF Nodes can have CF Nodes as children.</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.cluster.birch#sklearn.cluster.Birch&quot;&gt; &lt;code&gt;Birch&lt;/code&gt; &lt;/a&gt; construye un &amp;aacute;rbol llamado &amp;Aacute;rbol de caracter&amp;iacute;sticas caracter&amp;iacute;sticas (CFT) para los datos dados. Los datos se comprimen esencialmente con p&amp;eacute;rdida en un conjunto de nodos de caracter&amp;iacute;sticas caracter&amp;iacute;sticas (nodos CF). Los nodos CF tienen varios subclusters denominados subclusters de caracter&amp;iacute;sticas caracter&amp;iacute;sticas (subclusters CF) y estos subclusters CF ubicados en los nodos CF no terminales pueden tener nodos CF como hijos.</target>
        </trans-unit>
        <trans-unit id="5792059d2ce9d3e99380df43abdafaacd52cf188" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.birch#sklearn.cluster.Birch&quot;&gt;&lt;code&gt;Birch&lt;/code&gt;&lt;/a&gt; builds a tree called the Clustering Feature Tree (CFT) for the given data. The data is essentially lossy compressed to a set of Clustering Feature nodes (CF Nodes). The CF Nodes have a number of subclusters called Clustering Feature subclusters (CF Subclusters) and these CF Subclusters located in the non-terminal CF Nodes can have CF Nodes as children.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8b115edebda7f7bf86445503d0ce08900b4f8de" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt;&lt;code&gt;DBSCAN&lt;/code&gt;&lt;/a&gt; algorithm views clusters as areas of high density separated by areas of low density. Due to this rather generic view, clusters found by DBSCAN can be any shape, as opposed to k-means which assumes that clusters are convex shaped. The central component to the DBSCAN is the concept of &lt;em&gt;core samples&lt;/em&gt;, which are samples that are in areas of high density. A cluster is therefore a set of core samples, each close to each other (measured by some distance measure) and a set of non-core samples that are close to a core sample (but are not themselves core samples). There are two parameters to the algorithm, &lt;code&gt;min_samples&lt;/code&gt; and &lt;code&gt;eps&lt;/code&gt;, which define formally what we mean when we say &lt;em&gt;dense&lt;/em&gt;. Higher &lt;code&gt;min_samples&lt;/code&gt; or lower &lt;code&gt;eps&lt;/code&gt; indicate higher density necessary to form a cluster.</source>
          <target state="translated">El algoritmo &lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt; &lt;code&gt;DBSCAN&lt;/code&gt; &lt;/a&gt; ve los cl&amp;uacute;steres como &amp;aacute;reas de alta densidad separadas por &amp;aacute;reas de baja densidad. Debido a esta vista bastante gen&amp;eacute;rica, los grupos encontrados por DBSCAN pueden tener cualquier forma, a diferencia de k-means, que asume que los grupos tienen forma convexa. El componente central del DBSCAN es el concepto de &lt;em&gt;muestras centrales&lt;/em&gt; , que son muestras que se encuentran en &amp;aacute;reas de alta densidad. Por lo tanto, un grupo es un conjunto de muestras centrales, cada una cercana entre s&amp;iacute; (medida por alguna medida de distancia) y un conjunto de muestras no centrales que est&amp;aacute;n cerca de una muestra central (pero que no son muestras centrales). Hay dos par&amp;aacute;metros para el algoritmo, &lt;code&gt;min_samples&lt;/code&gt; y &lt;code&gt;eps&lt;/code&gt; , que definen formalmente lo que queremos decir cuando decimos &lt;em&gt;denso&lt;/em&gt; . Mayor &lt;code&gt;min_samples&lt;/code&gt; o &lt;code&gt;eps&lt;/code&gt; m&amp;aacute;s bajos indican una densidad m&amp;aacute;s alta necesaria para formar un grupo.</target>
        </trans-unit>
        <trans-unit id="844222980d29de5ed47698200091f13bdd09a284" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.featureagglomeration#sklearn.cluster.FeatureAgglomeration&quot;&gt;&lt;code&gt;FeatureAgglomeration&lt;/code&gt;&lt;/a&gt; uses agglomerative clustering to group together features that look very similar, thus decreasing the number of features. It is a dimensionality reduction tool, see &lt;a href=&quot;unsupervised_reduction#data-reduction&quot;&gt;Unsupervised dimensionality reduction&lt;/a&gt;.</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.cluster.featureagglomeration#sklearn.cluster.FeatureAgglomeration&quot;&gt; &lt;code&gt;FeatureAgglomeration&lt;/code&gt; &lt;/a&gt; utiliza agrupamiento aglutinador para agrupar caracter&amp;iacute;sticas que son muy similares, lo que disminuye el n&amp;uacute;mero de caracter&amp;iacute;sticas. Es una herramienta de reducci&amp;oacute;n de dimensionalidad, consulte &lt;a href=&quot;unsupervised_reduction#data-reduction&quot;&gt;Reducci&amp;oacute;n de dimensionalidad no supervisada&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="3ccd68ae912b5d8e7b609345a756782aaea1f1b3" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt;&lt;code&gt;KMeans&lt;/code&gt;&lt;/a&gt; algorithm clusters data by trying to separate samples in n groups of equal variance, minimizing a criterion known as the &lt;a href=&quot;inertia&quot;&gt;inertia&lt;/a&gt; or within-cluster sum-of-squares. This algorithm requires the number of clusters to be specified. It scales well to large number of samples and has been used across a large range of application areas in many different fields.</source>
          <target state="translated">El algoritmo de &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt; &lt;code&gt;KMeans&lt;/code&gt; &lt;/a&gt; agrupa los datos tratando de separar las muestras en n grupos de varianza igual, minimizando un criterio conocido como &lt;a href=&quot;inertia&quot;&gt;inercia&lt;/a&gt; o suma de cuadrados dentro del grupo. Este algoritmo requiere que se especifique el n&amp;uacute;mero de cl&amp;uacute;steres. Se adapta bien a una gran cantidad de muestras y se ha utilizado en una amplia gama de &amp;aacute;reas de aplicaci&amp;oacute;n en muchos campos diferentes.</target>
        </trans-unit>
        <trans-unit id="1ffab773fe637da04ea4c04490bc4a37e92e75f6" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt;&lt;code&gt;KMeans&lt;/code&gt;&lt;/a&gt; algorithm clusters data by trying to separate samples in n groups of equal variance, minimizing a criterion known as the &lt;em&gt;inertia&lt;/em&gt; or within-cluster sum-of-squares (see below). This algorithm requires the number of clusters to be specified. It scales well to large number of samples and has been used across a large range of application areas in many different fields.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f8f9ba49e304c2e7e84cbf4122c9838a65e0d463" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt;&lt;code&gt;MiniBatchKMeans&lt;/code&gt;&lt;/a&gt; is a variant of the &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt;&lt;code&gt;KMeans&lt;/code&gt;&lt;/a&gt; algorithm which uses mini-batches to reduce the computation time, while still attempting to optimise the same objective function. Mini-batches are subsets of the input data, randomly sampled in each training iteration. These mini-batches drastically reduce the amount of computation required to converge to a local solution. In contrast to other algorithms that reduce the convergence time of k-means, mini-batch k-means produces results that are generally only slightly worse than the standard algorithm.</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt; &lt;code&gt;MiniBatchKMeans&lt;/code&gt; &lt;/a&gt; es una variante del algoritmo &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt; &lt;code&gt;KMeans&lt;/code&gt; &lt;/a&gt; que usa mini-lotes para reducir el tiempo de c&amp;aacute;lculo, mientras intenta optimizar la misma funci&amp;oacute;n objetivo. Los mini lotes son subconjuntos de los datos de entrada, muestreados al azar en cada iteraci&amp;oacute;n de entrenamiento. Estos mini lotes reducen dr&amp;aacute;sticamente la cantidad de computaci&amp;oacute;n necesaria para converger en una soluci&amp;oacute;n local. A diferencia de otros algoritmos que reducen el tiempo de convergencia de k-medias, las k-medias de mini lotes producen resultados que generalmente son solo un poco peores que el algoritmo est&amp;aacute;ndar.</target>
        </trans-unit>
        <trans-unit id="13f492ae552c222beb8a78a6fea9613c4b7f22e2" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.optics#sklearn.cluster.OPTICS&quot;&gt;&lt;code&gt;OPTICS&lt;/code&gt;&lt;/a&gt; algorithm shares many similarities with the &lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt;&lt;code&gt;DBSCAN&lt;/code&gt;&lt;/a&gt; algorithm, and can be considered a generalization of DBSCAN that relaxes the &lt;code&gt;eps&lt;/code&gt; requirement from a single value to a value range. The key difference between DBSCAN and OPTICS is that the OPTICS algorithm builds a &lt;em&gt;reachability&lt;/em&gt; graph, which assigns each sample both a &lt;code&gt;reachability_&lt;/code&gt; distance, and a spot within the cluster &lt;code&gt;ordering_&lt;/code&gt; attribute; these two attributes are assigned when the model is fitted, and are used to determine cluster membership. If OPTICS is run with the default value of &lt;em&gt;inf&lt;/em&gt; set for &lt;code&gt;max_eps&lt;/code&gt;, then DBSCAN style cluster extraction can be performed repeatedly in linear time for any given &lt;code&gt;eps&lt;/code&gt; value using the &lt;code&gt;cluster_optics_dbscan&lt;/code&gt; method. Setting &lt;code&gt;max_eps&lt;/code&gt; to a lower value will result in shorter run times, and can be thought of as the maximum neighborhood radius from each point to find other potential reachable points.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="381def8c4d001638003d40e7acf9264b0a49ea0f" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; helps performing different transformations for different columns of the data, within a &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; that is safe from data leakage and that can be parametrized. &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; works on arrays, sparse matrices, and &lt;a href=&quot;http://pandas.pydata.org/pandas-docs/stable/&quot;&gt;pandas DataFrames&lt;/a&gt;.</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;ColumnTransformer&lt;/code&gt; &lt;/a&gt; ayuda a la realizaci&amp;oacute;n de diferentes transformaciones para diferentes columnas de los datos, dentro de un &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;Pipeline&lt;/code&gt; &lt;/a&gt; que est&amp;aacute; a salvo de la fuga de datos y que puede ser parametrizada. &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;ColumnTransformer&lt;/code&gt; &lt;/a&gt; funciona en matrices, matrices dispersas y &lt;a href=&quot;http://pandas.pydata.org/pandas-docs/stable/&quot;&gt;pandas DataFrames&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="d5b3cf1eea0426995e81b4c182953586d3dd6af5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; helps performing different transformations for different columns of the data, within a &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; that is safe from data leakage and that can be parametrized. &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; works on arrays, sparse matrices, and &lt;a href=&quot;https://pandas.pydata.org/pandas-docs/stable/&quot;&gt;pandas DataFrames&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37d727244bb97826f98eb0365b95bf6cd4afb239" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;compose.ColumnTransformer&lt;/code&gt;&lt;/a&gt; class is experimental and the API is subject to change.</source>
          <target state="translated">La clase &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;compose.ColumnTransformer&lt;/code&gt; &lt;/a&gt; es experimental y la API est&amp;aacute; sujeta a cambios.</target>
        </trans-unit>
        <trans-unit id="36f50b6d2de06293da3e162b3eb7e342568ccd05" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.compose.make_column_transformer#sklearn.compose.make_column_transformer&quot;&gt;&lt;code&gt;make_column_transformer&lt;/code&gt;&lt;/a&gt; function is available to more easily create a &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; object. Specifically, the names will be given automatically. The equivalent for the above example would be:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83e5137b54932bec66ccc36542bace6834598b69" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.covariance.graphicallasso#sklearn.covariance.GraphicalLasso&quot;&gt;&lt;code&gt;GraphicalLasso&lt;/code&gt;&lt;/a&gt; estimator uses an l1 penalty to enforce sparsity on the precision matrix: the higher its &lt;code&gt;alpha&lt;/code&gt; parameter, the more sparse the precision matrix. The corresponding &lt;a href=&quot;generated/sklearn.covariance.graphicallassocv#sklearn.covariance.GraphicalLassoCV&quot;&gt;&lt;code&gt;GraphicalLassoCV&lt;/code&gt;&lt;/a&gt; object uses cross-validation to automatically set the &lt;code&gt;alpha&lt;/code&gt; parameter.</source>
          <target state="translated">El estimador &lt;a href=&quot;generated/sklearn.covariance.graphicallasso#sklearn.covariance.GraphicalLasso&quot;&gt; &lt;code&gt;GraphicalLasso&lt;/code&gt; &lt;/a&gt; utiliza una penalizaci&amp;oacute;n de l1 para imponer la escasez en la matriz de precisi&amp;oacute;n: cuanto mayor sea su par&amp;aacute;metro &lt;code&gt;alpha&lt;/code&gt; , m&amp;aacute;s escasa ser&amp;aacute; la matriz de precisi&amp;oacute;n. El objeto &lt;a href=&quot;generated/sklearn.covariance.graphicallassocv#sklearn.covariance.GraphicalLassoCV&quot;&gt; &lt;code&gt;GraphicalLassoCV&lt;/code&gt; &lt;/a&gt; correspondiente utiliza validaci&amp;oacute;n cruzada para establecer autom&amp;aacute;ticamente el par&amp;aacute;metro &lt;code&gt;alpha&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4d547fe6e0c2b8c31056c1efceecbd9d17b8cbf1" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; object also provides a probabilistic interpretation of the PCA that can give a likelihood of data based on the amount of variance it explains. As such it implements a &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-score&quot;&gt;score&lt;/a&gt; method that can be used in cross-validation:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9447390bf3cfd368da76e6282f132428b32dfff8" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; object also provides a probabilistic interpretation of the PCA that can give a likelihood of data based on the amount of variance it explains. As such it implements a &lt;code&gt;score&lt;/code&gt; method that can be used in cross-validation:</source>
          <target state="translated">El objeto &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; tambi&amp;eacute;n proporciona una interpretaci&amp;oacute;n probabil&amp;iacute;stica del PCA que puede dar una probabilidad de datos basada en la cantidad de varianza que explica. Como tal, implementa un m&amp;eacute;todo de &lt;code&gt;score&lt;/code&gt; que se puede utilizar en la validaci&amp;oacute;n cruzada:</target>
        </trans-unit>
        <trans-unit id="de1125bcd2177e15b5b35e281621b5bbf18681e1" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; object is very useful, but has certain limitations for large datasets. The biggest limitation is that &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; only supports batch processing, which means all of the data to be processed must fit in main memory. The &lt;a href=&quot;generated/sklearn.decomposition.incrementalpca#sklearn.decomposition.IncrementalPCA&quot;&gt;&lt;code&gt;IncrementalPCA&lt;/code&gt;&lt;/a&gt; object uses a different form of processing and allows for partial computations which almost exactly match the results of &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; while processing the data in a minibatch fashion. &lt;a href=&quot;generated/sklearn.decomposition.incrementalpca#sklearn.decomposition.IncrementalPCA&quot;&gt;&lt;code&gt;IncrementalPCA&lt;/code&gt;&lt;/a&gt; makes it possible to implement out-of-core Principal Component Analysis either by:</source>
          <target state="translated">El objeto &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; es muy &amp;uacute;til, pero tiene ciertas limitaciones para grandes conjuntos de datos. La mayor limitaci&amp;oacute;n es que &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; solo admite el procesamiento por lotes, lo que significa que todos los datos que se procesar&amp;aacute;n deben caber en la memoria principal. El objeto &lt;a href=&quot;generated/sklearn.decomposition.incrementalpca#sklearn.decomposition.IncrementalPCA&quot;&gt; &lt;code&gt;IncrementalPCA&lt;/code&gt; &lt;/a&gt; utiliza una forma diferente de procesamiento y permite c&amp;aacute;lculos parciales que coinciden casi exactamente con los resultados de &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; mientras procesan los datos en forma de minibatch. &lt;a href=&quot;generated/sklearn.decomposition.incrementalpca#sklearn.decomposition.IncrementalPCA&quot;&gt; &lt;code&gt;IncrementalPCA&lt;/code&gt; &lt;/a&gt; hace posible implementar un An&amp;aacute;lisis de Componentes Principales fuera del n&amp;uacute;cleo ya sea por:</target>
        </trans-unit>
        <trans-unit id="ecd6b33d3bd2199aadcf263cff0e5246cde4bd39" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.decomposition.sparsecoder#sklearn.decomposition.SparseCoder&quot;&gt;&lt;code&gt;SparseCoder&lt;/code&gt;&lt;/a&gt; object is an estimator that can be used to transform signals into sparse linear combination of atoms from a fixed, precomputed dictionary such as a discrete wavelet basis. This object therefore does not implement a &lt;code&gt;fit&lt;/code&gt; method. The transformation amounts to a sparse coding problem: finding a representation of the data as a linear combination of as few dictionary atoms as possible. All variations of dictionary learning implement the following transform methods, controllable via the &lt;code&gt;transform_method&lt;/code&gt; initialization parameter:</source>
          <target state="translated">El objeto &lt;a href=&quot;generated/sklearn.decomposition.sparsecoder#sklearn.decomposition.SparseCoder&quot;&gt; &lt;code&gt;SparseCoder&lt;/code&gt; &lt;/a&gt; es un estimador que se puede utilizar para transformar se&amp;ntilde;ales en una combinaci&amp;oacute;n lineal dispersa de &amp;aacute;tomos a partir de un diccionario fijo precalculado, como una base de ond&amp;iacute;culas discretas. Por tanto, este objeto no implementa un m&amp;eacute;todo de &lt;code&gt;fit&lt;/code&gt; . La transformaci&amp;oacute;n equivale a un escaso problema de codificaci&amp;oacute;n: encontrar una representaci&amp;oacute;n de los datos como una combinaci&amp;oacute;n lineal de la menor cantidad posible de &amp;aacute;tomos de diccionario. Todas las variaciones del aprendizaje de diccionario implementan los siguientes m&amp;eacute;todos de transformaci&amp;oacute;n, controlables mediante el par&amp;aacute;metro de inicializaci&amp;oacute;n &lt;code&gt;transform_method&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="e3da78a60195e1f6e094f14916e2b477c6f8356b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt; supports &lt;code&gt;warm_start=True&lt;/code&gt; which allows you to add more trees to an already fitted model:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="541c2e4d790ae9e327bfbba2dc5bd507a6c1e503" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.ensemble.stackingclassifier#sklearn.ensemble.StackingClassifier&quot;&gt;&lt;code&gt;StackingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.stackingregressor#sklearn.ensemble.StackingRegressor&quot;&gt;&lt;code&gt;StackingRegressor&lt;/code&gt;&lt;/a&gt; provide such strategies which can be applied to classification and regression problems.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8482134b0c48ad8bcdfc22624a585a7b569b1ee" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.ensemble.votingclassifier#sklearn.ensemble.VotingClassifier&quot;&gt;&lt;code&gt;VotingClassifier&lt;/code&gt;&lt;/a&gt; can also be used together with &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; in order to tune the hyperparameters of the individual estimators:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51b760d25143490b212d3dce7b63a475beffe57d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.feature_extraction.image.extract_patches_2d#sklearn.feature_extraction.image.extract_patches_2d&quot;&gt;&lt;code&gt;extract_patches_2d&lt;/code&gt;&lt;/a&gt; function extracts patches from an image stored as a two-dimensional array, or three-dimensional with color information along the third axis. For rebuilding an image from all its patches, use &lt;a href=&quot;generated/sklearn.feature_extraction.image.reconstruct_from_patches_2d#sklearn.feature_extraction.image.reconstruct_from_patches_2d&quot;&gt;&lt;code&gt;reconstruct_from_patches_2d&lt;/code&gt;&lt;/a&gt;. For example let use generate a 4x4 pixel picture with 3 color channels (e.g. in RGB format):</source>
          <target state="translated">La funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.feature_extraction.image.extract_patches_2d#sklearn.feature_extraction.image.extract_patches_2d&quot;&gt; &lt;code&gt;extract_patches_2d&lt;/code&gt; &lt;/a&gt; extrae parches de una imagen almacenada como una matriz bidimensional o tridimensional con informaci&amp;oacute;n de color a lo largo del tercer eje. Para reconstruir una imagen a partir de todos sus parches, use &lt;a href=&quot;generated/sklearn.feature_extraction.image.reconstruct_from_patches_2d#sklearn.feature_extraction.image.reconstruct_from_patches_2d&quot;&gt; &lt;code&gt;reconstruct_from_patches_2d&lt;/code&gt; &lt;/a&gt; . Por ejemplo, perm&amp;iacute;tanos generar una imagen de 4x4 p&amp;iacute;xeles con 3 canales de color (por ejemplo, en formato RGB):</target>
        </trans-unit>
        <trans-unit id="13de12da96c62cdbe967814b1ded04e8c85eef13" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.feature_extraction.image.patchextractor#sklearn.feature_extraction.image.PatchExtractor&quot;&gt;&lt;code&gt;PatchExtractor&lt;/code&gt;&lt;/a&gt; class works in the same way as &lt;a href=&quot;generated/sklearn.feature_extraction.image.extract_patches_2d#sklearn.feature_extraction.image.extract_patches_2d&quot;&gt;&lt;code&gt;extract_patches_2d&lt;/code&gt;&lt;/a&gt;, only it supports multiple images as input. It is implemented as an estimator, so it can be used in pipelines. See:</source>
          <target state="translated">La clase &lt;a href=&quot;generated/sklearn.feature_extraction.image.patchextractor#sklearn.feature_extraction.image.PatchExtractor&quot;&gt; &lt;code&gt;PatchExtractor&lt;/code&gt; &lt;/a&gt; funciona de la misma manera que &lt;a href=&quot;generated/sklearn.feature_extraction.image.extract_patches_2d#sklearn.feature_extraction.image.extract_patches_2d&quot;&gt; &lt;code&gt;extract_patches_2d&lt;/code&gt; &lt;/a&gt; , solo que admite m&amp;uacute;ltiples im&amp;aacute;genes como entrada. Se implementa como un estimador, por lo que se puede utilizar en pipelines. Ver:</target>
        </trans-unit>
        <trans-unit id="5f1d9b11617dc21530d4a8e947334af50d14c144" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt;&lt;code&gt;HashingVectorizer&lt;/code&gt;&lt;/a&gt; also comes with the following limitations:</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt; &lt;code&gt;HashingVectorizer&lt;/code&gt; &lt;/a&gt; tambi&amp;eacute;n viene con las siguientes limitaciones:</target>
        </trans-unit>
        <trans-unit id="dec1e79879a530cf5d8d2ea5bf189d8118bb1961" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessclassifier#sklearn.gaussian_process.GaussianProcessClassifier&quot;&gt;&lt;code&gt;GaussianProcessClassifier&lt;/code&gt;&lt;/a&gt; implements Gaussian processes (GP) for classification purposes, more specifically for probabilistic classification, where test predictions take the form of class probabilities. GaussianProcessClassifier places a GP prior on a latent function \(f\), which is then squashed through a link function to obtain the probabilistic classification. The latent function \(f\) is a so-called nuisance function, whose values are not observed and are not relevant by themselves. Its purpose is to allow a convenient formulation of the model, and \(f\) is removed (integrated out) during prediction. GaussianProcessClassifier implements the logistic link function, for which the integral cannot be computed analytically but is easily approximated in the binary case.</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessclassifier#sklearn.gaussian_process.GaussianProcessClassifier&quot;&gt; &lt;code&gt;GaussianProcessClassifier&lt;/code&gt; &lt;/a&gt; implementa procesos gaussianos (GP) con fines de clasificaci&amp;oacute;n, m&amp;aacute;s espec&amp;iacute;ficamente para la clasificaci&amp;oacute;n probabil&amp;iacute;stica, donde las predicciones de prueba toman la forma de probabilidades de clase. GaussianProcessClassifier coloca un GP antes de una funci&amp;oacute;n latente \ (f \), que luego se aplasta mediante una funci&amp;oacute;n de enlace para obtener la clasificaci&amp;oacute;n probabil&amp;iacute;stica. La funci&amp;oacute;n latente \ (f \) es una llamada funci&amp;oacute;n de molestia, cuyos valores no se observan y no son relevantes por s&amp;iacute; mismos. Su prop&amp;oacute;sito es permitir una formulaci&amp;oacute;n conveniente del modelo, y \ (f \) se elimina (se integra) durante la predicci&amp;oacute;n. GaussianProcessClassifier implementa la funci&amp;oacute;n de enlace log&amp;iacute;stico, para la cual la integral no se puede calcular anal&amp;iacute;ticamente pero se aproxima f&amp;aacute;cilmente en el caso binario.</target>
        </trans-unit>
        <trans-unit id="2a70b80f4163a2c6bfd08f3c8b84b458a9627cc7" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessregressor#sklearn.gaussian_process.GaussianProcessRegressor&quot;&gt;&lt;code&gt;GaussianProcessRegressor&lt;/code&gt;&lt;/a&gt; implements Gaussian processes (GP) for regression purposes. For this, the prior of the GP needs to be specified. The prior mean is assumed to be constant and zero (for &lt;code&gt;normalize_y=False&lt;/code&gt;) or the training data&amp;rsquo;s mean (for &lt;code&gt;normalize_y=True&lt;/code&gt;). The prior&amp;rsquo;s covariance is specified by a passing a &lt;a href=&quot;#gp-kernels&quot;&gt;kernel&lt;/a&gt; object. The hyperparameters of the kernel are optimized during fitting of GaussianProcessRegressor by maximizing the log-marginal-likelihood (LML) based on the passed &lt;code&gt;optimizer&lt;/code&gt;. As the LML may have multiple local optima, the optimizer can be started repeatedly by specifying &lt;code&gt;n_restarts_optimizer&lt;/code&gt;. The first run is always conducted starting from the initial hyperparameter values of the kernel; subsequent runs are conducted from hyperparameter values that have been chosen randomly from the range of allowed values. If the initial hyperparameters should be kept fixed, &lt;code&gt;None&lt;/code&gt; can be passed as optimizer.</source>
          <target state="translated">Los &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessregressor#sklearn.gaussian_process.GaussianProcessRegressor&quot;&gt; &lt;code&gt;GaussianProcessRegressor&lt;/code&gt; &lt;/a&gt; implementos procesos Gaussianos (GP) para fines de regresi&amp;oacute;n. Para ello, es necesario especificar la previa del m&amp;eacute;dico de cabecera. Se supone que la media anterior es constante y cero (para &lt;code&gt;normalize_y=False&lt;/code&gt; ) o la media de los datos de entrenamiento (para &lt;code&gt;normalize_y=True&lt;/code&gt; ). La covarianza del prior se especifica pasando un objeto del &lt;a href=&quot;#gp-kernels&quot;&gt;kernel&lt;/a&gt; . Los hiperpar&amp;aacute;metros del kernel se optimizan durante el ajuste de GaussianProcessRegressor maximizando la probabilidad de log-marginal (LML) basada en el &lt;code&gt;optimizer&lt;/code&gt; pasado . Como el LML puede tener m&amp;uacute;ltiples &amp;oacute;ptimos locales, el optimizador se puede iniciar repetidamente especificando &lt;code&gt;n_restarts_optimizer&lt;/code&gt; . La primera ejecuci&amp;oacute;n siempre se realiza a partir de los valores de hiperpar&amp;aacute;metros iniciales del kernel; las ejecuciones posteriores se realizan a partir de valores de hiperpar&amp;aacute;metros que se han elegido aleatoriamente del rango de valores permitidos. Si los hiperpar&amp;aacute;metros iniciales deben mantenerse fijos, &lt;code&gt;None&lt;/code&gt; se puede pasar como optimizador.</target>
        </trans-unit>
        <trans-unit id="cef90bbcd0a36066d60f0a9fa46fd7add704859a" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessregressor#sklearn.gaussian_process.GaussianProcessRegressor&quot;&gt;&lt;code&gt;GaussianProcessRegressor&lt;/code&gt;&lt;/a&gt; implements Gaussian processes (GP) for regression purposes. For this, the prior of the GP needs to be specified. The prior mean is assumed to be constant and zero (for &lt;code&gt;normalize_y=False&lt;/code&gt;) or the training data&amp;rsquo;s mean (for &lt;code&gt;normalize_y=True&lt;/code&gt;). The prior&amp;rsquo;s covariance is specified by passing a &lt;a href=&quot;#gp-kernels&quot;&gt;kernel&lt;/a&gt; object. The hyperparameters of the kernel are optimized during fitting of GaussianProcessRegressor by maximizing the log-marginal-likelihood (LML) based on the passed &lt;code&gt;optimizer&lt;/code&gt;. As the LML may have multiple local optima, the optimizer can be started repeatedly by specifying &lt;code&gt;n_restarts_optimizer&lt;/code&gt;. The first run is always conducted starting from the initial hyperparameter values of the kernel; subsequent runs are conducted from hyperparameter values that have been chosen randomly from the range of allowed values. If the initial hyperparameters should be kept fixed, &lt;code&gt;None&lt;/code&gt; can be passed as optimizer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a013933edad2184a36ef1d15fcbf21a794c0c7f5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.constantkernel#sklearn.gaussian_process.kernels.ConstantKernel&quot;&gt;&lt;code&gt;ConstantKernel&lt;/code&gt;&lt;/a&gt; kernel can be used as part of a &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.product#sklearn.gaussian_process.kernels.Product&quot;&gt;&lt;code&gt;Product&lt;/code&gt;&lt;/a&gt; kernel where it scales the magnitude of the other factor (kernel) or as part of a &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.sum#sklearn.gaussian_process.kernels.Sum&quot;&gt;&lt;code&gt;Sum&lt;/code&gt;&lt;/a&gt; kernel, where it modifies the mean of the Gaussian process. It depends on a parameter \(constant\_value\). It is defined as:</source>
          <target state="translated">El kernel de &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.constantkernel#sklearn.gaussian_process.kernels.ConstantKernel&quot;&gt; &lt;code&gt;ConstantKernel&lt;/code&gt; &lt;/a&gt; se puede utilizar como parte de un kernel de &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.product#sklearn.gaussian_process.kernels.Product&quot;&gt; &lt;code&gt;Product&lt;/code&gt; &lt;/a&gt; donde escala la magnitud del otro factor (kernel) o como parte de un kernel de &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.sum#sklearn.gaussian_process.kernels.Sum&quot;&gt; &lt;code&gt;Sum&lt;/code&gt; &lt;/a&gt; , donde modifica la media del proceso gaussiano. Depende de un par&amp;aacute;metro \ (constante \ _valor \). Se define como:</target>
        </trans-unit>
        <trans-unit id="a1a78e3b1d5985ce1973c8989ff0075d7d078b79" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt;&lt;code&gt;DotProduct&lt;/code&gt;&lt;/a&gt; kernel is commonly combined with exponentiation. An example with exponent 2 is shown in the following figure:</source>
          <target state="translated">El kernel &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt; &lt;code&gt;DotProduct&lt;/code&gt; &lt;/a&gt; se combina com&amp;uacute;nmente con exponenciaci&amp;oacute;n. En la siguiente figura se muestra un ejemplo con exponente 2:</target>
        </trans-unit>
        <trans-unit id="299194d50f816028e01666a91e5aaf031d88d5c0" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt;&lt;code&gt;DotProduct&lt;/code&gt;&lt;/a&gt; kernel is non-stationary and can be obtained from linear regression by putting \(N(0, 1)\) priors on the coefficients of \(x_d (d = 1, . . . , D)\) and a prior of \(N(0, \sigma_0^2)\) on the bias. The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt;&lt;code&gt;DotProduct&lt;/code&gt;&lt;/a&gt; kernel is invariant to a rotation of the coordinates about the origin, but not translations. It is parameterized by a parameter \(\sigma_0^2\). For \(\sigma_0^2 = 0\), the kernel is called the homogeneous linear kernel, otherwise it is inhomogeneous. The kernel is given by</source>
          <target state="translated">El n&amp;uacute;cleo de &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt; &lt;code&gt;DotProduct&lt;/code&gt; &lt;/a&gt; no es estacionario y puede obtenerse de la regresi&amp;oacute;n lineal poniendo \ (N (0, 1) \) a priori en los coeficientes de \ (x_d (d = 1,..., D) \) y una de \ (N (0, \ sigma_0 ^ 2) \) en el sesgo. El kernel &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt; &lt;code&gt;DotProduct&lt;/code&gt; &lt;/a&gt; es invariante a una rotaci&amp;oacute;n de las coordenadas sobre el origen, pero no a las traducciones. Est&amp;aacute; parametrizado por un par&amp;aacute;metro \ (\ sigma_0 ^ 2 \). Para \ (\ sigma_0 ^ 2 = 0 \), el kernel se llama kernel lineal homog&amp;eacute;neo, de lo contrario, no es homog&amp;eacute;neo. El kernel est&amp;aacute; dado por</target>
        </trans-unit>
        <trans-unit id="9b254fd92e2584b8ca8c7f30ca756b0bac24ec2b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.expsinesquared#sklearn.gaussian_process.kernels.ExpSineSquared&quot;&gt;&lt;code&gt;ExpSineSquared&lt;/code&gt;&lt;/a&gt; kernel allows modeling periodic functions. It is parameterized by a length-scale parameter \(l&amp;gt;0\) and a periodicity parameter \(p&amp;gt;0\). Only the isotropic variant where \(l\) is a scalar is supported at the moment. The kernel is given by:</source>
          <target state="translated">El kernel &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.expsinesquared#sklearn.gaussian_process.kernels.ExpSineSquared&quot;&gt; &lt;code&gt;ExpSineSquared&lt;/code&gt; &lt;/a&gt; permite modelar funciones peri&amp;oacute;dicas. Est&amp;aacute; parametrizado por un par&amp;aacute;metro de escala de longitud \ (l&amp;gt; 0 \) y un par&amp;aacute;metro de periodicidad \ (p&amp;gt; 0 \). En este momento, solo se admite la variante isotr&amp;oacute;pica donde \ (l \) es un escalar. El n&amp;uacute;cleo est&amp;aacute; dado por:</target>
        </trans-unit>
        <trans-unit id="4fa9c3925ee31fe17ddb7d4f95d9aa563f446e7b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.matern#sklearn.gaussian_process.kernels.Matern&quot;&gt;&lt;code&gt;Matern&lt;/code&gt;&lt;/a&gt; kernel is a stationary kernel and a generalization of the &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt; kernel. It has an additional parameter \(\nu\) which controls the smoothness of the resulting function. It is parameterized by a length-scale parameter \(l&amp;gt;0\), which can either be a scalar (isotropic variant of the kernel) or a vector with the same number of dimensions as the inputs \(x\) (anisotropic variant of the kernel). The kernel is given by:</source>
          <target state="translated">El kernel de &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.matern#sklearn.gaussian_process.kernels.Matern&quot;&gt; &lt;code&gt;Matern&lt;/code&gt; &lt;/a&gt; es un kernel estacionario y una generalizaci&amp;oacute;n del kernel &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt; &lt;code&gt;RBF&lt;/code&gt; &lt;/a&gt; . Tiene un par&amp;aacute;metro adicional \ (\ nu \) que controla la suavidad de la funci&amp;oacute;n resultante. Est&amp;aacute; parametrizado por un par&amp;aacute;metro de escala de longitud \ (l&amp;gt; 0 \), que puede ser un escalar (variante isotr&amp;oacute;pica del kernel) o un vector con el mismo n&amp;uacute;mero de dimensiones que las entradas \ (x \) (variante anisotr&amp;oacute;pica del n&amp;uacute;cleo). El n&amp;uacute;cleo est&amp;aacute; dado por:</target>
        </trans-unit>
        <trans-unit id="9cc391d0a3f24c35e3e834b704611ffc08dfc23c" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rationalquadratic#sklearn.gaussian_process.kernels.RationalQuadratic&quot;&gt;&lt;code&gt;RationalQuadratic&lt;/code&gt;&lt;/a&gt; kernel can be seen as a scale mixture (an infinite sum) of &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt; kernels with different characteristic length-scales. It is parameterized by a length-scale parameter \(l&amp;gt;0\) and a scale mixture parameter \(\alpha&amp;gt;0\) Only the isotropic variant where \(l\) is a scalar is supported at the moment. The kernel is given by:</source>
          <target state="translated">El kernel &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rationalquadratic#sklearn.gaussian_process.kernels.RationalQuadratic&quot;&gt; &lt;code&gt;RationalQuadratic&lt;/code&gt; &lt;/a&gt; puede verse como una mezcla de escalas (una suma infinita) de kernels &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt; &lt;code&gt;RBF&lt;/code&gt; &lt;/a&gt; con diferentes escalas de longitud caracter&amp;iacute;sticas. Est&amp;aacute; parametrizado por un par&amp;aacute;metro de escala de longitud \ (l&amp;gt; 0 \) y un par&amp;aacute;metro de mezcla de escala \ (\ alpha&amp;gt; 0 \) Solo la variante isotr&amp;oacute;pica donde \ (l \) es un escalar es compatible en este momento. El n&amp;uacute;cleo est&amp;aacute; dado por:</target>
        </trans-unit>
        <trans-unit id="a0d4e8e5df8534d7f797dec945fa5951797b46d9" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt; kernel is a stationary kernel. It is also known as the &amp;ldquo;squared exponential&amp;rdquo; kernel. It is parameterized by a length-scale parameter \(l&amp;gt;0\), which can either be a scalar (isotropic variant of the kernel) or a vector with the same number of dimensions as the inputs \(x\) (anisotropic variant of the kernel). The kernel is given by:</source>
          <target state="translated">El kernel &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt; &lt;code&gt;RBF&lt;/code&gt; &lt;/a&gt; es un kernel estacionario. Tambi&amp;eacute;n se conoce como el n&amp;uacute;cleo &quot;exponencial al cuadrado&quot;. Est&amp;aacute; parametrizado por un par&amp;aacute;metro de escala de longitud \ (l&amp;gt; 0 \), que puede ser un escalar (variante isotr&amp;oacute;pica del kernel) o un vector con el mismo n&amp;uacute;mero de dimensiones que las entradas \ (x \) (variante anisotr&amp;oacute;pica del n&amp;uacute;cleo). El n&amp;uacute;cleo est&amp;aacute; dado por:</target>
        </trans-unit>
        <trans-unit id="82f3fd9dd57bf0bc3cf4c6bc458ae2db6dc1ab71" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.impute.knnimputer#sklearn.impute.KNNImputer&quot;&gt;&lt;code&gt;KNNImputer&lt;/code&gt;&lt;/a&gt; class provides imputation for filling in missing values using the k-Nearest Neighbors approach. By default, a euclidean distance metric that supports missing values, &lt;code&gt;nan_euclidean_distances&lt;/code&gt;, is used to find the nearest neighbors. Each missing feature is imputed using values from &lt;code&gt;n_neighbors&lt;/code&gt; nearest neighbors that have a value for the feature. The feature of the neighbors are averaged uniformly or weighted by distance to each neighbor. If a sample has more than one feature missing, then the neighbors for that sample can be different depending on the particular feature being imputed. When the number of available neighbors is less than &lt;code&gt;n_neighbors&lt;/code&gt; and there are no defined distances to the training set, the training set average for that feature is used during imputation. If there is at least one neighbor with a defined distance, the weighted or unweighted average of the remaining neighbors will be used during imputation. If a feature is always missing in training, it is removed during &lt;code&gt;transform&lt;/code&gt;. For more information on the methodology, see ref. &lt;a href=&quot;#ol2001&quot; id=&quot;id5&quot;&gt;[OL2001]&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f4b1aa7c1e397df865fdc8d1fd65546b5eaaf2f" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt; transformer is useful to transform a dataset into corresponding binary matrix indicating the presence of missing values in the dataset. This transformation is useful in conjunction with imputation. When using imputation, preserving the information about which values had been missing can be informative.</source>
          <target state="translated">El transformador &lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt; &lt;code&gt;MissingIndicator&lt;/code&gt; &lt;/a&gt; es &amp;uacute;til para transformar un conjunto de datos en la matriz binaria correspondiente que indica la presencia de valores perdidos en el conjunto de datos. Esta transformaci&amp;oacute;n es &amp;uacute;til junto con la imputaci&amp;oacute;n. Cuando se usa la imputaci&amp;oacute;n, preservar la informaci&amp;oacute;n sobre los valores que faltaban puede ser informativo.</target>
        </trans-unit>
        <trans-unit id="a7157e982e0dbd339518050ff3330356266a7d9d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt; transformer is useful to transform a dataset into corresponding binary matrix indicating the presence of missing values in the dataset. This transformation is useful in conjunction with imputation. When using imputation, preserving the information about which values had been missing can be informative. Note that both the &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;SimpleImputer&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt; have the boolean parameter &lt;code&gt;add_indicator&lt;/code&gt; (&lt;code&gt;False&lt;/code&gt; by default) which when set to &lt;code&gt;True&lt;/code&gt; provides a convenient way of stacking the output of the &lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt; transformer with the output of the imputer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0c9736c8ad276e3deabee46eb181026e0204e8e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;SimpleImputer&lt;/code&gt;&lt;/a&gt; class also supports categorical data represented as string values or pandas categoricals when using the &lt;code&gt;'most_frequent'&lt;/code&gt; or &lt;code&gt;'constant'&lt;/code&gt; strategy:</source>
          <target state="translated">La clase &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt; &lt;code&gt;SimpleImputer&lt;/code&gt; &lt;/a&gt; tambi&amp;eacute;n admite datos categ&amp;oacute;ricos representados como valores de cadena o categor&amp;iacute;as pandas cuando se usa la &lt;code&gt;'most_frequent'&lt;/code&gt; o &lt;code&gt;'constant'&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="4d17103c250c5ab6ac126fd9a857f81de53fed6f" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;SimpleImputer&lt;/code&gt;&lt;/a&gt; class also supports sparse matrices:</source>
          <target state="translated">La clase &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt; &lt;code&gt;SimpleImputer&lt;/code&gt; &lt;/a&gt; tambi&amp;eacute;n admite matrices dispersas:</target>
        </trans-unit>
        <trans-unit id="618df5d6360d655fcf582933900e1cb3bcf02379" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;SimpleImputer&lt;/code&gt;&lt;/a&gt; class provides basic strategies for imputing missing values. Missing values can be imputed with a provided constant value, or using the statistics (mean, median or most frequent) of each column in which the missing values are located. This class also allows for different missing values encodings.</source>
          <target state="translated">La clase &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt; &lt;code&gt;SimpleImputer&lt;/code&gt; &lt;/a&gt; proporciona estrategias b&amp;aacute;sicas para imputar valores perdidos. Los valores faltantes se pueden imputar con un valor constante proporcionado o utilizando las estad&amp;iacute;sticas (media, mediana o m&amp;aacute;s frecuente) de cada columna en la que se encuentran los valores faltantes. Esta clase tambi&amp;eacute;n permite diferentes codificaciones de valores perdidos.</target>
        </trans-unit>
        <trans-unit id="68b4ceed0ca0d6a56ff0860f4ead39fbe0f8312e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;permutation_importance&lt;/code&gt;&lt;/a&gt; function calculates the feature importance of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-estimators&quot;&gt;estimators&lt;/a&gt; for a given dataset. The &lt;code&gt;n_repeats&lt;/code&gt; parameter sets the number of times a feature is randomly shuffled and returns a sample of feature importances.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f59968771d1dbbd03a744853045d3c0b7aa414b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt;&lt;code&gt;RBFSampler&lt;/code&gt;&lt;/a&gt; constructs an approximate mapping for the radial basis function kernel, also known as &lt;em&gt;Random Kitchen Sinks&lt;/em&gt;&lt;a href=&quot;#rr2007&quot; id=&quot;id2&quot;&gt;[RR2007]&lt;/a&gt;. This transformation can be used to explicitly model a kernel map, prior to applying a linear algorithm, for example a linear SVM:</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt; &lt;code&gt;RBFSampler&lt;/code&gt; &lt;/a&gt; construye un mapeo aproximado para el n&amp;uacute;cleo de la funci&amp;oacute;n de base radial, tambi&amp;eacute;n conocido como &lt;em&gt;Fregaderos de Cocina Aleatorios &lt;/em&gt;&lt;a href=&quot;#rr2007&quot; id=&quot;id2&quot;&gt;[RR2007]&lt;/a&gt; . Esta transformaci&amp;oacute;n se puede utilizar para modelar expl&amp;iacute;citamente un mapa del n&amp;uacute;cleo, antes de aplicar un algoritmo lineal, por ejemplo, una SVM lineal:</target>
        </trans-unit>
        <trans-unit id="44948166b7a6695399209dd8e1e1f1af0b0058e5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.huberregressor#sklearn.linear_model.HuberRegressor&quot;&gt;&lt;code&gt;HuberRegressor&lt;/code&gt;&lt;/a&gt; differs from using &lt;a href=&quot;generated/sklearn.linear_model.sgdregressor#sklearn.linear_model.SGDRegressor&quot;&gt;&lt;code&gt;SGDRegressor&lt;/code&gt;&lt;/a&gt; with loss set to &lt;code&gt;huber&lt;/code&gt; in the following ways.</source>
          <target state="translated">Los &lt;a href=&quot;generated/sklearn.linear_model.huberregressor#sklearn.linear_model.HuberRegressor&quot;&gt; &lt;code&gt;HuberRegressor&lt;/code&gt; &lt;/a&gt; difiere de usar &lt;a href=&quot;generated/sklearn.linear_model.sgdregressor#sklearn.linear_model.SGDRegressor&quot;&gt; &lt;code&gt;SGDRegressor&lt;/code&gt; &lt;/a&gt; con juego de p&amp;eacute;rdida de &lt;code&gt;huber&lt;/code&gt; en las siguientes maneras.</target>
        </trans-unit>
        <trans-unit id="7ab9e90f2b3f808e98761c90cab46994be6820bb" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.huberregressor#sklearn.linear_model.HuberRegressor&quot;&gt;&lt;code&gt;HuberRegressor&lt;/code&gt;&lt;/a&gt; is different to &lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt;&lt;code&gt;Ridge&lt;/code&gt;&lt;/a&gt; because it applies a linear loss to samples that are classified as outliers. A sample is classified as an inlier if the absolute error of that sample is lesser than a certain threshold. It differs from &lt;a href=&quot;generated/sklearn.linear_model.theilsenregressor#sklearn.linear_model.TheilSenRegressor&quot;&gt;&lt;code&gt;TheilSenRegressor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.linear_model.ransacregressor#sklearn.linear_model.RANSACRegressor&quot;&gt;&lt;code&gt;RANSACRegressor&lt;/code&gt;&lt;/a&gt; because it does not ignore the effect of the outliers but gives a lesser weight to them.</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.linear_model.huberregressor#sklearn.linear_model.HuberRegressor&quot;&gt; &lt;code&gt;HuberRegressor&lt;/code&gt; &lt;/a&gt; es diferente a &lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt; &lt;code&gt;Ridge&lt;/code&gt; &lt;/a&gt; porque se aplica una p&amp;eacute;rdida lineal para muestras que se clasifican como valores at&amp;iacute;picos. Una muestra se clasifica como inlier si el error absoluto de esa muestra es menor que un cierto umbral. Se diferencia de &lt;a href=&quot;generated/sklearn.linear_model.theilsenregressor#sklearn.linear_model.TheilSenRegressor&quot;&gt; &lt;code&gt;TheilSenRegressor&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.linear_model.ransacregressor#sklearn.linear_model.RANSACRegressor&quot;&gt; &lt;code&gt;RANSACRegressor&lt;/code&gt; &lt;/a&gt; porque no ignora el efecto de los valores at&amp;iacute;picos, pero les da un peso menor.</target>
        </trans-unit>
        <trans-unit id="6c9667130f9758bb96a7c943daf0a6616eced1f9" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.lasso#sklearn.linear_model.Lasso&quot;&gt;&lt;code&gt;Lasso&lt;/code&gt;&lt;/a&gt; is a linear model that estimates sparse coefficients. It is useful in some contexts due to its tendency to prefer solutions with fewer non-zero coefficients, effectively reducing the number of features upon which the given solution is dependent. For this reason Lasso and its variants are fundamental to the field of compressed sensing. Under certain conditions, it can recover the exact set of non-zero coefficients (see &lt;a href=&quot;../auto_examples/applications/plot_tomography_l1_reconstruction#sphx-glr-auto-examples-applications-plot-tomography-l1-reconstruction-py&quot;&gt;Compressive sensing: tomography reconstruction with L1 prior (Lasso)&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70ef4a25a40856b26fd987533d68c36540345c20" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.lasso#sklearn.linear_model.Lasso&quot;&gt;&lt;code&gt;Lasso&lt;/code&gt;&lt;/a&gt; is a linear model that estimates sparse coefficients. It is useful in some contexts due to its tendency to prefer solutions with fewer parameter values, effectively reducing the number of variables upon which the given solution is dependent. For this reason, the Lasso and its variants are fundamental to the field of compressed sensing. Under certain conditions, it can recover the exact set of non-zero weights (see &lt;a href=&quot;../auto_examples/applications/plot_tomography_l1_reconstruction#sphx-glr-auto-examples-applications-plot-tomography-l1-reconstruction-py&quot;&gt;Compressive sensing: tomography reconstruction with L1 prior (Lasso)&lt;/a&gt;).</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.linear_model.lasso#sklearn.linear_model.Lasso&quot;&gt; &lt;code&gt;Lasso&lt;/code&gt; &lt;/a&gt; es un modelo lineal que estima coeficientes escasos. Es &amp;uacute;til en algunos contextos debido a su tendencia a preferir soluciones con menos valores de par&amp;aacute;metros, reduciendo efectivamente el n&amp;uacute;mero de variables de las que depende la soluci&amp;oacute;n dada. Por esta raz&amp;oacute;n, el Lasso y sus variantes son fundamentales para el campo de la detecci&amp;oacute;n comprimida. En determinadas condiciones, puede recuperar el conjunto exacto de pesos distintos de cero (consulte &lt;a href=&quot;../auto_examples/applications/plot_tomography_l1_reconstruction#sphx-glr-auto-examples-applications-plot-tomography-l1-reconstruction-py&quot;&gt;Detecci&amp;oacute;n de compresi&amp;oacute;n: reconstrucci&amp;oacute;n de tomograf&amp;iacute;a con L1 antes (Lasso)&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="eec44edb57da642e68d30eaaa1191346c0a6b209" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.multitaskelasticnet#sklearn.linear_model.MultiTaskElasticNet&quot;&gt;&lt;code&gt;MultiTaskElasticNet&lt;/code&gt;&lt;/a&gt; is an elastic-net model that estimates sparse coefficients for multiple regression problems jointly: &lt;code&gt;Y&lt;/code&gt; is a 2D array of shape &lt;code&gt;(n_samples, n_tasks)&lt;/code&gt;. The constraint is that the selected features are the same for all the regression problems, also called tasks.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c1095adf7bd87312f73373efdee9c54e778b1be" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.multitaskelasticnet#sklearn.linear_model.MultiTaskElasticNet&quot;&gt;&lt;code&gt;MultiTaskElasticNet&lt;/code&gt;&lt;/a&gt; is an elastic-net model that estimates sparse coefficients for multiple regression problems jointly: &lt;code&gt;Y&lt;/code&gt; is a 2D array, of shape &lt;code&gt;(n_samples, n_tasks)&lt;/code&gt;. The constraint is that the selected features are the same for all the regression problems, also called tasks.</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.linear_model.multitaskelasticnet#sklearn.linear_model.MultiTaskElasticNet&quot;&gt; &lt;code&gt;MultiTaskElasticNet&lt;/code&gt; &lt;/a&gt; es un modelo el&amp;aacute;stico-net que estima los coeficientes dispersos para m&amp;uacute;ltiples problemas de regresi&amp;oacute;n conjuntamente: &lt;code&gt;Y&lt;/code&gt; es una matriz de 2D, de forma &lt;code&gt;(n_samples, n_tasks)&lt;/code&gt; . La restricci&amp;oacute;n es que las caracter&amp;iacute;sticas seleccionadas son las mismas para todos los problemas de regresi&amp;oacute;n, tambi&amp;eacute;n llamados tareas.</target>
        </trans-unit>
        <trans-unit id="0855f24dbbabd45aa8775e800911f6fb3f3411c3" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.multitasklasso#sklearn.linear_model.MultiTaskLasso&quot;&gt;&lt;code&gt;MultiTaskLasso&lt;/code&gt;&lt;/a&gt; is a linear model that estimates sparse coefficients for multiple regression problems jointly: &lt;code&gt;y&lt;/code&gt; is a 2D array, of shape &lt;code&gt;(n_samples, n_tasks)&lt;/code&gt;. The constraint is that the selected features are the same for all the regression problems, also called tasks.</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.linear_model.multitasklasso#sklearn.linear_model.MultiTaskLasso&quot;&gt; &lt;code&gt;MultiTaskLasso&lt;/code&gt; &lt;/a&gt; es un modelo lineal que estima los coeficientes dispersos para m&amp;uacute;ltiples problemas de regresi&amp;oacute;n conjuntamente: &lt;code&gt;y&lt;/code&gt; es una matriz 2D, de forma &lt;code&gt;(n_samples, n_tasks)&lt;/code&gt; . La restricci&amp;oacute;n es que las caracter&amp;iacute;sticas seleccionadas son las mismas para todos los problemas de regresi&amp;oacute;n, tambi&amp;eacute;n llamados tareas.</target>
        </trans-unit>
        <trans-unit id="d927ce91bac1b6df649580c487bdf34ce5f21e13" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.perceptron#sklearn.linear_model.Perceptron&quot;&gt;&lt;code&gt;Perceptron&lt;/code&gt;&lt;/a&gt; is another simple classification algorithm suitable for large scale learning. By default:</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.linear_model.perceptron#sklearn.linear_model.Perceptron&quot;&gt; &lt;code&gt;Perceptron&lt;/code&gt; &lt;/a&gt; es otro algoritmo de clasificaci&amp;oacute;n simple adecuado para el aprendizaje a gran escala. Por defecto:</target>
        </trans-unit>
        <trans-unit id="114bd6c0908df3918d68db503a6c5b185beb59c6" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt;&lt;code&gt;Ridge&lt;/code&gt;&lt;/a&gt; regressor has a classifier variant: &lt;a href=&quot;generated/sklearn.linear_model.ridgeclassifier#sklearn.linear_model.RidgeClassifier&quot;&gt;&lt;code&gt;RidgeClassifier&lt;/code&gt;&lt;/a&gt;. This classifier first converts binary targets to &lt;code&gt;{-1, 1}&lt;/code&gt; and then treats the problem as a regression task, optimizing the same objective as above. The predicted class corresponds to the sign of the regressor&amp;rsquo;s prediction. For multiclass classification, the problem is treated as multi-output regression, and the predicted class corresponds to the output with the highest value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="97c2977337c286541956e3848f1e0d89e23d036d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.ridgeclassifier#sklearn.linear_model.RidgeClassifier&quot;&gt;&lt;code&gt;RidgeClassifier&lt;/code&gt;&lt;/a&gt; can be significantly faster than e.g. &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; with a high number of classes, because it is able to compute the projection matrix \((X^T X)^{-1} X^T\) only once.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc6941408ce5829c04ee30dacb5eec313120d42e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.theilsenregressor#sklearn.linear_model.TheilSenRegressor&quot;&gt;&lt;code&gt;TheilSenRegressor&lt;/code&gt;&lt;/a&gt; estimator uses a generalization of the median in multiple dimensions. It is thus robust to multivariate outliers. Note however that the robustness of the estimator decreases quickly with the dimensionality of the problem. It looses its robustness properties and becomes no better than an ordinary least squares in high dimension.</source>
          <target state="translated">El estimador de &lt;a href=&quot;generated/sklearn.linear_model.theilsenregressor#sklearn.linear_model.TheilSenRegressor&quot;&gt; &lt;code&gt;TheilSenRegressor&lt;/code&gt; &lt;/a&gt; utiliza una generalizaci&amp;oacute;n de la mediana en m&amp;uacute;ltiples dimensiones. Por tanto, es resistente a valores at&amp;iacute;picos multivariados. Sin embargo, tenga en cuenta que la robustez del estimador disminuye r&amp;aacute;pidamente con la dimensionalidad del problema. Pierde sus propiedades de robustez y no se vuelve mejor que los m&amp;iacute;nimos cuadrados ordinarios en alta dimensi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="6c80a0d39e7d7595f1867b8a38b3ed5fa33131bb" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.theilsenregressor#sklearn.linear_model.TheilSenRegressor&quot;&gt;&lt;code&gt;TheilSenRegressor&lt;/code&gt;&lt;/a&gt; estimator uses a generalization of the median in multiple dimensions. It is thus robust to multivariate outliers. Note however that the robustness of the estimator decreases quickly with the dimensionality of the problem. It loses its robustness properties and becomes no better than an ordinary least squares in high dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="497dd0db8e84137ac4b140cff3317a3423c09e22" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.accuracy_score#sklearn.metrics.accuracy_score&quot;&gt;&lt;code&gt;accuracy_score&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Accuracy_and_precision&quot;&gt;accuracy&lt;/a&gt;, either the fraction (default) or the count (normalize=False) of correct predictions.</source>
          <target state="translated">La funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.accuracy_score#sklearn.metrics.accuracy_score&quot;&gt; &lt;code&gt;accuracy_score&lt;/code&gt; &lt;/a&gt; calcula la &lt;a href=&quot;https://en.wikipedia.org/wiki/Accuracy_and_precision&quot;&gt;precisi&amp;oacute;n&lt;/a&gt; , ya sea la fracci&amp;oacute;n (predeterminada) o el recuento (normalizar = Falso) de las predicciones correctas.</target>
        </trans-unit>
        <trans-unit id="734b9a83298cb0e5bb404a0eb951bb89a38c30c1" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;http://en.wikipedia.org/w/index.php?title=Information_retrieval&amp;amp;oldid=793358396#Average_precision&quot;&gt;average precision&lt;/a&gt; (AP) from prediction scores. The value is between 0 and 1 and higher is better. AP is defined as</source>
          <target state="translated">La funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt; calcula la &lt;a href=&quot;http://en.wikipedia.org/w/index.php?title=Information_retrieval&amp;amp;oldid=793358396#Average_precision&quot;&gt;precisi&amp;oacute;n promedio&lt;/a&gt; (AP) a partir de las puntuaciones de predicci&amp;oacute;n. El valor est&amp;aacute; entre 0 y 1 y m&amp;aacute;s alto es mejor. AP se define como</target>
        </trans-unit>
        <trans-unit id="e82eb3ff042c4b3a5e1b920dfccc7718db2306b1" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;https://en.wikipedia.org/w/index.php?title=Information_retrieval&amp;amp;oldid=793358396#Average_precision&quot;&gt;average precision&lt;/a&gt; (AP) from prediction scores. The value is between 0 and 1 and higher is better. AP is defined as</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c1e547613cb8b25282a0a1d2e2d0fa8b86fab4a" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.balanced_accuracy_score#sklearn.metrics.balanced_accuracy_score&quot;&gt;&lt;code&gt;balanced_accuracy_score&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Accuracy_and_precision&quot;&gt;balanced accuracy&lt;/a&gt;, which avoids inflated performance estimates on imbalanced datasets. It is the macro-average of recall scores per class or, equivalently, raw accuracy where each sample is weighted according to the inverse prevalence of its true class. Thus for balanced datasets, the score is equal to accuracy.</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.metrics.balanced_accuracy_score#sklearn.metrics.balanced_accuracy_score&quot;&gt; &lt;code&gt;balanced_accuracy_score&lt;/code&gt; &lt;/a&gt; funci&amp;oacute;n calcula la &lt;a href=&quot;https://en.wikipedia.org/wiki/Accuracy_and_precision&quot;&gt;precisi&amp;oacute;n de equilibrado&lt;/a&gt; , lo que evita las estimaciones de rendimiento inflados en conjuntos de datos desequilibrado. Es el macropromedio de las puntuaciones de recuerdo por clase o, de manera equivalente, la precisi&amp;oacute;n bruta donde cada muestra se pondera de acuerdo con la prevalencia inversa de su verdadera clase. Por lo tanto, para conjuntos de datos equilibrados, la puntuaci&amp;oacute;n es igual a la precisi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="6c29a08df4ccee7316d3d3b84f8a1be99122d005" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.brier_score_loss#sklearn.metrics.brier_score_loss&quot;&gt;&lt;code&gt;brier_score_loss&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Brier_score&quot;&gt;Brier score&lt;/a&gt; for binary classes. Quoting Wikipedia:</source>
          <target state="translated">La funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.brier_score_loss#sklearn.metrics.brier_score_loss&quot;&gt; &lt;code&gt;brier_score_loss&lt;/code&gt; &lt;/a&gt; calcula la &lt;a href=&quot;https://en.wikipedia.org/wiki/Brier_score&quot;&gt;puntuaci&amp;oacute;n de Brier&lt;/a&gt; para clases binarias. Citando Wikipedia:</target>
        </trans-unit>
        <trans-unit id="446d2ff4c24d7bf4bbe8a92416191f1e2b3de72b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.brier_score_loss#sklearn.metrics.brier_score_loss&quot;&gt;&lt;code&gt;sklearn.metrics.brier_score_loss&lt;/code&gt;&lt;/a&gt; may be used to evaluate how well a classifier is calibrated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80ef899573ebb3be6112621f7df5aadf4a0d99d9" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.classification_report#sklearn.metrics.classification_report&quot;&gt;&lt;code&gt;classification_report&lt;/code&gt;&lt;/a&gt; function builds a text report showing the main classification metrics. Here is a small example with custom &lt;code&gt;target_names&lt;/code&gt; and inferred labels:</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.metrics.classification_report#sklearn.metrics.classification_report&quot;&gt; &lt;code&gt;classification_report&lt;/code&gt; &lt;/a&gt; funci&amp;oacute;n construye un informe de texto que muestra los principales par&amp;aacute;metros de clasificaci&amp;oacute;n. Aqu&amp;iacute; hay un peque&amp;ntilde;o ejemplo con &lt;code&gt;target_names&lt;/code&gt; personalizados y etiquetas inferidas:</target>
        </trans-unit>
        <trans-unit id="297cbd08a7b9d6cdee2db0fac772b51c60ecb158" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.confusion_matrix#sklearn.metrics.confusion_matrix&quot;&gt;&lt;code&gt;confusion_matrix&lt;/code&gt;&lt;/a&gt; function evaluates classification accuracy by computing the &lt;a href=&quot;https://en.wikipedia.org/wiki/Confusion_matrix&quot;&gt;confusion matrix&lt;/a&gt; with each row corresponding to the true class (Wikipedia and other references may use different convention for axes).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="646495d784f725b3203da7b1895753c47a46c957" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.confusion_matrix#sklearn.metrics.confusion_matrix&quot;&gt;&lt;code&gt;confusion_matrix&lt;/code&gt;&lt;/a&gt; function evaluates classification accuracy by computing the confusion matrix with each row corresponding to the true class &amp;lt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Confusion_matrix&quot;&gt;https://en.wikipedia.org/wiki/Confusion_matrix&lt;/a&gt;&amp;gt;`_. (Wikipedia and other references may use different convention for axes.)</source>
          <target state="translated">La funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.confusion_matrix#sklearn.metrics.confusion_matrix&quot;&gt; &lt;code&gt;confusion_matrix&lt;/code&gt; &lt;/a&gt; eval&amp;uacute;a la precisi&amp;oacute;n de la clasificaci&amp;oacute;n calculando la matriz de confusi&amp;oacute;n con cada fila correspondiente a la clase verdadera &amp;lt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Confusion_matrix&quot;&gt;https://en.wikipedia.org/wiki/Confusion_matrix&lt;/a&gt; &amp;gt; `_. (Wikipedia y otras referencias pueden usar una convenci&amp;oacute;n diferente para los ejes).</target>
        </trans-unit>
        <trans-unit id="627c762ce2611d603b6cf9dd93706bacfe9a64ab" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.coverage_error#sklearn.metrics.coverage_error&quot;&gt;&lt;code&gt;coverage_error&lt;/code&gt;&lt;/a&gt; function computes the average number of labels that have to be included in the final prediction such that all true labels are predicted. This is useful if you want to know how many top-scored-labels you have to predict in average without missing any true one. The best value of this metrics is thus the average number of true labels.</source>
          <target state="translated">La funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.coverage_error#sklearn.metrics.coverage_error&quot;&gt; &lt;code&gt;coverage_error&lt;/code&gt; &lt;/a&gt; calcula el n&amp;uacute;mero medio de etiquetas que deben incluirse en la predicci&amp;oacute;n final de modo que se predigan todas las etiquetas verdaderas. Esto es &amp;uacute;til si desea saber cu&amp;aacute;ntas etiquetas de puntaje alto tiene que predecir en promedio sin perder ninguna verdadera. El mejor valor de esta m&amp;eacute;trica es, por tanto, el n&amp;uacute;mero medio de etiquetas verdaderas.</target>
        </trans-unit>
        <trans-unit id="365c5eb64f0dc2e33be205a551210f568e81546d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt;&lt;code&gt;explained_variance_score&lt;/code&gt;&lt;/a&gt; computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Explained_variation&quot;&gt;explained variance regression score&lt;/a&gt;.</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt; &lt;code&gt;explained_variance_score&lt;/code&gt; &lt;/a&gt; calcula el &lt;a href=&quot;https://en.wikipedia.org/wiki/Explained_variation&quot;&gt;puntaje de regresi&amp;oacute;n de la varianza explicada&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="16accfb21d784810c328541c85b1894b818cde8e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.hamming_loss#sklearn.metrics.hamming_loss&quot;&gt;&lt;code&gt;hamming_loss&lt;/code&gt;&lt;/a&gt; computes the average Hamming loss or &lt;a href=&quot;https://en.wikipedia.org/wiki/Hamming_distance&quot;&gt;Hamming distance&lt;/a&gt; between two sets of samples.</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.metrics.hamming_loss#sklearn.metrics.hamming_loss&quot;&gt; &lt;code&gt;hamming_loss&lt;/code&gt; &lt;/a&gt; calcula la p&amp;eacute;rdida de Hamming media o &lt;a href=&quot;https://en.wikipedia.org/wiki/Hamming_distance&quot;&gt;distancia de Hamming&lt;/a&gt; entre dos conjuntos de muestras.</target>
        </trans-unit>
        <trans-unit id="6d1238c9791f472ba1850e50c0898d87bebfa2d3" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt;&lt;code&gt;hinge_loss&lt;/code&gt;&lt;/a&gt; function computes the average distance between the model and the data using &lt;a href=&quot;https://en.wikipedia.org/wiki/Hinge_loss&quot;&gt;hinge loss&lt;/a&gt;, a one-sided metric that considers only prediction errors. (Hinge loss is used in maximal margin classifiers such as support vector machines.)</source>
          <target state="translated">La funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt; &lt;code&gt;hinge_loss&lt;/code&gt; &lt;/a&gt; calcula la distancia promedio entre el modelo y los datos utilizando la &lt;a href=&quot;https://en.wikipedia.org/wiki/Hinge_loss&quot;&gt;p&amp;eacute;rdida de bisagra&lt;/a&gt; , una m&amp;eacute;trica unilateral que considera solo los errores de predicci&amp;oacute;n. (La p&amp;eacute;rdida de bisagra se utiliza en clasificadores de margen m&amp;aacute;ximo, como las m&amp;aacute;quinas de vectores de soporte).</target>
        </trans-unit>
        <trans-unit id="8897c326f42ba94a97047f2763d3dfdfd57b8bb8" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.jaccard_score#sklearn.metrics.jaccard_score&quot;&gt;&lt;code&gt;jaccard_score&lt;/code&gt;&lt;/a&gt; function computes the average of &lt;a href=&quot;https://en.wikipedia.org/wiki/Jaccard_index&quot;&gt;Jaccard similarity coefficients&lt;/a&gt;, also called the Jaccard index, between pairs of label sets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29930da8eb2c0b1ff7129cc1cbfbb0416883031e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.jaccard_similarity_score#sklearn.metrics.jaccard_similarity_score&quot;&gt;&lt;code&gt;jaccard_similarity_score&lt;/code&gt;&lt;/a&gt; function computes the average (default) or sum of &lt;a href=&quot;https://en.wikipedia.org/wiki/Jaccard_index&quot;&gt;Jaccard similarity coefficients&lt;/a&gt;, also called the Jaccard index, between pairs of label sets.</source>
          <target state="translated">La funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.jaccard_similarity_score#sklearn.metrics.jaccard_similarity_score&quot;&gt; &lt;code&gt;jaccard_similarity_score&lt;/code&gt; &lt;/a&gt; calcula el promedio (predeterminado) o la suma de los &lt;a href=&quot;https://en.wikipedia.org/wiki/Jaccard_index&quot;&gt;coeficientes de similitud&lt;/a&gt; de Jaccard , tambi&amp;eacute;n llamado &amp;iacute;ndice de Jaccard, entre pares de conjuntos de etiquetas.</target>
        </trans-unit>
        <trans-unit id="cbf6f35f94b93c090ec2e48a35d245f91dcfca65" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.label_ranking_average_precision_score#sklearn.metrics.label_ranking_average_precision_score&quot;&gt;&lt;code&gt;label_ranking_average_precision_score&lt;/code&gt;&lt;/a&gt; function implements label ranking average precision (LRAP). This metric is linked to the &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; function, but is based on the notion of label ranking instead of precision and recall.</source>
          <target state="translated">La funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.label_ranking_average_precision_score#sklearn.metrics.label_ranking_average_precision_score&quot;&gt; &lt;code&gt;label_ranking_average_precision_score&lt;/code&gt; &lt;/a&gt; implementa la precisi&amp;oacute;n promedio de clasificaci&amp;oacute;n de etiquetas (LRAP). Esta m&amp;eacute;trica est&amp;aacute; vinculada a la funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt; , pero se basa en la noci&amp;oacute;n de clasificaci&amp;oacute;n de etiquetas en lugar de precisi&amp;oacute;n y recuperaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="79620a85c10a9be19922ad33cc7395bed79c9e4e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.label_ranking_loss#sklearn.metrics.label_ranking_loss&quot;&gt;&lt;code&gt;label_ranking_loss&lt;/code&gt;&lt;/a&gt; function computes the ranking loss which averages over the samples the number of label pairs that are incorrectly ordered, i.e. true labels have a lower score than false labels, weighted by the inverse of the number of ordered pairs of false and true labels. The lowest achievable ranking loss is zero.</source>
          <target state="translated">La funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.label_ranking_loss#sklearn.metrics.label_ranking_loss&quot;&gt; &lt;code&gt;label_ranking_loss&lt;/code&gt; &lt;/a&gt; calcula la p&amp;eacute;rdida de clasificaci&amp;oacute;n que promedia sobre las muestras el n&amp;uacute;mero de pares de etiquetas que est&amp;aacute;n ordenados incorrectamente, es decir, las etiquetas verdaderas tienen una puntuaci&amp;oacute;n m&amp;aacute;s baja que las etiquetas falsas, ponderada por la inversa del n&amp;uacute;mero de pares ordenados de etiquetas falsas y verdaderas. La p&amp;eacute;rdida de clasificaci&amp;oacute;n m&amp;aacute;s baja alcanzable es cero.</target>
        </trans-unit>
        <trans-unit id="4b0810d3cef1ca02b990e21053d774c24a0e430b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.log_loss#sklearn.metrics.log_loss&quot;&gt;&lt;code&gt;log_loss&lt;/code&gt;&lt;/a&gt; function computes log loss given a list of ground-truth labels and a probability matrix, as returned by an estimator&amp;rsquo;s &lt;code&gt;predict_proba&lt;/code&gt; method.</source>
          <target state="translated">La funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.log_loss#sklearn.metrics.log_loss&quot;&gt; &lt;code&gt;log_loss&lt;/code&gt; &lt;/a&gt; calcula la p&amp;eacute;rdida logar&amp;iacute;tmica dada una lista de etiquetas de verdad del terreno y una matriz de probabilidad, como lo devuelve el m&amp;eacute;todo &lt;code&gt;predict_proba&lt;/code&gt; de un estimador .</target>
        </trans-unit>
        <trans-unit id="3661b0b19cd7cbd747b2bf1ce7b4a383102a7abe" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.matthews_corrcoef#sklearn.metrics.matthews_corrcoef&quot;&gt;&lt;code&gt;matthews_corrcoef&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Matthews_correlation_coefficient&quot;&gt;Matthew&amp;rsquo;s correlation coefficient (MCC)&lt;/a&gt; for binary classes. Quoting Wikipedia:</source>
          <target state="translated">La funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.matthews_corrcoef#sklearn.metrics.matthews_corrcoef&quot;&gt; &lt;code&gt;matthews_corrcoef&lt;/code&gt; &lt;/a&gt; calcula el &lt;a href=&quot;https://en.wikipedia.org/wiki/Matthews_correlation_coefficient&quot;&gt;coeficiente de correlaci&amp;oacute;n de Matthew (MCC)&lt;/a&gt; para clases binarias. Citando Wikipedia:</target>
        </trans-unit>
        <trans-unit id="61afc8dcca66cd062b78b06b9f6f1f6a381f8368" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.max_error#sklearn.metrics.max_error&quot;&gt;&lt;code&gt;max_error&lt;/code&gt;&lt;/a&gt; does not support multioutput.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d67557cc032f22cb8c3e56bc9812e04ade8f8ad" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.max_error#sklearn.metrics.max_error&quot;&gt;&lt;code&gt;max_error&lt;/code&gt;&lt;/a&gt; function computes the maximum &lt;a href=&quot;https://en.wikipedia.org/wiki/Errors_and_residuals&quot;&gt;residual error&lt;/a&gt; , a metric that captures the worst case error between the predicted value and the true value. In a perfectly fitted single output regression model, &lt;code&gt;max_error&lt;/code&gt; would be &lt;code&gt;0&lt;/code&gt; on the training set and though this would be highly unlikely in the real world, this metric shows the extent of error that the model had when it was fitted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8af6e2db7d7843522a3d6755e0b8d1e9cbd1e8f1" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.mean_absolute_error#sklearn.metrics.mean_absolute_error&quot;&gt;&lt;code&gt;mean_absolute_error&lt;/code&gt;&lt;/a&gt; function computes &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_absolute_error&quot;&gt;mean absolute error&lt;/a&gt;, a risk metric corresponding to the expected value of the absolute error loss or \(l1\)-norm loss.</source>
          <target state="translated">La funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.mean_absolute_error#sklearn.metrics.mean_absolute_error&quot;&gt; &lt;code&gt;mean_absolute_error&lt;/code&gt; &lt;/a&gt; calcula &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_absolute_error&quot;&gt;el error absoluto medio&lt;/a&gt; , una m&amp;eacute;trica de riesgo correspondiente al valor esperado de la p&amp;eacute;rdida de error absoluto o \ (l1 \) - p&amp;eacute;rdida de norma.</target>
        </trans-unit>
        <trans-unit id="798074cb4600d0906a9ad4975942309f6067f034" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt;&lt;code&gt;mean_squared_error&lt;/code&gt;&lt;/a&gt; function computes &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_squared_error&quot;&gt;mean square error&lt;/a&gt;, a risk metric corresponding to the expected value of the squared (quadratic) error or loss.</source>
          <target state="translated">La funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt; &lt;code&gt;mean_squared_error&lt;/code&gt; &lt;/a&gt; calcula el &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_squared_error&quot;&gt;error cuadr&amp;aacute;tico medio&lt;/a&gt; , una m&amp;eacute;trica de riesgo que corresponde al valor esperado del error o p&amp;eacute;rdida al cuadrado (cuadr&amp;aacute;tico).</target>
        </trans-unit>
        <trans-unit id="e4bbccf6d12a691e935e91e2611be809f1bb4329" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.mean_squared_log_error#sklearn.metrics.mean_squared_log_error&quot;&gt;&lt;code&gt;mean_squared_log_error&lt;/code&gt;&lt;/a&gt; function computes a risk metric corresponding to the expected value of the squared logarithmic (quadratic) error or loss.</source>
          <target state="translated">La funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.mean_squared_log_error#sklearn.metrics.mean_squared_log_error&quot;&gt; &lt;code&gt;mean_squared_log_error&lt;/code&gt; &lt;/a&gt; calcula una m&amp;eacute;trica de riesgo correspondiente al valor esperado del error o p&amp;eacute;rdida logar&amp;iacute;tmica al cuadrado (cuadr&amp;aacute;tico).</target>
        </trans-unit>
        <trans-unit id="9206d6989b69732d0750b8f7b0f0cca35f16a502" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.mean_tweedie_deviance#sklearn.metrics.mean_tweedie_deviance&quot;&gt;&lt;code&gt;mean_tweedie_deviance&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Tweedie_distribution#The_Tweedie_deviance&quot;&gt;mean Tweedie deviance error&lt;/a&gt; with a &lt;code&gt;power&lt;/code&gt; parameter (\(p\)). This is a metric that elicits predicted expectation values of regression targets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39f48c0bbd67ae6ad01f06368c176486b0da9e3b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.median_absolute_error#sklearn.metrics.median_absolute_error&quot;&gt;&lt;code&gt;median_absolute_error&lt;/code&gt;&lt;/a&gt; does not support multioutput.</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.metrics.median_absolute_error#sklearn.metrics.median_absolute_error&quot;&gt; &lt;code&gt;median_absolute_error&lt;/code&gt; &lt;/a&gt; no soporta salidas m&amp;uacute;ltiples.</target>
        </trans-unit>
        <trans-unit id="4c03eab2aa446025510f65f3a7e796a70c97a820" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.median_absolute_error#sklearn.metrics.median_absolute_error&quot;&gt;&lt;code&gt;median_absolute_error&lt;/code&gt;&lt;/a&gt; is particularly interesting because it is robust to outliers. The loss is calculated by taking the median of all absolute differences between the target and the prediction.</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.metrics.median_absolute_error#sklearn.metrics.median_absolute_error&quot;&gt; &lt;code&gt;median_absolute_error&lt;/code&gt; &lt;/a&gt; es particularmente interesante porque es robusto a valores at&amp;iacute;picos. La p&amp;eacute;rdida se calcula tomando la mediana de todas las diferencias absolutas entre el objetivo y la predicci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="9e08c2b58ff3ad56580920cccb403426006e1ddc" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.multilabel_confusion_matrix#sklearn.metrics.multilabel_confusion_matrix&quot;&gt;&lt;code&gt;multilabel_confusion_matrix&lt;/code&gt;&lt;/a&gt; function computes class-wise (default) or sample-wise (samplewise=True) multilabel confusion matrix to evaluate the accuracy of a classification. multilabel_confusion_matrix also treats multiclass data as if it were multilabel, as this is a transformation commonly applied to evaluate multiclass problems with binary classification metrics (such as precision, recall, etc.).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f5631acff2238ea5bcb79376fef6d2e143756a6" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt;&lt;code&gt;precision_recall_curve&lt;/code&gt;&lt;/a&gt; computes a precision-recall curve from the ground truth label and a score given by the classifier by varying a decision threshold.</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt; &lt;code&gt;precision_recall_curve&lt;/code&gt; &lt;/a&gt; calcula una curva de precisi&amp;oacute;n de recordar de la etiqueta realidad del terreno y una puntuaci&amp;oacute;n dada por el clasificador mediante la variaci&amp;oacute;n de un umbral de decisi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="d16f1c84f45a895677960253a6c6c45cf8b671e5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt;&lt;code&gt;explained_variance_score&lt;/code&gt;&lt;/a&gt; accept an additional value &lt;code&gt;'variance_weighted'&lt;/code&gt; for the &lt;code&gt;multioutput&lt;/code&gt; parameter. This option leads to a weighting of each individual score by the variance of the corresponding target variable. This setting quantifies the globally captured unscaled variance. If the target variables are of different scale, then this score puts more importance on well explaining the higher variance variables. &lt;code&gt;multioutput='variance_weighted'&lt;/code&gt; is the default value for &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt; for backward compatibility. This will be changed to &lt;code&gt;uniform_average&lt;/code&gt; in the future.</source>
          <target state="translated">La &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt; &lt;code&gt;r2_score&lt;/code&gt; &lt;/a&gt; y la puntuaci&amp;oacute;n varianza &lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt; &lt;code&gt;explained_variance_score&lt;/code&gt; &lt;/a&gt; aceptan un valor adicional &lt;code&gt;'variance_weighted'&lt;/code&gt; &lt;code&gt;multioutput&lt;/code&gt; ' para el par&amp;aacute;metro de salida m&amp;uacute;ltiple . Esta opci&amp;oacute;n conduce a una ponderaci&amp;oacute;n de cada puntuaci&amp;oacute;n individual por la varianza de la variable objetivo correspondiente. Esta configuraci&amp;oacute;n cuantifica la varianza sin escala capturada globalmente. Si las variables objetivo son de diferente escala, entonces esta puntuaci&amp;oacute;n le da m&amp;aacute;s importancia a explicar bien las variables de mayor varianza. &lt;code&gt;multioutput='variance_weighted'&lt;/code&gt; es el valor predeterminado de &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt; &lt;code&gt;r2_score&lt;/code&gt; &lt;/a&gt; para compatibilidad con versiones anteriores. Esto se cambiar&amp;aacute; a &lt;code&gt;uniform_average&lt;/code&gt; en el futuro.</target>
        </trans-unit>
        <trans-unit id="093b69e0a2a3ccbb33c0abc5ad459d307bcf6553" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt; function computes R&amp;sup2;, the &lt;a href=&quot;https://en.wikipedia.org/wiki/Coefficient_of_determination&quot;&gt;coefficient of determination&lt;/a&gt;. It provides a measure of how well future samples are likely to be predicted by the model. Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.</source>
          <target state="translated">La funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt; &lt;code&gt;r2_score&lt;/code&gt; &lt;/a&gt; calcula R&amp;sup2;, el &lt;a href=&quot;https://en.wikipedia.org/wiki/Coefficient_of_determination&quot;&gt;coeficiente de determinaci&amp;oacute;n&lt;/a&gt; . Proporciona una medida de qu&amp;eacute; tan bien es probable que el modelo prediga las muestras futuras. La mejor puntuaci&amp;oacute;n posible es 1.0 y puede ser negativa (porque el modelo puede ser arbitrariamente peor). Un modelo constante que siempre predice el valor esperado de y, sin tener en cuenta las caracter&amp;iacute;sticas de entrada, obtendr&amp;iacute;a una puntuaci&amp;oacute;n R ^ 2 de 0.0.</target>
        </trans-unit>
        <trans-unit id="38084709322f1f775abaac153e1595951318cede" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Coefficient_of_determination&quot;&gt;coefficient of determination&lt;/a&gt;, usually denoted as R&amp;sup2;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4fdc4c3e65c0a2a9ffbf753fef92ef0300417867" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt; function can also be used in multi-class classification. Two averaging strategies are currently supported: the one-vs-one algorithm computes the average of the pairwise ROC AUC scores, and the one-vs-rest algorithm computes the average of the ROC AUC scores for each class against all other classes. In both cases, the predicted labels are provided in an array with values from 0 to &lt;code&gt;n_classes&lt;/code&gt;, and the scores correspond to the probability estimates that a sample belongs to a particular class. The OvO and OvR algorithms support weighting uniformly (&lt;code&gt;average='macro'&lt;/code&gt;) and by prevalence (&lt;code&gt;average='weighted'&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cdf15299db25ef1f3b3628cdbe3b0de1b0d0ab3" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt; function computes the area under the receiver operating characteristic (ROC) curve, which is also denoted by AUC or AUROC. By computing the area under the roc curve, the curve information is summarized in one number. For more information see the &lt;a href=&quot;https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve&quot;&gt;Wikipedia article on AUC&lt;/a&gt;.</source>
          <target state="translated">La funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;roc_auc_score&lt;/code&gt; &lt;/a&gt; calcula el &amp;aacute;rea bajo la curva de caracter&amp;iacute;stica operativa del receptor (ROC), que tambi&amp;eacute;n se denota por AUC o AUROC. Al calcular el &amp;aacute;rea bajo la curva roc, la informaci&amp;oacute;n de la curva se resume en un n&amp;uacute;mero. Para obtener m&amp;aacute;s informaci&amp;oacute;n, consulte el &lt;a href=&quot;https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve&quot;&gt;art&amp;iacute;culo de Wikipedia sobre las AUC&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="fbc2259a8dc85fa7ed24780d0f0e2ac678fbcad9" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.zero_one_loss#sklearn.metrics.zero_one_loss&quot;&gt;&lt;code&gt;zero_one_loss&lt;/code&gt;&lt;/a&gt; function computes the sum or the average of the 0-1 classification loss (\(L_{0-1}\)) over \(n_{\text{samples}}\). By default, the function normalizes over the sample. To get the sum of the \(L_{0-1}\), set &lt;code&gt;normalize&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">La funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.zero_one_loss#sklearn.metrics.zero_one_loss&quot;&gt; &lt;code&gt;zero_one_loss&lt;/code&gt; &lt;/a&gt; calcula la suma o el promedio de la p&amp;eacute;rdida de clasificaci&amp;oacute;n 0-1 (\ (L_ {0-1} \)) sobre \ (n _ {\ text {samples}} \). De forma predeterminada, la funci&amp;oacute;n se normaliza sobre la muestra. Para obtener la suma de \ (L_ {0-1} \), establezca &lt;code&gt;normalize&lt;/code&gt; en &lt;code&gt;False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0ce78ef531a28f4df4b9620cf7454901e00bf965" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt; object implements a variant of the Gaussian mixture model with variational inference algorithms. The API is similar as the one defined by &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt;&lt;code&gt;GaussianMixture&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">El objeto &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt; &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; &lt;/a&gt; implementa una variante del modelo de mezcla gaussiana con algoritmos de inferencia variacional. La API es similar a la definida por &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt; &lt;code&gt;GaussianMixture&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="7755b185d3bd9567bc77a31c3d84e8be2c332f90" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt;&lt;code&gt;GaussianMixture&lt;/code&gt;&lt;/a&gt; comes with different options to constrain the covariance of the difference classes estimated: spherical, diagonal, tied or full covariance.</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt; &lt;code&gt;GaussianMixture&lt;/code&gt; &lt;/a&gt; viene con diferentes opciones para restringir la covarianza de las clases diferencia estimada: covarianza esf&amp;eacute;rica, diagonal, atado o total.</target>
        </trans-unit>
        <trans-unit id="9cb1ef419e28ff804b54eef9fc18747641996ac9" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt;&lt;code&gt;GaussianMixture&lt;/code&gt;&lt;/a&gt; object implements the &lt;a href=&quot;#expectation-maximization&quot;&gt;expectation-maximization&lt;/a&gt; (EM) algorithm for fitting mixture-of-Gaussian models. It can also draw confidence ellipsoids for multivariate models, and compute the Bayesian Information Criterion to assess the number of clusters in the data. A &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture.fit&quot;&gt;&lt;code&gt;GaussianMixture.fit&lt;/code&gt;&lt;/a&gt; method is provided that learns a Gaussian Mixture Model from train data. Given test data, it can assign to each sample the Gaussian it mostly probably belong to using the &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture.predict&quot;&gt;&lt;code&gt;GaussianMixture.predict&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="translated">El objeto &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt; &lt;code&gt;GaussianMixture&lt;/code&gt; &lt;/a&gt; implementa el algoritmo de &lt;a href=&quot;#expectation-maximization&quot;&gt;maximizaci&amp;oacute;n de expectativas&lt;/a&gt; (EM) para ajustar modelos de mezcla de gaussianos. Tambi&amp;eacute;n puede dibujar elipsoides de confianza para modelos multivariados y calcular el Criterio de informaci&amp;oacute;n bayesiano para evaluar el n&amp;uacute;mero de agrupaciones en los datos. Se proporciona un m&amp;eacute;todo &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture.fit&quot;&gt; &lt;code&gt;GaussianMixture.fit&lt;/code&gt; &lt;/a&gt; que aprende un modelo de mezcla gaussiana a partir de los datos del tren. Dados los datos de prueba, puede asignar a cada muestra el gaussiano al que probablemente pertenece utilizando el m&amp;eacute;todo &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture.predict&quot;&gt; &lt;code&gt;GaussianMixture.predict&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0716de4b023c33cd11d454f2784cb63c7a79bbcc" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.model_selection.cross_validate#sklearn.model_selection.cross_validate&quot;&gt;&lt;code&gt;cross_validate&lt;/code&gt;&lt;/a&gt; function differs from &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;cross_val_score&lt;/code&gt;&lt;/a&gt; in two ways:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0de55d1a8cabbad74e59064d298db364a4949211" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; instance implements the usual estimator API: when &amp;ldquo;fitting&amp;rdquo; it on a dataset all the possible combinations of parameter values are evaluated and the best combination is retained.</source>
          <target state="translated">La instancia de &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt; implementa la API de estimador habitual: cuando se &quot;ajusta&quot; a un conjunto de datos, se eval&amp;uacute;an todas las combinaciones posibles de valores de par&amp;aacute;metros y se conserva la mejor combinaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="45a8a9b77f54ed1a1a49e1eebdf058e73c1ad33a" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.model_selection.groupshufflesplit#sklearn.model_selection.GroupShuffleSplit&quot;&gt;&lt;code&gt;GroupShuffleSplit&lt;/code&gt;&lt;/a&gt; iterator behaves as a combination of &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt;&lt;code&gt;ShuffleSplit&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt;&lt;code&gt;LeavePGroupsOut&lt;/code&gt;&lt;/a&gt;, and generates a sequence of randomized partitions in which a subset of groups are held out for each split.</source>
          <target state="translated">El iterador &lt;a href=&quot;generated/sklearn.model_selection.groupshufflesplit#sklearn.model_selection.GroupShuffleSplit&quot;&gt; &lt;code&gt;GroupShuffleSplit&lt;/code&gt; se&lt;/a&gt; comporta como una combinaci&amp;oacute;n de &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt; &lt;code&gt;ShuffleSplit&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt; &lt;code&gt;LeavePGroupsOut&lt;/code&gt; &lt;/a&gt; , y genera una secuencia de particiones aleatorias en las que se mantiene un subconjunto de grupos para cada divisi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="ec15ef26f9a075815cd5139e68468c23802a4936" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt;&lt;code&gt;ShuffleSplit&lt;/code&gt;&lt;/a&gt; iterator will generate a user defined number of independent train / test dataset splits. Samples are first shuffled and then split into a pair of train and test sets.</source>
          <target state="translated">El iterador &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt; &lt;code&gt;ShuffleSplit&lt;/code&gt; &lt;/a&gt; generar&amp;aacute; un n&amp;uacute;mero definido por el usuario de divisiones de conjuntos de datos de prueba / tren independientes. Las muestras se mezclan primero y luego se dividen en un par de conjuntos de prueba y tren.</target>
        </trans-unit>
        <trans-unit id="9d19931407bdaf26c2091f0ff552c9705b61d84b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; (LOF) algorithm computes a score (called local outlier factor) reflecting the degree of abnormality of the observations. It measures the local density deviation of a given data point with respect to its neighbors. The idea is to detect the samples that have a substantially lower density than their neighbors.</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt; (LOF) algoritmo calcula una puntuaci&amp;oacute;n (llamada factor de valor extremo local) que refleja el grado de anormalidad de las observaciones. Mide la desviaci&amp;oacute;n de la densidad local de un punto de datos dado con respecto a sus vecinos. La idea es detectar las muestras que tienen una densidad sustancialmente menor que sus vecinas.</target>
        </trans-unit>
        <trans-unit id="7ee66eef276fb6deecd16d4b6508f3c8417f58ed" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt;&lt;code&gt;NearestCentroid&lt;/code&gt;&lt;/a&gt; classifier has a &lt;code&gt;shrink_threshold&lt;/code&gt; parameter, which implements the nearest shrunken centroid classifier. In effect, the value of each feature for each centroid is divided by the within-class variance of that feature. The feature values are then reduced by &lt;code&gt;shrink_threshold&lt;/code&gt;. Most notably, if a particular feature value crosses zero, it is set to zero. In effect, this removes the feature from affecting the classification. This is useful, for example, for removing noisy features.</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt; &lt;code&gt;NearestCentroid&lt;/code&gt; &lt;/a&gt; clasificador tiene una &lt;code&gt;shrink_threshold&lt;/code&gt; par&amp;aacute;metro, que implementa el encogida centroide clasificador m&amp;aacute;s cercano. En efecto, el valor de cada caracter&amp;iacute;stica para cada centroide se divide por la varianza dentro de la clase de esa caracter&amp;iacute;stica. Luego, los valores de las caracter&amp;iacute;sticas se reducen en &lt;code&gt;shrink_threshold&lt;/code&gt; . En particular, si el valor de una caracter&amp;iacute;stica particular cruza cero, se establece en cero. En efecto, esto evita que la caracter&amp;iacute;stica afecte a la clasificaci&amp;oacute;n. Esto es &amp;uacute;til, por ejemplo, para eliminar funciones ruidosas.</target>
        </trans-unit>
        <trans-unit id="80f0d0589fbf3ca83c23f0b6ee7bc1939986e528" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt;&lt;code&gt;NearestCentroid&lt;/code&gt;&lt;/a&gt; classifier is a simple algorithm that represents each class by the centroid of its members. In effect, this makes it similar to the label updating phase of the &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt;&lt;code&gt;sklearn.cluster.KMeans&lt;/code&gt;&lt;/a&gt; algorithm. It also has no parameters to choose, making it a good baseline classifier. It does, however, suffer on non-convex classes, as well as when classes have drastically different variances, as equal variance in all dimensions is assumed. See Linear Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;sklearn.discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) and Quadratic Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&quot;&gt;&lt;code&gt;sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) for more complex methods that do not make this assumption. Usage of the default &lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt;&lt;code&gt;NearestCentroid&lt;/code&gt;&lt;/a&gt; is simple:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43771e48f74cd166aa989881024956f81686fd39" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt;&lt;code&gt;NearestCentroid&lt;/code&gt;&lt;/a&gt; classifier is a simple algorithm that represents each class by the centroid of its members. In effect, this makes it similar to the label updating phase of the &lt;code&gt;sklearn.KMeans&lt;/code&gt; algorithm. It also has no parameters to choose, making it a good baseline classifier. It does, however, suffer on non-convex classes, as well as when classes have drastically different variances, as equal variance in all dimensions is assumed. See Linear Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;sklearn.discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) and Quadratic Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&quot;&gt;&lt;code&gt;sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) for more complex methods that do not make this assumption. Usage of the default &lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt;&lt;code&gt;NearestCentroid&lt;/code&gt;&lt;/a&gt; is simple:</source>
          <target state="translated">El clasificador &lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt; &lt;code&gt;NearestCentroid&lt;/code&gt; &lt;/a&gt; es un algoritmo simple que representa cada clase por el centroide de sus miembros. En efecto, esto lo hace similar a la fase de actualizaci&amp;oacute;n de &lt;code&gt;sklearn.KMeans&lt;/code&gt; algoritmo sklearn.KMeans . Tampoco tiene par&amp;aacute;metros para elegir, lo que lo convierte en un buen clasificador de l&amp;iacute;nea de base. Sin embargo, sufre en las clases no convexas, as&amp;iacute; como cuando las clases tienen variaciones dr&amp;aacute;sticamente diferentes, ya que se supone una variaci&amp;oacute;n igual en todas las dimensiones. Vea An&amp;aacute;lisis discriminante lineal ( &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt; &lt;code&gt;sklearn.discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt; ) y An&amp;aacute;lisis discriminante cuadr&amp;aacute;tico ( &lt;a href=&quot;generated/sklearn.discriminant_analysis.quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&quot;&gt; &lt;code&gt;sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt; ) para m&amp;eacute;todos m&amp;aacute;s complejos que no hacen esta suposici&amp;oacute;n. Uso del &lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt; &lt;code&gt;NearestCentroid&lt;/code&gt; &lt;/a&gt; predeterminado es simple:</target>
        </trans-unit>
        <trans-unit id="39bfe25102ea45948a285842eddb73a441e962a3" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; is built using a list of &lt;code&gt;(key, value)&lt;/code&gt; pairs, where the &lt;code&gt;key&lt;/code&gt; is a string containing the name you want to give this step and &lt;code&gt;value&lt;/code&gt; is an estimator object:</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;Pipeline&lt;/code&gt; &lt;/a&gt; se construye usando una lista de pares &lt;code&gt;(key, value)&lt;/code&gt; , donde la &lt;code&gt;key&lt;/code&gt; es una cadena que contiene el nombre que desea dar a este paso y el &lt;code&gt;value&lt;/code&gt; es un objeto estimador:</target>
        </trans-unit>
        <trans-unit id="c923ad3a865326ec6c72af48e5305bcc89674896" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.random_projection.gaussianrandomprojection#sklearn.random_projection.GaussianRandomProjection&quot;&gt;&lt;code&gt;sklearn.random_projection.GaussianRandomProjection&lt;/code&gt;&lt;/a&gt; reduces the dimensionality by projecting the original input space on a randomly generated matrix where components are drawn from the following distribution \(N(0, \frac{1}{n_{components}})\).</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.random_projection.gaussianrandomprojection#sklearn.random_projection.GaussianRandomProjection&quot;&gt; &lt;code&gt;sklearn.random_projection.GaussianRandomProjection&lt;/code&gt; &lt;/a&gt; reduce la dimensionalidad mediante la proyecci&amp;oacute;n del espacio original de entrada en una matriz generada de forma aleatoria, donde los componentes se han extra&amp;iacute;do de la distribuci&amp;oacute;n siguiente \ (N (0, \ frac {1} {n_ {componentes}}) \).</target>
        </trans-unit>
        <trans-unit id="bf402b0deb2f6872588357c0d1a4ee6663793993" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.random_projection.sparserandomprojection#sklearn.random_projection.SparseRandomProjection&quot;&gt;&lt;code&gt;sklearn.random_projection.SparseRandomProjection&lt;/code&gt;&lt;/a&gt; reduces the dimensionality by projecting the original input space using a sparse random matrix.</source>
          <target state="translated">El &lt;a href=&quot;generated/sklearn.random_projection.sparserandomprojection#sklearn.random_projection.SparseRandomProjection&quot;&gt; &lt;code&gt;sklearn.random_projection.SparseRandomProjection&lt;/code&gt; &lt;/a&gt; reduce la dimensionalidad mediante la proyecci&amp;oacute;n del espacio de entrada original usando una matriz aleatoria escasa.</target>
        </trans-unit>
        <trans-unit id="bfc6d74a43acae56b2f26724a2d5ae8338eaf262" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt;&lt;code&gt;export_graphviz&lt;/code&gt;&lt;/a&gt; exporter also supports a variety of aesthetic options, including coloring nodes by their class (or value for regression) and using explicit variable and class names if desired. Jupyter notebooks also render these plots inline automatically:</source>
          <target state="translated">El exportador &lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt; &lt;code&gt;export_graphviz&lt;/code&gt; &lt;/a&gt; tambi&amp;eacute;n admite una variedad de opciones est&amp;eacute;ticas, que incluyen colorear nodos por su clase (o valor para la regresi&amp;oacute;n) y usar nombres expl&amp;iacute;citos de variables y clases si se desea. Los cuadernos de Jupyter tambi&amp;eacute;n procesan estos gr&amp;aacute;ficos en l&amp;iacute;nea autom&amp;aacute;ticamente:</target>
        </trans-unit>
        <trans-unit id="7c175b2e5f3e3958b57eb43bc3177612df200e71" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;https://en.wikipedia.org/wiki/%20Johnson%E2%80%93Lindenstrauss_lemma&quot;&gt;Johnson-Lindenstrauss lemma&lt;/a&gt; states that any high dimensional dataset can be randomly projected into a lower dimensional Euclidean space while controlling the distortion in the pairwise distances.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a15d0b16a3ea1ca7d8280fbccb678c643c12770" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;https://en.wikipedia.org/wiki/F1_score&quot;&gt;F-measure&lt;/a&gt; (\(F_\beta\) and \(F_1\) measures) can be interpreted as a weighted harmonic mean of the precision and recall. A \(F_\beta\) measure reaches its best value at 1 and its worst score at 0. With \(\beta = 1\), \(F_\beta\) and \(F_1\) are equivalent, and the recall and the precision are equally important.</source>
          <target state="translated">La &lt;a href=&quot;https://en.wikipedia.org/wiki/F1_score&quot;&gt;medida F&lt;/a&gt; ( medidas \ (F_ \ beta \) y \ (F_1 \)) se puede interpretar como una media arm&amp;oacute;nica ponderada de la precisi&amp;oacute;n y la recuperaci&amp;oacute;n. Una medida \ (F_ \ beta \) alcanza su mejor valor en 1 y su peor puntuaci&amp;oacute;n en 0. Con \ (\ beta = 1 \), \ (F_ \ beta \) y \ (F_1 \) son equivalentes, y el el recuerdo y la precisi&amp;oacute;n son igualmente importantes.</target>
        </trans-unit>
        <trans-unit id="88cf2fa597f50207550c56a5d725499fc42ad462" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma&quot;&gt;Johnson-Lindenstrauss lemma&lt;/a&gt; states that any high dimensional dataset can be randomly projected into a lower dimensional Euclidean space while controlling the distortion in the pairwise distances.</source>
          <target state="translated">El &lt;a href=&quot;https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma&quot;&gt;lema de Johnson-Lindenstrauss&lt;/a&gt; establece que cualquier conjunto de datos de alta dimensi&amp;oacute;n puede proyectarse aleatoriamente en un espacio euclidiano de menor dimensi&amp;oacute;n mientras se controla la distorsi&amp;oacute;n en las distancias por pares.</target>
        </trans-unit>
        <trans-unit id="6b941988cfc8d08eb5daa76d4a5974b4197ff783" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-estimator&quot;&gt;estimator&lt;/a&gt; is required to be a fitted estimator. &lt;code&gt;X&lt;/code&gt; can be the data set used to train the estimator or a hold-out set. The permutation importance of a feature is calculated as follows. First, a baseline metric, defined by &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-scoring&quot;&gt;scoring&lt;/a&gt;, is evaluated on a (potentially different) dataset defined by the &lt;code&gt;X&lt;/code&gt;. Next, a feature column from the validation set is permuted and the metric is evaluated again. The permutation importance is defined to be the difference between the baseline metric and metric from permutating the feature column.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96678c00449216bcbe65a0961a8b25b8baf7a396" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; class can adapt its number of mixture components automatically. The parameter &lt;code&gt;weight_concentration_prior&lt;/code&gt; has a direct link with the resulting number of components with non-zero weights. Specifying a low value for the concentration prior will make the model put most of the weight on few components set the remaining components weights very close to zero. High values of the concentration prior will allow a larger number of components to be active in the mixture.</source>
          <target state="translated">La clase &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; puede adaptar autom&amp;aacute;ticamente su n&amp;uacute;mero de componentes de mezcla. El par&amp;aacute;metro &lt;code&gt;weight_concentration_prior&lt;/code&gt; tiene un v&amp;iacute;nculo directo con el n&amp;uacute;mero resultante de componentes con pesos distintos de cero. Especificar un valor bajo para la concentraci&amp;oacute;n anterior har&amp;aacute; que el modelo coloque la mayor parte del peso en algunos componentes y establezca los pesos de los componentes restantes muy cerca de cero. Los valores altos de la concentraci&amp;oacute;n anterior permitir&amp;aacute;n que un mayor n&amp;uacute;mero de componentes est&amp;eacute;n activos en la mezcla.</target>
        </trans-unit>
        <trans-unit id="c17c439e95320993d0276d174b035cd14b7ce3b3" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;C&lt;/code&gt; parameter controls the amount of regularization in the &lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; object: a large value for &lt;code&gt;C&lt;/code&gt; results in less regularization. &lt;code&gt;penalty=&quot;l2&quot;&lt;/code&gt; gives &lt;a href=&quot;#shrinkage&quot;&gt;Shrinkage&lt;/a&gt; (i.e. non-sparse coefficients), while &lt;code&gt;penalty=&quot;l1&quot;&lt;/code&gt; gives &lt;a href=&quot;#sparsity&quot;&gt;Sparsity&lt;/a&gt;.</source>
          <target state="translated">El par&amp;aacute;metro &lt;code&gt;C&lt;/code&gt; controla la cantidad de regularizaci&amp;oacute;n en el objeto &lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt; : un valor grande para &lt;code&gt;C&lt;/code&gt; resulta en menos regularizaci&amp;oacute;n. &lt;code&gt;penalty=&quot;l2&quot;&lt;/code&gt; da &lt;a href=&quot;#shrinkage&quot;&gt;contracci&amp;oacute;n&lt;/a&gt; (es decir, coeficientes no dispersos), mientras que &lt;code&gt;penalty=&quot;l1&quot;&lt;/code&gt; da &lt;a href=&quot;#sparsity&quot;&gt;escasez&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="9164d9a9144eaecf5fe284f2e40277e82f0b8068" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;C&lt;/code&gt; parameter trades off correct classification of training examples against maximization of the decision function&amp;rsquo;s margin. For larger values of &lt;code&gt;C&lt;/code&gt;, a smaller margin will be accepted if the decision function is better at classifying all training points correctly. A lower &lt;code&gt;C&lt;/code&gt; will encourage a larger margin, therefore a simpler decision function, at the cost of training accuracy. In other words``C`` behaves as a regularization parameter in the SVM.</source>
          <target state="translated">El par&amp;aacute;metro &lt;code&gt;C&lt;/code&gt; compensa la clasificaci&amp;oacute;n correcta de los ejemplos de entrenamiento con la maximizaci&amp;oacute;n del margen de la funci&amp;oacute;n de decisi&amp;oacute;n. Para valores mayores de &lt;code&gt;C&lt;/code&gt; , se aceptar&amp;aacute; un margen menor si la funci&amp;oacute;n de decisi&amp;oacute;n es mejor para clasificar correctamente todos los puntos de entrenamiento. Una &lt;code&gt;C&lt;/code&gt; m&amp;aacute;s baja fomentar&amp;aacute; un margen mayor, por lo tanto una funci&amp;oacute;n de decisi&amp;oacute;n m&amp;aacute;s simple, a costa de la precisi&amp;oacute;n del entrenamiento. En otras palabras, `` C '' se comporta como un par&amp;aacute;metro de regularizaci&amp;oacute;n en la SVM.</target>
        </trans-unit>
        <trans-unit id="9aa2de3f6ced8022ed53d959fe2e18d24e70ecf1" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;DESCR&lt;/code&gt; contains a free-text description of the data, while &lt;code&gt;details&lt;/code&gt; contains a dictionary of meta-data stored by openml, like the dataset id. For more details, see the &lt;a href=&quot;https://docs.openml.org/#data&quot;&gt;OpenML documentation&lt;/a&gt; The &lt;code&gt;data_id&lt;/code&gt; of the mice protein dataset is 40966, and you can use this (or the name) to get more information on the dataset on the openml website:</source>
          <target state="translated">El &lt;code&gt;DESCR&lt;/code&gt; contiene una descripci&amp;oacute;n de texto libre de los datos, mientras que los &lt;code&gt;details&lt;/code&gt; contienen un diccionario de metadatos almacenados por openml, como la identificaci&amp;oacute;n del conjunto de datos. Para obtener m&amp;aacute;s detalles, consulte la &lt;a href=&quot;https://docs.openml.org/#data&quot;&gt;documentaci&amp;oacute;n de OpenML.&lt;/a&gt; El &lt;code&gt;data_id&lt;/code&gt; del conjunto de datos de prote&amp;iacute;nas de ratones es 40966, y puede usar esto (o el nombre) para obtener m&amp;aacute;s informaci&amp;oacute;n sobre el conjunto de datos en el sitio web de openml:</target>
        </trans-unit>
        <trans-unit id="388bd8e84c98bb0ce4ff6564cc35fb4e0e8f41db" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; estimator has the most flexibility and is able to predict higher expected values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="81a0037eca65e4ed69e2a49ca4871b0ce138bc10" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Normalizer&lt;/code&gt; rescales the vector for each sample to have unit norm, independently of the distribution of the samples. It can be seen on both figures below where all samples are mapped onto the unit circle. In our example the two selected features have only positive values; therefore the transformed data only lie in the positive quadrant. This would not be the case if some original features had a mix of positive and negative values.</source>
          <target state="translated">El &lt;code&gt;Normalizer&lt;/code&gt; cambia la escala del vector para que cada muestra tenga una norma unitaria, independientemente de la distribuci&amp;oacute;n de las muestras. Se puede ver en las dos figuras siguientes, donde todas las muestras est&amp;aacute;n mapeadas en el c&amp;iacute;rculo unitario. En nuestro ejemplo, las dos caracter&amp;iacute;sticas seleccionadas solo tienen valores positivos; por lo tanto, los datos transformados solo se encuentran en el cuadrante positivo. Este no ser&amp;iacute;a el caso si algunas caracter&amp;iacute;sticas originales tuvieran una combinaci&amp;oacute;n de valores positivos y negativos.</target>
        </trans-unit>
        <trans-unit id="c108938c180fba7834742cb26f12054acc7a2184" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;PCA&lt;/code&gt; fitting is only computed at the evaluation of the first configuration of the &lt;code&gt;C&lt;/code&gt; parameter of the &lt;code&gt;LinearSVC&lt;/code&gt; classifier. The other configurations of &lt;code&gt;C&lt;/code&gt; will trigger the loading of the cached &lt;code&gt;PCA&lt;/code&gt; estimator data, leading to save processing time. Therefore, the use of caching the pipeline using &lt;code&gt;memory&lt;/code&gt; is highly beneficial when fitting a transformer is costly.</source>
          <target state="translated">El ajuste de &lt;code&gt;PCA&lt;/code&gt; solo se calcula en la evaluaci&amp;oacute;n de la primera configuraci&amp;oacute;n del par&amp;aacute;metro &lt;code&gt;C&lt;/code&gt; del clasificador &lt;code&gt;LinearSVC&lt;/code&gt; . Las otras configuraciones de &lt;code&gt;C&lt;/code&gt; activar&amp;aacute;n la carga de los datos del estimador de &lt;code&gt;PCA&lt;/code&gt; almacenados en cach&amp;eacute; , lo que permitir&amp;aacute; ahorrar tiempo de procesamiento. Por lo tanto, el uso de almacenamiento en cach&amp;eacute; de la tuber&amp;iacute;a utilizando &lt;code&gt;memory&lt;/code&gt; es muy beneficioso cuando la instalaci&amp;oacute;n de un transformador es costosa.</target>
        </trans-unit>
        <trans-unit id="c287f0a262d74ac1807987cdaae52227ef4012e1" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Product&lt;/code&gt; kernel takes two kernels \(k_1\) and \(k_2\) and combines them via</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a3cb6faf35a31966ca4f91d6d7c341a997f291b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;RandomForestClassifier&lt;/code&gt; is trained using &lt;em&gt;bootstrap aggregation&lt;/em&gt;, where each new tree is fit from a bootstrap sample of the training observations \(z_i = (x_i, y_i)\). The &lt;em&gt;out-of-bag&lt;/em&gt; (OOB) error is the average error for each \(z_i\) calculated using predictions from the trees that do not contain \(z_i\) in their respective bootstrap sample. This allows the &lt;code&gt;RandomForestClassifier&lt;/code&gt; to be fit and validated whilst being trained &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17baab07595bc9a1b9010bf52fc5ebb7c1555943" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;RandomForestClassifier&lt;/code&gt; is trained using &lt;em&gt;bootstrap aggregation&lt;/em&gt;, where each new tree is fit from a bootstrap sample of the training observations \(z_i = (x_i, y_i)\). The &lt;em&gt;out-of-bag&lt;/em&gt; (OOB) error is the average error for each \(z_i\) calculated using predictions from the trees that do not contain \(z_i\) in their respective bootstrap sample. This allows the &lt;code&gt;RandomForestClassifier&lt;/code&gt; to be fit and validated whilst being trained &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="translated">El &lt;code&gt;RandomForestClassifier&lt;/code&gt; se entrena mediante la &lt;em&gt;agregaci&amp;oacute;n de arranque&lt;/em&gt; , donde cada nuevo &amp;aacute;rbol se ajusta a partir de una muestra de arranque de las observaciones de entrenamiento \ (z_i = (x_i, y_i) \). El error &lt;em&gt;out-of-bag&lt;/em&gt; (OOB) es el error promedio para cada \ (z_i \) calculado usando predicciones de los &amp;aacute;rboles que no contienen \ (z_i \) en su respectiva muestra de arranque. Esto permite que el &lt;code&gt;RandomForestClassifier&lt;/code&gt; se ajuste y valide mientras se entrena &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="b88cefdaf9f96b3cdafb06bfae8af6e9f9c7d591" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Ridge&lt;/code&gt; regression model can predict very low expected frequencies that do not match the data. It can therefore severly under-estimate the risk for some policyholders.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2fcb1f40315317ee430343ccf6429ac412e1cf20" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;SpectralBiclustering&lt;/code&gt; algorithm assumes that the input data matrix has a hidden checkerboard structure. The rows and columns of a matrix with this structure may be partitioned so that the entries of any bicluster in the Cartesian product of row clusters and column clusters are approximately constant. For instance, if there are two row partitions and three column partitions, each row will belong to three biclusters, and each column will belong to two biclusters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68d62b9583d10d4cdba8ebe8ca76f4a0cc3bafcf" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;SpectralCoclustering&lt;/code&gt; algorithm finds biclusters with values higher than those in the corresponding other rows and columns. Each row and each column belongs to exactly one bicluster, so rearranging the rows and columns to make partitions contiguous reveals these high values along the diagonal:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2977d18fbb46e84c7bb310b8e5bfcc96a3f259f" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Sum&lt;/code&gt; kernel takes two kernels \(k_1\) and \(k_2\) and combines them via</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="093b9af7ff877738a1c191bf8fe58f666ce1b93c" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;VotingClassifier&lt;/code&gt; can also be used together with &lt;code&gt;GridSearch&lt;/code&gt; in order to tune the hyperparameters of the individual estimators:</source>
          <target state="translated">El &lt;code&gt;VotingClassifier&lt;/code&gt; tambi&amp;eacute;n se puede utilizar junto con &lt;code&gt;GridSearch&lt;/code&gt; para ajustar los hiperpar&amp;aacute;metros de los estimadores individuales:</target>
        </trans-unit>
        <trans-unit id="a92f24d7703ca3728952e82f17755a0b7604fe2c" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;alpha&lt;/code&gt; parameter controls the degree of sparsity of the coefficients estimated.</source>
          <target state="translated">El par&amp;aacute;metro &lt;code&gt;alpha&lt;/code&gt; controla el grado de dispersi&amp;oacute;n de los coeficientes estimados.</target>
        </trans-unit>
        <trans-unit id="315ca80415fed5e99f9417365418d048de6cb5f9" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;alpha&lt;/code&gt; parameter controls the degree of sparsity of the estimated coefficients.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d22b7c9a5ce685adf8551f77a733c13cab8fe2d4" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;best_estimator_&lt;/code&gt;, &lt;code&gt;best_index_&lt;/code&gt;, &lt;code&gt;best_score_&lt;/code&gt; and &lt;code&gt;best_params_&lt;/code&gt; correspond to the scorer (key) that is set to the &lt;code&gt;refit&lt;/code&gt; attribute.</source>
          <target state="translated">El &lt;code&gt;best_estimator_&lt;/code&gt; , &lt;code&gt;best_index_&lt;/code&gt; , &lt;code&gt;best_score_&lt;/code&gt; y &lt;code&gt;best_params_&lt;/code&gt; corresponden a la (clave) anotador que se establece en el &lt;code&gt;refit&lt;/code&gt; atributo.</target>
        </trans-unit>
        <trans-unit id="ea04fcbf02a8de4070a990d8e4f932cdf0278b0d" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;beta&lt;/code&gt; parameter determines the weight of precision in the combined score. &lt;code&gt;beta &amp;lt; 1&lt;/code&gt; lends more weight to precision, while &lt;code&gt;beta &amp;gt; 1&lt;/code&gt; favors recall (&lt;code&gt;beta -&amp;gt; 0&lt;/code&gt; considers only precision, &lt;code&gt;beta -&amp;gt; inf&lt;/code&gt; only recall).</source>
          <target state="translated">El par&amp;aacute;metro &lt;code&gt;beta&lt;/code&gt; determina el peso de la precisi&amp;oacute;n en la puntuaci&amp;oacute;n combinada. &lt;code&gt;beta &amp;lt; 1&lt;/code&gt; da m&amp;aacute;s peso a la precisi&amp;oacute;n, mientras que &lt;code&gt;beta &amp;gt; 1&lt;/code&gt; favorece la recuperaci&amp;oacute;n ( &lt;code&gt;beta -&amp;gt; 0&lt;/code&gt; solo considera precisi&amp;oacute;n, &lt;code&gt;beta -&amp;gt; inf&lt;/code&gt; solo recuperaci&amp;oacute;n).</target>
        </trans-unit>
        <trans-unit id="baaa5bd4c537184b8165bf82e50573a6954bd1a3" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;beta&lt;/code&gt; parameter determines the weight of recall in the combined score. &lt;code&gt;beta &amp;lt; 1&lt;/code&gt; lends more weight to precision, while &lt;code&gt;beta &amp;gt; 1&lt;/code&gt; favors recall (&lt;code&gt;beta -&amp;gt; 0&lt;/code&gt; considers only precision, &lt;code&gt;beta -&amp;gt; +inf&lt;/code&gt; only recall).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1cbc8f71751f51b8523a564fa7c56816a950df46" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;clf&lt;/code&gt; (for classifier) estimator instance is first fitted to the model; that is, it must &lt;em&gt;learn&lt;/em&gt; from the model. This is done by passing our training set to the &lt;code&gt;fit&lt;/code&gt; method. For the training set, we&amp;rsquo;ll use all the images from our dataset, except for the last image, which we&amp;rsquo;ll reserve for our predicting. We select the training set with the &lt;code&gt;[:-1]&lt;/code&gt; Python syntax, which produces a new array that contains all but the last item from &lt;code&gt;digits.data&lt;/code&gt;:</source>
          <target state="translated">La instancia del estimador &lt;code&gt;clf&lt;/code&gt; (para clasificador) se ajusta primero al modelo; es decir, debe &lt;em&gt;aprender&lt;/em&gt; del modelo. Esto se hace pasando nuestro conjunto de entrenamiento al m&amp;eacute;todo de &lt;code&gt;fit&lt;/code&gt; . Para el conjunto de entrenamiento, usaremos todas las im&amp;aacute;genes de nuestro conjunto de datos, excepto la &amp;uacute;ltima imagen, que reservaremos para nuestra predicci&amp;oacute;n. Seleccionamos el conjunto de entrenamiento con la sintaxis de Python &lt;code&gt;[:-1]&lt;/code&gt; , que produce una nueva matriz que contiene todo menos el &amp;uacute;ltimo elemento de &lt;code&gt;digits.data&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="0655de3e2b717fc73c590188fdaa9881c37414a7" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;cross_validate&lt;/code&gt; function differs from &lt;code&gt;cross_val_score&lt;/code&gt; in two ways -</source>
          <target state="translated">La funci&amp;oacute;n &lt;code&gt;cross_validate&lt;/code&gt; se diferencia de &lt;code&gt;cross_val_score&lt;/code&gt; en dos formas:</target>
        </trans-unit>
        <trans-unit id="f3aad90428722c87b3422d97c1856aa8204966ed" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;cv_results_&lt;/code&gt; parameter can be easily imported into pandas as a &lt;code&gt;DataFrame&lt;/code&gt; for further inspection.</source>
          <target state="translated">El par&amp;aacute;metro &lt;code&gt;cv_results_&lt;/code&gt; se puede importar f&amp;aacute;cilmente a pandas como un &lt;code&gt;DataFrame&lt;/code&gt; para una inspecci&amp;oacute;n m&amp;aacute;s detallada .</target>
        </trans-unit>
        <trans-unit id="6d0144f231c5dfa868fda545c176e4a6eca95147" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;data_id&lt;/code&gt; also uniquely identifies a dataset from OpenML:</source>
          <target state="translated">El &lt;code&gt;data_id&lt;/code&gt; tambi&amp;eacute;n identifica de forma &amp;uacute;nica un conjunto de datos de OpenML:</target>
        </trans-unit>
        <trans-unit id="7bfd5d978dedbc7159d3a401f357dd25ad25428a" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;decision_function&lt;/code&gt; method is also defined from the scoring function, in such a way that negative values are outliers and non-negative ones are inliers:</source>
          <target state="translated">El m&amp;eacute;todo &lt;code&gt;decision_function&lt;/code&gt; tambi&amp;eacute;n se define a partir de la funci&amp;oacute;n de puntuaci&amp;oacute;n, de tal manera que los valores negativos son valores at&amp;iacute;picos y los no negativos son valores inliers:</target>
        </trans-unit>
        <trans-unit id="bc22b4069c85e3e1ecbf3c942877625aea87d185" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;decision_function&lt;/code&gt; method of &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt;&lt;code&gt;NuSVC&lt;/code&gt;&lt;/a&gt; gives per-class scores for each sample (or a single score per sample in the binary case). When the constructor option &lt;code&gt;probability&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, class membership probability estimates (from the methods &lt;code&gt;predict_proba&lt;/code&gt; and &lt;code&gt;predict_log_proba&lt;/code&gt;) are enabled. In the binary case, the probabilities are calibrated using Platt scaling &lt;a href=&quot;#id11&quot; id=&quot;id2&quot;&gt;9&lt;/a&gt;: logistic regression on the SVM&amp;rsquo;s scores, fit by an additional cross-validation on the training data. In the multiclass case, this is extended as per &lt;a href=&quot;#id12&quot; id=&quot;id3&quot;&gt;10&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62eacbcbc4132ef1f5317a0a939d640165e31df3" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;decision_function&lt;/code&gt; method of &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt;&lt;code&gt;NuSVC&lt;/code&gt;&lt;/a&gt; gives per-class scores for each sample (or a single score per sample in the binary case). When the constructor option &lt;code&gt;probability&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, class membership probability estimates (from the methods &lt;code&gt;predict_proba&lt;/code&gt; and &lt;code&gt;predict_log_proba&lt;/code&gt;) are enabled. In the binary case, the probabilities are calibrated using Platt scaling: logistic regression on the SVM&amp;rsquo;s scores, fit by an additional cross-validation on the training data. In the multiclass case, this is extended as per Wu et al. (2004).</source>
          <target state="translated">El m&amp;eacute;todo &lt;code&gt;decision_function&lt;/code&gt; de &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt; &lt;code&gt;NuSVC&lt;/code&gt; &lt;/a&gt; da puntuaciones por clase para cada muestra (o una &amp;uacute;nica puntuaci&amp;oacute;n por muestra en el caso binario). Cuando la &lt;code&gt;probability&lt;/code&gt; opci&amp;oacute;n del constructor se establece en &lt;code&gt;True&lt;/code&gt; , las estimaciones de probabilidad de pertenencia a la clase (de los m&amp;eacute;todos &lt;code&gt;predict_proba&lt;/code&gt; y &lt;code&gt;predict_log_proba&lt;/code&gt; ) est&amp;aacute;n habilitadas. En el caso binario, las probabilidades se calibran usando la escala de Platt: regresi&amp;oacute;n log&amp;iacute;stica en los puntajes de la SVM, ajustada por una validaci&amp;oacute;n cruzada adicional en los datos de entrenamiento. En el caso multiclase, esto se ampl&amp;iacute;a seg&amp;uacute;n Wu et al. (2004).</target>
        </trans-unit>
        <trans-unit id="cacd73f2ee1bdb21ccf547bfa27f031af8d1c84f" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;estimators&lt;/code&gt; parameter corresponds to the list of the estimators which are stacked together in parallel on the input data. It should be given as a list of names and estimators:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="912eed5f20931cd928be8a8b3c3891f77622f73b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;features&lt;/code&gt; parameter can be set to &lt;code&gt;'all'&lt;/code&gt; to return all features whether or not they contain missing values:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac9899847d23144b2277382b5ec5bf6360733941" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;features&lt;/code&gt; parameter can be set to &lt;code&gt;'all'&lt;/code&gt; to returned all features whether or not they contain missing values:</source>
          <target state="translated">El par&amp;aacute;metro de &lt;code&gt;features&lt;/code&gt; se puede establecer en &lt;code&gt;'all'&lt;/code&gt; para devolver todas las caracter&amp;iacute;sticas, ya sea que contengan valores faltantes o no:</target>
        </trans-unit>
        <trans-unit id="0e29ac108f496200ac17f2eb1912fca379623586" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;features&lt;/code&gt; parameter is used to choose the features for which the mask is constructed. By default, it is &lt;code&gt;'missing-only'&lt;/code&gt; which returns the imputer mask of the features containing missing values at &lt;code&gt;fit&lt;/code&gt; time:</source>
          <target state="translated">El par&amp;aacute;metro de &lt;code&gt;features&lt;/code&gt; se utiliza para elegir las caracter&amp;iacute;sticas para las que se construye la m&amp;aacute;scara. De forma predeterminada, es &lt;code&gt;'missing-only'&lt;/code&gt; que devuelve la m&amp;aacute;scara de imputador de las caracter&amp;iacute;sticas que contienen valores faltantes en el momento de &lt;code&gt;fit&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="9c67ef88019a1b7e1168b9363c0a3a8856eb06c6" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;final_estimator&lt;/code&gt; will use the predictions of the &lt;code&gt;estimators&lt;/code&gt; as input. It needs to be a classifier or a regressor when using &lt;a href=&quot;generated/sklearn.ensemble.stackingclassifier#sklearn.ensemble.StackingClassifier&quot;&gt;&lt;code&gt;StackingClassifier&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.ensemble.stackingregressor#sklearn.ensemble.StackingRegressor&quot;&gt;&lt;code&gt;StackingRegressor&lt;/code&gt;&lt;/a&gt;, respectively:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b06298ca8347e48ebdf3df08a4c5d05e9d2dcbb" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;fit&lt;/code&gt; function takes two arguments: &lt;code&gt;n_components&lt;/code&gt;, which is the target dimensionality of the feature transform, and &lt;code&gt;gamma&lt;/code&gt;, the parameter of the RBF-kernel. A higher &lt;code&gt;n_components&lt;/code&gt; will result in a better approximation of the kernel and will yield results more similar to those produced by a kernel SVM. Note that &amp;ldquo;fitting&amp;rdquo; the feature function does not actually depend on the data given to the &lt;code&gt;fit&lt;/code&gt; function. Only the dimensionality of the data is used. Details on the method can be found in &lt;a href=&quot;#rr2007&quot; id=&quot;id3&quot;&gt;[RR2007]&lt;/a&gt;.</source>
          <target state="translated">La funci&amp;oacute;n de &lt;code&gt;fit&lt;/code&gt; toma dos argumentos: &lt;code&gt;n_components&lt;/code&gt; , que es la dimensionalidad objetivo de la transformaci&amp;oacute;n de caracter&amp;iacute;sticas, y &lt;code&gt;gamma&lt;/code&gt; , el par&amp;aacute;metro del kernel RBF. Un &lt;code&gt;n_components&lt;/code&gt; m&amp;aacute;s alto dar&amp;aacute; como resultado una mejor aproximaci&amp;oacute;n del kernel y producir&amp;aacute; resultados m&amp;aacute;s similares a los producidos por una SVM del kernel. Tenga en cuenta que &quot;ajustar&quot; la funci&amp;oacute;n de caracter&amp;iacute;stica no depende en realidad de los datos proporcionados a la funci&amp;oacute;n de &lt;code&gt;fit&lt;/code&gt; . Solo se utiliza la dimensionalidad de los datos. Los detalles sobre el m&amp;eacute;todo se pueden encontrar en &lt;a href=&quot;#rr2007&quot; id=&quot;id3&quot;&gt;[RR2007]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="24f4fe27df1296a0eb0115a0bb0e2832f2225923" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;id&lt;/code&gt; of each check is set to be a pprint version of the estimator and the name of the check with its keyword arguments. This allows to use &lt;code&gt;pytest -k&lt;/code&gt; to specify which tests to run:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8f8ea902ec10f43c9cca575477617a393bf1406" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;increasing&lt;/code&gt; parameter changes the constraint to \(\hat{y}_i \ge \hat{y}_j\) whenever \(X_i \le X_j\). Setting it to &amp;lsquo;auto&amp;rsquo; will automatically choose the constraint based on &lt;a href=&quot;https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient&quot;&gt;Spearman&amp;rsquo;s rank correlation coefficient&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f460a2e1f3d0337b4c58660913081d08e87c0f52" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;init&lt;/code&gt; attribute determines the initialization method applied, which has a great impact on the performance of the method. &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;NMF&lt;/code&gt;&lt;/a&gt; implements the method Nonnegative Double Singular Value Decomposition. NNDSVD &lt;a href=&quot;#id13&quot; id=&quot;id7&quot;&gt;4&lt;/a&gt; is based on two SVD processes, one approximating the data matrix, the other approximating positive sections of the resulting partial SVD factors utilizing an algebraic property of unit rank matrices. The basic NNDSVD algorithm is better fit for sparse factorization. Its variants NNDSVDa (in which all zeros are set equal to the mean of all elements of the data), and NNDSVDar (in which the zeros are set to random perturbations less than the mean of the data divided by 100) are recommended in the dense case.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="759d68cbc1b0e0c960b6f5234a5fe3b985174684" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;init&lt;/code&gt; attribute determines the initialization method applied, which has a great impact on the performance of the method. &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;NMF&lt;/code&gt;&lt;/a&gt; implements the method Nonnegative Double Singular Value Decomposition. NNDSVD &lt;a href=&quot;#id13&quot; id=&quot;id7&quot;&gt;[4]&lt;/a&gt; is based on two SVD processes, one approximating the data matrix, the other approximating positive sections of the resulting partial SVD factors utilizing an algebraic property of unit rank matrices. The basic NNDSVD algorithm is better fit for sparse factorization. Its variants NNDSVDa (in which all zeros are set equal to the mean of all elements of the data), and NNDSVDar (in which the zeros are set to random perturbations less than the mean of the data divided by 100) are recommended in the dense case.</source>
          <target state="translated">El atributo &lt;code&gt;init&lt;/code&gt; determina el m&amp;eacute;todo de inicializaci&amp;oacute;n aplicado, lo que tiene un gran impacto en el rendimiento del m&amp;eacute;todo. &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt; &lt;code&gt;NMF&lt;/code&gt; &lt;/a&gt; implementa el m&amp;eacute;todo de descomposici&amp;oacute;n de valores singulares dobles no negativos. NNDSVD &lt;a href=&quot;#id13&quot; id=&quot;id7&quot;&gt;[4]&lt;/a&gt; se basa en dos procesos de SVD, uno que se aproxima a la matriz de datos y el otro que se aproxima a las secciones positivas de los factores de SVD parciales resultantes, utilizando una propiedad algebraica de las matrices de rango unitario. El algoritmo b&amp;aacute;sico NNDSVD se adapta mejor a la factorizaci&amp;oacute;n dispersa. Sus variantes NNDSVDa (en la que todos los ceros se igualan a la media de todos los elementos de los datos) y NNDSVDar (en la que los ceros se establecen en perturbaciones aleatorias menores que la media de los datos dividida por 100) se recomiendan en el denso caso.</target>
        </trans-unit>
        <trans-unit id="dae4c344a8a96bf6754b4ff3002f4e9350562dbc" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;intercept_&lt;/code&gt; attribute holds the intercept (aka offset or bias):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5aaf2ff68858d9c24eece58235794e4a322e1ce9" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;intercept_&lt;/code&gt; member is not converted.</source>
          <target state="translated">El miembro &lt;code&gt;intercept_&lt;/code&gt; no se convierte.</target>
        </trans-unit>
        <trans-unit id="0e6b2b935d052640da205c359a0d82666ebb9942" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;is_data_valid&lt;/code&gt; and &lt;code&gt;is_model_valid&lt;/code&gt; functions allow to identify and reject degenerate combinations of random sub-samples. If the estimated model is not needed for identifying degenerate cases, &lt;code&gt;is_data_valid&lt;/code&gt; should be used as it is called prior to fitting the model and thus leading to better computational performance.</source>
          <target state="translated">Las funciones &lt;code&gt;is_data_valid&lt;/code&gt; e &lt;code&gt;is_model_valid&lt;/code&gt; permiten identificar y rechazar combinaciones degeneradas de submuestras aleatorias. Si el modelo estimado no es necesario para identificar casos degenerados, se debe usar &lt;code&gt;is_data_valid&lt;/code&gt; como se llama antes de ajustar el modelo y, por lo tanto, conducir a un mejor rendimiento computacional.</target>
        </trans-unit>
        <trans-unit id="dee80932cbc9425c512fa33535be444f8c4ddfa6" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;l2_regularization&lt;/code&gt; parameter is a regularizer on the loss function and corresponds to \(\lambda\) in equation (2) of &lt;a href=&quot;#xgboost&quot; id=&quot;id26&quot;&gt;[XGBoost]&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a1aa8bc8d7f393abce9beb6161257c50a1665624" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;len(features)&lt;/code&gt; plots are arranged in a grid with &lt;code&gt;n_cols&lt;/code&gt; columns. Two-way partial dependence plots are plotted as contour plots.</source>
          <target state="translated">Las gr&amp;aacute;ficas de &lt;code&gt;len(features)&lt;/code&gt; est&amp;aacute;n organizadas en una cuadr&amp;iacute;cula con columnas &lt;code&gt;n_cols&lt;/code&gt; . Las gr&amp;aacute;ficas de dependencia parcial bidireccional se trazan como gr&amp;aacute;ficas de contorno.</target>
        </trans-unit>
        <trans-unit id="da451cbcbf87abb0e9a3cde3e39db4fedec8991d" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;len(features)&lt;/code&gt; plots are arranged in a grid with &lt;code&gt;n_cols&lt;/code&gt; columns. Two-way partial dependence plots are plotted as contour plots. The deciles of the feature values will be shown with tick marks on the x-axes for one-way plots, and on both axes for two-way plots.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d39915194cee376ca662b61de9924274942d60a" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;make_columntransformer&lt;/code&gt; function is available to more easily create a &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; object. Specifically, the names will be given automatically. The equivalent for the above example would be:</source>
          <target state="translated">La funci&amp;oacute;n &lt;code&gt;make_columntransformer&lt;/code&gt; est&amp;aacute; disponible para crear m&amp;aacute;s f&amp;aacute;cilmente un objeto &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;ColumnTransformer&lt;/code&gt; &lt;/a&gt; . Espec&amp;iacute;ficamente, los nombres se dar&amp;aacute;n autom&amp;aacute;ticamente. El equivalente del ejemplo anterior ser&amp;iacute;a:</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
