<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="es" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="b70db829e86f8b0b87ee4b4ea9165e2800cb135e" translate="yes" xml:space="preserve">
          <source>In particular the interrogative form &amp;ldquo;Is this&amp;rdquo; is only present in the last document:</source>
          <target state="translated">En particular, la forma interrogativa &quot;Es esto&quot; solo est&amp;aacute; presente en el &amp;uacute;ltimo documento:</target>
        </trans-unit>
        <trans-unit id="48a72aaef5f57348c3c02ddfbd84f34663c56133" translate="yes" xml:space="preserve">
          <source>In particular we name:</source>
          <target state="translated">En particular,nombramos:</target>
        </trans-unit>
        <trans-unit id="32bae48b70c29501503578b88b61dfab45b0637c" translate="yes" xml:space="preserve">
          <source>In particular, \(\nu = 3/2\):</source>
          <target state="translated">En particular,\ ~-(\ ~ \ ~ nu=3/2\ ~ -):</target>
        </trans-unit>
        <trans-unit id="ff34c019cd4067dd0b8a1a6d1536db31ff351b58" translate="yes" xml:space="preserve">
          <source>In particular, truncated SVD works on term count/tf-idf matrices as returned by the vectorizers in sklearn.feature_extraction.text. In that context, it is known as latent semantic analysis (LSA).</source>
          <target state="translated">En particular,la SVD truncada funciona con matrices de conteo de términos/tf-idf como las devuelven los vectorizadores en sklearn.feature_extraction.text.En ese contexto,se conoce como análisis semántico latente (LSA).</target>
        </trans-unit>
        <trans-unit id="74d856933005d819af2a4b7d2ce24317b5186453" translate="yes" xml:space="preserve">
          <source>In practice Spectral Clustering is very useful when the structure of the individual clusters is highly non-convex or more generally when a measure of the center and spread of the cluster is not a suitable description of the complete cluster. For instance when clusters are nested circles on the 2D plan.</source>
          <target state="translated">En la práctica,la agrupación espectral es muy útil cuando la estructura de los cúmulos individuales es muy poco convexa o,más en general,cuando una medida del centro y la extensión del cúmulo no es una descripción adecuada del cúmulo completo.Por ejemplo cuando los cúmulos son círculos anidados en el plano 2D.</target>
        </trans-unit>
        <trans-unit id="5662b7bb73c6d21ae298513382716bd3fe526ba2" translate="yes" xml:space="preserve">
          <source>In practice the local density is obtained from the k-nearest neighbors. The LOF score of an observation is equal to the ratio of the average local density of his k-nearest neighbors, and its own local density: a normal instance is expected to have a local density similar to that of its neighbors, while abnormal data are expected to have much smaller local density.</source>
          <target state="translated">En la práctica,la densidad local se obtiene de los vecinos más cercanos.La puntuación de la LOF de una observación es igual a la proporción de la densidad local media de sus vecinos más cercanos,y su propia densidad local:se espera que una instancia normal tenga una densidad local similar a la de sus vecinos,mientras que se espera que los datos anormales tengan una densidad local mucho menor.</target>
        </trans-unit>
        <trans-unit id="7ab811a62d63edef5c9695fca6cafd8cc266404c" translate="yes" xml:space="preserve">
          <source>In practice those estimates are stored as an attribute named &lt;code&gt;feature_importances_&lt;/code&gt; on the fitted model. This is an array with shape &lt;code&gt;(n_features,)&lt;/code&gt; whose values are positive and sum to 1.0. The higher the value, the more important is the contribution of the matching feature to the prediction function.</source>
          <target state="translated">En la pr&amp;aacute;ctica, esas estimaciones se almacenan como un atributo denominado &lt;code&gt;feature_importances_&lt;/code&gt; en el modelo ajustado. Esta es una matriz con forma &lt;code&gt;(n_features,)&lt;/code&gt; cuyos valores son positivos y suman 1.0. Cuanto mayor sea el valor, m&amp;aacute;s importante es la contribuci&amp;oacute;n de la caracter&amp;iacute;stica de coincidencia a la funci&amp;oacute;n de predicci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="2f91c327e74b19930bc0b8d2d9c2f5d99fe44af7" translate="yes" xml:space="preserve">
          <source>In practice we often ignore the shape of the distribution and just transform the data to center it by removing the mean value of each feature, then scale it by dividing non-constant features by their standard deviation.</source>
          <target state="translated">En la práctica,a menudo ignoramos la forma de la distribución y sólo transformamos los datos para centrarlos eliminando el valor medio de cada característica,y luego los escalamos dividiendo las características no constantes por su desviación estándar.</target>
        </trans-unit>
        <trans-unit id="4c632dd9d37d8e850afe2fbbbdbddfedb108d119" translate="yes" xml:space="preserve">
          <source>In practice, \(\mu\) and \(\Sigma\) are replaced by some estimates. The usual covariance maximum likelihood estimate is very sensitive to the presence of outliers in the data set and therefor, the corresponding Mahalanobis distances are. One would better have to use a robust estimator of covariance to guarantee that the estimation is resistant to &amp;ldquo;erroneous&amp;rdquo; observations in the data set and that the associated Mahalanobis distances accurately reflect the true organisation of the observations.</source>
          <target state="translated">En la pr&amp;aacute;ctica, \ (\ mu \) y \ (\ Sigma \) se reemplazan por algunas estimaciones. La estimaci&amp;oacute;n de m&amp;aacute;xima verosimilitud de la covarianza habitual es muy sensible a la presencia de valores at&amp;iacute;picos en el conjunto de datos y, por lo tanto, las distancias de Mahalanobis correspondientes son. Ser&amp;iacute;a mejor utilizar un estimador robusto de covarianza para garantizar que la estimaci&amp;oacute;n sea resistente a observaciones &quot;err&amp;oacute;neas&quot; en el conjunto de datos y que las distancias de Mahalanobis asociadas reflejen con precisi&amp;oacute;n la verdadera organizaci&amp;oacute;n de las observaciones.</target>
        </trans-unit>
        <trans-unit id="7f19bfe5f66f3783151b8147191d95599d9b587d" translate="yes" xml:space="preserve">
          <source>In practice, the k-means algorithm is very fast (one of the fastest clustering algorithms available), but it falls in local minima. That&amp;rsquo;s why it can be useful to restart it several times.</source>
          <target state="translated">En la pr&amp;aacute;ctica, el algoritmo de k-medias es muy r&amp;aacute;pido (uno de los algoritmos de agrupamiento m&amp;aacute;s r&amp;aacute;pidos disponibles), pero cae en m&amp;iacute;nimos locales. Por eso puede resultar &amp;uacute;til reiniciarlo varias veces.</target>
        </trans-unit>
        <trans-unit id="a9809378b0338436bd7bbe8f2e2070a6272b570d" translate="yes" xml:space="preserve">
          <source>In problems where it is desired to give more importance to certain classes or certain individual samples keywords &lt;code&gt;class_weight&lt;/code&gt; and &lt;code&gt;sample_weight&lt;/code&gt; can be used.</source>
          <target state="translated">En problemas en los que se desee dar m&amp;aacute;s importancia a determinadas clases o determinadas muestras individuales, se pueden utilizar las palabras clave &lt;code&gt;class_weight&lt;/code&gt; y &lt;code&gt;sample_weight&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="cae7f41bfdb577edc832687cbceee9865d3220c5" translate="yes" xml:space="preserve">
          <source>In random forests (see &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;RandomForestClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt;&lt;code&gt;RandomForestRegressor&lt;/code&gt;&lt;/a&gt; classes), each tree in the ensemble is built from a sample drawn with replacement (i.e., a bootstrap sample) from the training set. In addition, when splitting a node during the construction of the tree, the split that is chosen is no longer the best split among all features. Instead, the split that is picked is the best split among a random subset of the features. As a result of this randomness, the bias of the forest usually slightly increases (with respect to the bias of a single non-random tree) but, due to averaging, its variance also decreases, usually more than compensating for the increase in bias, hence yielding an overall better model.</source>
          <target state="translated">En bosques aleatorios (consulte las clases &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt; &lt;code&gt;RandomForestClassifier&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt; &lt;code&gt;RandomForestRegressor&lt;/code&gt; &lt;/a&gt; ), cada &amp;aacute;rbol del conjunto se construye a partir de una muestra extra&amp;iacute;da con reemplazo (es decir, una muestra de arranque) del conjunto de entrenamiento. Adem&amp;aacute;s, al dividir un nodo durante la construcci&amp;oacute;n del &amp;aacute;rbol, la divisi&amp;oacute;n que se elige ya no es la mejor divisi&amp;oacute;n entre todas las caracter&amp;iacute;sticas. En cambio, la divisi&amp;oacute;n que se elige es la mejor divisi&amp;oacute;n entre un subconjunto aleatorio de caracter&amp;iacute;sticas. Como resultado de esta aleatoriedad, el sesgo del bosque generalmente aumenta ligeramente (con respecto al sesgo de un solo &amp;aacute;rbol no aleatorio) pero, debido al promedio, su varianza tambi&amp;eacute;n disminuye, generalmente m&amp;aacute;s que compensando el aumento del sesgo. de ah&amp;iacute; que produzca un modelo mejor en general.</target>
        </trans-unit>
        <trans-unit id="eee63fdeeb00f1867cdf7e3f336a4276e1d12ae2" translate="yes" xml:space="preserve">
          <source>In regression, the expected mean squared error of an estimator can be decomposed in terms of bias, variance and noise. On average over datasets of the regression problem, the bias term measures the average amount by which the predictions of the estimator differ from the predictions of the best possible estimator for the problem (i.e., the Bayes model). The variance term measures the variability of the predictions of the estimator when fit over different instances LS of the problem. Finally, the noise measures the irreducible part of the error which is due the variability in the data.</source>
          <target state="translated">En la regresión,el error cuadrático medio esperado de un estimador puede descomponerse en términos de sesgo,varianza y ruido.En promedio sobre los conjuntos de datos del problema de la regresión,el término de sesgo mide la cantidad promedio en la que las predicciones del estimador difieren de las predicciones del mejor estimador posible para el problema (es decir,el modelo de Bayes).El término de varianza mide la variabilidad de las predicciones del estimador cuando se ajustan sobre diferentes instancias LS del problema.Por último,el ruido mide la parte irreducible del error que se debe a la variabilidad de los datos.</target>
        </trans-unit>
        <trans-unit id="3eae88b0a075df5d4090eee16e911849fedcc7b3" translate="yes" xml:space="preserve">
          <source>In regression, the output remains as \(f(x)\); therefore, output activation function is just the identity function.</source>
          <target state="translated">En la regresión,la salida se mantiene como \(f(x)\);por lo tanto,la función de activación de la salida es sólo la función de identidad.</target>
        </trans-unit>
        <trans-unit id="253be6f032627aec5a3b2c4240659e2190b9fba2" translate="yes" xml:space="preserve">
          <source>In scikit-learn a random split into training and test sets can be quickly computed with the &lt;a href=&quot;generated/sklearn.model_selection.train_test_split#sklearn.model_selection.train_test_split&quot;&gt;&lt;code&gt;train_test_split&lt;/code&gt;&lt;/a&gt; helper function. Let&amp;rsquo;s load the iris data set to fit a linear support vector machine on it:</source>
          <target state="translated">En scikit-learn, una divisi&amp;oacute;n aleatoria en conjuntos de entrenamiento y prueba se puede calcular r&amp;aacute;pidamente con la funci&amp;oacute;n auxiliar &lt;a href=&quot;generated/sklearn.model_selection.train_test_split#sklearn.model_selection.train_test_split&quot;&gt; &lt;code&gt;train_test_split&lt;/code&gt; &lt;/a&gt; . Carguemos el conjunto de datos de iris para ajustarlo a una m&amp;aacute;quina de vectores de soporte lineal:</target>
        </trans-unit>
        <trans-unit id="bdcdb5bf0b220e10633a04e3b3d7b23fb832fcf9" translate="yes" xml:space="preserve">
          <source>In scikit-learn, an estimator for classification is a Python object that implements the methods &lt;code&gt;fit(X, y)&lt;/code&gt; and &lt;code&gt;predict(T)&lt;/code&gt;.</source>
          <target state="translated">En scikit-learn, un estimador para clasificaci&amp;oacute;n es un objeto Python que implementa los m&amp;eacute;todos &lt;code&gt;fit(X, y)&lt;/code&gt; y &lt;code&gt;predict(T)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a15700735758e7e1606b13cd4f276e5fe1e0ef96" translate="yes" xml:space="preserve">
          <source>In scikit-learn, bagging methods are offered as a unified &lt;a href=&quot;generated/sklearn.ensemble.baggingclassifier#sklearn.ensemble.BaggingClassifier&quot;&gt;&lt;code&gt;BaggingClassifier&lt;/code&gt;&lt;/a&gt; meta-estimator (resp. &lt;a href=&quot;generated/sklearn.ensemble.baggingregressor#sklearn.ensemble.BaggingRegressor&quot;&gt;&lt;code&gt;BaggingRegressor&lt;/code&gt;&lt;/a&gt;), taking as input a user-specified base estimator along with parameters specifying the strategy to draw random subsets. In particular, &lt;code&gt;max_samples&lt;/code&gt; and &lt;code&gt;max_features&lt;/code&gt; control the size of the subsets (in terms of samples and features), while &lt;code&gt;bootstrap&lt;/code&gt; and &lt;code&gt;bootstrap_features&lt;/code&gt; control whether samples and features are drawn with or without replacement. When using a subset of the available samples the generalization accuracy can be estimated with the out-of-bag samples by setting &lt;code&gt;oob_score=True&lt;/code&gt;. As an example, the snippet below illustrates how to instantiate a bagging ensemble of &lt;code&gt;KNeighborsClassifier&lt;/code&gt; base estimators, each built on random subsets of 50% of the samples and 50% of the features.</source>
          <target state="translated">En scikit-learn, los m&amp;eacute;todos de ensacado se ofrecen como un &lt;a href=&quot;generated/sklearn.ensemble.baggingclassifier#sklearn.ensemble.BaggingClassifier&quot;&gt; &lt;code&gt;BaggingClassifier&lt;/code&gt; &lt;/a&gt; unificado de BaggingClassifier (resp. &lt;a href=&quot;generated/sklearn.ensemble.baggingregressor#sklearn.ensemble.BaggingRegressor&quot;&gt; &lt;code&gt;BaggingRegressor&lt;/code&gt; &lt;/a&gt; ), tomando como entrada un estimador base especificado por el usuario junto con par&amp;aacute;metros que especifican la estrategia para dibujar subconjuntos aleatorios. En particular, &lt;code&gt;max_samples&lt;/code&gt; y &lt;code&gt;max_features&lt;/code&gt; controlan el tama&amp;ntilde;o de los subconjuntos (en t&amp;eacute;rminos de muestras y caracter&amp;iacute;sticas), mientras que &lt;code&gt;bootstrap&lt;/code&gt; y &lt;code&gt;bootstrap_features&lt;/code&gt; controlan si las muestras y caracter&amp;iacute;sticas se dibujan con o sin reemplazo. Cuando se utiliza un subconjunto de las muestras disponibles, la precisi&amp;oacute;n de la generalizaci&amp;oacute;n se puede estimar con las muestras fuera de la bolsa configurando &lt;code&gt;oob_score=True&lt;/code&gt; . Como ejemplo, el siguiente fragmento ilustra c&amp;oacute;mo crear una instancia de un conjunto de &lt;code&gt;KNeighborsClassifier&lt;/code&gt; estimadores base de KNeighborsClassifier , cada uno construido sobre subconjuntos aleatorios del 50% de las muestras y el 50% de las caracter&amp;iacute;sticas.</target>
        </trans-unit>
        <trans-unit id="0848ab34fddbc88dcbfdd395d0519986e8d182eb" translate="yes" xml:space="preserve">
          <source>In scikit-learn, this transformation (with a user-defined shrinkage coefficient) can be directly applied to a pre-computed covariance with the &lt;a href=&quot;generated/sklearn.covariance.shrunk_covariance#sklearn.covariance.shrunk_covariance&quot;&gt;&lt;code&gt;shrunk_covariance&lt;/code&gt;&lt;/a&gt; method. Also, a shrunk estimator of the covariance can be fitted to data with a &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance&quot;&gt;&lt;code&gt;ShrunkCovariance&lt;/code&gt;&lt;/a&gt; object and its &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance.fit&quot;&gt;&lt;code&gt;ShrunkCovariance.fit&lt;/code&gt;&lt;/a&gt; method. Again, results depend on whether the data are centered, so one may want to use the &lt;code&gt;assume_centered&lt;/code&gt; parameter accurately.</source>
          <target state="translated">En scikit-learn, esta transformaci&amp;oacute;n (con un coeficiente de contracci&amp;oacute;n definido por el usuario) se puede aplicar directamente a una covarianza &lt;a href=&quot;generated/sklearn.covariance.shrunk_covariance#sklearn.covariance.shrunk_covariance&quot;&gt; &lt;code&gt;shrunk_covariance&lt;/code&gt; &lt;/a&gt; con el m&amp;eacute;todo shrunk_covariance . Adem&amp;aacute;s, un estimador reducido de la covarianza se puede &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance&quot;&gt; &lt;code&gt;ShrunkCovariance&lt;/code&gt; &lt;/a&gt; a los datos con un objeto ShrunkCovariance y su m&amp;eacute;todo &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance.fit&quot;&gt; &lt;code&gt;ShrunkCovariance.fit&lt;/code&gt; &lt;/a&gt; . Nuevamente, los resultados dependen de si los datos est&amp;aacute;n centrados, por lo que es posible que desee utilizar el par&amp;aacute;metro &lt;code&gt;assume_centered&lt;/code&gt; precisi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="77c9e3634b9d256acc307751b68c900b0b833a29" translate="yes" xml:space="preserve">
          <source>In single precision, &lt;code&gt;mean&lt;/code&gt; can be inaccurate:</source>
          <target state="translated">En precisi&amp;oacute;n simple, la &lt;code&gt;mean&lt;/code&gt; puede ser inexacta:</target>
        </trans-unit>
        <trans-unit id="640c5c337251b299605fe0c1704cd43d50fcda84" translate="yes" xml:space="preserve">
          <source>In some cases it&amp;rsquo;s not necessary to include higher powers of any single feature, but only the so-called &lt;em&gt;interaction features&lt;/em&gt; that multiply together at most \(d\) distinct features. These can be gotten from &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt;&lt;code&gt;PolynomialFeatures&lt;/code&gt;&lt;/a&gt; with the setting &lt;code&gt;interaction_only=True&lt;/code&gt;.</source>
          <target state="translated">En algunos casos, no es necesario incluir potencias superiores de ninguna caracter&amp;iacute;stica &amp;uacute;nica, sino solo las llamadas &lt;em&gt;caracter&amp;iacute;sticas de interacci&amp;oacute;n&lt;/em&gt; que se multiplican juntas como m&amp;aacute;ximo \ (d \) caracter&amp;iacute;sticas distintas. Estos pueden obtenerse de &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt; &lt;code&gt;PolynomialFeatures&lt;/code&gt; &lt;/a&gt; con la configuraci&amp;oacute;n &lt;code&gt;interaction_only=True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4976a8ab8df4ced9a6ceb9c8368b484dbc953550" translate="yes" xml:space="preserve">
          <source>In some cases, only interaction terms among features are required, and it can be gotten with the setting &lt;code&gt;interaction_only=True&lt;/code&gt;:</source>
          <target state="translated">En algunos casos, solo se requieren t&amp;eacute;rminos de interacci&amp;oacute;n entre caracter&amp;iacute;sticas, y se puede obtener con la configuraci&amp;oacute;n &lt;code&gt;interaction_only=True&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="1b40a5cc0ca592bd5c1306138f251a81fe534579" translate="yes" xml:space="preserve">
          <source>In spite of their apparently over-simplified assumptions, naive Bayes classifiers have worked quite well in many real-world situations, famously document classification and spam filtering. They require a small amount of training data to estimate the necessary parameters. (For theoretical reasons why naive Bayes works well, and on which types of data it does, see the references below.)</source>
          <target state="translated">A pesar de sus supuestos aparentemente demasiado simplificados,los ingenuos clasificadores Bayes han funcionado bastante bien en muchas situaciones del mundo real,como la famosa clasificación de documentos y el filtrado de spam.Requieren una pequeña cantidad de datos de entrenamiento para estimar los parámetros necesarios.(Por razones teóricas,por qué los ingenuos Bayes funcionan bien,y sobre qué tipos de datos lo hacen,véanse las referencias que figuran a continuación).</target>
        </trans-unit>
        <trans-unit id="389828ed3005eb646a2fbe827835555cbdc74437" translate="yes" xml:space="preserve">
          <source>In terms of accuracy, LOO often results in high variance as an estimator for the test error. Intuitively, since \(n - 1\) of the \(n\) samples are used to build each model, models constructed from folds are virtually identical to each other and to the model built from the entire training set.</source>
          <target state="translated">En términos de precisión,LOO a menudo resulta en una alta varianza como estimador del error de la prueba.Intuitivamente,ya que \ ~ n-1\ ~ de las muestras se utilizan para construir cada modelo,los modelos construidos a partir de los pliegues son prácticamente idénticos entre sí y con el modelo construido a partir de todo el conjunto de la formación.</target>
        </trans-unit>
        <trans-unit id="36132aafc76511f4279f2a1765dcbaeb9d7a44b1" translate="yes" xml:space="preserve">
          <source>In terms of time and space complexity, Theil-Sen scales according to</source>
          <target state="translated">En términos de complejidad temporal y espacial,Theil-Sen escala según</target>
        </trans-unit>
        <trans-unit id="8cac8320893acecd46013a1cd740f5237cabb213" translate="yes" xml:space="preserve">
          <source>In that case, the model with 2 components and full covariance (which corresponds to the true generative model) is selected.</source>
          <target state="translated">En ese caso,se selecciona el modelo con 2 componentes y covarianza completa (que corresponde al verdadero modelo generativo).</target>
        </trans-unit>
        <trans-unit id="df23be83a828beae97b01644c9cebfd6ec568f81" translate="yes" xml:space="preserve">
          <source>In the &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt;&lt;code&gt;TfidfTransformer&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt;&lt;code&gt;TfidfVectorizer&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;smooth_idf=False&lt;/code&gt;, the &amp;ldquo;1&amp;rdquo; count is added to the idf instead of the idf&amp;rsquo;s denominator:</source>
          <target state="translated">En &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt; &lt;code&gt;TfidfTransformer&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt; &lt;code&gt;TfidfVectorizer&lt;/code&gt; &lt;/a&gt; con &lt;code&gt;smooth_idf=False&lt;/code&gt; , el recuento &quot;1&quot; se agrega al idf en lugar del denominador del idf:</target>
        </trans-unit>
        <trans-unit id="5bd53e1aa867b99daf4cb138797f33e24d9cfda1" translate="yes" xml:space="preserve">
          <source>In the &lt;a href=&quot;generated/sklearn.neural_network.bernoullirbm#sklearn.neural_network.BernoulliRBM&quot;&gt;&lt;code&gt;BernoulliRBM&lt;/code&gt;&lt;/a&gt;, all units are binary stochastic units. This means that the input data should either be binary, or real-valued between 0 and 1 signifying the probability that the visible unit would turn on or off. This is a good model for character recognition, where the interest is on which pixels are active and which aren&amp;rsquo;t. For images of natural scenes it no longer fits because of background, depth and the tendency of neighbouring pixels to take the same values.</source>
          <target state="translated">En &lt;a href=&quot;generated/sklearn.neural_network.bernoullirbm#sklearn.neural_network.BernoulliRBM&quot;&gt; &lt;code&gt;BernoulliRBM&lt;/code&gt; &lt;/a&gt; , todas las unidades son unidades estoc&amp;aacute;sticas binarias. Esto significa que los datos de entrada deben ser binarios o tener un valor real entre 0 y 1, lo que significa la probabilidad de que la unidad visible se encienda o apague. Este es un buen modelo para el reconocimiento de caracteres, donde el inter&amp;eacute;s est&amp;aacute; en qu&amp;eacute; p&amp;iacute;xeles est&amp;aacute;n activos y cu&amp;aacute;les no. Para im&amp;aacute;genes de escenas naturales ya no encaja debido al fondo, la profundidad y la tendencia de los p&amp;iacute;xeles vecinos a tomar los mismos valores.</target>
        </trans-unit>
        <trans-unit id="729860dcb0b5963ed7d873f5d8718ecbded39d56" translate="yes" xml:space="preserve">
          <source>In the &lt;code&gt;l1&lt;/code&gt; case, theory says that prediction consistency (i.e. that under given hypothesis, the estimator learned predicts as well as a model knowing the true distribution) is not possible because of the bias of the &lt;code&gt;l1&lt;/code&gt;. It does say, however, that model consistency, in terms of finding the right set of non-zero parameters as well as their signs, can be achieved by scaling &lt;code&gt;C1&lt;/code&gt;.</source>
          <target state="translated">En el caso &lt;code&gt;l1&lt;/code&gt; , la teor&amp;iacute;a dice que la consistencia de la predicci&amp;oacute;n (es decir, que bajo una hip&amp;oacute;tesis dada, el estimador aprendido predice as&amp;iacute; como un modelo que conoce la distribuci&amp;oacute;n verdadera) no es posible debido al sesgo del &lt;code&gt;l1&lt;/code&gt; . Sin embargo, s&amp;iacute; dice que la consistencia del modelo, en t&amp;eacute;rminos de encontrar el conjunto correcto de par&amp;aacute;metros distintos de cero, as&amp;iacute; como sus signos, se puede lograr escalando &lt;code&gt;C1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3ac113ba1d5ea8579f40e00fa885b5d980c4ba43" translate="yes" xml:space="preserve">
          <source>In the &lt;code&gt;l1&lt;/code&gt; penalty case, the cross-validation-error correlates best with the test-error, when scaling our &lt;code&gt;C&lt;/code&gt; with the number of samples, &lt;code&gt;n&lt;/code&gt;, which can be seen in the first figure.</source>
          <target state="translated">En el caso de penalizaci&amp;oacute;n &lt;code&gt;l1&lt;/code&gt; , el error de validaci&amp;oacute;n cruzada se correlaciona mejor con el error de prueba, al escalar nuestra &lt;code&gt;C&lt;/code&gt; con el n&amp;uacute;mero de muestras, &lt;code&gt;n&lt;/code&gt; , que se puede ver en la primera figura.</target>
        </trans-unit>
        <trans-unit id="4495b7082e60ec7cb3a7d3cf1946536697a0e6b3" translate="yes" xml:space="preserve">
          <source>In the above case, the classifier is fit on a 1d array of multiclass labels and the &lt;code&gt;predict()&lt;/code&gt; method therefore provides corresponding multiclass predictions. It is also possible to fit upon a 2d array of binary label indicators:</source>
          <target state="translated">En el caso anterior, el clasificador se ajusta a una matriz 1d de etiquetas multiclase y , por lo tanto, el m&amp;eacute;todo &lt;code&gt;predict()&lt;/code&gt; proporciona las predicciones multiclase correspondientes. Tambi&amp;eacute;n es posible encajar en una matriz 2d de indicadores de etiquetas binarias:</target>
        </trans-unit>
        <trans-unit id="41d2181ce120b72b14a943b5e6f5608fe64d404d" translate="yes" xml:space="preserve">
          <source>In the above example, &lt;code&gt;char_wb&lt;/code&gt; analyzer is used, which creates n-grams only from characters inside word boundaries (padded with space on each side). The &lt;code&gt;char&lt;/code&gt; analyzer, alternatively, creates n-grams that span across words:</source>
          <target state="translated">En el ejemplo anterior, se &lt;code&gt;char_wb&lt;/code&gt; analizador char_wb , que crea n-gramas solo a partir de caracteres dentro de los l&amp;iacute;mites de las palabras (rellenados con espacio en cada lado). El &lt;code&gt;char&lt;/code&gt; analizador, en su defecto, crea n-gramas que abarcan palabras:</target>
        </trans-unit>
        <trans-unit id="02dd6b844a6f6c7bb7b63318a0172b18e25d4984" translate="yes" xml:space="preserve">
          <source>In the above example, the &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt; expects a 1D array as input and therefore the columns were specified as a string (&lt;code&gt;'city'&lt;/code&gt;). However, other transformers generally expect 2D data, and in that case you need to specify the column as a list of strings (&lt;code&gt;['city']&lt;/code&gt;).</source>
          <target state="translated">En el ejemplo anterior, &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; espera una matriz 1D como entrada y, por lo tanto, las columnas se especificaron como una cadena ( &lt;code&gt;'city'&lt;/code&gt; ). Sin embargo, otros transformadores generalmente esperan datos 2D y, en ese caso, es necesario especificar la columna como una lista de cadenas ( &lt;code&gt;['city']&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="8be3ffb93abc4e32a08a3f61b709f6ed3e6124c4" translate="yes" xml:space="preserve">
          <source>In the above example-code, we firstly use the &lt;code&gt;fit(..)&lt;/code&gt; method to fit our estimator to the data and secondly the &lt;code&gt;transform(..)&lt;/code&gt; method to transform our count-matrix to a tf-idf representation. These two steps can be combined to achieve the same end result faster by skipping redundant processing. This is done through using the &lt;code&gt;fit_transform(..)&lt;/code&gt; method as shown below, and as mentioned in the note in the previous section:</source>
          <target state="translated">En el c&amp;oacute;digo de ejemplo anterior, primero usamos el m&amp;eacute;todo &lt;code&gt;fit(..)&lt;/code&gt; para ajustar nuestro estimador a los datos y, en segundo lugar, el m&amp;eacute;todo &lt;code&gt;transform(..)&lt;/code&gt; para transformar nuestra matriz de conteo en una representaci&amp;oacute;n tf-idf. Estos dos pasos se pueden combinar para lograr el mismo resultado final m&amp;aacute;s r&amp;aacute;pidamente omitiendo el procesamiento redundante. Esto se hace usando el &lt;code&gt;fit_transform(..)&lt;/code&gt; como se muestra a continuaci&amp;oacute;n, y como se menciona en la nota en la secci&amp;oacute;n anterior:</target>
        </trans-unit>
        <trans-unit id="fc1fc9feffcc3ab7062a5968abf403f994be456d" translate="yes" xml:space="preserve">
          <source>In the above process, rejection sampling is used to make sure that n is more than 2, and that the document length is never zero. Likewise, we reject classes which have already been chosen. The documents that are assigned to both classes are plotted surrounded by two colored circles.</source>
          <target state="translated">En el proceso anterior,el muestreo de rechazo se utiliza para asegurarse de que n es más de 2,y que la longitud del documento nunca es cero.De la misma manera,rechazamos las clases que ya han sido elegidas.Los documentos que se asignan a ambas clases se trazan rodeados de dos círculos de color.</target>
        </trans-unit>
        <trans-unit id="35ac86e1f976c024d854c94dc1a07d9250df373b" translate="yes" xml:space="preserve">
          <source>In the above process, rejection sampling is used to make sure that n is never zero or more than &lt;code&gt;n_classes&lt;/code&gt;, and that the document length is never zero. Likewise, we reject classes which have already been chosen.</source>
          <target state="translated">En el proceso anterior, el muestreo de rechazo se utiliza para asegurarse de que n nunca sea cero o m&amp;aacute;s que &lt;code&gt;n_classes&lt;/code&gt; , y que la longitud del documento nunca sea cero. Asimismo, rechazamos las clases que ya han sido elegidas.</target>
        </trans-unit>
        <trans-unit id="35b3eed71c5956697e4e941c9abda7fa7875d908" translate="yes" xml:space="preserve">
          <source>In the binary (two-class) case, \(tp\), \(tn\), \(fp\) and \(fn\) are respectively the number of true positives, true negatives, false positives and false negatives, the MCC is defined as</source>
          <target state="translated">En el caso binario (de dos clases),\ ~ \ ~-tp,\ ~-tn,\ ~ y \ ~-fn son,respectivamente,el número de verdaderos positivos,\ ~ verdaderos negativos,falsos positivos y falsos negativos,la MCC se define como</target>
        </trans-unit>
        <trans-unit id="8cf754386b9e93bff61012cc7eebd891fe098125" translate="yes" xml:space="preserve">
          <source>In the binary case, balanced accuracy is equal to the arithmetic mean of &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;sensitivity&lt;/a&gt; (true positive rate) and &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;specificity&lt;/a&gt; (true negative rate), or the area under the ROC curve with binary predictions rather than scores.</source>
          <target state="translated">En el caso binario, la precisi&amp;oacute;n equilibrada es igual a la media aritm&amp;eacute;tica de la &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;sensibilidad&lt;/a&gt; (tasa positiva verdadera) y la &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;especificidad&lt;/a&gt; (tasa negativa verdadera), o el &amp;aacute;rea bajo la curva ROC con predicciones binarias en lugar de puntuaciones.</target>
        </trans-unit>
        <trans-unit id="a998ef5238ae7921fe9486295ae64f00deab3566" translate="yes" xml:space="preserve">
          <source>In the binary case, we can extract true positives, etc as follows:</source>
          <target state="translated">En el caso binario,podemos extraer los verdaderos positivos,etc.,de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="2482e7f51309cef70ec85538824011f95f0813b1" translate="yes" xml:space="preserve">
          <source>In the case of &amp;ldquo;one-vs-one&amp;rdquo; &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt;, the layout of the attributes is a little more involved. In the case of having a linear kernel, the attributes &lt;code&gt;coef_&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; have the shape &lt;code&gt;[n_class * (n_class - 1) / 2, n_features]&lt;/code&gt; and &lt;code&gt;[n_class * (n_class - 1) / 2]&lt;/code&gt; respectively. This is similar to the layout for &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; described above, with each row now corresponding to a binary classifier. The order for classes 0 to n is &amp;ldquo;0 vs 1&amp;rdquo;, &amp;ldquo;0 vs 2&amp;rdquo; , &amp;hellip; &amp;ldquo;0 vs n&amp;rdquo;, &amp;ldquo;1 vs 2&amp;rdquo;, &amp;ldquo;1 vs 3&amp;rdquo;, &amp;ldquo;1 vs n&amp;rdquo;, . . . &amp;ldquo;n-1 vs n&amp;rdquo;.</source>
          <target state="translated">En el caso de &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt; &quot;uno contra uno&quot; , el dise&amp;ntilde;o de los atributos es un poco m&amp;aacute;s complicado. En el caso de tener un kernel lineal, los atributos &lt;code&gt;coef_&lt;/code&gt; e &lt;code&gt;intercept_&lt;/code&gt; tienen la forma &lt;code&gt;[n_class * (n_class - 1) / 2, n_features]&lt;/code&gt; y &lt;code&gt;[n_class * (n_class - 1) / 2]&lt;/code&gt; respectivamente. Esto es similar al dise&amp;ntilde;o de &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt; descrito anteriormente, con cada fila ahora correspondiente a un clasificador binario. El orden de las clases 0 an es &quot;0 vs 1&quot;, &quot;0 vs 2&quot;, ... &quot;0 vs n&quot;, &quot;1 vs 2&quot;, &quot;1 vs 3&quot;, &quot;1 vs n&quot;,. . . &quot;N-1 frente a n&quot;.</target>
        </trans-unit>
        <trans-unit id="7befa9fe69dc29e17ce8c14ce1f24dcd596f25dc" translate="yes" xml:space="preserve">
          <source>In the case of Gaussian process classification, &amp;ldquo;one_vs_one&amp;rdquo; might be computationally cheaper since it has to solve many problems involving only a subset of the whole training set rather than fewer problems on the whole dataset. Since Gaussian process classification scales cubically with the size of the dataset, this might be considerably faster. However, note that &amp;ldquo;one_vs_one&amp;rdquo; does not support predicting probability estimates but only plain predictions. Moreover, note that &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessclassifier#sklearn.gaussian_process.GaussianProcessClassifier&quot;&gt;&lt;code&gt;GaussianProcessClassifier&lt;/code&gt;&lt;/a&gt; does not (yet) implement a true multi-class Laplace approximation internally, but as discussed above is based on solving several binary classification tasks internally, which are combined using one-versus-rest or one-versus-one.</source>
          <target state="translated">En el caso de la clasificaci&amp;oacute;n de procesos gaussianos, &quot;one_vs_one&quot; podr&amp;iacute;a ser computacionalmente m&amp;aacute;s econ&amp;oacute;mico, ya que tiene que resolver muchos problemas que involucran solo un subconjunto de todo el conjunto de entrenamiento en lugar de menos problemas en todo el conjunto de datos. Dado que la clasificaci&amp;oacute;n del proceso gaussiano se escala c&amp;uacute;bicamente con el tama&amp;ntilde;o del conjunto de datos, esto podr&amp;iacute;a ser considerablemente m&amp;aacute;s r&amp;aacute;pido. Sin embargo, tenga en cuenta que &quot;one_vs_one&quot; no admite la predicci&amp;oacute;n de estimaciones de probabilidad, sino solo predicciones simples. Adem&amp;aacute;s, tenga en cuenta que &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessclassifier#sklearn.gaussian_process.GaussianProcessClassifier&quot;&gt; &lt;code&gt;GaussianProcessClassifier&lt;/code&gt; &lt;/a&gt; no implementa (todav&amp;iacute;a) una verdadera aproximaci&amp;oacute;n de Laplace de m&amp;uacute;ltiples clases internamente, pero como se discuti&amp;oacute; anteriormente se basa en resolver varias tareas de clasificaci&amp;oacute;n binaria internamente, que se combinan usando uno contra resto o uno contra uno.</target>
        </trans-unit>
        <trans-unit id="35a5ada3d16c18d2778299b423e5960182d45740" translate="yes" xml:space="preserve">
          <source>In the case of LDA, the Gaussians for each class are assumed to share the same covariance matrix: \(\Sigma_k = \Sigma\) for all \(k\). This leads to linear decision surfaces, which can be seen by comparing the log-probability ratios \(\log[P(y=k | X) / P(y=l | X)]\):</source>
          <target state="translated">En el caso de la LDA,se supone que los gausianos de cada clase comparten la misma matriz de covarianza:\N-Sigma_k=\N-Sigma para todos.Esto conduce a superficies de decisión lineales,que pueden verse comparando los ratios de probabilidad logarítmica \N \N ;logarítmica[P(y=k | X)/P(y=l | X)]\N):</target>
        </trans-unit>
        <trans-unit id="9191afe7181654f4c123a5274615786e30f48b2b" translate="yes" xml:space="preserve">
          <source>In the case of QDA, there are no assumptions on the covariance matrices \(\Sigma_k\) of the Gaussians, leading to quadratic decision surfaces. See &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[3]&lt;/a&gt; for more details.</source>
          <target state="translated">En el caso de QDA, no hay supuestos sobre las matrices de covarianza \ (\ Sigma_k \) de los gaussianos, lo que conduce a superficies de decisi&amp;oacute;n cuadr&amp;aacute;ticas. Consulte &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[3]&lt;/a&gt; para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="be50ffb98df62eb79c354d934aa76c5587bf8cba" translate="yes" xml:space="preserve">
          <source>In the case of multi-class classification &lt;code&gt;coef_&lt;/code&gt; is a two-dimensional array of &lt;code&gt;shape=[n_classes, n_features]&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; is a one-dimensional array of &lt;code&gt;shape=[n_classes]&lt;/code&gt;. The i-th row of &lt;code&gt;coef_&lt;/code&gt; holds the weight vector of the OVA classifier for the i-th class; classes are indexed in ascending order (see attribute &lt;code&gt;classes_&lt;/code&gt;). Note that, in principle, since they allow to create a probability model, &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; and &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; are more suitable for one-vs-all classification.</source>
          <target state="translated">En el caso de la clasificaci&amp;oacute;n de clases m&amp;uacute;ltiples, &lt;code&gt;coef_&lt;/code&gt; es una matriz bidimensional de &lt;code&gt;shape=[n_classes, n_features]&lt;/code&gt; e &lt;code&gt;intercept_&lt;/code&gt; es una matriz unidimensional de &lt;code&gt;shape=[n_classes]&lt;/code&gt; . La i-&amp;eacute;sima fila de &lt;code&gt;coef_&lt;/code&gt; contiene el vector de peso del clasificador OVA para la i-&amp;eacute;sima clase; las clases est&amp;aacute;n indexadas en orden ascendente (ver atributo &lt;code&gt;classes_&lt;/code&gt; ). Tenga en cuenta que, en principio, dado que permiten crear un modelo de probabilidad, &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; y &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; son m&amp;aacute;s adecuados para la clasificaci&amp;oacute;n de uno contra todos.</target>
        </trans-unit>
        <trans-unit id="e1959581346965192dc91c946ef9926bceb1c51a" translate="yes" xml:space="preserve">
          <source>In the case of multi-class classification, the mean log-marginal likelihood of the one-versus-rest classifiers are returned.</source>
          <target state="translated">En el caso de la clasificación multiclase,se devuelve la media de la probabilidad logarítmica marginal de los clasificadores de uno contra uno.</target>
        </trans-unit>
        <trans-unit id="a45d03e82085c1e194b2b19d0700767439a7ac42" translate="yes" xml:space="preserve">
          <source>In the case of one-hot/one-of-K coding, the constructed feature names and values are returned rather than the original ones.</source>
          <target state="translated">En el caso de la codificación &quot;uno-de-uno-de-K&quot;,se devuelven los nombres y valores de las características construidas en lugar de los originales.</target>
        </trans-unit>
        <trans-unit id="108b9e0576d5a78538771fb415a46ae76d1a6e26" translate="yes" xml:space="preserve">
          <source>In the case of text classification, word occurrence vectors (rather than word count vectors) may be used to train and use this classifier. &lt;code&gt;BernoulliNB&lt;/code&gt; might perform better on some datasets, especially those with shorter documents. It is advisable to evaluate both models, if time permits.</source>
          <target state="translated">En el caso de la clasificaci&amp;oacute;n de texto, se pueden usar vectores de ocurrencia de palabras (en lugar de vectores de conteo de palabras) para entrenar y usar este clasificador. &lt;code&gt;BernoulliNB&lt;/code&gt; podr&amp;iacute;a funcionar mejor en algunos conjuntos de datos, especialmente aquellos con documentos m&amp;aacute;s cortos. Es recomendable evaluar ambos modelos, si el tiempo lo permite.</target>
        </trans-unit>
        <trans-unit id="1ee37ddaa2e2b7fb0103fdddd162d9ad76a8f2dd" translate="yes" xml:space="preserve">
          <source>In the case of the digits dataset, the task is to predict, given an image, which digit it represents. We are given samples of each of the 10 possible classes (the digits zero through nine) on which we &lt;em&gt;fit&lt;/em&gt; an &lt;a href=&quot;https://en.wikipedia.org/wiki/Estimator&quot;&gt;estimator&lt;/a&gt; to be able to &lt;em&gt;predict&lt;/em&gt; the classes to which unseen samples belong.</source>
          <target state="translated">En el caso del conjunto de datos de d&amp;iacute;gitos, la tarea es predecir, dada una imagen, qu&amp;eacute; d&amp;iacute;gito representa. Se nos dan muestras de cada una de las 10 clases posibles (los d&amp;iacute;gitos del cero al nueve) en las que &lt;em&gt;ajustamos&lt;/em&gt; un &lt;a href=&quot;https://en.wikipedia.org/wiki/Estimator&quot;&gt;estimador&lt;/a&gt; para poder &lt;em&gt;predecir&lt;/em&gt; las clases a las que pertenecen las muestras invisibles.</target>
        </trans-unit>
        <trans-unit id="0484e6facaecfeba6a4ff8e0552fa9a5ac1c52dd" translate="yes" xml:space="preserve">
          <source>In the case that one or more classes are absent in a training portion, a default score needs to be assigned to all instances for that class if &lt;code&gt;method&lt;/code&gt; produces columns per class, as in {&amp;lsquo;decision_function&amp;rsquo;, &amp;lsquo;predict_proba&amp;rsquo;, &amp;lsquo;predict_log_proba&amp;rsquo;}. For &lt;code&gt;predict_proba&lt;/code&gt; this value is 0. In order to ensure finite output, we approximate negative infinity by the minimum finite float value for the dtype in other cases.</source>
          <target state="translated">En el caso de que una o m&amp;aacute;s clases est&amp;eacute;n ausentes en una parte de entrenamiento, se debe asignar una puntuaci&amp;oacute;n predeterminada a todas las instancias de esa clase si el &lt;code&gt;method&lt;/code&gt; produce columnas por clase, como en {'decision_function', 'predict_proba', 'predict_log_proba'} . Para &lt;code&gt;predict_proba&lt;/code&gt; , este valor es 0. Para asegurar una salida finita, aproximamos el infinito negativo por el valor flotante finito m&amp;iacute;nimo para el tipo d en otros casos.</target>
        </trans-unit>
        <trans-unit id="74ff5bfdda6b3e93f59169f7c22fc2d68fa3fcf3" translate="yes" xml:space="preserve">
          <source>In the case when the binary labels are fractional (probabilistic), inverse_transform chooses the class with the greatest value. Typically, this allows to use the output of a linear model&amp;rsquo;s decision_function method directly as the input of inverse_transform.</source>
          <target state="translated">En el caso de que las etiquetas binarias sean fraccionarias (probabil&amp;iacute;sticas), inverse_transform elige la clase con el mayor valor. Normalmente, esto permite utilizar la salida del m&amp;eacute;todo de funci&amp;oacute;n_decisi&amp;oacute;n de un modelo lineal directamente como entrada de transformaci&amp;oacute;n_inversa.</target>
        </trans-unit>
        <trans-unit id="2d852af4ac330c07eec96a31a9559a88b3b70655" translate="yes" xml:space="preserve">
          <source>In the cases of a tie, the &lt;code&gt;VotingClassifier&lt;/code&gt; will select the class based on the ascending sort order. E.g., in the following scenario</source>
          <target state="translated">En los casos de empate, el &lt;code&gt;VotingClassifier&lt;/code&gt; seleccionar&amp;aacute; la clase en funci&amp;oacute;n del orden de clasificaci&amp;oacute;n ascendente. Por ejemplo, en el siguiente escenario</target>
        </trans-unit>
        <trans-unit id="84352a0fa93e8d3c09e63ba562819b09bff22e0e" translate="yes" xml:space="preserve">
          <source>In the checkerboard case, each row belongs to all column clusters, and each column belongs to all row clusters. Here is an example of this structure where the variance of the values within each bicluster is small:</source>
          <target state="translated">En el caso del tablero de damas,cada fila pertenece a todos los grupos de columnas,y cada columna pertenece a todos los grupos de filas.He aquí un ejemplo de esta estructura en la que la variación de los valores dentro de cada bíceps es pequeña:</target>
        </trans-unit>
        <trans-unit id="6a06bacf0f95acd504bad8493dc228833ae72576" translate="yes" xml:space="preserve">
          <source>In the event that the 95% confidence interval based on Fisher transform spans zero, a warning is raised.</source>
          <target state="translated">En el caso de que el intervalo de confianza del 95% basado en la transformación de Fisher se extienda hasta el cero,se eleva una advertencia.</target>
        </trans-unit>
        <trans-unit id="2da0fe066fd806cee05903c8f41b8c38bb726d66" translate="yes" xml:space="preserve">
          <source>In the example below, using a small shrink threshold increases the accuracy of the model from 0.81 to 0.82.</source>
          <target state="translated">En el ejemplo que figura a continuación,el uso de un pequeño umbral de contracción aumenta la precisión del modelo de 0,81 a 0,82.</target>
        </trans-unit>
        <trans-unit id="ae3527cc8009043f3459062f8b3ac5f4c7cdc080" translate="yes" xml:space="preserve">
          <source>In the figure below, the color indicates cluster membership, with large circles indicating core samples found by the algorithm. Smaller circles are non-core samples that are still part of a cluster. Moreover, the outliers are indicated by black points below.</source>
          <target state="translated">En la figura siguiente,el color indica la pertenencia al grupo,con grandes círculos que indican las muestras centrales encontradas por el algoritmo.Los círculos más pequeños son muestras no centrales que todavía forman parte de un cúmulo.Además,los valores atípicos se indican con puntos negros abajo.</target>
        </trans-unit>
        <trans-unit id="a915ebedbc9fc712ae336eb7409727fc370425dc" translate="yes" xml:space="preserve">
          <source>In the first row, the classifiers are built using the sepal width and the sepal length features only, on the second row using the petal length and sepal length only, and on the third row using the petal width and the petal length only.</source>
          <target state="translated">En la primera fila,los clasificadores se construyen utilizando únicamente la anchura y la longitud del sépalo,en la segunda fila se utiliza la longitud del pétalo y la longitud del sépalo solamente,y en la tercera fila se utiliza la anchura y la longitud del pétalo solamente.</target>
        </trans-unit>
        <trans-unit id="bd9366b471cf174a5dc26260b1ee3e4775bd8a95" translate="yes" xml:space="preserve">
          <source>In the following example, we construct a NeighborsClassifier class from an array representing our data set and ask who&amp;rsquo;s the closest point to [1, 1, 1]:</source>
          <target state="translated">En el siguiente ejemplo, construimos una clase NeighborsClassifier a partir de una matriz que representa nuestro conjunto de datos y preguntamos qui&amp;eacute;n es el punto m&amp;aacute;s cercano a [1, 1, 1]:</target>
        </trans-unit>
        <trans-unit id="f873541d5e32ccd97b454877a7265b9e862eeb9a" translate="yes" xml:space="preserve">
          <source>In the following example, we construct a NeighborsClassifier class from an array representing our data set and ask who&amp;rsquo;s the closest point to [1,1,1]</source>
          <target state="translated">En el siguiente ejemplo, construimos una clase NeighborsClassifier a partir de una matriz que representa nuestro conjunto de datos y preguntamos qui&amp;eacute;n es el punto m&amp;aacute;s cercano a [1,1,1]</target>
        </trans-unit>
        <trans-unit id="65f9f2f58e8b0fd298381aa88835a40b1607c17f" translate="yes" xml:space="preserve">
          <source>In the following figure, 100 points are drawn from a bimodal distribution, and the kernel density estimates are shown for three choices of kernels:</source>
          <target state="translated">En la siguiente figura,se extraen 100 puntos de una distribución bimodal,y se muestran las estimaciones de densidad de los núcleos para tres opciones de núcleos:</target>
        </trans-unit>
        <trans-unit id="24263a7351535bc4435386a661d4637b721eb5a0" translate="yes" xml:space="preserve">
          <source>In the following plot, we see a function \(f(x) = \cos (\frac{3}{2} \pi x)\) and some noisy samples from that function. We use three different estimators to fit the function: linear regression with polynomial features of degree 1, 4 and 15. We see that the first estimator can at best provide only a poor fit to the samples and the true function because it is too simple (high bias), the second estimator approximates it almost perfectly and the last estimator approximates the training data perfectly but does not fit the true function very well, i.e. it is very sensitive to varying training data (high variance).</source>
          <target state="translated">En la siguiente gráfica,vemos una función \N \N \N-f(x)=\N -cos (\N -fraccio{3}{2}\N -pi x)\N y algunas muestras ruidosas de esa función.Utilizamos tres estimadores diferentes para ajustar la función:regresión lineal con características polinómicas de grado 1,4 y 15.Vemos que el primer estimador puede,en el mejor de los casos,proporcionar sólo un mal ajuste a las muestras y a la función verdadera porque es demasiado simple (alto sesgo),el segundo estimador la aproxima casi perfectamente y el último estimador aproxima los datos de entrenamiento perfectamente pero no se ajusta muy bien a la función verdadera,es decir,es muy sensible a la variación de los datos de entrenamiento (alta varianza).</target>
        </trans-unit>
        <trans-unit id="de54ef0bf525631d31eb0623dcd55f8a9ddc120b" translate="yes" xml:space="preserve">
          <source>In the following sub-sections, we will describe each of those functions, preceded by some notes on common API and metric definition.</source>
          <target state="translated">En las siguientes subsecciones,describiremos cada una de esas funciones,precedidas de algunas notas sobre la API común y la definición de la métrica.</target>
        </trans-unit>
        <trans-unit id="7549668dfe247eb9e0e172cc89f620a63604992b" translate="yes" xml:space="preserve">
          <source>In the following we will use the built-in dataset loader for 20 newsgroups from scikit-learn. Alternatively, it is possible to download the dataset manually from the website and use the &lt;a href=&quot;../../modules/generated/sklearn.datasets.load_files#sklearn.datasets.load_files&quot;&gt;&lt;code&gt;sklearn.datasets.load_files&lt;/code&gt;&lt;/a&gt; function by pointing it to the &lt;code&gt;20news-bydate-train&lt;/code&gt; sub-folder of the uncompressed archive folder.</source>
          <target state="translated">A continuaci&amp;oacute;n, utilizaremos el cargador de conjuntos de datos integrado para 20 grupos de noticias de scikit-learn. Alternativamente, es posible descargar el conjunto de datos manualmente desde el sitio web y usar la funci&amp;oacute;n &lt;a href=&quot;../../modules/generated/sklearn.datasets.load_files#sklearn.datasets.load_files&quot;&gt; &lt;code&gt;sklearn.datasets.load_files&lt;/code&gt; &lt;/a&gt; apunt&amp;aacute;ndolo a la &lt;code&gt;20news-bydate-train&lt;/code&gt; de la carpeta de archivo sin comprimir.</target>
        </trans-unit>
        <trans-unit id="2cb0b9817ecf09ea4893bb9df9d328ce75ef2d1b" translate="yes" xml:space="preserve">
          <source>In the following, &amp;ldquo;city&amp;rdquo; is a categorical attribute while &amp;ldquo;temperature&amp;rdquo; is a traditional numerical feature:</source>
          <target state="translated">A continuaci&amp;oacute;n, &quot;ciudad&quot; es un atributo categ&amp;oacute;rico, mientras que &quot;temperatura&quot; es una caracter&amp;iacute;stica num&amp;eacute;rica tradicional:</target>
        </trans-unit>
        <trans-unit id="3e019b4cbe3ce7f1554fa08ce08898c560cb8a3b" translate="yes" xml:space="preserve">
          <source>In the following, we start a Python interpreter from our shell and then load the &lt;code&gt;iris&lt;/code&gt; and &lt;code&gt;digits&lt;/code&gt; datasets. Our notational convention is that &lt;code&gt;$&lt;/code&gt; denotes the shell prompt while &lt;code&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; denotes the Python interpreter prompt:</source>
          <target state="translated">A continuaci&amp;oacute;n, iniciamos un int&amp;eacute;rprete de Python desde nuestro shell y luego cargamos los conjuntos de datos de &lt;code&gt;iris&lt;/code&gt; y &lt;code&gt;digits&lt;/code&gt; . Nuestra convenci&amp;oacute;n de notaci&amp;oacute;n es que &lt;code&gt;$&lt;/code&gt; denota el indicador del shell mientras que &lt;code&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; denota el indicador del int&amp;eacute;rprete de Python:</target>
        </trans-unit>
        <trans-unit id="fe30ab8cfcc104ee94b5fb01793274570a377034" translate="yes" xml:space="preserve">
          <source>In the formula above, \(\mathbf{b}\) and \(\mathbf{c}\) are the intercept vectors for the visible and hidden layers, respectively. The joint probability of the model is defined in terms of the energy:</source>
          <target state="translated">En la fórmula anterior,\N \N los vectores de intercepción de las capas visibles y las ocultas,respectivamente.La probabilidad conjunta del modelo se define en términos de la energía:</target>
        </trans-unit>
        <trans-unit id="66070e8da21856ec34fc0b507e5d723e9475a567" translate="yes" xml:space="preserve">
          <source>In the multi-class and multi-label case, this is the average of the F1 score of each class with weighting depending on the &lt;code&gt;average&lt;/code&gt; parameter.</source>
          <target state="translated">En el caso de m&amp;uacute;ltiples clases y m&amp;uacute;ltiples etiquetas, este es el promedio de la puntuaci&amp;oacute;n F1 de cada clase con una ponderaci&amp;oacute;n que depende del par&amp;aacute;metro &lt;code&gt;average&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="47604d7ff8f733fb868ecbca5a77b859a57fe5aa" translate="yes" xml:space="preserve">
          <source>In the multiclass case, the Matthews correlation coefficient can be &lt;a href=&quot;http://rk.kvl.dk/introduction/index.html&quot;&gt;defined&lt;/a&gt; in terms of a &lt;a href=&quot;generated/sklearn.metrics.confusion_matrix#sklearn.metrics.confusion_matrix&quot;&gt;&lt;code&gt;confusion_matrix&lt;/code&gt;&lt;/a&gt;\(C\) for \(K\) classes. To simplify the definition consider the following intermediate variables:</source>
          <target state="translated">En el caso multiclase, el coeficiente de correlaci&amp;oacute;n de Matthews se puede &lt;a href=&quot;http://rk.kvl.dk/introduction/index.html&quot;&gt;definir&lt;/a&gt; en t&amp;eacute;rminos de una &lt;a href=&quot;generated/sklearn.metrics.confusion_matrix#sklearn.metrics.confusion_matrix&quot;&gt; &lt;code&gt;confusion_matrix&lt;/code&gt; &lt;/a&gt; \ (C \) para clases \ (K \). Para simplificar la definici&amp;oacute;n, considere las siguientes variables intermedias:</target>
        </trans-unit>
        <trans-unit id="b8d01a57cb617acafda7dfb6fdd570d7cb46be7c" translate="yes" xml:space="preserve">
          <source>In the multiclass case, the training algorithm uses the one-vs-rest (OvR) scheme if the &amp;lsquo;multi_class&amp;rsquo; option is set to &amp;lsquo;ovr&amp;rsquo;, and uses the cross- entropy loss if the &amp;lsquo;multi_class&amp;rsquo; option is set to &amp;lsquo;multinomial&amp;rsquo;. (Currently the &amp;lsquo;multinomial&amp;rsquo; option is supported only by the &amp;lsquo;lbfgs&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;newton-cg&amp;rsquo; solvers.)</source>
          <target state="translated">En el caso de multiclase, el algoritmo de entrenamiento usa el esquema one-vs-rest (OvR) si la opci&amp;oacute;n 'multi_class' est&amp;aacute; configurada como 'ovr', y usa la p&amp;eacute;rdida de entrop&amp;iacute;a cruzada si la opci&amp;oacute;n 'multi_class' est&amp;aacute; configurada como 'multinomial '. (Actualmente, la opci&amp;oacute;n 'multinomial' solo es compatible con los solucionadores 'lbfgs', 'sag' y 'newton-cg').</target>
        </trans-unit>
        <trans-unit id="0fc004eb44e3b89b80f2b6796f35d04551e921cc" translate="yes" xml:space="preserve">
          <source>In the multiclass case:</source>
          <target state="translated">En el caso de la multiclase:</target>
        </trans-unit>
        <trans-unit id="d77598124fa8bad46b51e89decd127c4c83bc1e3" translate="yes" xml:space="preserve">
          <source>In the multilabel case with binary label indicators, where the first label set [0,1] has an error:</source>
          <target state="translated">En el caso de las etiquetas con indicadores binarios,donde el primer conjunto de etiquetas [0,1]tiene un error:</target>
        </trans-unit>
        <trans-unit id="4557110f167a92f3d0af48823270c458eb95839b" translate="yes" xml:space="preserve">
          <source>In the multilabel case with binary label indicators:</source>
          <target state="translated">En el caso de las etiquetas múltiples con indicadores de etiquetas binarias:</target>
        </trans-unit>
        <trans-unit id="3dbb497f0422701e359a6bab16a477019a81aa92" translate="yes" xml:space="preserve">
          <source>In the multilabel learning literature, OvR is also known as the binary relevance method.</source>
          <target state="translated">En la literatura de aprendizaje de etiquetas múltiples,el OvR también se conoce como el método de relevancia binaria.</target>
        </trans-unit>
        <trans-unit id="b098a0ed402e179dee6b5de05c6210f893507735" translate="yes" xml:space="preserve">
          <source>In the new space, each dimension is the distance to the cluster centers. Note that even if X is sparse, the array returned by &lt;code&gt;transform&lt;/code&gt; will typically be dense.</source>
          <target state="translated">En el nuevo espacio, cada dimensi&amp;oacute;n es la distancia a los centros de los grupos. Tenga en cuenta que incluso si X es escasa, la matriz devuelta por &lt;code&gt;transform&lt;/code&gt; ser&amp;aacute; normalmente densa.</target>
        </trans-unit>
        <trans-unit id="a90aa674a36fbb7c4f65ac18f5e6a5a0eb4c7bc3" translate="yes" xml:space="preserve">
          <source>In the official &lt;a href=&quot;http://vis-www.cs.umass.edu/lfw/README.txt&quot;&gt;README.txt&lt;/a&gt; this task is described as the &amp;ldquo;Restricted&amp;rdquo; task. As I am not sure as to implement the &amp;ldquo;Unrestricted&amp;rdquo; variant correctly, I left it as unsupported for now.</source>
          <target state="translated">En el &lt;a href=&quot;http://vis-www.cs.umass.edu/lfw/README.txt&quot;&gt;archivo README.txt&lt;/a&gt; oficial, esta tarea se describe como la tarea &quot;Restringida&quot;. Como no estoy seguro de implementar la variante &quot;Sin restricciones&quot; correctamente, la dej&amp;eacute; sin soporte por ahora.</target>
        </trans-unit>
        <trans-unit id="901c760a214576d30b4ced7bbcce771984b42233" translate="yes" xml:space="preserve">
          <source>In the simple one-dimensional problem that we have seen in the example it is easy to see whether the estimator suffers from bias or variance. However, in high-dimensional spaces, models can become very difficult to visualize. For this reason, it is often helpful to use the tools described below.</source>
          <target state="translated">En el simple problema unidimensional que hemos visto en el ejemplo es fácil ver si el estimador sufre de sesgo o de varianza.Sin embargo,en espacios de alta dimensión,los modelos pueden llegar a ser muy difíciles de visualizar.Por esta razón,a menudo es útil utilizar las herramientas que se describen a continuación.</target>
        </trans-unit>
        <trans-unit id="bada0a0c8458a65354b2c23e7134e865cc4bf85c" translate="yes" xml:space="preserve">
          <source>In the single label multiclass case, the rows of the returned matrix sum to 1.</source>
          <target state="translated">En el caso de la multiclase de etiqueta única,las filas de la matriz devuelta suman 1.</target>
        </trans-unit>
        <trans-unit id="696912c12d134eed0fdc2e472302634288905dc5" translate="yes" xml:space="preserve">
          <source>In the small-samples situation, in which &lt;code&gt;n_samples&lt;/code&gt; is on the order of &lt;code&gt;n_features&lt;/code&gt; or smaller, sparse inverse covariance estimators tend to work better than shrunk covariance estimators. However, in the opposite situation, or for very correlated data, they can be numerically unstable. In addition, unlike shrinkage estimators, sparse estimators are able to recover off-diagonal structure.</source>
          <target state="translated">En la situaci&amp;oacute;n de muestras peque&amp;ntilde;as, en la que &lt;code&gt;n_samples&lt;/code&gt; est&amp;aacute; en el orden de &lt;code&gt;n_features&lt;/code&gt; o m&amp;aacute;s peque&amp;ntilde;o, los estimadores de covarianza inversa dispersos tienden a funcionar mejor que los estimadores de covarianza reducidos. Sin embargo, en la situaci&amp;oacute;n opuesta, o para datos muy correlacionados, pueden ser num&amp;eacute;ricamente inestables. Adem&amp;aacute;s, a diferencia de los estimadores de contracci&amp;oacute;n, los estimadores dispersos pueden recuperar la estructura fuera de la diagonal.</target>
        </trans-unit>
        <trans-unit id="d5f33dda5b96ece3c041650e9fa8db02e62bfd46" translate="yes" xml:space="preserve">
          <source>In the specific case of scikit-learn, it may be better to use joblib&amp;rsquo;s replacement of pickle (&lt;code&gt;joblib.dump&lt;/code&gt; &amp;amp; &lt;code&gt;joblib.load&lt;/code&gt;), which is more efficient on objects that carry large numpy arrays internally as is often the case for fitted scikit-learn estimators, but can only pickle to the disk and not to a string:</source>
          <target state="translated">En el caso espec&amp;iacute;fico de scikit-learn, puede ser mejor usar el reemplazo de pickle de &lt;code&gt;joblib.dump&lt;/code&gt; ( joblib.dump &amp;amp; &lt;code&gt;joblib.load&lt;/code&gt; ), que es m&amp;aacute;s eficiente en objetos que transportan matrices de n&amp;uacute;meros grandes internamente, como suele ser el caso de scikit- aprende estimadores, pero solo puede escanear en el disco y no en una cadena:</target>
        </trans-unit>
        <trans-unit id="4d7c6f4a78fb7d42f5b6b076760e4c0fb27e052c" translate="yes" xml:space="preserve">
          <source>In the specific case of scikit-learn, it may be more interesting to use joblib&amp;rsquo;s replacement for pickle (&lt;code&gt;joblib.dump&lt;/code&gt; &amp;amp; &lt;code&gt;joblib.load&lt;/code&gt;), which is more efficient on big data but it can only pickle to the disk and not to a string:</source>
          <target state="translated">En el caso espec&amp;iacute;fico de scikit-learn, puede ser m&amp;aacute;s interesante usar el reemplazo de pickle de &lt;code&gt;joblib.dump&lt;/code&gt; ( joblib.dump &amp;amp; &lt;code&gt;joblib.load&lt;/code&gt; ), que es m&amp;aacute;s eficiente en big data pero solo puede hacer pickle en el disco y no en una cadena :</target>
        </trans-unit>
        <trans-unit id="4e8940d2e745f9a24bd23b0a1547dcf715a870bb" translate="yes" xml:space="preserve">
          <source>In the total set of features, only the 4 first ones are significant. We can see that they have the highest score with univariate feature selection. The SVM assigns a large weight to one of these features, but also Selects many of the non-informative features. Applying univariate feature selection before the SVM increases the SVM weight attributed to the significant features, and will thus improve classification.</source>
          <target state="translated">En el conjunto total de características,sólo las 4 primeras son significativas.Podemos ver que tienen la puntuación más alta con la selección de rasgos univariantes.La SVM asigna un gran peso a uno de estos rasgos,pero también selecciona muchos de los rasgos no informativos.Aplicando la selección de rasgos univariantes antes de la SVM aumenta el peso de la SVM atribuido a los rasgos significativos,y así mejorará la clasificación.</target>
        </trans-unit>
        <trans-unit id="a3dd53135ff49dbe7e421a248bf614a3ea8f0d5e" translate="yes" xml:space="preserve">
          <source>In the vector quantization literature, &lt;code&gt;cluster_centers_&lt;/code&gt; is called the code book and each value returned by &lt;code&gt;predict&lt;/code&gt; is the index of the closest code in the code book.</source>
          <target state="translated">En la literatura de cuantificaci&amp;oacute;n de vectores, &lt;code&gt;cluster_centers_&lt;/code&gt; se llama libro de c&amp;oacute;digos y cada valor devuelto por &lt;code&gt;predict&lt;/code&gt; es el &amp;iacute;ndice del c&amp;oacute;digo m&amp;aacute;s cercano en el libro de c&amp;oacute;digos.</target>
        </trans-unit>
        <trans-unit id="9a63d5086bf9614df56a7612405271e0122a8145" translate="yes" xml:space="preserve">
          <source>In their 2004 paper &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;, O. Ledoit and M. Wolf propose a formula to compute the optimal shrinkage coefficient \(\alpha\) that minimizes the Mean Squared Error between the estimated and the real covariance matrix.</source>
          <target state="translated">En su art&amp;iacute;culo de 2004 &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt; , O. Ledoit y M. Wolf proponen una f&amp;oacute;rmula para calcular el coeficiente de contracci&amp;oacute;n &amp;oacute;ptimo \ (\ alpha \) que minimiza el error cuadr&amp;aacute;tico medio entre la matriz de covarianza estimada y la real.</target>
        </trans-unit>
        <trans-unit id="ee9767309b3df05ebf7c392a0bb4e8915eee3d46" translate="yes" xml:space="preserve">
          <source>In these settings, the &lt;a href=&quot;../../modules/clustering#spectral-clustering&quot;&gt;Spectral clustering&lt;/a&gt; approach solves the problem know as &amp;lsquo;normalized graph cuts&amp;rsquo;: the image is seen as a graph of connected voxels, and the spectral clustering algorithm amounts to choosing graph cuts defining regions while minimizing the ratio of the gradient along the cut, and the volume of the region.</source>
          <target state="translated">En estas configuraciones, el enfoque de &lt;a href=&quot;../../modules/clustering#spectral-clustering&quot;&gt;agrupamiento espectral&lt;/a&gt; resuelve el problema conocido como 'cortes de gr&amp;aacute;fico normalizados': la imagen se ve como un gr&amp;aacute;fico de v&amp;oacute;xeles conectados, y el algoritmo de agrupamiento espectral equivale a elegir cortes de gr&amp;aacute;fico que definen regiones mientras minimiza la relaci&amp;oacute;n del gradiente a lo largo de el corte y el volumen de la regi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="e2e4475ec0999dd975ba681e19179d817d6681ae" translate="yes" xml:space="preserve">
          <source>In this case we would like to know if a model trained on a particular set of groups generalizes well to the unseen groups. To measure this, we need to ensure that all the samples in the validation fold come from groups that are not represented at all in the paired training fold.</source>
          <target state="translated">En este caso nos gustaría saber si un modelo entrenado en un conjunto particular de grupos se generaliza bien a los grupos invisibles.Para medir esto,necesitamos asegurarnos de que todas las muestras del pliegue de validación proceden de grupos que no están representados en absoluto en el pliegue de entrenamiento emparejado.</target>
        </trans-unit>
        <trans-unit id="8e6586aaac37d3a887b7276aee6797fdd6471b11" translate="yes" xml:space="preserve">
          <source>In this case, &lt;code&gt;X_train&lt;/code&gt; and &lt;code&gt;X_test&lt;/code&gt; are guaranteed to have the same number of features. Another way to achieve the same result is to fix the number of features:</source>
          <target state="translated">En este caso, se garantiza que &lt;code&gt;X_train&lt;/code&gt; y &lt;code&gt;X_test&lt;/code&gt; tendr&amp;aacute;n la misma cantidad de funciones. Otra forma de lograr el mismo resultado es corregir el n&amp;uacute;mero de funciones:</target>
        </trans-unit>
        <trans-unit id="c94c921d6a6a8582b29da8ef5a3a44fe1ea80a89" translate="yes" xml:space="preserve">
          <source>In this case, the classifier is fit upon instances each assigned multiple labels. The &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.multilabelbinarizer#sklearn.preprocessing.MultiLabelBinarizer&quot;&gt;&lt;code&gt;MultiLabelBinarizer&lt;/code&gt;&lt;/a&gt; is used to binarize the 2d array of multilabels to &lt;code&gt;fit&lt;/code&gt; upon. As a result, &lt;code&gt;predict()&lt;/code&gt; returns a 2d array with multiple predicted labels for each instance.</source>
          <target state="translated">En este caso, el clasificador se ajusta a instancias a cada una de las cuales se le asignaron m&amp;uacute;ltiples etiquetas. El &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.multilabelbinarizer#sklearn.preprocessing.MultiLabelBinarizer&quot;&gt; &lt;code&gt;MultiLabelBinarizer&lt;/code&gt; &lt;/a&gt; se utiliza para binarizar la matriz 2D de multilabels para &lt;code&gt;fit&lt;/code&gt; sobre. Como resultado, &lt;code&gt;predict()&lt;/code&gt; devuelve una matriz 2d con m&amp;uacute;ltiples etiquetas predichas para cada instancia.</target>
        </trans-unit>
        <trans-unit id="4367a423584d0b6ba622189fa17b21bb3e206f2c" translate="yes" xml:space="preserve">
          <source>In this case, the cross-validation retained the same ratio of classes across each CV split. Next we&amp;rsquo;ll visualize this behavior for a number of CV iterators.</source>
          <target state="translated">En este caso, la validaci&amp;oacute;n cruzada retuvo la misma proporci&amp;oacute;n de clases en cada divisi&amp;oacute;n de CV. A continuaci&amp;oacute;n, visualizaremos este comportamiento para varios iteradores de CV.</target>
        </trans-unit>
        <trans-unit id="d121f450bc55250670235f93c8cd2083eb40a561" translate="yes" xml:space="preserve">
          <source>In this context, we can define the notions of precision, recall and F-measure:</source>
          <target state="translated">En este contexto,podemos definir las nociones de precisión,recuerdo y medida F:</target>
        </trans-unit>
        <trans-unit id="6b7e5d4a758a26d1b659ba54387246d5cebcf12f" translate="yes" xml:space="preserve">
          <source>In this example the dependent variable Y is set as a function of the input features: y = X*w + c. The coefficient vector w is randomly sampled from a normal distribution, whereas the bias term c is set to a constant.</source>
          <target state="translated">En este ejemplo,la variable dependiente Y se establece en función de las características de entrada:y=X*w+c.El vector del coeficiente w se muestrea aleatoriamente a partir de una distribución normal,mientras que el término de sesgo c se establece como una constante.</target>
        </trans-unit>
        <trans-unit id="5d530c717737ac885c81ddc70c9c4fe51f2f2e42" translate="yes" xml:space="preserve">
          <source>In this example the silhouette analysis is used to choose an optimal value for &lt;code&gt;n_clusters&lt;/code&gt;. The silhouette plot shows that the &lt;code&gt;n_clusters&lt;/code&gt; value of 3, 5 and 6 are a bad pick for the given data due to the presence of clusters with below average silhouette scores and also due to wide fluctuations in the size of the silhouette plots. Silhouette analysis is more ambivalent in deciding between 2 and 4.</source>
          <target state="translated">En este ejemplo, el an&amp;aacute;lisis de silueta se utiliza para elegir un valor &amp;oacute;ptimo para &lt;code&gt;n_clusters&lt;/code&gt; . El gr&amp;aacute;fico de silueta muestra que el valor de &lt;code&gt;n_clusters&lt;/code&gt; de 3, 5 y 6 es una mala elecci&amp;oacute;n para los datos dados debido a la presencia de cl&amp;uacute;steres con puntuaciones de silueta por debajo del promedio y tambi&amp;eacute;n debido a amplias fluctuaciones en el tama&amp;ntilde;o de los gr&amp;aacute;ficos de silueta. El an&amp;aacute;lisis de silueta es m&amp;aacute;s ambivalente al decidir entre 2 y 4.</target>
        </trans-unit>
        <trans-unit id="550c896ceafe31d2e76547c4031642097a79581f" translate="yes" xml:space="preserve">
          <source>In this example we compare the various initialization strategies for K-means in terms of runtime and quality of the results.</source>
          <target state="translated">En este ejemplo se comparan las diversas estrategias de inicialización de los medios K en cuanto al tiempo de ejecución y la calidad de los resultados.</target>
        </trans-unit>
        <trans-unit id="d9bed364e1f96090d42e72d8ad4e31b8f81dfc1d" translate="yes" xml:space="preserve">
          <source>In this example we prefer the &lt;code&gt;elasticnet&lt;/code&gt; penalty as it is often a good compromise between model compactness and prediction power. One can also further tune the &lt;code&gt;l1_ratio&lt;/code&gt; parameter (in combination with the regularization strength &lt;code&gt;alpha&lt;/code&gt;) to control this tradeoff.</source>
          <target state="translated">En este ejemplo preferimos la penalizaci&amp;oacute;n de &lt;code&gt;elasticnet&lt;/code&gt; , ya que a menudo es un buen compromiso entre la compacidad del modelo y el poder de predicci&amp;oacute;n. Tambi&amp;eacute;n se puede ajustar a&amp;uacute;n m&amp;aacute;s el par&amp;aacute;metro &lt;code&gt;l1_ratio&lt;/code&gt; (en combinaci&amp;oacute;n con la fuerza de regularizaci&amp;oacute;n &lt;code&gt;alpha&lt;/code&gt; ) para controlar esta compensaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="5f4ca84332e1fc2168e90c43c86e1d784ebd5f8c" translate="yes" xml:space="preserve">
          <source>In this example we see how to robustly fit a linear model to faulty data using the RANSAC algorithm.</source>
          <target state="translated">En este ejemplo vemos cómo ajustar de forma robusta un modelo lineal a los datos defectuosos utilizando el algoritmo RANSAC.</target>
        </trans-unit>
        <trans-unit id="38fc37287fc51222e73dd7c83e6c92e563107ff6" translate="yes" xml:space="preserve">
          <source>In this example you might try to:</source>
          <target state="translated">En este ejemplo podrías intentarlo:</target>
        </trans-unit>
        <trans-unit id="8a61e0fa0737723bbfe9d0174ce3aad285419f4d" translate="yes" xml:space="preserve">
          <source>In this example, &lt;code&gt;X&lt;/code&gt; is &lt;code&gt;float32&lt;/code&gt;, which is cast to &lt;code&gt;float64&lt;/code&gt; by &lt;code&gt;fit_transform(X)&lt;/code&gt;.</source>
          <target state="translated">En este ejemplo, &lt;code&gt;X&lt;/code&gt; es &lt;code&gt;float32&lt;/code&gt; , que &lt;code&gt;fit_transform(X)&lt;/code&gt; &lt;code&gt;float64&lt;/code&gt; en float64 .</target>
        </trans-unit>
        <trans-unit id="2812da8873763c11175cae962f9ab9000ab381c4" translate="yes" xml:space="preserve">
          <source>In this example, an image with connected circles is generated and spectral clustering is used to separate the circles.</source>
          <target state="translated">En este ejemplo,se genera una imagen con círculos conectados y se utiliza la agrupación espectral para separar los círculos.</target>
        </trans-unit>
        <trans-unit id="69af0b849be70a0524a821dde21a609feb16811a" translate="yes" xml:space="preserve">
          <source>In this example, pixels are represented in a 3D-space and K-means is used to find 64 color clusters. In the image processing literature, the codebook obtained from K-means (the cluster centers) is called the color palette. Using a single byte, up to 256 colors can be addressed, whereas an RGB encoding requires 3 bytes per pixel. The GIF file format, for example, uses such a palette.</source>
          <target state="translated">En este ejemplo,los píxeles están representados en un espacio 3D y se utiliza la media K para encontrar 64 grupos de colores.En la literatura de procesamiento de imágenes,el libro de códigos obtenido de los K-means (los centros de los cúmulos)se llama la paleta de colores.Usando un solo byte,se pueden direccionar hasta 256 colores,mientras que una codificación RGB requiere 3 bytes por píxel.El formato de archivo GIF,por ejemplo,utiliza esta paleta.</target>
        </trans-unit>
        <trans-unit id="2f0fb947da0f2bfc5faf32b771a3cb10ff049eda" translate="yes" xml:space="preserve">
          <source>In this example, the numeric data is standard-scaled after mean-imputation, while the categorical data is one-hot encoded after imputing missing values with a new category (&lt;code&gt;'missing'&lt;/code&gt;).</source>
          <target state="translated">En este ejemplo, los datos num&amp;eacute;ricos tienen una escala est&amp;aacute;ndar despu&amp;eacute;s de la imputaci&amp;oacute;n de la media, mientras que los datos categ&amp;oacute;ricos se codifican de forma &amp;uacute;nica despu&amp;eacute;s de imputar los valores faltantes con una nueva categor&amp;iacute;a ( &lt;code&gt;'missing'&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="d88656bc2e040320cf9595554acac12be98f916c" translate="yes" xml:space="preserve">
          <source>In this example, we compare the estimation errors that are made when using various types of location and covariance estimates on contaminated Gaussian distributed data sets:</source>
          <target state="translated">En este ejemplo se comparan los errores de estimación que se cometen al utilizar diversos tipos de estimaciones de localización y covarianza en conjuntos de datos distribuidos de Gauss contaminados:</target>
        </trans-unit>
        <trans-unit id="2b7bcaf87ef3b0730f7083836942b0b038810927" translate="yes" xml:space="preserve">
          <source>In this example, we give an overview of the &lt;a href=&quot;../../modules/generated/sklearn.compose.transformedtargetregressor#sklearn.compose.TransformedTargetRegressor&quot;&gt;&lt;code&gt;sklearn.compose.TransformedTargetRegressor&lt;/code&gt;&lt;/a&gt;. Two examples illustrate the benefit of transforming the targets before learning a linear regression model. The first example uses synthetic data while the second example is based on the Boston housing data set.</source>
          <target state="translated">En este ejemplo, ofrecemos una descripci&amp;oacute;n general de &lt;a href=&quot;../../modules/generated/sklearn.compose.transformedtargetregressor#sklearn.compose.TransformedTargetRegressor&quot;&gt; &lt;code&gt;sklearn.compose.TransformedTargetRegressor&lt;/code&gt; &lt;/a&gt; . Dos ejemplos ilustran el beneficio de transformar los objetivos antes de aprender un modelo de regresi&amp;oacute;n lineal. El primer ejemplo utiliza datos sint&amp;eacute;ticos, mientras que el segundo ejemplo se basa en el conjunto de datos de vivienda de Boston.</target>
        </trans-unit>
        <trans-unit id="fd9410f53a0f1d1aa2f5ff77c7bafaf9751d4c08" translate="yes" xml:space="preserve">
          <source>In this example, we set the value of &lt;code&gt;gamma&lt;/code&gt; manually. To find good values for these parameters, we can use tools such as &lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;grid search&lt;/a&gt; and &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;cross validation&lt;/a&gt;.</source>
          <target state="translated">En este ejemplo, establecemos el valor de &lt;code&gt;gamma&lt;/code&gt; manualmente. Para encontrar buenos valores para estos par&amp;aacute;metros, podemos utilizar herramientas como &lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;la b&amp;uacute;squeda de cuadr&amp;iacute;culas&lt;/a&gt; y &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;la validaci&amp;oacute;n cruzada&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="9e0782ea6d7859077c07d60aaa0a30b1c4373f50" translate="yes" xml:space="preserve">
          <source>In this plot you can see the training scores and validation scores of an SVM for different values of the kernel parameter gamma. For very low values of gamma, you can see that both the training score and the validation score are low. This is called underfitting. Medium values of gamma will result in high values for both scores, i.e. the classifier is performing fairly well. If gamma is too high, the classifier will overfit, which means that the training score is good but the validation score is poor.</source>
          <target state="translated">En este gráfico se pueden ver los resultados de entrenamiento y los resultados de validación de un SVM para diferentes valores del parámetro gamma del núcleo.Para valores muy bajos de gamma,puedes ver que tanto la puntuación de entrenamiento como la puntuación de validación son bajas.Esto se denomina infravaloración.Los valores medios de gamma darán como resultado valores altos para ambas puntuaciones,es decir,el clasificador está funcionando bastante bien.Si el gamma es demasiado alto,el clasificador se sobreajustará,lo que significa que la puntuación de entrenamiento es buena pero la puntuación de validación es pobre.</target>
        </trans-unit>
        <trans-unit id="2c39a03080473177a8509645110953edafebbd76" translate="yes" xml:space="preserve">
          <source>In this scheme, features and samples are defined as follows:</source>
          <target state="translated">En este esquema,las características y las muestras se definen de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="5941fbb58c226f551ff80660bcd51a84bcc2bae1" translate="yes" xml:space="preserve">
          <source>In this section we will see how to:</source>
          <target state="translated">En esta sección veremos cómo hacerlo:</target>
        </trans-unit>
        <trans-unit id="6ce5845b6414a0cfccffc603f3efdd4b47c7ce4b" translate="yes" xml:space="preserve">
          <source>In this section, we introduce the &lt;a href=&quot;https://en.wikipedia.org/wiki/Machine_learning&quot;&gt;machine learning&lt;/a&gt; vocabulary that we use throughout scikit-learn and give a simple learning example.</source>
          <target state="translated">En esta secci&amp;oacute;n, presentamos el vocabulario de &lt;a href=&quot;https://en.wikipedia.org/wiki/Machine_learning&quot;&gt;aprendizaje autom&amp;aacute;tico&lt;/a&gt; que usamos en scikit-learn y damos un ejemplo de aprendizaje simple.</target>
        </trans-unit>
        <trans-unit id="e7b54ae8e73f20fa370a273bbb52814367b82582" translate="yes" xml:space="preserve">
          <source>In this snippet we make use of a &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;sklearn.svm.LinearSVC&lt;/code&gt;&lt;/a&gt; coupled with &lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt;&lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt;&lt;/a&gt; to evaluate feature importances and select the most relevant features. Then, a &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;sklearn.ensemble.RandomForestClassifier&lt;/code&gt;&lt;/a&gt; is trained on the transformed output, i.e. using only relevant features. You can perform similar operations with the other feature selection methods and also classifiers that provide a way to evaluate feature importances of course. See the &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt; examples for more details.</source>
          <target state="translated">En este fragmento, utilizamos &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;sklearn.svm.LinearSVC&lt;/code&gt; &lt;/a&gt; junto con &lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt; &lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt; &lt;/a&gt; para evaluar la importancia de las caracter&amp;iacute;sticas y seleccionar las caracter&amp;iacute;sticas m&amp;aacute;s relevantes. Luego, un &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt; &lt;code&gt;sklearn.ensemble.RandomForestClassifier&lt;/code&gt; &lt;/a&gt; se entrena en la salida transformada, es decir, usando solo caracter&amp;iacute;sticas relevantes. Puede realizar operaciones similares con los otros m&amp;eacute;todos de selecci&amp;oacute;n de caracter&amp;iacute;sticas y tambi&amp;eacute;n clasificadores que brindan una forma de evaluar la importancia de las caracter&amp;iacute;sticas, por supuesto. Consulte los ejemplos de &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="87aee0924ee2a28e2d573efd8e050c2a5c1632a3" translate="yes" xml:space="preserve">
          <source>In unsupervised learning we only have a dataset \(X = \{x_1, x_2, \dots, x_n \}\). How can this dataset be described mathematically? A very simple &lt;code&gt;continuous latent variable&lt;/code&gt; model for \(X\) is</source>
          <target state="translated">En el aprendizaje no supervisado, solo tenemos un conjunto de datos \ (X = \ {x_1, x_2, \ dots, x_n \} \). &amp;iquest;C&amp;oacute;mo se puede describir matem&amp;aacute;ticamente este conjunto de datos? Un modelo de &lt;code&gt;continuous latent variable&lt;/code&gt; muy simple para \ (X \) es</target>
        </trans-unit>
        <trans-unit id="c89a6ca6f29b888687c7afd577a282b5b95a2be5" translate="yes" xml:space="preserve">
          <source>Incorporating statistics from test data into the preprocessors makes cross-validation scores unreliable (known as &lt;em&gt;data leakage&lt;/em&gt;), for example in the case of scalers or imputing missing values.</source>
          <target state="translated">La incorporaci&amp;oacute;n de estad&amp;iacute;sticas de datos de prueba en los preprocesadores hace que las puntuaciones de validaci&amp;oacute;n cruzada no sean fiables (lo que se conoce como &lt;em&gt;fuga de datos&lt;/em&gt; ), por ejemplo, en el caso de escaladores o imputaci&amp;oacute;n de valores perdidos.</target>
        </trans-unit>
        <trans-unit id="4c33f1e1286c254eaae3fbe03197d5578f08f56a" translate="yes" xml:space="preserve">
          <source>Increasing &lt;code&gt;max_depth&lt;/code&gt; for AdaBoost lowers the standard deviation of the scores (but the average score does not improve).</source>
          <target state="translated">El aumento de &lt;code&gt;max_depth&lt;/code&gt; para AdaBoost reduce la desviaci&amp;oacute;n est&amp;aacute;ndar de las puntuaciones (pero la puntuaci&amp;oacute;n media no mejora).</target>
        </trans-unit>
        <trans-unit id="e79b1358981354168a853701629e2643ba45bf93" translate="yes" xml:space="preserve">
          <source>Increasing false positive rates such that element i is the false positive rate of predictions with score &amp;gt;= thresholds[i].</source>
          <target state="translated">Incrementar las tasas de falsos positivos de manera que el elemento i sea la tasa de falsos positivos de predicciones con una puntuaci&amp;oacute;n&amp;gt; = umbrales [i].</target>
        </trans-unit>
        <trans-unit id="3ca08d3a2216068596512fa76cc1f85e2464a3a8" translate="yes" xml:space="preserve">
          <source>Increasing thresholds on the decision function used to compute precision and recall.</source>
          <target state="translated">Aumentar los umbrales de la función de decisión utilizada para calcular la precisión y el recuerdo.</target>
        </trans-unit>
        <trans-unit id="7ae5f53b337e575381bac1d47d2d4a4d2e4839b6" translate="yes" xml:space="preserve">
          <source>Increasing true positive rates such that element i is the true positive rate of predictions with score &amp;gt;= thresholds[i].</source>
          <target state="translated">Incrementar las tasas de verdaderos positivos de manera que el elemento i sea la tasa de verdaderos positivos de predicciones con una puntuaci&amp;oacute;n&amp;gt; = umbrales [i].</target>
        </trans-unit>
        <trans-unit id="54206634ab03f8962d59d7c24e12c85ebd45b5e1" translate="yes" xml:space="preserve">
          <source>Incremental PCA</source>
          <target state="translated">PCA incremental</target>
        </trans-unit>
        <trans-unit id="acaf3165fc4e0ddec759b9648ee12eed48089691" translate="yes" xml:space="preserve">
          <source>Incremental fit on a batch of samples.</source>
          <target state="translated">Ajuste incremental en un lote de muestras.</target>
        </trans-unit>
        <trans-unit id="a79a34aec33f8c8b084e4316cf8e243a4d6601e6" translate="yes" xml:space="preserve">
          <source>Incremental fit with X.</source>
          <target state="translated">Ajuste incremental con X.</target>
        </trans-unit>
        <trans-unit id="87210470540ea5af2ee40f330fdeea4017f1c0aa" translate="yes" xml:space="preserve">
          <source>Incremental fit with X. All of X is processed as a single batch.</source>
          <target state="translated">Ajuste incremental con X.Todo X se procesa como un solo lote.</target>
        </trans-unit>
        <trans-unit id="5b9d567927b0a80924b0a28fdea6cf19b23d2e57" translate="yes" xml:space="preserve">
          <source>Incremental principal component analysis (IPCA) is typically used as a replacement for principal component analysis (PCA) when the dataset to be decomposed is too large to fit in memory. IPCA builds a low-rank approximation for the input data using an amount of memory which is independent of the number of input data samples. It is still dependent on the input data features, but changing the batch size allows for control of memory usage.</source>
          <target state="translated">El análisis incremental de componentes principales (IPCA)se utiliza normalmente como sustituto del análisis de componentes principales (PCA)cuando el conjunto de datos a descomponer es demasiado grande para caber en la memoria.El IPCA construye una aproximación de bajo rango para los datos de entrada utilizando una cantidad de memoria que es independiente del número de muestras de datos de entrada.Sigue dependiendo de las características de los datos de entrada,pero el cambio del tamaño del lote permite controlar el uso de la memoria.</target>
        </trans-unit>
        <trans-unit id="66088e706ece2d903ed2071fa2d42be9315774b6" translate="yes" xml:space="preserve">
          <source>Incremental principal components analysis (IPCA).</source>
          <target state="translated">Análisis de componentes principales incrementales (IPCA).</target>
        </trans-unit>
        <trans-unit id="ef7722207a6c2343d08e45f401cd00ccd19381c7" translate="yes" xml:space="preserve">
          <source>Incrementally fit the model to data.</source>
          <target state="translated">Incrementar el ajuste del modelo a los datos.</target>
        </trans-unit>
        <trans-unit id="505bf67b8aa7cec37d64a9ce9b03d73f70b38b8b" translate="yes" xml:space="preserve">
          <source>Incrementally fit the model to data. Fit a separate model for each output variable.</source>
          <target state="translated">Incrementar el ajuste del modelo a los datos.Ajustar un modelo separado para cada variable de salida.</target>
        </trans-unit>
        <trans-unit id="9e12e704fa3eb16be83d58c2167c9c4f83379a1d" translate="yes" xml:space="preserve">
          <source>Indeed many estimators are designed with the assumption that each feature takes values close to zero or more importantly that all features vary on comparable scales. In particular, metric-based and gradient-based estimators often assume approximately standardized data (centered features with unit variances). A notable exception are decision tree-based estimators that are robust to arbitrary scaling of the data.</source>
          <target state="translated">De hecho,muchos estimadores están diseñados con la suposición de que cada característica toma valores cercanos a cero o,lo que es más importante,que todas las características varían en escalas comparables.En particular,los estimadores basados en el sistema métrico y en el gradiente suelen suponer datos aproximadamente normalizados (características centradas con variaciones de unidades).Una excepción notable son los estimadores basados en árboles de decisión que son robustos a la escala arbitraria de los datos.</target>
        </trans-unit>
        <trans-unit id="7933c6d72de999f40e22d3286d9c782fd636305b" translate="yes" xml:space="preserve">
          <source>Independent Component Analysis: ICA</source>
          <target state="translated">Análisis de componentes independientes:ICA</target>
        </trans-unit>
        <trans-unit id="d170598045cdc9e2df037718a96d1706ed03e640" translate="yes" xml:space="preserve">
          <source>Independent component analysis separates a multivariate signal into additive subcomponents that are maximally independent. It is implemented in scikit-learn using the &lt;a href=&quot;generated/sklearn.decomposition.fastica#sklearn.decomposition.FastICA&quot;&gt;&lt;code&gt;Fast ICA&lt;/code&gt;&lt;/a&gt; algorithm. Typically, ICA is not used for reducing dimensionality but for separating superimposed signals. Since the ICA model does not include a noise term, for the model to be correct, whitening must be applied. This can be done internally using the whiten argument or manually using one of the PCA variants.</source>
          <target state="translated">El an&amp;aacute;lisis de componentes independientes separa una se&amp;ntilde;al multivariante en subcomponentes aditivos que son m&amp;aacute;ximamente independientes. Se implementa en scikit-learn usando el algoritmo &lt;a href=&quot;generated/sklearn.decomposition.fastica#sklearn.decomposition.FastICA&quot;&gt; &lt;code&gt;Fast ICA&lt;/code&gt; &lt;/a&gt; . Normalmente, ICA no se utiliza para reducir la dimensionalidad sino para separar se&amp;ntilde;ales superpuestas. Dado que el modelo ICA no incluye un t&amp;eacute;rmino de ruido, para que el modelo sea correcto, se debe aplicar blanqueamiento. Esto se puede hacer internamente usando el argumento blanquear o manualmente usando una de las variantes de PCA.</target>
        </trans-unit>
        <trans-unit id="420bdf88d0c37e0c49c684e7be83be0c3065749b" translate="yes" xml:space="preserve">
          <source>Independent component analysis, a latent variable model with non-Gaussian latent variables.</source>
          <target state="translated">Análisis de componentes independientes,un modelo de variables latentes con variables latentes no gausianas.</target>
        </trans-unit>
        <trans-unit id="e81fd2ba1ed4351b51becec6b3e044be03272d29" translate="yes" xml:space="preserve">
          <source>Independent parameter in poly/sigmoid kernel.</source>
          <target state="translated">Parámetro independiente en el núcleo poli/sigmoide.</target>
        </trans-unit>
        <trans-unit id="75b2e172573134b992419919380eaa4d379125c8" translate="yes" xml:space="preserve">
          <source>Independent parameter in poly/sigmoid kernel. 0 by default.</source>
          <target state="translated">Parámetro independiente en el núcleo poli/sigmoide.0 por defecto.</target>
        </trans-unit>
        <trans-unit id="93ccb8f475af3ead0828a4d704d80fd7c1bcca2a" translate="yes" xml:space="preserve">
          <source>Independent term in decision function.</source>
          <target state="translated">Término independiente en la función de decisión.</target>
        </trans-unit>
        <trans-unit id="d60b4ce63cb13d9b546e71bb468305b122e1ff12" translate="yes" xml:space="preserve">
          <source>Independent term in decision function. Set to 0.0 if &lt;code&gt;fit_intercept = False&lt;/code&gt;.</source>
          <target state="translated">T&amp;eacute;rmino independiente en funci&amp;oacute;n de decisi&amp;oacute;n. Establecer en 0.0 si &lt;code&gt;fit_intercept = False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="62ca36e367478a373b265bf6692ac1dd0b87c736" translate="yes" xml:space="preserve">
          <source>Independent term in kernel function. It is only significant in &amp;lsquo;poly&amp;rsquo; and &amp;lsquo;sigmoid&amp;rsquo;.</source>
          <target state="translated">T&amp;eacute;rmino independiente en funci&amp;oacute;n del kernel. Solo es significativo en 'poli' y 'sigmoide'.</target>
        </trans-unit>
        <trans-unit id="498514c5789196d4e7f38be6d2ccefad9084f660" translate="yes" xml:space="preserve">
          <source>Independent term in poly and sigmoid kernels. Ignored by other kernels.</source>
          <target state="translated">Término independiente en los núcleos poli y sigmoide.Ignorado por otros núcleos.</target>
        </trans-unit>
        <trans-unit id="c818388cffefe0c1449b9099e6b8c434f2466b05" translate="yes" xml:space="preserve">
          <source>Independent term in the decision function.</source>
          <target state="translated">Término independiente en la función de decisión.</target>
        </trans-unit>
        <trans-unit id="b8069da00c91cf6e966b739b57f9cbe347e859d2" translate="yes" xml:space="preserve">
          <source>Independent term in the linear model.</source>
          <target state="translated">Término independiente en el modelo lineal.</target>
        </trans-unit>
        <trans-unit id="5c78017fad7dc4be13e21b61b07a09cb5931df33" translate="yes" xml:space="preserve">
          <source>Index of the cluster each sample belongs to.</source>
          <target state="translated">Índice del grupo al que pertenece cada muestra.</target>
        </trans-unit>
        <trans-unit id="79bbc01c7afbd569e88078c06011f6a142dc18ba" translate="yes" xml:space="preserve">
          <source>Index of the column of X to be swapped.</source>
          <target state="translated">Índice de la columna de X a intercambiar.</target>
        </trans-unit>
        <trans-unit id="ed1d58c02de7a13d74564b832a9effc7dd7512f7" translate="yes" xml:space="preserve">
          <source>Index of the row of X to be swapped.</source>
          <target state="translated">Índice de la fila de X a intercambiar.</target>
        </trans-unit>
        <trans-unit id="ec76f2d92b2be403363a104dc4a87849c9c331a9" translate="yes" xml:space="preserve">
          <source>Indexable data-structures can be arrays, lists, dataframes or scipy sparse matrices with consistent first dimension.</source>
          <target state="translated">Las estructuras de datos indexables pueden ser matrices,listas,marcos de datos o matrices de scipy sparse con una primera dimensión consistente.</target>
        </trans-unit>
        <trans-unit id="436737ead6b730ec05aa4979d3ab186eb46b0b4a" translate="yes" xml:space="preserve">
          <source>Indexes the data on its second axis. Integers are interpreted as positional columns, while strings can reference DataFrame columns by name. A scalar string or int should be used where &lt;code&gt;transformer&lt;/code&gt; expects X to be a 1d array-like (vector), otherwise a 2d array will be passed to the transformer. A callable is passed the input data &lt;code&gt;X&lt;/code&gt; and can return any of the above.</source>
          <target state="translated">Indexa los datos en su segundo eje. Los enteros se interpretan como columnas posicionales, mientras que las cadenas pueden hacer referencia a las columnas DataFrame por su nombre. Se debe usar una cadena escalar o int donde el &lt;code&gt;transformer&lt;/code&gt; espera que X sea un vector similar a una matriz 1d; de lo contrario, se pasar&amp;aacute; una matriz 2d al transformador. A un invocable se le pasan los datos de entrada &lt;code&gt;X&lt;/code&gt; y puede devolver cualquiera de los anteriores.</target>
        </trans-unit>
        <trans-unit id="33324894ea0a98c1ef1f880dc97967e00c913318" translate="yes" xml:space="preserve">
          <source>Indicate that func accepts a sparse matrix as input. If validate is False, this has no effect. Otherwise, if accept_sparse is false, sparse matrix inputs will cause an exception to be raised.</source>
          <target state="translated">Indique que la función acepta una matriz escasa como entrada.Si validar es falso,esto no tiene ningún efecto.De lo contrario,si accept_sparse es False,las entradas de matriz dispersa harán que se plantee una excepción.</target>
        </trans-unit>
        <trans-unit id="eb7cd0d8cb7fae1e80a3e28d3771772ae8884b48" translate="yes" xml:space="preserve">
          <source>Indicate that the input X array should be checked before calling &lt;code&gt;func&lt;/code&gt;. The possibilities are:</source>
          <target state="translated">Indique que la matriz de entrada X debe verificarse antes de llamar a &lt;code&gt;func&lt;/code&gt; . Las posibilidades son:</target>
        </trans-unit>
        <trans-unit id="ae286e88bfa268243cfd38132ccb40e58428bfed" translate="yes" xml:space="preserve">
          <source>Indicate that transform should forward the y argument to the inner callable.</source>
          <target state="translated">Indicar que la transformación debe reenviar el argumento y a la llamada interior.</target>
        </trans-unit>
        <trans-unit id="9d241566a403a6506d3449cf17d407da2b6e2613" translate="yes" xml:space="preserve">
          <source>Indicates an ordering for the class labels</source>
          <target state="translated">Indica un orden para las etiquetas de clase</target>
        </trans-unit>
        <trans-unit id="9f992c130abda366b807271662ae2ae17c7305e7" translate="yes" xml:space="preserve">
          <source>Indices according to which X will be subsampled.</source>
          <target state="translated">Índices según los cuales X será submuestreado.</target>
        </trans-unit>
        <trans-unit id="13d9e5d82e7cab8325fb7843fa12831d259a69f1" translate="yes" xml:space="preserve">
          <source>Indices of &lt;code&gt;components_&lt;/code&gt; in the training set.</source>
          <target state="translated">&amp;Iacute;ndices de &lt;code&gt;components_&lt;/code&gt; en el conjunto de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="eeb5984b85169d88759ac10f7fe9d10f5246bc74" translate="yes" xml:space="preserve">
          <source>Indices of active variables at the end of the path.</source>
          <target state="translated">Índices de variables activas al final del camino.</target>
        </trans-unit>
        <trans-unit id="fff8cc57ffbca371ebcb1bd938597e8d339ff509" translate="yes" xml:space="preserve">
          <source>Indices of cluster centers</source>
          <target state="translated">Índices de los centros de clústeres</target>
        </trans-unit>
        <trans-unit id="2c68ceeb78b6311d290c266259420efe85138435" translate="yes" xml:space="preserve">
          <source>Indices of columns in the dataset that belong to the bicluster.</source>
          <target state="translated">Índices de columnas en el conjunto de datos que pertenecen al bicluster.</target>
        </trans-unit>
        <trans-unit id="d4d2ad6637f8190da67b396b7e452baac4f7558f" translate="yes" xml:space="preserve">
          <source>Indices of core samples.</source>
          <target state="translated">Índices de muestras del núcleo.</target>
        </trans-unit>
        <trans-unit id="c71c298055da26ecac09942b9115f5fc73f7640d" translate="yes" xml:space="preserve">
          <source>Indices of rows in the dataset that belong to the bicluster.</source>
          <target state="translated">Índices de filas en el conjunto de datos que pertenecen al bicluster.</target>
        </trans-unit>
        <trans-unit id="a5ecd973c55633f90c97a971f74a80fe11af3310" translate="yes" xml:space="preserve">
          <source>Indices of support vectors.</source>
          <target state="translated">Índices de vectores de apoyo.</target>
        </trans-unit>
        <trans-unit id="9ccd80ce2c5e0529264583d000f7c9651892271d" translate="yes" xml:space="preserve">
          <source>Indices of the approximate nearest points in the population matrix.</source>
          <target state="translated">Índices de los puntos más cercanos aproximados en la matriz de población.</target>
        </trans-unit>
        <trans-unit id="94147abfa5127a12fe3c3b0c7153a32b171d401a" translate="yes" xml:space="preserve">
          <source>Indices of the nearest points in the population matrix.</source>
          <target state="translated">Índices de los puntos más cercanos en la matriz de población.</target>
        </trans-unit>
        <trans-unit id="3db97f5586a1b88a52d6998bdcb68ce6424bd44e" translate="yes" xml:space="preserve">
          <source>Individual decision trees can be interpreted easily by simply visualizing the tree structure. Gradient boosting models, however, comprise hundreds of regression trees thus they cannot be easily interpreted by visual inspection of the individual trees. Fortunately, a number of techniques have been proposed to summarize and interpret gradient boosting models.</source>
          <target state="translated">Los árboles de decisión individuales pueden interpretarse fácilmente con sólo visualizar la estructura del árbol.Sin embargo,los modelos de potenciación de gradientes comprenden cientos de árboles de regresión,por lo que no pueden interpretarse fácilmente mediante la inspección visual de los árboles individuales.Afortunadamente,se han propuesto varias técnicas para resumir e interpretar los modelos de potenciación de gradientes.</target>
        </trans-unit>
        <trans-unit id="dda28c621b6ebb6a75808a25ba823af15c148423" translate="yes" xml:space="preserve">
          <source>Individual decision trees intrinsically perform feature selection by selecting appropriate split points. This information can be used to measure the importance of each feature; the basic idea is: the more often a feature is used in the split points of a tree the more important that feature is. This notion of importance can be extended to decision tree ensembles by simply averaging the feature importance of each tree (see &lt;a href=&quot;#random-forest-feature-importance&quot;&gt;Feature importance evaluation&lt;/a&gt; for more details).</source>
          <target state="translated">Los &amp;aacute;rboles de decisi&amp;oacute;n individuales realizan intr&amp;iacute;nsecamente la selecci&amp;oacute;n de caracter&amp;iacute;sticas mediante la selecci&amp;oacute;n de puntos de divisi&amp;oacute;n apropiados. Esta informaci&amp;oacute;n se puede utilizar para medir la importancia de cada caracter&amp;iacute;stica; la idea b&amp;aacute;sica es: cuanto m&amp;aacute;s a menudo se usa una caracter&amp;iacute;stica en los puntos de divisi&amp;oacute;n de un &amp;aacute;rbol, m&amp;aacute;s importante es esa caracter&amp;iacute;stica. Esta noci&amp;oacute;n de importancia se puede extender a los conjuntos de &amp;aacute;rboles de decisi&amp;oacute;n simplemente promediando la importancia de la caracter&amp;iacute;stica de cada &amp;aacute;rbol (consulte &lt;a href=&quot;#random-forest-feature-importance&quot;&gt;Evaluaci&amp;oacute;n de la importancia de la caracter&amp;iacute;stica&lt;/a&gt; para obtener m&amp;aacute;s detalles).</target>
        </trans-unit>
        <trans-unit id="e3bee3019e098ad6b65e2ff793a0e712b529b8f1" translate="yes" xml:space="preserve">
          <source>Individual samples are assumed to be files stored a two levels folder structure such as the following:</source>
          <target state="translated">Se supone que las muestras individuales son archivos almacenados en una estructura de carpetas de dos niveles como la siguiente:</target>
        </trans-unit>
        <trans-unit id="c0fc01010c6e24d626cecdd62fd33ec75c0c929c" translate="yes" xml:space="preserve">
          <source>Individual steps may also be replaced as parameters, and non-final steps may be ignored by setting them to &lt;code&gt;None&lt;/code&gt;:</source>
          <target state="translated">Los pasos individuales tambi&amp;eacute;n se pueden reemplazar como par&amp;aacute;metros, y los pasos no finales se pueden ignorar configur&amp;aacute;ndolos en &lt;code&gt;None&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="1005c12f11beba0f3b6f9dd6a7112c31b922588d" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample</source>
          <target state="translated">Pesos individuales para cada muestra</target>
        </trans-unit>
        <trans-unit id="1fda26bba39629c5adc019bfeebf23b6ea1cae92" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample raises error if sample_weight is passed and base_estimator fit method does not support it.</source>
          <target state="translated">Los pesos individuales de cada muestra aumentan el error si se pasa el peso de la muestra y el método de ajuste del estimador base no lo admite.</target>
        </trans-unit>
        <trans-unit id="fa75f1e4d13933a19ded3aa860129fc7cab3ed7d" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample, ignored if None is passed.</source>
          <target state="translated">Pesos individuales para cada muestra,ignorados si no se aprueba ninguna.</target>
        </trans-unit>
        <trans-unit id="718e842694bb04faf5cc021c83e29c576f98c12d" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample. If sample_weight is not None and solver=&amp;rsquo;auto&amp;rsquo;, the solver will be set to &amp;lsquo;cholesky&amp;rsquo;.</source>
          <target state="translated">Pesos individuales para cada muestra. Si sample_weight no es None y solver = 'auto', el solucionador se establecer&amp;aacute; en 'cholesky'.</target>
        </trans-unit>
        <trans-unit id="f221e5d04a99f60098722e2605a369c8541e6c9c" translate="yes" xml:space="preserve">
          <source>Inertia is not a normalized metric: we just know that lower values are better and zero is optimal. But in very high-dimensional spaces, Euclidean distances tend to become inflated (this is an instance of the so-called &amp;ldquo;curse of dimensionality&amp;rdquo;). Running a dimensionality reduction algorithm such as &lt;a href=&quot;pca&quot;&gt;PCA&lt;/a&gt; prior to k-means clustering can alleviate this problem and speed up the computations.</source>
          <target state="translated">La inercia no es una m&amp;eacute;trica normalizada: solo sabemos que los valores m&amp;aacute;s bajos son mejores y cero es &amp;oacute;ptimo. Pero en espacios de muy alta dimensi&amp;oacute;n, las distancias euclidianas tienden a inflarse (este es un ejemplo de la llamada &quot;maldici&amp;oacute;n de la dimensionalidad&quot;). La ejecuci&amp;oacute;n de un algoritmo de reducci&amp;oacute;n de dimensionalidad como &lt;a href=&quot;pca&quot;&gt;PCA&lt;/a&gt; antes de la agrupaci&amp;oacute;n de k-medias puede aliviar este problema y acelerar los c&amp;aacute;lculos.</target>
        </trans-unit>
        <trans-unit id="e010b0c9058bbaf9975d3f14818f3861029f83a1" translate="yes" xml:space="preserve">
          <source>Inertia makes the assumption that clusters are convex and isotropic, which is not always the case. It responds poorly to elongated clusters, or manifolds with irregular shapes.</source>
          <target state="translated">La inercia supone que los cúmulos son convexos e isotrópicos,lo que no siempre es así.Responde mal a los cúmulos alargados,o a los colectores de formas irregulares.</target>
        </trans-unit>
        <trans-unit id="2d57b1c4d1f958efe3710f23677dd552a8a1384c" translate="yes" xml:space="preserve">
          <source>Inertia, or the within-cluster sum of squares criterion, can be recognized as a measure of how internally coherent clusters are. It suffers from various drawbacks:</source>
          <target state="translated">La inercia,o el criterio de la suma de cuadrados dentro del cúmulo,puede reconocerse como una medida de la coherencia interna de los cúmulos.Sufre de varios inconvenientes:</target>
        </trans-unit>
        <trans-unit id="1b9b7d4cd56309d7954eee8c5d88a8d58559a22d" translate="yes" xml:space="preserve">
          <source>Inference of the model can be time consuming.</source>
          <target state="translated">La inferencia del modelo puede llevar mucho tiempo.</target>
        </trans-unit>
        <trans-unit id="8f5d2c4b74b9f6de8f1a369f5793fd5ad3db1bd0" translate="yes" xml:space="preserve">
          <source>Influence of outliers on location and covariance estimates</source>
          <target state="translated">Influencia de los valores atípicos en las estimaciones de localización y covarianza</target>
        </trans-unit>
        <trans-unit id="b8c700f6663aab653644d35fb6aa9a0e53919c01" translate="yes" xml:space="preserve">
          <source>Information on how to contribute. This also contains useful information for advanced users, for example how to build their own estimators.</source>
          <target state="translated">Información sobre cómo contribuir.También contiene información útil para los usuarios avanzados,por ejemplo,cómo construir sus propios estimadores.</target>
        </trans-unit>
        <trans-unit id="c4fbdb7aab44015fbed39936864f9255a99074c1" translate="yes" xml:space="preserve">
          <source>Information-criterion based model selection is very fast, but it relies on a proper estimation of degrees of freedom, are derived for large samples (asymptotic results) and assume the model is correct, i.e. that the data are actually generated by this model. They also tend to break when the problem is badly conditioned (more features than samples).</source>
          <target state="translated">La selección del modelo basado en criterios de información es muy rápida,pero se basa en una estimación adecuada de los grados de libertad,se derivan para muestras grandes (resultados asintóticos)y se supone que el modelo es correcto,es decir,que los datos son realmente generados por este modelo.También tienden a romperse cuando el problema está mal condicionado (más características que muestras).</target>
        </trans-unit>
        <trans-unit id="168bf67b39abe0e5515698a4ec915c75e07ca524" translate="yes" xml:space="preserve">
          <source>Initial value for the dictionary for warm restart scenarios.</source>
          <target state="translated">Valor inicial del diccionario para los escenarios de reinicio en caliente.</target>
        </trans-unit>
        <trans-unit id="64b2b9f72c239478fc1b9e586ac8147218ca87bd" translate="yes" xml:space="preserve">
          <source>Initial value for the sparse code for warm restart scenarios.</source>
          <target state="translated">Valor inicial del código escaso para los escenarios de reinicio en caliente.</target>
        </trans-unit>
        <trans-unit id="1a6282c9a9baf1c9231fe6132d9510c0860835e2" translate="yes" xml:space="preserve">
          <source>Initial values for the components for warm restart scenarios.</source>
          <target state="translated">Valores iniciales de los componentes para los escenarios de reinicio en caliente.</target>
        </trans-unit>
        <trans-unit id="ff1f0a80e07dd6cd648bd3a5e935a909ec2cb299" translate="yes" xml:space="preserve">
          <source>Initial values for the loadings for warm restart scenarios.</source>
          <target state="translated">Valores iniciales de las cargas para los escenarios de reinicio en caliente.</target>
        </trans-unit>
        <trans-unit id="e597ad1e68022a1929058718fd92959e281b3619" translate="yes" xml:space="preserve">
          <source>Initialization of embedding. Possible options are &amp;lsquo;random&amp;rsquo;, &amp;lsquo;pca&amp;rsquo;, and a numpy array of shape (n_samples, n_components). PCA initialization cannot be used with precomputed distances and is usually more globally stable than random initialization.</source>
          <target state="translated">Inicializaci&amp;oacute;n de incrustaci&amp;oacute;n. Las opciones posibles son 'aleatorio', 'pca' y una gran variedad de formas (n_samples, n_components). La inicializaci&amp;oacute;n de PCA no se puede utilizar con distancias precalculadas y suele ser m&amp;aacute;s estable globalmente que la inicializaci&amp;oacute;n aleatoria.</target>
        </trans-unit>
        <trans-unit id="e644154875d3e41452e4b87177ec7a98e4e47540" translate="yes" xml:space="preserve">
          <source>Initialization value for coefficients of logistic regression. Useless for liblinear solver.</source>
          <target state="translated">Valor de inicialización de los coeficientes de regresión logística.Inútil para el solucionador liblineal.</target>
        </trans-unit>
        <trans-unit id="ed7011971816dd0f1903ad54a411facedaee4ded" translate="yes" xml:space="preserve">
          <source>Initialization value of the sparse codes. Only used if &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt;.</source>
          <target state="translated">Valor de inicializaci&amp;oacute;n de los c&amp;oacute;digos dispersos. Solo se usa si &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5f66672d1a211feccb2663e524389cc7bbdc9544" translate="yes" xml:space="preserve">
          <source>Initialize self. See help(type(self)) for accurate signature.</source>
          <target state="translated">Iniciarse.Ver ayuda para una firma precisa.</target>
        </trans-unit>
        <trans-unit id="f4694fddfebcd07057574f3bedbe073aecef8cbe" translate="yes" xml:space="preserve">
          <source>Inliers are labeled 1, while outliers are labeled -1. The predict method makes use of a threshold on the raw scoring function computed by the estimator. This scoring function is accessible through the &lt;code&gt;score_samples&lt;/code&gt; method, while the threshold can be controlled by the &lt;code&gt;contamination&lt;/code&gt; parameter.</source>
          <target state="translated">Los valores internos est&amp;aacute;n etiquetados como 1, mientras que los valores at&amp;iacute;picos est&amp;aacute;n etiquetados como -1. El m&amp;eacute;todo de predicci&amp;oacute;n utiliza un umbral en la funci&amp;oacute;n de puntuaci&amp;oacute;n bruta calculada por el estimador. Esta funci&amp;oacute;n de puntuaci&amp;oacute;n es accesible a trav&amp;eacute;s del m&amp;eacute;todo &lt;code&gt;score_samples&lt;/code&gt; , mientras que el umbral se puede controlar mediante el par&amp;aacute;metro de &lt;code&gt;contamination&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2495be2cc170e277a5d9d5dd99a3f779ff0175c9" translate="yes" xml:space="preserve">
          <source>Inner sufficient statistics that are kept by the algorithm. Passing them at initialization is useful in online settings, to avoid loosing the history of the evolution. A (n_components, n_components) is the dictionary covariance matrix. B (n_features, n_components) is the data approximation matrix</source>
          <target state="translated">Las suficientes estadísticas internas que se mantienen por el algoritmo.Pasarlas en la inicialización es útil en los entornos en línea,para no perder la historia de la evolución.A (n_componentes,n_componentes)es la matriz de covarianza del diccionario.B (n_características,n_componentes)es la matriz de aproximación de datos</target>
        </trans-unit>
        <trans-unit id="4cb705151cf2a5dcfea8029a0e74d39c67469fa5" translate="yes" xml:space="preserve">
          <source>Inplace column scaling of a CSC/CSR matrix.</source>
          <target state="translated">Columna de escalado en el lugar de una matriz CSC/CSR.</target>
        </trans-unit>
        <trans-unit id="15ad21d3f40808b965488683b0faaff07ad4b5e9" translate="yes" xml:space="preserve">
          <source>Inplace column scaling of a CSR matrix.</source>
          <target state="translated">Columna de escalado en el lugar de una matriz de CSR.</target>
        </trans-unit>
        <trans-unit id="75290bdbc975498c98c7572ec067e43ddceb0c68" translate="yes" xml:space="preserve">
          <source>Inplace row normalize using the l1 norm</source>
          <target state="translated">La fila del lugar se normaliza usando la norma l1</target>
        </trans-unit>
        <trans-unit id="bc0180825da8415aba8c76f27c29d7e471b70c2a" translate="yes" xml:space="preserve">
          <source>Inplace row normalize using the l2 norm</source>
          <target state="translated">La fila del lugar se normaliza usando la norma l2</target>
        </trans-unit>
        <trans-unit id="d91ae689358e283ef6d343e24e55244f1fb1cad2" translate="yes" xml:space="preserve">
          <source>Inplace row scaling of a CSR or CSC matrix.</source>
          <target state="translated">En el lugar de la fila de escalado de una matriz de CSR o CSC.</target>
        </trans-unit>
        <trans-unit id="16ca749420dd58126c1f3f4ccf95ce2fc49387c9" translate="yes" xml:space="preserve">
          <source>Input array.</source>
          <target state="translated">Matriz de entrada.</target>
        </trans-unit>
        <trans-unit id="f6fcca00499ce6b21e6114d56b450f6d3d43ccb2" translate="yes" xml:space="preserve">
          <source>Input checker utility for building a cross-validator</source>
          <target state="translated">Utilidad de verificación de entrada para construir un validador cruzado</target>
        </trans-unit>
        <trans-unit id="3f43a2e4863dbf39da8cfbd5e4e557f3052ec269" translate="yes" xml:space="preserve">
          <source>Input data</source>
          <target state="translated">Datos de entrada</target>
        </trans-unit>
        <trans-unit id="41aa04ac5754100b497c803419573444b7e1d42b" translate="yes" xml:space="preserve">
          <source>Input data representation and sparsity</source>
          <target state="translated">La representación de los datos de entrada y la escasez</target>
        </trans-unit>
        <trans-unit id="66a8a4e34fe15bd5eafb5d984d77b9c0e3866728" translate="yes" xml:space="preserve">
          <source>Input data that will be transformed.</source>
          <target state="translated">Introducir datos que se transformarán.</target>
        </trans-unit>
        <trans-unit id="fbb05f66a147e8520f226c078931507f60d0caac" translate="yes" xml:space="preserve">
          <source>Input data that will be transformed. It cannot be sparse.</source>
          <target state="translated">Introducir datos que se transformarán.No pueden ser escasos.</target>
        </trans-unit>
        <trans-unit id="1e3e0a570b83c9cbe639106afeb9bedd23e3fcfd" translate="yes" xml:space="preserve">
          <source>Input data to be transformed.</source>
          <target state="translated">Datos de entrada para ser transformados.</target>
        </trans-unit>
        <trans-unit id="071feefe9143dba47a473de169ba49367bfce443" translate="yes" xml:space="preserve">
          <source>Input data to be transformed. Use &lt;code&gt;dtype=np.float32&lt;/code&gt; for maximum efficiency. Sparse matrices are also supported, use sparse &lt;code&gt;csr_matrix&lt;/code&gt; for maximum efficiency.</source>
          <target state="translated">Datos de entrada a transformar. Utilice &lt;code&gt;dtype=np.float32&lt;/code&gt; para obtener la m&amp;aacute;xima eficiencia. Tambi&amp;eacute;n se admiten matrices dispersas, use &lt;code&gt;csr_matrix&lt;/code&gt; disperso para una m&amp;aacute;xima eficiencia.</target>
        </trans-unit>
        <trans-unit id="688f24dc1e25fac1dc510cf29e6e51a5cdee42ba" translate="yes" xml:space="preserve">
          <source>Input data used to build forests. Use &lt;code&gt;dtype=np.float32&lt;/code&gt; for maximum efficiency.</source>
          <target state="translated">Datos de entrada utilizados para construir bosques. Utilice &lt;code&gt;dtype=np.float32&lt;/code&gt; para obtener la m&amp;aacute;xima eficiencia.</target>
        </trans-unit>
        <trans-unit id="ece9df27fcdc2d8935842ef4ed6ac1e8d53f8b6c" translate="yes" xml:space="preserve">
          <source>Input data, of which specified subsets are used to fit the transformers.</source>
          <target state="translated">Datos de entrada,de los cuales se utilizan subconjuntos específicos para ajustar los transformadores.</target>
        </trans-unit>
        <trans-unit id="8c020a67c0398f86d112987222d02c36283701ba" translate="yes" xml:space="preserve">
          <source>Input data, target values.</source>
          <target state="translated">Datos de entrada,valores objetivo.</target>
        </trans-unit>
        <trans-unit id="0d15fc28721eb2bcf2d53de59215da674d786463" translate="yes" xml:space="preserve">
          <source>Input data, used to fit transformers.</source>
          <target state="translated">Datos de entrada,usados para ajustar los transformadores.</target>
        </trans-unit>
        <trans-unit id="aee2f5203193bb3069f6e2f7b08e833e91d53841" translate="yes" xml:space="preserve">
          <source>Input data, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the number of features.</source>
          <target state="translated">Datos de entrada, donde &lt;code&gt;n_samples&lt;/code&gt; es el n&amp;uacute;mero de muestras y &lt;code&gt;n_features&lt;/code&gt; es el n&amp;uacute;mero de caracter&amp;iacute;sticas.</target>
        </trans-unit>
        <trans-unit id="8f9c683e36e31c7c38c7e8d6a2daeccf181d4c94" translate="yes" xml:space="preserve">
          <source>Input data, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">Datos de entrada,donde n_muestras es el número de muestras y n_características es el número de características.</target>
        </trans-unit>
        <trans-unit id="260753716624ad2077f13f38ada17a33c0f48cba" translate="yes" xml:space="preserve">
          <source>Input data.</source>
          <target state="translated">Datos de entrada.</target>
        </trans-unit>
        <trans-unit id="c414149f534c72aa4d2016c93404604f17aa41fd" translate="yes" xml:space="preserve">
          <source>Input data. Columns are assumed to have unit norm.</source>
          <target state="translated">Datos de entrada.Se supone que las columnas tienen una norma de unidad.</target>
        </trans-unit>
        <trans-unit id="fc921091c020b61d18864b21129c4eb989ef6d69" translate="yes" xml:space="preserve">
          <source>Input data. If &lt;code&gt;None&lt;/code&gt;, the output will be the pairwise similarities between all samples in &lt;code&gt;X&lt;/code&gt;.</source>
          <target state="translated">Datos de entrada. Si &lt;code&gt;None&lt;/code&gt; , la salida ser&amp;aacute; la similitud por pares entre todas las muestras en &lt;code&gt;X&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="afaf08d18a1423dc1a78bf3492e5ce0eb50d8638" translate="yes" xml:space="preserve">
          <source>Input data. If &lt;code&gt;dissimilarity=='precomputed'&lt;/code&gt;, the input should be the dissimilarity matrix.</source>
          <target state="translated">Datos de entrada. Si la &lt;code&gt;dissimilarity=='precomputed'&lt;/code&gt; , la entrada debe ser la matriz de disimilitud.</target>
        </trans-unit>
        <trans-unit id="c7e2acaca5145e47486c9c2928ab5532aee98fd4" translate="yes" xml:space="preserve">
          <source>Input data. If X is not provided, only the global clustering step is done.</source>
          <target state="translated">Datos de entrada.Si no se proporciona X,sólo se realiza el paso de agrupación global.</target>
        </trans-unit>
        <trans-unit id="d39fe8b9c923e952612de77f70ad5aff60c34542" translate="yes" xml:space="preserve">
          <source>Input object to check / convert.</source>
          <target state="translated">Introducir objeto para comprobar/convertir.</target>
        </trans-unit>
        <trans-unit id="ca7fd27e447d5e335b2e80d1b2bb1406dceac239" translate="yes" xml:space="preserve">
          <source>Input object to check / convert. Must be two-dimensional and square, otherwise a ValueError will be raised.</source>
          <target state="translated">Introducir el objeto para comprobar/convertir.Debe ser bidimensional y cuadrado,de lo contrario se producirá un error de valor.</target>
        </trans-unit>
        <trans-unit id="f24bf584af83fad1f47a5035ff05cdc62fd1daef" translate="yes" xml:space="preserve">
          <source>Input points.</source>
          <target state="translated">Puntos de entrada.</target>
        </trans-unit>
        <trans-unit id="71b2d21e1f2e71c0dcf88bd09dfe9ef6fd499ea3" translate="yes" xml:space="preserve">
          <source>Input targets</source>
          <target state="translated">Objetivos de entrada</target>
        </trans-unit>
        <trans-unit id="b58e4bce1b7ebb41f970a06dbe933522f9ad2c46" translate="yes" xml:space="preserve">
          <source>Input targets multiplied by X: X.T * y</source>
          <target state="translated">Objetivos de entrada multiplicados por X:X.T*y</target>
        </trans-unit>
        <trans-unit id="69a0e9f3a009e8ccbba64367545e9fbe88306b19" translate="yes" xml:space="preserve">
          <source>Input targets.</source>
          <target state="translated">Objetivos de entrada.</target>
        </trans-unit>
        <trans-unit id="51c9f9fb1fac83429c51404b5e9b2caee57cc2f2" translate="yes" xml:space="preserve">
          <source>Input validation for standard estimators.</source>
          <target state="translated">Validación de entrada para los estimadores estándar.</target>
        </trans-unit>
        <trans-unit id="346da7aa7d7e4eb884706a35a69404b7d3fc9daa" translate="yes" xml:space="preserve">
          <source>Input validation on an array, list, sparse matrix or similar.</source>
          <target state="translated">Validación de entrada en una matriz,lista,matriz dispersa o similar.</target>
        </trans-unit>
        <trans-unit id="8344beaf285df55c120907e8b74a9a1f87253895" translate="yes" xml:space="preserve">
          <source>Inputs &lt;code&gt;X&lt;/code&gt; are 4 independent features uniformly distributed on the intervals:</source>
          <target state="translated">Las entradas &lt;code&gt;X&lt;/code&gt; son 4 caracter&amp;iacute;sticas independientes distribuidas uniformemente en los intervalos:</target>
        </trans-unit>
        <trans-unit id="bcbcb56a88ddeef69ce01bcc9a78a456071e2cf0" translate="yes" xml:space="preserve">
          <source>Inputs &lt;code&gt;X&lt;/code&gt; are independent features uniformly distributed on the interval [0, 1]. The output &lt;code&gt;y&lt;/code&gt; is created according to the formula:</source>
          <target state="translated">Las entradas &lt;code&gt;X&lt;/code&gt; son caracter&amp;iacute;sticas independientes distribuidas uniformemente en el intervalo [0, 1]. La salida &lt;code&gt;y&lt;/code&gt; se crea de acuerdo con la f&amp;oacute;rmula:</target>
        </trans-unit>
        <trans-unit id="fffa8f8e3b740ecfc583b9bf477ffcbdb298b533" translate="yes" xml:space="preserve">
          <source>Inserts new data into the already fitted LSH Forest.</source>
          <target state="translated">Inserta nuevos datos en el ya instalado Bosque LSH.</target>
        </trans-unit>
        <trans-unit id="e78cacac23222d74508b7d4b79fbb8a5cb79c6fc" translate="yes" xml:space="preserve">
          <source>Inserts new data into the already fitted LSH Forest. Cost is proportional to new total size, so additions should be batched.</source>
          <target state="translated">Inserta nuevos datos en el ya instalado Bosque LSH.El costo es proporcional al nuevo tamaño total,por lo que las adiciones deben ser agrupadas.</target>
        </trans-unit>
        <trans-unit id="58768f013d8600aed4da42a9f67c30c0b0e7f2be" translate="yes" xml:space="preserve">
          <source>Instead of computing with a set of cardinality &amp;lsquo;n choose k&amp;rsquo;, where n is the number of samples and k is the number of subsamples (at least number of features), consider only a stochastic subpopulation of a given maximal size if &amp;lsquo;n choose k&amp;rsquo; is larger than max_subpopulation. For other than small problem sizes this parameter will determine memory usage and runtime if n_subsamples is not changed.</source>
          <target state="translated">En lugar de calcular con un conjunto de cardinalidad 'n elija k', donde n es el n&amp;uacute;mero de muestras yk es el n&amp;uacute;mero de submuestras (al menos el n&amp;uacute;mero de caracter&amp;iacute;sticas), considere solo una subpoblaci&amp;oacute;n estoc&amp;aacute;stica de un tama&amp;ntilde;o m&amp;aacute;ximo dado si 'n elige k 'es m&amp;aacute;s grande que max_subpopulation. Para problemas que no sean peque&amp;ntilde;os, este par&amp;aacute;metro determinar&amp;aacute; el uso de la memoria y el tiempo de ejecuci&amp;oacute;n si no se cambia n_subsamples.</target>
        </trans-unit>
        <trans-unit id="ce6171dee8019fcd810326710a2a425d2ef2e21c" translate="yes" xml:space="preserve">
          <source>Instead of giving a vector result, the LARS solution consists of a curve denoting the solution for each value of the L1 norm of the parameter vector. The full coefficients path is stored in the array &lt;code&gt;coef_path_&lt;/code&gt;, which has size (n_features, max_features+1). The first column is always zero.</source>
          <target state="translated">En lugar de dar un resultado vectorial, la soluci&amp;oacute;n LARS consiste en una curva que denota la soluci&amp;oacute;n para cada valor de la norma L1 del vector de par&amp;aacute;metros. La ruta completa de los coeficientes se almacena en la matriz &lt;code&gt;coef_path_&lt;/code&gt; , que tiene un tama&amp;ntilde;o (n_features, max_features + 1). La primera columna siempre es cero.</target>
        </trans-unit>
        <trans-unit id="1c47d2e573aac76a94273f4c46c066cf6f2a8ad1" translate="yes" xml:space="preserve">
          <source>Instead of tweaking the parameters of the various components of the chain, it is possible to run an exhaustive search of the best parameters on a grid of possible values. We try out all classifiers on either words or bigrams, with or without idf, and with a penalty parameter of either 0.01 or 0.001 for the linear SVM:</source>
          <target state="translated">En lugar de ajustar los parámetros de los diversos componentes de la cadena,es posible realizar una búsqueda exhaustiva de los mejores parámetros en una cuadrícula de posibles valores.Probamos todos los clasificadores en palabras o en bigrams,con o sin idf,y con un parámetro de penalización de 0,01 o 0,001 para el SVM lineal:</target>
        </trans-unit>
        <trans-unit id="db33f6d449a5c5c7a074dd03bb12ec7fc077641c" translate="yes" xml:space="preserve">
          <source>Instead the caller is expected to either set explicitly &lt;code&gt;with_centering=False&lt;/code&gt; (in that case, only variance scaling will be performed on the features of the CSR matrix) or to call &lt;code&gt;X.toarray()&lt;/code&gt; if he/she expects the materialized dense array to fit in memory.</source>
          <target state="translated">En su lugar, se espera que la persona que llama establezca expl&amp;iacute;citamente &lt;code&gt;with_centering=False&lt;/code&gt; (en ese caso, solo se realizar&amp;aacute; el escalado de varianza en las caracter&amp;iacute;sticas de la matriz CSR) o que llame a &lt;code&gt;X.toarray()&lt;/code&gt; si espera que la matriz densa materializada se ajuste en memoria.</target>
        </trans-unit>
        <trans-unit id="f080b277d95a6b1142abd6eb9ea11a07abcb1917" translate="yes" xml:space="preserve">
          <source>Instead the caller is expected to either set explicitly &lt;code&gt;with_mean=False&lt;/code&gt; (in that case, only variance scaling will be performed on the features of the CSC matrix) or to call &lt;code&gt;X.toarray()&lt;/code&gt; if he/she expects the materialized dense array to fit in memory.</source>
          <target state="translated">En su lugar, se espera que la persona que llama establezca expl&amp;iacute;citamente &lt;code&gt;with_mean=False&lt;/code&gt; (en ese caso, solo se realizar&amp;aacute; el escalado de varianza en las caracter&amp;iacute;sticas de la matriz CSC) o que llame a &lt;code&gt;X.toarray()&lt;/code&gt; si espera que la matriz densa materializada se ajuste en memoria.</target>
        </trans-unit>
        <trans-unit id="b11f1ba476938b01d18dd66d0c3826617a20151e" translate="yes" xml:space="preserve">
          <source>Instead, the distribution over \(w\) is assumed to be an axis-parallel, elliptical Gaussian distribution.</source>
          <target state="translated">En su lugar,se supone que la distribución sobre \ ~ (w)es un eje paralelo,elíptica distribución Gaussiana.</target>
        </trans-unit>
        <trans-unit id="33a2873657f7cc53fbafced5857dd217868f1368" translate="yes" xml:space="preserve">
          <source>Instruction on what to do if a byte sequence is given to analyze that contains characters not of the given &lt;code&gt;encoding&lt;/code&gt;. By default, it is &amp;lsquo;strict&amp;rsquo;, meaning that a UnicodeDecodeError will be raised. Other values are &amp;lsquo;ignore&amp;rsquo; and &amp;lsquo;replace&amp;rsquo;.</source>
          <target state="translated">Instrucciones sobre qu&amp;eacute; hacer si se proporciona una secuencia de bytes para analizar que contiene caracteres que no pertenecen a la &lt;code&gt;encoding&lt;/code&gt; dada . De forma predeterminada, es 'estricto', lo que significa que se generar&amp;aacute; un UnicodeDecodeError. Otros valores son 'ignorar' y 'reemplazar'.</target>
        </trans-unit>
        <trans-unit id="d22b7ba366228e805a5817961de5812cf7af3a5e" translate="yes" xml:space="preserve">
          <source>Instruction on what to do if a byte sequence is given to analyze that contains characters not of the given &lt;code&gt;encoding&lt;/code&gt;. Passed as keyword argument &amp;lsquo;errors&amp;rsquo; to bytes.decode.</source>
          <target state="translated">Instrucciones sobre qu&amp;eacute; hacer si se proporciona una secuencia de bytes para analizar que contiene caracteres que no pertenecen a la &lt;code&gt;encoding&lt;/code&gt; dada . Pasado como argumento de palabra clave 'errores' a bytes.decode.</target>
        </trans-unit>
        <trans-unit id="98ae123013fca86e4cc21f01a470888e055215cc" translate="yes" xml:space="preserve">
          <source>Integer array of labels. If not provided, labels will be inferred from y_true and y_pred.</source>
          <target state="translated">Una serie de etiquetas enteras.Si no se proporcionan,las etiquetas se deducirán de y_true y y_pred.</target>
        </trans-unit>
        <trans-unit id="fb86aae8ca1d5ea8c3a2f0216a09b115ca2c4371" translate="yes" xml:space="preserve">
          <source>Intercept (a.k.a. bias) added to the decision function.</source>
          <target state="translated">La intercepción (también conocida como sesgo)se añadió a la función de decisión.</target>
        </trans-unit>
        <trans-unit id="02c60e7ce23b1ba7da9aadaca682e74dd23bd987" translate="yes" xml:space="preserve">
          <source>Intercept term.</source>
          <target state="translated">Término de intercepción.</target>
        </trans-unit>
        <trans-unit id="077392291decf12f1b024c471b5bea6bcd10e56c" translate="yes" xml:space="preserve">
          <source>Internal sufficient statistics that are kept by the algorithm. Keeping them is useful in online settings, to avoid loosing the history of the evolution, but they shouldn&amp;rsquo;t have any use for the end user. A (n_components, n_components) is the dictionary covariance matrix. B (n_features, n_components) is the data approximation matrix</source>
          <target state="translated">Estad&amp;iacute;sticas internas suficientes que mantiene el algoritmo. Mantenerlos es &amp;uacute;til en entornos online, para no perder el historial de evoluci&amp;oacute;n, pero no deber&amp;iacute;an tener ning&amp;uacute;n uso para el usuario final. A (n_components, n_components) es la matriz de covarianza del diccionario. B (n_features, n_components) es la matriz de aproximaci&amp;oacute;n de datos</target>
        </trans-unit>
        <trans-unit id="14f5f43f255d2aa36ff5598f3fb3ace3d6d04389" translate="yes" xml:space="preserve">
          <source>Internally, the Laplace approximation is used for approximating the non-Gaussian posterior by a Gaussian.</source>
          <target state="translated">Internamente,la aproximación de Laplace se utiliza para aproximar el posterior no gaussiano por un gaussiano.</target>
        </trans-unit>
        <trans-unit id="0b925a293764508f95547bba83dbd960f81b58e6" translate="yes" xml:space="preserve">
          <source>Internally, the target &lt;code&gt;y&lt;/code&gt; is always converted into a 2-dimensional array to be used by scikit-learn transformers. At the time of prediction, the output will be reshaped to a have the same number of dimensions as &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">Internamente, el objetivo &lt;code&gt;y&lt;/code&gt; siempre se convierte en una matriz bidimensional para ser utilizada por transformadores scikit-learn. En el momento de la predicci&amp;oacute;n, la salida se reformar&amp;aacute; para que tenga el mismo n&amp;uacute;mero de dimensiones que &lt;code&gt;y&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a6c7ce41d2f8fb06b74993c6b6972d365c014219" translate="yes" xml:space="preserve">
          <source>Internally, we use &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; and &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; to handle all computations. These libraries are wrapped using C and Cython.</source>
          <target state="translated">Internamente, usamos &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; y &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; para manejar todos los c&amp;aacute;lculos. Estas bibliotecas est&amp;aacute;n empaquetadas con C y Cython.</target>
        </trans-unit>
        <trans-unit id="a2d983855292bfa7e006da9cc5e0020136bdcd0e" translate="yes" xml:space="preserve">
          <source>Interruption of multiprocesses jobs with &amp;lsquo;Ctrl-C&amp;rsquo;</source>
          <target state="translated">Interrupci&amp;oacute;n de trabajos multiprocesos con 'Ctrl-C'</target>
        </trans-unit>
        <trans-unit id="c8666d7061618ff72086e37218ea77619df4e168" translate="yes" xml:space="preserve">
          <source>Intuitive interpretation: clustering with bad V-measure can be &lt;strong&gt;qualitatively analyzed in terms of homogeneity and completeness&lt;/strong&gt; to better feel what &amp;lsquo;kind&amp;rsquo; of mistakes is done by the assignment.</source>
          <target state="translated">Interpretaci&amp;oacute;n intuitiva: la agrupaci&amp;oacute;n con una mala medida V se puede &lt;strong&gt;analizar cualitativamente en t&amp;eacute;rminos de homogeneidad e integridad&lt;/strong&gt; para sentir mejor qu&amp;eacute; &quot;tipo&quot; de errores comete la asignaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="b3bf13a5a75c5bcae60f4d54f651f7f504b37960" translate="yes" xml:space="preserve">
          <source>Intuitively, &lt;a href=&quot;https://en.wikipedia.org/wiki/Precision_and_recall#Precision&quot;&gt;precision&lt;/a&gt; is the ability of the classifier not to label as positive a sample that is negative, and &lt;a href=&quot;https://en.wikipedia.org/wiki/Precision_and_recall#Recall&quot;&gt;recall&lt;/a&gt; is the ability of the classifier to find all the positive samples.</source>
          <target state="translated">Intuitivamente, la &lt;a href=&quot;https://en.wikipedia.org/wiki/Precision_and_recall#Precision&quot;&gt;precisi&amp;oacute;n&lt;/a&gt; es la capacidad del clasificador de no etiquetar como positiva una muestra negativa, y la &lt;a href=&quot;https://en.wikipedia.org/wiki/Precision_and_recall#Recall&quot;&gt;recuperaci&amp;oacute;n&lt;/a&gt; es la capacidad del clasificador de encontrar todas las muestras positivas.</target>
        </trans-unit>
        <trans-unit id="d7d0867c1bea54b1fdaded0f6d4a137c7b95792e" translate="yes" xml:space="preserve">
          <source>Intuitively, one can also think of a histogram as a stack of blocks, one block per point. By stacking the blocks in the appropriate grid space, we recover the histogram. But what if, instead of stacking the blocks on a regular grid, we center each block on the point it represents, and sum the total height at each location? This idea leads to the lower-left visualization. It is perhaps not as clean as a histogram, but the fact that the data drive the block locations mean that it is a much better representation of the underlying data.</source>
          <target state="translated">Intuitivamente,también se puede pensar en un histograma como una pila de bloques,un bloque por punto.Apilando los bloques en el espacio de la cuadrícula apropiada,recuperamos el histograma.¿Pero qué pasa si,en lugar de apilar los bloques en una cuadrícula regular,centramos cada bloque en el punto que representa,y sumamos la altura total en cada lugar? Esta idea nos lleva a la visualización de la parte inferior izquierda.Tal vez no sea tan limpia como un histograma,pero el hecho de que los datos impulsen las ubicaciones de los bloques significa que es una representación mucho mejor de los datos subyacentes.</target>
        </trans-unit>
        <trans-unit id="a413ab311fb3ee6ba0089ad38e522b4769b873e8" translate="yes" xml:space="preserve">
          <source>Intuitively, the &lt;code&gt;gamma&lt;/code&gt; parameter defines how far the influence of a single training example reaches, with low values meaning &amp;lsquo;far&amp;rsquo; and high values meaning &amp;lsquo;close&amp;rsquo;. The &lt;code&gt;gamma&lt;/code&gt; parameters can be seen as the inverse of the radius of influence of samples selected by the model as support vectors.</source>
          <target state="translated">De manera intuitiva, el par&amp;aacute;metro &lt;code&gt;gamma&lt;/code&gt; define hasta d&amp;oacute;nde llega la influencia de un solo ejemplo de entrenamiento, con valores bajos que significan &quot;lejos&quot; y valores altos que significan &quot;cerca&quot;. Los par&amp;aacute;metros &lt;code&gt;gamma&lt;/code&gt; pueden verse como la inversa del radio de influencia de las muestras seleccionadas por el modelo como vectores de apoyo.</target>
        </trans-unit>
        <trans-unit id="0af317bc827b64b57bcc63f42ad5928a61b8cb1f" translate="yes" xml:space="preserve">
          <source>Intuitively, this matrix can be interpreted as a matrix of pseudo features (the points raised to some power). The matrix is akin to (but different from) the matrix induced by a polynomial kernel.</source>
          <target state="translated">Intuitivamente,esta matriz puede ser interpretada como una matriz de seudo características (los puntos elevados a cierta potencia).La matriz es similar (pero diferente)a la matriz inducida por un núcleo polinómico.</target>
        </trans-unit>
        <trans-unit id="20dc7b25181635b005eb94a34d79a1d1ef88f5eb" translate="yes" xml:space="preserve">
          <source>Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.</source>
          <target state="translated">Invertir la fuerza de regularización;debe ser una flotación positiva.Al igual que en las máquinas de vectores de apoyo,los valores más pequeños especifican una mayor regularización.</target>
        </trans-unit>
        <trans-unit id="33bf667eeef9f8f87ba0b221f0610de05f350c0d" translate="yes" xml:space="preserve">
          <source>Inverse the transformation.</source>
          <target state="translated">Invertir la transformación.</target>
        </trans-unit>
        <trans-unit id="c6d1024dc4c416573a81f58d53b390ce79e27d74" translate="yes" xml:space="preserve">
          <source>Inverse the transformation. Return a vector of size nb_features with the values of Xred assigned to each group of features</source>
          <target state="translated">Invertir la transformación.Devolver un vector de tamaño nb_funciones con los valores de Xred asignados a cada grupo de características</target>
        </trans-unit>
        <trans-unit id="68776e7556a932d7c1772f163bcd0ea5d3036f2f" translate="yes" xml:space="preserve">
          <source>Inverse transform matrix. Only available when &lt;code&gt;fit_inverse_transform&lt;/code&gt; is True.</source>
          <target state="translated">Matriz de transformaci&amp;oacute;n inversa. Solo disponible cuando &lt;code&gt;fit_inverse_transform&lt;/code&gt; es True.</target>
        </trans-unit>
        <trans-unit id="a53229d5506328691d3b32e8898ac28b845cf1d2" translate="yes" xml:space="preserve">
          <source>Inverse transformed array.</source>
          <target state="translated">Matriz transformada inversa.</target>
        </trans-unit>
        <trans-unit id="6d0db9202e10d4b2a1eb16356a668a8027a929fc" translate="yes" xml:space="preserve">
          <source>Invokes the passed method name of the passed estimator. For method=&amp;rsquo;predict_proba&amp;rsquo;, the columns correspond to the classes in sorted order.</source>
          <target state="translated">Invoca el nombre del m&amp;eacute;todo pasado del estimador pasado. Para method = 'predict_proba', las columnas corresponden a las clases en orden ordenado.</target>
        </trans-unit>
        <trans-unit id="d37270b3f9f32ae673296712eb4a194d52812d8f" translate="yes" xml:space="preserve">
          <source>Invoking the &lt;code&gt;fit&lt;/code&gt; method on the &lt;code&gt;VotingClassifier&lt;/code&gt; will fit clones of those original estimators that will be stored in the class attribute &lt;code&gt;self.estimators_&lt;/code&gt;. An estimator can be set to &lt;code&gt;None&lt;/code&gt; using &lt;code&gt;set_params&lt;/code&gt;.</source>
          <target state="translated">Invocar el m&amp;eacute;todo de &lt;code&gt;fit&lt;/code&gt; en el &lt;code&gt;VotingClassifier&lt;/code&gt; ajustar&amp;aacute; los clones de esos estimadores originales que se almacenar&amp;aacute;n en el atributo de clase &lt;code&gt;self.estimators_&lt;/code&gt; . Un estimador se puede establecer en &lt;code&gt;None&lt;/code&gt; usando &lt;code&gt;set_params&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="42b4a555867c758d3e1c4078b74a325ea5729a8f" translate="yes" xml:space="preserve">
          <source>Iris-Setosa</source>
          <target state="translated">Iris-Setosa</target>
        </trans-unit>
        <trans-unit id="0e4a66fb06fc31fa26bb267122a303163869bd83" translate="yes" xml:space="preserve">
          <source>Iris-Versicolour</source>
          <target state="translated">Iris-Versicolour</target>
        </trans-unit>
        <trans-unit id="c11352543468838c7f536aa067f758dd5cf065cc" translate="yes" xml:space="preserve">
          <source>Iris-Virginica</source>
          <target state="translated">Iris-Virginica</target>
        </trans-unit>
        <trans-unit id="bb0f5655f4fe0f8adc1a787c53ae1e836f4be186" translate="yes" xml:space="preserve">
          <source>Iso-probability lines for Gaussian Processes classification (GPC)</source>
          <target state="translated">Líneas de isoprobabilidad para la clasificación de los Procesos Gausianos (GPC)</target>
        </trans-unit>
        <trans-unit id="2b50512539d0e21a6687a0e4968f704ff8cc80fe" translate="yes" xml:space="preserve">
          <source>Isolation Forest Algorithm</source>
          <target state="translated">Algoritmo de aislamiento forestal</target>
        </trans-unit>
        <trans-unit id="00617c131e78d4c4ef41c400773154d235217731" translate="yes" xml:space="preserve">
          <source>IsolationForest example</source>
          <target state="translated">AislamientoEjemplo de bosque</target>
        </trans-unit>
        <trans-unit id="3a2755971bbebbe11d424139f5382799c401f262" translate="yes" xml:space="preserve">
          <source>Isomap Embedding</source>
          <target state="translated">Incrustación de Isomap</target>
        </trans-unit>
        <trans-unit id="fe769adce6faebe1974c95ecc576637486cbe643" translate="yes" xml:space="preserve">
          <source>Isotone Optimization in R : Pool-Adjacent-Violators Algorithm (PAVA) and Active Set Methods Leeuw, Hornik, Mair Journal of Statistical Software 2009</source>
          <target state="translated">Optimización de Isotonos en R:Algoritmo de los violadores-ajustadores de piscina (PAVA)y métodos de conjuntos activos Leeuw,Hornik,Mair Journal of Statistical Software 2009</target>
        </trans-unit>
        <trans-unit id="906c68921cb26d68c13066c88efbe4d7d97d1205" translate="yes" xml:space="preserve">
          <source>Isotonic Median Regression: A Linear Programming Approach Nilotpal Chakravarti Mathematics of Operations Research Vol. 14, No. 2 (May, 1989), pp. 303-308</source>
          <target state="translated">Regresión Isotónica Mediana:A Linear Programming Approach Nilotpal Chakravarti Mathematics of Operations Research Vol.14,No.2 (May,1989),pp.303-308</target>
        </trans-unit>
        <trans-unit id="73b36c35655a3846d59943ac16d2df052178f43b" translate="yes" xml:space="preserve">
          <source>Isotonic Regression</source>
          <target state="translated">Regresión isotónica</target>
        </trans-unit>
        <trans-unit id="c214056f848cd4e39c52f175df94ac0d422815da" translate="yes" xml:space="preserve">
          <source>Isotonic fit of y.</source>
          <target state="translated">Ajuste isotónico de y.</target>
        </trans-unit>
        <trans-unit id="350a83a6eea9b1b3e9903b81e34485a4ebed4999" translate="yes" xml:space="preserve">
          <source>Isotonic regression model.</source>
          <target state="translated">Modelo de regresión isotónica.</target>
        </trans-unit>
        <trans-unit id="7c5ae8804283297e052b100d9986cbd5cd009701" translate="yes" xml:space="preserve">
          <source>Issue a warning when the function is called/the class is instantiated and adds a warning to the docstring.</source>
          <target state="translated">Emite una advertencia cuando la función es llamada/la clase es instanciada y añade una advertencia a la cadena de doctores.</target>
        </trans-unit>
        <trans-unit id="4de98053a0f4264ca5362b17521388fcee7300ef" translate="yes" xml:space="preserve">
          <source>It adapts to the data at hand.</source>
          <target state="translated">Se adapta a los datos que tenemos a mano.</target>
        </trans-unit>
        <trans-unit id="d00cd2eb4ac76616c412b13d0e3140cdba7905a2" translate="yes" xml:space="preserve">
          <source>It allows specifying multiple metrics for evaluation.</source>
          <target state="translated">Permite especificar múltiples métricas para la evaluación.</target>
        </trans-unit>
        <trans-unit id="f7ac040f9311efb440d25da16c027a81ab8e3ad5" translate="yes" xml:space="preserve">
          <source>It also can be expressed in set cardinality formulation:</source>
          <target state="translated">También puede expresarse en la formulación de la cardinalidad establecida:</target>
        </trans-unit>
        <trans-unit id="aedad5338d2a0edf1701c1d5c20ad5954bfd8c84" translate="yes" xml:space="preserve">
          <source>It can also be directly used as the &lt;code&gt;kernel&lt;/code&gt; argument:</source>
          <target state="translated">Tambi&amp;eacute;n se puede usar directamente como argumento del &lt;code&gt;kernel&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="9678c3fa14b59b03394b92e8e0080149cf3f64c8" translate="yes" xml:space="preserve">
          <source>It can also be used as a pre-processing step for estimators that consider boolean random variables (e.g. modelled using the Bernoulli distribution in a Bayesian setting).</source>
          <target state="translated">También puede utilizarse como paso de preprocesamiento para los estimadores que consideran las variables aleatorias booleanas (por ejemplo,modeladas utilizando la distribución de Bernoulli en un entorno bayesiano).</target>
        </trans-unit>
        <trans-unit id="94554b8e34efbb328f639daf4ccda2adc301f69d" translate="yes" xml:space="preserve">
          <source>It can also be used to transform non-numerical labels (as long as they are hashable and comparable) to numerical labels.</source>
          <target state="translated">También puede utilizarse para transformar las etiquetas no numéricas (siempre y cuando sean hashable y comparables)en etiquetas numéricas.</target>
        </trans-unit>
        <trans-unit id="f96e6d208d3d13906cbf9cd9c045b4122e99a4e4" translate="yes" xml:space="preserve">
          <source>It can also be used to transform non-numerical labels (as long as they are hashable and comparable) to numerical labels:</source>
          <target state="translated">También puede utilizarse para transformar las etiquetas no numéricas (siempre y cuando sean hashable y comparables)en etiquetas numéricas:</target>
        </trans-unit>
        <trans-unit id="52f6dad43e1775ee0bbb04be9ef515bae958e0a2" translate="yes" xml:space="preserve">
          <source>It can also have a regularization term added to the loss function that shrinks model parameters to prevent overfitting.</source>
          <target state="translated">También puede tener un término de regularización añadido a la función de pérdida que encoge los parámetros del modelo para evitar el sobreajuste.</target>
        </trans-unit>
        <trans-unit id="998bd5d13863b9f1e85f5a6708bf38f625d563b0" translate="yes" xml:space="preserve">
          <source>It can also use the scipy.sparse.linalg ARPACK implementation of the truncated SVD.</source>
          <target state="translated">También puede utilizar la aplicación scipy.sparse.linalg ARPACK de la SVD truncada.</target>
        </trans-unit>
        <trans-unit id="a5f9c7ba1af0aaff84e6645b602de8095311d995" translate="yes" xml:space="preserve">
          <source>It can be called with parameters &lt;code&gt;(estimator, X, y)&lt;/code&gt;, where &lt;code&gt;estimator&lt;/code&gt; is the model that should be evaluated, &lt;code&gt;X&lt;/code&gt; is validation data, and &lt;code&gt;y&lt;/code&gt; is the ground truth target for &lt;code&gt;X&lt;/code&gt; (in the supervised case) or &lt;code&gt;None&lt;/code&gt; (in the unsupervised case).</source>
          <target state="translated">Se puede llamar con par&amp;aacute;metros &lt;code&gt;(estimator, X, y)&lt;/code&gt; , donde el &lt;code&gt;estimator&lt;/code&gt; es el modelo que se debe evaluar, &lt;code&gt;X&lt;/code&gt; son los datos de validaci&amp;oacute;n e &lt;code&gt;y&lt;/code&gt; es el objetivo de verdad del terreno para &lt;code&gt;X&lt;/code&gt; (en el caso supervisado) o &lt;code&gt;None&lt;/code&gt; (en el caso no supervisado). caso).</target>
        </trans-unit>
        <trans-unit id="9a6afc7a825a539f282e6908ea3004d59da105e7" translate="yes" xml:space="preserve">
          <source>It can be downloaded/loaded using the &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_california_housing#sklearn.datasets.fetch_california_housing&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_california_housing&lt;/code&gt;&lt;/a&gt; function.</source>
          <target state="translated">Se puede descargar / cargar usando la funci&amp;oacute;n &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_california_housing#sklearn.datasets.fetch_california_housing&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_california_housing&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="afe5a10e4cd1db3d3b82e37290c3a4b0be9670c8" translate="yes" xml:space="preserve">
          <source>It can be interpreted as a weighted difference per entry.</source>
          <target state="translated">Puede interpretarse como una diferencia ponderada por cada entrada.</target>
        </trans-unit>
        <trans-unit id="d898e853ebb8a8ce7531765c1307531f5ab826e6" translate="yes" xml:space="preserve">
          <source>It can be noted that k-means (and minibatch k-means) are very sensitive to feature scaling and that in this case the IDF weighting helps improve the quality of the clustering by quite a lot as measured against the &amp;ldquo;ground truth&amp;rdquo; provided by the class label assignments of the 20 newsgroups dataset.</source>
          <target state="translated">Se puede observar que k-means (y minibatch k-means) son muy sensibles a la escala de caracter&amp;iacute;sticas y que, en este caso, la ponderaci&amp;oacute;n IDF ayuda a mejorar la calidad de la agrupaci&amp;oacute;n en bastante medida en comparaci&amp;oacute;n con la &quot;verdad b&amp;aacute;sica&quot; proporcionada por las asignaciones de etiquetas de clase del conjunto de datos de 20 grupos de noticias.</target>
        </trans-unit>
        <trans-unit id="074f1a9d1908eeea94dd9624b8e4e74f70971f1f" translate="yes" xml:space="preserve">
          <source>It can be seen from the plots that the results of &lt;a href=&quot;../../modules/linear_model#omp&quot;&gt;Orthogonal Matching Pursuit (OMP)&lt;/a&gt; with two non-zero coefficients is a bit less biased than when keeping only one (the edges look less prominent). It is in addition closer from the ground truth in Frobenius norm.</source>
          <target state="translated">Se puede ver en los gr&amp;aacute;ficos que los resultados de la &lt;a href=&quot;../../modules/linear_model#omp&quot;&gt;b&amp;uacute;squeda de correspondencia ortogonal (OMP)&lt;/a&gt; con dos coeficientes distintos de cero son un poco menos sesgados que cuando se mantiene solo uno (los bordes se ven menos prominentes). Adem&amp;aacute;s, est&amp;aacute; m&amp;aacute;s cerca de la verdad b&amp;aacute;sica en la norma Frobenius.</target>
        </trans-unit>
        <trans-unit id="0cf8fb702abea7c91fd29d6847c4f9bb34be57f9" translate="yes" xml:space="preserve">
          <source>It can be shown that the \(\nu\)-SVC formulation is a reparameterization of the \(C\)-SVC and therefore mathematically equivalent.</source>
          <target state="translated">Se puede demostrar que la formulación del CVC es una reparameterización del CVC y por lo tanto matemáticamente equivalente.</target>
        </trans-unit>
        <trans-unit id="157aa7190191e4be1be236c86eabe4e67d5e1efd" translate="yes" xml:space="preserve">
          <source>It can be used for univariate features selection, read more in the &lt;a href=&quot;../feature_selection#univariate-feature-selection&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">Se puede utilizar para la selecci&amp;oacute;n de funciones univariadas; lea m&amp;aacute;s en la &lt;a href=&quot;../feature_selection#univariate-feature-selection&quot;&gt;Gu&amp;iacute;a del usuario&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="711c50760d4f6c264d6b8a92b5297202a600fa0b" translate="yes" xml:space="preserve">
          <source>It can be used to include regularization parameters in the estimation procedure.</source>
          <target state="translated">Puede utilizarse para incluir parámetros de regularización en el procedimiento de estimación.</target>
        </trans-unit>
        <trans-unit id="e52b5bc871c7db656a1b43abcce93011714c74d2" translate="yes" xml:space="preserve">
          <source>It does not require a learning rate.</source>
          <target state="translated">No requiere un ritmo de aprendizaje.</target>
        </trans-unit>
        <trans-unit id="4d19424efe5e9e20338f3273e68fb2ccbb132c12" translate="yes" xml:space="preserve">
          <source>It doesn&amp;rsquo;t give a single metric to use as an objective for clustering optimisation.</source>
          <target state="translated">No proporciona una sola m&amp;eacute;trica para usar como objetivo para la optimizaci&amp;oacute;n de la agrupaci&amp;oacute;n en cl&amp;uacute;steres.</target>
        </trans-unit>
        <trans-unit id="0a46e66645323d1f8dad68441e68b478eacb85f4" translate="yes" xml:space="preserve">
          <source>It has been observed in [Hoyer, 2004] &lt;a href=&quot;#id12&quot; id=&quot;id6&quot;&gt;[2]&lt;/a&gt; that, when carefully constrained, &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;NMF&lt;/code&gt;&lt;/a&gt; can produce a parts-based representation of the dataset, resulting in interpretable models. The following example displays 16 sparse components found by &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;NMF&lt;/code&gt;&lt;/a&gt; from the images in the Olivetti faces dataset, in comparison with the PCA eigenfaces.</source>
          <target state="translated">Se ha observado en [Hoyer, 2004] &lt;a href=&quot;#id12&quot; id=&quot;id6&quot;&gt;[2]&lt;/a&gt; que, cuando se restringe cuidadosamente, &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt; &lt;code&gt;NMF&lt;/code&gt; &lt;/a&gt; puede producir una representaci&amp;oacute;n basada en partes del conjunto de datos, dando como resultado modelos interpretables. El siguiente ejemplo muestra 16 componentes dispersos encontrados por &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt; &lt;code&gt;NMF&lt;/code&gt; &lt;/a&gt; de las im&amp;aacute;genes en el conjunto de datos de caras de Olivetti, en comparaci&amp;oacute;n con las caras propias de PCA.</target>
        </trans-unit>
        <trans-unit id="8dcb00db48002a7fdf6f8f4ffd6c64f833e7dfb1" translate="yes" xml:space="preserve">
          <source>It has properties that are similar to the exponentiated chi squared kernel often used in computer vision, but allows for a simple Monte Carlo approximation of the feature map.</source>
          <target state="translated">Tiene propiedades que son similares a las del núcleo de chi cuadrado exponencial que se utiliza a menudo en la visión por computador,pero permite una simple aproximación de Monte Carlo del mapa de características.</target>
        </trans-unit>
        <trans-unit id="37dc8b6f979214e286ace27e5272dd91d61126bc" translate="yes" xml:space="preserve">
          <source>It has proven useful in ML applied to noiseless data. See e.g. &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1002/qua.24954/abstract/&quot;&gt;Machine learning for quantum mechanics in a nutshell&lt;/a&gt;.</source>
          <target state="translated">Ha demostrado su utilidad en ML aplicado a datos silenciosos. Ver, por ejemplo, &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1002/qua.24954/abstract/&quot;&gt;aprendizaje autom&amp;aacute;tico para la mec&amp;aacute;nica cu&amp;aacute;ntica en pocas palabras&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="e3ea912466304dbf8e7c52052ad02a2c286c1ad1" translate="yes" xml:space="preserve">
          <source>It implements a variant of Random Kitchen Sinks.[1]</source>
          <target state="translated">Implementa una variante de los fregaderos de cocina al azar.[1]</target>
        </trans-unit>
        <trans-unit id="74d404b8e11acc4d9a6402146bf70c71d78d2e94" translate="yes" xml:space="preserve">
          <source>It is a Linear Model trained with an L1 prior as regularizer.</source>
          <target state="translated">Es un Modelo Lineal entrenado con un L1 previo como regularizador.</target>
        </trans-unit>
        <trans-unit id="971eff281c404ac7ff23799c2f2e17c93f769de1" translate="yes" xml:space="preserve">
          <source>It is a memory-efficient, online-learning algorithm provided as an alternative to &lt;a href=&quot;sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt;&lt;code&gt;MiniBatchKMeans&lt;/code&gt;&lt;/a&gt;. It constructs a tree data structure with the cluster centroids being read off the leaf. These can be either the final cluster centroids or can be provided as input to another clustering algorithm such as &lt;a href=&quot;sklearn.cluster.agglomerativeclustering#sklearn.cluster.AgglomerativeClustering&quot;&gt;&lt;code&gt;AgglomerativeClustering&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Es un algoritmo de aprendizaje en l&amp;iacute;nea que ahorra memoria y se proporciona como alternativa a &lt;a href=&quot;sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt; &lt;code&gt;MiniBatchKMeans&lt;/code&gt; &lt;/a&gt; . Construye una estructura de datos de &amp;aacute;rbol con los centroides del cl&amp;uacute;ster que se leen de la hoja. Estos pueden ser los centroides del cl&amp;uacute;ster final o pueden proporcionarse como entrada a otro algoritmo de agrupamiento como &lt;a href=&quot;sklearn.cluster.agglomerativeclustering#sklearn.cluster.AgglomerativeClustering&quot;&gt; &lt;code&gt;AgglomerativeClustering&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="1a9933b24a1c1c056c0577574d6613078e271127" translate="yes" xml:space="preserve">
          <source>It is a parameter that control learning rate in the online learning method. The value should be set between (0.5, 1.0] to guarantee asymptotic convergence. When the value is 0.0 and batch_size is &lt;code&gt;n_samples&lt;/code&gt;, the update method is same as batch learning. In the literature, this is called kappa.</source>
          <target state="translated">Es un par&amp;aacute;metro que controla la tasa de aprendizaje en el m&amp;eacute;todo de aprendizaje en l&amp;iacute;nea. El valor debe establecerse entre (0.5, 1.0] para garantizar la convergencia asint&amp;oacute;tica. Cuando el valor es 0.0 y el tama&amp;ntilde;o del lote es &lt;code&gt;n_samples&lt;/code&gt; , el m&amp;eacute;todo de actualizaci&amp;oacute;n es el mismo que el aprendizaje por lotes. En la literatura, esto se llama kappa.</target>
        </trans-unit>
        <trans-unit id="15f125826dc7be5a6512e2415a2ab7dc87afbdb7" translate="yes" xml:space="preserve">
          <source>It is advised to set the parameter &lt;code&gt;epsilon&lt;/code&gt; to 1.35 to achieve 95% statistical efficiency.</source>
          <target state="translated">Se recomienda establecer el par&amp;aacute;metro &lt;code&gt;epsilon&lt;/code&gt; en 1,35 para lograr una eficiencia estad&amp;iacute;stica del 95%.</target>
        </trans-unit>
        <trans-unit id="542f7392581e6c4610879b36a37978fc74650959" translate="yes" xml:space="preserve">
          <source>It is also common among the text processing community to use binary feature values (probably to simplify the probabilistic reasoning) even if normalized counts (a.k.a. term frequencies) or TF-IDF valued features often perform slightly better in practice.</source>
          <target state="translated">También es común entre la comunidad de procesamiento de textos utilizar valores de características binarias (probablemente para simplificar el razonamiento probabilístico)aunque los recuentos normalizados (también conocidos como frecuencias de término)o las características valoradas de TF-IDF suelen tener un rendimiento ligeramente superior en la práctica.</target>
        </trans-unit>
        <trans-unit id="005dab4eb22b6ead110b29a8850c3898f552d977" translate="yes" xml:space="preserve">
          <source>It is also known as the Variance Ratio Criterion.</source>
          <target state="translated">También se conoce como el Criterio de la Relación de Variación.</target>
        </trans-unit>
        <trans-unit id="4221678f503b8b29e4ba191986027706279048ac" translate="yes" xml:space="preserve">
          <source>It is also possible to constrain the dictionary and/or code to be positive to match constraints that may be present in the data. Below are the faces with different positivity constraints applied. Red indicates negative values, blue indicates positive values, and white represents zeros.</source>
          <target state="translated">También es posible restringir el diccionario y/o el código para que sean positivos y se ajusten a las limitaciones que puedan estar presentes en los datos.A continuación se presentan las caras con diferentes restricciones de positividad aplicadas.El rojo indica valores negativos,el azul indica valores positivos y el blanco representa ceros.</target>
        </trans-unit>
        <trans-unit id="cd4e94997f77b01819c6451ba1d9a9d98a78db7c" translate="yes" xml:space="preserve">
          <source>It is also possible to efficiently produce a sparse graph showing the connections between neighboring points:</source>
          <target state="translated">También es posible producir eficientemente un gráfico disperso que muestre las conexiones entre los puntos vecinos:</target>
        </trans-unit>
        <trans-unit id="e5cc911e1a3213d4a6ea82327423c6b7195a9251" translate="yes" xml:space="preserve">
          <source>It is also possible to map data to a normal distribution using &lt;a href=&quot;generated/sklearn.preprocessing.quantiletransformer#sklearn.preprocessing.QuantileTransformer&quot;&gt;&lt;code&gt;QuantileTransformer&lt;/code&gt;&lt;/a&gt; by setting &lt;code&gt;output_distribution='normal'&lt;/code&gt;. Using the earlier example with the iris dataset:</source>
          <target state="translated">Tambi&amp;eacute;n es posible asignar los datos a una distribuci&amp;oacute;n normal usando &lt;a href=&quot;generated/sklearn.preprocessing.quantiletransformer#sklearn.preprocessing.QuantileTransformer&quot;&gt; &lt;code&gt;QuantileTransformer&lt;/code&gt; &lt;/a&gt; configurando &lt;code&gt;output_distribution='normal'&lt;/code&gt; . Usando el ejemplo anterior con el conjunto de datos de iris:</target>
        </trans-unit>
        <trans-unit id="f35eb3fdcbe153523a6b78440df1aad8edf3b026" translate="yes" xml:space="preserve">
          <source>It is also possible to use other cross validation strategies by passing a cross validation iterator instead, for instance:</source>
          <target state="translated">También es posible utilizar otras estrategias de validación cruzada aprobando en su lugar un iterador de validación cruzada,por ejemplo:</target>
        </trans-unit>
        <trans-unit id="c62a692f1bef88aa9ea1dc55b02f68e6ac2b429f" translate="yes" xml:space="preserve">
          <source>It is classically used to separate mixed signals (a problem known as &lt;em&gt;blind source separation&lt;/em&gt;), as in the example below:</source>
          <target state="translated">Se utiliza cl&amp;aacute;sicamente para separar se&amp;ntilde;ales mixtas (un problema conocido como &lt;em&gt;separaci&amp;oacute;n ciega de fuentes&lt;/em&gt; ), como en el ejemplo siguiente:</target>
        </trans-unit>
        <trans-unit id="579f13cf2a54010546e31ecfaa7ced83f4da4e12" translate="yes" xml:space="preserve">
          <source>It is computationally just as fast as forward selection and has the same order of complexity as an ordinary least squares.</source>
          <target state="translated">Es computacionalmente tan rápido como la selección hacia adelante y tiene el mismo orden de complejidad que un mínimo cuadrado ordinario.</target>
        </trans-unit>
        <trans-unit id="2a0b5a3028e23e8f66ba4845cf98605a35e74ca3" translate="yes" xml:space="preserve">
          <source>It is converted to an F score then to a p-value.</source>
          <target state="translated">Se convierte en una puntuación F y luego en un valor p.</target>
        </trans-unit>
        <trans-unit id="9da4ca4cacbca0baec3287f1b2124c4dcd00df7a" translate="yes" xml:space="preserve">
          <source>It is easily modified to produce solutions for other estimators, like the Lasso.</source>
          <target state="translated">Se modifica fácilmente para producir soluciones para otros estimadores,como el Lazo.</target>
        </trans-unit>
        <trans-unit id="a180f7cced602efdc3c3224733570427c990972f" translate="yes" xml:space="preserve">
          <source>It is easy for a classifier to overfit on particular things that appear in the 20 Newsgroups data, such as newsgroup headers. Many classifiers achieve very high F-scores, but their results would not generalize to other documents that aren&amp;rsquo;t from this window of time.</source>
          <target state="translated">Es f&amp;aacute;cil para un clasificador sobreajustarse en cosas particulares que aparecen en los datos de los 20 grupos de noticias, como los encabezados de los grupos de noticias. Muchos clasificadores logran puntuaciones F muy altas, pero sus resultados no se generalizar&amp;iacute;an a otros documentos que no pertenecen a esta ventana de tiempo.</target>
        </trans-unit>
        <trans-unit id="2e5aa329cff0eb3a121eaf66246e864cad7413ee" translate="yes" xml:space="preserve">
          <source>It is highly recommended to use another dimensionality reduction method (e.g. PCA for dense data or TruncatedSVD for sparse data) to reduce the number of dimensions to a reasonable amount (e.g. 50) if the number of features is very high. This will suppress some noise and speed up the computation of pairwise distances between samples. For more tips see Laurens van der Maaten&amp;rsquo;s FAQ [2].</source>
          <target state="translated">Se recomienda utilizar otro m&amp;eacute;todo de reducci&amp;oacute;n de dimensionalidad (por ejemplo, PCA para datos densos o TruncatedSVD para datos escasos) para reducir el n&amp;uacute;mero de dimensiones a una cantidad razonable (por ejemplo, 50) si el n&amp;uacute;mero de caracter&amp;iacute;sticas es muy alto. Esto suprimir&amp;aacute; algo de ruido y acelerar&amp;aacute; el c&amp;aacute;lculo de distancias por pares entre muestras. Para obtener m&amp;aacute;s consejos, consulte las preguntas frecuentes de Laurens van der Maaten [2].</target>
        </trans-unit>
        <trans-unit id="4c694641d1b1cd9e68259bd2f7aabf747615adda" translate="yes" xml:space="preserve">
          <source>It is important to assign an identifier to unlabeled points along with the labeled data when training the model with the &lt;code&gt;fit&lt;/code&gt; method. The identifier that this implementation uses is the integer value \(-1\).</source>
          <target state="translated">Es importante asignar un identificador a los puntos sin etiquetar junto con los datos etiquetados al entrenar el modelo con el m&amp;eacute;todo de &lt;code&gt;fit&lt;/code&gt; . El identificador que utiliza esta implementaci&amp;oacute;n es el valor entero \ (- 1 \).</target>
        </trans-unit>
        <trans-unit id="a067b4f8fd8c4002a8fc9abd7aa015e146d303ad" translate="yes" xml:space="preserve">
          <source>It is important to note that when the number of samples is much larger than the number of features, one would expect that no shrinkage would be necessary. The intuition behind this is that if the population covariance is full rank, when the number of sample grows, the sample covariance will also become positive definite. As a result, no shrinkage would necessary and the method should automatically do this.</source>
          <target state="translated">Es importante señalar que cuando el número de muestras es mucho mayor que el número de características,es de esperar que no sea necesario reducirlo.La intuición que subyace a esto es que si la covarianza de la población es de rango completo,cuando el número de muestras aumente,la covarianza de la muestra también se convertirá en definitiva positiva.Como resultado,no sería necesaria ninguna contracción y el método debería hacer esto automáticamente.</target>
        </trans-unit>
        <trans-unit id="d9e45bb570908f10d72f7b51c91c236b78670a3c" translate="yes" xml:space="preserve">
          <source>It is made of 150 observations of irises, each described by 4 features: their sepal and petal length and width, as detailed in &lt;code&gt;iris.DESCR&lt;/code&gt;.</source>
          <target state="translated">Se compone de 150 observaciones de iris, cada una descrita por 4 caracter&amp;iacute;sticas: su s&amp;eacute;palo y el largo y ancho de los p&amp;eacute;talos, como se detalla en &lt;code&gt;iris.DESCR&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1856ef8269f110a1ccc7c37c9db810b8176fc5f8" translate="yes" xml:space="preserve">
          <source>It is more efficient than the LassoCV if only a small number of features are selected compared to the total number, for instance if there are very few samples compared to the number of features.</source>
          <target state="translated">Es más eficiente que el LassoCV si sólo se selecciona un pequeño número de características en comparación con el número total,por ejemplo si hay muy pocas muestras en comparación con el número de características.</target>
        </trans-unit>
        <trans-unit id="1d58fe1839ae301f10f6b9aaac159ed67a9eabfe" translate="yes" xml:space="preserve">
          <source>It is not appropriate to pass these predictions into an evaluation metric. Use &lt;a href=&quot;sklearn.model_selection.cross_validate#sklearn.model_selection.cross_validate&quot;&gt;&lt;code&gt;cross_validate&lt;/code&gt;&lt;/a&gt; to measure generalization error.</source>
          <target state="translated">No es apropiado pasar estas predicciones a una m&amp;eacute;trica de evaluaci&amp;oacute;n. Utilice &lt;a href=&quot;sklearn.model_selection.cross_validate#sklearn.model_selection.cross_validate&quot;&gt; &lt;code&gt;cross_validate&lt;/code&gt; &lt;/a&gt; para medir el error de generalizaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="9af2e9f8fa22ff915f29e1a168987ff536812b91" translate="yes" xml:space="preserve">
          <source>It is not recommended to hard-code the backend name in a call to Parallel in a library. Instead it is recommended to set soft hints (prefer) or hard constraints (require) so as to make it possible for library users to change the backend from the outside using the parallel_backend context manager.</source>
          <target state="translated">No es recomendable codificar el nombre del backend en una llamada a Paralelo en una biblioteca.En su lugar se recomienda establecer sugerencias suaves (preferir)o restricciones duras (requerir)para hacer posible que los usuarios de la biblioteca cambien el backend desde el exterior usando el gestor de contexto parallel_backend.</target>
        </trans-unit>
        <trans-unit id="b26cf025ddad5c1f883715bf24d85887eccade22" translate="yes" xml:space="preserve">
          <source>It is not regularized (penalized).</source>
          <target state="translated">No se regulariza (penaliza).</target>
        </trans-unit>
        <trans-unit id="f18c5e38092754d2adb7bb6eb5c0799854e297b3" translate="yes" xml:space="preserve">
          <source>It is numerically efficient in contexts where p &amp;gt;&amp;gt; n (i.e., when the number of dimensions is significantly greater than the number of points)</source>
          <target state="translated">Es num&amp;eacute;ricamente eficiente en contextos donde p &amp;gt;&amp;gt; n (es decir, cuando el n&amp;uacute;mero de dimensiones es significativamente mayor que el n&amp;uacute;mero de puntos)</target>
        </trans-unit>
        <trans-unit id="8c7122bd43c891f087ca247f2fcde5236f637b0c" translate="yes" xml:space="preserve">
          <source>It is often interesting to project data to a lower-dimensional space that preserves most of the variance, by dropping the singular vector of components associated with lower singular values.</source>
          <target state="translated">A menudo es interesante proyectar los datos a un espacio de dimensiones más bajas que conserve la mayor parte de la varianza,dejando caer el vector singular de componentes asociados con valores singulares más bajos.</target>
        </trans-unit>
        <trans-unit id="5ed0af274291a2311daa7ee05d7bd79f85fc7e49" translate="yes" xml:space="preserve">
          <source>It is possible and recommended to search the hyper-parameter space for the best &lt;a href=&quot;cross_validation#cross-validation&quot;&gt;cross validation&lt;/a&gt; score.</source>
          <target state="translated">Es posible y recomendable buscar en el espacio de hiperpar&amp;aacute;metros para obtener la mejor puntuaci&amp;oacute;n de &lt;a href=&quot;cross_validation#cross-validation&quot;&gt;validaci&amp;oacute;n cruzada&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="19b21329d1ba1e2fd90b4634d03905cf0f5e7826" translate="yes" xml:space="preserve">
          <source>It is possible to adjust the threshold of the binarizer:</source>
          <target state="translated">Es posible ajustar el umbral del binarizador:</target>
        </trans-unit>
        <trans-unit id="5fdc4b2c9af36a36fca156373f6cb7c574f550b3" translate="yes" xml:space="preserve">
          <source>It is possible to compute per-label precisions, recalls, F1-scores and supports instead of averaging:</source>
          <target state="translated">Es posible calcular las precisiones,retiradas,puntuaciones F1 y soportes por etiqueta en lugar de hacer un promedio:</target>
        </trans-unit>
        <trans-unit id="c890fcaf4f6baafc6ccf39a67fce7daf92b8b950" translate="yes" xml:space="preserve">
          <source>It is possible to control the randomness for reproducibility of the results by explicitly seeding the &lt;code&gt;random_state&lt;/code&gt; pseudo random number generator.</source>
          <target state="translated">Es posible controlar la aleatoriedad para la reproducibilidad de los resultados mediante la siembra expl&amp;iacute;cita del generador de n&amp;uacute;meros pseudoaleatorios &lt;code&gt;random_state&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8c436001d07579c89b669f127dbaf0c3bd65de34" translate="yes" xml:space="preserve">
          <source>It is possible to customize the behavior by passing a callable to the vectorizer constructor:</source>
          <target state="translated">Es posible personalizar el comportamiento pasando una llamada al constructor del vectorizador:</target>
        </trans-unit>
        <trans-unit id="0839b4d3a34db46e778e581b781425b62631583b" translate="yes" xml:space="preserve">
          <source>It is possible to disable either centering or scaling by either passing &lt;code&gt;with_mean=False&lt;/code&gt; or &lt;code&gt;with_std=False&lt;/code&gt; to the constructor of &lt;a href=&quot;generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt;&lt;code&gt;StandardScaler&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Es posible deshabilitar el centrado o el escalado pasando &lt;code&gt;with_mean=False&lt;/code&gt; o &lt;code&gt;with_std=False&lt;/code&gt; al constructor de &lt;a href=&quot;generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt; &lt;code&gt;StandardScaler&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="85a1eed4b8a0f5199be27070848fbc013f8f8638" translate="yes" xml:space="preserve">
          <source>It is possible to get back the category names as follows:</source>
          <target state="translated">Es posible recuperar los nombres de las categorías de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="6b11842b410c7ed9014abd60118219965dd51782" translate="yes" xml:space="preserve">
          <source>It is possible to introspect the scaler attributes to find about the exact nature of the transformation learned on the training data:</source>
          <target state="translated">Es posible hacer una introspección de los atributos del escalador para averiguar la naturaleza exacta de la transformación aprendida en los datos de entrenamiento:</target>
        </trans-unit>
        <trans-unit id="d994dbf018869cdf387e647211852d55a08f6930" translate="yes" xml:space="preserve">
          <source>It is possible to load only a sub-selection of the categories by passing the list of the categories to load to the &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Es posible cargar solo una sub-selecci&amp;oacute;n de las categor&amp;iacute;as pasando la lista de categor&amp;iacute;as para cargar a la funci&amp;oacute;n &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="03749a52f5e2e7e976928d01767369407c7307c4" translate="yes" xml:space="preserve">
          <source>It is possible to mix sparse and dense arrays in the same run:</source>
          <target state="translated">Es posible mezclar conjuntos dispersos y densos en la misma carrera:</target>
        </trans-unit>
        <trans-unit id="be16ce674bae3bf54f6cdc3d4d41c5990ca746b6" translate="yes" xml:space="preserve">
          <source>It is possible to overcome those limitations by combining the &amp;ldquo;hashing trick&amp;rdquo; (&lt;a href=&quot;#feature-hashing&quot;&gt;Feature hashing&lt;/a&gt;) implemented by the &lt;a href=&quot;generated/sklearn.feature_extraction.featurehasher#sklearn.feature_extraction.FeatureHasher&quot;&gt;&lt;code&gt;sklearn.feature_extraction.FeatureHasher&lt;/code&gt;&lt;/a&gt; class and the text preprocessing and tokenization features of the &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Es posible superar esas limitaciones combinando el &quot;truco de hash&quot; ( &lt;a href=&quot;#feature-hashing&quot;&gt;Feature hashing&lt;/a&gt; ) implementado por la clase &lt;a href=&quot;generated/sklearn.feature_extraction.featurehasher#sklearn.feature_extraction.FeatureHasher&quot;&gt; &lt;code&gt;sklearn.feature_extraction.FeatureHasher&lt;/code&gt; &lt;/a&gt; y las caracter&amp;iacute;sticas de preprocesamiento y tokenizaci&amp;oacute;n de texto del &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="737f1fd475d1dc22b14b4896563d476e36ccb4e8" translate="yes" xml:space="preserve">
          <source>It is possible to save a model in scikit-learn by using Python&amp;rsquo;s built-in persistence model, &lt;a href=&quot;https://docs.python.org/2/library/pickle.html&quot;&gt;pickle&lt;/a&gt;:</source>
          <target state="translated">Es posible guardar un modelo en scikit-learn usando el modelo de persistencia incorporado de Python, &lt;a href=&quot;https://docs.python.org/2/library/pickle.html&quot;&gt;pickle&lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="1d319918af937e7b588f1bdf4ba0c9bc1d2e6a8f" translate="yes" xml:space="preserve">
          <source>It is possible to save a model in scikit-learn by using Python&amp;rsquo;s built-in persistence model, namely &lt;a href=&quot;https://docs.python.org/2/library/pickle.html&quot;&gt;pickle&lt;/a&gt;:</source>
          <target state="translated">Es posible guardar un modelo en scikit-learn usando el modelo de persistencia incorporado de Python, a saber, &lt;a href=&quot;https://docs.python.org/2/library/pickle.html&quot;&gt;pickle&lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="33bdca276514e666ea92e40ef8d9c04e5206a96b" translate="yes" xml:space="preserve">
          <source>It is possible to specify this explicitly using the parameter &lt;code&gt;categories&lt;/code&gt;. There are two genders, four possible continents and four web browsers in our dataset:</source>
          <target state="translated">Es posible especificar esto expl&amp;iacute;citamente utilizando las &lt;code&gt;categories&lt;/code&gt; par&amp;aacute;metros . Hay dos g&amp;eacute;neros, cuatro continentes posibles y cuatro navegadores web en nuestro conjunto de datos:</target>
        </trans-unit>
        <trans-unit id="cbfa3a3539d1ad40958cd50540686b2891b5e349" translate="yes" xml:space="preserve">
          <source>It is sometimes not enough to center and scale the features independently, since a downstream model can further make some assumption on the linear independence of the features.</source>
          <target state="translated">A veces no basta con centrar y escalar los rasgos de forma independiente,ya que un modelo posterior puede hacer algunas suposiciones sobre la independencia lineal de los rasgos.</target>
        </trans-unit>
        <trans-unit id="311a1593daf1f1187805481bab88c0d399c3cecf" translate="yes" xml:space="preserve">
          <source>It is sometimes worthwhile storing the state of a specific transformer since it could be used again. Using a pipeline in &lt;code&gt;GridSearchCV&lt;/code&gt; triggers such situations. Therefore, we use the argument &lt;code&gt;memory&lt;/code&gt; to enable caching.</source>
          <target state="translated">A veces vale la pena almacenar el estado de un transformador espec&amp;iacute;fico, ya que podr&amp;iacute;a usarse nuevamente. El uso de una canalizaci&amp;oacute;n en &lt;code&gt;GridSearchCV&lt;/code&gt; desencadena este tipo de situaciones. Por lo tanto, usamos la &lt;code&gt;memory&lt;/code&gt; argumentos para habilitar el almacenamiento en cach&amp;eacute;.</target>
        </trans-unit>
        <trans-unit id="ba51434e495bfdf85ff2401c563345468fae8389" translate="yes" xml:space="preserve">
          <source>It is the fastest algorithm for learning mixture models</source>
          <target state="translated">Es el algoritmo más rápido para el aprendizaje de modelos de mezcla</target>
        </trans-unit>
        <trans-unit id="5c9cedaa4c291702a05bee05d8b7517536cf8c97" translate="yes" xml:space="preserve">
          <source>It is the opposite as as bigger is better, i.e. large values correspond to inliers.</source>
          <target state="translated">Es lo contrario,ya que cuanto más grande es mejor,es decir,los valores grandes corresponden a los inliers.</target>
        </trans-unit>
        <trans-unit id="b0c456c256349cc53ca134d105c8be601465dd39" translate="yes" xml:space="preserve">
          <source>It is worth noting that RandomForests and ExtraTrees can be fitted in parallel on many cores as each tree is built independently of the others. AdaBoost&amp;rsquo;s samples are built sequentially and so do not use multiple cores.</source>
          <target state="translated">Vale la pena se&amp;ntilde;alar que RandomForests y ExtraTrees se pueden instalar en paralelo en muchos n&amp;uacute;cleos, ya que cada &amp;aacute;rbol se construye independientemente de los dem&amp;aacute;s. Las muestras de AdaBoost se crean secuencialmente y, por lo tanto, no utilizan varios n&amp;uacute;cleos.</target>
        </trans-unit>
        <trans-unit id="a4029704b1c865bc18db0f7f71b472d5421882ac" translate="yes" xml:space="preserve">
          <source>It produces a full piecewise linear solution path, which is useful in cross-validation or similar attempts to tune the model.</source>
          <target state="translated">Produce un camino de solución lineal completo,que es útil en la validación cruzada o intentos similares para afinar el modelo.</target>
        </trans-unit>
        <trans-unit id="a4dee1947755b5fe4ca1a29e0b9b0f0b85817660" translate="yes" xml:space="preserve">
          <source>It returns a dict containing fit-times, score-times (and optionally training scores as well as fitted estimators) in addition to the test score.</source>
          <target state="translated">Devuelve un dictado que contiene tiempos de ajuste,tiempos de puntuación (y opcionalmente puntuaciones de entrenamiento así como estimadores ajustados)además de la puntuación de la prueba.</target>
        </trans-unit>
        <trans-unit id="be2089f68dcca4fd6c2250f878425dd499fc444a" translate="yes" xml:space="preserve">
          <source>It returns a dictionary-like object, with the following attributes:</source>
          <target state="translated">Devuelve un objeto parecido a un diccionario,con los siguientes atributos:</target>
        </trans-unit>
        <trans-unit id="6f65f619abd94296c7075a4b5d91a76ac1e641bc" translate="yes" xml:space="preserve">
          <source>It returns a floating point number that quantifies the &lt;code&gt;estimator&lt;/code&gt; prediction quality on &lt;code&gt;X&lt;/code&gt;, with reference to &lt;code&gt;y&lt;/code&gt;. Again, by convention higher numbers are better, so if your scorer returns loss, that value should be negated.</source>
          <target state="translated">Devuelve un n&amp;uacute;mero de punto flotante que cuantifica la calidad de la predicci&amp;oacute;n del &lt;code&gt;estimator&lt;/code&gt; en &lt;code&gt;X&lt;/code&gt; , con referencia &lt;code&gt;y&lt;/code&gt; . Nuevamente, por convenci&amp;oacute;n, los n&amp;uacute;meros m&amp;aacute;s altos son mejores, por lo que si su anotador devuelve p&amp;eacute;rdidas, ese valor debe negarse.</target>
        </trans-unit>
        <trans-unit id="58c0c1b9288f5ba70bfdf3e509c8376ea38265d4" translate="yes" xml:space="preserve">
          <source>It should be noted that Johnson-Lindenstrauss lemma can yield very conservative estimated of the required number of components as it makes no assumption on the structure of the dataset.</source>
          <target state="translated">Cabe señalar que el lema de Johnson-Lindenstrauss puede dar una estimación muy conservadora del número necesario de componentes,ya que no hace ninguna suposición sobre la estructura del conjunto de datos.</target>
        </trans-unit>
        <trans-unit id="5bcecde02163a3a6b9fb69b7700a66c21be36347" translate="yes" xml:space="preserve">
          <source>It shows how to use &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt;&lt;code&gt;RBFSampler&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt;&lt;code&gt;Nystroem&lt;/code&gt;&lt;/a&gt; to approximate the feature map of an RBF kernel for classification with an SVM on the digits dataset. Results using a linear SVM in the original space, a linear SVM using the approximate mappings and using a kernelized SVM are compared. Timings and accuracy for varying amounts of Monte Carlo samplings (in the case of &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt;&lt;code&gt;RBFSampler&lt;/code&gt;&lt;/a&gt;, which uses random Fourier features) and different sized subsets of the training set (for &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt;&lt;code&gt;Nystroem&lt;/code&gt;&lt;/a&gt;) for the approximate mapping are shown.</source>
          <target state="translated">Muestra c&amp;oacute;mo usar &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt; &lt;code&gt;RBFSampler&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt; &lt;code&gt;Nystroem&lt;/code&gt; &lt;/a&gt; para aproximar el mapa de caracter&amp;iacute;sticas de un kernel RBF para la clasificaci&amp;oacute;n con una SVM en el conjunto de datos de d&amp;iacute;gitos. Se comparan los resultados usando una SVM lineal en el espacio original, una SVM lineal usando las asignaciones aproximadas y usando una SVM kernelizada. Se muestran los tiempos y la precisi&amp;oacute;n para cantidades variables de muestreos de Monte Carlo (en el caso de &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt; &lt;code&gt;RBFSampler&lt;/code&gt; &lt;/a&gt; , que usa caracter&amp;iacute;sticas aleatorias de Fourier) y subconjuntos de diferentes tama&amp;ntilde;os del conjunto de entrenamiento (para &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt; &lt;code&gt;Nystroem&lt;/code&gt; &lt;/a&gt; ) para el mapeo aproximado.</target>
        </trans-unit>
        <trans-unit id="45249c231a1e8d583e28deb277d22f5fe88e16b7" translate="yes" xml:space="preserve">
          <source>It turns a collection of text documents into a scipy.sparse matrix holding token occurrence counts (or binary occurrence information), possibly normalized as token frequencies if norm=&amp;rsquo;l1&amp;rsquo; or projected on the euclidean unit sphere if norm=&amp;rsquo;l2&amp;rsquo;.</source>
          <target state="translated">Convierte una colecci&amp;oacute;n de documentos de texto en una matriz scipy.sparse que contiene recuentos de ocurrencia de tokens (o informaci&amp;oacute;n de ocurrencia binaria), posiblemente normalizada como frecuencias de tokens si norm = 'l1' o proyectada en la esfera de la unidad euclidiana si norm = 'l2'.</target>
        </trans-unit>
        <trans-unit id="9b65a724f589693294d8b39fded9beef68bf84ef" translate="yes" xml:space="preserve">
          <source>It updates its model only on mistakes.</source>
          <target state="translated">Actualiza su modelo sólo en los errores.</target>
        </trans-unit>
        <trans-unit id="4ef1ebaa3d2757730ff62ab1b50211fc95aec89a" translate="yes" xml:space="preserve">
          <source>It uses the LAPACK implementation of the full SVD or a randomized truncated SVD by the method of Halko et al. 2009, depending on the shape of the input data and the number of components to extract.</source>
          <target state="translated">Utiliza la implementación LAPACK de la SVD completa o una SVD truncada aleatoriamente por el método de Halko et al.2009,dependiendo de la forma de los datos de entrada y el número de componentes a extraer.</target>
        </trans-unit>
        <trans-unit id="eb35f7366145b28ea8e69aba84c19929cb4fd162" translate="yes" xml:space="preserve">
          <source>It&amp;rsquo;s also possible for almost all of these function to constrain the output to be a tuple containing only the data and the target, by setting the &lt;code&gt;return_X_y&lt;/code&gt; parameter to &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">Tambi&amp;eacute;n es posible que casi todas estas funciones restrinjan la salida para que sea una tupla que contenga solo los datos y el destino, estableciendo el par&amp;aacute;metro &lt;code&gt;return_X_y&lt;/code&gt; en &lt;code&gt;True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="522ad20a1aa12ab3e8e796322f388a9318be6368" translate="yes" xml:space="preserve">
          <source>It&amp;rsquo;s clear how the kernel shape affects the smoothness of the resulting distribution. The scikit-learn kernel density estimator can be used as follows:</source>
          <target state="translated">Est&amp;aacute; claro c&amp;oacute;mo la forma del grano afecta la suavidad de la distribuci&amp;oacute;n resultante. El estimador de densidad del kernel de scikit-learn se puede utilizar de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="262f72bd253b7e8f886f3645ecd5afaaf624d7fc" translate="yes" xml:space="preserve">
          <source>Iterate 2 and 3 until convergence.</source>
          <target state="translated">Iterar 2 y 3 hasta la convergencia.</target>
        </trans-unit>
        <trans-unit id="f2f172891cc8c1241e8513ed23c4f46ceb939f0f" translate="yes" xml:space="preserve">
          <source>Iterative procedure to maximize the evidence</source>
          <target state="translated">Procedimiento iterativo para maximizar la evidencia</target>
        </trans-unit>
        <trans-unit id="1e87dcaf344d15783f1af4ad18b162b497d772d4" translate="yes" xml:space="preserve">
          <source>Its dual is</source>
          <target state="translated">Su doble es</target>
        </trans-unit>
        <trans-unit id="4ba292a3729a3ffa6797e98ae7a24bba4f0e087f" translate="yes" xml:space="preserve">
          <source>J. Davis, M. Goadrich, &lt;a href=&quot;http://www.machinelearning.org/proceedings/icml2006/030_The_Relationship_Bet.pdf&quot;&gt;The Relationship Between Precision-Recall and ROC Curves&lt;/a&gt;, ICML 2006.</source>
          <target state="translated">J. Davis, M. Goadrich, &lt;a href=&quot;http://www.machinelearning.org/proceedings/icml2006/030_The_Relationship_Bet.pdf&quot;&gt;La relaci&amp;oacute;n entre precisi&amp;oacute;n-recuperaci&amp;oacute;n y curvas ROC&lt;/a&gt; , ICML 2006.</target>
        </trans-unit>
        <trans-unit id="9f9ca6a90c561398be254053aedc4a945c9160d7" translate="yes" xml:space="preserve">
          <source>J. Friedman, &amp;ldquo;Multivariate adaptive regression splines&amp;rdquo;, The Annals of Statistics 19 (1), pages 1-67, 1991.</source>
          <target state="translated">J. Friedman, &quot;Splines de regresi&amp;oacute;n adaptativa multivariante&quot;, The Annals of Statistics 19 (1), p&amp;aacute;ginas 1-67, 1991.</target>
        </trans-unit>
        <trans-unit id="f3a4e2abf1b3937c134504328e857f33b32a50ea" translate="yes" xml:space="preserve">
          <source>J. Friedman, Greedy Function Approximation: A Gradient Boosting Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.</source>
          <target state="translated">J.Friedman,Aproximación de la Función Codiciosa:A Gradient Boosting Machine,The Annals of Statistics,Vol.29,No.5,2001.</target>
        </trans-unit>
        <trans-unit id="37cd6f13ac969b2cba8a5a7a242580515d06793b" translate="yes" xml:space="preserve">
          <source>J. Mairal, F. Bach, J. Ponce, G. Sapiro, 2009: Online dictionary learning for sparse coding (&lt;a href=&quot;http://www.di.ens.fr/sierra/pdfs/icml09.pdf&quot;&gt;http://www.di.ens.fr/sierra/pdfs/icml09.pdf&lt;/a&gt;)</source>
          <target state="translated">J. Mairal, F. Bach, J. Ponce, G. Sapiro, 2009: Aprendizaje de diccionarios en l&amp;iacute;nea para codificaci&amp;oacute;n dispersa ( &lt;a href=&quot;http://www.di.ens.fr/sierra/pdfs/icml09.pdf&quot;&gt;http://www.di.ens.fr/sierra/pdfs/icml09.pdf&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="d67bb0042b556d1819c5bcf6e551c8393e0d921f" translate="yes" xml:space="preserve">
          <source>J. Nothman, H. Qin and R. Yurchak (2018). &lt;a href=&quot;http://aclweb.org/anthology/W18-2502&quot;&gt;&amp;ldquo;Stop Word Lists in Free Open-source Software Packages&amp;rdquo;&lt;/a&gt;. In &lt;em&gt;Proc. Workshop for NLP Open Source Software&lt;/em&gt;.</source>
          <target state="translated">J. Nothman, H. Qin y R. Yurchak (2018). &lt;a href=&quot;http://aclweb.org/anthology/W18-2502&quot;&gt;&quot;Detener listas de palabras en paquetes de software de c&amp;oacute;digo abierto gratuitos&quot;&lt;/a&gt; . En &lt;em&gt;Proc. Taller de software de c&amp;oacute;digo abierto de PNL&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="692e866d29ab5ac27b12eb939942a283756e56c6" translate="yes" xml:space="preserve">
          <source>J. Zhu, H. Zou, S. Rosset, T. Hastie. &amp;ldquo;Multi-class AdaBoost&amp;rdquo;, 2009.</source>
          <target state="translated">J. Zhu, H. Zou, S. Rosset, T. Hastie. &amp;ldquo;AdaBoost de varias clases&amp;rdquo;, 2009.</target>
        </trans-unit>
        <trans-unit id="5d92020b429e9c336d3ae7d33c4ba163d63036bb" translate="yes" xml:space="preserve">
          <source>J.R. Quinlan. C4. 5: programs for machine learning. Morgan Kaufmann, 1993.</source>
          <target state="translated">J.R.Quinlan.C4.5:programas para el aprendizaje de la máquina.Morgan Kaufmann,1993.</target>
        </trans-unit>
        <trans-unit id="b259e0488f66e10ad76098d33440aa4c5f23c876" translate="yes" xml:space="preserve">
          <source>JA Wegelin &lt;a href=&quot;https://www.stat.washington.edu/research/reports/2000/tr371.pdf&quot;&gt;A survey of Partial Least Squares (PLS) methods, with emphasis on the two-block case&lt;/a&gt;</source>
          <target state="translated">JA Wegelin &lt;a href=&quot;https://www.stat.washington.edu/research/reports/2000/tr371.pdf&quot;&gt;Una encuesta de m&amp;eacute;todos de m&amp;iacute;nimos cuadrados parciales (PLS), con &amp;eacute;nfasis en el caso de dos bloques&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="89591613ce2ead27076b0dd7b68b18da1f4e31d9" translate="yes" xml:space="preserve">
          <source>Jaccard similarity coefficient score</source>
          <target state="translated">La puntuación del coeficiente de similitud de Jaccard</target>
        </trans-unit>
        <trans-unit id="3dd35b446a7d3de6ee5688cfabde9bb7cc55f61a" translate="yes" xml:space="preserve">
          <source>JaccardDistance</source>
          <target state="translated">JaccardDistance</target>
        </trans-unit>
        <trans-unit id="493395686693db33a59d5eea00e82ad6c02c5742" translate="yes" xml:space="preserve">
          <source>Jacob A. Wegelin. A survey of Partial Least Squares (PLS) methods, with emphasis on the two-block case. Technical Report 371, Department of Statistics, University of Washington, Seattle, 2000.</source>
          <target state="translated">Jacob A.Wegelin.Un estudio de los métodos de mínimos cuadrados parciales (PLS),con énfasis en el caso de los dos bloques.Informe técnico 371,Departamento de Estadística,Universidad de Washington,Seattle,2000.</target>
        </trans-unit>
        <trans-unit id="80af07b09c2acb231d89e62f1382b88433574f92" translate="yes" xml:space="preserve">
          <source>Jesse Read, Bernhard Pfahringer, Geoff Holmes, Eibe Frank,</source>
          <target state="translated">Jesse Read,Bernhard Pfahringer,Geoff Holmes,Yew Frank,</target>
        </trans-unit>
        <trans-unit id="6f9c9a3eee3a8f7459d68946df6ef289f22fee94" translate="yes" xml:space="preserve">
          <source>Jesse Read, Bernhard Pfahringer, Geoff Holmes, Eibe Frank, &amp;ldquo;Classifier Chains for Multi-label Classification&amp;rdquo;, 2009.</source>
          <target state="translated">Jesse Read, Bernhard Pfahringer, Geoff Holmes, Eibe Frank, &amp;ldquo;Cadenas clasificadoras para clasificaci&amp;oacute;n de etiquetas m&amp;uacute;ltiples&amp;rdquo;, 2009.</target>
        </trans-unit>
        <trans-unit id="2da78ef6529cd970b51628e985f5f2ea249ac134" translate="yes" xml:space="preserve">
          <source>Johanna Hardin, David M Rocke. The distribution of robust distances. Journal of Computational and Graphical Statistics. December 1, 2005, 14(4): 928-946.</source>
          <target state="translated">Johanna Hardin,David M.Rocke.La distribución de las distancias robustas.Revista de Estadísticas Gráficas y Computacionales.1 de diciembre de 2005,14(4):928-946.</target>
        </trans-unit>
        <trans-unit id="f669c43cc07002b0d2c74696c2e577f06e2f830d" translate="yes" xml:space="preserve">
          <source>John. D. Kelleher, Brian Mac Namee, Aoife D&amp;rsquo;Arcy, (2015). &lt;a href=&quot;https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics&quot;&gt;Fundamentals of Machine Learning for Predictive Data Analytics: Algorithms, Worked Examples, and Case Studies&lt;/a&gt;.</source>
          <target state="translated">Juan. D. Kelleher, Brian Mac Namee, Aoife D'Arcy, (2015). &lt;a href=&quot;https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics&quot;&gt;Fundamentos del aprendizaje autom&amp;aacute;tico para el an&amp;aacute;lisis predictivo de datos: algoritmos, ejemplos resueltos y estudios de casos&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="7aafef76ed32e6bfff8b0b682dc86da3ac5a13fa" translate="yes" xml:space="preserve">
          <source>John. D. Kelleher, Brian Mac Namee, Aoife D&amp;rsquo;Arcy, &lt;a href=&quot;https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics&quot;&gt;Fundamentals of Machine Learning for Predictive Data Analytics: Algorithms, Worked Examples, and Case Studies&lt;/a&gt;, 2015.</source>
          <target state="translated">Juan. D. Kelleher, Brian Mac Namee, Aoife D'Arcy, &lt;a href=&quot;https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics&quot;&gt;Fundamentos del aprendizaje autom&amp;aacute;tico para el an&amp;aacute;lisis predictivo de datos: algoritmos, ejemplos resueltos y estudios de casos&lt;/a&gt; , 2015.</target>
        </trans-unit>
        <trans-unit id="19e6bf8efc7133dd97d0abbd89569a0495139bdc" translate="yes" xml:space="preserve">
          <source>Joint feature selection with multi-task Lasso</source>
          <target state="translated">Selección conjunta de características con el lazo multitarea</target>
        </trans-unit>
        <trans-unit id="6e210d8e33bded6f565ddf30568ce6ee46546dcb" translate="yes" xml:space="preserve">
          <source>Joint parameter selection</source>
          <target state="translated">Selección de parámetros conjuntos</target>
        </trans-unit>
        <trans-unit id="5dcd2dd79faa568a08732dcdc7a1c5d001632db6" translate="yes" xml:space="preserve">
          <source>Journal of Machine Learning Research 15(Oct):3221-3245, 2014. &lt;a href=&quot;http://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf&quot;&gt;http://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf&lt;/a&gt;</source>
          <target state="translated">Journal of Machine Learning Research 15 (octubre): 3221-3245, 2014. &lt;a href=&quot;http://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf&quot;&gt;http://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6689749f561220cbe925de6f0809b1dc75c6258d" translate="yes" xml:space="preserve">
          <source>July, 1988</source>
          <target state="translated">Julio de 1988</target>
        </trans-unit>
        <trans-unit id="854e66ede1ccc0e35f92ec3068666dcad934aaf9" translate="yes" xml:space="preserve">
          <source>July; 1998</source>
          <target state="translated">Julio;1998</target>
        </trans-unit>
        <trans-unit id="a2a7da9b458fe4f43b31552673f0b66352445d61" translate="yes" xml:space="preserve">
          <source>Jurman, Riccadonna, Furlanello, (2012). A Comparison of MCC and CEN Error Measures in MultiClass Prediction</source>
          <target state="translated">Jurman,Riccadonna,Furlanello,(2012).Una comparación de las medidas de error del MCC y el CEN en la predicción de multiclases</target>
        </trans-unit>
        <trans-unit id="a8dcc7a6052d083397dd89c88efdae4d16610c1e" translate="yes" xml:space="preserve">
          <source>Just as it is important to test a predictor on data held-out from training, preprocessing (such as standardization, feature selection, etc.) and similar &lt;a href=&quot;http://scikit-learn.org/stable/data_transforms.html#data-transforms&quot;&gt;data transformations&lt;/a&gt; similarly should be learnt from a training set and applied to held-out data for prediction:</source>
          <target state="translated">Del mismo modo que es importante probar un predictor en datos retenidos durante el entrenamiento, el preprocesamiento (como la estandarizaci&amp;oacute;n, la selecci&amp;oacute;n de caracter&amp;iacute;sticas, etc.) y &lt;a href=&quot;http://scikit-learn.org/stable/data_transforms.html#data-transforms&quot;&gt;transformaciones de datos&lt;/a&gt; similares tambi&amp;eacute;n deben aprenderse de un conjunto de entrenamiento y aplicarse a los datos retenidos para la predicci&amp;oacute;n. :</target>
        </trans-unit>
        <trans-unit id="19ba747b37c5ad6ac1cc4689022bdfff83622716" translate="yes" xml:space="preserve">
          <source>Just like self.assertTrue(a in b), but with a nicer default message.</source>
          <target state="translated">Igual que self.assertTrue(a en b),pero con un mejor mensaje por defecto.</target>
        </trans-unit>
        <trans-unit id="a7abce2837c2684f6308e0a3abb93654038ccc5f" translate="yes" xml:space="preserve">
          <source>Just like self.assertTrue(a not in b), but with a nicer default message.</source>
          <target state="translated">Como self.assertTrue(a no en b),pero con un mejor mensaje por defecto.</target>
        </trans-unit>
        <trans-unit id="57113affe2edb0e21a97719d086746970040c08f" translate="yes" xml:space="preserve">
          <source>K&amp;auml;rkk&amp;auml;inen and S. &amp;Auml;yr&amp;auml;m&amp;ouml;: &lt;a href=&quot;http://users.jyu.fi/~samiayr/pdf/ayramo_eurogen05.pdf&quot;&gt;On Computation of Spatial Median for Robust Data Mining.&lt;/a&gt;</source>
          <target state="translated">K&amp;auml;rkk&amp;auml;inen y S. &amp;Auml;yr&amp;auml;m&amp;ouml;: &lt;a href=&quot;http://users.jyu.fi/~samiayr/pdf/ayramo_eurogen05.pdf&quot;&gt;sobre el c&amp;aacute;lculo de la mediana espacial para la miner&amp;iacute;a de datos robusta.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7c859ded2bd8aa408f6c0369beaf2c2cf3f0ddde" translate="yes" xml:space="preserve">
          <source>K(X, Y) = &amp;lt;X, Y&amp;gt; / (||X||*||Y||)</source>
          <target state="translated">K (X, Y) = &amp;lt;X, Y&amp;gt; / (|| X || * || Y ||)</target>
        </trans-unit>
        <trans-unit id="86beb78a3bdf4132202cbc165378339bb7f278e3" translate="yes" xml:space="preserve">
          <source>K-Folds cross-validator</source>
          <target state="translated">El validador cruzado de los pliegues K</target>
        </trans-unit>
        <trans-unit id="66e29f0aeaaf6f3b77934175874c79014b658ea2" translate="yes" xml:space="preserve">
          <source>K-Means</source>
          <target state="translated">K-Means</target>
        </trans-unit>
        <trans-unit id="bc6e2dbca5eeaca5cfd908f6085c13e70dbbe207" translate="yes" xml:space="preserve">
          <source>K-Means clustering</source>
          <target state="translated">Agrupación de K-Means</target>
        </trans-unit>
        <trans-unit id="c532c5671424d23a3a3bc85d7cee5f6f8a964404" translate="yes" xml:space="preserve">
          <source>K-fold iterator variant with non-overlapping groups.</source>
          <target state="translated">Variante del iterador K con grupos no superpuestos.</target>
        </trans-unit>
        <trans-unit id="8434c9f312099287fd33427192dcba6bdae1583b" translate="yes" xml:space="preserve">
          <source>K-means Clustering</source>
          <target state="translated">K-means Clustering</target>
        </trans-unit>
        <trans-unit id="16176fa529a1e6d30521129cdc8f04353aaff22e" translate="yes" xml:space="preserve">
          <source>K-means algorithm to use. The classical EM-style algorithm is &amp;ldquo;full&amp;rdquo;. The &amp;ldquo;elkan&amp;rdquo; variation is more efficient by using the triangle inequality, but currently doesn&amp;rsquo;t support sparse data. &amp;ldquo;auto&amp;rdquo; chooses &amp;ldquo;elkan&amp;rdquo; for dense data and &amp;ldquo;full&amp;rdquo; for sparse data.</source>
          <target state="translated">Algoritmo K-means a utilizar. El algoritmo cl&amp;aacute;sico de estilo EM es &quot;completo&quot;. La variaci&amp;oacute;n &quot;elkan&quot; es m&amp;aacute;s eficiente al usar la desigualdad del tri&amp;aacute;ngulo, pero actualmente no admite datos escasos. &quot;Auto&quot; elige &quot;elkan&quot; para datos densos y &quot;completo&quot; para datos escasos.</target>
        </trans-unit>
        <trans-unit id="848dff73d6f69d92cd5b01b40f76a731abde9743" translate="yes" xml:space="preserve">
          <source>K-means can be used for vector quantization. This is achieved using the transform method of a trained model of &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt;&lt;code&gt;KMeans&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Se pueden usar K-medias para la cuantificaci&amp;oacute;n de vectores. Esto se logra utilizando el m&amp;eacute;todo de transformaci&amp;oacute;n de un modelo entrenado de &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt; &lt;code&gt;KMeans&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="ba78203e9e9f38ce3f7e015938283eb704622fc1" translate="yes" xml:space="preserve">
          <source>K-means clustering</source>
          <target state="translated">K significa agrupación</target>
        </trans-unit>
        <trans-unit id="4c31918fe250fba32eafec9c8bd2408d0665baa0" translate="yes" xml:space="preserve">
          <source>K-means clustering algorithm.</source>
          <target state="translated">K significa algoritmo de agrupación.</target>
        </trans-unit>
        <trans-unit id="3f9399be9d9993e05f4712a210efb7bcf391430f" translate="yes" xml:space="preserve">
          <source>K-means is equivalent to the expectation-maximization algorithm with a small, all-equal, diagonal covariance matrix.</source>
          <target state="translated">K-means es equivalente al algoritmo de maximización de expectativas con una pequeña matriz de covarianza diagonal,totalmente igual.</target>
        </trans-unit>
        <trans-unit id="f931e58c5b02fb6c60e80955646f359bee6ac7ee" translate="yes" xml:space="preserve">
          <source>K-means is often referred to as Lloyd&amp;rsquo;s algorithm. In basic terms, the algorithm has three steps. The first step chooses the initial centroids, with the most basic method being to choose \(k\) samples from the dataset \(X\). After initialization, K-means consists of looping between the two other steps. The first step assigns each sample to its nearest centroid. The second step creates new centroids by taking the mean value of all of the samples assigned to each previous centroid. The difference between the old and the new centroids are computed and the algorithm repeats these last two steps until this value is less than a threshold. In other words, it repeats until the centroids do not move significantly.</source>
          <target state="translated">K-means a menudo se conoce como algoritmo de Lloyd. En t&amp;eacute;rminos b&amp;aacute;sicos, el algoritmo tiene tres pasos. El primer paso elige los centroides iniciales, siendo el m&amp;eacute;todo m&amp;aacute;s b&amp;aacute;sico elegir \ (k \) muestras del conjunto de datos \ (X \). Despu&amp;eacute;s de la inicializaci&amp;oacute;n, K-means consiste en recorrer los otros dos pasos. El primer paso asigna cada muestra a su centroide m&amp;aacute;s cercano. El segundo paso crea nuevos centroides tomando el valor medio de todas las muestras asignadas a cada centroide anterior. Se calcula la diferencia entre el antiguo y el nuevo centroide y el algoritmo repite estos dos &amp;uacute;ltimos pasos hasta que este valor es menor que un umbral. En otras palabras, se repite hasta que los centroides no se mueven significativamente.</target>
        </trans-unit>
        <trans-unit id="c91b0be65ee9c7db25b71aa279369cca08edc7ca" translate="yes" xml:space="preserve">
          <source>K-means quantization</source>
          <target state="translated">K significa cuantificación</target>
        </trans-unit>
        <trans-unit id="5cf295fcd230ab825b1fa5bcf82b9dac494d126c" translate="yes" xml:space="preserve">
          <source>KDTree for fast generalized N-point problems</source>
          <target state="translated">KDTree para problemas de puntos N rápidamente generalizados</target>
        </trans-unit>
        <trans-unit id="34d74f913e8bd68fa4a9d1c4d3966f34ca72fc15" translate="yes" xml:space="preserve">
          <source>KDTree(X, leaf_size=40, metric=&amp;rsquo;minkowski&amp;rsquo;, **kwargs)</source>
          <target state="translated">KDTree (X, tama&amp;ntilde;o_hoja = 40, m&amp;eacute;trico = 'minkowski', ** kwargs)</target>
        </trans-unit>
        <trans-unit id="8a130d990c735953536ce43a1c5cf50c4989bca1" translate="yes" xml:space="preserve">
          <source>Kappa scores can be computed for binary or multiclass problems, but not for multilabel problems (except by manually computing a per-label score) and not for more than two annotators.</source>
          <target state="translated">Las puntuaciones Kappa pueden calcularse para problemas binarios o de varias clases,pero no para problemas de varias etiquetas (excepto si se calcula manualmente una puntuación por etiqueta)y no para más de dos anotadores.</target>
        </trans-unit>
        <trans-unit id="992bd2f88020b43ae9d881f8a8ecb43504cd4a74" translate="yes" xml:space="preserve">
          <source>Keep the 3 RGB channels instead of averaging them to a single gray level channel. If color is True the shape of the data has one more dimension than the shape with color = False.</source>
          <target state="translated">Mantén los 3 canales RGB en lugar de promediarlos en un solo canal de nivel de gris.Si el color es Verdadero,la forma de los datos tiene una dimensión más que la forma con color=Falso.</target>
        </trans-unit>
        <trans-unit id="e85b73c38883acb129e419e1a2f1719d75a444c5" translate="yes" xml:space="preserve">
          <source>Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin. Linear dimensionalityreduction using relevance weighted LDA. School of Electrical and Electronic Engineering Nanyang Technological University. 2005.</source>
          <target state="translated">Ken Tang y Ponnuthurai N.Suganthan y Xi Yao y A.Kai Qin.Reducción de la dimensionalidad lineal utilizando LDA ponderado por relevancia.Escuela de Ingeniería Eléctrica y Electrónica de la Universidad Tecnológica de Nanyang.2005.</target>
        </trans-unit>
        <trans-unit id="4ac337776123607052d628758806e2172a140241" translate="yes" xml:space="preserve">
          <source>Kernel Density Estimate of Species Distributions</source>
          <target state="translated">Estimación de la densidad del núcleo de la distribución de las especies</target>
        </trans-unit>
        <trans-unit id="1794dd0445cf0665650fb5446983f4ef8a3519d3" translate="yes" xml:space="preserve">
          <source>Kernel Density Estimation</source>
          <target state="translated">Estimación de la densidad del núcleo</target>
        </trans-unit>
        <trans-unit id="3bd4b1d4f074cf6b0f30ea849b2a75ad1d3777d9" translate="yes" xml:space="preserve">
          <source>Kernel PCA</source>
          <target state="translated">Núcleo PCA</target>
        </trans-unit>
        <trans-unit id="e5cb129fc99d7ba99fe28de6d8de36380920334b" translate="yes" xml:space="preserve">
          <source>Kernel PCA was introduced in:</source>
          <target state="translated">Se introdujo el PCA del núcleo:</target>
        </trans-unit>
        <trans-unit id="ba5a4a64bda1b4288aa7730d4a3cc2a5a99cf5dc" translate="yes" xml:space="preserve">
          <source>Kernel Principal component analysis (KPCA)</source>
          <target state="translated">Análisis del componente principal del núcleo (KPCA)</target>
        </trans-unit>
        <trans-unit id="f9f3967ca79560e0b7bba219989bbd17450e2f6e" translate="yes" xml:space="preserve">
          <source>Kernel bandwidth.</source>
          <target state="translated">Ancho de banda del núcleo.</target>
        </trans-unit>
        <trans-unit id="8f8874978483d89d1eb3e15131193d11bfd798e3" translate="yes" xml:space="preserve">
          <source>Kernel coefficient for &amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;poly&amp;rsquo; and &amp;lsquo;sigmoid&amp;rsquo;.</source>
          <target state="translated">Coeficiente de kernel para 'rbf', 'poli' y 'sigmoide'.</target>
        </trans-unit>
        <trans-unit id="97392135d656893f41c86b28ea3abd0d9e018bae" translate="yes" xml:space="preserve">
          <source>Kernel coefficient for rbf kernel.</source>
          <target state="translated">Coeficiente del núcleo para el núcleo rbf.</target>
        </trans-unit>
        <trans-unit id="0ae546d11d3317bcab299286e34e2f35ebfa8832" translate="yes" xml:space="preserve">
          <source>Kernel coefficient for rbf, poly and sigmoid kernels. Ignored by other kernels.</source>
          <target state="translated">Coeficiente de núcleo para los núcleos rbf,poli y sigmoide.Ignorado por otros núcleos.</target>
        </trans-unit>
        <trans-unit id="4a5a36cb73b6fa8cb90e406a9b203038f766b3f9" translate="yes" xml:space="preserve">
          <source>Kernel coefficient for rbf, poly, sigmoid, laplacian and chi2 kernels. Ignored for &lt;code&gt;affinity='nearest_neighbors'&lt;/code&gt;.</source>
          <target state="translated">Coeficiente de kernel para kernels rbf, poli, sigmoide, laplaciano y chi2. Ignorado por &lt;code&gt;affinity='nearest_neighbors'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7ed139f80ae0f25db98c92c5cce6311e8435271b" translate="yes" xml:space="preserve">
          <source>Kernel density estimation in scikit-learn is implemented in the &lt;a href=&quot;generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt;&lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt;&lt;/a&gt; estimator, which uses the Ball Tree or KD Tree for efficient queries (see &lt;a href=&quot;neighbors#neighbors&quot;&gt;Nearest Neighbors&lt;/a&gt; for a discussion of these). Though the above example uses a 1D data set for simplicity, kernel density estimation can be performed in any number of dimensions, though in practice the curse of dimensionality causes its performance to degrade in high dimensions.</source>
          <target state="translated">La estimaci&amp;oacute;n de la densidad del kernel en scikit-learn se implementa en el estimador &lt;a href=&quot;generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt; &lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt; &lt;/a&gt; , que usa el &amp;aacute;rbol de bolas o el &amp;aacute;rbol KD para consultas eficientes (consulte &lt;a href=&quot;neighbors#neighbors&quot;&gt;Vecinos m&amp;aacute;s cercanos&lt;/a&gt; para una discusi&amp;oacute;n sobre estos). Aunque el ejemplo anterior utiliza un conjunto de datos 1D para simplificar, la estimaci&amp;oacute;n de la densidad del n&amp;uacute;cleo se puede realizar en cualquier n&amp;uacute;mero de dimensiones, aunque en la pr&amp;aacute;ctica la maldici&amp;oacute;n de la dimensionalidad hace que su rendimiento se degrade en dimensiones altas.</target>
        </trans-unit>
        <trans-unit id="55e8fbe20e17e26ae0f3d4e88a1aeba0651c9393" translate="yes" xml:space="preserve">
          <source>Kernel hyperparameters for which the log-marginal likelihood is evaluated. If None, the precomputed log_marginal_likelihood of &lt;code&gt;self.kernel_.theta&lt;/code&gt; is returned.</source>
          <target state="translated">Hiperpar&amp;aacute;metros de kernel para los que se eval&amp;uacute;a la probabilidad log-marginal. Si es None, se devuelve el &lt;code&gt;self.kernel_.theta&lt;/code&gt; precalculado de self.kernel_.theta .</target>
        </trans-unit>
        <trans-unit id="aef459d7999942524bf342d4727b96b71e8fe80a" translate="yes" xml:space="preserve">
          <source>Kernel hyperparameters for which the log-marginal likelihood is evaluated. In the case of multi-class classification, theta may be the hyperparameters of the compound kernel or of an individual kernel. In the latter case, all individual kernel get assigned the same theta values. If None, the precomputed log_marginal_likelihood of &lt;code&gt;self.kernel_.theta&lt;/code&gt; is returned.</source>
          <target state="translated">Hiperpar&amp;aacute;metros de kernel para los que se eval&amp;uacute;a la probabilidad log-marginal. En el caso de la clasificaci&amp;oacute;n de clases m&amp;uacute;ltiples, theta pueden ser los hiperpar&amp;aacute;metros del n&amp;uacute;cleo compuesto o de un n&amp;uacute;cleo individual. En el &amp;uacute;ltimo caso, a todos los n&amp;uacute;cleos individuales se les asignan los mismos valores theta. Si es None, se devuelve el &lt;code&gt;self.kernel_.theta&lt;/code&gt; precalculado de self.kernel_.theta .</target>
        </trans-unit>
        <trans-unit id="e5fe7d4b4a2b4b1f4287c0408af092681ae17306" translate="yes" xml:space="preserve">
          <source>Kernel k(X, Y)</source>
          <target state="translated">Kernel k(X,Y)</target>
        </trans-unit>
        <trans-unit id="3ec24bca52509370dd13e99805241c7649952db1" translate="yes" xml:space="preserve">
          <source>Kernel map to be approximated. A callable should accept two arguments and the keyword arguments passed to this object as kernel_params, and should return a floating point number.</source>
          <target state="translated">Mapa del núcleo para ser aproximado.Un llamable debe aceptar dos argumentos y los argumentos de la palabra clave pasados a este objeto como kernel_params,y debe devolver un número de punto flotante.</target>
        </trans-unit>
        <trans-unit id="819d0e343c77a54a44f85a514be1d98b92643c33" translate="yes" xml:space="preserve">
          <source>Kernel mapping used internally. A callable should accept two arguments and the keyword arguments passed to this object as kernel_params, and should return a floating point number. Set to &amp;ldquo;precomputed&amp;rdquo; in order to pass a precomputed kernel matrix to the estimator methods instead of samples.</source>
          <target state="translated">Mapeo de kernel utilizado internamente. Un invocable debe aceptar dos argumentos y los argumentos de palabra clave pasados ​​a este objeto como kernel_params, y debe devolver un n&amp;uacute;mero de punto flotante. Establ&amp;eacute;zcalo en &quot;precalculado&quot; para pasar una matriz de kernel precalculada a los m&amp;eacute;todos de estimador en lugar de a las muestras.</target>
        </trans-unit>
        <trans-unit id="5470105c2039f2210b1a2c9d8e55edfd818f2e42" translate="yes" xml:space="preserve">
          <source>Kernel matrix.</source>
          <target state="translated">Matriz del núcleo.</target>
        </trans-unit>
        <trans-unit id="839a7f66845e964bf2afbaec5611c3402217b903" translate="yes" xml:space="preserve">
          <source>Kernel methods like support vector machines or kernelized PCA rely on a property of reproducing kernel Hilbert spaces. For any positive definite kernel function \(k\) (a so called Mercer kernel), it is guaranteed that there exists a mapping \(\phi\) into a Hilbert space \(\mathcal{H}\), such that</source>
          <target state="translated">Los métodos de núcleo como las máquinas de vector de apoyo o el PCA kernelizado se basan en la propiedad de reproducir los espacios del núcleo Hilbert.Para cualquier función positiva definida del kernel (un llamado kernel Mercer),se garantiza que existe un mapeo en el espacio Hilbert,de tal manera que</target>
        </trans-unit>
        <trans-unit id="a3bb404582c234b1b5161269097e65342126edc8" translate="yes" xml:space="preserve">
          <source>Kernel methods to project data into alternate dimensional spaces</source>
          <target state="translated">Métodos de núcleo para proyectar datos en espacios dimensionales alternativos</target>
        </trans-unit>
        <trans-unit id="7853e504e205e94517ed94484ade6d5285c25255" translate="yes" xml:space="preserve">
          <source>Kernel operators take one or two base kernels and combine them into a new kernel. The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.sum#sklearn.gaussian_process.kernels.Sum&quot;&gt;&lt;code&gt;Sum&lt;/code&gt;&lt;/a&gt; kernel takes two kernels \(k1\) and \(k2\) and combines them via \(k_{sum}(X, Y) = k1(X, Y) + k2(X, Y)\). The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.product#sklearn.gaussian_process.kernels.Product&quot;&gt;&lt;code&gt;Product&lt;/code&gt;&lt;/a&gt; kernel takes two kernels \(k1\) and \(k2\) and combines them via \(k_{product}(X, Y) = k1(X, Y) * k2(X, Y)\). The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.exponentiation#sklearn.gaussian_process.kernels.Exponentiation&quot;&gt;&lt;code&gt;Exponentiation&lt;/code&gt;&lt;/a&gt; kernel takes one base kernel and a scalar parameter \(exponent\) and combines them via \(k_{exp}(X, Y) = k(X, Y)^\text{exponent}\).</source>
          <target state="translated">Los operadores de kernel toman uno o dos kernels base y los combinan en un nuevo kernel. El n&amp;uacute;cleo &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.sum#sklearn.gaussian_process.kernels.Sum&quot;&gt; &lt;code&gt;Sum&lt;/code&gt; &lt;/a&gt; toma dos n&amp;uacute;cleos \ (k1 \) y \ (k2 \) y los combina a trav&amp;eacute;s de \ (k_ {sum} (X, Y) = k1 (X, Y) + k2 (X, Y) \). El n&amp;uacute;cleo del &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.product#sklearn.gaussian_process.kernels.Product&quot;&gt; &lt;code&gt;Product&lt;/code&gt; o&lt;/a&gt; toma dos n&amp;uacute;cleos \ (k1 \) y \ (k2 \) y los combina mediante \ (k_ {producto} (X, Y) = k1 (X, Y) * k2 (X, Y) \). El kernel de &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.exponentiation#sklearn.gaussian_process.kernels.Exponentiation&quot;&gt; &lt;code&gt;Exponentiation&lt;/code&gt; &lt;/a&gt; toma un kernel base y un par&amp;aacute;metro escalar \ (exponente \) y los combina mediante \ (k_ {exp} (X, Y) = k (X, Y) ^ \ text {exponent} \).</target>
        </trans-unit>
        <trans-unit id="9dc320ddac29ab60da57cafc47693079e4b6b082" translate="yes" xml:space="preserve">
          <source>Kernel ridge regression (KRR) &lt;a href=&quot;#m2012&quot; id=&quot;id1&quot;&gt;[M2012]&lt;/a&gt; combines &lt;a href=&quot;linear_model#ridge-regression&quot;&gt;Ridge Regression&lt;/a&gt; (linear least squares with l2-norm regularization) with the kernel trick. It thus learns a linear function in the space induced by the respective kernel and the data. For non-linear kernels, this corresponds to a non-linear function in the original space.</source>
          <target state="translated">La regresi&amp;oacute;n de la cresta del n&amp;uacute;cleo (KRR) &lt;a href=&quot;#m2012&quot; id=&quot;id1&quot;&gt;[M2012]&lt;/a&gt; combina la &lt;a href=&quot;linear_model#ridge-regression&quot;&gt;regresi&amp;oacute;n de la cresta&lt;/a&gt; (m&amp;iacute;nimos cuadrados lineales con regularizaci&amp;oacute;n de la norma l2) con el truco del n&amp;uacute;cleo. De este modo, aprende una funci&amp;oacute;n lineal en el espacio inducida por el n&amp;uacute;cleo respectivo y los datos. Para los n&amp;uacute;cleos no lineales, esto corresponde a una funci&amp;oacute;n no lineal en el espacio original.</target>
        </trans-unit>
        <trans-unit id="7d585be11bb912be319b898c908d63ce568dd8c0" translate="yes" xml:space="preserve">
          <source>Kernel ridge regression (KRR) combines ridge regression (linear least squares with l2-norm regularization) with the kernel trick. It thus learns a linear function in the space induced by the respective kernel and the data. For non-linear kernels, this corresponds to a non-linear function in the original space.</source>
          <target state="translated">La regresión de la cresta del núcleo (KRR)combina la regresión de la cresta (mínimos cuadrados lineales con regularización de la norma l2)con el truco del núcleo.De este modo,aprende una función lineal en el espacio inducido por el núcleo respectivo y los datos.En el caso de los núcleos no lineales,esto corresponde a una función no lineal en el espacio original.</target>
        </trans-unit>
        <trans-unit id="262cee695a2ed79939315817b4a3a26823167afe" translate="yes" xml:space="preserve">
          <source>Kernel ridge regression combines ridge regression with the kernel trick</source>
          <target state="translated">La regresión de la cresta del núcleo combina la regresión de la cresta con el truco del núcleo</target>
        </trans-unit>
        <trans-unit id="589ad014b6254add975c198ac204f9560e253ac1" translate="yes" xml:space="preserve">
          <source>Kernel ridge regression.</source>
          <target state="translated">Regresión de la cresta del núcleo.</target>
        </trans-unit>
        <trans-unit id="a797077c9a6730a652ad75f039a934d138c2b41f" translate="yes" xml:space="preserve">
          <source>Kernel to use in the model: linear, polynomial, RBF, sigmoid or precomputed.</source>
          <target state="translated">Núcleo a utilizar en el modelo:lineal,polinomio,RBF,sigmoide o precalculado.</target>
        </trans-unit>
        <trans-unit id="407ab400408caf91955e34873fdbfe1f6ae14b07" translate="yes" xml:space="preserve">
          <source>Kernel to use in the model: linear, polynomial, RBF, sigmoid or precomputed. &amp;lsquo;rbf&amp;rsquo; by default.</source>
          <target state="translated">Kernel a utilizar en el modelo: lineal, polinomial, RBF, sigmoide o precomputado. 'rbf' por defecto.</target>
        </trans-unit>
        <trans-unit id="716837a63a81bd1da24c9f2580ff0581777fc381" translate="yes" xml:space="preserve">
          <source>Kernel which is composed of a set of other kernels.</source>
          <target state="translated">Núcleo que se compone de un conjunto de otros núcleos.</target>
        </trans-unit>
        <trans-unit id="a170413f32a293189023e0700b83d22ea6042972" translate="yes" xml:space="preserve">
          <source>Kernel. Default=&amp;rdquo;linear&amp;rdquo;.</source>
          <target state="translated">N&amp;uacute;cleo. Predeterminado = &amp;rdquo;lineal&amp;rdquo;.</target>
        </trans-unit>
        <trans-unit id="e3cb275740ef8ee4f25f4b8b1bb2cb56094f01c1" translate="yes" xml:space="preserve">
          <source>Kernels (also called &amp;ldquo;covariance functions&amp;rdquo; in the context of GPs) are a crucial ingredient of GPs which determine the shape of prior and posterior of the GP. They encode the assumptions on the function being learned by defining the &amp;ldquo;similarity&amp;rdquo; of two datapoints combined with the assumption that similar datapoints should have similar target values. Two categories of kernels can be distinguished: stationary kernels depend only on the distance of two datapoints and not on their absolute values \(k(x_i, x_j)= k(d(x_i, x_j))\) and are thus invariant to translations in the input space, while non-stationary kernels depend also on the specific values of the datapoints. Stationary kernels can further be subdivided into isotropic and anisotropic kernels, where isotropic kernels are also invariant to rotations in the input space. For more details, we refer to Chapter 4 of &lt;a href=&quot;#rw2006&quot; id=&quot;id5&quot;&gt;[RW2006]&lt;/a&gt;.</source>
          <target state="translated">Los kernels (tambi&amp;eacute;n llamados &quot;funciones de covarianza&quot; en el contexto de los GP) son un ingrediente crucial de los GP que determinan la forma del anterior y posterior del GP. Codifican las suposiciones sobre la funci&amp;oacute;n que se est&amp;aacute; aprendiendo definiendo la &quot;similitud&quot; de dos puntos de datos combinados con la suposici&amp;oacute;n de que los puntos de datos similares deben tener valores objetivo similares. Se pueden distinguir dos categor&amp;iacute;as de n&amp;uacute;cleos: los n&amp;uacute;cleos estacionarios dependen solo de la distancia de dos puntos de datos y no de sus valores absolutos \ (k (x_i, x_j) = k (d (x_i, x_j)) \) y por lo tanto son invariantes a las traducciones en el espacio de entrada, mientras que los n&amp;uacute;cleos no estacionarios dependen tambi&amp;eacute;n de los valores espec&amp;iacute;ficos de los puntos de datos. Los granos estacionarios se pueden subdividir en granos isotr&amp;oacute;picos y anisotr&amp;oacute;picos, donde los granos isotr&amp;oacute;picos tambi&amp;eacute;n son invariantes a las rotaciones en el espacio de entrada. Para m&amp;aacute;s detalles,nos referimos al Cap&amp;iacute;tulo 4 de&lt;a href=&quot;#rw2006&quot; id=&quot;id5&quot;&gt;[RW2006]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0ad8dd8fec70a9d46c4f724f1ce47b4b45810363" translate="yes" xml:space="preserve">
          <source>Kernels are measures of similarity, i.e. &lt;code&gt;s(a, b) &amp;gt; s(a, c)&lt;/code&gt; if objects &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; are considered &amp;ldquo;more similar&amp;rdquo; than objects &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;c&lt;/code&gt;. A kernel must also be positive semi-definite.</source>
          <target state="translated">Kernels son medidas de similitud, es decir, &lt;code&gt;s(a, b) &amp;gt; s(a, c)&lt;/code&gt; si los objetos &lt;code&gt;a&lt;/code&gt; y &lt;code&gt;b&lt;/code&gt; se consideran &amp;ldquo;m&amp;aacute;s similares&amp;rdquo; que los objetos &lt;code&gt;a&lt;/code&gt; y &lt;code&gt;c&lt;/code&gt; . Un grano tambi&amp;eacute;n debe ser positivo semi-definido.</target>
        </trans-unit>
        <trans-unit id="cd28143394596209b24bd87df6806973641c2997" translate="yes" xml:space="preserve">
          <source>Kernels are parameterized by a vector \(\theta\) of hyperparameters. These hyperparameters can for instance control length-scales or periodicity of a kernel (see below). All kernels support computing analytic gradients of of the kernel&amp;rsquo;s auto-covariance with respect to \(\theta\) via setting &lt;code&gt;eval_gradient=True&lt;/code&gt; in the &lt;code&gt;__call__&lt;/code&gt; method. This gradient is used by the Gaussian process (both regressor and classifier) in computing the gradient of the log-marginal-likelihood, which in turn is used to determine the value of \(\theta\), which maximizes the log-marginal-likelihood, via gradient ascent. For each hyperparameter, the initial value and the bounds need to be specified when creating an instance of the kernel. The current value of \(\theta\) can be get and set via the property &lt;code&gt;theta&lt;/code&gt; of the kernel object. Moreover, the bounds of the hyperparameters can be accessed by the property &lt;code&gt;bounds&lt;/code&gt; of the kernel. Note that both properties (theta and bounds) return log-transformed values of the internally used values since those are typically more amenable to gradient-based optimization. The specification of each hyperparameter is stored in the form of an instance of &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.hyperparameter#sklearn.gaussian_process.kernels.Hyperparameter&quot;&gt;&lt;code&gt;Hyperparameter&lt;/code&gt;&lt;/a&gt; in the respective kernel. Note that a kernel using a hyperparameter with name &amp;ldquo;x&amp;rdquo; must have the attributes self.x and self.x_bounds.</source>
          <target state="translated">Los kernels est&amp;aacute;n parametrizados por un vector \ (\ theta \) de hiperpar&amp;aacute;metros. Estos hiperpar&amp;aacute;metros pueden, por ejemplo, controlar las escalas de longitud o la periodicidad de un kernel (ver m&amp;aacute;s abajo). Todos los n&amp;uacute;cleos admiten la computaci&amp;oacute;n de gradientes anal&amp;iacute;ticos de la autocovarianza del n&amp;uacute;cleo con respecto a \ (\ theta \) mediante la configuraci&amp;oacute;n de &lt;code&gt;eval_gradient=True&lt;/code&gt; en el m&amp;eacute;todo &lt;code&gt;__call__&lt;/code&gt; . Este gradiente es utilizado por el proceso gaussiano (tanto regresor como clasificador) para calcular el gradiente de la probabilidad log-marginal, que a su vez se usa para determinar el valor de \ (\ theta \), que maximiza el log-marginal- probabilidad, mediante ascenso en pendiente. Para cada hiperpar&amp;aacute;metro, el valor inicial y los l&amp;iacute;mites deben especificarse al crear una instancia del kernel. El valor actual de \ (\ theta \) se puede obtener y establecer mediante la propiedad &lt;code&gt;theta&lt;/code&gt; del objeto del kernel. Adem&amp;aacute;s, se puede acceder a los l&amp;iacute;mites de los hiperpar&amp;aacute;metros mediante los &lt;code&gt;bounds&lt;/code&gt; de propiedad del kernel. Tenga en cuenta que ambas propiedades (theta y l&amp;iacute;mites) devuelven valores transformados logar&amp;iacute;tmicamente de los valores utilizados internamente, ya que suelen ser m&amp;aacute;s susceptibles a la optimizaci&amp;oacute;n basada en gradientes. La especificaci&amp;oacute;n de cada hiperpar&amp;aacute;metro se almacena en forma de una instancia de &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.hyperparameter#sklearn.gaussian_process.kernels.Hyperparameter&quot;&gt; &lt;code&gt;Hyperparameter&lt;/code&gt; &lt;/a&gt; en el kernel respectivo. Tenga en cuenta que un kernel que utiliza un hiperpar&amp;aacute;metro con el nombre &quot;x&quot; debe tener los atributos self.xy self.x_bounds.</target>
        </trans-unit>
        <trans-unit id="2a754d09a87b01a5043bf319d676ca0f6cb6a853" translate="yes" xml:space="preserve">
          <source>Kernels:</source>
          <target state="translated">Kernels:</target>
        </trans-unit>
        <trans-unit id="c3b9fc0d0d17c07a841795715ed044ed9e710926" translate="yes" xml:space="preserve">
          <source>Kevin P. Murphy &amp;ldquo;Machine Learning: A Probabilistic Perspective&amp;rdquo;, The MIT Press chapter 14.4.3, pp. 492-493</source>
          <target state="translated">Kevin P. Murphy &quot;Machine Learning: A Probabilistic Perspective&quot;, The MIT Press cap&amp;iacute;tulo 14.4.3, p&amp;aacute;gs. 492-493</target>
        </trans-unit>
        <trans-unit id="1ebff3fd3bf929976eef25f0da78c334d18a2c1d" translate="yes" xml:space="preserve">
          <source>Keys are parameter names that can be passed to &lt;a href=&quot;sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;set_config&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Las claves son nombres de par&amp;aacute;metros que se pueden pasar a &lt;a href=&quot;sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;set_config&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="c16cf0c8b95cb6641127d4ecde39c2d13ee54107" translate="yes" xml:space="preserve">
          <source>Keyword arguments allow to adapt these defaults to specific data sets (see parameters &lt;code&gt;target_name&lt;/code&gt;, &lt;code&gt;data_name&lt;/code&gt;, &lt;code&gt;transpose_data&lt;/code&gt;, and the examples below).</source>
          <target state="translated">Los argumentos de palabras clave permiten adaptar estos valores predeterminados a conjuntos de datos espec&amp;iacute;ficos (consulte los par&amp;aacute;metros &lt;code&gt;target_name&lt;/code&gt; , &lt;code&gt;data_name&lt;/code&gt; , &lt;code&gt;transpose_data&lt;/code&gt; y los ejemplos a continuaci&amp;oacute;n).</target>
        </trans-unit>
        <trans-unit id="bd2209e677c2e2331711a5337dc06706ac2ee537" translate="yes" xml:space="preserve">
          <source>Keyword arguments to pass to specified metric function.</source>
          <target state="translated">Argumentos de palabras clave para pasar a una función métrica específica.</target>
        </trans-unit>
        <trans-unit id="b6574be8c6baa963e814d600a049a18b07924f05" translate="yes" xml:space="preserve">
          <source>Kilian Weinberger, Anirban Dasgupta, John Langford, Alex Smola and Josh Attenberg (2009). &lt;a href=&quot;http://alex.smola.org/papers/2009/Weinbergeretal09.pdf&quot;&gt;Feature hashing for large scale multitask learning&lt;/a&gt;. Proc. ICML.</source>
          <target state="translated">Kilian Weinberger, Anirban Dasgupta, John Langford, Alex Smola y Josh Attenberg (2009). &lt;a href=&quot;http://alex.smola.org/papers/2009/Weinbergeretal09.pdf&quot;&gt;Funci&amp;oacute;n hash para el aprendizaje multitarea a gran escala&lt;/a&gt; . Proc. ICML.</target>
        </trans-unit>
        <trans-unit id="35a95e3949c1091022c84b09bdfaee477e2ca247" translate="yes" xml:space="preserve">
          <source>Kingma, Diederik, and Jimmy Ba. &amp;ldquo;Adam: A method for stochastic</source>
          <target state="translated">Kingma, Diederik y Jimmy Ba. &quot;Adam: un m&amp;eacute;todo para estoc&amp;aacute;stico</target>
        </trans-unit>
        <trans-unit id="7bf0d4f9044d36fbabdb373fe028824c8f48b797" translate="yes" xml:space="preserve">
          <source>Kluger, Y., Basri, R., Chang, J. T., &amp;amp; Gerstein, M. (2003). Spectral biclustering of microarray data: coclustering genes and conditions. Genome research, 13(4), 703-716.</source>
          <target state="translated">Kluger, Y., Basri, R., Chang, JT y Gerstein, M. (2003). Biclustering espectral de datos de microarrays: genes y condiciones de coclustering. Investigaci&amp;oacute;n del genoma, 13 (4), 703-716.</target>
        </trans-unit>
        <trans-unit id="454573718b795c598350a3ed3c4e500004992423" translate="yes" xml:space="preserve">
          <source>Kluger, Yuval, et. al., 2003. &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.135.1608&quot;&gt;Spectral biclustering of microarray data: coclustering genes and conditions&lt;/a&gt;.</source>
          <target state="translated">Kluger, Yuval y col. al., 2003. &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.135.1608&quot;&gt;Biclustering espectral de datos de microarrays: genes y condiciones de coagrupaci&amp;oacute;n&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="c956cdb3811d15bc82b9ab562e4744234449e302" translate="yes" xml:space="preserve">
          <source>Knowing only the number of samples, the &lt;a href=&quot;generated/sklearn.random_projection.johnson_lindenstrauss_min_dim#sklearn.random_projection.johnson_lindenstrauss_min_dim&quot;&gt;&lt;code&gt;sklearn.random_projection.johnson_lindenstrauss_min_dim&lt;/code&gt;&lt;/a&gt; estimates conservatively the minimal size of the random subspace to guarantee a bounded distortion introduced by the random projection:</source>
          <target state="translated">Conociendo solo el n&amp;uacute;mero de muestras, &lt;a href=&quot;generated/sklearn.random_projection.johnson_lindenstrauss_min_dim#sklearn.random_projection.johnson_lindenstrauss_min_dim&quot;&gt; &lt;code&gt;sklearn.random_projection.johnson_lindenstrauss_min_dim&lt;/code&gt; &lt;/a&gt; estima de forma conservadora el tama&amp;ntilde;o m&amp;iacute;nimo del subespacio aleatorio para garantizar una distorsi&amp;oacute;n acotada introducida por la proyecci&amp;oacute;n aleatoria:</target>
        </trans-unit>
        <trans-unit id="dc8be79b794b57340c1a9b2bf6e67594910f3213" translate="yes" xml:space="preserve">
          <source>Koby Crammer, Yoram Singer. On the Algorithmic Implementation of Multiclass Kernel-based Vector Machines. Journal of Machine Learning Research 2, (2001), 265-292</source>
          <target state="translated">Koby Crammer,Yoram Singer.Sobre la implementación algorítmica de las máquinas vectoriales basadas en núcleos multiclases.Journal of Machine Learning Research 2,(2001),265-292</target>
        </trans-unit>
        <trans-unit id="5c3682641cb862b7b72f47a7d095c9e12f698d72" translate="yes" xml:space="preserve">
          <source>Kullback-Leibler divergence after optimization.</source>
          <target state="translated">Divergencia Kullback-Leibler después de la optimización.</target>
        </trans-unit>
        <trans-unit id="58f9065948558949c0307af59f2acaf3f9203c82" translate="yes" xml:space="preserve">
          <source>KulsinskiDistance</source>
          <target state="translated">KulsinskiDistance</target>
        </trans-unit>
        <trans-unit id="cb6565437657bdf8e9b94faf7a832064c7b5f242" translate="yes" xml:space="preserve">
          <source>L-BFGS is a solver that approximates the Hessian matrix which represents the second-order partial derivative of a function. Further it approximates the inverse of the Hessian matrix to perform parameter updates. The implementation uses the Scipy version of &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_l_bfgs_b.html&quot;&gt;L-BFGS&lt;/a&gt;.</source>
          <target state="translated">L-BFGS es un solucionador que se aproxima a la matriz hessiana que representa la derivada parcial de segundo orden de una funci&amp;oacute;n. Adem&amp;aacute;s, se aproxima a la inversa de la matriz de Hesse para realizar actualizaciones de par&amp;aacute;metros. La implementaci&amp;oacute;n utiliza la versi&amp;oacute;n Scipy de &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_l_bfgs_b.html&quot;&gt;L-BFGS&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="a9d5151f1c406ba9642eb6d20ad7472462d4b8c9" translate="yes" xml:space="preserve">
          <source>L. Breiman, &amp;ldquo;Bagging predictors&amp;rdquo;, Machine Learning 24, pages 123-140, 1996.</source>
          <target state="translated">L. Breiman, &quot;Bagging predictors&quot;, Machine Learning 24, p&amp;aacute;ginas 123-140, 1996.</target>
        </trans-unit>
        <trans-unit id="05401786a74b32c74f5aaf77879ff5fe2a1ce4dc" translate="yes" xml:space="preserve">
          <source>L. Breiman, &amp;ldquo;Bagging predictors&amp;rdquo;, Machine Learning, 24(2), 123-140, 1996.</source>
          <target state="translated">L. Breiman, &quot;Bagging predictors&quot;, Machine Learning, 24 (2), 123-140, 1996.</target>
        </trans-unit>
        <trans-unit id="ae813a657051355d781d3ca7a4417546370b5fb0" translate="yes" xml:space="preserve">
          <source>L. Breiman, &amp;ldquo;Pasting small votes for classification in large databases and on-line&amp;rdquo;, Machine Learning, 36(1), 85-103, 1999.</source>
          <target state="translated">L. Breiman, &quot;Pegar peque&amp;ntilde;os votos para la clasificaci&amp;oacute;n en grandes bases de datos y en l&amp;iacute;nea&quot;, Machine Learning, 36 (1), 85-103, 1999.</target>
        </trans-unit>
        <trans-unit id="93aaad4c8bcdef78f99bc463e879b251fb063491" translate="yes" xml:space="preserve">
          <source>L. Breiman, J. Friedman, R. Olshen, and C. Stone, &amp;ldquo;Classification and Regression Trees&amp;rdquo;, Wadsworth, Belmont, CA, 1984.</source>
          <target state="translated">L. Breiman, J. Friedman, R. Olshen y C. Stone, &quot;&amp;Aacute;rboles de clasificaci&amp;oacute;n y regresi&amp;oacute;n&quot;, Wadsworth, Belmont, CA, 1984.</target>
        </trans-unit>
        <trans-unit id="728ad1a9616394c8f19b0d53311780e8eed780ec" translate="yes" xml:space="preserve">
          <source>L. Breiman, J. Friedman, R. Olshen, and C. Stone. Classification and Regression Trees. Wadsworth, Belmont, CA, 1984.</source>
          <target state="translated">L.Breiman,J.Friedman,R.Olshen y C.Stone.Árboles de clasificación y regresión.Wadsworth,Belmont,CA,1984.</target>
        </trans-unit>
        <trans-unit id="26e831dbfd841f8bca5cddecddc5d95f765adc3b" translate="yes" xml:space="preserve">
          <source>L. Breiman, P. Spector &lt;a href=&quot;http://digitalassets.lib.berkeley.edu/sdtr/ucb/text/197.pdf&quot;&gt;Submodel selection and evaluation in regression: The X-random case&lt;/a&gt;, International Statistical Review 1992;</source>
          <target state="translated">L. Breiman, P. Spector &lt;a href=&quot;http://digitalassets.lib.berkeley.edu/sdtr/ucb/text/197.pdf&quot;&gt;Selecci&amp;oacute;n y evaluaci&amp;oacute;n de submodelos en regresi&amp;oacute;n: el caso X-random&lt;/a&gt; , International Statistical Review 1992;</target>
        </trans-unit>
        <trans-unit id="da524759b928a0c6c0410a2ba55315d0723efbf9" translate="yes" xml:space="preserve">
          <source>L. Breiman, and A. Cutler, &amp;ldquo;Random Forests&amp;rdquo;, &lt;a href=&quot;http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm&quot;&gt;http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm&lt;/a&gt;</source>
          <target state="translated">L. Breiman y A. Cutler, &quot;Random Forests&quot;, &lt;a href=&quot;http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm&quot;&gt;http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="27e9c034667fd587e63afe1b6bd9ac5dd761c4eb" translate="yes" xml:space="preserve">
          <source>L1 AND L2 Regularization for Multiclass Hinge Loss Models by Robert C. Moore, John DeNero.</source>
          <target state="translated">Regularización de L1 y L2 para modelos de pérdida de bisagras multiclase por Robert C.Moore,John DeNero.</target>
        </trans-unit>
        <trans-unit id="739dce23f089e2bc4737d849cf6e6812aaac6b25" translate="yes" xml:space="preserve">
          <source>L1 Penalty and Sparsity in Logistic Regression</source>
          <target state="translated">L1 Penalización y escasez en la regresión logística</target>
        </trans-unit>
        <trans-unit id="8d79d7e84774c8797e94aafbcec78896f21a814d" translate="yes" xml:space="preserve">
          <source>L1 norm: \(R(w) := \sum_{i=1}^{n} |w_i|\), which leads to sparse solutions.</source>
          <target state="translated">Norma L1:\N-R(w):=\N-suma de las cifras.|que conduce a soluciones escasas.</target>
        </trans-unit>
        <trans-unit id="ae8ca0f194d88f499adeb94f8b5c01af62268b9f" translate="yes" xml:space="preserve">
          <source>L2 norm: \(R(w) := \frac{1}{2} \sum_{i=1}^{n} w_i^2\),</source>
          <target state="translated">Norma L2:\ ~-(R(w):=\ ~ \ ~ fracaso 1}{\a6}{\a6}\N-w_i^2\N,</target>
        </trans-unit>
        <trans-unit id="e55996560b375d2b1311657b3550d521d2224094" translate="yes" xml:space="preserve">
          <source>L2 penalty (regularization term) parameter.</source>
          <target state="translated">Parámetro de penalización L2 (término de regularización).</target>
        </trans-unit>
        <trans-unit id="7d7eb4b58ee70885659f8b6dfa6b739d18b840b6" translate="yes" xml:space="preserve">
          <source>LIBLINEAR &amp;ndash; A Library for Large Linear Classification</source>
          <target state="translated">LIBLINEAR: una biblioteca para grandes clasificaciones lineales</target>
        </trans-unit>
        <trans-unit id="23f600324ae930d885bf27049a430c382dc77087" translate="yes" xml:space="preserve">
          <source>LIBLINEAR: A Library for Large Linear Classification</source>
          <target state="translated">LIBERAL:Una biblioteca para la clasificación lineal grande</target>
        </trans-unit>
        <trans-unit id="2f7204b5759b40e38407ab9bdcb1553f2d733475" translate="yes" xml:space="preserve">
          <source>LSA is also known as latent semantic indexing, LSI, though strictly that refers to its use in persistent indexes for information retrieval purposes.</source>
          <target state="translated">El LSA también se conoce como indexación semántica latente,LSI,aunque estrictamente eso se refiere a su uso en índices persistentes para fines de recuperación de información.</target>
        </trans-unit>
        <trans-unit id="f4a5095ae748443324845cf5a2f1b28d147ed2ca" translate="yes" xml:space="preserve">
          <source>LSH Forest being an approximate method, some true neighbors from the indexed dataset might be missing from the results.</source>
          <target state="translated">Siendo el Bosque LSH un método aproximado,algunos verdaderos vecinos del conjunto de datos indexados podrían faltar en los resultados.</target>
        </trans-unit>
        <trans-unit id="afceea8d4c81422ac802414c94f3f49075a51ec4" translate="yes" xml:space="preserve">
          <source>LSH Forest: Locality Sensitive Hashing forest [1] is an alternative method for vanilla approximate nearest neighbor search methods. LSH forest data structure has been implemented using sorted arrays and binary search and 32 bit fixed-length hashes. Random projection is used as the hash family which approximates cosine distance.</source>
          <target state="translated">Bosque LSH:Bosque Hashing sensible a la localidad [1]es un método alternativo para la búsqueda de vainilla aproximada del vecino más cercano.La estructura de datos del bosque LSH ha sido implementada usando matrices ordenadas y búsqueda binaria y hashes de 32 bits de longitud fija.Se utiliza la proyección aleatoria como la familia de hashes que se aproxima a la distancia del coseno.</target>
        </trans-unit>
        <trans-unit id="497cbd9196f20980eefacbc5b295901fb0a6c25f" translate="yes" xml:space="preserve">
          <source>LSTAT % lower status of the population</source>
          <target state="translated">LSTAT % estatus inferior de la población</target>
        </trans-unit>
        <trans-unit id="10e8ec7cf1b34af007bc1d6b016abc85aa0b454d" translate="yes" xml:space="preserve">
          <source>Label Propagation classifier</source>
          <target state="translated">Etiqueta Clasificador de propagación</target>
        </trans-unit>
        <trans-unit id="abaf5a09ed6812e5734e77c1313bb44d953f5d5d" translate="yes" xml:space="preserve">
          <source>Label Propagation digits active learning</source>
          <target state="translated">Propagación de la etiqueta dígitos aprendizaje activo</target>
        </trans-unit>
        <trans-unit id="a45a75b5c87b437cf487b153831ce5b94e5322d0" translate="yes" xml:space="preserve">
          <source>Label Propagation digits: Demonstrating performance</source>
          <target state="translated">Cifras de propagación de la etiqueta:Demostración de rendimiento</target>
        </trans-unit>
        <trans-unit id="f15baf6416f92a52b1527f1d28d49a335fe3d388" translate="yes" xml:space="preserve">
          <source>Label Propagation learning a complex structure</source>
          <target state="translated">Propagación de etiquetas aprendiendo una estructura compleja</target>
        </trans-unit>
        <trans-unit id="5f24cba3626113f57fbd8f2c1a1dac90f055831d" translate="yes" xml:space="preserve">
          <source>Label assigned to each item via the transduction.</source>
          <target state="translated">Etiqueta asignada a cada artículo a través de la transducción.</target>
        </trans-unit>
        <trans-unit id="0154541a5d5e8e0b2444f876377737f91ad447a9" translate="yes" xml:space="preserve">
          <source>Label considered as positive and others are considered negative.</source>
          <target state="translated">La etiqueta se considera positiva y las demás se consideran negativas.</target>
        </trans-unit>
        <trans-unit id="e1c383c45e91a1b41ae4aea8504e1ff71ada889a" translate="yes" xml:space="preserve">
          <source>Label is 1 for an inlier and -1 for an outlier according to the LOF score and the contamination parameter.</source>
          <target state="translated">La etiqueta es 1 para un valor atípico y -1 para un valor atípico según la puntuación de la LOF y el parámetro de contaminación.</target>
        </trans-unit>
        <trans-unit id="4a4a633c5d3b5ebf2a9c4453fb41f8475e350bc9" translate="yes" xml:space="preserve">
          <source>Label of the positive class. If None, the maximum label is used as positive class</source>
          <target state="translated">Etiqueta de la clase positiva.Si no hay ninguno,la etiqueta máxima se utiliza como clase positiva</target>
        </trans-unit>
        <trans-unit id="91ed314c98998b774c857769b601470c2a4233d0" translate="yes" xml:space="preserve">
          <source>Label propagation denotes a few variations of semi-supervised graph inference algorithms.</source>
          <target state="translated">La propagación de etiquetas denota unas pocas variaciones de algoritmos de inferencia gráfica semisupervisados.</target>
        </trans-unit>
        <trans-unit id="3a4c36d2f1914cbaa6f86d2f3e759e05f747e6f8" translate="yes" xml:space="preserve">
          <source>Label propagation models have two built-in kernel methods. Choice of kernel effects both scalability and performance of the algorithms. The following are available:</source>
          <target state="translated">Los modelos de propagación de etiquetas tienen dos métodos de núcleo incorporados.La elección del núcleo afecta tanto a la escalabilidad como al rendimiento de los algoritmos.Los siguientes están disponibles:</target>
        </trans-unit>
        <trans-unit id="d9c8943fba1565dfa00ecc788417147c59e84b5a" translate="yes" xml:space="preserve">
          <source>Label ranking average precision (LRAP) averages over the samples the answer to the following question: for each ground truth label, what fraction of higher-ranked labels were true labels? This performance measure will be higher if you are able to give better rank to the labels associated with each sample. The obtained score is always strictly greater than 0, and the best value is 1. If there is exactly one relevant label per sample, label ranking average precision is equivalent to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_reciprocal_rank&quot;&gt;mean reciprocal rank&lt;/a&gt;.</source>
          <target state="translated">La precisi&amp;oacute;n promedio de clasificaci&amp;oacute;n de etiquetas (LRAP) promedia sobre las muestras la respuesta a la siguiente pregunta: para cada etiqueta de verdad del terreno, &amp;iquest;qu&amp;eacute; fracci&amp;oacute;n de las etiquetas de mayor rango eran etiquetas verdaderas? Esta medida de rendimiento ser&amp;aacute; m&amp;aacute;s alta si puede dar una mejor clasificaci&amp;oacute;n a las etiquetas asociadas con cada muestra. La puntuaci&amp;oacute;n obtenida es siempre estrictamente mayor que 0, y el mejor valor es 1. Si hay exactamente una etiqueta relevante por muestra, la precisi&amp;oacute;n promedio de clasificaci&amp;oacute;n de etiquetas es equivalente a la &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_reciprocal_rank&quot;&gt;clasificaci&amp;oacute;n rec&amp;iacute;proca media&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="12d27d4c8cd4504c7079d27029449977fea3fa44" translate="yes" xml:space="preserve">
          <source>Label ranking average precision (LRAP) is the average over each ground truth label assigned to each sample, of the ratio of true vs. total labels with lower score.</source>
          <target state="translated">La precisión media de la clasificación de etiquetas (LRAP)es el promedio de cada etiqueta de verdad asignada a cada muestra,de la relación entre las etiquetas de verdad y las etiquetas totales con menor puntuación.</target>
        </trans-unit>
        <trans-unit id="57882529b52287495d04cf4c6bba559a970b02d4" translate="yes" xml:space="preserve">
          <source>Label, which is given for outlier samples (samples with no neighbors on given radius). If set to None, ValueError is raised, when outlier is detected.</source>
          <target state="translated">Etiqueta,que se da para las muestras atípicas (muestras sin vecinos en un radio determinado).Si se establece en Ninguno,se eleva el valor de Error,cuando se detecta un valor atípico.</target>
        </trans-unit>
        <trans-unit id="a3ea7d5af24c9f7706e04a90b4cc006ad64537bf" translate="yes" xml:space="preserve">
          <source>LabelSpreading model for semi-supervised learning</source>
          <target state="translated">Modelo de difusión de etiquetas para el aprendizaje semisupervisado</target>
        </trans-unit>
        <trans-unit id="82b6583f37d4a090f2277f71261de91f41eff15e" translate="yes" xml:space="preserve">
          <source>Labelings that assign all classes members to the same clusters are complete be not always pure, hence penalized:</source>
          <target state="translated">Las etiquetas que asignan a todos los miembros de las clases a los mismos grupos son completas no ser siempre puras,por lo tanto se penalizan:</target>
        </trans-unit>
        <trans-unit id="a59d28cce33bc578e32e7790445917276a69fe16" translate="yes" xml:space="preserve">
          <source>Labelings that assign all classes members to the same clusters are complete be not homogeneous, hence penalized:</source>
          <target state="translated">Las etiquetas que asignan a todos los miembros de las clases a los mismos grupos son completas no son homogéneas,por lo que se penalizan:</target>
        </trans-unit>
        <trans-unit id="2625047637f13a503b1aa26353d53ce007980d47" translate="yes" xml:space="preserve">
          <source>Labelings that have pure clusters with members coming from the same classes are homogeneous but un-necessary splits harms completeness and thus penalize V-measure as well:</source>
          <target state="translated">Los etiquetados que tienen agrupaciones puras con miembros que provienen de las mismas clases son homogéneos,pero las divisiones innecesarias perjudican la integridad y,por lo tanto,penalizan también la medida V:</target>
        </trans-unit>
        <trans-unit id="040e8af7f9faa240f939c7eb15dd2f3691882d68" translate="yes" xml:space="preserve">
          <source>Labelled data.</source>
          <target state="translated">Datos etiquetados.</target>
        </trans-unit>
        <trans-unit id="a8a910f7e8e66128e5f0f93a7ebe3b1d5812067b" translate="yes" xml:space="preserve">
          <source>Labelling a new sample is performed by finding the nearest centroid for a given sample.</source>
          <target state="translated">El etiquetado de una nueva muestra se realiza encontrando el centroide más cercano para una muestra determinada.</target>
        </trans-unit>
        <trans-unit id="47fc9fa69e29f326a363aa6376f6761fa85e0797" translate="yes" xml:space="preserve">
          <source>Labels assigned by the first annotator.</source>
          <target state="translated">Etiquetas asignadas por el primer anotador.</target>
        </trans-unit>
        <trans-unit id="bdb7346e56bb733f97e8f0b9d11cce2ffadf9042" translate="yes" xml:space="preserve">
          <source>Labels assigned by the second annotator. The kappa statistic is symmetric, so swapping &lt;code&gt;y1&lt;/code&gt; and &lt;code&gt;y2&lt;/code&gt; doesn&amp;rsquo;t change the value.</source>
          <target state="translated">Etiquetas asignadas por el segundo anotador. La estad&amp;iacute;stica kappa es sim&amp;eacute;trica, por lo que intercambiar &lt;code&gt;y1&lt;/code&gt; e &lt;code&gt;y2&lt;/code&gt; no cambia el valor.</target>
        </trans-unit>
        <trans-unit id="202396c3dbc4d15cb0462523b4fd7f2f49834479" translate="yes" xml:space="preserve">
          <source>Labels assigned to the centroids of the subclusters after they are clustered globally.</source>
          <target state="translated">Etiquetas asignadas a los centroides de los subconjuntos después de que se agrupen globalmente.</target>
        </trans-unit>
        <trans-unit id="86a5303314971b15773b1ad8460967a7978fc1e6" translate="yes" xml:space="preserve">
          <source>Labels associated to each face image. Those labels are ranging from 0-39 and correspond to the Subject IDs.</source>
          <target state="translated">Etiquetas asociadas a cada imagen de la cara.Esas etiquetas van de 0 a 39 y corresponden a las identificaciones de los sujetos.</target>
        </trans-unit>
        <trans-unit id="b8a8237c586e7a43e02e7a221af16786bca65b16" translate="yes" xml:space="preserve">
          <source>Labels associated to each face image. Those labels range from 0-5748 and correspond to the person IDs.</source>
          <target state="translated">Etiquetas asociadas a cada imagen de la cara.Esas etiquetas van de 0 a 5748 y corresponden a las identificaciones de las personas.</target>
        </trans-unit>
        <trans-unit id="639c7a5f12221be9fa16d4184a91d960ee8d5fb6" translate="yes" xml:space="preserve">
          <source>Labels associated to each pair of images. The two label values being different persons or the same person.</source>
          <target state="translated">Etiquetas asociadas a cada par de imágenes.Los dos valores de la etiqueta son personas diferentes o la misma persona.</target>
        </trans-unit>
        <trans-unit id="dd9359ae6e29bf7b087516560ad1a2e91d10cfb0" translate="yes" xml:space="preserve">
          <source>Labels for X.</source>
          <target state="translated">Etiquetas para la X.</target>
        </trans-unit>
        <trans-unit id="0b53b6571e9267409e85ff23873e0a0824df02a7" translate="yes" xml:space="preserve">
          <source>Labels of each point</source>
          <target state="translated">Las etiquetas de cada punto</target>
        </trans-unit>
        <trans-unit id="4350a7104cda6c17ed013efe2d00ebaae03eeb73" translate="yes" xml:space="preserve">
          <source>Labels of each point (if compute_labels is set to True).</source>
          <target state="translated">Etiquetas de cada punto (si compute_labels se establece en True).</target>
        </trans-unit>
        <trans-unit id="8c76fdcbe4be61c2bbf79d2e67413441e31eb988" translate="yes" xml:space="preserve">
          <source>Labels of each point.</source>
          <target state="translated">Etiquetas de cada punto.</target>
        </trans-unit>
        <trans-unit id="9caa2dbfb17c8c2f4ae17aa6bab878223c8520e3" translate="yes" xml:space="preserve">
          <source>Labels to constrain permutation within groups, i.e. &lt;code&gt;y&lt;/code&gt; values are permuted among samples with the same group identifier. When not specified, &lt;code&gt;y&lt;/code&gt; values are permuted among all samples.</source>
          <target state="translated">Etiquetas para restringir la permutaci&amp;oacute;n dentro de los grupos, es decir, los valores de &lt;code&gt;y&lt;/code&gt; se permutan entre muestras con el mismo identificador de grupo. Cuando no se especifica, los valores de &lt;code&gt;y&lt;/code&gt; se permutan entre todas las muestras.</target>
        </trans-unit>
        <trans-unit id="c21c4f0b2fc516030c767721367e1d2fba51e007" translate="yes" xml:space="preserve">
          <source>Labels.</source>
          <target state="translated">Labels.</target>
        </trans-unit>
        <trans-unit id="45efe9972f3bf7c62e3db1678d501faf12d10c1b" translate="yes" xml:space="preserve">
          <source>Large &lt;code&gt;n_clusters&lt;/code&gt; and &lt;code&gt;n_samples&lt;/code&gt;</source>
          <target state="translated">Grandes &lt;code&gt;n_clusters&lt;/code&gt; y &lt;code&gt;n_samples&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="28e08fa26129e68210c4b016ca6da1b08a1a37e9" translate="yes" xml:space="preserve">
          <source>Large &lt;code&gt;n_samples&lt;/code&gt; and &lt;code&gt;n_clusters&lt;/code&gt;</source>
          <target state="translated">Grandes &lt;code&gt;n_samples&lt;/code&gt; y &lt;code&gt;n_clusters&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="d40959dcecc27d1d44b2e4cffa59a304e9a052a1" translate="yes" xml:space="preserve">
          <source>Large dataset, outlier removal, data reduction.</source>
          <target state="translated">Gran conjunto de datos,eliminación de valores atípicos,reducción de datos.</target>
        </trans-unit>
        <trans-unit id="8f1784e927c9c4e578edb46d860596eed4a90b35" translate="yes" xml:space="preserve">
          <source>Large outliers</source>
          <target state="translated">Grandes valores atípicos</target>
        </trans-unit>
        <trans-unit id="20dfcd03ef69fe3c6c6e8549019c43956f87d5db" translate="yes" xml:space="preserve">
          <source>Lars computes a path solution only for each kink in the path. As a result, it is very efficient when there are only of few kinks, which is the case if there are few features or samples. Also, it is able to compute the full path without setting any meta parameter. On the opposite, coordinate descent compute the path points on a pre-specified grid (here we use the default). Thus it is more efficient if the number of grid points is smaller than the number of kinks in the path. Such a strategy can be interesting if the number of features is really large and there are enough samples to select a large amount. In terms of numerical errors, for heavily correlated variables, Lars will accumulate more errors, while the coordinate descent algorithm will only sample the path on a grid.</source>
          <target state="translated">Lars calcula una solución del camino sólo para cada curva del camino.Como resultado,es muy eficiente cuando hay sólo unos pocos pliegues,que es el caso si hay pocas características o muestras.Además,es capaz de calcular el camino completo sin establecer ningún meta parámetro.Por el contrario,el descenso de coordenadas calcula los puntos del camino en una cuadrícula preespecificada (aquí utilizamos el valor por defecto).Por lo tanto,es más eficiente si el número de puntos de la cuadrícula es menor que el número de pliegues del camino.Tal estrategia puede ser interesante si el número de características es realmente grande y hay suficientes muestras para seleccionar una gran cantidad.En cuanto a los errores numéricos,para las variables muy correlacionadas,Lars acumulará más errores,mientras que el algoritmo de descenso de coordenadas sólo muestreará el camino en una cuadrícula.</target>
        </trans-unit>
        <trans-unit id="fafbf93538200568ab2506c2a63168c161506b4f" translate="yes" xml:space="preserve">
          <source>Lasso and Elastic Net</source>
          <target state="translated">Lazo y red elástica</target>
        </trans-unit>
        <trans-unit id="64045413f4cce0f6cc0a64e33254b9beab1142d8" translate="yes" xml:space="preserve">
          <source>Lasso and Elastic Net for Sparse Signals</source>
          <target state="translated">Lazo y red elástica para señales dispersas</target>
        </trans-unit>
        <trans-unit id="02b3c1dbfc5f6c26007e2282ba4be10a77581a65" translate="yes" xml:space="preserve">
          <source>Lasso and elastic net (L1 and L2 penalisation) implemented using a coordinate descent.</source>
          <target state="translated">Lazo y red elástica (penalización L1 y L2)implementados mediante un descenso coordinado.</target>
        </trans-unit>
        <trans-unit id="721bb6d50a67145009b7e81abd6add7dc9980ff6" translate="yes" xml:space="preserve">
          <source>Lasso computed by least-angle regression</source>
          <target state="translated">El lazo calculado por la regresión del ángulo menor</target>
        </trans-unit>
        <trans-unit id="c805258f4c266592bbe9892ca4c6fe8fe41525e3" translate="yes" xml:space="preserve">
          <source>Lasso linear model with iterative fitting along a regularization path</source>
          <target state="translated">Modelo lineal de lazo con ajuste iterativo a lo largo de un camino de regularización</target>
        </trans-unit>
        <trans-unit id="af3dece2cf6ae684f46dbebc7279e4f62e00335d" translate="yes" xml:space="preserve">
          <source>Lasso model fit with Lars using BIC or AIC for model selection</source>
          <target state="translated">El modelo de lazo encaja con Lars usando BIC o AIC para la selección del modelo</target>
        </trans-unit>
        <trans-unit id="050a0d126029facc258b43169ac1e55a978389bf" translate="yes" xml:space="preserve">
          <source>Lasso model fit with Least Angle Regression a.k.a.</source>
          <target state="translated">El modelo de lazo encaja con la Regresión de Menor Ángulo,también conocida como...</target>
        </trans-unit>
        <trans-unit id="9cd5532bfae0b1e27ef3555196bbd1195b2078fe" translate="yes" xml:space="preserve">
          <source>Lasso model fit with Least Angle Regression a.k.a. Lars</source>
          <target state="translated">El modelo de lazo encaja con la regresión del ángulo mínimo,también conocido como Lars.</target>
        </trans-unit>
        <trans-unit id="7cbdf91f396ae23c8822ab30bdd340882655aa26" translate="yes" xml:space="preserve">
          <source>Lasso model selection: Cross-Validation / AIC / BIC</source>
          <target state="translated">Selección de modelo de lazo:Validación cruzada/AIC/BIC</target>
        </trans-unit>
        <trans-unit id="51c5bc73e17f640c8a180ee453dbdca923d8c408" translate="yes" xml:space="preserve">
          <source>Lasso on dense and sparse data</source>
          <target state="translated">Lazo en datos densos y escasos</target>
        </trans-unit>
        <trans-unit id="4222e17e965145615293d33dd92e1394e71c2b5b" translate="yes" xml:space="preserve">
          <source>Lasso path using LARS</source>
          <target state="translated">Trayectoria del lazo usando LARS</target>
        </trans-unit>
        <trans-unit id="1acac83cf58491df993404acd51caed4c4458648" translate="yes" xml:space="preserve">
          <source>Lasso using coordinate descent (&lt;a href=&quot;linear_model#lasso&quot;&gt;Lasso&lt;/a&gt;)</source>
          <target state="translated">Lazo con descenso de coordenadas ( &lt;a href=&quot;linear_model#lasso&quot;&gt;Lazo&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="e33c33e9d593ce188f7d437b3dd829993a23358f" translate="yes" xml:space="preserve">
          <source>Latent Dirichlet Allocation is a generative probabilistic model for collections of discrete dataset such as text corpora. It is also a topic model that is used for discovering abstract topics from a collection of documents.</source>
          <target state="translated">La Asignación de Dirichlets Latentes es un modelo probabilístico generativo para colecciones de conjuntos de datos discretos como corpúsculos de texto.También es un modelo temático que se utiliza para descubrir temas abstractos de una colección de documentos.</target>
        </trans-unit>
        <trans-unit id="b259b9fed25933f3361602dc71394efbeb9d0882" translate="yes" xml:space="preserve">
          <source>Latent Dirichlet Allocation with online variational Bayes algorithm</source>
          <target state="translated">Asignación de Dirichlet latente con un algoritmo Bayes de variación en línea</target>
        </trans-unit>
        <trans-unit id="691257140e4ed31a708c6cf301cec44aee34c69f" translate="yes" xml:space="preserve">
          <source>Latent representations of the data.</source>
          <target state="translated">Representaciones latentes de los datos.</target>
        </trans-unit>
        <trans-unit id="7972223ce1d5a83652f334b349de24d196516da5" translate="yes" xml:space="preserve">
          <source>Later you can load back the pickled model (possibly in another Python process) with:</source>
          <target state="translated">Más tarde puedes volver a cargar el modelo encurtido (posiblemente en otro proceso de Python)con:</target>
        </trans-unit>
        <trans-unit id="af705669290f66a0c593b0deebc97c8dff7d4996" translate="yes" xml:space="preserve">
          <source>Later, you can reload the pickled model (possibly in another Python process) with:</source>
          <target state="translated">Más tarde,puedes recargar el modelo encurtido (posiblemente en otro proceso de Python)con:</target>
        </trans-unit>
        <trans-unit id="87b4154b3c380b9ca1fa8f1419dd8e2c1d34065a" translate="yes" xml:space="preserve">
          <source>Latitude house block latitude</source>
          <target state="translated">La casa de la latitud bloquea la latitud</target>
        </trans-unit>
        <trans-unit id="5d6517da9252e690b07eb861ecaf7b79646512be" translate="yes" xml:space="preserve">
          <source>Leaf size passed to &lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt;&lt;code&gt;KDTree&lt;/code&gt;&lt;/a&gt;. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.</source>
          <target state="translated">El tama&amp;ntilde;o de la hoja pas&amp;oacute; a &lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; &lt;/a&gt; o &lt;a href=&quot;sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt; &lt;code&gt;KDTree&lt;/code&gt; &lt;/a&gt; . Esto puede afectar la velocidad de construcci&amp;oacute;n y consulta, as&amp;iacute; como la memoria requerida para almacenar el &amp;aacute;rbol. El valor &amp;oacute;ptimo depende de la naturaleza del problema.</target>
        </trans-unit>
        <trans-unit id="adfd1a5c3117b99a14c45a4ae06038fd4593b137" translate="yes" xml:space="preserve">
          <source>Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.</source>
          <target state="translated">El tamaño de la hoja pasó a BallTree o KDTree.Esto puede afectar a la velocidad de la construcción y la consulta,así como la memoria necesaria para almacenar el árbol.El valor óptimo depende de la naturaleza del problema.</target>
        </trans-unit>
        <trans-unit id="2f4f4f9d9992d30c454ebca3af5182554c5dd5d3" translate="yes" xml:space="preserve">
          <source>Leaf size passed to BallTree or cKDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.</source>
          <target state="translated">El tamaño de la hoja pasó a BallTree o cKDTree.Esto puede afectar a la velocidad de la construcción y la consulta,así como la memoria necesaria para almacenar el árbol.El valor óptimo depende de la naturaleza del problema.</target>
        </trans-unit>
        <trans-unit id="31743e5f5ee8b348cb24154ab26179446399d075" translate="yes" xml:space="preserve">
          <source>Learn a NMF model for the data X and returns the transformed data.</source>
          <target state="translated">Aprende un modelo NMF para los datos X y devuelve los datos transformados.</target>
        </trans-unit>
        <trans-unit id="a49199fe15b3d192e2f8e78d2cfcc004b5bb592f" translate="yes" xml:space="preserve">
          <source>Learn a NMF model for the data X.</source>
          <target state="translated">Aprende un modelo NMF para los datos X.</target>
        </trans-unit>
        <trans-unit id="f28a5a2a8197ba712162f1642134c8c32dff12de" translate="yes" xml:space="preserve">
          <source>Learn a list of feature name -&amp;gt; indices mappings and transform X.</source>
          <target state="translated">Aprenda una lista de nombres de funciones -&amp;gt; asignaciones de &amp;iacute;ndices y transforme X.</target>
        </trans-unit>
        <trans-unit id="8c410f4ecac33d5545793d5deb3e8b1121157db0" translate="yes" xml:space="preserve">
          <source>Learn a list of feature name -&amp;gt; indices mappings.</source>
          <target state="translated">Conozca una lista de nombres de funciones -&amp;gt; asignaciones de &amp;iacute;ndices.</target>
        </trans-unit>
        <trans-unit id="a753afaf1f2a5a0c1c19f381e2c844f4e69ccf16" translate="yes" xml:space="preserve">
          <source>Learn a vocabulary dictionary of all tokens in the raw documents.</source>
          <target state="translated">Aprende un diccionario de vocabulario de todas las fichas de los documentos en bruto.</target>
        </trans-unit>
        <trans-unit id="d9349583a45dc48570d0d3236e8faf8ecfef570b" translate="yes" xml:space="preserve">
          <source>Learn and apply the dimension reduction on the train data.</source>
          <target state="translated">Aprende y aplica la reducción de dimensiones en los datos del tren.</target>
        </trans-unit>
        <trans-unit id="c8e9cfdd99f37695b9bb2a2cf234f653fe10a376" translate="yes" xml:space="preserve">
          <source>Learn empirical variances from X.</source>
          <target state="translated">Aprende las variaciones empíricas de X.</target>
        </trans-unit>
        <trans-unit id="650a6ae9c550e7f32470024973e3b36aee2841fa" translate="yes" xml:space="preserve">
          <source>Learn model for the data X with variational Bayes method.</source>
          <target state="translated">Aprende el modelo para los datos X con el método variacional de Bayes.</target>
        </trans-unit>
        <trans-unit id="dacb80f7c7ce4a5db80b953f259da8b386886101" translate="yes" xml:space="preserve">
          <source>Learn the idf vector (global term weights)</source>
          <target state="translated">Aprende el vector idf (pesos de término global)</target>
        </trans-unit>
        <trans-unit id="b331e0a3149fc26c2099c41ac3e9655d530c7a47" translate="yes" xml:space="preserve">
          <source>Learn the inverse transform for non-precomputed kernels. (i.e. learn to find the pre-image of a point)</source>
          <target state="translated">Aprende la transformación inversa para los núcleos no precalculados.(es decir,aprender a encontrar la imagen previa de un punto)</target>
        </trans-unit>
        <trans-unit id="ee96e1f94ac61b3bff29cbb75afd2fdb8a437bed" translate="yes" xml:space="preserve">
          <source>Learn the vocabulary dictionary and return term-document matrix.</source>
          <target state="translated">Aprende el diccionario de vocabulario y devuelve la matriz de términos-documentos.</target>
        </trans-unit>
        <trans-unit id="65adc2e107d7d619d7107cf14005ab5e9c9cd5ef" translate="yes" xml:space="preserve">
          <source>Learn vocabulary and idf from training set.</source>
          <target state="translated">Aprende el vocabulario y el idf del set de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="d9ba5b6f4cc6cff1198de21973fdc3c62d64336f" translate="yes" xml:space="preserve">
          <source>Learn vocabulary and idf, return term-document matrix.</source>
          <target state="translated">Aprende el vocabulario y el idf,devuelve la matriz de términos-documentos.</target>
        </trans-unit>
        <trans-unit id="5b86400dde56a045e486ecc10d7618c7daf0f573" translate="yes" xml:space="preserve">
          <source>Learning a graph structure</source>
          <target state="translated">Aprendiendo la estructura de un gráfico</target>
        </trans-unit>
        <trans-unit id="f89176d3f1741099f1479699aa585a0c6906b634" translate="yes" xml:space="preserve">
          <source>Learning and predicting</source>
          <target state="translated">Aprender y predecir</target>
        </trans-unit>
        <trans-unit id="5087c606edcdf30c07ac8bd6a14c9b96c0975b25" translate="yes" xml:space="preserve">
          <source>Learning curve.</source>
          <target state="translated">Curva de aprendizaje.</target>
        </trans-unit>
        <trans-unit id="af86142d107ea3e7d568509ca68cbef348748b05" translate="yes" xml:space="preserve">
          <source>Learning problems fall into a few categories:</source>
          <target state="translated">Los problemas de aprendizaje se dividen en varias categorías:</target>
        </trans-unit>
        <trans-unit id="213b18cf4e4c891522544c2231435e470a8853a1" translate="yes" xml:space="preserve">
          <source>Learning rate schedule for weight updates.</source>
          <target state="translated">Calendario de tasas de aprendizaje para las actualizaciones de peso.</target>
        </trans-unit>
        <trans-unit id="ad3970bc51aa8e2c82bc13dcb9d4922e01a06590" translate="yes" xml:space="preserve">
          <source>Learning rate shrinks the contribution of each classifier by &lt;code&gt;learning_rate&lt;/code&gt;. There is a trade-off between &lt;code&gt;learning_rate&lt;/code&gt; and &lt;code&gt;n_estimators&lt;/code&gt;.</source>
          <target state="translated">La tasa de aprendizaje reduce la contribuci&amp;oacute;n de cada clasificador por tasa de &lt;code&gt;learning_rate&lt;/code&gt; . Existe una compensaci&amp;oacute;n entre &lt;code&gt;learning_rate&lt;/code&gt; y &lt;code&gt;n_estimators&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="cc055e36b16b7ea8669e5252649d8e3ee1af0b11" translate="yes" xml:space="preserve">
          <source>Learning rate shrinks the contribution of each regressor by &lt;code&gt;learning_rate&lt;/code&gt;. There is a trade-off between &lt;code&gt;learning_rate&lt;/code&gt; and &lt;code&gt;n_estimators&lt;/code&gt;.</source>
          <target state="translated">La tasa de aprendizaje reduce la contribuci&amp;oacute;n de cada regresor en tasa de &lt;code&gt;learning_rate&lt;/code&gt; . Existe una compensaci&amp;oacute;n entre &lt;code&gt;learning_rate&lt;/code&gt; y &lt;code&gt;n_estimators&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8982fb177d3b5a895540d84670a324c9b8376572" translate="yes" xml:space="preserve">
          <source>Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called &lt;strong&gt;overfitting&lt;/strong&gt;. To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a &lt;strong&gt;test set&lt;/strong&gt;&lt;code&gt;X_test, y_test&lt;/code&gt;. Note that the word &amp;ldquo;experiment&amp;rdquo; is not intended to denote academic use only, because even in commercial settings machine learning usually starts out experimentally.</source>
          <target state="translated">Aprender los par&amp;aacute;metros de una funci&amp;oacute;n de predicci&amp;oacute;n y probarlos con los mismos datos es un error metodol&amp;oacute;gico: un modelo que simplemente repetir&amp;iacute;a las etiquetas de las muestras que acaba de ver tendr&amp;iacute;a una puntuaci&amp;oacute;n perfecta, pero no podr&amp;iacute;a predecir nada &amp;uacute;til todav&amp;iacute;a. datos no vistos. Esta situaci&amp;oacute;n se llama &lt;strong&gt;sobreajuste&lt;/strong&gt; . Para evitarlo, es una pr&amp;aacute;ctica com&amp;uacute;n cuando se realiza un experimento de aprendizaje autom&amp;aacute;tico (supervisado) para mantener parte de los datos disponibles como un &lt;strong&gt;conjunto de prueba &lt;/strong&gt; &lt;code&gt;X_test, y_test&lt;/code&gt; . Tenga en cuenta que la palabra &quot;experimento&quot; no est&amp;aacute; destinada a denotar solo el uso acad&amp;eacute;mico, porque incluso en entornos comerciales, el aprendizaje autom&amp;aacute;tico generalmente comienza de manera experimental.</target>
        </trans-unit>
        <trans-unit id="93c3e1794e48ba7d8637b32d813e97686cf36d4f" translate="yes" xml:space="preserve">
          <source>Learns each output independently rather than chaining.</source>
          <target state="translated">Aprende cada salida de forma independiente en lugar de encadenarla.</target>
        </trans-unit>
        <trans-unit id="5fce8b00092369b98dfb920b76a7ee0efe5e00b1" translate="yes" xml:space="preserve">
          <source>Least Angle Regression model a.k.a.</source>
          <target state="translated">Modelo de Regresión de Menor Ángulo,también conocido como...</target>
        </trans-unit>
        <trans-unit id="3b28e26eb21f16fdbdefabf1ed5ad375edeafb8b" translate="yes" xml:space="preserve">
          <source>Least Angle Regression model a.k.a. LAR</source>
          <target state="translated">Modelo de regresión de ángulo mínimo,también conocido como LAR.</target>
        </trans-unit>
        <trans-unit id="b8ab306ac662259fba4aa6725b193c75be140b61" translate="yes" xml:space="preserve">
          <source>Least Squares projection of the data onto the sparse components.</source>
          <target state="translated">Proyección de los datos en los componentes dispersos.</target>
        </trans-unit>
        <trans-unit id="2c3aa035aea93ac3dc79ecee5528b7c8dcfba4ab" translate="yes" xml:space="preserve">
          <source>Least absolute deviation (&lt;code&gt;'lad'&lt;/code&gt;): A robust loss function for regression. The initial model is given by the median of the target values.</source>
          <target state="translated">Desviaci&amp;oacute;n m&amp;iacute;nima absoluta ( &lt;code&gt;'lad'&lt;/code&gt; ): una funci&amp;oacute;n de p&amp;eacute;rdida robusta para la regresi&amp;oacute;n. El modelo inicial viene dado por la mediana de los valores objetivo.</target>
        </trans-unit>
        <trans-unit id="3aeaacb76e6b5d496047f324133ddd0747e1d2c6" translate="yes" xml:space="preserve">
          <source>Least squares (&lt;code&gt;'ls'&lt;/code&gt;): The natural choice for regression due to its superior computational properties. The initial model is given by the mean of the target values.</source>
          <target state="translated">M&amp;iacute;nimos cuadrados ( &lt;code&gt;'ls'&lt;/code&gt; ): la elecci&amp;oacute;n natural para la regresi&amp;oacute;n debido a sus propiedades computacionales superiores. El modelo inicial viene dado por la media de los valores objetivo.</target>
        </trans-unit>
        <trans-unit id="7963186b092849241b779637d34ce64214b0375a" translate="yes" xml:space="preserve">
          <source>Least-Squares: Ridge Regression.</source>
          <target state="translated">Cuadrados mínimos:Regresión de la cresta.</target>
        </trans-unit>
        <trans-unit id="acf6db0396d489bb160af474285d57fb823df68a" translate="yes" xml:space="preserve">
          <source>Least-angle regression (&lt;a href=&quot;linear_model#least-angle-regression&quot;&gt;Least Angle Regression&lt;/a&gt;)</source>
          <target state="translated">Regresi&amp;oacute;n de &amp;aacute;ngulo m&amp;iacute;nimo (regresi&amp;oacute;n de &lt;a href=&quot;linear_model#least-angle-regression&quot;&gt;&amp;aacute;ngulo m&amp;iacute;nimo&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="818f02ffe71d576f8833c06d3318f5d50790be37" translate="yes" xml:space="preserve">
          <source>Least-angle regression (LARS) is a regression algorithm for high-dimensional data, developed by Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani. LARS is similar to forward stepwise regression. At each step, it finds the predictor most correlated with the response. When there are multiple predictors having equal correlation, instead of continuing along the same predictor, it proceeds in a direction equiangular between the predictors.</source>
          <target state="translated">La regresión de ángulo mínimo (LARS)es un algoritmo de regresión para datos de alta dimensión,desarrollado por Bradley Efron,Trevor Hastie,Iain Johnstone y Robert Tibshirani.LARS es similar a la regresión por pasos hacia adelante.En cada paso,encuentra el predictor más correlacionado con la respuesta.Cuando hay múltiples predictores que tienen igual correlación,en lugar de continuar a lo largo del mismo predictor,procede en una dirección equiangular entre los predictores.</target>
        </trans-unit>
        <trans-unit id="5cc9936fd171dfb4c941611970a01e31c9182cee" translate="yes" xml:space="preserve">
          <source>Leave One Group Out cross-validator</source>
          <target state="translated">Deje un grupo fuera del validador cruzado</target>
        </trans-unit>
        <trans-unit id="708b3ff9ed12b2c6f3635d37f516d672f76ad26e" translate="yes" xml:space="preserve">
          <source>Leave P Group(s) Out cross-validator</source>
          <target state="translated">Deje el grupo(s)P fuera del validador cruzado</target>
        </trans-unit>
        <trans-unit id="b1d423c90dfa79c0db1cf2e91d8b80c110d2debb" translate="yes" xml:space="preserve">
          <source>Leave P groups out.</source>
          <target state="translated">Deje los grupos P fuera.</target>
        </trans-unit>
        <trans-unit id="2e788c12c63436d5bbf2b3d54792d07b4ad5906d" translate="yes" xml:space="preserve">
          <source>Leave P observations out.</source>
          <target state="translated">Deje las observaciones P fuera.</target>
        </trans-unit>
        <trans-unit id="23a4dfbb0e55172e2c29fa75763519463b465b57" translate="yes" xml:space="preserve">
          <source>Leave one observation out.</source>
          <target state="translated">Deje una observación fuera.</target>
        </trans-unit>
        <trans-unit id="96e7c056605d5580183d915f0e8250d81cc4028b" translate="yes" xml:space="preserve">
          <source>Leave-One-Out cross-validator</source>
          <target state="translated">El validador cruzado de &quot;Leave-One-Out&quot;...</target>
        </trans-unit>
        <trans-unit id="a3d5fb094bf6540a5945dfebfc612a40422d0970" translate="yes" xml:space="preserve">
          <source>Leave-P-Out cross-validator</source>
          <target state="translated">El validador cruzado Leave-P-Out</target>
        </trans-unit>
        <trans-unit id="7fa92633d7eb4070a1a9e7f3ffd6a6dd808d5514" translate="yes" xml:space="preserve">
          <source>Ledoit O, Wolf M. Honey, I Shrunk the Sample Covariance Matrix. The Journal of Portfolio Management 30(4), 110-119, 2004.</source>
          <target state="translated">Ledoit O,Wolf M.Honey,encogí la matriz de covarianza de la muestra.The Journal of Portfolio Management 30(4),110-119,2004.</target>
        </trans-unit>
        <trans-unit id="b6a08e295c1dafc447ef93ac82d0e6a70b01528e" translate="yes" xml:space="preserve">
          <source>Ledoit-Wolf is a particular form of shrinkage, where the shrinkage coefficient is computed using O. Ledoit and M. Wolf&amp;rsquo;s formula as described in &amp;ldquo;A Well-Conditioned Estimator for Large-Dimensional Covariance Matrices&amp;rdquo;, Ledoit and Wolf, Journal of Multivariate Analysis, Volume 88, Issue 2, February 2004, pages 365-411.</source>
          <target state="translated">Ledoit-Wolf es una forma particular de contracci&amp;oacute;n, donde el coeficiente de contracci&amp;oacute;n se calcula utilizando la f&amp;oacute;rmula de O. Ledoit y M. Wolf como se describe en &quot;Un estimador bien condicionado para matrices de covarianza de gran dimensi&amp;oacute;n&quot;, Ledoit y Wolf, Journal of Multivariate Analysis , Volumen 88, N&amp;uacute;mero 2, febrero de 2004, p&amp;aacute;ginas 365-411.</target>
        </trans-unit>
        <trans-unit id="b450ff5574aa7547a2d2804a59fde9043d1f11e3" translate="yes" xml:space="preserve">
          <source>Ledoit-Wolf vs OAS estimation</source>
          <target state="translated">Estimación de Ledoit-Wolf vs.OAS</target>
        </trans-unit>
        <trans-unit id="74b56641357b357e1a04f8ba20caa0211258f1b9" translate="yes" xml:space="preserve">
          <source>LedoitWolf Estimator</source>
          <target state="translated">Estimador LedoitWolf</target>
        </trans-unit>
        <trans-unit id="a7127a921977497178bbe9d19b374d5b3660e695" translate="yes" xml:space="preserve">
          <source>Left argument of the returned kernel k(X, Y)</source>
          <target state="translated">Argumento izquierdo del kernel devuelto k(X,Y)</target>
        </trans-unit>
        <trans-unit id="75bf879e9683d8e42f9cdbce4ac2378477aafa4c" translate="yes" xml:space="preserve">
          <source>Length of the path. &lt;code&gt;eps=1e-3&lt;/code&gt; means that &lt;code&gt;alpha_min / alpha_max = 1e-3&lt;/code&gt;</source>
          <target state="translated">Longitud del camino. &lt;code&gt;eps=1e-3&lt;/code&gt; significa que &lt;code&gt;alpha_min / alpha_max = 1e-3&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c25fd55e85b58584519914fbcbbc8e0b71dacb4b" translate="yes" xml:space="preserve">
          <source>Length of the path. &lt;code&gt;eps=1e-3&lt;/code&gt; means that &lt;code&gt;alpha_min / alpha_max = 1e-3&lt;/code&gt;.</source>
          <target state="translated">Longitud del camino. &lt;code&gt;eps=1e-3&lt;/code&gt; significa que &lt;code&gt;alpha_min / alpha_max = 1e-3&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="820f47ab7dc5f77aa60df5d42cf3669d7140be19" translate="yes" xml:space="preserve">
          <source>Less sensitivity to the number of parameters:</source>
          <target state="translated">Menos sensibilidad al número de parámetros:</target>
        </trans-unit>
        <trans-unit id="650648dcfa58ca5d69540fc9d7c76c71c03cdd8d" translate="yes" xml:space="preserve">
          <source>Let K(x, z) be a kernel defined by phi(x)^T phi(z), where phi is a function mapping x to a Hilbert space. KernelCenterer centers (i.e., normalize to have zero mean) the data without explicitly computing phi(x). It is equivalent to centering phi(x) with sklearn.preprocessing.StandardScaler(with_std=False).</source>
          <target state="translated">Dejemos que K(x,z)sea un núcleo definido por phi(x)^T phi(z),donde phi es una función que asigna x a un espacio Hilbert.El KernelCenterer centra (es decir,normaliza para tener una media cero)los datos sin computar explícitamente phi(x).Es equivalente a centrar phi(x)con sklearn.preprocessing.StandardScaler(with_std=False).</target>
        </trans-unit>
        <trans-unit id="4d3e4f22e7563805ce13fd93e247765bb5c10653" translate="yes" xml:space="preserve">
          <source>Let \(S\) be the similarity matrix, and \(X\) the coordinates of the \(n\) input points. Disparities \(\hat{d}_{ij}\) are transformation of the similarities chosen in some optimal ways. The objective, called the stress, is then defined by \(sum_{i &amp;lt; j} d_{ij}(X) - \hat{d}_{ij}(X)\)</source>
          <target state="translated">Sea \ (S \) la matriz de similitud y \ (X \) las coordenadas de los \ (n \) puntos de entrada. Las disparidades \ (\ hat {d} _ {ij} \) son la transformaci&amp;oacute;n de las similitudes elegidas de algunas formas &amp;oacute;ptimas. El objetivo, llamado estr&amp;eacute;s, es definido por \ (sum_ {i &amp;lt;j} d_ {ij} (X) - \ hat {d} _ {ij} (X) \)</target>
        </trans-unit>
        <trans-unit id="c0a7cf3804b0fab7efc2f61eebe3b5930a870c77" translate="yes" xml:space="preserve">
          <source>Let the data at node \(m\) be represented by \(Q\). For each candidate split \(\theta = (j, t_m)\) consisting of a feature \(j\) and threshold \(t_m\), partition the data into \(Q_{left}(\theta)\) and \(Q_{right}(\theta)\) subsets</source>
          <target state="translated">Deja que los datos del nodo sean representados por &quot;Q&quot;.Para cada candidato dividido=(j,t_m)\Nque consiste en una característica y un umbral,divide los datos en subconjuntos...</target>
        </trans-unit>
        <trans-unit id="0eec5761b9ded7fa59a47d01c0fcb2883cae7dd4" translate="yes" xml:space="preserve">
          <source>Let us now try to reconstruct the original image from the patches by averaging on overlapping areas:</source>
          <target state="translated">Intentemos ahora reconstruir la imagen original a partir de los parches,haciendo un promedio de las áreas superpuestas:</target>
        </trans-unit>
        <trans-unit id="106ecb5f7c6bb4669d70caeae32d17518696e61b" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s print the first lines of the first loaded file:</source>
          <target state="translated">Imprimamos las primeras l&amp;iacute;neas del primer archivo cargado:</target>
        </trans-unit>
        <trans-unit id="bcd495b6fedeb570ab62363e5dbb308b08a2e969" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s say you are interested in the samples 10, 25, and 50, and want to know their class name.</source>
          <target state="translated">Supongamos que est&amp;aacute; interesado en las muestras 10, 25 y 50, y desea saber el nombre de su clase.</target>
        </trans-unit>
        <trans-unit id="65595eba1f80a7173dc24674f2afc2d5837968b2" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s say you are interested in the samples 10, 50, and 85, and want to know their class name.</source>
          <target state="translated">Supongamos que est&amp;aacute; interesado en las muestras 10, 50 y 85 y desea saber el nombre de su clase.</target>
        </trans-unit>
        <trans-unit id="fb46983e946ca9f3803c9b6fd00931719bb67d7b" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s say you are interested in the samples 10, 80, and 140, and want to know their class name.</source>
          <target state="translated">Supongamos que est&amp;aacute; interesado en las muestras 10, 80 y 140 y desea saber el nombre de su clase.</target>
        </trans-unit>
        <trans-unit id="36ae1b66774b74a6fe504ba4aa0655c5c58c7d06" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s see how it looks for the &lt;code&gt;KFold&lt;/code&gt; cross-validation object:</source>
          <target state="translated">Veamos c&amp;oacute;mo se ve el objeto de validaci&amp;oacute;n cruzada de &lt;code&gt;KFold&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="9c035fe2592c35e4264add67f9ea318300cfbf19" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s take a look at what the most informative features are:</source>
          <target state="translated">Echemos un vistazo a cu&amp;aacute;les son las caracter&amp;iacute;sticas m&amp;aacute;s informativas:</target>
        </trans-unit>
        <trans-unit id="fc26adc7a4427a7251d50d414ace6a50d7fbe76d" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s take an example with the following counts. The first term is present 100% of the time hence not very interesting. The two other features only in less than 50% of the time hence probably more representative of the content of the documents:</source>
          <target state="translated">Tomemos un ejemplo con los siguientes recuentos. El primer t&amp;eacute;rmino est&amp;aacute; presente el 100% del tiempo, por lo que no es muy interesante. Las otras dos caracter&amp;iacute;sticas solo en menos del 50% del tiempo, por lo que probablemente sean m&amp;aacute;s representativas del contenido de los documentos:</target>
        </trans-unit>
        <trans-unit id="2f95c182cf5fa2e13ce2622defe8af992d765313" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s try again with the default setting:</source>
          <target state="translated">Intentemos de nuevo con la configuraci&amp;oacute;n predeterminada:</target>
        </trans-unit>
        <trans-unit id="c3a6b9996c4370e6a8670703084aa093c6face20" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s use it to tokenize and count the word occurrences of a minimalistic corpus of text documents:</source>
          <target state="translated">Us&amp;eacute;moslo para tokenizar y contar las apariciones de palabras de un corpus minimalista de documentos de texto:</target>
        </trans-unit>
        <trans-unit id="c77ba9dd4a1f63d6e3e47c6ccfdd6637c48fa284" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s visually compare the cross validation behavior for many scikit-learn cross-validation objects. Below we will loop through several common cross-validation objects, visualizing the behavior of each.</source>
          <target state="translated">Comparemos visualmente el comportamiento de validaci&amp;oacute;n cruzada para muchos objetos de validaci&amp;oacute;n cruzada de scikit-learn. A continuaci&amp;oacute;n, recorreremos varios objetos comunes de validaci&amp;oacute;n cruzada, visualizando el comportamiento de cada uno.</target>
        </trans-unit>
        <trans-unit id="6c69807d4e78cfb8da9f8e8c21f378d88124782a" translate="yes" xml:space="preserve">
          <source>Level of verbosity.</source>
          <target state="translated">Nivel de verbosidad.</target>
        </trans-unit>
        <trans-unit id="ee9267aef527ceaeed70f092da783571e1b2536d" translate="yes" xml:space="preserve">
          <source>Libsvm GUI</source>
          <target state="translated">Libsvm GUI</target>
        </trans-unit>
        <trans-unit id="538c09161b8497f998404cafc34964ed3a445575" translate="yes" xml:space="preserve">
          <source>Licensed under the 3-clause BSD License.</source>
          <target state="translated">Licenciado bajo la licencia BSD de 3 cláusulas.</target>
        </trans-unit>
        <trans-unit id="d119b02c417272fad54f56fb5c480a5a866c4e2e" translate="yes" xml:space="preserve">
          <source>Lichman, M. (2013). UCI Machine Learning Repository [&lt;a href=&quot;http://archive.ics.uci.edu/ml&quot;&gt;http://archive.ics.uci.edu/ml&lt;/a&gt;]. Irvine, CA: University of California, School of Information and Computer Science.</source>
          <target state="translated">Lichman, M. (2013). Repositorio de aprendizaje autom&amp;aacute;tico de la UCI [ &lt;a href=&quot;http://archive.ics.uci.edu/ml&quot;&gt;http://archive.ics.uci.edu/ml&lt;/a&gt; ]. Irvine, CA: Universidad de California, Facultad de Informaci&amp;oacute;n y Ciencias de la Computaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="4a2cabe35d47f4d173451a3dc4bce594fc9e8434" translate="yes" xml:space="preserve">
          <source>Like &lt;a href=&quot;tree#tree&quot;&gt;decision trees&lt;/a&gt;, forests of trees also extend to &lt;a href=&quot;tree#tree-multioutput&quot;&gt;multi-output problems&lt;/a&gt; (if Y is an array of size &lt;code&gt;[n_samples, n_outputs]&lt;/code&gt;).</source>
          <target state="translated">Al igual &lt;a href=&quot;tree#tree&quot;&gt;que los &amp;aacute;rboles de decisi&amp;oacute;n&lt;/a&gt; , los bosques de &amp;aacute;rboles tambi&amp;eacute;n se extienden a &lt;a href=&quot;tree#tree-multioutput&quot;&gt;problemas de m&amp;uacute;ltiples salidas&lt;/a&gt; (si Y es una matriz de tama&amp;ntilde;o &lt;code&gt;[n_samples, n_outputs]&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="f8c94a1d14fd76e50a18d8c5112493b7c41a75b8" translate="yes" xml:space="preserve">
          <source>Like &lt;code&gt;Pipeline&lt;/code&gt;, individual steps may be replaced using &lt;code&gt;set_params&lt;/code&gt;, and ignored by setting to &lt;code&gt;'drop'&lt;/code&gt;:</source>
          <target state="translated">Al igual que &lt;code&gt;Pipeline&lt;/code&gt; , los pasos individuales se pueden reemplazar usando &lt;code&gt;set_params&lt;/code&gt; , e ignorarse estableciendo en &lt;code&gt;'drop'&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="09c07eeb7023cd495f9b67aa8c5832e9de0a3634" translate="yes" xml:space="preserve">
          <source>Like MultinomialNB, this classifier is suitable for discrete data. The difference is that while MultinomialNB works with occurrence counts, BernoulliNB is designed for binary/boolean features.</source>
          <target state="translated">Al igual que el MultinomialNB,este clasificador es adecuado para datos discretos.La diferencia es que mientras que MultinomialNB trabaja con recuentos de ocurrencia,BernoulliNB está diseñado para características binarias/booleanas.</target>
        </trans-unit>
        <trans-unit id="33e640491ab99ccee8501c0c94b8deb9f93a420b" translate="yes" xml:space="preserve">
          <source>Like fit(X) followed by transform(X), but does not require materializing X in memory.</source>
          <target state="translated">Como fit(X)seguido de transform(X),pero no requiere materializar X en la memoria.</target>
        </trans-unit>
        <trans-unit id="07a7d71492c9370f4c5f214183352ca2f48a9590" translate="yes" xml:space="preserve">
          <source>Like in Pipeline and FeatureUnion, this allows the transformer and its parameters to be set using &lt;code&gt;set_params&lt;/code&gt; and searched in grid search.</source>
          <target state="translated">Como en Pipeline y FeatureUnion, esto permite que el transformador y sus par&amp;aacute;metros se establezcan usando &lt;code&gt;set_params&lt;/code&gt; y se busquen en la b&amp;uacute;squeda de cuadr&amp;iacute;cula.</target>
        </trans-unit>
        <trans-unit id="ace16ab25f8f0e2cb278ad02989604150a81258c" translate="yes" xml:space="preserve">
          <source>Like pipelines, feature unions have a shorthand constructor called &lt;a href=&quot;generated/sklearn.pipeline.make_union#sklearn.pipeline.make_union&quot;&gt;&lt;code&gt;make_union&lt;/code&gt;&lt;/a&gt; that does not require explicit naming of the components.</source>
          <target state="translated">Al igual que las canalizaciones, las uniones de caracter&amp;iacute;sticas tienen un constructor abreviado llamado &lt;a href=&quot;generated/sklearn.pipeline.make_union#sklearn.pipeline.make_union&quot;&gt; &lt;code&gt;make_union&lt;/code&gt; &lt;/a&gt; que no requiere un nombre expl&amp;iacute;cito de los componentes.</target>
        </trans-unit>
        <trans-unit id="29685b73b0fbefa3dc8a3378779801b7f7266cf2" translate="yes" xml:space="preserve">
          <source>Like scalers, &lt;a href=&quot;generated/sklearn.preprocessing.quantiletransformer#sklearn.preprocessing.QuantileTransformer&quot;&gt;&lt;code&gt;QuantileTransformer&lt;/code&gt;&lt;/a&gt; puts all features into the same, known range or distribution. However, by performing a rank transformation, it smooths out unusual distributions and is less influenced by outliers than scaling methods. It does, however, distort correlations and distances within and across features.</source>
          <target state="translated">Al igual que los escaladores, &lt;a href=&quot;generated/sklearn.preprocessing.quantiletransformer#sklearn.preprocessing.QuantileTransformer&quot;&gt; &lt;code&gt;QuantileTransformer&lt;/code&gt; &lt;/a&gt; coloca todas las funciones en el mismo rango o distribuci&amp;oacute;n conocidos. Sin embargo, al realizar una transformaci&amp;oacute;n de rango, suaviza distribuciones inusuales y est&amp;aacute; menos influenciado por valores at&amp;iacute;picos que los m&amp;eacute;todos de escala. Sin embargo, distorsiona las correlaciones y distancias dentro y entre entidades.</target>
        </trans-unit>
        <trans-unit id="0ae4ed5af04ee97eab148462e283fb7149bd9d04" translate="yes" xml:space="preserve">
          <source>Limit in bytes of the size of the cache.</source>
          <target state="translated">Límite en bytes del tamaño del caché.</target>
        </trans-unit>
        <trans-unit id="bbd76c46a461ce6867ca433ec8697501cc65b137" translate="yes" xml:space="preserve">
          <source>Limiting distance of neighbors to return. (default is the value passed to the constructor).</source>
          <target state="translated">Limitando la distancia de los vecinos para regresar.(por defecto es el valor pasado al constructor).</target>
        </trans-unit>
        <trans-unit id="62c917554a7197d63486db913ca90de577c0bfe0" translate="yes" xml:space="preserve">
          <source>Linear Discriminant Analysis</source>
          <target state="translated">Análisis discriminante lineal</target>
        </trans-unit>
        <trans-unit id="719a12bbe391db4f9a1b1f0f22d958d133e79356" translate="yes" xml:space="preserve">
          <source>Linear Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) and Quadratic Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&quot;&gt;&lt;code&gt;discriminant_analysis.QuadraticDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) are two classic classifiers, with, as their names suggest, a linear and a quadratic decision surface, respectively.</source>
          <target state="translated">An&amp;aacute;lisis discriminante lineal ( &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt; ) y an&amp;aacute;lisis discriminante cuadr&amp;aacute;tico ( &lt;a href=&quot;generated/sklearn.discriminant_analysis.quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&quot;&gt; &lt;code&gt;discriminant_analysis.QuadraticDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt; ) son dos clasificadores cl&amp;aacute;sicos, con, como su nombre indica, una lineal y una superficie de decisi&amp;oacute;n cuadr&amp;aacute;tica, respectivamente.</target>
        </trans-unit>
        <trans-unit id="e36f5257c349ab3d8389a5027fa29765ef7a78a4" translate="yes" xml:space="preserve">
          <source>Linear Discriminant Analysis (LDA) tries to identify attributes that account for the most variance &lt;em&gt;between classes&lt;/em&gt;. In particular, LDA, in contrast to PCA, is a supervised method, using known class labels.</source>
          <target state="translated">El an&amp;aacute;lisis discriminante lineal (LDA) intenta identificar los atributos que explican la mayor variaci&amp;oacute;n &lt;em&gt;entre clases&lt;/em&gt; . En particular, LDA, a diferencia de PCA, es un m&amp;eacute;todo supervisado que utiliza etiquetas de clase conocidas.</target>
        </trans-unit>
        <trans-unit id="02924b985796944d65c857ba377ee96748a5fefe" translate="yes" xml:space="preserve">
          <source>Linear Discriminant Analysis and Quadratic Discriminant Analysis</source>
          <target state="translated">Análisis discriminante lineal y análisis discriminante cuadrático</target>
        </trans-unit>
        <trans-unit id="fe99070400d8a366d4438afb34b3817ed643e76c" translate="yes" xml:space="preserve">
          <source>Linear Model trained with L1 prior as regularizer (aka the Lasso)</source>
          <target state="translated">Modelo lineal entrenado con L1 previo como regularizador (alias el Lazo)</target>
        </trans-unit>
        <trans-unit id="b4819d272193c458d14d3c2a02b6439edb693339" translate="yes" xml:space="preserve">
          <source>Linear Regression Example</source>
          <target state="translated">Ejemplo de regresión lineal</target>
        </trans-unit>
        <trans-unit id="85494d31f5cd31cf05c6e37284f8e968283c0002" translate="yes" xml:space="preserve">
          <source>Linear SVC is not a probabilistic classifier by default but it has a built-in calibration option enabled in this example (&lt;code&gt;probability=True&lt;/code&gt;).</source>
          <target state="translated">El SVC lineal no es un clasificador probabil&amp;iacute;stico por defecto, pero tiene una opci&amp;oacute;n de calibraci&amp;oacute;n incorporada habilitada en este ejemplo ( &lt;code&gt;probability=True&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="e97d7a71e4408e1f570cb8d2ee92b68f661724af" translate="yes" xml:space="preserve">
          <source>Linear SVMs</source>
          <target state="translated">SVMs lineales</target>
        </trans-unit>
        <trans-unit id="73af0f0fe2656e7c704e9d2782f72d490054905e" translate="yes" xml:space="preserve">
          <source>Linear Sum - A n-dimensional vector holding the sum of all samples</source>
          <target state="translated">Suma lineal-Un vector n-dimensional que contiene la suma de todas las muestras</target>
        </trans-unit>
        <trans-unit id="1cd7978197df4491cb006d18687f0ce787689e06" translate="yes" xml:space="preserve">
          <source>Linear Support Vector Classification (&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt;) shows an even more sigmoid curve as the RandomForestClassifier, which is typical for maximum-margin methods (compare Niculescu-Mizil and Caruana &lt;a href=&quot;#id4&quot; id=&quot;id3&quot;&gt;[4]&lt;/a&gt;), which focus on hard samples that are close to the decision boundary (the support vectors).</source>
          <target state="translated">La clasificaci&amp;oacute;n de vectores de soporte lineal ( &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt; ) muestra una curva a&amp;uacute;n m&amp;aacute;s sigmoidea como RandomForestClassifier, que es t&amp;iacute;pica de los m&amp;eacute;todos de margen m&amp;aacute;ximo (compare Niculescu-Mizil y Caruana &lt;a href=&quot;#id4&quot; id=&quot;id3&quot;&gt;[4]&lt;/a&gt; ), que se centran en muestras duras que est&amp;aacute;n cerca del l&amp;iacute;mite de decisi&amp;oacute;n ( los vectores de soporte).</target>
        </trans-unit>
        <trans-unit id="88aaad048f30298d89bc0519c1e6f4cfbb7c20ea" translate="yes" xml:space="preserve">
          <source>Linear Support Vector Classification.</source>
          <target state="translated">Clasificación de Vectores de Soporte Lineal.</target>
        </trans-unit>
        <trans-unit id="4669e7bb12c975a34b6d592ccfe985850a9e31eb" translate="yes" xml:space="preserve">
          <source>Linear Support Vector Regression.</source>
          <target state="translated">Regresión vectorial de apoyo lineal.</target>
        </trans-unit>
        <trans-unit id="299f04ebeb7ad11bec6b5498c6b639ccade4023d" translate="yes" xml:space="preserve">
          <source>Linear and Quadratic Discriminant Analysis with covariance ellipsoid</source>
          <target state="translated">Análisis discriminante lineal y cuadrático con el elipsoide de covarianza</target>
        </trans-unit>
        <trans-unit id="c0463594ed874e4d015c682e8a6395a05e3fbd8b" translate="yes" xml:space="preserve">
          <source>Linear classifiers (SVM, logistic regression, a.o.) with SGD training.</source>
          <target state="translated">Clasificadores lineales (SVM,regresión logística,etc.)con entrenamiento en SGD.</target>
        </trans-unit>
        <trans-unit id="fa82faf2d530b479b3e87ec39c80fc313d729e93" translate="yes" xml:space="preserve">
          <source>Linear dimensionality reduction using Singular Value Decomposition of centered data, keeping only the most significant singular vectors to project the data to a lower dimensional space.</source>
          <target state="translated">Reducción de la dimensionalidad lineal utilizando la Descomposición de Valor Singular de los datos centrados,manteniendo sólo los vectores singulares más significativos para proyectar los datos a un espacio dimensional inferior.</target>
        </trans-unit>
        <trans-unit id="9db7130b75e27bc47e2764b6ec7d1ce03bb7f92f" translate="yes" xml:space="preserve">
          <source>Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space.</source>
          <target state="translated">Reducción de la dimensionalidad lineal utilizando la Descomposición de Valor Singular de los datos para proyectarlos a un espacio dimensional inferior.</target>
        </trans-unit>
        <trans-unit id="212b70af3cba5b501136f7c4f46821ce9f54ad31" translate="yes" xml:space="preserve">
          <source>Linear kernel (&lt;code&gt;kernel = 'linear'&lt;/code&gt;)</source>
          <target state="translated">N&amp;uacute;cleo lineal ( &lt;code&gt;kernel = 'linear'&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="1196f0388e6edcd3bda2236746717385556b159a" translate="yes" xml:space="preserve">
          <source>Linear least squares with l2 regularization.</source>
          <target state="translated">Cuadrados lineales mínimos con regularización de l2.</target>
        </trans-unit>
        <trans-unit id="0663410286eb390a6a91a4885ecdb0348930bc50" translate="yes" xml:space="preserve">
          <source>Linear model fitted by minimizing a regularized empirical loss with SGD</source>
          <target state="translated">Modelo lineal ajustado minimizando una pérdida empírica regularizada con SGD</target>
        </trans-unit>
        <trans-unit id="8d6556caff9af87efd1e0ccffe2463b6a45189f7" translate="yes" xml:space="preserve">
          <source>Linear model for testing the individual effect of each of many regressors. This is a scoring function to be used in a feature selection procedure, not a free standing feature selection procedure.</source>
          <target state="translated">Modelo lineal para probar el efecto individual de cada uno de los muchos regresores.Esta es una función de puntuación para ser usada en un procedimiento de selección de características,no un procedimiento de selección de características independiente.</target>
        </trans-unit>
        <trans-unit id="8f05719b5c26a33c08ae54e21caa15631a4bbbf1" translate="yes" xml:space="preserve">
          <source>Linear model: from regression to sparsity</source>
          <target state="translated">Modelo lineal:de la regresión a la escasez</target>
        </trans-unit>
        <trans-unit id="2c94cc16a66b49675f2acef482a0fbcd40d606ee" translate="yes" xml:space="preserve">
          <source>Linear models: \(y = X\beta + \epsilon\)</source>
          <target state="translated">Modelos lineales:\(y=X\beta+\ ~ -epsilon-)</target>
        </trans-unit>
        <trans-unit id="b501f602569674c31fc384f2cd7a29bcf6c1ce1f" translate="yes" xml:space="preserve">
          <source>Linear regression</source>
          <target state="translated">Regresión lineal</target>
        </trans-unit>
        <trans-unit id="d8f88b232d41c327138bbda59458fa5fc4086fff" translate="yes" xml:space="preserve">
          <source>Linear regression model that is robust to outliers.</source>
          <target state="translated">Un modelo de regresión lineal que es robusto a los valores atípicos.</target>
        </trans-unit>
        <trans-unit id="597ff76dcbb7bc322f194ba001977a736c193c2d" translate="yes" xml:space="preserve">
          <source>Linear regression with combined L1 and L2 priors as regularizer.</source>
          <target state="translated">Regresión lineal con los antecedentes combinados de L1 y L2 como regularizador.</target>
        </trans-unit>
        <trans-unit id="0a2d386e0774637a1788b00b4abdb8b2c6c38c74" translate="yes" xml:space="preserve">
          <source>Linear ridge regression.</source>
          <target state="translated">Regresión lineal de la cresta.</target>
        </trans-unit>
        <trans-unit id="c7ed3fbb6680836b95c3db482cfaf054c37a8419" translate="yes" xml:space="preserve">
          <source>List containing train-test split of inputs.</source>
          <target state="translated">Lista que contiene la división de entradas de la prueba del tren.</target>
        </trans-unit>
        <trans-unit id="7946c78611ea79ca25491c94f60dac5182c68016" translate="yes" xml:space="preserve">
          <source>List of (name, class), where &lt;code&gt;name&lt;/code&gt; is the class name as string and &lt;code&gt;class&lt;/code&gt; is the actuall type of the class.</source>
          <target state="translated">Lista de (nombre, clase), donde &lt;code&gt;name&lt;/code&gt; es el nombre de la clase como cadena y &lt;code&gt;class&lt;/code&gt; es el tipo actual de la clase.</target>
        </trans-unit>
        <trans-unit id="01f72260e79a828ac37c6e1b27f0158a5c017639" translate="yes" xml:space="preserve">
          <source>List of (name, transform) tuples (implementing fit/transform) that are chained, in the order in which they are chained, with the last object an estimator.</source>
          <target state="translated">Lista de tuplas (nombre,transformación)que se encadenan,en el orden en que se encadenan,con el último objeto un estimador.</target>
        </trans-unit>
        <trans-unit id="da3552a00ac25869a883c68bd3a0b9b483a759ac" translate="yes" xml:space="preserve">
          <source>List of (name, transformer, column(s)) tuples specifying the transformer objects to be applied to subsets of the data.</source>
          <target state="translated">Lista de tuplas (nombre,transformador,columna(s))en las que se especifican los objetos transformadores que se aplicarán a los subconjuntos de los datos.</target>
        </trans-unit>
        <trans-unit id="9ce9067b559ab6542ebc584f224960b4d8e01fb3" translate="yes" xml:space="preserve">
          <source>List of &lt;code&gt;n_features&lt;/code&gt;-dimensional data points. Each row corresponds to a single data point.</source>
          <target state="translated">Lista de &lt;code&gt;n_features&lt;/code&gt; -puntos de datos dimensionales. Cada fila corresponde a un &amp;uacute;nico punto de datos.</target>
        </trans-unit>
        <trans-unit id="5f38bb9ffb369276ed25fb7c04fb0e0e029823d8" translate="yes" xml:space="preserve">
          <source>List of all the classes that can possibly appear in the y vector.</source>
          <target state="translated">Lista de todas las clases que pueden aparecer en el vector y.</target>
        </trans-unit>
        <trans-unit id="7cd6d854280958549421b40e7d622e1782f63df4" translate="yes" xml:space="preserve">
          <source>List of alphas where to compute the models. If &lt;code&gt;None&lt;/code&gt; alphas are set automatically</source>
          <target state="translated">Lista de alfas donde calcular los modelos. Si &lt;code&gt;None&lt;/code&gt; alfas se configuran autom&amp;aacute;ticamente</target>
        </trans-unit>
        <trans-unit id="917b5a956108e84a4893edaf20f4507c6507d0e2" translate="yes" xml:space="preserve">
          <source>List of alphas where to compute the models. If None alphas are set automatically</source>
          <target state="translated">Lista de alfas donde calcular los modelos.Si no se establece ningún alfa automáticamente</target>
        </trans-unit>
        <trans-unit id="d057f35a68cef6d291f5ea686ce0f4438a6a2951" translate="yes" xml:space="preserve">
          <source>List of alphas where to compute the models. If not provided, set automatically.</source>
          <target state="translated">Lista de alfas donde calcular los modelos.Si no se proporciona,se establece automáticamente.</target>
        </trans-unit>
        <trans-unit id="fb8d4641f5ca2701f801733b19cf7bb77974f371" translate="yes" xml:space="preserve">
          <source>List of arrays of terms.</source>
          <target state="translated">Lista de arreglos de términos.</target>
        </trans-unit>
        <trans-unit id="6ecedd8bbbc6137125014e8bb7a429cbcef11be8" translate="yes" xml:space="preserve">
          <source>List of built-in kernels.</source>
          <target state="translated">Lista de núcleos incorporados.</target>
        </trans-unit>
        <trans-unit id="36c7ba17f19f78b4b0b98a1a27cecbfd22dc65e4" translate="yes" xml:space="preserve">
          <source>List of coefficients for the Logistic Regression model. If fit_intercept is set to True then the second dimension will be n_features + 1, where the last item represents the intercept. For &lt;code&gt;multiclass='multinomial'&lt;/code&gt;, the shape is (n_classes, n_cs, n_features) or (n_classes, n_cs, n_features + 1).</source>
          <target state="translated">Lista de coeficientes del modelo de regresi&amp;oacute;n log&amp;iacute;stica. Si fit_intercept se establece en True, la segunda dimensi&amp;oacute;n ser&amp;aacute; n_features + 1, donde el &amp;uacute;ltimo elemento representa la intersecci&amp;oacute;n. Para &lt;code&gt;multiclass='multinomial'&lt;/code&gt; , la forma es (n_classes, n_cs, n_features) o (n_classes, n_cs, n_features + 1).</target>
        </trans-unit>
        <trans-unit id="568d5fc554d78a8c3f420990686843b1d52522c9" translate="yes" xml:space="preserve">
          <source>List of labels to index the matrix. This may be used to reorder or select a subset of labels. If none is given, those that appear at least once in &lt;code&gt;y_true&lt;/code&gt; or &lt;code&gt;y_pred&lt;/code&gt; are used in sorted order.</source>
          <target state="translated">Lista de etiquetas para indexar la matriz. Esto se puede utilizar para reordenar o seleccionar un subconjunto de etiquetas. Si no se proporciona ninguno, los que aparecen al menos una vez en &lt;code&gt;y_true&lt;/code&gt; o &lt;code&gt;y_pred&lt;/code&gt; se utilizan en orden ordenado.</target>
        </trans-unit>
        <trans-unit id="4904457db6e3ad315971a386c35727cdd591b70f" translate="yes" xml:space="preserve">
          <source>List of labels to index the matrix. This may be used to select a subset of labels. If None, all labels that appear at least once in &lt;code&gt;y1&lt;/code&gt; or &lt;code&gt;y2&lt;/code&gt; are used.</source>
          <target state="translated">Lista de etiquetas para indexar la matriz. Esto se puede utilizar para seleccionar un subconjunto de etiquetas. Si es Ninguno, se utilizan todas las etiquetas que aparecen al menos una vez en &lt;code&gt;y1&lt;/code&gt; o &lt;code&gt;y2&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b841f355bd90388eac15a6584a26192e6c900c97" translate="yes" xml:space="preserve">
          <source>List of n_features-dimensional data points. Each row corresponds to a single data point.</source>
          <target state="translated">Lista de n_características-puntos de datos dimensionales.Cada fila corresponde a un único punto de datos.</target>
        </trans-unit>
        <trans-unit id="af1051d092002bc2f98d27cb1ada3b5cc2dacea1" translate="yes" xml:space="preserve">
          <source>List of n_features-dimensional data points. Each row corresponds to a single query.</source>
          <target state="translated">Lista de n_características-puntos de datos dimensionales.Cada fila corresponde a una única consulta.</target>
        </trans-unit>
        <trans-unit id="85e7a2833a6b5505d28e95f0c1116dee51aa01e1" translate="yes" xml:space="preserve">
          <source>List of objects to ensure sliceability.</source>
          <target state="translated">Lista de objetos para asegurar la cortabilidad.</target>
        </trans-unit>
        <trans-unit id="5538dc428bf1dd702d4666daf2c6801367c4f065" translate="yes" xml:space="preserve">
          <source>List of sample weights attached to the data X.</source>
          <target state="translated">Lista de pesos de muestra adjunta a los datos X.</target>
        </trans-unit>
        <trans-unit id="af4d88e1f955adfe14752a1cab15db410dc25046" translate="yes" xml:space="preserve">
          <source>List of samples.</source>
          <target state="translated">Lista de muestras.</target>
        </trans-unit>
        <trans-unit id="9fa149a90ccae2cfe066dfb859bf8a7c95ef01ca" translate="yes" xml:space="preserve">
          <source>List of transformer objects to be applied to the data. The first half of each tuple is the name of the transformer.</source>
          <target state="translated">Lista de objetos transformadores que se aplicarán a los datos.La primera mitad de cada tupla es el nombre del transformador.</target>
        </trans-unit>
        <trans-unit id="f2f499a9d9cf5fba3b5aa16bff4e7ad9f538a51f" translate="yes" xml:space="preserve">
          <source>List of values for the regularization parameter or integer specifying the number of regularization parameters that should be used. In this case, the parameters will be chosen in a logarithmic scale between 1e-4 and 1e4.</source>
          <target state="translated">Lista de valores del parámetro o entero de regularización que especifica el número de parámetros de regularización que deben utilizarse.En este caso,los parámetros se elegirán en una escala logarítmica entre 1e-4 y 1e4.</target>
        </trans-unit>
        <trans-unit id="d742bd356ab53d1131907c9ca41e9f89956bc677" translate="yes" xml:space="preserve">
          <source>List of weighting type to calculate the score. None means no weighted; &amp;ldquo;linear&amp;rdquo; means linear weighted; &amp;ldquo;quadratic&amp;rdquo; means quadratic weighted.</source>
          <target state="translated">Lista de tipo de ponderaci&amp;oacute;n para calcular la puntuaci&amp;oacute;n. Ninguno significa no ponderado; &quot;Lineal&quot; significa lineal ponderado; &amp;ldquo;Cuadr&amp;aacute;tico&amp;rdquo; significa cuadr&amp;aacute;tico ponderado.</target>
        </trans-unit>
        <trans-unit id="ccaadae3fd2b8d525242b8298319bebc15b1d7f7" translate="yes" xml:space="preserve">
          <source>Liu, Fei Tony, Ting, Kai Ming and Zhou, Zhi-Hua. &amp;ldquo;Isolation forest.&amp;rdquo; Data Mining, 2008. ICDM&amp;lsquo;08. Eighth IEEE International Conference on.</source>
          <target state="translated">Liu, Fei Tony, Ting, Kai Ming y Zhou, Zhi-Hua. &quot;Bosque de aislamiento&quot;. Miner&amp;iacute;a de datos, 2008. ICDM'08. Octava Conferencia Internacional IEEE sobre.</target>
        </trans-unit>
        <trans-unit id="8d858831be3c025b5261ad0994fdd43e36106d2f" translate="yes" xml:space="preserve">
          <source>Liu, Fei Tony, Ting, Kai Ming and Zhou, Zhi-Hua. &amp;ldquo;Isolation-based anomaly detection.&amp;rdquo; ACM Transactions on Knowledge Discovery from Data (TKDD) 6.1 (2012): 3.</source>
          <target state="translated">Liu, Fei Tony, Ting, Kai Ming y Zhou, Zhi-Hua. &quot;Detecci&amp;oacute;n de anomal&amp;iacute;as basada en aislamiento&quot;. Transacciones de ACM sobre el descubrimiento de conocimientos a partir de datos (TKDD) 6.1 (2012): 3.</target>
        </trans-unit>
        <trans-unit id="bc1c89a3655919cbe107b23bf70fdaef2d59b7e4" translate="yes" xml:space="preserve">
          <source>Load a datasets as downloaded from &lt;a href=&quot;http://mlcomp.org&quot;&gt;http://mlcomp.org&lt;/a&gt;</source>
          <target state="translated">Cargue un conjunto de datos descargado de &lt;a href=&quot;http://mlcomp.org&quot;&gt;http://mlcomp.org&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="10fbb828ccf5ef978744b601a27eefff85b82acd" translate="yes" xml:space="preserve">
          <source>Load and return the boston house-prices dataset (regression).</source>
          <target state="translated">Cargar y devolver el conjunto de datos de precios de la casa de Boston (regresión).</target>
        </trans-unit>
        <trans-unit id="f0b03288037dddab02ba1bf0d814f5cc8cf63088" translate="yes" xml:space="preserve">
          <source>Load and return the breast cancer wisconsin dataset (classification).</source>
          <target state="translated">Cargue y devuelva el conjunto de datos de Wisconsin sobre el cáncer de mama (clasificación).</target>
        </trans-unit>
        <trans-unit id="fb9c782009d54032f572c4b8eb05f6ff3c69b6ee" translate="yes" xml:space="preserve">
          <source>Load and return the diabetes dataset (regression).</source>
          <target state="translated">Cargar y devolver el conjunto de datos de la diabetes (regresión).</target>
        </trans-unit>
        <trans-unit id="5ee0c3f160bd1db558fab50ff07fd2d60e875939" translate="yes" xml:space="preserve">
          <source>Load and return the digits dataset (classification).</source>
          <target state="translated">Cargar y devolver el conjunto de datos de los dígitos (clasificación).</target>
        </trans-unit>
        <trans-unit id="91627f9a236f04bf8e67f696e6012e55dde096ca" translate="yes" xml:space="preserve">
          <source>Load and return the iris dataset (classification).</source>
          <target state="translated">Cargar y devolver el conjunto de datos del iris (clasificación).</target>
        </trans-unit>
        <trans-unit id="08308ecd69078eb0533ddcbcb38611925dd58ae7" translate="yes" xml:space="preserve">
          <source>Load and return the linnerud dataset (multivariate regression).</source>
          <target state="translated">Cargar y devolver el conjunto de datos de linnerud (regresión multivariante).</target>
        </trans-unit>
        <trans-unit id="0a61d81b3e38cd33952ad8e4ab4da4e0afb0ac23" translate="yes" xml:space="preserve">
          <source>Load and return the wine dataset (classification).</source>
          <target state="translated">Cargar y devolver el conjunto de datos del vino (clasificación).</target>
        </trans-unit>
        <trans-unit id="907ca9fec180a2f563a6eb0b2c208dd89483dfe5" translate="yes" xml:space="preserve">
          <source>Load dataset from multiple files in SVMlight format</source>
          <target state="translated">Cargar el conjunto de datos de múltiples archivos en formato SVMlight</target>
        </trans-unit>
        <trans-unit id="e0287d019fcfe4320ef71958ec3623d393a07d68" translate="yes" xml:space="preserve">
          <source>Load datasets in the svmlight / libsvm format into sparse CSR matrix</source>
          <target state="translated">Cargar los conjuntos de datos en el formato svmlight/libsvm en una matriz CSR dispersa</target>
        </trans-unit>
        <trans-unit id="15df99bbc404778e529956fb3833b1f8b300577d" translate="yes" xml:space="preserve">
          <source>Load sample images for image manipulation.</source>
          <target state="translated">Cargar imágenes de muestra para la manipulación de la imagen.</target>
        </trans-unit>
        <trans-unit id="93b606a5680687306536f14272c219f02caf9a74" translate="yes" xml:space="preserve">
          <source>Load text files with categories as subfolder names.</source>
          <target state="translated">Cargar archivos de texto con categorías como nombres de subcarpeta.</target>
        </trans-unit>
        <trans-unit id="ada1ba97e9c53b7b56715b1a2824f0ae676a78c6" translate="yes" xml:space="preserve">
          <source>Load the 20 newsgroups dataset and vectorize it into token counts (classification).</source>
          <target state="translated">Cargue el conjunto de datos de los 20 grupos de noticias y vectorícelo en recuentos simbólicos (clasificación).</target>
        </trans-unit>
        <trans-unit id="4f7a062fa00aaafd76d451b474abbba6455b18d1" translate="yes" xml:space="preserve">
          <source>Load the California housing dataset (regression).</source>
          <target state="translated">Cargue el conjunto de datos de viviendas de California (regresión).</target>
        </trans-unit>
        <trans-unit id="d369acbb02d6ae84bdcebcaf52c16540c4d5f177" translate="yes" xml:space="preserve">
          <source>Load the Labeled Faces in the Wild (LFW) pairs dataset (classification).</source>
          <target state="translated">Cargue el conjunto de datos de los pares de Caras Etiquetadas en la Naturaleza (LFW)(clasificación).</target>
        </trans-unit>
        <trans-unit id="fdf290fe8f8a97ef39a92df3e1f665ba9f5137b7" translate="yes" xml:space="preserve">
          <source>Load the Labeled Faces in the Wild (LFW) people dataset (classification).</source>
          <target state="translated">Carga el conjunto de datos de las personas etiquetadas en la selva (LFW)(clasificación).</target>
        </trans-unit>
        <trans-unit id="c1d9dfefbd2137b268a0489f71dee7b704510f30" translate="yes" xml:space="preserve">
          <source>Load the Olivetti faces data-set from AT&amp;amp;T (classification).</source>
          <target state="translated">Cargue el conjunto de datos de caras de Olivetti de AT&amp;amp;T (clasificaci&amp;oacute;n).</target>
        </trans-unit>
        <trans-unit id="2772bcfa51d7f467cdc1ff56dd2a38098daf99c8" translate="yes" xml:space="preserve">
          <source>Load the RCV1 multilabel dataset (classification).</source>
          <target state="translated">Cargar el conjunto de datos de la RCV1 (clasificación).</target>
        </trans-unit>
        <trans-unit id="b34ac8eb475e3d0c92e532ea1f16cafea2826dba" translate="yes" xml:space="preserve">
          <source>Load the covertype dataset (classification).</source>
          <target state="translated">Cargar el conjunto de datos de la cubierta (clasificación).</target>
        </trans-unit>
        <trans-unit id="54322fa6d75ea033036ee5315e01f5a9e265e0ca" translate="yes" xml:space="preserve">
          <source>Load the filenames and data from the 20 newsgroups dataset (classification).</source>
          <target state="translated">Cargue los nombres de los archivos y los datos del conjunto de datos de los 20 grupos de noticias (clasificación).</target>
        </trans-unit>
        <trans-unit id="ae3c786b5593f01e176137f6a4960d769f8b9d22" translate="yes" xml:space="preserve">
          <source>Load the kddcup99 dataset (classification).</source>
          <target state="translated">Cargue el conjunto de datos kddcup99 (clasificación).</target>
        </trans-unit>
        <trans-unit id="820329ef76c355bc57213e87e726caebf3ec8e17" translate="yes" xml:space="preserve">
          <source>Load the numpy array of a single sample image</source>
          <target state="translated">Cargar la matriz numérica de una sola imagen de muestra</target>
        </trans-unit>
        <trans-unit id="6565057c8bbe701655d34466bc255155c3ea2c6e" translate="yes" xml:space="preserve">
          <source>Loader for species distribution dataset from Phillips et.</source>
          <target state="translated">Cargador para el conjunto de datos de distribución de especies de Phillips et al.</target>
        </trans-unit>
        <trans-unit id="00912c83de18e685a34ddbd42e1354c697eb14e0" translate="yes" xml:space="preserve">
          <source>Loader for species distribution dataset from Phillips et. al. (2006)</source>
          <target state="translated">Cargador para el conjunto de datos de distribución de especies de Phillips et.al.(2006)</target>
        </trans-unit>
        <trans-unit id="4f514b04ed6b877534da140af8e12cab5016f713" translate="yes" xml:space="preserve">
          <source>Loaders</source>
          <target state="translated">Loaders</target>
        </trans-unit>
        <trans-unit id="1d603b233f1badee343cd4d051b0c74346bf8ab5" translate="yes" xml:space="preserve">
          <source>Loading an example dataset</source>
          <target state="translated">Cargando un ejemplo de conjunto de datos</target>
        </trans-unit>
        <trans-unit id="afb9453c6f5c0750a61be0390918061037ab3605" translate="yes" xml:space="preserve">
          <source>Loading from external datasets</source>
          <target state="translated">Carga de conjuntos de datos externos</target>
        </trans-unit>
        <trans-unit id="b4240e57d982043f1f905f33f107714b1056ff0f" translate="yes" xml:space="preserve">
          <source>Loading the 20 newsgroups dataset</source>
          <target state="translated">Cargando el conjunto de datos de los 20 grupos de noticias</target>
        </trans-unit>
        <trans-unit id="bf453b7e00694519c6d048cddce89c9acdc80f61" translate="yes" xml:space="preserve">
          <source>Loads both, &lt;code&gt;china&lt;/code&gt; and &lt;code&gt;flower&lt;/code&gt;.</source>
          <target state="translated">Carga tanto de &lt;code&gt;china&lt;/code&gt; como de &lt;code&gt;flower&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5a8b86a7fef7215f7de926bc65cb224b10c3ccba" translate="yes" xml:space="preserve">
          <source>Locally Linear Embedding</source>
          <target state="translated">Encajonamiento local lineal</target>
        </trans-unit>
        <trans-unit id="f71746cee5cf3673e7e527aaea93ab0ac960ab66" translate="yes" xml:space="preserve">
          <source>Locally linear embedding (LLE) seeks a lower-dimensional projection of the data which preserves distances within local neighborhoods. It can be thought of as a series of local Principal Component Analyses which are globally compared to find the best non-linear embedding.</source>
          <target state="translated">La incrustación lineal local (LLE)busca una proyección de datos de menor dimensión que preserve las distancias dentro de los vecindarios locales.Se puede pensar en una serie de Análisis de Componentes Principales locales que se comparan globalmente para encontrar la mejor incrustación no lineal.</target>
        </trans-unit>
        <trans-unit id="ba721026e6725be51f569c81e87377b42c664dd5" translate="yes" xml:space="preserve">
          <source>Locally linear embedding can be performed with function &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt;&lt;code&gt;locally_linear_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt;&lt;code&gt;LocallyLinearEmbedding&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">La incrustaci&amp;oacute;n localmente lineal se puede realizar con la funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt; &lt;code&gt;locally_linear_embedding&lt;/code&gt; &lt;/a&gt; o su contraparte orientada a objetos &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt; &lt;code&gt;LocallyLinearEmbedding&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="120996393a2755aae459a0342f6a159574a0420b" translate="yes" xml:space="preserve">
          <source>Log likelihood of the Gaussian mixture given X.</source>
          <target state="translated">Logra la probabilidad de la mezcla gaussiana dada X.</target>
        </trans-unit>
        <trans-unit id="10dac5cbd2ef695e498b42bff8cc166d8d6c8a26" translate="yes" xml:space="preserve">
          <source>Log loss is undefined for p=0 or p=1, so probabilities are clipped to max(eps, min(1 - eps, p)).</source>
          <target state="translated">La pérdida de registros no está definida para p=0 o p=1,por lo que las probabilidades se recortan a max(eps,min(1-eps,p)).</target>
        </trans-unit>
        <trans-unit id="8742f15984971d3e598576d7cde59958d4df18a1" translate="yes" xml:space="preserve">
          <source>Log loss, aka logistic loss or cross-entropy loss.</source>
          <target state="translated">Pérdida de tronco,también conocida como pérdida de logística o pérdida de entropía.</target>
        </trans-unit>
        <trans-unit id="3332ed47adb99d618a3191081bd1b56f7df887fc" translate="yes" xml:space="preserve">
          <source>Log loss, also called logistic regression loss or cross-entropy loss, is defined on probability estimates. It is commonly used in (multinomial) logistic regression and neural networks, as well as in some variants of expectation-maximization, and can be used to evaluate the probability outputs (&lt;code&gt;predict_proba&lt;/code&gt;) of a classifier instead of its discrete predictions.</source>
          <target state="translated">La p&amp;eacute;rdida logar&amp;iacute;tmica, tambi&amp;eacute;n llamada p&amp;eacute;rdida de regresi&amp;oacute;n log&amp;iacute;stica o p&amp;eacute;rdida de entrop&amp;iacute;a cruzada, se define en estimaciones de probabilidad. Se usa com&amp;uacute;nmente en regresiones log&amp;iacute;sticas (multinomiales) y redes neuronales, as&amp;iacute; como en algunas variantes de maximizaci&amp;oacute;n de expectativas, y se puede usar para evaluar las salidas de probabilidad ( &lt;code&gt;predict_proba&lt;/code&gt; ) de un clasificador en lugar de sus predicciones discretas.</target>
        </trans-unit>
        <trans-unit id="f8ceba0d5dd7df5e53e4d9ba0bfe4881369ef7f1" translate="yes" xml:space="preserve">
          <source>Log of probability estimates.</source>
          <target state="translated">Registro de estimaciones de probabilidad.</target>
        </trans-unit>
        <trans-unit id="b2dede1f561914a3bc83cf7a3f85dcff6bab8c76" translate="yes" xml:space="preserve">
          <source>Log probabilities of each data point in X.</source>
          <target state="translated">Registra las probabilidades de cada punto de datos en X.</target>
        </trans-unit>
        <trans-unit id="ce21bba36fd356086ab08edfbf5461d606fc0046" translate="yes" xml:space="preserve">
          <source>Log probability of each class (smoothed).</source>
          <target state="translated">Logra la probabilidad de cada clase (suavizada).</target>
        </trans-unit>
        <trans-unit id="10521a3daec9ae1f69d9eb092c8ffd785e7a6414" translate="yes" xml:space="preserve">
          <source>Log-likelihood of each sample under the current model</source>
          <target state="translated">La probabilidad de registro de cada muestra en el modelo actual</target>
        </trans-unit>
        <trans-unit id="9c1e8dc95e554810186fcd38490e4f1fe6e53c32" translate="yes" xml:space="preserve">
          <source>Log-likelihood score on left-out data across folds.</source>
          <target state="translated">La puntuación de la probabilidad de registro en los datos de la izquierda a través de los pliegues.</target>
        </trans-unit>
        <trans-unit id="af6fc4d4c535e2fcc7787b2d2b354e641a5cdf07" translate="yes" xml:space="preserve">
          <source>Log-marginal likelihood of theta for training data.</source>
          <target state="translated">Probabilidad logarítmica de theta para los datos de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="a79f6e0f430c7ecad68ae2bba39688851de03cfd" translate="yes" xml:space="preserve">
          <source>Log: Logistic Regression.</source>
          <target state="translated">Tronco:Regresión logística.</target>
        </trans-unit>
        <trans-unit id="667a374e42016ea0491009bae949bbc3eb5a98fe" translate="yes" xml:space="preserve">
          <source>Logistic Regression (aka logit, MaxEnt) classifier.</source>
          <target state="translated">Clasificador de Regresión Logística (alias logit,MaxEnt).</target>
        </trans-unit>
        <trans-unit id="7553fecbacc2ab6c754b732dd2a40625b016efa3" translate="yes" xml:space="preserve">
          <source>Logistic Regression 3-class Classifier</source>
          <target state="translated">Regresión logística Clasificador de 3 clases</target>
        </trans-unit>
        <trans-unit id="67b9d1bed8ce4778bb74ee8f32cf37a9f88e56b4" translate="yes" xml:space="preserve">
          <source>Logistic Regression CV (aka logit, MaxEnt) classifier.</source>
          <target state="translated">Clasificador CV de regresión logística (alias logit,MaxEnt).</target>
        </trans-unit>
        <trans-unit id="4c4251ffdad99c44ab6ab03dc44e767ed73a387b" translate="yes" xml:space="preserve">
          <source>Logistic function</source>
          <target state="translated">Función logística</target>
        </trans-unit>
        <trans-unit id="2c0f1438d10823ae208574adad9979316ecf1f7d" translate="yes" xml:space="preserve">
          <source>Logistic regression on raw pixel values is presented for comparison. The example shows that the features extracted by the BernoulliRBM help improve the classification accuracy.</source>
          <target state="translated">La regresión logística de los valores de los píxeles en bruto se presenta para su comparación.El ejemplo muestra que las características extraídas por el BernoulliRBM ayudan a mejorar la precisión de la clasificación.</target>
        </trans-unit>
        <trans-unit id="f05fe21aed88fc82a5a0513559ae877673e205fc" translate="yes" xml:space="preserve">
          <source>Logistic regression with built-in cross validation</source>
          <target state="translated">Regresión logística con validación cruzada incorporada</target>
        </trans-unit>
        <trans-unit id="d3b2957f5500f497ec4678d49dfe4396dcf43781" translate="yes" xml:space="preserve">
          <source>Logistic regression, despite its name, is a linear model for classification rather than regression. Logistic regression is also known in the literature as logit regression, maximum-entropy classification (MaxEnt) or the log-linear classifier. In this model, the probabilities describing the possible outcomes of a single trial are modeled using a &lt;a href=&quot;https://en.wikipedia.org/wiki/Logistic_function&quot;&gt;logistic function&lt;/a&gt;.</source>
          <target state="translated">La regresi&amp;oacute;n log&amp;iacute;stica, a pesar de su nombre, es un modelo lineal de clasificaci&amp;oacute;n m&amp;aacute;s que de regresi&amp;oacute;n. La regresi&amp;oacute;n log&amp;iacute;stica tambi&amp;eacute;n se conoce en la literatura como regresi&amp;oacute;n logit, clasificaci&amp;oacute;n de m&amp;aacute;xima entrop&amp;iacute;a (MaxEnt) o clasificador log-lineal. En este modelo, las probabilidades que describen los posibles resultados de un solo ensayo se modelan utilizando una &lt;a href=&quot;https://en.wikipedia.org/wiki/Logistic_function&quot;&gt;funci&amp;oacute;n log&amp;iacute;stica&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="de456a9443564fc60f026f7b3757765c6c521491" translate="yes" xml:space="preserve">
          <source>LogisticRegression returns well calibrated predictions as it directly optimizes log-loss. In contrast, the other methods return biased probabilities, with different biases per method:</source>
          <target state="translated">LogisticRegression devuelve predicciones bien calibradas ya que optimiza directamente la pérdida de registros.En contraste,los otros métodos devuelven probabilidades sesgadas,con diferentes sesgos por método:</target>
        </trans-unit>
        <trans-unit id="83ec89bbbb1925d31612bf071115de8d555d9924" translate="yes" xml:space="preserve">
          <source>Longitude house block longitude</source>
          <target state="translated">Longitud del bloque de casas longitud</target>
        </trans-unit>
        <trans-unit id="f2ebf0012d7d593bf1ef0d0a316102397c08a9f0" translate="yes" xml:space="preserve">
          <source>Low-level methods</source>
          <target state="translated">Métodos de bajo nivel</target>
        </trans-unit>
        <trans-unit id="ea609f61be1ccbae7413cc55d9401ee01dff16e3" translate="yes" xml:space="preserve">
          <source>Lower bound value on the likelihood (of the training data with respect to the model) of the best fit of inference.</source>
          <target state="translated">Valor límite inferior de la probabilidad (de los datos de capacitación con respecto al modelo)del mejor ajuste de la inferencia.</target>
        </trans-unit>
        <trans-unit id="af301438554e0ee8815f3548a50754545e52e051" translate="yes" xml:space="preserve">
          <source>Lower bound value on the log-likelihood (of the training data with respect to the model) of the best fit of EM.</source>
          <target state="translated">Valor límite inferior de la probabilidad logarítmica (de los datos de formación con respecto al modelo)del mejor ajuste de la EM.</target>
        </trans-unit>
        <trans-unit id="4ada54abc98e483baeab7ae15def52027a7aae96" translate="yes" xml:space="preserve">
          <source>Lower-triangular Cholesky decomposition of the kernel in &lt;code&gt;X_train_&lt;/code&gt;</source>
          <target state="translated">Descomposici&amp;oacute;n de Cholesky triangular inferior del kernel en &lt;code&gt;X_train_&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="b93b2eafc7fea724b9bcb08bb1fb9109b8d1d561" translate="yes" xml:space="preserve">
          <source>M. Bawa, T. Condie and P. Ganesan, &amp;ldquo;LSH Forest: Self-Tuning Indexes for Similarity Search&amp;rdquo;, WWW &amp;lsquo;05 Proceedings of the 14th international conference on World Wide Web, 651-660, 2005.</source>
          <target state="translated">M. Bawa, T. Condie y P. Ganesan, &amp;ldquo;LSH Forest: Self-Tuning Indexes for Similarity Search&amp;rdquo;, Actas WWW '05 de la 14&amp;ordf; conferencia internacional sobre World Wide Web, 651-660, 2005.</target>
        </trans-unit>
        <trans-unit id="e8445854a0cf4ad63f8ee64cb2fc2359051f4c85" translate="yes" xml:space="preserve">
          <source>M. Dumont et al, &lt;a href=&quot;http://www.montefiore.ulg.ac.be/services/stochastic/pubs/2009/DMWG09/dumont-visapp09-shortpaper.pdf&quot;&gt;Fast multi-class image annotation with random subwindows and multiple output randomized trees&lt;/a&gt;, International Conference on Computer Vision Theory and Applications 2009</source>
          <target state="translated">M. Dumont et al, &lt;a href=&quot;http://www.montefiore.ulg.ac.be/services/stochastic/pubs/2009/DMWG09/dumont-visapp09-shortpaper.pdf&quot;&gt;Anotaci&amp;oacute;n r&amp;aacute;pida de im&amp;aacute;genes de varias clases con subventanas aleatorias y &amp;aacute;rboles aleatorizados de salida m&amp;uacute;ltiple&lt;/a&gt; , Conferencia internacional sobre teor&amp;iacute;a y aplicaciones de la visi&amp;oacute;n por computadora 2009</target>
        </trans-unit>
        <trans-unit id="2422710e8cdc4f555670a3606a875134eadd99fe" translate="yes" xml:space="preserve">
          <source>M. Everingham, L. Van Gool, C.K.I. Williams, J. Winn, A. Zisserman, &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157.5766&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;The Pascal Visual Object Classes (VOC) Challenge&lt;/a&gt;, IJCV 2010.</source>
          <target state="translated">M. Everingham, L. Van Gool, CKI Williams, J. Winn, A. Zisserman, Desaf&amp;iacute;o de &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157.5766&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;clases de objetos visuales (VOC) de&lt;/a&gt; Pascal, IJCV 2010.</target>
        </trans-unit>
        <trans-unit id="aa09c5b3704d1cab7c2f9d80f35ab989ea05cba1" translate="yes" xml:space="preserve">
          <source>MAE output is non-negative floating point. The best value is 0.0.</source>
          <target state="translated">La salida del MAE es un punto flotante no negativo.El mejor valor es 0.0.</target>
        </trans-unit>
        <trans-unit id="f4d1d18b18dbadb43dc94aafefb0919124514bb4" translate="yes" xml:space="preserve">
          <source>MEDV Median value of owner-occupied homes in $1000&amp;rsquo;s</source>
          <target state="translated">MEDV Valor medio de las viviendas ocupadas por sus propietarios en $ 1000</target>
        </trans-unit>
        <trans-unit id="33379c640ef1bcb7b4dbc3ceb61d0f9854342e44" translate="yes" xml:space="preserve">
          <source>MKL</source>
          <target state="translated">MKL</target>
        </trans-unit>
        <trans-unit id="a8e1fd8b99167af6d3e02ac86d0a101dabaf0e42" translate="yes" xml:space="preserve">
          <source>MLP can fit a non-linear model to the training data. &lt;code&gt;clf.coefs_&lt;/code&gt; contains the weight matrices that constitute the model parameters:</source>
          <target state="translated">MLP puede ajustar un modelo no lineal a los datos de entrenamiento. &lt;code&gt;clf.coefs_&lt;/code&gt; contiene las matrices de peso que constituyen los par&amp;aacute;metros del modelo:</target>
        </trans-unit>
        <trans-unit id="7fc5f2a7a15f6ccd1641b37c2fb96c6ce75018c2" translate="yes" xml:space="preserve">
          <source>MLP is sensitive to feature scaling.</source>
          <target state="translated">El MLP es sensible al escalamiento de las características.</target>
        </trans-unit>
        <trans-unit id="08431dee59de79a71b4718dbf6ee28e75fee38c3" translate="yes" xml:space="preserve">
          <source>MLP requires tuning a number of hyperparameters such as the number of hidden neurons, layers, and iterations.</source>
          <target state="translated">El MLP requiere la sintonización de una serie de hiperparámetros como el número de neuronas,capas e iteraciones ocultas.</target>
        </trans-unit>
        <trans-unit id="e82dbcf8b443c94c79e54d7d53faa6f5db46762a" translate="yes" xml:space="preserve">
          <source>MLP trains on two arrays: array X of size (n_samples, n_features), which holds the training samples represented as floating point feature vectors; and array y of size (n_samples,), which holds the target values (class labels) for the training samples:</source>
          <target state="translated">El MLP se entrena en dos matrices:la matriz X de tamaño (n_muestras,n_características),que contiene las muestras de entrenamiento representadas como vectores de características de punto flotante;y la matriz y de tamaño (n_muestras,),que contiene los valores objetivo (etiquetas de clase)para las muestras de entrenamiento:</target>
        </trans-unit>
        <trans-unit id="f0c27305c85163e665d40daa0f2ca2e458a2e63e" translate="yes" xml:space="preserve">
          <source>MLP trains using &lt;a href=&quot;https://en.wikipedia.org/wiki/Stochastic_gradient_descent&quot;&gt;Stochastic Gradient Descent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/abs/1412.6980&quot;&gt;Adam&lt;/a&gt;, or &lt;a href=&quot;https://en.wikipedia.org/wiki/Limited-memory_BFGS&quot;&gt;L-BFGS&lt;/a&gt;. Stochastic Gradient Descent (SGD) updates parameters using the gradient of the loss function with respect to a parameter that needs adaptation, i.e.</source>
          <target state="translated">Trenes MLP usando &lt;a href=&quot;https://en.wikipedia.org/wiki/Stochastic_gradient_descent&quot;&gt;Descenso de gradiente estoc&amp;aacute;stico&lt;/a&gt; , &lt;a href=&quot;http://arxiv.org/abs/1412.6980&quot;&gt;Adam&lt;/a&gt; o &lt;a href=&quot;https://en.wikipedia.org/wiki/Limited-memory_BFGS&quot;&gt;L-BFGS&lt;/a&gt; . El descenso de gradiente estoc&amp;aacute;stico (SGD) actualiza los par&amp;aacute;metros utilizando el gradiente de la funci&amp;oacute;n de p&amp;eacute;rdida con respecto a un par&amp;aacute;metro que necesita adaptaci&amp;oacute;n, es decir</target>
        </trans-unit>
        <trans-unit id="f27922032032bfc1325082b9b33d5f3a9228ddf6" translate="yes" xml:space="preserve">
          <source>MLP trains using Backpropagation. More precisely, it trains using some form of gradient descent and the gradients are calculated using Backpropagation. For classification, it minimizes the Cross-Entropy loss function, giving a vector of probability estimates \(P(y|x)\) per sample \(x\):</source>
          <target state="translated">El MLP entrena usando Backpropagation.Más precisamente,se entrena usando alguna forma de descenso de gradiente y los gradientes se calculan usando Backpropagation.Para la clasificación,minimiza la función de pérdida de la entropía cruzada,dando un vector de estimaciones de probabilidad \N (P(y|x)\N por muestra:</target>
        </trans-unit>
        <trans-unit id="c8c1d3b7c59691465cb0496f22bcb3604bca5a60" translate="yes" xml:space="preserve">
          <source>MLP uses different loss functions depending on the problem type. The loss function for classification is Cross-Entropy, which in binary case is given as,</source>
          <target state="translated">El MLP utiliza diferentes funciones de pérdida dependiendo del tipo de problema.La función de pérdida para la clasificación es la de la entropía cruzada,que en el caso binario se da como,</target>
        </trans-unit>
        <trans-unit id="d03f0b750d6ad970862b8ceab4b82a667eb1bc44" translate="yes" xml:space="preserve">
          <source>MLP with hidden layers have a non-convex loss function where there exists more than one local minimum. Therefore different random weight initializations can lead to different validation accuracy.</source>
          <target state="translated">Los MLP con capas ocultas tienen una función de pérdida no convexa cuando existe más de un mínimo local.Por lo tanto,las diferentes inicializaciones de peso aleatorio pueden llevar a una precisión de validación diferente.</target>
        </trans-unit>
        <trans-unit id="14160d0f2e53b28f2f5c2a7702cb0510220c29b8" translate="yes" xml:space="preserve">
          <source>MLPClassifier trains iteratively since at each time step the partial derivatives of the loss function with respect to the model parameters are computed to update the parameters.</source>
          <target state="translated">El MLPClassifier se entrena de forma iterativa ya que en cada paso temporal se calculan las derivadas parciales de la función de pérdida con respecto a los parámetros del modelo para actualizar los parámetros.</target>
        </trans-unit>
        <trans-unit id="8b27d0c0c6a8a44ae6f32f660e2bfb892d109024" translate="yes" xml:space="preserve">
          <source>MLPRegressor trains iteratively since at each time step the partial derivatives of the loss function with respect to the model parameters are computed to update the parameters.</source>
          <target state="translated">El MLPRegressor se entrena de manera iterativa ya que en cada paso de tiempo se calculan las derivadas parciales de la función de pérdida con respecto a los parámetros del modelo para actualizar los parámetros.</target>
        </trans-unit>
        <trans-unit id="8e70290c1fc16432a8f4b616e4fd6fbaa4abfbea" translate="yes" xml:space="preserve">
          <source>MNIST classfification using multinomial logistic + L1</source>
          <target state="translated">Clasificación del MNIST usando logística multinomial+L1</target>
        </trans-unit>
        <trans-unit id="25845da185fe3a02cb60c18fcf84202e8f31d1e7" translate="yes" xml:space="preserve">
          <source>Machine learning algorithms need data. Go to each &lt;code&gt;$TUTORIAL_HOME/data&lt;/code&gt; sub-folder and run the &lt;code&gt;fetch_data.py&lt;/code&gt; script from there (after having read them first).</source>
          <target state="translated">Los algoritmos de aprendizaje autom&amp;aacute;tico necesitan datos. Vaya a cada subcarpeta &lt;code&gt;$TUTORIAL_HOME/data&lt;/code&gt; y ejecute el script &lt;code&gt;fetch_data.py&lt;/code&gt; desde all&amp;iacute; (despu&amp;eacute;s de haberlos le&amp;iacute;do primero).</target>
        </trans-unit>
        <trans-unit id="45f2bd27f62f0226a5b3177e6a59d79cc23fea68" translate="yes" xml:space="preserve">
          <source>Machine learning is about learning some properties of a data set and then testing those properties against another data set. A common practice in machine learning is to evaluate an algorithm by splitting a data set into two. We call one of those sets the &lt;strong&gt;training set&lt;/strong&gt;, on which we learn some properties; we call the other set the &lt;strong&gt;testing set&lt;/strong&gt;, on which we test the learned properties.</source>
          <target state="translated">El aprendizaje autom&amp;aacute;tico consiste en aprender algunas propiedades de un conjunto de datos y luego probar esas propiedades con otro conjunto de datos. Una pr&amp;aacute;ctica com&amp;uacute;n en el aprendizaje autom&amp;aacute;tico es evaluar un algoritmo dividiendo un conjunto de datos en dos. A uno de esos conjuntos lo llamamos conjunto de &lt;strong&gt;entrenamiento&lt;/strong&gt; , en el que aprendemos algunas propiedades; llamamos al otro conjunto el conjunto de &lt;strong&gt;prueba&lt;/strong&gt; , en el que probamos las propiedades aprendidas.</target>
        </trans-unit>
        <trans-unit id="17dc705c260bdc393406dc006335656d8788b655" translate="yes" xml:space="preserve">
          <source>Machine learning: the problem setting</source>
          <target state="translated">Aprendizaje de la máquina:la configuración del problema</target>
        </trans-unit>
        <trans-unit id="e6a69273199992ddfe41f469dda4cc1f6b79ceb0" translate="yes" xml:space="preserve">
          <source>Magnesium</source>
          <target state="translated">Magnesium</target>
        </trans-unit>
        <trans-unit id="2bb08573261ae718ebb52db49951821b64f9a80c" translate="yes" xml:space="preserve">
          <source>Magnesium:</source>
          <target state="translated">Magnesium:</target>
        </trans-unit>
        <trans-unit id="91059cae8d3b76142d7879b78c0a2ccaab268e7d" translate="yes" xml:space="preserve">
          <source>Mahalanobis distances of the training set (on which &lt;code&gt;fit&lt;/code&gt; is called) observations.</source>
          <target state="translated">Distancias de Mahalanobis del conjunto de entrenamiento (en el que se llama &lt;code&gt;fit&lt;/code&gt; ) observaciones.</target>
        </trans-unit>
        <trans-unit id="d469f730cc4a1b58c5ef61209e446f59013c3c80" translate="yes" xml:space="preserve">
          <source>Mahalanobis distances to centers</source>
          <target state="translated">Las distancias de Mahalanobis a los centros</target>
        </trans-unit>
        <trans-unit id="6f98cc22ed52c0a1e40fae778fadcd35627c25b5" translate="yes" xml:space="preserve">
          <source>MahalanobisDistance</source>
          <target state="translated">MahalanobisDistance</target>
        </trans-unit>
        <trans-unit id="62bce9422ff2d14f69ab80a154510232fc8a9afd" translate="yes" xml:space="preserve">
          <source>Main</source>
          <target state="translated">Main</target>
        </trans-unit>
        <trans-unit id="8d6381188443dad8aa5d016fb4ec69dd96237200" translate="yes" xml:space="preserve">
          <source>Make a copy of input data.</source>
          <target state="translated">Haga una copia de los datos de entrada.</target>
        </trans-unit>
        <trans-unit id="f11963f5d19078a49cfab3cc41da5922accd3330" translate="yes" xml:space="preserve">
          <source>Make a large circle containing a smaller circle in 2d.</source>
          <target state="translated">Haz un círculo grande que contenga un círculo más pequeño en 2d.</target>
        </trans-unit>
        <trans-unit id="1cce5fef6c99c293eee32e22f026e768f4b5d892" translate="yes" xml:space="preserve">
          <source>Make a scorer from a performance metric or loss function.</source>
          <target state="translated">Hacer un marcador a partir de una métrica de rendimiento o de una función de pérdida.</target>
        </trans-unit>
        <trans-unit id="bdd3abd6a5ef3ffb2c4167fd4f1b6dc60d7a55bd" translate="yes" xml:space="preserve">
          <source>Make arrays indexable for cross-validation.</source>
          <target state="translated">Hacer las matrices indexables para su validación cruzada.</target>
        </trans-unit>
        <trans-unit id="2d28cad808149ac4eb3c924434a0979417f24a68" translate="yes" xml:space="preserve">
          <source>Make sure that X has a minimum number of samples in its first axis (rows for a 2D array).</source>
          <target state="translated">Asegúrate de que X tenga un número mínimo de muestras en su primer eje (filas para una matriz 2D).</target>
        </trans-unit>
        <trans-unit id="b2b1ee415b35f3ec33d28dbc91a8479edeb8d71e" translate="yes" xml:space="preserve">
          <source>Make sure that array is 2D, square and symmetric.</source>
          <target state="translated">Asegúrate de que la matriz sea 2D,cuadrada y simétrica.</target>
        </trans-unit>
        <trans-unit id="6885424e5e7bfa46a7e7c7cb1bd5d6e804bbccd9" translate="yes" xml:space="preserve">
          <source>Make sure that the 2D array has some minimum number of features (columns). The default value of 1 rejects empty datasets. This check is only enforced when X has effectively 2 dimensions or is originally 1D and &lt;code&gt;ensure_2d&lt;/code&gt; is True. Setting to 0 disables this check.</source>
          <target state="translated">Aseg&amp;uacute;rese de que la matriz 2D tenga un n&amp;uacute;mero m&amp;iacute;nimo de caracter&amp;iacute;sticas (columnas). El valor predeterminado de 1 rechaza los conjuntos de datos vac&amp;iacute;os. Esta verificaci&amp;oacute;n solo se aplica cuando X tiene efectivamente 2 dimensiones o es originalmente 1D y &lt;code&gt;ensure_2d&lt;/code&gt; es True. El ajuste a 0 desactiva esta verificaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="37a276f69711964822e7fcec88111a5f6d2f84a0" translate="yes" xml:space="preserve">
          <source>Make sure that the 2D array has some minimum number of features (columns). The default value of 1 rejects empty datasets. This check is only enforced when the input data has effectively 2 dimensions or is originally 1D and &lt;code&gt;ensure_2d&lt;/code&gt; is True. Setting to 0 disables this check.</source>
          <target state="translated">Aseg&amp;uacute;rese de que la matriz 2D tenga un n&amp;uacute;mero m&amp;iacute;nimo de caracter&amp;iacute;sticas (columnas). El valor predeterminado de 1 rechaza los conjuntos de datos vac&amp;iacute;os. Esta verificaci&amp;oacute;n solo se aplica cuando los datos de entrada tienen efectivamente 2 dimensiones o son originalmente 1D y &lt;code&gt;ensure_2d&lt;/code&gt; es True. El ajuste a 0 desactiva esta verificaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="c24d8a1e4fcddcfde73957adfbe65fb40c76c786" translate="yes" xml:space="preserve">
          <source>Make sure that the array has a minimum number of samples in its first axis (rows for a 2D array). Setting to 0 disables this check.</source>
          <target state="translated">Asegúrate de que la matriz tiene un número mínimo de muestras en su primer eje (filas para una matriz 2D).Ponerlo a 0 desactiva esta comprobación.</target>
        </trans-unit>
        <trans-unit id="fdc3084b2db3fff3561874bdbe81f2954a4b0ffc" translate="yes" xml:space="preserve">
          <source>Make sure the same scale is used over all features. Because manifold learning methods are based on a nearest-neighbor search, the algorithm may perform poorly otherwise. See &lt;a href=&quot;preprocessing#preprocessing-scaler&quot;&gt;StandardScaler&lt;/a&gt; for convenient ways of scaling heterogeneous data.</source>
          <target state="translated">Aseg&amp;uacute;rese de que se utilice la misma escala en todas las funciones. Debido a que varios m&amp;eacute;todos de aprendizaje se basan en una b&amp;uacute;squeda del vecino m&amp;aacute;s cercano, el algoritmo puede funcionar mal de otra manera. Consulte &lt;a href=&quot;preprocessing#preprocessing-scaler&quot;&gt;StandardScaler&lt;/a&gt; para conocer formas convenientes de escalar datos heterog&amp;eacute;neos.</target>
        </trans-unit>
        <trans-unit id="7f7e62e13bb8885a4df4d0d5a8e1dba7c3c65c15" translate="yes" xml:space="preserve">
          <source>Make sure you permute (shuffle) your training data before fitting the model or use &lt;code&gt;shuffle=True&lt;/code&gt; to shuffle after each iteration.</source>
          <target state="translated">Aseg&amp;uacute;rate de permutar (mezclar) tus datos de entrenamiento antes de ajustar el modelo o usa &lt;code&gt;shuffle=True&lt;/code&gt; para mezclar despu&amp;eacute;s de cada iteraci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="f48f3a474378f962985a41275dc98355541c63d2" translate="yes" xml:space="preserve">
          <source>Make two interleaving half circles</source>
          <target state="translated">Haz dos semicírculos intercalados</target>
        </trans-unit>
        <trans-unit id="0a0a9871e0af603535e4f6104cfca3266e203a87" translate="yes" xml:space="preserve">
          <source>Malic Acid:</source>
          <target state="translated">Ácido málico:</target>
        </trans-unit>
        <trans-unit id="245748b8f3a70aaac9759204b7d3978b9d337db8" translate="yes" xml:space="preserve">
          <source>Malic acid</source>
          <target state="translated">El ácido málico</target>
        </trans-unit>
        <trans-unit id="a81a721fb7e702ed0a37d056ec4a9d2f925e70b0" translate="yes" xml:space="preserve">
          <source>ManhattanDistance</source>
          <target state="translated">ManhattanDistance</target>
        </trans-unit>
        <trans-unit id="ccbe2127be70aaa7c3514b3155dd29902fae6143" translate="yes" xml:space="preserve">
          <source>Manifold Learning can be thought of as an attempt to generalize linear frameworks like PCA to be sensitive to non-linear structure in data. Though supervised variants exist, the typical manifold learning problem is unsupervised: it learns the high-dimensional structure of the data from the data itself, without the use of predetermined classifications.</source>
          <target state="translated">El Aprendizaje Múltiple puede ser pensado como un intento de generalizar marcos lineales como el PCA para ser sensible a la estructura no lineal en los datos.Aunque existen variantes supervisadas,el típico problema de aprendizaje múltiple no está supervisado:aprende la estructura altamente dimensional de los datos a partir de los propios datos,sin el uso de clasificaciones predeterminadas.</target>
        </trans-unit>
        <trans-unit id="7a0e60acb472080022463866637a1ea7c0251335" translate="yes" xml:space="preserve">
          <source>Manifold Learning methods on a severed sphere</source>
          <target state="translated">Múltiples métodos de aprendizaje en una esfera cortada</target>
        </trans-unit>
        <trans-unit id="aca365adba00c10f7a3cc50cff4a88afd0947dd9" translate="yes" xml:space="preserve">
          <source>Manifold learning is an approach to non-linear dimensionality reduction. Algorithms for this task are based on the idea that the dimensionality of many data sets is only artificially high.</source>
          <target state="translated">El aprendizaje múltiple es un enfoque para la reducción de la dimensionalidad no lineal.Los algoritmos para esta tarea se basan en la idea de que la dimensionalidad de muchos conjuntos de datos es sólo artificialmente alta.</target>
        </trans-unit>
        <trans-unit id="1e718f0bccbec4566b4c8536fdd24c184318a8a9" translate="yes" xml:space="preserve">
          <source>Manifold learning on handwritten digits: Locally Linear Embedding, Isomap&amp;hellip;</source>
          <target state="translated">Aprendizaje m&amp;uacute;ltiple en d&amp;iacute;gitos escritos a mano: incrustaci&amp;oacute;n lineal local, Isomap ...</target>
        </trans-unit>
        <trans-unit id="0d3695eb907329bab9f0e9752d7ff00d200420c9" translate="yes" xml:space="preserve">
          <source>Many applications require being able to decide whether a new observation belongs to the same distribution as existing observations (it is an &lt;em&gt;inlier&lt;/em&gt;), or should be considered as different (it is an &lt;em&gt;outlier&lt;/em&gt;). Often, this ability is used to clean real data sets. Two important distinctions must be made:</source>
          <target state="translated">Muchas aplicaciones requieren poder decidir si una nueva observaci&amp;oacute;n pertenece a la misma distribuci&amp;oacute;n que las observaciones existentes (es un valor &lt;em&gt;inlier&lt;/em&gt; ), o debe considerarse diferente (es un &lt;em&gt;valor at&amp;iacute;pico&lt;/em&gt; ). A menudo, esta capacidad se utiliza para limpiar conjuntos de datos reales. Deben hacerse dos distinciones importantes:</target>
        </trans-unit>
        <trans-unit id="626f0980ad5cd6d2b6f18a99ff094a7bf141dc9a" translate="yes" xml:space="preserve">
          <source>Many clusters, possibly connectivity constraints</source>
          <target state="translated">Muchos grupos,posiblemente con limitaciones de conectividad</target>
        </trans-unit>
        <trans-unit id="9d1190903d42ddc70f3db2311f157c56b6260b92" translate="yes" xml:space="preserve">
          <source>Many clusters, possibly connectivity constraints, non Euclidean distances</source>
          <target state="translated">Muchos conglomerados,posiblemente con limitaciones de conectividad,distancias no euclidianas</target>
        </trans-unit>
        <trans-unit id="ac65e2f8a158fa7cc404d708906171f5ea9f26fd" translate="yes" xml:space="preserve">
          <source>Many clusters, uneven cluster size, non-flat geometry</source>
          <target state="translated">Muchos cúmulos,tamaño desigual de los cúmulos,geometría no plana</target>
        </trans-unit>
        <trans-unit id="241eda779a46dbe514b8b7f2a96e98aed4d935af" translate="yes" xml:space="preserve">
          <source>Many datasets contain features of different types, say text, floats, and dates, where each type of feature requires separate preprocessing or feature extraction steps. Often it is easiest to preprocess data before applying scikit-learn methods, for example using &lt;a href=&quot;http://pandas.pydata.org/&quot;&gt;pandas&lt;/a&gt;. Processing your data before passing it to scikit-learn might be problematic for one of the following reasons:</source>
          <target state="translated">Muchos conjuntos de datos contienen caracter&amp;iacute;sticas de diferentes tipos, por ejemplo, texto, flotantes y fechas, donde cada tipo de caracter&amp;iacute;stica requiere pasos separados de preprocesamiento o extracci&amp;oacute;n de caracter&amp;iacute;sticas. A menudo, es m&amp;aacute;s f&amp;aacute;cil preprocesar los datos antes de aplicar m&amp;eacute;todos de scikit-learn, por ejemplo, usando &lt;a href=&quot;http://pandas.pydata.org/&quot;&gt;pandas&lt;/a&gt; . Procesar sus datos antes de pasarlos a scikit-learn puede ser problem&amp;aacute;tico por una de las siguientes razones:</target>
        </trans-unit>
        <trans-unit id="192c25a6ed904d1327958fde4c93098505cb86b8" translate="yes" xml:space="preserve">
          <source>Many metrics are not given names to be used as &lt;code&gt;scoring&lt;/code&gt; values, sometimes because they require additional parameters, such as &lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt;&lt;code&gt;fbeta_score&lt;/code&gt;&lt;/a&gt;. In such cases, you need to generate an appropriate scoring object. The simplest way to generate a callable object for scoring is by using &lt;a href=&quot;generated/sklearn.metrics.make_scorer#sklearn.metrics.make_scorer&quot;&gt;&lt;code&gt;make_scorer&lt;/code&gt;&lt;/a&gt;. That function converts metrics into callables that can be used for model evaluation.</source>
          <target state="translated">Muchas m&amp;eacute;tricas no reciben nombres para &lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt; &lt;code&gt;fbeta_score&lt;/code&gt; &lt;/a&gt; como valores de &lt;code&gt;scoring&lt;/code&gt; , a veces porque requieren par&amp;aacute;metros adicionales, como fbeta_score . En tales casos, debe generar un objeto de puntuaci&amp;oacute;n adecuado. La forma m&amp;aacute;s sencilla de generar un objeto invocable para puntuar es utilizando &lt;a href=&quot;generated/sklearn.metrics.make_scorer#sklearn.metrics.make_scorer&quot;&gt; &lt;code&gt;make_scorer&lt;/code&gt; &lt;/a&gt; . Esa funci&amp;oacute;n convierte las m&amp;eacute;tricas en callables que se pueden usar para la evaluaci&amp;oacute;n del modelo.</target>
        </trans-unit>
        <trans-unit id="dacd10610ea3bac36f91971d47d3019273ca964d" translate="yes" xml:space="preserve">
          <source>Many statistical problems require the estimation of a population&amp;rsquo;s covariance matrix, which can be seen as an estimation of data set scatter plot shape. Most of the time, such an estimation has to be done on a sample whose properties (size, structure, homogeneity) have a large influence on the estimation&amp;rsquo;s quality. The &lt;code&gt;sklearn.covariance&lt;/code&gt; package provides tools for accurately estimating a population&amp;rsquo;s covariance matrix under various settings.</source>
          <target state="translated">Muchos problemas estad&amp;iacute;sticos requieren la estimaci&amp;oacute;n de la matriz de covarianza de una poblaci&amp;oacute;n, que puede verse como una estimaci&amp;oacute;n de la forma del diagrama de dispersi&amp;oacute;n del conjunto de datos. La mayor&amp;iacute;a de las veces, dicha estimaci&amp;oacute;n debe realizarse en una muestra cuyas propiedades (tama&amp;ntilde;o, estructura, homogeneidad) tienen una gran influencia en la calidad de la estimaci&amp;oacute;n. El paquete &lt;code&gt;sklearn.covariance&lt;/code&gt; proporciona herramientas para estimar con precisi&amp;oacute;n la matriz de covarianza de una poblaci&amp;oacute;n en varios entornos.</target>
        </trans-unit>
        <trans-unit id="be7bf3b7e371f4bec9a03a7522f6dcf31d112a68" translate="yes" xml:space="preserve">
          <source>Many, many more &amp;hellip;</source>
          <target state="translated">Mucho, mucho, mas &amp;hellip;</target>
        </trans-unit>
        <trans-unit id="01a4f781a04bf81d6d3609180ff5b158082bf232" translate="yes" xml:space="preserve">
          <source>Map data to a normal distribution</source>
          <target state="translated">Los datos del mapa a una distribución normal</target>
        </trans-unit>
        <trans-unit id="16409bc40b2df043ac11786860ad0f327aa511b9" translate="yes" xml:space="preserve">
          <source>Maps data to a normal distribution using a power transformation.</source>
          <target state="translated">Mapea los datos a una distribución normal usando una transformación de energía.</target>
        </trans-unit>
        <trans-unit id="05aecccd2b32722fa423ccbd7840d48763834385" translate="yes" xml:space="preserve">
          <source>Maps data to a standard normal distribution with the parameter &lt;code&gt;output_distribution=&amp;rsquo;normal&amp;rsquo;&lt;/code&gt;.</source>
          <target state="translated">Asigna datos a una distribuci&amp;oacute;n normal est&amp;aacute;ndar con el par&amp;aacute;metro &lt;code&gt;output_distribution=&amp;rsquo;normal&amp;rsquo;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2546740d19a0cb39e3dfa40dd82138fa02a22968" translate="yes" xml:space="preserve">
          <source>Maps each categorical feature name to a list of values, such that the value encoded as i is ith in the list.</source>
          <target state="translated">Mapea cada nombre de característica categórica a una lista de valores,de tal manera que el valor codificado como i es i en la lista.</target>
        </trans-unit>
        <trans-unit id="601b228138151f5d614818578f5a990f06465ee3" translate="yes" xml:space="preserve">
          <source>Marginal distribution for the transformed data. The choices are &amp;lsquo;uniform&amp;rsquo; (default) or &amp;lsquo;normal&amp;rsquo;.</source>
          <target state="translated">Distribuci&amp;oacute;n marginal de los datos transformados. Las opciones son 'uniforme' (predeterminado) o 'normal'.</target>
        </trans-unit>
        <trans-unit id="32cec489ab51eb304acc5d56c34e0b5894817af1" translate="yes" xml:space="preserve">
          <source>Mark Schmidt, Nicolas Le Roux, and Francis Bach: &lt;a href=&quot;https://hal.inria.fr/hal-00860051/document&quot;&gt;Minimizing Finite Sums with the Stochastic Average Gradient.&lt;/a&gt;</source>
          <target state="translated">Mark Schmidt, Nicolas Le Roux y Francis Bach: &lt;a href=&quot;https://hal.inria.fr/hal-00860051/document&quot;&gt;Minimizaci&amp;oacute;n de sumas finitas con el gradiente medio estoc&amp;aacute;stico.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b66f191d027329ba9273c4c5f9be765f9b3745f5" translate="yes" xml:space="preserve">
          <source>Mask to be used on X.</source>
          <target state="translated">Máscara para ser usada en X.</target>
        </trans-unit>
        <trans-unit id="54a21a4d94fa24c6c092fd6e4c2ec05359c76c09" translate="yes" xml:space="preserve">
          <source>MatchingDistance</source>
          <target state="translated">MatchingDistance</target>
        </trans-unit>
        <trans-unit id="38c6b835ca8294e13538ac219d64ae1244beb7fc" translate="yes" xml:space="preserve">
          <source>Matern kernel.</source>
          <target state="translated">Núcleo materno.</target>
        </trans-unit>
        <trans-unit id="c2846fd5b2a8440131137c07fea40912afc701b7" translate="yes" xml:space="preserve">
          <source>Mathematically, it consists of a linear model trained with \(\ell_1\) prior as regularizer. The objective function to minimize is:</source>
          <target state="translated">Matemáticamente,consiste en un modelo lineal entrenado con anterioridad como regularizador.La función objetiva a minimizar es:</target>
        </trans-unit>
        <trans-unit id="bf1818d1c45b1997515a16368907c8cf902bab56" translate="yes" xml:space="preserve">
          <source>Mathematically, it consists of a linear model trained with a mixed \(\ell_1\)\(\ell_2\) prior and \(\ell_2\) prior as regularizer. The objective function to minimize is:</source>
          <target state="translated">Matemáticamente,consiste en un modelo lineal entrenado con un prior mixto y un prior como regularizador.La función objetiva a minimizar es:</target>
        </trans-unit>
        <trans-unit id="1d9fe275a9038555cabcfe46b4a675067788d84f" translate="yes" xml:space="preserve">
          <source>Mathematically, it consists of a linear model trained with a mixed \(\ell_1\)\(\ell_2\) prior as regularizer. The objective function to minimize is:</source>
          <target state="translated">Matemáticamente,consiste en un modelo lineal entrenado con un priorizador mixto como regularizador.La función objetiva a minimizar es:</target>
        </trans-unit>
        <trans-unit id="461064fec990b9f56bd78c5da4699263962dc67b" translate="yes" xml:space="preserve">
          <source>Mathematically, this shrinkage consists in reducing the ratio between the smallest and the largest eigenvalues of the empirical covariance matrix. It can be done by simply shifting every eigenvalue according to a given offset, which is equivalent of finding the l2-penalized Maximum Likelihood Estimator of the covariance matrix. In practice, shrinkage boils down to a simple a convex transformation : \(\Sigma_{\rm shrunk} = (1-\alpha)\hat{\Sigma} + \alpha\frac{{\rm Tr}\hat{\Sigma}}{p}\rm Id\).</source>
          <target state="translated">Matemáticamente,esta contracción consiste en reducir la relación entre los valores propios más pequeños y más grandes de la matriz de covarianza empírica.Se puede hacer simplemente desplazando cada valor propio según una compensación dada,lo que equivale a encontrar el estimador de máxima probabilidad penalizado en l2 de la matriz de covarianza.En la práctica,la contracción se reduce a una simple transformación convexa:\Sigma encogido=(1-alfa)que es un Sigma+alfafraccionado.</target>
        </trans-unit>
        <trans-unit id="7f2fa948973686599d9719cd22bf9c261bdbf5a5" translate="yes" xml:space="preserve">
          <source>Mathematically, truncated SVD applied to training samples \(X\) produces a low-rank approximation \(X\):</source>
          <target state="translated">Matemáticamente,la SVD truncada aplicada a las muestras de entrenamiento (X)produce una aproximación de bajo rango (X):</target>
        </trans-unit>
        <trans-unit id="b8c6141893596b10260b39727bf4a66986a56a95" translate="yes" xml:space="preserve">
          <source>Matrices:</source>
          <target state="translated">Matrices:</target>
        </trans-unit>
        <trans-unit id="878abbe8708b2c0d949ede6590fbf80f3b3ca712" translate="yes" xml:space="preserve">
          <source>Matrix \(C\) such that \(C_{i, j}\) is the number of samples in true class \(i\) and in predicted class \(j\). If &lt;code&gt;eps is None&lt;/code&gt;, the dtype of this array will be integer. If &lt;code&gt;eps&lt;/code&gt; is given, the dtype will be float. Will be a &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; if &lt;code&gt;sparse=True&lt;/code&gt;.</source>
          <target state="translated">Matriz \ (C \) tal que \ (C_ {i, j} \) es el n&amp;uacute;mero de muestras en la clase verdadera \ (i \) y en la clase predicha \ (j \). Si &lt;code&gt;eps is None&lt;/code&gt; , el dtype de esta matriz ser&amp;aacute; un n&amp;uacute;mero entero. Si se da &lt;code&gt;eps&lt;/code&gt; , el tipo d ser&amp;aacute; flotante. Ser&amp;aacute; un &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; si &lt;code&gt;sparse=True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="9a9d3bf25623c95ec103c9ba9ebefafc39b31e10" translate="yes" xml:space="preserve">
          <source>Matrix of similarities between points</source>
          <target state="translated">Matriz de similitudes entre puntos</target>
        </trans-unit>
        <trans-unit id="fe09cc11ed56c787dbf583e1d3c86930e73d13b7" translate="yes" xml:space="preserve">
          <source>Matrix to be scaled.</source>
          <target state="translated">Matriz a escala.</target>
        </trans-unit>
        <trans-unit id="f581a8973d13aee9e6d301f776c7ac0aca9937df" translate="yes" xml:space="preserve">
          <source>Matrix to decompose</source>
          <target state="translated">La matriz para descomponerse</target>
        </trans-unit>
        <trans-unit id="64c58969af0dfb121c9b8582a353fed07f3ae81a" translate="yes" xml:space="preserve">
          <source>Matrix to normalize using the variance of the features.</source>
          <target state="translated">Matriz para normalizar usando la variación de las características.</target>
        </trans-unit>
        <trans-unit id="dc67599b55e21aadb81c15a2c42c0d243f238c7f" translate="yes" xml:space="preserve">
          <source>Matrix whose two columns are to be swapped.</source>
          <target state="translated">Matriz cuyas dos columnas deben ser intercambiadas.</target>
        </trans-unit>
        <trans-unit id="2ea8698954891f702cc6556af5a70f4a4777910c" translate="yes" xml:space="preserve">
          <source>Matrix whose two rows are to be swapped.</source>
          <target state="translated">Matriz cuyas dos filas deben ser intercambiadas.</target>
        </trans-unit>
        <trans-unit id="91c27cd36373d9f3e97d3e8652e4d5420038195e" translate="yes" xml:space="preserve">
          <source>Max number of iterations for updating document topic distribution in the E-step.</source>
          <target state="translated">Número máximo de iteraciones para la actualización de la distribución de temas de documentos en el E-step.</target>
        </trans-unit>
        <trans-unit id="00c71f39eb3784f568496e9b201bef34cf1fba1e" translate="yes" xml:space="preserve">
          <source>MaxAbsScaler</source>
          <target state="translated">MaxAbsScaler</target>
        </trans-unit>
        <trans-unit id="b19f6ae06ce0301b0f2f115ace4b151976f71361" translate="yes" xml:space="preserve">
          <source>Maximizing ELBO is equivalent to minimizing the Kullback-Leibler(KL) divergence between \(q(z,\theta,\beta)\) and the true posterior \(p(z, \theta, \beta |w, \alpha, \eta)\).</source>
          <target state="translated">Maximizar el ELBO equivale a minimizar la divergencia Kullback-Leibler(KL)entre \ ~ q(z,\N-theta,\N-beta)y el verdadero posterior (p(z,\N-theta,\N-beta,\Nw,\N-alpha,eta)).</target>
        </trans-unit>
        <trans-unit id="c7118c6c94bd33474c6bd73b2a0ef4d05bd61b9a" translate="yes" xml:space="preserve">
          <source>Maximizing the log-marginal-likelihood after subtracting the target&amp;rsquo;s mean yields the following kernel with an LML of -83.214:</source>
          <target state="translated">Maximizar la probabilidad logar&amp;iacute;tmica marginal despu&amp;eacute;s de restar la media del objetivo produce el siguiente kernel con un LML de -83,214:</target>
        </trans-unit>
        <trans-unit id="3cc68e53e734e045e272d9b61d6ce440314a7c5a" translate="yes" xml:space="preserve">
          <source>Maximum distortion rate as defined by the Johnson-Lindenstrauss lemma. If an array is given, it will compute a safe number of components array-wise.</source>
          <target state="translated">Tasa de distorsión máxima definida por el lema de Johnson-Lindenstrauss.Si se da una matriz,se calculará un número seguro de componentes por matriz.</target>
        </trans-unit>
        <trans-unit id="2648af65469bf6064127630edb239d63fa9087cb" translate="yes" xml:space="preserve">
          <source>Maximum likelihood covariance estimator</source>
          <target state="translated">Estimador de covarianza de máxima probabilidad</target>
        </trans-unit>
        <trans-unit id="c549d82a160dc50758b33cda113fa1dc7a80727c" translate="yes" xml:space="preserve">
          <source>Maximum norm of the residual. If not None, overrides n_nonzero_coefs.</source>
          <target state="translated">Norma máxima del residuo.Si no hay ninguno,anula los n_nonzero_coefs.</target>
        </trans-unit>
        <trans-unit id="c4d8a154588727ab7c620ef2088eb03d03fdb2cd" translate="yes" xml:space="preserve">
          <source>Maximum number of CF subclusters in each node. If a new samples enters such that the number of subclusters exceed the branching_factor then that node is split into two nodes with the subclusters redistributed in each. The parent subcluster of that node is removed and two new subclusters are added as parents of the 2 split nodes.</source>
          <target state="translated">Número máximo de subconjuntos de FQ en cada nodo.Si una nueva muestra entra de tal manera que el número de subconjuntos excede el factor_rama,entonces ese nodo se divide en dos nodos con los subconjuntos redistribuidos en cada uno.El subclúster padre de ese nodo se elimina y se añaden dos nuevos subclústeres como padres de los 2 nodos divididos.</target>
        </trans-unit>
        <trans-unit id="ffcbfb393ae9341f5e6cf4dea80093dbb65c654d" translate="yes" xml:space="preserve">
          <source>Maximum number of epochs to not meet &lt;code&gt;tol&lt;/code&gt; improvement. Only effective when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;</source>
          <target state="translated">N&amp;uacute;mero m&amp;aacute;ximo de &amp;eacute;pocas para no cumplir con la mejora de la &lt;code&gt;tol&lt;/code&gt; . Solo es efectivo cuando solver = 'sgd' o 'adam'</target>
        </trans-unit>
        <trans-unit id="2d31095f21fc709b8362fbfbc8701ee49bed43f4" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations</source>
          <target state="translated">Número máximo de iteraciones</target>
        </trans-unit>
        <trans-unit id="8d0f629c611a546c50fbd29c0a5c09d14523502f" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations before timing out.</source>
          <target state="translated">Número máximo de iteraciones antes de la sincronización.</target>
        </trans-unit>
        <trans-unit id="e5ab15aeae2ebd19c6cc8dd9b722001d143407e7" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations during fit.</source>
          <target state="translated">Número máximo de iteraciones durante el ajuste.</target>
        </trans-unit>
        <trans-unit id="4bd775e3e4801f1199d0d4b78f5390120406b7db" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for arpack. If None, optimal value will be chosen by arpack.</source>
          <target state="translated">Número máximo de iteraciones para el arpack.Si no hay ninguna,el valor óptimo será elegido por arpack.</target>
        </trans-unit>
        <trans-unit id="f374a3956c9375a530255caa54ee43ca08273ef7" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for conjugate gradient solver. For &amp;lsquo;sparse_cg&amp;rsquo; and &amp;lsquo;lsqr&amp;rsquo; solvers, the default value is determined by scipy.sparse.linalg. For &amp;lsquo;sag&amp;rsquo; solver, the default value is 1000.</source>
          <target state="translated">N&amp;uacute;mero m&amp;aacute;ximo de iteraciones para el solucionador de gradiente conjugado. Para los solucionadores 'sparse_cg' y 'lsqr', scipy.sparse.linalg determina el valor predeterminado. Para el solucionador 'sag', el valor predeterminado es 1000.</target>
        </trans-unit>
        <trans-unit id="11f341e8f36dbf9c1af7cfa8e66dcc9686e34f6b" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for conjugate gradient solver. For the &amp;lsquo;sparse_cg&amp;rsquo; and &amp;lsquo;lsqr&amp;rsquo; solvers, the default value is determined by scipy.sparse.linalg. For &amp;lsquo;sag&amp;rsquo; and saga solver, the default value is 1000.</source>
          <target state="translated">N&amp;uacute;mero m&amp;aacute;ximo de iteraciones para el solucionador de gradiente conjugado. Para los solucionadores 'sparse_cg' y 'lsqr', scipy.sparse.linalg determina el valor predeterminado. Para 'sag' y saga solver, el valor predeterminado es 1000.</target>
        </trans-unit>
        <trans-unit id="c5354ceb6cfff4ad460f2a35427697293dda616c" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for conjugate gradient solver. The default value is determined by scipy.sparse.linalg.</source>
          <target state="translated">Número máximo de iteraciones para el solucionador de gradientes conjugados.El valor por defecto está determinado por scipy.sparse.linalg.</target>
        </trans-unit>
        <trans-unit id="1e7dfd80e629f3bb34ea64892d98c69b612b79e1" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for random sample selection.</source>
          <target state="translated">Número máximo de iteraciones para la selección de muestras aleatorias.</target>
        </trans-unit>
        <trans-unit id="ecd130d87b8a2f3d02f709f684a50be372cae2c9" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for the arpack solver. not used if eigen_solver == &amp;lsquo;dense&amp;rsquo;.</source>
          <target state="translated">N&amp;uacute;mero m&amp;aacute;ximo de iteraciones para el solucionador de arpack. no se usa si eigen_solver == 'denso'.</target>
        </trans-unit>
        <trans-unit id="9de38c6ff2395ad8506cb6d44f0cafffcf62c788" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for the calculation of spatial median.</source>
          <target state="translated">Número máximo de iteraciones para el cálculo de la mediana espacial.</target>
        </trans-unit>
        <trans-unit id="07f904d8faecfe25c803428c8e7a88d0070e3e3e" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for the optimization. Should be at least 250.</source>
          <target state="translated">Número máximo de iteraciones para la optimización.Debería ser de al menos 250.</target>
        </trans-unit>
        <trans-unit id="dce17045503a4e7dfc48c40d90d1aeae843b7e1f" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for the solver.</source>
          <target state="translated">Número máximo de iteraciones para el solucionador.</target>
        </trans-unit>
        <trans-unit id="e1c1739cc631f47e83bf7484461b685fd99cca3d" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations of the SMACOF algorithm for a single run.</source>
          <target state="translated">Número máximo de iteraciones del algoritmo SMACOF para una sola corrida.</target>
        </trans-unit>
        <trans-unit id="7f1e71a3c23990192b71291657a3bae2f490d4ee" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations of the k-means algorithm for a single run.</source>
          <target state="translated">Número máximo de iteraciones del algoritmo k-means para una sola corrida.</target>
        </trans-unit>
        <trans-unit id="f0e6e9653318c3bc8385e39576298e438fdcd759" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations of the k-means algorithm to run.</source>
          <target state="translated">Número máximo de iteraciones del algoritmo k-means a ejecutar.</target>
        </trans-unit>
        <trans-unit id="368dd40a437636dbd3f559d65e7725494d2a9fb1" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations of the optimization algorithm.</source>
          <target state="translated">Número máximo de iteraciones del algoritmo de optimización.</target>
        </trans-unit>
        <trans-unit id="63c06831f070b2a52428ee45e49cb4b88ea5a09d" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations over the complete dataset before stopping independently of any early stopping criterion heuristics.</source>
          <target state="translated">Número máximo de iteraciones sobre el conjunto de datos completo antes de detenerse independientemente de cualquier heurística de criterio de detención temprana.</target>
        </trans-unit>
        <trans-unit id="7899fd5b3a78738f0401cfc3b35e8ce4d2309778" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations that can be skipped due to finding zero inliers or invalid data defined by &lt;code&gt;is_data_valid&lt;/code&gt; or invalid models defined by &lt;code&gt;is_model_valid&lt;/code&gt;.</source>
          <target state="translated">N&amp;uacute;mero m&amp;aacute;ximo de iteraciones que se pueden omitir debido a la b&amp;uacute;squeda de cero inliers o datos no v&amp;aacute;lidos definidos por &lt;code&gt;is_data_valid&lt;/code&gt; o modelos no v&amp;aacute;lidos definidos por &lt;code&gt;is_model_valid&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e7fba252520d1990cf2d4eb5716def2f32bbae99" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations that scipy.optimize.fmin_l_bfgs_b should run for.</source>
          <target state="translated">El máximo número de iteraciones que scipy.optimize.fmin_l_bfgs_b debe ejecutar.</target>
        </trans-unit>
        <trans-unit id="4e1098501827a192b62ebb4f1cab51c2d422cf00" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations to perform if &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt;.</source>
          <target state="translated">N&amp;uacute;mero m&amp;aacute;ximo de iteraciones a realizar si &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="aa990833ac4f020e2d41da9d6169624866ecf0ee" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations to perform in the Lars algorithm.</source>
          <target state="translated">Número máximo de iteraciones a realizar en el algoritmo de Lars.</target>
        </trans-unit>
        <trans-unit id="d0f4ce7794b613699161c8c6e0e45882e1e59e63" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations to perform, set to infinity for no limit.</source>
          <target state="translated">Número máximo de iteraciones a realizar,fijado al infinito sin límite.</target>
        </trans-unit>
        <trans-unit id="6484f135db2cde17daa0042bcd9839216d734460" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations to perform.</source>
          <target state="translated">Número máximo de iteraciones a realizar.</target>
        </trans-unit>
        <trans-unit id="db2ca83257c5e157920232d66349b60febf20184" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations to perform. Can be used for early stopping.</source>
          <target state="translated">Número máximo de iteraciones a realizar.Puede ser usado para una parada temprana.</target>
        </trans-unit>
        <trans-unit id="3ae0883a212da2486dca35b829a405dbbd2b8c29" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations without progress before we abort the optimization, used after 250 initial iterations with early exaggeration. Note that progress is only checked every 50 iterations so this value is rounded to the next multiple of 50.</source>
          <target state="translated">Número máximo de iteraciones sin progreso antes de abortar la optimización,utilizado después de 250 iteraciones iniciales con exageración temprana.Tenga en cuenta que el progreso sólo se comprueba cada 50 iteraciones,por lo que este valor se redondea al siguiente múltiplo de 50.</target>
        </trans-unit>
        <trans-unit id="5919ba2c46521b64537304f167c62803da4391df" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations, per seed point before the clustering operation terminates (for that seed point), if has not converged yet.</source>
          <target state="translated">Número máximo de iteraciones,por punto de siembra antes de que termine la operación de agrupación (para ese punto de siembra),si no ha convergido todavía.</target>
        </trans-unit>
        <trans-unit id="3fcea6ff6580050eb63d7142d23e7d7896de7626" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations.</source>
          <target state="translated">Número máximo de iteraciones.</target>
        </trans-unit>
        <trans-unit id="2bd71b5c83b9f5da0d4a94baa31a035271906ce7" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations. Default is 300</source>
          <target state="translated">Número máximo de iteraciones.Por defecto es 300</target>
        </trans-unit>
        <trans-unit id="6740f9eed55c5399b0f5fe47513d42802b2d72aa" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations. Default is 300.</source>
          <target state="translated">Número máximo de iteraciones.Por defecto es 300.</target>
        </trans-unit>
        <trans-unit id="1d3427b734648d0ef9c00f4282011f095b732bba" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations. The solver iterates until convergence (determined by &amp;lsquo;tol&amp;rsquo;) or this number of iterations. For stochastic solvers (&amp;lsquo;sgd&amp;rsquo;, &amp;lsquo;adam&amp;rsquo;), note that this determines the number of epochs (how many times each data point will be used), not the number of gradient steps.</source>
          <target state="translated">N&amp;uacute;mero m&amp;aacute;ximo de iteraciones. El solucionador itera hasta la convergencia (determinada por 'tol') o este n&amp;uacute;mero de iteraciones. Para los solucionadores estoc&amp;aacute;sticos ('sgd', 'adam'), tenga en cuenta que esto determina el n&amp;uacute;mero de &amp;eacute;pocas (cu&amp;aacute;ntas veces se utilizar&amp;aacute; cada punto de datos), no el n&amp;uacute;mero de pasos de gradiente.</target>
        </trans-unit>
        <trans-unit id="647156dc0e4267e82660e321d855d0ab57ee6ce8" translate="yes" xml:space="preserve">
          <source>Maximum number of samples used to estimate the quantiles for computational efficiency. Note that the subsampling procedure may differ for value-identical sparse and dense matrices.</source>
          <target state="translated">Número máximo de muestras utilizadas para estimar los cuantiles para la eficiencia de los cálculos.Obsérvese que el procedimiento de submuestreo puede diferir para matrices dispersas y densas de valor idéntico.</target>
        </trans-unit>
        <trans-unit id="415a2ec1c451656db8760ffe077b89b191d3a2b3" translate="yes" xml:space="preserve">
          <source>Maximum numbers of iterations to perform, therefore maximum features to include. 10% of &lt;code&gt;n_features&lt;/code&gt; but at least 5 if available.</source>
          <target state="translated">N&amp;uacute;mero m&amp;aacute;ximo de iteraciones para realizar, por lo tanto, caracter&amp;iacute;sticas m&amp;aacute;ximas para incluir. 10% de &lt;code&gt;n_features&lt;/code&gt; pero al menos 5 si est&amp;aacute;n disponibles.</target>
        </trans-unit>
        <trans-unit id="631012abffd401f8346d1251260aa1bdd321bf8a" translate="yes" xml:space="preserve">
          <source>Maximum of covariances (in absolute value) at each iteration. &lt;code&gt;n_alphas&lt;/code&gt; is either &lt;code&gt;max_iter&lt;/code&gt;, &lt;code&gt;n_features&lt;/code&gt; or the number of nodes in the path with &lt;code&gt;alpha &amp;gt;= alpha_min&lt;/code&gt;, whichever is smaller.</source>
          <target state="translated">M&amp;aacute;ximo de covarianzas (en valor absoluto) en cada iteraci&amp;oacute;n. &lt;code&gt;n_alphas&lt;/code&gt; es &lt;code&gt;max_iter&lt;/code&gt; , &lt;code&gt;n_features&lt;/code&gt; o el n&amp;uacute;mero de nodos en la ruta con &lt;code&gt;alpha &amp;gt;= alpha_min&lt;/code&gt; , el que sea menor.</target>
        </trans-unit>
        <trans-unit id="705f01a5b973480d43f7edb8b4f1d8b46afffacc" translate="yes" xml:space="preserve">
          <source>Maximum of covariances (in absolute value) at each iteration. &lt;code&gt;n_alphas&lt;/code&gt; is either &lt;code&gt;max_iter&lt;/code&gt;, &lt;code&gt;n_features&lt;/code&gt;, or the number of nodes in the path with correlation greater than &lt;code&gt;alpha&lt;/code&gt;, whichever is smaller.</source>
          <target state="translated">M&amp;aacute;ximo de covarianzas (en valor absoluto) en cada iteraci&amp;oacute;n. &lt;code&gt;n_alphas&lt;/code&gt; es &lt;code&gt;max_iter&lt;/code&gt; , &lt;code&gt;n_features&lt;/code&gt; o el n&amp;uacute;mero de nodos en la ruta con una correlaci&amp;oacute;n mayor que &lt;code&gt;alpha&lt;/code&gt; , el que sea menor.</target>
        </trans-unit>
        <trans-unit id="62989d4a3b259ca439d6192faa2834aa0e75a2e0" translate="yes" xml:space="preserve">
          <source>Maximum of covariances (in absolute value) at each iteration. &lt;code&gt;n_alphas&lt;/code&gt; is either &lt;code&gt;n_nonzero_coefs&lt;/code&gt; or &lt;code&gt;n_features&lt;/code&gt;, whichever is smaller.</source>
          <target state="translated">M&amp;aacute;ximo de covarianzas (en valor absoluto) en cada iteraci&amp;oacute;n. &lt;code&gt;n_alphas&lt;/code&gt; es &lt;code&gt;n_nonzero_coefs&lt;/code&gt; o &lt;code&gt;n_features&lt;/code&gt; , el que sea menor.</target>
        </trans-unit>
        <trans-unit id="e56eb85aade57d415023e1a3a8ae03f5b942a0cd" translate="yes" xml:space="preserve">
          <source>Maximum residual for a data sample to be classified as an inlier. By default the threshold is chosen as the MAD (median absolute deviation) of the target values &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">M&amp;aacute;ximo residual para que una muestra de datos se clasifique como un valor interno. De forma predeterminada, el umbral se elige como la DMA (desviaci&amp;oacute;n absoluta media) de los valores objetivo &lt;code&gt;y&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6dd6334c9c1bb29cde2ace0d7ca9c039e7de14bd" translate="yes" xml:space="preserve">
          <source>Maximum size for a single training set.</source>
          <target state="translated">Tamaño máximo para un solo equipo de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="3feffec2bfb871f0142dbd2d75d410b437245309" translate="yes" xml:space="preserve">
          <source>Maximum squared sum of X over samples. Used only in SAG solver. If None, it will be computed, going through all the samples. The value should be precomputed to speed up cross validation.</source>
          <target state="translated">Suma cuadrada máxima de X sobre las muestras.Usado sólo en el solucionador SAG.Si no hay ninguno,se calculará,pasando por todas las muestras.El valor debe ser precalculado para acelerar la validación cruzada.</target>
        </trans-unit>
        <trans-unit id="229948f9503f6467f2a53d61f4254093e7ca3738" translate="yes" xml:space="preserve">
          <source>Maximum step size (regularization). Defaults to 1.0.</source>
          <target state="translated">Tamaño máximo del paso (regularización).Por defecto es 1.0.</target>
        </trans-unit>
        <trans-unit id="843c61e3ff0f74449c911dbb02faa43821e29850" translate="yes" xml:space="preserve">
          <source>Maximum value of a bicluster.</source>
          <target state="translated">Valor máximo de un bíceps.</target>
        </trans-unit>
        <trans-unit id="ce9a39e13a20e687ebff9fcf4496175bdfa0afbb" translate="yes" xml:space="preserve">
          <source>Maximum value of input array &lt;code&gt;X_&lt;/code&gt; for right bound.</source>
          <target state="translated">Valor m&amp;aacute;ximo de la matriz de entrada &lt;code&gt;X_&lt;/code&gt; para el l&amp;iacute;mite derecho.</target>
        </trans-unit>
        <trans-unit id="9fa80bb15d05b082522b43fcb83b05beb6f022c6" translate="yes" xml:space="preserve">
          <source>May be the string &amp;ldquo;jaccard&amp;rdquo; to use the Jaccard coefficient, or any function that takes four arguments, each of which is a 1d indicator vector: (a_rows, a_columns, b_rows, b_columns).</source>
          <target state="translated">Puede ser la cadena &quot;jaccard&quot; para usar el coeficiente de Jaccard, o cualquier funci&amp;oacute;n que tome cuatro argumentos, cada uno de los cuales es un vector indicador 1d: (a_rows, a_columns, b_rows, b_columns).</target>
        </trans-unit>
        <trans-unit id="4fad1e9d11d435bd5f0db307b217272d94f19197" translate="yes" xml:space="preserve">
          <source>May contain any subset of (&amp;lsquo;headers&amp;rsquo;, &amp;lsquo;footers&amp;rsquo;, &amp;lsquo;quotes&amp;rsquo;). Each of these are kinds of text that will be detected and removed from the newsgroup posts, preventing classifiers from overfitting on metadata.</source>
          <target state="translated">Puede contener cualquier subconjunto de ('encabezados', 'pies de p&amp;aacute;gina', 'comillas'). Cada uno de estos son tipos de texto que se detectar&amp;aacute;n y eliminar&amp;aacute;n de las publicaciones del grupo de noticias, evitando que los clasificadores se ajusten demasiado a los metadatos.</target>
        </trans-unit>
        <trans-unit id="4f0935dfe9ab3f30e90c245d2338ed727682177f" translate="yes" xml:space="preserve">
          <source>Mean Absolute Error:</source>
          <target state="translated">Error medio absoluto:</target>
        </trans-unit>
        <trans-unit id="007ffde203dd83c4c710b22da1cbe0b3700a98d1" translate="yes" xml:space="preserve">
          <source>Mean Silhouette Coefficient for all samples.</source>
          <target state="translated">Coeficiente de Silueta Media para todas las muestras.</target>
        </trans-unit>
        <trans-unit id="2762f10f75116f5e4a70c10eb14cf5f478eb498f" translate="yes" xml:space="preserve">
          <source>Mean Squared Error:</source>
          <target state="translated">Error de media cuadra:</target>
        </trans-unit>
        <trans-unit id="43559adecf21dbddbbe17afba52b16b4a67e4402" translate="yes" xml:space="preserve">
          <source>Mean absolute error regression loss</source>
          <target state="translated">Promedio de la pérdida de regresión del error absoluto</target>
        </trans-unit>
        <trans-unit id="ec9517dd8574c2a6b45d6a307e2a503f5e6d275d" translate="yes" xml:space="preserve">
          <source>Mean accuracy of self.predict(X) wrt. y.</source>
          <target state="translated">Exactitud media de la auto predicción (X)con respecto a la y.</target>
        </trans-unit>
        <trans-unit id="7493a61b1729d0e0247689ac97555930f03706df" translate="yes" xml:space="preserve">
          <source>Mean cross-validated score of the best_estimator</source>
          <target state="translated">Promedio de la puntuación cruzada del mejor_estimador</target>
        </trans-unit>
        <trans-unit id="140100875ffefa42eddb6a75afe4c55e05443030" translate="yes" xml:space="preserve">
          <source>Mean cross-validated score of the best_estimator.</source>
          <target state="translated">Promedio de la puntuación cruzada del mejor_estimador.</target>
        </trans-unit>
        <trans-unit id="dd2a669704ec2ab03a0e4ca8e2abc9c2d42f71c6" translate="yes" xml:space="preserve">
          <source>Mean of predictive distribution a query points</source>
          <target state="translated">Media de la distribución predictiva de los puntos de consulta</target>
        </trans-unit>
        <trans-unit id="b609d0f7d96a7b9c8e60baf85298ffc173cbc6f7" translate="yes" xml:space="preserve">
          <source>Mean of predictive distribution of query points.</source>
          <target state="translated">Media de la distribución predictiva de los puntos de consulta.</target>
        </trans-unit>
        <trans-unit id="e7f5a133eabd3f3a470b8b7cb54eeb045b64973a" translate="yes" xml:space="preserve">
          <source>Mean or median or quantile of the training targets or constant value given by the user.</source>
          <target state="translated">Media o mediana o cuantil de los objetivos de entrenamiento o valor constante dado por el usuario.</target>
        </trans-unit>
        <trans-unit id="9ede03e41402c8eec43dd01264f8f822af5fb92b" translate="yes" xml:space="preserve">
          <source>Mean shift clustering aims to discover &amp;ldquo;blobs&amp;rdquo; in a smooth density of samples. It is a centroid-based algorithm, which works by updating candidates for centroids to be the mean of the points within a given region. These candidates are then filtered in a post-processing stage to eliminate near-duplicates to form the final set of centroids.</source>
          <target state="translated">La agrupaci&amp;oacute;n de cambios medios tiene como objetivo descubrir &quot;manchas&quot; en una densidad uniforme de muestras. Es un algoritmo basado en centroides, que funciona actualizando candidatos para centroides para que sean la media de los puntos dentro de una regi&amp;oacute;n determinada. Estos candidatos luego se filtran en una etapa de posprocesamiento para eliminar casi duplicados para formar el conjunto final de centroides.</target>
        </trans-unit>
        <trans-unit id="08b2e6d37eec1f5ceae1376ffba9071609b6547f" translate="yes" xml:space="preserve">
          <source>Mean shift clustering using a flat kernel.</source>
          <target state="translated">Agrupación de turnos media usando un núcleo plano.</target>
        </trans-unit>
        <trans-unit id="4484f1a9abfaeee06549ff0a6b75712b44fd35f2" translate="yes" xml:space="preserve">
          <source>Mean square error for the test set on each fold, varying l1_ratio and alpha.</source>
          <target state="translated">Error cuadrático medio del conjunto de pruebas en cada pliegue,variando l1_ratio y alfa.</target>
        </trans-unit>
        <trans-unit id="4a0031a2d59450a58aeaa638a064cb2e2c9a0da5" translate="yes" xml:space="preserve">
          <source>Mean squared error regression loss</source>
          <target state="translated">Pérdida de regresión del error cuadrado medio</target>
        </trans-unit>
        <trans-unit id="831bfb250ab69b773c25fae60f230a00bfdc7239" translate="yes" xml:space="preserve">
          <source>Mean squared logarithmic error regression loss</source>
          <target state="translated">Pérdida de regresión del error logarítmico al cuadrado medio</target>
        </trans-unit>
        <trans-unit id="2db7f6881ab1082c632822482db18fa9fc34ed90" translate="yes" xml:space="preserve">
          <source>Mean-shift</source>
          <target state="translated">Mean-shift</target>
        </trans-unit>
        <trans-unit id="df21241945c8fd60618f888d81f315be3f7af674" translate="yes" xml:space="preserve">
          <source>Measure the similarity of two clusterings of a set of points.</source>
          <target state="translated">Mide la similitud de dos agrupaciones de un conjunto de puntos.</target>
        </trans-unit>
        <trans-unit id="e49da6a85d81735a7b28ef79fc256dec989d2443" translate="yes" xml:space="preserve">
          <source>Measurement errors in X</source>
          <target state="translated">Errores de medición en X</target>
        </trans-unit>
        <trans-unit id="471fba4dfe2d4f61d0ae5efc77acb722551abb7b" translate="yes" xml:space="preserve">
          <source>Measurement errors in y</source>
          <target state="translated">Errores de medición en y</target>
        </trans-unit>
        <trans-unit id="d59aa4a9911bb1573c0ba0a2779ea96a4989f27f" translate="yes" xml:space="preserve">
          <source>MedInc median income in block</source>
          <target state="translated">Ingreso medio en bloque</target>
        </trans-unit>
        <trans-unit id="bb82014fc42479d50d7886c5d05c20bd8db97f56" translate="yes" xml:space="preserve">
          <source>Median absolute error regression loss</source>
          <target state="translated">Pérdida de regresión del error absoluto medio</target>
        </trans-unit>
        <trans-unit id="9e7082d8eb8f2409deaa71605e5d6dbf5b190217" translate="yes" xml:space="preserve">
          <source>Medium &lt;code&gt;n_samples&lt;/code&gt;, small &lt;code&gt;n_clusters&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;n_samples&lt;/code&gt; medianos , &lt;code&gt;n_clusters&lt;/code&gt; peque&amp;ntilde;os</target>
        </trans-unit>
        <trans-unit id="da13fe6da16d1b0d3601ee1416010215c9da2b3d" translate="yes" xml:space="preserve">
          <source>Member &lt;code&gt;coef_&lt;/code&gt; holds the weights \(w\)</source>
          <target state="translated">El miembro &lt;code&gt;coef_&lt;/code&gt; tiene los pesos \ (w \)</target>
        </trans-unit>
        <trans-unit id="b26ca7073281a8f4da3f64aafb4932ce0dc723cc" translate="yes" xml:space="preserve">
          <source>Member &lt;code&gt;intercept_&lt;/code&gt; holds \(b\)</source>
          <target state="translated">La &lt;code&gt;intercept_&lt;/code&gt; tiene \ (b \)</target>
        </trans-unit>
        <trans-unit id="8e7e4ea63f467ef992e1b5515c3662fd092327fd" translate="yes" xml:space="preserve">
          <source>Member &lt;code&gt;intercept_&lt;/code&gt; holds the intercept (aka offset or bias):</source>
          <target state="translated">Miembro &lt;code&gt;intercept_&lt;/code&gt; sostiene el intercepto (tambi&amp;eacute;n conocido como offset o sesgo):</target>
        </trans-unit>
        <trans-unit id="b6ef7f0fdf735583a61dbfc359227479e43bf842" translate="yes" xml:space="preserve">
          <source>Memmapping mode for numpy arrays passed to workers. See &amp;lsquo;max_nbytes&amp;rsquo; parameter documentation for more details.</source>
          <target state="translated">Modo Memmapping para matrices numpy pasadas a los trabajadores. Consulte la documentaci&amp;oacute;n del par&amp;aacute;metro 'max_nbytes' para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="424b610ebd2af23e4bb8a29dcabbc0551e9c3d87" translate="yes" xml:space="preserve">
          <source>Memory consumption for large sample sizes</source>
          <target state="translated">Consumo de memoria para muestras de gran tamaño</target>
        </trans-unit>
        <trans-unit id="5418f36b831a9c825f5d841c5ee3b1bdb2dd3e28" translate="yes" xml:space="preserve">
          <source>Meta-estimator to regress on a transformed target.</source>
          <target state="translated">Metaestimulador para retroceder en un objetivo transformado.</target>
        </trans-unit>
        <trans-unit id="79599678d3d5e2500fd2a7f727461a2dac0b6cd4" translate="yes" xml:space="preserve">
          <source>Meta-estimators for building composite models with transformers</source>
          <target state="translated">Metaestimuladores para construir modelos compuestos con transformadores</target>
        </trans-unit>
        <trans-unit id="d5a7b3579e10eeaa00ced1884380b174708caebd" translate="yes" xml:space="preserve">
          <source>Meta-transformer for selecting features based on importance weights.</source>
          <target state="translated">Meta-transformador para seleccionar características basadas en pesos de importancia.</target>
        </trans-unit>
        <trans-unit id="88306943fea7e76f9cd57cae0ea6d8b32d2e8434" translate="yes" xml:space="preserve">
          <source>Method</source>
          <target state="translated">Method</target>
        </trans-unit>
        <trans-unit id="3dad9226be4bd937f8a455ee0badad4ee6cceff1" translate="yes" xml:space="preserve">
          <source>Method for initialization of k-means algorithm; defaults to &amp;lsquo;k-means++&amp;rsquo;.</source>
          <target state="translated">M&amp;eacute;todo de inicializaci&amp;oacute;n del algoritmo k-means; por defecto es 'k-means ++'.</target>
        </trans-unit>
        <trans-unit id="2c3f3dc3ba37d9b2f1af18176cea15628b89a09c" translate="yes" xml:space="preserve">
          <source>Method for initialization, default to &amp;lsquo;k-means++&amp;rsquo;:</source>
          <target state="translated">M&amp;eacute;todo de inicializaci&amp;oacute;n, predeterminado en 'k-means ++':</target>
        </trans-unit>
        <trans-unit id="62b8a3dc56fc8229948d624cc5b38920d22e2365" translate="yes" xml:space="preserve">
          <source>Method for initialization, defaults to &amp;lsquo;k-means++&amp;rsquo;:</source>
          <target state="translated">M&amp;eacute;todo de inicializaci&amp;oacute;n, predeterminado en 'k-means ++':</target>
        </trans-unit>
        <trans-unit id="3b1389e0e832a05337d6ccb31e50ea1425ca91a8" translate="yes" xml:space="preserve">
          <source>Method name</source>
          <target state="translated">Nombre del método</target>
        </trans-unit>
        <trans-unit id="b78ea13fd7ce3e01d82dac91ffffedca9d6a516f" translate="yes" xml:space="preserve">
          <source>Method of normalizing and converting singular vectors into biclusters. May be one of &amp;lsquo;scale&amp;rsquo;, &amp;lsquo;bistochastic&amp;rsquo;, or &amp;lsquo;log&amp;rsquo;. The authors recommend using &amp;lsquo;log&amp;rsquo;. If the data is sparse, however, log normalization will not work, which is why the default is &amp;lsquo;bistochastic&amp;rsquo;. CAUTION: if &lt;code&gt;method=&amp;rsquo;log&amp;rsquo;&lt;/code&gt;, the data must not be sparse.</source>
          <target state="translated">M&amp;eacute;todo de normalizaci&amp;oacute;n y conversi&amp;oacute;n de vectores singulares en biclusters. Puede ser uno de 'escala', 'bistoc&amp;aacute;stico' o 'log'. Los autores recomiendan usar 'log'. Sin embargo, si los datos son escasos, la normalizaci&amp;oacute;n de registros no funcionar&amp;aacute;, por lo que el valor predeterminado es &quot;bistoc&amp;aacute;stico&quot;. PRECAUCI&amp;Oacute;N: si &lt;code&gt;method=&amp;rsquo;log&amp;rsquo;&lt;/code&gt; , los datos no deben ser escasos.</target>
        </trans-unit>
        <trans-unit id="7e7b59d1db0b41f1f7de6a768474fa98a959edfd" translate="yes" xml:space="preserve">
          <source>Method to use in finding shortest path.</source>
          <target state="translated">Método a utilizar para encontrar el camino más corto.</target>
        </trans-unit>
        <trans-unit id="46674c498c855af96974ed544b15ae6396d6f74f" translate="yes" xml:space="preserve">
          <source>Method used to encode the transformed result.</source>
          <target state="translated">Método utilizado para codificar el resultado transformado.</target>
        </trans-unit>
        <trans-unit id="155758829048f282b684f453070e5e32e8a3b098" translate="yes" xml:space="preserve">
          <source>Method used to initialize the procedure. Default: &amp;lsquo;nndsvd&amp;rsquo; if n_components &amp;lt; n_features, otherwise random. Valid options:</source>
          <target state="translated">M&amp;eacute;todo utilizado para inicializar el procedimiento. Predeterminado: 'nndsvd' si n_components &amp;lt;n_features, de lo contrario aleatorio. Opciones v&amp;aacute;lidas:</target>
        </trans-unit>
        <trans-unit id="2c32a8fabfe7118c5a18a023b129a09f5774d869" translate="yes" xml:space="preserve">
          <source>Method used to update &lt;code&gt;_component&lt;/code&gt;. Only used in &lt;code&gt;fit&lt;/code&gt; method. In general, if the data size is large, the online update will be much faster than the batch update.</source>
          <target state="translated">M&amp;eacute;todo utilizado para actualizar &lt;code&gt;_component&lt;/code&gt; . Solo se utiliza en el m&amp;eacute;todo de &lt;code&gt;fit&lt;/code&gt; . En general, si el tama&amp;ntilde;o de los datos es grande, la actualizaci&amp;oacute;n en l&amp;iacute;nea ser&amp;aacute; mucho m&amp;aacute;s r&amp;aacute;pida que la actualizaci&amp;oacute;n por lotes.</target>
        </trans-unit>
        <trans-unit id="7e4ac6803c9159c694f63d089cb06b2519c16aba" translate="yes" xml:space="preserve">
          <source>Methods</source>
          <target state="translated">Methods</target>
        </trans-unit>
        <trans-unit id="ef01ecfb88c8d650a45a85cec9ebc18d89f4ecbc" translate="yes" xml:space="preserve">
          <source>Metric used to compute the linkage. Can be &amp;ldquo;euclidean&amp;rdquo;, &amp;ldquo;l1&amp;rdquo;, &amp;ldquo;l2&amp;rdquo;, &amp;ldquo;manhattan&amp;rdquo;, &amp;ldquo;cosine&amp;rdquo;, or &amp;lsquo;precomputed&amp;rsquo;. If linkage is &amp;ldquo;ward&amp;rdquo;, only &amp;ldquo;euclidean&amp;rdquo; is accepted.</source>
          <target state="translated">M&amp;eacute;trica utilizada para calcular el v&amp;iacute;nculo. Puede ser &quot;euclidiana&quot;, &quot;l1&quot;, &quot;l2&quot;, &quot;manhattan&quot;, &quot;coseno&quot; o &quot;precalculado&quot;. Si el enlace es &quot;pupilo&quot;, solo se acepta &quot;euclidiana&quot;.</target>
        </trans-unit>
        <trans-unit id="b996dbf9b464efe667f55d3c7b947b9e2ffb345f" translate="yes" xml:space="preserve">
          <source>Metrics available for various machine learning tasks are detailed in sections below.</source>
          <target state="translated">Las métricas disponibles para varias tareas de aprendizaje de la máquina se detallan en las secciones siguientes.</target>
        </trans-unit>
        <trans-unit id="276b36ad13c4507935dcfa6095085df1bf048be3" translate="yes" xml:space="preserve">
          <source>Michael E. Tipping: &lt;a href=&quot;http://www.jmlr.org/papers/volume1/tipping01a/tipping01a.pdf&quot;&gt;Sparse Bayesian Learning and the Relevance Vector Machine&lt;/a&gt;</source>
          <target state="translated">Michael E. Tipping: &lt;a href=&quot;http://www.jmlr.org/papers/volume1/tipping01a/tipping01a.pdf&quot;&gt;aprendizaje bayesiano disperso y la m&amp;aacute;quina de vectores de relevancia&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="ee22c86ee428b82d33b13bdebced2deed71d63a1" translate="yes" xml:space="preserve">
          <source>Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)</source>
          <target state="translated">Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)</target>
        </trans-unit>
        <trans-unit id="f33a348553a7d85d27424bb525b1eca4fb8a5155" translate="yes" xml:space="preserve">
          <source>MinMaxScaler</source>
          <target state="translated">MinMaxScaler</target>
        </trans-unit>
        <trans-unit id="6fad9f3e5fbaefddf87807ab8e89f2398827a6e0" translate="yes" xml:space="preserve">
          <source>Mini-Batch K-Means clustering</source>
          <target state="translated">Agrupación de Mini-Batch K-Means</target>
        </trans-unit>
        <trans-unit id="8a7343b748199980306d06faf24494c5fb233c16" translate="yes" xml:space="preserve">
          <source>Mini-batch Sparse Principal Components Analysis</source>
          <target state="translated">Análisis de los componentes principales de los mini lotes dispersos</target>
        </trans-unit>
        <trans-unit id="4a04231399e807603297c55fa730ae6cac785e8b" translate="yes" xml:space="preserve">
          <source>Mini-batch dictionary learning</source>
          <target state="translated">Aprendizaje de diccionarios en miniatura</target>
        </trans-unit>
        <trans-unit id="b36d4bb746673223e9f3eddf90497433b367472a" translate="yes" xml:space="preserve">
          <source>Mini-batch sparse PCA (&lt;a href=&quot;generated/sklearn.decomposition.minibatchsparsepca#sklearn.decomposition.MiniBatchSparsePCA&quot;&gt;&lt;code&gt;MiniBatchSparsePCA&lt;/code&gt;&lt;/a&gt;) is a variant of &lt;a href=&quot;generated/sklearn.decomposition.sparsepca#sklearn.decomposition.SparsePCA&quot;&gt;&lt;code&gt;SparsePCA&lt;/code&gt;&lt;/a&gt; that is faster but less accurate. The increased speed is reached by iterating over small chunks of the set of features, for a given number of iterations.</source>
          <target state="translated">Mini-batch sparse PCA ( &lt;a href=&quot;generated/sklearn.decomposition.minibatchsparsepca#sklearn.decomposition.MiniBatchSparsePCA&quot;&gt; &lt;code&gt;MiniBatchSparsePCA&lt;/code&gt; &lt;/a&gt; ) es una variante de &lt;a href=&quot;generated/sklearn.decomposition.sparsepca#sklearn.decomposition.SparsePCA&quot;&gt; &lt;code&gt;SparsePCA&lt;/code&gt; &lt;/a&gt; que es m&amp;aacute;s r&amp;aacute;pida pero menos precisa. La velocidad aumentada se alcanza iterando sobre peque&amp;ntilde;os fragmentos del conjunto de caracter&amp;iacute;sticas, para un n&amp;uacute;mero determinado de iteraciones.</target>
        </trans-unit>
        <trans-unit id="338b69eb058f4b8de205ae0e6a0b364261aebe7e" translate="yes" xml:space="preserve">
          <source>Minimizes the objective function:</source>
          <target state="translated">Minimiza la función objetiva:</target>
        </trans-unit>
        <trans-unit id="84c971787220fb3e13d325cba22644ed7cfc6396" translate="yes" xml:space="preserve">
          <source>Minimizing Finite Sums with the Stochastic Average Gradient &lt;a href=&quot;https://hal.inria.fr/hal-00860051/document&quot;&gt;https://hal.inria.fr/hal-00860051/document&lt;/a&gt;</source>
          <target state="translated">Minimizaci&amp;oacute;n de sumas finitas con el gradiente medio estoc&amp;aacute;stico &lt;a href=&quot;https://hal.inria.fr/hal-00860051/document&quot;&gt;https://hal.inria.fr/hal-00860051/document&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="40d428add0b0bb2b15690324c7a65b1e95d21444" translate="yes" xml:space="preserve">
          <source>Minimum Covariance Determinant (MCD): robust estimator of covariance.</source>
          <target state="translated">Determinante de la covarianza mínima (MCD):estimador robusto de la covarianza.</target>
        </trans-unit>
        <trans-unit id="f0d923ebaec99475dba3ff68622a8b582426df2b" translate="yes" xml:space="preserve">
          <source>Minimum Covariance Determinant Estimator</source>
          <target state="translated">Estimador del determinante de la covarianza mínima</target>
        </trans-unit>
        <trans-unit id="acdf76216ef7494ca3a405d1a4760970f1dcb045" translate="yes" xml:space="preserve">
          <source>Minimum correlation along the path. It corresponds to the regularization parameter alpha parameter in the Lasso.</source>
          <target state="translated">Correlación mínima a lo largo del camino.Corresponde al parámetro de regularización alfa del Lasso.</target>
        </trans-unit>
        <trans-unit id="45261c0e2275ffe7c782578b7e04c16d232cec64" translate="yes" xml:space="preserve">
          <source>Minimum number of candidates evaluated per estimator, assuming enough items meet the &lt;code&gt;min_hash_match&lt;/code&gt; constraint.</source>
          <target state="translated">N&amp;uacute;mero m&amp;iacute;nimo de candidatos evaluados por estimador, asumiendo que suficientes elementos cumplen la restricci&amp;oacute;n &lt;code&gt;min_hash_match&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1f6032c543b0bedd4ef1a29303943c7332e81e08" translate="yes" xml:space="preserve">
          <source>Minimum number of samples chosen randomly from original data. Treated as an absolute number of samples for &lt;code&gt;min_samples &amp;gt;= 1&lt;/code&gt;, treated as a relative number &lt;code&gt;ceil(min_samples * X.shape[0]&lt;/code&gt;) for &lt;code&gt;min_samples &amp;lt; 1&lt;/code&gt;. This is typically chosen as the minimal number of samples necessary to estimate the given &lt;code&gt;base_estimator&lt;/code&gt;. By default a &lt;code&gt;sklearn.linear_model.LinearRegression()&lt;/code&gt; estimator is assumed and &lt;code&gt;min_samples&lt;/code&gt; is chosen as &lt;code&gt;X.shape[1] + 1&lt;/code&gt;.</source>
          <target state="translated">N&amp;uacute;mero m&amp;iacute;nimo de muestras elegidas al azar de los datos originales. Se trata como un n&amp;uacute;mero absoluto de muestras para &lt;code&gt;min_samples &amp;gt;= 1&lt;/code&gt; , se trata como un n&amp;uacute;mero relativo &lt;code&gt;ceil(min_samples * X.shape[0]&lt;/code&gt; ) para &lt;code&gt;min_samples &amp;lt; 1&lt;/code&gt; . Esto normalmente se elige como el n&amp;uacute;mero m&amp;iacute;nimo de muestras necesarias para estimar el dado &lt;code&gt;base_estimator&lt;/code&gt; . Por defecto, un &lt;code&gt;sklearn.linear_model.LinearRegression()&lt;/code&gt; se supone estimador y &lt;code&gt;min_samples&lt;/code&gt; se elige como &lt;code&gt;X.shape[1] + 1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3a6bb55043794a0a93e8ff0524f08e79cbc35225" translate="yes" xml:space="preserve">
          <source>Minimum value of a bicluster.</source>
          <target state="translated">Valor mínimo de un bíceps.</target>
        </trans-unit>
        <trans-unit id="59e81ca4cbc76e95e029c93b9fa76bb8c2828a22" translate="yes" xml:space="preserve">
          <source>Minimum value of input array &lt;code&gt;X_&lt;/code&gt; for left bound.</source>
          <target state="translated">Valor m&amp;iacute;nimo de la matriz de entrada &lt;code&gt;X_&lt;/code&gt; para el l&amp;iacute;mite izquierdo.</target>
        </trans-unit>
        <trans-unit id="2b5d457149fe5be167ed99387c99dd4725835fe8" translate="yes" xml:space="preserve">
          <source>MinkowskiDistance</source>
          <target state="translated">MinkowskiDistance</target>
        </trans-unit>
        <trans-unit id="f3547bc4550b1de5a83615a3b3bc38cc23770ce0" translate="yes" xml:space="preserve">
          <source>Mirrors &lt;code&gt;class_log_prior_&lt;/code&gt; for interpreting MultinomialNB as a linear model.</source>
          <target state="translated">Espejos &lt;code&gt;class_log_prior_&lt;/code&gt; para interpretar MultinomialNB como un modelo lineal.</target>
        </trans-unit>
        <trans-unit id="7814bd45bfd54f380e5f0cd3f0461e627752ef7b" translate="yes" xml:space="preserve">
          <source>Mirrors &lt;code&gt;feature_log_prob_&lt;/code&gt; for interpreting MultinomialNB as a linear model.</source>
          <target state="translated">Refleja &lt;code&gt;feature_log_prob_&lt;/code&gt; para interpretar MultinomialNB como un modelo lineal.</target>
        </trans-unit>
        <trans-unit id="e446df504bb1a7ba9afc2f86aa7e483abdbc1937" translate="yes" xml:space="preserve">
          <source>Missing Attribute Values:</source>
          <target state="translated">Valores de atributo faltantes:</target>
        </trans-unit>
        <trans-unit id="391b82fea55e1ed8699fe6e91400e8d6055ab0df" translate="yes" xml:space="preserve">
          <source>Missing values can be replaced by the mean, the median or the most frequent value using the basic &lt;a href=&quot;../modules/generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;sklearn.impute.SimpleImputer&lt;/code&gt;&lt;/a&gt;. The median is a more robust estimator for data with high magnitude variables which could dominate results (otherwise known as a &amp;lsquo;long tail&amp;rsquo;).</source>
          <target state="translated">Los valores que faltan se pueden reemplazar por la media, la mediana o el valor m&amp;aacute;s frecuente usando el &lt;a href=&quot;../modules/generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt; &lt;code&gt;sklearn.impute.SimpleImputer&lt;/code&gt; &lt;/a&gt; b&amp;aacute;sico . La mediana es un estimador m&amp;aacute;s robusto para datos con variables de alta magnitud que podr&amp;iacute;an dominar los resultados (tambi&amp;eacute;n conocido como 'cola larga').</target>
        </trans-unit>
        <trans-unit id="7657a2d6545adb4955b10f53c4131bc5602e90eb" translate="yes" xml:space="preserve">
          <source>Missing values in the &amp;lsquo;data&amp;rsquo; are represented as NaN&amp;rsquo;s. Missing values in &amp;lsquo;target&amp;rsquo; are represented as NaN&amp;rsquo;s (numerical target) or None (categorical target)</source>
          <target state="translated">Los valores que faltan en los 'datos' se representan como NaN. Los valores que faltan en 'objetivo' se representan como NaN (objetivo num&amp;eacute;rico) o Ninguno (objetivo categ&amp;oacute;rico)</target>
        </trans-unit>
        <trans-unit id="6a6932c856f91eed3dd44780fa6b9fe69490c4b8" translate="yes" xml:space="preserve">
          <source>Mixin class for all bicluster estimators in scikit-learn</source>
          <target state="translated">Clase mixta para todos los estimadores de bíceps en scikit-learn</target>
        </trans-unit>
        <trans-unit id="2c10e3ce37d297d342507e753914a98859330d14" translate="yes" xml:space="preserve">
          <source>Mixin class for all classifiers in scikit-learn.</source>
          <target state="translated">Clase mixta para todos los clasificadores en scikit-learn.</target>
        </trans-unit>
        <trans-unit id="5fa39e3354bc95759f1ac752182b15d93d7771cd" translate="yes" xml:space="preserve">
          <source>Mixin class for all cluster estimators in scikit-learn.</source>
          <target state="translated">Clase mixta para todos los estimadores de cúmulos en scikit-learn.</target>
        </trans-unit>
        <trans-unit id="eb8addc65b16d7fa21479da43bfb0ac745b8fd54" translate="yes" xml:space="preserve">
          <source>Mixin class for all density estimators in scikit-learn.</source>
          <target state="translated">Clase de mixina para todos los estimadores de densidad en scikit-learn.</target>
        </trans-unit>
        <trans-unit id="6ac045bb154d5d0dbd1cc9d29eba911e1ea2781a" translate="yes" xml:space="preserve">
          <source>Mixin class for all regression estimators in scikit-learn.</source>
          <target state="translated">Clase mixta para todos los estimadores de regresión en scikit-learn.</target>
        </trans-unit>
        <trans-unit id="f73bd7177b7212616f9ae4cd764e784bac6a7ce1" translate="yes" xml:space="preserve">
          <source>Mixin class for all transformers in scikit-learn.</source>
          <target state="translated">Clase de mezcla para todos los transformadores en scikit-learn.</target>
        </trans-unit>
        <trans-unit id="4d9a44acff48ccb4a2b026d4835ebe86a95495fc" translate="yes" xml:space="preserve">
          <source>Model Complexity Influence</source>
          <target state="translated">Influencia de la complejidad del modelo</target>
        </trans-unit>
        <trans-unit id="7d5e06ce8e5a0fb1e8e99aee47dbf3426de865fe" translate="yes" xml:space="preserve">
          <source>Model Selection Interface</source>
          <target state="translated">Interfaz de selección de modelos</target>
        </trans-unit>
        <trans-unit id="d9b7f2bb0f8fc0d29940e1aefd1565fcc5b449f7" translate="yes" xml:space="preserve">
          <source>Model blending: When predictions of one supervised estimator are used to train another estimator in ensemble methods.</source>
          <target state="translated">Mezcla de modelos:Cuando las predicciones de un estimador supervisado se utilizan para entrenar a otro estimador en métodos de conjunto.</target>
        </trans-unit>
        <trans-unit id="c3b027b1bc55171725d0853107d2cd63b70cf1b0" translate="yes" xml:space="preserve">
          <source>Model complexity</source>
          <target state="translated">Complejidad del modelo</target>
        </trans-unit>
        <trans-unit id="088cfdc97cd06f5c2647d7bc4d07170997a1804d" translate="yes" xml:space="preserve">
          <source>Model compression in scikit-learn only concerns linear models for the moment. In this context it means that we want to control the model sparsity (i.e. the number of non-zero coordinates in the model vectors). It is generally a good idea to combine model sparsity with sparse input data representation.</source>
          <target state="translated">La compresión de modelos en scikit-learn sólo concierne a los modelos lineales por el momento.En este contexto significa que queremos controlar la dispersión del modelo (es decir,el número de coordenadas no nulas en los vectores del modelo).En general,es una buena idea combinar la dispersión del modelo con la representación de los datos de entrada escasos.</target>
        </trans-unit>
        <trans-unit id="12cb4d758358636a28aab0195639a05c4c6adf09" translate="yes" xml:space="preserve">
          <source>Model persistence</source>
          <target state="translated">Model persistence</target>
        </trans-unit>
        <trans-unit id="c38101ec23202ddb2bcf9ed4925ad6d1c9181511" translate="yes" xml:space="preserve">
          <source>Model reshaping consists in selecting only a portion of the available features to fit a model. In other words, if a model discards features during the learning phase we can then strip those from the input. This has several benefits. Firstly it reduces memory (and therefore time) overhead of the model itself. It also allows to discard explicit feature selection components in a pipeline once we know which features to keep from a previous run. Finally, it can help reduce processing time and I/O usage upstream in the data access and feature extraction layers by not collecting and building features that are discarded by the model. For instance if the raw data come from a database, it can make it possible to write simpler and faster queries or reduce I/O usage by making the queries return lighter records. At the moment, reshaping needs to be performed manually in scikit-learn. In the case of sparse input (particularly in &lt;code&gt;CSR&lt;/code&gt; format), it is generally sufficient to not generate the relevant features, leaving their columns empty.</source>
          <target state="translated">La remodelaci&amp;oacute;n del modelo consiste en seleccionar solo una parte de las funciones disponibles para adaptarse a un modelo. En otras palabras, si un modelo descarta caracter&amp;iacute;sticas durante la fase de aprendizaje, podemos eliminarlas de la entrada. Esto tiene varios beneficios. En primer lugar, reduce la sobrecarga de memoria (y, por lo tanto, de tiempo) del modelo en s&amp;iacute;. Tambi&amp;eacute;n permite descartar componentes de selecci&amp;oacute;n de caracter&amp;iacute;sticas expl&amp;iacute;citas en una canalizaci&amp;oacute;n una vez que sabemos qu&amp;eacute; caracter&amp;iacute;sticas conservar de una ejecuci&amp;oacute;n anterior. Finalmente, puede ayudar a reducir el tiempo de procesamiento y el uso de E / S en sentido ascendente en las capas de extracci&amp;oacute;n de caracter&amp;iacute;sticas y acceso a datos al no recopilar y generar caracter&amp;iacute;sticas que el modelo descarta. Por ejemplo, si los datos sin procesar provienen de una base de datos, puede hacer posible escribir consultas m&amp;aacute;s simples y r&amp;aacute;pidas o reducir el uso de E / S haciendo que las consultas devuelvan registros m&amp;aacute;s ligeros. En el momento,la remodelaci&amp;oacute;n debe realizarse manualmente en scikit-learn. En el caso de entrada escasa (particularmente en &lt;code&gt;CSR&lt;/code&gt; Formato CSR ), generalmente es suficiente no generar las caracter&amp;iacute;sticas relevantes, dejando sus columnas vac&amp;iacute;as.</target>
        </trans-unit>
        <trans-unit id="12aba00cd9b6d07b68e1c4795de07ac9d7b738d7" translate="yes" xml:space="preserve">
          <source>Model selection and evaluation using tools, such as &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;model_selection.GridSearchCV&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;model_selection.cross_val_score&lt;/code&gt;&lt;/a&gt;, take a &lt;code&gt;scoring&lt;/code&gt; parameter that controls what metric they apply to the estimators evaluated.</source>
          <target state="translated">La selecci&amp;oacute;n y evaluaci&amp;oacute;n de modelos mediante herramientas, como &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;model_selection.GridSearchCV&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt; &lt;code&gt;model_selection.cross_val_score&lt;/code&gt; &lt;/a&gt; , toman un par&amp;aacute;metro de &lt;code&gt;scoring&lt;/code&gt; que controla qu&amp;eacute; m&amp;eacute;trica aplican a los estimadores evaluados.</target>
        </trans-unit>
        <trans-unit id="855cd5c7a76f661266d80a6648a2f964caf6a19e" translate="yes" xml:space="preserve">
          <source>Model selection by evaluating various parameter settings can be seen as a way to use the labeled data to &amp;ldquo;train&amp;rdquo; the parameters of the grid.</source>
          <target state="translated">La selecci&amp;oacute;n del modelo mediante la evaluaci&amp;oacute;n de varios ajustes de par&amp;aacute;metros puede verse como una forma de utilizar los datos etiquetados para &quot;entrenar&quot; los par&amp;aacute;metros de la cuadr&amp;iacute;cula.</target>
        </trans-unit>
        <trans-unit id="89917070f2baaaaf3d7a4bc37b23fe9e19c05135" translate="yes" xml:space="preserve">
          <source>Model selection with Probabilistic PCA and Factor Analysis (FA)</source>
          <target state="translated">Selección de modelos con PCA Probabilístico y Análisis Factorial (FA)</target>
        </trans-unit>
        <trans-unit id="9c731d5ab6adf4a98df3f1383f23cf8f7eed3338" translate="yes" xml:space="preserve">
          <source>Model selection without nested CV uses the same data to tune model parameters and evaluate model performance. Information may thus &amp;ldquo;leak&amp;rdquo; into the model and overfit the data. The magnitude of this effect is primarily dependent on the size of the dataset and the stability of the model. See Cawley and Talbot &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; for an analysis of these issues.</source>
          <target state="translated">La selecci&amp;oacute;n del modelo sin CV anidado utiliza los mismos datos para ajustar los par&amp;aacute;metros del modelo y evaluar el rendimiento del modelo. Por tanto, la informaci&amp;oacute;n puede &quot;filtrarse&quot; en el modelo y ajustarse a los datos. La magnitud de este efecto depende principalmente del tama&amp;ntilde;o del conjunto de datos y la estabilidad del modelo. Ver Cawley y Talbot &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; para un an&amp;aacute;lisis de estos temas.</target>
        </trans-unit>
        <trans-unit id="74392d3518eac75d4c193fc75b5f4945cf9be3f9" translate="yes" xml:space="preserve">
          <source>Model selection: choosing estimators and their parameters</source>
          <target state="translated">Selección del modelo:elección de los estimadores y sus parámetros</target>
        </trans-unit>
        <trans-unit id="ad79a801df8015a66d5501cf36f7ffcd2a41ddf8" translate="yes" xml:space="preserve">
          <source>Model validation</source>
          <target state="translated">Model validation</target>
        </trans-unit>
        <trans-unit id="04c7998384d3cc95ade6e27711f83c95af26806e" translate="yes" xml:space="preserve">
          <source>Modeling species&amp;rsquo; geographic distributions is an important problem in conservation biology. In this example we model the geographic distribution of two south american mammals given past observations and 14 environmental variables. Since we have only positive examples (there are no unsuccessful observations), we cast this problem as a density estimation problem and use the &lt;code&gt;OneClassSVM&lt;/code&gt; provided by the package &lt;code&gt;sklearn.svm&lt;/code&gt; as our modeling tool. The dataset is provided by Phillips et. al. (2006). If available, the example uses &lt;a href=&quot;http://matplotlib.org/basemap&quot;&gt;basemap&lt;/a&gt; to plot the coast lines and national boundaries of South America.</source>
          <target state="translated">Modelar las distribuciones geogr&amp;aacute;ficas de las especies es un problema importante en la biolog&amp;iacute;a de la conservaci&amp;oacute;n. En este ejemplo modelamos la distribuci&amp;oacute;n geogr&amp;aacute;fica de dos mam&amp;iacute;feros sudamericanos dadas las observaciones anteriores y 14 variables ambientales. Dado que solo tenemos ejemplos positivos (no hay observaciones fallidas), planteamos este problema como un problema de estimaci&amp;oacute;n de densidad y usamos &lt;code&gt;OneClassSVM&lt;/code&gt; proporcionado por el paquete &lt;code&gt;sklearn.svm&lt;/code&gt; como nuestra herramienta de modelado. El conjunto de datos es proporcionado por Phillips et. Alabama. (2006). Si est&amp;aacute; disponible, el ejemplo utiliza un &lt;a href=&quot;http://matplotlib.org/basemap&quot;&gt;mapa base&lt;/a&gt; para trazar las l&amp;iacute;neas costeras y los l&amp;iacute;mites nacionales de Am&amp;eacute;rica del Sur.</target>
        </trans-unit>
        <trans-unit id="41be465b762359b2fa053c297894959404d2b4b5" translate="yes" xml:space="preserve">
          <source>Module &lt;a href=&quot;#module-sklearn.kernel_ridge&quot;&gt;&lt;code&gt;sklearn.kernel_ridge&lt;/code&gt;&lt;/a&gt; implements kernel ridge regression.</source>
          <target state="translated">El m&amp;oacute;dulo &lt;a href=&quot;#module-sklearn.kernel_ridge&quot;&gt; &lt;code&gt;sklearn.kernel_ridge&lt;/code&gt; &lt;/a&gt; implementa la regresi&amp;oacute;n de la cresta del kernel.</target>
        </trans-unit>
        <trans-unit id="7c19bb73223842069c348f5ce2be56f6bdc47336" translate="yes" xml:space="preserve">
          <source>Momentum for gradient descent update. Should be between 0 and 1. Only used when solver=&amp;rsquo;sgd&amp;rsquo;.</source>
          <target state="translated">Momento para la actualizaci&amp;oacute;n del descenso del gradiente. Debe estar entre 0 y 1. Solo se usa cuando solver = 'sgd'.</target>
        </trans-unit>
        <trans-unit id="afdb29f8a2a5c8088f948d58228ab92ec4b8dbc8" translate="yes" xml:space="preserve">
          <source>Moosmann, F. and Triggs, B. and Jurie, F. &amp;ldquo;Fast discriminative visual codebooks using randomized clustering forests&amp;rdquo; NIPS 2007</source>
          <target state="translated">Moosmann, F. y Triggs, B. y Jurie, F. &amp;ldquo;Libros de c&amp;oacute;digos visuales discriminativos r&amp;aacute;pidos que utilizan bosques agrupados aleatoriamente&amp;rdquo; NIPS 2007</target>
        </trans-unit>
        <trans-unit id="ea951c164724999b1e82491617fa7550c41c4ea4" translate="yes" xml:space="preserve">
          <source>More details can be found in the article &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.27.9072&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Bayesian Interpolation&lt;/a&gt; by MacKay, David J. C.</source>
          <target state="translated">Se pueden encontrar m&amp;aacute;s detalles en el art&amp;iacute;culo &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.27.9072&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Interpolaci&amp;oacute;n bayesiana&lt;/a&gt; de MacKay, David JC</target>
        </trans-unit>
        <trans-unit id="5be68ba5f49b8c23c2004cef7b8f1738816fd7ff" translate="yes" xml:space="preserve">
          <source>More details can be found in the documentation of &lt;a href=&quot;sgd&quot;&gt;SGD&lt;/a&gt;</source>
          <target state="translated">Se pueden encontrar m&amp;aacute;s detalles en la documentaci&amp;oacute;n de &lt;a href=&quot;sgd&quot;&gt;SGD&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="eeddded239db4ba79d40ed239189aa60eea25acb" translate="yes" xml:space="preserve">
          <source>More details on tools available for model selection can be found in the sections on &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;Cross-validation: evaluating estimator performance&lt;/a&gt; and &lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;Tuning the hyper-parameters of an estimator&lt;/a&gt;.</source>
          <target state="translated">Se pueden encontrar m&amp;aacute;s detalles sobre las herramientas disponibles para la selecci&amp;oacute;n de modelos en las secciones sobre &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;Validaci&amp;oacute;n cruzada: evaluaci&amp;oacute;n del rendimiento del estimador&lt;/a&gt; y &lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;Ajuste de los hiperpar&amp;aacute;metros de un estimador&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="d431b615f9733586de025b4f9872bf1a8badc9bd" translate="yes" xml:space="preserve">
          <source>More formally, the responsibility of a sample \(k\) to be the exemplar of sample \(i\) is given by:</source>
          <target state="translated">Más formalmente,la responsabilidad de que una muestra sea el ejemplo de la muestra está dada por:</target>
        </trans-unit>
        <trans-unit id="e5fcb8eb05185b2ae6a7561ecfd54e7e78d1825d" translate="yes" xml:space="preserve">
          <source>More formally, we define a core sample as being a sample in the dataset such that there exist &lt;code&gt;min_samples&lt;/code&gt; other samples within a distance of &lt;code&gt;eps&lt;/code&gt;, which are defined as &lt;em&gt;neighbors&lt;/em&gt; of the core sample. This tells us that the core sample is in a dense area of the vector space. A cluster is a set of core samples that can be built by recursively taking a core sample, finding all of its neighbors that are core samples, finding all of &lt;em&gt;their&lt;/em&gt; neighbors that are core samples, and so on. A cluster also has a set of non-core samples, which are samples that are neighbors of a core sample in the cluster but are not themselves core samples. Intuitively, these samples are on the fringes of a cluster.</source>
          <target state="translated">M&amp;aacute;s formalmente, definimos una muestra central como una muestra en el conjunto de datos, de modo que existen &lt;code&gt;min_samples&lt;/code&gt; otras muestras dentro de una distancia de &lt;code&gt;eps&lt;/code&gt; , que se definen como &lt;em&gt;vecinas&lt;/em&gt; de la muestra central. Esto nos dice que la muestra central est&amp;aacute; en un &amp;aacute;rea densa del espacio vectorial. Un cl&amp;uacute;ster es un conjunto de muestras centrales que se puede construir tomando de forma recursiva una muestra central, encontrando todos sus vecinos que son muestras centrales, encontrando todos &lt;em&gt;sus&lt;/em&gt; vecinos que son muestras centrales, y as&amp;iacute; sucesivamente. Un conglomerado tambi&amp;eacute;n tiene un conjunto de muestras no centrales, que son muestras vecinas de una muestra central del conglomerado, pero que no son en s&amp;iacute; mismas muestras centrales. Intuitivamente, estas muestras est&amp;aacute;n al margen de un grupo.</target>
        </trans-unit>
        <trans-unit id="39d3fe53d51c5218d78f036015830e2502c27f2b" translate="yes" xml:space="preserve">
          <source>More generally, when the accuracy of a classifier is too close to random, it probably means that something went wrong: features are not helpful, a hyperparameter is not correctly tuned, the classifier is suffering from class imbalance, etc&amp;hellip;</source>
          <target state="translated">De manera m&amp;aacute;s general, cuando la precisi&amp;oacute;n de un clasificador es demasiado cercana a la aleatoria, probablemente significa que algo sali&amp;oacute; mal: las caracter&amp;iacute;sticas no son &amp;uacute;tiles, un hiperpar&amp;aacute;metro no est&amp;aacute; ajustado correctamente, el clasificador sufre un desequilibrio de clases, etc.</target>
        </trans-unit>
        <trans-unit id="63b4a4241c78c35e803f9a1e6a808d1813f2fb30" translate="yes" xml:space="preserve">
          <source>More information can be found on the &lt;a href=&quot;http://docs.scipy.org/doc/numpy/user/install.html&quot;&gt;Scipy install page&lt;/a&gt; and in this &lt;a href=&quot;http://danielnouri.org/notes/2012/12/19/libblas-and-liblapack-issues-and-speed,-with-scipy-and-ubuntu/&quot;&gt;blog post&lt;/a&gt; from Daniel Nouri which has some nice step by step install instructions for Debian / Ubuntu.</source>
          <target state="translated">Puede encontrar m&amp;aacute;s informaci&amp;oacute;n en la &lt;a href=&quot;http://docs.scipy.org/doc/numpy/user/install.html&quot;&gt;p&amp;aacute;gina de instalaci&amp;oacute;n de Scipy&lt;/a&gt; y en esta &lt;a href=&quot;http://danielnouri.org/notes/2012/12/19/libblas-and-liblapack-issues-and-speed,-with-scipy-and-ubuntu/&quot;&gt;publicaci&amp;oacute;n de blog&lt;/a&gt; de Daniel Nouri, que tiene algunas instrucciones de instalaci&amp;oacute;n paso a paso para Debian / Ubuntu.</target>
        </trans-unit>
        <trans-unit id="5d4e98f0a8d8595ea60691c38a1427dece6499fb" translate="yes" xml:space="preserve">
          <source>More metadata from OpenML</source>
          <target state="translated">Más metadatos de OpenML</target>
        </trans-unit>
        <trans-unit id="12db8232292ca8d1cf35bc6b9168f2c8b63d47ca" translate="yes" xml:space="preserve">
          <source>More precisely its the expectation of the target response after accounting for the initial model; partial dependence plots do not include the &lt;code&gt;init&lt;/code&gt; model.</source>
          <target state="translated">M&amp;aacute;s precisamente, es la expectativa de la respuesta objetivo despu&amp;eacute;s de considerar el modelo inicial; las gr&amp;aacute;ficas de dependencia parcial no incluyen el modelo &lt;code&gt;init&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="73794f226fb348eb5da6ad63afeb16cb41727d95" translate="yes" xml:space="preserve">
          <source>More readable code, in particular since it avoids constructing list of arguments.</source>
          <target state="translated">Un código más legible,en particular porque evita la construcción de una lista de argumentos.</target>
        </trans-unit>
        <trans-unit id="a22dda2285328f04695cb396d42b64909dfc0d90" translate="yes" xml:space="preserve">
          <source>More specifically, for linear and quadratic discriminant analysis, \(P(X|y)\) is modeled as a multivariate Gaussian distribution with density:</source>
          <target state="translated">Más específicamente,para el análisis discriminante lineal y cuadrático,\ ~ P(X|y)\ ~ se modela como una distribución gaussiana multivariante con densidad:</target>
        </trans-unit>
        <trans-unit id="79ecb6d9275fdfeccdbd69d6aa3919b92952032e" translate="yes" xml:space="preserve">
          <source>Most commonly, disparities are set to \(\hat{d}_{ij} = b S_{ij}\).</source>
          <target state="translated">Lo más común es que las disparidades se fijen en \ ~-(\ ~-que {d}_{ij}=b S_{ij}).</target>
        </trans-unit>
        <trans-unit id="13411f05832555677b503d8db5e64b4930c99086" translate="yes" xml:space="preserve">
          <source>Most of the variance can be explained by a bell-shaped curve of width effective_rank: the low rank part of the singular values profile is:</source>
          <target state="translated">La mayor parte de la varianza puede explicarse por una curva en forma de campana de ancho effective_rank:la parte de bajo rango del perfil de valores singulares es:</target>
        </trans-unit>
        <trans-unit id="9a311c70d6fa85e99fb6533c84253a4d2c760cf7" translate="yes" xml:space="preserve">
          <source>Most scikit-learn models are usually pretty fast as they are implemented either with compiled Cython extensions or optimized computing libraries. On the other hand, in many real world applications the feature extraction process (i.e. turning raw data like database rows or network packets into numpy arrays) governs the overall prediction time. For example on the Reuters text classification task the whole preparation (reading and parsing SGML files, tokenizing the text and hashing it into a common vector space) is taking 100 to 500 times more time than the actual prediction code, depending on the chosen model.</source>
          <target state="translated">La mayoría de los modelos de aprendizaje de ciencias suelen ser bastante rápidos ya que se implementan con extensiones de Cython compiladas o librerías de computación optimizadas.Por otro lado,en muchas aplicaciones del mundo real el proceso de extracción de características (es decir,convertir datos en bruto como filas de bases de datos o paquetes de red en matrices numéricas)gobierna el tiempo de predicción global.Por ejemplo,en la tarea de clasificación de textos de Reuters,toda la preparación (lectura y análisis sintáctico de los archivos SGML,conversión del texto en fichas y su introducción en un espacio vectorial común)lleva entre 100 y 500 veces más tiempo que el código de predicción real,según el modelo elegido.</target>
        </trans-unit>
        <trans-unit id="1f57c7d2294fbf421c865e0ff805433c9e9164a6" translate="yes" xml:space="preserve">
          <source>Most treatments of LSA in the natural language processing (NLP) and information retrieval (IR) literature swap the axes of the matrix \(X\) so that it has shape &lt;code&gt;n_features&lt;/code&gt; &amp;times; &lt;code&gt;n_samples&lt;/code&gt;. We present LSA in a different way that matches the scikit-learn API better, but the singular values found are the same.</source>
          <target state="translated">La mayor&amp;iacute;a de los tratamientos de LSA en la literatura sobre procesamiento del lenguaje natural (NLP) y recuperaci&amp;oacute;n de informaci&amp;oacute;n (IR) intercambian los ejes de la matriz \ (X \) para que tenga forma &lt;code&gt;n_features&lt;/code&gt; &amp;times; &lt;code&gt;n_samples&lt;/code&gt; . Presentamos LSA de una manera diferente que coincide mejor con la API de scikit-learn, pero los valores singulares encontrados son los mismos.</target>
        </trans-unit>
        <trans-unit id="56ac69cc3d5e8e713d723baf0656a6eefef8f81b" translate="yes" xml:space="preserve">
          <source>Multi target classification</source>
          <target state="translated">Clasificación de objetivos múltiples</target>
        </trans-unit>
        <trans-unit id="b9b406b23aa7207ecf1f2aef41fc5c5ad0ba0c31" translate="yes" xml:space="preserve">
          <source>Multi target regression</source>
          <target state="translated">Regresión de objetivos múltiples</target>
        </trans-unit>
        <trans-unit id="332c064d1606c8de1a2522f9e4ee668dee56478e" translate="yes" xml:space="preserve">
          <source>Multi-class AdaBoosted Decision Trees</source>
          <target state="translated">Árboles de decisión multiclase AdaBoosted</target>
        </trans-unit>
        <trans-unit id="d384b7095ac166d1b587c1dafb0cadad28beb4c2" translate="yes" xml:space="preserve">
          <source>Multi-class targets.</source>
          <target state="translated">Objetivos multiclase.</target>
        </trans-unit>
        <trans-unit id="3243798e9c1a783043187bb0ea60ba4b8d0dfc62" translate="yes" xml:space="preserve">
          <source>Multi-class targets. An indicator matrix turns on multilabel classification.</source>
          <target state="translated">Objetivos multiclase.Una matriz de indicadores enciende la clasificación de multiples clases.</target>
        </trans-unit>
        <trans-unit id="552ba9a8fb8ef0b9cf8d9ea68e7f0c182ae9af5e" translate="yes" xml:space="preserve">
          <source>Multi-dimensional scaling</source>
          <target state="translated">Escalado multidimensional</target>
        </trans-unit>
        <trans-unit id="9815dac6e8971893d838904dc7e1cfe16372af94" translate="yes" xml:space="preserve">
          <source>Multi-layer Perceptron classifier.</source>
          <target state="translated">Clasificador de Perceptrón de varias capas.</target>
        </trans-unit>
        <trans-unit id="b994a134c1a31489af71fc772bdcadb38a217ddf" translate="yes" xml:space="preserve">
          <source>Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to [0, 1] or [-1, +1], or standardize it to have mean 0 and variance 1. Note that you must apply the &lt;em&gt;same&lt;/em&gt; scaling to the test set for meaningful results. You can use &lt;code&gt;StandardScaler&lt;/code&gt; for standardization.</source>
          <target state="translated">Perceptron multicapa es sensible al escalado de caracter&amp;iacute;sticas, por lo que se recomienda encarecidamente escalar sus datos. Por ejemplo, escale cada atributo en el vector de entrada X a [0, 1] o [-1, +1], o estandar&amp;iacute;celo para tener una media 0 y una varianza 1. Tenga en cuenta que debe aplicar la &lt;em&gt;misma&lt;/em&gt; escala al conjunto de prueba para resultados significativos. Puede utilizar &lt;code&gt;StandardScaler&lt;/code&gt; para la estandarizaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="8b22895cdf3840f5acfe1ac32cbc8961e8fd336a" translate="yes" xml:space="preserve">
          <source>Multi-layer Perceptron regressor.</source>
          <target state="translated">Regresor Perceptrón de varias capas.</target>
        </trans-unit>
        <trans-unit id="dc72474a07afc8bb8057ac9bf6d8fbc65e56a63e" translate="yes" xml:space="preserve">
          <source>Multi-output Decision Tree Regression</source>
          <target state="translated">Regresión del árbol de decisión de múltiples salidas</target>
        </trans-unit>
        <trans-unit id="2627f8f7a5d9294ea8dcfe47a04508977edd8f7c" translate="yes" xml:space="preserve">
          <source>Multi-output targets predicted across multiple predictors. Note: Separate models are generated for each predictor.</source>
          <target state="translated">Objetivos de salida múltiples predichos a través de múltiples predictores.Nota:Se generan modelos separados para cada predictor.</target>
        </trans-unit>
        <trans-unit id="4da1e42d60732d934b60458ac859ed1253e6bfbd" translate="yes" xml:space="preserve">
          <source>Multi-output targets.</source>
          <target state="translated">Objetivos de salida múltiple.</target>
        </trans-unit>
        <trans-unit id="d25d7d780166f0481648cccd463a78a5e417f6f3" translate="yes" xml:space="preserve">
          <source>Multi-output targets. An indicator matrix turns on multilabel estimation.</source>
          <target state="translated">Objetivos de salida múltiple.Una matriz de indicadores activa la estimación multietapa.</target>
        </trans-unit>
        <trans-unit id="775030d60513b2f729789206b06d021b6661e16d" translate="yes" xml:space="preserve">
          <source>Multi-task ElasticNet model trained with L1/L2 mixed-norm as regularizer</source>
          <target state="translated">Modelo de ElasticNet multitarea entrenado con norma mixta L1/L2 como regularizador</target>
        </trans-unit>
        <trans-unit id="7259143bf01ac8062e2b5725644f1e005f808315" translate="yes" xml:space="preserve">
          <source>Multi-task L1/L2 ElasticNet with built-in cross-validation.</source>
          <target state="translated">Multitarea L1/L2 ElasticNet con validación cruzada incorporada.</target>
        </trans-unit>
        <trans-unit id="5c1ad40e838b03e514631adae1736168414d6605" translate="yes" xml:space="preserve">
          <source>Multi-task L1/L2 Lasso with built-in cross-validation</source>
          <target state="translated">Lazo L1/L2 multitarea con validación cruzada incorporada</target>
        </trans-unit>
        <trans-unit id="a743aa48cf046a15087b0f4886f436159c359dd5" translate="yes" xml:space="preserve">
          <source>Multi-task L1/L2 Lasso with built-in cross-validation.</source>
          <target state="translated">Lazo L1/L2 multitarea con validación cruzada incorporada.</target>
        </trans-unit>
        <trans-unit id="6377873684d0ac47f9792cf0130c074e6b5d5c8f" translate="yes" xml:space="preserve">
          <source>Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer</source>
          <target state="translated">Un modelo de lazo multitarea entrenado con una norma mixta L1/L2 como regularizador</target>
        </trans-unit>
        <trans-unit id="669e809a0e7044a9302d0da3188c44feddafe180" translate="yes" xml:space="preserve">
          <source>Multiclass and multilabel classification strategies</source>
          <target state="translated">Estrategias de clasificación multiclase y multietiqueta</target>
        </trans-unit>
        <trans-unit id="957cc5ae23e389ffa9c767fc16d7ac37036b0153" translate="yes" xml:space="preserve">
          <source>Multiclass classification</source>
          <target state="translated">Clasificación multiclase</target>
        </trans-unit>
        <trans-unit id="f43fb647f0e5eccf5a3760b6eafe5e21b79a50a6" translate="yes" xml:space="preserve">
          <source>Multiclass probability estimates are derived from binary (one-vs.-rest) estimates by simple normalization, as recommended by Zadrozny and Elkan.</source>
          <target state="translated">Las estimaciones de probabilidad de múltiples clases se derivan de las estimaciones binarias (uno-vs.-descanso)por simple normalización,como lo recomiendan Zadrozny y Elkan.</target>
        </trans-unit>
        <trans-unit id="3debc5753cd55840fa65a540929e237591ad2faf" translate="yes" xml:space="preserve">
          <source>Multiclass settings</source>
          <target state="translated">Ajustes de multiclase</target>
        </trans-unit>
        <trans-unit id="e3f8736465f26b4a50bfa9739f8adbcfb24ccc56" translate="yes" xml:space="preserve">
          <source>Multiclass sparse logisitic regression on newgroups20</source>
          <target state="translated">Regresión logística de multiclase dispersa en los nuevos grupos20</target>
        </trans-unit>
        <trans-unit id="38a70920d0cd2001f4ef8f9ee41dfa6b122f018c" translate="yes" xml:space="preserve">
          <source>Multiclass spectral clustering, 2003 Stella X. Yu, Jianbo Shi &lt;a href=&quot;http://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf&quot;&gt;http://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf&lt;/a&gt;</source>
          <target state="translated">Agrupaci&amp;oacute;n espectral multiclase, 2003 Stella X. Yu, Jianbo Shi &lt;a href=&quot;http://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf&quot;&gt;http://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c5d0b14c4e8dd95e44e1cd37847a8b6674049750" translate="yes" xml:space="preserve">
          <source>Multiclass vs. multilabel fitting</source>
          <target state="translated">Adaptación multiclase vs.multietiqueta</target>
        </trans-unit>
        <trans-unit id="dbc4079d7d6495ef3cfc4fdaba01141075b60d89" translate="yes" xml:space="preserve">
          <source>Multidimensional scaling</source>
          <target state="translated">Escalado multidimensional</target>
        </trans-unit>
        <trans-unit id="7c33b81ffc3ca04c62af4f5074ba33e510028ebd" translate="yes" xml:space="preserve">
          <source>Multilabel classification</source>
          <target state="translated">Clasificación de la multi-etiqueta</target>
        </trans-unit>
        <trans-unit id="c720ba81272f13af125e464e56bd5648c8146ada" translate="yes" xml:space="preserve">
          <source>Multilabel ranking metrics</source>
          <target state="translated">Métrica de clasificación multi-etiqueta</target>
        </trans-unit>
        <trans-unit id="b6031d58e46d313eca93045d9598faea168256f9" translate="yes" xml:space="preserve">
          <source>Multimetric scoring can either be specified as a list of strings of predefined scores names or a dict mapping the scorer name to the scorer function and/or the predefined scorer name(s). See &lt;a href=&quot;model_evaluation#multimetric-scoring&quot;&gt;Using multiple metric evaluation&lt;/a&gt; for more details.</source>
          <target state="translated">La puntuaci&amp;oacute;n multim&amp;eacute;trica puede especificarse como una lista de cadenas de nombres de puntuaciones predefinidos o un dict que asigna el nombre del anotador a la funci&amp;oacute;n del anotador y / o el nombre (s) del anotador predefinido. Consulte &lt;a href=&quot;model_evaluation#multimetric-scoring&quot;&gt;Uso de la evaluaci&amp;oacute;n&lt;/a&gt; de varias m&amp;eacute;tricas para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="71e5ed6f7fb13f64a7d1e47fd6ffef12dfd5580e" translate="yes" xml:space="preserve">
          <source>Multinomial + L1 penalty</source>
          <target state="translated">Multinomio+L1 de penalización</target>
        </trans-unit>
        <trans-unit id="82d79c421161a2e0a31300a79127c9804ae62ed5" translate="yes" xml:space="preserve">
          <source>Multinomial + L2 penalty</source>
          <target state="translated">Multinomio+L2 de penalización</target>
        </trans-unit>
        <trans-unit id="efccef2252a812759badf849dd9e2acd4cd7eb95" translate="yes" xml:space="preserve">
          <source>Multinomial deviance (&lt;code&gt;'deviance'&lt;/code&gt;): The negative multinomial log-likelihood loss function for multi-class classification with &lt;code&gt;n_classes&lt;/code&gt; mutually exclusive classes. It provides probability estimates. The initial model is given by the prior probability of each class. At each iteration &lt;code&gt;n_classes&lt;/code&gt; regression trees have to be constructed which makes GBRT rather inefficient for data sets with a large number of classes.</source>
          <target state="translated">Desviaci&amp;oacute;n multinomial ( &lt;code&gt;'deviance'&lt;/code&gt; ): La funci&amp;oacute;n de p&amp;eacute;rdida de probabilidad logar&amp;iacute;tmica multinomial negativa para la clasificaci&amp;oacute;n de clases m&amp;uacute;ltiples con &lt;code&gt;n_classes&lt;/code&gt; clases mutuamente excluyentes. Proporciona estimaciones de probabilidad. El modelo inicial viene dado por la probabilidad previa de cada clase. En cada iteraci&amp;oacute;n , se deben construir &lt;code&gt;n_classes&lt;/code&gt; &amp;aacute;rboles de regresi&amp;oacute;n, lo que hace que GBRT sea bastante ineficiente para conjuntos de datos con una gran cantidad de clases.</target>
        </trans-unit>
        <trans-unit id="313293589005fec34a4137f7e7a462e44753a91e" translate="yes" xml:space="preserve">
          <source>Multioutput classification support can be added to any classifier with &lt;code&gt;MultiOutputClassifier&lt;/code&gt;. This strategy consists of fitting one classifier per target. This allows multiple target variable classifications. The purpose of this class is to extend estimators to be able to estimate a series of target functions (f1,f2,f3&amp;hellip;,fn) that are trained on a single X predictor matrix to predict a series of responses (y1,y2,y3&amp;hellip;,yn).</source>
          <target state="translated">El soporte de clasificaci&amp;oacute;n de &lt;code&gt;MultiOutputClassifier&lt;/code&gt; se puede agregar a cualquier clasificador con MultiOutputClassifier . Esta estrategia consiste en ajustar un clasificador por objetivo. Esto permite m&amp;uacute;ltiples clasificaciones de variables objetivo. El prop&amp;oacute;sito de esta clase es extender los estimadores para poder estimar una serie de funciones objetivo (f1, f2, f3&amp;hellip;, fn) que se entrenan en una &amp;uacute;nica matriz de predictores X para predecir una serie de respuestas (y1, y2, y3 &amp;hellip;, Yn).</target>
        </trans-unit>
        <trans-unit id="086b68ade408f93caaac80f71e1eabb4cc44f3fd" translate="yes" xml:space="preserve">
          <source>Multioutput regression support can be added to any regressor with &lt;code&gt;MultiOutputRegressor&lt;/code&gt;. This strategy consists of fitting one regressor per target. Since each target is represented by exactly one regressor it is possible to gain knowledge about the target by inspecting its corresponding regressor. As &lt;code&gt;MultiOutputRegressor&lt;/code&gt; fits one regressor per target it can not take advantage of correlations between targets.</source>
          <target state="translated">Se puede agregar soporte de regresi&amp;oacute;n de &lt;code&gt;MultiOutputRegressor&lt;/code&gt; a cualquier regresor con MultiOutputRegressor . Esta estrategia consiste en ajustar un regresor por objetivo. Dado que cada objetivo est&amp;aacute; representado por exactamente un regresor, es posible obtener conocimiento sobre el objetivo inspeccionando su regresor correspondiente. Como &lt;code&gt;MultiOutputRegressor&lt;/code&gt; se ajusta a un regresor por objetivo, no puede aprovechar las correlaciones entre objetivos.</target>
        </trans-unit>
        <trans-unit id="96e252b1f2ecf6cba5d585af259eddb308663e2e" translate="yes" xml:space="preserve">
          <source>Multiple metric evaluation using &lt;code&gt;cross_validate&lt;/code&gt; (please refer the &lt;code&gt;scoring&lt;/code&gt; parameter doc for more information)</source>
          <target state="translated">Evaluaci&amp;oacute;n de varias m&amp;eacute;tricas mediante &lt;code&gt;cross_validate&lt;/code&gt; (consulte el documento del par&amp;aacute;metro de &lt;code&gt;scoring&lt;/code&gt; para obtener m&amp;aacute;s informaci&amp;oacute;n)</target>
        </trans-unit>
        <trans-unit id="629b6c06ee9b92eec539c00c0d5b033d1b11a26d" translate="yes" xml:space="preserve">
          <source>Multiple metric parameter search can be done by setting the &lt;code&gt;scoring&lt;/code&gt; parameter to a list of metric scorer names or a dict mapping the scorer names to the scorer callables.</source>
          <target state="translated">Se puede realizar una b&amp;uacute;squeda de par&amp;aacute;metros de m&amp;eacute;tricas m&amp;uacute;ltiples estableciendo el par&amp;aacute;metro de &lt;code&gt;scoring&lt;/code&gt; en una lista de nombres de anotadores de m&amp;eacute;tricas o un dict que mapee los nombres de los anotadores a los anotadores callables.</target>
        </trans-unit>
        <trans-unit id="85ae0fa16a20d62aa04d6b821cea2aa9547567a2" translate="yes" xml:space="preserve">
          <source>Multiplicative weights for features per transformer. Keys are transformer names, values the weights.</source>
          <target state="translated">Pesos multiplicadores para las características por transformador.Las claves son los nombres de los transformadores,los valores de los pesos.</target>
        </trans-unit>
        <trans-unit id="0634d761605b2ffdac7cc3b47cb937d2911bb7fc" translate="yes" xml:space="preserve">
          <source>Multiplicative weights for features per transformer. The output of the transformer is multiplied by these weights. Keys are transformer names, values the weights.</source>
          <target state="translated">Pesos multiplicadores para las características por transformador.La salida del transformador se multiplica por estos pesos.Las claves son los nombres de los transformadores,los valores de los pesos.</target>
        </trans-unit>
        <trans-unit id="7f4f1f6c0e0110908215d6d402a5fd0376794171" translate="yes" xml:space="preserve">
          <source>Multiply features by the specified value. If None, then features are scaled by a random value drawn in [1, 100]. Note that scaling happens after shifting.</source>
          <target state="translated">Multiplica las características por el valor especificado.Si no hay ninguno,entonces los rasgos se escalan por un valor aleatorio dibujado en [1,100].Tenga en cuenta que la escalada se produce después del desplazamiento.</target>
        </trans-unit>
        <trans-unit id="773db00cec71fc706de69e832dff6b23a68d6b97" translate="yes" xml:space="preserve">
          <source>Multithreaded BLAS libraries sometimes conflict with Python&amp;rsquo;s &lt;code&gt;multiprocessing&lt;/code&gt; module, which is used by e.g. &lt;code&gt;GridSearchCV&lt;/code&gt; and most other estimators that take an &lt;code&gt;n_jobs&lt;/code&gt; argument (with the exception of &lt;code&gt;SGDClassifier&lt;/code&gt;, &lt;code&gt;SGDRegressor&lt;/code&gt;, &lt;code&gt;Perceptron&lt;/code&gt;, &lt;code&gt;PassiveAggressiveClassifier&lt;/code&gt; and tree-based methods such as random forests). This is true of Apple&amp;rsquo;s Accelerate and OpenBLAS when built with OpenMP support.</source>
          <target state="translated">Las bibliotecas BLAS multiproceso a veces entran en conflicto con el m&amp;oacute;dulo de &lt;code&gt;multiprocessing&lt;/code&gt; de Python , que es utilizado por, por ejemplo, &lt;code&gt;GridSearchCV&lt;/code&gt; y la mayor&amp;iacute;a de los otros estimadores que toman un argumento &lt;code&gt;n_jobs&lt;/code&gt; (con la excepci&amp;oacute;n de &lt;code&gt;SGDClassifier&lt;/code&gt; , &lt;code&gt;SGDRegressor&lt;/code&gt; , &lt;code&gt;Perceptron&lt;/code&gt; , &lt;code&gt;PassiveAggressiveClassifier&lt;/code&gt; y m&amp;eacute;todos basados ​​en &amp;aacute;rboles como bosques aleatorios). Esto es cierto para Accelerate y OpenBLAS de Apple cuando se construyen con soporte OpenMP.</target>
        </trans-unit>
        <trans-unit id="425dc1fa519b0f6261993bae28e1ad51c131bb66" translate="yes" xml:space="preserve">
          <source>Must be provided at the first call to partial_fit, can be omitted in subsequent calls.</source>
          <target state="translated">Debe proporcionarse en la primera llamada a partial_fit,puede omitirse en llamadas posteriores.</target>
        </trans-unit>
        <trans-unit id="b6845c300d4f945b800f2e50de745703cc5cc891" translate="yes" xml:space="preserve">
          <source>Must fulfill the input assumptions of the underlying estimator.</source>
          <target state="translated">Debe cumplir con los supuestos de entrada del estimador subyacente.</target>
        </trans-unit>
        <trans-unit id="214188886e4a84a8788bdd82b6f8744f5146fead" translate="yes" xml:space="preserve">
          <source>Mutual Information (not adjusted for chance)</source>
          <target state="translated">Información mutua (no ajustada al azar)</target>
        </trans-unit>
        <trans-unit id="16b7cc0e7a5234ba809ed1e09a3a8960dff39693" translate="yes" xml:space="preserve">
          <source>Mutual Information between two clusterings.</source>
          <target state="translated">Información mutua entre dos agrupaciones.</target>
        </trans-unit>
        <trans-unit id="81e08bee8a8968c08bd07aed8cef44d9fb7a13f3" translate="yes" xml:space="preserve">
          <source>Mutual information (MI) &lt;a href=&quot;#r37d39d7589e2-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.</source>
          <target state="translated">La informaci&amp;oacute;n mutua (MI) &lt;a href=&quot;#r37d39d7589e2-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; entre dos variables aleatorias es un valor no negativo, que mide la dependencia entre las variables. Es igual a cero si y solo si dos variables aleatorias son independientes y los valores m&amp;aacute;s altos significan una mayor dependencia.</target>
        </trans-unit>
        <trans-unit id="92d0e5dc6672a19ad8c5b9523b6a6d1a9b82c89e" translate="yes" xml:space="preserve">
          <source>Mutual information (MI) &lt;a href=&quot;#r50b872b699c4-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.</source>
          <target state="translated">La informaci&amp;oacute;n mutua (MI) &lt;a href=&quot;#r50b872b699c4-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; entre dos variables aleatorias es un valor no negativo, que mide la dependencia entre las variables. Es igual a cero si y solo si dos variables aleatorias son independientes y los valores m&amp;aacute;s altos significan una mayor dependencia.</target>
        </trans-unit>
        <trans-unit id="4276bd70be44db9c6fb9548906a97ab826aba297" translate="yes" xml:space="preserve">
          <source>Mutual information between features and the target.</source>
          <target state="translated">Información mutua entre las características y el objetivo.</target>
        </trans-unit>
        <trans-unit id="33ca9360bf5453bcb4bf9aed03e658f161f23932" translate="yes" xml:space="preserve">
          <source>Mutual information for a continuous target.</source>
          <target state="translated">Información mutua para un objetivo continuo.</target>
        </trans-unit>
        <trans-unit id="aa199ad103c044c23c4e2e0edbe572bad088827c" translate="yes" xml:space="preserve">
          <source>Mutual information for a contnuous target.</source>
          <target state="translated">Información mutua para un objetivo contnuo.</target>
        </trans-unit>
        <trans-unit id="ef9610a089a978dd0d661be292e2bde712e413d1" translate="yes" xml:space="preserve">
          <source>Mutual information for a discrete target.</source>
          <target state="translated">Información mutua para un objetivo discreto.</target>
        </trans-unit>
        <trans-unit id="2555b04ef28112b324874c1cc2f3bf2b5b5c384e" translate="yes" xml:space="preserve">
          <source>Mutual information, a non-negative value</source>
          <target state="translated">La información mutua,un valor no negativo</target>
        </trans-unit>
        <trans-unit id="b51a60734da64be0e618bacbea2865a8a7dcd669" translate="yes" xml:space="preserve">
          <source>N</source>
          <target state="translated">N</target>
        </trans-unit>
        <trans-unit id="4e1221dedd7ee34eb6931a44dc15d9a84ca69a81" translate="yes" xml:space="preserve">
          <source>N : number of dimensions</source>
          <target state="translated">N:número de dimensiones</target>
        </trans-unit>
        <trans-unit id="8daf5ce04352d841160e980446540ca50cce58e4" translate="yes" xml:space="preserve">
          <source>N-grams to the rescue! Instead of building a simple collection of unigrams (n=1), one might prefer a collection of bigrams (n=2), where occurrences of pairs of consecutive words are counted.</source>
          <target state="translated">¡N-grams al rescate! En lugar de construir una simple colección de unigramas (n=1),uno podría preferir una colección de bigrams (n=2),donde se cuentan las ocurrencias de pares de palabras consecutivas.</target>
        </trans-unit>
        <trans-unit id="235c4fdc295d941494351e73dad0edc432affd04" translate="yes" xml:space="preserve">
          <source>NFF : number of dims in which both values are False</source>
          <target state="translated">NFF:número de dimisiones en las que ambos valores son falsos</target>
        </trans-unit>
        <trans-unit id="f242d8e1cdbbc8cb628621d8d57f10327047707d" translate="yes" xml:space="preserve">
          <source>NFT : number of dims in which the first value is False, second is True</source>
          <target state="translated">NFT:número de puntos débiles en los que el primer valor es falso,el segundo es verdadero.</target>
        </trans-unit>
        <trans-unit id="ced12bb5137dbf26fd788e77cae54623cdb8b2e8" translate="yes" xml:space="preserve">
          <source>NMF is best used with the &lt;code&gt;fit_transform&lt;/code&gt; method, which returns the matrix W. The matrix H is stored into the fitted model in the &lt;code&gt;components_&lt;/code&gt; attribute; the method &lt;code&gt;transform&lt;/code&gt; will decompose a new matrix X_new based on these stored components:</source>
          <target state="translated">NMF se utiliza mejor con el m&amp;eacute;todo &lt;code&gt;fit_transform&lt;/code&gt; , que devuelve la matriz W. La matriz H se almacena en el modelo ajustado en el atributo &lt;code&gt;components_&lt;/code&gt; ; la &lt;code&gt;transform&lt;/code&gt; aci&amp;oacute;n del m&amp;eacute;todo descompondr&amp;aacute; una nueva matriz X_new basada en estos componentes almacenados:</target>
        </trans-unit>
        <trans-unit id="9546ef450bf032f2a099e2b8894066e314108bcc" translate="yes" xml:space="preserve">
          <source>NMI and MI are not adjusted against chance.</source>
          <target state="translated">El NMI y el MI no se ajustan al azar.</target>
        </trans-unit>
        <trans-unit id="ec8506cc20e415f16975d43b2c6e163b63b7c223" translate="yes" xml:space="preserve">
          <source>NNEQ / (NNEQ + 0.5 * NTT)</source>
          <target state="translated">NNEQ/(NNEQ+0.5*NTT)</target>
        </trans-unit>
        <trans-unit id="64142d93685b184d0f4668dd2d38de67d364504a" translate="yes" xml:space="preserve">
          <source>NNEQ / (NTT + NNZ)</source>
          <target state="translated">NNEQ/(NTT+NNZ)</target>
        </trans-unit>
        <trans-unit id="9e2ca45598fef4852f298770d7c7037071a195c1" translate="yes" xml:space="preserve">
          <source>NNEQ / N</source>
          <target state="translated">NNEQ/N</target>
        </trans-unit>
        <trans-unit id="bd22d441438dd8339012b8925c55919834498020" translate="yes" xml:space="preserve">
          <source>NNEQ / NNZ</source>
          <target state="translated">NNEQ/NNZ</target>
        </trans-unit>
        <trans-unit id="a4e22ff89a7f8daef1da10b2c311e81f8eb57054" translate="yes" xml:space="preserve">
          <source>NNEQ : number of non-equal dimensions, NNEQ = NTF + NFT</source>
          <target state="translated">NNEQ:número de dimensiones no iguales,NNEQ=NTF+NFT</target>
        </trans-unit>
        <trans-unit id="80bfd3623c0e507836f83286688a2ee41b18b00e" translate="yes" xml:space="preserve">
          <source>NNZ / N</source>
          <target state="translated">NNZ/N</target>
        </trans-unit>
        <trans-unit id="93209a2edd337e6dc4e7c870a3c72537cea28fdf" translate="yes" xml:space="preserve">
          <source>NNZ : number of nonzero dimensions, NNZ = NTF + NFT + NTT</source>
          <target state="translated">NNZ:número de dimensiones no nulas,NNZ=NTF+NFT+NTT</target>
        </trans-unit>
        <trans-unit id="a8ad860c15810cce0e7beac1c91da3ab2cb22c47" translate="yes" xml:space="preserve">
          <source>NOTE</source>
          <target state="translated">NOTE</target>
        </trans-unit>
        <trans-unit id="b81cbdff62e50c72d48e4feea8a9ed88bea18bef" translate="yes" xml:space="preserve">
          <source>NOTE that when using custom scorers, each scorer should return a single value. Metric functions returning a list/array of values can be wrapped into multiple scorers that return one value each.</source>
          <target state="translated">NOTA:cuando se usan marcadores personalizados,cada marcador debe devolver un único valor.Las funciones métricas que devuelven una lista/matriz de valores pueden ser envueltas en múltiples anotadores que devuelven un valor cada uno.</target>
        </trans-unit>
        <trans-unit id="9764dfb854390dc404102ac64200b55e363e83df" translate="yes" xml:space="preserve">
          <source>NOX nitric oxides concentration (parts per 10 million)</source>
          <target state="translated">Concentración de óxidos nítricos NOX (partes por 10 millones)</target>
        </trans-unit>
        <trans-unit id="99542bc2231d38286b9a1dbe4685e8690203b845" translate="yes" xml:space="preserve">
          <source>NTF : number of dims in which the first value is True, second is False</source>
          <target state="translated">NTF:número de dimesiones en las que el primer valor es Verdadero,el segundo es Falso</target>
        </trans-unit>
        <trans-unit id="d7aff2fba38c5d47fc1d509779237efeccf9cd66" translate="yes" xml:space="preserve">
          <source>NTT : number of dims in which both values are True</source>
          <target state="translated">NTT:número de dimisiones en las que ambos valores son verdaderos</target>
        </trans-unit>
        <trans-unit id="6e2518fe965a665a40ec6f1bf71cbacd3d7014df" translate="yes" xml:space="preserve">
          <source>NaNs are ignored in the algorithm.</source>
          <target state="translated">Las NaNs son ignoradas en el algoritmo.</target>
        </trans-unit>
        <trans-unit id="7b2cc2bc3bfa4ab2fba6e73cce899558220dd79a" translate="yes" xml:space="preserve">
          <source>NaNs are treated as missing values: disregarded in fit, and maintained in transform.</source>
          <target state="translated">Los NaNs son tratados como valores faltantes:desestimados en el ajuste,y mantenidos en la transformación.</target>
        </trans-unit>
        <trans-unit id="d13d7452647efb26ab0d2b1a3596526a7f4ca5d6" translate="yes" xml:space="preserve">
          <source>NaNs are treated as missing values: disregarded to compute the statistics, and maintained during the data transformation.</source>
          <target state="translated">Los NaNs se tratan como valores perdidos:no se tienen en cuenta para calcular las estadísticas,y se mantienen durante la transformación de los datos.</target>
        </trans-unit>
        <trans-unit id="80d8f13b4e334c4342adf34b360ad118e5e25aa3" translate="yes" xml:space="preserve">
          <source>Naive Bayes classifier for multinomial models</source>
          <target state="translated">El ingenuo clasificador Bayes para modelos multinomiales</target>
        </trans-unit>
        <trans-unit id="92990e6c1a566f0d055f974e25026ec604b9ccd9" translate="yes" xml:space="preserve">
          <source>Naive Bayes classifier for multivariate Bernoulli models.</source>
          <target state="translated">Clasificador Bayes ingenuo para los modelos multivariantes de Bernoulli.</target>
        </trans-unit>
        <trans-unit id="c95f9acb4985f23ad6962fd01ae91dec549e7273" translate="yes" xml:space="preserve">
          <source>Naive Bayes learners and classifiers can be extremely fast compared to more sophisticated methods. The decoupling of the class conditional feature distributions means that each distribution can be independently estimated as a one dimensional distribution. This in turn helps to alleviate problems stemming from the curse of dimensionality.</source>
          <target state="translated">Los ingenuos aprendices y clasificadores de Bayes pueden ser extremadamente rápidos en comparación con los métodos más sofisticados.La disociación de las distribuciones de características condicionales de la clase significa que cada distribución puede ser estimada independientemente como una distribución unidimensional.Esto a su vez ayuda a aliviar los problemas derivados de la maldición de la dimensionalidad.</target>
        </trans-unit>
        <trans-unit id="bb7ceea48fd3728ed03cf0ba21b4839b323fc974" translate="yes" xml:space="preserve">
          <source>Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes&amp;rsquo; theorem with the &amp;ldquo;naive&amp;rdquo; assumption of conditional independence between every pair of features given the value of the class variable. Bayes&amp;rsquo; theorem states the following relationship, given class variable \(y\) and dependent feature vector \(x_1\) through \(x_n\), :</source>
          <target state="translated">Los m&amp;eacute;todos ingenuos de Bayes son un conjunto de algoritmos de aprendizaje supervisado basados ​​en la aplicaci&amp;oacute;n del teorema de Bayes con la suposici&amp;oacute;n &amp;ldquo;ingenua&amp;rdquo; de independencia condicional entre cada par de caracter&amp;iacute;sticas dado el valor de la variable de clase. El teorema de Bayes establece la siguiente relaci&amp;oacute;n, dada la variable de clase \ (y \) y el vector de caracter&amp;iacute;sticas dependientes \ (x_1 \) a \ (x_n \),:</target>
        </trans-unit>
        <trans-unit id="f65600325bc091b7b293639582ad70691e2ac960" translate="yes" xml:space="preserve">
          <source>Naive Bayes models can be used to tackle large scale classification problems for which the full training set might not fit in memory. To handle this case, &lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt;&lt;code&gt;MultinomialNB&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.naive_bayes.bernoullinb#sklearn.naive_bayes.BernoulliNB&quot;&gt;&lt;code&gt;BernoulliNB&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt;&lt;code&gt;GaussianNB&lt;/code&gt;&lt;/a&gt; expose a &lt;code&gt;partial_fit&lt;/code&gt; method that can be used incrementally as done with other classifiers as demonstrated in &lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;Out-of-core classification of text documents&lt;/a&gt;. All naive Bayes classifiers support sample weighting.</source>
          <target state="translated">Los modelos Naive Bayes se pueden utilizar para abordar problemas de clasificaci&amp;oacute;n a gran escala para los que el conjunto de entrenamiento completo podr&amp;iacute;a no caber en la memoria. Para manejar este caso, &lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt; &lt;code&gt;MultinomialNB&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.naive_bayes.bernoullinb#sklearn.naive_bayes.BernoulliNB&quot;&gt; &lt;code&gt;BernoulliNB&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt; &lt;code&gt;GaussianNB&lt;/code&gt; &lt;/a&gt; exponen un m&amp;eacute;todo de &lt;code&gt;partial_fit&lt;/code&gt; que se puede usar de forma incremental como se hace con otros clasificadores, como se demuestra en Clasificaci&amp;oacute;n &lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;fuera del n&amp;uacute;cleo de documentos de texto&lt;/a&gt; . Todos los clasificadores de Bayes ingenuos admiten la ponderaci&amp;oacute;n de muestras.</target>
        </trans-unit>
        <trans-unit id="7f39a3bd9bee33098b86f18fcaf23fc1b1f211a0" translate="yes" xml:space="preserve">
          <source>Name of dataset</source>
          <target state="translated">Nombre del conjunto de datos</target>
        </trans-unit>
        <trans-unit id="325b56c17b8389991fec124de840a19f36bc1993" translate="yes" xml:space="preserve">
          <source>Name of each feature; feature_names[i] holds the name of the feature with index i.</source>
          <target state="translated">Nombre de cada característica;feature_names[i]contiene el nombre de la característica con el índice i.</target>
        </trans-unit>
        <trans-unit id="1d63bfd9357f039d867c5652a85ab61996c87f94" translate="yes" xml:space="preserve">
          <source>Name of the data set on mldata.org, e.g.: &amp;ldquo;leukemia&amp;rdquo;, &amp;ldquo;Whistler Daily Snowfall&amp;rdquo;, etc. The raw name is automatically converted to a mldata.org URL .</source>
          <target state="translated">Nombre del conjunto de datos en mldata.org, por ejemplo: &quot;leucemia&quot;, &quot;Whistler Daily Snowfall&quot;, etc. El nombre sin formato se convierte autom&amp;aacute;ticamente en una URL de mldata.org.</target>
        </trans-unit>
        <trans-unit id="866f4401ef93cfed3b044fff6753dc1e913659b2" translate="yes" xml:space="preserve">
          <source>Name of the output activation function.</source>
          <target state="translated">Nombre de la función de activación de la salida.</target>
        </trans-unit>
        <trans-unit id="5a3a86d298c7e4314e724bb2623d8c6979ee2b6e" translate="yes" xml:space="preserve">
          <source>Name of the parameter that will be varied.</source>
          <target state="translated">Nombre del parámetro que será variado.</target>
        </trans-unit>
        <trans-unit id="ce3ec81584fa2d87df12f144e2480deecc5a975a" translate="yes" xml:space="preserve">
          <source>Name or index of the column containing the data.</source>
          <target state="translated">Nombre o índice de la columna que contiene los datos.</target>
        </trans-unit>
        <trans-unit id="0ae5e537b1c061ee0b3ccea7c63ace2088ca02dd" translate="yes" xml:space="preserve">
          <source>Name or index of the column containing the target values.</source>
          <target state="translated">Nombre o índice de la columna que contiene los valores objetivo.</target>
        </trans-unit>
        <trans-unit id="3170e49e906772d2e2d83c510613a736bad3f541" translate="yes" xml:space="preserve">
          <source>Named features not encountered during fit or fit_transform will be silently ignored.</source>
          <target state="translated">Las características nombradas no encontradas durante fit o fit_transform serán silenciosamente ignoradas.</target>
        </trans-unit>
        <trans-unit id="dd3283d9f71127c2e2cb8ea6f07a41ece4a049ce" translate="yes" xml:space="preserve">
          <source>Names of each of the features.</source>
          <target state="translated">Nombres de cada una de las características.</target>
        </trans-unit>
        <trans-unit id="99983f06243c41c70b7f7a98a21b26cf2a2ec6a9" translate="yes" xml:space="preserve">
          <source>Names of each of the target classes in ascending numerical order. Only relevant for classification and not supported for multi-output. If &lt;code&gt;True&lt;/code&gt;, shows a symbolic representation of the class name.</source>
          <target state="translated">Nombres de cada una de las clases objetivo en orden num&amp;eacute;rico ascendente. Solo es relevante para la clasificaci&amp;oacute;n y no es compatible con m&amp;uacute;ltiples salidas. Si es &lt;code&gt;True&lt;/code&gt; , muestra una representaci&amp;oacute;n simb&amp;oacute;lica del nombre de la clase.</target>
        </trans-unit>
        <trans-unit id="e9e6ba24a1711383d87f42cc11bb29b29e568b73" translate="yes" xml:space="preserve">
          <source>Names of each target (RCV1 topics), as ordered in dataset.target.</source>
          <target state="translated">Nombres de cada objetivo (temas de RCV1),como se ordena en dataset.target.</target>
        </trans-unit>
        <trans-unit id="5ee798b80fce1c26ac31847940e2cbb9594ee08b" translate="yes" xml:space="preserve">
          <source>Names of the features produced by transform.</source>
          <target state="translated">Nombres de los rasgos producidos por la transformación.</target>
        </trans-unit>
        <trans-unit id="4aded465f8c4c45d7d7ec8d437901909b15f0b3f" translate="yes" xml:space="preserve">
          <source>Natural handling of data of mixed type (= heterogeneous features)</source>
          <target state="translated">Manejo natural de datos de tipo mixto (=características heterogéneas)</target>
        </trans-unit>
        <trans-unit id="0a4d2a1303aed1ff654767155d9269907f0d020c" translate="yes" xml:space="preserve">
          <source>Nearest Centroid Classification</source>
          <target state="translated">Clasificación del centroide más cercano</target>
        </trans-unit>
        <trans-unit id="fa1459036257eab60db8e1afe6d9886bbc5e8a42" translate="yes" xml:space="preserve">
          <source>Nearest Neighbors Classification</source>
          <target state="translated">Clasificación de los vecinos más cercanos</target>
        </trans-unit>
        <trans-unit id="c7b70d3a90c9b413590f1c3fdfeae8dc16304398" translate="yes" xml:space="preserve">
          <source>Nearest Neighbors regression</source>
          <target state="translated">Regresión de los vecinos más cercanos</target>
        </trans-unit>
        <trans-unit id="cc8575a20e3e28eef4bfc70e48146f9994bd7318" translate="yes" xml:space="preserve">
          <source>Nearest centroid classifier.</source>
          <target state="translated">El clasificador centroide más cercano.</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
