<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="es" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="b8cd925555526484cde7ba65174f600e33250f6b" translate="yes" xml:space="preserve">
          <source>Hochreiter, Bodenhofer, et. al., 2010. &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2881408/&quot;&gt;FABIA: factor analysis for bicluster acquisition&lt;/a&gt;.</source>
          <target state="translated">Hochreiter, Bodenhofer y col. al., 2010. &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2881408/&quot;&gt;FABIA: an&amp;aacute;lisis factorial para la adquisici&amp;oacute;n de bicluster&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="cbd8a9628e732e150b1ccedb68c9c6ad4fe27c2c" translate="yes" xml:space="preserve">
          <source>Holds arrays of shape (n_classes, n_categories of respective feature) for each feature. Each array provides the empirical log probability of categories given the respective feature and class, &lt;code&gt;P(x_i|y)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0265e0dec8e2ff0952abf481f5094201e14a30d8" translate="yes" xml:space="preserve">
          <source>Holds arrays of shape (n_classes, n_categories of respective feature) for each feature. Each array provides the number of samples encountered for each class and category of the specific feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a5c3ac7ac58dcde82acc59c23c0dce0d31966d1" translate="yes" xml:space="preserve">
          <source>Holds the label for each class.</source>
          <target state="translated">Lleva la etiqueta de cada clase.</target>
        </trans-unit>
        <trans-unit id="4b7dceb5fe5f7e92199815a2b66fef8fdf05dc27" translate="yes" xml:space="preserve">
          <source>Homogeneity and completeness scores are formally given by:</source>
          <target state="translated">Los puntajes de homogeneidad e integridad son formalmente dados por:</target>
        </trans-unit>
        <trans-unit id="7c13e77bc830b382c041eec0e3fcc1723f375e05" translate="yes" xml:space="preserve">
          <source>Homogeneity metric of a cluster labeling given a ground truth.</source>
          <target state="translated">La métrica de homogeneidad de la etiqueta de un cúmulo dada una verdad de la tierra.</target>
        </trans-unit>
        <trans-unit id="3afc9b67230d985e8782525c7b58b615e013e8f9" translate="yes" xml:space="preserve">
          <source>Homogeneity, completeness and V-measure can be computed at once using &lt;a href=&quot;generated/sklearn.metrics.homogeneity_completeness_v_measure#sklearn.metrics.homogeneity_completeness_v_measure&quot;&gt;&lt;code&gt;homogeneity_completeness_v_measure&lt;/code&gt;&lt;/a&gt; as follows:</source>
          <target state="translated">La homogeneidad, la completitud y la medida V se pueden calcular a la vez utilizando &lt;a href=&quot;generated/sklearn.metrics.homogeneity_completeness_v_measure#sklearn.metrics.homogeneity_completeness_v_measure&quot;&gt; &lt;code&gt;homogeneity_completeness_v_measure&lt;/code&gt; de la&lt;/a&gt; siguiente manera:</target>
        </trans-unit>
        <trans-unit id="0878824f511837fc1a1c8d27240af19053ebdbd4" translate="yes" xml:space="preserve">
          <source>HouseAge median house age in block</source>
          <target state="translated">Edad de la casa Edad media de la casa en el bloque</target>
        </trans-unit>
        <trans-unit id="95f00bca96463f976c07bb46f71ce6b37ead0db0" translate="yes" xml:space="preserve">
          <source>How often to evaluate perplexity. Only used in &lt;code&gt;fit&lt;/code&gt; method. set it to 0 or negative number to not evaluate perplexity in training at all. Evaluating perplexity can help you check convergence in training process, but it will also increase total training time. Evaluating perplexity in every iteration might increase training time up to two-fold.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be45c283b4c54643c38f84bc65a4bfc525d6d30a" translate="yes" xml:space="preserve">
          <source>How often to evaluate perplexity. Only used in &lt;code&gt;fit&lt;/code&gt; method. set it to 0 or negative number to not evalute perplexity in training at all. Evaluating perplexity can help you check convergence in training process, but it will also increase total training time. Evaluating perplexity in every iteration might increase training time up to two-fold.</source>
          <target state="translated">Con qu&amp;eacute; frecuencia evaluar la perplejidad. Solo se utiliza en el m&amp;eacute;todo de &lt;code&gt;fit&lt;/code&gt; . config&amp;uacute;relo en 0 o en un n&amp;uacute;mero negativo para no evaluar la perplejidad en el entrenamiento. La evaluaci&amp;oacute;n de la perplejidad puede ayudarlo a verificar la convergencia en el proceso de entrenamiento, pero tambi&amp;eacute;n aumentar&amp;aacute; el tiempo total de entrenamiento. Evaluar la perplejidad en cada iteraci&amp;oacute;n podr&amp;iacute;a aumentar el tiempo de entrenamiento hasta dos veces.</target>
        </trans-unit>
        <trans-unit id="82dc6d28bb69b15075cb833b4ea7ee856b1fb8a5" translate="yes" xml:space="preserve">
          <source>How to compute the normalizer in the denominator. Possible options are &amp;lsquo;min&amp;rsquo;, &amp;lsquo;geometric&amp;rsquo;, &amp;lsquo;arithmetic&amp;rsquo;, and &amp;lsquo;max&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="060faa287065b4ad6ba6c00f598635b42adc21de" translate="yes" xml:space="preserve">
          <source>How to compute the normalizer in the denominator. Possible options are &amp;lsquo;min&amp;rsquo;, &amp;lsquo;geometric&amp;rsquo;, &amp;lsquo;arithmetic&amp;rsquo;, and &amp;lsquo;max&amp;rsquo;. If &amp;lsquo;warn&amp;rsquo;, &amp;lsquo;geometric&amp;rsquo; will be used. The default will change to &amp;lsquo;arithmetic&amp;rsquo; in version 0.22.</source>
          <target state="translated">C&amp;oacute;mo calcular el normalizador en el denominador. Las opciones posibles son 'm&amp;iacute;nimo', 'geom&amp;eacute;trico', 'aritm&amp;eacute;tico' y 'm&amp;aacute;ximo'. Si 'advertir', se utilizar&amp;aacute; 'geom&amp;eacute;trico'. El valor predeterminado cambiar&amp;aacute; a 'aritm&amp;eacute;tico' en la versi&amp;oacute;n 0.22.</target>
        </trans-unit>
        <trans-unit id="b8efa217d0db9ce56ac60653645beebe151304f9" translate="yes" xml:space="preserve">
          <source>How to compute the normalizer in the denominator. Possible options are &amp;lsquo;min&amp;rsquo;, &amp;lsquo;geometric&amp;rsquo;, &amp;lsquo;arithmetic&amp;rsquo;, and &amp;lsquo;max&amp;rsquo;. If &amp;lsquo;warn&amp;rsquo;, &amp;lsquo;max&amp;rsquo; will be used. The default will change to &amp;lsquo;arithmetic&amp;rsquo; in version 0.22.</source>
          <target state="translated">C&amp;oacute;mo calcular el normalizador en el denominador. Las opciones posibles son 'm&amp;iacute;nimo', 'geom&amp;eacute;trico', 'aritm&amp;eacute;tico' y 'm&amp;aacute;ximo'. Si 'advertir', se usar&amp;aacute; 'max'. El valor predeterminado cambiar&amp;aacute; a 'aritm&amp;eacute;tico' en la versi&amp;oacute;n 0.22.</target>
        </trans-unit>
        <trans-unit id="cf894bb3f8fceedab10cdd5da9a5edd37e00865d" translate="yes" xml:space="preserve">
          <source>How to construct the affinity matrix.</source>
          <target state="translated">Cómo construir la matriz de afinidad.</target>
        </trans-unit>
        <trans-unit id="d34268ba2716d71aaaeee2c35e527ca55a46dd2f" translate="yes" xml:space="preserve">
          <source>However ARI can also be useful in a purely unsupervised setting as a building block for a Consensus Index that can be used for clustering model selection (TODO).</source>
          <target state="translated">Sin embargo,el ARI también puede ser útil en un entorno puramente no supervisado como base para un Índice de Consenso que puede utilizarse para la selección de modelos de agrupación (TODO).</target>
        </trans-unit>
        <trans-unit id="0121c2b22395d1a9db3fd77f24d0a9f0e41170e3" translate="yes" xml:space="preserve">
          <source>However MI-based measures can also be useful in purely unsupervised setting as a building block for a Consensus Index that can be used for clustering model selection.</source>
          <target state="translated">Sin embargo,las medidas basadas en la IM también pueden ser útiles en un entorno puramente no supervisado como base para un Índice de Consenso que puede utilizarse para la selección de modelos de agrupación.</target>
        </trans-unit>
        <trans-unit id="117b6230e0e8ab3fcdc1b277507becef8a05f759" translate="yes" xml:space="preserve">
          <source>However care must taken to always make the affinity matrix symmetric so that the eigenvector decomposition works as expected.</source>
          <target state="translated">Sin embargo,hay que tener cuidado de que la matriz de afinidad sea siempre simétrica para que la descomposición de los vectores propios funcione como se espera.</target>
        </trans-unit>
        <trans-unit id="92447df8a934c98a63d3aa91a9c263efa88d6300" translate="yes" xml:space="preserve">
          <source>However let&amp;rsquo;s keep our high capacity random forest model for now so as to illustrate some pitfalls with feature importance on variables with many unique values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="925f5b77eb2888a89c04118c35bff0f0ace7255e" translate="yes" xml:space="preserve">
          <source>However the RI score does not guarantee that random label assignments will get a value close to zero (esp. if the number of clusters is in the same order of magnitude as the number of samples).</source>
          <target state="translated">Sin embargo,la puntuación del RI no garantiza que las asignaciones aleatorias de etiquetas obtengan un valor cercano a cero (sobre todo si el número de cúmulos está en el mismo orden de magnitud que el número de muestras).</target>
        </trans-unit>
        <trans-unit id="11d179b15971b8eaae6270be9fce57c0bd0d2416" translate="yes" xml:space="preserve">
          <source>However, by partitioning the available data into three sets, we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets.</source>
          <target state="translated">Sin embargo,al dividir los datos disponibles en tres conjuntos,reducimos drásticamente el número de muestras que pueden utilizarse para el aprendizaje del modelo,y los resultados pueden depender de una elección aleatoria particular para el par de conjuntos (tren,validación).</target>
        </trans-unit>
        <trans-unit id="56c680421b5fb07e56baa9a65f13a80fce385b54" translate="yes" xml:space="preserve">
          <source>However, coefficient estimates for Ordinary Least Squares rely on the independence of the model terms. When terms are correlated and the columns of the design matrix \(X\) have an approximate linear dependence, the design matrix becomes close to singular and as a result, the least-squares estimate becomes highly sensitive to random errors in the observed response, producing a large variance. This situation of &lt;em&gt;multicollinearity&lt;/em&gt; can arise, for example, when data are collected without an experimental design.</source>
          <target state="translated">Sin embargo, las estimaciones de coeficientes para m&amp;iacute;nimos cuadrados ordinarios se basan en la independencia de los t&amp;eacute;rminos del modelo. Cuando los t&amp;eacute;rminos est&amp;aacute;n correlacionados y las columnas de la matriz de dise&amp;ntilde;o \ (X \) tienen una dependencia lineal aproximada, la matriz de dise&amp;ntilde;o se vuelve casi singular y, como resultado, la estimaci&amp;oacute;n de m&amp;iacute;nimos cuadrados se vuelve altamente sensible a errores aleatorios en la respuesta observada, produciendo una gran variaci&amp;oacute;n. Esta situaci&amp;oacute;n de &lt;em&gt;multicolinealidad&lt;/em&gt; puede surgir, por ejemplo, cuando se recopilan datos sin un dise&amp;ntilde;o experimental.</target>
        </trans-unit>
        <trans-unit id="aca3ba038ade9dc36b01dc839f8a0cfb1c392a3d" translate="yes" xml:space="preserve">
          <source>However, dropping one category breaks the symmetry of the original representation and can therefore induce a bias in downstream models, for instance for penalized linear classification or regression models.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf734282463bfc3a9cb343729f546342ec401691" translate="yes" xml:space="preserve">
          <source>However, if the learning curve is steep for the training size in question, then 5- or 10- fold cross validation can overestimate the generalization error.</source>
          <target state="translated">Sin embargo,si la curva de aprendizaje es pronunciada para el tamaño del entrenamiento en cuestión,entonces la validación cruzada de 5 o 10 veces puede sobreestimar el error de generalización.</target>
        </trans-unit>
        <trans-unit id="fc162d85afa0b20b4064f40b16eb0e55ca89c629" translate="yes" xml:space="preserve">
          <source>However, it is sometimes helpful to plot the influence of a single hyperparameter on the training score and the validation score to find out whether the estimator is overfitting or underfitting for some hyperparameter values.</source>
          <target state="translated">Sin embargo,a veces es útil trazar la influencia de un solo hiperparámetro en la puntuación de entrenamiento y en la puntuación de validación para averiguar si el estimador se ajusta en exceso o en defecto para algunos valores de hiperparámetro.</target>
        </trans-unit>
        <trans-unit id="5c8b24673bb3f660f66f90035a856044be6d6f9e" translate="yes" xml:space="preserve">
          <source>However, note that this transformer will only do a binary one-hot encoding when feature values are of type string. If categorical features are represented as numeric values such as int, the DictVectorizer can be followed by &lt;a href=&quot;sklearn.preprocessing.onehotencoder#sklearn.preprocessing.OneHotEncoder&quot;&gt;&lt;code&gt;sklearn.preprocessing.OneHotEncoder&lt;/code&gt;&lt;/a&gt; to complete binary one-hot encoding.</source>
          <target state="translated">Sin embargo, tenga en cuenta que este transformador solo realizar&amp;aacute; una codificaci&amp;oacute;n binaria one-hot cuando los valores de las caracter&amp;iacute;sticas sean de tipo cadena. Si las caracter&amp;iacute;sticas categ&amp;oacute;ricas se representan como valores num&amp;eacute;ricos como int, el DictVectorizer puede ser seguido por &lt;a href=&quot;sklearn.preprocessing.onehotencoder#sklearn.preprocessing.OneHotEncoder&quot;&gt; &lt;code&gt;sklearn.preprocessing.OneHotEncoder&lt;/code&gt; &lt;/a&gt; para completar la codificaci&amp;oacute;n binaria one-hot.</target>
        </trans-unit>
        <trans-unit id="8b25d9ad009118aef0894664f601ac10786f8b49" translate="yes" xml:space="preserve">
          <source>However, this is not the most precise way of doing this computation, and the distance matrix returned by this function may not be exactly symmetric as required by, e.g., &lt;code&gt;scipy.spatial.distance&lt;/code&gt; functions.</source>
          <target state="translated">Sin embargo, esta no es la forma m&amp;aacute;s precisa de hacer este c&amp;aacute;lculo, y la matriz de distancia devuelta por esta funci&amp;oacute;n puede no ser exactamente sim&amp;eacute;trica como lo requieren, por ejemplo, &lt;code&gt;scipy.spatial.distance&lt;/code&gt; funciones scipy.spatial.distance .</target>
        </trans-unit>
        <trans-unit id="379cfb166aa26713fe1131478e9b37a4224780ad" translate="yes" xml:space="preserve">
          <source>Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent</source>
          <target state="translated">Hsiang-Fu Yu,Fang-Lan Huang,Chih-Jen Lin (2011).Descenso de doble coordenada</target>
        </trans-unit>
        <trans-unit id="15d1d4b26d2ba06629e368bf6c8a860d8762ef89" translate="yes" xml:space="preserve">
          <source>Huber (&lt;code&gt;'huber'&lt;/code&gt;): Another robust loss function that combines least squares and least absolute deviation; use &lt;code&gt;alpha&lt;/code&gt; to control the sensitivity with regards to outliers (see &lt;a href=&quot;#f2001&quot; id=&quot;id15&quot;&gt;[F2001]&lt;/a&gt; for more details).</source>
          <target state="translated">Huber ( &lt;code&gt;'huber'&lt;/code&gt; ): Otra funci&amp;oacute;n de p&amp;eacute;rdida robusta que combina m&amp;iacute;nimos cuadrados y m&amp;iacute;nima desviaci&amp;oacute;n absoluta; utilice &lt;code&gt;alpha&lt;/code&gt; para controlar la sensibilidad con respecto a los valores at&amp;iacute;picos (consulte &lt;a href=&quot;#f2001&quot; id=&quot;id15&quot;&gt;[F2001]&lt;/a&gt; para obtener m&amp;aacute;s detalles).</target>
        </trans-unit>
        <trans-unit id="31a935f21354ade96cddb9bceb15816934445a99" translate="yes" xml:space="preserve">
          <source>Huber (&lt;code&gt;'huber'&lt;/code&gt;): Another robust loss function that combines least squares and least absolute deviation; use &lt;code&gt;alpha&lt;/code&gt; to control the sensitivity with regards to outliers (see &lt;a href=&quot;model_evaluation#f2001&quot; id=&quot;id18&quot;&gt;[F2001]&lt;/a&gt; for more details).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ac7569be3812003aa580f2d415abbe085c935f8" translate="yes" xml:space="preserve">
          <source>Huber: less sensitive to outliers than least-squares. It is equivalent to least squares when \(|y_i - f(x_i)| \leq \varepsilon\), and \(L(y_i, f(x_i)) = \varepsilon |y_i - f(x_i)| - \frac{1}{2} \varepsilon^2\) otherwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d12d436101cbc3212af50bf81000f6d78d4cf01" translate="yes" xml:space="preserve">
          <source>HuberRegressor vs Ridge on dataset with strong outliers</source>
          <target state="translated">HuberRegressor vs Ridge en un conjunto de datos con fuertes valores atípicos</target>
        </trans-unit>
        <trans-unit id="7e58a6e8d89e8504ad31e135de9b485ad40f05f6" translate="yes" xml:space="preserve">
          <source>Hue</source>
          <target state="translated">Hue</target>
        </trans-unit>
        <trans-unit id="c7a8b2b20a9c45f674f17cd8ef7ece305e1c36eb" translate="yes" xml:space="preserve">
          <source>Hue:</source>
          <target state="translated">Hue:</target>
        </trans-unit>
        <trans-unit id="4e99bcdee413a9c98d317e0e8e4199a2bf582f90" translate="yes" xml:space="preserve">
          <source>Hugo Chavez</source>
          <target state="translated">Hugo Chávez</target>
        </trans-unit>
        <trans-unit id="27d175ec2bd32b6e89237e92741eaada2632ca6b" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the alpha parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="135e7e12c7ab5ea7496649e72ee134478ecf558e" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the alpha parameter. Default is 1.e-6.</source>
          <target state="translated">Hiperparámetro:parámetro de escala inversa (parámetro de tasa)para la distribución Gamma anterior al parámetro alfa.El valor por defecto es 1.e-6.</target>
        </trans-unit>
        <trans-unit id="b2f7b3253a19f527d0298206233b561d7b41b5a7" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the lambda parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="761054fe5bafcad49a16f057764235860452b8da" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the lambda parameter. Default is 1.e-6</source>
          <target state="translated">Hiperparámetro:parámetro de escala inversa (parámetro de tasa)para la distribución Gamma anterior al parámetro lambda.El valor por defecto es 1.e-6</target>
        </trans-unit>
        <trans-unit id="6001ea6392d3003569381e7107254e88f75fd600" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the lambda parameter. Default is 1.e-6.</source>
          <target state="translated">Hiperparámetro:parámetro de escala inversa (parámetro de tasa)para la distribución Gamma anterior al parámetro lambda.El valor por defecto es 1.e-6.</target>
        </trans-unit>
        <trans-unit id="dc7fba2810913663c629f4f037b88df90cdd9978" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : shape parameter for the Gamma distribution prior over the alpha parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="81e171654bf22a490946ec147c219e96694497ff" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : shape parameter for the Gamma distribution prior over the alpha parameter. Default is 1.e-6</source>
          <target state="translated">Hiperparámetro:parámetro de forma para la distribución Gamma anterior al parámetro alfa.El valor por defecto es 1.e-6</target>
        </trans-unit>
        <trans-unit id="b07af48fd68aeaacb4df041ef30bae006150c237" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : shape parameter for the Gamma distribution prior over the alpha parameter. Default is 1.e-6.</source>
          <target state="translated">Hiperparámetro:parámetro de forma para la distribución Gamma anterior al parámetro alfa.El valor por defecto es 1.e-6.</target>
        </trans-unit>
        <trans-unit id="532d93a63b09b5d558170a615d6e76799550e7c3" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : shape parameter for the Gamma distribution prior over the lambda parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1398aea0b1e181e76b6d9d73db4040ccf06ee2f7" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : shape parameter for the Gamma distribution prior over the lambda parameter. Default is 1.e-6.</source>
          <target state="translated">Hiperparámetro:parámetro de forma para la distribución Gamma anterior al parámetro lambda.El valor por defecto es 1.e-6.</target>
        </trans-unit>
        <trans-unit id="7a5b8a439bb2492412d2944256add4dcdf337928" translate="yes" xml:space="preserve">
          <source>Hyper-parameter optimizers</source>
          <target state="translated">Optimizadores de hiperparámetros</target>
        </trans-unit>
        <trans-unit id="223bf115da53d3d9cdf837b624135b565596fd92" translate="yes" xml:space="preserve">
          <source>Hyper-parameters are parameters that are not directly learnt within estimators. In scikit-learn they are passed as arguments to the constructor of the estimator classes. Typical examples include &lt;code&gt;C&lt;/code&gt;, &lt;code&gt;kernel&lt;/code&gt; and &lt;code&gt;gamma&lt;/code&gt; for Support Vector Classifier, &lt;code&gt;alpha&lt;/code&gt; for Lasso, etc.</source>
          <target state="translated">Los hiperpar&amp;aacute;metros son par&amp;aacute;metros que no se aprenden directamente dentro de los estimadores. En scikit-learn, se pasan como argumentos al constructor de las clases de estimador. Los ejemplos t&amp;iacute;picos incluyen &lt;code&gt;C&lt;/code&gt; , &lt;code&gt;kernel&lt;/code&gt; y &lt;code&gt;gamma&lt;/code&gt; para Support Vector Classifier, &lt;code&gt;alpha&lt;/code&gt; para Lasso, etc.</target>
        </trans-unit>
        <trans-unit id="568b05951392672a52de0358537dd29fcafbe544" translate="yes" xml:space="preserve">
          <source>Hyper-parameters of an estimator can be updated after it has been constructed via the &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-set-params&quot;&gt;set_params()&lt;/a&gt; method. Calling &lt;code&gt;fit()&lt;/code&gt; more than once will overwrite what was learned by any previous &lt;code&gt;fit()&lt;/code&gt;:</source>
          <target state="translated">Los hiperpar&amp;aacute;metros de un estimador se pueden actualizar despu&amp;eacute;s de que se haya construido mediante el m&amp;eacute;todo &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-set-params&quot;&gt;set_params ()&lt;/a&gt; . Llamar a &lt;code&gt;fit()&lt;/code&gt; m&amp;aacute;s de una vez sobrescribir&amp;aacute; lo aprendido por cualquier &lt;code&gt;fit()&lt;/code&gt; previo () :</target>
        </trans-unit>
        <trans-unit id="3320fca926b13c61acfba24014e8ac870169bd3f" translate="yes" xml:space="preserve">
          <source>Hyper-parameters of an estimator can be updated after it has been constructed via the &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-set-params&quot;&gt;set_params()&lt;/a&gt; method. Calling &lt;code&gt;fit()&lt;/code&gt; more than once will overwrite what was learned by any previous &lt;code&gt;fit()&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1db8c072507305b4aa23189287be39423349b8f4" translate="yes" xml:space="preserve">
          <source>Hyperparameter of the ridge regression that learns the inverse transform (when fit_inverse_transform=True).</source>
          <target state="translated">Hiperparámetro de la regresión de la cresta que aprende la transformación inversa (cuando fit_inverse_transform=True).</target>
        </trans-unit>
        <trans-unit id="a15138d06876fc00149292405bf57e4204d00bbe" translate="yes" xml:space="preserve">
          <source>Hyperparameters</source>
          <target state="translated">Hyperparameters</target>
        </trans-unit>
        <trans-unit id="181eca8daf7aaeed93f61701c7eddb643dc6b36a" translate="yes" xml:space="preserve">
          <source>Hyperparameters:</source>
          <target state="translated">Hyperparameters:</target>
        </trans-unit>
        <trans-unit id="8bb86931be2a9d0449c3eec151da751cb88591f1" translate="yes" xml:space="preserve">
          <source>I. Guyon, &amp;ldquo;Design of experiments for the NIPS 2003 variable selection benchmark&amp;rdquo;, 2003.</source>
          <target state="translated">I. Guyon, &amp;ldquo;Dise&amp;ntilde;o de experimentos para el benchmark de selecci&amp;oacute;n de variables NIPS 2003&amp;rdquo;, 2003.</target>
        </trans-unit>
        <trans-unit id="074b587a2df67fa7bdaebb29bf4f1381e49051c3" translate="yes" xml:space="preserve">
          <source>I. Guyon, K. Bennett, G. Cawley, H.J. Escalante, S. Escalera, T.K. Ho, N. Maci&amp;agrave;, B. Ray, M. Saeed, A.R. Statnikov, E. Viegas, &lt;a href=&quot;https://ieeexplore.ieee.org/document/7280767&quot;&gt;Design of the 2015 ChaLearn AutoML Challenge&lt;/a&gt;, IJCNN 2015.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="483f14c4d9fef04833d7508282eb9a08a8019931" translate="yes" xml:space="preserve">
          <source>I.K. Yeo and R.A. Johnson, &amp;ldquo;A new family of power transformations to improve normality or symmetry.&amp;rdquo; Biometrika, 87(4), pp.954-959, (2000).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a238a89365b9d0ce7f5fb26e189eb03cdc08fbe5" translate="yes" xml:space="preserve">
          <source>ICA can also be used as yet another non linear decomposition that finds components with some sparsity:</source>
          <target state="translated">El ICA también puede ser usado como otra descomposición no lineal que encuentra componentes con cierta escasez:</target>
        </trans-unit>
        <trans-unit id="57933c6e2d57c3e3911db47768687ccc98d16924" translate="yes" xml:space="preserve">
          <source>IDpol</source>
          <target state="translated">IDpol</target>
        </trans-unit>
        <trans-unit id="fcc34dd193c826ae2f0c8b804c532252b4a25480" translate="yes" xml:space="preserve">
          <source>INDUS proportion of non-retail business acres per town</source>
          <target state="translated">INDUS proporción de acres de negocios no minoristas por ciudad</target>
        </trans-unit>
        <trans-unit id="44a4d7b7db7815be999da6a406f4dadd2c4327c5" translate="yes" xml:space="preserve">
          <source>Identification number of each sample, as ordered in dataset.data.</source>
          <target state="translated">Número de identificación de cada muestra,como se ordena en dataset.data.</target>
        </trans-unit>
        <trans-unit id="4b5c601d48e24d2806952d270f88677fcd7cfb39" translate="yes" xml:space="preserve">
          <source>Identifying which category an object belongs to.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02d51b4f13558cbcfc807b53522b1ffb156ad7e7" translate="yes" xml:space="preserve">
          <source>Identity: d(x, y) = 0 if and only if x == y</source>
          <target state="translated">Identidad:d(x,y)=0 si y sólo si x ==y</target>
        </trans-unit>
        <trans-unit id="35bd2069c37f2c6a308bc5401948b247d5bcfc02" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;all&amp;rdquo;, the imputer mask will represent all features.</source>
          <target state="translated">Si es &quot;todos&quot;, la m&amp;aacute;scara de imputador representar&amp;aacute; todas las caracter&amp;iacute;sticas.</target>
        </trans-unit>
        <trans-unit id="84934b5d658c0a370c458ee55fa3255bb65884a6" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;auto&amp;rdquo; (default), the imputer mask will be of same type as input.</source>
          <target state="translated">Si es &quot;autom&amp;aacute;tico&quot; (predeterminado), la m&amp;aacute;scara de imputador ser&amp;aacute; del mismo tipo que la entrada.</target>
        </trans-unit>
        <trans-unit id="7cdc1bc49e801caf1ff212e1000d88bb13d7e93e" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;auto&amp;rdquo;, then &lt;code&gt;max_features=n_features&lt;/code&gt;.</source>
          <target state="translated">Si es &quot;auto&quot;, entonces &lt;code&gt;max_features=n_features&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="164a2722286c1b34bc2df80a90c75397afce3e6b" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;auto&amp;rdquo;, then &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt;.</source>
          <target state="translated">Si es &quot;auto&quot;, entonces &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="911a50d98b398312fa01572b5d7b864da542117b" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;auto&amp;rdquo;, then &lt;code&gt;max_samples=min(256, n_samples)&lt;/code&gt;.</source>
          <target state="translated">Si es &quot;autom&amp;aacute;tico&quot;, entonces &lt;code&gt;max_samples=min(256, n_samples)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="dca169b413a6ec050ae0928eb38f43b00b9c08e0" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;constant&amp;rdquo;, then replace missing values with fill_value. Can be used with strings or numeric data.</source>
          <target state="translated">Si es &quot;constante&quot;, reemplace los valores faltantes con fill_value. Se puede usar con cadenas o datos num&amp;eacute;ricos.</target>
        </trans-unit>
        <trans-unit id="fed653e1ff76c14b62a8cb9c0f4474c620b2641e" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;log2&amp;rdquo;, then &lt;code&gt;max_features=log2(n_features)&lt;/code&gt;.</source>
          <target state="translated">Si es &quot;log2&quot;, entonces &lt;code&gt;max_features=log2(n_features)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e799052bdd1932be1b28378fc91f87421f6d1065" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;mean&amp;rdquo;, then replace missing values using the mean along each column. Can only be used with numeric data.</source>
          <target state="translated">Si es &quot;media&quot;, reemplace los valores faltantes utilizando la media de cada columna. Solo se puede utilizar con datos num&amp;eacute;ricos.</target>
        </trans-unit>
        <trans-unit id="8c28cbae695709f5ae6daaba6d2035fa26d4e040" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;mean&amp;rdquo;, then replace missing values using the mean along the axis.</source>
          <target state="translated">Si es &quot;media&quot;, reemplace los valores faltantes utilizando la media a lo largo del eje.</target>
        </trans-unit>
        <trans-unit id="d5353b7f39f25231d62cbbc36fcd604e05d2faa0" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;median&amp;rdquo;, then replace missing values using the median along each column. Can only be used with numeric data.</source>
          <target state="translated">Si es &quot;mediana&quot;, reemplace los valores faltantes utilizando la mediana a lo largo de cada columna. Solo se puede utilizar con datos num&amp;eacute;ricos.</target>
        </trans-unit>
        <trans-unit id="2c7bf0a70af62c9d1ff80c38810d3732da415b46" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;median&amp;rdquo;, then replace missing values using the median along the axis.</source>
          <target state="translated">Si es &quot;mediana&quot;, reemplace los valores faltantes utilizando la mediana a lo largo del eje.</target>
        </trans-unit>
        <trans-unit id="b9dfb246debbef95e2bc6e78da2b0aca54b8e768" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;missing-only&amp;rdquo; (default), the imputer mask will only represent features containing missing values during fit time.</source>
          <target state="translated">Si es &quot;solo faltante&quot; (predeterminado), la m&amp;aacute;scara de imputador solo representar&amp;aacute; entidades que contengan valores perdidos durante el tiempo de ajuste.</target>
        </trans-unit>
        <trans-unit id="fb9cd590a090a11e857ebbc7c5d49f19787d4a57" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;most_frequent&amp;rdquo;, then replace missing using the most frequent value along each column. Can be used with strings or numeric data.</source>
          <target state="translated">Si es &quot;most_frequent&quot;, reemplace los que faltan usando el valor m&amp;aacute;s frecuente en cada columna. Se puede usar con cadenas o datos num&amp;eacute;ricos.</target>
        </trans-unit>
        <trans-unit id="a90ab2bff0e7c4a2db0c7d70bcb17fa44e1b8cb3" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;most_frequent&amp;rdquo;, then replace missing using the most frequent value along the axis.</source>
          <target state="translated">Si es &quot;most_frequent&quot;, reemplace lo que falta usando el valor m&amp;aacute;s frecuente a lo largo del eje.</target>
        </trans-unit>
        <trans-unit id="8007580c79fb9470823eec0b7f7391f7011a44a8" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;prefit&amp;rdquo; is passed, it is assumed that &lt;code&gt;base_estimator&lt;/code&gt; has been fitted already and all data is used for calibration.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d25972b438acba3aa495003bff5b880c3dc78f95" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;prefit&amp;rdquo; is passed, it is assumed that base_estimator has been fitted already and all data is used for calibration.</source>
          <target state="translated">Si se pasa &quot;prefit&quot;, se supone que base_estimator ya se ha instalado y todos los datos se utilizan para la calibraci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="ddc01f2adfc0b5da49bb0bea104c04055f37082b" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;sqrt&amp;rdquo;, then &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt; (same as &amp;ldquo;auto&amp;rdquo;).</source>
          <target state="translated">Si es &quot;sqrt&quot;, entonces &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt; (igual que &quot;auto&quot;).</target>
        </trans-unit>
        <trans-unit id="050de520f25e08567f8dcb7bcdaa6887bd8ca53c" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;sqrt&amp;rdquo;, then &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt;.</source>
          <target state="translated">Si es &quot;sqrt&quot;, entonces &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="274dd12ab1d70a7a9d00df8bbe2aa7f35f2ca3c4" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;SAMME.R&amp;rsquo; then use the SAMME.R real boosting algorithm. &lt;code&gt;base_estimator&lt;/code&gt; must support calculation of class probabilities. If &amp;lsquo;SAMME&amp;rsquo; then use the SAMME discrete boosting algorithm. The SAMME.R algorithm typically converges faster than SAMME, achieving a lower test error with fewer boosting iterations.</source>
          <target state="translated">Si es 'SAMME.R', utilice el algoritmo de refuerzo real de SAMME.R. &lt;code&gt;base_estimator&lt;/code&gt; debe soportar el c&amp;aacute;lculo de probabilidades de clase. Si es 'SAMME', utilice el algoritmo de refuerzo discreto de SAMME. El algoritmo SAMME.R generalmente converge m&amp;aacute;s r&amp;aacute;pido que SAMME, logrando un error de prueba menor con menos iteraciones de impulso.</target>
        </trans-unit>
        <trans-unit id="51b26722f92fe40c28c6f4d36bb516d8181566a9" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;auto&amp;rsquo;, early stopping is enabled if the sample size is larger than 10000. If True, early stopping is enabled, otherwise early stopping is disabled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ae3261c7ce3a365ccb1e46d21ef269f4ad371b0" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;auto&amp;rsquo;, the threshold is determined as in the original paper.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34bbe83eef64f8685433d192f4dd39b726225179" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;auto&amp;rsquo;, then &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bac8214432dad215f7331c0af16dfd3868b9e19" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;balanced&amp;rsquo;, class weights will be given by &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;. If a dictionary is given, keys are classes and values are corresponding class weights. If None is given, the class weights will be uniform.</source>
          <target state="translated">Si est&amp;aacute; 'equilibrado', las ponderaciones de clase vendr&amp;aacute;n dadas por &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt; . Si se proporciona un diccionario, las claves son clases y los valores son pesos de clase correspondientes. Si se da Ninguno, los pesos de la clase ser&amp;aacute;n uniformes.</target>
        </trans-unit>
        <trans-unit id="2ed37f73bd5305414a6ee47c4802aa22bc780ac0" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;diagram&amp;rsquo;, estimators will be displayed as a diagram in a Jupyter lab or notebook context. If &amp;lsquo;text&amp;rsquo;, estimators will be displayed as text. Default is &amp;lsquo;text&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="456401c87cfc2a15cdd408f2dd8be315dc3e833e" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;english&amp;rsquo;, a built-in stop word list for English is used. There are several known issues with &amp;lsquo;english&amp;rsquo; and you should consider an alternative (see &lt;a href=&quot;../feature_extraction#stop-words&quot;&gt;Using stop words&lt;/a&gt;).</source>
          <target state="translated">Si es 'ingl&amp;eacute;s', se utiliza una lista de palabras de detenci&amp;oacute;n incorporada para ingl&amp;eacute;s. Hay varios problemas conocidos con 'ingl&amp;eacute;s' y deber&amp;iacute;a considerar una alternativa (consulte &lt;a href=&quot;../feature_extraction#stop-words&quot;&gt;Uso de palabras vac&amp;iacute;as&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="f2019bdbdfa8956b7b54e8a5677954f4996f6374" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;file&amp;rsquo;, the sequence items must have a &amp;lsquo;read&amp;rsquo; method (file-like object) that is called to fetch the bytes in memory.</source>
          <target state="translated">Si es 'archivo', los elementos de secuencia deben tener un m&amp;eacute;todo de 'lectura' (objeto similar a un archivo) que se llama para obtener los bytes en la memoria.</target>
        </trans-unit>
        <trans-unit id="3dd1f3ca74314afe1ddf15184f6ab04977d1a20b" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;filename&amp;rsquo;, the sequence passed as an argument to fit is expected to be a list of filenames that need reading to fetch the raw content to analyze.</source>
          <target state="translated">Si es 'nombre de archivo', se espera que la secuencia pasada como argumento para encajar sea una lista de nombres de archivo que necesitan lectura para obtener el contenido sin procesar para analizar.</target>
        </trans-unit>
        <trans-unit id="6381402e5f026c95872c614d3f284a846d432d3e" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;hard&amp;rsquo;, uses predicted class labels for majority rule voting. Else if &amp;lsquo;soft&amp;rsquo;, predicts the class label based on the argmax of the sums of the predicted probabilities, which is recommended for an ensemble of well-calibrated classifiers.</source>
          <target state="translated">Si es &quot;dif&amp;iacute;cil&quot;, utiliza etiquetas de clase previstas para la votaci&amp;oacute;n de la regla de la mayor&amp;iacute;a. De lo contrario, si es 'suave', predice la etiqueta de clase basada en el argmax de las sumas de las probabilidades predichas, lo que se recomienda para un conjunto de clasificadores bien calibrados.</target>
        </trans-unit>
        <trans-unit id="4a61aad0a278d4a0b23f699c1bb6bc9a25b8f483" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;log2&amp;rsquo;, then &lt;code&gt;max_features=log2(n_features)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="034a602ff18129b75a77961464f62c916fb178cb" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;precomputed&amp;rsquo;, the training input X is expected to be a distance matrix.</source>
          <target state="translated">Si se 'calcula previamente', se espera que la entrada de entrenamiento X sea una matriz de distancia.</target>
        </trans-unit>
        <trans-unit id="d286c5a17d9d64b09f62a6cd1cf2dc973056dbb7" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;sqrt&amp;rsquo;, then &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="efe2693abb0ad6fb0bb32fc7410403c6f8a6131c" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;warm_start&amp;rsquo; is True, the solution of the last fitting is used as initialization for the next call of fit(). This can speed up convergence when fit is called several times on similar problems. In that case, &amp;lsquo;n_init&amp;rsquo; is ignored and only a single initialization occurs upon the first call. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Si 'warm_start' es True, la soluci&amp;oacute;n del &amp;uacute;ltimo ajuste se usa como inicializaci&amp;oacute;n para la siguiente llamada de fit (). Esto puede acelerar la convergencia cuando se llama al ajuste varias veces en problemas similares. En ese caso, se ignora 'n_init' y solo se produce una inicializaci&amp;oacute;n en la primera llamada. Consulte &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;el glosario&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="65bcde64719b83bdeb345ca5fab269155ae4a753" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;warm_start&amp;rsquo; is True, the solution of the last fitting is used as initialization for the next call of fit(). This can speed up convergence when fit is called several times on similar problems. In that case, &amp;lsquo;n_init&amp;rsquo; is ignored and only a single initialization occurs upon the first call. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="245f671779646599b33075b7dcf37bf735b34555" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;warm_start&amp;rsquo; is True, the solution of the last fitting is used as initialization for the next call of fit(). This can speed up convergence when fit is called several times on similar problems. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Si 'warm_start' es True, la soluci&amp;oacute;n del &amp;uacute;ltimo ajuste se usa como inicializaci&amp;oacute;n para la siguiente llamada de fit (). Esto puede acelerar la convergencia cuando se llama al ajuste varias veces en problemas similares. Consulte &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;el glosario&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="775000d0783a0c4a0cc36e649a7e52e403237e23" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;warm_start&amp;rsquo; is True, the solution of the last fitting is used as initialization for the next call of fit(). This can speed up convergence when fit is called several times on similar problems. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5bb29953be4032aa8bb2090970ba2fb09c57dc65" translate="yes" xml:space="preserve">
          <source>If 0, no progress messages will be printed. If 1, progress messages will be printed to stdout. If &amp;gt; 1, progress messages will be printed and the &lt;code&gt;disp&lt;/code&gt; parameter of &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize&quot;&gt;&lt;code&gt;scipy.optimize.minimize&lt;/code&gt;&lt;/a&gt; will be set to &lt;code&gt;verbose - 2&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a2ad0e9541d6795a0339e5a9c03b37f24ea5bc7" translate="yes" xml:space="preserve">
          <source>If &lt;a href=&quot;#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; has not been called before.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e311856e2dbc16a358c30263eb21c62e3f976c09" translate="yes" xml:space="preserve">
          <source>If &lt;a href=&quot;generated/sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt;&lt;code&gt;MinMaxScaler&lt;/code&gt;&lt;/a&gt; is given an explicit &lt;code&gt;feature_range=(min, max)&lt;/code&gt; the full formula is:</source>
          <target state="translated">Si a &lt;a href=&quot;generated/sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt; &lt;code&gt;MinMaxScaler&lt;/code&gt; &lt;/a&gt; se le da un &lt;code&gt;feature_range=(min, max)&lt;/code&gt; expl&amp;iacute;cito = (min, max), la f&amp;oacute;rmula completa es:</target>
        </trans-unit>
        <trans-unit id="6f352ac5787c6e0994736f1793f840aefef2eb74" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;0 &amp;lt; n_components &amp;lt; 1&lt;/code&gt; and &lt;code&gt;svd_solver == 'full'&lt;/code&gt;, select the number of components such that the amount of variance that needs to be explained is greater than the percentage specified by n_components.</source>
          <target state="translated">Si &lt;code&gt;0 &amp;lt; n_components &amp;lt; 1&lt;/code&gt; y &lt;code&gt;svd_solver == 'full'&lt;/code&gt; , seleccione el n&amp;uacute;mero de componentes de modo que la cantidad de variaci&amp;oacute;n que deba explicarse sea mayor que el porcentaje especificado por n_components.</target>
        </trans-unit>
        <trans-unit id="6154e481a1bfebf053da4021c41ed6b15075ac75" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, &lt;code&gt;Gram&lt;/code&gt; is overwritten.</source>
          <target state="translated">Si es &lt;code&gt;False&lt;/code&gt; , se sobrescribe &lt;code&gt;Gram&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c8ea59a59509714d84c6c3be2a8959e87ca2c339" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, &lt;code&gt;X&lt;/code&gt; is overwritten.</source>
          <target state="translated">Si es &lt;code&gt;False&lt;/code&gt; , se sobrescribe &lt;code&gt;X&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ecd953eee019b7cf39fa95c1745e9486ce5fb903" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, return the number of correctly classified samples. Otherwise, return the fraction of correctly classified samples.</source>
          <target state="translated">Si es &lt;code&gt;False&lt;/code&gt; , devuelva el n&amp;uacute;mero de muestras clasificadas correctamente. De lo contrario, devuelva la fracci&amp;oacute;n de muestras correctamente clasificadas.</target>
        </trans-unit>
        <trans-unit id="8dd52da2b8b6d856acbbc6b969b86fd0a4246941" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, return the number of misclassifications. Otherwise, return the fraction of misclassifications.</source>
          <target state="translated">Si es &lt;code&gt;False&lt;/code&gt; , devuelva el n&amp;uacute;mero de clasificaciones err&amp;oacute;neas. De lo contrario, devuelva la fracci&amp;oacute;n de clasificaciones err&amp;oacute;neas.</target>
        </trans-unit>
        <trans-unit id="85fcfc531652a8814592a07e791b2030fbc9598e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, return the sum of the Jaccard similarity coefficient over the sample set. Otherwise, return the average of Jaccard similarity coefficient.</source>
          <target state="translated">Si es &lt;code&gt;False&lt;/code&gt; , devuelve la suma del coeficiente de similitud de Jaccard sobre el conjunto de muestra. De lo contrario, devuelva el promedio del coeficiente de similitud de Jaccard.</target>
        </trans-unit>
        <trans-unit id="c21045a17e85201e2f77134fc96d9edd698a8ef9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, the &lt;code&gt;cv_results_&lt;/code&gt; attribute will not include training scores.</source>
          <target state="translated">Si es &lt;code&gt;False&lt;/code&gt; , el atributo &lt;code&gt;cv_results_&lt;/code&gt; no incluir&amp;aacute; las puntuaciones de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="363d7b7bc89b4fe7d745ba13b3bf107700064544" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, the &lt;code&gt;cv_results_&lt;/code&gt; attribute will not include training scores. Computing training scores is used to get insights on how different parameter settings impact the overfitting/underfitting trade-off. However computing the scores on the training set can be computationally expensive and is not strictly required to select the parameters that yield the best generalization performance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f7a2b9af6d7b5ad533a302e51ca948f564886c6" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;None&lt;/code&gt; the estimator&amp;rsquo;s default scorer is used.</source>
          <target state="translated">Si es &lt;code&gt;None&lt;/code&gt; , se utiliza el puntaje predeterminado del estimador.</target>
        </trans-unit>
        <trans-unit id="ab9a136f2eebf764f09dd9b08d3d9d7a3daec6b9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;None&lt;/code&gt; the estimator&amp;rsquo;s score method is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8dec298ccc565c5c7f632ae827694845b31aa21" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;None&lt;/code&gt;, &lt;code&gt;estimator&lt;/code&gt; is considered fitted if there exist an attribute that ends with a underscore and does not start with double underscore.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89a2c07a59e8a597581d7c4accbf8ade7624601a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;None&lt;/code&gt;, &lt;code&gt;init_size= 3 * batch_size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0206caad9c301767e28c1eb37b72a3a7f7598e94" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;None&lt;/code&gt;, the scores for each class are returned. Otherwise, this determines the type of averaging performed on the data:</source>
          <target state="translated">Si es &lt;code&gt;None&lt;/code&gt; , se devuelven las puntuaciones de cada clase. De lo contrario, esto determina el tipo de promediado realizado en los datos:</target>
        </trans-unit>
        <trans-unit id="de8d1676c9bb98aea236fe73b6992134925cbda9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;None&lt;/code&gt;, the scores for each class are returned. Otherwise, this determines the type of averaging performed on the data: Note: multiclass ROC AUC currently only handles the &amp;lsquo;macro&amp;rsquo; and &amp;lsquo;weighted&amp;rsquo; averages.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1170dbf5a5618e80add067200212cb5804a58cd" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt; the full path is stored in the &lt;code&gt;coef_path_&lt;/code&gt; attribute. If you compute the solution for a large problem or many targets, setting &lt;code&gt;fit_path&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt; will lead to a speedup, especially with a small alpha.</source>
          <target state="translated">Si es &lt;code&gt;True&lt;/code&gt; , la ruta completa se almacena en el atributo &lt;code&gt;coef_path_&lt;/code&gt; . Si calcula la soluci&amp;oacute;n para un problema grande o muchos objetivos, establecer &lt;code&gt;fit_path&lt;/code&gt; en &lt;code&gt;False&lt;/code&gt; conducir&amp;aacute; a una aceleraci&amp;oacute;n, especialmente con un alfa peque&amp;ntilde;o.</target>
        </trans-unit>
        <trans-unit id="97edef35821191bb6c4443dade8924b80d003e19" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt; then features with missing values during &lt;code&gt;transform&lt;/code&gt; which did not have any missing values during &lt;code&gt;fit&lt;/code&gt; will be imputed with the initial imputation method only. Set to &lt;code&gt;True&lt;/code&gt; if you have many features with no missing values at both &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;transform&lt;/code&gt; time to save compute.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e703de20e5680ee264e2b1b950a8b1ca587cd24f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, X will be copied; else, it may be overwritten.</source>
          <target state="translated">Si es &lt;code&gt;True&lt;/code&gt; , se copiar&amp;aacute; X; de lo contrario, puede sobrescribirse.</target>
        </trans-unit>
        <trans-unit id="8e26b0bb501133486ba99496e311f44a49ce472b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, perform metric MDS; otherwise, perform nonmetric MDS.</source>
          <target state="translated">Si es &lt;code&gt;True&lt;/code&gt; , realice MDS m&amp;eacute;tricas; de lo contrario, realice MDS no m&amp;eacute;tricas.</target>
        </trans-unit>
        <trans-unit id="a2b129bca8e38a348fd53d1896c7796acded2f57" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, return a sparse feature matrix</source>
          <target state="translated">Si es &lt;code&gt;True&lt;/code&gt; , devuelve una matriz de caracter&amp;iacute;sticas dispersas</target>
        </trans-unit>
        <trans-unit id="887d26ef7077238a636d223d3985225a211c8d82" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, return the prior class probability and conditional probabilities of features given classes, from which the data was drawn.</source>
          <target state="translated">Si es &lt;code&gt;True&lt;/code&gt; , devuelve la probabilidad de clase anterior y las probabilidades condicionales de las caracter&amp;iacute;sticas de clases determinadas, de las que se extrajeron los datos.</target>
        </trans-unit>
        <trans-unit id="0b7bef40bad08d9d2c4e67da6c9b56ea79751005" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, some instances might not belong to any class.</source>
          <target state="translated">Si es &lt;code&gt;True&lt;/code&gt; , es posible que algunas instancias no pertenezcan a ninguna clase.</target>
        </trans-unit>
        <trans-unit id="e223ba26a8622e808f0df02e86007844177282d6" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;algorithm=&amp;rsquo;lasso_lars&amp;rsquo;&lt;/code&gt; or &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt;, &lt;code&gt;alpha&lt;/code&gt; is the penalty applied to the L1 norm. If &lt;code&gt;algorithm=&amp;rsquo;threshold&amp;rsquo;&lt;/code&gt;, &lt;code&gt;alpha&lt;/code&gt; is the absolute value of the threshold below which coefficients will be squashed to zero. If &lt;code&gt;algorithm=&amp;rsquo;omp&amp;rsquo;&lt;/code&gt;, &lt;code&gt;alpha&lt;/code&gt; is the tolerance parameter: the value of the reconstruction error targeted. In this case, it overrides &lt;code&gt;n_nonzero_coefs&lt;/code&gt;.</source>
          <target state="translated">Si &lt;code&gt;algorithm=&amp;rsquo;lasso_lars&amp;rsquo;&lt;/code&gt; o &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt; , &lt;code&gt;alpha&lt;/code&gt; es la penalizaci&amp;oacute;n aplicada a la norma L1. Si &lt;code&gt;algorithm=&amp;rsquo;threshold&amp;rsquo;&lt;/code&gt; , &lt;code&gt;alpha&lt;/code&gt; es el valor absoluto del umbral por debajo del cual los coeficientes se reducir&amp;aacute;n a cero. Si &lt;code&gt;algorithm=&amp;rsquo;omp&amp;rsquo;&lt;/code&gt; , &lt;code&gt;alpha&lt;/code&gt; es el par&amp;aacute;metro de tolerancia: el valor del error de reconstrucci&amp;oacute;n objetivo. En este caso, anula &lt;code&gt;n_nonzero_coefs&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c8adb20b3b91095a2c077330ab11f60b186c2818" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;algorithm='lasso_lars'&lt;/code&gt; or &lt;code&gt;algorithm='lasso_cd'&lt;/code&gt;, &lt;code&gt;alpha&lt;/code&gt; is the penalty applied to the L1 norm. If &lt;code&gt;algorithm='threshold'&lt;/code&gt;, &lt;code&gt;alpha&lt;/code&gt; is the absolute value of the threshold below which coefficients will be squashed to zero. If &lt;code&gt;algorithm='omp'&lt;/code&gt;, &lt;code&gt;alpha&lt;/code&gt; is the tolerance parameter: the value of the reconstruction error targeted. In this case, it overrides &lt;code&gt;n_nonzero_coefs&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ef12938b73ad4fc11883a02f290e9f35cac58e0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ax&lt;/code&gt; is an axes or None, &lt;code&gt;axes_[i, j]&lt;/code&gt; is the axes on the i-th row and j-th column. If &lt;code&gt;ax&lt;/code&gt; is a list of axes, &lt;code&gt;axes_[i]&lt;/code&gt; is the i-th item in &lt;code&gt;ax&lt;/code&gt;. Elements that are None correspond to a nonexisting axes in that position.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd2bdf4031503663b9e9168a5bd9a1faa112780b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ax&lt;/code&gt; is an axes or None, &lt;code&gt;contours_[i, j]&lt;/code&gt; is the partial dependence plot on the i-th row and j-th column. If &lt;code&gt;ax&lt;/code&gt; is a list of axes, &lt;code&gt;contours_[i]&lt;/code&gt; is the partial dependence plot corresponding to the i-th item in &lt;code&gt;ax&lt;/code&gt;. Elements that are None correspond to a nonexisting axes or an axes that does not include a contour plot.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16daa78b71c8fbb0a04353048c9be677f4bd1a67" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ax&lt;/code&gt; is an axes or None, &lt;code&gt;lines_[i, j]&lt;/code&gt; is the partial dependence curve on the i-th row and j-th column. If &lt;code&gt;ax&lt;/code&gt; is a list of axes, &lt;code&gt;lines_[i]&lt;/code&gt; is the partial dependence curve corresponding to the i-th item in &lt;code&gt;ax&lt;/code&gt;. Elements that are None correspond to a nonexisting axes or an axes that does not include a line plot.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b7c522014bc873fbd61bfb64d47b7833096d1b1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ax&lt;/code&gt; is an axes or None, &lt;code&gt;vlines_[i, j]&lt;/code&gt; is the line collection representing the x axis deciles of the i-th row and j-th column. If &lt;code&gt;ax&lt;/code&gt; is a list of axes, &lt;code&gt;vlines_[i]&lt;/code&gt; corresponds to the i-th item in &lt;code&gt;ax&lt;/code&gt;. Elements that are None correspond to a nonexisting axes or an axes that does not include a PDP plot. .. versionadded:: 0.23</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03e758847856246528ffcca83ba803cf5d3e9c24" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ax&lt;/code&gt; is an axes or None, &lt;code&gt;vlines_[i, j]&lt;/code&gt; is the line collection representing the y axis deciles of the i-th row and j-th column. If &lt;code&gt;ax&lt;/code&gt; is a list of axes, &lt;code&gt;vlines_[i]&lt;/code&gt; corresponds to the i-th item in &lt;code&gt;ax&lt;/code&gt;. Elements that are None correspond to a nonexisting axes or an axes that does not include a 2-way plot. .. versionadded:: 0.23</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e5d3c60fbe26a21b3685b7cd50d8157796cb85c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ax&lt;/code&gt; is an axes or None, the &lt;code&gt;bounding_ax_&lt;/code&gt; is the axes where the grid of partial dependence plots are drawn. If &lt;code&gt;ax&lt;/code&gt; is a list of axes or a numpy array of axes, &lt;code&gt;bounding_ax_&lt;/code&gt; is None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a88caf8f6b6232395c9c1524315c6ed672bcf763" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=0&lt;/code&gt; and X is encoded as a CSR matrix;</source>
          <target state="translated">Si &lt;code&gt;axis=0&lt;/code&gt; y X se codifica como una matriz CSR;</target>
        </trans-unit>
        <trans-unit id="160d044408c23f7840586e9cc7d8cab0e43ba9b5" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=0&lt;/code&gt;, boolean and integer array-like, integer slice, and scalar integer are supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b74f02ef0c3e3aceaf2040e39764c8bf5d153fee" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=0&lt;/code&gt;, then impute along columns.</source>
          <target state="translated">Si &lt;code&gt;axis=0&lt;/code&gt; , impute a lo largo de las columnas.</target>
        </trans-unit>
        <trans-unit id="231cba4e2ed9eee1fca5c3a6b02c0c6f66c47550" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=1&lt;/code&gt; and X is encoded as a CSC matrix.</source>
          <target state="translated">Si el &lt;code&gt;axis=1&lt;/code&gt; y X est&amp;aacute; codificado como una matriz CSC.</target>
        </trans-unit>
        <trans-unit id="4405a4c1e894889993d89bb6694cef1a6a8f7db3" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=1&lt;/code&gt;, then impute along rows.</source>
          <target state="translated">Si &lt;code&gt;axis=1&lt;/code&gt; , impute a lo largo de las filas.</target>
        </trans-unit>
        <trans-unit id="afe718681bc04a6b175f3e0dbacf56b2e22d3277" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=1&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf71a4a70c1ff1b9076f02c43d89e78c4b0ffc27" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;backend&lt;/code&gt; is a string it must match a previously registered implementation using the &lt;code&gt;register_parallel_backend&lt;/code&gt; function.</source>
          <target state="translated">Si el &lt;code&gt;backend&lt;/code&gt; es una cadena, debe coincidir con una implementaci&amp;oacute;n registrada previamente usando la funci&amp;oacute;n &lt;code&gt;register_parallel_backend&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6456a4494f2ba1f052aff4cf6d35ef66e787bc14" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;base_estimator&lt;/code&gt; is None, then &lt;code&gt;base_estimator=sklearn.linear_model.LinearRegression()&lt;/code&gt; is used for target values of dtype float.</source>
          <target state="translated">Si &lt;code&gt;base_estimator&lt;/code&gt; es None, entonces &lt;code&gt;base_estimator=sklearn.linear_model.LinearRegression()&lt;/code&gt; se usa para los valores objetivo de dtype float.</target>
        </trans-unit>
        <trans-unit id="898731158b64382ef9aad2307b39d22b5cd2a315" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;dense&lt;/code&gt; return &lt;code&gt;Y&lt;/code&gt; in the dense binary indicator format. If &lt;code&gt;'sparse'&lt;/code&gt; return &lt;code&gt;Y&lt;/code&gt; in the sparse binary indicator format. &lt;code&gt;False&lt;/code&gt; returns a list of lists of labels.</source>
          <target state="translated">Si es &lt;code&gt;dense&lt;/code&gt; devuelve &lt;code&gt;Y&lt;/code&gt; en el formato de indicador binario denso. Si es &lt;code&gt;'sparse'&lt;/code&gt; devuelve &lt;code&gt;Y&lt;/code&gt; en el formato de indicador binario disperso. &lt;code&gt;False&lt;/code&gt; devuelve una lista de listas de etiquetas.</target>
        </trans-unit>
        <trans-unit id="b1213caecc623f2a5139e82ba5db339edb5f6265" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;fit_intercept&lt;/code&gt; is set to False, the intercept is set to zero. &lt;code&gt;intercept_&lt;/code&gt; is of shape (1,) when the given problem is binary. In particular, when &lt;code&gt;multi_class=&amp;rsquo;multinomial&amp;rsquo;&lt;/code&gt;, &lt;code&gt;intercept_&lt;/code&gt; corresponds to outcome 1 (True) and &lt;code&gt;-intercept_&lt;/code&gt; corresponds to outcome 0 (False).</source>
          <target state="translated">Si &lt;code&gt;fit_intercept&lt;/code&gt; se establece en False, la intersecci&amp;oacute;n se establece en cero. &lt;code&gt;intercept_&lt;/code&gt; tiene forma (1,) cuando el problema dado es binario. En particular, cuando &lt;code&gt;multi_class=&amp;rsquo;multinomial&amp;rsquo;&lt;/code&gt; , &lt;code&gt;intercept_&lt;/code&gt; corresponde al resultado 1 (Verdadero) e &lt;code&gt;-intercept_&lt;/code&gt; corresponde al resultado 0 (Falso).</target>
        </trans-unit>
        <trans-unit id="5adb2b902dec2303b1749b6ba9f10123fe5ab03c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;fit_intercept&lt;/code&gt; is set to False, the intercept is set to zero. &lt;code&gt;intercept_&lt;/code&gt; is of shape (1,) when the given problem is binary. In particular, when &lt;code&gt;multi_class='multinomial'&lt;/code&gt;, &lt;code&gt;intercept_&lt;/code&gt; corresponds to outcome 1 (True) and &lt;code&gt;-intercept_&lt;/code&gt; corresponds to outcome 0 (False).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4504cae87026fef1f6989cfa20e2e5bc171d37e0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;fit_intercept&lt;/code&gt; is set to False, the intercept is set to zero. &lt;code&gt;intercept_&lt;/code&gt; is of shape(1,) when the problem is binary.</source>
          <target state="translated">Si &lt;code&gt;fit_intercept&lt;/code&gt; se establece en False, la intersecci&amp;oacute;n se establece en cero. &lt;code&gt;intercept_&lt;/code&gt; tiene forma (1,) cuando el problema es binario.</target>
        </trans-unit>
        <trans-unit id="646836188c841e4fea39e4e4200d1f27e6191986" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;loss&lt;/code&gt; is a callable, then it should be a function that takes two arrays as inputs, the true and predicted value and returns a 1-D array with the i-th value of the array corresponding to the loss on &lt;code&gt;X[i]&lt;/code&gt;.</source>
          <target state="translated">Si la &lt;code&gt;loss&lt;/code&gt; es invocable, entonces deber&amp;iacute;a ser una funci&amp;oacute;n que tome dos matrices como entradas, el valor verdadero y predicho, y devuelva una matriz 1-D con el i-&amp;eacute;simo valor de la matriz correspondiente a la p&amp;eacute;rdida en &lt;code&gt;X[i]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c42d62680a26d66fc0f439c634f24ee01c670c77" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;memory&lt;/code&gt; is not joblib.Memory-like.</source>
          <target state="translated">Si la &lt;code&gt;memory&lt;/code&gt; no es joblib.Memory-like.</target>
        </trans-unit>
        <trans-unit id="e14dd7c153267d74f6b2214ce66bcf041482d792" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_bins&lt;/code&gt; is an array, and there is an ignored feature at index &lt;code&gt;i&lt;/code&gt;, &lt;code&gt;n_bins[i]&lt;/code&gt; will be ignored.</source>
          <target state="translated">Si &lt;code&gt;n_bins&lt;/code&gt; es una matriz y hay una caracter&amp;iacute;stica ignorada en el &amp;iacute;ndice &lt;code&gt;i&lt;/code&gt; , &lt;code&gt;n_bins[i]&lt;/code&gt; se ignorar&amp;aacute;n.</target>
        </trans-unit>
        <trans-unit id="20ab457ec31da79f104a0f7a337ba6bfe94b5438" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_clusters&lt;/code&gt; is set to None, the data is reduced from 100,000 samples to a set of 158 clusters. This can be viewed as a preprocessing step before the final (global) clustering step that further reduces these 158 clusters to 100 clusters.</source>
          <target state="translated">Si &lt;code&gt;n_clusters&lt;/code&gt; se establece en None, los datos se reducen de 100.000 muestras a un conjunto de 158 conglomerados. Esto puede verse como un paso de preprocesamiento antes del paso de agrupamiento final (global) que reduce a&amp;uacute;n m&amp;aacute;s estos 158 grupos a 100 grupos.</target>
        </trans-unit>
        <trans-unit id="1769c2fe615105013ff722090827f85ac960dff9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_components == 'mle'&lt;/code&gt; and &lt;code&gt;svd_solver == 'full'&lt;/code&gt;, Minka&amp;rsquo;s MLE is used to guess the dimension. Use of &lt;code&gt;n_components == 'mle'&lt;/code&gt; will interpret &lt;code&gt;svd_solver == 'auto'&lt;/code&gt; as &lt;code&gt;svd_solver == 'full'&lt;/code&gt;.</source>
          <target state="translated">Si &lt;code&gt;n_components == 'mle'&lt;/code&gt; y &lt;code&gt;svd_solver == 'full'&lt;/code&gt; , se utiliza el MLE de Minka para adivinar la dimensi&amp;oacute;n. El uso de &lt;code&gt;n_components == 'mle'&lt;/code&gt; interpretar&amp;aacute; &lt;code&gt;svd_solver == 'auto'&lt;/code&gt; como &lt;code&gt;svd_solver == 'full'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="959758e689ea656dd0e72e3bda18b0a45bbef2e0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_components&lt;/code&gt; is not set then all components are stored and the sum of the ratios is equal to 1.0.</source>
          <target state="translated">Si no se establece &lt;code&gt;n_components&lt;/code&gt; , todos los componentes se almacenan y la suma de las relaciones es igual a 1.0.</target>
        </trans-unit>
        <trans-unit id="712e62a0190856257c5f6877b0d11f259bd408b5" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_components&lt;/code&gt; is strictly smaller than the dimensionality of the inputs passed to &lt;a href=&quot;#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt;, the identity matrix will be truncated to the first &lt;code&gt;n_components&lt;/code&gt; rows.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4aaa2df3fa37c88b24d06638ef7188d7e8ebe112" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_jobs&lt;/code&gt; was set to a value higher than one, the data is copied for each parameter setting(and not &lt;code&gt;n_jobs&lt;/code&gt; times). This is done for efficiency reasons if individual jobs take very little time, but may raise errors if the dataset is large and not enough memory is available. A workaround in this case is to set &lt;code&gt;pre_dispatch&lt;/code&gt;. Then, the memory is copied only &lt;code&gt;pre_dispatch&lt;/code&gt; many times. A reasonable value for &lt;code&gt;pre_dispatch&lt;/code&gt; is &lt;code&gt;2 * n_jobs&lt;/code&gt;.</source>
          <target state="translated">Si &lt;code&gt;n_jobs&lt;/code&gt; se estableci&amp;oacute; en un valor superior a uno, los datos se copian para cada configuraci&amp;oacute;n de par&amp;aacute;metro (y no &lt;code&gt;n_jobs&lt;/code&gt; veces). Esto se hace por razones de eficiencia si los trabajos individuales toman muy poco tiempo, pero pueden generar errores si el conjunto de datos es grande y no hay suficiente memoria disponible. Una soluci&amp;oacute;n alternativa en este caso es establecer &lt;code&gt;pre_dispatch&lt;/code&gt; . Entonces, la memoria se copia solo &lt;code&gt;pre_dispatch&lt;/code&gt; muchas veces. Un valor razonable para &lt;code&gt;pre_dispatch&lt;/code&gt; es &lt;code&gt;2 * n_jobs&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="53682a81a25d0884d79ca09b064b0fc6e7cabd67" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_jobs&lt;/code&gt; was set to a value higher than one, the data is copied for each point in the grid (and not &lt;code&gt;n_jobs&lt;/code&gt; times). This is done for efficiency reasons if individual jobs take very little time, but may raise errors if the dataset is large and not enough memory is available. A workaround in this case is to set &lt;code&gt;pre_dispatch&lt;/code&gt;. Then, the memory is copied only &lt;code&gt;pre_dispatch&lt;/code&gt; many times. A reasonable value for &lt;code&gt;pre_dispatch&lt;/code&gt; is &lt;code&gt;2 * n_jobs&lt;/code&gt;.</source>
          <target state="translated">Si &lt;code&gt;n_jobs&lt;/code&gt; se estableci&amp;oacute; en un valor superior a uno, los datos se copian para cada punto de la cuadr&amp;iacute;cula (y no &lt;code&gt;n_jobs&lt;/code&gt; veces). Esto se hace por razones de eficiencia si los trabajos individuales toman muy poco tiempo, pero pueden generar errores si el conjunto de datos es grande y no hay suficiente memoria disponible. Una soluci&amp;oacute;n alternativa en este caso es establecer &lt;code&gt;pre_dispatch&lt;/code&gt; . Entonces, la memoria se copia solo &lt;code&gt;pre_dispatch&lt;/code&gt; muchas veces. Un valor razonable para &lt;code&gt;pre_dispatch&lt;/code&gt; es &lt;code&gt;2 * n_jobs&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c1cc035dd2ff12188f95601d6fe5c4679ad6bb78" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_samples == 10000&lt;/code&gt;, storing &lt;code&gt;X&lt;/code&gt; as a NumPy array of type float32 would require 10000 x 100000 x 4 bytes = &lt;strong&gt;4GB in RAM&lt;/strong&gt; which is barely manageable on today&amp;rsquo;s computers.</source>
          <target state="translated">Si &lt;code&gt;n_samples == 10000&lt;/code&gt; , almacenar &lt;code&gt;X&lt;/code&gt; como una matriz NumPy de tipo float32 requerir&amp;iacute;a 10000 x 100000 x 4 bytes = &lt;strong&gt;4 GB de RAM, lo&lt;/strong&gt; que apenas es manejable en las computadoras actuales.</target>
        </trans-unit>
        <trans-unit id="dd40778e7a383f2053d98b9a07e6219944c6316f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;needs_proba=False&lt;/code&gt; and &lt;code&gt;needs_threshold=False&lt;/code&gt;, the score function is supposed to accept the output of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict&quot;&gt;predict&lt;/a&gt;. If &lt;code&gt;needs_proba=True&lt;/code&gt;, the score function is supposed to accept the output of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt; (For binary &lt;code&gt;y_true&lt;/code&gt;, the score function is supposed to accept probability of the positive class). If &lt;code&gt;needs_threshold=True&lt;/code&gt;, the score function is supposed to accept the output of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e65ba558868cb56b0c8a76632ea67901b254afe" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;normalize == True&lt;/code&gt;, return the average Jaccard similarity coefficient, else it returns the sum of the Jaccard similarity coefficient over the sample set.</source>
          <target state="translated">Si &lt;code&gt;normalize == True&lt;/code&gt; , devuelve el coeficiente de similitud de Jaccard promedio; de lo contrario, devuelve la suma del coeficiente de similitud de Jaccard sobre el conjunto de muestra.</target>
        </trans-unit>
        <trans-unit id="c606413521700e073d3e669024415faa2300a113" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;normalize == True&lt;/code&gt;, return the fraction of correctly classified samples (float), else returns the number of correctly classified samples (int).</source>
          <target state="translated">Si &lt;code&gt;normalize == True&lt;/code&gt; , devuelve la fracci&amp;oacute;n de muestras clasificadas correctamente (flotante), de lo contrario devuelve el n&amp;uacute;mero de muestras clasificadas correctamente (int).</target>
        </trans-unit>
        <trans-unit id="cd9dc36a4d7167817c2823908b4ce633913b9765" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;normalize == True&lt;/code&gt;, return the fraction of misclassifications (float), else it returns the number of misclassifications (int).</source>
          <target state="translated">Si &lt;code&gt;normalize == True&lt;/code&gt; , devuelve la fracci&amp;oacute;n de errores de clasificaci&amp;oacute;n (flotante), de lo contrario, devuelve el n&amp;uacute;mero de errores de clasificaci&amp;oacute;n (int).</target>
        </trans-unit>
        <trans-unit id="4260d2abf4eeb10994306d99a6424e7eb5ca19c8" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;order='random'&lt;/code&gt;, determines random number generation for the chain order. In addition, it controls the random seed given at each &lt;code&gt;base_estimator&lt;/code&gt; at each chaining iteration. Thus, it is only used when &lt;code&gt;base_estimator&lt;/code&gt; exposes a &lt;code&gt;random_state&lt;/code&gt;. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0b860961bc5b4a4c45189c0fd4de5c2d61f1ab4" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;out=None&lt;/code&gt;, returns a new array containing the mean values, otherwise a reference to the output array is returned.</source>
          <target state="translated">Si &lt;code&gt;out=None&lt;/code&gt; , devuelve una nueva matriz que contiene los valores medios; de lo contrario, se devuelve una referencia a la matriz de salida.</target>
        </trans-unit>
        <trans-unit id="a1e72f87e91fc5bb6f8882ece59a46bf9ee089e2" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;pos_label is None&lt;/code&gt; and in binary classification, this function returns the average precision, recall and F-measure if &lt;code&gt;average&lt;/code&gt; is one of &lt;code&gt;'micro'&lt;/code&gt;, &lt;code&gt;'macro'&lt;/code&gt;, &lt;code&gt;'weighted'&lt;/code&gt; or &lt;code&gt;'samples'&lt;/code&gt;.</source>
          <target state="translated">Si &lt;code&gt;pos_label is None&lt;/code&gt; y en clasificaci&amp;oacute;n binaria, esta funci&amp;oacute;n devuelve la precisi&amp;oacute;n promedio, recuperaci&amp;oacute;n y medida F si el &lt;code&gt;average&lt;/code&gt; es uno de &lt;code&gt;'micro'&lt;/code&gt; , &lt;code&gt;'macro'&lt;/code&gt; , &lt;code&gt;'weighted'&lt;/code&gt; o &lt;code&gt;'samples'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="933b8be58a37dcefc6ca9fd3f4735aba59bace4c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;probability=True&lt;/code&gt;, it corresponds to the parameters learned in Platt scaling to produce probability estimates from decision values. If &lt;code&gt;probability=False&lt;/code&gt;, it&amp;rsquo;s an empty array. Platt scaling uses the logistic function &lt;code&gt;1 / (1 + exp(decision_value * probA_ + probB_))&lt;/code&gt; where &lt;code&gt;probA_&lt;/code&gt; and &lt;code&gt;probB_&lt;/code&gt; are learned from the dataset &lt;a href=&quot;#r20c70293ef72-2&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt;. For more information on the multiclass case and training procedure see section 8 of &lt;a href=&quot;#r20c70293ef72-1&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="afcc3cf20f075d3a281dbe1f0f610f65f9ef38a7" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;probability=True&lt;/code&gt;, it corresponds to the parameters learned in Platt scaling to produce probability estimates from decision values. If &lt;code&gt;probability=False&lt;/code&gt;, it&amp;rsquo;s an empty array. Platt scaling uses the logistic function &lt;code&gt;1 / (1 + exp(decision_value * probA_ + probB_))&lt;/code&gt; where &lt;code&gt;probA_&lt;/code&gt; and &lt;code&gt;probB_&lt;/code&gt; are learned from the dataset &lt;a href=&quot;#r9709ce4a60d3-2&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt;. For more information on the multiclass case and training procedure see section 8 of &lt;a href=&quot;#r9709ce4a60d3-1&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bb4c6eca31ede3ca3e8fe5a9b41ecd9a55b266b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;return_path==True&lt;/code&gt; returns the entire path, else returns only the last point of the path.</source>
          <target state="translated">Si &lt;code&gt;return_path==True&lt;/code&gt; devuelve la ruta completa, de lo contrario solo devuelve el &amp;uacute;ltimo punto de la ruta.</target>
        </trans-unit>
        <trans-unit id="9e477bb8072307702a812f869b8166fe31bf9ca0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;smooth_idf=True&lt;/code&gt; (the default), the constant &amp;ldquo;1&amp;rdquo; is added to the numerator and denominator of the idf as if an extra document was seen containing every term in the collection exactly once, which prevents zero divisions: idf(d, t) = log [ (1 + n) / (1 + df(d, t)) ] + 1.</source>
          <target state="translated">Si &lt;code&gt;smooth_idf=True&lt;/code&gt; (el valor predeterminado), la constante &quot;1&quot; se agrega al numerador y al denominador de la idf como si se viera un documento adicional que contiene cada t&amp;eacute;rmino de la colecci&amp;oacute;n exactamente una vez, lo que evita las divisiones cero: idf (d, t ) = log [(1 + n) / (1 + gl (d, t))] + 1.</target>
        </trans-unit>
        <trans-unit id="7e7ad1036fa8cee418b26fc730608087f9208f2c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;smooth_idf=True&lt;/code&gt; (the default), the constant &amp;ldquo;1&amp;rdquo; is added to the numerator and denominator of the idf as if an extra document was seen containing every term in the collection exactly once, which prevents zero divisions: idf(t) = log [ (1 + n) / (1 + df(t)) ] + 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f772487671a5560a2a2bb3464b54cf0bad5b348" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;svd_solver == 'arpack'&lt;/code&gt;, the number of components must be strictly less than the minimum of n_features and n_samples.</source>
          <target state="translated">Si &lt;code&gt;svd_solver == 'arpack'&lt;/code&gt; , el n&amp;uacute;mero de componentes debe ser estrictamente menor que el m&amp;iacute;nimo de n_features y n_samples.</target>
        </trans-unit>
        <trans-unit id="abdb8ed2b871d03510343cf9ee77736674d298ab" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;validate&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;X&lt;/code&gt; will be checked.</source>
          <target state="translated">Si &lt;code&gt;validate&lt;/code&gt; es &lt;code&gt;True&lt;/code&gt; , se marcar&amp;aacute; &lt;code&gt;X&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5cfb594032bd50fcef2738a25df520e95867f411" translate="yes" xml:space="preserve">
          <source>If C is a ground truth class assignment and K the clustering, let us define \(a\) and \(b\) as:</source>
          <target state="translated">Si C es una asignación de clase de la verdad de la tierra y K la agrupación,vamos a definir como..:</target>
        </trans-unit>
        <trans-unit id="40e72ab25b1921db07187a1c526cc9080a10eaea" translate="yes" xml:space="preserve">
          <source>If False, X will be overwritten. &lt;code&gt;copy=False&lt;/code&gt; can be used to save memory but is unsafe for general use.</source>
          <target state="translated">Si es False, X se sobrescribir&amp;aacute;. &lt;code&gt;copy=False&lt;/code&gt; puede usarse para ahorrar memoria, pero no es seguro para uso general.</target>
        </trans-unit>
        <trans-unit id="b5379fd8e8700833a560e6ab84ea58c40e10b6a8" translate="yes" xml:space="preserve">
          <source>If False, data passed to fit are overwritten and running fit(X).transform(X) will not yield the expected results, use fit_transform(X) instead.</source>
          <target state="translated">Si es falso,los datos pasados a fit se sobrescriben y la ejecución de fit(X).transform(X)no dará los resultados esperados,utilice fit_transform(X)en su lugar.</target>
        </trans-unit>
        <trans-unit id="3d545281a4ef31d03ffb244079b728a3c5cc8b18" translate="yes" xml:space="preserve">
          <source>If False, data passed to fit are overwritten. Defaults to True.</source>
          <target state="translated">Si es falsa,los datos pasados para encajar se sobrescriben.Por defecto es Verdadero.</target>
        </trans-unit>
        <trans-unit id="4bf616e8d9d604d2525c59d889782525e410270c" translate="yes" xml:space="preserve">
          <source>If False, distances will not be returned</source>
          <target state="translated">Si es falso,las distancias no serán devueltas</target>
        </trans-unit>
        <trans-unit id="b4145c6e6cc098818614b51aca0cae30eca8ed94" translate="yes" xml:space="preserve">
          <source>If False, distances will not be returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8cdf8e9cb326e6212f67c80aca3a4f04326fc4c" translate="yes" xml:space="preserve">
          <source>If False, raise a IOError if the data is not locally available instead of trying to download the data from the source site.</source>
          <target state="translated">Si es falsa,levante un IOError si los datos no están disponibles localmente en lugar de intentar descargar los datos del sitio de origen.</target>
        </trans-unit>
        <trans-unit id="707f36c34b2f81eacbaf143a8e62cb9371b1332e" translate="yes" xml:space="preserve">
          <source>If False, raise an IOError if the data is not locally available instead of trying to download the data from the source site.</source>
          <target state="translated">Si es falsa,levante un IOError si los datos no están disponibles localmente en lugar de intentar descargar los datos del sitio de origen.</target>
        </trans-unit>
        <trans-unit id="d32001af2bcb0806daa431ab8cf432f700c0bb79" translate="yes" xml:space="preserve">
          <source>If False, the imputer mask will be a numpy array.</source>
          <target state="translated">Si es falsa,la máscara imputadora será un conjunto de entumecimiento.</target>
        </trans-unit>
        <trans-unit id="2823ebb07c9bdb5cae0bfca227f5db48d585ba5a" translate="yes" xml:space="preserve">
          <source>If False, the input arrays X and dictionary will not be checked.</source>
          <target state="translated">Si es falso,las matrices de entrada X y el diccionario no se comprobarán.</target>
        </trans-unit>
        <trans-unit id="bd8e933f9aa74b9b27da566d4ffb96f4e62218cf" translate="yes" xml:space="preserve">
          <source>If False, the input arrays X and y will not be checked.</source>
          <target state="translated">Si es falso,no se comprobarán las matrices de entrada X e y.</target>
        </trans-unit>
        <trans-unit id="85aa52dd8c7d5d29b6bebfd616a7ca3fe91cde14" translate="yes" xml:space="preserve">
          <source>If False, the projected data uses a sparse representation if the input is sparse.</source>
          <target state="translated">Si son falsos,los datos proyectados utilizan una representación escasa si la entrada es escasa.</target>
        </trans-unit>
        <trans-unit id="7bfec8f3204bdf713e2d3557ec53ea6f3960ad24" translate="yes" xml:space="preserve">
          <source>If False, there is no input validation.</source>
          <target state="translated">Si es falso,no hay validación de entrada.</target>
        </trans-unit>
        <trans-unit id="a67320198a0b746d35fcc941198f1221ee73c87b" translate="yes" xml:space="preserve">
          <source>If False, try to avoid a copy and do inplace scaling instead. This is not guaranteed to always work inplace; e.g. if the data is not a NumPy array or scipy.sparse CSR matrix, a copy may still be returned.</source>
          <target state="translated">Si es falso,trata de evitar una copia y haz un escalado en el lugar.No se garantiza que esto funcione siempre en el lugar;por ejemplo,si los datos no son una matriz NumPy o una matriz CSR scipy.sparse,puede que se devuelva una copia.</target>
        </trans-unit>
        <trans-unit id="fcd08eda0bca1685e28de89ae046095006b92653" translate="yes" xml:space="preserve">
          <source>If None (default), load all the categories. If not None, list of category names to load (other categories ignored).</source>
          <target state="translated">Si no hay ninguna (por defecto),cargue todas las categorías.Si no hay ninguna,lista de nombres de categorías a cargar (otras categorías ignoradas).</target>
        </trans-unit>
        <trans-unit id="7c0ab0b638c1cad0f1492e60796eecd4f321a731" translate="yes" xml:space="preserve">
          <source>If None (default), then draw &lt;code&gt;X.shape[0]&lt;/code&gt; samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7cbd99fe721a3cd173045eddaf688b83e7620c1" translate="yes" xml:space="preserve">
          <source>If None the estimator&amp;rsquo;s default scorer, if available, is used.</source>
          <target state="translated">Si es Ninguno, se utiliza el puntaje predeterminado del estimador, si est&amp;aacute; disponible.</target>
        </trans-unit>
        <trans-unit id="8c0f950a52950ceff35d04e0ab42f83a05b3adb9" translate="yes" xml:space="preserve">
          <source>If None the estimator&amp;rsquo;s score method is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96ad58db5ee1b903109c173fcab72b0955bb0408" translate="yes" xml:space="preserve">
          <source>If None, defaults to 1.0 / n_features</source>
          <target state="translated">Si no hay ninguno,el valor por defecto es 1.0/n_funciones</target>
        </trans-unit>
        <trans-unit id="e5ce9a9046a52014390758ba790166ae01779c1f" translate="yes" xml:space="preserve">
          <source>If None, do not try to decode the content of the files (e.g. for images or other non-text content). If not None, encoding to use to decode text files to Unicode if load_content is True.</source>
          <target state="translated">Si no hay ninguno,no intente decodificar el contenido de los archivos (por ejemplo,para imágenes u otro contenido no textual).Si no es None,codificar para usar para decodificar archivos de texto a Unicode si load_content es True.</target>
        </trans-unit>
        <trans-unit id="3e5e8d666168a7a15a80edb16364256ae0a379e4" translate="yes" xml:space="preserve">
          <source>If None, no stop words will be used. max_df can be set to a value in the range [0.7, 1.0) to automatically detect and filter stop words based on intra corpus document frequency of terms.</source>
          <target state="translated">Si no hay ninguna,no se usarán palabras de parada.max_df puede ajustarse a un valor en el rango [0,7,1,0]para detectar y filtrar automáticamente las palabras de parada en función de la frecuencia de los términos del documento intracorpóreo.</target>
        </trans-unit>
        <trans-unit id="02542a43a2f09f5328657402d69f49ce442cb6c2" translate="yes" xml:space="preserve">
          <source>If None, pairwise_distances_chunked returns a generator of vertical chunks of the distance matrix.</source>
          <target state="translated">Si es None,pairwise_distances_chunked devuelve un generador de trozos verticales de la matriz de distancia.</target>
        </trans-unit>
        <trans-unit id="eb5d73cb83520641b0e2c815c109159135d569cc" translate="yes" xml:space="preserve">
          <source>If None, the estimator&amp;rsquo;s default scorer (if available) is used.</source>
          <target state="translated">Si es Ninguno, se usa el puntaje predeterminado del estimador (si est&amp;aacute; disponible).</target>
        </trans-unit>
        <trans-unit id="43ea051b06405f0316e7696e80296e11d93edbf6" translate="yes" xml:space="preserve">
          <source>If None, the estimator&amp;rsquo;s score method is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="651c3653c15c90a6722a00465ba57c19c30adb9b" translate="yes" xml:space="preserve">
          <source>If None, the threshold is assumed to be half way between neg_label and pos_label.</source>
          <target state="translated">Si no hay ninguno,se supone que el umbral está a mitad de camino entre neg_label y pos_label.</target>
        </trans-unit>
        <trans-unit id="ac652d29bc285e4e46f5aaf2fe5415c63aee1f09" translate="yes" xml:space="preserve">
          <source>If None, then &lt;code&gt;max_features=n_features&lt;/code&gt;.</source>
          <target state="translated">Si es Ninguno, entonces &lt;code&gt;max_features=n_features&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2f9e5ee96434f57529c2481b71d631d9dd0cb5e7" translate="yes" xml:space="preserve">
          <source>If True (default), the squared error norm is divided by n_features. If False, the squared error norm is not rescaled.</source>
          <target state="translated">Si es True (por defecto),la norma de error al cuadrado se divide por n_características.Si es Falso,la norma de error al cuadrado no se reajusta.</target>
        </trans-unit>
        <trans-unit id="da82574bb396bf8045c493d20398be74e4e9ef51" translate="yes" xml:space="preserve">
          <source>If True (default), then include a bias column, the feature in which all polynomial powers are zero (i.e. a column of ones - acts as an intercept term in a linear model).</source>
          <target state="translated">Si es True (por defecto),entonces incluya una columna de sesgo,la característica en la que todas las potencias polinómicas son cero (es decir,una columna de unos-actúa como un término de intercepción en un modelo lineal).</target>
        </trans-unit>
        <trans-unit id="d150b2a4c21e929dfd726f6463d03ca9f005e91a" translate="yes" xml:space="preserve">
          <source>If True (default), transform will raise an error when there are features with missing values in transform that have no missing values in fit This is applicable only when &lt;code&gt;features=&quot;missing-only&quot;&lt;/code&gt;.</source>
          <target state="translated">Si es Verdadero (predeterminado), la transformaci&amp;oacute;n generar&amp;aacute; un error cuando hay entidades con valores perdidos en la transformaci&amp;oacute;n que no tienen valores perdidos en el ajuste. Esto es aplicable solo cuando &lt;code&gt;features=&quot;missing-only&quot;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="9da3cf1a0e0153fc6c646a1aa71f68e34d8d27f5" translate="yes" xml:space="preserve">
          <source>If True (default), transform will raise an error when there are features with missing values in transform that have no missing values in fit. This is applicable only when &lt;code&gt;features=&quot;missing-only&quot;&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4fe165b3f600e13152308080cc2a736269c867b" translate="yes" xml:space="preserve">
          <source>If True and &lt;a href=&quot;#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; has been called before, the solution of the previous call to &lt;a href=&quot;#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; is used as the initial linear transformation (&lt;code&gt;n_components&lt;/code&gt; and &lt;code&gt;init&lt;/code&gt; will be ignored).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d91ad850130f94be79fb668041bf3eecd01a29b0" translate="yes" xml:space="preserve">
          <source>If True and if X is sparse, the method also returns the intercept, and the solver is automatically changed to &amp;lsquo;sag&amp;rsquo;. This is only a temporary fix for fitting the intercept with sparse data. For dense data, use sklearn.linear_model._preprocess_data before your regression.</source>
          <target state="translated">Si es Verdadero y si X es escaso, el m&amp;eacute;todo tambi&amp;eacute;n devuelve la intersecci&amp;oacute;n y el solucionador se cambia autom&amp;aacute;ticamente a 'hundirse'. Esta es solo una soluci&amp;oacute;n temporal para ajustar la intersecci&amp;oacute;n con datos escasos. Para datos densos, use sklearn.linear_model._preprocess_data antes de su regresi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="d1eef608e634bc22aa5f2e22e802ae927e355666" translate="yes" xml:space="preserve">
          <source>If True returns MSE value, if False returns RMSE value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a68108e0ea5bf983075f127e077ee80517d6dfdd" translate="yes" xml:space="preserve">
          <source>If True the covariance matrices are computed and stored in the &lt;code&gt;self.covariance_&lt;/code&gt; attribute.</source>
          <target state="translated">Si es True, las matrices de covarianza se calculan y almacenan en el atributo &lt;code&gt;self.covariance_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5c5d5facc126a265032a533a4664c8926339ade0" translate="yes" xml:space="preserve">
          <source>If True the full path is stored in the &lt;code&gt;coef_path_&lt;/code&gt; attribute. If you compute the solution for a large problem or many targets, setting &lt;code&gt;fit_path&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt; will lead to a speedup, especially with a small alpha.</source>
          <target state="translated">Si es True, la ruta completa se almacena en el atributo &lt;code&gt;coef_path_&lt;/code&gt; . Si calcula la soluci&amp;oacute;n para un problema grande o muchos objetivos, establecer &lt;code&gt;fit_path&lt;/code&gt; en &lt;code&gt;False&lt;/code&gt; conducir&amp;aacute; a una aceleraci&amp;oacute;n, especialmente con un alfa peque&amp;ntilde;o.</target>
        </trans-unit>
        <trans-unit id="53e960778922c6ba257a9c66f18d0e260655f043" translate="yes" xml:space="preserve">
          <source>If True the function returns the pairwise distance matrix else it returns the componentwise L1 pairwise-distances. Not supported for sparse matrix inputs.</source>
          <target state="translated">Si es True,la función devuelve la matriz de distancias en pares,o bien devuelve las distancias en pares L1 en componentes.No se admite para entradas de matrices escasas.</target>
        </trans-unit>
        <trans-unit id="2546c89362b151bbba35dab463b810d1f7c0a359" translate="yes" xml:space="preserve">
          <source>If True the order of the dataset is shuffled to avoid having images of the same person grouped.</source>
          <target state="translated">Si es cierto,el orden del conjunto de datos se baraja para evitar que se agrupen imágenes de la misma persona.</target>
        </trans-unit>
        <trans-unit id="618a67ac95fc4ccc3385ae319143bf344e1ffb63" translate="yes" xml:space="preserve">
          <source>If True then raise a warning if conversion is required.</source>
          <target state="translated">Si es cierto,entonces,plantea una advertencia si se requiere la conversión.</target>
        </trans-unit>
        <trans-unit id="19362eed638b2dc6d204e12092075aedd87e6e93" translate="yes" xml:space="preserve">
          <source>If True then raise an exception if array is not symmetric.</source>
          <target state="translated">Si es cierto,entonces haz una excepción si la matriz no es simétrica.</target>
        </trans-unit>
        <trans-unit id="baf82faf959595f525e5d5a94c6b8526ad942779" translate="yes" xml:space="preserve">
          <source>If True, X will be copied; else, it may be overwritten.</source>
          <target state="translated">Si es cierto,X será copiado;si no,puede ser sobrescrito.</target>
        </trans-unit>
        <trans-unit id="e25c58f63a5736150718d46a3a4c05d31a44c0e6" translate="yes" xml:space="preserve">
          <source>If True, a &lt;a href=&quot;sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt; transform will stack onto output of the imputer&amp;rsquo;s transform. This allows a predictive estimator to account for missingness despite imputation. If a feature has no missing values at fit/train time, the feature won&amp;rsquo;t appear on the missing indicator even if there are missing values at transform/test time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df1778fbc0c3701b8b17966bdd64201d1f2550fe" translate="yes" xml:space="preserve">
          <source>If True, a &lt;a href=&quot;sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt; transform will stack onto the output of the imputer&amp;rsquo;s transform. This allows a predictive estimator to account for missingness despite imputation. If a feature has no missing values at fit/train time, the feature won&amp;rsquo;t appear on the missing indicator even if there are missing values at transform/test time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa91f074d713faca021e35ddd5331805b9848f9e" translate="yes" xml:space="preserve">
          <source>If True, a copy of X will be created. If False, a copy may still be returned if X&amp;rsquo;s dtype is not a floating point type.</source>
          <target state="translated">Si es True, se crear&amp;aacute; una copia de X. Si es False, a&amp;uacute;n se puede devolver una copia si el dtype de X no es un tipo de coma flotante.</target>
        </trans-unit>
        <trans-unit id="45f6e4d313f4bf3abc200106ce518a942e07ab23" translate="yes" xml:space="preserve">
          <source>If True, a copy of X will be created. If False, imputation will be done in-place whenever possible.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="054b374d036034be5d7258a6a975038eb8fec935" translate="yes" xml:space="preserve">
          <source>If True, a copy of X will be created. If False, imputation will be done in-place whenever possible. Note that, in the following cases, a new copy will always be made, even if &lt;code&gt;copy=False&lt;/code&gt;:</source>
          <target state="translated">Si es True, se crear&amp;aacute; una copia de X. Si es Falso, la imputaci&amp;oacute;n se realizar&amp;aacute; en el lugar siempre que sea posible. Tenga en cuenta que, en los siguientes casos, siempre se realizar&amp;aacute; una nueva copia, incluso si &lt;code&gt;copy=False&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="f237ade75e04520befb53fc36267d58be41dc5ae" translate="yes" xml:space="preserve">
          <source>If True, a persistent copy of the training data is stored in the object. Otherwise, just a reference to the training data is stored, which might cause predictions to change if the data is modified externally.</source>
          <target state="translated">Si es cierto,una copia persistente de los datos de entrenamiento se almacena en el objeto.De lo contrario,sólo se almacena una referencia a los datos de entrenamiento,lo que puede hacer que las predicciones cambien si los datos se modifican externamente.</target>
        </trans-unit>
        <trans-unit id="5b4ca3bdeb594ab34289df8cfc7fa70c9919ad95" translate="yes" xml:space="preserve">
          <source>If True, all non zero counts are set to 1. This is useful for discrete probabilistic models that model binary events rather than integer counts.</source>
          <target state="translated">Si es True,todos los recuentos no nulos se establecen en 1.Esto es útil para los modelos probabilísticos discretos que modelan eventos binarios en lugar de recuentos enteros.</target>
        </trans-unit>
        <trans-unit id="95f1a98443a6aa5501cfb81c289c266bb7baf4d6" translate="yes" xml:space="preserve">
          <source>If True, all non-zero term counts are set to 1. This does not mean outputs will have only 0/1 values, only that the tf term in tf-idf is binary. (Set idf and normalization to False to get 0/1 outputs).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0beec2b2d6b910456e155063f83ec1e59c6c0df1" translate="yes" xml:space="preserve">
          <source>If True, all non-zero term counts are set to 1. This does not mean outputs will have only 0/1 values, only that the tf term in tf-idf is binary. (Set idf and normalization to False to get 0/1 outputs.)</source>
          <target state="translated">Si es True,todos los recuentos de términos que no sean cero se establecen en 1.Esto no significa que las salidas tengan sólo valores 0/1,sólo que el término tf en tf-idf es binario.(Establezca idf y normalización a Falso para obtener salidas 0/1).</target>
        </trans-unit>
        <trans-unit id="b69242de00e60526a79082b37846a2a724d7b3dd" translate="yes" xml:space="preserve">
          <source>If True, center the data before scaling.</source>
          <target state="translated">Si es cierto,centra los datos antes de escalar.</target>
        </trans-unit>
        <trans-unit id="6c9a4d2da449884c97015be12ce056a53dc04757" translate="yes" xml:space="preserve">
          <source>If True, center the data before scaling. This does not work (and will raise an exception) when attempted on sparse matrices, because centering them entails building a dense matrix which in common use cases is likely to be too large to fit in memory.</source>
          <target state="translated">Si es cierto,centra los datos antes de escalar.Esto no funciona (y planteará una excepción)cuando se intente en matrices escasas,porque centrarlos implica construir una matriz densa que en los casos de uso común es probable que sea demasiado grande para caber en la memoria.</target>
        </trans-unit>
        <trans-unit id="9d7135e468914be214009091b1fc11f6721afd0a" translate="yes" xml:space="preserve">
          <source>If True, center the data before scaling. This will cause &lt;code&gt;transform&lt;/code&gt; to raise an exception when attempted on sparse matrices, because centering them entails building a dense matrix which in common use cases is likely to be too large to fit in memory.</source>
          <target state="translated">Si es Verdadero, centre los datos antes de escalar. Esto har&amp;aacute; que la &lt;code&gt;transform&lt;/code&gt; aci&amp;oacute;n genere una excepci&amp;oacute;n cuando se intente en matrices dispersas, porque centrarlas implica construir una matriz densa que, en casos de uso com&amp;uacute;n, es probable que sea demasiado grande para caber en la memoria.</target>
        </trans-unit>
        <trans-unit id="694a00b6963c573c0a68b328feb15483853b44c0" translate="yes" xml:space="preserve">
          <source>If True, compute the log marginal likelihood at each iteration of the optimization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c24f1c3d35266b322135ac3270540ea5ef40a09d" translate="yes" xml:space="preserve">
          <source>If True, compute the objective function at each step of the model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20839df17b3bca6b55533337f17b7c17f0881d1a" translate="yes" xml:space="preserve">
          <source>If True, compute the objective function at each step of the model. Default is False</source>
          <target state="translated">Si es cierto,calcula la función objetivo en cada paso del modelo.Por defecto es Falso</target>
        </trans-unit>
        <trans-unit id="afb80999f635ad0619301e31bb4cd6b353188af0" translate="yes" xml:space="preserve">
          <source>If True, compute the objective function at each step of the model. Default is False.</source>
          <target state="translated">Si es cierto,calcula la función objetivo en cada paso del modelo.El valor por defecto es Falso.</target>
        </trans-unit>
        <trans-unit id="9df36ef1b24eb49a93a9d932c395b3324554689c" translate="yes" xml:space="preserve">
          <source>If True, data are not centered before computation. Useful to work with data whose mean is significantly equal to zero but is not exactly zero. If False, data are centered before computation.</source>
          <target state="translated">Si es cierto,los datos no se centran antes del cálculo.Es útil para trabajar con datos cuya media es significativamente igual a cero pero no es exactamente cero.Si es falso,los datos se centran antes del cálculo.</target>
        </trans-unit>
        <trans-unit id="cdd266c276f30f1ed8fec5e418bed1790d829f9f" translate="yes" xml:space="preserve">
          <source>If True, data are not centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False (default), data are centered before computation.</source>
          <target state="translated">Si es cierto,los datos no se centran antes del cálculo.Es útil cuando se trabaja con datos cuya media es casi,pero no exactamente cero.Si es falso (predeterminado),los datos se centran antes del cálculo.</target>
        </trans-unit>
        <trans-unit id="b4e1adfc1374b7a62eee31a2ac4be08eea958149" translate="yes" xml:space="preserve">
          <source>If True, data are not centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False, data are centered before computation.</source>
          <target state="translated">Si es cierto,los datos no se centran antes del cálculo.Es útil cuando se trabaja con datos cuya media es casi,pero no exactamente cero.Si es falso,los datos se centran antes del cálculo.</target>
        </trans-unit>
        <trans-unit id="4b7584f328528f9b2a426f648be6c8534ecc99c4" translate="yes" xml:space="preserve">
          <source>If True, data will not be centered before computation. Useful to work with data whose mean is significantly equal to zero but is not exactly zero. If False, data will be centered before computation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="899541250010cf3e75fa34e54556cce0c0296945" translate="yes" xml:space="preserve">
          <source>If True, data will not be centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False (default), data will be centered before computation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d925d680717ba978e6037a9fa61e005a509ad73c" translate="yes" xml:space="preserve">
          <source>If True, data will not be centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False, data will be centered before computation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2902b07926590508dee697d1e97c541f35cd531" translate="yes" xml:space="preserve">
          <source>If True, ensure that the output of the random projection is a dense numpy array even if the input and random projection matrix are both sparse. In practice, if the number of components is small the number of zero components in the projected data will be very small and it will be more CPU and memory efficient to use a dense representation.</source>
          <target state="translated">Si es cierto,asegúrese de que la salida de la proyección aleatoria sea una matriz densa y numérica,incluso si la matriz de entrada y la de proyección aleatoria son ambas escasas.En la práctica,si el número de componentes es pequeño,el número de componentes cero en los datos proyectados será muy pequeño y será más eficiente para la CPU y la memoria utilizar una representación densa.</target>
        </trans-unit>
        <trans-unit id="41679ec27e720c4445a3d18e34d01eeadf44de13" translate="yes" xml:space="preserve">
          <source>If True, explicitely compute the weighted within-class covariance matrix when solver is &amp;lsquo;svd&amp;rsquo;. The matrix is always computed and stored for the other solvers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5a6d396b2b3b1ae647f1eed557078cef4ea31ec" translate="yes" xml:space="preserve">
          <source>If True, for binary &lt;code&gt;y_true&lt;/code&gt;, the score function is supposed to accept a 1D &lt;code&gt;y_pred&lt;/code&gt; (i.e., probability of the positive class or the decision function, shape &lt;code&gt;(n_samples,)&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92550063b64465fcb2c6a46cd5346c9970dc1bb3" translate="yes" xml:space="preserve">
          <source>If True, for binary &lt;code&gt;y_true&lt;/code&gt;, the score function is supposed to accept a 1D &lt;code&gt;y_pred&lt;/code&gt; (i.e., probability of the positive class, shape &lt;code&gt;(n_samples,)&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3946c2202800dbed0f15da39a81b563f2054e41" translate="yes" xml:space="preserve">
          <source>If True, individual trees are fit on random subsets of the training data sampled with replacement. If False, sampling without replacement is performed.</source>
          <target state="translated">Si es cierto,los árboles individuales se ajustan en subconjuntos aleatorios de los datos de entrenamiento muestreados con el reemplazo.Si es falso,se realiza un muestreo sin reemplazo.</target>
        </trans-unit>
        <trans-unit id="47a8f3ebe1bf3e97122b0404e375e9c09f1cef3f" translate="yes" xml:space="preserve">
          <source>If True, input X is copied and stored by the model in the &lt;code&gt;X_fit_&lt;/code&gt; attribute. If no further changes will be done to X, setting &lt;code&gt;copy_X=False&lt;/code&gt; saves memory by storing a reference.</source>
          <target state="translated">Si es True, el modelo copia y almacena la entrada X en el atributo &lt;code&gt;X_fit_&lt;/code&gt; . Si no se realizar&amp;aacute;n m&amp;aacute;s cambios en X, la configuraci&amp;oacute;n de &lt;code&gt;copy_X=False&lt;/code&gt; ahorra memoria almacenando una referencia.</target>
        </trans-unit>
        <trans-unit id="396eb3a1b9a656b43a14e28fce4ff1f92f4bae42" translate="yes" xml:space="preserve">
          <source>If True, normalizes each document&amp;rsquo;s feature vector to unit norm using &lt;a href=&quot;sklearn.preprocessing.normalize#sklearn.preprocessing.normalize&quot;&gt;&lt;code&gt;sklearn.preprocessing.normalize&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f3a3bba5e0b6c545bdd5d5451a2769f0ab6a17d" translate="yes" xml:space="preserve">
          <source>If True, only the parameters that were set to non-default values will be printed when printing an estimator. For example, &lt;code&gt;print(SVC())&lt;/code&gt; while True will only print &amp;lsquo;SVC()&amp;rsquo; while the default behaviour would be to print &amp;lsquo;SVC(C=1.0, cache_size=200, &amp;hellip;)&amp;rsquo; with all the non-changed parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e2f5f725dbeca38c6f078963224eb5885ad4abb" translate="yes" xml:space="preserve">
          <source>If True, only the parameters that were set to non-default values will be printed when printing an estimator. For example, &lt;code&gt;print(SVC())&lt;/code&gt; while True will only print &amp;lsquo;SVC()&amp;rsquo;, but would print &amp;lsquo;SVC(C=1.0, cache_size=200, &amp;hellip;)&amp;rsquo; with all the non-changed parameters when False. Default is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10ab7d9c4ef9751f0861c3cfbcd363da08ee1196" translate="yes" xml:space="preserve">
          <source>If True, return a sparse CSR continency matrix. If &lt;code&gt;eps is not None&lt;/code&gt;, and &lt;code&gt;sparse is True&lt;/code&gt;, will throw ValueError.</source>
          <target state="translated">Si es Verdadero, devuelve una matriz de continencia de CSR escasa. Si &lt;code&gt;eps is not None&lt;/code&gt; , y &lt;code&gt;sparse is True&lt;/code&gt; , arrojar&amp;aacute; ValueError.</target>
        </trans-unit>
        <trans-unit id="bbadcb21277fb2fd7500e5e018984adc0515f847" translate="yes" xml:space="preserve">
          <source>If True, return output as dict</source>
          <target state="translated">Si es cierto,devuelva la salida como dict</target>
        </trans-unit>
        <trans-unit id="5d0bfe964a0a56bae92b114342901e57452f609f" translate="yes" xml:space="preserve">
          <source>If True, return the average score across folds, weighted by the number of samples in each test set. In this case, the data is assumed to be identically distributed across the folds, and the loss minimized is the total loss per sample, and not the mean loss across the folds.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c0f661b8fac7f22363a5a1e55327c6967bb56d8" translate="yes" xml:space="preserve">
          <source>If True, return the average score across folds, weighted by the number of samples in each test set. In this case, the data is assumed to be identically distributed across the folds, and the loss minimized is the total loss per sample, and not the mean loss across the folds. If False, return the average score across folds. Default is True, but will change to False in version 0.21, to correspond to the standard definition of cross-validation.</source>
          <target state="translated">Si es cierto,devuelva la puntuación media en los pliegues,ponderada por el número de muestras de cada conjunto de pruebas.En este caso,se supone que los datos están distribuidos de forma idéntica en los pliegues,y la pérdida minimizada es la pérdida total por muestra,y no la pérdida media en los pliegues.Si es falso,devuelva la puntuación media a través de los pliegues.El valor por defecto es True,pero cambiará a False en la versión 0.21,para corresponder a la definición estándar de validación cruzada.</target>
        </trans-unit>
        <trans-unit id="cd7031ac688b02e25258c5831c7d3ea164486db6" translate="yes" xml:space="preserve">
          <source>If True, return the distance between the clusters.</source>
          <target state="translated">Si es cierto,devuelve la distancia entre los grupos.</target>
        </trans-unit>
        <trans-unit id="a6e36ec8e19c4760ce9d4d884ef8627513b82b97" translate="yes" xml:space="preserve">
          <source>If True, returns &lt;code&gt;(data, target)&lt;/code&gt; instead of a &lt;code&gt;Bunch&lt;/code&gt; object. See below for more information about the &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt; object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48eeb388f7c432fd1b00c136703cc691939b77aa" translate="yes" xml:space="preserve">
          <source>If True, returns &lt;code&gt;(data, target)&lt;/code&gt; instead of a Bunch object. See below for more information about the &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt; object.</source>
          <target state="translated">Si es True, devuelve &lt;code&gt;(data, target)&lt;/code&gt; lugar de un objeto Bunch. Consulte a continuaci&amp;oacute;n para obtener m&amp;aacute;s informaci&amp;oacute;n sobre los &lt;code&gt;data&lt;/code&gt; y &lt;code&gt;target&lt;/code&gt; objeto de destino .</target>
        </trans-unit>
        <trans-unit id="b8ef976b3bf0a8c5fe0d328bf69ca77595314915" translate="yes" xml:space="preserve">
          <source>If True, returns &lt;code&gt;(data, target)&lt;/code&gt; instead of a Bunch object. See below for more information about the &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt; objects.</source>
          <target state="translated">Si es True, devuelve &lt;code&gt;(data, target)&lt;/code&gt; lugar de un objeto Bunch. Consulte a continuaci&amp;oacute;n para obtener m&amp;aacute;s informaci&amp;oacute;n sobre los &lt;code&gt;data&lt;/code&gt; y &lt;code&gt;target&lt;/code&gt; objetos de destino .</target>
        </trans-unit>
        <trans-unit id="d467c22a2bd71ab649cbad26364f06a31ce58ac1" translate="yes" xml:space="preserve">
          <source>If True, returns &lt;code&gt;(data.data, data.target)&lt;/code&gt; instead of a Bunch object.</source>
          <target state="translated">Si es True, devuelve &lt;code&gt;(data.data, data.target)&lt;/code&gt; lugar de un objeto Bunch.</target>
        </trans-unit>
        <trans-unit id="248b6d0d481e47f352d5f3203242e6800072c658" translate="yes" xml:space="preserve">
          <source>If True, returns &lt;code&gt;(dataset.data, dataset.target)&lt;/code&gt; instead of a Bunch object. See below for more information about the &lt;code&gt;dataset.data&lt;/code&gt; and &lt;code&gt;dataset.target&lt;/code&gt; object.</source>
          <target state="translated">Si es True, devuelve &lt;code&gt;(dataset.data, dataset.target)&lt;/code&gt; lugar de un objeto Bunch. Consulte a continuaci&amp;oacute;n para obtener m&amp;aacute;s informaci&amp;oacute;n sobre el objeto &lt;code&gt;dataset.data&lt;/code&gt; y &lt;code&gt;dataset.target&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c220af25fde2fda1e9985d78b63166a331905d63" translate="yes" xml:space="preserve">
          <source>If True, scale the data to interquartile range.</source>
          <target state="translated">Si es cierto,escalar los datos al rango intercuartílico.</target>
        </trans-unit>
        <trans-unit id="0f395f8257fe0bdfb8a823c88f3be9843583f8a6" translate="yes" xml:space="preserve">
          <source>If True, scale the data to unit variance (or equivalently, unit standard deviation).</source>
          <target state="translated">Si es cierto,escale los datos a la varianza unitaria (o,de manera equivalente,a la desviación estándar unitaria).</target>
        </trans-unit>
        <trans-unit id="df95a4486aac1e164d23cfb2a72a9a3a02411ccb" translate="yes" xml:space="preserve">
          <source>If True, the class covariance matrices are explicitely computed and stored in the &lt;code&gt;self.covariance_&lt;/code&gt; attribute.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a491ca8d8797fa01293c195b8787d725c30e073a" translate="yes" xml:space="preserve">
          <source>If True, the clusters are put on the vertices of a hypercube. If False, the clusters are put on the vertices of a random polytope.</source>
          <target state="translated">Si es cierto,los cúmulos se ponen en los vértices de un hipercubo.Si es falso,los cúmulos se colocan en los vértices de un politopo aleatorio.</target>
        </trans-unit>
        <trans-unit id="dc426ca785aa82bc3726faf833e38673875ff1ab" translate="yes" xml:space="preserve">
          <source>If True, the coefficients of the underlying linear model are returned.</source>
          <target state="translated">Si es cierto,se devuelven los coeficientes del modelo lineal subyacente.</target>
        </trans-unit>
        <trans-unit id="5724be8fac97575b0a1ba6783afc1c2fbe0fcac8" translate="yes" xml:space="preserve">
          <source>If True, the covariance of the joint predictive distribution at the query points is returned along with the mean</source>
          <target state="translated">Si es cierto,la covarianza de la distribución predictiva conjunta en los puntos de consulta se devuelve junto con la media</target>
        </trans-unit>
        <trans-unit id="dbcfae5acdcda56eec77c1115971fac37cdadcbc" translate="yes" xml:space="preserve">
          <source>If True, the data is a pandas DataFrame including columns with appropriate dtypes (numeric). The target is a pandas DataFrame or Series depending on the number of target columns. If &lt;code&gt;return_X_y&lt;/code&gt; is True, then (&lt;code&gt;data&lt;/code&gt;, &lt;code&gt;target&lt;/code&gt;) will be pandas DataFrames or Series as described below.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e36608088c739a911a649d964516a72573ccb05" translate="yes" xml:space="preserve">
          <source>If True, the data is a pandas DataFrame including columns with appropriate dtypes (numeric, string or categorical). The target is a pandas DataFrame or Series depending on the number of target columns. If &lt;code&gt;return_X_y&lt;/code&gt; is True, then (&lt;code&gt;data&lt;/code&gt;, &lt;code&gt;target&lt;/code&gt;) will be pandas DataFrames or Series as described below.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b39e4230ac891358bd0af7c3eedd9e07bde06b43" translate="yes" xml:space="preserve">
          <source>If True, the data is a pandas DataFrame including columns with appropriate dtypes (numeric, string or categorical). The target is a pandas DataFrame or Series depending on the number of target_columns.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="132ae12ba4f9038c17051f7e128fd887c18e17fe" translate="yes" xml:space="preserve">
          <source>If True, the data is a pandas DataFrame including columns with appropriate dtypes (numeric, string or categorical). The target is a pandas DataFrame or Series depending on the number of target_columns. The Bunch will contain a &lt;code&gt;frame&lt;/code&gt; attribute with the target and the data. If &lt;code&gt;return_X_y&lt;/code&gt; is True, then &lt;code&gt;(data, target)&lt;/code&gt; will be pandas DataFrames or Series as describe above.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab63854b4cbc92de5ee21a5ee4815065271902d4" translate="yes" xml:space="preserve">
          <source>If True, the distances and indices will be sorted before being returned. If False, the results will not be sorted. If return_distance == False, setting sort_results = True will result in an error.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91db79e9bb9248c604fdbf115bede6d2bc2e0f43" translate="yes" xml:space="preserve">
          <source>If True, the distances and indices will be sorted before being returned. If False, the results will not be sorted. Only used with mode=&amp;rsquo;distance&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d28765388f526f443e8440713d9f120592d23759" translate="yes" xml:space="preserve">
          <source>If True, the gradient of the log-marginal likelihood with respect to the kernel hyperparameters at position theta is returned additionally. If True, theta must not be None.</source>
          <target state="translated">Si es cierto,el gradiente de la probabilidad logarítmica marginal con respecto a los hiperparámetros del núcleo en la posición theta se devuelve adicionalmente.Si es True,theta no debe ser None.</target>
        </trans-unit>
        <trans-unit id="2ecaf6f4ca3e741011335b25b38b91313c972ea3" translate="yes" xml:space="preserve">
          <source>If True, the gradient of the log-marginal likelihood with respect to the kernel hyperparameters at position theta is returned additionally. Note that gradient computation is not supported for non-binary classification. If True, theta must not be None.</source>
          <target state="translated">Si es cierto,el gradiente de la probabilidad logarítmica marginal con respecto a los hiperparámetros del núcleo en la posición theta se devuelve adicionalmente.Obsérvese que el cálculo del gradiente no se admite para la clasificación no binaria.Si es True,theta no debe ser None.</target>
        </trans-unit>
        <trans-unit id="65ddb79c8d6a76beebeeb976d10455d7eb1fb46d" translate="yes" xml:space="preserve">
          <source>If True, the imputer mask will be a sparse matrix.</source>
          <target state="translated">Si es cierto,la máscara imputadora será una matriz escasa.</target>
        </trans-unit>
        <trans-unit id="eb2cac4cae6a6c8ef92320b8c850d0341c9b187b" translate="yes" xml:space="preserve">
          <source>If True, the kernel attribute is copied. If False, the kernel attribute is modified, but may result in a performance improvement.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a134a28236267fd097c12ab6f4f7b85d957aa9ca" translate="yes" xml:space="preserve">
          <source>If True, the method also returns &lt;code&gt;n_iter&lt;/code&gt;, the actual number of iteration performed by the solver.</source>
          <target state="translated">Si es True, el m&amp;eacute;todo tambi&amp;eacute;n devuelve &lt;code&gt;n_iter&lt;/code&gt; , el n&amp;uacute;mero real de iteraciones realizadas por el solucionador.</target>
        </trans-unit>
        <trans-unit id="af50e40087f45610f2fbcc323b88ccd93dcf9324" translate="yes" xml:space="preserve">
          <source>If True, the regressors X will be normalized before regression. This parameter is ignored when &lt;code&gt;fit_intercept&lt;/code&gt; is set to False. When the regressors are normalized, note that this makes the hyperparameters learned more robust and almost independent of the number of samples. The same property is not valid for standardized data. However, if you wish to standardize, please use &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; before calling &lt;code&gt;fit&lt;/code&gt; on an estimator with &lt;code&gt;normalize=False&lt;/code&gt;.</source>
          <target state="translated">Si es verdadero, los regresores X se normalizar&amp;aacute;n antes de la regresi&amp;oacute;n. Este par&amp;aacute;metro se ignora cuando &lt;code&gt;fit_intercept&lt;/code&gt; se establece en False. Cuando los regresores est&amp;aacute;n normalizados, tenga en cuenta que esto hace que los hiperpar&amp;aacute;metros aprendidos sean m&amp;aacute;s robustos y casi independientes del n&amp;uacute;mero de muestras. La misma propiedad no es v&amp;aacute;lida para datos estandarizados. Sin embargo, si desea estandarizar, use &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; antes de llamar a &lt;code&gt;fit&lt;/code&gt; en un estimador con &lt;code&gt;normalize=False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="016e8fefc2c3108a2b7a4351de86dada7ecbd68e" translate="yes" xml:space="preserve">
          <source>If True, the regressors X will be normalized before regression. This parameter is ignored when &lt;code&gt;fit_intercept&lt;/code&gt; is set to False. When the regressors are normalized, note that this makes the hyperparameters learnt more robust and almost independent of the number of samples. The same property is not valid for standardized data. However, if you wish to standardize, please use &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; before calling &lt;code&gt;fit&lt;/code&gt; on an estimator with &lt;code&gt;normalize=False&lt;/code&gt;.</source>
          <target state="translated">Si es verdadero, los regresores X se normalizar&amp;aacute;n antes de la regresi&amp;oacute;n. Este par&amp;aacute;metro se ignora cuando &lt;code&gt;fit_intercept&lt;/code&gt; se establece en False. Cuando los regresores est&amp;aacute;n normalizados, tenga en cuenta que esto hace que los hiperpar&amp;aacute;metros aprendidos sean m&amp;aacute;s robustos y casi independientes del n&amp;uacute;mero de muestras. La misma propiedad no es v&amp;aacute;lida para datos estandarizados. Sin embargo, si desea estandarizar, use &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; antes de llamar a &lt;code&gt;fit&lt;/code&gt; en un estimador con &lt;code&gt;normalize=False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c3fdb7e36f654834d666d698b8cb7219451a4481" translate="yes" xml:space="preserve">
          <source>If True, the return value will be an array of integers, rather than a boolean mask.</source>
          <target state="translated">Si es cierto,el valor de retorno será un conjunto de números enteros,en lugar de una máscara booleana.</target>
        </trans-unit>
        <trans-unit id="d17d4bbcdf2df4ef33c01a7114516c2e4e90d7d8" translate="yes" xml:space="preserve">
          <source>If True, the standard-deviation of the predictive distribution at the query points is returned along with the mean.</source>
          <target state="translated">Si es cierto,la desviación estándar de la distribución predictiva en los puntos de consulta se devuelve junto con la media.</target>
        </trans-unit>
        <trans-unit id="3f294130716f356d91654999eee9757bd2ba6c1c" translate="yes" xml:space="preserve">
          <source>If True, the support of robust location and covariance estimates is computed, and a covariance estimate is recomputed from it, without centering the data. Useful to work with data whose mean is significantly equal to zero but is not exactly zero. If False, the robust location and covariance are directly computed with the FastMCD algorithm without additional treatment.</source>
          <target state="translated">Si es cierto,se calcula el apoyo de las estimaciones robustas de localización y covarianza,y se vuelve a calcular una estimación de covarianza a partir de ella,sin centrar los datos.Es útil para trabajar con datos cuya media es significativamente igual a cero pero no es exactamente cero.Si es falso,la localización robusta y la covarianza se calculan directamente con el algoritmo FastMCD sin tratamiento adicional.</target>
        </trans-unit>
        <trans-unit id="667a36b1a1b94aa0d760aa610f277fcd1918ae0a" translate="yes" xml:space="preserve">
          <source>If True, the support of the robust location and the covariance estimates is computed, and a covariance estimate is recomputed from it, without centering the data. Useful to work with data whose mean is significantly equal to zero but is not exactly zero. If False, the robust location and covariance are directly computed with the FastMCD algorithm without additional treatment.</source>
          <target state="translated">Si es cierto,se calcula el apoyo de la ubicación robusta y las estimaciones de covarianza,y se vuelve a calcular una estimación de covarianza a partir de ella,sin centrar los datos.Es útil para trabajar con datos cuya media es significativamente igual a cero pero no es exactamente cero.Si es falso,la localización robusta y la covarianza se calculan directamente con el algoritmo FastMCD sin tratamiento adicional.</target>
        </trans-unit>
        <trans-unit id="77487b230b7ba030d96d8037319b1c202fdf89dc" translate="yes" xml:space="preserve">
          <source>If True, the time elapsed while fitting each step will be printed as it is completed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c5c205f98c6f7e0686c6b1dad61d3840345a50a" translate="yes" xml:space="preserve">
          <source>If True, the time elapsed while fitting each transformer will be printed as it is completed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af3eeb64eec0b2d56ce55e625f484e757480a63a" translate="yes" xml:space="preserve">
          <source>If True, the time elapsed while fitting will be printed as it is completed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28346b69fb6f1a64d688b2ef42aabb524b6563d8" translate="yes" xml:space="preserve">
          <source>If True, then X will be converted to a 2-dimensional NumPy array or sparse matrix. If the conversion is not possible an exception is raised.</source>
          <target state="translated">Si es True,entonces X se convertirá en una matriz NumPy bidimensional o matriz dispersa.Si la conversión no es posible,se plantea una excepción.</target>
        </trans-unit>
        <trans-unit id="5c0fef9c1e6748fc4d3cb84e62459147a039a4fd" translate="yes" xml:space="preserve">
          <source>If True, then all components with zero eigenvalues are removed, so that the number of components in the output may be &amp;lt; n_components (and sometimes even zero due to numerical instability). When n_components is None, this parameter is ignored and components with zero eigenvalues are removed regardless.</source>
          <target state="translated">Si es Verdadero, entonces se eliminan todos los componentes con valores propios cero, de modo que el n&amp;uacute;mero de componentes en la salida puede ser &amp;lt;n_components (y algunas veces incluso cero debido a la inestabilidad num&amp;eacute;rica). Cuando n_components es None, este par&amp;aacute;metro se ignora y los componentes con valores propios cero se eliminan independientemente.</target>
        </trans-unit>
        <trans-unit id="42874c4e7adb064c98a0fb44835161462f985220" translate="yes" xml:space="preserve">
          <source>If True, then compute normalized Laplacian.</source>
          <target state="translated">Si es cierto,entonces computa el laplaciano normalizado.</target>
        </trans-unit>
        <trans-unit id="ba532aca0424d37b34ea4248f58728a030b07d2d" translate="yes" xml:space="preserve">
          <source>If True, then return the centers of each cluster</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7818bd11ce52f2496690f2a19701e1fdc3bace9d" translate="yes" xml:space="preserve">
          <source>If True, transpose the downloaded data array.</source>
          <target state="translated">Si es cierto,transponga la matriz de datos descargada.</target>
        </trans-unit>
        <trans-unit id="9b28aadc7e361758f4f56436eeab711f856e9105" translate="yes" xml:space="preserve">
          <source>If True, use a breadth-first search. If False (default) use a depth-first search. Breadth-first is generally faster for compact kernels and/or high tolerances.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06e972e2019f64a904722b2934f5b7cf1e54e236" translate="yes" xml:space="preserve">
          <source>If True, use a dualtree algorithm. Otherwise, use a single-tree algorithm. Dual tree algorithms can have better scaling for large N.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09f8cdcb36703e0413a45867eb062d48bc42e4a4" translate="yes" xml:space="preserve">
          <source>If True, validation for finiteness will be skipped, saving time, but leading to potential crashes. If False, validation for finiteness will be performed, avoiding error. Global default: False.</source>
          <target state="translated">Si es cierto,la validación de la finitud se omitirá,ahorrando tiempo,pero conduciendo a posibles accidentes.Si es falso,la validación de la finitud se realizará,evitando errores.Predeterminado global:Falso.</target>
        </trans-unit>
        <trans-unit id="f770d204acb3934762188e63b6bd0977cfe619aa" translate="yes" xml:space="preserve">
          <source>If True, will return the parameters for this estimator and contained subobjects that are estimators.</source>
          <target state="translated">Si es cierto,devolverá los parámetros para este estimador y los subobjetos contenidos que son estimadores.</target>
        </trans-unit>
        <trans-unit id="edc518974aa9f8ea115d0f36469bc2b1e2cd15a2" translate="yes" xml:space="preserve">
          <source>If True, will return the query_id array for each file.</source>
          <target state="translated">Si es True,devolverá la matriz query_id de cada archivo.</target>
        </trans-unit>
        <trans-unit id="80fdba1026cc980884a84dfa72ad1747c034afc6" translate="yes" xml:space="preserve">
          <source>If X and y are not C-ordered and contiguous arrays of np.float64 and X is not a scipy.sparse.csr_matrix, X and/or y may be copied.</source>
          <target state="translated">Si X e y no están ordenados por C y los arreglos contiguos de np.float64 y X no es una scipy.sparse.csr_matrix,X y/o y pueden ser copiados.</target>
        </trans-unit>
        <trans-unit id="a601440183ce5a872479c357e441563196aab652" translate="yes" xml:space="preserve">
          <source>If X is a dense array, then the other methods will not support sparse matrices as input.</source>
          <target state="translated">Si X es una matriz densa,entonces los otros métodos no soportarán matrices escasas como entrada.</target>
        </trans-unit>
        <trans-unit id="efab9063b47a2afb85758f067069188b21b34f3e" translate="yes" xml:space="preserve">
          <source>If X is encoded as a CSR matrix.</source>
          <target state="translated">Si X está codificado como una matriz CSR.</target>
        </trans-unit>
        <trans-unit id="f4e2537cdb42d2bfe76e858b065192a8758650ef" translate="yes" xml:space="preserve">
          <source>If X is encoded as a CSR matrix;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da96e9fabf18fc39905756390120e4a7a1e09f97" translate="yes" xml:space="preserve">
          <source>If X is not a C-ordered contiguous array it is copied.</source>
          <target state="translated">Si X no es una matriz contigua ordenada por C,se copia.</target>
        </trans-unit>
        <trans-unit id="9cc8f34afbd30e04cc65d91f1b233abc1c382996" translate="yes" xml:space="preserve">
          <source>If X is not an array of floating values;</source>
          <target state="translated">Si X no es un conjunto de valores flotantes;</target>
        </trans-unit>
        <trans-unit id="e7ca7ce1d419c3d60265041304210343f2e8b91d" translate="yes" xml:space="preserve">
          <source>If X is our multivariate data, then the problem that we are trying to solve is to rewrite it on a different observational basis: we want to learn loadings L and a set of components C such that &lt;em&gt;X = L C&lt;/em&gt;. Different criteria exist to choose the components</source>
          <target state="translated">Si X son nuestros datos multivariados, entonces el problema que estamos tratando de resolver es reescribirlo sobre una base de observaci&amp;oacute;n diferente: queremos aprender las cargas L y un conjunto de componentes C tales que &lt;em&gt;X = LC&lt;/em&gt; . Existen diferentes criterios para elegir los componentes</target>
        </trans-unit>
        <trans-unit id="4691b6eeb6f44a63af5f24ac30dc066ab023aa61" translate="yes" xml:space="preserve">
          <source>If X is sparse and &lt;code&gt;missing_values=0&lt;/code&gt;;</source>
          <target state="translated">Si X es escasa y &lt;code&gt;missing_values=0&lt;/code&gt; ;</target>
        </trans-unit>
        <trans-unit id="5bf131136f9283115170d3f032466f07678834a5" translate="yes" xml:space="preserve">
          <source>If Y is given (default is None), then the returned matrix is the pairwise distance between the arrays from both X and Y.</source>
          <target state="translated">Si se da Y (por defecto es Ninguno),entonces la matriz devuelta es la distancia en pares entre las matrices de X e Y.</target>
        </trans-unit>
        <trans-unit id="a6e7fe3e345be28d5e67984fa49ad01aeaa444dd" translate="yes" xml:space="preserve">
          <source>If Y is given (default is None), then the returned matrix is the pairwise kernel between the arrays from both X and Y.</source>
          <target state="translated">Si se da Y (por defecto es Ninguno),entonces la matriz devuelta es el núcleo en par entre las matrices de X e Y.</target>
        </trans-unit>
        <trans-unit id="15e0fd61e3b85d8ebad2fc2135f6d5822723ce41" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}\) is the estimated target output, \(y\) the corresponding (correct) target output, and \(Var\) is &lt;a href=&quot;https://en.wikipedia.org/wiki/Variance&quot;&gt;Variance&lt;/a&gt;, the square of the standard deviation, then the explained variance is estimated as follow:</source>
          <target state="translated">Si \ (\ hat {y} \) es el resultado objetivo estimado, \ (y \) el resultado objetivo correspondiente (correcto) y \ (Var \) es la &lt;a href=&quot;https://en.wikipedia.org/wiki/Variance&quot;&gt;varianza&lt;/a&gt; , el cuadrado de la desviaci&amp;oacute;n est&amp;aacute;ndar, entonces la varianza explicada es estimado de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="1d8ad99bdd9bde4f8f4c5eb30616979db9d7983c" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value for total \(n\) samples, the estimated R&amp;sup2; is defined as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8fb389b8a60a2b57fc22c9161412c484a73dd18" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value, then the 0-1 loss \(L_{0-1}\) is defined as:</source>
          <target state="translated">Si es el valor predicho de la muestra y es el valor real correspondiente,entonces la pérdida de 0-1 se define como..:</target>
        </trans-unit>
        <trans-unit id="01fda7f04ce93ad5d6b5843c80c53ee91e04866d" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value, then the fraction of correct predictions over \(n_\text{samples}\) is defined as</source>
          <target state="translated">Si es el valor predicho de la muestra y es el valor verdadero correspondiente,entonces la fracción de predicciones correctas sobre las muestras se define como</target>
        </trans-unit>
        <trans-unit id="af46aeec0a0c654990b43c84ec26ca8a3817bbd3" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value, then the median absolute error (MedAE) estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="translated">Si es el valor predicho de la muestra y es el valor verdadero correspondiente,entonces el error absoluto medio (MedAE)estimado sobre las muestras se define como</target>
        </trans-unit>
        <trans-unit id="27ab05c62dcfc0b1ca98228a2c106c2bd25d72f6" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value, then the score R&amp;sup2; estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="translated">Si \ (\ hat {y} _i \) es el valor predicho de la \ (i \) - &amp;eacute;sima muestra y \ (y_i \) es el valor verdadero correspondiente, entonces la puntuaci&amp;oacute;n R&amp;sup2; estimada sobre \ (n _ {\ text { samples}} \) se define como</target>
        </trans-unit>
        <trans-unit id="2057e5fd21ea6e3999b964ff2858a1023496793a" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the max error is defined as</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b2139578cc75e1715d428f9c389fc66abbdc391" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the mean Tweedie deviance error (D) for power \(p\), estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9be139031431f33624d9549cf24272bbec27cad" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the mean absolute error (MAE) estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="translated">Si es el valor predicho de la muestra,y es el valor verdadero correspondiente,entonces el error absoluto medio (MAE)estimado sobre las muestras se define como</target>
        </trans-unit>
        <trans-unit id="b7836e2114e345225a74c22cbe0d3b5d52c8f253" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the mean squared error (MSE) estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="translated">Si es el valor predicho de la muestra,y es el valor verdadero correspondiente,entonces el error cuadrado medio (MSE)estimado sobre las muestras se define como</target>
        </trans-unit>
        <trans-unit id="1cf47fc0a0aaaffd1c0a818b8704218b8ae722c1" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the mean squared logarithmic error (MSLE) estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="translated">Si es el valor predicho de la muestra,y es el valor real correspondiente,entonces el error logarítmico cuadrado medio (MSLE)estimado sobre las muestras se define como</target>
        </trans-unit>
        <trans-unit id="f295fa8851d145ac326bc63b92809e2fbf3d1f72" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_j\) is the predicted value for the \(j\)-th label of a given sample, \(y_j\) is the corresponding true value, and \(n_\text{labels}\) is the number of classes or labels, then the Hamming loss \(L_{Hamming}\) between two samples is defined as:</source>
          <target state="translated">Si \ ~ es el valor predicho para la etiqueta de una muestra dada,es el valor verdadero correspondiente,y el número de clases o etiquetas,entonces la pérdida de Hamming \ ~ entre dos muestras se define como:</target>
        </trans-unit>
        <trans-unit id="7fa4bf510f83c73a55e8dec038abaacf960351ca" translate="yes" xml:space="preserve">
          <source>If \(c_0 = 0\) the kernel is said to be homogeneous.</source>
          <target state="translated">Si \(c_0=0\)se dice que el núcleo es homogéneo.</target>
        </trans-unit>
        <trans-unit id="c7d07701826b4f4c8efa455b46a49990993930f2" translate="yes" xml:space="preserve">
          <source>If \(h_i\) is given, the above equation automatically implies the following probabilistic interpretation:</source>
          <target state="translated">Si se da \N la ecuación anterior implica automáticamente la siguiente interpretación probabilística:</target>
        </trans-unit>
        <trans-unit id="9d9af8bc9b90a6fbf0d539b126efbd694bdaddf6" translate="yes" xml:space="preserve">
          <source>If \(y_i\) is the true value of the \(i\)-th sample, and \(w_i\) is the corresponding sample weight, then we adjust the sample weight to:</source>
          <target state="translated">Si \ ~ es el verdadero valor de la muestra,y \ ~ es el peso de la muestra correspondiente,entonces ajustamos el peso de la muestra a:</target>
        </trans-unit>
        <trans-unit id="4c76ddad0ef7a743f202685a0861880cbc2062e2" translate="yes" xml:space="preserve">
          <source>If \(y_w\) is the predicted decision for true label and \(y_t\) is the maximum of the predicted decisions for all other labels, where predicted decisions are output by decision function, then multiclass hinge loss is defined by:</source>
          <target state="translated">Si \(y_w\)es la decisión pronosticada para la etiqueta verdadera y \(y_t\)es el máximo de las decisiones pronosticadas para todas las demás etiquetas,donde las decisiones pronosticadas se producen por la función de decisión,entonces la pérdida de bisagra multiclase se define por:</target>
        </trans-unit>
        <trans-unit id="b8371056060d53aef38082b274a12c6e92dd981b" translate="yes" xml:space="preserve">
          <source>If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by accept_sparse, accept_large_sparse will cause it to be accepted only if its indices are stored with a 32-bit dtype.</source>
          <target state="translated">Si se suministra una matriz dispersa CSR,CSC,COO o BSR y es aceptada por accept_sparse,accept_large_sparse hará que sea aceptada sólo si sus índices se almacenan con un tipo d de 32 bits.</target>
        </trans-unit>
        <trans-unit id="ca2f554a4272574081b19f205bd8db66223aa9f8" translate="yes" xml:space="preserve">
          <source>If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by accept_sparse, accept_large_sparse=False will cause it to be accepted only if its indices are stored with a 32-bit dtype.</source>
          <target state="translated">Si se suministra una matriz dispersa CSR,CSC,COO o BSR y es aceptada por accept_sparse,accept_large_sparse=False hará que sea aceptada sólo si sus índices se almacenan con un tipo de 32 bits.</target>
        </trans-unit>
        <trans-unit id="b0090a224443cfea422c2167734e98ec705e71a5" translate="yes" xml:space="preserve">
          <source>If a callable is passed it is used to extract the sequence of features out of the raw, unprocessed input.</source>
          <target state="translated">Si se pasa una llamada se utiliza para extraer la secuencia de características de la entrada sin procesar.</target>
        </trans-unit>
        <trans-unit id="dcd8eacb988e0fa27afa1a7692943530b07747f6" translate="yes" xml:space="preserve">
          <source>If a callable is passed, it should take arguments X, k and and a random state and return an initialization.</source>
          <target state="translated">Si se pasa una llamada,debería tomar los argumentos X,k y y un estado aleatorio y devolver una inicialización.</target>
        </trans-unit>
        <trans-unit id="cf28b181c12fdc4001f26b46f656bc18426882b0" translate="yes" xml:space="preserve">
          <source>If a callable is passed, it should take arguments X, n_clusters and a random state and return an initialization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15b5ddf5d35e7b6d7436896e31247316b726ba30" translate="yes" xml:space="preserve">
          <source>If a float, that value is added to all values in the contingency matrix. This helps to stop NaN propagation. If &lt;code&gt;None&lt;/code&gt;, nothing is adjusted.</source>
          <target state="translated">Si es flotante, ese valor se agrega a todos los valores en la matriz de contingencia. Esto ayuda a detener la propagaci&amp;oacute;n de NaN. Si es &lt;code&gt;None&lt;/code&gt; , no se ajusta nada.</target>
        </trans-unit>
        <trans-unit id="aec58020de2b924f9656034ee47c95a7ace302db" translate="yes" xml:space="preserve">
          <source>If a list is passed it&amp;rsquo;s expected to be one of n_targets such arrays. The varying values of the coefficients along the path. It is not present if the &lt;code&gt;fit_path&lt;/code&gt; parameter is &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">Si se pasa una lista, se espera que sea uno de los n_targets de tales matrices. Los valores variables de los coeficientes a lo largo del camino. No est&amp;aacute; presente si el par&amp;aacute;metro &lt;code&gt;fit_path&lt;/code&gt; es &lt;code&gt;False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8e3b6cd9422926a607fefd39c3e9bd3020c06d14" translate="yes" xml:space="preserve">
          <source>If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens. Only applies if &lt;code&gt;analyzer == 'word'&lt;/code&gt;.</source>
          <target state="translated">Si es una lista, se supone que esa lista contiene palabras vac&amp;iacute;as, todas las cuales se eliminar&amp;aacute;n de los tokens resultantes. Solo se aplica si &lt;code&gt;analyzer == 'word'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3a891d1ec4d966c2171dc7ddf73d952ce675676b" translate="yes" xml:space="preserve">
          <source>If a single axis is passed in, it is treated as a bounding axes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58d1b02436a7aa9160e580f582400827e1ad046d" translate="yes" xml:space="preserve">
          <source>If a string, it is passed to _check_stop_list and the appropriate stop list is returned. &amp;lsquo;english&amp;rsquo; is currently the only supported string value. There are several known issues with &amp;lsquo;english&amp;rsquo; and you should consider an alternative (see &lt;a href=&quot;../feature_extraction#stop-words&quot;&gt;Using stop words&lt;/a&gt;).</source>
          <target state="translated">Si es una cadena, se pasa a _check_stop_list y se devuelve la lista de detenci&amp;oacute;n correspondiente. 'english' es actualmente el &amp;uacute;nico valor de cadena admitido. Hay varios problemas conocidos con 'ingl&amp;eacute;s' y deber&amp;iacute;a considerar una alternativa (consulte &lt;a href=&quot;../feature_extraction#stop-words&quot;&gt;Uso de palabras vac&amp;iacute;as&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="564b43bc82acf22a1de3b85bb28ac591ff97b4bf" translate="yes" xml:space="preserve">
          <source>If a string, this may be one of &amp;lsquo;nearest_neighbors&amp;rsquo;, &amp;lsquo;precomputed&amp;rsquo;, &amp;lsquo;rbf&amp;rsquo; or one of the kernels supported by &lt;code&gt;sklearn.metrics.pairwise_kernels&lt;/code&gt;.</source>
          <target state="translated">Si es una cadena, puede ser uno de los 'vecinos_m&amp;aacute;s cercanos', 'precalculados', 'rbf' o uno de los n&amp;uacute;cleos admitidos por &lt;code&gt;sklearn.metrics.pairwise_kernels&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="675cbfc234c52633edd36cba3388cd72c1b8e2d3" translate="yes" xml:space="preserve">
          <source>If a target is a classification outcome taking on values 0,1,&amp;hellip;,K-1, for node \(m\), representing a region \(R_m\) with \(N_m\) observations, let</source>
          <target state="translated">Si un objetivo es un resultado de clasificaci&amp;oacute;n que toma valores 0,1,&amp;hellip;, K-1, para el nodo \ (m \), que representa una regi&amp;oacute;n \ (R_m \) con \ (N_m \) observaciones, sea</target>
        </trans-unit>
        <trans-unit id="b39b95bbd18e310b00daaab2152e27da5d834f6a" translate="yes" xml:space="preserve">
          <source>If add_indicator=True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="373500a68bbbd934744d157d24ba37240f790a20" translate="yes" xml:space="preserve">
          <source>If affinity is &amp;ldquo;precomputed&amp;rdquo; X : array-like, shape (n_samples, n_samples), Interpret X as precomputed adjacency graph computed from samples.</source>
          <target state="translated">Si la afinidad est&amp;aacute; &quot;precalculada&quot; X: similar a una matriz, forma (n_samples, n_samples), interprete X como un gr&amp;aacute;fico de adyacencia precalculado calculado a partir de muestras.</target>
        </trans-unit>
        <trans-unit id="86d4d97c781f9d1a441e0d9197ea013d3820b489" translate="yes" xml:space="preserve">
          <source>If affinity is &amp;ldquo;precomputed&amp;rdquo; X : {array-like, sparse matrix}, shape (n_samples, n_samples), Interpret X as precomputed adjacency graph computed from samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c306493486d7abaed871db69a1b0f3a0d3e230f4" translate="yes" xml:space="preserve">
          <source>If affinity is the adjacency matrix of a graph, this method can be used to find normalized graph cuts.</source>
          <target state="translated">Si la afinidad es la matriz de adyacencia de un gráfico,este método puede utilizarse para encontrar cortes de gráfico normalizados.</target>
        </trans-unit>
        <trans-unit id="fef3ba1186af33eef8e244a6a4bb530d43ffdf84" translate="yes" xml:space="preserve">
          <source>If all examples are from the same class, it uses a one-class SVM.</source>
          <target state="translated">Si todos los ejemplos son de la misma clase,utiliza un SVM de una clase.</target>
        </trans-unit>
        <trans-unit id="b53805960d76925767243aca9c19243fc1b08d06" translate="yes" xml:space="preserve">
          <source>If all parameters are presented as a list, sampling without replacement is performed. If at least one parameter is given as a distribution, sampling with replacement is used. It is highly recommended to use continuous distributions for continuous parameters.</source>
          <target state="translated">Si todos los parámetros se presentan en forma de lista,se realiza un muestreo sin sustitución.Si al menos un parámetro se presenta como una distribución,se utiliza el muestreo con sustitución.Se recomienda encarecidamente utilizar distribuciones continuas para los parámetros continuos.</target>
        </trans-unit>
        <trans-unit id="44ee4928f6faf842a93c2259e4d1b6db16c4073a" translate="yes" xml:space="preserve">
          <source>If all the coordinates are missing or if there are no common present coordinates then NaN is returned for that pair.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f219d1953670922fbbfe88159427df7222c9397" translate="yes" xml:space="preserve">
          <source>If an algorithm, such as a linear support vector machine or PCA, relies only on the scalar product of data points \(x_i\), one may use the value of \(k(x_i, x_j)\), which corresponds to applying the algorithm to the mapped data points \(\phi(x_i)\). The advantage of using \(k\) is that the mapping \(\phi\) never has to be calculated explicitly, allowing for arbitrary large features (even infinite).</source>
          <target state="translated">Si un algoritmo,como una máquina de vector de soporte lineal o PCA,se basa sólo en el producto escalar de los puntos de datos \(x_i\),se puede utilizar el valor de \(k(x_i,x_j)\),que corresponde a la aplicación del algoritmo a los puntos de datos mapeados \N(\phi(x_i)\N).La ventaja de usar \N \N \N es que el mapeo \N \N nunca tiene que ser calculado explícitamente,permitiendo grandes características arbitrarias (incluso infinitas).</target>
        </trans-unit>
        <trans-unit id="22b4c02685073d2c5c3e900f3a57456658da8b22" translate="yes" xml:space="preserve">
          <source>If an array-like of axes are passed in, the partial dependence</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9fea95f95d0577b3d2b8dde1c99a4f5f11240b1d" translate="yes" xml:space="preserve">
          <source>If an exception is triggered, use &lt;code&gt;%debug&lt;/code&gt; to fire-up a post mortem ipdb session.</source>
          <target state="translated">Si se activa una excepci&amp;oacute;n, utilice &lt;code&gt;%debug&lt;/code&gt; para iniciar una sesi&amp;oacute;n ipdb post mortem.</target>
        </trans-unit>
        <trans-unit id="5c4a826b768bf0ea44b0de0cf9a279c59410da1d" translate="yes" xml:space="preserve">
          <source>If an integer is given, it fixes the number of points on the grids of alpha to be used. If a list is given, it gives the grid to be used. See the notes in the class docstring for more details.</source>
          <target state="translated">Si se da un número entero,se fija el número de puntos en las cuadrículas de alfa a utilizar.Si se da una lista,da la cuadrícula a ser utilizada.Vea las notas de la clase docstring para más detalles.</target>
        </trans-unit>
        <trans-unit id="9e0d496b83e5a4c02138b5662acc0d0357377648" translate="yes" xml:space="preserve">
          <source>If an integer is given, it fixes the number of points on the grids of alpha to be used. If a list is given, it gives the grid to be used. See the notes in the class docstring for more details. Range is (0, inf] when floats given.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f54c86c80b29ba93fdb4405121f2a742f42412e" translate="yes" xml:space="preserve">
          <source>If an ndarray is passed, it should be of shape (n_clusters, n_features) and gives the initial centers.</source>
          <target state="translated">Si se pasa un ndarray,debe tener forma (n_clusters,n_features)y da los centros iniciales.</target>
        </trans-unit>
        <trans-unit id="ce1d1dc15735f50591b21078e51cada592338767" translate="yes" xml:space="preserve">
          <source>If arpack :</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57a89ce6b3eb175b37e97fdc8660396b5ef203e5" translate="yes" xml:space="preserve">
          <source>If auto :</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bf20b6ab9e24e0313be1f29e5bd87350c62fc72" translate="yes" xml:space="preserve">
          <source>If bandwidth is not given, it is determined using a heuristic based on the median of all pairwise distances. This will take quadratic time in the number of samples. The sklearn.cluster.estimate_bandwidth function can be used to do this more efficiently.</source>
          <target state="translated">Si no se da el ancho de banda,se determina usando una heurística basada en la mediana de todas las distancias en pares.Esto tomará un tiempo cuadrático en el número de muestras.La función sklearn.cluster.estimate_banda ancha puede utilizarse para hacer esto de manera más eficiente.</target>
        </trans-unit>
        <trans-unit id="307d133eac653119e68c3f800803dcc4776573b9" translate="yes" xml:space="preserve">
          <source>If bool, then determines whether to consider all features discrete or continuous. If array, then it should be either a boolean mask with shape (n_features,) or array with indices of discrete features. If &amp;lsquo;auto&amp;rsquo;, it is assigned to False for dense &lt;code&gt;X&lt;/code&gt; and to True for sparse &lt;code&gt;X&lt;/code&gt;.</source>
          <target state="translated">Si es bool, determina si se deben considerar todas las caracter&amp;iacute;sticas como discretas o continuas. Si es una matriz, entonces deber&amp;iacute;a ser una m&amp;aacute;scara booleana con forma (n_features) o una matriz con &amp;iacute;ndices de caracter&amp;iacute;sticas discretas. Si es 'auto', se asigna a False para &lt;code&gt;X&lt;/code&gt; denso y a Verdadero para &lt;code&gt;X&lt;/code&gt; disperso .</target>
        </trans-unit>
        <trans-unit id="14d26c2cb6ccf4f84a440b5eee94360749d30490" translate="yes" xml:space="preserve">
          <source>If boolean, whether or not to fit the isotonic regression with y increasing or decreasing.</source>
          <target state="translated">Si es booleana,si encaja o no en la regresión isotónica con y aumentando o disminuyendo.</target>
        </trans-unit>
        <trans-unit id="34ddc69f78e9ae21f32c4048eb992eb5ea37253a" translate="yes" xml:space="preserve">
          <source>If bootstrap is True, the number of samples to draw from X to train each base estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7380002883f78b7443a4cf144369e2cdf9c7dd5" translate="yes" xml:space="preserve">
          <source>If bytes or files are given to analyze, this encoding is used to decode.</source>
          <target state="translated">Si se dan bytes o archivos para analizar,esta codificación se utiliza para decodificar.</target>
        </trans-unit>
        <trans-unit id="b1cd46fc8b5b18d3d8ec258c92a5832fe49ecb69" translate="yes" xml:space="preserve">
          <source>If classes members are completely split across different clusters, the assignment is totally in-complete, hence the AMI is null:</source>
          <target state="translated">Si los miembros de las clases están completamente divididos en diferentes grupos,la asignación está totalmente incompleta,por lo que el AMI es nulo:</target>
        </trans-unit>
        <trans-unit id="e6f2dbc2c288fdff952bc5d6d0612fad044f50c2" translate="yes" xml:space="preserve">
          <source>If classes members are completely split across different clusters, the assignment is totally in-complete, hence the NMI is null:</source>
          <target state="translated">Si los miembros de las clases están completamente divididos en diferentes grupos,la asignación está totalmente incompleta,por lo tanto el NMI es nulo:</target>
        </trans-unit>
        <trans-unit id="60b93fba5d2befe30dad173ef2989a32caf2707d" translate="yes" xml:space="preserve">
          <source>If classes members are completely split across different clusters, the assignment is totally incomplete, hence the ARI is very low:</source>
          <target state="translated">Si los miembros de las clases están completamente divididos en diferentes grupos,la asignación es totalmente incompleta,por lo que el ARI es muy bajo:</target>
        </trans-unit>
        <trans-unit id="e02bb35b2a969fdf2ff25b865a0b3ba938fb92a9" translate="yes" xml:space="preserve">
          <source>If classes members are completely split across different clusters, the assignment is totally incomplete, hence the V-Measure is null:</source>
          <target state="translated">Si los miembros de las clases están completamente divididos en diferentes grupos,la asignación es totalmente incompleta,por lo que la medida V es nula:</target>
        </trans-unit>
        <trans-unit id="d0974a75f074fb11fd0a08f495fdb803227dd0c6" translate="yes" xml:space="preserve">
          <source>If classes members are completely split across different clusters, the assignment is totally random, hence the FMI is null:</source>
          <target state="translated">Si los miembros de las clases están completamente divididos en diferentes grupos,la asignación es totalmente aleatoria,por lo que el FMI es nulo:</target>
        </trans-unit>
        <trans-unit id="3a4c44f6cadbe5141305e79bc3f8068062652c4d" translate="yes" xml:space="preserve">
          <source>If classes members are split across different clusters, the assignment cannot be complete:</source>
          <target state="translated">Si los miembros de las clases se dividen en diferentes grupos,la tarea no puede ser completada:</target>
        </trans-unit>
        <trans-unit id="a2787535a9b0772f98dac284faca0d2184e54d74" translate="yes" xml:space="preserve">
          <source>If coefficients vary significantly when changing the input dataset their robustness is not guaranteed, and they should probably be interpreted with caution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52c8ac55b5c80763168c6804bd2b4b595db63ef9" translate="yes" xml:space="preserve">
          <source>If computed_score is True, value of the log marginal likelihood (to be maximized) at each iteration of the optimization. The array starts with the value of the log marginal likelihood obtained for the initial values of alpha and lambda and ends with the value obtained for the estimated alpha and lambda.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="baf96abe9df5cd386826eafcd47454c9dcc36819" translate="yes" xml:space="preserve">
          <source>If copy is False, the affinity matrix is modified inplace by the algorithm, for memory efficiency</source>
          <target state="translated">Si la copia es falsa,la matriz de afinidad se modifica en el lugar por el algoritmo,para la eficiencia de la memoria</target>
        </trans-unit>
        <trans-unit id="0070f2c19699b732c372ba0e363293b507463ed1" translate="yes" xml:space="preserve">
          <source>If decision_function_shape=&amp;rsquo;ovo&amp;rsquo;, the function values are proportional to the distance of the samples X to the separating hyperplane. If the exact distances are required, divide the function values by the norm of the weight vector (&lt;code&gt;coef_&lt;/code&gt;). See also &lt;a href=&quot;https://stats.stackexchange.com/questions/14876/interpreting-distance-from-hyperplane-in-svm&quot;&gt;this question&lt;/a&gt; for further details. If decision_function_shape=&amp;rsquo;ovr&amp;rsquo;, the decision function is a monotonic transformation of ovo decision function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="671e4e16873255449d2ba54f06975c272f73c34d" translate="yes" xml:space="preserve">
          <source>If density = &amp;lsquo;auto&amp;rsquo;, the value is set to the minimum density as recommended by Ping Li et al.: 1 / sqrt(n_features).</source>
          <target state="translated">Si densidad = 'auto', el valor se establece en la densidad m&amp;iacute;nima recomendada por Ping Li et al .: 1 / sqrt (n_features).</target>
        </trans-unit>
        <trans-unit id="391517cb3cfce3ac9c6c32b7ceac049807282afc" translate="yes" xml:space="preserve">
          <source>If documents are pre-tokenized by an external package, then store them in files (or strings) with the tokens separated by whitespace and pass &lt;code&gt;analyzer=str.split&lt;/code&gt;</source>
          <target state="translated">Si los documentos est&amp;aacute;n pre-tokenizados por un paquete externo, gu&amp;aacute;rdelos en archivos (o cadenas) con los tokens separados por espacios en blanco y pase &lt;code&gt;analyzer=str.split&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="80416b24b5f24b22b80d50d90aa942e77a2dadfc" translate="yes" xml:space="preserve">
          <source>If each row and each column belongs to exactly one bicluster, then rearranging the rows and columns of the data matrix reveals the biclusters on the diagonal. Here is an example of this structure where biclusters have higher average values than the other rows and columns:</source>
          <target state="translated">Si cada fila y cada columna pertenece exactamente a un biclustro,entonces al reorganizar las filas y columnas de la matriz de datos se revelan los biclustros en la diagonal.He aquí un ejemplo de esta estructura en la que los bíceps tienen valores medios más altos que las otras filas y columnas:</target>
        </trans-unit>
        <trans-unit id="78ba0badd104b3ed95bd2061747613a1b6f84ce9" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of groups to include in the test split (rounded up). If int, represents the absolute number of test groups. If None, the value is set to the complement of the train size. The default will change in version 0.21. It will remain 0.2 only if &lt;code&gt;train_size&lt;/code&gt; is unspecified, otherwise it will complement the specified &lt;code&gt;train_size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1db9c10662b6d49b6b84ca8b7b7ce2a9580afa10" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. By default (the parameter is unspecified), the value is set to 0.1. The default will change in version 0.21. It will remain 0.1 only if &lt;code&gt;train_size&lt;/code&gt; is unspecified, otherwise it will complement the specified &lt;code&gt;train_size&lt;/code&gt;.</source>
          <target state="translated">Si es flotante, debe estar entre 0.0 y 1.0 y representar la proporci&amp;oacute;n del conjunto de datos para incluir en la divisi&amp;oacute;n de prueba. Si es int, representa el n&amp;uacute;mero absoluto de muestras de prueba. Si es Ninguno, el valor se establece como complemento del tama&amp;ntilde;o del tren. De forma predeterminada (el par&amp;aacute;metro no est&amp;aacute; especificado), el valor se establece en 0,1. El valor predeterminado cambiar&amp;aacute; en la versi&amp;oacute;n 0.21. Seguir&amp;aacute; siendo 0.1 solo si &lt;code&gt;train_size&lt;/code&gt; no est&amp;aacute; especificado, de lo contrario complementar&amp;aacute; el &lt;code&gt;train_size&lt;/code&gt; especificado .</target>
        </trans-unit>
        <trans-unit id="73ce93bb920d84bef49715afdf02f771938f8206" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. By default, the value is set to 0.1. The default will change in version 0.21. It will remain 0.1 only if &lt;code&gt;train_size&lt;/code&gt; is unspecified, otherwise it will complement the specified &lt;code&gt;train_size&lt;/code&gt;.</source>
          <target state="translated">Si es flotante, debe estar entre 0.0 y 1.0 y representar la proporci&amp;oacute;n del conjunto de datos para incluir en la divisi&amp;oacute;n de prueba. Si es int, representa el n&amp;uacute;mero absoluto de muestras de prueba. Si es Ninguno, el valor se establece como complemento del tama&amp;ntilde;o del tren. De forma predeterminada, el valor se establece en 0,1. El valor predeterminado cambiar&amp;aacute; en la versi&amp;oacute;n 0.21. Seguir&amp;aacute; siendo 0.1 solo si &lt;code&gt;train_size&lt;/code&gt; no est&amp;aacute; especificado, de lo contrario complementar&amp;aacute; el &lt;code&gt;train_size&lt;/code&gt; especificado .</target>
        </trans-unit>
        <trans-unit id="aa74ab3ce21513c4e7c83e9b91dad63582c835b8" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. By default, the value is set to 0.2. The default will change in version 0.21. It will remain 0.2 only if &lt;code&gt;train_size&lt;/code&gt; is unspecified, otherwise it will complement the specified &lt;code&gt;train_size&lt;/code&gt;.</source>
          <target state="translated">Si es flotante, debe estar entre 0.0 y 1.0 y representar la proporci&amp;oacute;n del conjunto de datos para incluir en la divisi&amp;oacute;n de prueba. Si es int, representa el n&amp;uacute;mero absoluto de muestras de prueba. Si es Ninguno, el valor se establece como complemento del tama&amp;ntilde;o del tren. De forma predeterminada, el valor se establece en 0,2. El valor predeterminado cambiar&amp;aacute; en la versi&amp;oacute;n 0.21. Seguir&amp;aacute; siendo 0.2 solo si &lt;code&gt;train_size&lt;/code&gt; no est&amp;aacute; especificado, de lo contrario complementar&amp;aacute; el &lt;code&gt;train_size&lt;/code&gt; especificado .</target>
        </trans-unit>
        <trans-unit id="dfe0bc4ba0825c6b9e54b3177711e714d6e28a2b" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. By default, the value is set to 0.25. The default will change in version 0.21. It will remain 0.25 only if &lt;code&gt;train_size&lt;/code&gt; is unspecified, otherwise it will complement the specified &lt;code&gt;train_size&lt;/code&gt;.</source>
          <target state="translated">Si es flotante, debe estar entre 0.0 y 1.0 y representar la proporci&amp;oacute;n del conjunto de datos para incluir en la divisi&amp;oacute;n de prueba. Si es int, representa el n&amp;uacute;mero absoluto de muestras de prueba. Si es Ninguno, el valor se establece como complemento del tama&amp;ntilde;o del tren. De forma predeterminada, el valor se establece en 0,25. El valor predeterminado cambiar&amp;aacute; en la versi&amp;oacute;n 0.21. Seguir&amp;aacute; siendo 0.25 solo si &lt;code&gt;train_size&lt;/code&gt; no est&amp;aacute; especificado, de lo contrario complementar&amp;aacute; el &lt;code&gt;train_size&lt;/code&gt; especificado .</target>
        </trans-unit>
        <trans-unit id="09a40f5654bce0b9dd81c58e4db01bd35e373391" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. If &lt;code&gt;train_size&lt;/code&gt; is also None, it will be set to 0.1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c86f8c8782626d870a975f8a368ba48b84e1e80" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. If &lt;code&gt;train_size&lt;/code&gt; is also None, it will be set to 0.25.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3b7da8f21403a8e0fce55a369b8d82b4da5bfd1" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split. If int, represents the absolute number of train samples. If None, the value is automatically set to the complement of the test size.</source>
          <target state="translated">Si flota,debe estar entre 0,0 y 1,0 y representar la proporción del conjunto de datos a incluir en la división del tren.Si int,representa el número absoluto de muestras de tren.Si none,el valor se ajusta automáticamente al complemento del tamaño de la prueba.</target>
        </trans-unit>
        <trans-unit id="62b47f7a89d7c976d2813299381cdc4f4f5b3cad" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the groups to include in the train split. If int, represents the absolute number of train groups. If None, the value is automatically set to the complement of the test size.</source>
          <target state="translated">Si flota,debe estar entre 0,0 y 1,0 y representar la proporción de los grupos a incluir en la división del tren.Si int,representa el número absoluto de grupos de trenes.Si none,el valor se ajusta automáticamente al complemento del tamaño de la prueba.</target>
        </trans-unit>
        <trans-unit id="561d4c125db4b741d015190537a6b19d8f8e55c1" translate="yes" xml:space="preserve">
          <source>If float, the contamination should be in the range [0, 0.5].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0ffbda1c59db43809cf9245f33efa45a65a5c05" translate="yes" xml:space="preserve">
          <source>If float, then &lt;code&gt;max_features&lt;/code&gt; is a fraction and &lt;code&gt;int(max_features * n_features)&lt;/code&gt; features are considered at each split.</source>
          <target state="translated">Si es flotante, &lt;code&gt;max_features&lt;/code&gt; es una fracci&amp;oacute;n y las caracter&amp;iacute;sticas &lt;code&gt;int(max_features * n_features)&lt;/code&gt; se consideran en cada divisi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="47d0c1ebc9dc44a7018a0ce88d0d45201068f385" translate="yes" xml:space="preserve">
          <source>If float, then &lt;code&gt;min_samples_leaf&lt;/code&gt; is a fraction and &lt;code&gt;ceil(min_samples_leaf * n_samples)&lt;/code&gt; are the minimum number of samples for each node.</source>
          <target state="translated">Si es flotante, &lt;code&gt;min_samples_leaf&lt;/code&gt; es una fracci&amp;oacute;n y &lt;code&gt;ceil(min_samples_leaf * n_samples)&lt;/code&gt; es el n&amp;uacute;mero m&amp;iacute;nimo de muestras para cada nodo.</target>
        </trans-unit>
        <trans-unit id="c217707834c84f95b745c6fd735e46ef1d5cb29d" translate="yes" xml:space="preserve">
          <source>If float, then &lt;code&gt;min_samples_leaf&lt;/code&gt; is a fraction and &lt;code&gt;ceil(min_samples_leaf * n_samples)&lt;/code&gt; is the minimum number of samples for each node.</source>
          <target state="translated">Si es flotante, &lt;code&gt;min_samples_leaf&lt;/code&gt; es una fracci&amp;oacute;n y &lt;code&gt;ceil(min_samples_leaf * n_samples)&lt;/code&gt; es el n&amp;uacute;mero m&amp;iacute;nimo de muestras para cada nodo.</target>
        </trans-unit>
        <trans-unit id="f5813e9c1656f619ed6234eb86815e1c76ec9071" translate="yes" xml:space="preserve">
          <source>If float, then &lt;code&gt;min_samples_split&lt;/code&gt; is a fraction and &lt;code&gt;ceil(min_samples_split * n_samples)&lt;/code&gt; are the minimum number of samples for each split.</source>
          <target state="translated">Si es flotante, &lt;code&gt;min_samples_split&lt;/code&gt; es una fracci&amp;oacute;n y &lt;code&gt;ceil(min_samples_split * n_samples)&lt;/code&gt; es el n&amp;uacute;mero m&amp;iacute;nimo de muestras para cada divisi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="c32957ea85344bbb6b41aa874b4a5e7763ff6b76" translate="yes" xml:space="preserve">
          <source>If float, then &lt;code&gt;min_samples_split&lt;/code&gt; is a fraction and &lt;code&gt;ceil(min_samples_split * n_samples)&lt;/code&gt; is the minimum number of samples for each split.</source>
          <target state="translated">Si es flotante, &lt;code&gt;min_samples_split&lt;/code&gt; es una fracci&amp;oacute;n y &lt;code&gt;ceil(min_samples_split * n_samples)&lt;/code&gt; es el n&amp;uacute;mero m&amp;iacute;nimo de muestras para cada divisi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="81fe24c94c96599e85080c0cc195542bdb1ce722" translate="yes" xml:space="preserve">
          <source>If float, then draw &lt;code&gt;max_features * X.shape[1]&lt;/code&gt; features.</source>
          <target state="translated">Si es flotante, dibuja &lt;code&gt;max_features * X.shape[1]&lt;/code&gt; features.</target>
        </trans-unit>
        <trans-unit id="a2b1676fcae8577852e20614ce418906e2f79102" translate="yes" xml:space="preserve">
          <source>If float, then draw &lt;code&gt;max_samples * X.shape[0]&lt;/code&gt; samples.</source>
          <target state="translated">Si es flotante, entonces dibuja &lt;code&gt;max_samples * X.shape[0]&lt;/code&gt; samples.</target>
        </trans-unit>
        <trans-unit id="271d97216c612b23c04f108b3da94d4db7dcfcec" translate="yes" xml:space="preserve">
          <source>If float, then draw &lt;code&gt;max_samples * X.shape[0]&lt;/code&gt; samples. Thus, &lt;code&gt;max_samples&lt;/code&gt; should be in the interval &lt;code&gt;(0, 1)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2cf469ccb5c1129883a42e4f4a3183401e643c51" translate="yes" xml:space="preserve">
          <source>If full :</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f234188a9694365b66e83538b40de1fa4059a074" translate="yes" xml:space="preserve">
          <source>If greater than or equal to 1, then &lt;code&gt;step&lt;/code&gt; corresponds to the (integer) number of features to remove at each iteration. If within (0.0, 1.0), then &lt;code&gt;step&lt;/code&gt; corresponds to the percentage (rounded down) of features to remove at each iteration.</source>
          <target state="translated">Si es mayor o igual que 1, el &lt;code&gt;step&lt;/code&gt; corresponde al n&amp;uacute;mero (entero) de caracter&amp;iacute;sticas que se eliminar&amp;aacute;n en cada iteraci&amp;oacute;n. Si est&amp;aacute; dentro de (0.0, 1.0), el &lt;code&gt;step&lt;/code&gt; corresponde al porcentaje (redondeado hacia abajo) de caracter&amp;iacute;sticas que se eliminar&amp;aacute;n en cada iteraci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="d3aeb6a39c457b69bdde12a943780461d08c388d" translate="yes" xml:space="preserve">
          <source>If greater than or equal to 1, then &lt;code&gt;step&lt;/code&gt; corresponds to the (integer) number of features to remove at each iteration. If within (0.0, 1.0), then &lt;code&gt;step&lt;/code&gt; corresponds to the percentage (rounded down) of features to remove at each iteration. Note that the last iteration may remove fewer than &lt;code&gt;step&lt;/code&gt; features in order to reach &lt;code&gt;min_features_to_select&lt;/code&gt;.</source>
          <target state="translated">Si es mayor o igual que 1, el &lt;code&gt;step&lt;/code&gt; corresponde al n&amp;uacute;mero (entero) de caracter&amp;iacute;sticas que se eliminar&amp;aacute;n en cada iteraci&amp;oacute;n. Si est&amp;aacute; dentro de (0.0, 1.0), entonces el &lt;code&gt;step&lt;/code&gt; corresponde al porcentaje (redondeado hacia abajo) de caracter&amp;iacute;sticas para eliminar en cada iteraci&amp;oacute;n. Tenga en cuenta que la &amp;uacute;ltima iteraci&amp;oacute;n puede eliminar menos caracter&amp;iacute;sticas de &lt;code&gt;step&lt;/code&gt; para llegar a &lt;code&gt;min_features_to_select&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1351e34960b08f78869e356e9d9129a529a17168" translate="yes" xml:space="preserve">
          <source>If in the QDA model one assumes that the covariance matrices are diagonal, then the inputs are assumed to be conditionally independent in each class, and the resulting classifier is equivalent to the Gaussian Naive Bayes classifier &lt;a href=&quot;generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt;&lt;code&gt;naive_bayes.GaussianNB&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Si en el modelo QDA se supone que las matrices de covarianza son diagonales, se supone que las entradas son condicionalmente independientes en cada clase, y el clasificador resultante es equivalente al clasificador Gaussiano Naive Bayes &lt;a href=&quot;generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt; &lt;code&gt;naive_bayes.GaussianNB&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="47884bf7f490577d7025ceb970813cb997acfc82" translate="yes" xml:space="preserve">
          <source>If init=&amp;rsquo;custom&amp;rsquo;, it is used as initial guess for the solution.</source>
          <target state="translated">Si init = 'custom', se utiliza como conjetura inicial para la soluci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="25a1f9fc4e56498f0b6e355b29cc8aeb5e3daeb3" translate="yes" xml:space="preserve">
          <source>If init=&amp;rsquo;custom&amp;rsquo;, it is used as initial guess for the solution. If update_H=False, it is used as a constant, to solve for W only.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b9c788e52ff7adb618d2b8cf3dd396e088800c8" translate="yes" xml:space="preserve">
          <source>If int, it is the total number of points equally divided among clusters. If array-like, each element of the sequence indicates the number of samples per cluster.</source>
          <target state="translated">Si int,es el número total de puntos divididos equitativamente entre los grupos.Si es array,cada elemento de la secuencia indica el número de muestras por cluster.</target>
        </trans-unit>
        <trans-unit id="424c096f1eaf5892378c66d2235ced4e356f327c" translate="yes" xml:space="preserve">
          <source>If int, it is the total number of points generated. For odd numbers, the inner circle will have one point more than the outer circle. If two-element tuple, number of points in outer circle and inner circle.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2403d0bd3d2ac8c8a9756c4cde9cd9202cbe9926" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;.</source>
          <target state="translated">Si es int, random_state es la semilla usada por el generador de n&amp;uacute;meros aleatorios; Si es una instancia de RandomState, random_state es el generador de n&amp;uacute;meros aleatorios; Si es None, el generador de n&amp;uacute;meros aleatorios es la instancia de RandomState utilizada por &lt;code&gt;np.random&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="676c2454734bf9216c5797d643595f0b850b4e7a" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Note that different initializations might result in different local minima of the cost function.</source>
          <target state="translated">Si es int, random_state es la semilla usada por el generador de n&amp;uacute;meros aleatorios; Si es una instancia de RandomState, random_state es el generador de n&amp;uacute;meros aleatorios; Si es None, el generador de n&amp;uacute;meros aleatorios es la instancia de RandomState utilizada por &lt;code&gt;np.random&lt;/code&gt; . Tenga en cuenta que las diferentes inicializaciones pueden resultar en diferentes m&amp;iacute;nimos locales de la funci&amp;oacute;n de costo.</target>
        </trans-unit>
        <trans-unit id="a1933900181bd8e24f0237ebecc7a06b2ef8b486" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Only used when &lt;code&gt;svd_method&lt;/code&gt; equals &amp;lsquo;randomized&amp;rsquo;.</source>
          <target state="translated">Si es int, random_state es la semilla usada por el generador de n&amp;uacute;meros aleatorios; Si es una instancia de RandomState, random_state es el generador de n&amp;uacute;meros aleatorios; Si es None, el generador de n&amp;uacute;meros aleatorios es la instancia de RandomState utilizada por &lt;code&gt;np.random&lt;/code&gt; . Solo se usa cuando &lt;code&gt;svd_method&lt;/code&gt; es igual a 'aleatorio'.</target>
        </trans-unit>
        <trans-unit id="4914440c8828885c0b1efea7679daefd5f1e4eaf" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;eigen_solver&lt;/code&gt; == &amp;lsquo;arpack&amp;rsquo;.</source>
          <target state="translated">Si es int, random_state es la semilla usada por el generador de n&amp;uacute;meros aleatorios; Si es una instancia de RandomState, random_state es el generador de n&amp;uacute;meros aleatorios; Si es None, el generador de n&amp;uacute;meros aleatorios es la instancia de RandomState utilizada por &lt;code&gt;np.random&lt;/code&gt; . Se usa cuando &lt;code&gt;eigen_solver&lt;/code&gt; == 'arpack'.</target>
        </trans-unit>
        <trans-unit id="90657492e3c46d11fb3a1c799a4569e4854211ed" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;shuffle&lt;/code&gt; == True.</source>
          <target state="translated">Si es int, random_state es la semilla usada por el generador de n&amp;uacute;meros aleatorios; Si es una instancia de RandomState, random_state es el generador de n&amp;uacute;meros aleatorios; Si es None, el generador de n&amp;uacute;meros aleatorios es la instancia de RandomState utilizada por &lt;code&gt;np.random&lt;/code&gt; . Se usa cuando &lt;code&gt;shuffle&lt;/code&gt; == True.</target>
        </trans-unit>
        <trans-unit id="7e39c8ed74a38762200c178da772671eaa6b3f52" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;shuffle&lt;/code&gt; is True.</source>
          <target state="translated">Si es int, random_state es la semilla usada por el generador de n&amp;uacute;meros aleatorios; Si es una instancia de RandomState, random_state es el generador de n&amp;uacute;meros aleatorios; Si es None, el generador de n&amp;uacute;meros aleatorios es la instancia de RandomState utilizada por &lt;code&gt;np.random&lt;/code&gt; . Se usa cuando la &lt;code&gt;shuffle&lt;/code&gt; es True.</target>
        </trans-unit>
        <trans-unit id="636d95a8f3edcd08bb7a122de05f8944c1a330ee" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;solver&lt;/code&gt; == &amp;lsquo;arpack&amp;rsquo;.</source>
          <target state="translated">Si es int, random_state es la semilla usada por el generador de n&amp;uacute;meros aleatorios; Si es una instancia de RandomState, random_state es el generador de n&amp;uacute;meros aleatorios; Si es None, el generador de n&amp;uacute;meros aleatorios es la instancia de RandomState utilizada por &lt;code&gt;np.random&lt;/code&gt; . Se usa cuando &lt;code&gt;solver&lt;/code&gt; == 'arpack'.</target>
        </trans-unit>
        <trans-unit id="d8bb54edf7a318cb4f3734b3f7721b6c840db8b1" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;svd_solver&lt;/code&gt; == &amp;lsquo;arpack&amp;rsquo; or &amp;lsquo;randomized&amp;rsquo;.</source>
          <target state="translated">Si es int, random_state es la semilla usada por el generador de n&amp;uacute;meros aleatorios; Si es una instancia de RandomState, random_state es el generador de n&amp;uacute;meros aleatorios; Si es None, el generador de n&amp;uacute;meros aleatorios es la instancia de RandomState utilizada por &lt;code&gt;np.random&lt;/code&gt; . Se usa cuando &lt;code&gt;svd_solver&lt;/code&gt; == 'arpack' o 'randomized'.</target>
        </trans-unit>
        <trans-unit id="49fc99a0f8ec79ab5cf6633c8b91ad397447b0ae" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random. Note that this is used by subsampling and smoothing noise.</source>
          <target state="translated">Si int,random_state es la semilla utilizada por el generador de números aleatorios;Si instancia RandomState,random_state es el generador de números aleatorios;Si None,el generador de números aleatorios es la instancia RandomState utilizada por np.random.Obsérvese que se utiliza para el submuestreo y el suavizado de ruido.</target>
        </trans-unit>
        <trans-unit id="20ecb73824a9c787c46458c94b754eb343f23997" translate="yes" xml:space="preserve">
          <source>If int, the total number of points generated. If two-element tuple, number of points in each of two moons.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8faba5e55a8f0e899120109354364cac8c2354b" translate="yes" xml:space="preserve">
          <source>If int, then consider &lt;code&gt;max_features&lt;/code&gt; features at each split.</source>
          <target state="translated">Si es int, entonces considere &lt;code&gt;max_features&lt;/code&gt; caracter&amp;iacute;sticas de max_features en cada divisi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="79438cfe8b8de1684467307814da6af61cdfe6ba" translate="yes" xml:space="preserve">
          <source>If int, then consider &lt;code&gt;min_samples_leaf&lt;/code&gt; as the minimum number.</source>
          <target state="translated">Si es int, entonces considere &lt;code&gt;min_samples_leaf&lt;/code&gt; como el n&amp;uacute;mero m&amp;iacute;nimo.</target>
        </trans-unit>
        <trans-unit id="69e04ca78560d3ef445be4d724f5c0cc8198187a" translate="yes" xml:space="preserve">
          <source>If int, then consider &lt;code&gt;min_samples_split&lt;/code&gt; as the minimum number.</source>
          <target state="translated">Si es int, entonces considere &lt;code&gt;min_samples_split&lt;/code&gt; como el n&amp;uacute;mero m&amp;iacute;nimo.</target>
        </trans-unit>
        <trans-unit id="a8d276c242fbe315ce14903af35e7ebf9a0c3619" translate="yes" xml:space="preserve">
          <source>If int, then draw &lt;code&gt;max_features&lt;/code&gt; features.</source>
          <target state="translated">Si es int, dibuja caracter&amp;iacute;sticas de &lt;code&gt;max_features&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0771ca4ef29dd427aac0ffda56943aa541e3af54" translate="yes" xml:space="preserve">
          <source>If int, then draw &lt;code&gt;max_samples&lt;/code&gt; samples.</source>
          <target state="translated">Si es int, entonces dibuja muestras de &lt;code&gt;max_samples&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4430c154e22158c0d6435f75a2d640312ee73ab2" translate="yes" xml:space="preserve">
          <source>If log normalization was used, all the singular vectors are meaningful. However, if independent normalization or bistochastization were used, the first singular vectors, \(u_1\) and \(v_1\). are discarded. From now on, the &amp;ldquo;first&amp;rdquo; singular vectors refers to \(u_2 \dots u_{p+1}\) and \(v_2 \dots v_{p+1}\) except in the case of log normalization.</source>
          <target state="translated">Si se utiliz&amp;oacute; la normalizaci&amp;oacute;n logar&amp;iacute;tmica, todos los vectores singulares son significativos. Sin embargo, si se usaran normalizaci&amp;oacute;n independiente o bistocastizaci&amp;oacute;n, los primeros vectores singulares, \ (u_1 \) y \ (v_1 \). se descartan. De ahora en adelante, los &amp;ldquo;primeros&amp;rdquo; vectores singulares se refieren a \ (u_2 \ dots u_ {p + 1} \) y \ (v_2 \ dots v_ {p + 1} \) excepto en el caso de la normalizaci&amp;oacute;n logar&amp;iacute;tmica.</target>
        </trans-unit>
        <trans-unit id="f38434d38fce86523bd80aac7625c65019a5f868" translate="yes" xml:space="preserve">
          <source>If max_samples is larger than the number of samples provided, all samples will be used for all trees (no sampling).</source>
          <target state="translated">Si max_samples es mayor que el número de muestras proporcionadas,todas las muestras se utilizarán para todos los árboles (sin muestreo).</target>
        </trans-unit>
        <trans-unit id="0512919782ceb898f5e82137605d37f1918f7fe8" translate="yes" xml:space="preserve">
          <source>If method == &amp;ldquo;auto&amp;rdquo;, the ratio of n_samples / n_population is used to determine which algorithm to use: If ratio is between 0 and 0.01, tracking selection is used. If ratio is between 0.01 and 0.99, numpy.random.permutation is used. If ratio is greater than 0.99, reservoir sampling is used. The order of the selected integers is undefined. If a random order is desired, the selected subset should be shuffled.</source>
          <target state="translated">Si m&amp;eacute;todo == &amp;ldquo;auto&amp;rdquo;, la proporci&amp;oacute;n de n_muestras / n_poblaci&amp;oacute;n se usa para determinar qu&amp;eacute; algoritmo usar: Si la proporci&amp;oacute;n est&amp;aacute; entre 0 y 0.01, se usa la selecci&amp;oacute;n de seguimiento. Si la relaci&amp;oacute;n est&amp;aacute; entre 0.01 y 0.99, se usa numpy.random.permutation. Si la relaci&amp;oacute;n es superior a 0,99, se utiliza el muestreo del yacimiento. El orden de los n&amp;uacute;meros enteros seleccionados no est&amp;aacute; definido. Si se desea un orden aleatorio, se debe mezclar el subconjunto seleccionado.</target>
        </trans-unit>
        <trans-unit id="aa3ae5990e2e00fef99c00cc07049cdbc9d8e931" translate="yes" xml:space="preserve">
          <source>If method == &amp;ldquo;pool&amp;rdquo;, a pool based algorithm is particularly fast, even faster than the tracking selection method. Hovewer, a vector containing the entire population has to be initialized. If n_samples ~ n_population, the reservoir sampling method is faster.</source>
          <target state="translated">Si m&amp;eacute;todo == &quot;grupo&quot;, un algoritmo basado en grupo es particularmente r&amp;aacute;pido, incluso m&amp;aacute;s r&amp;aacute;pido que el m&amp;eacute;todo de selecci&amp;oacute;n de seguimiento. Sin embargo, se debe inicializar un vector que contenga toda la poblaci&amp;oacute;n. Si n_muestras ~ n_poblaci&amp;oacute;n, el m&amp;eacute;todo de muestreo del yacimiento es m&amp;aacute;s r&amp;aacute;pido.</target>
        </trans-unit>
        <trans-unit id="6916dcd6d6c8f00e1ac0ef865ab4c75ff38ebedf" translate="yes" xml:space="preserve">
          <source>If method == &amp;ldquo;reservoir_sampling&amp;rdquo;, a reservoir sampling algorithm is used which is suitable for high memory constraint or when O(&lt;code&gt;n_samples&lt;/code&gt;) ~ O(&lt;code&gt;n_population&lt;/code&gt;). The order of the selected integers is undefined. If a random order is desired, the selected subset should be shuffled.</source>
          <target state="translated">Si el m&amp;eacute;todo == &amp;ldquo;muestreo_de_ reservorio&amp;rdquo;, se usa un algoritmo de muestreo de reservorio que es adecuado para una alta restricci&amp;oacute;n de memoria o cuando O ( &lt;code&gt;n_samples&lt;/code&gt; ) ~ O ( &lt;code&gt;n_population&lt;/code&gt; ). El orden de los n&amp;uacute;meros enteros seleccionados no est&amp;aacute; definido. Si se desea un orden aleatorio, se debe mezclar el subconjunto seleccionado.</target>
        </trans-unit>
        <trans-unit id="0dea8a6c91cef90e0430014d895bb3954c8fb19c" translate="yes" xml:space="preserve">
          <source>If method ==&amp;rdquo;tracking_selection&amp;rdquo;, a set based implementation is used which is suitable for &lt;code&gt;n_samples&lt;/code&gt; &amp;lt;&amp;lt;&amp;lt; &lt;code&gt;n_population&lt;/code&gt;.</source>
          <target state="translated">Si el m&amp;eacute;todo == &amp;rdquo;tracking_selection&amp;rdquo;, se utiliza una implementaci&amp;oacute;n basada en conjuntos que es adecuada para &lt;code&gt;n_samples&lt;/code&gt; &amp;lt;&amp;lt;&amp;lt; &lt;code&gt;n_population&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b83a3c2dac1d5c17a6e580230ebdf136c940fa15" translate="yes" xml:space="preserve">
          <source>If metric is &amp;ldquo;precomputed&amp;rdquo;, X is assumed to be a distance matrix and must be square. X may be a sparse matrix, in which case only &amp;ldquo;nonzero&amp;rdquo; elements may be considered neighbors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79ae0bba548597b9902c41c70fbd6bf9602e8534" translate="yes" xml:space="preserve">
          <source>If metric is &amp;lsquo;precomputed&amp;rsquo;, Y is ignored and X is returned.</source>
          <target state="translated">Si la m&amp;eacute;trica est&amp;aacute; 'precalculada', Y se ignora y se devuelve X.</target>
        </trans-unit>
        <trans-unit id="ca8cb47e72e166fd730a116349e050254e6876d5" translate="yes" xml:space="preserve">
          <source>If metric is a callable function, it is called on each pair of instances (rows) and the resulting value recorded. The callable should take two arrays as input and return one value indicating the distance between them. This works for Scipy&amp;rsquo;s metrics, but is less efficient than passing the metric name as a string.</source>
          <target state="translated">Si la m&amp;eacute;trica es una funci&amp;oacute;n invocable, se invoca en cada par de instancias (filas) y se registra el valor resultante. El invocable debe tomar dos matrices como entrada y devolver un valor que indique la distancia entre ellas. Esto funciona para las m&amp;eacute;tricas de Scipy, pero es menos eficiente que pasar el nombre de la m&amp;eacute;trica como una cadena.</target>
        </trans-unit>
        <trans-unit id="574d42008b369aefc553aab20dba12b6d233789b" translate="yes" xml:space="preserve">
          <source>If metric is a callable function, it is called on each pair of instances (rows) and the resulting value recorded. The callable should take two arrays as input and return one value indicating the distance between them. This works for Scipy&amp;rsquo;s metrics, but is less efficient than passing the metric name as a string. If metric is &amp;ldquo;precomputed&amp;rdquo;, X is assumed to be a distance matrix and must be square.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27305db22802f1bb3d3e2d60db076f6f0d275369" translate="yes" xml:space="preserve">
          <source>If mini-batch k-means is used, the best initialization is chosen and the algorithm runs once. Otherwise, the algorithm is run for each initialization and the best solution chosen.</source>
          <target state="translated">Si se utiliza el mini lote k-means,se elige la mejor inicialización y el algoritmo se ejecuta una vez.En caso contrario,el algoritmo se ejecuta para cada inicialización y se elige la mejor solución.</target>
        </trans-unit>
        <trans-unit id="16e6684b95c26e373af21b6c0d2ea50b705c0505" translate="yes" xml:space="preserve">
          <source>If multioutput is &amp;lsquo;raw_values&amp;rsquo;, then mean absolute error is returned for each output separately. If multioutput is &amp;lsquo;uniform_average&amp;rsquo; or an ndarray of weights, then the weighted average of all output errors is returned.</source>
          <target state="translated">Si la salida m&amp;uacute;ltiple es 'raw_values', el error absoluto medio se devuelve para cada salida por separado. Si la salida m&amp;uacute;ltiple es 'uniform_average' o un ndarray de pesos, se devuelve el promedio ponderado de todos los errores de salida.</target>
        </trans-unit>
        <trans-unit id="5304821b08fca43ab85cd7593997416e8f601261" translate="yes" xml:space="preserve">
          <source>If neighbors_algorithm=&amp;rsquo;precomputed&amp;rsquo;, X is assumed to be a distance matrix or a sparse graph of shape (n_queries, n_samples_fit).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62bc17472717b60146346d5aed7f5c0278bbe8ae" translate="yes" xml:space="preserve">
          <source>If no missing values were encountered for a given feature during training, then samples with missing values are mapped to whichever child has the most samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="caf3d42023b133b9efdfbb493fc66df503092e71" translate="yes" xml:space="preserve">
          <source>If no scoring is specified and the estimator has no score function, we can either return None or raise an exception.</source>
          <target state="translated">Si no se especifica una puntuación y el estimador no tiene una función de puntuación,podemos devolver Ninguno o plantear una excepción.</target>
        </trans-unit>
        <trans-unit id="5519c1c6825bf59bfd06c08f68bb64b64ee1a0ae" translate="yes" xml:space="preserve">
          <source>If no valid consensus set could be found. This occurs if &lt;code&gt;is_data_valid&lt;/code&gt; and &lt;code&gt;is_model_valid&lt;/code&gt; return False for all &lt;code&gt;max_trials&lt;/code&gt; randomly chosen sub-samples.</source>
          <target state="translated">Si no se pudo encontrar un consenso v&amp;aacute;lido. Esto ocurre si &lt;code&gt;is_data_valid&lt;/code&gt; y &lt;code&gt;is_model_valid&lt;/code&gt; devuelven False para todas las &lt;code&gt;max_trials&lt;/code&gt; elegidas al azar.</target>
        </trans-unit>
        <trans-unit id="e48a960f323664c14eed43108cfafa1159796090" translate="yes" xml:space="preserve">
          <source>If normalize is &lt;code&gt;True&lt;/code&gt;, return the fraction of misclassifications (float), else it returns the number of misclassifications (int). The best performance is 0.</source>
          <target state="translated">Si normalizar es &lt;code&gt;True&lt;/code&gt; , devuelve la fracci&amp;oacute;n de errores de clasificaci&amp;oacute;n (flotante); de lo contrario, devuelve el n&amp;uacute;mero de errores de clasificaci&amp;oacute;n (int). El mejor rendimiento es 0.</target>
        </trans-unit>
        <trans-unit id="66ebd47239b72bc82239183dacc1b3e58bfa41bb" translate="yes" xml:space="preserve">
          <source>If not &lt;code&gt;None&lt;/code&gt;, the standardized partial AUC &lt;a href=&quot;#r4bb7c4558997-2&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt; over the range [0, max_fpr] is returned. For the multiclass case, &lt;code&gt;max_fpr&lt;/code&gt;, should be either equal to &lt;code&gt;None&lt;/code&gt; or &lt;code&gt;1.0&lt;/code&gt; as AUC ROC partial computation currently is not supported for multiclass.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d93355ca0c397a92c0eb63483bbae0b531d00cf1" translate="yes" xml:space="preserve">
          <source>If not &lt;code&gt;None&lt;/code&gt;, the standardized partial AUC &lt;a href=&quot;#r4bb7c4558997-3&quot; id=&quot;id1&quot;&gt;[3]&lt;/a&gt; over the range [0, max_fpr] is returned.</source>
          <target state="translated">Si no es &lt;code&gt;None&lt;/code&gt; , se devuelve el AUC parcial estandarizado &lt;a href=&quot;#r4bb7c4558997-3&quot; id=&quot;id1&quot;&gt;[3]&lt;/a&gt; sobre el rango [0, max_fpr].</target>
        </trans-unit>
        <trans-unit id="954d968337062d6fae676f5915fb0dc48db9ccef" translate="yes" xml:space="preserve">
          <source>If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus.</source>
          <target state="translated">Si no hay ninguno,construye un vocabulario que sólo considere las máximas características ordenadas por la frecuencia de los términos a través del corpus.</target>
        </trans-unit>
        <trans-unit id="6b6dff5f6d294c2bdbfe5ee6b0ee56319193880c" translate="yes" xml:space="preserve">
          <source>If not None, data is split in a stratified fashion, using this as the class labels.</source>
          <target state="translated">Si no hay ninguno,los datos se dividen de manera estratificada,usando esto como las etiquetas de clase.</target>
        </trans-unit>
        <trans-unit id="d9fe4271c08ca870db7143f08e0938aa49f2d1d0" translate="yes" xml:space="preserve">
          <source>If not None, set the highest value of the fit to y_max.</source>
          <target state="translated">Si no es None,establezca el valor más alto del ajuste en y_max.</target>
        </trans-unit>
        <trans-unit id="3c138b5d1ed12eddb3226ed7535814059b7a615c" translate="yes" xml:space="preserve">
          <source>If not None, set the lowest value of the fit to y_min.</source>
          <target state="translated">Si no es None,establezca el valor más bajo del ajuste en y_min.</target>
        </trans-unit>
        <trans-unit id="ebcf44116da09ed76a723aed5cadbe6d4ed2530d" translate="yes" xml:space="preserve">
          <source>If not None, this argument is passed as &lt;code&gt;sample_weight&lt;/code&gt; keyword argument to the &lt;code&gt;score&lt;/code&gt; method of the final estimator.</source>
          <target state="translated">Si no es None, este argumento se pasa como argumento de palabra clave &lt;code&gt;sample_weight&lt;/code&gt; al m&amp;eacute;todo de &lt;code&gt;score&lt;/code&gt; del estimador final.</target>
        </trans-unit>
        <trans-unit id="3798f9f768af1129609b1d811ed41c3721cfae7d" translate="yes" xml:space="preserve">
          <source>If not None, this function is called after every iteration of the optimizer, taking as arguments the current solution (flattened transformation matrix) and the number of iterations. This might be useful in case one wants to examine or store the transformation found after each iteration.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0f7d0b7263b16cf926e8314af8096b9ae6c9066" translate="yes" xml:space="preserve">
          <source>If not given, the bandwidth is estimated using sklearn.cluster.estimate_bandwidth; see the documentation for that function for hints on scalability (see also the Notes, below).</source>
          <target state="translated">Si no se indica,el ancho de banda se estima utilizando sklearn.cluster.estimate_banda;véanse en la documentación de esa función las indicaciones sobre la escalabilidad (véanse también las Notas,más adelante).</target>
        </trans-unit>
        <trans-unit id="e77fe01e6cae9364473d1714c8219315178ecad2" translate="yes" xml:space="preserve">
          <source>If not provided, labels will be inferred from y_true. If &lt;code&gt;labels&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; has shape (n_samples,) the labels are assumed to be binary and are inferred from &lt;code&gt;y_true&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3fc57ade66d3b29b2e5dacfcee394aac7f4ec951" translate="yes" xml:space="preserve">
          <source>If not provided, labels will be inferred from y_true. If &lt;code&gt;labels&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; has shape (n_samples,) the labels are assumed to be binary and are inferred from &lt;code&gt;y_true&lt;/code&gt;. .. versionadded:: 0.18</source>
          <target state="translated">Si no se proporciona, las etiquetas se deducir&amp;aacute;n de y_true. Si &lt;code&gt;labels&lt;/code&gt; es &lt;code&gt;None&lt;/code&gt; y &lt;code&gt;y_pred&lt;/code&gt; tiene forma (n_samples), se supone que las etiquetas son binarias y se infieren de &lt;code&gt;y_true&lt;/code&gt; . .. versionadded :: 0.18</target>
        </trans-unit>
        <trans-unit id="d3a1f4e96f04c6f8dfd4835d50de53587903b2e7" translate="yes" xml:space="preserve">
          <source>If one-of-K coding is applied to categorical features, this will include the constructed feature names but not the original ones.</source>
          <target state="translated">Si se aplica la codificación &quot;uno de los K&quot; a los rasgos categóricos,esto incluirá los nombres de los rasgos construidos pero no los originales.</target>
        </trans-unit>
        <trans-unit id="c3b8faf61102e14148418b48bf3dbb3389d54ef3" translate="yes" xml:space="preserve">
          <source>If only the diagonal of the auto-covariance is being used, the method &lt;code&gt;diag()&lt;/code&gt; of a kernel can be called, which is more computationally efficient than the equivalent call to &lt;code&gt;__call__&lt;/code&gt;: &lt;code&gt;np.diag(k(X, X)) == k.diag(X)&lt;/code&gt;</source>
          <target state="translated">Si solo se usa la diagonal de la covarianza autom&amp;aacute;tica, se puede llamar al m&amp;eacute;todo &lt;code&gt;diag()&lt;/code&gt; de un kernel, que es m&amp;aacute;s eficiente computacionalmente que la llamada equivalente a &lt;code&gt;__call__&lt;/code&gt; : &lt;code&gt;np.diag(k(X, X)) == k.diag(X)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="db7f35e5fc1dd73c10c86bdccb4a2449d5a89ec7" translate="yes" xml:space="preserve">
          <source>If order is &amp;lsquo;random&amp;rsquo; a random ordering will be used.</source>
          <target state="translated">Si el orden es &quot;aleatorio&quot;, se utilizar&amp;aacute; un orden aleatorio.</target>
        </trans-unit>
        <trans-unit id="f42275492b00fc14b5861ea85e0f4944992d0324" translate="yes" xml:space="preserve">
          <source>If passed, include the name of the estimator in warning messages.</source>
          <target state="translated">Si se aprueba,incluya el nombre del estimador en los mensajes de advertencia.</target>
        </trans-unit>
        <trans-unit id="908cd551a5eab6201799122746b2ad3d99f4a3d2" translate="yes" xml:space="preserve">
          <source>If positive, restrict regression coefficients to be positive</source>
          <target state="translated">Si es positivo,restringe los coeficientes de regresión para que sean positivos</target>
        </trans-unit>
        <trans-unit id="66637d66644751acb1ce04342cdfce0be0ef5495" translate="yes" xml:space="preserve">
          <source>If provided, this parameter will override the choice of copy_X made at instance creation. If &lt;code&gt;True&lt;/code&gt;, X will be copied; else, it may be overwritten.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71021bee801a334b18f6587cd74d122911551ceb" translate="yes" xml:space="preserve">
          <source>If query_id is set to True, this will return instead [X1, y1, q1,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54d5c9aca2dfc54fbbbdb98327375a6f374bdf8f" translate="yes" xml:space="preserve">
          <source>If randomized :</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c5484f943f94af044829e2453a87ea1beff675d6" translate="yes" xml:space="preserve">
          <source>If return_costs is True, the objective function and dual gap at each iteration are returned.</source>
          <target state="translated">Si return_costs es True,la función objetivo y la brecha dual en cada iteración son devueltas.</target>
        </trans-unit>
        <trans-unit id="3a07f641c209d2556442bcd652915ffb4ab857db" translate="yes" xml:space="preserve">
          <source>If safe is false, clone will fall back to a deep copy on objects that are not estimators.</source>
          <target state="translated">Si la seguridad es falsa,el clon caerá en una copia profunda en objetos que no son estimadores.</target>
        </trans-unit>
        <trans-unit id="179d83839b7c246b21dd4fad6260ec3c338cc783" translate="yes" xml:space="preserve">
          <source>If seed is None, return the RandomState singleton used by np.random. If seed is an int, return a new RandomState instance seeded with seed. If seed is already a RandomState instance, return it. Otherwise raise ValueError.</source>
          <target state="translated">Si la semilla es None,devuelve el singleton RandomState usado por np.random.Si la semilla es un int,devuelve una nueva instancia de RandomState sembrada con semilla.Si la semilla ya es una instancia RandomState,devuélvela.De lo contrario,aumente el ValueError.</target>
        </trans-unit>
        <trans-unit id="7108bbb3c9ecad70c2ad038e49ece7ce906a1c8f" translate="yes" xml:space="preserve">
          <source>If seq[i] is an int or a tuple with one int value, a one-way PDP is created; if seq[i] is a tuple of two ints, a two-way PDP is created. If feature_names is specified and seq[i] is an int, seq[i] must be &amp;lt; len(feature_names). If seq[i] is a string, feature_names must be specified, and seq[i] must be in feature_names.</source>
          <target state="translated">Si seq [i] es un int o una tupla con un valor int, se crea un PDP unidireccional; si seq [i] es una tupla de dos enteros, se crea un PDP bidireccional. Si se especifica feature_names y seq [i] es un int, seq [i] debe ser &amp;lt;len (feature_names). Si seq [i] es una cadena, feature_names debe especificarse y seq [i] debe estar en feature_names.</target>
        </trans-unit>
        <trans-unit id="4c1ce6df0b81e7680bbf5092a9535a5fa0cb37a8" translate="yes" xml:space="preserve">
          <source>If set to &amp;ldquo;warn&amp;rdquo;, this acts as 0, but warnings are also raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b01ea458e6ed79ec076f21dd79564eecc3f7a882" translate="yes" xml:space="preserve">
          <source>If set to &amp;lsquo;random&amp;rsquo;, a random coefficient is updated every iteration rather than looping over features sequentially by default. This (setting to &amp;lsquo;random&amp;rsquo;) often leads to significantly faster convergence especially when tol is higher than 1e-4</source>
          <target state="translated">Si se establece en 'aleatorio', un coeficiente aleatorio se actualiza en cada iteraci&amp;oacute;n en lugar de recorrer las caracter&amp;iacute;sticas secuencialmente de forma predeterminada. Este (ajuste a 'aleatorio') a menudo conduce a una convergencia significativamente m&amp;aacute;s r&amp;aacute;pida, especialmente cuando tol es mayor que 1e-4</target>
        </trans-unit>
        <trans-unit id="7a4374896942a67a58d05d59133607fc7483d7a2" translate="yes" xml:space="preserve">
          <source>If set to &amp;lsquo;random&amp;rsquo;, a random coefficient is updated every iteration rather than looping over features sequentially by default. This (setting to &amp;lsquo;random&amp;rsquo;) often leads to significantly faster convergence especially when tol is higher than 1e-4.</source>
          <target state="translated">Si se establece en 'aleatorio', un coeficiente aleatorio se actualiza en cada iteraci&amp;oacute;n en lugar de recorrer las caracter&amp;iacute;sticas secuencialmente de forma predeterminada. Esta (configuraci&amp;oacute;n en 'aleatoria') a menudo conduce a una convergencia significativamente m&amp;aacute;s r&amp;aacute;pida, especialmente cuando tol es mayor que 1e-4.</target>
        </trans-unit>
        <trans-unit id="b3732982402454957d1d44e2700684220ba9b532" translate="yes" xml:space="preserve">
          <source>If set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to &lt;code&gt;fit&lt;/code&gt; as initialization for &lt;code&gt;coef_&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; .</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d15f7a009cd3b6e81a757534913f0edc7a2b7947" translate="yes" xml:space="preserve">
          <source>If set to True, forces coefficients to be positive. (Only allowed when &lt;code&gt;y.ndim == 1&lt;/code&gt;).</source>
          <target state="translated">Si se establece en Verdadero, fuerza a los coeficientes a ser positivos. (Solo permitido cuando &lt;code&gt;y.ndim == 1&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="6bd31584b0a279bb6a357ab195ba9534cb5cad4e" translate="yes" xml:space="preserve">
          <source>If set to True, the scores are averaged across all folds, and the coefs and the C that corresponds to the best score is taken, and a final refit is done using these parameters. Otherwise the coefs, intercepts and C that correspond to the best scores across folds are averaged.</source>
          <target state="translated">Si se establece en True,se promedian las puntuaciones en todos los pliegues,y se toman los arrecifes y la C que corresponde a la mejor puntuación,y se hace un ajuste final utilizando estos parámetros.En caso contrario,se promedian los arrecifes,las interceptaciones y la C que corresponden a las mejores puntuaciones en todos los pliegues.</target>
        </trans-unit>
        <trans-unit id="f3d43f9f7c9e3af1ca6eddc0268b8ee91bb07ee3" translate="yes" xml:space="preserve">
          <source>If set, scikit-learn will attempt to limit the size of temporary arrays to this number of MiB (per job when parallelised), often saving both computation time and memory on expensive operations that can be performed in chunks. Global default: 1024.</source>
          <target state="translated">Si se establece,scikit-learn intentará limitar el tamaño de las matrices temporales a este número de MiB (por trabajo cuando se paraleliza),a menudo ahorrando tanto tiempo de cálculo como memoria en operaciones costosas que pueden realizarse en trozos.Valor por defecto global:1024.</target>
        </trans-unit>
        <trans-unit id="cd9d66e1ab8be1fe689482ddb0cbca43b44a3950" translate="yes" xml:space="preserve">
          <source>If strictly positive, stop reading any new line of data once the position in the file has reached the (offset + length) bytes threshold.</source>
          <target state="translated">Si es estrictamente positivo,deje de leer cualquier nueva línea de datos una vez que la posición en el archivo haya alcanzado el umbral de (offset+longitud)bytes.</target>
        </trans-unit>
        <trans-unit id="af99c20b0f1015ebcecc8bfb6a50ca848ab08d15" translate="yes" xml:space="preserve">
          <source>If string, specifies the path that will contain the data. If file-like, data will be written to f. f should be opened in binary mode.</source>
          <target state="translated">Si la cadena,especifica el camino que contendrá los datos.Si es de tipo archivo,los datos se escribirán en f.f debe abrirse en modo binario.</target>
        </trans-unit>
        <trans-unit id="d25cbbfb18995acebbdc8e788e3994e16b21b8ae" translate="yes" xml:space="preserve">
          <source>If sum_over_features is False shape is (n_samples_X * n_samples_Y, n_features) and D contains the componentwise L1 pairwise-distances (ie. absolute difference), else shape is (n_samples_X, n_samples_Y) and D contains the pairwise L1 distances.</source>
          <target state="translated">Si sum_over_features es False shape es (n_samples_X*n_samples_Y,n_features)y D contiene las distancias por pares L1 en sentido componente (es decir,diferencia absoluta),si no shape es (n_samples_X,n_samples_Y)y D contiene las distancias por pares L1.</target>
        </trans-unit>
        <trans-unit id="1979731cc29c616c5ac5593ab888192599b2d46b" translate="yes" xml:space="preserve">
          <source>If the &lt;code&gt;loss&lt;/code&gt; does not support probabilities.</source>
          <target state="translated">Si la &lt;code&gt;loss&lt;/code&gt; no admite probabilidades.</target>
        </trans-unit>
        <trans-unit id="41f96f9118cd39448d94e68aca8aa6d327b368ef" translate="yes" xml:space="preserve">
          <source>If the algorithm is &amp;ldquo;deflation&amp;rdquo;, n_iter is the maximum number of iterations run across all components. Else they are just the number of iterations taken to converge.</source>
          <target state="translated">Si el algoritmo es &quot;deflaci&amp;oacute;n&quot;, n_iter es el n&amp;uacute;mero m&amp;aacute;ximo de iteraciones ejecutadas en todos los componentes. De lo contrario, son solo el n&amp;uacute;mero de iteraciones necesarias para converger.</target>
        </trans-unit>
        <trans-unit id="b72ab6a8a780a6da86f798b7381c54dc2236b80c" translate="yes" xml:space="preserve">
          <source>If the algorithm stops before fully converging (because of &lt;code&gt;tol&lt;/code&gt; of &lt;code&gt;max_iter&lt;/code&gt;), &lt;code&gt;labels_&lt;/code&gt; and &lt;code&gt;means_&lt;/code&gt; will not be consistent, i.e. the &lt;code&gt;means_&lt;/code&gt; will not be the means of the points in each cluster. Also, the estimator will reassign &lt;code&gt;labels_&lt;/code&gt; after the last iteration to make &lt;code&gt;labels_&lt;/code&gt; consistent with &lt;code&gt;predict&lt;/code&gt; on the training set.</source>
          <target state="translated">Si el algoritmo se detiene antes de converger completamente (debido a &lt;code&gt;tol&lt;/code&gt; de &lt;code&gt;max_iter&lt;/code&gt; ), las &lt;code&gt;labels_&lt;/code&gt; y &lt;code&gt;means_&lt;/code&gt; no ser&amp;aacute;n consistentes, es decir, las &lt;code&gt;means_&lt;/code&gt; no ser&amp;aacute;n las medias de los puntos en cada grupo. Adem&amp;aacute;s, el estimador reasignar&amp;aacute; las &lt;code&gt;labels_&lt;/code&gt; despu&amp;eacute;s de la &amp;uacute;ltima iteraci&amp;oacute;n para que las &lt;code&gt;labels_&lt;/code&gt; consistentes con &lt;code&gt;predict&lt;/code&gt; en el conjunto de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="12008b7aa6dad452411115d8236f3a855fd0fea9" translate="yes" xml:space="preserve">
          <source>If the algorithm stops before fully converging (because of &lt;code&gt;tol&lt;/code&gt; or &lt;code&gt;max_iter&lt;/code&gt;), &lt;code&gt;labels_&lt;/code&gt; and &lt;code&gt;cluster_centers_&lt;/code&gt; will not be consistent, i.e. the &lt;code&gt;cluster_centers_&lt;/code&gt; will not be the means of the points in each cluster. Also, the estimator will reassign &lt;code&gt;labels_&lt;/code&gt; after the last iteration to make &lt;code&gt;labels_&lt;/code&gt; consistent with &lt;code&gt;predict&lt;/code&gt; on the training set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4043c787702cc081c41f25b031d69ea98cf35c42" translate="yes" xml:space="preserve">
          <source>If the array is not symmetric, then a symmetrized version is returned. Optionally, a warning or exception is raised if the matrix is not symmetric.</source>
          <target state="translated">Si la matriz no es simétrica,entonces se devuelve una versión simétrica.Opcionalmente,se plantea una advertencia o excepción si la matriz no es simétrica.</target>
        </trans-unit>
        <trans-unit id="d4238935d45ce51eea0be6c47146a609e05c26ed" translate="yes" xml:space="preserve">
          <source>If the attributes are not found.</source>
          <target state="translated">Si no se encuentran los atributos.</target>
        </trans-unit>
        <trans-unit id="10f86bc0a8ef8d94dd88200305e21d6ac290743f" translate="yes" xml:space="preserve">
          <source>If the classifier performs equally well on either class, this term reduces to the conventional accuracy (i.e., the number of correct predictions divided by the total number of predictions).</source>
          <target state="translated">Si el clasificador funciona igual de bien en cualquiera de las dos clases,este término se reduce a la precisión convencional (es decir,el número de predicciones correctas dividido por el número total de predicciones).</target>
        </trans-unit>
        <trans-unit id="9d0651dbf433477af9dfe8c9482b03c0b28a7aea" translate="yes" xml:space="preserve">
          <source>If the data ordering is not arbitrary (e.g. samples with the same class label are contiguous), shuffling it first may be essential to get a meaningful cross- validation result. However, the opposite may be true if the samples are not independently and identically distributed. For example, if samples correspond to news articles, and are ordered by their time of publication, then shuffling the data will likely lead to a model that is overfit and an inflated validation score: it will be tested on samples that are artificially similar (close in time) to training samples.</source>
          <target state="translated">Si el orden de los datos no es arbitrario (por ejemplo,las muestras con la misma etiqueta de clase son contiguas),barajarlo primero puede ser esencial para obtener un resultado de validación cruzada significativo.Sin embargo,puede ocurrir lo contrario si las muestras no están distribuidas de forma independiente e idéntica.Por ejemplo,si las muestras corresponden a artículos de noticias,y se ordenan por su tiempo de publicación,entonces barajando los datos probablemente se obtendrá un modelo que se sobrepone y un resultado de validación inflado:se probará en muestras que son artificialmente similares (cercanas en el tiempo)a las muestras de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="4fdc5debb409dcec7a673c288152f0ef6e4738ef" translate="yes" xml:space="preserve">
          <source>If the default value is passed, then &lt;code&gt;keepdims&lt;/code&gt; will not be passed through to the &lt;code&gt;mean&lt;/code&gt; method of sub-classes of &lt;code&gt;ndarray&lt;/code&gt;, however any non-default value will be. If the sub-class&amp;rsquo; method does not implement &lt;code&gt;keepdims&lt;/code&gt; any exceptions will be raised.</source>
          <target state="translated">Si se pasa el valor predeterminado, &lt;code&gt;keepdims&lt;/code&gt; no se pasar&amp;aacute; al m&amp;eacute;todo &lt;code&gt;mean&lt;/code&gt; de las subclases de &lt;code&gt;ndarray&lt;/code&gt; , sin embargo, cualquier valor no predeterminado s&amp;iacute; lo ser&amp;aacute;. Si el m&amp;eacute;todo de la &lt;code&gt;keepdims&lt;/code&gt; no implementa keepdims , se generar&amp;aacute;n excepciones.</target>
        </trans-unit>
        <trans-unit id="322da3aec4cc8f30cb7592a5692203180007e581" translate="yes" xml:space="preserve">
          <source>If the degree is 2 or 3, the method described in &amp;ldquo;Leveraging Sparsity to Speed Up Polynomial Feature Expansions of CSR Matrices Using K-Simplex Numbers&amp;rdquo; by Andrew Nystrom and John Hughes is used, which is much faster than the method used on CSC input. For this reason, a CSC input will be converted to CSR, and the output will be converted back to CSC prior to being returned, hence the preference of CSR.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca5777d1057fb92ff835301c12f93dc71bd51069" translate="yes" xml:space="preserve">
          <source>If the difference between the current prediction and the correct label is below this threshold, the model is not updated.</source>
          <target state="translated">Si la diferencia entre la predicción actual y la etiqueta correcta está por debajo de este umbral,el modelo no se actualiza.</target>
        </trans-unit>
        <trans-unit id="54f187a0c12dbeb2b22455f8308653334a568512" translate="yes" xml:space="preserve">
          <source>If the estimator supports incremental learning, this will be used to speed up fitting for different training set sizes.</source>
          <target state="translated">Si el estimador apoya el aprendizaje incremental,esto se usará para acelerar el ajuste para diferentes tamaños de conjuntos de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="28446974a089033b0f005a14dd2e5e7cde0d019d" translate="yes" xml:space="preserve">
          <source>If the file does not exist yet, it is downloaded from mldata.org .</source>
          <target state="translated">Si el archivo no existe todavía,se descarga de mldata.org .</target>
        </trans-unit>
        <trans-unit id="3377386ec971b5f97505ad0b0efacd641307a6b2" translate="yes" xml:space="preserve">
          <source>If the folder does not already exist, it is automatically created.</source>
          <target state="translated">Si la carpeta no existe ya,se crea automáticamente.</target>
        </trans-unit>
        <trans-unit id="bcf86cd76452a354a39a384d6cc008f0521fadc0" translate="yes" xml:space="preserve">
          <source>If the gradient norm is below this threshold, the optimization will be stopped.</source>
          <target state="translated">Si la norma del gradiente está por debajo de este umbral,la optimización se detendrá.</target>
        </trans-unit>
        <trans-unit id="aaea0ac91de1101ebb5583d72a39edadc546a9ed" translate="yes" xml:space="preserve">
          <source>If the ground truth labels are not known, evaluation must be performed using the model itself. The Silhouette Coefficient (&lt;a href=&quot;generated/sklearn.metrics.silhouette_score#sklearn.metrics.silhouette_score&quot;&gt;&lt;code&gt;sklearn.metrics.silhouette_score&lt;/code&gt;&lt;/a&gt;) is an example of such an evaluation, where a higher Silhouette Coefficient score relates to a model with better defined clusters. The Silhouette Coefficient is defined for each sample and is composed of two scores:</source>
          <target state="translated">Si no se conocen las etiquetas de verdad del terreno, la evaluaci&amp;oacute;n debe realizarse utilizando el propio modelo. El coeficiente de silueta ( &lt;a href=&quot;generated/sklearn.metrics.silhouette_score#sklearn.metrics.silhouette_score&quot;&gt; &lt;code&gt;sklearn.metrics.silhouette_score&lt;/code&gt; &lt;/a&gt; ) es un ejemplo de tal evaluaci&amp;oacute;n, donde una puntuaci&amp;oacute;n m&amp;aacute;s alta del coeficiente de silueta se relaciona con un modelo con grupos mejor definidos. El coeficiente de silueta se define para cada muestra y se compone de dos puntuaciones:</target>
        </trans-unit>
        <trans-unit id="f86f2c18ff62eced8e4c69ce5c4a60d3487f70e2" translate="yes" xml:space="preserve">
          <source>If the ground truth labels are not known, the Calinski-Harabasz index (&lt;a href=&quot;generated/sklearn.metrics.calinski_harabasz_score#sklearn.metrics.calinski_harabasz_score&quot;&gt;&lt;code&gt;sklearn.metrics.calinski_harabasz_score&lt;/code&gt;&lt;/a&gt;) - also known as the Variance Ratio Criterion - can be used to evaluate the model, where a higher Calinski-Harabasz score relates to a model with better defined clusters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb3f5944370bdcf362ff4bffb46e8bf1ded41ef1" translate="yes" xml:space="preserve">
          <source>If the ground truth labels are not known, the Calinski-Harabaz index (&lt;a href=&quot;generated/sklearn.metrics.calinski_harabaz_score#sklearn.metrics.calinski_harabaz_score&quot;&gt;&lt;code&gt;sklearn.metrics.calinski_harabaz_score&lt;/code&gt;&lt;/a&gt;) - also known as the Variance Ratio Criterion - can be used to evaluate the model, where a higher Calinski-Harabaz score relates to a model with better defined clusters.</source>
          <target state="translated">Si no se conocen las etiquetas de la verdad fundamental, el &amp;iacute;ndice de Calinski-Harabaz ( &lt;a href=&quot;generated/sklearn.metrics.calinski_harabaz_score#sklearn.metrics.calinski_harabaz_score&quot;&gt; &lt;code&gt;sklearn.metrics.calinski_harabaz_score&lt;/code&gt; &lt;/a&gt; ), tambi&amp;eacute;n conocido como Criterio de relaci&amp;oacute;n de varianza, se puede utilizar para evaluar el modelo, donde una puntuaci&amp;oacute;n de Calinski-Harabaz m&amp;aacute;s alta se relaciona con un modelo con agrupaciones mejor definidas.</target>
        </trans-unit>
        <trans-unit id="a4a519d35f95c18e319df7e8878b98f013f9bd44" translate="yes" xml:space="preserve">
          <source>If the ground truth labels are not known, the Davies-Bouldin index (&lt;a href=&quot;generated/sklearn.metrics.davies_bouldin_score#sklearn.metrics.davies_bouldin_score&quot;&gt;&lt;code&gt;sklearn.metrics.davies_bouldin_score&lt;/code&gt;&lt;/a&gt;) can be used to evaluate the model, where a lower Davies-Bouldin index relates to a model with better separation between the clusters.</source>
          <target state="translated">Si no se conocen las etiquetas de verdad del terreno, el &amp;iacute;ndice de Davies-Bouldin ( &lt;a href=&quot;generated/sklearn.metrics.davies_bouldin_score#sklearn.metrics.davies_bouldin_score&quot;&gt; &lt;code&gt;sklearn.metrics.davies_bouldin_score&lt;/code&gt; &lt;/a&gt; ) se puede utilizar para evaluar el modelo, donde un &amp;iacute;ndice de Davies-Bouldin m&amp;aacute;s bajo se relaciona con un modelo con una mejor separaci&amp;oacute;n entre los grupos.</target>
        </trans-unit>
        <trans-unit id="7ce6861d9ec6948a6bc8aef858e97abae7ed0654" translate="yes" xml:space="preserve">
          <source>If the input is a sparse matrix, only the non-zero values are subject to update by the Binarizer class.</source>
          <target state="translated">Si la entrada es una matriz dispersa,sólo los valores que no son cero están sujetos a actualización por la clase Binarizer.</target>
        </trans-unit>
        <trans-unit id="c10a8d9d8c40f9f50dafe36b727f5b47e7075f19" translate="yes" xml:space="preserve">
          <source>If the input matrix X is very sparse, it is recommended to convert to sparse &lt;code&gt;csc_matrix&lt;/code&gt; before calling fit and sparse &lt;code&gt;csr_matrix&lt;/code&gt; before calling predict. Training time can be orders of magnitude faster for a sparse matrix input compared to a dense matrix when features have zero values in most of the samples.</source>
          <target state="translated">Si la matriz de entrada X es muy dispersa, se recomienda convertir a &lt;code&gt;csc_matrix&lt;/code&gt; dispersa antes de llamar a fit y &lt;code&gt;csr_matrix&lt;/code&gt; dispersa antes de llamar a predict. El tiempo de entrenamiento puede ser &amp;oacute;rdenes de magnitud m&amp;aacute;s r&amp;aacute;pido para una entrada de matriz escasa en comparaci&amp;oacute;n con una matriz densa cuando las entidades tienen valores cero en la mayor&amp;iacute;a de las muestras.</target>
        </trans-unit>
        <trans-unit id="661cb29a3f5fe68fda8ea5f8c53273efb7753ce1" translate="yes" xml:space="preserve">
          <source>If the labels are encoded with +1 and -1, \(y\): is the true value, and \(w\) is the predicted decisions as output by &lt;code&gt;decision_function&lt;/code&gt;, then the hinge loss is defined as:</source>
          <target state="translated">Si las etiquetas est&amp;aacute;n codificadas con +1 y -1, \ (y \): es el valor verdadero, y \ (w \) son las decisiones predichas como resultado de &lt;code&gt;decision_function&lt;/code&gt; , entonces la p&amp;eacute;rdida de bisagra se define como:</target>
        </trans-unit>
        <trans-unit id="30e7605353fedb22ff0c25c7418abbab28137e70" translate="yes" xml:space="preserve">
          <source>If the loss on a sample is greater than the &lt;code&gt;residual_threshold&lt;/code&gt;, then this sample is classified as an outlier.</source>
          <target state="translated">Si la p&amp;eacute;rdida en una muestra es mayor que &lt;code&gt;residual_threshold&lt;/code&gt; , esta muestra se clasifica como un valor at&amp;iacute;pico.</target>
        </trans-unit>
        <trans-unit id="fd47c1f065810b1b45f0d8d994aa0a4ff29505d4" translate="yes" xml:space="preserve">
          <source>If the metric constructor parameter is &amp;ldquo;precomputed&amp;rdquo;, X is assumed to be the distance matrix between the data to be predicted and &lt;code&gt;self.centroids_&lt;/code&gt;.</source>
          <target state="translated">Si el par&amp;aacute;metro del constructor m&amp;eacute;trico est&amp;aacute; &amp;ldquo;precalculado&amp;rdquo;, se supone que X es la matriz de distancia entre los datos que se van a predecir y &lt;code&gt;self.centroids_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c8476d320358236ab03a9b2e5775d6207658d4f7" translate="yes" xml:space="preserve">
          <source>If the metric is &amp;lsquo;precomputed&amp;rsquo; X must be a square distance matrix. Otherwise it contains a sample per row.</source>
          <target state="translated">Si la m&amp;eacute;trica est&amp;aacute; 'precalculada', X debe ser una matriz de distancia cuadrada. De lo contrario, contiene una muestra por fila.</target>
        </trans-unit>
        <trans-unit id="ed2846275337b6c05f70ce353bc177c3fd2fc1b0" translate="yes" xml:space="preserve">
          <source>If the metric is &amp;lsquo;precomputed&amp;rsquo; X must be a square distance matrix. Otherwise it contains a sample per row. If the method is &amp;lsquo;exact&amp;rsquo;, X may be a sparse matrix of type &amp;lsquo;csr&amp;rsquo;, &amp;lsquo;csc&amp;rsquo; or &amp;lsquo;coo&amp;rsquo;.</source>
          <target state="translated">Si la m&amp;eacute;trica est&amp;aacute; 'precalculada', X debe ser una matriz de distancia cuadrada. De lo contrario, contiene una muestra por fila. Si el m&amp;eacute;todo es 'exacto', X puede ser una matriz dispersa de tipo 'csr', 'csc' o 'coo'.</target>
        </trans-unit>
        <trans-unit id="3a27e115b0c223dd4eebc69d8c1ee49334684c4e" translate="yes" xml:space="preserve">
          <source>If the metric is &amp;lsquo;precomputed&amp;rsquo; X must be a square distance matrix. Otherwise it contains a sample per row. If the method is &amp;lsquo;exact&amp;rsquo;, X may be a sparse matrix of type &amp;lsquo;csr&amp;rsquo;, &amp;lsquo;csc&amp;rsquo; or &amp;lsquo;coo&amp;rsquo;. If the method is &amp;lsquo;barnes_hut&amp;rsquo; and the metric is &amp;lsquo;precomputed&amp;rsquo;, X may be a precomputed sparse graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be2b4ccc2ee21bcc622b72ad8a09e29905f86d22" translate="yes" xml:space="preserve">
          <source>If the number of features is \(p\), you now require \(n \sim 1/d^p\) points. Let&amp;rsquo;s say that we require 10 points in one dimension: now \(10^p\) points are required in \(p\) dimensions to pave the \([0, 1]\) space. As \(p\) becomes large, the number of training points required for a good estimator grows exponentially.</source>
          <target state="translated">Si el n&amp;uacute;mero de entidades es \ (p \), ahora necesita \ (n \ sim 1 / d ^ p \) puntos. Digamos que necesitamos 10 puntos en una dimensi&amp;oacute;n: ahora se requieren \ (10 ​​^ p \) puntos en las dimensiones \ (p \) para pavimentar el espacio \ ([0, 1] \). A medida que \ (p \) se vuelve grande, el n&amp;uacute;mero de puntos de entrenamiento necesarios para un buen estimador crece exponencialmente.</target>
        </trans-unit>
        <trans-unit id="31f6fadae8fdb5e25318685f0dd36c90a3234b90" translate="yes" xml:space="preserve">
          <source>If the number of features is much greater than the number of samples, avoid over-fitting in choosing &lt;a href=&quot;#svm-kernels&quot;&gt;Kernel functions&lt;/a&gt; and regularization term is crucial.</source>
          <target state="translated">Si el n&amp;uacute;mero de caracter&amp;iacute;sticas es mucho mayor que el n&amp;uacute;mero de muestras, evite el ajuste excesivo al elegir las &lt;a href=&quot;#svm-kernels&quot;&gt;funciones del Kernel&lt;/a&gt; y el t&amp;eacute;rmino de regularizaci&amp;oacute;n es crucial.</target>
        </trans-unit>
        <trans-unit id="421f2017551080d266c05ad587f0ba1ecff6bff8" translate="yes" xml:space="preserve">
          <source>If the number of instances of data needs to be reduced, or if one wants a large number of subclusters either as a preprocessing step or otherwise, Birch is more useful than MiniBatchKMeans.</source>
          <target state="translated">Si es necesario reducir el número de instancias de datos,o si se desea un gran número de subconjuntos,ya sea como paso previo al procesamiento o de otra manera,el abedul es más útil que el MiniBatchKMeans.</target>
        </trans-unit>
        <trans-unit id="0169ea68b458a3b315ac7acca32e943f8bdb1bed" translate="yes" xml:space="preserve">
          <source>If the option chosen is &amp;lsquo;ovr&amp;rsquo;, then a binary problem is fit for each label. For &amp;lsquo;multinomial&amp;rsquo; the loss minimised is the multinomial loss fit across the entire probability distribution, &lt;em&gt;even when the data is binary&lt;/em&gt;. &amp;lsquo;multinomial&amp;rsquo; is unavailable when solver=&amp;rsquo;liblinear&amp;rsquo;. &amp;lsquo;auto&amp;rsquo; selects &amp;lsquo;ovr&amp;rsquo; if the data is binary, or if solver=&amp;rsquo;liblinear&amp;rsquo;, and otherwise selects &amp;lsquo;multinomial&amp;rsquo;.</source>
          <target state="translated">Si la opci&amp;oacute;n elegida es 'ovr', entonces se ajusta un problema binario para cada etiqueta. Para 'multinomial', la p&amp;eacute;rdida minimizada es el ajuste de p&amp;eacute;rdida multinomial en toda la distribuci&amp;oacute;n de probabilidad, &lt;em&gt;incluso cuando los datos son binarios&lt;/em&gt; . 'multinomial' no est&amp;aacute; disponible cuando solver = 'liblinear'. 'auto' selecciona 'ovr' si los datos son binarios, o si solver = 'liblinear', y de lo contrario selecciona 'multinomial'.</target>
        </trans-unit>
        <trans-unit id="e56253ed1e137739144617c8f91af1433e314b57" translate="yes" xml:space="preserve">
          <source>If the output of the different transformers contains sparse matrices, these will be stacked as a sparse matrix if the overall density is lower than this value. Use &lt;code&gt;sparse_threshold=0&lt;/code&gt; to always return dense. When the transformed output consists of all dense data, the stacked result will be dense, and this keyword will be ignored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ff404c7c7b751e78382edbf95c1647019d00b38" translate="yes" xml:space="preserve">
          <source>If the parameter&amp;rsquo;s type does not match the desired type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="74c8a6dddf7307f96841c8e0079e93341eb05526" translate="yes" xml:space="preserve">
          <source>If the parameter&amp;rsquo;s value violates the given bounds.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb7bde2a134f67333f646adb3cb422fdb3b0a619" translate="yes" xml:space="preserve">
          <source>If the prediction task is to classify the observations in a set of finite labels, in other words to &amp;ldquo;name&amp;rdquo; the objects observed, the task is said to be a &lt;strong&gt;classification&lt;/strong&gt; task. On the other hand, if the goal is to predict a continuous target variable, it is said to be a &lt;strong&gt;regression&lt;/strong&gt; task.</source>
          <target state="translated">Si la tarea de predicci&amp;oacute;n es clasificar las observaciones en un conjunto de etiquetas finitas, en otras palabras, &quot;nombrar&quot; los objetos observados, se dice que la tarea es una tarea de &lt;strong&gt;clasificaci&amp;oacute;n&lt;/strong&gt; . Por otro lado, si el objetivo es predecir una variable objetivo continua, se dice que es una tarea de &lt;strong&gt;regresi&amp;oacute;n&lt;/strong&gt; .</target>
        </trans-unit>
        <trans-unit id="c305135e1b17987e86652a7910deafacf0f5dc9d" translate="yes" xml:space="preserve">
          <source>If the pyamg package is installed, it is used: this greatly speeds up computation.</source>
          <target state="translated">Si se instala el paquete pyamg,se utiliza:esto acelera enormemente la computación.</target>
        </trans-unit>
        <trans-unit id="04f07265ff7d7b70145be5aec52784e1b24d6f09" translate="yes" xml:space="preserve">
          <source>If the radius of the subcluster obtained by merging the new sample and the nearest subcluster is greater than the square of the threshold and if the number of subclusters is greater than the branching factor, then a space is temporarily allocated to this new sample. The two farthest subclusters are taken and the subclusters are divided into two groups on the basis of the distance between these subclusters.</source>
          <target state="translated">Si el radio del subclúster obtenido mediante la fusión de la nueva muestra y el subclúster más cercano es mayor que el cuadrado del umbral y si el número de subclústeres es mayor que el factor de ramificación,entonces se asigna temporalmente un espacio a esta nueva muestra.Se toman los dos subconjuntos más lejanos y se dividen los subconjuntos en dos grupos en función de la distancia entre estos subconjuntos.</target>
        </trans-unit>
        <trans-unit id="41eef1b8a501219131b2619b097a82294e78c28a" translate="yes" xml:space="preserve">
          <source>If the samples are weighted, it will be easier to optimize the tree structure using weight-based pre-pruning criterion such as &lt;code&gt;min_weight_fraction_leaf&lt;/code&gt;, which ensure that leaf nodes contain at least a fraction of the overall sum of the sample weights.</source>
          <target state="translated">Si las muestras est&amp;aacute;n ponderadas, ser&amp;aacute; m&amp;aacute;s f&amp;aacute;cil optimizar la estructura del &amp;aacute;rbol utilizando un criterio de poda previa basado en el peso, como &lt;code&gt;min_weight_fraction_leaf&lt;/code&gt; , que asegura que los nodos de las hojas contengan al menos una fracci&amp;oacute;n de la suma total de los pesos de la muestra.</target>
        </trans-unit>
        <trans-unit id="0c1baaebbfab363e25ace0c6b6ee91539fab116b" translate="yes" xml:space="preserve">
          <source>If the selected solver is &amp;lsquo;L-BFGS&amp;rsquo;, training does not support online nor mini-batch learning.</source>
          <target state="translated">Si el solucionador seleccionado es 'L-BFGS', la capacitaci&amp;oacute;n no admite el aprendizaje en l&amp;iacute;nea ni por mini lotes.</target>
        </trans-unit>
        <trans-unit id="6b79b273c5ccf0e85d810ff5a4ad56e9102a13be" translate="yes" xml:space="preserve">
          <source>If the target is a continuous value, then for node \(m\), representing a region \(R_m\) with \(N_m\) observations, common criteria to minimise as for determining locations for future splits are Mean Squared Error, which minimizes the L2 error using mean values at terminal nodes, and Mean Absolute Error, which minimizes the L1 error using median values at terminal nodes.</source>
          <target state="translated">Si el objetivo es un valor continuo,entonces para el nodo \(m\),que representa una región \Ncon \Nobservaciones,los criterios comunes a minimizar en cuanto a la determinación de las ubicaciones para futuras divisiones son el Error Medio Cuadrado,que minimiza el error L2 utilizando valores medios en los nodos terminales,y el Error Medio Absoluto,que minimiza el error L1 utilizando valores medios en los nodos terminales.</target>
        </trans-unit>
        <trans-unit id="43d2fac91a90af78192c1e9cb5f608e633304262" translate="yes" xml:space="preserve">
          <source>If the target values \(y\) are counts (non-negative integer valued) or relative frequencies (non-negative), you might use a Poisson deviance with log-link.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25b233fcf730d262746a1d2c5c4f20ca63e89053" translate="yes" xml:space="preserve">
          <source>If the target values are positive valued and skewed, you might try a Gamma deviance with log-link.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73b808b1b5912c4df231c6d6d8790651299cc5e0" translate="yes" xml:space="preserve">
          <source>If the target values seem to be heavier tailed than a Gamma distribution, you might try an Inverse Gaussian deviance (or even higher variance powers of the Tweedie family).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd360b0d17d9758c91116a373249c96c3c493365" translate="yes" xml:space="preserve">
          <source>If the text is in a mish-mash of encodings that is simply too hard to sort out (which is the case for the 20 Newsgroups dataset), you can fall back on a simple single-byte encoding such as &lt;code&gt;latin-1&lt;/code&gt;. Some text may display incorrectly, but at least the same sequence of bytes will always represent the same feature.</source>
          <target state="translated">Si el texto se encuentra en una mezcla de codificaciones que es simplemente demasiado dif&amp;iacute;cil de clasificar (que es el caso del conjunto de datos de 20 grupos de noticias), puede recurrir a una codificaci&amp;oacute;n simple de un solo byte como &lt;code&gt;latin-1&lt;/code&gt; . Es posible que parte del texto se muestre incorrectamente, pero al menos la misma secuencia de bytes siempre representar&amp;aacute; la misma caracter&amp;iacute;stica.</target>
        </trans-unit>
        <trans-unit id="21286b430a50cd4c4f50df67c996d4b5b475416f" translate="yes" xml:space="preserve">
          <source>If the text you are loading is not actually encoded with UTF-8, however, you will get a &lt;code&gt;UnicodeDecodeError&lt;/code&gt;. The vectorizers can be told to be silent about decoding errors by setting the &lt;code&gt;decode_error&lt;/code&gt; parameter to either &lt;code&gt;&quot;ignore&quot;&lt;/code&gt; or &lt;code&gt;&quot;replace&quot;&lt;/code&gt;. See the documentation for the Python function &lt;code&gt;bytes.decode&lt;/code&gt; for more details (type &lt;code&gt;help(bytes.decode)&lt;/code&gt; at the Python prompt).</source>
          <target state="translated">Sin embargo, si el texto que est&amp;aacute; cargando no est&amp;aacute; codificado con UTF-8, obtendr&amp;aacute; un &lt;code&gt;UnicodeDecodeError&lt;/code&gt; . Se puede decir a los &lt;code&gt;decode_error&lt;/code&gt; que guarden silencio sobre los errores de decodificaci&amp;oacute;n configurando el par&amp;aacute;metro decode_error en &lt;code&gt;&quot;ignore&quot;&lt;/code&gt; o &lt;code&gt;&quot;replace&quot;&lt;/code&gt; . Consulte la documentaci&amp;oacute;n de la funci&amp;oacute;n de Python &lt;code&gt;bytes.decode&lt;/code&gt; para obtener m&amp;aacute;s detalles (escriba &lt;code&gt;help(bytes.decode)&lt;/code&gt; en el indicador de Python).</target>
        </trans-unit>
        <trans-unit id="13a9f813159d9e6258a164870cb1dc6a301dddd5" translate="yes" xml:space="preserve">
          <source>If the training score and the validation score are both low, the estimator will be underfitting. If the training score is high and the validation score is low, the estimator is overfitting and otherwise it is working very well. A low training score and a high validation score is usually not possible. All three cases can be found in the plot below where we vary the parameter \(\gamma\) of an SVM on the digits dataset.</source>
          <target state="translated">Si el puntaje de entrenamiento y el puntaje de validación son ambos bajos,el estimador no se ajustará.Si el puntaje de entrenamiento es alto y el puntaje de validación es bajo,el estimador se está adaptando demasiado y por lo demás está funcionando muy bien.Normalmente no es posible obtener un resultado de formación bajo y un resultado de validación alto.Los tres casos se pueden encontrar en el siguiente gráfico donde variamos el parámetro de un SVM en el conjunto de datos de los dígitos.</target>
        </trans-unit>
        <trans-unit id="80e789647361ff21671194a00300fe312dc530d2" translate="yes" xml:space="preserve">
          <source>If the transformed output consists of a mix of sparse and dense data, it will be stacked as a sparse matrix if the density is lower than this value. Use &lt;code&gt;sparse_threshold=0&lt;/code&gt; to always return dense. When the transformed output consists of all sparse or all dense data, the stacked result will be sparse or dense, respectively, and this keyword will be ignored.</source>
          <target state="translated">Si la salida transformada consiste en una combinaci&amp;oacute;n de datos densos y escasos, se apilar&amp;aacute; como una matriz dispersa si la densidad es menor que este valor. Utilice &lt;code&gt;sparse_threshold=0&lt;/code&gt; para devolver siempre denso. Cuando la salida transformada consta de todos los datos escasos o densos, el resultado apilado ser&amp;aacute; escaso o denso, respectivamente, y esta palabra clave se ignorar&amp;aacute;.</target>
        </trans-unit>
        <trans-unit id="efca83041c066057e65d83989c4190b74b69dba6" translate="yes" xml:space="preserve">
          <source>If the underlying graph has nodes with much more connections than the average node, the algorithm will miss some of these connections.</source>
          <target state="translated">Si el gráfico subyacente tiene nodos con muchas más conexiones que el nodo promedio,el algoritmo perderá algunas de estas conexiones.</target>
        </trans-unit>
        <trans-unit id="27f470c8c1d74aa01f92e63860f4d2b9149dd0bb" translate="yes" xml:space="preserve">
          <source>If there are few data points per dimension, noise in the observations induces high variance:</source>
          <target state="translated">Si hay pocos puntos de datos por dimensión,el ruido en las observaciones induce una alta variabilidad:</target>
        </trans-unit>
        <trans-unit id="fbaec65eed1139944f6f906201326eaef7bc4d08" translate="yes" xml:space="preserve">
          <source>If there are more than two classes, \(f(x)\) itself would be a vector of size (n_classes,). Instead of passing through logistic function, it passes through the softmax function, which is written as,</source>
          <target state="translated">Si hay más de dos clases,el mismo sería un vector de tamaño (n_clases,).En lugar de pasar por la función logística,pasa por la función softmax,que se escribe como,</target>
        </trans-unit>
        <trans-unit id="e2c9b002eac60ce02e4a3cafb47196266855c43e" translate="yes" xml:space="preserve">
          <source>If there are more than two labels, &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt;&lt;code&gt;hinge_loss&lt;/code&gt;&lt;/a&gt; uses a multiclass variant due to Crammer &amp;amp; Singer. &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume2/crammer01a/crammer01a.pdf&quot;&gt;Here&lt;/a&gt; is the paper describing it.</source>
          <target state="translated">Si hay m&amp;aacute;s de dos etiquetas, &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt; &lt;code&gt;hinge_loss&lt;/code&gt; &lt;/a&gt; usa una variante multiclase debido a Crammer &amp;amp; Singer. &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume2/crammer01a/crammer01a.pdf&quot;&gt;Aqu&amp;iacute;&lt;/a&gt; est&amp;aacute; el art&amp;iacute;culo que lo describe.</target>
        </trans-unit>
        <trans-unit id="362b6e0ad023f937918b9ce5c294c8243f2c8ea1" translate="yes" xml:space="preserve">
          <source>If there is a possibility that the training data might have missing categorical features, it can often be better to specify &lt;code&gt;handle_unknown='ignore'&lt;/code&gt; instead of setting the &lt;code&gt;categories&lt;/code&gt; manually as above. When &lt;code&gt;handle_unknown='ignore'&lt;/code&gt; is specified and unknown categories are encountered during transform, no error will be raised but the resulting one-hot encoded columns for this feature will be all zeros (&lt;code&gt;handle_unknown='ignore'&lt;/code&gt; is only supported for one-hot encoding):</source>
          <target state="translated">Si existe la posibilidad de que a los datos de entrenamiento les falten caracter&amp;iacute;sticas categ&amp;oacute;ricas, a menudo puede ser mejor especificar &lt;code&gt;handle_unknown='ignore'&lt;/code&gt; en lugar de configurar las &lt;code&gt;categories&lt;/code&gt; manualmente como se indic&amp;oacute; anteriormente. Cuando se especifica &lt;code&gt;handle_unknown='ignore'&lt;/code&gt; y se encuentran categor&amp;iacute;as desconocidas durante la transformaci&amp;oacute;n, no se generar&amp;aacute; ning&amp;uacute;n error, pero las columnas codificadas one-hot resultantes para esta funci&amp;oacute;n ser&amp;aacute;n todas ceros ( &lt;code&gt;handle_unknown='ignore'&lt;/code&gt; solo es compatible con la codificaci&amp;oacute;n one-hot ):</target>
        </trans-unit>
        <trans-unit id="76c3aee0f8dcd7757eeddd2a91b271bc2108fb17" translate="yes" xml:space="preserve">
          <source>If there is more than one such value, only the first is returned. The bin-count for the modal bins is also returned.</source>
          <target state="translated">Si hay más de un valor de este tipo,sólo se devuelve el primero.También se devuelve el recuento de los contenedores modales.</target>
        </trans-unit>
        <trans-unit id="e4599c6e53b844db2376ed9e56ed7b49e63c6ec3" translate="yes" xml:space="preserve">
          <source>If this is a tuple of ints, a mean is performed over multiple axes, instead of a single axis or all the axes as before.</source>
          <target state="translated">Si se trata de una tupla de ints,se realiza una media sobre varios ejes,en lugar de un solo eje o todos los ejes como antes.</target>
        </trans-unit>
        <trans-unit id="015e500928e7c3f86f2c9b5121c746246fcd7a9f" translate="yes" xml:space="preserve">
          <source>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array.</source>
          <target state="translated">Si esto se establece en True,los ejes que se reducen se dejan en el resultado como dimensiones con tamaño uno.Con esta opción,el resultado se emitirá correctamente contra la matriz de entrada.</target>
        </trans-unit>
        <trans-unit id="1d47783a4de427039b4db643f305b3dd195e7ba2" translate="yes" xml:space="preserve">
          <source>If this split node has a parent subcluster and there is room for a new subcluster, then the parent is split into two. If there is no room, then this node is again split into two and the process is continued recursively, till it reaches the root.</source>
          <target state="translated">Si este nodo dividido tiene un subconjunto padre y hay espacio para un nuevo subconjunto,entonces el padre se divide en dos.Si no hay espacio,entonces este nodo se divide de nuevo en dos y el proceso continúa recursivamente,hasta que llega a la raíz.</target>
        </trans-unit>
        <trans-unit id="012f5a7e85e6e4a424dae20b5f0c103c4fa516ee" translate="yes" xml:space="preserve">
          <source>If true (default), use a breadth-first approach to the problem. Otherwise use a depth-first approach.</source>
          <target state="translated">Si es cierto (por defecto),utilice un enfoque de amplitud primero para el problema.De lo contrario,utilice un enfoque de profundidad primero.</target>
        </trans-unit>
        <trans-unit id="5f57fd46a52f081b17c9c11ebb2ef30582e94549" translate="yes" xml:space="preserve">
          <source>If true the classification weights will be exported on each leaf. The classification weights are the number of samples each class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cec7c6586dbaf8eb8cda6633d2caddbd361cde5b" translate="yes" xml:space="preserve">
          <source>If true, &lt;code&gt;decision_function_shape='ovr'&lt;/code&gt;, and number of classes &amp;gt; 2, &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict&quot;&gt;predict&lt;/a&gt; will break ties according to the confidence values of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt;; otherwise the first class among the tied classes is returned. Please note that breaking ties comes at a relatively high computational cost compared to a simple predict.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8002efc50268110232cc0ffbdad97c50440caadd" translate="yes" xml:space="preserve">
          <source>If true, X and y will be centered.</source>
          <target state="translated">Si es cierto,X e Y estarán centrados.</target>
        </trans-unit>
        <trans-unit id="de73b79cb6d725781d21d3fce59be150e3f40a4c" translate="yes" xml:space="preserve">
          <source>If true, initial kernel locations are not locations of all points, but rather the location of the discretized version of points, where points are binned onto a grid whose coarseness corresponds to the bandwidth. Setting this option to True will speed up the algorithm because fewer seeds will be initialized. Ignored if seeds argument is not None.</source>
          <target state="translated">Si es cierto,las ubicaciones iniciales del núcleo no son las ubicaciones de todos los puntos,sino más bien la ubicación de la versión discretizada de los puntos,en la que los puntos están ubicados en una cuadrícula cuya grosería corresponde al ancho de banda.Si se establece esta opción en True se acelerará el algoritmo porque se inicializarán menos semillas.Se ignora si el argumento de las semillas no es None.</target>
        </trans-unit>
        <trans-unit id="8e21ac3d3be6bbf299e61e387ddc28e4aa0e4b76" translate="yes" xml:space="preserve">
          <source>If true, initial kernel locations are not locations of all points, but rather the location of the discretized version of points, where points are binned onto a grid whose coarseness corresponds to the bandwidth. Setting this option to True will speed up the algorithm because fewer seeds will be initialized. The default value is False. Ignored if seeds argument is not None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="382a329c7d03e3dc0838d8f846116bb309725e41" translate="yes" xml:space="preserve">
          <source>If true, initial kernel locations are not locations of all points, but rather the location of the discretized version of points, where points are binned onto a grid whose coarseness corresponds to the bandwidth. Setting this option to True will speed up the algorithm because fewer seeds will be initialized. default value: False Ignored if seeds argument is not None.</source>
          <target state="translated">Si es cierto,las ubicaciones iniciales del núcleo no son las ubicaciones de todos los puntos,sino más bien la ubicación de la versión discretizada de los puntos,en la que los puntos están ubicados en una cuadrícula cuya grosería corresponde al ancho de banda.Si se establece esta opción en True se acelerará el algoritmo porque se inicializarán menos semillas.valor predeterminado:Falso Ignorado si el argumento de las semillas no es None.</target>
        </trans-unit>
        <trans-unit id="5f8f1503f4ad4447aabcfddb9ab2a5dcd7bfde79" translate="yes" xml:space="preserve">
          <source>If true, only interaction features are produced: features that are products of at most &lt;code&gt;degree&lt;/code&gt;&lt;em&gt;distinct&lt;/em&gt; input features (so not &lt;code&gt;x[1] ** 2&lt;/code&gt;, &lt;code&gt;x[0] * x[2] ** 3&lt;/code&gt;, etc.).</source>
          <target state="translated">Si es verdadero, solo se producen caracter&amp;iacute;sticas de interacci&amp;oacute;n: caracter&amp;iacute;sticas que son productos de &lt;em&gt;caracter&amp;iacute;sticas de&lt;/em&gt; entrada &lt;em&gt;distintas&lt;/em&gt; en su mayor &lt;code&gt;degree&lt;/code&gt; (por lo tanto, no &lt;code&gt;x[1] ** 2&lt;/code&gt; , &lt;code&gt;x[0] * x[2] ** 3&lt;/code&gt; , etc.).&lt;em&gt;&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="2d6ce18ffe19be253728c95b7f8882b85215b418" translate="yes" xml:space="preserve">
          <source>If true, randomize the order of coordinates in the CD solver.</source>
          <target state="translated">Si es cierto,aleatoriza el orden de las coordenadas en el solucionador de CD.</target>
        </trans-unit>
        <trans-unit id="c9d7c7ecbdd08be425848806cc6f9d68c29d7323" translate="yes" xml:space="preserve">
          <source>If true, return the mean loss per sample. Otherwise, return the sum of the per-sample losses.</source>
          <target state="translated">Si es cierto,devuelva la pérdida media por muestra.En caso contrario,devuelva la suma de las pérdidas por muestra.</target>
        </trans-unit>
        <trans-unit id="6d32e9cabd3e10e0279ad9dd2b7c71514057bf52" translate="yes" xml:space="preserve">
          <source>If true, then all points are clustered, even those orphans that are not within any kernel. Orphans are assigned to the nearest kernel. If false, then orphans are given cluster label -1.</source>
          <target state="translated">Si es cierto,entonces todos los puntos están agrupados,incluso los huérfanos que no están dentro de ningún núcleo.Los huérfanos son asignados al núcleo más cercano.Si es falso,entonces a los huérfanos se les da la etiqueta de grupo -1.</target>
        </trans-unit>
        <trans-unit id="87535a59e28d16a49b32c83a6882f2aefd67503d" translate="yes" xml:space="preserve">
          <source>If true, use a dualtree algorithm. Otherwise, use a single-tree algorithm. Dual tree algorithms can have better scaling for large N.</source>
          <target state="translated">Si es cierto,use un algoritmo de doble árbol.De lo contrario,use un algoritmo de árbol único.Los algoritmos de árbol dual pueden tener una mejor escala para el N grande.</target>
        </trans-unit>
        <trans-unit id="1f1b5d26ff8a3e05067cc01bd3cc7a0f425c7062" translate="yes" xml:space="preserve">
          <source>If two features are almost equally correlated with the target, then their coefficients should increase at approximately the same rate. The algorithm thus behaves as intuition would expect, and also is more stable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a62f22814f97612f53d5c62d8ea50a484acea3fc" translate="yes" xml:space="preserve">
          <source>If two variables are almost equally correlated with the response, then their coefficients should increase at approximately the same rate. The algorithm thus behaves as intuition would expect, and also is more stable.</source>
          <target state="translated">Si dos variables están casi igualmente correlacionadas con la respuesta,entonces sus coeficientes deberían aumentar aproximadamente a la misma velocidad.El algoritmo se comporta así como la intuición esperaría,y también es más estable.</target>
        </trans-unit>
        <trans-unit id="c6d813716240a58cb1e341ee096ed78ff4d17824" translate="yes" xml:space="preserve">
          <source>If verbose is True, the objective function and dual gap are plotted at each iteration.</source>
          <target state="translated">Si la verbosidad es verdadera,la función objetiva y la doble brecha se trazan en cada iteración.</target>
        </trans-unit>
        <trans-unit id="c845cf733c967b921d034159fbd6e6d551e8f5a1" translate="yes" xml:space="preserve">
          <source>If verbose is True, the objective function and dual gap are printed at each iteration.</source>
          <target state="translated">Si la verbosidad es verdadera,la función objetivo y la doble brecha se imprimen en cada iteración.</target>
        </trans-unit>
        <trans-unit id="d04bb65f95446e17ac813ad52d517cc52bee8bef" translate="yes" xml:space="preserve">
          <source>If verbose is True, the objective function and duality gap are printed at each iteration.</source>
          <target state="translated">Si la palabra &quot;verboso&quot; es &quot;verdadero&quot;,la función objetivo y la brecha de dualidad se imprimen en cada iteración.</target>
        </trans-unit>
        <trans-unit id="c297e2c2dea63aea70529d05594e08d33ba95930" translate="yes" xml:space="preserve">
          <source>If warm-starts are enabled, the solution of the last Newton iteration on the Laplace approximation of the posterior mode is used as initialization for the next call of _posterior_mode(). This can speed up convergence when _posterior_mode is called several times on similar problems as in hyperparameter optimization. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Si los inicios en caliente est&amp;aacute;n habilitados, la soluci&amp;oacute;n de la &amp;uacute;ltima iteraci&amp;oacute;n de Newton en la aproximaci&amp;oacute;n de Laplace del modo posterior se usa como inicializaci&amp;oacute;n para la siguiente llamada de _posterior_mode (). Esto puede acelerar la convergencia cuando se llama a _posterior_mode varias veces en problemas similares como en la optimizaci&amp;oacute;n de hiperpar&amp;aacute;metros. Consulte &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;el glosario&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="250e3ab5ccbd8ff9f61320148d394ace048df253" translate="yes" xml:space="preserve">
          <source>If warm-starts are enabled, the solution of the last Newton iteration on the Laplace approximation of the posterior mode is used as initialization for the next call of _posterior_mode(). This can speed up convergence when _posterior_mode is called several times on similar problems as in hyperparameter optimization. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0beda1307d8fba8bf455ad043421d0e1b5743334" translate="yes" xml:space="preserve">
          <source>If we consider the loss function to be the individual error per sample, then the data-fit term, or the sum of the error for each sample, will increase as we add more samples. The penalization term, however, will not increase.</source>
          <target state="translated">Si consideramos que la función de pérdida es el error individual por muestra,entonces el término de ajuste de datos,o la suma del error de cada muestra,aumentará a medida que añadamos más muestras.El término de penalización,sin embargo,no aumentará.</target>
        </trans-unit>
        <trans-unit id="232b0b83965c86185ba5cb4047fca7ca1eb2e5e8" translate="yes" xml:space="preserve">
          <source>If we define &lt;code&gt;s = 1 / density&lt;/code&gt;, the elements of the random matrix are drawn from</source>
          <target state="translated">Si definimos &lt;code&gt;s = 1 / density&lt;/code&gt; , los elementos de la matriz aleatoria se extraen de</target>
        </trans-unit>
        <trans-unit id="de1968292a81bf57ac7d922cf400e8863c649aea" translate="yes" xml:space="preserve">
          <source>If we increase &lt;code&gt;power&lt;/code&gt; to 1,:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1427e0ae27c6ada10257117ddf3e602836e812e6" translate="yes" xml:space="preserve">
          <source>If we note &lt;code&gt;s = 1 / density&lt;/code&gt; the components of the random matrix are drawn from:</source>
          <target state="translated">Si observamos &lt;code&gt;s = 1 / density&lt;/code&gt; los componentes de la matriz aleatoria se extraen de:</target>
        </trans-unit>
        <trans-unit id="f9cbc4d2964857d1865d4f91b696f12d3cce3cff" translate="yes" xml:space="preserve">
          <source>If we note \(n_{\max} = \max(n_{\mathrm{samples}}, n_{\mathrm{features}})\) and \(n_{\min} = \min(n_{\mathrm{samples}}, n_{\mathrm{features}})\), the time complexity of the randomized &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; is \(O(n_{\max}^2 \cdot n_{\mathrm{components}})\) instead of \(O(n_{\max}^2 \cdot n_{\min})\) for the exact method implemented in &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Si notamos \ (n _ {\ max} = \ max (n _ {\ mathrm {muestras}}, n _ {\ mathrm {caracter&amp;iacute;sticas}}) \) y \ (n _ {\ min} = \ min (n _ {\ mathrm {samples}}, n _ {\ mathrm {features}}) \), la complejidad de tiempo del &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; aleatorio es \ (O (n _ {\ max} ^ 2 \ cdot n _ {\ mathrm {components}}) \) en su lugar of \ (O (n _ {\ max} ^ 2 \ cdot n _ {\ min}) \) para el m&amp;eacute;todo exacto implementado en &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="483854d9b52bcc6a7814b6c99e197398a7767c0e" translate="yes" xml:space="preserve">
          <source>If we use l2 shrinkage, as with the Ledoit-Wolf estimator, as the number of samples is small, we need to shrink a lot. As a result, the Ledoit-Wolf precision is fairly close to the ground truth precision, that is not far from being diagonal, but the off-diagonal structure is lost.</source>
          <target state="translated">Si usamos la contracción l2,como con el estimador Ledoit-Wolf,ya que el número de muestras es pequeño,necesitamos reducir mucho.Como resultado,la precisión de Ledoit-Wolf es bastante cercana a la precisión de la verdad del terreno,que no está lejos de ser diagonal,pero la estructura fuera de la diagonal se pierde.</target>
        </trans-unit>
        <trans-unit id="c048d2d806d4fc664d0d49e2240da1f9038d7165" translate="yes" xml:space="preserve">
          <source>If we want to fit a paraboloid to the data instead of a plane, we can combine the features in second-order polynomials, so that the model looks like this:</source>
          <target state="translated">Si queremos ajustar un paraboloide a los datos en lugar de un plano,podemos combinar las características en polinomios de segundo orden,para que el modelo tenga este aspecto:</target>
        </trans-unit>
        <trans-unit id="9cd2bdd13889db844fd297c5019d226d5f2214ec" translate="yes" xml:space="preserve">
          <source>If we would restrict the model further, by assuming that the Gaussian noise is even isotropic (all diagonal entries are the same) we would obtain &lt;code&gt;PPCA&lt;/code&gt;.</source>
          <target state="translated">Si restringi&amp;eacute;ramos a&amp;uacute;n m&amp;aacute;s el modelo, asumiendo que el ruido gaussiano es incluso is&amp;oacute;tropo (todas las entradas diagonales son iguales) obtendr&amp;iacute;amos &lt;code&gt;PPCA&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="722d8ecf13f293f3aeb1f206f30063d8afe3b1aa" translate="yes" xml:space="preserve">
          <source>If whiten is false, the data is already considered to be whitened, and no whitening is performed.</source>
          <target state="translated">Si el blanqueo es falso,los datos ya se consideran blanqueados y no se realiza ningún blanqueo.</target>
        </trans-unit>
        <trans-unit id="7d7146f3cf5f6ee3a12daad9561636b3070c19dc" translate="yes" xml:space="preserve">
          <source>If whitening is enabled, inverse_transform will compute the exact inverse operation, which includes reversing whitening.</source>
          <target state="translated">Si se habilita el blanqueamiento,la transformación_inversa calculará la operación inversa exacta,que incluye la inversión del blanqueamiento.</target>
        </trans-unit>
        <trans-unit id="d6701cdf426d6a22381b3dd206332eab0defeb4b" translate="yes" xml:space="preserve">
          <source>If you apply SGD to features extracted using PCA we found that it is often wise to scale the feature values by some constant &lt;code&gt;c&lt;/code&gt; such that the average L2 norm of the training data equals one.</source>
          <target state="translated">Si aplica SGD a las caracter&amp;iacute;sticas extra&amp;iacute;das mediante PCA, descubrimos que a menudo es aconsejable escalar los valores de las caracter&amp;iacute;sticas mediante una constante &lt;code&gt;c&lt;/code&gt; de modo que la norma L2 promedio de los datos de entrenamiento sea igual a uno.</target>
        </trans-unit>
        <trans-unit id="88e7b5f8ea1b769958767cd4c4986cb0d84b69d4" translate="yes" xml:space="preserve">
          <source>If you are having trouble decoding text, here are some things to try:</source>
          <target state="translated">Si tienes problemas para descifrar el texto,aquí tienes algunas cosas que puedes probar:</target>
        </trans-unit>
        <trans-unit id="79c8dbf5a9dd8e0bcb21dbc0b3d21d4a002af1f5" translate="yes" xml:space="preserve">
          <source>If you are interested in controlling the L1 and L2 penalty separately, keep in mind that this is equivalent to:</source>
          <target state="translated">Si le interesa controlar la pena L1 y L2 por separado,tenga en cuenta que esto equivale a..:</target>
        </trans-unit>
        <trans-unit id="fda5569b1e927ca58d1243554ef8331577e43162" translate="yes" xml:space="preserve">
          <source>If you do not provide an a-priori dictionary and you do not use an analyzer that does some kind of feature selection then the number of features will be equal to the vocabulary size found by analyzing the data.</source>
          <target state="translated">Si no proporciona un diccionario a-priori y no utiliza un analizador que haga algún tipo de selección de características,entonces el número de características será igual al tamaño del vocabulario encontrado al analizar los datos.</target>
        </trans-unit>
        <trans-unit id="44906a85511569286aafb87826155b3c2905ddf9" translate="yes" xml:space="preserve">
          <source>If you don&amp;rsquo;t have labels, try using &lt;a href=&quot;../../auto_examples/text/plot_document_clustering#sphx-glr-auto-examples-text-plot-document-clustering-py&quot;&gt;Clustering&lt;/a&gt; on your problem.</source>
          <target state="translated">Si no tiene etiquetas, intente usar &lt;a href=&quot;../../auto_examples/text/plot_document_clustering#sphx-glr-auto-examples-text-plot-document-clustering-py&quot;&gt;Clustering&lt;/a&gt; en su problema.</target>
        </trans-unit>
        <trans-unit id="951c73020178956033a4088912e01e49fd5d4ad8" translate="yes" xml:space="preserve">
          <source>If you encounter a bug with &lt;code&gt;scikit-learn&lt;/code&gt; or something that needs clarification in the docstring or the online documentation, please feel free to ask on the &lt;a href=&quot;http://scikit-learn.org/stable/support.html&quot;&gt;Mailing List&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e3c9a76f4703e92f09f761bb01632ba0994c7fc" translate="yes" xml:space="preserve">
          <source>If you experience hanging subprocesses with &lt;code&gt;n_jobs&amp;gt;1&lt;/code&gt; or &lt;code&gt;n_jobs=-1&lt;/code&gt;, make sure you have a single-threaded BLAS library, or set &lt;code&gt;n_jobs=1&lt;/code&gt;, or upgrade to Python 3.4 which has a new version of &lt;code&gt;multiprocessing&lt;/code&gt; that should be immune to this problem.</source>
          <target state="translated">Si experimenta subprocesos colgantes con &lt;code&gt;n_jobs&amp;gt;1&lt;/code&gt; o &lt;code&gt;n_jobs=-1&lt;/code&gt; , aseg&amp;uacute;rese de tener una biblioteca BLAS de un solo subproceso, o establezca &lt;code&gt;n_jobs=1&lt;/code&gt; , o actualice a Python 3.4, que tiene una nueva versi&amp;oacute;n de &lt;code&gt;multiprocessing&lt;/code&gt; que deber&amp;iacute;a ser inmune a esto problema.</target>
        </trans-unit>
        <trans-unit id="01bbb2c6066f4ee0c3cd8eec64a157d2ed58c8df" translate="yes" xml:space="preserve">
          <source>If you have a kernel matrix of a kernel \(K\) that computes a dot product in a feature space defined by function \(\phi\), a &lt;a href=&quot;generated/sklearn.preprocessing.kernelcenterer#sklearn.preprocessing.KernelCenterer&quot;&gt;&lt;code&gt;KernelCenterer&lt;/code&gt;&lt;/a&gt; can transform the kernel matrix so that it contains inner products in the feature space defined by \(\phi\) followed by removal of the mean in that space.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4d3f940390acd5b7c567c108aba27222ddceb7d" translate="yes" xml:space="preserve">
          <source>If you have a kernel matrix of a kernel \(K\) that computes a dot product in a feature space defined by function \(phi\), a &lt;a href=&quot;generated/sklearn.preprocessing.kernelcenterer#sklearn.preprocessing.KernelCenterer&quot;&gt;&lt;code&gt;KernelCenterer&lt;/code&gt;&lt;/a&gt; can transform the kernel matrix so that it contains inner products in the feature space defined by \(phi\) followed by removal of the mean in that space.</source>
          <target state="translated">Si tiene una matriz de kernel de un kernel \ (K \) que calcula un producto &lt;a href=&quot;generated/sklearn.preprocessing.kernelcenterer#sklearn.preprocessing.KernelCenterer&quot;&gt; &lt;code&gt;KernelCenterer&lt;/code&gt; &lt;/a&gt; en un espacio de caracter&amp;iacute;sticas definido por la funci&amp;oacute;n \ (phi \), un KernelCenterer puede transformar la matriz de kernel para que contenga productos internos en el espacio de caracter&amp;iacute;sticas definido por \ (phi \) seguido de la eliminaci&amp;oacute;n de la media en ese espacio.</target>
        </trans-unit>
        <trans-unit id="2615ef2dcc8005e7f8f1fe1a8b864f8c5c8b40ba" translate="yes" xml:space="preserve">
          <source>If you have an affinity matrix, such as a distance matrix, for which 0 means identical elements, and high values means very dissimilar elements, it can be transformed in a similarity matrix that is well suited for the algorithm by applying the Gaussian (RBF, heat) kernel:</source>
          <target state="translated">Si se tiene una matriz de afinidad,como una matriz de distancia,para la cual 0 significa elementos idénticos,y valores altos significa elementos muy disímiles,puede transformarse en una matriz de similitud que se adapte bien al algoritmo aplicando el núcleo gaussiano (RBF,calor):</target>
        </trans-unit>
        <trans-unit id="fe35ae96a69c356c4c790a684b706493b567f769" translate="yes" xml:space="preserve">
          <source>If you have multiple labels per document, e.g categories, have a look at the &lt;a href=&quot;../../modules/multiclass#multiclass&quot;&gt;Multiclass and multilabel section&lt;/a&gt;.</source>
          <target state="translated">Si tiene varias etiquetas por documento, por ejemplo, categor&amp;iacute;as, eche un vistazo a la &lt;a href=&quot;../../modules/multiclass#multiclass&quot;&gt;secci&amp;oacute;n Multiclass y multilabel&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="4c5f38a361bcbafd12cc29508483a444dfcf9728" translate="yes" xml:space="preserve">
          <source>If you have several classes to predict, an option often used is to fit one-versus-all classifiers and then use a voting heuristic for the final decision.</source>
          <target state="translated">Si se tienen varias clases para predecir,una opción que se utiliza a menudo es la de ajustar uno contra todos los clasificadores y luego utilizar un heurístico de votación para la decisión final.</target>
        </trans-unit>
        <trans-unit id="f97615967054f5695c197161c38be5160cb380e9" translate="yes" xml:space="preserve">
          <source>If you need the raw values of the partial dependence function rather than the plots you can use the &lt;a href=&quot;generated/sklearn.ensemble.partial_dependence.partial_dependence#sklearn.ensemble.partial_dependence.partial_dependence&quot;&gt;&lt;code&gt;partial_dependence&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Si necesita los valores en bruto de la funci&amp;oacute;n de la dependencia parcial en lugar de las parcelas se puede utilizar el &lt;a href=&quot;generated/sklearn.ensemble.partial_dependence.partial_dependence#sklearn.ensemble.partial_dependence.partial_dependence&quot;&gt; &lt;code&gt;partial_dependence&lt;/code&gt; &lt;/a&gt; funci&amp;oacute;n:</target>
        </trans-unit>
        <trans-unit id="89ce73b51d6a3d39879546007326b93ba776d729" translate="yes" xml:space="preserve">
          <source>If you need the raw values of the partial dependence function rather than the plots, you can use the &lt;a href=&quot;generated/sklearn.inspection.partial_dependence#sklearn.inspection.partial_dependence&quot;&gt;&lt;code&gt;sklearn.inspection.partial_dependence&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57ce2ca8cd47ab25ffa05da2880829913ab0ea8d" translate="yes" xml:space="preserve">
          <source>If you really want to use &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; for novelty detection, i.e. predict labels or compute the score of abnormality of new unseen data, you can instantiate the estimator with the &lt;code&gt;novelty&lt;/code&gt; parameter set to &lt;code&gt;True&lt;/code&gt; before fitting the estimator. In this case, &lt;code&gt;fit_predict&lt;/code&gt; is not available.</source>
          <target state="translated">Si realmente desea utilizar &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt; para la detecci&amp;oacute;n de novedades, es decir, predecir etiquetas o calcular la puntuaci&amp;oacute;n de anomal&amp;iacute;a de nuevos datos no vistos, puede crear una instancia del estimador con el par&amp;aacute;metro de &lt;code&gt;novelty&lt;/code&gt; establecido en &lt;code&gt;True&lt;/code&gt; antes de ajustar el estimador. En este caso, &lt;code&gt;fit_predict&lt;/code&gt; no est&amp;aacute; disponible.</target>
        </trans-unit>
        <trans-unit id="d5eafa493c5ec5c70bb915830d883a4547e5cefd" translate="yes" xml:space="preserve">
          <source>If you set load_content=True, you should also specify the encoding of the text using the &amp;lsquo;encoding&amp;rsquo; parameter. For many modern text files, &amp;lsquo;utf-8&amp;rsquo; will be the correct encoding. If you leave encoding equal to None, then the content will be made of bytes instead of Unicode, and you will not be able to use most functions in &lt;a href=&quot;../classes#module-sklearn.feature_extraction.text&quot;&gt;&lt;code&gt;text&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f2c392b35ce2be9956cf3b6740e21a9cb0e7eb8" translate="yes" xml:space="preserve">
          <source>If you set load_content=True, you should also specify the encoding of the text using the &amp;lsquo;encoding&amp;rsquo; parameter. For many modern text files, &amp;lsquo;utf-8&amp;rsquo; will be the correct encoding. If you leave encoding equal to None, then the content will be made of bytes instead of Unicode, and you will not be able to use most functions in &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt;.</source>
          <target state="translated">Si establece load_content = True, tambi&amp;eacute;n debe especificar la codificaci&amp;oacute;n del texto usando el par&amp;aacute;metro 'codificaci&amp;oacute;n'. Para muchos archivos de texto modernos, 'utf-8' ser&amp;aacute; la codificaci&amp;oacute;n correcta. Si deja la codificaci&amp;oacute;n igual a None, entonces el contenido estar&amp;aacute; compuesto por bytes en lugar de Unicode, y no podr&amp;aacute; usar la mayor&amp;iacute;a de las funciones en &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="bc2de8e7176de3a7ec5f2ba66eebe7612bd92fb1" translate="yes" xml:space="preserve">
          <source>If you specify &lt;code&gt;max_depth=h&lt;/code&gt; then complete binary trees of depth &lt;code&gt;h&lt;/code&gt; will be grown. Such trees will have (at most) &lt;code&gt;2**h&lt;/code&gt; leaf nodes and &lt;code&gt;2**h - 1&lt;/code&gt; split nodes.</source>
          <target state="translated">Si especifica &lt;code&gt;max_depth=h&lt;/code&gt; &lt;code&gt;h&lt;/code&gt; , se cultivar&amp;aacute;n &amp;aacute;rboles binarios completos de profundidad h . Dichos &amp;aacute;rboles tendr&amp;aacute;n (como m&amp;aacute;ximo) &lt;code&gt;2**h&lt;/code&gt; nodos de hojas y &lt;code&gt;2**h - 1&lt;/code&gt; nodos divididos.</target>
        </trans-unit>
        <trans-unit id="b5e591b33a0bd24a7e9f3db1117e493d465fb600" translate="yes" xml:space="preserve">
          <source>If you use sparse data (i.e. data represented as sparse matrices), &lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt;&lt;code&gt;chi2&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_regression#sklearn.feature_selection.mutual_info_regression&quot;&gt;&lt;code&gt;mutual_info_regression&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_classif#sklearn.feature_selection.mutual_info_classif&quot;&gt;&lt;code&gt;mutual_info_classif&lt;/code&gt;&lt;/a&gt; will deal with the data without making it dense.</source>
          <target state="translated">Si usa datos dispersos (es decir, datos representados como matrices dispersas), &lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt; &lt;code&gt;chi2&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_regression#sklearn.feature_selection.mutual_info_regression&quot;&gt; &lt;code&gt;mutual_info_regression&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_classif#sklearn.feature_selection.mutual_info_classif&quot;&gt; &lt;code&gt;mutual_info_classif&lt;/code&gt; &lt;/a&gt; tratar&amp;aacute; los datos sin hacerlos densos.</target>
        </trans-unit>
        <trans-unit id="a1ac2d367786359c2f555cec450b280865094e6b" translate="yes" xml:space="preserve">
          <source>If you want more control over stopping criteria or learning rate in SGD, or want to do additional monitoring, using &lt;code&gt;warm_start=True&lt;/code&gt; and &lt;code&gt;max_iter=1&lt;/code&gt; and iterating yourself can be helpful:</source>
          <target state="translated">Si desea tener m&amp;aacute;s control sobre los criterios de detenci&amp;oacute;n o la tasa de aprendizaje en SGD, o desea realizar un seguimiento adicional, puede ser &amp;uacute;til usar &lt;code&gt;warm_start=True&lt;/code&gt; y &lt;code&gt;max_iter=1&lt;/code&gt; e iterar usted mismo:</target>
        </trans-unit>
        <trans-unit id="5572f4380789e92c52811040d71f90082bdb6315" translate="yes" xml:space="preserve">
          <source>If you want to know more about these issues and explore other possible serialization methods, please refer to this &lt;a href=&quot;http://pyvideo.org/video/2566/pickles-are-for-delis-not-software&quot;&gt;talk by Alex Gaynor&lt;/a&gt;.</source>
          <target state="translated">Si desea saber m&amp;aacute;s sobre estos problemas y explorar otros posibles m&amp;eacute;todos de serializaci&amp;oacute;n, consulte esta &lt;a href=&quot;http://pyvideo.org/video/2566/pickles-are-for-delis-not-software&quot;&gt;charla de Alex Gaynor&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="f3aeb01a6e584fc1ad67fbb7aa6de9be209b24eb" translate="yes" xml:space="preserve">
          <source>If you want to know more about these issues and explore other possible serialization methods, please refer to this &lt;a href=&quot;https://pyvideo.org/video/2566/pickles-are-for-delis-not-software&quot;&gt;talk by Alex Gaynor&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73e4bcb37920038eaa4bbe1483d8a08f411face1" translate="yes" xml:space="preserve">
          <source>If you want to model a relative frequency, i.e. counts per exposure (time, volume, &amp;hellip;) you can do so by using a Poisson distribution and passing \(y=\frac{\mathrm{counts}}{\mathrm{exposure}}\) as target values together with \(\mathrm{exposure}\) as sample weights. For a concrete example see e.g. &lt;a href=&quot;../auto_examples/linear_model/plot_tweedie_regression_insurance_claims#sphx-glr-auto-examples-linear-model-plot-tweedie-regression-insurance-claims-py&quot;&gt;Tweedie regression on insurance claims&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9d28c176517636a408517ab464ebf5a8ed78a10" translate="yes" xml:space="preserve">
          <source>If your attributes have an intrinsic scale (e.g. word frequencies or indicator features) scaling is not needed.</source>
          <target state="translated">Si sus atributos tienen una escala intrínseca (por ejemplo,frecuencias de palabras o características de los indicadores)la escala no es necesaria.</target>
        </trans-unit>
        <trans-unit id="1c54fdc8274e03b04e776296dd28d5ff9fd81085" translate="yes" xml:space="preserve">
          <source>If your data contains many outliers, scaling using the mean and variance of the data is likely to not work very well. In these cases, you can use &lt;a href=&quot;generated/sklearn.preprocessing.robust_scale#sklearn.preprocessing.robust_scale&quot;&gt;&lt;code&gt;robust_scale&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.preprocessing.robustscaler#sklearn.preprocessing.RobustScaler&quot;&gt;&lt;code&gt;RobustScaler&lt;/code&gt;&lt;/a&gt; as drop-in replacements instead. They use more robust estimates for the center and range of your data.</source>
          <target state="translated">Si sus datos contienen muchos valores at&amp;iacute;picos, es probable que el escalado utilizando la media y la varianza de los datos no funcione muy bien. En estos casos, puede usar &lt;a href=&quot;generated/sklearn.preprocessing.robust_scale#sklearn.preprocessing.robust_scale&quot;&gt; &lt;code&gt;robust_scale&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.preprocessing.robustscaler#sklearn.preprocessing.RobustScaler&quot;&gt; &lt;code&gt;RobustScaler&lt;/code&gt; &lt;/a&gt; como reemplazos directos . Usan estimaciones m&amp;aacute;s s&amp;oacute;lidas para el centro y rango de sus datos.</target>
        </trans-unit>
        <trans-unit id="a10bfba29a759d89e81956a541262290109cf294" translate="yes" xml:space="preserve">
          <source>If your number of features is high, it may be useful to reduce it with an unsupervised step prior to supervised steps. Many of the &lt;a href=&quot;http://scikit-learn.org/stable/unsupervised_learning.html#unsupervised-learning&quot;&gt;Unsupervised learning&lt;/a&gt; methods implement a &lt;code&gt;transform&lt;/code&gt; method that can be used to reduce the dimensionality. Below we discuss two specific example of this pattern that are heavily used.</source>
          <target state="translated">Si su n&amp;uacute;mero de funciones es alto, puede ser &amp;uacute;til reducirlo con un paso sin supervisi&amp;oacute;n antes de los pasos supervisados. Muchos de los m&amp;eacute;todos de &lt;a href=&quot;http://scikit-learn.org/stable/unsupervised_learning.html#unsupervised-learning&quot;&gt;aprendizaje no supervisados&lt;/a&gt; implementan un m&amp;eacute;todo de &lt;code&gt;transform&lt;/code&gt; aci&amp;oacute;n que se puede utilizar para reducir la dimensionalidad. A continuaci&amp;oacute;n, analizamos dos ejemplos espec&amp;iacute;ficos de este patr&amp;oacute;n que se utilizan mucho.</target>
        </trans-unit>
        <trans-unit id="7fd7c263c0ce2fcb7f46b0e79b01f4b5e3878456" translate="yes" xml:space="preserve">
          <source>If your number of features is high, it may be useful to reduce it with an unsupervised step prior to supervised steps. Many of the &lt;a href=&quot;https://scikit-learn.org/0.23/unsupervised_learning.html#unsupervised-learning&quot;&gt;Unsupervised learning&lt;/a&gt; methods implement a &lt;code&gt;transform&lt;/code&gt; method that can be used to reduce the dimensionality. Below we discuss two specific example of this pattern that are heavily used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="933c257247173f2464c3cf8d4de4af2d678e5a7c" translate="yes" xml:space="preserve">
          <source>If your number of observations is not large compared to the number of edges in your underlying graph, you will not recover it.</source>
          <target state="translated">Si el número de observaciones no es grande comparado con el número de bordes de su gráfico subyacente,no lo recuperará.</target>
        </trans-unit>
        <trans-unit id="4f34c772816074a373c0d5e918e2e9ac136448b7" translate="yes" xml:space="preserve">
          <source>Ignore the offset first bytes by seeking forward, then discarding the following bytes up until the next new line character.</source>
          <target state="translated">Ignoren el desplazamiento de los primeros bytes buscando hacia adelante,luego descartando los siguientes bytes hasta el próximo carácter de la nueva línea.</target>
        </trans-unit>
        <trans-unit id="78fee1435d74666b84850cd5e82c18229351da5d" translate="yes" xml:space="preserve">
          <source>Ignored</source>
          <target state="translated">Ignored</target>
        </trans-unit>
        <trans-unit id="9b02e8c10d5a363337d6fcee177ec3e9cae9f1ce" translate="yes" xml:space="preserve">
          <source>Ignored in binary classification or classical regression settings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ce03a847a845250be1b2b174971c463802e32813" translate="yes" xml:space="preserve">
          <source>Ignored variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e65bb4eca2d3c71529c96890a4b735eb7dafeac" translate="yes" xml:space="preserve">
          <source>Ignored.</source>
          <target state="translated">Ignored.</target>
        </trans-unit>
        <trans-unit id="d0c592be2a6267cc2802c86a5116a8ba2d4b6ff9" translate="yes" xml:space="preserve">
          <source>Ignored. This parameter exists only for compatibility with &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e417badfc4d52f79664b451110854e41b4a0daf" translate="yes" xml:space="preserve">
          <source>Ignored. This parameter exists only for compatibility with sklearn.pipeline.Pipeline.</source>
          <target state="translated">Ignorado.Este parámetro sólo existe para la compatibilidad con sklearn.pipeline.Pipeline.</target>
        </trans-unit>
        <trans-unit id="2d34b7c897f7b41a0f0625575a2c9cc21b1078a7" translate="yes" xml:space="preserve">
          <source>Illustration of &lt;code&gt;Pipeline&lt;/code&gt; and &lt;code&gt;GridSearchCV&lt;/code&gt;</source>
          <target state="translated">Ilustraci&amp;oacute;n de &lt;code&gt;Pipeline&lt;/code&gt; y &lt;code&gt;GridSearchCV&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="643998f34944846c305de7d49de1c3e80f814d2d" translate="yes" xml:space="preserve">
          <source>Illustration of Gaussian process classification (GPC) on the XOR dataset</source>
          <target state="translated">Ilustración de la clasificación del proceso Gaussiano (GPC)en el conjunto de datos XOR</target>
        </trans-unit>
        <trans-unit id="c2cd661f8089fd4df71dfb566ea137083aa22024" translate="yes" xml:space="preserve">
          <source>Illustration of how the performance of an estimator on unseen data (test data) is not the same as the performance on training data. As the regularization increases the performance on train decreases while the performance on test is optimal within a range of values of the regularization parameter. The example with an Elastic-Net regression model and the performance is measured using the explained variance a.k.a. R^2.</source>
          <target state="translated">Ilustración de cómo el rendimiento de un estimador en datos no vistos (datos de prueba)no es el mismo que el rendimiento en datos de entrenamiento.A medida que la regularización aumenta el rendimiento en el tren disminuye mientras que el rendimiento en la prueba es óptimo dentro de un rango de valores del parámetro de regularización.El ejemplo con un modelo de regresión de Elastic-Net y el rendimiento se mide utilizando la varianza explicada,también conocida como R^2.</target>
        </trans-unit>
        <trans-unit id="5790a5aaa3a6c4543a820b9b12ce6d261eeb0581" translate="yes" xml:space="preserve">
          <source>Illustration of prior and posterior Gaussian process for different kernels</source>
          <target state="translated">Ilustración del proceso gaussiano anterior y posterior para diferentes núcleos</target>
        </trans-unit>
        <trans-unit id="71618836e7c136eb1b3d1aef884b22f68af959aa" translate="yes" xml:space="preserve">
          <source>Illustration of the effect of different regularization strategies for Gradient Boosting. The example is taken from Hastie et al 2009 &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27c062ea4e410688effe23ac51313a8ab9a70f1c" translate="yes" xml:space="preserve">
          <source>Illustration of the effect of different regularization strategies for Gradient Boosting. The example is taken from Hastie et al 2009 &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="translated">Ilustraci&amp;oacute;n del efecto de diferentes estrategias de regularizaci&amp;oacute;n para Gradient Boosting. El ejemplo est&amp;aacute; tomado de Hastie et al 2009 &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="5beb1d257bbb65ddb7ec568445a1c3acdcb42d37" translate="yes" xml:space="preserve">
          <source>Image denoising using dictionary learning</source>
          <target state="translated">Denotación de imágenes usando el aprendizaje del diccionario</target>
        </trans-unit>
        <trans-unit id="5ab7decf36c80b04aff06a11c0e8ef068c85a1b9" translate="yes" xml:space="preserve">
          <source>Image histogram</source>
          <target state="translated">Histograma de imágenes</target>
        </trans-unit>
        <trans-unit id="2c151a57b190c9b9e70046810542a00e0344b5af" translate="yes" xml:space="preserve">
          <source>Image representing the confusion matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c328038b14054033bab1147ef5d1ad234b3373d" translate="yes" xml:space="preserve">
          <source>Imagine you have three subjects, each with an associated number from 1 to 3:</source>
          <target state="translated">Imagina que tienes tres sujetos,cada uno con un número asociado del 1 al 3:</target>
        </trans-unit>
        <trans-unit id="8781d615fd77be9578225c40ac67b9471394cced" translate="yes" xml:space="preserve">
          <source>Implementation</source>
          <target state="translated">Implementation</target>
        </trans-unit>
        <trans-unit id="8d522809f4125f5930c1f4f77ec91f8735a003d8" translate="yes" xml:space="preserve">
          <source>Implementation based on &lt;code&gt;A. Hyvarinen and E. Oja, Independent Component Analysis: Algorithms and Applications, Neural Networks, 13(4-5), 2000, pp. 411-430&lt;/code&gt;</source>
          <target state="translated">Implementaci&amp;oacute;n basada en &lt;code&gt;A. Hyvarinen and E. Oja, Independent Component Analysis: Algorithms and Applications, Neural Networks, 13(4-5), 2000, pp. 411-430&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="1f57545a08e425cccaf152a77959fb187cad06cb" translate="yes" xml:space="preserve">
          <source>Implementation based on &lt;em&gt;A. Hyvarinen and E. Oja, Independent Component Analysis: Algorithms and Applications, Neural Networks, 13(4-5), 2000, pp. 411-430&lt;/em&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6a1ab1256c83ccf4dbd316f43007b044bc691a2" translate="yes" xml:space="preserve">
          <source>Implementation detail: taking sample weights into account amounts to multiplying the gradients (and the hessians) by the sample weights. Note that the binning stage (specifically the quantiles computation) does not take the weights into account.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6ac8df85fe47d2d00b4a78e1facdef4fbcae73b" translate="yes" xml:space="preserve">
          <source>Implementation of Support Vector Machine classifier using libsvm: the kernel can be non-linear but its SMO algorithm does not scale to large number of samples as LinearSVC does. Furthermore SVC multi-class mode is implemented using one vs one scheme while LinearSVC uses one vs the rest. It is possible to implement one vs the rest with SVC by using the &lt;a href=&quot;sklearn.multiclass.onevsrestclassifier#sklearn.multiclass.OneVsRestClassifier&quot;&gt;&lt;code&gt;sklearn.multiclass.OneVsRestClassifier&lt;/code&gt;&lt;/a&gt; wrapper. Finally SVC can fit dense data without memory copy if the input is C-contiguous. Sparse data will still incur memory copy though.</source>
          <target state="translated">Implementaci&amp;oacute;n del clasificador Support Vector Machine usando libsvm: el kernel puede ser no lineal pero su algoritmo SMO no escala a un gran n&amp;uacute;mero de muestras como lo hace LinearSVC. Adem&amp;aacute;s, el modo de m&amp;uacute;ltiples clases de SVC se implementa usando un esquema de uno contra uno, mientras que LinearSVC usa uno contra el resto. Es posible implementar uno frente al resto con SVC utilizando el contenedor &lt;a href=&quot;sklearn.multiclass.onevsrestclassifier#sklearn.multiclass.OneVsRestClassifier&quot;&gt; &lt;code&gt;sklearn.multiclass.OneVsRestClassifier&lt;/code&gt; &lt;/a&gt; . Finalmente, SVC puede ajustar datos densos sin copia de memoria si la entrada es C-contigua. Sin embargo, los datos escasos seguir&amp;aacute;n incurriendo en copia de memoria.</target>
        </trans-unit>
        <trans-unit id="78b58091d5da65fb36aa747d9975841d97302dec" translate="yes" xml:space="preserve">
          <source>Implementation of Support Vector Machine classifier using the same library as this class (liblinear).</source>
          <target state="translated">Implementación del clasificador de la Máquina Vectorial de Soporte usando la misma biblioteca que esta clase (liblinear).</target>
        </trans-unit>
        <trans-unit id="0faf8832b17d93a1b230f7a6ca4feb36d15cc4ac" translate="yes" xml:space="preserve">
          <source>Implementation of Support Vector Machine regression using libsvm: the kernel can be non-linear but its SMO algorithm does not scale to large number of samples as LinearSVC does.</source>
          <target state="translated">Implementación de la regresión de la máquina de vectores de apoyo utilizando libsvm:el núcleo puede ser no lineal pero su algoritmo SMO no se escala a un gran número de muestras como lo hace LinearSVC.</target>
        </trans-unit>
        <trans-unit id="adae10003f16f5885f71700e866f2cc76e2c6af9" translate="yes" xml:space="preserve">
          <source>Implements feature hashing, aka the hashing trick.</source>
          <target state="translated">Implementa el &quot;hashing&quot;,también conocido como el truco del &quot;hashing&quot;.</target>
        </trans-unit>
        <trans-unit id="d98e09b894119d4a2d55bf3e2f04052ec103359a" translate="yes" xml:space="preserve">
          <source>Implements resampling with replacement. If False, this will implement (sliced) random permutations.</source>
          <target state="translated">Implementa el remuestreo con reemplazo.Si es falso,implementará (rebanado)permutaciones aleatorias.</target>
        </trans-unit>
        <trans-unit id="9f9d0b6a3b9dbc770ff8e17c3a6979d6ebb5425d" translate="yes" xml:space="preserve">
          <source>Implements the Birch clustering algorithm.</source>
          <target state="translated">Implementa el algoritmo de agrupación del abedul.</target>
        </trans-unit>
        <trans-unit id="82028db75262dc1a82a0dc4cf2e6f254032ff9f7" translate="yes" xml:space="preserve">
          <source>Implements the incremental PCA model from: &lt;code&gt;D. Ross, J. Lim, R. Lin, M. Yang, Incremental Learning for Robust Visual Tracking, International Journal of Computer Vision, Volume 77, Issue 1-3, pp. 125-141, May 2008.&lt;/code&gt; See &lt;a href=&quot;http://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf&quot;&gt;http://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf&lt;/a&gt;</source>
          <target state="translated">Implementa el modelo de PCA incremental de: &lt;code&gt;D. Ross, J. Lim, R. Lin, M. Yang, Incremental Learning for Robust Visual Tracking, International Journal of Computer Vision, Volume 77, Issue 1-3, pp. 125-141, May 2008.&lt;/code&gt; V&amp;eacute;ase &lt;a href=&quot;http://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf&quot;&gt;http://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="eddd9fc5411550a8b67e601c8cf138c977f02e42" translate="yes" xml:space="preserve">
          <source>Implements the incremental PCA model from: &lt;em&gt;D. Ross, J. Lim, R. Lin, M. Yang, Incremental Learning for Robust Visual Tracking, International Journal of Computer Vision, Volume 77, Issue 1-3, pp. 125-141, May 2008.&lt;/em&gt; See &lt;a href=&quot;https://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf&quot;&gt;https://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06be3bf25c44efb35fdd12e8816c051b94a6e5d6" translate="yes" xml:space="preserve">
          <source>Implements the probabilistic PCA model from: &lt;a href=&quot;#id1&quot;&gt;&lt;span id=&quot;id2&quot;&gt;`&lt;/span&gt;&lt;/a&gt;Tipping, M. E., and Bishop, C. M. (1999). &amp;ldquo;Probabilistic principal component analysis&amp;rdquo;. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 61(3), 611-622. via the score and score_samples methods. See &lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdf&lt;/a&gt;</source>
          <target state="translated">Implementa el modelo probabil&amp;iacute;stico de PCA de: &lt;a href=&quot;#id1&quot;&gt;&lt;span id=&quot;id2&quot;&gt;`&lt;/span&gt;&lt;/a&gt; Tipping, ME, y Bishop, CM (1999). &amp;ldquo;An&amp;aacute;lisis probabil&amp;iacute;stico de componentes principales&amp;rdquo;. Revista de la Royal Statistical Society: Serie B (Metodolog&amp;iacute;a estad&amp;iacute;stica), 61 (3), 611-622. mediante los m&amp;eacute;todos score y score_samples. Ver &lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5153c1832189653f3d836c4da5e485c3d1b56671" translate="yes" xml:space="preserve">
          <source>Implements the probabilistic PCA model from: Tipping, M. E., and Bishop, C. M. (1999). &amp;ldquo;Probabilistic principal component analysis&amp;rdquo;. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 61(3), 611-622. via the score and score_samples methods. See &lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="496d8573358dc0bbf8fad0d466b95c37d153e5fd" translate="yes" xml:space="preserve">
          <source>Importance of Feature Scaling</source>
          <target state="translated">Importancia de la escalada de características</target>
        </trans-unit>
        <trans-unit id="dee0fbd7a096536203f3e083c7a95f20ef772057" translate="yes" xml:space="preserve">
          <source>Important members are fit, predict.</source>
          <target state="translated">Los miembros importantes están en forma,predicen.</target>
        </trans-unit>
        <trans-unit id="34aace9b4c119f775f92304ec637d19c91f28ab6" translate="yes" xml:space="preserve">
          <source>Importantly, this tabular dataset has very different dynamic ranges for its features. Neural networks tend to be very sensitive to features with varying scales and forgetting to preprocess the numeric feature would lead to a very poor model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7f6e12fca9c93deac0f3e9ce5406887ec818c03" translate="yes" xml:space="preserve">
          <source>Improvements to the histogram-based Gradient Boosting estimators</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eed74af8ff28262ccadec0b3ca567aeb04ce5592" translate="yes" xml:space="preserve">
          <source>Imputation for completing missing values using k-Nearest Neighbors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0004bf233145469d6159f141af0ae0b05f3c5e9a" translate="yes" xml:space="preserve">
          <source>Imputation transformer for completing missing values.</source>
          <target state="translated">Transformador de imputación para completar los valores que faltan.</target>
        </trans-unit>
        <trans-unit id="8154b566118976ff2097cfffb2c92470797b0a69" translate="yes" xml:space="preserve">
          <source>Impute all missing values in X.</source>
          <target state="translated">Impute todos los valores que faltan en X.</target>
        </trans-unit>
        <trans-unit id="ad8e498cb05e98f21bd0f42774d74dde4c2bb7ea" translate="yes" xml:space="preserve">
          <source>Impute missing values with mean</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4715d3875af4e3819958eff35e6816030a9c89e" translate="yes" xml:space="preserve">
          <source>Impute the missing data and score</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="689f1aca2f66f40afe86b2a1257542980cceee50" translate="yes" xml:space="preserve">
          <source>Imputer used to initialize the missing values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="74ee388ccf36d172dba88b767c11eeb31f63d971" translate="yes" xml:space="preserve">
          <source>Imputes all missing values in X.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="510c592fb9a4fd828788fc0bdd902c165ca78889" translate="yes" xml:space="preserve">
          <source>Imputing missing values before building an estimator</source>
          <target state="translated">Imputar los valores perdidos antes de construir un estimador</target>
        </trans-unit>
        <trans-unit id="87c53ba7fd85032a63ff707cca98951b5852e72d" translate="yes" xml:space="preserve">
          <source>Imputing missing values with variants of IterativeImputer</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5d148df74ab3f703a9d283fda0c99f4936ff674" translate="yes" xml:space="preserve">
          <source>In &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;NMF&lt;/code&gt;&lt;/a&gt;, L1 and L2 priors can be added to the loss function in order to regularize the model. The L2 prior uses the Frobenius norm, while the L1 prior uses an elementwise L1 norm. As in &lt;code&gt;ElasticNet&lt;/code&gt;, we control the combination of L1 and L2 with the &lt;code&gt;l1_ratio&lt;/code&gt; (\(\rho\)) parameter, and the intensity of the regularization with the &lt;code&gt;alpha&lt;/code&gt; (\(\alpha\)) parameter. Then the priors terms are:</source>
          <target state="translated">En &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt; &lt;code&gt;NMF&lt;/code&gt; &lt;/a&gt; , se pueden agregar a la funci&amp;oacute;n de p&amp;eacute;rdida los previos L1 y L2 para regularizar el modelo. El anterior L2 usa la norma de Frobenius, mientras que el anterior L1 usa una norma L1 por elementos. Como en &lt;code&gt;ElasticNet&lt;/code&gt; , controlamos la combinaci&amp;oacute;n de L1 y L2 con el &lt;code&gt;l1_ratio&lt;/code&gt; (\ (\ rho \)), y la intensidad de la regularizaci&amp;oacute;n con el par&amp;aacute;metro &lt;code&gt;alpha&lt;/code&gt; (\ (\ alpha \)). Entonces los t&amp;eacute;rminos a priori son:</target>
        </trans-unit>
        <trans-unit id="eee03375c59654f18a55a7961e4f26a36fbc2cee" translate="yes" xml:space="preserve">
          <source>In &lt;a href=&quot;generated/sklearn.multiclass.outputcodeclassifier#sklearn.multiclass.OutputCodeClassifier&quot;&gt;&lt;code&gt;OutputCodeClassifier&lt;/code&gt;&lt;/a&gt;, the &lt;code&gt;code_size&lt;/code&gt; attribute allows the user to control the number of classifiers which will be used. It is a percentage of the total number of classes.</source>
          <target state="translated">En &lt;a href=&quot;generated/sklearn.multiclass.outputcodeclassifier#sklearn.multiclass.OutputCodeClassifier&quot;&gt; &lt;code&gt;OutputCodeClassifier&lt;/code&gt; &lt;/a&gt; , el atributo &lt;code&gt;code_size&lt;/code&gt; permite al usuario controlar el n&amp;uacute;mero de clasificadores que se utilizar&amp;aacute;n. Es un porcentaje del n&amp;uacute;mero total de clases.</target>
        </trans-unit>
        <trans-unit id="92869ea1268ab85728d32cc145b2fc2a3cf98201" translate="yes" xml:space="preserve">
          <source>In &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt;, if data for classification are unbalanced (e.g. many positive and few negative), set &lt;code&gt;class_weight='balanced'&lt;/code&gt; and/or try different penalty parameters &lt;code&gt;C&lt;/code&gt;.</source>
          <target state="translated">En &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt; , si los datos para la clasificaci&amp;oacute;n est&amp;aacute;n desequilibradas (por ejemplo, muchos positivo y pocos negativo), conjunto &lt;code&gt;class_weight='balanced'&lt;/code&gt; y / o tratar diferentes par&amp;aacute;metros de penalizaci&amp;oacute;n &lt;code&gt;C&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3c0402c73702f19dd4de5bea870fc6f39e9426a9" translate="yes" xml:space="preserve">
          <source>In &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt;, if the data is unbalanced (e.g. many positive and few negative), set &lt;code&gt;class_weight='balanced'&lt;/code&gt; and/or try different penalty parameters &lt;code&gt;C&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4a2dd93e9c8bc18123ea577d336109c88e8c2c3" translate="yes" xml:space="preserve">
          <source>In &lt;strong&gt;averaging methods&lt;/strong&gt;, the driving principle is to build several estimators independently and then to average their predictions. On average, the combined estimator is usually better than any of the single base estimator because its variance is reduced.</source>
          <target state="translated">En los &lt;strong&gt;m&amp;eacute;todos de promediado&lt;/strong&gt; , el principio impulsor es construir varios estimadores de forma independiente y luego promediar sus predicciones. En promedio, el estimador combinado suele ser mejor que cualquiera de los estimadores de base &amp;uacute;nica porque su varianza es reducida.</target>
        </trans-unit>
        <trans-unit id="ca51c131377adedf53770a869ad18245bd6bd115" translate="yes" xml:space="preserve">
          <source>In a binary classification context, imposing a monotonic constraint means that the feature is supposed to have a positive / negative effect on the probability to belong to the positive class. Monotonic constraints are not supported for multiclass context.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="baeac0931c0e4b4385579000935f2bb52ceb9f07" translate="yes" xml:space="preserve">
          <source>In a binary classification task, the terms &amp;lsquo;&amp;rsquo;positive&amp;rsquo;&amp;rsquo; and &amp;lsquo;&amp;rsquo;negative&amp;rsquo;&amp;rsquo; refer to the classifier&amp;rsquo;s prediction, and the terms &amp;lsquo;&amp;rsquo;true&amp;rsquo;&amp;rsquo; and &amp;lsquo;&amp;rsquo;false&amp;rsquo;&amp;rsquo; refer to whether that prediction corresponds to the external judgment (sometimes known as the &amp;lsquo;&amp;rsquo;observation&amp;rsquo;&amp;lsquo;). Given these definitions, we can formulate the following table:</source>
          <target state="translated">En una tarea de clasificaci&amp;oacute;n binaria, los t&amp;eacute;rminos '' positivo '' y '' negativo '' se refieren a la predicci&amp;oacute;n del clasificador, y los t&amp;eacute;rminos '' verdadero '' y '' falso '' se refieren a si esa predicci&amp;oacute;n corresponde al juicio externo ( a veces conocida como la '' observaci&amp;oacute;n ''). Dadas estas definiciones, podemos formular la siguiente tabla:</target>
        </trans-unit>
        <trans-unit id="ccc920586f4d3de666e5e909b4599881349f812c" translate="yes" xml:space="preserve">
          <source>In a binary classification task, the terms &amp;lsquo;&amp;rsquo;positive&amp;rsquo;&amp;rsquo; and &amp;lsquo;&amp;rsquo;negative&amp;rsquo;&amp;rsquo; refer to the classifier&amp;rsquo;s prediction, and the terms &amp;lsquo;&amp;rsquo;true&amp;rsquo;&amp;rsquo; and &amp;lsquo;&amp;rsquo;false&amp;rsquo;&amp;rsquo; refer to whether that prediction corresponds to the external judgment (sometimes known as the &amp;lsquo;&amp;rsquo;observation&amp;rsquo;&amp;rsquo;). Given these definitions, we can formulate the following table:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="995a1ae8b5be72e5d8cbdf391052b665e77e9964" translate="yes" xml:space="preserve">
          <source>In a first step, the hierarchical clustering is performed without connectivity constraints on the structure and is solely based on distance, whereas in a second step the clustering is restricted to the k-Nearest Neighbors graph: it&amp;rsquo;s a hierarchical clustering with structure prior.</source>
          <target state="translated">En un primer paso, el agrupamiento jer&amp;aacute;rquico se realiza sin restricciones de conectividad en la estructura y se basa &amp;uacute;nicamente en la distancia, mientras que en un segundo paso el agrupamiento se restringe al gr&amp;aacute;fico k-Vecinos m&amp;aacute;s cercanos: es un agrupamiento jer&amp;aacute;rquico con estructura previa.</target>
        </trans-unit>
        <trans-unit id="0336cb4d8e7c9adb72abdea9417802db49cccd1f" translate="yes" xml:space="preserve">
          <source>In a large text corpus, some words will be very present (e.g. &amp;ldquo;the&amp;rdquo;, &amp;ldquo;a&amp;rdquo;, &amp;ldquo;is&amp;rdquo; in English) hence carrying very little meaningful information about the actual contents of the document. If we were to feed the direct count data directly to a classifier those very frequent terms would shadow the frequencies of rarer yet more interesting terms.</source>
          <target state="translated">En un corpus de texto extenso, algunas palabras estar&amp;aacute;n muy presentes (por ejemplo, &quot;the&quot;, &quot;a&quot;, &quot;is&quot; en ingl&amp;eacute;s), por lo que contienen muy poca informaci&amp;oacute;n significativa sobre el contenido real del documento. Si tuvi&amp;eacute;ramos que alimentar los datos de conteo directo directamente a un clasificador, esos t&amp;eacute;rminos muy frecuentes sombrear&amp;iacute;an las frecuencias de t&amp;eacute;rminos m&amp;aacute;s raros pero m&amp;aacute;s interesantes.</target>
        </trans-unit>
        <trans-unit id="0caaa107286ab067ca8115855386dd04703bccc4" translate="yes" xml:space="preserve">
          <source>In a multiclass setting, specifies the class for which the PDPs should be computed. Note that for binary classification, the positive class (index 1) is always used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52eb2197195ece26c6612081f2107f907b3e4099" translate="yes" xml:space="preserve">
          <source>In a multioutput setting, specifies the task for which the PDPs should be computed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd0ed349168abd35a1fce87e6ae9e8ccc5ff58f4" translate="yes" xml:space="preserve">
          <source>In a nutshell, the following table summarizes the solvers characteristics:</source>
          <target state="translated">En resumen,el siguiente cuadro resume las características de los solucionadores:</target>
        </trans-unit>
        <trans-unit id="b4ec4bcaff3e86d4d99c938f5623ab4b737e65c7" translate="yes" xml:space="preserve">
          <source>In a real world setting, the &lt;code&gt;n_features&lt;/code&gt; parameter can be left to its default value of &lt;code&gt;2 ** 20&lt;/code&gt; (roughly one million possible features). If memory or downstream models size is an issue selecting a lower value such as &lt;code&gt;2 **
18&lt;/code&gt; might help without introducing too many additional collisions on typical text classification tasks.</source>
          <target state="translated">En una configuraci&amp;oacute;n del mundo real, el par&amp;aacute;metro &lt;code&gt;n_features&lt;/code&gt; se puede dejar en su valor predeterminado de &lt;code&gt;2 ** 20&lt;/code&gt; (aproximadamente un mill&amp;oacute;n de caracter&amp;iacute;sticas posibles). Si la memoria o el tama&amp;ntilde;o de los modelos posteriores es un problema, seleccionar un valor m&amp;aacute;s bajo, como &lt;code&gt;2 ** 18&lt;/code&gt; podr&amp;iacute;a ayudar sin introducir demasiadas colisiones adicionales en las tareas t&amp;iacute;picas de clasificaci&amp;oacute;n de texto.</target>
        </trans-unit>
        <trans-unit id="c75e295f24e05d06cacc1a2f9bb570a61bdd802e" translate="yes" xml:space="preserve">
          <source>In a similar manner, the boston housing data set is used to show the impact of transforming the targets before learning a model. In this example, the targets to be predicted corresponds to the weighted distances to the five Boston employment centers.</source>
          <target state="translated">De manera similar,el conjunto de datos de la vivienda de Boston se utiliza para mostrar el impacto de la transformación de los objetivos antes de aprender un modelo.En este ejemplo,los objetivos a predecir corresponden a las distancias ponderadas a los cinco centros de empleo de Boston.</target>
        </trans-unit>
        <trans-unit id="c210295417ef2f29cc593be46bbc5efed5892a5f" translate="yes" xml:space="preserve">
          <source>In addition of using an imputing method, we can also keep an indication of the missing information using &lt;a href=&quot;../modules/generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;sklearn.impute.MissingIndicator&lt;/code&gt;&lt;/a&gt; which might carry some information.</source>
          <target state="translated">Adem&amp;aacute;s de utilizar un m&amp;eacute;todo de imputaci&amp;oacute;n, tambi&amp;eacute;n podemos mantener una indicaci&amp;oacute;n de la informaci&amp;oacute;n que falta utilizando &lt;a href=&quot;../modules/generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt; &lt;code&gt;sklearn.impute.MissingIndicator&lt;/code&gt; &lt;/a&gt; que podr&amp;iacute;a contener alguna informaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="67d21513f58775c1e37b37d0e7fc556492bd761a" translate="yes" xml:space="preserve">
          <source>In addition to imputing the missing values, the imputers have an &lt;code&gt;add_indicator&lt;/code&gt; parameter that marks the values that were missing, which might carry some information.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45e3263783ee36dc90c5821ae7ffc8d210750151" translate="yes" xml:space="preserve">
          <source>In addition to its current contents, this module will eventually be home to refurbished versions of Pipeline and FeatureUnion.</source>
          <target state="translated">Además de su contenido actual,este módulo será eventualmente el hogar de versiones renovadas de Pipeline y FeatureUnion.</target>
        </trans-unit>
        <trans-unit id="3dda0db479e61a3dc2539c918fe85f072a3cc4a4" translate="yes" xml:space="preserve">
          <source>In addition to standard scikit-learn estimator API, GaussianProcessRegressor:</source>
          <target state="translated">Además de la API del estimador estándar de aprendizaje científico,GaussianProcessRegressor:</target>
        </trans-unit>
        <trans-unit id="6c259b1081efe473add72a6c01ee26dbc96ee486" translate="yes" xml:space="preserve">
          <source>In addition to the mean of the predictive distribution, also its standard deviation can be returned.</source>
          <target state="translated">Además de la media de la distribución predictiva,también se puede devolver su desviación estándar.</target>
        </trans-unit>
        <trans-unit id="f5f01da0b407208bd57121f71ed7408cbbce3fe6" translate="yes" xml:space="preserve">
          <source>In addition, as there is no useful information in the intensity of the image, or its gradient, we choose to perform the spectral clustering on a graph that is only weakly informed by the gradient. This is close to performing a Voronoi partition of the graph.</source>
          <target state="translated">Además,como no hay información útil en la intensidad de la imagen,o su gradiente,elegimos realizar la agrupación espectral en un gráfico que sólo está débilmente informado por el gradiente.Esto está cerca de realizar una partición Voronoi del gráfico.</target>
        </trans-unit>
        <trans-unit id="8be2789c3e2f5a1d410c34b62e20c28c8adc9fef" translate="yes" xml:space="preserve">
          <source>In addition, if the &lt;code&gt;dask&lt;/code&gt; and &lt;code&gt;distributed&lt;/code&gt; Python packages are installed, it is possible to use the &amp;lsquo;dask&amp;rsquo; backend for better scheduling of nested parallel calls without over-subscription and potentially distribute parallel calls over a networked cluster of several hosts.</source>
          <target state="translated">Adem&amp;aacute;s, si los paquetes &lt;code&gt;dask&lt;/code&gt; y Python &lt;code&gt;distributed&lt;/code&gt; est&amp;aacute;n instalados, es posible usar el backend 'dask' para una mejor programaci&amp;oacute;n de llamadas paralelas anidadas sin suscripci&amp;oacute;n excesiva y potencialmente distribuir llamadas paralelas a trav&amp;eacute;s de un cl&amp;uacute;ster en red de varios hosts.</target>
        </trans-unit>
        <trans-unit id="1068dbee0dd3c16e2fc93e44b0ce455f5b052f8b" translate="yes" xml:space="preserve">
          <source>In addition, scikit-learn includes various random sample generators that can be used to build artificial datasets of controlled size and complexity.</source>
          <target state="translated">Además,scikit-learn incluye varios generadores de muestras aleatorias que pueden utilizarse para construir conjuntos de datos artificiales de tamaño y complejidad controlados.</target>
        </trans-unit>
        <trans-unit id="fc65b58b68e776527046619280b83dca96b85eef" translate="yes" xml:space="preserve">
          <source>In addition, some of the numpy routines that are used internally by scikit-learn may also be parallelized if numpy is installed with specific numerical libraries such as MKL, OpenBLAS, or BLIS.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a9dc36feb47a20be69368bf3755ac289f3cd578" translate="yes" xml:space="preserve">
          <source>In addition, there are also miscellaneous tools to load datasets of other formats or from other locations, described in the &lt;a href=&quot;#loading-other-datasets&quot;&gt;Loading other datasets&lt;/a&gt; section.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67ed28f1d0cd9fef0560dd0bbfe2b568680ea5a6" translate="yes" xml:space="preserve">
          <source>In addition, there are also miscellanous tools to load datasets of other formats or from other locations, described in the &lt;a href=&quot;#loading-other-datasets&quot;&gt;Loading other datasets&lt;/a&gt; section.</source>
          <target state="translated">Adem&amp;aacute;s, tambi&amp;eacute;n existen diversas herramientas para cargar conjuntos de datos de otros formatos o desde otras ubicaciones, que se describen en la secci&amp;oacute;n &lt;a href=&quot;#loading-other-datasets&quot;&gt;Carga de otros conjuntos de datos&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="5f2d75a19b27e52127d76b03616ce749746e4308" translate="yes" xml:space="preserve">
          <source>In addition, we show two different ways to dispatch the columns to the particular pre-processor: by column names and by column data types.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="846c6c3d11b49bd5243a8b72c066c7aae06dcfe3" translate="yes" xml:space="preserve">
          <source>In addition, we use the mask of the objects to restrict the graph to the outline of the objects. In this example, we are interested in separating the objects one from the other, and not from the background.</source>
          <target state="translated">Además,usamos la máscara de los objetos para restringir el gráfico al contorno de los objetos.En este ejemplo,estamos interesados en separar los objetos uno del otro,y no del fondo.</target>
        </trans-unit>
        <trans-unit id="b490744f01019d4237b3a8568465e031a5ae6e1f" translate="yes" xml:space="preserve">
          <source>In all these strategies, the &lt;code&gt;predict&lt;/code&gt; method completely ignores the input data.</source>
          <target state="translated">En todas estas estrategias, el m&amp;eacute;todo de &lt;code&gt;predict&lt;/code&gt; ignora por completo los datos de entrada.</target>
        </trans-unit>
        <trans-unit id="450c8a41f7c5da3bb2b7da9a15306b194b36c681" translate="yes" xml:space="preserve">
          <source>In an &lt;strong&gt;unsupervised setting&lt;/strong&gt; it can be used to group similar documents together by applying clustering algorithms such as &lt;a href=&quot;clustering#k-means&quot;&gt;K-means&lt;/a&gt;:</source>
          <target state="translated">En un &lt;strong&gt;entorno&lt;/strong&gt; no &lt;strong&gt;supervisado,&lt;/strong&gt; se puede utilizar para agrupar documentos similares mediante la aplicaci&amp;oacute;n de algoritmos de agrupaci&amp;oacute;n como &lt;a href=&quot;clustering#k-means&quot;&gt;K-means&lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="e5af8b183011d6bf7238d58f71b94384a5a96f84" translate="yes" xml:space="preserve">
          <source>In any case be warned that decreasing model complexity can hurt accuracy as mentioned above. For instance a non-linearly separable problem can be handled with a speedy linear model but prediction power will very likely suffer in the process.</source>
          <target state="translated">En cualquier caso,se advierte que la disminución de la complejidad de los modelos puede perjudicar la precisión como se ha mencionado anteriormente.Por ejemplo,un problema no lineal separable puede manejarse con un modelo lineal rápido,pero es muy probable que la potencia de predicción se vea afectada en el proceso.</target>
        </trans-unit>
        <trans-unit id="8c17ce8abfedb506f7ed46ebde27121f581c8bb7" translate="yes" xml:space="preserve">
          <source>In applications where a high false positive rate is not tolerable the parameter &lt;code&gt;max_fpr&lt;/code&gt; of &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt; can be used to summarize the ROC curve up to the given limit.</source>
          <target state="translated">En aplicaciones donde una tasa alta de falsos positivos no es tolerable, el par&amp;aacute;metro &lt;code&gt;max_fpr&lt;/code&gt; de &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;roc_auc_score&lt;/code&gt; &lt;/a&gt; se puede usar para resumir la curva ROC hasta el l&amp;iacute;mite dado.</target>
        </trans-unit>
        <trans-unit id="bbcc07c440f8193b3e7ecf64eaaca0e386adcbad" translate="yes" xml:space="preserve">
          <source>In bin edges for feature &lt;code&gt;i&lt;/code&gt;, the first and last values are used only for &lt;code&gt;inverse_transform&lt;/code&gt;. During transform, bin edges are extended to:</source>
          <target state="translated">En los bordes del contenedor para la caracter&amp;iacute;stica &lt;code&gt;i&lt;/code&gt; , el primer y &amp;uacute;ltimo valor se usan solo para &lt;code&gt;inverse_transform&lt;/code&gt; . Durante la transformaci&amp;oacute;n, los bordes del contenedor se extienden a:</target>
        </trans-unit>
        <trans-unit id="9d083c0b55e1a00133d4b27dd85f5ea26aca3922" translate="yes" xml:space="preserve">
          <source>In binary and multiclass classification, the Jaccard similarity coefficient score is equal to the classification accuracy.</source>
          <target state="translated">En la clasificación binaria y multiclase,la puntuación del coeficiente de similitud de Jaccard es igual a la precisión de la clasificación.</target>
        </trans-unit>
        <trans-unit id="834fbb10f3b1dd0752ef9b7f9aa530ac5202b2db" translate="yes" xml:space="preserve">
          <source>In binary and multiclass classification, this function is equal to the &lt;code&gt;jaccard_score&lt;/code&gt; function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0b30958f6975dadd3d7eaf24f5447254d56c629" translate="yes" xml:space="preserve">
          <source>In binary and multiclass classification, this function is equal to the &lt;code&gt;jaccard_similarity_score&lt;/code&gt; function.</source>
          <target state="translated">En la clasificaci&amp;oacute;n binaria y multiclase, esta funci&amp;oacute;n es igual a la funci&amp;oacute;n &lt;code&gt;jaccard_similarity_score&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e731c9654f26a8d7255165d2c0d5f78e47c3bd9a" translate="yes" xml:space="preserve">
          <source>In binary and multiclass classification, this function is equivalent to the &lt;code&gt;accuracy_score&lt;/code&gt;. It differs in the multilabel classification problem.</source>
          <target state="translated">En la clasificaci&amp;oacute;n binaria y multiclase, esta funci&amp;oacute;n es equivalente a la &lt;code&gt;accuracy_score&lt;/code&gt; . Se diferencia en el problema de clasificaci&amp;oacute;n de m&amp;uacute;ltiples etiquetas.</target>
        </trans-unit>
        <trans-unit id="c4cb57bb3e2c0bb1485829473f6ca6362cee5b90" translate="yes" xml:space="preserve">
          <source>In binary class case, assuming labels in y_true are encoded with +1 and -1, when a prediction mistake is made, &lt;code&gt;margin = y_true * pred_decision&lt;/code&gt; is always negative (since the signs disagree), implying &lt;code&gt;1 - margin&lt;/code&gt; is always greater than 1. The cumulated hinge loss is therefore an upper bound of the number of mistakes made by the classifier.</source>
          <target state="translated">En el caso de clase binaria, asumiendo que las etiquetas en y_true est&amp;aacute;n codificadas con +1 y -1, cuando se comete un error de predicci&amp;oacute;n, &lt;code&gt;margin = y_true * pred_decision&lt;/code&gt; siempre es negativo (ya que los signos no est&amp;aacute;n de acuerdo), lo que implica que &lt;code&gt;1 - margin&lt;/code&gt; es siempre mayor que 1. La p&amp;eacute;rdida de bisagra acumulada es, por tanto, un l&amp;iacute;mite superior del n&amp;uacute;mero de errores cometidos por el clasificador.</target>
        </trans-unit>
        <trans-unit id="f2c8a5d61695d64c32adbdec8051b4ecc7f404cb" translate="yes" xml:space="preserve">
          <source>In binary classification settings</source>
          <target state="translated">En los escenarios de clasificación binaria</target>
        </trans-unit>
        <trans-unit id="0e8524872beef3003e748e1d9b4f90c7ce280313" translate="yes" xml:space="preserve">
          <source>In both cases, the criterion is evaluated once by epoch, and the algorithm stops when the criterion does not improve &lt;code&gt;n_iter_no_change&lt;/code&gt; times in a row. The improvement is evaluated with a tolerance &lt;code&gt;tol&lt;/code&gt;, and the algorithm stops in any case after a maximum number of iteration &lt;code&gt;max_iter&lt;/code&gt;.</source>
          <target state="translated">En ambos casos, el criterio se eval&amp;uacute;a una vez por &amp;eacute;poca y el algoritmo se detiene cuando el criterio no mejora &lt;code&gt;n_iter_no_change&lt;/code&gt; tiempos seguidos. La mejora se eval&amp;uacute;a con una tolerancia &lt;code&gt;tol&lt;/code&gt; , y el algoritmo se detiene en cualquier caso despu&amp;eacute;s de un n&amp;uacute;mero m&amp;aacute;ximo de iteraciones &lt;code&gt;max_iter&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e7dad232dab7fc7fe4bb0ec13d7d0a07fef6ce88" translate="yes" xml:space="preserve">
          <source>In both cases, the criterion is evaluated once by epoch, and the algorithm stops when the criterion does not improve &lt;code&gt;n_iter_no_change&lt;/code&gt; times in a row. The improvement is evaluated with absolute tolerance &lt;code&gt;tol&lt;/code&gt;, and the algorithm stops in any case after a maximum number of iteration &lt;code&gt;max_iter&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f03bffae8069d1108a85252dc34a4485434865b8" translate="yes" xml:space="preserve">
          <source>In both cases, the kernel&amp;rsquo;s parameters are estimated using the maximum likelihood principle.</source>
          <target state="translated">En ambos casos, los par&amp;aacute;metros del kernel se estiman utilizando el principio de m&amp;aacute;xima verosimilitud.</target>
        </trans-unit>
        <trans-unit id="dc8004c8d5b437fc6c479e2e5882eb635fa97592" translate="yes" xml:space="preserve">
          <source>In both examples below, the main result is that the empirical covariance estimate, as a non-robust one, is highly influenced by the heterogeneous structure of the observations. Although the robust covariance estimate is able to focus on the main mode of the data distribution, it sticks to the assumption that the data should be Gaussian distributed, yielding some biased estimation of the data structure, but yet accurate to some extent. The One-Class SVM does not assume any parametric form of the data distribution and can therefore model the complex shape of the data much better.</source>
          <target state="translated">En los dos ejemplos que figuran a continuación,el resultado principal es que la estimación de la covarianza empírica,al no ser robusta,está muy influida por la estructura heterogénea de las observaciones.Aunque la estimación de la covarianza robusta puede centrarse en el modo principal de la distribución de los datos,se ciñe al supuesto de que los datos deben estar distribuidos en Gauss,lo que produce cierta estimación sesgada de la estructura de los datos,pero aún así es precisa en cierta medida.El SVM de una clase no asume ninguna forma paramétrica de la distribución de datos y por lo tanto puede modelar mucho mejor la forma compleja de los datos.</target>
        </trans-unit>
        <trans-unit id="7f2b051010be4e679b8556fa182a1724fa1e49b9" translate="yes" xml:space="preserve">
          <source>In case the file contains a pairwise preference constraint (known as &amp;ldquo;qid&amp;rdquo; in the svmlight format) these are ignored unless the query_id parameter is set to True. These pairwise preference constraints can be used to constraint the combination of samples when using pairwise loss functions (as is the case in some learning to rank problems) so that only pairs with the same query_id value are considered.</source>
          <target state="translated">En caso de que el archivo contenga una restricci&amp;oacute;n de preferencia por pares (conocida como &quot;qid&quot; en el formato svmlight), se ignoran a menos que el par&amp;aacute;metro query_id se establezca en True. Estas restricciones de preferencia por pares se pueden usar para restringir la combinaci&amp;oacute;n de muestras cuando se usan funciones de p&amp;eacute;rdida por pares (como es el caso en algunos problemas de aprendizaje de clasificaci&amp;oacute;n) de modo que solo se consideren los pares con el mismo valor de query_id.</target>
        </trans-unit>
        <trans-unit id="b2d3bbc7ab1d1edcd850a10f6fb01a251c14a28b" translate="yes" xml:space="preserve">
          <source>In case unknown categories are encountered (all zero&amp;rsquo;s in the one-hot encoding), &lt;code&gt;None&lt;/code&gt; is used to represent this category.</source>
          <target state="translated">En caso de que se encuentren categor&amp;iacute;as desconocidas (todos los ceros en la codificaci&amp;oacute;n one-hot), se utiliza &lt;code&gt;None&lt;/code&gt; para representar esta categor&amp;iacute;a.</target>
        </trans-unit>
        <trans-unit id="d452896d1312cac0434176b68ca8ca9a2bb1195e" translate="yes" xml:space="preserve">
          <source>In case unknown categories are encountered (all zeros in the one-hot encoding), &lt;code&gt;None&lt;/code&gt; is used to represent this category.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca499264726caa99e06bab43fc3d4644ea84df01" translate="yes" xml:space="preserve">
          <source>In cases where not all of a pairwise distance matrix needs to be stored at once, this is used to calculate pairwise distances in &lt;code&gt;working_memory&lt;/code&gt;-sized chunks. If &lt;code&gt;reduce_func&lt;/code&gt; is given, it is run on each chunk and its return values are concatenated into lists, arrays or sparse matrices.</source>
          <target state="translated">En los casos en los que no es necesario almacenar toda una matriz de distancias por pares a la vez, esto se utiliza para calcular distancias por pares en &lt;code&gt;working_memory&lt;/code&gt; tama&amp;ntilde;o de la memoria de trabajo. Si se proporciona &lt;code&gt;reduce_func&lt;/code&gt; , se ejecuta en cada fragmento y sus valores de retorno se concatenan en listas, matrices o matrices dispersas.</target>
        </trans-unit>
        <trans-unit id="261de18f8066fcaced5cb3f145cb26c170301e09" translate="yes" xml:space="preserve">
          <source>In cases where the data is not uniformly sampled, radius-based neighbors classification in &lt;a href=&quot;generated/sklearn.neighbors.radiusneighborsclassifier#sklearn.neighbors.RadiusNeighborsClassifier&quot;&gt;&lt;code&gt;RadiusNeighborsClassifier&lt;/code&gt;&lt;/a&gt; can be a better choice. The user specifies a fixed radius \(r\), such that points in sparser neighborhoods use fewer nearest neighbors for the classification. For high-dimensional parameter spaces, this method becomes less effective due to the so-called &amp;ldquo;curse of dimensionality&amp;rdquo;.</source>
          <target state="translated">En los casos en que los datos no se muestrean de manera uniforme, la clasificaci&amp;oacute;n de vecinos basada en &lt;a href=&quot;generated/sklearn.neighbors.radiusneighborsclassifier#sklearn.neighbors.RadiusNeighborsClassifier&quot;&gt; &lt;code&gt;RadiusNeighborsClassifier&lt;/code&gt; &lt;/a&gt; en RadiusNeighborsClassifier puede ser una mejor opci&amp;oacute;n. El usuario especifica un radio fijo \ (r \), de modo que los puntos en vecindarios m&amp;aacute;s dispersos usan menos vecinos m&amp;aacute;s cercanos para la clasificaci&amp;oacute;n. Para espacios de par&amp;aacute;metros de alta dimensi&amp;oacute;n, este m&amp;eacute;todo se vuelve menos efectivo debido a la llamada &quot;maldici&amp;oacute;n de la dimensionalidad&quot;.</target>
        </trans-unit>
        <trans-unit id="46149a533d1136e96a72fc2595f06ccb02814862" translate="yes" xml:space="preserve">
          <source>In certain cases Theil-Sen performs better than &lt;a href=&quot;../../modules/linear_model#ransac-regression&quot;&gt;RANSAC&lt;/a&gt; which is also a robust method. This is illustrated in the second example below where outliers with respect to the x-axis perturb RANSAC. Tuning the &lt;code&gt;residual_threshold&lt;/code&gt; parameter of RANSAC remedies this but in general a priori knowledge about the data and the nature of the outliers is needed. Due to the computational complexity of Theil-Sen it is recommended to use it only for small problems in terms of number of samples and features. For larger problems the &lt;code&gt;max_subpopulation&lt;/code&gt; parameter restricts the magnitude of all possible combinations of p subsample points to a randomly chosen subset and therefore also limits the runtime. Therefore, Theil-Sen is applicable to larger problems with the drawback of losing some of its mathematical properties since it then works on a random subset.</source>
          <target state="translated">En ciertos casos, Theil-Sen funciona mejor que &lt;a href=&quot;../../modules/linear_model#ransac-regression&quot;&gt;RANSAC,&lt;/a&gt; que tambi&amp;eacute;n es un m&amp;eacute;todo robusto. Esto se ilustra en el segundo ejemplo a continuaci&amp;oacute;n, donde los valores at&amp;iacute;picos con respecto al eje x perturban RANSAC. El ajuste del par&amp;aacute;metro &lt;code&gt;residual_threshold&lt;/code&gt; de RANSAC soluciona esto, pero en general se necesita un conocimiento a priori sobre los datos y la naturaleza de los valores at&amp;iacute;picos. Debido a la complejidad computacional de Theil-Sen, se recomienda usarlo solo para peque&amp;ntilde;os problemas en t&amp;eacute;rminos de n&amp;uacute;mero de muestras y caracter&amp;iacute;sticas. Para problemas m&amp;aacute;s grandes, &lt;code&gt;max_subpopulation&lt;/code&gt; El par&amp;aacute;metro restringe la magnitud de todas las combinaciones posibles de p puntos de submuestra a un subconjunto elegido al azar y, por lo tanto, tambi&amp;eacute;n limita el tiempo de ejecuci&amp;oacute;n. Por lo tanto, Theil-Sen es aplicable a problemas m&amp;aacute;s grandes con el inconveniente de perder algunas de sus propiedades matem&amp;aacute;ticas, ya que luego trabaja en un subconjunto aleatorio.</target>
        </trans-unit>
        <trans-unit id="08403787ed9849b402f6d04f68a0bae46063dfaf" translate="yes" xml:space="preserve">
          <source>In contrast to &lt;a href=&quot;#id13&quot;&gt;Bayesian Ridge Regression&lt;/a&gt;, each coordinate of \(w_{i}\) has its own standard deviation \(\lambda_i\). The prior over all \(\lambda_i\) is chosen to be the same gamma distribution given by hyperparameters \(\lambda_1\) and \(\lambda_2\).</source>
          <target state="translated">En contraste con &lt;a href=&quot;#id13&quot;&gt;la regresi&amp;oacute;n de cresta bayesiana&lt;/a&gt; , cada coordenada de \ (w_ {i} \) tiene su propia desviaci&amp;oacute;n est&amp;aacute;ndar \ (\ lambda_i \). El anterior sobre todo \ (\ lambda_i \) se elige para que sea la misma distribuci&amp;oacute;n gamma dada por los hiperpar&amp;aacute;metros \ (\ lambda_1 \) y \ (\ lambda_2 \).</target>
        </trans-unit>
        <trans-unit id="f00603c6aeddee02bf1dc7fdebe82c8fea70d634" translate="yes" xml:space="preserve">
          <source>In contrast to &lt;a href=&quot;#id9&quot;&gt;Bayesian Ridge Regression&lt;/a&gt;, each coordinate of \(w_{i}\) has its own standard deviation \(\lambda_i\). The prior over all \(\lambda_i\) is chosen to be the same gamma distribution given by hyperparameters \(\lambda_1\) and \(\lambda_2\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="741dc2ca1b0b96b753a4293cdc66da483cb961b9" translate="yes" xml:space="preserve">
          <source>In contrast to GridSearchCV, not all parameter values are tried out, but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter.</source>
          <target state="translated">A diferencia del GridSearchCV,no se prueban todos los valores de los parámetros,sino que se muestrean un número fijo de ajustes de parámetros de las distribuciones especificadas.El número de ajustes de parámetros que se prueban viene dado por n_iter.</target>
        </trans-unit>
        <trans-unit id="f7007cbebb915951a7329a621ec59e7bfd3c1528" translate="yes" xml:space="preserve">
          <source>In contrast to majority voting (hard voting), soft voting returns the class label as argmax of the sum of predicted probabilities.</source>
          <target state="translated">A diferencia de la votación por mayoría (votación dura),la votación blanda devuelve la etiqueta de clase como argmax de la suma de las probabilidades previstas.</target>
        </trans-unit>
        <trans-unit id="a5222e41535c7e60d0bed8020d5a39a4cdb9c58d" translate="yes" xml:space="preserve">
          <source>In contrast to the original publication &lt;a href=&quot;#b2001&quot; id=&quot;id6&quot;&gt;[B2001]&lt;/a&gt;, the scikit-learn implementation combines classifiers by averaging their probabilistic prediction, instead of letting each classifier vote for a single class.</source>
          <target state="translated">A diferencia de la publicaci&amp;oacute;n original &lt;a href=&quot;#b2001&quot; id=&quot;id6&quot;&gt;[B2001]&lt;/a&gt; , la implementaci&amp;oacute;n de scikit-learn combina clasificadores promediando su predicci&amp;oacute;n probabil&amp;iacute;stica, en lugar de dejar que cada clasificador vote por una sola clase.</target>
        </trans-unit>
        <trans-unit id="092465bd0b61837459fb29bf14c2dda6ed20e949" translate="yes" xml:space="preserve">
          <source>In contrast to the regression setting, the posterior of the latent function \(f\) is not Gaussian even for a GP prior since a Gaussian likelihood is inappropriate for discrete class labels. Rather, a non-Gaussian likelihood corresponding to the logistic link function (logit) is used. GaussianProcessClassifier approximates the non-Gaussian posterior with a Gaussian based on the Laplace approximation. More details can be found in Chapter 3 of &lt;a href=&quot;#rw2006&quot; id=&quot;id4&quot;&gt;[RW2006]&lt;/a&gt;.</source>
          <target state="translated">En contraste con la configuraci&amp;oacute;n de regresi&amp;oacute;n, la parte posterior de la funci&amp;oacute;n latente \ (f \) no es gaussiana ni siquiera para un GP antes, ya que una probabilidad gaussiana es inapropiada para etiquetas de clase discretas. M&amp;aacute;s bien, se utiliza una probabilidad no gaussiana correspondiente a la funci&amp;oacute;n de enlace log&amp;iacute;stico (logit). GaussianProcessClassifier aproxima el posterior no gaussiano con un gaussiano basado en la aproximaci&amp;oacute;n de Laplace. Se pueden encontrar m&amp;aacute;s detalles en el Cap&amp;iacute;tulo 3 de &lt;a href=&quot;#rw2006&quot; id=&quot;id4&quot;&gt;[RW2006]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="8da23c4fea95dfb9e1a4723525c1617ef732103e" translate="yes" xml:space="preserve">
          <source>In contrast, for small amounts of data, the training score of the SVM is much greater than the validation score. Adding more training samples will most likely increase generalization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d7f12a42ea8277b24625f1aff8d53cb363a14e0" translate="yes" xml:space="preserve">
          <source>In contrast, if the conventional accuracy is above chance only because the classifier takes advantage of an imbalanced test set, then the balanced accuracy, as appropriate, will drop to \(\frac{1}{\text{n\_classes}}\).</source>
          <target state="translated">Por el contrario,si la precisión convencional está por encima de la casualidad sólo porque el clasificador aprovecha un conjunto de pruebas desequilibradas,entonces la precisión equilibrada,según corresponda,bajará a \ ~ (\ ~ -fracaso{1}{\ ~ texto {\ ~ clases}).</target>
        </trans-unit>
        <trans-unit id="8343cdcc0bd2973a4149cb63a31822f5be571a78" translate="yes" xml:space="preserve">
          <source>In contrast, if the conventional accuracy is above chance only because the classifier takes advantage of an imbalanced test set, then the balanced accuracy, as appropriate, will drop to \(\frac{1}{n\_classes}\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89611c1358b346353d5469c5670ea64fb02fcdd7" translate="yes" xml:space="preserve">
          <source>In descending order of quality, when trained (outside of this example) on all 4 features using 30 estimators and scored using 10 fold cross validation, we see:</source>
          <target state="translated">En orden descendente de calidad,cuando se entrenó (fuera de este ejemplo)en los 4 rasgos usando 30 estimadores y se anotó usando una validación cruzada de 10 veces,vemos:</target>
        </trans-unit>
        <trans-unit id="0732cca6c2251b860da4c331fa5748d479b14945" translate="yes" xml:space="preserve">
          <source>In ensemble algorithms, bagging methods form a class of algorithms which build several instances of a black-box estimator on random subsets of the original training set and then aggregate their individual predictions to form a final prediction. These methods are used as a way to reduce the variance of a base estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it. In many cases, bagging methods constitute a very simple way to improve with respect to a single model, without making it necessary to adapt the underlying base algorithm. As they provide a way to reduce overfitting, bagging methods work best with strong and complex models (e.g., fully developed decision trees), in contrast with boosting methods which usually work best with weak models (e.g., shallow decision trees).</source>
          <target state="translated">En los algoritmos de conjunto,los métodos de empaquetamiento forman una clase de algoritmos que construyen varias instancias de un estimador de caja negra sobre subconjuntos aleatorios del conjunto original de entrenamiento y luego agregan sus predicciones individuales para formar una predicción final.Estos métodos se utilizan como una forma de reducir la varianza de un estimador de base (por ejemplo,un árbol de decisión),introduciendo la aleatorización en su procedimiento de construcción y luego haciendo un conjunto a partir de él.En muchos casos,los métodos de ensamblaje constituyen una forma muy sencilla de mejorar con respecto a un modelo único,sin que sea necesario adaptar el algoritmo de base subyacente.Como proporcionan una forma de reducir el exceso de adaptación,los métodos de ensacado funcionan mejor con modelos fuertes y complejos (por ejemplo,árboles de decisión plenamente desarrollados),en contraste con los métodos de potenciación que suelen funcionar mejor con modelos débiles (por ejemplo,árboles de decisión poco profundos).</target>
        </trans-unit>
        <trans-unit id="5305d1e9b70806a8391e61e804a0df6abd8f6cc5" translate="yes" xml:space="preserve">
          <source>In extending a binary metric to multiclass or multilabel problems, the data is treated as a collection of binary problems, one for each class. There are then a number of ways to average binary metric calculations across the set of classes, each of which may be useful in some scenario. Where available, you should select among these using the &lt;code&gt;average&lt;/code&gt; parameter.</source>
          <target state="translated">Al extender una m&amp;eacute;trica binaria a problemas de m&amp;uacute;ltiples clases o etiquetas, los datos se tratan como una colecci&amp;oacute;n de problemas binarios, uno para cada clase. Hay entonces varias formas de promediar los c&amp;aacute;lculos de m&amp;eacute;tricas binarias en el conjunto de clases, cada una de las cuales puede ser &amp;uacute;til en alg&amp;uacute;n escenario. Donde est&amp;eacute; disponible, debe seleccionar entre estos usando el par&amp;aacute;metro &lt;code&gt;average&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e87cfc9dff0fe670bd40ebf7e26edaa15ca842ad" translate="yes" xml:space="preserve">
          <source>In extremely randomized trees (see &lt;a href=&quot;generated/sklearn.ensemble.extratreesclassifier#sklearn.ensemble.ExtraTreesClassifier&quot;&gt;&lt;code&gt;ExtraTreesClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.extratreesregressor#sklearn.ensemble.ExtraTreesRegressor&quot;&gt;&lt;code&gt;ExtraTreesRegressor&lt;/code&gt;&lt;/a&gt; classes), randomness goes one step further in the way splits are computed. As in random forests, a random subset of candidate features is used, but instead of looking for the most discriminative thresholds, thresholds are drawn at random for each candidate feature and the best of these randomly-generated thresholds is picked as the splitting rule. This usually allows to reduce the variance of the model a bit more, at the expense of a slightly greater increase in bias:</source>
          <target state="translated">En &amp;aacute;rboles extremadamente aleatorios (consulte las clases &lt;a href=&quot;generated/sklearn.ensemble.extratreesclassifier#sklearn.ensemble.ExtraTreesClassifier&quot;&gt; &lt;code&gt;ExtraTreesClassifier&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.ensemble.extratreesregressor#sklearn.ensemble.ExtraTreesRegressor&quot;&gt; &lt;code&gt;ExtraTreesRegressor&lt;/code&gt; &lt;/a&gt; ), la aleatoriedad va un paso m&amp;aacute;s all&amp;aacute; en la forma en que se calculan las divisiones. Al igual que en los bosques aleatorios, se utiliza un subconjunto aleatorio de caracter&amp;iacute;sticas candidatas, pero en lugar de buscar los umbrales m&amp;aacute;s discriminativos, los umbrales se dibujan al azar para cada caracter&amp;iacute;stica candidata y el mejor de estos umbrales generados aleatoriamente se elige como la regla de divisi&amp;oacute;n. Esto suele permitir reducir un poco m&amp;aacute;s la varianza del modelo, a expensas de un aumento ligeramente mayor del sesgo:</target>
        </trans-unit>
        <trans-unit id="5c1305e3ce4cbb99adc8d313e42a43efab81ea5c" translate="yes" xml:space="preserve">
          <source>In fact, this dataset only has one version. The iris dataset on the other hand has multiple versions:</source>
          <target state="translated">De hecho,este conjunto de datos sólo tiene una versión.El conjunto de datos del iris,por otro lado,tiene múltiples versiones:</target>
        </trans-unit>
        <trans-unit id="63493dde535d33b43819cf48666bb2a9620c2476" translate="yes" xml:space="preserve">
          <source>In french but still a reference: Tenenhaus, M. (1998). La regression PLS: theorie et pratique. Paris: Editions Technic.</source>
          <target state="translated">En francés,pero sigue siendo una referencia:Tenenhaus,M.(1998).La regresión PLS:theorie et pratique.París:Ediciones Technic.</target>
        </trans-unit>
        <trans-unit id="6e95c3ada3b2525ed5f608da19594b4a42ad3dc4" translate="yes" xml:space="preserve">
          <source>In general doing predictions in bulk (many instances at the same time) is more efficient for a number of reasons (branching predictability, CPU cache, linear algebra libraries optimizations etc.). Here we see on a setting with few features that independently of estimator choice the bulk mode is always faster, and for some of them by 1 to 2 orders of magnitude:</source>
          <target state="translated">En general,hacer predicciones en masa (muchos casos al mismo tiempo)es más eficiente por varias razones (previsibilidad de las ramificaciones,caché de la CPU,optimización de las bibliotecas de álgebra lineal,etc.).Aquí vemos en un entorno con pocas características que,independientemente de la elección del estimador,el modo masivo es siempre más rápido,y para algunos de ellos de 1 a 2 órdenes de magnitud:</target>
        </trans-unit>
        <trans-unit id="73d5a0649f1537ceaa4a43b2819de8ab34f4f95d" translate="yes" xml:space="preserve">
          <source>In general, &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; is a technique used for analyzing similarity or dissimilarity data. It attempts to model similarity or dissimilarity data as distances in a geometric spaces. The data can be ratings of similarity between objects, interaction frequencies of molecules, or trade indices between countries.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5f14cdf8cb9c0df1b6ffce69bd866cdeffd9355" translate="yes" xml:space="preserve">
          <source>In general, a learning problem considers a set of n &lt;a href=&quot;https://en.wikipedia.org/wiki/Sample_(statistics)&quot;&gt;samples&lt;/a&gt; of data and then tries to predict properties of unknown data. If each sample is more than a single number and, for instance, a multi-dimensional entry (aka &lt;a href=&quot;https://en.wikipedia.org/wiki/Multivariate_random_variable&quot;&gt;multivariate&lt;/a&gt; data), it is said to have several attributes or &lt;strong&gt;features&lt;/strong&gt;.</source>
          <target state="translated">En general, un problema de aprendizaje considera un conjunto de n &lt;a href=&quot;https://en.wikipedia.org/wiki/Sample_(statistics)&quot;&gt;muestras&lt;/a&gt; de datos y luego intenta predecir las propiedades de los datos desconocidos. Si cada muestra tiene m&amp;aacute;s de un n&amp;uacute;mero y, por ejemplo, una entrada multidimensional (tambi&amp;eacute;n conocida como datos &lt;a href=&quot;https://en.wikipedia.org/wiki/Multivariate_random_variable&quot;&gt;multivariados&lt;/a&gt; ), se dice que tiene varios atributos o &lt;strong&gt;caracter&amp;iacute;sticas&lt;/strong&gt; .</target>
        </trans-unit>
        <trans-unit id="9cf7334c38597a2189c7af702ab9abdbe9f10093" translate="yes" xml:space="preserve">
          <source>In general, is a technique used for analyzing similarity or dissimilarity data. &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; attempts to model similarity or dissimilarity data as distances in a geometric spaces. The data can be ratings of similarity between objects, interaction frequencies of molecules, or trade indices between countries.</source>
          <target state="translated">En general, es una t&amp;eacute;cnica utilizada para analizar datos de similitud o disimilitud. &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt; &lt;code&gt;MDS&lt;/code&gt; &lt;/a&gt; intenta modelar datos de similitud o disimilitud como distancias en espacios geom&amp;eacute;tricos. Los datos pueden ser calificaciones de similitud entre objetos, frecuencias de interacci&amp;oacute;n de mol&amp;eacute;culas o &amp;iacute;ndices comerciales entre pa&amp;iacute;ses.</target>
        </trans-unit>
        <trans-unit id="71aab6786f00490669e72ac36911ce2d2486dab4" translate="yes" xml:space="preserve">
          <source>In general, it is about to learn a rough, close frontier delimiting the contour of the initial observations distribution, plotted in embedding \(p\)-dimensional space. Then, if further observations lay within the frontier-delimited subspace, they are considered as coming from the same population than the initial observations. Otherwise, if they lay outside the frontier, we can say that they are abnormal with a given confidence in our assessment.</source>
          <target state="translated">En general,está a punto de aprender una frontera aproximada y cercana que delimita el contorno de la distribución de las observaciones iniciales,trazada en el espacio incrustado.Luego,si las observaciones posteriores se encuentran dentro de la frontera delimitada del subespacio,se considera que provienen de la misma población que las observaciones iniciales.De lo contrario,si se encuentran fuera de la frontera,podemos decir que son anormales con una cierta confianza en nuestra evaluación.</target>
        </trans-unit>
        <trans-unit id="c9bca25ec918e4e036ec8a37ec502896ec56d542" translate="yes" xml:space="preserve">
          <source>In general, learning algorithms benefit from standardization of the data set. If some outliers are present in the set, robust scalers or transformers are more appropriate. The behaviors of the different scalers, transformers, and normalizers on a dataset containing marginal outliers is highlighted in &lt;a href=&quot;../auto_examples/preprocessing/plot_all_scaling#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py&quot;&gt;Compare the effect of different scalers on data with outliers&lt;/a&gt;.</source>
          <target state="translated">En general, los algoritmos de aprendizaje se benefician de la estandarizaci&amp;oacute;n del conjunto de datos. Si algunos valores at&amp;iacute;picos est&amp;aacute;n presentes en el conjunto, los escaladores o transformadores robustos son m&amp;aacute;s apropiados. Los comportamientos de los diferentes escaladores, transformadores y normalizadores en un conjunto de datos que contiene valores at&amp;iacute;picos marginales se resaltan en &lt;a href=&quot;../auto_examples/preprocessing/plot_all_scaling#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py&quot;&gt;Comparar el efecto de diferentes escaladores en datos con valores at&amp;iacute;picos&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="baeb2b7a43c2bc0dd04675c021d6ed663a58bf2d" translate="yes" xml:space="preserve">
          <source>In general, the run time cost to construct a balanced binary tree is \(O(n_{samples}n_{features}\log(n_{samples}))\) and query time \(O(\log(n_{samples}))\). Although the tree construction algorithm attempts to generate balanced trees, they will not always be balanced. Assuming that the subtrees remain approximately balanced, the cost at each node consists of searching through \(O(n_{features})\) to find the feature that offers the largest reduction in entropy. This has a cost of \(O(n_{features}n_{samples}\log(n_{samples}))\) at each node, leading to a total cost over the entire trees (by summing the cost at each node) of \(O(n_{features}n_{samples}^{2}\log(n_{samples}))\).</source>
          <target state="translated">En general,el coste del tiempo de ejecución para construir un árbol binario equilibrado es Aunque el algoritmo de construcción de árboles intenta generar árboles equilibrados,no siempre estarán equilibrados.Asumiendo que los subárboles permanecen aproximadamente equilibrados,el coste en cada nodo consiste en buscar a través de \(O(n_{características})\)para encontrar la característica que ofrece la mayor reducción de entropía.Esto tiene un coste de \N (O(n_{características}n_{muestras}}en cada nodo,lo que lleva a un coste total sobre los árboles enteros (sumando el coste en cada nodo)de \N (O(n_{características}n_{muestras}^{2}log(n_{muestras}))}).</target>
        </trans-unit>
        <trans-unit id="144a3925f6b19404e9d474c272482fb04a69a6ff" translate="yes" xml:space="preserve">
          <source>In general, when fitting a curve with a polynomial by Bayesian ridge regression, the selection of initial values of the regularization parameters (alpha, lambda) may be important. This is because the regularization parameters are determined by an iterative procedure that depends on initial values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dba314b8268f3eec306fec03d7cfe13e8e090ace" translate="yes" xml:space="preserve">
          <source>In general, when the problem isn&amp;rsquo;t linearly separable, the support vectors are the samples &lt;em&gt;within&lt;/em&gt; the margin boundaries.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="635895acc09f2d99381585bc2d144c9a66a85f3a" translate="yes" xml:space="preserve">
          <source>In gradient descent, the gradient \(\nabla Loss_{W}\) of the loss with respect to the weights is computed and deducted from \(W\). More formally, this is expressed as,</source>
          <target state="translated">En el descenso del gradiente,el gradiente de la pérdida con respecto a los pesos se calcula y se deduce de la pérdida.Más formalmente,esto se expresa como,</target>
        </trans-unit>
        <trans-unit id="2c51a2af5a19ac0ce7e4fb04fd6d887c03b6fecb" translate="yes" xml:space="preserve">
          <source>In high-dimensional spaces, linear classifiers often achieve excellent accuracy. For sparse binary data, BernoulliNB is particularly well-suited. The bottom row compares the decision boundary obtained by BernoulliNB in the transformed space with an ExtraTreesClassifier forests learned on the original data.</source>
          <target state="translated">En los espacios de altas dimensiones,los clasificadores lineales a menudo logran una excelente precisión.Para datos binarios escasos,BernoulliNB es particularmente adecuado.La fila inferior compara el límite de decisión obtenido por BernoulliNB en el espacio transformado con un ExtraTreesClassifier bosques aprendido en los datos originales.</target>
        </trans-unit>
        <trans-unit id="26c26ee3d75b66c7f22fed706da52f459434240f" translate="yes" xml:space="preserve">
          <source>In linear models, the target value is modeled as a linear combination of the features (see the &lt;a href=&quot;../../modules/linear_model#linear-model&quot;&gt;Linear Models&lt;/a&gt; User Guide section for a description of a set of linear models available in scikit-learn). Coefficients in multiple linear models represent the relationship between the given feature, \(X_i\) and the target, \(y\), assuming that all the other features remain constant (&lt;a href=&quot;https://en.wikipedia.org/wiki/Conditional_dependence&quot;&gt;conditional dependence&lt;/a&gt;). This is different from plotting \(X_i\) versus \(y\) and fitting a linear relationship: in that case all possible values of the other features are taken into account in the estimation (marginal dependence).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2367cf553e95efae790eac559ef2be19cd28f503" translate="yes" xml:space="preserve">
          <source>In machine-learning practice, Ridge Regression is more often used with non-negligible regularization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b577c96674cf299faa19ce0d11e2224d3c2c813" translate="yes" xml:space="preserve">
          <source>In majority voting, the predicted class label for a particular sample is the class label that represents the majority (mode) of the class labels predicted by each individual classifier.</source>
          <target state="translated">En la votación por mayoría,la etiqueta de clase pronosticada para una muestra particular es la etiqueta de clase que representa la mayoría (modo)de las etiquetas de clase pronosticadas por cada clasificador individual.</target>
        </trans-unit>
        <trans-unit id="589394183aec0e7af2afe4b456559f6baedc9992" translate="yes" xml:space="preserve">
          <source>In many cases it is thus recommended to carefully time and profile your feature extraction code as it may be a good place to start optimizing when your overall latency is too slow for your application.</source>
          <target state="translated">Por lo tanto,en muchos casos se recomienda cronometrar y perfilar cuidadosamente el código de extracción de características,ya que puede ser un buen lugar para comenzar a optimizar cuando la latencia general es demasiado lenta para la aplicación.</target>
        </trans-unit>
        <trans-unit id="aeae04273a5ed1fc88f796de718e3c2190c04f0d" translate="yes" xml:space="preserve">
          <source>In many modeling scenarios, normality of the features in a dataset is desirable. Power transforms are a family of parametric, monotonic transformations that aim to map data from any distribution to as close to a Gaussian distribution as possible in order to stabilize variance and minimize skewness.</source>
          <target state="translated">En muchos escenarios de modelización,es deseable la normalidad de las características de un conjunto de datos.Las transformaciones de potencia son una familia de transformaciones paramétricas y monótonas que tienen por objeto cartografiar los datos de cualquier distribución lo más cerca posible de una distribución gaussiana a fin de estabilizar la varianza y minimizar la asimetría.</target>
        </trans-unit>
        <trans-unit id="c82f65d47c3f4e11ad468a4165bdc787c51720a5" translate="yes" xml:space="preserve">
          <source>In many real-world examples, there are many ways to extract features from a dataset. Often it is beneficial to combine several methods to obtain good performance. This example shows how to use &lt;code&gt;FeatureUnion&lt;/code&gt; to combine features obtained by PCA and univariate selection.</source>
          <target state="translated">En muchos ejemplos del mundo real, hay muchas formas de extraer caracter&amp;iacute;sticas de un conjunto de datos. A menudo es beneficioso combinar varios m&amp;eacute;todos para obtener un buen rendimiento. Este ejemplo muestra c&amp;oacute;mo usar &lt;code&gt;FeatureUnion&lt;/code&gt; para combinar caracter&amp;iacute;sticas obtenidas por PCA y selecci&amp;oacute;n univariante.</target>
        </trans-unit>
        <trans-unit id="9c0b7f3861d3fe001968b978c49f3447d1233fa3" translate="yes" xml:space="preserve">
          <source>In mathematics, the Johnson-Lindenstrauss lemma is a result concerning low-distortion embeddings of points from high-dimensional into low-dimensional Euclidean space. The lemma states that a small set of points in a high-dimensional space can be embedded into a space of much lower dimension in such a way that distances between the points are nearly preserved. The map used for the embedding is at least Lipschitz, and can even be taken to be an orthogonal projection.</source>
          <target state="translated">En matemáticas,el lema de Johnson-Lindenstrauss es un resultado relativo a las incrustaciones de baja distorsión de los puntos del espacio euclidiano de alta dimensión en el de baja dimensión.El lema afirma que un pequeño conjunto de puntos en un espacio de alta dimensión puede ser incrustado en un espacio de dimensión mucho más baja de tal manera que las distancias entre los puntos se conservan casi intactas.El mapa utilizado para la incrustación es al menos Lipschitz,e incluso puede ser tomado como una proyección ortogonal.</target>
        </trans-unit>
        <trans-unit id="35a3805825da50966c5f8cb649b1d2ea852b8f59" translate="yes" xml:space="preserve">
          <source>In maximizing the log-likelihood, the positive gradient makes the model prefer hidden states that are compatible with the observed training data. Because of the bipartite structure of RBMs, it can be computed efficiently. The negative gradient, however, is intractable. Its goal is to lower the energy of joint states that the model prefers, therefore making it stay true to the data. It can be approximated by Markov chain Monte Carlo using block Gibbs sampling by iteratively sampling each of \(v\) and \(h\) given the other, until the chain mixes. Samples generated in this way are sometimes referred as fantasy particles. This is inefficient and it is difficult to determine whether the Markov chain mixes.</source>
          <target state="translated">Al maximizar la probabilidad logarítmica,el gradiente positivo hace que el modelo prefiera los estados ocultos que son compatibles con los datos de entrenamiento observados.Debido a la estructura bipartita de los RBM,puede ser computado eficientemente.El gradiente negativo,sin embargo,es intratable.Su objetivo es reducir la energía de los estados conjuntos que el modelo prefiere,por lo que se mantiene fiel a los datos.Puede ser aproximado por la cadena de Markov Monte Carlo usando el muestreo de Gibbs en bloque,muestreando iterativamente cada uno de \ ~ (v)y \ ~ dado el otro,hasta que la cadena se mezcla.Las muestras generadas de esta manera se denominan a veces partículas de fantasía.Esto es ineficiente y es difícil determinar si la cadena de Markov se mezcla.</target>
        </trans-unit>
        <trans-unit id="54db7da5f1b2e2f16e8f4dc3a375dac661b78213" translate="yes" xml:space="preserve">
          <source>In multi-label classification, the &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt; function is extended by averaging over the labels as &lt;a href=&quot;#average&quot;&gt;above&lt;/a&gt;.</source>
          <target state="translated">En la clasificaci&amp;oacute;n de etiquetas m&amp;uacute;ltiples, la funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;roc_auc_score&lt;/code&gt; &lt;/a&gt; se ampl&amp;iacute;a promediando las etiquetas como se indic&amp;oacute;&lt;a href=&quot;#average&quot;&gt; anteriormente&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="d9be5dcb267dcb84c278d12d7b1a881ada760886" translate="yes" xml:space="preserve">
          <source>In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.</source>
          <target state="translated">En la clasificación multi-etiqueta,ésta es la precisión del subconjunto,que es una métrica dura,ya que se requiere para cada muestra que cada conjunto de etiquetas sea predicho correctamente.</target>
        </trans-unit>
        <trans-unit id="9ff5420b9cd3095ee44bf9941c38c72dce6d517a" translate="yes" xml:space="preserve">
          <source>In multi-label settings</source>
          <target state="translated">En los entornos de múltiples etiquetas</target>
        </trans-unit>
        <trans-unit id="cf7a69d811fd496380ea6a3966d13bf17ca83f43" translate="yes" xml:space="preserve">
          <source>In multiclass and multilabel classification task, the notions of precision, recall, and F-measures can be applied to each label independently. There are a few ways to combine results across labels, specified by the &lt;code&gt;average&lt;/code&gt; argument to the &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; (multilabel only), &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt;&lt;code&gt;f1_score&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt;&lt;code&gt;fbeta_score&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.precision_recall_fscore_support#sklearn.metrics.precision_recall_fscore_support&quot;&gt;&lt;code&gt;precision_recall_fscore_support&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.precision_score#sklearn.metrics.precision_score&quot;&gt;&lt;code&gt;precision_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.recall_score#sklearn.metrics.recall_score&quot;&gt;&lt;code&gt;recall_score&lt;/code&gt;&lt;/a&gt; functions, as described &lt;a href=&quot;#average&quot;&gt;above&lt;/a&gt;. Note that if all labels are included, &amp;ldquo;micro&amp;rdquo;-averaging in a multiclass setting will produce precision, recall and \(F\) that are all identical to accuracy. Also note that &amp;ldquo;weighted&amp;rdquo; averaging may produce an F-score that is not between precision and recall.</source>
          <target state="translated">En la tarea de clasificaci&amp;oacute;n multiclase y de m&amp;uacute;ltiples etiquetas, las nociones de precisi&amp;oacute;n, recuperaci&amp;oacute;n y medidas F se pueden aplicar a cada etiqueta de forma independiente. Hay unas pocas maneras de combinar resultados a trav&amp;eacute;s de etiquetas, especificados por el &lt;code&gt;average&lt;/code&gt; argumento a la &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt; (Multilabel solamente), &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt; &lt;code&gt;f1_score&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt; &lt;code&gt;fbeta_score&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.metrics.precision_recall_fscore_support#sklearn.metrics.precision_recall_fscore_support&quot;&gt; &lt;code&gt;precision_recall_fscore_support&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.metrics.precision_score#sklearn.metrics.precision_score&quot;&gt; &lt;code&gt;precision_score&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.metrics.recall_score#sklearn.metrics.recall_score&quot;&gt; &lt;code&gt;recall_score&lt;/code&gt; &lt;/a&gt; funciones, como se describe &lt;a href=&quot;#average&quot;&gt;anteriormente&lt;/a&gt;. Tenga en cuenta que si se incluyen todas las etiquetas, el &quot;micro&quot; promediado en un entorno multiclase producir&amp;aacute; precisi&amp;oacute;n, recuperaci&amp;oacute;n y \ (F \) que son todos id&amp;eacute;nticos a la precisi&amp;oacute;n. Tambi&amp;eacute;n tenga en cuenta que el promedio &quot;ponderado&quot; puede producir una puntuaci&amp;oacute;n F que no se encuentra entre la precisi&amp;oacute;n y el recuerdo.</target>
        </trans-unit>
        <trans-unit id="afc91520f5287da47360dcd6fd00b4fb446bcf96" translate="yes" xml:space="preserve">
          <source>In multiclass case, the function expects that either all the labels are included in y_true or an optional labels argument is provided which contains all the labels. The multilabel margin is calculated according to Crammer-Singer&amp;rsquo;s method. As in the binary case, the cumulated hinge loss is an upper bound of the number of mistakes made by the classifier.</source>
          <target state="translated">En el caso multiclase, la funci&amp;oacute;n espera que todas las etiquetas est&amp;eacute;n incluidas en y_true o se proporcione un argumento de etiquetas opcional que contenga todas las etiquetas. El margen de varias etiquetas se calcula seg&amp;uacute;n el m&amp;eacute;todo de Crammer-Singer. Como en el caso binario, la p&amp;eacute;rdida de bisagra acumulada es un l&amp;iacute;mite superior del n&amp;uacute;mero de errores cometidos por el clasificador.</target>
        </trans-unit>
        <trans-unit id="a7ec36140af641cfb5e4e5e11dec536798cfb2f8" translate="yes" xml:space="preserve">
          <source>In multiclass classification, the Hamming loss correspond to the Hamming distance between &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; which is equivalent to the subset &lt;code&gt;zero_one_loss&lt;/code&gt; function.</source>
          <target state="translated">En la clasificaci&amp;oacute;n multiclase, la p&amp;eacute;rdida de Hamming corresponde a la distancia de Hamming entre &lt;code&gt;y_true&lt;/code&gt; e &lt;code&gt;y_pred&lt;/code&gt; que es equivalente al subconjunto &lt;code&gt;zero_one_loss&lt;/code&gt; funci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="a514b0b14d02249930d02d183e261b474a100dbd" translate="yes" xml:space="preserve">
          <source>In multiclass classification, the Hamming loss corresponds to the Hamming distance between &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; which is equivalent to the subset &lt;code&gt;zero_one_loss&lt;/code&gt; function, when &lt;code&gt;normalize&lt;/code&gt; parameter is set to True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff1916ae5265c4d87d1472e5cc3e0c2594a22de8" translate="yes" xml:space="preserve">
          <source>In multiclass classification, the Hamming loss corresponds to the Hamming distance between &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; which is similar to the &lt;a href=&quot;#zero-one-loss&quot;&gt;Zero one loss&lt;/a&gt; function. However, while zero-one loss penalizes prediction sets that do not strictly match true sets, the Hamming loss penalizes individual labels. Thus the Hamming loss, upper bounded by the zero-one loss, is always between zero and one, inclusive; and predicting a proper subset or superset of the true labels will give a Hamming loss between zero and one, exclusive.</source>
          <target state="translated">En la clasificaci&amp;oacute;n multiclase, la p&amp;eacute;rdida de Hamming corresponde a la distancia de Hamming entre &lt;code&gt;y_true&lt;/code&gt; e &lt;code&gt;y_pred&lt;/code&gt; , que es similar a la funci&amp;oacute;n de &lt;a href=&quot;#zero-one-loss&quot;&gt;cero una p&amp;eacute;rdida&lt;/a&gt; . Sin embargo, mientras que la p&amp;eacute;rdida cero-uno penaliza los conjuntos de predicci&amp;oacute;n que no coinciden estrictamente con los conjuntos verdaderos, la p&amp;eacute;rdida de Hamming penaliza a las etiquetas individuales. As&amp;iacute;, la p&amp;eacute;rdida de Hamming, delimitada por la p&amp;eacute;rdida cero-uno, est&amp;aacute; siempre entre cero y uno, inclusive; y predecir un subconjunto o superconjunto adecuado de las etiquetas verdaderas dar&amp;aacute; una p&amp;eacute;rdida de Hamming entre cero y uno, exclusiva.</target>
        </trans-unit>
        <trans-unit id="cf7ce831a18d046dad4e38dc2cae92648b792778" translate="yes" xml:space="preserve">
          <source>In multilabel classification, the &lt;a href=&quot;generated/sklearn.metrics.zero_one_loss#sklearn.metrics.zero_one_loss&quot;&gt;&lt;code&gt;zero_one_loss&lt;/code&gt;&lt;/a&gt; scores a subset as one if its labels strictly match the predictions, and as a zero if there are any errors. By default, the function returns the percentage of imperfectly predicted subsets. To get the count of such subsets instead, set &lt;code&gt;normalize&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">En la clasificaci&amp;oacute;n de m&amp;uacute;ltiples etiquetas, &lt;a href=&quot;generated/sklearn.metrics.zero_one_loss#sklearn.metrics.zero_one_loss&quot;&gt; &lt;code&gt;zero_one_loss&lt;/code&gt; &lt;/a&gt; punt&amp;uacute;a un subconjunto como uno si sus etiquetas coinciden estrictamente con las predicciones, y como un cero si hay alg&amp;uacute;n error. De forma predeterminada, la funci&amp;oacute;n devuelve el porcentaje de subconjuntos predichos de manera imperfecta. Para obtener el recuento de dichos subconjuntos, establezca &lt;code&gt;normalize&lt;/code&gt; en &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="2cdc777c3fd9aacea19e984339f1423c55608098" translate="yes" xml:space="preserve">
          <source>In multilabel classification, the Hamming loss is different from the subset zero-one loss. The zero-one loss considers the entire set of labels for a given sample incorrect if it does entirely match the true set of labels. Hamming loss is more forgiving in that it penalizes the individual labels.</source>
          <target state="translated">En la clasificación de la multi-etiqueta,la pérdida de Hamming es diferente de la pérdida del subconjunto cero-uno.La pérdida de cero uno considera que el conjunto de etiquetas de una muestra dada es incorrecto si coincide totalmente con el verdadero conjunto de etiquetas.La pérdida por martilleo es más indulgente porque penaliza las etiquetas individuales.</target>
        </trans-unit>
        <trans-unit id="602aeb7c2d89b27ea6d03c59146d4b4fecde4c31" translate="yes" xml:space="preserve">
          <source>In multilabel classification, the Hamming loss is different from the subset zero-one loss. The zero-one loss considers the entire set of labels for a given sample incorrect if it does not entirely match the true set of labels. Hamming loss is more forgiving in that it penalizes only the individual labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00e9bece59054d08c4ac787e06eeb4fc8070bdab" translate="yes" xml:space="preserve">
          <source>In multilabel classification, the function returns the subset accuracy. If the entire set of predicted labels for a sample strictly match with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0.</source>
          <target state="translated">En la clasificación de la etiqueta múltiple,la función devuelve la precisión del subconjunto.Si el conjunto completo de etiquetas predichas para una muestra coincide estrictamente con el verdadero conjunto de etiquetas,entonces la precisión del subconjunto es 1.0;de lo contrario es 0.0.</target>
        </trans-unit>
        <trans-unit id="7cd1b88a6c55666089bdc7543f7e259d70d5898d" translate="yes" xml:space="preserve">
          <source>In multilabel classification, the zero_one_loss function corresponds to the subset zero-one loss: for each sample, the entire set of labels must be correctly predicted, otherwise the loss for that sample is equal to one.</source>
          <target state="translated">En la clasificación de las etiquetas múltiples,la función zero_one_loss corresponde al subconjunto de la pérdida zero_one:para cada muestra,el conjunto de etiquetas debe ser correctamente previsto,de lo contrario la pérdida para esa muestra es igual a uno.</target>
        </trans-unit>
        <trans-unit id="c56a96e702a01557c0cb1c7c6c5d254cdaebcc8b" translate="yes" xml:space="preserve">
          <source>In multilabel classification, this function computes subset accuracy: the set of labels predicted for a sample must &lt;em&gt;exactly&lt;/em&gt; match the corresponding set of labels in y_true.</source>
          <target state="translated">En la clasificaci&amp;oacute;n de etiquetas m&amp;uacute;ltiples, esta funci&amp;oacute;n calcula la precisi&amp;oacute;n del subconjunto: el conjunto de etiquetas predichas para una muestra debe coincidir &lt;em&gt;exactamente&lt;/em&gt; con el conjunto de etiquetas correspondiente en y_true.</target>
        </trans-unit>
        <trans-unit id="00440d1e0316ae49b10a616cf581f0acff1a935a" translate="yes" xml:space="preserve">
          <source>In multilabel confusion matrix \(MCM\), the count of true negatives is \(MCM_{:,0,0}\), false negatives is \(MCM_{:,1,0}\), true positives is \(MCM_{:,1,1}\) and false positives is \(MCM_{:,0,1}\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3fad4287dcc0210ad8169708b233947ca706f077" translate="yes" xml:space="preserve">
          <source>In multilabel learning, each sample can have any number of ground truth labels associated with it. The goal is to give high scores and better rank to the ground truth labels.</source>
          <target state="translated">En el aprendizaje de las etiquetas múltiples,cada muestra puede tener asociadas cualquier número de etiquetas de verdad de la tierra.El objetivo es dar altas puntuaciones y una mejor clasificación a las etiquetas de verdades básicas.</target>
        </trans-unit>
        <trans-unit id="9d6449537c42279d12e406059563c338784d06f3" translate="yes" xml:space="preserve">
          <source>In multilabel learning, the joint set of binary classification tasks is expressed with label binary indicator array: each sample is one row of a 2d array of shape (n_samples, n_classes) with binary values: the one, i.e. the non zero elements, corresponds to the subset of labels. An array such as &lt;code&gt;np.array([[1, 0, 0], [0, 1, 1], [0, 0, 0]])&lt;/code&gt; represents label 0 in the first sample, labels 1 and 2 in the second sample, and no labels in the third sample.</source>
          <target state="translated">En el aprendizaje de m&amp;uacute;ltiples etiquetas, el conjunto conjunto de tareas de clasificaci&amp;oacute;n binaria se expresa con la etiqueta matriz de indicador binario: cada muestra es una fila de una matriz 2d de forma (n_samples, n_classes) con valores binarios: el uno, es decir, los elementos distintos de cero, corresponde a el subconjunto de etiquetas. Una matriz como &lt;code&gt;np.array([[1, 0, 0], [0, 1, 1], [0, 0, 0]])&lt;/code&gt; representa la etiqueta 0 en la primera muestra, las etiquetas 1 y 2 en la segunda muestra y sin etiquetas en la tercera muestra.</target>
        </trans-unit>
        <trans-unit id="65f6ef4e3d2b7a1359958abf87c802c2de77e1d9" translate="yes" xml:space="preserve">
          <source>In normal usage, the Calinski-Harabasz index is applied to the results of a cluster analysis:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c2c0f769c8a98dc6df3f2e7afe566ac80c0f339" translate="yes" xml:space="preserve">
          <source>In normal usage, the Calinski-Harabaz index is applied to the results of a cluster analysis.</source>
          <target state="translated">En el uso normal,el índice de Calinski-Harabaz se aplica a los resultados de un análisis de conglomerados.</target>
        </trans-unit>
        <trans-unit id="5f0c7d20ec265094d1673fd625fd38165b384452" translate="yes" xml:space="preserve">
          <source>In normal usage, the Davies-Bouldin index is applied to the results of a cluster analysis as follows:</source>
          <target state="translated">En el uso normal,el índice de Davies-Bouldin se aplica a los resultados de un análisis de conglomerados de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="0488e7351783ef8ef785f4bdea49af8c75724adf" translate="yes" xml:space="preserve">
          <source>In normal usage, the Silhouette Coefficient is applied to the results of a cluster analysis.</source>
          <target state="translated">En el uso normal,el Coeficiente de Silueta se aplica a los resultados de un análisis de conglomerados.</target>
        </trans-unit>
        <trans-unit id="af7916eabb756a4304309b1e18ceea097a7a5071" translate="yes" xml:space="preserve">
          <source>In order to address the wider task of Natural Language Understanding, the local structure of sentences and paragraphs should thus be taken into account. Many such models will thus be casted as &amp;ldquo;Structured output&amp;rdquo; problems which are currently outside of the scope of scikit-learn.</source>
          <target state="translated">Por tanto, para abordar la tarea m&amp;aacute;s amplia de la comprensi&amp;oacute;n del lenguaje natural, se debe tener en cuenta la estructura local de oraciones y p&amp;aacute;rrafos. Por lo tanto, muchos de estos modelos se considerar&amp;aacute;n problemas de &quot;salida estructurada&quot; que actualmente est&amp;aacute;n fuera del alcance de scikit-learn.</target>
        </trans-unit>
        <trans-unit id="819693d214fc959100941f9c2bf3cb570fc069ec" translate="yes" xml:space="preserve">
          <source>In order to address this, scikit-learn provides utilities for the most common ways to extract numerical features from text content, namely:</source>
          <target state="translated">Para hacer frente a esto,scikit-learn proporciona utilidades para las formas más comunes de extraer características numéricas del contenido del texto,a saber:</target>
        </trans-unit>
        <trans-unit id="5bdd52099ccc039c40b609f18b326c63aea62fae" translate="yes" xml:space="preserve">
          <source>In order to be able to store such a matrix in memory but also to speed up algebraic operations matrix / vector, implementations will typically use a sparse representation such as the implementations available in the &lt;code&gt;scipy.sparse&lt;/code&gt; package.</source>
          <target state="translated">Para poder almacenar una matriz de este tipo en la memoria, pero tambi&amp;eacute;n para acelerar la matriz / vector de operaciones algebraicas, las implementaciones normalmente utilizar&amp;aacute;n una representaci&amp;oacute;n escasa, como las implementaciones disponibles en el paquete &lt;code&gt;scipy.sparse&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="af0531a207de85560d0c6e1dcc4e5a478aa65d8d" translate="yes" xml:space="preserve">
          <source>In order to build histograms, the input data &lt;code&gt;X&lt;/code&gt; needs to be binned into integer-valued bins. This binning procedure does require sorting the feature values, but it only happens once at the very beginning of the boosting process (not at each node, like in &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0bf98f40bc311f4824763dea8c552bc0812d861" translate="yes" xml:space="preserve">
          <source>In order to feed predictive or clustering models with the text data, one first need to turn the text into vectors of numerical values suitable for statistical analysis. This can be achieved with the utilities of the &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; as demonstrated in the following example that extract &lt;a href=&quot;https://en.wikipedia.org/wiki/Tf-idf&quot;&gt;TF-IDF&lt;/a&gt; vectors of unigram tokens from a subset of 20news:</source>
          <target state="translated">Para alimentar modelos predictivos o de agrupamiento con datos de texto, primero es necesario convertir el texto en vectores de valores num&amp;eacute;ricos adecuados para el an&amp;aacute;lisis estad&amp;iacute;stico. Esto se puede lograr con las utilidades de &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; como se demuestra en el siguiente ejemplo que extrae vectores &lt;a href=&quot;https://en.wikipedia.org/wiki/Tf-idf&quot;&gt;TF-IDF&lt;/a&gt; de tokens unigram de un subconjunto de 20news:</target>
        </trans-unit>
        <trans-unit id="c3614fb1e15f18200960459d2e1c203458a6eae2" translate="yes" xml:space="preserve">
          <source>In order to fit linear models with those predictors it is therefore necessary to perform standard feature transformations as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a439a73e36b65ee0a94b3f1d9d89e3ac154697cf" translate="yes" xml:space="preserve">
          <source>In order to get faster execution times for this first example we will work on a partial dataset with only 4 categories out of the 20 available in the dataset:</source>
          <target state="translated">Para obtener tiempos de ejecución más rápidos para este primer ejemplo trabajaremos en un conjunto de datos parciales con sólo 4 categorías de las 20 disponibles en el conjunto de datos:</target>
        </trans-unit>
        <trans-unit id="da7edac191ef2f2a6bab6d167570c5dc3d626b83" translate="yes" xml:space="preserve">
          <source>In order to learn good latent representations from a small dataset, we artificially generate more labeled data by perturbing the training data with linear shifts of 1 pixel in each direction.</source>
          <target state="translated">Para aprender buenas representaciones latentes de un pequeño conjunto de datos,generamos artificialmente más datos etiquetados perturbando los datos de entrenamiento con desplazamientos lineales de 1 píxel en cada dirección.</target>
        </trans-unit>
        <trans-unit id="6983d2c6ff1cbf277ea5d9522b128070bfd0a615" translate="yes" xml:space="preserve">
          <source>In order to make the vectorizer =&amp;gt; transformer =&amp;gt; classifier easier to work with, &lt;code&gt;scikit-learn&lt;/code&gt; provides a &lt;a href=&quot;../../modules/generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; class that behaves like a compound classifier:</source>
          <target state="translated">Para facilitar el trabajo con el vectorizador =&amp;gt; transformador =&amp;gt; clasificador, &lt;code&gt;scikit-learn&lt;/code&gt; proporciona una clase &lt;a href=&quot;../../modules/generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;Pipeline&lt;/code&gt; &lt;/a&gt; que se comporta como un clasificador compuesto:</target>
        </trans-unit>
        <trans-unit id="5257e11193f291f6f81d5d2347e3cbb71ec9f310" translate="yes" xml:space="preserve">
          <source>In order to perform machine learning on text documents, we first need to turn the text content into numerical feature vectors.</source>
          <target state="translated">Para realizar el aprendizaje automático en documentos de texto,primero tenemos que convertir el contenido del texto en vectores de características numéricas.</target>
        </trans-unit>
        <trans-unit id="7b973d24b18f4331d1cc68b945953f9c40c766fe" translate="yes" xml:space="preserve">
          <source>In order to predict the class labels based on the predicted class-probabilities (scikit-learn estimators in the VotingClassifier must support &lt;code&gt;predict_proba&lt;/code&gt; method):</source>
          <target state="translated">Para predecir las etiquetas de clase basadas en las probabilidades de clase predichas (los estimadores de scikit-learn en el VotingClassifier deben admitir el m&amp;eacute;todo &lt;code&gt;predict_proba&lt;/code&gt; ):</target>
        </trans-unit>
        <trans-unit id="a7ffbb7849ad7a74935991324e062c6b6722378d" translate="yes" xml:space="preserve">
          <source>In order to re-weight the count features into floating point values suitable for usage by a classifier it is very common to use the tf&amp;ndash;idf transform.</source>
          <target state="translated">Para volver a ponderar las caracter&amp;iacute;sticas de recuento en valores de punto flotante adecuados para su uso por un clasificador, es muy com&amp;uacute;n utilizar la transformaci&amp;oacute;n tf-idf.</target>
        </trans-unit>
        <trans-unit id="4707665df8a323c1a68b209bc6166b3798e4ea75" translate="yes" xml:space="preserve">
          <source>In order to rebuild a similar model with future versions of scikit-learn, additional metadata should be saved along the pickled model:</source>
          <target state="translated">Para reconstruir un modelo similar con futuras versiones de scikit-learn,se deben guardar metadatos adicionales a lo largo del modelo encurtido:</target>
        </trans-unit>
        <trans-unit id="168239ecf279021917cbfef805f1d7d711ae1c44" translate="yes" xml:space="preserve">
          <source>In order to test if a classification score is significative a technique in repeating the classification procedure after randomizing, permuting, the labels. The p-value is then given by the percentage of runs for which the score obtained is greater than the classification score obtained in the first place.</source>
          <target state="translated">Para comprobar si una puntuación de clasificación es significativa,se ha recurrido a una técnica de repetición del procedimiento de clasificación después de aleatorizar,permutar,las etiquetas.El valor p viene dado entonces por el porcentaje de carreras en las que la puntuación obtenida es mayor que la puntuación de clasificación obtenida en primer lugar.</target>
        </trans-unit>
        <trans-unit id="fdc8e1656ba1332f0933f9f656403151b15252d2" translate="yes" xml:space="preserve">
          <source>In other words, return an input X_original whose transform would be X.</source>
          <target state="translated">En otras palabras,devuelve una entrada X_original cuya transformación sería X.</target>
        </trans-unit>
        <trans-unit id="f84fbaf022a2c87e2f72b92c7b8059751d7f8963" translate="yes" xml:space="preserve">
          <source>In other words, we &lt;em&gt;decomposed&lt;/em&gt; matrix \(\mathbf{X}\).</source>
          <target state="translated">En otras palabras, &lt;em&gt;descomponemos la&lt;/em&gt; matriz \ (\ mathbf {X} \).</target>
        </trans-unit>
        <trans-unit id="573ad5780d66d8749d635925a4f90732aa002652" translate="yes" xml:space="preserve">
          <source>In particular Rosenberg and Hirschberg (2007) define the following two desirable objectives for any cluster assignment:</source>
          <target state="translated">En particular,Rosenberg y Hirschberg (2007)definen los dos siguientes objetivos deseables para cualquier asignación de grupos:</target>
        </trans-unit>
        <trans-unit id="dafd8fff090495231531a6dce6a0d9bf23cd3c87" translate="yes" xml:space="preserve">
          <source>In particular in a &lt;strong&gt;supervised setting&lt;/strong&gt; it can be successfully combined with fast and scalable linear models to train &lt;strong&gt;document classifiers&lt;/strong&gt;, for instance:</source>
          <target state="translated">En particular, en un &lt;strong&gt;entorno supervisado,&lt;/strong&gt; se puede combinar con &amp;eacute;xito con modelos lineales r&amp;aacute;pidos y escalables para entrenar &lt;strong&gt;clasificadores de documentos&lt;/strong&gt; , por ejemplo:</target>
        </trans-unit>
        <trans-unit id="b70db829e86f8b0b87ee4b4ea9165e2800cb135e" translate="yes" xml:space="preserve">
          <source>In particular the interrogative form &amp;ldquo;Is this&amp;rdquo; is only present in the last document:</source>
          <target state="translated">En particular, la forma interrogativa &quot;Es esto&quot; solo est&amp;aacute; presente en el &amp;uacute;ltimo documento:</target>
        </trans-unit>
        <trans-unit id="48a72aaef5f57348c3c02ddfbd84f34663c56133" translate="yes" xml:space="preserve">
          <source>In particular we name:</source>
          <target state="translated">En particular,nombramos:</target>
        </trans-unit>
        <trans-unit id="32bae48b70c29501503578b88b61dfab45b0637c" translate="yes" xml:space="preserve">
          <source>In particular, \(\nu = 3/2\):</source>
          <target state="translated">En particular,\ ~-(\ ~ \ ~ nu=3/2\ ~ -):</target>
        </trans-unit>
        <trans-unit id="204dd46cfb26952328568f02a630bc8ec2809e56" translate="yes" xml:space="preserve">
          <source>In particular, truncated SVD works on term count/tf-idf matrices as returned by the vectorizers in &lt;a href=&quot;../classes#module-sklearn.feature_extraction.text&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt;&lt;/a&gt;. In that context, it is known as latent semantic analysis (LSA).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff34c019cd4067dd0b8a1a6d1536db31ff351b58" translate="yes" xml:space="preserve">
          <source>In particular, truncated SVD works on term count/tf-idf matrices as returned by the vectorizers in sklearn.feature_extraction.text. In that context, it is known as latent semantic analysis (LSA).</source>
          <target state="translated">En particular,la SVD truncada funciona con matrices de conteo de términos/tf-idf como las devuelven los vectorizadores en sklearn.feature_extraction.text.En ese contexto,se conoce como análisis semántico latente (LSA).</target>
        </trans-unit>
        <trans-unit id="74d856933005d819af2a4b7d2ce24317b5186453" translate="yes" xml:space="preserve">
          <source>In practice Spectral Clustering is very useful when the structure of the individual clusters is highly non-convex or more generally when a measure of the center and spread of the cluster is not a suitable description of the complete cluster. For instance when clusters are nested circles on the 2D plan.</source>
          <target state="translated">En la práctica,la agrupación espectral es muy útil cuando la estructura de los cúmulos individuales es muy poco convexa o,más en general,cuando una medida del centro y la extensión del cúmulo no es una descripción adecuada del cúmulo completo.Por ejemplo cuando los cúmulos son círculos anidados en el plano 2D.</target>
        </trans-unit>
        <trans-unit id="316ef03a3b1d8845e6fcfccde0af625da5037900" translate="yes" xml:space="preserve">
          <source>In practice Spectral Clustering is very useful when the structure of the individual clusters is highly non-convex or more generally when a measure of the center and spread of the cluster is not a suitable description of the complete cluster. For instance when clusters are nested circles on the 2D plane.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21d1a0735c97d36c546ea3246065facc34b4f5a9" translate="yes" xml:space="preserve">
          <source>In practice Spectral Clustering is very useful when the structure of the individual clusters is highly non-convex or more generally when a measure of the center and spread of the cluster is not a suitable description of the complete cluster. For instance, when clusters are nested circles on the 2D plane.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5662b7bb73c6d21ae298513382716bd3fe526ba2" translate="yes" xml:space="preserve">
          <source>In practice the local density is obtained from the k-nearest neighbors. The LOF score of an observation is equal to the ratio of the average local density of his k-nearest neighbors, and its own local density: a normal instance is expected to have a local density similar to that of its neighbors, while abnormal data are expected to have much smaller local density.</source>
          <target state="translated">En la práctica,la densidad local se obtiene de los vecinos más cercanos.La puntuación de la LOF de una observación es igual a la proporción de la densidad local media de sus vecinos más cercanos,y su propia densidad local:se espera que una instancia normal tenga una densidad local similar a la de sus vecinos,mientras que se espera que los datos anormales tengan una densidad local mucho menor.</target>
        </trans-unit>
        <trans-unit id="7ab811a62d63edef5c9695fca6cafd8cc266404c" translate="yes" xml:space="preserve">
          <source>In practice those estimates are stored as an attribute named &lt;code&gt;feature_importances_&lt;/code&gt; on the fitted model. This is an array with shape &lt;code&gt;(n_features,)&lt;/code&gt; whose values are positive and sum to 1.0. The higher the value, the more important is the contribution of the matching feature to the prediction function.</source>
          <target state="translated">En la pr&amp;aacute;ctica, esas estimaciones se almacenan como un atributo denominado &lt;code&gt;feature_importances_&lt;/code&gt; en el modelo ajustado. Esta es una matriz con forma &lt;code&gt;(n_features,)&lt;/code&gt; cuyos valores son positivos y suman 1.0. Cuanto mayor sea el valor, m&amp;aacute;s importante es la contribuci&amp;oacute;n de la caracter&amp;iacute;stica de coincidencia a la funci&amp;oacute;n de predicci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="2f91c327e74b19930bc0b8d2d9c2f5d99fe44af7" translate="yes" xml:space="preserve">
          <source>In practice we often ignore the shape of the distribution and just transform the data to center it by removing the mean value of each feature, then scale it by dividing non-constant features by their standard deviation.</source>
          <target state="translated">En la práctica,a menudo ignoramos la forma de la distribución y sólo transformamos los datos para centrarlos eliminando el valor medio de cada característica,y luego los escalamos dividiendo las características no constantes por su desviación estándar.</target>
        </trans-unit>
        <trans-unit id="4c632dd9d37d8e850afe2fbbbdbddfedb108d119" translate="yes" xml:space="preserve">
          <source>In practice, \(\mu\) and \(\Sigma\) are replaced by some estimates. The usual covariance maximum likelihood estimate is very sensitive to the presence of outliers in the data set and therefor, the corresponding Mahalanobis distances are. One would better have to use a robust estimator of covariance to guarantee that the estimation is resistant to &amp;ldquo;erroneous&amp;rdquo; observations in the data set and that the associated Mahalanobis distances accurately reflect the true organisation of the observations.</source>
          <target state="translated">En la pr&amp;aacute;ctica, \ (\ mu \) y \ (\ Sigma \) se reemplazan por algunas estimaciones. La estimaci&amp;oacute;n de m&amp;aacute;xima verosimilitud de la covarianza habitual es muy sensible a la presencia de valores at&amp;iacute;picos en el conjunto de datos y, por lo tanto, las distancias de Mahalanobis correspondientes son. Ser&amp;iacute;a mejor utilizar un estimador robusto de covarianza para garantizar que la estimaci&amp;oacute;n sea resistente a observaciones &quot;err&amp;oacute;neas&quot; en el conjunto de datos y que las distancias de Mahalanobis asociadas reflejen con precisi&amp;oacute;n la verdadera organizaci&amp;oacute;n de las observaciones.</target>
        </trans-unit>
        <trans-unit id="7f19bfe5f66f3783151b8147191d95599d9b587d" translate="yes" xml:space="preserve">
          <source>In practice, the k-means algorithm is very fast (one of the fastest clustering algorithms available), but it falls in local minima. That&amp;rsquo;s why it can be useful to restart it several times.</source>
          <target state="translated">En la pr&amp;aacute;ctica, el algoritmo de k-medias es muy r&amp;aacute;pido (uno de los algoritmos de agrupamiento m&amp;aacute;s r&amp;aacute;pidos disponibles), pero cae en m&amp;iacute;nimos locales. Por eso puede resultar &amp;uacute;til reiniciarlo varias veces.</target>
        </trans-unit>
        <trans-unit id="514529e761d628932a46cfab06e171128c270c12" translate="yes" xml:space="preserve">
          <source>In practice, whether parallelism is helpful at improving runtime depends on many factors. It is usually a good idea to experiment rather than assuming that increasing the number of workers is always a good thing. In some cases it can be highly detrimental to performance to run multiple copies of some estimators or functions in parallel (see oversubscription below).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f131bcc125dc920f59e2c48cc0ec0622c3531f86" translate="yes" xml:space="preserve">
          <source>In practice, you will have to handle yourself the column data type. If you want some columns to be considered as &lt;code&gt;category&lt;/code&gt;, you will have to convert them into categorical columns. If you are using pandas, you can refer to their documentation regarding &lt;a href=&quot;https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html&quot;&gt;Categorical data&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c017831824360a69856c6ccfffcd3f1b73574d4" translate="yes" xml:space="preserve">
          <source>In practise, a stacking predictor predict as good as the best predictor of the base layer and even sometimes outputperform it by combining the different strength of the these predictors. However, training a stacking predictor is computationally expensive.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0aad0cfd8ffb7884222ad0979279d2b7ce81ef15" translate="yes" xml:space="preserve">
          <source>In principle, any function can be passed that provides a &lt;code&gt;rvs&lt;/code&gt; (random variate sample) method to sample a value. A call to the &lt;code&gt;rvs&lt;/code&gt; function should provide independent random samples from possible parameter values on consecutive calls.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9809378b0338436bd7bbe8f2e2070a6272b570d" translate="yes" xml:space="preserve">
          <source>In problems where it is desired to give more importance to certain classes or certain individual samples keywords &lt;code&gt;class_weight&lt;/code&gt; and &lt;code&gt;sample_weight&lt;/code&gt; can be used.</source>
          <target state="translated">En problemas en los que se desee dar m&amp;aacute;s importancia a determinadas clases o determinadas muestras individuales, se pueden utilizar las palabras clave &lt;code&gt;class_weight&lt;/code&gt; y &lt;code&gt;sample_weight&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="274191e11959a25ec702f3eb0728b40adf181870" translate="yes" xml:space="preserve">
          <source>In problems where it is desired to give more importance to certain classes or certain individual samples, the parameters &lt;code&gt;class_weight&lt;/code&gt; and &lt;code&gt;sample_weight&lt;/code&gt; can be used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c88cb15e9453fb980c7d19e00322e852632f7bf2" translate="yes" xml:space="preserve">
          <source>In random forests (see &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;RandomForestClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt;&lt;code&gt;RandomForestRegressor&lt;/code&gt;&lt;/a&gt; classes), each tree in the ensemble is built from a sample drawn with replacement (i.e., a bootstrap sample) from the training set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cae7f41bfdb577edc832687cbceee9865d3220c5" translate="yes" xml:space="preserve">
          <source>In random forests (see &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;RandomForestClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt;&lt;code&gt;RandomForestRegressor&lt;/code&gt;&lt;/a&gt; classes), each tree in the ensemble is built from a sample drawn with replacement (i.e., a bootstrap sample) from the training set. In addition, when splitting a node during the construction of the tree, the split that is chosen is no longer the best split among all features. Instead, the split that is picked is the best split among a random subset of the features. As a result of this randomness, the bias of the forest usually slightly increases (with respect to the bias of a single non-random tree) but, due to averaging, its variance also decreases, usually more than compensating for the increase in bias, hence yielding an overall better model.</source>
          <target state="translated">En bosques aleatorios (consulte las clases &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt; &lt;code&gt;RandomForestClassifier&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt; &lt;code&gt;RandomForestRegressor&lt;/code&gt; &lt;/a&gt; ), cada &amp;aacute;rbol del conjunto se construye a partir de una muestra extra&amp;iacute;da con reemplazo (es decir, una muestra de arranque) del conjunto de entrenamiento. Adem&amp;aacute;s, al dividir un nodo durante la construcci&amp;oacute;n del &amp;aacute;rbol, la divisi&amp;oacute;n que se elige ya no es la mejor divisi&amp;oacute;n entre todas las caracter&amp;iacute;sticas. En cambio, la divisi&amp;oacute;n que se elige es la mejor divisi&amp;oacute;n entre un subconjunto aleatorio de caracter&amp;iacute;sticas. Como resultado de esta aleatoriedad, el sesgo del bosque generalmente aumenta ligeramente (con respecto al sesgo de un solo &amp;aacute;rbol no aleatorio) pero, debido al promedio, su varianza tambi&amp;eacute;n disminuye, generalmente m&amp;aacute;s que compensando el aumento del sesgo. de ah&amp;iacute; que produzca un modelo mejor en general.</target>
        </trans-unit>
        <trans-unit id="eee63fdeeb00f1867cdf7e3f336a4276e1d12ae2" translate="yes" xml:space="preserve">
          <source>In regression, the expected mean squared error of an estimator can be decomposed in terms of bias, variance and noise. On average over datasets of the regression problem, the bias term measures the average amount by which the predictions of the estimator differ from the predictions of the best possible estimator for the problem (i.e., the Bayes model). The variance term measures the variability of the predictions of the estimator when fit over different instances LS of the problem. Finally, the noise measures the irreducible part of the error which is due the variability in the data.</source>
          <target state="translated">En la regresión,el error cuadrático medio esperado de un estimador puede descomponerse en términos de sesgo,varianza y ruido.En promedio sobre los conjuntos de datos del problema de la regresión,el término de sesgo mide la cantidad promedio en la que las predicciones del estimador difieren de las predicciones del mejor estimador posible para el problema (es decir,el modelo de Bayes).El término de varianza mide la variabilidad de las predicciones del estimador cuando se ajustan sobre diferentes instancias LS del problema.Por último,el ruido mide la parte irreducible del error que se debe a la variabilidad de los datos.</target>
        </trans-unit>
        <trans-unit id="3eae88b0a075df5d4090eee16e911849fedcc7b3" translate="yes" xml:space="preserve">
          <source>In regression, the output remains as \(f(x)\); therefore, output activation function is just the identity function.</source>
          <target state="translated">En la regresión,la salida se mantiene como \(f(x)\);por lo tanto,la función de activación de la salida es sólo la función de identidad.</target>
        </trans-unit>
        <trans-unit id="253be6f032627aec5a3b2c4240659e2190b9fba2" translate="yes" xml:space="preserve">
          <source>In scikit-learn a random split into training and test sets can be quickly computed with the &lt;a href=&quot;generated/sklearn.model_selection.train_test_split#sklearn.model_selection.train_test_split&quot;&gt;&lt;code&gt;train_test_split&lt;/code&gt;&lt;/a&gt; helper function. Let&amp;rsquo;s load the iris data set to fit a linear support vector machine on it:</source>
          <target state="translated">En scikit-learn, una divisi&amp;oacute;n aleatoria en conjuntos de entrenamiento y prueba se puede calcular r&amp;aacute;pidamente con la funci&amp;oacute;n auxiliar &lt;a href=&quot;generated/sklearn.model_selection.train_test_split#sklearn.model_selection.train_test_split&quot;&gt; &lt;code&gt;train_test_split&lt;/code&gt; &lt;/a&gt; . Carguemos el conjunto de datos de iris para ajustarlo a una m&amp;aacute;quina de vectores de soporte lineal:</target>
        </trans-unit>
        <trans-unit id="bdcdb5bf0b220e10633a04e3b3d7b23fb832fcf9" translate="yes" xml:space="preserve">
          <source>In scikit-learn, an estimator for classification is a Python object that implements the methods &lt;code&gt;fit(X, y)&lt;/code&gt; and &lt;code&gt;predict(T)&lt;/code&gt;.</source>
          <target state="translated">En scikit-learn, un estimador para clasificaci&amp;oacute;n es un objeto Python que implementa los m&amp;eacute;todos &lt;code&gt;fit(X, y)&lt;/code&gt; y &lt;code&gt;predict(T)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a15700735758e7e1606b13cd4f276e5fe1e0ef96" translate="yes" xml:space="preserve">
          <source>In scikit-learn, bagging methods are offered as a unified &lt;a href=&quot;generated/sklearn.ensemble.baggingclassifier#sklearn.ensemble.BaggingClassifier&quot;&gt;&lt;code&gt;BaggingClassifier&lt;/code&gt;&lt;/a&gt; meta-estimator (resp. &lt;a href=&quot;generated/sklearn.ensemble.baggingregressor#sklearn.ensemble.BaggingRegressor&quot;&gt;&lt;code&gt;BaggingRegressor&lt;/code&gt;&lt;/a&gt;), taking as input a user-specified base estimator along with parameters specifying the strategy to draw random subsets. In particular, &lt;code&gt;max_samples&lt;/code&gt; and &lt;code&gt;max_features&lt;/code&gt; control the size of the subsets (in terms of samples and features), while &lt;code&gt;bootstrap&lt;/code&gt; and &lt;code&gt;bootstrap_features&lt;/code&gt; control whether samples and features are drawn with or without replacement. When using a subset of the available samples the generalization accuracy can be estimated with the out-of-bag samples by setting &lt;code&gt;oob_score=True&lt;/code&gt;. As an example, the snippet below illustrates how to instantiate a bagging ensemble of &lt;code&gt;KNeighborsClassifier&lt;/code&gt; base estimators, each built on random subsets of 50% of the samples and 50% of the features.</source>
          <target state="translated">En scikit-learn, los m&amp;eacute;todos de ensacado se ofrecen como un &lt;a href=&quot;generated/sklearn.ensemble.baggingclassifier#sklearn.ensemble.BaggingClassifier&quot;&gt; &lt;code&gt;BaggingClassifier&lt;/code&gt; &lt;/a&gt; unificado de BaggingClassifier (resp. &lt;a href=&quot;generated/sklearn.ensemble.baggingregressor#sklearn.ensemble.BaggingRegressor&quot;&gt; &lt;code&gt;BaggingRegressor&lt;/code&gt; &lt;/a&gt; ), tomando como entrada un estimador base especificado por el usuario junto con par&amp;aacute;metros que especifican la estrategia para dibujar subconjuntos aleatorios. En particular, &lt;code&gt;max_samples&lt;/code&gt; y &lt;code&gt;max_features&lt;/code&gt; controlan el tama&amp;ntilde;o de los subconjuntos (en t&amp;eacute;rminos de muestras y caracter&amp;iacute;sticas), mientras que &lt;code&gt;bootstrap&lt;/code&gt; y &lt;code&gt;bootstrap_features&lt;/code&gt; controlan si las muestras y caracter&amp;iacute;sticas se dibujan con o sin reemplazo. Cuando se utiliza un subconjunto de las muestras disponibles, la precisi&amp;oacute;n de la generalizaci&amp;oacute;n se puede estimar con las muestras fuera de la bolsa configurando &lt;code&gt;oob_score=True&lt;/code&gt; . Como ejemplo, el siguiente fragmento ilustra c&amp;oacute;mo crear una instancia de un conjunto de &lt;code&gt;KNeighborsClassifier&lt;/code&gt; estimadores base de KNeighborsClassifier , cada uno construido sobre subconjuntos aleatorios del 50% de las muestras y el 50% de las caracter&amp;iacute;sticas.</target>
        </trans-unit>
        <trans-unit id="0848ab34fddbc88dcbfdd395d0519986e8d182eb" translate="yes" xml:space="preserve">
          <source>In scikit-learn, this transformation (with a user-defined shrinkage coefficient) can be directly applied to a pre-computed covariance with the &lt;a href=&quot;generated/sklearn.covariance.shrunk_covariance#sklearn.covariance.shrunk_covariance&quot;&gt;&lt;code&gt;shrunk_covariance&lt;/code&gt;&lt;/a&gt; method. Also, a shrunk estimator of the covariance can be fitted to data with a &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance&quot;&gt;&lt;code&gt;ShrunkCovariance&lt;/code&gt;&lt;/a&gt; object and its &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance.fit&quot;&gt;&lt;code&gt;ShrunkCovariance.fit&lt;/code&gt;&lt;/a&gt; method. Again, results depend on whether the data are centered, so one may want to use the &lt;code&gt;assume_centered&lt;/code&gt; parameter accurately.</source>
          <target state="translated">En scikit-learn, esta transformaci&amp;oacute;n (con un coeficiente de contracci&amp;oacute;n definido por el usuario) se puede aplicar directamente a una covarianza &lt;a href=&quot;generated/sklearn.covariance.shrunk_covariance#sklearn.covariance.shrunk_covariance&quot;&gt; &lt;code&gt;shrunk_covariance&lt;/code&gt; &lt;/a&gt; con el m&amp;eacute;todo shrunk_covariance . Adem&amp;aacute;s, un estimador reducido de la covarianza se puede &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance&quot;&gt; &lt;code&gt;ShrunkCovariance&lt;/code&gt; &lt;/a&gt; a los datos con un objeto ShrunkCovariance y su m&amp;eacute;todo &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance.fit&quot;&gt; &lt;code&gt;ShrunkCovariance.fit&lt;/code&gt; &lt;/a&gt; . Nuevamente, los resultados dependen de si los datos est&amp;aacute;n centrados, por lo que es posible que desee utilizar el par&amp;aacute;metro &lt;code&gt;assume_centered&lt;/code&gt; precisi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="77c9e3634b9d256acc307751b68c900b0b833a29" translate="yes" xml:space="preserve">
          <source>In single precision, &lt;code&gt;mean&lt;/code&gt; can be inaccurate:</source>
          <target state="translated">En precisi&amp;oacute;n simple, la &lt;code&gt;mean&lt;/code&gt; puede ser inexacta:</target>
        </trans-unit>
        <trans-unit id="640c5c337251b299605fe0c1704cd43d50fcda84" translate="yes" xml:space="preserve">
          <source>In some cases it&amp;rsquo;s not necessary to include higher powers of any single feature, but only the so-called &lt;em&gt;interaction features&lt;/em&gt; that multiply together at most \(d\) distinct features. These can be gotten from &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt;&lt;code&gt;PolynomialFeatures&lt;/code&gt;&lt;/a&gt; with the setting &lt;code&gt;interaction_only=True&lt;/code&gt;.</source>
          <target state="translated">En algunos casos, no es necesario incluir potencias superiores de ninguna caracter&amp;iacute;stica &amp;uacute;nica, sino solo las llamadas &lt;em&gt;caracter&amp;iacute;sticas de interacci&amp;oacute;n&lt;/em&gt; que se multiplican juntas como m&amp;aacute;ximo \ (d \) caracter&amp;iacute;sticas distintas. Estos pueden obtenerse de &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt; &lt;code&gt;PolynomialFeatures&lt;/code&gt; &lt;/a&gt; con la configuraci&amp;oacute;n &lt;code&gt;interaction_only=True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4976a8ab8df4ced9a6ceb9c8368b484dbc953550" translate="yes" xml:space="preserve">
          <source>In some cases, only interaction terms among features are required, and it can be gotten with the setting &lt;code&gt;interaction_only=True&lt;/code&gt;:</source>
          <target state="translated">En algunos casos, solo se requieren t&amp;eacute;rminos de interacci&amp;oacute;n entre caracter&amp;iacute;sticas, y se puede obtener con la configuraci&amp;oacute;n &lt;code&gt;interaction_only=True&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="fc4d9d9d36cc2fd0e96fb6fded728410f07d4165" translate="yes" xml:space="preserve">
          <source>In some specific cases (when the code that is run in parallel releases the GIL), scikit-learn will indicate to &lt;code&gt;joblib&lt;/code&gt; that a multi-threading backend is preferable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b40a5cc0ca592bd5c1306138f251a81fe534579" translate="yes" xml:space="preserve">
          <source>In spite of their apparently over-simplified assumptions, naive Bayes classifiers have worked quite well in many real-world situations, famously document classification and spam filtering. They require a small amount of training data to estimate the necessary parameters. (For theoretical reasons why naive Bayes works well, and on which types of data it does, see the references below.)</source>
          <target state="translated">A pesar de sus supuestos aparentemente demasiado simplificados,los ingenuos clasificadores Bayes han funcionado bastante bien en muchas situaciones del mundo real,como la famosa clasificación de documentos y el filtrado de spam.Requieren una pequeña cantidad de datos de entrenamiento para estimar los parámetros necesarios.(Por razones teóricas,por qué los ingenuos Bayes funcionan bien,y sobre qué tipos de datos lo hacen,véanse las referencias que figuran a continuación).</target>
        </trans-unit>
        <trans-unit id="389828ed3005eb646a2fbe827835555cbdc74437" translate="yes" xml:space="preserve">
          <source>In terms of accuracy, LOO often results in high variance as an estimator for the test error. Intuitively, since \(n - 1\) of the \(n\) samples are used to build each model, models constructed from folds are virtually identical to each other and to the model built from the entire training set.</source>
          <target state="translated">En términos de precisión,LOO a menudo resulta en una alta varianza como estimador del error de la prueba.Intuitivamente,ya que \ ~ n-1\ ~ de las muestras se utilizan para construir cada modelo,los modelos construidos a partir de los pliegues son prácticamente idénticos entre sí y con el modelo construido a partir de todo el conjunto de la formación.</target>
        </trans-unit>
        <trans-unit id="36132aafc76511f4279f2a1765dcbaeb9d7a44b1" translate="yes" xml:space="preserve">
          <source>In terms of time and space complexity, Theil-Sen scales according to</source>
          <target state="translated">En términos de complejidad temporal y espacial,Theil-Sen escala según</target>
        </trans-unit>
        <trans-unit id="8cac8320893acecd46013a1cd740f5237cabb213" translate="yes" xml:space="preserve">
          <source>In that case, the model with 2 components and full covariance (which corresponds to the true generative model) is selected.</source>
          <target state="translated">En ese caso,se selecciona el modelo con 2 componentes y covarianza completa (que corresponde al verdadero modelo generativo).</target>
        </trans-unit>
        <trans-unit id="56b0989d4ac400367ce631898b8b32a7aa114deb" translate="yes" xml:space="preserve">
          <source>In that way, we emphasize that the greater the variance of a feature, the larger the weight of the corresponding coefficient on the output, all else being equal.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df23be83a828beae97b01644c9cebfd6ec568f81" translate="yes" xml:space="preserve">
          <source>In the &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt;&lt;code&gt;TfidfTransformer&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt;&lt;code&gt;TfidfVectorizer&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;smooth_idf=False&lt;/code&gt;, the &amp;ldquo;1&amp;rdquo; count is added to the idf instead of the idf&amp;rsquo;s denominator:</source>
          <target state="translated">En &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt; &lt;code&gt;TfidfTransformer&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt; &lt;code&gt;TfidfVectorizer&lt;/code&gt; &lt;/a&gt; con &lt;code&gt;smooth_idf=False&lt;/code&gt; , el recuento &quot;1&quot; se agrega al idf en lugar del denominador del idf:</target>
        </trans-unit>
        <trans-unit id="5bd53e1aa867b99daf4cb138797f33e24d9cfda1" translate="yes" xml:space="preserve">
          <source>In the &lt;a href=&quot;generated/sklearn.neural_network.bernoullirbm#sklearn.neural_network.BernoulliRBM&quot;&gt;&lt;code&gt;BernoulliRBM&lt;/code&gt;&lt;/a&gt;, all units are binary stochastic units. This means that the input data should either be binary, or real-valued between 0 and 1 signifying the probability that the visible unit would turn on or off. This is a good model for character recognition, where the interest is on which pixels are active and which aren&amp;rsquo;t. For images of natural scenes it no longer fits because of background, depth and the tendency of neighbouring pixels to take the same values.</source>
          <target state="translated">En &lt;a href=&quot;generated/sklearn.neural_network.bernoullirbm#sklearn.neural_network.BernoulliRBM&quot;&gt; &lt;code&gt;BernoulliRBM&lt;/code&gt; &lt;/a&gt; , todas las unidades son unidades estoc&amp;aacute;sticas binarias. Esto significa que los datos de entrada deben ser binarios o tener un valor real entre 0 y 1, lo que significa la probabilidad de que la unidad visible se encienda o apague. Este es un buen modelo para el reconocimiento de caracteres, donde el inter&amp;eacute;s est&amp;aacute; en qu&amp;eacute; p&amp;iacute;xeles est&amp;aacute;n activos y cu&amp;aacute;les no. Para im&amp;aacute;genes de escenas naturales ya no encaja debido al fondo, la profundidad y la tendencia de los p&amp;iacute;xeles vecinos a tomar los mismos valores.</target>
        </trans-unit>
        <trans-unit id="729860dcb0b5963ed7d873f5d8718ecbded39d56" translate="yes" xml:space="preserve">
          <source>In the &lt;code&gt;l1&lt;/code&gt; case, theory says that prediction consistency (i.e. that under given hypothesis, the estimator learned predicts as well as a model knowing the true distribution) is not possible because of the bias of the &lt;code&gt;l1&lt;/code&gt;. It does say, however, that model consistency, in terms of finding the right set of non-zero parameters as well as their signs, can be achieved by scaling &lt;code&gt;C1&lt;/code&gt;.</source>
          <target state="translated">En el caso &lt;code&gt;l1&lt;/code&gt; , la teor&amp;iacute;a dice que la consistencia de la predicci&amp;oacute;n (es decir, que bajo una hip&amp;oacute;tesis dada, el estimador aprendido predice as&amp;iacute; como un modelo que conoce la distribuci&amp;oacute;n verdadera) no es posible debido al sesgo del &lt;code&gt;l1&lt;/code&gt; . Sin embargo, s&amp;iacute; dice que la consistencia del modelo, en t&amp;eacute;rminos de encontrar el conjunto correcto de par&amp;aacute;metros distintos de cero, as&amp;iacute; como sus signos, se puede lograr escalando &lt;code&gt;C1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3ac113ba1d5ea8579f40e00fa885b5d980c4ba43" translate="yes" xml:space="preserve">
          <source>In the &lt;code&gt;l1&lt;/code&gt; penalty case, the cross-validation-error correlates best with the test-error, when scaling our &lt;code&gt;C&lt;/code&gt; with the number of samples, &lt;code&gt;n&lt;/code&gt;, which can be seen in the first figure.</source>
          <target state="translated">En el caso de penalizaci&amp;oacute;n &lt;code&gt;l1&lt;/code&gt; , el error de validaci&amp;oacute;n cruzada se correlaciona mejor con el error de prueba, al escalar nuestra &lt;code&gt;C&lt;/code&gt; con el n&amp;uacute;mero de muestras, &lt;code&gt;n&lt;/code&gt; , que se puede ver en la primera figura.</target>
        </trans-unit>
        <trans-unit id="4495b7082e60ec7cb3a7d3cf1946536697a0e6b3" translate="yes" xml:space="preserve">
          <source>In the above case, the classifier is fit on a 1d array of multiclass labels and the &lt;code&gt;predict()&lt;/code&gt; method therefore provides corresponding multiclass predictions. It is also possible to fit upon a 2d array of binary label indicators:</source>
          <target state="translated">En el caso anterior, el clasificador se ajusta a una matriz 1d de etiquetas multiclase y , por lo tanto, el m&amp;eacute;todo &lt;code&gt;predict()&lt;/code&gt; proporciona las predicciones multiclase correspondientes. Tambi&amp;eacute;n es posible encajar en una matriz 2d de indicadores de etiquetas binarias:</target>
        </trans-unit>
        <trans-unit id="41d2181ce120b72b14a943b5e6f5608fe64d404d" translate="yes" xml:space="preserve">
          <source>In the above example, &lt;code&gt;char_wb&lt;/code&gt; analyzer is used, which creates n-grams only from characters inside word boundaries (padded with space on each side). The &lt;code&gt;char&lt;/code&gt; analyzer, alternatively, creates n-grams that span across words:</source>
          <target state="translated">En el ejemplo anterior, se &lt;code&gt;char_wb&lt;/code&gt; analizador char_wb , que crea n-gramas solo a partir de caracteres dentro de los l&amp;iacute;mites de las palabras (rellenados con espacio en cada lado). El &lt;code&gt;char&lt;/code&gt; analizador, en su defecto, crea n-gramas que abarcan palabras:</target>
        </trans-unit>
        <trans-unit id="02dd6b844a6f6c7bb7b63318a0172b18e25d4984" translate="yes" xml:space="preserve">
          <source>In the above example, the &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt; expects a 1D array as input and therefore the columns were specified as a string (&lt;code&gt;'city'&lt;/code&gt;). However, other transformers generally expect 2D data, and in that case you need to specify the column as a list of strings (&lt;code&gt;['city']&lt;/code&gt;).</source>
          <target state="translated">En el ejemplo anterior, &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; espera una matriz 1D como entrada y, por lo tanto, las columnas se especificaron como una cadena ( &lt;code&gt;'city'&lt;/code&gt; ). Sin embargo, otros transformadores generalmente esperan datos 2D y, en ese caso, es necesario especificar la columna como una lista de cadenas ( &lt;code&gt;['city']&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="af32f30ac84780c46ec03071f0807a02a06be37e" translate="yes" xml:space="preserve">
          <source>In the above example, the &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt; expects a 1D array as input and therefore the columns were specified as a string (&lt;code&gt;'title'&lt;/code&gt;). However, &lt;a href=&quot;generated/sklearn.preprocessing.onehotencoder#sklearn.preprocessing.OneHotEncoder&quot;&gt;&lt;code&gt;preprocessing.OneHotEncoder&lt;/code&gt;&lt;/a&gt; as most of other transformers expects 2D data, therefore in that case you need to specify the column as a list of strings (&lt;code&gt;['city']&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8be3ffb93abc4e32a08a3f61b709f6ed3e6124c4" translate="yes" xml:space="preserve">
          <source>In the above example-code, we firstly use the &lt;code&gt;fit(..)&lt;/code&gt; method to fit our estimator to the data and secondly the &lt;code&gt;transform(..)&lt;/code&gt; method to transform our count-matrix to a tf-idf representation. These two steps can be combined to achieve the same end result faster by skipping redundant processing. This is done through using the &lt;code&gt;fit_transform(..)&lt;/code&gt; method as shown below, and as mentioned in the note in the previous section:</source>
          <target state="translated">En el c&amp;oacute;digo de ejemplo anterior, primero usamos el m&amp;eacute;todo &lt;code&gt;fit(..)&lt;/code&gt; para ajustar nuestro estimador a los datos y, en segundo lugar, el m&amp;eacute;todo &lt;code&gt;transform(..)&lt;/code&gt; para transformar nuestra matriz de conteo en una representaci&amp;oacute;n tf-idf. Estos dos pasos se pueden combinar para lograr el mismo resultado final m&amp;aacute;s r&amp;aacute;pidamente omitiendo el procesamiento redundante. Esto se hace usando el &lt;code&gt;fit_transform(..)&lt;/code&gt; como se muestra a continuaci&amp;oacute;n, y como se menciona en la nota en la secci&amp;oacute;n anterior:</target>
        </trans-unit>
        <trans-unit id="370df873906104ebc3c5f7c3ad3752f50f2bb258" translate="yes" xml:space="preserve">
          <source>In the above illustrating figure, we consider some points from a randomly generated dataset. We focus on the stochastic KNN classification of point no. 3. The thickness of a link between sample 3 and another point is proportional to their distance, and can be seen as the relative weight (or probability) that a stochastic nearest neighbor prediction rule would assign to this point. In the original space, sample 3 has many stochastic neighbors from various classes, so the right class is not very likely. However, in the projected space learned by NCA, the only stochastic neighbors with non-negligible weight are from the same class as sample 3, guaranteeing that the latter will be well classified. See the &lt;a href=&quot;#nca-mathematical-formulation&quot;&gt;mathematical formulation&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc1fc9feffcc3ab7062a5968abf403f994be456d" translate="yes" xml:space="preserve">
          <source>In the above process, rejection sampling is used to make sure that n is more than 2, and that the document length is never zero. Likewise, we reject classes which have already been chosen. The documents that are assigned to both classes are plotted surrounded by two colored circles.</source>
          <target state="translated">En el proceso anterior,el muestreo de rechazo se utiliza para asegurarse de que n es más de 2,y que la longitud del documento nunca es cero.De la misma manera,rechazamos las clases que ya han sido elegidas.Los documentos que se asignan a ambas clases se trazan rodeados de dos círculos de color.</target>
        </trans-unit>
        <trans-unit id="35ac86e1f976c024d854c94dc1a07d9250df373b" translate="yes" xml:space="preserve">
          <source>In the above process, rejection sampling is used to make sure that n is never zero or more than &lt;code&gt;n_classes&lt;/code&gt;, and that the document length is never zero. Likewise, we reject classes which have already been chosen.</source>
          <target state="translated">En el proceso anterior, el muestreo de rechazo se utiliza para asegurarse de que n nunca sea cero o m&amp;aacute;s que &lt;code&gt;n_classes&lt;/code&gt; , y que la longitud del documento nunca sea cero. Asimismo, rechazamos las clases que ya han sido elegidas.</target>
        </trans-unit>
        <trans-unit id="35b3eed71c5956697e4e941c9abda7fa7875d908" translate="yes" xml:space="preserve">
          <source>In the binary (two-class) case, \(tp\), \(tn\), \(fp\) and \(fn\) are respectively the number of true positives, true negatives, false positives and false negatives, the MCC is defined as</source>
          <target state="translated">En el caso binario (de dos clases),\ ~ \ ~-tp,\ ~-tn,\ ~ y \ ~-fn son,respectivamente,el número de verdaderos positivos,\ ~ verdaderos negativos,falsos positivos y falsos negativos,la MCC se define como</target>
        </trans-unit>
        <trans-unit id="8cf754386b9e93bff61012cc7eebd891fe098125" translate="yes" xml:space="preserve">
          <source>In the binary case, balanced accuracy is equal to the arithmetic mean of &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;sensitivity&lt;/a&gt; (true positive rate) and &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;specificity&lt;/a&gt; (true negative rate), or the area under the ROC curve with binary predictions rather than scores.</source>
          <target state="translated">En el caso binario, la precisi&amp;oacute;n equilibrada es igual a la media aritm&amp;eacute;tica de la &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;sensibilidad&lt;/a&gt; (tasa positiva verdadera) y la &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;especificidad&lt;/a&gt; (tasa negativa verdadera), o el &amp;aacute;rea bajo la curva ROC con predicciones binarias en lugar de puntuaciones.</target>
        </trans-unit>
        <trans-unit id="43cd3b6bd763c03854427d73b603fdca48b2b30e" translate="yes" xml:space="preserve">
          <source>In the binary case, balanced accuracy is equal to the arithmetic mean of &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;sensitivity&lt;/a&gt; (true positive rate) and &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;specificity&lt;/a&gt; (true negative rate), or the area under the ROC curve with binary predictions rather than scores:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a998ef5238ae7921fe9486295ae64f00deab3566" translate="yes" xml:space="preserve">
          <source>In the binary case, we can extract true positives, etc as follows:</source>
          <target state="translated">En el caso binario,podemos extraer los verdaderos positivos,etc.,de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="3e94daaa4e8fed019552e1789dc3caf5c267c82f" translate="yes" xml:space="preserve">
          <source>In the binary case:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="193e8f9e646cb769a122ba34f156f35dc1f6d79e" translate="yes" xml:space="preserve">
          <source>In the case of &amp;ldquo;one-vs-one&amp;rdquo; &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt;&lt;code&gt;NuSVC&lt;/code&gt;&lt;/a&gt;, the layout of the attributes is a little more involved. In the case of a linear kernel, the attributes &lt;code&gt;coef_&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; have the shape &lt;code&gt;(n_classes * (n_classes - 1) / 2, n_features)&lt;/code&gt; and &lt;code&gt;(n_classes *
(n_classes - 1) / 2)&lt;/code&gt; respectively. This is similar to the layout for &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; described above, with each row now corresponding to a binary classifier. The order for classes 0 to n is &amp;ldquo;0 vs 1&amp;rdquo;, &amp;ldquo;0 vs 2&amp;rdquo; , &amp;hellip; &amp;ldquo;0 vs n&amp;rdquo;, &amp;ldquo;1 vs 2&amp;rdquo;, &amp;ldquo;1 vs 3&amp;rdquo;, &amp;ldquo;1 vs n&amp;rdquo;, . . . &amp;ldquo;n-1 vs n&amp;rdquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2482e7f51309cef70ec85538824011f95f0813b1" translate="yes" xml:space="preserve">
          <source>In the case of &amp;ldquo;one-vs-one&amp;rdquo; &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt;, the layout of the attributes is a little more involved. In the case of having a linear kernel, the attributes &lt;code&gt;coef_&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; have the shape &lt;code&gt;[n_class * (n_class - 1) / 2, n_features]&lt;/code&gt; and &lt;code&gt;[n_class * (n_class - 1) / 2]&lt;/code&gt; respectively. This is similar to the layout for &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; described above, with each row now corresponding to a binary classifier. The order for classes 0 to n is &amp;ldquo;0 vs 1&amp;rdquo;, &amp;ldquo;0 vs 2&amp;rdquo; , &amp;hellip; &amp;ldquo;0 vs n&amp;rdquo;, &amp;ldquo;1 vs 2&amp;rdquo;, &amp;ldquo;1 vs 3&amp;rdquo;, &amp;ldquo;1 vs n&amp;rdquo;, . . . &amp;ldquo;n-1 vs n&amp;rdquo;.</source>
          <target state="translated">En el caso de &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt; &quot;uno contra uno&quot; , el dise&amp;ntilde;o de los atributos es un poco m&amp;aacute;s complicado. En el caso de tener un kernel lineal, los atributos &lt;code&gt;coef_&lt;/code&gt; e &lt;code&gt;intercept_&lt;/code&gt; tienen la forma &lt;code&gt;[n_class * (n_class - 1) / 2, n_features]&lt;/code&gt; y &lt;code&gt;[n_class * (n_class - 1) / 2]&lt;/code&gt; respectivamente. Esto es similar al dise&amp;ntilde;o de &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt; descrito anteriormente, con cada fila ahora correspondiente a un clasificador binario. El orden de las clases 0 an es &quot;0 vs 1&quot;, &quot;0 vs 2&quot;, ... &quot;0 vs n&quot;, &quot;1 vs 2&quot;, &quot;1 vs 3&quot;, &quot;1 vs n&quot;,. . . &quot;N-1 frente a n&quot;.</target>
        </trans-unit>
        <trans-unit id="7befa9fe69dc29e17ce8c14ce1f24dcd596f25dc" translate="yes" xml:space="preserve">
          <source>In the case of Gaussian process classification, &amp;ldquo;one_vs_one&amp;rdquo; might be computationally cheaper since it has to solve many problems involving only a subset of the whole training set rather than fewer problems on the whole dataset. Since Gaussian process classification scales cubically with the size of the dataset, this might be considerably faster. However, note that &amp;ldquo;one_vs_one&amp;rdquo; does not support predicting probability estimates but only plain predictions. Moreover, note that &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessclassifier#sklearn.gaussian_process.GaussianProcessClassifier&quot;&gt;&lt;code&gt;GaussianProcessClassifier&lt;/code&gt;&lt;/a&gt; does not (yet) implement a true multi-class Laplace approximation internally, but as discussed above is based on solving several binary classification tasks internally, which are combined using one-versus-rest or one-versus-one.</source>
          <target state="translated">En el caso de la clasificaci&amp;oacute;n de procesos gaussianos, &quot;one_vs_one&quot; podr&amp;iacute;a ser computacionalmente m&amp;aacute;s econ&amp;oacute;mico, ya que tiene que resolver muchos problemas que involucran solo un subconjunto de todo el conjunto de entrenamiento en lugar de menos problemas en todo el conjunto de datos. Dado que la clasificaci&amp;oacute;n del proceso gaussiano se escala c&amp;uacute;bicamente con el tama&amp;ntilde;o del conjunto de datos, esto podr&amp;iacute;a ser considerablemente m&amp;aacute;s r&amp;aacute;pido. Sin embargo, tenga en cuenta que &quot;one_vs_one&quot; no admite la predicci&amp;oacute;n de estimaciones de probabilidad, sino solo predicciones simples. Adem&amp;aacute;s, tenga en cuenta que &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessclassifier#sklearn.gaussian_process.GaussianProcessClassifier&quot;&gt; &lt;code&gt;GaussianProcessClassifier&lt;/code&gt; &lt;/a&gt; no implementa (todav&amp;iacute;a) una verdadera aproximaci&amp;oacute;n de Laplace de m&amp;uacute;ltiples clases internamente, pero como se discuti&amp;oacute; anteriormente se basa en resolver varias tareas de clasificaci&amp;oacute;n binaria internamente, que se combinan usando uno contra resto o uno contra uno.</target>
        </trans-unit>
        <trans-unit id="35a5ada3d16c18d2778299b423e5960182d45740" translate="yes" xml:space="preserve">
          <source>In the case of LDA, the Gaussians for each class are assumed to share the same covariance matrix: \(\Sigma_k = \Sigma\) for all \(k\). This leads to linear decision surfaces, which can be seen by comparing the log-probability ratios \(\log[P(y=k | X) / P(y=l | X)]\):</source>
          <target state="translated">En el caso de la LDA,se supone que los gausianos de cada clase comparten la misma matriz de covarianza:\N-Sigma_k=\N-Sigma para todos.Esto conduce a superficies de decisión lineales,que pueden verse comparando los ratios de probabilidad logarítmica \N \N ;logarítmica[P(y=k | X)/P(y=l | X)]\N):</target>
        </trans-unit>
        <trans-unit id="9191afe7181654f4c123a5274615786e30f48b2b" translate="yes" xml:space="preserve">
          <source>In the case of QDA, there are no assumptions on the covariance matrices \(\Sigma_k\) of the Gaussians, leading to quadratic decision surfaces. See &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[3]&lt;/a&gt; for more details.</source>
          <target state="translated">En el caso de QDA, no hay supuestos sobre las matrices de covarianza \ (\ Sigma_k \) de los gaussianos, lo que conduce a superficies de decisi&amp;oacute;n cuadr&amp;aacute;ticas. Consulte &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[3]&lt;/a&gt; para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="be50ffb98df62eb79c354d934aa76c5587bf8cba" translate="yes" xml:space="preserve">
          <source>In the case of multi-class classification &lt;code&gt;coef_&lt;/code&gt; is a two-dimensional array of &lt;code&gt;shape=[n_classes, n_features]&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; is a one-dimensional array of &lt;code&gt;shape=[n_classes]&lt;/code&gt;. The i-th row of &lt;code&gt;coef_&lt;/code&gt; holds the weight vector of the OVA classifier for the i-th class; classes are indexed in ascending order (see attribute &lt;code&gt;classes_&lt;/code&gt;). Note that, in principle, since they allow to create a probability model, &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; and &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; are more suitable for one-vs-all classification.</source>
          <target state="translated">En el caso de la clasificaci&amp;oacute;n de clases m&amp;uacute;ltiples, &lt;code&gt;coef_&lt;/code&gt; es una matriz bidimensional de &lt;code&gt;shape=[n_classes, n_features]&lt;/code&gt; e &lt;code&gt;intercept_&lt;/code&gt; es una matriz unidimensional de &lt;code&gt;shape=[n_classes]&lt;/code&gt; . La i-&amp;eacute;sima fila de &lt;code&gt;coef_&lt;/code&gt; contiene el vector de peso del clasificador OVA para la i-&amp;eacute;sima clase; las clases est&amp;aacute;n indexadas en orden ascendente (ver atributo &lt;code&gt;classes_&lt;/code&gt; ). Tenga en cuenta que, en principio, dado que permiten crear un modelo de probabilidad, &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; y &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; son m&amp;aacute;s adecuados para la clasificaci&amp;oacute;n de uno contra todos.</target>
        </trans-unit>
        <trans-unit id="a5109fe6449c3757593d6d14759e9857d15d95c4" translate="yes" xml:space="preserve">
          <source>In the case of multi-class classification &lt;code&gt;coef_&lt;/code&gt; is a two-dimensional array of shape (n_classes, n_features) and &lt;code&gt;intercept_&lt;/code&gt; is a one-dimensional array of shape (n_classes,). The i-th row of &lt;code&gt;coef_&lt;/code&gt; holds the weight vector of the OVA classifier for the i-th class; classes are indexed in ascending order (see attribute &lt;code&gt;classes_&lt;/code&gt;). Note that, in principle, since they allow to create a probability model, &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; and &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; are more suitable for one-vs-all classification.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1959581346965192dc91c946ef9926bceb1c51a" translate="yes" xml:space="preserve">
          <source>In the case of multi-class classification, the mean log-marginal likelihood of the one-versus-rest classifiers are returned.</source>
          <target state="translated">En el caso de la clasificación multiclase,se devuelve la media de la probabilidad logarítmica marginal de los clasificadores de uno contra uno.</target>
        </trans-unit>
        <trans-unit id="a45d03e82085c1e194b2b19d0700767439a7ac42" translate="yes" xml:space="preserve">
          <source>In the case of one-hot/one-of-K coding, the constructed feature names and values are returned rather than the original ones.</source>
          <target state="translated">En el caso de la codificación &quot;uno-de-uno-de-K&quot;,se devuelven los nombres y valores de las características construidas en lugar de los originales.</target>
        </trans-unit>
        <trans-unit id="108b9e0576d5a78538771fb415a46ae76d1a6e26" translate="yes" xml:space="preserve">
          <source>In the case of text classification, word occurrence vectors (rather than word count vectors) may be used to train and use this classifier. &lt;code&gt;BernoulliNB&lt;/code&gt; might perform better on some datasets, especially those with shorter documents. It is advisable to evaluate both models, if time permits.</source>
          <target state="translated">En el caso de la clasificaci&amp;oacute;n de texto, se pueden usar vectores de ocurrencia de palabras (en lugar de vectores de conteo de palabras) para entrenar y usar este clasificador. &lt;code&gt;BernoulliNB&lt;/code&gt; podr&amp;iacute;a funcionar mejor en algunos conjuntos de datos, especialmente aquellos con documentos m&amp;aacute;s cortos. Es recomendable evaluar ambos modelos, si el tiempo lo permite.</target>
        </trans-unit>
        <trans-unit id="1ee37ddaa2e2b7fb0103fdddd162d9ad76a8f2dd" translate="yes" xml:space="preserve">
          <source>In the case of the digits dataset, the task is to predict, given an image, which digit it represents. We are given samples of each of the 10 possible classes (the digits zero through nine) on which we &lt;em&gt;fit&lt;/em&gt; an &lt;a href=&quot;https://en.wikipedia.org/wiki/Estimator&quot;&gt;estimator&lt;/a&gt; to be able to &lt;em&gt;predict&lt;/em&gt; the classes to which unseen samples belong.</source>
          <target state="translated">En el caso del conjunto de datos de d&amp;iacute;gitos, la tarea es predecir, dada una imagen, qu&amp;eacute; d&amp;iacute;gito representa. Se nos dan muestras de cada una de las 10 clases posibles (los d&amp;iacute;gitos del cero al nueve) en las que &lt;em&gt;ajustamos&lt;/em&gt; un &lt;a href=&quot;https://en.wikipedia.org/wiki/Estimator&quot;&gt;estimador&lt;/a&gt; para poder &lt;em&gt;predecir&lt;/em&gt; las clases a las que pertenecen las muestras invisibles.</target>
        </trans-unit>
        <trans-unit id="0484e6facaecfeba6a4ff8e0552fa9a5ac1c52dd" translate="yes" xml:space="preserve">
          <source>In the case that one or more classes are absent in a training portion, a default score needs to be assigned to all instances for that class if &lt;code&gt;method&lt;/code&gt; produces columns per class, as in {&amp;lsquo;decision_function&amp;rsquo;, &amp;lsquo;predict_proba&amp;rsquo;, &amp;lsquo;predict_log_proba&amp;rsquo;}. For &lt;code&gt;predict_proba&lt;/code&gt; this value is 0. In order to ensure finite output, we approximate negative infinity by the minimum finite float value for the dtype in other cases.</source>
          <target state="translated">En el caso de que una o m&amp;aacute;s clases est&amp;eacute;n ausentes en una parte de entrenamiento, se debe asignar una puntuaci&amp;oacute;n predeterminada a todas las instancias de esa clase si el &lt;code&gt;method&lt;/code&gt; produce columnas por clase, como en {'decision_function', 'predict_proba', 'predict_log_proba'} . Para &lt;code&gt;predict_proba&lt;/code&gt; , este valor es 0. Para asegurar una salida finita, aproximamos el infinito negativo por el valor flotante finito m&amp;iacute;nimo para el tipo d en otros casos.</target>
        </trans-unit>
        <trans-unit id="74ff5bfdda6b3e93f59169f7c22fc2d68fa3fcf3" translate="yes" xml:space="preserve">
          <source>In the case when the binary labels are fractional (probabilistic), inverse_transform chooses the class with the greatest value. Typically, this allows to use the output of a linear model&amp;rsquo;s decision_function method directly as the input of inverse_transform.</source>
          <target state="translated">En el caso de que las etiquetas binarias sean fraccionarias (probabil&amp;iacute;sticas), inverse_transform elige la clase con el mayor valor. Normalmente, esto permite utilizar la salida del m&amp;eacute;todo de funci&amp;oacute;n_decisi&amp;oacute;n de un modelo lineal directamente como entrada de transformaci&amp;oacute;n_inversa.</target>
        </trans-unit>
        <trans-unit id="e087c17fe61957d86c5cc0e9905f0323cd8dea87" translate="yes" xml:space="preserve">
          <source>In the cases of a tie, the &lt;a href=&quot;generated/sklearn.ensemble.votingclassifier#sklearn.ensemble.VotingClassifier&quot;&gt;&lt;code&gt;VotingClassifier&lt;/code&gt;&lt;/a&gt; will select the class based on the ascending sort order. E.g., in the following scenario</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d852af4ac330c07eec96a31a9559a88b3b70655" translate="yes" xml:space="preserve">
          <source>In the cases of a tie, the &lt;code&gt;VotingClassifier&lt;/code&gt; will select the class based on the ascending sort order. E.g., in the following scenario</source>
          <target state="translated">En los casos de empate, el &lt;code&gt;VotingClassifier&lt;/code&gt; seleccionar&amp;aacute; la clase en funci&amp;oacute;n del orden de clasificaci&amp;oacute;n ascendente. Por ejemplo, en el siguiente escenario</target>
        </trans-unit>
        <trans-unit id="84352a0fa93e8d3c09e63ba562819b09bff22e0e" translate="yes" xml:space="preserve">
          <source>In the checkerboard case, each row belongs to all column clusters, and each column belongs to all row clusters. Here is an example of this structure where the variance of the values within each bicluster is small:</source>
          <target state="translated">En el caso del tablero de damas,cada fila pertenece a todos los grupos de columnas,y cada columna pertenece a todos los grupos de filas.He aquí un ejemplo de esta estructura en la que la variación de los valores dentro de cada bíceps es pequeña:</target>
        </trans-unit>
        <trans-unit id="6a06bacf0f95acd504bad8493dc228833ae72576" translate="yes" xml:space="preserve">
          <source>In the event that the 95% confidence interval based on Fisher transform spans zero, a warning is raised.</source>
          <target state="translated">En el caso de que el intervalo de confianza del 95% basado en la transformación de Fisher se extienda hasta el cero,se eleva una advertencia.</target>
        </trans-unit>
        <trans-unit id="2da0fe066fd806cee05903c8f41b8c38bb726d66" translate="yes" xml:space="preserve">
          <source>In the example below, using a small shrink threshold increases the accuracy of the model from 0.81 to 0.82.</source>
          <target state="translated">En el ejemplo que figura a continuación,el uso de un pequeño umbral de contracción aumenta la precisión del modelo de 0,81 a 0,82.</target>
        </trans-unit>
        <trans-unit id="ae3527cc8009043f3459062f8b3ac5f4c7cdc080" translate="yes" xml:space="preserve">
          <source>In the figure below, the color indicates cluster membership, with large circles indicating core samples found by the algorithm. Smaller circles are non-core samples that are still part of a cluster. Moreover, the outliers are indicated by black points below.</source>
          <target state="translated">En la figura siguiente,el color indica la pertenencia al grupo,con grandes círculos que indican las muestras centrales encontradas por el algoritmo.Los círculos más pequeños son muestras no centrales que todavía forman parte de un cúmulo.Además,los valores atípicos se indican con puntos negros abajo.</target>
        </trans-unit>
        <trans-unit id="cfa64cd986932f750b1c68de33ab3971d444bf3d" translate="yes" xml:space="preserve">
          <source>In the first column, first row the learning curve of a naive Bayes classifier is shown for the digits dataset. Note that the training score and the cross-validation score are both not very good at the end. However, the shape of the curve can be found in more complex datasets very often: the training score is very high at the beginning and decreases and the cross-validation score is very low at the beginning and increases. In the second column, first row we see the learning curve of an SVM with RBF kernel. We can see clearly that the training score is still around the maximum and the validation score could be increased with more training samples. The plots in the second row show the times required by the models to train with various sizes of training dataset. The plots in the third row show how much time was required to train the models for each training sizes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbb41405aaf08b233f5d5a9cb37143ee4833765d" translate="yes" xml:space="preserve">
          <source>In the first figure, we visualize the value of the kernel, i.e. the similarity of the sequences, using a colormap. Brighter color here indicates higher similarity.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a915ebedbc9fc712ae336eb7409727fc370425dc" translate="yes" xml:space="preserve">
          <source>In the first row, the classifiers are built using the sepal width and the sepal length features only, on the second row using the petal length and sepal length only, and on the third row using the petal width and the petal length only.</source>
          <target state="translated">En la primera fila,los clasificadores se construyen utilizando únicamente la anchura y la longitud del sépalo,en la segunda fila se utiliza la longitud del pétalo y la longitud del sépalo solamente,y en la tercera fila se utiliza la anchura y la longitud del pétalo solamente.</target>
        </trans-unit>
        <trans-unit id="974efdfc7b27c9e04d6e731c42ba40fb3d593ff5" translate="yes" xml:space="preserve">
          <source>In the following example, we construct a NearestNeighbors class from an array representing our data set and ask who&amp;rsquo;s the closest point to [1,1,1]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd9366b471cf174a5dc26260b1ee3e4775bd8a95" translate="yes" xml:space="preserve">
          <source>In the following example, we construct a NeighborsClassifier class from an array representing our data set and ask who&amp;rsquo;s the closest point to [1, 1, 1]:</source>
          <target state="translated">En el siguiente ejemplo, construimos una clase NeighborsClassifier a partir de una matriz que representa nuestro conjunto de datos y preguntamos qui&amp;eacute;n es el punto m&amp;aacute;s cercano a [1, 1, 1]:</target>
        </trans-unit>
        <trans-unit id="f873541d5e32ccd97b454877a7265b9e862eeb9a" translate="yes" xml:space="preserve">
          <source>In the following example, we construct a NeighborsClassifier class from an array representing our data set and ask who&amp;rsquo;s the closest point to [1,1,1]</source>
          <target state="translated">En el siguiente ejemplo, construimos una clase NeighborsClassifier a partir de una matriz que representa nuestro conjunto de datos y preguntamos qui&amp;eacute;n es el punto m&amp;aacute;s cercano a [1,1,1]</target>
        </trans-unit>
        <trans-unit id="65f9f2f58e8b0fd298381aa88835a40b1607c17f" translate="yes" xml:space="preserve">
          <source>In the following figure, 100 points are drawn from a bimodal distribution, and the kernel density estimates are shown for three choices of kernels:</source>
          <target state="translated">En la siguiente figura,se extraen 100 puntos de una distribución bimodal,y se muestran las estimaciones de densidad de los núcleos para tres opciones de núcleos:</target>
        </trans-unit>
        <trans-unit id="a08df9eebc31ca3edc4756b37a4fdadef1454fe3" translate="yes" xml:space="preserve">
          <source>In the following plot, the maximum effective alpha value is removed, because it is the trivial tree with only one node.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24263a7351535bc4435386a661d4637b721eb5a0" translate="yes" xml:space="preserve">
          <source>In the following plot, we see a function \(f(x) = \cos (\frac{3}{2} \pi x)\) and some noisy samples from that function. We use three different estimators to fit the function: linear regression with polynomial features of degree 1, 4 and 15. We see that the first estimator can at best provide only a poor fit to the samples and the true function because it is too simple (high bias), the second estimator approximates it almost perfectly and the last estimator approximates the training data perfectly but does not fit the true function very well, i.e. it is very sensitive to varying training data (high variance).</source>
          <target state="translated">En la siguiente gráfica,vemos una función \N \N \N-f(x)=\N -cos (\N -fraccio{3}{2}\N -pi x)\N y algunas muestras ruidosas de esa función.Utilizamos tres estimadores diferentes para ajustar la función:regresión lineal con características polinómicas de grado 1,4 y 15.Vemos que el primer estimador puede,en el mejor de los casos,proporcionar sólo un mal ajuste a las muestras y a la función verdadera porque es demasiado simple (alto sesgo),el segundo estimador la aproxima casi perfectamente y el último estimador aproxima los datos de entrenamiento perfectamente pero no se ajusta muy bien a la función verdadera,es decir,es muy sensible a la variación de los datos de entrenamiento (alta varianza).</target>
        </trans-unit>
        <trans-unit id="605a0ccca31d97f6c29fd62c728a36908756654e" translate="yes" xml:space="preserve">
          <source>In the following section, we will interpret the coefficients of the model. While we do so, we should keep in mind that any conclusion we draw is about the model that we build, rather than about the true (real-world) generative process of the data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de54ef0bf525631d31eb0623dcd55f8a9ddc120b" translate="yes" xml:space="preserve">
          <source>In the following sub-sections, we will describe each of those functions, preceded by some notes on common API and metric definition.</source>
          <target state="translated">En las siguientes subsecciones,describiremos cada una de esas funciones,precedidas de algunas notas sobre la API común y la definición de la métrica.</target>
        </trans-unit>
        <trans-unit id="7549668dfe247eb9e0e172cc89f620a63604992b" translate="yes" xml:space="preserve">
          <source>In the following we will use the built-in dataset loader for 20 newsgroups from scikit-learn. Alternatively, it is possible to download the dataset manually from the website and use the &lt;a href=&quot;../../modules/generated/sklearn.datasets.load_files#sklearn.datasets.load_files&quot;&gt;&lt;code&gt;sklearn.datasets.load_files&lt;/code&gt;&lt;/a&gt; function by pointing it to the &lt;code&gt;20news-bydate-train&lt;/code&gt; sub-folder of the uncompressed archive folder.</source>
          <target state="translated">A continuaci&amp;oacute;n, utilizaremos el cargador de conjuntos de datos integrado para 20 grupos de noticias de scikit-learn. Alternativamente, es posible descargar el conjunto de datos manualmente desde el sitio web y usar la funci&amp;oacute;n &lt;a href=&quot;../../modules/generated/sklearn.datasets.load_files#sklearn.datasets.load_files&quot;&gt; &lt;code&gt;sklearn.datasets.load_files&lt;/code&gt; &lt;/a&gt; apunt&amp;aacute;ndolo a la &lt;code&gt;20news-bydate-train&lt;/code&gt; de la carpeta de archivo sin comprimir.</target>
        </trans-unit>
        <trans-unit id="2cb0b9817ecf09ea4893bb9df9d328ce75ef2d1b" translate="yes" xml:space="preserve">
          <source>In the following, &amp;ldquo;city&amp;rdquo; is a categorical attribute while &amp;ldquo;temperature&amp;rdquo; is a traditional numerical feature:</source>
          <target state="translated">A continuaci&amp;oacute;n, &quot;ciudad&quot; es un atributo categ&amp;oacute;rico, mientras que &quot;temperatura&quot; es una caracter&amp;iacute;stica num&amp;eacute;rica tradicional:</target>
        </trans-unit>
        <trans-unit id="3e019b4cbe3ce7f1554fa08ce08898c560cb8a3b" translate="yes" xml:space="preserve">
          <source>In the following, we start a Python interpreter from our shell and then load the &lt;code&gt;iris&lt;/code&gt; and &lt;code&gt;digits&lt;/code&gt; datasets. Our notational convention is that &lt;code&gt;$&lt;/code&gt; denotes the shell prompt while &lt;code&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; denotes the Python interpreter prompt:</source>
          <target state="translated">A continuaci&amp;oacute;n, iniciamos un int&amp;eacute;rprete de Python desde nuestro shell y luego cargamos los conjuntos de datos de &lt;code&gt;iris&lt;/code&gt; y &lt;code&gt;digits&lt;/code&gt; . Nuestra convenci&amp;oacute;n de notaci&amp;oacute;n es que &lt;code&gt;$&lt;/code&gt; denota el indicador del shell mientras que &lt;code&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; denota el indicador del int&amp;eacute;rprete de Python:</target>
        </trans-unit>
        <trans-unit id="fe30ab8cfcc104ee94b5fb01793274570a377034" translate="yes" xml:space="preserve">
          <source>In the formula above, \(\mathbf{b}\) and \(\mathbf{c}\) are the intercept vectors for the visible and hidden layers, respectively. The joint probability of the model is defined in terms of the energy:</source>
          <target state="translated">En la fórmula anterior,\N \N los vectores de intercepción de las capas visibles y las ocultas,respectivamente.La probabilidad conjunta del modelo se define en términos de la energía:</target>
        </trans-unit>
        <trans-unit id="e448c91ec6db1584eec64770c66e9fad7266b47b" translate="yes" xml:space="preserve">
          <source>In the graphical model, each node is a random variable and has a role in the generative process. A shaded node indicates an observed variable and an unshaded node indicates a hidden (latent) variable. In this case, words in the corpus are the only data that we observe. The latent variables determine the random mixture of topics in the corpus and the distribution of words in the documents. The goal of LDA is to use the observed words to infer the hidden topic structure.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66070e8da21856ec34fc0b507e5d723e9475a567" translate="yes" xml:space="preserve">
          <source>In the multi-class and multi-label case, this is the average of the F1 score of each class with weighting depending on the &lt;code&gt;average&lt;/code&gt; parameter.</source>
          <target state="translated">En el caso de m&amp;uacute;ltiples clases y m&amp;uacute;ltiples etiquetas, este es el promedio de la puntuaci&amp;oacute;n F1 de cada clase con una ponderaci&amp;oacute;n que depende del par&amp;aacute;metro &lt;code&gt;average&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="47604d7ff8f733fb868ecbca5a77b859a57fe5aa" translate="yes" xml:space="preserve">
          <source>In the multiclass case, the Matthews correlation coefficient can be &lt;a href=&quot;http://rk.kvl.dk/introduction/index.html&quot;&gt;defined&lt;/a&gt; in terms of a &lt;a href=&quot;generated/sklearn.metrics.confusion_matrix#sklearn.metrics.confusion_matrix&quot;&gt;&lt;code&gt;confusion_matrix&lt;/code&gt;&lt;/a&gt;\(C\) for \(K\) classes. To simplify the definition consider the following intermediate variables:</source>
          <target state="translated">En el caso multiclase, el coeficiente de correlaci&amp;oacute;n de Matthews se puede &lt;a href=&quot;http://rk.kvl.dk/introduction/index.html&quot;&gt;definir&lt;/a&gt; en t&amp;eacute;rminos de una &lt;a href=&quot;generated/sklearn.metrics.confusion_matrix#sklearn.metrics.confusion_matrix&quot;&gt; &lt;code&gt;confusion_matrix&lt;/code&gt; &lt;/a&gt; \ (C \) para clases \ (K \). Para simplificar la definici&amp;oacute;n, considere las siguientes variables intermedias:</target>
        </trans-unit>
        <trans-unit id="b8d01a57cb617acafda7dfb6fdd570d7cb46be7c" translate="yes" xml:space="preserve">
          <source>In the multiclass case, the training algorithm uses the one-vs-rest (OvR) scheme if the &amp;lsquo;multi_class&amp;rsquo; option is set to &amp;lsquo;ovr&amp;rsquo;, and uses the cross- entropy loss if the &amp;lsquo;multi_class&amp;rsquo; option is set to &amp;lsquo;multinomial&amp;rsquo;. (Currently the &amp;lsquo;multinomial&amp;rsquo; option is supported only by the &amp;lsquo;lbfgs&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;newton-cg&amp;rsquo; solvers.)</source>
          <target state="translated">En el caso de multiclase, el algoritmo de entrenamiento usa el esquema one-vs-rest (OvR) si la opci&amp;oacute;n 'multi_class' est&amp;aacute; configurada como 'ovr', y usa la p&amp;eacute;rdida de entrop&amp;iacute;a cruzada si la opci&amp;oacute;n 'multi_class' est&amp;aacute; configurada como 'multinomial '. (Actualmente, la opci&amp;oacute;n 'multinomial' solo es compatible con los solucionadores 'lbfgs', 'sag' y 'newton-cg').</target>
        </trans-unit>
        <trans-unit id="df1f72c5b54cf7ce11968ba990ade83d8b80475a" translate="yes" xml:space="preserve">
          <source>In the multiclass case, the training algorithm uses the one-vs-rest (OvR) scheme if the &amp;lsquo;multi_class&amp;rsquo; option is set to &amp;lsquo;ovr&amp;rsquo;, and uses the cross-entropy loss if the &amp;lsquo;multi_class&amp;rsquo; option is set to &amp;lsquo;multinomial&amp;rsquo;. (Currently the &amp;lsquo;multinomial&amp;rsquo; option is supported only by the &amp;lsquo;lbfgs&amp;rsquo;, &amp;lsquo;sag&amp;rsquo;, &amp;lsquo;saga&amp;rsquo; and &amp;lsquo;newton-cg&amp;rsquo; solvers.)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fc004eb44e3b89b80f2b6796f35d04551e921cc" translate="yes" xml:space="preserve">
          <source>In the multiclass case:</source>
          <target state="translated">En el caso de la multiclase:</target>
        </trans-unit>
        <trans-unit id="d77598124fa8bad46b51e89decd127c4c83bc1e3" translate="yes" xml:space="preserve">
          <source>In the multilabel case with binary label indicators, where the first label set [0,1] has an error:</source>
          <target state="translated">En el caso de las etiquetas con indicadores binarios,donde el primer conjunto de etiquetas [0,1]tiene un error:</target>
        </trans-unit>
        <trans-unit id="4557110f167a92f3d0af48823270c458eb95839b" translate="yes" xml:space="preserve">
          <source>In the multilabel case with binary label indicators:</source>
          <target state="translated">En el caso de las etiquetas múltiples con indicadores de etiquetas binarias:</target>
        </trans-unit>
        <trans-unit id="e898613ef6934f2809451f3fa3e427c4a4bd49ce" translate="yes" xml:space="preserve">
          <source>In the multilabel case, this calculates a confusion matrix per sample</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b2a464789db8978cf9674eef13e9bc3f4a4cf79" translate="yes" xml:space="preserve">
          <source>In the multilabel case:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3dbb497f0422701e359a6bab16a477019a81aa92" translate="yes" xml:space="preserve">
          <source>In the multilabel learning literature, OvR is also known as the binary relevance method.</source>
          <target state="translated">En la literatura de aprendizaje de etiquetas múltiples,el OvR también se conoce como el método de relevancia binaria.</target>
        </trans-unit>
        <trans-unit id="b098a0ed402e179dee6b5de05c6210f893507735" translate="yes" xml:space="preserve">
          <source>In the new space, each dimension is the distance to the cluster centers. Note that even if X is sparse, the array returned by &lt;code&gt;transform&lt;/code&gt; will typically be dense.</source>
          <target state="translated">En el nuevo espacio, cada dimensi&amp;oacute;n es la distancia a los centros de los grupos. Tenga en cuenta que incluso si X es escasa, la matriz devuelta por &lt;code&gt;transform&lt;/code&gt; ser&amp;aacute; normalmente densa.</target>
        </trans-unit>
        <trans-unit id="a90aa674a36fbb7c4f65ac18f5e6a5a0eb4c7bc3" translate="yes" xml:space="preserve">
          <source>In the official &lt;a href=&quot;http://vis-www.cs.umass.edu/lfw/README.txt&quot;&gt;README.txt&lt;/a&gt; this task is described as the &amp;ldquo;Restricted&amp;rdquo; task. As I am not sure as to implement the &amp;ldquo;Unrestricted&amp;rdquo; variant correctly, I left it as unsupported for now.</source>
          <target state="translated">En el &lt;a href=&quot;http://vis-www.cs.umass.edu/lfw/README.txt&quot;&gt;archivo README.txt&lt;/a&gt; oficial, esta tarea se describe como la tarea &quot;Restringida&quot;. Como no estoy seguro de implementar la variante &quot;Sin restricciones&quot; correctamente, la dej&amp;eacute; sin soporte por ahora.</target>
        </trans-unit>
        <trans-unit id="5f046ff1a0210873f4b93ca532a15f1f001fc328" translate="yes" xml:space="preserve">
          <source>In the second figure, we show some regression result on a dataset of 6 sequences. Here we use the 1st, 2nd, 4th, and 5th sequences as the training set to make predictions on the 3rd and 6th sequences.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="901c760a214576d30b4ced7bbcce771984b42233" translate="yes" xml:space="preserve">
          <source>In the simple one-dimensional problem that we have seen in the example it is easy to see whether the estimator suffers from bias or variance. However, in high-dimensional spaces, models can become very difficult to visualize. For this reason, it is often helpful to use the tools described below.</source>
          <target state="translated">En el simple problema unidimensional que hemos visto en el ejemplo es fácil ver si el estimador sufre de sesgo o de varianza.Sin embargo,en espacios de alta dimensión,los modelos pueden llegar a ser muy difíciles de visualizar.Por esta razón,a menudo es útil utilizar las herramientas que se describen a continuación.</target>
        </trans-unit>
        <trans-unit id="bada0a0c8458a65354b2c23e7134e865cc4bf85c" translate="yes" xml:space="preserve">
          <source>In the single label multiclass case, the rows of the returned matrix sum to 1.</source>
          <target state="translated">En el caso de la multiclase de etiqueta única,las filas de la matriz devuelta suman 1.</target>
        </trans-unit>
        <trans-unit id="696912c12d134eed0fdc2e472302634288905dc5" translate="yes" xml:space="preserve">
          <source>In the small-samples situation, in which &lt;code&gt;n_samples&lt;/code&gt; is on the order of &lt;code&gt;n_features&lt;/code&gt; or smaller, sparse inverse covariance estimators tend to work better than shrunk covariance estimators. However, in the opposite situation, or for very correlated data, they can be numerically unstable. In addition, unlike shrinkage estimators, sparse estimators are able to recover off-diagonal structure.</source>
          <target state="translated">En la situaci&amp;oacute;n de muestras peque&amp;ntilde;as, en la que &lt;code&gt;n_samples&lt;/code&gt; est&amp;aacute; en el orden de &lt;code&gt;n_features&lt;/code&gt; o m&amp;aacute;s peque&amp;ntilde;o, los estimadores de covarianza inversa dispersos tienden a funcionar mejor que los estimadores de covarianza reducidos. Sin embargo, en la situaci&amp;oacute;n opuesta, o para datos muy correlacionados, pueden ser num&amp;eacute;ricamente inestables. Adem&amp;aacute;s, a diferencia de los estimadores de contracci&amp;oacute;n, los estimadores dispersos pueden recuperar la estructura fuera de la diagonal.</target>
        </trans-unit>
        <trans-unit id="1c648bbbf8ddd269e7c36de7c1822a2705968fac" translate="yes" xml:space="preserve">
          <source>In the specific case of scikit-learn, it may be better to use joblib&amp;rsquo;s replacement of pickle (&lt;code&gt;dump&lt;/code&gt; &amp;amp; &lt;code&gt;load&lt;/code&gt;), which is more efficient on objects that carry large numpy arrays internally as is often the case for fitted scikit-learn estimators, but can only pickle to the disk and not to a string:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5f33dda5b96ece3c041650e9fa8db02e62bfd46" translate="yes" xml:space="preserve">
          <source>In the specific case of scikit-learn, it may be better to use joblib&amp;rsquo;s replacement of pickle (&lt;code&gt;joblib.dump&lt;/code&gt; &amp;amp; &lt;code&gt;joblib.load&lt;/code&gt;), which is more efficient on objects that carry large numpy arrays internally as is often the case for fitted scikit-learn estimators, but can only pickle to the disk and not to a string:</source>
          <target state="translated">En el caso espec&amp;iacute;fico de scikit-learn, puede ser mejor usar el reemplazo de pickle de &lt;code&gt;joblib.dump&lt;/code&gt; ( joblib.dump &amp;amp; &lt;code&gt;joblib.load&lt;/code&gt; ), que es m&amp;aacute;s eficiente en objetos que transportan matrices de n&amp;uacute;meros grandes internamente, como suele ser el caso de scikit- aprende estimadores, pero solo puede escanear en el disco y no en una cadena:</target>
        </trans-unit>
        <trans-unit id="4d7c6f4a78fb7d42f5b6b076760e4c0fb27e052c" translate="yes" xml:space="preserve">
          <source>In the specific case of scikit-learn, it may be more interesting to use joblib&amp;rsquo;s replacement for pickle (&lt;code&gt;joblib.dump&lt;/code&gt; &amp;amp; &lt;code&gt;joblib.load&lt;/code&gt;), which is more efficient on big data but it can only pickle to the disk and not to a string:</source>
          <target state="translated">En el caso espec&amp;iacute;fico de scikit-learn, puede ser m&amp;aacute;s interesante usar el reemplazo de pickle de &lt;code&gt;joblib.dump&lt;/code&gt; ( joblib.dump &amp;amp; &lt;code&gt;joblib.load&lt;/code&gt; ), que es m&amp;aacute;s eficiente en big data pero solo puede hacer pickle en el disco y no en una cadena :</target>
        </trans-unit>
        <trans-unit id="6bc18b31ba734fa9a1f609c8898b12e640d531fb" translate="yes" xml:space="preserve">
          <source>In the statistics community, it is common practice to perform multiple imputations, generating, for example, &lt;code&gt;m&lt;/code&gt; separate imputations for a single feature matrix. Each of these &lt;code&gt;m&lt;/code&gt; imputations is then put through the subsequent analysis pipeline (e.g. feature engineering, clustering, regression, classification). The &lt;code&gt;m&lt;/code&gt; final analysis results (e.g. held-out validation errors) allow the data scientist to obtain understanding of how analytic results may differ as a consequence of the inherent uncertainty caused by the missing values. The above practice is called multiple imputation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3fa57071e687f0bc6b84bf63b957df19fb1d89e" translate="yes" xml:space="preserve">
          <source>In the third figure, we demonstrate a classification model by training on 6 sequences and make predictions on another 5 sequences. The ground truth here is simply whether there is at least one &amp;lsquo;A&amp;rsquo; in the sequence. Here the model makes four correct classifications and fails on one.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e8940d2e745f9a24bd23b0a1547dcf715a870bb" translate="yes" xml:space="preserve">
          <source>In the total set of features, only the 4 first ones are significant. We can see that they have the highest score with univariate feature selection. The SVM assigns a large weight to one of these features, but also Selects many of the non-informative features. Applying univariate feature selection before the SVM increases the SVM weight attributed to the significant features, and will thus improve classification.</source>
          <target state="translated">En el conjunto total de características,sólo las 4 primeras son significativas.Podemos ver que tienen la puntuación más alta con la selección de rasgos univariantes.La SVM asigna un gran peso a uno de estos rasgos,pero también selecciona muchos de los rasgos no informativos.Aplicando la selección de rasgos univariantes antes de la SVM aumenta el peso de la SVM atribuido a los rasgos significativos,y así mejorará la clasificación.</target>
        </trans-unit>
        <trans-unit id="5cab08ab26978fd8cb0ee3262a21c03baca4d379" translate="yes" xml:space="preserve">
          <source>In the transformed &lt;code&gt;X&lt;/code&gt;, the first column is the encoding of the feature with categories &amp;ldquo;male&amp;rdquo;/&amp;rdquo;female&amp;rdquo;, while the remaining 6 columns is the encoding of the 2 features with respectively 3 categories each.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3dd53135ff49dbe7e421a248bf614a3ea8f0d5e" translate="yes" xml:space="preserve">
          <source>In the vector quantization literature, &lt;code&gt;cluster_centers_&lt;/code&gt; is called the code book and each value returned by &lt;code&gt;predict&lt;/code&gt; is the index of the closest code in the code book.</source>
          <target state="translated">En la literatura de cuantificaci&amp;oacute;n de vectores, &lt;code&gt;cluster_centers_&lt;/code&gt; se llama libro de c&amp;oacute;digos y cada valor devuelto por &lt;code&gt;predict&lt;/code&gt; es el &amp;iacute;ndice del c&amp;oacute;digo m&amp;aacute;s cercano en el libro de c&amp;oacute;digos.</target>
        </trans-unit>
        <trans-unit id="71ea1d0e6870ae14110d577f25dbcd29b63431c3" translate="yes" xml:space="preserve">
          <source>In their 2004 paper &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;1&lt;/a&gt;, O. Ledoit and M. Wolf propose a formula to compute the optimal shrinkage coefficient \(\alpha\) that minimizes the Mean Squared Error between the estimated and the real covariance matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a63d5086bf9614df56a7612405271e0122a8145" translate="yes" xml:space="preserve">
          <source>In their 2004 paper &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;, O. Ledoit and M. Wolf propose a formula to compute the optimal shrinkage coefficient \(\alpha\) that minimizes the Mean Squared Error between the estimated and the real covariance matrix.</source>
          <target state="translated">En su art&amp;iacute;culo de 2004 &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt; , O. Ledoit y M. Wolf proponen una f&amp;oacute;rmula para calcular el coeficiente de contracci&amp;oacute;n &amp;oacute;ptimo \ (\ alpha \) que minimiza el error cuadr&amp;aacute;tico medio entre la matriz de covarianza estimada y la real.</target>
        </trans-unit>
        <trans-unit id="ee9767309b3df05ebf7c392a0bb4e8915eee3d46" translate="yes" xml:space="preserve">
          <source>In these settings, the &lt;a href=&quot;../../modules/clustering#spectral-clustering&quot;&gt;Spectral clustering&lt;/a&gt; approach solves the problem know as &amp;lsquo;normalized graph cuts&amp;rsquo;: the image is seen as a graph of connected voxels, and the spectral clustering algorithm amounts to choosing graph cuts defining regions while minimizing the ratio of the gradient along the cut, and the volume of the region.</source>
          <target state="translated">En estas configuraciones, el enfoque de &lt;a href=&quot;../../modules/clustering#spectral-clustering&quot;&gt;agrupamiento espectral&lt;/a&gt; resuelve el problema conocido como 'cortes de gr&amp;aacute;fico normalizados': la imagen se ve como un gr&amp;aacute;fico de v&amp;oacute;xeles conectados, y el algoritmo de agrupamiento espectral equivale a elegir cortes de gr&amp;aacute;fico que definen regiones mientras minimiza la relaci&amp;oacute;n del gradiente a lo largo de el corte y el volumen de la regi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="e2e4475ec0999dd975ba681e19179d817d6681ae" translate="yes" xml:space="preserve">
          <source>In this case we would like to know if a model trained on a particular set of groups generalizes well to the unseen groups. To measure this, we need to ensure that all the samples in the validation fold come from groups that are not represented at all in the paired training fold.</source>
          <target state="translated">En este caso nos gustaría saber si un modelo entrenado en un conjunto particular de grupos se generaliza bien a los grupos invisibles.Para medir esto,necesitamos asegurarnos de que todas las muestras del pliegue de validación proceden de grupos que no están representados en absoluto en el pliegue de entrenamiento emparejado.</target>
        </trans-unit>
        <trans-unit id="8e6586aaac37d3a887b7276aee6797fdd6471b11" translate="yes" xml:space="preserve">
          <source>In this case, &lt;code&gt;X_train&lt;/code&gt; and &lt;code&gt;X_test&lt;/code&gt; are guaranteed to have the same number of features. Another way to achieve the same result is to fix the number of features:</source>
          <target state="translated">En este caso, se garantiza que &lt;code&gt;X_train&lt;/code&gt; y &lt;code&gt;X_test&lt;/code&gt; tendr&amp;aacute;n la misma cantidad de funciones. Otra forma de lograr el mismo resultado es corregir el n&amp;uacute;mero de funciones:</target>
        </trans-unit>
        <trans-unit id="c94c921d6a6a8582b29da8ef5a3a44fe1ea80a89" translate="yes" xml:space="preserve">
          <source>In this case, the classifier is fit upon instances each assigned multiple labels. The &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.multilabelbinarizer#sklearn.preprocessing.MultiLabelBinarizer&quot;&gt;&lt;code&gt;MultiLabelBinarizer&lt;/code&gt;&lt;/a&gt; is used to binarize the 2d array of multilabels to &lt;code&gt;fit&lt;/code&gt; upon. As a result, &lt;code&gt;predict()&lt;/code&gt; returns a 2d array with multiple predicted labels for each instance.</source>
          <target state="translated">En este caso, el clasificador se ajusta a instancias a cada una de las cuales se le asignaron m&amp;uacute;ltiples etiquetas. El &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.multilabelbinarizer#sklearn.preprocessing.MultiLabelBinarizer&quot;&gt; &lt;code&gt;MultiLabelBinarizer&lt;/code&gt; &lt;/a&gt; se utiliza para binarizar la matriz 2D de multilabels para &lt;code&gt;fit&lt;/code&gt; sobre. Como resultado, &lt;code&gt;predict()&lt;/code&gt; devuelve una matriz 2d con m&amp;uacute;ltiples etiquetas predichas para cada instancia.</target>
        </trans-unit>
        <trans-unit id="4367a423584d0b6ba622189fa17b21bb3e206f2c" translate="yes" xml:space="preserve">
          <source>In this case, the cross-validation retained the same ratio of classes across each CV split. Next we&amp;rsquo;ll visualize this behavior for a number of CV iterators.</source>
          <target state="translated">En este caso, la validaci&amp;oacute;n cruzada retuvo la misma proporci&amp;oacute;n de clases en cada divisi&amp;oacute;n de CV. A continuaci&amp;oacute;n, visualizaremos este comportamiento para varios iteradores de CV.</target>
        </trans-unit>
        <trans-unit id="d121f450bc55250670235f93c8cd2083eb40a561" translate="yes" xml:space="preserve">
          <source>In this context, we can define the notions of precision, recall and F-measure:</source>
          <target state="translated">En este contexto,podemos definir las nociones de precisión,recuerdo y medida F:</target>
        </trans-unit>
        <trans-unit id="308ef10a0e6fa4feab74c9fff8eae0756aa171db" translate="yes" xml:space="preserve">
          <source>In this dataset, each sample corresponds to an insurance policy, i.e. a contract within an insurance company and an individual (policyholder). Available features include driver age, vehicle age, vehicle power, etc.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b69830262e95394b14f5a754f7290cc7372dc2b1" translate="yes" xml:space="preserve">
          <source>In this dataset, each sample corresponds to an insurance policy. Available features include driver age, vehicle age, vehicle power, etc.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b7e5d4a758a26d1b659ba54387246d5cebcf12f" translate="yes" xml:space="preserve">
          <source>In this example the dependent variable Y is set as a function of the input features: y = X*w + c. The coefficient vector w is randomly sampled from a normal distribution, whereas the bias term c is set to a constant.</source>
          <target state="translated">En este ejemplo,la variable dependiente Y se establece en función de las características de entrada:y=X*w+c.El vector del coeficiente w se muestrea aleatoriamente a partir de una distribución normal,mientras que el término de sesgo c se establece como una constante.</target>
        </trans-unit>
        <trans-unit id="5d530c717737ac885c81ddc70c9c4fe51f2f2e42" translate="yes" xml:space="preserve">
          <source>In this example the silhouette analysis is used to choose an optimal value for &lt;code&gt;n_clusters&lt;/code&gt;. The silhouette plot shows that the &lt;code&gt;n_clusters&lt;/code&gt; value of 3, 5 and 6 are a bad pick for the given data due to the presence of clusters with below average silhouette scores and also due to wide fluctuations in the size of the silhouette plots. Silhouette analysis is more ambivalent in deciding between 2 and 4.</source>
          <target state="translated">En este ejemplo, el an&amp;aacute;lisis de silueta se utiliza para elegir un valor &amp;oacute;ptimo para &lt;code&gt;n_clusters&lt;/code&gt; . El gr&amp;aacute;fico de silueta muestra que el valor de &lt;code&gt;n_clusters&lt;/code&gt; de 3, 5 y 6 es una mala elecci&amp;oacute;n para los datos dados debido a la presencia de cl&amp;uacute;steres con puntuaciones de silueta por debajo del promedio y tambi&amp;eacute;n debido a amplias fluctuaciones en el tama&amp;ntilde;o de los gr&amp;aacute;ficos de silueta. El an&amp;aacute;lisis de silueta es m&amp;aacute;s ambivalente al decidir entre 2 y 4.</target>
        </trans-unit>
        <trans-unit id="0b7aa73d7d4561b0e25989b4fff6f5d53474b724" translate="yes" xml:space="preserve">
          <source>In this example we compare some estimators for the purpose of missing feature imputation with &lt;a href=&quot;../../modules/generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;sklearn.impute.IterativeImputer&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="550c896ceafe31d2e76547c4031642097a79581f" translate="yes" xml:space="preserve">
          <source>In this example we compare the various initialization strategies for K-means in terms of runtime and quality of the results.</source>
          <target state="translated">En este ejemplo se comparan las diversas estrategias de inicialización de los medios K en cuanto al tiempo de ejecución y la calidad de los resultados.</target>
        </trans-unit>
        <trans-unit id="d9bed364e1f96090d42e72d8ad4e31b8f81dfc1d" translate="yes" xml:space="preserve">
          <source>In this example we prefer the &lt;code&gt;elasticnet&lt;/code&gt; penalty as it is often a good compromise between model compactness and prediction power. One can also further tune the &lt;code&gt;l1_ratio&lt;/code&gt; parameter (in combination with the regularization strength &lt;code&gt;alpha&lt;/code&gt;) to control this tradeoff.</source>
          <target state="translated">En este ejemplo preferimos la penalizaci&amp;oacute;n de &lt;code&gt;elasticnet&lt;/code&gt; , ya que a menudo es un buen compromiso entre la compacidad del modelo y el poder de predicci&amp;oacute;n. Tambi&amp;eacute;n se puede ajustar a&amp;uacute;n m&amp;aacute;s el par&amp;aacute;metro &lt;code&gt;l1_ratio&lt;/code&gt; (en combinaci&amp;oacute;n con la fuerza de regularizaci&amp;oacute;n &lt;code&gt;alpha&lt;/code&gt; ) para controlar esta compensaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="5f4ca84332e1fc2168e90c43c86e1d784ebd5f8c" translate="yes" xml:space="preserve">
          <source>In this example we see how to robustly fit a linear model to faulty data using the RANSAC algorithm.</source>
          <target state="translated">En este ejemplo vemos cómo ajustar de forma robusta un modelo lineal a los datos defectuosos utilizando el algoritmo RANSAC.</target>
        </trans-unit>
        <trans-unit id="8b2f8ba713590c7461bca4df745b9c8578a9ee4a" translate="yes" xml:space="preserve">
          <source>In this example we will illustrate both approaches. We start by defining a few helper functions for loading the data and visualizing results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9cb7bd690b6a99c0206d146b05cd9c20c5a47dca" translate="yes" xml:space="preserve">
          <source>In this example we will investigate different imputation techniques:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38fc37287fc51222e73dd7c83e6c92e563107ff6" translate="yes" xml:space="preserve">
          <source>In this example you might try to:</source>
          <target state="translated">En este ejemplo podrías intentarlo:</target>
        </trans-unit>
        <trans-unit id="8a61e0fa0737723bbfe9d0174ce3aad285419f4d" translate="yes" xml:space="preserve">
          <source>In this example, &lt;code&gt;X&lt;/code&gt; is &lt;code&gt;float32&lt;/code&gt;, which is cast to &lt;code&gt;float64&lt;/code&gt; by &lt;code&gt;fit_transform(X)&lt;/code&gt;.</source>
          <target state="translated">En este ejemplo, &lt;code&gt;X&lt;/code&gt; es &lt;code&gt;float32&lt;/code&gt; , que &lt;code&gt;fit_transform(X)&lt;/code&gt; &lt;code&gt;float64&lt;/code&gt; en float64 .</target>
        </trans-unit>
        <trans-unit id="2812da8873763c11175cae962f9ab9000ab381c4" translate="yes" xml:space="preserve">
          <source>In this example, an image with connected circles is generated and spectral clustering is used to separate the circles.</source>
          <target state="translated">En este ejemplo,se genera una imagen con círculos conectados y se utiliza la agrupación espectral para separar los círculos.</target>
        </trans-unit>
        <trans-unit id="79a59d7ef51f3f34cd5dc94073ebe194acbc66c6" translate="yes" xml:space="preserve">
          <source>In this example, both modeling approaches yield comparable performance metrics. For implementation reasons, the percentage of explained variance \(D^2\) is not available for the product model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69af0b849be70a0524a821dde21a609feb16811a" translate="yes" xml:space="preserve">
          <source>In this example, pixels are represented in a 3D-space and K-means is used to find 64 color clusters. In the image processing literature, the codebook obtained from K-means (the cluster centers) is called the color palette. Using a single byte, up to 256 colors can be addressed, whereas an RGB encoding requires 3 bytes per pixel. The GIF file format, for example, uses such a palette.</source>
          <target state="translated">En este ejemplo,los píxeles están representados en un espacio 3D y se utiliza la media K para encontrar 64 grupos de colores.En la literatura de procesamiento de imágenes,el libro de códigos obtenido de los K-means (los centros de los cúmulos)se llama la paleta de colores.Usando un solo byte,se pueden direccionar hasta 256 colores,mientras que una codificación RGB requiere 3 bytes por píxel.El formato de archivo GIF,por ejemplo,utiliza esta paleta.</target>
        </trans-unit>
        <trans-unit id="2f0fb947da0f2bfc5faf32b771a3cb10ff049eda" translate="yes" xml:space="preserve">
          <source>In this example, the numeric data is standard-scaled after mean-imputation, while the categorical data is one-hot encoded after imputing missing values with a new category (&lt;code&gt;'missing'&lt;/code&gt;).</source>
          <target state="translated">En este ejemplo, los datos num&amp;eacute;ricos tienen una escala est&amp;aacute;ndar despu&amp;eacute;s de la imputaci&amp;oacute;n de la media, mientras que los datos categ&amp;oacute;ricos se codifican de forma &amp;uacute;nica despu&amp;eacute;s de imputar los valores faltantes con una nueva categor&amp;iacute;a ( &lt;code&gt;'missing'&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="354a556d83cef273107f176ebec9db1b19a5c757" translate="yes" xml:space="preserve">
          <source>In this example, the sinusoid is approximated by a polynomial using different pairs of initial values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d88656bc2e040320cf9595554acac12be98f916c" translate="yes" xml:space="preserve">
          <source>In this example, we compare the estimation errors that are made when using various types of location and covariance estimates on contaminated Gaussian distributed data sets:</source>
          <target state="translated">En este ejemplo se comparan los errores de estimación que se cometen al utilizar diversos tipos de estimaciones de localización y covarianza en conjuntos de datos distribuidos de Gauss contaminados:</target>
        </trans-unit>
        <trans-unit id="26a8e8ae6383655dcfc18bd00f71528218aa360e" translate="yes" xml:space="preserve">
          <source>In this example, we compute the permutation importance on the Wisconsin breast cancer dataset using &lt;a href=&quot;../../modules/generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;permutation_importance&lt;/code&gt;&lt;/a&gt;. The &lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;RandomForestClassifier&lt;/code&gt;&lt;/a&gt; can easily get about 97% accuracy on a test dataset. Because this dataset contains multicollinear features, the permutation importance will show that none of the features are important. One approach to handling multicollinearity is by performing hierarchical clustering on the features&amp;rsquo; Spearman rank-order correlations, picking a threshold, and keeping a single feature from each cluster.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b7bcaf87ef3b0730f7083836942b0b038810927" translate="yes" xml:space="preserve">
          <source>In this example, we give an overview of the &lt;a href=&quot;../../modules/generated/sklearn.compose.transformedtargetregressor#sklearn.compose.TransformedTargetRegressor&quot;&gt;&lt;code&gt;sklearn.compose.TransformedTargetRegressor&lt;/code&gt;&lt;/a&gt;. Two examples illustrate the benefit of transforming the targets before learning a linear regression model. The first example uses synthetic data while the second example is based on the Boston housing data set.</source>
          <target state="translated">En este ejemplo, ofrecemos una descripci&amp;oacute;n general de &lt;a href=&quot;../../modules/generated/sklearn.compose.transformedtargetregressor#sklearn.compose.TransformedTargetRegressor&quot;&gt; &lt;code&gt;sklearn.compose.TransformedTargetRegressor&lt;/code&gt; &lt;/a&gt; . Dos ejemplos ilustran el beneficio de transformar los objetivos antes de aprender un modelo de regresi&amp;oacute;n lineal. El primer ejemplo utiliza datos sint&amp;eacute;ticos, mientras que el segundo ejemplo se basa en el conjunto de datos de vivienda de Boston.</target>
        </trans-unit>
        <trans-unit id="5f4a1f2d68c8f41cbf437ea7e001b2f1285b3f2f" translate="yes" xml:space="preserve">
          <source>In this example, we illustrate the use case in which different regressors are stacked together and a final linear penalized regressor is used to output the prediction. We compare the performance of each individual regressor with the stacking strategy. Stacking slightly improves the overall performance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd9410f53a0f1d1aa2f5ff77c7bafaf9751d4c08" translate="yes" xml:space="preserve">
          <source>In this example, we set the value of &lt;code&gt;gamma&lt;/code&gt; manually. To find good values for these parameters, we can use tools such as &lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;grid search&lt;/a&gt; and &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;cross validation&lt;/a&gt;.</source>
          <target state="translated">En este ejemplo, establecemos el valor de &lt;code&gt;gamma&lt;/code&gt; manualmente. Para encontrar buenos valores para estos par&amp;aacute;metros, podemos utilizar herramientas como &lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;la b&amp;uacute;squeda de cuadr&amp;iacute;culas&lt;/a&gt; y &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;la validaci&amp;oacute;n cruzada&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="be5803bd91839824804bc4aadf2784b6ed10723a" translate="yes" xml:space="preserve">
          <source>In this example, we will compare the impurity-based feature importance of &lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;RandomForestClassifier&lt;/code&gt;&lt;/a&gt; with the permutation importance on the titanic dataset using &lt;a href=&quot;../../modules/generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;permutation_importance&lt;/code&gt;&lt;/a&gt;. We will show that the impurity-based feature importance can inflate the importance of numerical features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f66533d22104292e30bad75824b906ee4fc1acd9" translate="yes" xml:space="preserve">
          <source>In this example, we will construct display objects, &lt;a href=&quot;../../modules/generated/sklearn.metrics.confusionmatrixdisplay#sklearn.metrics.ConfusionMatrixDisplay&quot;&gt;&lt;code&gt;ConfusionMatrixDisplay&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../modules/generated/sklearn.metrics.roccurvedisplay#sklearn.metrics.RocCurveDisplay&quot;&gt;&lt;code&gt;RocCurveDisplay&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;../../modules/generated/sklearn.metrics.precisionrecalldisplay#sklearn.metrics.PrecisionRecallDisplay&quot;&gt;&lt;code&gt;PrecisionRecallDisplay&lt;/code&gt;&lt;/a&gt; directly from their respective metrics. This is an alternative to using their corresponding plot functions when a model&amp;rsquo;s predictions are already computed or expensive to compute. Note that this is advanced usage, and in general we recommend using their respective plot functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e0782ea6d7859077c07d60aaa0a30b1c4373f50" translate="yes" xml:space="preserve">
          <source>In this plot you can see the training scores and validation scores of an SVM for different values of the kernel parameter gamma. For very low values of gamma, you can see that both the training score and the validation score are low. This is called underfitting. Medium values of gamma will result in high values for both scores, i.e. the classifier is performing fairly well. If gamma is too high, the classifier will overfit, which means that the training score is good but the validation score is poor.</source>
          <target state="translated">En este gráfico se pueden ver los resultados de entrenamiento y los resultados de validación de un SVM para diferentes valores del parámetro gamma del núcleo.Para valores muy bajos de gamma,puedes ver que tanto la puntuación de entrenamiento como la puntuación de validación son bajas.Esto se denomina infravaloración.Los valores medios de gamma darán como resultado valores altos para ambas puntuaciones,es decir,el clasificador está funcionando bastante bien.Si el gamma es demasiado alto,el clasificador se sobreajustará,lo que significa que la puntuación de entrenamiento es buena pero la puntuación de validación es pobre.</target>
        </trans-unit>
        <trans-unit id="2c39a03080473177a8509645110953edafebbd76" translate="yes" xml:space="preserve">
          <source>In this scheme, features and samples are defined as follows:</source>
          <target state="translated">En este esquema,las características y las muestras se definen de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="5941fbb58c226f551ff80660bcd51a84bcc2bae1" translate="yes" xml:space="preserve">
          <source>In this section we will see how to:</source>
          <target state="translated">En esta sección veremos cómo hacerlo:</target>
        </trans-unit>
        <trans-unit id="6ce5845b6414a0cfccffc603f3efdd4b47c7ce4b" translate="yes" xml:space="preserve">
          <source>In this section, we introduce the &lt;a href=&quot;https://en.wikipedia.org/wiki/Machine_learning&quot;&gt;machine learning&lt;/a&gt; vocabulary that we use throughout scikit-learn and give a simple learning example.</source>
          <target state="translated">En esta secci&amp;oacute;n, presentamos el vocabulario de &lt;a href=&quot;https://en.wikipedia.org/wiki/Machine_learning&quot;&gt;aprendizaje autom&amp;aacute;tico&lt;/a&gt; que usamos en scikit-learn y damos un ejemplo de aprendizaje simple.</target>
        </trans-unit>
        <trans-unit id="e7b54ae8e73f20fa370a273bbb52814367b82582" translate="yes" xml:space="preserve">
          <source>In this snippet we make use of a &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;sklearn.svm.LinearSVC&lt;/code&gt;&lt;/a&gt; coupled with &lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt;&lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt;&lt;/a&gt; to evaluate feature importances and select the most relevant features. Then, a &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;sklearn.ensemble.RandomForestClassifier&lt;/code&gt;&lt;/a&gt; is trained on the transformed output, i.e. using only relevant features. You can perform similar operations with the other feature selection methods and also classifiers that provide a way to evaluate feature importances of course. See the &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt; examples for more details.</source>
          <target state="translated">En este fragmento, utilizamos &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;sklearn.svm.LinearSVC&lt;/code&gt; &lt;/a&gt; junto con &lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt; &lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt; &lt;/a&gt; para evaluar la importancia de las caracter&amp;iacute;sticas y seleccionar las caracter&amp;iacute;sticas m&amp;aacute;s relevantes. Luego, un &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt; &lt;code&gt;sklearn.ensemble.RandomForestClassifier&lt;/code&gt; &lt;/a&gt; se entrena en la salida transformada, es decir, usando solo caracter&amp;iacute;sticas relevantes. Puede realizar operaciones similares con los otros m&amp;eacute;todos de selecci&amp;oacute;n de caracter&amp;iacute;sticas y tambi&amp;eacute;n clasificadores que brindan una forma de evaluar la importancia de las caracter&amp;iacute;sticas, por supuesto. Consulte los ejemplos de &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="87aee0924ee2a28e2d573efd8e050c2a5c1632a3" translate="yes" xml:space="preserve">
          <source>In unsupervised learning we only have a dataset \(X = \{x_1, x_2, \dots, x_n \}\). How can this dataset be described mathematically? A very simple &lt;code&gt;continuous latent variable&lt;/code&gt; model for \(X\) is</source>
          <target state="translated">En el aprendizaje no supervisado, solo tenemos un conjunto de datos \ (X = \ {x_1, x_2, \ dots, x_n \} \). &amp;iquest;C&amp;oacute;mo se puede describir matem&amp;aacute;ticamente este conjunto de datos? Un modelo de &lt;code&gt;continuous latent variable&lt;/code&gt; muy simple para \ (X \) es</target>
        </trans-unit>
        <trans-unit id="a1efe7e891f38316d324e0fe7b8b483308bcbebf" translate="yes" xml:space="preserve">
          <source>Includes values in confusion matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c89a6ca6f29b888687c7afd577a282b5b95a2be5" translate="yes" xml:space="preserve">
          <source>Incorporating statistics from test data into the preprocessors makes cross-validation scores unreliable (known as &lt;em&gt;data leakage&lt;/em&gt;), for example in the case of scalers or imputing missing values.</source>
          <target state="translated">La incorporaci&amp;oacute;n de estad&amp;iacute;sticas de datos de prueba en los preprocesadores hace que las puntuaciones de validaci&amp;oacute;n cruzada no sean fiables (lo que se conoce como &lt;em&gt;fuga de datos&lt;/em&gt; ), por ejemplo, en el caso de escaladores o imputaci&amp;oacute;n de valores perdidos.</target>
        </trans-unit>
        <trans-unit id="4c33f1e1286c254eaae3fbe03197d5578f08f56a" translate="yes" xml:space="preserve">
          <source>Increasing &lt;code&gt;max_depth&lt;/code&gt; for AdaBoost lowers the standard deviation of the scores (but the average score does not improve).</source>
          <target state="translated">El aumento de &lt;code&gt;max_depth&lt;/code&gt; para AdaBoost reduce la desviaci&amp;oacute;n est&amp;aacute;ndar de las puntuaciones (pero la puntuaci&amp;oacute;n media no mejora).</target>
        </trans-unit>
        <trans-unit id="e79b1358981354168a853701629e2643ba45bf93" translate="yes" xml:space="preserve">
          <source>Increasing false positive rates such that element i is the false positive rate of predictions with score &amp;gt;= thresholds[i].</source>
          <target state="translated">Incrementar las tasas de falsos positivos de manera que el elemento i sea la tasa de falsos positivos de predicciones con una puntuaci&amp;oacute;n&amp;gt; = umbrales [i].</target>
        </trans-unit>
        <trans-unit id="3ca08d3a2216068596512fa76cc1f85e2464a3a8" translate="yes" xml:space="preserve">
          <source>Increasing thresholds on the decision function used to compute precision and recall.</source>
          <target state="translated">Aumentar los umbrales de la función de decisión utilizada para calcular la precisión y el recuerdo.</target>
        </trans-unit>
        <trans-unit id="7ae5f53b337e575381bac1d47d2d4a4d2e4839b6" translate="yes" xml:space="preserve">
          <source>Increasing true positive rates such that element i is the true positive rate of predictions with score &amp;gt;= thresholds[i].</source>
          <target state="translated">Incrementar las tasas de verdaderos positivos de manera que el elemento i sea la tasa de verdaderos positivos de predicciones con una puntuaci&amp;oacute;n&amp;gt; = umbrales [i].</target>
        </trans-unit>
        <trans-unit id="54206634ab03f8962d59d7c24e12c85ebd45b5e1" translate="yes" xml:space="preserve">
          <source>Incremental PCA</source>
          <target state="translated">PCA incremental</target>
        </trans-unit>
        <trans-unit id="0254682de6b7d13bd44669747bb093c1dca18b21" translate="yes" xml:space="preserve">
          <source>Incremental Principal Component Analysis.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="acaf3165fc4e0ddec759b9648ee12eed48089691" translate="yes" xml:space="preserve">
          <source>Incremental fit on a batch of samples.</source>
          <target state="translated">Ajuste incremental en un lote de muestras.</target>
        </trans-unit>
        <trans-unit id="a79a34aec33f8c8b084e4316cf8e243a4d6601e6" translate="yes" xml:space="preserve">
          <source>Incremental fit with X.</source>
          <target state="translated">Ajuste incremental con X.</target>
        </trans-unit>
        <trans-unit id="87210470540ea5af2ee40f330fdeea4017f1c0aa" translate="yes" xml:space="preserve">
          <source>Incremental fit with X. All of X is processed as a single batch.</source>
          <target state="translated">Ajuste incremental con X.Todo X se procesa como un solo lote.</target>
        </trans-unit>
        <trans-unit id="5b9d567927b0a80924b0a28fdea6cf19b23d2e57" translate="yes" xml:space="preserve">
          <source>Incremental principal component analysis (IPCA) is typically used as a replacement for principal component analysis (PCA) when the dataset to be decomposed is too large to fit in memory. IPCA builds a low-rank approximation for the input data using an amount of memory which is independent of the number of input data samples. It is still dependent on the input data features, but changing the batch size allows for control of memory usage.</source>
          <target state="translated">El análisis incremental de componentes principales (IPCA)se utiliza normalmente como sustituto del análisis de componentes principales (PCA)cuando el conjunto de datos a descomponer es demasiado grande para caber en la memoria.El IPCA construye una aproximación de bajo rango para los datos de entrada utilizando una cantidad de memoria que es independiente del número de muestras de datos de entrada.Sigue dependiendo de las características de los datos de entrada,pero el cambio del tamaño del lote permite controlar el uso de la memoria.</target>
        </trans-unit>
        <trans-unit id="66088e706ece2d903ed2071fa2d42be9315774b6" translate="yes" xml:space="preserve">
          <source>Incremental principal components analysis (IPCA).</source>
          <target state="translated">Análisis de componentes principales incrementales (IPCA).</target>
        </trans-unit>
        <trans-unit id="ef7722207a6c2343d08e45f401cd00ccd19381c7" translate="yes" xml:space="preserve">
          <source>Incrementally fit the model to data.</source>
          <target state="translated">Incrementar el ajuste del modelo a los datos.</target>
        </trans-unit>
        <trans-unit id="505bf67b8aa7cec37d64a9ce9b03d73f70b38b8b" translate="yes" xml:space="preserve">
          <source>Incrementally fit the model to data. Fit a separate model for each output variable.</source>
          <target state="translated">Incrementar el ajuste del modelo a los datos.Ajustar un modelo separado para cada variable de salida.</target>
        </trans-unit>
        <trans-unit id="e7353e5363cf13ee1c3efdc144e75ff650f6c2d1" translate="yes" xml:space="preserve">
          <source>Incrementally trained logistic regression (when given the parameter &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e12e704fa3eb16be83d58c2167c9c4f83379a1d" translate="yes" xml:space="preserve">
          <source>Indeed many estimators are designed with the assumption that each feature takes values close to zero or more importantly that all features vary on comparable scales. In particular, metric-based and gradient-based estimators often assume approximately standardized data (centered features with unit variances). A notable exception are decision tree-based estimators that are robust to arbitrary scaling of the data.</source>
          <target state="translated">De hecho,muchos estimadores están diseñados con la suposición de que cada característica toma valores cercanos a cero o,lo que es más importante,que todas las características varían en escalas comparables.En particular,los estimadores basados en el sistema métrico y en el gradiente suelen suponer datos aproximadamente normalizados (características centradas con variaciones de unidades).Una excepción notable son los estimadores basados en árboles de decisión que son robustos a la escala arbitraria de los datos.</target>
        </trans-unit>
        <trans-unit id="9cde6c3dae7189a85444fb86f682cb4ecd226cef" translate="yes" xml:space="preserve">
          <source>Indeed, from the plot above the most important factor in determining WAGE appears to be the variable UNION, even if our intuition might tell us that variables like EXPERIENCE should have more impact.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7933c6d72de999f40e22d3286d9c782fd636305b" translate="yes" xml:space="preserve">
          <source>Independent Component Analysis: ICA</source>
          <target state="translated">Análisis de componentes independientes:ICA</target>
        </trans-unit>
        <trans-unit id="d170598045cdc9e2df037718a96d1706ed03e640" translate="yes" xml:space="preserve">
          <source>Independent component analysis separates a multivariate signal into additive subcomponents that are maximally independent. It is implemented in scikit-learn using the &lt;a href=&quot;generated/sklearn.decomposition.fastica#sklearn.decomposition.FastICA&quot;&gt;&lt;code&gt;Fast ICA&lt;/code&gt;&lt;/a&gt; algorithm. Typically, ICA is not used for reducing dimensionality but for separating superimposed signals. Since the ICA model does not include a noise term, for the model to be correct, whitening must be applied. This can be done internally using the whiten argument or manually using one of the PCA variants.</source>
          <target state="translated">El an&amp;aacute;lisis de componentes independientes separa una se&amp;ntilde;al multivariante en subcomponentes aditivos que son m&amp;aacute;ximamente independientes. Se implementa en scikit-learn usando el algoritmo &lt;a href=&quot;generated/sklearn.decomposition.fastica#sklearn.decomposition.FastICA&quot;&gt; &lt;code&gt;Fast ICA&lt;/code&gt; &lt;/a&gt; . Normalmente, ICA no se utiliza para reducir la dimensionalidad sino para separar se&amp;ntilde;ales superpuestas. Dado que el modelo ICA no incluye un t&amp;eacute;rmino de ruido, para que el modelo sea correcto, se debe aplicar blanqueamiento. Esto se puede hacer internamente usando el argumento blanquear o manualmente usando una de las variantes de PCA.</target>
        </trans-unit>
        <trans-unit id="420bdf88d0c37e0c49c684e7be83be0c3065749b" translate="yes" xml:space="preserve">
          <source>Independent component analysis, a latent variable model with non-Gaussian latent variables.</source>
          <target state="translated">Análisis de componentes independientes,un modelo de variables latentes con variables latentes no gausianas.</target>
        </trans-unit>
        <trans-unit id="e81fd2ba1ed4351b51becec6b3e044be03272d29" translate="yes" xml:space="preserve">
          <source>Independent parameter in poly/sigmoid kernel.</source>
          <target state="translated">Parámetro independiente en el núcleo poli/sigmoide.</target>
        </trans-unit>
        <trans-unit id="75b2e172573134b992419919380eaa4d379125c8" translate="yes" xml:space="preserve">
          <source>Independent parameter in poly/sigmoid kernel. 0 by default.</source>
          <target state="translated">Parámetro independiente en el núcleo poli/sigmoide.0 por defecto.</target>
        </trans-unit>
        <trans-unit id="93ccb8f475af3ead0828a4d704d80fd7c1bcca2a" translate="yes" xml:space="preserve">
          <source>Independent term in decision function.</source>
          <target state="translated">Término independiente en la función de decisión.</target>
        </trans-unit>
        <trans-unit id="d60b4ce63cb13d9b546e71bb468305b122e1ff12" translate="yes" xml:space="preserve">
          <source>Independent term in decision function. Set to 0.0 if &lt;code&gt;fit_intercept = False&lt;/code&gt;.</source>
          <target state="translated">T&amp;eacute;rmino independiente en funci&amp;oacute;n de decisi&amp;oacute;n. Establecer en 0.0 si &lt;code&gt;fit_intercept = False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="62ca36e367478a373b265bf6692ac1dd0b87c736" translate="yes" xml:space="preserve">
          <source>Independent term in kernel function. It is only significant in &amp;lsquo;poly&amp;rsquo; and &amp;lsquo;sigmoid&amp;rsquo;.</source>
          <target state="translated">T&amp;eacute;rmino independiente en funci&amp;oacute;n del kernel. Solo es significativo en 'poli' y 'sigmoide'.</target>
        </trans-unit>
        <trans-unit id="498514c5789196d4e7f38be6d2ccefad9084f660" translate="yes" xml:space="preserve">
          <source>Independent term in poly and sigmoid kernels. Ignored by other kernels.</source>
          <target state="translated">Término independiente en los núcleos poli y sigmoide.Ignorado por otros núcleos.</target>
        </trans-unit>
        <trans-unit id="c818388cffefe0c1449b9099e6b8c434f2466b05" translate="yes" xml:space="preserve">
          <source>Independent term in the decision function.</source>
          <target state="translated">Término independiente en la función de decisión.</target>
        </trans-unit>
        <trans-unit id="b8069da00c91cf6e966b739b57f9cbe347e859d2" translate="yes" xml:space="preserve">
          <source>Independent term in the linear model.</source>
          <target state="translated">Término independiente en el modelo lineal.</target>
        </trans-unit>
        <trans-unit id="191e8d234bde29edd43499e6f75fe115a0a775a9" translate="yes" xml:space="preserve">
          <source>Independent term in the linear model. Set to 0.0 if &lt;code&gt;fit_intercept = False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c78017fad7dc4be13e21b61b07a09cb5931df33" translate="yes" xml:space="preserve">
          <source>Index of the cluster each sample belongs to.</source>
          <target state="translated">Índice del grupo al que pertenece cada muestra.</target>
        </trans-unit>
        <trans-unit id="79bbc01c7afbd569e88078c06011f6a142dc18ba" translate="yes" xml:space="preserve">
          <source>Index of the column of X to be swapped.</source>
          <target state="translated">Índice de la columna de X a intercambiar.</target>
        </trans-unit>
        <trans-unit id="ed1d58c02de7a13d74564b832a9effc7dd7512f7" translate="yes" xml:space="preserve">
          <source>Index of the row of X to be swapped.</source>
          <target state="translated">Índice de la fila de X a intercambiar.</target>
        </trans-unit>
        <trans-unit id="ec76f2d92b2be403363a104dc4a87849c9c331a9" translate="yes" xml:space="preserve">
          <source>Indexable data-structures can be arrays, lists, dataframes or scipy sparse matrices with consistent first dimension.</source>
          <target state="translated">Las estructuras de datos indexables pueden ser matrices,listas,marcos de datos o matrices de scipy sparse con una primera dimensión consistente.</target>
        </trans-unit>
        <trans-unit id="436737ead6b730ec05aa4979d3ab186eb46b0b4a" translate="yes" xml:space="preserve">
          <source>Indexes the data on its second axis. Integers are interpreted as positional columns, while strings can reference DataFrame columns by name. A scalar string or int should be used where &lt;code&gt;transformer&lt;/code&gt; expects X to be a 1d array-like (vector), otherwise a 2d array will be passed to the transformer. A callable is passed the input data &lt;code&gt;X&lt;/code&gt; and can return any of the above.</source>
          <target state="translated">Indexa los datos en su segundo eje. Los enteros se interpretan como columnas posicionales, mientras que las cadenas pueden hacer referencia a las columnas DataFrame por su nombre. Se debe usar una cadena escalar o int donde el &lt;code&gt;transformer&lt;/code&gt; espera que X sea un vector similar a una matriz 1d; de lo contrario, se pasar&amp;aacute; una matriz 2d al transformador. A un invocable se le pasan los datos de entrada &lt;code&gt;X&lt;/code&gt; y puede devolver cualquiera de los anteriores.</target>
        </trans-unit>
        <trans-unit id="14c06502f716a74d640158c7430747c2d65e82bc" translate="yes" xml:space="preserve">
          <source>Indexes the data on its second axis. Integers are interpreted as positional columns, while strings can reference DataFrame columns by name. A scalar string or int should be used where &lt;code&gt;transformer&lt;/code&gt; expects X to be a 1d array-like (vector), otherwise a 2d array will be passed to the transformer. A callable is passed the input data &lt;code&gt;X&lt;/code&gt; and can return any of the above. To select multiple columns by name or dtype, you can use &lt;a href=&quot;sklearn.compose.make_column_selector#sklearn.compose.make_column_selector&quot;&gt;&lt;code&gt;make_column_selector&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="33324894ea0a98c1ef1f880dc97967e00c913318" translate="yes" xml:space="preserve">
          <source>Indicate that func accepts a sparse matrix as input. If validate is False, this has no effect. Otherwise, if accept_sparse is false, sparse matrix inputs will cause an exception to be raised.</source>
          <target state="translated">Indique que la función acepta una matriz escasa como entrada.Si validar es falso,esto no tiene ningún efecto.De lo contrario,si accept_sparse es False,las entradas de matriz dispersa harán que se plantee una excepción.</target>
        </trans-unit>
        <trans-unit id="eb7cd0d8cb7fae1e80a3e28d3771772ae8884b48" translate="yes" xml:space="preserve">
          <source>Indicate that the input X array should be checked before calling &lt;code&gt;func&lt;/code&gt;. The possibilities are:</source>
          <target state="translated">Indique que la matriz de entrada X debe verificarse antes de llamar a &lt;code&gt;func&lt;/code&gt; . Las posibilidades son:</target>
        </trans-unit>
        <trans-unit id="ae286e88bfa268243cfd38132ccb40e58428bfed" translate="yes" xml:space="preserve">
          <source>Indicate that transform should forward the y argument to the inner callable.</source>
          <target state="translated">Indicar que la transformación debe reenviar el argumento y a la llamada interior.</target>
        </trans-unit>
        <trans-unit id="9d241566a403a6506d3449cf17d407da2b6e2613" translate="yes" xml:space="preserve">
          <source>Indicates an ordering for the class labels</source>
          <target state="translated">Indica un orden para las etiquetas de clase</target>
        </trans-unit>
        <trans-unit id="5daac4dde04b0b12288306e9a52dc06ec04c0c8f" translate="yes" xml:space="preserve">
          <source>Indicates an ordering for the class labels. All entries should be unique (cannot contain duplicate classes).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1159dbae1b402de01888d0798e1ed328834a2b28" translate="yes" xml:space="preserve">
          <source>Indicates the monotonic constraint to enforce on each feature. -1, 1 and 0 respectively correspond to a positive constraint, negative constraint and no constraint. Read more in the &lt;a href=&quot;../ensemble#monotonic-cst-gbdt&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61bd4246c5310fe8fe14b7816d8991bfb310307e" translate="yes" xml:space="preserve">
          <source>Indicator used to add binary indicators for missing values. &lt;code&gt;None&lt;/code&gt; if add_indicator is False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f992c130abda366b807271662ae2ae17c7305e7" translate="yes" xml:space="preserve">
          <source>Indices according to which X will be subsampled.</source>
          <target state="translated">Índices según los cuales X será submuestreado.</target>
        </trans-unit>
        <trans-unit id="13d9e5d82e7cab8325fb7843fa12831d259a69f1" translate="yes" xml:space="preserve">
          <source>Indices of &lt;code&gt;components_&lt;/code&gt; in the training set.</source>
          <target state="translated">&amp;Iacute;ndices de &lt;code&gt;components_&lt;/code&gt; en el conjunto de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="eeb5984b85169d88759ac10f7fe9d10f5246bc74" translate="yes" xml:space="preserve">
          <source>Indices of active variables at the end of the path.</source>
          <target state="translated">Índices de variables activas al final del camino.</target>
        </trans-unit>
        <trans-unit id="fff8cc57ffbca371ebcb1bd938597e8d339ff509" translate="yes" xml:space="preserve">
          <source>Indices of cluster centers</source>
          <target state="translated">Índices de los centros de clústeres</target>
        </trans-unit>
        <trans-unit id="2c68ceeb78b6311d290c266259420efe85138435" translate="yes" xml:space="preserve">
          <source>Indices of columns in the dataset that belong to the bicluster.</source>
          <target state="translated">Índices de columnas en el conjunto de datos que pertenecen al bicluster.</target>
        </trans-unit>
        <trans-unit id="d4d2ad6637f8190da67b396b7e452baac4f7558f" translate="yes" xml:space="preserve">
          <source>Indices of core samples.</source>
          <target state="translated">Índices de muestras del núcleo.</target>
        </trans-unit>
        <trans-unit id="82cd4a5510ba380bec1e554cdeb5d721222207d6" translate="yes" xml:space="preserve">
          <source>Indices of features for a given plot. A tuple of one integer will plot a partial dependence curve of one feature. A tuple of two integers will plot a two-way partial dependence curve as a contour plot.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c71c298055da26ecac09942b9115f5fc73f7640d" translate="yes" xml:space="preserve">
          <source>Indices of rows in the dataset that belong to the bicluster.</source>
          <target state="translated">Índices de filas en el conjunto de datos que pertenecen al bicluster.</target>
        </trans-unit>
        <trans-unit id="d9c7ee7b4f1a89fde0903f47c0111e0985a4d274" translate="yes" xml:space="preserve">
          <source>Indices of samples used when training the estimators. &lt;code&gt;None&lt;/code&gt; when &lt;code&gt;estimator&lt;/code&gt; does not have &lt;code&gt;_pairwise&lt;/code&gt; attribute.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5ecd973c55633f90c97a971f74a80fe11af3310" translate="yes" xml:space="preserve">
          <source>Indices of support vectors.</source>
          <target state="translated">Índices de vectores de apoyo.</target>
        </trans-unit>
        <trans-unit id="9ccd80ce2c5e0529264583d000f7c9651892271d" translate="yes" xml:space="preserve">
          <source>Indices of the approximate nearest points in the population matrix.</source>
          <target state="translated">Índices de los puntos más cercanos aproximados en la matriz de población.</target>
        </trans-unit>
        <trans-unit id="94147abfa5127a12fe3c3b0c7153a32b171d401a" translate="yes" xml:space="preserve">
          <source>Indices of the nearest points in the population matrix.</source>
          <target state="translated">Índices de los puntos más cercanos en la matriz de población.</target>
        </trans-unit>
        <trans-unit id="3db97f5586a1b88a52d6998bdcb68ce6424bd44e" translate="yes" xml:space="preserve">
          <source>Individual decision trees can be interpreted easily by simply visualizing the tree structure. Gradient boosting models, however, comprise hundreds of regression trees thus they cannot be easily interpreted by visual inspection of the individual trees. Fortunately, a number of techniques have been proposed to summarize and interpret gradient boosting models.</source>
          <target state="translated">Los árboles de decisión individuales pueden interpretarse fácilmente con sólo visualizar la estructura del árbol.Sin embargo,los modelos de potenciación de gradientes comprenden cientos de árboles de regresión,por lo que no pueden interpretarse fácilmente mediante la inspección visual de los árboles individuales.Afortunadamente,se han propuesto varias técnicas para resumir e interpretar los modelos de potenciación de gradientes.</target>
        </trans-unit>
        <trans-unit id="dda28c621b6ebb6a75808a25ba823af15c148423" translate="yes" xml:space="preserve">
          <source>Individual decision trees intrinsically perform feature selection by selecting appropriate split points. This information can be used to measure the importance of each feature; the basic idea is: the more often a feature is used in the split points of a tree the more important that feature is. This notion of importance can be extended to decision tree ensembles by simply averaging the feature importance of each tree (see &lt;a href=&quot;#random-forest-feature-importance&quot;&gt;Feature importance evaluation&lt;/a&gt; for more details).</source>
          <target state="translated">Los &amp;aacute;rboles de decisi&amp;oacute;n individuales realizan intr&amp;iacute;nsecamente la selecci&amp;oacute;n de caracter&amp;iacute;sticas mediante la selecci&amp;oacute;n de puntos de divisi&amp;oacute;n apropiados. Esta informaci&amp;oacute;n se puede utilizar para medir la importancia de cada caracter&amp;iacute;stica; la idea b&amp;aacute;sica es: cuanto m&amp;aacute;s a menudo se usa una caracter&amp;iacute;stica en los puntos de divisi&amp;oacute;n de un &amp;aacute;rbol, m&amp;aacute;s importante es esa caracter&amp;iacute;stica. Esta noci&amp;oacute;n de importancia se puede extender a los conjuntos de &amp;aacute;rboles de decisi&amp;oacute;n simplemente promediando la importancia de la caracter&amp;iacute;stica de cada &amp;aacute;rbol (consulte &lt;a href=&quot;#random-forest-feature-importance&quot;&gt;Evaluaci&amp;oacute;n de la importancia de la caracter&amp;iacute;stica&lt;/a&gt; para obtener m&amp;aacute;s detalles).</target>
        </trans-unit>
        <trans-unit id="a4ca1ad4d7f055ed4989788bfa5efeb8e8f28cc3" translate="yes" xml:space="preserve">
          <source>Individual decision trees intrinsically perform feature selection by selecting appropriate split points. This information can be used to measure the importance of each feature; the basic idea is: the more often a feature is used in the split points of a tree the more important that feature is. This notion of importance can be extended to decision tree ensembles by simply averaging the impurity-based feature importance of each tree (see &lt;a href=&quot;#random-forest-feature-importance&quot;&gt;Feature importance evaluation&lt;/a&gt; for more details).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3bee3019e098ad6b65e2ff793a0e712b529b8f1" translate="yes" xml:space="preserve">
          <source>Individual samples are assumed to be files stored a two levels folder structure such as the following:</source>
          <target state="translated">Se supone que las muestras individuales son archivos almacenados en una estructura de carpetas de dos niveles como la siguiente:</target>
        </trans-unit>
        <trans-unit id="675958cddf4afedd9b3304a64c0ebf41aefd317c" translate="yes" xml:space="preserve">
          <source>Individual steps may also be replaced as parameters, and non-final steps may be ignored by setting them to &lt;code&gt;'passthrough'&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0fc01010c6e24d626cecdd62fd33ec75c0c929c" translate="yes" xml:space="preserve">
          <source>Individual steps may also be replaced as parameters, and non-final steps may be ignored by setting them to &lt;code&gt;None&lt;/code&gt;:</source>
          <target state="translated">Los pasos individuales tambi&amp;eacute;n se pueden reemplazar como par&amp;aacute;metros, y los pasos no finales se pueden ignorar configur&amp;aacute;ndolos en &lt;code&gt;None&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="1005c12f11beba0f3b6f9dd6a7112c31b922588d" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample</source>
          <target state="translated">Pesos individuales para cada muestra</target>
        </trans-unit>
        <trans-unit id="1fda26bba39629c5adc019bfeebf23b6ea1cae92" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample raises error if sample_weight is passed and base_estimator fit method does not support it.</source>
          <target state="translated">Los pesos individuales de cada muestra aumentan el error si se pasa el peso de la muestra y el método de ajuste del estimador base no lo admite.</target>
        </trans-unit>
        <trans-unit id="fa75f1e4d13933a19ded3aa860129fc7cab3ed7d" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample, ignored if None is passed.</source>
          <target state="translated">Pesos individuales para cada muestra,ignorados si no se aprueba ninguna.</target>
        </trans-unit>
        <trans-unit id="00c4a167764cbf2ab25348f070ffdca6c4a1b160" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample. If given a float, every sample will have the same weight.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f445327eb6fc51f2a25624b484ae69f8950143fb" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample. If given a float, every sample will have the same weight. If sample_weight is not None and solver=&amp;rsquo;auto&amp;rsquo;, the solver will be set to &amp;lsquo;cholesky&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="718e842694bb04faf5cc021c83e29c576f98c12d" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample. If sample_weight is not None and solver=&amp;rsquo;auto&amp;rsquo;, the solver will be set to &amp;lsquo;cholesky&amp;rsquo;.</source>
          <target state="translated">Pesos individuales para cada muestra. Si sample_weight no es None y solver = 'auto', el solucionador se establecer&amp;aacute; en 'cholesky'.</target>
        </trans-unit>
        <trans-unit id="080f186426dd365e06ebdb64bb4da000ce313de8" translate="yes" xml:space="preserve">
          <source>Inductive Clustering</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="390c151b41ae038aa81f8d4fccaa7e2c366dd521" translate="yes" xml:space="preserve">
          <source>Inertia can be recognized as a measure of how internally coherent clusters are. It suffers from various drawbacks:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4facccaf3ac8930794a0b5d15e4cd633a166965" translate="yes" xml:space="preserve">
          <source>Inertia is not a normalized metric: we just know that lower values are better and zero is optimal. But in very high-dimensional spaces, Euclidean distances tend to become inflated (this is an instance of the so-called &amp;ldquo;curse of dimensionality&amp;rdquo;). Running a dimensionality reduction algorithm such as &lt;a href=&quot;decomposition#pca&quot;&gt;Principal component analysis (PCA)&lt;/a&gt; prior to k-means clustering can alleviate this problem and speed up the computations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f221e5d04a99f60098722e2605a369c8541e6c9c" translate="yes" xml:space="preserve">
          <source>Inertia is not a normalized metric: we just know that lower values are better and zero is optimal. But in very high-dimensional spaces, Euclidean distances tend to become inflated (this is an instance of the so-called &amp;ldquo;curse of dimensionality&amp;rdquo;). Running a dimensionality reduction algorithm such as &lt;a href=&quot;pca&quot;&gt;PCA&lt;/a&gt; prior to k-means clustering can alleviate this problem and speed up the computations.</source>
          <target state="translated">La inercia no es una m&amp;eacute;trica normalizada: solo sabemos que los valores m&amp;aacute;s bajos son mejores y cero es &amp;oacute;ptimo. Pero en espacios de muy alta dimensi&amp;oacute;n, las distancias euclidianas tienden a inflarse (este es un ejemplo de la llamada &quot;maldici&amp;oacute;n de la dimensionalidad&quot;). La ejecuci&amp;oacute;n de un algoritmo de reducci&amp;oacute;n de dimensionalidad como &lt;a href=&quot;pca&quot;&gt;PCA&lt;/a&gt; antes de la agrupaci&amp;oacute;n de k-medias puede aliviar este problema y acelerar los c&amp;aacute;lculos.</target>
        </trans-unit>
        <trans-unit id="e010b0c9058bbaf9975d3f14818f3861029f83a1" translate="yes" xml:space="preserve">
          <source>Inertia makes the assumption that clusters are convex and isotropic, which is not always the case. It responds poorly to elongated clusters, or manifolds with irregular shapes.</source>
          <target state="translated">La inercia supone que los cúmulos son convexos e isotrópicos,lo que no siempre es así.Responde mal a los cúmulos alargados,o a los colectores de formas irregulares.</target>
        </trans-unit>
        <trans-unit id="2d57b1c4d1f958efe3710f23677dd552a8a1384c" translate="yes" xml:space="preserve">
          <source>Inertia, or the within-cluster sum of squares criterion, can be recognized as a measure of how internally coherent clusters are. It suffers from various drawbacks:</source>
          <target state="translated">La inercia,o el criterio de la suma de cuadrados dentro del cúmulo,puede reconocerse como una medida de la coherencia interna de los cúmulos.Sufre de varios inconvenientes:</target>
        </trans-unit>
        <trans-unit id="1b9b7d4cd56309d7954eee8c5d88a8d58559a22d" translate="yes" xml:space="preserve">
          <source>Inference of the model can be time consuming.</source>
          <target state="translated">La inferencia del modelo puede llevar mucho tiempo.</target>
        </trans-unit>
        <trans-unit id="52570031388abf13077117eb25231bb2412ec6ba" translate="yes" xml:space="preserve">
          <source>Inferred batch size from &lt;code&gt;batch_size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3406f3eade82db35711ae0ecbcd4dea59f7e1be" translate="yes" xml:space="preserve">
          <source>Inferred value for &lt;code&gt;increasing&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f5d2c4b74b9f6de8f1a369f5793fd5ad3db1bd0" translate="yes" xml:space="preserve">
          <source>Influence of outliers on location and covariance estimates</source>
          <target state="translated">Influencia de los valores atípicos en las estimaciones de localización y covarianza</target>
        </trans-unit>
        <trans-unit id="b8c700f6663aab653644d35fb6aa9a0e53919c01" translate="yes" xml:space="preserve">
          <source>Information on how to contribute. This also contains useful information for advanced users, for example how to build their own estimators.</source>
          <target state="translated">Información sobre cómo contribuir.También contiene información útil para los usuarios avanzados,por ejemplo,cómo construir sus propios estimadores.</target>
        </trans-unit>
        <trans-unit id="c4fbdb7aab44015fbed39936864f9255a99074c1" translate="yes" xml:space="preserve">
          <source>Information-criterion based model selection is very fast, but it relies on a proper estimation of degrees of freedom, are derived for large samples (asymptotic results) and assume the model is correct, i.e. that the data are actually generated by this model. They also tend to break when the problem is badly conditioned (more features than samples).</source>
          <target state="translated">La selección del modelo basado en criterios de información es muy rápida,pero se basa en una estimación adecuada de los grados de libertad,se derivan para muestras grandes (resultados asintóticos)y se supone que el modelo es correcto,es decir,que los datos son realmente generados por este modelo.También tienden a romperse cuando el problema está mal condicionado (más características que muestras).</target>
        </trans-unit>
        <trans-unit id="132062fafb54cb7d1e8b42d922906ff561bc3d9c" translate="yes" xml:space="preserve">
          <source>Inherits from SGDClassifier. &lt;code&gt;Perceptron()&lt;/code&gt; is equivalent to &lt;code&gt;SGDClassifier(loss=&quot;perceptron&quot;, eta0=1, learning_rate=&quot;constant&quot;, penalty=None)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="897de0e7da29095e5d730f2c7102743d023bc056" translate="yes" xml:space="preserve">
          <source>Initial value for alpha (precision of the noise). If not set, alpha_init is 1/Var(y).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5584ccc82484d2c61a85300c7acd35cb5205fef6" translate="yes" xml:space="preserve">
          <source>Initial value for lambda (precision of the weights). If not set, lambda_init is 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="168bf67b39abe0e5515698a4ec915c75e07ca524" translate="yes" xml:space="preserve">
          <source>Initial value for the dictionary for warm restart scenarios.</source>
          <target state="translated">Valor inicial del diccionario para los escenarios de reinicio en caliente.</target>
        </trans-unit>
        <trans-unit id="64b2b9f72c239478fc1b9e586ac8147218ca87bd" translate="yes" xml:space="preserve">
          <source>Initial value for the sparse code for warm restart scenarios.</source>
          <target state="translated">Valor inicial del código escaso para los escenarios de reinicio en caliente.</target>
        </trans-unit>
        <trans-unit id="1a6282c9a9baf1c9231fe6132d9510c0860835e2" translate="yes" xml:space="preserve">
          <source>Initial values for the components for warm restart scenarios.</source>
          <target state="translated">Valores iniciales de los componentes para los escenarios de reinicio en caliente.</target>
        </trans-unit>
        <trans-unit id="ff1f0a80e07dd6cd648bd3a5e935a909ec2cb299" translate="yes" xml:space="preserve">
          <source>Initial values for the loadings for warm restart scenarios.</source>
          <target state="translated">Valores iniciales de las cargas para los escenarios de reinicio en caliente.</target>
        </trans-unit>
        <trans-unit id="e597ad1e68022a1929058718fd92959e281b3619" translate="yes" xml:space="preserve">
          <source>Initialization of embedding. Possible options are &amp;lsquo;random&amp;rsquo;, &amp;lsquo;pca&amp;rsquo;, and a numpy array of shape (n_samples, n_components). PCA initialization cannot be used with precomputed distances and is usually more globally stable than random initialization.</source>
          <target state="translated">Inicializaci&amp;oacute;n de incrustaci&amp;oacute;n. Las opciones posibles son 'aleatorio', 'pca' y una gran variedad de formas (n_samples, n_components). La inicializaci&amp;oacute;n de PCA no se puede utilizar con distancias precalculadas y suele ser m&amp;aacute;s estable globalmente que la inicializaci&amp;oacute;n aleatoria.</target>
        </trans-unit>
        <trans-unit id="726483459f359a8ededc78286c7835b11430e40a" translate="yes" xml:space="preserve">
          <source>Initialization of the linear transformation. Possible options are &amp;lsquo;auto&amp;rsquo;, &amp;lsquo;pca&amp;rsquo;, &amp;lsquo;lda&amp;rsquo;, &amp;lsquo;identity&amp;rsquo;, &amp;lsquo;random&amp;rsquo;, and a numpy array of shape (n_features_a, n_features_b).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e644154875d3e41452e4b87177ec7a98e4e47540" translate="yes" xml:space="preserve">
          <source>Initialization value for coefficients of logistic regression. Useless for liblinear solver.</source>
          <target state="translated">Valor de inicialización de los coeficientes de regresión logística.Inútil para el solucionador liblineal.</target>
        </trans-unit>
        <trans-unit id="ed7011971816dd0f1903ad54a411facedaee4ded" translate="yes" xml:space="preserve">
          <source>Initialization value of the sparse codes. Only used if &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt;.</source>
          <target state="translated">Valor de inicializaci&amp;oacute;n de los c&amp;oacute;digos dispersos. Solo se usa si &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8989f9ab8650a480a58e2f03b20f1b5428df4549" translate="yes" xml:space="preserve">
          <source>Initialization value of the sparse codes. Only used if &lt;code&gt;algorithm='lasso_cd'&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f66672d1a211feccb2663e524389cc7bbdc9544" translate="yes" xml:space="preserve">
          <source>Initialize self. See help(type(self)) for accurate signature.</source>
          <target state="translated">Iniciarse.Ver ayuda para una firma precisa.</target>
        </trans-unit>
        <trans-unit id="ccac906d8789727d67e839b8a0f34db2f9002a71" translate="yes" xml:space="preserve">
          <source>Initializing components, sampling from layers during fit.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4694fddfebcd07057574f3bedbe073aecef8cbe" translate="yes" xml:space="preserve">
          <source>Inliers are labeled 1, while outliers are labeled -1. The predict method makes use of a threshold on the raw scoring function computed by the estimator. This scoring function is accessible through the &lt;code&gt;score_samples&lt;/code&gt; method, while the threshold can be controlled by the &lt;code&gt;contamination&lt;/code&gt; parameter.</source>
          <target state="translated">Los valores internos est&amp;aacute;n etiquetados como 1, mientras que los valores at&amp;iacute;picos est&amp;aacute;n etiquetados como -1. El m&amp;eacute;todo de predicci&amp;oacute;n utiliza un umbral en la funci&amp;oacute;n de puntuaci&amp;oacute;n bruta calculada por el estimador. Esta funci&amp;oacute;n de puntuaci&amp;oacute;n es accesible a trav&amp;eacute;s del m&amp;eacute;todo &lt;code&gt;score_samples&lt;/code&gt; , mientras que el umbral se puede controlar mediante el par&amp;aacute;metro de &lt;code&gt;contamination&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2495be2cc170e277a5d9d5dd99a3f779ff0175c9" translate="yes" xml:space="preserve">
          <source>Inner sufficient statistics that are kept by the algorithm. Passing them at initialization is useful in online settings, to avoid loosing the history of the evolution. A (n_components, n_components) is the dictionary covariance matrix. B (n_features, n_components) is the data approximation matrix</source>
          <target state="translated">Las suficientes estadísticas internas que se mantienen por el algoritmo.Pasarlas en la inicialización es útil en los entornos en línea,para no perder la historia de la evolución.A (n_componentes,n_componentes)es la matriz de covarianza del diccionario.B (n_características,n_componentes)es la matriz de aproximación de datos</target>
        </trans-unit>
        <trans-unit id="06dcf06c32dda54c31aa74eee694be9763d822e4" translate="yes" xml:space="preserve">
          <source>Inner sufficient statistics that are kept by the algorithm. Passing them at initialization is useful in online settings, to avoid losing the history of the evolution. A (n_components, n_components) is the dictionary covariance matrix. B (n_features, n_components) is the data approximation matrix</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4cb705151cf2a5dcfea8029a0e74d39c67469fa5" translate="yes" xml:space="preserve">
          <source>Inplace column scaling of a CSC/CSR matrix.</source>
          <target state="translated">Columna de escalado en el lugar de una matriz CSC/CSR.</target>
        </trans-unit>
        <trans-unit id="15ad21d3f40808b965488683b0faaff07ad4b5e9" translate="yes" xml:space="preserve">
          <source>Inplace column scaling of a CSR matrix.</source>
          <target state="translated">Columna de escalado en el lugar de una matriz de CSR.</target>
        </trans-unit>
        <trans-unit id="75290bdbc975498c98c7572ec067e43ddceb0c68" translate="yes" xml:space="preserve">
          <source>Inplace row normalize using the l1 norm</source>
          <target state="translated">La fila del lugar se normaliza usando la norma l1</target>
        </trans-unit>
        <trans-unit id="bc0180825da8415aba8c76f27c29d7e471b70c2a" translate="yes" xml:space="preserve">
          <source>Inplace row normalize using the l2 norm</source>
          <target state="translated">La fila del lugar se normaliza usando la norma l2</target>
        </trans-unit>
        <trans-unit id="d91ae689358e283ef6d343e24e55244f1fb1cad2" translate="yes" xml:space="preserve">
          <source>Inplace row scaling of a CSR or CSC matrix.</source>
          <target state="translated">En el lugar de la fila de escalado de una matriz de CSR o CSC.</target>
        </trans-unit>
        <trans-unit id="16ca749420dd58126c1f3f4ccf95ce2fc49387c9" translate="yes" xml:space="preserve">
          <source>Input array.</source>
          <target state="translated">Matriz de entrada.</target>
        </trans-unit>
        <trans-unit id="f6fcca00499ce6b21e6114d56b450f6d3d43ccb2" translate="yes" xml:space="preserve">
          <source>Input checker utility for building a cross-validator</source>
          <target state="translated">Utilidad de verificación de entrada para construir un validador cruzado</target>
        </trans-unit>
        <trans-unit id="3f43a2e4863dbf39da8cfbd5e4e557f3052ec269" translate="yes" xml:space="preserve">
          <source>Input data</source>
          <target state="translated">Datos de entrada</target>
        </trans-unit>
        <trans-unit id="a2e2ac083ce3186e216de5448418ffc50e83a494" translate="yes" xml:space="preserve">
          <source>Input data for prediction.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41aa04ac5754100b497c803419573444b7e1d42b" translate="yes" xml:space="preserve">
          <source>Input data representation and sparsity</source>
          <target state="translated">La representación de los datos de entrada y la escasez</target>
        </trans-unit>
        <trans-unit id="66a8a4e34fe15bd5eafb5d984d77b9c0e3866728" translate="yes" xml:space="preserve">
          <source>Input data that will be transformed.</source>
          <target state="translated">Introducir datos que se transformarán.</target>
        </trans-unit>
        <trans-unit id="fbb05f66a147e8520f226c078931507f60d0caac" translate="yes" xml:space="preserve">
          <source>Input data that will be transformed. It cannot be sparse.</source>
          <target state="translated">Introducir datos que se transformarán.No pueden ser escasos.</target>
        </trans-unit>
        <trans-unit id="1e3e0a570b83c9cbe639106afeb9bedd23e3fcfd" translate="yes" xml:space="preserve">
          <source>Input data to be transformed.</source>
          <target state="translated">Datos de entrada para ser transformados.</target>
        </trans-unit>
        <trans-unit id="071feefe9143dba47a473de169ba49367bfce443" translate="yes" xml:space="preserve">
          <source>Input data to be transformed. Use &lt;code&gt;dtype=np.float32&lt;/code&gt; for maximum efficiency. Sparse matrices are also supported, use sparse &lt;code&gt;csr_matrix&lt;/code&gt; for maximum efficiency.</source>
          <target state="translated">Datos de entrada a transformar. Utilice &lt;code&gt;dtype=np.float32&lt;/code&gt; para obtener la m&amp;aacute;xima eficiencia. Tambi&amp;eacute;n se admiten matrices dispersas, use &lt;code&gt;csr_matrix&lt;/code&gt; disperso para una m&amp;aacute;xima eficiencia.</target>
        </trans-unit>
        <trans-unit id="688f24dc1e25fac1dc510cf29e6e51a5cdee42ba" translate="yes" xml:space="preserve">
          <source>Input data used to build forests. Use &lt;code&gt;dtype=np.float32&lt;/code&gt; for maximum efficiency.</source>
          <target state="translated">Datos de entrada utilizados para construir bosques. Utilice &lt;code&gt;dtype=np.float32&lt;/code&gt; para obtener la m&amp;aacute;xima eficiencia.</target>
        </trans-unit>
        <trans-unit id="ece9df27fcdc2d8935842ef4ed6ac1e8d53f8b6c" translate="yes" xml:space="preserve">
          <source>Input data, of which specified subsets are used to fit the transformers.</source>
          <target state="translated">Datos de entrada,de los cuales se utilizan subconjuntos específicos para ajustar los transformadores.</target>
        </trans-unit>
        <trans-unit id="8c020a67c0398f86d112987222d02c36283701ba" translate="yes" xml:space="preserve">
          <source>Input data, target values.</source>
          <target state="translated">Datos de entrada,valores objetivo.</target>
        </trans-unit>
        <trans-unit id="0d15fc28721eb2bcf2d53de59215da674d786463" translate="yes" xml:space="preserve">
          <source>Input data, used to fit transformers.</source>
          <target state="translated">Datos de entrada,usados para ajustar los transformadores.</target>
        </trans-unit>
        <trans-unit id="6db69e17f58030ae15478a3e504e982203a8ead7" translate="yes" xml:space="preserve">
          <source>Input data, where &amp;ldquo;n_samples&amp;rdquo; is the number of samples and &amp;ldquo;n_features&amp;rdquo; is the number of features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aee2f5203193bb3069f6e2f7b08e833e91d53841" translate="yes" xml:space="preserve">
          <source>Input data, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the number of features.</source>
          <target state="translated">Datos de entrada, donde &lt;code&gt;n_samples&lt;/code&gt; es el n&amp;uacute;mero de muestras y &lt;code&gt;n_features&lt;/code&gt; es el n&amp;uacute;mero de caracter&amp;iacute;sticas.</target>
        </trans-unit>
        <trans-unit id="8f9c683e36e31c7c38c7e8d6a2daeccf181d4c94" translate="yes" xml:space="preserve">
          <source>Input data, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">Datos de entrada,donde n_muestras es el número de muestras y n_características es el número de características.</target>
        </trans-unit>
        <trans-unit id="260753716624ad2077f13f38ada17a33c0f48cba" translate="yes" xml:space="preserve">
          <source>Input data.</source>
          <target state="translated">Datos de entrada.</target>
        </trans-unit>
        <trans-unit id="c414149f534c72aa4d2016c93404604f17aa41fd" translate="yes" xml:space="preserve">
          <source>Input data. Columns are assumed to have unit norm.</source>
          <target state="translated">Datos de entrada.Se supone que las columnas tienen una norma de unidad.</target>
        </trans-unit>
        <trans-unit id="fc921091c020b61d18864b21129c4eb989ef6d69" translate="yes" xml:space="preserve">
          <source>Input data. If &lt;code&gt;None&lt;/code&gt;, the output will be the pairwise similarities between all samples in &lt;code&gt;X&lt;/code&gt;.</source>
          <target state="translated">Datos de entrada. Si &lt;code&gt;None&lt;/code&gt; , la salida ser&amp;aacute; la similitud por pares entre todas las muestras en &lt;code&gt;X&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="afaf08d18a1423dc1a78bf3492e5ce0eb50d8638" translate="yes" xml:space="preserve">
          <source>Input data. If &lt;code&gt;dissimilarity=='precomputed'&lt;/code&gt;, the input should be the dissimilarity matrix.</source>
          <target state="translated">Datos de entrada. Si la &lt;code&gt;dissimilarity=='precomputed'&lt;/code&gt; , la entrada debe ser la matriz de disimilitud.</target>
        </trans-unit>
        <trans-unit id="c7e2acaca5145e47486c9c2928ab5532aee98fd4" translate="yes" xml:space="preserve">
          <source>Input data. If X is not provided, only the global clustering step is done.</source>
          <target state="translated">Datos de entrada.Si no se proporciona X,sólo se realiza el paso de agrupación global.</target>
        </trans-unit>
        <trans-unit id="609eafdfc25268bf81369faed57dc8b7d067fce7" translate="yes" xml:space="preserve">
          <source>Input data. Note that if X is None then the Gram matrix must be specified, i.e., cannot be None or False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d39fe8b9c923e952612de77f70ad5aff60c34542" translate="yes" xml:space="preserve">
          <source>Input object to check / convert.</source>
          <target state="translated">Introducir objeto para comprobar/convertir.</target>
        </trans-unit>
        <trans-unit id="ca7fd27e447d5e335b2e80d1b2bb1406dceac239" translate="yes" xml:space="preserve">
          <source>Input object to check / convert. Must be two-dimensional and square, otherwise a ValueError will be raised.</source>
          <target state="translated">Introducir el objeto para comprobar/convertir.Debe ser bidimensional y cuadrado,de lo contrario se producirá un error de valor.</target>
        </trans-unit>
        <trans-unit id="f24bf584af83fad1f47a5035ff05cdc62fd1daef" translate="yes" xml:space="preserve">
          <source>Input points.</source>
          <target state="translated">Puntos de entrada.</target>
        </trans-unit>
        <trans-unit id="71b2d21e1f2e71c0dcf88bd09dfe9ef6fd499ea3" translate="yes" xml:space="preserve">
          <source>Input targets</source>
          <target state="translated">Objetivos de entrada</target>
        </trans-unit>
        <trans-unit id="b58e4bce1b7ebb41f970a06dbe933522f9ad2c46" translate="yes" xml:space="preserve">
          <source>Input targets multiplied by X: X.T * y</source>
          <target state="translated">Objetivos de entrada multiplicados por X:X.T*y</target>
        </trans-unit>
        <trans-unit id="69a0e9f3a009e8ccbba64367545e9fbe88306b19" translate="yes" xml:space="preserve">
          <source>Input targets.</source>
          <target state="translated">Objetivos de entrada.</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
