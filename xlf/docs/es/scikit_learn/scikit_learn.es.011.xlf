<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="es" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="4fae2d49ee8a5e8d8ea52343db3e2b05ff45988e" translate="yes" xml:space="preserve">
          <source>Fit the ridge classifier.</source>
          <target state="translated">Encaja con el clasificador de cresta.</target>
        </trans-unit>
        <trans-unit id="2b96765d688b574c756064537ec2686c8ac36571" translate="yes" xml:space="preserve">
          <source>Fit the transformer on X.</source>
          <target state="translated">Ponga el transformador en X.</target>
        </trans-unit>
        <trans-unit id="acd485cd941415835a11d2180278c2146ce5888c" translate="yes" xml:space="preserve">
          <source>Fit the weights of a regression model, using an ARD prior. The weights of the regression model are assumed to be in Gaussian distributions. Also estimate the parameters lambda (precisions of the distributions of the weights) and alpha (precision of the distribution of the noise). The estimation is done by an iterative procedures (Evidence Maximization)</source>
          <target state="translated">Ajustar los pesos de un modelo de regresión,usando un previo ARD.Se supone que los pesos del modelo de regresión están en las distribuciones gaussianas.También se estiman los parámetros lambda (precisiones de las distribuciones de los pesos)y alfa (precisión de la distribución del ruido).La estimación se realiza mediante un procedimiento iterativo (Maximización de la evidencia)</target>
        </trans-unit>
        <trans-unit id="ea18404b90123396c3f41537d11afad54c507780" translate="yes" xml:space="preserve">
          <source>Fit to data, then transform it.</source>
          <target state="translated">Ajustar a los datos,luego transformarlos.</target>
        </trans-unit>
        <trans-unit id="c2cf341635a3875675d46dd618b9a1757d9a6c7c" translate="yes" xml:space="preserve">
          <source>Fit transformer by checking X.</source>
          <target state="translated">Ajustar el transformador comprobando X.</target>
        </trans-unit>
        <trans-unit id="eb75d7eb91b3dadf245e1b3bf8f4c37a27824085" translate="yes" xml:space="preserve">
          <source>Fit underlying estimators.</source>
          <target state="translated">Ajustar los estimadores subyacentes.</target>
        </trans-unit>
        <trans-unit id="c093c0cee7f3b9fa93ffb32acb026baea322889f" translate="yes" xml:space="preserve">
          <source>Fits a Minimum Covariance Determinant with the FastMCD algorithm.</source>
          <target state="translated">Se ajusta a un determinante de covarianza mínima con el algoritmo FastMCD.</target>
        </trans-unit>
        <trans-unit id="f30506afc59d08eae550fdeb02ae856731ea996b" translate="yes" xml:space="preserve">
          <source>Fits all the transforms one after the other and transforms the data, then uses fit_transform on transformed data with the final estimator.</source>
          <target state="translated">Encaja todas las transformaciones una tras otra y transforma los datos,luego usa fit_transform sobre los datos transformados con el estimador final.</target>
        </trans-unit>
        <trans-unit id="c5c1cc9c0352ec3e2d5fcc0df63b71ce152f382f" translate="yes" xml:space="preserve">
          <source>Fits the GraphicalLasso covariance model to X.</source>
          <target state="translated">Encaja con el modelo de covarianza de GraphicalLasso en X.</target>
        </trans-unit>
        <trans-unit id="268ae9ae0a9043d80b2e575c7e344f83f78e662d" translate="yes" xml:space="preserve">
          <source>Fits the GraphicalLasso model to X.</source>
          <target state="translated">Encaja con el modelo de GraphicalLasso en X.</target>
        </trans-unit>
        <trans-unit id="643e04850030e1e1aeeaf619a88e7dab7e6a06be" translate="yes" xml:space="preserve">
          <source>Fits the Ledoit-Wolf shrunk covariance model according to the given training data and parameters.</source>
          <target state="translated">Se ajusta al modelo de covarianza encogida de Ledoit-Wolf según los datos y parámetros de entrenamiento dados.</target>
        </trans-unit>
        <trans-unit id="60a2c06b8221e361c36d5fdce8ee644d8456bfce" translate="yes" xml:space="preserve">
          <source>Fits the Maximum Likelihood Estimator covariance model according to the given training data and parameters.</source>
          <target state="translated">Se ajusta al modelo de covarianza del Estimador de Máxima Verosimilitud según los datos y parámetros de capacitación dados.</target>
        </trans-unit>
        <trans-unit id="9b00c787fd8f13356df0bf86c478f2b7848ac4d7" translate="yes" xml:space="preserve">
          <source>Fits the Oracle Approximating Shrinkage covariance model according to the given training data and parameters.</source>
          <target state="translated">Se ajusta al modelo de covarianza de encogimiento aproximado de Oracle según los datos y parámetros de entrenamiento dados.</target>
        </trans-unit>
        <trans-unit id="2fb3d8548147a6429a7eeed9e3fbe0456049bc8c" translate="yes" xml:space="preserve">
          <source>Fits the estimator.</source>
          <target state="translated">Encaja con el estimador.</target>
        </trans-unit>
        <trans-unit id="98f6beb1ac87a74b86b8c1fedd5ae0ed0ac89461" translate="yes" xml:space="preserve">
          <source>Fits the shrunk covariance model according to the given training data and parameters.</source>
          <target state="translated">Se ajusta al modelo de covarianza encogida según los datos y parámetros de entrenamiento dados.</target>
        </trans-unit>
        <trans-unit id="f072640da94e1ad56e67373f3632aeaebdd8b854" translate="yes" xml:space="preserve">
          <source>Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.</source>
          <target state="translated">Ajusta el transformador a X e y con parámetros opcionales fit_params y devuelve una versión transformada de X.</target>
        </trans-unit>
        <trans-unit id="fd568de48dadd27cd4e3ca2395da082642e8f8ec" translate="yes" xml:space="preserve">
          <source>Fitted regressor.</source>
          <target state="translated">Un regresor encajado.</target>
        </trans-unit>
        <trans-unit id="14c6da7cd39661e1b0c6468a3c6a5907d4f99a9c" translate="yes" xml:space="preserve">
          <source>Fitting transformers may be computationally expensive. With its &lt;code&gt;memory&lt;/code&gt; parameter set, &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; will cache each transformer after calling &lt;code&gt;fit&lt;/code&gt;. This feature is used to avoid computing the fit transformers within a pipeline if the parameters and input data are identical. A typical example is the case of a grid search in which the transformers can be fitted only once and reused for each configuration.</source>
          <target state="translated">La instalaci&amp;oacute;n de transformadores puede resultar computacionalmente costosa. Con su conjunto de par&amp;aacute;metros de &lt;code&gt;memory&lt;/code&gt; , &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;Pipeline&lt;/code&gt; &lt;/a&gt; almacenar&amp;aacute; en cach&amp;eacute; cada transformador despu&amp;eacute;s de llamar a &lt;code&gt;fit&lt;/code&gt; . Esta funci&amp;oacute;n se utiliza para evitar calcular los transformadores de ajuste dentro de una tuber&amp;iacute;a si los par&amp;aacute;metros y los datos de entrada son id&amp;eacute;nticos. Un ejemplo t&amp;iacute;pico es el caso de una b&amp;uacute;squeda de red en la que los transformadores pueden instalarse una sola vez y reutilizarse para cada configuraci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="01fe05c223cb56d84d085e38ca62de1932a87e50" translate="yes" xml:space="preserve">
          <source>Flag indicating if the cross-validation values corresponding to each alpha should be stored in the &lt;code&gt;cv_values_&lt;/code&gt; attribute (see below). This flag is only compatible with &lt;code&gt;cv=None&lt;/code&gt; (i.e. using Generalized Cross-Validation).</source>
          <target state="translated">Bandera que indica si los valores de validaci&amp;oacute;n cruzada correspondientes a cada alfa deben almacenarse en el atributo &lt;code&gt;cv_values_&lt;/code&gt; (ver m&amp;aacute;s abajo). Esta bandera solo es compatible con &lt;code&gt;cv=None&lt;/code&gt; (es decir, con validaci&amp;oacute;n cruzada generalizada).</target>
        </trans-unit>
        <trans-unit id="1f498759924682e2363e94f7b83282b97429fcf5" translate="yes" xml:space="preserve">
          <source>Flag indicating which strategy to use when performing Generalized Cross-Validation. Options are:</source>
          <target state="translated">Bandera que indica la estrategia a utilizar cuando se realiza la validación cruzada generalizada.Las opciones son:</target>
        </trans-unit>
        <trans-unit id="3407c4421a1f6ede0cab565dc5123546e65ddde6" translate="yes" xml:space="preserve">
          <source>Flat geometry, good for density estimation</source>
          <target state="translated">Geometría plana,buena para la estimación de la densidad</target>
        </trans-unit>
        <trans-unit id="748a38982c93bb25fbfeb18b34277c35439ac98c" translate="yes" xml:space="preserve">
          <source>Flavanoids</source>
          <target state="translated">Flavanoids</target>
        </trans-unit>
        <trans-unit id="f55beb472c3b08362b7861294963760ddd037d08" translate="yes" xml:space="preserve">
          <source>Flavanoids:</source>
          <target state="translated">Flavanoids:</target>
        </trans-unit>
        <trans-unit id="1bf94453d6aa9e9092828eefafa6394692100339" translate="yes" xml:space="preserve">
          <source>Flexible pickling control for the communication to and from the worker processes.</source>
          <target state="translated">Control flexible del decapado para la comunicación con los procesos de los trabajadores.</target>
        </trans-unit>
        <trans-unit id="2d83a2dbf42ef510856c4fe5eb69b3efa4599763" translate="yes" xml:space="preserve">
          <source>Flow Chart</source>
          <target state="translated">Gráfico de flujo</target>
        </trans-unit>
        <trans-unit id="87698cca8f914c77b735bad53fe489d2af135e70" translate="yes" xml:space="preserve">
          <source>Folder to be used by the pool for memmapping large arrays for sharing memory with worker processes. If None, this will try in order:</source>
          <target state="translated">Carpeta para ser usada por el grupo para hacer mapas de grandes matrices para compartir la memoria con los procesos de los trabajadores.Si no hay ninguna,esto se intentará en orden:</target>
        </trans-unit>
        <trans-unit id="313fc38f449c398563f152e4416c92af47202923" translate="yes" xml:space="preserve">
          <source>Follows Algorithm 4.3 of Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions Halko, et al., 2009 (arXiv:909) http://arxiv.org/pdf/0909.4061</source>
          <target state="translated">Sigue el Algoritmo 4.3 de Hallazgo de la estructura con aleatoriedad:Algoritmos estocásticos para la construcción de descomposiciones matriciales aproximadas Halko,et al.,2009 (arXiv:909)http://arxiv.org/pdf/0909.4061</target>
        </trans-unit>
        <trans-unit id="ec0c3b76630fd745381cc215a284820af75a683a" translate="yes" xml:space="preserve">
          <source>Footnotes</source>
          <target state="translated">Footnotes</target>
        </trans-unit>
        <trans-unit id="41e2c901c13d4daacf7c9adad4d559c077a8e51e" translate="yes" xml:space="preserve">
          <source>For &amp;ldquo;one-vs-rest&amp;rdquo; &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; the attributes &lt;code&gt;coef_&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; have the shape &lt;code&gt;[n_class, n_features]&lt;/code&gt; and &lt;code&gt;[n_class]&lt;/code&gt; respectively. Each row of the coefficients corresponds to one of the &lt;code&gt;n_class&lt;/code&gt; many &amp;ldquo;one-vs-rest&amp;rdquo; classifiers and similar for the intercepts, in the order of the &amp;ldquo;one&amp;rdquo; class.</source>
          <target state="translated">Para &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt; &amp;ldquo;one-vs-rest&amp;rdquo;, los atributos &lt;code&gt;coef_&lt;/code&gt; e &lt;code&gt;intercept_&lt;/code&gt; tienen la forma &lt;code&gt;[n_class, n_features]&lt;/code&gt; y &lt;code&gt;[n_class]&lt;/code&gt; respectivamente. Cada fila de los coeficientes corresponde a uno de los muchos &lt;code&gt;n_class&lt;/code&gt; &quot;uno contra resto&quot; de n_class y similares para las intersecciones, en el orden de la clase &quot;uno&quot;.</target>
        </trans-unit>
        <trans-unit id="c6cc35fe8de003f58f84a7c02bbc9d4b652dc227" translate="yes" xml:space="preserve">
          <source>For &amp;ldquo;pairwise&amp;rdquo; metrics, between &lt;em&gt;samples&lt;/em&gt; and not estimators or predictions, see the &lt;a href=&quot;metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt; section.</source>
          <target state="translated">Para conocer las m&amp;eacute;tricas &quot;por pares&quot;, entre &lt;em&gt;muestras&lt;/em&gt; y no estimadores o predicciones, consulte la secci&amp;oacute;n &lt;a href=&quot;metrics#metrics&quot;&gt;M&amp;eacute;tricas&lt;/a&gt; por pares , afinidades y n&amp;uacute;cleos .</target>
        </trans-unit>
        <trans-unit id="935f9d2961eec1b64a8d3f62208c3a16e0e7ef63" translate="yes" xml:space="preserve">
          <source>For &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt;&lt;code&gt;sklearn.ensemble&lt;/code&gt;&lt;/a&gt; of trees (e.g. RandomForest, GBT, ExtraTrees etc) the number of trees and their depth play the most important role. Latency and throughput should scale linearly with the number of trees. In this case we used directly the &lt;code&gt;n_estimators&lt;/code&gt; parameter of &lt;code&gt;sklearn.ensemble.gradient_boosting.GradientBoostingRegressor&lt;/code&gt;.</source>
          <target state="translated">Para &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt; &lt;code&gt;sklearn.ensemble&lt;/code&gt; &lt;/a&gt; de &amp;aacute;rboles (por ejemplo, RandomForest, GBT, ExtraTrees, etc.), el n&amp;uacute;mero de &amp;aacute;rboles y su profundidad juegan el papel m&amp;aacute;s importante. La latencia y el rendimiento deben escalar linealmente con el n&amp;uacute;mero de &amp;aacute;rboles. En este caso utilizamos directamente la &lt;code&gt;n_estimators&lt;/code&gt; par&amp;aacute;metro de &lt;code&gt;sklearn.ensemble.gradient_boosting.GradientBoostingRegressor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c2e53d45d0579b4b39658069206cb04a03ac3808" translate="yes" xml:space="preserve">
          <source>For &lt;a href=&quot;classes#module-sklearn.linear_model&quot;&gt;&lt;code&gt;sklearn.linear_model&lt;/code&gt;&lt;/a&gt; (e.g. Lasso, ElasticNet, SGDClassifier/Regressor, Ridge &amp;amp; RidgeClassifier, PassiveAggressiveClassifier/Regressor, LinearSVC, LogisticRegression&amp;hellip;) the decision function that is applied at prediction time is the same (a dot product) , so latency should be equivalent.</source>
          <target state="translated">Para &lt;a href=&quot;classes#module-sklearn.linear_model&quot;&gt; &lt;code&gt;sklearn.linear_model&lt;/code&gt; &lt;/a&gt; (por ejemplo, Lasso, ElasticNet, SGDClassifier / Regressor, Ridge &amp;amp; RidgeClassifier, PassiveAggressiveClassifier / Regressor, LinearSVC, LogisticRegression ...) la funci&amp;oacute;n de decisi&amp;oacute;n que se aplica en el tiempo de predicci&amp;oacute;n es la misma (un producto escalar), por lo que la latencia debe ser equivalente .</target>
        </trans-unit>
        <trans-unit id="8582a7ae6ed830b76bb2d9fd21363d4d3995f59c" translate="yes" xml:space="preserve">
          <source>For &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; (and &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt;) any input passed as a numpy array will be copied and converted to the liblinear internal sparse data representation (double precision floats and int32 indices of non-zero components). If you want to fit a large-scale linear classifier without copying a dense numpy C-contiguous double precision array as input we suggest to use the &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;SGDClassifier&lt;/code&gt;&lt;/a&gt; class instead. The objective function can be configured to be almost the same as the &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; model.</source>
          <target state="translated">Para &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt; (y &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt; ), cualquier entrada pasada como una matriz num&amp;eacute;rica se copiar&amp;aacute; y convertir&amp;aacute; a la representaci&amp;oacute;n de datos dispersos internos liblinear (flotantes de doble precisi&amp;oacute;n e &amp;iacute;ndices int32 de componentes distintos de cero). Si desea ajustar un clasificador lineal a gran escala sin copiar una matriz de doble precisi&amp;oacute;n contigua C densa y numpy como entrada, le sugerimos que use la clase &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;SGDClassifier&lt;/code&gt; en su&lt;/a&gt; lugar. La funci&amp;oacute;n objetivo se puede configurar para que sea casi igual que el modelo &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="e56c72d645a0047396221ed2eb5407914a9b6bf6" translate="yes" xml:space="preserve">
          <source>For &lt;code&gt;make_classification&lt;/code&gt;, three binary and two multi-class classification datasets are generated, with different numbers of informative features and clusters per class.</source>
          <target state="translated">Para &lt;code&gt;make_classification&lt;/code&gt; , se generan tres conjuntos de datos de clasificaci&amp;oacute;n binarios y dos de clases m&amp;uacute;ltiples, con diferentes n&amp;uacute;meros de caracter&amp;iacute;sticas informativas y grupos por clase.</target>
        </trans-unit>
        <trans-unit id="dda7c631740b122861937f9ebbfdde73fd44b016" translate="yes" xml:space="preserve">
          <source>For Gaussian distributed data, the distance of an observation \(x_i\) to the mode of the distribution can be computed using its Mahalanobis distance: \(d_{(\mu,\Sigma)}(x_i)^2 = (x_i - \mu)'\Sigma^{-1}(x_i - \mu)\) where \(\mu\) and \(\Sigma\) are the location and the covariance of the underlying Gaussian distribution.</source>
          <target state="translated">Para los datos distribuidos de Gauss,la distancia de una observación \N al modo de distribución puede ser calculada usando su distancia de Mahalanobis:\N(d_{(\Nmu,\NSigma)}(x_i)^2=(x_i-\Nmu)'\NSigma^{\N-1}(x_i-\N-sigma)}donde \N(\Nmu)y \N(\Nsigma)son la ubicación y la covarianza de la distribución gaussiana subyacente.</target>
        </trans-unit>
        <trans-unit id="3fb903a20f5aad7e20f9123d2edfa2a0638dc6bc" translate="yes" xml:space="preserve">
          <source>For \(k\) clusters, the Calinski-Harabaz score \(s\) is given as the ratio of the between-clusters dispersion mean and the within-cluster dispersion:</source>
          <target state="translated">Para los cúmulos,el puntaje de Calinski-Harabaz se da como la relación entre la media de dispersión entre los cúmulos y la dispersión dentro del cúmulo:</target>
        </trans-unit>
        <trans-unit id="d27bcc7c91650762beefd01dc3089ec6978d5c87" translate="yes" xml:space="preserve">
          <source>For a classification model, the predicted class for each sample in X is returned. For a regression model, the predicted value based on X is returned.</source>
          <target state="translated">Para un modelo de clasificación,se devuelve la clase prevista para cada muestra en X.Para un modelo de regresión,se devuelve el valor predicho basado en X.</target>
        </trans-unit>
        <trans-unit id="e6fd66f776dfd09a091bc857e8c9d10d50ac3ba8" translate="yes" xml:space="preserve">
          <source>For a comparison of the different scalers, transformers, and normalizers, see &lt;a href=&quot;../../auto_examples/preprocessing/plot_all_scaling#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py&quot;&gt;examples/preprocessing/plot_all_scaling.py&lt;/a&gt;.</source>
          <target state="translated">Para una comparaci&amp;oacute;n de los diferentes escaladores, transformadores y normalizadores, consulte &lt;a href=&quot;../../auto_examples/preprocessing/plot_all_scaling#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py&quot;&gt;examples / preprocessing / plot_all_scaling.py&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="33f57a2a03940da66a0808ac0a9d7e45bc98afe2" translate="yes" xml:space="preserve">
          <source>For a complete probabilistic model we also need a prior distribution for the latent variable \(h\). The most straightforward assumption (based on the nice properties of the Gaussian distribution) is \(h \sim \mathcal{N}(0, \mathbf{I})\). This yields a Gaussian as the marginal distribution of \(x\):</source>
          <target state="translated">Para un modelo probabilístico completo también necesitamos una distribución previa de la variable latente (h).La suposición más directa (basada en las bonitas propiedades de la distribución Gaussiana)es la de que Esto produce un Gaussiano como la distribución marginal de la distribución:</target>
        </trans-unit>
        <trans-unit id="7e3b25cfbbacb17bf9ce066c3983b6610e3fab10" translate="yes" xml:space="preserve">
          <source>For a constant learning rate use &lt;code&gt;learning_rate='constant'&lt;/code&gt; and use &lt;code&gt;eta0&lt;/code&gt; to specify the learning rate.</source>
          <target state="translated">Para una tasa de aprendizaje constante, use &lt;code&gt;learning_rate='constant'&lt;/code&gt; y use &lt;code&gt;eta0&lt;/code&gt; para especificar la tasa de aprendizaje.</target>
        </trans-unit>
        <trans-unit id="76a9227cf28fa05c9bb19673e15a2774476a035c" translate="yes" xml:space="preserve">
          <source>For a description of the implementation and details of the algorithms used, please refer to</source>
          <target state="translated">Para una descripción de la implementación y los detalles de los algoritmos utilizados,por favor consulte</target>
        </trans-unit>
        <trans-unit id="ccaff5036b34bf3986d666eb2f98e4ef943f3dfd" translate="yes" xml:space="preserve">
          <source>For a discussion and comparison of these algorithms, see the &lt;a href=&quot;../../modules/manifold#manifold&quot;&gt;manifold module page&lt;/a&gt;</source>
          <target state="translated">Para una discusi&amp;oacute;n y comparaci&amp;oacute;n de estos algoritmos, vea la &lt;a href=&quot;../../modules/manifold#manifold&quot;&gt;p&amp;aacute;gina del m&amp;oacute;dulo m&amp;uacute;ltiple&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7b7d7f03d534f8340da15e8579a79cb680de77bd" translate="yes" xml:space="preserve">
          <source>For a document generated from multiple topics, all topics are weighted equally in generating its bag of words.</source>
          <target state="translated">Para un documento generado a partir de múltiples temas,todos los temas se ponderan por igual en la generación de su bolsa de palabras.</target>
        </trans-unit>
        <trans-unit id="b87483db50bfd800e7f61326ccd19592abcc3547" translate="yes" xml:space="preserve">
          <source>For a few of the best biclusters, its most common document categories and its ten most important words get printed. The best biclusters are determined by their normalized cut. The best words are determined by comparing their sums inside and outside the bicluster.</source>
          <target state="translated">Se imprimen sus categorías de documentos más comunes y sus diez palabras más importantes.Los mejores bíceps están determinados por su corte normalizado.Las mejores palabras se determinan comparando sus sumas dentro y fuera del bíceps.</target>
        </trans-unit>
        <trans-unit id="859f5c51d38da3ad244e41ebf28b507a4a99bc62" translate="yes" xml:space="preserve">
          <source>For a full code example that demonstrates using a &lt;a href=&quot;generated/sklearn.preprocessing.functiontransformer#sklearn.preprocessing.FunctionTransformer&quot;&gt;&lt;code&gt;FunctionTransformer&lt;/code&gt;&lt;/a&gt; to do custom feature selection, see &lt;a href=&quot;../auto_examples/preprocessing/plot_function_transformer#sphx-glr-auto-examples-preprocessing-plot-function-transformer-py&quot;&gt;Using FunctionTransformer to select columns&lt;/a&gt;</source>
          <target state="translated">Para obtener un ejemplo de c&amp;oacute;digo completo que demuestra el uso de &lt;a href=&quot;generated/sklearn.preprocessing.functiontransformer#sklearn.preprocessing.FunctionTransformer&quot;&gt; &lt;code&gt;FunctionTransformer&lt;/code&gt; &lt;/a&gt; para realizar una selecci&amp;oacute;n de caracter&amp;iacute;sticas personalizadas, consulte &lt;a href=&quot;../auto_examples/preprocessing/plot_function_transformer#sphx-glr-auto-examples-preprocessing-plot-function-transformer-py&quot;&gt;Uso de FunctionTransformer para seleccionar columnas&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a29c02b5f33160de772eacbd74337a53f6625181" translate="yes" xml:space="preserve">
          <source>For a full-fledged example of out-of-core scaling in a text classification task see &lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;Out-of-core classification of text documents&lt;/a&gt;.</source>
          <target state="translated">Para obtener un ejemplo completo de escalado fuera del n&amp;uacute;cleo en una tarea de clasificaci&amp;oacute;n de texto, consulte Clasificaci&amp;oacute;n &lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;fuera del n&amp;uacute;cleo de documentos de texto&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="d78aafa74d01fdbbdb67982f22aabb8fb92e6131" translate="yes" xml:space="preserve">
          <source>For a given value of &lt;code&gt;n_components&lt;/code&gt;&lt;a href=&quot;generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt;&lt;code&gt;RBFSampler&lt;/code&gt;&lt;/a&gt; is often less accurate as &lt;a href=&quot;generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt;&lt;code&gt;Nystroem&lt;/code&gt;&lt;/a&gt;. &lt;a href=&quot;generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt;&lt;code&gt;RBFSampler&lt;/code&gt;&lt;/a&gt; is cheaper to compute, though, making use of larger feature spaces more efficient.</source>
          <target state="translated">Para un valor dado de &lt;code&gt;n_components&lt;/code&gt; ,&lt;a href=&quot;generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt; &lt;code&gt;RBFSampler&lt;/code&gt; &lt;/a&gt; suele ser menos preciso que &lt;a href=&quot;generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt; &lt;code&gt;Nystroem&lt;/code&gt; &lt;/a&gt; . &lt;a href=&quot;generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt; &lt;code&gt;RBFSampler&lt;/code&gt; &lt;/a&gt; embargo, RBFSampler es m&amp;aacute;s econ&amp;oacute;mico de calcular, lo que hace que el uso de espacios de caracter&amp;iacute;sticas m&amp;aacute;s grandes sea m&amp;aacute;s eficiente.</target>
        </trans-unit>
        <trans-unit id="46cec00c813e8ea8e2f5bd58264262a28ac481cf" translate="yes" xml:space="preserve">
          <source>For a good choice of alpha, the &lt;a href=&quot;linear_model#lasso&quot;&gt;Lasso&lt;/a&gt; can fully recover the exact set of non-zero variables using only few observations, provided certain specific conditions are met. In particular, the number of samples should be &amp;ldquo;sufficiently large&amp;rdquo;, or L1 models will perform at random, where &amp;ldquo;sufficiently large&amp;rdquo; depends on the number of non-zero coefficients, the logarithm of the number of features, the amount of noise, the smallest absolute value of non-zero coefficients, and the structure of the design matrix X. In addition, the design matrix must display certain specific properties, such as not being too correlated.</source>
          <target state="translated">Para una buena elecci&amp;oacute;n de alfa, el &lt;a href=&quot;linear_model#lasso&quot;&gt;Lasso&lt;/a&gt; puede recuperar completamente el conjunto exacto de variables distintas de cero utilizando solo unas pocas observaciones, siempre que se cumplan ciertas condiciones espec&amp;iacute;ficas. En particular, el n&amp;uacute;mero de muestras debe ser &quot;suficientemente grande&quot;, o los modelos L1 funcionar&amp;aacute;n al azar, donde &quot;suficientemente grande&quot; depende del n&amp;uacute;mero de coeficientes distintos de cero, el logaritmo del n&amp;uacute;mero de caracter&amp;iacute;sticas, la cantidad de ruido, el valor absoluto m&amp;aacute;s peque&amp;ntilde;o de los coeficientes distintos de cero, y la estructura de la matriz de dise&amp;ntilde;o X. Adem&amp;aacute;s, la matriz de dise&amp;ntilde;o debe mostrar ciertas propiedades espec&amp;iacute;ficas, como no estar demasiado correlacionada.</target>
        </trans-unit>
        <trans-unit id="283fe9d87c4a4faac62d4b9cee8a3089a1cb638f" translate="yes" xml:space="preserve">
          <source>For a multi-label classification problem with N classes, N binary classifiers are assigned an integer between 0 and N-1. These integers define the order of models in the chain. Each classifier is then fit on the available training data plus the true labels of the classes whose models were assigned a lower number.</source>
          <target state="translated">Para un problema de clasificación multi-etiqueta con clases N,a los clasificadores binarios N se les asigna un número entero entre 0 y N-1.Estos números enteros definen el orden de los modelos en la cadena.Cada clasificador se ajusta entonces a los datos de formación disponibles más las etiquetas verdaderas de las clases a cuyos modelos se les asignó un número inferior.</target>
        </trans-unit>
        <trans-unit id="73e6ca6403df9166903acb4326e48adf2d2e8f55" translate="yes" xml:space="preserve">
          <source>For a multi_class problem, if multi_class is set to be &amp;ldquo;multinomial&amp;rdquo; the softmax function is used to find the predicted probability of each class. Else use a one-vs-rest approach, i.e calculate the probability of each class assuming it to be positive using the logistic function. and normalize these values across all the classes.</source>
          <target state="translated">Para un problema multi_class, si multi_class se establece como &amp;ldquo;multinomial&amp;rdquo;, la funci&amp;oacute;n softmax se usa para encontrar la probabilidad predicha de cada clase. De lo contrario, utilice un enfoque de uno contra el resto, es decir, calcule la probabilidad de cada clase asumiendo que es positiva utilizando la funci&amp;oacute;n log&amp;iacute;stica. y normalizar estos valores en todas las clases.</target>
        </trans-unit>
        <trans-unit id="642c44d27e63bf2bd3e040832cd67d4f4b97be3d" translate="yes" xml:space="preserve">
          <source>For a multiclass problem, the hyperparameters for each class are computed using the best scores got by doing a one-vs-rest in parallel across all folds and classes. Hence this is not the true multinomial loss.</source>
          <target state="translated">Para un problema de clases múltiples,los hiperparámetros de cada clase se calculan usando las mejores puntuaciones obtenidas al hacer un descanso de uno contra uno en paralelo en todos los pliegues y clases.Por lo tanto,esta no es la verdadera pérdida multinomial.</target>
        </trans-unit>
        <trans-unit id="3c102da8b9e1a48c3e9639790d9170902789d884" translate="yes" xml:space="preserve">
          <source>For a new point entering the root, it is merged with the subcluster closest to it and the linear sum, squared sum and the number of samples of that subcluster are updated. This is done recursively till the properties of the leaf node are updated.</source>
          <target state="translated">Para un nuevo punto que entra en la raíz,se fusiona con el subclúster más cercano y se actualizan la suma lineal,la suma cuadrada y el número de muestras de ese subclúster.Esto se hace de forma recursiva hasta que las propiedades del nodo de la hoja se actualizan.</target>
        </trans-unit>
        <trans-unit id="d36945b7ba93218440d9a3fb3620ffe9bc7ebec1" translate="yes" xml:space="preserve">
          <source>For a similar example, where the methods are applied to a sphere dataset, see &lt;a href=&quot;plot_manifold_sphere#sphx-glr-auto-examples-manifold-plot-manifold-sphere-py&quot;&gt;Manifold Learning methods on a severed sphere&lt;/a&gt;</source>
          <target state="translated">Para ver un ejemplo similar, donde los m&amp;eacute;todos se aplican a un dataset de esfera, consulte &lt;a href=&quot;plot_manifold_sphere#sphx-glr-auto-examples-manifold-plot-manifold-sphere-py&quot;&gt;M&amp;eacute;todos de aprendizaje m&amp;uacute;ltiple en una esfera cortada&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="945c76e7faeb6fe6d013381d6851dfb972b0f8ae" translate="yes" xml:space="preserve">
          <source>For a similar example, where the methods are applied to the S-curve dataset, see &lt;a href=&quot;plot_compare_methods#sphx-glr-auto-examples-manifold-plot-compare-methods-py&quot;&gt;Comparison of Manifold Learning methods&lt;/a&gt;</source>
          <target state="translated">Para ver un ejemplo similar, donde los m&amp;eacute;todos se aplican al conjunto de datos de la curva S, consulte &lt;a href=&quot;plot_compare_methods#sphx-glr-auto-examples-manifold-plot-compare-methods-py&quot;&gt;Comparaci&amp;oacute;n de m&amp;eacute;todos de aprendizaje m&amp;uacute;ltiple&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5693da1a0a426bf5e6f357791de67cea3dcb709e" translate="yes" xml:space="preserve">
          <source>For an adaptively decreasing learning rate, use &lt;code&gt;learning_rate='adaptive'&lt;/code&gt; and use &lt;code&gt;eta0&lt;/code&gt; to specify the starting learning rate. When the stopping criterion is reached, the learning rate is divided by 5, and the algorithm does not stop. The algorithm stops when the learning rate goes below 1e-6.</source>
          <target state="translated">Para una tasa de aprendizaje decreciente adaptativa, use &lt;code&gt;learning_rate='adaptive'&lt;/code&gt; y use &lt;code&gt;eta0&lt;/code&gt; para especificar la tasa de aprendizaje inicial. Cuando se alcanza el criterio de parada, la tasa de aprendizaje se divide por 5 y el algoritmo no se detiene. El algoritmo se detiene cuando la tasa de aprendizaje desciende por debajo de 1e-6.</target>
        </trans-unit>
        <trans-unit id="289eda38dfb97e5735805aabc918de776eb35066" translate="yes" xml:space="preserve">
          <source>For an estimator to be effective, you need the distance between neighboring points to be less than some value \(d\), which depends on the problem. In one dimension, this requires on average \(n \sim 1/d\) points. In the context of the above \(k\)-NN example, if the data is described by just one feature with values ranging from 0 to 1 and with \(n\) training observations, then new data will be no further away than \(1/n\). Therefore, the nearest neighbor decision rule will be efficient as soon as \(1/n\) is small compared to the scale of between-class feature variations.</source>
          <target state="translated">Para que un estimador sea efectivo,necesitas que la distancia entre los puntos vecinos sea menor que algún valor,lo cual depende del problema.En una dimensión,esto requiere un promedio de 1/d de puntos.En el contexto del ejemplo anterior \(k)-NN,si los datos se describen por una sola característica con valores que van de 0 a 1 y con \N observaciones de entrenamiento,entonces los nuevos datos no estarán más lejos que \N(1/n).Por lo tanto,la regla de la decisión del vecino más cercano será eficiente tan pronto como \ ~ (1/n)es pequeña en comparación con la escala de las variaciones de las características entre las clases.</target>
        </trans-unit>
        <trans-unit id="cc92ccd33be99f33389b25ab23e30ca5c4b36d12" translate="yes" xml:space="preserve">
          <source>For an example of using this dataset with scikit-learn, see &lt;a href=&quot;../../auto_examples/applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;examples/applications/plot_species_distribution_modeling.py&lt;/a&gt;.</source>
          <target state="translated">Para ver un ejemplo del uso de este conjunto de datos con scikit-learn, consulte &lt;a href=&quot;../../auto_examples/applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;examples / applications / plot_species_distribution_modeling.py&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="84cc57ff6bd3680e44c549367baf76fa37633107" translate="yes" xml:space="preserve">
          <source>For an example, see &lt;a href=&quot;../../auto_examples/cluster/plot_affinity_propagation#sphx-glr-auto-examples-cluster-plot-affinity-propagation-py&quot;&gt;examples/cluster/plot_affinity_propagation.py&lt;/a&gt;.</source>
          <target state="translated">Para ver un ejemplo, consulte &lt;a href=&quot;../../auto_examples/cluster/plot_affinity_propagation#sphx-glr-auto-examples-cluster-plot-affinity-propagation-py&quot;&gt;examples / cluster / plot_affinity_propagation.py&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="550540d863fd72ef27788284d554fe3cf91d4d31" translate="yes" xml:space="preserve">
          <source>For an example, see &lt;a href=&quot;../../auto_examples/cluster/plot_dbscan#sphx-glr-auto-examples-cluster-plot-dbscan-py&quot;&gt;examples/cluster/plot_dbscan.py&lt;/a&gt;.</source>
          <target state="translated">Para ver un ejemplo, consulte &lt;a href=&quot;../../auto_examples/cluster/plot_dbscan#sphx-glr-auto-examples-cluster-plot-dbscan-py&quot;&gt;examples / cluster / plot_dbscan.py&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="5a609c98d64d09ee64c2c225998c2e63797d885b" translate="yes" xml:space="preserve">
          <source>For an example, see &lt;a href=&quot;../../auto_examples/cluster/plot_mean_shift#sphx-glr-auto-examples-cluster-plot-mean-shift-py&quot;&gt;examples/cluster/plot_mean_shift.py&lt;/a&gt;.</source>
          <target state="translated">Para ver un ejemplo, consulte &lt;a href=&quot;../../auto_examples/cluster/plot_mean_shift#sphx-glr-auto-examples-cluster-plot-mean-shift-py&quot;&gt;examples / cluster / plot_mean_shift.py&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0c7aeec7cbc3121a908ff21339ef38d8e3682ea4" translate="yes" xml:space="preserve">
          <source>For an example, see &lt;a href=&quot;../../auto_examples/linear_model/plot_ard#sphx-glr-auto-examples-linear-model-plot-ard-py&quot;&gt;examples/linear_model/plot_ard.py&lt;/a&gt;.</source>
          <target state="translated">Para ver un ejemplo, consulte &lt;a href=&quot;../../auto_examples/linear_model/plot_ard#sphx-glr-auto-examples-linear-model-plot-ard-py&quot;&gt;examples / linear_model / plot_ard.py&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="8606b3a4ce46a8dc7d8f3fc386175108176c1a2f" translate="yes" xml:space="preserve">
          <source>For an example, see &lt;a href=&quot;../../auto_examples/linear_model/plot_bayesian_ridge#sphx-glr-auto-examples-linear-model-plot-bayesian-ridge-py&quot;&gt;examples/linear_model/plot_bayesian_ridge.py&lt;/a&gt;.</source>
          <target state="translated">Para ver un ejemplo, consulte &lt;a href=&quot;../../auto_examples/linear_model/plot_bayesian_ridge#sphx-glr-auto-examples-linear-model-plot-bayesian-ridge-py&quot;&gt;examples / linear_model / plot_bayesian_ridge.py&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="1a253fcf6bd3baedce8e1812aafc9e481fd05853" translate="yes" xml:space="preserve">
          <source>For an example, see &lt;a href=&quot;../../auto_examples/linear_model/plot_lasso_coordinate_descent_path#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py&quot;&gt;examples/linear_model/plot_lasso_coordinate_descent_path.py&lt;/a&gt;.</source>
          <target state="translated">Para ver un ejemplo, consulte &lt;a href=&quot;../../auto_examples/linear_model/plot_lasso_coordinate_descent_path#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py&quot;&gt;examples / linear_model / plot_lasso_coordinate_descent_path.py&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="dd893fae3c875581ed42afc5493c8a73ae57ea3a" translate="yes" xml:space="preserve">
          <source>For an example, see &lt;a href=&quot;../../auto_examples/linear_model/plot_lasso_model_selection#sphx-glr-auto-examples-linear-model-plot-lasso-model-selection-py&quot;&gt;examples/linear_model/plot_lasso_model_selection.py&lt;/a&gt;.</source>
          <target state="translated">Para ver un ejemplo, consulte &lt;a href=&quot;../../auto_examples/linear_model/plot_lasso_model_selection#sphx-glr-auto-examples-linear-model-plot-lasso-model-selection-py&quot;&gt;examples / linear_model / plot_lasso_model_selection.py&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="7185c2666c1903f0809fab3c9082ec1324c6a9c7" translate="yes" xml:space="preserve">
          <source>For an introduction to Unicode and character encodings in general, see Joel Spolsky&amp;rsquo;s &lt;a href=&quot;http://www.joelonsoftware.com/articles/Unicode.html&quot;&gt;Absolute Minimum Every Software Developer Must Know About Unicode&lt;/a&gt;.</source>
          <target state="translated">Para obtener una introducci&amp;oacute;n a Unicode y las codificaciones de caracteres en general, consulte &lt;a href=&quot;http://www.joelonsoftware.com/articles/Unicode.html&quot;&gt;M&amp;iacute;nimo absoluto que todo desarrollador de software debe saber sobre Unicode de&lt;/a&gt; Joel Spolsky .</target>
        </trans-unit>
        <trans-unit id="3a88e794655306a2809e5d03a41b7ab87506c6aa" translate="yes" xml:space="preserve">
          <source>For an one-class model, +1 (inlier) or -1 (outlier) is returned.</source>
          <target state="translated">Para un modelo de una clase,se devuelve +1 (atípico)o -1 (atípico).</target>
        </trans-unit>
        <trans-unit id="6b041f627b95dafb713c53f369d3fb59c9505ee0" translate="yes" xml:space="preserve">
          <source>For an one-class model, +1 or -1 is returned.</source>
          <target state="translated">Para un modelo de una clase,se devuelve +1 o -1.</target>
        </trans-unit>
        <trans-unit id="90c9667034ee59a28024b8500c3a1c0772f75e0b" translate="yes" xml:space="preserve">
          <source>For an overview of available strategies in scikit-learn, see also the &lt;a href=&quot;computing#scaling-strategies&quot;&gt;out-of-core learning&lt;/a&gt; documentation.</source>
          <target state="translated">Para obtener una descripci&amp;oacute;n general de las estrategias disponibles en scikit-learn, consulte tambi&amp;eacute;n la documentaci&amp;oacute;n de &lt;a href=&quot;computing#scaling-strategies&quot;&gt;aprendizaje fuera del n&amp;uacute;cleo&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="bd83f9999f935e2f6fce3641b48e5b3393b97a71" translate="yes" xml:space="preserve">
          <source>For binary classification with a true label \(y \in \{0,1\}\) and a probability estimate \(p = \operatorname{Pr}(y = 1)\), the log loss per sample is the negative log-likelihood of the classifier given the true label:</source>
          <target state="translated">Para la clasificación binaria con una etiqueta verdadera \ ~ (y \ ~ en 0,1)y una estimación de probabilidad \ ~ (p=\ ~ nombre del operador (Pr)(y=1)),la pérdida de registro por muestra es la logaritmo negativo \ ~ probabilidad del clasificador dado la etiqueta verdadera:</target>
        </trans-unit>
        <trans-unit id="23a4f6b8b8e57d58b02ac23ef6f32b82b6049d45" translate="yes" xml:space="preserve">
          <source>For binary classification, \(f(x)\) passes through the logistic function \(g(z)=1/(1+e^{-z})\) to obtain output values between zero and one. A threshold, set to 0.5, would assign samples of outputs larger or equal 0.5 to the positive class, and the rest to the negative class.</source>
          <target state="translated">Para la clasificación binaria,\(f(x)\)pasa a través de la función logística \N \N (g(z)=1/(1+e^{-z})\N para obtener valores de salida entre cero y uno.Un umbral,fijado en 0,5,asignaría muestras de salidas mayores o iguales a 0,5 a la clase positiva,y el resto a la clase negativa.</target>
        </trans-unit>
        <trans-unit id="883efcc2dc17e184b74392564fb44d2a6f9c0bf6" translate="yes" xml:space="preserve">
          <source>For binary problems, we can get counts of true negatives, false positives, false negatives and true positives as follows:</source>
          <target state="translated">Para los problemas binarios,podemos obtener recuentos de verdaderos negativos,falsos positivos,falsos negativos y verdaderos positivos de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="7f954d6786e07c3ef37ff8e0245acb91efbb4b2a" translate="yes" xml:space="preserve">
          <source>For classification with &lt;code&gt;loss='deviance'&lt;/code&gt; the target response is logit(p).</source>
          <target state="translated">Para la clasificaci&amp;oacute;n con &lt;code&gt;loss='deviance'&lt;/code&gt; la respuesta objetivo es logit (p).</target>
        </trans-unit>
        <trans-unit id="4118e1de638d62fd337275c2f8d28f38f1e40db3" translate="yes" xml:space="preserve">
          <source>For classification with a logistic loss, another variant of SGD with an averaging strategy is available with Stochastic Average Gradient (SAG) algorithm, available as a solver in &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Para la clasificaci&amp;oacute;n con una p&amp;eacute;rdida log&amp;iacute;stica, otra variante de SGD con una estrategia de promediado est&amp;aacute; disponible con el algoritmo de gradiente medio estoc&amp;aacute;stico (SAG), disponible como solucionador en &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="7a750c34f262db1f2c0c844eb9774104416e6f5c" translate="yes" xml:space="preserve">
          <source>For classification you can think of it as the regression score before the link function.</source>
          <target state="translated">Para la clasificación puedes pensar en ello como la puntuación de regresión antes de la función de enlace.</target>
        </trans-unit>
        <trans-unit id="6a3d9b2c887776af95639587c4c76f62b0d1c8f1" translate="yes" xml:space="preserve">
          <source>For classification, &lt;a href=&quot;generated/sklearn.linear_model.passiveaggressiveclassifier#sklearn.linear_model.PassiveAggressiveClassifier&quot;&gt;&lt;code&gt;PassiveAggressiveClassifier&lt;/code&gt;&lt;/a&gt; can be used with &lt;code&gt;loss='hinge'&lt;/code&gt; (PA-I) or &lt;code&gt;loss='squared_hinge'&lt;/code&gt; (PA-II). For regression, &lt;a href=&quot;generated/sklearn.linear_model.passiveaggressiveregressor#sklearn.linear_model.PassiveAggressiveRegressor&quot;&gt;&lt;code&gt;PassiveAggressiveRegressor&lt;/code&gt;&lt;/a&gt; can be used with &lt;code&gt;loss='epsilon_insensitive'&lt;/code&gt; (PA-I) or &lt;code&gt;loss='squared_epsilon_insensitive'&lt;/code&gt; (PA-II).</source>
          <target state="translated">Para la clasificaci&amp;oacute;n, &lt;a href=&quot;generated/sklearn.linear_model.passiveaggressiveclassifier#sklearn.linear_model.PassiveAggressiveClassifier&quot;&gt; &lt;code&gt;PassiveAggressiveClassifier&lt;/code&gt; &lt;/a&gt; se puede utilizar con &lt;code&gt;loss='hinge'&lt;/code&gt; (PA-I) o &lt;code&gt;loss='squared_hinge'&lt;/code&gt; (PA-II). Para la regresi&amp;oacute;n, &lt;a href=&quot;generated/sklearn.linear_model.passiveaggressiveregressor#sklearn.linear_model.PassiveAggressiveRegressor&quot;&gt; &lt;code&gt;PassiveAggressiveRegressor&lt;/code&gt; &lt;/a&gt; se puede utilizar con &lt;code&gt;loss='epsilon_insensitive'&lt;/code&gt; (PA-I) o &lt;code&gt;loss='squared_epsilon_insensitive'&lt;/code&gt; (PA-II).</target>
        </trans-unit>
        <trans-unit id="27898fb8346ff80dce087f616900965fd4196842" translate="yes" xml:space="preserve">
          <source>For classification, a somewhat important thing to note is that although a stateless feature extraction routine may be able to cope with new/unseen attributes, the incremental learner itself may be unable to cope with new/unseen targets classes. In this case you have to pass all the possible classes to the first &lt;code&gt;partial_fit&lt;/code&gt; call using the &lt;code&gt;classes=&lt;/code&gt; parameter.</source>
          <target state="translated">Para la clasificaci&amp;oacute;n, algo importante a tener en cuenta es que, aunque una rutina de extracci&amp;oacute;n de caracter&amp;iacute;sticas sin estado puede hacer frente a atributos nuevos / no vistos, el alumno incremental por s&amp;iacute; mismo puede ser incapaz de hacer frente a clases de objetivos nuevos / no vistos. En este caso, debe pasar todas las clases posibles a la primera llamada &lt;code&gt;partial_fit&lt;/code&gt; usando el par&amp;aacute;metro &lt;code&gt;classes=&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="fda4c776ec3f2170d3e99301b50afa3144298d48" translate="yes" xml:space="preserve">
          <source>For classification, as in the labeling &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;iris&lt;/a&gt; task, linear regression is not the right approach as it will give too much weight to data far from the decision frontier. A linear approach is to fit a sigmoid function or &lt;strong&gt;logistic&lt;/strong&gt; function:</source>
          <target state="translated">Para la clasificaci&amp;oacute;n, como en la tarea de etiquetado del &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;iris&lt;/a&gt; , la regresi&amp;oacute;n lineal no es el enfoque correcto, ya que dar&amp;aacute; demasiado peso a los datos alejados de la frontera de decisi&amp;oacute;n. Un enfoque lineal es ajustar una funci&amp;oacute;n sigmoidea o una funci&amp;oacute;n &lt;strong&gt;log&amp;iacute;stica&lt;/strong&gt; :</target>
        </trans-unit>
        <trans-unit id="049512f622ab4a1900a694aa9ec5fcf56244d47a" translate="yes" xml:space="preserve">
          <source>For classification: &lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt;&lt;code&gt;chi2&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.feature_selection.f_classif#sklearn.feature_selection.f_classif&quot;&gt;&lt;code&gt;f_classif&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_classif#sklearn.feature_selection.mutual_info_classif&quot;&gt;&lt;code&gt;mutual_info_classif&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">Para clasificaci&amp;oacute;n: &lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt; &lt;code&gt;chi2&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.feature_selection.f_classif#sklearn.feature_selection.f_classif&quot;&gt; &lt;code&gt;f_classif&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_classif#sklearn.feature_selection.mutual_info_classif&quot;&gt; &lt;code&gt;mutual_info_classif&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2b5c234d472222c920c562abfd3ef4ec80e6cfee" translate="yes" xml:space="preserve">
          <source>For comparison, a quantized image using a random codebook (colors picked up randomly) is also shown.</source>
          <target state="translated">Para la comparación,también se muestra una imagen cuantizada usando un libro de códigos aleatorios (colores recogidos al azar).</target>
        </trans-unit>
        <trans-unit id="3be5878f7d3ebd4495804d5a6a55058ed71eceb1" translate="yes" xml:space="preserve">
          <source>For comparison, the documents are also clustered using MiniBatchKMeans. The document clusters derived from the biclusters achieve a better V-measure than clusters found by MiniBatchKMeans.</source>
          <target state="translated">Para la comparación,los documentos también se agrupan usando MiniBatchKMeans.Los clusters de documentos derivados de los biclusters logran una mejor medida de V que los clusters encontrados por MiniBatchKMeans.</target>
        </trans-unit>
        <trans-unit id="6d421941474530194b10c6be8d7b89e2eb530191" translate="yes" xml:space="preserve">
          <source>For comparison, we also add the output from &lt;code&gt;preprocessing.QuantileTransformer&lt;/code&gt;. It can force any arbitrary distribution into a gaussian, provided that there are enough training samples (thousands). Because it is a non-parametric method, it is harder to interpret than the parametric ones (Box-Cox and Yeo-Johnson).</source>
          <target state="translated">A modo de comparaci&amp;oacute;n, tambi&amp;eacute;n agregamos la salida del &lt;code&gt;preprocessing.QuantileTransformer&lt;/code&gt; . Puede forzar cualquier distribuci&amp;oacute;n arbitraria en un gaussiano, siempre que haya suficientes muestras de entrenamiento (miles). Debido a que es un m&amp;eacute;todo no param&amp;eacute;trico, es m&amp;aacute;s dif&amp;iacute;cil de interpretar que los param&amp;eacute;tricos (Box-Cox y Yeo-Johnson).</target>
        </trans-unit>
        <trans-unit id="3fedc899dde91ba75e541f7b8d87d7a3665ca193" translate="yes" xml:space="preserve">
          <source>For compatibility, user code relying on this method should wrap its calls in &lt;code&gt;np.asarray&lt;/code&gt; to avoid type issues.</source>
          <target state="translated">Por compatibilidad, el c&amp;oacute;digo de usuario que se basa en este m&amp;eacute;todo debe envolver sus llamadas en &lt;code&gt;np.asarray&lt;/code&gt; para evitar problemas de tipo.</target>
        </trans-unit>
        <trans-unit id="6f31aee2196032d492cf3c67f7f43ab3f6981996" translate="yes" xml:space="preserve">
          <source>For continuous parameters, such as &lt;code&gt;C&lt;/code&gt; above, it is important to specify a continuous distribution to take full advantage of the randomization. This way, increasing &lt;code&gt;n_iter&lt;/code&gt; will always lead to a finer search.</source>
          <target state="translated">Para los par&amp;aacute;metros continuos, como &lt;code&gt;C&lt;/code&gt; anterior, es importante especificar una distribuci&amp;oacute;n continua para aprovechar al m&amp;aacute;ximo la aleatorizaci&amp;oacute;n. De esta manera, aumentar &lt;code&gt;n_iter&lt;/code&gt; siempre conducir&amp;aacute; a una b&amp;uacute;squeda m&amp;aacute;s fina.</target>
        </trans-unit>
        <trans-unit id="4288bdf523218f188616117af5e7ab510c1e81a7" translate="yes" xml:space="preserve">
          <source>For cross-validation, we use 20-fold with 2 algorithms to compute the Lasso path: coordinate descent, as implemented by the LassoCV class, and Lars (least angle regression) as implemented by the LassoLarsCV class. Both algorithms give roughly the same results. They differ with regards to their execution speed and sources of numerical errors.</source>
          <target state="translated">Para la validación cruzada,usamos 20 veces con 2 algoritmos para calcular el camino de Lasso:descenso coordinado,como lo implementa la clase LassoCV,y Lars (regresión del ángulo menor)como lo implementa la clase LassoLarsCV.Ambos algoritmos dan aproximadamente los mismos resultados.Se diferencian en cuanto a su velocidad de ejecución y a las fuentes de errores numéricos.</target>
        </trans-unit>
        <trans-unit id="c8cbf2457961ac615bed8ee5d0896fee418cd0e6" translate="yes" xml:space="preserve">
          <source>For custom messages if &amp;ldquo;%(name)s&amp;rdquo; is present in the message string, it is substituted for the estimator name.</source>
          <target state="translated">Para mensajes personalizados, si &quot;% (nombre) s&quot; est&amp;aacute; presente en la cadena del mensaje, se sustituye por el nombre del estimador.</target>
        </trans-unit>
        <trans-unit id="67e0a596cb4bf62edc844af1488251663768a571" translate="yes" xml:space="preserve">
          <source>For details on the precise mathematical formulation of the provided kernel functions and how &lt;code&gt;gamma&lt;/code&gt;, &lt;code&gt;coef0&lt;/code&gt; and &lt;code&gt;degree&lt;/code&gt; affect each other, see the corresponding section in the narrative documentation: &lt;a href=&quot;../svm#svm-kernels&quot;&gt;Kernel functions&lt;/a&gt;.</source>
          <target state="translated">Para obtener detalles sobre la formulaci&amp;oacute;n matem&amp;aacute;tica precisa de las funciones del n&amp;uacute;cleo proporcionadas y c&amp;oacute;mo &lt;code&gt;gamma&lt;/code&gt; , &lt;code&gt;coef0&lt;/code&gt; y &lt;code&gt;degree&lt;/code&gt; afectan entre s&amp;iacute;, consulte la secci&amp;oacute;n correspondiente en la documentaci&amp;oacute;n narrativa: &lt;a href=&quot;../svm#svm-kernels&quot;&gt;Funciones del n&amp;uacute;cleo&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="e4ed0f1e2f8642affc7014ca7518ae7bfac1b31c" translate="yes" xml:space="preserve">
          <source>For each class k an array of shape [n_features, n_k], with &lt;code&gt;n_k = min(n_features, number of elements in class k)&lt;/code&gt; It is the rotation of the Gaussian distribution, i.e. its principal axis.</source>
          <target state="translated">Para cada clase k una matriz de forma [n_features, n_k], con &lt;code&gt;n_k = min(n_features, number of elements in class k)&lt;/code&gt; Es la rotaci&amp;oacute;n de la distribuci&amp;oacute;n gaussiana, es decir, su eje principal.</target>
        </trans-unit>
        <trans-unit id="a5ae820e12dddee4457f060f6b705b304ca3a1e3" translate="yes" xml:space="preserve">
          <source>For each class k an array of shape [n_k]. It contains the scaling of the Gaussian distributions along its principal axes, i.e. the variance in the rotated coordinate system.</source>
          <target state="translated">Para cada clase k una matriz de forma [n_k].Contiene la escala de las distribuciones gaussianas a lo largo de sus ejes principales,es decir,la varianza en el sistema de coordenadas giradas.</target>
        </trans-unit>
        <trans-unit id="bb1ef71f090300eb5b67a4f2bd338bada7005d30" translate="yes" xml:space="preserve">
          <source>For each class of models we make the model complexity vary through the choice of relevant model parameters and measure the influence on both computational performance (latency) and predictive power (MSE or Hamming Loss).</source>
          <target state="translated">Para cada clase de modelos hacemos que la complejidad del modelo varíe a través de la elección de los parámetros relevantes del modelo y medimos la influencia tanto en el rendimiento computacional (latencia)como en la potencia de predicción (MSE o Hamming Loss).</target>
        </trans-unit>
        <trans-unit id="51af5a1cbe5b213e1b6f97e9040e40d195d22222" translate="yes" xml:space="preserve">
          <source>For each component k, find the weights u, v that maximizes max corr(Xk u, Yk v), such that &lt;code&gt;|u| = |v| = 1&lt;/code&gt;</source>
          <target state="translated">Para cada componente k, encuentre los pesos u, v que maximizan la corr. M&amp;aacute;x. (Xk u, Yk v), tales que &lt;code&gt;|u| = |v| = 1&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="0acc93a412fe0bc296f4de29ad2df21b9415e5fb" translate="yes" xml:space="preserve">
          <source>For each component k, find weights u, v that optimize:</source>
          <target state="translated">Para cada componente k,encuentra los pesos u,v que optimizan:</target>
        </trans-unit>
        <trans-unit id="34ffb7458447c8e84aeb0c0dcae78f73f1c9783e" translate="yes" xml:space="preserve">
          <source>For each component k, find weights u, v that optimizes: &lt;code&gt;max corr(Xk u, Yk v) * std(Xk u) std(Yk u)&lt;/code&gt;, such that &lt;code&gt;|u| = 1&lt;/code&gt;</source>
          <target state="translated">Para cada componente k, encuentre los pesos u, v que optimicen: &lt;code&gt;max corr(Xk u, Yk v) * std(Xk u) std(Yk u)&lt;/code&gt; , tales que &lt;code&gt;|u| = 1&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f9db939b51ba3d78630796e1c0444915001bc251" translate="yes" xml:space="preserve">
          <source>For each datapoint x in X and for each tree in the ensemble, return the index of the leaf x ends up in each estimator.</source>
          <target state="translated">Para cada punto de datos x en X y para cada árbol del conjunto,devolver el índice de la hoja x termina en cada estimador.</target>
        </trans-unit>
        <trans-unit id="4571d700205de7840eb7f685393b9c35a449521a" translate="yes" xml:space="preserve">
          <source>For each datapoint x in X and for each tree in the ensemble, return the index of the leaf x ends up in each estimator. In the case of binary classification n_classes is 1.</source>
          <target state="translated">Para cada punto de datos x en X y para cada árbol del conjunto,devolver el índice de la hoja x termina en cada estimador.En el caso de la clasificación binaria n_clases es 1.</target>
        </trans-unit>
        <trans-unit id="44ac20da24a40ac490697d0897d69873261c6900" translate="yes" xml:space="preserve">
          <source>For each datapoint x in X and for each tree in the forest, return the index of the leaf x ends up in.</source>
          <target state="translated">Para cada punto de datos x en X y para cada árbol del bosque,devuelve el índice de la hoja en la que x termina.</target>
        </trans-unit>
        <trans-unit id="d82941d49be2d46b8acb0305feded896c81f7a70" translate="yes" xml:space="preserve">
          <source>For each datapoint x in X, return the index of the leaf x ends up in. Leaves are numbered within &lt;code&gt;[0; self.tree_.node_count)&lt;/code&gt;, possibly with gaps in the numbering.</source>
          <target state="translated">Para cada punto de datos x en X, devuelve el &amp;iacute;ndice de la hoja en la que termina x. Las hojas est&amp;aacute;n numeradas dentro de &lt;code&gt;[0; self.tree_.node_count)&lt;/code&gt; , posiblemente con espacios en la numeraci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="7b85d3d77de0d2c34f470b25ce92cd73fbf8293c" translate="yes" xml:space="preserve">
          <source>For each dataset, 15% of samples are generated as random uniform noise. This proportion is the value given to the nu parameter of the OneClassSVM and the contamination parameter of the other outlier detection algorithms. Decision boundaries between inliers and outliers are displayed in black except for Local Outlier Factor (LOF) as it has no predict method to be applied on new data when it is used for outlier detection.</source>
          <target state="translated">Para cada conjunto de datos,el 15% de las muestras se generan como ruido uniforme aleatorio.Esta proporción es el valor dado al parámetro nu del OneClassSVM y al parámetro de contaminación de los otros algoritmos de detección de valores atípicos.Los límites de decisión entre los valores atípicos y los valores atípicos se muestran en negro,excepto para el Factor Atípico Local (LOF),ya que no tiene un método de predicción que se aplique a los nuevos datos cuando se utiliza para la detección de valores atípicos.</target>
        </trans-unit>
        <trans-unit id="894d665cd020f2e7e68923ae49f3798173d1a959" translate="yes" xml:space="preserve">
          <source>For each document &lt;code&gt;#i&lt;/code&gt;, count the number of occurrences of each word &lt;code&gt;w&lt;/code&gt; and store it in &lt;code&gt;X[i, j]&lt;/code&gt; as the value of feature &lt;code&gt;#j&lt;/code&gt; where &lt;code&gt;j&lt;/code&gt; is the index of word &lt;code&gt;w&lt;/code&gt; in the dictionary.</source>
          <target state="translated">Para cada documento &lt;code&gt;#i&lt;/code&gt; , cuente el n&amp;uacute;mero de ocurrencias de cada palabra &lt;code&gt;w&lt;/code&gt; y gu&amp;aacute;rdelo en &lt;code&gt;X[i, j]&lt;/code&gt; como el valor de la caracter&amp;iacute;stica &lt;code&gt;#j&lt;/code&gt; donde &lt;code&gt;j&lt;/code&gt; es el &amp;iacute;ndice de la palabra &lt;code&gt;w&lt;/code&gt; en el diccionario.</target>
        </trans-unit>
        <trans-unit id="f8df1081a030b15d2d8afea6cd05ff167080d1cd" translate="yes" xml:space="preserve">
          <source>For each document \(d\), draw \(\theta_d \sim \mathrm{Dirichlet}(\alpha), \: d=1...D\)</source>
          <target state="translated">Para cada documento,dibuja un dibujo de un simbolo de matemáticas.</target>
        </trans-unit>
        <trans-unit id="d88ce97fd881b7b3225357f99ece9e603e7378b5" translate="yes" xml:space="preserve">
          <source>For each observation, tells whether or not (+1 or -1) it should be considered as an inlier according to the fitted model.</source>
          <target state="translated">Para cada observación,dice si debe ser considerada o no (+1 o -1)como un inlier según el modelo ajustado.</target>
        </trans-unit>
        <trans-unit id="ceeb3b0129a3e252c3947f10f0ffdea6343158bd" translate="yes" xml:space="preserve">
          <source>For each pair of iris features, the decision tree learns decision boundaries made of combinations of simple thresholding rules inferred from the training samples.</source>
          <target state="translated">Para cada par de características del iris,el árbol de decisión aprende límites de decisión hechos de combinaciones de reglas de umbral simples inferidas de las muestras de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="ebc579ef4368e5d7216210ea27aaa16d7216a1cd" translate="yes" xml:space="preserve">
          <source>For each sample, the generative process is:</source>
          <target state="translated">Para cada muestra,el proceso generativo es:</target>
        </trans-unit>
        <trans-unit id="884540e9625ad90cb4316f6468437987a56adbd4" translate="yes" xml:space="preserve">
          <source>For each topic \(k\), draw \(\beta_k \sim \mathrm{Dirichlet}(\eta),\: k =1...K\)</source>
          <target state="translated">Para cada tema,dibuja un dibujo de Kim Dirichlet,k =1...K)</target>
        </trans-unit>
        <trans-unit id="ebc60a8584824b9b236f9d24a5aa9b01b10427f0" translate="yes" xml:space="preserve">
          <source>For each value of &lt;code&gt;n_components&lt;/code&gt;, we plot:</source>
          <target state="translated">Para cada valor de &lt;code&gt;n_components&lt;/code&gt; , trazamos :</target>
        </trans-unit>
        <trans-unit id="6ad9736839514923dd21aa4c5541f4da9ec0e497" translate="yes" xml:space="preserve">
          <source>For each value of the &amp;lsquo;target&amp;rsquo; features in the &lt;code&gt;grid&lt;/code&gt; the partial dependence function need to marginalize the predictions of a tree over all possible values of the &amp;lsquo;complement&amp;rsquo; features. In decision trees this function can be evaluated efficiently without reference to the training data. For each grid point a weighted tree traversal is performed: if a split node involves a &amp;lsquo;target&amp;rsquo; feature, the corresponding left or right branch is followed, otherwise both branches are followed, each branch is weighted by the fraction of training samples that entered that branch. Finally, the partial dependence is given by a weighted average of all visited leaves. For tree ensembles the results of each individual tree are again averaged.</source>
          <target state="translated">Para cada valor de las caracter&amp;iacute;sticas 'objetivo' en la &lt;code&gt;grid&lt;/code&gt; la funci&amp;oacute;n de dependencia parcial necesita marginar las predicciones de un &amp;aacute;rbol sobre todos los valores posibles de las caracter&amp;iacute;sticas 'complementarias'. En los &amp;aacute;rboles de decisi&amp;oacute;n, esta funci&amp;oacute;n se puede evaluar de manera eficiente sin referencia a los datos de entrenamiento. Para cada punto de la cuadr&amp;iacute;cula, se realiza un recorrido de &amp;aacute;rbol ponderado: si un nodo dividido implica una caracter&amp;iacute;stica 'objetivo', se sigue la rama izquierda o derecha correspondiente; de ​​lo contrario, se siguen ambas ramas, cada rama se pondera por la fracci&amp;oacute;n de muestras de entrenamiento que ingresaron en ese punto. rama. Finalmente, la dependencia parcial viene dada por un promedio ponderado de todas las hojas visitadas. Para los conjuntos de &amp;aacute;rboles, los resultados de cada &amp;aacute;rbol individual se vuelven a promediar.</target>
        </trans-unit>
        <trans-unit id="719d4a30c8dd97a24789edd5bdd1f3a14cdc8a6c" translate="yes" xml:space="preserve">
          <source>For each word \(i\) in document \(d\):</source>
          <target state="translated">Por cada palabra del documento:</target>
        </trans-unit>
        <trans-unit id="d13eb916a8aa10457ca38f56195d8da451f22b82" translate="yes" xml:space="preserve">
          <source>For efficiency reasons, the euclidean distance between a pair of row vector x and y is computed as:</source>
          <target state="translated">Por razones de eficiencia,la distancia euclidiana entre un par de hileras de vectores x e y se calcula como:</target>
        </trans-unit>
        <trans-unit id="9aa1f675d2607b44cb2ebebaba9400cb8fdf4c6d" translate="yes" xml:space="preserve">
          <source>For evaluating multiple metrics, either give a list of (unique) strings or a dict with names as keys and callables as values.</source>
          <target state="translated">Para evaluar múltiples métricas,o bien dar una lista de cadenas (únicas)o un dictado con nombres como claves y llamables como valores.</target>
        </trans-unit>
        <trans-unit id="091a4026feae279bd855844156c1035b747b54da" translate="yes" xml:space="preserve">
          <source>For example &lt;code&gt;average_precision&lt;/code&gt; or the area under the roc curve can not be computed using discrete predictions alone.</source>
          <target state="translated">Por ejemplo, &lt;code&gt;average_precision&lt;/code&gt; o el &amp;aacute;rea bajo la curva roc no se pueden calcular utilizando predicciones discretas solamente.</target>
        </trans-unit>
        <trans-unit id="d73a71b2256308d0d5e12341f8e7d64f3e849f98" translate="yes" xml:space="preserve">
          <source>For example try instead of the &lt;code&gt;SVC&lt;/code&gt;:</source>
          <target state="translated">Por ejemplo, intente en lugar del &lt;code&gt;SVC&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="541edf61321b8728dd0c7cafa11d713cadb8fb1e" translate="yes" xml:space="preserve">
          <source>For example, a less computationally intensive alternative to &lt;code&gt;LeavePGroupsOut(p=10)&lt;/code&gt; would be &lt;code&gt;GroupShuffleSplit(test_size=10, n_splits=100)&lt;/code&gt;.</source>
          <target state="translated">Por ejemplo, una alternativa menos computacionalmente intensiva a &lt;code&gt;LeavePGroupsOut(p=10)&lt;/code&gt; ser&amp;iacute;a &lt;code&gt;GroupShuffleSplit(test_size=10, n_splits=100)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="65cec63d764ed66c423ae4b0636bcfb02973f7ba" translate="yes" xml:space="preserve">
          <source>For example, a simple linear regression can be extended by constructing &lt;strong&gt;polynomial features&lt;/strong&gt; from the coefficients. In the standard linear regression case, you might have a model that looks like this for two-dimensional data:</source>
          <target state="translated">Por ejemplo, una regresi&amp;oacute;n lineal simple puede extenderse construyendo &lt;strong&gt;caracter&amp;iacute;sticas polin&amp;oacute;micas a&lt;/strong&gt; partir de los coeficientes. En el caso de regresi&amp;oacute;n lineal est&amp;aacute;ndar, es posible que tenga un modelo que se ve as&amp;iacute; para datos bidimensionales:</target>
        </trans-unit>
        <trans-unit id="f87725ef6020293ce39f30b54128c30f50570f0e" translate="yes" xml:space="preserve">
          <source>For example, if each point is just a single number (8 bytes), then an effective \(k\)-NN estimator in a paltry \(p \sim 20\) dimensions would require more training data than the current estimated size of the entire internet (&amp;plusmn;1000 Exabytes or so).</source>
          <target state="translated">Por ejemplo, si cada punto es solo un n&amp;uacute;mero (8 bytes), entonces un estimador \ (k \) - NN efectivo en unas dimensiones insignificantes \ (p \ sim 20 \) requerir&amp;iacute;a m&amp;aacute;s datos de entrenamiento que el tama&amp;ntilde;o estimado actual de todo Internet (&amp;plusmn; 1000 Exabytes m&amp;aacute;s o menos).</target>
        </trans-unit>
        <trans-unit id="5e44134c443036a12804aff41c3842c8f74c39ce" translate="yes" xml:space="preserve">
          <source>For example, in random projection, this warning is raised when the number of components, which quantifies the dimensionality of the target projection space, is higher than the number of features, which quantifies the dimensionality of the original source space, to imply that the dimensionality of the problem will not be reduced.</source>
          <target state="translated">Por ejemplo,en la proyección aleatoria,esta advertencia se plantea cuando el número de componentes,que cuantifica la dimensionalidad del espacio de proyección del objetivo,es mayor que el número de características,que cuantifica la dimensionalidad del espacio fuente original,para implicar que la dimensionalidad del problema no se reducirá.</target>
        </trans-unit>
        <trans-unit id="4bb7f297d1cf6895bcaff7553e1e2a2edd1164e9" translate="yes" xml:space="preserve">
          <source>For example, in the cases of multiple experiments, &lt;a href=&quot;generated/sklearn.model_selection.leaveonegroupout#sklearn.model_selection.LeaveOneGroupOut&quot;&gt;&lt;code&gt;LeaveOneGroupOut&lt;/code&gt;&lt;/a&gt; can be used to create a cross-validation based on the different experiments: we create a training set using the samples of all the experiments except one:</source>
          <target state="translated">Por ejemplo, en los casos de m&amp;uacute;ltiples experimentos, &lt;a href=&quot;generated/sklearn.model_selection.leaveonegroupout#sklearn.model_selection.LeaveOneGroupOut&quot;&gt; &lt;code&gt;LeaveOneGroupOut&lt;/code&gt; &lt;/a&gt; se puede utilizar para crear una validaci&amp;oacute;n cruzada basada en los diferentes experimentos: creamos un conjunto de entrenamiento usando las muestras de todos los experimentos excepto uno:</target>
        </trans-unit>
        <trans-unit id="9dc98c27045ddaa13bc1efc30f0c70951a11ebf1" translate="yes" xml:space="preserve">
          <source>For example, let&amp;rsquo;s look at the results of a multinomial Naive Bayes classifier, which is fast to train and achieves a decent F-score:</source>
          <target state="translated">Por ejemplo, veamos los resultados de un clasificador multinomial Naive Bayes, que es r&amp;aacute;pido de entrenar y logra una puntuaci&amp;oacute;n F decente:</target>
        </trans-unit>
        <trans-unit id="85d6aa34dc31a086da5a0b5a46fa6367e968ccaf" translate="yes" xml:space="preserve">
          <source>For example, let&amp;rsquo;s say we&amp;rsquo;re dealing with a corpus of two documents: &lt;code&gt;['words', 'wprds']&lt;/code&gt;. The second document contains a misspelling of the word &amp;lsquo;words&amp;rsquo;. A simple bag of words representation would consider these two as very distinct documents, differing in both of the two possible features. A character 2-gram representation, however, would find the documents matching in 4 out of 8 features, which may help the preferred classifier decide better:</source>
          <target state="translated">Por ejemplo, digamos que estamos tratando con un corpus de dos documentos: &lt;code&gt;['words', 'wprds']&lt;/code&gt; . El segundo documento contiene un error ortogr&amp;aacute;fico de la palabra &quot;palabras&quot;. Una simple representaci&amp;oacute;n de una bolsa de palabras considerar&amp;iacute;a estos dos documentos muy distintos, que difieren en las dos caracter&amp;iacute;sticas posibles. Sin embargo, una representaci&amp;oacute;n de caracteres de 2 gramos encontrar&amp;iacute;a los documentos coincidentes en 4 de las 8 caracter&amp;iacute;sticas, lo que puede ayudar al clasificador preferido a decidir mejor:</target>
        </trans-unit>
        <trans-unit id="a34fc3c98b3c662bed7829df5d3e68b291f14f22" translate="yes" xml:space="preserve">
          <source>For example, suppose that we have a first algorithm that extracts Part of Speech (PoS) tags that we want to use as complementary tags for training a sequence classifier (e.g. a chunker). The following dict could be such a window of features extracted around the word &amp;lsquo;sat&amp;rsquo; in the sentence &amp;lsquo;The cat sat on the mat.&amp;rsquo;:</source>
          <target state="translated">Por ejemplo, suponga que tenemos un primer algoritmo que extrae etiquetas de parte del habla (PoS) que queremos usar como etiquetas complementarias para entrenar un clasificador de secuencia (por ejemplo, un chunker). El siguiente dict podr&amp;iacute;a ser una ventana de caracter&amp;iacute;sticas extra&amp;iacute;das alrededor de la palabra 'sentado' en la oraci&amp;oacute;n 'El gato se sent&amp;oacute; en la estera':</target>
        </trans-unit>
        <trans-unit id="875d6b4f0ebd92b4525ff9ff007e35a4ef09b992" translate="yes" xml:space="preserve">
          <source>For example, the following snippet uses &lt;code&gt;chardet&lt;/code&gt; (not shipped with scikit-learn, must be installed separately) to figure out the encoding of three texts. It then vectorizes the texts and prints the learned vocabulary. The output is not shown here.</source>
          <target state="translated">Por ejemplo, el siguiente fragmento usa &lt;code&gt;chardet&lt;/code&gt; (no se env&amp;iacute;a con scikit-learn, debe instalarse por separado) para averiguar la codificaci&amp;oacute;n de tres textos. Luego vectoriza los textos e imprime el vocabulario aprendido. La salida no se muestra aqu&amp;iacute;.</target>
        </trans-unit>
        <trans-unit id="a5b55b26c17fcbb577abf03053fdea355f9d1a85" translate="yes" xml:space="preserve">
          <source>For example, this warning may occur when the user</source>
          <target state="translated">Por ejemplo,esta advertencia puede ocurrir cuando el usuario</target>
        </trans-unit>
        <trans-unit id="fa61683485e98ae724ab66c0cc502f9a28b6f341" translate="yes" xml:space="preserve">
          <source>For example, to download a dataset of gene expressions in mice brains:</source>
          <target state="translated">Por ejemplo,para descargar un conjunto de datos de expresiones genéticas en cerebros de ratones:</target>
        </trans-unit>
        <trans-unit id="bea8752fb35944e93422e8c1c3a159c63e531901" translate="yes" xml:space="preserve">
          <source>For example, we can compute the tf-idf of the first term in the first document in the &lt;code&gt;counts&lt;/code&gt; array as follows:</source>
          <target state="translated">Por ejemplo, podemos calcular el tf-idf del primer t&amp;eacute;rmino en el primer documento en la matriz de &lt;code&gt;counts&lt;/code&gt; siguiente manera:</target>
        </trans-unit>
        <trans-unit id="8e5e851ba9e40a81086c0f41a19109e3eeaaee54" translate="yes" xml:space="preserve">
          <source>For example, when dealing with boolean features, \(x_i^n = x_i\) for all \(n\) and is therefore useless; but \(x_i x_j\) represents the conjunction of two booleans. This way, we can solve the XOR problem with a linear classifier:</source>
          <target state="translated">Por ejemplo,cuando se trata de características booleanas,\N \N \N â??x_i^n=x_i\N para todos y por lo tanto es inútil;pero \N \N \N â??x_i x_jâ?)representa la conjunción de dos booleanos.De esta manera,podemos resolver el problema de XOR con un clasificador lineal:</target>
        </trans-unit>
        <trans-unit id="dfe2d757676022996b9aa748350ec295d5357a7e" translate="yes" xml:space="preserve">
          <source>For example, when using a validation set, set the &lt;code&gt;test_fold&lt;/code&gt; to 0 for all samples that are part of the validation set, and to -1 for all other samples.</source>
          <target state="translated">Por ejemplo, cuando utilice un conjunto de validaci&amp;oacute;n, establezca &lt;code&gt;test_fold&lt;/code&gt; en 0 para todas las muestras que forman parte del conjunto de validaci&amp;oacute;n y en -1 para todas las dem&amp;aacute;s muestras.</target>
        </trans-unit>
        <trans-unit id="98a47ab600b3d6adb5169d4d316e6fcca6b662b8" translate="yes" xml:space="preserve">
          <source>For examples on how it is to be used refer to the sections below.</source>
          <target state="translated">En las secciones que figuran a continuación se dan ejemplos de su utilización.</target>
        </trans-unit>
        <trans-unit id="1fd7dfc113fdc87e0b1f446fd7d77e9da35e9457" translate="yes" xml:space="preserve">
          <source>For further details on bias-variance decomposition, see section 7.3 of &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="translated">Para obtener m&amp;aacute;s detalles sobre la descomposici&amp;oacute;n de la varianza-sesgo, consulte la secci&amp;oacute;n 7.3 de &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2f1f137cd461ac2e31c6cc087610e0dfea901ed1" translate="yes" xml:space="preserve">
          <source>For further details, &amp;ldquo;How to Use t-SNE Effectively&amp;rdquo; &lt;a href=&quot;http://distill.pub/2016/misread-tsne/&quot;&gt;http://distill.pub/2016/misread-tsne/&lt;/a&gt; provides a good discussion of the effects of various parameters, as well as interactive plots to explore those effects.</source>
          <target state="translated">Para obtener m&amp;aacute;s detalles, &quot;C&amp;oacute;mo usar t-SNE de manera efectiva&quot; &lt;a href=&quot;http://distill.pub/2016/misread-tsne/&quot;&gt;http://distill.pub/2016/misread-tsne/&lt;/a&gt; proporciona una buena discusi&amp;oacute;n de los efectos de varios par&amp;aacute;metros, as&amp;iacute; como gr&amp;aacute;ficos interactivos para explorar esos efectos.</target>
        </trans-unit>
        <trans-unit id="0f1bbe6e8000be72ab1e63dd45896ee0e4b6eb7a" translate="yes" xml:space="preserve">
          <source>For greyscale image data where pixel values can be interpreted as degrees of blackness on a white background, like handwritten digit recognition, the Bernoulli Restricted Boltzmann machine model (&lt;a href=&quot;../../modules/generated/sklearn.neural_network.bernoullirbm#sklearn.neural_network.BernoulliRBM&quot;&gt;&lt;code&gt;BernoulliRBM&lt;/code&gt;&lt;/a&gt;) can perform effective non-linear feature extraction.</source>
          <target state="translated">Para datos de imagen en escala de grises donde los valores de p&amp;iacute;xeles se pueden interpretar como grados de negrura sobre un fondo blanco, como el reconocimiento de d&amp;iacute;gitos escritos a mano, el modelo de m&amp;aacute;quina Bernoulli Restricted Boltzmann ( &lt;a href=&quot;../../modules/generated/sklearn.neural_network.bernoullirbm#sklearn.neural_network.BernoulliRBM&quot;&gt; &lt;code&gt;BernoulliRBM&lt;/code&gt; &lt;/a&gt; ) puede realizar una extracci&amp;oacute;n de caracter&amp;iacute;sticas no lineal efectiva.</target>
        </trans-unit>
        <trans-unit id="866314f9db098f25a642d6cb6f4a133adac68ce1" translate="yes" xml:space="preserve">
          <source>For high-dimensional datasets with many collinear regressors, &lt;a href=&quot;generated/sklearn.linear_model.lassocv#sklearn.linear_model.LassoCV&quot;&gt;&lt;code&gt;LassoCV&lt;/code&gt;&lt;/a&gt; is most often preferable. However, &lt;a href=&quot;generated/sklearn.linear_model.lassolarscv#sklearn.linear_model.LassoLarsCV&quot;&gt;&lt;code&gt;LassoLarsCV&lt;/code&gt;&lt;/a&gt; has the advantage of exploring more relevant values of &lt;code&gt;alpha&lt;/code&gt; parameter, and if the number of samples is very small compared to the number of features, it is often faster than &lt;a href=&quot;generated/sklearn.linear_model.lassocv#sklearn.linear_model.LassoCV&quot;&gt;&lt;code&gt;LassoCV&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Para conjuntos de datos de alta dimensi&amp;oacute;n con muchos regresores colineales, &lt;a href=&quot;generated/sklearn.linear_model.lassocv#sklearn.linear_model.LassoCV&quot;&gt; &lt;code&gt;LassoCV&lt;/code&gt; &lt;/a&gt; es a menudo preferible. Sin embargo, &lt;a href=&quot;generated/sklearn.linear_model.lassolarscv#sklearn.linear_model.LassoLarsCV&quot;&gt; &lt;code&gt;LassoLarsCV&lt;/code&gt; &lt;/a&gt; tiene la ventaja de explorar valores m&amp;aacute;s relevantes del par&amp;aacute;metro &lt;code&gt;alpha&lt;/code&gt; , y si el n&amp;uacute;mero de muestras es muy peque&amp;ntilde;o en comparaci&amp;oacute;n con el n&amp;uacute;mero de caracter&amp;iacute;sticas, a menudo es m&amp;aacute;s r&amp;aacute;pido que &lt;a href=&quot;generated/sklearn.linear_model.lassocv#sklearn.linear_model.LassoCV&quot;&gt; &lt;code&gt;LassoCV&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="aff7e1aca1f3054316321a609c5b24bbfe0a02a6" translate="yes" xml:space="preserve">
          <source>For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G. T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C. L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469, 1994.</source>
          <target state="translated">Para información sobre las rutinas de preprocesamiento del NIST,véase M.D.Garris,J.L.Blue,G.T.Candela,D.L.Dimmick,J.Geist,P.J.Grother,S.A.Janet,y C.L.Wilson,NIST Form-Based Handprint Recognition System,NISTIR 5469,1994.</target>
        </trans-unit>
        <trans-unit id="ee57e485cfe4c61d12541e3ea6e169aab79014e8" translate="yes" xml:space="preserve">
          <source>For instance a collection of 10,000 short text documents (such as emails) will use a vocabulary with a size in the order of 100,000 unique words in total while each document will use 100 to 1000 unique words individually.</source>
          <target state="translated">Por ejemplo,una colección de 10.000 documentos de texto corto (como los correos electrónicos)utilizará un vocabulario con un tamaño del orden de 100.000 palabras únicas en total,mientras que cada documento utilizará de 100 a 1000 palabras únicas individualmente.</target>
        </trans-unit>
        <trans-unit id="4e9f2f3fee78ca296cddfe5ea5b4e060f79a0a4e" translate="yes" xml:space="preserve">
          <source>For instance many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the L1 and L2 regularizers of linear models) assume that all features are centered around 0 and have variance in the same order. If a feature has a variance that is orders of magnitude larger that others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.</source>
          <target state="translated">Por ejemplo,muchos elementos utilizados en la función objetiva de un algoritmo de aprendizaje (como el núcleo RBF de las máquinas vectoriales de apoyo o los regularizadores L1 y L2 de los modelos lineales)suponen que todas las características están centradas en torno a 0 y tienen una varianza en el mismo orden.Si una característica tiene una varianza de órdenes de magnitud mayores que otras,podría dominar la función objetiva y hacer que el estimador no pueda aprender de otras características correctamente como se espera.</target>
        </trans-unit>
        <trans-unit id="9c54ff6618aa4505fc044efee7a1b7aa2d457afd" translate="yes" xml:space="preserve">
          <source>For instance the below given table</source>
          <target state="translated">Por ejemplo,el siguiente cuadro</target>
        </trans-unit>
        <trans-unit id="61fc71afaf6946d5d1cad0702c1f4030326fcb83" translate="yes" xml:space="preserve">
          <source>For instance the groups could be the year of collection of the samples and thus allow for cross-validation against time-based splits.</source>
          <target state="translated">Por ejemplo,los grupos podrían ser el año de la recogida de las muestras y así permitir la validación cruzada contra las divisiones basadas en el tiempo.</target>
        </trans-unit>
        <trans-unit id="c007161505dacd37b43b63ce0c84bfbd3ce25160" translate="yes" xml:space="preserve">
          <source>For instance, assuming that the inlier data are Gaussian distributed, it will estimate the inlier location and covariance in a robust way (i.e. without being influenced by outliers). The Mahalanobis distances obtained from this estimate is used to derive a measure of outlyingness. This strategy is illustrated below.</source>
          <target state="translated">Por ejemplo,suponiendo que los datos anteriores estén distribuidos en Gauss,estimará la ubicación y covarianza anterior de manera sólida (es decir,sin dejarse influir por los valores atípicos).Las distancias de Mahalanobis obtenidas a partir de esta estimación se utilizan para derivar una medida de los valores atípicos.Esta estrategia se ilustra a continuación.</target>
        </trans-unit>
        <trans-unit id="7519828cefe279ed0b1f593fd20db7243c914832" translate="yes" xml:space="preserve">
          <source>For instance, given a matrix of shape &lt;code&gt;(10, 10)&lt;/code&gt;, one possible bicluster with three rows and two columns induces a submatrix of shape &lt;code&gt;(3, 2)&lt;/code&gt;:</source>
          <target state="translated">Por ejemplo, dada una matriz de forma &lt;code&gt;(10, 10)&lt;/code&gt; , un posible bicluster con tres filas y dos columnas induce una submatriz de forma &lt;code&gt;(3, 2)&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="66b8e52235d720becae09b00e19696b279a13527" translate="yes" xml:space="preserve">
          <source>For instance, if \(p\) singular vectors were calculated, the \(q\) best are found as described, where \(q&amp;lt;p\). Let \(U\) be the matrix with columns the \(q\) best left singular vectors, and similarly \(V\) for the right. To partition the rows, the rows of \(A\) are projected to a \(q\) dimensional space: \(A * V\). Treating the \(m\) rows of this \(m \times q\) matrix as samples and clustering using k-means yields the row labels. Similarly, projecting the columns to \(A^{\top} * U\) and clustering this \(n \times q\) matrix yields the column labels.</source>
          <target state="translated">Por ejemplo, si se calcularon \ (p \) vectores singulares, los \ (q \) mejores se encuentran como se describe, donde \ (q &amp;lt;p \). Sea \ (U \) la matriz con columnas los \ (q \) mejores vectores singulares izquierdos, y de manera similar \ (V \) para el derecho. Para dividir las filas, las filas de \ (A \) se proyectan en un espacio dimensional \ (q \): \ (A * V \). Si se tratan las filas \ (m \) de esta matriz \ (m \ times q \) como muestras y se agrupan con k-medias, se obtienen las etiquetas de las filas. De manera similar, proyectar las columnas a \ (A ^ {\ top} * U \) y agrupar esta matriz \ (n \ times q \) produce las etiquetas de columna.</target>
        </trans-unit>
        <trans-unit id="040e034a022032a75dc3b85f4ce9de7cff88a6fc" translate="yes" xml:space="preserve">
          <source>For instance, if we work with 64x64 pixel gray-level pictures for face recognition, the dimensionality of the data is 4096 and it is slow to train an RBF support vector machine on such wide data. Furthermore we know that the intrinsic dimensionality of the data is much lower than 4096 since all pictures of human faces look somewhat alike. The samples lie on a manifold of much lower dimension (say around 200 for instance). The PCA algorithm can be used to linearly transform the data while both reducing the dimensionality and preserve most of the explained variance at the same time.</source>
          <target state="translated">Por ejemplo,si trabajamos con imágenes de nivel de gris de 64x64 píxeles para el reconocimiento facial,la dimensionalidad de los datos es de 4096 y es lento entrenar una máquina de vector de soporte de RBF en datos tan amplios.Además sabemos que la dimensionalidad intrínseca de los datos es mucho menor que 4096 ya que todas las imágenes de rostros humanos se parecen un poco.Las muestras se encuentran en un múltiplo de dimensiones mucho más bajas (digamos alrededor de 200,por ejemplo).El algoritmo de PCA puede utilizarse para transformar linealmente los datos,reduciendo la dimensionalidad y conservando al mismo tiempo la mayor parte de la varianza explicada.</target>
        </trans-unit>
        <trans-unit id="f676ab37a8d5ec2f850de1fcd3ee779d6ce55a52" translate="yes" xml:space="preserve">
          <source>For instance, in the case of the digits dataset, &lt;code&gt;digits.data&lt;/code&gt; gives access to the features that can be used to classify the digits samples:</source>
          <target state="translated">Por ejemplo, en el caso del conjunto de datos de d&amp;iacute;gitos, &lt;code&gt;digits.data&lt;/code&gt; da acceso a las caracter&amp;iacute;sticas que se pueden usar para clasificar las muestras de d&amp;iacute;gitos:</target>
        </trans-unit>
        <trans-unit id="0b72faa109feccaf14265d5a54672e188bc4b73a" translate="yes" xml:space="preserve">
          <source>For instance, in the example below, decision trees learn from data to approximate a sine curve with a set of if-then-else decision rules. The deeper the tree, the more complex the decision rules and the fitter the model.</source>
          <target state="translated">Por ejemplo,en el siguiente ejemplo,los árboles de decisión aprenden de los datos para aproximarse a una curva sinusoidal con un conjunto de reglas de decisión de &quot;si luego no&quot;.Cuanto más profundo es el árbol,más complejas son las reglas de decisión y más ajustado es el modelo.</target>
        </trans-unit>
        <trans-unit id="bb4b6181584be99d136bb8fd3d82dd09da37eec0" translate="yes" xml:space="preserve">
          <source>For instance, many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the l1 and l2 regularizers of linear models) assume that all features are centered around zero and have variance in the same order. If a feature has a variance that is orders of magnitude larger than others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.</source>
          <target state="translated">Por ejemplo,muchos elementos utilizados en la función objetiva de un algoritmo de aprendizaje (como el núcleo RBF de las máquinas vectoriales de apoyo o los regularizadores l1 y l2 de los modelos lineales)suponen que todas las características están centradas en torno a cero y tienen una varianza en el mismo orden.Si una característica tiene una varianza de órdenes de magnitud mayores que otras,podría dominar la función objetiva y hacer que el estimador no pueda aprender de otras características correctamente como se espera.</target>
        </trans-unit>
        <trans-unit id="2500a85d8a54066d44afc291418c2bdbdb2d8331" translate="yes" xml:space="preserve">
          <source>For instance, the following shows 16 sample portraits (centered around 0.0) from the Olivetti dataset. On the right hand side are the first 16 singular vectors reshaped as portraits. Since we only require the top 16 singular vectors of a dataset with size \(n_{samples} = 400\) and \(n_{features} = 64 \times 64 = 4096\), the computation time is less than 1s:</source>
          <target state="translated">Por ejemplo,a continuación se muestran 16 retratos de muestra (centrados en torno a 0,0)del conjunto de datos de Olivetti.A la derecha están los primeros 16 vectores singulares remodelados como retratos.Dado que sólo requerimos los 16 vectores singulares superiores de un conjunto de datos con tamaño \(n_{muestras}=400\)y \(n_{características}=64 \ veces 64=4096\),el tiempo de cálculo es inferior a 1s:</target>
        </trans-unit>
        <trans-unit id="8f189274df939cb66095eb188cc3a399c86cb294" translate="yes" xml:space="preserve">
          <source>For instance, we can perform a \(\chi^2\) test to the samples to retrieve only the two best features as follows:</source>
          <target state="translated">Por ejemplo,podemos realizar una prueba a las muestras para recuperar sólo las dos mejores características de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="abc897209b2f98b7966665fa36a5eddbbc44f66d" translate="yes" xml:space="preserve">
          <source>For instance:</source>
          <target state="translated">Por ejemplo:</target>
        </trans-unit>
        <trans-unit id="21205df9d4ba13a75af14823666b84f64bd04084" translate="yes" xml:space="preserve">
          <source>For integer/None inputs &lt;code&gt;KFold&lt;/code&gt; is used.</source>
          <target state="translated">Para entradas enteras / Ninguna, se utiliza &lt;code&gt;KFold&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f4cdf9352c6e062816193041b97f5514c42b421e" translate="yes" xml:space="preserve">
          <source>For integer/None inputs, &lt;code&gt;KFold&lt;/code&gt; is used.</source>
          <target state="translated">Para entradas enteras / Ninguna, se utiliza &lt;code&gt;KFold&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f206c091dc56a7e693c1c1efe6b0899c57cec04a" translate="yes" xml:space="preserve">
          <source>For integer/None inputs, if &lt;code&gt;y&lt;/code&gt; is binary or multiclass, &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;sklearn.model_selection.StratifiedKFold&lt;/code&gt;&lt;/a&gt; is used, else, &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;sklearn.model_selection.KFold&lt;/code&gt;&lt;/a&gt; is used.</source>
          <target state="translated">Para entradas enteras / Ninguna, si &lt;code&gt;y&lt;/code&gt; es binario o multiclase, se usa &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;sklearn.model_selection.StratifiedKFold&lt;/code&gt; &lt;/a&gt; , de lo contrario, se usa &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;sklearn.model_selection.KFold&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="84373ac49af10a751441a8470e060e3de62490b1" translate="yes" xml:space="preserve">
          <source>For integer/None inputs, if &lt;code&gt;y&lt;/code&gt; is binary or multiclass, &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;sklearn.model_selection.StratifiedKFold&lt;/code&gt;&lt;/a&gt; is used. If &lt;code&gt;y&lt;/code&gt; is neither binary nor multiclass, &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;sklearn.model_selection.KFold&lt;/code&gt;&lt;/a&gt; is used.</source>
          <target state="translated">Para entradas enteras / Ninguna, si &lt;code&gt;y&lt;/code&gt; es binario o multiclase, se usa &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;sklearn.model_selection.StratifiedKFold&lt;/code&gt; &lt;/a&gt; . Si &lt;code&gt;y&lt;/code&gt; no es ni binario ni multiclase, se utiliza &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;sklearn.model_selection.KFold&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="8d4fea32021fed22e35126e0e01d0c620369dc78" translate="yes" xml:space="preserve">
          <source>For integer/None inputs, if &lt;code&gt;y&lt;/code&gt; is binary or multiclass, &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;sklearn.model_selection.StratifiedKFold&lt;/code&gt;&lt;/a&gt; is used. If the estimator is a classifier or if &lt;code&gt;y&lt;/code&gt; is neither binary nor multiclass, &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;sklearn.model_selection.KFold&lt;/code&gt;&lt;/a&gt; is used.</source>
          <target state="translated">Para entradas enteras / Ninguna, si &lt;code&gt;y&lt;/code&gt; es binario o multiclase, se usa &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;sklearn.model_selection.StratifiedKFold&lt;/code&gt; &lt;/a&gt; . Si el estimador es un clasificador o si &lt;code&gt;y&lt;/code&gt; no es binario ni multiclase, se utiliza &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;sklearn.model_selection.KFold&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="68ad85210cd514ab63c161f2689020aa738ee186" translate="yes" xml:space="preserve">
          <source>For integer/None inputs, if classifier is True and &lt;code&gt;y&lt;/code&gt; is either binary or multiclass, &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; is used. In all other cases, &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; is used.</source>
          <target state="translated">Para entradas enteras / Ninguna, si el clasificador es Verdadero e &lt;code&gt;y&lt;/code&gt; es binario o multiclase, se usa &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;StratifiedKFold&lt;/code&gt; &lt;/a&gt; . En todos los dem&amp;aacute;s casos, se utiliza &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="821cadb32f750528bd31875526972b81201437b9" translate="yes" xml:space="preserve">
          <source>For integer/None inputs, if the estimator is a classifier and &lt;code&gt;y&lt;/code&gt; is either binary or multiclass, &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; is used. In all other cases, &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; is used.</source>
          <target state="translated">Para entradas de n&amp;uacute;mero entero / Ninguno, si el estimador es un clasificador y &lt;code&gt;y&lt;/code&gt; es binario o multiclase, se utiliza &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;StratifiedKFold&lt;/code&gt; &lt;/a&gt; . En todos los dem&amp;aacute;s casos, se utiliza &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="cfc9bcb00c8530f8c99a68584e1330a4da8fc56a" translate="yes" xml:space="preserve">
          <source>For intermediate values, we can see on the second plot that good models can be found on a diagonal of &lt;code&gt;C&lt;/code&gt; and &lt;code&gt;gamma&lt;/code&gt;. Smooth models (lower &lt;code&gt;gamma&lt;/code&gt; values) can be made more complex by increasing the importance of classifying each point correctly (larger &lt;code&gt;C&lt;/code&gt; values) hence the diagonal of good performing models.</source>
          <target state="translated">Para valores intermedios, podemos ver en el segundo gr&amp;aacute;fico que se pueden encontrar buenos modelos en una diagonal de &lt;code&gt;C&lt;/code&gt; y &lt;code&gt;gamma&lt;/code&gt; . Los modelos suaves ( valores &lt;code&gt;gamma&lt;/code&gt; m&amp;aacute;s bajos) se pueden hacer m&amp;aacute;s complejos aumentando la importancia de clasificar cada punto correctamente ( valores &lt;code&gt;C&lt;/code&gt; m&amp;aacute;s altos), por lo tanto, la diagonal de los modelos de buen rendimiento.</target>
        </trans-unit>
        <trans-unit id="eb96f16ecd15a6be088f1dc93fa28ca4ca7ecca5" translate="yes" xml:space="preserve">
          <source>For kernel=&amp;rdquo;precomputed&amp;rdquo;, the expected shape of X is (n_samples_test, n_samples_train).</source>
          <target state="translated">Para kernel = &amp;rdquo;precalculado&amp;rdquo;, la forma esperada de X es (n_samples_test, n_samples_train).</target>
        </trans-unit>
        <trans-unit id="93c16e02e4641d6fe7bdb8a83439c237817b53cd" translate="yes" xml:space="preserve">
          <source>For kernel=&amp;rdquo;precomputed&amp;rdquo;, the expected shape of X is [n_samples_test, n_samples_train]</source>
          <target state="translated">Para kernel = &quot;precalculado&quot;, la forma esperada de X es [n_samples_test, n_samples_train]</target>
        </trans-unit>
        <trans-unit id="9cb299cfc771ccbc3a241c16ffeed37fabbcff7c" translate="yes" xml:space="preserve">
          <source>For large dataset, you may also consider using &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;SGDClassifier&lt;/code&gt;&lt;/a&gt; with &amp;lsquo;log&amp;rsquo; loss.</source>
          <target state="translated">Para conjuntos de datos grandes, tambi&amp;eacute;n puede considerar usar &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;SGDClassifier&lt;/code&gt; &lt;/a&gt; con p&amp;eacute;rdida de 'registro'.</target>
        </trans-unit>
        <trans-unit id="98187e1f181515ca77d41de7fa27ac44b69c7c11" translate="yes" xml:space="preserve">
          <source>For many estimators, including the SVMs, having datasets with unit standard deviation for each feature is important to get good prediction.</source>
          <target state="translated">Para muchos estimadores,incluidos los SVM,tener conjuntos de datos con desviación estándar unitaria para cada característica es importante para obtener una buena predicción.</target>
        </trans-unit>
        <trans-unit id="f1359c1e0656157adbc7e3ee11ae253cb961bb70" translate="yes" xml:space="preserve">
          <source>For mono-output tasks it is:</source>
          <target state="translated">Para las tareas de salida única lo es:</target>
        </trans-unit>
        <trans-unit id="c24592da8118b35d1dd067bf2a75576669aef344" translate="yes" xml:space="preserve">
          <source>For more information see: Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) &amp;ldquo;Least Angle Regression,&amp;rdquo; Annals of Statistics (with discussion), 407-499. (&lt;a href=&quot;http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&lt;/a&gt;)</source>
          <target state="translated">Para obtener m&amp;aacute;s informaci&amp;oacute;n, consulte: Bradley Efron, Trevor Hastie, Iain Johnstone y Robert Tibshirani (2004) &amp;ldquo;Least Angle Regression&amp;rdquo;, Annals of Statistics (con discusi&amp;oacute;n), 407-499. ( &lt;a href=&quot;http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="a4bc4c3f735998ec8c1614ec6127a37e3e7a02d8" translate="yes" xml:space="preserve">
          <source>For more information, see &lt;a href=&quot;../../modules/clustering#hierarchical-clustering&quot;&gt;Hierarchical clustering&lt;/a&gt;.</source>
          <target state="translated">Para obtener m&amp;aacute;s informaci&amp;oacute;n, consulte &lt;a href=&quot;../../modules/clustering#hierarchical-clustering&quot;&gt;Agrupaci&amp;oacute;n jer&amp;aacute;rquica&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="b089e1ecd97ba592f22037a3c3fabf2924387c39" translate="yes" xml:space="preserve">
          <source>For more on usage see the &lt;a href=&quot;../feature_selection#univariate-feature-selection&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">Para obtener m&amp;aacute;s informaci&amp;oacute;n sobre el uso, consulte la &lt;a href=&quot;../feature_selection#univariate-feature-selection&quot;&gt;Gu&amp;iacute;a del usuario&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2e682df49d58d058f1f4b4c26ca6fb15a2f979d8" translate="yes" xml:space="preserve">
          <source>For multi-class classification, &lt;a href=&quot;generated/sklearn.ensemble.adaboostclassifier#sklearn.ensemble.AdaBoostClassifier&quot;&gt;&lt;code&gt;AdaBoostClassifier&lt;/code&gt;&lt;/a&gt; implements AdaBoost-SAMME and AdaBoost-SAMME.R &lt;a href=&quot;#zzrh2009&quot; id=&quot;id11&quot;&gt;[ZZRH2009]&lt;/a&gt;.</source>
          <target state="translated">Para la clasificaci&amp;oacute;n de clases m&amp;uacute;ltiples, &lt;a href=&quot;generated/sklearn.ensemble.adaboostclassifier#sklearn.ensemble.AdaBoostClassifier&quot;&gt; &lt;code&gt;AdaBoostClassifier&lt;/code&gt; &lt;/a&gt; implementa AdaBoost-SAMME y AdaBoost-SAMME.R &lt;a href=&quot;#zzrh2009&quot; id=&quot;id11&quot;&gt;[ZZRH2009]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="416ab9ed1829c79f2f091ddf9b13cfb5bb7486ce" translate="yes" xml:space="preserve">
          <source>For multi-class classification, n_class classifiers are trained in a one-versus-all approach. Concretely, this is implemented by taking advantage of the multi-variate response support in Ridge.</source>
          <target state="translated">Para la clasificación multiclase,los clasificadores n_clase se entrenan en un enfoque de uno contra todos.Concretamente,esto se implementa aprovechando el apoyo de respuesta multivariante en Ridge.</target>
        </trans-unit>
        <trans-unit id="65042013a5d26811a6a7088f4c47e70c6ddb0074" translate="yes" xml:space="preserve">
          <source>For multi-class models, you need to set the class label for which the PDPs should be created via the &lt;code&gt;label&lt;/code&gt; argument:</source>
          <target state="translated">Para modelos de varias clases, debe establecer la etiqueta de clase para la que se deben crear los PDP a trav&amp;eacute;s del argumento de &lt;code&gt;label&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="ccc2264ef7a998ec0c6ed9c92245080e0f0807c7" translate="yes" xml:space="preserve">
          <source>For multi-metric evaluation, the scores for all the scorers are available in the &lt;code&gt;cv_results_&lt;/code&gt; dict at the keys ending with that scorer&amp;rsquo;s name (&lt;code&gt;'_&amp;lt;scorer_name&amp;gt;'&lt;/code&gt;) instead of &lt;code&gt;'_score'&lt;/code&gt; shown above. (&amp;lsquo;split0_test_precision&amp;rsquo;, &amp;lsquo;mean_train_precision&amp;rsquo; etc.)</source>
          <target state="translated">Para la evaluaci&amp;oacute;n &lt;code&gt;cv_results_&lt;/code&gt; , las puntuaciones de todos los anotadores est&amp;aacute;n disponibles en el dictado cv_results_ en las claves que terminan con el nombre de ese anotador ( &lt;code&gt;'_&amp;lt;scorer_name&amp;gt;'&lt;/code&gt; ) en lugar de &lt;code&gt;'_score'&lt;/code&gt; que se muestra arriba. ('split0_test_precision', 'mean_train_precision', etc.)</target>
        </trans-unit>
        <trans-unit id="6cd27769ef18013ec211b9a824f9bced7dd1ce74" translate="yes" xml:space="preserve">
          <source>For multi-metric evaluation, this attribute holds the validated &lt;code&gt;scoring&lt;/code&gt; dict which maps the scorer key to the scorer callable.</source>
          <target state="translated">Para la evaluaci&amp;oacute;n multim&amp;eacute;trica, este atributo contiene el dictado de &lt;code&gt;scoring&lt;/code&gt; validado que asigna la clave del anotador al anotador que se puede llamar.</target>
        </trans-unit>
        <trans-unit id="39c0f65b87a914c1f3244978c44bbc4d0d1190be" translate="yes" xml:space="preserve">
          <source>For multi-metric evaluation, this attribute is present only if &lt;code&gt;refit&lt;/code&gt; is specified.</source>
          <target state="translated">Para la evaluaci&amp;oacute;n multim&amp;eacute;trica, este atributo est&amp;aacute; presente solo si se especifica &lt;code&gt;refit&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="dd788cb84c37fa5cbd110321907573fb764ddce9" translate="yes" xml:space="preserve">
          <source>For multi-metric evaluation, this is not available if &lt;code&gt;refit&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;. See &lt;code&gt;refit&lt;/code&gt; parameter for more information.</source>
          <target state="translated">Para la evaluaci&amp;oacute;n multim&amp;eacute;trica, esto no est&amp;aacute; disponible si &lt;code&gt;refit&lt;/code&gt; es &lt;code&gt;False&lt;/code&gt; . Consulte el par&amp;aacute;metro de &lt;code&gt;refit&lt;/code&gt; para obtener m&amp;aacute;s informaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="4367b150d838b05eaff7170a1426f1dc4e6edc76" translate="yes" xml:space="preserve">
          <source>For multi-metric evaluation, this is present only if &lt;code&gt;refit&lt;/code&gt; is specified.</source>
          <target state="translated">Para la evaluaci&amp;oacute;n multim&amp;eacute;trica, esto solo est&amp;aacute; presente si se especifica &lt;code&gt;refit&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d328aa31182c6b57c5d921c1da1c7333c03486fe" translate="yes" xml:space="preserve">
          <source>For multi-output tasks it is:</source>
          <target state="translated">Para tareas con múltiples salidas lo es:</target>
        </trans-unit>
        <trans-unit id="22c12fa701004eab18f67dae2fb9f6cb3b68f428" translate="yes" xml:space="preserve">
          <source>For multi-output, the weights of each column of y will be multiplied.</source>
          <target state="translated">Para la salida múltiple,se multiplicarán los pesos de cada columna de y.</target>
        </trans-unit>
        <trans-unit id="77f8b599f18368a52e2142c2cada7c61eef9fbca" translate="yes" xml:space="preserve">
          <source>For multiclass classification with a &amp;ldquo;negative class&amp;rdquo;, it is possible to exclude some labels:</source>
          <target state="translated">Para la clasificaci&amp;oacute;n multiclase con una &quot;clase negativa&quot;, es posible excluir algunas etiquetas:</target>
        </trans-unit>
        <trans-unit id="393c73f8bfb73747a6a85987ccf51d73c8d3636f" translate="yes" xml:space="preserve">
          <source>For multiclass problems, only &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo;, &amp;lsquo;saga&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; handle multinomial loss; &amp;lsquo;liblinear&amp;rsquo; is limited to one-versus-rest schemes.</source>
          <target state="translated">Para problemas multiclase, solo 'newton-cg', 'sag', 'saga' y 'lbfgs' manejan la p&amp;eacute;rdida multinomial; 'liblinear' se limita a esquemas uno versus resto.</target>
        </trans-unit>
        <trans-unit id="de227a68bb98af9d7f682ac4556427f028c04d66" translate="yes" xml:space="preserve">
          <source>For multiple labels per instance, use &lt;a href=&quot;generated/sklearn.preprocessing.multilabelbinarizer#sklearn.preprocessing.MultiLabelBinarizer&quot;&gt;&lt;code&gt;MultiLabelBinarizer&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">Para varias etiquetas por instancia, use &lt;a href=&quot;generated/sklearn.preprocessing.multilabelbinarizer#sklearn.preprocessing.MultiLabelBinarizer&quot;&gt; &lt;code&gt;MultiLabelBinarizer&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="088c3cd08ec3b30c1e8d705dc9f773b25266ffd1" translate="yes" xml:space="preserve">
          <source>For multiple metric evaluation, this needs to be a string denoting the scorer is used to find the best parameters for refitting the estimator at the end.</source>
          <target state="translated">Para la evaluación de métricas múltiples,ésta debe ser una cadena que denote que el anotador se utiliza para encontrar los mejores parámetros para reajustar el estimador al final.</target>
        </trans-unit>
        <trans-unit id="ab406c3bb6ddaeec6408e58ba4985d8a5097ee33" translate="yes" xml:space="preserve">
          <source>For multiple metric evaluation, this needs to be a string denoting the scorer that would be used to find the best parameters for refitting the estimator at the end.</source>
          <target state="translated">Para la evaluación de métricas múltiples,ésta debe ser una cadena que denote el calificador que se utilizaría para encontrar los mejores parámetros para reajustar el estimador al final.</target>
        </trans-unit>
        <trans-unit id="f895ac59b8264ca94c275f903e2d6c6c438b4c9c" translate="yes" xml:space="preserve">
          <source>For multiplicative-update (&amp;lsquo;mu&amp;rsquo;) solver, the Frobenius norm (0.5 * ||X - WH||_Fro^2) can be changed into another beta-divergence loss, by changing the beta_loss parameter.</source>
          <target state="translated">Para el solucionador de actualizaci&amp;oacute;n multiplicativa ('mu'), la norma de Frobenius (0.5 * || X - WH || _Fro ^ 2) se puede cambiar a otra p&amp;eacute;rdida de divergencia beta, cambiando el par&amp;aacute;metro beta_loss.</target>
        </trans-unit>
        <trans-unit id="4d0bed9bc5aa3b36bb0ba6ad6bc592a5bb3e78af" translate="yes" xml:space="preserve">
          <source>For n_components == &amp;lsquo;mle&amp;rsquo;, this class uses the method of &lt;code&gt;Minka, T. P. &amp;ldquo;Automatic choice of dimensionality for PCA&amp;rdquo;. In NIPS, pp. 598-604&lt;/code&gt;</source>
          <target state="translated">Para n_components == 'mle', esta clase utiliza el m&amp;eacute;todo de &lt;code&gt;Minka, T. P. &amp;ldquo;Automatic choice of dimensionality for PCA&amp;rdquo;. In NIPS, pp. 598-604&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="9f27cc961ae174b8e96b15764c2907159174c2c2" translate="yes" xml:space="preserve">
          <source>For non-sparse models, i.e. when there are not many zeros in &lt;code&gt;coef_&lt;/code&gt;, this may actually &lt;em&gt;increase&lt;/em&gt; memory usage, so use this method with care. A rule of thumb is that the number of zero elements, which can be computed with &lt;code&gt;(coef_ == 0).sum()&lt;/code&gt;, must be more than 50% for this to provide significant benefits.</source>
          <target state="translated">Para modelos no dispersos, es decir, cuando no hay muchos ceros en &lt;code&gt;coef_&lt;/code&gt; , esto puede &lt;em&gt;aumentar el&lt;/em&gt; uso de memoria, as&amp;iacute; que use este m&amp;eacute;todo con cuidado. Una regla general es que el n&amp;uacute;mero de elementos cero, que se puede calcular con &lt;code&gt;(coef_ == 0).sum()&lt;/code&gt; , debe ser superior al 50% para que esto proporcione beneficios significativos.</target>
        </trans-unit>
        <trans-unit id="e62cf2ed735d43186d3b55660d3dd2856258814f" translate="yes" xml:space="preserve">
          <source>For normalized mutual information and adjusted mutual information, the normalizing value is typically some &lt;em&gt;generalized&lt;/em&gt; mean of the entropies of each clustering. Various generalized means exist, and no firm rules exist for preferring one over the others. The decision is largely a field-by-field basis; for instance, in community detection, the arithmetic mean is most common. Each normalizing method provides &amp;ldquo;qualitatively similar behaviours&amp;rdquo; [YAT2016]. In our implementation, this is controlled by the &lt;code&gt;average_method&lt;/code&gt; parameter.</source>
          <target state="translated">Para la informaci&amp;oacute;n mutua normalizada y la informaci&amp;oacute;n mutua ajustada, el valor de normalizaci&amp;oacute;n suele ser una media &lt;em&gt;generalizada&lt;/em&gt; de las entrop&amp;iacute;as de cada agrupaci&amp;oacute;n. Existen varios medios generalizados y no existen reglas firmes para preferir uno sobre los otros. La decisi&amp;oacute;n se toma en gran medida campo por campo; por ejemplo, en la detecci&amp;oacute;n de comunidades, la media aritm&amp;eacute;tica es la m&amp;aacute;s com&amp;uacute;n. Cada m&amp;eacute;todo de normalizaci&amp;oacute;n proporciona &quot;comportamientos cualitativamente similares&quot; [YAT2016]. En nuestra implementaci&amp;oacute;n, esto est&amp;aacute; controlado por el par&amp;aacute;metro &lt;code&gt;average_method&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5573de0c3d8eae2871980794db1007675aa56eed" translate="yes" xml:space="preserve">
          <source>For now, we will consider the estimator as a black box:</source>
          <target state="translated">Por ahora,consideraremos el estimador como una caja negra:</target>
        </trans-unit>
        <trans-unit id="a7f8c21b68cc173c251c1992bff906fb9b13f276" translate="yes" xml:space="preserve">
          <source>For parameter estimation, the posterior distribution is:</source>
          <target state="translated">Para la estimación de los parámetros,la distribución posterior es:</target>
        </trans-unit>
        <trans-unit id="acaedbca04fb48c0d8436452cabe74f03629d275" translate="yes" xml:space="preserve">
          <source>For regression the default learning rate schedule is inverse scaling (&lt;code&gt;learning_rate='invscaling'&lt;/code&gt;), given by</source>
          <target state="translated">Para la regresi&amp;oacute;n, el programa de tasa de aprendizaje predeterminado es la escala inversa ( &lt;code&gt;learning_rate='invscaling'&lt;/code&gt; ), dada por</target>
        </trans-unit>
        <trans-unit id="17d6bf85a6ee02e9c1e3f5f799f4a791f96ca437" translate="yes" xml:space="preserve">
          <source>For regression with a squared loss and a l2 penalty, another variant of SGD with an averaging strategy is available with Stochastic Average Gradient (SAG) algorithm, available as a solver in &lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt;&lt;code&gt;Ridge&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Para la regresi&amp;oacute;n con una p&amp;eacute;rdida al cuadrado y una penalizaci&amp;oacute;n de 12, est&amp;aacute; disponible otra variante de SGD con una estrategia de promediado con el algoritmo de gradiente medio estoc&amp;aacute;stico (SAG), disponible como solucionador en &lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt; &lt;code&gt;Ridge&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="82e8631b28597b123d5803439222a08ee2e59047" translate="yes" xml:space="preserve">
          <source>For regression, &lt;a href=&quot;generated/sklearn.ensemble.adaboostregressor#sklearn.ensemble.AdaBoostRegressor&quot;&gt;&lt;code&gt;AdaBoostRegressor&lt;/code&gt;&lt;/a&gt; implements AdaBoost.R2 &lt;a href=&quot;#d1997&quot; id=&quot;id12&quot;&gt;[D1997]&lt;/a&gt;.</source>
          <target state="translated">Para la regresi&amp;oacute;n, &lt;a href=&quot;generated/sklearn.ensemble.adaboostregressor#sklearn.ensemble.AdaBoostRegressor&quot;&gt; &lt;code&gt;AdaBoostRegressor&lt;/code&gt; &lt;/a&gt; implementa AdaBoost.R2 &lt;a href=&quot;#d1997&quot; id=&quot;id12&quot;&gt;[D1997]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="faab950ebeb88e87f11e22c6efcd943439e07aea" translate="yes" xml:space="preserve">
          <source>For regression, MLP uses the Square Error loss function; written as,</source>
          <target state="translated">Para la regresión,el MLP utiliza la función de pérdida del error cuadrado;escrito como,</target>
        </trans-unit>
        <trans-unit id="a8c842b7da02e24dac30b073413aa7112e52aecd" translate="yes" xml:space="preserve">
          <source>For regression: &lt;a href=&quot;generated/sklearn.feature_selection.f_regression#sklearn.feature_selection.f_regression&quot;&gt;&lt;code&gt;f_regression&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_regression#sklearn.feature_selection.mutual_info_regression&quot;&gt;&lt;code&gt;mutual_info_regression&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">Para la regresi&amp;oacute;n: &lt;a href=&quot;generated/sklearn.feature_selection.f_regression#sklearn.feature_selection.f_regression&quot;&gt; &lt;code&gt;f_regression&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_regression#sklearn.feature_selection.mutual_info_regression&quot;&gt; &lt;code&gt;mutual_info_regression&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e8aa16ccbf6b94ae32b7c5b78e608f800f0eb6cd" translate="yes" xml:space="preserve">
          <source>For scikit-learn versions 0.14.1 and prior, return_as=np.ndarray was handled by returning a dense np.matrix instance. Going forward, np.ndarray returns an np.ndarray, as expected.</source>
          <target state="translated">Para las versiones 0.14.1 y anteriores de scikit-learn,return_as=np.ndarray se manejaba devolviendo una instancia densa de np.matrix.Siguiendo adelante,np.ndarray devuelve un np.ndarray,como se esperaba.</target>
        </trans-unit>
        <trans-unit id="2410f1ccaa1a03065aaeec2b709967381feb9cea" translate="yes" xml:space="preserve">
          <source>For simple transformations, instead of a Transformer object, a pair of functions can be passed, defining the transformation and its inverse mapping:</source>
          <target state="translated">Para transformaciones simples,en lugar de un objeto Transformador,se puede pasar un par de funciones que definen la transformación y su mapeo inverso:</target>
        </trans-unit>
        <trans-unit id="2f72f7e3c1f68f97fc714ad1c06f3f5738fb15a6" translate="yes" xml:space="preserve">
          <source>For simplicity the equation above is written for a single training example. The gradient with respect to the weights is formed of two terms corresponding to the ones above. They are usually known as the positive gradient and the negative gradient, because of their respective signs. In this implementation, the gradients are estimated over mini-batches of samples.</source>
          <target state="translated">Para simplificar,la ecuación anterior está escrita para un solo ejemplo de entrenamiento.El gradiente con respecto a los pesos está formado por dos términos correspondientes a los anteriores.Normalmente se conocen como el gradiente positivo y el gradiente negativo,debido a sus respectivos signos.En esta aplicación,los gradientes se estiman sobre mini lotes de muestras.</target>
        </trans-unit>
        <trans-unit id="27c46746207f2a31ae25da1632ef3ccf3ef87e4d" translate="yes" xml:space="preserve">
          <source>For single metric evaluation, where the scoring parameter is a string, callable or None, the keys will be - &lt;code&gt;['test_score', 'fit_time', 'score_time']&lt;/code&gt;</source>
          <target state="translated">Para la evaluaci&amp;oacute;n de m&amp;eacute;trica &amp;uacute;nica, donde el par&amp;aacute;metro de puntuaci&amp;oacute;n es una cadena, invocable o None, las claves ser&amp;aacute;n: &lt;code&gt;['test_score', 'fit_time', 'score_time']&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="a0a8bb77034843b440cd9ae1f7c55bd3aa47ece1" translate="yes" xml:space="preserve">
          <source>For small data sets (\(N\) less than 30 or so), \(\log(N)\) is comparable to \(N\), and brute force algorithms can be more efficient than a tree-based approach. Both &lt;a href=&quot;generated/sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt;&lt;code&gt;KDTree&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; address this through providing a &lt;em&gt;leaf size&lt;/em&gt; parameter: this controls the number of samples at which a query switches to brute-force. This allows both algorithms to approach the efficiency of a brute-force computation for small \(N\).</source>
          <target state="translated">Para conjuntos de datos peque&amp;ntilde;os (\ (N \) menos de 30 aproximadamente), \ (\ log (N) \) es comparable a \ (N \), y los algoritmos de fuerza bruta pueden ser m&amp;aacute;s eficientes que un enfoque basado en &amp;aacute;rboles. Tanto &lt;a href=&quot;generated/sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt; &lt;code&gt;KDTree&lt;/code&gt; &lt;/a&gt; como &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; &lt;/a&gt; abordan esto proporcionando un par&amp;aacute;metro de &lt;em&gt;tama&amp;ntilde;o de hoja&lt;/em&gt; : esto controla el n&amp;uacute;mero de muestras en las que una consulta cambia a fuerza bruta. Esto permite que ambos algoritmos se acerquen a la eficiencia de un c&amp;aacute;lculo de fuerza bruta para \ (N \) peque&amp;ntilde;o.</target>
        </trans-unit>
        <trans-unit id="4638d963661692a289a12b8cac2d92a9d2c758fa" translate="yes" xml:space="preserve">
          <source>For small datasets, &amp;lsquo;liblinear&amp;rsquo; is a good choice, whereas &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;saga&amp;rsquo; are faster for large ones.</source>
          <target state="translated">Para conjuntos de datos peque&amp;ntilde;os, 'liblinear' es una buena opci&amp;oacute;n, mientras que 'sag' y 'saga' son m&amp;aacute;s r&amp;aacute;pidos para los grandes.</target>
        </trans-unit>
        <trans-unit id="dffce5e2239efe7c22f00e78e9cfce148c8ba698" translate="yes" xml:space="preserve">
          <source>For some applications the amount of examples, features (or both) and/or the speed at which they need to be processed are challenging for traditional approaches. In these cases scikit-learn has a number of options you can consider to make your system scale.</source>
          <target state="translated">En algunas aplicaciones,la cantidad de ejemplos,características (o ambas)y/o la velocidad a la que deben procesarse son un reto para los enfoques tradicionales.En estos casos,scikit-learn tiene una serie de opciones que puede considerar para hacer que su sistema escale.</target>
        </trans-unit>
        <trans-unit id="d0fa030cdd6e029de147eaddac9b22a69b1ced78" translate="yes" xml:space="preserve">
          <source>For some applications the performance (mainly latency and throughput at prediction time) of estimators is crucial. It may also be of interest to consider the training throughput but this is often less important in a production setup (where it often takes place offline).</source>
          <target state="translated">Para algunas aplicaciones,el rendimiento (principalmente la latencia y el rendimiento en el tiempo de predicción)de los estimadores es crucial.También puede ser interesante considerar el rendimiento de la capacitación,pero a menudo es menos importante en una instalación de producción (donde a menudo tiene lugar fuera de línea).</target>
        </trans-unit>
        <trans-unit id="7400fa7073eb75f62370e5aadbb0f2aef8d5fc81" translate="yes" xml:space="preserve">
          <source>For some datasets, a pre-defined split of the data into training- and validation fold or into several cross-validation folds already exists. Using &lt;a href=&quot;generated/sklearn.model_selection.predefinedsplit#sklearn.model_selection.PredefinedSplit&quot;&gt;&lt;code&gt;PredefinedSplit&lt;/code&gt;&lt;/a&gt; it is possible to use these folds e.g. when searching for hyperparameters.</source>
          <target state="translated">Para algunos conjuntos de datos, ya existe una divisi&amp;oacute;n predefinida de los datos en pliegues de capacitaci&amp;oacute;n y validaci&amp;oacute;n o en varios pliegues de validaci&amp;oacute;n cruzada. Con &lt;a href=&quot;generated/sklearn.model_selection.predefinedsplit#sklearn.model_selection.PredefinedSplit&quot;&gt; &lt;code&gt;PredefinedSplit&lt;/code&gt; &lt;/a&gt; es posible utilizar estos pliegues, por ejemplo, al buscar hiperpar&amp;aacute;metros.</target>
        </trans-unit>
        <trans-unit id="c50bf24a893de08f1d0809fe397202f1a031fb85" translate="yes" xml:space="preserve">
          <source>For some miscellaneous data such as images, videos, and audio, you may wish to refer to:</source>
          <target state="translated">Para algunos datos misceláneos como imágenes,videos y audio,puede que desee consultar:</target>
        </trans-unit>
        <trans-unit id="303cfe0bd7811405e77868ed843c4904556ebde5" translate="yes" xml:space="preserve">
          <source>For sparse input the data is &lt;strong&gt;converted to the Compressed Sparse Rows representation&lt;/strong&gt; (see &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt;) before being fed to efficient Cython routines. To avoid unnecessary memory copies, it is recommended to choose the CSR representation upstream.</source>
          <target state="translated">Para una entrada dispersa, los datos se &lt;strong&gt;convierten a la representaci&amp;oacute;n de filas dispersas comprimidas&lt;/strong&gt; (consulte &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; ) antes de ser alimentados a rutinas Cython eficientes. Para evitar copias de memoria innecesarias, se recomienda elegir la representaci&amp;oacute;n CSR en sentido ascendente.</target>
        </trans-unit>
        <trans-unit id="44ae99861a7942ab4350b3f16d27ddb33207e51f" translate="yes" xml:space="preserve">
          <source>For sparse input the data is &lt;strong&gt;converted to the Compressed Sparse Rows representation&lt;/strong&gt; (see &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt;). To avoid unnecessary memory copies, it is recommended to choose the CSR representation upstream.</source>
          <target state="translated">Para una entrada dispersa, los datos se &lt;strong&gt;convierten a la representaci&amp;oacute;n de filas dispersas comprimidas&lt;/strong&gt; (consulte &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; ). Para evitar copias de memoria innecesarias, se recomienda elegir la representaci&amp;oacute;n CSR en sentido ascendente.</target>
        </trans-unit>
        <trans-unit id="a6ddfb481ebd700db5464677bebe705030e704c9" translate="yes" xml:space="preserve">
          <source>For speed and space efficiency reasons &lt;code&gt;scikit-learn&lt;/code&gt; loads the target attribute as an array of integers that corresponds to the index of the category name in the &lt;code&gt;target_names&lt;/code&gt; list. The category integer id of each sample is stored in the &lt;code&gt;target&lt;/code&gt; attribute:</source>
          <target state="translated">Por razones de velocidad y eficiencia de espacio, &lt;code&gt;scikit-learn&lt;/code&gt; carga el atributo de destino como una matriz de n&amp;uacute;meros enteros que corresponde al &amp;iacute;ndice del nombre de la categor&amp;iacute;a en la lista de &lt;code&gt;target_names&lt;/code&gt; . El ID de n&amp;uacute;mero entero de categor&amp;iacute;a de cada muestra se almacena en el atributo de &lt;code&gt;target&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="7ace947ef3298ab26b0edee5253deecf977a3b02" translate="yes" xml:space="preserve">
          <source>For speed, all real work is done at the C level in function copy_predict (libsvm_helper.c).</source>
          <target state="translated">Para la velocidad,todo el trabajo real se hace en el nivel C en la función copy_predict (libsvm_helper.c).</target>
        </trans-unit>
        <trans-unit id="1c3a0f29bcc1c543ffc020478b77d5b706223ce4" translate="yes" xml:space="preserve">
          <source>For splitting the data according to explicit domain-specific stratification of the dataset.</source>
          <target state="translated">Para dividir los datos según una estratificación explícita de dominio específico del conjunto de datos.</target>
        </trans-unit>
        <trans-unit id="0adf7a63adc917db1adffd6d4cf61e05de34a6e7" translate="yes" xml:space="preserve">
          <source>For splitting the data according to explicit, domain-specific stratification of the dataset.</source>
          <target state="translated">Para dividir los datos según una estratificación explícita y específica del dominio del conjunto de datos.</target>
        </trans-unit>
        <trans-unit id="ab4a742934d8510715858d09854f728742beaaec" translate="yes" xml:space="preserve">
          <source>For svd_solver == &amp;lsquo;arpack&amp;rsquo;, refer to &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt;.</source>
          <target state="translated">Para svd_solver == 'arpack', consulte &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="25caaa7ea914cf58c60f262a55964ee17d21e090" translate="yes" xml:space="preserve">
          <source>For svd_solver == &amp;lsquo;randomized&amp;rsquo;, see: &lt;code&gt;Halko, N., Martinsson, P. G., and Tropp, J. A. (2011). &amp;ldquo;Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions&amp;rdquo;. SIAM review, 53(2), 217-288.&lt;/code&gt; and also &lt;code&gt;Martinsson, P. G., Rokhlin, V., and Tygert, M. (2011). &amp;ldquo;A randomized algorithm for the decomposition of matrices&amp;rdquo;. Applied and Computational Harmonic Analysis, 30(1), 47-68.&lt;/code&gt;</source>
          <target state="translated">Para svd_solver == 'randomized', consulte: &lt;code&gt;Halko, N., Martinsson, P. G., and Tropp, J. A. (2011). &amp;ldquo;Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions&amp;rdquo;. SIAM review, 53(2), 217-288.&lt;/code&gt; y tambi&amp;eacute;n &lt;code&gt;Martinsson, P. G., Rokhlin, V., and Tygert, M. (2011). &amp;ldquo;A randomized algorithm for the decomposition of matrices&amp;rdquo;. Applied and Computational Harmonic Analysis, 30(1), 47-68.&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e7341be727234aad9fa4e331ba9d61b6fce122ff" translate="yes" xml:space="preserve">
          <source>For the &amp;lsquo;liblinear&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers set verbose to any positive number for verbosity.</source>
          <target state="translated">Para los solucionadores 'liblinear', 'sag' y 'lbfgs', establezca verbose en cualquier n&amp;uacute;mero positivo para verbosity.</target>
        </trans-unit>
        <trans-unit id="a081b6c50a07cf5457333031806f4c48e54ea42e" translate="yes" xml:space="preserve">
          <source>For the &lt;a href=&quot;classes#module-sklearn.svm&quot;&gt;&lt;code&gt;sklearn.svm&lt;/code&gt;&lt;/a&gt; family of algorithms with a non-linear kernel, the latency is tied to the number of support vectors (the fewer the faster). Latency and throughput should (asymptotically) grow linearly with the number of support vectors in a SVC or SVR model. The kernel will also influence the latency as it is used to compute the projection of the input vector once per support vector. In the following graph the &lt;code&gt;nu&lt;/code&gt; parameter of &lt;code&gt;sklearn.svm.classes.NuSVR&lt;/code&gt; was used to influence the number of support vectors.</source>
          <target state="translated">Para la familia de algoritmos &lt;a href=&quot;classes#module-sklearn.svm&quot;&gt; &lt;code&gt;sklearn.svm&lt;/code&gt; &lt;/a&gt; con un kernel no lineal, la latencia est&amp;aacute; ligada al n&amp;uacute;mero de vectores de soporte (cuantos menos, m&amp;aacute;s r&amp;aacute;pido). La latencia y el rendimiento deber&amp;iacute;an crecer (asint&amp;oacute;ticamente) linealmente con el n&amp;uacute;mero de vectores de soporte en un modelo SVC o SVR. El kernel tambi&amp;eacute;n influir&amp;aacute; en la latencia, ya que se utiliza para calcular la proyecci&amp;oacute;n del vector de entrada una vez por vector de soporte. En el siguiente gr&amp;aacute;fico, se us&amp;oacute; el par&amp;aacute;metro &lt;code&gt;nu&lt;/code&gt; de &lt;code&gt;sklearn.svm.classes.NuSVR&lt;/code&gt; para influir en el n&amp;uacute;mero de vectores de soporte.</target>
        </trans-unit>
        <trans-unit id="49dfac47eea992144c43ccc29f61713fabd0e5ae" translate="yes" xml:space="preserve">
          <source>For the &lt;code&gt;l2&lt;/code&gt; penalty case, the best result comes from the case where &lt;code&gt;C&lt;/code&gt; is not scaled.</source>
          <target state="translated">Para el caso de penalizaci&amp;oacute;n de &lt;code&gt;l2&lt;/code&gt; , el mejor resultado proviene del caso en el que &lt;code&gt;C&lt;/code&gt; no est&amp;aacute; escalado.</target>
        </trans-unit>
        <trans-unit id="d9f81a56586341e43516abb99b238b1b5d6587c8" translate="yes" xml:space="preserve">
          <source>For the grid of Cs values (that are set by default to be ten values in a logarithmic scale between 1e-4 and 1e4), the best hyperparameter is selected by the cross-validator StratifiedKFold, but it can be changed using the cv parameter. In the case of newton-cg and lbfgs solvers, we warm start along the path i.e guess the initial coefficients of the present fit to be the coefficients got after convergence in the previous fit, so it is supposed to be faster for high-dimensional dense data.</source>
          <target state="translated">Para la cuadrícula de valores de Cs (que por defecto se establecen en diez valores en una escala logarítmica entre 1e-4 y 1e4),el mejor hiperparámetro es seleccionado por el validador cruzado StratifiedKFold,pero puede ser cambiado usando el parámetro cv.En el caso de los solucionadores de newton-cg y lbfgs,hacemos un arranque en caliente a lo largo del camino,es decir,suponemos que los coeficientes iniciales del ajuste actual son los coeficientes obtenidos tras la convergencia en el ajuste anterior,por lo que se supone que es más rápido para los datos densos de alta dimensión.</target>
        </trans-unit>
        <trans-unit id="93f0b6841feed67e5fc00af0443562656921cce7" translate="yes" xml:space="preserve">
          <source>For the liblinear and lbfgs solvers set verbose to any positive number for verbosity.</source>
          <target state="translated">Para los solucionadores liblineares y lbfgs pongan verboso a cualquier número positivo para la verbosidad.</target>
        </trans-unit>
        <trans-unit id="4c4a7d0fb25ecd0231acfef000eb4ebb4024b077" translate="yes" xml:space="preserve">
          <source>For the most common use cases, you can designate a scorer object with the &lt;code&gt;scoring&lt;/code&gt; parameter; the table below shows all possible values. All scorer objects follow the convention that &lt;strong&gt;higher return values are better than lower return values&lt;/strong&gt;. Thus metrics which measure the distance between the model and the data, like &lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt;&lt;code&gt;metrics.mean_squared_error&lt;/code&gt;&lt;/a&gt;, are available as neg_mean_squared_error which return the negated value of the metric.</source>
          <target state="translated">Para los casos de uso m&amp;aacute;s comunes, puede designar un objeto de &lt;code&gt;scoring&lt;/code&gt; con el par&amp;aacute;metro de puntuaci&amp;oacute;n ; la siguiente tabla muestra todos los valores posibles. Todos los objetos de puntuaci&amp;oacute;n siguen la convenci&amp;oacute;n de que &lt;strong&gt;los valores de retorno m&amp;aacute;s altos son mejores que los valores de retorno m&amp;aacute;s bajos&lt;/strong&gt; . Por lo tanto, las m&amp;eacute;tricas que miden la distancia entre el modelo y los datos, como &lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt; &lt;code&gt;metrics.mean_squared_error&lt;/code&gt; &lt;/a&gt; , est&amp;aacute;n disponibles como neg_mean_squared_error que devuelven el valor negado de la m&amp;eacute;trica.</target>
        </trans-unit>
        <trans-unit id="5c5d7d9872e083b1cf44dccc9ef51ebf6d1fc473" translate="yes" xml:space="preserve">
          <source>For the rationale behind the names &lt;code&gt;coef_&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt;, i.e. naive Bayes as a linear classifier, see J. Rennie et al. (2003), Tackling the poor assumptions of naive Bayes text classifiers, ICML.</source>
          <target state="translated">Para conocer el fundamento de los nombres &lt;code&gt;coef_&lt;/code&gt; e &lt;code&gt;intercept_&lt;/code&gt; , es decir, Bayes ingenuo como clasificador lineal, v&amp;eacute;ase J. Rennie et al. (2003), Abordando las malas suposiciones de los clasificadores de texto ingenuos de Bayes, ICML.</target>
        </trans-unit>
        <trans-unit id="08233f540a36ed45603c5cb01e2e4f593cd79c27" translate="yes" xml:space="preserve">
          <source>For the simple task of finding the nearest neighbors between two sets of data, the unsupervised algorithms within &lt;a href=&quot;classes#module-sklearn.neighbors&quot;&gt;&lt;code&gt;sklearn.neighbors&lt;/code&gt;&lt;/a&gt; can be used:</source>
          <target state="translated">Para la simple tarea de encontrar los vecinos m&amp;aacute;s cercanos entre dos conjuntos de datos, se pueden usar los algoritmos no supervisados ​​dentro de &lt;a href=&quot;classes#module-sklearn.neighbors&quot;&gt; &lt;code&gt;sklearn.neighbors&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="daed0c58d42835f25cc91f4ef37c8c2918d442fd" translate="yes" xml:space="preserve">
          <source>For this data, we might want to encode the &lt;code&gt;'city'&lt;/code&gt; column as a categorical variable, but apply a &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;feature_extraction.text.CountVectorizer&lt;/code&gt;&lt;/a&gt; to the &lt;code&gt;'title'&lt;/code&gt; column. As we might use multiple feature extraction methods on the same column, we give each transformer a unique name, say &lt;code&gt;'city_category'&lt;/code&gt; and &lt;code&gt;'title_bow'&lt;/code&gt;. By default, the remaining rating columns are ignored (&lt;code&gt;remainder='drop'&lt;/code&gt;):</source>
          <target state="translated">Para estos datos, es posible que queramos codificar la columna &lt;code&gt;'city'&lt;/code&gt; como una variable categ&amp;oacute;rica, pero aplicar &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;feature_extraction.text.CountVectorizer&lt;/code&gt; &lt;/a&gt; a la columna &lt;code&gt;'title'&lt;/code&gt; . Como podr&amp;iacute;amos usar varios m&amp;eacute;todos de extracci&amp;oacute;n de caracter&amp;iacute;sticas en la misma columna, le damos a cada transformador un nombre &amp;uacute;nico, digamos &lt;code&gt;'city_category'&lt;/code&gt; y &lt;code&gt;'title_bow'&lt;/code&gt; . De forma predeterminada, las columnas de calificaci&amp;oacute;n restantes se ignoran ( &lt;code&gt;remainder='drop'&lt;/code&gt; ):</target>
        </trans-unit>
        <trans-unit id="2e47bbc09921a29cf4a007e2d92242f5a8a9f3d8" translate="yes" xml:space="preserve">
          <source>For this example we will use the &lt;a href=&quot;http://mldata.org/repository/data/viewslug/yeast&quot;&gt;yeast&lt;/a&gt; dataset which contains 2417 datapoints each with 103 features and 14 possible labels. Each data point has at least one label. As a baseline we first train a logistic regression classifier for each of the 14 labels. To evaluate the performance of these classifiers we predict on a held-out test set and calculate the &lt;a href=&quot;../../modules/model_evaluation#jaccard-similarity-score&quot;&gt;jaccard similarity score&lt;/a&gt;.</source>
          <target state="translated">Para este ejemplo, utilizaremos el conjunto de datos de &lt;a href=&quot;http://mldata.org/repository/data/viewslug/yeast&quot;&gt;levadura&lt;/a&gt; que contiene 2417 puntos de datos, cada uno con 103 caracter&amp;iacute;sticas y 14 etiquetas posibles. Cada punto de datos tiene al menos una etiqueta. Como l&amp;iacute;nea de base, primero entrenamos un clasificador de regresi&amp;oacute;n log&amp;iacute;stica para cada una de las 14 etiquetas. Para evaluar el rendimiento de estos clasificadores, predecimos en un conjunto de pruebas retenido y calculamos la &lt;a href=&quot;../../modules/model_evaluation#jaccard-similarity-score&quot;&gt;puntuaci&amp;oacute;n de similitud de jaccard&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="6ab77ac3ad8536d0d4bc113a409f055607cd6e01" translate="yes" xml:space="preserve">
          <source>For this method, M may be a dense matrix, sparse matrix, or general linear operator. Warning: ARPACK can be unstable for some problems. It is best to try several random seeds in order to check results.</source>
          <target state="translated">Para este método,M puede ser una matriz densa,una matriz escasa o un operador lineal general.Advertencia:ARPACK puede ser inestable para algunos problemas.Es mejor probar varias semillas al azar para comprobar los resultados.</target>
        </trans-unit>
        <trans-unit id="201d282b655d8d026b78eb9f9255553e50678277" translate="yes" xml:space="preserve">
          <source>For this purpose, the estimators use a &amp;lsquo;connectivity&amp;rsquo; matrix, giving which samples are connected.</source>
          <target state="translated">Para este prop&amp;oacute;sito, los estimadores utilizan una matriz de 'conectividad', dando qu&amp;eacute; muestras est&amp;aacute;n conectadas.</target>
        </trans-unit>
        <trans-unit id="764ea2ccb7951b3db73f825ee916559c0e4bce1d" translate="yes" xml:space="preserve">
          <source>For this reason, the functions that load 20 Newsgroups data provide a parameter called &lt;strong&gt;remove&lt;/strong&gt;, telling it what kinds of information to strip out of each file. &lt;strong&gt;remove&lt;/strong&gt; should be a tuple containing any subset of &lt;code&gt;('headers', 'footers', 'quotes')&lt;/code&gt;, telling it to remove headers, signature blocks, and quotation blocks respectively.</source>
          <target state="translated">Por esta raz&amp;oacute;n, las funciones que cargan datos de 20 grupos de noticias proporcionan un par&amp;aacute;metro llamado &lt;strong&gt;eliminar&lt;/strong&gt; , que le indica qu&amp;eacute; tipo de informaci&amp;oacute;n eliminar de cada archivo. &lt;strong&gt;remove&lt;/strong&gt; debe ser una tupla que contenga cualquier subconjunto de &lt;code&gt;('headers', 'footers', 'quotes')&lt;/code&gt; , indic&amp;aacute;ndole que elimine encabezados, bloques de firmas y bloques de citas respectivamente.</target>
        </trans-unit>
        <trans-unit id="f2d2e6058597b408c702846b2d537e901630ce3a" translate="yes" xml:space="preserve">
          <source>For two clusters, it solves a convex relaxation of the &lt;a href=&quot;http://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf&quot;&gt;normalised cuts&lt;/a&gt; problem on the similarity graph: cutting the graph in two so that the weight of the edges cut is small compared to the weights of the edges inside each cluster. This criteria is especially interesting when working on images: graph vertices are pixels, and edges of the similarity graph are a function of the gradient of the image.</source>
          <target state="translated">Para dos grupos, resuelve una relajaci&amp;oacute;n convexa del problema de &lt;a href=&quot;http://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf&quot;&gt;cortes normalizados&lt;/a&gt; en el gr&amp;aacute;fico de similitud: cortar el gr&amp;aacute;fico en dos para que el peso de los bordes cortados sea peque&amp;ntilde;o en comparaci&amp;oacute;n con los pesos de los bordes dentro de cada grupo. Este criterio es especialmente interesante cuando se trabaja con im&amp;aacute;genes: los v&amp;eacute;rtices del gr&amp;aacute;fico son p&amp;iacute;xeles y los bordes del gr&amp;aacute;fico de similitud son una funci&amp;oacute;n del gradiente de la imagen.</target>
        </trans-unit>
        <trans-unit id="4092abbbb6ead577ab2b40e6704455f3cb4d3df5" translate="yes" xml:space="preserve">
          <source>For various reasons, many real world datasets contain missing values, often encoded as blanks, NaNs or other placeholders. Such datasets however are incompatible with scikit-learn estimators which assume that all values in an array are numerical, and that all have and hold meaning. A basic strategy to use incomplete datasets is to discard entire rows and/or columns containing missing values. However, this comes at the price of losing data which may be valuable (even though incomplete). A better strategy is to impute the missing values, i.e., to infer them from the known part of the data. See the &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#glossary&quot;&gt;Glossary of Common Terms and API Elements&lt;/a&gt; entry on imputation.</source>
          <target state="translated">Por diversas razones, muchos conjuntos de datos del mundo real contienen valores perdidos, a menudo codificados como espacios en blanco, NaN u otros marcadores de posici&amp;oacute;n. Sin embargo, estos conjuntos de datos son incompatibles con los estimadores de scikit-learn, que asumen que todos los valores de una matriz son num&amp;eacute;ricos y que todos tienen y tienen significado. Una estrategia b&amp;aacute;sica para utilizar conjuntos de datos incompletos es descartar filas y / o columnas completas que contienen valores faltantes. Sin embargo, esto tiene el precio de perder datos que pueden ser valiosos (aunque est&amp;eacute;n incompletos). Una mejor estrategia es imputar los valores perdidos, es decir, inferirlos de la parte conocida de los datos. Consulte la entrada &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#glossary&quot;&gt;Glosario de t&amp;eacute;rminos comunes y elementos de API&lt;/a&gt; sobre imputaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="7f12e7919ffa1c3009c9eefff46504b7c0642e13" translate="yes" xml:space="preserve">
          <source>For visualization purpose (which is the main use case of t-SNE), using the Barnes-Hut method is strongly recommended. The exact t-SNE method is useful for checking the theoretically properties of the embedding possibly in higher dimensional space but limit to small datasets due to computational constraints.</source>
          <target state="translated">Para la visualización (que es el principal caso de uso del t-SNE),se recomienda encarecidamente utilizar el método Barnes-Hut.El método exacto de t-SNE es útil para comprobar las propiedades teóricas de la incrustación posiblemente en un espacio dimensional más alto,pero limitado a pequeños conjuntos de datos debido a las limitaciones de los cálculos.</target>
        </trans-unit>
        <trans-unit id="e7a5b4b1244321faa67509dff73df9a23d7da1b3" translate="yes" xml:space="preserve">
          <source>For visualization purposes, given a bicluster, the rows and columns of the data matrix may be rearranged to make the bicluster contiguous.</source>
          <target state="translated">A efectos de visualización,dado un bicluster,las filas y columnas de la matriz de datos pueden reordenarse para que el bicluster sea contiguo.</target>
        </trans-unit>
        <trans-unit id="d62d3122e2e4eef979e7c46fd629936aec0233be" translate="yes" xml:space="preserve">
          <source>For visualization purposes, we need to lay out the different symbols on a 2D canvas. For this we use &lt;a href=&quot;../../modules/manifold#manifold&quot;&gt;Manifold learning&lt;/a&gt; techniques to retrieve 2D embedding.</source>
          <target state="translated">Para fines de visualizaci&amp;oacute;n, necesitamos dise&amp;ntilde;ar los diferentes s&amp;iacute;mbolos en un lienzo 2D. Para ello, utilizamos t&amp;eacute;cnicas de &lt;a href=&quot;../../modules/manifold#manifold&quot;&gt;aprendizaje m&amp;uacute;ltiples&lt;/a&gt; para recuperar la incrustaci&amp;oacute;n 2D.</target>
        </trans-unit>
        <trans-unit id="c502fd7960fae5affa9295a7a329adeddad6ab37" translate="yes" xml:space="preserve">
          <source>Force row-by-row generation by reducing &lt;code&gt;working_memory&lt;/code&gt;:</source>
          <target state="translated">Forzar la generaci&amp;oacute;n fila por fila reduciendo &lt;code&gt;working_memory&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="4bb98e5d778957b0dd66fa6aed87be22d170768c" translate="yes" xml:space="preserve">
          <source>Forina, M. et al, PARVUS - An Extendible Package for Data Exploration, Classification and Correlation. Institute of Pharmaceutical and Food Analysis and Technologies, Via Brigata Salerno, 16147 Genoa, Italy.</source>
          <target state="translated">Forina,M.et al,PARVUS-Un paquete extensible para la exploración,clasificación y correlación de datos.Instituto de Análisis y Tecnologías Farmacéuticas y Alimenticias,Via Brigata Salerno,16147 Génova,Italia.</target>
        </trans-unit>
        <trans-unit id="35705e005c1f18ed14dab92df9e1435742858283" translate="yes" xml:space="preserve">
          <source>Formally, given a binary indicator matrix of the ground truth labels \(y \in \left\{0, 1\right\}^{n_\text{samples} \times n_\text{labels}}\) and the score associated with each label \(\hat{f} \in \mathbb{R}^{n_\text{samples} \times n_\text{labels}}\), the average precision is defined as</source>
          <target state="translated">Formalmente,dada una matriz indicadora binaria de las etiquetas de la verdad del suelo (y en la izquierda,1 derecha,1 derecha)y la puntuación asociada a cada etiqueta (en la derecha,1 derecha),la precisión media se define como</target>
        </trans-unit>
        <trans-unit id="4f395914b8fb9e643646835cc07cbc38c9742edc" translate="yes" xml:space="preserve">
          <source>Formally, given a binary indicator matrix of the ground truth labels \(y \in \left\{0, 1\right\}^{n_\text{samples} \times n_\text{labels}}\) and the score associated with each label \(\hat{f} \in \mathbb{R}^{n_\text{samples} \times n_\text{labels}}\), the coverage is defined as</source>
          <target state="translated">Formalmente,dada una matriz indicadora binaria de las etiquetas de la verdad del suelo (y en la izquierda,1 derecha,1 derecha)y la puntuación asociada a cada etiqueta (en la derecha,1 derecha,1 derecha),la cobertura se define como</target>
        </trans-unit>
        <trans-unit id="c175d46f254d733413b5b0ee831c9d600136a7b6" translate="yes" xml:space="preserve">
          <source>Formally, given a binary indicator matrix of the ground truth labels \(y \in \left\{0, 1\right\}^{n_\text{samples} \times n_\text{labels}}\) and the score associated with each label \(\hat{f} \in \mathbb{R}^{n_\text{samples} \times n_\text{labels}}\), the ranking loss is defined as</source>
          <target state="translated">Formalmente,dada una matriz indicadora binaria de las etiquetas de verdad del suelo (y en la izquierda,1 derecha,1 derecha)y la puntuación asociada a cada etiqueta (en la derecha,1 derecha),la pérdida de clasificación se define como</target>
        </trans-unit>
        <trans-unit id="47fb5045fef615598469a37da8a59110352753ff" translate="yes" xml:space="preserve">
          <source>Forms an affinity matrix given by the specified function and applies spectral decomposition to the corresponding graph laplacian. The resulting transformation is given by the value of the eigenvectors for each data point.</source>
          <target state="translated">Forma una matriz de afinidad dada por la función especificada y aplica la descomposición espectral al correspondiente gráfico laplaciano.La transformación resultante viene dada por el valor de los vectores propios de cada punto de datos.</target>
        </trans-unit>
        <trans-unit id="638babaaa209a18fe959f40f19725a01af068351" translate="yes" xml:space="preserve">
          <source>Fortunately, &lt;strong&gt;most values in X will be zeros&lt;/strong&gt; since for a given document less than a few thousand distinct words will be used. For this reason we say that bags of words are typically &lt;strong&gt;high-dimensional sparse datasets&lt;/strong&gt;. We can save a lot of memory by only storing the non-zero parts of the feature vectors in memory.</source>
          <target state="translated">Afortunadamente, la &lt;strong&gt;mayor&amp;iacute;a de los valores en X ser&amp;aacute;n ceros,&lt;/strong&gt; ya que para un documento dado se usar&amp;aacute;n menos de unos pocos miles de palabras distintas. Por esta raz&amp;oacute;n, decimos que las bolsas de palabras son t&amp;iacute;picamente &lt;strong&gt;conjuntos de datos dispersos de alta dimensi&amp;oacute;n&lt;/strong&gt; . Podemos ahorrar mucha memoria almacenando solo las partes distintas de cero de los vectores de caracter&amp;iacute;sticas en la memoria.</target>
        </trans-unit>
        <trans-unit id="659b18cdaec75234c8e955e09af5dc004ab6498a" translate="yes" xml:space="preserve">
          <source>Frequently asked questions about the project and contributing.</source>
          <target state="translated">Preguntas frecuentes sobre el proyecto y la contribución.</target>
        </trans-unit>
        <trans-unit id="c378e5372fbcc6968de3f23916b1cc385b9617be" translate="yes" xml:space="preserve">
          <source>Friedman et al, &lt;a href=&quot;http://biostatistics.oxfordjournals.org/content/9/3/432.short&quot;&gt;&amp;ldquo;Sparse inverse covariance estimation with the graphical lasso&amp;rdquo;&lt;/a&gt;, Biostatistics 9, pp 432, 2008</source>
          <target state="translated">Friedman et al, &lt;a href=&quot;http://biostatistics.oxfordjournals.org/content/9/3/432.short&quot;&gt;&amp;ldquo;Estimaci&amp;oacute;n de covarianza inversa dispersa con el lazo gr&amp;aacute;fico&amp;rdquo;&lt;/a&gt; , Bioestad&amp;iacute;stica 9, p&amp;aacute;gs. 432, 2008</target>
        </trans-unit>
        <trans-unit id="8438e27109208985a133518d65493568dedc6924" translate="yes" xml:space="preserve">
          <source>Friedman, &amp;ldquo;Stochastic Gradient Boosting&amp;rdquo;, 1999</source>
          <target state="translated">Friedman, &quot;Impulso de gradiente estoc&amp;aacute;stico&quot;, 1999</target>
        </trans-unit>
        <trans-unit id="9fcad16d5a3614a8ac9a3dd3615a46004936d92d" translate="yes" xml:space="preserve">
          <source>Friedman, Stochastic Gradient Boosting, 1999</source>
          <target state="translated">Friedman,Stochastic Gradient Boosting,1999</target>
        </trans-unit>
        <trans-unit id="d93c5ad51427861e9927c0f93ba75f21fa7b3769" translate="yes" xml:space="preserve">
          <source>Frobenius norm of the matrix difference, or beta-divergence, between the training data &lt;code&gt;X&lt;/code&gt; and the reconstructed data &lt;code&gt;WH&lt;/code&gt; from the fitted model.</source>
          <target state="translated">Norma de Frobenius de la diferencia de matriz, o divergencia beta, entre los datos de entrenamiento &lt;code&gt;X&lt;/code&gt; y los datos reconstruidos &lt;code&gt;WH&lt;/code&gt; del modelo ajustado.</target>
        </trans-unit>
        <trans-unit id="2a2bd03e6f160e636919837a5a755bde731a1eeb" translate="yes" xml:space="preserve">
          <source>From images</source>
          <target state="translated">De las imágenes</target>
        </trans-unit>
        <trans-unit id="5ff0ffd1e24dbd90ba4e307313dc3fed8b0cd6c4" translate="yes" xml:space="preserve">
          <source>From occurrences to frequencies</source>
          <target state="translated">De las ocurrencias a las frecuencias</target>
        </trans-unit>
        <trans-unit id="4a6ea847ae49dd26abc66504268644d690f3206b" translate="yes" xml:space="preserve">
          <source>From scikit-learn: [&amp;lsquo;cityblock&amp;rsquo;, &amp;lsquo;cosine&amp;rsquo;, &amp;lsquo;euclidean&amp;rsquo;, &amp;lsquo;l1&amp;rsquo;, &amp;lsquo;l2&amp;rsquo;, &amp;lsquo;manhattan&amp;rsquo;]. These metrics support sparse matrix inputs.</source>
          <target state="translated">De scikit-learn: ['cityblock', 'cosine', 'euclidean', 'l1', 'l2', 'manhattan']. Estas m&amp;eacute;tricas admiten entradas de matriz dispersas.</target>
        </trans-unit>
        <trans-unit id="6d8d962b98fbbe50de709ee2f1e71db53d579c2e" translate="yes" xml:space="preserve">
          <source>From scipy.spatial.distance: [&amp;lsquo;braycurtis&amp;rsquo;, &amp;lsquo;canberra&amp;rsquo;, &amp;lsquo;chebyshev&amp;rsquo;, &amp;lsquo;correlation&amp;rsquo;, &amp;lsquo;dice&amp;rsquo;, &amp;lsquo;hamming&amp;rsquo;, &amp;lsquo;jaccard&amp;rsquo;, &amp;lsquo;kulsinski&amp;rsquo;, &amp;lsquo;mahalanobis&amp;rsquo;, &amp;lsquo;minkowski&amp;rsquo;, &amp;lsquo;rogerstanimoto&amp;rsquo;, &amp;lsquo;russellrao&amp;rsquo;, &amp;lsquo;seuclidean&amp;rsquo;, &amp;lsquo;sokalmichener&amp;rsquo;, &amp;lsquo;sokalsneath&amp;rsquo;, &amp;lsquo;sqeuclidean&amp;rsquo;, &amp;lsquo;yule&amp;rsquo;] See the documentation for scipy.spatial.distance for details on these metrics. These metrics do not support sparse matrix inputs.</source>
          <target state="translated">De scipy.spatial.distance: ['braycurtis', 'canberra', 'chebyshev', 'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'minkowski', 'rogerstanimoto ',' russellrao ',' seuclidean ',' sokalmichener ',' sokalsneath ',' sqeuclidean ',' yule '] Consulte la documentaci&amp;oacute;n de scipy.spatial.distance para obtener detalles sobre estas m&amp;eacute;tricas. Estas m&amp;eacute;tricas no admiten entradas matriciales dispersas.</target>
        </trans-unit>
        <trans-unit id="d3990f36d057d6745fedc272447b2563e02193f7" translate="yes" xml:space="preserve">
          <source>From text</source>
          <target state="translated">Del texto</target>
        </trans-unit>
        <trans-unit id="13bce2493b501286a428cebcb4e0bc57e6083c63" translate="yes" xml:space="preserve">
          <source>From the implementation point of view, this is just plain Ordinary Least Squares (scipy.linalg.lstsq) wrapped as a predictor object.</source>
          <target state="translated">Desde el punto de vista de la implementación,esto es simplemente cuadrados mínimos ordinarios (scipy.linalg.lstsq)envueltos como un objeto predictor.</target>
        </trans-unit>
        <trans-unit id="ae8e3bdf9c1967ed71af43f356a6c2d5d1712708" translate="yes" xml:space="preserve">
          <source>From the programming standpoint, it is interesting because it shows how to use the online API of the scikit-learn to process a very large dataset by chunks. The way we proceed is that we load an image at a time and extract randomly 50 patches from this image. Once we have accumulated 500 of these patches (using 10 images), we run the &lt;code&gt;partial_fit&lt;/code&gt; method of the online KMeans object, MiniBatchKMeans.</source>
          <target state="translated">Desde el punto de vista de la programaci&amp;oacute;n, es interesante porque muestra c&amp;oacute;mo utilizar la API en l&amp;iacute;nea de scikit-learn para procesar un conjunto de datos muy grande por fragmentos. La forma en que procedemos es que cargamos una imagen a la vez y extraemos al azar 50 parches de esta imagen. Una vez que hemos acumulado 500 de estos parches (usando 10 im&amp;aacute;genes), se corre el &lt;code&gt;partial_fit&lt;/code&gt; m&amp;eacute;todo del objeto KMeans en l&amp;iacute;nea, MiniBatchKMeans.</target>
        </trans-unit>
        <trans-unit id="f1e410ad1472b42cb42cc98962428637290b6706" translate="yes" xml:space="preserve">
          <source>Function</source>
          <target state="translated">Function</target>
        </trans-unit>
        <trans-unit id="9f410a9e5384dfe1720c4cd228fe7bb63965656b" translate="yes" xml:space="preserve">
          <source>Function taking two arrays X and y, and returning a pair of arrays (scores, pvalues) or a single array with scores. Default is f_classif (see below &amp;ldquo;See also&amp;rdquo;). The default function only works with classification tasks.</source>
          <target state="translated">Funci&amp;oacute;n que toma dos matrices X e y, y devuelve un par de matrices (puntuaciones, valores p) o una &amp;uacute;nica matriz con puntuaciones. El valor predeterminado es f_classif (ver m&amp;aacute;s abajo &quot;Ver tambi&amp;eacute;n&quot;). La funci&amp;oacute;n predeterminada solo funciona con tareas de clasificaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="a8696032e0adf35ffec7c9da28cd036adeb91c99" translate="yes" xml:space="preserve">
          <source>Function taking two arrays X and y, and returning a pair of arrays (scores, pvalues). Default is f_classif (see below &amp;ldquo;See also&amp;rdquo;). The default function only works with classification tasks.</source>
          <target state="translated">Funci&amp;oacute;n que toma dos matrices X e y, y devuelve un par de matrices (puntuaciones, pvalores). El valor predeterminado es f_classif (ver m&amp;aacute;s abajo &quot;Ver tambi&amp;eacute;n&quot;). La funci&amp;oacute;n predeterminada solo funciona con tareas de clasificaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="acf1f055cd0885a9fc7d245efda7d1c727fca691" translate="yes" xml:space="preserve">
          <source>Function taking two arrays X and y, and returning a pair of arrays (scores, pvalues). For modes &amp;lsquo;percentile&amp;rsquo; or &amp;lsquo;kbest&amp;rsquo; it can return a single array scores.</source>
          <target state="translated">Funci&amp;oacute;n que toma dos matrices X e y, y devuelve un par de matrices (puntuaciones, pvalores). Para los modos 'percentil' o 'kbest', puede devolver una &amp;uacute;nica puntuaci&amp;oacute;n de matriz.</target>
        </trans-unit>
        <trans-unit id="0c64f21c81859fb42c302c0d2cd301e40332c2c7" translate="yes" xml:space="preserve">
          <source>Function to apply to &lt;code&gt;y&lt;/code&gt; before passing to &lt;code&gt;fit&lt;/code&gt;. Cannot be set at the same time as &lt;code&gt;transformer&lt;/code&gt;. The function needs to return a 2-dimensional array. If &lt;code&gt;func&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt;, the function used will be the identity function.</source>
          <target state="translated">Funci&amp;oacute;n para aplicar &lt;code&gt;y&lt;/code&gt; antes de pasar a &lt;code&gt;fit&lt;/code&gt; . No se puede configurar al mismo tiempo que el &lt;code&gt;transformer&lt;/code&gt; . La funci&amp;oacute;n debe devolver una matriz bidimensional. Si &lt;code&gt;func&lt;/code&gt; es &lt;code&gt;None&lt;/code&gt; , la funci&amp;oacute;n utilizada ser&amp;aacute; la funci&amp;oacute;n de identidad.</target>
        </trans-unit>
        <trans-unit id="f712e33ad68950dd5132b77ad3129994bf2cbbce" translate="yes" xml:space="preserve">
          <source>Function to apply to the prediction of the regressor. Cannot be set at the same time as &lt;code&gt;transformer&lt;/code&gt; as well. The function needs to return a 2-dimensional array. The inverse function is used to return predictions to the same space of the original training labels.</source>
          <target state="translated">Funci&amp;oacute;n a aplicar a la predicci&amp;oacute;n del regresor. No se puede configurar al mismo tiempo que el &lt;code&gt;transformer&lt;/code&gt; . La funci&amp;oacute;n debe devolver una matriz bidimensional. La funci&amp;oacute;n inversa se usa para devolver predicciones al mismo espacio de las etiquetas de entrenamiento originales.</target>
        </trans-unit>
        <trans-unit id="2b961dea1dc0c60ddf9a2c8e9d090f6f7d082483" translate="yes" xml:space="preserve">
          <source>Functions</source>
          <target state="translated">Functions</target>
        </trans-unit>
        <trans-unit id="c216053588b385d3de175b467017426b8b421912" translate="yes" xml:space="preserve">
          <source>Further discussion on the importance of centering and scaling data is available on this FAQ: &lt;a href=&quot;http://www.faqs.org/faqs/ai-faq/neural-nets/part2/section-16.html&quot;&gt;Should I normalize/standardize/rescale the data?&lt;/a&gt;</source>
          <target state="translated">M&amp;aacute;s informaci&amp;oacute;n sobre la importancia de centrar y escalar los datos est&amp;aacute; disponible en esta pregunta frecuente: &lt;a href=&quot;http://www.faqs.org/faqs/ai-faq/neural-nets/part2/section-16.html&quot;&gt;&amp;iquest;Deber&amp;iacute;a normalizar / estandarizar / cambiar la escala de los datos?&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="606b0f774f1d5e4151969dbb768df62ebca8a20e" translate="yes" xml:space="preserve">
          <source>Further removes the linear correlation across features with &amp;lsquo;whiten=True&amp;rsquo;.</source>
          <target state="translated">Elimina a&amp;uacute;n m&amp;aacute;s la correlaci&amp;oacute;n lineal entre caracter&amp;iacute;sticas con 'blanquear = Verdadero'.</target>
        </trans-unit>
        <trans-unit id="ec9ba56eabfa3f70786eb84612f0623df80dfc4d" translate="yes" xml:space="preserve">
          <source>Further, the model supports &lt;a href=&quot;multiclass#multiclass&quot;&gt;multi-label classification&lt;/a&gt; in which a sample can belong to more than one class. For each class, the raw output passes through the logistic function. Values larger or equal to &lt;code&gt;0.5&lt;/code&gt; are rounded to &lt;code&gt;1&lt;/code&gt;, otherwise to &lt;code&gt;0&lt;/code&gt;. For a predicted output of a sample, the indices where the value is &lt;code&gt;1&lt;/code&gt; represents the assigned classes of that sample:</source>
          <target state="translated">Adem&amp;aacute;s, el modelo admite la &lt;a href=&quot;multiclass#multiclass&quot;&gt;clasificaci&amp;oacute;n de m&amp;uacute;ltiples etiquetas&lt;/a&gt; en la que una muestra puede pertenecer a m&amp;aacute;s de una clase. Para cada clase, la salida sin procesar pasa por la funci&amp;oacute;n log&amp;iacute;stica. Los valores mayores o iguales a &lt;code&gt;0.5&lt;/code&gt; se redondean a &lt;code&gt;1&lt;/code&gt; , de lo contrario a &lt;code&gt;0&lt;/code&gt; . Para una salida prevista de una muestra, los &amp;iacute;ndices donde el valor es &lt;code&gt;1&lt;/code&gt; representan las clases asignadas de esa muestra:</target>
        </trans-unit>
        <trans-unit id="cc118108875cca01a2724ce6e20debf4e124a846" translate="yes" xml:space="preserve">
          <source>Furthermore, &lt;a href=&quot;generated/sklearn.metrics.adjusted_rand_score#sklearn.metrics.adjusted_rand_score&quot;&gt;&lt;code&gt;adjusted_rand_score&lt;/code&gt;&lt;/a&gt; is &lt;strong&gt;symmetric&lt;/strong&gt;: swapping the argument does not change the score. It can thus be used as a &lt;strong&gt;consensus measure&lt;/strong&gt;:</source>
          <target state="translated">Adem&amp;aacute;s, la puntuaci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.adjusted_rand_score#sklearn.metrics.adjusted_rand_score&quot;&gt; &lt;code&gt;adjusted_rand_score&lt;/code&gt; &lt;/a&gt; la puntuaci&amp;oacute;n es &lt;strong&gt;sim&amp;eacute;trica&lt;/strong&gt; : cambiar el argumento no cambia la puntuaci&amp;oacute;n. Por tanto, puede utilizarse como &lt;strong&gt;medida de consenso&lt;/strong&gt; :</target>
        </trans-unit>
        <trans-unit id="7218de362b7befd5a71b1a5a01365e3552aa1087" translate="yes" xml:space="preserve">
          <source>Furthermore, it also shows the evolution of the performance of different algorithms with the number of processed examples.</source>
          <target state="translated">Además,también muestra la evolución del rendimiento de los diferentes algoritmos con el número de ejemplos procesados.</target>
        </trans-unit>
        <trans-unit id="17753e7322d4f150d032ddf1f2dbdf4fe6d38592" translate="yes" xml:space="preserve">
          <source>Furthermore, the default parameter &lt;code&gt;smooth_idf=True&lt;/code&gt; adds &amp;ldquo;1&amp;rdquo; to the numerator and denominator as if an extra document was seen containing every term in the collection exactly once, which prevents zero divisions:</source>
          <target state="translated">Adem&amp;aacute;s, el par&amp;aacute;metro predeterminado &lt;code&gt;smooth_idf=True&lt;/code&gt; agrega &quot;1&quot; al numerador y al denominador como si se viera un documento adicional que contiene todos los t&amp;eacute;rminos de la colecci&amp;oacute;n exactamente una vez, lo que evita las divisiones cero:</target>
        </trans-unit>
        <trans-unit id="2e93583dd7fd8dcf1f0371a9818f0db1fd3c80a7" translate="yes" xml:space="preserve">
          <source>Furthermore, the formulas used to compute tf and idf depend on parameter settings that correspond to the SMART notation used in IR as follows:</source>
          <target state="translated">Además,las fórmulas utilizadas para calcular tf y idf dependen de los ajustes de los parámetros que corresponden a la notación SMART utilizada en el IR de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="2b6ca190d547b1e777d8fa3e93274ce6ad7c42b4" translate="yes" xml:space="preserve">
          <source>G. Brier, &lt;a href=&quot;ftp://ftp.library.noaa.gov/docs.lib/htdocs/rescue/mwr/078/mwr-078-01-0001.pdf&quot;&gt;Verification of forecasts expressed in terms of probability&lt;/a&gt;, Monthly weather review 78.1 (1950)</source>
          <target state="translated">G. Brier, &lt;a href=&quot;ftp://ftp.library.noaa.gov/docs.lib/htdocs/rescue/mwr/078/mwr-078-01-0001.pdf&quot;&gt;Verificaci&amp;oacute;n de pron&amp;oacute;sticos expresados ​​en t&amp;eacute;rminos de probabilidad&lt;/a&gt; , Revisi&amp;oacute;n meteorol&amp;oacute;gica mensual 78.1 (1950)</target>
        </trans-unit>
        <trans-unit id="8ccf25498da17f5ff69133909511a6d98d2976f3" translate="yes" xml:space="preserve">
          <source>G. Celeux, M. El Anbari, J.-M. Marin, C. P. Robert, &amp;ldquo;Regularization in regression: comparing Bayesian and frequentist methods in a poorly informative situation&amp;rdquo;, 2009.</source>
          <target state="translated">G. Celeux, M. El Anbari, J.-M. Marin, CP Robert, &amp;ldquo;Regularizaci&amp;oacute;n en regresi&amp;oacute;n: comparaci&amp;oacute;n de m&amp;eacute;todos bayesianos y frecuentistas en una situaci&amp;oacute;n poco informativa&amp;rdquo;, 2009.</target>
        </trans-unit>
        <trans-unit id="755f0c9208b383f3b380dd0d2b1a156d6d5865c4" translate="yes" xml:space="preserve">
          <source>G. James, D. Witten, T. Hastie, R Tibshirani, &lt;a href=&quot;http://www-bcf.usc.edu/~gareth/ISL&quot;&gt;An Introduction to Statistical Learning&lt;/a&gt;, Springer 2013.</source>
          <target state="translated">G. James, D. Witten, T. Hastie, R Tibshirani, &lt;a href=&quot;http://www-bcf.usc.edu/~gareth/ISL&quot;&gt;Introducci&amp;oacute;n al aprendizaje estad&amp;iacute;stico&lt;/a&gt; , Springer 2013.</target>
        </trans-unit>
        <trans-unit id="28ef1689ee2219c624cfde5d7c88afdcae0138ec" translate="yes" xml:space="preserve">
          <source>G. Louppe and P. Geurts, &amp;ldquo;Ensembles on Random Patches&amp;rdquo;, Machine Learning and Knowledge Discovery in Databases, 346-361, 2012.</source>
          <target state="translated">G. Louppe y P. Geurts, &quot;Ensambles on Random Patches&quot;, Aprendizaje autom&amp;aacute;tico y descubrimiento de conocimientos en bases de datos, 346-361, 2012.</target>
        </trans-unit>
        <trans-unit id="c722e87d5d9d7dbc54dd2b811a759cc621efb047" translate="yes" xml:space="preserve">
          <source>G. Louppe, &amp;ldquo;Understanding Random Forests: From Theory to Practice&amp;rdquo;, PhD Thesis, U. of Liege, 2014.</source>
          <target state="translated">G. Louppe, &quot;Comprensi&amp;oacute;n de los bosques aleatorios: de la teor&amp;iacute;a a la pr&amp;aacute;ctica&quot;, Tesis doctoral, U. de Lieja, 2014.</target>
        </trans-unit>
        <trans-unit id="a8ed6bad205ec1f52f0b48e7f8377435663ec074" translate="yes" xml:space="preserve">
          <source>G.E.P. Box and D.R. Cox, &amp;ldquo;An Analysis of Transformations&amp;rdquo;, Journal of the Royal Statistical Society B, 26, 211-252 (1964).</source>
          <target state="translated">GEP Box y DR Cox, &quot;Un an&amp;aacute;lisis de transformaciones&quot;, Revista de la Royal Statistical Society B, 26, 211-252 (1964).</target>
        </trans-unit>
        <trans-unit id="b8cb867b444fe174ab482df0a111ed147a9ceddf" translate="yes" xml:space="preserve">
          <source>GB builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage &lt;code&gt;n_classes_&lt;/code&gt; regression trees are fit on the negative gradient of the binomial or multinomial deviance loss function. Binary classification is a special case where only a single regression tree is induced.</source>
          <target state="translated">GB construye un modelo aditivo de manera progresiva por etapas; permite la optimizaci&amp;oacute;n de funciones de p&amp;eacute;rdida diferenciables arbitrarias. En cada etapa, &lt;code&gt;n_classes_&lt;/code&gt; &amp;aacute;rboles de regresi&amp;oacute;n se ajustan al gradiente negativo de la funci&amp;oacute;n de p&amp;eacute;rdida de desviaci&amp;oacute;n binomial o multinomial. La clasificaci&amp;oacute;n binaria es un caso especial en el que solo se induce un &amp;uacute;nico &amp;aacute;rbol de regresi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="80f39c4fc4a6461ea00d5d7be636d9c6f77055de" translate="yes" xml:space="preserve">
          <source>GB builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage a regression tree is fit on the negative gradient of the given loss function.</source>
          <target state="translated">GB construye un modelo aditivo de forma progresiva;permite la optimización de funciones de pérdida diferenciables arbitrarias.En cada etapa se ajusta un árbol de regresión en el gradiente negativo de la función de pérdida dada.</target>
        </trans-unit>
        <trans-unit id="2c1af0078ebec6d87c6fe14b52a6ca7ecb93e0e6" translate="yes" xml:space="preserve">
          <source>GBRT considers additive models of the following form:</source>
          <target state="translated">La GBRT considera modelos aditivos de la siguiente forma:</target>
        </trans-unit>
        <trans-unit id="348ddf733ebe39c89fe60cc4aea0def489f0df0c" translate="yes" xml:space="preserve">
          <source>GMM covariances</source>
          <target state="translated">Covarianzas del GMM</target>
        </trans-unit>
        <trans-unit id="89a541e422be32f4e38c95b70a35778f6b3b29a5" translate="yes" xml:space="preserve">
          <source>G[i,j] gives the shortest distance from point i to point j along the graph.</source>
          <target state="translated">G[i,j]da la distancia más corta del punto i al punto j a lo largo del gráfico.</target>
        </trans-unit>
        <trans-unit id="dc7da4ca9757d9015c0ba1d2228560006792966e" translate="yes" xml:space="preserve">
          <source>Gallery generated by Sphinx-Gallery</source>
          <target state="translated">Galería generada por Sphinx-Gallery</target>
        </trans-unit>
        <trans-unit id="24f0f86d8b8da4a3eb66c5315b49fb7db14a0fa6" translate="yes" xml:space="preserve">
          <source>Gamma parameter for the RBF, laplacian, polynomial, exponential chi2 and sigmoid kernels. Interpretation of the default value is left to the kernel; see the documentation for sklearn.metrics.pairwise. Ignored by other kernels.</source>
          <target state="translated">Parámetro gamma para los núcleos RBF,laplaciano,polinomio,chi2 exponencial y sigmoide.La interpretación del valor por defecto se deja en manos del núcleo;véase la documentación de sklearn.metrics.pairwise.Ignorado por otros núcleos.</target>
        </trans-unit>
        <trans-unit id="8abb933fe9bd6d8a92eb104bdc2fd613c351d44f" translate="yes" xml:space="preserve">
          <source>Gamma parameter in rbf, poly and sigmoid kernels. Ignored by other kernels. 0.1 by default.</source>
          <target state="translated">Parámetro gamma en los núcleos rbf,poly y sigmoidales.Ignorado por otros núcleos.0.1 por defecto.</target>
        </trans-unit>
        <trans-unit id="86050f4573c138fca290821e4b579d6d320e40d1" translate="yes" xml:space="preserve">
          <source>Gates, G.W. (1972) &amp;ldquo;The Reduced Nearest Neighbor Rule&amp;rdquo;. IEEE Transactions on Information Theory, May 1972, 431-433.</source>
          <target state="translated">Gates, GW (1972) &quot;La regla del vecino m&amp;aacute;s cercano reducido&quot;. IEEE Transactions on Information Theory, mayo de 1972, 431-433.</target>
        </trans-unit>
        <trans-unit id="46a57bcdd34ea523f3417e94b431a41097b638e9" translate="yes" xml:space="preserve">
          <source>Gaussian Mixture Model Ellipsoids</source>
          <target state="translated">Modelo de mezcla gaussiana de elipsoides</target>
        </trans-unit>
        <trans-unit id="2f22bd1dad8340bd3d8973db40a56083b791482c" translate="yes" xml:space="preserve">
          <source>Gaussian Mixture Model Selection</source>
          <target state="translated">Selección del modelo de mezcla gaussiana</target>
        </trans-unit>
        <trans-unit id="7ada59d703243073c5122ce20c200108df4cf582" translate="yes" xml:space="preserve">
          <source>Gaussian Mixture Model Sine Curve</source>
          <target state="translated">Curva sinusoidal modelo de mezcla gaussiana</target>
        </trans-unit>
        <trans-unit id="662a25df4ddd527b4e6e6b4415fd19857fcb55fc" translate="yes" xml:space="preserve">
          <source>Gaussian Mixture.</source>
          <target state="translated">Mezcla Gaussiana.</target>
        </trans-unit>
        <trans-unit id="52d32c3ce740bd6bf6fa9b8c9a00c471e2b8ab61" translate="yes" xml:space="preserve">
          <source>Gaussian Naive Bayes (GaussianNB)</source>
          <target state="translated">Gaussian Naive Bayes (GaussianNB)</target>
        </trans-unit>
        <trans-unit id="3e71cc209c706f89187660af28df9dbd656b7dfb" translate="yes" xml:space="preserve">
          <source>Gaussian Processes regression: basic introductory example</source>
          <target state="translated">Regresión de los Procesos Gaussianos:ejemplo básico de introducción</target>
        </trans-unit>
        <trans-unit id="7c9060d2e2a8ab44211d4b8690374c1230f1b7f2" translate="yes" xml:space="preserve">
          <source>Gaussian kernel (&lt;code&gt;kernel = 'gaussian'&lt;/code&gt;)</source>
          <target state="translated">Kernel gaussiano ( &lt;code&gt;kernel = 'gaussian'&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="16bd9bbb5a5342036acd14278f2e03ad41c57f6a" translate="yes" xml:space="preserve">
          <source>Gaussian mixture model fit with a variational inference.</source>
          <target state="translated">El modelo de mezcla gaussiano encaja con una inferencia variacional.</target>
        </trans-unit>
        <trans-unit id="c4278ff51902cddfc2c28028add69085822b616d" translate="yes" xml:space="preserve">
          <source>Gaussian mixture models, useful for clustering, are described in &lt;a href=&quot;mixture#mixture&quot;&gt;another chapter of the documentation&lt;/a&gt; dedicated to mixture models. KMeans can be seen as a special case of Gaussian mixture model with equal covariance per component.</source>
          <target state="translated">Los modelos de mezcla gaussianos, &amp;uacute;tiles para la agrupaci&amp;oacute;n, se describen en &lt;a href=&quot;mixture#mixture&quot;&gt;otro cap&amp;iacute;tulo de la documentaci&amp;oacute;n&lt;/a&gt; dedicado a los modelos de mezcla. KMeans puede verse como un caso especial de modelo de mezcla gaussiana con igual covarianza por componente.</target>
        </trans-unit>
        <trans-unit id="52102b8851b98924c7d8b1f347902fc1a6a2f6c4" translate="yes" xml:space="preserve">
          <source>Gaussian mixtures</source>
          <target state="translated">Mezclas gaussianas</target>
        </trans-unit>
        <trans-unit id="fb2ed046d4b5b73ab490df316744dbd7803b27c6" translate="yes" xml:space="preserve">
          <source>Gaussian process classification (GPC) based on Laplace approximation.</source>
          <target state="translated">Clasificación del proceso Gaussiano (GPC)basada en la aproximación de Laplace.</target>
        </trans-unit>
        <trans-unit id="6022eb0f0e245ca9c1dcd7d4b4311ff01e4db354" translate="yes" xml:space="preserve">
          <source>Gaussian process classification (GPC) on iris dataset</source>
          <target state="translated">Clasificación del proceso Gaussiano (GPC)en el conjunto de datos del iris</target>
        </trans-unit>
        <trans-unit id="21a63bbdb2d774ad21ffa6c87b635dc00ddbdcbd" translate="yes" xml:space="preserve">
          <source>Gaussian process regression (GPR) on Mauna Loa CO2 data.</source>
          <target state="translated">Regresión del proceso Gaussiano (GPR)en los datos de CO2 de Mauna Loa.</target>
        </trans-unit>
        <trans-unit id="0c7b8e025d47923893c509b893c584646dec60f9" translate="yes" xml:space="preserve">
          <source>Gaussian process regression (GPR) with noise-level estimation</source>
          <target state="translated">Regresión del proceso Gaussiano (GPR)con estimación del nivel de ruido</target>
        </trans-unit>
        <trans-unit id="e020234a1ce464bccd79fd7ca6cd9571320c3263" translate="yes" xml:space="preserve">
          <source>Gaussian process regression (GPR).</source>
          <target state="translated">Regresión del proceso Gaussiano (GPR).</target>
        </trans-unit>
        <trans-unit id="3eef2758f8f04922436ba69e73f365c3b677d080" translate="yes" xml:space="preserve">
          <source>GaussianNaiveBayes tends to push probabilities to 0 or 1 (note the counts in the histograms). This is mainly because it makes the assumption that features are conditionally independent given the class, which is not the case in this dataset which contains 2 redundant features.</source>
          <target state="translated">GaussianNaiveBayes tiende a empujar las probabilidades a 0 o 1 (note los recuentos en los histogramas).Esto se debe principalmente a que asume que las características son condicionalmente independientes dada la clase,lo que no es el caso en este conjunto de datos que contiene 2 características redundantes.</target>
        </trans-unit>
        <trans-unit id="9ee50bfb8852bcfbfa07c7c7a246c842043563a2" translate="yes" xml:space="preserve">
          <source>General KDD structure :</source>
          <target state="translated">Estructura general de KDD:</target>
        </trans-unit>
        <trans-unit id="340183f53d5a585fe2f90b1573169f80622dc9bd" translate="yes" xml:space="preserve">
          <source>General-purpose, even cluster size, flat geometry, not too many clusters</source>
          <target state="translated">De uso general,tamaño de cúmulo uniforme,geometría plana,no demasiados cúmulos</target>
        </trans-unit>
        <trans-unit id="a807e718c7c2444084ecd599b5293f02618f18b0" translate="yes" xml:space="preserve">
          <source>Generally speaking, when model complexity increases, predictive power and latency are supposed to increase. Increasing predictive power is usually interesting, but for many applications we would better not increase prediction latency too much. We will now review this idea for different families of supervised models.</source>
          <target state="translated">En términos generales,cuando la complejidad del modelo aumenta,se supone que la potencia de predicción y la latencia aumentan.El aumento de la potencia de predicción suele ser interesante,pero para muchas aplicaciones sería mejor no aumentar demasiado la latencia de predicción.Ahora revisaremos esta idea para diferentes familias de modelos supervisados.</target>
        </trans-unit>
        <trans-unit id="af9887d0c879889fc0d4b97d28831fef1da0e335" translate="yes" xml:space="preserve">
          <source>Generate a distance matrix chunk by chunk with optional reduction</source>
          <target state="translated">Generar una matriz de distancia pedazo a pedazo con reducción opcional</target>
        </trans-unit>
        <trans-unit id="06c2a79c89c40ddc99e314455bfeabb348baaefc" translate="yes" xml:space="preserve">
          <source>Generate a mostly low rank matrix with bell-shaped singular values</source>
          <target state="translated">Generar una matriz de bajo rango con valores singulares en forma de campana</target>
        </trans-unit>
        <trans-unit id="c1825817fcf44112a4d64fe6f2acf131fceae396" translate="yes" xml:space="preserve">
          <source>Generate a new feature matrix consisting of all polynomial combinations of the features with degree less than or equal to the specified degree. For example, if an input sample is two dimensional and of the form [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].</source>
          <target state="translated">Generar una nueva matriz de características que consista en todas las combinaciones polinómicas de las características con grado menor o igual al grado especificado.Por ejemplo,si una muestra de entrada es bidimensional y de la forma [a,b],los rasgos del polinomio de grado 2 son [1,a,b,a^2,ab,b^2].</target>
        </trans-unit>
        <trans-unit id="138afdc51f7a90d9b74b5dc5c84735ab7ad5ab97" translate="yes" xml:space="preserve">
          <source>Generate a random multilabel classification problem.</source>
          <target state="translated">Generar un problema de clasificación aleatoria de múltiples etiquetas.</target>
        </trans-unit>
        <trans-unit id="6e53d56707f7eb93fc64a285e9e5b0c1571546a7" translate="yes" xml:space="preserve">
          <source>Generate a random n-class classification problem.</source>
          <target state="translated">Generar un problema de clasificación aleatoria de n clases.</target>
        </trans-unit>
        <trans-unit id="45b70aa4bfe7b5254dd4845949fd163391dae828" translate="yes" xml:space="preserve">
          <source>Generate a random regression problem with sparse uncorrelated design</source>
          <target state="translated">Generar un problema de regresión aleatoria con un diseño disperso no correlacionado</target>
        </trans-unit>
        <trans-unit id="097811da2f026de1c67525043ab17d6d057450a6" translate="yes" xml:space="preserve">
          <source>Generate a random regression problem.</source>
          <target state="translated">Generar un problema de regresión aleatoria.</target>
        </trans-unit>
        <trans-unit id="90aba5bbbbad8863550c06ced91ee520b1c0caff" translate="yes" xml:space="preserve">
          <source>Generate a random symmetric, positive-definite matrix.</source>
          <target state="translated">Generar una matriz simétrica aleatoria,positiva-definida.</target>
        </trans-unit>
        <trans-unit id="b303920886f4c442ac72ea67b8bd3cb1b7460430" translate="yes" xml:space="preserve">
          <source>Generate a signal as a sparse combination of dictionary elements.</source>
          <target state="translated">Generar una señal como una combinación dispersa de elementos de diccionario.</target>
        </trans-unit>
        <trans-unit id="035b22a208f9d34d7467f70a3f8e5a4c27edb9b2" translate="yes" xml:space="preserve">
          <source>Generate a sparse random projection matrix</source>
          <target state="translated">Generar una matriz de proyección aleatoria dispersa</target>
        </trans-unit>
        <trans-unit id="4dc557ac054fd2b6925cea078345560226a5469c" translate="yes" xml:space="preserve">
          <source>Generate a sparse symmetric definite positive matrix.</source>
          <target state="translated">Generar una matriz positiva definida simétrica y dispersa.</target>
        </trans-unit>
        <trans-unit id="2b6ed08a20bd86f602cf70906530ae751a13aa6a" translate="yes" xml:space="preserve">
          <source>Generate a swiss roll dataset.</source>
          <target state="translated">Generar un conjunto de datos de rollos suizos.</target>
        </trans-unit>
        <trans-unit id="2f7e815b3b193bc1cd3e7e4a28307316625909c7" translate="yes" xml:space="preserve">
          <source>Generate an S curve dataset.</source>
          <target state="translated">Generar un conjunto de datos de la curva S.</target>
        </trans-unit>
        <trans-unit id="a97cf86ca659bda28267893fc11990f8622b62e7" translate="yes" xml:space="preserve">
          <source>Generate an array with block checkerboard structure for biclustering.</source>
          <target state="translated">Generar una matriz con estructura de tablero de bloques para el biclustering.</target>
        </trans-unit>
        <trans-unit id="a9f13a8783d09446e6122b3e3234e1d6fcb95591" translate="yes" xml:space="preserve">
          <source>Generate an array with constant block diagonal structure for biclustering.</source>
          <target state="translated">Generar una matriz con una estructura diagonal de bloque constante para el biclustering.</target>
        </trans-unit>
        <trans-unit id="afeaee3f091598162e7eb33b08779a77e0e748f4" translate="yes" xml:space="preserve">
          <source>Generate cross-validated estimates for each input data point</source>
          <target state="translated">Generar estimaciones validadas cruzadas para cada punto de datos de entrada</target>
        </trans-unit>
        <trans-unit id="99b9ba538a40d50737f63d924a3c7ce27d75993f" translate="yes" xml:space="preserve">
          <source>Generate datasets. We choose the size big enough to see the scalability of the algorithms, but not too big to avoid too long running times</source>
          <target state="translated">Generar conjuntos de datos.Elegimos el tamaño lo suficientemente grande para ver la escalabilidad de los algoritmos,pero no demasiado grande para evitar tiempos de ejecución demasiado largos</target>
        </trans-unit>
        <trans-unit id="c00dd920cc2725de42546dcb337634c4ac897029" translate="yes" xml:space="preserve">
          <source>Generate indices to split data into training and test set.</source>
          <target state="translated">Generar índices para dividir los datos en el entrenamiento y el conjunto de pruebas.</target>
        </trans-unit>
        <trans-unit id="5107cc8a6ff57cac684ccce1f62420eaa4260507" translate="yes" xml:space="preserve">
          <source>Generate isotropic Gaussian and label samples by quantile</source>
          <target state="translated">Generar Gauss isotrópico y etiquetar las muestras por cuantiles</target>
        </trans-unit>
        <trans-unit id="8e89de3bc63d92fa78eda36337c27db80aab71fe" translate="yes" xml:space="preserve">
          <source>Generate isotropic Gaussian blobs for clustering.</source>
          <target state="translated">Generar glóbulos gausianos isotrópicos para la agrupación.</target>
        </trans-unit>
        <trans-unit id="37d03dbfefb10390fe483e5ed2d7b03c5a459fa1" translate="yes" xml:space="preserve">
          <source>Generate missing values indicator for X.</source>
          <target state="translated">Generar el indicador de valores perdidos para X.</target>
        </trans-unit>
        <trans-unit id="462cab2784077aa54955d18bb40a9de12e6edf3c" translate="yes" xml:space="preserve">
          <source>Generate polynomial and interaction features.</source>
          <target state="translated">Generar características polinómicas y de interacción.</target>
        </trans-unit>
        <trans-unit id="d1bba874447d3710a4261bda204e3775c6148149" translate="yes" xml:space="preserve">
          <source>Generate random samples from the fitted Gaussian distribution.</source>
          <target state="translated">Generar muestras aleatorias de la distribución gaussiana ajustada.</target>
        </trans-unit>
        <trans-unit id="ce67c2d91c83a1d56ab9a9ee35d822063af6506a" translate="yes" xml:space="preserve">
          <source>Generate random samples from the model.</source>
          <target state="translated">Generar muestras aleatorias del modelo.</target>
        </trans-unit>
        <trans-unit id="f4defed702b6f02ff908f1cd9f8b411c35ee40dd" translate="yes" xml:space="preserve">
          <source>Generate the &amp;ldquo;Friedman #1&amp;rdquo; regression problem</source>
          <target state="translated">Genere el problema de regresi&amp;oacute;n &quot;Friedman # 1&quot;</target>
        </trans-unit>
        <trans-unit id="75088d435099809ee2a5f0ec830b6e2b26fb0500" translate="yes" xml:space="preserve">
          <source>Generate the &amp;ldquo;Friedman #2&amp;rdquo; regression problem</source>
          <target state="translated">Genere el problema de regresi&amp;oacute;n &quot;Friedman # 2&quot;</target>
        </trans-unit>
        <trans-unit id="18ca02f4b303dec3c31289cd6db22246b19d8adb" translate="yes" xml:space="preserve">
          <source>Generate the &amp;ldquo;Friedman #3&amp;rdquo; regression problem</source>
          <target state="translated">Genere el problema de regresi&amp;oacute;n &quot;Friedman # 3&quot;</target>
        </trans-unit>
        <trans-unit id="1526c84b2e9b495f9ed3216009ebf8b31d461518" translate="yes" xml:space="preserve">
          <source>Generates data for binary classification used in Hastie et al.</source>
          <target state="translated">Genera datos para la clasificación binaria utilizada en Hastie et al.</target>
        </trans-unit>
        <trans-unit id="c2cb269fed6a06711794c0a014b9a89e92300ddb" translate="yes" xml:space="preserve">
          <source>Generates data for binary classification used in Hastie et al. 2009, Example 10.2.</source>
          <target state="translated">Genera datos para la clasificación binaria utilizada en Hastie et al.2009,Ejemplo 10.2.</target>
        </trans-unit>
        <trans-unit id="fbfd61fc35f16aea2f376426724b313bf45b644a" translate="yes" xml:space="preserve">
          <source>Generates indices to split data into training and test set.</source>
          <target state="translated">Genera índices para dividir los datos en el entrenamiento y el conjunto de pruebas.</target>
        </trans-unit>
        <trans-unit id="9a963ad633fdf36ff4f1d429308e1f3d90a2ceea" translate="yes" xml:space="preserve">
          <source>Generates train/test indices based on predefined splits.</source>
          <target state="translated">Genera índices de tren/prueba basados en divisiones predefinidas.</target>
        </trans-unit>
        <trans-unit id="4678269441c5cad2dec162c29e80b19e70944794" translate="yes" xml:space="preserve">
          <source>Generates train/test indices based on random permutation.</source>
          <target state="translated">Genera índices de tren/prueba basados en una permutación aleatoria.</target>
        </trans-unit>
        <trans-unit id="025efadf6f18cb5d61732c8188dd311431f2fe8b" translate="yes" xml:space="preserve">
          <source>Generator on parameters sampled from given distributions.</source>
          <target state="translated">Generador sobre los parámetros muestreados de las distribuciones dadas.</target>
        </trans-unit>
        <trans-unit id="9008c79b50b6e856f48dd8a1acb75bd481c83565" translate="yes" xml:space="preserve">
          <source>Generator to create n_packs slices going up to n.</source>
          <target state="translated">Generador para crear rebanadas de n_packs que van hasta n.</target>
        </trans-unit>
        <trans-unit id="6a34af9aa1c17133e53bdde13fa952c7bcbcf3f6" translate="yes" xml:space="preserve">
          <source>Geometry (metric used)</source>
          <target state="translated">Geometría (métrica utilizada)</target>
        </trans-unit>
        <trans-unit id="e5f048789e3e59e8993091df470af502112331aa" translate="yes" xml:space="preserve">
          <source>George W Bush</source>
          <target state="translated">George W.Bush</target>
        </trans-unit>
        <trans-unit id="b583db923d23716d80d92ca8bb6a609aa1f738a2" translate="yes" xml:space="preserve">
          <source>Gerhard Schroeder</source>
          <target state="translated">Gerhard Schroeder</target>
        </trans-unit>
        <trans-unit id="33868dad5f60b783d41cfb7c4e686fd5af82ea02" translate="yes" xml:space="preserve">
          <source>Get a list of all estimators from sklearn.</source>
          <target state="translated">Consigue una lista de todos los estimadores de Sklearn.</target>
        </trans-unit>
        <trans-unit id="c89b4f911ae16fa0b7caa09ce0c140306df6a7bd" translate="yes" xml:space="preserve">
          <source>Get a mask, or integer index, of the features selected</source>
          <target state="translated">Obtener una máscara,o índice entero,de las características seleccionadas</target>
        </trans-unit>
        <trans-unit id="72908cf84377de645c7534a22afeddeeaba91d9d" translate="yes" xml:space="preserve">
          <source>Get a scorer from string</source>
          <target state="translated">Consigue un anotador de cuerda</target>
        </trans-unit>
        <trans-unit id="45a250b2600ca82b0e59f392e6c981ee3cc2728d" translate="yes" xml:space="preserve">
          <source>Get feature names from all transformers.</source>
          <target state="translated">Consigue los nombres de las características de todos los transformadores.</target>
        </trans-unit>
        <trans-unit id="4be0c520942fc8926cfd53e42cd4ae1d1cc70df9" translate="yes" xml:space="preserve">
          <source>Get parameters for this estimator.</source>
          <target state="translated">Obtener los parámetros para este estimador.</target>
        </trans-unit>
        <trans-unit id="fe15f50ace10fe1b8c70139542f4a1796682abb3" translate="yes" xml:space="preserve">
          <source>Get parameters of this kernel.</source>
          <target state="translated">Obtener los parámetros de este núcleo.</target>
        </trans-unit>
        <trans-unit id="1314abe875bac1db97b1a7155d7b4a8c13c230ee" translate="yes" xml:space="preserve">
          <source>Get predictions from each split of cross-validation for diagnostic purposes.</source>
          <target state="translated">Obtener predicciones de cada división de la validación cruzada con fines de diagnóstico.</target>
        </trans-unit>
        <trans-unit id="dd0a065fc935a1fd709e1a1d7d55ca6c3433dca5" translate="yes" xml:space="preserve">
          <source>Get the given distance metric from the string identifier.</source>
          <target state="translated">Obtener la métrica de distancia dada del identificador de la cadena.</target>
        </trans-unit>
        <trans-unit id="df2089c702273c8bc78b6842775813fe9702ad55" translate="yes" xml:space="preserve">
          <source>Get the parameters of the VotingClassifier</source>
          <target state="translated">Obtener los parámetros del VotingClassifier</target>
        </trans-unit>
        <trans-unit id="1f6030226293d5ed7b4d4b045e215d6de20db61c" translate="yes" xml:space="preserve">
          <source>Getter for the precision matrix.</source>
          <target state="translated">Trae la matriz de precisión.</target>
        </trans-unit>
        <trans-unit id="53379a8bafa1cbd8bc5da14050f14d3817f01039" translate="yes" xml:space="preserve">
          <source>Given 2 multivariate covarying two-dimensional datasets, X, and Y, PLS extracts the &amp;lsquo;directions of covariance&amp;rsquo;, i.e. the components of each datasets that explain the most shared variance between both datasets. This is apparent on the &lt;strong&gt;scatterplot matrix&lt;/strong&gt; display: components 1 in dataset X and dataset Y are maximally correlated (points lie around the first diagonal). This is also true for components 2 in both dataset, however, the correlation across datasets for different components is weak: the point cloud is very spherical.</source>
          <target state="translated">Dados 2 conjuntos de datos bidimensionales covariantes multivariados, X e Y, PLS extrae las 'direcciones de covarianza', es decir, los componentes de cada conjunto de datos que explican la varianza m&amp;aacute;s compartida entre ambos conjuntos de datos. Esto es evidente en la pantalla de la &lt;strong&gt;matriz de gr&amp;aacute;ficos de dispersi&amp;oacute;n&lt;/strong&gt; : los componentes 1 en el conjunto de datos X y el conjunto de datos Y est&amp;aacute;n correlacionados al m&amp;aacute;ximo (los puntos se encuentran alrededor de la primera diagonal). Esto tambi&amp;eacute;n es cierto para los componentes 2 en ambos conjuntos de datos, sin embargo, la correlaci&amp;oacute;n entre conjuntos de datos para diferentes componentes es d&amp;eacute;bil: la nube de puntos es muy esf&amp;eacute;rica.</target>
        </trans-unit>
        <trans-unit id="16179644ab5a4c2a1f730ff634ab3d4d3a869791" translate="yes" xml:space="preserve">
          <source>Given a candidate centroid \(x_i\) for iteration \(t\), the candidate is updated according to the following equation:</source>
          <target state="translated">Si se le da un centroide candidato para la iteración,el candidato se actualiza de acuerdo con la siguiente ecuación:</target>
        </trans-unit>
        <trans-unit id="4368fa47ed8eb35b757e7b3d5aaf6d7ee1cd4ff6" translate="yes" xml:space="preserve">
          <source>Given a dataset with two features, we let the encoder find the unique values per feature and transform the data to a binary one-hot encoding.</source>
          <target state="translated">Dado un conjunto de datos con dos características,dejamos que el codificador encuentre los valores únicos por característica y transforme los datos en una codificación binaria de un solo disparo.</target>
        </trans-unit>
        <trans-unit id="a65060cb3a96ad97e8800308b9076a9a49180060" translate="yes" xml:space="preserve">
          <source>Given a dataset with two features, we let the encoder find the unique values per feature and transform the data to an ordinal encoding.</source>
          <target state="translated">Dado un conjunto de datos con dos características,dejamos que el codificador encuentre los valores únicos por característica y transforme los datos en una codificación ordinal.</target>
        </trans-unit>
        <trans-unit id="6cc0cdb4252ae3fe585bd759a612161dfe7c6d85" translate="yes" xml:space="preserve">
          <source>Given a set of training examples \((x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)\) where \(x_i \in \mathbf{R}^n\) and \(y_i \in \{0, 1\}\), a one hidden layer one hidden neuron MLP learns the function \(f(x) = W_2 g(W_1^T x + b_1) + b_2\) where \(W_1 \in \mathbf{R}^m\) and \(W_2, b_1, b_2 \in \mathbf{R}\) are model parameters. \(W_1, W_2\) represent the weights of the input layer and hidden layer, respectively; and \(b_1, b_2\) represent the bias added to the hidden layer and the output layer, respectively. \(g(\cdot) : R \rightarrow R\) is the activation function, set by default as the hyperbolic tan. It is given as,</source>
          <target state="translated">Dando un conjunto de ejemplos de entrenamiento \ ~ (x_1,y_1),(x_2,y_2),\ ~ puntos,(x_n,y_n)\ ~ donde \ ~ (x_i \ ~ en \ ~ Mathbf {R}}y \ ~ (y_i \ ~ en \ ~ 1),una capa oculta una neurona oculta MLP aprende la función \(f(x)=W_2 g(W_1^T x+b_1)+b_2\)donde \(W_1 \Nen \Nmathbf{R}^m})y \N(W_2,b_1,b_2 \Nen \Nmathbf{R})son parámetros modelo.\(W_1,W_2\)representan los pesos de la capa de entrada y la capa oculta,respectivamente;y \(b_1,b_2\)representan el sesgo añadido a la capa oculta y la capa de salida,respectivamente.\(g(\cdot):R \N-estrecha derecha R\N es la función de activación,establecida por defecto como el bronceado hiperbólico.Se da como,</target>
        </trans-unit>
        <trans-unit id="99b85508f1069fad6e9945b3624fea4140b5fbae" translate="yes" xml:space="preserve">
          <source>Given a set of training examples \((x_1, y_1), \ldots, (x_n, y_n)\) where \(x_i \in \mathbf{R}^m\) and \(y_i \in \{-1,1\}\), our goal is to learn a linear scoring function \(f(x) = w^T x + b\) with model parameters \(w \in \mathbf{R}^m\) and intercept \(b \in \mathbf{R}\). In order to make predictions, we simply look at the sign of \(f(x)\). A common choice to find the model parameters is by minimizing the regularized training error given by</source>
          <target state="translated">Dando un conjunto de ejemplos de entrenamiento \ ~ (x_1,y_1),\ ~ puntos,(x_n,y_n)\ ~ donde \ ~ (x_i \ ~ en \ ~ mathbf {R}}y \ ~ (y_i \ ~ en \ ~-1,1),nuestro objetivo es aprender una función de puntuación lineal (f(x)=w^T x+b)con los parámetros del modelo (w en matemáticas)e interceptar (b en matemáticas).Para hacer predicciones,simplemente miramos el signo de la f(x)²).Una elección común para encontrar los parámetros del modelo es minimizar el error de entrenamiento regularizado dado por</target>
        </trans-unit>
        <trans-unit id="f05ffd1dc56829aeb2ce3b1aa47183d5a5a71272" translate="yes" xml:space="preserve">
          <source>Given an exception, a callable to raise the exception, and a message string, tests that the correct exception is raised and that the message is a substring of the error thrown. Used to test that the specific message thrown during an exception is correct.</source>
          <target state="translated">Dada una excepción,una llamada para elevar la excepción,y una cadena de mensajes,prueba que la excepción correcta es elevada y que el mensaje es una subcadena del error lanzado.Se usa para probar que el mensaje específico lanzado durante una excepción es correcto.</target>
        </trans-unit>
        <trans-unit id="d5588778e54082615cf481fafbc7dcf0b337d76d" translate="yes" xml:space="preserve">
          <source>Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), recursive feature elimination (&lt;a href=&quot;generated/sklearn.feature_selection.rfe#sklearn.feature_selection.RFE&quot;&gt;&lt;code&gt;RFE&lt;/code&gt;&lt;/a&gt;) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a &lt;code&gt;coef_&lt;/code&gt; attribute or through a &lt;code&gt;feature_importances_&lt;/code&gt; attribute. Then, the least important features are pruned from current set of features.That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.</source>
          <target state="translated">Dado un estimador externo que asigna ponderaciones a las caracter&amp;iacute;sticas (por ejemplo, los coeficientes de un modelo lineal), la eliminaci&amp;oacute;n de caracter&amp;iacute;sticas recursivas ( &lt;a href=&quot;generated/sklearn.feature_selection.rfe#sklearn.feature_selection.RFE&quot;&gt; &lt;code&gt;RFE&lt;/code&gt; &lt;/a&gt; ) es seleccionar caracter&amp;iacute;sticas considerando recursivamente conjuntos de caracter&amp;iacute;sticas cada vez m&amp;aacute;s peque&amp;ntilde;os. Primero, el estimador se entrena en el conjunto inicial de caracter&amp;iacute;sticas y la importancia de cada caracter&amp;iacute;stica se obtiene a trav&amp;eacute;s de un atributo &lt;code&gt;coef_&lt;/code&gt; o mediante un atributo &lt;code&gt;feature_importances_&lt;/code&gt; . Luego, las caracter&amp;iacute;sticas menos importantes se eliminan del conjunto actual de caracter&amp;iacute;sticas. Ese procedimiento se repite de forma recursiva en el conjunto eliminado hasta que finalmente se alcanza el n&amp;uacute;mero deseado de caracter&amp;iacute;sticas para seleccionar.</target>
        </trans-unit>
        <trans-unit id="0a3e62329db7e0582a525546102e4bc5a3e414ee" translate="yes" xml:space="preserve">
          <source>Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a &lt;code&gt;coef_&lt;/code&gt; attribute or through a &lt;code&gt;feature_importances_&lt;/code&gt; attribute. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.</source>
          <target state="translated">Dado un estimador externo que asigna pesos a las caracter&amp;iacute;sticas (por ejemplo, los coeficientes de un modelo lineal), el objetivo de la eliminaci&amp;oacute;n de caracter&amp;iacute;sticas recursivas (RFE) es seleccionar caracter&amp;iacute;sticas considerando recursivamente conjuntos de caracter&amp;iacute;sticas cada vez m&amp;aacute;s peque&amp;ntilde;os. Primero, el estimador se entrena en el conjunto inicial de caracter&amp;iacute;sticas y la importancia de cada caracter&amp;iacute;stica se obtiene a trav&amp;eacute;s de un atributo &lt;code&gt;coef_&lt;/code&gt; o mediante un atributo &lt;code&gt;feature_importances_&lt;/code&gt; . Luego, las caracter&amp;iacute;sticas menos importantes se eliminan del conjunto de caracter&amp;iacute;sticas actual. Ese procedimiento se repite de forma recursiva en el conjunto podado hasta que finalmente se alcanza el n&amp;uacute;mero deseado de caracter&amp;iacute;sticas para seleccionar.</target>
        </trans-unit>
        <trans-unit id="2e4a90e9413cabdb8d0d79c137af8efe3fbd16ef" translate="yes" xml:space="preserve">
          <source>Given enough time, K-means will always converge, however this may be to a local minimum. This is highly dependent on the initialization of the centroids. As a result, the computation is often done several times, with different initializations of the centroids. One method to help address this issue is the k-means++ initialization scheme, which has been implemented in scikit-learn (use the &lt;code&gt;init='k-means++'&lt;/code&gt; parameter). This initializes the centroids to be (generally) distant from each other, leading to provably better results than random initialization, as shown in the reference.</source>
          <target state="translated">Con el tiempo suficiente, las K-medias siempre converger&amp;aacute;n, sin embargo, esto puede ser un m&amp;iacute;nimo local. Esto depende en gran medida de la inicializaci&amp;oacute;n de los centroides. Como resultado, el c&amp;aacute;lculo a menudo se realiza varias veces, con diferentes inicializaciones de los centroides. Un m&amp;eacute;todo para ayudar a abordar este problema es el esquema de inicializaci&amp;oacute;n k-means ++, que se ha implementado en scikit-learn (use el par&amp;aacute;metro &lt;code&gt;init='k-means++'&lt;/code&gt; ). Esto inicializa los centroides para que est&amp;eacute;n (generalmente) distantes entre s&amp;iacute;, lo que conduce a resultados demostrablemente mejores que la inicializaci&amp;oacute;n aleatoria, como se muestra en la referencia.</target>
        </trans-unit>
        <trans-unit id="74d4aecb20e2cdcd5c8865136aad914eecac7d61" translate="yes" xml:space="preserve">
          <source>Given the iris dataset, if we knew that there were 3 types of iris, but did not have access to a taxonomist to label them: we could try a &lt;strong&gt;clustering task&lt;/strong&gt;: split the observations into well-separated group called &lt;em&gt;clusters&lt;/em&gt;.</source>
          <target state="translated">Dado el conjunto de datos del iris, si supi&amp;eacute;ramos que hay 3 tipos de iris, pero no tuvi&amp;eacute;ramos acceso a un tax&amp;oacute;nomo para etiquetarlos: podr&amp;iacute;amos intentar una &lt;strong&gt;tarea de agrupamiento&lt;/strong&gt; : dividir las observaciones en grupos bien separados llamados &lt;em&gt;grupos&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="7ffdaa4cdda4b54b62086a7f5ac68bd7ea3b5908" translate="yes" xml:space="preserve">
          <source>Given the knowledge of the ground truth class assignments &lt;code&gt;labels_true&lt;/code&gt; and our clustering algorithm assignments of the same samples &lt;code&gt;labels_pred&lt;/code&gt;, the &lt;strong&gt;Mutual Information&lt;/strong&gt; is a function that measures the &lt;strong&gt;agreement&lt;/strong&gt; of the two assignments, ignoring permutations. Two different normalized versions of this measure are available, &lt;strong&gt;Normalized Mutual Information (NMI)&lt;/strong&gt; and &lt;strong&gt;Adjusted Mutual Information (AMI)&lt;/strong&gt;. NMI is often used in the literature, while AMI was proposed more recently and is &lt;strong&gt;normalized against chance&lt;/strong&gt;:</source>
          <target state="translated">Dado el conocimiento de las asignaciones de la clase de verdad &lt;code&gt;labels_true&lt;/code&gt; y nuestras asignaciones de algoritmo de agrupamiento de las mismas muestras &lt;code&gt;labels_pred&lt;/code&gt; , la &lt;strong&gt;Informaci&amp;oacute;n Mutua&lt;/strong&gt; es una funci&amp;oacute;n que mide la &lt;strong&gt;concordancia&lt;/strong&gt; de las dos asignaciones, ignorando las permutaciones. Hay dos versiones normalizadas diferentes de esta medida disponibles, &lt;strong&gt;Informaci&amp;oacute;n mutua normalizada (NMI)&lt;/strong&gt; e &lt;strong&gt;Informaci&amp;oacute;n mutua ajustada (AMI)&lt;/strong&gt; . El NMI se usa a menudo en la literatura, mientras que el IAM se propuso m&amp;aacute;s recientemente y se &lt;strong&gt;normaliza frente al azar&lt;/strong&gt; :</target>
        </trans-unit>
        <trans-unit id="943836cb04e0640667940c68f56d5deeb3e35898" translate="yes" xml:space="preserve">
          <source>Given the knowledge of the ground truth class assignments &lt;code&gt;labels_true&lt;/code&gt; and our clustering algorithm assignments of the same samples &lt;code&gt;labels_pred&lt;/code&gt;, the &lt;strong&gt;adjusted Rand index&lt;/strong&gt; is a function that measures the &lt;strong&gt;similarity&lt;/strong&gt; of the two assignments, ignoring permutations and &lt;strong&gt;with chance normalization&lt;/strong&gt;:</source>
          <target state="translated">Dado el conocimiento de las asignaciones de la clase de verdad &lt;code&gt;labels_true&lt;/code&gt; y nuestras asignaciones de algoritmo de agrupamiento de las mismas muestras &lt;code&gt;labels_pred&lt;/code&gt; , el &lt;strong&gt;&amp;iacute;ndice Rand ajustado&lt;/strong&gt; es una funci&amp;oacute;n que mide la &lt;strong&gt;similitud&lt;/strong&gt; de las dos asignaciones, ignorando las permutaciones y &lt;strong&gt;con normalizaci&amp;oacute;n al azar&lt;/strong&gt; :</target>
        </trans-unit>
        <trans-unit id="3a989bbd6a98db5dab53799fee5637e2080ce141" translate="yes" xml:space="preserve">
          <source>Given the knowledge of the ground truth class assignments of the samples, it is possible to define some intuitive metric using conditional entropy analysis.</source>
          <target state="translated">Dado el conocimiento de las asignaciones de clases de verdad de las muestras,es posible definir alguna métrica intuitiva utilizando el análisis de entropía condicional.</target>
        </trans-unit>
        <trans-unit id="4d7a7b1af5c7c7276434270fce7100038c705add" translate="yes" xml:space="preserve">
          <source>Given these singular vectors, they are ranked according to which can be best approximated by a piecewise-constant vector. The approximations for each vector are found using one-dimensional k-means and scored using the Euclidean distance. Some subset of the best left and right singular vector are selected. Next, the data is projected to this best subset of singular vectors and clustered.</source>
          <target state="translated">Dados estos vectores singulares,se clasifican de acuerdo a lo que se puede aproximar mejor por un vector constante a trozos.Las aproximaciones para cada vector se encuentran usando medios k unidimensionales y se califican usando la distancia euclidiana.Se seleccionan algunos subconjuntos del mejor vector singular izquierdo y derecho.A continuación,los datos se proyectan a este mejor subconjunto de vectores singulares y se agrupan.</target>
        </trans-unit>
        <trans-unit id="21675a464e2ca3b8f99eef191d00e106aa21c0dd" translate="yes" xml:space="preserve">
          <source>Given training vectors \(x_i \in R^n\), i=1,&amp;hellip;, l and a label vector \(y \in R^l\), a decision tree recursively partitions the space such that the samples with the same labels are grouped together.</source>
          <target state="translated">Dados los vectores de entrenamiento \ (x_i \ in R ^ n \), i = 1,&amp;hellip;, ly un vector de etiqueta \ (y \ in R ^ l \), un &amp;aacute;rbol de decisi&amp;oacute;n divide recursivamente el espacio de tal manera que las muestras con el mismo las etiquetas est&amp;aacute;n agrupadas.</target>
        </trans-unit>
        <trans-unit id="02fd4db44c84fce9026584422f7727ba079bc40a" translate="yes" xml:space="preserve">
          <source>Given training vectors \(x_i \in \mathbb{R}^p\), i=1,&amp;hellip;, n, and a vector \(y \in \mathbb{R}^n\)\(\varepsilon\)-SVR solves the following primal problem:</source>
          <target state="translated">Dados los vectores de entrenamiento \ (x_i \ in \ mathbb {R} ^ p \), i = 1,&amp;hellip;, n, y un vector \ (y \ in \ mathbb {R} ^ n \) \ (\ varepsilon \) - SVR resuelve el siguiente problema primario:</target>
        </trans-unit>
        <trans-unit id="70e397398a5003e0a6b00de067e9804bfe571e70" translate="yes" xml:space="preserve">
          <source>Given training vectors \(x_i \in \mathbb{R}^p\), i=1,&amp;hellip;, n, in two classes, and a vector \(y \in \{1, -1\}^n\), SVC solves the following primal problem:</source>
          <target state="translated">Dados los vectores de entrenamiento \ (x_i \ in \ mathbb {R} ^ p \), i = 1,&amp;hellip;, n, en dos clases y un vector \ (y \ in \ {1, -1 \} ^ n \) , SVC resuelve el siguiente problema primario:</target>
        </trans-unit>
        <trans-unit id="e44bf83eca8aa1cc0c5bdaa89da0afa702f51625" translate="yes" xml:space="preserve">
          <source>Gives the number of (complex) sampling points.</source>
          <target state="translated">Da el número de puntos de muestreo (complejos).</target>
        </trans-unit>
        <trans-unit id="f36c7685daa8ebc7e1344aa0d6e3a7d679decebf" translate="yes" xml:space="preserve">
          <source>Global structure is not explicitly preserved. This is problem is mitigated by initializing points with PCA (using &lt;code&gt;init=&amp;rsquo;pca&amp;rsquo;&lt;/code&gt;).</source>
          <target state="translated">La estructura global no se conserva expl&amp;iacute;citamente. Este problema se mitiga inicializando puntos con PCA (usando &lt;code&gt;init=&amp;rsquo;pca&amp;rsquo;&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="178c27bf7200da0534de904ea7e6ca7da842dbb5" translate="yes" xml:space="preserve">
          <source>Glorot, Xavier, and Yoshua Bengio. &amp;ldquo;Understanding the difficulty of</source>
          <target state="translated">Glorot, Xavier y Yoshua Bengio. &quot;Comprender la dificultad de</target>
        </trans-unit>
        <trans-unit id="7427cf697be16a4ec1d916910128a59d920125e7" translate="yes" xml:space="preserve">
          <source>Glossary</source>
          <target state="translated">Glossary</target>
        </trans-unit>
        <trans-unit id="f7c22aaad44fb28f4ee8f06d6d4f4f14ac9ce899" translate="yes" xml:space="preserve">
          <source>Golub and C. Van Loan. Matrix Computations, Third Edition, Chapter 5,</source>
          <target state="translated">Golub y C.Van Loan.Matrix Computations,tercera edición,capítulo 5,</target>
        </trans-unit>
        <trans-unit id="1de5b736be2f9def46d07ed88549feeeea5a97b0" translate="yes" xml:space="preserve">
          <source>Gorodkin, (2004). Comparing two K-category assignments by a K-category correlation coefficient</source>
          <target state="translated">Gorodkin,(2004).Comparando dos asignaciones de la categoría K mediante un coeficiente de correlación de la categoría K</target>
        </trans-unit>
        <trans-unit id="46268d41f41f8e1954ca3d54fd29ddb1959ea6db" translate="yes" xml:space="preserve">
          <source>Gradient Boosting Out-of-Bag estimates</source>
          <target state="translated">Estimaciones del aumento de la graduación fuera de la bolsa</target>
        </trans-unit>
        <trans-unit id="3e3d95a92c5a33953c001956fd3fd6ac3b1082fa" translate="yes" xml:space="preserve">
          <source>Gradient Boosting attempts to solve this minimization problem numerically via steepest descent: The steepest descent direction is the negative gradient of the loss function evaluated at the current model \(F_{m-1}\) which can be calculated for any differentiable loss function:</source>
          <target state="translated">Gradient Boosting intenta resolver este problema de minimización numéricamente a través del descenso más pronunciado:La dirección de descenso más pronunciado es el gradiente negativo de la función de pérdida evaluada en el modelo actual \(F_{m-1}\)que puede ser calculado para cualquier función de pérdida diferenciable:</target>
        </trans-unit>
        <trans-unit id="be45c92854a0f55592d6c3c1c28201cf75d59d94" translate="yes" xml:space="preserve">
          <source>Gradient Boosting for classification.</source>
          <target state="translated">Gradient Boosting para la clasificación.</target>
        </trans-unit>
        <trans-unit id="65fd480d2da13d80eb18643fd08c31b9e5239c9a" translate="yes" xml:space="preserve">
          <source>Gradient Boosting for regression.</source>
          <target state="translated">Impulso de gradiente para la regresión.</target>
        </trans-unit>
        <trans-unit id="23dcf8253cdacbdd915f0e5e69e684c3457ad1df" translate="yes" xml:space="preserve">
          <source>Gradient Boosting regression</source>
          <target state="translated">Gradiente Impulsando la regresión</target>
        </trans-unit>
        <trans-unit id="33b1659de13c2a7e036f71b3c26eda1d552a4b1c" translate="yes" xml:space="preserve">
          <source>Gradient Boosting regularization</source>
          <target state="translated">Gradiente Impulsar la regularización</target>
        </trans-unit>
        <trans-unit id="cf9557c4e6e59de44aebd2e8b07221ff19e46958" translate="yes" xml:space="preserve">
          <source>Gradient boosting is an ensembling technique where several weak learners (regression trees) are combined to yield a powerful single model, in an iterative fashion.</source>
          <target state="translated">El aumento de gradiente es una técnica de ensamblaje en la que se combinan varios aprendices débiles (árboles de regresión)para obtener un poderoso modelo único,de manera iterativa.</target>
        </trans-unit>
        <trans-unit id="c4611f197e5e7430aa271445ae503720ad1cf3d4" translate="yes" xml:space="preserve">
          <source>Gradient of the log-marginal likelihood with respect to the kernel hyperparameters at position theta. Only returned when eval_gradient is True.</source>
          <target state="translated">Gradiente de la probabilidad logarítmica marginal con respecto a los hiperparámetros del núcleo en la posición theta.Sólo se devuelve cuando eval_gradient es True.</target>
        </trans-unit>
        <trans-unit id="f77edae6db0cdcd4449adeeb038c653af7406ea3" translate="yes" xml:space="preserve">
          <source>Gram Orthogonal Matching Pursuit (OMP)</source>
          <target state="translated">La persecución ortogonal de la Gram Orthogonal Matching Pursuit (OMP)</target>
        </trans-unit>
        <trans-unit id="10ef9123115df39a65f62ffa3d9d0e10899ca7cd" translate="yes" xml:space="preserve">
          <source>Gram matrix of the input data: X.T * X</source>
          <target state="translated">Matriz de gramas de los datos de entrada:X.T*X</target>
        </trans-unit>
        <trans-unit id="a83784084519ce853a92535121a74c85019c19b0" translate="yes" xml:space="preserve">
          <source>Graph distance (e.g. nearest-neighbor graph)</source>
          <target state="translated">Gráfico de distancia (por ejemplo,el gráfico del vecino más cercano)</target>
        </trans-unit>
        <trans-unit id="8d5c9a04db77341319c1b38643f0d38066fc8710" translate="yes" xml:space="preserve">
          <source>Graph of the pixel-to-pixel connections</source>
          <target state="translated">Gráfico de las conexiones píxel a píxel</target>
        </trans-unit>
        <trans-unit id="1b6f746d097f9fe3740f364d944363a7e3d991f9" translate="yes" xml:space="preserve">
          <source>Graph of the pixel-to-pixel gradient connections</source>
          <target state="translated">Gráfico de las conexiones de gradiente píxel a píxel</target>
        </trans-unit>
        <trans-unit id="933bf21afdd55a0d2283845fed0e7bbdd1f5db49" translate="yes" xml:space="preserve">
          <source>Green</source>
          <target state="translated">Green</target>
        </trans-unit>
        <trans-unit id="9786dcbe8afbab8ac93bdfcd6653b6cd7aa7993b" translate="yes" xml:space="preserve">
          <source>Grid of Cs used for cross-validation.</source>
          <target state="translated">Cuadrícula de Cs utilizada para la validación cruzada.</target>
        </trans-unit>
        <trans-unit id="5bd85812ea7e2436359885d902fd71d10cd1c2d9" translate="yes" xml:space="preserve">
          <source>Grid of parameters with a discrete number of values for each.</source>
          <target state="translated">Cuadrícula de parámetros con un número discreto de valores para cada uno.</target>
        </trans-unit>
        <trans-unit id="4a6f9190abeab5c3ccde3d9c276bc4db019e7d38" translate="yes" xml:space="preserve">
          <source>Grid search can also be performed on the different preprocessing steps defined in the &lt;code&gt;ColumnTransformer&lt;/code&gt; object, together with the classifier&amp;rsquo;s hyperparameters as part of the &lt;code&gt;Pipeline&lt;/code&gt;. We will search for both the imputer strategy of the numeric preprocessing and the regularization parameter of the logistic regression using &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;sklearn.model_selection.GridSearchCV&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">La b&amp;uacute;squeda de cuadr&amp;iacute;cula tambi&amp;eacute;n se puede realizar en los diferentes pasos de preprocesamiento definidos en el objeto &lt;code&gt;ColumnTransformer&lt;/code&gt; , junto con los hiperpar&amp;aacute;metros del clasificador como parte de la &lt;code&gt;Pipeline&lt;/code&gt; . Buscaremos tanto la estrategia de imputaci&amp;oacute;n del preprocesamiento num&amp;eacute;rico como el par&amp;aacute;metro de regularizaci&amp;oacute;n de la regresi&amp;oacute;n log&amp;iacute;stica utilizando &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;sklearn.model_selection.GridSearchCV&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="71a1782f5aa6d2b7cc26a083f91eef66c1cf3aff" translate="yes" xml:space="preserve">
          <source>Grid-search</source>
          <target state="translated">Grid-search</target>
        </trans-unit>
        <trans-unit id="ed926e289de9aa5047e6b09f7b537df04bde4bbf" translate="yes" xml:space="preserve">
          <source>Grid-search and cross-validated estimators</source>
          <target state="translated">Búsqueda en cuadrículas y estimadores validados cruzados</target>
        </trans-unit>
        <trans-unit id="64ba146c44fdd8e95f622a314398320f76845aed" translate="yes" xml:space="preserve">
          <source>GridSearchCV implements a &amp;ldquo;fit&amp;rdquo; and a &amp;ldquo;score&amp;rdquo; method. It also implements &amp;ldquo;predict&amp;rdquo;, &amp;ldquo;predict_proba&amp;rdquo;, &amp;ldquo;decision_function&amp;rdquo;, &amp;ldquo;transform&amp;rdquo; and &amp;ldquo;inverse_transform&amp;rdquo; if they are implemented in the estimator used.</source>
          <target state="translated">GridSearchCV implementa un m&amp;eacute;todo de &quot;ajuste&quot; y &quot;puntuaci&amp;oacute;n&quot;. Tambi&amp;eacute;n implementa &amp;ldquo;predict&amp;rdquo;, &amp;ldquo;predict_proba&amp;rdquo;, &amp;ldquo;decision_function&amp;rdquo;, &amp;ldquo;transform&amp;rdquo; y &amp;ldquo;inverse_transform&amp;rdquo; si est&amp;aacute;n implementados en el estimador utilizado.</target>
        </trans-unit>
        <trans-unit id="2e6f2bdd92d1c5e33352841cf6b10ed864b19fa7" translate="yes" xml:space="preserve">
          <source>Grigorios Tsoumakas, Ioannis Katakis. Multi-Label Classification: An Overview. International Journal of Data Warehousing &amp;amp; Mining, 3(3), 1-13, July-September 2007.</source>
          <target state="translated">Grigorios Tsoumakas, Ioannis Katakis. Clasificaci&amp;oacute;n de etiquetas m&amp;uacute;ltiples: descripci&amp;oacute;n general. Revista Internacional de Almacenamiento de Datos y Miner&amp;iacute;a, 3 (3), 1-13, julio-septiembre de 2007.</target>
        </trans-unit>
        <trans-unit id="796325c68f51f69a2afcc84a9fb61fa1d8420435" translate="yes" xml:space="preserve">
          <source>Ground truth (correct) labels for n_samples samples.</source>
          <target state="translated">Etiquetas de verdad (correctas)para n_muestras de muestras.</target>
        </trans-unit>
        <trans-unit id="740dd68aa13d511b42941c79135a52aa5a0f5bc4" translate="yes" xml:space="preserve">
          <source>Ground truth (correct) labels.</source>
          <target state="translated">Etiquetas de la verdad del suelo (correcto).</target>
        </trans-unit>
        <trans-unit id="cf154969e860842a471602bf65b740057751e47b" translate="yes" xml:space="preserve">
          <source>Ground truth (correct) target values.</source>
          <target state="translated">Valores del objetivo de la verdad de la tierra (correctos).</target>
        </trans-unit>
        <trans-unit id="691f624e8ff75b4d50175631f407699ccfb7e35d" translate="yes" xml:space="preserve">
          <source>Ground truth class labels to be used as a reference</source>
          <target state="translated">Las etiquetas de clase de verdad de la tierra se usarán como referencia</target>
        </trans-unit>
        <trans-unit id="2859baca63ac3255284d20bc28f887a4c54fefb4" translate="yes" xml:space="preserve">
          <source>Group labels for the samples used while splitting the dataset into train/test set.</source>
          <target state="translated">Etiquetas de grupo para las muestras utilizadas al dividir el conjunto de datos en tren/juego de pruebas.</target>
        </trans-unit>
        <trans-unit id="f5ee660cf40b3d432d2833cbe2c4255cb71b873d" translate="yes" xml:space="preserve">
          <source>Group labels for the samples used while splitting the dataset into train/test set. This &amp;lsquo;groups&amp;rsquo; parameter must always be specified to calculate the number of splits, though the other parameters can be omitted.</source>
          <target state="translated">Agrupe las etiquetas para las muestras utilizadas al dividir el conjunto de datos en conjunto de tren / prueba. Este par&amp;aacute;metro de 'grupos' siempre debe especificarse para calcular el n&amp;uacute;mero de divisiones, aunque los dem&amp;aacute;s par&amp;aacute;metros pueden omitirse.</target>
        </trans-unit>
        <trans-unit id="2fe58cc1aca321453c1632eb3218b2ee2034ed27" translate="yes" xml:space="preserve">
          <source>Grow a tree with &lt;code&gt;max_leaf_nodes&lt;/code&gt; in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.</source>
          <target state="translated">&lt;code&gt;max_leaf_nodes&lt;/code&gt; crecer un &amp;aacute;rbol con max_leaf_nodes de la mejor manera primero. Los mejores nodos se definen como una reducci&amp;oacute;n relativa de la impureza. Si es Ninguno, entonces un n&amp;uacute;mero ilimitado de nodos hoja.</target>
        </trans-unit>
        <trans-unit id="9f319cd9d13cdc03649579ff252c6b96c720508d" translate="yes" xml:space="preserve">
          <source>Grow trees with &lt;code&gt;max_leaf_nodes&lt;/code&gt; in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.</source>
          <target state="translated">&lt;code&gt;max_leaf_nodes&lt;/code&gt; &amp;aacute;rboles con max_leaf_nodes de la mejor manera. Los mejores nodos se definen como una reducci&amp;oacute;n relativa de la impureza. Si es Ninguno, entonces un n&amp;uacute;mero ilimitado de nodos hoja.</target>
        </trans-unit>
        <trans-unit id="bf073fae640ded81eeb7a4cee70faff4a623c16c" translate="yes" xml:space="preserve">
          <source>Guide</source>
          <target state="translated">Guide</target>
        </trans-unit>
        <trans-unit id="1fd932db6b504d046b60a30c3273eb39ba2ac7a5" translate="yes" xml:space="preserve">
          <source>Guyon, I., Weston, J., Barnhill, S., &amp;amp; Vapnik, V., &amp;ldquo;Gene selection for cancer classification using support vector machines&amp;rdquo;, Mach. Learn., 46(1-3), 389&amp;ndash;422, 2002.</source>
          <target state="translated">Guyon, I., Weston, J., Barnhill, S. y Vapnik, V., &quot;Selecci&amp;oacute;n de genes para la clasificaci&amp;oacute;n del c&amp;aacute;ncer mediante m&amp;aacute;quinas de vectores de apoyo&quot;, Mach. Learn., 46 (1-3), 389&amp;ndash;422, 2002.</target>
        </trans-unit>
        <trans-unit id="dd4d457c816b0cb358c91f5b8813986bac26cb3d" translate="yes" xml:space="preserve">
          <source>H. Zhang (2004). &lt;a href=&quot;http://www.cs.unb.ca/~hzhang/publications/FLAIRS04ZhangH.pdf&quot;&gt;The optimality of Naive Bayes.&lt;/a&gt; Proc. FLAIRS.</source>
          <target state="translated">H. Zhang (2004). &lt;a href=&quot;http://www.cs.unb.ca/~hzhang/publications/FLAIRS04ZhangH.pdf&quot;&gt;La optimalidad de Naive Bayes. &lt;/a&gt;Proc. FLAIRS.</target>
        </trans-unit>
        <trans-unit id="f5b6915b0e377ea69d7b62d27d3f027cc63657d7" translate="yes" xml:space="preserve">
          <source>Hagai Attias. (2000). &amp;ldquo;A Variational Bayesian Framework for Graphical Models&amp;rdquo;. In Advances in Neural Information Processing Systems 12.</source>
          <target state="translated">Hagai Attias. (2000). &amp;ldquo;Un marco bayesiano variacional para modelos gr&amp;aacute;ficos&amp;rdquo;. Avances en los sistemas de procesamiento de informaci&amp;oacute;n neuronal 12.</target>
        </trans-unit>
        <trans-unit id="8446ed65374f4c03b547ffebe7ab69437207be78" translate="yes" xml:space="preserve">
          <source>Halkidi, Maria; Batistakis, Yannis; Vazirgiannis, Michalis (2001). &amp;ldquo;On Clustering Validation Techniques&amp;rdquo; Journal of Intelligent Information Systems, 17(2-3), 107-145. &lt;a href=&quot;http://dx.doi.org/10.1023/A:1012801612483&quot;&gt;doi:10.1023/A:1012801612483&lt;/a&gt;.</source>
          <target state="translated">Halkidi, Maria; Batistakis, Yannis; Vazirgiannis, Michalis (2001). Revista de sistemas de informaci&amp;oacute;n inteligentes sobre t&amp;eacute;cnicas de validaci&amp;oacute;n de agrupaciones, 17 (2-3), 107-145. &lt;a href=&quot;http://dx.doi.org/10.1023/A:1012801612483&quot;&gt;doi: 10.1023 / A: 1012801612483&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="57fe625410e680c160d128700bfb1af1b965809e" translate="yes" xml:space="preserve">
          <source>HammingDistance</source>
          <target state="translated">HammingDistance</target>
        </trans-unit>
        <trans-unit id="dee17735ec3038cb9f5dda5413031eefdf59071a" translate="yes" xml:space="preserve">
          <source>Handle or name of the output file. If &lt;code&gt;None&lt;/code&gt;, the result is returned as a string.</source>
          <target state="translated">Identificador o nombre del archivo de salida. Si es &lt;code&gt;None&lt;/code&gt; , el resultado se devuelve como una cadena.</target>
        </trans-unit>
        <trans-unit id="077bb86f8a4736a0992a0b108c1d4b8e9298e04f" translate="yes" xml:space="preserve">
          <source>Hard constraint to select the backend. If set to &amp;lsquo;sharedmem&amp;rsquo;, the selected backend will be single-host and thread-based even if the user asked for a non-thread based backend with parallel_backend.</source>
          <target state="translated">Restricci&amp;oacute;n dura para seleccionar el backend. Si se establece en 'sharedmem', el backend seleccionado ser&amp;aacute; de un solo host y estar&amp;aacute; basado en subprocesos incluso si el usuario solicit&amp;oacute; un backend no basado en subprocesos con paralelo_backend.</target>
        </trans-unit>
        <trans-unit id="9b9156693e970a15a3c18a9425374c7bf2903574" translate="yes" xml:space="preserve">
          <source>Hard limit on iterations within solver, or -1 for no limit.</source>
          <target state="translated">Límite duro en las iteraciones dentro del solucionador,o -1 para ningún límite.</target>
        </trans-unit>
        <trans-unit id="73dd008516fbc283773051e5943e3b658488b1b1" translate="yes" xml:space="preserve">
          <source>Harrison, D. and Rubinfeld, D.L.</source>
          <target state="translated">Harrison,D.y Rubinfeld,D.L.</target>
        </trans-unit>
        <trans-unit id="c23f4e8aad7e2235e0ebdbc3c9d2bf9b602d6e3d" translate="yes" xml:space="preserve">
          <source>Hash function g(p,x) for a tree is an array of 32 randomly generated float arrays with the same dimension as the data set. This array is stored in GaussianRandomProjectionHash object and can be obtained from &lt;code&gt;components_&lt;/code&gt; attribute.</source>
          <target state="translated">La funci&amp;oacute;n hash g (p, x) para un &amp;aacute;rbol es una matriz de 32 matrices flotantes generadas aleatoriamente con la misma dimensi&amp;oacute;n que el conjunto de datos. Esta matriz se almacena en el objeto GaussianRandomProjectionHash y se puede obtener del atributo &lt;code&gt;components_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8b5d87d4a16c0b826cb8988befd77a0e52c765c1" translate="yes" xml:space="preserve">
          <source>Hashing feature transformation using Totally Random Trees</source>
          <target state="translated">Transformación de la característica Hashing usando Árboles Totalmente Aleatorios</target>
        </trans-unit>
        <trans-unit id="717a562588a8bf4bd25fb65069c4d3192c7a16dc" translate="yes" xml:space="preserve">
          <source>HashingVectorizer does not provide IDF weighting as this is a stateless model (the fit method does nothing). When IDF weighting is needed it can be added by pipelining its output to a TfidfTransformer instance.</source>
          <target state="translated">HashingVectorizer no proporciona la ponderación de la FID,ya que se trata de un modelo sin estado (el método de ajuste no hace nada).Cuando se necesita la ponderación de la FID,se puede añadir canalizando su salida a una instancia del Transformador Tfidf.</target>
        </trans-unit>
        <trans-unit id="d06cc92706967f16b8b9c95848cf5aff7ec1c456" translate="yes" xml:space="preserve">
          <source>HashingVectorizer hashes word occurrences to a fixed dimensional space, possibly with collisions. The word count vectors are then normalized to each have l2-norm equal to one (projected to the euclidean unit-ball) which seems to be important for k-means to work in high dimensional space.</source>
          <target state="translated">HashingVectorizer envía los sucesos de las palabras a un espacio dimensional fijo,posiblemente con colisiones.Los vectores de recuento de palabras se normalizan entonces para que cada uno tenga una norma l2 igual a una (proyectada a la bola unidad euclidiana),lo que parece ser importante para que los vectores k funcionen en un espacio dimensional elevado.</target>
        </trans-unit>
        <trans-unit id="28041ffc119d6685560d28cedcd34e917cd495e5" translate="yes" xml:space="preserve">
          <source>Hastie, R. Tibshirani and J. Friedman, &amp;ldquo;Elements of Statistical Learning Ed. 2&amp;rdquo;, Springer, 2009.</source>
          <target state="translated">Hastie, R. Tibshirani y J. Friedman, &amp;ldquo;Elements of Statistical Learning Ed. 2 &amp;rdquo;, Springer, 2009.</target>
        </trans-unit>
        <trans-unit id="b8dd0d155e19e8a71f19b1bbe40cdccabf151805" translate="yes" xml:space="preserve">
          <source>Have a look at the &lt;a href=&quot;../../modules/feature_extraction#hashing-vectorizer&quot;&gt;Hashing Vectorizer&lt;/a&gt; as a memory efficient alternative to &lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Eche un vistazo al &lt;a href=&quot;../../modules/feature_extraction#hashing-vectorizer&quot;&gt;Hashing Vectorizer&lt;/a&gt; como una alternativa eficiente en memoria a &lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="a899619755f5d06da20b9b2964b88739a1ab106e" translate="yes" xml:space="preserve">
          <source>Have a look at using &lt;a href=&quot;../../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;Out-of-core Classification&lt;/a&gt; to learn from data that would not fit into the computer main memory.</source>
          <target state="translated">Eche un vistazo a la &lt;a href=&quot;../../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;clasificaci&amp;oacute;n de fuera del n&amp;uacute;cleo&lt;/a&gt; para aprender de los datos que no cabr&amp;iacute;an en la memoria principal de la computadora.</target>
        </trans-unit>
        <trans-unit id="27a688f240efc4c1f8111e73298dc1d5dd7e9964" translate="yes" xml:space="preserve">
          <source>HaversineDistance</source>
          <target state="translated">HaversineDistance</target>
        </trans-unit>
        <trans-unit id="260c7f8bcac0cff0858b268328a3c57270e6d05b" translate="yes" xml:space="preserve">
          <source>He, Kaiming, et al. &amp;ldquo;Delving deep into rectifiers: Surpassing human-level</source>
          <target state="translated">&amp;Eacute;l, Kaiming y col. &quot;Profundizando en los rectificadores: superando el nivel humano</target>
        </trans-unit>
        <trans-unit id="2f8a00b4f7c2990e23253c9271642cb45a1f2224" translate="yes" xml:space="preserve">
          <source>Helper class for readable parallel mapping.</source>
          <target state="translated">Clase de ayuda para la cartografía paralela legible.</target>
        </trans-unit>
        <trans-unit id="15e3ecfce92d858c5fac5d21e2153dba45c36e72" translate="yes" xml:space="preserve">
          <source>Helper function to test the message raised in an exception.</source>
          <target state="translated">Función de ayuda para probar el mensaje planteado en una excepción.</target>
        </trans-unit>
        <trans-unit id="e22b8152bb5ec7ad5480951d5d1692b1809abba4" translate="yes" xml:space="preserve">
          <source>Hence using random projections on the digits dataset which only has 64 features in the input space does not make sense: it does not allow for dimensionality reduction in this case.</source>
          <target state="translated">Por lo tanto,el uso de proyecciones aleatorias en el conjunto de datos de los dígitos que sólo tiene 64 características en el espacio de entrada no tiene sentido:no permite la reducción de la dimensionalidad en este caso.</target>
        </trans-unit>
        <trans-unit id="858c4ba42a503184b8af0061cb8145e1add6548c" translate="yes" xml:space="preserve">
          <source>Hence words that were not seen in the training corpus will be completely ignored in future calls to the transform method:</source>
          <target state="translated">Por lo tanto,las palabras que no se vieron en el corpus de entrenamiento serán completamente ignoradas en futuras llamadas al método de transformación:</target>
        </trans-unit>
        <trans-unit id="3fea43b2d3bbf05cef0fdbdec4ca7b01a2de9eb5" translate="yes" xml:space="preserve">
          <source>Hence, the None case results in:</source>
          <target state="translated">Por lo tanto,el caso None resulta:</target>
        </trans-unit>
        <trans-unit id="4fffc6a6ec537bad9c19e154df4fbf4c1dee1839" translate="yes" xml:space="preserve">
          <source>Here &lt;code&gt;func&lt;/code&gt; is a function which takes two one-dimensional numpy arrays, and returns a distance. Note that in order to be used within the BallTree, the distance must be a true metric: i.e. it must satisfy the following properties</source>
          <target state="translated">Aqu&amp;iacute; &lt;code&gt;func&lt;/code&gt; es una funci&amp;oacute;n que toma dos matrices num&amp;eacute;ricas unidimensionales y devuelve una distancia. Tenga en cuenta que para que se utilice dentro de BallTree, la distancia debe ser una m&amp;eacute;trica verdadera: es decir, debe satisfacer las siguientes propiedades</target>
        </trans-unit>
        <trans-unit id="8918252717f29fe05952e0490941948a7c1afcd2" translate="yes" xml:space="preserve">
          <source>Here a sine function is fit with a polynomial of order 3, for values close to zero.</source>
          <target state="translated">Aquí una función sinusoidal se ajusta con un polinomio de orden 3,para valores cercanos a cero.</target>
        </trans-unit>
        <trans-unit id="dd2684d229285b3b1a04454d9cd068cd1e054408" translate="yes" xml:space="preserve">
          <source>Here a small example demonstrating the use of the &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt;&lt;code&gt;hinge_loss&lt;/code&gt;&lt;/a&gt; function with a svm classifier in a binary class problem:</source>
          <target state="translated">Aqu&amp;iacute; un peque&amp;ntilde;o ejemplo que demuestra el uso de la funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt; &lt;code&gt;hinge_loss&lt;/code&gt; &lt;/a&gt; con un clasificador svm en un problema de clase binaria:</target>
        </trans-unit>
        <trans-unit id="5113795d86cf9b1916006aecdb0ceee73192da33" translate="yes" xml:space="preserve">
          <source>Here a small excerpt which illustrates how to use the Gaussian random projection transformer:</source>
          <target state="translated">Aquí un pequeño extracto que ilustra cómo utilizar el transformador de proyección aleatoria gaussiano:</target>
        </trans-unit>
        <trans-unit id="d838251a264bfc0a86e50e7c2f5d9ef6f54d10aa" translate="yes" xml:space="preserve">
          <source>Here a small excerpt which illustrates how to use the sparse random projection transformer:</source>
          <target state="translated">Aquí un pequeño extracto que ilustra cómo usar el transformador de proyección aleatoria dispersa:</target>
        </trans-unit>
        <trans-unit id="32f51b9dd909238771016da8eae995fa183bb752" translate="yes" xml:space="preserve">
          <source>Here are a few suggestions to help further your scikit-learn intuition upon the completion of this tutorial:</source>
          <target state="translated">Aquí hay algunas sugerencias para ayudar a fomentar su intuición de aprendizaje de la ciencia al completar este tutorial:</target>
        </trans-unit>
        <trans-unit id="8d2ed57227d29b030e11d07a6ad14619156d6baa" translate="yes" xml:space="preserve">
          <source>Here are some recommended ways to load standard columnar data into a format usable by scikit-learn:</source>
          <target state="translated">A continuación se recomiendan algunas formas de cargar los datos de las columnas estándar en un formato utilizable por scikit-learn:</target>
        </trans-unit>
        <trans-unit id="6caa2e3f5fa319efda163f3ada59f70b9af4251d" translate="yes" xml:space="preserve">
          <source>Here are some small examples in binary classification:</source>
          <target state="translated">He aquí algunos pequeños ejemplos en la clasificación binaria:</target>
        </trans-unit>
        <trans-unit id="cad58f968788a0c8b830200526f46c2e8380af6d" translate="yes" xml:space="preserve">
          <source>Here is a list of incremental estimators for different tasks:</source>
          <target state="translated">Aquí hay una lista de estimadores incrementales para diferentes tareas:</target>
        </trans-unit>
        <trans-unit id="e5cc3ef05cd44a377ff0113c5a0144a6cd05b3f4" translate="yes" xml:space="preserve">
          <source>Here is a sample output of a run on a quad-core machine:</source>
          <target state="translated">Aquí hay una muestra de una corrida en una máquina de cuatro núcleos:</target>
        </trans-unit>
        <trans-unit id="00dac27806e77f637d738445566eb627365e0881" translate="yes" xml:space="preserve">
          <source>Here is a sketch of a system designed to achieve this goal:</source>
          <target state="translated">Aquí hay un bosquejo de un sistema diseñado para lograr este objetivo:</target>
        </trans-unit>
        <trans-unit id="c595619fa24f58ee3930e8429960f874f9b329e7" translate="yes" xml:space="preserve">
          <source>Here is a small example illustrating the usage of the &lt;a href=&quot;generated/sklearn.metrics.matthews_corrcoef#sklearn.metrics.matthews_corrcoef&quot;&gt;&lt;code&gt;matthews_corrcoef&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Aqu&amp;iacute; hay un peque&amp;ntilde;o ejemplo que ilustra el uso de la funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.matthews_corrcoef#sklearn.metrics.matthews_corrcoef&quot;&gt; &lt;code&gt;matthews_corrcoef&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="423aaa3f8753fc630af578bc1fbb46728b5a06e5" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of the &lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt;&lt;code&gt;explained_variance_score&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">A continuaci&amp;oacute;n, se muestra un peque&amp;ntilde;o ejemplo del uso de la funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt; &lt;code&gt;explained_variance_score&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="cb41f576a02130e8636700bae5b58c941781076b" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of the &lt;a href=&quot;generated/sklearn.metrics.mean_absolute_error#sklearn.metrics.mean_absolute_error&quot;&gt;&lt;code&gt;mean_absolute_error&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Aqu&amp;iacute; hay un peque&amp;ntilde;o ejemplo del uso de la funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.mean_absolute_error#sklearn.metrics.mean_absolute_error&quot;&gt; &lt;code&gt;mean_absolute_error&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="7c0ba7d72bd4599fa8b6676ec86f846e3705f7da" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of the &lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt;&lt;code&gt;mean_squared_error&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Aqu&amp;iacute; hay un peque&amp;ntilde;o ejemplo del uso de la funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt; &lt;code&gt;mean_squared_error&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="0be0450f469be9534c036908ab2afdbd59b24548" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of the &lt;a href=&quot;generated/sklearn.metrics.mean_squared_log_error#sklearn.metrics.mean_squared_log_error&quot;&gt;&lt;code&gt;mean_squared_log_error&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Aqu&amp;iacute; hay un peque&amp;ntilde;o ejemplo de uso de la funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.mean_squared_log_error#sklearn.metrics.mean_squared_log_error&quot;&gt; &lt;code&gt;mean_squared_log_error&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="f8da86e09b21d704ee9aa6f7fcb4b0cf6258a18d" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of the &lt;a href=&quot;generated/sklearn.metrics.median_absolute_error#sklearn.metrics.median_absolute_error&quot;&gt;&lt;code&gt;median_absolute_error&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Aqu&amp;iacute; hay un peque&amp;ntilde;o ejemplo de uso de la funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.median_absolute_error#sklearn.metrics.median_absolute_error&quot;&gt; &lt;code&gt;median_absolute_error&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="e0060b4a19332fa9cdf176d47debc4e3de22af1f" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of the &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Aqu&amp;iacute; hay un peque&amp;ntilde;o ejemplo de uso de la funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt; &lt;code&gt;r2_score&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="2121874e07dc9ac1fb205417370f94e728d5e5e6" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of this function:</source>
          <target state="translated">Aquí hay un pequeño ejemplo del uso de esta función:</target>
        </trans-unit>
        <trans-unit id="f03ea6f9a5b7db0b84376e166dbfe9d87d690fa9" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of this function::</source>
          <target state="translated">Aquí hay un pequeño ejemplo del uso de esta función::</target>
        </trans-unit>
        <trans-unit id="da9291cb119f102218681b72119ede84a1e93115" translate="yes" xml:space="preserve">
          <source>Here is a usage example:</source>
          <target state="translated">Aquí hay un ejemplo de uso:</target>
        </trans-unit>
        <trans-unit id="ec46f6fe41e667dcb81fcf9a89e2aaf0a6763af5" translate="yes" xml:space="preserve">
          <source>Here is a visual representation of such a confusion matrix (this figure comes from the &lt;a href=&quot;../auto_examples/model_selection/plot_confusion_matrix#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py&quot;&gt;Confusion matrix&lt;/a&gt; example):</source>
          <target state="translated">Aqu&amp;iacute; hay una representaci&amp;oacute;n visual de dicha matriz de confusi&amp;oacute;n (esta figura proviene del ejemplo de la &lt;a href=&quot;../auto_examples/model_selection/plot_confusion_matrix#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py&quot;&gt;matriz de confusi&amp;oacute;n&lt;/a&gt; ):</target>
        </trans-unit>
        <trans-unit id="876abdb2188ee5022ae84c77928e2082f05a478c" translate="yes" xml:space="preserve">
          <source>Here is a visualization of the cross-validation behavior.</source>
          <target state="translated">Aquí hay una visualización del comportamiento de validación cruzada.</target>
        </trans-unit>
        <trans-unit id="d5a8fd11bd11ae3f4eb764b39ba1acfee92579af" translate="yes" xml:space="preserve">
          <source>Here is a visualization of the cross-validation behavior. Note that &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; is not affected by classes or groups.</source>
          <target state="translated">A continuaci&amp;oacute;n se muestra una visualizaci&amp;oacute;n del comportamiento de validaci&amp;oacute;n cruzada. Tenga en cuenta que &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt; no se ve afectado por clases o grupos.</target>
        </trans-unit>
        <trans-unit id="e10cd61d7e44ad9e6bb0d4cec30745248d4c4e93" translate="yes" xml:space="preserve">
          <source>Here is a visualization of the cross-validation behavior. Note that &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt;&lt;code&gt;ShuffleSplit&lt;/code&gt;&lt;/a&gt; is not affected by classes or groups.</source>
          <target state="translated">A continuaci&amp;oacute;n se muestra una visualizaci&amp;oacute;n del comportamiento de validaci&amp;oacute;n cruzada. Tenga en cuenta que &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt; &lt;code&gt;ShuffleSplit&lt;/code&gt; &lt;/a&gt; no se ve afectado por clases o grupos.</target>
        </trans-unit>
        <trans-unit id="0b166c480658b240c273df0a43ce9ffa8405561c" translate="yes" xml:space="preserve">
          <source>Here is an example demonstrating the use of the &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt;&lt;code&gt;hinge_loss&lt;/code&gt;&lt;/a&gt; function with a svm classifier in a multiclass problem:</source>
          <target state="translated">Aqu&amp;iacute; hay un ejemplo que demuestra el uso de la funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt; &lt;code&gt;hinge_loss&lt;/code&gt; &lt;/a&gt; con un clasificador svm en un problema multiclase:</target>
        </trans-unit>
        <trans-unit id="58bc8e3595ba3624485387b6def524d2d31bae65" translate="yes" xml:space="preserve">
          <source>Here is an example of &lt;code&gt;cross_validate&lt;/code&gt; using a single metric:</source>
          <target state="translated">A continuaci&amp;oacute;n, se muestra un ejemplo de &lt;code&gt;cross_validate&lt;/code&gt; con una &amp;uacute;nica m&amp;eacute;trica:</target>
        </trans-unit>
        <trans-unit id="f7e50cdf4078c7823c206e72ce0bf5486f1e2a9f" translate="yes" xml:space="preserve">
          <source>Here is an example of applying this idea to one-dimensional data, using polynomial features of varying degrees:</source>
          <target state="translated">He aquí un ejemplo de la aplicación de esta idea a datos unidimensionales,utilizando características polinómicas de diversos grados:</target>
        </trans-unit>
        <trans-unit id="8375acd14d3c16b75f14ad4cf9799bf09154cba1" translate="yes" xml:space="preserve">
          <source>Here is an example of building custom scorers, and of using the &lt;code&gt;greater_is_better&lt;/code&gt; parameter:</source>
          <target state="translated">A continuaci&amp;oacute;n, se muestra un ejemplo de &lt;code&gt;greater_is_better&lt;/code&gt; crear marcadores personalizados y de utilizar el par&amp;aacute;metro mayor_es_better :</target>
        </trans-unit>
        <trans-unit id="120ffb4ca9b2da814644df8eb634b8cef584b2a0" translate="yes" xml:space="preserve">
          <source>Here is an example to scale a toy data matrix to the &lt;code&gt;[0, 1]&lt;/code&gt; range:</source>
          <target state="translated">A continuaci&amp;oacute;n, se muestra un ejemplo para escalar una matriz de datos de juguete al rango &lt;code&gt;[0, 1]&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="8f89ae42a83e786b17cd6f1b83024799754e5687" translate="yes" xml:space="preserve">
          <source>Here is an example using &lt;code&gt;sklearn.linear_model.stochastic_gradient.SGDClassifier&lt;/code&gt; with the &lt;code&gt;elasticnet&lt;/code&gt; penalty. The regularization strength is globally controlled by the &lt;code&gt;alpha&lt;/code&gt; parameter. With a sufficiently high &lt;code&gt;alpha&lt;/code&gt;, one can then increase the &lt;code&gt;l1_ratio&lt;/code&gt; parameter of &lt;code&gt;elasticnet&lt;/code&gt; to enforce various levels of sparsity in the model coefficients. Higher sparsity here is interpreted as less model complexity as we need fewer coefficients to describe it fully. Of course sparsity influences in turn the prediction time as the sparse dot-product takes time roughly proportional to the number of non-zero coefficients.</source>
          <target state="translated">Aqu&amp;iacute; hay un ejemplo que usa &lt;code&gt;sklearn.linear_model.stochastic_gradient.SGDClassifier&lt;/code&gt; con la penalizaci&amp;oacute;n de &lt;code&gt;elasticnet&lt;/code&gt; . La intensidad de la regularizaci&amp;oacute;n est&amp;aacute; controlada globalmente por el par&amp;aacute;metro &lt;code&gt;alpha&lt;/code&gt; . Con una suficientemente alta &lt;code&gt;alpha&lt;/code&gt; , se puede entonces aumentar la &lt;code&gt;l1_ratio&lt;/code&gt; par&amp;aacute;metro de &lt;code&gt;elasticnet&lt;/code&gt; para hacer cumplir varios niveles de escasez en los coeficientes del modelo. Aqu&amp;iacute;, una mayor dispersi&amp;oacute;n se interpreta como una menor complejidad del modelo, ya que necesitamos menos coeficientes para describirlo completamente. Por supuesto, la escasez influye a su vez en el tiempo de predicci&amp;oacute;n, ya que el producto punto escaso lleva un tiempo aproximadamente proporcional al n&amp;uacute;mero de coeficientes distintos de cero.</target>
        </trans-unit>
        <trans-unit id="540ee2aaf7182c6dfc449b18e5accb694e3b0894" translate="yes" xml:space="preserve">
          <source>Here is an example:</source>
          <target state="translated">Aquí hay un ejemplo:</target>
        </trans-unit>
        <trans-unit id="a1ce1cc95adf7777aaf8483ebc72e46f7e0c5dd5" translate="yes" xml:space="preserve">
          <source>Here is how to use the toy data from the previous example with this scaler:</source>
          <target state="translated">Aquí está cómo usar los datos de los juguetes del ejemplo anterior con este escalador:</target>
        </trans-unit>
        <trans-unit id="da00252cb105e8e07c4719d8131543c2597c6b64" translate="yes" xml:space="preserve">
          <source>Here is sample code that illustrates the use of the &lt;code&gt;sparsify()&lt;/code&gt; method:</source>
          <target state="translated">Aqu&amp;iacute; hay un c&amp;oacute;digo de muestra que ilustra el uso del m&amp;eacute;todo &lt;code&gt;sparsify()&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="b1b76d97b9ed98e3661e06b53d247e6f552362c3" translate="yes" xml:space="preserve">
          <source>Here is sample code to test the sparsity of your input:</source>
          <target state="translated">Aquí está el código de muestra para probar la escasez de su entrada:</target>
        </trans-unit>
        <trans-unit id="7a4f1fdf399f62578619e41a5fba4a345597683a" translate="yes" xml:space="preserve">
          <source>Here is the list of models benefiting from the Akaike Information Criterion (AIC) or the Bayesian Information Criterion (BIC) for automated model selection:</source>
          <target state="translated">A continuación figura la lista de modelos que se benefician del Criterio de Información Akaike (AIC)o del Criterio de Información Bayesiana (BIC)para la selección automatizada de modelos:</target>
        </trans-unit>
        <trans-unit id="24d46233c5b1cf5947d798926d1e317b272fc656" translate="yes" xml:space="preserve">
          <source>Here is the list of such models:</source>
          <target state="translated">Aquí está la lista de tales modelos:</target>
        </trans-unit>
        <trans-unit id="8029b08717fd12d596415c9951c99ad442611512" translate="yes" xml:space="preserve">
          <source>Here the computation is achieved thanks to Martinsson&amp;rsquo;s Randomized SVD algorithm implemented in scikit-learn.</source>
          <target state="translated">Aqu&amp;iacute; el c&amp;aacute;lculo se logra gracias al algoritmo SVD aleatorio de Martinsson implementado en scikit-learn.</target>
        </trans-unit>
        <trans-unit id="baa6fd34087f3f3b80a068e5198c152eb2224084" translate="yes" xml:space="preserve">
          <source>Here the results are not as good as they could be as our choice for the regularization parameter C was not the best. In real life applications this parameter is usually chosen using &lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;Tuning the hyper-parameters of an estimator&lt;/a&gt;.</source>
          <target state="translated">Aqu&amp;iacute; los resultados no son tan buenos como podr&amp;iacute;an ser ya que nuestra elecci&amp;oacute;n para el par&amp;aacute;metro de regularizaci&amp;oacute;n C no fue la mejor. En aplicaciones de la vida real, este par&amp;aacute;metro generalmente se elige mediante el &lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;ajuste de los hiperpar&amp;aacute;metros de un estimador&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="e33a1b9fd8981a72cf8c17c638c489933e2535f4" translate="yes" xml:space="preserve">
          <source>Here we choose the SAGA solver because it can efficiently optimize for the Logistic Regression loss with a non-smooth, sparsity inducing l1 penalty.</source>
          <target state="translated">Aquí elegimos el solucionador SAGA porque puede optimizar eficientemente para la pérdida de la Regresión Logística con una penalización de l1 inducida por la escasez.</target>
        </trans-unit>
        <trans-unit id="d4668460d1dfffc9a12dd3f0ca645c8016c22599" translate="yes" xml:space="preserve">
          <source>Here we compare 3 approaches:</source>
          <target state="translated">Aquí comparamos 3 enfoques:</target>
        </trans-unit>
        <trans-unit id="3aadfee7aa5bef8aeacf179790398b01b017dc93" translate="yes" xml:space="preserve">
          <source>Here we describe variational inference algorithms on Dirichlet process mixture. The Dirichlet process is a prior probability distribution on &lt;em&gt;clusterings with an infinite, unbounded, number of partitions&lt;/em&gt;. Variational techniques let us incorporate this prior structure on Gaussian mixture models at almost no penalty in inference time, comparing with a finite Gaussian mixture model.</source>
          <target state="translated">Aqu&amp;iacute; describimos algoritmos de inferencia variacional en la mezcla de procesos de Dirichlet. El proceso de Dirichlet es una distribuci&amp;oacute;n de probabilidad previa en &lt;em&gt;agrupaciones con un n&amp;uacute;mero infinito e ilimitado de particiones&lt;/em&gt; . Las t&amp;eacute;cnicas de variaci&amp;oacute;n nos permiten incorporar esta estructura previa en modelos de mezcla gaussiana casi sin penalizaci&amp;oacute;n en el tiempo de inferencia, en comparaci&amp;oacute;n con un modelo de mezcla gaussiano finito.</target>
        </trans-unit>
        <trans-unit id="19eba1946aa4b2b6c504a0a7a0b9c334a19205ae" translate="yes" xml:space="preserve">
          <source>Here we fit a multinomial logistic regression with L1 penalty on a subset of the MNIST digits classification task. We use the SAGA algorithm for this purpose: this a solver that is fast when the number of samples is significantly larger than the number of features and is able to finely optimize non-smooth objective functions which is the case with the l1-penalty. Test accuracy reaches &amp;gt; 0.8, while weight vectors remains &lt;em&gt;sparse&lt;/em&gt; and therefore more easily &lt;em&gt;interpretable&lt;/em&gt;.</source>
          <target state="translated">Aqu&amp;iacute; ajustamos una regresi&amp;oacute;n log&amp;iacute;stica multinomial con penalizaci&amp;oacute;n L1 en un subconjunto de la tarea de clasificaci&amp;oacute;n de d&amp;iacute;gitos MNIST. Usamos el algoritmo SAGA para este prop&amp;oacute;sito: este es un solucionador que es r&amp;aacute;pido cuando el n&amp;uacute;mero de muestras es significativamente mayor que el n&amp;uacute;mero de caracter&amp;iacute;sticas y es capaz de optimizar con precisi&amp;oacute;n funciones objetivas que no son uniformes, como es el caso de la penalizaci&amp;oacute;n l1. La precisi&amp;oacute;n de la prueba alcanza&amp;gt; 0,8, mientras que los vectores de peso siguen siendo &lt;em&gt;escasos&lt;/em&gt; y, por lo tanto, m&amp;aacute;s f&amp;aacute;ciles de &lt;em&gt;interpretar&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="bc0bdb5bd44175832d7fcee805ba26710508e043" translate="yes" xml:space="preserve">
          <source>Here we have used &lt;code&gt;kernel='gaussian'&lt;/code&gt;, as seen above. Mathematically, a kernel is a positive function \(K(x;h)\) which is controlled by the bandwidth parameter \(h\). Given this kernel form, the density estimate at a point \(y\) within a group of points \(x_i; i=1\cdots N\) is given by:</source>
          <target state="translated">Aqu&amp;iacute; hemos usado &lt;code&gt;kernel='gaussian'&lt;/code&gt; , como se vio arriba. Matem&amp;aacute;ticamente, un n&amp;uacute;cleo es una funci&amp;oacute;n positiva \ (K (x; h) \) que est&amp;aacute; controlada por el par&amp;aacute;metro de ancho de banda \ (h \). Dada esta forma de n&amp;uacute;cleo, la estimaci&amp;oacute;n de densidad en un punto \ (y \) dentro de un grupo de puntos \ (x_i; i = 1 \ cdots N \) viene dada por:</target>
        </trans-unit>
        <trans-unit id="9bc4f467db4b070f940a4ae98fc40a9d9951075c" translate="yes" xml:space="preserve">
          <source>Here we simulate independent sources using a highly non-Gaussian process, 2 student T with a low number of degrees of freedom (top left figure). We mix them to create observations (top right figure). In this raw observation space, directions identified by PCA are represented by orange vectors. We represent the signal in the PCA space, after whitening by the variance corresponding to the PCA vectors (lower left). Running ICA corresponds to finding a rotation in this space to identify the directions of largest non-Gaussianity (lower right).</source>
          <target state="translated">Aquí simulamos fuentes independientes usando un proceso altamente no-gausiano,2 estudiantes T con un bajo número de grados de libertad (figura superior izquierda).Los mezclamos para crear observaciones (figura superior derecha).En este espacio de observación en bruto,las direcciones identificadas por PCA están representadas por vectores naranja.Representamos la señal en el espacio de PCA,después de blanquearla por la varianza correspondiente a los vectores de PCA (abajo a la izquierda).Ejecutar el PCA corresponde a encontrar una rotación en este espacio para identificar las direcciones de mayor no gaussianismo (abajo a la derecha).</target>
        </trans-unit>
        <trans-unit id="4efad2f65eb490631f07741acecbb3c6dbc45f0c" translate="yes" xml:space="preserve">
          <source>Here we use the l1 sparsity that trims the weights of not informative features to zero. This is good if the goal is to extract the strongly discriminative vocabulary of each class. If the goal is to get the best predictive accuracy, it is better to use the non sparsity-inducing l2 penalty instead.</source>
          <target state="translated">Aquí usamos la sparsidad l1 que reduce a cero los pesos de las características no informativas.Esto es bueno si el objetivo es extraer el vocabulario fuertemente discriminatorio de cada clase.Si el objetivo es obtener la mejor precisión de predicción,es mejor usar la penalización de l2 no inductora de la dispersión.</target>
        </trans-unit>
        <trans-unit id="0260adbe3be54cb933a36e08a92f87d76459f0fc" translate="yes" xml:space="preserve">
          <source>Here, \(\alpha \geq 0\) is a complexity parameter that controls the amount of shrinkage: the larger the value of \(\alpha\), the greater the amount of shrinkage and thus the coefficients become more robust to collinearity.</source>
          <target state="translated">Aquí,\ ~-es un parámetro de complejidad que controla la cantidad de la contracción:cuanto mayor sea el valor de \ ~-mayor es la cantidad de la contracción y por lo tanto los coeficientes se vuelven más robustos a la colinealidad.</target>
        </trans-unit>
        <trans-unit id="9412689bc5806775f9bf0419d0db25d5c39e9741" translate="yes" xml:space="preserve">
          <source>Here, the classifier is &lt;code&gt;fit()&lt;/code&gt; on a 2d binary label representation of &lt;code&gt;y&lt;/code&gt;, using the &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.labelbinarizer#sklearn.preprocessing.LabelBinarizer&quot;&gt;&lt;code&gt;LabelBinarizer&lt;/code&gt;&lt;/a&gt;. In this case &lt;code&gt;predict()&lt;/code&gt; returns a 2d array representing the corresponding multilabel predictions.</source>
          <target state="translated">Aqu&amp;iacute;, el clasificador se &lt;code&gt;fit()&lt;/code&gt; en una representaci&amp;oacute;n de etiqueta binaria 2d de &lt;code&gt;y&lt;/code&gt; , usando &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.labelbinarizer#sklearn.preprocessing.LabelBinarizer&quot;&gt; &lt;code&gt;LabelBinarizer&lt;/code&gt; &lt;/a&gt; . En este caso, &lt;code&gt;predict()&lt;/code&gt; devuelve una matriz 2d que representa las predicciones de m&amp;uacute;ltiples etiquetas correspondientes.</target>
        </trans-unit>
        <trans-unit id="e42ec4b790491f01a91defa6334fdc833c4f6019" translate="yes" xml:space="preserve">
          <source>Here, the default kernel &lt;code&gt;rbf&lt;/code&gt; is first changed to &lt;code&gt;linear&lt;/code&gt; via &lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC.set_params&quot;&gt;&lt;code&gt;SVC.set_params()&lt;/code&gt;&lt;/a&gt; after the estimator has been constructed, and changed back to &lt;code&gt;rbf&lt;/code&gt; to refit the estimator and to make a second prediction.</source>
          <target state="translated">Aqu&amp;iacute;, el &lt;code&gt;rbf&lt;/code&gt; del kernel predeterminado se cambia primero a &lt;code&gt;linear&lt;/code&gt; trav&amp;eacute;s de &lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC.set_params&quot;&gt; &lt;code&gt;SVC.set_params()&lt;/code&gt; &lt;/a&gt; despu&amp;eacute;s de que se ha construido el estimador, y se cambia de nuevo a &lt;code&gt;rbf&lt;/code&gt; para reajustar el estimador y hacer una segunda predicci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="379b23b33ba6458bba2f568a4c2b136ad7c827a5" translate="yes" xml:space="preserve">
          <source>Here, the first &lt;code&gt;predict()&lt;/code&gt; returns an integer array, since &lt;code&gt;iris.target&lt;/code&gt; (an integer array) was used in &lt;code&gt;fit&lt;/code&gt;. The second &lt;code&gt;predict()&lt;/code&gt; returns a string array, since &lt;code&gt;iris.target_names&lt;/code&gt; was for fitting.</source>
          <target state="translated">Aqu&amp;iacute;, el primer &lt;code&gt;predict()&lt;/code&gt; devuelve una matriz de enteros, ya que &lt;code&gt;iris.target&lt;/code&gt; (una matriz de enteros) se us&amp;oacute; en &lt;code&gt;fit&lt;/code&gt; . El segundo &lt;code&gt;predict()&lt;/code&gt; devuelve una matriz de cadenas, ya que &lt;code&gt;iris.target_names&lt;/code&gt; fue para ajustar.</target>
        </trans-unit>
        <trans-unit id="21a97ae1e0557499a4ed4420c47199de8f6f0cde" translate="yes" xml:space="preserve">
          <source>Here, the number of samples is slightly larger than the number of dimensions, thus the empirical covariance is still invertible. However, as the observations are strongly correlated, the empirical covariance matrix is ill-conditioned and as a result its inverse &amp;ndash;the empirical precision matrix&amp;ndash; is very far from the ground truth.</source>
          <target state="translated">Aqu&amp;iacute;, el n&amp;uacute;mero de muestras es ligeramente mayor que el n&amp;uacute;mero de dimensiones, por lo que la covarianza emp&amp;iacute;rica sigue siendo invertible. Sin embargo, como las observaciones est&amp;aacute;n fuertemente correlacionadas, la matriz de covarianza emp&amp;iacute;rica est&amp;aacute; mal condicionada y, como resultado, su inversa, la matriz de precisi&amp;oacute;n emp&amp;iacute;rica, est&amp;aacute; muy lejos de la verdad fundamental.</target>
        </trans-unit>
        <trans-unit id="2c6a31e993187ebfe932ff15824a46e0c83fd078" translate="yes" xml:space="preserve">
          <source>Here, the predicted class label is 2, since it has the highest average probability.</source>
          <target state="translated">Aquí,la etiqueta de clase pronosticada es 2,ya que tiene la probabilidad media más alta.</target>
        </trans-unit>
        <trans-unit id="264995c0dc7ac7309d4709ed0ce1258e4439b015" translate="yes" xml:space="preserve">
          <source>Hessian Eigenmapping (also known as Hessian-based LLE: HLLE) is another method of solving the regularization problem of LLE. It revolves around a hessian-based quadratic form at each neighborhood which is used to recover the locally linear structure. Though other implementations note its poor scaling with data size, &lt;code&gt;sklearn&lt;/code&gt; implements some algorithmic improvements which make its cost comparable to that of other LLE variants for small output dimension. HLLE can be performed with function &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt;&lt;code&gt;locally_linear_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt;&lt;code&gt;LocallyLinearEmbedding&lt;/code&gt;&lt;/a&gt;, with the keyword &lt;code&gt;method = 'hessian'&lt;/code&gt;. It requires &lt;code&gt;n_neighbors &amp;gt; n_components * (n_components + 3) / 2&lt;/code&gt;.</source>
          <target state="translated">El mapeo propio de Hessian (tambi&amp;eacute;n conocido como LLE: HLLE basado en Hessian) es otro m&amp;eacute;todo para resolver el problema de regularizaci&amp;oacute;n de LLE. Gira en torno a una forma cuadr&amp;aacute;tica basada en arpillera en cada vecindario que se utiliza para recuperar la estructura lineal local. Aunque otras implementaciones notan su escaso escalado con el tama&amp;ntilde;o de los datos, &lt;code&gt;sklearn&lt;/code&gt; implementa algunas mejoras algor&amp;iacute;tmicas que hacen que su costo sea comparable al de otras variantes de LLE para una dimensi&amp;oacute;n de salida peque&amp;ntilde;a. HLLE puede realizarse con la funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt; &lt;code&gt;locally_linear_embedding&lt;/code&gt; &lt;/a&gt; o su contraparte orientada a objetos &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt; &lt;code&gt;LocallyLinearEmbedding&lt;/code&gt; &lt;/a&gt; , con la palabra clave &lt;code&gt;method = 'hessian'&lt;/code&gt; . Requiere &lt;code&gt;n_neighbors &amp;gt; n_components * (n_components + 3) / 2&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="afac02e66e409c4004e2cc2adafb5b5e842109eb" translate="yes" xml:space="preserve">
          <source>Hierarchical agglomerative clustering: Ward</source>
          <target state="translated">Agrupación aglomerada jerárquica:Ward</target>
        </trans-unit>
        <trans-unit id="09f7d65b121068e93f6d1d655d20b242aded6b7b" translate="yes" xml:space="preserve">
          <source>Hierarchical clustering is a general family of clustering algorithms that build nested clusters by merging or splitting them successively. This hierarchy of clusters is represented as a tree (or dendrogram). The root of the tree is the unique cluster that gathers all the samples, the leaves being the clusters with only one sample. See the &lt;a href=&quot;https://en.wikipedia.org/wiki/Hierarchical_clustering&quot;&gt;Wikipedia page&lt;/a&gt; for more details.</source>
          <target state="translated">La agrupaci&amp;oacute;n en cl&amp;uacute;steres jer&amp;aacute;rquica es una familia general de algoritmos de agrupaci&amp;oacute;n en cl&amp;uacute;steres que construyen cl&amp;uacute;steres anidados fusion&amp;aacute;ndolos o dividi&amp;eacute;ndolos sucesivamente. Esta jerarqu&amp;iacute;a de grupos se representa como un &amp;aacute;rbol (o dendrograma). La ra&amp;iacute;z del &amp;aacute;rbol es el grupo &amp;uacute;nico que re&amp;uacute;ne todas las muestras, siendo las hojas los grupos con una sola muestra. Consulte la &lt;a href=&quot;https://en.wikipedia.org/wiki/Hierarchical_clustering&quot;&gt;p&amp;aacute;gina de Wikipedia&lt;/a&gt; para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="dbe40063cd6e20f1519715e45afa5ca7ed6442de" translate="yes" xml:space="preserve">
          <source>Hierarchical clustering: structured vs unstructured ward</source>
          <target state="translated">Agrupación jerárquica:sala estructurada vs.no estructurada</target>
        </trans-unit>
        <trans-unit id="645ba4388b8ba9172558b321f188082e4d2fd9ef" translate="yes" xml:space="preserve">
          <source>High-dimensional datasets can be very difficult to visualize. While data in two or three dimensions can be plotted to show the inherent structure of the data, equivalent high-dimensional plots are much less intuitive. To aid visualization of the structure of a dataset, the dimension must be reduced in some way.</source>
          <target state="translated">Los conjuntos de datos de alta dimensión pueden ser muy difíciles de visualizar.Mientras que los datos en dos o tres dimensiones pueden ser trazados para mostrar la estructura inherente de los datos,los trazados equivalentes de alta dimensión son mucho menos intuitivos.Para ayudar a la visualización de la estructura de un conjunto de datos,la dimensión debe ser reducida de alguna manera.</target>
        </trans-unit>
        <trans-unit id="75c18021e736bcb99a099c597122a642054caa8c" translate="yes" xml:space="preserve">
          <source>Hinge: (soft-margin) Support Vector Machines.</source>
          <target state="translated">Bisagra:(soft-margin)Máquinas Vectoriales de Apoyo.</target>
        </trans-unit>
        <trans-unit id="a319ae13863bb8d6da087a8b6e0305de9278e27f" translate="yes" xml:space="preserve">
          <source>Hinton, Geoffrey E.</source>
          <target state="translated">Hinton,Geoffrey E.</target>
        </trans-unit>
        <trans-unit id="b8cd925555526484cde7ba65174f600e33250f6b" translate="yes" xml:space="preserve">
          <source>Hochreiter, Bodenhofer, et. al., 2010. &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2881408/&quot;&gt;FABIA: factor analysis for bicluster acquisition&lt;/a&gt;.</source>
          <target state="translated">Hochreiter, Bodenhofer y col. al., 2010. &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2881408/&quot;&gt;FABIA: an&amp;aacute;lisis factorial para la adquisici&amp;oacute;n de bicluster&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="7a5c3ac7ac58dcde82acc59c23c0dce0d31966d1" translate="yes" xml:space="preserve">
          <source>Holds the label for each class.</source>
          <target state="translated">Lleva la etiqueta de cada clase.</target>
        </trans-unit>
        <trans-unit id="4b7dceb5fe5f7e92199815a2b66fef8fdf05dc27" translate="yes" xml:space="preserve">
          <source>Homogeneity and completeness scores are formally given by:</source>
          <target state="translated">Los puntajes de homogeneidad e integridad son formalmente dados por:</target>
        </trans-unit>
        <trans-unit id="7c13e77bc830b382c041eec0e3fcc1723f375e05" translate="yes" xml:space="preserve">
          <source>Homogeneity metric of a cluster labeling given a ground truth.</source>
          <target state="translated">La métrica de homogeneidad de la etiqueta de un cúmulo dada una verdad de la tierra.</target>
        </trans-unit>
        <trans-unit id="3afc9b67230d985e8782525c7b58b615e013e8f9" translate="yes" xml:space="preserve">
          <source>Homogeneity, completeness and V-measure can be computed at once using &lt;a href=&quot;generated/sklearn.metrics.homogeneity_completeness_v_measure#sklearn.metrics.homogeneity_completeness_v_measure&quot;&gt;&lt;code&gt;homogeneity_completeness_v_measure&lt;/code&gt;&lt;/a&gt; as follows:</source>
          <target state="translated">La homogeneidad, la completitud y la medida V se pueden calcular a la vez utilizando &lt;a href=&quot;generated/sklearn.metrics.homogeneity_completeness_v_measure#sklearn.metrics.homogeneity_completeness_v_measure&quot;&gt; &lt;code&gt;homogeneity_completeness_v_measure&lt;/code&gt; de la&lt;/a&gt; siguiente manera:</target>
        </trans-unit>
        <trans-unit id="0878824f511837fc1a1c8d27240af19053ebdbd4" translate="yes" xml:space="preserve">
          <source>HouseAge median house age in block</source>
          <target state="translated">Edad de la casa Edad media de la casa en el bloque</target>
        </trans-unit>
        <trans-unit id="be45c283b4c54643c38f84bc65a4bfc525d6d30a" translate="yes" xml:space="preserve">
          <source>How often to evaluate perplexity. Only used in &lt;code&gt;fit&lt;/code&gt; method. set it to 0 or negative number to not evalute perplexity in training at all. Evaluating perplexity can help you check convergence in training process, but it will also increase total training time. Evaluating perplexity in every iteration might increase training time up to two-fold.</source>
          <target state="translated">Con qu&amp;eacute; frecuencia evaluar la perplejidad. Solo se utiliza en el m&amp;eacute;todo de &lt;code&gt;fit&lt;/code&gt; . config&amp;uacute;relo en 0 o en un n&amp;uacute;mero negativo para no evaluar la perplejidad en el entrenamiento. La evaluaci&amp;oacute;n de la perplejidad puede ayudarlo a verificar la convergencia en el proceso de entrenamiento, pero tambi&amp;eacute;n aumentar&amp;aacute; el tiempo total de entrenamiento. Evaluar la perplejidad en cada iteraci&amp;oacute;n podr&amp;iacute;a aumentar el tiempo de entrenamiento hasta dos veces.</target>
        </trans-unit>
        <trans-unit id="060faa287065b4ad6ba6c00f598635b42adc21de" translate="yes" xml:space="preserve">
          <source>How to compute the normalizer in the denominator. Possible options are &amp;lsquo;min&amp;rsquo;, &amp;lsquo;geometric&amp;rsquo;, &amp;lsquo;arithmetic&amp;rsquo;, and &amp;lsquo;max&amp;rsquo;. If &amp;lsquo;warn&amp;rsquo;, &amp;lsquo;geometric&amp;rsquo; will be used. The default will change to &amp;lsquo;arithmetic&amp;rsquo; in version 0.22.</source>
          <target state="translated">C&amp;oacute;mo calcular el normalizador en el denominador. Las opciones posibles son 'm&amp;iacute;nimo', 'geom&amp;eacute;trico', 'aritm&amp;eacute;tico' y 'm&amp;aacute;ximo'. Si 'advertir', se utilizar&amp;aacute; 'geom&amp;eacute;trico'. El valor predeterminado cambiar&amp;aacute; a 'aritm&amp;eacute;tico' en la versi&amp;oacute;n 0.22.</target>
        </trans-unit>
        <trans-unit id="b8efa217d0db9ce56ac60653645beebe151304f9" translate="yes" xml:space="preserve">
          <source>How to compute the normalizer in the denominator. Possible options are &amp;lsquo;min&amp;rsquo;, &amp;lsquo;geometric&amp;rsquo;, &amp;lsquo;arithmetic&amp;rsquo;, and &amp;lsquo;max&amp;rsquo;. If &amp;lsquo;warn&amp;rsquo;, &amp;lsquo;max&amp;rsquo; will be used. The default will change to &amp;lsquo;arithmetic&amp;rsquo; in version 0.22.</source>
          <target state="translated">C&amp;oacute;mo calcular el normalizador en el denominador. Las opciones posibles son 'm&amp;iacute;nimo', 'geom&amp;eacute;trico', 'aritm&amp;eacute;tico' y 'm&amp;aacute;ximo'. Si 'advertir', se usar&amp;aacute; 'max'. El valor predeterminado cambiar&amp;aacute; a 'aritm&amp;eacute;tico' en la versi&amp;oacute;n 0.22.</target>
        </trans-unit>
        <trans-unit id="cf894bb3f8fceedab10cdd5da9a5edd37e00865d" translate="yes" xml:space="preserve">
          <source>How to construct the affinity matrix.</source>
          <target state="translated">Cómo construir la matriz de afinidad.</target>
        </trans-unit>
        <trans-unit id="d34268ba2716d71aaaeee2c35e527ca55a46dd2f" translate="yes" xml:space="preserve">
          <source>However ARI can also be useful in a purely unsupervised setting as a building block for a Consensus Index that can be used for clustering model selection (TODO).</source>
          <target state="translated">Sin embargo,el ARI también puede ser útil en un entorno puramente no supervisado como base para un Índice de Consenso que puede utilizarse para la selección de modelos de agrupación (TODO).</target>
        </trans-unit>
        <trans-unit id="0121c2b22395d1a9db3fd77f24d0a9f0e41170e3" translate="yes" xml:space="preserve">
          <source>However MI-based measures can also be useful in purely unsupervised setting as a building block for a Consensus Index that can be used for clustering model selection.</source>
          <target state="translated">Sin embargo,las medidas basadas en la IM también pueden ser útiles en un entorno puramente no supervisado como base para un Índice de Consenso que puede utilizarse para la selección de modelos de agrupación.</target>
        </trans-unit>
        <trans-unit id="117b6230e0e8ab3fcdc1b277507becef8a05f759" translate="yes" xml:space="preserve">
          <source>However care must taken to always make the affinity matrix symmetric so that the eigenvector decomposition works as expected.</source>
          <target state="translated">Sin embargo,hay que tener cuidado de que la matriz de afinidad sea siempre simétrica para que la descomposición de los vectores propios funcione como se espera.</target>
        </trans-unit>
        <trans-unit id="925f5b77eb2888a89c04118c35bff0f0ace7255e" translate="yes" xml:space="preserve">
          <source>However the RI score does not guarantee that random label assignments will get a value close to zero (esp. if the number of clusters is in the same order of magnitude as the number of samples).</source>
          <target state="translated">Sin embargo,la puntuación del RI no garantiza que las asignaciones aleatorias de etiquetas obtengan un valor cercano a cero (sobre todo si el número de cúmulos está en el mismo orden de magnitud que el número de muestras).</target>
        </trans-unit>
        <trans-unit id="11d179b15971b8eaae6270be9fce57c0bd0d2416" translate="yes" xml:space="preserve">
          <source>However, by partitioning the available data into three sets, we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets.</source>
          <target state="translated">Sin embargo,al dividir los datos disponibles en tres conjuntos,reducimos drásticamente el número de muestras que pueden utilizarse para el aprendizaje del modelo,y los resultados pueden depender de una elección aleatoria particular para el par de conjuntos (tren,validación).</target>
        </trans-unit>
        <trans-unit id="56c680421b5fb07e56baa9a65f13a80fce385b54" translate="yes" xml:space="preserve">
          <source>However, coefficient estimates for Ordinary Least Squares rely on the independence of the model terms. When terms are correlated and the columns of the design matrix \(X\) have an approximate linear dependence, the design matrix becomes close to singular and as a result, the least-squares estimate becomes highly sensitive to random errors in the observed response, producing a large variance. This situation of &lt;em&gt;multicollinearity&lt;/em&gt; can arise, for example, when data are collected without an experimental design.</source>
          <target state="translated">Sin embargo, las estimaciones de coeficientes para m&amp;iacute;nimos cuadrados ordinarios se basan en la independencia de los t&amp;eacute;rminos del modelo. Cuando los t&amp;eacute;rminos est&amp;aacute;n correlacionados y las columnas de la matriz de dise&amp;ntilde;o \ (X \) tienen una dependencia lineal aproximada, la matriz de dise&amp;ntilde;o se vuelve casi singular y, como resultado, la estimaci&amp;oacute;n de m&amp;iacute;nimos cuadrados se vuelve altamente sensible a errores aleatorios en la respuesta observada, produciendo una gran variaci&amp;oacute;n. Esta situaci&amp;oacute;n de &lt;em&gt;multicolinealidad&lt;/em&gt; puede surgir, por ejemplo, cuando se recopilan datos sin un dise&amp;ntilde;o experimental.</target>
        </trans-unit>
        <trans-unit id="bf734282463bfc3a9cb343729f546342ec401691" translate="yes" xml:space="preserve">
          <source>However, if the learning curve is steep for the training size in question, then 5- or 10- fold cross validation can overestimate the generalization error.</source>
          <target state="translated">Sin embargo,si la curva de aprendizaje es pronunciada para el tamaño del entrenamiento en cuestión,entonces la validación cruzada de 5 o 10 veces puede sobreestimar el error de generalización.</target>
        </trans-unit>
        <trans-unit id="fc162d85afa0b20b4064f40b16eb0e55ca89c629" translate="yes" xml:space="preserve">
          <source>However, it is sometimes helpful to plot the influence of a single hyperparameter on the training score and the validation score to find out whether the estimator is overfitting or underfitting for some hyperparameter values.</source>
          <target state="translated">Sin embargo,a veces es útil trazar la influencia de un solo hiperparámetro en la puntuación de entrenamiento y en la puntuación de validación para averiguar si el estimador se ajusta en exceso o en defecto para algunos valores de hiperparámetro.</target>
        </trans-unit>
        <trans-unit id="5c8b24673bb3f660f66f90035a856044be6d6f9e" translate="yes" xml:space="preserve">
          <source>However, note that this transformer will only do a binary one-hot encoding when feature values are of type string. If categorical features are represented as numeric values such as int, the DictVectorizer can be followed by &lt;a href=&quot;sklearn.preprocessing.onehotencoder#sklearn.preprocessing.OneHotEncoder&quot;&gt;&lt;code&gt;sklearn.preprocessing.OneHotEncoder&lt;/code&gt;&lt;/a&gt; to complete binary one-hot encoding.</source>
          <target state="translated">Sin embargo, tenga en cuenta que este transformador solo realizar&amp;aacute; una codificaci&amp;oacute;n binaria one-hot cuando los valores de las caracter&amp;iacute;sticas sean de tipo cadena. Si las caracter&amp;iacute;sticas categ&amp;oacute;ricas se representan como valores num&amp;eacute;ricos como int, el DictVectorizer puede ser seguido por &lt;a href=&quot;sklearn.preprocessing.onehotencoder#sklearn.preprocessing.OneHotEncoder&quot;&gt; &lt;code&gt;sklearn.preprocessing.OneHotEncoder&lt;/code&gt; &lt;/a&gt; para completar la codificaci&amp;oacute;n binaria one-hot.</target>
        </trans-unit>
        <trans-unit id="8b25d9ad009118aef0894664f601ac10786f8b49" translate="yes" xml:space="preserve">
          <source>However, this is not the most precise way of doing this computation, and the distance matrix returned by this function may not be exactly symmetric as required by, e.g., &lt;code&gt;scipy.spatial.distance&lt;/code&gt; functions.</source>
          <target state="translated">Sin embargo, esta no es la forma m&amp;aacute;s precisa de hacer este c&amp;aacute;lculo, y la matriz de distancia devuelta por esta funci&amp;oacute;n puede no ser exactamente sim&amp;eacute;trica como lo requieren, por ejemplo, &lt;code&gt;scipy.spatial.distance&lt;/code&gt; funciones scipy.spatial.distance .</target>
        </trans-unit>
        <trans-unit id="379cfb166aa26713fe1131478e9b37a4224780ad" translate="yes" xml:space="preserve">
          <source>Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent</source>
          <target state="translated">Hsiang-Fu Yu,Fang-Lan Huang,Chih-Jen Lin (2011).Descenso de doble coordenada</target>
        </trans-unit>
        <trans-unit id="15d1d4b26d2ba06629e368bf6c8a860d8762ef89" translate="yes" xml:space="preserve">
          <source>Huber (&lt;code&gt;'huber'&lt;/code&gt;): Another robust loss function that combines least squares and least absolute deviation; use &lt;code&gt;alpha&lt;/code&gt; to control the sensitivity with regards to outliers (see &lt;a href=&quot;#f2001&quot; id=&quot;id15&quot;&gt;[F2001]&lt;/a&gt; for more details).</source>
          <target state="translated">Huber ( &lt;code&gt;'huber'&lt;/code&gt; ): Otra funci&amp;oacute;n de p&amp;eacute;rdida robusta que combina m&amp;iacute;nimos cuadrados y m&amp;iacute;nima desviaci&amp;oacute;n absoluta; utilice &lt;code&gt;alpha&lt;/code&gt; para controlar la sensibilidad con respecto a los valores at&amp;iacute;picos (consulte &lt;a href=&quot;#f2001&quot; id=&quot;id15&quot;&gt;[F2001]&lt;/a&gt; para obtener m&amp;aacute;s detalles).</target>
        </trans-unit>
        <trans-unit id="3d12d436101cbc3212af50bf81000f6d78d4cf01" translate="yes" xml:space="preserve">
          <source>HuberRegressor vs Ridge on dataset with strong outliers</source>
          <target state="translated">HuberRegressor vs Ridge en un conjunto de datos con fuertes valores atípicos</target>
        </trans-unit>
        <trans-unit id="7e58a6e8d89e8504ad31e135de9b485ad40f05f6" translate="yes" xml:space="preserve">
          <source>Hue</source>
          <target state="translated">Hue</target>
        </trans-unit>
        <trans-unit id="c7a8b2b20a9c45f674f17cd8ef7ece305e1c36eb" translate="yes" xml:space="preserve">
          <source>Hue:</source>
          <target state="translated">Hue:</target>
        </trans-unit>
        <trans-unit id="4e99bcdee413a9c98d317e0e8e4199a2bf582f90" translate="yes" xml:space="preserve">
          <source>Hugo Chavez</source>
          <target state="translated">Hugo Chávez</target>
        </trans-unit>
        <trans-unit id="135e7e12c7ab5ea7496649e72ee134478ecf558e" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the alpha parameter. Default is 1.e-6.</source>
          <target state="translated">Hiperparámetro:parámetro de escala inversa (parámetro de tasa)para la distribución Gamma anterior al parámetro alfa.El valor por defecto es 1.e-6.</target>
        </trans-unit>
        <trans-unit id="761054fe5bafcad49a16f057764235860452b8da" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the lambda parameter. Default is 1.e-6</source>
          <target state="translated">Hiperparámetro:parámetro de escala inversa (parámetro de tasa)para la distribución Gamma anterior al parámetro lambda.El valor por defecto es 1.e-6</target>
        </trans-unit>
        <trans-unit id="6001ea6392d3003569381e7107254e88f75fd600" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the lambda parameter. Default is 1.e-6.</source>
          <target state="translated">Hiperparámetro:parámetro de escala inversa (parámetro de tasa)para la distribución Gamma anterior al parámetro lambda.El valor por defecto es 1.e-6.</target>
        </trans-unit>
        <trans-unit id="81e171654bf22a490946ec147c219e96694497ff" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : shape parameter for the Gamma distribution prior over the alpha parameter. Default is 1.e-6</source>
          <target state="translated">Hiperparámetro:parámetro de forma para la distribución Gamma anterior al parámetro alfa.El valor por defecto es 1.e-6</target>
        </trans-unit>
        <trans-unit id="b07af48fd68aeaacb4df041ef30bae006150c237" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : shape parameter for the Gamma distribution prior over the alpha parameter. Default is 1.e-6.</source>
          <target state="translated">Hiperparámetro:parámetro de forma para la distribución Gamma anterior al parámetro alfa.El valor por defecto es 1.e-6.</target>
        </trans-unit>
        <trans-unit id="1398aea0b1e181e76b6d9d73db4040ccf06ee2f7" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : shape parameter for the Gamma distribution prior over the lambda parameter. Default is 1.e-6.</source>
          <target state="translated">Hiperparámetro:parámetro de forma para la distribución Gamma anterior al parámetro lambda.El valor por defecto es 1.e-6.</target>
        </trans-unit>
        <trans-unit id="7a5b8a439bb2492412d2944256add4dcdf337928" translate="yes" xml:space="preserve">
          <source>Hyper-parameter optimizers</source>
          <target state="translated">Optimizadores de hiperparámetros</target>
        </trans-unit>
        <trans-unit id="223bf115da53d3d9cdf837b624135b565596fd92" translate="yes" xml:space="preserve">
          <source>Hyper-parameters are parameters that are not directly learnt within estimators. In scikit-learn they are passed as arguments to the constructor of the estimator classes. Typical examples include &lt;code&gt;C&lt;/code&gt;, &lt;code&gt;kernel&lt;/code&gt; and &lt;code&gt;gamma&lt;/code&gt; for Support Vector Classifier, &lt;code&gt;alpha&lt;/code&gt; for Lasso, etc.</source>
          <target state="translated">Los hiperpar&amp;aacute;metros son par&amp;aacute;metros que no se aprenden directamente dentro de los estimadores. En scikit-learn, se pasan como argumentos al constructor de las clases de estimador. Los ejemplos t&amp;iacute;picos incluyen &lt;code&gt;C&lt;/code&gt; , &lt;code&gt;kernel&lt;/code&gt; y &lt;code&gt;gamma&lt;/code&gt; para Support Vector Classifier, &lt;code&gt;alpha&lt;/code&gt; para Lasso, etc.</target>
        </trans-unit>
        <trans-unit id="568b05951392672a52de0358537dd29fcafbe544" translate="yes" xml:space="preserve">
          <source>Hyper-parameters of an estimator can be updated after it has been constructed via the &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-set-params&quot;&gt;set_params()&lt;/a&gt; method. Calling &lt;code&gt;fit()&lt;/code&gt; more than once will overwrite what was learned by any previous &lt;code&gt;fit()&lt;/code&gt;:</source>
          <target state="translated">Los hiperpar&amp;aacute;metros de un estimador se pueden actualizar despu&amp;eacute;s de que se haya construido mediante el m&amp;eacute;todo &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-set-params&quot;&gt;set_params ()&lt;/a&gt; . Llamar a &lt;code&gt;fit()&lt;/code&gt; m&amp;aacute;s de una vez sobrescribir&amp;aacute; lo aprendido por cualquier &lt;code&gt;fit()&lt;/code&gt; previo () :</target>
        </trans-unit>
        <trans-unit id="1db8c072507305b4aa23189287be39423349b8f4" translate="yes" xml:space="preserve">
          <source>Hyperparameter of the ridge regression that learns the inverse transform (when fit_inverse_transform=True).</source>
          <target state="translated">Hiperparámetro de la regresión de la cresta que aprende la transformación inversa (cuando fit_inverse_transform=True).</target>
        </trans-unit>
        <trans-unit id="181eca8daf7aaeed93f61701c7eddb643dc6b36a" translate="yes" xml:space="preserve">
          <source>Hyperparameters:</source>
          <target state="translated">Hyperparameters:</target>
        </trans-unit>
        <trans-unit id="8bb86931be2a9d0449c3eec151da751cb88591f1" translate="yes" xml:space="preserve">
          <source>I. Guyon, &amp;ldquo;Design of experiments for the NIPS 2003 variable selection benchmark&amp;rdquo;, 2003.</source>
          <target state="translated">I. Guyon, &amp;ldquo;Dise&amp;ntilde;o de experimentos para el benchmark de selecci&amp;oacute;n de variables NIPS 2003&amp;rdquo;, 2003.</target>
        </trans-unit>
        <trans-unit id="a238a89365b9d0ce7f5fb26e189eb03cdc08fbe5" translate="yes" xml:space="preserve">
          <source>ICA can also be used as yet another non linear decomposition that finds components with some sparsity:</source>
          <target state="translated">El ICA también puede ser usado como otra descomposición no lineal que encuentra componentes con cierta escasez:</target>
        </trans-unit>
        <trans-unit id="fcc34dd193c826ae2f0c8b804c532252b4a25480" translate="yes" xml:space="preserve">
          <source>INDUS proportion of non-retail business acres per town</source>
          <target state="translated">INDUS proporción de acres de negocios no minoristas por ciudad</target>
        </trans-unit>
        <trans-unit id="44a4d7b7db7815be999da6a406f4dadd2c4327c5" translate="yes" xml:space="preserve">
          <source>Identification number of each sample, as ordered in dataset.data.</source>
          <target state="translated">Número de identificación de cada muestra,como se ordena en dataset.data.</target>
        </trans-unit>
        <trans-unit id="02d51b4f13558cbcfc807b53522b1ffb156ad7e7" translate="yes" xml:space="preserve">
          <source>Identity: d(x, y) = 0 if and only if x == y</source>
          <target state="translated">Identidad:d(x,y)=0 si y sólo si x ==y</target>
        </trans-unit>
        <trans-unit id="35bd2069c37f2c6a308bc5401948b247d5bcfc02" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;all&amp;rdquo;, the imputer mask will represent all features.</source>
          <target state="translated">Si es &quot;todos&quot;, la m&amp;aacute;scara de imputador representar&amp;aacute; todas las caracter&amp;iacute;sticas.</target>
        </trans-unit>
        <trans-unit id="84934b5d658c0a370c458ee55fa3255bb65884a6" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;auto&amp;rdquo; (default), the imputer mask will be of same type as input.</source>
          <target state="translated">Si es &quot;autom&amp;aacute;tico&quot; (predeterminado), la m&amp;aacute;scara de imputador ser&amp;aacute; del mismo tipo que la entrada.</target>
        </trans-unit>
        <trans-unit id="7cdc1bc49e801caf1ff212e1000d88bb13d7e93e" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;auto&amp;rdquo;, then &lt;code&gt;max_features=n_features&lt;/code&gt;.</source>
          <target state="translated">Si es &quot;auto&quot;, entonces &lt;code&gt;max_features=n_features&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="164a2722286c1b34bc2df80a90c75397afce3e6b" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;auto&amp;rdquo;, then &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt;.</source>
          <target state="translated">Si es &quot;auto&quot;, entonces &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="911a50d98b398312fa01572b5d7b864da542117b" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;auto&amp;rdquo;, then &lt;code&gt;max_samples=min(256, n_samples)&lt;/code&gt;.</source>
          <target state="translated">Si es &quot;autom&amp;aacute;tico&quot;, entonces &lt;code&gt;max_samples=min(256, n_samples)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="dca169b413a6ec050ae0928eb38f43b00b9c08e0" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;constant&amp;rdquo;, then replace missing values with fill_value. Can be used with strings or numeric data.</source>
          <target state="translated">Si es &quot;constante&quot;, reemplace los valores faltantes con fill_value. Se puede usar con cadenas o datos num&amp;eacute;ricos.</target>
        </trans-unit>
        <trans-unit id="fed653e1ff76c14b62a8cb9c0f4474c620b2641e" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;log2&amp;rdquo;, then &lt;code&gt;max_features=log2(n_features)&lt;/code&gt;.</source>
          <target state="translated">Si es &quot;log2&quot;, entonces &lt;code&gt;max_features=log2(n_features)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e799052bdd1932be1b28378fc91f87421f6d1065" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;mean&amp;rdquo;, then replace missing values using the mean along each column. Can only be used with numeric data.</source>
          <target state="translated">Si es &quot;media&quot;, reemplace los valores faltantes utilizando la media de cada columna. Solo se puede utilizar con datos num&amp;eacute;ricos.</target>
        </trans-unit>
        <trans-unit id="8c28cbae695709f5ae6daaba6d2035fa26d4e040" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;mean&amp;rdquo;, then replace missing values using the mean along the axis.</source>
          <target state="translated">Si es &quot;media&quot;, reemplace los valores faltantes utilizando la media a lo largo del eje.</target>
        </trans-unit>
        <trans-unit id="d5353b7f39f25231d62cbbc36fcd604e05d2faa0" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;median&amp;rdquo;, then replace missing values using the median along each column. Can only be used with numeric data.</source>
          <target state="translated">Si es &quot;mediana&quot;, reemplace los valores faltantes utilizando la mediana a lo largo de cada columna. Solo se puede utilizar con datos num&amp;eacute;ricos.</target>
        </trans-unit>
        <trans-unit id="2c7bf0a70af62c9d1ff80c38810d3732da415b46" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;median&amp;rdquo;, then replace missing values using the median along the axis.</source>
          <target state="translated">Si es &quot;mediana&quot;, reemplace los valores faltantes utilizando la mediana a lo largo del eje.</target>
        </trans-unit>
        <trans-unit id="b9dfb246debbef95e2bc6e78da2b0aca54b8e768" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;missing-only&amp;rdquo; (default), the imputer mask will only represent features containing missing values during fit time.</source>
          <target state="translated">Si es &quot;solo faltante&quot; (predeterminado), la m&amp;aacute;scara de imputador solo representar&amp;aacute; entidades que contengan valores perdidos durante el tiempo de ajuste.</target>
        </trans-unit>
        <trans-unit id="fb9cd590a090a11e857ebbc7c5d49f19787d4a57" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;most_frequent&amp;rdquo;, then replace missing using the most frequent value along each column. Can be used with strings or numeric data.</source>
          <target state="translated">Si es &quot;most_frequent&quot;, reemplace los que faltan usando el valor m&amp;aacute;s frecuente en cada columna. Se puede usar con cadenas o datos num&amp;eacute;ricos.</target>
        </trans-unit>
        <trans-unit id="a90ab2bff0e7c4a2db0c7d70bcb17fa44e1b8cb3" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;most_frequent&amp;rdquo;, then replace missing using the most frequent value along the axis.</source>
          <target state="translated">Si es &quot;most_frequent&quot;, reemplace lo que falta usando el valor m&amp;aacute;s frecuente a lo largo del eje.</target>
        </trans-unit>
        <trans-unit id="d25972b438acba3aa495003bff5b880c3dc78f95" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;prefit&amp;rdquo; is passed, it is assumed that base_estimator has been fitted already and all data is used for calibration.</source>
          <target state="translated">Si se pasa &quot;prefit&quot;, se supone que base_estimator ya se ha instalado y todos los datos se utilizan para la calibraci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="ddc01f2adfc0b5da49bb0bea104c04055f37082b" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;sqrt&amp;rdquo;, then &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt; (same as &amp;ldquo;auto&amp;rdquo;).</source>
          <target state="translated">Si es &quot;sqrt&quot;, entonces &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt; (igual que &quot;auto&quot;).</target>
        </trans-unit>
        <trans-unit id="050de520f25e08567f8dcb7bcdaa6887bd8ca53c" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;sqrt&amp;rdquo;, then &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt;.</source>
          <target state="translated">Si es &quot;sqrt&quot;, entonces &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="274dd12ab1d70a7a9d00df8bbe2aa7f35f2ca3c4" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;SAMME.R&amp;rsquo; then use the SAMME.R real boosting algorithm. &lt;code&gt;base_estimator&lt;/code&gt; must support calculation of class probabilities. If &amp;lsquo;SAMME&amp;rsquo; then use the SAMME discrete boosting algorithm. The SAMME.R algorithm typically converges faster than SAMME, achieving a lower test error with fewer boosting iterations.</source>
          <target state="translated">Si es 'SAMME.R', utilice el algoritmo de refuerzo real de SAMME.R. &lt;code&gt;base_estimator&lt;/code&gt; debe soportar el c&amp;aacute;lculo de probabilidades de clase. Si es 'SAMME', utilice el algoritmo de refuerzo discreto de SAMME. El algoritmo SAMME.R generalmente converge m&amp;aacute;s r&amp;aacute;pido que SAMME, logrando un error de prueba menor con menos iteraciones de impulso.</target>
        </trans-unit>
        <trans-unit id="7bac8214432dad215f7331c0af16dfd3868b9e19" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;balanced&amp;rsquo;, class weights will be given by &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;. If a dictionary is given, keys are classes and values are corresponding class weights. If None is given, the class weights will be uniform.</source>
          <target state="translated">Si est&amp;aacute; 'equilibrado', las ponderaciones de clase vendr&amp;aacute;n dadas por &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt; . Si se proporciona un diccionario, las claves son clases y los valores son pesos de clase correspondientes. Si se da Ninguno, los pesos de la clase ser&amp;aacute;n uniformes.</target>
        </trans-unit>
        <trans-unit id="456401c87cfc2a15cdd408f2dd8be315dc3e833e" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;english&amp;rsquo;, a built-in stop word list for English is used. There are several known issues with &amp;lsquo;english&amp;rsquo; and you should consider an alternative (see &lt;a href=&quot;../feature_extraction#stop-words&quot;&gt;Using stop words&lt;/a&gt;).</source>
          <target state="translated">Si es 'ingl&amp;eacute;s', se utiliza una lista de palabras de detenci&amp;oacute;n incorporada para ingl&amp;eacute;s. Hay varios problemas conocidos con 'ingl&amp;eacute;s' y deber&amp;iacute;a considerar una alternativa (consulte &lt;a href=&quot;../feature_extraction#stop-words&quot;&gt;Uso de palabras vac&amp;iacute;as&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="f2019bdbdfa8956b7b54e8a5677954f4996f6374" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;file&amp;rsquo;, the sequence items must have a &amp;lsquo;read&amp;rsquo; method (file-like object) that is called to fetch the bytes in memory.</source>
          <target state="translated">Si es 'archivo', los elementos de secuencia deben tener un m&amp;eacute;todo de 'lectura' (objeto similar a un archivo) que se llama para obtener los bytes en la memoria.</target>
        </trans-unit>
        <trans-unit id="3dd1f3ca74314afe1ddf15184f6ab04977d1a20b" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;filename&amp;rsquo;, the sequence passed as an argument to fit is expected to be a list of filenames that need reading to fetch the raw content to analyze.</source>
          <target state="translated">Si es 'nombre de archivo', se espera que la secuencia pasada como argumento para encajar sea una lista de nombres de archivo que necesitan lectura para obtener el contenido sin procesar para analizar.</target>
        </trans-unit>
        <trans-unit id="6381402e5f026c95872c614d3f284a846d432d3e" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;hard&amp;rsquo;, uses predicted class labels for majority rule voting. Else if &amp;lsquo;soft&amp;rsquo;, predicts the class label based on the argmax of the sums of the predicted probabilities, which is recommended for an ensemble of well-calibrated classifiers.</source>
          <target state="translated">Si es &quot;dif&amp;iacute;cil&quot;, utiliza etiquetas de clase previstas para la votaci&amp;oacute;n de la regla de la mayor&amp;iacute;a. De lo contrario, si es 'suave', predice la etiqueta de clase basada en el argmax de las sumas de las probabilidades predichas, lo que se recomienda para un conjunto de clasificadores bien calibrados.</target>
        </trans-unit>
        <trans-unit id="034a602ff18129b75a77961464f62c916fb178cb" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;precomputed&amp;rsquo;, the training input X is expected to be a distance matrix.</source>
          <target state="translated">Si se 'calcula previamente', se espera que la entrada de entrenamiento X sea una matriz de distancia.</target>
        </trans-unit>
        <trans-unit id="efe2693abb0ad6fb0bb32fc7410403c6f8a6131c" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;warm_start&amp;rsquo; is True, the solution of the last fitting is used as initialization for the next call of fit(). This can speed up convergence when fit is called several times on similar problems. In that case, &amp;lsquo;n_init&amp;rsquo; is ignored and only a single initialization occurs upon the first call. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Si 'warm_start' es True, la soluci&amp;oacute;n del &amp;uacute;ltimo ajuste se usa como inicializaci&amp;oacute;n para la siguiente llamada de fit (). Esto puede acelerar la convergencia cuando se llama al ajuste varias veces en problemas similares. En ese caso, se ignora 'n_init' y solo se produce una inicializaci&amp;oacute;n en la primera llamada. Consulte &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;el glosario&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="245f671779646599b33075b7dcf37bf735b34555" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;warm_start&amp;rsquo; is True, the solution of the last fitting is used as initialization for the next call of fit(). This can speed up convergence when fit is called several times on similar problems. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Si 'warm_start' es True, la soluci&amp;oacute;n del &amp;uacute;ltimo ajuste se usa como inicializaci&amp;oacute;n para la siguiente llamada de fit (). Esto puede acelerar la convergencia cuando se llama al ajuste varias veces en problemas similares. Consulte &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;el glosario&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="e311856e2dbc16a358c30263eb21c62e3f976c09" translate="yes" xml:space="preserve">
          <source>If &lt;a href=&quot;generated/sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt;&lt;code&gt;MinMaxScaler&lt;/code&gt;&lt;/a&gt; is given an explicit &lt;code&gt;feature_range=(min, max)&lt;/code&gt; the full formula is:</source>
          <target state="translated">Si a &lt;a href=&quot;generated/sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt; &lt;code&gt;MinMaxScaler&lt;/code&gt; &lt;/a&gt; se le da un &lt;code&gt;feature_range=(min, max)&lt;/code&gt; expl&amp;iacute;cito = (min, max), la f&amp;oacute;rmula completa es:</target>
        </trans-unit>
        <trans-unit id="6f352ac5787c6e0994736f1793f840aefef2eb74" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;0 &amp;lt; n_components &amp;lt; 1&lt;/code&gt; and &lt;code&gt;svd_solver == 'full'&lt;/code&gt;, select the number of components such that the amount of variance that needs to be explained is greater than the percentage specified by n_components.</source>
          <target state="translated">Si &lt;code&gt;0 &amp;lt; n_components &amp;lt; 1&lt;/code&gt; y &lt;code&gt;svd_solver == 'full'&lt;/code&gt; , seleccione el n&amp;uacute;mero de componentes de modo que la cantidad de variaci&amp;oacute;n que deba explicarse sea mayor que el porcentaje especificado por n_components.</target>
        </trans-unit>
        <trans-unit id="6154e481a1bfebf053da4021c41ed6b15075ac75" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, &lt;code&gt;Gram&lt;/code&gt; is overwritten.</source>
          <target state="translated">Si es &lt;code&gt;False&lt;/code&gt; , se sobrescribe &lt;code&gt;Gram&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c8ea59a59509714d84c6c3be2a8959e87ca2c339" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, &lt;code&gt;X&lt;/code&gt; is overwritten.</source>
          <target state="translated">Si es &lt;code&gt;False&lt;/code&gt; , se sobrescribe &lt;code&gt;X&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ecd953eee019b7cf39fa95c1745e9486ce5fb903" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, return the number of correctly classified samples. Otherwise, return the fraction of correctly classified samples.</source>
          <target state="translated">Si es &lt;code&gt;False&lt;/code&gt; , devuelva el n&amp;uacute;mero de muestras clasificadas correctamente. De lo contrario, devuelva la fracci&amp;oacute;n de muestras correctamente clasificadas.</target>
        </trans-unit>
        <trans-unit id="8dd52da2b8b6d856acbbc6b969b86fd0a4246941" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, return the number of misclassifications. Otherwise, return the fraction of misclassifications.</source>
          <target state="translated">Si es &lt;code&gt;False&lt;/code&gt; , devuelva el n&amp;uacute;mero de clasificaciones err&amp;oacute;neas. De lo contrario, devuelva la fracci&amp;oacute;n de clasificaciones err&amp;oacute;neas.</target>
        </trans-unit>
        <trans-unit id="85fcfc531652a8814592a07e791b2030fbc9598e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, return the sum of the Jaccard similarity coefficient over the sample set. Otherwise, return the average of Jaccard similarity coefficient.</source>
          <target state="translated">Si es &lt;code&gt;False&lt;/code&gt; , devuelve la suma del coeficiente de similitud de Jaccard sobre el conjunto de muestra. De lo contrario, devuelva el promedio del coeficiente de similitud de Jaccard.</target>
        </trans-unit>
        <trans-unit id="c21045a17e85201e2f77134fc96d9edd698a8ef9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, the &lt;code&gt;cv_results_&lt;/code&gt; attribute will not include training scores.</source>
          <target state="translated">Si es &lt;code&gt;False&lt;/code&gt; , el atributo &lt;code&gt;cv_results_&lt;/code&gt; no incluir&amp;aacute; las puntuaciones de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="4f7a2b9af6d7b5ad533a302e51ca948f564886c6" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;None&lt;/code&gt; the estimator&amp;rsquo;s default scorer is used.</source>
          <target state="translated">Si es &lt;code&gt;None&lt;/code&gt; , se utiliza el puntaje predeterminado del estimador.</target>
        </trans-unit>
        <trans-unit id="0206caad9c301767e28c1eb37b72a3a7f7598e94" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;None&lt;/code&gt;, the scores for each class are returned. Otherwise, this determines the type of averaging performed on the data:</source>
          <target state="translated">Si es &lt;code&gt;None&lt;/code&gt; , se devuelven las puntuaciones de cada clase. De lo contrario, esto determina el tipo de promediado realizado en los datos:</target>
        </trans-unit>
        <trans-unit id="f1170dbf5a5618e80add067200212cb5804a58cd" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt; the full path is stored in the &lt;code&gt;coef_path_&lt;/code&gt; attribute. If you compute the solution for a large problem or many targets, setting &lt;code&gt;fit_path&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt; will lead to a speedup, especially with a small alpha.</source>
          <target state="translated">Si es &lt;code&gt;True&lt;/code&gt; , la ruta completa se almacena en el atributo &lt;code&gt;coef_path_&lt;/code&gt; . Si calcula la soluci&amp;oacute;n para un problema grande o muchos objetivos, establecer &lt;code&gt;fit_path&lt;/code&gt; en &lt;code&gt;False&lt;/code&gt; conducir&amp;aacute; a una aceleraci&amp;oacute;n, especialmente con un alfa peque&amp;ntilde;o.</target>
        </trans-unit>
        <trans-unit id="e703de20e5680ee264e2b1b950a8b1ca587cd24f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, X will be copied; else, it may be overwritten.</source>
          <target state="translated">Si es &lt;code&gt;True&lt;/code&gt; , se copiar&amp;aacute; X; de lo contrario, puede sobrescribirse.</target>
        </trans-unit>
        <trans-unit id="8e26b0bb501133486ba99496e311f44a49ce472b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, perform metric MDS; otherwise, perform nonmetric MDS.</source>
          <target state="translated">Si es &lt;code&gt;True&lt;/code&gt; , realice MDS m&amp;eacute;tricas; de lo contrario, realice MDS no m&amp;eacute;tricas.</target>
        </trans-unit>
        <trans-unit id="a2b129bca8e38a348fd53d1896c7796acded2f57" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, return a sparse feature matrix</source>
          <target state="translated">Si es &lt;code&gt;True&lt;/code&gt; , devuelve una matriz de caracter&amp;iacute;sticas dispersas</target>
        </trans-unit>
        <trans-unit id="887d26ef7077238a636d223d3985225a211c8d82" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, return the prior class probability and conditional probabilities of features given classes, from which the data was drawn.</source>
          <target state="translated">Si es &lt;code&gt;True&lt;/code&gt; , devuelve la probabilidad de clase anterior y las probabilidades condicionales de las caracter&amp;iacute;sticas de clases determinadas, de las que se extrajeron los datos.</target>
        </trans-unit>
        <trans-unit id="0b7bef40bad08d9d2c4e67da6c9b56ea79751005" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, some instances might not belong to any class.</source>
          <target state="translated">Si es &lt;code&gt;True&lt;/code&gt; , es posible que algunas instancias no pertenezcan a ninguna clase.</target>
        </trans-unit>
        <trans-unit id="e223ba26a8622e808f0df02e86007844177282d6" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;algorithm=&amp;rsquo;lasso_lars&amp;rsquo;&lt;/code&gt; or &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt;, &lt;code&gt;alpha&lt;/code&gt; is the penalty applied to the L1 norm. If &lt;code&gt;algorithm=&amp;rsquo;threshold&amp;rsquo;&lt;/code&gt;, &lt;code&gt;alpha&lt;/code&gt; is the absolute value of the threshold below which coefficients will be squashed to zero. If &lt;code&gt;algorithm=&amp;rsquo;omp&amp;rsquo;&lt;/code&gt;, &lt;code&gt;alpha&lt;/code&gt; is the tolerance parameter: the value of the reconstruction error targeted. In this case, it overrides &lt;code&gt;n_nonzero_coefs&lt;/code&gt;.</source>
          <target state="translated">Si &lt;code&gt;algorithm=&amp;rsquo;lasso_lars&amp;rsquo;&lt;/code&gt; o &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt; , &lt;code&gt;alpha&lt;/code&gt; es la penalizaci&amp;oacute;n aplicada a la norma L1. Si &lt;code&gt;algorithm=&amp;rsquo;threshold&amp;rsquo;&lt;/code&gt; , &lt;code&gt;alpha&lt;/code&gt; es el valor absoluto del umbral por debajo del cual los coeficientes se reducir&amp;aacute;n a cero. Si &lt;code&gt;algorithm=&amp;rsquo;omp&amp;rsquo;&lt;/code&gt; , &lt;code&gt;alpha&lt;/code&gt; es el par&amp;aacute;metro de tolerancia: el valor del error de reconstrucci&amp;oacute;n objetivo. En este caso, anula &lt;code&gt;n_nonzero_coefs&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a88caf8f6b6232395c9c1524315c6ed672bcf763" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=0&lt;/code&gt; and X is encoded as a CSR matrix;</source>
          <target state="translated">Si &lt;code&gt;axis=0&lt;/code&gt; y X se codifica como una matriz CSR;</target>
        </trans-unit>
        <trans-unit id="b74f02ef0c3e3aceaf2040e39764c8bf5d153fee" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=0&lt;/code&gt;, then impute along columns.</source>
          <target state="translated">Si &lt;code&gt;axis=0&lt;/code&gt; , impute a lo largo de las columnas.</target>
        </trans-unit>
        <trans-unit id="231cba4e2ed9eee1fca5c3a6b02c0c6f66c47550" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=1&lt;/code&gt; and X is encoded as a CSC matrix.</source>
          <target state="translated">Si el &lt;code&gt;axis=1&lt;/code&gt; y X est&amp;aacute; codificado como una matriz CSC.</target>
        </trans-unit>
        <trans-unit id="4405a4c1e894889993d89bb6694cef1a6a8f7db3" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=1&lt;/code&gt;, then impute along rows.</source>
          <target state="translated">Si &lt;code&gt;axis=1&lt;/code&gt; , impute a lo largo de las filas.</target>
        </trans-unit>
        <trans-unit id="bf71a4a70c1ff1b9076f02c43d89e78c4b0ffc27" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;backend&lt;/code&gt; is a string it must match a previously registered implementation using the &lt;code&gt;register_parallel_backend&lt;/code&gt; function.</source>
          <target state="translated">Si el &lt;code&gt;backend&lt;/code&gt; es una cadena, debe coincidir con una implementaci&amp;oacute;n registrada previamente usando la funci&amp;oacute;n &lt;code&gt;register_parallel_backend&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6456a4494f2ba1f052aff4cf6d35ef66e787bc14" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;base_estimator&lt;/code&gt; is None, then &lt;code&gt;base_estimator=sklearn.linear_model.LinearRegression()&lt;/code&gt; is used for target values of dtype float.</source>
          <target state="translated">Si &lt;code&gt;base_estimator&lt;/code&gt; es None, entonces &lt;code&gt;base_estimator=sklearn.linear_model.LinearRegression()&lt;/code&gt; se usa para los valores objetivo de dtype float.</target>
        </trans-unit>
        <trans-unit id="898731158b64382ef9aad2307b39d22b5cd2a315" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;dense&lt;/code&gt; return &lt;code&gt;Y&lt;/code&gt; in the dense binary indicator format. If &lt;code&gt;'sparse'&lt;/code&gt; return &lt;code&gt;Y&lt;/code&gt; in the sparse binary indicator format. &lt;code&gt;False&lt;/code&gt; returns a list of lists of labels.</source>
          <target state="translated">Si es &lt;code&gt;dense&lt;/code&gt; devuelve &lt;code&gt;Y&lt;/code&gt; en el formato de indicador binario denso. Si es &lt;code&gt;'sparse'&lt;/code&gt; devuelve &lt;code&gt;Y&lt;/code&gt; en el formato de indicador binario disperso. &lt;code&gt;False&lt;/code&gt; devuelve una lista de listas de etiquetas.</target>
        </trans-unit>
        <trans-unit id="b1213caecc623f2a5139e82ba5db339edb5f6265" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;fit_intercept&lt;/code&gt; is set to False, the intercept is set to zero. &lt;code&gt;intercept_&lt;/code&gt; is of shape (1,) when the given problem is binary. In particular, when &lt;code&gt;multi_class=&amp;rsquo;multinomial&amp;rsquo;&lt;/code&gt;, &lt;code&gt;intercept_&lt;/code&gt; corresponds to outcome 1 (True) and &lt;code&gt;-intercept_&lt;/code&gt; corresponds to outcome 0 (False).</source>
          <target state="translated">Si &lt;code&gt;fit_intercept&lt;/code&gt; se establece en False, la intersecci&amp;oacute;n se establece en cero. &lt;code&gt;intercept_&lt;/code&gt; tiene forma (1,) cuando el problema dado es binario. En particular, cuando &lt;code&gt;multi_class=&amp;rsquo;multinomial&amp;rsquo;&lt;/code&gt; , &lt;code&gt;intercept_&lt;/code&gt; corresponde al resultado 1 (Verdadero) e &lt;code&gt;-intercept_&lt;/code&gt; corresponde al resultado 0 (Falso).</target>
        </trans-unit>
        <trans-unit id="4504cae87026fef1f6989cfa20e2e5bc171d37e0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;fit_intercept&lt;/code&gt; is set to False, the intercept is set to zero. &lt;code&gt;intercept_&lt;/code&gt; is of shape(1,) when the problem is binary.</source>
          <target state="translated">Si &lt;code&gt;fit_intercept&lt;/code&gt; se establece en False, la intersecci&amp;oacute;n se establece en cero. &lt;code&gt;intercept_&lt;/code&gt; tiene forma (1,) cuando el problema es binario.</target>
        </trans-unit>
        <trans-unit id="646836188c841e4fea39e4e4200d1f27e6191986" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;loss&lt;/code&gt; is a callable, then it should be a function that takes two arrays as inputs, the true and predicted value and returns a 1-D array with the i-th value of the array corresponding to the loss on &lt;code&gt;X[i]&lt;/code&gt;.</source>
          <target state="translated">Si la &lt;code&gt;loss&lt;/code&gt; es invocable, entonces deber&amp;iacute;a ser una funci&amp;oacute;n que tome dos matrices como entradas, el valor verdadero y predicho, y devuelva una matriz 1-D con el i-&amp;eacute;simo valor de la matriz correspondiente a la p&amp;eacute;rdida en &lt;code&gt;X[i]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c42d62680a26d66fc0f439c634f24ee01c670c77" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;memory&lt;/code&gt; is not joblib.Memory-like.</source>
          <target state="translated">Si la &lt;code&gt;memory&lt;/code&gt; no es joblib.Memory-like.</target>
        </trans-unit>
        <trans-unit id="e14dd7c153267d74f6b2214ce66bcf041482d792" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_bins&lt;/code&gt; is an array, and there is an ignored feature at index &lt;code&gt;i&lt;/code&gt;, &lt;code&gt;n_bins[i]&lt;/code&gt; will be ignored.</source>
          <target state="translated">Si &lt;code&gt;n_bins&lt;/code&gt; es una matriz y hay una caracter&amp;iacute;stica ignorada en el &amp;iacute;ndice &lt;code&gt;i&lt;/code&gt; , &lt;code&gt;n_bins[i]&lt;/code&gt; se ignorar&amp;aacute;n.</target>
        </trans-unit>
        <trans-unit id="20ab457ec31da79f104a0f7a337ba6bfe94b5438" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_clusters&lt;/code&gt; is set to None, the data is reduced from 100,000 samples to a set of 158 clusters. This can be viewed as a preprocessing step before the final (global) clustering step that further reduces these 158 clusters to 100 clusters.</source>
          <target state="translated">Si &lt;code&gt;n_clusters&lt;/code&gt; se establece en None, los datos se reducen de 100.000 muestras a un conjunto de 158 conglomerados. Esto puede verse como un paso de preprocesamiento antes del paso de agrupamiento final (global) que reduce a&amp;uacute;n m&amp;aacute;s estos 158 grupos a 100 grupos.</target>
        </trans-unit>
        <trans-unit id="1769c2fe615105013ff722090827f85ac960dff9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_components == 'mle'&lt;/code&gt; and &lt;code&gt;svd_solver == 'full'&lt;/code&gt;, Minka&amp;rsquo;s MLE is used to guess the dimension. Use of &lt;code&gt;n_components == 'mle'&lt;/code&gt; will interpret &lt;code&gt;svd_solver == 'auto'&lt;/code&gt; as &lt;code&gt;svd_solver == 'full'&lt;/code&gt;.</source>
          <target state="translated">Si &lt;code&gt;n_components == 'mle'&lt;/code&gt; y &lt;code&gt;svd_solver == 'full'&lt;/code&gt; , se utiliza el MLE de Minka para adivinar la dimensi&amp;oacute;n. El uso de &lt;code&gt;n_components == 'mle'&lt;/code&gt; interpretar&amp;aacute; &lt;code&gt;svd_solver == 'auto'&lt;/code&gt; como &lt;code&gt;svd_solver == 'full'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="959758e689ea656dd0e72e3bda18b0a45bbef2e0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_components&lt;/code&gt; is not set then all components are stored and the sum of the ratios is equal to 1.0.</source>
          <target state="translated">Si no se establece &lt;code&gt;n_components&lt;/code&gt; , todos los componentes se almacenan y la suma de las relaciones es igual a 1.0.</target>
        </trans-unit>
        <trans-unit id="4aaa2df3fa37c88b24d06638ef7188d7e8ebe112" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_jobs&lt;/code&gt; was set to a value higher than one, the data is copied for each parameter setting(and not &lt;code&gt;n_jobs&lt;/code&gt; times). This is done for efficiency reasons if individual jobs take very little time, but may raise errors if the dataset is large and not enough memory is available. A workaround in this case is to set &lt;code&gt;pre_dispatch&lt;/code&gt;. Then, the memory is copied only &lt;code&gt;pre_dispatch&lt;/code&gt; many times. A reasonable value for &lt;code&gt;pre_dispatch&lt;/code&gt; is &lt;code&gt;2 * n_jobs&lt;/code&gt;.</source>
          <target state="translated">Si &lt;code&gt;n_jobs&lt;/code&gt; se estableci&amp;oacute; en un valor superior a uno, los datos se copian para cada configuraci&amp;oacute;n de par&amp;aacute;metro (y no &lt;code&gt;n_jobs&lt;/code&gt; veces). Esto se hace por razones de eficiencia si los trabajos individuales toman muy poco tiempo, pero pueden generar errores si el conjunto de datos es grande y no hay suficiente memoria disponible. Una soluci&amp;oacute;n alternativa en este caso es establecer &lt;code&gt;pre_dispatch&lt;/code&gt; . Entonces, la memoria se copia solo &lt;code&gt;pre_dispatch&lt;/code&gt; muchas veces. Un valor razonable para &lt;code&gt;pre_dispatch&lt;/code&gt; es &lt;code&gt;2 * n_jobs&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="53682a81a25d0884d79ca09b064b0fc6e7cabd67" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_jobs&lt;/code&gt; was set to a value higher than one, the data is copied for each point in the grid (and not &lt;code&gt;n_jobs&lt;/code&gt; times). This is done for efficiency reasons if individual jobs take very little time, but may raise errors if the dataset is large and not enough memory is available. A workaround in this case is to set &lt;code&gt;pre_dispatch&lt;/code&gt;. Then, the memory is copied only &lt;code&gt;pre_dispatch&lt;/code&gt; many times. A reasonable value for &lt;code&gt;pre_dispatch&lt;/code&gt; is &lt;code&gt;2 * n_jobs&lt;/code&gt;.</source>
          <target state="translated">Si &lt;code&gt;n_jobs&lt;/code&gt; se estableci&amp;oacute; en un valor superior a uno, los datos se copian para cada punto de la cuadr&amp;iacute;cula (y no &lt;code&gt;n_jobs&lt;/code&gt; veces). Esto se hace por razones de eficiencia si los trabajos individuales toman muy poco tiempo, pero pueden generar errores si el conjunto de datos es grande y no hay suficiente memoria disponible. Una soluci&amp;oacute;n alternativa en este caso es establecer &lt;code&gt;pre_dispatch&lt;/code&gt; . Entonces, la memoria se copia solo &lt;code&gt;pre_dispatch&lt;/code&gt; muchas veces. Un valor razonable para &lt;code&gt;pre_dispatch&lt;/code&gt; es &lt;code&gt;2 * n_jobs&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c1cc035dd2ff12188f95601d6fe5c4679ad6bb78" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_samples == 10000&lt;/code&gt;, storing &lt;code&gt;X&lt;/code&gt; as a NumPy array of type float32 would require 10000 x 100000 x 4 bytes = &lt;strong&gt;4GB in RAM&lt;/strong&gt; which is barely manageable on today&amp;rsquo;s computers.</source>
          <target state="translated">Si &lt;code&gt;n_samples == 10000&lt;/code&gt; , almacenar &lt;code&gt;X&lt;/code&gt; como una matriz NumPy de tipo float32 requerir&amp;iacute;a 10000 x 100000 x 4 bytes = &lt;strong&gt;4 GB de RAM, lo&lt;/strong&gt; que apenas es manejable en las computadoras actuales.</target>
        </trans-unit>
        <trans-unit id="8e65ba558868cb56b0c8a76632ea67901b254afe" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;normalize == True&lt;/code&gt;, return the average Jaccard similarity coefficient, else it returns the sum of the Jaccard similarity coefficient over the sample set.</source>
          <target state="translated">Si &lt;code&gt;normalize == True&lt;/code&gt; , devuelve el coeficiente de similitud de Jaccard promedio; de lo contrario, devuelve la suma del coeficiente de similitud de Jaccard sobre el conjunto de muestra.</target>
        </trans-unit>
        <trans-unit id="c606413521700e073d3e669024415faa2300a113" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;normalize == True&lt;/code&gt;, return the fraction of correctly classified samples (float), else returns the number of correctly classified samples (int).</source>
          <target state="translated">Si &lt;code&gt;normalize == True&lt;/code&gt; , devuelve la fracci&amp;oacute;n de muestras clasificadas correctamente (flotante), de lo contrario devuelve el n&amp;uacute;mero de muestras clasificadas correctamente (int).</target>
        </trans-unit>
        <trans-unit id="cd9dc36a4d7167817c2823908b4ce633913b9765" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;normalize == True&lt;/code&gt;, return the fraction of misclassifications (float), else it returns the number of misclassifications (int).</source>
          <target state="translated">Si &lt;code&gt;normalize == True&lt;/code&gt; , devuelve la fracci&amp;oacute;n de errores de clasificaci&amp;oacute;n (flotante), de lo contrario, devuelve el n&amp;uacute;mero de errores de clasificaci&amp;oacute;n (int).</target>
        </trans-unit>
        <trans-unit id="d0b860961bc5b4a4c45189c0fd4de5c2d61f1ab4" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;out=None&lt;/code&gt;, returns a new array containing the mean values, otherwise a reference to the output array is returned.</source>
          <target state="translated">Si &lt;code&gt;out=None&lt;/code&gt; , devuelve una nueva matriz que contiene los valores medios; de lo contrario, se devuelve una referencia a la matriz de salida.</target>
        </trans-unit>
        <trans-unit id="a1e72f87e91fc5bb6f8882ece59a46bf9ee089e2" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;pos_label is None&lt;/code&gt; and in binary classification, this function returns the average precision, recall and F-measure if &lt;code&gt;average&lt;/code&gt; is one of &lt;code&gt;'micro'&lt;/code&gt;, &lt;code&gt;'macro'&lt;/code&gt;, &lt;code&gt;'weighted'&lt;/code&gt; or &lt;code&gt;'samples'&lt;/code&gt;.</source>
          <target state="translated">Si &lt;code&gt;pos_label is None&lt;/code&gt; y en clasificaci&amp;oacute;n binaria, esta funci&amp;oacute;n devuelve la precisi&amp;oacute;n promedio, recuperaci&amp;oacute;n y medida F si el &lt;code&gt;average&lt;/code&gt; es uno de &lt;code&gt;'micro'&lt;/code&gt; , &lt;code&gt;'macro'&lt;/code&gt; , &lt;code&gt;'weighted'&lt;/code&gt; o &lt;code&gt;'samples'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7bb4c6eca31ede3ca3e8fe5a9b41ecd9a55b266b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;return_path==True&lt;/code&gt; returns the entire path, else returns only the last point of the path.</source>
          <target state="translated">Si &lt;code&gt;return_path==True&lt;/code&gt; devuelve la ruta completa, de lo contrario solo devuelve el &amp;uacute;ltimo punto de la ruta.</target>
        </trans-unit>
        <trans-unit id="9e477bb8072307702a812f869b8166fe31bf9ca0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;smooth_idf=True&lt;/code&gt; (the default), the constant &amp;ldquo;1&amp;rdquo; is added to the numerator and denominator of the idf as if an extra document was seen containing every term in the collection exactly once, which prevents zero divisions: idf(d, t) = log [ (1 + n) / (1 + df(d, t)) ] + 1.</source>
          <target state="translated">Si &lt;code&gt;smooth_idf=True&lt;/code&gt; (el valor predeterminado), la constante &quot;1&quot; se agrega al numerador y al denominador de la idf como si se viera un documento adicional que contiene cada t&amp;eacute;rmino de la colecci&amp;oacute;n exactamente una vez, lo que evita las divisiones cero: idf (d, t ) = log [(1 + n) / (1 + gl (d, t))] + 1.</target>
        </trans-unit>
        <trans-unit id="3f772487671a5560a2a2bb3464b54cf0bad5b348" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;svd_solver == 'arpack'&lt;/code&gt;, the number of components must be strictly less than the minimum of n_features and n_samples.</source>
          <target state="translated">Si &lt;code&gt;svd_solver == 'arpack'&lt;/code&gt; , el n&amp;uacute;mero de componentes debe ser estrictamente menor que el m&amp;iacute;nimo de n_features y n_samples.</target>
        </trans-unit>
        <trans-unit id="abdb8ed2b871d03510343cf9ee77736674d298ab" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;validate&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;X&lt;/code&gt; will be checked.</source>
          <target state="translated">Si &lt;code&gt;validate&lt;/code&gt; es &lt;code&gt;True&lt;/code&gt; , se marcar&amp;aacute; &lt;code&gt;X&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5cfb594032bd50fcef2738a25df520e95867f411" translate="yes" xml:space="preserve">
          <source>If C is a ground truth class assignment and K the clustering, let us define \(a\) and \(b\) as:</source>
          <target state="translated">Si C es una asignación de clase de la verdad de la tierra y K la agrupación,vamos a definir como..:</target>
        </trans-unit>
        <trans-unit id="40e72ab25b1921db07187a1c526cc9080a10eaea" translate="yes" xml:space="preserve">
          <source>If False, X will be overwritten. &lt;code&gt;copy=False&lt;/code&gt; can be used to save memory but is unsafe for general use.</source>
          <target state="translated">Si es False, X se sobrescribir&amp;aacute;. &lt;code&gt;copy=False&lt;/code&gt; puede usarse para ahorrar memoria, pero no es seguro para uso general.</target>
        </trans-unit>
        <trans-unit id="b5379fd8e8700833a560e6ab84ea58c40e10b6a8" translate="yes" xml:space="preserve">
          <source>If False, data passed to fit are overwritten and running fit(X).transform(X) will not yield the expected results, use fit_transform(X) instead.</source>
          <target state="translated">Si es falso,los datos pasados a fit se sobrescriben y la ejecución de fit(X).transform(X)no dará los resultados esperados,utilice fit_transform(X)en su lugar.</target>
        </trans-unit>
        <trans-unit id="3d545281a4ef31d03ffb244079b728a3c5cc8b18" translate="yes" xml:space="preserve">
          <source>If False, data passed to fit are overwritten. Defaults to True.</source>
          <target state="translated">Si es falsa,los datos pasados para encajar se sobrescriben.Por defecto es Verdadero.</target>
        </trans-unit>
        <trans-unit id="4bf616e8d9d604d2525c59d889782525e410270c" translate="yes" xml:space="preserve">
          <source>If False, distances will not be returned</source>
          <target state="translated">Si es falso,las distancias no serán devueltas</target>
        </trans-unit>
        <trans-unit id="d8cdf8e9cb326e6212f67c80aca3a4f04326fc4c" translate="yes" xml:space="preserve">
          <source>If False, raise a IOError if the data is not locally available instead of trying to download the data from the source site.</source>
          <target state="translated">Si es falsa,levante un IOError si los datos no están disponibles localmente en lugar de intentar descargar los datos del sitio de origen.</target>
        </trans-unit>
        <trans-unit id="707f36c34b2f81eacbaf143a8e62cb9371b1332e" translate="yes" xml:space="preserve">
          <source>If False, raise an IOError if the data is not locally available instead of trying to download the data from the source site.</source>
          <target state="translated">Si es falsa,levante un IOError si los datos no están disponibles localmente en lugar de intentar descargar los datos del sitio de origen.</target>
        </trans-unit>
        <trans-unit id="d32001af2bcb0806daa431ab8cf432f700c0bb79" translate="yes" xml:space="preserve">
          <source>If False, the imputer mask will be a numpy array.</source>
          <target state="translated">Si es falsa,la máscara imputadora será un conjunto de entumecimiento.</target>
        </trans-unit>
        <trans-unit id="2823ebb07c9bdb5cae0bfca227f5db48d585ba5a" translate="yes" xml:space="preserve">
          <source>If False, the input arrays X and dictionary will not be checked.</source>
          <target state="translated">Si es falso,las matrices de entrada X y el diccionario no se comprobarán.</target>
        </trans-unit>
        <trans-unit id="bd8e933f9aa74b9b27da566d4ffb96f4e62218cf" translate="yes" xml:space="preserve">
          <source>If False, the input arrays X and y will not be checked.</source>
          <target state="translated">Si es falso,no se comprobarán las matrices de entrada X e y.</target>
        </trans-unit>
        <trans-unit id="85aa52dd8c7d5d29b6bebfd616a7ca3fe91cde14" translate="yes" xml:space="preserve">
          <source>If False, the projected data uses a sparse representation if the input is sparse.</source>
          <target state="translated">Si son falsos,los datos proyectados utilizan una representación escasa si la entrada es escasa.</target>
        </trans-unit>
        <trans-unit id="7bfec8f3204bdf713e2d3557ec53ea6f3960ad24" translate="yes" xml:space="preserve">
          <source>If False, there is no input validation.</source>
          <target state="translated">Si es falso,no hay validación de entrada.</target>
        </trans-unit>
        <trans-unit id="a67320198a0b746d35fcc941198f1221ee73c87b" translate="yes" xml:space="preserve">
          <source>If False, try to avoid a copy and do inplace scaling instead. This is not guaranteed to always work inplace; e.g. if the data is not a NumPy array or scipy.sparse CSR matrix, a copy may still be returned.</source>
          <target state="translated">Si es falso,trata de evitar una copia y haz un escalado en el lugar.No se garantiza que esto funcione siempre en el lugar;por ejemplo,si los datos no son una matriz NumPy o una matriz CSR scipy.sparse,puede que se devuelva una copia.</target>
        </trans-unit>
        <trans-unit id="fcd08eda0bca1685e28de89ae046095006b92653" translate="yes" xml:space="preserve">
          <source>If None (default), load all the categories. If not None, list of category names to load (other categories ignored).</source>
          <target state="translated">Si no hay ninguna (por defecto),cargue todas las categorías.Si no hay ninguna,lista de nombres de categorías a cargar (otras categorías ignoradas).</target>
        </trans-unit>
        <trans-unit id="a7cbd99fe721a3cd173045eddaf688b83e7620c1" translate="yes" xml:space="preserve">
          <source>If None the estimator&amp;rsquo;s default scorer, if available, is used.</source>
          <target state="translated">Si es Ninguno, se utiliza el puntaje predeterminado del estimador, si est&amp;aacute; disponible.</target>
        </trans-unit>
        <trans-unit id="96ad58db5ee1b903109c173fcab72b0955bb0408" translate="yes" xml:space="preserve">
          <source>If None, defaults to 1.0 / n_features</source>
          <target state="translated">Si no hay ninguno,el valor por defecto es 1.0/n_funciones</target>
        </trans-unit>
        <trans-unit id="e5ce9a9046a52014390758ba790166ae01779c1f" translate="yes" xml:space="preserve">
          <source>If None, do not try to decode the content of the files (e.g. for images or other non-text content). If not None, encoding to use to decode text files to Unicode if load_content is True.</source>
          <target state="translated">Si no hay ninguno,no intente decodificar el contenido de los archivos (por ejemplo,para imágenes u otro contenido no textual).Si no es None,codificar para usar para decodificar archivos de texto a Unicode si load_content es True.</target>
        </trans-unit>
        <trans-unit id="3e5e8d666168a7a15a80edb16364256ae0a379e4" translate="yes" xml:space="preserve">
          <source>If None, no stop words will be used. max_df can be set to a value in the range [0.7, 1.0) to automatically detect and filter stop words based on intra corpus document frequency of terms.</source>
          <target state="translated">Si no hay ninguna,no se usarán palabras de parada.max_df puede ajustarse a un valor en el rango [0,7,1,0]para detectar y filtrar automáticamente las palabras de parada en función de la frecuencia de los términos del documento intracorpóreo.</target>
        </trans-unit>
        <trans-unit id="02542a43a2f09f5328657402d69f49ce442cb6c2" translate="yes" xml:space="preserve">
          <source>If None, pairwise_distances_chunked returns a generator of vertical chunks of the distance matrix.</source>
          <target state="translated">Si es None,pairwise_distances_chunked devuelve un generador de trozos verticales de la matriz de distancia.</target>
        </trans-unit>
        <trans-unit id="eb5d73cb83520641b0e2c815c109159135d569cc" translate="yes" xml:space="preserve">
          <source>If None, the estimator&amp;rsquo;s default scorer (if available) is used.</source>
          <target state="translated">Si es Ninguno, se usa el puntaje predeterminado del estimador (si est&amp;aacute; disponible).</target>
        </trans-unit>
        <trans-unit id="651c3653c15c90a6722a00465ba57c19c30adb9b" translate="yes" xml:space="preserve">
          <source>If None, the threshold is assumed to be half way between neg_label and pos_label.</source>
          <target state="translated">Si no hay ninguno,se supone que el umbral está a mitad de camino entre neg_label y pos_label.</target>
        </trans-unit>
        <trans-unit id="ac652d29bc285e4e46f5aaf2fe5415c63aee1f09" translate="yes" xml:space="preserve">
          <source>If None, then &lt;code&gt;max_features=n_features&lt;/code&gt;.</source>
          <target state="translated">Si es Ninguno, entonces &lt;code&gt;max_features=n_features&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2f9e5ee96434f57529c2481b71d631d9dd0cb5e7" translate="yes" xml:space="preserve">
          <source>If True (default), the squared error norm is divided by n_features. If False, the squared error norm is not rescaled.</source>
          <target state="translated">Si es True (por defecto),la norma de error al cuadrado se divide por n_características.Si es Falso,la norma de error al cuadrado no se reajusta.</target>
        </trans-unit>
        <trans-unit id="da82574bb396bf8045c493d20398be74e4e9ef51" translate="yes" xml:space="preserve">
          <source>If True (default), then include a bias column, the feature in which all polynomial powers are zero (i.e. a column of ones - acts as an intercept term in a linear model).</source>
          <target state="translated">Si es True (por defecto),entonces incluya una columna de sesgo,la característica en la que todas las potencias polinómicas son cero (es decir,una columna de unos-actúa como un término de intercepción en un modelo lineal).</target>
        </trans-unit>
        <trans-unit id="d150b2a4c21e929dfd726f6463d03ca9f005e91a" translate="yes" xml:space="preserve">
          <source>If True (default), transform will raise an error when there are features with missing values in transform that have no missing values in fit This is applicable only when &lt;code&gt;features=&quot;missing-only&quot;&lt;/code&gt;.</source>
          <target state="translated">Si es Verdadero (predeterminado), la transformaci&amp;oacute;n generar&amp;aacute; un error cuando hay entidades con valores perdidos en la transformaci&amp;oacute;n que no tienen valores perdidos en el ajuste. Esto es aplicable solo cuando &lt;code&gt;features=&quot;missing-only&quot;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d91ad850130f94be79fb668041bf3eecd01a29b0" translate="yes" xml:space="preserve">
          <source>If True and if X is sparse, the method also returns the intercept, and the solver is automatically changed to &amp;lsquo;sag&amp;rsquo;. This is only a temporary fix for fitting the intercept with sparse data. For dense data, use sklearn.linear_model._preprocess_data before your regression.</source>
          <target state="translated">Si es Verdadero y si X es escaso, el m&amp;eacute;todo tambi&amp;eacute;n devuelve la intersecci&amp;oacute;n y el solucionador se cambia autom&amp;aacute;ticamente a 'hundirse'. Esta es solo una soluci&amp;oacute;n temporal para ajustar la intersecci&amp;oacute;n con datos escasos. Para datos densos, use sklearn.linear_model._preprocess_data antes de su regresi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="a68108e0ea5bf983075f127e077ee80517d6dfdd" translate="yes" xml:space="preserve">
          <source>If True the covariance matrices are computed and stored in the &lt;code&gt;self.covariance_&lt;/code&gt; attribute.</source>
          <target state="translated">Si es True, las matrices de covarianza se calculan y almacenan en el atributo &lt;code&gt;self.covariance_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5c5d5facc126a265032a533a4664c8926339ade0" translate="yes" xml:space="preserve">
          <source>If True the full path is stored in the &lt;code&gt;coef_path_&lt;/code&gt; attribute. If you compute the solution for a large problem or many targets, setting &lt;code&gt;fit_path&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt; will lead to a speedup, especially with a small alpha.</source>
          <target state="translated">Si es True, la ruta completa se almacena en el atributo &lt;code&gt;coef_path_&lt;/code&gt; . Si calcula la soluci&amp;oacute;n para un problema grande o muchos objetivos, establecer &lt;code&gt;fit_path&lt;/code&gt; en &lt;code&gt;False&lt;/code&gt; conducir&amp;aacute; a una aceleraci&amp;oacute;n, especialmente con un alfa peque&amp;ntilde;o.</target>
        </trans-unit>
        <trans-unit id="53e960778922c6ba257a9c66f18d0e260655f043" translate="yes" xml:space="preserve">
          <source>If True the function returns the pairwise distance matrix else it returns the componentwise L1 pairwise-distances. Not supported for sparse matrix inputs.</source>
          <target state="translated">Si es True,la función devuelve la matriz de distancias en pares,o bien devuelve las distancias en pares L1 en componentes.No se admite para entradas de matrices escasas.</target>
        </trans-unit>
        <trans-unit id="2546c89362b151bbba35dab463b810d1f7c0a359" translate="yes" xml:space="preserve">
          <source>If True the order of the dataset is shuffled to avoid having images of the same person grouped.</source>
          <target state="translated">Si es cierto,el orden del conjunto de datos se baraja para evitar que se agrupen imágenes de la misma persona.</target>
        </trans-unit>
        <trans-unit id="618a67ac95fc4ccc3385ae319143bf344e1ffb63" translate="yes" xml:space="preserve">
          <source>If True then raise a warning if conversion is required.</source>
          <target state="translated">Si es cierto,entonces,plantea una advertencia si se requiere la conversión.</target>
        </trans-unit>
        <trans-unit id="19362eed638b2dc6d204e12092075aedd87e6e93" translate="yes" xml:space="preserve">
          <source>If True then raise an exception if array is not symmetric.</source>
          <target state="translated">Si es cierto,entonces haz una excepción si la matriz no es simétrica.</target>
        </trans-unit>
        <trans-unit id="baf82faf959595f525e5d5a94c6b8526ad942779" translate="yes" xml:space="preserve">
          <source>If True, X will be copied; else, it may be overwritten.</source>
          <target state="translated">Si es cierto,X será copiado;si no,puede ser sobrescrito.</target>
        </trans-unit>
        <trans-unit id="aa91f074d713faca021e35ddd5331805b9848f9e" translate="yes" xml:space="preserve">
          <source>If True, a copy of X will be created. If False, a copy may still be returned if X&amp;rsquo;s dtype is not a floating point type.</source>
          <target state="translated">Si es True, se crear&amp;aacute; una copia de X. Si es False, a&amp;uacute;n se puede devolver una copia si el dtype de X no es un tipo de coma flotante.</target>
        </trans-unit>
        <trans-unit id="054b374d036034be5d7258a6a975038eb8fec935" translate="yes" xml:space="preserve">
          <source>If True, a copy of X will be created. If False, imputation will be done in-place whenever possible. Note that, in the following cases, a new copy will always be made, even if &lt;code&gt;copy=False&lt;/code&gt;:</source>
          <target state="translated">Si es True, se crear&amp;aacute; una copia de X. Si es Falso, la imputaci&amp;oacute;n se realizar&amp;aacute; en el lugar siempre que sea posible. Tenga en cuenta que, en los siguientes casos, siempre se realizar&amp;aacute; una nueva copia, incluso si &lt;code&gt;copy=False&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="f237ade75e04520befb53fc36267d58be41dc5ae" translate="yes" xml:space="preserve">
          <source>If True, a persistent copy of the training data is stored in the object. Otherwise, just a reference to the training data is stored, which might cause predictions to change if the data is modified externally.</source>
          <target state="translated">Si es cierto,una copia persistente de los datos de entrenamiento se almacena en el objeto.De lo contrario,sólo se almacena una referencia a los datos de entrenamiento,lo que puede hacer que las predicciones cambien si los datos se modifican externamente.</target>
        </trans-unit>
        <trans-unit id="5b4ca3bdeb594ab34289df8cfc7fa70c9919ad95" translate="yes" xml:space="preserve">
          <source>If True, all non zero counts are set to 1. This is useful for discrete probabilistic models that model binary events rather than integer counts.</source>
          <target state="translated">Si es True,todos los recuentos no nulos se establecen en 1.Esto es útil para los modelos probabilísticos discretos que modelan eventos binarios en lugar de recuentos enteros.</target>
        </trans-unit>
        <trans-unit id="0beec2b2d6b910456e155063f83ec1e59c6c0df1" translate="yes" xml:space="preserve">
          <source>If True, all non-zero term counts are set to 1. This does not mean outputs will have only 0/1 values, only that the tf term in tf-idf is binary. (Set idf and normalization to False to get 0/1 outputs.)</source>
          <target state="translated">Si es True,todos los recuentos de términos que no sean cero se establecen en 1.Esto no significa que las salidas tengan sólo valores 0/1,sólo que el término tf en tf-idf es binario.(Establezca idf y normalización a Falso para obtener salidas 0/1).</target>
        </trans-unit>
        <trans-unit id="b69242de00e60526a79082b37846a2a724d7b3dd" translate="yes" xml:space="preserve">
          <source>If True, center the data before scaling.</source>
          <target state="translated">Si es cierto,centra los datos antes de escalar.</target>
        </trans-unit>
        <trans-unit id="6c9a4d2da449884c97015be12ce056a53dc04757" translate="yes" xml:space="preserve">
          <source>If True, center the data before scaling. This does not work (and will raise an exception) when attempted on sparse matrices, because centering them entails building a dense matrix which in common use cases is likely to be too large to fit in memory.</source>
          <target state="translated">Si es cierto,centra los datos antes de escalar.Esto no funciona (y planteará una excepción)cuando se intente en matrices escasas,porque centrarlos implica construir una matriz densa que en los casos de uso común es probable que sea demasiado grande para caber en la memoria.</target>
        </trans-unit>
        <trans-unit id="9d7135e468914be214009091b1fc11f6721afd0a" translate="yes" xml:space="preserve">
          <source>If True, center the data before scaling. This will cause &lt;code&gt;transform&lt;/code&gt; to raise an exception when attempted on sparse matrices, because centering them entails building a dense matrix which in common use cases is likely to be too large to fit in memory.</source>
          <target state="translated">Si es Verdadero, centre los datos antes de escalar. Esto har&amp;aacute; que la &lt;code&gt;transform&lt;/code&gt; aci&amp;oacute;n genere una excepci&amp;oacute;n cuando se intente en matrices dispersas, porque centrarlas implica construir una matriz densa que, en casos de uso com&amp;uacute;n, es probable que sea demasiado grande para caber en la memoria.</target>
        </trans-unit>
        <trans-unit id="20839df17b3bca6b55533337f17b7c17f0881d1a" translate="yes" xml:space="preserve">
          <source>If True, compute the objective function at each step of the model. Default is False</source>
          <target state="translated">Si es cierto,calcula la función objetivo en cada paso del modelo.Por defecto es Falso</target>
        </trans-unit>
        <trans-unit id="afb80999f635ad0619301e31bb4cd6b353188af0" translate="yes" xml:space="preserve">
          <source>If True, compute the objective function at each step of the model. Default is False.</source>
          <target state="translated">Si es cierto,calcula la función objetivo en cada paso del modelo.El valor por defecto es Falso.</target>
        </trans-unit>
        <trans-unit id="9df36ef1b24eb49a93a9d932c395b3324554689c" translate="yes" xml:space="preserve">
          <source>If True, data are not centered before computation. Useful to work with data whose mean is significantly equal to zero but is not exactly zero. If False, data are centered before computation.</source>
          <target state="translated">Si es cierto,los datos no se centran antes del cálculo.Es útil para trabajar con datos cuya media es significativamente igual a cero pero no es exactamente cero.Si es falso,los datos se centran antes del cálculo.</target>
        </trans-unit>
        <trans-unit id="cdd266c276f30f1ed8fec5e418bed1790d829f9f" translate="yes" xml:space="preserve">
          <source>If True, data are not centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False (default), data are centered before computation.</source>
          <target state="translated">Si es cierto,los datos no se centran antes del cálculo.Es útil cuando se trabaja con datos cuya media es casi,pero no exactamente cero.Si es falso (predeterminado),los datos se centran antes del cálculo.</target>
        </trans-unit>
        <trans-unit id="b4e1adfc1374b7a62eee31a2ac4be08eea958149" translate="yes" xml:space="preserve">
          <source>If True, data are not centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False, data are centered before computation.</source>
          <target state="translated">Si es cierto,los datos no se centran antes del cálculo.Es útil cuando se trabaja con datos cuya media es casi,pero no exactamente cero.Si es falso,los datos se centran antes del cálculo.</target>
        </trans-unit>
        <trans-unit id="a2902b07926590508dee697d1e97c541f35cd531" translate="yes" xml:space="preserve">
          <source>If True, ensure that the output of the random projection is a dense numpy array even if the input and random projection matrix are both sparse. In practice, if the number of components is small the number of zero components in the projected data will be very small and it will be more CPU and memory efficient to use a dense representation.</source>
          <target state="translated">Si es cierto,asegúrese de que la salida de la proyección aleatoria sea una matriz densa y numérica,incluso si la matriz de entrada y la de proyección aleatoria son ambas escasas.En la práctica,si el número de componentes es pequeño,el número de componentes cero en los datos proyectados será muy pequeño y será más eficiente para la CPU y la memoria utilizar una representación densa.</target>
        </trans-unit>
        <trans-unit id="a3946c2202800dbed0f15da39a81b563f2054e41" translate="yes" xml:space="preserve">
          <source>If True, individual trees are fit on random subsets of the training data sampled with replacement. If False, sampling without replacement is performed.</source>
          <target state="translated">Si es cierto,los árboles individuales se ajustan en subconjuntos aleatorios de los datos de entrenamiento muestreados con el reemplazo.Si es falso,se realiza un muestreo sin reemplazo.</target>
        </trans-unit>
        <trans-unit id="47a8f3ebe1bf3e97122b0404e375e9c09f1cef3f" translate="yes" xml:space="preserve">
          <source>If True, input X is copied and stored by the model in the &lt;code&gt;X_fit_&lt;/code&gt; attribute. If no further changes will be done to X, setting &lt;code&gt;copy_X=False&lt;/code&gt; saves memory by storing a reference.</source>
          <target state="translated">Si es True, el modelo copia y almacena la entrada X en el atributo &lt;code&gt;X_fit_&lt;/code&gt; . Si no se realizar&amp;aacute;n m&amp;aacute;s cambios en X, la configuraci&amp;oacute;n de &lt;code&gt;copy_X=False&lt;/code&gt; ahorra memoria almacenando una referencia.</target>
        </trans-unit>
        <trans-unit id="10ab7d9c4ef9751f0861c3cfbcd363da08ee1196" translate="yes" xml:space="preserve">
          <source>If True, return a sparse CSR continency matrix. If &lt;code&gt;eps is not None&lt;/code&gt;, and &lt;code&gt;sparse is True&lt;/code&gt;, will throw ValueError.</source>
          <target state="translated">Si es Verdadero, devuelve una matriz de continencia de CSR escasa. Si &lt;code&gt;eps is not None&lt;/code&gt; , y &lt;code&gt;sparse is True&lt;/code&gt; , arrojar&amp;aacute; ValueError.</target>
        </trans-unit>
        <trans-unit id="bbadcb21277fb2fd7500e5e018984adc0515f847" translate="yes" xml:space="preserve">
          <source>If True, return output as dict</source>
          <target state="translated">Si es cierto,devuelva la salida como dict</target>
        </trans-unit>
        <trans-unit id="4c0f661b8fac7f22363a5a1e55327c6967bb56d8" translate="yes" xml:space="preserve">
          <source>If True, return the average score across folds, weighted by the number of samples in each test set. In this case, the data is assumed to be identically distributed across the folds, and the loss minimized is the total loss per sample, and not the mean loss across the folds. If False, return the average score across folds. Default is True, but will change to False in version 0.21, to correspond to the standard definition of cross-validation.</source>
          <target state="translated">Si es cierto,devuelva la puntuación media en los pliegues,ponderada por el número de muestras de cada conjunto de pruebas.En este caso,se supone que los datos están distribuidos de forma idéntica en los pliegues,y la pérdida minimizada es la pérdida total por muestra,y no la pérdida media en los pliegues.Si es falso,devuelva la puntuación media a través de los pliegues.El valor por defecto es True,pero cambiará a False en la versión 0.21,para corresponder a la definición estándar de validación cruzada.</target>
        </trans-unit>
        <trans-unit id="cd7031ac688b02e25258c5831c7d3ea164486db6" translate="yes" xml:space="preserve">
          <source>If True, return the distance between the clusters.</source>
          <target state="translated">Si es cierto,devuelve la distancia entre los grupos.</target>
        </trans-unit>
        <trans-unit id="48eeb388f7c432fd1b00c136703cc691939b77aa" translate="yes" xml:space="preserve">
          <source>If True, returns &lt;code&gt;(data, target)&lt;/code&gt; instead of a Bunch object. See below for more information about the &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt; object.</source>
          <target state="translated">Si es True, devuelve &lt;code&gt;(data, target)&lt;/code&gt; lugar de un objeto Bunch. Consulte a continuaci&amp;oacute;n para obtener m&amp;aacute;s informaci&amp;oacute;n sobre los &lt;code&gt;data&lt;/code&gt; y &lt;code&gt;target&lt;/code&gt; objeto de destino .</target>
        </trans-unit>
        <trans-unit id="b8ef976b3bf0a8c5fe0d328bf69ca77595314915" translate="yes" xml:space="preserve">
          <source>If True, returns &lt;code&gt;(data, target)&lt;/code&gt; instead of a Bunch object. See below for more information about the &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt; objects.</source>
          <target state="translated">Si es True, devuelve &lt;code&gt;(data, target)&lt;/code&gt; lugar de un objeto Bunch. Consulte a continuaci&amp;oacute;n para obtener m&amp;aacute;s informaci&amp;oacute;n sobre los &lt;code&gt;data&lt;/code&gt; y &lt;code&gt;target&lt;/code&gt; objetos de destino .</target>
        </trans-unit>
        <trans-unit id="d467c22a2bd71ab649cbad26364f06a31ce58ac1" translate="yes" xml:space="preserve">
          <source>If True, returns &lt;code&gt;(data.data, data.target)&lt;/code&gt; instead of a Bunch object.</source>
          <target state="translated">Si es True, devuelve &lt;code&gt;(data.data, data.target)&lt;/code&gt; lugar de un objeto Bunch.</target>
        </trans-unit>
        <trans-unit id="248b6d0d481e47f352d5f3203242e6800072c658" translate="yes" xml:space="preserve">
          <source>If True, returns &lt;code&gt;(dataset.data, dataset.target)&lt;/code&gt; instead of a Bunch object. See below for more information about the &lt;code&gt;dataset.data&lt;/code&gt; and &lt;code&gt;dataset.target&lt;/code&gt; object.</source>
          <target state="translated">Si es True, devuelve &lt;code&gt;(dataset.data, dataset.target)&lt;/code&gt; lugar de un objeto Bunch. Consulte a continuaci&amp;oacute;n para obtener m&amp;aacute;s informaci&amp;oacute;n sobre el objeto &lt;code&gt;dataset.data&lt;/code&gt; y &lt;code&gt;dataset.target&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c220af25fde2fda1e9985d78b63166a331905d63" translate="yes" xml:space="preserve">
          <source>If True, scale the data to interquartile range.</source>
          <target state="translated">Si es cierto,escalar los datos al rango intercuartílico.</target>
        </trans-unit>
        <trans-unit id="0f395f8257fe0bdfb8a823c88f3be9843583f8a6" translate="yes" xml:space="preserve">
          <source>If True, scale the data to unit variance (or equivalently, unit standard deviation).</source>
          <target state="translated">Si es cierto,escale los datos a la varianza unitaria (o,de manera equivalente,a la desviación estándar unitaria).</target>
        </trans-unit>
        <trans-unit id="a491ca8d8797fa01293c195b8787d725c30e073a" translate="yes" xml:space="preserve">
          <source>If True, the clusters are put on the vertices of a hypercube. If False, the clusters are put on the vertices of a random polytope.</source>
          <target state="translated">Si es cierto,los cúmulos se ponen en los vértices de un hipercubo.Si es falso,los cúmulos se colocan en los vértices de un politopo aleatorio.</target>
        </trans-unit>
        <trans-unit id="dc426ca785aa82bc3726faf833e38673875ff1ab" translate="yes" xml:space="preserve">
          <source>If True, the coefficients of the underlying linear model are returned.</source>
          <target state="translated">Si es cierto,se devuelven los coeficientes del modelo lineal subyacente.</target>
        </trans-unit>
        <trans-unit id="5724be8fac97575b0a1ba6783afc1c2fbe0fcac8" translate="yes" xml:space="preserve">
          <source>If True, the covariance of the joint predictive distribution at the query points is returned along with the mean</source>
          <target state="translated">Si es cierto,la covarianza de la distribución predictiva conjunta en los puntos de consulta se devuelve junto con la media</target>
        </trans-unit>
        <trans-unit id="d28765388f526f443e8440713d9f120592d23759" translate="yes" xml:space="preserve">
          <source>If True, the gradient of the log-marginal likelihood with respect to the kernel hyperparameters at position theta is returned additionally. If True, theta must not be None.</source>
          <target state="translated">Si es cierto,el gradiente de la probabilidad logarítmica marginal con respecto a los hiperparámetros del núcleo en la posición theta se devuelve adicionalmente.Si es True,theta no debe ser None.</target>
        </trans-unit>
        <trans-unit id="2ecaf6f4ca3e741011335b25b38b91313c972ea3" translate="yes" xml:space="preserve">
          <source>If True, the gradient of the log-marginal likelihood with respect to the kernel hyperparameters at position theta is returned additionally. Note that gradient computation is not supported for non-binary classification. If True, theta must not be None.</source>
          <target state="translated">Si es cierto,el gradiente de la probabilidad logarítmica marginal con respecto a los hiperparámetros del núcleo en la posición theta se devuelve adicionalmente.Obsérvese que el cálculo del gradiente no se admite para la clasificación no binaria.Si es True,theta no debe ser None.</target>
        </trans-unit>
        <trans-unit id="65ddb79c8d6a76beebeeb976d10455d7eb1fb46d" translate="yes" xml:space="preserve">
          <source>If True, the imputer mask will be a sparse matrix.</source>
          <target state="translated">Si es cierto,la máscara imputadora será una matriz escasa.</target>
        </trans-unit>
        <trans-unit id="a134a28236267fd097c12ab6f4f7b85d957aa9ca" translate="yes" xml:space="preserve">
          <source>If True, the method also returns &lt;code&gt;n_iter&lt;/code&gt;, the actual number of iteration performed by the solver.</source>
          <target state="translated">Si es True, el m&amp;eacute;todo tambi&amp;eacute;n devuelve &lt;code&gt;n_iter&lt;/code&gt; , el n&amp;uacute;mero real de iteraciones realizadas por el solucionador.</target>
        </trans-unit>
        <trans-unit id="af50e40087f45610f2fbcc323b88ccd93dcf9324" translate="yes" xml:space="preserve">
          <source>If True, the regressors X will be normalized before regression. This parameter is ignored when &lt;code&gt;fit_intercept&lt;/code&gt; is set to False. When the regressors are normalized, note that this makes the hyperparameters learned more robust and almost independent of the number of samples. The same property is not valid for standardized data. However, if you wish to standardize, please use &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; before calling &lt;code&gt;fit&lt;/code&gt; on an estimator with &lt;code&gt;normalize=False&lt;/code&gt;.</source>
          <target state="translated">Si es verdadero, los regresores X se normalizar&amp;aacute;n antes de la regresi&amp;oacute;n. Este par&amp;aacute;metro se ignora cuando &lt;code&gt;fit_intercept&lt;/code&gt; se establece en False. Cuando los regresores est&amp;aacute;n normalizados, tenga en cuenta que esto hace que los hiperpar&amp;aacute;metros aprendidos sean m&amp;aacute;s robustos y casi independientes del n&amp;uacute;mero de muestras. La misma propiedad no es v&amp;aacute;lida para datos estandarizados. Sin embargo, si desea estandarizar, use &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; antes de llamar a &lt;code&gt;fit&lt;/code&gt; en un estimador con &lt;code&gt;normalize=False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="016e8fefc2c3108a2b7a4351de86dada7ecbd68e" translate="yes" xml:space="preserve">
          <source>If True, the regressors X will be normalized before regression. This parameter is ignored when &lt;code&gt;fit_intercept&lt;/code&gt; is set to False. When the regressors are normalized, note that this makes the hyperparameters learnt more robust and almost independent of the number of samples. The same property is not valid for standardized data. However, if you wish to standardize, please use &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; before calling &lt;code&gt;fit&lt;/code&gt; on an estimator with &lt;code&gt;normalize=False&lt;/code&gt;.</source>
          <target state="translated">Si es verdadero, los regresores X se normalizar&amp;aacute;n antes de la regresi&amp;oacute;n. Este par&amp;aacute;metro se ignora cuando &lt;code&gt;fit_intercept&lt;/code&gt; se establece en False. Cuando los regresores est&amp;aacute;n normalizados, tenga en cuenta que esto hace que los hiperpar&amp;aacute;metros aprendidos sean m&amp;aacute;s robustos y casi independientes del n&amp;uacute;mero de muestras. La misma propiedad no es v&amp;aacute;lida para datos estandarizados. Sin embargo, si desea estandarizar, use &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; antes de llamar a &lt;code&gt;fit&lt;/code&gt; en un estimador con &lt;code&gt;normalize=False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c3fdb7e36f654834d666d698b8cb7219451a4481" translate="yes" xml:space="preserve">
          <source>If True, the return value will be an array of integers, rather than a boolean mask.</source>
          <target state="translated">Si es cierto,el valor de retorno será un conjunto de números enteros,en lugar de una máscara booleana.</target>
        </trans-unit>
        <trans-unit id="d17d4bbcdf2df4ef33c01a7114516c2e4e90d7d8" translate="yes" xml:space="preserve">
          <source>If True, the standard-deviation of the predictive distribution at the query points is returned along with the mean.</source>
          <target state="translated">Si es cierto,la desviación estándar de la distribución predictiva en los puntos de consulta se devuelve junto con la media.</target>
        </trans-unit>
        <trans-unit id="3f294130716f356d91654999eee9757bd2ba6c1c" translate="yes" xml:space="preserve">
          <source>If True, the support of robust location and covariance estimates is computed, and a covariance estimate is recomputed from it, without centering the data. Useful to work with data whose mean is significantly equal to zero but is not exactly zero. If False, the robust location and covariance are directly computed with the FastMCD algorithm without additional treatment.</source>
          <target state="translated">Si es cierto,se calcula el apoyo de las estimaciones robustas de localización y covarianza,y se vuelve a calcular una estimación de covarianza a partir de ella,sin centrar los datos.Es útil para trabajar con datos cuya media es significativamente igual a cero pero no es exactamente cero.Si es falso,la localización robusta y la covarianza se calculan directamente con el algoritmo FastMCD sin tratamiento adicional.</target>
        </trans-unit>
        <trans-unit id="667a36b1a1b94aa0d760aa610f277fcd1918ae0a" translate="yes" xml:space="preserve">
          <source>If True, the support of the robust location and the covariance estimates is computed, and a covariance estimate is recomputed from it, without centering the data. Useful to work with data whose mean is significantly equal to zero but is not exactly zero. If False, the robust location and covariance are directly computed with the FastMCD algorithm without additional treatment.</source>
          <target state="translated">Si es cierto,se calcula el apoyo de la ubicación robusta y las estimaciones de covarianza,y se vuelve a calcular una estimación de covarianza a partir de ella,sin centrar los datos.Es útil para trabajar con datos cuya media es significativamente igual a cero pero no es exactamente cero.Si es falso,la localización robusta y la covarianza se calculan directamente con el algoritmo FastMCD sin tratamiento adicional.</target>
        </trans-unit>
        <trans-unit id="28346b69fb6f1a64d688b2ef42aabb524b6563d8" translate="yes" xml:space="preserve">
          <source>If True, then X will be converted to a 2-dimensional NumPy array or sparse matrix. If the conversion is not possible an exception is raised.</source>
          <target state="translated">Si es True,entonces X se convertirá en una matriz NumPy bidimensional o matriz dispersa.Si la conversión no es posible,se plantea una excepción.</target>
        </trans-unit>
        <trans-unit id="5c0fef9c1e6748fc4d3cb84e62459147a039a4fd" translate="yes" xml:space="preserve">
          <source>If True, then all components with zero eigenvalues are removed, so that the number of components in the output may be &amp;lt; n_components (and sometimes even zero due to numerical instability). When n_components is None, this parameter is ignored and components with zero eigenvalues are removed regardless.</source>
          <target state="translated">Si es Verdadero, entonces se eliminan todos los componentes con valores propios cero, de modo que el n&amp;uacute;mero de componentes en la salida puede ser &amp;lt;n_components (y algunas veces incluso cero debido a la inestabilidad num&amp;eacute;rica). Cuando n_components es None, este par&amp;aacute;metro se ignora y los componentes con valores propios cero se eliminan independientemente.</target>
        </trans-unit>
        <trans-unit id="42874c4e7adb064c98a0fb44835161462f985220" translate="yes" xml:space="preserve">
          <source>If True, then compute normalized Laplacian.</source>
          <target state="translated">Si es cierto,entonces computa el laplaciano normalizado.</target>
        </trans-unit>
        <trans-unit id="7818bd11ce52f2496690f2a19701e1fdc3bace9d" translate="yes" xml:space="preserve">
          <source>If True, transpose the downloaded data array.</source>
          <target state="translated">Si es cierto,transponga la matriz de datos descargada.</target>
        </trans-unit>
        <trans-unit id="09f8cdcb36703e0413a45867eb062d48bc42e4a4" translate="yes" xml:space="preserve">
          <source>If True, validation for finiteness will be skipped, saving time, but leading to potential crashes. If False, validation for finiteness will be performed, avoiding error. Global default: False.</source>
          <target state="translated">Si es cierto,la validación de la finitud se omitirá,ahorrando tiempo,pero conduciendo a posibles accidentes.Si es falso,la validación de la finitud se realizará,evitando errores.Predeterminado global:Falso.</target>
        </trans-unit>
        <trans-unit id="f770d204acb3934762188e63b6bd0977cfe619aa" translate="yes" xml:space="preserve">
          <source>If True, will return the parameters for this estimator and contained subobjects that are estimators.</source>
          <target state="translated">Si es cierto,devolverá los parámetros para este estimador y los subobjetos contenidos que son estimadores.</target>
        </trans-unit>
        <trans-unit id="edc518974aa9f8ea115d0f36469bc2b1e2cd15a2" translate="yes" xml:space="preserve">
          <source>If True, will return the query_id array for each file.</source>
          <target state="translated">Si es True,devolverá la matriz query_id de cada archivo.</target>
        </trans-unit>
        <trans-unit id="80fdba1026cc980884a84dfa72ad1747c034afc6" translate="yes" xml:space="preserve">
          <source>If X and y are not C-ordered and contiguous arrays of np.float64 and X is not a scipy.sparse.csr_matrix, X and/or y may be copied.</source>
          <target state="translated">Si X e y no están ordenados por C y los arreglos contiguos de np.float64 y X no es una scipy.sparse.csr_matrix,X y/o y pueden ser copiados.</target>
        </trans-unit>
        <trans-unit id="a601440183ce5a872479c357e441563196aab652" translate="yes" xml:space="preserve">
          <source>If X is a dense array, then the other methods will not support sparse matrices as input.</source>
          <target state="translated">Si X es una matriz densa,entonces los otros métodos no soportarán matrices escasas como entrada.</target>
        </trans-unit>
        <trans-unit id="efab9063b47a2afb85758f067069188b21b34f3e" translate="yes" xml:space="preserve">
          <source>If X is encoded as a CSR matrix.</source>
          <target state="translated">Si X está codificado como una matriz CSR.</target>
        </trans-unit>
        <trans-unit id="da96e9fabf18fc39905756390120e4a7a1e09f97" translate="yes" xml:space="preserve">
          <source>If X is not a C-ordered contiguous array it is copied.</source>
          <target state="translated">Si X no es una matriz contigua ordenada por C,se copia.</target>
        </trans-unit>
        <trans-unit id="9cc8f34afbd30e04cc65d91f1b233abc1c382996" translate="yes" xml:space="preserve">
          <source>If X is not an array of floating values;</source>
          <target state="translated">Si X no es un conjunto de valores flotantes;</target>
        </trans-unit>
        <trans-unit id="e7ca7ce1d419c3d60265041304210343f2e8b91d" translate="yes" xml:space="preserve">
          <source>If X is our multivariate data, then the problem that we are trying to solve is to rewrite it on a different observational basis: we want to learn loadings L and a set of components C such that &lt;em&gt;X = L C&lt;/em&gt;. Different criteria exist to choose the components</source>
          <target state="translated">Si X son nuestros datos multivariados, entonces el problema que estamos tratando de resolver es reescribirlo sobre una base de observaci&amp;oacute;n diferente: queremos aprender las cargas L y un conjunto de componentes C tales que &lt;em&gt;X = LC&lt;/em&gt; . Existen diferentes criterios para elegir los componentes</target>
        </trans-unit>
        <trans-unit id="4691b6eeb6f44a63af5f24ac30dc066ab023aa61" translate="yes" xml:space="preserve">
          <source>If X is sparse and &lt;code&gt;missing_values=0&lt;/code&gt;;</source>
          <target state="translated">Si X es escasa y &lt;code&gt;missing_values=0&lt;/code&gt; ;</target>
        </trans-unit>
        <trans-unit id="5bf131136f9283115170d3f032466f07678834a5" translate="yes" xml:space="preserve">
          <source>If Y is given (default is None), then the returned matrix is the pairwise distance between the arrays from both X and Y.</source>
          <target state="translated">Si se da Y (por defecto es Ninguno),entonces la matriz devuelta es la distancia en pares entre las matrices de X e Y.</target>
        </trans-unit>
        <trans-unit id="a6e7fe3e345be28d5e67984fa49ad01aeaa444dd" translate="yes" xml:space="preserve">
          <source>If Y is given (default is None), then the returned matrix is the pairwise kernel between the arrays from both X and Y.</source>
          <target state="translated">Si se da Y (por defecto es Ninguno),entonces la matriz devuelta es el núcleo en par entre las matrices de X e Y.</target>
        </trans-unit>
        <trans-unit id="15e0fd61e3b85d8ebad2fc2135f6d5822723ce41" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}\) is the estimated target output, \(y\) the corresponding (correct) target output, and \(Var\) is &lt;a href=&quot;https://en.wikipedia.org/wiki/Variance&quot;&gt;Variance&lt;/a&gt;, the square of the standard deviation, then the explained variance is estimated as follow:</source>
          <target state="translated">Si \ (\ hat {y} \) es el resultado objetivo estimado, \ (y \) el resultado objetivo correspondiente (correcto) y \ (Var \) es la &lt;a href=&quot;https://en.wikipedia.org/wiki/Variance&quot;&gt;varianza&lt;/a&gt; , el cuadrado de la desviaci&amp;oacute;n est&amp;aacute;ndar, entonces la varianza explicada es estimado de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="c8fb389b8a60a2b57fc22c9161412c484a73dd18" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value, then the 0-1 loss \(L_{0-1}\) is defined as:</source>
          <target state="translated">Si es el valor predicho de la muestra y es el valor real correspondiente,entonces la pérdida de 0-1 se define como..:</target>
        </trans-unit>
        <trans-unit id="01fda7f04ce93ad5d6b5843c80c53ee91e04866d" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value, then the fraction of correct predictions over \(n_\text{samples}\) is defined as</source>
          <target state="translated">Si es el valor predicho de la muestra y es el valor verdadero correspondiente,entonces la fracción de predicciones correctas sobre las muestras se define como</target>
        </trans-unit>
        <trans-unit id="af46aeec0a0c654990b43c84ec26ca8a3817bbd3" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value, then the median absolute error (MedAE) estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="translated">Si es el valor predicho de la muestra y es el valor verdadero correspondiente,entonces el error absoluto medio (MedAE)estimado sobre las muestras se define como</target>
        </trans-unit>
        <trans-unit id="27ab05c62dcfc0b1ca98228a2c106c2bd25d72f6" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value, then the score R&amp;sup2; estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="translated">Si \ (\ hat {y} _i \) es el valor predicho de la \ (i \) - &amp;eacute;sima muestra y \ (y_i \) es el valor verdadero correspondiente, entonces la puntuaci&amp;oacute;n R&amp;sup2; estimada sobre \ (n _ {\ text { samples}} \) se define como</target>
        </trans-unit>
        <trans-unit id="e9be139031431f33624d9549cf24272bbec27cad" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the mean absolute error (MAE) estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="translated">Si es el valor predicho de la muestra,y es el valor verdadero correspondiente,entonces el error absoluto medio (MAE)estimado sobre las muestras se define como</target>
        </trans-unit>
        <trans-unit id="b7836e2114e345225a74c22cbe0d3b5d52c8f253" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the mean squared error (MSE) estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="translated">Si es el valor predicho de la muestra,y es el valor verdadero correspondiente,entonces el error cuadrado medio (MSE)estimado sobre las muestras se define como</target>
        </trans-unit>
        <trans-unit id="1cf47fc0a0aaaffd1c0a818b8704218b8ae722c1" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the mean squared logarithmic error (MSLE) estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="translated">Si es el valor predicho de la muestra,y es el valor real correspondiente,entonces el error logarítmico cuadrado medio (MSLE)estimado sobre las muestras se define como</target>
        </trans-unit>
        <trans-unit id="f295fa8851d145ac326bc63b92809e2fbf3d1f72" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_j\) is the predicted value for the \(j\)-th label of a given sample, \(y_j\) is the corresponding true value, and \(n_\text{labels}\) is the number of classes or labels, then the Hamming loss \(L_{Hamming}\) between two samples is defined as:</source>
          <target state="translated">Si \ ~ es el valor predicho para la etiqueta de una muestra dada,es el valor verdadero correspondiente,y el número de clases o etiquetas,entonces la pérdida de Hamming \ ~ entre dos muestras se define como:</target>
        </trans-unit>
        <trans-unit id="7fa4bf510f83c73a55e8dec038abaacf960351ca" translate="yes" xml:space="preserve">
          <source>If \(c_0 = 0\) the kernel is said to be homogeneous.</source>
          <target state="translated">Si \(c_0=0\)se dice que el núcleo es homogéneo.</target>
        </trans-unit>
        <trans-unit id="c7d07701826b4f4c8efa455b46a49990993930f2" translate="yes" xml:space="preserve">
          <source>If \(h_i\) is given, the above equation automatically implies the following probabilistic interpretation:</source>
          <target state="translated">Si se da \N la ecuación anterior implica automáticamente la siguiente interpretación probabilística:</target>
        </trans-unit>
        <trans-unit id="9d9af8bc9b90a6fbf0d539b126efbd694bdaddf6" translate="yes" xml:space="preserve">
          <source>If \(y_i\) is the true value of the \(i\)-th sample, and \(w_i\) is the corresponding sample weight, then we adjust the sample weight to:</source>
          <target state="translated">Si \ ~ es el verdadero valor de la muestra,y \ ~ es el peso de la muestra correspondiente,entonces ajustamos el peso de la muestra a:</target>
        </trans-unit>
        <trans-unit id="4c76ddad0ef7a743f202685a0861880cbc2062e2" translate="yes" xml:space="preserve">
          <source>If \(y_w\) is the predicted decision for true label and \(y_t\) is the maximum of the predicted decisions for all other labels, where predicted decisions are output by decision function, then multiclass hinge loss is defined by:</source>
          <target state="translated">Si \(y_w\)es la decisión pronosticada para la etiqueta verdadera y \(y_t\)es el máximo de las decisiones pronosticadas para todas las demás etiquetas,donde las decisiones pronosticadas se producen por la función de decisión,entonces la pérdida de bisagra multiclase se define por:</target>
        </trans-unit>
        <trans-unit id="b8371056060d53aef38082b274a12c6e92dd981b" translate="yes" xml:space="preserve">
          <source>If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by accept_sparse, accept_large_sparse will cause it to be accepted only if its indices are stored with a 32-bit dtype.</source>
          <target state="translated">Si se suministra una matriz dispersa CSR,CSC,COO o BSR y es aceptada por accept_sparse,accept_large_sparse hará que sea aceptada sólo si sus índices se almacenan con un tipo d de 32 bits.</target>
        </trans-unit>
        <trans-unit id="ca2f554a4272574081b19f205bd8db66223aa9f8" translate="yes" xml:space="preserve">
          <source>If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by accept_sparse, accept_large_sparse=False will cause it to be accepted only if its indices are stored with a 32-bit dtype.</source>
          <target state="translated">Si se suministra una matriz dispersa CSR,CSC,COO o BSR y es aceptada por accept_sparse,accept_large_sparse=False hará que sea aceptada sólo si sus índices se almacenan con un tipo de 32 bits.</target>
        </trans-unit>
        <trans-unit id="b0090a224443cfea422c2167734e98ec705e71a5" translate="yes" xml:space="preserve">
          <source>If a callable is passed it is used to extract the sequence of features out of the raw, unprocessed input.</source>
          <target state="translated">Si se pasa una llamada se utiliza para extraer la secuencia de características de la entrada sin procesar.</target>
        </trans-unit>
        <trans-unit id="dcd8eacb988e0fa27afa1a7692943530b07747f6" translate="yes" xml:space="preserve">
          <source>If a callable is passed, it should take arguments X, k and and a random state and return an initialization.</source>
          <target state="translated">Si se pasa una llamada,debería tomar los argumentos X,k y y un estado aleatorio y devolver una inicialización.</target>
        </trans-unit>
        <trans-unit id="15b5ddf5d35e7b6d7436896e31247316b726ba30" translate="yes" xml:space="preserve">
          <source>If a float, that value is added to all values in the contingency matrix. This helps to stop NaN propagation. If &lt;code&gt;None&lt;/code&gt;, nothing is adjusted.</source>
          <target state="translated">Si es flotante, ese valor se agrega a todos los valores en la matriz de contingencia. Esto ayuda a detener la propagaci&amp;oacute;n de NaN. Si es &lt;code&gt;None&lt;/code&gt; , no se ajusta nada.</target>
        </trans-unit>
        <trans-unit id="aec58020de2b924f9656034ee47c95a7ace302db" translate="yes" xml:space="preserve">
          <source>If a list is passed it&amp;rsquo;s expected to be one of n_targets such arrays. The varying values of the coefficients along the path. It is not present if the &lt;code&gt;fit_path&lt;/code&gt; parameter is &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">Si se pasa una lista, se espera que sea uno de los n_targets de tales matrices. Los valores variables de los coeficientes a lo largo del camino. No est&amp;aacute; presente si el par&amp;aacute;metro &lt;code&gt;fit_path&lt;/code&gt; es &lt;code&gt;False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8e3b6cd9422926a607fefd39c3e9bd3020c06d14" translate="yes" xml:space="preserve">
          <source>If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens. Only applies if &lt;code&gt;analyzer == 'word'&lt;/code&gt;.</source>
          <target state="translated">Si es una lista, se supone que esa lista contiene palabras vac&amp;iacute;as, todas las cuales se eliminar&amp;aacute;n de los tokens resultantes. Solo se aplica si &lt;code&gt;analyzer == 'word'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="58d1b02436a7aa9160e580f582400827e1ad046d" translate="yes" xml:space="preserve">
          <source>If a string, it is passed to _check_stop_list and the appropriate stop list is returned. &amp;lsquo;english&amp;rsquo; is currently the only supported string value. There are several known issues with &amp;lsquo;english&amp;rsquo; and you should consider an alternative (see &lt;a href=&quot;../feature_extraction#stop-words&quot;&gt;Using stop words&lt;/a&gt;).</source>
          <target state="translated">Si es una cadena, se pasa a _check_stop_list y se devuelve la lista de detenci&amp;oacute;n correspondiente. 'english' es actualmente el &amp;uacute;nico valor de cadena admitido. Hay varios problemas conocidos con 'ingl&amp;eacute;s' y deber&amp;iacute;a considerar una alternativa (consulte &lt;a href=&quot;../feature_extraction#stop-words&quot;&gt;Uso de palabras vac&amp;iacute;as&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="564b43bc82acf22a1de3b85bb28ac591ff97b4bf" translate="yes" xml:space="preserve">
          <source>If a string, this may be one of &amp;lsquo;nearest_neighbors&amp;rsquo;, &amp;lsquo;precomputed&amp;rsquo;, &amp;lsquo;rbf&amp;rsquo; or one of the kernels supported by &lt;code&gt;sklearn.metrics.pairwise_kernels&lt;/code&gt;.</source>
          <target state="translated">Si es una cadena, puede ser uno de los 'vecinos_m&amp;aacute;s cercanos', 'precalculados', 'rbf' o uno de los n&amp;uacute;cleos admitidos por &lt;code&gt;sklearn.metrics.pairwise_kernels&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="675cbfc234c52633edd36cba3388cd72c1b8e2d3" translate="yes" xml:space="preserve">
          <source>If a target is a classification outcome taking on values 0,1,&amp;hellip;,K-1, for node \(m\), representing a region \(R_m\) with \(N_m\) observations, let</source>
          <target state="translated">Si un objetivo es un resultado de clasificaci&amp;oacute;n que toma valores 0,1,&amp;hellip;, K-1, para el nodo \ (m \), que representa una regi&amp;oacute;n \ (R_m \) con \ (N_m \) observaciones, sea</target>
        </trans-unit>
        <trans-unit id="373500a68bbbd934744d157d24ba37240f790a20" translate="yes" xml:space="preserve">
          <source>If affinity is &amp;ldquo;precomputed&amp;rdquo; X : array-like, shape (n_samples, n_samples), Interpret X as precomputed adjacency graph computed from samples.</source>
          <target state="translated">Si la afinidad est&amp;aacute; &quot;precalculada&quot; X: similar a una matriz, forma (n_samples, n_samples), interprete X como un gr&amp;aacute;fico de adyacencia precalculado calculado a partir de muestras.</target>
        </trans-unit>
        <trans-unit id="c306493486d7abaed871db69a1b0f3a0d3e230f4" translate="yes" xml:space="preserve">
          <source>If affinity is the adjacency matrix of a graph, this method can be used to find normalized graph cuts.</source>
          <target state="translated">Si la afinidad es la matriz de adyacencia de un gráfico,este método puede utilizarse para encontrar cortes de gráfico normalizados.</target>
        </trans-unit>
        <trans-unit id="fef3ba1186af33eef8e244a6a4bb530d43ffdf84" translate="yes" xml:space="preserve">
          <source>If all examples are from the same class, it uses a one-class SVM.</source>
          <target state="translated">Si todos los ejemplos son de la misma clase,utiliza un SVM de una clase.</target>
        </trans-unit>
        <trans-unit id="b53805960d76925767243aca9c19243fc1b08d06" translate="yes" xml:space="preserve">
          <source>If all parameters are presented as a list, sampling without replacement is performed. If at least one parameter is given as a distribution, sampling with replacement is used. It is highly recommended to use continuous distributions for continuous parameters.</source>
          <target state="translated">Si todos los parámetros se presentan en forma de lista,se realiza un muestreo sin sustitución.Si al menos un parámetro se presenta como una distribución,se utiliza el muestreo con sustitución.Se recomienda encarecidamente utilizar distribuciones continuas para los parámetros continuos.</target>
        </trans-unit>
        <trans-unit id="4f219d1953670922fbbfe88159427df7222c9397" translate="yes" xml:space="preserve">
          <source>If an algorithm, such as a linear support vector machine or PCA, relies only on the scalar product of data points \(x_i\), one may use the value of \(k(x_i, x_j)\), which corresponds to applying the algorithm to the mapped data points \(\phi(x_i)\). The advantage of using \(k\) is that the mapping \(\phi\) never has to be calculated explicitly, allowing for arbitrary large features (even infinite).</source>
          <target state="translated">Si un algoritmo,como una máquina de vector de soporte lineal o PCA,se basa sólo en el producto escalar de los puntos de datos \(x_i\),se puede utilizar el valor de \(k(x_i,x_j)\),que corresponde a la aplicación del algoritmo a los puntos de datos mapeados \N(\phi(x_i)\N).La ventaja de usar \N \N \N es que el mapeo \N \N nunca tiene que ser calculado explícitamente,permitiendo grandes características arbitrarias (incluso infinitas).</target>
        </trans-unit>
        <trans-unit id="9fea95f95d0577b3d2b8dde1c99a4f5f11240b1d" translate="yes" xml:space="preserve">
          <source>If an exception is triggered, use &lt;code&gt;%debug&lt;/code&gt; to fire-up a post mortem ipdb session.</source>
          <target state="translated">Si se activa una excepci&amp;oacute;n, utilice &lt;code&gt;%debug&lt;/code&gt; para iniciar una sesi&amp;oacute;n ipdb post mortem.</target>
        </trans-unit>
        <trans-unit id="5c4a826b768bf0ea44b0de0cf9a279c59410da1d" translate="yes" xml:space="preserve">
          <source>If an integer is given, it fixes the number of points on the grids of alpha to be used. If a list is given, it gives the grid to be used. See the notes in the class docstring for more details.</source>
          <target state="translated">Si se da un número entero,se fija el número de puntos en las cuadrículas de alfa a utilizar.Si se da una lista,da la cuadrícula a ser utilizada.Vea las notas de la clase docstring para más detalles.</target>
        </trans-unit>
        <trans-unit id="3f54c86c80b29ba93fdb4405121f2a742f42412e" translate="yes" xml:space="preserve">
          <source>If an ndarray is passed, it should be of shape (n_clusters, n_features) and gives the initial centers.</source>
          <target state="translated">Si se pasa un ndarray,debe tener forma (n_clusters,n_features)y da los centros iniciales.</target>
        </trans-unit>
        <trans-unit id="7bf20b6ab9e24e0313be1f29e5bd87350c62fc72" translate="yes" xml:space="preserve">
          <source>If bandwidth is not given, it is determined using a heuristic based on the median of all pairwise distances. This will take quadratic time in the number of samples. The sklearn.cluster.estimate_bandwidth function can be used to do this more efficiently.</source>
          <target state="translated">Si no se da el ancho de banda,se determina usando una heurística basada en la mediana de todas las distancias en pares.Esto tomará un tiempo cuadrático en el número de muestras.La función sklearn.cluster.estimate_banda ancha puede utilizarse para hacer esto de manera más eficiente.</target>
        </trans-unit>
        <trans-unit id="307d133eac653119e68c3f800803dcc4776573b9" translate="yes" xml:space="preserve">
          <source>If bool, then determines whether to consider all features discrete or continuous. If array, then it should be either a boolean mask with shape (n_features,) or array with indices of discrete features. If &amp;lsquo;auto&amp;rsquo;, it is assigned to False for dense &lt;code&gt;X&lt;/code&gt; and to True for sparse &lt;code&gt;X&lt;/code&gt;.</source>
          <target state="translated">Si es bool, determina si se deben considerar todas las caracter&amp;iacute;sticas como discretas o continuas. Si es una matriz, entonces deber&amp;iacute;a ser una m&amp;aacute;scara booleana con forma (n_features) o una matriz con &amp;iacute;ndices de caracter&amp;iacute;sticas discretas. Si es 'auto', se asigna a False para &lt;code&gt;X&lt;/code&gt; denso y a Verdadero para &lt;code&gt;X&lt;/code&gt; disperso .</target>
        </trans-unit>
        <trans-unit id="14d26c2cb6ccf4f84a440b5eee94360749d30490" translate="yes" xml:space="preserve">
          <source>If boolean, whether or not to fit the isotonic regression with y increasing or decreasing.</source>
          <target state="translated">Si es booleana,si encaja o no en la regresión isotónica con y aumentando o disminuyendo.</target>
        </trans-unit>
        <trans-unit id="c7380002883f78b7443a4cf144369e2cdf9c7dd5" translate="yes" xml:space="preserve">
          <source>If bytes or files are given to analyze, this encoding is used to decode.</source>
          <target state="translated">Si se dan bytes o archivos para analizar,esta codificación se utiliza para decodificar.</target>
        </trans-unit>
        <trans-unit id="b1cd46fc8b5b18d3d8ec258c92a5832fe49ecb69" translate="yes" xml:space="preserve">
          <source>If classes members are completely split across different clusters, the assignment is totally in-complete, hence the AMI is null:</source>
          <target state="translated">Si los miembros de las clases están completamente divididos en diferentes grupos,la asignación está totalmente incompleta,por lo que el AMI es nulo:</target>
        </trans-unit>
        <trans-unit id="e6f2dbc2c288fdff952bc5d6d0612fad044f50c2" translate="yes" xml:space="preserve">
          <source>If classes members are completely split across different clusters, the assignment is totally in-complete, hence the NMI is null:</source>
          <target state="translated">Si los miembros de las clases están completamente divididos en diferentes grupos,la asignación está totalmente incompleta,por lo tanto el NMI es nulo:</target>
        </trans-unit>
        <trans-unit id="60b93fba5d2befe30dad173ef2989a32caf2707d" translate="yes" xml:space="preserve">
          <source>If classes members are completely split across different clusters, the assignment is totally incomplete, hence the ARI is very low:</source>
          <target state="translated">Si los miembros de las clases están completamente divididos en diferentes grupos,la asignación es totalmente incompleta,por lo que el ARI es muy bajo:</target>
        </trans-unit>
        <trans-unit id="e02bb35b2a969fdf2ff25b865a0b3ba938fb92a9" translate="yes" xml:space="preserve">
          <source>If classes members are completely split across different clusters, the assignment is totally incomplete, hence the V-Measure is null:</source>
          <target state="translated">Si los miembros de las clases están completamente divididos en diferentes grupos,la asignación es totalmente incompleta,por lo que la medida V es nula:</target>
        </trans-unit>
        <trans-unit id="d0974a75f074fb11fd0a08f495fdb803227dd0c6" translate="yes" xml:space="preserve">
          <source>If classes members are completely split across different clusters, the assignment is totally random, hence the FMI is null:</source>
          <target state="translated">Si los miembros de las clases están completamente divididos en diferentes grupos,la asignación es totalmente aleatoria,por lo que el FMI es nulo:</target>
        </trans-unit>
        <trans-unit id="3a4c44f6cadbe5141305e79bc3f8068062652c4d" translate="yes" xml:space="preserve">
          <source>If classes members are split across different clusters, the assignment cannot be complete:</source>
          <target state="translated">Si los miembros de las clases se dividen en diferentes grupos,la tarea no puede ser completada:</target>
        </trans-unit>
        <trans-unit id="baf96abe9df5cd386826eafcd47454c9dcc36819" translate="yes" xml:space="preserve">
          <source>If copy is False, the affinity matrix is modified inplace by the algorithm, for memory efficiency</source>
          <target state="translated">Si la copia es falsa,la matriz de afinidad se modifica en el lugar por el algoritmo,para la eficiencia de la memoria</target>
        </trans-unit>
        <trans-unit id="671e4e16873255449d2ba54f06975c272f73c34d" translate="yes" xml:space="preserve">
          <source>If density = &amp;lsquo;auto&amp;rsquo;, the value is set to the minimum density as recommended by Ping Li et al.: 1 / sqrt(n_features).</source>
          <target state="translated">Si densidad = 'auto', el valor se establece en la densidad m&amp;iacute;nima recomendada por Ping Li et al .: 1 / sqrt (n_features).</target>
        </trans-unit>
        <trans-unit id="391517cb3cfce3ac9c6c32b7ceac049807282afc" translate="yes" xml:space="preserve">
          <source>If documents are pre-tokenized by an external package, then store them in files (or strings) with the tokens separated by whitespace and pass &lt;code&gt;analyzer=str.split&lt;/code&gt;</source>
          <target state="translated">Si los documentos est&amp;aacute;n pre-tokenizados por un paquete externo, gu&amp;aacute;rdelos en archivos (o cadenas) con los tokens separados por espacios en blanco y pase &lt;code&gt;analyzer=str.split&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="80416b24b5f24b22b80d50d90aa942e77a2dadfc" translate="yes" xml:space="preserve">
          <source>If each row and each column belongs to exactly one bicluster, then rearranging the rows and columns of the data matrix reveals the biclusters on the diagonal. Here is an example of this structure where biclusters have higher average values than the other rows and columns:</source>
          <target state="translated">Si cada fila y cada columna pertenece exactamente a un biclustro,entonces al reorganizar las filas y columnas de la matriz de datos se revelan los biclustros en la diagonal.He aquí un ejemplo de esta estructura en la que los bíceps tienen valores medios más altos que las otras filas y columnas:</target>
        </trans-unit>
        <trans-unit id="1db9c10662b6d49b6b84ca8b7b7ce2a9580afa10" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. By default (the parameter is unspecified), the value is set to 0.1. The default will change in version 0.21. It will remain 0.1 only if &lt;code&gt;train_size&lt;/code&gt; is unspecified, otherwise it will complement the specified &lt;code&gt;train_size&lt;/code&gt;.</source>
          <target state="translated">Si es flotante, debe estar entre 0.0 y 1.0 y representar la proporci&amp;oacute;n del conjunto de datos para incluir en la divisi&amp;oacute;n de prueba. Si es int, representa el n&amp;uacute;mero absoluto de muestras de prueba. Si es Ninguno, el valor se establece como complemento del tama&amp;ntilde;o del tren. De forma predeterminada (el par&amp;aacute;metro no est&amp;aacute; especificado), el valor se establece en 0,1. El valor predeterminado cambiar&amp;aacute; en la versi&amp;oacute;n 0.21. Seguir&amp;aacute; siendo 0.1 solo si &lt;code&gt;train_size&lt;/code&gt; no est&amp;aacute; especificado, de lo contrario complementar&amp;aacute; el &lt;code&gt;train_size&lt;/code&gt; especificado .</target>
        </trans-unit>
        <trans-unit id="73ce93bb920d84bef49715afdf02f771938f8206" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. By default, the value is set to 0.1. The default will change in version 0.21. It will remain 0.1 only if &lt;code&gt;train_size&lt;/code&gt; is unspecified, otherwise it will complement the specified &lt;code&gt;train_size&lt;/code&gt;.</source>
          <target state="translated">Si es flotante, debe estar entre 0.0 y 1.0 y representar la proporci&amp;oacute;n del conjunto de datos para incluir en la divisi&amp;oacute;n de prueba. Si es int, representa el n&amp;uacute;mero absoluto de muestras de prueba. Si es Ninguno, el valor se establece como complemento del tama&amp;ntilde;o del tren. De forma predeterminada, el valor se establece en 0,1. El valor predeterminado cambiar&amp;aacute; en la versi&amp;oacute;n 0.21. Seguir&amp;aacute; siendo 0.1 solo si &lt;code&gt;train_size&lt;/code&gt; no est&amp;aacute; especificado, de lo contrario complementar&amp;aacute; el &lt;code&gt;train_size&lt;/code&gt; especificado .</target>
        </trans-unit>
        <trans-unit id="aa74ab3ce21513c4e7c83e9b91dad63582c835b8" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. By default, the value is set to 0.2. The default will change in version 0.21. It will remain 0.2 only if &lt;code&gt;train_size&lt;/code&gt; is unspecified, otherwise it will complement the specified &lt;code&gt;train_size&lt;/code&gt;.</source>
          <target state="translated">Si es flotante, debe estar entre 0.0 y 1.0 y representar la proporci&amp;oacute;n del conjunto de datos para incluir en la divisi&amp;oacute;n de prueba. Si es int, representa el n&amp;uacute;mero absoluto de muestras de prueba. Si es Ninguno, el valor se establece como complemento del tama&amp;ntilde;o del tren. De forma predeterminada, el valor se establece en 0,2. El valor predeterminado cambiar&amp;aacute; en la versi&amp;oacute;n 0.21. Seguir&amp;aacute; siendo 0.2 solo si &lt;code&gt;train_size&lt;/code&gt; no est&amp;aacute; especificado, de lo contrario complementar&amp;aacute; el &lt;code&gt;train_size&lt;/code&gt; especificado .</target>
        </trans-unit>
        <trans-unit id="dfe0bc4ba0825c6b9e54b3177711e714d6e28a2b" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. By default, the value is set to 0.25. The default will change in version 0.21. It will remain 0.25 only if &lt;code&gt;train_size&lt;/code&gt; is unspecified, otherwise it will complement the specified &lt;code&gt;train_size&lt;/code&gt;.</source>
          <target state="translated">Si es flotante, debe estar entre 0.0 y 1.0 y representar la proporci&amp;oacute;n del conjunto de datos para incluir en la divisi&amp;oacute;n de prueba. Si es int, representa el n&amp;uacute;mero absoluto de muestras de prueba. Si es Ninguno, el valor se establece como complemento del tama&amp;ntilde;o del tren. De forma predeterminada, el valor se establece en 0,25. El valor predeterminado cambiar&amp;aacute; en la versi&amp;oacute;n 0.21. Seguir&amp;aacute; siendo 0.25 solo si &lt;code&gt;train_size&lt;/code&gt; no est&amp;aacute; especificado, de lo contrario complementar&amp;aacute; el &lt;code&gt;train_size&lt;/code&gt; especificado .</target>
        </trans-unit>
        <trans-unit id="a3b7da8f21403a8e0fce55a369b8d82b4da5bfd1" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split. If int, represents the absolute number of train samples. If None, the value is automatically set to the complement of the test size.</source>
          <target state="translated">Si flota,debe estar entre 0,0 y 1,0 y representar la proporción del conjunto de datos a incluir en la división del tren.Si int,representa el número absoluto de muestras de tren.Si none,el valor se ajusta automáticamente al complemento del tamaño de la prueba.</target>
        </trans-unit>
        <trans-unit id="62b47f7a89d7c976d2813299381cdc4f4f5b3cad" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the groups to include in the train split. If int, represents the absolute number of train groups. If None, the value is automatically set to the complement of the test size.</source>
          <target state="translated">Si flota,debe estar entre 0,0 y 1,0 y representar la proporción de los grupos a incluir en la división del tren.Si int,representa el número absoluto de grupos de trenes.Si none,el valor se ajusta automáticamente al complemento del tamaño de la prueba.</target>
        </trans-unit>
        <trans-unit id="b0ffbda1c59db43809cf9245f33efa45a65a5c05" translate="yes" xml:space="preserve">
          <source>If float, then &lt;code&gt;max_features&lt;/code&gt; is a fraction and &lt;code&gt;int(max_features * n_features)&lt;/code&gt; features are considered at each split.</source>
          <target state="translated">Si es flotante, &lt;code&gt;max_features&lt;/code&gt; es una fracci&amp;oacute;n y las caracter&amp;iacute;sticas &lt;code&gt;int(max_features * n_features)&lt;/code&gt; se consideran en cada divisi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="47d0c1ebc9dc44a7018a0ce88d0d45201068f385" translate="yes" xml:space="preserve">
          <source>If float, then &lt;code&gt;min_samples_leaf&lt;/code&gt; is a fraction and &lt;code&gt;ceil(min_samples_leaf * n_samples)&lt;/code&gt; are the minimum number of samples for each node.</source>
          <target state="translated">Si es flotante, &lt;code&gt;min_samples_leaf&lt;/code&gt; es una fracci&amp;oacute;n y &lt;code&gt;ceil(min_samples_leaf * n_samples)&lt;/code&gt; es el n&amp;uacute;mero m&amp;iacute;nimo de muestras para cada nodo.</target>
        </trans-unit>
        <trans-unit id="c217707834c84f95b745c6fd735e46ef1d5cb29d" translate="yes" xml:space="preserve">
          <source>If float, then &lt;code&gt;min_samples_leaf&lt;/code&gt; is a fraction and &lt;code&gt;ceil(min_samples_leaf * n_samples)&lt;/code&gt; is the minimum number of samples for each node.</source>
          <target state="translated">Si es flotante, &lt;code&gt;min_samples_leaf&lt;/code&gt; es una fracci&amp;oacute;n y &lt;code&gt;ceil(min_samples_leaf * n_samples)&lt;/code&gt; es el n&amp;uacute;mero m&amp;iacute;nimo de muestras para cada nodo.</target>
        </trans-unit>
        <trans-unit id="f5813e9c1656f619ed6234eb86815e1c76ec9071" translate="yes" xml:space="preserve">
          <source>If float, then &lt;code&gt;min_samples_split&lt;/code&gt; is a fraction and &lt;code&gt;ceil(min_samples_split * n_samples)&lt;/code&gt; are the minimum number of samples for each split.</source>
          <target state="translated">Si es flotante, &lt;code&gt;min_samples_split&lt;/code&gt; es una fracci&amp;oacute;n y &lt;code&gt;ceil(min_samples_split * n_samples)&lt;/code&gt; es el n&amp;uacute;mero m&amp;iacute;nimo de muestras para cada divisi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="c32957ea85344bbb6b41aa874b4a5e7763ff6b76" translate="yes" xml:space="preserve">
          <source>If float, then &lt;code&gt;min_samples_split&lt;/code&gt; is a fraction and &lt;code&gt;ceil(min_samples_split * n_samples)&lt;/code&gt; is the minimum number of samples for each split.</source>
          <target state="translated">Si es flotante, &lt;code&gt;min_samples_split&lt;/code&gt; es una fracci&amp;oacute;n y &lt;code&gt;ceil(min_samples_split * n_samples)&lt;/code&gt; es el n&amp;uacute;mero m&amp;iacute;nimo de muestras para cada divisi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="81fe24c94c96599e85080c0cc195542bdb1ce722" translate="yes" xml:space="preserve">
          <source>If float, then draw &lt;code&gt;max_features * X.shape[1]&lt;/code&gt; features.</source>
          <target state="translated">Si es flotante, dibuja &lt;code&gt;max_features * X.shape[1]&lt;/code&gt; features.</target>
        </trans-unit>
        <trans-unit id="a2b1676fcae8577852e20614ce418906e2f79102" translate="yes" xml:space="preserve">
          <source>If float, then draw &lt;code&gt;max_samples * X.shape[0]&lt;/code&gt; samples.</source>
          <target state="translated">Si es flotante, entonces dibuja &lt;code&gt;max_samples * X.shape[0]&lt;/code&gt; samples.</target>
        </trans-unit>
        <trans-unit id="f234188a9694365b66e83538b40de1fa4059a074" translate="yes" xml:space="preserve">
          <source>If greater than or equal to 1, then &lt;code&gt;step&lt;/code&gt; corresponds to the (integer) number of features to remove at each iteration. If within (0.0, 1.0), then &lt;code&gt;step&lt;/code&gt; corresponds to the percentage (rounded down) of features to remove at each iteration.</source>
          <target state="translated">Si es mayor o igual que 1, el &lt;code&gt;step&lt;/code&gt; corresponde al n&amp;uacute;mero (entero) de caracter&amp;iacute;sticas que se eliminar&amp;aacute;n en cada iteraci&amp;oacute;n. Si est&amp;aacute; dentro de (0.0, 1.0), el &lt;code&gt;step&lt;/code&gt; corresponde al porcentaje (redondeado hacia abajo) de caracter&amp;iacute;sticas que se eliminar&amp;aacute;n en cada iteraci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="d3aeb6a39c457b69bdde12a943780461d08c388d" translate="yes" xml:space="preserve">
          <source>If greater than or equal to 1, then &lt;code&gt;step&lt;/code&gt; corresponds to the (integer) number of features to remove at each iteration. If within (0.0, 1.0), then &lt;code&gt;step&lt;/code&gt; corresponds to the percentage (rounded down) of features to remove at each iteration. Note that the last iteration may remove fewer than &lt;code&gt;step&lt;/code&gt; features in order to reach &lt;code&gt;min_features_to_select&lt;/code&gt;.</source>
          <target state="translated">Si es mayor o igual que 1, el &lt;code&gt;step&lt;/code&gt; corresponde al n&amp;uacute;mero (entero) de caracter&amp;iacute;sticas que se eliminar&amp;aacute;n en cada iteraci&amp;oacute;n. Si est&amp;aacute; dentro de (0.0, 1.0), entonces el &lt;code&gt;step&lt;/code&gt; corresponde al porcentaje (redondeado hacia abajo) de caracter&amp;iacute;sticas para eliminar en cada iteraci&amp;oacute;n. Tenga en cuenta que la &amp;uacute;ltima iteraci&amp;oacute;n puede eliminar menos caracter&amp;iacute;sticas de &lt;code&gt;step&lt;/code&gt; para llegar a &lt;code&gt;min_features_to_select&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1351e34960b08f78869e356e9d9129a529a17168" translate="yes" xml:space="preserve">
          <source>If in the QDA model one assumes that the covariance matrices are diagonal, then the inputs are assumed to be conditionally independent in each class, and the resulting classifier is equivalent to the Gaussian Naive Bayes classifier &lt;a href=&quot;generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt;&lt;code&gt;naive_bayes.GaussianNB&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Si en el modelo QDA se supone que las matrices de covarianza son diagonales, se supone que las entradas son condicionalmente independientes en cada clase, y el clasificador resultante es equivalente al clasificador Gaussiano Naive Bayes &lt;a href=&quot;generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt; &lt;code&gt;naive_bayes.GaussianNB&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="47884bf7f490577d7025ceb970813cb997acfc82" translate="yes" xml:space="preserve">
          <source>If init=&amp;rsquo;custom&amp;rsquo;, it is used as initial guess for the solution.</source>
          <target state="translated">Si init = 'custom', se utiliza como conjetura inicial para la soluci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="5b9c788e52ff7adb618d2b8cf3dd396e088800c8" translate="yes" xml:space="preserve">
          <source>If int, it is the total number of points equally divided among clusters. If array-like, each element of the sequence indicates the number of samples per cluster.</source>
          <target state="translated">Si int,es el número total de puntos divididos equitativamente entre los grupos.Si es array,cada elemento de la secuencia indica el número de muestras por cluster.</target>
        </trans-unit>
        <trans-unit id="2403d0bd3d2ac8c8a9756c4cde9cd9202cbe9926" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;.</source>
          <target state="translated">Si es int, random_state es la semilla usada por el generador de n&amp;uacute;meros aleatorios; Si es una instancia de RandomState, random_state es el generador de n&amp;uacute;meros aleatorios; Si es None, el generador de n&amp;uacute;meros aleatorios es la instancia de RandomState utilizada por &lt;code&gt;np.random&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="676c2454734bf9216c5797d643595f0b850b4e7a" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Note that different initializations might result in different local minima of the cost function.</source>
          <target state="translated">Si es int, random_state es la semilla usada por el generador de n&amp;uacute;meros aleatorios; Si es una instancia de RandomState, random_state es el generador de n&amp;uacute;meros aleatorios; Si es None, el generador de n&amp;uacute;meros aleatorios es la instancia de RandomState utilizada por &lt;code&gt;np.random&lt;/code&gt; . Tenga en cuenta que las diferentes inicializaciones pueden resultar en diferentes m&amp;iacute;nimos locales de la funci&amp;oacute;n de costo.</target>
        </trans-unit>
        <trans-unit id="a1933900181bd8e24f0237ebecc7a06b2ef8b486" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Only used when &lt;code&gt;svd_method&lt;/code&gt; equals &amp;lsquo;randomized&amp;rsquo;.</source>
          <target state="translated">Si es int, random_state es la semilla usada por el generador de n&amp;uacute;meros aleatorios; Si es una instancia de RandomState, random_state es el generador de n&amp;uacute;meros aleatorios; Si es None, el generador de n&amp;uacute;meros aleatorios es la instancia de RandomState utilizada por &lt;code&gt;np.random&lt;/code&gt; . Solo se usa cuando &lt;code&gt;svd_method&lt;/code&gt; es igual a 'aleatorio'.</target>
        </trans-unit>
        <trans-unit id="4914440c8828885c0b1efea7679daefd5f1e4eaf" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;eigen_solver&lt;/code&gt; == &amp;lsquo;arpack&amp;rsquo;.</source>
          <target state="translated">Si es int, random_state es la semilla usada por el generador de n&amp;uacute;meros aleatorios; Si es una instancia de RandomState, random_state es el generador de n&amp;uacute;meros aleatorios; Si es None, el generador de n&amp;uacute;meros aleatorios es la instancia de RandomState utilizada por &lt;code&gt;np.random&lt;/code&gt; . Se usa cuando &lt;code&gt;eigen_solver&lt;/code&gt; == 'arpack'.</target>
        </trans-unit>
        <trans-unit id="90657492e3c46d11fb3a1c799a4569e4854211ed" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;shuffle&lt;/code&gt; == True.</source>
          <target state="translated">Si es int, random_state es la semilla usada por el generador de n&amp;uacute;meros aleatorios; Si es una instancia de RandomState, random_state es el generador de n&amp;uacute;meros aleatorios; Si es None, el generador de n&amp;uacute;meros aleatorios es la instancia de RandomState utilizada por &lt;code&gt;np.random&lt;/code&gt; . Se usa cuando &lt;code&gt;shuffle&lt;/code&gt; == True.</target>
        </trans-unit>
        <trans-unit id="7e39c8ed74a38762200c178da772671eaa6b3f52" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;shuffle&lt;/code&gt; is True.</source>
          <target state="translated">Si es int, random_state es la semilla usada por el generador de n&amp;uacute;meros aleatorios; Si es una instancia de RandomState, random_state es el generador de n&amp;uacute;meros aleatorios; Si es None, el generador de n&amp;uacute;meros aleatorios es la instancia de RandomState utilizada por &lt;code&gt;np.random&lt;/code&gt; . Se usa cuando la &lt;code&gt;shuffle&lt;/code&gt; es True.</target>
        </trans-unit>
        <trans-unit id="636d95a8f3edcd08bb7a122de05f8944c1a330ee" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;solver&lt;/code&gt; == &amp;lsquo;arpack&amp;rsquo;.</source>
          <target state="translated">Si es int, random_state es la semilla usada por el generador de n&amp;uacute;meros aleatorios; Si es una instancia de RandomState, random_state es el generador de n&amp;uacute;meros aleatorios; Si es None, el generador de n&amp;uacute;meros aleatorios es la instancia de RandomState utilizada por &lt;code&gt;np.random&lt;/code&gt; . Se usa cuando &lt;code&gt;solver&lt;/code&gt; == 'arpack'.</target>
        </trans-unit>
        <trans-unit id="d8bb54edf7a318cb4f3734b3f7721b6c840db8b1" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;svd_solver&lt;/code&gt; == &amp;lsquo;arpack&amp;rsquo; or &amp;lsquo;randomized&amp;rsquo;.</source>
          <target state="translated">Si es int, random_state es la semilla usada por el generador de n&amp;uacute;meros aleatorios; Si es una instancia de RandomState, random_state es el generador de n&amp;uacute;meros aleatorios; Si es None, el generador de n&amp;uacute;meros aleatorios es la instancia de RandomState utilizada por &lt;code&gt;np.random&lt;/code&gt; . Se usa cuando &lt;code&gt;svd_solver&lt;/code&gt; == 'arpack' o 'randomized'.</target>
        </trans-unit>
        <trans-unit id="49fc99a0f8ec79ab5cf6633c8b91ad397447b0ae" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random. Note that this is used by subsampling and smoothing noise.</source>
          <target state="translated">Si int,random_state es la semilla utilizada por el generador de números aleatorios;Si instancia RandomState,random_state es el generador de números aleatorios;Si None,el generador de números aleatorios es la instancia RandomState utilizada por np.random.Obsérvese que se utiliza para el submuestreo y el suavizado de ruido.</target>
        </trans-unit>
        <trans-unit id="c8faba5e55a8f0e899120109354364cac8c2354b" translate="yes" xml:space="preserve">
          <source>If int, then consider &lt;code&gt;max_features&lt;/code&gt; features at each split.</source>
          <target state="translated">Si es int, entonces considere &lt;code&gt;max_features&lt;/code&gt; caracter&amp;iacute;sticas de max_features en cada divisi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="79438cfe8b8de1684467307814da6af61cdfe6ba" translate="yes" xml:space="preserve">
          <source>If int, then consider &lt;code&gt;min_samples_leaf&lt;/code&gt; as the minimum number.</source>
          <target state="translated">Si es int, entonces considere &lt;code&gt;min_samples_leaf&lt;/code&gt; como el n&amp;uacute;mero m&amp;iacute;nimo.</target>
        </trans-unit>
        <trans-unit id="69e04ca78560d3ef445be4d724f5c0cc8198187a" translate="yes" xml:space="preserve">
          <source>If int, then consider &lt;code&gt;min_samples_split&lt;/code&gt; as the minimum number.</source>
          <target state="translated">Si es int, entonces considere &lt;code&gt;min_samples_split&lt;/code&gt; como el n&amp;uacute;mero m&amp;iacute;nimo.</target>
        </trans-unit>
        <trans-unit id="a8d276c242fbe315ce14903af35e7ebf9a0c3619" translate="yes" xml:space="preserve">
          <source>If int, then draw &lt;code&gt;max_features&lt;/code&gt; features.</source>
          <target state="translated">Si es int, dibuja caracter&amp;iacute;sticas de &lt;code&gt;max_features&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0771ca4ef29dd427aac0ffda56943aa541e3af54" translate="yes" xml:space="preserve">
          <source>If int, then draw &lt;code&gt;max_samples&lt;/code&gt; samples.</source>
          <target state="translated">Si es int, entonces dibuja muestras de &lt;code&gt;max_samples&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4430c154e22158c0d6435f75a2d640312ee73ab2" translate="yes" xml:space="preserve">
          <source>If log normalization was used, all the singular vectors are meaningful. However, if independent normalization or bistochastization were used, the first singular vectors, \(u_1\) and \(v_1\). are discarded. From now on, the &amp;ldquo;first&amp;rdquo; singular vectors refers to \(u_2 \dots u_{p+1}\) and \(v_2 \dots v_{p+1}\) except in the case of log normalization.</source>
          <target state="translated">Si se utiliz&amp;oacute; la normalizaci&amp;oacute;n logar&amp;iacute;tmica, todos los vectores singulares son significativos. Sin embargo, si se usaran normalizaci&amp;oacute;n independiente o bistocastizaci&amp;oacute;n, los primeros vectores singulares, \ (u_1 \) y \ (v_1 \). se descartan. De ahora en adelante, los &amp;ldquo;primeros&amp;rdquo; vectores singulares se refieren a \ (u_2 \ dots u_ {p + 1} \) y \ (v_2 \ dots v_ {p + 1} \) excepto en el caso de la normalizaci&amp;oacute;n logar&amp;iacute;tmica.</target>
        </trans-unit>
        <trans-unit id="f38434d38fce86523bd80aac7625c65019a5f868" translate="yes" xml:space="preserve">
          <source>If max_samples is larger than the number of samples provided, all samples will be used for all trees (no sampling).</source>
          <target state="translated">Si max_samples es mayor que el número de muestras proporcionadas,todas las muestras se utilizarán para todos los árboles (sin muestreo).</target>
        </trans-unit>
        <trans-unit id="0512919782ceb898f5e82137605d37f1918f7fe8" translate="yes" xml:space="preserve">
          <source>If method == &amp;ldquo;auto&amp;rdquo;, the ratio of n_samples / n_population is used to determine which algorithm to use: If ratio is between 0 and 0.01, tracking selection is used. If ratio is between 0.01 and 0.99, numpy.random.permutation is used. If ratio is greater than 0.99, reservoir sampling is used. The order of the selected integers is undefined. If a random order is desired, the selected subset should be shuffled.</source>
          <target state="translated">Si m&amp;eacute;todo == &amp;ldquo;auto&amp;rdquo;, la proporci&amp;oacute;n de n_muestras / n_poblaci&amp;oacute;n se usa para determinar qu&amp;eacute; algoritmo usar: Si la proporci&amp;oacute;n est&amp;aacute; entre 0 y 0.01, se usa la selecci&amp;oacute;n de seguimiento. Si la relaci&amp;oacute;n est&amp;aacute; entre 0.01 y 0.99, se usa numpy.random.permutation. Si la relaci&amp;oacute;n es superior a 0,99, se utiliza el muestreo del yacimiento. El orden de los n&amp;uacute;meros enteros seleccionados no est&amp;aacute; definido. Si se desea un orden aleatorio, se debe mezclar el subconjunto seleccionado.</target>
        </trans-unit>
        <trans-unit id="aa3ae5990e2e00fef99c00cc07049cdbc9d8e931" translate="yes" xml:space="preserve">
          <source>If method == &amp;ldquo;pool&amp;rdquo;, a pool based algorithm is particularly fast, even faster than the tracking selection method. Hovewer, a vector containing the entire population has to be initialized. If n_samples ~ n_population, the reservoir sampling method is faster.</source>
          <target state="translated">Si m&amp;eacute;todo == &quot;grupo&quot;, un algoritmo basado en grupo es particularmente r&amp;aacute;pido, incluso m&amp;aacute;s r&amp;aacute;pido que el m&amp;eacute;todo de selecci&amp;oacute;n de seguimiento. Sin embargo, se debe inicializar un vector que contenga toda la poblaci&amp;oacute;n. Si n_muestras ~ n_poblaci&amp;oacute;n, el m&amp;eacute;todo de muestreo del yacimiento es m&amp;aacute;s r&amp;aacute;pido.</target>
        </trans-unit>
        <trans-unit id="6916dcd6d6c8f00e1ac0ef865ab4c75ff38ebedf" translate="yes" xml:space="preserve">
          <source>If method == &amp;ldquo;reservoir_sampling&amp;rdquo;, a reservoir sampling algorithm is used which is suitable for high memory constraint or when O(&lt;code&gt;n_samples&lt;/code&gt;) ~ O(&lt;code&gt;n_population&lt;/code&gt;). The order of the selected integers is undefined. If a random order is desired, the selected subset should be shuffled.</source>
          <target state="translated">Si el m&amp;eacute;todo == &amp;ldquo;muestreo_de_ reservorio&amp;rdquo;, se usa un algoritmo de muestreo de reservorio que es adecuado para una alta restricci&amp;oacute;n de memoria o cuando O ( &lt;code&gt;n_samples&lt;/code&gt; ) ~ O ( &lt;code&gt;n_population&lt;/code&gt; ). El orden de los n&amp;uacute;meros enteros seleccionados no est&amp;aacute; definido. Si se desea un orden aleatorio, se debe mezclar el subconjunto seleccionado.</target>
        </trans-unit>
        <trans-unit id="0dea8a6c91cef90e0430014d895bb3954c8fb19c" translate="yes" xml:space="preserve">
          <source>If method ==&amp;rdquo;tracking_selection&amp;rdquo;, a set based implementation is used which is suitable for &lt;code&gt;n_samples&lt;/code&gt; &amp;lt;&amp;lt;&amp;lt; &lt;code&gt;n_population&lt;/code&gt;.</source>
          <target state="translated">Si el m&amp;eacute;todo == &amp;rdquo;tracking_selection&amp;rdquo;, se utiliza una implementaci&amp;oacute;n basada en conjuntos que es adecuada para &lt;code&gt;n_samples&lt;/code&gt; &amp;lt;&amp;lt;&amp;lt; &lt;code&gt;n_population&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="79ae0bba548597b9902c41c70fbd6bf9602e8534" translate="yes" xml:space="preserve">
          <source>If metric is &amp;lsquo;precomputed&amp;rsquo;, Y is ignored and X is returned.</source>
          <target state="translated">Si la m&amp;eacute;trica est&amp;aacute; 'precalculada', Y se ignora y se devuelve X.</target>
        </trans-unit>
        <trans-unit id="ca8cb47e72e166fd730a116349e050254e6876d5" translate="yes" xml:space="preserve">
          <source>If metric is a callable function, it is called on each pair of instances (rows) and the resulting value recorded. The callable should take two arrays as input and return one value indicating the distance between them. This works for Scipy&amp;rsquo;s metrics, but is less efficient than passing the metric name as a string.</source>
          <target state="translated">Si la m&amp;eacute;trica es una funci&amp;oacute;n invocable, se invoca en cada par de instancias (filas) y se registra el valor resultante. El invocable debe tomar dos matrices como entrada y devolver un valor que indique la distancia entre ellas. Esto funciona para las m&amp;eacute;tricas de Scipy, pero es menos eficiente que pasar el nombre de la m&amp;eacute;trica como una cadena.</target>
        </trans-unit>
        <trans-unit id="27305db22802f1bb3d3e2d60db076f6f0d275369" translate="yes" xml:space="preserve">
          <source>If mini-batch k-means is used, the best initialization is chosen and the algorithm runs once. Otherwise, the algorithm is run for each initialization and the best solution chosen.</source>
          <target state="translated">Si se utiliza el mini lote k-means,se elige la mejor inicialización y el algoritmo se ejecuta una vez.En caso contrario,el algoritmo se ejecuta para cada inicialización y se elige la mejor solución.</target>
        </trans-unit>
        <trans-unit id="16e6684b95c26e373af21b6c0d2ea50b705c0505" translate="yes" xml:space="preserve">
          <source>If multioutput is &amp;lsquo;raw_values&amp;rsquo;, then mean absolute error is returned for each output separately. If multioutput is &amp;lsquo;uniform_average&amp;rsquo; or an ndarray of weights, then the weighted average of all output errors is returned.</source>
          <target state="translated">Si la salida m&amp;uacute;ltiple es 'raw_values', el error absoluto medio se devuelve para cada salida por separado. Si la salida m&amp;uacute;ltiple es 'uniform_average' o un ndarray de pesos, se devuelve el promedio ponderado de todos los errores de salida.</target>
        </trans-unit>
        <trans-unit id="caf3d42023b133b9efdfbb493fc66df503092e71" translate="yes" xml:space="preserve">
          <source>If no scoring is specified and the estimator has no score function, we can either return None or raise an exception.</source>
          <target state="translated">Si no se especifica una puntuación y el estimador no tiene una función de puntuación,podemos devolver Ninguno o plantear una excepción.</target>
        </trans-unit>
        <trans-unit id="5519c1c6825bf59bfd06c08f68bb64b64ee1a0ae" translate="yes" xml:space="preserve">
          <source>If no valid consensus set could be found. This occurs if &lt;code&gt;is_data_valid&lt;/code&gt; and &lt;code&gt;is_model_valid&lt;/code&gt; return False for all &lt;code&gt;max_trials&lt;/code&gt; randomly chosen sub-samples.</source>
          <target state="translated">Si no se pudo encontrar un consenso v&amp;aacute;lido. Esto ocurre si &lt;code&gt;is_data_valid&lt;/code&gt; y &lt;code&gt;is_model_valid&lt;/code&gt; devuelven False para todas las &lt;code&gt;max_trials&lt;/code&gt; elegidas al azar.</target>
        </trans-unit>
        <trans-unit id="e48a960f323664c14eed43108cfafa1159796090" translate="yes" xml:space="preserve">
          <source>If normalize is &lt;code&gt;True&lt;/code&gt;, return the fraction of misclassifications (float), else it returns the number of misclassifications (int). The best performance is 0.</source>
          <target state="translated">Si normalizar es &lt;code&gt;True&lt;/code&gt; , devuelve la fracci&amp;oacute;n de errores de clasificaci&amp;oacute;n (flotante); de lo contrario, devuelve el n&amp;uacute;mero de errores de clasificaci&amp;oacute;n (int). El mejor rendimiento es 0.</target>
        </trans-unit>
        <trans-unit id="d93355ca0c397a92c0eb63483bbae0b531d00cf1" translate="yes" xml:space="preserve">
          <source>If not &lt;code&gt;None&lt;/code&gt;, the standardized partial AUC &lt;a href=&quot;#r4bb7c4558997-3&quot; id=&quot;id1&quot;&gt;[3]&lt;/a&gt; over the range [0, max_fpr] is returned.</source>
          <target state="translated">Si no es &lt;code&gt;None&lt;/code&gt; , se devuelve el AUC parcial estandarizado &lt;a href=&quot;#r4bb7c4558997-3&quot; id=&quot;id1&quot;&gt;[3]&lt;/a&gt; sobre el rango [0, max_fpr].</target>
        </trans-unit>
        <trans-unit id="954d968337062d6fae676f5915fb0dc48db9ccef" translate="yes" xml:space="preserve">
          <source>If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus.</source>
          <target state="translated">Si no hay ninguno,construye un vocabulario que sólo considere las máximas características ordenadas por la frecuencia de los términos a través del corpus.</target>
        </trans-unit>
        <trans-unit id="6b6dff5f6d294c2bdbfe5ee6b0ee56319193880c" translate="yes" xml:space="preserve">
          <source>If not None, data is split in a stratified fashion, using this as the class labels.</source>
          <target state="translated">Si no hay ninguno,los datos se dividen de manera estratificada,usando esto como las etiquetas de clase.</target>
        </trans-unit>
        <trans-unit id="d9fe4271c08ca870db7143f08e0938aa49f2d1d0" translate="yes" xml:space="preserve">
          <source>If not None, set the highest value of the fit to y_max.</source>
          <target state="translated">Si no es None,establezca el valor más alto del ajuste en y_max.</target>
        </trans-unit>
        <trans-unit id="3c138b5d1ed12eddb3226ed7535814059b7a615c" translate="yes" xml:space="preserve">
          <source>If not None, set the lowest value of the fit to y_min.</source>
          <target state="translated">Si no es None,establezca el valor más bajo del ajuste en y_min.</target>
        </trans-unit>
        <trans-unit id="ebcf44116da09ed76a723aed5cadbe6d4ed2530d" translate="yes" xml:space="preserve">
          <source>If not None, this argument is passed as &lt;code&gt;sample_weight&lt;/code&gt; keyword argument to the &lt;code&gt;score&lt;/code&gt; method of the final estimator.</source>
          <target state="translated">Si no es None, este argumento se pasa como argumento de palabra clave &lt;code&gt;sample_weight&lt;/code&gt; al m&amp;eacute;todo de &lt;code&gt;score&lt;/code&gt; del estimador final.</target>
        </trans-unit>
        <trans-unit id="f0f7d0b7263b16cf926e8314af8096b9ae6c9066" translate="yes" xml:space="preserve">
          <source>If not given, the bandwidth is estimated using sklearn.cluster.estimate_bandwidth; see the documentation for that function for hints on scalability (see also the Notes, below).</source>
          <target state="translated">Si no se indica,el ancho de banda se estima utilizando sklearn.cluster.estimate_banda;véanse en la documentación de esa función las indicaciones sobre la escalabilidad (véanse también las Notas,más adelante).</target>
        </trans-unit>
        <trans-unit id="3fc57ade66d3b29b2e5dacfcee394aac7f4ec951" translate="yes" xml:space="preserve">
          <source>If not provided, labels will be inferred from y_true. If &lt;code&gt;labels&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; has shape (n_samples,) the labels are assumed to be binary and are inferred from &lt;code&gt;y_true&lt;/code&gt;. .. versionadded:: 0.18</source>
          <target state="translated">Si no se proporciona, las etiquetas se deducir&amp;aacute;n de y_true. Si &lt;code&gt;labels&lt;/code&gt; es &lt;code&gt;None&lt;/code&gt; y &lt;code&gt;y_pred&lt;/code&gt; tiene forma (n_samples), se supone que las etiquetas son binarias y se infieren de &lt;code&gt;y_true&lt;/code&gt; . .. versionadded :: 0.18</target>
        </trans-unit>
        <trans-unit id="d3a1f4e96f04c6f8dfd4835d50de53587903b2e7" translate="yes" xml:space="preserve">
          <source>If one-of-K coding is applied to categorical features, this will include the constructed feature names but not the original ones.</source>
          <target state="translated">Si se aplica la codificación &quot;uno de los K&quot; a los rasgos categóricos,esto incluirá los nombres de los rasgos construidos pero no los originales.</target>
        </trans-unit>
        <trans-unit id="c3b8faf61102e14148418b48bf3dbb3389d54ef3" translate="yes" xml:space="preserve">
          <source>If only the diagonal of the auto-covariance is being used, the method &lt;code&gt;diag()&lt;/code&gt; of a kernel can be called, which is more computationally efficient than the equivalent call to &lt;code&gt;__call__&lt;/code&gt;: &lt;code&gt;np.diag(k(X, X)) == k.diag(X)&lt;/code&gt;</source>
          <target state="translated">Si solo se usa la diagonal de la covarianza autom&amp;aacute;tica, se puede llamar al m&amp;eacute;todo &lt;code&gt;diag()&lt;/code&gt; de un kernel, que es m&amp;aacute;s eficiente computacionalmente que la llamada equivalente a &lt;code&gt;__call__&lt;/code&gt; : &lt;code&gt;np.diag(k(X, X)) == k.diag(X)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="db7f35e5fc1dd73c10c86bdccb4a2449d5a89ec7" translate="yes" xml:space="preserve">
          <source>If order is &amp;lsquo;random&amp;rsquo; a random ordering will be used.</source>
          <target state="translated">Si el orden es &quot;aleatorio&quot;, se utilizar&amp;aacute; un orden aleatorio.</target>
        </trans-unit>
        <trans-unit id="f42275492b00fc14b5861ea85e0f4944992d0324" translate="yes" xml:space="preserve">
          <source>If passed, include the name of the estimator in warning messages.</source>
          <target state="translated">Si se aprueba,incluya el nombre del estimador en los mensajes de advertencia.</target>
        </trans-unit>
        <trans-unit id="908cd551a5eab6201799122746b2ad3d99f4a3d2" translate="yes" xml:space="preserve">
          <source>If positive, restrict regression coefficients to be positive</source>
          <target state="translated">Si es positivo,restringe los coeficientes de regresión para que sean positivos</target>
        </trans-unit>
        <trans-unit id="c5484f943f94af044829e2453a87ea1beff675d6" translate="yes" xml:space="preserve">
          <source>If return_costs is True, the objective function and dual gap at each iteration are returned.</source>
          <target state="translated">Si return_costs es True,la función objetivo y la brecha dual en cada iteración son devueltas.</target>
        </trans-unit>
        <trans-unit id="3a07f641c209d2556442bcd652915ffb4ab857db" translate="yes" xml:space="preserve">
          <source>If safe is false, clone will fall back to a deep copy on objects that are not estimators.</source>
          <target state="translated">Si la seguridad es falsa,el clon caerá en una copia profunda en objetos que no son estimadores.</target>
        </trans-unit>
        <trans-unit id="179d83839b7c246b21dd4fad6260ec3c338cc783" translate="yes" xml:space="preserve">
          <source>If seed is None, return the RandomState singleton used by np.random. If seed is an int, return a new RandomState instance seeded with seed. If seed is already a RandomState instance, return it. Otherwise raise ValueError.</source>
          <target state="translated">Si la semilla es None,devuelve el singleton RandomState usado por np.random.Si la semilla es un int,devuelve una nueva instancia de RandomState sembrada con semilla.Si la semilla ya es una instancia RandomState,devuélvela.De lo contrario,aumente el ValueError.</target>
        </trans-unit>
        <trans-unit id="7108bbb3c9ecad70c2ad038e49ece7ce906a1c8f" translate="yes" xml:space="preserve">
          <source>If seq[i] is an int or a tuple with one int value, a one-way PDP is created; if seq[i] is a tuple of two ints, a two-way PDP is created. If feature_names is specified and seq[i] is an int, seq[i] must be &amp;lt; len(feature_names). If seq[i] is a string, feature_names must be specified, and seq[i] must be in feature_names.</source>
          <target state="translated">Si seq [i] es un int o una tupla con un valor int, se crea un PDP unidireccional; si seq [i] es una tupla de dos enteros, se crea un PDP bidireccional. Si se especifica feature_names y seq [i] es un int, seq [i] debe ser &amp;lt;len (feature_names). Si seq [i] es una cadena, feature_names debe especificarse y seq [i] debe estar en feature_names.</target>
        </trans-unit>
        <trans-unit id="b01ea458e6ed79ec076f21dd79564eecc3f7a882" translate="yes" xml:space="preserve">
          <source>If set to &amp;lsquo;random&amp;rsquo;, a random coefficient is updated every iteration rather than looping over features sequentially by default. This (setting to &amp;lsquo;random&amp;rsquo;) often leads to significantly faster convergence especially when tol is higher than 1e-4</source>
          <target state="translated">Si se establece en 'aleatorio', un coeficiente aleatorio se actualiza en cada iteraci&amp;oacute;n en lugar de recorrer las caracter&amp;iacute;sticas secuencialmente de forma predeterminada. Este (ajuste a 'aleatorio') a menudo conduce a una convergencia significativamente m&amp;aacute;s r&amp;aacute;pida, especialmente cuando tol es mayor que 1e-4</target>
        </trans-unit>
        <trans-unit id="7a4374896942a67a58d05d59133607fc7483d7a2" translate="yes" xml:space="preserve">
          <source>If set to &amp;lsquo;random&amp;rsquo;, a random coefficient is updated every iteration rather than looping over features sequentially by default. This (setting to &amp;lsquo;random&amp;rsquo;) often leads to significantly faster convergence especially when tol is higher than 1e-4.</source>
          <target state="translated">Si se establece en 'aleatorio', un coeficiente aleatorio se actualiza en cada iteraci&amp;oacute;n en lugar de recorrer las caracter&amp;iacute;sticas secuencialmente de forma predeterminada. Esta (configuraci&amp;oacute;n en 'aleatoria') a menudo conduce a una convergencia significativamente m&amp;aacute;s r&amp;aacute;pida, especialmente cuando tol es mayor que 1e-4.</target>
        </trans-unit>
        <trans-unit id="d15f7a009cd3b6e81a757534913f0edc7a2b7947" translate="yes" xml:space="preserve">
          <source>If set to True, forces coefficients to be positive. (Only allowed when &lt;code&gt;y.ndim == 1&lt;/code&gt;).</source>
          <target state="translated">Si se establece en Verdadero, fuerza a los coeficientes a ser positivos. (Solo permitido cuando &lt;code&gt;y.ndim == 1&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="6bd31584b0a279bb6a357ab195ba9534cb5cad4e" translate="yes" xml:space="preserve">
          <source>If set to True, the scores are averaged across all folds, and the coefs and the C that corresponds to the best score is taken, and a final refit is done using these parameters. Otherwise the coefs, intercepts and C that correspond to the best scores across folds are averaged.</source>
          <target state="translated">Si se establece en True,se promedian las puntuaciones en todos los pliegues,y se toman los arrecifes y la C que corresponde a la mejor puntuación,y se hace un ajuste final utilizando estos parámetros.En caso contrario,se promedian los arrecifes,las interceptaciones y la C que corresponden a las mejores puntuaciones en todos los pliegues.</target>
        </trans-unit>
        <trans-unit id="f3d43f9f7c9e3af1ca6eddc0268b8ee91bb07ee3" translate="yes" xml:space="preserve">
          <source>If set, scikit-learn will attempt to limit the size of temporary arrays to this number of MiB (per job when parallelised), often saving both computation time and memory on expensive operations that can be performed in chunks. Global default: 1024.</source>
          <target state="translated">Si se establece,scikit-learn intentará limitar el tamaño de las matrices temporales a este número de MiB (por trabajo cuando se paraleliza),a menudo ahorrando tanto tiempo de cálculo como memoria en operaciones costosas que pueden realizarse en trozos.Valor por defecto global:1024.</target>
        </trans-unit>
        <trans-unit id="cd9d66e1ab8be1fe689482ddb0cbca43b44a3950" translate="yes" xml:space="preserve">
          <source>If strictly positive, stop reading any new line of data once the position in the file has reached the (offset + length) bytes threshold.</source>
          <target state="translated">Si es estrictamente positivo,deje de leer cualquier nueva línea de datos una vez que la posición en el archivo haya alcanzado el umbral de (offset+longitud)bytes.</target>
        </trans-unit>
        <trans-unit id="af99c20b0f1015ebcecc8bfb6a50ca848ab08d15" translate="yes" xml:space="preserve">
          <source>If string, specifies the path that will contain the data. If file-like, data will be written to f. f should be opened in binary mode.</source>
          <target state="translated">Si la cadena,especifica el camino que contendrá los datos.Si es de tipo archivo,los datos se escribirán en f.f debe abrirse en modo binario.</target>
        </trans-unit>
        <trans-unit id="d25cbbfb18995acebbdc8e788e3994e16b21b8ae" translate="yes" xml:space="preserve">
          <source>If sum_over_features is False shape is (n_samples_X * n_samples_Y, n_features) and D contains the componentwise L1 pairwise-distances (ie. absolute difference), else shape is (n_samples_X, n_samples_Y) and D contains the pairwise L1 distances.</source>
          <target state="translated">Si sum_over_features es False shape es (n_samples_X*n_samples_Y,n_features)y D contiene las distancias por pares L1 en sentido componente (es decir,diferencia absoluta),si no shape es (n_samples_X,n_samples_Y)y D contiene las distancias por pares L1.</target>
        </trans-unit>
        <trans-unit id="1979731cc29c616c5ac5593ab888192599b2d46b" translate="yes" xml:space="preserve">
          <source>If the &lt;code&gt;loss&lt;/code&gt; does not support probabilities.</source>
          <target state="translated">Si la &lt;code&gt;loss&lt;/code&gt; no admite probabilidades.</target>
        </trans-unit>
        <trans-unit id="41f96f9118cd39448d94e68aca8aa6d327b368ef" translate="yes" xml:space="preserve">
          <source>If the algorithm is &amp;ldquo;deflation&amp;rdquo;, n_iter is the maximum number of iterations run across all components. Else they are just the number of iterations taken to converge.</source>
          <target state="translated">Si el algoritmo es &quot;deflaci&amp;oacute;n&quot;, n_iter es el n&amp;uacute;mero m&amp;aacute;ximo de iteraciones ejecutadas en todos los componentes. De lo contrario, son solo el n&amp;uacute;mero de iteraciones necesarias para converger.</target>
        </trans-unit>
        <trans-unit id="b72ab6a8a780a6da86f798b7381c54dc2236b80c" translate="yes" xml:space="preserve">
          <source>If the algorithm stops before fully converging (because of &lt;code&gt;tol&lt;/code&gt; of &lt;code&gt;max_iter&lt;/code&gt;), &lt;code&gt;labels_&lt;/code&gt; and &lt;code&gt;means_&lt;/code&gt; will not be consistent, i.e. the &lt;code&gt;means_&lt;/code&gt; will not be the means of the points in each cluster. Also, the estimator will reassign &lt;code&gt;labels_&lt;/code&gt; after the last iteration to make &lt;code&gt;labels_&lt;/code&gt; consistent with &lt;code&gt;predict&lt;/code&gt; on the training set.</source>
          <target state="translated">Si el algoritmo se detiene antes de converger completamente (debido a &lt;code&gt;tol&lt;/code&gt; de &lt;code&gt;max_iter&lt;/code&gt; ), las &lt;code&gt;labels_&lt;/code&gt; y &lt;code&gt;means_&lt;/code&gt; no ser&amp;aacute;n consistentes, es decir, las &lt;code&gt;means_&lt;/code&gt; no ser&amp;aacute;n las medias de los puntos en cada grupo. Adem&amp;aacute;s, el estimador reasignar&amp;aacute; las &lt;code&gt;labels_&lt;/code&gt; despu&amp;eacute;s de la &amp;uacute;ltima iteraci&amp;oacute;n para que las &lt;code&gt;labels_&lt;/code&gt; consistentes con &lt;code&gt;predict&lt;/code&gt; en el conjunto de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="4043c787702cc081c41f25b031d69ea98cf35c42" translate="yes" xml:space="preserve">
          <source>If the array is not symmetric, then a symmetrized version is returned. Optionally, a warning or exception is raised if the matrix is not symmetric.</source>
          <target state="translated">Si la matriz no es simétrica,entonces se devuelve una versión simétrica.Opcionalmente,se plantea una advertencia o excepción si la matriz no es simétrica.</target>
        </trans-unit>
        <trans-unit id="d4238935d45ce51eea0be6c47146a609e05c26ed" translate="yes" xml:space="preserve">
          <source>If the attributes are not found.</source>
          <target state="translated">Si no se encuentran los atributos.</target>
        </trans-unit>
        <trans-unit id="10f86bc0a8ef8d94dd88200305e21d6ac290743f" translate="yes" xml:space="preserve">
          <source>If the classifier performs equally well on either class, this term reduces to the conventional accuracy (i.e., the number of correct predictions divided by the total number of predictions).</source>
          <target state="translated">Si el clasificador funciona igual de bien en cualquiera de las dos clases,este término se reduce a la precisión convencional (es decir,el número de predicciones correctas dividido por el número total de predicciones).</target>
        </trans-unit>
        <trans-unit id="9d0651dbf433477af9dfe8c9482b03c0b28a7aea" translate="yes" xml:space="preserve">
          <source>If the data ordering is not arbitrary (e.g. samples with the same class label are contiguous), shuffling it first may be essential to get a meaningful cross- validation result. However, the opposite may be true if the samples are not independently and identically distributed. For example, if samples correspond to news articles, and are ordered by their time of publication, then shuffling the data will likely lead to a model that is overfit and an inflated validation score: it will be tested on samples that are artificially similar (close in time) to training samples.</source>
          <target state="translated">Si el orden de los datos no es arbitrario (por ejemplo,las muestras con la misma etiqueta de clase son contiguas),barajarlo primero puede ser esencial para obtener un resultado de validación cruzada significativo.Sin embargo,puede ocurrir lo contrario si las muestras no están distribuidas de forma independiente e idéntica.Por ejemplo,si las muestras corresponden a artículos de noticias,y se ordenan por su tiempo de publicación,entonces barajando los datos probablemente se obtendrá un modelo que se sobrepone y un resultado de validación inflado:se probará en muestras que son artificialmente similares (cercanas en el tiempo)a las muestras de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="4fdc5debb409dcec7a673c288152f0ef6e4738ef" translate="yes" xml:space="preserve">
          <source>If the default value is passed, then &lt;code&gt;keepdims&lt;/code&gt; will not be passed through to the &lt;code&gt;mean&lt;/code&gt; method of sub-classes of &lt;code&gt;ndarray&lt;/code&gt;, however any non-default value will be. If the sub-class&amp;rsquo; method does not implement &lt;code&gt;keepdims&lt;/code&gt; any exceptions will be raised.</source>
          <target state="translated">Si se pasa el valor predeterminado, &lt;code&gt;keepdims&lt;/code&gt; no se pasar&amp;aacute; al m&amp;eacute;todo &lt;code&gt;mean&lt;/code&gt; de las subclases de &lt;code&gt;ndarray&lt;/code&gt; , sin embargo, cualquier valor no predeterminado s&amp;iacute; lo ser&amp;aacute;. Si el m&amp;eacute;todo de la &lt;code&gt;keepdims&lt;/code&gt; no implementa keepdims , se generar&amp;aacute;n excepciones.</target>
        </trans-unit>
        <trans-unit id="ca5777d1057fb92ff835301c12f93dc71bd51069" translate="yes" xml:space="preserve">
          <source>If the difference between the current prediction and the correct label is below this threshold, the model is not updated.</source>
          <target state="translated">Si la diferencia entre la predicción actual y la etiqueta correcta está por debajo de este umbral,el modelo no se actualiza.</target>
        </trans-unit>
        <trans-unit id="54f187a0c12dbeb2b22455f8308653334a568512" translate="yes" xml:space="preserve">
          <source>If the estimator supports incremental learning, this will be used to speed up fitting for different training set sizes.</source>
          <target state="translated">Si el estimador apoya el aprendizaje incremental,esto se usará para acelerar el ajuste para diferentes tamaños de conjuntos de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="28446974a089033b0f005a14dd2e5e7cde0d019d" translate="yes" xml:space="preserve">
          <source>If the file does not exist yet, it is downloaded from mldata.org .</source>
          <target state="translated">Si el archivo no existe todavía,se descarga de mldata.org .</target>
        </trans-unit>
        <trans-unit id="3377386ec971b5f97505ad0b0efacd641307a6b2" translate="yes" xml:space="preserve">
          <source>If the folder does not already exist, it is automatically created.</source>
          <target state="translated">Si la carpeta no existe ya,se crea automáticamente.</target>
        </trans-unit>
        <trans-unit id="bcf86cd76452a354a39a384d6cc008f0521fadc0" translate="yes" xml:space="preserve">
          <source>If the gradient norm is below this threshold, the optimization will be stopped.</source>
          <target state="translated">Si la norma del gradiente está por debajo de este umbral,la optimización se detendrá.</target>
        </trans-unit>
        <trans-unit id="aaea0ac91de1101ebb5583d72a39edadc546a9ed" translate="yes" xml:space="preserve">
          <source>If the ground truth labels are not known, evaluation must be performed using the model itself. The Silhouette Coefficient (&lt;a href=&quot;generated/sklearn.metrics.silhouette_score#sklearn.metrics.silhouette_score&quot;&gt;&lt;code&gt;sklearn.metrics.silhouette_score&lt;/code&gt;&lt;/a&gt;) is an example of such an evaluation, where a higher Silhouette Coefficient score relates to a model with better defined clusters. The Silhouette Coefficient is defined for each sample and is composed of two scores:</source>
          <target state="translated">Si no se conocen las etiquetas de verdad del terreno, la evaluaci&amp;oacute;n debe realizarse utilizando el propio modelo. El coeficiente de silueta ( &lt;a href=&quot;generated/sklearn.metrics.silhouette_score#sklearn.metrics.silhouette_score&quot;&gt; &lt;code&gt;sklearn.metrics.silhouette_score&lt;/code&gt; &lt;/a&gt; ) es un ejemplo de tal evaluaci&amp;oacute;n, donde una puntuaci&amp;oacute;n m&amp;aacute;s alta del coeficiente de silueta se relaciona con un modelo con grupos mejor definidos. El coeficiente de silueta se define para cada muestra y se compone de dos puntuaciones:</target>
        </trans-unit>
        <trans-unit id="bb3f5944370bdcf362ff4bffb46e8bf1ded41ef1" translate="yes" xml:space="preserve">
          <source>If the ground truth labels are not known, the Calinski-Harabaz index (&lt;a href=&quot;generated/sklearn.metrics.calinski_harabaz_score#sklearn.metrics.calinski_harabaz_score&quot;&gt;&lt;code&gt;sklearn.metrics.calinski_harabaz_score&lt;/code&gt;&lt;/a&gt;) - also known as the Variance Ratio Criterion - can be used to evaluate the model, where a higher Calinski-Harabaz score relates to a model with better defined clusters.</source>
          <target state="translated">Si no se conocen las etiquetas de la verdad fundamental, el &amp;iacute;ndice de Calinski-Harabaz ( &lt;a href=&quot;generated/sklearn.metrics.calinski_harabaz_score#sklearn.metrics.calinski_harabaz_score&quot;&gt; &lt;code&gt;sklearn.metrics.calinski_harabaz_score&lt;/code&gt; &lt;/a&gt; ), tambi&amp;eacute;n conocido como Criterio de relaci&amp;oacute;n de varianza, se puede utilizar para evaluar el modelo, donde una puntuaci&amp;oacute;n de Calinski-Harabaz m&amp;aacute;s alta se relaciona con un modelo con agrupaciones mejor definidas.</target>
        </trans-unit>
        <trans-unit id="a4a519d35f95c18e319df7e8878b98f013f9bd44" translate="yes" xml:space="preserve">
          <source>If the ground truth labels are not known, the Davies-Bouldin index (&lt;a href=&quot;generated/sklearn.metrics.davies_bouldin_score#sklearn.metrics.davies_bouldin_score&quot;&gt;&lt;code&gt;sklearn.metrics.davies_bouldin_score&lt;/code&gt;&lt;/a&gt;) can be used to evaluate the model, where a lower Davies-Bouldin index relates to a model with better separation between the clusters.</source>
          <target state="translated">Si no se conocen las etiquetas de verdad del terreno, el &amp;iacute;ndice de Davies-Bouldin ( &lt;a href=&quot;generated/sklearn.metrics.davies_bouldin_score#sklearn.metrics.davies_bouldin_score&quot;&gt; &lt;code&gt;sklearn.metrics.davies_bouldin_score&lt;/code&gt; &lt;/a&gt; ) se puede utilizar para evaluar el modelo, donde un &amp;iacute;ndice de Davies-Bouldin m&amp;aacute;s bajo se relaciona con un modelo con una mejor separaci&amp;oacute;n entre los grupos.</target>
        </trans-unit>
        <trans-unit id="7ce6861d9ec6948a6bc8aef858e97abae7ed0654" translate="yes" xml:space="preserve">
          <source>If the input is a sparse matrix, only the non-zero values are subject to update by the Binarizer class.</source>
          <target state="translated">Si la entrada es una matriz dispersa,sólo los valores que no son cero están sujetos a actualización por la clase Binarizer.</target>
        </trans-unit>
        <trans-unit id="c10a8d9d8c40f9f50dafe36b727f5b47e7075f19" translate="yes" xml:space="preserve">
          <source>If the input matrix X is very sparse, it is recommended to convert to sparse &lt;code&gt;csc_matrix&lt;/code&gt; before calling fit and sparse &lt;code&gt;csr_matrix&lt;/code&gt; before calling predict. Training time can be orders of magnitude faster for a sparse matrix input compared to a dense matrix when features have zero values in most of the samples.</source>
          <target state="translated">Si la matriz de entrada X es muy dispersa, se recomienda convertir a &lt;code&gt;csc_matrix&lt;/code&gt; dispersa antes de llamar a fit y &lt;code&gt;csr_matrix&lt;/code&gt; dispersa antes de llamar a predict. El tiempo de entrenamiento puede ser &amp;oacute;rdenes de magnitud m&amp;aacute;s r&amp;aacute;pido para una entrada de matriz escasa en comparaci&amp;oacute;n con una matriz densa cuando las entidades tienen valores cero en la mayor&amp;iacute;a de las muestras.</target>
        </trans-unit>
        <trans-unit id="661cb29a3f5fe68fda8ea5f8c53273efb7753ce1" translate="yes" xml:space="preserve">
          <source>If the labels are encoded with +1 and -1, \(y\): is the true value, and \(w\) is the predicted decisions as output by &lt;code&gt;decision_function&lt;/code&gt;, then the hinge loss is defined as:</source>
          <target state="translated">Si las etiquetas est&amp;aacute;n codificadas con +1 y -1, \ (y \): es el valor verdadero, y \ (w \) son las decisiones predichas como resultado de &lt;code&gt;decision_function&lt;/code&gt; , entonces la p&amp;eacute;rdida de bisagra se define como:</target>
        </trans-unit>
        <trans-unit id="30e7605353fedb22ff0c25c7418abbab28137e70" translate="yes" xml:space="preserve">
          <source>If the loss on a sample is greater than the &lt;code&gt;residual_threshold&lt;/code&gt;, then this sample is classified as an outlier.</source>
          <target state="translated">Si la p&amp;eacute;rdida en una muestra es mayor que &lt;code&gt;residual_threshold&lt;/code&gt; , esta muestra se clasifica como un valor at&amp;iacute;pico.</target>
        </trans-unit>
        <trans-unit id="fd47c1f065810b1b45f0d8d994aa0a4ff29505d4" translate="yes" xml:space="preserve">
          <source>If the metric constructor parameter is &amp;ldquo;precomputed&amp;rdquo;, X is assumed to be the distance matrix between the data to be predicted and &lt;code&gt;self.centroids_&lt;/code&gt;.</source>
          <target state="translated">Si el par&amp;aacute;metro del constructor m&amp;eacute;trico est&amp;aacute; &amp;ldquo;precalculado&amp;rdquo;, se supone que X es la matriz de distancia entre los datos que se van a predecir y &lt;code&gt;self.centroids_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c8476d320358236ab03a9b2e5775d6207658d4f7" translate="yes" xml:space="preserve">
          <source>If the metric is &amp;lsquo;precomputed&amp;rsquo; X must be a square distance matrix. Otherwise it contains a sample per row.</source>
          <target state="translated">Si la m&amp;eacute;trica est&amp;aacute; 'precalculada', X debe ser una matriz de distancia cuadrada. De lo contrario, contiene una muestra por fila.</target>
        </trans-unit>
        <trans-unit id="ed2846275337b6c05f70ce353bc177c3fd2fc1b0" translate="yes" xml:space="preserve">
          <source>If the metric is &amp;lsquo;precomputed&amp;rsquo; X must be a square distance matrix. Otherwise it contains a sample per row. If the method is &amp;lsquo;exact&amp;rsquo;, X may be a sparse matrix of type &amp;lsquo;csr&amp;rsquo;, &amp;lsquo;csc&amp;rsquo; or &amp;lsquo;coo&amp;rsquo;.</source>
          <target state="translated">Si la m&amp;eacute;trica est&amp;aacute; 'precalculada', X debe ser una matriz de distancia cuadrada. De lo contrario, contiene una muestra por fila. Si el m&amp;eacute;todo es 'exacto', X puede ser una matriz dispersa de tipo 'csr', 'csc' o 'coo'.</target>
        </trans-unit>
        <trans-unit id="be2b4ccc2ee21bcc622b72ad8a09e29905f86d22" translate="yes" xml:space="preserve">
          <source>If the number of features is \(p\), you now require \(n \sim 1/d^p\) points. Let&amp;rsquo;s say that we require 10 points in one dimension: now \(10^p\) points are required in \(p\) dimensions to pave the \([0, 1]\) space. As \(p\) becomes large, the number of training points required for a good estimator grows exponentially.</source>
          <target state="translated">Si el n&amp;uacute;mero de entidades es \ (p \), ahora necesita \ (n \ sim 1 / d ^ p \) puntos. Digamos que necesitamos 10 puntos en una dimensi&amp;oacute;n: ahora se requieren \ (10 ​​^ p \) puntos en las dimensiones \ (p \) para pavimentar el espacio \ ([0, 1] \). A medida que \ (p \) se vuelve grande, el n&amp;uacute;mero de puntos de entrenamiento necesarios para un buen estimador crece exponencialmente.</target>
        </trans-unit>
        <trans-unit id="31f6fadae8fdb5e25318685f0dd36c90a3234b90" translate="yes" xml:space="preserve">
          <source>If the number of features is much greater than the number of samples, avoid over-fitting in choosing &lt;a href=&quot;#svm-kernels&quot;&gt;Kernel functions&lt;/a&gt; and regularization term is crucial.</source>
          <target state="translated">Si el n&amp;uacute;mero de caracter&amp;iacute;sticas es mucho mayor que el n&amp;uacute;mero de muestras, evite el ajuste excesivo al elegir las &lt;a href=&quot;#svm-kernels&quot;&gt;funciones del Kernel&lt;/a&gt; y el t&amp;eacute;rmino de regularizaci&amp;oacute;n es crucial.</target>
        </trans-unit>
        <trans-unit id="421f2017551080d266c05ad587f0ba1ecff6bff8" translate="yes" xml:space="preserve">
          <source>If the number of instances of data needs to be reduced, or if one wants a large number of subclusters either as a preprocessing step or otherwise, Birch is more useful than MiniBatchKMeans.</source>
          <target state="translated">Si es necesario reducir el número de instancias de datos,o si se desea un gran número de subconjuntos,ya sea como paso previo al procesamiento o de otra manera,el abedul es más útil que el MiniBatchKMeans.</target>
        </trans-unit>
        <trans-unit id="0169ea68b458a3b315ac7acca32e943f8bdb1bed" translate="yes" xml:space="preserve">
          <source>If the option chosen is &amp;lsquo;ovr&amp;rsquo;, then a binary problem is fit for each label. For &amp;lsquo;multinomial&amp;rsquo; the loss minimised is the multinomial loss fit across the entire probability distribution, &lt;em&gt;even when the data is binary&lt;/em&gt;. &amp;lsquo;multinomial&amp;rsquo; is unavailable when solver=&amp;rsquo;liblinear&amp;rsquo;. &amp;lsquo;auto&amp;rsquo; selects &amp;lsquo;ovr&amp;rsquo; if the data is binary, or if solver=&amp;rsquo;liblinear&amp;rsquo;, and otherwise selects &amp;lsquo;multinomial&amp;rsquo;.</source>
          <target state="translated">Si la opci&amp;oacute;n elegida es 'ovr', entonces se ajusta un problema binario para cada etiqueta. Para 'multinomial', la p&amp;eacute;rdida minimizada es el ajuste de p&amp;eacute;rdida multinomial en toda la distribuci&amp;oacute;n de probabilidad, &lt;em&gt;incluso cuando los datos son binarios&lt;/em&gt; . 'multinomial' no est&amp;aacute; disponible cuando solver = 'liblinear'. 'auto' selecciona 'ovr' si los datos son binarios, o si solver = 'liblinear', y de lo contrario selecciona 'multinomial'.</target>
        </trans-unit>
        <trans-unit id="fb7bde2a134f67333f646adb3cb422fdb3b0a619" translate="yes" xml:space="preserve">
          <source>If the prediction task is to classify the observations in a set of finite labels, in other words to &amp;ldquo;name&amp;rdquo; the objects observed, the task is said to be a &lt;strong&gt;classification&lt;/strong&gt; task. On the other hand, if the goal is to predict a continuous target variable, it is said to be a &lt;strong&gt;regression&lt;/strong&gt; task.</source>
          <target state="translated">Si la tarea de predicci&amp;oacute;n es clasificar las observaciones en un conjunto de etiquetas finitas, en otras palabras, &quot;nombrar&quot; los objetos observados, se dice que la tarea es una tarea de &lt;strong&gt;clasificaci&amp;oacute;n&lt;/strong&gt; . Por otro lado, si el objetivo es predecir una variable objetivo continua, se dice que es una tarea de &lt;strong&gt;regresi&amp;oacute;n&lt;/strong&gt; .</target>
        </trans-unit>
        <trans-unit id="c305135e1b17987e86652a7910deafacf0f5dc9d" translate="yes" xml:space="preserve">
          <source>If the pyamg package is installed, it is used: this greatly speeds up computation.</source>
          <target state="translated">Si se instala el paquete pyamg,se utiliza:esto acelera enormemente la computación.</target>
        </trans-unit>
        <trans-unit id="04f07265ff7d7b70145be5aec52784e1b24d6f09" translate="yes" xml:space="preserve">
          <source>If the radius of the subcluster obtained by merging the new sample and the nearest subcluster is greater than the square of the threshold and if the number of subclusters is greater than the branching factor, then a space is temporarily allocated to this new sample. The two farthest subclusters are taken and the subclusters are divided into two groups on the basis of the distance between these subclusters.</source>
          <target state="translated">Si el radio del subclúster obtenido mediante la fusión de la nueva muestra y el subclúster más cercano es mayor que el cuadrado del umbral y si el número de subclústeres es mayor que el factor de ramificación,entonces se asigna temporalmente un espacio a esta nueva muestra.Se toman los dos subconjuntos más lejanos y se dividen los subconjuntos en dos grupos en función de la distancia entre estos subconjuntos.</target>
        </trans-unit>
        <trans-unit id="41eef1b8a501219131b2619b097a82294e78c28a" translate="yes" xml:space="preserve">
          <source>If the samples are weighted, it will be easier to optimize the tree structure using weight-based pre-pruning criterion such as &lt;code&gt;min_weight_fraction_leaf&lt;/code&gt;, which ensure that leaf nodes contain at least a fraction of the overall sum of the sample weights.</source>
          <target state="translated">Si las muestras est&amp;aacute;n ponderadas, ser&amp;aacute; m&amp;aacute;s f&amp;aacute;cil optimizar la estructura del &amp;aacute;rbol utilizando un criterio de poda previa basado en el peso, como &lt;code&gt;min_weight_fraction_leaf&lt;/code&gt; , que asegura que los nodos de las hojas contengan al menos una fracci&amp;oacute;n de la suma total de los pesos de la muestra.</target>
        </trans-unit>
        <trans-unit id="0c1baaebbfab363e25ace0c6b6ee91539fab116b" translate="yes" xml:space="preserve">
          <source>If the selected solver is &amp;lsquo;L-BFGS&amp;rsquo;, training does not support online nor mini-batch learning.</source>
          <target state="translated">Si el solucionador seleccionado es 'L-BFGS', la capacitaci&amp;oacute;n no admite el aprendizaje en l&amp;iacute;nea ni por mini lotes.</target>
        </trans-unit>
        <trans-unit id="6b79b273c5ccf0e85d810ff5a4ad56e9102a13be" translate="yes" xml:space="preserve">
          <source>If the target is a continuous value, then for node \(m\), representing a region \(R_m\) with \(N_m\) observations, common criteria to minimise as for determining locations for future splits are Mean Squared Error, which minimizes the L2 error using mean values at terminal nodes, and Mean Absolute Error, which minimizes the L1 error using median values at terminal nodes.</source>
          <target state="translated">Si el objetivo es un valor continuo,entonces para el nodo \(m\),que representa una región \Ncon \Nobservaciones,los criterios comunes a minimizar en cuanto a la determinación de las ubicaciones para futuras divisiones son el Error Medio Cuadrado,que minimiza el error L2 utilizando valores medios en los nodos terminales,y el Error Medio Absoluto,que minimiza el error L1 utilizando valores medios en los nodos terminales.</target>
        </trans-unit>
        <trans-unit id="bd360b0d17d9758c91116a373249c96c3c493365" translate="yes" xml:space="preserve">
          <source>If the text is in a mish-mash of encodings that is simply too hard to sort out (which is the case for the 20 Newsgroups dataset), you can fall back on a simple single-byte encoding such as &lt;code&gt;latin-1&lt;/code&gt;. Some text may display incorrectly, but at least the same sequence of bytes will always represent the same feature.</source>
          <target state="translated">Si el texto se encuentra en una mezcla de codificaciones que es simplemente demasiado dif&amp;iacute;cil de clasificar (que es el caso del conjunto de datos de 20 grupos de noticias), puede recurrir a una codificaci&amp;oacute;n simple de un solo byte como &lt;code&gt;latin-1&lt;/code&gt; . Es posible que parte del texto se muestre incorrectamente, pero al menos la misma secuencia de bytes siempre representar&amp;aacute; la misma caracter&amp;iacute;stica.</target>
        </trans-unit>
        <trans-unit id="21286b430a50cd4c4f50df67c996d4b5b475416f" translate="yes" xml:space="preserve">
          <source>If the text you are loading is not actually encoded with UTF-8, however, you will get a &lt;code&gt;UnicodeDecodeError&lt;/code&gt;. The vectorizers can be told to be silent about decoding errors by setting the &lt;code&gt;decode_error&lt;/code&gt; parameter to either &lt;code&gt;&quot;ignore&quot;&lt;/code&gt; or &lt;code&gt;&quot;replace&quot;&lt;/code&gt;. See the documentation for the Python function &lt;code&gt;bytes.decode&lt;/code&gt; for more details (type &lt;code&gt;help(bytes.decode)&lt;/code&gt; at the Python prompt).</source>
          <target state="translated">Sin embargo, si el texto que est&amp;aacute; cargando no est&amp;aacute; codificado con UTF-8, obtendr&amp;aacute; un &lt;code&gt;UnicodeDecodeError&lt;/code&gt; . Se puede decir a los &lt;code&gt;decode_error&lt;/code&gt; que guarden silencio sobre los errores de decodificaci&amp;oacute;n configurando el par&amp;aacute;metro decode_error en &lt;code&gt;&quot;ignore&quot;&lt;/code&gt; o &lt;code&gt;&quot;replace&quot;&lt;/code&gt; . Consulte la documentaci&amp;oacute;n de la funci&amp;oacute;n de Python &lt;code&gt;bytes.decode&lt;/code&gt; para obtener m&amp;aacute;s detalles (escriba &lt;code&gt;help(bytes.decode)&lt;/code&gt; en el indicador de Python).</target>
        </trans-unit>
        <trans-unit id="13a9f813159d9e6258a164870cb1dc6a301dddd5" translate="yes" xml:space="preserve">
          <source>If the training score and the validation score are both low, the estimator will be underfitting. If the training score is high and the validation score is low, the estimator is overfitting and otherwise it is working very well. A low training score and a high validation score is usually not possible. All three cases can be found in the plot below where we vary the parameter \(\gamma\) of an SVM on the digits dataset.</source>
          <target state="translated">Si el puntaje de entrenamiento y el puntaje de validación son ambos bajos,el estimador no se ajustará.Si el puntaje de entrenamiento es alto y el puntaje de validación es bajo,el estimador se está adaptando demasiado y por lo demás está funcionando muy bien.Normalmente no es posible obtener un resultado de formación bajo y un resultado de validación alto.Los tres casos se pueden encontrar en el siguiente gráfico donde variamos el parámetro de un SVM en el conjunto de datos de los dígitos.</target>
        </trans-unit>
        <trans-unit id="80e789647361ff21671194a00300fe312dc530d2" translate="yes" xml:space="preserve">
          <source>If the transformed output consists of a mix of sparse and dense data, it will be stacked as a sparse matrix if the density is lower than this value. Use &lt;code&gt;sparse_threshold=0&lt;/code&gt; to always return dense. When the transformed output consists of all sparse or all dense data, the stacked result will be sparse or dense, respectively, and this keyword will be ignored.</source>
          <target state="translated">Si la salida transformada consiste en una combinaci&amp;oacute;n de datos densos y escasos, se apilar&amp;aacute; como una matriz dispersa si la densidad es menor que este valor. Utilice &lt;code&gt;sparse_threshold=0&lt;/code&gt; para devolver siempre denso. Cuando la salida transformada consta de todos los datos escasos o densos, el resultado apilado ser&amp;aacute; escaso o denso, respectivamente, y esta palabra clave se ignorar&amp;aacute;.</target>
        </trans-unit>
        <trans-unit id="efca83041c066057e65d83989c4190b74b69dba6" translate="yes" xml:space="preserve">
          <source>If the underlying graph has nodes with much more connections than the average node, the algorithm will miss some of these connections.</source>
          <target state="translated">Si el gráfico subyacente tiene nodos con muchas más conexiones que el nodo promedio,el algoritmo perderá algunas de estas conexiones.</target>
        </trans-unit>
        <trans-unit id="27f470c8c1d74aa01f92e63860f4d2b9149dd0bb" translate="yes" xml:space="preserve">
          <source>If there are few data points per dimension, noise in the observations induces high variance:</source>
          <target state="translated">Si hay pocos puntos de datos por dimensión,el ruido en las observaciones induce una alta variabilidad:</target>
        </trans-unit>
        <trans-unit id="fbaec65eed1139944f6f906201326eaef7bc4d08" translate="yes" xml:space="preserve">
          <source>If there are more than two classes, \(f(x)\) itself would be a vector of size (n_classes,). Instead of passing through logistic function, it passes through the softmax function, which is written as,</source>
          <target state="translated">Si hay más de dos clases,el mismo sería un vector de tamaño (n_clases,).En lugar de pasar por la función logística,pasa por la función softmax,que se escribe como,</target>
        </trans-unit>
        <trans-unit id="e2c9b002eac60ce02e4a3cafb47196266855c43e" translate="yes" xml:space="preserve">
          <source>If there are more than two labels, &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt;&lt;code&gt;hinge_loss&lt;/code&gt;&lt;/a&gt; uses a multiclass variant due to Crammer &amp;amp; Singer. &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume2/crammer01a/crammer01a.pdf&quot;&gt;Here&lt;/a&gt; is the paper describing it.</source>
          <target state="translated">Si hay m&amp;aacute;s de dos etiquetas, &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt; &lt;code&gt;hinge_loss&lt;/code&gt; &lt;/a&gt; usa una variante multiclase debido a Crammer &amp;amp; Singer. &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume2/crammer01a/crammer01a.pdf&quot;&gt;Aqu&amp;iacute;&lt;/a&gt; est&amp;aacute; el art&amp;iacute;culo que lo describe.</target>
        </trans-unit>
        <trans-unit id="362b6e0ad023f937918b9ce5c294c8243f2c8ea1" translate="yes" xml:space="preserve">
          <source>If there is a possibility that the training data might have missing categorical features, it can often be better to specify &lt;code&gt;handle_unknown='ignore'&lt;/code&gt; instead of setting the &lt;code&gt;categories&lt;/code&gt; manually as above. When &lt;code&gt;handle_unknown='ignore'&lt;/code&gt; is specified and unknown categories are encountered during transform, no error will be raised but the resulting one-hot encoded columns for this feature will be all zeros (&lt;code&gt;handle_unknown='ignore'&lt;/code&gt; is only supported for one-hot encoding):</source>
          <target state="translated">Si existe la posibilidad de que a los datos de entrenamiento les falten caracter&amp;iacute;sticas categ&amp;oacute;ricas, a menudo puede ser mejor especificar &lt;code&gt;handle_unknown='ignore'&lt;/code&gt; en lugar de configurar las &lt;code&gt;categories&lt;/code&gt; manualmente como se indic&amp;oacute; anteriormente. Cuando se especifica &lt;code&gt;handle_unknown='ignore'&lt;/code&gt; y se encuentran categor&amp;iacute;as desconocidas durante la transformaci&amp;oacute;n, no se generar&amp;aacute; ning&amp;uacute;n error, pero las columnas codificadas one-hot resultantes para esta funci&amp;oacute;n ser&amp;aacute;n todas ceros ( &lt;code&gt;handle_unknown='ignore'&lt;/code&gt; solo es compatible con la codificaci&amp;oacute;n one-hot ):</target>
        </trans-unit>
        <trans-unit id="76c3aee0f8dcd7757eeddd2a91b271bc2108fb17" translate="yes" xml:space="preserve">
          <source>If there is more than one such value, only the first is returned. The bin-count for the modal bins is also returned.</source>
          <target state="translated">Si hay más de un valor de este tipo,sólo se devuelve el primero.También se devuelve el recuento de los contenedores modales.</target>
        </trans-unit>
        <trans-unit id="e4599c6e53b844db2376ed9e56ed7b49e63c6ec3" translate="yes" xml:space="preserve">
          <source>If this is a tuple of ints, a mean is performed over multiple axes, instead of a single axis or all the axes as before.</source>
          <target state="translated">Si se trata de una tupla de ints,se realiza una media sobre varios ejes,en lugar de un solo eje o todos los ejes como antes.</target>
        </trans-unit>
        <trans-unit id="015e500928e7c3f86f2c9b5121c746246fcd7a9f" translate="yes" xml:space="preserve">
          <source>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array.</source>
          <target state="translated">Si esto se establece en True,los ejes que se reducen se dejan en el resultado como dimensiones con tamaño uno.Con esta opción,el resultado se emitirá correctamente contra la matriz de entrada.</target>
        </trans-unit>
        <trans-unit id="1d47783a4de427039b4db643f305b3dd195e7ba2" translate="yes" xml:space="preserve">
          <source>If this split node has a parent subcluster and there is room for a new subcluster, then the parent is split into two. If there is no room, then this node is again split into two and the process is continued recursively, till it reaches the root.</source>
          <target state="translated">Si este nodo dividido tiene un subconjunto padre y hay espacio para un nuevo subconjunto,entonces el padre se divide en dos.Si no hay espacio,entonces este nodo se divide de nuevo en dos y el proceso continúa recursivamente,hasta que llega a la raíz.</target>
        </trans-unit>
        <trans-unit id="012f5a7e85e6e4a424dae20b5f0c103c4fa516ee" translate="yes" xml:space="preserve">
          <source>If true (default), use a breadth-first approach to the problem. Otherwise use a depth-first approach.</source>
          <target state="translated">Si es cierto (por defecto),utilice un enfoque de amplitud primero para el problema.De lo contrario,utilice un enfoque de profundidad primero.</target>
        </trans-unit>
        <trans-unit id="8002efc50268110232cc0ffbdad97c50440caadd" translate="yes" xml:space="preserve">
          <source>If true, X and y will be centered.</source>
          <target state="translated">Si es cierto,X e Y estarán centrados.</target>
        </trans-unit>
        <trans-unit id="de73b79cb6d725781d21d3fce59be150e3f40a4c" translate="yes" xml:space="preserve">
          <source>If true, initial kernel locations are not locations of all points, but rather the location of the discretized version of points, where points are binned onto a grid whose coarseness corresponds to the bandwidth. Setting this option to True will speed up the algorithm because fewer seeds will be initialized. Ignored if seeds argument is not None.</source>
          <target state="translated">Si es cierto,las ubicaciones iniciales del núcleo no son las ubicaciones de todos los puntos,sino más bien la ubicación de la versión discretizada de los puntos,en la que los puntos están ubicados en una cuadrícula cuya grosería corresponde al ancho de banda.Si se establece esta opción en True se acelerará el algoritmo porque se inicializarán menos semillas.Se ignora si el argumento de las semillas no es None.</target>
        </trans-unit>
        <trans-unit id="382a329c7d03e3dc0838d8f846116bb309725e41" translate="yes" xml:space="preserve">
          <source>If true, initial kernel locations are not locations of all points, but rather the location of the discretized version of points, where points are binned onto a grid whose coarseness corresponds to the bandwidth. Setting this option to True will speed up the algorithm because fewer seeds will be initialized. default value: False Ignored if seeds argument is not None.</source>
          <target state="translated">Si es cierto,las ubicaciones iniciales del núcleo no son las ubicaciones de todos los puntos,sino más bien la ubicación de la versión discretizada de los puntos,en la que los puntos están ubicados en una cuadrícula cuya grosería corresponde al ancho de banda.Si se establece esta opción en True se acelerará el algoritmo porque se inicializarán menos semillas.valor predeterminado:Falso Ignorado si el argumento de las semillas no es None.</target>
        </trans-unit>
        <trans-unit id="5f8f1503f4ad4447aabcfddb9ab2a5dcd7bfde79" translate="yes" xml:space="preserve">
          <source>If true, only interaction features are produced: features that are products of at most &lt;code&gt;degree&lt;/code&gt;&lt;em&gt;distinct&lt;/em&gt; input features (so not &lt;code&gt;x[1] ** 2&lt;/code&gt;, &lt;code&gt;x[0] * x[2] ** 3&lt;/code&gt;, etc.).</source>
          <target state="translated">Si es verdadero, solo se producen caracter&amp;iacute;sticas de interacci&amp;oacute;n: caracter&amp;iacute;sticas que son productos de &lt;em&gt;caracter&amp;iacute;sticas de&lt;/em&gt; entrada &lt;em&gt;distintas&lt;/em&gt; en su mayor &lt;code&gt;degree&lt;/code&gt; (por lo tanto, no &lt;code&gt;x[1] ** 2&lt;/code&gt; , &lt;code&gt;x[0] * x[2] ** 3&lt;/code&gt; , etc.).&lt;em&gt;&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="2d6ce18ffe19be253728c95b7f8882b85215b418" translate="yes" xml:space="preserve">
          <source>If true, randomize the order of coordinates in the CD solver.</source>
          <target state="translated">Si es cierto,aleatoriza el orden de las coordenadas en el solucionador de CD.</target>
        </trans-unit>
        <trans-unit id="c9d7c7ecbdd08be425848806cc6f9d68c29d7323" translate="yes" xml:space="preserve">
          <source>If true, return the mean loss per sample. Otherwise, return the sum of the per-sample losses.</source>
          <target state="translated">Si es cierto,devuelva la pérdida media por muestra.En caso contrario,devuelva la suma de las pérdidas por muestra.</target>
        </trans-unit>
        <trans-unit id="6d32e9cabd3e10e0279ad9dd2b7c71514057bf52" translate="yes" xml:space="preserve">
          <source>If true, then all points are clustered, even those orphans that are not within any kernel. Orphans are assigned to the nearest kernel. If false, then orphans are given cluster label -1.</source>
          <target state="translated">Si es cierto,entonces todos los puntos están agrupados,incluso los huérfanos que no están dentro de ningún núcleo.Los huérfanos son asignados al núcleo más cercano.Si es falso,entonces a los huérfanos se les da la etiqueta de grupo -1.</target>
        </trans-unit>
        <trans-unit id="87535a59e28d16a49b32c83a6882f2aefd67503d" translate="yes" xml:space="preserve">
          <source>If true, use a dualtree algorithm. Otherwise, use a single-tree algorithm. Dual tree algorithms can have better scaling for large N.</source>
          <target state="translated">Si es cierto,use un algoritmo de doble árbol.De lo contrario,use un algoritmo de árbol único.Los algoritmos de árbol dual pueden tener una mejor escala para el N grande.</target>
        </trans-unit>
        <trans-unit id="a62f22814f97612f53d5c62d8ea50a484acea3fc" translate="yes" xml:space="preserve">
          <source>If two variables are almost equally correlated with the response, then their coefficients should increase at approximately the same rate. The algorithm thus behaves as intuition would expect, and also is more stable.</source>
          <target state="translated">Si dos variables están casi igualmente correlacionadas con la respuesta,entonces sus coeficientes deberían aumentar aproximadamente a la misma velocidad.El algoritmo se comporta así como la intuición esperaría,y también es más estable.</target>
        </trans-unit>
        <trans-unit id="c6d813716240a58cb1e341ee096ed78ff4d17824" translate="yes" xml:space="preserve">
          <source>If verbose is True, the objective function and dual gap are plotted at each iteration.</source>
          <target state="translated">Si la verbosidad es verdadera,la función objetiva y la doble brecha se trazan en cada iteración.</target>
        </trans-unit>
        <trans-unit id="c845cf733c967b921d034159fbd6e6d551e8f5a1" translate="yes" xml:space="preserve">
          <source>If verbose is True, the objective function and dual gap are printed at each iteration.</source>
          <target state="translated">Si la verbosidad es verdadera,la función objetivo y la doble brecha se imprimen en cada iteración.</target>
        </trans-unit>
        <trans-unit id="d04bb65f95446e17ac813ad52d517cc52bee8bef" translate="yes" xml:space="preserve">
          <source>If verbose is True, the objective function and duality gap are printed at each iteration.</source>
          <target state="translated">Si la palabra &quot;verboso&quot; es &quot;verdadero&quot;,la función objetivo y la brecha de dualidad se imprimen en cada iteración.</target>
        </trans-unit>
        <trans-unit id="c297e2c2dea63aea70529d05594e08d33ba95930" translate="yes" xml:space="preserve">
          <source>If warm-starts are enabled, the solution of the last Newton iteration on the Laplace approximation of the posterior mode is used as initialization for the next call of _posterior_mode(). This can speed up convergence when _posterior_mode is called several times on similar problems as in hyperparameter optimization. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Si los inicios en caliente est&amp;aacute;n habilitados, la soluci&amp;oacute;n de la &amp;uacute;ltima iteraci&amp;oacute;n de Newton en la aproximaci&amp;oacute;n de Laplace del modo posterior se usa como inicializaci&amp;oacute;n para la siguiente llamada de _posterior_mode (). Esto puede acelerar la convergencia cuando se llama a _posterior_mode varias veces en problemas similares como en la optimizaci&amp;oacute;n de hiperpar&amp;aacute;metros. Consulte &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;el glosario&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0beda1307d8fba8bf455ad043421d0e1b5743334" translate="yes" xml:space="preserve">
          <source>If we consider the loss function to be the individual error per sample, then the data-fit term, or the sum of the error for each sample, will increase as we add more samples. The penalization term, however, will not increase.</source>
          <target state="translated">Si consideramos que la función de pérdida es el error individual por muestra,entonces el término de ajuste de datos,o la suma del error de cada muestra,aumentará a medida que añadamos más muestras.El término de penalización,sin embargo,no aumentará.</target>
        </trans-unit>
        <trans-unit id="232b0b83965c86185ba5cb4047fca7ca1eb2e5e8" translate="yes" xml:space="preserve">
          <source>If we define &lt;code&gt;s = 1 / density&lt;/code&gt;, the elements of the random matrix are drawn from</source>
          <target state="translated">Si definimos &lt;code&gt;s = 1 / density&lt;/code&gt; , los elementos de la matriz aleatoria se extraen de</target>
        </trans-unit>
        <trans-unit id="1427e0ae27c6ada10257117ddf3e602836e812e6" translate="yes" xml:space="preserve">
          <source>If we note &lt;code&gt;s = 1 / density&lt;/code&gt; the components of the random matrix are drawn from:</source>
          <target state="translated">Si observamos &lt;code&gt;s = 1 / density&lt;/code&gt; los componentes de la matriz aleatoria se extraen de:</target>
        </trans-unit>
        <trans-unit id="f9cbc4d2964857d1865d4f91b696f12d3cce3cff" translate="yes" xml:space="preserve">
          <source>If we note \(n_{\max} = \max(n_{\mathrm{samples}}, n_{\mathrm{features}})\) and \(n_{\min} = \min(n_{\mathrm{samples}}, n_{\mathrm{features}})\), the time complexity of the randomized &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; is \(O(n_{\max}^2 \cdot n_{\mathrm{components}})\) instead of \(O(n_{\max}^2 \cdot n_{\min})\) for the exact method implemented in &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Si notamos \ (n _ {\ max} = \ max (n _ {\ mathrm {muestras}}, n _ {\ mathrm {caracter&amp;iacute;sticas}}) \) y \ (n _ {\ min} = \ min (n _ {\ mathrm {samples}}, n _ {\ mathrm {features}}) \), la complejidad de tiempo del &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; aleatorio es \ (O (n _ {\ max} ^ 2 \ cdot n _ {\ mathrm {components}}) \) en su lugar of \ (O (n _ {\ max} ^ 2 \ cdot n _ {\ min}) \) para el m&amp;eacute;todo exacto implementado en &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="483854d9b52bcc6a7814b6c99e197398a7767c0e" translate="yes" xml:space="preserve">
          <source>If we use l2 shrinkage, as with the Ledoit-Wolf estimator, as the number of samples is small, we need to shrink a lot. As a result, the Ledoit-Wolf precision is fairly close to the ground truth precision, that is not far from being diagonal, but the off-diagonal structure is lost.</source>
          <target state="translated">Si usamos la contracción l2,como con el estimador Ledoit-Wolf,ya que el número de muestras es pequeño,necesitamos reducir mucho.Como resultado,la precisión de Ledoit-Wolf es bastante cercana a la precisión de la verdad del terreno,que no está lejos de ser diagonal,pero la estructura fuera de la diagonal se pierde.</target>
        </trans-unit>
        <trans-unit id="c048d2d806d4fc664d0d49e2240da1f9038d7165" translate="yes" xml:space="preserve">
          <source>If we want to fit a paraboloid to the data instead of a plane, we can combine the features in second-order polynomials, so that the model looks like this:</source>
          <target state="translated">Si queremos ajustar un paraboloide a los datos en lugar de un plano,podemos combinar las características en polinomios de segundo orden,para que el modelo tenga este aspecto:</target>
        </trans-unit>
        <trans-unit id="9cd2bdd13889db844fd297c5019d226d5f2214ec" translate="yes" xml:space="preserve">
          <source>If we would restrict the model further, by assuming that the Gaussian noise is even isotropic (all diagonal entries are the same) we would obtain &lt;code&gt;PPCA&lt;/code&gt;.</source>
          <target state="translated">Si restringi&amp;eacute;ramos a&amp;uacute;n m&amp;aacute;s el modelo, asumiendo que el ruido gaussiano es incluso is&amp;oacute;tropo (todas las entradas diagonales son iguales) obtendr&amp;iacute;amos &lt;code&gt;PPCA&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="722d8ecf13f293f3aeb1f206f30063d8afe3b1aa" translate="yes" xml:space="preserve">
          <source>If whiten is false, the data is already considered to be whitened, and no whitening is performed.</source>
          <target state="translated">Si el blanqueo es falso,los datos ya se consideran blanqueados y no se realiza ningún blanqueo.</target>
        </trans-unit>
        <trans-unit id="7d7146f3cf5f6ee3a12daad9561636b3070c19dc" translate="yes" xml:space="preserve">
          <source>If whitening is enabled, inverse_transform will compute the exact inverse operation, which includes reversing whitening.</source>
          <target state="translated">Si se habilita el blanqueamiento,la transformación_inversa calculará la operación inversa exacta,que incluye la inversión del blanqueamiento.</target>
        </trans-unit>
        <trans-unit id="d6701cdf426d6a22381b3dd206332eab0defeb4b" translate="yes" xml:space="preserve">
          <source>If you apply SGD to features extracted using PCA we found that it is often wise to scale the feature values by some constant &lt;code&gt;c&lt;/code&gt; such that the average L2 norm of the training data equals one.</source>
          <target state="translated">Si aplica SGD a las caracter&amp;iacute;sticas extra&amp;iacute;das mediante PCA, descubrimos que a menudo es aconsejable escalar los valores de las caracter&amp;iacute;sticas mediante una constante &lt;code&gt;c&lt;/code&gt; de modo que la norma L2 promedio de los datos de entrenamiento sea igual a uno.</target>
        </trans-unit>
        <trans-unit id="88e7b5f8ea1b769958767cd4c4986cb0d84b69d4" translate="yes" xml:space="preserve">
          <source>If you are having trouble decoding text, here are some things to try:</source>
          <target state="translated">Si tienes problemas para descifrar el texto,aquí tienes algunas cosas que puedes probar:</target>
        </trans-unit>
        <trans-unit id="79c8dbf5a9dd8e0bcb21dbc0b3d21d4a002af1f5" translate="yes" xml:space="preserve">
          <source>If you are interested in controlling the L1 and L2 penalty separately, keep in mind that this is equivalent to:</source>
          <target state="translated">Si le interesa controlar la pena L1 y L2 por separado,tenga en cuenta que esto equivale a..:</target>
        </trans-unit>
        <trans-unit id="fda5569b1e927ca58d1243554ef8331577e43162" translate="yes" xml:space="preserve">
          <source>If you do not provide an a-priori dictionary and you do not use an analyzer that does some kind of feature selection then the number of features will be equal to the vocabulary size found by analyzing the data.</source>
          <target state="translated">Si no proporciona un diccionario a-priori y no utiliza un analizador que haga algún tipo de selección de características,entonces el número de características será igual al tamaño del vocabulario encontrado al analizar los datos.</target>
        </trans-unit>
        <trans-unit id="44906a85511569286aafb87826155b3c2905ddf9" translate="yes" xml:space="preserve">
          <source>If you don&amp;rsquo;t have labels, try using &lt;a href=&quot;../../auto_examples/text/plot_document_clustering#sphx-glr-auto-examples-text-plot-document-clustering-py&quot;&gt;Clustering&lt;/a&gt; on your problem.</source>
          <target state="translated">Si no tiene etiquetas, intente usar &lt;a href=&quot;../../auto_examples/text/plot_document_clustering#sphx-glr-auto-examples-text-plot-document-clustering-py&quot;&gt;Clustering&lt;/a&gt; en su problema.</target>
        </trans-unit>
        <trans-unit id="1e3c9a76f4703e92f09f761bb01632ba0994c7fc" translate="yes" xml:space="preserve">
          <source>If you experience hanging subprocesses with &lt;code&gt;n_jobs&amp;gt;1&lt;/code&gt; or &lt;code&gt;n_jobs=-1&lt;/code&gt;, make sure you have a single-threaded BLAS library, or set &lt;code&gt;n_jobs=1&lt;/code&gt;, or upgrade to Python 3.4 which has a new version of &lt;code&gt;multiprocessing&lt;/code&gt; that should be immune to this problem.</source>
          <target state="translated">Si experimenta subprocesos colgantes con &lt;code&gt;n_jobs&amp;gt;1&lt;/code&gt; o &lt;code&gt;n_jobs=-1&lt;/code&gt; , aseg&amp;uacute;rese de tener una biblioteca BLAS de un solo subproceso, o establezca &lt;code&gt;n_jobs=1&lt;/code&gt; , o actualice a Python 3.4, que tiene una nueva versi&amp;oacute;n de &lt;code&gt;multiprocessing&lt;/code&gt; que deber&amp;iacute;a ser inmune a esto problema.</target>
        </trans-unit>
        <trans-unit id="b4d3f940390acd5b7c567c108aba27222ddceb7d" translate="yes" xml:space="preserve">
          <source>If you have a kernel matrix of a kernel \(K\) that computes a dot product in a feature space defined by function \(phi\), a &lt;a href=&quot;generated/sklearn.preprocessing.kernelcenterer#sklearn.preprocessing.KernelCenterer&quot;&gt;&lt;code&gt;KernelCenterer&lt;/code&gt;&lt;/a&gt; can transform the kernel matrix so that it contains inner products in the feature space defined by \(phi\) followed by removal of the mean in that space.</source>
          <target state="translated">Si tiene una matriz de kernel de un kernel \ (K \) que calcula un producto &lt;a href=&quot;generated/sklearn.preprocessing.kernelcenterer#sklearn.preprocessing.KernelCenterer&quot;&gt; &lt;code&gt;KernelCenterer&lt;/code&gt; &lt;/a&gt; en un espacio de caracter&amp;iacute;sticas definido por la funci&amp;oacute;n \ (phi \), un KernelCenterer puede transformar la matriz de kernel para que contenga productos internos en el espacio de caracter&amp;iacute;sticas definido por \ (phi \) seguido de la eliminaci&amp;oacute;n de la media en ese espacio.</target>
        </trans-unit>
        <trans-unit id="2615ef2dcc8005e7f8f1fe1a8b864f8c5c8b40ba" translate="yes" xml:space="preserve">
          <source>If you have an affinity matrix, such as a distance matrix, for which 0 means identical elements, and high values means very dissimilar elements, it can be transformed in a similarity matrix that is well suited for the algorithm by applying the Gaussian (RBF, heat) kernel:</source>
          <target state="translated">Si se tiene una matriz de afinidad,como una matriz de distancia,para la cual 0 significa elementos idénticos,y valores altos significa elementos muy disímiles,puede transformarse en una matriz de similitud que se adapte bien al algoritmo aplicando el núcleo gaussiano (RBF,calor):</target>
        </trans-unit>
        <trans-unit id="fe35ae96a69c356c4c790a684b706493b567f769" translate="yes" xml:space="preserve">
          <source>If you have multiple labels per document, e.g categories, have a look at the &lt;a href=&quot;../../modules/multiclass#multiclass&quot;&gt;Multiclass and multilabel section&lt;/a&gt;.</source>
          <target state="translated">Si tiene varias etiquetas por documento, por ejemplo, categor&amp;iacute;as, eche un vistazo a la &lt;a href=&quot;../../modules/multiclass#multiclass&quot;&gt;secci&amp;oacute;n Multiclass y multilabel&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="4c5f38a361bcbafd12cc29508483a444dfcf9728" translate="yes" xml:space="preserve">
          <source>If you have several classes to predict, an option often used is to fit one-versus-all classifiers and then use a voting heuristic for the final decision.</source>
          <target state="translated">Si se tienen varias clases para predecir,una opción que se utiliza a menudo es la de ajustar uno contra todos los clasificadores y luego utilizar un heurístico de votación para la decisión final.</target>
        </trans-unit>
        <trans-unit id="f97615967054f5695c197161c38be5160cb380e9" translate="yes" xml:space="preserve">
          <source>If you need the raw values of the partial dependence function rather than the plots you can use the &lt;a href=&quot;generated/sklearn.ensemble.partial_dependence.partial_dependence#sklearn.ensemble.partial_dependence.partial_dependence&quot;&gt;&lt;code&gt;partial_dependence&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Si necesita los valores en bruto de la funci&amp;oacute;n de la dependencia parcial en lugar de las parcelas se puede utilizar el &lt;a href=&quot;generated/sklearn.ensemble.partial_dependence.partial_dependence#sklearn.ensemble.partial_dependence.partial_dependence&quot;&gt; &lt;code&gt;partial_dependence&lt;/code&gt; &lt;/a&gt; funci&amp;oacute;n:</target>
        </trans-unit>
        <trans-unit id="57ce2ca8cd47ab25ffa05da2880829913ab0ea8d" translate="yes" xml:space="preserve">
          <source>If you really want to use &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; for novelty detection, i.e. predict labels or compute the score of abnormality of new unseen data, you can instantiate the estimator with the &lt;code&gt;novelty&lt;/code&gt; parameter set to &lt;code&gt;True&lt;/code&gt; before fitting the estimator. In this case, &lt;code&gt;fit_predict&lt;/code&gt; is not available.</source>
          <target state="translated">Si realmente desea utilizar &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt; para la detecci&amp;oacute;n de novedades, es decir, predecir etiquetas o calcular la puntuaci&amp;oacute;n de anomal&amp;iacute;a de nuevos datos no vistos, puede crear una instancia del estimador con el par&amp;aacute;metro de &lt;code&gt;novelty&lt;/code&gt; establecido en &lt;code&gt;True&lt;/code&gt; antes de ajustar el estimador. En este caso, &lt;code&gt;fit_predict&lt;/code&gt; no est&amp;aacute; disponible.</target>
        </trans-unit>
        <trans-unit id="9f2c392b35ce2be9956cf3b6740e21a9cb0e7eb8" translate="yes" xml:space="preserve">
          <source>If you set load_content=True, you should also specify the encoding of the text using the &amp;lsquo;encoding&amp;rsquo; parameter. For many modern text files, &amp;lsquo;utf-8&amp;rsquo; will be the correct encoding. If you leave encoding equal to None, then the content will be made of bytes instead of Unicode, and you will not be able to use most functions in &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt;.</source>
          <target state="translated">Si establece load_content = True, tambi&amp;eacute;n debe especificar la codificaci&amp;oacute;n del texto usando el par&amp;aacute;metro 'codificaci&amp;oacute;n'. Para muchos archivos de texto modernos, 'utf-8' ser&amp;aacute; la codificaci&amp;oacute;n correcta. Si deja la codificaci&amp;oacute;n igual a None, entonces el contenido estar&amp;aacute; compuesto por bytes en lugar de Unicode, y no podr&amp;aacute; usar la mayor&amp;iacute;a de las funciones en &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="bc2de8e7176de3a7ec5f2ba66eebe7612bd92fb1" translate="yes" xml:space="preserve">
          <source>If you specify &lt;code&gt;max_depth=h&lt;/code&gt; then complete binary trees of depth &lt;code&gt;h&lt;/code&gt; will be grown. Such trees will have (at most) &lt;code&gt;2**h&lt;/code&gt; leaf nodes and &lt;code&gt;2**h - 1&lt;/code&gt; split nodes.</source>
          <target state="translated">Si especifica &lt;code&gt;max_depth=h&lt;/code&gt; &lt;code&gt;h&lt;/code&gt; , se cultivar&amp;aacute;n &amp;aacute;rboles binarios completos de profundidad h . Dichos &amp;aacute;rboles tendr&amp;aacute;n (como m&amp;aacute;ximo) &lt;code&gt;2**h&lt;/code&gt; nodos de hojas y &lt;code&gt;2**h - 1&lt;/code&gt; nodos divididos.</target>
        </trans-unit>
        <trans-unit id="b5e591b33a0bd24a7e9f3db1117e493d465fb600" translate="yes" xml:space="preserve">
          <source>If you use sparse data (i.e. data represented as sparse matrices), &lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt;&lt;code&gt;chi2&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_regression#sklearn.feature_selection.mutual_info_regression&quot;&gt;&lt;code&gt;mutual_info_regression&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_classif#sklearn.feature_selection.mutual_info_classif&quot;&gt;&lt;code&gt;mutual_info_classif&lt;/code&gt;&lt;/a&gt; will deal with the data without making it dense.</source>
          <target state="translated">Si usa datos dispersos (es decir, datos representados como matrices dispersas), &lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt; &lt;code&gt;chi2&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_regression#sklearn.feature_selection.mutual_info_regression&quot;&gt; &lt;code&gt;mutual_info_regression&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_classif#sklearn.feature_selection.mutual_info_classif&quot;&gt; &lt;code&gt;mutual_info_classif&lt;/code&gt; &lt;/a&gt; tratar&amp;aacute; los datos sin hacerlos densos.</target>
        </trans-unit>
        <trans-unit id="a1ac2d367786359c2f555cec450b280865094e6b" translate="yes" xml:space="preserve">
          <source>If you want more control over stopping criteria or learning rate in SGD, or want to do additional monitoring, using &lt;code&gt;warm_start=True&lt;/code&gt; and &lt;code&gt;max_iter=1&lt;/code&gt; and iterating yourself can be helpful:</source>
          <target state="translated">Si desea tener m&amp;aacute;s control sobre los criterios de detenci&amp;oacute;n o la tasa de aprendizaje en SGD, o desea realizar un seguimiento adicional, puede ser &amp;uacute;til usar &lt;code&gt;warm_start=True&lt;/code&gt; y &lt;code&gt;max_iter=1&lt;/code&gt; e iterar usted mismo:</target>
        </trans-unit>
        <trans-unit id="5572f4380789e92c52811040d71f90082bdb6315" translate="yes" xml:space="preserve">
          <source>If you want to know more about these issues and explore other possible serialization methods, please refer to this &lt;a href=&quot;http://pyvideo.org/video/2566/pickles-are-for-delis-not-software&quot;&gt;talk by Alex Gaynor&lt;/a&gt;.</source>
          <target state="translated">Si desea saber m&amp;aacute;s sobre estos problemas y explorar otros posibles m&amp;eacute;todos de serializaci&amp;oacute;n, consulte esta &lt;a href=&quot;http://pyvideo.org/video/2566/pickles-are-for-delis-not-software&quot;&gt;charla de Alex Gaynor&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="c9d28c176517636a408517ab464ebf5a8ed78a10" translate="yes" xml:space="preserve">
          <source>If your attributes have an intrinsic scale (e.g. word frequencies or indicator features) scaling is not needed.</source>
          <target state="translated">Si sus atributos tienen una escala intrínseca (por ejemplo,frecuencias de palabras o características de los indicadores)la escala no es necesaria.</target>
        </trans-unit>
        <trans-unit id="1c54fdc8274e03b04e776296dd28d5ff9fd81085" translate="yes" xml:space="preserve">
          <source>If your data contains many outliers, scaling using the mean and variance of the data is likely to not work very well. In these cases, you can use &lt;a href=&quot;generated/sklearn.preprocessing.robust_scale#sklearn.preprocessing.robust_scale&quot;&gt;&lt;code&gt;robust_scale&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.preprocessing.robustscaler#sklearn.preprocessing.RobustScaler&quot;&gt;&lt;code&gt;RobustScaler&lt;/code&gt;&lt;/a&gt; as drop-in replacements instead. They use more robust estimates for the center and range of your data.</source>
          <target state="translated">Si sus datos contienen muchos valores at&amp;iacute;picos, es probable que el escalado utilizando la media y la varianza de los datos no funcione muy bien. En estos casos, puede usar &lt;a href=&quot;generated/sklearn.preprocessing.robust_scale#sklearn.preprocessing.robust_scale&quot;&gt; &lt;code&gt;robust_scale&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.preprocessing.robustscaler#sklearn.preprocessing.RobustScaler&quot;&gt; &lt;code&gt;RobustScaler&lt;/code&gt; &lt;/a&gt; como reemplazos directos . Usan estimaciones m&amp;aacute;s s&amp;oacute;lidas para el centro y rango de sus datos.</target>
        </trans-unit>
        <trans-unit id="a10bfba29a759d89e81956a541262290109cf294" translate="yes" xml:space="preserve">
          <source>If your number of features is high, it may be useful to reduce it with an unsupervised step prior to supervised steps. Many of the &lt;a href=&quot;http://scikit-learn.org/stable/unsupervised_learning.html#unsupervised-learning&quot;&gt;Unsupervised learning&lt;/a&gt; methods implement a &lt;code&gt;transform&lt;/code&gt; method that can be used to reduce the dimensionality. Below we discuss two specific example of this pattern that are heavily used.</source>
          <target state="translated">Si su n&amp;uacute;mero de funciones es alto, puede ser &amp;uacute;til reducirlo con un paso sin supervisi&amp;oacute;n antes de los pasos supervisados. Muchos de los m&amp;eacute;todos de &lt;a href=&quot;http://scikit-learn.org/stable/unsupervised_learning.html#unsupervised-learning&quot;&gt;aprendizaje no supervisados&lt;/a&gt; implementan un m&amp;eacute;todo de &lt;code&gt;transform&lt;/code&gt; aci&amp;oacute;n que se puede utilizar para reducir la dimensionalidad. A continuaci&amp;oacute;n, analizamos dos ejemplos espec&amp;iacute;ficos de este patr&amp;oacute;n que se utilizan mucho.</target>
        </trans-unit>
        <trans-unit id="933c257247173f2464c3cf8d4de4af2d678e5a7c" translate="yes" xml:space="preserve">
          <source>If your number of observations is not large compared to the number of edges in your underlying graph, you will not recover it.</source>
          <target state="translated">Si el número de observaciones no es grande comparado con el número de bordes de su gráfico subyacente,no lo recuperará.</target>
        </trans-unit>
        <trans-unit id="4f34c772816074a373c0d5e918e2e9ac136448b7" translate="yes" xml:space="preserve">
          <source>Ignore the offset first bytes by seeking forward, then discarding the following bytes up until the next new line character.</source>
          <target state="translated">Ignoren el desplazamiento de los primeros bytes buscando hacia adelante,luego descartando los siguientes bytes hasta el próximo carácter de la nueva línea.</target>
        </trans-unit>
        <trans-unit id="78fee1435d74666b84850cd5e82c18229351da5d" translate="yes" xml:space="preserve">
          <source>Ignored</source>
          <target state="translated">Ignored</target>
        </trans-unit>
        <trans-unit id="1e65bb4eca2d3c71529c96890a4b735eb7dafeac" translate="yes" xml:space="preserve">
          <source>Ignored.</source>
          <target state="translated">Ignored.</target>
        </trans-unit>
        <trans-unit id="1e417badfc4d52f79664b451110854e41b4a0daf" translate="yes" xml:space="preserve">
          <source>Ignored. This parameter exists only for compatibility with sklearn.pipeline.Pipeline.</source>
          <target state="translated">Ignorado.Este parámetro sólo existe para la compatibilidad con sklearn.pipeline.Pipeline.</target>
        </trans-unit>
        <trans-unit id="2d34b7c897f7b41a0f0625575a2c9cc21b1078a7" translate="yes" xml:space="preserve">
          <source>Illustration of &lt;code&gt;Pipeline&lt;/code&gt; and &lt;code&gt;GridSearchCV&lt;/code&gt;</source>
          <target state="translated">Ilustraci&amp;oacute;n de &lt;code&gt;Pipeline&lt;/code&gt; y &lt;code&gt;GridSearchCV&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="643998f34944846c305de7d49de1c3e80f814d2d" translate="yes" xml:space="preserve">
          <source>Illustration of Gaussian process classification (GPC) on the XOR dataset</source>
          <target state="translated">Ilustración de la clasificación del proceso Gaussiano (GPC)en el conjunto de datos XOR</target>
        </trans-unit>
        <trans-unit id="c2cd661f8089fd4df71dfb566ea137083aa22024" translate="yes" xml:space="preserve">
          <source>Illustration of how the performance of an estimator on unseen data (test data) is not the same as the performance on training data. As the regularization increases the performance on train decreases while the performance on test is optimal within a range of values of the regularization parameter. The example with an Elastic-Net regression model and the performance is measured using the explained variance a.k.a. R^2.</source>
          <target state="translated">Ilustración de cómo el rendimiento de un estimador en datos no vistos (datos de prueba)no es el mismo que el rendimiento en datos de entrenamiento.A medida que la regularización aumenta el rendimiento en el tren disminuye mientras que el rendimiento en la prueba es óptimo dentro de un rango de valores del parámetro de regularización.El ejemplo con un modelo de regresión de Elastic-Net y el rendimiento se mide utilizando la varianza explicada,también conocida como R^2.</target>
        </trans-unit>
        <trans-unit id="5790a5aaa3a6c4543a820b9b12ce6d261eeb0581" translate="yes" xml:space="preserve">
          <source>Illustration of prior and posterior Gaussian process for different kernels</source>
          <target state="translated">Ilustración del proceso gaussiano anterior y posterior para diferentes núcleos</target>
        </trans-unit>
        <trans-unit id="27c062ea4e410688effe23ac51313a8ab9a70f1c" translate="yes" xml:space="preserve">
          <source>Illustration of the effect of different regularization strategies for Gradient Boosting. The example is taken from Hastie et al 2009 &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="translated">Ilustraci&amp;oacute;n del efecto de diferentes estrategias de regularizaci&amp;oacute;n para Gradient Boosting. El ejemplo est&amp;aacute; tomado de Hastie et al 2009 &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="5beb1d257bbb65ddb7ec568445a1c3acdcb42d37" translate="yes" xml:space="preserve">
          <source>Image denoising using dictionary learning</source>
          <target state="translated">Denotación de imágenes usando el aprendizaje del diccionario</target>
        </trans-unit>
        <trans-unit id="5ab7decf36c80b04aff06a11c0e8ef068c85a1b9" translate="yes" xml:space="preserve">
          <source>Image histogram</source>
          <target state="translated">Histograma de imágenes</target>
        </trans-unit>
        <trans-unit id="5c328038b14054033bab1147ef5d1ad234b3373d" translate="yes" xml:space="preserve">
          <source>Imagine you have three subjects, each with an associated number from 1 to 3:</source>
          <target state="translated">Imagina que tienes tres sujetos,cada uno con un número asociado del 1 al 3:</target>
        </trans-unit>
        <trans-unit id="8781d615fd77be9578225c40ac67b9471394cced" translate="yes" xml:space="preserve">
          <source>Implementation</source>
          <target state="translated">Implementation</target>
        </trans-unit>
        <trans-unit id="8d522809f4125f5930c1f4f77ec91f8735a003d8" translate="yes" xml:space="preserve">
          <source>Implementation based on &lt;code&gt;A. Hyvarinen and E. Oja, Independent Component Analysis: Algorithms and Applications, Neural Networks, 13(4-5), 2000, pp. 411-430&lt;/code&gt;</source>
          <target state="translated">Implementaci&amp;oacute;n basada en &lt;code&gt;A. Hyvarinen and E. Oja, Independent Component Analysis: Algorithms and Applications, Neural Networks, 13(4-5), 2000, pp. 411-430&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="b6ac8df85fe47d2d00b4a78e1facdef4fbcae73b" translate="yes" xml:space="preserve">
          <source>Implementation of Support Vector Machine classifier using libsvm: the kernel can be non-linear but its SMO algorithm does not scale to large number of samples as LinearSVC does. Furthermore SVC multi-class mode is implemented using one vs one scheme while LinearSVC uses one vs the rest. It is possible to implement one vs the rest with SVC by using the &lt;a href=&quot;sklearn.multiclass.onevsrestclassifier#sklearn.multiclass.OneVsRestClassifier&quot;&gt;&lt;code&gt;sklearn.multiclass.OneVsRestClassifier&lt;/code&gt;&lt;/a&gt; wrapper. Finally SVC can fit dense data without memory copy if the input is C-contiguous. Sparse data will still incur memory copy though.</source>
          <target state="translated">Implementaci&amp;oacute;n del clasificador Support Vector Machine usando libsvm: el kernel puede ser no lineal pero su algoritmo SMO no escala a un gran n&amp;uacute;mero de muestras como lo hace LinearSVC. Adem&amp;aacute;s, el modo de m&amp;uacute;ltiples clases de SVC se implementa usando un esquema de uno contra uno, mientras que LinearSVC usa uno contra el resto. Es posible implementar uno frente al resto con SVC utilizando el contenedor &lt;a href=&quot;sklearn.multiclass.onevsrestclassifier#sklearn.multiclass.OneVsRestClassifier&quot;&gt; &lt;code&gt;sklearn.multiclass.OneVsRestClassifier&lt;/code&gt; &lt;/a&gt; . Finalmente, SVC puede ajustar datos densos sin copia de memoria si la entrada es C-contigua. Sin embargo, los datos escasos seguir&amp;aacute;n incurriendo en copia de memoria.</target>
        </trans-unit>
        <trans-unit id="78b58091d5da65fb36aa747d9975841d97302dec" translate="yes" xml:space="preserve">
          <source>Implementation of Support Vector Machine classifier using the same library as this class (liblinear).</source>
          <target state="translated">Implementación del clasificador de la Máquina Vectorial de Soporte usando la misma biblioteca que esta clase (liblinear).</target>
        </trans-unit>
        <trans-unit id="0faf8832b17d93a1b230f7a6ca4feb36d15cc4ac" translate="yes" xml:space="preserve">
          <source>Implementation of Support Vector Machine regression using libsvm: the kernel can be non-linear but its SMO algorithm does not scale to large number of samples as LinearSVC does.</source>
          <target state="translated">Implementación de la regresión de la máquina de vectores de apoyo utilizando libsvm:el núcleo puede ser no lineal pero su algoritmo SMO no se escala a un gran número de muestras como lo hace LinearSVC.</target>
        </trans-unit>
        <trans-unit id="adae10003f16f5885f71700e866f2cc76e2c6af9" translate="yes" xml:space="preserve">
          <source>Implements feature hashing, aka the hashing trick.</source>
          <target state="translated">Implementa el &quot;hashing&quot;,también conocido como el truco del &quot;hashing&quot;.</target>
        </trans-unit>
        <trans-unit id="d98e09b894119d4a2d55bf3e2f04052ec103359a" translate="yes" xml:space="preserve">
          <source>Implements resampling with replacement. If False, this will implement (sliced) random permutations.</source>
          <target state="translated">Implementa el remuestreo con reemplazo.Si es falso,implementará (rebanado)permutaciones aleatorias.</target>
        </trans-unit>
        <trans-unit id="9f9d0b6a3b9dbc770ff8e17c3a6979d6ebb5425d" translate="yes" xml:space="preserve">
          <source>Implements the Birch clustering algorithm.</source>
          <target state="translated">Implementa el algoritmo de agrupación del abedul.</target>
        </trans-unit>
        <trans-unit id="82028db75262dc1a82a0dc4cf2e6f254032ff9f7" translate="yes" xml:space="preserve">
          <source>Implements the incremental PCA model from: &lt;code&gt;D. Ross, J. Lim, R. Lin, M. Yang, Incremental Learning for Robust Visual Tracking, International Journal of Computer Vision, Volume 77, Issue 1-3, pp. 125-141, May 2008.&lt;/code&gt; See &lt;a href=&quot;http://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf&quot;&gt;http://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf&lt;/a&gt;</source>
          <target state="translated">Implementa el modelo de PCA incremental de: &lt;code&gt;D. Ross, J. Lim, R. Lin, M. Yang, Incremental Learning for Robust Visual Tracking, International Journal of Computer Vision, Volume 77, Issue 1-3, pp. 125-141, May 2008.&lt;/code&gt; V&amp;eacute;ase &lt;a href=&quot;http://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf&quot;&gt;http://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="06be3bf25c44efb35fdd12e8816c051b94a6e5d6" translate="yes" xml:space="preserve">
          <source>Implements the probabilistic PCA model from: &lt;a href=&quot;#id1&quot;&gt;&lt;span id=&quot;id2&quot;&gt;`&lt;/span&gt;&lt;/a&gt;Tipping, M. E., and Bishop, C. M. (1999). &amp;ldquo;Probabilistic principal component analysis&amp;rdquo;. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 61(3), 611-622. via the score and score_samples methods. See &lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdf&lt;/a&gt;</source>
          <target state="translated">Implementa el modelo probabil&amp;iacute;stico de PCA de: &lt;a href=&quot;#id1&quot;&gt;&lt;span id=&quot;id2&quot;&gt;`&lt;/span&gt;&lt;/a&gt; Tipping, ME, y Bishop, CM (1999). &amp;ldquo;An&amp;aacute;lisis probabil&amp;iacute;stico de componentes principales&amp;rdquo;. Revista de la Royal Statistical Society: Serie B (Metodolog&amp;iacute;a estad&amp;iacute;stica), 61 (3), 611-622. mediante los m&amp;eacute;todos score y score_samples. Ver &lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="496d8573358dc0bbf8fad0d466b95c37d153e5fd" translate="yes" xml:space="preserve">
          <source>Importance of Feature Scaling</source>
          <target state="translated">Importancia de la escalada de características</target>
        </trans-unit>
        <trans-unit id="dee0fbd7a096536203f3e083c7a95f20ef772057" translate="yes" xml:space="preserve">
          <source>Important members are fit, predict.</source>
          <target state="translated">Los miembros importantes están en forma,predicen.</target>
        </trans-unit>
        <trans-unit id="0004bf233145469d6159f141af0ae0b05f3c5e9a" translate="yes" xml:space="preserve">
          <source>Imputation transformer for completing missing values.</source>
          <target state="translated">Transformador de imputación para completar los valores que faltan.</target>
        </trans-unit>
        <trans-unit id="8154b566118976ff2097cfffb2c92470797b0a69" translate="yes" xml:space="preserve">
          <source>Impute all missing values in X.</source>
          <target state="translated">Impute todos los valores que faltan en X.</target>
        </trans-unit>
        <trans-unit id="510c592fb9a4fd828788fc0bdd902c165ca78889" translate="yes" xml:space="preserve">
          <source>Imputing missing values before building an estimator</source>
          <target state="translated">Imputar los valores perdidos antes de construir un estimador</target>
        </trans-unit>
        <trans-unit id="e5d148df74ab3f703a9d283fda0c99f4936ff674" translate="yes" xml:space="preserve">
          <source>In &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;NMF&lt;/code&gt;&lt;/a&gt;, L1 and L2 priors can be added to the loss function in order to regularize the model. The L2 prior uses the Frobenius norm, while the L1 prior uses an elementwise L1 norm. As in &lt;code&gt;ElasticNet&lt;/code&gt;, we control the combination of L1 and L2 with the &lt;code&gt;l1_ratio&lt;/code&gt; (\(\rho\)) parameter, and the intensity of the regularization with the &lt;code&gt;alpha&lt;/code&gt; (\(\alpha\)) parameter. Then the priors terms are:</source>
          <target state="translated">En &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt; &lt;code&gt;NMF&lt;/code&gt; &lt;/a&gt; , se pueden agregar a la funci&amp;oacute;n de p&amp;eacute;rdida los previos L1 y L2 para regularizar el modelo. El anterior L2 usa la norma de Frobenius, mientras que el anterior L1 usa una norma L1 por elementos. Como en &lt;code&gt;ElasticNet&lt;/code&gt; , controlamos la combinaci&amp;oacute;n de L1 y L2 con el &lt;code&gt;l1_ratio&lt;/code&gt; (\ (\ rho \)), y la intensidad de la regularizaci&amp;oacute;n con el par&amp;aacute;metro &lt;code&gt;alpha&lt;/code&gt; (\ (\ alpha \)). Entonces los t&amp;eacute;rminos a priori son:</target>
        </trans-unit>
        <trans-unit id="eee03375c59654f18a55a7961e4f26a36fbc2cee" translate="yes" xml:space="preserve">
          <source>In &lt;a href=&quot;generated/sklearn.multiclass.outputcodeclassifier#sklearn.multiclass.OutputCodeClassifier&quot;&gt;&lt;code&gt;OutputCodeClassifier&lt;/code&gt;&lt;/a&gt;, the &lt;code&gt;code_size&lt;/code&gt; attribute allows the user to control the number of classifiers which will be used. It is a percentage of the total number of classes.</source>
          <target state="translated">En &lt;a href=&quot;generated/sklearn.multiclass.outputcodeclassifier#sklearn.multiclass.OutputCodeClassifier&quot;&gt; &lt;code&gt;OutputCodeClassifier&lt;/code&gt; &lt;/a&gt; , el atributo &lt;code&gt;code_size&lt;/code&gt; permite al usuario controlar el n&amp;uacute;mero de clasificadores que se utilizar&amp;aacute;n. Es un porcentaje del n&amp;uacute;mero total de clases.</target>
        </trans-unit>
        <trans-unit id="92869ea1268ab85728d32cc145b2fc2a3cf98201" translate="yes" xml:space="preserve">
          <source>In &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt;, if data for classification are unbalanced (e.g. many positive and few negative), set &lt;code&gt;class_weight='balanced'&lt;/code&gt; and/or try different penalty parameters &lt;code&gt;C&lt;/code&gt;.</source>
          <target state="translated">En &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt; , si los datos para la clasificaci&amp;oacute;n est&amp;aacute;n desequilibradas (por ejemplo, muchos positivo y pocos negativo), conjunto &lt;code&gt;class_weight='balanced'&lt;/code&gt; y / o tratar diferentes par&amp;aacute;metros de penalizaci&amp;oacute;n &lt;code&gt;C&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d4a2dd93e9c8bc18123ea577d336109c88e8c2c3" translate="yes" xml:space="preserve">
          <source>In &lt;strong&gt;averaging methods&lt;/strong&gt;, the driving principle is to build several estimators independently and then to average their predictions. On average, the combined estimator is usually better than any of the single base estimator because its variance is reduced.</source>
          <target state="translated">En los &lt;strong&gt;m&amp;eacute;todos de promediado&lt;/strong&gt; , el principio impulsor es construir varios estimadores de forma independiente y luego promediar sus predicciones. En promedio, el estimador combinado suele ser mejor que cualquiera de los estimadores de base &amp;uacute;nica porque su varianza es reducida.</target>
        </trans-unit>
        <trans-unit id="baeac0931c0e4b4385579000935f2bb52ceb9f07" translate="yes" xml:space="preserve">
          <source>In a binary classification task, the terms &amp;lsquo;&amp;rsquo;positive&amp;rsquo;&amp;rsquo; and &amp;lsquo;&amp;rsquo;negative&amp;rsquo;&amp;rsquo; refer to the classifier&amp;rsquo;s prediction, and the terms &amp;lsquo;&amp;rsquo;true&amp;rsquo;&amp;rsquo; and &amp;lsquo;&amp;rsquo;false&amp;rsquo;&amp;rsquo; refer to whether that prediction corresponds to the external judgment (sometimes known as the &amp;lsquo;&amp;rsquo;observation&amp;rsquo;&amp;lsquo;). Given these definitions, we can formulate the following table:</source>
          <target state="translated">En una tarea de clasificaci&amp;oacute;n binaria, los t&amp;eacute;rminos '' positivo '' y '' negativo '' se refieren a la predicci&amp;oacute;n del clasificador, y los t&amp;eacute;rminos '' verdadero '' y '' falso '' se refieren a si esa predicci&amp;oacute;n corresponde al juicio externo ( a veces conocida como la '' observaci&amp;oacute;n ''). Dadas estas definiciones, podemos formular la siguiente tabla:</target>
        </trans-unit>
        <trans-unit id="995a1ae8b5be72e5d8cbdf391052b665e77e9964" translate="yes" xml:space="preserve">
          <source>In a first step, the hierarchical clustering is performed without connectivity constraints on the structure and is solely based on distance, whereas in a second step the clustering is restricted to the k-Nearest Neighbors graph: it&amp;rsquo;s a hierarchical clustering with structure prior.</source>
          <target state="translated">En un primer paso, el agrupamiento jer&amp;aacute;rquico se realiza sin restricciones de conectividad en la estructura y se basa &amp;uacute;nicamente en la distancia, mientras que en un segundo paso el agrupamiento se restringe al gr&amp;aacute;fico k-Vecinos m&amp;aacute;s cercanos: es un agrupamiento jer&amp;aacute;rquico con estructura previa.</target>
        </trans-unit>
        <trans-unit id="0336cb4d8e7c9adb72abdea9417802db49cccd1f" translate="yes" xml:space="preserve">
          <source>In a large text corpus, some words will be very present (e.g. &amp;ldquo;the&amp;rdquo;, &amp;ldquo;a&amp;rdquo;, &amp;ldquo;is&amp;rdquo; in English) hence carrying very little meaningful information about the actual contents of the document. If we were to feed the direct count data directly to a classifier those very frequent terms would shadow the frequencies of rarer yet more interesting terms.</source>
          <target state="translated">En un corpus de texto extenso, algunas palabras estar&amp;aacute;n muy presentes (por ejemplo, &quot;the&quot;, &quot;a&quot;, &quot;is&quot; en ingl&amp;eacute;s), por lo que contienen muy poca informaci&amp;oacute;n significativa sobre el contenido real del documento. Si tuvi&amp;eacute;ramos que alimentar los datos de conteo directo directamente a un clasificador, esos t&amp;eacute;rminos muy frecuentes sombrear&amp;iacute;an las frecuencias de t&amp;eacute;rminos m&amp;aacute;s raros pero m&amp;aacute;s interesantes.</target>
        </trans-unit>
        <trans-unit id="cd0ed349168abd35a1fce87e6ae9e8ccc5ff58f4" translate="yes" xml:space="preserve">
          <source>In a nutshell, the following table summarizes the solvers characteristics:</source>
          <target state="translated">En resumen,el siguiente cuadro resume las características de los solucionadores:</target>
        </trans-unit>
        <trans-unit id="b4ec4bcaff3e86d4d99c938f5623ab4b737e65c7" translate="yes" xml:space="preserve">
          <source>In a real world setting, the &lt;code&gt;n_features&lt;/code&gt; parameter can be left to its default value of &lt;code&gt;2 ** 20&lt;/code&gt; (roughly one million possible features). If memory or downstream models size is an issue selecting a lower value such as &lt;code&gt;2 **
18&lt;/code&gt; might help without introducing too many additional collisions on typical text classification tasks.</source>
          <target state="translated">En una configuraci&amp;oacute;n del mundo real, el par&amp;aacute;metro &lt;code&gt;n_features&lt;/code&gt; se puede dejar en su valor predeterminado de &lt;code&gt;2 ** 20&lt;/code&gt; (aproximadamente un mill&amp;oacute;n de caracter&amp;iacute;sticas posibles). Si la memoria o el tama&amp;ntilde;o de los modelos posteriores es un problema, seleccionar un valor m&amp;aacute;s bajo, como &lt;code&gt;2 ** 18&lt;/code&gt; podr&amp;iacute;a ayudar sin introducir demasiadas colisiones adicionales en las tareas t&amp;iacute;picas de clasificaci&amp;oacute;n de texto.</target>
        </trans-unit>
        <trans-unit id="c75e295f24e05d06cacc1a2f9bb570a61bdd802e" translate="yes" xml:space="preserve">
          <source>In a similar manner, the boston housing data set is used to show the impact of transforming the targets before learning a model. In this example, the targets to be predicted corresponds to the weighted distances to the five Boston employment centers.</source>
          <target state="translated">De manera similar,el conjunto de datos de la vivienda de Boston se utiliza para mostrar el impacto de la transformación de los objetivos antes de aprender un modelo.En este ejemplo,los objetivos a predecir corresponden a las distancias ponderadas a los cinco centros de empleo de Boston.</target>
        </trans-unit>
        <trans-unit id="c210295417ef2f29cc593be46bbc5efed5892a5f" translate="yes" xml:space="preserve">
          <source>In addition of using an imputing method, we can also keep an indication of the missing information using &lt;a href=&quot;../modules/generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;sklearn.impute.MissingIndicator&lt;/code&gt;&lt;/a&gt; which might carry some information.</source>
          <target state="translated">Adem&amp;aacute;s de utilizar un m&amp;eacute;todo de imputaci&amp;oacute;n, tambi&amp;eacute;n podemos mantener una indicaci&amp;oacute;n de la informaci&amp;oacute;n que falta utilizando &lt;a href=&quot;../modules/generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt; &lt;code&gt;sklearn.impute.MissingIndicator&lt;/code&gt; &lt;/a&gt; que podr&amp;iacute;a contener alguna informaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="45e3263783ee36dc90c5821ae7ffc8d210750151" translate="yes" xml:space="preserve">
          <source>In addition to its current contents, this module will eventually be home to refurbished versions of Pipeline and FeatureUnion.</source>
          <target state="translated">Además de su contenido actual,este módulo será eventualmente el hogar de versiones renovadas de Pipeline y FeatureUnion.</target>
        </trans-unit>
        <trans-unit id="3dda0db479e61a3dc2539c918fe85f072a3cc4a4" translate="yes" xml:space="preserve">
          <source>In addition to standard scikit-learn estimator API, GaussianProcessRegressor:</source>
          <target state="translated">Además de la API del estimador estándar de aprendizaje científico,GaussianProcessRegressor:</target>
        </trans-unit>
        <trans-unit id="6c259b1081efe473add72a6c01ee26dbc96ee486" translate="yes" xml:space="preserve">
          <source>In addition to the mean of the predictive distribution, also its standard deviation can be returned.</source>
          <target state="translated">Además de la media de la distribución predictiva,también se puede devolver su desviación estándar.</target>
        </trans-unit>
        <trans-unit id="f5f01da0b407208bd57121f71ed7408cbbce3fe6" translate="yes" xml:space="preserve">
          <source>In addition, as there is no useful information in the intensity of the image, or its gradient, we choose to perform the spectral clustering on a graph that is only weakly informed by the gradient. This is close to performing a Voronoi partition of the graph.</source>
          <target state="translated">Además,como no hay información útil en la intensidad de la imagen,o su gradiente,elegimos realizar la agrupación espectral en un gráfico que sólo está débilmente informado por el gradiente.Esto está cerca de realizar una partición Voronoi del gráfico.</target>
        </trans-unit>
        <trans-unit id="8be2789c3e2f5a1d410c34b62e20c28c8adc9fef" translate="yes" xml:space="preserve">
          <source>In addition, if the &lt;code&gt;dask&lt;/code&gt; and &lt;code&gt;distributed&lt;/code&gt; Python packages are installed, it is possible to use the &amp;lsquo;dask&amp;rsquo; backend for better scheduling of nested parallel calls without over-subscription and potentially distribute parallel calls over a networked cluster of several hosts.</source>
          <target state="translated">Adem&amp;aacute;s, si los paquetes &lt;code&gt;dask&lt;/code&gt; y Python &lt;code&gt;distributed&lt;/code&gt; est&amp;aacute;n instalados, es posible usar el backend 'dask' para una mejor programaci&amp;oacute;n de llamadas paralelas anidadas sin suscripci&amp;oacute;n excesiva y potencialmente distribuir llamadas paralelas a trav&amp;eacute;s de un cl&amp;uacute;ster en red de varios hosts.</target>
        </trans-unit>
        <trans-unit id="1068dbee0dd3c16e2fc93e44b0ce455f5b052f8b" translate="yes" xml:space="preserve">
          <source>In addition, scikit-learn includes various random sample generators that can be used to build artificial datasets of controlled size and complexity.</source>
          <target state="translated">Además,scikit-learn incluye varios generadores de muestras aleatorias que pueden utilizarse para construir conjuntos de datos artificiales de tamaño y complejidad controlados.</target>
        </trans-unit>
        <trans-unit id="67ed28f1d0cd9fef0560dd0bbfe2b568680ea5a6" translate="yes" xml:space="preserve">
          <source>In addition, there are also miscellanous tools to load datasets of other formats or from other locations, described in the &lt;a href=&quot;#loading-other-datasets&quot;&gt;Loading other datasets&lt;/a&gt; section.</source>
          <target state="translated">Adem&amp;aacute;s, tambi&amp;eacute;n existen diversas herramientas para cargar conjuntos de datos de otros formatos o desde otras ubicaciones, que se describen en la secci&amp;oacute;n &lt;a href=&quot;#loading-other-datasets&quot;&gt;Carga de otros conjuntos de datos&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="846c6c3d11b49bd5243a8b72c066c7aae06dcfe3" translate="yes" xml:space="preserve">
          <source>In addition, we use the mask of the objects to restrict the graph to the outline of the objects. In this example, we are interested in separating the objects one from the other, and not from the background.</source>
          <target state="translated">Además,usamos la máscara de los objetos para restringir el gráfico al contorno de los objetos.En este ejemplo,estamos interesados en separar los objetos uno del otro,y no del fondo.</target>
        </trans-unit>
        <trans-unit id="b490744f01019d4237b3a8568465e031a5ae6e1f" translate="yes" xml:space="preserve">
          <source>In all these strategies, the &lt;code&gt;predict&lt;/code&gt; method completely ignores the input data.</source>
          <target state="translated">En todas estas estrategias, el m&amp;eacute;todo de &lt;code&gt;predict&lt;/code&gt; ignora por completo los datos de entrada.</target>
        </trans-unit>
        <trans-unit id="450c8a41f7c5da3bb2b7da9a15306b194b36c681" translate="yes" xml:space="preserve">
          <source>In an &lt;strong&gt;unsupervised setting&lt;/strong&gt; it can be used to group similar documents together by applying clustering algorithms such as &lt;a href=&quot;clustering#k-means&quot;&gt;K-means&lt;/a&gt;:</source>
          <target state="translated">En un &lt;strong&gt;entorno&lt;/strong&gt; no &lt;strong&gt;supervisado,&lt;/strong&gt; se puede utilizar para agrupar documentos similares mediante la aplicaci&amp;oacute;n de algoritmos de agrupaci&amp;oacute;n como &lt;a href=&quot;clustering#k-means&quot;&gt;K-means&lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="e5af8b183011d6bf7238d58f71b94384a5a96f84" translate="yes" xml:space="preserve">
          <source>In any case be warned that decreasing model complexity can hurt accuracy as mentioned above. For instance a non-linearly separable problem can be handled with a speedy linear model but prediction power will very likely suffer in the process.</source>
          <target state="translated">En cualquier caso,se advierte que la disminución de la complejidad de los modelos puede perjudicar la precisión como se ha mencionado anteriormente.Por ejemplo,un problema no lineal separable puede manejarse con un modelo lineal rápido,pero es muy probable que la potencia de predicción se vea afectada en el proceso.</target>
        </trans-unit>
        <trans-unit id="8c17ce8abfedb506f7ed46ebde27121f581c8bb7" translate="yes" xml:space="preserve">
          <source>In applications where a high false positive rate is not tolerable the parameter &lt;code&gt;max_fpr&lt;/code&gt; of &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt; can be used to summarize the ROC curve up to the given limit.</source>
          <target state="translated">En aplicaciones donde una tasa alta de falsos positivos no es tolerable, el par&amp;aacute;metro &lt;code&gt;max_fpr&lt;/code&gt; de &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;roc_auc_score&lt;/code&gt; &lt;/a&gt; se puede usar para resumir la curva ROC hasta el l&amp;iacute;mite dado.</target>
        </trans-unit>
        <trans-unit id="bbcc07c440f8193b3e7ecf64eaaca0e386adcbad" translate="yes" xml:space="preserve">
          <source>In bin edges for feature &lt;code&gt;i&lt;/code&gt;, the first and last values are used only for &lt;code&gt;inverse_transform&lt;/code&gt;. During transform, bin edges are extended to:</source>
          <target state="translated">En los bordes del contenedor para la caracter&amp;iacute;stica &lt;code&gt;i&lt;/code&gt; , el primer y &amp;uacute;ltimo valor se usan solo para &lt;code&gt;inverse_transform&lt;/code&gt; . Durante la transformaci&amp;oacute;n, los bordes del contenedor se extienden a:</target>
        </trans-unit>
        <trans-unit id="9d083c0b55e1a00133d4b27dd85f5ea26aca3922" translate="yes" xml:space="preserve">
          <source>In binary and multiclass classification, the Jaccard similarity coefficient score is equal to the classification accuracy.</source>
          <target state="translated">En la clasificación binaria y multiclase,la puntuación del coeficiente de similitud de Jaccard es igual a la precisión de la clasificación.</target>
        </trans-unit>
        <trans-unit id="b0b30958f6975dadd3d7eaf24f5447254d56c629" translate="yes" xml:space="preserve">
          <source>In binary and multiclass classification, this function is equal to the &lt;code&gt;jaccard_similarity_score&lt;/code&gt; function.</source>
          <target state="translated">En la clasificaci&amp;oacute;n binaria y multiclase, esta funci&amp;oacute;n es igual a la funci&amp;oacute;n &lt;code&gt;jaccard_similarity_score&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e731c9654f26a8d7255165d2c0d5f78e47c3bd9a" translate="yes" xml:space="preserve">
          <source>In binary and multiclass classification, this function is equivalent to the &lt;code&gt;accuracy_score&lt;/code&gt;. It differs in the multilabel classification problem.</source>
          <target state="translated">En la clasificaci&amp;oacute;n binaria y multiclase, esta funci&amp;oacute;n es equivalente a la &lt;code&gt;accuracy_score&lt;/code&gt; . Se diferencia en el problema de clasificaci&amp;oacute;n de m&amp;uacute;ltiples etiquetas.</target>
        </trans-unit>
        <trans-unit id="c4cb57bb3e2c0bb1485829473f6ca6362cee5b90" translate="yes" xml:space="preserve">
          <source>In binary class case, assuming labels in y_true are encoded with +1 and -1, when a prediction mistake is made, &lt;code&gt;margin = y_true * pred_decision&lt;/code&gt; is always negative (since the signs disagree), implying &lt;code&gt;1 - margin&lt;/code&gt; is always greater than 1. The cumulated hinge loss is therefore an upper bound of the number of mistakes made by the classifier.</source>
          <target state="translated">En el caso de clase binaria, asumiendo que las etiquetas en y_true est&amp;aacute;n codificadas con +1 y -1, cuando se comete un error de predicci&amp;oacute;n, &lt;code&gt;margin = y_true * pred_decision&lt;/code&gt; siempre es negativo (ya que los signos no est&amp;aacute;n de acuerdo), lo que implica que &lt;code&gt;1 - margin&lt;/code&gt; es siempre mayor que 1. La p&amp;eacute;rdida de bisagra acumulada es, por tanto, un l&amp;iacute;mite superior del n&amp;uacute;mero de errores cometidos por el clasificador.</target>
        </trans-unit>
        <trans-unit id="f2c8a5d61695d64c32adbdec8051b4ecc7f404cb" translate="yes" xml:space="preserve">
          <source>In binary classification settings</source>
          <target state="translated">En los escenarios de clasificación binaria</target>
        </trans-unit>
        <trans-unit id="0e8524872beef3003e748e1d9b4f90c7ce280313" translate="yes" xml:space="preserve">
          <source>In both cases, the criterion is evaluated once by epoch, and the algorithm stops when the criterion does not improve &lt;code&gt;n_iter_no_change&lt;/code&gt; times in a row. The improvement is evaluated with a tolerance &lt;code&gt;tol&lt;/code&gt;, and the algorithm stops in any case after a maximum number of iteration &lt;code&gt;max_iter&lt;/code&gt;.</source>
          <target state="translated">En ambos casos, el criterio se eval&amp;uacute;a una vez por &amp;eacute;poca y el algoritmo se detiene cuando el criterio no mejora &lt;code&gt;n_iter_no_change&lt;/code&gt; tiempos seguidos. La mejora se eval&amp;uacute;a con una tolerancia &lt;code&gt;tol&lt;/code&gt; , y el algoritmo se detiene en cualquier caso despu&amp;eacute;s de un n&amp;uacute;mero m&amp;aacute;ximo de iteraciones &lt;code&gt;max_iter&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f03bffae8069d1108a85252dc34a4485434865b8" translate="yes" xml:space="preserve">
          <source>In both cases, the kernel&amp;rsquo;s parameters are estimated using the maximum likelihood principle.</source>
          <target state="translated">En ambos casos, los par&amp;aacute;metros del kernel se estiman utilizando el principio de m&amp;aacute;xima verosimilitud.</target>
        </trans-unit>
        <trans-unit id="dc8004c8d5b437fc6c479e2e5882eb635fa97592" translate="yes" xml:space="preserve">
          <source>In both examples below, the main result is that the empirical covariance estimate, as a non-robust one, is highly influenced by the heterogeneous structure of the observations. Although the robust covariance estimate is able to focus on the main mode of the data distribution, it sticks to the assumption that the data should be Gaussian distributed, yielding some biased estimation of the data structure, but yet accurate to some extent. The One-Class SVM does not assume any parametric form of the data distribution and can therefore model the complex shape of the data much better.</source>
          <target state="translated">En los dos ejemplos que figuran a continuación,el resultado principal es que la estimación de la covarianza empírica,al no ser robusta,está muy influida por la estructura heterogénea de las observaciones.Aunque la estimación de la covarianza robusta puede centrarse en el modo principal de la distribución de los datos,se ciñe al supuesto de que los datos deben estar distribuidos en Gauss,lo que produce cierta estimación sesgada de la estructura de los datos,pero aún así es precisa en cierta medida.El SVM de una clase no asume ninguna forma paramétrica de la distribución de datos y por lo tanto puede modelar mucho mejor la forma compleja de los datos.</target>
        </trans-unit>
        <trans-unit id="7f2b051010be4e679b8556fa182a1724fa1e49b9" translate="yes" xml:space="preserve">
          <source>In case the file contains a pairwise preference constraint (known as &amp;ldquo;qid&amp;rdquo; in the svmlight format) these are ignored unless the query_id parameter is set to True. These pairwise preference constraints can be used to constraint the combination of samples when using pairwise loss functions (as is the case in some learning to rank problems) so that only pairs with the same query_id value are considered.</source>
          <target state="translated">En caso de que el archivo contenga una restricci&amp;oacute;n de preferencia por pares (conocida como &quot;qid&quot; en el formato svmlight), se ignoran a menos que el par&amp;aacute;metro query_id se establezca en True. Estas restricciones de preferencia por pares se pueden usar para restringir la combinaci&amp;oacute;n de muestras cuando se usan funciones de p&amp;eacute;rdida por pares (como es el caso en algunos problemas de aprendizaje de clasificaci&amp;oacute;n) de modo que solo se consideren los pares con el mismo valor de query_id.</target>
        </trans-unit>
        <trans-unit id="b2d3bbc7ab1d1edcd850a10f6fb01a251c14a28b" translate="yes" xml:space="preserve">
          <source>In case unknown categories are encountered (all zero&amp;rsquo;s in the one-hot encoding), &lt;code&gt;None&lt;/code&gt; is used to represent this category.</source>
          <target state="translated">En caso de que se encuentren categor&amp;iacute;as desconocidas (todos los ceros en la codificaci&amp;oacute;n one-hot), se utiliza &lt;code&gt;None&lt;/code&gt; para representar esta categor&amp;iacute;a.</target>
        </trans-unit>
        <trans-unit id="ca499264726caa99e06bab43fc3d4644ea84df01" translate="yes" xml:space="preserve">
          <source>In cases where not all of a pairwise distance matrix needs to be stored at once, this is used to calculate pairwise distances in &lt;code&gt;working_memory&lt;/code&gt;-sized chunks. If &lt;code&gt;reduce_func&lt;/code&gt; is given, it is run on each chunk and its return values are concatenated into lists, arrays or sparse matrices.</source>
          <target state="translated">En los casos en los que no es necesario almacenar toda una matriz de distancias por pares a la vez, esto se utiliza para calcular distancias por pares en &lt;code&gt;working_memory&lt;/code&gt; tama&amp;ntilde;o de la memoria de trabajo. Si se proporciona &lt;code&gt;reduce_func&lt;/code&gt; , se ejecuta en cada fragmento y sus valores de retorno se concatenan en listas, matrices o matrices dispersas.</target>
        </trans-unit>
        <trans-unit id="261de18f8066fcaced5cb3f145cb26c170301e09" translate="yes" xml:space="preserve">
          <source>In cases where the data is not uniformly sampled, radius-based neighbors classification in &lt;a href=&quot;generated/sklearn.neighbors.radiusneighborsclassifier#sklearn.neighbors.RadiusNeighborsClassifier&quot;&gt;&lt;code&gt;RadiusNeighborsClassifier&lt;/code&gt;&lt;/a&gt; can be a better choice. The user specifies a fixed radius \(r\), such that points in sparser neighborhoods use fewer nearest neighbors for the classification. For high-dimensional parameter spaces, this method becomes less effective due to the so-called &amp;ldquo;curse of dimensionality&amp;rdquo;.</source>
          <target state="translated">En los casos en que los datos no se muestrean de manera uniforme, la clasificaci&amp;oacute;n de vecinos basada en &lt;a href=&quot;generated/sklearn.neighbors.radiusneighborsclassifier#sklearn.neighbors.RadiusNeighborsClassifier&quot;&gt; &lt;code&gt;RadiusNeighborsClassifier&lt;/code&gt; &lt;/a&gt; en RadiusNeighborsClassifier puede ser una mejor opci&amp;oacute;n. El usuario especifica un radio fijo \ (r \), de modo que los puntos en vecindarios m&amp;aacute;s dispersos usan menos vecinos m&amp;aacute;s cercanos para la clasificaci&amp;oacute;n. Para espacios de par&amp;aacute;metros de alta dimensi&amp;oacute;n, este m&amp;eacute;todo se vuelve menos efectivo debido a la llamada &quot;maldici&amp;oacute;n de la dimensionalidad&quot;.</target>
        </trans-unit>
        <trans-unit id="46149a533d1136e96a72fc2595f06ccb02814862" translate="yes" xml:space="preserve">
          <source>In certain cases Theil-Sen performs better than &lt;a href=&quot;../../modules/linear_model#ransac-regression&quot;&gt;RANSAC&lt;/a&gt; which is also a robust method. This is illustrated in the second example below where outliers with respect to the x-axis perturb RANSAC. Tuning the &lt;code&gt;residual_threshold&lt;/code&gt; parameter of RANSAC remedies this but in general a priori knowledge about the data and the nature of the outliers is needed. Due to the computational complexity of Theil-Sen it is recommended to use it only for small problems in terms of number of samples and features. For larger problems the &lt;code&gt;max_subpopulation&lt;/code&gt; parameter restricts the magnitude of all possible combinations of p subsample points to a randomly chosen subset and therefore also limits the runtime. Therefore, Theil-Sen is applicable to larger problems with the drawback of losing some of its mathematical properties since it then works on a random subset.</source>
          <target state="translated">En ciertos casos, Theil-Sen funciona mejor que &lt;a href=&quot;../../modules/linear_model#ransac-regression&quot;&gt;RANSAC,&lt;/a&gt; que tambi&amp;eacute;n es un m&amp;eacute;todo robusto. Esto se ilustra en el segundo ejemplo a continuaci&amp;oacute;n, donde los valores at&amp;iacute;picos con respecto al eje x perturban RANSAC. El ajuste del par&amp;aacute;metro &lt;code&gt;residual_threshold&lt;/code&gt; de RANSAC soluciona esto, pero en general se necesita un conocimiento a priori sobre los datos y la naturaleza de los valores at&amp;iacute;picos. Debido a la complejidad computacional de Theil-Sen, se recomienda usarlo solo para peque&amp;ntilde;os problemas en t&amp;eacute;rminos de n&amp;uacute;mero de muestras y caracter&amp;iacute;sticas. Para problemas m&amp;aacute;s grandes, &lt;code&gt;max_subpopulation&lt;/code&gt; El par&amp;aacute;metro restringe la magnitud de todas las combinaciones posibles de p puntos de submuestra a un subconjunto elegido al azar y, por lo tanto, tambi&amp;eacute;n limita el tiempo de ejecuci&amp;oacute;n. Por lo tanto, Theil-Sen es aplicable a problemas m&amp;aacute;s grandes con el inconveniente de perder algunas de sus propiedades matem&amp;aacute;ticas, ya que luego trabaja en un subconjunto aleatorio.</target>
        </trans-unit>
        <trans-unit id="08403787ed9849b402f6d04f68a0bae46063dfaf" translate="yes" xml:space="preserve">
          <source>In contrast to &lt;a href=&quot;#id13&quot;&gt;Bayesian Ridge Regression&lt;/a&gt;, each coordinate of \(w_{i}\) has its own standard deviation \(\lambda_i\). The prior over all \(\lambda_i\) is chosen to be the same gamma distribution given by hyperparameters \(\lambda_1\) and \(\lambda_2\).</source>
          <target state="translated">En contraste con &lt;a href=&quot;#id13&quot;&gt;la regresi&amp;oacute;n de cresta bayesiana&lt;/a&gt; , cada coordenada de \ (w_ {i} \) tiene su propia desviaci&amp;oacute;n est&amp;aacute;ndar \ (\ lambda_i \). El anterior sobre todo \ (\ lambda_i \) se elige para que sea la misma distribuci&amp;oacute;n gamma dada por los hiperpar&amp;aacute;metros \ (\ lambda_1 \) y \ (\ lambda_2 \).</target>
        </trans-unit>
        <trans-unit id="741dc2ca1b0b96b753a4293cdc66da483cb961b9" translate="yes" xml:space="preserve">
          <source>In contrast to GridSearchCV, not all parameter values are tried out, but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter.</source>
          <target state="translated">A diferencia del GridSearchCV,no se prueban todos los valores de los parámetros,sino que se muestrean un número fijo de ajustes de parámetros de las distribuciones especificadas.El número de ajustes de parámetros que se prueban viene dado por n_iter.</target>
        </trans-unit>
        <trans-unit id="f7007cbebb915951a7329a621ec59e7bfd3c1528" translate="yes" xml:space="preserve">
          <source>In contrast to majority voting (hard voting), soft voting returns the class label as argmax of the sum of predicted probabilities.</source>
          <target state="translated">A diferencia de la votación por mayoría (votación dura),la votación blanda devuelve la etiqueta de clase como argmax de la suma de las probabilidades previstas.</target>
        </trans-unit>
        <trans-unit id="a5222e41535c7e60d0bed8020d5a39a4cdb9c58d" translate="yes" xml:space="preserve">
          <source>In contrast to the original publication &lt;a href=&quot;#b2001&quot; id=&quot;id6&quot;&gt;[B2001]&lt;/a&gt;, the scikit-learn implementation combines classifiers by averaging their probabilistic prediction, instead of letting each classifier vote for a single class.</source>
          <target state="translated">A diferencia de la publicaci&amp;oacute;n original &lt;a href=&quot;#b2001&quot; id=&quot;id6&quot;&gt;[B2001]&lt;/a&gt; , la implementaci&amp;oacute;n de scikit-learn combina clasificadores promediando su predicci&amp;oacute;n probabil&amp;iacute;stica, en lugar de dejar que cada clasificador vote por una sola clase.</target>
        </trans-unit>
        <trans-unit id="092465bd0b61837459fb29bf14c2dda6ed20e949" translate="yes" xml:space="preserve">
          <source>In contrast to the regression setting, the posterior of the latent function \(f\) is not Gaussian even for a GP prior since a Gaussian likelihood is inappropriate for discrete class labels. Rather, a non-Gaussian likelihood corresponding to the logistic link function (logit) is used. GaussianProcessClassifier approximates the non-Gaussian posterior with a Gaussian based on the Laplace approximation. More details can be found in Chapter 3 of &lt;a href=&quot;#rw2006&quot; id=&quot;id4&quot;&gt;[RW2006]&lt;/a&gt;.</source>
          <target state="translated">En contraste con la configuraci&amp;oacute;n de regresi&amp;oacute;n, la parte posterior de la funci&amp;oacute;n latente \ (f \) no es gaussiana ni siquiera para un GP antes, ya que una probabilidad gaussiana es inapropiada para etiquetas de clase discretas. M&amp;aacute;s bien, se utiliza una probabilidad no gaussiana correspondiente a la funci&amp;oacute;n de enlace log&amp;iacute;stico (logit). GaussianProcessClassifier aproxima el posterior no gaussiano con un gaussiano basado en la aproximaci&amp;oacute;n de Laplace. Se pueden encontrar m&amp;aacute;s detalles en el Cap&amp;iacute;tulo 3 de &lt;a href=&quot;#rw2006&quot; id=&quot;id4&quot;&gt;[RW2006]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2d7f12a42ea8277b24625f1aff8d53cb363a14e0" translate="yes" xml:space="preserve">
          <source>In contrast, if the conventional accuracy is above chance only because the classifier takes advantage of an imbalanced test set, then the balanced accuracy, as appropriate, will drop to \(\frac{1}{\text{n\_classes}}\).</source>
          <target state="translated">Por el contrario,si la precisión convencional está por encima de la casualidad sólo porque el clasificador aprovecha un conjunto de pruebas desequilibradas,entonces la precisión equilibrada,según corresponda,bajará a \ ~ (\ ~ -fracaso{1}{\ ~ texto {\ ~ clases}).</target>
        </trans-unit>
        <trans-unit id="89611c1358b346353d5469c5670ea64fb02fcdd7" translate="yes" xml:space="preserve">
          <source>In descending order of quality, when trained (outside of this example) on all 4 features using 30 estimators and scored using 10 fold cross validation, we see:</source>
          <target state="translated">En orden descendente de calidad,cuando se entrenó (fuera de este ejemplo)en los 4 rasgos usando 30 estimadores y se anotó usando una validación cruzada de 10 veces,vemos:</target>
        </trans-unit>
        <trans-unit id="0732cca6c2251b860da4c331fa5748d479b14945" translate="yes" xml:space="preserve">
          <source>In ensemble algorithms, bagging methods form a class of algorithms which build several instances of a black-box estimator on random subsets of the original training set and then aggregate their individual predictions to form a final prediction. These methods are used as a way to reduce the variance of a base estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it. In many cases, bagging methods constitute a very simple way to improve with respect to a single model, without making it necessary to adapt the underlying base algorithm. As they provide a way to reduce overfitting, bagging methods work best with strong and complex models (e.g., fully developed decision trees), in contrast with boosting methods which usually work best with weak models (e.g., shallow decision trees).</source>
          <target state="translated">En los algoritmos de conjunto,los métodos de empaquetamiento forman una clase de algoritmos que construyen varias instancias de un estimador de caja negra sobre subconjuntos aleatorios del conjunto original de entrenamiento y luego agregan sus predicciones individuales para formar una predicción final.Estos métodos se utilizan como una forma de reducir la varianza de un estimador de base (por ejemplo,un árbol de decisión),introduciendo la aleatorización en su procedimiento de construcción y luego haciendo un conjunto a partir de él.En muchos casos,los métodos de ensamblaje constituyen una forma muy sencilla de mejorar con respecto a un modelo único,sin que sea necesario adaptar el algoritmo de base subyacente.Como proporcionan una forma de reducir el exceso de adaptación,los métodos de ensacado funcionan mejor con modelos fuertes y complejos (por ejemplo,árboles de decisión plenamente desarrollados),en contraste con los métodos de potenciación que suelen funcionar mejor con modelos débiles (por ejemplo,árboles de decisión poco profundos).</target>
        </trans-unit>
        <trans-unit id="5305d1e9b70806a8391e61e804a0df6abd8f6cc5" translate="yes" xml:space="preserve">
          <source>In extending a binary metric to multiclass or multilabel problems, the data is treated as a collection of binary problems, one for each class. There are then a number of ways to average binary metric calculations across the set of classes, each of which may be useful in some scenario. Where available, you should select among these using the &lt;code&gt;average&lt;/code&gt; parameter.</source>
          <target state="translated">Al extender una m&amp;eacute;trica binaria a problemas de m&amp;uacute;ltiples clases o etiquetas, los datos se tratan como una colecci&amp;oacute;n de problemas binarios, uno para cada clase. Hay entonces varias formas de promediar los c&amp;aacute;lculos de m&amp;eacute;tricas binarias en el conjunto de clases, cada una de las cuales puede ser &amp;uacute;til en alg&amp;uacute;n escenario. Donde est&amp;eacute; disponible, debe seleccionar entre estos usando el par&amp;aacute;metro &lt;code&gt;average&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e87cfc9dff0fe670bd40ebf7e26edaa15ca842ad" translate="yes" xml:space="preserve">
          <source>In extremely randomized trees (see &lt;a href=&quot;generated/sklearn.ensemble.extratreesclassifier#sklearn.ensemble.ExtraTreesClassifier&quot;&gt;&lt;code&gt;ExtraTreesClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.extratreesregressor#sklearn.ensemble.ExtraTreesRegressor&quot;&gt;&lt;code&gt;ExtraTreesRegressor&lt;/code&gt;&lt;/a&gt; classes), randomness goes one step further in the way splits are computed. As in random forests, a random subset of candidate features is used, but instead of looking for the most discriminative thresholds, thresholds are drawn at random for each candidate feature and the best of these randomly-generated thresholds is picked as the splitting rule. This usually allows to reduce the variance of the model a bit more, at the expense of a slightly greater increase in bias:</source>
          <target state="translated">En &amp;aacute;rboles extremadamente aleatorios (consulte las clases &lt;a href=&quot;generated/sklearn.ensemble.extratreesclassifier#sklearn.ensemble.ExtraTreesClassifier&quot;&gt; &lt;code&gt;ExtraTreesClassifier&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.ensemble.extratreesregressor#sklearn.ensemble.ExtraTreesRegressor&quot;&gt; &lt;code&gt;ExtraTreesRegressor&lt;/code&gt; &lt;/a&gt; ), la aleatoriedad va un paso m&amp;aacute;s all&amp;aacute; en la forma en que se calculan las divisiones. Al igual que en los bosques aleatorios, se utiliza un subconjunto aleatorio de caracter&amp;iacute;sticas candidatas, pero en lugar de buscar los umbrales m&amp;aacute;s discriminativos, los umbrales se dibujan al azar para cada caracter&amp;iacute;stica candidata y el mejor de estos umbrales generados aleatoriamente se elige como la regla de divisi&amp;oacute;n. Esto suele permitir reducir un poco m&amp;aacute;s la varianza del modelo, a expensas de un aumento ligeramente mayor del sesgo:</target>
        </trans-unit>
        <trans-unit id="5c1305e3ce4cbb99adc8d313e42a43efab81ea5c" translate="yes" xml:space="preserve">
          <source>In fact, this dataset only has one version. The iris dataset on the other hand has multiple versions:</source>
          <target state="translated">De hecho,este conjunto de datos sólo tiene una versión.El conjunto de datos del iris,por otro lado,tiene múltiples versiones:</target>
        </trans-unit>
        <trans-unit id="63493dde535d33b43819cf48666bb2a9620c2476" translate="yes" xml:space="preserve">
          <source>In french but still a reference: Tenenhaus, M. (1998). La regression PLS: theorie et pratique. Paris: Editions Technic.</source>
          <target state="translated">En francés,pero sigue siendo una referencia:Tenenhaus,M.(1998).La regresión PLS:theorie et pratique.París:Ediciones Technic.</target>
        </trans-unit>
        <trans-unit id="6e95c3ada3b2525ed5f608da19594b4a42ad3dc4" translate="yes" xml:space="preserve">
          <source>In general doing predictions in bulk (many instances at the same time) is more efficient for a number of reasons (branching predictability, CPU cache, linear algebra libraries optimizations etc.). Here we see on a setting with few features that independently of estimator choice the bulk mode is always faster, and for some of them by 1 to 2 orders of magnitude:</source>
          <target state="translated">En general,hacer predicciones en masa (muchos casos al mismo tiempo)es más eficiente por varias razones (previsibilidad de las ramificaciones,caché de la CPU,optimización de las bibliotecas de álgebra lineal,etc.).Aquí vemos en un entorno con pocas características que,independientemente de la elección del estimador,el modo masivo es siempre más rápido,y para algunos de ellos de 1 a 2 órdenes de magnitud:</target>
        </trans-unit>
        <trans-unit id="d5f14cdf8cb9c0df1b6ffce69bd866cdeffd9355" translate="yes" xml:space="preserve">
          <source>In general, a learning problem considers a set of n &lt;a href=&quot;https://en.wikipedia.org/wiki/Sample_(statistics)&quot;&gt;samples&lt;/a&gt; of data and then tries to predict properties of unknown data. If each sample is more than a single number and, for instance, a multi-dimensional entry (aka &lt;a href=&quot;https://en.wikipedia.org/wiki/Multivariate_random_variable&quot;&gt;multivariate&lt;/a&gt; data), it is said to have several attributes or &lt;strong&gt;features&lt;/strong&gt;.</source>
          <target state="translated">En general, un problema de aprendizaje considera un conjunto de n &lt;a href=&quot;https://en.wikipedia.org/wiki/Sample_(statistics)&quot;&gt;muestras&lt;/a&gt; de datos y luego intenta predecir las propiedades de los datos desconocidos. Si cada muestra tiene m&amp;aacute;s de un n&amp;uacute;mero y, por ejemplo, una entrada multidimensional (tambi&amp;eacute;n conocida como datos &lt;a href=&quot;https://en.wikipedia.org/wiki/Multivariate_random_variable&quot;&gt;multivariados&lt;/a&gt; ), se dice que tiene varios atributos o &lt;strong&gt;caracter&amp;iacute;sticas&lt;/strong&gt; .</target>
        </trans-unit>
        <trans-unit id="9cf7334c38597a2189c7af702ab9abdbe9f10093" translate="yes" xml:space="preserve">
          <source>In general, is a technique used for analyzing similarity or dissimilarity data. &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; attempts to model similarity or dissimilarity data as distances in a geometric spaces. The data can be ratings of similarity between objects, interaction frequencies of molecules, or trade indices between countries.</source>
          <target state="translated">En general, es una t&amp;eacute;cnica utilizada para analizar datos de similitud o disimilitud. &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt; &lt;code&gt;MDS&lt;/code&gt; &lt;/a&gt; intenta modelar datos de similitud o disimilitud como distancias en espacios geom&amp;eacute;tricos. Los datos pueden ser calificaciones de similitud entre objetos, frecuencias de interacci&amp;oacute;n de mol&amp;eacute;culas o &amp;iacute;ndices comerciales entre pa&amp;iacute;ses.</target>
        </trans-unit>
        <trans-unit id="71aab6786f00490669e72ac36911ce2d2486dab4" translate="yes" xml:space="preserve">
          <source>In general, it is about to learn a rough, close frontier delimiting the contour of the initial observations distribution, plotted in embedding \(p\)-dimensional space. Then, if further observations lay within the frontier-delimited subspace, they are considered as coming from the same population than the initial observations. Otherwise, if they lay outside the frontier, we can say that they are abnormal with a given confidence in our assessment.</source>
          <target state="translated">En general,está a punto de aprender una frontera aproximada y cercana que delimita el contorno de la distribución de las observaciones iniciales,trazada en el espacio incrustado.Luego,si las observaciones posteriores se encuentran dentro de la frontera delimitada del subespacio,se considera que provienen de la misma población que las observaciones iniciales.De lo contrario,si se encuentran fuera de la frontera,podemos decir que son anormales con una cierta confianza en nuestra evaluación.</target>
        </trans-unit>
        <trans-unit id="c9bca25ec918e4e036ec8a37ec502896ec56d542" translate="yes" xml:space="preserve">
          <source>In general, learning algorithms benefit from standardization of the data set. If some outliers are present in the set, robust scalers or transformers are more appropriate. The behaviors of the different scalers, transformers, and normalizers on a dataset containing marginal outliers is highlighted in &lt;a href=&quot;../auto_examples/preprocessing/plot_all_scaling#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py&quot;&gt;Compare the effect of different scalers on data with outliers&lt;/a&gt;.</source>
          <target state="translated">En general, los algoritmos de aprendizaje se benefician de la estandarizaci&amp;oacute;n del conjunto de datos. Si algunos valores at&amp;iacute;picos est&amp;aacute;n presentes en el conjunto, los escaladores o transformadores robustos son m&amp;aacute;s apropiados. Los comportamientos de los diferentes escaladores, transformadores y normalizadores en un conjunto de datos que contiene valores at&amp;iacute;picos marginales se resaltan en &lt;a href=&quot;../auto_examples/preprocessing/plot_all_scaling#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py&quot;&gt;Comparar el efecto de diferentes escaladores en datos con valores at&amp;iacute;picos&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="baeb2b7a43c2bc0dd04675c021d6ed663a58bf2d" translate="yes" xml:space="preserve">
          <source>In general, the run time cost to construct a balanced binary tree is \(O(n_{samples}n_{features}\log(n_{samples}))\) and query time \(O(\log(n_{samples}))\). Although the tree construction algorithm attempts to generate balanced trees, they will not always be balanced. Assuming that the subtrees remain approximately balanced, the cost at each node consists of searching through \(O(n_{features})\) to find the feature that offers the largest reduction in entropy. This has a cost of \(O(n_{features}n_{samples}\log(n_{samples}))\) at each node, leading to a total cost over the entire trees (by summing the cost at each node) of \(O(n_{features}n_{samples}^{2}\log(n_{samples}))\).</source>
          <target state="translated">En general,el coste del tiempo de ejecución para construir un árbol binario equilibrado es Aunque el algoritmo de construcción de árboles intenta generar árboles equilibrados,no siempre estarán equilibrados.Asumiendo que los subárboles permanecen aproximadamente equilibrados,el coste en cada nodo consiste en buscar a través de \(O(n_{características})\)para encontrar la característica que ofrece la mayor reducción de entropía.Esto tiene un coste de \N (O(n_{características}n_{muestras}}en cada nodo,lo que lleva a un coste total sobre los árboles enteros (sumando el coste en cada nodo)de \N (O(n_{características}n_{muestras}^{2}log(n_{muestras}))}).</target>
        </trans-unit>
        <trans-unit id="635895acc09f2d99381585bc2d144c9a66a85f3a" translate="yes" xml:space="preserve">
          <source>In gradient descent, the gradient \(\nabla Loss_{W}\) of the loss with respect to the weights is computed and deducted from \(W\). More formally, this is expressed as,</source>
          <target state="translated">En el descenso del gradiente,el gradiente de la pérdida con respecto a los pesos se calcula y se deduce de la pérdida.Más formalmente,esto se expresa como,</target>
        </trans-unit>
        <trans-unit id="2c51a2af5a19ac0ce7e4fb04fd6d887c03b6fecb" translate="yes" xml:space="preserve">
          <source>In high-dimensional spaces, linear classifiers often achieve excellent accuracy. For sparse binary data, BernoulliNB is particularly well-suited. The bottom row compares the decision boundary obtained by BernoulliNB in the transformed space with an ExtraTreesClassifier forests learned on the original data.</source>
          <target state="translated">En los espacios de altas dimensiones,los clasificadores lineales a menudo logran una excelente precisión.Para datos binarios escasos,BernoulliNB es particularmente adecuado.La fila inferior compara el límite de decisión obtenido por BernoulliNB en el espacio transformado con un ExtraTreesClassifier bosques aprendido en los datos originales.</target>
        </trans-unit>
        <trans-unit id="7b577c96674cf299faa19ce0d11e2224d3c2c813" translate="yes" xml:space="preserve">
          <source>In majority voting, the predicted class label for a particular sample is the class label that represents the majority (mode) of the class labels predicted by each individual classifier.</source>
          <target state="translated">En la votación por mayoría,la etiqueta de clase pronosticada para una muestra particular es la etiqueta de clase que representa la mayoría (modo)de las etiquetas de clase pronosticadas por cada clasificador individual.</target>
        </trans-unit>
        <trans-unit id="589394183aec0e7af2afe4b456559f6baedc9992" translate="yes" xml:space="preserve">
          <source>In many cases it is thus recommended to carefully time and profile your feature extraction code as it may be a good place to start optimizing when your overall latency is too slow for your application.</source>
          <target state="translated">Por lo tanto,en muchos casos se recomienda cronometrar y perfilar cuidadosamente el código de extracción de características,ya que puede ser un buen lugar para comenzar a optimizar cuando la latencia general es demasiado lenta para la aplicación.</target>
        </trans-unit>
        <trans-unit id="aeae04273a5ed1fc88f796de718e3c2190c04f0d" translate="yes" xml:space="preserve">
          <source>In many modeling scenarios, normality of the features in a dataset is desirable. Power transforms are a family of parametric, monotonic transformations that aim to map data from any distribution to as close to a Gaussian distribution as possible in order to stabilize variance and minimize skewness.</source>
          <target state="translated">En muchos escenarios de modelización,es deseable la normalidad de las características de un conjunto de datos.Las transformaciones de potencia son una familia de transformaciones paramétricas y monótonas que tienen por objeto cartografiar los datos de cualquier distribución lo más cerca posible de una distribución gaussiana a fin de estabilizar la varianza y minimizar la asimetría.</target>
        </trans-unit>
        <trans-unit id="c82f65d47c3f4e11ad468a4165bdc787c51720a5" translate="yes" xml:space="preserve">
          <source>In many real-world examples, there are many ways to extract features from a dataset. Often it is beneficial to combine several methods to obtain good performance. This example shows how to use &lt;code&gt;FeatureUnion&lt;/code&gt; to combine features obtained by PCA and univariate selection.</source>
          <target state="translated">En muchos ejemplos del mundo real, hay muchas formas de extraer caracter&amp;iacute;sticas de un conjunto de datos. A menudo es beneficioso combinar varios m&amp;eacute;todos para obtener un buen rendimiento. Este ejemplo muestra c&amp;oacute;mo usar &lt;code&gt;FeatureUnion&lt;/code&gt; para combinar caracter&amp;iacute;sticas obtenidas por PCA y selecci&amp;oacute;n univariante.</target>
        </trans-unit>
        <trans-unit id="9c0b7f3861d3fe001968b978c49f3447d1233fa3" translate="yes" xml:space="preserve">
          <source>In mathematics, the Johnson-Lindenstrauss lemma is a result concerning low-distortion embeddings of points from high-dimensional into low-dimensional Euclidean space. The lemma states that a small set of points in a high-dimensional space can be embedded into a space of much lower dimension in such a way that distances between the points are nearly preserved. The map used for the embedding is at least Lipschitz, and can even be taken to be an orthogonal projection.</source>
          <target state="translated">En matemáticas,el lema de Johnson-Lindenstrauss es un resultado relativo a las incrustaciones de baja distorsión de los puntos del espacio euclidiano de alta dimensión en el de baja dimensión.El lema afirma que un pequeño conjunto de puntos en un espacio de alta dimensión puede ser incrustado en un espacio de dimensión mucho más baja de tal manera que las distancias entre los puntos se conservan casi intactas.El mapa utilizado para la incrustación es al menos Lipschitz,e incluso puede ser tomado como una proyección ortogonal.</target>
        </trans-unit>
        <trans-unit id="35a3805825da50966c5f8cb649b1d2ea852b8f59" translate="yes" xml:space="preserve">
          <source>In maximizing the log-likelihood, the positive gradient makes the model prefer hidden states that are compatible with the observed training data. Because of the bipartite structure of RBMs, it can be computed efficiently. The negative gradient, however, is intractable. Its goal is to lower the energy of joint states that the model prefers, therefore making it stay true to the data. It can be approximated by Markov chain Monte Carlo using block Gibbs sampling by iteratively sampling each of \(v\) and \(h\) given the other, until the chain mixes. Samples generated in this way are sometimes referred as fantasy particles. This is inefficient and it is difficult to determine whether the Markov chain mixes.</source>
          <target state="translated">Al maximizar la probabilidad logarítmica,el gradiente positivo hace que el modelo prefiera los estados ocultos que son compatibles con los datos de entrenamiento observados.Debido a la estructura bipartita de los RBM,puede ser computado eficientemente.El gradiente negativo,sin embargo,es intratable.Su objetivo es reducir la energía de los estados conjuntos que el modelo prefiere,por lo que se mantiene fiel a los datos.Puede ser aproximado por la cadena de Markov Monte Carlo usando el muestreo de Gibbs en bloque,muestreando iterativamente cada uno de \ ~ (v)y \ ~ dado el otro,hasta que la cadena se mezcla.Las muestras generadas de esta manera se denominan a veces partículas de fantasía.Esto es ineficiente y es difícil determinar si la cadena de Markov se mezcla.</target>
        </trans-unit>
        <trans-unit id="54db7da5f1b2e2f16e8f4dc3a375dac661b78213" translate="yes" xml:space="preserve">
          <source>In multi-label classification, the &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt; function is extended by averaging over the labels as &lt;a href=&quot;#average&quot;&gt;above&lt;/a&gt;.</source>
          <target state="translated">En la clasificaci&amp;oacute;n de etiquetas m&amp;uacute;ltiples, la funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;roc_auc_score&lt;/code&gt; &lt;/a&gt; se ampl&amp;iacute;a promediando las etiquetas como se indic&amp;oacute;&lt;a href=&quot;#average&quot;&gt; anteriormente&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="d9be5dcb267dcb84c278d12d7b1a881ada760886" translate="yes" xml:space="preserve">
          <source>In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.</source>
          <target state="translated">En la clasificación multi-etiqueta,ésta es la precisión del subconjunto,que es una métrica dura,ya que se requiere para cada muestra que cada conjunto de etiquetas sea predicho correctamente.</target>
        </trans-unit>
        <trans-unit id="9ff5420b9cd3095ee44bf9941c38c72dce6d517a" translate="yes" xml:space="preserve">
          <source>In multi-label settings</source>
          <target state="translated">En los entornos de múltiples etiquetas</target>
        </trans-unit>
        <trans-unit id="cf7a69d811fd496380ea6a3966d13bf17ca83f43" translate="yes" xml:space="preserve">
          <source>In multiclass and multilabel classification task, the notions of precision, recall, and F-measures can be applied to each label independently. There are a few ways to combine results across labels, specified by the &lt;code&gt;average&lt;/code&gt; argument to the &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; (multilabel only), &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt;&lt;code&gt;f1_score&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt;&lt;code&gt;fbeta_score&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.precision_recall_fscore_support#sklearn.metrics.precision_recall_fscore_support&quot;&gt;&lt;code&gt;precision_recall_fscore_support&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.precision_score#sklearn.metrics.precision_score&quot;&gt;&lt;code&gt;precision_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.recall_score#sklearn.metrics.recall_score&quot;&gt;&lt;code&gt;recall_score&lt;/code&gt;&lt;/a&gt; functions, as described &lt;a href=&quot;#average&quot;&gt;above&lt;/a&gt;. Note that if all labels are included, &amp;ldquo;micro&amp;rdquo;-averaging in a multiclass setting will produce precision, recall and \(F\) that are all identical to accuracy. Also note that &amp;ldquo;weighted&amp;rdquo; averaging may produce an F-score that is not between precision and recall.</source>
          <target state="translated">En la tarea de clasificaci&amp;oacute;n multiclase y de m&amp;uacute;ltiples etiquetas, las nociones de precisi&amp;oacute;n, recuperaci&amp;oacute;n y medidas F se pueden aplicar a cada etiqueta de forma independiente. Hay unas pocas maneras de combinar resultados a trav&amp;eacute;s de etiquetas, especificados por el &lt;code&gt;average&lt;/code&gt; argumento a la &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt; (Multilabel solamente), &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt; &lt;code&gt;f1_score&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt; &lt;code&gt;fbeta_score&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.metrics.precision_recall_fscore_support#sklearn.metrics.precision_recall_fscore_support&quot;&gt; &lt;code&gt;precision_recall_fscore_support&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.metrics.precision_score#sklearn.metrics.precision_score&quot;&gt; &lt;code&gt;precision_score&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.metrics.recall_score#sklearn.metrics.recall_score&quot;&gt; &lt;code&gt;recall_score&lt;/code&gt; &lt;/a&gt; funciones, como se describe &lt;a href=&quot;#average&quot;&gt;anteriormente&lt;/a&gt;. Tenga en cuenta que si se incluyen todas las etiquetas, el &quot;micro&quot; promediado en un entorno multiclase producir&amp;aacute; precisi&amp;oacute;n, recuperaci&amp;oacute;n y \ (F \) que son todos id&amp;eacute;nticos a la precisi&amp;oacute;n. Tambi&amp;eacute;n tenga en cuenta que el promedio &quot;ponderado&quot; puede producir una puntuaci&amp;oacute;n F que no se encuentra entre la precisi&amp;oacute;n y el recuerdo.</target>
        </trans-unit>
        <trans-unit id="afc91520f5287da47360dcd6fd00b4fb446bcf96" translate="yes" xml:space="preserve">
          <source>In multiclass case, the function expects that either all the labels are included in y_true or an optional labels argument is provided which contains all the labels. The multilabel margin is calculated according to Crammer-Singer&amp;rsquo;s method. As in the binary case, the cumulated hinge loss is an upper bound of the number of mistakes made by the classifier.</source>
          <target state="translated">En el caso multiclase, la funci&amp;oacute;n espera que todas las etiquetas est&amp;eacute;n incluidas en y_true o se proporcione un argumento de etiquetas opcional que contenga todas las etiquetas. El margen de varias etiquetas se calcula seg&amp;uacute;n el m&amp;eacute;todo de Crammer-Singer. Como en el caso binario, la p&amp;eacute;rdida de bisagra acumulada es un l&amp;iacute;mite superior del n&amp;uacute;mero de errores cometidos por el clasificador.</target>
        </trans-unit>
        <trans-unit id="a7ec36140af641cfb5e4e5e11dec536798cfb2f8" translate="yes" xml:space="preserve">
          <source>In multiclass classification, the Hamming loss correspond to the Hamming distance between &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; which is equivalent to the subset &lt;code&gt;zero_one_loss&lt;/code&gt; function.</source>
          <target state="translated">En la clasificaci&amp;oacute;n multiclase, la p&amp;eacute;rdida de Hamming corresponde a la distancia de Hamming entre &lt;code&gt;y_true&lt;/code&gt; e &lt;code&gt;y_pred&lt;/code&gt; que es equivalente al subconjunto &lt;code&gt;zero_one_loss&lt;/code&gt; funci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="ff1916ae5265c4d87d1472e5cc3e0c2594a22de8" translate="yes" xml:space="preserve">
          <source>In multiclass classification, the Hamming loss corresponds to the Hamming distance between &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; which is similar to the &lt;a href=&quot;#zero-one-loss&quot;&gt;Zero one loss&lt;/a&gt; function. However, while zero-one loss penalizes prediction sets that do not strictly match true sets, the Hamming loss penalizes individual labels. Thus the Hamming loss, upper bounded by the zero-one loss, is always between zero and one, inclusive; and predicting a proper subset or superset of the true labels will give a Hamming loss between zero and one, exclusive.</source>
          <target state="translated">En la clasificaci&amp;oacute;n multiclase, la p&amp;eacute;rdida de Hamming corresponde a la distancia de Hamming entre &lt;code&gt;y_true&lt;/code&gt; e &lt;code&gt;y_pred&lt;/code&gt; , que es similar a la funci&amp;oacute;n de &lt;a href=&quot;#zero-one-loss&quot;&gt;cero una p&amp;eacute;rdida&lt;/a&gt; . Sin embargo, mientras que la p&amp;eacute;rdida cero-uno penaliza los conjuntos de predicci&amp;oacute;n que no coinciden estrictamente con los conjuntos verdaderos, la p&amp;eacute;rdida de Hamming penaliza a las etiquetas individuales. As&amp;iacute;, la p&amp;eacute;rdida de Hamming, delimitada por la p&amp;eacute;rdida cero-uno, est&amp;aacute; siempre entre cero y uno, inclusive; y predecir un subconjunto o superconjunto adecuado de las etiquetas verdaderas dar&amp;aacute; una p&amp;eacute;rdida de Hamming entre cero y uno, exclusiva.</target>
        </trans-unit>
        <trans-unit id="cf7ce831a18d046dad4e38dc2cae92648b792778" translate="yes" xml:space="preserve">
          <source>In multilabel classification, the &lt;a href=&quot;generated/sklearn.metrics.zero_one_loss#sklearn.metrics.zero_one_loss&quot;&gt;&lt;code&gt;zero_one_loss&lt;/code&gt;&lt;/a&gt; scores a subset as one if its labels strictly match the predictions, and as a zero if there are any errors. By default, the function returns the percentage of imperfectly predicted subsets. To get the count of such subsets instead, set &lt;code&gt;normalize&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">En la clasificaci&amp;oacute;n de m&amp;uacute;ltiples etiquetas, &lt;a href=&quot;generated/sklearn.metrics.zero_one_loss#sklearn.metrics.zero_one_loss&quot;&gt; &lt;code&gt;zero_one_loss&lt;/code&gt; &lt;/a&gt; punt&amp;uacute;a un subconjunto como uno si sus etiquetas coinciden estrictamente con las predicciones, y como un cero si hay alg&amp;uacute;n error. De forma predeterminada, la funci&amp;oacute;n devuelve el porcentaje de subconjuntos predichos de manera imperfecta. Para obtener el recuento de dichos subconjuntos, establezca &lt;code&gt;normalize&lt;/code&gt; en &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="2cdc777c3fd9aacea19e984339f1423c55608098" translate="yes" xml:space="preserve">
          <source>In multilabel classification, the Hamming loss is different from the subset zero-one loss. The zero-one loss considers the entire set of labels for a given sample incorrect if it does entirely match the true set of labels. Hamming loss is more forgiving in that it penalizes the individual labels.</source>
          <target state="translated">En la clasificación de la multi-etiqueta,la pérdida de Hamming es diferente de la pérdida del subconjunto cero-uno.La pérdida de cero uno considera que el conjunto de etiquetas de una muestra dada es incorrecto si coincide totalmente con el verdadero conjunto de etiquetas.La pérdida por martilleo es más indulgente porque penaliza las etiquetas individuales.</target>
        </trans-unit>
        <trans-unit id="00e9bece59054d08c4ac787e06eeb4fc8070bdab" translate="yes" xml:space="preserve">
          <source>In multilabel classification, the function returns the subset accuracy. If the entire set of predicted labels for a sample strictly match with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0.</source>
          <target state="translated">En la clasificación de la etiqueta múltiple,la función devuelve la precisión del subconjunto.Si el conjunto completo de etiquetas predichas para una muestra coincide estrictamente con el verdadero conjunto de etiquetas,entonces la precisión del subconjunto es 1.0;de lo contrario es 0.0.</target>
        </trans-unit>
        <trans-unit id="7cd1b88a6c55666089bdc7543f7e259d70d5898d" translate="yes" xml:space="preserve">
          <source>In multilabel classification, the zero_one_loss function corresponds to the subset zero-one loss: for each sample, the entire set of labels must be correctly predicted, otherwise the loss for that sample is equal to one.</source>
          <target state="translated">En la clasificación de las etiquetas múltiples,la función zero_one_loss corresponde al subconjunto de la pérdida zero_one:para cada muestra,el conjunto de etiquetas debe ser correctamente previsto,de lo contrario la pérdida para esa muestra es igual a uno.</target>
        </trans-unit>
        <trans-unit id="c56a96e702a01557c0cb1c7c6c5d254cdaebcc8b" translate="yes" xml:space="preserve">
          <source>In multilabel classification, this function computes subset accuracy: the set of labels predicted for a sample must &lt;em&gt;exactly&lt;/em&gt; match the corresponding set of labels in y_true.</source>
          <target state="translated">En la clasificaci&amp;oacute;n de etiquetas m&amp;uacute;ltiples, esta funci&amp;oacute;n calcula la precisi&amp;oacute;n del subconjunto: el conjunto de etiquetas predichas para una muestra debe coincidir &lt;em&gt;exactamente&lt;/em&gt; con el conjunto de etiquetas correspondiente en y_true.</target>
        </trans-unit>
        <trans-unit id="3fad4287dcc0210ad8169708b233947ca706f077" translate="yes" xml:space="preserve">
          <source>In multilabel learning, each sample can have any number of ground truth labels associated with it. The goal is to give high scores and better rank to the ground truth labels.</source>
          <target state="translated">En el aprendizaje de las etiquetas múltiples,cada muestra puede tener asociadas cualquier número de etiquetas de verdad de la tierra.El objetivo es dar altas puntuaciones y una mejor clasificación a las etiquetas de verdades básicas.</target>
        </trans-unit>
        <trans-unit id="9d6449537c42279d12e406059563c338784d06f3" translate="yes" xml:space="preserve">
          <source>In multilabel learning, the joint set of binary classification tasks is expressed with label binary indicator array: each sample is one row of a 2d array of shape (n_samples, n_classes) with binary values: the one, i.e. the non zero elements, corresponds to the subset of labels. An array such as &lt;code&gt;np.array([[1, 0, 0], [0, 1, 1], [0, 0, 0]])&lt;/code&gt; represents label 0 in the first sample, labels 1 and 2 in the second sample, and no labels in the third sample.</source>
          <target state="translated">En el aprendizaje de m&amp;uacute;ltiples etiquetas, el conjunto conjunto de tareas de clasificaci&amp;oacute;n binaria se expresa con la etiqueta matriz de indicador binario: cada muestra es una fila de una matriz 2d de forma (n_samples, n_classes) con valores binarios: el uno, es decir, los elementos distintos de cero, corresponde a el subconjunto de etiquetas. Una matriz como &lt;code&gt;np.array([[1, 0, 0], [0, 1, 1], [0, 0, 0]])&lt;/code&gt; representa la etiqueta 0 en la primera muestra, las etiquetas 1 y 2 en la segunda muestra y sin etiquetas en la tercera muestra.</target>
        </trans-unit>
        <trans-unit id="6c2c0f769c8a98dc6df3f2e7afe566ac80c0f339" translate="yes" xml:space="preserve">
          <source>In normal usage, the Calinski-Harabaz index is applied to the results of a cluster analysis.</source>
          <target state="translated">En el uso normal,el índice de Calinski-Harabaz se aplica a los resultados de un análisis de conglomerados.</target>
        </trans-unit>
        <trans-unit id="5f0c7d20ec265094d1673fd625fd38165b384452" translate="yes" xml:space="preserve">
          <source>In normal usage, the Davies-Bouldin index is applied to the results of a cluster analysis as follows:</source>
          <target state="translated">En el uso normal,el índice de Davies-Bouldin se aplica a los resultados de un análisis de conglomerados de la siguiente manera:</target>
        </trans-unit>
        <trans-unit id="0488e7351783ef8ef785f4bdea49af8c75724adf" translate="yes" xml:space="preserve">
          <source>In normal usage, the Silhouette Coefficient is applied to the results of a cluster analysis.</source>
          <target state="translated">En el uso normal,el Coeficiente de Silueta se aplica a los resultados de un análisis de conglomerados.</target>
        </trans-unit>
        <trans-unit id="af7916eabb756a4304309b1e18ceea097a7a5071" translate="yes" xml:space="preserve">
          <source>In order to address the wider task of Natural Language Understanding, the local structure of sentences and paragraphs should thus be taken into account. Many such models will thus be casted as &amp;ldquo;Structured output&amp;rdquo; problems which are currently outside of the scope of scikit-learn.</source>
          <target state="translated">Por tanto, para abordar la tarea m&amp;aacute;s amplia de la comprensi&amp;oacute;n del lenguaje natural, se debe tener en cuenta la estructura local de oraciones y p&amp;aacute;rrafos. Por lo tanto, muchos de estos modelos se considerar&amp;aacute;n problemas de &quot;salida estructurada&quot; que actualmente est&amp;aacute;n fuera del alcance de scikit-learn.</target>
        </trans-unit>
        <trans-unit id="819693d214fc959100941f9c2bf3cb570fc069ec" translate="yes" xml:space="preserve">
          <source>In order to address this, scikit-learn provides utilities for the most common ways to extract numerical features from text content, namely:</source>
          <target state="translated">Para hacer frente a esto,scikit-learn proporciona utilidades para las formas más comunes de extraer características numéricas del contenido del texto,a saber:</target>
        </trans-unit>
        <trans-unit id="5bdd52099ccc039c40b609f18b326c63aea62fae" translate="yes" xml:space="preserve">
          <source>In order to be able to store such a matrix in memory but also to speed up algebraic operations matrix / vector, implementations will typically use a sparse representation such as the implementations available in the &lt;code&gt;scipy.sparse&lt;/code&gt; package.</source>
          <target state="translated">Para poder almacenar una matriz de este tipo en la memoria, pero tambi&amp;eacute;n para acelerar la matriz / vector de operaciones algebraicas, las implementaciones normalmente utilizar&amp;aacute;n una representaci&amp;oacute;n escasa, como las implementaciones disponibles en el paquete &lt;code&gt;scipy.sparse&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b0bf98f40bc311f4824763dea8c552bc0812d861" translate="yes" xml:space="preserve">
          <source>In order to feed predictive or clustering models with the text data, one first need to turn the text into vectors of numerical values suitable for statistical analysis. This can be achieved with the utilities of the &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; as demonstrated in the following example that extract &lt;a href=&quot;https://en.wikipedia.org/wiki/Tf-idf&quot;&gt;TF-IDF&lt;/a&gt; vectors of unigram tokens from a subset of 20news:</source>
          <target state="translated">Para alimentar modelos predictivos o de agrupamiento con datos de texto, primero es necesario convertir el texto en vectores de valores num&amp;eacute;ricos adecuados para el an&amp;aacute;lisis estad&amp;iacute;stico. Esto se puede lograr con las utilidades de &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; como se demuestra en el siguiente ejemplo que extrae vectores &lt;a href=&quot;https://en.wikipedia.org/wiki/Tf-idf&quot;&gt;TF-IDF&lt;/a&gt; de tokens unigram de un subconjunto de 20news:</target>
        </trans-unit>
        <trans-unit id="a439a73e36b65ee0a94b3f1d9d89e3ac154697cf" translate="yes" xml:space="preserve">
          <source>In order to get faster execution times for this first example we will work on a partial dataset with only 4 categories out of the 20 available in the dataset:</source>
          <target state="translated">Para obtener tiempos de ejecución más rápidos para este primer ejemplo trabajaremos en un conjunto de datos parciales con sólo 4 categorías de las 20 disponibles en el conjunto de datos:</target>
        </trans-unit>
        <trans-unit id="da7edac191ef2f2a6bab6d167570c5dc3d626b83" translate="yes" xml:space="preserve">
          <source>In order to learn good latent representations from a small dataset, we artificially generate more labeled data by perturbing the training data with linear shifts of 1 pixel in each direction.</source>
          <target state="translated">Para aprender buenas representaciones latentes de un pequeño conjunto de datos,generamos artificialmente más datos etiquetados perturbando los datos de entrenamiento con desplazamientos lineales de 1 píxel en cada dirección.</target>
        </trans-unit>
        <trans-unit id="6983d2c6ff1cbf277ea5d9522b128070bfd0a615" translate="yes" xml:space="preserve">
          <source>In order to make the vectorizer =&amp;gt; transformer =&amp;gt; classifier easier to work with, &lt;code&gt;scikit-learn&lt;/code&gt; provides a &lt;a href=&quot;../../modules/generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; class that behaves like a compound classifier:</source>
          <target state="translated">Para facilitar el trabajo con el vectorizador =&amp;gt; transformador =&amp;gt; clasificador, &lt;code&gt;scikit-learn&lt;/code&gt; proporciona una clase &lt;a href=&quot;../../modules/generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;Pipeline&lt;/code&gt; &lt;/a&gt; que se comporta como un clasificador compuesto:</target>
        </trans-unit>
        <trans-unit id="5257e11193f291f6f81d5d2347e3cbb71ec9f310" translate="yes" xml:space="preserve">
          <source>In order to perform machine learning on text documents, we first need to turn the text content into numerical feature vectors.</source>
          <target state="translated">Para realizar el aprendizaje automático en documentos de texto,primero tenemos que convertir el contenido del texto en vectores de características numéricas.</target>
        </trans-unit>
        <trans-unit id="7b973d24b18f4331d1cc68b945953f9c40c766fe" translate="yes" xml:space="preserve">
          <source>In order to predict the class labels based on the predicted class-probabilities (scikit-learn estimators in the VotingClassifier must support &lt;code&gt;predict_proba&lt;/code&gt; method):</source>
          <target state="translated">Para predecir las etiquetas de clase basadas en las probabilidades de clase predichas (los estimadores de scikit-learn en el VotingClassifier deben admitir el m&amp;eacute;todo &lt;code&gt;predict_proba&lt;/code&gt; ):</target>
        </trans-unit>
        <trans-unit id="a7ffbb7849ad7a74935991324e062c6b6722378d" translate="yes" xml:space="preserve">
          <source>In order to re-weight the count features into floating point values suitable for usage by a classifier it is very common to use the tf&amp;ndash;idf transform.</source>
          <target state="translated">Para volver a ponderar las caracter&amp;iacute;sticas de recuento en valores de punto flotante adecuados para su uso por un clasificador, es muy com&amp;uacute;n utilizar la transformaci&amp;oacute;n tf-idf.</target>
        </trans-unit>
        <trans-unit id="4707665df8a323c1a68b209bc6166b3798e4ea75" translate="yes" xml:space="preserve">
          <source>In order to rebuild a similar model with future versions of scikit-learn, additional metadata should be saved along the pickled model:</source>
          <target state="translated">Para reconstruir un modelo similar con futuras versiones de scikit-learn,se deben guardar metadatos adicionales a lo largo del modelo encurtido:</target>
        </trans-unit>
        <trans-unit id="168239ecf279021917cbfef805f1d7d711ae1c44" translate="yes" xml:space="preserve">
          <source>In order to test if a classification score is significative a technique in repeating the classification procedure after randomizing, permuting, the labels. The p-value is then given by the percentage of runs for which the score obtained is greater than the classification score obtained in the first place.</source>
          <target state="translated">Para comprobar si una puntuación de clasificación es significativa,se ha recurrido a una técnica de repetición del procedimiento de clasificación después de aleatorizar,permutar,las etiquetas.El valor p viene dado entonces por el porcentaje de carreras en las que la puntuación obtenida es mayor que la puntuación de clasificación obtenida en primer lugar.</target>
        </trans-unit>
        <trans-unit id="fdc8e1656ba1332f0933f9f656403151b15252d2" translate="yes" xml:space="preserve">
          <source>In other words, return an input X_original whose transform would be X.</source>
          <target state="translated">En otras palabras,devuelve una entrada X_original cuya transformación sería X.</target>
        </trans-unit>
        <trans-unit id="f84fbaf022a2c87e2f72b92c7b8059751d7f8963" translate="yes" xml:space="preserve">
          <source>In other words, we &lt;em&gt;decomposed&lt;/em&gt; matrix \(\mathbf{X}\).</source>
          <target state="translated">En otras palabras, &lt;em&gt;descomponemos la&lt;/em&gt; matriz \ (\ mathbf {X} \).</target>
        </trans-unit>
        <trans-unit id="573ad5780d66d8749d635925a4f90732aa002652" translate="yes" xml:space="preserve">
          <source>In particular Rosenberg and Hirschberg (2007) define the following two desirable objectives for any cluster assignment:</source>
          <target state="translated">En particular,Rosenberg y Hirschberg (2007)definen los dos siguientes objetivos deseables para cualquier asignación de grupos:</target>
        </trans-unit>
        <trans-unit id="dafd8fff090495231531a6dce6a0d9bf23cd3c87" translate="yes" xml:space="preserve">
          <source>In particular in a &lt;strong&gt;supervised setting&lt;/strong&gt; it can be successfully combined with fast and scalable linear models to train &lt;strong&gt;document classifiers&lt;/strong&gt;, for instance:</source>
          <target state="translated">En particular, en un &lt;strong&gt;entorno supervisado,&lt;/strong&gt; se puede combinar con &amp;eacute;xito con modelos lineales r&amp;aacute;pidos y escalables para entrenar &lt;strong&gt;clasificadores de documentos&lt;/strong&gt; , por ejemplo:</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
