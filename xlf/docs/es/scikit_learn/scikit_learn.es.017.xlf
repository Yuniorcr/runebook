<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="es" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="2555b04ef28112b324874c1cc2f3bf2b5b5c384e" translate="yes" xml:space="preserve">
          <source>Mutual information, a non-negative value</source>
          <target state="translated">La información mutua,un valor no negativo</target>
        </trans-unit>
        <trans-unit id="b51a60734da64be0e618bacbea2865a8a7dcd669" translate="yes" xml:space="preserve">
          <source>N</source>
          <target state="translated">N</target>
        </trans-unit>
        <trans-unit id="4e1221dedd7ee34eb6931a44dc15d9a84ca69a81" translate="yes" xml:space="preserve">
          <source>N : number of dimensions</source>
          <target state="translated">N:número de dimensiones</target>
        </trans-unit>
        <trans-unit id="8daf5ce04352d841160e980446540ca50cce58e4" translate="yes" xml:space="preserve">
          <source>N-grams to the rescue! Instead of building a simple collection of unigrams (n=1), one might prefer a collection of bigrams (n=2), where occurrences of pairs of consecutive words are counted.</source>
          <target state="translated">¡N-grams al rescate! En lugar de construir una simple colección de unigramas (n=1),uno podría preferir una colección de bigrams (n=2),donde se cuentan las ocurrencias de pares de palabras consecutivas.</target>
        </trans-unit>
        <trans-unit id="0d5c48bb908535393359e08969f6193dc43fff44" translate="yes" xml:space="preserve">
          <source>NCA can be seen as learning a (squared) Mahalanobis distance metric:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78bd06a1d3ff24b26b2d2d7bba48b35d89d447f8" translate="yes" xml:space="preserve">
          <source>NCA can be used to perform supervised dimensionality reduction. The input data are projected onto a linear subspace consisting of the directions which minimize the NCA objective. The desired dimensionality can be set using the parameter &lt;code&gt;n_components&lt;/code&gt;. For instance, the following figure shows a comparison of dimensionality reduction with Principal Component Analysis (&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;sklearn.decomposition.PCA&lt;/code&gt;&lt;/a&gt;), Linear Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;sklearn.discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) and Neighborhood Component Analysis (&lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt;&lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt;&lt;/a&gt;) on the Digits dataset, a dataset with size \(n_{samples} = 1797\) and \(n_{features} = 64\). The data set is split into a training and a test set of equal size, then standardized. For evaluation the 3-nearest neighbor classification accuracy is computed on the 2-dimensional projected points found by each method. Each data sample belongs to one of 10 classes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="178c8cecc0d6623e23a76bbb064f3967dc7aa43a" translate="yes" xml:space="preserve">
          <source>NCA classification has been shown to work well in practice for data sets of varying size and difficulty. In contrast to related methods such as Linear Discriminant Analysis, NCA does not make any assumptions about the class distributions. The nearest neighbor classification can naturally produce highly irregular decision boundaries.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a288a9444d289c6327b252974b74e26d9ed71a92" translate="yes" xml:space="preserve">
          <source>NCA stores a matrix of pairwise distances, taking &lt;code&gt;n_samples ** 2&lt;/code&gt; memory. Time complexity depends on the number of iterations done by the optimisation algorithm. However, one can set the maximum number of iterations with the argument &lt;code&gt;max_iter&lt;/code&gt;. For each iteration, time complexity is &lt;code&gt;O(n_components x n_samples x min(n_samples, n_features))&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="235c4fdc295d941494351e73dad0edc432affd04" translate="yes" xml:space="preserve">
          <source>NFF : number of dims in which both values are False</source>
          <target state="translated">NFF:número de dimisiones en las que ambos valores son falsos</target>
        </trans-unit>
        <trans-unit id="f242d8e1cdbbc8cb628621d8d57f10327047707d" translate="yes" xml:space="preserve">
          <source>NFT : number of dims in which the first value is False, second is True</source>
          <target state="translated">NFT:número de puntos débiles en los que el primer valor es falso,el segundo es verdadero.</target>
        </trans-unit>
        <trans-unit id="ced12bb5137dbf26fd788e77cae54623cdb8b2e8" translate="yes" xml:space="preserve">
          <source>NMF is best used with the &lt;code&gt;fit_transform&lt;/code&gt; method, which returns the matrix W. The matrix H is stored into the fitted model in the &lt;code&gt;components_&lt;/code&gt; attribute; the method &lt;code&gt;transform&lt;/code&gt; will decompose a new matrix X_new based on these stored components:</source>
          <target state="translated">NMF se utiliza mejor con el m&amp;eacute;todo &lt;code&gt;fit_transform&lt;/code&gt; , que devuelve la matriz W. La matriz H se almacena en el modelo ajustado en el atributo &lt;code&gt;components_&lt;/code&gt; ; la &lt;code&gt;transform&lt;/code&gt; aci&amp;oacute;n del m&amp;eacute;todo descompondr&amp;aacute; una nueva matriz X_new basada en estos componentes almacenados:</target>
        </trans-unit>
        <trans-unit id="9546ef450bf032f2a099e2b8894066e314108bcc" translate="yes" xml:space="preserve">
          <source>NMI and MI are not adjusted against chance.</source>
          <target state="translated">El NMI y el MI no se ajustan al azar.</target>
        </trans-unit>
        <trans-unit id="ec8506cc20e415f16975d43b2c6e163b63b7c223" translate="yes" xml:space="preserve">
          <source>NNEQ / (NNEQ + 0.5 * NTT)</source>
          <target state="translated">NNEQ/(NNEQ+0.5*NTT)</target>
        </trans-unit>
        <trans-unit id="64142d93685b184d0f4668dd2d38de67d364504a" translate="yes" xml:space="preserve">
          <source>NNEQ / (NTT + NNZ)</source>
          <target state="translated">NNEQ/(NTT+NNZ)</target>
        </trans-unit>
        <trans-unit id="9e2ca45598fef4852f298770d7c7037071a195c1" translate="yes" xml:space="preserve">
          <source>NNEQ / N</source>
          <target state="translated">NNEQ/N</target>
        </trans-unit>
        <trans-unit id="bd22d441438dd8339012b8925c55919834498020" translate="yes" xml:space="preserve">
          <source>NNEQ / NNZ</source>
          <target state="translated">NNEQ/NNZ</target>
        </trans-unit>
        <trans-unit id="a4e22ff89a7f8daef1da10b2c311e81f8eb57054" translate="yes" xml:space="preserve">
          <source>NNEQ : number of non-equal dimensions, NNEQ = NTF + NFT</source>
          <target state="translated">NNEQ:número de dimensiones no iguales,NNEQ=NTF+NFT</target>
        </trans-unit>
        <trans-unit id="80bfd3623c0e507836f83286688a2ee41b18b00e" translate="yes" xml:space="preserve">
          <source>NNZ / N</source>
          <target state="translated">NNZ/N</target>
        </trans-unit>
        <trans-unit id="93209a2edd337e6dc4e7c870a3c72537cea28fdf" translate="yes" xml:space="preserve">
          <source>NNZ : number of nonzero dimensions, NNZ = NTF + NFT + NTT</source>
          <target state="translated">NNZ:número de dimensiones no nulas,NNZ=NTF+NFT+NTT</target>
        </trans-unit>
        <trans-unit id="a8ad860c15810cce0e7beac1c91da3ab2cb22c47" translate="yes" xml:space="preserve">
          <source>NOTE</source>
          <target state="translated">NOTE</target>
        </trans-unit>
        <trans-unit id="b81cbdff62e50c72d48e4feea8a9ed88bea18bef" translate="yes" xml:space="preserve">
          <source>NOTE that when using custom scorers, each scorer should return a single value. Metric functions returning a list/array of values can be wrapped into multiple scorers that return one value each.</source>
          <target state="translated">NOTA:cuando se usan marcadores personalizados,cada marcador debe devolver un único valor.Las funciones métricas que devuelven una lista/matriz de valores pueden ser envueltas en múltiples anotadores que devuelven un valor cada uno.</target>
        </trans-unit>
        <trans-unit id="9764dfb854390dc404102ac64200b55e363e83df" translate="yes" xml:space="preserve">
          <source>NOX nitric oxides concentration (parts per 10 million)</source>
          <target state="translated">Concentración de óxidos nítricos NOX (partes por 10 millones)</target>
        </trans-unit>
        <trans-unit id="99542bc2231d38286b9a1dbe4685e8690203b845" translate="yes" xml:space="preserve">
          <source>NTF : number of dims in which the first value is True, second is False</source>
          <target state="translated">NTF:número de dimesiones en las que el primer valor es Verdadero,el segundo es Falso</target>
        </trans-unit>
        <trans-unit id="d7aff2fba38c5d47fc1d509779237efeccf9cd66" translate="yes" xml:space="preserve">
          <source>NTT : number of dims in which both values are True</source>
          <target state="translated">NTT:número de dimisiones en las que ambos valores son verdaderos</target>
        </trans-unit>
        <trans-unit id="f7fd9c68f804acda665d2ab082217bb1583318f2" translate="yes" xml:space="preserve">
          <source>NaN</source>
          <target state="translated">NaN</target>
        </trans-unit>
        <trans-unit id="6e2518fe965a665a40ec6f1bf71cbacd3d7014df" translate="yes" xml:space="preserve">
          <source>NaNs are ignored in the algorithm.</source>
          <target state="translated">Las NaNs son ignoradas en el algoritmo.</target>
        </trans-unit>
        <trans-unit id="bce02ea83698a345c8e67696ff8bdcc86ad6e774" translate="yes" xml:space="preserve">
          <source>NaNs are treated as missing values: disregarded in &lt;code&gt;fit&lt;/code&gt;, and maintained in &lt;code&gt;transform&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b2cc2bc3bfa4ab2fba6e73cce899558220dd79a" translate="yes" xml:space="preserve">
          <source>NaNs are treated as missing values: disregarded in fit, and maintained in transform.</source>
          <target state="translated">Los NaNs son tratados como valores faltantes:desestimados en el ajuste,y mantenidos en la transformación.</target>
        </trans-unit>
        <trans-unit id="d13d7452647efb26ab0d2b1a3596526a7f4ca5d6" translate="yes" xml:space="preserve">
          <source>NaNs are treated as missing values: disregarded to compute the statistics, and maintained during the data transformation.</source>
          <target state="translated">Los NaNs se tratan como valores perdidos:no se tienen en cuenta para calcular las estadísticas,y se mantienen durante la transformación de los datos.</target>
        </trans-unit>
        <trans-unit id="d5c044a4b683787e1d22f3d89c2071d25a271b09" translate="yes" xml:space="preserve">
          <source>Naive Bayes classifier for categorical features</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80d8f13b4e334c4342adf34b360ad118e5e25aa3" translate="yes" xml:space="preserve">
          <source>Naive Bayes classifier for multinomial models</source>
          <target state="translated">El ingenuo clasificador Bayes para modelos multinomiales</target>
        </trans-unit>
        <trans-unit id="92990e6c1a566f0d055f974e25026ec604b9ccd9" translate="yes" xml:space="preserve">
          <source>Naive Bayes classifier for multivariate Bernoulli models.</source>
          <target state="translated">Clasificador Bayes ingenuo para los modelos multivariantes de Bernoulli.</target>
        </trans-unit>
        <trans-unit id="c95f9acb4985f23ad6962fd01ae91dec549e7273" translate="yes" xml:space="preserve">
          <source>Naive Bayes learners and classifiers can be extremely fast compared to more sophisticated methods. The decoupling of the class conditional feature distributions means that each distribution can be independently estimated as a one dimensional distribution. This in turn helps to alleviate problems stemming from the curse of dimensionality.</source>
          <target state="translated">Los ingenuos aprendices y clasificadores de Bayes pueden ser extremadamente rápidos en comparación con los métodos más sofisticados.La disociación de las distribuciones de características condicionales de la clase significa que cada distribución puede ser estimada independientemente como una distribución unidimensional.Esto a su vez ayuda a aliviar los problemas derivados de la maldición de la dimensionalidad.</target>
        </trans-unit>
        <trans-unit id="bb7ceea48fd3728ed03cf0ba21b4839b323fc974" translate="yes" xml:space="preserve">
          <source>Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes&amp;rsquo; theorem with the &amp;ldquo;naive&amp;rdquo; assumption of conditional independence between every pair of features given the value of the class variable. Bayes&amp;rsquo; theorem states the following relationship, given class variable \(y\) and dependent feature vector \(x_1\) through \(x_n\), :</source>
          <target state="translated">Los m&amp;eacute;todos ingenuos de Bayes son un conjunto de algoritmos de aprendizaje supervisado basados ​​en la aplicaci&amp;oacute;n del teorema de Bayes con la suposici&amp;oacute;n &amp;ldquo;ingenua&amp;rdquo; de independencia condicional entre cada par de caracter&amp;iacute;sticas dado el valor de la variable de clase. El teorema de Bayes establece la siguiente relaci&amp;oacute;n, dada la variable de clase \ (y \) y el vector de caracter&amp;iacute;sticas dependientes \ (x_1 \) a \ (x_n \),:</target>
        </trans-unit>
        <trans-unit id="f65600325bc091b7b293639582ad70691e2ac960" translate="yes" xml:space="preserve">
          <source>Naive Bayes models can be used to tackle large scale classification problems for which the full training set might not fit in memory. To handle this case, &lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt;&lt;code&gt;MultinomialNB&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.naive_bayes.bernoullinb#sklearn.naive_bayes.BernoulliNB&quot;&gt;&lt;code&gt;BernoulliNB&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt;&lt;code&gt;GaussianNB&lt;/code&gt;&lt;/a&gt; expose a &lt;code&gt;partial_fit&lt;/code&gt; method that can be used incrementally as done with other classifiers as demonstrated in &lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;Out-of-core classification of text documents&lt;/a&gt;. All naive Bayes classifiers support sample weighting.</source>
          <target state="translated">Los modelos Naive Bayes se pueden utilizar para abordar problemas de clasificaci&amp;oacute;n a gran escala para los que el conjunto de entrenamiento completo podr&amp;iacute;a no caber en la memoria. Para manejar este caso, &lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt; &lt;code&gt;MultinomialNB&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.naive_bayes.bernoullinb#sklearn.naive_bayes.BernoulliNB&quot;&gt; &lt;code&gt;BernoulliNB&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt; &lt;code&gt;GaussianNB&lt;/code&gt; &lt;/a&gt; exponen un m&amp;eacute;todo de &lt;code&gt;partial_fit&lt;/code&gt; que se puede usar de forma incremental como se hace con otros clasificadores, como se demuestra en Clasificaci&amp;oacute;n &lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;fuera del n&amp;uacute;cleo de documentos de texto&lt;/a&gt; . Todos los clasificadores de Bayes ingenuos admiten la ponderaci&amp;oacute;n de muestras.</target>
        </trans-unit>
        <trans-unit id="f07ca99358e3e69c28471fb128e9c221473a78cf" translate="yes" xml:space="preserve">
          <source>Name for labeling curve. If &lt;code&gt;None&lt;/code&gt;, the name of the estimator is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44b4a8733a267298aba42ed906f0510d314435b0" translate="yes" xml:space="preserve">
          <source>Name of ROC Curve for labeling. If &lt;code&gt;None&lt;/code&gt;, use the name of the estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="048c56c2b44d92cd1c41343db29430d22afe211f" translate="yes" xml:space="preserve">
          <source>Name of columns containing this regex pattern will be included. If None, column selection will not be selected based on pattern.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f39a3bd9bee33098b86f18fcaf23fc1b1f211a0" translate="yes" xml:space="preserve">
          <source>Name of dataset</source>
          <target state="translated">Nombre del conjunto de datos</target>
        </trans-unit>
        <trans-unit id="325b56c17b8389991fec124de840a19f36bc1993" translate="yes" xml:space="preserve">
          <source>Name of each feature; feature_names[i] holds the name of the feature with index i.</source>
          <target state="translated">Nombre de cada característica;feature_names[i]contiene el nombre de la característica con el índice i.</target>
        </trans-unit>
        <trans-unit id="f379c68cd7abf28a38376a7f9401ab9de0d511e5" translate="yes" xml:space="preserve">
          <source>Name of each feature; feature_names[i] holds the name of the feature with index i. By default, the name of the feature corresponds to their numerical index for NumPy array and their column name for pandas dataframe.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ea3134d139c317d0bc4edf673307764ffe8b0cd" translate="yes" xml:space="preserve">
          <source>Name of estimator. If None, the estimator name is not shown.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8c1daded10cddfabf9a6fd7ee9e2ee679e1adbf" translate="yes" xml:space="preserve">
          <source>Name of estimator. If None, then the estimator name is not shown.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed7e838c9509fe0de6c00e0d7bd5bf221ec76bc1" translate="yes" xml:space="preserve">
          <source>Name of precision recall curve for labeling. If &lt;code&gt;None&lt;/code&gt;, use the name of the estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d63bfd9357f039d867c5652a85ab61996c87f94" translate="yes" xml:space="preserve">
          <source>Name of the data set on mldata.org, e.g.: &amp;ldquo;leukemia&amp;rdquo;, &amp;ldquo;Whistler Daily Snowfall&amp;rdquo;, etc. The raw name is automatically converted to a mldata.org URL .</source>
          <target state="translated">Nombre del conjunto de datos en mldata.org, por ejemplo: &quot;leucemia&quot;, &quot;Whistler Daily Snowfall&quot;, etc. El nombre sin formato se convierte autom&amp;aacute;ticamente en una URL de mldata.org.</target>
        </trans-unit>
        <trans-unit id="866f4401ef93cfed3b044fff6753dc1e913659b2" translate="yes" xml:space="preserve">
          <source>Name of the output activation function.</source>
          <target state="translated">Nombre de la función de activación de la salida.</target>
        </trans-unit>
        <trans-unit id="5a3a86d298c7e4314e724bb2623d8c6979ee2b6e" translate="yes" xml:space="preserve">
          <source>Name of the parameter that will be varied.</source>
          <target state="translated">Nombre del parámetro que será variado.</target>
        </trans-unit>
        <trans-unit id="d08ba4e92bc82e0b0eddb2db204950ac5386e156" translate="yes" xml:space="preserve">
          <source>Name of the sub-estimator that can be accessed as an attribute of the base object. If a list or a tuple of names are provided, the first sub-estimator that is an attribute of the base object will be used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ce3ec81584fa2d87df12f144e2480deecc5a975a" translate="yes" xml:space="preserve">
          <source>Name or index of the column containing the data.</source>
          <target state="translated">Nombre o índice de la columna que contiene los datos.</target>
        </trans-unit>
        <trans-unit id="0ae5e537b1c061ee0b3ccea7c63ace2088ca02dd" translate="yes" xml:space="preserve">
          <source>Name or index of the column containing the target values.</source>
          <target state="translated">Nombre o índice de la columna que contiene los valores objetivo.</target>
        </trans-unit>
        <trans-unit id="3170e49e906772d2e2d83c510613a736bad3f541" translate="yes" xml:space="preserve">
          <source>Named features not encountered during fit or fit_transform will be silently ignored.</source>
          <target state="translated">Las características nombradas no encontradas durante fit o fit_transform serán silenciosamente ignoradas.</target>
        </trans-unit>
        <trans-unit id="dd3283d9f71127c2e2cb8ea6f07a41ece4a049ce" translate="yes" xml:space="preserve">
          <source>Names of each of the features.</source>
          <target state="translated">Nombres de cada una de las características.</target>
        </trans-unit>
        <trans-unit id="99983f06243c41c70b7f7a98a21b26cf2a2ec6a9" translate="yes" xml:space="preserve">
          <source>Names of each of the target classes in ascending numerical order. Only relevant for classification and not supported for multi-output. If &lt;code&gt;True&lt;/code&gt;, shows a symbolic representation of the class name.</source>
          <target state="translated">Nombres de cada una de las clases objetivo en orden num&amp;eacute;rico ascendente. Solo es relevante para la clasificaci&amp;oacute;n y no es compatible con m&amp;uacute;ltiples salidas. Si es &lt;code&gt;True&lt;/code&gt; , muestra una representaci&amp;oacute;n simb&amp;oacute;lica del nombre de la clase.</target>
        </trans-unit>
        <trans-unit id="e9e6ba24a1711383d87f42cc11bb29b29e568b73" translate="yes" xml:space="preserve">
          <source>Names of each target (RCV1 topics), as ordered in dataset.target.</source>
          <target state="translated">Nombres de cada objetivo (temas de RCV1),como se ordena en dataset.target.</target>
        </trans-unit>
        <trans-unit id="5ee798b80fce1c26ac31847940e2cbb9594ee08b" translate="yes" xml:space="preserve">
          <source>Names of the features produced by transform.</source>
          <target state="translated">Nombres de los rasgos producidos por la transformación.</target>
        </trans-unit>
        <trans-unit id="8769733c023d80ccc969e39d7e721f7eef2c8e42" translate="yes" xml:space="preserve">
          <source>Native support for missing values for gradient boosting</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4aded465f8c4c45d7d7ec8d437901909b15f0b3f" translate="yes" xml:space="preserve">
          <source>Natural handling of data of mixed type (= heterogeneous features)</source>
          <target state="translated">Manejo natural de datos de tipo mixto (=características heterogéneas)</target>
        </trans-unit>
        <trans-unit id="0a4d2a1303aed1ff654767155d9269907f0d020c" translate="yes" xml:space="preserve">
          <source>Nearest Centroid Classification</source>
          <target state="translated">Clasificación del centroide más cercano</target>
        </trans-unit>
        <trans-unit id="bfa0969ff4ed25d459c6eac3badc5bf9f79ee3f4" translate="yes" xml:space="preserve">
          <source>Nearest Neighbors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa1459036257eab60db8e1afe6d9886bbc5e8a42" translate="yes" xml:space="preserve">
          <source>Nearest Neighbors Classification</source>
          <target state="translated">Clasificación de los vecinos más cercanos</target>
        </trans-unit>
        <trans-unit id="c7b70d3a90c9b413590f1c3fdfeae8dc16304398" translate="yes" xml:space="preserve">
          <source>Nearest Neighbors regression</source>
          <target state="translated">Regresión de los vecinos más cercanos</target>
        </trans-unit>
        <trans-unit id="cc8575a20e3e28eef4bfc70e48146f9994bd7318" translate="yes" xml:space="preserve">
          <source>Nearest centroid classifier.</source>
          <target state="translated">El clasificador centroide más cercano.</target>
        </trans-unit>
        <trans-unit id="8b02ae7bd0e5dc3ad9885f92e92e8dfc0759e655" translate="yes" xml:space="preserve">
          <source>Nearest neighbor and the curse of dimensionality</source>
          <target state="translated">El vecino más cercano y la maldición de la dimensionalidad</target>
        </trans-unit>
        <trans-unit id="5db95950f32dda99cc2cb722bb90ec8e1106f00f" translate="yes" xml:space="preserve">
          <source>Needless to say, the cross-validation involved in Platt scaling is an expensive operation for large datasets. In addition, the probability estimates may be inconsistent with the scores, in the sense that the &amp;ldquo;argmax&amp;rdquo; of the scores may not be the argmax of the probabilities. (E.g., in binary classification, a sample may be labeled by &lt;code&gt;predict&lt;/code&gt; as belonging to a class that has probability &amp;lt;&amp;frac12; according to &lt;code&gt;predict_proba&lt;/code&gt;.) Platt&amp;rsquo;s method is also known to have theoretical issues. If confidence scores are required, but these do not have to be probabilities, then it is advisable to set &lt;code&gt;probability=False&lt;/code&gt; and use &lt;code&gt;decision_function&lt;/code&gt; instead of &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">No hace falta decir que la validaci&amp;oacute;n cruzada involucrada en el escalado de Platt es una operaci&amp;oacute;n costosa para grandes conjuntos de datos. Adem&amp;aacute;s, las estimaciones de probabilidad pueden ser inconsistentes con los puntajes, en el sentido de que el &quot;argmax&quot; de los puntajes puede no ser el argmax de las probabilidades. (Por ejemplo, en la clasificaci&amp;oacute;n binaria, una muestra puede etiquetarse mediante &lt;code&gt;predict&lt;/code&gt; como perteneciente a una clase que tiene una probabilidad &amp;lt;&amp;frac12; seg&amp;uacute;n &lt;code&gt;predict_proba&lt;/code&gt; .) Tambi&amp;eacute;n se sabe que el m&amp;eacute;todo de Platt tiene problemas te&amp;oacute;ricos. Si se requieren puntuaciones de confianza, pero estas no tienen que ser probabilidades, entonces es aconsejable establecer &lt;code&gt;probability=False&lt;/code&gt; y usar &lt;code&gt;decision_function&lt;/code&gt; en lugar de &lt;code&gt;predict_proba&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5040421db1ecb4c2ff96e24808174eee959aab93" translate="yes" xml:space="preserve">
          <source>Neighborhood Component Analysis (NCA) is a machine learning algorithm for metric learning. It learns a linear transformation in a supervised fashion to improve the classification accuracy of a stochastic nearest neighbors rule in the transformed space.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e58fc95c9278805803f18a9db5fe3ea3f42040b6" translate="yes" xml:space="preserve">
          <source>Neighborhood Components Analysis</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba8f206becb6fe0a43da0c0c40642a7520c206e1" translate="yes" xml:space="preserve">
          <source>Neighborhood Components Analysis (NCA) tries to find a feature space such that a stochastic nearest neighbor algorithm will give the best accuracy. Like LDA, it is a supervised method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aee814d8b405edd4d076224daf37938472d0e4bb" translate="yes" xml:space="preserve">
          <source>Neighborhood Components Analysis (NCA, &lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt;&lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt;&lt;/a&gt;) is a distance metric learning algorithm which aims to improve the accuracy of nearest neighbors classification compared to the standard Euclidean distance. The algorithm directly maximizes a stochastic variant of the leave-one-out k-nearest neighbors (KNN) score on the training set. It can also learn a low-dimensional linear projection of data that can be used for data visualization and fast classification.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e267b3659f7643549165a2fa213a97174cdd61c0" translate="yes" xml:space="preserve">
          <source>Neighborhood Components Analysis Illustration</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d2390b5dea0fabfaec001753e4e7ab98989a540" translate="yes" xml:space="preserve">
          <source>Neighborhoods are restricted the points at a distance lower than radius.</source>
          <target state="translated">Los vecindarios tienen restringidos los puntos a una distancia inferior al radio.</target>
        </trans-unit>
        <trans-unit id="71b4c3c0886885b3bdb78dd9feb31a745b98d96e" translate="yes" xml:space="preserve">
          <source>Neighbors-based classification is a type of &lt;em&gt;instance-based learning&lt;/em&gt; or &lt;em&gt;non-generalizing learning&lt;/em&gt;: it does not attempt to construct a general internal model, but simply stores instances of the training data. Classification is computed from a simple majority vote of the nearest neighbors of each point: a query point is assigned the data class which has the most representatives within the nearest neighbors of the point.</source>
          <target state="translated">La clasificaci&amp;oacute;n basada en vecinos es un tipo de &lt;em&gt;aprendizaje basado en instancias&lt;/em&gt; o &lt;em&gt;aprendizaje &lt;/em&gt;&lt;em&gt;no generalizado&lt;/em&gt; : no intenta construir un modelo interno general, sino que simplemente almacena instancias de los datos de entrenamiento. La clasificaci&amp;oacute;n se calcula a partir de un voto mayoritario simple de los vecinos m&amp;aacute;s cercanos de cada punto: a un punto de consulta se le asigna la clase de datos que tiene m&amp;aacute;s representantes dentro de los vecinos m&amp;aacute;s cercanos del punto.</target>
        </trans-unit>
        <trans-unit id="f556f4d2d6fabe3a4b78772a04d1d08bf693d3a1" translate="yes" xml:space="preserve">
          <source>Neighbors-based regression can be used in cases where the data labels are continuous rather than discrete variables. The label assigned to a query point is computed based on the mean of the labels of its nearest neighbors.</source>
          <target state="translated">La regresión basada en los vecinos puede utilizarse en los casos en que las etiquetas de los datos son continuas en lugar de variables discretas.La etiqueta asignada a un punto de consulta se calcula en base a la media de las etiquetas de sus vecinos más cercanos.</target>
        </trans-unit>
        <trans-unit id="f17c48105fdd248ad2de1f1ac3f1cabb43429cec" translate="yes" xml:space="preserve">
          <source>Nested cross-validation</source>
          <target state="translated">Validación cruzada anidada</target>
        </trans-unit>
        <trans-unit id="029453980f1f56140cec84a6516b88cf4da43353" translate="yes" xml:space="preserve">
          <source>Nested versus non-nested cross-validation</source>
          <target state="translated">Validación cruzada anidada versus no anidada</target>
        </trans-unit>
        <trans-unit id="3991fd2dc72259103c5d9e42cbe59d2a7e448f31" translate="yes" xml:space="preserve">
          <source>Neural Networks</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c7edd0d2fdd43b38d35974fe3274794c4023842" translate="yes" xml:space="preserve">
          <source>Never unpickle untrusted data as it could lead to malicious code being executed upon loading.</source>
          <target state="translated">Nunca desentrañe los datos no confiables ya que podría llevar a que se ejecute un código malicioso al cargarlos.</target>
        </trans-unit>
        <trans-unit id="5a7c69a057920dae02f0ceb2f6458cca465cc67b" translate="yes" xml:space="preserve">
          <source>New data point to be inserted into the LSH Forest.</source>
          <target state="translated">Nuevo punto de datos que se insertará en el Bosque LSH.</target>
        </trans-unit>
        <trans-unit id="48ff6f532fccde3a69a322cc1151c107ad295ffd" translate="yes" xml:space="preserve">
          <source>New data to predict.</source>
          <target state="translated">Nuevos datos para predecir.</target>
        </trans-unit>
        <trans-unit id="b9599b4d9149cfd51951922f7155a3dc95944ff0" translate="yes" xml:space="preserve">
          <source>New data to predict. If a sparse matrix is provided, it will be converted into a sparse &lt;code&gt;csr_matrix&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e461db7b42b4e1d723a59598bcca510859163aef" translate="yes" xml:space="preserve">
          <source>New data to transform.</source>
          <target state="translated">Nuevos datos para transformar.</target>
        </trans-unit>
        <trans-unit id="329a026b697f0ae2b6fcf5ede884e3254ea37650" translate="yes" xml:space="preserve">
          <source>New data, where n_samples in the number of samples and n_features is the number of features.</source>
          <target state="translated">Nuevos datos,donde n_muestras en el número de muestras y n_características es el número de características.</target>
        </trans-unit>
        <trans-unit id="68d214f5c1780f5e1075a93cc2054064839f0ca3" translate="yes" xml:space="preserve">
          <source>New data, where n_samples in the number of samples and n_features is the number of features. All values of X must be strictly greater than &amp;ldquo;-skewedness&amp;rdquo;.</source>
          <target state="translated">Nuevos datos, donde n_samples en el n&amp;uacute;mero de muestras y n_features es el n&amp;uacute;mero de caracter&amp;iacute;sticas. Todos los valores de X deben ser estrictamente mayores que &quot;-skewedness&quot;.</target>
        </trans-unit>
        <trans-unit id="6e6bacb37aec6214dc7bc345656e9fc6be9d8645" translate="yes" xml:space="preserve">
          <source>New data, where n_samples is the number of samples and n_components is the number of components.</source>
          <target state="translated">Nuevos datos,donde n_muestras es el número de muestras y n_componentes es el número de componentes.</target>
        </trans-unit>
        <trans-unit id="ed0f15ab3ccef84bd24b03af80dd2d8f760b3551" translate="yes" xml:space="preserve">
          <source>New data, where n_samples is the number of samples and n_components is the number of pls components.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9774ac05294602db6164b128c08e5838d8dd2c30" translate="yes" xml:space="preserve">
          <source>New data, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">Nuevos datos,donde n_muestras es el número de muestras y n_características es el número de características.</target>
        </trans-unit>
        <trans-unit id="2cec1d1d13a623e2cead9e687223c0b43410804e" translate="yes" xml:space="preserve">
          <source>New data.</source>
          <target state="translated">Nuevos datos.</target>
        </trans-unit>
        <trans-unit id="2dcde8ec0560b6129ac7ceb94e6b76437cebda2e" translate="yes" xml:space="preserve">
          <source>New in version 0.10.</source>
          <target state="translated">Nuevo en la versión 0.10.</target>
        </trans-unit>
        <trans-unit id="d68d01022d3e4f6b4abc88815d154b4b27565257" translate="yes" xml:space="preserve">
          <source>New in version 0.12.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc28b70929f839a69ed3e45ea011105ea33d52a9" translate="yes" xml:space="preserve">
          <source>New in version 0.13.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52ebd0001be9ad2ddaeba3e98fe57c162ffbf813" translate="yes" xml:space="preserve">
          <source>New in version 0.14.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73af4998c8d20c7743147253e8c7d8a51d34634f" translate="yes" xml:space="preserve">
          <source>New in version 0.15.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="81c56a91b55dc7fbe4322466c0b6b3d2def29380" translate="yes" xml:space="preserve">
          <source>New in version 0.16.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2a489d3a2d4dc51668c693a83253f531fff88d5" translate="yes" xml:space="preserve">
          <source>New in version 0.16: If the input is sparse, the output will be a &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt;. Else, output type is the same as the input type.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.16: si la entrada es escasa, la salida ser&amp;aacute; un &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; . De lo contrario, el tipo de salida es el mismo que el tipo de entrada.</target>
        </trans-unit>
        <trans-unit id="60b69c65bf1a3241e15d0d894ba32eab25d7cdd7" translate="yes" xml:space="preserve">
          <source>New in version 0.17.</source>
          <target state="translated">Nuevo en la versión 0.17.</target>
        </trans-unit>
        <trans-unit id="21cf2264569599d5dcc312306fa70dfc0eda22f5" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;code&gt;random_state&lt;/code&gt; to support Stochastic Average Gradient.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc470080fe5f5c357c2ad73809b92faa7362d9a9" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;LinearDiscriminantAnalysis&lt;/em&gt;.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: &lt;em&gt;LinearDiscriminantAnalysis&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="abf887094b036a443ef8f8f3b6efb216ee34cd24" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;QuadraticDiscriminantAnalysis&lt;/em&gt;</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: &lt;em&gt;QuadraticDiscriminantAnalysis&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="6b2ff85ecc2a1a01962dd33b1e34753285ca0790" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;alpha&lt;/em&gt; used in the Coordinate Descent solver.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: &lt;em&gt;alpha&lt;/em&gt; usado en el solucionador de Descenso de coordenadas.</target>
        </trans-unit>
        <trans-unit id="6808fe2d57e6aeef92c976187ce0a06abf1ebec1" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;cd&lt;/em&gt; coordinate descent method to improve speed.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: m&amp;eacute;todo de descenso por coordenadas &lt;em&gt;cd&lt;/em&gt; para mejorar la velocidad.</target>
        </trans-unit>
        <trans-unit id="7b66bf990e4010a15f9d64925c054de502637170" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;class_weight=&amp;rsquo;balanced&amp;rsquo;&lt;/em&gt;</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: &lt;em&gt;class_weight = 'balanceado'&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="ea86dc59df4308dd8eeb6d9e2ae15359239ba528" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;data_max_&lt;/em&gt;</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: &lt;em&gt;data_max_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="1f6c1c10d870e8e7d70fedf31cf3a9ee8c7d746d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;data_min_&lt;/em&gt;</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: &lt;em&gt;data_min_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="e853c35f6d282db32a11152441252fd53da7f57f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;data_range_&lt;/em&gt;</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: &lt;em&gt;data_range_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="edb88b5a13c967ddfdc52fb30c87cf6cd8e55cef" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;decision_function_shape=&amp;rsquo;ovr&amp;rsquo;&lt;/em&gt; is recommended.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: se recomienda &lt;em&gt;decision_function_shape = 'ovr'&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="18bd409dbab688800dc645ecf6dc2d319b6dc274" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;lasso_cd&lt;/em&gt; coordinate descent method to improve speed.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: m&amp;eacute;todo de descenso de coordenadas &lt;em&gt;lasso_cd&lt;/em&gt; para mejorar la velocidad.</target>
        </trans-unit>
        <trans-unit id="5c5696058be6bc7e1f1d8d04441e99d3b67a5a9d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;minmax_scale&lt;/em&gt; function interface to &lt;a href=&quot;sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt;&lt;code&gt;sklearn.preprocessing.MinMaxScaler&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: &lt;em&gt;minmax_scale&lt;/em&gt; interfaz de la funci&amp;oacute;n de &lt;a href=&quot;sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt; &lt;code&gt;sklearn.preprocessing.MinMaxScaler&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="61491e91a5cc882c8d0472b81b77bf74b7ea4e3d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;presort&lt;/em&gt; parameter.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: par&amp;aacute;metro de &lt;em&gt;clasificaci&amp;oacute;n previa&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="b2b731bdc9bf8dfc47673f8abfcc6c2c7f1f838c" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;random_state&lt;/em&gt; to support Stochastic Average Gradient.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: &lt;em&gt;random_state&lt;/em&gt; para admitir el gradiente medio estoc&amp;aacute;stico.</target>
        </trans-unit>
        <trans-unit id="727acdfec60aa8d5fe01b0fab35aa36437da02bb" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;sample_weight&lt;/em&gt; support to Classifier.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: soporte &lt;em&gt;sample_weight&lt;/em&gt; para Classifier.</target>
        </trans-unit>
        <trans-unit id="6a9e702e6dde8c5e083d3061949d66f0c1cd0a95" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;sample_weight&lt;/em&gt; support to LogisticRegression.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: soporte &lt;em&gt;sample_weight&lt;/em&gt; para LogisticRegression.</target>
        </trans-unit>
        <trans-unit id="8bf7c72c906a46e4bafab411161accafb9f3258f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;scale_&lt;/em&gt;</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: &lt;em&gt;scale_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="26b994b5337cbc66d9e87cecbe064dc645c2d9c5" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;scale_&lt;/em&gt; attribute.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: atributo &lt;em&gt;scale_&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="acaea6c314c50f12e63f6a31caa95dae9a93cb16" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;shuffle&lt;/em&gt; parameter used in the Coordinate Descent solver.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: par&amp;aacute;metro &lt;em&gt;aleatorio&lt;/em&gt; usado en el solucionador de Descenso de coordenadas.</target>
        </trans-unit>
        <trans-unit id="3c9ad8ece37a0ad66c0695ab197f051fc5c4f74b" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;warm_start&lt;/em&gt; constructor parameter.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: par&amp;aacute;metro de constructor &lt;em&gt;warm_start&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="5d7ee9d78ae5139184086665f72ad9adc489e60f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;warm_start&lt;/em&gt; to support &lt;em&gt;lbfgs&lt;/em&gt;, &lt;em&gt;newton-cg&lt;/em&gt;, &lt;em&gt;sag&lt;/em&gt;, &lt;em&gt;saga&lt;/em&gt; solvers.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: &lt;em&gt;warm_start&lt;/em&gt; para soportar &lt;em&gt;lbfgs&lt;/em&gt; , &lt;em&gt;newton-cg&lt;/em&gt; , &lt;em&gt;sag&lt;/em&gt; , &lt;em&gt;saga&lt;/em&gt; solvers.</target>
        </trans-unit>
        <trans-unit id="6005792b774eeae7e9401b712800c9c602a22ebe" translate="yes" xml:space="preserve">
          <source>New in version 0.17: A function &lt;em&gt;label_ranking_loss&lt;/em&gt;</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: una funci&amp;oacute;n &lt;em&gt;label_ranking_loss&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="e93da6946e01b1e23cbc1e7009a23425c993a384" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Approximate optimization &lt;em&gt;method&lt;/em&gt; via the Barnes-Hut.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: &lt;em&gt;M&amp;eacute;todo de&lt;/em&gt; optimizaci&amp;oacute;n aproximado a trav&amp;eacute;s de Barnes-Hut.</target>
        </trans-unit>
        <trans-unit id="9365f66e13f87cb3bbf8aaf0ec5863c643029aff" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Coordinate Descent solver.</source>
          <target state="translated">Nuevo en la versión 0.17:Solucionador de Descenso de Coordenadas.</target>
        </trans-unit>
        <trans-unit id="c589f3a156d1562e5e258c1483b29eaa7a3bb671" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Dummy Classifier now supports prior fitting strategy using parameter &lt;em&gt;prior&lt;/em&gt;.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: Dummy Classifier ahora es compatible con la estrategia de ajuste anterior utilizando el par&amp;aacute;metro &lt;em&gt;anterior&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="4c1ba1a9df4e3f1eda2057a3d8675352ba0c6105" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Gaussian Naive Bayes supports fitting with &lt;em&gt;sample_weight&lt;/em&gt;.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: Gaussian Naive Bayes admite el ajuste con &lt;em&gt;sample_weight&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="b94e1008bb6bd8880b48f9c93c89015eb39cf414" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Parallel Execution using &lt;em&gt;n_jobs&lt;/em&gt;.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: Ejecuci&amp;oacute;n en paralelo usando &lt;em&gt;n_jobs&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="56295350a01a04673ce10a1274f3f2850857660f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Regularization parameter &lt;em&gt;l1_ratio&lt;/em&gt; used in the Coordinate Descent solver.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: par&amp;aacute;metro de regularizaci&amp;oacute;n &lt;em&gt;l1_ratio&lt;/em&gt; usado en el solucionador de Descenso de coordenadas.</target>
        </trans-unit>
        <trans-unit id="bfb15daea388e7bc4652a64e3ee368ec3ef32e45" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Stochastic Average Gradient descent solver.</source>
          <target state="translated">Nuevo en la versión 0.17:Solucionador de descenso de gradiente medio estocástico.</target>
        </trans-unit>
        <trans-unit id="90ee93ad6b0e53eed26b86779c90b9633cb9848b" translate="yes" xml:space="preserve">
          <source>New in version 0.17: class_weight == &amp;lsquo;balanced&amp;rsquo;</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: class_weight == 'balanceado'</target>
        </trans-unit>
        <trans-unit id="db422a34a0885d2d1033db36affb13affc0d2065" translate="yes" xml:space="preserve">
          <source>New in version 0.17: metric &lt;em&gt;precomputed&lt;/em&gt; to accept precomputed sparse matrix.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: m&amp;eacute;trica &lt;em&gt;precalculada&lt;/em&gt; para aceptar una matriz dispersa precalculada.</target>
        </trans-unit>
        <trans-unit id="545f1d599ea32d73544f4951073f7ce5e1f64bf6" translate="yes" xml:space="preserve">
          <source>New in version 0.17: optional parameter &lt;em&gt;presort&lt;/em&gt;.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: &lt;em&gt;preordenar&lt;/em&gt; par&amp;aacute;metro opcional .</target>
        </trans-unit>
        <trans-unit id="1c0b7964a491c4c8234983325c356450f442446c" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;code&gt;dense_output&lt;/code&gt; for dense output.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: par&amp;aacute;metro &lt;code&gt;dense_output&lt;/code&gt; para salida densa.</target>
        </trans-unit>
        <trans-unit id="46c6419997a8eb39c61c2c50456a363282489838" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;class_weight&lt;/em&gt; to automatically weight samples.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: par&amp;aacute;metro &lt;em&gt;class_weight&lt;/em&gt; para &lt;em&gt;ponderar&lt;/em&gt; autom&amp;aacute;ticamente las muestras.</target>
        </trans-unit>
        <trans-unit id="e8cbf38ab0cedfa95f7fc33391f9602285bd6e17" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;drop_intermediate&lt;/em&gt;.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: par&amp;aacute;metro &lt;em&gt;drop_intermediate&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="960c43bc8538ca35574a01cc68a5f2b510105d22" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;multilabel&lt;/em&gt; to support multilabel datasets.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: par&amp;aacute;metro &lt;em&gt;multilabel&lt;/em&gt; para admitir conjuntos de datos de m&amp;uacute;ltiples etiquetas.</target>
        </trans-unit>
        <trans-unit id="3788b38f2b10aab217952de3365bf7b88f170f8d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;n_iter_without_progress&lt;/em&gt; to control stopping criteria.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: par&amp;aacute;metro &lt;em&gt;n_iter_without_progress&lt;/em&gt; para controlar los criterios de parada.</target>
        </trans-unit>
        <trans-unit id="8db0c53c524e84f302dbc1a0dbd534321460f08f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;sample_weight&lt;/em&gt; support to LinearRegression.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: par&amp;aacute;metro &lt;em&gt;sample_weight&lt;/em&gt; compatible con LinearRegression.</target>
        </trans-unit>
        <trans-unit id="2a05312b3a418ca739af1c2a1750981f3df80101" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter to allow &lt;em&gt;sparse&lt;/em&gt; output.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.17: par&amp;aacute;metro para permitir salida &lt;em&gt;escasa&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="8550f8dcfdefc5ee2595ff5a932287ae10047927" translate="yes" xml:space="preserve">
          <source>New in version 0.18.</source>
          <target state="translated">Nuevo en la versión 0.18.</target>
        </trans-unit>
        <trans-unit id="bc1978fea309e92ee1923ea481a6fd1eab915379" translate="yes" xml:space="preserve">
          <source>New in version 0.18.0.</source>
          <target state="translated">Nuevo en la versión 0.18.0.</target>
        </trans-unit>
        <trans-unit id="f6899efa546ca366fb803a6a6fcb7b4b47706e4f" translate="yes" xml:space="preserve">
          <source>New in version 0.18: ..</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11462cefb53316ba0a8e0880815bfa04af36466b" translate="yes" xml:space="preserve">
          <source>New in version 0.18: Mean Absolute Error (MAE) criterion.</source>
          <target state="translated">Nuevo en la versión 0.18:el criterio del Error Medio Absoluto (MAE).</target>
        </trans-unit>
        <trans-unit id="f3588d83291a2be20994392c7201429910c5a8e9" translate="yes" xml:space="preserve">
          <source>New in version 0.18: Stochastic Average Gradient descent solver for &amp;lsquo;multinomial&amp;rsquo; case.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.18: solucionador de descenso de gradiente medio estoc&amp;aacute;stico para el caso 'multinomial'.</target>
        </trans-unit>
        <trans-unit id="0eb4d3b4907b28878c6666a16cc5abd9e36f4f00" translate="yes" xml:space="preserve">
          <source>New in version 0.19.</source>
          <target state="translated">Nuevo en la versión 0.19.</target>
        </trans-unit>
        <trans-unit id="e10489dae5e0fb6aa174b77a26bd312889388c1d" translate="yes" xml:space="preserve">
          <source>New in version 0.19: Multiplicative Update solver.</source>
          <target state="translated">Nuevo en la versión 0.19:Solucionador de actualizaciones multiplicativas.</target>
        </trans-unit>
        <trans-unit id="c260a9e7caaac82377fee1bfeace2cf2272b4b1a" translate="yes" xml:space="preserve">
          <source>New in version 0.19: SAGA solver.</source>
          <target state="translated">Nuevo en la versión 0.19:SAGA solver.</target>
        </trans-unit>
        <trans-unit id="d56c2d84411d9a6c91bdf6681efc0b4e653d1de5" translate="yes" xml:space="preserve">
          <source>New in version 0.19: l1 penalty with SAGA solver (allowing &amp;lsquo;multinomial&amp;rsquo; + L1)</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.19: penalizaci&amp;oacute;n l1 con solucionador SAGA (permitiendo 'multinomial' + L1)</target>
        </trans-unit>
        <trans-unit id="69d687c70a1657bfe591a19056b06b9f07dd4b5e" translate="yes" xml:space="preserve">
          <source>New in version 0.19: parameter &lt;em&gt;average&lt;/em&gt; to use weights averaging in SGD</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.19: &lt;em&gt;promedio de&lt;/em&gt; par&amp;aacute;metros para usar promedios de pesos en SGD</target>
        </trans-unit>
        <trans-unit id="e6570e8764c255a027de40e9e3eb2d1c722d495c" translate="yes" xml:space="preserve">
          <source>New in version 0.20.</source>
          <target state="translated">Nuevo en la versión 0.20.</target>
        </trans-unit>
        <trans-unit id="6c617d40b81d2b01909932fc5a27e561e533ba93" translate="yes" xml:space="preserve">
          <source>New in version 0.20: &lt;code&gt;SimpleImputer&lt;/code&gt; replaces the previous &lt;code&gt;sklearn.preprocessing.Imputer&lt;/code&gt; estimator which is now removed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92da9b59ee8f1aee40e76bd7e7f9a69e15158836" translate="yes" xml:space="preserve">
          <source>New in version 0.20: &lt;code&gt;behaviour&lt;/code&gt; is added in 0.20 for back-compatibility purpose.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.20: el &lt;code&gt;behaviour&lt;/code&gt; se agrega en 0.20 para fines de compatibilidad con versiones anteriores.</target>
        </trans-unit>
        <trans-unit id="89ff3bd96af64e1a70d0744f65ccf966040b095d" translate="yes" xml:space="preserve">
          <source>New in version 0.20: &lt;code&gt;force_all_finite&lt;/code&gt; accepts the string &lt;code&gt;'allow-nan'&lt;/code&gt;.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.20: &lt;code&gt;force_all_finite&lt;/code&gt; acepta la cadena &lt;code&gt;'allow-nan'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="fe256f44bbbbc2bd0c867a8e63ec681a6240ed59" translate="yes" xml:space="preserve">
          <source>New in version 0.20: Added &amp;lsquo;adaptive&amp;rsquo; option</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c29982d75481689af02d31b620cd5f76c827f04a" translate="yes" xml:space="preserve">
          <source>New in version 0.20: Added &amp;lsquo;early_stopping&amp;rsquo; option</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="383b2bc5e9967f26e0b4b20cd947fb1316e6616a" translate="yes" xml:space="preserve">
          <source>New in version 0.20: Added &amp;lsquo;n_iter_no_change&amp;rsquo; option</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5896f9ff4dd021dab607afd66ed0a221195a00c5" translate="yes" xml:space="preserve">
          <source>New in version 0.20: Added &amp;lsquo;validation_fraction&amp;rsquo; option</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="646e72bed85791f997c7991fa5af303d05883478" translate="yes" xml:space="preserve">
          <source>New in version 0.20: Added the &amp;lsquo;single&amp;rsquo; option</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1468919e56b56c4ded7ab6dba66d158a1002d5be" translate="yes" xml:space="preserve">
          <source>New in version 0.20: parameter &lt;em&gt;sample_weight&lt;/em&gt; support to BayesianRidge.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.20: par&amp;aacute;metro &lt;em&gt;sample_weight&lt;/em&gt; compatible con BayesianRidge.</target>
        </trans-unit>
        <trans-unit id="7c256855a0d81868bca650e3f1d5676a1f0ae5da" translate="yes" xml:space="preserve">
          <source>New in version 0.20: strategy=&amp;rdquo;constant&amp;rdquo; for fixed value imputation.</source>
          <target state="translated">Nuevo en la versi&amp;oacute;n 0.20: estrategia = &amp;rdquo;constante&amp;rdquo; para imputaci&amp;oacute;n de valor fijo.</target>
        </trans-unit>
        <trans-unit id="6371a324a0f9b28d52fcce7a713bd8acc7b321e0" translate="yes" xml:space="preserve">
          <source>New in version 0.21.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28bbafe212871917c1ae23be319d534da486ed2c" translate="yes" xml:space="preserve">
          <source>New in version 0.21: &lt;code&gt;n_connected_components_&lt;/code&gt; was added to replace &lt;code&gt;n_components_&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be8b989c4868c5bd7f2040240742c5509b13b840" translate="yes" xml:space="preserve">
          <source>New in version 0.22.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69cdaee84ba92c12f0c1ee7d5ea78cec5fb3129d" translate="yes" xml:space="preserve">
          <source>New in version 0.22: &lt;code&gt;force_all_finite&lt;/code&gt; accepts the string &lt;code&gt;'allow-nan'&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1fed47321851e7513d73e52b53e589471c95ed14" translate="yes" xml:space="preserve">
          <source>New in version 0.23.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3131ca254bc6ccc53b97a121b7c7087eb729d9ad" translate="yes" xml:space="preserve">
          <source>New in version 0.23: this parameter was previously hardcoded as 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c41c95cafce09fc00bdb02d31fa4b185ade21eb" translate="yes" xml:space="preserve">
          <source>New in version 0.5.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48e2833e629833b7582fc86a591171cccb4a2aa1" translate="yes" xml:space="preserve">
          <source>New in version 0.8.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0798e2f31cc8f6f05534a395874ff516c037ea2" translate="yes" xml:space="preserve">
          <source>New in version 0.9.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3dcb523c8b35ef7bba188a1b72a37583d73585c0" translate="yes" xml:space="preserve">
          <source>New in version 1.7.0.</source>
          <target state="translated">Nuevo en la versión 1.7.0.</target>
        </trans-unit>
        <trans-unit id="382bf23b05f69ca7724427a219843811ca7f86bf" translate="yes" xml:space="preserve">
          <source>New plotting API</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58fbaea601eebe84b9d8f8508a33c9a4b3025541" translate="yes" xml:space="preserve">
          <source>New to Scientific Python?</source>
          <target state="translated">¿Nuevo en la Pitón Científica?</target>
        </trans-unit>
        <trans-unit id="9f6a58e9ea6f2ce3d4a15836e22f7c6b8aed6e50" translate="yes" xml:space="preserve">
          <source>Next we create 10 classifier chains. Each classifier chain contains a logistic regression model for each of the 14 labels. The models in each chain are ordered randomly. In addition to the 103 features in the dataset, each model gets the predictions of the preceding models in the chain as features (note that by default at training time each model gets the true labels as features). These additional features allow each chain to exploit correlations among the classes. The Jaccard similarity score for each chain tends to be greater than that of the set independent logistic models.</source>
          <target state="translated">A continuación creamos 10 cadenas clasificadoras.Cada cadena clasificadora contiene un modelo de regresión logística para cada una de las 14 etiquetas.Los modelos de cada cadena están ordenados al azar.Además de las 103 características del conjunto de datos,cada modelo obtiene las predicciones de los modelos precedentes de la cadena como características (nótese que por defecto en el momento de la formación cada modelo obtiene las etiquetas verdaderas como características).Estas características adicionales permiten a cada cadena explotar las correlaciones entre las clases.El puntaje de similitud de Jaccard para cada cadena tiende a ser mayor que el de los modelos logísticos independientes del conjunto.</target>
        </trans-unit>
        <trans-unit id="d753c88a8af3a7221324f1f115e965ef2e7003fc" translate="yes" xml:space="preserve">
          <source>Next we fit the Poisson regressor on the target variable. We set the regularization strength &lt;code&gt;alpha&lt;/code&gt; to approximately 1e-6 over number of samples (i.e. &lt;code&gt;1e-12&lt;/code&gt;) in order to mimic the Ridge regressor whose L2 penalty term scales differently with the number of samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ae340c010af24c68842322aa72c1a3f11d7dacf" translate="yes" xml:space="preserve">
          <source>Next, let&amp;rsquo;s compare the accuracy of &lt;code&gt;SVC&lt;/code&gt; and &lt;code&gt;most_frequent&lt;/code&gt;:</source>
          <target state="translated">A continuaci&amp;oacute;n, comparemos la precisi&amp;oacute;n de &lt;code&gt;SVC&lt;/code&gt; y &lt;code&gt;most_frequent&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="c6c64a04d2e12fed93b98d6c01ec2531f747d55c" translate="yes" xml:space="preserve">
          <source>Next, we manually pick a threshold by visual inspection of the dendrogram to group our features into clusters and choose a feature from each cluster to keep, select those features from our dataset, and train a new random forest. The test accuracy of the new random forest did not change much compared to the random forest trained on the complete dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60abf98c19bebf728f6b765cf9ba6a0bbf19fa43" translate="yes" xml:space="preserve">
          <source>Next, we plot the ROC curve with a single call to &lt;a href=&quot;../../modules/generated/sklearn.metrics.plot_roc_curve#sklearn.metrics.plot_roc_curve&quot;&gt;&lt;code&gt;sklearn.metrics.plot_roc_curve&lt;/code&gt;&lt;/a&gt;. The returned &lt;code&gt;svc_disp&lt;/code&gt; object allows us to continue using the already computed ROC curve for the SVC in future plots.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e2a2edce50f17d924871b306d2618d9b3454954" translate="yes" xml:space="preserve">
          <source>Next, we plot the tree based feature importance and the permutation importance. The permutation importance plot shows that permuting a feature drops the accuracy by at most &lt;code&gt;0.012&lt;/code&gt;, which would suggest that none of the features are important. This is in contradiction with the high test accuracy computed above: some feature must be important. The permutation importance is calculated on the training set to show how much the model relies on each feature during training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4301caa6a55515044571ecdaaa2f60c152ef3c59" translate="yes" xml:space="preserve">
          <source>Next, we train a decision tree using the effective alphas. The last value in &lt;code&gt;ccp_alphas&lt;/code&gt; is the alpha value that prunes the whole tree, leaving the tree, &lt;code&gt;clfs[-1]&lt;/code&gt;, with one node.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="19146388ab896a5ab7b0d5fd5a0ecbdbda416e05" translate="yes" xml:space="preserve">
          <source>Next, we will split our dataset to use 90% for training and leave the rest for testing. We will also set the regression model parameters. You can play with these parameters to see how the results change.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cedfa60674e3afd543975ecc551b601711fc3043" translate="yes" xml:space="preserve">
          <source>Nick Street</source>
          <target state="translated">Nick Street</target>
        </trans-unit>
        <trans-unit id="91b4478e43e149a2b1b071a76d13f7593530f726" translate="yes" xml:space="preserve">
          <source>No measurement errors, only modelling errors (fitting a sine with a polynomial)</source>
          <target state="translated">No hay errores de medición,sólo errores de modelización (ajuste de un seno con un polinomio)</target>
        </trans-unit>
        <trans-unit id="53e801c8ef7a5f95a28c0516586238c464a24031" translate="yes" xml:space="preserve">
          <source>No penalty (&amp;lsquo;none&amp;rsquo;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea249cedbd757dbfa8a8d6da523734c90b706a5c" translate="yes" xml:space="preserve">
          <source>No-op.</source>
          <target state="translated">No-op.</target>
        </trans-unit>
        <trans-unit id="91eb5693ecb00a7deb087fb78e26bb4414167d8c" translate="yes" xml:space="preserve">
          <source>Noisy (non informative) features are added to the iris data and univariate feature selection is applied. For each feature, we plot the p-values for the univariate feature selection and the corresponding weights of an SVM. We can see that univariate feature selection selects the informative features and that these have larger SVM weights.</source>
          <target state="translated">Se añaden características ruidosas (no informativas)a los datos del iris y se aplica una selección univariante de características.Para cada rasgo,se trazan los valores p de la selección univariante de rasgos y los correspondientes pesos de un SVM.Podemos ver que la selección univariante de rasgos selecciona los rasgos informativos y que éstos tienen mayores pesos de SVM.</target>
        </trans-unit>
        <trans-unit id="7bfbed76958c0127f9523f9a22b3af54ca060586" translate="yes" xml:space="preserve">
          <source>Non metric &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; focuses on the ordination of the data. If \(S_{ij} &amp;lt; S_{jk}\), then the embedding should enforce \(d_{ij} &amp;lt; d_{jk}\). A simple algorithm to enforce that is to use a monotonic regression of \(d_{ij}\) on \(S_{ij}\), yielding disparities \(\hat{d}_{ij}\) in the same order as \(S_{ij}\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79474361fd46a8f4ede8053ea7e6b01fe3e41cb6" translate="yes" xml:space="preserve">
          <source>Non metric &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; focuses on the ordination of the data. If \(S_{ij} &amp;lt; S_{kl}\), then the embedding should enforce \(d_{ij} &amp;lt; d_{jk}\). A simple algorithm to enforce that is to use a monotonic regression of \(d_{ij}\) on \(S_{ij}\), yielding disparities \(\hat{d}_{ij}\) in the same order as \(S_{ij}\).</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt; &lt;code&gt;MDS&lt;/code&gt; &lt;/a&gt; no m&amp;eacute;trico se centra en la ordenaci&amp;oacute;n de los datos. Si \ (S_ {ij} &amp;lt;S_ {kl} \), entonces la incrustaci&amp;oacute;n deber&amp;iacute;a hacer cumplir \ (d_ {ij} &amp;lt;d_ {jk} \). Un algoritmo simple para hacer cumplir es usar una regresi&amp;oacute;n mon&amp;oacute;tona de \ (d_ {ij} \) en \ (S_ {ij} \), produciendo disparidades \ (\ hat {d} _ {ij} \) en el mismo orden como \ (S_ {ij} \).</target>
        </trans-unit>
        <trans-unit id="cde06657a13db59e2826469e9066556199cf0756" translate="yes" xml:space="preserve">
          <source>Non-Negative Matrix Factorization (NMF)</source>
          <target state="translated">Factorización de Matriz No Negativa (NMF)</target>
        </trans-unit>
        <trans-unit id="68976e33a3c8d43b10cc9525f441a8468ba55fa6" translate="yes" xml:space="preserve">
          <source>Non-adjusted measures such as the V-Measure show a dependency between the number of clusters and the number of samples: the mean V-Measure of random labeling increases significantly as the number of clusters is closer to the total number of samples used to compute the measure.</source>
          <target state="translated">Las medidas no ajustadas como la V-Measure muestran una dependencia entre el número de conglomerados y el número de muestras:la media de la V-Measure del etiquetado aleatorio aumenta significativamente a medida que el número de conglomerados se acerca al número total de muestras utilizadas para calcular la medida.</target>
        </trans-unit>
        <trans-unit id="f88076515287321d1c6a383215ea60241a35e283" translate="yes" xml:space="preserve">
          <source>Non-categorical features are always stacked to the right of the matrix.</source>
          <target state="translated">Los rasgos no categóricos siempre se apilan a la derecha de la matriz.</target>
        </trans-unit>
        <trans-unit id="24a06b494b2c3f21a83a9f0f9fdd0eb49c7e8dca" translate="yes" xml:space="preserve">
          <source>Non-deterministic iterable over random candidate combinations for hyper- parameter search. If all parameters are presented as a list, sampling without replacement is performed. If at least one parameter is given as a distribution, sampling with replacement is used. It is highly recommended to use continuous distributions for continuous parameters.</source>
          <target state="translated">No determinable iterable sobre combinaciones candidatas aleatorias para la búsqueda de hiper parámetros.Si todos los parámetros se presentan en forma de lista,se realiza un muestreo sin reemplazo.Si al menos un parámetro se presenta como una distribución,se utiliza el muestreo con reemplazo.Se recomienda encarecidamente utilizar distribuciones continuas para los parámetros continuos.</target>
        </trans-unit>
        <trans-unit id="aed22ef611faa3f82d0b12f8491e5be1b5315c9c" translate="yes" xml:space="preserve">
          <source>Non-flat geometry clustering is useful when the clusters have a specific shape, i.e. a non-flat manifold, and the standard euclidean distance is not the right metric. This case arises in the two top rows of the figure above.</source>
          <target state="translated">La agrupación de geometría no plana es útil cuando los cúmulos tienen una forma específica,es decir,un múltiple no plano,y la distancia euclidiana estándar no es la métrica correcta.Este caso surge en las dos filas superiores de la figura anterior.</target>
        </trans-unit>
        <trans-unit id="d81a98cb7a8247dec56f2cf029b08c2754ab68be" translate="yes" xml:space="preserve">
          <source>Non-flat geometry, uneven cluster sizes</source>
          <target state="translated">Geometría no plana,tamaños desiguales de los cúmulos</target>
        </trans-unit>
        <trans-unit id="e75d67cb225b885154dd48c75a213bc3e9636016" translate="yes" xml:space="preserve">
          <source>Non-flat geometry, uneven cluster sizes, variable cluster density</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b7727887cb8285fcb9cde529e76207a2b5daf47" translate="yes" xml:space="preserve">
          <source>Non-linear SVM</source>
          <target state="translated">SVM no lineal</target>
        </trans-unit>
        <trans-unit id="71ce2ef9edaad67f892b761574c731b5860fa36a" translate="yes" xml:space="preserve">
          <source>Non-linear dimensionality reduction through Isometric Mapping</source>
          <target state="translated">Reducción de la dimensionalidad no lineal a través de la cartografía isométrica</target>
        </trans-unit>
        <trans-unit id="ca7d812e2ac6b7f89b19c50d5270fc422c0be019" translate="yes" xml:space="preserve">
          <source>Non-linear dimensionality reduction through the use of kernels (see &lt;a href=&quot;../metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt;).</source>
          <target state="translated">Reducci&amp;oacute;n de dimensionalidad no lineal mediante el uso de kernels (consulte &lt;a href=&quot;../metrics#metrics&quot;&gt;M&amp;eacute;tricas por pares, Afinidades y Kernels&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="69451865a7cd1607229864b3445a0d944d36c962" translate="yes" xml:space="preserve">
          <source>Non-negative Matrix Factorization is applied with two different objective functions: the Frobenius norm, and the generalized Kullback-Leibler divergence. The latter is equivalent to Probabilistic Latent Semantic Indexing.</source>
          <target state="translated">La Factorización de Matriz No Negativa se aplica con dos funciones objetivas diferentes:la norma Frobenius y la divergencia generalizada Kullback-Leibler.Esta última equivale a la Indización Semántica Latente Probabilística.</target>
        </trans-unit>
        <trans-unit id="049d9a61285421f1af788bdccc4c4d917a5eaaf1" translate="yes" xml:space="preserve">
          <source>Non-negative regularization added to the diagonal of covariance. Allows to assure that the covariance matrices are all positive.</source>
          <target state="translated">Regularización no negativa añadida a la diagonal de la covarianza.Permite asegurar que las matrices de covarianza son todas positivas.</target>
        </trans-unit>
        <trans-unit id="e703a00863d9d81a02bf7dd7a3e8359867bf5db3" translate="yes" xml:space="preserve">
          <source>Non-negativity: d(x, y) &amp;gt;= 0</source>
          <target state="translated">No negatividad: d (x, y)&amp;gt; = 0</target>
        </trans-unit>
        <trans-unit id="8ae68d0948137da9bc3c21e9e27af7e4326ecb8c" translate="yes" xml:space="preserve">
          <source>Non-perfect labelings that assign all classes members to the same clusters are still complete:</source>
          <target state="translated">Las etiquetas no perfectas que asignan a todos los miembros de las clases a los mismos grupos aún están completas:</target>
        </trans-unit>
        <trans-unit id="3eebc1d955c5491410d251396ee4489d9155e3cb" translate="yes" xml:space="preserve">
          <source>Non-perfect labelings that further split classes into more clusters can be perfectly homogeneous:</source>
          <target state="translated">Las etiquetas no perfectas que dividen aún más las clases en más grupos pueden ser perfectamente homogéneas:</target>
        </trans-unit>
        <trans-unit id="6eef6648406c333a4035cd5e60d0bf2ecf2606d7" translate="yes" xml:space="preserve">
          <source>None</source>
          <target state="translated">None</target>
        </trans-unit>
        <trans-unit id="cc144a8b86207cd903656d8b31d75d721fe9dfb7" translate="yes" xml:space="preserve">
          <source>None : retain all features (the default).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff2ddb49167696f5a698e9f0e7cdd839b8eb8d6f" translate="yes" xml:space="preserve">
          <source>None : when any outlier is detected, ValueError will be raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7d85d18152a49d1da74509ce25fde6fe11019f7" translate="yes" xml:space="preserve">
          <source>None, in which case all the jobs are immediately created and spawned. Use this for lightweight and fast-running jobs, to avoid delays due to on-demand spawning of the jobs</source>
          <target state="translated">Ninguno,en cuyo caso todos los trabajos se crean y se generan inmediatamente.Utilícelo para trabajos ligeros y rápidos,para evitar retrasos debido a la creación de trabajos a demanda.</target>
        </trans-unit>
        <trans-unit id="bbd7e8e517d8f43bda3aa20760641b5d7e8f9cfa" translate="yes" xml:space="preserve">
          <source>None, to use the default 3-fold cross validation,</source>
          <target state="translated">Ninguno,para usar la validación cruzada triple por defecto,</target>
        </trans-unit>
        <trans-unit id="888271bd46afcca7669b4e3985d515e3c7e7f9d8" translate="yes" xml:space="preserve">
          <source>None, to use the default 3-fold cross-validation,</source>
          <target state="translated">Ninguno,para usar la validación cruzada triple por defecto,</target>
        </trans-unit>
        <trans-unit id="13182ccf32b1d9cf4c4c76a99a35a2cf619a1e90" translate="yes" xml:space="preserve">
          <source>None, to use the default 5-fold cross validation,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93be41b6686f4cc42a91be2da8610759134def66" translate="yes" xml:space="preserve">
          <source>None, to use the default 5-fold cross-validation,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="701ee91f692f57554848e1c6f0edff54e4f7d839" translate="yes" xml:space="preserve">
          <source>None, to use the efficient Leave-One-Out cross-validation</source>
          <target state="translated">Ninguno,para usar la eficiente validación cruzada de Leave-One-Out</target>
        </trans-unit>
        <trans-unit id="d7a547edfb07309939d3c23d0b3c605eac4c310a" translate="yes" xml:space="preserve">
          <source>None, to use the efficient Leave-One-Out cross-validation (also known as Generalized Cross-Validation).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb8094c10799533f02930dac24b80933c23d4beb" translate="yes" xml:space="preserve">
          <source>None: &amp;lsquo;nndsvd&amp;rsquo; if n_components &amp;lt; n_features, otherwise &amp;lsquo;random&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac08cb5e83064548a9a5dbf3f70202653e682537" translate="yes" xml:space="preserve">
          <source>None: &amp;lsquo;nndsvd&amp;rsquo; if n_components &amp;lt;= min(n_samples, n_features),</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64b167835d86e0f7a116b1ea8c9009b09567d9bf" translate="yes" xml:space="preserve">
          <source>None: no shrinkage (default).</source>
          <target state="translated">Ninguno:no hay encogimiento (por defecto).</target>
        </trans-unit>
        <trans-unit id="147e773e8ccd784cf7c8200779acc5978ecfc7ee" translate="yes" xml:space="preserve">
          <source>Nonflavanoid Phenols:</source>
          <target state="translated">Fenoles no flavonoides:</target>
        </trans-unit>
        <trans-unit id="906dd4b97159051d3691e718b04ffdc7a18ebb83" translate="yes" xml:space="preserve">
          <source>Nonflavanoid phenols</source>
          <target state="translated">Fenoles no flavonoides</target>
        </trans-unit>
        <trans-unit id="c5cf58c1ab6a436b96c0b6790ce2675b3d6917ee" translate="yes" xml:space="preserve">
          <source>Norm used to normalize term vectors. None for no normalization.</source>
          <target state="translated">Norma utilizada para normalizar los vectores de término.Ninguno para ninguna normalización.</target>
        </trans-unit>
        <trans-unit id="45e118d0563ea8581f830f46e85b60ae714faae4" translate="yes" xml:space="preserve">
          <source>Normal</source>
          <target state="translated">Normal</target>
        </trans-unit>
        <trans-unit id="baeabcda0198bd70ffaabb333ee49b38a8e0ee34" translate="yes" xml:space="preserve">
          <source>Normal and Shrinkage Linear Discriminant Analysis for classification</source>
          <target state="translated">Análisis discriminante lineal normal y de contracción para la clasificación</target>
        </trans-unit>
        <trans-unit id="1c651aee92e671db7fa9048c6cdacbd12ea197da" translate="yes" xml:space="preserve">
          <source>Normalization matrix needed for embedding. Square root of the kernel matrix on &lt;code&gt;components_&lt;/code&gt;.</source>
          <target state="translated">Matriz de normalizaci&amp;oacute;n necesaria para la incrustaci&amp;oacute;n. Ra&amp;iacute;z cuadrada de la matriz del n&amp;uacute;cleo en &lt;code&gt;components_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b2dd009a742549bee9ad100542b0f67ba3a05708" translate="yes" xml:space="preserve">
          <source>Normalize samples individually to unit norm.</source>
          <target state="translated">Normalizar las muestras individualmente a la norma de la unidad.</target>
        </trans-unit>
        <trans-unit id="1cc78071dce653cdb1a895ced93da41b36798ab2" translate="yes" xml:space="preserve">
          <source>Normalized Mutual Information</source>
          <target state="translated">Información mutua normalizada</target>
        </trans-unit>
        <trans-unit id="6d15c4ae0d04e936f901929872b9ad476ca9800b" translate="yes" xml:space="preserve">
          <source>Normalized Mutual Information (NMI) is a normalization of the Mutual Information (MI) score to scale the results between 0 (no mutual information) and 1 (perfect correlation). In this function, mutual information is normalized by some generalized mean of &lt;code&gt;H(labels_true)&lt;/code&gt; and &lt;code&gt;H(labels_pred))&lt;/code&gt;, defined by the &lt;code&gt;average_method&lt;/code&gt;.</source>
          <target state="translated">La informaci&amp;oacute;n mutua normalizada (NMI) es una normalizaci&amp;oacute;n de la puntuaci&amp;oacute;n de informaci&amp;oacute;n mutua (MI) para escalar los resultados entre 0 (sin informaci&amp;oacute;n mutua) y 1 (correlaci&amp;oacute;n perfecta). En esta funci&amp;oacute;n, la informaci&amp;oacute;n mutua se normaliza por algunos media generalizada de &lt;code&gt;H(labels_true)&lt;/code&gt; y &lt;code&gt;H(labels_pred))&lt;/code&gt; , definida por la &lt;code&gt;average_method&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2009d38e6ab058cf38d5f44a4aa1fda0316b3372" translate="yes" xml:space="preserve">
          <source>Normalized Mutual Information between two clusterings.</source>
          <target state="translated">Información mutua normalizada entre dos agrupaciones.</target>
        </trans-unit>
        <trans-unit id="4f7979e77b9a0db2d6d4f14823a6b0012cc9a130" translate="yes" xml:space="preserve">
          <source>Normalized cuts and image segmentation, 2000 Jianbo Shi, Jitendra Malik &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&lt;/a&gt;</source>
          <target state="translated">Cortes normalizados y segmentaci&amp;oacute;n de im&amp;aacute;genes, 2000 Jianbo Shi, Jitendra Malik &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="bcdc09e5b38e3433007fe04c41bf1718c142c846" translate="yes" xml:space="preserve">
          <source>Normalized input X.</source>
          <target state="translated">Entrada normalizada X.</target>
        </trans-unit>
        <trans-unit id="cf0305ad6a5172727382b32897870cffde3ce433" translate="yes" xml:space="preserve">
          <source>Normalized probability distributions across class labels</source>
          <target state="translated">Distribuciones de probabilidad normalizadas a través de etiquetas de clase</target>
        </trans-unit>
        <trans-unit id="53f158b7f3551b0f974a1547fdea15ef3000e7be" translate="yes" xml:space="preserve">
          <source>Normalized probability distributions across class labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3dd51ff507e0ed7c736dd049baf65846cc243ec4" translate="yes" xml:space="preserve">
          <source>Normalized total reduction of criteria by feature (Gini importance).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4b126cd68b1eba9b799b0ffccc1898e8bfe924f" translate="yes" xml:space="preserve">
          <source>Normalizer</source>
          <target state="translated">Normalizer</target>
        </trans-unit>
        <trans-unit id="2b3ec4d083535b907de33251ab28d9b72b55d74b" translate="yes" xml:space="preserve">
          <source>Normalizes confusion matrix over the true (rows), predicted (columns) conditions or all the population. If None, confusion matrix will not be normalized.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a19366221588f526c166820c530dd8f2268ea2b7" translate="yes" xml:space="preserve">
          <source>Not all models benefit from optimized BLAS and Lapack implementations. For instance models based on (randomized) decision trees typically do not rely on BLAS calls in their inner loops, nor do kernel SVMs (&lt;code&gt;SVC&lt;/code&gt;, &lt;code&gt;SVR&lt;/code&gt;, &lt;code&gt;NuSVC&lt;/code&gt;, &lt;code&gt;NuSVR&lt;/code&gt;). On the other hand a linear model implemented with a BLAS DGEMM call (via &lt;code&gt;numpy.dot&lt;/code&gt;) will typically benefit hugely from a tuned BLAS implementation and lead to orders of magnitude speedup over a non-optimized BLAS.</source>
          <target state="translated">No todos los modelos se benefician de las implementaciones optimizadas de BLAS y Lapack. Por ejemplo, los modelos basados ​​en &amp;aacute;rboles de decisi&amp;oacute;n (aleatorios) normalmente no dependen de las llamadas BLAS en sus bucles internos, ni tampoco las SVM del kernel ( &lt;code&gt;SVC&lt;/code&gt; , &lt;code&gt;SVR&lt;/code&gt; , &lt;code&gt;NuSVC&lt;/code&gt; , &lt;code&gt;NuSVR&lt;/code&gt; ). Por otro lado, un modelo lineal implementado con una llamada BLAS DGEMM (a trav&amp;eacute;s de &lt;code&gt;numpy.dot&lt;/code&gt; ) generalmente se beneficiar&amp;aacute; enormemente de una implementaci&amp;oacute;n BLAS ajustada y conducir&amp;aacute; a una aceleraci&amp;oacute;n de &amp;oacute;rdenes de magnitud sobre un BLAS no optimizado.</target>
        </trans-unit>
        <trans-unit id="d1a17af19f5388af9d6596cc0ea7dbb1d739e255" translate="yes" xml:space="preserve">
          <source>Not available</source>
          <target state="translated">No está disponible.</target>
        </trans-unit>
        <trans-unit id="2f1306ffef95e5ddbb8f4b2f3a60c6ede1c9a1f3" translate="yes" xml:space="preserve">
          <source>Not scalable</source>
          <target state="translated">No es escalable</target>
        </trans-unit>
        <trans-unit id="6671bcf801635373715efa03216b0f9d13f34c22" translate="yes" xml:space="preserve">
          <source>Not scalable with &lt;code&gt;n_samples&lt;/code&gt;</source>
          <target state="translated">No escalable con &lt;code&gt;n_samples&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="d70eb56b501fa2ef808df1c818502bbb5b800d19" translate="yes" xml:space="preserve">
          <source>Not scalable with n_samples</source>
          <target state="translated">No es escalable con n_muestras</target>
        </trans-unit>
        <trans-unit id="5f0f2378acb52b70e08107dc0bdd42ae2edf4fdf" translate="yes" xml:space="preserve">
          <source>Not used, present for API consistence purpose.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c8ec850c7c26d11c7ae99e5fae0ce11ac404b3f" translate="yes" xml:space="preserve">
          <source>Not used, present for API consistency by convention.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abfeb2bc66d46ae118c694d4f663b42a0b277b39" translate="yes" xml:space="preserve">
          <source>Not used, present here for API consistency by convention.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f8740a7ea28a56477d25ad1aaaf52d864b49a7d" translate="yes" xml:space="preserve">
          <source>NotFittedError</source>
          <target state="translated">NotFittedError</target>
        </trans-unit>
        <trans-unit id="2c924e3088204ee77ba681f72be3444357932fca" translate="yes" xml:space="preserve">
          <source>Note</source>
          <target state="translated">Note</target>
        </trans-unit>
        <trans-unit id="14ba06ae5f3993adde2848620bcf508016c9c617" translate="yes" xml:space="preserve">
          <source>Note : Laplacian Eigenmaps is the actual algorithm implemented here.</source>
          <target state="translated">Nota:Laplacian Eigenmaps es el verdadero algoritmo implementado aquí.</target>
        </trans-unit>
        <trans-unit id="21546711de316cf946ba53a498f41ae0550616cc" translate="yes" xml:space="preserve">
          <source>Note how some use the group/class information while others do not.</source>
          <target state="translated">Obsérvese cómo algunos utilizan la información de grupo/clase mientras que otros no lo hacen.</target>
        </trans-unit>
        <trans-unit id="c3c271844b997675d3bb1a8d39599227fbe7b490" translate="yes" xml:space="preserve">
          <source>Note how the optimal value of alpha varies for each fold. This illustrates why nested-cross validation is necessary when trying to evaluate the performance of a method for which a parameter is chosen by cross-validation: this choice of parameter may not be optimal for unseen data.</source>
          <target state="translated">Obsérvese cómo varía el valor óptimo del alfa para cada pliegue.Esto ilustra por qué es necesaria la validación cruzada anidada cuando se intenta evaluar el rendimiento de un método para el que se elige un parámetro mediante la validación cruzada:esta elección del parámetro puede no ser óptima para datos no vistos.</target>
        </trans-unit>
        <trans-unit id="92e53ea7bdcc226c7bc1da5197dd56da468b26d1" translate="yes" xml:space="preserve">
          <source>Note on inappropriate usage of cross_val_predict</source>
          <target state="translated">Nota sobre el uso inapropiado de cross_val_predict</target>
        </trans-unit>
        <trans-unit id="b437e168efe2a06e08f52a3ad3a931f217ecf431" translate="yes" xml:space="preserve">
          <source>Note on notations presented in the graphical model above, which can be found in Hoffman et al. (2013):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="029f2db65bc50c936edb77149f903f8d03abd995" translate="yes" xml:space="preserve">
          <source>Note on the lookup process: depending on the type of name_or_id, will choose between integer id lookup or metadata name lookup by looking at the unzipped archives and metadata file.</source>
          <target state="translated">Nota sobre el proceso de búsqueda:dependiendo del tipo de name_or_id,elegirá entre la búsqueda de id entero o la búsqueda de nombre de metadatos mirando los archivos descomprimidos y el archivo de metadatos.</target>
        </trans-unit>
        <trans-unit id="637677b94f16fb377d9bcfbae4602956aad7da33" translate="yes" xml:space="preserve">
          <source>Note that &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;saga&amp;rsquo; fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing.</source>
          <target state="translated">Tenga en cuenta que la convergencia r&amp;aacute;pida 'sag' y 'saga' solo est&amp;aacute; garantizada en entidades con aproximadamente la misma escala. Puede preprocesar los datos con un escalador de sklearn.preprocessing.</target>
        </trans-unit>
        <trans-unit id="92f3fcd7326295f6a74b7d0528bb22c0cf404ba4" translate="yes" xml:space="preserve">
          <source>Note that &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kneighborsregressor#sklearn.neighbors.KNeighborsRegressor&quot;&gt;&lt;code&gt;sklearn.neighbors.KNeighborsRegressor&lt;/code&gt;&lt;/a&gt; is different from KNN imputation, which learns from samples with missing values by using a distance metric that accounts for missing values, rather than imputing them.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bfc6f56d0d9af5825aa3c5bc1de0fcc87a2bde36" translate="yes" xml:space="preserve">
          <source>Note that &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt; calculates unadjusted R&amp;sup2; without correcting for bias in sample variance of y.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb2d865fbf24560bc423d4932883d3877000a02a" translate="yes" xml:space="preserve">
          <source>Note that &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; does not support &lt;code&gt;predict&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;score_samples&lt;/code&gt; methods by default but only a &lt;code&gt;fit_predict&lt;/code&gt; method, as this estimator was originally meant to be applied for outlier detection. The scores of abnormality of the training samples are accessible through the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute.</source>
          <target state="translated">Tenga en cuenta que &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt; no soporta &lt;code&gt;predict&lt;/code&gt; , &lt;code&gt;decision_function&lt;/code&gt; y &lt;code&gt;score_samples&lt;/code&gt; m&amp;eacute;todos por defecto, pero s&amp;oacute;lo un &lt;code&gt;fit_predict&lt;/code&gt; m&amp;eacute;todo, ya que este estimador fue originalmente concebido para ser aplicado para la detecci&amp;oacute;n de valores at&amp;iacute;picos. Se puede acceder a las puntuaciones de anomal&amp;iacute;a de las muestras de entrenamiento a trav&amp;eacute;s del atributo &lt;code&gt;negative_outlier_factor_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c2b0ede00caa9f24f249766b854d734ce8a77594" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;estimators_&lt;/code&gt; are fitted on the full &lt;code&gt;X&lt;/code&gt; while &lt;code&gt;final_estimator_&lt;/code&gt; is trained using cross-validated predictions of the base estimators using &lt;code&gt;cross_val_predict&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9cc23e915eab7d76b355d3d788a42c200a9cfa75" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;fit_predict&lt;/code&gt; is not available in this case.</source>
          <target state="translated">Tenga en cuenta que &lt;code&gt;fit_predict&lt;/code&gt; no est&amp;aacute; disponible en este caso.</target>
        </trans-unit>
        <trans-unit id="a64277fe0445c7a49bb63f1b3128c36db8f44687" translate="yes" xml:space="preserve">
          <source>Note that &lt;strong&gt;early-stopping is enabled by default if the number of samples is larger than 10,000&lt;/strong&gt;. The early-stopping behaviour is controlled via the &lt;code&gt;early-stopping&lt;/code&gt;, &lt;code&gt;scoring&lt;/code&gt;, &lt;code&gt;validation_fraction&lt;/code&gt;, &lt;code&gt;n_iter_no_change&lt;/code&gt;, and &lt;code&gt;tol&lt;/code&gt; parameters. It is possible to early-stop using an arbitrary &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-scorer&quot;&gt;scorer&lt;/a&gt;, or just the training or validation loss. Note that for technical reasons, using a scorer is significantly slower than using the loss. By default, early-stopping is performed if there are at least 10,000 samples in the training set, using the validation loss.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05da1e73517821e307ab23620f26a2cb5cf58320" translate="yes" xml:space="preserve">
          <source>Note that Sparse PCA components orthogonality is not enforced as in PCA hence one cannot use a simple linear projection.</source>
          <target state="translated">Tenga en cuenta que la ortogonalidad de los componentes del PCA no se aplica como en el PCA,por lo que no se puede utilizar una simple proyección lineal.</target>
        </trans-unit>
        <trans-unit id="6d11171b334a15c9f3a0ed71d47a8e76e15de782" translate="yes" xml:space="preserve">
          <source>Note that a call to the &lt;code&gt;transform&lt;/code&gt; method of &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt; is not allowed to change the number of samples. Therefore multiple imputations cannot be achieved by a single call to &lt;code&gt;transform&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38919ec8aa75d45b22406b99670380fbc01ee90e" translate="yes" xml:space="preserve">
          <source>Note that all classifiers handling multioutput-multiclass (also known as multitask classification) tasks, support the multilabel classification task as a special case. Multitask classification is similar to the multioutput classification task with different model formulations. For more information, see the relevant estimator documentation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a04205581b19a745020f7a71bf7734034b648ca" translate="yes" xml:space="preserve">
          <source>Note that backwards compatibility may not be supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a36ac6808e625c8a29705bcc1d1fb6cf63760b8" translate="yes" xml:space="preserve">
          <source>Note that before SciPy 0.16, the &lt;code&gt;scipy.stats.distributions&lt;/code&gt; do not accept a custom RNG instance and always use the singleton RNG from &lt;code&gt;numpy.random&lt;/code&gt;. Hence setting &lt;code&gt;random_state&lt;/code&gt; will not guarantee a deterministic iteration whenever &lt;code&gt;scipy.stats&lt;/code&gt; distributions are used to define the parameter search space.</source>
          <target state="translated">Tenga en cuenta que antes de SciPy 0.16, las &lt;code&gt;scipy.stats.distributions&lt;/code&gt; no aceptan una instancia de RNG personalizada y siempre usan el RNG singleton de &lt;code&gt;numpy.random&lt;/code&gt; . Por lo tanto, establecer &lt;code&gt;random_state&lt;/code&gt; no garantizar&amp;aacute; una iteraci&amp;oacute;n determinista siempre que se &lt;code&gt;scipy.stats&lt;/code&gt; distribuciones scipy.stats para definir el espacio de b&amp;uacute;squeda de par&amp;aacute;metros.</target>
        </trans-unit>
        <trans-unit id="9a716693e5778e1463e7644515aedc4c9b2a1b82" translate="yes" xml:space="preserve">
          <source>Note that before SciPy 0.16, the &lt;code&gt;scipy.stats.distributions&lt;/code&gt; do not accept a custom RNG instance and always use the singleton RNG from &lt;code&gt;numpy.random&lt;/code&gt;. Hence setting &lt;code&gt;random_state&lt;/code&gt; will not guarantee a deterministic iteration whenever &lt;code&gt;scipy.stats&lt;/code&gt; distributions are used to define the parameter search space. Deterministic behavior is however guaranteed from SciPy 0.16 onwards.</source>
          <target state="translated">Tenga en cuenta que antes de SciPy 0.16, las &lt;code&gt;scipy.stats.distributions&lt;/code&gt; no aceptan una instancia de RNG personalizada y siempre usan el RNG singleton de &lt;code&gt;numpy.random&lt;/code&gt; . Por lo tanto, establecer &lt;code&gt;random_state&lt;/code&gt; no garantizar&amp;aacute; una iteraci&amp;oacute;n determinista siempre que se &lt;code&gt;scipy.stats&lt;/code&gt; distribuciones scipy.stats para definir el espacio de b&amp;uacute;squeda de par&amp;aacute;metros. Sin embargo, el comportamiento determinista est&amp;aacute; garantizado desde SciPy 0.16 en adelante.</target>
        </trans-unit>
        <trans-unit id="8803233984e598253564c68adac3c470cc868526" translate="yes" xml:space="preserve">
          <source>Note that even for a classification task, the \(h_m\) sub-estimator is still a regressor, not a classifier. This is because the sub-estimators are trained to predict (negative) &lt;em&gt;gradients&lt;/em&gt;, which are always continuous quantities.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45e5cb26ef2b019b9c0f33d27cd0fca50cc9bb8f" translate="yes" xml:space="preserve">
          <source>Note that for any single value of &lt;code&gt;eps&lt;/code&gt;, DBSCAN will tend to have a shorter run time than OPTICS; however, for repeated runs at varying &lt;code&gt;eps&lt;/code&gt; values, a single run of OPTICS may require less cumulative runtime than DBSCAN. It is also important to note that OPTICS&amp;rsquo; output is close to DBSCAN&amp;rsquo;s only if &lt;code&gt;eps&lt;/code&gt; and &lt;code&gt;max_eps&lt;/code&gt; are close.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c441ea193159e43e5ae4f2f43b7cd455bbc50a0" translate="yes" xml:space="preserve">
          <source>Note that for floating-point input, the mean is computed using the same precision the input has. Depending on the input data, this can cause the results to be inaccurate, especially for &lt;code&gt;float32&lt;/code&gt; (see example below). Specifying a higher-precision accumulator using the &lt;code&gt;dtype&lt;/code&gt; keyword can alleviate this issue.</source>
          <target state="translated">Tenga en cuenta que para la entrada de punto flotante, la media se calcula con la misma precisi&amp;oacute;n que tiene la entrada. Dependiendo de los datos de entrada, esto puede causar que los resultados sean inexactos, especialmente para &lt;code&gt;float32&lt;/code&gt; (vea el ejemplo a continuaci&amp;oacute;n). Especificar un acumulador de mayor precisi&amp;oacute;n mediante la palabra clave &lt;code&gt;dtype&lt;/code&gt; puede aliviar este problema.</target>
        </trans-unit>
        <trans-unit id="1c1b3dcae0a3cdb049378b61a52e8a6e218b843e" translate="yes" xml:space="preserve">
          <source>Note that for multioutput (including multilabel) weights should be defined for each class of every column in its own dict. For example, for four-class multilabel classification weights should be [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of [{1:1}, {2:5}, {3:1}, {4:1}].</source>
          <target state="translated">Nótese que para la multi-salida (incluyendo la multi-etiqueta)los pesos deben ser definidos para cada clase de cada columna en su propio diccionario.Por ejemplo,para una clasificación de cuatro clases,los pesos deberían ser [{0:1,1:1},{0:1,1:5},{0:1,1:1},{0:1,1:1}]en lugar de [{1:1},{2:5},{3:1},{4:1}].</target>
        </trans-unit>
        <trans-unit id="7f057f4a3cfb222efbfc3fdf93e59924824aafce" translate="yes" xml:space="preserve">
          <source>Note that if features have very different scaling or statistical properties, &lt;a href=&quot;generated/sklearn.cluster.featureagglomeration#sklearn.cluster.FeatureAgglomeration&quot;&gt;&lt;code&gt;cluster.FeatureAgglomeration&lt;/code&gt;&lt;/a&gt; may not be able to capture the links between related features. Using a &lt;a href=&quot;generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt;&lt;code&gt;preprocessing.StandardScaler&lt;/code&gt;&lt;/a&gt; can be useful in these settings.</source>
          <target state="translated">Tenga en cuenta que si las caracter&amp;iacute;sticas tienen propiedades estad&amp;iacute;sticas o de escala muy diferentes, es posible que &lt;a href=&quot;generated/sklearn.cluster.featureagglomeration#sklearn.cluster.FeatureAgglomeration&quot;&gt; &lt;code&gt;cluster.FeatureAgglomeration&lt;/code&gt; &lt;/a&gt; no pueda capturar los v&amp;iacute;nculos entre las caracter&amp;iacute;sticas relacionadas. El uso de un &lt;a href=&quot;generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt; &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; &lt;/a&gt; puede ser &amp;uacute;til en esta configuraci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="daa34c655040f11fbac2193226735416d5ff6724" translate="yes" xml:space="preserve">
          <source>Note that if the values of your similarity matrix are not well distributed, e.g. with negative values or with a distance matrix rather than a similarity, the spectral problem will be singular and the problem not solvable. In which case it is advised to apply a transformation to the entries of the matrix. For instance, in the case of a signed distance matrix, is common to apply a heat kernel:</source>
          <target state="translated">Tenga en cuenta que si los valores de su matriz de similitud no están bien distribuidos,por ejemplo,con valores negativos o con una matriz de distancia en lugar de una similitud,el problema espectral será singular y el problema no se podrá resolver.En ese caso se aconseja aplicar una transformación a las entradas de la matriz.Por ejemplo,en el caso de una matriz de distancia con signo,es común aplicar un núcleo de calor:</target>
        </trans-unit>
        <trans-unit id="82c5d12dd2770bc5d00d9e0fd296f522b36a2aec" translate="yes" xml:space="preserve">
          <source>Note that in binary classification, recall of the positive class is also known as &amp;ldquo;sensitivity&amp;rdquo;; recall of the negative class is &amp;ldquo;specificity&amp;rdquo;.</source>
          <target state="translated">Tenga en cuenta que en la clasificaci&amp;oacute;n binaria, la recuperaci&amp;oacute;n de la clase positiva tambi&amp;eacute;n se conoce como &quot;sensibilidad&quot;; el recuerdo de la clase negativa es &quot;especificidad&quot;.</target>
        </trans-unit>
        <trans-unit id="56700fbea0a4382f56515fac76889ee512c8d3cb" translate="yes" xml:space="preserve">
          <source>Note that in certain cases, the Lars solver may be significantly faster to implement this functionality. In particular, linear interpolation can be used to retrieve model coefficients between the values output by lars_path</source>
          <target state="translated">Tenga en cuenta que en ciertos casos,el solucionador de Lars puede ser significativamente más rápido para implementar esta funcionalidad.En particular,la interpolación lineal puede utilizarse para recuperar los coeficientes del modelo entre los valores emitidos por lars_path</target>
        </trans-unit>
        <trans-unit id="c065b9ad388e273aa3b214ab1297a55e0496eb57" translate="yes" xml:space="preserve">
          <source>Note that in general, robust fitting in high-dimensional setting (large &lt;code&gt;n_features&lt;/code&gt;) is very hard. The robust models here will probably not work in these settings.</source>
          <target state="translated">Tenga en cuenta que, en general, un ajuste robusto en un entorno de alta dimensi&amp;oacute;n ( &lt;code&gt;n_features&lt;/code&gt; grandes ) es muy dif&amp;iacute;cil. Los modelos robustos aqu&amp;iacute; probablemente no funcionar&amp;aacute;n en estos entornos.</target>
        </trans-unit>
        <trans-unit id="64011c56ebca18074907020d8d3e99112269576a" translate="yes" xml:space="preserve">
          <source>Note that in practice, one would not search over this many different parameters simultaneously using grid search, but pick only the ones deemed most important.</source>
          <target state="translated">Obsérvese que,en la práctica,no se buscarían tantos parámetros diferentes simultáneamente mediante la búsqueda de cuadrículas,sino que se elegirían sólo los que se considerasen más importantes.</target>
        </trans-unit>
        <trans-unit id="b7d16723edd6b0c8a445c16934e7dfaedb2752ae" translate="yes" xml:space="preserve">
          <source>Note that in the case of &amp;lsquo;cityblock&amp;rsquo;, &amp;lsquo;cosine&amp;rsquo; and &amp;lsquo;euclidean&amp;rsquo; (which are valid scipy.spatial.distance metrics), the scikit-learn implementation will be used, which is faster and has support for sparse matrices (except for &amp;lsquo;cityblock&amp;rsquo;). For a verbose description of the metrics from scikit-learn, see the __doc__ of the sklearn.pairwise.distance_metrics function.</source>
          <target state="translated">Tenga en cuenta que en el caso de 'cityblock', 'cosine' y 'euclidean' (que son m&amp;eacute;tricas v&amp;aacute;lidas de scipy.spatial.distance), se utilizar&amp;aacute; la implementaci&amp;oacute;n scikit-learn, que es m&amp;aacute;s r&amp;aacute;pida y tiene soporte para matrices dispersas (excepto para 'Manzana de la ciudad'). Para obtener una descripci&amp;oacute;n detallada de las m&amp;eacute;tricas de scikit-learn, consulte el __doc__ de la funci&amp;oacute;n sklearn.pairwise.distance_metrics.</target>
        </trans-unit>
        <trans-unit id="81154799705dfac8836df66f3a0269041db1173b" translate="yes" xml:space="preserve">
          <source>Note that in the multilabel case, each sample can have any number of labels. This returns the marginal probability that the given sample has the label in question. For example, it is entirely consistent that two labels both have a 90% probability of applying to a given sample.</source>
          <target state="translated">Obsérvese que en el caso de las etiquetas múltiples,cada muestra puede tener cualquier número de etiquetas.Esto devuelve la probabilidad marginal de que la muestra dada tenga la etiqueta en cuestión.Por ejemplo,es totalmente coherente que dos etiquetas tengan ambas una probabilidad del 90% de aplicarse a una muestra dada.</target>
        </trans-unit>
        <trans-unit id="01d7bf1a38a1f2f757397967cae9b7d66ce2602c" translate="yes" xml:space="preserve">
          <source>Note that in the previous corpus, the first and the last documents have exactly the same words hence are encoded in equal vectors. In particular we lose the information that the last document is an interrogative form. To preserve some of the local ordering information we can extract 2-grams of words in addition to the 1-grams (individual words):</source>
          <target state="translated">Obsérvese que en el corpus anterior,el primer y el último documento tienen exactamente las mismas palabras,por lo que están codificados en vectores iguales.En particular,perdemos la información de que el último documento es una forma interrogativa.Para preservar parte de la información de ordenamiento local podemos extraer 2 gramos de palabras además de los 1 gramos (palabras individuales):</target>
        </trans-unit>
        <trans-unit id="61d12fb0837cc546c2865fefff8f9a5fb5f27798" translate="yes" xml:space="preserve">
          <source>Note that it is also possible to get the output of the stacked &lt;code&gt;estimators&lt;/code&gt; using the &lt;code&gt;transform&lt;/code&gt; method:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8dcb354ad6f05344d318f25389a442779bd42bda" translate="yes" xml:space="preserve">
          <source>Note that it is common that a small subset of those parameters can have a large impact on the predictive or computation performance of the model while others can be left to their default values. It is recommended to read the docstring of the estimator class to get a finer understanding of their expected behavior, possibly by reading the enclosed reference to the literature.</source>
          <target state="translated">Obsérvese que es común que un pequeño subconjunto de esos parámetros pueda tener un gran impacto en el rendimiento predictivo o de cálculo del modelo,mientras que otros pueden dejarse a sus valores por defecto.Se recomienda leer la cadena de documentación de la clase de estimadores para obtener una mejor comprensión de su comportamiento esperado,posiblemente leyendo la referencia adjunta a la literatura.</target>
        </trans-unit>
        <trans-unit id="e39d258640f71b07567efcd3611fa0f4dfc35df8" translate="yes" xml:space="preserve">
          <source>Note that it is important to check that the model is accurate enough on a test set before plotting the partial dependence since there would be little use in explaining the impact of a given feature on the prediction function of a poor model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38e7c6473cb1417f0189c236d54733065555b837" translate="yes" xml:space="preserve">
          <source>Note that it maximizes both the correlations between the scores and the intra-block variances.</source>
          <target state="translated">Observe que maximiza tanto las correlaciones entre las puntuaciones como las variaciones intrabloqueales.</target>
        </trans-unit>
        <trans-unit id="7fe083a60697e58d27f138d9ea26d77a87096c53" translate="yes" xml:space="preserve">
          <source>Note that it maximizes only the correlations between the scores.</source>
          <target state="translated">Tengan en cuenta que sólo maximiza las correlaciones entre las puntuaciones.</target>
        </trans-unit>
        <trans-unit id="4ad685eaf7c64ded5f9210b1f3461deac7d47f1a" translate="yes" xml:space="preserve">
          <source>Note that monotonic constraints only constraint the output &amp;ldquo;all else being equal&amp;rdquo;. Indeed, the following relation &lt;strong&gt;is not enforced&lt;/strong&gt; by a positive constraint: \(x_1 \leq x_1' \implies F(x_1, x_2) \leq F(x_1', x_2')\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b4460fdb66af9bc149af45e106adc5f1d493bbf" translate="yes" xml:space="preserve">
          <source>Note that noisy data can &amp;ldquo;short-circuit&amp;rdquo; the manifold, in essence acting as a bridge between parts of the manifold that would otherwise be well-separated. Manifold learning on noisy and/or incomplete data is an active area of research.</source>
          <target state="translated">Tenga en cuenta que los datos ruidosos pueden &quot;provocar un cortocircuito&quot; en el colector, actuando en esencia como un puente entre las partes del colector que de otro modo estar&amp;iacute;an bien separadas. El aprendizaje m&amp;uacute;ltiple sobre datos ruidosos y / o incompletos es un &amp;aacute;rea activa de investigaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="cf4033d0f4ffad84f5c58c4e0d89634a33d57e14" translate="yes" xml:space="preserve">
          <source>Note that on this tabular dataset, Gradient Boosting Machines are both significantly faster to train and more accurate than neural networks. It is also significantly cheaper to tune their hyperparameters (the default tend to work well while this is not often the case for neural networks).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67d5dd89ca82637aa1c574ab8cabbf8ba39e4cb8" translate="yes" xml:space="preserve">
          <source>Note that pickle has some security and maintainability issues. Please refer to section &lt;a href=&quot;../../modules/model_persistence#model-persistence&quot;&gt;Model persistence&lt;/a&gt; for more detailed information about model persistence with scikit-learn.</source>
          <target state="translated">Tenga en cuenta que pickle tiene algunos problemas de seguridad y mantenimiento. Consulte la secci&amp;oacute;n &lt;a href=&quot;../../modules/model_persistence#model-persistence&quot;&gt;Persistencia del modelo&lt;/a&gt; para obtener informaci&amp;oacute;n m&amp;aacute;s detallada sobre la persistencia del modelo con scikit-learn.</target>
        </trans-unit>
        <trans-unit id="23cd95765d94c327b5282b4a1fe3e5dffe405a3a" translate="yes" xml:space="preserve">
          <source>Note that polynomial features are used implicitly in &lt;a href=&quot;https://en.wikipedia.org/wiki/Kernel_method&quot;&gt;kernel methods&lt;/a&gt; (e.g., &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;sklearn.svm.SVC&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.decomposition.kernelpca#sklearn.decomposition.KernelPCA&quot;&gt;&lt;code&gt;sklearn.decomposition.KernelPCA&lt;/code&gt;&lt;/a&gt;) when using polynomial &lt;a href=&quot;svm#svm-kernels&quot;&gt;Kernel functions&lt;/a&gt;.</source>
          <target state="translated">Tenga en cuenta que las caracter&amp;iacute;sticas polinomiales se utilizan impl&amp;iacute;citamente en los &lt;a href=&quot;https://en.wikipedia.org/wiki/Kernel_method&quot;&gt;m&amp;eacute;todos del kernel&lt;/a&gt; (por ejemplo, &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;sklearn.svm.SVC&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.decomposition.kernelpca#sklearn.decomposition.KernelPCA&quot;&gt; &lt;code&gt;sklearn.decomposition.KernelPCA&lt;/code&gt; &lt;/a&gt; ) cuando se utilizan &lt;a href=&quot;svm#svm-kernels&quot;&gt;funciones&lt;/a&gt; polinomiales del kernel .</target>
        </trans-unit>
        <trans-unit id="675c6d53180ed2915c2b59bf4a0a0e8fbac69215" translate="yes" xml:space="preserve">
          <source>Note that providing &lt;code&gt;y&lt;/code&gt; is sufficient to generate the splits and hence &lt;code&gt;np.zeros(n_samples)&lt;/code&gt; may be used as a placeholder for &lt;code&gt;X&lt;/code&gt; instead of actual training data.</source>
          <target state="translated">Tenga en cuenta que proporcionar &lt;code&gt;y&lt;/code&gt; es suficiente para generar las divisiones y, por &lt;code&gt;np.zeros(n_samples)&lt;/code&gt; tanto, np.zeros (n_samples) se puede usar como marcador de posici&amp;oacute;n para &lt;code&gt;X&lt;/code&gt; en lugar de los datos de entrenamiento reales.</target>
        </trans-unit>
        <trans-unit id="df4d1f63cde2c26d664594a284ce306040d06cfb" translate="yes" xml:space="preserve">
          <source>Note that shrinkage works only with &amp;lsquo;lsqr&amp;rsquo; and &amp;lsquo;eigen&amp;rsquo; solvers.</source>
          <target state="translated">Tenga en cuenta que la contracci&amp;oacute;n solo funciona con los solucionadores 'lsqr' y 'eigen'.</target>
        </trans-unit>
        <trans-unit id="dd7adf0d494ffc5bcd4e70266fd05b000aa00dcc" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt;&lt;code&gt;precision_recall_curve&lt;/code&gt;&lt;/a&gt; function is restricted to the binary case. The &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; function works only in binary classification and multilabel indicator format.</source>
          <target state="translated">Tenga en cuenta que la funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt; &lt;code&gt;precision_recall_curve&lt;/code&gt; &lt;/a&gt; est&amp;aacute; restringida al caso binario. El &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt; funci&amp;oacute;n s&amp;oacute;lo funciona en la clasificaci&amp;oacute;n binaria y el formato indicador Multilabel.</target>
        </trans-unit>
        <trans-unit id="8d400c4e81cd0336ee43fd779c1c25e212117f34" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt;&lt;code&gt;precision_recall_curve&lt;/code&gt;&lt;/a&gt; function is restricted to the binary case. The &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; function works only in binary classification and multilabel indicator format. The &lt;a href=&quot;generated/sklearn.metrics.plot_precision_recall_curve#sklearn.metrics.plot_precision_recall_curve&quot;&gt;&lt;code&gt;plot_precision_recall_curve&lt;/code&gt;&lt;/a&gt; function plots the precision recall as follows.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="651372cf76a2e0eca2cd0e2ced075f5cfd44a313" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.preprocessing.binarizer#sklearn.preprocessing.Binarizer&quot;&gt;&lt;code&gt;Binarizer&lt;/code&gt;&lt;/a&gt; is similar to the &lt;a href=&quot;generated/sklearn.preprocessing.kbinsdiscretizer#sklearn.preprocessing.KBinsDiscretizer&quot;&gt;&lt;code&gt;KBinsDiscretizer&lt;/code&gt;&lt;/a&gt; when &lt;code&gt;k = 2&lt;/code&gt;, and when the bin edge is at the value &lt;code&gt;threshold&lt;/code&gt;.</source>
          <target state="translated">Tenga en cuenta que el &lt;a href=&quot;generated/sklearn.preprocessing.binarizer#sklearn.preprocessing.Binarizer&quot;&gt; &lt;code&gt;Binarizer&lt;/code&gt; &lt;/a&gt; es similar al &lt;a href=&quot;generated/sklearn.preprocessing.kbinsdiscretizer#sklearn.preprocessing.KBinsDiscretizer&quot;&gt; &lt;code&gt;KBinsDiscretizer&lt;/code&gt; &lt;/a&gt; cuando &lt;code&gt;k = 2&lt;/code&gt; y cuando el borde del contenedor est&amp;aacute; en el &lt;code&gt;threshold&lt;/code&gt; valor .</target>
        </trans-unit>
        <trans-unit id="96049a1871e8f004cea40c870be340fc85046579" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; also implements an alternative multi-class strategy, the so-called multi-class SVM formulated by Crammer and Singer &lt;a href=&quot;#id18&quot; id=&quot;id1&quot;&gt;16&lt;/a&gt;, by using the option &lt;code&gt;multi_class='crammer_singer'&lt;/code&gt;. In practice, one-vs-rest classification is usually preferred, since the results are mostly similar, but the runtime is significantly less.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b78ef718e6ed1cb354d8ff189ba4de9e4443cf71" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; also implements an alternative multi-class strategy, the so-called multi-class SVM formulated by Crammer and Singer, by using the option &lt;code&gt;multi_class='crammer_singer'&lt;/code&gt;. This method is consistent, which is not true for one-vs-rest classification. In practice, one-vs-rest classification is usually preferred, since the results are mostly similar, but the runtime is significantly less.</source>
          <target state="translated">Tenga en cuenta que &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt; tambi&amp;eacute;n implementa una estrategia alternativa de clases m&amp;uacute;ltiples, la denominada SVM de clases m&amp;uacute;ltiples formulada por Crammer y Singer, mediante el uso de la opci&amp;oacute;n &lt;code&gt;multi_class='crammer_singer'&lt;/code&gt; . Este m&amp;eacute;todo es consistente, lo que no es cierto para la clasificaci&amp;oacute;n de uno contra el resto. En la pr&amp;aacute;ctica, generalmente se prefiere la clasificaci&amp;oacute;n de uno frente al resto, ya que los resultados son en su mayor&amp;iacute;a similares, pero el tiempo de ejecuci&amp;oacute;n es significativamente menor.</target>
        </trans-unit>
        <trans-unit id="6d0f75c58b62c96c540e90be5dd6446b78869fb4" translate="yes" xml:space="preserve">
          <source>Note that the &lt;code&gt;__add__&lt;/code&gt; magic method is overridden, so &lt;code&gt;Sum(RBF(), RBF())&lt;/code&gt; is equivalent to using the + operator with &lt;code&gt;RBF() + RBF()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="acd06ce9a0926c4eda997a94789bc82988610943" translate="yes" xml:space="preserve">
          <source>Note that the &lt;code&gt;__mul__&lt;/code&gt; magic method is overridden, so &lt;code&gt;Product(RBF(), RBF())&lt;/code&gt; is equivalent to using the * operator with &lt;code&gt;RBF() * RBF()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d495fb41e55b7018b37ac27eeb250fbaf347d05a" translate="yes" xml:space="preserve">
          <source>Note that the &lt;code&gt;__pow__&lt;/code&gt; magic method is overridden, so &lt;code&gt;Exponentiation(RBF(), 2)&lt;/code&gt; is equivalent to using the ** operator with &lt;code&gt;RBF() ** 2&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a88b0087b5b199ea4beb800b3ce5a1f6c9022a8" translate="yes" xml:space="preserve">
          <source>Note that the Gini index only characterize the ranking performance of the model but not its calibration: any monotonic transformation of the predictions leaves the Gini index of the model unchanged.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4b2885ce1a0d54c6be5b37dba1e7a9bea3c67ec1" translate="yes" xml:space="preserve">
          <source>Note that the Multiplicative Update (&amp;lsquo;mu&amp;rsquo;) solver cannot update zeros present in the initialization, so it leads to poorer results when used jointly with the basic NNDSVD algorithm which introduces a lot of zeros; in this case, NNDSVDa or NNDSVDar should be preferred.</source>
          <target state="translated">Tenga en cuenta que el solucionador de Actualizaci&amp;oacute;n Multiplicativa ('mu') no puede actualizar los ceros presentes en la inicializaci&amp;oacute;n, por lo que conduce a resultados m&amp;aacute;s pobres cuando se usa junto con el algoritmo b&amp;aacute;sico NNDSVD que introduce muchos ceros; en este caso, deber&amp;iacute;a preferirse NNDSVDa o NNDSVDar.</target>
        </trans-unit>
        <trans-unit id="542b5d2a5a3926264004f7807400969fe48d422d" translate="yes" xml:space="preserve">
          <source>Note that the current implementation only supports regression estimators.</source>
          <target state="translated">Obsérvese que la aplicación actual sólo admite estimadores de regresión.</target>
        </trans-unit>
        <trans-unit id="7ac1e23398a8f2960b2ec6ee5eea4c00d3f041dd" translate="yes" xml:space="preserve">
          <source>Note that the dataset contains categorical and numerical variables. We will need to take this into account when preprocessing the dataset thereafter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5878ce2fa9f81f5b0b2794d8ccb7e40e7db1917d" translate="yes" xml:space="preserve">
          <source>Note that the dict values can either be scorer functions or one of the predefined metric strings.</source>
          <target state="translated">Nótese que los valores dictados pueden ser funciones de puntuación o una de las cadenas métricas predefinidas.</target>
        </trans-unit>
        <trans-unit id="a97f1f4d24f812e6f4b824a150b492f876f8dbe2" translate="yes" xml:space="preserve">
          <source>Note that the dimensionality does not affect the CPU training time of algorithms which operate on CSR matrices (&lt;code&gt;LinearSVC(dual=True)&lt;/code&gt;, &lt;code&gt;Perceptron&lt;/code&gt;, &lt;code&gt;SGDClassifier&lt;/code&gt;, &lt;code&gt;PassiveAggressive&lt;/code&gt;) but it does for algorithms that work with CSC matrices (&lt;code&gt;LinearSVC(dual=False)&lt;/code&gt;, &lt;code&gt;Lasso()&lt;/code&gt;, etc).</source>
          <target state="translated">Tenga en cuenta que la dimensionalidad no afecta el tiempo de entrenamiento de la CPU de los algoritmos que operan en matrices CSR ( &lt;code&gt;LinearSVC(dual=True)&lt;/code&gt; , &lt;code&gt;Perceptron&lt;/code&gt; , &lt;code&gt;SGDClassifier&lt;/code&gt; , &lt;code&gt;PassiveAggressive&lt;/code&gt; ) pero s&amp;iacute; para algoritmos que funcionan con matrices CSC ( &lt;code&gt;LinearSVC(dual=False)&lt;/code&gt; , &lt;code&gt;Lasso()&lt;/code&gt; , etc.).</target>
        </trans-unit>
        <trans-unit id="435cce9f843df9a5bdcdf7f7022599966bcaee8d" translate="yes" xml:space="preserve">
          <source>Note that the estimate_bandwidth function is much less scalable than the mean shift algorithm and will be the bottleneck if it is used.</source>
          <target state="translated">Obsérvese que la función estimate_banda es mucho menos escalable que el algoritmo de desplazamiento medio y será el cuello de botella si se utiliza.</target>
        </trans-unit>
        <trans-unit id="bce829a8923d634c66b8b2d36d28916cd48e0ab9" translate="yes" xml:space="preserve">
          <source>Note that the fourth and fifth instances returned all zeroes, indicating that they matched none of the three labels &lt;code&gt;fit&lt;/code&gt; upon. With multilabel outputs, it is similarly possible for an instance to be assigned multiple labels:</source>
          <target state="translated">Tenga en cuenta que las instancias cuarto y quinto devuelven todos los ceros, lo que indica que coincid&amp;iacute;an con ninguna de las tres etiquetas &lt;code&gt;fit&lt;/code&gt; al. Con salidas de etiquetas m&amp;uacute;ltiples, es igualmente posible que a una instancia se le asignen m&amp;uacute;ltiples etiquetas:</target>
        </trans-unit>
        <trans-unit id="21f39572b525862541f5e3b74bb03e06aac617ef" translate="yes" xml:space="preserve">
          <source>Note that the heat map plot has a special colorbar with a midpoint value close to the score values of the best performing models so as to make it easy to tell them apart in the blink of an eye.</source>
          <target state="translated">Obsérvese que el gráfico del mapa de calor tiene una barra de color especial con un valor de punto medio cercano a los valores de puntuación de los modelos de mejor rendimiento para que sea fácil distinguirlos en un abrir y cerrar de ojos.</target>
        </trans-unit>
        <trans-unit id="8c847c9ef93d363951399eb5e5ddd91d785490b8" translate="yes" xml:space="preserve">
          <source>Note that the importance values for the top features represent a large fraction of the reference score of 0.356.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f19bf1a17574ce6b7f5a8199cbb6b2ed04a3916" translate="yes" xml:space="preserve">
          <source>Note that the maximum likelihood estimate corresponds to no shrinkage, and thus performs poorly. The Ledoit-Wolf estimate performs really well, as it is close to the optimal and is computational not costly. In this example, the OAS estimate is a bit further away. Interestingly, both approaches outperform cross-validation, which is significantly most computationally costly.</source>
          <target state="translated">Obsérvese que la estimación de máxima probabilidad corresponde a la ausencia de contracción y,por lo tanto,tiene un rendimiento deficiente.La estimación de Ledoit-Wolf funciona muy bien,ya que está cerca de lo óptimo y es computacional no costosa.En este ejemplo,la estimación de la OEA está un poco más lejos.Es interesante que ambos enfoques superan la validación cruzada,que es significativamente más costosa desde el punto de vista computacional.</target>
        </trans-unit>
        <trans-unit id="be3cea96be539a6f36c7349851efbc1b4f539ceb" translate="yes" xml:space="preserve">
          <source>Note that the number of dimensions is independent of the original number of features but instead depends on the size of the dataset: the larger the dataset, the higher is the minimal dimensionality of an eps-embedding.</source>
          <target state="translated">Obsérvese que el número de dimensiones es independiente del número original de características,pero en cambio depende del tamaño del conjunto de datos:cuanto mayor es el conjunto de datos,mayor es la dimensionalidad mínima de una incorporación de eps.</target>
        </trans-unit>
        <trans-unit id="1426a0972df2ef3ae4847218faa4ab1a45e2a26b" translate="yes" xml:space="preserve">
          <source>Note that the parameter &lt;code&gt;alpha&lt;/code&gt; is applied as a Tikhonov regularization of the assumed covariance between the training points.</source>
          <target state="translated">Tenga en cuenta que el par&amp;aacute;metro &lt;code&gt;alpha&lt;/code&gt; se aplica como una regularizaci&amp;oacute;n de Tikhonov de la covarianza asumida entre los puntos de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="57bfd4549eb4e4a76c8eb0b9ddf20a2f4a52c8d2" translate="yes" xml:space="preserve">
          <source>Note that the precision may not decrease with recall. The definition of precision (\(\frac{T_p}{T_p + F_p}\)) shows that lowering the threshold of a classifier may increase the denominator, by increasing the number of results returned. If the threshold was previously set too high, the new results may all be true positives, which will increase precision. If the previous threshold was about right or too low, further lowering the threshold will introduce false positives, decreasing precision.</source>
          <target state="translated">Tenga en cuenta que la precisión no puede disminuir con el recuerdo.La definición de precisión (\(\frac{T_p}{T_p+F_p}\))muestra que bajar el umbral de un clasificador puede aumentar el denominador,aumentando el número de resultados devueltos.Si el umbral se fijó previamente demasiado alto,los nuevos resultados pueden ser todos verdaderos positivos,lo que aumentará la precisión.Si el umbral anterior era más o menos correcto o demasiado bajo,una mayor reducción del umbral introducirá falsos positivos,lo que disminuirá la precisión.</target>
        </trans-unit>
        <trans-unit id="07e181d114b5848fdd4cb0661edb49154d99e027" translate="yes" xml:space="preserve">
          <source>Note that the purpose of the &lt;a href=&quot;../../modules/manifold#multidimensional-scaling&quot;&gt;MDS&lt;/a&gt; is to find a low-dimensional representation of the data (here 2D) in which the distances respect well the distances in the original high-dimensional space, unlike other manifold-learning algorithms, it does not seeks an isotropic representation of the data in the low-dimensional space. Here the manifold problem matches fairly that of representing a flat map of the Earth, as with &lt;a href=&quot;https://en.wikipedia.org/wiki/Map_projection&quot;&gt;map projection&lt;/a&gt;</source>
          <target state="translated">Tenga en cuenta que el prop&amp;oacute;sito del &lt;a href=&quot;../../modules/manifold#multidimensional-scaling&quot;&gt;MDS&lt;/a&gt; es encontrar una representaci&amp;oacute;n de baja dimensi&amp;oacute;n de los datos (aqu&amp;iacute; 2D) en la que las distancias respeten bien las distancias en el espacio original de alta dimensi&amp;oacute;n, a diferencia de otros algoritmos de aprendizaje m&amp;uacute;ltiple, no busca una representaci&amp;oacute;n isotr&amp;oacute;pica de los datos en el espacio de baja dimensi&amp;oacute;n. Aqu&amp;iacute; el problema m&amp;uacute;ltiple coincide bastante con el de representar un mapa plano de la Tierra, como con la &lt;a href=&quot;https://en.wikipedia.org/wiki/Map_projection&quot;&gt;proyecci&amp;oacute;n de mapas.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="951ad93c2b6a49b38a3c4a8dabf905c9019bf128" translate="yes" xml:space="preserve">
          <source>Note that the purpose of the MDS is to find a low-dimensional representation of the data (here 2D) in which the distances respect well the distances in the original high-dimensional space, unlike other manifold-learning algorithms, it does not seeks an isotropic representation of the data in the low-dimensional space.</source>
          <target state="translated">Nótese que el propósito del MDS es encontrar una representación de las bajas dimensiones de los datos (aquí 2D)en la que las distancias respeten bien las distancias en el espacio original de altas dimensiones,a diferencia de otros algoritmos de aprendizaje múltiple,no busca una representación isotrópica de los datos en el espacio de bajas dimensiones.</target>
        </trans-unit>
        <trans-unit id="6c07e8b80629c5d24a4c78874f28fde4e1598ff3" translate="yes" xml:space="preserve">
          <source>Note that the resulting model is the average claim amount per claim. As such, it is conditional on having at least one claim, and cannot be used to predict the average claim amount per policy in general.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="faff2f13ccab498a5068027cb2f2891a11c4c2ca" translate="yes" xml:space="preserve">
          <source>Note that the scalers accept both Compressed Sparse Rows and Compressed Sparse Columns format (see &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; and &lt;code&gt;scipy.sparse.csc_matrix&lt;/code&gt;). Any other sparse input will be &lt;strong&gt;converted to the Compressed Sparse Rows representation&lt;/strong&gt;. To avoid unnecessary memory copies, it is recommended to choose the CSR or CSC representation upstream.</source>
          <target state="translated">Tenga en cuenta que los escaladores aceptan el formato de filas dispersas comprimidas y columnas dispersas comprimidas (consulte &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; y &lt;code&gt;scipy.sparse.csc_matrix&lt;/code&gt; ). Cualquier otra entrada dispersa se &lt;strong&gt;convertir&amp;aacute; a la representaci&amp;oacute;n de filas dispersas comprimidas&lt;/strong&gt; . Para evitar copias de memoria innecesarias, se recomienda elegir la representaci&amp;oacute;n CSR o CSC en sentido ascendente.</target>
        </trans-unit>
        <trans-unit id="0ac4948c4f86990406e6391d28cab3438b2d6038" translate="yes" xml:space="preserve">
          <source>Note that the transformations successfully map the data to a normal distribution when applied to certain datasets, but are ineffective with others. This highlights the importance of visualizing the data before and after transformation.</source>
          <target state="translated">Obsérvese que las transformaciones asignan con éxito los datos a una distribución normal cuando se aplican a ciertos conjuntos de datos,pero son ineficaces con otros.Esto resalta la importancia de visualizar los datos antes y después de la transformación.</target>
        </trans-unit>
        <trans-unit id="c025c974076c003b893079ae24539cfe87c45c45" translate="yes" xml:space="preserve">
          <source>Note that the use of &lt;code&gt;memory&lt;/code&gt; to enable caching becomes interesting when the fitting of a transformer is costly.</source>
          <target state="translated">Tenga en cuenta que el uso de la &lt;code&gt;memory&lt;/code&gt; para habilitar el almacenamiento en cach&amp;eacute; se vuelve interesante cuando la instalaci&amp;oacute;n de un transformador es costosa.</target>
        </trans-unit>
        <trans-unit id="e3bd8ce7db50d77dd828df23ba8a7913ea07b656" translate="yes" xml:space="preserve">
          <source>Note that there are many different formulations for the Sparse PCA problem. The one implemented here is based on &lt;a href=&quot;#mrl09&quot; id=&quot;id3&quot;&gt;[Mrl09]&lt;/a&gt; . The optimization problem solved is a PCA problem (dictionary learning) with an \(\ell_1\) penalty on the components:</source>
          <target state="translated">Tenga en cuenta que existen muchas formulaciones diferentes para el problema de la PCA dispersa. El que se implementa aqu&amp;iacute; se basa en &lt;a href=&quot;#mrl09&quot; id=&quot;id3&quot;&gt;[Mrl09]&lt;/a&gt; . El problema de optimizaci&amp;oacute;n resuelto es un problema de PCA (aprendizaje de diccionario) con una penalizaci&amp;oacute;n \ (\ ell_1 \) en los componentes:</target>
        </trans-unit>
        <trans-unit id="3533aed52b9c93cbfd7c732492e759ef81f9eff6" translate="yes" xml:space="preserve">
          <source>Note that there exist a lot of different clustering criteria and associated algorithms. The simplest clustering algorithm is &lt;a href=&quot;../../modules/clustering#k-means&quot;&gt;K-means&lt;/a&gt;.</source>
          <target state="translated">Tenga en cuenta que existen muchos criterios de agrupaci&amp;oacute;n diferentes y algoritmos asociados. El algoritmo de agrupamiento m&amp;aacute;s simple es &lt;a href=&quot;../../modules/clustering#k-means&quot;&gt;K-means&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="7a1a308b56337fe667b4a60765401b66807cafaf" translate="yes" xml:space="preserve">
          <source>Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.</source>
          <target state="translated">Tenga en cuenta que estos pesos se multiplicarán por el peso_muestra (pasado por el método de ajuste)si se especifica el peso_muestra.</target>
        </trans-unit>
        <trans-unit id="523c4300803e2407441df32761d9ac234d32f175" translate="yes" xml:space="preserve">
          <source>Note that theta are typically the log-transformed values of the kernel&amp;rsquo;s hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale.</source>
          <target state="translated">Tenga en cuenta que theta son t&amp;iacute;picamente los valores transformados logar&amp;iacute;tmicamente de los hiperpar&amp;aacute;metros del kernel, ya que esta representaci&amp;oacute;n del espacio de b&amp;uacute;squeda es m&amp;aacute;s adecuada para la b&amp;uacute;squeda de hiperpar&amp;aacute;metros, ya que los hiperpar&amp;aacute;metros como las escalas de longitud viven naturalmente en una escala logar&amp;iacute;tmica.</target>
        </trans-unit>
        <trans-unit id="18d756a791b41973e0843ab0a78a9e37c703da28" translate="yes" xml:space="preserve">
          <source>Note that this accuracy of this l1-penalized linear model is significantly below what can be reached by an l2-penalized linear model or a non-linear multi-layer perceptron model on this dataset.</source>
          <target state="translated">Nótese que la precisión de este modelo lineal con penalización de l1 está significativamente por debajo de lo que se puede alcanzar con un modelo lineal con penalización de l2 o un modelo de perceptrón no lineal de múltiples capas en este conjunto de datos.</target>
        </trans-unit>
        <trans-unit id="fe64330213465e1693b793ed059df249f5fb9ff2" translate="yes" xml:space="preserve">
          <source>Note that this component typically should not be used in a vanilla &lt;code&gt;Pipeline&lt;/code&gt; consisting of transformers and a classifier, but rather could be added using a &lt;code&gt;FeatureUnion&lt;/code&gt; or &lt;code&gt;ColumnTransformer&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1586f7c06fc3985d60451a7a19048e48e062430" translate="yes" xml:space="preserve">
          <source>Note that this compound kernel returns the results of all simple kernel stacked along an additional axis.</source>
          <target state="translated">Obsérvese que este núcleo compuesto devuelve los resultados de todos los núcleos simples apilados a lo largo de un eje adicional.</target>
        </trans-unit>
        <trans-unit id="31acdd30123a3b6dcbfca492a99f8cbc9dc2455a" translate="yes" xml:space="preserve">
          <source>Note that this computation of feature importance is based on entropy, and it is distinct from &lt;a href=&quot;generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;sklearn.inspection.permutation_importance&lt;/code&gt;&lt;/a&gt; which is based on permutation of the features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70f8f8292a30b78b7e2885afabc408eef407b785" translate="yes" xml:space="preserve">
          <source>Note that this definition is not valid if \(\beta \in (0; 1)\), yet it can be continuously extended to the definitions of \(d_{KL}\) and \(d_{IS}\) respectively.</source>
          <target state="translated">Nótese que esta definición no es válida si \ ~ (0;1)),sin embargo,puede ser ampliada continuamente a las definiciones de \ ~ (d_{KL})y \ ~ (d_{IS}),respectivamente.</target>
        </trans-unit>
        <trans-unit id="7550e059eb4d092ae42a40cda726bb20131c9e24" translate="yes" xml:space="preserve">
          <source>Note that this estimator is different from the R implementation of Robust Regression (&lt;a href=&quot;http://www.ats.ucla.edu/stat/r/dae/rreg.htm&quot;&gt;http://www.ats.ucla.edu/stat/r/dae/rreg.htm&lt;/a&gt;) because the R implementation does a weighted least squares implementation with weights given to each sample on the basis of how much the residual is greater than a certain threshold.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5472d869ea9e0f8e4cfcc121937d62eb4599c58a" translate="yes" xml:space="preserve">
          <source>Note that this example is, however, only an illustration since for this specific case fitting PCA is not necessarily slower than loading the cache. Hence, use the &lt;code&gt;memory&lt;/code&gt; constructor parameter when the fitting of a transformer is costly.</source>
          <target state="translated">Sin embargo, tenga en cuenta que este ejemplo es solo una ilustraci&amp;oacute;n, ya que para este caso espec&amp;iacute;fico, ajustar PCA no es necesariamente m&amp;aacute;s lento que cargar el cach&amp;eacute;. Por lo tanto, use el par&amp;aacute;metro del constructor de &lt;code&gt;memory&lt;/code&gt; cuando la instalaci&amp;oacute;n de un transformador sea costosa.</target>
        </trans-unit>
        <trans-unit id="1b5bac58d61d7142976dd586739448ed8787f73e" translate="yes" xml:space="preserve">
          <source>Note that this format is not meant to be used to implicitly store missing values in the matrix because it would densify it at transform time. Missing values encoded by 0 must be used with dense input.</source>
          <target state="translated">Obsérvese que este formato no está pensado para almacenar implícitamente los valores perdidos en la matriz porque la densificaría en el momento de la transformación.Los valores perdidos codificados con 0 deben ser usados con entrada densa.</target>
        </trans-unit>
        <trans-unit id="ceed59ec0d8d185c9512413b150620f381e9c0c0" translate="yes" xml:space="preserve">
          <source>Note that this function does not regenerate the original data due to discretization rounding.</source>
          <target state="translated">Obsérvese que esta función no regenera los datos originales debido al redondeo de la discretización.</target>
        </trans-unit>
        <trans-unit id="90f3882ef5e6cb2ec08d6d3659b834d53aaa84d9" translate="yes" xml:space="preserve">
          <source>Note that this gives us a different indication than the graph, as the graph reflects conditional relations between variables, while the clustering reflects marginal properties: variables clustered together can be considered as having a similar impact at the level of the full stock market.</source>
          <target state="translated">Obsérvese que esto nos da una indicación diferente a la del gráfico,ya que éste refleja las relaciones condicionales entre las variables,mientras que la agrupación refleja las propiedades marginales:puede considerarse que las variables agrupadas tienen un impacto similar a nivel del mercado de valores completo.</target>
        </trans-unit>
        <trans-unit id="29fe04606c06b888c8ec9e6f0120963e08f606ce" translate="yes" xml:space="preserve">
          <source>Note that this is always a dense array.</source>
          <target state="translated">Tengan en cuenta que este es siempre un conjunto denso.</target>
        </trans-unit>
        <trans-unit id="8400da57b096333e7a778582f2569282a236fe34" translate="yes" xml:space="preserve">
          <source>Note that this is stochastic, and that if random_state is not fixed, repeated calls, or permuted input, will yield different results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="426217e7254990be151f425ed53a8b743a92e13d" translate="yes" xml:space="preserve">
          <source>Note that this two-dimensional example is very degenerate: generally the number of features would be much greater than the &amp;ldquo;document length&amp;rdquo;, while here we have much larger documents than vocabulary. Similarly, with &lt;code&gt;n_classes &amp;gt; n_features&lt;/code&gt;, it is much less likely that a feature distinguishes a particular class.</source>
          <target state="translated">Tenga en cuenta que este ejemplo bidimensional es muy degenerado: generalmente el n&amp;uacute;mero de caracter&amp;iacute;sticas ser&amp;iacute;a mucho mayor que la &quot;longitud del documento&quot;, mientras que aqu&amp;iacute; tenemos documentos mucho m&amp;aacute;s grandes que vocabulario. De manera similar, con &lt;code&gt;n_classes &amp;gt; n_features&lt;/code&gt; , es mucho menos probable que una caracter&amp;iacute;stica distinga a una clase en particular.</target>
        </trans-unit>
        <trans-unit id="dcf3e0855a66eb55e0eddd9daaf862dddfda1dac" translate="yes" xml:space="preserve">
          <source>Note that this type is the most specific type that can be inferred. For example:</source>
          <target state="translated">Tenga en cuenta que este tipo es el más específico que se puede inferir.Por ejemplo:</target>
        </trans-unit>
        <trans-unit id="1fefb84f794ce8a86674757b08d8dabfe97347de" translate="yes" xml:space="preserve">
          <source>Note that this will affect all uses of &lt;a href=&quot;generated/sklearn.utils.assert_all_finite#sklearn.utils.assert_all_finite&quot;&gt;&lt;code&gt;sklearn.utils.assert_all_finite&lt;/code&gt;&lt;/a&gt; within the context.</source>
          <target state="translated">Tenga en cuenta que esto afectar&amp;aacute; a todos los usos de &lt;a href=&quot;generated/sklearn.utils.assert_all_finite#sklearn.utils.assert_all_finite&quot;&gt; &lt;code&gt;sklearn.utils.assert_all_finite&lt;/code&gt; &lt;/a&gt; dentro del contexto.</target>
        </trans-unit>
        <trans-unit id="ab32001c49d58b4f0c9d94bbfb77f7ddeaf05601" translate="yes" xml:space="preserve">
          <source>Note that those results can be highly dependent on the value of &lt;code&gt;learning_rate_init&lt;/code&gt;.</source>
          <target state="translated">Tenga en cuenta que esos resultados pueden depender en gran medida del valor de &lt;code&gt;learning_rate_init&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="aa786acd948a782d7b514486d406120e9b9bf46a" translate="yes" xml:space="preserve">
          <source>Note that unlike standard cross-validation methods, successive training sets are supersets of those that come before them.</source>
          <target state="translated">Obsérvese que,a diferencia de los métodos estándar de validación cruzada,los conjuntos sucesivos de entrenamiento son superpuestos a los que les preceden.</target>
        </trans-unit>
        <trans-unit id="be1d5d21cf434df3c562c8f7229d77ef9e790ff3" translate="yes" xml:space="preserve">
          <source>Note that we could have used the least squares loss for the &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; model. This would wrongly assume a normal distributed response variable as does the &lt;code&gt;Ridge&lt;/code&gt; model, and possibly also lead to slightly negative predictions. However the gradient boosted trees would still perform relatively well and in particular better than &lt;code&gt;PoissonRegressor&lt;/code&gt; thanks to the flexibility of the trees combined with the large number of training samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b632488ec02d373b59188cfae81036b1d7135a34" translate="yes" xml:space="preserve">
          <source>Note that when using dictionary learning to extract a representation (e.g. for sparse coding) clustering can be a good proxy to learn the dictionary. For instance the &lt;a href=&quot;generated/sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt;&lt;code&gt;MiniBatchKMeans&lt;/code&gt;&lt;/a&gt; estimator is computationally efficient and implements on-line learning with a &lt;code&gt;partial_fit&lt;/code&gt; method.</source>
          <target state="translated">Tenga en cuenta que cuando se utiliza el aprendizaje de diccionario para extraer una representaci&amp;oacute;n (por ejemplo, para codificaci&amp;oacute;n escasa), la agrupaci&amp;oacute;n en cl&amp;uacute;steres puede ser un buen proxy para aprender el diccionario. Por ejemplo, el &lt;a href=&quot;generated/sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt; &lt;code&gt;MiniBatchKMeans&lt;/code&gt; &lt;/a&gt; estimador es computacionalmente eficiente y aperos de aprendizaje en l&amp;iacute;nea con un &lt;code&gt;partial_fit&lt;/code&gt; m&amp;eacute;todo.</target>
        </trans-unit>
        <trans-unit id="b38cc6be43472cae197ca98a60df5eafaa29d73f" translate="yes" xml:space="preserve">
          <source>Note that with all these strategies, the &lt;code&gt;predict&lt;/code&gt; method completely ignores the input data!</source>
          <target state="translated">Tenga en cuenta que con todas estas estrategias, el m&amp;eacute;todo de &lt;code&gt;predict&lt;/code&gt; ignora por completo los datos de entrada.</target>
        </trans-unit>
        <trans-unit id="75c6be4694b9eabe59018390268fd820a052b7d5" translate="yes" xml:space="preserve">
          <source>Note that, by default, scikit-learn uses its embedded (vendored) version of joblib. A configuration switch (documented below) controls this behavior.</source>
          <target state="translated">Tengan en cuenta que,por defecto,scikit-learn utiliza su versión incrustada (vendida)de joblib.Un interruptor de configuración (documentado más abajo)controla este comportamiento.</target>
        </trans-unit>
        <trans-unit id="ae98ee9bcd2e5d0854b3eaebde47d02a011f815f" translate="yes" xml:space="preserve">
          <source>Note that, in this notation, it&amp;rsquo;s assumed that the observation \(y_i\) takes values in the set \({-1, 1}\) at trial \(i\).</source>
          <target state="translated">Tenga en cuenta que, en esta notaci&amp;oacute;n, se supone que la observaci&amp;oacute;n \ (y_i \) toma valores en el conjunto \ ({- 1, 1} \) en la prueba \ (i \).</target>
        </trans-unit>
        <trans-unit id="e6bd4762fd372de20f9b98cd74d805456dc39e3e" translate="yes" xml:space="preserve">
          <source>Note that, in this notation, it&amp;rsquo;s assumed that the target \(y_i\) takes values in the set \({-1, 1}\) at trial \(i\). We can also see that Elastic-Net is equivalent to \(\ell_1\) when \(\rho = 1\) and equivalent to \(\ell_2\) when \(\rho=0\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79d7c15c2a930f99c60199078ea59a499e19fbc8" translate="yes" xml:space="preserve">
          <source>Note that, the color range of the precision matrices is tweaked to improve readability of the figure. The full range of values of the empirical precision is not displayed.</source>
          <target state="translated">Obsérvese que la gama de colores de las matrices de precisión se ha ajustado para mejorar la legibilidad de la figura.El rango completo de valores de la precisión empírica no se muestra.</target>
        </trans-unit>
        <trans-unit id="285f98e8d01e4962eff6724b78a3c6724d0931e6" translate="yes" xml:space="preserve">
          <source>Note that:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5bd74df6988f671f3aaedf9864231e7cb14cad2a" translate="yes" xml:space="preserve">
          <source>Note the use of a generator comprehension, which introduces laziness into the feature extraction: tokens are only processed on demand from the hasher.</source>
          <target state="translated">Obsérvese el uso de un generador de comprensión,que introduce la pereza en la extracción de características:las fichas sólo se procesan a petición del hasher.</target>
        </trans-unit>
        <trans-unit id="1984eb2d93c7fabc5820f74c1a6deb67cdefe2d3" translate="yes" xml:space="preserve">
          <source>Note! the synthetic feature weight is subject to l1/l2 regularization as all other features. To lessen the effect of regularization on synthetic feature weight (and therefore on the intercept) intercept_scaling has to be increased.</source>
          <target state="translated">Nota! el peso del rasgo sintético está sujeto a una regularización de l1/l2 como todos los demás rasgos.Para disminuir el efecto de la regularización en el peso del rasgo sintético (y por lo tanto en la intercepción),la escala interceptada debe ser aumentada.</target>
        </trans-unit>
        <trans-unit id="83423c198b6099edba08f185f940042d5dba3b79" translate="yes" xml:space="preserve">
          <source>Note:</source>
          <target state="translated">Note:</target>
        </trans-unit>
        <trans-unit id="b85cf8e5cd9762e5dd866d246742bbab950fd9b8" translate="yes" xml:space="preserve">
          <source>Note: &lt;code&gt;LeaveOneOut()&lt;/code&gt; is equivalent to &lt;code&gt;KFold(n_splits=n)&lt;/code&gt; and &lt;code&gt;LeavePOut(p=1)&lt;/code&gt; where &lt;code&gt;n&lt;/code&gt; is the number of samples.</source>
          <target state="translated">Nota: &lt;code&gt;LeaveOneOut()&lt;/code&gt; es equivalente a &lt;code&gt;KFold(n_splits=n)&lt;/code&gt; y &lt;code&gt;LeavePOut(p=1)&lt;/code&gt; donde &lt;code&gt;n&lt;/code&gt; es el n&amp;uacute;mero de muestras.</target>
        </trans-unit>
        <trans-unit id="31e8baf167adcc23a2adc9382a5f1918c617d9e9" translate="yes" xml:space="preserve">
          <source>Note: &lt;code&gt;LeavePOut(p)&lt;/code&gt; is NOT equivalent to &lt;code&gt;KFold(n_splits=n_samples // p)&lt;/code&gt; which creates non-overlapping test sets.</source>
          <target state="translated">Nota: &lt;code&gt;LeavePOut(p)&lt;/code&gt; NO es equivalente a &lt;code&gt;KFold(n_splits=n_samples // p)&lt;/code&gt; que crea conjuntos de prueba que no se superponen.</target>
        </trans-unit>
        <trans-unit id="bea1be387c131c6f224a4e72fba375bf5b015ed7" translate="yes" xml:space="preserve">
          <source>Note: Currently &lt;code&gt;TSNE(metric='precomputed')&lt;/code&gt; does not modify the precomputed distances, and thus assumes that precomputed euclidean distances are squared. In future versions, a parameter in TSNE will control the optional squaring of precomputed distances (see #12401).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="432e1c4e6e288e7db18e2c42d6e410c6adeb71c8" translate="yes" xml:space="preserve">
          <source>Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times &lt;code&gt;n_samples&lt;/code&gt; (i.e. the sum of squares of each column totals 1).</source>
          <target state="translated">Nota: Cada una de estas 10 variables de caracter&amp;iacute;sticas se ha centrado en la media y se ha escalado seg&amp;uacute;n la desviaci&amp;oacute;n est&amp;aacute;ndar multiplicada por &lt;code&gt;n_samples&lt;/code&gt; (es decir, la suma de los cuadrados de cada columna suma 1).</target>
        </trans-unit>
        <trans-unit id="02b388a51976f4b3884d316ec9ed343cbbaf27f0" translate="yes" xml:space="preserve">
          <source>Note: Evaluation of eval_gradient is not analytic but numeric and all</source>
          <target state="translated">Nota:La evaluación de eval_gradient no es analítica sino numérica y toda</target>
        </trans-unit>
        <trans-unit id="f97fa8efa81cc34898992868ec31edd01fe1abf9" translate="yes" xml:space="preserve">
          <source>Note: For larger datasets (n_samples &amp;gt;= 10000), please refer to &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;sklearn.ensemble.HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5290473efc5984775f303f01f61e6c7775623f5" translate="yes" xml:space="preserve">
          <source>Note: If a lambda is used as the function, then the resulting transformer will not be pickleable.</source>
          <target state="translated">Nota:Si se utiliza un lambda como función,entonces el transformador resultante no será encurtido.</target>
        </trans-unit>
        <trans-unit id="78c3e35dab7ccbe33bae1787c55dabbd050c5a91" translate="yes" xml:space="preserve">
          <source>Note: In KNeighborsTransformer we use the definition which includes each training point as its own neighbor in the count of &lt;code&gt;n_neighbors&lt;/code&gt;, and for compatibility reasons, one extra neighbor is computed when &lt;code&gt;mode == 'distance'&lt;/code&gt;. Please note that we do the same in the proposed wrappers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab7df665871a4d2a9feffe69dfea4e192c2cd75e" translate="yes" xml:space="preserve">
          <source>Note: L2 normalization is also known as spatial sign preprocessing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09a1c78e2b9dafeb4ae2773774e2099dbe747a0e" translate="yes" xml:space="preserve">
          <source>Note: Our implementation&amp;rsquo;s score is 1 greater than the one given in Tsoumakas et al., 2010. This extends it to handle the degenerate case in which an instance has 0 true labels.</source>
          <target state="translated">Nota: La puntuaci&amp;oacute;n de nuestra implementaci&amp;oacute;n es 1 mayor que la dada en Tsoumakas et al., 2010. Esto la ampl&amp;iacute;a para manejar el caso degenerado en el que una instancia tiene 0 etiquetas verdaderas.</target>
        </trans-unit>
        <trans-unit id="956d1e2ca58f2ab0bdb4afea5546244c422bc323" translate="yes" xml:space="preserve">
          <source>Note: See the &lt;a href=&quot;../basic/tutorial#introduction&quot;&gt;Introduction to machine learning with scikit-learn Tutorial&lt;/a&gt; for a quick run-through on the basic machine learning vocabulary used within scikit-learn.</source>
          <target state="translated">Nota: Consulte el &lt;a href=&quot;../basic/tutorial#introduction&quot;&gt;tutorial Introducci&amp;oacute;n al aprendizaje autom&amp;aacute;tico con scikit-learn&lt;/a&gt; para obtener un repaso r&amp;aacute;pido del vocabulario b&amp;aacute;sico del aprendizaje autom&amp;aacute;tico que se utiliza en scikit-learn.</target>
        </trans-unit>
        <trans-unit id="7a9381252d0555984c45c1d913a85b0a19a4797d" translate="yes" xml:space="preserve">
          <source>Note: The default solver &amp;lsquo;adam&amp;rsquo; works pretty well on relatively large datasets (with thousands of training samples or more) in terms of both training time and validation score. For small datasets, however, &amp;lsquo;lbfgs&amp;rsquo; can converge faster and perform better.</source>
          <target state="translated">Nota: El solucionador predeterminado 'adam' funciona bastante bien en conjuntos de datos relativamente grandes (con miles de muestras de entrenamiento o m&amp;aacute;s) en t&amp;eacute;rminos de tiempo de entrenamiento y puntuaci&amp;oacute;n de validaci&amp;oacute;n. Sin embargo, para conjuntos de datos peque&amp;ntilde;os, 'lbfgs' puede converger m&amp;aacute;s r&amp;aacute;pido y funcionar mejor.</target>
        </trans-unit>
        <trans-unit id="271df9bc769d4f6f6224f70e1c75a6c3d0d4e15f" translate="yes" xml:space="preserve">
          <source>Note: The parameters &lt;code&gt;test_size&lt;/code&gt; and &lt;code&gt;train_size&lt;/code&gt; refer to groups, and not to samples, as in ShuffleSplit.</source>
          <target state="translated">Nota: Los par&amp;aacute;metros &lt;code&gt;test_size&lt;/code&gt; y &lt;code&gt;train_size&lt;/code&gt; se refieren a grupos y no a muestras, como en ShuffleSplit.</target>
        </trans-unit>
        <trans-unit id="d9b8539222215de6f9b7a2dc0d47dad55ab9503a" translate="yes" xml:space="preserve">
          <source>Note: a one-hot encoding of y labels should use a LabelBinarizer instead.</source>
          <target state="translated">Nota:una codificación de una sola vez de las etiquetas y debería usar un LabelBinarizer en su lugar.</target>
        </trans-unit>
        <trans-unit id="1ed0914b13c92897638e72f9758df4b91ef77876" translate="yes" xml:space="preserve">
          <source>Note: although we will make new pipelines with the processors which we wrote in the previous section for the 3 learners, the final estimator RidgeCV() does not need preprocessing of the data as it will be fed with the already preprocessed output from the 3 learners.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af48a21921f21ca5ba4feec03dc7cfdb83d643b6" translate="yes" xml:space="preserve">
          <source>Note: as k-means is optimizing a non-convex objective function, it will likely end up in a local optimum. Several runs with independent random init might be necessary to get a good convergence.</source>
          <target state="translated">Nota:como k-means es la optimización de una función objetiva no convexa,es probable que termine en un óptimo local.Podrían ser necesarias varias ejecuciones con inicio aleatorio independiente para conseguir una buena convergencia.</target>
        </trans-unit>
        <trans-unit id="3bb7791854593a3b717f90311f25871cac16570c" translate="yes" xml:space="preserve">
          <source>Note: contrary to other cross-validation strategies, random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets.</source>
          <target state="translated">Nota:a diferencia de otras estrategias de validación cruzada,las divisiones aleatorias no garantizan que todos los pliegues sean diferentes,aunque es muy probable que así sea en el caso de conjuntos de datos de gran tamaño.</target>
        </trans-unit>
        <trans-unit id="ec23f8c549cab8298e97ba96412d8acd5b97a819" translate="yes" xml:space="preserve">
          <source>Note: fitting on sparse input will override the setting of this parameter, using brute force.</source>
          <target state="translated">Nota:el ajuste en la entrada dispersa anulará el ajuste de este parámetro,usando la fuerza bruta.</target>
        </trans-unit>
        <trans-unit id="f2a5a8b06402f76d2a1b1f28ad2e90efb04ea841" translate="yes" xml:space="preserve">
          <source>Note: if you manage your own numerical data it is recommended to use an optimized file format such as HDF5 to reduce data load times. Various libraries such as H5Py, PyTables and pandas provides a Python interface for reading and writing data in that format.</source>
          <target state="translated">Nota:si usted maneja sus propios datos numéricos se recomienda utilizar un formato de archivo optimizado como el HDF5 para reducir los tiempos de carga de datos.Varias bibliotecas como H5Py,PyTables y pandas proporcionan una interfaz Python para leer y escribir datos en ese formato.</target>
        </trans-unit>
        <trans-unit id="cb39d5746d1ab528272657961084b4241cfe3f85" translate="yes" xml:space="preserve">
          <source>Note: in the plot, &amp;ldquo;unlabeled samples&amp;rdquo; does not mean that we don&amp;rsquo;t know the labels (as in semi-supervised learning) but that the samples simply do &lt;em&gt;not&lt;/em&gt; have a label.</source>
          <target state="translated">Nota: en el gr&amp;aacute;fico, &quot;muestras sin etiqueta&quot; no significa que no conocemos las etiquetas (como en el aprendizaje semi-supervisado), sino que las muestras simplemente &lt;em&gt;no&lt;/em&gt; tienen una etiqueta.</target>
        </trans-unit>
        <trans-unit id="403fd153dcfc1c72561472b5e34372d5de58734f" translate="yes" xml:space="preserve">
          <source>Note: like the ShuffleSplit strategy, stratified random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets.</source>
          <target state="translated">Nota:al igual que la estrategia ShuffleSplit,las divisiones aleatorias estratificadas no garantizan que todos los pliegues sean diferentes,aunque es muy probable que así sea en el caso de conjuntos de datos de gran tamaño.</target>
        </trans-unit>
        <trans-unit id="12964c4f090e67fee00edc80b29c8ee9b28b7b3b" translate="yes" xml:space="preserve">
          <source>Note: the implementation of &lt;code&gt;inverse_transform&lt;/code&gt; in &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;svd_solver='randomized'&lt;/code&gt; is not the exact inverse transform of &lt;code&gt;transform&lt;/code&gt; even when &lt;code&gt;whiten=False&lt;/code&gt; (default).</source>
          <target state="translated">Nota: la implementaci&amp;oacute;n de &lt;code&gt;inverse_transform&lt;/code&gt; en &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; con &lt;code&gt;svd_solver='randomized'&lt;/code&gt; no es la transformaci&amp;oacute;n inversa exacta de &lt;code&gt;transform&lt;/code&gt; incluso cuando &lt;code&gt;whiten=False&lt;/code&gt; (predeterminado).</target>
        </trans-unit>
        <trans-unit id="f5990a880094bfe59d250a6cb72959923dee6858" translate="yes" xml:space="preserve">
          <source>Note: the list is re-created at each call to the property in order to reduce the object memory footprint by not storing the sampling data. Thus fetching the property may be slower than expected.</source>
          <target state="translated">Nota:la lista se vuelve a crear en cada llamada a la propiedad para reducir la huella de la memoria del objeto al no almacenar los datos de muestreo.Por lo tanto,la recuperación de la propiedad puede ser más lenta de lo esperado.</target>
        </trans-unit>
        <trans-unit id="b4fa4a5f4c66fdf91fefb2f5d8a9d04622e730f8" translate="yes" xml:space="preserve">
          <source>Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than &lt;code&gt;max_features&lt;/code&gt; features.</source>
          <target state="translated">Nota: la b&amp;uacute;squeda de una divisi&amp;oacute;n no se detiene hasta que se encuentra al menos una partici&amp;oacute;n v&amp;aacute;lida de las muestras de nodos, incluso si requiere inspeccionar de manera efectiva m&amp;aacute;s de &lt;code&gt;max_features&lt;/code&gt; caracter&amp;iacute;sticas de max_features .</target>
        </trans-unit>
        <trans-unit id="4064827fd69033d32661395cc63853ae193f7d3a" translate="yes" xml:space="preserve">
          <source>Note: this implementation can be used with binary, multiclass and multilabel classification, but some restrictions apply (see Parameters).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5af1722805bd08a73be9d8b2f383c0eb417bbdd9" translate="yes" xml:space="preserve">
          <source>Note: this implementation is restricted to the binary classification task or multilabel classification task in label indicator format.</source>
          <target state="translated">Nota:esta aplicación se limita a la tarea de clasificación binaria o a la tarea de clasificación multi-etiqueta en formato de indicador de etiqueta.</target>
        </trans-unit>
        <trans-unit id="2dab9af505b98147ed8303644f1fce8db17174c7" translate="yes" xml:space="preserve">
          <source>Note: this implementation is restricted to the binary classification task or multilabel classification task.</source>
          <target state="translated">Nota:esta aplicación está restringida a la tarea de clasificación binaria o a la tarea de clasificación multi-etiqueta.</target>
        </trans-unit>
        <trans-unit id="229c71e40bdbb475df5a5f3c46414bb1e9fb11cf" translate="yes" xml:space="preserve">
          <source>Note: this implementation is restricted to the binary classification task.</source>
          <target state="translated">Nota:esta aplicación se limita a la tarea de clasificación binaria.</target>
        </trans-unit>
        <trans-unit id="77503a53930a4c6773bcfd9900ee0500aa085f94" translate="yes" xml:space="preserve">
          <source>Note: with the optional parameter &lt;code&gt;svd_solver='randomized'&lt;/code&gt;, we also need to give &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; the size of the lower-dimensional space &lt;code&gt;n_components&lt;/code&gt; as a mandatory input parameter.</source>
          <target state="translated">Nota: con el par&amp;aacute;metro opcional &lt;code&gt;svd_solver='randomized'&lt;/code&gt; , tambi&amp;eacute;n necesitamos darle a &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; el tama&amp;ntilde;o del espacio de menor dimensi&amp;oacute;n &lt;code&gt;n_components&lt;/code&gt; como par&amp;aacute;metro de entrada obligatorio.</target>
        </trans-unit>
        <trans-unit id="70440046a3dc2e079f23ee1c57dfa76669b732aa" translate="yes" xml:space="preserve">
          <source>Notes</source>
          <target state="translated">Notes</target>
        </trans-unit>
        <trans-unit id="8365e7c537a7bde197e775fc685e729bf7dcde79" translate="yes" xml:space="preserve">
          <source>Notice that this class does not support sparse input. See &lt;a href=&quot;sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt;&lt;code&gt;TruncatedSVD&lt;/code&gt;&lt;/a&gt; for an alternative with sparse data.</source>
          <target state="translated">Tenga en cuenta que esta clase no admite entradas dispersas. Consulte &lt;a href=&quot;sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt; &lt;code&gt;TruncatedSVD&lt;/code&gt; &lt;/a&gt; para obtener una alternativa con datos escasos.</target>
        </trans-unit>
        <trans-unit id="24a6d73ad577eece3a7c4a8079ee0685b19c5eef" translate="yes" xml:space="preserve">
          <source>Novelty detection</source>
          <target state="translated">Detección de novedades</target>
        </trans-unit>
        <trans-unit id="0c6ce6f3a8c7f0ac9123407bf644e00c93b8a85c" translate="yes" xml:space="preserve">
          <source>Novelty detection with Local Outlier Factor (LOF)</source>
          <target state="translated">Detección de novedades con el Factor Atípico Local (LOF)</target>
        </trans-unit>
        <trans-unit id="d039fa812c1beff75961eedb7fd0d56d4bd6cef8" translate="yes" xml:space="preserve">
          <source>Novelty detection with Local Outlier Factor is illustrated below.</source>
          <target state="translated">La detección de novedades con el Factor Atípico Local se ilustra a continuación.</target>
        </trans-unit>
        <trans-unit id="0baacee2d29c362912e19aeae2a56e9b5de18251" translate="yes" xml:space="preserve">
          <source>November, 1995</source>
          <target state="translated">Noviembre de 1995</target>
        </trans-unit>
        <trans-unit id="f56b60fb36ba6e7108f33fd204674d75974c9ca0" translate="yes" xml:space="preserve">
          <source>Now looking at the computation time of the different parts, we see that the vectorization is much more expensive than learning itself. From the different algorithms, &lt;code&gt;MultinomialNB&lt;/code&gt; is the most expensive, but its overhead can be mitigated by increasing the size of the mini-batches (exercise: change &lt;code&gt;minibatch_size&lt;/code&gt; to 100 and 10000 in the program and compare).</source>
          <target state="translated">Ahora mirando el tiempo de c&amp;aacute;lculo de las diferentes partes, vemos que la vectorizaci&amp;oacute;n es mucho m&amp;aacute;s cara que el aprendizaje en s&amp;iacute;. De los diferentes algoritmos, &lt;code&gt;MultinomialNB&lt;/code&gt; es el m&amp;aacute;s caro, pero su sobrecarga se puede mitigar aumentando el tama&amp;ntilde;o de los mini lotes (ejercicio: cambie &lt;code&gt;minibatch_size&lt;/code&gt; a 100 y 10000 en el programa y compare).</target>
        </trans-unit>
        <trans-unit id="e921254526b0e2e9cacf92a70632a272e818cfb0" translate="yes" xml:space="preserve">
          <source>Now that the coefficients have been scaled, we can safely compare them.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="703648eec6ac2a9ecd5332ac2370f3cbb5d40c50" translate="yes" xml:space="preserve">
          <source>Now that we have our features, we can train a classifier to try to predict the category of a post. Let&amp;rsquo;s start with a &lt;a href=&quot;../../modules/naive_bayes#naive-bayes&quot;&gt;na&amp;iuml;ve Bayes&lt;/a&gt; classifier, which provides a nice baseline for this task. &lt;code&gt;scikit-learn&lt;/code&gt; includes several variants of this classifier; the one most suitable for word counts is the multinomial variant:</source>
          <target state="translated">Ahora que tenemos nuestras funciones, podemos entrenar a un clasificador para que intente predecir la categor&amp;iacute;a de una publicaci&amp;oacute;n. Comencemos con un clasificador de &lt;a href=&quot;../../modules/naive_bayes#naive-bayes&quot;&gt;Bayes ingenuo&lt;/a&gt; , que proporciona una buena base para esta tarea. &lt;code&gt;scikit-learn&lt;/code&gt; incluye varias variantes de este clasificador; la m&amp;aacute;s adecuada para el recuento de palabras es la variante multinomial:</target>
        </trans-unit>
        <trans-unit id="88e8cd01d787ca5c585c186900aea23cd932893c" translate="yes" xml:space="preserve">
          <source>Now we can use Ames Housing dataset to make the predictions. We check the performance of each individual predictor as well as of the stack of the regressors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c77da09ad9df95918caa9589e1cfa5804c7aace6" translate="yes" xml:space="preserve">
          <source>Now we create a &lt;code&gt;FeatureUnion&lt;/code&gt;. All features will be imputed using &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;SimpleImputer&lt;/code&gt;&lt;/a&gt;, in order to enable classifiers to work with this data. Additionally, it adds the the indicator variables from &lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e66fc30e8519d1cd12806317bc82ad0b2345f16" translate="yes" xml:space="preserve">
          <source>Now we want to select the two features which are the most important. SelectFromModel() allows for setting the threshold. Only the features with the &lt;code&gt;coef_&lt;/code&gt; higher than the threshold will remain. Here, we want to set the threshold slightly above the third highest &lt;code&gt;coef_&lt;/code&gt; calculated by LassoCV() from our data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c18c8137b5b9d8aae8dc57c26f7d6b41951afd4" translate="yes" xml:space="preserve">
          <source>Now we will estimate the score on the data where the missing values are replaced by 0:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b6f8334bd6af42d0add5e2131513b016d9f6e6d" translate="yes" xml:space="preserve">
          <source>Now we will initiate the gradient boosting regressors and fit it with our training data. Let&amp;rsquo;s also look and the mean squared error on the test data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c5cf2d42930f189f93938b87f35b21f55ff5f6c" translate="yes" xml:space="preserve">
          <source>Now we will use each of the regressors to make the 20 first predictions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="936a8dbed55baf9b2e1ebda09b75843de98173ab" translate="yes" xml:space="preserve">
          <source>Now we will write a function which will score the results on the differently imputed data. Let&amp;rsquo;s look at each imputer separately:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39c382cf98b09c769e0ece49478f8e5a21269790" translate="yes" xml:space="preserve">
          <source>Now you can &lt;em&gt;predict&lt;/em&gt; new values. In this case, you&amp;rsquo;ll predict using the last image from &lt;code&gt;digits.data&lt;/code&gt;. By predicting, you&amp;rsquo;ll determine the image from the training set that best matches the last image.</source>
          <target state="translated">Ahora puede &lt;em&gt;predecir&lt;/em&gt; nuevos valores. En este caso, predecir&amp;aacute; utilizando la &amp;uacute;ltima imagen de &lt;code&gt;digits.data&lt;/code&gt; . Al predecir, determinar&amp;aacute; la imagen del conjunto de entrenamiento que mejor se adapta a la &amp;uacute;ltima imagen.</target>
        </trans-unit>
        <trans-unit id="4bde0a1195bac7469e935b78a194104a68da7a29" translate="yes" xml:space="preserve">
          <source>Now, if we repeat this computation for the remaining 2 terms in the document, we get</source>
          <target state="translated">Ahora,si repetimos este cálculo para los 2 términos restantes en el documento,obtenemos</target>
        </trans-unit>
        <trans-unit id="ece88bcd9ec161c2a2872c2fb61e36a0d64c7a18" translate="yes" xml:space="preserve">
          <source>Now, without any further assumptions the idea of having a latent variable \(h\) would be superfluous &amp;ndash; \(x\) can be completely modelled with a mean and a covariance. We need to impose some more specific structure on one of these two parameters. A simple additional assumption regards the structure of the error covariance \(\Psi\):</source>
          <target state="translated">Ahora, sin m&amp;aacute;s suposiciones, la idea de tener una variable latente \ (h \) ser&amp;iacute;a superflua; \ (x \) se puede modelar completamente con una media y una covarianza. Necesitamos imponer una estructura m&amp;aacute;s espec&amp;iacute;fica a uno de estos dos par&amp;aacute;metros. Un supuesto adicional simple se refiere a la estructura de la covarianza de error \ (\ Psi \):</target>
        </trans-unit>
        <trans-unit id="a31389fe4ff0ebc6e5c5d38e5dab56436f6bc483" translate="yes" xml:space="preserve">
          <source>Nu Support Vector Regression.</source>
          <target state="translated">Regresión vectorial de Nu Support.</target>
        </trans-unit>
        <trans-unit id="a9b51312b4e809b61f7b24f233552372d8a4d343" translate="yes" xml:space="preserve">
          <source>Nu-Support Vector Classification.</source>
          <target state="translated">Clasificación de Vectores de Nu-Support.</target>
        </trans-unit>
        <trans-unit id="3fd1d9cda92e08af6fee8cba19fd970cf1f0632b" translate="yes" xml:space="preserve">
          <source>Number between 0 and 1 passed to elastic net (scaling between l1 and l2 penalties). &lt;code&gt;l1_ratio=1&lt;/code&gt; corresponds to the Lasso.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7957f8886c98fbf5a70e65a8ee06b411dfa2ec9d" translate="yes" xml:space="preserve">
          <source>Number of Attributes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28831313b9efda1fb2d5e62ae541d82eeaf2e628" translate="yes" xml:space="preserve">
          <source>Number of Attributes:</source>
          <target state="translated">Número de atributos:</target>
        </trans-unit>
        <trans-unit id="2bbc98640e09a456dee6d19b3fcc0a288b212310" translate="yes" xml:space="preserve">
          <source>Number of CPU cores used during the cross-validation loop. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">N&amp;uacute;mero de n&amp;uacute;cleos de CPU utilizados durante el ciclo de validaci&amp;oacute;n cruzada. &lt;code&gt;None&lt;/code&gt; significa 1 a menos que est&amp;eacute; en un contexto &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; significa usar todos los procesadores. Consulte el &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;glosario&lt;/a&gt; para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="e0f96f6f23ce740144b8c92df340b8480f6b786d" translate="yes" xml:space="preserve">
          <source>Number of CPU cores used during the cross-validation loop. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e056a5a70210c137f261290dad04190fbc9ce82b" translate="yes" xml:space="preserve">
          <source>Number of CPU cores used when parallelizing over classes if multi_class=&amp;rsquo;ovr&amp;rsquo;&amp;rdquo;. This parameter is ignored when the &lt;code&gt;solver&lt;/code&gt; is set to &amp;lsquo;liblinear&amp;rsquo; regardless of whether &amp;lsquo;multi_class&amp;rsquo; is specified or not. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">N&amp;uacute;mero de n&amp;uacute;cleos de CPU utilizados al paralelizar clases si multi_class = 'ovr' &amp;rdquo;. Este par&amp;aacute;metro se ignora cuando el &lt;code&gt;solver&lt;/code&gt; se establece en 'liblinear' independientemente de si se especifica 'multi_class' o no. &lt;code&gt;None&lt;/code&gt; significa 1 a menos que est&amp;eacute; en un contexto &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; significa usar todos los procesadores. Consulte el &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;glosario&lt;/a&gt; para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="ba00da4689fb46c7f1453ab4c4d840dda819bf30" translate="yes" xml:space="preserve">
          <source>Number of CPU cores used when parallelizing over classes if multi_class=&amp;rsquo;ovr&amp;rsquo;&amp;rdquo;. This parameter is ignored when the &lt;code&gt;solver&lt;/code&gt; is set to &amp;lsquo;liblinear&amp;rsquo; regardless of whether &amp;lsquo;multi_class&amp;rsquo; is specified or not. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="044a045266785f2237c066206c338baa3e1d5bb2" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the cross validation. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">N&amp;uacute;mero de CPU que se utilizar&amp;aacute;n durante la validaci&amp;oacute;n cruzada. &lt;code&gt;None&lt;/code&gt; significa 1 a menos que est&amp;eacute; en un contexto &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; significa usar todos los procesadores. Consulte el &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;glosario&lt;/a&gt; para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="299b1e18443f4440c97e32fcbc5b33894e6807aa" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the cross validation. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aaf36da587212084529abec535211c954c2e7c01" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the cross validation. Note that this is used only if multiple values for l1_ratio are given. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">N&amp;uacute;mero de CPU que se utilizar&amp;aacute;n durante la validaci&amp;oacute;n cruzada. Tenga en cuenta que esto se usa solo si se dan varios valores para l1_ratio. &lt;code&gt;None&lt;/code&gt; significa 1 a menos que est&amp;eacute; en un contexto &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; significa usar todos los procesadores. Consulte el &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;glosario&lt;/a&gt; para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="abb87aba72afe118ccbcfcbd98130537908df821" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the cross validation. Note that this is used only if multiple values for l1_ratio are given. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52783b9f963f3f1690dd5d40572b3875e2a7ade7" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the resampling. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">N&amp;uacute;mero de CPU que se utilizar&amp;aacute;n durante el remuestreo. &lt;code&gt;None&lt;/code&gt; significa 1 a menos que est&amp;eacute; en un contexto &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; significa usar todos los procesadores. Consulte el &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;glosario&lt;/a&gt; para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="9b0888ca0284a2c854ae8715c4ccbdf2a4510807" translate="yes" xml:space="preserve">
          <source>Number of Instances</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2666336978a0f4e8c547b7534c07249ba6000fd" translate="yes" xml:space="preserve">
          <source>Number of Instances:</source>
          <target state="translated">Número de instancias:</target>
        </trans-unit>
        <trans-unit id="0bc3461e8033920222bec6b216692137eee9c091" translate="yes" xml:space="preserve">
          <source>Number of Monte Carlo samples per original feature. Equals the dimensionality of the computed feature space.</source>
          <target state="translated">Número de muestras de Monte Carlo por característica original.Es igual a la dimensionalidad del espacio del rasgo calculado.</target>
        </trans-unit>
        <trans-unit id="3262f2b1a48253ff0690a8a75cfdd12aae481720" translate="yes" xml:space="preserve">
          <source>Number of active features across every target for the model refit with the best hyperparameters got by cross-validating across all folds.</source>
          <target state="translated">El número de características activas en cada objetivo para el modelo reajustado con los mejores hiperparámetros obtenidos por validación cruzada en todos los pliegues.</target>
        </trans-unit>
        <trans-unit id="4cbf5cb47ecd9996ec380ef5f0f19c258c9e11e4" translate="yes" xml:space="preserve">
          <source>Number of active features across every target.</source>
          <target state="translated">Número de características activas en cada objetivo.</target>
        </trans-unit>
        <trans-unit id="4d39e5d8b3efa9d6f8372f94e39a5395c837b600" translate="yes" xml:space="preserve">
          <source>Number of active features across every target. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">N&amp;uacute;mero de funciones activas en cada objetivo. Se devuelve solo si &lt;code&gt;return_n_iter&lt;/code&gt; se establece en True.</target>
        </trans-unit>
        <trans-unit id="e0c8a9190fa0a6b6567e6260a08bbc16ad38e0e1" translate="yes" xml:space="preserve">
          <source>Number of alphas along the regularization path</source>
          <target state="translated">Número de alfas a lo largo de la ruta de regularización</target>
        </trans-unit>
        <trans-unit id="21389bf92cd8e8648f186478c091bf8c596c9371" translate="yes" xml:space="preserve">
          <source>Number of alphas along the regularization path, used for each l1_ratio.</source>
          <target state="translated">Número de alfas a lo largo del camino de regularización,utilizado para cada l1_ratio.</target>
        </trans-unit>
        <trans-unit id="cbe7afb5599ad451cab3f599179a64fd19bd9311" translate="yes" xml:space="preserve">
          <source>Number of alphas along the regularization path.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb76f13b1ca274d0ac0509e0599ee9f88692f95e" translate="yes" xml:space="preserve">
          <source>Number of best singular vectors to which to project the data for clustering.</source>
          <target state="translated">Número de mejores vectores singulares a los que proyectar los datos para la agrupación.</target>
        </trans-unit>
        <trans-unit id="669eddc43c369820a90c37333994758dabadb237" translate="yes" xml:space="preserve">
          <source>Number of binary hidden units.</source>
          <target state="translated">Número de unidades binarias ocultas.</target>
        </trans-unit>
        <trans-unit id="df5056a6b08a72e6eb298ef5a65870b5ddc8c698" translate="yes" xml:space="preserve">
          <source>Number of bins per feature. An ignored feature at index &lt;code&gt;i&lt;/code&gt; will have &lt;code&gt;n_bins_[i] == 0&lt;/code&gt;.</source>
          <target state="translated">N&amp;uacute;mero de contenedores por funci&amp;oacute;n. Una caracter&amp;iacute;stica ignorada en el &amp;iacute;ndice &lt;code&gt;i&lt;/code&gt; tendr&amp;aacute; &lt;code&gt;n_bins_[i] == 0&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d7a7f2e004236d911cb66cf34176f3d71e43ecca" translate="yes" xml:space="preserve">
          <source>Number of bins per feature. Bins whose width are too small (i.e., &amp;lt;= 1e-8) are removed with a warning.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a230a570a7b298a4731493b5111f06efb3bd3e1c" translate="yes" xml:space="preserve">
          <source>Number of bins to discretize the [0, 1] interval. A bigger number requires more data. Bins with no samples (i.e. without corresponding values in &lt;code&gt;y_prob&lt;/code&gt;) will not be returned, thus the returned arrays may have less than &lt;code&gt;n_bins&lt;/code&gt; values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e19457800c5864e1fbdcc0291b0ef620abfd78c" translate="yes" xml:space="preserve">
          <source>Number of bins. A bigger number requires more data.</source>
          <target state="translated">Número de contenedores.Un número mayor requiere más datos.</target>
        </trans-unit>
        <trans-unit id="0c552ab63ca0f87bf2127208daa3692ef5597992" translate="yes" xml:space="preserve">
          <source>Number of classes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbe9989009b56729007d1b9895a9883c9be1c338" translate="yes" xml:space="preserve">
          <source>Number of classes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f70f556044c9d189136c9439d7b869763e660892" translate="yes" xml:space="preserve">
          <source>Number of clusters after the final clustering step, which treats the subclusters from the leaves as new samples.</source>
          <target state="translated">Número de racimos después de la etapa final de agrupación,que trata los subconjuntos de las hojas como nuevas muestras.</target>
        </trans-unit>
        <trans-unit id="d93f166299b2fe351648697f50539b771bbcab5f" translate="yes" xml:space="preserve">
          <source>Number of clusters to extract.</source>
          <target state="translated">Número de grupos a extraer.</target>
        </trans-unit>
        <trans-unit id="eb68d1899db83f395f515eac11a92a2f39369f2a" translate="yes" xml:space="preserve">
          <source>Number of combinations taken into account from &amp;lsquo;n choose k&amp;rsquo;, where n is the number of samples and k is the number of subsamples.</source>
          <target state="translated">N&amp;uacute;mero de combinaciones tomadas en cuenta de 'n elegir k', donde n es el n&amp;uacute;mero de muestras yk es el n&amp;uacute;mero de submuestras.</target>
        </trans-unit>
        <trans-unit id="7fdc37b73d2c326edb84e2aac0aaad0a3921fc6b" translate="yes" xml:space="preserve">
          <source>Number of components</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd12f5ccc87c2314d1a7462c1838eb4fba879a35" translate="yes" xml:space="preserve">
          <source>Number of components (&amp;lt; n_classes - 1) for dimensionality reduction.</source>
          <target state="translated">N&amp;uacute;mero de componentes (&amp;lt;n_classes - 1) para reducci&amp;oacute;n de dimensionalidad.</target>
        </trans-unit>
        <trans-unit id="dfb009c80642e429ebd085f522e99f9888546747" translate="yes" xml:space="preserve">
          <source>Number of components (&amp;lt;= min(n_classes - 1, n_features)) for dimensionality reduction. If None, will be set to min(n_classes - 1, n_features). This parameter only affects the &lt;code&gt;transform&lt;/code&gt; method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="678dcaccd382015a606461223e75a521f8c270e3" translate="yes" xml:space="preserve">
          <source>Number of components to keep</source>
          <target state="translated">Número de componentes a mantener</target>
        </trans-unit>
        <trans-unit id="209051725a6de8e5e1e5fa7a1e74f7eb06a44fec" translate="yes" xml:space="preserve">
          <source>Number of components to keep.</source>
          <target state="translated">Número de componentes a guardar.</target>
        </trans-unit>
        <trans-unit id="d04623123bcfd2ce2b9c37b5c1e9535768de28a7" translate="yes" xml:space="preserve">
          <source>Number of components to keep. If &lt;code&gt;n_components `` is ``None&lt;/code&gt;, then &lt;code&gt;n_components&lt;/code&gt; is set to &lt;code&gt;min(n_samples, n_features)&lt;/code&gt;.</source>
          <target state="translated">N&amp;uacute;mero de componentes a conservar. Si &lt;code&gt;n_components `` is ``None&lt;/code&gt; , entonces &lt;code&gt;n_components&lt;/code&gt; se establece en &lt;code&gt;min(n_samples, n_features)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="864a5ed4a409c99b07b3c02fc85e293c54d58811" translate="yes" xml:space="preserve">
          <source>Number of components to keep. if n_components is not set all components are kept:</source>
          <target state="translated">Número de componentes a guardar.si n_componentes no se establece todos los componentes se guardan:</target>
        </trans-unit>
        <trans-unit id="b681f0aabf7a4e88ff6e07d02e6d3053416c7e30" translate="yes" xml:space="preserve">
          <source>Number of components to use. If none is passed, all are used.</source>
          <target state="translated">Número de componentes a utilizar.Si no se aprueba ninguno,se utilizan todos.</target>
        </trans-unit>
        <trans-unit id="a4c9442f9290e02b19f88b85f02bacea3cfec6f7" translate="yes" xml:space="preserve">
          <source>Number of components, if n_components is not set all features are kept.</source>
          <target state="translated">Número de componentes,si no se establece n_componentes se mantienen todas las características.</target>
        </trans-unit>
        <trans-unit id="cd25fc9de4a04b081f0b9a2b60926bce89997152" translate="yes" xml:space="preserve">
          <source>Number of components. If None, all non-zero components are kept.</source>
          <target state="translated">Número de componentes.Si no hay ninguno,se conservan todos los componentes que no sean cero.</target>
        </trans-unit>
        <trans-unit id="45f800ea0c8bd716a5f59f6d34dd8fdf95b8f22e" translate="yes" xml:space="preserve">
          <source>Number of components:</source>
          <target state="translated">Número de componentes:</target>
        </trans-unit>
        <trans-unit id="08ad46845beb5661bae33c15135ad1635029f790" translate="yes" xml:space="preserve">
          <source>Number of cores to run in parallel while fitting across folds. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">N&amp;uacute;mero de n&amp;uacute;cleos para correr en paralelo mientras se ajusta a trav&amp;eacute;s de pliegues &lt;code&gt;None&lt;/code&gt; significa 1 a menos que est&amp;eacute; en un contexto &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; significa usar todos los procesadores. Consulte el &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;glosario&lt;/a&gt; para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="858edfcde96e4df6617cbdeba5e365378b873cbb" translate="yes" xml:space="preserve">
          <source>Number of cores to run in parallel while fitting across folds. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c854de6ce1141c59e336a0d697b5a2d467a137a" translate="yes" xml:space="preserve">
          <source>Number of decimal digits to display.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0da9d602da12f13ca29bd75af12cc8c869e57a9f" translate="yes" xml:space="preserve">
          <source>Number of dictionary atoms to extract.</source>
          <target state="translated">Número de átomos del diccionario a extraer.</target>
        </trans-unit>
        <trans-unit id="5227337d1c8f00f0cc5985a46091828c912745d3" translate="yes" xml:space="preserve">
          <source>Number of digits for formatting output floating point values. When &lt;code&gt;output_dict&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, this will be ignored and the returned values will not be rounded.</source>
          <target state="translated">N&amp;uacute;mero de d&amp;iacute;gitos para formatear valores de coma flotante de salida. Cuando &lt;code&gt;output_dict&lt;/code&gt; es &lt;code&gt;True&lt;/code&gt; , esto se ignorar&amp;aacute; y los valores devueltos no se redondear&amp;aacute;n.</target>
        </trans-unit>
        <trans-unit id="393e0ab0962f61be4ea05f66f75cf83a58c8acb8" translate="yes" xml:space="preserve">
          <source>Number of digits of precision for floating point in the values of impurity, threshold and value attributes of each node.</source>
          <target state="translated">Número de dígitos de precisión para el punto flotante en los valores de impureza,umbral y atributos de valor de cada nodo.</target>
        </trans-unit>
        <trans-unit id="857511ca3ff53ac74c7a9a64491518f8a98aa57b" translate="yes" xml:space="preserve">
          <source>Number of dimensions in which to immerse the dissimilarities.</source>
          <target state="translated">Número de dimensiones en las que sumergir las disimilitudes.</target>
        </trans-unit>
        <trans-unit id="60a7a9ccef477eb7d360b15d4ec93323fc3722cf" translate="yes" xml:space="preserve">
          <source>Number of dimensions in which to immerse the dissimilarities. If an &lt;code&gt;init&lt;/code&gt; array is provided, this option is overridden and the shape of &lt;code&gt;init&lt;/code&gt; is used to determine the dimensionality of the embedding space.</source>
          <target state="translated">N&amp;uacute;mero de dimensiones en las que sumergir las diferencias. Si se proporciona una matriz &lt;code&gt;init&lt;/code&gt; , esta opci&amp;oacute;n se anula y la forma de &lt;code&gt;init&lt;/code&gt; se usa para determinar la dimensionalidad del espacio de incrustaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="f601fdb82b970f8ccae9e3060c9f42a8faed55c3" translate="yes" xml:space="preserve">
          <source>Number of documents to use in each EM iteration. Only used in online learning.</source>
          <target state="translated">Número de documentos a utilizar en cada iteración EM.Sólo se utiliza en el aprendizaje en línea.</target>
        </trans-unit>
        <trans-unit id="25fead66533b3559387b2fcbff51a361b6ce623f" translate="yes" xml:space="preserve">
          <source>Number of eigen vectors to use for the spectral embedding</source>
          <target state="translated">Número de vectores propios a utilizar para la incrustación espectral</target>
        </trans-unit>
        <trans-unit id="70fb7e9ad9dffd747feff757e8b6b2c3b8c3ad21" translate="yes" xml:space="preserve">
          <source>Number of examples per minibatch.</source>
          <target state="translated">Número de ejemplos por minilanzadera.</target>
        </trans-unit>
        <trans-unit id="f3a87cabcd8ae2a3f47b41980367db8a154ace86" translate="yes" xml:space="preserve">
          <source>Number of features</source>
          <target state="translated">Número de características</target>
        </trans-unit>
        <trans-unit id="c43d2150a87097029c4596d560aaf86e8bb6b759" translate="yes" xml:space="preserve">
          <source>Number of features in the training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="577fe93a084a93466c74dd6388a400050adba06b" translate="yes" xml:space="preserve">
          <source>Number of features of each sample.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48c9c477edb63770940bc1b8209cb208de55d13b" translate="yes" xml:space="preserve">
          <source>Number of features seen during &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fit&quot;&gt;fit&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f26773f39b3b679c0daff789f714ad69f2880ea0" translate="yes" xml:space="preserve">
          <source>Number of features to construct. How many data points will be used to construct the mapping.</source>
          <target state="translated">Número de características a construir.Cuántos puntos de datos se utilizarán para construir el mapa.</target>
        </trans-unit>
        <trans-unit id="d56ef4ad6a94ab0bc79a9c8a295f26cabf4e9608" translate="yes" xml:space="preserve">
          <source>Number of features with missing values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8bfcb7d61331a9745e723fb4ee723054b5ce91e8" translate="yes" xml:space="preserve">
          <source>Number of folds. Must be at least 2.</source>
          <target state="translated">Número de pliegues.Debe ser al menos 2.</target>
        </trans-unit>
        <trans-unit id="37148505c5ccd477f2cd9888510233bf49ab48d7" translate="yes" xml:space="preserve">
          <source>Number of grid points. The path is linearly reinterpolated on a grid between 0 and 1 before computing the scores.</source>
          <target state="translated">Número de puntos de la cuadrícula.El camino se reinterpola linealmente en una cuadrícula entre 0 y 1 antes de calcular los puntos.</target>
        </trans-unit>
        <trans-unit id="609fe53affef0db7e95afe01e9b3b2b42cfee225" translate="yes" xml:space="preserve">
          <source>Number of groups (&lt;code&gt;p&lt;/code&gt;) to leave out in the test split.</source>
          <target state="translated">N&amp;uacute;mero de grupos ( &lt;code&gt;p&lt;/code&gt; ) para dejar fuera en la divisi&amp;oacute;n de prueba.</target>
        </trans-unit>
        <trans-unit id="7836a44e33451a2adc5e90b29cc50de43f4df6df" translate="yes" xml:space="preserve">
          <source>Number of iteration done before the next print.</source>
          <target state="translated">Número de iteraciones realizadas antes de la siguiente impresión.</target>
        </trans-unit>
        <trans-unit id="58ef557aa3516e101a9370d2bf015690817ac32f" translate="yes" xml:space="preserve">
          <source>Number of iteration rounds that occurred. Will be less than &lt;code&gt;self.max_iter&lt;/code&gt; if early stopping criterion was reached.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7ee7fcff30c38dbe60673fcfaba39d5dcac363e" translate="yes" xml:space="preserve">
          <source>Number of iterations corresponding to the best results. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">N&amp;uacute;mero de iteraciones correspondientes a los mejores resultados. Se devuelve solo si &lt;code&gt;return_n_iter&lt;/code&gt; se establece en True.</target>
        </trans-unit>
        <trans-unit id="b6dedae4e35c925119d2eb7b698bd022b8304ae7" translate="yes" xml:space="preserve">
          <source>Number of iterations for randomized SVD solver. Not used by ARPACK. The default is larger than the default in &lt;a href=&quot;sklearn.utils.extmath.randomized_svd#sklearn.utils.extmath.randomized_svd&quot;&gt;&lt;code&gt;randomized_svd&lt;/code&gt;&lt;/a&gt; to handle sparse matrices that may have large slowly decaying spectrum.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b89cf5a40a3578805b3d3e22f18c4e3365baf655" translate="yes" xml:space="preserve">
          <source>Number of iterations for randomized SVD solver. Not used by ARPACK. The default is larger than the default in &lt;code&gt;randomized_svd&lt;/code&gt; to handle sparse matrices that may have large slowly decaying spectrum.</source>
          <target state="translated">N&amp;uacute;mero de iteraciones para el solucionador de SVD aleatorio. No utilizado por ARPACK. El valor predeterminado es mayor que el predeterminado en &lt;code&gt;randomized_svd&lt;/code&gt; para manejar matrices dispersas que pueden tener un gran espectro que decae lentamente.</target>
        </trans-unit>
        <trans-unit id="b158b03d08af1b718d3d75c350a03244a2d1a76a" translate="yes" xml:space="preserve">
          <source>Number of iterations for the power method computed by svd_solver == &amp;lsquo;randomized&amp;rsquo;.</source>
          <target state="translated">N&amp;uacute;mero de iteraciones para el m&amp;eacute;todo de potencia calculado por svd_solver == 'randomized'.</target>
        </trans-unit>
        <trans-unit id="ea8482c683ec2d466d38eba89e78f2c408d93dba" translate="yes" xml:space="preserve">
          <source>Number of iterations for the power method. 3 by default. Only used if &lt;code&gt;svd_method&lt;/code&gt; equals &amp;lsquo;randomized&amp;rsquo;</source>
          <target state="translated">N&amp;uacute;mero de iteraciones para el m&amp;eacute;todo de potencia. 3 por defecto. Solo se usa si &lt;code&gt;svd_method&lt;/code&gt; es igual a 'aleatorio'</target>
        </trans-unit>
        <trans-unit id="e2a3f7897a04130ec9ab6e8a06f184c73a2db962" translate="yes" xml:space="preserve">
          <source>Number of iterations needed for the spatial median.</source>
          <target state="translated">Número de iteraciones necesarias para la mediana espacial.</target>
        </trans-unit>
        <trans-unit id="0a6f367644c8353f5e90ff32f9e722b8b3c35762" translate="yes" xml:space="preserve">
          <source>Number of iterations of the EM step.</source>
          <target state="translated">Número de iteraciones del paso EM.</target>
        </trans-unit>
        <trans-unit id="ca85b057132e8737cc9bd5d9895d1c2f0a3952a0" translate="yes" xml:space="preserve">
          <source>Number of iterations of the NIPALS inner loop for each component.</source>
          <target state="translated">Número de iteraciones del bucle interior del NIPALS para cada componente.</target>
        </trans-unit>
        <trans-unit id="38592412005a60e12235ac166647e6d24941d551" translate="yes" xml:space="preserve">
          <source>Number of iterations of the NIPALS inner loop for each component. Not useful if the algorithm provided is &amp;ldquo;svd&amp;rdquo;.</source>
          <target state="translated">N&amp;uacute;mero de iteraciones del bucle interno NIPALS para cada componente. No es &amp;uacute;til si el algoritmo proporcionado es &quot;svd&quot;.</target>
        </trans-unit>
        <trans-unit id="b3f0661f5b6a537d1cfcf27ec4e37f08f53a4a65" translate="yes" xml:space="preserve">
          <source>Number of iterations run for the optimal alpha.</source>
          <target state="translated">El número de iteraciones se ejecuta para el alfa óptimo.</target>
        </trans-unit>
        <trans-unit id="c9d82135ee15642aa7ae8817dc570334ab80622b" translate="yes" xml:space="preserve">
          <source>Number of iterations run.</source>
          <target state="translated">Número de iteraciones ejecutadas.</target>
        </trans-unit>
        <trans-unit id="cc453132656fb5fe083f1f7f5f3c0a7066108d51" translate="yes" xml:space="preserve">
          <source>Number of iterations run. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">N&amp;uacute;mero de iteraciones ejecutadas. Se devuelve solo si &lt;code&gt;return_n_iter&lt;/code&gt; se establece en &lt;code&gt;True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="346838eb1c236609499116f6804a1aeab6029a68" translate="yes" xml:space="preserve">
          <source>Number of iterations run. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">N&amp;uacute;mero de iteraciones ejecutadas. Se devuelve solo si &lt;code&gt;return_n_iter&lt;/code&gt; se establece en True.</target>
        </trans-unit>
        <trans-unit id="bae285cae0e2d21ef6dbbaa8dd54db30234b47e0" translate="yes" xml:space="preserve">
          <source>Number of iterations run. Returned only if return_n_iter is set to True.</source>
          <target state="translated">Número de iteraciones ejecutadas.Sólo se devuelve si return_n_iter se establece en True.</target>
        </trans-unit>
        <trans-unit id="6e040a3af3a9255e0d8c4455bc3543184ccbc3ff" translate="yes" xml:space="preserve">
          <source>Number of iterations skipped due to an invalid model defined by &lt;code&gt;is_model_valid&lt;/code&gt;.</source>
          <target state="translated">N&amp;uacute;mero de iteraciones omitidas debido a un modelo no v&amp;aacute;lido definido por &lt;code&gt;is_model_valid&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="51f697c488b6017321338ddb492864c9436800d7" translate="yes" xml:space="preserve">
          <source>Number of iterations skipped due to finding zero inliers.</source>
          <target state="translated">Número de iteraciones salteadas debido a la búsqueda de cero inliers.</target>
        </trans-unit>
        <trans-unit id="6eebd535eebcad36fc18ca23295141a0bc8384b3" translate="yes" xml:space="preserve">
          <source>Number of iterations skipped due to invalid data defined by &lt;code&gt;is_data_valid&lt;/code&gt;.</source>
          <target state="translated">N&amp;uacute;mero de iteraciones omitidas debido a datos no v&amp;aacute;lidos definidos por &lt;code&gt;is_data_valid&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2b48b7f3d47c667152c7041a648c896ae52b12ff" translate="yes" xml:space="preserve">
          <source>Number of iterations taken to converge.</source>
          <target state="translated">Número de iteraciones tomadas para converger.</target>
        </trans-unit>
        <trans-unit id="63b22566940c8c05aad34ed364e32e6bea85ba5f" translate="yes" xml:space="preserve">
          <source>Number of iterations that &lt;code&gt;scipy.optimize.minimize(method=&quot;L-BFGS-B&quot;)&lt;/code&gt; has run for.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e35e76f80d1bcb32a849fe5cd7421a6593683d9d" translate="yes" xml:space="preserve">
          <source>Number of iterations that fmin_l_bfgs_b has run for.</source>
          <target state="translated">Número de iteraciones que fmin_l_bfgs_b ha ejecutado.</target>
        </trans-unit>
        <trans-unit id="e6fe9562687f3b9f37db26e9dd5d7295821884aa" translate="yes" xml:space="preserve">
          <source>Number of iterations to perform.</source>
          <target state="translated">Número de iteraciones a realizar.</target>
        </trans-unit>
        <trans-unit id="744edb5cd8af9d3cbdec3cef824f76ed36468258" translate="yes" xml:space="preserve">
          <source>Number of iterations with no change in the number of estimated clusters that stops the convergence.</source>
          <target state="translated">Número de iteraciones sin cambios en el número de cúmulos estimados que detiene la convergencia.</target>
        </trans-unit>
        <trans-unit id="1bb6572e9c67b7f2e1d3c0099c8130bc63fa4d36" translate="yes" xml:space="preserve">
          <source>Number of iterations with no improvement to wait before early stopping.</source>
          <target state="translated">Número de iteraciones sin mejoría para esperar antes de parar temprano.</target>
        </trans-unit>
        <trans-unit id="427bd42a1575036c8163feb881b5305713a1194a" translate="yes" xml:space="preserve">
          <source>Number of iterations. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">N&amp;uacute;mero de iteraciones. Se devuelve solo si &lt;code&gt;return_n_iter&lt;/code&gt; se establece en True.</target>
        </trans-unit>
        <trans-unit id="20dbe7868d12b42e72b8007b758b8aa006423eb6" translate="yes" xml:space="preserve">
          <source>Number of iterations/sweeps over the training dataset to perform during training.</source>
          <target state="translated">Número de iteraciones/barridos sobre el conjunto de datos de entrenamiento para realizar durante el entrenamiento.</target>
        </trans-unit>
        <trans-unit id="805e89de9bc259ba0d4faba86a9892d5aeb2c894" translate="yes" xml:space="preserve">
          <source>Number of jobs to run in parallel. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">N&amp;uacute;mero de trabajos a ejecutar en paralelo. &lt;code&gt;None&lt;/code&gt; significa 1 a menos que est&amp;eacute; en un contexto &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; significa usar todos los procesadores. Consulte el &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;glosario&lt;/a&gt; para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="f64638965b4156e5561d4f1aeb7b5023899255aa" translate="yes" xml:space="preserve">
          <source>Number of jobs to run in parallel. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68e07911a64110ae2d25f4573c1be042d5d1283e" translate="yes" xml:space="preserve">
          <source>Number of label for each output.</source>
          <target state="translated">Número de etiqueta para cada salida.</target>
        </trans-unit>
        <trans-unit id="bd419af7c37c78ed35cd8f556746c5d780f24447" translate="yes" xml:space="preserve">
          <source>Number of layers.</source>
          <target state="translated">Número de capas.</target>
        </trans-unit>
        <trans-unit id="4192e6479d3e36a298ef5ede4c2274eeba61eb5b" translate="yes" xml:space="preserve">
          <source>Number of leaves in the hierarchical tree.</source>
          <target state="translated">Número de hojas en el árbol jerárquico.</target>
        </trans-unit>
        <trans-unit id="ba1aa7966ff18979251514a0f2aad7e015769458" translate="yes" xml:space="preserve">
          <source>Number of leaves.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfcbfd1023f8a82de0be1bdb45b84e4fb92fdade" translate="yes" xml:space="preserve">
          <source>Number of mini-batch iterations to perform.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4bc27955a0ba30e7799dd7d637ec50bb558a2a01" translate="yes" xml:space="preserve">
          <source>Number of nearest neighbors effectively used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eff81c828ce86aeb5087b71b68182742b417d4b0" translate="yes" xml:space="preserve">
          <source>Number of nearest neighbors for nearest_neighbors graph building.</source>
          <target state="translated">Número de vecinos más cercanos para el edificio de gráficos &quot;closest_neighbors&quot;.</target>
        </trans-unit>
        <trans-unit id="f4b6da30fa273de202c93a0a24f9b983a9a2a207" translate="yes" xml:space="preserve">
          <source>Number of neighboring samples to use for imputation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="216e3472c822df844cda9519c2636b73cd479f24" translate="yes" xml:space="preserve">
          <source>Number of neighbors for each sample in the transformed sparse graph. For compatibility reasons, as each sample is considered as its own neighbor, one extra neighbor will be computed when mode == &amp;lsquo;distance&amp;rsquo;. In this case, the sparse graph contains (n_neighbors + 1) neighbors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37fe95cfc748f25efeacf97021fc7a2313be0b5a" translate="yes" xml:space="preserve">
          <source>Number of neighbors for each sample.</source>
          <target state="translated">Número de vecinos para cada muestra.</target>
        </trans-unit>
        <trans-unit id="51b538d5b2a3f95b9485557e25d620a9a782f3b4" translate="yes" xml:space="preserve">
          <source>Number of neighbors for each sample. (default is value passed to the constructor).</source>
          <target state="translated">Número de vecinos para cada muestra.(El valor por defecto es el que se pasa al constructor).</target>
        </trans-unit>
        <trans-unit id="efd458290903df55801a7ce6bf62f9ba73dd0009" translate="yes" xml:space="preserve">
          <source>Number of neighbors k that will be considered.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3cee20cf7566ae95a6af940493b4c430f93d3a6" translate="yes" xml:space="preserve">
          <source>Number of neighbors required. If not provided, this will return the number specified at the initialization.</source>
          <target state="translated">Número de vecinos requeridos.Si no se proporciona,se devolverá el número especificado en la inicialización.</target>
        </trans-unit>
        <trans-unit id="1e55799760cfa2d3bdbd572fe607c1fc4b77b9d7" translate="yes" xml:space="preserve">
          <source>Number of neighbors to be returned from query function when it is not provided to the &lt;a href=&quot;#sklearn.neighbors.LSHForest.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="translated">N&amp;uacute;mero de vecinos que se devolver&amp;aacute;n desde la funci&amp;oacute;n de consulta cuando no se proporciona al m&amp;eacute;todo de &lt;a href=&quot;#sklearn.neighbors.LSHForest.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="3262363328a422de3ed07567136a319deb9ad271" translate="yes" xml:space="preserve">
          <source>Number of neighbors to get (default is the value passed to the constructor).</source>
          <target state="translated">Número de vecinos a conseguir (por defecto es el valor pasado al constructor).</target>
        </trans-unit>
        <trans-unit id="02076e172db6b5e77d67d9ae83e2b88dc66a094e" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.KNeighborsClassifier.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">N&amp;uacute;mero de vecinos que se utilizar&amp;aacute;n de forma predeterminada para &lt;a href=&quot;#sklearn.neighbors.KNeighborsClassifier.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt; consultas de vecinos .</target>
        </trans-unit>
        <trans-unit id="e28eb76463a74cc573864c82f5c8b8d60708a92f" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.KNeighborsRegressor.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">N&amp;uacute;mero de vecinos que se utilizar&amp;aacute;n de forma predeterminada para &lt;a href=&quot;#sklearn.neighbors.KNeighborsRegressor.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt; consultas de vecinos .</target>
        </trans-unit>
        <trans-unit id="4a844d73b7e4afd6cea1487cf59defb5c0385114" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.LocalOutlierFactor.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries. If n_neighbors is larger than the number of samples provided, all samples will be used.</source>
          <target state="translated">N&amp;uacute;mero de vecinos que se utilizar&amp;aacute;n de forma predeterminada para &lt;a href=&quot;#sklearn.neighbors.LocalOutlierFactor.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt; consultas de vecinos . Si n_neighbors es mayor que el n&amp;uacute;mero de muestras proporcionadas, se utilizar&amp;aacute;n todas las muestras.</target>
        </trans-unit>
        <trans-unit id="7e98c15b26d0846d8c1e878d641afc0e3d115b38" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.NearestNeighbors.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">N&amp;uacute;mero de vecinos que se utilizar&amp;aacute;n de forma predeterminada para &lt;a href=&quot;#sklearn.neighbors.NearestNeighbors.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt; consultas de vecinos .</target>
        </trans-unit>
        <trans-unit id="70cd89c4110a42556e2c733194f1c90f3d647ddb" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use for MI estimation for continuous variables, see &lt;a href=&quot;#r37d39d7589e2-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; and &lt;a href=&quot;#r37d39d7589e2-3&quot; id=&quot;id6&quot;&gt;[3]&lt;/a&gt;. Higher values reduce variance of the estimation, but could introduce a bias.</source>
          <target state="translated">N&amp;uacute;mero de vecinos a utilizar para la estimaci&amp;oacute;n de MI para variables continuas, consulte &lt;a href=&quot;#r37d39d7589e2-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; y &lt;a href=&quot;#r37d39d7589e2-3&quot; id=&quot;id6&quot;&gt;[3]&lt;/a&gt; . Los valores m&amp;aacute;s altos reducen la varianza de la estimaci&amp;oacute;n, pero podr&amp;iacute;an introducir un sesgo.</target>
        </trans-unit>
        <trans-unit id="237e706a6f5317f1b4ad85e94d1e882cb7b24021" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use for MI estimation for continuous variables, see &lt;a href=&quot;#r50b872b699c4-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; and &lt;a href=&quot;#r50b872b699c4-3&quot; id=&quot;id6&quot;&gt;[3]&lt;/a&gt;. Higher values reduce variance of the estimation, but could introduce a bias.</source>
          <target state="translated">N&amp;uacute;mero de vecinos a utilizar para la estimaci&amp;oacute;n de MI para variables continuas, consulte &lt;a href=&quot;#r50b872b699c4-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; y &lt;a href=&quot;#r50b872b699c4-3&quot; id=&quot;id6&quot;&gt;[3]&lt;/a&gt; . Los valores m&amp;aacute;s altos reducen la varianza de la estimaci&amp;oacute;n, pero podr&amp;iacute;an introducir un sesgo.</target>
        </trans-unit>
        <trans-unit id="9f8819cc7687f8afeb7c24c0200033a234d0c39c" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use when constructing the affinity matrix using the nearest neighbors method. Ignored for &lt;code&gt;affinity='rbf'&lt;/code&gt;.</source>
          <target state="translated">N&amp;uacute;mero de vecinos que se utilizar&amp;aacute;n al construir la matriz de afinidad utilizando el m&amp;eacute;todo de vecinos m&amp;aacute;s cercanos. Ignorado por &lt;code&gt;affinity='rbf'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c37287ec818bb6dad17b995ed5729153d9a8118d" translate="yes" xml:space="preserve">
          <source>Number of nonzero coefficients to target in each column of the solution. This is only used by &lt;code&gt;algorithm=&amp;rsquo;lars&amp;rsquo;&lt;/code&gt; and &lt;code&gt;algorithm=&amp;rsquo;omp&amp;rsquo;&lt;/code&gt; and is overridden by &lt;code&gt;alpha&lt;/code&gt; in the &lt;code&gt;omp&lt;/code&gt; case.</source>
          <target state="translated">N&amp;uacute;mero de coeficientes distintos de cero para apuntar en cada columna de la soluci&amp;oacute;n. Esto solo lo usa el &lt;code&gt;algorithm=&amp;rsquo;lars&amp;rsquo;&lt;/code&gt; y el &lt;code&gt;algorithm=&amp;rsquo;omp&amp;rsquo;&lt;/code&gt; y es anulado por &lt;code&gt;alpha&lt;/code&gt; en el caso &lt;code&gt;omp&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3d8a9b81dd6bc7c054449c6745360802b0f076b9" translate="yes" xml:space="preserve">
          <source>Number of nonzero coefficients to target in each column of the solution. This is only used by &lt;code&gt;algorithm='lars'&lt;/code&gt; and &lt;code&gt;algorithm='omp'&lt;/code&gt; and is overridden by &lt;code&gt;alpha&lt;/code&gt; in the &lt;code&gt;omp&lt;/code&gt; case.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0be2c79389c0a56a89ad2014f6366b3f95d2bca8" translate="yes" xml:space="preserve">
          <source>Number of other features to use to estimate the missing values of each feature column. Nearness between features is measured using the absolute correlation coefficient between each feature pair (after initial imputation). To ensure coverage of features throughout the imputation process, the neighbor features are not necessarily nearest, but are drawn with probability proportional to correlation for each imputed target feature. Can provide significant speed-up when the number of features is huge. If &lt;code&gt;None&lt;/code&gt;, all features will be used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27f9bf5a85bc89aa70ea3dbacba13e73a444a9f8" translate="yes" xml:space="preserve">
          <source>Number of outputs.</source>
          <target state="translated">Número de productos.</target>
        </trans-unit>
        <trans-unit id="a01758eccae198371ad1fbda71e0227c6924ab24" translate="yes" xml:space="preserve">
          <source>Number of parallel jobs to run. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">N&amp;uacute;mero de trabajos paralelos a ejecutar. &lt;code&gt;None&lt;/code&gt; significa 1 a menos que est&amp;eacute; en un contexto &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; significa usar todos los procesadores. Consulte el &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;glosario&lt;/a&gt; para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="aec9eb1029d40469b12f590579b2421b0ac783c2" translate="yes" xml:space="preserve">
          <source>Number of parallel jobs to run. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89260d16706c6571daecae9b230dfb394e4f8e34" translate="yes" xml:space="preserve">
          <source>Number of parameter settings that are produced.</source>
          <target state="translated">Número de ajustes de parámetros que se producen.</target>
        </trans-unit>
        <trans-unit id="26680dedc0c193794be077118d1d33ec7cee22de" translate="yes" xml:space="preserve">
          <source>Number of parameter settings that are sampled. n_iter trades off runtime vs quality of the solution.</source>
          <target state="translated">Número de ajustes de parámetros que se muestrean.n_iter intercambia el tiempo de ejecución por la calidad de la solución.</target>
        </trans-unit>
        <trans-unit id="9b3af5a87173ff58737497b2a7b2dff4ac22b716" translate="yes" xml:space="preserve">
          <source>Number of passes over the dataset.</source>
          <target state="translated">Número de pasadas sobre el conjunto de datos.</target>
        </trans-unit>
        <trans-unit id="e919298382f2b30ec9254222b02df5121a7447b9" translate="yes" xml:space="preserve">
          <source>Number of points at which to switch to brute-force. Changing leaf_size will not affect the results of a query, but can significantly impact the speed of a query and the memory required to store the constructed tree. The amount of memory needed to store the tree scales as approximately n_samples / leaf_size. For a specified &lt;code&gt;leaf_size&lt;/code&gt;, a leaf node is guaranteed to satisfy &lt;code&gt;leaf_size &amp;lt;= n_points &amp;lt;= 2 * leaf_size&lt;/code&gt;, except in the case that &lt;code&gt;n_samples &amp;lt; leaf_size&lt;/code&gt;.</source>
          <target state="translated">N&amp;uacute;mero de puntos en los que cambiar a fuerza bruta. El cambio de tama&amp;ntilde;o de hoja no afectar&amp;aacute; los resultados de una consulta, pero puede afectar significativamente la velocidad de una consulta y la memoria requerida para almacenar el &amp;aacute;rbol construido. La cantidad de memoria necesaria para almacenar las escalas del &amp;aacute;rbol es aproximadamente n_samples / leaf_size. Para un &lt;code&gt;leaf_size&lt;/code&gt; especificado , se garantiza que un nodo de hoja satisfaga &lt;code&gt;leaf_size &amp;lt;= n_points &amp;lt;= 2 * leaf_size&lt;/code&gt; , excepto en el caso de que &lt;code&gt;n_samples &amp;lt; leaf_size&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="74f0e4f1324b195e40b6b67840245cc6639acde5" translate="yes" xml:space="preserve">
          <source>Number of power iterations used to stabilize the result</source>
          <target state="translated">Número de iteraciones de potencia utilizadas para estabilizar el resultado</target>
        </trans-unit>
        <trans-unit id="3af0fded49ca0f3c99c5f4242edefb1980f1ee1e" translate="yes" xml:space="preserve">
          <source>Number of power iterations. It can be used to deal with very noisy problems. When &amp;lsquo;auto&amp;rsquo;, it is set to 4, unless &lt;code&gt;n_components&lt;/code&gt; is small (&amp;lt; .1 * min(X.shape)) &lt;code&gt;n_iter&lt;/code&gt; in which case is set to 7. This improves precision with few components.</source>
          <target state="translated">N&amp;uacute;mero de iteraciones de potencia. Puede utilizarse para solucionar problemas muy ruidosos. Cuando es 'auto', se establece en 4, a menos que &lt;code&gt;n_components&lt;/code&gt; sea ​​peque&amp;ntilde;o (&amp;lt;.1 * min (X.shape)) &lt;code&gt;n_iter&lt;/code&gt; , en cuyo caso se establece en 7. Esto mejora la precisi&amp;oacute;n con pocos componentes.</target>
        </trans-unit>
        <trans-unit id="01905db27e1b09268197900ceb99a1346e890115" translate="yes" xml:space="preserve">
          <source>Number of predispatched jobs for parallel execution (default is all). The option can reduce the allocated memory. The str can be an expression like &amp;lsquo;2*n_jobs&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c2b5ab18e2bf242894b9a2ecca14a388d432f49" translate="yes" xml:space="preserve">
          <source>Number of predispatched jobs for parallel execution (default is all). The option can reduce the allocated memory. The string can be an expression like &amp;lsquo;2*n_jobs&amp;rsquo;.</source>
          <target state="translated">N&amp;uacute;mero de trabajos previamente enviados para ejecuci&amp;oacute;n en paralelo (el valor predeterminado es todos). La opci&amp;oacute;n puede reducir la memoria asignada. La cadena puede ser una expresi&amp;oacute;n como '2 * n_jobs'.</target>
        </trans-unit>
        <trans-unit id="344e1da2c8fa0e4b376ce3e457a99189b911e25a" translate="yes" xml:space="preserve">
          <source>Number of previous iterations completed on the dictionary used for initialization.</source>
          <target state="translated">Número de iteraciones anteriores completadas en el diccionario utilizado para la inicialización.</target>
        </trans-unit>
        <trans-unit id="20853d9102158a366a61d28a6b2cb29c20c98681" translate="yes" xml:space="preserve">
          <source>Number of quantiles to be computed. It corresponds to the number of landmarks used to discretize the cumulative density function.</source>
          <target state="translated">Número de cuantiles a computar.Corresponde al número de puntos de referencia utilizados para discretizar la función de densidad acumulada.</target>
        </trans-unit>
        <trans-unit id="548caec42d172e8575f71a33916af24287471704" translate="yes" xml:space="preserve">
          <source>Number of quantiles to be computed. It corresponds to the number of landmarks used to discretize the cumulative distribution function. If n_quantiles is larger than the number of samples, n_quantiles is set to the number of samples as a larger number of quantiles does not give a better approximation of the cumulative distribution function estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4aaf1e86836dfafd99ac1220487fd647e794f84" translate="yes" xml:space="preserve">
          <source>Number of random initializations that are tried with the k-means algorithm.</source>
          <target state="translated">Número de inicializaciones aleatorias que se intentan con el algoritmo k-means.</target>
        </trans-unit>
        <trans-unit id="b43bc8af90e8df6a17a3d2db5f152fc9e0f7509e" translate="yes" xml:space="preserve">
          <source>Number of random initializations that are tried. In contrast to KMeans, the algorithm is only run once, using the best of the &lt;code&gt;n_init&lt;/code&gt; initializations as measured by inertia.</source>
          <target state="translated">N&amp;uacute;mero de inicializaciones aleatorias que se prueban. A diferencia de KMeans, el algoritmo solo se ejecuta una vez, utilizando la mejor de las inicializaciones &lt;code&gt;n_init&lt;/code&gt; medidas por inercia.</target>
        </trans-unit>
        <trans-unit id="2a775249dab61ada8ba714fbef3fe2a6cd5e7f9a" translate="yes" xml:space="preserve">
          <source>Number of random selection trials until one of the stop criteria is met. It is always &lt;code&gt;&amp;lt;= max_trials&lt;/code&gt;.</source>
          <target state="translated">N&amp;uacute;mero de ensayos de selecci&amp;oacute;n aleatoria hasta que se cumpla uno de los criterios de parada. Siempre es &lt;code&gt;&amp;lt;= max_trials&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ddb00b53d153c760e3c244cb1587828c964053be" translate="yes" xml:space="preserve">
          <source>Number of randomized models.</source>
          <target state="translated">Número de modelos aleatorios.</target>
        </trans-unit>
        <trans-unit id="6e7920a40024bb45accfba5d3a9412bad8885ccd" translate="yes" xml:space="preserve">
          <source>Number of re-shuffling &amp;amp; splitting iterations.</source>
          <target state="translated">N&amp;uacute;mero de iteraciones de re-barajado y divisi&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="8c1de77526ac5586c3170ef35d398449f2b6a01e" translate="yes" xml:space="preserve">
          <source>Number of rows and columns (resp.) in the bicluster.</source>
          <target state="translated">Número de filas y columnas (resp.)en el bicluster.</target>
        </trans-unit>
        <trans-unit id="ad1b9067ab876b7409a0c802cf769015719aca95" translate="yes" xml:space="preserve">
          <source>Number of samples encountered for each (class, feature) during fitting. This value is weighted by the sample weight when provided.</source>
          <target state="translated">Número de muestras encontradas para cada una (clase,característica)durante el ajuste.Este valor es ponderado por el peso de la muestra cuando se proporciona.</target>
        </trans-unit>
        <trans-unit id="c92a24738a539e752aec89fe917078bdb81b48d8" translate="yes" xml:space="preserve">
          <source>Number of samples encountered for each class during fitting. This value is weighted by the sample weight when provided.</source>
          <target state="translated">Número de muestras encontradas para cada clase durante la adaptación.Este valor es ponderado por el peso de la muestra cuando se proporciona.</target>
        </trans-unit>
        <trans-unit id="7d9434e4be81d003217d0ff99bec2958d6cf8f1c" translate="yes" xml:space="preserve">
          <source>Number of samples encountered for each feature during fitting. This value is weighted by the sample weight when provided.</source>
          <target state="translated">Número de muestras encontradas para cada rasgo durante el ajuste.Este valor es ponderado por el peso de la muestra cuando se proporciona.</target>
        </trans-unit>
        <trans-unit id="4189046e920c071a46d31153d30f2c5546e5d75d" translate="yes" xml:space="preserve">
          <source>Number of samples in a subcluster.</source>
          <target state="translated">Número de muestras en un subconjunto.</target>
        </trans-unit>
        <trans-unit id="d6a1b136f66f610a4896adec7fc65cb72260eca1" translate="yes" xml:space="preserve">
          <source>Number of samples in the training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1b8d68fdf55246f42bd4140ab8cdd3ea5232e3c" translate="yes" xml:space="preserve">
          <source>Number of samples seen so far, excluded X.</source>
          <target state="translated">Número de muestras vistas hasta ahora,excluido X.</target>
        </trans-unit>
        <trans-unit id="f3eb4ebcff443a5740a69d115e4c7d66ed2b7058" translate="yes" xml:space="preserve">
          <source>Number of samples to calculate the parameters. This is at least the number of features (plus 1 if fit_intercept=True) and the number of samples as a maximum. A lower number leads to a higher breakdown point and a low efficiency while a high number leads to a low breakdown point and a high efficiency. If None, take the minimum number of subsamples leading to maximal robustness. If n_subsamples is set to n_samples, Theil-Sen is identical to least squares.</source>
          <target state="translated">Número de muestras para calcular los parámetros.Este es al menos el número de características (más 1 si fit_intercept=True)y el número de muestras como máximo.Un número más bajo conduce a un punto de ruptura más alto y a una eficiencia baja,mientras que un número alto conduce a un punto de ruptura bajo y a una eficiencia alta.Si no hay ninguna,toma el número mínimo de submuestras que conduce a la máxima robustez.Si n_submuestras se establece en n_muestras,Theil-Sen es idéntico a los mínimos cuadrados.</target>
        </trans-unit>
        <trans-unit id="fc350dda13f5c287c8548b6575ceb1d2c780f61c" translate="yes" xml:space="preserve">
          <source>Number of samples to generate. Defaults to 1.</source>
          <target state="translated">Número de muestras a generar.Por defecto es 1.</target>
        </trans-unit>
        <trans-unit id="e94e897f1bb653d4e0feaefd5987d4a553f8af8b" translate="yes" xml:space="preserve">
          <source>Number of samples to generate. If left to None this is automatically set to the first dimension of the arrays.</source>
          <target state="translated">Número de muestras a generar.Si se deja en Ninguno,se ajusta automáticamente a la primera dimensión de las matrices.</target>
        </trans-unit>
        <trans-unit id="1a167b23f9bb21704b10da0ef2fc738d507dce40" translate="yes" xml:space="preserve">
          <source>Number of samples to generate. If left to None this is automatically set to the first dimension of the arrays. If replace is False it should not be larger than the length of arrays.</source>
          <target state="translated">Número de muestras a generar.Si se deja en Ninguno,se ajusta automáticamente a la primera dimensión de las matrices.Si la sustitución es falsa,no debe ser mayor que la longitud de las matrices.</target>
        </trans-unit>
        <trans-unit id="37b65d0e64d2d03034e5f2f5fa109bac79447708" translate="yes" xml:space="preserve">
          <source>Number of samples to randomly sample for speeding up the initialization (sometimes at the expense of accuracy): the only algorithm is initialized by running a batch KMeans on a random subset of the data. This needs to be larger than n_clusters.</source>
          <target state="translated">Número de muestras a muestrear aleatoriamente para acelerar la inicialización (a veces a expensas de la precisión):el único algoritmo se inicializa ejecutando un lote de KMeans en un subconjunto aleatorio de los datos.Éste debe ser mayor que n_clusters.</target>
        </trans-unit>
        <trans-unit id="79fd133ee683290a8c4b438718235e4555547cff" translate="yes" xml:space="preserve">
          <source>Number of samples. If an array is given, it will compute a safe number of components array-wise.</source>
          <target state="translated">Número de muestras.Si se da una matriz,se calculará un número seguro de componentes por matriz.</target>
        </trans-unit>
        <trans-unit id="ea4ca73ab41ec6033a853674e7fbc815a311d3cf" translate="yes" xml:space="preserve">
          <source>Number of samples. Pass n_samples when the slices are to be used for sparse matrix indexing; slicing off-the-end raises an exception, while it works for NumPy arrays.</source>
          <target state="translated">Número de muestras.Pasa n_muestras cuando los cortes se van a utilizar para la indexación de matrices dispersas;el corte fuera del extremo plantea una excepción,mientras que funciona para las matrices NumPy.</target>
        </trans-unit>
        <trans-unit id="a75d9ceb8c321c78e9909168b2356ee01f06d1c4" translate="yes" xml:space="preserve">
          <source>Number of singular values and vectors to extract.</source>
          <target state="translated">Número de valores y vectores singulares a extraer.</target>
        </trans-unit>
        <trans-unit id="9259a302604f8c3d052d9766a0665f74598f4a66" translate="yes" xml:space="preserve">
          <source>Number of singular vectors to check.</source>
          <target state="translated">Número de vectores singulares a comprobar.</target>
        </trans-unit>
        <trans-unit id="4e03fb606fcab969781bb42da4618d24e54a8291" translate="yes" xml:space="preserve">
          <source>Number of slices to generate.</source>
          <target state="translated">Número de rebanadas a generar.</target>
        </trans-unit>
        <trans-unit id="2834c0f8a56b1dcfce6f6e78db200759bce6dd7b" translate="yes" xml:space="preserve">
          <source>Number of spaces between edges. The higher it is, the wider the result.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c55cc369cb9552b44b4a575f3aae7b0b751a97c8" translate="yes" xml:space="preserve">
          <source>Number of sparse atoms to extract.</source>
          <target state="translated">Número de átomos escasos a extraer.</target>
        </trans-unit>
        <trans-unit id="133c33b7f976c18813a243c5632b24f2c8e81111" translate="yes" xml:space="preserve">
          <source>Number of splits. Must be at least 2.</source>
          <target state="translated">Número de divisiones.Debe ser al menos 2.</target>
        </trans-unit>
        <trans-unit id="a6bce09538dcde7e7ff60020a73de4974cae38ac" translate="yes" xml:space="preserve">
          <source>Number of step used by the best fit of EM to reach the convergence.</source>
          <target state="translated">Número de paso utilizado por el mejor ajuste de EM para alcanzar la convergencia.</target>
        </trans-unit>
        <trans-unit id="aec50834e9d4a500ee385c37d29d58bdc624bb7e" translate="yes" xml:space="preserve">
          <source>Number of step used by the best fit of inference to reach the convergence.</source>
          <target state="translated">Número de paso utilizado por el mejor ajuste de la inferencia para alcanzar la convergencia.</target>
        </trans-unit>
        <trans-unit id="ef96b42c053cf6cd51d23012a0a52b84b2a07604" translate="yes" xml:space="preserve">
          <source>Number of support vectors for each class.</source>
          <target state="translated">Número de vectores de apoyo para cada clase.</target>
        </trans-unit>
        <trans-unit id="424ae2b2f85d63b5b83778ea64c14167e1acf984" translate="yes" xml:space="preserve">
          <source>Number of targets</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abc9da602c481111cdc9cad2b9a2ec618fddfb11" translate="yes" xml:space="preserve">
          <source>Number of test samples in this split.</source>
          <target state="translated">Número de muestras de prueba en esta división.</target>
        </trans-unit>
        <trans-unit id="35ccbd0ed91056f0b431a8e36f769a8655c75e9b" translate="yes" xml:space="preserve">
          <source>Number of time the k-means algorithm will be run with different centroid seeds. The final results will be the best output of n_init consecutive runs in terms of inertia.</source>
          <target state="translated">Número de veces que el algoritmo de k-means se ejecutará con diferentes semillas centroides.El resultado final será el mejor resultado de n_init ejecuciones consecutivas en términos de inercia.</target>
        </trans-unit>
        <trans-unit id="f584f00fb96d0392221b2f107adcb2345328d3b9" translate="yes" xml:space="preserve">
          <source>Number of times cross-validator needs to be repeated.</source>
          <target state="translated">El número de veces que el validador cruzado debe ser repetido.</target>
        </trans-unit>
        <trans-unit id="5d2e8dfe07ab898c902f4c479175b6b09037f98d" translate="yes" xml:space="preserve">
          <source>Number of times the SMACOF algorithm will be run with different initializations. The final results will be the best output of the runs, determined by the run with the smallest final stress.</source>
          <target state="translated">Número de veces que el algoritmo SMACOF se ejecutará con diferentes inicializaciones.El resultado final será el mejor resultado de las ejecuciones,determinado por la ejecución con el menor esfuerzo final.</target>
        </trans-unit>
        <trans-unit id="61d47a44584bfde40c1396e5d7fc8603c469e589" translate="yes" xml:space="preserve">
          <source>Number of times the SMACOF algorithm will be run with different initializations. The final results will be the best output of the runs, determined by the run with the smallest final stress. If &lt;code&gt;init&lt;/code&gt; is provided, this option is overridden and a single run is performed.</source>
          <target state="translated">N&amp;uacute;mero de veces que se ejecutar&amp;aacute; el algoritmo SMACOF con diferentes inicializaciones. Los resultados finales ser&amp;aacute;n el mejor resultado de las corridas, determinado por la corrida con la menor tensi&amp;oacute;n final. Si se proporciona &lt;code&gt;init&lt;/code&gt; , esta opci&amp;oacute;n se anula y se realiza una sola ejecuci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="279a7d188f8d456ddd160319a5480a2db5aa1c81" translate="yes" xml:space="preserve">
          <source>Number of times to permute &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">N&amp;uacute;mero de veces que se permuta &lt;code&gt;y&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="463dac0c15a56b554ec940dbcedbd42982c379fb" translate="yes" xml:space="preserve">
          <source>Number of times to permute a feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69631a318e07c7e122bb29c914f2e0417bbb3ea3" translate="yes" xml:space="preserve">
          <source>Number of top features to select. The &amp;ldquo;all&amp;rdquo; option bypasses selection, for use in a parameter search.</source>
          <target state="translated">N&amp;uacute;mero de funciones principales para seleccionar. La opci&amp;oacute;n &quot;todos&quot; omite la selecci&amp;oacute;n, para su uso en una b&amp;uacute;squeda de par&amp;aacute;metros.</target>
        </trans-unit>
        <trans-unit id="da4c15da76668749b2d08dac7e93fa89fa01cae3" translate="yes" xml:space="preserve">
          <source>Number of topics.</source>
          <target state="translated">Número de temas.</target>
        </trans-unit>
        <trans-unit id="fbddcfb20eac49b636d0567ae2783e45f24d5db9" translate="yes" xml:space="preserve">
          <source>Number of trees in the LSH Forest.</source>
          <target state="translated">Número de árboles en el bosque LSH.</target>
        </trans-unit>
        <trans-unit id="f59a66952049f5c09c592626a93864184fb52de6" translate="yes" xml:space="preserve">
          <source>Number of trees in the forest.</source>
          <target state="translated">Número de árboles en el bosque.</target>
        </trans-unit>
        <trans-unit id="883143c355bb70d9c124548ac182b0a674cf4c90" translate="yes" xml:space="preserve">
          <source>Number of values per feature.</source>
          <target state="translated">Número de valores por característica.</target>
        </trans-unit>
        <trans-unit id="3d3c8a841ea2fec708f92a22e6cb69db77e1725b" translate="yes" xml:space="preserve">
          <source>Number of vectors to use in calculating the SVD. Corresponds to &lt;code&gt;ncv&lt;/code&gt; when &lt;code&gt;svd_method=arpack&lt;/code&gt; and &lt;code&gt;n_oversamples&lt;/code&gt; when &lt;code&gt;svd_method&lt;/code&gt; is &amp;lsquo;randomized`.</source>
          <target state="translated">N&amp;uacute;mero de vectores a utilizar para calcular la SVD. Corresponde a &lt;code&gt;ncv&lt;/code&gt; cuando &lt;code&gt;svd_method=arpack&lt;/code&gt; y &lt;code&gt;n_oversamples&lt;/code&gt; cuando &lt;code&gt;svd_method&lt;/code&gt; es 'aleatorio'.</target>
        </trans-unit>
        <trans-unit id="16bf53dde5c63fb6777b19bf3ca8bb646d21ca57" translate="yes" xml:space="preserve">
          <source>Number of weight updates performed during training. Same as &lt;code&gt;(n_iter_ * n_samples)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfc2be0c624984ee3eedecc63144bb2eb0e00cd3" translate="yes" xml:space="preserve">
          <source>Numbers of training examples that has been used to generate the learning curve. Note that the number of ticks might be less than n_ticks because duplicate entries will be removed.</source>
          <target state="translated">Número de ejemplos de entrenamiento que se han utilizado para generar la curva de aprendizaje.Tenga en cuenta que el número de ticks puede ser menor que n_ticks porque se eliminarán las entradas duplicadas.</target>
        </trans-unit>
        <trans-unit id="a28c04c9b4b005997c9b362ad026f41b8cd86540" translate="yes" xml:space="preserve">
          <source>Numeric Features:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89c43bf4b62114e4d6b82aa7a39bcd64acde71ea" translate="yes" xml:space="preserve">
          <source>Numeric stopping criterion (WRITEME). 1e-3 by default.</source>
          <target state="translated">Criterio de parada numérica (WRITEME).1e-3 por defecto.</target>
        </trans-unit>
        <trans-unit id="546b4b9a9bb1a271c23a369b5102c7b719bb257b" translate="yes" xml:space="preserve">
          <source>Numerical solver to use.</source>
          <target state="translated">Soldador numérico para usar.</target>
        </trans-unit>
        <trans-unit id="e91bee1467e40de4d946ed662375c173925b59f5" translate="yes" xml:space="preserve">
          <source>Numerical solver to use:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1bda3e35c6cc189118f551c9ef807d4c37dc07f6" translate="yes" xml:space="preserve">
          <source>Numerical solver to use: &amp;lsquo;cd&amp;rsquo; is a Coordinate Descent solver. &amp;lsquo;mu&amp;rsquo; is a Multiplicative Update solver.</source>
          <target state="translated">Solucionador num&amp;eacute;rico para usar: 'cd' es un solucionador de Descenso de coordenadas. 'mu' es un solucionador de actualizaciones multiplicativas.</target>
        </trans-unit>
        <trans-unit id="c42d401e991cba0a784aff1388e26ed9b57a65e8" translate="yes" xml:space="preserve">
          <source>O. Ledoit and M. Wolf, &amp;ldquo;A Well-Conditioned Estimator for Large-Dimensional Covariance Matrices&amp;rdquo;, Journal of Multivariate Analysis, Volume 88, Issue 2, February 2004, pages 365-411.</source>
          <target state="translated">O. Ledoit y M. Wolf, &amp;ldquo;Un estimador bien condicionado para matrices de covarianza de grandes dimensiones&amp;rdquo;, Journal of Multivariate Analysis, Volumen 88, N&amp;uacute;mero 2, febrero de 2004, p&amp;aacute;ginas 365-411.</target>
        </trans-unit>
        <trans-unit id="e39d7c7a6dfc71c75f7fd3b1688e4255ab0569b5" translate="yes" xml:space="preserve">
          <source>O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995.</source>
          <target state="translated">O.L.Mangasarian,W.N.Street y W.H.Wolberg.Diagnóstico y pronóstico de cáncer de mama mediante programación lineal.Investigación Operativa,43(4),páginas 570-577,julio-agosto de 1995.</target>
        </trans-unit>
        <trans-unit id="dea6ae2f186812bc2bf8114a674ec0e8c8de8039" translate="yes" xml:space="preserve">
          <source>OAS is a particular form of shrinkage described in &amp;ldquo;Shrinkage Algorithms for MMSE Covariance Estimation&amp;rdquo; Chen et al., IEEE Trans. on Sign. Proc., Volume 58, Issue 10, October 2010.</source>
          <target state="translated">OAS es una forma particular de contracci&amp;oacute;n descrita en &amp;ldquo;Algoritmos de contracci&amp;oacute;n para estimaci&amp;oacute;n de covarianza MMSE&amp;rdquo; Chen et al., IEEE Trans. al firmar. Proc., Volumen 58, N&amp;uacute;mero 10, octubre de 2010.</target>
        </trans-unit>
        <trans-unit id="516f97783bd415e3a50d6dad8302febb07d2e198" translate="yes" xml:space="preserve">
          <source>OCCUPATION</source>
          <target state="translated">OCCUPATION</target>
        </trans-unit>
        <trans-unit id="d588c2d5cad6e344a9a328bc0dcc94f63bfe1c53" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Clerical</source>
          <target state="translated">OCCUPATION_Clerical</target>
        </trans-unit>
        <trans-unit id="b725bc8de0a483c5d88499d9e7c87c7ae4685ba8" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Management</source>
          <target state="translated">OCCUPATION_Management</target>
        </trans-unit>
        <trans-unit id="0e54eeff266f2a17bed8c69e66148a30421390e0" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Other</source>
          <target state="translated">OCCUPATION_Other</target>
        </trans-unit>
        <trans-unit id="d50ba20894189c3830106f0cfb4a70b0e6554b4e" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Professional</source>
          <target state="translated">OCCUPATION_Professional</target>
        </trans-unit>
        <trans-unit id="d9264bc2d4c97fd3584da75ee0731d202c6b28fe" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Sales</source>
          <target state="translated">OCCUPATION_Sales</target>
        </trans-unit>
        <trans-unit id="7c720959f75a9b22fee1afe843481ec6692d4aa6" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Service</source>
          <target state="translated">OCCUPATION_Service</target>
        </trans-unit>
        <trans-unit id="f3fd8009dd2433d1a63abbabb480a18d05e74108" translate="yes" xml:space="preserve">
          <source>OD280/OD315 of diluted wines</source>
          <target state="translated">OD280/OD315 de vinos diluidos</target>
        </trans-unit>
        <trans-unit id="2f76e133c144664f6ceed4509b6ad3d9fe14a67d" translate="yes" xml:space="preserve">
          <source>OD280/OD315 of diluted wines:</source>
          <target state="translated">OD280/OD315 de vinos diluidos:</target>
        </trans-unit>
        <trans-unit id="9ce3bd4224c8c1780db56b4125ecf3f24bf748b7" translate="yes" xml:space="preserve">
          <source>OK</source>
          <target state="translated">OK</target>
        </trans-unit>
        <trans-unit id="8e8565eb895a4e523ac266f2a6f2af45cda869f8" translate="yes" xml:space="preserve">
          <source>OMP is based on a greedy algorithm that includes at each step the atom most highly correlated with the current residual. It is similar to the simpler matching pursuit (MP) method, but better in that at each iteration, the residual is recomputed using an orthogonal projection on the space of the previously chosen dictionary elements.</source>
          <target state="translated">OMP se basa en un algoritmo codicioso que incluye en cada paso el átomo más altamente correlacionado con el residuo actual.Es similar al método de búsqueda de coincidencia más simple (MP),pero mejor en el sentido de que en cada iteración,el residuo se vuelve a calcular utilizando una proyección ortogonal en el espacio de los elementos de diccionario previamente elegidos.</target>
        </trans-unit>
        <trans-unit id="702567365ae2f6da8d5fc9650aab7f68f2e2b4bd" translate="yes" xml:space="preserve">
          <source>OOB Errors for Random Forests</source>
          <target state="translated">Errores de OOB para bosques aleatorios</target>
        </trans-unit>
        <trans-unit id="7556880ffb905f4996fa16b161902fde13e5d1be" translate="yes" xml:space="preserve">
          <source>OPTICS</source>
          <target state="translated">OPTICS</target>
        </trans-unit>
        <trans-unit id="3921b01080f70880ca169ee2dd262001f08a9a03" translate="yes" xml:space="preserve">
          <source>OPTICS (Ordering Points To Identify the Clustering Structure), closely related to DBSCAN, finds core sample of high density and expands clusters from them &lt;a href=&quot;#r2c55e37003fe-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;. Unlike DBSCAN, keeps cluster hierarchy for a variable neighborhood radius. Better suited for usage on large datasets than the current sklearn implementation of DBSCAN.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3657cfede2d1ca1450e1e96704c7fe1e79174b7f" translate="yes" xml:space="preserve">
          <source>OPTICS ordered point indices (&lt;code&gt;ordering_&lt;/code&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b77a29777f0317be507e501f5c60c74e4daaff5" translate="yes" xml:space="preserve">
          <source>OR, if affinity==`precomputed`, a precomputed affinity matrix of shape (n_samples, n_samples)</source>
          <target state="translated">O,si la afinidad==`precomputada`,una matriz de afinidad precomputada de la forma (n_muestras,n_muestras)</target>
        </trans-unit>
        <trans-unit id="c8f36dd22506f2db935605e7016ba4725ee8d954" translate="yes" xml:space="preserve">
          <source>OVR + L1 penalty</source>
          <target state="translated">OVR+L1 penalización</target>
        </trans-unit>
        <trans-unit id="6fb4b4e4f3901ecb1795e224abe18919de690335" translate="yes" xml:space="preserve">
          <source>OVR + L2 penalty</source>
          <target state="translated">OVR+L2 de penalización</target>
        </trans-unit>
        <trans-unit id="cb5d65d3f62b5d33c694bb026fc2cc2e2c9008af" translate="yes" xml:space="preserve">
          <source>Object that mocks the urlopen function to fake requests to mldata.</source>
          <target state="translated">Objeto que se burla de la función urlopen para falsificar solicitudes a mldata.</target>
        </trans-unit>
        <trans-unit id="e59a9b80a8b5844a54b21160c3e6341a042b77f2" translate="yes" xml:space="preserve">
          <source>Object that stores computed values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04c754a9ec758f22d2ae91b0fe2718c4051ca8ed" translate="yes" xml:space="preserve">
          <source>Object used to transform multiclass labels to binary labels and vice-versa.</source>
          <target state="translated">Objeto utilizado para transformar etiquetas multiclase en etiquetas binarias y viceversa.</target>
        </trans-unit>
        <trans-unit id="cdd1673e245cacca55f04fb3561b4eb5194072ad" translate="yes" xml:space="preserve">
          <source>Objects that will be checked for consistent length.</source>
          <target state="translated">Objetos que serán revisados para una longitud consistente.</target>
        </trans-unit>
        <trans-unit id="ca9385c00c56b402f0d7c8ffd3817a9453089565" translate="yes" xml:space="preserve">
          <source>Obtaining calibrated probability estimates from decision trees and naive Bayesian classifiers, B. Zadrozny &amp;amp; C. Elkan, ICML 2001</source>
          <target state="translated">Obtenci&amp;oacute;n de estimaciones de probabilidad calibradas de &amp;aacute;rboles de decisi&amp;oacute;n y clasificadores bayesianos ingenuos, B. Zadrozny &amp;amp; C. Elkan, ICML 2001</target>
        </trans-unit>
        <trans-unit id="e90a2c57a395bd5ca1744a90561d5ec67c512ffb" translate="yes" xml:space="preserve">
          <source>Obviously when the number of features increases so does the memory consumption of each example. Indeed, for a matrix of \(M\) instances with \(N\) features, the space complexity is in \(O(NM)\). From a computing perspective it also means that the number of basic operations (e.g., multiplications for vector-matrix products in linear models) increases too. Here is a graph of the evolution of the prediction latency with the number of features:</source>
          <target state="translated">Obviamente,cuando el número de características aumenta,también lo hace el consumo de memoria de cada ejemplo.De hecho,para una matriz de instancias con características,la complejidad del espacio está en O(NM).Desde la perspectiva de la computación también significa que el número de operaciones básicas (por ejemplo,las multiplicaciones para los productos de matriz vectorial en los modelos lineales)también aumenta.Aquí hay un gráfico de la evolución de la latencia de la predicción con el número de características:</target>
        </trans-unit>
        <trans-unit id="215c08c61e401481973fc6ab07ef3f7e0eb253cc" translate="yes" xml:space="preserve">
          <source>Obviously, such an exhaustive search can be expensive. If we have multiple CPU cores at our disposal, we can tell the grid searcher to try these eight parameter combinations in parallel with the &lt;code&gt;n_jobs&lt;/code&gt; parameter. If we give this parameter a value of &lt;code&gt;-1&lt;/code&gt;, grid search will detect how many cores are installed and use them all:</source>
          <target state="translated">Evidentemente, una b&amp;uacute;squeda tan exhaustiva puede resultar cara. Si tenemos varios n&amp;uacute;cleos de CPU a nuestra disposici&amp;oacute;n, podemos decirle al buscador de cuadr&amp;iacute;cula que pruebe estas ocho combinaciones de par&amp;aacute;metros en paralelo con el par&amp;aacute;metro &lt;code&gt;n_jobs&lt;/code&gt; . Si le damos a este par&amp;aacute;metro un valor de &lt;code&gt;-1&lt;/code&gt; , la b&amp;uacute;squeda en la cuadr&amp;iacute;cula detectar&amp;aacute; cu&amp;aacute;ntos n&amp;uacute;cleos est&amp;aacute;n instalados y los usar&amp;aacute; todos:</target>
        </trans-unit>
        <trans-unit id="b4b9ad57c64718cb6c7c5d4cbab51ee018de2ade" translate="yes" xml:space="preserve">
          <source>Occurrence count is a good start but there is an issue: longer documents will have higher average count values than shorter documents, even though they might talk about the same topics.</source>
          <target state="translated">El recuento de incidencias es un buen comienzo,pero hay un problema:los documentos más largos tendrán valores de recuento medios más altos que los documentos más cortos,aunque hablen de los mismos temas.</target>
        </trans-unit>
        <trans-unit id="ca59a1039148105183d8291ca83a4fbed4483e6f" translate="yes" xml:space="preserve">
          <source>Of course, we cannot use the transformer to make any predictions. We should wrap this in a &lt;code&gt;Pipeline&lt;/code&gt; with a classifier (e.g., a &lt;code&gt;DecisionTreeClassifier&lt;/code&gt;) to be able to make predictions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d31e6b35c3a4fbda0c959d2368ee4f77d248cc70" translate="yes" xml:space="preserve">
          <source>Of particular interest is the ability of &lt;a href=&quot;../../modules/generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;sklearn.impute.IterativeImputer&lt;/code&gt;&lt;/a&gt; to mimic the behavior of missForest, a popular imputation package for R. In this example, we have chosen to use &lt;a href=&quot;../../modules/generated/sklearn.ensemble.extratreesregressor#sklearn.ensemble.ExtraTreesRegressor&quot;&gt;&lt;code&gt;sklearn.ensemble.ExtraTreesRegressor&lt;/code&gt;&lt;/a&gt; instead of &lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt;&lt;code&gt;sklearn.ensemble.RandomForestRegressor&lt;/code&gt;&lt;/a&gt; (as in missForest) due to its increased speed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2bfdaca8f6fadc90e32a081ace94f3ad9884e84" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt;. &lt;code&gt;offset_&lt;/code&gt; is defined as follows. When the contamination parameter is set to &amp;ldquo;auto&amp;rdquo;, the offset is equal to -0.5 as the scores of inliers are close to 0 and the scores of outliers are close to -1. When a contamination parameter different than &amp;ldquo;auto&amp;rdquo; is provided, the offset is defined in such a way we obtain the expected number of outliers (samples with decision function &amp;lt; 0) in training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64b2af0bc2328de785be4029344182e16e12fcc6" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt;. Assuming behaviour == &amp;lsquo;new&amp;rsquo;, &lt;code&gt;offset_&lt;/code&gt; is defined as follows. When the contamination parameter is set to &amp;ldquo;auto&amp;rdquo;, the offset is equal to -0.5 as the scores of inliers are close to 0 and the scores of outliers are close to -1. When a contamination parameter different than &amp;ldquo;auto&amp;rdquo; is provided, the offset is defined in such a way we obtain the expected number of outliers (samples with decision function &amp;lt; 0) in training. Assuming the behaviour parameter is set to &amp;lsquo;old&amp;rsquo;, we always have &lt;code&gt;offset_ = -0.5&lt;/code&gt;, making the decision function independent from the contamination parameter.</source>
          <target state="translated">Compensaci&amp;oacute;n utilizada para definir la funci&amp;oacute;n de decisi&amp;oacute;n a partir de las puntuaciones brutas. Tenemos la relaci&amp;oacute;n: &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt; . Suponiendo un comportamiento == 'nuevo', &lt;code&gt;offset_&lt;/code&gt; se define de la siguiente manera. Cuando el par&amp;aacute;metro de contaminaci&amp;oacute;n se establece en &quot;autom&amp;aacute;tico&quot;, la compensaci&amp;oacute;n es igual a -0,5 ya que las puntuaciones de los valores inliers est&amp;aacute;n cerca de 0 y las puntuaciones de los valores at&amp;iacute;picos est&amp;aacute;n cerca de -1. Cuando se proporciona un par&amp;aacute;metro de contaminaci&amp;oacute;n diferente a &amp;ldquo;auto&amp;rdquo;, la compensaci&amp;oacute;n se define de tal manera que obtengamos el n&amp;uacute;mero esperado de valores at&amp;iacute;picos (muestras con funci&amp;oacute;n de decisi&amp;oacute;n &amp;lt;0) en el entrenamiento. Suponiendo que el par&amp;aacute;metro de comportamiento se establece en 'antiguo', siempre tenemos &lt;code&gt;offset_ = -0.5&lt;/code&gt; , lo que hace que la funci&amp;oacute;n de decisi&amp;oacute;n sea independiente del par&amp;aacute;metro de contaminaci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="bbd227107da9d921e8bc12d3a3ca7fd4c0bd101f" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt;. The offset depends on the contamination parameter and is defined in such a way we obtain the expected number of outliers (samples with decision function &amp;lt; 0) in training.</source>
          <target state="translated">Compensaci&amp;oacute;n utilizada para definir la funci&amp;oacute;n de decisi&amp;oacute;n a partir de las puntuaciones brutas. Tenemos la relaci&amp;oacute;n: &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt; . El offset depende del par&amp;aacute;metro de contaminaci&amp;oacute;n y se define de tal manera que obtengamos el n&amp;uacute;mero esperado de valores at&amp;iacute;picos (muestras con funci&amp;oacute;n de decisi&amp;oacute;n &amp;lt;0) en el entrenamiento.</target>
        </trans-unit>
        <trans-unit id="4f4356395ebd6023fbdce24e12feab7e5ca80606" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: decision_function = score_samples - &lt;code&gt;offset_&lt;/code&gt;. The offset is the opposite of &lt;code&gt;intercept_&lt;/code&gt; and is provided for consistency with other outlier detection algorithms.</source>
          <target state="translated">Compensaci&amp;oacute;n utilizada para definir la funci&amp;oacute;n de decisi&amp;oacute;n a partir de las puntuaciones brutas. Tenemos la relaci&amp;oacute;n: decision_function = score_samples - &lt;code&gt;offset_&lt;/code&gt; . El desplazamiento es lo opuesto a &lt;code&gt;intercept_&lt;/code&gt; y se proporciona para mantener la coherencia con otros algoritmos de detecci&amp;oacute;n de valores at&amp;iacute;picos.</target>
        </trans-unit>
        <trans-unit id="9195b75fbc020bb9db88d8b131967914e6de2adf" translate="yes" xml:space="preserve">
          <source>Offset used to obtain binary labels from the raw scores. Observations having a negative_outlier_factor smaller than &lt;code&gt;offset_&lt;/code&gt; are detected as abnormal. The offset is set to -1.5 (inliers score around -1), except when a contamination parameter different than &amp;ldquo;auto&amp;rdquo; is provided. In that case, the offset is defined in such a way we obtain the expected number of outliers in training.</source>
          <target state="translated">Desplazamiento utilizado para obtener etiquetas binarias a partir de las puntuaciones brutas. Las observaciones que tienen un &lt;code&gt;offset_&lt;/code&gt; menor que el desplazamiento_ se detectan como anormales. La compensaci&amp;oacute;n se establece en -1,5 (los valores inliers tienen una puntuaci&amp;oacute;n de alrededor de -1), excepto cuando se proporciona un par&amp;aacute;metro de contaminaci&amp;oacute;n diferente de &quot;auto&quot;. En ese caso, el desplazamiento se define de tal manera que obtengamos el n&amp;uacute;mero esperado de valores at&amp;iacute;picos en el entrenamiento.</target>
        </trans-unit>
        <trans-unit id="36fd88d1882973048dccc0ac8ca74e6c4f6b2ec1" translate="yes" xml:space="preserve">
          <source>Often features are not given as continuous values but categorical. For example a person could have features &lt;code&gt;[&quot;male&quot;, &quot;female&quot;]&lt;/code&gt;, &lt;code&gt;[&quot;from Europe&quot;, &quot;from US&quot;, &quot;from Asia&quot;]&lt;/code&gt;, &lt;code&gt;[&quot;uses Firefox&quot;, &quot;uses Chrome&quot;, &quot;uses Safari&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt;. Such features can be efficiently coded as integers, for instance &lt;code&gt;[&quot;male&quot;, &quot;from US&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt; could be expressed as &lt;code&gt;[0, 1, 3]&lt;/code&gt; while &lt;code&gt;[&quot;female&quot;, &quot;from Asia&quot;, &quot;uses Chrome&quot;]&lt;/code&gt; would be &lt;code&gt;[1, 2, 1]&lt;/code&gt;.</source>
          <target state="translated">A menudo, las caracter&amp;iacute;sticas no se dan como valores continuos sino categ&amp;oacute;ricos. Por ejemplo, una persona podr&amp;iacute;a tener caracter&amp;iacute;sticas &lt;code&gt;[&quot;male&quot;, &quot;female&quot;]&lt;/code&gt; , &lt;code&gt;[&quot;from Europe&quot;, &quot;from US&quot;, &quot;from Asia&quot;]&lt;/code&gt; , &lt;code&gt;[&quot;uses Firefox&quot;, &quot;uses Chrome&quot;, &quot;uses Safari&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt; . Estas caracter&amp;iacute;sticas se pueden codificar de manera eficiente como n&amp;uacute;meros enteros, por ejemplo, &lt;code&gt;[&quot;male&quot;, &quot;from US&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt; podr&amp;iacute;a expresarse como &lt;code&gt;[0, 1, 3]&lt;/code&gt; mientras que &lt;code&gt;[&quot;female&quot;, &quot;from Asia&quot;, &quot;uses Chrome&quot;]&lt;/code&gt; ser&amp;iacute;a &lt;code&gt;[1, 2, 1]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3d1f21e77b74fb7449c1f9b0570088bab1bd6c20" translate="yes" xml:space="preserve">
          <source>Often features do not contribute equally to predict the target response; in many situations the majority of the features are in fact irrelevant. When interpreting a model, the first question usually is: what are those important features and how do they contributing in predicting the target response?</source>
          <target state="translated">A menudo las características no contribuyen por igual a predecir la respuesta del objetivo;en muchas situaciones la mayoría de las características son de hecho irrelevantes.Al interpretar un modelo,la primera pregunta suele ser:¿cuáles son esas características importantes y cómo contribuyen a predecir la respuesta del objetivo?</target>
        </trans-unit>
        <trans-unit id="cd4e41585434180ead957592fb3bbf7ed399aaf1" translate="yes" xml:space="preserve">
          <source>Often it&amp;rsquo;s useful to add complexity to the model by considering nonlinear features of the input data. A simple and common method to use is polynomial features, which can get features&amp;rsquo; high-order and interaction terms. It is implemented in &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt;&lt;code&gt;PolynomialFeatures&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">A menudo es &amp;uacute;til agregar complejidad al modelo al considerar caracter&amp;iacute;sticas no lineales de los datos de entrada. Un m&amp;eacute;todo simple y com&amp;uacute;n de usar son las caracter&amp;iacute;sticas polinomiales, que pueden obtener t&amp;eacute;rminos de interacci&amp;oacute;n y de orden superior de las caracter&amp;iacute;sticas. Est&amp;aacute; implementado en &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt; &lt;code&gt;PolynomialFeatures&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="e408c9080a80cd5dee3de8b66c635dedc13aaef1" translate="yes" xml:space="preserve">
          <source>Often the hardest part of solving a machine learning problem can be finding the right estimator for the job.</source>
          <target state="translated">A menudo la parte más difícil de resolver un problema de aprendizaje de una máquina puede ser encontrar el estimador adecuado para el trabajo.</target>
        </trans-unit>
        <trans-unit id="7b3890ce47285c29340d329412b63023825aa83a" translate="yes" xml:space="preserve">
          <source>Often, you will want to convert an existing Python function into a transformer to assist in data cleaning or processing. You can implement a transformer from an arbitrary function with &lt;a href=&quot;generated/sklearn.preprocessing.functiontransformer#sklearn.preprocessing.FunctionTransformer&quot;&gt;&lt;code&gt;FunctionTransformer&lt;/code&gt;&lt;/a&gt;. For example, to build a transformer that applies a log transformation in a pipeline, do:</source>
          <target state="translated">A menudo, querr&amp;aacute; convertir una funci&amp;oacute;n de Python existente en un transformador para ayudar en la limpieza o el procesamiento de datos. Puede implementar un transformador a partir de una funci&amp;oacute;n arbitraria con &lt;a href=&quot;generated/sklearn.preprocessing.functiontransformer#sklearn.preprocessing.FunctionTransformer&quot;&gt; &lt;code&gt;FunctionTransformer&lt;/code&gt; &lt;/a&gt; . Por ejemplo, para construir un transformador que aplica una transformaci&amp;oacute;n de registro en una canalizaci&amp;oacute;n, haga lo siguiente:</target>
        </trans-unit>
        <trans-unit id="3a99e53e60f11cdf73347e45ac4d6a8ace6059f3" translate="yes" xml:space="preserve">
          <source>Ojala and Garriga. Permutation Tests for Studying Classifier Performance. The Journal of Machine Learning Research (2010) vol. 11</source>
          <target state="translated">Ojala y Garriga.Pruebas de permutación para estudiar el rendimiento de los clasificadores.The Journal of Machine Learning Research (2010)vol.11</target>
        </trans-unit>
        <trans-unit id="4a78f8007754f084c0abbe2f8fe08318ed671586" translate="yes" xml:space="preserve">
          <source>Ojala and Garriga. Permutation Tests for Studying Classifier Performance. The Journal of Machine Learning Research (2010) vol. 11 &lt;a href=&quot;http://www.jmlr.org/papers/volume11/ojala10a/ojala10a.pdf&quot;&gt;[pdf]&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d82f7d71018bfffc818f9af5a47b640ae31345cd" translate="yes" xml:space="preserve">
          <source>Olga Troyanskaya, Michael Cantor, Gavin Sherlock, Pat Brown, Trevor Hastie, Robert Tibshirani, David Botstein and Russ B. Altman, Missing value estimation methods for DNA microarrays, BIOINFORMATICS Vol. 17 no. 6, 2001 Pages 520-525.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9aa2dba7b6fd084ffccc78f5a1359dabe654fd3" translate="yes" xml:space="preserve">
          <source>On &amp;ldquo;small&amp;rdquo; datasets (less than a few hundred points), the quantile transformer is prone to overfitting. The use of the power transform is then recommended.</source>
          <target state="translated">En conjuntos de datos &amp;ldquo;peque&amp;ntilde;os&amp;rdquo; (menos de unos pocos cientos de puntos), el transformador de cuantiles es propenso a sobreajustarse. A continuaci&amp;oacute;n, se recomienda el uso de la transformaci&amp;oacute;n de potencia.</target>
        </trans-unit>
        <trans-unit id="d0f97ce49fc19f915019c9855a072a57bec1774a" translate="yes" xml:space="preserve">
          <source>On L2-normalized data, this function is equivalent to linear_kernel.</source>
          <target state="translated">En los datos normalizados de L2,esta función es equivalente al núcleo_lineal.</target>
        </trans-unit>
        <trans-unit id="d978bf78cd4e4a7f593a82a72e7f97f769b529af" translate="yes" xml:space="preserve">
          <source>On Spectral Clustering: Analysis and an algorithm, 2001 Andrew Y. Ng, Michael I. Jordan, Yair Weiss &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&lt;/a&gt;</source>
          <target state="translated">Sobre agrupaci&amp;oacute;n espectral: an&amp;aacute;lisis y algoritmo, 2001 Andrew Y. Ng, Michael I. Jordan, Yair Weiss &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c042431c0ae0ab161c8569f0669e312480d87b4b" translate="yes" xml:space="preserve">
          <source>On the combination of forecast probabilities for consecutive precipitation periods. Wea. Forecasting, 5, 640&amp;ndash;650., Wilks, D. S., 1990a</source>
          <target state="translated">Sobre la combinaci&amp;oacute;n de probabilidades de pron&amp;oacute;stico para per&amp;iacute;odos de precipitaci&amp;oacute;n consecutivos. Wea. Forecasting, 5, 640&amp;ndash;650., Wilks, DS, 1990a</target>
        </trans-unit>
        <trans-unit id="05fe02625303adf1ec7a757f80f079f0cfb615a5" translate="yes" xml:space="preserve">
          <source>On the contrary the classical finite mixture model with a Dirichlet distribution prior will favor more uniformly weighted components and therefore tends to divide natural clusters into unnecessary sub-components.</source>
          <target state="translated">Por el contrario,el modelo clásico de mezcla finita con una distribución Dirichlet previa favorecerá los componentes más uniformemente ponderados y por lo tanto tiende a dividir los cúmulos naturales en subcomponentes innecesarios.</target>
        </trans-unit>
        <trans-unit id="a881270be1f0c36e65b4d9407272c7539d9eb831" translate="yes" xml:space="preserve">
          <source>On the diabetes dataset, find the optimal regularization parameter alpha.</source>
          <target state="translated">En el conjunto de datos de la diabetes,encuentra el parámetro óptimo de regularización alfa.</target>
        </trans-unit>
        <trans-unit id="d20d94e86b214eba2d2a083bdeb7805cae8a5dbd" translate="yes" xml:space="preserve">
          <source>On the digits dataset, plot the cross-validation score of a &lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; estimator with an linear kernel as a function of parameter &lt;code&gt;C&lt;/code&gt; (use a logarithmic grid of points, from 1 to 10).</source>
          <target state="translated">En el conjunto de datos de d&amp;iacute;gitos, grafique la puntuaci&amp;oacute;n de validaci&amp;oacute;n cruzada de un estimador de &lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt; con un kernel lineal en funci&amp;oacute;n del par&amp;aacute;metro &lt;code&gt;C&lt;/code&gt; (use una cuadr&amp;iacute;cula logar&amp;iacute;tmica de puntos, de 1 a 10).</target>
        </trans-unit>
        <trans-unit id="70934046ec7198c15e5255a457f5b5f8aad47e7d" translate="yes" xml:space="preserve">
          <source>On the flip side, although naive Bayes is known as a decent classifier, it is known to be a bad estimator, so the probability outputs from &lt;code&gt;predict_proba&lt;/code&gt; are not to be taken too seriously.</source>
          <target state="translated">Por otro lado, aunque Bayes ingenuo se conoce como un clasificador decente, se sabe que es un mal estimador, por lo que las salidas de probabilidad de &lt;code&gt;predict_proba&lt;/code&gt; no deben tomarse demasiado en serio.</target>
        </trans-unit>
        <trans-unit id="11ff999f3cb9557f779d2d870e0da3265a08df2a" translate="yes" xml:space="preserve">
          <source>On the following figure we are fitting a dataset not well-depicted by a Gaussian mixture. Adjusting the &lt;code&gt;weight_concentration_prior&lt;/code&gt;, parameter of the &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt; controls the number of components used to fit this data. We also present on the last two plots a random sampling generated from the two resulting mixtures.</source>
          <target state="translated">En la siguiente figura, estamos ajustando un conjunto de datos que no est&amp;aacute; bien representado por una mezcla gaussiana. Al ajustar el &lt;code&gt;weight_concentration_prior&lt;/code&gt; , el par&amp;aacute;metro de &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt; &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; &lt;/a&gt; controla el n&amp;uacute;mero de componentes utilizados para ajustar estos datos. Tambi&amp;eacute;n presentamos en las dos &amp;uacute;ltimas parcelas un muestreo aleatorio generado a partir de las dos mezclas resultantes.</target>
        </trans-unit>
        <trans-unit id="e0986e74679be65bf8af00d65ae0c2feb9ddbaaf" translate="yes" xml:space="preserve">
          <source>On the graph of webpages and links those values are called the PageRank scores by Google.</source>
          <target state="translated">En el gráfico de las páginas web y los enlaces,esos valores se llaman los puntajes de PageRank de Google.</target>
        </trans-unit>
        <trans-unit id="56dda47abffe67d113799c44a62fa9885afd300e" translate="yes" xml:space="preserve">
          <source>On the left side the learning curve of a naive Bayes classifier is shown for the digits dataset. Note that the training score and the cross-validation score are both not very good at the end. However, the shape of the curve can be found in more complex datasets very often: the training score is very high at the beginning and decreases and the cross-validation score is very low at the beginning and increases. On the right side we see the learning curve of an SVM with RBF kernel. We can see clearly that the training score is still around the maximum and the validation score could be increased with more training samples.</source>
          <target state="translated">En el lado izquierdo se muestra la curva de aprendizaje de un ingenuo clasificador Bayes para el conjunto de datos de los dígitos.Observe que la puntuación de entrenamiento y la puntuación de validación cruzada no son muy buenas al final.Sin embargo,la forma de la curva se puede encontrar en conjuntos de datos más complejos muy a menudo:el puntaje de entrenamiento es muy alto al principio y disminuye y el puntaje de validación cruzada es muy bajo al principio y aumenta.A la derecha vemos la curva de aprendizaje de un SVM con núcleo RBF.Podemos ver claramente que la puntuación de entrenamiento está todavía alrededor del máximo y la puntuación de validación podría aumentarse con más muestras de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="8734edc10a3853b319869c6d2b6c4a8a8cc0d2c2" translate="yes" xml:space="preserve">
          <source>On the other hand, &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; implements &amp;ldquo;one-vs-the-rest&amp;rdquo; multi-class strategy, thus training &lt;code&gt;n_classes&lt;/code&gt; models.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f954522d1ed09b2ae8779aaabe3dfa6c3ae4de4e" translate="yes" xml:space="preserve">
          <source>On the other hand, &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; implements &amp;ldquo;one-vs-the-rest&amp;rdquo; multi-class strategy, thus training n_class models. If there are only two classes, only one model is trained:</source>
          <target state="translated">Por otro lado, &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt; implementa la estrategia de clases m&amp;uacute;ltiples &amp;ldquo;uno contra el resto&amp;rdquo;, por lo que entrena modelos n_class. Si solo hay dos clases, solo se entrena un modelo:</target>
        </trans-unit>
        <trans-unit id="b6899866fd2175cc1abac032537947b3dc26ecc5" translate="yes" xml:space="preserve">
          <source>On the other hand, the weights obtained with regularization are more stable (see the &lt;a href=&quot;../../modules/linear_model#ridge-regression&quot;&gt;Ridge regression and classification&lt;/a&gt; User Guide section). This increased stability is visible from the plot, obtained from data perturbations, in a cross validation. This plot can be compared with the &lt;a href=&quot;#covariation&quot;&gt;previous one&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86b28d625cb14fb5485ff23b3eca337a06cecaf2" translate="yes" xml:space="preserve">
          <source>On the plots, train data is shown as dots, while test data is shown as crosses. The iris dataset is four-dimensional. Only the first two dimensions are shown here, and thus some points are separated in other dimensions.</source>
          <target state="translated">En los gráficos,los datos del tren se muestran como puntos,mientras que los datos de prueba se muestran como cruces.El conjunto de datos del iris es cuatridimensional.Aquí sólo se muestran las dos primeras dimensiones,y así algunos puntos se separan en otras dimensiones.</target>
        </trans-unit>
        <trans-unit id="fc82fddedc10b52f931e2d57575d5196e2c6dd2d" translate="yes" xml:space="preserve">
          <source>On the twenty newsgroups on the other hand the dimensionality can be decreased from 56436 down to 10000 while reasonably preserving pairwise distances.</source>
          <target state="translated">Por otra parte,en los veinte grupos de noticias,la dimensionalidad puede reducirse de 56436 a 10.000,conservando razonablemente las distancias entre pares.</target>
        </trans-unit>
        <trans-unit id="43f757b33d0dc72835f44fdaffe6492249fea14f" translate="yes" xml:space="preserve">
          <source>On this example, the first two rows represent linearly non-separable datasets (moons and concentric circles) while the third is approximately linearly separable. On the two linearly non-separable datasets, feature discretization largely increases the performance of linear classifiers. On the linearly separable dataset, feature discretization decreases the performance of linear classifiers. Two non-linear classifiers are also shown for comparison.</source>
          <target state="translated">En este ejemplo,las dos primeras filas representan conjuntos de datos linealmente no separables (lunas y círculos concéntricos)mientras que la tercera es aproximadamente linealmente separable.En los dos conjuntos de datos linealmente no separables,la discretización de las características aumenta en gran medida el rendimiento de los clasificadores lineales.En el conjunto de datos linealmente separables,la discretización de las características disminuye el rendimiento de los clasificadores lineales.También se muestran dos clasificadores no lineales para su comparación.</target>
        </trans-unit>
        <trans-unit id="3162e7b183de96ba6bf8f8587d34db62edc4b217" translate="yes" xml:space="preserve">
          <source>Once the optimization problem is solved, the output of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt; for a given sample \(x\) becomes:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07aa293f8032a091371331fd78ad762690098968" translate="yes" xml:space="preserve">
          <source>Once trained, we can export the tree in &lt;a href=&quot;http://www.graphviz.org/&quot;&gt;Graphviz&lt;/a&gt; format using the &lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt;&lt;code&gt;export_graphviz&lt;/code&gt;&lt;/a&gt; exporter. If you use the &lt;a href=&quot;http://conda.io&quot;&gt;conda&lt;/a&gt; package manager, the graphviz binaries and the python package can be installed with</source>
          <target state="translated">Una vez entrenado, podemos exportar el &amp;aacute;rbol en formato &lt;a href=&quot;http://www.graphviz.org/&quot;&gt;Graphviz&lt;/a&gt; usando el exportador &lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt; &lt;code&gt;export_graphviz&lt;/code&gt; &lt;/a&gt; . Si usa el &lt;a href=&quot;http://conda.io&quot;&gt;administrador de&lt;/a&gt; paquetes conda , los binarios graphviz y el paquete python se pueden instalar con</target>
        </trans-unit>
        <trans-unit id="ed70a2ff6fe86d781de8936cfd7e74b27161e201" translate="yes" xml:space="preserve">
          <source>Once trained, you can plot the tree with the &lt;a href=&quot;generated/sklearn.tree.plot_tree#sklearn.tree.plot_tree&quot;&gt;&lt;code&gt;plot_tree&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28066560ad38f3f5dad45c5652f6a508803ee2c3" translate="yes" xml:space="preserve">
          <source>One can always drop the first column for each feature:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0471206705323c6d53e55b1c35697675c16b2c95" translate="yes" xml:space="preserve">
          <source>One can discard categories not seen during &lt;code&gt;fit&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1a30cbb2660486e3a34f97fc6f2ebc285138723" translate="yes" xml:space="preserve">
          <source>One can observe here that logistic regression is well calibrated as its curve is nearly diagonal. Linear SVC&amp;rsquo;s calibration curve or reliability diagram has a sigmoid curve, which is typical for an under-confident classifier. In the case of LinearSVC, this is caused by the margin property of the hinge loss, which lets the model focus on hard samples that are close to the decision boundary (the support vectors). Both kinds of calibration can fix this issue and yield nearly identical results. The next figure shows the calibration curve of Gaussian naive Bayes on the same data, with both kinds of calibration and also without calibration.</source>
          <target state="translated">Aqu&amp;iacute; se puede observar que la regresi&amp;oacute;n log&amp;iacute;stica est&amp;aacute; bien calibrada ya que su curva es casi diagonal. La curva de calibraci&amp;oacute;n de SVC lineal o el diagrama de confiabilidad tiene una curva sigmoidea, que es t&amp;iacute;pica de un clasificador con poca confianza. En el caso de LinearSVC, esto se debe a la propiedad de margen de la p&amp;eacute;rdida de bisagra, que permite que el modelo se centre en muestras duras que est&amp;aacute;n cerca del l&amp;iacute;mite de decisi&amp;oacute;n (los vectores de soporte). Ambos tipos de calibraci&amp;oacute;n pueden solucionar este problema y producir resultados casi id&amp;eacute;nticos. La siguiente figura muestra la curva de calibraci&amp;oacute;n de Bayes ingenuo gaussiano sobre los mismos datos, con ambos tipos de calibraci&amp;oacute;n y tambi&amp;eacute;n sin calibraci&amp;oacute;n.</target>
        </trans-unit>
        <trans-unit id="cce2911ccedb3667eaee804d61905917155ff5c2" translate="yes" xml:space="preserve">
          <source>One can observe that with homoscedastic noise both FA and PCA succeed in recovering the size of the low rank subspace. The likelihood with PCA is higher than FA in this case. However PCA fails and overestimates the rank when heteroscedastic noise is present. Under appropriate circumstances the low rank models are more likely than shrinkage models.</source>
          <target state="translated">Se puede observar que con el ruido homosexual tanto el FA como el PCA logran recuperar el tamaño del subespacio de bajo rango.La probabilidad con PCA es mayor que con FA en este caso.Sin embargo,el PCA falla y sobreestima el rango cuando hay ruido heteroscedástico.Bajo circunstancias apropiadas,los modelos de rango bajo son más probables que los modelos de contracción.</target>
        </trans-unit>
        <trans-unit id="5282642c4183bcd75159c8592f0d08e21bceb6b2" translate="yes" xml:space="preserve">
          <source>One can permute 0 and 1 in the predicted labels, rename 2 to 3 and get the same score:</source>
          <target state="translated">Se puede permutar 0 y 1 en las etiquetas de predicción,renombrar 2 a 3 y obtener la misma puntuación:</target>
        </trans-unit>
        <trans-unit id="f2e197fb258bad312502ac44a4234fe5a6877692" translate="yes" xml:space="preserve">
          <source>One can permute 0 and 1 in the predicted labels, rename 2 to 3, and get the same score:</source>
          <target state="translated">Se puede permutar 0 y 1 en las etiquetas de predicción,renombrar 2 a 3,y obtener la misma puntuación:</target>
        </trans-unit>
        <trans-unit id="e33d3feeafd2b2e6157812f722f3e7fb8358ba7c" translate="yes" xml:space="preserve">
          <source>One can see that Gaussian naive Bayes performs very badly but does so in an other way than linear SVC: While linear SVC exhibited a sigmoid calibration curve, Gaussian naive Bayes&amp;rsquo; calibration curve has a transposed-sigmoid shape. This is typical for an over-confident classifier. In this case, the classifier&amp;rsquo;s overconfidence is caused by the redundant features which violate the naive Bayes assumption of feature-independence.</source>
          <target state="translated">Se puede ver que Bayes ingenuo gaussiano se desempe&amp;ntilde;a muy mal, pero lo hace de una manera diferente al SVC lineal: mientras que el SVC lineal exhibi&amp;oacute; una curva de calibraci&amp;oacute;n sigmoidea, la curva de calibraci&amp;oacute;n de Bayes ingenuo gaussiano tiene una forma sigmoide transpuesta. Esto es t&amp;iacute;pico de un clasificador con exceso de confianza. En este caso, el exceso de confianza del clasificador es causado por las caracter&amp;iacute;sticas redundantes que violan el supuesto ingenuo de Bayes de independencia de caracter&amp;iacute;sticas.</target>
        </trans-unit>
        <trans-unit id="15c1fc9ad0e4ecc150e99497720122e04673bd38" translate="yes" xml:space="preserve">
          <source>One can see that NCA enforces a clustering of the data that is visually meaningful despite the large reduction in dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82900035fe0f11887cd04ee23edd3ee0d6e6bf18" translate="yes" xml:space="preserve">
          <source>One common pattern within machine learning is to use linear models trained on nonlinear functions of the data. This approach maintains the generally fast performance of linear methods, while allowing them to fit a much wider range of data.</source>
          <target state="translated">Un patrón común dentro del aprendizaje de las máquinas es utilizar modelos lineales entrenados en funciones no lineales de los datos.Este enfoque mantiene el rendimiento generalmente rápido de los métodos lineales,a la vez que les permite ajustarse a una gama mucho más amplia de datos.</target>
        </trans-unit>
        <trans-unit id="fa0690f9f0e7bd840855247cda57999b3e6dd175" translate="yes" xml:space="preserve">
          <source>One common way of performing outlier detection is to assume that the regular data come from a known distribution (e.g. data are Gaussian distributed). From this assumption, we generally try to define the &amp;ldquo;shape&amp;rdquo; of the data, and can define outlying observations as observations which stand far enough from the fit shape.</source>
          <target state="translated">Una forma com&amp;uacute;n de realizar la detecci&amp;oacute;n de valores at&amp;iacute;picos es asumir que los datos regulares provienen de una distribuci&amp;oacute;n conocida (por ejemplo, los datos tienen una distribuci&amp;oacute;n gaussiana). A partir de esta suposici&amp;oacute;n, generalmente tratamos de definir la &quot;forma&quot; de los datos y podemos definir las observaciones perif&amp;eacute;ricas como observaciones que est&amp;aacute;n lo suficientemente lejos de la forma ajustada.</target>
        </trans-unit>
        <trans-unit id="9d03fc67e51edb11ba912aa95289c786040f1c20" translate="yes" xml:space="preserve">
          <source>One drawback of kernel methods is, that it might be necessary to store many kernel values \(k(x_i, x_j)\) during optimization. If a kernelized classifier is applied to new data \(y_j\), \(k(x_i, y_j)\) needs to be computed to make predictions, possibly for many different \(x_i\) in the training set.</source>
          <target state="translated">Una desventaja de los métodos de kernel es que podría ser necesario almacenar muchos valores de kernel \N (k(x_i,x_j)\N durante la optimización.Si se aplica un clasificador del núcleo a los nuevos datos (y_j),(k(x_i,y_j))debe ser calculado para hacer predicciones,posiblemente para muchos diferentes (x_i)en el conjunto de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="cdf9b1d4485b82e7ed1999a3fb7fb5adb4dbca12" translate="yes" xml:space="preserve">
          <source>One efficient way of performing outlier detection in high-dimensional datasets is to use random forests. The &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt; &amp;lsquo;isolates&amp;rsquo; observations by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature.</source>
          <target state="translated">Una forma eficaz de realizar la detecci&amp;oacute;n de valores at&amp;iacute;picos en conjuntos de datos de alta dimensi&amp;oacute;n es utilizar bosques aleatorios. El &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt; &lt;code&gt;ensemble.IsolationForest&lt;/code&gt; &lt;/a&gt; 'a&amp;iacute;sla' las observaciones seleccionando aleatoriamente una caracter&amp;iacute;stica y luego seleccionando aleatoriamente un valor dividido entre los valores m&amp;aacute;ximo y m&amp;iacute;nimo de la caracter&amp;iacute;stica seleccionada.</target>
        </trans-unit>
        <trans-unit id="b5c13007d70aa1a0e4a2816404f0d61b9e0ac135" translate="yes" xml:space="preserve">
          <source>One important thing to note is that the algorithms implemented in this module can take different kinds of matrix as input. All the methods accept standard data matrices of shape &lt;code&gt;[n_samples, n_features]&lt;/code&gt;. These can be obtained from the classes in the &lt;a href=&quot;classes#module-sklearn.feature_extraction&quot;&gt;&lt;code&gt;sklearn.feature_extraction&lt;/code&gt;&lt;/a&gt; module. For &lt;a href=&quot;generated/sklearn.cluster.affinitypropagation#sklearn.cluster.AffinityPropagation&quot;&gt;&lt;code&gt;AffinityPropagation&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.cluster.spectralclustering#sklearn.cluster.SpectralClustering&quot;&gt;&lt;code&gt;SpectralClustering&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt;&lt;code&gt;DBSCAN&lt;/code&gt;&lt;/a&gt; one can also input similarity matrices of shape &lt;code&gt;[n_samples, n_samples]&lt;/code&gt;. These can be obtained from the functions in the &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt;&lt;/a&gt; module.</source>
          <target state="translated">Una cosa importante a tener en cuenta es que los algoritmos implementados en este m&amp;oacute;dulo pueden tomar diferentes tipos de matriz como entrada. Todos los m&amp;eacute;todos aceptan matrices de datos est&amp;aacute;ndar de forma &lt;code&gt;[n_samples, n_features]&lt;/code&gt; . Estos se pueden obtener de las clases en el m&amp;oacute;dulo &lt;a href=&quot;classes#module-sklearn.feature_extraction&quot;&gt; &lt;code&gt;sklearn.feature_extraction&lt;/code&gt; &lt;/a&gt; . Para &lt;a href=&quot;generated/sklearn.cluster.affinitypropagation#sklearn.cluster.AffinityPropagation&quot;&gt; &lt;code&gt;AffinityPropagation&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.cluster.spectralclustering#sklearn.cluster.SpectralClustering&quot;&gt; &lt;code&gt;SpectralClustering&lt;/code&gt; &lt;/a&gt; y &lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt; &lt;code&gt;DBSCAN&lt;/code&gt; &lt;/a&gt; tambi&amp;eacute;n se pueden ingresar matrices de similitud de forma &lt;code&gt;[n_samples, n_samples]&lt;/code&gt; . Estos se pueden obtener de las funciones del m&amp;oacute;dulo &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt; &lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="deab058e87e7d8cac343ed7483a7cf721eca4119" translate="yes" xml:space="preserve">
          <source>One method to address the regularization problem is to use multiple weight vectors in each neighborhood. This is the essence of &lt;em&gt;modified locally linear embedding&lt;/em&gt; (MLLE). MLLE can be performed with function &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt;&lt;code&gt;locally_linear_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt;&lt;code&gt;LocallyLinearEmbedding&lt;/code&gt;&lt;/a&gt;, with the keyword &lt;code&gt;method = 'modified'&lt;/code&gt;. It requires &lt;code&gt;n_neighbors &amp;gt; n_components&lt;/code&gt;.</source>
          <target state="translated">Un m&amp;eacute;todo para abordar el problema de la regularizaci&amp;oacute;n es utilizar m&amp;uacute;ltiples vectores de peso en cada vecindario. &amp;Eacute;sta es la esencia de &lt;em&gt;la incrustaci&amp;oacute;n local lineal modificada&lt;/em&gt; (MLLE). MLLE se puede realizar con la funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt; &lt;code&gt;locally_linear_embedding&lt;/code&gt; &lt;/a&gt; o su contraparte orientada a objetos &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt; &lt;code&gt;LocallyLinearEmbedding&lt;/code&gt; &lt;/a&gt; , con la palabra clave &lt;code&gt;method = 'modified'&lt;/code&gt; . Requiere &lt;code&gt;n_neighbors &amp;gt; n_components&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8b0abef56ded5ecf131b35733971a4004aa542f0" translate="yes" xml:space="preserve">
          <source>One might alternatively consider a collection of character n-grams, a representation resilient against misspellings and derivations.</source>
          <target state="translated">Se podría considerar alternativamente una colección de caracteres n-gramas,una representación resistente a los errores ortográficos y las derivaciones.</target>
        </trans-unit>
        <trans-unit id="9787d541696df0f6a8e4fd9ada866862db9e0d0c" translate="yes" xml:space="preserve">
          <source>One might want to drop one of the two columns only for features with 2 categories. In this case, you can set the parameter &lt;code&gt;drop='if_binary'&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61c492958dc81c1a6d9f632bafd3909d2bb143b8" translate="yes" xml:space="preserve">
          <source>One of the challenges which is faced here is that the solvers can fail to converge to a well-conditioned estimate. The corresponding values of alpha then come out as missing values, but the optimum may be close to these missing values.</source>
          <target state="translated">Uno de los desafíos que se enfrentan aquí es que los solucionadores pueden no converger en una estimación bien condicionada.Los valores correspondientes del alfa salen entonces como valores perdidos,pero el óptimo puede estar cerca de estos valores perdidos.</target>
        </trans-unit>
        <trans-unit id="70a04d887115ca6d6700f00cd1afa9bf1cffed38" translate="yes" xml:space="preserve">
          <source>One of the earliest approaches to manifold learning is the Isomap algorithm, short for Isometric Mapping. Isomap can be viewed as an extension of Multi-dimensional Scaling (MDS) or Kernel PCA. Isomap seeks a lower-dimensional embedding which maintains geodesic distances between all points. Isomap can be performed with the object &lt;a href=&quot;generated/sklearn.manifold.isomap#sklearn.manifold.Isomap&quot;&gt;&lt;code&gt;Isomap&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Uno de los primeros enfoques del aprendizaje m&amp;uacute;ltiple es el algoritmo Isomap, abreviatura de Isometric Mapping. Isomap se puede ver como una extensi&amp;oacute;n del Escalado multidimensional (MDS) o Kernel PCA. Isomap busca una incrustaci&amp;oacute;n de menor dimensi&amp;oacute;n que mantenga las distancias geod&amp;eacute;sicas entre todos los puntos. Isomap se puede realizar con el objeto &lt;a href=&quot;generated/sklearn.manifold.isomap#sklearn.manifold.Isomap&quot;&gt; &lt;code&gt;Isomap&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="8d30b63915c687687af955c31a96ac094f06cb9f" translate="yes" xml:space="preserve">
          <source>One of the most straight-forward concerns one may have when using/choosing a machine learning toolkit is the latency at which predictions can be made in a production environment.</source>
          <target state="translated">Una de las preocupaciones más directas que se pueden tener cuando se utiliza o se elige un juego de herramientas de aprendizaje automático es la latencia con la que se pueden hacer predicciones en un entorno de producción.</target>
        </trans-unit>
        <trans-unit id="e3967d3ba22f4ac7f4c1ab09bac9634bd847ca9c" translate="yes" xml:space="preserve">
          <source>One of:</source>
          <target state="translated">Uno de:</target>
        </trans-unit>
        <trans-unit id="d25b0126083dd51df31e94af07b51bd893fc80ee" translate="yes" xml:space="preserve">
          <source>One other useful application of kernel density estimation is to learn a non-parametric generative model of a dataset in order to efficiently draw new samples from this generative model. Here is an example of using this process to create a new set of hand-written digits, using a Gaussian kernel learned on a PCA projection of the data:</source>
          <target state="translated">Otra aplicación útil de la estimación de la densidad del núcleo es aprender un modelo generativo no paramétrico de un conjunto de datos para extraer eficientemente nuevas muestras de este modelo generativo.He aquí un ejemplo de la utilización de este proceso para crear un nuevo conjunto de dígitos escritos a mano,utilizando un núcleo gaussiano aprendido en una proyección PCA de los datos:</target>
        </trans-unit>
        <trans-unit id="fee8a97f6bc38e5962a611f176ea8084294905c7" translate="yes" xml:space="preserve">
          <source>One possible difference with the &lt;code&gt;glasso&lt;/code&gt; R package is that the diagonal coefficients are not penalized.</source>
          <target state="translated">Una posible diferencia con el paquete &lt;code&gt;glasso&lt;/code&gt; R es que los coeficientes diagonales no est&amp;aacute;n penalizados.</target>
        </trans-unit>
        <trans-unit id="a927f9db65135d8f0443d271707e3494a0dc3ae7" translate="yes" xml:space="preserve">
          <source>One type of imputation algorithm is univariate, which imputes values in the i-th feature dimension using only non-missing values in that feature dimension (e.g. &lt;code&gt;impute.SimpleImputer&lt;/code&gt;). By contrast, multivariate imputation algorithms use the entire set of available feature dimensions to estimate the missing values (e.g. &lt;code&gt;impute.IterativeImputer&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea6c78b875e9abbb9afb65361c14c4ab4fe517e5" translate="yes" xml:space="preserve">
          <source>One typical use case is to wrap an existing metric function from the library with non-default values for its parameters, such as the &lt;code&gt;beta&lt;/code&gt; parameter for the &lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt;&lt;code&gt;fbeta_score&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Un caso de uso t&amp;iacute;pico es envolver una funci&amp;oacute;n m&amp;eacute;trica existente de la biblioteca con valores no predeterminados para sus par&amp;aacute;metros, como el par&amp;aacute;metro &lt;code&gt;beta&lt;/code&gt; para la funci&amp;oacute;n &lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt; &lt;code&gt;fbeta_score&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="d21d62671a1a16508e611633019b29f0b4ceb760" translate="yes" xml:space="preserve">
          <source>One way to avoid the query complexity is to pre-compute sparse neighborhoods in chunks using &lt;a href=&quot;sklearn.neighbors.nearestneighbors#sklearn.neighbors.NearestNeighbors.radius_neighbors_graph&quot;&gt;&lt;code&gt;NearestNeighbors.radius_neighbors_graph&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;mode='distance'&lt;/code&gt;, then using &lt;code&gt;metric='precomputed'&lt;/code&gt; here.</source>
          <target state="translated">Una forma de evitar la complejidad de la consulta es &lt;a href=&quot;sklearn.neighbors.nearestneighbors#sklearn.neighbors.NearestNeighbors.radius_neighbors_graph&quot;&gt; &lt;code&gt;NearestNeighbors.radius_neighbors_graph&lt;/code&gt; &lt;/a&gt; vecindarios dispersos en fragmentos usando NeighborsNeighbors.radius_neighbors_graph con &lt;code&gt;mode='distance'&lt;/code&gt; , luego usando &lt;code&gt;metric='precomputed'&lt;/code&gt; aqu&amp;iacute;.</target>
        </trans-unit>
        <trans-unit id="cfb9ef5c0f82cd02b0fe2a37197cc7c17a10edff" translate="yes" xml:space="preserve">
          <source>One way to handle this is to cluster features that are correlated and only keep one feature from each cluster. This strategy is explored in the following example: &lt;a href=&quot;../auto_examples/inspection/plot_permutation_importance_multicollinear#sphx-glr-auto-examples-inspection-plot-permutation-importance-multicollinear-py&quot;&gt;Permutation Importance with Multicollinear or Correlated Features&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4307d41eb1bb94d21cc13cd8d41c0af8c2af52b" translate="yes" xml:space="preserve">
          <source>One way to plot the curves is to place them in the same figure, with the curves of each model on each row. First, we create a figure with two axes within two rows and one column. The two axes are passed to the &lt;a href=&quot;../../modules/generated/sklearn.inspection.partialdependencedisplay#sklearn.inspection.PartialDependenceDisplay.plot&quot;&gt;&lt;code&gt;plot&lt;/code&gt;&lt;/a&gt; functions of &lt;code&gt;tree_disp&lt;/code&gt; and &lt;code&gt;mlp_disp&lt;/code&gt;. The given axes will be used by the plotting function to draw the partial dependence. The resulting plot places the decision tree partial dependence curves in the first row of the multi-layer perceptron in the second row.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7904a0df31dead1d3d1a1bdda9b6baa78b3e3ac4" translate="yes" xml:space="preserve">
          <source>One well-known issue with LLE is the regularization problem. When the number of neighbors is greater than the number of input dimensions, the matrix defining each local neighborhood is rank-deficient. To address this, standard LLE applies an arbitrary regularization parameter \(r\), which is chosen relative to the trace of the local weight matrix. Though it can be shown formally that as \(r \to 0\), the solution converges to the desired embedding, there is no guarantee that the optimal solution will be found for \(r &amp;gt; 0\). This problem manifests itself in embeddings which distort the underlying geometry of the manifold.</source>
          <target state="translated">Un problema conocido con LLE es el problema de regularizaci&amp;oacute;n. Cuando el n&amp;uacute;mero de vecinos es mayor que el n&amp;uacute;mero de dimensiones de entrada, la matriz que define a cada vecindario local tiene un rango deficiente. Para abordar esto, LLE est&amp;aacute;ndar aplica un par&amp;aacute;metro de regularizaci&amp;oacute;n arbitrario \ (r \), que se elige en relaci&amp;oacute;n con la traza de la matriz de peso local. Aunque se puede demostrar formalmente que como \ (r \ a 0 \), la soluci&amp;oacute;n converge a la inserci&amp;oacute;n deseada, no hay garant&amp;iacute;a de que se encuentre la soluci&amp;oacute;n &amp;oacute;ptima para \ (r&amp;gt; 0 \). Este problema se manifiesta en incrustaciones que distorsionan la geometr&amp;iacute;a subyacente del colector.</target>
        </trans-unit>
        <trans-unit id="4a89ac2f620199dd99f97fe1ad98300bc4f72269" translate="yes" xml:space="preserve">
          <source>One-class SVM with non-linear kernel (RBF)</source>
          <target state="translated">SVM de una clase con núcleo no lineal (RBF)</target>
        </trans-unit>
        <trans-unit id="a699b63cc6020c9e087bddfc75a6724c5b45ee5c" translate="yes" xml:space="preserve">
          <source>One-hot encoded discretized features can make a model more expressive, while maintaining interpretability. For instance, pre-processing with a discretizer can introduce nonlinearity to linear models.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4a3aede9df40da523f973c7487f254218f78511" translate="yes" xml:space="preserve">
          <source>One-vs-one multiclass strategy</source>
          <target state="translated">Estrategia multiclase uno contra uno</target>
        </trans-unit>
        <trans-unit id="ee528cbd4b4f2e2829af351b64b6eb8bfd42a4f6" translate="yes" xml:space="preserve">
          <source>One-vs-the-rest (OvR) multiclass/multilabel strategy</source>
          <target state="translated">Estrategia multiclase/multietiqueta de uno contra el resto (OvR)</target>
        </trans-unit>
        <trans-unit id="64ecee535f4fdc8be570462551ed8105268af715" translate="yes" xml:space="preserve">
          <source>One-way PDPs tell us about the interaction between the target response and the target feature (e.g. linear, non-linear). The upper left plot in the above Figure shows the effect of the median income in a district on the median house price; we can clearly see a linear relationship among them.</source>
          <target state="translated">Los PDPs unidireccionales nos hablan de la interacción entre la respuesta del objetivo y la característica del objetivo (por ejemplo,lineal,no lineal).El gráfico superior izquierdo de la figura anterior muestra el efecto de la mediana de los ingresos en un distrito sobre la mediana del precio de la vivienda;podemos ver claramente una relación lineal entre ellos.</target>
        </trans-unit>
        <trans-unit id="0d4f461fa5ad14a45b8d87efade862b196a923a9" translate="yes" xml:space="preserve">
          <source>One-way PDPs tell us about the interaction between the target response and the target feature (e.g. linear, non-linear). The upper left plot in the above figure shows the effect of the median income in a district on the median house price; we can clearly see a linear relationship among them. Note that PDPs assume that the target features are independent from the complement features, and this assumption is often violated in practice.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="624143e59cce6d91c0d6bbc328865a41ed589524" translate="yes" xml:space="preserve">
          <source>OneHotEncoder</source>
          <target state="translated">OneHotEncoder</target>
        </trans-unit>
        <trans-unit id="aae2ee6c9851c7a4ce4cd6cfb817bfde607325bf" translate="yes" xml:space="preserve">
          <source>Online Passive-Aggressive Algorithms &amp;lt;&lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&lt;/a&gt;&amp;gt; K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR (2006)</source>
          <target state="translated">Algoritmos pasivo-agresivos en l&amp;iacute;nea &amp;lt; &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&lt;/a&gt; &amp;gt; K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR (2006)</target>
        </trans-unit>
        <trans-unit id="59363dcf6a532d4c72655a5346d2c500295612f8" translate="yes" xml:space="preserve">
          <source>Online VB with Mini-Batch update.</source>
          <target state="translated">VB en línea con actualización de Mini-Batch.</target>
        </trans-unit>
        <trans-unit id="829e73254cb47c834763ade46578341830688d18" translate="yes" xml:space="preserve">
          <source>Online computation of max absolute value of X for later scaling.</source>
          <target state="translated">Cálculo en línea del valor absoluto máximo de X para su posterior escalado.</target>
        </trans-unit>
        <trans-unit id="1dffcf7d5a055d764cfb2adb13901c054d8691b3" translate="yes" xml:space="preserve">
          <source>Online computation of max absolute value of X for later scaling. All of X is processed as a single batch. This is intended for cases when &lt;code&gt;fit&lt;/code&gt; is not feasible due to very large number of &lt;code&gt;n_samples&lt;/code&gt; or because X is read from a continuous stream.</source>
          <target state="translated">C&amp;aacute;lculo en l&amp;iacute;nea del valor absoluto m&amp;aacute;ximo de X para escalado posterior. Todo X se procesa como un solo lote. Esto est&amp;aacute; destinado a los casos en los que el &lt;code&gt;fit&lt;/code&gt; no es factible debido a una gran cantidad de &lt;code&gt;n_samples&lt;/code&gt; o porque se lee X de un flujo continuo.</target>
        </trans-unit>
        <trans-unit id="5b59fd4b2594ce8e5c7bbe150a07e7588723c96b" translate="yes" xml:space="preserve">
          <source>Online computation of mean and std on X for later scaling.</source>
          <target state="translated">Cálculo en línea de la media y las ETS en X para su posterior escalado.</target>
        </trans-unit>
        <trans-unit id="98a787216e7563ac11e03cf3274711f17911c2c2" translate="yes" xml:space="preserve">
          <source>Online computation of mean and std on X for later scaling. All of X is processed as a single batch. This is intended for cases when &lt;code&gt;fit&lt;/code&gt; is not feasible due to very large number of &lt;code&gt;n_samples&lt;/code&gt; or because X is read from a continuous stream.</source>
          <target state="translated">C&amp;aacute;lculo en l&amp;iacute;nea de la media y la est&amp;aacute;ndar en X para escalar posteriormente. Todo X se procesa como un solo lote. Esto est&amp;aacute; destinado a los casos en los que el &lt;code&gt;fit&lt;/code&gt; no es factible debido a una gran cantidad de &lt;code&gt;n_samples&lt;/code&gt; o porque se lee X de un flujo continuo.</target>
        </trans-unit>
        <trans-unit id="3a0a40bed8a368eb74567adc0b902d5438bbb233" translate="yes" xml:space="preserve">
          <source>Online computation of min and max on X for later scaling.</source>
          <target state="translated">Cálculo en línea de los mínimos y máximos de X para su posterior escalado.</target>
        </trans-unit>
        <trans-unit id="245a52e0e0da8fa60b8bd0ab73c4b352a71c8d4a" translate="yes" xml:space="preserve">
          <source>Online computation of min and max on X for later scaling. All of X is processed as a single batch. This is intended for cases when &lt;code&gt;fit&lt;/code&gt; is not feasible due to very large number of &lt;code&gt;n_samples&lt;/code&gt; or because X is read from a continuous stream.</source>
          <target state="translated">C&amp;aacute;lculo en l&amp;iacute;nea de m&amp;iacute;nimo y m&amp;aacute;ximo en X para escalado posterior. Todo X se procesa como un solo lote. Esto est&amp;aacute; destinado a los casos en los que el &lt;code&gt;fit&lt;/code&gt; no es factible debido a una gran cantidad de &lt;code&gt;n_samples&lt;/code&gt; o porque se lee X de un flujo continuo.</target>
        </trans-unit>
        <trans-unit id="3bdeb493aeece54b83eea920715d4b7167b710bb" translate="yes" xml:space="preserve">
          <source>Online learning of a dictionary of parts of faces</source>
          <target state="translated">Aprendizaje en línea de un diccionario de partes de rostros</target>
        </trans-unit>
        <trans-unit id="afbac89ba6ac8bba06d8e8f00f8db1d633c505b3" translate="yes" xml:space="preserve">
          <source>Online learning.</source>
          <target state="translated">Aprendizaje en línea.</target>
        </trans-unit>
        <trans-unit id="e15bae968fe9434653919edecb56e181cf3bdca0" translate="yes" xml:space="preserve">
          <source>Online learning. Prevents rebuilding of CFTree from scratch.</source>
          <target state="translated">Aprendizaje en línea.Evita la reconstrucción de CFTree desde cero.</target>
        </trans-unit>
        <trans-unit id="fba366205dda8a9f9c620fa8147677029ec02688" translate="yes" xml:space="preserve">
          <source>Only active when backend=&amp;rdquo;loky&amp;rdquo; or &amp;ldquo;multiprocessing&amp;rdquo;.</source>
          <target state="translated">Solo activo cuando backend = &quot;loky&quot; o &quot;multiprocesamiento&quot;.</target>
        </trans-unit>
        <trans-unit id="302203b3b2bd4b6979838ea661e3dedb562a6303" translate="yes" xml:space="preserve">
          <source>Only adjusted measures can hence safely be used as a consensus index to evaluate the average stability of clustering algorithms for a given value of k on various overlapping sub-samples of the dataset.</source>
          <target state="translated">Por lo tanto,sólo las medidas ajustadas pueden utilizarse con seguridad como índice de consenso para evaluar la estabilidad media de los algoritmos de agrupación para un valor dado de k en diversas submuestras superpuestas del conjunto de datos.</target>
        </trans-unit>
        <trans-unit id="b41ade38f91e30c61b5c1030ad80447ac59509af" translate="yes" xml:space="preserve">
          <source>Only applies to sparse matrices. If True, the sparse entries of the matrix are discarded to compute the quantile statistics. If False, these entries are treated as zeros.</source>
          <target state="translated">Sólo se aplica a matrices escasas.Si es cierto,las entradas dispersas de la matriz se descartan para calcular las estadísticas de los cuantiles.Si es Falso,estas entradas se tratan como ceros.</target>
        </trans-unit>
        <trans-unit id="6239790ca1ea503b946542f5fd11362f9a8d181e" translate="yes" xml:space="preserve">
          <source>Only available for novelty detection (when novelty is set to True). The argument X is supposed to contain &lt;em&gt;new data&lt;/em&gt;: if X contains a point from training, it considers the later in its own neighborhood. Also, the samples in X are not considered in the neighborhood of any point. The score_samples on training data is available by considering the the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute.</source>
          <target state="translated">Solo disponible para la detecci&amp;oacute;n de novedades (cuando la novedad se establece en Verdadero). Se supone que el argumento X contiene &lt;em&gt;nuevos datos&lt;/em&gt; : si X contiene un punto del entrenamiento, considera el &amp;uacute;ltimo en su propio vecindario. Adem&amp;aacute;s, las muestras en X no se consideran pr&amp;oacute;ximas a ning&amp;uacute;n punto. Los score_samples sobre datos de entrenamiento est&amp;aacute; disponible considerando la del &lt;code&gt;negative_outlier_factor_&lt;/code&gt; atributo.</target>
        </trans-unit>
        <trans-unit id="42065a31e81b2581624e9d29e5e9b175fb835b62" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;decision_function&lt;/code&gt;.</source>
          <target state="translated">Solo disponible si &lt;code&gt;refit=True&lt;/code&gt; y el estimador subyacente admite &lt;code&gt;decision_function&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b5f87bbc5994209afe765ecb3d4b6e3e28348b8b" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;predict&lt;/code&gt;.</source>
          <target state="translated">Solo disponible si &lt;code&gt;refit=True&lt;/code&gt; y el estimador subyacente admite &lt;code&gt;predict&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d2e232f30b7c8c685e1c17116e7dcb136df3f8ad" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;predict_log_proba&lt;/code&gt;.</source>
          <target state="translated">Solo disponible si &lt;code&gt;refit=True&lt;/code&gt; y el estimador subyacente admite &lt;code&gt;predict_log_proba&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="590883a61b4915ecfb6720c62deaa2c81b9eda84" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">Solo disponible si &lt;code&gt;refit=True&lt;/code&gt; y el estimador subyacente admite &lt;code&gt;predict_proba&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3fd90433c474723d07589bf28196170034c8822e" translate="yes" xml:space="preserve">
          <source>Only available if the underlying estimator implements &lt;code&gt;inverse_transform&lt;/code&gt; and &lt;code&gt;refit=True&lt;/code&gt;.</source>
          <target state="translated">Solo disponible si el estimador subyacente implementa &lt;code&gt;inverse_transform&lt;/code&gt; y &lt;code&gt;refit=True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5b6ee95bb2d64ff7d78caebfb3e0ee07b947d80e" translate="yes" xml:space="preserve">
          <source>Only available if the underlying estimator supports &lt;code&gt;transform&lt;/code&gt; and &lt;code&gt;refit=True&lt;/code&gt;.</source>
          <target state="translated">Solo disponible si el estimador subyacente admite &lt;code&gt;transform&lt;/code&gt; y &lt;code&gt;refit=True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="551c945d5055fc75c52f88f345bac01b44b1a207" translate="yes" xml:space="preserve">
          <source>Only consider the highest k scores in the ranking. If None, use all outputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91571ddad0f13d4b107795b8172bb8b9e0e57731" translate="yes" xml:space="preserve">
          <source>Only kernels that produce similarity scores (non-negative values that increase with similarity) should be used. This property is not checked by the clustering algorithm.</source>
          <target state="translated">Sólo se deben utilizar los núcleos que produzcan puntuaciones de similitud (valores no negativos que aumentan con la similitud).Esta propiedad no se comprueba mediante el algoritmo de agrupación.</target>
        </trans-unit>
        <trans-unit id="78ed917f99bf2dac895a03ac7d7777a9a2c30e89" translate="yes" xml:space="preserve">
          <source>Only present when &lt;code&gt;as_frame=True&lt;/code&gt;. DataFrame with &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fcc91c5ac8dfa2c9d74fba74f9744bbfabacd86" translate="yes" xml:space="preserve">
          <source>Only present when &lt;code&gt;load_content=True&lt;/code&gt;. The raw text data to learn.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91f57910319c7032022a687ad833db0e0811e172" translate="yes" xml:space="preserve">
          <source>Only report results for the class specified by &lt;code&gt;pos_label&lt;/code&gt;. This is applicable only if targets (&lt;code&gt;y_{true,pred}&lt;/code&gt;) are binary.</source>
          <target state="translated">Informe &amp;uacute;nicamente los resultados de la clase especificada por &lt;code&gt;pos_label&lt;/code&gt; . Esto es aplicable solo si los destinos ( &lt;code&gt;y_{true,pred}&lt;/code&gt; ) son binarios.</target>
        </trans-unit>
        <trans-unit id="aa7683d2cc754187a7839c7481d51d4e421e244f" translate="yes" xml:space="preserve">
          <source>Only returned if return_distance is set to True (for compatibility). The distances between the centers of the nodes. &lt;code&gt;distances[i]&lt;/code&gt; corresponds to a weighted euclidean distance between the nodes &lt;code&gt;children[i, 1]&lt;/code&gt; and &lt;code&gt;children[i, 2]&lt;/code&gt;. If the nodes refer to leaves of the tree, then &lt;code&gt;distances[i]&lt;/code&gt; is their unweighted euclidean distance. Distances are updated in the following way (from scipy.hierarchy.linkage):</source>
          <target state="translated">Solo se devuelve si return_distance se establece en True (por compatibilidad). Las distancias entre los centros de los nodos. &lt;code&gt;distances[i]&lt;/code&gt; corresponde a una distancia euclidiana ponderada entre los nodos &lt;code&gt;children[i, 1]&lt;/code&gt; y &lt;code&gt;children[i, 2]&lt;/code&gt; . Si los nodos se refieren a las hojas del &amp;aacute;rbol, entonces &lt;code&gt;distances[i]&lt;/code&gt; es su distancia euclidiana no ponderada. Las distancias se actualizan de la siguiente manera (de scipy.hierarchy.linkage):</target>
        </trans-unit>
        <trans-unit id="76cbc59243676edd420339801c25adc86e4aefb2" translate="yes" xml:space="preserve">
          <source>Only set if whiten is &amp;lsquo;True&amp;rsquo;. This is the pre-whitening matrix that projects data onto the first &lt;code&gt;n_components&lt;/code&gt; principal components.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2ff6162a14531590c3fe05f5c4da22c170a731e" translate="yes" xml:space="preserve">
          <source>Only the first 4 features are informative. The remaining features are useless.</source>
          <target state="translated">Sólo las primeras 4 características son informativas.Las restantes características son inútiles.</target>
        </trans-unit>
        <trans-unit id="9ccbc07fdd81d8170c7e3632973044099dfe4b4c" translate="yes" xml:space="preserve">
          <source>Only the first max_depth levels of the tree are exported. Truncated branches will be marked with &amp;ldquo;&amp;hellip;&amp;rdquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ccdb28c17d5d885e725cff4c70b04cf05f415c05" translate="yes" xml:space="preserve">
          <source>Only used if method=&amp;rsquo;barnes_hut&amp;rsquo; This is the trade-off between speed and accuracy for Barnes-Hut T-SNE. &amp;lsquo;angle&amp;rsquo; is the angular size (referred to as theta in [3]) of a distant node as measured from a point. If this size is below &amp;lsquo;angle&amp;rsquo; then it is used as a summary node of all points contained within it. This method is not very sensitive to changes in this parameter in the range of 0.2 - 0.8. Angle less than 0.2 has quickly increasing computation time and angle greater 0.8 has quickly increasing error.</source>
          <target state="translated">Solo se usa si m&amp;eacute;todo = 'barnes_hut' Este es el compromiso entre velocidad y precisi&amp;oacute;n para Barnes-Hut T-SNE. '&amp;aacute;ngulo' es el tama&amp;ntilde;o angular (denominado theta en [3]) de un nodo distante medido desde un punto. Si este tama&amp;ntilde;o est&amp;aacute; por debajo del '&amp;aacute;ngulo', se utiliza como un nodo de resumen de todos los puntos que contiene. Este m&amp;eacute;todo no es muy sensible a cambios en este par&amp;aacute;metro en el rango de 0.2 - 0.8. Un &amp;aacute;ngulo inferior a 0,2 aumenta r&amp;aacute;pidamente el tiempo de c&amp;aacute;lculo y el &amp;aacute;ngulo superior a 0,8 aumenta r&amp;aacute;pidamente el error.</target>
        </trans-unit>
        <trans-unit id="feeded53201cd1098b357f2543d3cc3ddaf2bc59" translate="yes" xml:space="preserve">
          <source>Only used in edge case with a single class in the training set.</source>
          <target state="translated">Sólo se utiliza en caso de borde con una sola clase en el conjunto de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="e51e92f95034c804fc0810fdbc5d315daca2beb0" translate="yes" xml:space="preserve">
          <source>Only used when &lt;code&gt;solver='sgd'&lt;/code&gt;.</source>
          <target state="translated">Solo se usa cuando &lt;code&gt;solver='sgd'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="593a45b59b3c39f850f6d06cebef909401c1e524" translate="yes" xml:space="preserve">
          <source>Only used when &lt;code&gt;svd_method&lt;/code&gt; equals &amp;lsquo;randomized&amp;rsquo;. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da0ee672f8455720f39dadc83f429b90e16b4655" translate="yes" xml:space="preserve">
          <source>Only used when solver=&amp;rsquo;lbfgs&amp;rsquo;. Maximum number of function calls. The solver iterates until convergence (determined by &amp;lsquo;tol&amp;rsquo;), number of iterations reaches max_iter, or this number of function calls. Note that number of function calls will be greater than or equal to the number of iterations for the MLPRegressor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f33d0ac38f880719381151e0f77c153552e9c099" translate="yes" xml:space="preserve">
          <source>Only used when solver=&amp;rsquo;lbfgs&amp;rsquo;. Maximum number of loss function calls. The solver iterates until convergence (determined by &amp;lsquo;tol&amp;rsquo;), number of iterations reaches max_iter, or this number of loss function calls. Note that number of loss function calls will be greater than or equal to the number of iterations for the &lt;code&gt;MLPClassifier&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3466b805d384e470c3d1ee2beb1b9b317ac5cc22" translate="yes" xml:space="preserve">
          <source>Only used when solver=&amp;rsquo;sgd&amp;rsquo;.</source>
          <target state="translated">Solo se usa cuando solver = 'sgd'.</target>
        </trans-unit>
        <trans-unit id="04fb050fa307025a8b877f9d2c83069449f7ca94" translate="yes" xml:space="preserve">
          <source>Only works if &lt;code&gt;rows_&lt;/code&gt; and &lt;code&gt;columns_&lt;/code&gt; attributes exist.</source>
          <target state="translated">Solo funciona si existen atributos de &lt;code&gt;rows_&lt;/code&gt; y &lt;code&gt;columns_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="516478ad62f05e00111ddd57ddd26de9d50efa29" translate="yes" xml:space="preserve">
          <source>Open problem: Stock Market Structure</source>
          <target state="translated">Problema abierto:Estructura del mercado de valores</target>
        </trans-unit>
        <trans-unit id="988a0621a69f95c126d429edd6ad72b8b9753d30" translate="yes" xml:space="preserve">
          <source>OpenBLAS</source>
          <target state="translated">OpenBLAS</target>
        </trans-unit>
        <trans-unit id="01e06dfe8463084e545b7490a5b6cab212cacc1b" translate="yes" xml:space="preserve">
          <source>OpenML ID of the dataset. The most specific way of retrieving a dataset. If data_id is not given, name (and potential version) are used to obtain a dataset.</source>
          <target state="translated">OpenML ID del conjunto de datos.La forma más específica de recuperar un conjunto de datos.Si no se da el data_id,se utiliza el nombre (y la versión potencial)para obtener un conjunto de datos.</target>
        </trans-unit>
        <trans-unit id="b73a248fb134eb9cb2d0288db81a01291423c17b" translate="yes" xml:space="preserve">
          <source>OpenMP is used to parallelize code written in Cython or C, relying on multi-threading exclusively. By default (and unless joblib is trying to avoid oversubscription), the implementation will use as many threads as possible.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c0cb6e8849966972823d3a411e3fa85cccc3662" translate="yes" xml:space="preserve">
          <source>Opposite of the Local Outlier Factor of X.</source>
          <target state="translated">Opuesto al Factor Local Atípico de X.</target>
        </trans-unit>
        <trans-unit id="5e68f725eeef777e12b4d3a454a6208991fd24e6" translate="yes" xml:space="preserve">
          <source>Opposite of the Mahalanobis distances.</source>
          <target state="translated">Frente a las distancias de Mahalanobis.</target>
        </trans-unit>
        <trans-unit id="b5fb56d4ea090bc2e90702500456ef35c8c80910" translate="yes" xml:space="preserve">
          <source>Opposite of the anomaly score defined in the original paper.</source>
          <target state="translated">Opuesto a la puntuación de la anomalía definida en el documento original.</target>
        </trans-unit>
        <trans-unit id="8d0235738e36c010f5cce0e1d51d26583f4fbd2f" translate="yes" xml:space="preserve">
          <source>Opposite of the value of X on the K-means objective.</source>
          <target state="translated">Opuesto al valor de X en el objetivo de K-means.</target>
        </trans-unit>
        <trans-unit id="d4790d7d59a93c4896ec3d473b252d9c8e90d50a" translate="yes" xml:space="preserve">
          <source>Optimal choices for the sampling interval for certain data ranges can be computed (see the reference). The default values should be reasonable.</source>
          <target state="translated">Se pueden calcular las opciones óptimas para el intervalo de muestreo para ciertos rangos de datos (véase la referencia).Los valores por defecto deben ser razonables.</target>
        </trans-unit>
        <trans-unit id="ce024d3ab746293c4c12993e7780e537aaab5bd3" translate="yes" xml:space="preserve">
          <source>Optimized BLAS / LAPACK implementations include:</source>
          <target state="translated">Las implementaciones optimizadas de BLAS/LAPACK incluyen:</target>
        </trans-unit>
        <trans-unit id="e7a4cb55708bbb7494e2613ab1d6bd3cf5f4ed80" translate="yes" xml:space="preserve">
          <source>Optimizing the KL divergence can be a little bit tricky sometimes. There are five parameters that control the optimization of t-SNE and therefore possibly the quality of the resulting embedding:</source>
          <target state="translated">Optimizar la divergencia del KL puede ser un poco difícil a veces.Hay cinco parámetros que controlan la optimización del t-SNE y por lo tanto posiblemente la calidad de la incrustación resultante:</target>
        </trans-unit>
        <trans-unit id="59b7edea35dae0ba7f04b93972cd416b8729437e" translate="yes" xml:space="preserve">
          <source>Option to scale data</source>
          <target state="translated">Opción de escalar los datos</target>
        </trans-unit>
        <trans-unit id="b448cb50c967f57d438352622bd92cc83d5cd21c" translate="yes" xml:space="preserve">
          <source>Optional display names matching the labels (same order).</source>
          <target state="translated">Nombres de pantalla opcionales que coincidan con las etiquetas (mismo orden).</target>
        </trans-unit>
        <trans-unit id="f7746b3179890337eeaaee24d3cefbf3e21f4716" translate="yes" xml:space="preserve">
          <source>Optional list of label indices to include in the report.</source>
          <target state="translated">Lista opcional de índices de etiquetas para incluir en el informe.</target>
        </trans-unit>
        <trans-unit id="444d0152ba1b6a9d2f83b135dcad3591aef4140b" translate="yes" xml:space="preserve">
          <source>Optionally, weights can be provided for the individual classifiers:</source>
          <target state="translated">Opcionalmente,se pueden proporcionar pesos para los clasificadores individuales:</target>
        </trans-unit>
        <trans-unit id="53297f66af025e9af455b9620b74f88cfef40f7b" translate="yes" xml:space="preserve">
          <source>Or a confusion matrix can be constructed for each sample&amp;rsquo;s labels:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bdffb8593fdda1fb06f464d41401bd543c75d539" translate="yes" xml:space="preserve">
          <source>Or as a dict mapping scorer name to a predefined or custom scoring function:</source>
          <target state="translated">O como un dictador que asigna el nombre del anotador a una función de puntuación predefinida o personalizada:</target>
        </trans-unit>
        <trans-unit id="568b3f93d3d74f4712d93109fe9bc1b3579dc2ff" translate="yes" xml:space="preserve">
          <source>Or drop a column for feature only having 2 categories:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2919d9f2f1803bd27d88cb6979d8731b9671873d" translate="yes" xml:space="preserve">
          <source>Or, the Itakura-Saito (IS) divergence:</source>
          <target state="translated">O,la divergencia Itakura-Saito (IS):</target>
        </trans-unit>
        <trans-unit id="2eae1790c8b18065a4e4be5e643bf49617d7e481" translate="yes" xml:space="preserve">
          <source>Oracle Approximating Shrinkage Estimator</source>
          <target state="translated">Estimador de contracción aproximado de Oracle</target>
        </trans-unit>
        <trans-unit id="09fb6aaba7940a7b7ffdbc9cbb9b3498303c1bad" translate="yes" xml:space="preserve">
          <source>Orange</source>
          <target state="translated">Orange</target>
        </trans-unit>
        <trans-unit id="1b5910554dc9c47445df182faeace08d47d3ef72" translate="yes" xml:space="preserve">
          <source>Order of output array in the dense case. &amp;lsquo;F&amp;rsquo; order is faster to compute, but may slow down subsequent estimators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61e854a8201b91e00e8fdcbd770fb61bc8a83663" translate="yes" xml:space="preserve">
          <source>Order of the norm used to filter the vectors of coefficients below &lt;code&gt;threshold&lt;/code&gt; in the case where the &lt;code&gt;coef_&lt;/code&gt; attribute of the estimator is of dimension 2.</source>
          <target state="translated">Orden de la norma utilizada para filtrar los vectores de coeficientes por debajo del &lt;code&gt;threshold&lt;/code&gt; en el caso en que el atributo &lt;code&gt;coef_&lt;/code&gt; del estimador sea de dimensi&amp;oacute;n 2.</target>
        </trans-unit>
        <trans-unit id="04f01a5d4b5e2de7c5bc38f04fe789073a85e1a0" translate="yes" xml:space="preserve">
          <source>Ordinary Least Squares and Ridge Regression Variance</source>
          <target state="translated">Cuadrados mínimos ordinarios y variación de la regresión de la cresta</target>
        </trans-unit>
        <trans-unit id="69dfb38c02d49acfa60317532da350814008c91b" translate="yes" xml:space="preserve">
          <source>Ordinary least squares Linear Regression.</source>
          <target state="translated">Regresión lineal de mínimos cuadrados ordinarios.</target>
        </trans-unit>
        <trans-unit id="c6a26fb9333dc9c04fcf0b8a8d439bec3529ccb6" translate="yes" xml:space="preserve">
          <source>Original Algorithm is detailed in the book &lt;code&gt;Bayesian learning for neural networks&lt;/code&gt; by Radford M. Neal</source>
          <target state="translated">El algoritmo original se detalla en el libro &lt;code&gt;Bayesian learning for neural networks&lt;/code&gt; de Radford M. Neal</target>
        </trans-unit>
        <trans-unit id="285a92205b1ae0ee38089b09c3441dcd00669592" translate="yes" xml:space="preserve">
          <source>Original Algorithm is detailed in the paper &lt;a href=&quot;http://www-stat.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;Least Angle Regression&lt;/a&gt; by Hastie et al.</source>
          <target state="translated">El algoritmo original se detalla en el art&amp;iacute;culo &lt;a href=&quot;http://www-stat.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;Regresi&amp;oacute;n de &amp;aacute;ngulo m&amp;iacute;nimo&lt;/a&gt; de Hastie et al.</target>
        </trans-unit>
        <trans-unit id="b56fc3a445b7bdb3d075f8c4b435d8408f7cbd6d" translate="yes" xml:space="preserve">
          <source>Original Algorithm is detailed in the paper &lt;a href=&quot;https://www-stat.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;Least Angle Regression&lt;/a&gt; by Hastie et al.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40e1a40682f2197d130d7160c72b099cf6445896" translate="yes" xml:space="preserve">
          <source>Original Owners:</source>
          <target state="translated">Propietarios originales:</target>
        </trans-unit>
        <trans-unit id="7ad091e9d90ec0296b62c3e5e44ac8d89a063912" translate="yes" xml:space="preserve">
          <source>Original data</source>
          <target state="translated">Datos originales</target>
        </trans-unit>
        <trans-unit id="e08c8e7e7ce9b41fa431a10c664db0046193d186" translate="yes" xml:space="preserve">
          <source>Original indices of sorted hashed values in the fitted index.</source>
          <target state="translated">Índices originales de valores hash clasificados en el índice ajustado.</target>
        </trans-unit>
        <trans-unit id="7bcdd254a48ca093c51f99fbea960c8ba5abba3d" translate="yes" xml:space="preserve">
          <source>Original points</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d62335c307cfd6338409df5c3eb510c3da387b07" translate="yes" xml:space="preserve">
          <source>Orthogonal Matching Pursuit</source>
          <target state="translated">Búsqueda de coincidencia ortogonal</target>
        </trans-unit>
        <trans-unit id="4b43e1fc477a65c488f6b885c65608062bcdd067" translate="yes" xml:space="preserve">
          <source>Orthogonal Matching Pursuit (OMP)</source>
          <target state="translated">Orthogonal Matching Pursuit (OMP)</target>
        </trans-unit>
        <trans-unit id="6f8635fe08116f66d41828127f270123a3daf2dc" translate="yes" xml:space="preserve">
          <source>Orthogonal Matching Pursuit model (OMP)</source>
          <target state="translated">Modelo de persecución ortogonal (OMP)</target>
        </trans-unit>
        <trans-unit id="b4cea4b2e1d94206efdd2c81ac084782051e04a0" translate="yes" xml:space="preserve">
          <source>Orthogonal matching pursuit (&lt;a href=&quot;linear_model#omp&quot;&gt;Orthogonal Matching Pursuit (OMP)&lt;/a&gt;)</source>
          <target state="translated">Ortogonal matching pursuit ( &lt;a href=&quot;linear_model#omp&quot;&gt;Orthogonal Matching Pursuit (OMP)&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="2d35a4350f19547a1df08de9c97e28d5eb4c4c18" translate="yes" xml:space="preserve">
          <source>Orthogonal matching pursuit was introduced in G. Mallat, Z. Zhang, Matching pursuits with time-frequency dictionaries, IEEE Transactions on Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415. (&lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt;)</source>
          <target state="translated">La b&amp;uacute;squeda de correspondencia ortogonal se introdujo en G. Mallat, Z. Zhang, B&amp;uacute;squeda de correspondencia con diccionarios de frecuencia de tiempo, IEEE Transactions on Signal Processing, Vol. 41, No. 12. (diciembre de 1993), p&amp;aacute;gs. 3397-3415. ( &lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="5e7d9b3e4cebb5843b9125c6b797beb3832d1f95" translate="yes" xml:space="preserve">
          <source>Orthogonal matching pursuit was introduced in S. Mallat, Z. Zhang, Matching pursuits with time-frequency dictionaries, IEEE Transactions on Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415. (&lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt;)</source>
          <target state="translated">La b&amp;uacute;squeda de correspondencia ortogonal se introdujo en S. Mallat, Z. Zhang, B&amp;uacute;squeda de correspondencia con diccionarios de frecuencia de tiempo, IEEE Transactions on Signal Processing, Vol. 41, No. 12. (diciembre de 1993), p&amp;aacute;gs. 3397-3415. ( &lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="6e6a6f2086bb5fe5dbfd17d8d5f502d48759834b" translate="yes" xml:space="preserve">
          <source>Other</source>
          <target state="translated">Other</target>
        </trans-unit>
        <trans-unit id="708bf6f62e354ff314651598e7eebc62fd8d2bb2" translate="yes" xml:space="preserve">
          <source>Other Parameters</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0faa321ae463cf423d057b0fb19c09b0142f3c2a" translate="yes" xml:space="preserve">
          <source>Other Parameters:</source>
          <target state="translated">Otros parámetros:</target>
        </trans-unit>
        <trans-unit id="f7488409b393eaa19a207155b56a3606cc42d9c5" translate="yes" xml:space="preserve">
          <source>Other Versions</source>
          <target state="translated">Otras versiones</target>
        </trans-unit>
        <trans-unit id="bf60b2f111b62bfaee7623785937d680b71fe343" translate="yes" xml:space="preserve">
          <source>Other distance functions can be used in NMF as, for example, the (generalized) Kullback-Leibler (KL) divergence, also referred as I-divergence:</source>
          <target state="translated">En el NMF se pueden utilizar otras funciones de distancia como,por ejemplo,la divergencia (generalizada)Kullback-Leibler (KL),también denominada I-divergencia:</target>
        </trans-unit>
        <trans-unit id="7ba50765d1cae4c4ed89d4ff332ed3b825d08abc" translate="yes" xml:space="preserve">
          <source>Other features match the names and e-mail addresses of particular people who were posting at the time.</source>
          <target state="translated">Otras características coinciden con los nombres y direcciones de correo electrónico de determinadas personas que estaban publicando en ese momento.</target>
        </trans-unit>
        <trans-unit id="51c966edfa7d64a0b7dcf68b92d77cfd5b366772" translate="yes" xml:space="preserve">
          <source>Other machine learning packages for Python and related projects. Also algorithms that are slightly out of scope or not well established enough for scikit-learn.</source>
          <target state="translated">Otros paquetes de aprendizaje de máquinas para Python y proyectos relacionados.También algoritmos que están ligeramente fuera de alcance o que no están lo suficientemente bien establecidos para el aprendizaje de la ciencia.</target>
        </trans-unit>
        <trans-unit id="2ea8bcd548fe9ec11d17cc82aea4ab0fbdf7f8f3" translate="yes" xml:space="preserve">
          <source>Other regression generators generate functions deterministically from randomized features. &lt;a href=&quot;../modules/generated/sklearn.datasets.make_sparse_uncorrelated#sklearn.datasets.make_sparse_uncorrelated&quot;&gt;&lt;code&gt;make_sparse_uncorrelated&lt;/code&gt;&lt;/a&gt; produces a target as a linear combination of four features with fixed coefficients. Others encode explicitly non-linear relations: &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman1#sklearn.datasets.make_friedman1&quot;&gt;&lt;code&gt;make_friedman1&lt;/code&gt;&lt;/a&gt; is related by polynomial and sine transforms; &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman2#sklearn.datasets.make_friedman2&quot;&gt;&lt;code&gt;make_friedman2&lt;/code&gt;&lt;/a&gt; includes feature multiplication and reciprocation; and &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman3#sklearn.datasets.make_friedman3&quot;&gt;&lt;code&gt;make_friedman3&lt;/code&gt;&lt;/a&gt; is similar with an arctan transformation on the target.</source>
          <target state="translated">Otros generadores de regresi&amp;oacute;n generan funciones de forma determinista a partir de caracter&amp;iacute;sticas aleatorias. &lt;a href=&quot;../modules/generated/sklearn.datasets.make_sparse_uncorrelated#sklearn.datasets.make_sparse_uncorrelated&quot;&gt; &lt;code&gt;make_sparse_uncorrelated&lt;/code&gt; &lt;/a&gt; produce un objetivo como una combinaci&amp;oacute;n lineal de cuatro caracter&amp;iacute;sticas con coeficientes fijos. Otros codifican relaciones expl&amp;iacute;citamente no lineales: &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman1#sklearn.datasets.make_friedman1&quot;&gt; &lt;code&gt;make_friedman1&lt;/code&gt; &lt;/a&gt; est&amp;aacute; relacionado mediante transformaciones polinomiales y sinusoidales; &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman2#sklearn.datasets.make_friedman2&quot;&gt; &lt;code&gt;make_friedman2&lt;/code&gt; &lt;/a&gt; incluye funci&amp;oacute;n de multiplicaci&amp;oacute;n y reciprocidad; y &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman3#sklearn.datasets.make_friedman3&quot;&gt; &lt;code&gt;make_friedman3&lt;/code&gt; &lt;/a&gt; es similar con una transformaci&amp;oacute;n arctan en el objetivo.</target>
        </trans-unit>
        <trans-unit id="756226f83bdd3199110bcb639e6fbe93b81b2b14" translate="yes" xml:space="preserve">
          <source>Others also work in the multiclass case:</source>
          <target state="translated">Otros también trabajan en el caso de la multiclase:</target>
        </trans-unit>
        <trans-unit id="31c4dae2edc1b6ad8f22c0a6f68a8f7ab2bd8316" translate="yes" xml:space="preserve">
          <source>Otherwise the input is expected to be a sequence of items that can be of type string or byte.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bce48a0cb0a5e5960a4a35ec10cf25f56bf2f60b" translate="yes" xml:space="preserve">
          <source>Otherwise the input is expected to be the sequence strings or bytes items are expected to be analyzed directly.</source>
          <target state="translated">De lo contrario,se espera que la entrada sea la secuencia de cadenas o que los elementos de bytes sean analizados directamente.</target>
        </trans-unit>
        <trans-unit id="1eb83bd09e16b910ee3986257ed6e80732bc066a" translate="yes" xml:space="preserve">
          <source>Our definition: &lt;a href=&quot;#mosley2013&quot; id=&quot;id5&quot;&gt;[Mosley2013]&lt;/a&gt;, &lt;a href=&quot;#kelleher2015&quot; id=&quot;id6&quot;&gt;[Kelleher2015]&lt;/a&gt; and &lt;a href=&quot;#guyon2015&quot; id=&quot;id7&quot;&gt;[Guyon2015]&lt;/a&gt;, where &lt;a href=&quot;#guyon2015&quot; id=&quot;id8&quot;&gt;[Guyon2015]&lt;/a&gt; adopt the adjusted version to ensure that random predictions have a score of \(0\) and perfect predictions have a score of \(1\)..</source>
          <target state="translated">Nuestra definici&amp;oacute;n: &lt;a href=&quot;#mosley2013&quot; id=&quot;id5&quot;&gt;[Mosley2013]&lt;/a&gt; , &lt;a href=&quot;#kelleher2015&quot; id=&quot;id6&quot;&gt;[Kelleher2015]&lt;/a&gt; y &lt;a href=&quot;#guyon2015&quot; id=&quot;id7&quot;&gt;[Guyon2015]&lt;/a&gt; , donde &lt;a href=&quot;#guyon2015&quot; id=&quot;id8&quot;&gt;[Guyon2015]&lt;/a&gt; adopta la versi&amp;oacute;n ajustada para garantizar que las predicciones aleatorias tengan una puntuaci&amp;oacute;n de \ (0 \) y las predicciones perfectas tengan una puntuaci&amp;oacute;n de \ (1 \). .</target>
        </trans-unit>
        <trans-unit id="4dd148768e9c37b7c74e1f4e4e0bf60f2fa1ec4e" translate="yes" xml:space="preserve">
          <source>Our goal is to predict the expected frequency of claims following car accidents for a new policyholder given the historical data over a population of policyholders.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51a30e97a793068228d5bb8b3efc1038cb1f9689" translate="yes" xml:space="preserve">
          <source>Our implementation of &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt; was inspired by the R MICE package (Multivariate Imputation by Chained Equations) &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;, but differs from it by returning a single imputation instead of multiple imputations. However, &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt; can also be used for multiple imputations by applying it repeatedly to the same dataset with different random seeds when &lt;code&gt;sample_posterior=True&lt;/code&gt;. See &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;2&lt;/a&gt;, chapter 4 for more discussion on multiple vs. single imputations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a60ce8fd0b60aee8ad7f5d9f917babe62e72b491" translate="yes" xml:space="preserve">
          <source>Our implementation&amp;rsquo;s score is 1 greater than the one given in Tsoumakas et al., 2010. This extends it to handle the degenerate case in which an instance has 0 true labels.</source>
          <target state="translated">La puntuaci&amp;oacute;n de nuestra implementaci&amp;oacute;n es 1 mayor que la dada en Tsoumakas et al., 2010. Esto la ampl&amp;iacute;a para manejar el caso degenerado en el que una instancia tiene 0 etiquetas verdaderas.</target>
        </trans-unit>
        <trans-unit id="fe0259b257120510b76da78ac976bdfb1e816c30" translate="yes" xml:space="preserve">
          <source>Our target for prediction: the wage. Wages are described as floating-point number in dollars per hour.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3f0fa9ade6f943d608603fdef87384f7f12b49b" translate="yes" xml:space="preserve">
          <source>Out of the &lt;code&gt;n_features&lt;/code&gt; features, only 5 are actually used to compute &lt;code&gt;y&lt;/code&gt;. The remaining features are independent of &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">De las caracter&amp;iacute;sticas &lt;code&gt;n_features&lt;/code&gt; , solo 5 se usan realmente para calcular &lt;code&gt;y&lt;/code&gt; . Las dem&amp;aacute;s caracter&amp;iacute;sticas son independientes de &lt;code&gt;y&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="de345f1c1e8c124d63c9ee465bc413813ba2423e" translate="yes" xml:space="preserve">
          <source>Out-of-bag (OOB) estimates can be a useful heuristic to estimate the &amp;ldquo;optimal&amp;rdquo; number of boosting iterations. OOB estimates are almost identical to cross-validation estimates but they can be computed on-the-fly without the need for repeated model fitting. OOB estimates are only available for Stochastic Gradient Boosting (i.e. &lt;code&gt;subsample &amp;lt; 1.0&lt;/code&gt;), the estimates are derived from the improvement in loss based on the examples not included in the bootstrap sample (the so-called out-of-bag examples). The OOB estimator is a pessimistic estimator of the true test loss, but remains a fairly good approximation for a small number of trees.</source>
          <target state="translated">Las estimaciones fuera de bolsa (OOB) pueden ser una heur&amp;iacute;stica &amp;uacute;til para estimar el n&amp;uacute;mero &quot;&amp;oacute;ptimo&quot; de iteraciones de impulso. Las estimaciones OOB son casi id&amp;eacute;nticas a las estimaciones de validaci&amp;oacute;n cruzada, pero se pueden calcular sobre la marcha sin necesidad de repetir el ajuste del modelo. Las estimaciones de OOB solo est&amp;aacute;n disponibles para el aumento de gradiente estoc&amp;aacute;stico (es decir, &lt;code&gt;subsample &amp;lt; 1.0&lt;/code&gt; ), las estimaciones se derivan de la mejora en la p&amp;eacute;rdida basadas en los ejemplos no incluidos en la muestra de arranque (los llamados ejemplos fuera de bolsa). El estimador OOB es un estimador pesimista de la verdadera p&amp;eacute;rdida de prueba, pero sigue siendo una aproximaci&amp;oacute;n bastante buena para una peque&amp;ntilde;a cantidad de &amp;aacute;rboles.</target>
        </trans-unit>
        <trans-unit id="0edae687594f6a8a4aaab025d755be89c91cf6e0" translate="yes" xml:space="preserve">
          <source>Out-of-core (or &amp;ldquo;external memory&amp;rdquo;) learning is a technique used to learn from data that cannot fit in a computer&amp;rsquo;s main memory (RAM).</source>
          <target state="translated">El aprendizaje fuera del n&amp;uacute;cleo (o &quot;memoria externa&quot;) es una t&amp;eacute;cnica que se utiliza para aprender de los datos que no caben en la memoria principal (RAM) de una computadora.</target>
        </trans-unit>
        <trans-unit id="9961951956a78a655327742f08dd6b72dea1283f" translate="yes" xml:space="preserve">
          <source>Out-of-core classification of text documents</source>
          <target state="translated">Clasificación de documentos de texto fuera del núcleo</target>
        </trans-unit>
        <trans-unit id="1ee8fea1697e4d708569e4bb179873c92ff19379" translate="yes" xml:space="preserve">
          <source>Out:</source>
          <target state="translated">Out:</target>
        </trans-unit>
        <trans-unit id="5dd0aa388360b95626a38da9b18844d684c8d25b" translate="yes" xml:space="preserve">
          <source>Outlier detection</source>
          <target state="translated">Detección de valores atípicos</target>
        </trans-unit>
        <trans-unit id="875f738eb0e68cda4066331e25fac5af4c71d682" translate="yes" xml:space="preserve">
          <source>Outlier detection and novelty detection are both used for anomaly detection, where one is interested in detecting abnormal or unusual observations. Outlier detection is then also known as unsupervised anomaly detection and novelty detection as semi-supervised anomaly detection. In the context of outlier detection, the outliers/anomalies cannot form a dense cluster as available estimators assume that the outliers/anomalies are located in low density regions. On the contrary, in the context of novelty detection, novelties/anomalies can form a dense cluster as long as they are in a low density region of the training data, considered as normal in this context.</source>
          <target state="translated">La detección de anomalías y la detección de novedades se utilizan para la detección de anomalías,donde uno está interesado en detectar observaciones anormales o inusuales.La detección de anomalías atípicas se conoce también como detección de anomalías no supervisada y la detección de novedades como detección de anomalías semisupervisada.En el contexto de la detección de valores atípicos,los valores atípicos/anómalos no pueden formar un grupo denso ya que los estimadores disponibles suponen que los valores atípicos/anómalos están situados en regiones de baja densidad.Por el contrario,en el contexto de la detección de novedades,las novedades/anomalías pueden formar un conglomerado denso siempre que se encuentren en una región de baja densidad de los datos de formación,considerada como normal en este contexto.</target>
        </trans-unit>
        <trans-unit id="e16ebe52f017c4437fca8210daa352b7f7a34559" translate="yes" xml:space="preserve">
          <source>Outlier detection from covariance estimation may break or not perform well in high-dimensional settings. In particular, one will always take care to work with &lt;code&gt;n_samples &amp;gt; n_features ** 2&lt;/code&gt;.</source>
          <target state="translated">La detecci&amp;oacute;n de valores at&amp;iacute;picos a partir de la estimaci&amp;oacute;n de covarianza puede romperse o no funcionar bien en entornos de alta dimensi&amp;oacute;n. En particular, siempre se cuidar&amp;aacute; de trabajar con &lt;code&gt;n_samples &amp;gt; n_features ** 2&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="eb5776745abd0907a25a2d19ca27c92845132829" translate="yes" xml:space="preserve">
          <source>Outlier detection is similar to novelty detection in the sense that the goal is to separate a core of regular observations from some polluting ones, called &lt;em&gt;outliers&lt;/em&gt;. Yet, in the case of outlier detection, we don&amp;rsquo;t have a clean data set representing the population of regular observations that can be used to train any tool.</source>
          <target state="translated">La detecci&amp;oacute;n de valores at&amp;iacute;picos es similar a la detecci&amp;oacute;n de novedades en el sentido de que el objetivo es separar un n&amp;uacute;cleo de observaciones regulares de algunas contaminantes, llamadas &lt;em&gt;valores at&amp;iacute;picos&lt;/em&gt; . Sin embargo, en el caso de la detecci&amp;oacute;n de valores at&amp;iacute;picos, no tenemos un conjunto de datos limpios que represente la poblaci&amp;oacute;n de observaciones regulares que se pueda utilizar para entrenar cualquier herramienta.</target>
        </trans-unit>
        <trans-unit id="1d8881b6614c5c1d87283378baf1dfbd30d62aa2" translate="yes" xml:space="preserve">
          <source>Outlier detection on a real data set</source>
          <target state="translated">Detección de valores atípicos en un conjunto de datos reales</target>
        </trans-unit>
        <trans-unit id="4567caf33a07f033c1e56ef9d81272da195ec4e4" translate="yes" xml:space="preserve">
          <source>Outlier detection with Local Outlier Factor (LOF)</source>
          <target state="translated">Detección de valores atípicos con el Factor Atípico Local (LOF)</target>
        </trans-unit>
        <trans-unit id="fd5effe3fc538ea2a8eadf46c1fdeca372b53b13" translate="yes" xml:space="preserve">
          <source>Outlier-robust regressors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d4ae6e212657597b75c35cebf362553af1f6b83" translate="yes" xml:space="preserve">
          <source>Outliers in the X direction</source>
          <target state="translated">Los valores atípicos en la dirección X</target>
        </trans-unit>
        <trans-unit id="1280eb8e6f7378d868cfa7fd24acb5cb10594078" translate="yes" xml:space="preserve">
          <source>Outliers in the y direction</source>
          <target state="translated">Los valores atípicos en la dirección &quot;y&quot;...</target>
        </trans-unit>
        <trans-unit id="fd162763a0f66a902211a2d40da7afdfc74ea634" translate="yes" xml:space="preserve">
          <source>Output a list of n_output arrays of class probabilities upon &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">Genere una lista de matrices n_output de probabilidades de clase sobre &lt;code&gt;predict_proba&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8298d7fc7f7d06e9b0287b5d9b7af6acdbad01e4" translate="yes" xml:space="preserve">
          <source>Output n_output values upon &lt;code&gt;predict&lt;/code&gt;;</source>
          <target state="translated">Salida n valores de salida al &lt;code&gt;predict&lt;/code&gt; ;</target>
        </trans-unit>
        <trans-unit id="c9a682f0f812fa2f90e0a2d7878d2c9702a9c510" translate="yes" xml:space="preserve">
          <source>Output-code based strategies are fairly different from one-vs-the-rest and one-vs-one. With these strategies, each class is represented in a Euclidean space, where each dimension can only be 0 or 1. Another way to put it is that each class is represented by a binary code (an array of 0 and 1). The matrix which keeps track of the location/code of each class is called the code book. The code size is the dimensionality of the aforementioned space. Intuitively, each class should be represented by a code as unique as possible and a good code book should be designed to optimize classification accuracy. In this implementation, we simply use a randomly-generated code book as advocated in &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;3&lt;/a&gt; although more elaborate methods may be added in the future.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c950fe98702d8e76b55b31a01ec26c58021324c" translate="yes" xml:space="preserve">
          <source>Output-code based strategies are fairly different from one-vs-the-rest and one-vs-one. With these strategies, each class is represented in a Euclidean space, where each dimension can only be 0 or 1. Another way to put it is that each class is represented by a binary code (an array of 0 and 1). The matrix which keeps track of the location/code of each class is called the code book. The code size is the dimensionality of the aforementioned space. Intuitively, each class should be represented by a code as unique as possible and a good code book should be designed to optimize classification accuracy. In this implementation, we simply use a randomly-generated code book as advocated in &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3]&lt;/a&gt; although more elaborate methods may be added in the future.</source>
          <target state="translated">Las estrategias basadas en c&amp;oacute;digos de salida son bastante diferentes de uno contra el resto y uno contra uno. Con estas estrategias, cada clase se representa en un espacio euclidiano, donde cada dimensi&amp;oacute;n solo puede ser 0 o 1. Otra forma de decirlo es que cada clase est&amp;aacute; representada por un c&amp;oacute;digo binario (una matriz de 0 y 1). La matriz que realiza un seguimiento de la ubicaci&amp;oacute;n / c&amp;oacute;digo de cada clase se llama libro de c&amp;oacute;digos. El tama&amp;ntilde;o del c&amp;oacute;digo es la dimensionalidad del espacio mencionado anteriormente. De manera intuitiva, cada clase debe estar representada por un c&amp;oacute;digo lo m&amp;aacute;s exclusivo posible y debe dise&amp;ntilde;arse un buen libro de c&amp;oacute;digos para optimizar la precisi&amp;oacute;n de la clasificaci&amp;oacute;n. En esta implementaci&amp;oacute;n, simplemente usamos un libro de c&amp;oacute;digos generado aleatoriamente como se recomienda en &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3],&lt;/a&gt; aunque se pueden agregar m&amp;eacute;todos m&amp;aacute;s elaborados en el futuro.</target>
        </trans-unit>
        <trans-unit id="ce947ff733c2ff6c4c204d57e36546e6961c8fdc" translate="yes" xml:space="preserve">
          <source>Output-code based strategies consist in representing each class with a binary code (an array of 0s and 1s). At fitting time, one binary classifier per bit in the code book is fitted. At prediction time, the classifiers are used to project new points in the class space and the class closest to the points is chosen. The main advantage of these strategies is that the number of classifiers used can be controlled by the user, either for compressing the model (0 &amp;lt; code_size &amp;lt; 1) or for making the model more robust to errors (code_size &amp;gt; 1). See the documentation for more details.</source>
          <target state="translated">Las estrategias basadas en c&amp;oacute;digo de salida consisten en representar cada clase con un c&amp;oacute;digo binario (una matriz de 0 y 1). En el momento del ajuste, se ajusta un clasificador binario por bit en el libro de c&amp;oacute;digos. En el momento de la predicci&amp;oacute;n, los clasificadores se utilizan para proyectar nuevos puntos en el espacio de clases y se elige la clase m&amp;aacute;s cercana a los puntos. La principal ventaja de estas estrategias es que el usuario puede controlar la cantidad de clasificadores utilizados, ya sea para comprimir el modelo (0 &amp;lt;code_size &amp;lt;1) o para hacer que el modelo sea m&amp;aacute;s robusto a errores (code_size&amp;gt; 1). Consulte la documentaci&amp;oacute;n para obtener m&amp;aacute;s detalles.</target>
        </trans-unit>
        <trans-unit id="a7e6bae7017e237617a86072aea77d9c980daf13" translate="yes" xml:space="preserve">
          <source>Overall mean.</source>
          <target state="translated">Media general.</target>
        </trans-unit>
        <trans-unit id="870624bf4593bb4fe243ffdc55690c0daf6811c5" translate="yes" xml:space="preserve">
          <source>Overall mean. Only present if solver is &amp;lsquo;svd&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39400cd6ec0520b5a4505f75497b844c4371060d" translate="yes" xml:space="preserve">
          <source>Overall you can expect the prediction time to increase at least linearly with the number of features (non-linear cases can happen depending on the global memory footprint and estimator).</source>
          <target state="translated">En general se puede esperar que el tiempo de predicción aumente al menos linealmente con el número de características (los casos no lineales pueden ocurrir dependiendo de la huella de la memoria global y del estimador).</target>
        </trans-unit>
        <trans-unit id="3ee1d3fb4e75cd6c2d707958304caf7e92bfaa8b" translate="yes" xml:space="preserve">
          <source>Overall, the drivers age (&lt;code&gt;DrivAge&lt;/code&gt;) has a weak impact on the claim severity, both in observed and predicted data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91bd96083d98dc97930a239b87544217767aceaf" translate="yes" xml:space="preserve">
          <source>Override the preprocessing (string transformation) stage while preserving the tokenizing and n-grams generation steps.</source>
          <target state="translated">Anular la etapa de preprocesamiento (transformación de la cuerda)conservando los pasos de generación de token y n-grams.</target>
        </trans-unit>
        <trans-unit id="acdc2f08598a5d995bb4a299bbeb6695fc569906" translate="yes" xml:space="preserve">
          <source>Override the preprocessing (string transformation) stage while preserving the tokenizing and n-grams generation steps. Only applies if &lt;code&gt;analyzer is not callable&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abd6316e00c26c25837bba2d69b86f216194acd8" translate="yes" xml:space="preserve">
          <source>Override the string tokenization step while preserving the preprocessing and n-grams generation steps. Only applies if &lt;code&gt;analyzer == 'word'&lt;/code&gt;.</source>
          <target state="translated">Anule el paso de tokenizaci&amp;oacute;n de cadenas conservando los pasos de preprocesamiento y generaci&amp;oacute;n de n-gramos. Solo se aplica si &lt;code&gt;analyzer == 'word'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="33411261f8481ce8d25af4edfb3eb882b6e66f99" translate="yes" xml:space="preserve">
          <source>Oversubscription can arise in the exact same fashion with parallelized routines from MKL, OpenBLAS or BLIS that are nested in joblib calls.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ed28a68908d4cdeb1448490b897df73855c6566" translate="yes" xml:space="preserve">
          <source>P. Geurts, D. Ernst., and L. Wehenkel, &amp;ldquo;Extremely randomized trees&amp;rdquo;, Machine Learning, 63(1), 3-42, 2006.</source>
          <target state="translated">P. Geurts, D. Ernst. Y L. Wehenkel, &quot;&amp;Aacute;rboles extremadamente aleatorios&quot;, Machine Learning, 63 (1), 3-42, 2006.</target>
        </trans-unit>
        <trans-unit id="12d77ff2c2e2faf889fa68d60f9acbbdadb178db" translate="yes" xml:space="preserve">
          <source>P. J. Rousseeuw. Least median of squares regression. J. Am Stat Ass, 79:871, 1984.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="915eb2720a9af992fe72961a5e439fc3997b7b8e" translate="yes" xml:space="preserve">
          <source>P. J. Rousseeuw. Least median of squares regression. Journal of American Statistical Ass., 79:871, 1984.</source>
          <target state="translated">P.J.Rousseeuw.Media mínima de regresión de los cuadrados.Journal of American Statistical Ass.,79:871,1984.</target>
        </trans-unit>
        <trans-unit id="b9c25cc16ba020ea92289241ec3d659cb7a5c1ce" translate="yes" xml:space="preserve">
          <source>P.A. Flach, M. Kull, &lt;a href=&quot;http://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf&quot;&gt;Precision-Recall-Gain Curves: PR Analysis Done Right&lt;/a&gt;, NIPS 2015.</source>
          <target state="translated">PA Flach, M. Kull, &lt;a href=&quot;http://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf&quot;&gt;Curvas de precisi&amp;oacute;n-recuperaci&amp;oacute;n-ganancia: an&amp;aacute;lisis de relaciones p&amp;uacute;blicas bien hecho&lt;/a&gt; , NIPS 2015.</target>
        </trans-unit>
        <trans-unit id="6732b8c3c2862c9a25623cf97fcdcc10a13cb40d" translate="yes" xml:space="preserve">
          <source>P.A. Flach, M. Kull, &lt;a href=&quot;https://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf&quot;&gt;Precision-Recall-Gain Curves: PR Analysis Done Right&lt;/a&gt;, NIPS 2015.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df9f68f22da202cd6a48417661656eae814961f2" translate="yes" xml:space="preserve">
          <source>PCA centers but does not scale the input data for each feature before applying the SVD. The optional parameter &lt;code&gt;whiten=True&lt;/code&gt; makes it possible to project the data onto the singular space while scaling each component to unit variance. This is often useful if the models down-stream make strong assumptions on the isotropy of the signal: this is for example the case for Support Vector Machines with the RBF kernel and the K-Means clustering algorithm.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="492b92fdeb678aa5ea0a0b2e24c313120c5ad6a0" translate="yes" xml:space="preserve">
          <source>PCA example with Iris Data-set</source>
          <target state="translated">Ejemplo de PCA con el conjunto de datos del Iris</target>
        </trans-unit>
        <trans-unit id="e783d8dc6810fed89a1dbeb972c615c5d6fa683c" translate="yes" xml:space="preserve">
          <source>PCA is used to decompose a multivariate dataset in a set of successive orthogonal components that explain a maximum amount of the variance. In scikit-learn, &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; is implemented as a &lt;em&gt;transformer&lt;/em&gt; object that learns \(n\) components in its &lt;code&gt;fit&lt;/code&gt; method, and can be used on new data to project it on these components.</source>
          <target state="translated">El PCA se utiliza para descomponer un conjunto de datos multivariante en un conjunto de componentes ortogonales sucesivos que explican una cantidad m&amp;aacute;xima de varianza. En scikit-learn, &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; se implementa como un objeto &lt;em&gt;transformador&lt;/em&gt; que aprende \ (n \) componentes en su m&amp;eacute;todo de &lt;code&gt;fit&lt;/code&gt; y se puede utilizar en nuevos datos para proyectarlos en estos componentes.</target>
        </trans-unit>
        <trans-unit id="a8428e4319c22658665567a92df72d0be42ed589" translate="yes" xml:space="preserve">
          <source>PCA, on the other hand, finds orthogonal directions in the raw feature space that correspond to directions accounting for maximum variance.</source>
          <target state="translated">El PCA,por otro lado,encuentra direcciones ortogonales en el espacio de características brutas que corresponden a las direcciones que dan cuenta de la máxima variación.</target>
        </trans-unit>
        <trans-unit id="daf6b41a17ad64437397807edf4249f5c767d4f8" translate="yes" xml:space="preserve">
          <source>PDF documentation</source>
          <target state="translated">Documentación en PDF</target>
        </trans-unit>
        <trans-unit id="39addbbc6b853c00475e9525bae3e13c16a88c57" translate="yes" xml:space="preserve">
          <source>PDF of a random variable Y following Poisson, Tweedie (power=1.5) and Gamma distributions with different mean values (\(\mu\)). Observe the point mass at \(Y=0\) for the Poisson distribution and the Tweedie (power=1.5) distribution, but not for the Gamma distribution which has a strictly positive target domain.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83a2c673c060675dd48fb711d1c30c7deadadba5" translate="yes" xml:space="preserve">
          <source>PDPs with two target features show the interactions among the two features. For example, the two-variable PDP in the above Figure shows the dependence of median house price on joint values of house age and avg. occupants per household. We can clearly see an interaction between the two features: For an avg. occupancy greater than two, the house price is nearly independent of the house age, whereas for values less than two there is a strong dependence on age.</source>
          <target state="translated">Los PDP con dos características de objetivo muestran las interacciones entre las dos características.Por ejemplo,la PDP de dos variables de la figura anterior muestra la dependencia del precio medio de la vivienda de los valores conjuntos de la edad de la vivienda y el promedio de ocupantes por hogar.Podemos ver claramente una interacción entre las dos características:Para una ocupación media superior a dos,el precio de la vivienda es casi independiente de la edad de la casa,mientras que para valores inferiores a dos hay una fuerte dependencia de la edad.</target>
        </trans-unit>
        <trans-unit id="eb9628323c2e00c334e5176712c96c9098e56078" translate="yes" xml:space="preserve">
          <source>PDPs with two target features show the interactions among the two features. For example, the two-variable PDP in the above figure shows the dependence of median house price on joint values of house age and average occupants per household. We can clearly see an interaction between the two features: for an average occupancy greater than two, the house price is nearly independent of the house age, whereas for values less than 2 there is a strong dependence on age.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="818b23313a5fe3e3ead33eeac95b3f83aefbbeb6" translate="yes" xml:space="preserve">
          <source>PLS regression</source>
          <target state="translated">Regresión PLS</target>
        </trans-unit>
        <trans-unit id="256d47be93e9a1da4b73eeee064926026bfad0da" translate="yes" xml:space="preserve">
          <source>PLSCanonical implements the 2 blocks canonical PLS of the original Wold algorithm [Tenenhaus 1998] p.204, referred as PLS-C2A in [Wegelin 2000].</source>
          <target state="translated">PLSCanonical implementa los 2 bloques canónicos PLS del algoritmo original de Wold [Tenenhaus 1998]p.204,referido como PLS-C2A en [Wegelin 2000].</target>
        </trans-unit>
        <trans-unit id="cbfe13649cb0f1ff547f98c2537765f522c1604e" translate="yes" xml:space="preserve">
          <source>PLSRegression implements the PLS 2 blocks regression known as PLS2 or PLS1 in case of one dimensional response. This class inherits from _PLS with mode=&amp;rdquo;A&amp;rdquo;, deflation_mode=&amp;rdquo;regression&amp;rdquo;, norm_y_weights=False and algorithm=&amp;rdquo;nipals&amp;rdquo;.</source>
          <target state="translated">PLSRegression implementa la regresi&amp;oacute;n de bloques PLS 2 conocida como PLS2 o PLS1 en caso de respuesta unidimensional. Esta clase hereda de _PLS con mode = &amp;rdquo;A&amp;rdquo;, deflation_mode = &amp;rdquo;regression&amp;rdquo;, norm_y_weights = False y algor&amp;iacute;tmo = &amp;rdquo;nipals&amp;rdquo;.</target>
        </trans-unit>
        <trans-unit id="5bd004de10b3be3d62af4c772e0a783e4c8d0cf7" translate="yes" xml:space="preserve">
          <source>PTRATIO pupil-teacher ratio by town</source>
          <target state="translated">PTRATIO proporción alumno-profesor por ciudad</target>
        </trans-unit>
        <trans-unit id="41c1bb8d3d0929f28ded963b3c507fc9ad31e847" translate="yes" xml:space="preserve">
          <source>Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions, Statistics and Probability Letters, 33 (1997) 291-297</source>
          <target state="translated">Pace,R.Kelley y Ronald Barry,Sparse Spatial Autoregressions,Statistics and Probability Letters,33 (1997)291-297</target>
        </trans-unit>
        <trans-unit id="839107cb8051c220f3fa3546dd66b100d0cfaf46" translate="yes" xml:space="preserve">
          <source>Pairwise Euclidean distances between points in the dataset.</source>
          <target state="translated">Distancias euclidianas por pares entre los puntos del conjunto de datos.</target>
        </trans-unit>
        <trans-unit id="91ced6bbdf313e062ca8a5307f468c6f86bd6aab" translate="yes" xml:space="preserve">
          <source>Pairwise dissimilarities between the points. Must be symmetric.</source>
          <target state="translated">Disimilitudes entre los puntos.Debe ser simétrico.</target>
        </trans-unit>
        <trans-unit id="d8020c04569a536923cc79cf93520b90edece8e9" translate="yes" xml:space="preserve">
          <source>Pairwise metrics</source>
          <target state="translated">Métricas por pares</target>
        </trans-unit>
        <trans-unit id="0f7f7966f9f80e85baa6445a47b9d7c8941de99f" translate="yes" xml:space="preserve">
          <source>Parameter &lt;code&gt;nu&lt;/code&gt; in &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt;&lt;code&gt;NuSVC&lt;/code&gt;&lt;/a&gt;/&lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;OneClassSVM&lt;/code&gt;&lt;/a&gt;/&lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt;&lt;code&gt;NuSVR&lt;/code&gt;&lt;/a&gt; approximates the fraction of training errors and support vectors.</source>
          <target state="translated">El par&amp;aacute;metro &lt;code&gt;nu&lt;/code&gt; en &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt; &lt;code&gt;NuSVC&lt;/code&gt; &lt;/a&gt; / &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;OneClassSVM&lt;/code&gt; &lt;/a&gt; / &lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt; &lt;code&gt;NuSVR&lt;/code&gt; se&lt;/a&gt; aproxima a la fracci&amp;oacute;n de errores de entrenamiento y vectores de soporte.</target>
        </trans-unit>
        <trans-unit id="539d705b4d5ce5e51b178019bd7f151f362e066d" translate="yes" xml:space="preserve">
          <source>Parameter controlling the inhomogenity of the kernel. If sigma_0=0, the kernel is homogenous.</source>
          <target state="translated">Parámetro que controla la inhomogeneidad del núcleo.Si sigma_0=0,el núcleo es homogéneo.</target>
        </trans-unit>
        <trans-unit id="2462327ecfe7c5d6548ffb2d6d2c9cd234dbc30c" translate="yes" xml:space="preserve">
          <source>Parameter controlling the noise level</source>
          <target state="translated">Parámetro que controla el nivel de ruido</target>
        </trans-unit>
        <trans-unit id="c00b33b8475549fd87f899268c585bfb7eff3c97" translate="yes" xml:space="preserve">
          <source>Parameter controlling the noise level (variance)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4958bb8c16cafb2697226165d2c132d7ac8dc77e" translate="yes" xml:space="preserve">
          <source>Parameter estimation using grid search with cross-validation</source>
          <target state="translated">Estimación de parámetros mediante la búsqueda de cuadrículas con validación cruzada</target>
        </trans-unit>
        <trans-unit id="c2428812e57708220766f99c6be2b35f70d17ffd" translate="yes" xml:space="preserve">
          <source>Parameter for knn kernel</source>
          <target state="translated">Parámetro para el knn kernel</target>
        </trans-unit>
        <trans-unit id="3b0d1a590649f050970c31b6418be3790d6a82df" translate="yes" xml:space="preserve">
          <source>Parameter for knn kernel which is a strictly positive integer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="849fb657e2772ba4166207f98cd952ea68adf842" translate="yes" xml:space="preserve">
          <source>Parameter for knn kernel which need to be strictly positive.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1fe064660ce73ee246b908fe6ec0781ebb1b98a2" translate="yes" xml:space="preserve">
          <source>Parameter for rbf kernel</source>
          <target state="translated">Parámetro para el núcleo rbf</target>
        </trans-unit>
        <trans-unit id="deecb0cfdd93d212c57e43f85e54500d3ea12cc6" translate="yes" xml:space="preserve">
          <source>Parameter for rbf kernel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="766ac73c1e3445a4aa75bd4ec364753f58d7ba1c" translate="yes" xml:space="preserve">
          <source>Parameter for the Minkowski metric from &lt;a href=&quot;sklearn.metrics.pairwise_distances#sklearn.metrics.pairwise_distances&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise_distances&lt;/code&gt;&lt;/a&gt;. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79b884107bc3e783bfcd688080df4a673a9117bc" translate="yes" xml:space="preserve">
          <source>Parameter for the Minkowski metric from &lt;code&gt;sklearn.metrics.pairwise.pairwise_distances&lt;/code&gt;. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</source>
          <target state="translated">Par&amp;aacute;metro para la m&amp;eacute;trica de Minkowski de &lt;code&gt;sklearn.metrics.pairwise.pairwise_distances&lt;/code&gt; . Cuando p = 1, esto es equivalente a usar manhattan_distance (l1) y euclidean_distance (l2) para p = 2. Para p arbitrario, se usa minkowski_distance (l_p).</target>
        </trans-unit>
        <trans-unit id="2987673c5e2227c54e84a4c36c70d874959de513" translate="yes" xml:space="preserve">
          <source>Parameter for the Minkowski metric from sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</source>
          <target state="translated">Parámetro para la métrica de Minkowski de sklearn.metrics.pairwise.pairwise_distances.Cuando p=1,esto equivale a usar la distancia_de_manhattan (l1),y la distancia_de_euclides (l2)para p=2.Para p arbitraria,se usa minkowski_distance (l_p).</target>
        </trans-unit>
        <trans-unit id="76b1a424a6610c92a4ff7dfc12b9deaa7fadd9d4" translate="yes" xml:space="preserve">
          <source>Parameter gamma of the pairwise kernel specified by metric</source>
          <target state="translated">El parámetro gamma del núcleo por pares especificado por la métrica</target>
        </trans-unit>
        <trans-unit id="1a54a92f7211f800d04136c5d7139c5f372c6e37" translate="yes" xml:space="preserve">
          <source>Parameter gamma of the pairwise kernel specified by metric. It should be positive.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f182d859d9049c92f489a6a5f8f861f198a0672" translate="yes" xml:space="preserve">
          <source>Parameter names mapped to their values.</source>
          <target state="translated">Nombres de parámetros mapeados a sus valores.</target>
        </trans-unit>
        <trans-unit id="6c7eaceb91dd3f01e9a6c5c6273381eb8837898b" translate="yes" xml:space="preserve">
          <source>Parameter of RBF kernel: exp(-gamma * x^2)</source>
          <target state="translated">Parámetro o núcleo RBF:exp(-gamma*x^2)</target>
        </trans-unit>
        <trans-unit id="0a55d1c3b23ce41ff45285111de0d234bf72191c" translate="yes" xml:space="preserve">
          <source>Parameter of the corresponding mode.</source>
          <target state="translated">Parámetro del modo correspondiente.</target>
        </trans-unit>
        <trans-unit id="bd306dfafa0f09eb6ebeeb4165e12648835ffbc7" translate="yes" xml:space="preserve">
          <source>Parameter setting that gave the best results on the hold out data.</source>
          <target state="translated">El ajuste de los parámetros que dieron los mejores resultados en los datos de la retención.</target>
        </trans-unit>
        <trans-unit id="feb33995ff27df7648c2862697f9ab2d916fc6ad" translate="yes" xml:space="preserve">
          <source>Parameter to control the quality of the embedding according to the Johnson-Lindenstrauss lemma when n_components is set to &amp;lsquo;auto&amp;rsquo;.</source>
          <target state="translated">Par&amp;aacute;metro para controlar la calidad de la incrustaci&amp;oacute;n de acuerdo con el lema de Johnson-Lindenstrauss cuando n_components se establece en 'auto'.</target>
        </trans-unit>
        <trans-unit id="9ebea54f905d700d979affa38d92638bb2ef6e53" translate="yes" xml:space="preserve">
          <source>Parameter tuning using grid search</source>
          <target state="translated">Sintonización de parámetros mediante la búsqueda de cuadrículas</target>
        </trans-unit>
        <trans-unit id="025546b75e4d071d18ff381aef96422930bc33e9" translate="yes" xml:space="preserve">
          <source>Parameter vector (W in the cost function formula). If a 1D y is passed in at fit (non multi-task usage), &lt;code&gt;coef_&lt;/code&gt; is then a 1D array. Note that &lt;code&gt;coef_&lt;/code&gt; stores the transpose of &lt;code&gt;W&lt;/code&gt;, &lt;code&gt;W.T&lt;/code&gt;.</source>
          <target state="translated">Vector de par&amp;aacute;metros (W en la f&amp;oacute;rmula de la funci&amp;oacute;n de costo). Si un 1D y se pasa en ajuste (uso no multitarea), &lt;code&gt;coef_&lt;/code&gt; es entonces una matriz 1D. Tenga en cuenta que &lt;code&gt;coef_&lt;/code&gt; almacena la transposici&amp;oacute;n de &lt;code&gt;W&lt;/code&gt; , &lt;code&gt;W.T&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="fe2cd82aa0b85722f1fb3f2651910fd5a1cb8bc3" translate="yes" xml:space="preserve">
          <source>Parameter vector (W in the cost function formula). Note that &lt;code&gt;coef_&lt;/code&gt; stores the transpose of &lt;code&gt;W&lt;/code&gt;, &lt;code&gt;W.T&lt;/code&gt;.</source>
          <target state="translated">Vector de par&amp;aacute;metros (W en la f&amp;oacute;rmula de la funci&amp;oacute;n de costo). Tenga en cuenta que &lt;code&gt;coef_&lt;/code&gt; almacena la transposici&amp;oacute;n de &lt;code&gt;W&lt;/code&gt; , &lt;code&gt;W.T&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="40a18e293fedd48b8399b301e107b7d0fd89c55d" translate="yes" xml:space="preserve">
          <source>Parameter vector (w in the cost function formula),</source>
          <target state="translated">Vector del parámetro (w en la fórmula de la función de costo),</target>
        </trans-unit>
        <trans-unit id="f2cc602f72e28952a1109943af93a6b27340c9a5" translate="yes" xml:space="preserve">
          <source>Parameter vector (w in the formulation formula).</source>
          <target state="translated">Vector del parámetro (w en la fórmula de la formulación).</target>
        </trans-unit>
        <trans-unit id="b98d4ebc4de7e076498469fbea1e480d774d01d2" translate="yes" xml:space="preserve">
          <source>Parameter vector (w in the problem formulation).</source>
          <target state="translated">Vector del parámetro (w en la formulación del problema).</target>
        </trans-unit>
        <trans-unit id="a975eea30db9fa05003e3b5097688bd49ec7e01b" translate="yes" xml:space="preserve">
          <source>Parameters</source>
          <target state="translated">Parameters</target>
        </trans-unit>
        <trans-unit id="561ad54783e422872a1f3fe4a9c36ebd61273494" translate="yes" xml:space="preserve">
          <source>Parameters (keyword arguments) and values for kernel passed as callable object. Ignored by other kernels.</source>
          <target state="translated">Parámetros (argumentos de palabras clave)y valores para el núcleo pasados como objeto llamable.Ignorado por otros núcleos.</target>
        </trans-unit>
        <trans-unit id="80f07c17ffcb9ce6c39eaf0025d7648367dfab02" translate="yes" xml:space="preserve">
          <source>Parameters for the metric used to compute distances to neighbors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89febd358321017f18d670418f2852c0de1ee9c6" translate="yes" xml:space="preserve">
          <source>Parameters of the estimators in the pipeline can be accessed using the &lt;code&gt;&amp;lt;estimator&amp;gt;__&amp;lt;parameter&amp;gt;&lt;/code&gt; syntax:</source>
          <target state="translated">Se puede acceder a los par&amp;aacute;metros de los estimadores en la canalizaci&amp;oacute;n usando la sintaxis &lt;code&gt;&amp;lt;estimator&amp;gt;__&amp;lt;parameter&amp;gt;&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="da0d463840d0f1c86c777dbae23f9ad6731982e6" translate="yes" xml:space="preserve">
          <source>Parameters of the transformers may be set using its name and the parameter name separated by a &amp;lsquo;__&amp;rsquo;. A transformer may be replaced entirely by setting the parameter with its name to another transformer, or removed by setting to &amp;lsquo;drop&amp;rsquo; or &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">Los par&amp;aacute;metros de los transformadores se pueden configurar usando su nombre y el nombre del par&amp;aacute;metro separados por un '__'. Un transformador puede reemplazarse por completo configurando el par&amp;aacute;metro con su nombre a otro transformador, o eliminarse configurando en 'ca&amp;iacute;da' o &lt;code&gt;None&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="689a87c23200ec6fa5f83b0f33b09b3222cdab89" translate="yes" xml:space="preserve">
          <source>Parameters of the transformers may be set using its name and the parameter name separated by a &amp;lsquo;__&amp;rsquo;. A transformer may be replaced entirely by setting the parameter with its name to another transformer, or removed by setting to &amp;lsquo;drop&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc1660202c57ce270668effe7d8743477471db0d" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;estimator.fit&lt;/code&gt; method of each step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cdc9ca5309db0dd08f8314e5e5818e96afcd9144" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;fit&lt;/code&gt; method at each step of the regressor chain.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b076b9abb4a3e4211d375c7fba667486c4754cb9" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;fit&lt;/code&gt; method of each step, where each parameter name is prefixed such that parameter &lt;code&gt;p&lt;/code&gt; for step &lt;code&gt;s&lt;/code&gt; has key &lt;code&gt;s__p&lt;/code&gt;.</source>
          <target state="translated">Par&amp;aacute;metros pasados ​​al m&amp;eacute;todo de &lt;code&gt;fit&lt;/code&gt; de cada paso, donde cada nombre de par&amp;aacute;metro tiene un prefijo tal que el par&amp;aacute;metro &lt;code&gt;p&lt;/code&gt; para el paso &lt;code&gt;s&lt;/code&gt; tiene la clave &lt;code&gt;s__p&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1ab85e076de8886205c489db8ed7843daa19517c" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;fit&lt;/code&gt; method of the estimator</source>
          <target state="translated">Par&amp;aacute;metros pasados ​​al m&amp;eacute;todo de &lt;code&gt;fit&lt;/code&gt; del estimador</target>
        </trans-unit>
        <trans-unit id="6dde0ba4e8565b39355c42aec6126c1947540a58" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;fit&lt;/code&gt; method of the underlying regressor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e8067debf1488481c61a1eaa4a0a76867521e4f" translate="yes" xml:space="preserve">
          <source>Parameters to be set on estimator for this grid point.</source>
          <target state="translated">Parámetros a establecer en el estimador para este punto de la cuadrícula.</target>
        </trans-unit>
        <trans-unit id="191e3e986e6964fefdb746bdbd32d026ac54732c" translate="yes" xml:space="preserve">
          <source>Parameters to pass to the fit method of the estimator.</source>
          <target state="translated">Parámetros para pasar al método de ajuste del estimador.</target>
        </trans-unit>
        <trans-unit id="80e379dd51d34ce2dbedd57a975596631a95d883" translate="yes" xml:space="preserve">
          <source>Parameters to pass to the fit method.</source>
          <target state="translated">Parámetros para pasar al método de ajuste.</target>
        </trans-unit>
        <trans-unit id="36ccb38b123600d9fbc78ab0cd9b6b307a008e1c" translate="yes" xml:space="preserve">
          <source>Parameters to the &lt;code&gt;predict&lt;/code&gt; called at the end of all transformations in the pipeline. Note that while this may be used to return uncertainties from some models with return_std or return_cov, uncertainties that are generated by the transformations in the pipeline are not propagated to the final estimator.</source>
          <target state="translated">Par&amp;aacute;metros de la &lt;code&gt;predict&lt;/code&gt; llamados al final de todas las transformaciones en la canalizaci&amp;oacute;n. Tenga en cuenta que, si bien esto puede usarse para devolver incertidumbres de algunos modelos con return_std o return_cov, las incertidumbres que se generan por las transformaciones en la tuber&amp;iacute;a no se propagan al estimador final.</target>
        </trans-unit>
        <trans-unit id="b3a7c9dd881e64a7f41aafeb58e4f8bfcc6a5b4f" translate="yes" xml:space="preserve">
          <source>Parameters to the &lt;code&gt;predict&lt;/code&gt; called by the &lt;code&gt;final_estimator&lt;/code&gt;. Note that this may be used to return uncertainties from some estimators with &lt;code&gt;return_std&lt;/code&gt; or &lt;code&gt;return_cov&lt;/code&gt;. Be aware that it will only accounts for uncertainty in the final estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="381c775599d6e4185d4410725809e360928357cd" translate="yes" xml:space="preserve">
          <source>Parameters:</source>
          <target state="translated">Parameters:</target>
        </trans-unit>
        <trans-unit id="99be92c9a2dedb3674880d6acb8f2dcdcbd96ff3" translate="yes" xml:space="preserve">
          <source>Parsing a text based source can be expensive. When working on repeatedly on the same dataset, it is recommended to wrap this loader with joblib.Memory.cache to store a memmapped backup of the CSR results of the first call and benefit from the near instantaneous loading of memmapped structures for the subsequent calls.</source>
          <target state="translated">Analizar una fuente basada en un texto puede ser costoso.Cuando se trabaja repetidamente en el mismo conjunto de datos,se recomienda envolver este cargador con joblib.Memory.cache para almacenar una copia de seguridad en un memmapped de los resultados CSR de la primera llamada y beneficiarse de la carga casi instantánea de las estructuras en un memmapped para las llamadas posteriores.</target>
        </trans-unit>
        <trans-unit id="9dffe51138babd8f1ead215ce660a1e946197066" translate="yes" xml:space="preserve">
          <source>Partial Dependence Plot (PDP) visualization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f8d5f258416422c57466cd67cc8a02c6b05a80fd" translate="yes" xml:space="preserve">
          <source>Partial Dependence Plots</source>
          <target state="translated">Parcelas de dependencia parcial</target>
        </trans-unit>
        <trans-unit id="07df4cbd5294e07465f804b7c9b36c5d5a43e82b" translate="yes" xml:space="preserve">
          <source>Partial Dependence computation for Gradient Boosting</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b282664cc1d0ff2c6d0b320162703f3341719289" translate="yes" xml:space="preserve">
          <source>Partial Dependence computation for multi-layer perceptron</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9c89f964f1a01a36b42f3fe4848b74ccc63e0e6" translate="yes" xml:space="preserve">
          <source>Partial Least Square SVD</source>
          <target state="translated">SVD de cuadrados mínimos parciales</target>
        </trans-unit>
        <trans-unit id="0af696b5fd6af6b13c25a86aed283f8f2b249126" translate="yes" xml:space="preserve">
          <source>Partial dependence of &lt;code&gt;features&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93cbd804a6e8e51bf70182f90134157ea23f1138" translate="yes" xml:space="preserve">
          <source>Partial dependence of &lt;code&gt;target_variables&lt;/code&gt;.</source>
          <target state="translated">Dependencia parcial de &lt;code&gt;target_variables&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="abf44f40a8ead68e3c71b46bec075211dc75d783" translate="yes" xml:space="preserve">
          <source>Partial dependence of a feature (or a set of features) corresponds to the average response of an estimator for each possible value of the feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c99d4545385034142f3b81de241245acbbd2acd6" translate="yes" xml:space="preserve">
          <source>Partial dependence plots (PDP) show the dependence between the target response &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt; and a set of &amp;lsquo;target&amp;rsquo; features, marginalizing over the values of all other features (the &amp;lsquo;complement&amp;rsquo; features). Intuitively, we can interpret the partial dependence as the expected target response as a function of the &amp;lsquo;target&amp;rsquo; features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a65d01c56b56d7e6904a157392f75eb71dc3b44" translate="yes" xml:space="preserve">
          <source>Partial dependence plots (PDP) show the dependence between the target response and a set of &amp;lsquo;target&amp;rsquo; features, marginalizing over the values of all other features (the &amp;lsquo;complement&amp;rsquo; features). Intuitively, we can interpret the partial dependence as the expected target response &lt;a href=&quot;#id23&quot; id=&quot;id21&quot;&gt;[1]&lt;/a&gt; as a function of the &amp;lsquo;target&amp;rsquo; features &lt;a href=&quot;#id24&quot; id=&quot;id22&quot;&gt;[2]&lt;/a&gt;.</source>
          <target state="translated">Los gr&amp;aacute;ficos de dependencia parcial (PDP) muestran la dependencia entre la respuesta objetivo y un conjunto de caracter&amp;iacute;sticas 'objetivo', marginando los valores de todas las dem&amp;aacute;s caracter&amp;iacute;sticas (las caracter&amp;iacute;sticas 'complementarias'). Intuitivamente, podemos interpretar la dependencia parcial como la respuesta objetivo esperada &lt;a href=&quot;#id23&quot; id=&quot;id21&quot;&gt;[1]&lt;/a&gt; en funci&amp;oacute;n de las caracter&amp;iacute;sticas del 'objetivo' &lt;a href=&quot;#id24&quot; id=&quot;id22&quot;&gt;[2]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="9fe71a24f95abe640c27c0bbf2214ad816fa5b2e" translate="yes" xml:space="preserve">
          <source>Partial dependence plots for &lt;code&gt;features&lt;/code&gt;.</source>
          <target state="translated">Gr&amp;aacute;ficos de dependencia parcial para &lt;code&gt;features&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="652e656223f58b0f5fc37309adb1b1ac47d155cf" translate="yes" xml:space="preserve">
          <source>Partial dependence plots for tree ensembles.</source>
          <target state="translated">Parcelas de dependencia parcial para conjuntos de árboles.</target>
        </trans-unit>
        <trans-unit id="c1a7be74107eb23fd9bfcd8698a88bc718aa4772" translate="yes" xml:space="preserve">
          <source>Partial dependence plots show the dependence between the joint values of the &lt;code&gt;target_variables&lt;/code&gt; and the function represented by the &lt;code&gt;gbrt&lt;/code&gt;.</source>
          <target state="translated">Los gr&amp;aacute;ficos de dependencia parcial muestran la dependencia entre los valores conjuntos de &lt;code&gt;target_variables&lt;/code&gt; y la funci&amp;oacute;n representada por &lt;code&gt;gbrt&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="fc1161112f98108492921350df0f600984c6b3b0" translate="yes" xml:space="preserve">
          <source>Partial dependence plots show the dependence between the target function &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;2&lt;/a&gt; and a set of &amp;lsquo;target&amp;rsquo; features, marginalizing over the values of all other features (the complement features). Due to the limits of human perception, the size of the target feature set must be small (usually, one or two) thus the target features are usually chosen among the most important features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04afc172d4359535322f4eeb08a601341437662b" translate="yes" xml:space="preserve">
          <source>Partial dependence plots show the dependence between the target function &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt; and a set of &amp;lsquo;target&amp;rsquo; features, marginalizing over the values of all other features (the complement features). Due to the limits of human perception the size of the target feature set must be small (usually, one or two) thus the target features are usually chosen among the most important features (see &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor.feature_importances_&quot;&gt;&lt;code&gt;feature_importances_&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">Los gr&amp;aacute;ficos de dependencia parcial muestran la dependencia entre la funci&amp;oacute;n objetivo &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt; y un conjunto de caracter&amp;iacute;sticas 'objetivo', marginando los valores de todas las dem&amp;aacute;s caracter&amp;iacute;sticas (las caracter&amp;iacute;sticas complementarias). Debido a los l&amp;iacute;mites de la percepci&amp;oacute;n humana, el tama&amp;ntilde;o del conjunto de caracter&amp;iacute;sticas de destino debe ser peque&amp;ntilde;o (generalmente, uno o dos), por lo que las caracter&amp;iacute;sticas de destino generalmente se eligen entre las caracter&amp;iacute;sticas m&amp;aacute;s importantes (ver &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor.feature_importances_&quot;&gt; &lt;code&gt;feature_importances_&lt;/code&gt; &lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="a4a9c59e85db7b4787e5c0d6935be7408b0e1749" translate="yes" xml:space="preserve">
          <source>Partial dependence plots with two target features enable us to visualize interactions among them. The two-way partial dependence plot shows the dependence of median house price on joint values of house age and average occupants per household. We can clearly see an interaction between the two features: for an average occupancy greater than two, the house price is nearly independent of the house age, whereas for values less than two there is a strong dependence on age.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27028d4e93727066aec3e2e83aa74954e7719a8b" translate="yes" xml:space="preserve">
          <source>Partial dependence plots with two target features enable us to visualize interactions among them. The two-way partial dependence plot shows the dependence of median house price on joint values of house age and avg. occupants per household. We can clearly see an interaction between the two features: For an avg. occupancy greater than two, the house price is nearly independent of the house age, whereas for values less than two there is a strong dependence on age.</source>
          <target state="translated">Las tramas de dependencia parcial con dos características de objetivo nos permiten visualizar las interacciones entre ellas.La gráfica de dependencia parcial de dos direcciones muestra la dependencia del precio medio de la vivienda de los valores conjuntos de la edad de la vivienda y el promedio de ocupantes por hogar.Podemos ver claramente una interacción entre las dos características:Para una media de ocupación mayor de dos,el precio de la casa es casi independiente de la edad de la misma,mientras que para valores menores de dos hay una fuerte dependencia de la edad.</target>
        </trans-unit>
        <trans-unit id="b6af299fa9b94db48e98129e260b1eeb813719a6" translate="yes" xml:space="preserve">
          <source>Partial dependence plots.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e99bc5cb78022b1555bc70fa32795dba1ae5f4f" translate="yes" xml:space="preserve">
          <source>Partially fit underlying estimators</source>
          <target state="translated">Los estimadores subyacentes se ajustan parcialmente</target>
        </trans-unit>
        <trans-unit id="0a5bfb5dfddbf187589aac0e6c6f726ea3a56e0f" translate="yes" xml:space="preserve">
          <source>Particularly in high-dimensional spaces, data can more easily be separated linearly and the simplicity of classifiers such as naive Bayes and linear SVMs might lead to better generalization than is achieved by other classifiers.</source>
          <target state="translated">Particularmente en los espacios de altas dimensiones,los datos pueden separarse más fácilmente de manera lineal y la simplicidad de los clasificadores,como los Bayes ingenuos y los SVM lineales,podría conducir a una mejor generalización que la lograda por otros clasificadores.</target>
        </trans-unit>
        <trans-unit id="ee5c2f652fa0ba7331b6add7547b0b3f663aedd3" translate="yes" xml:space="preserve">
          <source>Partitions rows and columns under the assumption that the data has an underlying checkerboard structure. For instance, if there are two row partitions and three column partitions, each row will belong to three biclusters, and each column will belong to two biclusters. The outer product of the corresponding row and column label vectors gives this checkerboard structure.</source>
          <target state="translated">Divide las filas y columnas bajo el supuesto de que los datos tienen una estructura de tablero de ajedrez subyacente.Por ejemplo,si hay dos particiones de fila y tres de columna,cada fila pertenecerá a tres bíceps,y cada columna pertenecerá a dos bíceps.El producto exterior de los vectores correspondientes de las etiquetas de filas y columnas da esta estructura de tablero de ajedrez.</target>
        </trans-unit>
        <trans-unit id="364b4c71a5c83a360f4fe86b4c60a48d2e33f726" translate="yes" xml:space="preserve">
          <source>Pass an int for reproducible output for permutation of &lt;code&gt;y&lt;/code&gt; values among samples. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa828ddb159ddfa77238aad6f870c00db1af477d" translate="yes" xml:space="preserve">
          <source>Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9f564dc265e98a01f24f70d1576b62ca3b43bd3" translate="yes" xml:space="preserve">
          <source>Passing a 2D matrix for multilabel classification</source>
          <target state="translated">Pasando una matriz 2D para la clasificación de la multi-etiqueta</target>
        </trans-unit>
        <trans-unit id="cd2bb1a7aa8efcc1bd63306134f3100f91fc6ef3" translate="yes" xml:space="preserve">
          <source>Passing these predictions into an evaluation metric may not be a valid way to measure generalization performance. Results can differ from &lt;a href=&quot;sklearn.model_selection.cross_validate#sklearn.model_selection.cross_validate&quot;&gt;&lt;code&gt;cross_validate&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;cross_val_score&lt;/code&gt;&lt;/a&gt; unless all tests sets have equal size and the metric decomposes over samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="144adab066cd5c92a6778f61a4778ef74c72b2a0" translate="yes" xml:space="preserve">
          <source>Passive Aggressive Classifier</source>
          <target state="translated">Clasificador Pasivo Agresivo</target>
        </trans-unit>
        <trans-unit id="d61635eec17c853d9d6e1ff234afe50660f92701" translate="yes" xml:space="preserve">
          <source>Passive Aggressive Regressor</source>
          <target state="translated">Regressor pasivo agresivo</target>
        </trans-unit>
        <trans-unit id="291afa1da61effaacff4bf3e40a8045b9b8d343b" translate="yes" xml:space="preserve">
          <source>Patches are assumed to overlap and the image is constructed by filling in the patches from left to right, top to bottom, averaging the overlapping regions.</source>
          <target state="translated">Se supone que los parches se superponen y la imagen se construye rellenando los parches de izquierda a derecha,de arriba a abajo,promediando las regiones superpuestas.</target>
        </trans-unit>
        <trans-unit id="18a1699e2836ba2addd008ee2015c4e0ca5931f6" translate="yes" xml:space="preserve">
          <source>Path to the main folder holding one subfolder per category</source>
          <target state="translated">Ruta a la carpeta principal que contiene una subcarpeta por categoría</target>
        </trans-unit>
        <trans-unit id="98ee95181d901b366d1fe1c0df5a309cc7a3de65" translate="yes" xml:space="preserve">
          <source>Penalization parameter selected.</source>
          <target state="translated">Parámetro de penalización seleccionado.</target>
        </trans-unit>
        <trans-unit id="269c93d9d03f37f0d0341535ce102e3bd06fa60f" translate="yes" xml:space="preserve">
          <source>Penalize the intercept (bad)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3bbf431b41c522bd1eb1b65ea50fc21584275d87" translate="yes" xml:space="preserve">
          <source>Penalize the intercept (bad) yes no no no no Faster for large datasets no no no yes yes Robust to unscaled datasets yes yes yes no no ============================ =========== ======= =========== ===== ======</source>
          <target state="translated">Penalizar la interceptación (malo)sí no no no no Más rápido para grandes conjuntos de datos no no no sí sí Robusto para conjuntos de datos no escalados sí sí sí no no ===========================================================================</target>
        </trans-unit>
        <trans-unit id="64a00002571bc14aac9e57cf087ec95ea0663632" translate="yes" xml:space="preserve">
          <source>Penalty parameter C of the error term.</source>
          <target state="translated">Parámetro de penalización C del término de error.</target>
        </trans-unit>
        <trans-unit id="78e16aaecb446c766536c888cb2ab681d45d227a" translate="yes" xml:space="preserve">
          <source>Penalty parameter C of the error term. The penalty is a squared l2 penalty. The bigger this parameter, the less regularization is used.</source>
          <target state="translated">Parámetro de penalización C del término de error.La penalización es una penalización de l2 al cuadrado.Cuanto más grande es este parámetro,menos regularización se utiliza.</target>
        </trans-unit>
        <trans-unit id="92dc577567bc10903722a0cd6bc84fd8cb538ac8" translate="yes" xml:space="preserve">
          <source>Per default, the &amp;lsquo;L-BFGS-B&amp;rsquo; algorithm from scipy.optimize.minimize is used. If None is passed, the kernel&amp;rsquo;s parameters are kept fixed. Available internal optimizers are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36c27027dd1d6e2db082fc2d8518ad5ddec8cac4" translate="yes" xml:space="preserve">
          <source>Per default, the &amp;lsquo;L-BGFS-B&amp;rsquo; algorithm from scipy.optimize.minimize is used. If None is passed, the kernel&amp;rsquo;s parameters are kept fixed. Available internal optimizers are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4b4203fc28ce6d3a674721e39c00d5f8047107a" translate="yes" xml:space="preserve">
          <source>Per default, the &amp;lsquo;fmin_l_bfgs_b&amp;rsquo; algorithm from scipy.optimize is used. If None is passed, the kernel&amp;rsquo;s parameters are kept fixed. Available internal optimizers are:</source>
          <target state="translated">De forma predeterminada, se utiliza el algoritmo 'fmin_l_bfgs_b' de scipy.optimize. Si se pasa None, los par&amp;aacute;metros del kernel se mantienen fijos. Los optimizadores internos disponibles son:</target>
        </trans-unit>
        <trans-unit id="6244b7856d25c3c666d36fccf077f85fa1982ad7" translate="yes" xml:space="preserve">
          <source>Per feature adjustment for minimum.</source>
          <target state="translated">Por ajuste de características para el mínimo.</target>
        </trans-unit>
        <trans-unit id="3b00bbffe150e7b8c58881b0f3768ad4c9012a12" translate="yes" xml:space="preserve">
          <source>Per feature adjustment for minimum. Equivalent to &lt;code&gt;min - X.min(axis=0) * self.scale_&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1fcc9536b36965b70f539451057ec6f4f433503" translate="yes" xml:space="preserve">
          <source>Per feature maximum absolute value.</source>
          <target state="translated">El valor absoluto máximo por característica.</target>
        </trans-unit>
        <trans-unit id="c5e7199d590adbeaea5c7d5a6fd8bd4755090a1c" translate="yes" xml:space="preserve">
          <source>Per feature maximum seen in the data</source>
          <target state="translated">Por cada característica máxima vista en los datos</target>
        </trans-unit>
        <trans-unit id="102581d144872704eb291cec69ea6b75f7b2f4ae" translate="yes" xml:space="preserve">
          <source>Per feature minimum seen in the data</source>
          <target state="translated">Por cada característica mínima vista en los datos</target>
        </trans-unit>
        <trans-unit id="9af0de5bb3d05f02ad6ecd6ef96e244722359bc9" translate="yes" xml:space="preserve">
          <source>Per feature range &lt;code&gt;(data_max_ - data_min_)&lt;/code&gt; seen in the data</source>
          <target state="translated">Por rango de caracter&amp;iacute;sticas &lt;code&gt;(data_max_ - data_min_)&lt;/code&gt; visto en los datos</target>
        </trans-unit>
        <trans-unit id="3041c95c2bc4cf499751cc15dcfa6079b79d0c01" translate="yes" xml:space="preserve">
          <source>Per feature relative scaling of the data.</source>
          <target state="translated">Por la característica de la escala relativa de los datos.</target>
        </trans-unit>
        <trans-unit id="2aca96873ba30a1f44a2ea13c9cca023c862496e" translate="yes" xml:space="preserve">
          <source>Per feature relative scaling of the data. Equal to &lt;code&gt;None&lt;/code&gt; when &lt;code&gt;with_std=False&lt;/code&gt;.</source>
          <target state="translated">Escalado relativo de los datos por funci&amp;oacute;n. Igual a &lt;code&gt;None&lt;/code&gt; cuando &lt;code&gt;with_std=False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="add1f6f8b0508a85231ee2c9d67b3d85e4b4574a" translate="yes" xml:space="preserve">
          <source>Per feature relative scaling of the data. Equivalent to &lt;code&gt;(max - min) / (X.max(axis=0) - X.min(axis=0))&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f0850ba910ca1120662899ac545a63448e94c53" translate="yes" xml:space="preserve">
          <source>Per feature relative scaling of the data. This is calculated using &lt;code&gt;np.sqrt(var_)&lt;/code&gt;. Equal to &lt;code&gt;None&lt;/code&gt; when &lt;code&gt;with_std=False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03c5a380bfcbdfa271df31ac8e5033140b3c462f" translate="yes" xml:space="preserve">
          <source>Per-feature empirical mean, aggregate over calls to &lt;code&gt;partial_fit&lt;/code&gt;.</source>
          <target state="translated">Media emp&amp;iacute;rica por funci&amp;oacute;n, agregada sobre las llamadas a &lt;code&gt;partial_fit&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="9b69855eee3f3bb7b79cdf586195cf71da93449f" translate="yes" xml:space="preserve">
          <source>Per-feature empirical mean, estimated from the training set.</source>
          <target state="translated">Media empírica por característica,estimada a partir del conjunto de entrenamiento.</target>
        </trans-unit>
        <trans-unit id="78b2f336c949583f3bdffdc9a030b0f9e6170c47" translate="yes" xml:space="preserve">
          <source>Per-feature empirical mean, estimated from the training set. Equal to &lt;code&gt;X.mean(axis=0)&lt;/code&gt;.</source>
          <target state="translated">Media emp&amp;iacute;rica por funci&amp;oacute;n, estimada a partir del conjunto de entrenamiento. Igual a &lt;code&gt;X.mean(axis=0)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a8c85c36120ad4d7e0ffc8553bf9d9bb4f653d40" translate="yes" xml:space="preserve">
          <source>Per-feature empirical variance, aggregate over calls to &lt;code&gt;partial_fit&lt;/code&gt;.</source>
          <target state="translated">Varianza emp&amp;iacute;rica por funci&amp;oacute;n, agregada sobre las llamadas a &lt;code&gt;partial_fit&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="bb6e9ff3187e622eed5823426c5d8cc8b9a5e66d" translate="yes" xml:space="preserve">
          <source>Per-sample weights. Rescale C per sample. Higher weights force the classifier to put more emphasis on these points.</source>
          <target state="translated">Pesos por muestra.Reescalar C por muestra.Pesos más altos obligan al clasificador a poner más énfasis en estos puntos.</target>
        </trans-unit>
        <trans-unit id="022818083764d59bc1c545a8df2dfc49cf87ec2a" translate="yes" xml:space="preserve">
          <source>Per-topic word distributions are independently drawn, where in reality all would be affected by a sparse base distribution, and would be correlated.</source>
          <target state="translated">Las distribuciones de palabras por tema se dibujan de forma independiente,donde en realidad todas se verían afectadas por una distribución de base escasa,y estarían correlacionadas.</target>
        </trans-unit>
        <trans-unit id="508100893e29e053d40024965b139e71658b7b80" translate="yes" xml:space="preserve">
          <source>Percent of features to keep.</source>
          <target state="translated">El porcentaje de características que hay que mantener.</target>
        </trans-unit>
        <trans-unit id="510c90c1028713db83438ed3b7d7b97622c046bb" translate="yes" xml:space="preserve">
          <source>Percentage of the number of classes to be used to create the code book. A number between 0 and 1 will require fewer classifiers than one-vs-the-rest. A number greater than 1 will require more classifiers than one-vs-the-rest.</source>
          <target state="translated">Porcentaje del número de clases que se usarán para crear el libro de códigos.Un número entre 0 y 1 requerirá menos clasificadores que uno contra el resto.Un número mayor que 1 requerirá más clasificadores que uno contra el resto.</target>
        </trans-unit>
        <trans-unit id="ab474311418f716aa90a18ba4aac10d5e0126b01" translate="yes" xml:space="preserve">
          <source>Percentage of variance explained by each of the selected components.</source>
          <target state="translated">Porcentaje de variación explicado por cada uno de los componentes seleccionados.</target>
        </trans-unit>
        <trans-unit id="6b606c4b3521608268acaf8a83daf1d705edec66" translate="yes" xml:space="preserve">
          <source>Percentage of variance explained by each of the selected components. If &lt;code&gt;n_components&lt;/code&gt; is not set then all components are stored and the sum of explained variances is equal to 1.0. Only available when eigen or svd solver is used.</source>
          <target state="translated">Porcentaje de varianza explicada por cada uno de los componentes seleccionados. Si no se establece &lt;code&gt;n_components&lt;/code&gt; , todos los componentes se almacenan y la suma de las varianzas explicadas es igual a 1.0. Solo disponible cuando se utiliza eigen o svd solver.</target>
        </trans-unit>
        <trans-unit id="d93d3d6b53ae20e2e020e6bfd5f07bc4328ff552" translate="yes" xml:space="preserve">
          <source>Percentage of variance explained by each of the selected components. If all components are stored, the sum of explained variances is equal to 1.0.</source>
          <target state="translated">Porcentaje de variación explicado por cada uno de los componentes seleccionados.Si se almacenan todos los componentes,la suma de las desviaciones explicadas es igual a 1,0.</target>
        </trans-unit>
        <trans-unit id="b76d05a7855a1137343582656ace6f381d34c7bd" translate="yes" xml:space="preserve">
          <source>Perceptron: \(L(y_i, f(x_i)) = \max(0, - y_i f(x_i))\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ae537dc31ff6e276137ba1f3f08f14e2d75b135" translate="yes" xml:space="preserve">
          <source>Perfect labeling is scored 1.0:</source>
          <target state="translated">El etiquetado perfecto tiene una puntuación de 1.0:</target>
        </trans-unit>
        <trans-unit id="e0246cf8e59488c8ec6f2dd495c80e88ab5e2c38" translate="yes" xml:space="preserve">
          <source>Perfect labelings are both homogeneous and complete, hence have score 1.0:</source>
          <target state="translated">Las etiquetas perfectas son a la vez homogéneas y completas,por lo que tienen una puntuación de 1,0:</target>
        </trans-unit>
        <trans-unit id="0b6e6a15e84a2c0c2b67bd408293381d6bde8086" translate="yes" xml:space="preserve">
          <source>Perfect labelings are complete:</source>
          <target state="translated">Las etiquetas perfectas están completas:</target>
        </trans-unit>
        <trans-unit id="c929d898b15ba46b39cbe3a578cc048974dbb0f3" translate="yes" xml:space="preserve">
          <source>Perfect labelings are homogeneous:</source>
          <target state="translated">Las etiquetas perfectas son homogéneas:</target>
        </trans-unit>
        <trans-unit id="158762f0fcedf70ff27743eef2b9fe2391aaecf5" translate="yes" xml:space="preserve">
          <source>Perfectly matching labelings have a score of 1 even</source>
          <target state="translated">Las etiquetas que coinciden perfectamente tienen una puntuación de 1 incluso</target>
        </trans-unit>
        <trans-unit id="689d4751e15d0ca03ac4490cb60697622e5a7435" translate="yes" xml:space="preserve">
          <source>Perform Affinity Propagation Clustering of data</source>
          <target state="translated">Realizar la agrupación de la propagación de la afinidad de los datos</target>
        </trans-unit>
        <trans-unit id="dee861689c2a0a2296c4bb43119e58f854cfe756" translate="yes" xml:space="preserve">
          <source>Perform Affinity Propagation Clustering of data.</source>
          <target state="translated">Realizar la agrupación de datos de Propagación de Afinidad.</target>
        </trans-unit>
        <trans-unit id="5a1975729819b04264272cf944b37eeff6c54bb5" translate="yes" xml:space="preserve">
          <source>Perform DBSCAN clustering from features or distance matrix, and return cluster labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="463c2804b4b2c3d108889b17acd479af4436cc72" translate="yes" xml:space="preserve">
          <source>Perform DBSCAN clustering from features or distance matrix.</source>
          <target state="translated">Realizar el agrupamiento del DBSCAN a partir de características o matriz de distancia.</target>
        </trans-unit>
        <trans-unit id="b65b6612279cd3a62fed32683d01c69787a97da2" translate="yes" xml:space="preserve">
          <source>Perform DBSCAN clustering from features, or distance matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="458d7c0c2b90dff326f89ad767c75f6a1812b730" translate="yes" xml:space="preserve">
          <source>Perform DBSCAN clustering from vector array or distance matrix.</source>
          <target state="translated">Realizar el agrupamiento del DBSCAN desde una matriz de vectores o de distancia.</target>
        </trans-unit>
        <trans-unit id="959d910f7763a2ffdb63e2da58508fc0266c6120" translate="yes" xml:space="preserve">
          <source>Perform Fast Independent Component Analysis.</source>
          <target state="translated">Realizar un análisis rápido e independiente de los componentes.</target>
        </trans-unit>
        <trans-unit id="c424661559fd4111ae395a81a440da23c2d8b00f" translate="yes" xml:space="preserve">
          <source>Perform OPTICS clustering.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b44047366aaa6bbf25bda0720c2b9955136f4c83" translate="yes" xml:space="preserve">
          <source>Perform a Locally Linear Embedding analysis on the data.</source>
          <target state="translated">Realice un análisis de incrustación local lineal de los datos.</target>
        </trans-unit>
        <trans-unit id="ac1255795fd03e9f556426224dcbfbd70ca25e88" translate="yes" xml:space="preserve">
          <source>Perform a shortest-path graph search on a positive directed or undirected graph.</source>
          <target state="translated">Realizar una búsqueda de gráfico más corta en un gráfico positivo dirigido o no dirigido.</target>
        </trans-unit>
        <trans-unit id="5913acb65bcb3cfc0407c274e6a0ae6c08f54988" translate="yes" xml:space="preserve">
          <source>Perform binary classification using non-linear SVC with RBF kernel. The target to predict is a XOR of the inputs.</source>
          <target state="translated">Realizar la clasificación binaria usando SVC no lineal con el núcleo RBF.El objetivo a predecir es un XOR de las entradas.</target>
        </trans-unit>
        <trans-unit id="a259ca5c38306ae844a312467fcf634f7a4c4cb8" translate="yes" xml:space="preserve">
          <source>Perform classification on an array of test vectors X.</source>
          <target state="translated">Realizar la clasificación en un conjunto de vectores de prueba X.</target>
        </trans-unit>
        <trans-unit id="1af0f015c949bd1c16d805fdf5523bbcd5119678" translate="yes" xml:space="preserve">
          <source>Perform classification on samples in X.</source>
          <target state="translated">Realizar la clasificación de las muestras en X.</target>
        </trans-unit>
        <trans-unit id="b3b3f491b55f8b579a228793b65f99ca8d0d1a92" translate="yes" xml:space="preserve">
          <source>Perform classification on test vectors X.</source>
          <target state="translated">Realizar la clasificación en los vectores de prueba X.</target>
        </trans-unit>
        <trans-unit id="2cc5f65a2c2c90fbeebd06f8fc6c4b4510abcc97" translate="yes" xml:space="preserve">
          <source>Perform clustering on X and returns cluster labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db94ca6613eef6e933177aeabe20672ae9208bdf" translate="yes" xml:space="preserve">
          <source>Perform clustering.</source>
          <target state="translated">Realizar la agrupación.</target>
        </trans-unit>
        <trans-unit id="f9f7c30d76f5b933404ebf4eb86819fed33be90a" translate="yes" xml:space="preserve">
          <source>Perform dimensionality reduction on X.</source>
          <target state="translated">Realizar la reducción de la dimensionalidad en X.</target>
        </trans-unit>
        <trans-unit id="ea3d4bd6b3c1842187bced8b218fbec04eb7bd42" translate="yes" xml:space="preserve">
          <source>Perform fit on X and returns labels for X.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d24d9dcbe2141c7b30ceff371628950cd7ca425" translate="yes" xml:space="preserve">
          <source>Perform is_fitted validation for estimator.</source>
          <target state="translated">Realizar la validación de is_fitted para el estimador.</target>
        </trans-unit>
        <trans-unit id="28c6ac8c77fceae308f63cb91c2fe135b4f5904f" translate="yes" xml:space="preserve">
          <source>Perform mapping to a normal distribution using a power transform.</source>
          <target state="translated">Realizar el mapeo a una distribución normal usando un transformador de energía.</target>
        </trans-unit>
        <trans-unit id="f154e55e13cfe215c964ae2fb4c3f06da46b83fe" translate="yes" xml:space="preserve">
          <source>Perform mean shift clustering of data using a flat kernel.</source>
          <target state="translated">Realizar el agrupamiento de los datos de los cambios medios usando un núcleo plano.</target>
        </trans-unit>
        <trans-unit id="5d74999037a10ebb61d14a38ac3c1f58c8d3eb1c" translate="yes" xml:space="preserve">
          <source>Perform one Gibbs sampling step.</source>
          <target state="translated">Realiza un paso de muestreo de Gibbs.</target>
        </trans-unit>
        <trans-unit id="a608c191f0cb8597865dd893c202fb7da2ab975c" translate="yes" xml:space="preserve">
          <source>Perform one epoch of stochastic gradient descent on given samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b97c414705aa3f4f9199ddb08da830ac54e8fe97" translate="yes" xml:space="preserve">
          <source>Perform regression on samples in X.</source>
          <target state="translated">Realiza una regresión en las muestras en X.</target>
        </trans-unit>
        <trans-unit id="dd51e0250263d470cb8a4effc410185e24e99d6f" translate="yes" xml:space="preserve">
          <source>Perform robust standardization that removes the influence of outliers but does not put outliers and inliers on the same scale.</source>
          <target state="translated">Realizar una normalización sólida que elimine la influencia de los valores atípicos pero que no ponga en la misma escala los valores atípicos y los valores atípicos.</target>
        </trans-unit>
        <trans-unit id="1506956d6558b19c7df6e1dc69b0a99dea667d55" translate="yes" xml:space="preserve">
          <source>Perform spectral clustering from features, or affinity matrix, and return cluster labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="557e6799397c88d4bc14664b365f9609412e8548" translate="yes" xml:space="preserve">
          <source>Perform spectral clustering from features, or affinity matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebef79dfac2e65b8c25ad9bb7fdce83cd9513504" translate="yes" xml:space="preserve">
          <source>Perform standardization by centering and scaling</source>
          <target state="translated">Realizar la normalización centrando y escalando</target>
        </trans-unit>
        <trans-unit id="4bc7fa7479a101fbc87b729f92b16086a341ed9e" translate="yes" xml:space="preserve">
          <source>Perform standardization that is faster, but less robust to outliers.</source>
          <target state="translated">Realizar una estandarización que sea más rápida,pero menos robusta a los valores atípicos.</target>
        </trans-unit>
        <trans-unit id="3c9e3951bcb75f5ea77167c7144b5b5a81bd6690" translate="yes" xml:space="preserve">
          <source>Performs DBSCAN extraction for an arbitrary epsilon.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b688f62a3ad12b1d7c84b19ede9050b44271064d" translate="yes" xml:space="preserve">
          <source>Performs a one-hot encoding of categorical features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d75208cdd518398a274b5c66a99a07cd1c4674d" translate="yes" xml:space="preserve">
          <source>Performs a one-hot encoding of dictionary items (also handles string-valued features).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8a1451466ddb25587dffc5d4da05875ebb74725" translate="yes" xml:space="preserve">
          <source>Performs a pixel-wise Vector Quantization (VQ) of an image of the summer palace (China), reducing the number of colors required to show the image from 96,615 unique colors to 64, while preserving the overall appearance quality.</source>
          <target state="translated">Realiza una cuantificación vectorial por píxeles (VQ)de una imagen del palacio de verano (China),reduciendo el número de colores necesarios para mostrar la imagen de 96.615 colores únicos a 64,preservando la calidad de la apariencia general.</target>
        </trans-unit>
        <trans-unit id="b9ac5dd9fc2e45481e3dd5c8a6199a86e1da0656" translate="yes" xml:space="preserve">
          <source>Performs an approximate one-hot encoding of dictionary items or strings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d01f1a997cf8a75714d83a10021fc81a3a7d1f94" translate="yes" xml:space="preserve">
          <source>Performs an ordinal (integer) encoding of the categorical features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7945877a79ee9606b9df91e80330316ac1099e28" translate="yes" xml:space="preserve">
          <source>Performs approximate nearest neighbor search using LSH forest.</source>
          <target state="translated">Realiza una búsqueda aproximada del vecino más cercano utilizando el bosque LSH.</target>
        </trans-unit>
        <trans-unit id="9bab7093aa44c52b527bcacee82e15ab827f7949" translate="yes" xml:space="preserve">
          <source>Performs binarization using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">Realiza binarizaci&amp;oacute;n utilizando la API de &lt;code&gt;Transformer&lt;/code&gt; (por ejemplo, como parte de un &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="9334db1899f0bba94453f1ee6fbd171b507e5ed1" translate="yes" xml:space="preserve">
          <source>Performs centering and scaling using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">Realiza el centrado y el escalado utilizando la API de &lt;code&gt;Transformer&lt;/code&gt; (por ejemplo, como parte de un &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; de&lt;/a&gt; preprocesamiento ).</target>
        </trans-unit>
        <trans-unit id="506256c7ae18c8053ecaa6445590a98acf36aa0e" translate="yes" xml:space="preserve">
          <source>Performs clustering on X and returns cluster labels.</source>
          <target state="translated">Realiza la agrupación en X y devuelve las etiquetas de agrupación.</target>
        </trans-unit>
        <trans-unit id="38545772bd4529f41bf4bec322ebc7f80ab61f41" translate="yes" xml:space="preserve">
          <source>Performs inductive inference across the model.</source>
          <target state="translated">Realiza una inferencia inductiva a través del modelo.</target>
        </trans-unit>
        <trans-unit id="de7dc9fb5a771d54ea7fadc4d86dd2f8269f14e4" translate="yes" xml:space="preserve">
          <source>Performs normalization using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">Realiza la normalizaci&amp;oacute;n utilizando la API de &lt;code&gt;Transformer&lt;/code&gt; (por ejemplo, como parte de un &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="72f57dd0021b24f09da3fde633d42235df9baa52" translate="yes" xml:space="preserve">
          <source>Performs outlier detection on X.</source>
          <target state="translated">Realiza una detección de valores atípicos en X.</target>
        </trans-unit>
        <trans-unit id="c032681b9d32a5a7daa554f673be122edd3ede2b" translate="yes" xml:space="preserve">
          <source>Performs power transformation using the &lt;code&gt;Transformer&lt;/code&gt; API (as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">Realiza la transformaci&amp;oacute;n de energ&amp;iacute;a mediante la API de &lt;code&gt;Transformer&lt;/code&gt; (como parte de un &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; de&lt;/a&gt; preprocesamiento ).</target>
        </trans-unit>
        <trans-unit id="9b0d235575d753630f72f479dd595fb051616b74" translate="yes" xml:space="preserve">
          <source>Performs quantile-based scaling using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">Realiza un escalado basado en cuantiles utilizando la API de &lt;code&gt;Transformer&lt;/code&gt; (por ejemplo, como parte de un preprocesamiento &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="b88ebf81bb1a4e07e575709aa3160fcbaf33439c" translate="yes" xml:space="preserve">
          <source>Performs robust standardization that removes the influence of outliers but does not put outliers and inliers on the same scale.</source>
          <target state="translated">Lleva a cabo una sólida normalización que elimina la influencia de los valores atípicos pero no pone en la misma escala a los valores atípicos y a los valores atípicos.</target>
        </trans-unit>
        <trans-unit id="269796266e3e34d93d181d30bdc48e574f3c9af7" translate="yes" xml:space="preserve">
          <source>Performs scaling to a given range using the``Transformer`` API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">Realiza escalado a un rango dado usando la API de `` Transformador '' (por ejemplo, como parte de un preprocesamiento &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="bd68fa80cce73218da8c0d7af21a3e3a79fd9429" translate="yes" xml:space="preserve">
          <source>Performs scaling to the [-1, 1] range using the``Transformer`` API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">Realiza escalado al rango [-1, 1] usando la API de `` Transformador '' (por ejemplo, como parte de un preprocesamiento &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="a6c272533c048656769d2922baf310f99127bfa0" translate="yes" xml:space="preserve">
          <source>Performs scaling to unit variance using the``Transformer`` API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">Realiza el escalado a la variaci&amp;oacute;n de la unidad utilizando la API de `` Transformador '' (por ejemplo, como parte de un &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; de&lt;/a&gt; preprocesamiento ).</target>
        </trans-unit>
        <trans-unit id="ac7c14a68907c3e1c4fe02a23cc6348fd68ae158" translate="yes" xml:space="preserve">
          <source>Performs standardization that is faster, but less robust to outliers.</source>
          <target state="translated">Realiza una estandarización más rápida,pero menos robusta a los valores atípicos.</target>
        </trans-unit>
        <trans-unit id="1607c75c65b63f50e007f7f133bc5dda8dc230b2" translate="yes" xml:space="preserve">
          <source>Performs the TF-IDF transformation from a provided matrix of counts.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1ac21bb0cdcd78e01860cf682da905f50be135c" translate="yes" xml:space="preserve">
          <source>Performs well even if its assumptions are somewhat violated by the true model from which the data were generated.</source>
          <target state="translated">Funciona bien incluso si sus supuestos son violados de alguna manera por el verdadero modelo a partir del cual se generaron los datos.</target>
        </trans-unit>
        <trans-unit id="692363e79545ccc206eddd0f61af20f5fd6d3794" translate="yes" xml:space="preserve">
          <source>Permutation Importance vs Random Forest Feature Importance (MDI)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2dbaba5e5cc669da918a57d2be9cb7dc2cc9dadb" translate="yes" xml:space="preserve">
          <source>Permutation Importance with Multicollinear or Correlated Features</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a4bc8d95c0343a8677dd56e966704c1868adf4a" translate="yes" xml:space="preserve">
          <source>Permutation feature importance is a model inspection technique that can be used for any &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fitted&quot;&gt;fitted&lt;/a&gt;&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-estimator&quot;&gt;estimator&lt;/a&gt; when the data is tabular. This is especially useful for non-linear or opaque &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-estimators&quot;&gt;estimators&lt;/a&gt;. The permutation feature importance is defined to be the decrease in a model score when a single feature value is randomly shuffled &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;. This procedure breaks the relationship between the feature and the target, thus the drop in the model score is indicative of how much the model depends on the feature. This technique benefits from being model agnostic and can be calculated many times with different permutations of the feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3fc1a156ae6d2a8be8ad1b31632c3738303816a9" translate="yes" xml:space="preserve">
          <source>Permutation importance for feature evaluation &lt;a href=&quot;#rd9e56ef97513-bre&quot; id=&quot;id1&quot;&gt;[BRE]&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dcae56d3241bbe2509401411f131fd455126611a" translate="yes" xml:space="preserve">
          <source>Permutation importance for feature evaluation &lt;a href=&quot;generated/sklearn.inspection.permutation_importance#rd9e56ef97513-bre&quot; id=&quot;id2&quot;&gt;[Rd9e56ef97513-BRE]&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0604878bcce5e380bc3c27303af860b5876e2620" translate="yes" xml:space="preserve">
          <source>Permutation importances can be computed either on the training set or on a held-out testing or validation set. Using a held-out set makes it possible to highlight which features contribute the most to the generalization power of the inspected model. Features that are important on the training set but not on the held-out set might cause the model to overfit.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff7711423fb41bb0ca16132a11855fff8a63fa44" translate="yes" xml:space="preserve">
          <source>Permutation-based feature importance</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2babb881bd9df0cbbe32387aebb8f1fc14de7576" translate="yes" xml:space="preserve">
          <source>Permutation-based feature importances do not exhibit such a bias. Additionally, the permutation feature importance may be computed performance metric on the model predictions predictions and can be used to analyze any model class (not just tree-based models).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a9a31609b061b9c4c3ea5164d451f2cf664e34b" translate="yes" xml:space="preserve">
          <source>Perplexity is defined as exp(-1. * log-likelihood per word)</source>
          <target state="translated">La perplejidad se define como exp(-1.*log-probabilidad por palabra)</target>
        </trans-unit>
        <trans-unit id="80863d8aea17a1c5fba5bee33e10fcfe3c3b5254" translate="yes" xml:space="preserve">
          <source>Perplexity score.</source>
          <target state="translated">Puntuación de perplejidad.</target>
        </trans-unit>
        <trans-unit id="25e7450397b385690390d4cb490d54af7bb7f613" translate="yes" xml:space="preserve">
          <source>Perplexity tolerance in batch learning. Only used when &lt;code&gt;evaluate_every&lt;/code&gt; is greater than 0.</source>
          <target state="translated">Tolerancia a la perplejidad en el aprendizaje por lotes. Solo se usa cuando &lt;code&gt;evaluate_every&lt;/code&gt; es mayor que 0.</target>
        </trans-unit>
        <trans-unit id="bed69aed128c6d53c076bf23b1786ba34af67dfd" translate="yes" xml:space="preserve">
          <source>Persistent Contrastive Divergence addresses this. Instead of starting a new chain each time the gradient is needed, and performing only one Gibbs sampling step, in PCD we keep a number of chains (fantasy particles) that are updated \(k\) Gibbs steps after each weight update. This allows the particles to explore the space more thoroughly.</source>
          <target state="translated">La Divergencia Contrastante Persistente aborda esto.En lugar de iniciar una nueva cadena cada vez que se necesita el gradiente,y realizar sólo un paso de muestreo de Gibbs,en el PCD mantenemos una serie de cadenas (partículas de fantasía)que se actualizan \ ~ pasos de Gibbs después de cada actualización de peso.Esto permite que las partículas exploren el espacio más a fondo.</target>
        </trans-unit>
        <trans-unit id="d4d9d12e88278335e6c824e88af73f55a763004e" translate="yes" xml:space="preserve">
          <source>Peter J. Huber, Elvezio M. Ronchetti, Robust Statistics Concomitant scale estimates, pg 172</source>
          <target state="translated">Peter J.Huber,Helvetius M.Ronchetti,Robust Statistics Concomitant scale estimates,pg 172</target>
        </trans-unit>
        <trans-unit id="977cdb0f1102753846469a4e3ab78497c359fae5" translate="yes" xml:space="preserve">
          <source>Peter J. Huber, Elvezio M. Ronchetti: Robust Statistics, Concomitant scale estimates, pg 172</source>
          <target state="translated">Peter J.Huber,Helvetius M.Ronchetti:Robustas estadísticas,Estimaciones de escala concomitante,pg 172</target>
        </trans-unit>
        <trans-unit id="f869e193262fa2d8e1a9ddde0485aa49aaa656aa" translate="yes" xml:space="preserve">
          <source>Peter J. Rousseeuw (1987). &amp;ldquo;Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis&amp;rdquo;. Computational and Applied Mathematics 20: 53&amp;ndash;65. &lt;a href=&quot;https://doi.org/10.1016/0377-0427(87)90125-7&quot;&gt;doi:10.1016/0377-0427(87)90125-7&lt;/a&gt;.</source>
          <target state="translated">Peter J. Rousseeuw (1987). &amp;ldquo;Siluetas: una ayuda gr&amp;aacute;fica para la interpretaci&amp;oacute;n y validaci&amp;oacute;n del an&amp;aacute;lisis de conglomerados&amp;rdquo;. Matem&amp;aacute;ticas computacionales y aplicadas 20: 53&amp;ndash;65. &lt;a href=&quot;https://doi.org/10.1016/0377-0427(87)90125-7&quot;&gt;doi: 10.1016 / 0377-0427 (87) 90125-7&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="801ff1e5ba061302f2ef13b831a12ef30f616d52" translate="yes" xml:space="preserve">
          <source>Peter J. Rousseeuw (1987). &amp;ldquo;Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis&amp;rdquo;. Computational and Applied Mathematics 20: 53-65.</source>
          <target state="translated">Peter J. Rousseeuw (1987). &amp;ldquo;Siluetas: una ayuda gr&amp;aacute;fica para la interpretaci&amp;oacute;n y validaci&amp;oacute;n del an&amp;aacute;lisis de conglomerados&amp;rdquo;. Matem&amp;aacute;ticas Computacionales y Aplicadas 20: 53-65.</target>
        </trans-unit>
        <trans-unit id="6884db0930152b7581421b9e7df37cdc709bc0ae" translate="yes" xml:space="preserve">
          <source>Pickle and Unpickle a tree. Note that the state of the tree is saved in the pickle operation: the tree needs not be rebuilt upon unpickling.</source>
          <target state="translated">Encurtir y desenterrar un árbol.Tenga en cuenta que el estado del árbol se salva en la operación de encurtido:el árbol no necesita ser reconstruido al despincharlo.</target>
        </trans-unit>
        <trans-unit id="4a6d28315bc21af0edd71a7862fc9db5f7a4917f" translate="yes" xml:space="preserve">
          <source>Ping Li, T. Hastie and K. W. Church, 2006, &amp;ldquo;Very Sparse Random Projections&amp;rdquo;. &lt;a href=&quot;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&lt;/a&gt;</source>
          <target state="translated">Ping Li, T. Hastie y KW Church, 2006, &amp;ldquo;Proyecciones aleatorias muy dispersas&amp;rdquo;. &lt;a href=&quot;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="fb3d4adf8ec429eb640cc1eefb0227abf08a6683" translate="yes" xml:space="preserve">
          <source>Ping Li, T. Hastie and K. W. Church, 2006, &amp;ldquo;Very Sparse Random Projections&amp;rdquo;. &lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3462e562173cab76115a1fabd23d03498a615dda" translate="yes" xml:space="preserve">
          <source>Ping Li, Trevor J. Hastie, and Kenneth W. Church. 2006. &lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;Very sparse random projections.&lt;/a&gt; In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD &amp;lsquo;06). ACM, New York, NY, USA, 287-296.</source>
          <target state="translated">Ping Li, Trevor J. Hastie y Kenneth W. Church. 2006. &lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;Proyecciones aleatorias muy escasas. &lt;/a&gt;En Actas de la 12&amp;ordf; conferencia internacional ACM SIGKDD sobre descubrimiento de conocimiento y miner&amp;iacute;a de datos (KDD '06). ACM, Nueva York, NY, EE. UU., 287-296.</target>
        </trans-unit>
        <trans-unit id="32b1d5a78493496dd5152fd2d504f7e21009e3f2" translate="yes" xml:space="preserve">
          <source>Pipeline</source>
          <target state="translated">Pipeline</target>
        </trans-unit>
        <trans-unit id="5fcec2c4630ab50971732249756f691f50ae9f29" translate="yes" xml:space="preserve">
          <source>Pipeline Anova SVM</source>
          <target state="translated">Tubería Anova SVM</target>
        </trans-unit>
        <trans-unit id="a041187d94eb589a1ba5ff98293ef896e00c97e7" translate="yes" xml:space="preserve">
          <source>Pipeline of transforms with a final estimator.</source>
          <target state="translated">Tubería de transformaciones con un estimador final.</target>
        </trans-unit>
        <trans-unit id="b728ae3e883ea99a9d120fc06880b19e80fef86a" translate="yes" xml:space="preserve">
          <source>Pipeline&amp;rsquo;s &lt;code&gt;named_steps&lt;/code&gt; attribute allows accessing steps by name with tab completion in interactive environments:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73de4ddfaf9a511a59191faaa0679d43b9d9c3eb" translate="yes" xml:space="preserve">
          <source>Pipelines and composite estimators</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52761af283a0d9e614a4e2ba9d4a353d3fd70a7b" translate="yes" xml:space="preserve">
          <source>Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors.</source>
          <target state="translated">Las tuberías ayudan a evitar la fuga de estadísticas de sus datos de prueba al modelo entrenado en la validación cruzada,asegurando que las mismas muestras se utilicen para entrenar los transformadores y predictores.</target>
        </trans-unit>
        <trans-unit id="3d31223cfe1830200469a76812f595efba107474" translate="yes" xml:space="preserve">
          <source>Pipelining</source>
          <target state="translated">Pipelining</target>
        </trans-unit>
        <trans-unit id="04ae27026f61a0e2fe9396849cac7271f4f56e69" translate="yes" xml:space="preserve">
          <source>Pipelining: chaining a PCA and a logistic regression</source>
          <target state="translated">Encadenamiento:encadenamiento de un PCA y una regresión logística</target>
        </trans-unit>
        <trans-unit id="4d2bb7a399ca2f416aedb250a1c02b6dbddd98f5" translate="yes" xml:space="preserve">
          <source>Pixel importances with a parallel forest of trees</source>
          <target state="translated">Importancia de los píxeles con un bosque paralelo de árboles</target>
        </trans-unit>
        <trans-unit id="2ca4493c014c6673344a97eb7b5e5aaa17897b68" translate="yes" xml:space="preserve">
          <source>Platt &lt;a href=&quot;http://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf&quot;&gt;&amp;ldquo;Probabilistic outputs for SVMs and comparisons to regularized likelihood methods&amp;rdquo;&lt;/a&gt;.</source>
          <target state="translated">Platt &lt;a href=&quot;http://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf&quot;&gt;&amp;ldquo;Salidas probabil&amp;iacute;sticas para SVM y comparaciones con m&amp;eacute;todos de verosimilitud regularizados&amp;rdquo;&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="94b48515f27c2ba66dc001876eed954b37962189" translate="yes" xml:space="preserve">
          <source>Platt &lt;a href=&quot;https://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf&quot;&gt;&amp;ldquo;Probabilistic outputs for SVMs and comparisons to regularized likelihood methods&amp;rdquo;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cd3fc864a17260622e839224271f277841ca1af" translate="yes" xml:space="preserve">
          <source>Platt&amp;rsquo;s method is also known to have theoretical issues. If confidence scores are required, but these do not have to be probabilities, then it is advisable to set &lt;code&gt;probability=False&lt;/code&gt; and use &lt;code&gt;decision_function&lt;/code&gt; instead of &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
