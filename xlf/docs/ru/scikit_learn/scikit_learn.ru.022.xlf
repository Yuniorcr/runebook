<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ru" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="21ade7db23177cbafdee1241d820ab218814e247" translate="yes" xml:space="preserve">
          <source>There are two ways to specify multiple scoring metrics for the &lt;code&gt;scoring&lt;/code&gt; parameter:</source>
          <target state="translated">Есть два способа указать несколько показателей оценки для параметра &lt;code&gt;scoring&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="c9e248c64205afb9beabc74d09eccb0781bdceea" translate="yes" xml:space="preserve">
          <source>There exist several strategies to perform Bayesian ridge regression. This implementation is based on the algorithm described in Appendix A of (Tipping, 2001) where updates of the regularization parameters are done as suggested in (MacKay, 1992). Note that according to A New View of Automatic Relevance Determination (Wipf and Nagarajan, 2008) these update rules do not guarantee that the marginal likelihood is increasing between two consecutive iterations of the optimization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cdf4947857438b0c51097ba679415b8309e576f2" translate="yes" xml:space="preserve">
          <source>There exists two types of MDS algorithm: metric and non metric. In the scikit-learn, the class &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; implements both. In Metric MDS, the input similarity matrix arises from a metric (and thus respects the triangular inequality), the distances between output two points are then set to be as close as possible to the similarity or dissimilarity data. In the non-metric version, the algorithms will try to preserve the order of the distances, and hence seek for a monotonic relationship between the distances in the embedded space and the similarities/dissimilarities.</source>
          <target state="translated">Существует два типа алгоритма MDS: метрический и неметрический. В scikit-learn класс &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt; &lt;code&gt;MDS&lt;/code&gt; &lt;/a&gt; реализует оба. В Metric MDS входная матрица подобия возникает из метрики (и, таким образом, соблюдается треугольное неравенство), расстояния между выходными двумя точками затем устанавливаются как можно ближе к данным подобия или несходства. В неметрической версии алгоритмы будут пытаться сохранить порядок расстояний и, следовательно, искать монотонную связь между расстояниями во встроенном пространстве и сходствами / различиями.</target>
        </trans-unit>
        <trans-unit id="9e945ec56932f8495741411aac1ef0391f41ea70" translate="yes" xml:space="preserve">
          <source>There is absolutely no guarantee of recovering a ground truth. First, choosing the right number of clusters is hard. Second, the algorithm is sensitive to initialization, and can fall into local minima, although scikit-learn employs several tricks to mitigate this issue.</source>
          <target state="translated">Нет абсолютно никаких гарантий восстановления истины на земле.Во-первых,выбрать нужное количество кластеров очень сложно.Во-вторых,алгоритм чувствителен к инициализации и может попасть в локальные минимумы,хотя в Scikit-learn используется несколько ухищрений,чтобы смягчить эту проблему.</target>
        </trans-unit>
        <trans-unit id="a5fa0b690cccf03ea1d32deadc1c15c3039ee96d" translate="yes" xml:space="preserve">
          <source>There is built-in support for sparse data given in any matrix in a format supported by &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;scipy.sparse&lt;/a&gt;. For maximum efficiency, however, use the CSR matrix format as defined in &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html&quot;&gt;scipy.sparse.csr_matrix&lt;/a&gt;.</source>
          <target state="translated">Имеется встроенная поддержка разреженных данных, представленных в любой матрице в формате, поддерживаемом &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;scipy.sparse&lt;/a&gt; . Однако для максимальной эффективности используйте формат матрицы CSR, как определено в &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html&quot;&gt;scipy.sparse.csr_matrix&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="46a0af0f073c85f45d179011b96dd0c21ed6963a" translate="yes" xml:space="preserve">
          <source>There is built-in support for sparse data given in any matrix in a format supported by &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;scipy.sparse&lt;/a&gt;. For maximum efficiency, however, use the CSR matrix format as defined in &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html&quot;&gt;scipy.sparse.csr_matrix&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bf90eed7a42877d9e674dd4cae64f5ef3af07a9" translate="yes" xml:space="preserve">
          <source>There is no general rule to select an alpha parameter for recovery of non-zero coefficients. It can by set by cross-validation (&lt;code&gt;LassoCV&lt;/code&gt; or &lt;code&gt;LassoLarsCV&lt;/code&gt;), though this may lead to under-penalized models: including a small number of non-relevant variables is not detrimental to prediction score. BIC (&lt;code&gt;LassoLarsIC&lt;/code&gt;) tends, on the opposite, to set high values of alpha.</source>
          <target state="translated">Не существует общего правила выбора альфа-параметра для восстановления ненулевых коэффициентов. Его можно установить с помощью перекрестной проверки ( &lt;code&gt;LassoCV&lt;/code&gt; или &lt;code&gt;LassoLarsCV&lt;/code&gt; ), хотя это может привести к модели с недостаточными штрафами : включение небольшого количества нерелевантных переменных не повлияет на оценку прогноза. BIC ( &lt;code&gt;LassoLarsIC&lt;/code&gt; ), напротив, имеет тенденцию устанавливать высокие значения альфа.</target>
        </trans-unit>
        <trans-unit id="ff0ab54a4c7a8a1cf35484dbae4d9dce95d5c026" translate="yes" xml:space="preserve">
          <source>There might be a difference in the scores obtained between &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;solver=liblinear&lt;/code&gt; or &lt;code&gt;LinearSVC&lt;/code&gt; and the external liblinear library directly, when &lt;code&gt;fit_intercept=False&lt;/code&gt; and the fit &lt;code&gt;coef_&lt;/code&gt; (or) the data to be predicted are zeroes. This is because for the sample(s) with &lt;code&gt;decision_function&lt;/code&gt; zero, &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; and &lt;code&gt;LinearSVC&lt;/code&gt; predict the negative class, while liblinear predicts the positive class. Note that a model with &lt;code&gt;fit_intercept=False&lt;/code&gt; and having many samples with &lt;code&gt;decision_function&lt;/code&gt; zero, is likely to be a underfit, bad model and you are advised to set &lt;code&gt;fit_intercept=True&lt;/code&gt; and increase the intercept_scaling.</source>
          <target state="translated">Может быть разница в оценках, полученных между &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt; с &lt;code&gt;solver=liblinear&lt;/code&gt; или &lt;code&gt;LinearSVC&lt;/code&gt; и напрямую внешней liblinear библиотекой, когда &lt;code&gt;fit_intercept=False&lt;/code&gt; и подходящие &lt;code&gt;coef_&lt;/code&gt; (или) данные, которые должны быть предсказаны, равны нулю. Это связано с тем, что для образца (ов) с нулевой &lt;code&gt;LinearSVC&lt;/code&gt; &lt;code&gt;decision_function&lt;/code&gt; &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt; и LinearSVC предсказывают отрицательный класс, а liblinear предсказывают положительный класс. Обратите внимание , что модель с &lt;code&gt;fit_intercept=False&lt;/code&gt; и имеющим множество образцов с &lt;code&gt;decision_function&lt;/code&gt; нуля, скорее всего, будет underfit, плохая модель и вам рекомендуется набор &lt;code&gt;fit_intercept=True&lt;/code&gt; и увеличьте intercept_scaling.</target>
        </trans-unit>
        <trans-unit id="4a4216d2986ca1c413a45927f7f8dc07ca811204" translate="yes" xml:space="preserve">
          <source>Therefore, a logarithmic (&lt;code&gt;np.log1p&lt;/code&gt;) and an exponential function (&lt;code&gt;np.expm1&lt;/code&gt;) will be used to transform the targets before training a linear regression model and using it for prediction.</source>
          <target state="translated">Следовательно, логарифмическая ( &lt;code&gt;np.log1p&lt;/code&gt; ) и экспоненциальная функции ( &lt;code&gt;np.expm1&lt;/code&gt; ) будут использоваться для преобразования целей перед обучением модели линейной регрессии и использованием ее для прогнозирования.</target>
        </trans-unit>
        <trans-unit id="6912f2dbecf0d873a7ad1021b00fc015a0232427" translate="yes" xml:space="preserve">
          <source>These are transformers that are not intended to be used on features, only on supervised learning targets. See also &lt;a href=&quot;compose#transformed-target-regressor&quot;&gt;Transforming target in regression&lt;/a&gt; if you want to transform the prediction target for learning, but evaluate the model in the original (untransformed) space.</source>
          <target state="translated">Это преобразователи, которые не предназначены для использования в функциях, а только для контролируемых целей обучения. См. Также &lt;a href=&quot;compose#transformed-target-regressor&quot;&gt;Преобразование цели в регрессии,&lt;/a&gt; если вы хотите преобразовать цель прогнозирования для обучения, но оценить модель в исходном (непреобразованном) пространстве.</target>
        </trans-unit>
        <trans-unit id="9c615abfdf912d61f49e70314e0bacb6d3789d48" translate="yes" xml:space="preserve">
          <source>These classifiers are attractive because they have closed-form solutions that can be easily computed, are inherently multiclass, have proven to work well in practice, and have no hyperparameters to tune.</source>
          <target state="translated">Эти классификаторы привлекательны тем,что имеют закрытые формы,которые легко вычисляются,являются по своей сути многоклассовыми,хорошо зарекомендовали себя на практике и не имеют гиперпараметров,которые можно настроить.</target>
        </trans-unit>
        <trans-unit id="fde55c65b8197fd0cbaa58300d107768af9ed389" translate="yes" xml:space="preserve">
          <source>These constraint are useful to impose a certain local structure, but they also make the algorithm faster, especially when the number of the samples is high.</source>
          <target state="translated">Эти ограничения полезны для наложения определенной локальной структуры,но они также делают алгоритм более быстрым,особенно при большом количестве отсчетов.</target>
        </trans-unit>
        <trans-unit id="ebd210a6b7ae21f6cafc3c41203edaaa46e25728" translate="yes" xml:space="preserve">
          <source>These datasets are useful to quickly illustrate the behavior of the various algorithms implemented in scikit-learn. They are however often too small to be representative of real world machine learning tasks.</source>
          <target state="translated">Эти наборы данных полезны для быстрой иллюстрации поведения различных алгоритмов,реализованных в Scikit-learn.Однако часто они слишком малы,чтобы быть репрезентативными для реальных задач машинного обучения.</target>
        </trans-unit>
        <trans-unit id="8d2ab26191aa60fb366e6a03a6fce9c7d01208ba" translate="yes" xml:space="preserve">
          <source>These environment variables should be set before importing scikit-learn.</source>
          <target state="translated">Эти переменные окружения должны быть установлены перед импортом scikit-learn.</target>
        </trans-unit>
        <trans-unit id="b821932825baa77bb11f8b1f95c8cc38b1d75bf5" translate="yes" xml:space="preserve">
          <source>These estimators are called similarly to their counterparts, with &amp;lsquo;CV&amp;rsquo; appended to their name.</source>
          <target state="translated">Эти оценщики называются так же, как и их аналоги, с добавлением &amp;laquo;CV&amp;raquo; к их имени.</target>
        </trans-unit>
        <trans-unit id="4895efc31f112ba17d5e8de5c88b9b84cbaac29a" translate="yes" xml:space="preserve">
          <source>These estimators are described in more detail below in &lt;a href=&quot;#histogram-based-gradient-boosting&quot;&gt;Histogram-Based Gradient Boosting&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31d7d129bfc794bb111166051ddf1fbfd1e21090" translate="yes" xml:space="preserve">
          <source>These estimators are still &lt;strong&gt;experimental&lt;/strong&gt;: their predictions and their API might change without any deprecation cycle. To use them, you need to explicitly import &lt;code&gt;enable_hist_gradient_boosting&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd57beb09d61462992a46fc07ecdff56e4d9c660" translate="yes" xml:space="preserve">
          <source>These estimators fit multiple regression problems (or tasks) jointly, while inducing sparse coefficients. While the inferred coefficients may differ between the tasks, they are constrained to agree on the features that are selected (non-zero coefficients).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fac22fa1718df2cc93fd78246f559caa4e598cf3" translate="yes" xml:space="preserve">
          <source>These examples illustrate the main features of the releases of scikit-learn.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8bef6d4f1ba3e716c219b98d63998eb428a7438d" translate="yes" xml:space="preserve">
          <source>These families of algorithms are useful to find linear relations between two multivariate datasets: the &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;Y&lt;/code&gt; arguments of the &lt;code&gt;fit&lt;/code&gt; method are 2D arrays.</source>
          <target state="translated">Эти семейства алгоритмов полезны для поиска линейных отношений между двумя многомерными наборами данных: аргументы &lt;code&gt;X&lt;/code&gt; и &lt;code&gt;Y&lt;/code&gt; метода &lt;code&gt;fit&lt;/code&gt; представляют собой 2D-массивы.</target>
        </trans-unit>
        <trans-unit id="1f2f0c6c7df23095dba3fa00aa5227521de2ff47" translate="yes" xml:space="preserve">
          <source>These fast estimators first bin the input samples &lt;code&gt;X&lt;/code&gt; into integer-valued bins (typically 256 bins) which tremendously reduces the number of splitting points to consider, and allows the algorithm to leverage integer-based data structures (histograms) instead of relying on sorted continuous values when building the trees. The API of these estimators is slightly different, and some of the features from &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; are not yet supported, for instance some loss functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e90c7c20b495d718d6ee1761b52661a07d31f2ac" translate="yes" xml:space="preserve">
          <source>These figures aid in illustrating how a point cloud can be very flat in one direction&amp;ndash;which is where PCA comes in to choose a direction that is not flat.</source>
          <target state="translated">Эти рисунки помогают проиллюстрировать, как облако точек может быть очень плоским в одном направлении - именно здесь PCA помогает выбрать направление, которое не является плоским.</target>
        </trans-unit>
        <trans-unit id="5b3c06102d71e9aa21ce3635f214fb7544bfe93e" translate="yes" xml:space="preserve">
          <source>These functions have an &lt;code&gt;multioutput&lt;/code&gt; keyword argument which specifies the way the scores or losses for each individual target should be averaged. The default is &lt;code&gt;'uniform_average'&lt;/code&gt;, which specifies a uniformly weighted mean over outputs. If an &lt;code&gt;ndarray&lt;/code&gt; of shape &lt;code&gt;(n_outputs,)&lt;/code&gt; is passed, then its entries are interpreted as weights and an according weighted average is returned. If &lt;code&gt;multioutput&lt;/code&gt; is &lt;code&gt;'raw_values'&lt;/code&gt; is specified, then all unaltered individual scores or losses will be returned in an array of shape &lt;code&gt;(n_outputs,)&lt;/code&gt;.</source>
          <target state="translated">У этих функций есть &lt;code&gt;multioutput&lt;/code&gt; ключевого слова multioutput, который определяет способ усреднения оценок или потерь для каждой отдельной цели. Значение по умолчанию - &lt;code&gt;'uniform_average'&lt;/code&gt; , которое определяет равномерно взвешенное среднее по выходным данным . Если &lt;code&gt;ndarray&lt;/code&gt; формы &lt;code&gt;(n_outputs,)&lt;/code&gt; , то его записи интерпретируются как веса, и возвращается соответствующее средневзвешенное значение. Если &lt;code&gt;multioutput&lt;/code&gt; является &lt;code&gt;'raw_values'&lt;/code&gt; указан, то все неизменные индивидуальные баллы или потери будут возвращены в массиве формы &lt;code&gt;(n_outputs,)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8f744234c4fef479ca52103694dddbbb39569d67" translate="yes" xml:space="preserve">
          <source>These functions return a tuple &lt;code&gt;(X, y)&lt;/code&gt; consisting of a &lt;code&gt;n_samples&lt;/code&gt; * &lt;code&gt;n_features&lt;/code&gt; numpy array &lt;code&gt;X&lt;/code&gt; and an array of length &lt;code&gt;n_samples&lt;/code&gt; containing the targets &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">Эти функции возвращают кортеж &lt;code&gt;(X, y)&lt;/code&gt; состоящий из &lt;code&gt;n_samples&lt;/code&gt; * &lt;code&gt;n_features&lt;/code&gt; numpy-массива &lt;code&gt;X&lt;/code&gt; и массива длиной &lt;code&gt;n_samples&lt;/code&gt; , содержащего цели &lt;code&gt;y&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7ea4b087a47ece8eb67eda1c13d069b3e5f40d70" translate="yes" xml:space="preserve">
          <source>These generators produce a matrix of features and corresponding discrete targets.</source>
          <target state="translated">Эти генераторы создают матрицу характеристик и соответствующих дискретных целей.</target>
        </trans-unit>
        <trans-unit id="ff830f502c3a30a0f4f3f842eff62f7849f20cad" translate="yes" xml:space="preserve">
          <source>These histogram-based estimators can be &lt;strong&gt;orders of magnitude faster&lt;/strong&gt; than &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; when the number of samples is larger than tens of thousands of samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7870342f67a34d74383fe781d3e91593569275ef" translate="yes" xml:space="preserve">
          <source>These images how similar features are merged together using feature agglomeration.</source>
          <target state="translated">Эти изображения,как похожие функции объединяются с помощью агломерации функций.</target>
        </trans-unit>
        <trans-unit id="2f6550a6d877a222d311c7f7d2e4efbab68b15f3" translate="yes" xml:space="preserve">
          <source>These matrices can be used to impose connectivity in estimators that use connectivity information, such as Ward clustering (&lt;a href=&quot;clustering#hierarchical-clustering&quot;&gt;Hierarchical clustering&lt;/a&gt;), but also to build precomputed kernels, or similarity matrices.</source>
          <target state="translated">Эти матрицы могут использоваться для наложения связности в оценщиках, которые используют информацию о связности, например кластеризацию Уорда ( &lt;a href=&quot;clustering#hierarchical-clustering&quot;&gt;иерархическая кластеризация&lt;/a&gt; ), а также для построения предварительно вычисленных ядер или матриц сходства.</target>
        </trans-unit>
        <trans-unit id="f1476efa19922a5a7b34be362fc1e06a3ae81118" translate="yes" xml:space="preserve">
          <source>These metrics &lt;strong&gt;require the knowledge of the ground truth classes&lt;/strong&gt; while almost never available in practice or requires manual assignment by human annotators (as in the supervised learning setting).</source>
          <target state="translated">Эти метрики &lt;strong&gt;требуют знания основных классов истинности,&lt;/strong&gt; хотя практически никогда не доступны на практике или требуют ручного назначения аннотаторами (как в условиях контролируемого обучения).</target>
        </trans-unit>
        <trans-unit id="102278a50cfd01c3d7a2cbdc18b76a5ce6b39772" translate="yes" xml:space="preserve">
          <source>These models allow for response variables to have error distributions other than a normal distribution:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b78634dcd7b938ef7f64bb3d2756751845f06a1" translate="yes" xml:space="preserve">
          <source>These objects take as input a scoring function that returns univariate scores and p-values (or only scores for &lt;a href=&quot;generated/sklearn.feature_selection.selectkbest#sklearn.feature_selection.SelectKBest&quot;&gt;&lt;code&gt;SelectKBest&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.feature_selection.selectpercentile#sklearn.feature_selection.SelectPercentile&quot;&gt;&lt;code&gt;SelectPercentile&lt;/code&gt;&lt;/a&gt;):</source>
          <target state="translated">Эти объекты принимают в качестве входных данных функцию оценки, которая возвращает одномерные оценки и p-значения (или только оценки для &lt;a href=&quot;generated/sklearn.feature_selection.selectkbest#sklearn.feature_selection.SelectKBest&quot;&gt; &lt;code&gt;SelectKBest&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.feature_selection.selectpercentile#sklearn.feature_selection.SelectPercentile&quot;&gt; &lt;code&gt;SelectPercentile&lt;/code&gt; &lt;/a&gt; ):</target>
        </trans-unit>
        <trans-unit id="7d570e698357345b9d25fb0f909251adbc540e40" translate="yes" xml:space="preserve">
          <source>These parameters can be accessed through the attributes &lt;code&gt;dual_coef_&lt;/code&gt; which holds the difference \(\alpha_i - \alpha_i^*\), &lt;code&gt;support_vectors_&lt;/code&gt; which holds the support vectors, and &lt;code&gt;intercept_&lt;/code&gt; which holds the independent term \(b\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc9887aaf0c2ed20eb0f603451b50a8d7e26af7c" translate="yes" xml:space="preserve">
          <source>These parameters can be accessed through the attributes &lt;code&gt;dual_coef_&lt;/code&gt; which holds the product \(y_i \alpha_i\), &lt;code&gt;support_vectors_&lt;/code&gt; which holds the support vectors, and &lt;code&gt;intercept_&lt;/code&gt; which holds the independent term \(b\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3403571e1d1dd77b054e08b8e749a4d9b5c4d316" translate="yes" xml:space="preserve">
          <source>These parameters can be accessed through the members &lt;code&gt;dual_coef_&lt;/code&gt; which holds the difference \(\alpha_i - \alpha_i^*\), &lt;code&gt;support_vectors_&lt;/code&gt; which holds the support vectors, and &lt;code&gt;intercept_&lt;/code&gt; which holds the independent term \(\rho\)</source>
          <target state="translated">К этим параметрам можно получить доступ через члены &lt;code&gt;dual_coef_&lt;/code&gt; , который содержит разницу \ (\ alpha_i - \ alpha_i ^ * \), &lt;code&gt;support_vectors_&lt;/code&gt; , который содержит опорные векторы, и &lt;code&gt;intercept_&lt;/code&gt; , который содержит независимый член \ (\ rho \)</target>
        </trans-unit>
        <trans-unit id="9254aef96f1c8727db185406da2727e74822dda9" translate="yes" xml:space="preserve">
          <source>These quantities are also related to the (\(F_1\)) score, which is defined as the harmonic mean of precision and recall.</source>
          <target state="translated">Эти количества также связаны с (\(F_1\))оценкой,которая определяется как гармоническое среднее значение точности и памяти.</target>
        </trans-unit>
        <trans-unit id="8ec6209edcb97e57d934d74900289c4f7467ca16" translate="yes" xml:space="preserve">
          <source>These represent the 14 features measured at each point of the map grid. The latitude/longitude values for the grid are discussed below. Missing data is represented by the value -9999.</source>
          <target state="translated">Они представляют собой 14 объектов,измеренных в каждой точке сетки карты.Значения широты/долготы для сетки рассмотрены ниже.Пропущенные данные представлены значением -9999.</target>
        </trans-unit>
        <trans-unit id="e11ef00d62661e429b4b798a345a9c8d62a348e6" translate="yes" xml:space="preserve">
          <source>These steps are performed either a maximum number of times (&lt;code&gt;max_trials&lt;/code&gt;) or until one of the special stop criteria are met (see &lt;code&gt;stop_n_inliers&lt;/code&gt; and &lt;code&gt;stop_score&lt;/code&gt;). The final model is estimated using all inlier samples (consensus set) of the previously determined best model.</source>
          <target state="translated">Эти шаги выполняются либо максимальное количество раз ( &lt;code&gt;max_trials&lt;/code&gt; ), либо до тех пор, пока не будет соблюден один из специальных критериев остановки (см. &lt;code&gt;stop_n_inliers&lt;/code&gt; и &lt;code&gt;stop_score&lt;/code&gt; ). Окончательная модель оценивается с использованием всех промежуточных выборок (консенсусного набора) ранее определенной лучшей модели.</target>
        </trans-unit>
        <trans-unit id="ffccb4ceb37928160a8178b1e93c390573c106cb" translate="yes" xml:space="preserve">
          <source>These three distances are special cases of the beta-divergence family, with \(\beta = 2, 1, 0\) respectively &lt;a href=&quot;#id15&quot; id=&quot;id8&quot;&gt;6&lt;/a&gt;. The beta-divergence are defined by :</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eff89650d9905b662c6df80228e926f2f144c91b" translate="yes" xml:space="preserve">
          <source>These three distances are special cases of the beta-divergence family, with \(\beta = 2, 1, 0\) respectively &lt;a href=&quot;#id15&quot; id=&quot;id8&quot;&gt;[6]&lt;/a&gt;. The beta-divergence are defined by :</source>
          <target state="translated">Эти три расстояния являются частными случаями семейства бета-расходимостей с \ (\ beta = 2, 1, 0 \) соответственно &lt;a href=&quot;#id15&quot; id=&quot;id8&quot;&gt;[6]&lt;/a&gt; . Бета-дивергенция определяется:</target>
        </trans-unit>
        <trans-unit id="100dafc268c3e9d0b628da1715aed2440b14ba32" translate="yes" xml:space="preserve">
          <source>These throughputs are achieved on a single process. An obvious way to increase the throughput of your application is to spawn additional instances (usually processes in Python because of the &lt;a href=&quot;https://wiki.python.org/moin/GlobalInterpreterLock&quot;&gt;GIL&lt;/a&gt;) that share the same model. One might also add machines to spread the load. A detailed explanation on how to achieve this is beyond the scope of this documentation though.</source>
          <target state="translated">Эти показатели достигаются за один процесс. Очевидный способ увеличить пропускную способность вашего приложения - создать дополнительные экземпляры (обычно процессы в Python из-за &lt;a href=&quot;https://wiki.python.org/moin/GlobalInterpreterLock&quot;&gt;GIL&lt;/a&gt; ), которые используют одну и ту же модель. Можно также добавить машины для распределения нагрузки. Однако подробное объяснение того, как этого добиться, выходит за рамки данной документации.</target>
        </trans-unit>
        <trans-unit id="b826ad64b72daa0458c9fdfb2862fce60b4db70b" translate="yes" xml:space="preserve">
          <source>They also have built-in support for missing values, which avoids the need for an imputer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e63971597c4df5f2dc150f90b566e1219b6a632a" translate="yes" xml:space="preserve">
          <source>They are not sparse, i.e., they use the whole samples/features information to perform the prediction.</source>
          <target state="translated">Они не являются разрозненными,т.е.используют всю информацию об образцах/функциях для выполнения прогноза.</target>
        </trans-unit>
        <trans-unit id="26f84bd6fe103542912ebb1fb588d29515a2fd6d" translate="yes" xml:space="preserve">
          <source>They can be loaded using the following functions:</source>
          <target state="translated">Они могут быть загружены с помощью следующих функций:</target>
        </trans-unit>
        <trans-unit id="f7ddbd9f45ee3f137b5eb656135dce7584351da0" translate="yes" xml:space="preserve">
          <source>They expose a &lt;code&gt;split&lt;/code&gt; method which accepts the input dataset to be split and yields the train/test set indices for each iteration of the chosen cross-validation strategy.</source>
          <target state="translated">Они предоставляют метод &lt;code&gt;split&lt;/code&gt; который принимает входной набор данных для разделения и выдает индексы обучающего / тестового набора для каждой итерации выбранной стратегии перекрестной проверки.</target>
        </trans-unit>
        <trans-unit id="03bbcc98e1d567dd0afc112fe378a99851c98226" translate="yes" xml:space="preserve">
          <source>They lose efficiency in high dimensional spaces &amp;ndash; namely when the number of features exceeds a few dozens.</source>
          <target state="translated">Они теряют эффективность в пространствах большой размерности, а именно, когда количество функций превышает несколько десятков.</target>
        </trans-unit>
        <trans-unit id="a673690dbc33eee17ee6f3995f817097918876ff" translate="yes" xml:space="preserve">
          <source>This Scaler removes the median and scales the data according to the quantile range (defaults to IQR: Interquartile Range). The IQR is the range between the 1st quartile (25th quantile) and the 3rd quartile (75th quantile).</source>
          <target state="translated">Этот Scaler удаляет медиану и масштабирует данные в соответствии с квантильным диапазоном (по умолчанию IQR:Interquartile Range).IQR-это диапазон между 1-м квартилем (25-й квантиль)и 3-м квартилем (75-й квантиль).</target>
        </trans-unit>
        <trans-unit id="d9994b645c162ae9e80a2c6bc1c81390f2e92325" translate="yes" xml:space="preserve">
          <source>This Warning is used in meta estimators GridSearchCV and RandomizedSearchCV and the cross-validation helper function cross_val_score to warn when there is an error while fitting the estimator.</source>
          <target state="translated">Данное предупреждение используется в метаоценках GridSearchCV и RandomizedSearchCV,а также в вспомогательной функции перекрестной проверки Cross_val_score для предупреждения об ошибке при подборе оценочного значения.</target>
        </trans-unit>
        <trans-unit id="7f5e3d23312509826c13f1663d34b7e7912ac4af" translate="yes" xml:space="preserve">
          <source>This algorithm can be viewed as an instance or data reduction method, since it reduces the input data to a set of subclusters which are obtained directly from the leaves of the CFT. This reduced data can be further processed by feeding it into a global clusterer. This global clusterer can be set by &lt;code&gt;n_clusters&lt;/code&gt;. If &lt;code&gt;n_clusters&lt;/code&gt; is set to None, the subclusters from the leaves are directly read off, otherwise a global clustering step labels these subclusters into global clusters (labels) and the samples are mapped to the global label of the nearest subcluster.</source>
          <target state="translated">Этот алгоритм можно рассматривать как экземпляр или метод сокращения данных, поскольку он сводит входные данные к набору подкластеров, которые получаются непосредственно из оконечных элементов CFT. Эти сокращенные данные могут быть дополнительно обработаны путем подачи их в глобальный кластер. Этот глобальный кластеризатор может быть установлен &lt;code&gt;n_clusters&lt;/code&gt; . Если для &lt;code&gt;n_clusters&lt;/code&gt; установлено значение None, подкластеры из листьев считываются напрямую, в противном случае шаг глобальной кластеризации помечает эти подкластеры в глобальные кластеры (метки), а выборки сопоставляются с глобальной меткой ближайшего подкластера.</target>
        </trans-unit>
        <trans-unit id="895ec6bb1e64f58ea59b9ae781fa620e703125a9" translate="yes" xml:space="preserve">
          <source>This algorithm encompasses several works from the literature. When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting &lt;a href=&quot;#r4d113ba76fc0-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;. If samples are drawn with replacement, then the method is known as Bagging &lt;a href=&quot;#r4d113ba76fc0-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt;. When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces &lt;a href=&quot;#r4d113ba76fc0-3&quot; id=&quot;id3&quot;&gt;[3]&lt;/a&gt;. Finally, when base estimators are built on subsets of both samples and features, then the method is known as Random Patches &lt;a href=&quot;#r4d113ba76fc0-4&quot; id=&quot;id4&quot;&gt;[4]&lt;/a&gt;.</source>
          <target state="translated">В этот алгоритм вошли несколько работ из литературы. Когда случайные подмножества набора данных рисуются как случайные подмножества выборок, этот алгоритм известен как Вставка &lt;a href=&quot;#r4d113ba76fc0-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; . Если образцы отбираются с заменой, то метод известен как Bagging &lt;a href=&quot;#r4d113ba76fc0-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt; . Когда случайные подмножества набора данных рисуются как случайные подмножества признаков, тогда метод известен как случайные подпространства &lt;a href=&quot;#r4d113ba76fc0-3&quot; id=&quot;id3&quot;&gt;[3]&lt;/a&gt; . Наконец, когда базовые оценки строятся на подмножествах как выборок, так и функций, тогда метод известен как случайные исправления &lt;a href=&quot;#r4d113ba76fc0-4&quot; id=&quot;id4&quot;&gt;[4]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="870122c945d57891e89c2ba931542331f1b4afdb" translate="yes" xml:space="preserve">
          <source>This algorithm encompasses several works from the literature. When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting &lt;a href=&quot;#rb1846455d0e5-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;. If samples are drawn with replacement, then the method is known as Bagging &lt;a href=&quot;#rb1846455d0e5-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt;. When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces &lt;a href=&quot;#rb1846455d0e5-3&quot; id=&quot;id3&quot;&gt;[3]&lt;/a&gt;. Finally, when base estimators are built on subsets of both samples and features, then the method is known as Random Patches &lt;a href=&quot;#rb1846455d0e5-4&quot; id=&quot;id4&quot;&gt;[4]&lt;/a&gt;.</source>
          <target state="translated">В этот алгоритм вошли несколько работ из литературы. Когда случайные подмножества набора данных рисуются как случайные подмножества выборок, этот алгоритм известен как Вставка &lt;a href=&quot;#rb1846455d0e5-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; . Если образцы отбираются с заменой, то метод известен как Bagging &lt;a href=&quot;#rb1846455d0e5-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt; . Когда случайные подмножества набора данных рисуются как случайные подмножества признаков, тогда метод известен как случайные подпространства &lt;a href=&quot;#rb1846455d0e5-3&quot; id=&quot;id3&quot;&gt;[3]&lt;/a&gt; . Наконец, когда базовые оценки строятся на подмножествах как выборок, так и функций, тогда метод известен как случайные исправления &lt;a href=&quot;#rb1846455d0e5-4&quot; id=&quot;id4&quot;&gt;[4]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="866e774dfaaba96a720c3090067c49c13cac935f" translate="yes" xml:space="preserve">
          <source>This algorithm finds a (usually very good) approximate truncated singular value decomposition using randomization to speed up the computations. It is particularly fast on large matrices on which you wish to extract only a small number of components. In order to obtain further speed up, &lt;code&gt;n_iter&lt;/code&gt; can be set &amp;lt;=2 (at the cost of loss of precision).</source>
          <target state="translated">Этот алгоритм находит (обычно очень хорошее) приближенное разложение усеченного сингулярного числа с использованием рандомизации для ускорения вычислений. Это особенно быстро для больших матриц, на которых вы хотите извлечь только небольшое количество компонентов. Чтобы получить дальнейшее ускорение, &lt;code&gt;n_iter&lt;/code&gt; можно установить &amp;lt;= 2 (за счет потери точности).</target>
        </trans-unit>
        <trans-unit id="c5eff13aab5e02ba6e328f932a803b28ba41ee60" translate="yes" xml:space="preserve">
          <source>This algorithm has constant memory complexity, on the order of &lt;code&gt;batch_size * n_features&lt;/code&gt;, enabling use of np.memmap files without loading the entire file into memory. For sparse matrices, the input is converted to dense in batches (in order to be able to subtract the mean) which avoids storing the entire dense matrix at any one time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77977d31f5357c834112cbb27bbc98b5c64c10d7" translate="yes" xml:space="preserve">
          <source>This algorithm has constant memory complexity, on the order of &lt;code&gt;batch_size&lt;/code&gt;, enabling use of np.memmap files without loading the entire file into memory.</source>
          <target state="translated">Этот алгоритм имеет постоянную сложность памяти, порядка &lt;code&gt;batch_size&lt;/code&gt; , что позволяет использовать файлы np.memmap без загрузки всего файла в память.</target>
        </trans-unit>
        <trans-unit id="f443979a9a019e4d6947465617b7828e98c7b59f" translate="yes" xml:space="preserve">
          <source>This algorithm is illustrated below.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9586aed3b1a5b6a2c44b32af5cc0558b6ad496a6" translate="yes" xml:space="preserve">
          <source>This algorithm solves the normalized cut for k=2: it is a normalized spectral clustering.</source>
          <target state="translated">Этот алгоритм решает нормализованную разрезку при k=2:это нормализованная спектральная кластеризация.</target>
        </trans-unit>
        <trans-unit id="01c65a021c885e4e00baaaa5c6652a314a97daa3" translate="yes" xml:space="preserve">
          <source>This algorithm will always use all the components it has access to, needing held-out data or information theoretical criteria to decide how many components to use in the absence of external cues.</source>
          <target state="translated">Этот алгоритм всегда будет использовать все компоненты,к которым он имеет доступ,нуждаясь в теоретических критериях наличия данных или информации для принятия решения о том,сколько компонентов использовать при отсутствии внешних подсказок.</target>
        </trans-unit>
        <trans-unit id="ddf04fe856314e7dd4ddddf49f4086029e04d842" translate="yes" xml:space="preserve">
          <source>This allows better model selection than probabilistic PCA in the presence of heteroscedastic noise:</source>
          <target state="translated">Это позволяет лучше подбирать модель,чем вероятностный PCA при наличии гетероскедастичного шума:</target>
        </trans-unit>
        <trans-unit id="3307a2458ebbefda8ea7fe8b898077ec4cadcf2c" translate="yes" xml:space="preserve">
          <source>This also works where final estimator is &lt;code&gt;None&lt;/code&gt;: all prior transformations are applied.</source>
          <target state="translated">Это также работает, когда окончательная оценка &lt;code&gt;None&lt;/code&gt; : применяются все предыдущие преобразования.</target>
        </trans-unit>
        <trans-unit id="c63b80512d8853cd76b24210ee07543da5c60fc4" translate="yes" xml:space="preserve">
          <source>This assumption is the base of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Vector_Space_Model&quot;&gt;Vector Space Model&lt;/a&gt; often used in text classification and clustering contexts.</source>
          <target state="translated">Это предположение является основой модели &lt;a href=&quot;https://en.wikipedia.org/wiki/Vector_Space_Model&quot;&gt;векторного пространства,&lt;/a&gt; часто используемой в контекстах классификации и кластеризации текста.</target>
        </trans-unit>
        <trans-unit id="a8d2386009078ecaad8deb62662ebfbef6798072" translate="yes" xml:space="preserve">
          <source>This attribute is not available if &lt;code&gt;refit&lt;/code&gt; is a function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8142b653ecd3322ad782e8a8807635d6c4c0325e" translate="yes" xml:space="preserve">
          <source>This calibration results in a lower log-loss. Note that an alternative would have been to increase the number of base estimators which would have resulted in a similar decrease in log-loss.</source>
          <target state="translated">Эта калибровка приводит к меньшим потерям в журнале.Обратите внимание,что альтернативой было бы увеличение количества базовых оценок,что привело бы к аналогичному снижению потерь.</target>
        </trans-unit>
        <trans-unit id="3ba422e075fa10216e381bf46530abda4e719fab" translate="yes" xml:space="preserve">
          <source>This call requires the estimation of a p x q matrix, which may be an issue in high dimensional space.</source>
          <target state="translated">Этот вызов требует оценки матрицы p x q,что может быть проблемой в высокоразмерном пространстве.</target>
        </trans-unit>
        <trans-unit id="345a3bd30c8553d3251f728b344d1bd100958670" translate="yes" xml:space="preserve">
          <source>This can be confirmed on a independent testing set with similar remarks:</source>
          <target state="translated">Это может быть подтверждено на независимом испытательном комплекте с аналогичными замечаниями:</target>
        </trans-unit>
        <trans-unit id="e60927eda9d0f07135f56fa39eaa1a8f1f9c2813" translate="yes" xml:space="preserve">
          <source>This can be done by introducing &lt;a href=&quot;https://en.wikipedia.org/wiki/Non-informative_prior#Uninformative_priors&quot;&gt;uninformative priors&lt;/a&gt; over the hyper parameters of the model. The \(\ell_{2}\) regularization used in &lt;a href=&quot;#id2&quot;&gt;Ridge Regression&lt;/a&gt; is equivalent to finding a maximum a posteriori estimation under a Gaussian prior over the parameters \(w\) with precision \(\lambda^{-1}\). Instead of setting &lt;code&gt;lambda&lt;/code&gt; manually, it is possible to treat it as a random variable to be estimated from the data.</source>
          <target state="translated">Это может быть сделано путем введения &lt;a href=&quot;https://en.wikipedia.org/wiki/Non-informative_prior#Uninformative_priors&quot;&gt;неинформативных априоров&lt;/a&gt; над гиперпараметрами модели. Регуляризация \ (\ ell_ {2} \), используемая в &lt;a href=&quot;#id2&quot;&gt;регрессии Риджа,&lt;/a&gt; эквивалентна нахождению максимальной апостериорной оценки при гауссовском априорном приближении по параметрам \ (w \) с точностью \ (\ lambda ^ {- 1} \). Вместо того, чтобы устанавливать &lt;code&gt;lambda&lt;/code&gt; вручную, ее можно рассматривать как случайную величину, которую нужно оценить на основе данных.</target>
        </trans-unit>
        <trans-unit id="bdd26b00d9d2e1f23dcd81c9f002391507919ff9" translate="yes" xml:space="preserve">
          <source>This can be done by introducing &lt;a href=&quot;https://en.wikipedia.org/wiki/Non-informative_prior#Uninformative_priors&quot;&gt;uninformative priors&lt;/a&gt; over the hyper parameters of the model. The \(\ell_{2}\) regularization used in &lt;a href=&quot;#ridge-regression&quot;&gt;Ridge regression and classification&lt;/a&gt; is equivalent to finding a maximum a posteriori estimation under a Gaussian prior over the coefficients \(w\) with precision \(\lambda^{-1}\). Instead of setting &lt;code&gt;lambda&lt;/code&gt; manually, it is possible to treat it as a random variable to be estimated from the data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa181018cfeb3219e1e67073f9c58ca90a0c4faa" translate="yes" xml:space="preserve">
          <source>This can be done by using the &lt;a href=&quot;generated/sklearn.model_selection.train_test_split#sklearn.model_selection.train_test_split&quot;&gt;&lt;code&gt;train_test_split&lt;/code&gt;&lt;/a&gt; utility function.</source>
          <target state="translated">Это можно сделать с помощью служебной функции &lt;a href=&quot;generated/sklearn.model_selection.train_test_split#sklearn.model_selection.train_test_split&quot;&gt; &lt;code&gt;train_test_split&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="821e5435b62e56a883478da64d6731f6479103d5" translate="yes" xml:space="preserve">
          <source>This can be set to a higher value than the actual number of features in any of the input files, but setting it to a lower value will cause an exception to be raised.</source>
          <target state="translated">Его можно установить на большее значение,чем фактическое количество функций в любом из входных файлов,но установка его на меньшее значение приведет к поднятию исключения.</target>
        </trans-unit>
        <trans-unit id="4a0bd36c1ccd6d51b38a900236d58695657d5aff" translate="yes" xml:space="preserve">
          <source>This class allows to infer an approximate posterior distribution over the parameters of a Gaussian mixture distribution. The effective number of components can be inferred from the data.</source>
          <target state="translated">Этот класс позволяет сделать приблизительный вывод о более низком распределении по сравнению с параметрами распределения гауссовской смеси.На основании данных можно сделать вывод об эффективном количестве компонентов.</target>
        </trans-unit>
        <trans-unit id="6130cf2c7564234b715447525f16ff596ebe842e" translate="yes" xml:space="preserve">
          <source>This class can be used to cross-validate time series data samples that are observed at fixed time intervals.</source>
          <target state="translated">Этот класс может использоваться для перекрестного подтверждения образцов данных временных рядов,которые наблюдаются через фиксированные промежутки времени.</target>
        </trans-unit>
        <trans-unit id="88afb4091eb2a25b2e2017ee8508b1ff5c5ae125" translate="yes" xml:space="preserve">
          <source>This class implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.</source>
          <target state="translated">В данном классе реализован метаоценщик,который подходит к ряду рандомизированных деревьев решений (так же известных как экстра-деревья)на различных подвыборках набора данных и использует усреднение для повышения точности прогнозирования и контроля над подгонкой.</target>
        </trans-unit>
        <trans-unit id="dd60f6580be8e1908408c4fbfd8d3915f46e55b1" translate="yes" xml:space="preserve">
          <source>This class implements logistic regression using liblinear, newton-cg, sag of lbfgs optimizer. The newton-cg, sag and lbfgs solvers support only L2 regularization with primal formulation. The liblinear solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty.</source>
          <target state="translated">В этом классе реализована логистическая регрессия с использованием liblinear,newton-cg,sag оптимизатора lbfgs.Растворители newton-cg,sag и lbfgs поддерживают только регуляризацию L2 с первичной рецептурой.Сольвер Liblinear поддерживает как L1,так и L2 регуляризацию,с двойной рецептурой только для L2 штрафа.</target>
        </trans-unit>
        <trans-unit id="44487ffdb33876a6a42d281dea9cfa59f8e7af24" translate="yes" xml:space="preserve">
          <source>This class implements logistic regression using liblinear, newton-cg, sag of lbfgs optimizer. The newton-cg, sag and lbfgs solvers support only L2 regularization with primal formulation. The liblinear solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty. Elastic-Net penalty is only supported by the saga solver.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="350693d0493245dcbd676a8f10e001d5020f745e" translate="yes" xml:space="preserve">
          <source>This class implements regularized logistic regression using the &amp;lsquo;liblinear&amp;rsquo; library, &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers. It can handle both dense and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit floats for optimal performance; any other input format will be converted (and copied).</source>
          <target state="translated">Этот класс реализует регуляризованную логистическую регрессию с использованием библиотеки liblinear, решателей newton-cg, sag и lbfgs. Он может обрабатывать как плотный, так и разреженный ввод. Используйте C-упорядоченные массивы или матрицы CSR, содержащие 64-битные числа с плавающей запятой для оптимальной производительности; любой другой формат ввода будет преобразован (и скопирован).</target>
        </trans-unit>
        <trans-unit id="7a8a7622df62d8a1b619a206bf179dc5e9e851ab" translate="yes" xml:space="preserve">
          <source>This class implements regularized logistic regression using the &amp;lsquo;liblinear&amp;rsquo; library, &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo;, &amp;lsquo;saga&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers. &lt;strong&gt;Note that regularization is applied by default&lt;/strong&gt;. It can handle both dense and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit floats for optimal performance; any other input format will be converted (and copied).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c107aea4a3526193efe1f31d97ccab92891d87f" translate="yes" xml:space="preserve">
          <source>This class implements the Graphical Lasso algorithm.</source>
          <target state="translated">В данном классе реализован алгоритм Графического Лассо.</target>
        </trans-unit>
        <trans-unit id="456e7e6f7be68de425401d6f66fe28d8a1090538" translate="yes" xml:space="preserve">
          <source>This class implements the algorithm known as AdaBoost-SAMME [2].</source>
          <target state="translated">В данном классе реализован алгоритм,известный как AdaBoost-SAMME [2].</target>
        </trans-unit>
        <trans-unit id="003b6bf538c58eeda3c6fd28b21967bfd8b6c40e" translate="yes" xml:space="preserve">
          <source>This class implements the algorithm known as AdaBoost.R2 [2].</source>
          <target state="translated">Данный класс реализует алгоритм,известный как AdaBoost.R2 [2].</target>
        </trans-unit>
        <trans-unit id="63c4b52b10df12140782204ea7cf58fe0edab9de" translate="yes" xml:space="preserve">
          <source>This class implements two types of prior for the weights distribution: a finite mixture model with Dirichlet distribution and an infinite mixture model with the Dirichlet Process. In practice Dirichlet Process inference algorithm is approximated and uses a truncated distribution with a fixed maximum number of components (called the Stick-breaking representation). The number of components actually used almost always depends on the data.</source>
          <target state="translated">В этом классе реализованы два типа предварительного распределения весов:модель конечной смеси с распределением по Дирихлету и модель бесконечной смеси с процессом Дирихлет.На практике алгоритм вывода Дирихлетского процесса аппроксимируется и использует усеченное распределение с фиксированным максимальным количеством компонентов (называется Stick-breaking representation).Количество фактически используемых компонентов почти всегда зависит от данных.</target>
        </trans-unit>
        <trans-unit id="e15e7e7d8d04d41fdd2a4f34183baa0366e86dea" translate="yes" xml:space="preserve">
          <source>This class inherits from PLS with mode=&amp;rdquo;A&amp;rdquo; and deflation_mode=&amp;rdquo;canonical&amp;rdquo;, norm_y_weights=True and algorithm=&amp;rdquo;nipals&amp;rdquo;, but svd should provide similar results up to numerical errors.</source>
          <target state="translated">Этот класс наследуется от PLS с mode = &quot;A&quot; и deflation_mode = &quot;canonical&quot;, norm_y_weights = True и алгоритмом = &quot;nipals&quot;, но svd должен обеспечивать аналогичные результаты с точностью до числовых ошибок.</target>
        </trans-unit>
        <trans-unit id="a0a1d1daa83e6ad727cb13fd589f28f37b44df20" translate="yes" xml:space="preserve">
          <source>This class inherits from both ValueError and AttributeError to help with exception handling and backward compatibility.</source>
          <target state="translated">Этот класс наследует как ValueError,так и AttributeError для помощи в обработке исключений и обратной совместимости.</target>
        </trans-unit>
        <trans-unit id="d34b4e0a14d3a494edeba399329a47fb49b3ee6c" translate="yes" xml:space="preserve">
          <source>This class is a low-memory alternative to DictVectorizer and CountVectorizer, intended for large-scale (online) learning and situations where memory is tight, e.g. when running prediction code on embedded devices.</source>
          <target state="translated">Этот класс является низкопамятной альтернативой DictVectorizer и CountVectorizer,предназначенной для крупномасштабного (онлайн)обучения и ситуаций с нехваткой памяти,например,при выполнении предсказательного кода на встраиваемых устройствах.</target>
        </trans-unit>
        <trans-unit id="8e34d865883b535f68990f01a240eaab9f87f080" translate="yes" xml:space="preserve">
          <source>This class is hence suitable for use in the early steps of a &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">Таким образом, этот класс подходит для использования на ранних этапах &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="eef0760dd6d25fd731b9abce61656453bb690cee" translate="yes" xml:space="preserve">
          <source>This class is useful when the behavior of &lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt;&lt;code&gt;LeavePGroupsOut&lt;/code&gt;&lt;/a&gt; is desired, but the number of groups is large enough that generating all possible partitions with \(P\) groups withheld would be prohibitively expensive. In such a scenario, &lt;a href=&quot;generated/sklearn.model_selection.groupshufflesplit#sklearn.model_selection.GroupShuffleSplit&quot;&gt;&lt;code&gt;GroupShuffleSplit&lt;/code&gt;&lt;/a&gt; provides a random sample (with replacement) of the train / test splits generated by &lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt;&lt;code&gt;LeavePGroupsOut&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Этот класс полезен, когда желательно поведение &lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt; &lt;code&gt;LeavePGroupsOut&lt;/code&gt; &lt;/a&gt; , но количество групп достаточно велико, поэтому создание всех возможных разделов с удерживаемыми группами \ (P \) было бы чрезмерно дорогостоящим. В таком сценарии &lt;a href=&quot;generated/sklearn.model_selection.groupshufflesplit#sklearn.model_selection.GroupShuffleSplit&quot;&gt; &lt;code&gt;GroupShuffleSplit&lt;/code&gt; &lt;/a&gt; предоставляет случайную выборку (с заменой) разделений поезд / тест, сгенерированных &lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt; &lt;code&gt;LeavePGroupsOut&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="9d924f7a026f05763f1c88ce464db057fdea146c" translate="yes" xml:space="preserve">
          <source>This class provides a uniform interface to fast distance metric functions. The various metrics can be accessed via the &lt;a href=&quot;#sklearn.neighbors.DistanceMetric.get_metric&quot;&gt;&lt;code&gt;get_metric&lt;/code&gt;&lt;/a&gt; class method and the metric string identifier (see below).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="edf4c29bfa2afe43016dc0b6660ad50132bd51ec" translate="yes" xml:space="preserve">
          <source>This class provides a uniform interface to fast distance metric functions. The various metrics can be accessed via the &lt;code&gt;get_metric&lt;/code&gt; class method and the metric string identifier (see below). For example, to use the Euclidean distance:</source>
          <target state="translated">Этот класс предоставляет унифицированный интерфейс для быстрых метрических функций. Доступ к различным метрикам можно получить с помощью &lt;code&gt;get_metric&lt;/code&gt; класса get_metric и идентификатора строки метрики (см. Ниже). Например, чтобы использовать евклидово расстояние:</target>
        </trans-unit>
        <trans-unit id="336f533fd7cf96bc18f597ff7211d31f0cd62386" translate="yes" xml:space="preserve">
          <source>This class supports both dense and sparse input and the multiclass support is handled according to a one-vs-the-rest scheme.</source>
          <target state="translated">Этот класс поддерживает как плотный,так и разреженный вход,а поддержка мультикласса обрабатывается по схеме &quot;один против одного&quot;.</target>
        </trans-unit>
        <trans-unit id="aebcf6792861578bf4b4a69a0be71898d4023b6a" translate="yes" xml:space="preserve">
          <source>This class supports both dense and sparse input.</source>
          <target state="translated">Этот класс поддерживает как плотный,так и разреженный вход.</target>
        </trans-unit>
        <trans-unit id="4042c6697e9df3310aa51f4f2bbe289c3d222c6e" translate="yes" xml:space="preserve">
          <source>This class turns sequences of symbolic feature names (strings) into scipy.sparse matrices, using a hash function to compute the matrix column corresponding to a name. The hash function employed is the signed 32-bit version of Murmurhash3.</source>
          <target state="translated">Этот класс превращает последовательности имён символических признаков (строк)в матрицы scipy.sparse,используя хэш-функцию для вычисления столбца матрицы,соответствующего имени.Используемая хэш-функция является знаковой 32-битной версией Murmurhash3.</target>
        </trans-unit>
        <trans-unit id="afb2ca6e635ea8a6abf9d5cec38428c8ecdc147c" translate="yes" xml:space="preserve">
          <source>This classification dataset is constructed by taking a multi-dimensional standard normal distribution and defining classes separated by nested concentric multi-dimensional spheres such that roughly equal numbers of samples are in each class (quantiles of the \(\chi^2\) distribution).</source>
          <target state="translated">Этот классификационный набор данных построен путем взятия многомерного стандартного нормального распределения и определения классов,разделенных вложенными концентрическими многомерными сферами таким образом,чтобы в каждом классе было примерно равное количество образцов (квантилей распределения \ (\chi^2\)).</target>
        </trans-unit>
        <trans-unit id="db081d4f3b8473550c6831dd235016867584f8ea" translate="yes" xml:space="preserve">
          <source>This classifier first converts the target values into &lt;code&gt;{-1, 1}&lt;/code&gt; and then treats the problem as a regression task (multi-output regression in the multiclass case).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c043eb0cb49ef78462962da4adb4099e130c09c" translate="yes" xml:space="preserve">
          <source>This classifier is sometimes referred to as a &lt;a href=&quot;https://en.wikipedia.org/wiki/Least-squares_support-vector_machine&quot;&gt;Least Squares Support Vector Machines&lt;/a&gt; with a linear kernel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a35e593acabc67ebdf8fae8d0484d5f85056d4a7" translate="yes" xml:space="preserve">
          <source>This classifier is useful as a simple baseline to compare with other (real) classifiers. Do not use it for real problems.</source>
          <target state="translated">Этот классификатор полезен в качестве простой основы для сравнения с другими (реальными)классификаторами.Не используйте его для реальных проблем.</target>
        </trans-unit>
        <trans-unit id="4ceac36d1efc9bb429dd84350330a84101bb5c8c" translate="yes" xml:space="preserve">
          <source>This classifier lost over a lot of its F-score, just because we removed metadata that has little to do with topic classification. It loses even more if we also strip this metadata from the training data:</source>
          <target state="translated">Этот классификатор потерял большую часть своей F-оценки только потому,что мы удалили метаданные,которые имеют мало общего с тематической классификацией.Он теряет еще больше,если мы также удалим эти метаданные из обучающих данных:</target>
        </trans-unit>
        <trans-unit id="064e5da463cfecd3ca166c4023a79d0a6500160d" translate="yes" xml:space="preserve">
          <source>This combination is implementing in &lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt;&lt;code&gt;HashingVectorizer&lt;/code&gt;&lt;/a&gt;, a transformer class that is mostly API compatible with &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;. &lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt;&lt;code&gt;HashingVectorizer&lt;/code&gt;&lt;/a&gt; is stateless, meaning that you don&amp;rsquo;t have to call &lt;code&gt;fit&lt;/code&gt; on it:</source>
          <target state="translated">Эта комбинация реализуется в &lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt; &lt;code&gt;HashingVectorizer&lt;/code&gt; &lt;/a&gt; , классе-преобразователе, который в основном API-совместим с &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; . &lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt; &lt;code&gt;HashingVectorizer&lt;/code&gt; не&lt;/a&gt; имеет состояния, что означает, что вам не нужно называть его &lt;code&gt;fit&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="1d56591f4aa7f0ebb864c2d8835af7dfb7f8f26b" translate="yes" xml:space="preserve">
          <source>This combines the values of agglomerated features into a single value, and should accept an array of shape [M, N] and the keyword argument &lt;code&gt;axis=1&lt;/code&gt;, and reduce it to an array of size [M].</source>
          <target state="translated">Это объединяет значения агломерированных функций в одно значение и должно принимать массив формы [M, N] и ключевое слово аргумент &lt;code&gt;axis=1&lt;/code&gt; и уменьшать его до массива размера [M].</target>
        </trans-unit>
        <trans-unit id="26c788fe31e79bd1bbf24fbba8a1b8342ff15ce1" translate="yes" xml:space="preserve">
          <source>This consumes less memory than shuffling the data directly.</source>
          <target state="translated">Это потребляет меньше памяти,чем прямая перетасовка данных.</target>
        </trans-unit>
        <trans-unit id="9c8cf431c4f1299ae41612f84a50a597aa4a1059" translate="yes" xml:space="preserve">
          <source>This creates binary hashes of input data points by getting the dot product of input points and hash_function then transforming the projection into a binary string array based on the sign (positive/negative) of the projection. A sorted array of binary hashes is created.</source>
          <target state="translated">При этом создаются бинарные хэши точек входных данных путем получения точечного произведения точек входа и хэш_функции,а затем преобразования проекции в бинарный строковый массив,основанный на знаке (положительном/отрицательном)проекции.Создается отсортированный массив двоичных хэшей.</target>
        </trans-unit>
        <trans-unit id="75f340063df2a6996986c297d7d4423dc4417e05" translate="yes" xml:space="preserve">
          <source>This cross-validation object is a merge of StratifiedKFold and ShuffleSplit, which returns stratified randomized folds. The folds are made by preserving the percentage of samples for each class.</source>
          <target state="translated">Этот объект перекрестной проверки представляет собой слияние StratifiedKFold и ShuffleSplit,которое возвращает стратифицированные случайные складки.Складки делаются путем сохранения процента образцов для каждого класса.</target>
        </trans-unit>
        <trans-unit id="ab90d891a9b7f61040a0bd2fc78eae2488d53a3a" translate="yes" xml:space="preserve">
          <source>This cross-validation object is a variation of &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt;. In the kth split, it returns first k folds as train set and the (k+1)th fold as test set.</source>
          <target state="translated">Этот объект перекрестной проверки является разновидностью &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt; . В k-м разбиении он возвращает первые k складок как набор поездов и (k + 1) -я кратность как набор тестов.</target>
        </trans-unit>
        <trans-unit id="c3d6a6171342c06e134b7087a7e83e3f80ba8a79" translate="yes" xml:space="preserve">
          <source>This cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for each class.</source>
          <target state="translated">Этот объект перекрестной проверки является разновидностью KFold,которая возвращает стратифицированные складки.Складки делаются путем сохранения процента образцов для каждого класса.</target>
        </trans-unit>
        <trans-unit id="2c34ca372157ddad0d3d18ffb66a8717775276f6" translate="yes" xml:space="preserve">
          <source>This data sets consists of 3 different types of irises&amp;rsquo; (Setosa, Versicolour, and Virginica) petal and sepal length, stored in a 150x4 numpy.ndarray</source>
          <target state="translated">Эти наборы данных состоят из трех различных типов ирисов (Setosa, Versicolour и Virginica), длина лепестков и чашелистиков, хранящихся в numpy.ndarray 150x4.</target>
        </trans-unit>
        <trans-unit id="158d23b76a72fb850a277110200a4b319b51d7f5" translate="yes" xml:space="preserve">
          <source>This database is also available through the UW CS ftp server:</source>
          <target state="translated">Эта база данных также доступна через ftp-сервер UW CS:</target>
        </trans-unit>
        <trans-unit id="8f0ed5f875aa21e65ca9d6116dc0e918ff34c0ff" translate="yes" xml:space="preserve">
          <source>This dataset consists of 20,640 samples and 9 features.</source>
          <target state="translated">Этот набор данных состоит из 20 640 образцов и 9 функций.</target>
        </trans-unit>
        <trans-unit id="2e15d3adbea56bdf31e76cb4ee55fcf6dfb7c05f" translate="yes" xml:space="preserve">
          <source>This dataset is a collection of JPEG pictures of famous people collected over the internet, all details are available on the official website:</source>
          <target state="translated">Этот набор данных представляет собой коллекцию фотографий в формате JPEG известных людей,собранных через Интернет,все подробности доступны на официальном сайте:</target>
        </trans-unit>
        <trans-unit id="1c0b9129c637e05601004735cb7bfdbdba431796" translate="yes" xml:space="preserve">
          <source>This dataset is described in Celeux et al [1]. as:</source>
          <target state="translated">Этот набор данных описан в Celeux et al.[1].как:</target>
        </trans-unit>
        <trans-unit id="e92704f97c6e77c413a0405e7cf7dd2e32191660" translate="yes" xml:space="preserve">
          <source>This dataset is described in Friedman [1] and Breiman [2].</source>
          <target state="translated">Этот набор данных описан во Фридмане [1]и Бреймане [2].</target>
        </trans-unit>
        <trans-unit id="473d3b557a1c23b381f633c2c2acf0c38c2a328f" translate="yes" xml:space="preserve">
          <source>This dataset is made up of 1797 8x8 images. Each image, like the one shown below, is of a hand-written digit. In order to utilize an 8x8 figure like this, we&amp;rsquo;d have to first transform it into a feature vector with length 64.</source>
          <target state="translated">Этот набор данных состоит из 1797 изображений 8x8. Каждое изображение, как и показанное ниже, представляет собой рукописную цифру. Чтобы использовать подобную фигуру 8x8, нам нужно сначала преобразовать ее в вектор признаков длиной 64.</target>
        </trans-unit>
        <trans-unit id="39a3f4ca0d0c444ed57d3ff159dafbaf0cf5d2c9" translate="yes" xml:space="preserve">
          <source>This dataset is suitable for multi-ouput regression tasks.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73cdbbbbdb25af126933f658f4b065e86b9c1a55" translate="yes" xml:space="preserve">
          <source>This dataset represents the geographic distribution of species. The dataset is provided by Phillips et. al. (2006).</source>
          <target state="translated">Этот набор данных представляет собой географическое распределение видов.Набор данных предоставлен Филлипсом и др.(2006).</target>
        </trans-unit>
        <trans-unit id="e72397d5f7691c5c60df49442bb007cee4717786" translate="yes" xml:space="preserve">
          <source>This dataset was derived from the 1990 U.S. census, using one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people).</source>
          <target state="translated">Этот набор данных был получен на основе переписи населения США 1990 года с использованием одной строки на группу переписных блоков.Блок-группа-это наименьшая географическая единица,для которой Бюро переписи населения США публикует выборочные данные (блок-группа,как правило,насчитывает от 600 до 3000 человек).</target>
        </trans-unit>
        <trans-unit id="47bf559cf1abc9fb33a96a120f583ad0bcd0f9f8" translate="yes" xml:space="preserve">
          <source>This dataset was obtained from the StatLib repository. &lt;a href=&quot;http://lib.stat.cmu.edu/datasets/&quot;&gt;http://lib.stat.cmu.edu/datasets/&lt;/a&gt;</source>
          <target state="translated">Этот набор данных был получен из репозитория StatLib. &lt;a href=&quot;http://lib.stat.cmu.edu/datasets/&quot;&gt;http://lib.stat.cmu.edu/datasets/&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="4668c093fae272aec3196fc6d39e4e5a4eede980" translate="yes" xml:space="preserve">
          <source>This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.</source>
          <target state="translated">Этот набор данных был взят из библиотеки StatLib,которая ведется в Университете Карнеги-Меллон.</target>
        </trans-unit>
        <trans-unit id="9b1b90be23e0adb200134bcc2570822a79ae6e88" translate="yes" xml:space="preserve">
          <source>This demonstrates Label Propagation learning a good boundary even with a small amount of labeled data.</source>
          <target state="translated">Это демонстрирует,что Label Propagation изучает хорошие границы даже с небольшим количеством помеченных данных.</target>
        </trans-unit>
        <trans-unit id="33d36bf521beb70b7b2f4b7e5d24d58f96f46c86" translate="yes" xml:space="preserve">
          <source>This description can be vectorized into a sparse two-dimensional matrix suitable for feeding into a classifier (maybe after being piped into a &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt;&lt;code&gt;text.TfidfTransformer&lt;/code&gt;&lt;/a&gt; for normalization):</source>
          <target state="translated">Это описание может быть векторизовано в разреженную двумерную матрицу, подходящую для подачи в классификатор (возможно, после &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt; &lt;code&gt;text.TfidfTransformer&lt;/code&gt; &lt;/a&gt; в текст. TfidfTransformer для нормализации):</target>
        </trans-unit>
        <trans-unit id="12f7e332bc936dbb460a17349dda07780cab7782" translate="yes" xml:space="preserve">
          <source>This determines which warnings will be made in the case that this function is being used to return only one of its metrics.</source>
          <target state="translated">Это определяет,какие предупреждения будут выданы в случае,если данная функция используется для возврата только одной из своих метрик.</target>
        </trans-unit>
        <trans-unit id="a1a66d0ad9255f63c11b93170b95da4e6eeaea4f" translate="yes" xml:space="preserve">
          <source>This downscaling is called &lt;a href=&quot;https://en.wikipedia.org/wiki/Tf-idf&quot;&gt;tf&amp;ndash;idf&lt;/a&gt; for &amp;ldquo;Term Frequency times Inverse Document Frequency&amp;rdquo;.</source>
          <target state="translated">Это масштабирование называется &lt;a href=&quot;https://en.wikipedia.org/wiki/Tf-idf&quot;&gt;tf &amp;ndash; idf&lt;/a&gt; для &amp;laquo;частоты термина, умноженной на обратную частоту документа&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="edeebc499fdf886cf2b1fe82f9cc25a148384f70" translate="yes" xml:space="preserve">
          <source>This early stopping strategy is activated if &lt;code&gt;early_stopping=True&lt;/code&gt;; otherwise the stopping criterion only uses the training loss on the entire input data. To better control the early stopping strategy, we can specify a parameter &lt;code&gt;validation_fraction&lt;/code&gt; which set the fraction of the input dataset that we keep aside to compute the validation score. The optimization will continue until the validation score did not improve by at least &lt;code&gt;tol&lt;/code&gt; during the last &lt;code&gt;n_iter_no_change&lt;/code&gt; iterations. The actual number of iterations is available at the attribute &lt;code&gt;n_iter_&lt;/code&gt;.</source>
          <target state="translated">Эта стратегия ранней остановки активируется, если &lt;code&gt;early_stopping=True&lt;/code&gt; ; в противном случае критерий остановки использует только обучающую потерю для всех входных данных. Чтобы лучше контролировать стратегию ранней остановки, мы можем указать параметр &lt;code&gt;validation_fraction&lt;/code&gt; , который устанавливает долю входного набора данных, которую мы оставляем в стороне для вычисления оценки проверки. Оптимизация будет продолжаться до тех пор, пока оценка валидации не улучшится по крайней мере на &lt;code&gt;tol&lt;/code&gt; в течение последних итераций &lt;code&gt;n_iter_no_change&lt;/code&gt; . Фактическое количество итераций доступно в атрибуте &lt;code&gt;n_iter_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6528dcf2523991bd357ca56474b42d537ada09b8" translate="yes" xml:space="preserve">
          <source>This embedding can also &amp;lsquo;work&amp;rsquo; even if the &lt;code&gt;adjacency&lt;/code&gt; variable is not strictly the adjacency matrix of a graph but more generally an affinity or similarity matrix between samples (for instance the heat kernel of a euclidean distance matrix or a k-NN matrix).</source>
          <target state="translated">Это вложение также может &amp;laquo;работать&amp;raquo;, даже если переменная &lt;code&gt;adjacency&lt;/code&gt; не является строго матрицей смежности графа, а в более общем плане является матрицей сродства или сходства между выборками (например, тепловое ядро ​​матрицы евклидовых расстояний или матрицы k-NN).</target>
        </trans-unit>
        <trans-unit id="ac8e43e8e0acd749c6d9f51af67c9e65cc70e9b4" translate="yes" xml:space="preserve">
          <source>This enables ducktyping by hasattr returning True according to the sub-estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="662188aeeffeee289aab2f0d97150266d90c022d" translate="yes" xml:space="preserve">
          <source>This encoding is needed for feeding categorical data to many scikit-learn estimators, notably linear models and SVMs with the standard kernels.</source>
          <target state="translated">Эта кодировка необходима для передачи категорических данных многим ученым,в частности,линейным моделям и SVM со стандартными ядрами.</target>
        </trans-unit>
        <trans-unit id="752036d9bd5ae374e975c046f504e0b38de39538" translate="yes" xml:space="preserve">
          <source>This estimator</source>
          <target state="translated">данный оценщик</target>
        </trans-unit>
        <trans-unit id="f8a8301fe86e970315ab1f664d0852d178958868" translate="yes" xml:space="preserve">
          <source>This estimator allows different columns or column subsets of the input to be transformed separately and the features generated by each transformer will be concatenated to form a single feature space. This is useful for heterogeneous or columnar data, to combine several feature extraction mechanisms or transformations into a single transformer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36ceeb9f387752a577aeb048b3f21cd319ecfb48" translate="yes" xml:space="preserve">
          <source>This estimator allows different columns or column subsets of the input to be transformed separately and the results combined into a single feature space. This is useful for heterogeneous or columnar data, to combine several feature extraction mechanisms or transformations into a single transformer.</source>
          <target state="translated">Этот оценщик позволяет преобразовывать различные столбцы или подмножества столбцов входа по отдельности,а результаты объединять в единое функциональное пространство.Это полезно для гетерогенных или столбчатых данных,для объединения нескольких механизмов выделения признаков или преобразований в один трансформатор.</target>
        </trans-unit>
        <trans-unit id="02199e2b9b2bd941c7464261eedf68a6fd2d82e2" translate="yes" xml:space="preserve">
          <source>This estimator applies a list of transformer objects in parallel to the input data, then concatenates the results. This is useful to combine several feature extraction mechanisms into a single transformer.</source>
          <target state="translated">Этот оценщик применяет параллельно входным данным список объектов трансформатора,а затем объединяет результаты.Это полезно для объединения нескольких механизмов выделения объектов в один трансформатор.</target>
        </trans-unit>
        <trans-unit id="a93ab3d6ae360c030a56bd4fabca46c42abdaf54" translate="yes" xml:space="preserve">
          <source>This estimator approximates a slightly different version of the additive chi squared kernel then &lt;code&gt;metric.additive_chi2&lt;/code&gt; computes.</source>
          <target state="translated">Этот оценщик аппроксимирует немного иную версию ядра аддитивного хи-квадрат, &lt;code&gt;metric.additive_chi2&lt;/code&gt; вычисляет metric.additive_chi2 .</target>
        </trans-unit>
        <trans-unit id="53ea424698dba4ed1ec741d2d0ce2fbd09225a41" translate="yes" xml:space="preserve">
          <source>This estimator can be used to model different GLMs depending on the &lt;code&gt;power&lt;/code&gt; parameter, which determines the underlying distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57f1dab8dd3e838e06f9128461ff865667eb2891" translate="yes" xml:space="preserve">
          <source>This estimator has built-in support for multi-variate regression (i.e., when y is a 2d-array of shape [n_samples, n_targets]).</source>
          <target state="translated">Этот оценщик имеет встроенную поддержку многомерной регрессии (т.е.когда y является 2d-массивом формы [n_samples,n_targets]).</target>
        </trans-unit>
        <trans-unit id="534f21211e3056d3896d05b949c661c4f992dd5f" translate="yes" xml:space="preserve">
          <source>This estimator has native support for missing values (NaNs). During training, the tree grower learns at each split point whether samples with missing values should go to the left or right child, based on the potential gain. When predicting, samples with missing values are assigned to the left or right child consequently. If no missing values were encountered for a given feature during training, then samples with missing values are mapped to whichever child has the most samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7130a824407818977c24f15960ee70da6f59d9ca" translate="yes" xml:space="preserve">
          <source>This estimator implements regularized linear models with stochastic gradient descent (SGD) learning: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate). SGD allows minibatch (online/out-of-core) learning via the &lt;code&gt;partial_fit&lt;/code&gt; method. For best results using the default learning rate schedule, the data should have zero mean and unit variance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab45bcef3fd31ebffe9c4724334c2d64921dae44" translate="yes" xml:space="preserve">
          <source>This estimator implements regularized linear models with stochastic gradient descent (SGD) learning: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate). SGD allows minibatch (online/out-of-core) learning, see the partial_fit method. For best results using the default learning rate schedule, the data should have zero mean and unit variance.</source>
          <target state="translated">Этот оценщик реализует регулярные линейные модели со стохастическим градиентным спуском (SGD):градиент потерь оценивается для каждой выборки за раз,и модель обновляется по мере убывания силового графика (так же известного как скорость обучения).SGD позволяет проводить обучение с использованием миниатюр (онлайн/выход из ядра),см.метод частичной подгонки (partial_fit).Для достижения наилучших результатов при использовании установленного по умолчанию графика интенсивности обучения данные должны иметь нулевое среднее значение и дисперсию в единицах.</target>
        </trans-unit>
        <trans-unit id="7005478518d9bca348fcae966cb157ede91131ca" translate="yes" xml:space="preserve">
          <source>This estimator is much faster than &lt;a href=&quot;sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; for big datasets (n_samples &amp;gt;= 10 000).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="505ce7903463cb2537c439b476cf7830c59f9934" translate="yes" xml:space="preserve">
          <source>This estimator is much faster than &lt;a href=&quot;sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; for big datasets (n_samples &amp;gt;= 10 000).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fdb17bfdb14f498d9377f8ca9b7cc2199a41d7f" translate="yes" xml:space="preserve">
          <source>This estimator is stateless (besides constructor parameters), the fit method does nothing but is useful when used in a pipeline.</source>
          <target state="translated">Этот оценщик является апатридом (кроме параметров конструктора),метод подгонки не делает ничего,кроме как полезен при использовании в трубопроводе.</target>
        </trans-unit>
        <trans-unit id="b10e025b81eb3a8b5b21ad615292ad7338f1e2a3" translate="yes" xml:space="preserve">
          <source>This estimator is still &lt;strong&gt;experimental&lt;/strong&gt; for now: default parameters or details of behaviour might change without any deprecation cycle. Resolving the following issues would help stabilize &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt;: convergence criteria (&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/14338&quot;&gt;#14338&lt;/a&gt;), default estimators (&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/13286&quot;&gt;#13286&lt;/a&gt;), and use of random state (&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/15611&quot;&gt;#15611&lt;/a&gt;). To use it, you need to explicitly import &lt;code&gt;enable_iterative_imputer&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ba8a49b5a7145a75b81ed477df1577dc2f0d079" translate="yes" xml:space="preserve">
          <source>This estimator is still &lt;strong&gt;experimental&lt;/strong&gt; for now: the predictions and the API might change without any deprecation cycle. To use it, you need to explicitly import &lt;code&gt;enable_hist_gradient_boosting&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c7878b26bf7f32e88e4f83c2d2d772f7f3023cd" translate="yes" xml:space="preserve">
          <source>This estimator is still &lt;strong&gt;experimental&lt;/strong&gt; for now: the predictions and the API might change without any deprecation cycle. To use it, you need to explicitly import &lt;code&gt;enable_iterative_imputer&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8c9fb1adc7eae2561c12b442ef315ae822391e8" translate="yes" xml:space="preserve">
          <source>This estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42d08f109b32ce107e9f058e7449521b0b6eab28" translate="yes" xml:space="preserve">
          <source>This estimator scales and translates each feature individually such that it is in the given range on the training set, i.e. between zero and one.</source>
          <target state="translated">Этот оценщик масштабирует и переводит каждую характеристику в отдельности так,чтобы она находилась в заданном диапазоне на тренировочном наборе,т.е.между нулем и единицей.</target>
        </trans-unit>
        <trans-unit id="ce7850baf5a7a3e7ef75716db2d2e4af71c92137" translate="yes" xml:space="preserve">
          <source>This estimator scales and translates each feature individually such that the maximal absolute value of each feature in the training set will be 1.0. It does not shift/center the data, and thus does not destroy any sparsity.</source>
          <target state="translated">Этот оценщик масштабирует и переводит каждый элемент в отдельности таким образом,что максимальное абсолютное значение каждого элемента в обучающем наборе составит 1,0.Он не сдвигает/центрирует данные и,таким образом,не уничтожает всякую разреженность.</target>
        </trans-unit>
        <trans-unit id="0ff92b3f8e56701f386ccbc5279ec5fdb2974bc0" translate="yes" xml:space="preserve">
          <source>This estimator scales each feature individually such that the maximal absolute value of each feature in the training set will be 1.0.</source>
          <target state="translated">Этот оценщик масштабирует каждый элемент индивидуально таким образом,что максимальное абсолютное значение каждого элемента в обучающем наборе составит 1,0.</target>
        </trans-unit>
        <trans-unit id="354214ed410106228bbb593cd82a49f32a2508f8" translate="yes" xml:space="preserve">
          <source>This estimator supports two algorithms: a fast randomized SVD solver, and a &amp;ldquo;naive&amp;rdquo; algorithm that uses ARPACK as an eigensolver on (X * X.T) or (X.T * X), whichever is more efficient.</source>
          <target state="translated">Этот оценщик поддерживает два алгоритма: быстрый рандомизированный решатель SVD и &amp;laquo;наивный&amp;raquo; алгоритм, который использует ARPACK в качестве собственного решателя для (X * XT) или (XT * X), ​​в зависимости от того, какой из них более эффективен.</target>
        </trans-unit>
        <trans-unit id="0a991e8d6eff0a5b7f5a276b54be6da66c4dae45" translate="yes" xml:space="preserve">
          <source>This estimator supports two algorithms: a fast randomized SVD solver, and a &amp;ldquo;naive&amp;rdquo; algorithm that uses ARPACK as an eigensolver on &lt;code&gt;X * X.T&lt;/code&gt; or &lt;code&gt;X.T * X&lt;/code&gt;, whichever is more efficient.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="438c738ad18e280c91d7884cd24490873bfed375" translate="yes" xml:space="preserve">
          <source>This estimator will run an extensive test-suite for input validation, shapes, etc, making sure that the estimator complies with &lt;code&gt;scikit-learn&lt;/code&gt; conventions as detailed in &lt;a href=&quot;https://scikit-learn.org/0.23/developers/develop.html#rolling-your-own-estimator&quot;&gt;Rolling your own estimator&lt;/a&gt;. Additional tests for classifiers, regressors, clustering or transformers will be run if the Estimator class inherits from the corresponding mixin from sklearn.base.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ed5861f671a7b7a1c102cd9c37c8bf2e273de13" translate="yes" xml:space="preserve">
          <source>This estimator will run an extensive test-suite for input validation, shapes, etc. Additional tests for classifiers, regressors, clustering or transformers will be run if the Estimator class inherits from the corresponding mixin from sklearn.base.</source>
          <target state="translated">Этот оценщик выполнит обширный набор тестов для проверки входных данных,форм и т.д.Дополнительные тесты для классификаторов,регрессоров,кластеризации или трансформаторов будут запущены,если класс Estimator наследует от соответствующей смеси от sklearn.base.</target>
        </trans-unit>
        <trans-unit id="7011f5e2b484f266188acd0aba4f3d3175f11ed0" translate="yes" xml:space="preserve">
          <source>This example also shows the usefulness of applying Ridge regression to highly ill-conditioned matrices. For such matrices, a slight change in the target variable can cause huge variances in the calculated weights. In such cases, it is useful to set a certain regularization (alpha) to reduce this variation (noise).</source>
          <target state="translated">Этот пример также показывает полезность применения хребтовой регрессии к матрицам с очень плохими условиями.Для таких матриц небольшое изменение целевой переменной может привести к огромным отклонениям в вычисленных весах.В таких случаях полезно задать некоторую регуляризацию (альфа)для уменьшения этой вариации (шума).</target>
        </trans-unit>
        <trans-unit id="66087b50dbc537ea3a892d00ee467bc12eeadd33" translate="yes" xml:space="preserve">
          <source>This example applies to &lt;a href=&quot;../../datasets/index#olivetti-faces-dataset&quot;&gt;The Olivetti faces dataset&lt;/a&gt; different unsupervised matrix decomposition (dimension reduction) methods from the module &lt;a href=&quot;../../modules/classes#module-sklearn.decomposition&quot;&gt;&lt;code&gt;sklearn.decomposition&lt;/code&gt;&lt;/a&gt; (see the documentation chapter &lt;a href=&quot;../../modules/decomposition#decompositions&quot;&gt;Decomposing signals in components (matrix factorization problems)&lt;/a&gt;) .</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f82721c4674480adff4241dbcac8e543f16c868" translate="yes" xml:space="preserve">
          <source>This example applies to olivetti_faces different unsupervised matrix decomposition (dimension reduction) methods from the module &lt;a href=&quot;../../modules/classes#module-sklearn.decomposition&quot;&gt;&lt;code&gt;sklearn.decomposition&lt;/code&gt;&lt;/a&gt; (see the documentation chapter &lt;a href=&quot;../../modules/decomposition#decompositions&quot;&gt;Decomposing signals in components (matrix factorization problems)&lt;/a&gt;) .</source>
          <target state="translated">Этот пример применяется к различным методам неконтролируемой разложения матрицы (уменьшения размерности) &lt;a href=&quot;../../modules/classes#module-sklearn.decomposition&quot;&gt; &lt;code&gt;sklearn.decomposition&lt;/code&gt; &lt;/a&gt; из модуля sklearn.decomposition (см. Главу документации &lt;a href=&quot;../../modules/decomposition#decompositions&quot;&gt;Разложение сигналов в компонентах (проблемы матричной факторизации)&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="209229078f7e258d4985eec4947d8dca83616df9" translate="yes" xml:space="preserve">
          <source>This example balances model complexity and cross-validated score by finding a decent accuracy within 1 standard deviation of the best accuracy score while minimising the number of PCA components [1].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="33924f5409489cd3edd1b22f28ee011b17a585da" translate="yes" xml:space="preserve">
          <source>This example compares 2 dimensionality reduction strategies:</source>
          <target state="translated">В этом примере сравниваются стратегии сокращения двухмерности:</target>
        </trans-unit>
        <trans-unit id="d2a9de2244899372ce613f7320d0c8868284b849" translate="yes" xml:space="preserve">
          <source>This example compares different (linear) dimensionality reduction methods applied on the Digits data set. The data set contains images of digits from 0 to 9 with approximately 180 samples of each class. Each image is of dimension 8x8 = 64, and is reduced to a two-dimensional data point.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ba8c26b14d0dc5555ed6b18d75cbed15c385668" translate="yes" xml:space="preserve">
          <source>This example compares non-nested and nested cross-validation strategies on a classifier of the iris data set. Nested cross-validation (CV) is often used to train a model in which hyperparameters also need to be optimized. Nested CV estimates the generalization error of the underlying model and its (hyper)parameter search. Choosing the parameters that maximize non-nested CV biases the model to the dataset, yielding an overly-optimistic score.</source>
          <target state="translated">В этом примере сравниваются не вложенные и вложенные стратегии перекрестной проверки на классификаторе набора данных по радужной оболочке глаза.Вложенная перекрестная проверка (CV)часто используется для обучения модели,в которой гиперпараметры также должны быть оптимизированы.Вложенная CV оценивает погрешность обобщения базовой модели и ее (гипер)параметрический поиск.Выбор параметров,которые максимизируют невложенное CV,приводит к смещению модели к набору данных,что дает чрезмерно оптимистичную оценку.</target>
        </trans-unit>
        <trans-unit id="7ef1cb506f6769f9ea8f57cc850c6090d62898eb" translate="yes" xml:space="preserve">
          <source>This example compares the timing of Birch (with and without the global clustering step) and MiniBatchKMeans on a synthetic dataset having 100,000 samples and 2 features generated using make_blobs.</source>
          <target state="translated">Этот пример сравнивает время Birch (с шагом глобальной кластеризации и без него)и MiniBatchKMeans на синтетическом наборе данных,имеющем 100,000 образцов и 2 функции,генерируемые с помощью make_blobs.</target>
        </trans-unit>
        <trans-unit id="8901e1f5225dc1b7e06d2fabb8f06f19a3753c45" translate="yes" xml:space="preserve">
          <source>This example constructs a pipeline that does dimensionality reduction followed by prediction with a support vector classifier. It demonstrates the use of &lt;code&gt;GridSearchCV&lt;/code&gt; and &lt;code&gt;Pipeline&lt;/code&gt; to optimize over different classes of estimators in a single CV run &amp;ndash; unsupervised &lt;code&gt;PCA&lt;/code&gt; and &lt;code&gt;NMF&lt;/code&gt; dimensionality reductions are compared to univariate feature selection during the grid search.</source>
          <target state="translated">В этом примере создается конвейер, который выполняет уменьшение размерности с последующим прогнозированием с помощью классификатора опорных векторов. Он демонстрирует использование &lt;code&gt;GridSearchCV&lt;/code&gt; и &lt;code&gt;Pipeline&lt;/code&gt; для оптимизации различных классов оценщиков в одном прогоне CV - неконтролируемое уменьшение размерности &lt;code&gt;PCA&lt;/code&gt; и &lt;code&gt;NMF&lt;/code&gt; сравнивается с одномерным выбором функций во время поиска по сетке.</target>
        </trans-unit>
        <trans-unit id="ebd831df4448cf766c6eb0e33a12d358fbfa3057" translate="yes" xml:space="preserve">
          <source>This example demonstrates Gradient Boosting to produce a predictive model from an ensemble of weak predictive models. Gradient boosting can be used for regression and classification problems. Here, we will train a model to tackle a diabetes regression task. We will obtain the results from &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; with least squares loss and 500 regression trees of depth 4.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b084d11db0bc218128b35a7afe55ac9fa7c4daf1" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to approximate a function with a polynomial of degree n_degree by using ridge regression. Concretely, from n_samples 1d points, it suffices to build the Vandermonde matrix, which is n_samples x n_degree+1 and has the following form:</source>
          <target state="translated">Данный пример демонстрирует,как аппроксимировать функцию с полиномом степени n_градуса с помощью гребневой регрессии.Конкретно из n_образцов 1d точек достаточно построить матрицу Вандермонда,которая является n_образцами x n_градусов+1 и имеет следующую форму:</target>
        </trans-unit>
        <trans-unit id="8509d7895b98e9b3d2d07ed03eae90baa68f1c72" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to generate a checkerboard dataset and bicluster it using the Spectral Biclustering algorithm.</source>
          <target state="translated">Этот пример демонстрирует,как генерировать набор данных шахматной доски и билюстрировать его,используя алгоритм Spectral Biclustering.</target>
        </trans-unit>
        <trans-unit id="fb9a20a0b6ffdb624c38c357324f211d180af27f" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to generate a dataset and bicluster it using the Spectral Co-Clustering algorithm.</source>
          <target state="translated">Этот пример демонстрирует,как генерировать набор данных и билюстер,используя алгоритм Spectral Co-Clustering.</target>
        </trans-unit>
        <trans-unit id="9b609f5368296ac180488994b6106bba8395b9b3" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to use &lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; on a dataset containing different types of features. The choice of features is not particularly helpful, but serves to illustrate the technique.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e024e96a6e8109f327c2d890a3a85ee374e03bd" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to use &lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt;&lt;/a&gt; on a dataset containing different types of features. We use the 20-newsgroups dataset and compute standard bag-of-words features for the subject line and body in separate pipelines as well as ad hoc features on the body. We combine them (with weights) using a ColumnTransformer and finally train a classifier on the combined set of features.</source>
          <target state="translated">В этом примере показано, как использовать &lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt; &lt;/a&gt; в наборе данных, содержащем различные типы функций. Мы используем набор данных из 20 групп новостей и вычисляем стандартные функции набора слов для строки темы и текста в отдельных конвейерах, а также специальные функции в теле. Мы объединяем их (с весами) с помощью ColumnTransformer и, наконец, обучаем классификатор комбинированному набору функций.</target>
        </trans-unit>
        <trans-unit id="76d491fec0fed042e6d7927f2dc124b698f9bded" translate="yes" xml:space="preserve">
          <source>This example demonstrates the Spectral Co-clustering algorithm on the twenty newsgroups dataset. The &amp;lsquo;comp.os.ms-windows.misc&amp;rsquo; category is excluded because it contains many posts containing nothing but data.</source>
          <target state="translated">Этот пример демонстрирует алгоритм спектральной совместной кластеризации для набора данных из двадцати групп новостей. Категория comp.os.ms-windows.misc исключена, потому что она содержит много сообщений, не содержащих ничего, кроме данных.</target>
        </trans-unit>
        <trans-unit id="6186f51b55d8cba756254a15fe651e5e8504791a" translate="yes" xml:space="preserve">
          <source>This example demonstrates the behavior of Gaussian mixture models fit on data that was not sampled from a mixture of Gaussian random variables. The dataset is formed by 100 points loosely spaced following a noisy sine curve. There is therefore no ground truth value for the number of Gaussian components.</source>
          <target state="translated">Данный пример демонстрирует поведение моделей смеси Гаусса,соответствующих данным,которые не были выведены из смеси случайных величин Гаусса.Набор данных формируется по 100 свободным точкам,следующим за шумной синусоидальной кривой.Таким образом,для числа гауссовых компонент не существует значения базовой истины.</target>
        </trans-unit>
        <trans-unit id="a1949f51dde2d60d7d4d1e707d145c1301537434" translate="yes" xml:space="preserve">
          <source>This example demonstrates the power of semisupervised learning by training a Label Spreading model to classify handwritten digits with sets of very few labels.</source>
          <target state="translated">Этот пример демонстрирует силу полупрофессионального обучения путем обучения модели &quot;Распространение этикеток&quot; для классификации рукописных цифр с наборами очень немногих этикеток.</target>
        </trans-unit>
        <trans-unit id="c6020c6a7334e89ced3b2c5f4b02f4ed9989e37f" translate="yes" xml:space="preserve">
          <source>This example demonstrates the problems of underfitting and overfitting and how we can use linear regression with polynomial features to approximate nonlinear functions. The plot shows the function that we want to approximate, which is a part of the cosine function. In addition, the samples from the real function and the approximations of different models are displayed. The models have polynomial features of different degrees. We can see that a linear function (polynomial with degree 1) is not sufficient to fit the training samples. This is called &lt;strong&gt;underfitting&lt;/strong&gt;. A polynomial of degree 4 approximates the true function almost perfectly. However, for higher degrees the model will &lt;strong&gt;overfit&lt;/strong&gt; the training data, i.e. it learns the noise of the training data. We evaluate quantitatively &lt;strong&gt;overfitting&lt;/strong&gt; / &lt;strong&gt;underfitting&lt;/strong&gt; by using cross-validation. We calculate the mean squared error (MSE) on the validation set, the higher, the less likely the model generalizes correctly from the training data.</source>
          <target state="translated">Этот пример демонстрирует проблемы недостаточного и переобучения, а также то, как мы можем использовать линейную регрессию с полиномиальными функциями для аппроксимации нелинейных функций. График показывает функцию, которую мы хотим аппроксимировать, которая является частью функции косинуса. Кроме того, отображаются образцы из реальной функции и приближения различных моделей. Модели обладают полиномиальными признаками разной степени. Мы видим, что линейной функции (полинома со степенью 1) недостаточно для соответствия обучающим выборкам. Это называется &lt;strong&gt;недостаточным оснащением&lt;/strong&gt; . Полином степени 4 почти идеально приближает истинную функцию. Однако для более высоких степеней модель будет &lt;strong&gt;превосходить&lt;/strong&gt; обучающие данные, то есть изучает шум обучающих данных. Мы оцениваем количественно&lt;strong&gt;переобучения&lt;/strong&gt; / &lt;strong&gt;underfitting&lt;/strong&gt; с помощью перекрестной проверки. Мы вычисляем среднеквадратичную ошибку (MSE) на проверочном наборе, чем выше, тем меньше вероятность правильного обобщения модели на основе данных обучения.</target>
        </trans-unit>
        <trans-unit id="a2d558b6f5e9fa98f7c27a3a7352d216289c9012" translate="yes" xml:space="preserve">
          <source>This example demonstrates the use of the Box-Cox and Yeo-Johnson transforms through &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.powertransformer#sklearn.preprocessing.PowerTransformer&quot;&gt;&lt;code&gt;PowerTransformer&lt;/code&gt;&lt;/a&gt; to map data from various distributions to a normal distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab8d51c9ac9762c2930c84a5a03c1c12345a6627" translate="yes" xml:space="preserve">
          <source>This example demonstrates the use of the Box-Cox and Yeo-Johnson transforms through &lt;code&gt;preprocessing.PowerTransformer&lt;/code&gt; to map data from various distributions to a normal distribution.</source>
          <target state="translated">Этот пример демонстрирует использование преобразований Бокса-Кокса и Йео-Джонсона посредством &lt;code&gt;preprocessing.PowerTransformer&lt;/code&gt; для отображения данных из различных распределений в нормальное распределение.</target>
        </trans-unit>
        <trans-unit id="9b62ef0be0bf7ce49acab00a23e04164c0becf9d" translate="yes" xml:space="preserve">
          <source>This example does not perform any learning over the data (see &lt;a href=&quot;../applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;Species distribution modeling&lt;/a&gt; for an example of classification based on the attributes in this dataset). It simply shows the kernel density estimate of observed data points in geospatial coordinates.</source>
          <target state="translated">В этом примере не выполняется никакого обучения по данным (см. &lt;a href=&quot;../applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;Моделирование распределения видов&lt;/a&gt; для примера классификации на основе атрибутов в этом наборе данных). Он просто показывает оценку плотности ядра наблюдаемых точек данных в геопространственных координатах.</target>
        </trans-unit>
        <trans-unit id="03eea75ae69c05ca0f9dc1a13d89bbd210d48145" translate="yes" xml:space="preserve">
          <source>This example doesn&amp;rsquo;t show it, as we&amp;rsquo;re in a low-dimensional space, but another advantage of the Dirichlet process model is that it can fit full covariance matrices effectively even when there are less examples per cluster than there are dimensions in the data, due to regularization properties of the inference algorithm.</source>
          <target state="translated">Этот пример не показывает этого, поскольку мы находимся в низкоразмерном пространстве, но еще одно преимущество модели процесса Дирихле состоит в том, что она может эффективно соответствовать полным ковариационным матрицам, даже когда примеров на кластер меньше, чем измерений в кластере. данные, благодаря свойствам регуляризации алгоритма вывода.</target>
        </trans-unit>
        <trans-unit id="7b398c0b1dbb0f3edb9cc17097a9c9f8696a24cc" translate="yes" xml:space="preserve">
          <source>This example employs several unsupervised learning techniques to extract the stock market structure from variations in historical quotes.</source>
          <target state="translated">В этом примере используется несколько неконтролируемых методов обучения для извлечения структуры фондового рынка из вариаций исторических котировок.</target>
        </trans-unit>
        <trans-unit id="41937f256baaea1198c4d043d4bb81b61df0d50b" translate="yes" xml:space="preserve">
          <source>This example fits a Gradient Boosting model with least squares loss and 500 regression trees of depth 4.</source>
          <target state="translated">Этот пример подходит для модели Gradient Boosting с наименьшими потерями квадратов и 500 деревьями регрессии глубиной 4.</target>
        </trans-unit>
        <trans-unit id="e8121408498cf6fb8c886d50eef2580465ff3307" translate="yes" xml:space="preserve">
          <source>This example fits an AdaBoosted decision stump on a non-linearly separable classification dataset composed of two &amp;ldquo;Gaussian quantiles&amp;rdquo; clusters (see &lt;a href=&quot;../../modules/generated/sklearn.datasets.make_gaussian_quantiles#sklearn.datasets.make_gaussian_quantiles&quot;&gt;&lt;code&gt;sklearn.datasets.make_gaussian_quantiles&lt;/code&gt;&lt;/a&gt;) and plots the decision boundary and decision scores. The distributions of decision scores are shown separately for samples of class A and B. The predicted class label for each sample is determined by the sign of the decision score. Samples with decision scores greater than zero are classified as B, and are otherwise classified as A. The magnitude of a decision score determines the degree of likeness with the predicted class label. Additionally, a new dataset could be constructed containing a desired purity of class B, for example, by only selecting samples with a decision score above some value.</source>
          <target state="translated">Этот пример соответствует пню решения AdaBoosted на нелинейно разделяемом наборе данных классификации, состоящем из двух кластеров &amp;laquo;гауссовских квантилей&amp;raquo; (см. &lt;a href=&quot;../../modules/generated/sklearn.datasets.make_gaussian_quantiles#sklearn.datasets.make_gaussian_quantiles&quot;&gt; &lt;code&gt;sklearn.datasets.make_gaussian_quantiles&lt;/code&gt; &lt;/a&gt; ), и строит границу решения и оценки решения. Распределение оценок за решение показано отдельно для выборок класса A и B. Метка предсказанного класса для каждой выборки определяется знаком оценки решения. Выборки с оценкой решения больше нуля классифицируются как B, а в противном случае классифицируются как A. Величина оценки решения определяет степень сходства с предсказанной меткой класса. Кроме того, можно создать новый набор данных, содержащий желаемую чистоту класса B, например, путем отбора только образцов с оценкой решения выше некоторого значения.</target>
        </trans-unit>
        <trans-unit id="02c230a18f98a72777c5f2652062014b16511fe8" translate="yes" xml:space="preserve">
          <source>This example has a fair amount of visualization-related code, as visualization is crucial here to display the graph. One of the challenge is to position the labels minimizing overlap. For this we use an heuristic based on the direction of the nearest neighbor along each axis.</source>
          <target state="translated">В этом примере достаточно много кода,связанного с визуализацией,так как визуализация здесь очень важна для отображения графика.Одна из задач состоит в том,чтобы расположить метки,минимизируя перекрытие.Для этого используется эвристика,основанная на направлении ближайшего соседа по каждой оси.</target>
        </trans-unit>
        <trans-unit id="6aeec4c0fd48150be3eb10918e11b6fbb03261c5" translate="yes" xml:space="preserve">
          <source>This example illustrates GPC on XOR data. Compared are a stationary, isotropic kernel (&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt;) and a non-stationary kernel (&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt;&lt;code&gt;DotProduct&lt;/code&gt;&lt;/a&gt;). On this particular dataset, the &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt;&lt;code&gt;DotProduct&lt;/code&gt;&lt;/a&gt; kernel obtains considerably better results because the class-boundaries are linear and coincide with the coordinate axes. In practice, however, stationary kernels such as &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt; often obtain better results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="259139974bd9ca7304e763dff02af979bb7908e6" translate="yes" xml:space="preserve">
          <source>This example illustrates GPC on XOR data. Compared are a stationary, isotropic kernel (&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt;) and a non-stationary kernel (&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt;&lt;code&gt;DotProduct&lt;/code&gt;&lt;/a&gt;). On this particular dataset, the &lt;code&gt;DotProduct&lt;/code&gt; kernel obtains considerably better results because the class-boundaries are linear and coincide with the coordinate axes. In practice, however, stationary kernels such as &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt; often obtain better results.</source>
          <target state="translated">Этот пример иллюстрирует GPC для данных XOR. Сравниваются стационарное изотропное ядро ​​( &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt; &lt;code&gt;RBF&lt;/code&gt; &lt;/a&gt; ) и нестационарное ядро ​​( &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt; &lt;code&gt;DotProduct&lt;/code&gt; &lt;/a&gt; ). В этом конкретном наборе данных ядро &lt;code&gt;DotProduct&lt;/code&gt; дает значительно лучшие результаты, поскольку границы классов линейны и совпадают с осями координат. Однако на практике стационарные ядра, такие как &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt; &lt;code&gt;RBF&lt;/code&gt; ,&lt;/a&gt; часто дают лучшие результаты.</target>
        </trans-unit>
        <trans-unit id="a467b781e30c272f4f5e4645f1261bd726b14e8d" translate="yes" xml:space="preserve">
          <source>This example illustrates GPC on XOR data. Compared are a stationary, isotropic kernel (RBF) and a non-stationary kernel (DotProduct). On this particular dataset, the DotProduct kernel obtains considerably better results because the class-boundaries are linear and coincide with the coordinate axes. In general, stationary kernels often obtain better results.</source>
          <target state="translated">Этот пример иллюстрирует GPC на данных XOR.Сравниваются стационарное,изотропное ядро (RBF)и нестационарное ядро (DotProduct).На этом конкретном наборе данных ядро DotProduct получает значительно лучшие результаты,так как границы классов являются линейными и совпадают с осями координат.В целом,стационарные ядра часто дают лучшие результаты.</target>
        </trans-unit>
        <trans-unit id="722f803000769d905ffb0b191f686c49464dc23e" translate="yes" xml:space="preserve">
          <source>This example illustrates a generic implementation of a meta-estimator which extends clustering by inducing a classifier from the cluster labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="397c051adb668f2e353216b8af31fde49c4b91b4" translate="yes" xml:space="preserve">
          <source>This example illustrates a learned distance metric that maximizes the nearest neighbors classification accuracy. It provides a visual representation of this metric compared to the original point space. Please refer to the &lt;a href=&quot;../../modules/neighbors#nca&quot;&gt;User Guide&lt;/a&gt; for more information.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b43f5231cb55a1a95a64bd8afe5472e7955fc98b" translate="yes" xml:space="preserve">
          <source>This example illustrates and compares the bias-variance decomposition of the expected mean squared error of a single estimator against a bagging ensemble.</source>
          <target state="translated">Этот пример иллюстрирует и сравнивает разложение смещения-изменения ожидаемой средней квадратной ошибки одного оценщика с ансамблем мешков.</target>
        </trans-unit>
        <trans-unit id="0a3450a632d656139c95a4f138b569cec22ba6ef" translate="yes" xml:space="preserve">
          <source>This example illustrates both methods on an artificial dataset, which consists of a sinusoidal target function and strong noise added to every fifth datapoint. The first figure compares the learned model of KRR and SVR when both complexity/regularization and bandwidth of the RBF kernel are optimized using grid-search. The learned functions are very similar; however, fitting KRR is approx. seven times faster than fitting SVR (both with grid-search). However, prediction of 100000 target values is more than tree times faster with SVR since it has learned a sparse model using only approx. 1/3 of the 100 training datapoints as support vectors.</source>
          <target state="translated">Этот пример иллюстрирует оба метода на искусственном наборе данных,который состоит из синусоидальной целевой функции и сильного шума,добавляемого к каждой пятой точке данных.Первый показатель сравнивает изученную модель KRR и SVR,когда сложность/регуляризация и полоса пропускания ядра RBF оптимизированы с помощью сеточного поиска.Изученные функции очень похожи,но подгонка KRR примерно в семь раз быстрее,чем подгонка SVR (обе с использованием сеточного поиска).Тем не менее,предсказание 100000 целевых значений с помощью SVR более чем в несколько раз быстрее,чем с помощью дерева,так как в качестве векторов поддержки была выучена разреженная модель,использующая только прибл.1/3 из 100 обучающих точек данных.</target>
        </trans-unit>
        <trans-unit id="bdbaaa805869c3c13d157f267aeffaf332ff1284" translate="yes" xml:space="preserve">
          <source>This example illustrates both methods on an artificial dataset, which consists of a sinusoidal target function and strong noise. The figure compares the learned model of KRR and GPR based on a ExpSineSquared kernel, which is suited for learning periodic functions. The kernel&amp;rsquo;s hyperparameters control the smoothness (l) and periodicity of the kernel (p). Moreover, the noise level of the data is learned explicitly by GPR by an additional WhiteKernel component in the kernel and by the regularization parameter alpha of KRR.</source>
          <target state="translated">Этот пример иллюстрирует оба метода на искусственном наборе данных, который состоит из синусоидальной целевой функции и сильного шума. На рисунке сравнивается изученная модель KRR и GPR на основе ядра ExpSineSquared, которое подходит для обучения периодических функций. Гиперпараметры ядра управляют гладкостью (l) и периодичностью ядра (p). Более того, уровень шума данных явно определяется GPR с помощью дополнительного компонента WhiteKernel в ядре и параметра регуляризации альфа KRR.</target>
        </trans-unit>
        <trans-unit id="745a420beb7d4cfe3dcb516bc28a36f2576e5395" translate="yes" xml:space="preserve">
          <source>This example illustrates how sigmoid calibration changes predicted probabilities for a 3-class classification problem. Illustrated is the standard 2-simplex, where the three corners correspond to the three classes. Arrows point from the probability vectors predicted by an uncalibrated classifier to the probability vectors predicted by the same classifier after sigmoid calibration on a hold-out validation set. Colors indicate the true class of an instance (red: class 1, green: class 2, blue: class 3).</source>
          <target state="translated">Этот пример иллюстрирует,как сигмовидная калибровка изменяет прогнозируемые вероятности для 3-классовой проблемы классификации.Иллюстрируется стандартный 2-симплекс,где три угла соответствуют трем классам.Стрелки указывают от векторов вероятности,предсказанных некалиброванным классификатором,к векторам вероятности,предсказанным тем же классификатором после сигмовидной калибровки на некалиброванном валидационном наборе.Цветами обозначен истинный класс экземпляра (красный:класс 1,зеленый:класс 2,синий:класс 3).</target>
        </trans-unit>
        <trans-unit id="12c733d8527ccd2c1862324a52d9d453fa3717b9" translate="yes" xml:space="preserve">
          <source>This example illustrates how the Mahalanobis distances are affected by outlying data: observations drawn from a contaminating distribution are not distinguishable from the observations coming from the real, Gaussian distribution that one may want to work with. Using MCD-based Mahalanobis distances, the two populations become distinguishable. Associated applications are outliers detection, observations ranking, clustering, &amp;hellip; For visualization purpose, the cubic root of the Mahalanobis distances are represented in the boxplot, as Wilson and Hilferty suggest [2]</source>
          <target state="translated">Этот пример показывает, как на расстояния Махаланобиса влияют внешние данные: наблюдения, полученные из загрязняющего распределения, неотличимы от наблюдений, исходящих из реального гауссовского распределения, с которым можно захотеть работать. Используя расстояния Махаланобиса на основе MCD, эти две популяции становятся различимыми. Связанные приложения - это обнаружение выбросов, ранжирование наблюдений, кластеризация,&amp;hellip; Для целей визуализации кубический корень из расстояний Махаланобиса представлен на прямоугольной диаграмме, как предлагают Уилсон и Хилферти [2]</target>
        </trans-unit>
        <trans-unit id="e6c2656adbcd3c5e59b375bc18300061f72c931d" translate="yes" xml:space="preserve">
          <source>This example illustrates how the early stopping can used in the &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;sklearn.ensemble.GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; model to achieve almost the same accuracy as compared to a model built without early stopping using many fewer estimators. This can significantly reduce training time, memory usage and prediction latency.</source>
          <target state="translated">В этом примере показано, как можно использовать раннюю остановку в модели &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt; &lt;code&gt;sklearn.ensemble.GradientBoostingClassifier&lt;/code&gt; &lt;/a&gt; для достижения почти такой же точности по сравнению с моделью, построенной без ранней остановки с использованием гораздо меньшего количества оценок. Это может значительно сократить время обучения, использование памяти и задержку прогнозирования.</target>
        </trans-unit>
        <trans-unit id="c9534999032b13d85edbba90f8420279af14435d" translate="yes" xml:space="preserve">
          <source>This example illustrates how the early stopping can used in the &lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt;&lt;/a&gt; model to achieve almost the same accuracy as compared to a model built without early stopping. This can significantly reduce training time. Note that scores differ between the stopping criteria even from early iterations because some of the training data is held out with the validation stopping criterion.</source>
          <target state="translated">Этот пример показывает, как можно использовать раннюю остановку в модели &lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt; &lt;/a&gt; для достижения почти такой же точности по сравнению с моделью, построенной без ранней остановки. Это может значительно сократить время обучения. Обратите внимание, что оценки различаются между критериями остановки даже на ранних итерациях, потому что некоторые обучающие данные удерживаются с критерием остановки проверки.</target>
        </trans-unit>
        <trans-unit id="c861b8fa50d5165e1e9cdc8044114c0ba76be7f1" translate="yes" xml:space="preserve">
          <source>This example illustrates how to apply different preprocessing and feature extraction pipelines to different subsets of features, using &lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt;&lt;/a&gt;. This is particularly handy for the case of datasets that contain heterogeneous data types, since we may want to scale the numeric features and one-hot encode the categorical ones.</source>
          <target state="translated">В этом примере показано, как применять различные конвейеры предварительной обработки и извлечения функций к разным подмножествам функций с помощью &lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt; &lt;/a&gt; . Это особенно удобно в случае наборов данных, которые содержат разнородные типы данных, поскольку мы можем захотеть масштабировать числовые функции и быстро кодировать категориальные.</target>
        </trans-unit>
        <trans-unit id="7688b615fac5133028d275260a50b4a9e7d6a213" translate="yes" xml:space="preserve">
          <source>This example illustrates that GPR with a sum-kernel including a WhiteKernel can estimate the noise level of data. An illustration of the log-marginal-likelihood (LML) landscape shows that there exist two local maxima of LML.</source>
          <target state="translated">Этот пример иллюстрирует,что георадар с суммарным ядром,включающим WhiteKernel,может оценить уровень шума данных.Иллюстрация ландшафта лог-маржинальной вероятности (LML)показывает,что существует два локальных максимума LML.</target>
        </trans-unit>
        <trans-unit id="aab3b4258aabcd6bfe55c7c5adf04622c59229dc" translate="yes" xml:space="preserve">
          <source>This example illustrates that GPR with a sum-kernel including a WhiteKernel can estimate the noise level of data. An illustration of the log-marginal-likelihood (LML) landscape shows that there exist two local maxima of LML. The first corresponds to a model with a high noise level and a large length scale, which explains all variations in the data by noise. The second one has a smaller noise level and shorter length scale, which explains most of the variation by the noise-free functional relationship. The second model has a higher likelihood; however, depending on the initial value for the hyperparameters, the gradient-based optimization might also converge to the high-noise solution. It is thus important to repeat the optimization several times for different initializations.</source>
          <target state="translated">Этот пример иллюстрирует,что георадар с суммарным ядром,включающим WhiteKernel,может оценить уровень шума данных.Иллюстрация ландшафта лог-маржинальной вероятности (LML)показывает,что существует два локальных максимума LML.Первый соответствует модели с высоким уровнем шума и большим масштабом длины,что объясняет все вариации данных по шумам.Второй имеет меньший уровень шума и более короткую шкалу длины,что объясняет большую часть вариаций бесшумной функциональной зависимостью.Вторая модель имеет более высокую вероятность;однако,в зависимости от исходного значения для гиперпараметров,градиентная оптимизация может также сойтись с высокошумным решением.Поэтому важно несколько раз повторить оптимизацию для различных инициализаций.</target>
        </trans-unit>
        <trans-unit id="d19a1528c92e37a37fb4fd9cad2cad1ac3d91123" translate="yes" xml:space="preserve">
          <source>This example illustrates the differences between univariate F-test statistics and mutual information.</source>
          <target state="translated">Этот пример иллюстрирует различия между одномерной F-статистикой теста и взаимной информацией.</target>
        </trans-unit>
        <trans-unit id="7867032d06fe0e647e7865e3d58419806006e425" translate="yes" xml:space="preserve">
          <source>This example illustrates the effect of monotonic constraints on a gradient boosting estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b411e019157b9b0953b37eb36e27bc6a8ffb3f5f" translate="yes" xml:space="preserve">
          <source>This example illustrates the effect of the parameters &lt;code&gt;gamma&lt;/code&gt; and &lt;code&gt;C&lt;/code&gt; of the Radial Basis Function (RBF) kernel SVM.</source>
          <target state="translated">Этот пример иллюстрирует влияние параметров &lt;code&gt;gamma&lt;/code&gt; и &lt;code&gt;C&lt;/code&gt; SVM ядра радиальной базисной функции (RBF).</target>
        </trans-unit>
        <trans-unit id="0f49634dcf1598fde3c403bd7ddd702e3816c634" translate="yes" xml:space="preserve">
          <source>This example illustrates the need for robust covariance estimation on a real data set. It is useful both for outlier detection and for a better understanding of the data structure.</source>
          <target state="translated">Этот пример иллюстрирует необходимость робастной ковариационной оценки на реальном наборе данных.Она полезна как для выявления отклонений,так и для лучшего понимания структуры данных.</target>
        </trans-unit>
        <trans-unit id="dc09ff23a3cae32be328d47d0a0a7e64185cd75a" translate="yes" xml:space="preserve">
          <source>This example illustrates the predicted probability of GPC for an RBF kernel with different choices of the hyperparameters. The first figure shows the predicted probability of GPC with arbitrarily chosen hyperparameters and with the hyperparameters corresponding to the maximum log-marginal-likelihood (LML).</source>
          <target state="translated">Этот пример иллюстрирует прогнозируемую вероятность GPC для ядра RBF с различным выбором гиперпараметров.На первом рисунке показана прогнозируемая вероятность GPC с произвольно выбранными гиперпараметрами и с гиперпараметрами,соответствующими максимальной лог-маржинальной вероятности (LML).</target>
        </trans-unit>
        <trans-unit id="d49b62c58d1a1ad4b52cfdb4df97043fcb25dfc7" translate="yes" xml:space="preserve">
          <source>This example illustrates the predicted probability of GPC for an isotropic and anisotropic RBF kernel on a two-dimensional version for the iris-dataset. The anisotropic RBF kernel obtains slightly higher log-marginal-likelihood by assigning different length-scales to the two feature dimensions.</source>
          <target state="translated">Этот пример иллюстрирует прогнозируемую вероятность GPC для изотропного и анизотропного RBF-ядра на двухмерном варианте для набора диафрагменных данных.Анизотропное ядро RBF получает немного большую лог-маржинальную вероятность,присваивая двум измерениям признаков различные диапазоны длины.</target>
        </trans-unit>
        <trans-unit id="f8e8b4dfa6bc8bbc237c34d26328609c3561c0d3" translate="yes" xml:space="preserve">
          <source>This example illustrates the predicted probability of GPC for an isotropic and anisotropic RBF kernel on a two-dimensional version for the iris-dataset. This illustrates the applicability of GPC to non-binary classification. The anisotropic RBF kernel obtains slightly higher log-marginal-likelihood by assigning different length-scales to the two feature dimensions.</source>
          <target state="translated">Этот пример иллюстрирует прогнозируемую вероятность GPC для изотропного и анизотропного RBF-ядра на двухмерном варианте для набора диафрагменных данных.Это иллюстрирует применимость GPC к небинарной классификации.Анизотропное ядро RBF получает несколько большую лог-маржинальную вероятность,присваивая двум измерениям признаков различные диапазоны длины.</target>
        </trans-unit>
        <trans-unit id="d60d503f722a9b87495f756d071794c2e2c52164" translate="yes" xml:space="preserve">
          <source>This example illustrates the prior and posterior of a GPR with different kernels. Mean, standard deviation, and 10 samples are shown for both prior and posterior.</source>
          <target state="translated">Этот пример иллюстрирует предшествующий и последующий GPR с различными ядрами.Среднее,стандартное отклонение и 10 выборок показаны как для предыдущего,так и для последующего.</target>
        </trans-unit>
        <trans-unit id="404891c56bd0f5f01fae61c2e12336745bf204d5" translate="yes" xml:space="preserve">
          <source>This example illustrates the use of Gaussian processes for regression and classification tasks on data that are not in fixed-length feature vector form. This is achieved through the use of kernel functions that operates directly on discrete structures such as variable-length sequences, trees, and graphs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b759d3b33b67e0716b08ee9d527244bce9326eed" translate="yes" xml:space="preserve">
          <source>This example illustrates the use of Poisson, Gamma and Tweedie regression on the &lt;a href=&quot;https://www.openml.org/d/41214&quot;&gt;French Motor Third-Party Liability Claims dataset&lt;/a&gt;, and is inspired by an R tutorial &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d658c6dcc61e946966ad0e8390aa06974df82a41" translate="yes" xml:space="preserve">
          <source>This example illustrates the use of log-linear Poisson regression on the &lt;a href=&quot;https://www.openml.org/d/41214&quot;&gt;French Motor Third-Party Liability Claims dataset&lt;/a&gt; from &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt; and compares it with a linear model fitted with the usual least squared error and a non-linear GBRT model fitted with the Poisson loss (and a log-link).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e4f09a45ae58596e6f6f82a5f372f88442c0679" translate="yes" xml:space="preserve">
          <source>This example illustrates the use of the &lt;a href=&quot;../../modules/multiclass#multiclass&quot;&gt;multioutput.MultiOutputRegressor&lt;/a&gt; meta-estimator to perform multi-output regression. A random forest regressor is used, which supports multi-output regression natively, so the results can be compared.</source>
          <target state="translated">В этом примере показано использование &lt;a href=&quot;../../modules/multiclass#multiclass&quot;&gt;метаоценки multioutput.MultiOutputRegressor&lt;/a&gt; для выполнения регрессии с несколькими выходами. Используется регрессор случайного леса, который изначально поддерживает регрессию с несколькими выходами, поэтому результаты можно сравнивать.</target>
        </trans-unit>
        <trans-unit id="b7cdc524f76e4e3da39b555dc7fb49145ad1abf9" translate="yes" xml:space="preserve">
          <source>This example illustrates the use of the print_changed_only global parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a4413b8994df2fb3a9be31d12e5c3eff453a657" translate="yes" xml:space="preserve">
          <source>This example illustrates visually in the feature space a comparison by results using two different component analysis techniques.</source>
          <target state="translated">Этот пример наглядно иллюстрирует в пространстве характеристик сравнение по результатам с использованием двух различных методов компонентного анализа.</target>
        </trans-unit>
        <trans-unit id="a61e83a5c393fe6eb13b5e3a4d37f5a941d5abef" translate="yes" xml:space="preserve">
          <source>This example is based on Figure 10.2 from Hastie et al 2009 &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt; and illustrates the difference in performance between the discrete SAMME &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;2&lt;/a&gt; boosting algorithm and real SAMME.R boosting algorithm. Both algorithms are evaluated on a binary classification task where the target Y is a non-linear function of 10 input features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2cd2616385e5968100e838cea35843639b5d4649" translate="yes" xml:space="preserve">
          <source>This example is based on Figure 10.2 from Hastie et al 2009 &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; and illustrates the difference in performance between the discrete SAMME &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt; boosting algorithm and real SAMME.R boosting algorithm. Both algorithms are evaluated on a binary classification task where the target Y is a non-linear function of 10 input features.</source>
          <target state="translated">Этот пример основан на рисунке 10.2 от Hastie et al 2009 &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; и иллюстрирует разницу в производительности между дискретным алгоритмом повышения SAMME &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt; и реальным алгоритмом повышения SAMME.R. Оба алгоритма оцениваются в задаче двоичной классификации, где цель Y является нелинейной функцией 10 входных характеристик.</target>
        </trans-unit>
        <trans-unit id="f74f72b73b7f5fc12f50525ee3a073668f796ed6" translate="yes" xml:space="preserve">
          <source>This example is based on Section 5.4.3 of &amp;ldquo;Gaussian Processes for Machine Learning&amp;rdquo; [RW2006]. It illustrates an example of complex kernel engineering and hyperparameter optimization using gradient ascent on the log-marginal-likelihood. The data consists of the monthly average atmospheric CO2 concentrations (in parts per million by volume (ppmv)) collected at the Mauna Loa Observatory in Hawaii, between 1958 and 2001. The objective is to model the CO2 concentration as a function of the time t.</source>
          <target state="translated">Этот пример основан на Разделе 5.4.3 &amp;laquo;Гауссовских процессов для машинного обучения&amp;raquo; [RW2006]. Он иллюстрирует пример сложной инженерии ядра и оптимизации гиперпараметров с использованием градиентного подъема на логарифмическом предельном правдоподобии. Эти данные состоят из среднемесячных концентраций CO2 в атмосфере (в частях на миллион по объему (ppmv)), собранных в обсерватории Мауна-Лоа на Гавайях в период с 1958 по 2001 год. Цель состоит в моделировании концентрации CO2 как функции времени t .</target>
        </trans-unit>
        <trans-unit id="b3b5741f90375b259727a574f2a0488e7637e5bc" translate="yes" xml:space="preserve">
          <source>This example is based on Section 5.4.3 of &lt;a href=&quot;#rw2006&quot; id=&quot;id2&quot;&gt;[RW2006]&lt;/a&gt;. It illustrates an example of complex kernel engineering and hyperparameter optimization using gradient ascent on the log-marginal-likelihood. The data consists of the monthly average atmospheric CO2 concentrations (in parts per million by volume (ppmv)) collected at the Mauna Loa Observatory in Hawaii, between 1958 and 1997. The objective is to model the CO2 concentration as a function of the time t.</source>
          <target state="translated">Этот пример основан на Разделе 5.4.3 &lt;a href=&quot;#rw2006&quot; id=&quot;id2&quot;&gt;[RW2006]&lt;/a&gt; . Он иллюстрирует пример сложной инженерии ядра и оптимизации гиперпараметров с использованием градиентного подъема на логарифмическом предельном правдоподобии. Данные состоят из среднемесячных концентраций CO2 в атмосфере (в частях на миллион по объему (ppmv)), собранных в обсерватории Мауна-Лоа на Гавайях в период с 1958 по 1997 год. Цель состоит в моделировании концентрации CO2 как функции времени t .</target>
        </trans-unit>
        <trans-unit id="9ecc1c02a68f38d70271669af08df8c1497b1d98" translate="yes" xml:space="preserve">
          <source>This example is commented in the &lt;a href=&quot;../../tutorial/basic/tutorial#introduction&quot;&gt;tutorial section of the user manual&lt;/a&gt;.</source>
          <target state="translated">Этот пример прокомментирован в &lt;a href=&quot;../../tutorial/basic/tutorial#introduction&quot;&gt;учебном разделе руководства пользователя&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="9143eb314f05280f157b4081755ef4be5d0d1857" translate="yes" xml:space="preserve">
          <source>This example is meant to illustrate situations where k-means will produce unintuitive and possibly unexpected clusters. In the first three plots, the input data does not conform to some implicit assumption that k-means makes and undesirable clusters are produced as a result. In the last plot, k-means returns intuitive clusters despite unevenly sized blobs.</source>
          <target state="translated">Этот пример призван проиллюстрировать ситуации,в которых k-средние производят неинтуитивные и,возможно,неожиданные кластеры.На первых трех графиках входные данные не соответствуют некоторым неявным предположениям о том,что в результате возникают к-средние и нежелательные кластеры.На последнем графике к-средние возвращают интуитивные кластеры,несмотря на капли неравномерного размера.</target>
        </trans-unit>
        <trans-unit id="0549792fdb7404b1799803948805283b1004db4d" translate="yes" xml:space="preserve">
          <source>This example plots several randomly generated classification datasets. For easy visualization, all datasets have 2 features, plotted on the x and y axis. The color of each point represents its class label.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="301c1da5ab62941da3ba93fb4d30f8869ad9b8b5" translate="yes" xml:space="preserve">
          <source>This example plots the corresponding dendrogram of a hierarchical clustering using AgglomerativeClustering and the dendrogram method available in scipy.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb84e7488212d58818869cb1a848aafb46dc6573" translate="yes" xml:space="preserve">
          <source>This example plots the covariance ellipsoids of each class and decision boundary learned by LDA and QDA. The ellipsoids display the double standard deviation for each class. With LDA, the standard deviation is the same for all the classes, while each class has its own standard deviation with QDA.</source>
          <target state="translated">В этом примере показаны ковариационные эллипсоиды каждого класса и граница решений,изученная LDA и QDA.Эллипсоиды отображают двойное стандартное отклонение для каждого класса.При использовании LDA,стандартное отклонение одинаково для всех классов,в то время как каждый класс имеет свое собственное стандартное отклонение при использовании QDA.</target>
        </trans-unit>
        <trans-unit id="61cf8846c08926de131cab630666b0d7a1ff4033" translate="yes" xml:space="preserve">
          <source>This example plots the ellipsoids obtained from a toy dataset (mixture of three Gaussians) fitted by the &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; class models with a Dirichlet distribution prior (&lt;code&gt;weight_concentration_prior_type='dirichlet_distribution'&lt;/code&gt;) and a Dirichlet process prior (&lt;code&gt;weight_concentration_prior_type='dirichlet_process'&lt;/code&gt;). On each figure, we plot the results for three different values of the weight concentration prior.</source>
          <target state="translated">В этом примере показаны эллипсоиды, полученные из набора данных игрушек (смесь трех гауссианов), подогнанного моделями класса &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; с предшествующим распределением Дирихле ( &lt;code&gt;weight_concentration_prior_type='dirichlet_distribution'&lt;/code&gt; ) и предшествующим процессом Дирихле ( &lt;code&gt;weight_concentration_prior_type='dirichlet_process'&lt;/code&gt; ). На каждом рисунке мы наносим результаты для трех различных значений предшествующей весовой концентрации.</target>
        </trans-unit>
        <trans-unit id="e769643d14b1851635097bc926523b99ade21d56" translate="yes" xml:space="preserve">
          <source>This example presents how to chain KNeighborsTransformer and TSNE in a pipeline. It also shows how to wrap the packages &lt;code&gt;annoy&lt;/code&gt; and &lt;code&gt;nmslib&lt;/code&gt; to replace KNeighborsTransformer and perform approximate nearest neighbors. These packages can be installed with &lt;code&gt;pip install annoy nmslib&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0d46d4faf4d4d45c7ba844c05b8ff931d890d6c" translate="yes" xml:space="preserve">
          <source>This example presents the different strategies implemented in KBinsDiscretizer:</source>
          <target state="translated">В этом примере представлены различные стратегии,реализованные в KBinsDiscretizer:</target>
        </trans-unit>
        <trans-unit id="83f4e337d08dbc1524d014ed0118fe74e8fd5454" translate="yes" xml:space="preserve">
          <source>This example reproduces Figure 1 of Zhu et al &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt; and shows how boosting can improve prediction accuracy on a multi-class problem. The classification dataset is constructed by taking a ten-dimensional standard normal distribution and defining three classes separated by nested concentric ten-dimensional spheres such that roughly equal numbers of samples are in each class (quantiles of the \(\chi^2\) distribution).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aff95617011fc0f39a1d4573107679df90fa3c83" translate="yes" xml:space="preserve">
          <source>This example reproduces Figure 1 of Zhu et al &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; and shows how boosting can improve prediction accuracy on a multi-class problem. The classification dataset is constructed by taking a ten-dimensional standard normal distribution and defining three classes separated by nested concentric ten-dimensional spheres such that roughly equal numbers of samples are in each class (quantiles of the \(\chi^2\) distribution).</source>
          <target state="translated">Этот пример воспроизводит рисунок 1 Чжу и др. &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; и показывает, как усиление может улучшить точность прогнозирования для мультиклассовой задачи. Набор данных классификации строится путем принятия десятимерного стандартного нормального распределения и определения трех классов, разделенных вложенными концентрическими десятимерными сферами, так что примерно равное количество выборок находится в каждом классе (квантили распределения \ (\ chi ^ 2 \) ).</target>
        </trans-unit>
        <trans-unit id="f0193d5eae04ea4c45d1272eb8f24ceb76514e1e" translate="yes" xml:space="preserve">
          <source>This example serves as a visual check that IPCA is able to find a similar projection of the data to PCA (to a sign flip), while only processing a few samples at a time. This can be considered a &amp;ldquo;toy example&amp;rdquo;, as IPCA is intended for large datasets which do not fit in main memory, requiring incremental approaches.</source>
          <target state="translated">Этот пример служит визуальной проверкой того, что IPCA может найти аналогичную проекцию данных для PCA (для переворота знака), одновременно обрабатывая только несколько выборок. Это можно считать &amp;laquo;игрушечным примером&amp;raquo;, поскольку IPCA предназначен для больших наборов данных, которые не помещаются в основную память, что требует дополнительных подходов.</target>
        </trans-unit>
        <trans-unit id="3dfa9a56451c107730b94ff094ad060fe6660b05" translate="yes" xml:space="preserve">
          <source>This example should be taken with a grain of salt, as the intuition conveyed does not necessarily carry over to real datasets. Particularly in high-dimensional spaces, data can more easily be separated linearly. Moreover, using feature discretization and one-hot encoding increases the number of features, which easily lead to overfitting when the number of samples is small.</source>
          <target state="translated">Этот пример следует брать с зерном соли,так как передаваемая интуиция не обязательно переносится на реальные наборы данных.В частности,в высокоразмерных пространствах данные легче разделить линейно.Более того,использование дискретизации признаков и одноразового кодирования увеличивает количество признаков,что легко приводит к переустановке при небольшом количестве образцов.</target>
        </trans-unit>
        <trans-unit id="ad21e470ff2bffe875ca12e50c6f8a883eaa0515" translate="yes" xml:space="preserve">
          <source>This example shows an example usage of the &lt;code&gt;split&lt;/code&gt; method.</source>
          <target state="translated">В этом примере показан пример использования метода &lt;code&gt;split&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="05321a1b8964aa5eaada463be8f8b6ab44686817" translate="yes" xml:space="preserve">
          <source>This example shows characteristics of different anomaly detection algorithms on 2D datasets. Datasets contain one or two modes (regions of high density) to illustrate the ability of algorithms to cope with multimodal data.</source>
          <target state="translated">В данном примере показаны характеристики различных алгоритмов обнаружения аномалий на 2D наборах данных.Наборы данных содержат один или два режима (области высокой плотности)для иллюстрации способности алгоритмов справляться с мультимодальными данными.</target>
        </trans-unit>
        <trans-unit id="9671740bdc9e0f010272719df08d61d30b070724" translate="yes" xml:space="preserve">
          <source>This example shows characteristics of different clustering algorithms on datasets that are &amp;ldquo;interesting&amp;rdquo; but still in 2D. With the exception of the last dataset, the parameters of each of these dataset-algorithm pairs has been tuned to produce good clustering results. Some algorithms are more sensitive to parameter values than others.</source>
          <target state="translated">В этом примере показаны характеристики различных алгоритмов кластеризации наборов данных, которые &amp;laquo;интересны&amp;raquo;, но все еще представлены в 2D. За исключением последнего набора данных, параметры каждой из этих пар набор данных-алгоритм были настроены для получения хороших результатов кластеризации. Некоторые алгоритмы более чувствительны к значениям параметров, чем другие.</target>
        </trans-unit>
        <trans-unit id="408c25df8162bc85c75adf89aefb6c4283aab313" translate="yes" xml:space="preserve">
          <source>This example shows characteristics of different linkage methods for hierarchical clustering on datasets that are &amp;ldquo;interesting&amp;rdquo; but still in 2D.</source>
          <target state="translated">В этом примере показаны характеристики различных методов связывания для иерархической кластеризации наборов данных, которые &amp;laquo;интересны&amp;raquo;, но все еще представлены в 2D.</target>
        </trans-unit>
        <trans-unit id="ee904b77cbf769dbe7d1093eb852f864329f4bb5" translate="yes" xml:space="preserve">
          <source>This example shows how kernel density estimation (KDE), a powerful non-parametric density estimation technique, can be used to learn a generative model for a dataset. With this generative model in place, new samples can be drawn. These new samples reflect the underlying model of the data.</source>
          <target state="translated">Этот пример показывает,как ядерная оценка плотности (KDE),мощный метод непараметрической оценки плотности,может быть использован для изучения генеративной модели набора данных.С помощью этой генеративной модели можно построить новые образцы.Эти новые выборки отражают базовую модель данных.</target>
        </trans-unit>
        <trans-unit id="54102d8f78c42d496181e5bcdf5a40bdaee3e42d" translate="yes" xml:space="preserve">
          <source>This example shows how quantile regression can be used to create prediction intervals.</source>
          <target state="translated">Этот пример показывает,как квантильная регрессия может быть использована для создания интервалов прогнозирования.</target>
        </trans-unit>
        <trans-unit id="682ea376dc5fd413204f119c7903367cc1b71149" translate="yes" xml:space="preserve">
          <source>This example shows how to build a classification pipeline with a BernoulliRBM feature extractor and a &lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; classifier. The hyperparameters of the entire model (learning rate, hidden layer size, regularization) were optimized by grid search, but the search is not reproduced here because of runtime constraints.</source>
          <target state="translated">В этом примере показано, как создать конвейер классификации с помощью экстрактора функций BernoulliRBM и классификатора &lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt; . Гиперпараметры всей модели (скорость обучения, размер скрытого слоя, регуляризация) были оптимизированы поиском по сетке, но поиск здесь не воспроизводится из-за ограничений времени выполнения.</target>
        </trans-unit>
        <trans-unit id="e6287a37f5ab2f7e58b3aa65bfc9b371f8d2e434" translate="yes" xml:space="preserve">
          <source>This example shows how to obtain partial dependence plots from a &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; trained on the California housing dataset. The example is taken from &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="translated">В этом примере показано, как получить графики частичной зависимости от &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt; &lt;code&gt;GradientBoostingRegressor&lt;/code&gt; ,&lt;/a&gt; обученного на наборе данных о жилье Калифорнии. Пример взят из &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="acf93c17a79b2f475e2915043f3e806cbddc60a2" translate="yes" xml:space="preserve">
          <source>This example shows how to obtain partial dependence plots from a &lt;a href=&quot;../../modules/generated/sklearn.neural_network.mlpregressor#sklearn.neural_network.MLPRegressor&quot;&gt;&lt;code&gt;MLPRegressor&lt;/code&gt;&lt;/a&gt; and a &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; trained on the California housing dataset. The example is taken from &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;1&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd4b844c3488b502b915a6b11d22b13911beaa74" translate="yes" xml:space="preserve">
          <source>This example shows how to perform univariate feature selection before running a SVC (support vector classifier) to improve the classification scores.</source>
          <target state="translated">В этом примере показано,как выполнить одномерный выбор функции перед запуском SVC (векторного классификатора с поддержкой)для улучшения баллов классификации.</target>
        </trans-unit>
        <trans-unit id="f7865c444403c29f04e970d66c2c5367cc834a8b" translate="yes" xml:space="preserve">
          <source>This example shows how to perform univariate feature selection before running a SVC (support vector classifier) to improve the classification scores. We use the iris dataset (4 features) and add 36 non-informative features. We can find that our model achieves best performance when we select around 10% of features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47a26e628df959c3e5ed3ffe4f4f3490e8927a8d" translate="yes" xml:space="preserve">
          <source>This example shows how to plot some of the first layer weights in a MLPClassifier trained on the MNIST dataset.</source>
          <target state="translated">Этот пример показывает,как построить некоторые из весов первого слоя в MLPClassifier,обученных на наборе данных MNIST.</target>
        </trans-unit>
        <trans-unit id="dd07bd7e7afed03f3c2a3c74458c42dc14028dfe" translate="yes" xml:space="preserve">
          <source>This example shows how to plot the decision surface for four SVM classifiers with different kernels.</source>
          <target state="translated">В этом примере показано,как построить поверхность принятия решений для четырех классификаторов SVM с различными ядрами.</target>
        </trans-unit>
        <trans-unit id="981971245cdda71fb264be7304dc1e201a08b23b" translate="yes" xml:space="preserve">
          <source>This example shows how to use &lt;a href=&quot;../../modules/generated/sklearn.model_selection.cross_val_predict#sklearn.model_selection.cross_val_predict&quot;&gt;&lt;code&gt;cross_val_predict&lt;/code&gt;&lt;/a&gt; to visualize prediction errors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52dcf2b8bf47a153b3ba3beca30c9af85b850fad" translate="yes" xml:space="preserve">
          <source>This example shows how to use &lt;code&gt;cross_val_predict&lt;/code&gt; to visualize prediction errors.</source>
          <target state="translated">В этом примере показано, как использовать &lt;code&gt;cross_val_predict&lt;/code&gt; для визуализации ошибок прогнозирования.</target>
        </trans-unit>
        <trans-unit id="42d1610b65eff631d96069dbbdf35236afd1d573" translate="yes" xml:space="preserve">
          <source>This example shows how to use Permutation Importances as an alternative that can mitigate those limitations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="351c02b1031f149a08df70cbeed39cd2a6bb9ec7" translate="yes" xml:space="preserve">
          <source>This example shows that Kernel PCA is able to find a projection of the data that makes data linearly separable.</source>
          <target state="translated">Этот пример показывает,что Kernel PCA способен найти проекцию данных,которая делает данные линейно разделенными.</target>
        </trans-unit>
        <trans-unit id="607fdb6fda0285694fd1dd982f83082f2f9a6687" translate="yes" xml:space="preserve">
          <source>This example shows that imputing the missing values can give better results than discarding the samples containing any missing value. Imputing does not always improve the predictions, so please check via cross-validation. Sometimes dropping rows or using marker values is more effective.</source>
          <target state="translated">Этот пример показывает,что вменение пропущенных значений может дать лучшие результаты,чем отбрасывание примеров,содержащих пропущенные значения.Вменение не всегда улучшает прогнозы,поэтому,пожалуйста,проверяйте через перекрестную проверку.Иногда более эффективным является отбрасывание строк или использование значений маркеров.</target>
        </trans-unit>
        <trans-unit id="b6045a3110197ccfd64402c3c879acac73bdaadb" translate="yes" xml:space="preserve">
          <source>This example shows that model selection can be performed with Gaussian Mixture Models using information-theoretic criteria (BIC). Model selection concerns both the covariance type and the number of components in the model. In that case, AIC also provides the right result (not shown to save time), but BIC is better suited if the problem is to identify the right model. Unlike Bayesian procedures, such inferences are prior-free.</source>
          <target state="translated">Этот пример показывает,что выбор модели может быть осуществлен с помощью Гауссовых моделей смешивания с использованием информационно-теоретических критериев (BIC).Выбор модели касается как типа ковариаций,так и количества компонентов в модели.В этом случае AIC также дает правильный результат (не показанный,чтобы сэкономить время),но BIC лучше подходит,если задача состоит в идентификации правильной модели.В отличие от байесовских процедур,такие умозаключения не требуют предварительного анализа.</target>
        </trans-unit>
        <trans-unit id="7ed4db944a196b1cb5ab23d8834c95cd5421c757" translate="yes" xml:space="preserve">
          <source>This example shows that you can do non-linear regression with a linear model, using a pipeline to add non-linear features. Kernel methods extend this idea and can induce very high (even infinite) dimensional feature spaces.</source>
          <target state="translated">В этом примере показано,что можно выполнять нелинейную регрессию с линейной моделью,используя трубопровод для добавления нелинейных признаков.Методы ядра расширяют эту идею и могут вызывать очень большие (даже бесконечные)размерные пространства признаков.</target>
        </trans-unit>
        <trans-unit id="48dcc848c2d6e1561f6c336d60b0fb518f9ab59a" translate="yes" xml:space="preserve">
          <source>This example shows the ROC response of different datasets, created from K-fold cross-validation. Taking all of these curves, it is possible to calculate the mean area under curve, and see the variance of the curve when the training set is split into different subsets. This roughly shows how the classifier output is affected by changes in the training data, and how different the splits generated by K-fold cross-validation are from one another.</source>
          <target state="translated">В этом примере показан ROC-ответ различных наборов данных,созданных из K-кратной перекрестной проверки.Принимая все эти кривые,можно вычислить среднюю площадь под кривой и увидеть дисперсию кривой,когда тренировочный набор разделен на разные подмножества.Это примерно показывает,как на результат работы классификатора влияют изменения в обучающих данных,и насколько отличаются друг от друга созданные из К-кратного перекрестного тестирования расщепления.</target>
        </trans-unit>
        <trans-unit id="7b92e840bf44fca60c7edc394c5ccf3da0546857" translate="yes" xml:space="preserve">
          <source>This example shows the effect of imposing a connectivity graph to capture local structure in the data. The graph is simply the graph of 20 nearest neighbors.</source>
          <target state="translated">В этом примере показан эффект наложения графика подключения для захвата локальной структуры в данных.График представляет собой просто график 20 ближайших соседей.</target>
        </trans-unit>
        <trans-unit id="a122bd5b47879a72d10715b2e2741901d74ebd5f" translate="yes" xml:space="preserve">
          <source>This example shows the reconstruction of an image from a set of parallel projections, acquired along different angles. Such a dataset is acquired in &lt;strong&gt;computed tomography&lt;/strong&gt; (CT).</source>
          <target state="translated">В этом примере показано восстановление изображения из набора параллельных проекций, полученных под разными углами. Такой набор данных получают при &lt;strong&gt;компьютерной томографии&lt;/strong&gt; (КТ).</target>
        </trans-unit>
        <trans-unit id="277c7e399c7f521a9367c3279ba6605ffa32bb5b" translate="yes" xml:space="preserve">
          <source>This example shows the use of forests of trees to evaluate the importance of the pixels in an image classification task (faces). The hotter the pixel, the more important.</source>
          <target state="translated">В этом примере показано использование лесов деревьев для оценки важности пикселей в задаче классификации изображений (граней).Чем горячее пиксель,тем важнее.</target>
        </trans-unit>
        <trans-unit id="1fc99c46b3490d43b644ebffe104cba9573e1195" translate="yes" xml:space="preserve">
          <source>This example shows the use of forests of trees to evaluate the impurity-based importance of the pixels in an image classification task (faces). The hotter the pixel, the more important.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="181df9c721e88b620fbcd3038af372d2bc17958d" translate="yes" xml:space="preserve">
          <source>This example shows the use of multi-output estimator to complete images. The goal is to predict the lower half of a face given its upper half.</source>
          <target state="translated">В этом примере показано использование многовыходного оценочного устройства для создания полных изображений.Целью является предсказание нижней половины лица с учетом его верхней половины.</target>
        </trans-unit>
        <trans-unit id="c194d9ad3fd820ff97a5b60a54a77ad5e096ac46" translate="yes" xml:space="preserve">
          <source>This example simulates a multi-label document classification problem. The dataset is generated randomly based on the following process:</source>
          <target state="translated">В этом примере симулируется проблема классификации документов с несколькими этикетками.Набор данных генерируется случайным образом на основе следующего процесса:</target>
        </trans-unit>
        <trans-unit id="beca62f6aeebe1ac71c16bdf04b277689fc51da6" translate="yes" xml:space="preserve">
          <source>This example uses &lt;a href=&quot;../../modules/clustering#spectral-clustering&quot;&gt;Spectral clustering&lt;/a&gt; on a graph created from voxel-to-voxel difference on an image to break this image into multiple partly-homogeneous regions.</source>
          <target state="translated">В этом примере используется &lt;a href=&quot;../../modules/clustering#spectral-clustering&quot;&gt;спектральная кластеризация&lt;/a&gt; на графике, созданном на основе разницы между вокселями изображения, чтобы разбить это изображение на несколько частично однородных областей.</target>
        </trans-unit>
        <trans-unit id="b1b3f16a0bb367262a72b24da0008ca16f86a096" translate="yes" xml:space="preserve">
          <source>This example uses a large dataset of faces to learn a set of 20 x 20 images patches that constitute faces.</source>
          <target state="translated">В этом примере используется большой набор данных о лицах для изучения набора патчей 20 x 20 изображений,представляющих собой лица.</target>
        </trans-unit>
        <trans-unit id="0ad2a4281006cf2ce3833b3619a37abf58d678e0" translate="yes" xml:space="preserve">
          <source>This example uses different scalers, transformers, and normalizers to bring the data within a pre-defined range.</source>
          <target state="translated">В этом примере используются различные скалеры,трансформаторы и нормализаторы для приведения данных в заранее заданный диапазон.</target>
        </trans-unit>
        <trans-unit id="e1bfbae38c6acd2b8b362eacb6ca0227cf12cdc6" translate="yes" xml:space="preserve">
          <source>This example uses the &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt;&lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt;&lt;/a&gt; class to demonstrate the principles of Kernel Density Estimation in one dimension.</source>
          <target state="translated">В этом примере используется класс &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt; &lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt; &lt;/a&gt; для демонстрации принципов оценки плотности ядра в одном измерении.</target>
        </trans-unit>
        <trans-unit id="a99077db11e6455dfdf5d225265c8630cb316352" translate="yes" xml:space="preserve">
          <source>This example uses the &lt;code&gt;scipy.stats&lt;/code&gt; module, which contains many useful distributions for sampling parameters, such as &lt;code&gt;expon&lt;/code&gt;, &lt;code&gt;gamma&lt;/code&gt;, &lt;code&gt;uniform&lt;/code&gt; or &lt;code&gt;randint&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c91a9c343e9d52fecff06520d2432c55d78e2a0" translate="yes" xml:space="preserve">
          <source>This example uses the &lt;code&gt;scipy.stats&lt;/code&gt; module, which contains many useful distributions for sampling parameters, such as &lt;code&gt;expon&lt;/code&gt;, &lt;code&gt;gamma&lt;/code&gt;, &lt;code&gt;uniform&lt;/code&gt; or &lt;code&gt;randint&lt;/code&gt;. In principle, any function can be passed that provides a &lt;code&gt;rvs&lt;/code&gt; (random variate sample) method to sample a value. A call to the &lt;code&gt;rvs&lt;/code&gt; function should provide independent random samples from possible parameter values on consecutive calls.</source>
          <target state="translated">В этом примере используется модуль &lt;code&gt;scipy.stats&lt;/code&gt; , который содержит множество полезных распределений для параметров выборки, таких как &lt;code&gt;expon&lt;/code&gt; , &lt;code&gt;gamma&lt;/code&gt; , &lt;code&gt;uniform&lt;/code&gt; или &lt;code&gt;randint&lt;/code&gt; . В принципе, можно передать любую функцию, которая предоставляет &lt;code&gt;rvs&lt;/code&gt; (случайная переменная выборка) для выборки значения. Вызов функции &lt;code&gt;rvs&lt;/code&gt; должен предоставлять независимые случайные выборки из возможных значений параметров при последовательных вызовах.</target>
        </trans-unit>
        <trans-unit id="d9381762b80079a0275cf5384c50652951b2c3b8" translate="yes" xml:space="preserve">
          <source>This example uses the only the first feature of the &lt;code&gt;diabetes&lt;/code&gt; dataset, in order to illustrate a two-dimensional plot of this regression technique. The straight line can be seen in the plot, showing how linear regression attempts to draw a straight line that will best minimize the residual sum of squares between the observed responses in the dataset, and the responses predicted by the linear approximation.</source>
          <target state="translated">В этом примере используется только первая функция набора данных о &lt;code&gt;diabetes&lt;/code&gt; , чтобы проиллюстрировать двухмерный график этого метода регрессии. На графике можно увидеть прямую линию, показывающую, как линейная регрессия пытается провести прямую линию, которая наилучшим образом минимизирует остаточную сумму квадратов между наблюдаемыми ответами в наборе данных и ответами, предсказанными линейным приближением.</target>
        </trans-unit>
        <trans-unit id="c6bb5d76743a81844f0fc5afc16345d399cae103" translate="yes" xml:space="preserve">
          <source>This example visualizes some training loss curves for different stochastic learning strategies, including SGD and Adam. Because of time-constraints, we use several small datasets, for which L-BFGS might be more suitable. The general trend shown in these examples seems to carry over to larger datasets, however.</source>
          <target state="translated">Этот пример визуализирует некоторые кривые потерь при тренировке для различных стохастических стратегий обучения,включая SGD и Адама.Из-за временных ограничений мы используем несколько небольших наборов данных,для которых L-BFGS может быть более подходящим.Однако общая тенденция,показанная в этих примерах,похоже,переносится на более крупные наборы данных.</target>
        </trans-unit>
        <trans-unit id="65646a35859e04e16667e59a0e282463725f9c9e" translate="yes" xml:space="preserve">
          <source>This example visualizes the behavior of several common scikit-learn objects for comparison.</source>
          <target state="translated">Этот пример визуализирует поведение нескольких распространённых наукоемких объектов для сравнения.</target>
        </trans-unit>
        <trans-unit id="49dcb9492cd2c3de6ca468ca869fddbd4adf1109" translate="yes" xml:space="preserve">
          <source>This example visualizes the partitions given by several trees and shows how the transformation can also be used for non-linear dimensionality reduction or non-linear classification.</source>
          <target state="translated">Этот пример визуализирует простенки,заданные несколькими деревьями,и показывает,как преобразование может быть также использовано для нелинейного уменьшения размерности или нелинейной классификации.</target>
        </trans-unit>
        <trans-unit id="6942c7999112e031e7e9f390f17a63a6ea65b8dd" translate="yes" xml:space="preserve">
          <source>This example was inspired by the &lt;a href=&quot;https://xgboost.readthedocs.io/en/latest/tutorials/monotonic.html&quot;&gt;XGBoost documentation&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6888e16176d5ba984d30e5b2aecac9e36e3202eb" translate="yes" xml:space="preserve">
          <source>This example will also work by replacing &lt;code&gt;SVC(kernel=&quot;linear&quot;)&lt;/code&gt; with &lt;code&gt;SGDClassifier(loss=&quot;hinge&quot;)&lt;/code&gt;. Setting the &lt;code&gt;loss&lt;/code&gt; parameter of the &lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;SGDClassifier&lt;/code&gt;&lt;/a&gt; equal to &lt;code&gt;hinge&lt;/code&gt; will yield behaviour such as that of a SVC with a linear kernel.</source>
          <target state="translated">Этот пример также будет работать, заменив &lt;code&gt;SVC(kernel=&quot;linear&quot;)&lt;/code&gt; на &lt;code&gt;SGDClassifier(loss=&quot;hinge&quot;)&lt;/code&gt; . Установка параметра &lt;code&gt;loss&lt;/code&gt; &lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;SGDClassifier&lt;/code&gt; &lt;/a&gt; равным &lt;code&gt;hinge&lt;/code&gt; приведет к поведению, аналогичному поведению SVC с линейным ядром.</target>
        </trans-unit>
        <trans-unit id="b7e7228e1bc6d35fed471b6c3015699404cca0fb" translate="yes" xml:space="preserve">
          <source>This example will generate three figures.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d6705d9213c8c7167b6f8a12276b073092deeca" translate="yes" xml:space="preserve">
          <source>This example will provide some hints in interpreting coefficient in linear models, pointing at problems that arise when either the linear model is not appropriate to describe the dataset, or when features are correlated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08633b59361c5b4332dffd09b9ac681bbe920080" translate="yes" xml:space="preserve">
          <source>This example, inspired from Chen&amp;rsquo;s publication [1], shows a comparison of the estimated MSE of the LW and OAS methods, using Gaussian distributed data.</source>
          <target state="translated">Этот пример, вдохновленный публикацией Чена [1], показывает сравнение расчетной MSE методов LW и OAS с использованием распределенных данных по Гауссу.</target>
        </trans-unit>
        <trans-unit id="8aeed7fa163e961c6e7fadbb3ef8c5a658c9cc15" translate="yes" xml:space="preserve">
          <source>This examples demonstrates how to precompute the k nearest neighbors before using them in KNeighborsClassifier. KNeighborsClassifier can compute the nearest neighbors internally, but precomputing them can have several benefits, such as finer parameter control, caching for multiple use, or custom implementations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9260a90e6c35e520398765702d07497fe04f1a8" translate="yes" xml:space="preserve">
          <source>This examples shows how a classifier is optimized by cross-validation, which is done using the &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;sklearn.model_selection.GridSearchCV&lt;/code&gt;&lt;/a&gt; object on a development set that comprises only half of the available labeled data.</source>
          <target state="translated">Этот пример показывает, как классификатор оптимизируется с помощью перекрестной проверки, которая выполняется с использованием объекта &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;sklearn.model_selection.GridSearchCV&lt;/code&gt; &lt;/a&gt; в наборе для разработки, который включает только половину доступных помеченных данных.</target>
        </trans-unit>
        <trans-unit id="e16048c7f7cf75798d53fe7e675cc81cd1d6af8b" translate="yes" xml:space="preserve">
          <source>This examples shows the use of forests of trees to evaluate the importance of features on an artificial classification task. The red bars are the feature importances of the forest, along with their inter-trees variability.</source>
          <target state="translated">Эти примеры показывают использование лесов деревьев для оценки важности признаков для выполнения задачи искусственной классификации.Красные полоски являются важными чертами леса,наряду с их междеревенностной изменчивостью.</target>
        </trans-unit>
        <trans-unit id="cdab1575e5f24de85ab913b14f241e0bd17fea2d" translate="yes" xml:space="preserve">
          <source>This examples shows the use of forests of trees to evaluate the importance of features on an artificial classification task. The red bars are the impurity-based feature importances of the forest, along with their inter-trees variability.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4fb4f14900902539137295018be0a0c7a07b1094" translate="yes" xml:space="preserve">
          <source>This exercise is used in the &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#cv-estimators-tut&quot;&gt;Cross-validated estimators&lt;/a&gt; part of the &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#model-selection-tut&quot;&gt;Model selection: choosing estimators and their parameters&lt;/a&gt; section of the &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;A tutorial on statistical-learning for scientific data processing&lt;/a&gt;.</source>
          <target state="translated">Это упражнение используется в &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#cv-estimators-tut&quot;&gt;перекрестной проверке оценщики&lt;/a&gt; части &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#model-selection-tut&quot;&gt;выбора модели: выбирающие оценки и их параметры&lt;/a&gt; раздел &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;Учебника по статистическому обучению для научной обработки данных&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="621b0c8349abb129c7bc150bd9745f46f49af3ab" translate="yes" xml:space="preserve">
          <source>This exercise is used in the &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#cv-generators-tut&quot;&gt;Cross-validation generators&lt;/a&gt; part of the &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#model-selection-tut&quot;&gt;Model selection: choosing estimators and their parameters&lt;/a&gt; section of the &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;A tutorial on statistical-learning for scientific data processing&lt;/a&gt;.</source>
          <target state="translated">Это упражнение используется в части &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#cv-generators-tut&quot;&gt;генераторов перекрестной проверки&lt;/a&gt; раздела &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#model-selection-tut&quot;&gt;Выбор модели: выбор оценок и их параметров &lt;/a&gt;&lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;учебного пособия по статистическому обучению для обработки научных данных&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="6915ba6643fea2f9e387885428a6e6189c7df3bf" translate="yes" xml:space="preserve">
          <source>This exercise is used in the &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#clf-tut&quot;&gt;Classification&lt;/a&gt; part of the &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#supervised-learning-tut&quot;&gt;Supervised learning: predicting an output variable from high-dimensional observations&lt;/a&gt; section of the &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;A tutorial on statistical-learning for scientific data processing&lt;/a&gt;.</source>
          <target state="translated">Это упражнение используется в &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#clf-tut&quot;&gt;классификации&lt;/a&gt; части &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#supervised-learning-tut&quot;&gt;поднадзорного обучения: предсказывая выходную переменный из высокой размерности наблюдений&lt;/a&gt; секции &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;учебника по статистическому обучению для научной обработки данных&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="421684adc1a996556d28fe46ff4c101c2f3063ef" translate="yes" xml:space="preserve">
          <source>This exercise is used in the &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#using-kernels-tut&quot;&gt;Using kernels&lt;/a&gt; part of the &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#supervised-learning-tut&quot;&gt;Supervised learning: predicting an output variable from high-dimensional observations&lt;/a&gt; section of the &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;A tutorial on statistical-learning for scientific data processing&lt;/a&gt;.</source>
          <target state="translated">Это упражнение используется в &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#using-kernels-tut&quot;&gt;Использовании ядер&lt;/a&gt; части &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#supervised-learning-tut&quot;&gt;поднадзорного обучения: предсказывая выходную переменный из многомерных наблюдений&lt;/a&gt; раздела &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;Учебника по статистико-обучений для научной обработки данных&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="dadb46eeaf7a2bf2f8f61dc107ba2d3f5d55d33a" translate="yes" xml:space="preserve">
          <source>This extends to the multiclass case as follows. Let the true labels for a set of samples be encoded as a 1-of-K binary indicator matrix \(Y\), i.e., \(y_{i,k} = 1\) if sample \(i\) has label \(k\) taken from a set of \(K\) labels. Let \(P\) be a matrix of probability estimates, with \(p_{i,k} = \operatorname{Pr}(t_{i,k} = 1)\). Then the log loss of the whole set is</source>
          <target state="translated">Это распространяется на многоклассовый случай следующим образом.Пусть истинные метки для набора сэмплов кодируются как 1-of-K двоичная индикаторная матрица \(Y\),т.е.\(y_{i,k}=1\),если сэмпл \(i\)имеет метку \(k\),взятую из набора меток \(K\).Пусть \(P\)будет матрицей вероятностных оценок,с \(p_{i,k}=\operatorname{Pr}(t_{i,k}=1)\).Тогда лог-потеря всего множества будет</target>
        </trans-unit>
        <trans-unit id="826a67cf49f96f56e23921af61e52712fab61d33" translate="yes" xml:space="preserve">
          <source>This factory function wraps scoring functions for use in GridSearchCV and cross_val_score. It takes a score function, such as &lt;code&gt;accuracy_score&lt;/code&gt;, &lt;code&gt;mean_squared_error&lt;/code&gt;, &lt;code&gt;adjusted_rand_index&lt;/code&gt; or &lt;code&gt;average_precision&lt;/code&gt; and returns a callable that scores an estimator&amp;rsquo;s output.</source>
          <target state="translated">Эта фабричная функция обертывает функции скоринга для использования в GridSearchCV и cross_val_score. Он принимает функцию вратаря, такие как &lt;code&gt;accuracy_score&lt;/code&gt; , &lt;code&gt;mean_squared_error&lt;/code&gt; , &lt;code&gt;adjusted_rand_index&lt;/code&gt; или &lt;code&gt;average_precision&lt;/code&gt; и возвращает вызываемый , что оценки выходного оценщика.</target>
        </trans-unit>
        <trans-unit id="5eb7a4eb6e2161d3d9f2a7b4c7010506ccf35ad1" translate="yes" xml:space="preserve">
          <source>This feature corresponds to the sepal length in cm. Once the quantile transformation applied, those landmarks approach closely the percentiles previously defined:</source>
          <target state="translated">Эта особенность соответствует длине чашелистика в см.После применения квантильного преобразования эти ориентиры приближаются к ранее определенным процентилям:</target>
        </trans-unit>
        <trans-unit id="18a1d2c5a41fd4d57af7a6bb802060cade230322" translate="yes" xml:space="preserve">
          <source>This feature selection algorithm looks only at the features (X), not the desired outputs (y), and can thus be used for unsupervised learning.</source>
          <target state="translated">Этот алгоритм выбора функций смотрит только на функции (X),а не на желаемые выходы (y),и,таким образом,может быть использован для неконтролируемого обучения.</target>
        </trans-unit>
        <trans-unit id="677c582ff4a458e9dc8e636909bbbb985fe5cce6" translate="yes" xml:space="preserve">
          <source>This figure is created using the &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt;&lt;code&gt;PolynomialFeatures&lt;/code&gt;&lt;/a&gt; preprocessor. This preprocessor transforms an input data matrix into a new data matrix of a given degree. It can be used as follows:</source>
          <target state="translated">Этот рисунок создается с помощью препроцессора &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt; &lt;code&gt;PolynomialFeatures&lt;/code&gt; &lt;/a&gt; . Этот препроцессор преобразует матрицу входных данных в новую матрицу данных заданной степени. Его можно использовать следующим образом:</target>
        </trans-unit>
        <trans-unit id="6faa801ac2c09333248247cbfc3515a179a790a8" translate="yes" xml:space="preserve">
          <source>This figure is created using the &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt;&lt;code&gt;PolynomialFeatures&lt;/code&gt;&lt;/a&gt; transformer, which transforms an input data matrix into a new data matrix of a given degree. It can be used as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="adbd1df9acbf84e51fe5dc83e34aca6a9423eabf" translate="yes" xml:space="preserve">
          <source>This figure shows an example of such an ROC curve:</source>
          <target state="translated">На этом рисунке показан пример такой УХО-кривой:</target>
        </trans-unit>
        <trans-unit id="e1207da0df5038f5f29891db83b7d5022ead8471" translate="yes" xml:space="preserve">
          <source>This folder is used by some large dataset loaders to avoid downloading the data several times.</source>
          <target state="translated">Эта папка используется некоторыми крупными загрузчиками наборов данных,чтобы избежать многократной загрузки данных.</target>
        </trans-unit>
        <trans-unit id="697a12fdadac01e298b3e16a8634659c2b054014" translate="yes" xml:space="preserve">
          <source>This format is a text-based format, with one sample per line. It does not store zero valued features hence is suitable for sparse dataset.</source>
          <target state="translated">Этот формат является текстовым,с одним образцом на строку.Он не хранит нулевые функции,поэтому подходит для разреженных наборов данных.</target>
        </trans-unit>
        <trans-unit id="a2fe6f0ee6734c2a60bcbb1d0d95dc9dfd886002" translate="yes" xml:space="preserve">
          <source>This format is used as the default format for both svmlight and the libsvm command line programs.</source>
          <target state="translated">Этот формат используется по умолчанию как для svmlight,так и для командной строки libsvm.</target>
        </trans-unit>
        <trans-unit id="a2e505f490185afab8e1242d5832b6872eb9a667" translate="yes" xml:space="preserve">
          <source>This formulation has two advantages over other ways of computing distances. First, it is computationally efficient when dealing with sparse data. Second, if one argument varies but the other remains unchanged, then &lt;code&gt;dot(x, x)&lt;/code&gt; and/or &lt;code&gt;dot(y, y)&lt;/code&gt; can be pre-computed.</source>
          <target state="translated">Эта формулировка имеет два преимущества перед другими способами вычисления расстояний. Во-первых, он эффективен с точки зрения вычислений при работе с разреженными данными. Во-вторых, если один аргумент меняется, а другой остается неизменным, то &lt;code&gt;dot(x, x)&lt;/code&gt; и / или &lt;code&gt;dot(y, y)&lt;/code&gt; могут быть предварительно вычислены.</target>
        </trans-unit>
        <trans-unit id="fd76e45c139161a6c2340aa524dcf0429afb583e" translate="yes" xml:space="preserve">
          <source>This function computes Cohen&amp;rsquo;s kappa &lt;a href=&quot;#r219a3b9132e1-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;, a score that expresses the level of agreement between two annotators on a classification problem. It is defined as</source>
          <target state="translated">Эта функция вычисляет каппа Коэна &lt;a href=&quot;#r219a3b9132e1-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; , показатель, который выражает уровень согласия между двумя аннотаторами по проблеме классификации. Он определяется как</target>
        </trans-unit>
        <trans-unit id="1a26f30c64bc915159ba37349551edb033f8db68" translate="yes" xml:space="preserve">
          <source>This function computes for each row in X, the index of the row of Y which is closest (according to the specified distance).</source>
          <target state="translated">Эта функция вычисляет для каждой строки в X,индекс строки Y,которая наиболее близка (в соответствии с заданным расстоянием).</target>
        </trans-unit>
        <trans-unit id="40ca8ec3788866f2480b1619115207e644d05cac" translate="yes" xml:space="preserve">
          <source>This function computes for each row in X, the index of the row of Y which is closest (according to the specified distance). The minimal distances are also returned.</source>
          <target state="translated">Эта функция вычисляет для каждой строки в X,индекс строки Y,которая наиболее близка (в соответствии с заданным расстоянием).Также возвращаются минимальные расстояния.</target>
        </trans-unit>
        <trans-unit id="6e14f241e1c03d6b67a6c0f22515d375ae432487" translate="yes" xml:space="preserve">
          <source>This function crawls the module and gets all classes that inherit from BaseEstimator. Classes that are defined in test-modules are not included. By default meta_estimators such as GridSearchCV are also not included.</source>
          <target state="translated">Эта функция сканирует модуль и получает все классы,унаследованные от BaseEstimator.Классы,которые определены в тестовых модулях,в нее не входят.По умолчанию не включены также такие метаоценщики,как GridSearchCV.</target>
        </trans-unit>
        <trans-unit id="311d27372cf5315019acfac7480657777c623446" translate="yes" xml:space="preserve">
          <source>This function does not try to extract features into a numpy array or scipy sparse matrix. In addition, if load_content is false it does not try to load the files in memory.</source>
          <target state="translated">Эта функция не пытается извлечь функции в массив numpy или матрицу scipy sparse.Кроме того,если load_content ложный,она не пытается загрузить файлы в память.</target>
        </trans-unit>
        <trans-unit id="28042729acf4bf75d343c82f013b112dad91f4c8" translate="yes" xml:space="preserve">
          <source>This function generates a GraphViz representation of the decision tree, which is then written into &lt;code&gt;out_file&lt;/code&gt;. Once exported, graphical renderings can be generated using, for example:</source>
          <target state="translated">Эта функция генерирует GraphViz-представление дерева решений, которое затем записывается в &lt;code&gt;out_file&lt;/code&gt; . После экспорта графические изображения могут быть созданы, например, с помощью:</target>
        </trans-unit>
        <trans-unit id="90af5dc07a0d6b1b987fbe6284966c35b8f7dbed" translate="yes" xml:space="preserve">
          <source>This function implements Test 1 in:</source>
          <target state="translated">Эта функция реализует Test 1 in:</target>
        </trans-unit>
        <trans-unit id="51510777ab8c25d02b45243629e172250d646e40" translate="yes" xml:space="preserve">
          <source>This function is called with the estimated model and the randomly selected data: &lt;code&gt;is_model_valid(model, X, y)&lt;/code&gt;. If its return value is False the current randomly chosen sub-sample is skipped. Rejecting samples with this function is computationally costlier than with &lt;code&gt;is_data_valid&lt;/code&gt;. &lt;code&gt;is_model_valid&lt;/code&gt; should therefore only be used if the estimated model is needed for making the rejection decision.</source>
          <target state="translated">Эта функция вызывается с оценочной моделью и случайно выбранными данными: &lt;code&gt;is_model_valid(model, X, y)&lt;/code&gt; . Если его возвращаемое значение - False, текущая случайно выбранная подвыборка пропускается. Отклонение выборок с помощью этой функции &lt;code&gt;is_data_valid&lt;/code&gt; вычислений, чем с is_data_valid . &lt;code&gt;is_model_valid&lt;/code&gt; следует использовать только в том случае, если оценочная модель необходима для принятия решения об отклонении.</target>
        </trans-unit>
        <trans-unit id="a4283f593950d3e9c84617d07a78fd011e78bfa4" translate="yes" xml:space="preserve">
          <source>This function is called with the randomly selected data before the model is fitted to it: &lt;code&gt;is_data_valid(X, y)&lt;/code&gt;. If its return value is False the current randomly chosen sub-sample is skipped.</source>
          <target state="translated">Эта функция вызывается со случайно выбранными данными до того, как модель будет соответствовать им: &lt;code&gt;is_data_valid(X, y)&lt;/code&gt; . Если его возвращаемое значение - False, текущая случайно выбранная подвыборка пропускается.</target>
        </trans-unit>
        <trans-unit id="7289fd594a0de96a89a572bf0a7bd6e9501fda52" translate="yes" xml:space="preserve">
          <source>This function is equivalent to mapping load_svmlight_file over a list of files, except that the results are concatenated into a single, flat list and the samples vectors are constrained to all have the same number of features.</source>
          <target state="translated">Эта функция эквивалентна отображению load_svmlight_file над списком файлов,за исключением того,что результаты объединены в единый,плоский список,а векторы выборки ограничены тем,что все они имеют одинаковое количество возможностей.</target>
        </trans-unit>
        <trans-unit id="828fa7414b6e6676bd49f6624bf5ec1232d13777" translate="yes" xml:space="preserve">
          <source>This function makes it possible to compute this transformation for a fixed set of class labels known ahead of time.</source>
          <target state="translated">Данная функция позволяет вычислить это преобразование для фиксированного заранее известного набора меток класса.</target>
        </trans-unit>
        <trans-unit id="910452d7cd5e91358a13a185cadee882cea17632" translate="yes" xml:space="preserve">
          <source>This function modifies the estimator in-place.</source>
          <target state="translated">Эта функция модифицирует встроенный оценщик.</target>
        </trans-unit>
        <trans-unit id="3e0bd9f3948e27380d0112f277598d80d17269d2" translate="yes" xml:space="preserve">
          <source>This function requires the true binary value and the target scores, which can either be probability estimates of the positive class, confidence values, or binary decisions. Here is a small example of how to use the &lt;a href=&quot;generated/sklearn.metrics.roc_curve#sklearn.metrics.roc_curve&quot;&gt;&lt;code&gt;roc_curve&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Для этой функции требуется истинное двоичное значение и целевые баллы, которые могут быть либо оценками вероятности положительного класса, либо значениями достоверности, либо двоичными решениями. Вот небольшой пример того, как использовать функцию &lt;a href=&quot;generated/sklearn.metrics.roc_curve#sklearn.metrics.roc_curve&quot;&gt; &lt;code&gt;roc_curve&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="2ddc8c678c75b432a0f0fafa6490a9a69a784bf8" translate="yes" xml:space="preserve">
          <source>This function returns a score of the mean square difference between the actual outcome and the predicted probability of the possible outcome. The actual outcome has to be 1 or 0 (true or false), while the predicted probability of the actual outcome can be a value between 0 and 1.</source>
          <target state="translated">Эта функция возвращает оценку средней квадратной разницы между фактическим результатом и прогнозируемой вероятностью возможного исхода.Фактический результат должен быть 1 или 0 (истинный или ложный),в то время как прогнозируемая вероятность фактического результата может быть между 0 и 1.</target>
        </trans-unit>
        <trans-unit id="fbdeef434a34fee928d2d9974f81cfc54768558d" translate="yes" xml:space="preserve">
          <source>This function returns posterior probabilities of classification according to each class on an array of test vectors X.</source>
          <target state="translated">Данная функция возвращает апостериорные вероятности классификации по каждому классу на массиве тестовых векторов X.</target>
        </trans-unit>
        <trans-unit id="f7adc46ef6325367984cfe5d6cabca879706d70d" translate="yes" xml:space="preserve">
          <source>This function returns the Silhouette Coefficient for each sample.</source>
          <target state="translated">Эта функция возвращает коэффициент силуэта для каждого образца.</target>
        </trans-unit>
        <trans-unit id="30221178098fdd3682a8c91454092d6226b25e4f" translate="yes" xml:space="preserve">
          <source>This function returns the mean Silhouette Coefficient over all samples. To obtain the values for each sample, use &lt;a href=&quot;sklearn.metrics.silhouette_samples#sklearn.metrics.silhouette_samples&quot;&gt;&lt;code&gt;silhouette_samples&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Эта функция возвращает средний коэффициент силуэта по всем выборкам. Чтобы получить значения для каждого образца, используйте &lt;a href=&quot;sklearn.metrics.silhouette_samples#sklearn.metrics.silhouette_samples&quot;&gt; &lt;code&gt;silhouette_samples&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="bd812dc35d867d7152375e5009e2698c8db08fc0" translate="yes" xml:space="preserve">
          <source>This function simply returns the valid pairwise distance metrics. It exists to allow for a description of the mapping for each of the valid strings.</source>
          <target state="translated">Эта функция просто возвращает действительные парные метрики расстояния.Она существует для того,чтобы можно было описать отображение для каждой из валидных строк.</target>
        </trans-unit>
        <trans-unit id="fa4705a70e55596dcf2ace89a6d2a8d09a9fcccf" translate="yes" xml:space="preserve">
          <source>This function simply returns the valid pairwise distance metrics. It exists, however, to allow for a verbose description of the mapping for each of the valid strings.</source>
          <target state="translated">Эта функция просто возвращает действительные парные метрики расстояния.Однако,она существует для того,чтобы обеспечить подробное описание отображения для каждой из валидных строк.</target>
        </trans-unit>
        <trans-unit id="d1a7a45215b31f0644d6e686c87b329e59419299" translate="yes" xml:space="preserve">
          <source>This function won&amp;rsquo;t compute the intercept.</source>
          <target state="translated">Эта функция не будет вычислять точку пересечения.</target>
        </trans-unit>
        <trans-unit id="a808622a520f852134a2d8734b9e29ce0a669efe" translate="yes" xml:space="preserve">
          <source>This function works with dense 2D arrays only.</source>
          <target state="translated">Эта функция работает только с плотными 2D массивами.</target>
        </trans-unit>
        <trans-unit id="19a23bf41918ee91955f633ce4d818d45490ef26" translate="yes" xml:space="preserve">
          <source>This function&amp;rsquo;s formula is as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7541ac358f5bb3bc5dcdfc1193ff72d6ac233a66" translate="yes" xml:space="preserve">
          <source>This generator method yields the ensemble predicted class probabilities after each iteration of boosting and therefore allows monitoring, such as to determine the predicted class probabilities on a test set after each boost.</source>
          <target state="translated">Этот метод генерации дает совокупность прогнозируемых классовых вероятностей после каждой итерации форсирования и,следовательно,позволяет проводить мониторинг,например,определять прогнозируемые классовые вероятности на тестовом наборе после каждой форсировки.</target>
        </trans-unit>
        <trans-unit id="7c1ad29f5d19940cf714626cd821b0934b5bc400" translate="yes" xml:space="preserve">
          <source>This generator method yields the ensemble prediction after each iteration of boosting and therefore allows monitoring, such as to determine the prediction on a test set after each boost.</source>
          <target state="translated">Этот метод генерации дает прогноз ансамбля после каждой итерации форсирования и,следовательно,позволяет осуществлять мониторинг,например,определять прогноз на тестовом наборе после каждой форсировки.</target>
        </trans-unit>
        <trans-unit id="acc74c06c673308a3e484c230b5ff2c8348cfe79" translate="yes" xml:space="preserve">
          <source>This generator method yields the ensemble score after each iteration of boosting and therefore allows monitoring, such as to determine the score on a test set after each boost.</source>
          <target state="translated">Этот метод генерации дает оценку ансамбля после каждой итерации форсировки и,следовательно,позволяет проводить мониторинг,например,определять оценку на тестовом наборе после каждой форсировки.</target>
        </trans-unit>
        <trans-unit id="1fe14f98435d58bb1786320c156e4b531f66e48b" translate="yes" xml:space="preserve">
          <source>This illustrates the &lt;a href=&quot;../../modules/generated/sklearn.datasets.make_multilabel_classification#sklearn.datasets.make_multilabel_classification&quot;&gt;&lt;code&gt;make_multilabel_classification&lt;/code&gt;&lt;/a&gt; dataset generator. Each sample consists of counts of two features (up to 50 in total), which are differently distributed in each of two classes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb7462acd1f1e763247c87d170997bea5c436272" translate="yes" xml:space="preserve">
          <source>This illustrates the &lt;code&gt;datasets.make_multilabel_classification&lt;/code&gt; dataset generator. Each sample consists of counts of two features (up to 50 in total), which are differently distributed in each of two classes.</source>
          <target state="translated">Это иллюстрирует генератор набора &lt;code&gt;datasets.make_multilabel_classification&lt;/code&gt; . Каждая выборка состоит из двух элементов (всего до 50), которые по-разному распределяются в каждом из двух классов.</target>
        </trans-unit>
        <trans-unit id="b80113eed9b4b9668cc4e8b638bede5d1f2cf638" translate="yes" xml:space="preserve">
          <source>This implementation bulk-computes all neighborhood queries, which increases the memory complexity to O(n.d) where d is the average number of neighbors, while original DBSCAN had memory complexity O(n). It may attract a higher memory complexity when querying these nearest neighborhoods, depending on the &lt;code&gt;algorithm&lt;/code&gt;.</source>
          <target state="translated">Эта реализация выполняет массовое вычисление всех запросов соседства, что увеличивает сложность памяти до O (nd), где d - среднее количество соседей, в то время как исходный DBSCAN имел сложность памяти O (n). В зависимости от &lt;code&gt;algorithm&lt;/code&gt; при запросе этих ближайших окрестностей может потребоваться более высокая сложность памяти .</target>
        </trans-unit>
        <trans-unit id="48627963240be2350bc0acdc732c6b5348961a90" translate="yes" xml:space="preserve">
          <source>This implementation deviates from the original OPTICS by first performing k-nearest-neighborhood searches on all points to identify core sizes, then computing only the distances to unprocessed points when constructing the cluster order. Note that we do not employ a heap to manage the expansion candidates, so the time complexity will be O(n^2).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aed3668d0e58719270c1129ddb01322705c078e7" translate="yes" xml:space="preserve">
          <source>This implementation follows what is explained in the original paper &lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;1&lt;/a&gt;. For the optimisation method, it currently uses scipy&amp;rsquo;s L-BFGS-B with a full gradient computation at each iteration, to avoid to tune the learning rate and provide stable learning.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92eb61902d4dfd6571a464d87feff72fe7b32901" translate="yes" xml:space="preserve">
          <source>This implementation is based on Rubinstein, R., Zibulevsky, M. and Elad, M., Efficient Implementation of the K-SVD Algorithm using Batch Orthogonal Matching Pursuit Technical Report - CS Technion, April 2008. &lt;a href=&quot;http://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&quot;&gt;http://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&lt;/a&gt;</source>
          <target state="translated">Эта реализация основана на материалах Rubinstein, R., Zibulevsky, M. и Elad, M., &amp;laquo;Эффективная реализация алгоритма K-SVD с использованием пакетного ортогонального сопоставления. Технический отчет&amp;raquo; - CS Technion, апрель 2008 г. &lt;a href=&quot;http://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&quot;&gt;http: //www.cs. technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="12813af32368fc3d74f568cdec1c9e38f408115a" translate="yes" xml:space="preserve">
          <source>This implementation is based on Rubinstein, R., Zibulevsky, M. and Elad, M., Efficient Implementation of the K-SVD Algorithm using Batch Orthogonal Matching Pursuit Technical Report - CS Technion, April 2008. &lt;a href=&quot;https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&quot;&gt;https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6fb112845601277f8931b295b857e73c1428c8fb" translate="yes" xml:space="preserve">
          <source>This implementation is by default not memory efficient because it constructs a full pairwise similarity matrix in the case where kd-trees or ball-trees cannot be used (e.g. with sparse matrices). This matrix will consume n^2 floats. A couple of mechanisms for getting around this are:</source>
          <target state="translated">Эта реализация по умолчанию не эффективна с точки зрения использования памяти,так как она строит полную матрицу парного сходства в случае,когда кд-деревья или шаровые деревья не могут быть использованы (например,с разреженными матрицами).Эта матрица будет потреблять n^2 с плавающей запятой.Пара механизмов обойти это:</target>
        </trans-unit>
        <trans-unit id="34d2660e23d61d989853bcf418296ddcc27d9606" translate="yes" xml:space="preserve">
          <source>This implementation is by default not memory efficient because it constructs a full pairwise similarity matrix in the case where kd-trees or ball-trees cannot be used (e.g., with sparse matrices). This matrix will consume n^2 floats. A couple of mechanisms for getting around this are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e691dc0883398091a16d8a17daee0ec7cd95f29" translate="yes" xml:space="preserve">
          <source>This implementation is inspired by &lt;a href=&quot;https://github.com/Microsoft/LightGBM&quot;&gt;LightGBM&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc51c30dcd01f51cada4be15777f17eb95eb7cbd" translate="yes" xml:space="preserve">
          <source>This implementation is not intended for large-scale applications. In particular, scikit-learn offers no GPU support. For much faster, GPU-based implementations, as well as frameworks offering much more flexibility to build deep learning architectures, see &lt;a href=&quot;http://scikit-learn.org/stable/related_projects.html#related-projects&quot;&gt;Related Projects&lt;/a&gt;.</source>
          <target state="translated">Эта реализация не предназначена для крупномасштабных приложений. В частности, scikit-learn не поддерживает GPU. Чтобы узнать о гораздо более быстрых реализациях на базе графического процессора, а также о фреймворках, предлагающих большую гибкость для создания архитектур глубокого обучения, см. &lt;a href=&quot;http://scikit-learn.org/stable/related_projects.html#related-projects&quot;&gt;Связанные проекты&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="228da043cb5452c21accbc429ac2d994bed0f4a9" translate="yes" xml:space="preserve">
          <source>This implementation is not intended for large-scale applications. In particular, scikit-learn offers no GPU support. For much faster, GPU-based implementations, as well as frameworks offering much more flexibility to build deep learning architectures, see &lt;a href=&quot;https://scikit-learn.org/0.23/related_projects.html#related-projects&quot;&gt;Related Projects&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e30a130e6449e6025aca5fcf59ecb737e97cb91" translate="yes" xml:space="preserve">
          <source>This implementation is written in Cython and is reasonably fast. However, a faster API-compatible loader is also available at:</source>
          <target state="translated">Эта реализация написана на языке Cython и достаточно быстрая.Тем не менее,более быстрый API-совместимый загрузчик также доступен на сайте:</target>
        </trans-unit>
        <trans-unit id="b488dd9d3cb1238d47d93805595214963db6dd0c" translate="yes" xml:space="preserve">
          <source>This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix.</source>
          <target state="translated">Эта реализация производит разреженное представление числа с использованием scipy.sparse.csr_matrix.</target>
        </trans-unit>
        <trans-unit id="42bc7bbc3f5bd0df8efbfbad62976f6ec6db583b" translate="yes" xml:space="preserve">
          <source>This implementation provides the same results that 3 PLS packages provided in the R language (R-project):</source>
          <target state="translated">Эта реализация дает тот же результат,что и 3 пакета PLS,предоставленных на языке R (R-проект):</target>
        </trans-unit>
        <trans-unit id="09c013dbb84b7e3d406ea0732bc3a8236ed37cbd" translate="yes" xml:space="preserve">
          <source>This implementation provides the same results that the &amp;ldquo;plspm&amp;rdquo; package provided in the R language (R-project), using the function plsca(X, Y). Results are equal or collinear with the function &lt;code&gt;pls(..., mode = &quot;canonical&quot;)&lt;/code&gt; of the &amp;ldquo;mixOmics&amp;rdquo; package. The difference relies in the fact that mixOmics implementation does not exactly implement the Wold algorithm since it does not normalize y_weights to one.</source>
          <target state="translated">Эта реализация обеспечивает те же результаты, что и пакет &amp;laquo;plspm&amp;raquo;, предоставленный на языке R (R-проект), с использованием функции plsca (X, Y). Результаты совпадают или коллинеарны с функцией &lt;code&gt;pls(..., mode = &quot;canonical&quot;)&lt;/code&gt; пакета &amp;laquo;mixOmics&amp;raquo;. Разница заключается в том, что реализация mixOmics не совсем реализует алгоритм Уолда, поскольку не нормализует y_weights до единицы.</target>
        </trans-unit>
        <trans-unit id="36e4a374c505873717456a086d5c9ed44e5157f6" translate="yes" xml:space="preserve">
          <source>This implementation will refuse to center scipy.sparse matrices since it would make them non-sparse and would potentially crash the program with memory exhaustion problems.</source>
          <target state="translated">Эта реализация откажется централизовать матрицы scipy.sparse,так как это сделает их неразборчивыми и потенциально приведет к аварийному завершению программы с проблемами исчерпания памяти.</target>
        </trans-unit>
        <trans-unit id="6684c1532df5f751b6b61c242ea952621dc3f4e8" translate="yes" xml:space="preserve">
          <source>This implementation works with data represented as dense and sparse numpy arrays of floating point values.</source>
          <target state="translated">Эта реализация работает с данными,представленными в виде плотных и разреженных нумеровых массивов значений с плавающей точкой.</target>
        </trans-unit>
        <trans-unit id="b0df3cb22108e4cd0ed0fcd534ed03e427412c64" translate="yes" xml:space="preserve">
          <source>This implementation works with data represented as dense numpy arrays of floating point values for the features.</source>
          <target state="translated">Эта реализация работает с данными,представленными в виде плотных нумерованных массивов значений с плавающей точкой для элементов.</target>
        </trans-unit>
        <trans-unit id="4abb3ee00da8e0ef45c7b10f884f8d272712ca81" translate="yes" xml:space="preserve">
          <source>This implementation works with data represented as dense numpy arrays or sparse scipy arrays of floating point values.</source>
          <target state="translated">Эта реализация работает с данными,представленными в виде плотных нумерованных массивов или разреженных массивов значений с плавающей точкой.</target>
        </trans-unit>
        <trans-unit id="c3c22c958df17cff584f8c572beeb762a9a0290e" translate="yes" xml:space="preserve">
          <source>This implementation works with data represented as dense or sparse arrays of floating point values for the features. The model it fits can be controlled with the loss parameter; by default, it fits a linear support vector machine (SVM).</source>
          <target state="translated">Эта реализация работает с данными,представленными в виде плотных или разреженных массивов значений с плавающей точкой для элементов.Модель,в которую она вписывается,может управляться параметром потерь;по умолчанию она вписывается в линейную векторную машину поддержки (SVM).</target>
        </trans-unit>
        <trans-unit id="c43a7d8bb7931a79100804db2f074a29d45e4b6b" translate="yes" xml:space="preserve">
          <source>This improvement is not visible in the Silhouette Coefficient which is small for both as this measure seem to suffer from the phenomenon called &amp;ldquo;Concentration of Measure&amp;rdquo; or &amp;ldquo;Curse of Dimensionality&amp;rdquo; for high dimensional datasets such as text data. Other measures such as V-measure and Adjusted Rand Index are information theoretic based evaluation scores: as they are only based on cluster assignments rather than distances, hence not affected by the curse of dimensionality.</source>
          <target state="translated">Это улучшение не видно в силуэтном коэффициенте, который невелик для обоих, поскольку эта мера, похоже, страдает от явления, называемого &amp;laquo;концентрация меры&amp;raquo; или &amp;laquo;проклятие размерности&amp;raquo; для многомерных наборов данных, таких как текстовые данные. Другие меры, такие как V-мера и Скорректированный индекс ранда, представляют собой оценочные баллы, основанные на теории информации: поскольку они основаны только на кластерных присвоениях, а не на расстояниях, поэтому на них не влияет проклятие размерности.</target>
        </trans-unit>
        <trans-unit id="18d0a71ee91c72fbdd2b834782dff2f0f441f1d5" translate="yes" xml:space="preserve">
          <source>This index signifies the average &amp;lsquo;similarity&amp;rsquo; between clusters, where the similarity is a measure that compares the distance between clusters with the size of the clusters themselves.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0d4ffe805942e66e32866a4eb458e728074d78e" translate="yes" xml:space="preserve">
          <source>This initially creates clusters of points normally distributed (std=1) about vertices of an &lt;code&gt;n_informative&lt;/code&gt;-dimensional hypercube with sides of length &lt;code&gt;2*class_sep&lt;/code&gt; and assigns an equal number of clusters to each class. It introduces interdependence between these features and adds various types of further noise to the data.</source>
          <target state="translated">Первоначально это создает кластеры нормально распределенных точек (std = 1) вокруг вершин &lt;code&gt;n_informative&lt;/code&gt; - мерного гиперкуба со сторонами длиной &lt;code&gt;2*class_sep&lt;/code&gt; и присваивает равное количество кластеров каждому классу. Он вводит взаимозависимость между этими функциями и добавляет к данным различные типы дополнительного шума.</target>
        </trans-unit>
        <trans-unit id="57108bb9f4ef70d6ebe6d73913a67e52e844d200" translate="yes" xml:space="preserve">
          <source>This interface is &lt;strong&gt;experimental&lt;/strong&gt; and subsequent releases may change attributes without notice (although there should only be minor changes to &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b14c6be212126cf2e3bdc1fe1c6fe8f3c7dc46d" translate="yes" xml:space="preserve">
          <source>This interface is &lt;strong&gt;experimental&lt;/strong&gt; as at version 0.20 and subsequent releases may change attributes without notice (although there should only be minor changes to &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt;).</source>
          <target state="translated">Этот интерфейс является &lt;strong&gt;экспериментальным,&lt;/strong&gt; начиная с версии 0.20, и последующие выпуски могут изменять атрибуты без уведомления (хотя должны быть только незначительные изменения &lt;code&gt;data&lt;/code&gt; и &lt;code&gt;target&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="7f6be37b4617684744b3ccc169d2c583b6e3ddc1" translate="yes" xml:space="preserve">
          <source>This is a convenience alias to &lt;code&gt;resample(*arrays, replace=False)&lt;/code&gt; to do random permutations of the collections.</source>
          <target state="translated">Это удобный псевдоним для &lt;code&gt;resample(*arrays, replace=False)&lt;/code&gt; для произвольных перестановок коллекций.</target>
        </trans-unit>
        <trans-unit id="4632bc2ee98a17257db1d248b06f38b79a53d4ef" translate="yes" xml:space="preserve">
          <source>This is a convenience function; the transformation is done using the default settings for &lt;a href=&quot;sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt;&lt;/a&gt;. For more advanced usage (stopword filtering, n-gram extraction, etc.), combine fetch_20newsgroups with a custom &lt;a href=&quot;sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.HashingVectorizer&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.TfidfTransformer&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.TfidfVectorizer&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Это удобная функция; преобразование выполняется с использованием настроек по умолчанию для &lt;a href=&quot;sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt; &lt;/a&gt; . Для получения более продвинутого использования (фильтрация стоп - слов, н-грамм для экстракции и т.д.), объединить fetch_20newsgroups с пользовательской &lt;a href=&quot;sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.HashingVectorizer&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.TfidfTransformer&lt;/code&gt; &lt;/a&gt; или &lt;a href=&quot;sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.TfidfVectorizer&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2b3dbf5e1c5e08d66c77786f2bcbc632afc0312a" translate="yes" xml:space="preserve">
          <source>This is a convenience routine for the sake of testing. For many metrics, the utilities in scipy.spatial.distance.cdist and scipy.spatial.distance.pdist will be faster.</source>
          <target state="translated">Это удобная рутина для тестирования.Для многих метрик утилиты в scipy.spatial.distance.cdist и scipy.spatial.distance.pdist будут работать быстрее.</target>
        </trans-unit>
        <trans-unit id="7a67e0a846a2ab3c88cb06fc2b7950cd30914abe" translate="yes" xml:space="preserve">
          <source>This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets. &lt;a href=&quot;https://goo.gl/U2Uwz2&quot;&gt;https://goo.gl/U2Uwz2&lt;/a&gt;</source>
          <target state="translated">Это копия наборов данных UCI ML Breast Cancer Wisconsin (Diagnostic). &lt;a href=&quot;https://goo.gl/U2Uwz2&quot;&gt;https://goo.gl/U2Uwz2&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="22bae61d9be3213577df5087cb01b12cfdf8dff4" translate="yes" xml:space="preserve">
          <source>This is a copy of UCI ML Wine recognition datasets. &lt;a href=&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&quot;&gt;https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&lt;/a&gt;</source>
          <target state="translated">Это копия наборов данных распознавания UCI ML Wine. &lt;a href=&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&quot;&gt;https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c52f45448ee0e84b694b7c38bdbed7fd0e586461" translate="yes" xml:space="preserve">
          <source>This is a copy of UCI ML housing dataset. &lt;a href=&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/housing/&quot;&gt;https://archive.ics.uci.edu/ml/machine-learning-databases/housing/&lt;/a&gt;</source>
          <target state="translated">Это копия набора данных о жилищном строительстве UCI ML. &lt;a href=&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/housing/&quot;&gt;https://archive.ics.uci.edu/ml/machine-learning-databases/housing/&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a6d742ac48191eb71d1c4aabf6003187f0d21a9d" translate="yes" xml:space="preserve">
          <source>This is a copy of the test set of the UCI ML hand-written digits datasets</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3dee2146876159a5a0b048cd24a612fae4a810ca" translate="yes" xml:space="preserve">
          <source>This is a copy of the test set of the UCI ML hand-written digits datasets &lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&quot;&gt;http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&lt;/a&gt;</source>
          <target state="translated">Это копия тестового набора наборов рукописных цифр UCI ML &lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&quot;&gt;http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="60177910f782c7923853f8284b0287f57e3bf220" translate="yes" xml:space="preserve">
          <source>This is a copy of the test set of the UCI ML hand-written digits datasets &lt;a href=&quot;https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&quot;&gt;https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd4a60c08b29c6d6af237f8cfa14740252c7d04a" translate="yes" xml:space="preserve">
          <source>This is a general function, given points on a curve. For computing the area under the ROC-curve, see &lt;a href=&quot;sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt;. For an alternative way to summarize a precision-recall curve, see &lt;a href=&quot;sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Это общая функция для заданных точек на кривой. Для вычисления площади под ROC-кривой см. &lt;a href=&quot;sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;roc_auc_score&lt;/code&gt; &lt;/a&gt; . Для альтернативного способа суммирования кривой точности-отзыва см. &lt;a href=&quot;sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="3944e3eb8c8ea1f918637d2548f35fa74cd97d2a" translate="yes" xml:space="preserve">
          <source>This is a shorthand for the ColumnTransformer constructor; it does not require, and does not permit, naming the transformers. Instead, they will be given names automatically based on their types. It also does not allow weighting with &lt;code&gt;transformer_weights&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37510c6c60985c0ea76b5bcc4364db965e5a12fd" translate="yes" xml:space="preserve">
          <source>This is a shorthand for the ColumnTransformer constructor; it does not require, and does not permit, naming the transformers. Instead, they will be given names automatically based on their types. It also does not allow weighting.</source>
          <target state="translated">Это сокращение для конструктора &quot;колонна-трансформатор&quot;;оно не требует и не позволяет называть трансформаторы.Вместо этого им будут даны имена автоматически на основе их типов.Он также не допускает взвешивания.</target>
        </trans-unit>
        <trans-unit id="022d95ed0540e35ea0bdce867e9a502603bc5f51" translate="yes" xml:space="preserve">
          <source>This is a shorthand for the FeatureUnion constructor; it does not require, and does not permit, naming the transformers. Instead, they will be given names automatically based on their types. It also does not allow weighting.</source>
          <target state="translated">Это сокращение для конструктора FeatureUnion;оно не требует и не позволяет называть трансформаторы.Вместо этого им будут даны имена автоматически в зависимости от их типов.Он также не допускает взвешивания.</target>
        </trans-unit>
        <trans-unit id="52a890ca0cc5d284d366294db21e8c380349733e" translate="yes" xml:space="preserve">
          <source>This is a shorthand for the Pipeline constructor; it does not require, and does not permit, naming the estimators. Instead, their names will be set to the lowercase of their types automatically.</source>
          <target state="translated">Это сокращение для &quot;Строителя газопровода&quot;;оно не требует и не позволяет называть оценщиков.Вместо этого,их имена будут автоматически установлены в нижний регистр их типов.</target>
        </trans-unit>
        <trans-unit id="bcbf4cb6d3eb7ea12d02241a9a60f7a4e6044f4d" translate="yes" xml:space="preserve">
          <source>This is a wrapper for &lt;code&gt;estimator_.predict(X)&lt;/code&gt;.</source>
          <target state="translated">Это оболочка для &lt;code&gt;estimator_.predict(X)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="17ebe8027dbbfba976bb150f0e9172e06d0c02ec" translate="yes" xml:space="preserve">
          <source>This is a wrapper for &lt;code&gt;estimator_.score(X, y)&lt;/code&gt;.</source>
          <target state="translated">Это оболочка для &lt;code&gt;estimator_.score(X, y)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="602675ab661ad893c615b29b13c1d56146fcfa0b" translate="yes" xml:space="preserve">
          <source>This is an alternative to passing a &lt;code&gt;backend='backend_name'&lt;/code&gt; argument to the &lt;code&gt;Parallel&lt;/code&gt; class constructor. It is particularly useful when calling into library code that uses joblib internally but does not expose the backend argument in its own API.</source>
          <target state="translated">Это альтернатива передаче аргумента &lt;code&gt;backend='backend_name'&lt;/code&gt; конструктору класса &lt;code&gt;Parallel&lt;/code&gt; . Это особенно полезно при вызове кода библиотеки, который внутренне использует joblib, но не предоставляет аргумент backend в собственном API.</target>
        </trans-unit>
        <trans-unit id="47f9c3947e84bb8a914aa6f2f19cb2c5e42e970f" translate="yes" xml:space="preserve">
          <source>This is an example of &lt;strong&gt;bias/variance tradeoff&lt;/strong&gt;: the larger the ridge &lt;code&gt;alpha&lt;/code&gt; parameter, the higher the bias and the lower the variance.</source>
          <target state="translated">Это пример &lt;strong&gt;компромисса смещения / дисперсии&lt;/strong&gt; : чем больше параметр &lt;code&gt;alpha&lt;/code&gt; гребня , тем выше смещение и тем ниже дисперсия.</target>
        </trans-unit>
        <trans-unit id="d75c7c933c17fefbabe7c2e292b885d0ecac3a21" translate="yes" xml:space="preserve">
          <source>This is an example of applying &lt;a href=&quot;../../modules/generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;sklearn.decomposition.NMF&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../modules/generated/sklearn.decomposition.latentdirichletallocation#sklearn.decomposition.LatentDirichletAllocation&quot;&gt;&lt;code&gt;sklearn.decomposition.LatentDirichletAllocation&lt;/code&gt;&lt;/a&gt; on a corpus of documents and extract additive models of the topic structure of the corpus. The output is a list of topics, each represented as a list of terms (weights are not shown).</source>
          <target state="translated">Это пример применения &lt;a href=&quot;../../modules/generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt; &lt;code&gt;sklearn.decomposition.NMF&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;../../modules/generated/sklearn.decomposition.latentdirichletallocation#sklearn.decomposition.LatentDirichletAllocation&quot;&gt; &lt;code&gt;sklearn.decomposition.LatentDirichletAllocation&lt;/code&gt; &lt;/a&gt; к корпусу документов и извлечения аддитивных моделей тематической структуры корпуса. Результатом является список тем, каждая из которых представлена ​​в виде списка терминов (веса не показаны).</target>
        </trans-unit>
        <trans-unit id="53176f2993974522405fa17c9a80a84e38a4969c" translate="yes" xml:space="preserve">
          <source>This is an example showing how scikit-learn can be used for classification using an out-of-core approach: learning from data that doesn&amp;rsquo;t fit into main memory. We make use of an online classifier, i.e., one that supports the partial_fit method, that will be fed with batches of examples. To guarantee that the features space remains the same over time we leverage a HashingVectorizer that will project each example into the same feature space. This is especially useful in the case of text classification where new features (words) may appear in each batch.</source>
          <target state="translated">Это пример, показывающий, как scikit-learn можно использовать для классификации с использованием внепрограммного подхода: обучение на основе данных, которые не помещаются в основную память. Мы используем онлайн-классификатор, т. Е. Тот, который поддерживает метод partial_fit, который будет снабжаться пакетами примеров. Чтобы гарантировать, что пространство функций остается неизменным с течением времени, мы используем HashingVectorizer, который будет проецировать каждый пример в одно и то же пространство функций. Это особенно полезно в случае классификации текста, когда в каждом пакете могут появиться новые функции (слова).</target>
        </trans-unit>
        <trans-unit id="1620bf9fc1f7795235eabc8e2a67657eca16390d" translate="yes" xml:space="preserve">
          <source>This is an example showing how scikit-learn can be used to classify documents by topics using a bag-of-words approach. This example uses a scipy.sparse matrix to store the features and demonstrates various classifiers that can efficiently handle sparse matrices.</source>
          <target state="translated">Это пример,показывающий,как scikit-learn может быть использован для классификации документов по темам с использованием подхода &quot;пакет слов&quot;.В этом примере используется матрица scipy.sparse для хранения функций и демонстрируются различные классификаторы,которые могут эффективно работать с разреженными матрицами.</target>
        </trans-unit>
        <trans-unit id="687fdb042e4ef171de769c4722977550577ec678" translate="yes" xml:space="preserve">
          <source>This is an example showing how the scikit-learn can be used to cluster documents by topics using a bag-of-words approach. This example uses a scipy.sparse matrix to store the features instead of standard numpy arrays.</source>
          <target state="translated">Это пример,показывающий,как scikit-learn может быть использован для группировки документов по темам с использованием подхода &quot;пакет слов&quot;.В этом примере используется матрица scipy.sparse для хранения функций вместо стандартных нумерованных массивов.</target>
        </trans-unit>
        <trans-unit id="c505c2f7b70a5aa0d5582bdc56a7d9627b32a4d8" translate="yes" xml:space="preserve">
          <source>This is an example showing the prediction latency of various scikit-learn estimators.</source>
          <target state="translated">Это пример,показывающий латентность предсказаний различных научно-образовательных оценщиков.</target>
        </trans-unit>
        <trans-unit id="9e4f7a05490ee1267f03d9980bace7147baa0b76" translate="yes" xml:space="preserve">
          <source>This is an extension of the algorithm in scipy.stats.mode.</source>
          <target state="translated">Это расширение алгоритма в режиме scipy.stats.mode.</target>
        </trans-unit>
        <trans-unit id="375819c22c211b4c7fc97205acd724c3a575f620" translate="yes" xml:space="preserve">
          <source>This is an implementation that uses the result of the previous model to speed up computations along the set of solutions, making it faster than sequentially calling LogisticRegression for the different parameters. Note that there will be no speedup with liblinear solver, since it does not handle warm-starting.</source>
          <target state="translated">Это реализация,использующая результат предыдущей модели для ускорения вычислений по набору решений,что делает ее быстрее,чем последовательный вызов LogisticRegression для различных параметров.Обратите внимание,что при использовании liblinear solver ускорения не будет,так как он не обрабатывает тепловой старт.</target>
        </trans-unit>
        <trans-unit id="89098058da4c55a1db96b87aadaa162a0a15baba" translate="yes" xml:space="preserve">
          <source>This is assumed to implement the scikit-learn estimator interface. Either estimator needs to provide a &lt;code&gt;score&lt;/code&gt; function, or &lt;code&gt;scoring&lt;/code&gt; must be passed.</source>
          <target state="translated">Предполагается, что это реализует интерфейс оценщика scikit-learn. Либо оценщик должен обеспечить &lt;code&gt;score&lt;/code&gt; функцию, или &lt;code&gt;scoring&lt;/code&gt; должен быть принят.</target>
        </trans-unit>
        <trans-unit id="a9f1a5b0fa7d00ad69170d1ab81bf1031dee11a2" translate="yes" xml:space="preserve">
          <source>This is called a &lt;a href=&quot;../../modules/generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; cross-validation.</source>
          <target state="translated">Это называется перекрестной проверкой &lt;a href=&quot;../../modules/generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2e974743bc0fdffbf7238debaf0ee76bb5a5d9b2" translate="yes" xml:space="preserve">
          <source>This is called cosine similarity, because Euclidean (L2) normalization projects the vectors onto the unit sphere, and their dot product is then the cosine of the angle between the points denoted by the vectors.</source>
          <target state="translated">Это называется косинусным сходством,поскольку евклидовая нормализация (L2)проецирует векторы на единичную сферу,а их точечным произведением является косинус угла между точками,обозначенными векторами.</target>
        </trans-unit>
        <trans-unit id="9b01365512b47448f649e450ddd111360a73cfc3" translate="yes" xml:space="preserve">
          <source>This is called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Curse_of_dimensionality&quot;&gt;curse of dimensionality&lt;/a&gt; and is a core problem that machine learning addresses.</source>
          <target state="translated">Это называется &lt;a href=&quot;https://en.wikipedia.org/wiki/Curse_of_dimensionality&quot;&gt;проклятием размерности&lt;/a&gt; и является основной проблемой, которую решает машинное обучение.</target>
        </trans-unit>
        <trans-unit id="25e5e11d6a0e13a60841f1cb72db59989d03472f" translate="yes" xml:space="preserve">
          <source>This is currently implemented in the following classes:</source>
          <target state="translated">В настоящее время это реализовано в следующих классах:</target>
        </trans-unit>
        <trans-unit id="a774a1be5070f83615f896d6d2ec16ebfbe92e4e" translate="yes" xml:space="preserve">
          <source>This is done in 2 steps:</source>
          <target state="translated">Это делается в два этапа:</target>
        </trans-unit>
        <trans-unit id="0c564a0d4cfad247ff47792f5a12558130a84f0c" translate="yes" xml:space="preserve">
          <source>This is equivalent to fit followed by transform, but more efficiently implemented.</source>
          <target state="translated">Это эквивалентно подгонке с последующим преобразованием,но более эффективно реализуется.</target>
        </trans-unit>
        <trans-unit id="831022bba18e9ed70a7a762cd8243e7523afeddb" translate="yes" xml:space="preserve">
          <source>This is especially useful when the whole dataset is too big to fit in memory at once.</source>
          <target state="translated">Это особенно полезно,когда весь набор данных слишком велик,чтобы поместиться в память сразу.</target>
        </trans-unit>
        <trans-unit id="75c0bef753e28aecf63e47221c52fe362a027981" translate="yes" xml:space="preserve">
          <source>This is implemented as &lt;code&gt;argmax(decision_function(X), axis=1)&lt;/code&gt; which will return the label of the class with most votes by estimators predicting the outcome of a decision for each possible class pair.</source>
          <target state="translated">Это реализовано как &lt;code&gt;argmax(decision_function(X), axis=1)&lt;/code&gt; который вернет метку класса с наибольшим количеством голосов от оценщиков, предсказывающих результат решения для каждой возможной пары классов.</target>
        </trans-unit>
        <trans-unit id="9b2a6723fed7b2d139e18e341020f963dc7f8450" translate="yes" xml:space="preserve">
          <source>This is implemented by linking the points X into the graph of geodesic distances of the training data. First the &lt;code&gt;n_neighbors&lt;/code&gt; nearest neighbors of X are found in the training data, and from these the shortest geodesic distances from each point in X to each point in the training data are computed in order to construct the kernel. The embedding of X is the projection of this kernel onto the embedding vectors of the training set.</source>
          <target state="translated">Это реализуется путем привязки точек X к графику геодезических расстояний обучающих данных. Сначала в &lt;code&gt;n_neighbors&lt;/code&gt; данных находятся n_neighbors, ближайшие соседи X, и из них вычисляются кратчайшие геодезические расстояния от каждой точки в X до каждой точки в обучающих данных, чтобы построить ядро. Вложение X - это проекция этого ядра на векторы вложения обучающей выборки.</target>
        </trans-unit>
        <trans-unit id="51ae8a82b3eff6fb295f70aa28171d41c73ac3db" translate="yes" xml:space="preserve">
          <source>This is implemented in &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.transform&lt;/code&gt;&lt;/a&gt;. The desired dimensionality can be set using the &lt;code&gt;n_components&lt;/code&gt; constructor parameter. This parameter has no influence on &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.fit&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.predict&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Это реализовано в &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.transform&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;n_components&lt;/code&gt; размерность можно установить с помощью параметра конструктора n_components . Этот параметр не влияет на &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.fit&lt;/code&gt; &lt;/a&gt; или &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.predict&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="8989f9efb82b77a4f24da08f40263dc49964cf0b" translate="yes" xml:space="preserve">
          <source>This is implemented in the &lt;code&gt;transform&lt;/code&gt; method. The desired dimensionality can be set using the &lt;code&gt;n_components&lt;/code&gt; parameter. This parameter has no influence on the &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt; methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de8220f3c95931fc4241bdd5334e66fca04da2f0" translate="yes" xml:space="preserve">
          <source>This is known as &lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Это называется &lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="1c0b6d6227299e9452904f2af6316a83adba923a" translate="yes" xml:space="preserve">
          <source>This is minimized if \(h(x_i)\) is fitted to predict a value that is proportional to the negative gradient \(-g_i\). Therefore, at each iteration, &lt;strong&gt;the estimator&lt;/strong&gt;\(h_m\)&lt;strong&gt;is fitted to predict the negative gradients of the samples&lt;/strong&gt;. The gradients are updated at each iteration. This can be considered as some kind of gradient descent in a functional space.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d1ef16c8ffe6df8c7a1a81b132f67cdda1b92ea" translate="yes" xml:space="preserve">
          <source>This is more efficient than calling fit followed by transform.</source>
          <target state="translated">Это более эффективно,чем называть соответствие,за которым следует преобразование.</target>
        </trans-unit>
        <trans-unit id="1dfb3afc660617ced3002fefa24847b5bb1a14dd" translate="yes" xml:space="preserve">
          <source>This is mostly equivalent to calling:</source>
          <target state="translated">Это в основном эквивалентно звонку:</target>
        </trans-unit>
        <trans-unit id="bbd51f304b678a157464ff7ab03c52123d04218d" translate="yes" xml:space="preserve">
          <source>This is not a symmetric function.</source>
          <target state="translated">Это не симметричная функция.</target>
        </trans-unit>
        <trans-unit id="0b5c42967b0e34c52656dd80a4e659c6f0fa2181" translate="yes" xml:space="preserve">
          <source>This is not exactly the same as &lt;code&gt;sklearn.metrics.additive_chi2_kernel&lt;/code&gt;. The authors of &lt;a href=&quot;#vz2010&quot; id=&quot;id4&quot;&gt;[VZ2010]&lt;/a&gt; prefer the version above as it is always positive definite. Since the kernel is additive, it is possible to treat all components \(x_i\) separately for embedding. This makes it possible to sample the Fourier transform in regular intervals, instead of approximating using Monte Carlo sampling.</source>
          <target state="translated">Это не совсем то же самое, что &lt;code&gt;sklearn.metrics.additive_chi2_kernel&lt;/code&gt; . Авторы &lt;a href=&quot;#vz2010&quot; id=&quot;id4&quot;&gt;[VZ2010]&lt;/a&gt; предпочитают версию выше, так как она всегда положительно определена. Поскольку ядро ​​является аддитивным, можно рассматривать все компоненты \ (x_i \) отдельно для встраивания. Это позволяет делать выборку преобразования Фурье через равные промежутки времени вместо аппроксимации с использованием выборки Монте-Карло.</target>
        </trans-unit>
        <trans-unit id="f7f802fcac19c1c8ed1c55f673312d761a2c94a7" translate="yes" xml:space="preserve">
          <source>This is not the case for &lt;a href=&quot;generated/sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt;&lt;code&gt;completeness_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt;&lt;code&gt;homogeneity_score&lt;/code&gt;&lt;/a&gt;: both are bound by the relationship:</source>
          <target state="translated">Это не относится к &lt;a href=&quot;generated/sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt; &lt;code&gt;completeness_score&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt; &lt;code&gt;homogeneity_score&lt;/code&gt; &lt;/a&gt; : оба связаны отношением:</target>
        </trans-unit>
        <trans-unit id="5d73f5b087f2ecb2dadb8778d3d18cfc19507034" translate="yes" xml:space="preserve">
          <source>This is not true for &lt;code&gt;mutual_info_score&lt;/code&gt;, which is therefore harder to judge:</source>
          <target state="translated">Это неверно для &lt;code&gt;mutual_info_score&lt;/code&gt; , поэтому судить о нем труднее:</target>
        </trans-unit>
        <trans-unit id="982101a3d677907e48e034c807cde26531a0468b" translate="yes" xml:space="preserve">
          <source>This is only available if no vocabulary was given.</source>
          <target state="translated">Это доступно только в том случае,если не был дан словарь.</target>
        </trans-unit>
        <trans-unit id="0ca1a333516e3b52907835d092958662636ea528" translate="yes" xml:space="preserve">
          <source>This is particularly important for doing grid searches:</source>
          <target state="translated">Это особенно важно при поиске по сетке:</target>
        </trans-unit>
        <trans-unit id="2413be66af5e312ff97e484aff33c56868971fbe" translate="yes" xml:space="preserve">
          <source>This is perhaps the best known database to be found in the pattern recognition literature. Fisher&amp;rsquo;s paper is a classic in the field and is referenced frequently to this day. (See Duda &amp;amp; Hart, for example.) The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other.</source>
          <target state="translated">Это, пожалуй, самая известная база данных, которую можно найти в литературе по распознаванию образов. Работа Фишера - классика в этой области, на которую часто ссылаются по сей день. (См., Например, Duda &amp;amp; Hart.) Набор данных содержит 3 класса по 50 экземпляров каждый, где каждый класс относится к типу растения ириса. Один класс линейно отделим от двух других; последние НЕ отделимы друг от друга линейно.</target>
        </trans-unit>
        <trans-unit id="32ef6d8e689e0cbccf726fb7a94339c2864c487f" translate="yes" xml:space="preserve">
          <source>This is present only if &lt;code&gt;refit&lt;/code&gt; is not False.</source>
          <target state="translated">Это присутствует, только если &lt;code&gt;refit&lt;/code&gt; не False.</target>
        </trans-unit>
        <trans-unit id="717414c2af196799a3d1dc1aec1269a995318377" translate="yes" xml:space="preserve">
          <source>This is similar to the error set size, but weighted by the number of relevant and irrelevant labels. The best performance is achieved with a ranking loss of zero.</source>
          <target state="translated">Это похоже на размер набора ошибок,но взвешено по количеству релевантных и не релевантных этикеток.Наилучшая производительность достигается при нулевой потере рейтинга.</target>
        </trans-unit>
        <trans-unit id="00034266cafd87d919959c8134650d981f2c4466" translate="yes" xml:space="preserve">
          <source>This is the class and function reference of scikit-learn. Please refer to the &lt;a href=&quot;http://scikit-learn.org/stable/user_guide.html#user-guide&quot;&gt;full user guide&lt;/a&gt; for further details, as the class and function raw specifications may not be enough to give full guidelines on their uses. For reference on concepts repeated across the API, see &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#glossary&quot;&gt;Glossary of Common Terms and API Elements&lt;/a&gt;.</source>
          <target state="translated">Это справочник по классам и функциям scikit-learn. Пожалуйста, обратитесь к &lt;a href=&quot;http://scikit-learn.org/stable/user_guide.html#user-guide&quot;&gt;полному руководству пользователя&lt;/a&gt; для получения дополнительной информации, так как необработанных спецификаций классов и функций может быть недостаточно, чтобы дать полные рекомендации по их использованию. Справочные сведения о концепциях, повторяющихся в API, см. В &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#glossary&quot;&gt;Глоссарии общих терминов и элементов API&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0706513e1a92902a9b1d8477404304aebd12678b" translate="yes" xml:space="preserve">
          <source>This is the class and function reference of scikit-learn. Please refer to the &lt;a href=&quot;https://scikit-learn.org/0.23/user_guide.html#user-guide&quot;&gt;full user guide&lt;/a&gt; for further details, as the class and function raw specifications may not be enough to give full guidelines on their uses. For reference on concepts repeated across the API, see &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#glossary&quot;&gt;Glossary of Common Terms and API Elements&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="486cb190a77f54ef106791f7b4834d94d87b42d4" translate="yes" xml:space="preserve">
          <source>This is the loss function used in (multinomial) logistic regression and extensions of it such as neural networks, defined as the negative log-likelihood of a logistic model that returns &lt;code&gt;y_pred&lt;/code&gt; probabilities for its training data &lt;code&gt;y_true&lt;/code&gt;. The log loss is only defined for two or more labels. For a single sample with true label yt in {0,1} and estimated probability yp that yt = 1, the log loss is</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c0b38fb17b983574b86706f2172c4c4bac1c6a5" translate="yes" xml:space="preserve">
          <source>This is the loss function used in (multinomial) logistic regression and extensions of it such as neural networks, defined as the negative log-likelihood of the true labels given a probabilistic classifier&amp;rsquo;s predictions. The log loss is only defined for two or more labels. For a single sample with true label yt in {0,1} and estimated probability yp that yt = 1, the log loss is</source>
          <target state="translated">Это функция потерь, используемая в (полиномиальной) логистической регрессии и ее расширениях, таких как нейронные сети, определяемая как отрицательная логарифмическая вероятность истинных меток с учетом прогнозов вероятностного классификатора. Потеря журнала определяется только для двух или более меток. Для одной выборки с истинной меткой yt в {0,1} и предполагаемой вероятностью yp того, что yt = 1, логарифмические потери составляют</target>
        </trans-unit>
        <trans-unit id="a9111de5c7f4d9db0e2dc4faf926c5c47ae0eb12" translate="yes" xml:space="preserve">
          <source>This is the result of calling &lt;code&gt;method&lt;/code&gt;</source>
          <target state="translated">Это результат вызова &lt;code&gt;method&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="611492c50f944d397ce592f12eabee4801e28de1" translate="yes" xml:space="preserve">
          <source>This is the structured version, that takes into account some topological structure between samples.</source>
          <target state="translated">Это структурированная версия,учитывающая некоторую топологическую структуру между выборками.</target>
        </trans-unit>
        <trans-unit id="eb0a6c68cdbb70ef7265210b8b8760243faa6912" translate="yes" xml:space="preserve">
          <source>This is useful for fitting an intercept term with implementations which cannot otherwise fit it directly.</source>
          <target state="translated">Это полезно для подгонки термина перехвата под реализации,которые в противном случае не смогут подогнать его напрямую.</target>
        </trans-unit>
        <trans-unit id="1c420e62ce6697ac415dbca5798c0153080b025c" translate="yes" xml:space="preserve">
          <source>This is useful if the stored attributes of a previously used model has to be reused. If set to False, then the coefficients will be rewritten for every call to fit. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Это полезно, если необходимо повторно использовать сохраненные атрибуты ранее использованной модели. Если установлено значение False, то коэффициенты будут переписываться для каждого вызова, чтобы соответствовать. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;Глоссарий&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="036c7996302f5b904a8b61c47c147a7a9733676a" translate="yes" xml:space="preserve">
          <source>This is useful if the stored attributes of a previously used model has to be reused. If set to False, then the coefficients will be rewritten for every call to fit. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2abc93ddea964d3eb32a39867456d5dfe5ef9180" translate="yes" xml:space="preserve">
          <source>This is visible if we compare the standard deviations of different features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42f2c0052d88e51f5df6c26752c192f81040ec01" translate="yes" xml:space="preserve">
          <source>This kernel is a popular choice for computing the similarity of documents represented as tf-idf vectors. &lt;a href=&quot;generated/sklearn.metrics.pairwise.cosine_similarity#sklearn.metrics.pairwise.cosine_similarity&quot;&gt;&lt;code&gt;cosine_similarity&lt;/code&gt;&lt;/a&gt; accepts &lt;code&gt;scipy.sparse&lt;/code&gt; matrices. (Note that the tf-idf functionality in &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; can produce normalized vectors, in which case &lt;a href=&quot;generated/sklearn.metrics.pairwise.cosine_similarity#sklearn.metrics.pairwise.cosine_similarity&quot;&gt;&lt;code&gt;cosine_similarity&lt;/code&gt;&lt;/a&gt; is equivalent to &lt;a href=&quot;generated/sklearn.metrics.pairwise.linear_kernel#sklearn.metrics.pairwise.linear_kernel&quot;&gt;&lt;code&gt;linear_kernel&lt;/code&gt;&lt;/a&gt;, only slower.)</source>
          <target state="translated">Это ядро ​​часто используется для вычисления подобия документов, представленных в виде векторов tf-idf. &lt;a href=&quot;generated/sklearn.metrics.pairwise.cosine_similarity#sklearn.metrics.pairwise.cosine_similarity&quot;&gt; &lt;code&gt;cosine_similarity&lt;/code&gt; &lt;/a&gt; принимает матрицы &lt;code&gt;scipy.sparse&lt;/code&gt; . (Обратите внимание, что функция tf-idf в &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; может создавать нормализованные векторы, и в этом случае &lt;a href=&quot;generated/sklearn.metrics.pairwise.cosine_similarity#sklearn.metrics.pairwise.cosine_similarity&quot;&gt; &lt;code&gt;cosine_similarity&lt;/code&gt; &lt;/a&gt; эквивалентен &lt;a href=&quot;generated/sklearn.metrics.pairwise.linear_kernel#sklearn.metrics.pairwise.linear_kernel&quot;&gt; &lt;code&gt;linear_kernel&lt;/code&gt; &lt;/a&gt; , только медленнее.)</target>
        </trans-unit>
        <trans-unit id="f1fbcea40cf4aba903be6eddf36c859a1718e3b8" translate="yes" xml:space="preserve">
          <source>This kernel is infinitely differentiable, which implies that GPs with this kernel as covariance function have mean square derivatives of all orders, and are thus very smooth.</source>
          <target state="translated">Это кернел бесконечно дифференцируемый,что подразумевает,что GP с этим ковариационным кернелом в качестве ковариационной функции имеют средние квадратные производные всех ордеров,и,таким образом,очень гладкие.</target>
        </trans-unit>
        <trans-unit id="ffa176d62610a7e6d304ab9efadadddacf7fa00e" translate="yes" xml:space="preserve">
          <source>This kernel is infinitely differentiable, which implies that GPs with this kernel as covariance function have mean square derivatives of all orders, and are thus very smooth. See &lt;a href=&quot;#redc669bcbe98-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt;, Chapter 4, Section 4.2, for further details of the RBF kernel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ad60f9f3ef06c9a3898414b0afc593eaff20c1d" translate="yes" xml:space="preserve">
          <source>This kernel is infinitely differentiable, which implies that GPs with this kernel as covariance function have mean square derivatives of all orders, and are thus very smooth. The prior and posterior of a GP resulting from an RBF kernel are shown in the following figure:</source>
          <target state="translated">Это кернел бесконечно дифференцируемый,что подразумевает,что GP с этим ковариационным кернелом в качестве ковариационной функции имеют средние квадратные производные всех ордеров,и,таким образом,очень гладкие.На следующем рисунке показаны предшествующая и последующая ГП,получаемые от ковариационного кернела RBF:</target>
        </trans-unit>
        <trans-unit id="6cbded70a18b870dfff7fda8d59e204ebd77900f" translate="yes" xml:space="preserve">
          <source>This kind of singular profiles is often seen in practice, for instance:</source>
          <target state="translated">Такого рода сингулярные профили часто встречаются,например,на практике:</target>
        </trans-unit>
        <trans-unit id="30529b10016c80d5c9ab1e213672fabc65487573" translate="yes" xml:space="preserve">
          <source>This last point is expected due to the nature of the problem: the occurrence of accidents is mostly dominated by circumstantial causes that are not captured in the columns of the dataset and can indeed be considered as purely random.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1df4414d1e47e9ea41e98b8c6e13b5eeb49e06ac" translate="yes" xml:space="preserve">
          <source>This left out portion can be used to estimate the generalization error without having to rely on a separate validation set. This estimate comes &amp;ldquo;for free&amp;rdquo; as no additional data is needed and can be used for model selection.</source>
          <target state="translated">Эту оставленную часть можно использовать для оценки ошибки обобщения без необходимости полагаться на отдельный набор для проверки. Эта оценка предоставляется &amp;laquo;бесплатно&amp;raquo;, поскольку никаких дополнительных данных не требуется и может использоваться для выбора модели.</target>
        </trans-unit>
        <trans-unit id="4f52c7809ab985057ba93af9b88459b0d10b33a2" translate="yes" xml:space="preserve">
          <source>This makes sure that the loss function is not heavily influenced by the outliers while not completely ignoring their effect.</source>
          <target state="translated">Это гарантирует,что функция потерь не будет сильно влиять на отклонения,не полностью игнорируя их эффект.</target>
        </trans-unit>
        <trans-unit id="2fb338a66a8f54901bcaa2314035cd86710a7d6d" translate="yes" xml:space="preserve">
          <source>This means each coefficient \(w_{i}\) is drawn from a Gaussian distribution, centered on zero and with a precision \(\lambda_{i}\):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4826ff4b754b03a246d73c38aa2c971ffdf335e1" translate="yes" xml:space="preserve">
          <source>This means each weight \(w_{i}\) is drawn from a Gaussian distribution, centered on zero and with a precision \(\lambda_{i}\):</source>
          <target state="translated">Это означает,что каждый вес \(w_{i}\)берется из гауссовского распределения,по центру-ноль и с точностью \(\lambda_{i}\):</target>
        </trans-unit>
        <trans-unit id="de2308f740624c092eea038ac13deb5af2b1fa80" translate="yes" xml:space="preserve">
          <source>This means that any classifiers handling multi-output multiclass or multi-task classification tasks, support the multi-label classification task as a special case. Multi-task classification is similar to the multi-output classification task with different model formulations. For more information, see the relevant estimator documentation.</source>
          <target state="translated">Это означает,что любые классификаторы,работающие с многопроцессорными или многозадачными классификационными задачами,поддерживают многомаркировочную классификационную задачу как особый случай.Многозадачная классификация похожа на многозадачную классификационную задачу с различными формулировками модели.Дополнительную информацию см.в соответствующей документации по оценщикам.</target>
        </trans-unit>
        <trans-unit id="6157bc0b8c2f67c8a593bf2d12852c000be43e72" translate="yes" xml:space="preserve">
          <source>This measure is not adjusted for chance. Therefore &lt;a href=&quot;sklearn.metrics.adjusted_mutual_info_score#sklearn.metrics.adjusted_mutual_info_score&quot;&gt;&lt;code&gt;adjusted_mutual_info_score&lt;/code&gt;&lt;/a&gt; might be preferred.</source>
          <target state="translated">Эта мера не скорректирована на случайность. Поэтому может быть предпочтительнее &lt;a href=&quot;sklearn.metrics.adjusted_mutual_info_score#sklearn.metrics.adjusted_mutual_info_score&quot;&gt; &lt;code&gt;adjusted_mutual_info_score&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="cca48ea1404a91d2df7b18cac656df30067cb12b" translate="yes" xml:space="preserve">
          <source>This method allows monitoring (i.e. determine error on testing set) after each boosting iteration.</source>
          <target state="translated">Этот метод позволяет осуществлять мониторинг (т.е.определять ошибку на тестовом комплекте)после каждой повышающей итерации.</target>
        </trans-unit>
        <trans-unit id="778da8cdceb825f45e49260c13130972c415ba18" translate="yes" xml:space="preserve">
          <source>This method allows monitoring (i.e. determine error on testing set) after each stage.</source>
          <target state="translated">Этот метод позволяет осуществлять мониторинг (т.е.определять ошибку на тестовом комплекте)после каждого этапа.</target>
        </trans-unit>
        <trans-unit id="893e20b8eaafff147aad0ee519c22b2be0783798" translate="yes" xml:space="preserve">
          <source>This method allows to generalize prediction to &lt;em&gt;new observations&lt;/em&gt; (not in the training set). Only available for novelty detection (when novelty is set to True).</source>
          <target state="translated">Этот метод позволяет обобщить прогноз на &lt;em&gt;новые наблюдения&lt;/em&gt; (не в обучающей выборке). Доступно только для обнаружения новизны (когда для новизны установлено значение True).</target>
        </trans-unit>
        <trans-unit id="e13bbab31202d773dbd5b155d7e0b7799ca54f84" translate="yes" xml:space="preserve">
          <source>This method computes the least squares solution using a singular value decomposition of X. If X is a matrix of size (n, p) this method has a cost of \(O(n p^2)\), assuming that \(n \geq p\).</source>
          <target state="translated">Этот метод вычисляет решение наименьших квадратов,используя сингулярное разложение X.Если X является матрицей размера (n,p),то этот метод имеет стоимость \(O(n p^2)\),предполагая,что \(n \geq p\).</target>
        </trans-unit>
        <trans-unit id="dc0919b0c811a79ed295c00492df459fa5ab93e8" translate="yes" xml:space="preserve">
          <source>This method doesn&amp;rsquo;t do anything. It exists purely for compatibility with the scikit-learn transformer API.</source>
          <target state="translated">Этот метод ничего не делает. Он существует исключительно для совместимости с API-интерфейсом scikit-learn transformer.</target>
        </trans-unit>
        <trans-unit id="89035c0aee87e0125ffcf7bf5f0dbe56fcfb74a9" translate="yes" xml:space="preserve">
          <source>This method has some performance and numerical stability overhead, hence it is better to call partial_fit on chunks of data that are as large as possible (as long as fitting in the memory budget) to hide the overhead.</source>
          <target state="translated">Этот метод имеет некоторую накладные расходы на производительность и числовую стабильность,поэтому для сокрытия накладных расходов лучше вызвать функцию partial_fit на как можно больших кусках данных (до тех пор,пока они подогнаны под бюджет памяти).</target>
        </trans-unit>
        <trans-unit id="a344504140059db6f88458066c961354f795c6a7" translate="yes" xml:space="preserve">
          <source>This method has some performance overhead hence it is better to call partial_fit on chunks of data that are as large as possible (as long as fitting in the memory budget) to hide the overhead.</source>
          <target state="translated">Этот метод имеет некоторые накладные расходы на производительность,поэтому для сокрытия накладных расходов лучше вызвать функцию partial_fit на максимально больших кусках данных (до тех пор,пока они подгоняются под бюджет памяти).</target>
        </trans-unit>
        <trans-unit id="03d61ee68976e414aa4354d3a63287b0819f990d" translate="yes" xml:space="preserve">
          <source>This method has the same order of complexity as &lt;a href=&quot;#ordinary-least-squares&quot;&gt;Ordinary Least Squares&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ceeeb1e178fb9959d4ffe786c9917a8fc68013bb" translate="yes" xml:space="preserve">
          <source>This method has the same order of complexity than an &lt;a href=&quot;#ordinary-least-squares&quot;&gt;Ordinary Least Squares&lt;/a&gt;.</source>
          <target state="translated">Этот метод имеет тот же порядок сложности, что и &lt;a href=&quot;#ordinary-least-squares&quot;&gt;обычный&lt;/a&gt; метод наименьших квадратов .</target>
        </trans-unit>
        <trans-unit id="8149d43c4db3023940e20ddee18dfd4caaeb24b1" translate="yes" xml:space="preserve">
          <source>This method is expected to be called several times consecutively on different chunks of a dataset so as to implement out-of-core or online learning.</source>
          <target state="translated">Предполагается,что этот метод будет вызываться несколько раз подряд на различных участках массива данных,чтобы реализовать внеядерное или онлайн-обучение.</target>
        </trans-unit>
        <trans-unit id="7914e16bc2009e2d4fc76b2006a65a031a42eb76" translate="yes" xml:space="preserve">
          <source>This method is just there to implement the usual API and hence work in pipelines.</source>
          <target state="translated">Этот метод как раз и используется для реализации обычного API и,следовательно,для работы в трубопроводах.</target>
        </trans-unit>
        <trans-unit id="53a4e9f6af590018ff1a37b6f68db2405dd79282" translate="yes" xml:space="preserve">
          <source>This method is just there to mark the fact that this transformer can work in a streaming setup.</source>
          <target state="translated">Этот метод предназначен только для того,чтобы отметить тот факт,что этот трансформатор может работать в потоковой установке.</target>
        </trans-unit>
        <trans-unit id="1ad1f3e2c791502dcf55d0ea0c930c86843ade76" translate="yes" xml:space="preserve">
          <source>This method is meant to be called concurrently by the multiprocessing callback. We rely on the thread-safety of dispatch_one_batch to protect against concurrent consumption of the unprotected iterator.</source>
          <target state="translated">Этот метод предназначен для одновременного вызова многопроцессорного обратного вызова.Мы полагаемся на потокобезопасность send_one_batch для защиты от одновременного потребления незащищенного итератора.</target>
        </trans-unit>
        <trans-unit id="4e81340dab29281a8d6b3bd99833383bb408f46c" translate="yes" xml:space="preserve">
          <source>This method is not deterministic: it computes a quantity called the free energy on X, then on a randomly corrupted version of X, and returns the log of the logistic function of the difference.</source>
          <target state="translated">Этот метод не детерминирован:он вычисляет величину,называемую свободной энергией по Х,затем по случайно испорченной версии Х,и возвращает журнал логистической функции разницы.</target>
        </trans-unit>
        <trans-unit id="483c17ab697933f17e74386d9739e36cf3fc93e7" translate="yes" xml:space="preserve">
          <source>This method is only available for log loss and modified Huber loss.</source>
          <target state="translated">Этот метод доступен только для потерь журнала и модифицированных потерь Huber.</target>
        </trans-unit>
        <trans-unit id="d7475ebc10f647671bee9a4be7afee1b81279276" translate="yes" xml:space="preserve">
          <source>This method provides a safe way to take a distance matrix as input, while preserving compatibility with many other algorithms that take a vector array.</source>
          <target state="translated">Этот метод обеспечивает безопасный способ взять на вход матрицу расстояний,сохраняя при этом совместимость со многими другими алгоритмами,которые берут векторный массив.</target>
        </trans-unit>
        <trans-unit id="b5d8e2fef5ebecb0c66f96f2926a64438412f355" translate="yes" xml:space="preserve">
          <source>This method provides a safe way to take a kernel matrix as input, while preserving compatibility with many other algorithms that take a vector array.</source>
          <target state="translated">Этот метод обеспечивает безопасный способ взять на вход матрицу кернела,сохраняя при этом совместимость со многими другими алгоритмами,которые берут векторный массив.</target>
        </trans-unit>
        <trans-unit id="c662dd229414f848149c194436efac32b71db4c2" translate="yes" xml:space="preserve">
          <source>This method returns a Fortran-ordered array. To convert it to a C-ordered array, use &amp;lsquo;np.ascontiguousarray&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fc2db598aaa9c1a0947d8f73a1238d30285a532" translate="yes" xml:space="preserve">
          <source>This method takes either a vector array or a distance matrix, and returns a distance matrix. If the input is a vector array, the distances are computed. If the input is a distances matrix, it is returned instead.</source>
          <target state="translated">Этот метод принимает либо векторный массив,либо матрицу расстояний и возвращает матрицу расстояний.Если на входе находится векторный массив,то вычисляются расстояния.Если входной сигнал является матрицей расстояний,то он возвращается.</target>
        </trans-unit>
        <trans-unit id="924736c0bae89c3f4376281e6a105fa549739eb4" translate="yes" xml:space="preserve">
          <source>This method takes either a vector array or a kernel matrix, and returns a kernel matrix. If the input is a vector array, the kernels are computed. If the input is a kernel matrix, it is returned instead.</source>
          <target state="translated">Этот метод берет либо векторный массив,либо матрицу кернела и возвращает матрицу кернела.Если на входе находится векторный массив,то вычисляются кернелы.Если входной сигнал является матрицей кернела,то он возвращается.</target>
        </trans-unit>
        <trans-unit id="b80df7fbbffdde8aff9c30af4a5bee17e602075b" translate="yes" xml:space="preserve">
          <source>This method transforms the features to follow a uniform or a normal distribution. Therefore, for a given feature, this transformation tends to spread out the most frequent values. It also reduces the impact of (marginal) outliers: this is therefore a robust preprocessing scheme.</source>
          <target state="translated">Этот метод преобразует характеристики,чтобы следовать равномерному или нормальному распределению.Таким образом,для данного признака это преобразование имеет тенденцию распределять наиболее часто встречающиеся значения.Оно также уменьшает влияние (предельных)отклонений:таким образом,это надежная схема предварительной обработки.</target>
        </trans-unit>
        <trans-unit id="88cc56a80a6739c5287afd3119dab66fa95d86a9" translate="yes" xml:space="preserve">
          <source>This method will raise a &lt;code&gt;ValueError&lt;/code&gt; if any of the estimators do not have &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a6448f2646e45809baed97b35289a513191212b" translate="yes" xml:space="preserve">
          <source>This method works similarly to the builtin &lt;code&gt;apply&lt;/code&gt;, except that the function is called only if the cache is not up to date.</source>
          <target state="translated">Этот метод работает аналогично встроенной функции &lt;code&gt;apply&lt;/code&gt; , за исключением того, что функция вызывается только в том случае, если кеш не обновлен.</target>
        </trans-unit>
        <trans-unit id="3b270b097c02b54b15c6706faba2a05992e48391" translate="yes" xml:space="preserve">
          <source>This metric is furthermore symmetric: switching &lt;code&gt;label_true&lt;/code&gt; with &lt;code&gt;label_pred&lt;/code&gt; will return the same score value. This can be useful to measure the agreement of two independent label assignments strategies on the same dataset when the real ground truth is not known.</source>
          <target state="translated">Более того, эта метрика симметрична: переключение &lt;code&gt;label_true&lt;/code&gt; на &lt;code&gt;label_pred&lt;/code&gt; вернет то же значение оценки. Это может быть полезно для измерения соответствия двух независимых стратегий присвоения меток одному и тому же набору данных, когда истинная достоверность неизвестна.</target>
        </trans-unit>
        <trans-unit id="b8da4b4fabd4786b82c03e2c15a17659173e15c8" translate="yes" xml:space="preserve">
          <source>This metric is independent of the absolute values of the labels: a permutation of the class or cluster label values won&amp;rsquo;t change the score value in any way.</source>
          <target state="translated">Эта метрика не зависит от абсолютных значений меток: перестановка значений метки класса или кластера никоим образом не изменит значение оценки.</target>
        </trans-unit>
        <trans-unit id="bfbb6fef2be45da43d1153172735208301268ab3" translate="yes" xml:space="preserve">
          <source>This metric is not symmetric: switching &lt;code&gt;label_true&lt;/code&gt; with &lt;code&gt;label_pred&lt;/code&gt; will return the &lt;a href=&quot;sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt;&lt;code&gt;completeness_score&lt;/code&gt;&lt;/a&gt; which will be different in general.</source>
          <target state="translated">Этот показатель не является симметричным: переключение &lt;code&gt;label_true&lt;/code&gt; с &lt;code&gt;label_pred&lt;/code&gt; возвратит &lt;a href=&quot;sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt; &lt;code&gt;completeness_score&lt;/code&gt; &lt;/a&gt; , который будет отличаться в целом.</target>
        </trans-unit>
        <trans-unit id="d6ecae2ce63387462768b5daf2f548b32eba4de4" translate="yes" xml:space="preserve">
          <source>This metric is not symmetric: switching &lt;code&gt;label_true&lt;/code&gt; with &lt;code&gt;label_pred&lt;/code&gt; will return the &lt;a href=&quot;sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt;&lt;code&gt;homogeneity_score&lt;/code&gt;&lt;/a&gt; which will be different in general.</source>
          <target state="translated">Этот показатель не является симметричным: переключение &lt;code&gt;label_true&lt;/code&gt; с &lt;code&gt;label_pred&lt;/code&gt; возвратит &lt;a href=&quot;sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt; &lt;code&gt;homogeneity_score&lt;/code&gt; &lt;/a&gt; , который будет отличаться в целом.</target>
        </trans-unit>
        <trans-unit id="b4ddf27eda44a85481c7034e578198a043591cb2" translate="yes" xml:space="preserve">
          <source>This metric is not well-defined for single samples and will return a NaN value if n_samples is less than two.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3d29b108d9b9b14881da7a1115d336ab614cf19" translate="yes" xml:space="preserve">
          <source>This metric is used in multilabel ranking problem, where the goal is to give better rank to the labels associated to each sample.</source>
          <target state="translated">Эта метрика используется в многомаркировочном ранге,где цель состоит в том,чтобы присвоить более высокий ранг меткам,связанным с каждой выборкой.</target>
        </trans-unit>
        <trans-unit id="aca1523dd1402afa978fd168a95010ba6eea69bb" translate="yes" xml:space="preserve">
          <source>This might be clearer with an example: consider a three class problem with class 0 having three support vectors \(v^{0}_0, v^{1}_0, v^{2}_0\) and class 1 and 2 having two support vectors \(v^{0}_1, v^{1}_1\) and \(v^{0}_2, v^{1}_2\) respectively. For each support vector \(v^{j}_i\), there are two dual coefficients. Let&amp;rsquo;s call the coefficient of support vector \(v^{j}_i\) in the classifier between classes \(i\) and \(k\)\(\alpha^{j}_{i,k}\). Then &lt;code&gt;dual_coef_&lt;/code&gt; looks like this:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70091de439c388c847d5db9bb63c11ef6af9aff3" translate="yes" xml:space="preserve">
          <source>This might be made more clear by an example:</source>
          <target state="translated">Это можно прояснить на примере:</target>
        </trans-unit>
        <trans-unit id="a18c0c170fadd6145ebf30e97149394844cb89ac" translate="yes" xml:space="preserve">
          <source>This mixin provides a feature selector implementation with &lt;code&gt;transform&lt;/code&gt; and &lt;code&gt;inverse_transform&lt;/code&gt; functionality given an implementation of &lt;code&gt;_get_support_mask&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87c35466b9ea86a2466ad7ff0fff224c499553d9" translate="yes" xml:space="preserve">
          <source>This model has many parameters, however the default values are quite reasonable (please see the &lt;a href=&quot;classes#text-feature-extraction-ref&quot;&gt;reference documentation&lt;/a&gt; for the details):</source>
          <target state="translated">Эта модель имеет множество параметров, однако значения по умолчанию вполне разумны (подробности см. В &lt;a href=&quot;classes#text-feature-extraction-ref&quot;&gt;справочной документации&lt;/a&gt; ):</target>
        </trans-unit>
        <trans-unit id="a96824cdb923fbde7424d806cedfbff3d185c97a" translate="yes" xml:space="preserve">
          <source>This model is an extension of the Sequential Karhunen-Loeve Transform from: &lt;code&gt;A. Levy and M. Lindenbaum, Sequential Karhunen-Loeve Basis Extraction and its Application to Images, IEEE Transactions on Image Processing, Volume 9, Number 8, pp. 1371-1374, August 2000.&lt;/code&gt; See &lt;a href=&quot;http://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&quot;&gt;http://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&lt;/a&gt;</source>
          <target state="translated">Эта модель является расширением последовательного преобразования Карунена-Лоэва из: &lt;code&gt;A. Levy and M. Lindenbaum, Sequential Karhunen-Loeve Basis Extraction and its Application to Images, IEEE Transactions on Image Processing, Volume 9, Number 8, pp. 1371-1374, August 2000.&lt;/code&gt; См. &lt;a href=&quot;http://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&quot;&gt;Http://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="22862405516241c579b3ee92c4c4e899025ea8d7" translate="yes" xml:space="preserve">
          <source>This model is an extension of the Sequential Karhunen-Loeve Transform from: &lt;em&gt;A. Levy and M. Lindenbaum, Sequential Karhunen-Loeve Basis Extraction and its Application to Images, IEEE Transactions on Image Processing, Volume 9, Number 8, pp. 1371-1374, August 2000.&lt;/em&gt; See &lt;a href=&quot;https://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&quot;&gt;https://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5eaf31e8c5d94894f814f950dadb507546a62c7a" translate="yes" xml:space="preserve">
          <source>This model is similar to the basic Label Propagation algorithm, but uses affinity matrix based on the normalized graph Laplacian and soft clamping across the labels.</source>
          <target state="translated">Данная модель аналогична базовому алгоритму Label Propagation,но использует матрицу аффинити,основанную на нормализованном графе Laplacian и мягком зажиме поперек этикеток.</target>
        </trans-unit>
        <trans-unit id="31cfc2556e1a899818d23b9328ee0744c892d322" translate="yes" xml:space="preserve">
          <source>This model optimizes the log-loss function using LBFGS or stochastic gradient descent.</source>
          <target state="translated">Эта модель оптимизирует функцию потери логов с помощью LBFGS или стохастического градиентного спуска.</target>
        </trans-unit>
        <trans-unit id="a4064d8d27531f23ac21cbcbd5928e344df2525d" translate="yes" xml:space="preserve">
          <source>This model optimizes the squared-loss using LBFGS or stochastic gradient descent.</source>
          <target state="translated">Эта модель оптимизирует квадратный убыток с помощью LBFGS или стохастического градиента спуска.</target>
        </trans-unit>
        <trans-unit id="5bcd7dedd8759fb896822dc89b59d5206ebfcc53" translate="yes" xml:space="preserve">
          <source>This model solves a regression model where the loss function is the linear least squares function and regularization is given by the l2-norm. Also known as Ridge Regression or Tikhonov regularization. This estimator has built-in support for multi-variate regression (i.e., when y is a 2d-array of shape (n_samples, n_targets)).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5745ffae87fdf8e03232a3372f515cd928402ef0" translate="yes" xml:space="preserve">
          <source>This model solves a regression model where the loss function is the linear least squares function and regularization is given by the l2-norm. Also known as Ridge Regression or Tikhonov regularization. This estimator has built-in support for multi-variate regression (i.e., when y is a 2d-array of shape [n_samples, n_targets]).</source>
          <target state="translated">Эта модель решает регрессионную модель,где функция потерь является линейной функцией наименьших квадратов,а регуляризация дается l2-нормой.Также известна как регрессия хребта или регуляризация Тихонова.Этот оценщик имеет встроенную поддержку многомерной регрессии (т.е.когда y-это 2d-массив формы [n_samples,n_targets]).</target>
        </trans-unit>
        <trans-unit id="f19c01936c0bc27e43d782c2c60b0838b0f4894d" translate="yes" xml:space="preserve">
          <source>This module contains both distance metrics and kernels. A brief summary is given on the two here.</source>
          <target state="translated">Данный модуль содержит как метрики расстояния,так и ядра.Краткая информация по этим двум параметрам приведена здесь.</target>
        </trans-unit>
        <trans-unit id="ea7156035377b3d98062532f66578932992ce326" translate="yes" xml:space="preserve">
          <source>This module contains two loaders. The first one, &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt;&lt;/a&gt;, returns a list of the raw texts that can be fed to text feature extractors such as &lt;a href=&quot;../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt;&lt;/a&gt; with custom parameters so as to extract feature vectors. The second one, &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized#sklearn.datasets.fetch_20newsgroups_vectorized&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_20newsgroups_vectorized&lt;/code&gt;&lt;/a&gt;, returns ready-to-use features, i.e., it is not necessary to use a feature extractor.</source>
          <target state="translated">Этот модуль содержит два загрузчика. Первый, &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt; &lt;/a&gt; , возвращает список необработанных текстов, которые могут быть переданы в экстракторы текстовых функций, такие как &lt;a href=&quot;../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt; ,&lt;/a&gt; с настраиваемыми параметрами для извлечения векторов признаков. Второй, &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized#sklearn.datasets.fetch_20newsgroups_vectorized&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_20newsgroups_vectorized&lt;/code&gt; &lt;/a&gt; , возвращает готовые к использованию функции, т. Е. Нет необходимости использовать средство извлечения признаков.</target>
        </trans-unit>
        <trans-unit id="e5dbda685e3f3b6ebc21c265d6368ea8386c5f03" translate="yes" xml:space="preserve">
          <source>This module implements multiclass learning algorithms:</source>
          <target state="translated">В этом модуле реализованы многоклассные алгоритмы обучения:</target>
        </trans-unit>
        <trans-unit id="40fee252ae7de928b5fc80e9416986beafe64ef4" translate="yes" xml:space="preserve">
          <source>This module implements multioutput regression and classification.</source>
          <target state="translated">В этом модуле реализована многовыходная регрессия и классификация.</target>
        </trans-unit>
        <trans-unit id="f4b5a1fcc345642615c5317116147407ee22511b" translate="yes" xml:space="preserve">
          <source>This module offers support for multi-output problems by implementing this strategy in both &lt;a href=&quot;generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt;&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.tree.decisiontreeregressor#sklearn.tree.DecisionTreeRegressor&quot;&gt;&lt;code&gt;DecisionTreeRegressor&lt;/code&gt;&lt;/a&gt;. If a decision tree is fit on an output array Y of size &lt;code&gt;[n_samples, n_outputs]&lt;/code&gt; then the resulting estimator will:</source>
          <target state="translated">Этот модуль предлагает поддержку задач с несколькими выходами путем реализации этой стратегии как в &lt;a href=&quot;generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt; &lt;code&gt;DecisionTreeClassifier&lt;/code&gt; ,так&lt;/a&gt; и в &lt;a href=&quot;generated/sklearn.tree.decisiontreeregressor#sklearn.tree.DecisionTreeRegressor&quot;&gt; &lt;code&gt;DecisionTreeRegressor&lt;/code&gt; &lt;/a&gt; . Если дерево решений помещается в выходной массив Y размера &lt;code&gt;[n_samples, n_outputs]&lt;/code&gt; то итоговая оценка будет:</target>
        </trans-unit>
        <trans-unit id="69b4d83c7d3d58178d932db005c229bef475361e" translate="yes" xml:space="preserve">
          <source>This normalization is implemented by the &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt;&lt;code&gt;TfidfTransformer&lt;/code&gt;&lt;/a&gt; class:</source>
          <target state="translated">Эта нормализация реализуется классом &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt; &lt;code&gt;TfidfTransformer&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="36bde3d3011eb8df53f7587f509f261b5588364f" translate="yes" xml:space="preserve">
          <source>This object uses workers to compute in parallel the application of a function to many different arguments. The main functionality it brings in addition to using the raw multiprocessing or concurrent.futures API are (see examples for details):</source>
          <target state="translated">Этот объект использует рабочих для параллельного вычисления применения функции к множеству различных аргументов.Основной функционал,который он приносит в дополнение к использованию raw multiprocessing или concurrent.futures API (см.примеры для подробностей):</target>
        </trans-unit>
        <trans-unit id="43f85d31a1122b5ce913b6ac1587dc97b9fac8c9" translate="yes" xml:space="preserve">
          <source>This package also features helpers to fetch larger datasets commonly used by the machine learning community to benchmark algorithms on data that comes from the &amp;lsquo;real world&amp;rsquo;.</source>
          <target state="translated">В этом пакете также есть помощники для получения больших наборов данных, которые обычно используются сообществом машинного обучения для тестирования алгоритмов на данных, поступающих из &amp;laquo;реального мира&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="8291d2ecf0ae6621cc55dbf9132ec6413177dbb1" translate="yes" xml:space="preserve">
          <source>This parameter does not have any effect. The components are always normalized.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f678792533c8ea573ae326139ccc463721df5e43" translate="yes" xml:space="preserve">
          <source>This parameter has been renamed to n_components and will be removed in version 0.21. .. deprecated:: 0.19</source>
          <target state="translated">Этот параметр был переименован в n_components и будет удален в версии 0.21....deprecated::0.19</target>
        </trans-unit>
        <trans-unit id="b9bd887348c693f73ff73c188c30554ec63931d0" translate="yes" xml:space="preserve">
          <source>This parameter has no effect on the matplotlib tree visualisation and it is kept here for backward compatibility.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95ab9404db52634d7b16f5cf223dc53c5df9617b" translate="yes" xml:space="preserve">
          <source>This parameter has no effect, is deprecated, and will be removed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3803345bcca4c293ec436fd5df6e0af3703aedc" translate="yes" xml:space="preserve">
          <source>This parameter is deprecated and will be removed in v0.24.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2008376a104f1f0d722babab4554d9900556a331" translate="yes" xml:space="preserve">
          <source>This parameter is ignored if vocabulary is not None.</source>
          <target state="translated">Этот параметр игнорируется,если словарь не None.</target>
        </trans-unit>
        <trans-unit id="4896edc233b2b945e9bfe76cd7c644f9b147f395" translate="yes" xml:space="preserve">
          <source>This parameter is ignored when &lt;code&gt;fit_intercept&lt;/code&gt; is set to False. If True, the regressors X will be normalized before regression by subtracting the mean and dividing by the l2-norm. If you wish to standardize, please use &lt;a href=&quot;sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt;&lt;code&gt;sklearn.preprocessing.StandardScaler&lt;/code&gt;&lt;/a&gt; before calling &lt;code&gt;fit&lt;/code&gt; on an estimator with &lt;code&gt;normalize=False&lt;/code&gt;.</source>
          <target state="translated">Этот параметр игнорируется, если для &lt;code&gt;fit_intercept&lt;/code&gt; установлено значение False. Если True, регрессоры X будут нормализованы перед регрессией путем вычитания среднего и деления на l2-норму. Если вы хотите стандартизировать, пожалуйста, используйте &lt;a href=&quot;sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt; &lt;code&gt;sklearn.preprocessing.StandardScaler&lt;/code&gt; &lt;/a&gt; перед вызовом &lt;code&gt;fit&lt;/code&gt; воценщике с &lt;code&gt;normalize=False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a954f8a244020c9f424e9822cfad5459a2f5fec4" translate="yes" xml:space="preserve">
          <source>This parameter is ignored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="74de1b86fb436972ff8b47352593daa33d35779f" translate="yes" xml:space="preserve">
          <source>This parameter is not needed to compute tfidf.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="18c6fb9267c5496a0a4415bd237b294d4f877c13" translate="yes" xml:space="preserve">
          <source>This parameter is required for multiclass/multilabel targets. If &lt;code&gt;None&lt;/code&gt;, the scores for each class are returned. Otherwise, this determines the type of averaging performed on the data:</source>
          <target state="translated">Этот параметр необходим для целей с несколькими классами / метками. Если &lt;code&gt;None&lt;/code&gt; , возвращаются оценки для каждого класса. В противном случае это определяет тип усреднения, выполняемого для данных:</target>
        </trans-unit>
        <trans-unit id="4b54c5323e385131687ecd8fe6362000ef5ec12b" translate="yes" xml:space="preserve">
          <source>This parameters can be accessed through the members &lt;code&gt;dual_coef_&lt;/code&gt; which holds the product \(y_i \alpha_i\), &lt;code&gt;support_vectors_&lt;/code&gt; which holds the support vectors, and &lt;code&gt;intercept_&lt;/code&gt; which holds the independent term \(\rho\) :</source>
          <target state="translated">К этим параметрам можно получить доступ через элементы &lt;code&gt;dual_coef_&lt;/code&gt; , которые содержат продукт \ (y_i \ alpha_i \), &lt;code&gt;support_vectors_&lt;/code&gt; , которые содержат опорные векторы, и &lt;code&gt;intercept_&lt;/code&gt; , который содержит независимый член \ (\ rho \):</target>
        </trans-unit>
        <trans-unit id="f0e92a41ff311d2df395e780ee2f06d2a63e9cbc" translate="yes" xml:space="preserve">
          <source>This path length, averaged over a forest of such random trees, is a measure of normality and our decision function.</source>
          <target state="translated">Эта длина пути,усредненная по лесу таких случайных деревьев,является мерой нормальности и нашей функции принятия решений.</target>
        </trans-unit>
        <trans-unit id="80dec09fc285dd6f9c561fc2931162bad1982cdb" translate="yes" xml:space="preserve">
          <source>This plot compares the decision surfaces learned by a decision tree classifier (first column), by a random forest classifier (second column), by an extra- trees classifier (third column) and by an AdaBoost classifier (fourth column).</source>
          <target state="translated">На данном рисунке сравниваются поверхности принятия решений,полученные с помощью классификатора деревьев принятия решений (первая колонка),случайного классификатора леса (вторая колонка),экстра-деревянного классификатора (третья колонка)и классификатора AdaBoost (четвертая колонка).</target>
        </trans-unit>
        <trans-unit id="3b15144cc63de75145bd9b8c8333a27bef49a738" translate="yes" xml:space="preserve">
          <source>This plot is called a Lorenz curve and can be summarized by the Gini index:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e05dc7c1a0ec44a96abb884d1ce621cca93db4e" translate="yes" xml:space="preserve">
          <source>This problem can safely be ignored when the number of samples is more than a thousand and the number of clusters is less than 10. &lt;strong&gt;For smaller sample sizes or larger number of clusters it is safer to use an adjusted index such as the Adjusted Rand Index (ARI)&lt;/strong&gt;.</source>
          <target state="translated">Эту проблему можно смело игнорировать, если количество выборок превышает тысячу, а количество кластеров меньше 10. &lt;strong&gt;Для меньших размеров выборки или большего количества кластеров безопаснее использовать скорректированный индекс, такой как Скорректированный индекс ранда ( ARI)&lt;/strong&gt; .</target>
        </trans-unit>
        <trans-unit id="432c2ac32bcc01f0466fb33da0cfef7067b741ad" translate="yes" xml:space="preserve">
          <source>This problem stems from two limitations of impurity-based feature importances:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcd7e110cbbcbd004685bcd45cf928dd3da1b5b1" translate="yes" xml:space="preserve">
          <source>This procedure (spectral clustering on an image) is an efficient approximate solution for finding normalized graph cuts.</source>
          <target state="translated">Эта процедура (спектральная кластеризация на изображении)является эффективным приблизительным решением для нахождения нормализованных графовых разрезов.</target>
        </trans-unit>
        <trans-unit id="f7d25c0cd20cd8cb8daa937c60ac3edd0b2b2f75" translate="yes" xml:space="preserve">
          <source>This ranking metric yields a high value if true labels are ranked high by &lt;code&gt;y_score&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a8651d966c336f363771d222433438f229cb5c2" translate="yes" xml:space="preserve">
          <source>This regressor is useful as a simple baseline to compare with other (real) regressors. Do not use it for real problems.</source>
          <target state="translated">Этот регрессор полезен в качестве простого базиса для сравнения с другими (реальными)регрессорами.Не используйте его для реальных проблем.</target>
        </trans-unit>
        <trans-unit id="566769fe300350777b617d7ceed39620171814da" translate="yes" xml:space="preserve">
          <source>This scaler can also be applied to sparse CSR or CSC matrices by passing &lt;code&gt;with_mean=False&lt;/code&gt; to avoid breaking the sparsity structure of the data.</source>
          <target state="translated">Этот масштабатор также можно применить к разреженным матрицам CSR или CSC, передав &lt;code&gt;with_mean=False&lt;/code&gt; , чтобы не нарушать разреженную структуру данных.</target>
        </trans-unit>
        <trans-unit id="bf350412f5695ebe05a62d114269ff308d8edf9f" translate="yes" xml:space="preserve">
          <source>This scaler can also be applied to sparse CSR or CSC matrices.</source>
          <target state="translated">Этот скалер также может быть применен к разреженным матрицам CSR или CSC.</target>
        </trans-unit>
        <trans-unit id="096cae15373bbc176ca80052b34794345347f334" translate="yes" xml:space="preserve">
          <source>This score can be used to select the n_features features with the highest values for the test chi-squared statistic from X, which must contain only non-negative features such as booleans or frequencies (e.g., term counts in document classification), relative to the classes.</source>
          <target state="translated">Эта оценка может быть использована для выбора характеристик n_features с наибольшими значениями для тестовой статистики хи-квадрат от X,которая должна содержать только неотрицательные характеристики,такие как булеан или частоты (например,количество терминов в классификации документов),по отношению к классам.</target>
        </trans-unit>
        <trans-unit id="bc67f7a4c884a57cb8d65e3051862bc296a2adb5" translate="yes" xml:space="preserve">
          <source>This score is identical to &lt;a href=&quot;sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt;&lt;code&gt;normalized_mutual_info_score&lt;/code&gt;&lt;/a&gt; with the &lt;code&gt;'arithmetic'&lt;/code&gt; option for averaging.</source>
          <target state="translated">Эта оценка идентична &lt;a href=&quot;sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt; &lt;code&gt;normalized_mutual_info_score&lt;/code&gt; &lt;/a&gt; с &lt;code&gt;'arithmetic'&lt;/code&gt; опцией для усреднения.</target>
        </trans-unit>
        <trans-unit id="81b377dd4306b3470c7efb10edcaa8d55b57210b" translate="yes" xml:space="preserve">
          <source>This section illustrates the use of a &lt;code&gt;Pipeline&lt;/code&gt; with &lt;code&gt;GridSearchCV&lt;/code&gt;</source>
          <target state="translated">В этом разделе показано использование &lt;code&gt;Pipeline&lt;/code&gt; с &lt;code&gt;GridSearchCV&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="929a45e65dc1a0cd0b685d6194be9ae4708eb857" translate="yes" xml:space="preserve">
          <source>This should make it possible to check that the cross-validation score is in the same range as before.</source>
          <target state="translated">Это должно позволить проверить,что результат перекрестного тестирования находится в том же диапазоне,что и раньше.</target>
        </trans-unit>
        <trans-unit id="08af461e03baea2ad13f22a738ff3dde29c2a50f" translate="yes" xml:space="preserve">
          <source>This shows an example of a neighbors-based query (in particular a kernel density estimate) on geospatial data, using a Ball Tree built upon the Haversine distance metric &amp;ndash; i.e. distances over points in latitude/longitude. The dataset is provided by Phillips et. al. (2006). If available, the example uses &lt;a href=&quot;http://matplotlib.org/basemap&quot;&gt;basemap&lt;/a&gt; to plot the coast lines and national boundaries of South America.</source>
          <target state="translated">Здесь показан пример запроса на основе соседей (в частности, оценка плотности ядра) для геопространственных данных с использованием дерева шариков, построенного на основе метрики расстояния Гаверсина, то есть расстояний по точкам по широте / долготе. Набор данных предоставлен Phillips et. al. (2006). Если возможно, в примере используется &lt;a href=&quot;http://matplotlib.org/basemap&quot;&gt;базовая карта&lt;/a&gt; для построения береговых линий и национальных границ Южной Америки.</target>
        </trans-unit>
        <trans-unit id="d9d5278cf29981ffe0af23942c116e835acd3587" translate="yes" xml:space="preserve">
          <source>This shows an example of a neighbors-based query (in particular a kernel density estimate) on geospatial data, using a Ball Tree built upon the Haversine distance metric &amp;ndash; i.e. distances over points in latitude/longitude. The dataset is provided by Phillips et. al. (2006). If available, the example uses &lt;a href=&quot;https://matplotlib.org/basemap/&quot;&gt;basemap&lt;/a&gt; to plot the coast lines and national boundaries of South America.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38716491ad409e2f991bc1db8f7b1d944921bf99" translate="yes" xml:space="preserve">
          <source>This sort of preprocessing can be streamlined with the &lt;a href=&quot;compose#pipeline&quot;&gt;Pipeline&lt;/a&gt; tools. A single object representing a simple polynomial regression can be created and used as follows:</source>
          <target state="translated">Такого рода предварительную обработку можно упростить с помощью инструментов &lt;a href=&quot;compose#pipeline&quot;&gt;конвейера&lt;/a&gt; . Один объект, представляющий простую полиномиальную регрессию, может быть создан и использован следующим образом:</target>
        </trans-unit>
        <trans-unit id="4e6050ab2083fb67a848ffe7f83ae292a8f60f62" translate="yes" xml:space="preserve">
          <source>This strategy can also be used for multilabel learning, where a classifier is used to predict multiple labels for instance, by fitting on a 2-d matrix in which cell [i, j] is 1 if sample i has label j and 0 otherwise.</source>
          <target state="translated">Эта стратегия также может быть использована для изучения многоэлементных этикеток,где классификатор используется для предсказания нескольких этикеток,например,путем подгонки к 2-d матрице,в которой ячейка [i,j]равна 1,если образец i имеет этикетку j,и 0 в противном случае.</target>
        </trans-unit>
        <trans-unit id="8cd6a64f79d725ef1cdd342315685305aab51887" translate="yes" xml:space="preserve">
          <source>This strategy consists in fitting one classifier per class pair. At prediction time, the class which received the most votes is selected. Since it requires to fit &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; classifiers, this method is usually slower than one-vs-the-rest, due to its O(n_classes^2) complexity. However, this method may be advantageous for algorithms such as kernel algorithms which don&amp;rsquo;t scale well with &lt;code&gt;n_samples&lt;/code&gt;. This is because each individual learning problem only involves a small subset of the data whereas, with one-vs-the-rest, the complete dataset is used &lt;code&gt;n_classes&lt;/code&gt; times.</source>
          <target state="translated">Эта стратегия заключается в подборе одного классификатора на пару классов. Во время прогнозирования выбирается класс, получивший наибольшее количество голосов. Поскольку он требует соответствия &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; , этот метод обычно медленнее, чем один против остальных, из-за его сложности O (n_classes ^ 2). Однако этот метод может быть &lt;code&gt;n_samples&lt;/code&gt; для таких алгоритмов, как алгоритмы ядра, которые плохо масштабируются с n_samples . Это связано с тем, что каждая отдельная задача обучения включает в себя только небольшое подмножество данных, тогда как при использовании одного против остальных полный набор данных используется &lt;code&gt;n_classes&lt;/code&gt; раз.</target>
        </trans-unit>
        <trans-unit id="de640b51f281cc0046c1a9e652c58d4e96ebef0b" translate="yes" xml:space="preserve">
          <source>This strategy consists of fitting one classifier per target. This is a simple strategy for extending classifiers that do not natively support multi-target classification</source>
          <target state="translated">Эта стратегия состоит в том,чтобы подогнать один классификатор под каждую цель.Это простая стратегия для расширения классификаторов,которые не поддерживают классификацию по нескольким целям.</target>
        </trans-unit>
        <trans-unit id="7d6fb6c6a7f2b79b31f4627b09bbb93dcc2f3bc4" translate="yes" xml:space="preserve">
          <source>This strategy consists of fitting one regressor per target. This is a simple strategy for extending regressors that do not natively support multi-target regression.</source>
          <target state="translated">Эта стратегия состоит в подборе одного регрессора на каждую цель.Это простая стратегия для расширения регрессоров,которые не поддерживают многоцелевую регрессию.</target>
        </trans-unit>
        <trans-unit id="27cbaceed22a6f90d5ae07c700825d27bfca1f78" translate="yes" xml:space="preserve">
          <source>This strategy has several advantages:</source>
          <target state="translated">Эта стратегия имеет ряд преимуществ:</target>
        </trans-unit>
        <trans-unit id="91d49a77db9793bc904e6dbf1c0dda029b6c110b" translate="yes" xml:space="preserve">
          <source>This strategy is illustrated below.</source>
          <target state="translated">Эта стратегия проиллюстрирована ниже.</target>
        </trans-unit>
        <trans-unit id="02849272fb07ed52ea9b00f7ccc02a748c971372" translate="yes" xml:space="preserve">
          <source>This strategy, also known as &lt;strong&gt;one-vs-all&lt;/strong&gt;, is implemented in &lt;a href=&quot;generated/sklearn.multiclass.onevsrestclassifier#sklearn.multiclass.OneVsRestClassifier&quot;&gt;&lt;code&gt;OneVsRestClassifier&lt;/code&gt;&lt;/a&gt;. The strategy consists in fitting one classifier per class. For each classifier, the class is fitted against all the other classes. In addition to its computational efficiency (only &lt;code&gt;n_classes&lt;/code&gt; classifiers are needed), one advantage of this approach is its interpretability. Since each class is represented by one and only one classifier, it is possible to gain knowledge about the class by inspecting its corresponding classifier. This is the most commonly used strategy and is a fair default choice.</source>
          <target state="translated">Эта стратегия, также известная как &amp;laquo; &lt;strong&gt;один против всех&amp;raquo;&lt;/strong&gt; , реализована в &lt;a href=&quot;generated/sklearn.multiclass.onevsrestclassifier#sklearn.multiclass.OneVsRestClassifier&quot;&gt; &lt;code&gt;OneVsRestClassifier&lt;/code&gt; &lt;/a&gt; . Стратегия заключается в подборе одного классификатора на класс. Для каждого классификатора класс сопоставляется со всеми другими классами. В дополнение к его вычислительной эффективности (необходимы только классификаторы &lt;code&gt;n_classes&lt;/code&gt; ), одним из преимуществ этого подхода является его интерпретируемость. Поскольку каждый класс представлен одним и только одним классификатором, можно получить информацию о классе, проверив соответствующий классификатор. Это наиболее часто используемая стратегия и справедливый выбор по умолчанию.</target>
        </trans-unit>
        <trans-unit id="27ac94ab878e8b852843daf6fdc6644656d86a0e" translate="yes" xml:space="preserve">
          <source>This submodule contains functions that approximate the feature mappings that correspond to certain kernels, as they are used for example in support vector machines (see &lt;a href=&quot;svm#svm&quot;&gt;Support Vector Machines&lt;/a&gt;). The following feature functions perform non-linear transformations of the input, which can serve as a basis for linear classification or other algorithms.</source>
          <target state="translated">Этот подмодуль содержит функции, которые аппроксимируют сопоставления функций, которые соответствуют определенным ядрам, поскольку они используются, например, в машинах опорных векторов (см. &lt;a href=&quot;svm#svm&quot;&gt;Машины&lt;/a&gt; опорных векторов ). Следующие функции функций выполняют нелинейные преобразования входных данных, которые могут служить основой для линейной классификации или других алгоритмов.</target>
        </trans-unit>
        <trans-unit id="fcbae9cfcf0bd03c252edbce0ec54b00175fa149" translate="yes" xml:space="preserve">
          <source>This test can be applied to classes or instances. Classes currently have some additional tests that related to construction, while passing instances allows the testing of multiple options.</source>
          <target state="translated">Этот тест может быть применен к классам или экземплярам.Классы в настоящее время имеют некоторые дополнительные тесты,которые связаны с построением,в то время как прохождение экземпляров позволяет проверить несколько вариантов.</target>
        </trans-unit>
        <trans-unit id="1df76b4b8062cdd31b59f7b7a96f694c7a4a84f4" translate="yes" xml:space="preserve">
          <source>This test can be applied to classes or instances. Classes currently have some additional tests that related to construction, while passing instances allows the testing of multiple options. However, support for classes is deprecated since version 0.23 and will be removed in version 0.24 (class checks will still be run on the instances).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe4512e0330ee3f9d4d908b10acadfb35dcb4b46" translate="yes" xml:space="preserve">
          <source>This text vectorizer implementation uses the hashing trick to find the token string name to feature integer index mapping.</source>
          <target state="translated">Эта реализация текстового векторизатора использует трюк хэширования для поиска имени строки токена для отображения целочисленного индекса.</target>
        </trans-unit>
        <trans-unit id="90704510327932a48fb3c52155398163f97475e2" translate="yes" xml:space="preserve">
          <source>This transformation is often used as an alternative to zero mean, unit variance scaling.</source>
          <target state="translated">Это преобразование часто используется в качестве альтернативы масштабированию нулевого среднего,дисперсии в единицах измерения.</target>
        </trans-unit>
        <trans-unit id="6539f7aec79b7dc39bdc0281525ed4d20f3ca8db" translate="yes" xml:space="preserve">
          <source>This transformation will only be exact if n_components=n_features</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f720ce11fea82f150f2e1314efc3b6e74d2aa65" translate="yes" xml:space="preserve">
          <source>This transformer is able to work both with dense numpy arrays and scipy.sparse matrix (use CSR format if you want to avoid the burden of a copy / conversion).</source>
          <target state="translated">Этот трансформатор способен работать как с плотными нумерованными массивами,так и с матрицей scipy.sparse (используйте CSR формат,если хотите избежать нагрузки,связанной с копированием/преобразованием).</target>
        </trans-unit>
        <trans-unit id="22f51ce5936d304512713b7c2d6420a9339ed07c" translate="yes" xml:space="preserve">
          <source>This transformer performs linear dimensionality reduction by means of truncated singular value decomposition (SVD). Contrary to PCA, this estimator does not center the data before computing the singular value decomposition. This means it can work with scipy.sparse matrices efficiently.</source>
          <target state="translated">Этот трансформатор выполняет линейное уменьшение размерности посредством усеченного разложения сингулярных величин (SVD).В отличие от СПС,этот оценщик не центрирует данные до расчета сингулярного разложения.Это означает,что он может эффективно работать с матрицами scipy.sparse.</target>
        </trans-unit>
        <trans-unit id="548ea059334e4b91f9c90aef5db25d9def754336" translate="yes" xml:space="preserve">
          <source>This transformer performs linear dimensionality reduction by means of truncated singular value decomposition (SVD). Contrary to PCA, this estimator does not center the data before computing the singular value decomposition. This means it can work with sparse matrices efficiently.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cbf82199a6ba754f7c0185042f3f4e595a8e8525" translate="yes" xml:space="preserve">
          <source>This transformer should be used to encode target values, &lt;em&gt;i.e.&lt;/em&gt;&lt;code&gt;y&lt;/code&gt;, and not the input &lt;code&gt;X&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c058bdf39166834e7b3e02bee2a3dc32df1bea5c" translate="yes" xml:space="preserve">
          <source>This transformer turns lists of mappings (dict-like objects) of feature names to feature values into Numpy arrays or scipy.sparse matrices for use with scikit-learn estimators.</source>
          <target state="translated">Этот трансформатор превращает списки отображений (dict-подобных объектов)имен элементов в значения элементов в массивы Numpy или scipy.sparse матрицы для использования с scikit-learn оценщиками.</target>
        </trans-unit>
        <trans-unit id="6fa17f9065133747f6dee2c04fd6c387874c04ab" translate="yes" xml:space="preserve">
          <source>This tutorial will explore &lt;em&gt;statistical learning&lt;/em&gt;, the use of machine learning techniques with the goal of &lt;a href=&quot;https://en.wikipedia.org/wiki/Statistical_inference&quot;&gt;statistical inference&lt;/a&gt;: drawing conclusions on the data at hand.</source>
          <target state="translated">В этом руководстве будет изучено &lt;em&gt;статистическое обучение&lt;/em&gt; , использование методов машинного обучения с целью &lt;a href=&quot;https://en.wikipedia.org/wiki/Statistical_inference&quot;&gt;статистического вывода&lt;/a&gt; : выводы на основе имеющихся данных.</target>
        </trans-unit>
        <trans-unit id="d770164eec068c2686e18d9f67f7678a7fe3d2ab" translate="yes" xml:space="preserve">
          <source>This uses the Benjamini-Hochberg procedure. &lt;code&gt;alpha&lt;/code&gt; is an upper bound on the expected false discovery rate.</source>
          <target state="translated">Здесь используется процедура Бенджамини-Хохберга. &lt;code&gt;alpha&lt;/code&gt; - это верхняя граница ожидаемого уровня ложного обнаружения.</target>
        </trans-unit>
        <trans-unit id="25630de50e6415b67bb72ea47abf6e457ed32d31" translate="yes" xml:space="preserve">
          <source>This uses the score defined by &lt;code&gt;scoring&lt;/code&gt; where provided, and the &lt;code&gt;best_estimator_.score&lt;/code&gt; method otherwise.</source>
          <target state="translated">При этом используется оценка, определенная путем &lt;code&gt;scoring&lt;/code&gt; если она предоставлена, и метод &lt;code&gt;best_estimator_.score&lt;/code&gt; в противном случае.</target>
        </trans-unit>
        <trans-unit id="28c90b747be44784ef68312c004db0e8049cba2c" translate="yes" xml:space="preserve">
          <source>This utility is documented, but &lt;strong&gt;private&lt;/strong&gt;. This means that backward compatibility might be broken without any deprecation cycle.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6f06f080d161d82167224fa4f5455a90c3bc7e3" translate="yes" xml:space="preserve">
          <source>This utility is meant to be used internally by estimators themselves, typically in their own predict / transform methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57e78bad29e459afb6f7e8e9a46e0b5e6e5f4fa9" translate="yes" xml:space="preserve">
          <source>This value is valid if class_weight parameter in fit() is not set.</source>
          <target state="translated">Это значение действует,если параметр class_weight в функции fit()не установлен.</target>
        </trans-unit>
        <trans-unit id="0973d55bbbd406d7d050b325e278935eae6a368e" translate="yes" xml:space="preserve">
          <source>This value of the mutual information and also the normalized variant is not adjusted for chance and will tend to increase as the number of different labels (clusters) increases, regardless of the actual amount of &amp;ldquo;mutual information&amp;rdquo; between the label assignments.</source>
          <target state="translated">Это значение взаимной информации, а также нормализованного варианта не скорректировано на случайность и будет иметь тенденцию к увеличению по мере увеличения количества различных меток (кластеров), независимо от фактического количества &amp;laquo;взаимной информации&amp;raquo; между назначениями меток.</target>
        </trans-unit>
        <trans-unit id="ec27c204380d1bf1bec671104c4e5cc563667983" translate="yes" xml:space="preserve">
          <source>This visualization is an example of a &lt;em&gt;kernel density estimation&lt;/em&gt;, in this case with a top-hat kernel (i.e. a square block at each point). We can recover a smoother distribution by using a smoother kernel. The bottom-right plot shows a Gaussian kernel density estimate, in which each point contributes a Gaussian curve to the total. The result is a smooth density estimate which is derived from the data, and functions as a powerful non-parametric model of the distribution of points.</source>
          <target state="translated">Эта визуализация является примером &lt;em&gt;оценки плотности ядра&lt;/em&gt; , в данном случае с ядром в форме цилиндра (то есть квадратным блоком в каждой точке). Мы можем восстановить более плавное распределение, используя более гладкое ядро. На нижнем правом графике показана оценка плотности ядра Гаусса, в которой каждая точка вносит свой вклад в общую кривую Гаусса. В результате получается гладкая оценка плотности, которая выводится из данных и функционирует как мощная непараметрическая модель распределения точек.</target>
        </trans-unit>
        <trans-unit id="1cad85e71e9b226b43b5778c8058de4fe70516a7" translate="yes" xml:space="preserve">
          <source>This warning is used to notify the user that BLAS was not used for dot operation and hence the efficiency may be affected.</source>
          <target state="translated">Это предупреждение используется для уведомления пользователя о том,что BLAS не использовался для работы с точками и,следовательно,эффективность может быть снижена.</target>
        </trans-unit>
        <trans-unit id="7b4c8162b5298ba9d922a2200274b38ddddf44e8" translate="yes" xml:space="preserve">
          <source>This warning notifies the user that the efficiency may not be optimal due to some reason which may be included as a part of the warning message. This may be subclassed into a more specific Warning class.</source>
          <target state="translated">Это предупреждение уведомляет пользователя о том,что эффективность может быть не оптимальной по какой-то причине,которая может быть включена в предупреждающее сообщение.Оно может быть подразделено на более конкретный класс предупреждения.</target>
        </trans-unit>
        <trans-unit id="ec79da6e5e29f4afd0662e82ec298c39ed6dbabd" translate="yes" xml:space="preserve">
          <source>This warning occurs when some input data needs to be converted or interpreted in a way that may not match the user&amp;rsquo;s expectations.</source>
          <target state="translated">Это предупреждение появляется, когда некоторые входные данные необходимо преобразовать или интерпретировать таким образом, который может не соответствовать ожиданиям пользователя.</target>
        </trans-unit>
        <trans-unit id="14994b75958434504d6803fa4be46a86d6219fc9" translate="yes" xml:space="preserve">
          <source>This was originally a term weighting scheme developed for information retrieval (as a ranking function for search engines results) that has also found good use in document classification and clustering.</source>
          <target state="translated">Первоначально это была схема взвешивания терминов,разработанная для поиска информации (как функция ранжирования результатов в поисковых системах),которая также нашла хорошее применение в классификации документов и кластеризации.</target>
        </trans-unit>
        <trans-unit id="90d00e9f85af52e63288d2fca3d9f513dce9de12" translate="yes" xml:space="preserve">
          <source>This, however, is not the case in the Ledoit-Wolf procedure when the population covariance happens to be a multiple of the identity matrix. In this case, the Ledoit-Wolf shrinkage estimate approaches 1 as the number of samples increases. This indicates that the optimal estimate of the covariance matrix in the Ledoit-Wolf sense is multiple of the identity. Since the population covariance is already a multiple of the identity matrix, the Ledoit-Wolf solution is indeed a reasonable estimate.</source>
          <target state="translated">Это,однако,не случай в процедуре Ледойт-Вульф когда коварианс населенности случается быть множественным из матрицы тождественности.В этом случае оценка усадки Ледойт-Вульф приближается к 1 по мере увеличения количества образцов.Это указывает на то,что оптимальная оценка матрицы ковариаций в смысле Ледойт-Вульф кратна идентичности.Так как ковариация популяции уже кратна матрице идентичности,решение Ледуарда-Вольфа действительно является разумной оценкой.</target>
        </trans-unit>
        <trans-unit id="e911226999d28ae4c4eb95cef049955b008548cf" translate="yes" xml:space="preserve">
          <source>Those 3 metrics are independent of the absolute values of the labels: a permutation of the class or cluster label values won&amp;rsquo;t change the score values in any way.</source>
          <target state="translated">Эти 3 метрики не зависят от абсолютных значений меток: перестановка значений метки класса или кластера никоим образом не изменит значения оценки.</target>
        </trans-unit>
        <trans-unit id="a17151aff3f6e79d6bfb3bc3e7c5d30ff3b77b7d" translate="yes" xml:space="preserve">
          <source>Those metrics are based on normalized conditional entropy measures of the clustering labeling to evaluate given the knowledge of a Ground Truth class labels of the same samples.</source>
          <target state="translated">Эти метрики основаны на нормализованных условных энтропийных мерах маркировки кластеризации для того чтобы оценить дано знание наземной истины ярлыков класса тех же самых образцов.</target>
        </trans-unit>
        <trans-unit id="831e093286e91d34e1415d38600e7c8277f14a07" translate="yes" xml:space="preserve">
          <source>Though not technically a variant of LLE, Local tangent space alignment (LTSA) is algorithmically similar enough to LLE that it can be put in this category. Rather than focusing on preserving neighborhood distances as in LLE, LTSA seeks to characterize the local geometry at each neighborhood via its tangent space, and performs a global optimization to align these local tangent spaces to learn the embedding. LTSA can be performed with function &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt;&lt;code&gt;locally_linear_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt;&lt;code&gt;LocallyLinearEmbedding&lt;/code&gt;&lt;/a&gt;, with the keyword &lt;code&gt;method = 'ltsa'&lt;/code&gt;.</source>
          <target state="translated">Хотя технически это не вариант LLE, локальное выравнивание касательного пространства (LTSA) алгоритмически достаточно похоже на LLE, чтобы его можно было отнести к этой категории. Вместо того, чтобы сосредоточиться на сохранении расстояний между соседями, как в LLE, LTSA стремится охарактеризовать локальную геометрию в каждой окрестности через его касательное пространство и выполняет глобальную оптимизацию для выравнивания этих локальных касательных пространств для изучения встраивания. LTSA может выполняться с помощью функции &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt; &lt;code&gt;locally_linear_embedding&lt;/code&gt; &lt;/a&gt; или ее объектно-ориентированного аналога &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt; &lt;code&gt;LocallyLinearEmbedding&lt;/code&gt; &lt;/a&gt; с ключевым словом &lt;code&gt;method = 'ltsa'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3dcfc8b5bdf930c1b66451c5dc30f486901100ee" translate="yes" xml:space="preserve">
          <source>Three different types of SVM-Kernels are displayed below. The polynomial and RBF are especially useful when the data-points are not linearly separable.</source>
          <target state="translated">Ниже отображаются три различных типа SVM-ядер.Полиномы и RBF особенно полезны,когда точки данных не разделяются линейно.</target>
        </trans-unit>
        <trans-unit id="2eb0d5d5e8d716a06a5bc42a652c1781cf721343" translate="yes" xml:space="preserve">
          <source>Threshold for binarizing (mapping to booleans) of sample features. If None, input is presumed to already consist of binary vectors.</source>
          <target state="translated">Порог для бинаризации (отображения в булеан)особенностей выборки.Если Нет,то предполагается,что вход уже состоит из бинарных векторов.</target>
        </trans-unit>
        <trans-unit id="ac359cd376aaf3163dffdc564a92f8f55ebdbfe9" translate="yes" xml:space="preserve">
          <source>Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.</source>
          <target state="translated">Порог для ранней остановки роста деревьев.Узел расколется,если его примесь окажется выше порога,иначе это лист.</target>
        </trans-unit>
        <trans-unit id="d2dde1e4fd07fa9e4ff99bf50a843f5c394281b4" translate="yes" xml:space="preserve">
          <source>Threshold for shrinking centroids to remove features.</source>
          <target state="translated">Порог для сжимания центроидов для удаления функций.</target>
        </trans-unit>
        <trans-unit id="5b50eca69565a6240c9cb586697767c09ac4525e" translate="yes" xml:space="preserve">
          <source>Threshold on the size of arrays passed to the workers that triggers automated memory mapping in temp_folder. Can be an int in Bytes, or a human-readable string, e.g., &amp;lsquo;1M&amp;rsquo; for 1 megabyte. Use None to disable memmapping of large arrays. Only active when backend=&amp;rdquo;loky&amp;rdquo; or &amp;ldquo;multiprocessing&amp;rdquo;.</source>
          <target state="translated">Порог размера массивов, передаваемых рабочим, который запускает автоматическое отображение памяти в temp_folder. Может быть int в байтах или удобочитаемой строкой, например, &amp;laquo;1M&amp;raquo; для 1 мегабайта. Используйте None, чтобы отключить отображение больших массивов. Активен, только когда backend = &quot;loky&quot; или &quot;multiprocessing&quot;.</target>
        </trans-unit>
        <trans-unit id="3bf722c4ec04176f091be4d50fbd629d5b754a20" translate="yes" xml:space="preserve">
          <source>Threshold used for rank estimation in SVD solver.</source>
          <target state="translated">Порог,используемый для оценки ранга в SVD solver.</target>
        </trans-unit>
        <trans-unit id="0168a115989469a76c56e8c46c0d56b1a01f88c6" translate="yes" xml:space="preserve">
          <source>Threshold used for rank estimation.</source>
          <target state="translated">Порог,используемый для оценки ранга.</target>
        </trans-unit>
        <trans-unit id="558232b0add0e7cf1e4001c15b7a509781ecfb59" translate="yes" xml:space="preserve">
          <source>Threshold used in the binary and multi-label cases.</source>
          <target state="translated">Порог,используемый в бинарных и мульти-маркировочных случаях.</target>
        </trans-unit>
        <trans-unit id="d260a173cc06214ee3d2352996ea165371c17c29" translate="yes" xml:space="preserve">
          <source>Thresholding</source>
          <target state="translated">Thresholding</target>
        </trans-unit>
        <trans-unit id="8265a18b28c2cb3c5a28ceb45384d9a49c2f7715" translate="yes" xml:space="preserve">
          <source>Thresholding is clearly not useful for denoising, but it is here to show that it can produce a suggestive output with very high speed, and thus be useful for other tasks such as object classification, where performance is not necessarily related to visualisation.</source>
          <target state="translated">Очевидно,что пороговый тон не полезен для размывания,но он здесь для того,чтобы показать,что он может производить внушающий результат с очень высокой скоростью,и,таким образом,быть полезным для других задач,таких как классификация объектов,где производительность не обязательно связана с визуализацией.</target>
        </trans-unit>
        <trans-unit id="c4d29a75003891e7d5c5dbb3dea7166bf19f4ab9" translate="yes" xml:space="preserve">
          <source>Thresholding is very fast but it does not yield accurate reconstructions. They have been shown useful in literature for classification tasks. For image reconstruction tasks, orthogonal matching pursuit yields the most accurate, unbiased reconstruction.</source>
          <target state="translated">Порог очень быстрый,но не дает точных реконструкций.Они были показаны в литературе,полезной для классификационных задач.Для задач реконструкции изображений,поиск ортогонального соответствия дает наиболее точную,объективную реконструкцию.</target>
        </trans-unit>
        <trans-unit id="3904c870d9e800cc53a98ecb8acef59d010fad3d" translate="yes" xml:space="preserve">
          <source>Throw a ValueError if X contains NaN or infinity.</source>
          <target state="translated">Бросьте ValueError,если X содержит NaN или бесконечность.</target>
        </trans-unit>
        <trans-unit id="8b8612c016401dc529cb09be5ddd6996fe872d9c" translate="yes" xml:space="preserve">
          <source>Thus in binary classification, the count of true negatives is \(C_{0,0}\), false negatives is \(C_{1,0}\), true positives is \(C_{1,1}\) and false positives is \(C_{0,1}\).</source>
          <target state="translated">Таким образом,в бинарной классификации количество истинных отрицательных значений равно \(C_{0,0}\),ложных отрицательных значений-\(C_{1,0}\),истинных значений-\(C_{1,1}\),а ложных значений-\(C_{0,1}\).</target>
        </trans-unit>
        <trans-unit id="877864e25b035038afd6bbe5a72ca90fb8e0741e" translate="yes" xml:space="preserve">
          <source>Thus the median of the input becomes the mean of the output, centered at 0. The normal output is clipped so that the input&amp;rsquo;s minimum and maximum &amp;mdash; corresponding to the 1e-7 and 1 - 1e-7 quantiles respectively &amp;mdash; do not become infinite under the transformation.</source>
          <target state="translated">Таким образом, медиана входных данных становится средним значением выходных данных с центром в 0. Нормальный выход обрезается так, чтобы минимум и максимум входного сигнала, соответствующие квантилям 1e-7 и 1 - 1e-7 соответственно, не становились бесконечными при преобразование.</target>
        </trans-unit>
        <trans-unit id="911ea2c24698b41ad1167139365e2f911ee7efcc" translate="yes" xml:space="preserve">
          <source>Thus, among the considered estimators, &lt;code&gt;PoissonRegressor&lt;/code&gt; and &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; are a-priori better suited for modeling the long tail distribution of the non-negative data as compared to the &lt;code&gt;Ridge&lt;/code&gt; model which makes a wrong assumption on the distribution of the target variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0808b4cdf67452766c8c5389635c6458f9990f5b" translate="yes" xml:space="preserve">
          <source>Thus, most of the target signal (34.4ppm) is explained by a long-term rising trend (length-scale 41.8 years). The periodic component has an amplitude of 3.27ppm, a decay time of 180 years and a length-scale of 1.44. The long decay time indicates that we have a locally very close to periodic seasonal component. The correlated noise has an amplitude of 0.197ppm with a length scale of 0.138 years and a white-noise contribution of 0.197ppm. Thus, the overall noise level is very small, indicating that the data can be very well explained by the model. The figure shows also that the model makes very confident predictions until around 2015</source>
          <target state="translated">Таким образом,большая часть целевого сигнала (34,4 п.п.)объясняется долгосрочной тенденцией роста (по шкале длины 41,8 года).Периодическая составляющая имеет амплитуду 3,27 промилле,время распада 180 лет и шкалу длины 1,44.Длительное время распада указывает на то,что мы имеем локально очень близкую к периодической сезонной составляющей.Коррелированный шум имеет амплитуду 0.197ppm при шкале длины 0.138 лет и вклад белого шума 0.197ppm.Таким образом,общий уровень шума очень мал,что указывает на то,что данные могут быть очень хорошо объяснены моделью.Рисунок также показывает,что модель делает очень уверенные прогнозы до примерно 2015 г.</target>
        </trans-unit>
        <trans-unit id="4ab3c0245825ab663f7197647adadf073e4b3e64" translate="yes" xml:space="preserve">
          <source>Thus, most of the target signal (34.4ppm) is explained by a long-term rising trend (length-scale 41.8 years). The periodic component has an amplitude of 3.27ppm, a decay time of 180 years and a length-scale of 1.44. The long decay time indicates that we have a locally very close to periodic seasonal component. The correlated noise has an amplitude of 0.197ppm with a length scale of 0.138 years and a white-noise contribution of 0.197ppm. Thus, the overall noise level is very small, indicating that the data can be very well explained by the model. The figure shows also that the model makes very confident predictions until around 2015.</source>
          <target state="translated">Таким образом,большая часть целевого сигнала (34,4 п.п.)объясняется долгосрочной тенденцией роста (по шкале длины 41,8 года).Периодическая составляющая имеет амплитуду 3,27 промилле,время распада 180 лет и шкалу длины 1,44.Длительное время распада указывает на то,что мы имеем локально очень близкую к периодической сезонной составляющей.Коррелированный шум имеет амплитуду 0.197ppm при шкале длины 0.138 лет и вклад белого шума 0.197ppm.Таким образом,общий уровень шума очень мал,что указывает на то,что данные могут быть очень хорошо объяснены моделью.Рисунок также показывает,что модель делает очень уверенные прогнозы до примерно 2015 года.</target>
        </trans-unit>
        <trans-unit id="af16f18f91308907d1dd8226e54112fa0bd29044" translate="yes" xml:space="preserve">
          <source>Tian Zhang, Raghu Ramakrishnan, Maron Livny BIRCH: An efficient data clustering method for large databases. &lt;a href=&quot;http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&quot;&gt;http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&lt;/a&gt;</source>
          <target state="translated">Тиан Чжан, Рагху Рамакришнан, Марон Ливни БЕРЕЗА: эффективный метод кластеризации данных для больших баз данных. &lt;a href=&quot;http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&quot;&gt;http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9d89b88657fcb13ceb20c877ea478d701717a393" translate="yes" xml:space="preserve">
          <source>Tian Zhang, Raghu Ramakrishnan, Maron Livny BIRCH: An efficient data clustering method for large databases. &lt;a href=&quot;https://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&quot;&gt;https://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="867d68dbf4c080ab9e706507919b510dbb556be3" translate="yes" xml:space="preserve">
          <source>Tianqi Chen, Carlos Guestrin, &lt;a href=&quot;https://arxiv.org/abs/1603.02754&quot;&gt;&amp;ldquo;XGBoost: A Scalable Tree Boosting System&amp;rdquo;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d53cad37906f55db18b858cf86bfeef9ad9688eb" translate="yes" xml:space="preserve">
          <source>Tibshirani, R., Hastie, T., Narasimhan, B., &amp;amp; Chu, G. (2002). Diagnosis of multiple cancer types by shrunken centroids of gene expression. Proceedings of the National Academy of Sciences of the United States of America, 99(10), 6567-6572. The National Academy of Sciences.</source>
          <target state="translated">Тибширани, Р., Хасти, Т., Нарасимхан, Б., и Чу, Г. (2002). Диагностика нескольких типов рака по уменьшенным центроидам экспрессии генов. Proceedings of the National Academy of Sciences of the United States of America, 99 (10), 6567-6572. Национальная академия наук.</target>
        </trans-unit>
        <trans-unit id="54643cfd9d395af8d03ef9fab4df1a2cdb437e0c" translate="yes" xml:space="preserve">
          <source>Tie breaking is costly if &lt;code&gt;decision_function_shape='ovr'&lt;/code&gt;, and therefore it is not enabled by default. This example illustrates the effect of the &lt;code&gt;break_ties&lt;/code&gt; parameter for a multiclass classification problem and &lt;code&gt;decision_function_shape='ovr'&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a297f524f28779281bb4e53d7b6af672dcac3672" translate="yes" xml:space="preserve">
          <source>Ties are broken using the secondary method from Leeuw, 1977.</source>
          <target state="translated">Связи разрываются с помощью вторичного метода из Leeuw,1977.</target>
        </trans-unit>
        <trans-unit id="59976e05663a4d82c80a3273030c2c2f87094f4d" translate="yes" xml:space="preserve">
          <source>Ties between features with equal scores will be broken in an unspecified way.</source>
          <target state="translated">Связи между функциями с одинаковым количеством баллов будут нарушены неуказанным образом.</target>
        </trans-unit>
        <trans-unit id="c41dd9e78b42392c90f4c6ddfb54f7863f5482f1" translate="yes" xml:space="preserve">
          <source>Ties in &lt;code&gt;y_scores&lt;/code&gt; are broken by giving maximal rank that would have been assigned to all tied values.</source>
          <target state="translated">Связи в &lt;code&gt;y_scores&lt;/code&gt; разрываются путем присвоения максимального ранга, который был бы присвоен всем связанным значениям.</target>
        </trans-unit>
        <trans-unit id="ba73dffe02601a1abd345b6200b276334877401b" translate="yes" xml:space="preserve">
          <source>Time Series cross-validator</source>
          <target state="translated">Кросс-валидатор временных рядов</target>
        </trans-unit>
        <trans-unit id="bbad16d201e3f82cae87bba42e6286ebcef9d190" translate="yes" xml:space="preserve">
          <source>Time series data is characterised by the correlation between observations that are near in time (&lt;em&gt;autocorrelation&lt;/em&gt;). However, classical cross-validation techniques such as &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt;&lt;code&gt;ShuffleSplit&lt;/code&gt;&lt;/a&gt; assume the samples are independent and identically distributed, and would result in unreasonable correlation between training and testing instances (yielding poor estimates of generalisation error) on time series data. Therefore, it is very important to evaluate our model for time series data on the &amp;ldquo;future&amp;rdquo; observations least like those that are used to train the model. To achieve this, one solution is provided by &lt;a href=&quot;generated/sklearn.model_selection.timeseriessplit#sklearn.model_selection.TimeSeriesSplit&quot;&gt;&lt;code&gt;TimeSeriesSplit&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Данные временных рядов характеризуются корреляцией между близкими по времени наблюдениями ( &lt;em&gt;автокорреляция&lt;/em&gt; ). Однако классические методы перекрестной проверки, такие как &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt; &lt;code&gt;ShuffleSplit&lt;/code&gt; ,&lt;/a&gt; предполагают, что выборки независимы и одинаково распределены, что приведет к необоснованной корреляции между обучающими и тестовыми экземплярами (что дает плохие оценки ошибки обобщения) данных временных рядов. Следовательно, очень важно оценивать нашу модель для данных временных рядов по &amp;laquo;будущим&amp;raquo; наблюдениям, в меньшей степени, чем те, которые используются для обучения модели. Для этого &lt;a href=&quot;generated/sklearn.model_selection.timeseriessplit#sklearn.model_selection.TimeSeriesSplit&quot;&gt; &lt;code&gt;TimeSeriesSplit&lt;/code&gt; &lt;/a&gt; предоставляет одно решение .</target>
        </trans-unit>
        <trans-unit id="a6268d75d578276d37dec9fce6dea804677e6b49" translate="yes" xml:space="preserve">
          <source>Timeout limit for each task to complete. If any task takes longer a TimeOutError will be raised. Only applied when n_jobs != 1</source>
          <target state="translated">Ограничение по времени выполнения каждой задачи.Если какая-либо задача занимает больше времени,будет поднята ошибка TimeOutError.Применяется только при n_jobs !=1.</target>
        </trans-unit>
        <trans-unit id="f98ee87f52adb2c6f3aaf1f01bab51d0b9ae3622" translate="yes" xml:space="preserve">
          <source>Times spent for fitting in seconds. Only present if &lt;code&gt;return_times&lt;/code&gt; is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c46532137bb2ae8358c0137ca60928cd3434340" translate="yes" xml:space="preserve">
          <source>Times spent for scoring in seconds. Only present if &lt;code&gt;return_times&lt;/code&gt; is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="22c6faf6f7a1dbffed43da8c3c0a736a2f22b862" translate="yes" xml:space="preserve">
          <source>Timing and accuracy plots</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="834cbd0fedba36c3380f74ce91ef668820820b53" translate="yes" xml:space="preserve">
          <source>To achieve better accuracy, &lt;code&gt;X_norm_squared&lt;/code&gt; and &lt;code&gt;Y_norm_squared&lt;/code&gt; may be unused if they are passed as &lt;code&gt;float32&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8879146d32620a1e603bf26a188c9426e79a5ed0" translate="yes" xml:space="preserve">
          <source>To address the computational inefficiencies of the brute-force approach, a variety of tree-based data structures have been invented. In general, these structures attempt to reduce the required number of distance calculations by efficiently encoding aggregate distance information for the sample. The basic idea is that if point \(A\) is very distant from point \(B\), and point \(B\) is very close to point \(C\), then we know that points \(A\) and \(C\) are very distant, &lt;em&gt;without having to explicitly calculate their distance&lt;/em&gt;. In this way, the computational cost of a nearest neighbors search can be reduced to \(O[D N \log(N)]\) or better. This is a significant improvement over brute-force for large \(N\).</source>
          <target state="translated">Для решения проблемы вычислительной неэффективности подхода грубой силы были изобретены различные древовидные структуры данных. В общем, эти структуры пытаются уменьшить необходимое количество вычислений расстояния путем эффективного кодирования совокупной информации о расстоянии для выборки. Основная идея состоит в том, что если точка \ (A \) очень удалена от точки \ (B \), а точка \ (B \) очень близко к точке \ (C \), то мы знаем, что точки \ (A \ ) и \ (C \) очень далеки, &lt;em&gt;без необходимости явно вычислять их расстояние&lt;/em&gt; . Таким образом, вычислительные затраты на поиск ближайших соседей могут быть уменьшены до \ (O [DN \ log (N)] \) или лучше. Это значительное улучшение по сравнению с перебором для больших \ (N \).</target>
        </trans-unit>
        <trans-unit id="81ec528524d941df99755c9bb7fceaf80c6a8752" translate="yes" xml:space="preserve">
          <source>To address the inefficiencies of KD Trees in higher dimensions, the &lt;em&gt;ball tree&lt;/em&gt; data structure was developed. Where KD trees partition data along Cartesian axes, ball trees partition data in a series of nesting hyper-spheres. This makes tree construction more costly than that of the KD tree, but results in a data structure which can be very efficient on highly structured data, even in very high dimensions.</source>
          <target state="translated">Чтобы устранить неэффективность KD Trees в более высоких измерениях, была разработана структура данных &lt;em&gt;дерева шара&lt;/em&gt; . Если деревья KD разделяют данные по декартовым осям, то шаровые деревья разделяют данные на ряд вложенных гипер-сфер. Это делает построение дерева более дорогостоящим, чем построение дерева KD, но приводит к структуре данных, которая может быть очень эффективной для сильно структурированных данных даже в очень больших измерениях.</target>
        </trans-unit>
        <trans-unit id="a11d5f0b5df4ea3ced24dc7521fb6d9f97740ba3" translate="yes" xml:space="preserve">
          <source>To address this concern, a number of supervised and unsupervised linear dimensionality reduction frameworks have been designed, such as Principal Component Analysis (PCA), Independent Component Analysis, Linear Discriminant Analysis, and others. These algorithms define specific rubrics to choose an &amp;ldquo;interesting&amp;rdquo; linear projection of the data. These methods can be powerful, but often miss important non-linear structure in the data.</source>
          <target state="translated">Для решения этой проблемы был разработан ряд контролируемых и неконтролируемых структур снижения линейной размерности, таких как анализ главных компонентов (PCA), независимый компонентный анализ, линейный дискриминантный анализ и другие. Эти алгоритмы определяют конкретные рубрики для выбора &amp;laquo;интересной&amp;raquo; линейной проекции данных. Эти методы могут быть мощными, но часто упускают важную нелинейную структуру данных.</target>
        </trans-unit>
        <trans-unit id="c134b5f4c4fa3b034f915a1c4077d9f58401c669" translate="yes" xml:space="preserve">
          <source>To address this issue you can use &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;sklearn.decomposition.PCA&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;whiten=True&lt;/code&gt; to further remove the linear correlation across features.</source>
          <target state="translated">Чтобы решить эту проблему, вы можете использовать &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;sklearn.decomposition.PCA&lt;/code&gt; &lt;/a&gt; с whiten &lt;code&gt;whiten=True&lt;/code&gt; чтобы дополнительно удалить линейную корреляцию между функциями.</target>
        </trans-unit>
        <trans-unit id="5dfb268e42cc748904256c70f6b80b2da01edce9" translate="yes" xml:space="preserve">
          <source>To also transform a test set \(X\), we multiply it with \(V_k\):</source>
          <target state="translated">Чтобы преобразовать тестовый набор \(X\),мы умножаем его на \(V_k\):</target>
        </trans-unit>
        <trans-unit id="6e914d8189fa250ac9b4b7ea3cf2e62431cbcccd" translate="yes" xml:space="preserve">
          <source>To apply an classifier on this data, we need to flatten the image, to turn the data in a (samples, feature) matrix:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ef7600ab8e39fc13b7dc9585804325c8072844d" translate="yes" xml:space="preserve">
          <source>To avoid instability issues in case the system is under-determined, regularization can be applied (Ridge regression) via the &lt;code&gt;ridge_alpha&lt;/code&gt; parameter.</source>
          <target state="translated">Чтобы избежать проблем с нестабильностью в случае, если система недостаточно определена, можно применить регуляризацию (регрессия гребня) с помощью параметра &lt;code&gt;ridge_alpha&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="622754a0a375aafa66f9d8336ffd00fcfc0a1948" translate="yes" xml:space="preserve">
          <source>To avoid memory copy the caller should pass a CSC matrix.</source>
          <target state="translated">Чтобы избежать копирования памяти,звонящий должен пройти CSC матрицу.</target>
        </trans-unit>
        <trans-unit id="21a05d95ccb73f51d245c302b02e9a8f32df0276" translate="yes" xml:space="preserve">
          <source>To avoid memory copy the caller should pass a CSR matrix.</source>
          <target state="translated">Чтобы избежать копирования памяти,звонящий должен передать CSR-матрицу.</target>
        </trans-unit>
        <trans-unit id="e5ab0a4f687079cc593610e8d8c0f15b79824d4d" translate="yes" xml:space="preserve">
          <source>To avoid memory re-allocation it is advised to allocate the initial data in memory directly using that format.</source>
          <target state="translated">Чтобы избежать перераспределения памяти,рекомендуется выделять исходные данные в памяти непосредственно с использованием этого формата.</target>
        </trans-unit>
        <trans-unit id="ee93c7e2ac06e08c1567b0ca209ad480ea5f1b80" translate="yes" xml:space="preserve">
          <source>To avoid the computation of global clustering, for every call of &lt;code&gt;partial_fit&lt;/code&gt; the user is advised</source>
          <target state="translated">Чтобы избежать вычисления глобальной кластеризации, для каждого вызова &lt;code&gt;partial_fit&lt;/code&gt; пользователю рекомендуется</target>
        </trans-unit>
        <trans-unit id="e81cbf7353acbc69eeae43ca8cf143e58e658d10" translate="yes" xml:space="preserve">
          <source>To avoid these potential discrepancies it suffices to divide the number of occurrences of each word in a document by the total number of words in the document: these new features are called &lt;code&gt;tf&lt;/code&gt; for Term Frequencies.</source>
          <target state="translated">Чтобы избежать этих возможных расхождений, достаточно разделить количество вхождений каждого слова в документе на общее количество слов в документе: эти новые функции называются &lt;code&gt;tf&lt;/code&gt; для Term Frequencies.</target>
        </trans-unit>
        <trans-unit id="39f01dfdcdf5847fd1935ba52ba9be2bfc80430b" translate="yes" xml:space="preserve">
          <source>To avoid this problem, nested CV effectively uses a series of train/validation/test set splits. In the inner loop (here executed by &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt;), the score is approximately maximized by fitting a model to each training set, and then directly maximized in selecting (hyper)parameters over the validation set. In the outer loop (here in &lt;a href=&quot;../../modules/generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;cross_val_score&lt;/code&gt;&lt;/a&gt;), generalization error is estimated by averaging test set scores over several dataset splits.</source>
          <target state="translated">Чтобы избежать этой проблемы, вложенное резюме эффективно использует серию разделений на обучение / проверку / набор тестов. Во внутреннем цикле (здесь выполняется &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt; ) оценка приблизительно максимизируется путем подбора модели для каждого обучающего набора, а затем напрямую максимизируется при выборе (гипер) параметров по набору проверки. Во внешнем цикле (здесь в &lt;a href=&quot;../../modules/generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt; &lt;code&gt;cross_val_score&lt;/code&gt; &lt;/a&gt; ) ошибка обобщения оценивается путем усреднения результатов набора тестов по нескольким разбиениям набора данных.</target>
        </trans-unit>
        <trans-unit id="5ed52a0ba64199519b793ee9dad54a31d6d3eaed" translate="yes" xml:space="preserve">
          <source>To avoid unnecessary memory duplication the X and y arguments of the fit method should be directly passed as Fortran-contiguous numpy arrays.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a37b39aad5fcf98e98548e781cdec5193cfe7b97" translate="yes" xml:space="preserve">
          <source>To avoid unnecessary memory duplication the X argument of the fit method should be directly passed as a Fortran-contiguous numpy array.</source>
          <target state="translated">Чтобы избежать ненужного дублирования памяти,аргумент X метода fit должен передаваться непосредственно в виде массива нумерации,граничащего с Fortran.</target>
        </trans-unit>
        <trans-unit id="d9c2f7485084c926a2f68d8587d615406cc01649" translate="yes" xml:space="preserve">
          <source>To be in favorable recovery conditions, we sample the data from a model with a sparse inverse covariance matrix. In addition, we ensure that the data is not too much correlated (limiting the largest coefficient of the precision matrix) and that there a no small coefficients in the precision matrix that cannot be recovered. In addition, with a small number of observations, it is easier to recover a correlation matrix rather than a covariance, thus we scale the time series.</source>
          <target state="translated">Для того чтобы быть в благоприятных условиях восстановления,мы берем данные из модели с разреженной обратной ковариационной матрицей.Кроме того,мы гарантируем,что данные не слишком сильно коррелируют (ограничивая наибольший коэффициент матрицы прецизионности)и что в матрице прецизионности нет малых коэффициентов,которые не могут быть восстановлены.Кроме того,при небольшом количестве наблюдений легче восстановить матрицу корреляции,чем ковариацию,поэтому мы масштабируем временной ряд.</target>
        </trans-unit>
        <trans-unit id="f7fd313aae703eaa110952d34fbc2e74f81a873c" translate="yes" xml:space="preserve">
          <source>To be removed in 0.21</source>
          <target state="translated">Удаляется через 0.21</target>
        </trans-unit>
        <trans-unit id="b656a9f4366f6cbcc5b1e6914e7bc1a8d099ee57" translate="yes" xml:space="preserve">
          <source>To be removed in 0.22</source>
          <target state="translated">Удаляется через 0.22</target>
        </trans-unit>
        <trans-unit id="b622879f90e0f79392a411b5be4ae9945d5e85aa" translate="yes" xml:space="preserve">
          <source>To be removed in 0.24</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc387423485c5a73576ae6f9089ec34a8b143ae6" translate="yes" xml:space="preserve">
          <source>To begin with, all values for \(r\) and \(a\) are set to zero, and the calculation of each iterates until convergence. As discussed above, in order to avoid numerical oscillations when updating the messages, the damping factor \(\lambda\) is introduced to iteration process:</source>
          <target state="translated">Для начала все значения для \(r\)и \(a\)устанавливаются на ноль,а расчет каждого итерата до сходимости.Как обсуждалось выше,чтобы избежать численных колебаний при обновлении сообщений,в итерационный процесс вводится коэффициент демпфирования \(\lambda\):</target>
        </trans-unit>
        <trans-unit id="ebc5cb56aa5d3da850d595b902c1384fa4142906" translate="yes" xml:space="preserve">
          <source>To begin, we&amp;rsquo;ll visualize our data.</source>
          <target state="translated">Для начала визуализируем наши данные.</target>
        </trans-unit>
        <trans-unit id="57e47e513e200b11a216f9768279c1f81e7b3157" translate="yes" xml:space="preserve">
          <source>To benchmark different estimators for your case you can simply change the &lt;code&gt;n_features&lt;/code&gt; parameter in this example: &lt;a href=&quot;../auto_examples/applications/plot_prediction_latency#sphx-glr-auto-examples-applications-plot-prediction-latency-py&quot;&gt;Prediction Latency&lt;/a&gt;. This should give you an estimate of the order of magnitude of the prediction latency.</source>
          <target state="translated">Чтобы сравнить различные оценщики в вашем случае, вы можете просто изменить параметр &lt;code&gt;n_features&lt;/code&gt; в этом примере: &lt;a href=&quot;../auto_examples/applications/plot_prediction_latency#sphx-glr-auto-examples-applications-plot-prediction-latency-py&quot;&gt;Prediction Latency&lt;/a&gt; . Это должно дать вам оценку порядка величины задержки предсказания.</target>
        </trans-unit>
        <trans-unit id="892d831a9e807296347eacb2e8474830ca349663" translate="yes" xml:space="preserve">
          <source>To compare a set of found biclusters to the set of true biclusters, two similarity measures are needed: a similarity measure for individual biclusters, and a way to combine these individual similarities into an overall score.</source>
          <target state="translated">Чтобы сравнить набор найденных биоклустеров с набором истинных биоклустеров,необходимы две меры сходства:мера сходства для отдельных биоклустеров и способ объединить эти индивидуальные сходства в общий балл.</target>
        </trans-unit>
        <trans-unit id="f0ff37a06cd777b22ebe208ab3110388f720b201" translate="yes" xml:space="preserve">
          <source>To compare individual biclusters, several measures have been used. For now, only the Jaccard index is implemented:</source>
          <target state="translated">Для сравнения отдельных билюстеров было использовано несколько мер.На данный момент реализован только индекс Jaccard:</target>
        </trans-unit>
        <trans-unit id="658de85a569a63b4d478720bcfaf7adeb72fbb36" translate="yes" xml:space="preserve">
          <source>To compare the 3 models from this perspective, one can plot the cumulative proportion of claims vs the cumulative proportion of exposure for the test samples order by the model predictions, from safest to riskiest according to each model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="30a2aa60dabe3d1d8b8497c6228442c6c55454f4" translate="yes" xml:space="preserve">
          <source>To control display of warnings.</source>
          <target state="translated">Для управления отображением предупреждений.</target>
        </trans-unit>
        <trans-unit id="6c3d05eecff544d238db6888c87daeb42794f44b" translate="yes" xml:space="preserve">
          <source>To control the verbosity of the procedure.</source>
          <target state="translated">Чтобы контролировать многословие процедуры.</target>
        </trans-unit>
        <trans-unit id="d66f891ca7bde7537002ad52d27fc9dd62dd5881" translate="yes" xml:space="preserve">
          <source>To convert categorical features to such integer codes, we can use the &lt;a href=&quot;generated/sklearn.preprocessing.ordinalencoder#sklearn.preprocessing.OrdinalEncoder&quot;&gt;&lt;code&gt;OrdinalEncoder&lt;/code&gt;&lt;/a&gt;. This estimator transforms each categorical feature to one new feature of integers (0 to n_categories - 1):</source>
          <target state="translated">Чтобы преобразовать категориальные признаки в такие целочисленные коды, мы можем использовать &lt;a href=&quot;generated/sklearn.preprocessing.ordinalencoder#sklearn.preprocessing.OrdinalEncoder&quot;&gt; &lt;code&gt;OrdinalEncoder&lt;/code&gt; &lt;/a&gt; . Этот оценщик преобразует каждую категориальную характеристику в одну новую характеристику целых чисел (от 0 до n_categories - 1):</target>
        </trans-unit>
        <trans-unit id="c4d6b75ae9bd1ab8a2aa45db1ede3ed88ee6cb4c" translate="yes" xml:space="preserve">
          <source>To correct this, the list of labels should be passed in as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="693e8d8ca1982fe1e279b5869b2b710976d06558" translate="yes" xml:space="preserve">
          <source>To counter this effect we can discount the expected RI \(E[\text{RI}]\) of random labelings by defining the adjusted Rand index as follows:</source>
          <target state="translated">Для борьбы с этим эффектом мы можем дисконтировать ожидаемый RI \(E[\text{RI}]\)случайных меток,определив скорректированный индекс Rand следующим образом:</target>
        </trans-unit>
        <trans-unit id="2ccfac714af4138a2df70ede11b2ff4e1963a414" translate="yes" xml:space="preserve">
          <source>To create positive examples click the left mouse button; to create negative examples click the right button.</source>
          <target state="translated">Для создания положительных примеров нажмите левую кнопку мыши,для создания отрицательных-правую.</target>
        </trans-unit>
        <trans-unit id="3c7bf94a5fb077c325503613ed6e46ecc0fdb413" translate="yes" xml:space="preserve">
          <source>To decide on the importance of the features we are going to use LassoCV estimator. The features with the highest absolute &lt;code&gt;coef_&lt;/code&gt; value are considered the most important</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91f3b8c70c19596fa3422a68b56ef8a0e44f9e91" translate="yes" xml:space="preserve">
          <source>To describe the dataset as a linear model we use a ridge regressor with a very small regularization and to model the logarithm of the WAGE.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a890a65f7673c36b72863dcfff2db0d979bb71bc" translate="yes" xml:space="preserve">
          <source>To design our machine-learning pipeline, we first manually check the type of data that we are dealing with:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0bfc36f728f01d8f998e7e774b5cc731a5652d7" translate="yes" xml:space="preserve">
          <source>To disable convergence detection based on inertia, set max_no_improvement to None.</source>
          <target state="translated">Чтобы отключить обнаружение сходимости по инерции,установите max_no_improvement равным None.</target>
        </trans-unit>
        <trans-unit id="644ea86209186f0b63818c18611416bf68aa348b" translate="yes" xml:space="preserve">
          <source>To disable convergence detection based on normalized center change, set tol to 0.0 (default).</source>
          <target state="translated">Чтобы отключить обнаружение сходимости на основе нормализованного изменения центра,установите допуск на 0.0 (по умолчанию).</target>
        </trans-unit>
        <trans-unit id="8f49411326bd4f684fb56ae33f90d4fd9150ab8c" translate="yes" xml:space="preserve">
          <source>To do the exercises, copy the content of the &amp;lsquo;skeletons&amp;rsquo; folder as a new folder named &amp;lsquo;workspace&amp;rsquo;:</source>
          <target state="translated">Для выполнения упражнений скопируйте содержимое папки &amp;laquo;скелеты&amp;raquo; в новую папку с именем &amp;laquo;рабочая область&amp;raquo;:</target>
        </trans-unit>
        <trans-unit id="79cf44a84fa8878b10f291a31335b47430451015" translate="yes" xml:space="preserve">
          <source>To each column, a different transformation can be applied, such as preprocessing or a specific feature extraction method:</source>
          <target state="translated">К каждой колонке можно применить различные преобразования,такие как препроцессирование или метод извлечения специфических признаков:</target>
        </trans-unit>
        <trans-unit id="2e998c39435525bfb05b6223ee051590414cf95b" translate="yes" xml:space="preserve">
          <source>To ensure that estimators yield reasonable predictions for different policyholder types, we can bin test samples according to &lt;code&gt;y_pred&lt;/code&gt; returned by each model. Then for each bin, we compare the mean predicted &lt;code&gt;y_pred&lt;/code&gt;, with the mean observed target:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0a5ce85df1e1aafd2ebf61b7efd7098beb62d7b" translate="yes" xml:space="preserve">
          <source>To estimate a probabilistic model (e.g. a Gaussian model), estimating the precision matrix, that is the inverse covariance matrix, is as important as estimating the covariance matrix. Indeed a Gaussian model is parametrized by the precision matrix.</source>
          <target state="translated">Для оценки вероятностной модели (например,гауссовской модели)оценка матрицы точности,т.е.обратной ковариационной матрицы,так же важна,как и оценка ковариационной матрицы.Действительно,гауссовская модель параметризуется матрицей точности.</target>
        </trans-unit>
        <trans-unit id="06985e50b51113b200d13cecad3eedd2a07fa798" translate="yes" xml:space="preserve">
          <source>To evaluate the impact of the scale of the dataset (&lt;code&gt;n_samples&lt;/code&gt; and &lt;code&gt;n_features&lt;/code&gt;) while controlling the statistical properties of the data (typically the correlation and informativeness of the features), it is also possible to generate synthetic data.</source>
          <target state="translated">Чтобы оценить влияние масштаба набора данных ( &lt;code&gt;n_samples&lt;/code&gt; и &lt;code&gt;n_features&lt;/code&gt; ) при контроле статистических свойств данных (обычно корреляции и информативности функций), также можно сгенерировать синтетические данные.</target>
        </trans-unit>
        <trans-unit id="fa6d485f0cac2ad780f34f2a0f500816dbb434b1" translate="yes" xml:space="preserve">
          <source>To evaluate the pertinence of the used metrics, we will consider as a baseline a &amp;ldquo;dummy&amp;rdquo; estimator that constantly predicts the mean frequency of the training sample.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b81da86f6a51388bf88e8748866dfbc1da10ddb" translate="yes" xml:space="preserve">
          <source>To fully specify a dataset, you need to provide a name and a version, though the version is optional, see &lt;a href=&quot;#openml-versions&quot;&gt;Dataset Versions&lt;/a&gt; below. The dataset contains a total of 1080 examples belonging to 8 different classes:</source>
          <target state="translated">Чтобы полностью указать набор данных, вам необходимо указать имя и версию, хотя версия не является обязательной, см. &amp;laquo; &lt;a href=&quot;#openml-versions&quot;&gt;Версии набора данных&amp;raquo;&lt;/a&gt; ниже. Набор данных содержит в общей сложности 1080 примеров, относящихся к 8 различным классам:</target>
        </trans-unit>
        <trans-unit id="eddbe44ecc236b178d14592239180b4231c2f462" translate="yes" xml:space="preserve">
          <source>To get a better measure of prediction accuracy (which we can use as a proxy for goodness of fit of the model), we can successively split the data in &lt;em&gt;folds&lt;/em&gt; that we use for training and testing:</source>
          <target state="translated">Чтобы получить лучшую меру точности предсказания (которую мы можем использовать в качестве прокси для оценки соответствия модели), мы можем последовательно разделить данные на &lt;em&gt;складки,&lt;/em&gt; которые мы используем для обучения и тестирования:</target>
        </trans-unit>
        <trans-unit id="8f2c7c86e5d1b0f8592203b4a46517414e54ce05" translate="yes" xml:space="preserve">
          <source>To get identical results for each split, set &lt;code&gt;random_state&lt;/code&gt; to an integer.</source>
          <target state="translated">Чтобы получить идентичные результаты для каждого разделения, установите &lt;code&gt;random_state&lt;/code&gt; в целое число.</target>
        </trans-unit>
        <trans-unit id="0228140936e0aced4eaa7c77d90637025c4d0909" translate="yes" xml:space="preserve">
          <source>To get started with this tutorial, you must first install &lt;em&gt;scikit-learn&lt;/em&gt; and all of its required dependencies.</source>
          <target state="translated">Чтобы начать работу с этим руководством, вы должны сначала установить &lt;em&gt;scikit-learn&lt;/em&gt; и все его необходимые зависимости.</target>
        </trans-unit>
        <trans-unit id="8d91bad777aec839541c338ab9f11be081ee54c6" translate="yes" xml:space="preserve">
          <source>To get the signed distance to the hyperplane use &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier.decision_function&quot;&gt;&lt;code&gt;SGDClassifier.decision_function&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">Чтобы получить расстояние со &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier.decision_function&quot;&gt; &lt;code&gt;SGDClassifier.decision_function&lt;/code&gt; &lt;/a&gt; до гиперплоскости, используйте SGDClassifier.decision_function :</target>
        </trans-unit>
        <trans-unit id="507e34b3976bcfaf958e1f0006102fdd2d8713ea" translate="yes" xml:space="preserve">
          <source>To go further we remove one of the 2 features and check what is the impact on the model stability.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ae2612052e54b7be6598947088a287fffd01403" translate="yes" xml:space="preserve">
          <source>To illustrate &lt;a href=&quot;generated/sklearn.dummy.dummyclassifier#sklearn.dummy.DummyClassifier&quot;&gt;&lt;code&gt;DummyClassifier&lt;/code&gt;&lt;/a&gt;, first let&amp;rsquo;s create an imbalanced dataset:</source>
          <target state="translated">Чтобы проиллюстрировать &lt;a href=&quot;generated/sklearn.dummy.dummyclassifier#sklearn.dummy.DummyClassifier&quot;&gt; &lt;code&gt;DummyClassifier&lt;/code&gt; &lt;/a&gt; , сначала давайте создадим несбалансированный набор данных:</target>
        </trans-unit>
        <trans-unit id="e7a02a8f3e922c68cd6ce64dca33ce54683ffb1b" translate="yes" xml:space="preserve">
          <source>To illustrate this with a simple example, let&amp;rsquo;s assume we have 3 classifiers and a 3-class classification problems where we assign equal weights to all classifiers: w1=1, w2=1, w3=1.</source>
          <target state="translated">Чтобы проиллюстрировать это на простом примере, предположим, что у нас есть 3 классификатора и 3 задачи классификации, в которых мы присваиваем всем классификаторам одинаковые веса: w1 = 1, w2 = 1, w3 = 1.</target>
        </trans-unit>
        <trans-unit id="27fe4060cc8aa9166cda2609863b9fdd12999baf" translate="yes" xml:space="preserve">
          <source>To illustrate this, PCA is performed comparing the use of data with &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt;&lt;code&gt;StandardScaler&lt;/code&gt;&lt;/a&gt; applied, to unscaled data. The results are visualized and a clear difference noted. The 1st principal component in the unscaled set can be seen. It can be seen that feature #13 dominates the direction, being a whole two orders of magnitude above the other features. This is contrasted when observing the principal component for the scaled version of the data. In the scaled version, the orders of magnitude are roughly the same across all the features.</source>
          <target state="translated">Чтобы проиллюстрировать это, PCA сравнивает использование данных с примененным &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt; &lt;code&gt;StandardScaler&lt;/code&gt; &lt;/a&gt; с немасштабированными данными. Результаты визуализируются, и отмечается четкая разница. Виден 1-й главный компонент немасштабированного набора. Можно видеть, что объект № 13 доминирует над направлением, будучи на два порядка выше остальных объектов. Это контрастирует при наблюдении за главным компонентом масштабированной версии данных. В масштабированной версии порядки величины для всех функций примерно одинаковы.</target>
        </trans-unit>
        <trans-unit id="952f60109f87198cc4767d483a08ad921abb5966" translate="yes" xml:space="preserve">
          <source>To improve the conditioning of the problem (i.e. mitigating the &lt;a href=&quot;#curse-of-dimensionality&quot;&gt;The curse of dimensionality&lt;/a&gt;), it would be interesting to select only the informative features and set non-informative ones, like feature 2 to 0. Ridge regression will decrease their contribution, but not set them to zero. Another penalization approach, called &lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;Lasso&lt;/a&gt; (least absolute shrinkage and selection operator), can set some coefficients to zero. Such methods are called &lt;strong&gt;sparse method&lt;/strong&gt; and sparsity can be seen as an application of Occam&amp;rsquo;s razor: &lt;em&gt;prefer simpler models&lt;/em&gt;.</source>
          <target state="translated">Чтобы улучшить обусловленность проблемы (т.е. смягчить &lt;a href=&quot;#curse-of-dimensionality&quot;&gt;проклятие размерности&lt;/a&gt; ), было бы интересно выбрать только информативные функции и установить неинформативные, например, функцию 2 равной 0. Риджевая регрессия уменьшит их вклад, но не установит. их к нулю. Другой подход к наказанию, называемый &lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;лассо&lt;/a&gt; (оператор наименьшего абсолютного сжатия и выбора), может устанавливать некоторые коэффициенты равными нулю. Такие методы называются &lt;strong&gt;разреженными методами,&lt;/strong&gt; а разреженность можно рассматривать как применение бритвы Оккама: &lt;em&gt;предпочитайте более простые модели&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="172f2bacd24a45cfb82f466d14d1d58833b9ee69" translate="yes" xml:space="preserve">
          <source>To install the latest version (with pip):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f028c20036ea78694db90136b8cb3004f099e0bf" translate="yes" xml:space="preserve">
          <source>To limit the memory consumption, we queue examples up to a fixed amount before feeding them to the learner.</source>
          <target state="translated">Чтобы ограничить потребление памяти,мы ставим примеры в очередь до фиксированного количества перед подачей ученику.</target>
        </trans-unit>
        <trans-unit id="61f860c325e06c4f97b9f4c7ced3d5279054856d" translate="yes" xml:space="preserve">
          <source>To load from an external dataset, please refer to &lt;a href=&quot;../../datasets/index#external-datasets&quot;&gt;loading external datasets&lt;/a&gt;.</source>
          <target state="translated">Чтобы загрузить из внешнего набора данных, обратитесь к &lt;a href=&quot;../../datasets/index#external-datasets&quot;&gt;разделу Загрузка внешних наборов данных&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="d787fd22509da728f07846c2b5d3ecac1d6b4105" translate="yes" xml:space="preserve">
          <source>To load the data and visualize the images:</source>
          <target state="translated">Для загрузки данных и визуализации изображений:</target>
        </trans-unit>
        <trans-unit id="b4be4dde535adc435619c6f0e295e0ce05bad72b" translate="yes" xml:space="preserve">
          <source>To make the example run faster, we use very few hidden units, and train only for a very short time. Training longer would result in weights with a much smoother spatial appearance.</source>
          <target state="translated">Чтобы заставить пример работать быстрее,мы используем очень мало скрытых единиц,и тренируемся только в течение очень короткого времени.Более длительные тренировки привели бы к тому,что веса стали бы намного более плавными в пространстве.</target>
        </trans-unit>
        <trans-unit id="c413b102ea3791278492eefc26d38700197d19c5" translate="yes" xml:space="preserve">
          <source>To make the example run faster, we use very few hidden units, and train only for a very short time. Training longer would result in weights with a much smoother spatial appearance. The example will throw a warning because it doesn&amp;rsquo;t converge, in this case this is what we want because of CI&amp;rsquo;s time constraints.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96ba992a3c5af68caa74d107191c5a3c32806c93" translate="yes" xml:space="preserve">
          <source>To make the preprocessor, tokenizer and analyzers aware of the model parameters it is possible to derive from the class and override the &lt;code&gt;build_preprocessor&lt;/code&gt;, &lt;code&gt;build_tokenizer&lt;/code&gt; and &lt;code&gt;build_analyzer&lt;/code&gt; factory methods instead of passing custom functions.</source>
          <target state="translated">Чтобы препроцессор, токенизатор и анализаторы знали параметры модели, можно &lt;code&gt;build_preprocessor&lt;/code&gt; от класса и переопределить фабричные методы build_preprocessor , &lt;code&gt;build_tokenizer&lt;/code&gt; и &lt;code&gt;build_analyzer&lt;/code&gt; вместо передачи пользовательских функций.</target>
        </trans-unit>
        <trans-unit id="c0f08b8475e4b67e5147698ce9ccb818f0394d27" translate="yes" xml:space="preserve">
          <source>To make this more explicit, consider the following notation:</source>
          <target state="translated">Чтобы сделать это более понятным,рассмотрим следующую нотацию:</target>
        </trans-unit>
        <trans-unit id="8ada09feb86f8f3751dffbeeaba0e1e4f69156a7" translate="yes" xml:space="preserve">
          <source>To obtain a fully probabilistic model, the output \(y\) is assumed to be Gaussian distributed around \(X w\):</source>
          <target state="translated">Для получения полностью вероятностной модели предполагается,что выход \(y\)будет гауссовским,распространяемым по адресу \(X w\):</target>
        </trans-unit>
        <trans-unit id="65178eef58b048e690e1c210520e38da80789880" translate="yes" xml:space="preserve">
          <source>To perform classification with generalized linear models, see &lt;a href=&quot;#logistic-regression&quot;&gt;Logistic regression&lt;/a&gt;.</source>
          <target state="translated">Чтобы выполнить классификацию с помощью обобщенных линейных моделей, см. &lt;a href=&quot;#logistic-regression&quot;&gt;Логистическая регрессия&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="72dc32b7225454e8d7c0ec26f14d95b55df2c79a" translate="yes" xml:space="preserve">
          <source>To quantify estimation error, we plot the likelihood of unseen data for different values of the shrinkage parameter. We also show the choices by cross-validation, or with the LedoitWolf and OAS estimates.</source>
          <target state="translated">Для количественной оценки погрешности оценки строится вероятность невидимых данных для различных значений параметра усадки.Мы также показываем выбор путем перекрестной проверки или с помощью оценок LedoitWolf и OAS.</target>
        </trans-unit>
        <trans-unit id="397393d3de29d9ed57b4f231bd553afc264bafab" translate="yes" xml:space="preserve">
          <source>To return the corresponding classical subsets of kddcup 99. If None, return the entire kddcup 99 dataset.</source>
          <target state="translated">Вернуть соответствующие классические подмножества kddcup 99.Если Нет,вернуть весь набор данных kddcup 99.</target>
        </trans-unit>
        <trans-unit id="b0e502baa68f0434bb574994337b41db58fa07c4" translate="yes" xml:space="preserve">
          <source>To run cross-validation on multiple metrics and also to return train scores, fit times and score times.</source>
          <target state="translated">Для проведения перекрестной проверки по нескольким показателям,а также для возврата очков поезда,времени посадки и времени очков.</target>
        </trans-unit>
        <trans-unit id="2d79b95a40b4d1ea2f276f13509aebc984e2d932" translate="yes" xml:space="preserve">
          <source>To see how this generalizes the binary log loss given above, note that in the binary case, \(p_{i,0} = 1 - p_{i,1}\) and \(y_{i,0} = 1 - y_{i,1}\), so expanding the inner sum over \(y_{i,k} \in \{0,1\}\) gives the binary log loss.</source>
          <target state="translated">Чтобы посмотреть,как это обобщает приведенный выше двоичный лог-потерь,обратите внимание,что в двоичном случае \(p_{i,0}=1-p_{i,1}\)и \(y_{i,0}=1-y_{i,1}\),таким образом расширяя внутреннюю сумму над \(y_{i,k}\in \{0,1\}\)дает двоичный лог-потерь.</target>
        </trans-unit>
        <trans-unit id="25684d8b1766d360b665e8498a44a626b2b5bd13" translate="yes" xml:space="preserve">
          <source>To set &lt;code&gt;n_clusters=None&lt;/code&gt; initially</source>
          <target state="translated">Чтобы изначально установить &lt;code&gt;n_clusters=None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="78f293aec6a6c458449c6dc3bcd71b696525a449" translate="yes" xml:space="preserve">
          <source>To speed up the algorithm, accept only those bins with at least min_bin_freq points as seeds.</source>
          <target state="translated">Чтобы ускорить работу алгоритма,в качестве семян принимайте только те бункеры,в которых есть хотя бы мин_бин_фрек.</target>
        </trans-unit>
        <trans-unit id="e1dfcbed698085a7ab462cf760bf24e65a9e8400" translate="yes" xml:space="preserve">
          <source>To speed up the algorithm, accept only those bins with at least min_bin_freq points as seeds. If not defined, set to 1.</source>
          <target state="translated">Чтобы ускорить работу алгоритма,в качестве семян принимайте только те бункеры,в которых есть хотя бы мин_бин_фрек.Если не определено,установите значение 1.</target>
        </trans-unit>
        <trans-unit id="d139a616dfe019ba73a251e6419e9ddac4a94c0f" translate="yes" xml:space="preserve">
          <source>To support imputation in inductive mode we store each feature&amp;rsquo;s estimator during the &lt;code&gt;fit&lt;/code&gt; phase, and predict without refitting (in order) during the &lt;code&gt;transform&lt;/code&gt; phase.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d14a37b58107d5112ea5c1494d2809710215a276" translate="yes" xml:space="preserve">
          <source>To train the &lt;code&gt;estimators&lt;/code&gt; and &lt;code&gt;final_estimator&lt;/code&gt;, the &lt;code&gt;fit&lt;/code&gt; method needs to be called on the training data:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd2f04d7c6e080a2cce0d2e7339e598ba17acac5" translate="yes" xml:space="preserve">
          <source>To try to predict the outcome on a new document we need to extract the features using almost the same feature extracting chain as before. The difference is that we call &lt;code&gt;transform&lt;/code&gt; instead of &lt;code&gt;fit_transform&lt;/code&gt; on the transformers, since they have already been fit to the training set:</source>
          <target state="translated">Чтобы попытаться предсказать результат для нового документа, нам нужно извлечь признаки, используя почти ту же цепочку извлечения признаков, что и раньше. Разница в том, что мы вызываем &lt;code&gt;transform&lt;/code&gt; вместо &lt;code&gt;fit_transform&lt;/code&gt; для трансформаторов, поскольку они уже соответствуют обучающему набору:</target>
        </trans-unit>
        <trans-unit id="5da67914dc5314b6125944bb748e1a3d6c08f736" translate="yes" xml:space="preserve">
          <source>To understand the use of LDA in dimensionality reduction, it is useful to start with a geometric reformulation of the LDA classification rule explained above. We write \(K\) for the total number of target classes. Since in LDA we assume that all classes have the same estimated covariance \(\Sigma\), we can rescale the data so that this covariance is the identity:</source>
          <target state="translated">Чтобы понять использование LDA в сокращении размерности,полезно начать с геометрического переосмысления правила классификации LDA,объясненного выше.Для общего количества целевых классов мы пишем \(K\).Поскольку в LDA мы предполагаем,что все классы имеют одну и ту же оценочную ковариацию \(\Sigma\),мы можем перемасштабировать данные таким образом,чтобы эта ковариация была идентична:</target>
        </trans-unit>
        <trans-unit id="6df5e0eab0e1e02def9ae99e68c6ddf1a841d6d1" translate="yes" xml:space="preserve">
          <source>To use &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; for novelty detection, i.e. predict labels or compute the score of abnormality of new unseen data, you need to instantiate the estimator with the &lt;code&gt;novelty&lt;/code&gt; parameter set to &lt;code&gt;True&lt;/code&gt; before fitting the estimator:</source>
          <target state="translated">Чтобы использовать &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt; для обнаружения новизны, т. Е. Прогнозирования меток или вычисления оценки отклонения от нормы новых невидимых данных, вам необходимо создать экземпляр оценщика с параметром &lt;code&gt;novelty&lt;/code&gt; установленным на &lt;code&gt;True&lt;/code&gt; , перед подгонкой оценщика:</target>
        </trans-unit>
        <trans-unit id="011ed6ad19bc2f123579a7e50ff8b4dad33bf360" translate="yes" xml:space="preserve">
          <source>To use joblib.Memory to cache the svmlight file:</source>
          <target state="translated">Использовать joblib.Memory для кэширования файла svmlight:</target>
        </trans-unit>
        <trans-unit id="e88dca9a24e84cd773e046a28a4daa4e8217f9da" translate="yes" xml:space="preserve">
          <source>To use text files in a scikit-learn classification or clustering algorithm, you will need to use the :mod`~sklearn.feature_extraction.text` module to build a feature extraction transformer that suits your problem.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e11936ea84de206f18d8b708b6f4eca9fb6c8b59" translate="yes" xml:space="preserve">
          <source>To use text files in a scikit-learn classification or clustering algorithm, you will need to use the &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; module to build a feature extraction transformer that suits your problem.</source>
          <target state="translated">Чтобы использовать текстовые файлы в алгоритме классификации или кластеризации scikit-learn, вам нужно будет использовать модуль &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; для создания преобразователя извлечения функций, который подходит для вашей задачи.</target>
        </trans-unit>
        <trans-unit id="c7aa2d2ef894f356c354736ecb4235681bee95b2" translate="yes" xml:space="preserve">
          <source>To use this dataset with scikit-learn, we transform each 8x8 image into a feature vector of length 64</source>
          <target state="translated">Чтобы использовать этот набор данных с scikit-learn,мы преобразовываем каждое изображение 8x8 в функциональный вектор длиной 64</target>
        </trans-unit>
        <trans-unit id="f5d271c927cff9ea25de07089e51938b7e86a2a7" translate="yes" xml:space="preserve">
          <source>To use this model as a classifier, we just need to estimate from the training data the class priors \(P(y=k)\) (by the proportion of instances of class \(k\)), the class means \(\mu_k\) (by the empirical sample class means) and the covariance matrices (either by the empirical sample class covariance matrices, or by a regularized estimator: see the section on shrinkage below).</source>
          <target state="translated">Для использования этой модели в качестве классификатора достаточно оценить по учебным данным классы-приоры \(P(y=k)\)(по доле экземпляров класса \(k\)),класс означает \(\mu_k\)(по средствам эмпирической выборки класса)и ковариационные матрицы (либо по ковариационным матрицам класса эмпирической выборки,либо по регуляризованной оценке:см.раздел &quot;Усадка&quot; ниже).</target>
        </trans-unit>
        <trans-unit id="54c39e1b5f1a8214dbbbffa4ce79accc0474a39a" translate="yes" xml:space="preserve">
          <source>To use this model for classification, one needs to combine a &lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt;&lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt;&lt;/a&gt; instance that learns the optimal transformation with a &lt;a href=&quot;generated/sklearn.neighbors.kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier&quot;&gt;&lt;code&gt;KNeighborsClassifier&lt;/code&gt;&lt;/a&gt; instance that performs the classification in the projected space. Here is an example using the two classes:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e5117e9f756d52dfb6878a7715bd7c9bf590353" translate="yes" xml:space="preserve">
          <source>To validate a model we need a scoring function (see &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;Metrics and scoring: quantifying the quality of predictions&lt;/a&gt;), for example accuracy for classifiers. The proper way of choosing multiple hyperparameters of an estimator are of course grid search or similar methods (see &lt;a href=&quot;grid_search#grid-search&quot;&gt;Tuning the hyper-parameters of an estimator&lt;/a&gt;) that select the hyperparameter with the maximum score on a validation set or multiple validation sets. Note that if we optimized the hyperparameters based on a validation score the validation score is biased and not a good estimate of the generalization any longer. To get a proper estimate of the generalization we have to compute the score on another test set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d015bfb570917361c4b4abaaa59f5e623d8c463" translate="yes" xml:space="preserve">
          <source>To validate a model we need a scoring function (see &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;Model evaluation: quantifying the quality of predictions&lt;/a&gt;), for example accuracy for classifiers. The proper way of choosing multiple hyperparameters of an estimator are of course grid search or similar methods (see &lt;a href=&quot;grid_search#grid-search&quot;&gt;Tuning the hyper-parameters of an estimator&lt;/a&gt;) that select the hyperparameter with the maximum score on a validation set or multiple validation sets. Note that if we optimized the hyperparameters based on a validation score the validation score is biased and not a good estimate of the generalization any longer. To get a proper estimate of the generalization we have to compute the score on another test set.</source>
          <target state="translated">Для проверки модели нам нужна функция &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;оценки&lt;/a&gt; (см. Оценка модели: количественная оценка качества прогнозов ), например, точность для классификаторов. Правильный способ выбора нескольких гиперпараметров оценщика - это, конечно, поиск по сетке или аналогичные методы (см. &lt;a href=&quot;grid_search#grid-search&quot;&gt;Настройка&lt;/a&gt; гиперпараметров оценщика ), которые выбирают гиперпараметр с максимальной оценкой на наборе проверки или нескольких наборах проверки. Обратите внимание, что если мы оптимизировали гиперпараметры на основе оценки валидации, оценка валидации будет смещена и больше не будет хорошей оценкой обобщения. Чтобы получить правильную оценку обобщения, мы должны вычислить оценку на другом наборе тестов.</target>
        </trans-unit>
        <trans-unit id="4f24d3986e58b34af3ea2c4b07af932b987ecc57" translate="yes" xml:space="preserve">
          <source>To verify this interpretation we plot the variability of the AGE and EXPERIENCE coefficient.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="baa10199f999bc30e58b0035ac2f6e51132399ed" translate="yes" xml:space="preserve">
          <source>To visualize the probability weighting, we fit each classifier on the training set and plot the predicted class probabilities for the first sample in this example dataset.</source>
          <target state="translated">Чтобы визуализировать взвешивание вероятностей,мы подгоняем каждый классификатор к обучающему набору и строим прогнозные классовые вероятности для первой выборки в этом примере набора данных.</target>
        </trans-unit>
        <trans-unit id="ba234a16bb1a2ae4619585ca04988c1afd574060" translate="yes" xml:space="preserve">
          <source>Tokenize the documents and count the occurrences of token and return them as a sparse matrix</source>
          <target state="translated">Токенирование документов и подсчёт случаев токена и возврат их в разрежённую матрицу</target>
        </trans-unit>
        <trans-unit id="e89caeb25fc24a274e225b242d49cc6fb7ddfa72" translate="yes" xml:space="preserve">
          <source>Tokenizing text with &lt;code&gt;scikit-learn&lt;/code&gt;</source>
          <target state="translated">Токенизация текста с помощью &lt;code&gt;scikit-learn&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="45d4a0ebe499a5d042ac0f7bc4284501d3667758" translate="yes" xml:space="preserve">
          <source>Tolerance for &amp;lsquo;arpack&amp;rsquo; method Not used if eigen_solver==&amp;rsquo;dense&amp;rsquo;.</source>
          <target state="translated">Допуск для метода 'arpack' Не используется, если eigen_solver == 'density'.</target>
        </trans-unit>
        <trans-unit id="318dfc593e0123f93a8fe309f411532f48eea756" translate="yes" xml:space="preserve">
          <source>Tolerance for ARPACK. 0 means machine precision. Ignored by randomized SVD solver.</source>
          <target state="translated">Толерантность к ARPACK.0 означает точность станка.Игнорируется рандомизированным SVD solver.</target>
        </trans-unit>
        <trans-unit id="13511570864a98fa2d61f43da929b11b4894937f" translate="yes" xml:space="preserve">
          <source>Tolerance for Hessian eigenmapping method. Only used if &lt;code&gt;method == 'hessian'&lt;/code&gt;</source>
          <target state="translated">Допуск для метода отображения собственных значений Гессе. Используется только если &lt;code&gt;method == 'hessian'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e4c877ba267607a99e62c8b31f7891feda117cf7" translate="yes" xml:space="preserve">
          <source>Tolerance for Hessian eigenmapping method. Only used if method == &amp;lsquo;hessian&amp;rsquo;</source>
          <target state="translated">Допуск для метода отображения собственных значений Гессе. Используется только если method == 'hessian'</target>
        </trans-unit>
        <trans-unit id="aeb25ea9c0101939a4336136b4e11db71f1bb1be" translate="yes" xml:space="preserve">
          <source>Tolerance for modified LLE method. Only used if &lt;code&gt;method == 'modified'&lt;/code&gt;</source>
          <target state="translated">Допуск для модифицированного метода LLE. Используется только если &lt;code&gt;method == 'modified'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="b6502cfb6f414093cd5faf0376953824eae5e86f" translate="yes" xml:space="preserve">
          <source>Tolerance for modified LLE method. Only used if method == &amp;lsquo;modified&amp;rsquo;</source>
          <target state="translated">Допуск для модифицированного метода LLE. Используется только если метод == 'изменен'</target>
        </trans-unit>
        <trans-unit id="40eaf2d9a188116c07595886d4a67c9121557ecf" translate="yes" xml:space="preserve">
          <source>Tolerance for singular values computed by svd_solver == &amp;lsquo;arpack&amp;rsquo;.</source>
          <target state="translated">Допуск для сингулярных значений, вычисленных svd_solver == 'arpack'.</target>
        </trans-unit>
        <trans-unit id="a495f50d68c5f0d21905244c442ac1ec46831c6d" translate="yes" xml:space="preserve">
          <source>Tolerance for stopping criteria.</source>
          <target state="translated">Толерантность к критериям остановки.</target>
        </trans-unit>
        <trans-unit id="1f900b2be351c5e1d6397b25c9a2e6c5e5c36343" translate="yes" xml:space="preserve">
          <source>Tolerance for stopping criterion.</source>
          <target state="translated">Толерантность к критерию остановки.</target>
        </trans-unit>
        <trans-unit id="4d73abe23fd3517118aa70ae58840719c14ae6a0" translate="yes" xml:space="preserve">
          <source>Tolerance for the early stopping. When the loss is not improving by at least tol for &lt;code&gt;n_iter_no_change&lt;/code&gt; iterations (if set to a number), the training stops.</source>
          <target state="translated">Допуск к преждевременной остановке. Когда потери не улучшаются по крайней мере на tol для итераций &lt;code&gt;n_iter_no_change&lt;/code&gt; (если установлено число), обучение прекращается.</target>
        </trans-unit>
        <trans-unit id="334a1d6597d473e85cc8725e20828e0c9824ea02" translate="yes" xml:space="preserve">
          <source>Tolerance for the optimization. When the loss or score is not improving by at least &lt;code&gt;tol&lt;/code&gt; for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive iterations, unless &lt;code&gt;learning_rate&lt;/code&gt; is set to &amp;lsquo;adaptive&amp;rsquo;, convergence is considered to be reached and training stops.</source>
          <target state="translated">Допуск на оптимизацию. Когда потеря или оценка не улучшаются по крайней мере на &lt;code&gt;tol&lt;/code&gt; для &lt;code&gt;n_iter_no_change&lt;/code&gt; последовательных итераций, если только &lt;code&gt;learning_rate&lt;/code&gt; не установлено на &amp;laquo;адаптивное&amp;raquo;, сходимость считается достигнутой, и обучение прекращается.</target>
        </trans-unit>
        <trans-unit id="6938a4dcb29969d15aaa6cafefb8f09b830ed305" translate="yes" xml:space="preserve">
          <source>Tolerance for the stopping condition.</source>
          <target state="translated">Толерантность к состоянию остановки.</target>
        </trans-unit>
        <trans-unit id="3a49445cc3e76e8c0deab47f4b10c5bd7dc33960" translate="yes" xml:space="preserve">
          <source>Tolerance of the stopping condition.</source>
          <target state="translated">Толерантность к состоянию остановки.</target>
        </trans-unit>
        <trans-unit id="48a48ded1ae1ed29a7ddaed19c15db301472918d" translate="yes" xml:space="preserve">
          <source>Tolerance on update at each iteration.</source>
          <target state="translated">Допуск на обновление на каждой итерации.</target>
        </trans-unit>
        <trans-unit id="a2223ba588ac8a94dc6928512bbe1ae559b46f6b" translate="yes" xml:space="preserve">
          <source>Tolerance used in the iterative algorithm default 1e-06.</source>
          <target state="translated">Допуск,используемый в итерационном алгоритме по умолчанию 1e-06.</target>
        </trans-unit>
        <trans-unit id="20a2955c412dcae35aa2ef964ce8c2d4b1c07dcb" translate="yes" xml:space="preserve">
          <source>Tolerance when calculating spatial median.</source>
          <target state="translated">Толерантность при расчете пространственной медианы.</target>
        </trans-unit>
        <trans-unit id="f3d0c54c4b7882f5280f0492c26f2bf33d35d2a2" translate="yes" xml:space="preserve">
          <source>Tony Blair</source>
          <target state="translated">Тони Блэр</target>
        </trans-unit>
        <trans-unit id="e1781cb6d03ccb2216639c1d54de7540b9fc2c2b" translate="yes" xml:space="preserve">
          <source>Tools for imputing missing values are discussed at &lt;a href=&quot;impute#impute&quot;&gt;Imputation of missing values&lt;/a&gt;.</source>
          <target state="translated">Инструменты для вменения пропущенных значений обсуждаются в &lt;a href=&quot;impute#impute&quot;&gt;разделе &amp;laquo;Вменение пропущенных значений&amp;raquo;&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0d184ce2992ee425b9d4cc3d528da94fb4da399d" translate="yes" xml:space="preserve">
          <source>Tophat kernel (&lt;code&gt;kernel = 'tophat'&lt;/code&gt;)</source>
          <target state="translated">Ядро Tophat ( &lt;code&gt;kernel = 'tophat'&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="0954aa60533f43dc3b2b9a9cbdee11a74f79eada" translate="yes" xml:space="preserve">
          <source>Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation</source>
          <target state="translated">Тематическое извлечение с помощью факторно-отрицательной матрицы и латентного дирихлетного выделения</target>
        </trans-unit>
        <trans-unit id="97129616afbfcb01d33b44619c8bf267194395ac" translate="yes" xml:space="preserve">
          <source>Total Phenols:</source>
          <target state="translated">Полные Фенолы:</target>
        </trans-unit>
        <trans-unit id="b9c3723a92a74173bb8adb739559660c0010b476" translate="yes" xml:space="preserve">
          <source>Total impurity of leaves vs effective alphas of pruned tree</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24a9e81269d05c734577a89440230faee238f7b2" translate="yes" xml:space="preserve">
          <source>Total log-likelihood of the data in X.</source>
          <target state="translated">Общая лог-вероятность данных в X.</target>
        </trans-unit>
        <trans-unit id="1861e0049c1f17066ecafccd7b29a27b43a45cf0" translate="yes" xml:space="preserve">
          <source>Total log-likelihood of the data in X. This is normalized to be a probability density, so the value will be low for high-dimensional data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0acc1077bbd3872347f5d4223b32bfa85b2dc24b" translate="yes" xml:space="preserve">
          <source>Total number of documents. Only used in the &lt;a href=&quot;#sklearn.decomposition.LatentDirichletAllocation.partial_fit&quot;&gt;&lt;code&gt;partial_fit&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4055747cee4593e58e4a6dcbfa7d6ccc61845cf0" translate="yes" xml:space="preserve">
          <source>Total number of documents. Only used in the &lt;code&gt;partial_fit&lt;/code&gt; method.</source>
          <target state="translated">Общее количество документов. Используется только в методе &lt;code&gt;partial_fit&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="aed40ed5719d059f29eba1177189a60b01059871" translate="yes" xml:space="preserve">
          <source>Total phenols</source>
          <target state="translated">Всего фенолов</target>
        </trans-unit>
        <trans-unit id="babba0bc0e9a3e36ce98f362a62519c8eacb94cb" translate="yes" xml:space="preserve">
          <source>Toward the Optimal Preconditioned Eigensolver: Locally Optimal Block Preconditioned Conjugate Gradient Method Andrew V. Knyazev &lt;a href=&quot;https://doi.org/10.1137%2FS1064827500366124&quot;&gt;https://doi.org/10.1137%2FS1064827500366124&lt;/a&gt;</source>
          <target state="translated">На пути к оптимальному предварительно обусловленному собственному вычислителю: локально оптимальный блочный предварительно обусловленный метод сопряженного градиента Андрей В. Князев &lt;a href=&quot;https://doi.org/10.1137%2FS1064827500366124&quot;&gt;https://doi.org/10.1137%2FS1064827500366124&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e3ae1e8d052cc2d0c25bbda7e5d0370ec624b1e8" translate="yes" xml:space="preserve">
          <source>Toy example of 1D regression using linear, polynomial and RBF kernels.</source>
          <target state="translated">Игрушечный пример 1D регрессии с использованием линейных,полиномиальных и RBF ядер.</target>
        </trans-unit>
        <trans-unit id="264fa08a131d6382d6715d8c951f2b5bea1c373c" translate="yes" xml:space="preserve">
          <source>Traceback example, note how the line of the error is indicated as well as the values of the parameter passed to the function that triggered the exception, even though the traceback happens in the child process:</source>
          <target state="translated">В примере трассировки обратите внимание на то,как указывается строка ошибки,а также на значения параметра,переданного функции,которая спровоцировала исключение,даже если трассировка происходит в дочернем процессе:</target>
        </trans-unit>
        <trans-unit id="8718fa41b5577d15733c0d074d4e6ea2d5f88486" translate="yes" xml:space="preserve">
          <source>Tracking, International Journal of Computer Vision, Volume 77, Issue 1-3, pp. 125-141, May 2008.</source>
          <target state="translated">Отслеживание,Международный журнал компьютерного зрения,том 77,выпуск 1-3,стр.125-141,май 2008.</target>
        </trans-unit>
        <trans-unit id="20662c705376209f11480639e3ee11e7bf62f8df" translate="yes" xml:space="preserve">
          <source>Traditional regression metrics such as Mean Squared Error and Mean Absolute Error are hard to meaningfully interpret on count values with many zeros.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e4826fce9da6f5f03d1b11115df13e0bc514c4a" translate="yes" xml:space="preserve">
          <source>Train all data by multiple calls to partial_fit.</source>
          <target state="translated">Обучение всех данных по нескольким вызовам на функцию partial_fit.</target>
        </trans-unit>
        <trans-unit id="bd98708380c7e60a9c0a687f254abca8478a36f8" translate="yes" xml:space="preserve">
          <source>Train and test sizes may be different in each fold, with a difference of at most &lt;code&gt;n_classes&lt;/code&gt;.</source>
          <target state="translated">Размеры &lt;code&gt;n_classes&lt;/code&gt; и тестов могут быть разными в каждом сгибе, с разницей не более n_classes .</target>
        </trans-unit>
        <trans-unit id="1c08c1bee3835bcafdb50e8cdda68c68d71fa67e" translate="yes" xml:space="preserve">
          <source>Train error vs Test error</source>
          <target state="translated">Ошибка поезда vs Ошибка теста</target>
        </trans-unit>
        <trans-unit id="357c94d50b669e3c60f0758a6140ed17dc81af61" translate="yes" xml:space="preserve">
          <source>Train l1-penalized logistic regression models on a binary classification problem derived from the Iris dataset.</source>
          <target state="translated">Поезд l1-пенализованных логистических регрессионных моделей по двоичной проблеме классификации,полученной из набора данных Iris.</target>
        </trans-unit>
        <trans-unit id="5099d1b071bb02f5306e84c9c0e29bbe834adc72" translate="yes" xml:space="preserve">
          <source>Train models on the diabetes dataset</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0cfcb0c276264df865da734aa7faab6c6b43fed6" translate="yes" xml:space="preserve">
          <source>Train the model using libsvm (low-level method)</source>
          <target state="translated">Обучение модели с помощью libsvm (низкоуровневый метод)</target>
        </trans-unit>
        <trans-unit id="b7dd566e0e9177f3a0300b3c2ac1d09a00aaeda2" translate="yes" xml:space="preserve">
          <source>Training a Random Forest and Plotting the ROC Curve</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff5331ad7dc89bf5a9dd23c31ab738af7815c499" translate="yes" xml:space="preserve">
          <source>Training a classifier</source>
          <target state="translated">Обучение классификатору</target>
        </trans-unit>
        <trans-unit id="8dcfc4ff7c1f7cc06878c0cf93f4198eb475ff8d" translate="yes" xml:space="preserve">
          <source>Training classifiers</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f0630eb2ecfdd0ed6f7defc6642e6c0143bcbf3" translate="yes" xml:space="preserve">
          <source>Training data</source>
          <target state="translated">Данные тренинга</target>
        </trans-unit>
        <trans-unit id="6c7c988c62ce8a65ab6394bf4f62bdef696bbe60" translate="yes" xml:space="preserve">
          <source>Training data, requires length = n_samples</source>
          <target state="translated">Данные тренировки,требуется длина=n_образец</target>
        </trans-unit>
        <trans-unit id="c0c6cec2e93954e8c33880af1baef2b15439d9d5" translate="yes" xml:space="preserve">
          <source>Training data, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the number of features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70fa8e3174eef9a1ccfc0bda8b38c7cfbf09ffd6" translate="yes" xml:space="preserve">
          <source>Training data, where n_samples in the number of samples and n_features is the number of features.</source>
          <target state="translated">Обучающие данные,где n_образцов в количестве образцов и n_функций-это количество функций.</target>
        </trans-unit>
        <trans-unit id="1d999bb02f6364cf15c69e5533af993a3fc0fdd8" translate="yes" xml:space="preserve">
          <source>Training data, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">Обучающие данные,где n_образцы-количество образцов,а n_функции-количество функций.</target>
        </trans-unit>
        <trans-unit id="c4f931e6893a5565e07f4500ddfb86c154c8b1a3" translate="yes" xml:space="preserve">
          <source>Training data, which is also required for prediction. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead the precomputed training matrix, of shape (n_samples, n_samples).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f12731d4ed32a02266da09997a2bf0e000555cf6" translate="yes" xml:space="preserve">
          <source>Training data, which is also required for prediction. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead the precomputed training matrix, shape = [n_samples, n_samples].</source>
          <target state="translated">Данные обучения, которые также необходимы для прогнозирования. Если ядро ​​== &amp;laquo;предварительно вычислено&amp;raquo;, это вместо предварительно вычисленной обучающей матрицы, shape = [n_samples, n_samples].</target>
        </trans-unit>
        <trans-unit id="c5441fed149296831061b9151bd71d563327dc0d" translate="yes" xml:space="preserve">
          <source>Training data.</source>
          <target state="translated">Данные по обучению.</target>
        </trans-unit>
        <trans-unit id="4319dec91a5574f9382b1b679ba9c82bf44c0f15" translate="yes" xml:space="preserve">
          <source>Training data. If array or matrix, shape [n_samples, n_features], or [n_samples, n_samples] if metric=&amp;rsquo;precomputed&amp;rsquo;.</source>
          <target state="translated">Данные обучения. Если массив или матрица, форма [n_samples, n_features] или [n_samples, n_samples], если metric = 'precomputed'.</target>
        </trans-unit>
        <trans-unit id="744e21c8d62df0575ccae05fe593cde4f20f55b7" translate="yes" xml:space="preserve">
          <source>Training data. If array or matrix, the shape is (n_samples, n_features), or (n_samples, n_samples) if metric=&amp;rsquo;precomputed&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6ee318ff46063d0c81310a68af0a95508a0a339" translate="yes" xml:space="preserve">
          <source>Training data. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead a precomputed kernel matrix, of shape (n_samples, n_samples).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3cc715a75ede17772899f7cc9ab69882475a79bc" translate="yes" xml:space="preserve">
          <source>Training data. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead a precomputed kernel matrix, shape = [n_samples, n_samples].</source>
          <target state="translated">Данные обучения. Если ядро ​​== &amp;laquo;предварительно вычислено&amp;raquo;, это вместо этого предварительно вычисленная матрица ядра, shape = [n_samples, n_samples].</target>
        </trans-unit>
        <trans-unit id="6ea489741914be2912ee247eeaf800f3ba49e6d8" translate="yes" xml:space="preserve">
          <source>Training data. If using GCV, will be cast to float64 if necessary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b12ede4c226e6e2f235813d30bce55744269c03f" translate="yes" xml:space="preserve">
          <source>Training data. Must fulfill input requirements of first step of the pipeline.</source>
          <target state="translated">Данные по обучению.Должны соответствовать входным требованиям первой ступени трубопровода.</target>
        </trans-unit>
        <trans-unit id="d5044fd4a2ac02d5a0b137f2f3b7fd6b8f65a006" translate="yes" xml:space="preserve">
          <source>Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If &lt;code&gt;y&lt;/code&gt; is mono-output then &lt;code&gt;X&lt;/code&gt; can be sparse.</source>
          <target state="translated">Данные обучения. Передайте данные напрямую как непрерывные данные Fortran, чтобы избежать ненужного дублирования памяти. Если &lt;code&gt;y&lt;/code&gt; моно-вывод, то &lt;code&gt;X&lt;/code&gt; может быть разреженным.</target>
        </trans-unit>
        <trans-unit id="8ed7855d8da328d2505a0bcd1c3302665b72cb3d" translate="yes" xml:space="preserve">
          <source>Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If y is mono-output, X can be sparse.</source>
          <target state="translated">Данные по обучению.Передавайте данные непосредственно в формате Fortran,чтобы избежать ненужного дублирования памяти.Если y-моно-выпуск,то X может быть разреженным.</target>
        </trans-unit>
        <trans-unit id="4c004afef287030c2dcb4a937f43adb06e1cdf0e" translate="yes" xml:space="preserve">
          <source>Training data. Shape [n_samples, n_features], or [n_samples, n_samples] if affinity==&amp;rsquo;precomputed&amp;rsquo;.</source>
          <target state="translated">Данные обучения. Форма [n_samples, n_features] или [n_samples, n_samples], если affinity == 'precomputed'.</target>
        </trans-unit>
        <trans-unit id="30765b444b768ceb7d6bccc7cc4dd80dd79e1fcb" translate="yes" xml:space="preserve">
          <source>Training instances to cluster, or distances between instances if &lt;code&gt;affinity='precomputed'&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7fd3fb257a793666a84757ce13a7e7b97d84277" translate="yes" xml:space="preserve">
          <source>Training instances to cluster, or distances between instances if &lt;code&gt;metric='precomputed'&lt;/code&gt;. If a sparse matrix is provided, it will be converted into a sparse &lt;code&gt;csr_matrix&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="106fdf378e3c73e01e49b8eb92780c5d664680e0" translate="yes" xml:space="preserve">
          <source>Training instances to cluster, or similarities / affinities between instances if &lt;code&gt;affinity='precomputed'&lt;/code&gt;. If a sparse feature matrix is provided, it will be converted into a sparse &lt;code&gt;csr_matrix&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e31b10426b1248f84a44c65b36e8acd0e5e7589c" translate="yes" xml:space="preserve">
          <source>Training instances to cluster, or similarities / affinities between instances if &lt;code&gt;affinity='precomputed'&lt;/code&gt;. If a sparse matrix is provided in a format other than &lt;code&gt;csr_matrix&lt;/code&gt;, &lt;code&gt;csc_matrix&lt;/code&gt;, or &lt;code&gt;coo_matrix&lt;/code&gt;, it will be converted into a sparse &lt;code&gt;csr_matrix&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be8959fb1d08ac2482d5adecb9cc6d42cd3487ff" translate="yes" xml:space="preserve">
          <source>Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous.</source>
          <target state="translated">Учебные примеры для кластера.Следует отметить,что данные будут преобразованы в C-заказ,что вызовет копирование памяти,если данные не являются C-сопряженными.</target>
        </trans-unit>
        <trans-unit id="eed67f947767b8d48d69b1a746024e52c70765e3" translate="yes" xml:space="preserve">
          <source>Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it&amp;rsquo;s not in CSR format.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1fb973e1446d09c43085a14e14217bfa82f35fac" translate="yes" xml:space="preserve">
          <source>Training set and testing set</source>
          <target state="translated">Учебный и испытательный набор</target>
        </trans-unit>
        <trans-unit id="ea59a824d416e7ea0dc63df33b1afa59cdb64566" translate="yes" xml:space="preserve">
          <source>Training set.</source>
          <target state="translated">Тренировочный набор.</target>
        </trans-unit>
        <trans-unit id="3c518c488676e60e90ca53bcc0aa7271b669fe4d" translate="yes" xml:space="preserve">
          <source>Training set: only the shape is used to find optimal random matrix dimensions based on the theory referenced in the afore mentioned papers.</source>
          <target state="translated">Учебный набор:только форма используется для нахождения оптимальных случайных размеров матрицы на основе теории,упомянутой в вышеупомянутых работах.</target>
        </trans-unit>
        <trans-unit id="68d52cda6c0756d21c2527d22eda07d7e45f55d9" translate="yes" xml:space="preserve">
          <source>Training target.</source>
          <target state="translated">Тренировочная цель.</target>
        </trans-unit>
        <trans-unit id="32e48bd3169f82f98b7879700514da5daba97549" translate="yes" xml:space="preserve">
          <source>Training targets. Must fulfill label requirements for all steps of the pipeline.</source>
          <target state="translated">Учебные цели.Должны соответствовать требованиям по маркировке для всех этапов трубопровода.</target>
        </trans-unit>
        <trans-unit id="bc89d708a926da60c1e855065f294a150e4844da" translate="yes" xml:space="preserve">
          <source>Training vector, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the total number of features.</source>
          <target state="translated">Вектор обучения, где &lt;code&gt;n_samples&lt;/code&gt; - это количество выборок, а &lt;code&gt;n_features&lt;/code&gt; - общее количество функций.</target>
        </trans-unit>
        <trans-unit id="325dc392b957558d0accbc4c288eabf85d0d476c" translate="yes" xml:space="preserve">
          <source>Training vector, where n_samples in the number of samples and n_features is the number of features.</source>
          <target state="translated">Вектор обучения,где n_образцов в количестве сэмплов и n_функций-это количество признаков.</target>
        </trans-unit>
        <trans-unit id="01000b19ae19a1d02ea4ceb374852ca509745c92" translate="yes" xml:space="preserve">
          <source>Training vector, where n_samples in the number of samples and n_features is the number of features. Note that centroid shrinking cannot be used with sparse matrices.</source>
          <target state="translated">Вектор обучения,где n_образцов в количестве сэмплов и n_функций-это количество признаков.Обратите внимание,что центроидная усадка не может использоваться с разреженными матрицами.</target>
        </trans-unit>
        <trans-unit id="6a8354ff2f178d04d8fd18ac8502cba6a9d2e53e" translate="yes" xml:space="preserve">
          <source>Training vector, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">Вектор обучения,где n_samples-количество сэмплов,а n_features-количество признаков.</target>
        </trans-unit>
        <trans-unit id="d6cf7c60af251621aaa911db11caacf9c4de19a4" translate="yes" xml:space="preserve">
          <source>Training vector, where n_samples is the number of samples and n_features is the number of features. Note that centroid shrinking cannot be used with sparse matrices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23811d7edf5d74f8278700a3182a9d6e499aa68e" translate="yes" xml:space="preserve">
          <source>Training vectors, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the number of features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66e0bce9861c05444da85a9795d5edcc3de5cb5e" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">Обучающие векторы,где n_samples-количество сэмплов,а n_features-количество признаков.</target>
        </trans-unit>
        <trans-unit id="f64b8abd734d5648613b346b4bb3c97a56c66bbf" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of features. For kernel=&amp;rdquo;precomputed&amp;rdquo;, the expected shape of X is (n_samples, n_samples).</source>
          <target state="translated">Обучающие векторы, где n_samples - это количество выборок, а n_features - количество функций. Для kernel = &quot;precomputed&quot; ожидаемая форма X будет (n_samples, n_samples).</target>
        </trans-unit>
        <trans-unit id="f07e6c81521ffea6a563851833abed1de8063cb9" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of features. Here, each feature of X is assumed to be from a different categorical distribution. It is further assumed that all categories of each feature are represented by the numbers 0, &amp;hellip;, n - 1, where n refers to the total number of categories for the given feature. This can, for instance, be achieved with the help of OrdinalEncoder.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1d0a9d845fc3b099041b2d0f31be0d050a7001e" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of features. When using GCV, will be cast to float64 if necessary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee5e82a19ba6d9a5b4fc8f431028f4e0ae5cae2a" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of predictors.</source>
          <target state="translated">Обучающие векторы,где n_образцы-количество сэмплов,а n_функции-количество предикторов.</target>
        </trans-unit>
        <trans-unit id="3dbb8cbc3c8d093280069e8e889d1e0c62e1afde" translate="yes" xml:space="preserve">
          <source>Transform X back to its original space.</source>
          <target state="translated">Трансформируйте Х обратно в исходное пространство.</target>
        </trans-unit>
        <trans-unit id="dbfeebba6e53c937056143e8cf1258378ae1c26d" translate="yes" xml:space="preserve">
          <source>Transform X back to original space.</source>
          <target state="translated">Трансформируйте Х обратно в исходное пространство.</target>
        </trans-unit>
        <trans-unit id="aad161b5ffd8fb6722cd74d5621a58697eead90e" translate="yes" xml:space="preserve">
          <source>Transform X into a (weighted) graph of k nearest neighbors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="063b3e20cfa017691e75a65bb052691ed38fc79c" translate="yes" xml:space="preserve">
          <source>Transform X into a (weighted) graph of neighbors nearer than a radius</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2fcdcd20eec681f04cc400d1e7a3d3a35f46ced9" translate="yes" xml:space="preserve">
          <source>Transform X into subcluster centroids dimension.</source>
          <target state="translated">Преобразовать Х в подкластерные центроиды.</target>
        </trans-unit>
        <trans-unit id="da3379264043ea94358e5b4b01ce80967c41f1a5" translate="yes" xml:space="preserve">
          <source>Transform X separately by each transformer, concatenate results.</source>
          <target state="translated">Трансформируйте Х по отдельности для каждого трансформатора,а затем согласуйте результаты.</target>
        </trans-unit>
        <trans-unit id="054e9dc484301382a53ef7807c44414f413c3b43" translate="yes" xml:space="preserve">
          <source>Transform X to a cluster-distance space.</source>
          <target state="translated">Трансформируйте Х в кластерно-дистанционное пространство.</target>
        </trans-unit>
        <trans-unit id="9340d4e978871cfc2faf3772609beb4370b76837" translate="yes" xml:space="preserve">
          <source>Transform X to ordinal codes.</source>
          <target state="translated">Трансформируйте Х в ординарные коды.</target>
        </trans-unit>
        <trans-unit id="d750cda6e828d45a370fec4538601ee99b5443be" translate="yes" xml:space="preserve">
          <source>Transform X using one-hot encoding.</source>
          <target state="translated">Преобразование X с использованием одноразрядной кодировки.</target>
        </trans-unit>
        <trans-unit id="f9e88a65d85f54852f98655b3f250fdbf7750c92" translate="yes" xml:space="preserve">
          <source>Transform X using the forward function.</source>
          <target state="translated">Трансформируйте X с помощью функции перемотки вперед.</target>
        </trans-unit>
        <trans-unit id="fb06535ce9222390887b51d0862f28eec382f495" translate="yes" xml:space="preserve">
          <source>Transform X using the inverse function.</source>
          <target state="translated">Трансформируйте Х с помощью обратной функции.</target>
        </trans-unit>
        <trans-unit id="55b2dc92fd17631d37a113cafae1257246c63b9f" translate="yes" xml:space="preserve">
          <source>Transform X.</source>
          <target state="translated">Трансформируй Х.</target>
        </trans-unit>
        <trans-unit id="df5b966033d10ab5ffd4498c25f3563581fac3a4" translate="yes" xml:space="preserve">
          <source>Transform a count matrix to a normalized tf or tf-idf representation</source>
          <target state="translated">Преобразование счетной матрицы в нормализованное представление tf или tf-idf</target>
        </trans-unit>
        <trans-unit id="c6579300b554475d257c93a2551d1e7ac8d00f29" translate="yes" xml:space="preserve">
          <source>Transform a count matrix to a tf or tf-idf representation</source>
          <target state="translated">Преобразование счетной матрицы в представление tf или tf-idf</target>
        </trans-unit>
        <trans-unit id="cfe77beec60d283a1ae2557849fffc568b20c2b6" translate="yes" xml:space="preserve">
          <source>Transform a new matrix using the built clustering</source>
          <target state="translated">Преобразование новой матрицы с помощью построенной кластеризации</target>
        </trans-unit>
        <trans-unit id="eb758f2f9f4d3b4a21a0f5aa711d86b7f433cb44" translate="yes" xml:space="preserve">
          <source>Transform a sequence of documents to a document-term matrix.</source>
          <target state="translated">Преобразование последовательности документов в документ-матрицу.</target>
        </trans-unit>
        <trans-unit id="90d7961623626a54873e65ae75f5e5aedaf80a7d" translate="yes" xml:space="preserve">
          <source>Transform a sequence of instances to a scipy.sparse matrix.</source>
          <target state="translated">Преобразовать последовательность инстансов в матрицу scipy.sparse.</target>
        </trans-unit>
        <trans-unit id="482237f55f57c5ab1436ea9ad6e0ca3a5497f2c8" translate="yes" xml:space="preserve">
          <source>Transform a signal as a sparse combination of Ricker wavelets. This example visually compares different sparse coding methods using the &lt;a href=&quot;../../modules/generated/sklearn.decomposition.sparsecoder#sklearn.decomposition.SparseCoder&quot;&gt;&lt;code&gt;sklearn.decomposition.SparseCoder&lt;/code&gt;&lt;/a&gt; estimator. The Ricker (also known as Mexican hat or the second derivative of a Gaussian) is not a particularly good kernel to represent piecewise constant signals like this one. It can therefore be seen how much adding different widths of atoms matters and it therefore motivates learning the dictionary to best fit your type of signals.</source>
          <target state="translated">Преобразуйте сигнал как разреженную комбинацию вейвлетов Рикера. В этом примере визуально сравниваются различные методы разреженного кодирования с помощью &lt;a href=&quot;../../modules/generated/sklearn.decomposition.sparsecoder#sklearn.decomposition.SparseCoder&quot;&gt; &lt;code&gt;sklearn.decomposition.SparseCoder&lt;/code&gt; &lt;/a&gt; . Риккер (также известный как мексиканская шляпа или вторая производная от гауссианы) не особенно хорошее ядро ​​для представления кусочно-постоянных сигналов, подобных этому. Таким образом, можно увидеть, насколько важно добавление атомов разной ширины и, следовательно, мотивирует изучение словаря, чтобы он наилучшим образом соответствовал вашему типу сигналов.</target>
        </trans-unit>
        <trans-unit id="3c3158f9e95a76dac9ab046600d246dc683b1322" translate="yes" xml:space="preserve">
          <source>Transform array or sparse matrix X back to feature mappings.</source>
          <target state="translated">Преобразование массива или разреженной матрицы X обратно в сопоставления функций.</target>
        </trans-unit>
        <trans-unit id="43aed443a30ff04a0a7d38cae0c2e3f2c765ad45" translate="yes" xml:space="preserve">
          <source>Transform between iterable of iterables and a multilabel format</source>
          <target state="translated">Преобразование между итерабельными итерабельными и многоячеистым форматом</target>
        </trans-unit>
        <trans-unit id="8428b18b095eb02611727f6a1283e0146f4aea18" translate="yes" xml:space="preserve">
          <source>Transform binary labels back to multi-class labels</source>
          <target state="translated">Преобразование бинарных этикеток обратно в многоклассные этикетки</target>
        </trans-unit>
        <trans-unit id="2d5fb2d774241a80b97c22822072a1cd5822cad7" translate="yes" xml:space="preserve">
          <source>Transform data X according to the fitted model.</source>
          <target state="translated">Преобразование данных Х в соответствии с установленной моделью.</target>
        </trans-unit>
        <trans-unit id="e993947ab9336eb409d6a8eb55c55e2b5b858d46" translate="yes" xml:space="preserve">
          <source>Transform data back to its original space.</source>
          <target state="translated">Трансформируйте данные обратно в исходное пространство.</target>
        </trans-unit>
        <trans-unit id="b922af176e5b4295d0d766cd496f7523d4754428" translate="yes" xml:space="preserve">
          <source>Transform data to polynomial features</source>
          <target state="translated">Преобразование данных в полиномы</target>
        </trans-unit>
        <trans-unit id="f1a4a6b05048c3643e26b0d505b52199b7895296" translate="yes" xml:space="preserve">
          <source>Transform dataset.</source>
          <target state="translated">Трансформируй набор данных.</target>
        </trans-unit>
        <trans-unit id="00a7e9f2b3e643cac0fe08c5b1d0d59cfff5c504" translate="yes" xml:space="preserve">
          <source>Transform discretized data back to original feature space.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0146265304f248a8c03f040ea5d584981839ec0b" translate="yes" xml:space="preserve">
          <source>Transform documents to document-term matrix.</source>
          <target state="translated">Преобразование документов в матрицу документов.</target>
        </trans-unit>
        <trans-unit id="778e7579ae52504e167839efee081ba3167de93f" translate="yes" xml:space="preserve">
          <source>Transform feature-&amp;gt;value dicts to array or sparse matrix.</source>
          <target state="translated">Функция преобразования-&amp;gt; значение указывает на массив или разреженную матрицу.</target>
        </trans-unit>
        <trans-unit id="8fde1456e50a374e1e8877ac2d0ea9941a580f00" translate="yes" xml:space="preserve">
          <source>Transform features by scaling each feature to a given range.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8f4f5c3bee4bfd8c782321e0d4eb227c2d3191b" translate="yes" xml:space="preserve">
          <source>Transform features using quantiles information.</source>
          <target state="translated">Функции преобразования с использованием информации квантилей.</target>
        </trans-unit>
        <trans-unit id="ace4ae2489dd9688eddb3a58e732664d39d28a92" translate="yes" xml:space="preserve">
          <source>Transform labels back to original encoding.</source>
          <target state="translated">Преобразуйте метки обратно в исходную кодировку.</target>
        </trans-unit>
        <trans-unit id="76c682df30bb4975f2641f2e89f16cc0b5f2d625" translate="yes" xml:space="preserve">
          <source>Transform labels to normalized encoding.</source>
          <target state="translated">Преобразование этикеток в нормализованную кодировку.</target>
        </trans-unit>
        <trans-unit id="e6d8f7568400d53b2f444fa6cbf018c08b09552e" translate="yes" xml:space="preserve">
          <source>Transform multi-class labels to binary labels</source>
          <target state="translated">Преобразование многоклассных этикеток в двоичные этикетки</target>
        </trans-unit>
        <trans-unit id="ec1f3a72d306387b537de1b3b116fbdf51b17550" translate="yes" xml:space="preserve">
          <source>Transform new data by linear interpolation</source>
          <target state="translated">Преобразование новых данных путем линейной интерполяции</target>
        </trans-unit>
        <trans-unit id="7e25dbc81754715628745ec728c6c249ac9d1737" translate="yes" xml:space="preserve">
          <source>Transform new points into embedding space.</source>
          <target state="translated">Преобразовывать новые точки во встраиваемое пространство.</target>
        </trans-unit>
        <trans-unit id="17e15b65d999776fc7cb047cfc38d87f9b340eec" translate="yes" xml:space="preserve">
          <source>Transform the data X according to the fitted NMF model</source>
          <target state="translated">Преобразование данных X в соответствии с установленной моделью NMF.</target>
        </trans-unit>
        <trans-unit id="28a4737ac1d13b4e451237dc699b89c49f7fb862" translate="yes" xml:space="preserve">
          <source>Transform the given indicator matrix into label sets</source>
          <target state="translated">Преобразовать данную индикаторную матрицу в наборы этикеток</target>
        </trans-unit>
        <trans-unit id="38739bda11e07f48ac023acb8323ed328f115bd5" translate="yes" xml:space="preserve">
          <source>Transform the given label sets</source>
          <target state="translated">Преобразовать данные наборы этикеток</target>
        </trans-unit>
        <trans-unit id="92a052e88a019f5aca9bb96a9137d202560617b4" translate="yes" xml:space="preserve">
          <source>Transform the sources back to the mixed data (apply mixing matrix).</source>
          <target state="translated">Преобразование источников обратно в смешанные данные (применить матрицу смешивания).</target>
        </trans-unit>
        <trans-unit id="6414c408546f181e607c3ec28647dd72e64872ea" translate="yes" xml:space="preserve">
          <source>Transform your features into a higher dimensional, sparse space. Then train a linear model on these features.</source>
          <target state="translated">Превратите свои особенности в более компактное и скудное пространство.Затем подготовьте линейную модель по этим характеристикам.</target>
        </trans-unit>
        <trans-unit id="d3709f378c935401f6b259df9cce5a50135da098" translate="yes" xml:space="preserve">
          <source>Transformed array.</source>
          <target state="translated">Преобразованный массив.</target>
        </trans-unit>
        <trans-unit id="4a8a97e010ec7ac27b50257ef7ee542c13ba8846" translate="yes" xml:space="preserve">
          <source>Transformed data</source>
          <target state="translated">преобразованные данные</target>
        </trans-unit>
        <trans-unit id="d460e113769e190612a2b959c1c729d7e8676439" translate="yes" xml:space="preserve">
          <source>Transformed data in the binned space.</source>
          <target state="translated">Преобразованные данные в мусорном пространстве.</target>
        </trans-unit>
        <trans-unit id="14642329121567cf9f5775d8a6512d3b978fccd2" translate="yes" xml:space="preserve">
          <source>Transformed data matrix</source>
          <target state="translated">преобразованная матрица данных</target>
        </trans-unit>
        <trans-unit id="0d3a338b719647431757293955a1513d13c572f4" translate="yes" xml:space="preserve">
          <source>Transformed data.</source>
          <target state="translated">Преобразованные данные.</target>
        </trans-unit>
        <trans-unit id="08b12f8aaa8632b66a6a22bc4de550a469c3cc9c" translate="yes" xml:space="preserve">
          <source>Transformed dataset.</source>
          <target state="translated">Преобразованный набор данных.</target>
        </trans-unit>
        <trans-unit id="eeb85e59603c1cea29acb31c92a29204737376ea" translate="yes" xml:space="preserve">
          <source>Transformed input.</source>
          <target state="translated">Преобразованный вход.</target>
        </trans-unit>
        <trans-unit id="0a6145f06a4913811002ff339bc5284d2892e790" translate="yes" xml:space="preserve">
          <source>Transformed samples</source>
          <target state="translated">Преобразованные образцы</target>
        </trans-unit>
        <trans-unit id="a40fe3e47da3940e6c654b4aca4fd3b4db53b382" translate="yes" xml:space="preserve">
          <source>Transformed values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b6f242e80f2185c5234be3f41a48f40589d58f3" translate="yes" xml:space="preserve">
          <source>Transformer instance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd414e8652819a2c899c58cada9c3dd8cc66e071" translate="yes" xml:space="preserve">
          <source>Transformer mixin that performs feature selection given a support mask</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d517e36599e67ec967c7be2afac6d7777579d1a" translate="yes" xml:space="preserve">
          <source>Transformer used in &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt;.</source>
          <target state="translated">Трансформатор используется в &lt;code&gt;fit&lt;/code&gt; и &lt;code&gt;predict&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="43471a7ace97310a9577002aa9803e00d83e6192" translate="yes" xml:space="preserve">
          <source>Transformers are usually combined with classifiers, regressors or other estimators to build a composite estimator. The most common tool is a &lt;a href=&quot;#pipeline&quot;&gt;Pipeline&lt;/a&gt;. Pipeline is often used in combination with &lt;a href=&quot;#feature-union&quot;&gt;FeatureUnion&lt;/a&gt; which concatenates the output of transformers into a composite feature space. &lt;a href=&quot;#transformed-target-regressor&quot;&gt;TransformedTargetRegressor&lt;/a&gt; deals with transforming the &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-target&quot;&gt;target&lt;/a&gt; (i.e. log-transform &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-171&quot;&gt;y&lt;/a&gt;). In contrast, Pipelines only transform the observed data (&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-x&quot;&gt;X&lt;/a&gt;).</source>
          <target state="translated">Преобразователи обычно комбинируются с классификаторами, регрессорами или другими оценщиками для построения составного оценщика. Самый распространенный инструмент - &lt;a href=&quot;#pipeline&quot;&gt;конвейер&lt;/a&gt; . Конвейер часто используется в сочетании с &lt;a href=&quot;#feature-union&quot;&gt;FeatureUnion,&lt;/a&gt; который объединяет выходные данные преобразователей в составное пространство функций. &lt;a href=&quot;#transformed-target-regressor&quot;&gt;TransformedTargetRegressor&lt;/a&gt; занимается преобразованием &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-target&quot;&gt;цели&lt;/a&gt; (т. Е. Логарифмическим преобразованием &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-171&quot;&gt;y&lt;/a&gt; ). Напротив, конвейеры преобразуют только наблюдаемые данные ( &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-x&quot;&gt;X&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="021fd2002f82b7c8da7b92d01fe659fdcbdaeb82" translate="yes" xml:space="preserve">
          <source>Transformers are usually combined with classifiers, regressors or other estimators to build a composite estimator. The most common tool is a &lt;a href=&quot;#pipeline&quot;&gt;Pipeline&lt;/a&gt;. Pipeline is often used in combination with &lt;a href=&quot;#feature-union&quot;&gt;FeatureUnion&lt;/a&gt; which concatenates the output of transformers into a composite feature space. &lt;a href=&quot;#transformed-target-regressor&quot;&gt;TransformedTargetRegressor&lt;/a&gt; deals with transforming the &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-target&quot;&gt;target&lt;/a&gt; (i.e. log-transform &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-177&quot;&gt;y&lt;/a&gt;). In contrast, Pipelines only transform the observed data (&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-x&quot;&gt;X&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b69fe15775501662a569d2ed632ddbe970e558ef" translate="yes" xml:space="preserve">
          <source>Transformers for missing value imputation</source>
          <target state="translated">Трансформаторы для вменения пропущенных значений</target>
        </trans-unit>
        <trans-unit id="4804df5ca1652cab2567ab10e41eae2d30b7e99a" translate="yes" xml:space="preserve">
          <source>Transforming Classifier Scores into Accurate Multiclass Probability Estimates, B. Zadrozny &amp;amp; C. Elkan, (KDD 2002)</source>
          <target state="translated">Преобразование оценок классификатора в точные оценки вероятности нескольких классов, Б. Задрозный и К. Элкан (KDD 2002)</target>
        </trans-unit>
        <trans-unit id="74f517360774a680819178109aa2b52b87d4fd99" translate="yes" xml:space="preserve">
          <source>Transforming distance to well-behaved similarities</source>
          <target state="translated">Преобразование расстояния до хорошо сохранившегося сходства</target>
        </trans-unit>
        <trans-unit id="87156c340b6aec33fafb3545fc791ff4187014aa" translate="yes" xml:space="preserve">
          <source>Transforms between iterable of iterables and a multilabel format, e.g. a (samples x classes) binary matrix indicating the presence of a class label.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dfe17b4b683a10ef2eafef30897d9c629bf96dd6" translate="yes" xml:space="preserve">
          <source>Transforms discretized data back to original feature space.</source>
          <target state="translated">Преобразовывает дискретизированные данные обратно в оригинальное функциональное пространство.</target>
        </trans-unit>
        <trans-unit id="5bd7a9a7032f01002afe1d21dc1635e87bd5dbc6" translate="yes" xml:space="preserve">
          <source>Transforms features by scaling each feature to a given range.</source>
          <target state="translated">Преобразование элементов путем масштабирования каждого элемента до заданного диапазона.</target>
        </trans-unit>
        <trans-unit id="45675a7235910659531092f94ca2cac1226cb6a9" translate="yes" xml:space="preserve">
          <source>Transforms lists of feature-value mappings to vectors.</source>
          <target state="translated">Преобразование списков отображений признаков в векторы.</target>
        </trans-unit>
        <trans-unit id="18a051a7877c1a9e6b194ac68c49193ac689d698" translate="yes" xml:space="preserve">
          <source>Transforms text into a sparse matrix of n-gram counts.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff596a653686d4986dda1851c66682d846f4bf4d" translate="yes" xml:space="preserve">
          <source>Transforms the image samples in X into a matrix of patch data.</source>
          <target state="translated">Преобразовывает образцы изображений в X в матрицу патч-данных.</target>
        </trans-unit>
        <trans-unit id="aff42f13a1dfe3735469a5dd26ab12a5bac4a9ad" translate="yes" xml:space="preserve">
          <source>Tree pruning</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dda8f4221caceb0e1b9d09350500616b39f0c3c5" translate="yes" xml:space="preserve">
          <source>Tree&amp;rsquo;s Feature Importance from Mean Decrease in Impurity (MDI)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6a25d0e3691aa7e7e60fcc1d61ee6046c7d09b3" translate="yes" xml:space="preserve">
          <source>Tree-based estimators (see the &lt;a href=&quot;classes#module-sklearn.tree&quot;&gt;&lt;code&gt;sklearn.tree&lt;/code&gt;&lt;/a&gt; module and forest of trees in the &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt;&lt;code&gt;sklearn.ensemble&lt;/code&gt;&lt;/a&gt; module) can be used to compute feature importances, which in turn can be used to discard irrelevant features (when coupled with the &lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt;&lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt;&lt;/a&gt; meta-transformer):</source>
          <target state="translated">&lt;a href=&quot;classes#module-sklearn.tree&quot;&gt; &lt;code&gt;sklearn.tree&lt;/code&gt; &lt;/a&gt; основе дерева (см. Модуль sklearn.tree и лес деревьев в модуле &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt; &lt;code&gt;sklearn.ensemble&lt;/code&gt; &lt;/a&gt; ) могут использоваться для вычисления значимости функций, которые, в свою очередь, могут использоваться для отбрасывания нерелевантных функций (в сочетании с &lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt; &lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt; &lt;/a&gt; мета-преобразователь):</target>
        </trans-unit>
        <trans-unit id="ccdf4aec1fccb56109a1e3945469e98a8d62aca9" translate="yes" xml:space="preserve">
          <source>Tree-based estimators (see the &lt;a href=&quot;classes#module-sklearn.tree&quot;&gt;&lt;code&gt;sklearn.tree&lt;/code&gt;&lt;/a&gt; module and forest of trees in the &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt;&lt;code&gt;sklearn.ensemble&lt;/code&gt;&lt;/a&gt; module) can be used to compute impurity-based feature importances, which in turn can be used to discard irrelevant features (when coupled with the &lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt;&lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt;&lt;/a&gt; meta-transformer):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3629b84a13698bd03a810f8a682027a82e4a7e42" translate="yes" xml:space="preserve">
          <source>Tree-based models provide an alternative measure of &lt;a href=&quot;ensemble#random-forest-feature-importance&quot;&gt;feature importances based on the mean decrease in impurity&lt;/a&gt; (MDI). Impurity is quantified by the splitting criterion of the decision trees (Gini, Entropy or Mean Squared Error). However, this method can give high importance to features that may not be predictive on unseen data when the model is overfitting. Permutation-based feature importance, on the other hand, avoids this issue, since it can be computed on unseen data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="81d8ac0c0739336d0bbd6f8053b2fde8039cdb1c" translate="yes" xml:space="preserve">
          <source>Triangle Inequality: d(x, y) + d(y, z) &amp;gt;= d(x, z)</source>
          <target state="translated">Неравенство треугольника: d (x, y) + d (y, z)&amp;gt; = d (x, z)</target>
        </trans-unit>
        <trans-unit id="331d2c199452ae22aa8941c5bcbe6a7fe41c68b5" translate="yes" xml:space="preserve">
          <source>Tristan Fletcher: &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.651.8603&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Relevance Vector Machines explained&lt;/a&gt;</source>
          <target state="translated">Тристан Флетчер: &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.651.8603&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Объяснение машин вектора релевантности&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3b19d80cd81c13647ace615b9d73da08b4d8c61b" translate="yes" xml:space="preserve">
          <source>True : always precompute distances</source>
          <target state="translated">Правда:всегда предварительные расчеты расстояний</target>
        </trans-unit>
        <trans-unit id="27f22be4c5a651c1c27cbdc4b85cf77c839d3ddd" translate="yes" xml:space="preserve">
          <source>True : always precompute distances.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebac1d7d68472a848a069828ba36b6b2dd6227bb" translate="yes" xml:space="preserve">
          <source>True binary labels in binary indicator format.</source>
          <target state="translated">Истинные двоичные метки в двоичном формате индикатора.</target>
        </trans-unit>
        <trans-unit id="94ad072572f1b0d8a6896ff3fd5d5269c3006cce" translate="yes" xml:space="preserve">
          <source>True binary labels or binary label indicators.</source>
          <target state="translated">Истинные двоичные этикетки или двоичные индикаторы.</target>
        </trans-unit>
        <trans-unit id="173029937373f6d16ed7438491b1a8131b2bc4cb" translate="yes" xml:space="preserve">
          <source>True binary labels. If labels are not either {-1, 1} or {0, 1}, then pos_label should be explicitly given.</source>
          <target state="translated">Истинные двоичные этикетки.Если метки не являются {-1,1}или {0,1},то следует явно указать pos_label.</target>
        </trans-unit>
        <trans-unit id="394534b1dcaf25753dd90ddcd321d6ef1b441d87" translate="yes" xml:space="preserve">
          <source>True if a fixed vocabulary of term to indices mapping is provided by the user</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cba1cd7ae39f91f6d0e2908d3956200bdf94de07" translate="yes" xml:space="preserve">
          <source>True if estimator is a classifier and False otherwise.</source>
          <target state="translated">Верно,если оценщик является классификатором,и неверно.</target>
        </trans-unit>
        <trans-unit id="7e34070b9f977933411df9b814860396cade02bb" translate="yes" xml:space="preserve">
          <source>True if estimator is a regressor and False otherwise.</source>
          <target state="translated">Верно,если оценщик является регрессором,и неверно.</target>
        </trans-unit>
        <trans-unit id="d039a95b006860b5b92d23f84015c0458d6fdb1a" translate="yes" xml:space="preserve">
          <source>True if the array returned from predict is to be in sparse CSC format. Is automatically set to True if the input y is passed in sparse format.</source>
          <target state="translated">Правда,если массив,возвращаемый из предсказания,должен быть в разреженном формате CSC.Автоматически устанавливается значение True,если вход y передан в разреженном формате.</target>
        </trans-unit>
        <trans-unit id="018f28ffd2c7241c63be51b46bba3e8aa528d907" translate="yes" xml:space="preserve">
          <source>True if the input data to transform is given as a sparse matrix, False otherwise.</source>
          <target state="translated">Правда,если входные данные для преобразования даны в виде разреженной матрицы,Ложно иначе.</target>
        </trans-unit>
        <trans-unit id="06236e43536e8bd62b7d950e36ddd9dca022a999" translate="yes" xml:space="preserve">
          <source>True if the output at fit is 2d, else false.</source>
          <target state="translated">Верно,если выход при подгонке 2d,иначе ложь.</target>
        </trans-unit>
        <trans-unit id="abda54d00232aa3c71419926e38966e372a6e200" translate="yes" xml:space="preserve">
          <source>True if the returned array from transform is desired to be in sparse CSR format.</source>
          <target state="translated">Правда,если возвращаемый массив из преобразования должен быть в разреженном формате CSR.</target>
        </trans-unit>
        <trans-unit id="b3f5d1c4b9aeea8d97315ada02d3f0f3b6e0dbc5" translate="yes" xml:space="preserve">
          <source>True labels for X.</source>
          <target state="translated">Истинные ярлыки для Икс.</target>
        </trans-unit>
        <trans-unit id="d40646e12c6271d621333c3801ded96344098308" translate="yes" xml:space="preserve">
          <source>True labels or binary label indicators. The binary and multiclass cases expect labels with shape (n_samples,) while the multilabel case expects binary label indicators with shape (n_samples, n_classes).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24a7816a0ae25d0715f83e367246b56738200fc8" translate="yes" xml:space="preserve">
          <source>True mutual information can&amp;rsquo;t be negative. If its estimate turns out to be negative, it is replaced by zero.</source>
          <target state="translated">Истинная взаимная информация не может быть отрицательной. Если его оценка оказывается отрицательной, она заменяется нулем.</target>
        </trans-unit>
        <trans-unit id="1086f49a3e748a59792d8342e65dffdfa18d8ff5" translate="yes" xml:space="preserve">
          <source>True positive rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e857c90bead41164c28f265fe201e3c7a69f5d75" translate="yes" xml:space="preserve">
          <source>True target, consisting of integers of two values. The positive label must be greater than the negative label.</source>
          <target state="translated">Истинная цель,состоящая из целых чисел двух значений.Положительная метка должна быть больше отрицательной.</target>
        </trans-unit>
        <trans-unit id="5f6f5563a268706baa91536cfcd1565c453cd8e7" translate="yes" xml:space="preserve">
          <source>True targets of binary classification in range {-1, 1} or {0, 1}.</source>
          <target state="translated">Истинные мишени бинарной классификации в диапазоне {-1,1}или {0,1}.</target>
        </trans-unit>
        <trans-unit id="308caeb8e2723647ce2ad06a73f50c7b1bd2b781" translate="yes" xml:space="preserve">
          <source>True targets of multilabel classification, or true scores of entities to be ranked.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e2bbfc40bf0e63b31fb5b0351be961b49cc74be" translate="yes" xml:space="preserve">
          <source>True targets.</source>
          <target state="translated">Истинные цели.</target>
        </trans-unit>
        <trans-unit id="18dd5ee40d70767a2f6629e8ff8969a87290115e" translate="yes" xml:space="preserve">
          <source>True values for X</source>
          <target state="translated">Истинные значения для X</target>
        </trans-unit>
        <trans-unit id="81e3774c236b4c61a22388a1a822b3e69fb3e5a6" translate="yes" xml:space="preserve">
          <source>True values for X.</source>
          <target state="translated">Истинные значения для X.</target>
        </trans-unit>
        <trans-unit id="7e4dee4cabccdb0d80fb65794484e70b177b35d1" translate="yes" xml:space="preserve">
          <source>True values of target.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d7ce48badf2f0a91a36bec7511768633417749f" translate="yes" xml:space="preserve">
          <source>True when convergence was reached in fit(), False otherwise.</source>
          <target state="translated">Верно,когда конвергенция была достигнута в функции fit(),неверно,в противном случае.</target>
        </trans-unit>
        <trans-unit id="d333cd18e174fe06286d776d55b1b9eaf760ce1b" translate="yes" xml:space="preserve">
          <source>True: Force all values of X to be finite.</source>
          <target state="translated">Правда:Заставить все значения X быть конечными.</target>
        </trans-unit>
        <trans-unit id="42eef53fc6823568b56bf4bf254799ea2d7766d8" translate="yes" xml:space="preserve">
          <source>True: Force all values of array to be finite.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="260b9ffda14105c1fd2ffa31d36eae7c83268ddd" translate="yes" xml:space="preserve">
          <source>True: the results is casted to an unsigned int</source>
          <target state="translated">Правда:результат кастится на неподписанный int</target>
        </trans-unit>
        <trans-unit id="e67782a583f6700ced58a8f740875b4358d4fb58" translate="yes" xml:space="preserve">
          <source>Trustworthiness of the low-dimensional embedding.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00b6f6ebc7b7070cf35772b16b427811573346a1" translate="yes" xml:space="preserve">
          <source>Try classifying classes 1 and 2 from the iris dataset with SVMs, with the 2 first features. Leave out 10% of each class and test prediction performance on these observations.</source>
          <target state="translated">Попробуйте классифицировать классы 1 и 2 из набора данных по радужной оболочке глаза с помощью SVM,с двумя первыми функциями.Оставьте 10% от каждого класса и протестируйте производительность прогнозирования по этим наблюдениям.</target>
        </trans-unit>
        <trans-unit id="5449ae93c54cf3f8e79ab0ee95bb4ee118bd4f84" translate="yes" xml:space="preserve">
          <source>Try classifying the digits dataset with nearest neighbors and a linear model. Leave out the last 10% and test prediction performance on these observations.</source>
          <target state="translated">Попробуйте классифицировать набор цифр с ближайшими соседями и линейную модель.Оставьте последние 10% и проверьте эффективность прогнозирования по этим наблюдениям.</target>
        </trans-unit>
        <trans-unit id="7a783eca4388b1c7b8c830f476caa080328ba3c3" translate="yes" xml:space="preserve">
          <source>Try playing around with the &lt;code&gt;analyzer&lt;/code&gt; and &lt;code&gt;token normalisation&lt;/code&gt; under &lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Попробуйте поиграть с &lt;code&gt;analyzer&lt;/code&gt; и &lt;code&gt;token normalisation&lt;/code&gt; в &lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="b7e468fa3f6cfdfb33fa6bf28dcdf3165bf89507" translate="yes" xml:space="preserve">
          <source>Try to differentiate the two first classes of the iris data</source>
          <target state="translated">Попробуйте дифференцировать два первых класса данных по радужной оболочке глаза.</target>
        </trans-unit>
        <trans-unit id="1bc09af6523c25787ea3631aac8c3f52f8bc29dc" translate="yes" xml:space="preserve">
          <source>Try using &lt;a href=&quot;../../modules/decomposition#lsa&quot;&gt;Truncated SVD&lt;/a&gt; for &lt;a href=&quot;https://en.wikipedia.org/wiki/Latent_semantic_analysis&quot;&gt;latent semantic analysis&lt;/a&gt;.</source>
          <target state="translated">Попробуйте использовать &lt;a href=&quot;../../modules/decomposition#lsa&quot;&gt;Truncated SVD&lt;/a&gt; для &lt;a href=&quot;https://en.wikipedia.org/wiki/Latent_semantic_analysis&quot;&gt;скрытого семантического анализа&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="126c548fa4d4a4c65c7759b8f0eb82ce5677dab5" translate="yes" xml:space="preserve">
          <source>Tsoumakas, G., Katakis, I., &amp;amp; Vlahavas, I. (2010). Mining multi-label data. In Data mining and knowledge discovery handbook (pp. 667-685). Springer US.</source>
          <target state="translated">Цумакас, Г., Катакис, И., и Влахавас, И. (2010). Майнинг данных с несколькими метками. В справочнике по интеллектуальному анализу данных и открытию знаний (стр. 667-685). Springer США.</target>
        </trans-unit>
        <trans-unit id="0d016a3ee3141a6ebd01b9c31169fb6ec8d37fd6" translate="yes" xml:space="preserve">
          <source>Tuning the hyper-parameters of an estimator</source>
          <target state="translated">Настройка гиперпараметров оценщика</target>
        </trans-unit>
        <trans-unit id="2e926727653886b165b872a4b6b2a62bf90f0bd1" translate="yes" xml:space="preserve">
          <source>Tuple of row and column indicators for a set of biclusters.</source>
          <target state="translated">Кортеж индикаторов ряда и столбца для набора бикластеров.</target>
        </trans-unit>
        <trans-unit id="a813118f879d8793b6336ef94325f8c8d09426be" translate="yes" xml:space="preserve">
          <source>Tuples of the form (transformer, columns) specifying the transformer objects to be applied to subsets of the data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c054700312acf34cbacbc98d115120c76da3a6d5" translate="yes" xml:space="preserve">
          <source>Turn seed into a np.random.RandomState instance</source>
          <target state="translated">Превратите семя в np.random.RandomState экземпляр.</target>
        </trans-unit>
        <trans-unit id="4b18a115e0842d6d0ba3a4ec2ed7b07c665b5f56" translate="yes" xml:space="preserve">
          <source>Tutorial exercises</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="007a671747688cedb01751baca6545483f05de7a" translate="yes" xml:space="preserve">
          <source>Tutorial setup</source>
          <target state="translated">учебная установка</target>
        </trans-unit>
        <trans-unit id="025f75efad84ed2b985f2818a53e81aa77abca7c" translate="yes" xml:space="preserve">
          <source>Tutorial: A tutorial on statistical-learning for scientific data processing</source>
          <target state="translated">Учебное пособие:Учебное пособие по статистике для обработки научных данных.</target>
        </trans-unit>
        <trans-unit id="e7df3b5ebbaf2fd3b4b4579edbd7ce42f46db699" translate="yes" xml:space="preserve">
          <source>Tutorial: An introduction to machine learning with scikit-learn</source>
          <target state="translated">Учебное пособие:Введение в машинное обучение с помощью научно-обученного.</target>
        </trans-unit>
        <trans-unit id="8682fb6c27e32858369b74e47f829fad6c8d3a68" translate="yes" xml:space="preserve">
          <source>Tutorial: Choosing the right estimator</source>
          <target state="translated">Учебное пособие:Выбор правильного оценщика</target>
        </trans-unit>
        <trans-unit id="2865c0d93493065de0c34da92792e35a845226d3" translate="yes" xml:space="preserve">
          <source>Tutorial: Model selection</source>
          <target state="translated">Учебное пособие:Выбор модели</target>
        </trans-unit>
        <trans-unit id="b7709b919b68974b71489ceb95a00ef31c4eda72" translate="yes" xml:space="preserve">
          <source>Tutorial: Putting it all together</source>
          <target state="translated">Учебное пособие:Складывая все вместе</target>
        </trans-unit>
        <trans-unit id="b0b3bc4bbf4e62230750bf24baeb122d7a994298" translate="yes" xml:space="preserve">
          <source>Tutorial: Statistical learning</source>
          <target state="translated">Учебное пособие:статистическое обучение</target>
        </trans-unit>
        <trans-unit id="a149365421f01d98250256737c350c42a4cd4b82" translate="yes" xml:space="preserve">
          <source>Tutorial: Supervised learning</source>
          <target state="translated">Учебное пособие:контролируемое обучение</target>
        </trans-unit>
        <trans-unit id="4353f067a68843e09ae0691ab9f9c44ef2e6db23" translate="yes" xml:space="preserve">
          <source>Tutorial: Unsupervised learning</source>
          <target state="translated">Учебное пособие:Неконтролируемое обучение</target>
        </trans-unit>
        <trans-unit id="206fac7baeed5ee14f8990630b6607a7c33e8644" translate="yes" xml:space="preserve">
          <source>Tutorial: Working With Text Data</source>
          <target state="translated">Учебное пособие:Работа с текстовыми данными</target>
        </trans-unit>
        <trans-unit id="b919de3c63710fd07133db7062fb5a1fbffa0bfe" translate="yes" xml:space="preserve">
          <source>Tutorial: scikit-learn Tutorials</source>
          <target state="translated">Учебное пособие:Уроки фантастического обучения</target>
        </trans-unit>
        <trans-unit id="654171647baa6be8557a5d627cf35c7075ebb257" translate="yes" xml:space="preserve">
          <source>Tutorials</source>
          <target state="translated">Tutorials</target>
        </trans-unit>
        <trans-unit id="b9f0efb9bc5f86b33edfdb893732e46d86a776bd" translate="yes" xml:space="preserve">
          <source>Tweedie deviance is a homogeneous function of degree &lt;code&gt;2-power&lt;/code&gt;. Thus, Gamma distribution with &lt;code&gt;power=2&lt;/code&gt; means that simultaneously scaling &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; has no effect on the deviance. For Poisson distribution &lt;code&gt;power=1&lt;/code&gt; the deviance scales linearly, and for Normal distribution (&lt;code&gt;power=0&lt;/code&gt;), quadratically. In general, the higher &lt;code&gt;power&lt;/code&gt; the less weight is given to extreme deviations between true and predicted targets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b534d41a45e4c1bc7da48b9a62fdc9565da97cac" translate="yes" xml:space="preserve">
          <source>Tweedie power parameter. Either power &amp;lt;= 0 or power &amp;gt;= 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25d7747a25958e3f10fc9c93bbab44d13248adbd" translate="yes" xml:space="preserve">
          <source>Tweedie regression on insurance claims</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="995550b74403db560a3a2ea8d3906cd56b901336" translate="yes" xml:space="preserve">
          <source>Two algorithms are demoed: ordinary k-means and its more scalable cousin minibatch k-means.</source>
          <target state="translated">Демонстрируются два алгоритма:обычный к-средний и его более масштабируемый двоюродный мини-пакет к-средний.</target>
        </trans-unit>
        <trans-unit id="3b934d458351995534fed7d234de7b14c38f4cd4" translate="yes" xml:space="preserve">
          <source>Two approaches for performing calibration of probabilistic predictions are provided: a parametric approach based on Platt&amp;rsquo;s sigmoid model and a non-parametric approach based on isotonic regression (&lt;a href=&quot;classes#module-sklearn.isotonic&quot;&gt;&lt;code&gt;sklearn.isotonic&lt;/code&gt;&lt;/a&gt;). Probability calibration should be done on new data not used for model fitting. The class &lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt;&lt;code&gt;CalibratedClassifierCV&lt;/code&gt;&lt;/a&gt; uses a cross-validation generator and estimates for each split the model parameter on the train samples and the calibration of the test samples. The probabilities predicted for the folds are then averaged. Already fitted classifiers can be calibrated by &lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt;&lt;code&gt;CalibratedClassifierCV&lt;/code&gt;&lt;/a&gt; via the parameter cv=&amp;rdquo;prefit&amp;rdquo;. In this case, the user has to take care manually that data for model fitting and calibration are disjoint.</source>
          <target state="translated">Предлагаются два подхода к выполнению калибровки вероятностных прогнозов: параметрический подход, основанный на сигмовидной модели Платта, и непараметрический подход, основанный на изотонической регрессии ( &lt;a href=&quot;classes#module-sklearn.isotonic&quot;&gt; &lt;code&gt;sklearn.isotonic&lt;/code&gt; &lt;/a&gt; ). Калибровку вероятности следует проводить на новых данных, не используемых для подгонки модели. Класс &lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt; &lt;code&gt;CalibratedClassifierCV&lt;/code&gt; &lt;/a&gt; использует генератор перекрестной проверки и оценки для каждого разделения параметра модели на образцах поездов и калибровки тестовых образцов. Вероятности, предсказанные для складок, затем усредняются. Уже установленные классификаторы могут быть откалиброваны с помощью &lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt; &lt;code&gt;CalibratedClassifierCV&lt;/code&gt; &lt;/a&gt; через параметр cv = &quot;prefit&quot;. В этом случае пользователь должен вручную следить за тем, чтобы данные для подгонки модели и калибровки не пересекались.</target>
        </trans-unit>
        <trans-unit id="de7e8d6ad699213a292d0c528c5ddad33bca14ae" translate="yes" xml:space="preserve">
          <source>Two consequences of imposing a connectivity can be seen. First clustering with a connectivity matrix is much faster.</source>
          <target state="translated">Можно заметить два последствия навязывания связи.Первая кластеризация с матрицей соединений происходит гораздо быстрее.</target>
        </trans-unit>
        <trans-unit id="73ece4ca1e1779fbf5110031e848f2313deac958" translate="yes" xml:space="preserve">
          <source>Two cross-validation loops are performed in parallel: one by the &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; estimator to set &lt;code&gt;gamma&lt;/code&gt; and the other one by &lt;code&gt;cross_val_score&lt;/code&gt; to measure the prediction performance of the estimator. The resulting scores are unbiased estimates of the prediction score on new data.</source>
          <target state="translated">Два &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt; перекрестной проверки выполняются параллельно: один оценщиком GridSearchCV для установки &lt;code&gt;gamma&lt;/code&gt; а другой с помощью &lt;code&gt;cross_val_score&lt;/code&gt; для измерения производительности прогнозирования оценщика. Результирующие оценки представляют собой объективные оценки оценки прогноза на основе новых данных.</target>
        </trans-unit>
        <trans-unit id="d467efdd44bf60415fc895b8589d9d81d46d02ec" translate="yes" xml:space="preserve">
          <source>Two families of ensemble methods are usually distinguished:</source>
          <target state="translated">Обычно различают два семейства ансамблевых методов:</target>
        </trans-unit>
        <trans-unit id="e8ac95de27d48015555c5b981483208d51b8f268" translate="yes" xml:space="preserve">
          <source>Two feature extraction methods can be used in this example:</source>
          <target state="translated">В этом примере можно использовать два метода извлечения признаков:</target>
        </trans-unit>
        <trans-unit id="ebb2ce8305b879c94bfe5ff4f307e7a35d679e99" translate="yes" xml:space="preserve">
          <source>Two plots will be shown for each scaler/normalizer/transformer. The left figure will show a scatter plot of the full data set while the right figure will exclude the extreme values considering only 99 % of the data set, excluding marginal outliers. In addition, the marginal distributions for each feature will be shown on the side of the scatter plot.</source>
          <target state="translated">Для каждого скалера/нормализатора/трансформатора будут показаны два графика.На левом рисунке будет показан график рассеяния полного набора данных,в то время как на правом рисунке будут исключены экстремальные значения,учитывающие только 99% набора данных,исключая предельные отклонения.Кроме того,предельные распределения для каждой характеристики будут показаны на боковой стороне диаграммы рассеяния.</target>
        </trans-unit>
        <trans-unit id="d08300d20f1b41587441de06b29a0ea2e0345c8c" translate="yes" xml:space="preserve">
          <source>Two regions are populated: when the EXPERIENCE coefficient is positive the AGE one is negative and viceversa.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="348f286c4d7d6b276984cd38d102dc527023a237" translate="yes" xml:space="preserve">
          <source>Two separate datasets are used for the two different plots. The reason behind this is the &lt;code&gt;l1&lt;/code&gt; case works better on sparse data, while &lt;code&gt;l2&lt;/code&gt; is better suited to the non-sparse case.</source>
          <target state="translated">Для двух разных графиков используются два отдельных набора данных. Причина этого в том, что случай &lt;code&gt;l1&lt;/code&gt; лучше работает с разреженными данными, тогда как &lt;code&gt;l2&lt;/code&gt; лучше подходит для не разреженного случая.</target>
        </trans-unit>
        <trans-unit id="77c4595f573f3df24ff0cb3827f75f6aed496412" translate="yes" xml:space="preserve">
          <source>Two types of transformations are available: quantile transforms and power transforms. Both quantile and power transforms are based on monotonic transformations of the features and thus preserve the rank of the values along each feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32895c2e5eacd1283051e2d5a4f1fd3f826fb6ed" translate="yes" xml:space="preserve">
          <source>Two-class AdaBoost</source>
          <target state="translated">Двухклассный АдаБост</target>
        </trans-unit>
        <trans-unit id="b8fde32df7d701e50fc79883cdf21005c9469e51" translate="yes" xml:space="preserve">
          <source>Type casting</source>
          <target state="translated">Типовое литьё</target>
        </trans-unit>
        <trans-unit id="7b90464c9a3a0593a486a1facdfd06e25cac2162" translate="yes" xml:space="preserve">
          <source>Type of SVM: C SVC, nu SVC, one class, epsilon SVR, nu SVR</source>
          <target state="translated">Тип SVM:C SVC,ню SVC,один класс,эпсилон SVR,ню SVR</target>
        </trans-unit>
        <trans-unit id="fb24034e0a15fdb11753c4c561fec377a847eca1" translate="yes" xml:space="preserve">
          <source>Type of SVM: C_SVC, NuSVC, OneClassSVM, EpsilonSVR or NuSVR respectively. 0 by default.</source>
          <target state="translated">Тип SVM:C_SVC,NuSVC,OneClassSVM,EpsilonSVR или NuSVR соответственно.0 по умолчанию.</target>
        </trans-unit>
        <trans-unit id="05734831eef4f60aabd73eed1535149e1780b49e" translate="yes" xml:space="preserve">
          <source>Type of kernel.</source>
          <target state="translated">Тип ядра.</target>
        </trans-unit>
        <trans-unit id="7784bde958a1d323776ea14d0478698cc397c040" translate="yes" xml:space="preserve">
          <source>Type of returned matrix: &amp;lsquo;connectivity&amp;rsquo; will return the connectivity matrix with ones and zeros, and &amp;lsquo;distance&amp;rsquo; will return the distances between neighbors according to the given metric.</source>
          <target state="translated">Тип возвращаемой матрицы: &amp;laquo;связность&amp;raquo; вернет матрицу связности с единицами и нулями, а &amp;laquo;расстояние&amp;raquo; вернет расстояния между соседями в соответствии с заданной метрикой.</target>
        </trans-unit>
        <trans-unit id="029a83801426f186d4049ef92d5f3d3590b1d125" translate="yes" xml:space="preserve">
          <source>Type of returned matrix: &amp;lsquo;connectivity&amp;rsquo; will return the connectivity matrix with ones and zeros, in &amp;lsquo;distance&amp;rsquo; the edges are Euclidean distance between points.</source>
          <target state="translated">Тип возвращаемой матрицы: &amp;laquo;связность&amp;raquo; вернет матрицу связности с единицами и нулями, в &amp;laquo;расстоянии&amp;raquo; края - это евклидово расстояние между точками.</target>
        </trans-unit>
        <trans-unit id="e2af4c36790c9137ba49cdb815accc60f6f75311" translate="yes" xml:space="preserve">
          <source>Type of store backend for reading/writing cache files. Default: &amp;lsquo;local&amp;rsquo;. The &amp;lsquo;local&amp;rsquo; backend is using regular filesystem operations to manipulate data (open, mv, etc) in the backend.</source>
          <target state="translated">Тип хранилища для чтения / записи файлов кеша. По умолчанию: &amp;laquo;местный&amp;raquo;. &amp;laquo;Локальный&amp;raquo; бэкэнд использует обычные операции файловой системы для управления данными (open, mv и т. Д.) В бэкэнде.</target>
        </trans-unit>
        <trans-unit id="858cba7a97e85950fd69a9661ce88f3dff1bf729" translate="yes" xml:space="preserve">
          <source>Type of the matrix returned by fit_transform() or transform().</source>
          <target state="translated">Тип матрицы,возвращаемой функциями fit_transform()или transform().</target>
        </trans-unit>
        <trans-unit id="b6e792a3d08a7bd144dac10e42edb461fd3dd2e3" translate="yes" xml:space="preserve">
          <source>Type to use in computing the mean. For integer inputs, the default is &lt;code&gt;float64&lt;/code&gt;; for floating point inputs, it is the same as the input dtype.</source>
          <target state="translated">Тип для использования при вычислении среднего. Для целочисленных входов значение по умолчанию - &lt;code&gt;float64&lt;/code&gt; ; для входных данных с плавающей запятой это то же самое, что и входной dtype.</target>
        </trans-unit>
        <trans-unit id="9af8f14bd15271db0f113f7c146e7fa9294b1caa" translate="yes" xml:space="preserve">
          <source>TypeError</source>
          <target state="translated">TypeError</target>
        </trans-unit>
        <trans-unit id="363cb5cb9b015bf8fe75ee8f6f3ad675ca5618cc" translate="yes" xml:space="preserve">
          <source>UNION</source>
          <target state="translated">UNION</target>
        </trans-unit>
        <trans-unit id="d609f86a64dc993cf97b5c1696e70d121d69089c" translate="yes" xml:space="preserve">
          <source>UNION_not_member</source>
          <target state="translated">UNION_not_member</target>
        </trans-unit>
        <trans-unit id="5c8cdf8bfe08e7fa632507cd27d7c4593fc32d5d" translate="yes" xml:space="preserve">
          <source>Under the assumption that the data are Gaussian distributed, Chen et al. &lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;2&lt;/a&gt; derived a formula aimed at choosing a shrinkage coefficient that yields a smaller Mean Squared Error than the one given by Ledoit and Wolf&amp;rsquo;s formula. The resulting estimator is known as the Oracle Shrinkage Approximating estimator of the covariance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f77afa338a167babd59a76b7f498d6550ba586ff" translate="yes" xml:space="preserve">
          <source>Under the assumption that the data are Gaussian distributed, Chen et al. &lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; derived a formula aimed at choosing a shrinkage coefficient that yields a smaller Mean Squared Error than the one given by Ledoit and Wolf&amp;rsquo;s formula. The resulting estimator is known as the Oracle Shrinkage Approximating estimator of the covariance.</source>
          <target state="translated">Предполагая, что данные распределены по Гауссу, Chen et al. &lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; вывели формулу, направленную на выбор коэффициента усадки, который дает меньшую среднеквадратичную ошибку, чем та, которая дается формулой Ледуа и Вольфа. Результирующая оценка известна как оценка ковариации Oracle Shrinkage Approximating.</target>
        </trans-unit>
        <trans-unit id="b57ce0246b95ca0ff3d95c499722ea513c24180d" translate="yes" xml:space="preserve">
          <source>Underfitting vs. Overfitting</source>
          <target state="translated">Переоснащение против переоснащения</target>
        </trans-unit>
        <trans-unit id="10dab5fb240281c20bb10ad043cbba82ec3b0bd6" translate="yes" xml:space="preserve">
          <source>Understanding the decision tree structure</source>
          <target state="translated">Понимание структуры дерева решений</target>
        </trans-unit>
        <trans-unit id="a381b476a1bdd0042346ffd8d02655a7131aa344" translate="yes" xml:space="preserve">
          <source>Undo the scaling of X according to feature_range.</source>
          <target state="translated">Отменить масштабирование X в соответствии с диапазоном feature_range.</target>
        </trans-unit>
        <trans-unit id="11b4a2e4a2b6531b9e75ad23f03f25fd4f8ecde0" translate="yes" xml:space="preserve">
          <source>Uniform weights are used by default.</source>
          <target state="translated">По умолчанию используются унифицированные веса.</target>
        </trans-unit>
        <trans-unit id="9421754583ed6d327fe582bef2d0e2d0f17ba0c4" translate="yes" xml:space="preserve">
          <source>Unique class labels.</source>
          <target state="translated">Уникальные этикетки класса.</target>
        </trans-unit>
        <trans-unit id="6efd4cf40567c19c24a13e3421a6d1109a47da44" translate="yes" xml:space="preserve">
          <source>Uniquely holds the label for each class.</source>
          <target state="translated">Уникально держит этикетку для каждого класса.</target>
        </trans-unit>
        <trans-unit id="78bd370935302db3cfb593c9af76aeb130eb71c4" translate="yes" xml:space="preserve">
          <source>Unit Deviance \(d(y, \hat{y})\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15f758514c6db2ef9033ee5636e4d09d40ce9747" translate="yes" xml:space="preserve">
          <source>Univariate Feature Selection</source>
          <target state="translated">Выбор одномерной характеристики</target>
        </trans-unit>
        <trans-unit id="820dda4dd874419c514343cc2737763cc18b33d1" translate="yes" xml:space="preserve">
          <source>Univariate feature selection works by selecting the best features based on univariate statistical tests. It can be seen as a preprocessing step to an estimator. Scikit-learn exposes feature selection routines as objects that implement the &lt;code&gt;transform&lt;/code&gt; method:</source>
          <target state="translated">Одномерный выбор функций работает путем выбора лучших функций на основе одномерных статистических тестов. Это можно рассматривать как этап предварительной обработки оценщика. Scikit-learn предоставляет процедуры выбора функций как объекты, реализующие метод &lt;code&gt;transform&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="b943e7c2ae0f248f889b02c7d797d243c0d56e6a" translate="yes" xml:space="preserve">
          <source>Univariate feature selector with configurable mode.</source>
          <target state="translated">Селектор однопараметрических функций с настраиваемым режимом.</target>
        </trans-unit>
        <trans-unit id="05b44ce5dcc153b8702db1e0eab0c9af1fb62f9c" translate="yes" xml:space="preserve">
          <source>Univariate feature selector with configurable strategy.</source>
          <target state="translated">Одномерный селектор функций с настраиваемой стратегией.</target>
        </trans-unit>
        <trans-unit id="049ea86cb7534beee7ca7abb3073edcde3e3d399" translate="yes" xml:space="preserve">
          <source>Univariate imputation of missing values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9b7ebeeb7d99a7c69a9087085473be1721215ee" translate="yes" xml:space="preserve">
          <source>Univariate linear regression tests.</source>
          <target state="translated">Одномерные тесты линейной регрессии.</target>
        </trans-unit>
        <trans-unit id="833fdc74927caa030c0f5f51bade98d55541b93d" translate="yes" xml:space="preserve">
          <source>Unlabeled entries in &lt;code&gt;y&lt;/code&gt;</source>
          <target state="translated">Записи без метки в &lt;code&gt;y&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="d5f2b47c1710490958929f8f01f5858025c133e1" translate="yes" xml:space="preserve">
          <source>Unless otherwise specified, input will be cast to &lt;code&gt;float64&lt;/code&gt;:</source>
          <target state="translated">Если не указано иное, ввод будет &lt;code&gt;float64&lt;/code&gt; в float64 :</target>
        </trans-unit>
        <trans-unit id="6027b38892a9b0df12f36988c98a41a4655ff464" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt;, the representation of a vector is obtained in an additive fashion, by superimposing the components, without subtracting. Such additive models are efficient for representing images and text.</source>
          <target state="translated">В отличие от &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; , представление вектора получается аддитивным способом, путем наложения компонентов без вычитания. Такие аддитивные модели эффективны для представления изображений и текста.</target>
        </trans-unit>
        <trans-unit id="5817d589292c98298ab95a877d7595e724495088" translate="yes" xml:space="preserve">
          <source>Unlike SVC (based on LIBSVM), LinearSVC (based on LIBLINEAR) does not provide the support vectors. This example demonstrates how to obtain the support vectors in LinearSVC.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f73d55c7488edaa74f7dc85966062a8a5be2b94b" translate="yes" xml:space="preserve">
          <source>Unlike most other scores, R^2 score may be negative (it need not actually be the square of a quantity R).</source>
          <target state="translated">В отличие от большинства других оценок,оценка R^2 может быть отрицательной (на самом деле она не обязательно должна быть квадратом количества R).</target>
        </trans-unit>
        <trans-unit id="fb0dd07f15380472f302743b85f6d7c3f60efb9d" translate="yes" xml:space="preserve">
          <source>Unlike the previous scalers, the centering and scaling statistics of this scaler are based on percentiles and are therefore not influenced by a few number of very large marginal outliers. Consequently, the resulting range of the transformed feature values is larger than for the previous scalers and, more importantly, are approximately similar: for both features most of the transformed values lie in a [-2, 3] range as seen in the zoomed-in figure. Note that the outliers themselves are still present in the transformed data. If a separate outlier clipping is desirable, a non-linear transformation is required (see below).</source>
          <target state="translated">В отличие от предыдущих сканеров,статистика центрирования и масштабирования этого скалера основана на процентилях и поэтому не подвержена влиянию нескольких очень больших маргинальных отклонений.Следовательно,результирующий диапазон преобразованных значений признаков больше,чем у предыдущих шкалеров,и,что более важно,примерно одинаков:для обоих признаков большая часть преобразованных значений лежит в диапазоне [-2,3],как видно из приближенного к масштабу рисунка.Обратите внимание,что сами отклонения все еще присутствуют в преобразованных данных.Если желателен отдельный обрезок выбросов,то требуется нелинейное преобразование (см.ниже).</target>
        </trans-unit>
        <trans-unit id="be4091e1f0941887f57bdebf1b1a9b607356f1f1" translate="yes" xml:space="preserve">
          <source>Unlike the previous transformations, normalization refers to a per sample transformation instead of a per feature transformation.</source>
          <target state="translated">В отличие от предыдущих преобразований,нормализация относится к преобразованию на выборку,а не к преобразованию на объект.</target>
        </trans-unit>
        <trans-unit id="1e78af54fb2d86af104fdf7cb3b33ae0e42d69f8" translate="yes" xml:space="preserve">
          <source>Unmarried</source>
          <target state="translated">Unmarried</target>
        </trans-unit>
        <trans-unit id="d6efdeaf0fd8663d7b74628a841a2a21988919e0" translate="yes" xml:space="preserve">
          <source>Unregularized graph based semi-supervised learning</source>
          <target state="translated">Нерегулируемое обучение на основе полууправляемых графиков</target>
        </trans-unit>
        <trans-unit id="27bee227769f6c4dd6bbb550e3dab104adba94bb" translate="yes" xml:space="preserve">
          <source>Unsupervised Outlier Detection using Local Outlier Factor (LOF)</source>
          <target state="translated">Обнаружение неконтролируемых выбросов с помощью локального коэффициента выброса (LOF).</target>
        </trans-unit>
        <trans-unit id="3cf71ccf2a88f28c3a0cfcb75adfc8979981d7f4" translate="yes" xml:space="preserve">
          <source>Unsupervised Outlier Detection using Local Outlier Factor (LOF).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b5353048e77b9864be0e146d8fe78c3034a09d3" translate="yes" xml:space="preserve">
          <source>Unsupervised Outlier Detection.</source>
          <target state="translated">Неконтролируемое обнаружение внешних воздействий.</target>
        </trans-unit>
        <trans-unit id="a2eb50b9e0078078696dd41ce50d788a5cac282f" translate="yes" xml:space="preserve">
          <source>Unsupervised Outlier Detection. Estimate the support of a high-dimensional distribution. The implementation is based on libsvm.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="091dbb252c60dafbec16ee540eb9588c7d736a5b" translate="yes" xml:space="preserve">
          <source>Unsupervised learner for implementing neighbor searches.</source>
          <target state="translated">Неконтролируемый ученик для осуществления поиска соседей.</target>
        </trans-unit>
        <trans-unit id="336bcbb510eed89e13ba021c352635cdc0677016" translate="yes" xml:space="preserve">
          <source>Unsupervised learning: seeking representations of the data</source>
          <target state="translated">Неконтролируемое обучение:поиск представлений данных</target>
        </trans-unit>
        <trans-unit id="568c5820f9e5362ca266c9125e695403019435a8" translate="yes" xml:space="preserve">
          <source>Unused parameter.</source>
          <target state="translated">Неиспользуемый параметр.</target>
        </trans-unit>
        <trans-unit id="207a5be036cc811b3313bce86d86c7d5b4302176" translate="yes" xml:space="preserve">
          <source>Update k means estimate on a single mini-batch X.</source>
          <target state="translated">Обновление k означает оценку на одну мини-группу X.</target>
        </trans-unit>
        <trans-unit id="08230ffcab1953eb1050f05815a03e0d48694ae9" translate="yes" xml:space="preserve">
          <source>Update the model with a single iteration over the given data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="718430f889e80a3494a47ee7bec5ca3329673e5e" translate="yes" xml:space="preserve">
          <source>Updated feature-wise means.</source>
          <target state="translated">Обновленные функциональные средства.</target>
        </trans-unit>
        <trans-unit id="4f10d24907ba29eca99bd941c7ead98539a4f5b4" translate="yes" xml:space="preserve">
          <source>Updated feature-wise variances.</source>
          <target state="translated">Обновленные функциональные изменения.</target>
        </trans-unit>
        <trans-unit id="693a7de21c7466734e7ffa03c5ae997209e7997d" translate="yes" xml:space="preserve">
          <source>Updated number of seen samples.</source>
          <target state="translated">Обновленное количество просмотренных образцов.</target>
        </trans-unit>
        <trans-unit id="410e0e09369f3d862bca36022b47e478be0933f7" translate="yes" xml:space="preserve">
          <source>Updates the model using the data in X as a mini-batch.</source>
          <target state="translated">Обновление модели с использованием данных в X в виде мини-партии.</target>
        </trans-unit>
        <trans-unit id="93ec1aa11f1be18275b029134004fd1ab02c997f" translate="yes" xml:space="preserve">
          <source>Upper bound on a uniform noise parameter to be added to the &lt;code&gt;y&lt;/code&gt; values, to satisfy the model&amp;rsquo;s assumption of one-at-a-time computations. Might help with stability.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07333ba49211f5c72e60dfd1b7f4f04d69ceed93" translate="yes" xml:space="preserve">
          <source>Upper bound on the highest predicted value (the maximum may still be lower). If not set, defaults to +inf.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48b5dd5eaa54e931a34dd1d6396ec1c9d66da80b" translate="yes" xml:space="preserve">
          <source>Urbanowicz R.J., Moore, J.H. &lt;a href=&quot;https://doi.org/10.1007/s12065-015-0128-8&quot;&gt;ExSTraCS 2.0: description and evaluation of a scalable learning classifier system&lt;/a&gt;, Evol. Intel. (2015) 8: 89.</source>
          <target state="translated">Urbanowicz RJ, Moore, JH &lt;a href=&quot;https://doi.org/10.1007/s12065-015-0128-8&quot;&gt;ExSTraCS 2.0: описание и оценка масштабируемой системы классификаторов обучения&lt;/a&gt; , Evol. Intel. (2015) 8:89.</target>
        </trans-unit>
        <trans-unit id="fec43ce445f974147bd0eb223a50147e7fb7202d" translate="yes" xml:space="preserve">
          <source>Usage example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="173610cb31251b28e80fadc258036215d99d7128" translate="yes" xml:space="preserve">
          <source>Usage examples:</source>
          <target state="translated">Примеры использования:</target>
        </trans-unit>
        <trans-unit id="272998fc40498f57127bf4e7cf71805cd53c9500" translate="yes" xml:space="preserve">
          <source>Use 0 when &lt;code&gt;Y&lt;/code&gt; contains the output of decision_function (classifier). Use 0.5 when &lt;code&gt;Y&lt;/code&gt; contains the output of predict_proba.</source>
          <target state="translated">Используйте 0, когда &lt;code&gt;Y&lt;/code&gt; содержит вывод функции решения (классификатора). Используйте 0.5, если &lt;code&gt;Y&lt;/code&gt; содержит вывод pred_proba.</target>
        </trans-unit>
        <trans-unit id="cf1718d68df5d7e88cb5c515bd9f0d9c1cb19546" translate="yes" xml:space="preserve">
          <source>Use &lt;a href=&quot;#optics&quot;&gt;OPTICS&lt;/a&gt; clustering in conjunction with the &lt;code&gt;extract_dbscan&lt;/code&gt; method. OPTICS clustering also calculates the full pairwise matrix, but only keeps one row in memory at a time (memory complexity n).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7e4377e83d25be8830adecce4de8c2384ca00b7" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;ColumnTransformer&lt;/code&gt; by selecting column by data types</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e21d1ee32a85ffa963b44a044a8fb65d4d276f52" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;ColumnTransformer&lt;/code&gt; by selecting column by names</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e620712d1a8872ff21d8a3d8ca61cf7867c4f8c8" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;min_samples_split&lt;/code&gt; or &lt;code&gt;min_samples_leaf&lt;/code&gt; to ensure that multiple samples inform every decision in the tree, by controlling which splits will be considered. A very small number will usually mean the tree will overfit, whereas a large number will prevent the tree from learning the data. Try &lt;code&gt;min_samples_leaf=5&lt;/code&gt; as an initial value. If the sample size varies greatly, a float number can be used as percentage in these two parameters. While &lt;code&gt;min_samples_split&lt;/code&gt; can create arbitrarily small leaves, &lt;code&gt;min_samples_leaf&lt;/code&gt; guarantees that each leaf has a minimum size, avoiding low-variance, over-fit leaf nodes in regression problems. For classification with few classes, &lt;code&gt;min_samples_leaf=1&lt;/code&gt; is often the best choice.</source>
          <target state="translated">Используйте &lt;code&gt;min_samples_split&lt;/code&gt; или &lt;code&gt;min_samples_leaf&lt;/code&gt; , чтобы гарантировать, что несколько выборок сообщают каждому решению в дереве, контролируя, какие разделения будут учитываться. Очень маленькое число обычно означает, что дерево будет переоснащаться, тогда как большое число не позволит дереву изучить данные. Попробуйте &lt;code&gt;min_samples_leaf=5&lt;/code&gt; в качестве начального значения. Если размер выборки сильно различается, в этих двух параметрах можно использовать число с плавающей запятой в процентах. В то время как &lt;code&gt;min_samples_split&lt;/code&gt; может создавать произвольно маленькие листья, &lt;code&gt;min_samples_leaf&lt;/code&gt; гарантирует, что каждый лист имеет минимальный размер, избегая низкоразмерных, чрезмерно подходящих конечных узлов в задачах регрессии. Для классификации с несколькими классами &lt;code&gt;min_samples_leaf=1&lt;/code&gt; часто лучший выбор.</target>
        </trans-unit>
        <trans-unit id="3429b333ce93c8bae91a85fe794f080132090825" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;negative_outlier_factor_&lt;/code&gt;</source>
          <target state="translated">Используйте &lt;code&gt;negative_outlier_factor_&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7760fd58346bed0a2b559e055012bd8a21868552" translate="yes" xml:space="preserve">
          <source>Use SelectFromModel meta-transformer along with Lasso to select the best couple of features from the Boston dataset.</source>
          <target state="translated">Используйте SelectFromModel мета-трансформатор вместе с Lasso,чтобы выбрать лучшую пару функций из Бостонского набора данных.</target>
        </trans-unit>
        <trans-unit id="054f12ffb2d5e13349a9508049b7a257d7468dbe" translate="yes" xml:space="preserve">
          <source>Use SelectFromModel meta-transformer along with Lasso to select the best couple of features from the diabetes dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71685d673fcc400f8aa4ec7ef3e4a61bf3bbf5f7" translate="yes" xml:space="preserve">
          <source>Use approximate bound as score.</source>
          <target state="translated">Используйте в качестве балла приблизительный результат.</target>
        </trans-unit>
        <trans-unit id="400d526bc775314ded26ebb1519045ccc0979588" translate="yes" xml:space="preserve">
          <source>Use density = 1 / 3.0 if you want to reproduce the results from Achlioptas, 2001.</source>
          <target state="translated">Используйте плотность=1/3,0,если вы хотите воспроизвести результаты Achlioptas,2001.</target>
        </trans-unit>
        <trans-unit id="38fb3c866f165060e0d95ec1a873c702ff2c91dc" translate="yes" xml:space="preserve">
          <source>Use only on new data</source>
          <target state="translated">Использовать только для новых данных</target>
        </trans-unit>
        <trans-unit id="0eb6d7f6360fc3b257840e6d0ece909142d961e3" translate="yes" xml:space="preserve">
          <source>Use splitting criteria that compute the average reduction across all n outputs.</source>
          <target state="translated">Используйте критерии разделения,которые вычисляют среднее снижение по всем n выводам.</target>
        </trans-unit>
        <trans-unit id="d4a5711bd46bd2a4542a66497bb7f3342ea23a7f" translate="yes" xml:space="preserve">
          <source>Use the Akaike information criterion (AIC), the Bayes Information criterion (BIC) and cross-validation to select an optimal value of the regularization parameter alpha of the &lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;Lasso&lt;/a&gt; estimator.</source>
          <target state="translated">Используйте информационный критерий Акаике (AIC), информационный критерий Байеса (BIC) и перекрестную проверку, чтобы выбрать оптимальное значение параметра регуляризации альфа для оценки &lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;Лассо&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="35f6c244b8fd2da4794beb17214246bc1c30610f" translate="yes" xml:space="preserve">
          <source>Usecase</source>
          <target state="translated">Usecase</target>
        </trans-unit>
        <trans-unit id="4ea5661d3bd8912bbf2723a42ab4c0cf1ece7994" translate="yes" xml:space="preserve">
          <source>Used during dictionary learning. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1bc010bd367bf6cb9590a9c8e8bd3ff37b7e270c" translate="yes" xml:space="preserve">
          <source>Used during randomized svd. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85ae15952ef1b8cedfa1ed0f0a5091e5742f9b4a" translate="yes" xml:space="preserve">
          <source>Used for NMF initialisation (when &lt;code&gt;init&lt;/code&gt; == &amp;lsquo;nndsvdar&amp;rsquo; or &amp;lsquo;random&amp;rsquo;), and in Coordinate Descent. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15383d0945f438ddc1d77fc1ae0921de1e717777" translate="yes" xml:space="preserve">
          <source>Used for VotingClassifier</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06c1133b6cf5dee9bc1f27b86d9cca1c046fd5c1" translate="yes" xml:space="preserve">
          <source>Used for initialisation (when &lt;code&gt;init&lt;/code&gt; == &amp;lsquo;nndsvdar&amp;rsquo; or &amp;lsquo;random&amp;rsquo;), and in Coordinate Descent. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4845a789add1f32681ae6a68b7dba0e6bdbe2af" translate="yes" xml:space="preserve">
          <source>Used for initializing the dictionary when &lt;code&gt;dict_init&lt;/code&gt; is not specified, randomly shuffling the data when &lt;code&gt;shuffle&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, and updating the dictionary. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d6d1bb4bf090f9031a078f80f81b5cfa346c5fb" translate="yes" xml:space="preserve">
          <source>Used for internal caching. By default, no caching is done. If a string is given, it is the path to the caching directory.</source>
          <target state="translated">Используется для внутреннего кэширования.По умолчанию кэширование не выполняется.Если задана строка,то это путь к каталогу кэширования.</target>
        </trans-unit>
        <trans-unit id="78a755bf17a9d084d2f5bc3468af8892921b3298" translate="yes" xml:space="preserve">
          <source>Used for random shuffling when &lt;code&gt;shuffle&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, during online dictionary learning. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a659f5ae4cfedf0686976ca2f311fa3c53dbc2ce" translate="yes" xml:space="preserve">
          <source>Used for randomizing the singular value decomposition and the k-means initialization. Use an int to make the randomness deterministic. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">Используется для рандомизации разложения по сингулярным числам и инициализации k-средних. Используйте int, чтобы сделать случайность детерминированной. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-random-state&quot;&gt;Глоссарий&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="b3bb1fd38ab7b6b511c90e9e3f961817f7b29fe6" translate="yes" xml:space="preserve">
          <source>Used for randomizing the singular value decomposition and the k-means initialization. Use an int to make the randomness deterministic. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad6bfb2aef10b93bd4ad8fd792d19a69ba0f50a9" translate="yes" xml:space="preserve">
          <source>Used for randomly initializing the dictionary. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0ee2dc12a427741bfbfa29dc3b32d1b1d854da3" translate="yes" xml:space="preserve">
          <source>Used for shuffling the data, when &lt;code&gt;shuffle&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04206996c9eca941c8da97d474cf5a147f4b8713" translate="yes" xml:space="preserve">
          <source>Used to cache the fitted transformers of the pipeline. By default, no caching is performed. If a string is given, it is the path to the caching directory. Enabling caching triggers a clone of the transformers before fitting. Therefore, the transformer instance given to the pipeline cannot be inspected directly. Use the attribute &lt;code&gt;named_steps&lt;/code&gt; or &lt;code&gt;steps&lt;/code&gt; to inspect estimators within the pipeline. Caching the transformers is advantageous when fitting is time consuming.</source>
          <target state="translated">Используется для кэширования установленных трансформаторов трубопровода. По умолчанию кэширование не выполняется. Если дана строка, это путь к каталогу кеширования. Включение кэширования запускает клонирование трансформаторов перед установкой. Следовательно, экземпляр трансформатора, переданный в трубопровод, нельзя проверить напрямую. Используйте атрибут &lt;code&gt;named_steps&lt;/code&gt; или &lt;code&gt;steps&lt;/code&gt; для проверки оценщиков в конвейере. Кэширование трансформаторов выгодно, если установка требует много времени.</target>
        </trans-unit>
        <trans-unit id="b831b0ccc618367ad6990c063d4f6b68c21b54a0" translate="yes" xml:space="preserve">
          <source>Used to cache the output of the computation of the tree. By default, no caching is done. If a string is given, it is the path to the caching directory.</source>
          <target state="translated">Используется для кэширования результатов вычисления дерева.По умолчанию кэширование не производится.Если задана строка,то это путь к каталогу кэширования.</target>
        </trans-unit>
        <trans-unit id="5b58434a86ea5888954537c341361956c0e8c395" translate="yes" xml:space="preserve">
          <source>Used to determine when to &amp;ldquo;early stop&amp;rdquo;. The fitting process is stopped when none of the last &lt;code&gt;n_iter_no_change&lt;/code&gt; scores are better than the &lt;code&gt;n_iter_no_change - 1&lt;/code&gt; -th-to-last one, up to some tolerance. Only used if early stopping is performed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9462556717c7577fff4ef47d9f5dcd20523f1516" translate="yes" xml:space="preserve">
          <source>Used to initialize &lt;code&gt;w_init&lt;/code&gt; when not specified, with a normal distribution. Pass an int, for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f19cda342b4acf0d93861aea53bc9a6ea559de82" translate="yes" xml:space="preserve">
          <source>Used to pick randomly the &lt;code&gt;max_features&lt;/code&gt; used at each split. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="605a4bcc1f5d9a0fe3ef69215d05c4963e05e516" translate="yes" xml:space="preserve">
          <source>Used to shuffle the training data, when &lt;code&gt;shuffle&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec2d1021c796c8396406488bdd5b004de6014166" translate="yes" xml:space="preserve">
          <source>Used to specify the norm used in the penalization. The &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers support only l2 penalties.</source>
          <target state="translated">Используется для указания нормы, применяемой при наложении штрафов. Решатели newton-cg, sag и lbfgs поддерживают только l2 штрафов.</target>
        </trans-unit>
        <trans-unit id="5860deefa3fd6b4c16483df037c0ad7cd840b1dc" translate="yes" xml:space="preserve">
          <source>Used to specify the norm used in the penalization. The &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers support only l2 penalties. &amp;lsquo;elasticnet&amp;rsquo; is only supported by the &amp;lsquo;saga&amp;rsquo; solver.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2cadba66c38ca766b85abc4b1e03568d1fa6dab" translate="yes" xml:space="preserve">
          <source>Used to specify the norm used in the penalization. The &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers support only l2 penalties. &amp;lsquo;elasticnet&amp;rsquo; is only supported by the &amp;lsquo;saga&amp;rsquo; solver. If &amp;lsquo;none&amp;rsquo; (not supported by the liblinear solver), no regularization is applied.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90efd63a8d51063de92a896b88cf64deaa03a244" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;eigen_solver&lt;/code&gt; == &amp;lsquo;arpack&amp;rsquo;. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27dcb202bde84d98eaa9b02f62b647ecce32aaba" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;shuffle&lt;/code&gt; is True. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8694b55c04737ba18ec4ec98388e9997e16f39ac" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;solver&lt;/code&gt; == &amp;lsquo;sag&amp;rsquo; or &amp;lsquo;saga&amp;rsquo; to shuffle the data. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="59bf45c1d50e7570f6107bdd3616f32c93f002ed" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;solver&lt;/code&gt; == &amp;lsquo;sag&amp;rsquo;, &amp;lsquo;saga&amp;rsquo; or &amp;lsquo;liblinear&amp;rsquo; to shuffle the data. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6070822f60356161845953fee6c5bfe74cf5d59" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;solver='sag'&lt;/code&gt;, &amp;lsquo;saga&amp;rsquo; or &amp;lsquo;liblinear&amp;rsquo; to shuffle the data. Note that this only applies to the solver and not the cross-validation generator. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f152cc191601223884f2e892b0e88e2ae399e550" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;svd_solver&lt;/code&gt; == &amp;lsquo;arpack&amp;rsquo; or &amp;lsquo;randomized&amp;rsquo;. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a789f5832dbb34972e6ab11f85f2125e32dddce" translate="yes" xml:space="preserve">
          <source>Useful for applying a non-linear transformation in regression problems. This transformation can be given as a Transformer such as the QuantileTransformer or as a function and its inverse such as &lt;code&gt;log&lt;/code&gt; and &lt;code&gt;exp&lt;/code&gt;.</source>
          <target state="translated">Полезно для применения нелинейного преобразования в задачах регрессии. Это преобразование может быть задано как преобразователь, например QuantileTransformer, или как функция и ее обратная функция, например &lt;code&gt;log&lt;/code&gt; и &lt;code&gt;exp&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="74349d111804f80e1a38097923f8879dfbcca7b0" translate="yes" xml:space="preserve">
          <source>Useful for applying a non-linear transformation to the target &lt;code&gt;y&lt;/code&gt; in regression problems. This transformation can be given as a Transformer such as the QuantileTransformer or as a function and its inverse such as &lt;code&gt;log&lt;/code&gt; and &lt;code&gt;exp&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="665be16622d5dce4c265443eced33f5309efed0f" translate="yes" xml:space="preserve">
          <source>Useful only for the newton-cg, sag and lbfgs solvers. Maximum number of iterations taken for the solvers to converge.</source>
          <target state="translated">Полезно только для ньютон-кг,sag и lbfgs solvers.Максимальное количество итераций,необходимое для конвергенции решателей.</target>
        </trans-unit>
        <trans-unit id="1f7081fc6e8837c157dbcac4dfe150624d77daa3" translate="yes" xml:space="preserve">
          <source>Useful only when the solver &amp;lsquo;liblinear&amp;rsquo; is used and self.fit_intercept is set to True. In this case, x becomes [x, self.intercept_scaling], i.e. a &amp;ldquo;synthetic&amp;rdquo; feature with constant value equal to intercept_scaling is appended to the instance vector. The intercept becomes &lt;code&gt;intercept_scaling * synthetic_feature_weight&lt;/code&gt;.</source>
          <target state="translated">Полезно, только если используется решатель liblinear и для self.fit_intercept установлено значение True. В этом случае x становится [x, self.intercept_scaling], т.е. &amp;laquo;синтетическая&amp;raquo; функция с постоянным значением, равным intercept_scaling, добавляется к вектору экземпляра. Перехват становится &lt;code&gt;intercept_scaling * synthetic_feature_weight&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="cb4f9242d2c5bef801309a7b11564e9f2917779f" translate="yes" xml:space="preserve">
          <source>Useful tutorials for developing a feel for some of scikit-learn's applications in the machine learning field.</source>
          <target state="translated">Полезные обучающие материалы для развития навыков работы с некоторыми приложениями Scikit-learn в области машинного обучения.</target>
        </trans-unit>
        <trans-unit id="bec249e659662f7d5947bf09a1ea1d4a552885b0" translate="yes" xml:space="preserve">
          <source>User Guide</source>
          <target state="translated">руководство пользователя</target>
        </trans-unit>
        <trans-unit id="221a6dc59fa62390ffe53703a42fa985bbe3d0ea" translate="yes" xml:space="preserve">
          <source>Uses &lt;a href=&quot;#sklearn.model_selection.ParameterGrid&quot;&gt;&lt;code&gt;ParameterGrid&lt;/code&gt;&lt;/a&gt; to perform a full parallelized parameter search.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32b4edc9350cb6d93cc0316d635ce26e35fa63d2" translate="yes" xml:space="preserve">
          <source>Uses BLAS GEMM as replacement for numpy.dot where possible to avoid unnecessary copies.</source>
          <target state="translated">Использует BLAS GEMM в качестве замены для numpy.dot там,где это возможно,чтобы избежать ненужных копий.</target>
        </trans-unit>
        <trans-unit id="ac4bd4f4f631e790604905794abbd6ed09d66803" translate="yes" xml:space="preserve">
          <source>Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.</source>
          <target state="translated">Использует подмножество обучающих точек в функции принятия решений (так называемые поддерживающие векторы),поэтому он также эффективен с точки зрения памяти.</target>
        </trans-unit>
        <trans-unit id="4a4b56e0bea50fff706430a1a94289a4e5e03040" translate="yes" xml:space="preserve">
          <source>Uses a white box model. If a given situation is observable in a model, the explanation for the condition is easily explained by boolean logic. By contrast, in a black box model (e.g., in an artificial neural network), results may be more difficult to interpret.</source>
          <target state="translated">Использует модель белой коробки.Если заданная ситуация наблюдается в модели,то объяснение условия легко объяснить с помощью булевой логики.Напротив,в модели &quot;черного ящика&quot; (например,в искусственной нейронной сети)результаты могут быть сложнее интерпретированы.</target>
        </trans-unit>
        <trans-unit id="ced5d25baa7aaf39837296d764096d52eb67f5ca" translate="yes" xml:space="preserve">
          <source>Uses sampling the fourier transform of the kernel characteristic at regular intervals.</source>
          <target state="translated">Использует выборку преобразования фурье характеристики ядра через регулярные промежутки времени.</target>
        </trans-unit>
        <trans-unit id="2c633fc259072170ae02b4cf8b2266258b09ddc5" translate="yes" xml:space="preserve">
          <source>Uses the vocabulary and document frequencies (df) learned by fit (or fit_transform).</source>
          <target state="translated">Использует словарный запас и частоты документов (df)узнал по мере необходимости (или fit_transform).</target>
        </trans-unit>
        <trans-unit id="cdea6e25f0fe24b03bf907dbf26253d4f40a11df" translate="yes" xml:space="preserve">
          <source>Using &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; or &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; enables the &lt;code&gt;predict_proba&lt;/code&gt; method, which gives a vector of probability estimates \(P(y|x)\) per sample \(x\):</source>
          <target state="translated">Использование &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; или &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; включает метод &lt;code&gt;predict_proba&lt;/code&gt; , который дает вектор оценок вероятности \ (P (y | x) \) на выборку \ (x \):</target>
        </trans-unit>
        <trans-unit id="4072d118d17ebbe341d060ec8f347bb287543668" translate="yes" xml:space="preserve">
          <source>Using FunctionTransformer to select columns</source>
          <target state="translated">Использование FunctionTransformer для выбора столбцов</target>
        </trans-unit>
        <trans-unit id="af570039f4e6335c176e5a0ced20f61ade37ec58" translate="yes" xml:space="preserve">
          <source>Using KBinsDiscretizer to discretize continuous features</source>
          <target state="translated">Использование KBinsDiscretizer для дискретизации непрерывных функций</target>
        </trans-unit>
        <trans-unit id="58dd6560cd1dd1ff16a956c31444ffff4530a294" translate="yes" xml:space="preserve">
          <source>Using L1 penalization as provided by &lt;code&gt;LinearSVC(loss='l2', penalty='l1',
dual=False)&lt;/code&gt; yields a sparse solution, i.e. only a subset of feature weights is different from zero and contribute to the decision function. Increasing &lt;code&gt;C&lt;/code&gt; yields a more complex model (more feature are selected). The &lt;code&gt;C&lt;/code&gt; value that yields a &amp;ldquo;null&amp;rdquo; model (all weights equal to zero) can be calculated using &lt;a href=&quot;generated/sklearn.svm.l1_min_c#sklearn.svm.l1_min_c&quot;&gt;&lt;code&gt;l1_min_c&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Использование &lt;code&gt;LinearSVC(loss='l2', penalty='l1', dual=False)&lt;/code&gt; L1, предоставляемых LinearSVC (потеря = 'l2', штраф = 'l1', dual = False), дает разреженное решение, то есть только подмножество весов характеристик отличается от нуля и вносит вклад в функцию принятия решения. Увеличение &lt;code&gt;C&lt;/code&gt; дает более сложную модель (выбирается больше функций). Значение &lt;code&gt;C&lt;/code&gt; , которое дает &amp;laquo;нулевую&amp;raquo; модель (все веса равны нулю), может быть вычислено с помощью &lt;a href=&quot;generated/sklearn.svm.l1_min_c#sklearn.svm.l1_min_c&quot;&gt; &lt;code&gt;l1_min_c&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="927a462bb89282ccdc19c70530472008783e5ed5" translate="yes" xml:space="preserve">
          <source>Using L1 penalization as provided by &lt;code&gt;LinearSVC(loss='l2', penalty='l1',
dual=False)&lt;/code&gt; yields a sparse solution, i.e. only a subset of feature weights is different from zero and contribute to the decision function. Increasing &lt;code&gt;C&lt;/code&gt; yields a more complex model (more features are selected). The &lt;code&gt;C&lt;/code&gt; value that yields a &amp;ldquo;null&amp;rdquo; model (all weights equal to zero) can be calculated using &lt;a href=&quot;generated/sklearn.svm.l1_min_c#sklearn.svm.l1_min_c&quot;&gt;&lt;code&gt;l1_min_c&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="757f15a3dfafa1d1e98a6f1f457c43151b4efe0d" translate="yes" xml:space="preserve">
          <source>Using LDA and QDA requires computing the log-posterior which depends on the class priors \(P(y=k)\), the class means \(\mu_k\), and the covariance matrices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0033ecf2999fee9c8f71baf5ea186698e26a6aa1" translate="yes" xml:space="preserve">
          <source>Using a &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; without cache enabled, it is possible to inspect the original instance such as:</source>
          <target state="translated">Используя &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;Pipeline&lt;/code&gt; &lt;/a&gt; без включенного кеша, можно проверить исходный экземпляр, например:</target>
        </trans-unit>
        <trans-unit id="8841876aa584e88fcc31f689448303a79af806c4" translate="yes" xml:space="preserve">
          <source>Using a first-order Taylor approximation, the value of \(l\) can be approximated as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4b38a6f3576ed137cc4e9a9f59798fb707d4dde4" translate="yes" xml:space="preserve">
          <source>Using a single underlying feature the model learns both the x and y coordinate as output.</source>
          <target state="translated">Используя единственную базовую функцию,модель получает на выходе координаты x и y.</target>
        </trans-unit>
        <trans-unit id="6d5ea28ea8efb863c08e76177dc50acce9324f64" translate="yes" xml:space="preserve">
          <source>Using a small &lt;code&gt;max_features&lt;/code&gt; value can significantly decrease the runtime.</source>
          <target state="translated">Использование небольшого значения &lt;code&gt;max_features&lt;/code&gt; может значительно сократить время выполнения.</target>
        </trans-unit>
        <trans-unit id="07d5b2f6d48114d6bc5306f53b2bbecb12f93559" translate="yes" xml:space="preserve">
          <source>Using a sub-pipeline, the fitted coefficients can be mapped back into the original feature space.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03c1a9468c05dba06aec630e70cb3912379c2cb0" translate="yes" xml:space="preserve">
          <source>Using its &lt;code&gt;partial_fit&lt;/code&gt; method on chunks of data fetched sequentially from the local hard drive or a network database.</source>
          <target state="translated">Использование его метода &lt;code&gt;partial_fit&lt;/code&gt; для фрагментов данных, последовательно извлекаемых с локального жесткого диска или сетевой базы данных.</target>
        </trans-unit>
        <trans-unit id="ee5e8e298a940fdf98e8e52d2f16edd9327907f7" translate="yes" xml:space="preserve">
          <source>Using kernels</source>
          <target state="translated">Использование ядер</target>
        </trans-unit>
        <trans-unit id="9cfba89ca182507cccdcf4094af12bc5a4c62801" translate="yes" xml:space="preserve">
          <source>Using orthogonal matching pursuit for recovering a sparse signal from a noisy measurement encoded with a dictionary</source>
          <target state="translated">Использование ортогонального поиска соответствия для восстановления разреженного сигнала от шумного измерения,закодированного в словаре.</target>
        </trans-unit>
        <trans-unit id="24a0ae926e510d4f01c040899e37f954b1d9b717" translate="yes" xml:space="preserve">
          <source>Using pre_dispatch in a producer/consumer situation, where the data is generated on the fly. Note how the producer is first called 3 times before the parallel loop is initiated, and then called to generate new data on the fly:</source>
          <target state="translated">Использование pre_dispatch в ситуации производитель/потребитель,где данные генерируются на лету.Обратите внимание,как производитель сначала вызывается 3 раза перед началом параллельного цикла,а затем вызывается для генерации новых данных &quot;на лету&quot;:</target>
        </trans-unit>
        <trans-unit id="efd1182f39233190c4734b5ce34b9cfcf1bbe0bb" translate="yes" xml:space="preserve">
          <source>Using t-SNE. Journal of Machine Learning Research 9:2579-2605, 2008.</source>
          <target state="translated">Используя t-SNE.Журнал исследований в области обучения на станках 9:2579-2605,2008.</target>
        </trans-unit>
        <trans-unit id="52758be5ab8f6ab028b2bf9ad6db5d2b69896663" translate="yes" xml:space="preserve">
          <source>Using the &lt;code&gt;TfidfTransformer&lt;/code&gt;&amp;rsquo;s default settings, &lt;code&gt;TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)&lt;/code&gt; the term frequency, the number of times a term occurs in a given document, is multiplied with idf component, which is computed as</source>
          <target state="translated">Использование &lt;code&gt;TfidfTransformer&lt;/code&gt; &amp;laquo;настройки s по умолчанию, &lt;code&gt;TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)&lt;/code&gt; термин частота, число раз термин встречается в данном документе, умножается на IDF компонент, который вычисляется как</target>
        </trans-unit>
        <trans-unit id="95d62a973e97428e1fb3d7b86f3a392143b00b8c" translate="yes" xml:space="preserve">
          <source>Using the GraphicalLasso estimator to learn a covariance and sparse precision from a small number of samples.</source>
          <target state="translated">Использование оценочного прибора GraphicalLasso для изучения ковариаций и разреженной точности на небольшом количестве образцов.</target>
        </trans-unit>
        <trans-unit id="f9e94a3c6c72e38b7c72fe500879db6b6bb31872" translate="yes" xml:space="preserve">
          <source>Using the Iris dataset, we can construct a tree as follows:</source>
          <target state="translated">Используя набор данных Iris,мы можем построить дерево следующим образом:</target>
        </trans-unit>
        <trans-unit id="99fdc1f5bc1cbf237a61e42fe43157752d29d604" translate="yes" xml:space="preserve">
          <source>Using the Poisson loss with a log-link can correct these problems and lead to a well-calibrated linear model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f990799abb31a15673ef02f50b5506399075290a" translate="yes" xml:space="preserve">
          <source>Using the expected value, the adjusted mutual information can then be calculated using a similar form to that of the adjusted Rand index:</source>
          <target state="translated">Используя ожидаемое значение,скорректированная взаимная информация может быть рассчитана в той же форме,что и скорректированный индекс Rand:</target>
        </trans-unit>
        <trans-unit id="525fdffa79943fda791ea83f2bc571cbb29e45c1" translate="yes" xml:space="preserve">
          <source>Using the naive conditional independence assumption that</source>
          <target state="translated">Используя наивное условное предположение о независимости,что</target>
        </trans-unit>
        <trans-unit id="ded2353583b49d229cc248063161251fcd75da59" translate="yes" xml:space="preserve">
          <source>Using the prediction pipeline in a grid search</source>
          <target state="translated">Использование конвейера прогнозирования при поиске по сетке</target>
        </trans-unit>
        <trans-unit id="4b65de55e2dd198ac6e2aecd67614d2f3e1d68d9" translate="yes" xml:space="preserve">
          <source>Using the results of the previous exercises and the &lt;code&gt;cPickle&lt;/code&gt; module of the standard library, write a command line utility that detects the language of some text provided on &lt;code&gt;stdin&lt;/code&gt; and estimate the polarity (positive or negative) if the text is written in English.</source>
          <target state="translated">Используя результаты предыдущих упражнений и модуль &lt;code&gt;cPickle&lt;/code&gt; стандартной библиотеки, напишите утилиту командной строки, которая определяет язык некоторого текста, предоставленного на &lt;code&gt;stdin&lt;/code&gt; , и оценивает полярность (положительную или отрицательную), если текст написан на английском языке.</target>
        </trans-unit>
        <trans-unit id="271df6087c1c40487d3dd610dcce2afcb5a005f8" translate="yes" xml:space="preserve">
          <source>Using this modification, the tf-idf of the third term in document 1 changes to 1.8473:</source>
          <target state="translated">Используя это изменение,tf-idf третьего срока в документе 1 изменяется на 1.8473:</target>
        </trans-unit>
        <trans-unit id="a81923715d05cfae1b7290021e8d9f8915c03011" translate="yes" xml:space="preserve">
          <source>Usually the Normalized Discounted Cumulative Gain (NDCG, computed by ndcg_score) is preferred.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35033b7b1c0300bd76803da2e755fdbe07a7c28b" translate="yes" xml:space="preserve">
          <source>Utilities from joblib:</source>
          <target state="translated">Коммунальные услуги от joblib:</target>
        </trans-unit>
        <trans-unit id="c9ee5681d3c59f7541c27a38b67edf46259e187b" translate="yes" xml:space="preserve">
          <source>V</source>
          <target state="translated">V</target>
        </trans-unit>
        <trans-unit id="8d1950c14bc870de437b37f806aaa51c635a9ec3" translate="yes" xml:space="preserve">
          <source>V measure</source>
          <target state="translated">V мера</target>
        </trans-unit>
        <trans-unit id="a6ed7787c295565530f8c589d9ab12370f5f5b3d" translate="yes" xml:space="preserve">
          <source>V or VI</source>
          <target state="translated">V или VI</target>
        </trans-unit>
        <trans-unit id="e659ac0cd03fda8c2776727471548e055d6ecaa7" translate="yes" xml:space="preserve">
          <source>V-Measure (NMI with arithmetic mean option.)</source>
          <target state="translated">V-Measure (NMI с опцией среднего арифметического).</target>
        </trans-unit>
        <trans-unit id="893c35d89ea6a5c89935fd8eeed462af4410524f" translate="yes" xml:space="preserve">
          <source>V-Measure is furthermore symmetric: swapping &lt;code&gt;labels_true&lt;/code&gt; and &lt;code&gt;label_pred&lt;/code&gt; will give the same score. This does not hold for homogeneity and completeness. V-Measure is identical to &lt;a href=&quot;sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt;&lt;code&gt;normalized_mutual_info_score&lt;/code&gt;&lt;/a&gt; with the arithmetic averaging method.</source>
          <target state="translated">Кроме того, V-Measure является симметричным: замена &lt;code&gt;labels_true&lt;/code&gt; и &lt;code&gt;label_pred&lt;/code&gt; даст одинаковый результат. Это не относится к однородности и полноте. V-Measure идентичен &lt;a href=&quot;sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt; &lt;code&gt;normalized_mutual_info_score&lt;/code&gt; &lt;/a&gt; с методом арифметического усреднения.</target>
        </trans-unit>
        <trans-unit id="47faeee4990a814efec079e593cccd036ad6778a" translate="yes" xml:space="preserve">
          <source>V-measure cluster labeling given a ground truth.</source>
          <target state="translated">Кластерная маркировка V-измерений,дающая основание для истины.</target>
        </trans-unit>
        <trans-unit id="a4fd517acce42be80ab9791260ae88f5cbdf1a52" translate="yes" xml:space="preserve">
          <source>V. Metsis, I. Androutsopoulos and G. Paliouras (2006). &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.61.5542&quot;&gt;Spam filtering with Naive Bayes &amp;ndash; Which Naive Bayes?&lt;/a&gt; 3rd Conf. on Email and Anti-Spam (CEAS).</source>
          <target state="translated">В. Метсис, И. Андроутсопулос и Г. Палиурас (2006). &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.61.5542&quot;&gt;Фильтрация спама с помощью наивного байесовского метода - какой наивный байесовский метод? &lt;/a&gt;3-я конф. по электронной почте и защите от спама (CEAS).</target>
        </trans-unit>
        <trans-unit id="942786415758a60976a047b84669d53dbc12ecc2" translate="yes" xml:space="preserve">
          <source>V. Metsis, I. Androutsopoulos and G. Paliouras (2006). Spam filtering with naive Bayes &amp;ndash; Which naive Bayes? 3rd Conf. on Email and Anti-Spam (CEAS).</source>
          <target state="translated">В. Метсис, И. Андроутсопулос и Г. Палиурас (2006). Фильтрация спама с помощью наивного Байеса - Какой наивный Байес? 3-я конф. по электронной почте и защите от спама (CEAS).</target>
        </trans-unit>
        <trans-unit id="a4d9f3d16f166bfe390c3f0be94b7a7169e9ff69" translate="yes" xml:space="preserve">
          <source>Valid &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-multiclass&quot;&gt;multiclass&lt;/a&gt; representations for &lt;code&gt;type_of_target&lt;/code&gt; (&lt;code&gt;y&lt;/code&gt;) are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9c007aafb4123183734854c6075f37be2b0eaac" translate="yes" xml:space="preserve">
          <source>Valid &lt;code&gt;type_of_target&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca4c1a38268237e7698432accf1a9a5a48b6fb08" translate="yes" xml:space="preserve">
          <source>Valid metrics for pairwise_distances.</source>
          <target state="translated">Действительные метрики для парных_расстояний.</target>
        </trans-unit>
        <trans-unit id="26700c8a25eea6fd902a0bb4963f14783c982650" translate="yes" xml:space="preserve">
          <source>Valid metrics for pairwise_kernels</source>
          <target state="translated">Действительные метрики для парных_ядер</target>
        </trans-unit>
        <trans-unit id="850c962c3f063b586578621ee12bbb84d6f38bb7" translate="yes" xml:space="preserve">
          <source>Valid options:</source>
          <target state="translated">Действительные варианты:</target>
        </trans-unit>
        <trans-unit id="493108de26f61e3b76acfe363b14fa409e1fdc9a" translate="yes" xml:space="preserve">
          <source>Valid parameter keys can be listed with &lt;code&gt;get_params()&lt;/code&gt;.</source>
          <target state="translated">Допустимые ключи параметров могут быть перечислены с помощью &lt;code&gt;get_params()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1a791ec45bdf21e7b9592679ed5472b3c5ab8093" translate="yes" xml:space="preserve">
          <source>Valid parameter keys can be listed with get_params().</source>
          <target state="translated">С помощью функции get_params()можно перечислить действительные ключи параметров.</target>
        </trans-unit>
        <trans-unit id="90d9fefcb561047bbbd742b13c3608c6fcf1e657" translate="yes" xml:space="preserve">
          <source>Valid values for metric are:</source>
          <target state="translated">Действительные значения для метрики:</target>
        </trans-unit>
        <trans-unit id="47edea5ff3c24dcb16dc15647447ec5c4a9d77c2" translate="yes" xml:space="preserve">
          <source>Valid values for metric are::</source>
          <target state="translated">Действительными значениями для метрики являются:..:</target>
        </trans-unit>
        <trans-unit id="21601426cfbdf9a26553c2613d8f13b5c8a0699e" translate="yes" xml:space="preserve">
          <source>Validate scalar parameters type and value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec59a2a93f21b1aa3fbc16cd26b3b2dbab6fa78b" translate="yes" xml:space="preserve">
          <source>Validation curve.</source>
          <target state="translated">Кривая проверки.</target>
        </trans-unit>
        <trans-unit id="675b8482a7f9f38fa965a1efe10c6a6ee6ec5cdb" translate="yes" xml:space="preserve">
          <source>Value added to the diagonal of the kernel matrix during fitting. Larger values correspond to increased noise level in the observations. This can also prevent a potential numerical issue during fitting, by ensuring that the calculated values form a positive definite matrix. If an array is passed, it must have the same number of entries as the data used for fitting and is used as datapoint-dependent noise level. Note that this is equivalent to adding a WhiteKernel with c=alpha. Allowing to specify the noise level directly as a parameter is mainly for convenience and for consistency with Ridge.</source>
          <target state="translated">Значение,добавленное к диагонали матрицы кернела при подгонке.Большие значения соответствуют повышенному уровню шума в наблюдениях.Это также может предотвратить потенциальную числовую проблему во время подгонки,гарантируя,что вычисленные значения образуют положительную определенную матрицу.Если передаётся массив,то он должен иметь то же количество записей,что и данные,используемые для подгонки,и использоваться как уровень шума,зависящий от точки отсчёта.Обратите внимание,что это эквивалентно добавлению WhiteKernel с c=alpha.Разрешение задавать уровень шума непосредственно в качестве параметра в основном для удобства и согласованности с Ridge.</target>
        </trans-unit>
        <trans-unit id="cdffc29f88adeffd4bcff100fb7aa53a66956d52" translate="yes" xml:space="preserve">
          <source>Value for numerical stability in adam. Only used when solver=&amp;rsquo;adam&amp;rsquo;</source>
          <target state="translated">Значение числовой устойчивости в адаме. Используется только когда solver = 'adam'</target>
        </trans-unit>
        <trans-unit id="c6350d6ef6528ee88ef12a12465bebefd1891dd8" translate="yes" xml:space="preserve">
          <source>Value of the pseudo-likelihood (proxy for likelihood).</source>
          <target state="translated">Значение псевдо-вероятности (прокси-сервер для вероятности).</target>
        </trans-unit>
        <trans-unit id="7a1b051ea7b4e31aba2ba2519e8c31958f649214" translate="yes" xml:space="preserve">
          <source>Value to assign to the score if an error occurs in estimator fitting. If set to &amp;lsquo;raise&amp;rsquo;, the error is raised. If a numeric value is given, FitFailedWarning is raised. This parameter does not affect the refit step, which will always raise the error.</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
