<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ru" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="b8cd925555526484cde7ba65174f600e33250f6b" translate="yes" xml:space="preserve">
          <source>Hochreiter, Bodenhofer, et. al., 2010. &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2881408/&quot;&gt;FABIA: factor analysis for bicluster acquisition&lt;/a&gt;.</source>
          <target state="translated">Hochreiter, Bodenhofer, et. др., 2010. &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2881408/&quot;&gt;FABIA: факторный анализ для бикластерного поглощения.&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="cbd8a9628e732e150b1ccedb68c9c6ad4fe27c2c" translate="yes" xml:space="preserve">
          <source>Holds arrays of shape (n_classes, n_categories of respective feature) for each feature. Each array provides the empirical log probability of categories given the respective feature and class, &lt;code&gt;P(x_i|y)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0265e0dec8e2ff0952abf481f5094201e14a30d8" translate="yes" xml:space="preserve">
          <source>Holds arrays of shape (n_classes, n_categories of respective feature) for each feature. Each array provides the number of samples encountered for each class and category of the specific feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a5c3ac7ac58dcde82acc59c23c0dce0d31966d1" translate="yes" xml:space="preserve">
          <source>Holds the label for each class.</source>
          <target state="translated">Держит этикетку для каждого класса.</target>
        </trans-unit>
        <trans-unit id="4b7dceb5fe5f7e92199815a2b66fef8fdf05dc27" translate="yes" xml:space="preserve">
          <source>Homogeneity and completeness scores are formally given by:</source>
          <target state="translated">Формально даются оценки однородности и полноты:</target>
        </trans-unit>
        <trans-unit id="7c13e77bc830b382c041eec0e3fcc1723f375e05" translate="yes" xml:space="preserve">
          <source>Homogeneity metric of a cluster labeling given a ground truth.</source>
          <target state="translated">Метрика гомогенности кластерной маркировки даёт основание для истины.</target>
        </trans-unit>
        <trans-unit id="3afc9b67230d985e8782525c7b58b615e013e8f9" translate="yes" xml:space="preserve">
          <source>Homogeneity, completeness and V-measure can be computed at once using &lt;a href=&quot;generated/sklearn.metrics.homogeneity_completeness_v_measure#sklearn.metrics.homogeneity_completeness_v_measure&quot;&gt;&lt;code&gt;homogeneity_completeness_v_measure&lt;/code&gt;&lt;/a&gt; as follows:</source>
          <target state="translated">Однородность, полнота и V-мера могут быть вычислены сразу с помощью &lt;a href=&quot;generated/sklearn.metrics.homogeneity_completeness_v_measure#sklearn.metrics.homogeneity_completeness_v_measure&quot;&gt; &lt;code&gt;homogeneity_completeness_v_measure&lt;/code&gt; &lt;/a&gt; следующим образом:</target>
        </trans-unit>
        <trans-unit id="0878824f511837fc1a1c8d27240af19053ebdbd4" translate="yes" xml:space="preserve">
          <source>HouseAge median house age in block</source>
          <target state="translated">HouseAge средний возраст дома в блоке</target>
        </trans-unit>
        <trans-unit id="95f00bca96463f976c07bb46f71ce6b37ead0db0" translate="yes" xml:space="preserve">
          <source>How often to evaluate perplexity. Only used in &lt;code&gt;fit&lt;/code&gt; method. set it to 0 or negative number to not evaluate perplexity in training at all. Evaluating perplexity can help you check convergence in training process, but it will also increase total training time. Evaluating perplexity in every iteration might increase training time up to two-fold.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be45c283b4c54643c38f84bc65a4bfc525d6d30a" translate="yes" xml:space="preserve">
          <source>How often to evaluate perplexity. Only used in &lt;code&gt;fit&lt;/code&gt; method. set it to 0 or negative number to not evalute perplexity in training at all. Evaluating perplexity can help you check convergence in training process, but it will also increase total training time. Evaluating perplexity in every iteration might increase training time up to two-fold.</source>
          <target state="translated">Как часто оценивать недоумение. Используется только по &lt;code&gt;fit&lt;/code&gt; методе. установите значение 0 или отрицательное число, чтобы вообще не оценивать затруднения при обучении. Оценка недоумения может помочь вам проверить сходимость в тренировочном процессе, но также увеличит общее время тренировки. Оценка сложности на каждой итерации может увеличить время обучения до двух раз.</target>
        </trans-unit>
        <trans-unit id="82dc6d28bb69b15075cb833b4ea7ee856b1fb8a5" translate="yes" xml:space="preserve">
          <source>How to compute the normalizer in the denominator. Possible options are &amp;lsquo;min&amp;rsquo;, &amp;lsquo;geometric&amp;rsquo;, &amp;lsquo;arithmetic&amp;rsquo;, and &amp;lsquo;max&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="060faa287065b4ad6ba6c00f598635b42adc21de" translate="yes" xml:space="preserve">
          <source>How to compute the normalizer in the denominator. Possible options are &amp;lsquo;min&amp;rsquo;, &amp;lsquo;geometric&amp;rsquo;, &amp;lsquo;arithmetic&amp;rsquo;, and &amp;lsquo;max&amp;rsquo;. If &amp;lsquo;warn&amp;rsquo;, &amp;lsquo;geometric&amp;rsquo; will be used. The default will change to &amp;lsquo;arithmetic&amp;rsquo; in version 0.22.</source>
          <target state="translated">Как вычислить нормализатор в знаменателе. Возможные варианты: &amp;laquo;минимум&amp;raquo;, &amp;laquo;геометрический&amp;raquo;, &amp;laquo;арифметический&amp;raquo; и &amp;laquo;максимум&amp;raquo;. Если &amp;laquo;предупреждать&amp;raquo;, будет использоваться &amp;laquo;геометрический&amp;raquo;. В версии 0.22 значение по умолчанию изменится на &amp;laquo;арифметический&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="b8efa217d0db9ce56ac60653645beebe151304f9" translate="yes" xml:space="preserve">
          <source>How to compute the normalizer in the denominator. Possible options are &amp;lsquo;min&amp;rsquo;, &amp;lsquo;geometric&amp;rsquo;, &amp;lsquo;arithmetic&amp;rsquo;, and &amp;lsquo;max&amp;rsquo;. If &amp;lsquo;warn&amp;rsquo;, &amp;lsquo;max&amp;rsquo; will be used. The default will change to &amp;lsquo;arithmetic&amp;rsquo; in version 0.22.</source>
          <target state="translated">Как вычислить нормализатор в знаменателе. Возможные варианты: &amp;laquo;минимум&amp;raquo;, &amp;laquo;геометрический&amp;raquo;, &amp;laquo;арифметический&amp;raquo; и &amp;laquo;максимум&amp;raquo;. Если &amp;laquo;предупредить&amp;raquo;, будет использоваться &amp;laquo;макс&amp;raquo;. В версии 0.22 значение по умолчанию изменится на &amp;laquo;арифметический&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="cf894bb3f8fceedab10cdd5da9a5edd37e00865d" translate="yes" xml:space="preserve">
          <source>How to construct the affinity matrix.</source>
          <target state="translated">Как построить матрицу сродства.</target>
        </trans-unit>
        <trans-unit id="d34268ba2716d71aaaeee2c35e527ca55a46dd2f" translate="yes" xml:space="preserve">
          <source>However ARI can also be useful in a purely unsupervised setting as a building block for a Consensus Index that can be used for clustering model selection (TODO).</source>
          <target state="translated">Однако ARI также может быть полезен в чисто неконтролируемой установке в качестве строительного блока для Индекса Консенсуса,который может быть использован для выбора кластерной модели (TODO).</target>
        </trans-unit>
        <trans-unit id="0121c2b22395d1a9db3fd77f24d0a9f0e41170e3" translate="yes" xml:space="preserve">
          <source>However MI-based measures can also be useful in purely unsupervised setting as a building block for a Consensus Index that can be used for clustering model selection.</source>
          <target state="translated">Однако меры,основанные на МИ,также могут быть полезны в чисто неконтролируемой обстановке в качестве строительного блока для Консенсус-индекса,который может быть использован для выбора кластерной модели.</target>
        </trans-unit>
        <trans-unit id="117b6230e0e8ab3fcdc1b277507becef8a05f759" translate="yes" xml:space="preserve">
          <source>However care must taken to always make the affinity matrix symmetric so that the eigenvector decomposition works as expected.</source>
          <target state="translated">Однако следует позаботиться о том,чтобы матрица сродства всегда была симметричной,чтобы разложение по собственному вектору работало так,как ожидается.</target>
        </trans-unit>
        <trans-unit id="92447df8a934c98a63d3aa91a9c263efa88d6300" translate="yes" xml:space="preserve">
          <source>However let&amp;rsquo;s keep our high capacity random forest model for now so as to illustrate some pitfalls with feature importance on variables with many unique values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="925f5b77eb2888a89c04118c35bff0f0ace7255e" translate="yes" xml:space="preserve">
          <source>However the RI score does not guarantee that random label assignments will get a value close to zero (esp. if the number of clusters is in the same order of magnitude as the number of samples).</source>
          <target state="translated">Однако оценка RI не гарантирует,что случайные назначения меток получат значение,близкое к нулю (например,если число кластеров находится в том же порядке величины,что и число выборок).</target>
        </trans-unit>
        <trans-unit id="11d179b15971b8eaae6270be9fce57c0bd0d2416" translate="yes" xml:space="preserve">
          <source>However, by partitioning the available data into three sets, we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets.</source>
          <target state="translated">Однако,разбивая имеющиеся данные на три набора,мы резко уменьшаем количество выборок,которые могут быть использованы для изучения модели,а результаты могут зависеть от конкретного случайного выбора для пары наборов (поезд,валидация).</target>
        </trans-unit>
        <trans-unit id="56c680421b5fb07e56baa9a65f13a80fce385b54" translate="yes" xml:space="preserve">
          <source>However, coefficient estimates for Ordinary Least Squares rely on the independence of the model terms. When terms are correlated and the columns of the design matrix \(X\) have an approximate linear dependence, the design matrix becomes close to singular and as a result, the least-squares estimate becomes highly sensitive to random errors in the observed response, producing a large variance. This situation of &lt;em&gt;multicollinearity&lt;/em&gt; can arise, for example, when data are collected without an experimental design.</source>
          <target state="translated">Однако оценки коэффициентов для обыкновенных наименьших квадратов полагаются на независимость членов модели. Когда члены коррелированы и столбцы матрицы плана \ (X \) имеют приблизительную линейную зависимость, матрица плана становится близкой к сингулярной, и в результате оценка методом наименьших квадратов становится очень чувствительной к случайным ошибкам в наблюдаемой реакции, производя большую дисперсию. Такая ситуация &lt;em&gt;мультиколлинеарности&lt;/em&gt; может возникнуть, например, когда данные собираются без экспериментального плана.</target>
        </trans-unit>
        <trans-unit id="aca3ba038ade9dc36b01dc839f8a0cfb1c392a3d" translate="yes" xml:space="preserve">
          <source>However, dropping one category breaks the symmetry of the original representation and can therefore induce a bias in downstream models, for instance for penalized linear classification or regression models.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf734282463bfc3a9cb343729f546342ec401691" translate="yes" xml:space="preserve">
          <source>However, if the learning curve is steep for the training size in question, then 5- or 10- fold cross validation can overestimate the generalization error.</source>
          <target state="translated">Однако,если кривая обучения является крутой для рассматриваемого размера обучения,то 5-или 10-кратное перекрестное валидирование может завысить ошибку обобщения.</target>
        </trans-unit>
        <trans-unit id="fc162d85afa0b20b4064f40b16eb0e55ca89c629" translate="yes" xml:space="preserve">
          <source>However, it is sometimes helpful to plot the influence of a single hyperparameter on the training score and the validation score to find out whether the estimator is overfitting or underfitting for some hyperparameter values.</source>
          <target state="translated">Тем не менее,иногда бывает полезно построить график влияния одного гиперпараметра на оценку тренировки и оценку валидации,чтобы выяснить,является ли оценка переподходящей или недоходящей для некоторых значений гиперпараметра.</target>
        </trans-unit>
        <trans-unit id="5c8b24673bb3f660f66f90035a856044be6d6f9e" translate="yes" xml:space="preserve">
          <source>However, note that this transformer will only do a binary one-hot encoding when feature values are of type string. If categorical features are represented as numeric values such as int, the DictVectorizer can be followed by &lt;a href=&quot;sklearn.preprocessing.onehotencoder#sklearn.preprocessing.OneHotEncoder&quot;&gt;&lt;code&gt;sklearn.preprocessing.OneHotEncoder&lt;/code&gt;&lt;/a&gt; to complete binary one-hot encoding.</source>
          <target state="translated">Однако обратите внимание, что этот преобразователь будет выполнять двоичное однократное кодирование только тогда, когда значения функций имеют тип string. Если категориальные функции представлены в виде числовых значений, таких как int, за DictVectorizer может следовать &lt;a href=&quot;sklearn.preprocessing.onehotencoder#sklearn.preprocessing.OneHotEncoder&quot;&gt; &lt;code&gt;sklearn.preprocessing.OneHotEncoder&lt;/code&gt; &lt;/a&gt; для завершения двоичного быстрого кодирования.</target>
        </trans-unit>
        <trans-unit id="8b25d9ad009118aef0894664f601ac10786f8b49" translate="yes" xml:space="preserve">
          <source>However, this is not the most precise way of doing this computation, and the distance matrix returned by this function may not be exactly symmetric as required by, e.g., &lt;code&gt;scipy.spatial.distance&lt;/code&gt; functions.</source>
          <target state="translated">Однако это не самый точный способ выполнения этого вычисления, и матрица расстояний, возвращаемая этой функцией, может быть не совсем симметричной, как того требуют, например, функции &lt;code&gt;scipy.spatial.distance&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="379cfb166aa26713fe1131478e9b37a4224780ad" translate="yes" xml:space="preserve">
          <source>Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent</source>
          <target state="translated">Хсян-Фу Ю,Фан-Лань Хуан,Чи-Чжэнь Линь (2011).Двойной координатный спуск</target>
        </trans-unit>
        <trans-unit id="15d1d4b26d2ba06629e368bf6c8a860d8762ef89" translate="yes" xml:space="preserve">
          <source>Huber (&lt;code&gt;'huber'&lt;/code&gt;): Another robust loss function that combines least squares and least absolute deviation; use &lt;code&gt;alpha&lt;/code&gt; to control the sensitivity with regards to outliers (see &lt;a href=&quot;#f2001&quot; id=&quot;id15&quot;&gt;[F2001]&lt;/a&gt; for more details).</source>
          <target state="translated">Хубер ( &lt;code&gt;'huber'&lt;/code&gt; ): еще одна надежная функция потерь, сочетающая наименьшие квадраты и наименьшее абсолютное отклонение; используйте &lt;code&gt;alpha&lt;/code&gt; для управления чувствительностью к выбросам (подробнее см. &lt;a href=&quot;#f2001&quot; id=&quot;id15&quot;&gt;[F2001]&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="31a935f21354ade96cddb9bceb15816934445a99" translate="yes" xml:space="preserve">
          <source>Huber (&lt;code&gt;'huber'&lt;/code&gt;): Another robust loss function that combines least squares and least absolute deviation; use &lt;code&gt;alpha&lt;/code&gt; to control the sensitivity with regards to outliers (see &lt;a href=&quot;model_evaluation#f2001&quot; id=&quot;id18&quot;&gt;[F2001]&lt;/a&gt; for more details).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ac7569be3812003aa580f2d415abbe085c935f8" translate="yes" xml:space="preserve">
          <source>Huber: less sensitive to outliers than least-squares. It is equivalent to least squares when \(|y_i - f(x_i)| \leq \varepsilon\), and \(L(y_i, f(x_i)) = \varepsilon |y_i - f(x_i)| - \frac{1}{2} \varepsilon^2\) otherwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d12d436101cbc3212af50bf81000f6d78d4cf01" translate="yes" xml:space="preserve">
          <source>HuberRegressor vs Ridge on dataset with strong outliers</source>
          <target state="translated">HuberRegressor vs Ridge на наборе данных с сильными промахами</target>
        </trans-unit>
        <trans-unit id="7e58a6e8d89e8504ad31e135de9b485ad40f05f6" translate="yes" xml:space="preserve">
          <source>Hue</source>
          <target state="translated">Hue</target>
        </trans-unit>
        <trans-unit id="c7a8b2b20a9c45f674f17cd8ef7ece305e1c36eb" translate="yes" xml:space="preserve">
          <source>Hue:</source>
          <target state="translated">Hue:</target>
        </trans-unit>
        <trans-unit id="4e99bcdee413a9c98d317e0e8e4199a2bf582f90" translate="yes" xml:space="preserve">
          <source>Hugo Chavez</source>
          <target state="translated">Уго Чавес</target>
        </trans-unit>
        <trans-unit id="27d175ec2bd32b6e89237e92741eaada2632ca6b" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the alpha parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="135e7e12c7ab5ea7496649e72ee134478ecf558e" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the alpha parameter. Default is 1.e-6.</source>
          <target state="translated">Гиперпараметр:параметр обратной шкалы (параметр скорости)для гамма-распределения,предшествующего альфа-параметру.По умолчанию 1.e-6.</target>
        </trans-unit>
        <trans-unit id="b2f7b3253a19f527d0298206233b561d7b41b5a7" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the lambda parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="761054fe5bafcad49a16f057764235860452b8da" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the lambda parameter. Default is 1.e-6</source>
          <target state="translated">Гиперпараметр:параметр обратной шкалы (параметр скорости)для гамма-распределения перед параметром лямбда.По умолчанию 1.e-6</target>
        </trans-unit>
        <trans-unit id="6001ea6392d3003569381e7107254e88f75fd600" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the lambda parameter. Default is 1.e-6.</source>
          <target state="translated">Гиперпараметр:параметр обратной шкалы (параметр скорости)для гамма-распределения перед параметром лямбда.По умолчанию 1.e-6.</target>
        </trans-unit>
        <trans-unit id="dc7fba2810913663c629f4f037b88df90cdd9978" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : shape parameter for the Gamma distribution prior over the alpha parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="81e171654bf22a490946ec147c219e96694497ff" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : shape parameter for the Gamma distribution prior over the alpha parameter. Default is 1.e-6</source>
          <target state="translated">Гиперпараметр:параметр формы для гамма-распределения перед альфа-параметром.По умолчанию 1.e-6</target>
        </trans-unit>
        <trans-unit id="b07af48fd68aeaacb4df041ef30bae006150c237" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : shape parameter for the Gamma distribution prior over the alpha parameter. Default is 1.e-6.</source>
          <target state="translated">Гиперпараметр:параметр формы для гамма-распределения перед альфа-параметром.По умолчанию 1.e-6.</target>
        </trans-unit>
        <trans-unit id="532d93a63b09b5d558170a615d6e76799550e7c3" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : shape parameter for the Gamma distribution prior over the lambda parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1398aea0b1e181e76b6d9d73db4040ccf06ee2f7" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : shape parameter for the Gamma distribution prior over the lambda parameter. Default is 1.e-6.</source>
          <target state="translated">Гиперпараметр:параметр формы для гамма-распределения,предшествующий параметру лямбда.По умолчанию 1.e-6.</target>
        </trans-unit>
        <trans-unit id="7a5b8a439bb2492412d2944256add4dcdf337928" translate="yes" xml:space="preserve">
          <source>Hyper-parameter optimizers</source>
          <target state="translated">гиперпараметрические оптимизаторы</target>
        </trans-unit>
        <trans-unit id="223bf115da53d3d9cdf837b624135b565596fd92" translate="yes" xml:space="preserve">
          <source>Hyper-parameters are parameters that are not directly learnt within estimators. In scikit-learn they are passed as arguments to the constructor of the estimator classes. Typical examples include &lt;code&gt;C&lt;/code&gt;, &lt;code&gt;kernel&lt;/code&gt; and &lt;code&gt;gamma&lt;/code&gt; for Support Vector Classifier, &lt;code&gt;alpha&lt;/code&gt; for Lasso, etc.</source>
          <target state="translated">Гиперпараметры - это параметры, которые не изучаются напрямую в оценщиках. В scikit-learn они передаются в качестве аргументов конструктору классов оценщика. Типичные примеры включают &lt;code&gt;C&lt;/code&gt; , &lt;code&gt;kernel&lt;/code&gt; и &lt;code&gt;gamma&lt;/code&gt; для классификатора опорных векторов, &lt;code&gt;alpha&lt;/code&gt; для лассо и т. Д.</target>
        </trans-unit>
        <trans-unit id="568b05951392672a52de0358537dd29fcafbe544" translate="yes" xml:space="preserve">
          <source>Hyper-parameters of an estimator can be updated after it has been constructed via the &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-set-params&quot;&gt;set_params()&lt;/a&gt; method. Calling &lt;code&gt;fit()&lt;/code&gt; more than once will overwrite what was learned by any previous &lt;code&gt;fit()&lt;/code&gt;:</source>
          <target state="translated">&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-set-params&quot;&gt;Гиперпараметры&lt;/a&gt; оценщика могут быть обновлены после его построения с помощью метода set_params () . Вызов &lt;code&gt;fit()&lt;/code&gt; более одного раза перезапишет то, что было изучено предыдущей &lt;code&gt;fit()&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="3320fca926b13c61acfba24014e8ac870169bd3f" translate="yes" xml:space="preserve">
          <source>Hyper-parameters of an estimator can be updated after it has been constructed via the &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-set-params&quot;&gt;set_params()&lt;/a&gt; method. Calling &lt;code&gt;fit()&lt;/code&gt; more than once will overwrite what was learned by any previous &lt;code&gt;fit()&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1db8c072507305b4aa23189287be39423349b8f4" translate="yes" xml:space="preserve">
          <source>Hyperparameter of the ridge regression that learns the inverse transform (when fit_inverse_transform=True).</source>
          <target state="translated">Гиперпараметр регрессии гребня,который учит обратное преобразование (когда fit_inverse_transform=True).</target>
        </trans-unit>
        <trans-unit id="a15138d06876fc00149292405bf57e4204d00bbe" translate="yes" xml:space="preserve">
          <source>Hyperparameters</source>
          <target state="translated">Hyperparameters</target>
        </trans-unit>
        <trans-unit id="181eca8daf7aaeed93f61701c7eddb643dc6b36a" translate="yes" xml:space="preserve">
          <source>Hyperparameters:</source>
          <target state="translated">Hyperparameters:</target>
        </trans-unit>
        <trans-unit id="8bb86931be2a9d0449c3eec151da751cb88591f1" translate="yes" xml:space="preserve">
          <source>I. Guyon, &amp;ldquo;Design of experiments for the NIPS 2003 variable selection benchmark&amp;rdquo;, 2003.</source>
          <target state="translated">И. Гийон, &amp;laquo;Планирование экспериментов для эталонного теста выбора переменных NIPS 2003&amp;raquo;, 2003.</target>
        </trans-unit>
        <trans-unit id="074b587a2df67fa7bdaebb29bf4f1381e49051c3" translate="yes" xml:space="preserve">
          <source>I. Guyon, K. Bennett, G. Cawley, H.J. Escalante, S. Escalera, T.K. Ho, N. Maci&amp;agrave;, B. Ray, M. Saeed, A.R. Statnikov, E. Viegas, &lt;a href=&quot;https://ieeexplore.ieee.org/document/7280767&quot;&gt;Design of the 2015 ChaLearn AutoML Challenge&lt;/a&gt;, IJCNN 2015.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="483f14c4d9fef04833d7508282eb9a08a8019931" translate="yes" xml:space="preserve">
          <source>I.K. Yeo and R.A. Johnson, &amp;ldquo;A new family of power transformations to improve normality or symmetry.&amp;rdquo; Biometrika, 87(4), pp.954-959, (2000).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a238a89365b9d0ce7f5fb26e189eb03cdc08fbe5" translate="yes" xml:space="preserve">
          <source>ICA can also be used as yet another non linear decomposition that finds components with some sparsity:</source>
          <target state="translated">ICA может также использоваться в качестве еще одного нелинейного разложения,при котором обнаруживаются компоненты с некоторой редкостью:</target>
        </trans-unit>
        <trans-unit id="57933c6e2d57c3e3911db47768687ccc98d16924" translate="yes" xml:space="preserve">
          <source>IDpol</source>
          <target state="translated">IDpol</target>
        </trans-unit>
        <trans-unit id="fcc34dd193c826ae2f0c8b804c532252b4a25480" translate="yes" xml:space="preserve">
          <source>INDUS proportion of non-retail business acres per town</source>
          <target state="translated">INDUS доля площадей нерозничного бизнеса на город</target>
        </trans-unit>
        <trans-unit id="44a4d7b7db7815be999da6a406f4dadd2c4327c5" translate="yes" xml:space="preserve">
          <source>Identification number of each sample, as ordered in dataset.data.</source>
          <target state="translated">Идентификационный номер каждого образца,упорядоченный в наборе данных.</target>
        </trans-unit>
        <trans-unit id="4b5c601d48e24d2806952d270f88677fcd7cfb39" translate="yes" xml:space="preserve">
          <source>Identifying which category an object belongs to.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02d51b4f13558cbcfc807b53522b1ffb156ad7e7" translate="yes" xml:space="preserve">
          <source>Identity: d(x, y) = 0 if and only if x == y</source>
          <target state="translated">Идентификация:d(x,y)=0 если и только если x ==y</target>
        </trans-unit>
        <trans-unit id="35bd2069c37f2c6a308bc5401948b247d5bcfc02" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;all&amp;rdquo;, the imputer mask will represent all features.</source>
          <target state="translated">Если &amp;laquo;все&amp;raquo;, маска импутера будет представлять все функции.</target>
        </trans-unit>
        <trans-unit id="84934b5d658c0a370c458ee55fa3255bb65884a6" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;auto&amp;rdquo; (default), the imputer mask will be of same type as input.</source>
          <target state="translated">Если &amp;laquo;авто&amp;raquo; (по умолчанию), маска импортера будет того же типа, что и входная.</target>
        </trans-unit>
        <trans-unit id="7cdc1bc49e801caf1ff212e1000d88bb13d7e93e" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;auto&amp;rdquo;, then &lt;code&gt;max_features=n_features&lt;/code&gt;.</source>
          <target state="translated">Если &amp;laquo;авто&amp;raquo;, то &lt;code&gt;max_features=n_features&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="164a2722286c1b34bc2df80a90c75397afce3e6b" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;auto&amp;rdquo;, then &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt;.</source>
          <target state="translated">Если &amp;laquo;авто&amp;raquo;, то &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="911a50d98b398312fa01572b5d7b864da542117b" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;auto&amp;rdquo;, then &lt;code&gt;max_samples=min(256, n_samples)&lt;/code&gt;.</source>
          <target state="translated">Если &amp;laquo;авто&amp;raquo;, то &lt;code&gt;max_samples=min(256, n_samples)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="dca169b413a6ec050ae0928eb38f43b00b9c08e0" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;constant&amp;rdquo;, then replace missing values with fill_value. Can be used with strings or numeric data.</source>
          <target state="translated">Если &amp;laquo;константа&amp;raquo;, замените отсутствующие значения на fill_value. Может использоваться со строками или числовыми данными.</target>
        </trans-unit>
        <trans-unit id="fed653e1ff76c14b62a8cb9c0f4474c620b2641e" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;log2&amp;rdquo;, then &lt;code&gt;max_features=log2(n_features)&lt;/code&gt;.</source>
          <target state="translated">Если &amp;laquo;log2&amp;raquo;, то &lt;code&gt;max_features=log2(n_features)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e799052bdd1932be1b28378fc91f87421f6d1065" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;mean&amp;rdquo;, then replace missing values using the mean along each column. Can only be used with numeric data.</source>
          <target state="translated">Если &amp;laquo;среднее&amp;raquo;, замените отсутствующие значения, используя среднее значение по каждому столбцу. Может использоваться только с числовыми данными.</target>
        </trans-unit>
        <trans-unit id="8c28cbae695709f5ae6daaba6d2035fa26d4e040" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;mean&amp;rdquo;, then replace missing values using the mean along the axis.</source>
          <target state="translated">Если &amp;laquo;среднее&amp;raquo;, то вместо отсутствующих значений используйте среднее значение по оси.</target>
        </trans-unit>
        <trans-unit id="d5353b7f39f25231d62cbbc36fcd604e05d2faa0" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;median&amp;rdquo;, then replace missing values using the median along each column. Can only be used with numeric data.</source>
          <target state="translated">Если &amp;laquo;медиана&amp;raquo;, замените отсутствующие значения, используя медиану по каждому столбцу. Может использоваться только с числовыми данными.</target>
        </trans-unit>
        <trans-unit id="2c7bf0a70af62c9d1ff80c38810d3732da415b46" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;median&amp;rdquo;, then replace missing values using the median along the axis.</source>
          <target state="translated">Если &amp;laquo;медиана&amp;raquo;, замените отсутствующие значения, используя медиану по оси.</target>
        </trans-unit>
        <trans-unit id="b9dfb246debbef95e2bc6e78da2b0aca54b8e768" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;missing-only&amp;rdquo; (default), the imputer mask will only represent features containing missing values during fit time.</source>
          <target state="translated">Если &amp;laquo;только отсутствующие&amp;raquo; (по умолчанию), маска импортера будет представлять только объекты, содержащие недостающие значения во время подгонки.</target>
        </trans-unit>
        <trans-unit id="fb9cd590a090a11e857ebbc7c5d49f19787d4a57" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;most_frequent&amp;rdquo;, then replace missing using the most frequent value along each column. Can be used with strings or numeric data.</source>
          <target state="translated">Если &amp;laquo;most_frequent&amp;raquo;, замените пропущенное, используя наиболее частое значение в каждом столбце. Может использоваться со строками или числовыми данными.</target>
        </trans-unit>
        <trans-unit id="a90ab2bff0e7c4a2db0c7d70bcb17fa44e1b8cb3" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;most_frequent&amp;rdquo;, then replace missing using the most frequent value along the axis.</source>
          <target state="translated">Если &amp;laquo;most_frequent&amp;raquo;, то замените пропущенное, используя наиболее частое значение по оси.</target>
        </trans-unit>
        <trans-unit id="8007580c79fb9470823eec0b7f7391f7011a44a8" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;prefit&amp;rdquo; is passed, it is assumed that &lt;code&gt;base_estimator&lt;/code&gt; has been fitted already and all data is used for calibration.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d25972b438acba3aa495003bff5b880c3dc78f95" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;prefit&amp;rdquo; is passed, it is assumed that base_estimator has been fitted already and all data is used for calibration.</source>
          <target state="translated">Если &amp;laquo;prefit&amp;raquo; передан, предполагается, что base_estimator уже настроен и все данные используются для калибровки.</target>
        </trans-unit>
        <trans-unit id="ddc01f2adfc0b5da49bb0bea104c04055f37082b" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;sqrt&amp;rdquo;, then &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt; (same as &amp;ldquo;auto&amp;rdquo;).</source>
          <target state="translated">Если &amp;laquo;sqrt&amp;raquo;, то &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt; (то же самое, что &amp;laquo;auto&amp;raquo;).</target>
        </trans-unit>
        <trans-unit id="050de520f25e08567f8dcb7bcdaa6887bd8ca53c" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;sqrt&amp;rdquo;, then &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt;.</source>
          <target state="translated">Если &amp;laquo;sqrt&amp;raquo;, то &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="274dd12ab1d70a7a9d00df8bbe2aa7f35f2ca3c4" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;SAMME.R&amp;rsquo; then use the SAMME.R real boosting algorithm. &lt;code&gt;base_estimator&lt;/code&gt; must support calculation of class probabilities. If &amp;lsquo;SAMME&amp;rsquo; then use the SAMME discrete boosting algorithm. The SAMME.R algorithm typically converges faster than SAMME, achieving a lower test error with fewer boosting iterations.</source>
          <target state="translated">Если &quot;SAMME.R&quot;, тогда используйте реальный алгоритм повышения SAMME.R. &lt;code&gt;base_estimator&lt;/code&gt; должен поддерживать расчет вероятностей классов. Если &quot;SAMME&quot;, тогда используйте алгоритм дискретного повышения SAMME. Алгоритм SAMME.R обычно сходится быстрее, чем SAMME, обеспечивая меньшую ошибку теста с меньшим количеством итераций повышения.</target>
        </trans-unit>
        <trans-unit id="51b26722f92fe40c28c6f4d36bb516d8181566a9" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;auto&amp;rsquo;, early stopping is enabled if the sample size is larger than 10000. If True, early stopping is enabled, otherwise early stopping is disabled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ae3261c7ce3a365ccb1e46d21ef269f4ad371b0" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;auto&amp;rsquo;, the threshold is determined as in the original paper.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34bbe83eef64f8685433d192f4dd39b726225179" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;auto&amp;rsquo;, then &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bac8214432dad215f7331c0af16dfd3868b9e19" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;balanced&amp;rsquo;, class weights will be given by &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;. If a dictionary is given, keys are classes and values are corresponding class weights. If None is given, the class weights will be uniform.</source>
          <target state="translated">Если &quot;сбалансировано&quot;, веса классов будут заданы как &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt; . Если дан словарь, ключи - это классы, а значения - соответствующие веса классов. Если задано None, веса классов будут одинаковыми.</target>
        </trans-unit>
        <trans-unit id="2ed37f73bd5305414a6ee47c4802aa22bc780ac0" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;diagram&amp;rsquo;, estimators will be displayed as a diagram in a Jupyter lab or notebook context. If &amp;lsquo;text&amp;rsquo;, estimators will be displayed as text. Default is &amp;lsquo;text&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="456401c87cfc2a15cdd408f2dd8be315dc3e833e" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;english&amp;rsquo;, a built-in stop word list for English is used. There are several known issues with &amp;lsquo;english&amp;rsquo; and you should consider an alternative (see &lt;a href=&quot;../feature_extraction#stop-words&quot;&gt;Using stop words&lt;/a&gt;).</source>
          <target state="translated">Если &quot;english&quot;, используется встроенный список стоп-слов для английского языка. Есть несколько известных проблем с &amp;laquo;английским&amp;raquo;, и вам следует рассмотреть альтернативу (см. &lt;a href=&quot;../feature_extraction#stop-words&quot;&gt;Использование стоп-слов&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="f2019bdbdfa8956b7b54e8a5677954f4996f6374" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;file&amp;rsquo;, the sequence items must have a &amp;lsquo;read&amp;rsquo; method (file-like object) that is called to fetch the bytes in memory.</source>
          <target state="translated">Если &amp;laquo;файл&amp;raquo;, элементы последовательности должны иметь метод &amp;laquo;чтения&amp;raquo; (файловый объект), который вызывается для извлечения байтов из памяти.</target>
        </trans-unit>
        <trans-unit id="3dd1f3ca74314afe1ddf15184f6ab04977d1a20b" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;filename&amp;rsquo;, the sequence passed as an argument to fit is expected to be a list of filenames that need reading to fetch the raw content to analyze.</source>
          <target state="translated">Если &amp;laquo;имя файла&amp;raquo;, последовательность, переданная в качестве аргумента для соответствия, должна быть списком имен файлов, которые необходимо прочитать, чтобы извлечь необработанное содержимое для анализа.</target>
        </trans-unit>
        <trans-unit id="6381402e5f026c95872c614d3f284a846d432d3e" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;hard&amp;rsquo;, uses predicted class labels for majority rule voting. Else if &amp;lsquo;soft&amp;rsquo;, predicts the class label based on the argmax of the sums of the predicted probabilities, which is recommended for an ensemble of well-calibrated classifiers.</source>
          <target state="translated">Если &amp;laquo;жестко&amp;raquo;, для голосования по правилу большинства используются метки предсказанного класса. В противном случае, если &amp;laquo;мягкий&amp;raquo;, предсказывает метку класса на основе argmax сумм предсказанных вероятностей, что рекомендуется для ансамбля хорошо откалиброванных классификаторов.</target>
        </trans-unit>
        <trans-unit id="4a61aad0a278d4a0b23f699c1bb6bc9a25b8f483" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;log2&amp;rsquo;, then &lt;code&gt;max_features=log2(n_features)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="034a602ff18129b75a77961464f62c916fb178cb" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;precomputed&amp;rsquo;, the training input X is expected to be a distance matrix.</source>
          <target state="translated">Если &quot;вычислено заранее&quot;, обучающий вход X должен быть матрицей расстояний.</target>
        </trans-unit>
        <trans-unit id="d286c5a17d9d64b09f62a6cd1cf2dc973056dbb7" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;sqrt&amp;rsquo;, then &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="efe2693abb0ad6fb0bb32fc7410403c6f8a6131c" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;warm_start&amp;rsquo; is True, the solution of the last fitting is used as initialization for the next call of fit(). This can speed up convergence when fit is called several times on similar problems. In that case, &amp;lsquo;n_init&amp;rsquo; is ignored and only a single initialization occurs upon the first call. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Если &amp;laquo;warm_start&amp;raquo; имеет значение &amp;laquo;Истина&amp;raquo;, решение последней подгонки используется в качестве инициализации для следующего вызова fit (). Это может ускорить сходимость, если подгонка вызывается несколько раз для аналогичных задач. В этом случае &amp;laquo;n_init&amp;raquo; игнорируется, и при первом вызове происходит только однократная инициализация. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;Глоссарий&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="65bcde64719b83bdeb345ca5fab269155ae4a753" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;warm_start&amp;rsquo; is True, the solution of the last fitting is used as initialization for the next call of fit(). This can speed up convergence when fit is called several times on similar problems. In that case, &amp;lsquo;n_init&amp;rsquo; is ignored and only a single initialization occurs upon the first call. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="245f671779646599b33075b7dcf37bf735b34555" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;warm_start&amp;rsquo; is True, the solution of the last fitting is used as initialization for the next call of fit(). This can speed up convergence when fit is called several times on similar problems. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Если &amp;laquo;warm_start&amp;raquo; имеет значение &amp;laquo;Истина&amp;raquo;, решение последней подгонки используется в качестве инициализации для следующего вызова fit (). Это может ускорить сходимость, если подгонка вызывается несколько раз для аналогичных задач. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;Глоссарий&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="775000d0783a0c4a0cc36e649a7e52e403237e23" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;warm_start&amp;rsquo; is True, the solution of the last fitting is used as initialization for the next call of fit(). This can speed up convergence when fit is called several times on similar problems. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5bb29953be4032aa8bb2090970ba2fb09c57dc65" translate="yes" xml:space="preserve">
          <source>If 0, no progress messages will be printed. If 1, progress messages will be printed to stdout. If &amp;gt; 1, progress messages will be printed and the &lt;code&gt;disp&lt;/code&gt; parameter of &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize&quot;&gt;&lt;code&gt;scipy.optimize.minimize&lt;/code&gt;&lt;/a&gt; will be set to &lt;code&gt;verbose - 2&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a2ad0e9541d6795a0339e5a9c03b37f24ea5bc7" translate="yes" xml:space="preserve">
          <source>If &lt;a href=&quot;#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; has not been called before.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e311856e2dbc16a358c30263eb21c62e3f976c09" translate="yes" xml:space="preserve">
          <source>If &lt;a href=&quot;generated/sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt;&lt;code&gt;MinMaxScaler&lt;/code&gt;&lt;/a&gt; is given an explicit &lt;code&gt;feature_range=(min, max)&lt;/code&gt; the full formula is:</source>
          <target state="translated">Если &lt;a href=&quot;generated/sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt; &lt;code&gt;MinMaxScaler&lt;/code&gt; &lt;/a&gt; задано явное значение &lt;code&gt;feature_range=(min, max)&lt;/code&gt; полная формула будет иметь следующий вид :</target>
        </trans-unit>
        <trans-unit id="6f352ac5787c6e0994736f1793f840aefef2eb74" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;0 &amp;lt; n_components &amp;lt; 1&lt;/code&gt; and &lt;code&gt;svd_solver == 'full'&lt;/code&gt;, select the number of components such that the amount of variance that needs to be explained is greater than the percentage specified by n_components.</source>
          <target state="translated">Если &lt;code&gt;0 &amp;lt; n_components &amp;lt; 1&lt;/code&gt; и &lt;code&gt;svd_solver == 'full'&lt;/code&gt; , выберите количество компонентов таким образом, чтобы величина отклонения, которую необходимо объяснить, была больше, чем процент, указанный n_components.</target>
        </trans-unit>
        <trans-unit id="6154e481a1bfebf053da4021c41ed6b15075ac75" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, &lt;code&gt;Gram&lt;/code&gt; is overwritten.</source>
          <target state="translated">Если &lt;code&gt;False&lt;/code&gt; , &lt;code&gt;Gram&lt;/code&gt; перезаписывается.</target>
        </trans-unit>
        <trans-unit id="c8ea59a59509714d84c6c3be2a8959e87ca2c339" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, &lt;code&gt;X&lt;/code&gt; is overwritten.</source>
          <target state="translated">Если &lt;code&gt;False&lt;/code&gt; , &lt;code&gt;X&lt;/code&gt; перезаписывается.</target>
        </trans-unit>
        <trans-unit id="ecd953eee019b7cf39fa95c1745e9486ce5fb903" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, return the number of correctly classified samples. Otherwise, return the fraction of correctly classified samples.</source>
          <target state="translated">Если &lt;code&gt;False&lt;/code&gt; , вернуть количество правильно классифицированных образцов. В противном случае верните долю правильно классифицированных образцов.</target>
        </trans-unit>
        <trans-unit id="8dd52da2b8b6d856acbbc6b969b86fd0a4246941" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, return the number of misclassifications. Otherwise, return the fraction of misclassifications.</source>
          <target state="translated">Если &lt;code&gt;False&lt;/code&gt; , вернуть количество ошибочных классификаций. В противном случае верните долю ошибочной классификации.</target>
        </trans-unit>
        <trans-unit id="85fcfc531652a8814592a07e791b2030fbc9598e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, return the sum of the Jaccard similarity coefficient over the sample set. Otherwise, return the average of Jaccard similarity coefficient.</source>
          <target state="translated">Если &lt;code&gt;False&lt;/code&gt; , вернуть сумму коэффициента сходства Жаккара по набору выборки. В противном случае верните среднее значение коэффициента сходства Жаккара.</target>
        </trans-unit>
        <trans-unit id="c21045a17e85201e2f77134fc96d9edd698a8ef9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, the &lt;code&gt;cv_results_&lt;/code&gt; attribute will not include training scores.</source>
          <target state="translated">Если &lt;code&gt;False&lt;/code&gt; , атрибут &lt;code&gt;cv_results_&lt;/code&gt; не будет включать оценки обучения.</target>
        </trans-unit>
        <trans-unit id="363d7b7bc89b4fe7d745ba13b3bf107700064544" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, the &lt;code&gt;cv_results_&lt;/code&gt; attribute will not include training scores. Computing training scores is used to get insights on how different parameter settings impact the overfitting/underfitting trade-off. However computing the scores on the training set can be computationally expensive and is not strictly required to select the parameters that yield the best generalization performance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f7a2b9af6d7b5ad533a302e51ca948f564886c6" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;None&lt;/code&gt; the estimator&amp;rsquo;s default scorer is used.</source>
          <target state="translated">Если &lt;code&gt;None&lt;/code&gt; используется счетчик по умолчанию оценщика.</target>
        </trans-unit>
        <trans-unit id="ab9a136f2eebf764f09dd9b08d3d9d7a3daec6b9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;None&lt;/code&gt; the estimator&amp;rsquo;s score method is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8dec298ccc565c5c7f632ae827694845b31aa21" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;None&lt;/code&gt;, &lt;code&gt;estimator&lt;/code&gt; is considered fitted if there exist an attribute that ends with a underscore and does not start with double underscore.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89a2c07a59e8a597581d7c4accbf8ade7624601a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;None&lt;/code&gt;, &lt;code&gt;init_size= 3 * batch_size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0206caad9c301767e28c1eb37b72a3a7f7598e94" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;None&lt;/code&gt;, the scores for each class are returned. Otherwise, this determines the type of averaging performed on the data:</source>
          <target state="translated">Если &lt;code&gt;None&lt;/code&gt; , возвращаются оценки для каждого класса. В противном случае это определяет тип усреднения, выполняемого для данных:</target>
        </trans-unit>
        <trans-unit id="de8d1676c9bb98aea236fe73b6992134925cbda9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;None&lt;/code&gt;, the scores for each class are returned. Otherwise, this determines the type of averaging performed on the data: Note: multiclass ROC AUC currently only handles the &amp;lsquo;macro&amp;rsquo; and &amp;lsquo;weighted&amp;rsquo; averages.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1170dbf5a5618e80add067200212cb5804a58cd" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt; the full path is stored in the &lt;code&gt;coef_path_&lt;/code&gt; attribute. If you compute the solution for a large problem or many targets, setting &lt;code&gt;fit_path&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt; will lead to a speedup, especially with a small alpha.</source>
          <target state="translated">Если &lt;code&gt;True&lt;/code&gt; , полный путь сохраняется в &lt;code&gt;coef_path_&lt;/code&gt; . Если вычислить решение для большой проблемы или многих целей, установка &lt;code&gt;fit_path&lt;/code&gt; в &lt;code&gt;False&lt;/code&gt; приведет к производительности, особенно с малым альфа.</target>
        </trans-unit>
        <trans-unit id="97edef35821191bb6c4443dade8924b80d003e19" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt; then features with missing values during &lt;code&gt;transform&lt;/code&gt; which did not have any missing values during &lt;code&gt;fit&lt;/code&gt; will be imputed with the initial imputation method only. Set to &lt;code&gt;True&lt;/code&gt; if you have many features with no missing values at both &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;transform&lt;/code&gt; time to save compute.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e703de20e5680ee264e2b1b950a8b1ca587cd24f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, X will be copied; else, it may be overwritten.</source>
          <target state="translated">Если &lt;code&gt;True&lt;/code&gt; , X будет скопирован; иначе он может быть перезаписан.</target>
        </trans-unit>
        <trans-unit id="8e26b0bb501133486ba99496e311f44a49ce472b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, perform metric MDS; otherwise, perform nonmetric MDS.</source>
          <target state="translated">Если &lt;code&gt;True&lt;/code&gt; , выполнить метрическую MDS; в противном случае выполните неметрические MDS.</target>
        </trans-unit>
        <trans-unit id="a2b129bca8e38a348fd53d1896c7796acded2f57" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, return a sparse feature matrix</source>
          <target state="translated">Если &lt;code&gt;True&lt;/code&gt; , вернуть разреженную матрицу признаков</target>
        </trans-unit>
        <trans-unit id="887d26ef7077238a636d223d3985225a211c8d82" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, return the prior class probability and conditional probabilities of features given classes, from which the data was drawn.</source>
          <target state="translated">Если &lt;code&gt;True&lt;/code&gt; , вернуть вероятность предшествующего класса и условные вероятности функций заданных классов, из которых были взяты данные.</target>
        </trans-unit>
        <trans-unit id="0b7bef40bad08d9d2c4e67da6c9b56ea79751005" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, some instances might not belong to any class.</source>
          <target state="translated">Если &lt;code&gt;True&lt;/code&gt; , некоторые экземпляры могут не принадлежать ни к какому классу.</target>
        </trans-unit>
        <trans-unit id="e223ba26a8622e808f0df02e86007844177282d6" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;algorithm=&amp;rsquo;lasso_lars&amp;rsquo;&lt;/code&gt; or &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt;, &lt;code&gt;alpha&lt;/code&gt; is the penalty applied to the L1 norm. If &lt;code&gt;algorithm=&amp;rsquo;threshold&amp;rsquo;&lt;/code&gt;, &lt;code&gt;alpha&lt;/code&gt; is the absolute value of the threshold below which coefficients will be squashed to zero. If &lt;code&gt;algorithm=&amp;rsquo;omp&amp;rsquo;&lt;/code&gt;, &lt;code&gt;alpha&lt;/code&gt; is the tolerance parameter: the value of the reconstruction error targeted. In this case, it overrides &lt;code&gt;n_nonzero_coefs&lt;/code&gt;.</source>
          <target state="translated">Если &lt;code&gt;algorithm=&amp;rsquo;lasso_lars&amp;rsquo;&lt;/code&gt; или &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt; , &lt;code&gt;alpha&lt;/code&gt; - это штраф, применяемый к норме L1. Если &lt;code&gt;algorithm=&amp;rsquo;threshold&amp;rsquo;&lt;/code&gt; , &lt;code&gt;alpha&lt;/code&gt; - это абсолютное значение порога, ниже которого коэффициенты будут сведены к нулю. Если &lt;code&gt;algorithm=&amp;rsquo;omp&amp;rsquo;&lt;/code&gt; , &lt;code&gt;alpha&lt;/code&gt; является параметром допуска: значение целевой ошибки восстановления. В этом случае он переопределяет &lt;code&gt;n_nonzero_coefs&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c8adb20b3b91095a2c077330ab11f60b186c2818" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;algorithm='lasso_lars'&lt;/code&gt; or &lt;code&gt;algorithm='lasso_cd'&lt;/code&gt;, &lt;code&gt;alpha&lt;/code&gt; is the penalty applied to the L1 norm. If &lt;code&gt;algorithm='threshold'&lt;/code&gt;, &lt;code&gt;alpha&lt;/code&gt; is the absolute value of the threshold below which coefficients will be squashed to zero. If &lt;code&gt;algorithm='omp'&lt;/code&gt;, &lt;code&gt;alpha&lt;/code&gt; is the tolerance parameter: the value of the reconstruction error targeted. In this case, it overrides &lt;code&gt;n_nonzero_coefs&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ef12938b73ad4fc11883a02f290e9f35cac58e0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ax&lt;/code&gt; is an axes or None, &lt;code&gt;axes_[i, j]&lt;/code&gt; is the axes on the i-th row and j-th column. If &lt;code&gt;ax&lt;/code&gt; is a list of axes, &lt;code&gt;axes_[i]&lt;/code&gt; is the i-th item in &lt;code&gt;ax&lt;/code&gt;. Elements that are None correspond to a nonexisting axes in that position.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd2bdf4031503663b9e9168a5bd9a1faa112780b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ax&lt;/code&gt; is an axes or None, &lt;code&gt;contours_[i, j]&lt;/code&gt; is the partial dependence plot on the i-th row and j-th column. If &lt;code&gt;ax&lt;/code&gt; is a list of axes, &lt;code&gt;contours_[i]&lt;/code&gt; is the partial dependence plot corresponding to the i-th item in &lt;code&gt;ax&lt;/code&gt;. Elements that are None correspond to a nonexisting axes or an axes that does not include a contour plot.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16daa78b71c8fbb0a04353048c9be677f4bd1a67" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ax&lt;/code&gt; is an axes or None, &lt;code&gt;lines_[i, j]&lt;/code&gt; is the partial dependence curve on the i-th row and j-th column. If &lt;code&gt;ax&lt;/code&gt; is a list of axes, &lt;code&gt;lines_[i]&lt;/code&gt; is the partial dependence curve corresponding to the i-th item in &lt;code&gt;ax&lt;/code&gt;. Elements that are None correspond to a nonexisting axes or an axes that does not include a line plot.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b7c522014bc873fbd61bfb64d47b7833096d1b1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ax&lt;/code&gt; is an axes or None, &lt;code&gt;vlines_[i, j]&lt;/code&gt; is the line collection representing the x axis deciles of the i-th row and j-th column. If &lt;code&gt;ax&lt;/code&gt; is a list of axes, &lt;code&gt;vlines_[i]&lt;/code&gt; corresponds to the i-th item in &lt;code&gt;ax&lt;/code&gt;. Elements that are None correspond to a nonexisting axes or an axes that does not include a PDP plot. .. versionadded:: 0.23</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03e758847856246528ffcca83ba803cf5d3e9c24" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ax&lt;/code&gt; is an axes or None, &lt;code&gt;vlines_[i, j]&lt;/code&gt; is the line collection representing the y axis deciles of the i-th row and j-th column. If &lt;code&gt;ax&lt;/code&gt; is a list of axes, &lt;code&gt;vlines_[i]&lt;/code&gt; corresponds to the i-th item in &lt;code&gt;ax&lt;/code&gt;. Elements that are None correspond to a nonexisting axes or an axes that does not include a 2-way plot. .. versionadded:: 0.23</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e5d3c60fbe26a21b3685b7cd50d8157796cb85c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ax&lt;/code&gt; is an axes or None, the &lt;code&gt;bounding_ax_&lt;/code&gt; is the axes where the grid of partial dependence plots are drawn. If &lt;code&gt;ax&lt;/code&gt; is a list of axes or a numpy array of axes, &lt;code&gt;bounding_ax_&lt;/code&gt; is None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a88caf8f6b6232395c9c1524315c6ed672bcf763" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=0&lt;/code&gt; and X is encoded as a CSR matrix;</source>
          <target state="translated">Если &lt;code&gt;axis=0&lt;/code&gt; и X кодируется как матрица CSR;</target>
        </trans-unit>
        <trans-unit id="160d044408c23f7840586e9cc7d8cab0e43ba9b5" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=0&lt;/code&gt;, boolean and integer array-like, integer slice, and scalar integer are supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b74f02ef0c3e3aceaf2040e39764c8bf5d153fee" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=0&lt;/code&gt;, then impute along columns.</source>
          <target state="translated">Если &lt;code&gt;axis=0&lt;/code&gt; , то рассчитать по столбцам.</target>
        </trans-unit>
        <trans-unit id="231cba4e2ed9eee1fca5c3a6b02c0c6f66c47550" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=1&lt;/code&gt; and X is encoded as a CSC matrix.</source>
          <target state="translated">Если &lt;code&gt;axis=1&lt;/code&gt; и X кодируется как матрица CSC.</target>
        </trans-unit>
        <trans-unit id="4405a4c1e894889993d89bb6694cef1a6a8f7db3" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=1&lt;/code&gt;, then impute along rows.</source>
          <target state="translated">Если &lt;code&gt;axis=1&lt;/code&gt; , то рассчитать по строкам.</target>
        </trans-unit>
        <trans-unit id="afe718681bc04a6b175f3e0dbacf56b2e22d3277" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=1&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf71a4a70c1ff1b9076f02c43d89e78c4b0ffc27" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;backend&lt;/code&gt; is a string it must match a previously registered implementation using the &lt;code&gt;register_parallel_backend&lt;/code&gt; function.</source>
          <target state="translated">Если &lt;code&gt;backend&lt;/code&gt; является строкой, он должен соответствовать ранее зарегистрированной реализации с помощью функции &lt;code&gt;register_parallel_backend&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6456a4494f2ba1f052aff4cf6d35ef66e787bc14" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;base_estimator&lt;/code&gt; is None, then &lt;code&gt;base_estimator=sklearn.linear_model.LinearRegression()&lt;/code&gt; is used for target values of dtype float.</source>
          <target state="translated">Если &lt;code&gt;base_estimator&lt;/code&gt; равен None, тогда &lt;code&gt;base_estimator=sklearn.linear_model.LinearRegression()&lt;/code&gt; используется для целевых значений dtype float.</target>
        </trans-unit>
        <trans-unit id="898731158b64382ef9aad2307b39d22b5cd2a315" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;dense&lt;/code&gt; return &lt;code&gt;Y&lt;/code&gt; in the dense binary indicator format. If &lt;code&gt;'sparse'&lt;/code&gt; return &lt;code&gt;Y&lt;/code&gt; in the sparse binary indicator format. &lt;code&gt;False&lt;/code&gt; returns a list of lists of labels.</source>
          <target state="translated">Если &lt;code&gt;dense&lt;/code&gt; верните &lt;code&gt;Y&lt;/code&gt; в плотном двоичном формате индикатора. Если &lt;code&gt;'sparse'&lt;/code&gt; вернет &lt;code&gt;Y&lt;/code&gt; в формате разреженного двоичного индикатора. &lt;code&gt;False&lt;/code&gt; возвращает список списков меток.</target>
        </trans-unit>
        <trans-unit id="b1213caecc623f2a5139e82ba5db339edb5f6265" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;fit_intercept&lt;/code&gt; is set to False, the intercept is set to zero. &lt;code&gt;intercept_&lt;/code&gt; is of shape (1,) when the given problem is binary. In particular, when &lt;code&gt;multi_class=&amp;rsquo;multinomial&amp;rsquo;&lt;/code&gt;, &lt;code&gt;intercept_&lt;/code&gt; corresponds to outcome 1 (True) and &lt;code&gt;-intercept_&lt;/code&gt; corresponds to outcome 0 (False).</source>
          <target state="translated">Если &lt;code&gt;fit_intercept&lt;/code&gt; установлен в False, точка пересечения устанавливается в ноль. &lt;code&gt;intercept_&lt;/code&gt; имеет форму (1,), когда данная задача является двоичной. В частности, когда &lt;code&gt;multi_class=&amp;rsquo;multinomial&amp;rsquo;&lt;/code&gt; , &lt;code&gt;intercept_&lt;/code&gt; соответствует результату 1 (True), а &lt;code&gt;-intercept_&lt;/code&gt; соответствует результату 0 (False).</target>
        </trans-unit>
        <trans-unit id="5adb2b902dec2303b1749b6ba9f10123fe5ab03c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;fit_intercept&lt;/code&gt; is set to False, the intercept is set to zero. &lt;code&gt;intercept_&lt;/code&gt; is of shape (1,) when the given problem is binary. In particular, when &lt;code&gt;multi_class='multinomial'&lt;/code&gt;, &lt;code&gt;intercept_&lt;/code&gt; corresponds to outcome 1 (True) and &lt;code&gt;-intercept_&lt;/code&gt; corresponds to outcome 0 (False).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4504cae87026fef1f6989cfa20e2e5bc171d37e0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;fit_intercept&lt;/code&gt; is set to False, the intercept is set to zero. &lt;code&gt;intercept_&lt;/code&gt; is of shape(1,) when the problem is binary.</source>
          <target state="translated">Если &lt;code&gt;fit_intercept&lt;/code&gt; установлен в False, точка пересечения устанавливается в ноль. &lt;code&gt;intercept_&lt;/code&gt; имеет форму (1,), когда проблема является двоичной.</target>
        </trans-unit>
        <trans-unit id="646836188c841e4fea39e4e4200d1f27e6191986" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;loss&lt;/code&gt; is a callable, then it should be a function that takes two arrays as inputs, the true and predicted value and returns a 1-D array with the i-th value of the array corresponding to the loss on &lt;code&gt;X[i]&lt;/code&gt;.</source>
          <target state="translated">Если &lt;code&gt;loss&lt;/code&gt; является вызываемой, то это должна быть функция, которая принимает два массива в качестве входных данных, истинное и прогнозируемое значение и возвращает одномерный массив с i-м значением массива, соответствующим потерям на &lt;code&gt;X[i]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c42d62680a26d66fc0f439c634f24ee01c670c77" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;memory&lt;/code&gt; is not joblib.Memory-like.</source>
          <target state="translated">Если &lt;code&gt;memory&lt;/code&gt; не является joblib.Memory-like.</target>
        </trans-unit>
        <trans-unit id="e14dd7c153267d74f6b2214ce66bcf041482d792" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_bins&lt;/code&gt; is an array, and there is an ignored feature at index &lt;code&gt;i&lt;/code&gt;, &lt;code&gt;n_bins[i]&lt;/code&gt; will be ignored.</source>
          <target state="translated">Если &lt;code&gt;n_bins&lt;/code&gt; является массивом, и есть игнорируемая функция в индексе &lt;code&gt;i&lt;/code&gt; , &lt;code&gt;n_bins[i]&lt;/code&gt; будет проигнорирована.</target>
        </trans-unit>
        <trans-unit id="20ab457ec31da79f104a0f7a337ba6bfe94b5438" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_clusters&lt;/code&gt; is set to None, the data is reduced from 100,000 samples to a set of 158 clusters. This can be viewed as a preprocessing step before the final (global) clustering step that further reduces these 158 clusters to 100 clusters.</source>
          <target state="translated">Если для &lt;code&gt;n_clusters&lt;/code&gt; установлено значение None, данные сокращаются со 100 000 выборок до набора из 158 кластеров. Это можно рассматривать как этап предварительной обработки перед заключительным (глобальным) этапом кластеризации, который дополнительно сокращает эти 158 кластеров до 100 кластеров.</target>
        </trans-unit>
        <trans-unit id="1769c2fe615105013ff722090827f85ac960dff9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_components == 'mle'&lt;/code&gt; and &lt;code&gt;svd_solver == 'full'&lt;/code&gt;, Minka&amp;rsquo;s MLE is used to guess the dimension. Use of &lt;code&gt;n_components == 'mle'&lt;/code&gt; will interpret &lt;code&gt;svd_solver == 'auto'&lt;/code&gt; as &lt;code&gt;svd_solver == 'full'&lt;/code&gt;.</source>
          <target state="translated">Если &lt;code&gt;n_components == 'mle'&lt;/code&gt; и &lt;code&gt;svd_solver == 'full'&lt;/code&gt; , MLE Минки используется для угадывания размера. Использование &lt;code&gt;n_components == 'mle'&lt;/code&gt; интерпретирует &lt;code&gt;svd_solver == 'auto'&lt;/code&gt; как &lt;code&gt;svd_solver == 'full'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="959758e689ea656dd0e72e3bda18b0a45bbef2e0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_components&lt;/code&gt; is not set then all components are stored and the sum of the ratios is equal to 1.0.</source>
          <target state="translated">Если &lt;code&gt;n_components&lt;/code&gt; не задано, все компоненты сохраняются, а сумма соотношений равна 1.0.</target>
        </trans-unit>
        <trans-unit id="712e62a0190856257c5f6877b0d11f259bd408b5" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_components&lt;/code&gt; is strictly smaller than the dimensionality of the inputs passed to &lt;a href=&quot;#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt;, the identity matrix will be truncated to the first &lt;code&gt;n_components&lt;/code&gt; rows.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4aaa2df3fa37c88b24d06638ef7188d7e8ebe112" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_jobs&lt;/code&gt; was set to a value higher than one, the data is copied for each parameter setting(and not &lt;code&gt;n_jobs&lt;/code&gt; times). This is done for efficiency reasons if individual jobs take very little time, but may raise errors if the dataset is large and not enough memory is available. A workaround in this case is to set &lt;code&gt;pre_dispatch&lt;/code&gt;. Then, the memory is copied only &lt;code&gt;pre_dispatch&lt;/code&gt; many times. A reasonable value for &lt;code&gt;pre_dispatch&lt;/code&gt; is &lt;code&gt;2 * n_jobs&lt;/code&gt;.</source>
          <target state="translated">Если для &lt;code&gt;n_jobs&lt;/code&gt; было установлено значение больше единицы, данные копируются для каждой настройки параметра (а не &lt;code&gt;n_jobs&lt;/code&gt; раз). Это делается из соображений эффективности, если отдельные задания занимают очень мало времени, но могут вызывать ошибки, если набор данных большой и недостаточно памяти. Обходной путь в этом случае - установить &lt;code&gt;pre_dispatch&lt;/code&gt; . Затем память копируется только &lt;code&gt;pre_dispatch&lt;/code&gt; много раз. &lt;code&gt;pre_dispatch&lt;/code&gt; значение для pre_dispatch - &lt;code&gt;2 * n_jobs&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="53682a81a25d0884d79ca09b064b0fc6e7cabd67" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_jobs&lt;/code&gt; was set to a value higher than one, the data is copied for each point in the grid (and not &lt;code&gt;n_jobs&lt;/code&gt; times). This is done for efficiency reasons if individual jobs take very little time, but may raise errors if the dataset is large and not enough memory is available. A workaround in this case is to set &lt;code&gt;pre_dispatch&lt;/code&gt;. Then, the memory is copied only &lt;code&gt;pre_dispatch&lt;/code&gt; many times. A reasonable value for &lt;code&gt;pre_dispatch&lt;/code&gt; is &lt;code&gt;2 * n_jobs&lt;/code&gt;.</source>
          <target state="translated">Если для &lt;code&gt;n_jobs&lt;/code&gt; было установлено значение больше единицы, данные копируются для каждой точки в сетке (а не &lt;code&gt;n_jobs&lt;/code&gt; раз). Это делается из соображений эффективности, если отдельные задания занимают очень мало времени, но могут вызывать ошибки, если набор данных большой и недостаточно памяти. Обходной путь в этом случае - установить &lt;code&gt;pre_dispatch&lt;/code&gt; . Затем память копируется только &lt;code&gt;pre_dispatch&lt;/code&gt; много раз. &lt;code&gt;pre_dispatch&lt;/code&gt; значение для pre_dispatch - &lt;code&gt;2 * n_jobs&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c1cc035dd2ff12188f95601d6fe5c4679ad6bb78" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_samples == 10000&lt;/code&gt;, storing &lt;code&gt;X&lt;/code&gt; as a NumPy array of type float32 would require 10000 x 100000 x 4 bytes = &lt;strong&gt;4GB in RAM&lt;/strong&gt; which is barely manageable on today&amp;rsquo;s computers.</source>
          <target state="translated">Если &lt;code&gt;n_samples == 10000&lt;/code&gt; , для хранения &lt;code&gt;X&lt;/code&gt; в виде массива NumPy типа float32 потребуется 10000 x 100000 x 4 байта = &lt;strong&gt;4 ГБ ОЗУ,&lt;/strong&gt; что едва ли возможно на современных компьютерах.</target>
        </trans-unit>
        <trans-unit id="dd40778e7a383f2053d98b9a07e6219944c6316f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;needs_proba=False&lt;/code&gt; and &lt;code&gt;needs_threshold=False&lt;/code&gt;, the score function is supposed to accept the output of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict&quot;&gt;predict&lt;/a&gt;. If &lt;code&gt;needs_proba=True&lt;/code&gt;, the score function is supposed to accept the output of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt; (For binary &lt;code&gt;y_true&lt;/code&gt;, the score function is supposed to accept probability of the positive class). If &lt;code&gt;needs_threshold=True&lt;/code&gt;, the score function is supposed to accept the output of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e65ba558868cb56b0c8a76632ea67901b254afe" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;normalize == True&lt;/code&gt;, return the average Jaccard similarity coefficient, else it returns the sum of the Jaccard similarity coefficient over the sample set.</source>
          <target state="translated">Если &lt;code&gt;normalize == True&lt;/code&gt; , возвращает средний коэффициент подобия Жаккара, иначе он возвращает сумму коэффициента сходства Жаккара по набору выборок.</target>
        </trans-unit>
        <trans-unit id="c606413521700e073d3e669024415faa2300a113" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;normalize == True&lt;/code&gt;, return the fraction of correctly classified samples (float), else returns the number of correctly classified samples (int).</source>
          <target state="translated">Если &lt;code&gt;normalize == True&lt;/code&gt; , возвращает долю правильно классифицированных выборок (float), иначе возвращает количество правильно классифицированных выборок (int).</target>
        </trans-unit>
        <trans-unit id="cd9dc36a4d7167817c2823908b4ce633913b9765" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;normalize == True&lt;/code&gt;, return the fraction of misclassifications (float), else it returns the number of misclassifications (int).</source>
          <target state="translated">Если &lt;code&gt;normalize == True&lt;/code&gt; , вернуть долю ошибочных классификаций (float), в противном случае возвращается количество ошибочных классификаций (int).</target>
        </trans-unit>
        <trans-unit id="4260d2abf4eeb10994306d99a6424e7eb5ca19c8" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;order='random'&lt;/code&gt;, determines random number generation for the chain order. In addition, it controls the random seed given at each &lt;code&gt;base_estimator&lt;/code&gt; at each chaining iteration. Thus, it is only used when &lt;code&gt;base_estimator&lt;/code&gt; exposes a &lt;code&gt;random_state&lt;/code&gt;. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0b860961bc5b4a4c45189c0fd4de5c2d61f1ab4" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;out=None&lt;/code&gt;, returns a new array containing the mean values, otherwise a reference to the output array is returned.</source>
          <target state="translated">Если &lt;code&gt;out=None&lt;/code&gt; , возвращается новый массив, содержащий средние значения, в противном случае возвращается ссылка на выходной массив.</target>
        </trans-unit>
        <trans-unit id="a1e72f87e91fc5bb6f8882ece59a46bf9ee089e2" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;pos_label is None&lt;/code&gt; and in binary classification, this function returns the average precision, recall and F-measure if &lt;code&gt;average&lt;/code&gt; is one of &lt;code&gt;'micro'&lt;/code&gt;, &lt;code&gt;'macro'&lt;/code&gt;, &lt;code&gt;'weighted'&lt;/code&gt; or &lt;code&gt;'samples'&lt;/code&gt;.</source>
          <target state="translated">Если &lt;code&gt;pos_label is None&lt;/code&gt; и в двоичной классификации, эта функция возвращает среднюю точность, отзыв и F-меру, если &lt;code&gt;average&lt;/code&gt; - одно из &lt;code&gt;'micro'&lt;/code&gt; , &lt;code&gt;'macro'&lt;/code&gt; , &lt;code&gt;'weighted'&lt;/code&gt; или &lt;code&gt;'samples'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="933b8be58a37dcefc6ca9fd3f4735aba59bace4c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;probability=True&lt;/code&gt;, it corresponds to the parameters learned in Platt scaling to produce probability estimates from decision values. If &lt;code&gt;probability=False&lt;/code&gt;, it&amp;rsquo;s an empty array. Platt scaling uses the logistic function &lt;code&gt;1 / (1 + exp(decision_value * probA_ + probB_))&lt;/code&gt; where &lt;code&gt;probA_&lt;/code&gt; and &lt;code&gt;probB_&lt;/code&gt; are learned from the dataset &lt;a href=&quot;#r20c70293ef72-2&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt;. For more information on the multiclass case and training procedure see section 8 of &lt;a href=&quot;#r20c70293ef72-1&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="afcc3cf20f075d3a281dbe1f0f610f65f9ef38a7" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;probability=True&lt;/code&gt;, it corresponds to the parameters learned in Platt scaling to produce probability estimates from decision values. If &lt;code&gt;probability=False&lt;/code&gt;, it&amp;rsquo;s an empty array. Platt scaling uses the logistic function &lt;code&gt;1 / (1 + exp(decision_value * probA_ + probB_))&lt;/code&gt; where &lt;code&gt;probA_&lt;/code&gt; and &lt;code&gt;probB_&lt;/code&gt; are learned from the dataset &lt;a href=&quot;#r9709ce4a60d3-2&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt;. For more information on the multiclass case and training procedure see section 8 of &lt;a href=&quot;#r9709ce4a60d3-1&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bb4c6eca31ede3ca3e8fe5a9b41ecd9a55b266b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;return_path==True&lt;/code&gt; returns the entire path, else returns only the last point of the path.</source>
          <target state="translated">Если &lt;code&gt;return_path==True&lt;/code&gt; возвращает весь путь, иначе возвращает только последнюю точку пути.</target>
        </trans-unit>
        <trans-unit id="9e477bb8072307702a812f869b8166fe31bf9ca0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;smooth_idf=True&lt;/code&gt; (the default), the constant &amp;ldquo;1&amp;rdquo; is added to the numerator and denominator of the idf as if an extra document was seen containing every term in the collection exactly once, which prevents zero divisions: idf(d, t) = log [ (1 + n) / (1 + df(d, t)) ] + 1.</source>
          <target state="translated">Если &lt;code&gt;smooth_idf=True&lt;/code&gt; (по умолчанию), константа &amp;laquo;1&amp;raquo; добавляется к числителю и знаменателю idf, как если бы был замечен дополнительный документ, содержащий каждый термин в коллекции ровно один раз, что предотвращает нулевое деление: idf (d, t ) = журнал [(1 + n) / (1 + df (d, t))] + 1.</target>
        </trans-unit>
        <trans-unit id="7e7ad1036fa8cee418b26fc730608087f9208f2c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;smooth_idf=True&lt;/code&gt; (the default), the constant &amp;ldquo;1&amp;rdquo; is added to the numerator and denominator of the idf as if an extra document was seen containing every term in the collection exactly once, which prevents zero divisions: idf(t) = log [ (1 + n) / (1 + df(t)) ] + 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f772487671a5560a2a2bb3464b54cf0bad5b348" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;svd_solver == 'arpack'&lt;/code&gt;, the number of components must be strictly less than the minimum of n_features and n_samples.</source>
          <target state="translated">Если &lt;code&gt;svd_solver == 'arpack'&lt;/code&gt; , количество компонентов должно быть строго меньше минимального из n_features и n_samples.</target>
        </trans-unit>
        <trans-unit id="abdb8ed2b871d03510343cf9ee77736674d298ab" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;validate&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;X&lt;/code&gt; will be checked.</source>
          <target state="translated">Если &lt;code&gt;validate&lt;/code&gt; это &lt;code&gt;True&lt;/code&gt; , &lt;code&gt;X&lt;/code&gt; будет проверяться.</target>
        </trans-unit>
        <trans-unit id="5cfb594032bd50fcef2738a25df520e95867f411" translate="yes" xml:space="preserve">
          <source>If C is a ground truth class assignment and K the clustering, let us define \(a\) and \(b\) as:</source>
          <target state="translated">Если C является основным классом истины и K кластеризации,давайте определим \(a\)и \(b\)как:</target>
        </trans-unit>
        <trans-unit id="40e72ab25b1921db07187a1c526cc9080a10eaea" translate="yes" xml:space="preserve">
          <source>If False, X will be overwritten. &lt;code&gt;copy=False&lt;/code&gt; can be used to save memory but is unsafe for general use.</source>
          <target state="translated">Если false, X будет перезаписан. &lt;code&gt;copy=False&lt;/code&gt; можно использовать для экономии памяти, но небезопасно для общего использования.</target>
        </trans-unit>
        <trans-unit id="b5379fd8e8700833a560e6ab84ea58c40e10b6a8" translate="yes" xml:space="preserve">
          <source>If False, data passed to fit are overwritten and running fit(X).transform(X) will not yield the expected results, use fit_transform(X) instead.</source>
          <target state="translated">Если False,данные,переданные в соответствие,перезаписываются и запуск fit(X).transform(X)не даст ожидаемого результата,используйте вместо этого fit_transform(X).</target>
        </trans-unit>
        <trans-unit id="3d545281a4ef31d03ffb244079b728a3c5cc8b18" translate="yes" xml:space="preserve">
          <source>If False, data passed to fit are overwritten. Defaults to True.</source>
          <target state="translated">Если False,данные,переданные в соответствие,перезаписываются.По умолчанию-True.</target>
        </trans-unit>
        <trans-unit id="4bf616e8d9d604d2525c59d889782525e410270c" translate="yes" xml:space="preserve">
          <source>If False, distances will not be returned</source>
          <target state="translated">Если Фальшивка,расстояния не будут возвращены.</target>
        </trans-unit>
        <trans-unit id="b4145c6e6cc098818614b51aca0cae30eca8ed94" translate="yes" xml:space="preserve">
          <source>If False, distances will not be returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8cdf8e9cb326e6212f67c80aca3a4f04326fc4c" translate="yes" xml:space="preserve">
          <source>If False, raise a IOError if the data is not locally available instead of trying to download the data from the source site.</source>
          <target state="translated">Если False,поднимите IOError,если данные не доступны локально,вместо того,чтобы пытаться загрузить данные с исходного сайта.</target>
        </trans-unit>
        <trans-unit id="707f36c34b2f81eacbaf143a8e62cb9371b1332e" translate="yes" xml:space="preserve">
          <source>If False, raise an IOError if the data is not locally available instead of trying to download the data from the source site.</source>
          <target state="translated">Если False,поднимите IOError,если данные не доступны локально,вместо того,чтобы пытаться загрузить данные с исходного сайта.</target>
        </trans-unit>
        <trans-unit id="d32001af2bcb0806daa431ab8cf432f700c0bb79" translate="yes" xml:space="preserve">
          <source>If False, the imputer mask will be a numpy array.</source>
          <target state="translated">Если False,то маска приёмника будет массивом numpy.</target>
        </trans-unit>
        <trans-unit id="2823ebb07c9bdb5cae0bfca227f5db48d585ba5a" translate="yes" xml:space="preserve">
          <source>If False, the input arrays X and dictionary will not be checked.</source>
          <target state="translated">Если False,то входные массивы X и словарь не будут проверяться.</target>
        </trans-unit>
        <trans-unit id="bd8e933f9aa74b9b27da566d4ffb96f4e62218cf" translate="yes" xml:space="preserve">
          <source>If False, the input arrays X and y will not be checked.</source>
          <target state="translated">Если False,входные массивы X и y не будут проверены.</target>
        </trans-unit>
        <trans-unit id="85aa52dd8c7d5d29b6bebfd616a7ca3fe91cde14" translate="yes" xml:space="preserve">
          <source>If False, the projected data uses a sparse representation if the input is sparse.</source>
          <target state="translated">Если False,то в проектируемых данных используется разреженное представление,если входные данные разрежены.</target>
        </trans-unit>
        <trans-unit id="7bfec8f3204bdf713e2d3557ec53ea6f3960ad24" translate="yes" xml:space="preserve">
          <source>If False, there is no input validation.</source>
          <target state="translated">Если False,то нет проверки входных данных.</target>
        </trans-unit>
        <trans-unit id="a67320198a0b746d35fcc941198f1221ee73c87b" translate="yes" xml:space="preserve">
          <source>If False, try to avoid a copy and do inplace scaling instead. This is not guaranteed to always work inplace; e.g. if the data is not a NumPy array or scipy.sparse CSR matrix, a copy may still be returned.</source>
          <target state="translated">Если Фальшивка,постарайтесь избежать копирования и вместо этого выполните масштабирование на месте.Это не всегда гарантированно работает на месте;например,если данные не являются массивом NumPy или матрицей scipy.sparse CSR,копия все равно может быть возвращена.</target>
        </trans-unit>
        <trans-unit id="fcd08eda0bca1685e28de89ae046095006b92653" translate="yes" xml:space="preserve">
          <source>If None (default), load all the categories. If not None, list of category names to load (other categories ignored).</source>
          <target state="translated">Если нет (по умолчанию),загрузите все категории.Если нет,загрузите список названий категорий (другие категории игнорируются).</target>
        </trans-unit>
        <trans-unit id="7c0ab0b638c1cad0f1492e60796eecd4f321a731" translate="yes" xml:space="preserve">
          <source>If None (default), then draw &lt;code&gt;X.shape[0]&lt;/code&gt; samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7cbd99fe721a3cd173045eddaf688b83e7620c1" translate="yes" xml:space="preserve">
          <source>If None the estimator&amp;rsquo;s default scorer, if available, is used.</source>
          <target state="translated">Если нет, используется счетчик по умолчанию оценщика, если таковой имеется.</target>
        </trans-unit>
        <trans-unit id="8c0f950a52950ceff35d04e0ab42f83a05b3adb9" translate="yes" xml:space="preserve">
          <source>If None the estimator&amp;rsquo;s score method is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96ad58db5ee1b903109c173fcab72b0955bb0408" translate="yes" xml:space="preserve">
          <source>If None, defaults to 1.0 / n_features</source>
          <target state="translated">Если нет,по умолчанию 1.0/n_features</target>
        </trans-unit>
        <trans-unit id="e5ce9a9046a52014390758ba790166ae01779c1f" translate="yes" xml:space="preserve">
          <source>If None, do not try to decode the content of the files (e.g. for images or other non-text content). If not None, encoding to use to decode text files to Unicode if load_content is True.</source>
          <target state="translated">Если нет,не пытайтесь декодировать содержимое файлов (например,для изображений или другого нетекстового содержимого).Если нет-использовать кодировку для декодирования текстовых файлов в Unicode,если load_content равен True.</target>
        </trans-unit>
        <trans-unit id="3e5e8d666168a7a15a80edb16364256ae0a379e4" translate="yes" xml:space="preserve">
          <source>If None, no stop words will be used. max_df can be set to a value in the range [0.7, 1.0) to automatically detect and filter stop words based on intra corpus document frequency of terms.</source>
          <target state="translated">Если нет,то стоп-слова не будут использоваться.max_df может быть установлен на значение в диапазоне [0.7,1.0]для автоматического обнаружения и фильтрации стоп-слов на основе внутрикорпусной периодичности терминов.</target>
        </trans-unit>
        <trans-unit id="02542a43a2f09f5328657402d69f49ce442cb6c2" translate="yes" xml:space="preserve">
          <source>If None, pairwise_distances_chunked returns a generator of vertical chunks of the distance matrix.</source>
          <target state="translated">Если None,pairwise_distances_chunked возвращает генератор вертикальных кусков матрицы расстояний.</target>
        </trans-unit>
        <trans-unit id="eb5d73cb83520641b0e2c815c109159135d569cc" translate="yes" xml:space="preserve">
          <source>If None, the estimator&amp;rsquo;s default scorer (if available) is used.</source>
          <target state="translated">Если &amp;laquo;Нет&amp;raquo;, используется счетчик по умолчанию оценщика (если есть).</target>
        </trans-unit>
        <trans-unit id="43ea051b06405f0316e7696e80296e11d93edbf6" translate="yes" xml:space="preserve">
          <source>If None, the estimator&amp;rsquo;s score method is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="651c3653c15c90a6722a00465ba57c19c30adb9b" translate="yes" xml:space="preserve">
          <source>If None, the threshold is assumed to be half way between neg_label and pos_label.</source>
          <target state="translated">Если None,порог принимается равным половине пути между negative_label и pos_label.</target>
        </trans-unit>
        <trans-unit id="ac652d29bc285e4e46f5aaf2fe5415c63aee1f09" translate="yes" xml:space="preserve">
          <source>If None, then &lt;code&gt;max_features=n_features&lt;/code&gt;.</source>
          <target state="translated">Если нет, то &lt;code&gt;max_features=n_features&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2f9e5ee96434f57529c2481b71d631d9dd0cb5e7" translate="yes" xml:space="preserve">
          <source>If True (default), the squared error norm is divided by n_features. If False, the squared error norm is not rescaled.</source>
          <target state="translated">Если значение True (по умолчанию),то норма квадратной ошибки делится на n_функции.Если False,норма квадратной ошибки не перемасштабируется.</target>
        </trans-unit>
        <trans-unit id="da82574bb396bf8045c493d20398be74e4e9ef51" translate="yes" xml:space="preserve">
          <source>If True (default), then include a bias column, the feature in which all polynomial powers are zero (i.e. a column of ones - acts as an intercept term in a linear model).</source>
          <target state="translated">Если True (по умолчанию),то включить столбец смещения-признак,в котором все полиномические силы равны нулю (т.е.столбец единичных-действует как член перехвата в линейной модели).</target>
        </trans-unit>
        <trans-unit id="d150b2a4c21e929dfd726f6463d03ca9f005e91a" translate="yes" xml:space="preserve">
          <source>If True (default), transform will raise an error when there are features with missing values in transform that have no missing values in fit This is applicable only when &lt;code&gt;features=&quot;missing-only&quot;&lt;/code&gt;.</source>
          <target state="translated">Если True (по умолчанию), преобразование вызовет ошибку, если в преобразовании есть объекты с пропущенными значениями, которые не имеют недостающих значений. Это применимо только тогда, когда &lt;code&gt;features=&quot;missing-only&quot;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="9da3cf1a0e0153fc6c646a1aa71f68e34d8d27f5" translate="yes" xml:space="preserve">
          <source>If True (default), transform will raise an error when there are features with missing values in transform that have no missing values in fit. This is applicable only when &lt;code&gt;features=&quot;missing-only&quot;&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4fe165b3f600e13152308080cc2a736269c867b" translate="yes" xml:space="preserve">
          <source>If True and &lt;a href=&quot;#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; has been called before, the solution of the previous call to &lt;a href=&quot;#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; is used as the initial linear transformation (&lt;code&gt;n_components&lt;/code&gt; and &lt;code&gt;init&lt;/code&gt; will be ignored).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d91ad850130f94be79fb668041bf3eecd01a29b0" translate="yes" xml:space="preserve">
          <source>If True and if X is sparse, the method also returns the intercept, and the solver is automatically changed to &amp;lsquo;sag&amp;rsquo;. This is only a temporary fix for fitting the intercept with sparse data. For dense data, use sklearn.linear_model._preprocess_data before your regression.</source>
          <target state="translated">Если True и если X является разреженным, метод также возвращает точку пересечения, и решающая программа автоматически изменяется на 'sag'. Это всего лишь временное исправление для подгонки перехвата с разреженными данными. Для плотных данных используйте sklearn.linear_model._preprocess_data перед регрессией.</target>
        </trans-unit>
        <trans-unit id="d1eef608e634bc22aa5f2e22e802ae927e355666" translate="yes" xml:space="preserve">
          <source>If True returns MSE value, if False returns RMSE value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a68108e0ea5bf983075f127e077ee80517d6dfdd" translate="yes" xml:space="preserve">
          <source>If True the covariance matrices are computed and stored in the &lt;code&gt;self.covariance_&lt;/code&gt; attribute.</source>
          <target state="translated">Если True, ковариационные матрицы вычисляются и сохраняются в &lt;code&gt;self.covariance_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5c5d5facc126a265032a533a4664c8926339ade0" translate="yes" xml:space="preserve">
          <source>If True the full path is stored in the &lt;code&gt;coef_path_&lt;/code&gt; attribute. If you compute the solution for a large problem or many targets, setting &lt;code&gt;fit_path&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt; will lead to a speedup, especially with a small alpha.</source>
          <target state="translated">Если True, полный путь сохраняется в &lt;code&gt;coef_path_&lt;/code&gt; . Если вычислить решение для большой проблемы или многих целей, установка &lt;code&gt;fit_path&lt;/code&gt; в &lt;code&gt;False&lt;/code&gt; приведет к производительности, особенно с малым альфа.</target>
        </trans-unit>
        <trans-unit id="53e960778922c6ba257a9c66f18d0e260655f043" translate="yes" xml:space="preserve">
          <source>If True the function returns the pairwise distance matrix else it returns the componentwise L1 pairwise-distances. Not supported for sparse matrix inputs.</source>
          <target state="translated">Если функция True возвращает матрицу парных расстояний,в противном случае она возвращает компонентные L1 парные расстояния.Не поддерживается для разреженных матричных входов.</target>
        </trans-unit>
        <trans-unit id="2546c89362b151bbba35dab463b810d1f7c0a359" translate="yes" xml:space="preserve">
          <source>If True the order of the dataset is shuffled to avoid having images of the same person grouped.</source>
          <target state="translated">Если True,то порядок следования набора данных перетасовывается,чтобы избежать группировки изображений одного и того же человека.</target>
        </trans-unit>
        <trans-unit id="618a67ac95fc4ccc3385ae319143bf344e1ffb63" translate="yes" xml:space="preserve">
          <source>If True then raise a warning if conversion is required.</source>
          <target state="translated">Если значение True,то поднимите предупреждение,если требуется преобразование.</target>
        </trans-unit>
        <trans-unit id="19362eed638b2dc6d204e12092075aedd87e6e93" translate="yes" xml:space="preserve">
          <source>If True then raise an exception if array is not symmetric.</source>
          <target state="translated">Если True,то поднимите исключение,если массив не симметричен.</target>
        </trans-unit>
        <trans-unit id="baf82faf959595f525e5d5a94c6b8526ad942779" translate="yes" xml:space="preserve">
          <source>If True, X will be copied; else, it may be overwritten.</source>
          <target state="translated">Если True,то будет скопирован X;в противном случае,он может быть переписан.</target>
        </trans-unit>
        <trans-unit id="e25c58f63a5736150718d46a3a4c05d31a44c0e6" translate="yes" xml:space="preserve">
          <source>If True, a &lt;a href=&quot;sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt; transform will stack onto output of the imputer&amp;rsquo;s transform. This allows a predictive estimator to account for missingness despite imputation. If a feature has no missing values at fit/train time, the feature won&amp;rsquo;t appear on the missing indicator even if there are missing values at transform/test time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df1778fbc0c3701b8b17966bdd64201d1f2550fe" translate="yes" xml:space="preserve">
          <source>If True, a &lt;a href=&quot;sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt; transform will stack onto the output of the imputer&amp;rsquo;s transform. This allows a predictive estimator to account for missingness despite imputation. If a feature has no missing values at fit/train time, the feature won&amp;rsquo;t appear on the missing indicator even if there are missing values at transform/test time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa91f074d713faca021e35ddd5331805b9848f9e" translate="yes" xml:space="preserve">
          <source>If True, a copy of X will be created. If False, a copy may still be returned if X&amp;rsquo;s dtype is not a floating point type.</source>
          <target state="translated">Если True, будет создана копия X. Если False, копия может быть возвращена, если dtype X не является типом с плавающей запятой.</target>
        </trans-unit>
        <trans-unit id="45f6e4d313f4bf3abc200106ce518a942e07ab23" translate="yes" xml:space="preserve">
          <source>If True, a copy of X will be created. If False, imputation will be done in-place whenever possible.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="054b374d036034be5d7258a6a975038eb8fec935" translate="yes" xml:space="preserve">
          <source>If True, a copy of X will be created. If False, imputation will be done in-place whenever possible. Note that, in the following cases, a new copy will always be made, even if &lt;code&gt;copy=False&lt;/code&gt;:</source>
          <target state="translated">Если True, будет создана копия X. Если имеет значение &amp;laquo;Ложь&amp;raquo;, вменение будет производиться на месте, когда это возможно. Обратите внимание, что в следующих случаях всегда будет создаваться новая копия, даже если &lt;code&gt;copy=False&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="f237ade75e04520befb53fc36267d58be41dc5ae" translate="yes" xml:space="preserve">
          <source>If True, a persistent copy of the training data is stored in the object. Otherwise, just a reference to the training data is stored, which might cause predictions to change if the data is modified externally.</source>
          <target state="translated">Если Правда,то в объекте сохраняется постоянная копия обучающих данных.В противном случае сохраняется только ссылка на данные тренинга,что может привести к изменению прогнозов,если данные будут изменены извне.</target>
        </trans-unit>
        <trans-unit id="5b4ca3bdeb594ab34289df8cfc7fa70c9919ad95" translate="yes" xml:space="preserve">
          <source>If True, all non zero counts are set to 1. This is useful for discrete probabilistic models that model binary events rather than integer counts.</source>
          <target state="translated">Если True,то все ненулевые числа установлены в 1.Это полезно для дискретных вероятностных моделей,которые моделируют двоичные события,а не целые числа.</target>
        </trans-unit>
        <trans-unit id="95f1a98443a6aa5501cfb81c289c266bb7baf4d6" translate="yes" xml:space="preserve">
          <source>If True, all non-zero term counts are set to 1. This does not mean outputs will have only 0/1 values, only that the tf term in tf-idf is binary. (Set idf and normalization to False to get 0/1 outputs).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0beec2b2d6b910456e155063f83ec1e59c6c0df1" translate="yes" xml:space="preserve">
          <source>If True, all non-zero term counts are set to 1. This does not mean outputs will have only 0/1 values, only that the tf term in tf-idf is binary. (Set idf and normalization to False to get 0/1 outputs.)</source>
          <target state="translated">Если значение True,то все ненулевые члены счетчика установлены на 1.Это не означает,что выходы будут иметь только значения 0/1,только то,что член tf в tf-idf является двоичным.(Чтобы получить выходы 0/1,установите idf и нормируйте значение False).</target>
        </trans-unit>
        <trans-unit id="b69242de00e60526a79082b37846a2a724d7b3dd" translate="yes" xml:space="preserve">
          <source>If True, center the data before scaling.</source>
          <target state="translated">Если значение True,отцентрируйте данные перед масштабированием.</target>
        </trans-unit>
        <trans-unit id="6c9a4d2da449884c97015be12ce056a53dc04757" translate="yes" xml:space="preserve">
          <source>If True, center the data before scaling. This does not work (and will raise an exception) when attempted on sparse matrices, because centering them entails building a dense matrix which in common use cases is likely to be too large to fit in memory.</source>
          <target state="translated">Если значение True,отцентрируйте данные перед масштабированием.Это не работает (и вызовет исключение)при попытке работы с разреженными матрицами,так как центрирование их приводит к построению плотной матрицы,которая в обычных случаях использования,скорее всего,будет слишком большой,чтобы поместиться в памяти.</target>
        </trans-unit>
        <trans-unit id="9d7135e468914be214009091b1fc11f6721afd0a" translate="yes" xml:space="preserve">
          <source>If True, center the data before scaling. This will cause &lt;code&gt;transform&lt;/code&gt; to raise an exception when attempted on sparse matrices, because centering them entails building a dense matrix which in common use cases is likely to be too large to fit in memory.</source>
          <target state="translated">Если True, центрируйте данные перед масштабированием. Это приведет к тому, что &lt;code&gt;transform&lt;/code&gt; вызовет исключение при попытке на разреженных матрицах, потому что их центрирование влечет за собой построение плотной матрицы, которая в обычных случаях использования, вероятно, будет слишком большой, чтобы поместиться в памяти.</target>
        </trans-unit>
        <trans-unit id="694a00b6963c573c0a68b328feb15483853b44c0" translate="yes" xml:space="preserve">
          <source>If True, compute the log marginal likelihood at each iteration of the optimization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c24f1c3d35266b322135ac3270540ea5ef40a09d" translate="yes" xml:space="preserve">
          <source>If True, compute the objective function at each step of the model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20839df17b3bca6b55533337f17b7c17f0881d1a" translate="yes" xml:space="preserve">
          <source>If True, compute the objective function at each step of the model. Default is False</source>
          <target state="translated">Если Верно,вычислите объективную функцию на каждом этапе модели.По умолчанию Ложь</target>
        </trans-unit>
        <trans-unit id="afb80999f635ad0619301e31bb4cd6b353188af0" translate="yes" xml:space="preserve">
          <source>If True, compute the objective function at each step of the model. Default is False.</source>
          <target state="translated">Если Верно,вычислите объективную функцию на каждом этапе модели.По умолчанию-Ложь.</target>
        </trans-unit>
        <trans-unit id="9df36ef1b24eb49a93a9d932c395b3324554689c" translate="yes" xml:space="preserve">
          <source>If True, data are not centered before computation. Useful to work with data whose mean is significantly equal to zero but is not exactly zero. If False, data are centered before computation.</source>
          <target state="translated">Если Верно,то данные не центрируются перед вычислением.Полезно для работы с данными,среднее значение которых значительно равно нулю,но не совсем равно нулю.Если False,данные центрируются перед вычислением.</target>
        </trans-unit>
        <trans-unit id="cdd266c276f30f1ed8fec5e418bed1790d829f9f" translate="yes" xml:space="preserve">
          <source>If True, data are not centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False (default), data are centered before computation.</source>
          <target state="translated">Если Верно,то данные не центрируются перед вычислением.Полезно при работе с данными,среднее значение которых почти равно,но не совсем равно нулю.Если False (по умолчанию),данные центрируются перед вычислением.</target>
        </trans-unit>
        <trans-unit id="b4e1adfc1374b7a62eee31a2ac4be08eea958149" translate="yes" xml:space="preserve">
          <source>If True, data are not centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False, data are centered before computation.</source>
          <target state="translated">Если Верно,то данные не центрируются перед вычислением.Полезно при работе с данными,среднее значение которых почти равно,но не совсем равно нулю.Если False,данные центрируются перед вычислением.</target>
        </trans-unit>
        <trans-unit id="4b7584f328528f9b2a426f648be6c8534ecc99c4" translate="yes" xml:space="preserve">
          <source>If True, data will not be centered before computation. Useful to work with data whose mean is significantly equal to zero but is not exactly zero. If False, data will be centered before computation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="899541250010cf3e75fa34e54556cce0c0296945" translate="yes" xml:space="preserve">
          <source>If True, data will not be centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False (default), data will be centered before computation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d925d680717ba978e6037a9fa61e005a509ad73c" translate="yes" xml:space="preserve">
          <source>If True, data will not be centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False, data will be centered before computation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2902b07926590508dee697d1e97c541f35cd531" translate="yes" xml:space="preserve">
          <source>If True, ensure that the output of the random projection is a dense numpy array even if the input and random projection matrix are both sparse. In practice, if the number of components is small the number of zero components in the projected data will be very small and it will be more CPU and memory efficient to use a dense representation.</source>
          <target state="translated">Если True,убедитесь,что на выходе случайная проекция представляет собой плотный массив нумерации,даже если входная матрица и матрица случайной проекции являются разреженными.На практике,если количество компонент мало,то количество нулевых компонентов в проектируемых данных будет очень мало,и будет более эффективно использовать плотное представление с точки зрения процессора и памяти.</target>
        </trans-unit>
        <trans-unit id="41679ec27e720c4445a3d18e34d01eeadf44de13" translate="yes" xml:space="preserve">
          <source>If True, explicitely compute the weighted within-class covariance matrix when solver is &amp;lsquo;svd&amp;rsquo;. The matrix is always computed and stored for the other solvers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5a6d396b2b3b1ae647f1eed557078cef4ea31ec" translate="yes" xml:space="preserve">
          <source>If True, for binary &lt;code&gt;y_true&lt;/code&gt;, the score function is supposed to accept a 1D &lt;code&gt;y_pred&lt;/code&gt; (i.e., probability of the positive class or the decision function, shape &lt;code&gt;(n_samples,)&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92550063b64465fcb2c6a46cd5346c9970dc1bb3" translate="yes" xml:space="preserve">
          <source>If True, for binary &lt;code&gt;y_true&lt;/code&gt;, the score function is supposed to accept a 1D &lt;code&gt;y_pred&lt;/code&gt; (i.e., probability of the positive class, shape &lt;code&gt;(n_samples,)&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3946c2202800dbed0f15da39a81b563f2054e41" translate="yes" xml:space="preserve">
          <source>If True, individual trees are fit on random subsets of the training data sampled with replacement. If False, sampling without replacement is performed.</source>
          <target state="translated">Если Правда,то отдельные деревья подходят к случайным подмно выбранным подмножествам тренировочных данных,отобранных с заменой.Если Правда,то производится выборка без замены.</target>
        </trans-unit>
        <trans-unit id="47a8f3ebe1bf3e97122b0404e375e9c09f1cef3f" translate="yes" xml:space="preserve">
          <source>If True, input X is copied and stored by the model in the &lt;code&gt;X_fit_&lt;/code&gt; attribute. If no further changes will be done to X, setting &lt;code&gt;copy_X=False&lt;/code&gt; saves memory by storing a reference.</source>
          <target state="translated">Если True, вход X копируется и сохраняется моделью в &lt;code&gt;X_fit_&lt;/code&gt; . Если в X не будут вноситься дальнейшие изменения, установка &lt;code&gt;copy_X=False&lt;/code&gt; экономит память, сохраняя ссылку.</target>
        </trans-unit>
        <trans-unit id="396eb3a1b9a656b43a14e28fce4ff1f92f4bae42" translate="yes" xml:space="preserve">
          <source>If True, normalizes each document&amp;rsquo;s feature vector to unit norm using &lt;a href=&quot;sklearn.preprocessing.normalize#sklearn.preprocessing.normalize&quot;&gt;&lt;code&gt;sklearn.preprocessing.normalize&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f3a3bba5e0b6c545bdd5d5451a2769f0ab6a17d" translate="yes" xml:space="preserve">
          <source>If True, only the parameters that were set to non-default values will be printed when printing an estimator. For example, &lt;code&gt;print(SVC())&lt;/code&gt; while True will only print &amp;lsquo;SVC()&amp;rsquo; while the default behaviour would be to print &amp;lsquo;SVC(C=1.0, cache_size=200, &amp;hellip;)&amp;rsquo; with all the non-changed parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e2f5f725dbeca38c6f078963224eb5885ad4abb" translate="yes" xml:space="preserve">
          <source>If True, only the parameters that were set to non-default values will be printed when printing an estimator. For example, &lt;code&gt;print(SVC())&lt;/code&gt; while True will only print &amp;lsquo;SVC()&amp;rsquo;, but would print &amp;lsquo;SVC(C=1.0, cache_size=200, &amp;hellip;)&amp;rsquo; with all the non-changed parameters when False. Default is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10ab7d9c4ef9751f0861c3cfbcd363da08ee1196" translate="yes" xml:space="preserve">
          <source>If True, return a sparse CSR continency matrix. If &lt;code&gt;eps is not None&lt;/code&gt;, and &lt;code&gt;sparse is True&lt;/code&gt;, will throw ValueError.</source>
          <target state="translated">Если True, вернуть разреженную матрицу непрерывности CSR. Если &lt;code&gt;eps is not None&lt;/code&gt; , а &lt;code&gt;sparse is True&lt;/code&gt; , выдаст ValueError.</target>
        </trans-unit>
        <trans-unit id="bbadcb21277fb2fd7500e5e018984adc0515f847" translate="yes" xml:space="preserve">
          <source>If True, return output as dict</source>
          <target state="translated">Если Верно,возвращайте вывод как диктант</target>
        </trans-unit>
        <trans-unit id="5d0bfe964a0a56bae92b114342901e57452f609f" translate="yes" xml:space="preserve">
          <source>If True, return the average score across folds, weighted by the number of samples in each test set. In this case, the data is assumed to be identically distributed across the folds, and the loss minimized is the total loss per sample, and not the mean loss across the folds.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c0f661b8fac7f22363a5a1e55327c6967bb56d8" translate="yes" xml:space="preserve">
          <source>If True, return the average score across folds, weighted by the number of samples in each test set. In this case, the data is assumed to be identically distributed across the folds, and the loss minimized is the total loss per sample, and not the mean loss across the folds. If False, return the average score across folds. Default is True, but will change to False in version 0.21, to correspond to the standard definition of cross-validation.</source>
          <target state="translated">Если значение True (Верно),верните средний балл по сгибам,взвешенный по количеству образцов в каждом тестовом наборе.В этом случае предполагается,что данные распределены идентично по сгибам,а минимизированные потери-это суммарные потери по каждой выборке,а не средние потери по сгибам.В случае Фальсификации верните средний балл по сгибам.Значение по умолчанию равно True,но в версии 0.21 оно изменится на False,чтобы соответствовать стандартному определению перекрестной проверки.</target>
        </trans-unit>
        <trans-unit id="cd7031ac688b02e25258c5831c7d3ea164486db6" translate="yes" xml:space="preserve">
          <source>If True, return the distance between the clusters.</source>
          <target state="translated">Если Верно,верните расстояние между кластерами.</target>
        </trans-unit>
        <trans-unit id="a6e36ec8e19c4760ce9d4d884ef8627513b82b97" translate="yes" xml:space="preserve">
          <source>If True, returns &lt;code&gt;(data, target)&lt;/code&gt; instead of a &lt;code&gt;Bunch&lt;/code&gt; object. See below for more information about the &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt; object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48eeb388f7c432fd1b00c136703cc691939b77aa" translate="yes" xml:space="preserve">
          <source>If True, returns &lt;code&gt;(data, target)&lt;/code&gt; instead of a Bunch object. See below for more information about the &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt; object.</source>
          <target state="translated">Если True, возвращает &lt;code&gt;(data, target)&lt;/code&gt; вместо объекта Bunch. См. Ниже дополнительную информацию о &lt;code&gt;data&lt;/code&gt; и &lt;code&gt;target&lt;/code&gt; объекте.</target>
        </trans-unit>
        <trans-unit id="b8ef976b3bf0a8c5fe0d328bf69ca77595314915" translate="yes" xml:space="preserve">
          <source>If True, returns &lt;code&gt;(data, target)&lt;/code&gt; instead of a Bunch object. See below for more information about the &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt; objects.</source>
          <target state="translated">Если True, возвращает &lt;code&gt;(data, target)&lt;/code&gt; вместо объекта Bunch. См. Ниже дополнительную информацию о &lt;code&gt;data&lt;/code&gt; и &lt;code&gt;target&lt;/code&gt; объектах.</target>
        </trans-unit>
        <trans-unit id="d467c22a2bd71ab649cbad26364f06a31ce58ac1" translate="yes" xml:space="preserve">
          <source>If True, returns &lt;code&gt;(data.data, data.target)&lt;/code&gt; instead of a Bunch object.</source>
          <target state="translated">Если True, возвращает &lt;code&gt;(data.data, data.target)&lt;/code&gt; вместо объекта Bunch.</target>
        </trans-unit>
        <trans-unit id="248b6d0d481e47f352d5f3203242e6800072c658" translate="yes" xml:space="preserve">
          <source>If True, returns &lt;code&gt;(dataset.data, dataset.target)&lt;/code&gt; instead of a Bunch object. See below for more information about the &lt;code&gt;dataset.data&lt;/code&gt; and &lt;code&gt;dataset.target&lt;/code&gt; object.</source>
          <target state="translated">Если True, возвращает &lt;code&gt;(dataset.data, dataset.target)&lt;/code&gt; вместо объекта Bunch. См. Ниже дополнительную информацию об &lt;code&gt;dataset.data&lt;/code&gt; и &lt;code&gt;dataset.target&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c220af25fde2fda1e9985d78b63166a331905d63" translate="yes" xml:space="preserve">
          <source>If True, scale the data to interquartile range.</source>
          <target state="translated">Если Правда,масштабируйте данные до межквартильного диапазона.</target>
        </trans-unit>
        <trans-unit id="0f395f8257fe0bdfb8a823c88f3be9843583f8a6" translate="yes" xml:space="preserve">
          <source>If True, scale the data to unit variance (or equivalently, unit standard deviation).</source>
          <target state="translated">Если значение True,масштабируйте данные до единичной дисперсии (или эквивалентно единичному среднеквадратическому отклонению).</target>
        </trans-unit>
        <trans-unit id="df95a4486aac1e164d23cfb2a72a9a3a02411ccb" translate="yes" xml:space="preserve">
          <source>If True, the class covariance matrices are explicitely computed and stored in the &lt;code&gt;self.covariance_&lt;/code&gt; attribute.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a491ca8d8797fa01293c195b8787d725c30e073a" translate="yes" xml:space="preserve">
          <source>If True, the clusters are put on the vertices of a hypercube. If False, the clusters are put on the vertices of a random polytope.</source>
          <target state="translated">Если Верно,кластеры помещаются на вершины гиперкуба.Если False,кластеры помещаются на вершины случайного политопа.</target>
        </trans-unit>
        <trans-unit id="dc426ca785aa82bc3726faf833e38673875ff1ab" translate="yes" xml:space="preserve">
          <source>If True, the coefficients of the underlying linear model are returned.</source>
          <target state="translated">Если значение True,возвращаются коэффициенты лежащей в основе линейной модели.</target>
        </trans-unit>
        <trans-unit id="5724be8fac97575b0a1ba6783afc1c2fbe0fcac8" translate="yes" xml:space="preserve">
          <source>If True, the covariance of the joint predictive distribution at the query points is returned along with the mean</source>
          <target state="translated">Если Верно,то ковариация совместного предсказательного распределения в точках запроса возвращается вместе со средней величиной</target>
        </trans-unit>
        <trans-unit id="dbcfae5acdcda56eec77c1115971fac37cdadcbc" translate="yes" xml:space="preserve">
          <source>If True, the data is a pandas DataFrame including columns with appropriate dtypes (numeric). The target is a pandas DataFrame or Series depending on the number of target columns. If &lt;code&gt;return_X_y&lt;/code&gt; is True, then (&lt;code&gt;data&lt;/code&gt;, &lt;code&gt;target&lt;/code&gt;) will be pandas DataFrames or Series as described below.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e36608088c739a911a649d964516a72573ccb05" translate="yes" xml:space="preserve">
          <source>If True, the data is a pandas DataFrame including columns with appropriate dtypes (numeric, string or categorical). The target is a pandas DataFrame or Series depending on the number of target columns. If &lt;code&gt;return_X_y&lt;/code&gt; is True, then (&lt;code&gt;data&lt;/code&gt;, &lt;code&gt;target&lt;/code&gt;) will be pandas DataFrames or Series as described below.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b39e4230ac891358bd0af7c3eedd9e07bde06b43" translate="yes" xml:space="preserve">
          <source>If True, the data is a pandas DataFrame including columns with appropriate dtypes (numeric, string or categorical). The target is a pandas DataFrame or Series depending on the number of target_columns.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="132ae12ba4f9038c17051f7e128fd887c18e17fe" translate="yes" xml:space="preserve">
          <source>If True, the data is a pandas DataFrame including columns with appropriate dtypes (numeric, string or categorical). The target is a pandas DataFrame or Series depending on the number of target_columns. The Bunch will contain a &lt;code&gt;frame&lt;/code&gt; attribute with the target and the data. If &lt;code&gt;return_X_y&lt;/code&gt; is True, then &lt;code&gt;(data, target)&lt;/code&gt; will be pandas DataFrames or Series as describe above.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab63854b4cbc92de5ee21a5ee4815065271902d4" translate="yes" xml:space="preserve">
          <source>If True, the distances and indices will be sorted before being returned. If False, the results will not be sorted. If return_distance == False, setting sort_results = True will result in an error.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91db79e9bb9248c604fdbf115bede6d2bc2e0f43" translate="yes" xml:space="preserve">
          <source>If True, the distances and indices will be sorted before being returned. If False, the results will not be sorted. Only used with mode=&amp;rsquo;distance&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d28765388f526f443e8440713d9f120592d23759" translate="yes" xml:space="preserve">
          <source>If True, the gradient of the log-marginal likelihood with respect to the kernel hyperparameters at position theta is returned additionally. If True, theta must not be None.</source>
          <target state="translated">Если Верно,то дополнительно возвращается градиент лог-маржинальной вероятности относительно гиперпараметров ядра в позиции тета.Если Верно,тета не должна быть НЕТ.</target>
        </trans-unit>
        <trans-unit id="2ecaf6f4ca3e741011335b25b38b91313c972ea3" translate="yes" xml:space="preserve">
          <source>If True, the gradient of the log-marginal likelihood with respect to the kernel hyperparameters at position theta is returned additionally. Note that gradient computation is not supported for non-binary classification. If True, theta must not be None.</source>
          <target state="translated">Если Верно,то дополнительно возвращается градиент лог-маржинальной вероятности относительно гиперпараметров ядра в позиции тета.Обратите внимание,что вычисление градиента не поддерживается для небинарной классификации.Если Верно,тета не должна быть Нет.</target>
        </trans-unit>
        <trans-unit id="65ddb79c8d6a76beebeeb976d10455d7eb1fb46d" translate="yes" xml:space="preserve">
          <source>If True, the imputer mask will be a sparse matrix.</source>
          <target state="translated">Если True,то маска приёмника будет разреженной матрицей.</target>
        </trans-unit>
        <trans-unit id="eb2cac4cae6a6c8ef92320b8c850d0341c9b187b" translate="yes" xml:space="preserve">
          <source>If True, the kernel attribute is copied. If False, the kernel attribute is modified, but may result in a performance improvement.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a134a28236267fd097c12ab6f4f7b85d957aa9ca" translate="yes" xml:space="preserve">
          <source>If True, the method also returns &lt;code&gt;n_iter&lt;/code&gt;, the actual number of iteration performed by the solver.</source>
          <target state="translated">Если True, метод также возвращает &lt;code&gt;n_iter&lt;/code&gt; , фактическое количество итераций, выполненных решателем.</target>
        </trans-unit>
        <trans-unit id="af50e40087f45610f2fbcc323b88ccd93dcf9324" translate="yes" xml:space="preserve">
          <source>If True, the regressors X will be normalized before regression. This parameter is ignored when &lt;code&gt;fit_intercept&lt;/code&gt; is set to False. When the regressors are normalized, note that this makes the hyperparameters learned more robust and almost independent of the number of samples. The same property is not valid for standardized data. However, if you wish to standardize, please use &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; before calling &lt;code&gt;fit&lt;/code&gt; on an estimator with &lt;code&gt;normalize=False&lt;/code&gt;.</source>
          <target state="translated">Если True, регрессоры X будут нормализованы перед регрессией. Этот параметр игнорируется, если для &lt;code&gt;fit_intercept&lt;/code&gt; установлено значение False. Когда регрессоры нормализованы, обратите внимание, что это делает изученные гиперпараметры более надежными и почти независимыми от количества выборок. То же свойство не действует для стандартизованных данных. Однако, если вы хотите стандартизировать, используйте &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; перед вызовом &lt;code&gt;fit&lt;/code&gt; в оценщике с &lt;code&gt;normalize=False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="016e8fefc2c3108a2b7a4351de86dada7ecbd68e" translate="yes" xml:space="preserve">
          <source>If True, the regressors X will be normalized before regression. This parameter is ignored when &lt;code&gt;fit_intercept&lt;/code&gt; is set to False. When the regressors are normalized, note that this makes the hyperparameters learnt more robust and almost independent of the number of samples. The same property is not valid for standardized data. However, if you wish to standardize, please use &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; before calling &lt;code&gt;fit&lt;/code&gt; on an estimator with &lt;code&gt;normalize=False&lt;/code&gt;.</source>
          <target state="translated">Если True, регрессоры X будут нормализованы перед регрессией. Этот параметр игнорируется, если для &lt;code&gt;fit_intercept&lt;/code&gt; установлено значение False. Когда регрессоры нормализованы, обратите внимание, что это делает изученные гиперпараметры более надежными и почти независимыми от количества выборок. То же свойство не действует для стандартизованных данных. Однако, если вы хотите стандартизировать, используйте &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; перед вызовом &lt;code&gt;fit&lt;/code&gt; в оценщике с &lt;code&gt;normalize=False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c3fdb7e36f654834d666d698b8cb7219451a4481" translate="yes" xml:space="preserve">
          <source>If True, the return value will be an array of integers, rather than a boolean mask.</source>
          <target state="translated">Если значение True,то возвращаемое значение будет представлять собой массив целых чисел,а не булевую маску.</target>
        </trans-unit>
        <trans-unit id="d17d4bbcdf2df4ef33c01a7114516c2e4e90d7d8" translate="yes" xml:space="preserve">
          <source>If True, the standard-deviation of the predictive distribution at the query points is returned along with the mean.</source>
          <target state="translated">Если значение True,то возвращается стандартное отклонение предиктивного распределения в точках запроса вместе со средним значением.</target>
        </trans-unit>
        <trans-unit id="3f294130716f356d91654999eee9757bd2ba6c1c" translate="yes" xml:space="preserve">
          <source>If True, the support of robust location and covariance estimates is computed, and a covariance estimate is recomputed from it, without centering the data. Useful to work with data whose mean is significantly equal to zero but is not exactly zero. If False, the robust location and covariance are directly computed with the FastMCD algorithm without additional treatment.</source>
          <target state="translated">Если верно,то рассчитывается поддержка робастных оценок местоположения и ковариаций,и оценка ковариаций пересчитывается из нее без центрирования данных.Полезно работать с данными,среднее значение которых значительно равно нулю,но не совсем равно нулю.Если False,то робастная оценка местоположения и ковариаций вычисляется напрямую с помощью алгоритма FastMCD без дополнительной обработки.</target>
        </trans-unit>
        <trans-unit id="667a36b1a1b94aa0d760aa610f277fcd1918ae0a" translate="yes" xml:space="preserve">
          <source>If True, the support of the robust location and the covariance estimates is computed, and a covariance estimate is recomputed from it, without centering the data. Useful to work with data whose mean is significantly equal to zero but is not exactly zero. If False, the robust location and covariance are directly computed with the FastMCD algorithm without additional treatment.</source>
          <target state="translated">Если верно,то рассчитывается поддержка робастного местоположения и оценка ковариаций,а оценка ковариаций пересчитывается из нее без центрирования данных.Полезно работать с данными,среднее значение которых значительно равно нулю,но не совсем равно нулю.Если False,то робастное местоположение и ковариативность вычисляются непосредственно с помощью алгоритма FastMCD без дополнительной обработки.</target>
        </trans-unit>
        <trans-unit id="77487b230b7ba030d96d8037319b1c202fdf89dc" translate="yes" xml:space="preserve">
          <source>If True, the time elapsed while fitting each step will be printed as it is completed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c5c205f98c6f7e0686c6b1dad61d3840345a50a" translate="yes" xml:space="preserve">
          <source>If True, the time elapsed while fitting each transformer will be printed as it is completed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af3eeb64eec0b2d56ce55e625f484e757480a63a" translate="yes" xml:space="preserve">
          <source>If True, the time elapsed while fitting will be printed as it is completed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28346b69fb6f1a64d688b2ef42aabb524b6563d8" translate="yes" xml:space="preserve">
          <source>If True, then X will be converted to a 2-dimensional NumPy array or sparse matrix. If the conversion is not possible an exception is raised.</source>
          <target state="translated">Если True,то X будет преобразован в 2-х мерный массив NumPy или разреженную матрицу.Если преобразование невозможно,то поднимается исключение.</target>
        </trans-unit>
        <trans-unit id="5c0fef9c1e6748fc4d3cb84e62459147a039a4fd" translate="yes" xml:space="preserve">
          <source>If True, then all components with zero eigenvalues are removed, so that the number of components in the output may be &amp;lt; n_components (and sometimes even zero due to numerical instability). When n_components is None, this parameter is ignored and components with zero eigenvalues are removed regardless.</source>
          <target state="translated">Если True, то все компоненты с нулевыми собственными значениями удаляются, так что количество компонентов на выходе может быть &amp;lt;n_components (а иногда даже нулевым из-за числовой нестабильности). Когда n_components равно None, этот параметр игнорируется, и компоненты с нулевыми собственными значениями удаляются независимо.</target>
        </trans-unit>
        <trans-unit id="42874c4e7adb064c98a0fb44835161462f985220" translate="yes" xml:space="preserve">
          <source>If True, then compute normalized Laplacian.</source>
          <target state="translated">Если Верно,то вычислите нормализованный лаплацкий.</target>
        </trans-unit>
        <trans-unit id="ba532aca0424d37b34ea4248f58728a030b07d2d" translate="yes" xml:space="preserve">
          <source>If True, then return the centers of each cluster</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7818bd11ce52f2496690f2a19701e1fdc3bace9d" translate="yes" xml:space="preserve">
          <source>If True, transpose the downloaded data array.</source>
          <target state="translated">Если True,транспонируйте массив загруженных данных.</target>
        </trans-unit>
        <trans-unit id="9b28aadc7e361758f4f56436eeab711f856e9105" translate="yes" xml:space="preserve">
          <source>If True, use a breadth-first search. If False (default) use a depth-first search. Breadth-first is generally faster for compact kernels and/or high tolerances.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06e972e2019f64a904722b2934f5b7cf1e54e236" translate="yes" xml:space="preserve">
          <source>If True, use a dualtree algorithm. Otherwise, use a single-tree algorithm. Dual tree algorithms can have better scaling for large N.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09f8cdcb36703e0413a45867eb062d48bc42e4a4" translate="yes" xml:space="preserve">
          <source>If True, validation for finiteness will be skipped, saving time, but leading to potential crashes. If False, validation for finiteness will be performed, avoiding error. Global default: False.</source>
          <target state="translated">Если параметр True,проверка конечности будет пропущена,что сэкономит время,но приведет к потенциальным авариям.Если False,проверка конечности будет выполнена,что позволит избежать ошибки.Глобальная настройка по умолчанию:Ложно.</target>
        </trans-unit>
        <trans-unit id="f770d204acb3934762188e63b6bd0977cfe619aa" translate="yes" xml:space="preserve">
          <source>If True, will return the parameters for this estimator and contained subobjects that are estimators.</source>
          <target state="translated">Если значение True,будут возвращены параметры для данного оценщика и содержащихся в нем подобъектов,являющихся оценщиками.</target>
        </trans-unit>
        <trans-unit id="edc518974aa9f8ea115d0f36469bc2b1e2cd15a2" translate="yes" xml:space="preserve">
          <source>If True, will return the query_id array for each file.</source>
          <target state="translated">Если значение True,то для каждого файла будет возвращен массив query_id.</target>
        </trans-unit>
        <trans-unit id="80fdba1026cc980884a84dfa72ad1747c034afc6" translate="yes" xml:space="preserve">
          <source>If X and y are not C-ordered and contiguous arrays of np.float64 and X is not a scipy.sparse.csr_matrix, X and/or y may be copied.</source>
          <target state="translated">Если X и y не являются C-упорядоченными и смежными массивами np.float64 и X не является scipy.sparse.csr_matrix,X и/или y могут быть скопированы.</target>
        </trans-unit>
        <trans-unit id="a601440183ce5a872479c357e441563196aab652" translate="yes" xml:space="preserve">
          <source>If X is a dense array, then the other methods will not support sparse matrices as input.</source>
          <target state="translated">Если X-плотный массив,то другие методы не будут поддерживать разреженные матрицы в качестве входных.</target>
        </trans-unit>
        <trans-unit id="efab9063b47a2afb85758f067069188b21b34f3e" translate="yes" xml:space="preserve">
          <source>If X is encoded as a CSR matrix.</source>
          <target state="translated">Если X кодируется как CSR-матрица.</target>
        </trans-unit>
        <trans-unit id="f4e2537cdb42d2bfe76e858b065192a8758650ef" translate="yes" xml:space="preserve">
          <source>If X is encoded as a CSR matrix;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da96e9fabf18fc39905756390120e4a7a1e09f97" translate="yes" xml:space="preserve">
          <source>If X is not a C-ordered contiguous array it is copied.</source>
          <target state="translated">Если X не является непрерывным массивом в C-образном порядке,он копируется.</target>
        </trans-unit>
        <trans-unit id="9cc8f34afbd30e04cc65d91f1b233abc1c382996" translate="yes" xml:space="preserve">
          <source>If X is not an array of floating values;</source>
          <target state="translated">Если X не является массивом плавающих значений;</target>
        </trans-unit>
        <trans-unit id="e7ca7ce1d419c3d60265041304210343f2e8b91d" translate="yes" xml:space="preserve">
          <source>If X is our multivariate data, then the problem that we are trying to solve is to rewrite it on a different observational basis: we want to learn loadings L and a set of components C such that &lt;em&gt;X = L C&lt;/em&gt;. Different criteria exist to choose the components</source>
          <target state="translated">Если X - наши многомерные данные, то проблема, которую мы пытаемся решить, состоит в том, чтобы переписать их на другой основе наблюдений: мы хотим узнать нагрузки L и набор компонентов C, таких что &lt;em&gt;X = LC&lt;/em&gt; . Существуют разные критерии выбора компонентов</target>
        </trans-unit>
        <trans-unit id="4691b6eeb6f44a63af5f24ac30dc066ab023aa61" translate="yes" xml:space="preserve">
          <source>If X is sparse and &lt;code&gt;missing_values=0&lt;/code&gt;;</source>
          <target state="translated">Если X является разреженным и &lt;code&gt;missing_values=0&lt;/code&gt; ;</target>
        </trans-unit>
        <trans-unit id="5bf131136f9283115170d3f032466f07678834a5" translate="yes" xml:space="preserve">
          <source>If Y is given (default is None), then the returned matrix is the pairwise distance between the arrays from both X and Y.</source>
          <target state="translated">Если задано Y (по умолчанию None),то возвращаемая матрица-это парное расстояние между массивами как от X,так и от Y.</target>
        </trans-unit>
        <trans-unit id="a6e7fe3e345be28d5e67984fa49ad01aeaa444dd" translate="yes" xml:space="preserve">
          <source>If Y is given (default is None), then the returned matrix is the pairwise kernel between the arrays from both X and Y.</source>
          <target state="translated">Если задано Y (по умолчанию None),то возвращаемой матрицей будет парное ядро между массивами как X,так и Y.</target>
        </trans-unit>
        <trans-unit id="15e0fd61e3b85d8ebad2fc2135f6d5822723ce41" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}\) is the estimated target output, \(y\) the corresponding (correct) target output, and \(Var\) is &lt;a href=&quot;https://en.wikipedia.org/wiki/Variance&quot;&gt;Variance&lt;/a&gt;, the square of the standard deviation, then the explained variance is estimated as follow:</source>
          <target state="translated">Если \ (\ hat {y} \) - это предполагаемый целевой результат, \ (y \) - соответствующий (правильный) целевой результат, а \ (Var \) - это &lt;a href=&quot;https://en.wikipedia.org/wiki/Variance&quot;&gt;дисперсия&lt;/a&gt; , квадрат стандартного отклонения, то объясненная дисперсия оценивается следующим образом:</target>
        </trans-unit>
        <trans-unit id="1d8ad99bdd9bde4f8f4c5eb30616979db9d7983c" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value for total \(n\) samples, the estimated R&amp;sup2; is defined as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8fb389b8a60a2b57fc22c9161412c484a73dd18" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value, then the 0-1 loss \(L_{0-1}\) is defined as:</source>
          <target state="translated">Если \(\hat{y}_i\)-прогнозируемое значение \(i\)-той выборки и \(y_i\)-соответствующее истинное значение,то определяется убыток 0-1 \(L_{0-1}\):</target>
        </trans-unit>
        <trans-unit id="01fda7f04ce93ad5d6b5843c80c53ee91e04866d" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value, then the fraction of correct predictions over \(n_\text{samples}\) is defined as</source>
          <target state="translated">Если \(\hat{y}_i\)-предсказанное значение \(i\)-той выборки и \(y_i\)-соответствующее истинное значение,то доля правильных предсказаний над \(n_\text{samples}\)определяется как</target>
        </trans-unit>
        <trans-unit id="af46aeec0a0c654990b43c84ec26ca8a3817bbd3" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value, then the median absolute error (MedAE) estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="translated">Если \(\hat{y}_i\)-прогнозируемое значение \(i\)-той выборки и \(y_i\)-соответствующее истинное значение,то медианная абсолютная погрешность (MedAE),оцененная над \(n_{\text{samples}}\),определяется как</target>
        </trans-unit>
        <trans-unit id="27ab05c62dcfc0b1ca98228a2c106c2bd25d72f6" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value, then the score R&amp;sup2; estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="translated">Если \ (\ hat {y} _i \) - это прогнозируемое значение для \ (i \) - й выборки, а \ (y_i \) - соответствующее истинное значение, тогда оценка R&amp;sup2; оценивается за \ (n _ {\ text { образцы}} \) определяется как</target>
        </trans-unit>
        <trans-unit id="2057e5fd21ea6e3999b964ff2858a1023496793a" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the max error is defined as</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b2139578cc75e1715d428f9c389fc66abbdc391" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the mean Tweedie deviance error (D) for power \(p\), estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9be139031431f33624d9549cf24272bbec27cad" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the mean absolute error (MAE) estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="translated">Если \(\hat{y}_i\)-прогнозируемое значение \(i\)-ой выборки,а \(y_i\)-соответствующее истинное значение,то средняя абсолютная ошибка (MAE),вычисленная по \(n_{\text{samples}}\),определяется как</target>
        </trans-unit>
        <trans-unit id="b7836e2114e345225a74c22cbe0d3b5d52c8f253" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the mean squared error (MSE) estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="translated">Если \(\hat{y}_i\)-прогнозируемое значение \(i\)-ой выборки,а \(y_i\)-соответствующее истинное значение,то средняя квадратная ошибка (MSE),вычисленная над \(n_{\text{samples}}\),определяется как</target>
        </trans-unit>
        <trans-unit id="1cf47fc0a0aaaffd1c0a818b8704218b8ae722c1" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the mean squared logarithmic error (MSLE) estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="translated">Если \(\hat{y}_i\)-прогнозируемое значение \(i\)-ой выборки,а \(y_i\)-соответствующее истинное значение,то средняя квадратная логарифмическая ошибка (MSLE),оцененная над \(n_{\text{samples}}\),определяется как</target>
        </trans-unit>
        <trans-unit id="f295fa8851d145ac326bc63b92809e2fbf3d1f72" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_j\) is the predicted value for the \(j\)-th label of a given sample, \(y_j\) is the corresponding true value, and \(n_\text{labels}\) is the number of classes or labels, then the Hamming loss \(L_{Hamming}\) between two samples is defined as:</source>
          <target state="translated">Если \(\hat{y}_j\)-прогнозируемое значение для \(j\)-метки данного образца,\(y_j\)-соответствующее истинное значение,а \(n_\text{labels}\)-число классов или этикеток,тогда между двумя образцами определяется потеря Хэмминга \(L_{Hamming}\):</target>
        </trans-unit>
        <trans-unit id="7fa4bf510f83c73a55e8dec038abaacf960351ca" translate="yes" xml:space="preserve">
          <source>If \(c_0 = 0\) the kernel is said to be homogeneous.</source>
          <target state="translated">Если \(c_0=0\)ядро считается однородным.</target>
        </trans-unit>
        <trans-unit id="c7d07701826b4f4c8efa455b46a49990993930f2" translate="yes" xml:space="preserve">
          <source>If \(h_i\) is given, the above equation automatically implies the following probabilistic interpretation:</source>
          <target state="translated">Если приводится \(h_i\),то приведенное выше уравнение автоматически подразумевает следующую вероятностную интерпретацию:</target>
        </trans-unit>
        <trans-unit id="9d9af8bc9b90a6fbf0d539b126efbd694bdaddf6" translate="yes" xml:space="preserve">
          <source>If \(y_i\) is the true value of the \(i\)-th sample, and \(w_i\) is the corresponding sample weight, then we adjust the sample weight to:</source>
          <target state="translated">Если \(y_i\)-истинное значение \(i\)-ой выборки,а \(w_i\)-соответствующий вес выборки,то мы корректируем вес выборки в соответствии с ним:</target>
        </trans-unit>
        <trans-unit id="4c76ddad0ef7a743f202685a0861880cbc2062e2" translate="yes" xml:space="preserve">
          <source>If \(y_w\) is the predicted decision for true label and \(y_t\) is the maximum of the predicted decisions for all other labels, where predicted decisions are output by decision function, then multiclass hinge loss is defined by:</source>
          <target state="translated">Если \(y_w\)-это предсказанное решение для истинной метки,а \(y_t\)-это максимум предсказанных решений для всех остальных меток,где предсказанные решения выводятся функцией принятия решения,то определяется потеря многоклассовых шарниров:</target>
        </trans-unit>
        <trans-unit id="b8371056060d53aef38082b274a12c6e92dd981b" translate="yes" xml:space="preserve">
          <source>If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by accept_sparse, accept_large_sparse will cause it to be accepted only if its indices are stored with a 32-bit dtype.</source>
          <target state="translated">Если CSR,CSC,COO или BSR разреженная матрица поставляется и принимается accept_sparse,accept_large_sparse приведет к тому,что она будет принята только в том случае,если ее индексы хранятся с 32-битным dtype.</target>
        </trans-unit>
        <trans-unit id="ca2f554a4272574081b19f205bd8db66223aa9f8" translate="yes" xml:space="preserve">
          <source>If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by accept_sparse, accept_large_sparse=False will cause it to be accepted only if its indices are stored with a 32-bit dtype.</source>
          <target state="translated">Если CSR,CSC,COO или BSR разреженная матрица поставляется и принимается accept_sparse,accept_large_sparse=False приведет к тому,что она будет принята только в том случае,если ее индексы хранятся с 32-битным dtype.</target>
        </trans-unit>
        <trans-unit id="b0090a224443cfea422c2167734e98ec705e71a5" translate="yes" xml:space="preserve">
          <source>If a callable is passed it is used to extract the sequence of features out of the raw, unprocessed input.</source>
          <target state="translated">Если передается вызываемая функция,то она используется для извлечения последовательности функций из необработанного,необработанного входа.</target>
        </trans-unit>
        <trans-unit id="dcd8eacb988e0fa27afa1a7692943530b07747f6" translate="yes" xml:space="preserve">
          <source>If a callable is passed, it should take arguments X, k and and a random state and return an initialization.</source>
          <target state="translated">Если передается вызываемое состояние,то оно должно принять аргументы X,k и случайное состояние и вернуть инициализацию.</target>
        </trans-unit>
        <trans-unit id="cf28b181c12fdc4001f26b46f656bc18426882b0" translate="yes" xml:space="preserve">
          <source>If a callable is passed, it should take arguments X, n_clusters and a random state and return an initialization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15b5ddf5d35e7b6d7436896e31247316b726ba30" translate="yes" xml:space="preserve">
          <source>If a float, that value is added to all values in the contingency matrix. This helps to stop NaN propagation. If &lt;code&gt;None&lt;/code&gt;, nothing is adjusted.</source>
          <target state="translated">Если число с плавающей запятой, это значение добавляется ко всем значениям в матрице непредвиденных обстоятельств. Это помогает остановить распространение NaN. Если &lt;code&gt;None&lt;/code&gt; , ничего не настраивается.</target>
        </trans-unit>
        <trans-unit id="aec58020de2b924f9656034ee47c95a7ace302db" translate="yes" xml:space="preserve">
          <source>If a list is passed it&amp;rsquo;s expected to be one of n_targets such arrays. The varying values of the coefficients along the path. It is not present if the &lt;code&gt;fit_path&lt;/code&gt; parameter is &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">Если список передан, он должен быть одним из таких массивов n_targets. Различные значения коэффициентов по пути. Его нет, если параметр &lt;code&gt;fit_path&lt;/code&gt; равен &lt;code&gt;False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8e3b6cd9422926a607fefd39c3e9bd3020c06d14" translate="yes" xml:space="preserve">
          <source>If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens. Only applies if &lt;code&gt;analyzer == 'word'&lt;/code&gt;.</source>
          <target state="translated">Если список, предполагается, что этот список содержит стоп-слова, все из которых будут удалены из результирующих токенов. Применяется только если &lt;code&gt;analyzer == 'word'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3a891d1ec4d966c2171dc7ddf73d952ce675676b" translate="yes" xml:space="preserve">
          <source>If a single axis is passed in, it is treated as a bounding axes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58d1b02436a7aa9160e580f582400827e1ad046d" translate="yes" xml:space="preserve">
          <source>If a string, it is passed to _check_stop_list and the appropriate stop list is returned. &amp;lsquo;english&amp;rsquo; is currently the only supported string value. There are several known issues with &amp;lsquo;english&amp;rsquo; and you should consider an alternative (see &lt;a href=&quot;../feature_extraction#stop-words&quot;&gt;Using stop words&lt;/a&gt;).</source>
          <target state="translated">Если строка, она передается в _check_stop_list, и возвращается соответствующий стоп-список. &quot;english&quot; в настоящее время является единственным поддерживаемым строковым значением. Есть несколько известных проблем с &amp;laquo;английским&amp;raquo;, и вам следует рассмотреть альтернативу (см. &lt;a href=&quot;../feature_extraction#stop-words&quot;&gt;Использование стоп-слов&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="564b43bc82acf22a1de3b85bb28ac591ff97b4bf" translate="yes" xml:space="preserve">
          <source>If a string, this may be one of &amp;lsquo;nearest_neighbors&amp;rsquo;, &amp;lsquo;precomputed&amp;rsquo;, &amp;lsquo;rbf&amp;rsquo; or one of the kernels supported by &lt;code&gt;sklearn.metrics.pairwise_kernels&lt;/code&gt;.</source>
          <target state="translated">Если строка, это может быть одно из &amp;laquo;ближайших_соседей&amp;raquo;, &amp;laquo;предварительно вычисленных&amp;raquo;, &amp;laquo;rbf&amp;raquo; или одно из ядер, поддерживаемых &lt;code&gt;sklearn.metrics.pairwise_kernels&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="675cbfc234c52633edd36cba3388cd72c1b8e2d3" translate="yes" xml:space="preserve">
          <source>If a target is a classification outcome taking on values 0,1,&amp;hellip;,K-1, for node \(m\), representing a region \(R_m\) with \(N_m\) observations, let</source>
          <target state="translated">Если целью является результат классификации, принимающий значения 0,1,&amp;hellip;, K-1, для узла \ (m \), представляющего регион \ (R_m \) с наблюдениями \ (N_m \), пусть</target>
        </trans-unit>
        <trans-unit id="b39b95bbd18e310b00daaab2152e27da5d834f6a" translate="yes" xml:space="preserve">
          <source>If add_indicator=True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="373500a68bbbd934744d157d24ba37240f790a20" translate="yes" xml:space="preserve">
          <source>If affinity is &amp;ldquo;precomputed&amp;rdquo; X : array-like, shape (n_samples, n_samples), Interpret X as precomputed adjacency graph computed from samples.</source>
          <target state="translated">Если сродство &amp;laquo;предварительно вычислено&amp;raquo;, X: подобный массиву, форма (n_samples, n_samples), Интерпретировать X как предварительно вычисленный граф смежности, вычисленный из образцов.</target>
        </trans-unit>
        <trans-unit id="86d4d97c781f9d1a441e0d9197ea013d3820b489" translate="yes" xml:space="preserve">
          <source>If affinity is &amp;ldquo;precomputed&amp;rdquo; X : {array-like, sparse matrix}, shape (n_samples, n_samples), Interpret X as precomputed adjacency graph computed from samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c306493486d7abaed871db69a1b0f3a0d3e230f4" translate="yes" xml:space="preserve">
          <source>If affinity is the adjacency matrix of a graph, this method can be used to find normalized graph cuts.</source>
          <target state="translated">Если сродство является матрицей примыкания графика,то этот метод может быть использован для поиска нормализованных разрезов графика.</target>
        </trans-unit>
        <trans-unit id="fef3ba1186af33eef8e244a6a4bb530d43ffdf84" translate="yes" xml:space="preserve">
          <source>If all examples are from the same class, it uses a one-class SVM.</source>
          <target state="translated">Если все примеры относятся к одному классу,то он использует одноклассный SVM.</target>
        </trans-unit>
        <trans-unit id="b53805960d76925767243aca9c19243fc1b08d06" translate="yes" xml:space="preserve">
          <source>If all parameters are presented as a list, sampling without replacement is performed. If at least one parameter is given as a distribution, sampling with replacement is used. It is highly recommended to use continuous distributions for continuous parameters.</source>
          <target state="translated">Если все параметры представлены в виде списка,производится выборка без замены.Если в качестве распределения указан хотя бы один параметр,используется выборка с заменой.Настоятельно рекомендуется использовать непрерывные распределения для непрерывных параметров.</target>
        </trans-unit>
        <trans-unit id="44ee4928f6faf842a93c2259e4d1b6db16c4073a" translate="yes" xml:space="preserve">
          <source>If all the coordinates are missing or if there are no common present coordinates then NaN is returned for that pair.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f219d1953670922fbbfe88159427df7222c9397" translate="yes" xml:space="preserve">
          <source>If an algorithm, such as a linear support vector machine or PCA, relies only on the scalar product of data points \(x_i\), one may use the value of \(k(x_i, x_j)\), which corresponds to applying the algorithm to the mapped data points \(\phi(x_i)\). The advantage of using \(k\) is that the mapping \(\phi\) never has to be calculated explicitly, allowing for arbitrary large features (even infinite).</source>
          <target state="translated">Если алгоритм,например,векторная машина линейной поддержки или PCA,опирается только на скалярное произведение точек данных \(x_i\),то можно использовать значение \(k(x_i,x_j)\),что соответствует применению алгоритма к отображенным точкам данных \(\phi(x_i)\).Преимущество использования \(k\)заключается в том,что отображение \(\phi\)никогда не нужно вычислять явно,что позволяет использовать произвольные большие признаки (даже бесконечные).</target>
        </trans-unit>
        <trans-unit id="22b4c02685073d2c5c3e900f3a57456658da8b22" translate="yes" xml:space="preserve">
          <source>If an array-like of axes are passed in, the partial dependence</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9fea95f95d0577b3d2b8dde1c99a4f5f11240b1d" translate="yes" xml:space="preserve">
          <source>If an exception is triggered, use &lt;code&gt;%debug&lt;/code&gt; to fire-up a post mortem ipdb session.</source>
          <target state="translated">Если инициировано исключение, используйте &lt;code&gt;%debug&lt;/code&gt; для запуска посмертного сеанса ipdb.</target>
        </trans-unit>
        <trans-unit id="5c4a826b768bf0ea44b0de0cf9a279c59410da1d" translate="yes" xml:space="preserve">
          <source>If an integer is given, it fixes the number of points on the grids of alpha to be used. If a list is given, it gives the grid to be used. See the notes in the class docstring for more details.</source>
          <target state="translated">Если задано целое число,то оно фиксирует количество используемых точек на сетках альфа.Если задан список,то фиксируется используемая сетка.Подробнее см.примечания в строке сцепления классов.</target>
        </trans-unit>
        <trans-unit id="9e0d496b83e5a4c02138b5662acc0d0357377648" translate="yes" xml:space="preserve">
          <source>If an integer is given, it fixes the number of points on the grids of alpha to be used. If a list is given, it gives the grid to be used. See the notes in the class docstring for more details. Range is (0, inf] when floats given.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f54c86c80b29ba93fdb4405121f2a742f42412e" translate="yes" xml:space="preserve">
          <source>If an ndarray is passed, it should be of shape (n_clusters, n_features) and gives the initial centers.</source>
          <target state="translated">Если передается андаррей,то он должен быть в форме (n_clusters,n_features)и давать начальные центры.</target>
        </trans-unit>
        <trans-unit id="ce1d1dc15735f50591b21078e51cada592338767" translate="yes" xml:space="preserve">
          <source>If arpack :</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57a89ce6b3eb175b37e97fdc8660396b5ef203e5" translate="yes" xml:space="preserve">
          <source>If auto :</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bf20b6ab9e24e0313be1f29e5bd87350c62fc72" translate="yes" xml:space="preserve">
          <source>If bandwidth is not given, it is determined using a heuristic based on the median of all pairwise distances. This will take quadratic time in the number of samples. The sklearn.cluster.estimate_bandwidth function can be used to do this more efficiently.</source>
          <target state="translated">Если полоса пропускания не задана,она определяется с помощью эвристики,основанной на медиане всех парных расстояний.Это займет квадратичное время в количестве отсчетов.Для этого можно использовать функцию sklearn.cluster.estimate_bandwidth.</target>
        </trans-unit>
        <trans-unit id="307d133eac653119e68c3f800803dcc4776573b9" translate="yes" xml:space="preserve">
          <source>If bool, then determines whether to consider all features discrete or continuous. If array, then it should be either a boolean mask with shape (n_features,) or array with indices of discrete features. If &amp;lsquo;auto&amp;rsquo;, it is assigned to False for dense &lt;code&gt;X&lt;/code&gt; and to True for sparse &lt;code&gt;X&lt;/code&gt;.</source>
          <target state="translated">Если bool, то определяет, следует ли рассматривать все функции дискретными или непрерывными. Если массив, то это должна быть либо логическая маска с формой (n_features,), либо массив с индексами дискретных функций. Если &amp;laquo;авто&amp;raquo;, то присваивается значение False для плотного &lt;code&gt;X&lt;/code&gt; и верно для разреженной &lt;code&gt;X&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="14d26c2cb6ccf4f84a440b5eee94360749d30490" translate="yes" xml:space="preserve">
          <source>If boolean, whether or not to fit the isotonic regression with y increasing or decreasing.</source>
          <target state="translated">Если булева,то подгонять или не подгонять изотоническую регрессию с увеличением или уменьшением y.</target>
        </trans-unit>
        <trans-unit id="34ddc69f78e9ae21f32c4048eb992eb5ea37253a" translate="yes" xml:space="preserve">
          <source>If bootstrap is True, the number of samples to draw from X to train each base estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7380002883f78b7443a4cf144369e2cdf9c7dd5" translate="yes" xml:space="preserve">
          <source>If bytes or files are given to analyze, this encoding is used to decode.</source>
          <target state="translated">Если для анализа выдаются байты или файлы,то эта кодировка используется для расшифровки.</target>
        </trans-unit>
        <trans-unit id="b1cd46fc8b5b18d3d8ec258c92a5832fe49ecb69" translate="yes" xml:space="preserve">
          <source>If classes members are completely split across different clusters, the assignment is totally in-complete, hence the AMI is null:</source>
          <target state="translated">Если члены классов полностью разделены по разным кластерам,то задание является полностью неполным,следовательно,AMI является нулевым:</target>
        </trans-unit>
        <trans-unit id="e6f2dbc2c288fdff952bc5d6d0612fad044f50c2" translate="yes" xml:space="preserve">
          <source>If classes members are completely split across different clusters, the assignment is totally in-complete, hence the NMI is null:</source>
          <target state="translated">Если члены классов полностью разделены по разным кластерам,то задание полностью не выполнено,следовательно,NMI равен нулю:</target>
        </trans-unit>
        <trans-unit id="60b93fba5d2befe30dad173ef2989a32caf2707d" translate="yes" xml:space="preserve">
          <source>If classes members are completely split across different clusters, the assignment is totally incomplete, hence the ARI is very low:</source>
          <target state="translated">Если члены классов полностью разделены по разным кластерам,то задание является полностью неполным,поэтому ARI очень низкий:</target>
        </trans-unit>
        <trans-unit id="e02bb35b2a969fdf2ff25b865a0b3ba938fb92a9" translate="yes" xml:space="preserve">
          <source>If classes members are completely split across different clusters, the assignment is totally incomplete, hence the V-Measure is null:</source>
          <target state="translated">Если члены классов полностью разделены по разным кластерам,то задание является полностью неполным,следовательно,V-оценка равна нулю:</target>
        </trans-unit>
        <trans-unit id="d0974a75f074fb11fd0a08f495fdb803227dd0c6" translate="yes" xml:space="preserve">
          <source>If classes members are completely split across different clusters, the assignment is totally random, hence the FMI is null:</source>
          <target state="translated">Если члены классов полностью разделены по разным кластерам,назначение является полностью случайным,следовательно,FMI является нулевым:</target>
        </trans-unit>
        <trans-unit id="3a4c44f6cadbe5141305e79bc3f8068062652c4d" translate="yes" xml:space="preserve">
          <source>If classes members are split across different clusters, the assignment cannot be complete:</source>
          <target state="translated">Если члены классов разделены по разным кластерам,задание не может быть полным:</target>
        </trans-unit>
        <trans-unit id="a2787535a9b0772f98dac284faca0d2184e54d74" translate="yes" xml:space="preserve">
          <source>If coefficients vary significantly when changing the input dataset their robustness is not guaranteed, and they should probably be interpreted with caution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52c8ac55b5c80763168c6804bd2b4b595db63ef9" translate="yes" xml:space="preserve">
          <source>If computed_score is True, value of the log marginal likelihood (to be maximized) at each iteration of the optimization. The array starts with the value of the log marginal likelihood obtained for the initial values of alpha and lambda and ends with the value obtained for the estimated alpha and lambda.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="baf96abe9df5cd386826eafcd47454c9dcc36819" translate="yes" xml:space="preserve">
          <source>If copy is False, the affinity matrix is modified inplace by the algorithm, for memory efficiency</source>
          <target state="translated">Если копия ошибочна,то матрица сродства модифицируется алгоритмом на месте,для повышения эффективности использования памяти.</target>
        </trans-unit>
        <trans-unit id="0070f2c19699b732c372ba0e363293b507463ed1" translate="yes" xml:space="preserve">
          <source>If decision_function_shape=&amp;rsquo;ovo&amp;rsquo;, the function values are proportional to the distance of the samples X to the separating hyperplane. If the exact distances are required, divide the function values by the norm of the weight vector (&lt;code&gt;coef_&lt;/code&gt;). See also &lt;a href=&quot;https://stats.stackexchange.com/questions/14876/interpreting-distance-from-hyperplane-in-svm&quot;&gt;this question&lt;/a&gt; for further details. If decision_function_shape=&amp;rsquo;ovr&amp;rsquo;, the decision function is a monotonic transformation of ovo decision function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="671e4e16873255449d2ba54f06975c272f73c34d" translate="yes" xml:space="preserve">
          <source>If density = &amp;lsquo;auto&amp;rsquo;, the value is set to the minimum density as recommended by Ping Li et al.: 1 / sqrt(n_features).</source>
          <target state="translated">Если density = 'auto', устанавливается минимальная плотность, рекомендованная Пинг Ли и др .: 1 / sqrt (n_features).</target>
        </trans-unit>
        <trans-unit id="391517cb3cfce3ac9c6c32b7ceac049807282afc" translate="yes" xml:space="preserve">
          <source>If documents are pre-tokenized by an external package, then store them in files (or strings) with the tokens separated by whitespace and pass &lt;code&gt;analyzer=str.split&lt;/code&gt;</source>
          <target state="translated">Если документы предварительно токенизируются внешним пакетом, сохраните их в файлах (или строках) с токенами, разделенными &lt;code&gt;analyzer=str.split&lt;/code&gt; и передайте анализатор = str.split</target>
        </trans-unit>
        <trans-unit id="80416b24b5f24b22b80d50d90aa942e77a2dadfc" translate="yes" xml:space="preserve">
          <source>If each row and each column belongs to exactly one bicluster, then rearranging the rows and columns of the data matrix reveals the biclusters on the diagonal. Here is an example of this structure where biclusters have higher average values than the other rows and columns:</source>
          <target state="translated">Если каждая строка и каждый столбец принадлежат ровно одному билюстру,то при перестановке строк и столбцов матрицы данных по диагонали выявляются билюстры.Вот пример такой структуры,где билюстры имеют более высокие средние значения,чем другие строки и столбцы:</target>
        </trans-unit>
        <trans-unit id="78ba0badd104b3ed95bd2061747613a1b6f84ce9" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of groups to include in the test split (rounded up). If int, represents the absolute number of test groups. If None, the value is set to the complement of the train size. The default will change in version 0.21. It will remain 0.2 only if &lt;code&gt;train_size&lt;/code&gt; is unspecified, otherwise it will complement the specified &lt;code&gt;train_size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1db9c10662b6d49b6b84ca8b7b7ce2a9580afa10" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. By default (the parameter is unspecified), the value is set to 0.1. The default will change in version 0.21. It will remain 0.1 only if &lt;code&gt;train_size&lt;/code&gt; is unspecified, otherwise it will complement the specified &lt;code&gt;train_size&lt;/code&gt;.</source>
          <target state="translated">Если с плавающей точкой, значение должно быть от 0,0 до 1,0 и представлять долю набора данных, которая будет включена в тестовую группу. Если int, представляет собой абсолютное количество тестовых образцов. Если None, значение устанавливается как дополнение к размеру поезда. По умолчанию (параметр не указан) установлено значение 0,1. Значение по умолчанию изменится в версии 0.21. Он останется &lt;code&gt;train_size&lt;/code&gt; 0,1, только если train_size не указан , иначе он будет дополнять указанный &lt;code&gt;train_size&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="73ce93bb920d84bef49715afdf02f771938f8206" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. By default, the value is set to 0.1. The default will change in version 0.21. It will remain 0.1 only if &lt;code&gt;train_size&lt;/code&gt; is unspecified, otherwise it will complement the specified &lt;code&gt;train_size&lt;/code&gt;.</source>
          <target state="translated">Если с плавающей точкой, значение должно быть от 0,0 до 1,0 и представлять долю набора данных, которая будет включена в тестовую группу. Если int, представляет собой абсолютное количество тестовых образцов. Если None, значение устанавливается как дополнение к размеру поезда. По умолчанию установлено значение 0,1. Значение по умолчанию изменится в версии 0.21. Он останется &lt;code&gt;train_size&lt;/code&gt; 0,1, только если train_size не указан , иначе он будет дополнять указанный &lt;code&gt;train_size&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="aa74ab3ce21513c4e7c83e9b91dad63582c835b8" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. By default, the value is set to 0.2. The default will change in version 0.21. It will remain 0.2 only if &lt;code&gt;train_size&lt;/code&gt; is unspecified, otherwise it will complement the specified &lt;code&gt;train_size&lt;/code&gt;.</source>
          <target state="translated">Если с плавающей точкой, значение должно быть от 0,0 до 1,0 и представлять долю набора данных, которая будет включена в тестовую группу. Если int, представляет собой абсолютное количество тестовых образцов. Если None, значение устанавливается как дополнение к размеру поезда. По умолчанию установлено значение 0,2. Значение по умолчанию изменится в версии 0.21. Он останется &lt;code&gt;train_size&lt;/code&gt; 0,2, только если train_size не указан , иначе он будет дополнять указанный &lt;code&gt;train_size&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="dfe0bc4ba0825c6b9e54b3177711e714d6e28a2b" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. By default, the value is set to 0.25. The default will change in version 0.21. It will remain 0.25 only if &lt;code&gt;train_size&lt;/code&gt; is unspecified, otherwise it will complement the specified &lt;code&gt;train_size&lt;/code&gt;.</source>
          <target state="translated">Если с плавающей точкой, значение должно быть от 0,0 до 1,0 и представлять долю набора данных, которая будет включена в тестовую группу. Если int, представляет собой абсолютное количество тестовых образцов. Если None, значение устанавливается как дополнение к размеру поезда. По умолчанию установлено значение 0,25. Значение по умолчанию изменится в версии 0.21. Он останется 0,25, только если &lt;code&gt;train_size&lt;/code&gt; не указан , иначе он будет дополнять указанный &lt;code&gt;train_size&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="09a40f5654bce0b9dd81c58e4db01bd35e373391" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. If &lt;code&gt;train_size&lt;/code&gt; is also None, it will be set to 0.1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c86f8c8782626d870a975f8a368ba48b84e1e80" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. If &lt;code&gt;train_size&lt;/code&gt; is also None, it will be set to 0.25.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3b7da8f21403a8e0fce55a369b8d82b4da5bfd1" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split. If int, represents the absolute number of train samples. If None, the value is automatically set to the complement of the test size.</source>
          <target state="translated">Если float,то он должен быть между 0.0 и 1.0 и представлять собой пропорцию набора данных для включения в разбиение поезда.Если int,то представляет абсолютное количество образцов состава.Если None,то значение автоматически устанавливается в качестве дополнения к размеру теста.</target>
        </trans-unit>
        <trans-unit id="62b47f7a89d7c976d2813299381cdc4f4f5b3cad" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the groups to include in the train split. If int, represents the absolute number of train groups. If None, the value is automatically set to the complement of the test size.</source>
          <target state="translated">Если float,то он должен быть между 0.0 и 1.0 и представлять собой пропорцию групп,которые должны быть включены в состав поездов,разбитых на части.Если int,то представляет абсолютное число групп поездов.Если None,то значение автоматически устанавливается в качестве дополнения к тестовому размеру.</target>
        </trans-unit>
        <trans-unit id="561d4c125db4b741d015190537a6b19d8f8e55c1" translate="yes" xml:space="preserve">
          <source>If float, the contamination should be in the range [0, 0.5].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0ffbda1c59db43809cf9245f33efa45a65a5c05" translate="yes" xml:space="preserve">
          <source>If float, then &lt;code&gt;max_features&lt;/code&gt; is a fraction and &lt;code&gt;int(max_features * n_features)&lt;/code&gt; features are considered at each split.</source>
          <target state="translated">Если float, то &lt;code&gt;max_features&lt;/code&gt; является дробной частью, а функции &lt;code&gt;int(max_features * n_features)&lt;/code&gt; учитываются при каждом разбиении.</target>
        </trans-unit>
        <trans-unit id="47d0c1ebc9dc44a7018a0ce88d0d45201068f385" translate="yes" xml:space="preserve">
          <source>If float, then &lt;code&gt;min_samples_leaf&lt;/code&gt; is a fraction and &lt;code&gt;ceil(min_samples_leaf * n_samples)&lt;/code&gt; are the minimum number of samples for each node.</source>
          <target state="translated">Если float, то &lt;code&gt;min_samples_leaf&lt;/code&gt; - это дробь, а &lt;code&gt;ceil(min_samples_leaf * n_samples)&lt;/code&gt; - минимальное количество выборок для каждого узла.</target>
        </trans-unit>
        <trans-unit id="c217707834c84f95b745c6fd735e46ef1d5cb29d" translate="yes" xml:space="preserve">
          <source>If float, then &lt;code&gt;min_samples_leaf&lt;/code&gt; is a fraction and &lt;code&gt;ceil(min_samples_leaf * n_samples)&lt;/code&gt; is the minimum number of samples for each node.</source>
          <target state="translated">Если float, то &lt;code&gt;min_samples_leaf&lt;/code&gt; - дробная часть, а &lt;code&gt;ceil(min_samples_leaf * n_samples)&lt;/code&gt; - минимальное количество выборок для каждого узла.</target>
        </trans-unit>
        <trans-unit id="f5813e9c1656f619ed6234eb86815e1c76ec9071" translate="yes" xml:space="preserve">
          <source>If float, then &lt;code&gt;min_samples_split&lt;/code&gt; is a fraction and &lt;code&gt;ceil(min_samples_split * n_samples)&lt;/code&gt; are the minimum number of samples for each split.</source>
          <target state="translated">Если с плавающей точкой, то &lt;code&gt;min_samples_split&lt;/code&gt; - это дробь, а &lt;code&gt;ceil(min_samples_split * n_samples)&lt;/code&gt; - минимальное количество выборок для каждого разделения.</target>
        </trans-unit>
        <trans-unit id="c32957ea85344bbb6b41aa874b4a5e7763ff6b76" translate="yes" xml:space="preserve">
          <source>If float, then &lt;code&gt;min_samples_split&lt;/code&gt; is a fraction and &lt;code&gt;ceil(min_samples_split * n_samples)&lt;/code&gt; is the minimum number of samples for each split.</source>
          <target state="translated">Если float, то &lt;code&gt;min_samples_split&lt;/code&gt; - это дробь, а &lt;code&gt;ceil(min_samples_split * n_samples)&lt;/code&gt; - минимальное количество выборок для каждого разделения.</target>
        </trans-unit>
        <trans-unit id="81fe24c94c96599e85080c0cc195542bdb1ce722" translate="yes" xml:space="preserve">
          <source>If float, then draw &lt;code&gt;max_features * X.shape[1]&lt;/code&gt; features.</source>
          <target state="translated">Если с плавающей точкой, то нарисуйте функции &lt;code&gt;max_features * X.shape[1]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a2b1676fcae8577852e20614ce418906e2f79102" translate="yes" xml:space="preserve">
          <source>If float, then draw &lt;code&gt;max_samples * X.shape[0]&lt;/code&gt; samples.</source>
          <target state="translated">Если с плавающей точкой, то отрисовываем &lt;code&gt;max_samples * X.shape[0]&lt;/code&gt; выборки.</target>
        </trans-unit>
        <trans-unit id="271d97216c612b23c04f108b3da94d4db7dcfcec" translate="yes" xml:space="preserve">
          <source>If float, then draw &lt;code&gt;max_samples * X.shape[0]&lt;/code&gt; samples. Thus, &lt;code&gt;max_samples&lt;/code&gt; should be in the interval &lt;code&gt;(0, 1)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2cf469ccb5c1129883a42e4f4a3183401e643c51" translate="yes" xml:space="preserve">
          <source>If full :</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f234188a9694365b66e83538b40de1fa4059a074" translate="yes" xml:space="preserve">
          <source>If greater than or equal to 1, then &lt;code&gt;step&lt;/code&gt; corresponds to the (integer) number of features to remove at each iteration. If within (0.0, 1.0), then &lt;code&gt;step&lt;/code&gt; corresponds to the percentage (rounded down) of features to remove at each iteration.</source>
          <target state="translated">Если больше или равно 1, то &lt;code&gt;step&lt;/code&gt; соответствует (целочисленному) количеству функций, которые необходимо удалить на каждой итерации. Если в пределах (0,0, 1,0), то &lt;code&gt;step&lt;/code&gt; соответствует проценту (с округлением в меньшую сторону) функций, удаляемых на каждой итерации.</target>
        </trans-unit>
        <trans-unit id="d3aeb6a39c457b69bdde12a943780461d08c388d" translate="yes" xml:space="preserve">
          <source>If greater than or equal to 1, then &lt;code&gt;step&lt;/code&gt; corresponds to the (integer) number of features to remove at each iteration. If within (0.0, 1.0), then &lt;code&gt;step&lt;/code&gt; corresponds to the percentage (rounded down) of features to remove at each iteration. Note that the last iteration may remove fewer than &lt;code&gt;step&lt;/code&gt; features in order to reach &lt;code&gt;min_features_to_select&lt;/code&gt;.</source>
          <target state="translated">Если больше или равно 1, то &lt;code&gt;step&lt;/code&gt; соответствует (целочисленному) количеству функций, которые необходимо удалить на каждой итерации. Если в пределах (0,0, 1,0), то &lt;code&gt;step&lt;/code&gt; соответствует проценту (с округлением в меньшую сторону) функций, удаляемых на каждой итерации. Обратите внимание, что последняя итерация может удалить меньше, чем &lt;code&gt;step&lt;/code&gt; функции, чтобы достичь &lt;code&gt;min_features_to_select&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1351e34960b08f78869e356e9d9129a529a17168" translate="yes" xml:space="preserve">
          <source>If in the QDA model one assumes that the covariance matrices are diagonal, then the inputs are assumed to be conditionally independent in each class, and the resulting classifier is equivalent to the Gaussian Naive Bayes classifier &lt;a href=&quot;generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt;&lt;code&gt;naive_bayes.GaussianNB&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Если в модели QDA предполагается, что ковариационные матрицы диагональны, то предполагается, что входные данные условно независимы в каждом классе, и результирующий классификатор эквивалентен гауссовскому &lt;a href=&quot;generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt; &lt;code&gt;naive_bayes.GaussianNB&lt;/code&gt; &lt;/a&gt; байесовскому классификатору naive_bayes.GaussianNB .</target>
        </trans-unit>
        <trans-unit id="47884bf7f490577d7025ceb970813cb997acfc82" translate="yes" xml:space="preserve">
          <source>If init=&amp;rsquo;custom&amp;rsquo;, it is used as initial guess for the solution.</source>
          <target state="translated">Если init = 'custom', он используется в качестве первоначального предположения для решения.</target>
        </trans-unit>
        <trans-unit id="25a1f9fc4e56498f0b6e355b29cc8aeb5e3daeb3" translate="yes" xml:space="preserve">
          <source>If init=&amp;rsquo;custom&amp;rsquo;, it is used as initial guess for the solution. If update_H=False, it is used as a constant, to solve for W only.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b9c788e52ff7adb618d2b8cf3dd396e088800c8" translate="yes" xml:space="preserve">
          <source>If int, it is the total number of points equally divided among clusters. If array-like, each element of the sequence indicates the number of samples per cluster.</source>
          <target state="translated">Если int,то это общее количество точек,равномерно распределенных между кластерами.Если массивовидно,то каждый элемент последовательности указывает количество отсчетов на кластер.</target>
        </trans-unit>
        <trans-unit id="424c096f1eaf5892378c66d2235ced4e356f327c" translate="yes" xml:space="preserve">
          <source>If int, it is the total number of points generated. For odd numbers, the inner circle will have one point more than the outer circle. If two-element tuple, number of points in outer circle and inner circle.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2403d0bd3d2ac8c8a9756c4cde9cd9202cbe9926" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;.</source>
          <target state="translated">Если int, random_state - это начальное число, используемое генератором случайных чисел; Если экземпляр RandomState, random_state является генератором случайных чисел; Если None, генератор случайных чисел - это экземпляр RandomState, используемый &lt;code&gt;np.random&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="676c2454734bf9216c5797d643595f0b850b4e7a" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Note that different initializations might result in different local minima of the cost function.</source>
          <target state="translated">Если int, random_state - это начальное число, используемое генератором случайных чисел; Если экземпляр RandomState, random_state является генератором случайных чисел; Если None, генератор случайных чисел - это экземпляр RandomState, используемый &lt;code&gt;np.random&lt;/code&gt; . Обратите внимание, что разные инициализации могут привести к различным локальным минимумам функции стоимости.</target>
        </trans-unit>
        <trans-unit id="a1933900181bd8e24f0237ebecc7a06b2ef8b486" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Only used when &lt;code&gt;svd_method&lt;/code&gt; equals &amp;lsquo;randomized&amp;rsquo;.</source>
          <target state="translated">Если int, random_state - это начальное число, используемое генератором случайных чисел; Если экземпляр RandomState, random_state является генератором случайных чисел; Если None, генератор случайных чисел - это экземпляр RandomState, используемый &lt;code&gt;np.random&lt;/code&gt; . Используется только когда &lt;code&gt;svd_method&lt;/code&gt; равно &quot;randomized&quot;.</target>
        </trans-unit>
        <trans-unit id="4914440c8828885c0b1efea7679daefd5f1e4eaf" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;eigen_solver&lt;/code&gt; == &amp;lsquo;arpack&amp;rsquo;.</source>
          <target state="translated">Если int, random_state - это начальное число, используемое генератором случайных чисел; Если экземпляр RandomState, random_state является генератором случайных чисел; Если None, генератор случайных чисел - это экземпляр RandomState, используемый &lt;code&gt;np.random&lt;/code&gt; . Используется, когда &lt;code&gt;eigen_solver&lt;/code&gt; == 'arpack'.</target>
        </trans-unit>
        <trans-unit id="90657492e3c46d11fb3a1c799a4569e4854211ed" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;shuffle&lt;/code&gt; == True.</source>
          <target state="translated">Если int, random_state - это начальное число, используемое генератором случайных чисел; Если экземпляр RandomState, random_state является генератором случайных чисел; Если None, генератор случайных чисел - это экземпляр RandomState, используемый &lt;code&gt;np.random&lt;/code&gt; . Используется при &lt;code&gt;shuffle&lt;/code&gt; == True.</target>
        </trans-unit>
        <trans-unit id="7e39c8ed74a38762200c178da772671eaa6b3f52" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;shuffle&lt;/code&gt; is True.</source>
          <target state="translated">Если int, random_state - это начальное число, используемое генератором случайных чисел; Если экземпляр RandomState, random_state является генератором случайных чисел; Если None, генератор случайных чисел - это экземпляр RandomState, используемый &lt;code&gt;np.random&lt;/code&gt; . Используется при &lt;code&gt;shuffle&lt;/code&gt; True.</target>
        </trans-unit>
        <trans-unit id="636d95a8f3edcd08bb7a122de05f8944c1a330ee" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;solver&lt;/code&gt; == &amp;lsquo;arpack&amp;rsquo;.</source>
          <target state="translated">Если int, random_state - это начальное число, используемое генератором случайных чисел; Если экземпляр RandomState, random_state является генератором случайных чисел; Если None, генератор случайных чисел - это экземпляр RandomState, используемый &lt;code&gt;np.random&lt;/code&gt; . Используется, когда &lt;code&gt;solver&lt;/code&gt; == 'arpack'.</target>
        </trans-unit>
        <trans-unit id="d8bb54edf7a318cb4f3734b3f7721b6c840db8b1" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;svd_solver&lt;/code&gt; == &amp;lsquo;arpack&amp;rsquo; or &amp;lsquo;randomized&amp;rsquo;.</source>
          <target state="translated">Если int, random_state - это начальное число, используемое генератором случайных чисел; Если экземпляр RandomState, random_state является генератором случайных чисел; Если None, генератор случайных чисел - это экземпляр RandomState, используемый &lt;code&gt;np.random&lt;/code&gt; . Используется, когда &lt;code&gt;svd_solver&lt;/code&gt; == 'arpack' или 'randomized'.</target>
        </trans-unit>
        <trans-unit id="49fc99a0f8ec79ab5cf6633c8b91ad397447b0ae" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random. Note that this is used by subsampling and smoothing noise.</source>
          <target state="translated">Если int,random_state-это семя,используемое генератором случайных чисел;если RandomState экземпляр,random_state-генератор случайных чисел;если None,генератор случайных чисел-это экземпляр RandomState,используемый np.random.Обратите внимание,что это используется субсэмплированием и сглаживанием шума.</target>
        </trans-unit>
        <trans-unit id="20ecb73824a9c787c46458c94b754eb343f23997" translate="yes" xml:space="preserve">
          <source>If int, the total number of points generated. If two-element tuple, number of points in each of two moons.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8faba5e55a8f0e899120109354364cac8c2354b" translate="yes" xml:space="preserve">
          <source>If int, then consider &lt;code&gt;max_features&lt;/code&gt; features at each split.</source>
          <target state="translated">Если int, то &lt;code&gt;max_features&lt;/code&gt; особенности max_features при каждом разбиении.</target>
        </trans-unit>
        <trans-unit id="79438cfe8b8de1684467307814da6af61cdfe6ba" translate="yes" xml:space="preserve">
          <source>If int, then consider &lt;code&gt;min_samples_leaf&lt;/code&gt; as the minimum number.</source>
          <target state="translated">Если int, то считайте &lt;code&gt;min_samples_leaf&lt;/code&gt; минимальным числом.</target>
        </trans-unit>
        <trans-unit id="69e04ca78560d3ef445be4d724f5c0cc8198187a" translate="yes" xml:space="preserve">
          <source>If int, then consider &lt;code&gt;min_samples_split&lt;/code&gt; as the minimum number.</source>
          <target state="translated">Если int, то считайте &lt;code&gt;min_samples_split&lt;/code&gt; минимальным числом.</target>
        </trans-unit>
        <trans-unit id="a8d276c242fbe315ce14903af35e7ebf9a0c3619" translate="yes" xml:space="preserve">
          <source>If int, then draw &lt;code&gt;max_features&lt;/code&gt; features.</source>
          <target state="translated">Если int, то нарисуйте функции &lt;code&gt;max_features&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0771ca4ef29dd427aac0ffda56943aa541e3af54" translate="yes" xml:space="preserve">
          <source>If int, then draw &lt;code&gt;max_samples&lt;/code&gt; samples.</source>
          <target state="translated">Если int, то рисуем образцы &lt;code&gt;max_samples&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4430c154e22158c0d6435f75a2d640312ee73ab2" translate="yes" xml:space="preserve">
          <source>If log normalization was used, all the singular vectors are meaningful. However, if independent normalization or bistochastization were used, the first singular vectors, \(u_1\) and \(v_1\). are discarded. From now on, the &amp;ldquo;first&amp;rdquo; singular vectors refers to \(u_2 \dots u_{p+1}\) and \(v_2 \dots v_{p+1}\) except in the case of log normalization.</source>
          <target state="translated">Если использовалась логарифмическая нормализация, все сингулярные векторы имеют смысл. Однако, если использовалась независимая нормализация или бистохастизация, первые сингулярные векторы, \ (u_1 \) и \ (v_1 \). отбрасываются. С этого момента &amp;laquo;первые&amp;raquo; сингулярные векторы относятся к \ (u_2 \ dots u_ {p + 1} \) и \ (v_2 \ dots v_ {p + 1} \), за исключением случая логарифмической нормализации.</target>
        </trans-unit>
        <trans-unit id="f38434d38fce86523bd80aac7625c65019a5f868" translate="yes" xml:space="preserve">
          <source>If max_samples is larger than the number of samples provided, all samples will be used for all trees (no sampling).</source>
          <target state="translated">Если max_samples больше,чем количество предоставленных выборок,то все выборки будут использоваться для всех деревьев (без выборок).</target>
        </trans-unit>
        <trans-unit id="0512919782ceb898f5e82137605d37f1918f7fe8" translate="yes" xml:space="preserve">
          <source>If method == &amp;ldquo;auto&amp;rdquo;, the ratio of n_samples / n_population is used to determine which algorithm to use: If ratio is between 0 and 0.01, tracking selection is used. If ratio is between 0.01 and 0.99, numpy.random.permutation is used. If ratio is greater than 0.99, reservoir sampling is used. The order of the selected integers is undefined. If a random order is desired, the selected subset should be shuffled.</source>
          <target state="translated">Если method == &amp;laquo;auto&amp;raquo;, соотношение n_samples / n_population используется для определения того, какой алгоритм использовать: если соотношение находится между 0 и 0,01, используется выбор отслеживания. Если соотношение составляет от 0,01 до 0,99, используется numpy.random.permutation. Если коэффициент больше 0,99, используется отбор проб из коллектора. Порядок выбранных целых чисел не определен. Если желателен случайный порядок, выбранное подмножество следует перемешать.</target>
        </trans-unit>
        <trans-unit id="aa3ae5990e2e00fef99c00cc07049cdbc9d8e931" translate="yes" xml:space="preserve">
          <source>If method == &amp;ldquo;pool&amp;rdquo;, a pool based algorithm is particularly fast, even faster than the tracking selection method. Hovewer, a vector containing the entire population has to be initialized. If n_samples ~ n_population, the reservoir sampling method is faster.</source>
          <target state="translated">Если method == &amp;laquo;pool&amp;raquo;, алгоритм на основе пула работает особенно быстро, даже быстрее, чем метод отслеживания выбора. Ховуэра необходимо инициализировать вектор, содержащий всю популяцию. Если n_samples ~ n_population, метод отбора проб из коллектора выполняется быстрее.</target>
        </trans-unit>
        <trans-unit id="6916dcd6d6c8f00e1ac0ef865ab4c75ff38ebedf" translate="yes" xml:space="preserve">
          <source>If method == &amp;ldquo;reservoir_sampling&amp;rdquo;, a reservoir sampling algorithm is used which is suitable for high memory constraint or when O(&lt;code&gt;n_samples&lt;/code&gt;) ~ O(&lt;code&gt;n_population&lt;/code&gt;). The order of the selected integers is undefined. If a random order is desired, the selected subset should be shuffled.</source>
          <target state="translated">Если method == &amp;laquo;servoir_sampling &amp;raquo;, используется алгоритм выборки коллектора, который подходит для ограничения высокой памяти или когда O ( &lt;code&gt;n_samples&lt;/code&gt; ) ~ O ( &lt;code&gt;n_population&lt;/code&gt; ). Порядок выбранных целых чисел не определен. Если желателен случайный порядок, выбранное подмножество следует перемешать.</target>
        </trans-unit>
        <trans-unit id="0dea8a6c91cef90e0430014d895bb3954c8fb19c" translate="yes" xml:space="preserve">
          <source>If method ==&amp;rdquo;tracking_selection&amp;rdquo;, a set based implementation is used which is suitable for &lt;code&gt;n_samples&lt;/code&gt; &amp;lt;&amp;lt;&amp;lt; &lt;code&gt;n_population&lt;/code&gt;.</source>
          <target state="translated">Если method == &amp;rdquo;tracking_selection&amp;rdquo;, используется реализация на основе набора, которая подходит для &lt;code&gt;n_samples&lt;/code&gt; &amp;lt;&amp;lt;&amp;lt; &lt;code&gt;n_population&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b83a3c2dac1d5c17a6e580230ebdf136c940fa15" translate="yes" xml:space="preserve">
          <source>If metric is &amp;ldquo;precomputed&amp;rdquo;, X is assumed to be a distance matrix and must be square. X may be a sparse matrix, in which case only &amp;ldquo;nonzero&amp;rdquo; elements may be considered neighbors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79ae0bba548597b9902c41c70fbd6bf9602e8534" translate="yes" xml:space="preserve">
          <source>If metric is &amp;lsquo;precomputed&amp;rsquo;, Y is ignored and X is returned.</source>
          <target state="translated">Если метрика &amp;laquo;предварительно вычислена&amp;raquo;, Y игнорируется и возвращается X.</target>
        </trans-unit>
        <trans-unit id="ca8cb47e72e166fd730a116349e050254e6876d5" translate="yes" xml:space="preserve">
          <source>If metric is a callable function, it is called on each pair of instances (rows) and the resulting value recorded. The callable should take two arrays as input and return one value indicating the distance between them. This works for Scipy&amp;rsquo;s metrics, but is less efficient than passing the metric name as a string.</source>
          <target state="translated">Если метрика является вызываемой функцией, она вызывается для каждой пары экземпляров (строк) и записывается полученное значение. Вызываемый объект должен принимать в качестве входных данных два массива и возвращать одно значение, указывающее расстояние между ними. Это работает для метрик Scipy, но менее эффективно, чем передача имени метрики в виде строки.</target>
        </trans-unit>
        <trans-unit id="574d42008b369aefc553aab20dba12b6d233789b" translate="yes" xml:space="preserve">
          <source>If metric is a callable function, it is called on each pair of instances (rows) and the resulting value recorded. The callable should take two arrays as input and return one value indicating the distance between them. This works for Scipy&amp;rsquo;s metrics, but is less efficient than passing the metric name as a string. If metric is &amp;ldquo;precomputed&amp;rdquo;, X is assumed to be a distance matrix and must be square.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27305db22802f1bb3d3e2d60db076f6f0d275369" translate="yes" xml:space="preserve">
          <source>If mini-batch k-means is used, the best initialization is chosen and the algorithm runs once. Otherwise, the algorithm is run for each initialization and the best solution chosen.</source>
          <target state="translated">Если используется мини-пачка к-средств,то выбирается лучшая инициализация и алгоритм запускается один раз.В противном случае алгоритм запускается для каждой инициализации и выбирается лучшее решение.</target>
        </trans-unit>
        <trans-unit id="16e6684b95c26e373af21b6c0d2ea50b705c0505" translate="yes" xml:space="preserve">
          <source>If multioutput is &amp;lsquo;raw_values&amp;rsquo;, then mean absolute error is returned for each output separately. If multioutput is &amp;lsquo;uniform_average&amp;rsquo; or an ndarray of weights, then the weighted average of all output errors is returned.</source>
          <target state="translated">Если multioutput равен 'raw_values', то средняя абсолютная ошибка возвращается для каждого выхода отдельно. Если multioutput равен 'uniform_average' или ndarray весов, то возвращается средневзвешенное значение всех ошибок вывода.</target>
        </trans-unit>
        <trans-unit id="5304821b08fca43ab85cd7593997416e8f601261" translate="yes" xml:space="preserve">
          <source>If neighbors_algorithm=&amp;rsquo;precomputed&amp;rsquo;, X is assumed to be a distance matrix or a sparse graph of shape (n_queries, n_samples_fit).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62bc17472717b60146346d5aed7f5c0278bbe8ae" translate="yes" xml:space="preserve">
          <source>If no missing values were encountered for a given feature during training, then samples with missing values are mapped to whichever child has the most samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="caf3d42023b133b9efdfbb493fc66df503092e71" translate="yes" xml:space="preserve">
          <source>If no scoring is specified and the estimator has no score function, we can either return None or raise an exception.</source>
          <target state="translated">Если оценка не указана и оценщик не имеет функции оценки,мы можем либо вернуть None,либо поднять исключение.</target>
        </trans-unit>
        <trans-unit id="5519c1c6825bf59bfd06c08f68bb64b64ee1a0ae" translate="yes" xml:space="preserve">
          <source>If no valid consensus set could be found. This occurs if &lt;code&gt;is_data_valid&lt;/code&gt; and &lt;code&gt;is_model_valid&lt;/code&gt; return False for all &lt;code&gt;max_trials&lt;/code&gt; randomly chosen sub-samples.</source>
          <target state="translated">Если не удалось найти действительный консенсусный набор. Это происходит, если &lt;code&gt;is_data_valid&lt;/code&gt; и &lt;code&gt;is_model_valid&lt;/code&gt; возвращают False для всех &lt;code&gt;max_trials&lt;/code&gt; , выбранных случайным образом подвыборок.</target>
        </trans-unit>
        <trans-unit id="e48a960f323664c14eed43108cfafa1159796090" translate="yes" xml:space="preserve">
          <source>If normalize is &lt;code&gt;True&lt;/code&gt;, return the fraction of misclassifications (float), else it returns the number of misclassifications (int). The best performance is 0.</source>
          <target state="translated">Если normalize имеет значение &lt;code&gt;True&lt;/code&gt; , вернуть долю ошибочных классификаций (float), в противном случае возвращается количество ошибочных классификаций (int). Лучшая производительность - 0.</target>
        </trans-unit>
        <trans-unit id="66ebd47239b72bc82239183dacc1b3e58bfa41bb" translate="yes" xml:space="preserve">
          <source>If not &lt;code&gt;None&lt;/code&gt;, the standardized partial AUC &lt;a href=&quot;#r4bb7c4558997-2&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt; over the range [0, max_fpr] is returned. For the multiclass case, &lt;code&gt;max_fpr&lt;/code&gt;, should be either equal to &lt;code&gt;None&lt;/code&gt; or &lt;code&gt;1.0&lt;/code&gt; as AUC ROC partial computation currently is not supported for multiclass.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d93355ca0c397a92c0eb63483bbae0b531d00cf1" translate="yes" xml:space="preserve">
          <source>If not &lt;code&gt;None&lt;/code&gt;, the standardized partial AUC &lt;a href=&quot;#r4bb7c4558997-3&quot; id=&quot;id1&quot;&gt;[3]&lt;/a&gt; over the range [0, max_fpr] is returned.</source>
          <target state="translated">Если не &lt;code&gt;None&lt;/code&gt; , возвращается стандартизованная частичная AUC &lt;a href=&quot;#r4bb7c4558997-3&quot; id=&quot;id1&quot;&gt;[3]&lt;/a&gt; в диапазоне [0, max_fpr].</target>
        </trans-unit>
        <trans-unit id="954d968337062d6fae676f5915fb0dc48db9ccef" translate="yes" xml:space="preserve">
          <source>If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus.</source>
          <target state="translated">Если нет None,построите словарь,который учитывает только верхние max_features,упорядоченные по частоте термина по всему телу.</target>
        </trans-unit>
        <trans-unit id="6b6dff5f6d294c2bdbfe5ee6b0ee56319193880c" translate="yes" xml:space="preserve">
          <source>If not None, data is split in a stratified fashion, using this as the class labels.</source>
          <target state="translated">Если нет Нет,то данные разбиваются стратифицированно,используя это в качестве ярлыков класса.</target>
        </trans-unit>
        <trans-unit id="d9fe4271c08ca870db7143f08e0938aa49f2d1d0" translate="yes" xml:space="preserve">
          <source>If not None, set the highest value of the fit to y_max.</source>
          <target state="translated">Если нет None,установите наибольшее значение подгонки под y_max.</target>
        </trans-unit>
        <trans-unit id="3c138b5d1ed12eddb3226ed7535814059b7a615c" translate="yes" xml:space="preserve">
          <source>If not None, set the lowest value of the fit to y_min.</source>
          <target state="translated">Если нет None,установите наименьшее значение подгонки в y_min.</target>
        </trans-unit>
        <trans-unit id="ebcf44116da09ed76a723aed5cadbe6d4ed2530d" translate="yes" xml:space="preserve">
          <source>If not None, this argument is passed as &lt;code&gt;sample_weight&lt;/code&gt; keyword argument to the &lt;code&gt;score&lt;/code&gt; method of the final estimator.</source>
          <target state="translated">Если не None, этот аргумент передается как &lt;code&gt;sample_weight&lt;/code&gt; ключевого слова аргумент &lt;code&gt;score&lt;/code&gt; метода окончательной оценки.</target>
        </trans-unit>
        <trans-unit id="3798f9f768af1129609b1d811ed41c3721cfae7d" translate="yes" xml:space="preserve">
          <source>If not None, this function is called after every iteration of the optimizer, taking as arguments the current solution (flattened transformation matrix) and the number of iterations. This might be useful in case one wants to examine or store the transformation found after each iteration.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0f7d0b7263b16cf926e8314af8096b9ae6c9066" translate="yes" xml:space="preserve">
          <source>If not given, the bandwidth is estimated using sklearn.cluster.estimate_bandwidth; see the documentation for that function for hints on scalability (see also the Notes, below).</source>
          <target state="translated">Если не указано,то пропускная способность оценивается с использованием sklearn.cluster.estimate_bandwidth;см.документацию по этой функции для подсказок о масштабируемости (см.также Примечания ниже).</target>
        </trans-unit>
        <trans-unit id="e77fe01e6cae9364473d1714c8219315178ecad2" translate="yes" xml:space="preserve">
          <source>If not provided, labels will be inferred from y_true. If &lt;code&gt;labels&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; has shape (n_samples,) the labels are assumed to be binary and are inferred from &lt;code&gt;y_true&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3fc57ade66d3b29b2e5dacfcee394aac7f4ec951" translate="yes" xml:space="preserve">
          <source>If not provided, labels will be inferred from y_true. If &lt;code&gt;labels&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; has shape (n_samples,) the labels are assumed to be binary and are inferred from &lt;code&gt;y_true&lt;/code&gt;. .. versionadded:: 0.18</source>
          <target state="translated">Если не указан, ярлыки будут выведены из y_true. Если &lt;code&gt;labels&lt;/code&gt; не &lt;code&gt;None&lt;/code&gt; и &lt;code&gt;y_pred&lt;/code&gt; имеет форму (n_samples,) метки предполагаются двоичными и выводятся из &lt;code&gt;y_true&lt;/code&gt; . .. добавлена ​​версия :: 0.18</target>
        </trans-unit>
        <trans-unit id="d3a1f4e96f04c6f8dfd4835d50de53587903b2e7" translate="yes" xml:space="preserve">
          <source>If one-of-K coding is applied to categorical features, this will include the constructed feature names but not the original ones.</source>
          <target state="translated">Если к категориальным признакам применяется кодировка &quot;один из k&quot;,то это будет включать имена построенных признаков,но не оригинальные.</target>
        </trans-unit>
        <trans-unit id="c3b8faf61102e14148418b48bf3dbb3389d54ef3" translate="yes" xml:space="preserve">
          <source>If only the diagonal of the auto-covariance is being used, the method &lt;code&gt;diag()&lt;/code&gt; of a kernel can be called, which is more computationally efficient than the equivalent call to &lt;code&gt;__call__&lt;/code&gt;: &lt;code&gt;np.diag(k(X, X)) == k.diag(X)&lt;/code&gt;</source>
          <target state="translated">Если используется только диагональ &lt;code&gt;__call__&lt;/code&gt; можно вызвать метод ядра &lt;code&gt;diag()&lt;/code&gt; , который более эффективен в вычислительном отношении, чем эквивалентный вызов __call__ : &lt;code&gt;np.diag(k(X, X)) == k.diag(X)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="db7f35e5fc1dd73c10c86bdccb4a2449d5a89ec7" translate="yes" xml:space="preserve">
          <source>If order is &amp;lsquo;random&amp;rsquo; a random ordering will be used.</source>
          <target state="translated">Если порядок &amp;laquo;случайный&amp;raquo;, будет использоваться случайный порядок.</target>
        </trans-unit>
        <trans-unit id="f42275492b00fc14b5861ea85e0f4944992d0324" translate="yes" xml:space="preserve">
          <source>If passed, include the name of the estimator in warning messages.</source>
          <target state="translated">В случае передачи включите имя оценщика в предупреждающие сообщения.</target>
        </trans-unit>
        <trans-unit id="908cd551a5eab6201799122746b2ad3d99f4a3d2" translate="yes" xml:space="preserve">
          <source>If positive, restrict regression coefficients to be positive</source>
          <target state="translated">Если он положительный,ограничить коэффициенты регрессии положительными.</target>
        </trans-unit>
        <trans-unit id="66637d66644751acb1ce04342cdfce0be0ef5495" translate="yes" xml:space="preserve">
          <source>If provided, this parameter will override the choice of copy_X made at instance creation. If &lt;code&gt;True&lt;/code&gt;, X will be copied; else, it may be overwritten.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71021bee801a334b18f6587cd74d122911551ceb" translate="yes" xml:space="preserve">
          <source>If query_id is set to True, this will return instead [X1, y1, q1,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54d5c9aca2dfc54fbbbdb98327375a6f374bdf8f" translate="yes" xml:space="preserve">
          <source>If randomized :</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c5484f943f94af044829e2453a87ea1beff675d6" translate="yes" xml:space="preserve">
          <source>If return_costs is True, the objective function and dual gap at each iteration are returned.</source>
          <target state="translated">Если return_costs равен True,то возвращается объективная функция и двойной разрыв на каждой итерации.</target>
        </trans-unit>
        <trans-unit id="3a07f641c209d2556442bcd652915ffb4ab857db" translate="yes" xml:space="preserve">
          <source>If safe is false, clone will fall back to a deep copy on objects that are not estimators.</source>
          <target state="translated">Если сейф является ложным,клон будет возвращаться в глубокую копию на объектах,которые не являются оценочными.</target>
        </trans-unit>
        <trans-unit id="179d83839b7c246b21dd4fad6260ec3c338cc783" translate="yes" xml:space="preserve">
          <source>If seed is None, return the RandomState singleton used by np.random. If seed is an int, return a new RandomState instance seeded with seed. If seed is already a RandomState instance, return it. Otherwise raise ValueError.</source>
          <target state="translated">Если семя Нет,верните сингл &quot;Случайное состояние&quot;,используемый np.random.Если &quot;seed&quot;-int,верните новый случайный экземпляр RandomState,заполненный &quot;seed&quot;.Если &quot;seed&quot; уже является случайным экземпляром,верните его.В противном случае поднимите ValueError.</target>
        </trans-unit>
        <trans-unit id="7108bbb3c9ecad70c2ad038e49ece7ce906a1c8f" translate="yes" xml:space="preserve">
          <source>If seq[i] is an int or a tuple with one int value, a one-way PDP is created; if seq[i] is a tuple of two ints, a two-way PDP is created. If feature_names is specified and seq[i] is an int, seq[i] must be &amp;lt; len(feature_names). If seq[i] is a string, feature_names must be specified, and seq[i] must be in feature_names.</source>
          <target state="translated">Если seq [i] является int или кортежем с одним значением int, создается односторонний PDP; если seq [i] представляет собой кортеж из двух целых чисел, создается двусторонний PDP. Если указано имя_функции и seq [i] является целым числом, значение seq [i] должно быть &amp;lt;len (имена_компонентов). Если seq [i] является строкой, должны быть указаны имена функций, а seq [i] должен быть в именах функций.</target>
        </trans-unit>
        <trans-unit id="4c1ce6df0b81e7680bbf5092a9535a5fa0cb37a8" translate="yes" xml:space="preserve">
          <source>If set to &amp;ldquo;warn&amp;rdquo;, this acts as 0, but warnings are also raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b01ea458e6ed79ec076f21dd79564eecc3f7a882" translate="yes" xml:space="preserve">
          <source>If set to &amp;lsquo;random&amp;rsquo;, a random coefficient is updated every iteration rather than looping over features sequentially by default. This (setting to &amp;lsquo;random&amp;rsquo;) often leads to significantly faster convergence especially when tol is higher than 1e-4</source>
          <target state="translated">Если установлено значение &amp;laquo;random&amp;raquo;, случайный коэффициент обновляется каждую итерацию, а не последовательно по умолчанию перебирает функции. Это (установка на &amp;laquo;случайный&amp;raquo;) часто приводит к значительно более быстрой сходимости, особенно когда tol выше 1e-4.</target>
        </trans-unit>
        <trans-unit id="7a4374896942a67a58d05d59133607fc7483d7a2" translate="yes" xml:space="preserve">
          <source>If set to &amp;lsquo;random&amp;rsquo;, a random coefficient is updated every iteration rather than looping over features sequentially by default. This (setting to &amp;lsquo;random&amp;rsquo;) often leads to significantly faster convergence especially when tol is higher than 1e-4.</source>
          <target state="translated">Если установлено значение &amp;laquo;random&amp;raquo;, случайный коэффициент обновляется каждую итерацию, а не последовательно по умолчанию перебирает функции. Это (установка на &amp;laquo;случайный&amp;raquo;) часто приводит к значительно более быстрой сходимости, особенно когда tol выше 1e-4.</target>
        </trans-unit>
        <trans-unit id="b3732982402454957d1d44e2700684220ba9b532" translate="yes" xml:space="preserve">
          <source>If set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to &lt;code&gt;fit&lt;/code&gt; as initialization for &lt;code&gt;coef_&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; .</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d15f7a009cd3b6e81a757534913f0edc7a2b7947" translate="yes" xml:space="preserve">
          <source>If set to True, forces coefficients to be positive. (Only allowed when &lt;code&gt;y.ndim == 1&lt;/code&gt;).</source>
          <target state="translated">Если установлено значение True, заставляет коэффициенты быть положительными. (Разрешено только при &lt;code&gt;y.ndim == 1&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="6bd31584b0a279bb6a357ab195ba9534cb5cad4e" translate="yes" xml:space="preserve">
          <source>If set to True, the scores are averaged across all folds, and the coefs and the C that corresponds to the best score is taken, and a final refit is done using these parameters. Otherwise the coefs, intercepts and C that correspond to the best scores across folds are averaged.</source>
          <target state="translated">Если установлено значение True,баллы усредняются по всем сгибам,и сгибы и C,соответствующие лучшей оценке,берутся,и с помощью этих параметров производится окончательная доработка.В противном случае кофы,перехваты и C,которые соответствуют лучшим баллам по сгибам,усредняются.</target>
        </trans-unit>
        <trans-unit id="f3d43f9f7c9e3af1ca6eddc0268b8ee91bb07ee3" translate="yes" xml:space="preserve">
          <source>If set, scikit-learn will attempt to limit the size of temporary arrays to this number of MiB (per job when parallelised), often saving both computation time and memory on expensive operations that can be performed in chunks. Global default: 1024.</source>
          <target state="translated">Если установлено,scikit-learn попытается ограничить размер временных массивов этим количеством MiB (на одно задание при распараллеливании),часто экономя как время вычислений,так и память на дорогостоящих операциях,которые могут выполняться в кусках.Глобальное значение по умолчанию:1024.</target>
        </trans-unit>
        <trans-unit id="cd9d66e1ab8be1fe689482ddb0cbca43b44a3950" translate="yes" xml:space="preserve">
          <source>If strictly positive, stop reading any new line of data once the position in the file has reached the (offset + length) bytes threshold.</source>
          <target state="translated">В случае строгого положительного результата прекратите считывание любой новой строки данных,как только позиция в файле достигнет порога (смещение+длина)байтов.</target>
        </trans-unit>
        <trans-unit id="af99c20b0f1015ebcecc8bfb6a50ca848ab08d15" translate="yes" xml:space="preserve">
          <source>If string, specifies the path that will contain the data. If file-like, data will be written to f. f should be opened in binary mode.</source>
          <target state="translated">Если строка,укажите путь,который будет содержать данные.Если файл-подобный,то данные будут записываться в f.f должны быть открыты в бинарном режиме.</target>
        </trans-unit>
        <trans-unit id="d25cbbfb18995acebbdc8e788e3994e16b21b8ae" translate="yes" xml:space="preserve">
          <source>If sum_over_features is False shape is (n_samples_X * n_samples_Y, n_features) and D contains the componentwise L1 pairwise-distances (ie. absolute difference), else shape is (n_samples_X, n_samples_Y) and D contains the pairwise L1 distances.</source>
          <target state="translated">Если sum_over_features-это ложная форма (n_samples_X*n_samples_Y,n_features)и D содержит парные расстояния L1 (т.е.абсолютные различия),то иначе форма (n_samples_X,n_samples_Y)и D содержит парные расстояния L1.</target>
        </trans-unit>
        <trans-unit id="1979731cc29c616c5ac5593ab888192599b2d46b" translate="yes" xml:space="preserve">
          <source>If the &lt;code&gt;loss&lt;/code&gt; does not support probabilities.</source>
          <target state="translated">Если &lt;code&gt;loss&lt;/code&gt; не поддерживает вероятности.</target>
        </trans-unit>
        <trans-unit id="41f96f9118cd39448d94e68aca8aa6d327b368ef" translate="yes" xml:space="preserve">
          <source>If the algorithm is &amp;ldquo;deflation&amp;rdquo;, n_iter is the maximum number of iterations run across all components. Else they are just the number of iterations taken to converge.</source>
          <target state="translated">Если используется алгоритм &amp;laquo;дефляция&amp;raquo;, n_iter - это максимальное количество итераций, выполняемых для всех компонентов. В противном случае это просто количество итераций, необходимых для схождения.</target>
        </trans-unit>
        <trans-unit id="b72ab6a8a780a6da86f798b7381c54dc2236b80c" translate="yes" xml:space="preserve">
          <source>If the algorithm stops before fully converging (because of &lt;code&gt;tol&lt;/code&gt; of &lt;code&gt;max_iter&lt;/code&gt;), &lt;code&gt;labels_&lt;/code&gt; and &lt;code&gt;means_&lt;/code&gt; will not be consistent, i.e. the &lt;code&gt;means_&lt;/code&gt; will not be the means of the points in each cluster. Also, the estimator will reassign &lt;code&gt;labels_&lt;/code&gt; after the last iteration to make &lt;code&gt;labels_&lt;/code&gt; consistent with &lt;code&gt;predict&lt;/code&gt; on the training set.</source>
          <target state="translated">Если алгоритм останавливается перед полностью сходящимися (из - за &lt;code&gt;tol&lt;/code&gt; из &lt;code&gt;max_iter&lt;/code&gt; ), &lt;code&gt;labels_&lt;/code&gt; и &lt;code&gt;means_&lt;/code&gt; не будет соответствовать, то есть &lt;code&gt;means_&lt;/code&gt; не будет средством точек в каждом кластере. Кроме того , оценщик будет переназначить &lt;code&gt;labels_&lt;/code&gt; после последней итерации , чтобы &lt;code&gt;labels_&lt;/code&gt; в соответствии с &lt;code&gt;predict&lt;/code&gt; на обучающем наборе.</target>
        </trans-unit>
        <trans-unit id="12008b7aa6dad452411115d8236f3a855fd0fea9" translate="yes" xml:space="preserve">
          <source>If the algorithm stops before fully converging (because of &lt;code&gt;tol&lt;/code&gt; or &lt;code&gt;max_iter&lt;/code&gt;), &lt;code&gt;labels_&lt;/code&gt; and &lt;code&gt;cluster_centers_&lt;/code&gt; will not be consistent, i.e. the &lt;code&gt;cluster_centers_&lt;/code&gt; will not be the means of the points in each cluster. Also, the estimator will reassign &lt;code&gt;labels_&lt;/code&gt; after the last iteration to make &lt;code&gt;labels_&lt;/code&gt; consistent with &lt;code&gt;predict&lt;/code&gt; on the training set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4043c787702cc081c41f25b031d69ea98cf35c42" translate="yes" xml:space="preserve">
          <source>If the array is not symmetric, then a symmetrized version is returned. Optionally, a warning or exception is raised if the matrix is not symmetric.</source>
          <target state="translated">Если массив не симметричен,то возвращается симметричный вариант.Опционально,предупреждение или исключение поднимается,если матрица не симметрична.</target>
        </trans-unit>
        <trans-unit id="d4238935d45ce51eea0be6c47146a609e05c26ed" translate="yes" xml:space="preserve">
          <source>If the attributes are not found.</source>
          <target state="translated">Если атрибуты не найдены.</target>
        </trans-unit>
        <trans-unit id="10f86bc0a8ef8d94dd88200305e21d6ac290743f" translate="yes" xml:space="preserve">
          <source>If the classifier performs equally well on either class, this term reduces to the conventional accuracy (i.e., the number of correct predictions divided by the total number of predictions).</source>
          <target state="translated">Если классификатор одинаково хорошо работает на любом из классов,то этот термин сводится к обычной точности (т.е.к количеству правильных прогнозов,деленному на общее количество прогнозов).</target>
        </trans-unit>
        <trans-unit id="9d0651dbf433477af9dfe8c9482b03c0b28a7aea" translate="yes" xml:space="preserve">
          <source>If the data ordering is not arbitrary (e.g. samples with the same class label are contiguous), shuffling it first may be essential to get a meaningful cross- validation result. However, the opposite may be true if the samples are not independently and identically distributed. For example, if samples correspond to news articles, and are ordered by their time of publication, then shuffling the data will likely lead to a model that is overfit and an inflated validation score: it will be tested on samples that are artificially similar (close in time) to training samples.</source>
          <target state="translated">Если порядок следования данных не является произвольным (например,выборки с одинаковой меткой класса являются смежными),то для получения значимого результата перекрестной проверки может оказаться необходимым сначала перетасовать данные.Однако может быть и обратное,если выборки не являются независимыми и одинаково распределенными.Например,если выборки соответствуют новостным статьям и упорядочены по времени их публикации,то перетасовка данных,скорее всего,приведет к перевернутой модели и завышенной оценке валидации:она будет протестирована на выборках,искусственно схожих (близких по времени)с обучающими выборками.</target>
        </trans-unit>
        <trans-unit id="4fdc5debb409dcec7a673c288152f0ef6e4738ef" translate="yes" xml:space="preserve">
          <source>If the default value is passed, then &lt;code&gt;keepdims&lt;/code&gt; will not be passed through to the &lt;code&gt;mean&lt;/code&gt; method of sub-classes of &lt;code&gt;ndarray&lt;/code&gt;, however any non-default value will be. If the sub-class&amp;rsquo; method does not implement &lt;code&gt;keepdims&lt;/code&gt; any exceptions will be raised.</source>
          <target state="translated">Если передается значение по умолчанию, то &lt;code&gt;keepdims&lt;/code&gt; не будет передаваться &lt;code&gt;mean&lt;/code&gt; методу подклассов &lt;code&gt;ndarray&lt;/code&gt; , однако любое значение, отличное от значения по умолчанию, будет. Если метод подкласса не реализует &lt;code&gt;keepdims&lt;/code&gt; , будут возникать исключения.</target>
        </trans-unit>
        <trans-unit id="322da3aec4cc8f30cb7592a5692203180007e581" translate="yes" xml:space="preserve">
          <source>If the degree is 2 or 3, the method described in &amp;ldquo;Leveraging Sparsity to Speed Up Polynomial Feature Expansions of CSR Matrices Using K-Simplex Numbers&amp;rdquo; by Andrew Nystrom and John Hughes is used, which is much faster than the method used on CSC input. For this reason, a CSC input will be converted to CSR, and the output will be converted back to CSC prior to being returned, hence the preference of CSR.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca5777d1057fb92ff835301c12f93dc71bd51069" translate="yes" xml:space="preserve">
          <source>If the difference between the current prediction and the correct label is below this threshold, the model is not updated.</source>
          <target state="translated">Если разница между текущим прогнозом и правильной меткой ниже этого порога,модель не обновляется.</target>
        </trans-unit>
        <trans-unit id="54f187a0c12dbeb2b22455f8308653334a568512" translate="yes" xml:space="preserve">
          <source>If the estimator supports incremental learning, this will be used to speed up fitting for different training set sizes.</source>
          <target state="translated">Если сметный анализатор поддерживает поэтапное обучение,то это ускоряет подгонку для различных размеров учебных комплектов.</target>
        </trans-unit>
        <trans-unit id="28446974a089033b0f005a14dd2e5e7cde0d019d" translate="yes" xml:space="preserve">
          <source>If the file does not exist yet, it is downloaded from mldata.org .</source>
          <target state="translated">Если файл еще не существует,он скачивается с mldata.org .</target>
        </trans-unit>
        <trans-unit id="3377386ec971b5f97505ad0b0efacd641307a6b2" translate="yes" xml:space="preserve">
          <source>If the folder does not already exist, it is automatically created.</source>
          <target state="translated">Если папка еще не существует,она создается автоматически.</target>
        </trans-unit>
        <trans-unit id="bcf86cd76452a354a39a384d6cc008f0521fadc0" translate="yes" xml:space="preserve">
          <source>If the gradient norm is below this threshold, the optimization will be stopped.</source>
          <target state="translated">Если норма градиента ниже этого порога,то оптимизация будет остановлена.</target>
        </trans-unit>
        <trans-unit id="aaea0ac91de1101ebb5583d72a39edadc546a9ed" translate="yes" xml:space="preserve">
          <source>If the ground truth labels are not known, evaluation must be performed using the model itself. The Silhouette Coefficient (&lt;a href=&quot;generated/sklearn.metrics.silhouette_score#sklearn.metrics.silhouette_score&quot;&gt;&lt;code&gt;sklearn.metrics.silhouette_score&lt;/code&gt;&lt;/a&gt;) is an example of such an evaluation, where a higher Silhouette Coefficient score relates to a model with better defined clusters. The Silhouette Coefficient is defined for each sample and is composed of two scores:</source>
          <target state="translated">Если наземные метки достоверности неизвестны, оценка должна выполняться с использованием самой модели. Коэффициент силуэта ( &lt;a href=&quot;generated/sklearn.metrics.silhouette_score#sklearn.metrics.silhouette_score&quot;&gt; &lt;code&gt;sklearn.metrics.silhouette_score&lt;/code&gt; &lt;/a&gt; ) является примером такой оценки, где более высокий показатель коэффициента силуэта относится к модели с лучше определенными кластерами. Коэффициент силуэта определяется для каждого образца и состоит из двух баллов:</target>
        </trans-unit>
        <trans-unit id="f86f2c18ff62eced8e4c69ce5c4a60d3487f70e2" translate="yes" xml:space="preserve">
          <source>If the ground truth labels are not known, the Calinski-Harabasz index (&lt;a href=&quot;generated/sklearn.metrics.calinski_harabasz_score#sklearn.metrics.calinski_harabasz_score&quot;&gt;&lt;code&gt;sklearn.metrics.calinski_harabasz_score&lt;/code&gt;&lt;/a&gt;) - also known as the Variance Ratio Criterion - can be used to evaluate the model, where a higher Calinski-Harabasz score relates to a model with better defined clusters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb3f5944370bdcf362ff4bffb46e8bf1ded41ef1" translate="yes" xml:space="preserve">
          <source>If the ground truth labels are not known, the Calinski-Harabaz index (&lt;a href=&quot;generated/sklearn.metrics.calinski_harabaz_score#sklearn.metrics.calinski_harabaz_score&quot;&gt;&lt;code&gt;sklearn.metrics.calinski_harabaz_score&lt;/code&gt;&lt;/a&gt;) - also known as the Variance Ratio Criterion - can be used to evaluate the model, where a higher Calinski-Harabaz score relates to a model with better defined clusters.</source>
          <target state="translated">Если наземные метки достоверности неизвестны, индекс &lt;a href=&quot;generated/sklearn.metrics.calinski_harabaz_score#sklearn.metrics.calinski_harabaz_score&quot;&gt; &lt;code&gt;sklearn.metrics.calinski_harabaz_score&lt;/code&gt; &lt;/a&gt; -Харабаза ( sklearn.metrics.calinski_harabaz_score ) - также известный как критерий отношения дисперсии - можно использовать для оценки модели, где более высокий балл Калински-Харабаза относится к модели с лучше определенные кластеры.</target>
        </trans-unit>
        <trans-unit id="a4a519d35f95c18e319df7e8878b98f013f9bd44" translate="yes" xml:space="preserve">
          <source>If the ground truth labels are not known, the Davies-Bouldin index (&lt;a href=&quot;generated/sklearn.metrics.davies_bouldin_score#sklearn.metrics.davies_bouldin_score&quot;&gt;&lt;code&gt;sklearn.metrics.davies_bouldin_score&lt;/code&gt;&lt;/a&gt;) can be used to evaluate the model, where a lower Davies-Bouldin index relates to a model with better separation between the clusters.</source>
          <target state="translated">Если наземные метки истинности неизвестны, индекс Дэвиса- &lt;a href=&quot;generated/sklearn.metrics.davies_bouldin_score#sklearn.metrics.davies_bouldin_score&quot;&gt; &lt;code&gt;sklearn.metrics.davies_bouldin_score&lt;/code&gt; &lt;/a&gt; ( sklearn.metrics.davies_bouldin_score ) можно использовать для оценки модели, где более низкий индекс Дэвиса-Болдина относится к модели с лучшим разделением между кластерами.</target>
        </trans-unit>
        <trans-unit id="7ce6861d9ec6948a6bc8aef858e97abae7ed0654" translate="yes" xml:space="preserve">
          <source>If the input is a sparse matrix, only the non-zero values are subject to update by the Binarizer class.</source>
          <target state="translated">Если вход является разреженной матрицей,то только ненулевые значения подлежат обновлению классом Бинаризатор.</target>
        </trans-unit>
        <trans-unit id="c10a8d9d8c40f9f50dafe36b727f5b47e7075f19" translate="yes" xml:space="preserve">
          <source>If the input matrix X is very sparse, it is recommended to convert to sparse &lt;code&gt;csc_matrix&lt;/code&gt; before calling fit and sparse &lt;code&gt;csr_matrix&lt;/code&gt; before calling predict. Training time can be orders of magnitude faster for a sparse matrix input compared to a dense matrix when features have zero values in most of the samples.</source>
          <target state="translated">Если входная матрица X очень разреженная, рекомендуется преобразовать в разреженную &lt;code&gt;csc_matrix&lt;/code&gt; перед вызовом подгонки и разреженную &lt;code&gt;csr_matrix&lt;/code&gt; перед вызовом предсказания. Время обучения может быть на порядки меньше для входной разреженной матрицы по сравнению с плотной матрицей, когда функции имеют нулевые значения в большинстве выборок.</target>
        </trans-unit>
        <trans-unit id="661cb29a3f5fe68fda8ea5f8c53273efb7753ce1" translate="yes" xml:space="preserve">
          <source>If the labels are encoded with +1 and -1, \(y\): is the true value, and \(w\) is the predicted decisions as output by &lt;code&gt;decision_function&lt;/code&gt;, then the hinge loss is defined as:</source>
          <target state="translated">Если метки закодированы с помощью +1 и -1, \ (y \): - истинное значение, а \ (w \) - это предсказанные решения, полученные с помощью функции &lt;code&gt;decision_function&lt;/code&gt; , то потеря на шарнире определяется как:</target>
        </trans-unit>
        <trans-unit id="30e7605353fedb22ff0c25c7418abbab28137e70" translate="yes" xml:space="preserve">
          <source>If the loss on a sample is greater than the &lt;code&gt;residual_threshold&lt;/code&gt;, then this sample is classified as an outlier.</source>
          <target state="translated">Если потери в выборке больше, чем &lt;code&gt;residual_threshold&lt;/code&gt; , то эта выборка классифицируется как выброс.</target>
        </trans-unit>
        <trans-unit id="fd47c1f065810b1b45f0d8d994aa0a4ff29505d4" translate="yes" xml:space="preserve">
          <source>If the metric constructor parameter is &amp;ldquo;precomputed&amp;rdquo;, X is assumed to be the distance matrix between the data to be predicted and &lt;code&gt;self.centroids_&lt;/code&gt;.</source>
          <target state="translated">Если параметр конструктора метрики &amp;laquo;предварительно вычислен&amp;raquo;, предполагается, что X - это матрица расстояний между данными, которые нужно прогнозировать, и &lt;code&gt;self.centroids_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c8476d320358236ab03a9b2e5775d6207658d4f7" translate="yes" xml:space="preserve">
          <source>If the metric is &amp;lsquo;precomputed&amp;rsquo; X must be a square distance matrix. Otherwise it contains a sample per row.</source>
          <target state="translated">Если метрика &amp;laquo;вычислена заранее&amp;raquo;, X должна быть квадратной матрицей расстояний. В противном случае он содержит образец для каждой строки.</target>
        </trans-unit>
        <trans-unit id="ed2846275337b6c05f70ce353bc177c3fd2fc1b0" translate="yes" xml:space="preserve">
          <source>If the metric is &amp;lsquo;precomputed&amp;rsquo; X must be a square distance matrix. Otherwise it contains a sample per row. If the method is &amp;lsquo;exact&amp;rsquo;, X may be a sparse matrix of type &amp;lsquo;csr&amp;rsquo;, &amp;lsquo;csc&amp;rsquo; or &amp;lsquo;coo&amp;rsquo;.</source>
          <target state="translated">Если метрика &amp;laquo;вычислена заранее&amp;raquo;, X должна быть квадратной матрицей расстояний. В противном случае он содержит образец для каждой строки. Если метод &amp;laquo;точный&amp;raquo;, X может быть разреженной матрицей типа &amp;laquo;csr&amp;raquo;, &amp;laquo;csc&amp;raquo; или &amp;laquo;coo&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="3a27e115b0c223dd4eebc69d8c1ee49334684c4e" translate="yes" xml:space="preserve">
          <source>If the metric is &amp;lsquo;precomputed&amp;rsquo; X must be a square distance matrix. Otherwise it contains a sample per row. If the method is &amp;lsquo;exact&amp;rsquo;, X may be a sparse matrix of type &amp;lsquo;csr&amp;rsquo;, &amp;lsquo;csc&amp;rsquo; or &amp;lsquo;coo&amp;rsquo;. If the method is &amp;lsquo;barnes_hut&amp;rsquo; and the metric is &amp;lsquo;precomputed&amp;rsquo;, X may be a precomputed sparse graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be2b4ccc2ee21bcc622b72ad8a09e29905f86d22" translate="yes" xml:space="preserve">
          <source>If the number of features is \(p\), you now require \(n \sim 1/d^p\) points. Let&amp;rsquo;s say that we require 10 points in one dimension: now \(10^p\) points are required in \(p\) dimensions to pave the \([0, 1]\) space. As \(p\) becomes large, the number of training points required for a good estimator grows exponentially.</source>
          <target state="translated">Если количество функций равно \ (p \), вам теперь требуется \ (n \ sim 1 / d ^ p \) очков. Допустим, нам требуется 10 точек в одном измерении: теперь требуется \ (10 ​​^ p \) точек в измерениях \ (p \), чтобы проложить пространство \ ([0, 1] \). По мере того как \ (p \) становится большим, количество обучающих точек, необходимых для хорошей оценки, растет экспоненциально.</target>
        </trans-unit>
        <trans-unit id="31f6fadae8fdb5e25318685f0dd36c90a3234b90" translate="yes" xml:space="preserve">
          <source>If the number of features is much greater than the number of samples, avoid over-fitting in choosing &lt;a href=&quot;#svm-kernels&quot;&gt;Kernel functions&lt;/a&gt; and regularization term is crucial.</source>
          <target state="translated">Если количество функций намного превышает количество выборок, избегайте чрезмерной подгонки при выборе &lt;a href=&quot;#svm-kernels&quot;&gt;функций ядра,&lt;/a&gt; и термин регуляризации имеет решающее значение.</target>
        </trans-unit>
        <trans-unit id="421f2017551080d266c05ad587f0ba1ecff6bff8" translate="yes" xml:space="preserve">
          <source>If the number of instances of data needs to be reduced, or if one wants a large number of subclusters either as a preprocessing step or otherwise, Birch is more useful than MiniBatchKMeans.</source>
          <target state="translated">Если необходимо уменьшить количество экземпляров данных,или если необходимо большое количество подкластеров,либо в качестве этапа предварительной обработки,либо иным образом,то Birch более полезен,чем MiniBatchKMeans.</target>
        </trans-unit>
        <trans-unit id="0169ea68b458a3b315ac7acca32e943f8bdb1bed" translate="yes" xml:space="preserve">
          <source>If the option chosen is &amp;lsquo;ovr&amp;rsquo;, then a binary problem is fit for each label. For &amp;lsquo;multinomial&amp;rsquo; the loss minimised is the multinomial loss fit across the entire probability distribution, &lt;em&gt;even when the data is binary&lt;/em&gt;. &amp;lsquo;multinomial&amp;rsquo; is unavailable when solver=&amp;rsquo;liblinear&amp;rsquo;. &amp;lsquo;auto&amp;rsquo; selects &amp;lsquo;ovr&amp;rsquo; if the data is binary, or if solver=&amp;rsquo;liblinear&amp;rsquo;, and otherwise selects &amp;lsquo;multinomial&amp;rsquo;.</source>
          <target state="translated">Если выбран вариант &amp;laquo;ovr&amp;raquo;, то для каждой метки подходит двоичная задача. Для &amp;laquo;полиномиального&amp;raquo; минимизируемые потери - это полиномиальные потери, соответствующие всему распределению вероятностей, &lt;em&gt;даже если данные являются двоичными&lt;/em&gt; . 'multinomial' недоступен, если solver = 'liblinear'. 'auto' выбирает 'ovr', если данные являются двоичными, или если solver = 'liblinear', а в противном случае выбирает 'multinomial'.</target>
        </trans-unit>
        <trans-unit id="e56253ed1e137739144617c8f91af1433e314b57" translate="yes" xml:space="preserve">
          <source>If the output of the different transformers contains sparse matrices, these will be stacked as a sparse matrix if the overall density is lower than this value. Use &lt;code&gt;sparse_threshold=0&lt;/code&gt; to always return dense. When the transformed output consists of all dense data, the stacked result will be dense, and this keyword will be ignored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ff404c7c7b751e78382edbf95c1647019d00b38" translate="yes" xml:space="preserve">
          <source>If the parameter&amp;rsquo;s type does not match the desired type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="74c8a6dddf7307f96841c8e0079e93341eb05526" translate="yes" xml:space="preserve">
          <source>If the parameter&amp;rsquo;s value violates the given bounds.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb7bde2a134f67333f646adb3cb422fdb3b0a619" translate="yes" xml:space="preserve">
          <source>If the prediction task is to classify the observations in a set of finite labels, in other words to &amp;ldquo;name&amp;rdquo; the objects observed, the task is said to be a &lt;strong&gt;classification&lt;/strong&gt; task. On the other hand, if the goal is to predict a continuous target variable, it is said to be a &lt;strong&gt;regression&lt;/strong&gt; task.</source>
          <target state="translated">Если задача прогнозирования состоит в том, чтобы классифицировать наблюдения по набору конечных меток, другими словами, чтобы &amp;laquo;назвать&amp;raquo; наблюдаемые объекты, эта задача называется задачей &lt;strong&gt;классификации&lt;/strong&gt; . С другой стороны, если цель состоит в том, чтобы предсказать непрерывную целевую переменную, это называется задачей &lt;strong&gt;регрессии&lt;/strong&gt; .</target>
        </trans-unit>
        <trans-unit id="c305135e1b17987e86652a7910deafacf0f5dc9d" translate="yes" xml:space="preserve">
          <source>If the pyamg package is installed, it is used: this greatly speeds up computation.</source>
          <target state="translated">Если установлен пакет pyamg,то он используется:это значительно ускоряет вычисления.</target>
        </trans-unit>
        <trans-unit id="04f07265ff7d7b70145be5aec52784e1b24d6f09" translate="yes" xml:space="preserve">
          <source>If the radius of the subcluster obtained by merging the new sample and the nearest subcluster is greater than the square of the threshold and if the number of subclusters is greater than the branching factor, then a space is temporarily allocated to this new sample. The two farthest subclusters are taken and the subclusters are divided into two groups on the basis of the distance between these subclusters.</source>
          <target state="translated">Если радиус подкластера,полученный при слиянии новой выборки и ближайшего подкластера,больше квадрата порога и если количество подкластеров больше фактора разветвления,то для этой новой выборки временно выделяется место.Берется два самых дальних подкластера,и подкластеры делятся на две группы в зависимости от расстояния между этими подкластерами.</target>
        </trans-unit>
        <trans-unit id="41eef1b8a501219131b2619b097a82294e78c28a" translate="yes" xml:space="preserve">
          <source>If the samples are weighted, it will be easier to optimize the tree structure using weight-based pre-pruning criterion such as &lt;code&gt;min_weight_fraction_leaf&lt;/code&gt;, which ensure that leaf nodes contain at least a fraction of the overall sum of the sample weights.</source>
          <target state="translated">Если выборки взвешены, будет проще оптимизировать древовидную структуру с использованием критерия предварительной отсечения на основе веса, такого как &lt;code&gt;min_weight_fraction_leaf&lt;/code&gt; , который гарантирует, что конечные узлы содержат по крайней мере часть общей суммы весов выборки.</target>
        </trans-unit>
        <trans-unit id="0c1baaebbfab363e25ace0c6b6ee91539fab116b" translate="yes" xml:space="preserve">
          <source>If the selected solver is &amp;lsquo;L-BFGS&amp;rsquo;, training does not support online nor mini-batch learning.</source>
          <target state="translated">Если выбран решатель &amp;laquo;L-BFGS&amp;raquo;, обучение не поддерживает ни онлайн, ни мини-пакетное обучение.</target>
        </trans-unit>
        <trans-unit id="6b79b273c5ccf0e85d810ff5a4ad56e9102a13be" translate="yes" xml:space="preserve">
          <source>If the target is a continuous value, then for node \(m\), representing a region \(R_m\) with \(N_m\) observations, common criteria to minimise as for determining locations for future splits are Mean Squared Error, which minimizes the L2 error using mean values at terminal nodes, and Mean Absolute Error, which minimizes the L1 error using median values at terminal nodes.</source>
          <target state="translated">Если целью является непрерывное значение,то для узла \(m\),представляющего регион \(R_m\)с наблюдениями \(N_m\),общими критериями минимизации при определении мест для будущих разбиений являются Ошибка среднего квадрата,которая минимизирует ошибку L2,используя средние значения в терминальных узлах,и Ошибка среднего абсолютного значения,которая минимизирует ошибку L1,используя средние значения в терминальных узлах.</target>
        </trans-unit>
        <trans-unit id="43d2fac91a90af78192c1e9cb5f608e633304262" translate="yes" xml:space="preserve">
          <source>If the target values \(y\) are counts (non-negative integer valued) or relative frequencies (non-negative), you might use a Poisson deviance with log-link.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25b233fcf730d262746a1d2c5c4f20ca63e89053" translate="yes" xml:space="preserve">
          <source>If the target values are positive valued and skewed, you might try a Gamma deviance with log-link.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73b808b1b5912c4df231c6d6d8790651299cc5e0" translate="yes" xml:space="preserve">
          <source>If the target values seem to be heavier tailed than a Gamma distribution, you might try an Inverse Gaussian deviance (or even higher variance powers of the Tweedie family).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd360b0d17d9758c91116a373249c96c3c493365" translate="yes" xml:space="preserve">
          <source>If the text is in a mish-mash of encodings that is simply too hard to sort out (which is the case for the 20 Newsgroups dataset), you can fall back on a simple single-byte encoding such as &lt;code&gt;latin-1&lt;/code&gt;. Some text may display incorrectly, but at least the same sequence of bytes will always represent the same feature.</source>
          <target state="translated">Если текст представляет собой мешанину кодировок, которую просто слишком сложно отсортировать (как в случае набора данных 20 Newsgroups), вы можете вернуться к простой однобайтовой кодировке, такой как &lt;code&gt;latin-1&lt;/code&gt; . Некоторый текст может отображаться неправильно, но, по крайней мере, одна и та же последовательность байтов всегда будет представлять одну и ту же функцию.</target>
        </trans-unit>
        <trans-unit id="21286b430a50cd4c4f50df67c996d4b5b475416f" translate="yes" xml:space="preserve">
          <source>If the text you are loading is not actually encoded with UTF-8, however, you will get a &lt;code&gt;UnicodeDecodeError&lt;/code&gt;. The vectorizers can be told to be silent about decoding errors by setting the &lt;code&gt;decode_error&lt;/code&gt; parameter to either &lt;code&gt;&quot;ignore&quot;&lt;/code&gt; or &lt;code&gt;&quot;replace&quot;&lt;/code&gt;. See the documentation for the Python function &lt;code&gt;bytes.decode&lt;/code&gt; for more details (type &lt;code&gt;help(bytes.decode)&lt;/code&gt; at the Python prompt).</source>
          <target state="translated">Однако если загружаемый текст на самом деле не закодирован с помощью UTF-8, вы получите &lt;code&gt;UnicodeDecodeError&lt;/code&gt; . Можно указать векторизаторам молчать об ошибках декодирования, установив для параметра &lt;code&gt;decode_error&lt;/code&gt; значение &lt;code&gt;&quot;ignore&quot;&lt;/code&gt; или &lt;code&gt;&quot;replace&quot;&lt;/code&gt; . Дополнительные сведения см. В документации по функции Python &lt;code&gt;bytes.decode&lt;/code&gt; (введите &lt;code&gt;help(bytes.decode)&lt;/code&gt; в командной строке Python).</target>
        </trans-unit>
        <trans-unit id="13a9f813159d9e6258a164870cb1dc6a301dddd5" translate="yes" xml:space="preserve">
          <source>If the training score and the validation score are both low, the estimator will be underfitting. If the training score is high and the validation score is low, the estimator is overfitting and otherwise it is working very well. A low training score and a high validation score is usually not possible. All three cases can be found in the plot below where we vary the parameter \(\gamma\) of an SVM on the digits dataset.</source>
          <target state="translated">Если и оценка обучения,и оценка валидации низкие,то оценщик будет недооценен.Если и оценка тренинга,и оценка валидации низкие,то оценщик переподходит,и в противном случае он работает очень хорошо.Низкий балл обучения и высокий балл валидации обычно невозможны.Все три случая можно найти на графике ниже,где мы варьируем параметр \(\gamma\)SVM в наборе цифр данных.</target>
        </trans-unit>
        <trans-unit id="80e789647361ff21671194a00300fe312dc530d2" translate="yes" xml:space="preserve">
          <source>If the transformed output consists of a mix of sparse and dense data, it will be stacked as a sparse matrix if the density is lower than this value. Use &lt;code&gt;sparse_threshold=0&lt;/code&gt; to always return dense. When the transformed output consists of all sparse or all dense data, the stacked result will be sparse or dense, respectively, and this keyword will be ignored.</source>
          <target state="translated">Если преобразованный вывод состоит из смеси разреженных и плотных данных, он будет сложен как разреженная матрица, если плотность ниже этого значения. Используйте &lt;code&gt;sparse_threshold=0&lt;/code&gt; , чтобы всегда возвращать плотность. Когда преобразованный вывод состоит из всех разреженных или всех плотных данных, сложенный результат будет разреженным или плотным, соответственно, и это ключевое слово будет проигнорировано.</target>
        </trans-unit>
        <trans-unit id="efca83041c066057e65d83989c4190b74b69dba6" translate="yes" xml:space="preserve">
          <source>If the underlying graph has nodes with much more connections than the average node, the algorithm will miss some of these connections.</source>
          <target state="translated">Если на нижеприведенном графике есть узлы с гораздо большим количеством соединений,чем в среднем по узлу,алгоритм пропустит некоторые из этих соединений.</target>
        </trans-unit>
        <trans-unit id="27f470c8c1d74aa01f92e63860f4d2b9149dd0bb" translate="yes" xml:space="preserve">
          <source>If there are few data points per dimension, noise in the observations induces high variance:</source>
          <target state="translated">При небольшом количестве точек данных на единицу измерения шум в наблюдениях вызывает высокую дисперсию:</target>
        </trans-unit>
        <trans-unit id="fbaec65eed1139944f6f906201326eaef7bc4d08" translate="yes" xml:space="preserve">
          <source>If there are more than two classes, \(f(x)\) itself would be a vector of size (n_classes,). Instead of passing through logistic function, it passes through the softmax function, which is written as,</source>
          <target state="translated">Если существует более двух классов,то \(f(x)\)сам по себе будет вектором размера (n_classes,).Вместо прохождения через логистическую функцию,она проходит через софтмакс-функцию,которая написана как,</target>
        </trans-unit>
        <trans-unit id="e2c9b002eac60ce02e4a3cafb47196266855c43e" translate="yes" xml:space="preserve">
          <source>If there are more than two labels, &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt;&lt;code&gt;hinge_loss&lt;/code&gt;&lt;/a&gt; uses a multiclass variant due to Crammer &amp;amp; Singer. &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume2/crammer01a/crammer01a.pdf&quot;&gt;Here&lt;/a&gt; is the paper describing it.</source>
          <target state="translated">Если меток больше двух, &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt; &lt;code&gt;hinge_loss&lt;/code&gt; &lt;/a&gt; использует мультиклассовый вариант из-за Crammer &amp;amp; Singer. &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume2/crammer01a/crammer01a.pdf&quot;&gt;Вот&lt;/a&gt; статья, описывающая это.</target>
        </trans-unit>
        <trans-unit id="362b6e0ad023f937918b9ce5c294c8243f2c8ea1" translate="yes" xml:space="preserve">
          <source>If there is a possibility that the training data might have missing categorical features, it can often be better to specify &lt;code&gt;handle_unknown='ignore'&lt;/code&gt; instead of setting the &lt;code&gt;categories&lt;/code&gt; manually as above. When &lt;code&gt;handle_unknown='ignore'&lt;/code&gt; is specified and unknown categories are encountered during transform, no error will be raised but the resulting one-hot encoded columns for this feature will be all zeros (&lt;code&gt;handle_unknown='ignore'&lt;/code&gt; is only supported for one-hot encoding):</source>
          <target state="translated">Если есть вероятность, что в обучающих данных могут отсутствовать категориальные особенности, часто бывает лучше указать &lt;code&gt;handle_unknown='ignore'&lt;/code&gt; вместо того, чтобы устанавливать &lt;code&gt;categories&lt;/code&gt; вручную, как указано выше. Когда &lt;code&gt;handle_unknown='ignore'&lt;/code&gt; и во время преобразования встречаются неизвестные категории, ошибка не возникает, но в результирующих столбцах с горячим кодированием для этой функции будут все нули ( &lt;code&gt;handle_unknown='ignore'&lt;/code&gt; поддерживается только для горячего кодирования ):</target>
        </trans-unit>
        <trans-unit id="76c3aee0f8dcd7757eeddd2a91b271bc2108fb17" translate="yes" xml:space="preserve">
          <source>If there is more than one such value, only the first is returned. The bin-count for the modal bins is also returned.</source>
          <target state="translated">Если таких значений больше одного,возвращается только первое.Возвращается также счетчик бина для модальных бинов.</target>
        </trans-unit>
        <trans-unit id="e4599c6e53b844db2376ed9e56ed7b49e63c6ec3" translate="yes" xml:space="preserve">
          <source>If this is a tuple of ints, a mean is performed over multiple axes, instead of a single axis or all the axes as before.</source>
          <target state="translated">Если это кортеж из интв,то среднее значение выполняется по нескольким осям,а не по одной оси или по всем осям,как раньше.</target>
        </trans-unit>
        <trans-unit id="015e500928e7c3f86f2c9b5121c746246fcd7a9f" translate="yes" xml:space="preserve">
          <source>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array.</source>
          <target state="translated">Если установлено значение True,то редуцированные оси останутся в результате в виде размеров с первым размером.При выборе этого параметра результат будет корректно отображаться на входном массиве.</target>
        </trans-unit>
        <trans-unit id="1d47783a4de427039b4db643f305b3dd195e7ba2" translate="yes" xml:space="preserve">
          <source>If this split node has a parent subcluster and there is room for a new subcluster, then the parent is split into two. If there is no room, then this node is again split into two and the process is continued recursively, till it reaches the root.</source>
          <target state="translated">Если этот разделенный узел имеет родительский подкластер и есть место для нового подкластера,то родительский подкластер делится на два.Если места нет,то этот узел снова разбивается на два и процесс продолжается рекурсивно,пока не достигнет корня.</target>
        </trans-unit>
        <trans-unit id="012f5a7e85e6e4a424dae20b5f0c103c4fa516ee" translate="yes" xml:space="preserve">
          <source>If true (default), use a breadth-first approach to the problem. Otherwise use a depth-first approach.</source>
          <target state="translated">Если переменная имеет значение true (по умолчанию),используйте широкий подход к проблеме.В противном случае используйте подход по глубине.</target>
        </trans-unit>
        <trans-unit id="5f57fd46a52f081b17c9c11ebb2ef30582e94549" translate="yes" xml:space="preserve">
          <source>If true the classification weights will be exported on each leaf. The classification weights are the number of samples each class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cec7c6586dbaf8eb8cda6633d2caddbd361cde5b" translate="yes" xml:space="preserve">
          <source>If true, &lt;code&gt;decision_function_shape='ovr'&lt;/code&gt;, and number of classes &amp;gt; 2, &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict&quot;&gt;predict&lt;/a&gt; will break ties according to the confidence values of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt;; otherwise the first class among the tied classes is returned. Please note that breaking ties comes at a relatively high computational cost compared to a simple predict.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8002efc50268110232cc0ffbdad97c50440caadd" translate="yes" xml:space="preserve">
          <source>If true, X and y will be centered.</source>
          <target state="translated">Если это правда,то Х и У будут по центру.</target>
        </trans-unit>
        <trans-unit id="de73b79cb6d725781d21d3fce59be150e3f40a4c" translate="yes" xml:space="preserve">
          <source>If true, initial kernel locations are not locations of all points, but rather the location of the discretized version of points, where points are binned onto a grid whose coarseness corresponds to the bandwidth. Setting this option to True will speed up the algorithm because fewer seeds will be initialized. Ignored if seeds argument is not None.</source>
          <target state="translated">Если верно,то исходные местоположения ядра-это местоположения не всех точек,а дискретизированной версии точек,где точки привязываются к сетке,чья крупность соответствует полосе пропускания.Установка этого параметра в значение True ускорит работу алгоритма,так как будет инициализировано меньшее количество семян.Игнорируется,если аргумент &quot;семена&quot; не равен None.</target>
        </trans-unit>
        <trans-unit id="8e21ac3d3be6bbf299e61e387ddc28e4aa0e4b76" translate="yes" xml:space="preserve">
          <source>If true, initial kernel locations are not locations of all points, but rather the location of the discretized version of points, where points are binned onto a grid whose coarseness corresponds to the bandwidth. Setting this option to True will speed up the algorithm because fewer seeds will be initialized. The default value is False. Ignored if seeds argument is not None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="382a329c7d03e3dc0838d8f846116bb309725e41" translate="yes" xml:space="preserve">
          <source>If true, initial kernel locations are not locations of all points, but rather the location of the discretized version of points, where points are binned onto a grid whose coarseness corresponds to the bandwidth. Setting this option to True will speed up the algorithm because fewer seeds will be initialized. default value: False Ignored if seeds argument is not None.</source>
          <target state="translated">Если верно,то исходные местоположения ядра-это местоположения не всех точек,а дискретизированной версии точек,где точки привязываются к сетке,чья крупность соответствует полосе пропускания.Установка этого параметра в значение True ускорит работу алгоритма,так как будет инициализировано меньшее количество семян.значение по умолчанию:False Ignored if seeds argument is not None.</target>
        </trans-unit>
        <trans-unit id="5f8f1503f4ad4447aabcfddb9ab2a5dcd7bfde79" translate="yes" xml:space="preserve">
          <source>If true, only interaction features are produced: features that are products of at most &lt;code&gt;degree&lt;/code&gt;&lt;em&gt;distinct&lt;/em&gt; input features (so not &lt;code&gt;x[1] ** 2&lt;/code&gt;, &lt;code&gt;x[0] * x[2] ** 3&lt;/code&gt;, etc.).</source>
          <target state="translated">Если это правда, только функция взаимодействия производится: функции , которые являются продуктами в большинстве &lt;code&gt;degree&lt;/code&gt; &lt;em&gt;различных&lt;/em&gt; функций ввода (поэтому не &lt;code&gt;x[1] ** 2&lt;/code&gt; , &lt;code&gt;x[0] * x[2] ** 3&lt;/code&gt; и т.д.).</target>
        </trans-unit>
        <trans-unit id="2d6ce18ffe19be253728c95b7f8882b85215b418" translate="yes" xml:space="preserve">
          <source>If true, randomize the order of coordinates in the CD solver.</source>
          <target state="translated">Если верно,то порядок координат в CD-решателе должен быть рандомизирован.</target>
        </trans-unit>
        <trans-unit id="c9d7c7ecbdd08be425848806cc6f9d68c29d7323" translate="yes" xml:space="preserve">
          <source>If true, return the mean loss per sample. Otherwise, return the sum of the per-sample losses.</source>
          <target state="translated">Если верно,верните средние потери на образец.В противном случае верните сумму потерь на выборку.</target>
        </trans-unit>
        <trans-unit id="6d32e9cabd3e10e0279ad9dd2b7c71514057bf52" translate="yes" xml:space="preserve">
          <source>If true, then all points are clustered, even those orphans that are not within any kernel. Orphans are assigned to the nearest kernel. If false, then orphans are given cluster label -1.</source>
          <target state="translated">Если это так,то все точки сгруппированы,даже те сироты,которые не входят ни в одно ядро.Сироты приписываются к ближайшему ядру.Если фальшивка,то сиротам присваивается ярлык кластера -1.</target>
        </trans-unit>
        <trans-unit id="87535a59e28d16a49b32c83a6882f2aefd67503d" translate="yes" xml:space="preserve">
          <source>If true, use a dualtree algorithm. Otherwise, use a single-tree algorithm. Dual tree algorithms can have better scaling for large N.</source>
          <target state="translated">Если это так,используйте алгоритм двойного дерева.В противном случае используйте алгоритм с одним деревом.Алгоритмы с двумя деревьями могут иметь лучшее масштабирование для больших N.</target>
        </trans-unit>
        <trans-unit id="1f1b5d26ff8a3e05067cc01bd3cc7a0f425c7062" translate="yes" xml:space="preserve">
          <source>If two features are almost equally correlated with the target, then their coefficients should increase at approximately the same rate. The algorithm thus behaves as intuition would expect, and also is more stable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a62f22814f97612f53d5c62d8ea50a484acea3fc" translate="yes" xml:space="preserve">
          <source>If two variables are almost equally correlated with the response, then their coefficients should increase at approximately the same rate. The algorithm thus behaves as intuition would expect, and also is more stable.</source>
          <target state="translated">Если две переменные почти одинаково коррелируют с откликом,то их коэффициенты должны увеличиваться примерно с одинаковой скоростью.Таким образом,алгоритм ведет себя так,как ожидала бы интуиция,а также более стабилен.</target>
        </trans-unit>
        <trans-unit id="c6d813716240a58cb1e341ee096ed78ff4d17824" translate="yes" xml:space="preserve">
          <source>If verbose is True, the objective function and dual gap are plotted at each iteration.</source>
          <target state="translated">Если многословие-True,то объективная функция и двойной промежуток строятся на каждой итерации.</target>
        </trans-unit>
        <trans-unit id="c845cf733c967b921d034159fbd6e6d551e8f5a1" translate="yes" xml:space="preserve">
          <source>If verbose is True, the objective function and dual gap are printed at each iteration.</source>
          <target state="translated">Если многословие-True,то функция объектива и двойной пробел печатаются на каждой итерации.</target>
        </trans-unit>
        <trans-unit id="d04bb65f95446e17ac813ad52d517cc52bee8bef" translate="yes" xml:space="preserve">
          <source>If verbose is True, the objective function and duality gap are printed at each iteration.</source>
          <target state="translated">Если многословие-True,то на каждой итерации печатается объективная функция и пробел двойственности.</target>
        </trans-unit>
        <trans-unit id="c297e2c2dea63aea70529d05594e08d33ba95930" translate="yes" xml:space="preserve">
          <source>If warm-starts are enabled, the solution of the last Newton iteration on the Laplace approximation of the posterior mode is used as initialization for the next call of _posterior_mode(). This can speed up convergence when _posterior_mode is called several times on similar problems as in hyperparameter optimization. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Если включен теплый старт, решение последней ньютоновской итерации аппроксимации Лапласа апостериорной моды используется в качестве инициализации для следующего вызова _posterior_mode (). Это может ускорить сходимость, если _posterior_mode вызывается несколько раз для решения тех же задач, что и при оптимизации гиперпараметров. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;Глоссарий&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="250e3ab5ccbd8ff9f61320148d394ace048df253" translate="yes" xml:space="preserve">
          <source>If warm-starts are enabled, the solution of the last Newton iteration on the Laplace approximation of the posterior mode is used as initialization for the next call of _posterior_mode(). This can speed up convergence when _posterior_mode is called several times on similar problems as in hyperparameter optimization. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0beda1307d8fba8bf455ad043421d0e1b5743334" translate="yes" xml:space="preserve">
          <source>If we consider the loss function to be the individual error per sample, then the data-fit term, or the sum of the error for each sample, will increase as we add more samples. The penalization term, however, will not increase.</source>
          <target state="translated">Если рассматривать функцию потерь как индивидуальную ошибку для каждой выборки,то при добавлении большего количества выборок увеличивается срок годности данных или сумма ошибки для каждой выборки.Однако срок пенизации не увеличится.</target>
        </trans-unit>
        <trans-unit id="232b0b83965c86185ba5cb4047fca7ca1eb2e5e8" translate="yes" xml:space="preserve">
          <source>If we define &lt;code&gt;s = 1 / density&lt;/code&gt;, the elements of the random matrix are drawn from</source>
          <target state="translated">Если мы определим &lt;code&gt;s = 1 / density&lt;/code&gt; , элементы случайной матрицы будут взяты из</target>
        </trans-unit>
        <trans-unit id="de1968292a81bf57ac7d922cf400e8863c649aea" translate="yes" xml:space="preserve">
          <source>If we increase &lt;code&gt;power&lt;/code&gt; to 1,:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1427e0ae27c6ada10257117ddf3e602836e812e6" translate="yes" xml:space="preserve">
          <source>If we note &lt;code&gt;s = 1 / density&lt;/code&gt; the components of the random matrix are drawn from:</source>
          <target state="translated">Если мы отметим &lt;code&gt;s = 1 / density&lt;/code&gt; компоненты случайной матрицы берутся из:</target>
        </trans-unit>
        <trans-unit id="f9cbc4d2964857d1865d4f91b696f12d3cce3cff" translate="yes" xml:space="preserve">
          <source>If we note \(n_{\max} = \max(n_{\mathrm{samples}}, n_{\mathrm{features}})\) and \(n_{\min} = \min(n_{\mathrm{samples}}, n_{\mathrm{features}})\), the time complexity of the randomized &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; is \(O(n_{\max}^2 \cdot n_{\mathrm{components}})\) instead of \(O(n_{\max}^2 \cdot n_{\min})\) for the exact method implemented in &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Если мы заметим \ (n _ {\ max} = \ max (n _ {\ mathrm {samples}}, n _ {\ mathrm {features}}) \) и \ (n _ {\ min} = \ min (n _ {\ mathrm {samples}}, n _ {\ mathrm {features}}) \), временная сложность рандомизированного &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; равна \ (O (n _ {\ max} ^ 2 \ cdot n _ {\ mathrm {components}}) \) вместо of \ (O (n _ {\ max} ^ 2 \ cdot n _ {\ min}) \) для точного метода, реализованного в &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="483854d9b52bcc6a7814b6c99e197398a7767c0e" translate="yes" xml:space="preserve">
          <source>If we use l2 shrinkage, as with the Ledoit-Wolf estimator, as the number of samples is small, we need to shrink a lot. As a result, the Ledoit-Wolf precision is fairly close to the ground truth precision, that is not far from being diagonal, but the off-diagonal structure is lost.</source>
          <target state="translated">Если мы используем l2 усадки,как и в случае с Ledoit-Волк оценщик,так как количество образцов мало,мы должны уменьшить много.В результате,точность Ledoit-Волк довольно близко к земле точность истины,что недалеко от диагонали,но вне диагональной структуры теряется.</target>
        </trans-unit>
        <trans-unit id="c048d2d806d4fc664d0d49e2240da1f9038d7165" translate="yes" xml:space="preserve">
          <source>If we want to fit a paraboloid to the data instead of a plane, we can combine the features in second-order polynomials, so that the model looks like this:</source>
          <target state="translated">Если мы хотим подогнать параболоид к данным,а не к плоскости,то мы можем объединить возможности полиномов второго порядка,чтобы модель выглядела именно так:</target>
        </trans-unit>
        <trans-unit id="9cd2bdd13889db844fd297c5019d226d5f2214ec" translate="yes" xml:space="preserve">
          <source>If we would restrict the model further, by assuming that the Gaussian noise is even isotropic (all diagonal entries are the same) we would obtain &lt;code&gt;PPCA&lt;/code&gt;.</source>
          <target state="translated">Если мы еще больше ограничим модель, предположив, что гауссов шум даже изотропен (все диагональные элементы одинаковы), мы получили бы &lt;code&gt;PPCA&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="722d8ecf13f293f3aeb1f206f30063d8afe3b1aa" translate="yes" xml:space="preserve">
          <source>If whiten is false, the data is already considered to be whitened, and no whitening is performed.</source>
          <target state="translated">Если отбеливание является ложным,данные уже считаются отбеленными,и отбеливание не производится.</target>
        </trans-unit>
        <trans-unit id="7d7146f3cf5f6ee3a12daad9561636b3070c19dc" translate="yes" xml:space="preserve">
          <source>If whitening is enabled, inverse_transform will compute the exact inverse operation, which includes reversing whitening.</source>
          <target state="translated">Если отбеливание включено,то inverse_transform вычислит точную обратную операцию,которая включает обратное отбеливание.</target>
        </trans-unit>
        <trans-unit id="d6701cdf426d6a22381b3dd206332eab0defeb4b" translate="yes" xml:space="preserve">
          <source>If you apply SGD to features extracted using PCA we found that it is often wise to scale the feature values by some constant &lt;code&gt;c&lt;/code&gt; such that the average L2 norm of the training data equals one.</source>
          <target state="translated">Если вы примените SGD к функциям, извлеченным с помощью PCA, мы обнаружили, что часто бывает разумно масштабировать значения функций с помощью некоторой константы &lt;code&gt;c&lt;/code&gt; , чтобы средняя норма L2 обучающих данных была равна единице.</target>
        </trans-unit>
        <trans-unit id="88e7b5f8ea1b769958767cd4c4986cb0d84b69d4" translate="yes" xml:space="preserve">
          <source>If you are having trouble decoding text, here are some things to try:</source>
          <target state="translated">Если у вас проблемы с расшифровкой текста,вот некоторые вещи,чтобы попробовать:</target>
        </trans-unit>
        <trans-unit id="79c8dbf5a9dd8e0bcb21dbc0b3d21d4a002af1f5" translate="yes" xml:space="preserve">
          <source>If you are interested in controlling the L1 and L2 penalty separately, keep in mind that this is equivalent to:</source>
          <target state="translated">Если вы заинтересованы в том,чтобы контролировать штраф L1 и L2 по отдельности,имейте в виду,что это эквивалентно:</target>
        </trans-unit>
        <trans-unit id="fda5569b1e927ca58d1243554ef8331577e43162" translate="yes" xml:space="preserve">
          <source>If you do not provide an a-priori dictionary and you do not use an analyzer that does some kind of feature selection then the number of features will be equal to the vocabulary size found by analyzing the data.</source>
          <target state="translated">Если вы не предоставляете словарь apriori и не используете анализатор,который делает какой-то выбор функций,то количество функций будет равно размеру словарного запаса,найденного при анализе данных.</target>
        </trans-unit>
        <trans-unit id="44906a85511569286aafb87826155b3c2905ddf9" translate="yes" xml:space="preserve">
          <source>If you don&amp;rsquo;t have labels, try using &lt;a href=&quot;../../auto_examples/text/plot_document_clustering#sphx-glr-auto-examples-text-plot-document-clustering-py&quot;&gt;Clustering&lt;/a&gt; on your problem.</source>
          <target state="translated">Если у вас нет ярлыков, попробуйте использовать &lt;a href=&quot;../../auto_examples/text/plot_document_clustering#sphx-glr-auto-examples-text-plot-document-clustering-py&quot;&gt;кластеризацию&lt;/a&gt; для своей проблемы.</target>
        </trans-unit>
        <trans-unit id="951c73020178956033a4088912e01e49fd5d4ad8" translate="yes" xml:space="preserve">
          <source>If you encounter a bug with &lt;code&gt;scikit-learn&lt;/code&gt; or something that needs clarification in the docstring or the online documentation, please feel free to ask on the &lt;a href=&quot;http://scikit-learn.org/stable/support.html&quot;&gt;Mailing List&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e3c9a76f4703e92f09f761bb01632ba0994c7fc" translate="yes" xml:space="preserve">
          <source>If you experience hanging subprocesses with &lt;code&gt;n_jobs&amp;gt;1&lt;/code&gt; or &lt;code&gt;n_jobs=-1&lt;/code&gt;, make sure you have a single-threaded BLAS library, or set &lt;code&gt;n_jobs=1&lt;/code&gt;, or upgrade to Python 3.4 which has a new version of &lt;code&gt;multiprocessing&lt;/code&gt; that should be immune to this problem.</source>
          <target state="translated">Если вы испытываете зависание подпроцессов с &lt;code&gt;n_jobs&amp;gt;1&lt;/code&gt; или &lt;code&gt;n_jobs=-1&lt;/code&gt; , убедитесь, что у вас есть однопоточная библиотека BLAS, или установите &lt;code&gt;n_jobs=1&lt;/code&gt; , или обновитесь до Python 3.4, который имеет новую версию &lt;code&gt;multiprocessing&lt;/code&gt; которая должна быть невосприимчивой к этому проблема.</target>
        </trans-unit>
        <trans-unit id="01bbb2c6066f4ee0c3cd8eec64a157d2ed58c8df" translate="yes" xml:space="preserve">
          <source>If you have a kernel matrix of a kernel \(K\) that computes a dot product in a feature space defined by function \(\phi\), a &lt;a href=&quot;generated/sklearn.preprocessing.kernelcenterer#sklearn.preprocessing.KernelCenterer&quot;&gt;&lt;code&gt;KernelCenterer&lt;/code&gt;&lt;/a&gt; can transform the kernel matrix so that it contains inner products in the feature space defined by \(\phi\) followed by removal of the mean in that space.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4d3f940390acd5b7c567c108aba27222ddceb7d" translate="yes" xml:space="preserve">
          <source>If you have a kernel matrix of a kernel \(K\) that computes a dot product in a feature space defined by function \(phi\), a &lt;a href=&quot;generated/sklearn.preprocessing.kernelcenterer#sklearn.preprocessing.KernelCenterer&quot;&gt;&lt;code&gt;KernelCenterer&lt;/code&gt;&lt;/a&gt; can transform the kernel matrix so that it contains inner products in the feature space defined by \(phi\) followed by removal of the mean in that space.</source>
          <target state="translated">Если у вас есть матрица ядра ядра \ (K \), которое вычисляет скалярное произведение в пространстве функций, определенном функцией \ (phi \), &lt;a href=&quot;generated/sklearn.preprocessing.kernelcenterer#sklearn.preprocessing.KernelCenterer&quot;&gt; &lt;code&gt;KernelCenterer&lt;/code&gt; &lt;/a&gt; может преобразовать матрицу ядра так, чтобы она содержала внутренние продукты в определенном пространстве функций на \ (phi \) с последующим удалением среднего в этом пространстве.</target>
        </trans-unit>
        <trans-unit id="2615ef2dcc8005e7f8f1fe1a8b864f8c5c8b40ba" translate="yes" xml:space="preserve">
          <source>If you have an affinity matrix, such as a distance matrix, for which 0 means identical elements, and high values means very dissimilar elements, it can be transformed in a similarity matrix that is well suited for the algorithm by applying the Gaussian (RBF, heat) kernel:</source>
          <target state="translated">Если у вас есть матрица сродства,например,матрица расстояния,для которой 0 означает идентичные элементы,а высокие значения означают очень разнородные элементы,то ее можно преобразовать в матрицу сходства,хорошо подходящую для алгоритма,применив Гауссово (RBF,heat)кернело (Gaussian,heat):</target>
        </trans-unit>
        <trans-unit id="fe35ae96a69c356c4c790a684b706493b567f769" translate="yes" xml:space="preserve">
          <source>If you have multiple labels per document, e.g categories, have a look at the &lt;a href=&quot;../../modules/multiclass#multiclass&quot;&gt;Multiclass and multilabel section&lt;/a&gt;.</source>
          <target state="translated">Если у вас есть несколько меток для каждого документа, например категории, посмотрите &lt;a href=&quot;../../modules/multiclass#multiclass&quot;&gt;раздел&lt;/a&gt; &amp;laquo; Мультикласс и несколько меток &amp;raquo; .</target>
        </trans-unit>
        <trans-unit id="4c5f38a361bcbafd12cc29508483a444dfcf9728" translate="yes" xml:space="preserve">
          <source>If you have several classes to predict, an option often used is to fit one-versus-all classifiers and then use a voting heuristic for the final decision.</source>
          <target state="translated">Если у вас есть несколько классов для предсказания,часто используется вариант,чтобы подогнать один против всех классификаторов,а затем использовать эвристическое голосование для принятия окончательного решения.</target>
        </trans-unit>
        <trans-unit id="f97615967054f5695c197161c38be5160cb380e9" translate="yes" xml:space="preserve">
          <source>If you need the raw values of the partial dependence function rather than the plots you can use the &lt;a href=&quot;generated/sklearn.ensemble.partial_dependence.partial_dependence#sklearn.ensemble.partial_dependence.partial_dependence&quot;&gt;&lt;code&gt;partial_dependence&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Если вам нужны необработанные значения функции частичной зависимости, а не графики, вы можете использовать функцию &lt;a href=&quot;generated/sklearn.ensemble.partial_dependence.partial_dependence#sklearn.ensemble.partial_dependence.partial_dependence&quot;&gt; &lt;code&gt;partial_dependence&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="89ce73b51d6a3d39879546007326b93ba776d729" translate="yes" xml:space="preserve">
          <source>If you need the raw values of the partial dependence function rather than the plots, you can use the &lt;a href=&quot;generated/sklearn.inspection.partial_dependence#sklearn.inspection.partial_dependence&quot;&gt;&lt;code&gt;sklearn.inspection.partial_dependence&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57ce2ca8cd47ab25ffa05da2880829913ab0ea8d" translate="yes" xml:space="preserve">
          <source>If you really want to use &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; for novelty detection, i.e. predict labels or compute the score of abnormality of new unseen data, you can instantiate the estimator with the &lt;code&gt;novelty&lt;/code&gt; parameter set to &lt;code&gt;True&lt;/code&gt; before fitting the estimator. In this case, &lt;code&gt;fit_predict&lt;/code&gt; is not available.</source>
          <target state="translated">Если вы действительно хотите использовать &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt; для обнаружения новизны, то есть для прогнозирования меток или вычисления оценки отклонения от нормы новых невидимых данных, вы можете создать экземпляр оценщика с параметром &lt;code&gt;novelty&lt;/code&gt; установленным на &lt;code&gt;True&lt;/code&gt; , перед подгонкой оценщика. В этом случае &lt;code&gt;fit_predict&lt;/code&gt; недоступен.</target>
        </trans-unit>
        <trans-unit id="d5eafa493c5ec5c70bb915830d883a4547e5cefd" translate="yes" xml:space="preserve">
          <source>If you set load_content=True, you should also specify the encoding of the text using the &amp;lsquo;encoding&amp;rsquo; parameter. For many modern text files, &amp;lsquo;utf-8&amp;rsquo; will be the correct encoding. If you leave encoding equal to None, then the content will be made of bytes instead of Unicode, and you will not be able to use most functions in &lt;a href=&quot;../classes#module-sklearn.feature_extraction.text&quot;&gt;&lt;code&gt;text&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f2c392b35ce2be9956cf3b6740e21a9cb0e7eb8" translate="yes" xml:space="preserve">
          <source>If you set load_content=True, you should also specify the encoding of the text using the &amp;lsquo;encoding&amp;rsquo; parameter. For many modern text files, &amp;lsquo;utf-8&amp;rsquo; will be the correct encoding. If you leave encoding equal to None, then the content will be made of bytes instead of Unicode, and you will not be able to use most functions in &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt;.</source>
          <target state="translated">Если вы установите load_content = True, вы также должны указать кодировку текста с помощью параметра encoding. Для многих современных текстовых файлов правильной кодировкой будет &amp;laquo;utf-8&amp;raquo;. Если вы оставите кодировку равной None, тогда содержимое будет состоять из байтов вместо Unicode, и вы не сможете использовать большинство функций в &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="bc2de8e7176de3a7ec5f2ba66eebe7612bd92fb1" translate="yes" xml:space="preserve">
          <source>If you specify &lt;code&gt;max_depth=h&lt;/code&gt; then complete binary trees of depth &lt;code&gt;h&lt;/code&gt; will be grown. Such trees will have (at most) &lt;code&gt;2**h&lt;/code&gt; leaf nodes and &lt;code&gt;2**h - 1&lt;/code&gt; split nodes.</source>
          <target state="translated">Если вы укажете &lt;code&gt;max_depth=h&lt;/code&gt; , то будут выращены полные двоичные деревья глубины &lt;code&gt;h&lt;/code&gt; . Такие деревья будут иметь (не более) &lt;code&gt;2**h&lt;/code&gt; листовых узла и &lt;code&gt;2**h - 1&lt;/code&gt; разделенных узла.</target>
        </trans-unit>
        <trans-unit id="b5e591b33a0bd24a7e9f3db1117e493d465fb600" translate="yes" xml:space="preserve">
          <source>If you use sparse data (i.e. data represented as sparse matrices), &lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt;&lt;code&gt;chi2&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_regression#sklearn.feature_selection.mutual_info_regression&quot;&gt;&lt;code&gt;mutual_info_regression&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_classif#sklearn.feature_selection.mutual_info_classif&quot;&gt;&lt;code&gt;mutual_info_classif&lt;/code&gt;&lt;/a&gt; will deal with the data without making it dense.</source>
          <target state="translated">Если вы используете разреженные данные (т. &lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt; &lt;code&gt;chi2&lt;/code&gt; &lt;/a&gt; Данные, представленные в виде разреженных матриц), chi2 , &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_regression#sklearn.feature_selection.mutual_info_regression&quot;&gt; &lt;code&gt;mutual_info_regression&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_classif#sklearn.feature_selection.mutual_info_classif&quot;&gt; &lt;code&gt;mutual_info_classif&lt;/code&gt; &lt;/a&gt; будут обрабатывать данные, не делая их плотными.</target>
        </trans-unit>
        <trans-unit id="a1ac2d367786359c2f555cec450b280865094e6b" translate="yes" xml:space="preserve">
          <source>If you want more control over stopping criteria or learning rate in SGD, or want to do additional monitoring, using &lt;code&gt;warm_start=True&lt;/code&gt; and &lt;code&gt;max_iter=1&lt;/code&gt; and iterating yourself can be helpful:</source>
          <target state="translated">Если вам нужен больший контроль над критериями остановки или скоростью обучения в SGD, или вы хотите провести дополнительный мониторинг, может оказаться полезным использование &lt;code&gt;warm_start=True&lt;/code&gt; и &lt;code&gt;max_iter=1&lt;/code&gt; и самостоятельное повторение:</target>
        </trans-unit>
        <trans-unit id="5572f4380789e92c52811040d71f90082bdb6315" translate="yes" xml:space="preserve">
          <source>If you want to know more about these issues and explore other possible serialization methods, please refer to this &lt;a href=&quot;http://pyvideo.org/video/2566/pickles-are-for-delis-not-software&quot;&gt;talk by Alex Gaynor&lt;/a&gt;.</source>
          <target state="translated">Если вы хотите узнать больше об этих проблемах и изучить другие возможные методы сериализации, обратитесь к &lt;a href=&quot;http://pyvideo.org/video/2566/pickles-are-for-delis-not-software&quot;&gt;докладу Алекса Гейнора&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="f3aeb01a6e584fc1ad67fbb7aa6de9be209b24eb" translate="yes" xml:space="preserve">
          <source>If you want to know more about these issues and explore other possible serialization methods, please refer to this &lt;a href=&quot;https://pyvideo.org/video/2566/pickles-are-for-delis-not-software&quot;&gt;talk by Alex Gaynor&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73e4bcb37920038eaa4bbe1483d8a08f411face1" translate="yes" xml:space="preserve">
          <source>If you want to model a relative frequency, i.e. counts per exposure (time, volume, &amp;hellip;) you can do so by using a Poisson distribution and passing \(y=\frac{\mathrm{counts}}{\mathrm{exposure}}\) as target values together with \(\mathrm{exposure}\) as sample weights. For a concrete example see e.g. &lt;a href=&quot;../auto_examples/linear_model/plot_tweedie_regression_insurance_claims#sphx-glr-auto-examples-linear-model-plot-tweedie-regression-insurance-claims-py&quot;&gt;Tweedie regression on insurance claims&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9d28c176517636a408517ab464ebf5a8ed78a10" translate="yes" xml:space="preserve">
          <source>If your attributes have an intrinsic scale (e.g. word frequencies or indicator features) scaling is not needed.</source>
          <target state="translated">Если Ваши атрибуты имеют свой собственный масштаб (например,частота слов или характеристики индикатора),масштабирование не требуется.</target>
        </trans-unit>
        <trans-unit id="1c54fdc8274e03b04e776296dd28d5ff9fd81085" translate="yes" xml:space="preserve">
          <source>If your data contains many outliers, scaling using the mean and variance of the data is likely to not work very well. In these cases, you can use &lt;a href=&quot;generated/sklearn.preprocessing.robust_scale#sklearn.preprocessing.robust_scale&quot;&gt;&lt;code&gt;robust_scale&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.preprocessing.robustscaler#sklearn.preprocessing.RobustScaler&quot;&gt;&lt;code&gt;RobustScaler&lt;/code&gt;&lt;/a&gt; as drop-in replacements instead. They use more robust estimates for the center and range of your data.</source>
          <target state="translated">Если ваши данные содержат много выбросов, масштабирование с использованием среднего значения и дисперсии данных, вероятно, не будет работать очень хорошо. В этих случаях вы можете &lt;a href=&quot;generated/sklearn.preprocessing.robust_scale#sklearn.preprocessing.robust_scale&quot;&gt; &lt;code&gt;robust_scale&lt;/code&gt; &lt;/a&gt; использовать robust_scale и &lt;a href=&quot;generated/sklearn.preprocessing.robustscaler#sklearn.preprocessing.RobustScaler&quot;&gt; &lt;code&gt;RobustScaler&lt;/code&gt; в&lt;/a&gt; качестве замены. Они используют более надежные оценки для центра и диапазона ваших данных.</target>
        </trans-unit>
        <trans-unit id="a10bfba29a759d89e81956a541262290109cf294" translate="yes" xml:space="preserve">
          <source>If your number of features is high, it may be useful to reduce it with an unsupervised step prior to supervised steps. Many of the &lt;a href=&quot;http://scikit-learn.org/stable/unsupervised_learning.html#unsupervised-learning&quot;&gt;Unsupervised learning&lt;/a&gt; methods implement a &lt;code&gt;transform&lt;/code&gt; method that can be used to reduce the dimensionality. Below we discuss two specific example of this pattern that are heavily used.</source>
          <target state="translated">Если у вас большое количество функций, может быть полезно уменьшить его с помощью неконтролируемого шага перед контролируемыми шагами. Многие из методов &lt;a href=&quot;http://scikit-learn.org/stable/unsupervised_learning.html#unsupervised-learning&quot;&gt;обучения без учителя&lt;/a&gt; реализуют метод &lt;code&gt;transform&lt;/code&gt; который можно использовать для уменьшения размерности. Ниже мы обсудим два конкретных примера этого шаблона, которые широко используются.</target>
        </trans-unit>
        <trans-unit id="7fd7c263c0ce2fcb7f46b0e79b01f4b5e3878456" translate="yes" xml:space="preserve">
          <source>If your number of features is high, it may be useful to reduce it with an unsupervised step prior to supervised steps. Many of the &lt;a href=&quot;https://scikit-learn.org/0.23/unsupervised_learning.html#unsupervised-learning&quot;&gt;Unsupervised learning&lt;/a&gt; methods implement a &lt;code&gt;transform&lt;/code&gt; method that can be used to reduce the dimensionality. Below we discuss two specific example of this pattern that are heavily used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="933c257247173f2464c3cf8d4de4af2d678e5a7c" translate="yes" xml:space="preserve">
          <source>If your number of observations is not large compared to the number of edges in your underlying graph, you will not recover it.</source>
          <target state="translated">Если ваше количество наблюдений невелико по сравнению с количеством ребер на базовом графике,вы не сможете его восстановить.</target>
        </trans-unit>
        <trans-unit id="4f34c772816074a373c0d5e918e2e9ac136448b7" translate="yes" xml:space="preserve">
          <source>Ignore the offset first bytes by seeking forward, then discarding the following bytes up until the next new line character.</source>
          <target state="translated">Игнорируйте смещение первых байтов,перебирая вперёд,затем отбрасывайте следующие байты до следующего нового символа строки.</target>
        </trans-unit>
        <trans-unit id="78fee1435d74666b84850cd5e82c18229351da5d" translate="yes" xml:space="preserve">
          <source>Ignored</source>
          <target state="translated">Ignored</target>
        </trans-unit>
        <trans-unit id="9b02e8c10d5a363337d6fcee177ec3e9cae9f1ce" translate="yes" xml:space="preserve">
          <source>Ignored in binary classification or classical regression settings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ce03a847a845250be1b2b174971c463802e32813" translate="yes" xml:space="preserve">
          <source>Ignored variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e65bb4eca2d3c71529c96890a4b735eb7dafeac" translate="yes" xml:space="preserve">
          <source>Ignored.</source>
          <target state="translated">Ignored.</target>
        </trans-unit>
        <trans-unit id="d0c592be2a6267cc2802c86a5116a8ba2d4b6ff9" translate="yes" xml:space="preserve">
          <source>Ignored. This parameter exists only for compatibility with &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e417badfc4d52f79664b451110854e41b4a0daf" translate="yes" xml:space="preserve">
          <source>Ignored. This parameter exists only for compatibility with sklearn.pipeline.Pipeline.</source>
          <target state="translated">Игнорируется.Этот параметр существует только для совместимости с sklearn.pipe.Pipeline.</target>
        </trans-unit>
        <trans-unit id="2d34b7c897f7b41a0f0625575a2c9cc21b1078a7" translate="yes" xml:space="preserve">
          <source>Illustration of &lt;code&gt;Pipeline&lt;/code&gt; and &lt;code&gt;GridSearchCV&lt;/code&gt;</source>
          <target state="translated">Иллюстрация &lt;code&gt;Pipeline&lt;/code&gt; и &lt;code&gt;GridSearchCV&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="643998f34944846c305de7d49de1c3e80f814d2d" translate="yes" xml:space="preserve">
          <source>Illustration of Gaussian process classification (GPC) on the XOR dataset</source>
          <target state="translated">Иллюстрация Гаусской классификации процессов (GPC)на наборе данных XOR</target>
        </trans-unit>
        <trans-unit id="c2cd661f8089fd4df71dfb566ea137083aa22024" translate="yes" xml:space="preserve">
          <source>Illustration of how the performance of an estimator on unseen data (test data) is not the same as the performance on training data. As the regularization increases the performance on train decreases while the performance on test is optimal within a range of values of the regularization parameter. The example with an Elastic-Net regression model and the performance is measured using the explained variance a.k.a. R^2.</source>
          <target state="translated">Иллюстрация того,как работа оценщика на невидимых данных (тестовых данных)не совпадает с работой на тренировочных данных.По мере увеличения регуляризации производительность на поезде снижается,в то время как производительность на тестах оптимальна в диапазоне значений параметра регуляризации.Пример с регрессионной моделью Elastic-Net и производительностью измеряется с помощью объясненной дисперсии a.k.a.R^2.</target>
        </trans-unit>
        <trans-unit id="5790a5aaa3a6c4543a820b9b12ce6d261eeb0581" translate="yes" xml:space="preserve">
          <source>Illustration of prior and posterior Gaussian process for different kernels</source>
          <target state="translated">Иллюстрация предшествующего и последующего гауссовского процесса для различных ядер</target>
        </trans-unit>
        <trans-unit id="71618836e7c136eb1b3d1aef884b22f68af959aa" translate="yes" xml:space="preserve">
          <source>Illustration of the effect of different regularization strategies for Gradient Boosting. The example is taken from Hastie et al 2009 &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27c062ea4e410688effe23ac51313a8ab9a70f1c" translate="yes" xml:space="preserve">
          <source>Illustration of the effect of different regularization strategies for Gradient Boosting. The example is taken from Hastie et al 2009 &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="translated">Иллюстрация эффекта различных стратегий регуляризации для повышения градиента. Пример взят из Hastie et al 2009 &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="5beb1d257bbb65ddb7ec568445a1c3acdcb42d37" translate="yes" xml:space="preserve">
          <source>Image denoising using dictionary learning</source>
          <target state="translated">Обозначение изображения с помощью изучения словаря</target>
        </trans-unit>
        <trans-unit id="5ab7decf36c80b04aff06a11c0e8ef068c85a1b9" translate="yes" xml:space="preserve">
          <source>Image histogram</source>
          <target state="translated">Гистограмма изображения</target>
        </trans-unit>
        <trans-unit id="2c151a57b190c9b9e70046810542a00e0344b5af" translate="yes" xml:space="preserve">
          <source>Image representing the confusion matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c328038b14054033bab1147ef5d1ad234b3373d" translate="yes" xml:space="preserve">
          <source>Imagine you have three subjects, each with an associated number from 1 to 3:</source>
          <target state="translated">Представьте,что у вас есть три предмета,каждый с соответствующим номером от 1 до 3:</target>
        </trans-unit>
        <trans-unit id="8781d615fd77be9578225c40ac67b9471394cced" translate="yes" xml:space="preserve">
          <source>Implementation</source>
          <target state="translated">Implementation</target>
        </trans-unit>
        <trans-unit id="8d522809f4125f5930c1f4f77ec91f8735a003d8" translate="yes" xml:space="preserve">
          <source>Implementation based on &lt;code&gt;A. Hyvarinen and E. Oja, Independent Component Analysis: Algorithms and Applications, Neural Networks, 13(4-5), 2000, pp. 411-430&lt;/code&gt;</source>
          <target state="translated">Реализация на основе &lt;code&gt;A. Hyvarinen and E. Oja, Independent Component Analysis: Algorithms and Applications, Neural Networks, 13(4-5), 2000, pp. 411-430&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="1f57545a08e425cccaf152a77959fb187cad06cb" translate="yes" xml:space="preserve">
          <source>Implementation based on &lt;em&gt;A. Hyvarinen and E. Oja, Independent Component Analysis: Algorithms and Applications, Neural Networks, 13(4-5), 2000, pp. 411-430&lt;/em&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6a1ab1256c83ccf4dbd316f43007b044bc691a2" translate="yes" xml:space="preserve">
          <source>Implementation detail: taking sample weights into account amounts to multiplying the gradients (and the hessians) by the sample weights. Note that the binning stage (specifically the quantiles computation) does not take the weights into account.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6ac8df85fe47d2d00b4a78e1facdef4fbcae73b" translate="yes" xml:space="preserve">
          <source>Implementation of Support Vector Machine classifier using libsvm: the kernel can be non-linear but its SMO algorithm does not scale to large number of samples as LinearSVC does. Furthermore SVC multi-class mode is implemented using one vs one scheme while LinearSVC uses one vs the rest. It is possible to implement one vs the rest with SVC by using the &lt;a href=&quot;sklearn.multiclass.onevsrestclassifier#sklearn.multiclass.OneVsRestClassifier&quot;&gt;&lt;code&gt;sklearn.multiclass.OneVsRestClassifier&lt;/code&gt;&lt;/a&gt; wrapper. Finally SVC can fit dense data without memory copy if the input is C-contiguous. Sparse data will still incur memory copy though.</source>
          <target state="translated">Реализация классификатора машины опорных векторов с использованием libsvm: ядро ​​может быть нелинейным, но его алгоритм SMO не масштабируется до большого количества выборок, как это делает LinearSVC. Кроме того, многоклассовый режим SVC реализован с использованием схемы &amp;laquo;один против одного&amp;raquo;, в то время как LinearSVC использует схему &amp;laquo;один против остальных&amp;raquo;. Можно реализовать одно против остальных с помощью SVC, используя оболочку &lt;a href=&quot;sklearn.multiclass.onevsrestclassifier#sklearn.multiclass.OneVsRestClassifier&quot;&gt; &lt;code&gt;sklearn.multiclass.OneVsRestClassifier&lt;/code&gt; &lt;/a&gt; . Наконец, SVC может вместить плотные данные без копирования в память, если вход C-смежный. Однако разреженные данные все равно будут копировать память.</target>
        </trans-unit>
        <trans-unit id="78b58091d5da65fb36aa747d9975841d97302dec" translate="yes" xml:space="preserve">
          <source>Implementation of Support Vector Machine classifier using the same library as this class (liblinear).</source>
          <target state="translated">Реализация классификатора Support Vector Machine с использованием той же библиотеки,что и данный класс (liblinear).</target>
        </trans-unit>
        <trans-unit id="0faf8832b17d93a1b230f7a6ca4feb36d15cc4ac" translate="yes" xml:space="preserve">
          <source>Implementation of Support Vector Machine regression using libsvm: the kernel can be non-linear but its SMO algorithm does not scale to large number of samples as LinearSVC does.</source>
          <target state="translated">Реализация поддержки векторной машинной регрессии с использованием libsvm:ядро может быть нелинейным,но его SMO алгоритм не масштабируется под большое количество сэмплов,как это делает LinearSVC.</target>
        </trans-unit>
        <trans-unit id="adae10003f16f5885f71700e866f2cc76e2c6af9" translate="yes" xml:space="preserve">
          <source>Implements feature hashing, aka the hashing trick.</source>
          <target state="translated">Элементы характеризуются хешированием,так же известным как трюк с хешированием.</target>
        </trans-unit>
        <trans-unit id="d98e09b894119d4a2d55bf3e2f04052ec103359a" translate="yes" xml:space="preserve">
          <source>Implements resampling with replacement. If False, this will implement (sliced) random permutations.</source>
          <target state="translated">Добавляет передискретизацию с заменой.Если False,то в этом случае будут реализованы (нарезанные)случайные перестановки.</target>
        </trans-unit>
        <trans-unit id="9f9d0b6a3b9dbc770ff8e17c3a6979d6ebb5425d" translate="yes" xml:space="preserve">
          <source>Implements the Birch clustering algorithm.</source>
          <target state="translated">Вводит алгоритм кластеризации Березы.</target>
        </trans-unit>
        <trans-unit id="82028db75262dc1a82a0dc4cf2e6f254032ff9f7" translate="yes" xml:space="preserve">
          <source>Implements the incremental PCA model from: &lt;code&gt;D. Ross, J. Lim, R. Lin, M. Yang, Incremental Learning for Robust Visual Tracking, International Journal of Computer Vision, Volume 77, Issue 1-3, pp. 125-141, May 2008.&lt;/code&gt; See &lt;a href=&quot;http://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf&quot;&gt;http://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf&lt;/a&gt;</source>
          <target state="translated">Реализует инкрементную модель PCA из: &lt;code&gt;D. Ross, J. Lim, R. Lin, M. Yang, Incremental Learning for Robust Visual Tracking, International Journal of Computer Vision, Volume 77, Issue 1-3, pp. 125-141, May 2008.&lt;/code&gt; См. &lt;a href=&quot;http://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf&quot;&gt;Http://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="eddd9fc5411550a8b67e601c8cf138c977f02e42" translate="yes" xml:space="preserve">
          <source>Implements the incremental PCA model from: &lt;em&gt;D. Ross, J. Lim, R. Lin, M. Yang, Incremental Learning for Robust Visual Tracking, International Journal of Computer Vision, Volume 77, Issue 1-3, pp. 125-141, May 2008.&lt;/em&gt; See &lt;a href=&quot;https://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf&quot;&gt;https://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06be3bf25c44efb35fdd12e8816c051b94a6e5d6" translate="yes" xml:space="preserve">
          <source>Implements the probabilistic PCA model from: &lt;a href=&quot;#id1&quot;&gt;&lt;span id=&quot;id2&quot;&gt;`&lt;/span&gt;&lt;/a&gt;Tipping, M. E., and Bishop, C. M. (1999). &amp;ldquo;Probabilistic principal component analysis&amp;rdquo;. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 61(3), 611-622. via the score and score_samples methods. See &lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdf&lt;/a&gt;</source>
          <target state="translated">Реализует вероятностную модель PCA из: &lt;a href=&quot;#id1&quot;&gt;&lt;span id=&quot;id2&quot;&gt;`&lt;/span&gt;&lt;/a&gt; Tipping, ME, and Bishop, CM (1999). &amp;laquo;Вероятностный анализ главных компонент&amp;raquo;. Журнал Королевского статистического общества: Серия B (Статистическая методология), 61 (3), 611-622. с помощью методов score и score_samples. См. &lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;Http://www.miketipping.com/papers/met-mppca.pdf.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5153c1832189653f3d836c4da5e485c3d1b56671" translate="yes" xml:space="preserve">
          <source>Implements the probabilistic PCA model from: Tipping, M. E., and Bishop, C. M. (1999). &amp;ldquo;Probabilistic principal component analysis&amp;rdquo;. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 61(3), 611-622. via the score and score_samples methods. See &lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="496d8573358dc0bbf8fad0d466b95c37d153e5fd" translate="yes" xml:space="preserve">
          <source>Importance of Feature Scaling</source>
          <target state="translated">Важность масштабирования характеристик</target>
        </trans-unit>
        <trans-unit id="dee0fbd7a096536203f3e083c7a95f20ef772057" translate="yes" xml:space="preserve">
          <source>Important members are fit, predict.</source>
          <target state="translated">Важные члены подходят,предсказывают.</target>
        </trans-unit>
        <trans-unit id="34aace9b4c119f775f92304ec637d19c91f28ab6" translate="yes" xml:space="preserve">
          <source>Importantly, this tabular dataset has very different dynamic ranges for its features. Neural networks tend to be very sensitive to features with varying scales and forgetting to preprocess the numeric feature would lead to a very poor model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7f6e12fca9c93deac0f3e9ce5406887ec818c03" translate="yes" xml:space="preserve">
          <source>Improvements to the histogram-based Gradient Boosting estimators</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eed74af8ff28262ccadec0b3ca567aeb04ce5592" translate="yes" xml:space="preserve">
          <source>Imputation for completing missing values using k-Nearest Neighbors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0004bf233145469d6159f141af0ae0b05f3c5e9a" translate="yes" xml:space="preserve">
          <source>Imputation transformer for completing missing values.</source>
          <target state="translated">Импульсный трансформатор для заполнения недостающих значений.</target>
        </trans-unit>
        <trans-unit id="8154b566118976ff2097cfffb2c92470797b0a69" translate="yes" xml:space="preserve">
          <source>Impute all missing values in X.</source>
          <target state="translated">Введите все недостающие значения в X.</target>
        </trans-unit>
        <trans-unit id="ad8e498cb05e98f21bd0f42774d74dde4c2bb7ea" translate="yes" xml:space="preserve">
          <source>Impute missing values with mean</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4715d3875af4e3819958eff35e6816030a9c89e" translate="yes" xml:space="preserve">
          <source>Impute the missing data and score</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="689f1aca2f66f40afe86b2a1257542980cceee50" translate="yes" xml:space="preserve">
          <source>Imputer used to initialize the missing values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="74ee388ccf36d172dba88b767c11eeb31f63d971" translate="yes" xml:space="preserve">
          <source>Imputes all missing values in X.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="510c592fb9a4fd828788fc0bdd902c165ca78889" translate="yes" xml:space="preserve">
          <source>Imputing missing values before building an estimator</source>
          <target state="translated">Вменение недостающих значений перед построением оценочного анализа</target>
        </trans-unit>
        <trans-unit id="87c53ba7fd85032a63ff707cca98951b5852e72d" translate="yes" xml:space="preserve">
          <source>Imputing missing values with variants of IterativeImputer</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5d148df74ab3f703a9d283fda0c99f4936ff674" translate="yes" xml:space="preserve">
          <source>In &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;NMF&lt;/code&gt;&lt;/a&gt;, L1 and L2 priors can be added to the loss function in order to regularize the model. The L2 prior uses the Frobenius norm, while the L1 prior uses an elementwise L1 norm. As in &lt;code&gt;ElasticNet&lt;/code&gt;, we control the combination of L1 and L2 with the &lt;code&gt;l1_ratio&lt;/code&gt; (\(\rho\)) parameter, and the intensity of the regularization with the &lt;code&gt;alpha&lt;/code&gt; (\(\alpha\)) parameter. Then the priors terms are:</source>
          <target state="translated">В &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt; &lt;code&gt;NMF&lt;/code&gt; априорные значения&lt;/a&gt; L1 и L2 могут быть добавлены к функции потерь, чтобы упорядочить модель. Приоритет в L2 использует норму Фробениуса, в то время как предварительный вариант L1 использует поэлементную норму L1. Как и в &lt;code&gt;ElasticNet&lt;/code&gt; , мы контролируем комбинацию L1 и L2 с помощью параметра &lt;code&gt;l1_ratio&lt;/code&gt; (\ (\ rho \)) и интенсивность регуляризации с помощью параметра &lt;code&gt;alpha&lt;/code&gt; (\ (\ alpha \)). Тогда априорные условия таковы:</target>
        </trans-unit>
        <trans-unit id="eee03375c59654f18a55a7961e4f26a36fbc2cee" translate="yes" xml:space="preserve">
          <source>In &lt;a href=&quot;generated/sklearn.multiclass.outputcodeclassifier#sklearn.multiclass.OutputCodeClassifier&quot;&gt;&lt;code&gt;OutputCodeClassifier&lt;/code&gt;&lt;/a&gt;, the &lt;code&gt;code_size&lt;/code&gt; attribute allows the user to control the number of classifiers which will be used. It is a percentage of the total number of classes.</source>
          <target state="translated">В &lt;a href=&quot;generated/sklearn.multiclass.outputcodeclassifier#sklearn.multiclass.OutputCodeClassifier&quot;&gt; &lt;code&gt;OutputCodeClassifier&lt;/code&gt; &lt;/a&gt; , то &lt;code&gt;code_size&lt;/code&gt; атрибут позволяет пользователю контролировать количество классификаторов , которые будут использоваться. Это процент от общего количества занятий.</target>
        </trans-unit>
        <trans-unit id="92869ea1268ab85728d32cc145b2fc2a3cf98201" translate="yes" xml:space="preserve">
          <source>In &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt;, if data for classification are unbalanced (e.g. many positive and few negative), set &lt;code&gt;class_weight='balanced'&lt;/code&gt; and/or try different penalty parameters &lt;code&gt;C&lt;/code&gt;.</source>
          <target state="translated">В &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt; , если данные для классификации являются несимметричными (например , много позитива и несколько отрицательных), множество &lt;code&gt;class_weight='balanced'&lt;/code&gt; и / или попробовать различные параметры КАЗНИ &lt;code&gt;C&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3c0402c73702f19dd4de5bea870fc6f39e9426a9" translate="yes" xml:space="preserve">
          <source>In &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt;, if the data is unbalanced (e.g. many positive and few negative), set &lt;code&gt;class_weight='balanced'&lt;/code&gt; and/or try different penalty parameters &lt;code&gt;C&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4a2dd93e9c8bc18123ea577d336109c88e8c2c3" translate="yes" xml:space="preserve">
          <source>In &lt;strong&gt;averaging methods&lt;/strong&gt;, the driving principle is to build several estimators independently and then to average their predictions. On average, the combined estimator is usually better than any of the single base estimator because its variance is reduced.</source>
          <target state="translated">В &lt;strong&gt;методах усреднения&lt;/strong&gt; основной принцип состоит в том, чтобы построить несколько оценщиков независимо, а затем усреднить их прогнозы. В среднем, комбинированная оценка обычно лучше, чем любая из оценок с одной базой, потому что ее дисперсия уменьшается.</target>
        </trans-unit>
        <trans-unit id="ca51c131377adedf53770a869ad18245bd6bd115" translate="yes" xml:space="preserve">
          <source>In a binary classification context, imposing a monotonic constraint means that the feature is supposed to have a positive / negative effect on the probability to belong to the positive class. Monotonic constraints are not supported for multiclass context.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="baeac0931c0e4b4385579000935f2bb52ceb9f07" translate="yes" xml:space="preserve">
          <source>In a binary classification task, the terms &amp;lsquo;&amp;rsquo;positive&amp;rsquo;&amp;rsquo; and &amp;lsquo;&amp;rsquo;negative&amp;rsquo;&amp;rsquo; refer to the classifier&amp;rsquo;s prediction, and the terms &amp;lsquo;&amp;rsquo;true&amp;rsquo;&amp;rsquo; and &amp;lsquo;&amp;rsquo;false&amp;rsquo;&amp;rsquo; refer to whether that prediction corresponds to the external judgment (sometimes known as the &amp;lsquo;&amp;rsquo;observation&amp;rsquo;&amp;lsquo;). Given these definitions, we can formulate the following table:</source>
          <target state="translated">В задаче двоичной классификации термины &amp;laquo;положительный&amp;raquo; и &amp;laquo;отрицательный&amp;raquo; относятся к предсказанию классификатора, а термины &amp;laquo;истинный&amp;raquo; и &amp;laquo;ложный&amp;raquo; относятся к тому, соответствует ли этот прогноз внешнему суждению ( иногда известное как &amp;laquo;наблюдение&amp;raquo;). Учитывая эти определения, мы можем сформулировать следующую таблицу:</target>
        </trans-unit>
        <trans-unit id="ccc920586f4d3de666e5e909b4599881349f812c" translate="yes" xml:space="preserve">
          <source>In a binary classification task, the terms &amp;lsquo;&amp;rsquo;positive&amp;rsquo;&amp;rsquo; and &amp;lsquo;&amp;rsquo;negative&amp;rsquo;&amp;rsquo; refer to the classifier&amp;rsquo;s prediction, and the terms &amp;lsquo;&amp;rsquo;true&amp;rsquo;&amp;rsquo; and &amp;lsquo;&amp;rsquo;false&amp;rsquo;&amp;rsquo; refer to whether that prediction corresponds to the external judgment (sometimes known as the &amp;lsquo;&amp;rsquo;observation&amp;rsquo;&amp;rsquo;). Given these definitions, we can formulate the following table:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="995a1ae8b5be72e5d8cbdf391052b665e77e9964" translate="yes" xml:space="preserve">
          <source>In a first step, the hierarchical clustering is performed without connectivity constraints on the structure and is solely based on distance, whereas in a second step the clustering is restricted to the k-Nearest Neighbors graph: it&amp;rsquo;s a hierarchical clustering with structure prior.</source>
          <target state="translated">На первом этапе иерархическая кластеризация выполняется без ограничений связности структуры и основывается исключительно на расстоянии, тогда как на втором этапе кластеризация ограничивается графом k-ближайших соседей: это иерархическая кластеризация со структурой предшествующей.</target>
        </trans-unit>
        <trans-unit id="0336cb4d8e7c9adb72abdea9417802db49cccd1f" translate="yes" xml:space="preserve">
          <source>In a large text corpus, some words will be very present (e.g. &amp;ldquo;the&amp;rdquo;, &amp;ldquo;a&amp;rdquo;, &amp;ldquo;is&amp;rdquo; in English) hence carrying very little meaningful information about the actual contents of the document. If we were to feed the direct count data directly to a classifier those very frequent terms would shadow the frequencies of rarer yet more interesting terms.</source>
          <target state="translated">В большом текстовом корпусе некоторые слова будут присутствовать очень часто (например, &amp;laquo;the&amp;raquo;, &amp;laquo;a&amp;raquo;, &amp;laquo;is&amp;raquo; на английском языке), следовательно, несут очень мало значимой информации о фактическом содержании документа. Если бы мы передавали данные прямого подсчета непосредственно классификатору, эти очень часто встречающиеся термины затеняли бы частоты более редких, но более интересных терминов.</target>
        </trans-unit>
        <trans-unit id="0caaa107286ab067ca8115855386dd04703bccc4" translate="yes" xml:space="preserve">
          <source>In a multiclass setting, specifies the class for which the PDPs should be computed. Note that for binary classification, the positive class (index 1) is always used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52eb2197195ece26c6612081f2107f907b3e4099" translate="yes" xml:space="preserve">
          <source>In a multioutput setting, specifies the task for which the PDPs should be computed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd0ed349168abd35a1fce87e6ae9e8ccc5ff58f4" translate="yes" xml:space="preserve">
          <source>In a nutshell, the following table summarizes the solvers characteristics:</source>
          <target state="translated">В двух словах,в следующей таблице приведены характеристики решателей:</target>
        </trans-unit>
        <trans-unit id="b4ec4bcaff3e86d4d99c938f5623ab4b737e65c7" translate="yes" xml:space="preserve">
          <source>In a real world setting, the &lt;code&gt;n_features&lt;/code&gt; parameter can be left to its default value of &lt;code&gt;2 ** 20&lt;/code&gt; (roughly one million possible features). If memory or downstream models size is an issue selecting a lower value such as &lt;code&gt;2 **
18&lt;/code&gt; might help without introducing too many additional collisions on typical text classification tasks.</source>
          <target state="translated">В реальных настройках &lt;code&gt;n_features&lt;/code&gt; параметра n_features можно оставить значение по умолчанию &lt;code&gt;2 ** 20&lt;/code&gt; (примерно один миллион возможных функций). Если размер памяти или последующих моделей является проблемой, выбор меньшего значения, такого как &lt;code&gt;2 ** 18&lt;/code&gt; может помочь, не создавая слишком много дополнительных конфликтов при выполнении типичных задач классификации текста.</target>
        </trans-unit>
        <trans-unit id="c75e295f24e05d06cacc1a2f9bb570a61bdd802e" translate="yes" xml:space="preserve">
          <source>In a similar manner, the boston housing data set is used to show the impact of transforming the targets before learning a model. In this example, the targets to be predicted corresponds to the weighted distances to the five Boston employment centers.</source>
          <target state="translated">Аналогичным образом,набор данных по бостонскому корпусу используется для того,чтобы показать влияние трансформации целей до изучения модели.В этом примере прогнозируемые цели соответствуют взвешенным расстояниям до пяти бостонских центров занятости.</target>
        </trans-unit>
        <trans-unit id="c210295417ef2f29cc593be46bbc5efed5892a5f" translate="yes" xml:space="preserve">
          <source>In addition of using an imputing method, we can also keep an indication of the missing information using &lt;a href=&quot;../modules/generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;sklearn.impute.MissingIndicator&lt;/code&gt;&lt;/a&gt; which might carry some information.</source>
          <target state="translated">Помимо использования метода вменения, мы также можем сохранить указание на недостающую информацию с помощью &lt;a href=&quot;../modules/generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt; &lt;code&gt;sklearn.impute.MissingIndicator&lt;/code&gt; ,&lt;/a&gt; который может нести некоторую информацию.</target>
        </trans-unit>
        <trans-unit id="67d21513f58775c1e37b37d0e7fc556492bd761a" translate="yes" xml:space="preserve">
          <source>In addition to imputing the missing values, the imputers have an &lt;code&gt;add_indicator&lt;/code&gt; parameter that marks the values that were missing, which might carry some information.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45e3263783ee36dc90c5821ae7ffc8d210750151" translate="yes" xml:space="preserve">
          <source>In addition to its current contents, this module will eventually be home to refurbished versions of Pipeline and FeatureUnion.</source>
          <target state="translated">В дополнение к его нынешнему содержанию,в этом модуле в конечном итоге появятся обновленные версии Pipeline и FeatureUnion.</target>
        </trans-unit>
        <trans-unit id="3dda0db479e61a3dc2539c918fe85f072a3cc4a4" translate="yes" xml:space="preserve">
          <source>In addition to standard scikit-learn estimator API, GaussianProcessRegressor:</source>
          <target state="translated">В дополнение к стандартному API для научной оценки,GaussianProcessRegressor:</target>
        </trans-unit>
        <trans-unit id="6c259b1081efe473add72a6c01ee26dbc96ee486" translate="yes" xml:space="preserve">
          <source>In addition to the mean of the predictive distribution, also its standard deviation can be returned.</source>
          <target state="translated">В дополнение к среднему значению прогностического распределения можно вернуть и его стандартное отклонение.</target>
        </trans-unit>
        <trans-unit id="f5f01da0b407208bd57121f71ed7408cbbce3fe6" translate="yes" xml:space="preserve">
          <source>In addition, as there is no useful information in the intensity of the image, or its gradient, we choose to perform the spectral clustering on a graph that is only weakly informed by the gradient. This is close to performing a Voronoi partition of the graph.</source>
          <target state="translated">Кроме того,поскольку отсутствует полезная информация об интенсивности изображения или его градиенте,мы решили провести спектральную кластеризацию на графике,который слабосведомлен только о градиенте.Это близко к выполнению Воронойского разбиения графика.</target>
        </trans-unit>
        <trans-unit id="8be2789c3e2f5a1d410c34b62e20c28c8adc9fef" translate="yes" xml:space="preserve">
          <source>In addition, if the &lt;code&gt;dask&lt;/code&gt; and &lt;code&gt;distributed&lt;/code&gt; Python packages are installed, it is possible to use the &amp;lsquo;dask&amp;rsquo; backend for better scheduling of nested parallel calls without over-subscription and potentially distribute parallel calls over a networked cluster of several hosts.</source>
          <target state="translated">Кроме того, если установлены &lt;code&gt;dask&lt;/code&gt; и &lt;code&gt;distributed&lt;/code&gt; пакеты Python, можно использовать серверную часть dask для лучшего планирования вложенных параллельных вызовов без избыточной подписки и потенциально распределять параллельные вызовы по сетевому кластеру из нескольких хостов.</target>
        </trans-unit>
        <trans-unit id="1068dbee0dd3c16e2fc93e44b0ce455f5b052f8b" translate="yes" xml:space="preserve">
          <source>In addition, scikit-learn includes various random sample generators that can be used to build artificial datasets of controlled size and complexity.</source>
          <target state="translated">Кроме того,Scikit-learn включает в себя различные генераторы случайных проб,которые могут быть использованы для создания искусственных наборов данных контролируемого размера и сложности.</target>
        </trans-unit>
        <trans-unit id="fc65b58b68e776527046619280b83dca96b85eef" translate="yes" xml:space="preserve">
          <source>In addition, some of the numpy routines that are used internally by scikit-learn may also be parallelized if numpy is installed with specific numerical libraries such as MKL, OpenBLAS, or BLIS.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a9dc36feb47a20be69368bf3755ac289f3cd578" translate="yes" xml:space="preserve">
          <source>In addition, there are also miscellaneous tools to load datasets of other formats or from other locations, described in the &lt;a href=&quot;#loading-other-datasets&quot;&gt;Loading other datasets&lt;/a&gt; section.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67ed28f1d0cd9fef0560dd0bbfe2b568680ea5a6" translate="yes" xml:space="preserve">
          <source>In addition, there are also miscellanous tools to load datasets of other formats or from other locations, described in the &lt;a href=&quot;#loading-other-datasets&quot;&gt;Loading other datasets&lt;/a&gt; section.</source>
          <target state="translated">Кроме того, существуют различные инструменты для загрузки наборов данных других форматов или из других мест, описанные в разделе &amp;laquo; &lt;a href=&quot;#loading-other-datasets&quot;&gt;Загрузка других наборов данных&lt;/a&gt; &amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="5f2d75a19b27e52127d76b03616ce749746e4308" translate="yes" xml:space="preserve">
          <source>In addition, we show two different ways to dispatch the columns to the particular pre-processor: by column names and by column data types.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="846c6c3d11b49bd5243a8b72c066c7aae06dcfe3" translate="yes" xml:space="preserve">
          <source>In addition, we use the mask of the objects to restrict the graph to the outline of the objects. In this example, we are interested in separating the objects one from the other, and not from the background.</source>
          <target state="translated">Кроме того,мы используем маску объектов,чтобы ограничить график контуром объектов.В данном примере мы заинтересованы в разделении объектов один от другого,а не от фона.</target>
        </trans-unit>
        <trans-unit id="b490744f01019d4237b3a8568465e031a5ae6e1f" translate="yes" xml:space="preserve">
          <source>In all these strategies, the &lt;code&gt;predict&lt;/code&gt; method completely ignores the input data.</source>
          <target state="translated">Во всех этих стратегиях метод &lt;code&gt;predict&lt;/code&gt; полностью игнорирует входные данные.</target>
        </trans-unit>
        <trans-unit id="450c8a41f7c5da3bb2b7da9a15306b194b36c681" translate="yes" xml:space="preserve">
          <source>In an &lt;strong&gt;unsupervised setting&lt;/strong&gt; it can be used to group similar documents together by applying clustering algorithms such as &lt;a href=&quot;clustering#k-means&quot;&gt;K-means&lt;/a&gt;:</source>
          <target state="translated">В &lt;strong&gt;неконтролируемой настройке&lt;/strong&gt; его можно использовать для группировки похожих документов вместе, применяя алгоритмы кластеризации, такие как &lt;a href=&quot;clustering#k-means&quot;&gt;K-means&lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="e5af8b183011d6bf7238d58f71b94384a5a96f84" translate="yes" xml:space="preserve">
          <source>In any case be warned that decreasing model complexity can hurt accuracy as mentioned above. For instance a non-linearly separable problem can be handled with a speedy linear model but prediction power will very likely suffer in the process.</source>
          <target state="translated">В любом случае следует предупредить,что уменьшение сложности модели может повредить точности,как уже упоминалось выше.Например,нелинейно отделяемая задача может быть решена с помощью скоростной линейной модели,но при этом очень вероятно,что в процессе будет страдать предсказательная мощность.</target>
        </trans-unit>
        <trans-unit id="8c17ce8abfedb506f7ed46ebde27121f581c8bb7" translate="yes" xml:space="preserve">
          <source>In applications where a high false positive rate is not tolerable the parameter &lt;code&gt;max_fpr&lt;/code&gt; of &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt; can be used to summarize the ROC curve up to the given limit.</source>
          <target state="translated">В приложениях, где недопустима высокая частота ложных срабатываний, можно использовать параметр &lt;code&gt;max_fpr&lt;/code&gt; в &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;roc_auc_score&lt;/code&gt; &lt;/a&gt; для суммирования кривой ROC до заданного предела.</target>
        </trans-unit>
        <trans-unit id="bbcc07c440f8193b3e7ecf64eaaca0e386adcbad" translate="yes" xml:space="preserve">
          <source>In bin edges for feature &lt;code&gt;i&lt;/code&gt;, the first and last values are used only for &lt;code&gt;inverse_transform&lt;/code&gt;. During transform, bin edges are extended to:</source>
          <target state="translated">В краях бункера для объекта &lt;code&gt;i&lt;/code&gt; первое и последнее значения используются только для &lt;code&gt;inverse_transform&lt;/code&gt; . Во время преобразования края бункера расширяются до:</target>
        </trans-unit>
        <trans-unit id="9d083c0b55e1a00133d4b27dd85f5ea26aca3922" translate="yes" xml:space="preserve">
          <source>In binary and multiclass classification, the Jaccard similarity coefficient score is equal to the classification accuracy.</source>
          <target state="translated">В бинарной и мультиклассификационной классификации коэффициент сходства Jaccard равен точности классификации.</target>
        </trans-unit>
        <trans-unit id="834fbb10f3b1dd0752ef9b7f9aa530ac5202b2db" translate="yes" xml:space="preserve">
          <source>In binary and multiclass classification, this function is equal to the &lt;code&gt;jaccard_score&lt;/code&gt; function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0b30958f6975dadd3d7eaf24f5447254d56c629" translate="yes" xml:space="preserve">
          <source>In binary and multiclass classification, this function is equal to the &lt;code&gt;jaccard_similarity_score&lt;/code&gt; function.</source>
          <target state="translated">В бинарной и мультиклассовой классификации эта функция равна функции &lt;code&gt;jaccard_similarity_score&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e731c9654f26a8d7255165d2c0d5f78e47c3bd9a" translate="yes" xml:space="preserve">
          <source>In binary and multiclass classification, this function is equivalent to the &lt;code&gt;accuracy_score&lt;/code&gt;. It differs in the multilabel classification problem.</source>
          <target state="translated">В бинарной и мультиклассовой классификации эта функция эквивалентна &lt;code&gt;accuracy_score&lt;/code&gt; . Отличается задачей классификации по нескольким меткам.</target>
        </trans-unit>
        <trans-unit id="c4cb57bb3e2c0bb1485829473f6ca6362cee5b90" translate="yes" xml:space="preserve">
          <source>In binary class case, assuming labels in y_true are encoded with +1 and -1, when a prediction mistake is made, &lt;code&gt;margin = y_true * pred_decision&lt;/code&gt; is always negative (since the signs disagree), implying &lt;code&gt;1 - margin&lt;/code&gt; is always greater than 1. The cumulated hinge loss is therefore an upper bound of the number of mistakes made by the classifier.</source>
          <target state="translated">В случае двоичного класса, предполагая, что метки в y_true закодированы с помощью +1 и -1, когда сделана ошибка предсказания, &lt;code&gt;margin = y_true * pred_decision&lt;/code&gt; всегда отрицательный (поскольку знаки не совпадают ), подразумевая &lt;code&gt;1 - margin&lt;/code&gt; всегда больше 1. Таким образом, совокупная потеря шарниров является верхней границей количества ошибок, допущенных классификатором.</target>
        </trans-unit>
        <trans-unit id="f2c8a5d61695d64c32adbdec8051b4ecc7f404cb" translate="yes" xml:space="preserve">
          <source>In binary classification settings</source>
          <target state="translated">В настройках бинарной классификации</target>
        </trans-unit>
        <trans-unit id="0e8524872beef3003e748e1d9b4f90c7ce280313" translate="yes" xml:space="preserve">
          <source>In both cases, the criterion is evaluated once by epoch, and the algorithm stops when the criterion does not improve &lt;code&gt;n_iter_no_change&lt;/code&gt; times in a row. The improvement is evaluated with a tolerance &lt;code&gt;tol&lt;/code&gt;, and the algorithm stops in any case after a maximum number of iteration &lt;code&gt;max_iter&lt;/code&gt;.</source>
          <target state="translated">В обоих случаях критерий оценивается один раз по эпохе, и алгоритм останавливается, когда критерий не улучшает &lt;code&gt;n_iter_no_change&lt;/code&gt; раз подряд. Улучшение оценивается с допуском &lt;code&gt;tol&lt;/code&gt; , и алгоритм останавливается в любом случае после максимального количества итераций &lt;code&gt;max_iter&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e7dad232dab7fc7fe4bb0ec13d7d0a07fef6ce88" translate="yes" xml:space="preserve">
          <source>In both cases, the criterion is evaluated once by epoch, and the algorithm stops when the criterion does not improve &lt;code&gt;n_iter_no_change&lt;/code&gt; times in a row. The improvement is evaluated with absolute tolerance &lt;code&gt;tol&lt;/code&gt;, and the algorithm stops in any case after a maximum number of iteration &lt;code&gt;max_iter&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f03bffae8069d1108a85252dc34a4485434865b8" translate="yes" xml:space="preserve">
          <source>In both cases, the kernel&amp;rsquo;s parameters are estimated using the maximum likelihood principle.</source>
          <target state="translated">В обоих случаях параметры ядра оцениваются по принципу максимального правдоподобия.</target>
        </trans-unit>
        <trans-unit id="dc8004c8d5b437fc6c479e2e5882eb635fa97592" translate="yes" xml:space="preserve">
          <source>In both examples below, the main result is that the empirical covariance estimate, as a non-robust one, is highly influenced by the heterogeneous structure of the observations. Although the robust covariance estimate is able to focus on the main mode of the data distribution, it sticks to the assumption that the data should be Gaussian distributed, yielding some biased estimation of the data structure, but yet accurate to some extent. The One-Class SVM does not assume any parametric form of the data distribution and can therefore model the complex shape of the data much better.</source>
          <target state="translated">В обоих приведенных ниже примерах основной результат заключается в том,что эмпирическая ковариационная оценка,как не робастная,сильно зависит от гетерогенной структуры наблюдений.Хотя робастная оценка ковариаций способна сфокусироваться на основном режиме распределения данных,она придерживается предположения,что данные должны быть распределены по Гауссу,что дает некоторую тенденциозную оценку структуры данных,но все же в некоторой степени точную.Одноклассная SVM не принимает никакой параметрической формы распределения данных и поэтому может гораздо лучше моделировать сложную форму данных.</target>
        </trans-unit>
        <trans-unit id="7f2b051010be4e679b8556fa182a1724fa1e49b9" translate="yes" xml:space="preserve">
          <source>In case the file contains a pairwise preference constraint (known as &amp;ldquo;qid&amp;rdquo; in the svmlight format) these are ignored unless the query_id parameter is set to True. These pairwise preference constraints can be used to constraint the combination of samples when using pairwise loss functions (as is the case in some learning to rank problems) so that only pairs with the same query_id value are considered.</source>
          <target state="translated">Если файл содержит ограничение парных предпочтений (известное как &amp;laquo;qid&amp;raquo; в формате svmlight), оно игнорируется, если для параметра query_id не установлено значение True. Эти парные ограничения предпочтений могут использоваться для ограничения комбинации выборок при использовании попарных функций потерь (как в случае некоторых задач обучения ранжированию), так что рассматриваются только пары с одинаковым значением query_id.</target>
        </trans-unit>
        <trans-unit id="b2d3bbc7ab1d1edcd850a10f6fb01a251c14a28b" translate="yes" xml:space="preserve">
          <source>In case unknown categories are encountered (all zero&amp;rsquo;s in the one-hot encoding), &lt;code&gt;None&lt;/code&gt; is used to represent this category.</source>
          <target state="translated">В случае, если встречаются неизвестные категории (все нули в кодировке one-hot), для представления этой категории используется значение &lt;code&gt;None&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d452896d1312cac0434176b68ca8ca9a2bb1195e" translate="yes" xml:space="preserve">
          <source>In case unknown categories are encountered (all zeros in the one-hot encoding), &lt;code&gt;None&lt;/code&gt; is used to represent this category.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca499264726caa99e06bab43fc3d4644ea84df01" translate="yes" xml:space="preserve">
          <source>In cases where not all of a pairwise distance matrix needs to be stored at once, this is used to calculate pairwise distances in &lt;code&gt;working_memory&lt;/code&gt;-sized chunks. If &lt;code&gt;reduce_func&lt;/code&gt; is given, it is run on each chunk and its return values are concatenated into lists, arrays or sparse matrices.</source>
          <target state="translated">В тех случаях , когда не все парное расстояние матрицы необходимо хранить сразу, это используется для вычисления попарных расстояний в &lt;code&gt;working_memory&lt;/code&gt; -sized кусков. Если &lt;code&gt;reduce_func&lt;/code&gt; , оно запускается для каждого фрагмента, и его возвращаемые значения объединяются в списки, массивы или разреженные матрицы.</target>
        </trans-unit>
        <trans-unit id="261de18f8066fcaced5cb3f145cb26c170301e09" translate="yes" xml:space="preserve">
          <source>In cases where the data is not uniformly sampled, radius-based neighbors classification in &lt;a href=&quot;generated/sklearn.neighbors.radiusneighborsclassifier#sklearn.neighbors.RadiusNeighborsClassifier&quot;&gt;&lt;code&gt;RadiusNeighborsClassifier&lt;/code&gt;&lt;/a&gt; can be a better choice. The user specifies a fixed radius \(r\), such that points in sparser neighborhoods use fewer nearest neighbors for the classification. For high-dimensional parameter spaces, this method becomes less effective due to the so-called &amp;ldquo;curse of dimensionality&amp;rdquo;.</source>
          <target state="translated">В случаях, когда данные не выбираются равномерно, классификация соседей на основе радиуса в &lt;a href=&quot;generated/sklearn.neighbors.radiusneighborsclassifier#sklearn.neighbors.RadiusNeighborsClassifier&quot;&gt; &lt;code&gt;RadiusNeighborsClassifier&lt;/code&gt; &lt;/a&gt; может быть лучшим выбором. Пользователь указывает фиксированный радиус \ (r \), так что точки в более разреженных окрестностях используют меньше ближайших соседей для классификации. Для пространств параметров большой размерности этот метод становится менее эффективным из-за так называемого &amp;laquo;проклятия размерности&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="46149a533d1136e96a72fc2595f06ccb02814862" translate="yes" xml:space="preserve">
          <source>In certain cases Theil-Sen performs better than &lt;a href=&quot;../../modules/linear_model#ransac-regression&quot;&gt;RANSAC&lt;/a&gt; which is also a robust method. This is illustrated in the second example below where outliers with respect to the x-axis perturb RANSAC. Tuning the &lt;code&gt;residual_threshold&lt;/code&gt; parameter of RANSAC remedies this but in general a priori knowledge about the data and the nature of the outliers is needed. Due to the computational complexity of Theil-Sen it is recommended to use it only for small problems in terms of number of samples and features. For larger problems the &lt;code&gt;max_subpopulation&lt;/code&gt; parameter restricts the magnitude of all possible combinations of p subsample points to a randomly chosen subset and therefore also limits the runtime. Therefore, Theil-Sen is applicable to larger problems with the drawback of losing some of its mathematical properties since it then works on a random subset.</source>
          <target state="translated">В некоторых случаях Theil-Sen работает лучше, чем &lt;a href=&quot;../../modules/linear_model#ransac-regression&quot;&gt;RANSAC,&lt;/a&gt; который также является надежным методом. Это проиллюстрировано во втором примере ниже, где выбросы по отношению к возмущению оси x нарушают RANSAC. Настройка параметра &lt;code&gt;residual_threshold&lt;/code&gt; RANSAC исправляет это, но в целом необходимы априорные знания о данных и природе выбросов. Из-за вычислительной сложности Theil-Sen рекомендуется использовать его только для небольших задач с точки зрения количества образцов и функций. Для более серьезных проблем &lt;code&gt;max_subpopulation&lt;/code&gt; Параметр ограничивает величину всех возможных комбинаций p точек подвыборки случайно выбранным подмножеством и, следовательно, также ограничивает время выполнения. Следовательно, Тейл-Сен применим к более крупным задачам с недостатком потери некоторых своих математических свойств, так как затем он работает со случайным подмножеством.</target>
        </trans-unit>
        <trans-unit id="08403787ed9849b402f6d04f68a0bae46063dfaf" translate="yes" xml:space="preserve">
          <source>In contrast to &lt;a href=&quot;#id13&quot;&gt;Bayesian Ridge Regression&lt;/a&gt;, each coordinate of \(w_{i}\) has its own standard deviation \(\lambda_i\). The prior over all \(\lambda_i\) is chosen to be the same gamma distribution given by hyperparameters \(\lambda_1\) and \(\lambda_2\).</source>
          <target state="translated">В отличие от &lt;a href=&quot;#id13&quot;&gt;регрессии байесовского хребта&lt;/a&gt; , каждая координата \ (w_ {i} \) имеет собственное стандартное отклонение \ (\ lambda_i \). Приоритет по всем \ (\ lambda_i \) выбирается таким же, как гамма-распределение, заданное гиперпараметрами \ (\ lambda_1 \) и \ (\ lambda_2 \).</target>
        </trans-unit>
        <trans-unit id="f00603c6aeddee02bf1dc7fdebe82c8fea70d634" translate="yes" xml:space="preserve">
          <source>In contrast to &lt;a href=&quot;#id9&quot;&gt;Bayesian Ridge Regression&lt;/a&gt;, each coordinate of \(w_{i}\) has its own standard deviation \(\lambda_i\). The prior over all \(\lambda_i\) is chosen to be the same gamma distribution given by hyperparameters \(\lambda_1\) and \(\lambda_2\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="741dc2ca1b0b96b753a4293cdc66da483cb961b9" translate="yes" xml:space="preserve">
          <source>In contrast to GridSearchCV, not all parameter values are tried out, but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter.</source>
          <target state="translated">В отличие от GridSearchCV,не все значения параметров опробованы,а из заданных распределений выбирается фиксированное количество параметров.Количество опробованных настроек параметров задается значением n_iter.</target>
        </trans-unit>
        <trans-unit id="f7007cbebb915951a7329a621ec59e7bfd3c1528" translate="yes" xml:space="preserve">
          <source>In contrast to majority voting (hard voting), soft voting returns the class label as argmax of the sum of predicted probabilities.</source>
          <target state="translated">В отличие от мажоритарного голосования (жесткого),мягкое голосование возвращает классовый знак в качестве аргумента суммы прогнозируемых вероятностей.</target>
        </trans-unit>
        <trans-unit id="a5222e41535c7e60d0bed8020d5a39a4cdb9c58d" translate="yes" xml:space="preserve">
          <source>In contrast to the original publication &lt;a href=&quot;#b2001&quot; id=&quot;id6&quot;&gt;[B2001]&lt;/a&gt;, the scikit-learn implementation combines classifiers by averaging their probabilistic prediction, instead of letting each classifier vote for a single class.</source>
          <target state="translated">В отличие от исходной публикации &lt;a href=&quot;#b2001&quot; id=&quot;id6&quot;&gt;[B2001]&lt;/a&gt; , реализация scikit-learn объединяет классификаторы путем усреднения их вероятностного прогноза вместо того, чтобы позволить каждому классификатору голосовать за один класс.</target>
        </trans-unit>
        <trans-unit id="092465bd0b61837459fb29bf14c2dda6ed20e949" translate="yes" xml:space="preserve">
          <source>In contrast to the regression setting, the posterior of the latent function \(f\) is not Gaussian even for a GP prior since a Gaussian likelihood is inappropriate for discrete class labels. Rather, a non-Gaussian likelihood corresponding to the logistic link function (logit) is used. GaussianProcessClassifier approximates the non-Gaussian posterior with a Gaussian based on the Laplace approximation. More details can be found in Chapter 3 of &lt;a href=&quot;#rw2006&quot; id=&quot;id4&quot;&gt;[RW2006]&lt;/a&gt;.</source>
          <target state="translated">В отличие от настройки регрессии, апостериор скрытой функции \ (f \) не является гауссовым даже для априорного GP, поскольку гауссовское правдоподобие не подходит для меток дискретных классов. Вместо этого используется негауссовское правдоподобие, соответствующее функции логистической связи (логит). GaussianProcessClassifier аппроксимирует негауссову апостериорную функцию гауссовой функцией на основе аппроксимации Лапласа. Более подробную информацию можно найти в главе 3 &lt;a href=&quot;#rw2006&quot; id=&quot;id4&quot;&gt;[RW2006]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="8da23c4fea95dfb9e1a4723525c1617ef732103e" translate="yes" xml:space="preserve">
          <source>In contrast, for small amounts of data, the training score of the SVM is much greater than the validation score. Adding more training samples will most likely increase generalization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d7f12a42ea8277b24625f1aff8d53cb363a14e0" translate="yes" xml:space="preserve">
          <source>In contrast, if the conventional accuracy is above chance only because the classifier takes advantage of an imbalanced test set, then the balanced accuracy, as appropriate, will drop to \(\frac{1}{\text{n\_classes}}\).</source>
          <target state="translated">Напротив,если обычная точность выше шансов только потому,что классификатор использует несбалансированный набор тестов,то сбалансированная точность,по мере необходимости,упадет на \(\frac{1}{\text{n\_classes}}\).</target>
        </trans-unit>
        <trans-unit id="8343cdcc0bd2973a4149cb63a31822f5be571a78" translate="yes" xml:space="preserve">
          <source>In contrast, if the conventional accuracy is above chance only because the classifier takes advantage of an imbalanced test set, then the balanced accuracy, as appropriate, will drop to \(\frac{1}{n\_classes}\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89611c1358b346353d5469c5670ea64fb02fcdd7" translate="yes" xml:space="preserve">
          <source>In descending order of quality, when trained (outside of this example) on all 4 features using 30 estimators and scored using 10 fold cross validation, we see:</source>
          <target state="translated">В порядке убывания качества,при обучении (за пределами этого примера)всех 4-х характеристик с использованием 30 оценщиков и оценке с использованием 10-кратной поперечной проверки,мы видим:</target>
        </trans-unit>
        <trans-unit id="0732cca6c2251b860da4c331fa5748d479b14945" translate="yes" xml:space="preserve">
          <source>In ensemble algorithms, bagging methods form a class of algorithms which build several instances of a black-box estimator on random subsets of the original training set and then aggregate their individual predictions to form a final prediction. These methods are used as a way to reduce the variance of a base estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it. In many cases, bagging methods constitute a very simple way to improve with respect to a single model, without making it necessary to adapt the underlying base algorithm. As they provide a way to reduce overfitting, bagging methods work best with strong and complex models (e.g., fully developed decision trees), in contrast with boosting methods which usually work best with weak models (e.g., shallow decision trees).</source>
          <target state="translated">В ансамблевых алгоритмах методы суммирования образуют класс алгоритмов,которые строят несколько экземпляров черного ящика оценки на случайных подмножествах исходного обучающего множества,а затем агрегируют их индивидуальные прогнозы для формирования окончательного прогноза.Эти методы используются как способ снижения дисперсии базовой оценки (например,дерева решений),путем введения в процедуру ее построения рандомизации с последующим формированием из нее ансамбля.Во многих случаях методы суммирования представляют собой очень простой способ улучшения по отношению к одной модели,без необходимости адаптации базового алгоритма.Так как они позволяют уменьшить переоснащение,методы упаковки лучше всего работают с сильными и сложными моделями (например,с полностью разработанными деревьями решений),в отличие от методов форсирования,которые обычно лучше всего работают со слабыми моделями (например,с неглубокими деревьями решений).</target>
        </trans-unit>
        <trans-unit id="5305d1e9b70806a8391e61e804a0df6abd8f6cc5" translate="yes" xml:space="preserve">
          <source>In extending a binary metric to multiclass or multilabel problems, the data is treated as a collection of binary problems, one for each class. There are then a number of ways to average binary metric calculations across the set of classes, each of which may be useful in some scenario. Where available, you should select among these using the &lt;code&gt;average&lt;/code&gt; parameter.</source>
          <target state="translated">При расширении двоичной метрики на задачи с несколькими классами или метками данные обрабатываются как набор двоичных задач, по одной для каждого класса. Затем существует несколько способов усреднить вычисления двоичных показателей по набору классов, каждый из которых может быть полезен в каком-то сценарии. Если возможно, вы должны выбрать среди них, используя &lt;code&gt;average&lt;/code&gt; параметр.</target>
        </trans-unit>
        <trans-unit id="e87cfc9dff0fe670bd40ebf7e26edaa15ca842ad" translate="yes" xml:space="preserve">
          <source>In extremely randomized trees (see &lt;a href=&quot;generated/sklearn.ensemble.extratreesclassifier#sklearn.ensemble.ExtraTreesClassifier&quot;&gt;&lt;code&gt;ExtraTreesClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.extratreesregressor#sklearn.ensemble.ExtraTreesRegressor&quot;&gt;&lt;code&gt;ExtraTreesRegressor&lt;/code&gt;&lt;/a&gt; classes), randomness goes one step further in the way splits are computed. As in random forests, a random subset of candidate features is used, but instead of looking for the most discriminative thresholds, thresholds are drawn at random for each candidate feature and the best of these randomly-generated thresholds is picked as the splitting rule. This usually allows to reduce the variance of the model a bit more, at the expense of a slightly greater increase in bias:</source>
          <target state="translated">В чрезвычайно рандомизированных деревьях (см. &lt;a href=&quot;generated/sklearn.ensemble.extratreesclassifier#sklearn.ensemble.ExtraTreesClassifier&quot;&gt; &lt;code&gt;ExtraTreesClassifier&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.ensemble.extratreesregressor#sklearn.ensemble.ExtraTreesRegressor&quot;&gt; &lt;code&gt;ExtraTreesRegressor&lt;/code&gt; &lt;/a&gt; ) случайность идет на один шаг дальше в способе вычисления разбиений. Как и в случайных лесах, используется случайное подмножество функций-кандидатов, но вместо поиска наиболее отличительных пороговых значений пороги выбираются случайным образом для каждой функции-кандидата, и в качестве правила разделения выбирается лучший из этих случайно сгенерированных пороговых значений. Обычно это позволяет немного уменьшить дисперсию модели за счет немного большего увеличения смещения:</target>
        </trans-unit>
        <trans-unit id="5c1305e3ce4cbb99adc8d313e42a43efab81ea5c" translate="yes" xml:space="preserve">
          <source>In fact, this dataset only has one version. The iris dataset on the other hand has multiple versions:</source>
          <target state="translated">Фактически,этот набор данных имеет только одну версию.С другой стороны,набор данных радужной оболочки глаза имеет несколько версий:</target>
        </trans-unit>
        <trans-unit id="63493dde535d33b43819cf48666bb2a9620c2476" translate="yes" xml:space="preserve">
          <source>In french but still a reference: Tenenhaus, M. (1998). La regression PLS: theorie et pratique. Paris: Editions Technic.</source>
          <target state="translated">На французском,но все же ссылка:Тененхаус,М.(1998).La regression PLS:theorie et pratique.Париж:Издания Техника.</target>
        </trans-unit>
        <trans-unit id="6e95c3ada3b2525ed5f608da19594b4a42ad3dc4" translate="yes" xml:space="preserve">
          <source>In general doing predictions in bulk (many instances at the same time) is more efficient for a number of reasons (branching predictability, CPU cache, linear algebra libraries optimizations etc.). Here we see on a setting with few features that independently of estimator choice the bulk mode is always faster, and for some of them by 1 to 2 orders of magnitude:</source>
          <target state="translated">В целом,делать прогнозы массово (во многих случаях одновременно)более эффективно по ряду причин (прогнозируемость ветвей,кэш процессора,оптимизация библиотек линейной алгебры и т.д.).Здесь мы видим на настройке с небольшим количеством возможностей,что независимо от выбора оценочного средства режим bulk всегда быстрее,а для некоторых из них на 1-2 порядка:</target>
        </trans-unit>
        <trans-unit id="73d5a0649f1537ceaa4a43b2819de8ab34f4f95d" translate="yes" xml:space="preserve">
          <source>In general, &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; is a technique used for analyzing similarity or dissimilarity data. It attempts to model similarity or dissimilarity data as distances in a geometric spaces. The data can be ratings of similarity between objects, interaction frequencies of molecules, or trade indices between countries.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5f14cdf8cb9c0df1b6ffce69bd866cdeffd9355" translate="yes" xml:space="preserve">
          <source>In general, a learning problem considers a set of n &lt;a href=&quot;https://en.wikipedia.org/wiki/Sample_(statistics)&quot;&gt;samples&lt;/a&gt; of data and then tries to predict properties of unknown data. If each sample is more than a single number and, for instance, a multi-dimensional entry (aka &lt;a href=&quot;https://en.wikipedia.org/wiki/Multivariate_random_variable&quot;&gt;multivariate&lt;/a&gt; data), it is said to have several attributes or &lt;strong&gt;features&lt;/strong&gt;.</source>
          <target state="translated">Как правило, задача обучения рассматривает набор из n &lt;a href=&quot;https://en.wikipedia.org/wiki/Sample_(statistics)&quot;&gt;выборок&lt;/a&gt; данных, а затем пытается предсказать свойства неизвестных данных. Если каждая выборка представляет собой более одного числа и, например, многомерную запись (также &lt;a href=&quot;https://en.wikipedia.org/wiki/Multivariate_random_variable&quot;&gt;известную&lt;/a&gt; как многомерные данные), считается, что она имеет несколько атрибутов или &lt;strong&gt;функций&lt;/strong&gt; .</target>
        </trans-unit>
        <trans-unit id="9cf7334c38597a2189c7af702ab9abdbe9f10093" translate="yes" xml:space="preserve">
          <source>In general, is a technique used for analyzing similarity or dissimilarity data. &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; attempts to model similarity or dissimilarity data as distances in a geometric spaces. The data can be ratings of similarity between objects, interaction frequencies of molecules, or trade indices between countries.</source>
          <target state="translated">В общем, это метод, используемый для анализа данных о сходстве или несходстве. &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt; &lt;code&gt;MDS&lt;/code&gt; &lt;/a&gt; пытается моделировать данные сходства или несходства как расстояния в геометрических пространствах. Данные могут быть рейтингами сходства между объектами, частотами взаимодействия молекул или торговыми индексами между странами.</target>
        </trans-unit>
        <trans-unit id="71aab6786f00490669e72ac36911ce2d2486dab4" translate="yes" xml:space="preserve">
          <source>In general, it is about to learn a rough, close frontier delimiting the contour of the initial observations distribution, plotted in embedding \(p\)-dimensional space. Then, if further observations lay within the frontier-delimited subspace, they are considered as coming from the same population than the initial observations. Otherwise, if they lay outside the frontier, we can say that they are abnormal with a given confidence in our assessment.</source>
          <target state="translated">В общем,речь идет о том,чтобы узнать грубую,близкую границу,разграничивающую контур исходного распределения наблюдений,начерченный во вложенном \(p\)-размерном пространстве.Затем,если дальнейшие наблюдения лежат в пределах разделенного границей подпространства,то считается,что они происходят из той же популяции,что и начальные наблюдения.В противном случае,если они лежат за пределами границы,можно сказать,что они аномальны с определенной долей уверенности в нашей оценке.</target>
        </trans-unit>
        <trans-unit id="c9bca25ec918e4e036ec8a37ec502896ec56d542" translate="yes" xml:space="preserve">
          <source>In general, learning algorithms benefit from standardization of the data set. If some outliers are present in the set, robust scalers or transformers are more appropriate. The behaviors of the different scalers, transformers, and normalizers on a dataset containing marginal outliers is highlighted in &lt;a href=&quot;../auto_examples/preprocessing/plot_all_scaling#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py&quot;&gt;Compare the effect of different scalers on data with outliers&lt;/a&gt;.</source>
          <target state="translated">В целом алгоритмы обучения выигрывают от стандартизации набора данных. Если в наборе присутствуют какие-то выбросы, более подходящими являются надежные скейлеры или трансформаторы. Поведение различных средств масштабирования, преобразователей и нормализаторов в наборе данных, содержащем маргинальные выбросы, выделено в &lt;a href=&quot;../auto_examples/preprocessing/plot_all_scaling#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py&quot;&gt;разделе &amp;laquo;Сравнить влияние различных средств масштабирования на данные с выбросами&amp;raquo;&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="baeb2b7a43c2bc0dd04675c021d6ed663a58bf2d" translate="yes" xml:space="preserve">
          <source>In general, the run time cost to construct a balanced binary tree is \(O(n_{samples}n_{features}\log(n_{samples}))\) and query time \(O(\log(n_{samples}))\). Although the tree construction algorithm attempts to generate balanced trees, they will not always be balanced. Assuming that the subtrees remain approximately balanced, the cost at each node consists of searching through \(O(n_{features})\) to find the feature that offers the largest reduction in entropy. This has a cost of \(O(n_{features}n_{samples}\log(n_{samples}))\) at each node, leading to a total cost over the entire trees (by summing the cost at each node) of \(O(n_{features}n_{samples}^{2}\log(n_{samples}))\).</source>
          <target state="translated">В общем случае,стоимость времени выполнения для построения сбалансированного двоичного дерева составляет \(O(n_{samples}n_{features}\log(n_{samples}))\)и время запроса \(O(\log(n_{samples}))\).Несмотря на то,что алгоритм построения деревьев пытается генерировать сбалансированные деревья,они не всегда будут сбалансированы.Если предположить,что поддеревья остаются приблизительно сбалансированными,то стоимость каждого узла состоит из поиска по адресу \(O(n_{features})\),чтобы найти возможность,предлагающую наибольшее снижение энтропии.При этом стоимость \(O(n_{features}n_{samples}\log(n_{samples}))\)в каждом узле приводит к общей стоимости по всем деревьям (путем суммирования стоимости в каждом узле)\(O(n_{features}n_{samples}^{2}\log(n_{samples}))\).</target>
        </trans-unit>
        <trans-unit id="144a3925f6b19404e9d474c272482fb04a69a6ff" translate="yes" xml:space="preserve">
          <source>In general, when fitting a curve with a polynomial by Bayesian ridge regression, the selection of initial values of the regularization parameters (alpha, lambda) may be important. This is because the regularization parameters are determined by an iterative procedure that depends on initial values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dba314b8268f3eec306fec03d7cfe13e8e090ace" translate="yes" xml:space="preserve">
          <source>In general, when the problem isn&amp;rsquo;t linearly separable, the support vectors are the samples &lt;em&gt;within&lt;/em&gt; the margin boundaries.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="635895acc09f2d99381585bc2d144c9a66a85f3a" translate="yes" xml:space="preserve">
          <source>In gradient descent, the gradient \(\nabla Loss_{W}\) of the loss with respect to the weights is computed and deducted from \(W\). More formally, this is expressed as,</source>
          <target state="translated">В градиентном спуске вычисляется и вычитается градиент \(\nabla Loss_{W}\)потери по отношению к весам \(W\).Более формально это выражается как,</target>
        </trans-unit>
        <trans-unit id="2c51a2af5a19ac0ce7e4fb04fd6d887c03b6fecb" translate="yes" xml:space="preserve">
          <source>In high-dimensional spaces, linear classifiers often achieve excellent accuracy. For sparse binary data, BernoulliNB is particularly well-suited. The bottom row compares the decision boundary obtained by BernoulliNB in the transformed space with an ExtraTreesClassifier forests learned on the original data.</source>
          <target state="translated">В высокоразмерных пространствах линейные классификаторы часто достигают превосходной точности.Для разреженных двоичных данных особенно хорошо подходит BernoulliNB.В нижней строке сравнивается граница решения,полученная BernoulliNB в преобразованном пространстве,с лесами ExtraTreesClassifier,полученными на основе исходных данных.</target>
        </trans-unit>
        <trans-unit id="26c26ee3d75b66c7f22fed706da52f459434240f" translate="yes" xml:space="preserve">
          <source>In linear models, the target value is modeled as a linear combination of the features (see the &lt;a href=&quot;../../modules/linear_model#linear-model&quot;&gt;Linear Models&lt;/a&gt; User Guide section for a description of a set of linear models available in scikit-learn). Coefficients in multiple linear models represent the relationship between the given feature, \(X_i\) and the target, \(y\), assuming that all the other features remain constant (&lt;a href=&quot;https://en.wikipedia.org/wiki/Conditional_dependence&quot;&gt;conditional dependence&lt;/a&gt;). This is different from plotting \(X_i\) versus \(y\) and fitting a linear relationship: in that case all possible values of the other features are taken into account in the estimation (marginal dependence).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2367cf553e95efae790eac559ef2be19cd28f503" translate="yes" xml:space="preserve">
          <source>In machine-learning practice, Ridge Regression is more often used with non-negligible regularization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b577c96674cf299faa19ce0d11e2224d3c2c813" translate="yes" xml:space="preserve">
          <source>In majority voting, the predicted class label for a particular sample is the class label that represents the majority (mode) of the class labels predicted by each individual classifier.</source>
          <target state="translated">При голосовании большинства,прогнозируемая метка класса для определенной выборки является меткой класса,которая представляет собой большинство (способ)метки класса,прогнозируемой каждым отдельным классификатором.</target>
        </trans-unit>
        <trans-unit id="589394183aec0e7af2afe4b456559f6baedc9992" translate="yes" xml:space="preserve">
          <source>In many cases it is thus recommended to carefully time and profile your feature extraction code as it may be a good place to start optimizing when your overall latency is too slow for your application.</source>
          <target state="translated">Поэтому во многих случаях рекомендуется тщательно определить время и профиль кода извлечения функции,так как это может быть хорошим местом,чтобы начать оптимизацию,когда ваша общая задержка слишком медленна для вашего приложения.</target>
        </trans-unit>
        <trans-unit id="aeae04273a5ed1fc88f796de718e3c2190c04f0d" translate="yes" xml:space="preserve">
          <source>In many modeling scenarios, normality of the features in a dataset is desirable. Power transforms are a family of parametric, monotonic transformations that aim to map data from any distribution to as close to a Gaussian distribution as possible in order to stabilize variance and minimize skewness.</source>
          <target state="translated">Во многих сценариях моделирования желательна нормальность характеристик в наборе данных.Силовые преобразования-это семейство параметрических,монотонных преобразований,целью которых является отображение данных от любого распределения до максимально близкого к гауссовскому распределения,чтобы стабилизировать дисперсию и минимизировать асимметрию.</target>
        </trans-unit>
        <trans-unit id="c82f65d47c3f4e11ad468a4165bdc787c51720a5" translate="yes" xml:space="preserve">
          <source>In many real-world examples, there are many ways to extract features from a dataset. Often it is beneficial to combine several methods to obtain good performance. This example shows how to use &lt;code&gt;FeatureUnion&lt;/code&gt; to combine features obtained by PCA and univariate selection.</source>
          <target state="translated">Во многих реальных примерах существует множество способов извлечения объектов из набора данных. Часто бывает полезно комбинировать несколько методов для получения хорошей производительности. В этом примере показано, как использовать &lt;code&gt;FeatureUnion&lt;/code&gt; для объединения функций, полученных с помощью PCA, и одномерного выбора.</target>
        </trans-unit>
        <trans-unit id="9c0b7f3861d3fe001968b978c49f3447d1233fa3" translate="yes" xml:space="preserve">
          <source>In mathematics, the Johnson-Lindenstrauss lemma is a result concerning low-distortion embeddings of points from high-dimensional into low-dimensional Euclidean space. The lemma states that a small set of points in a high-dimensional space can be embedded into a space of much lower dimension in such a way that distances between the points are nearly preserved. The map used for the embedding is at least Lipschitz, and can even be taken to be an orthogonal projection.</source>
          <target state="translated">В математике лемма Джонсона-Линденстрауса-это результат,относящийся к встраиванию точек из высокоразмерного в низкоразмерное евклидовое пространство с низкими искажениями.Лемма утверждает,что небольшой набор точек в высокомерном пространстве может быть встроен в пространство гораздо меньшей размерности таким образом,что расстояния между точками практически сохраняются.Карта,используемая для встраивания,является,по крайней мере,Липшицем и даже может быть принята за ортогональную проекцию.</target>
        </trans-unit>
        <trans-unit id="35a3805825da50966c5f8cb649b1d2ea852b8f59" translate="yes" xml:space="preserve">
          <source>In maximizing the log-likelihood, the positive gradient makes the model prefer hidden states that are compatible with the observed training data. Because of the bipartite structure of RBMs, it can be computed efficiently. The negative gradient, however, is intractable. Its goal is to lower the energy of joint states that the model prefers, therefore making it stay true to the data. It can be approximated by Markov chain Monte Carlo using block Gibbs sampling by iteratively sampling each of \(v\) and \(h\) given the other, until the chain mixes. Samples generated in this way are sometimes referred as fantasy particles. This is inefficient and it is difficult to determine whether the Markov chain mixes.</source>
          <target state="translated">При максимизации вероятности лога положительный градиент заставляет модель отдавать предпочтение скрытым состояниям,совместимым с наблюдаемыми тренировочными данными.Благодаря бипартитовой структуре УКР ее можно эффективно вычислить.Однако отрицательный градиент является трудноразрешимым.Его цель-снизить энергию совместных состояний,которую предпочитает модель,и тем самым заставить ее оставаться верной данным.Его можно аппроксимировать по марковской цепи Монте-Карло,используя блочную выборку Гиббса,путем итеративной выборки каждого из \(v\)и \(h\)с учетом другого,до тех пор,пока цепь не смешается.Образующиеся таким образом пробы иногда называют частицами фантазии.Это неэффективно,и трудно определить,смешивается ли цепь Маркова.</target>
        </trans-unit>
        <trans-unit id="54db7da5f1b2e2f16e8f4dc3a375dac661b78213" translate="yes" xml:space="preserve">
          <source>In multi-label classification, the &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt; function is extended by averaging over the labels as &lt;a href=&quot;#average&quot;&gt;above&lt;/a&gt;.</source>
          <target state="translated">В классификации с несколькими &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;roc_auc_score&lt;/code&gt; &lt;/a&gt; функция roc_auc_score расширяется путем усреднения по меткам, как &lt;a href=&quot;#average&quot;&gt;указано выше&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="d9be5dcb267dcb84c278d12d7b1a881ada760886" translate="yes" xml:space="preserve">
          <source>In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.</source>
          <target state="translated">В многомаркировочной классификации точность подмножества является жесткой метрикой,так как для каждого образца требуется,чтобы каждый набор этикеток был правильно спрогнозирован.</target>
        </trans-unit>
        <trans-unit id="9ff5420b9cd3095ee44bf9941c38c72dce6d517a" translate="yes" xml:space="preserve">
          <source>In multi-label settings</source>
          <target state="translated">В настройках с несколькими этикетками</target>
        </trans-unit>
        <trans-unit id="cf7a69d811fd496380ea6a3966d13bf17ca83f43" translate="yes" xml:space="preserve">
          <source>In multiclass and multilabel classification task, the notions of precision, recall, and F-measures can be applied to each label independently. There are a few ways to combine results across labels, specified by the &lt;code&gt;average&lt;/code&gt; argument to the &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; (multilabel only), &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt;&lt;code&gt;f1_score&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt;&lt;code&gt;fbeta_score&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.precision_recall_fscore_support#sklearn.metrics.precision_recall_fscore_support&quot;&gt;&lt;code&gt;precision_recall_fscore_support&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.precision_score#sklearn.metrics.precision_score&quot;&gt;&lt;code&gt;precision_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.recall_score#sklearn.metrics.recall_score&quot;&gt;&lt;code&gt;recall_score&lt;/code&gt;&lt;/a&gt; functions, as described &lt;a href=&quot;#average&quot;&gt;above&lt;/a&gt;. Note that if all labels are included, &amp;ldquo;micro&amp;rdquo;-averaging in a multiclass setting will produce precision, recall and \(F\) that are all identical to accuracy. Also note that &amp;ldquo;weighted&amp;rdquo; averaging may produce an F-score that is not between precision and recall.</source>
          <target state="translated">В задаче классификации с несколькими классами и метками понятия точности, отзыва и F-мер могут применяться к каждой метке независимо. Есть несколько способов , чтобы объединить результаты по этикеткам, указанных в &lt;code&gt;average&lt;/code&gt; аргумента к &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt; (MultiLabel только), &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt; &lt;code&gt;f1_score&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt; &lt;code&gt;fbeta_score&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.metrics.precision_recall_fscore_support#sklearn.metrics.precision_recall_fscore_support&quot;&gt; &lt;code&gt;precision_recall_fscore_support&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.metrics.precision_score#sklearn.metrics.precision_score&quot;&gt; &lt;code&gt;precision_score&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.metrics.recall_score#sklearn.metrics.recall_score&quot;&gt; &lt;code&gt;recall_score&lt;/code&gt; &lt;/a&gt; функции, как описаны &lt;a href=&quot;#average&quot;&gt;выше&lt;/a&gt;. Обратите внимание, что если включены все метки, &amp;laquo;микро&amp;raquo; -усреднение в настройке мультикласса приведет к точности, отзыву и \ (F \), которые идентичны точности. Также обратите внимание, что &amp;laquo;взвешенное&amp;raquo; усреднение может дать оценку F, которая не находится между точностью и отзывом.</target>
        </trans-unit>
        <trans-unit id="afc91520f5287da47360dcd6fd00b4fb446bcf96" translate="yes" xml:space="preserve">
          <source>In multiclass case, the function expects that either all the labels are included in y_true or an optional labels argument is provided which contains all the labels. The multilabel margin is calculated according to Crammer-Singer&amp;rsquo;s method. As in the binary case, the cumulated hinge loss is an upper bound of the number of mistakes made by the classifier.</source>
          <target state="translated">В случае мультикласса функция ожидает, что либо все метки включены в y_true, либо предоставлен необязательный аргумент меток, содержащий все метки. Поле для нескольких этикеток рассчитывается по методу Краммера-Зингера. Как и в двоичном случае, совокупные потери на шарнирах являются верхней границей количества ошибок, сделанных классификатором.</target>
        </trans-unit>
        <trans-unit id="a7ec36140af641cfb5e4e5e11dec536798cfb2f8" translate="yes" xml:space="preserve">
          <source>In multiclass classification, the Hamming loss correspond to the Hamming distance between &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; which is equivalent to the subset &lt;code&gt;zero_one_loss&lt;/code&gt; function.</source>
          <target state="translated">В мультиклассовой классификации потери Хэмминга соответствуют расстоянию Хэмминга между &lt;code&gt;y_true&lt;/code&gt; и &lt;code&gt;y_pred&lt;/code&gt; , что эквивалентно функции subset &lt;code&gt;zero_one_loss&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a514b0b14d02249930d02d183e261b474a100dbd" translate="yes" xml:space="preserve">
          <source>In multiclass classification, the Hamming loss corresponds to the Hamming distance between &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; which is equivalent to the subset &lt;code&gt;zero_one_loss&lt;/code&gt; function, when &lt;code&gt;normalize&lt;/code&gt; parameter is set to True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff1916ae5265c4d87d1472e5cc3e0c2594a22de8" translate="yes" xml:space="preserve">
          <source>In multiclass classification, the Hamming loss corresponds to the Hamming distance between &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; which is similar to the &lt;a href=&quot;#zero-one-loss&quot;&gt;Zero one loss&lt;/a&gt; function. However, while zero-one loss penalizes prediction sets that do not strictly match true sets, the Hamming loss penalizes individual labels. Thus the Hamming loss, upper bounded by the zero-one loss, is always between zero and one, inclusive; and predicting a proper subset or superset of the true labels will give a Hamming loss between zero and one, exclusive.</source>
          <target state="translated">В мультиклассовой классификации потери Хэмминга соответствуют расстоянию Хэмминга между &lt;code&gt;y_true&lt;/code&gt; и &lt;code&gt;y_pred&lt;/code&gt; , которое аналогично функции &lt;a href=&quot;#zero-one-loss&quot;&gt;потерь Zero one&lt;/a&gt; . Однако, в то время как потеря нуля или единицы наказывает наборы предсказаний, которые не строго соответствуют истинным наборам, потеря Хэмминга наказывает отдельные метки. Таким образом, потеря Хэмминга, ограниченная сверху потерей нуля или единицы, всегда находится между нулем и единицей включительно; и прогнозирование надлежащего подмножества или надмножества истинных меток даст исключительную потерю Хэмминга от нуля до единицы.</target>
        </trans-unit>
        <trans-unit id="cf7ce831a18d046dad4e38dc2cae92648b792778" translate="yes" xml:space="preserve">
          <source>In multilabel classification, the &lt;a href=&quot;generated/sklearn.metrics.zero_one_loss#sklearn.metrics.zero_one_loss&quot;&gt;&lt;code&gt;zero_one_loss&lt;/code&gt;&lt;/a&gt; scores a subset as one if its labels strictly match the predictions, and as a zero if there are any errors. By default, the function returns the percentage of imperfectly predicted subsets. To get the count of such subsets instead, set &lt;code&gt;normalize&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">В классификации с несколькими &lt;a href=&quot;generated/sklearn.metrics.zero_one_loss#sklearn.metrics.zero_one_loss&quot;&gt; &lt;code&gt;zero_one_loss&lt;/code&gt; &lt;/a&gt; оценивает подмножество как единицу, если его метки строго соответствуют предсказаниям, и как ноль, если есть какие-либо ошибки. По умолчанию функция возвращает процент неправильно спрогнозированных подмножеств. Чтобы вместо этого получить количество таких подмножеств, установите для &lt;code&gt;normalize&lt;/code&gt; значение &lt;code&gt;False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2cdc777c3fd9aacea19e984339f1423c55608098" translate="yes" xml:space="preserve">
          <source>In multilabel classification, the Hamming loss is different from the subset zero-one loss. The zero-one loss considers the entire set of labels for a given sample incorrect if it does entirely match the true set of labels. Hamming loss is more forgiving in that it penalizes the individual labels.</source>
          <target state="translated">В многомаркировочной классификации потери по Хаммингу отличаются от подмножества потерь по нулю.Нулевая потеря считает весь набор меток для данного образца неверным,если он полностью совпадает с истинным набором меток.Потеря при ударе более простительна в том смысле,что она наказывает отдельные этикетки.</target>
        </trans-unit>
        <trans-unit id="602aeb7c2d89b27ea6d03c59146d4b4fecde4c31" translate="yes" xml:space="preserve">
          <source>In multilabel classification, the Hamming loss is different from the subset zero-one loss. The zero-one loss considers the entire set of labels for a given sample incorrect if it does not entirely match the true set of labels. Hamming loss is more forgiving in that it penalizes only the individual labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00e9bece59054d08c4ac787e06eeb4fc8070bdab" translate="yes" xml:space="preserve">
          <source>In multilabel classification, the function returns the subset accuracy. If the entire set of predicted labels for a sample strictly match with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0.</source>
          <target state="translated">При многомаркировочной классификации функция возвращает точность подмножества.Если весь набор прогнозируемых меток для образца строго совпадает с истинным набором меток,то точность подмножества составляет 1.0;в противном случае-0.0.</target>
        </trans-unit>
        <trans-unit id="7cd1b88a6c55666089bdc7543f7e259d70d5898d" translate="yes" xml:space="preserve">
          <source>In multilabel classification, the zero_one_loss function corresponds to the subset zero-one loss: for each sample, the entire set of labels must be correctly predicted, otherwise the loss for that sample is equal to one.</source>
          <target state="translated">При многомаркировочной классификации функция zero_one_loss соответствует подмножеству нулевых потерь:для каждой выборки должен быть правильно спрогнозирован весь набор меток,иначе потери для этой выборки равны единице.</target>
        </trans-unit>
        <trans-unit id="c56a96e702a01557c0cb1c7c6c5d254cdaebcc8b" translate="yes" xml:space="preserve">
          <source>In multilabel classification, this function computes subset accuracy: the set of labels predicted for a sample must &lt;em&gt;exactly&lt;/em&gt; match the corresponding set of labels in y_true.</source>
          <target state="translated">В классификации по нескольким меткам эта функция вычисляет точность подмножества: набор меток, предсказанных для выборки, должен &lt;em&gt;точно&lt;/em&gt; соответствовать соответствующему набору меток в y_true.</target>
        </trans-unit>
        <trans-unit id="00440d1e0316ae49b10a616cf581f0acff1a935a" translate="yes" xml:space="preserve">
          <source>In multilabel confusion matrix \(MCM\), the count of true negatives is \(MCM_{:,0,0}\), false negatives is \(MCM_{:,1,0}\), true positives is \(MCM_{:,1,1}\) and false positives is \(MCM_{:,0,1}\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3fad4287dcc0210ad8169708b233947ca706f077" translate="yes" xml:space="preserve">
          <source>In multilabel learning, each sample can have any number of ground truth labels associated with it. The goal is to give high scores and better rank to the ground truth labels.</source>
          <target state="translated">При многомаркировочном обучении каждый образец может иметь любое количество связанных с ним ярлыков &quot;грунтовой истины&quot;.Цель состоит в том,чтобы дать высокие баллы и лучшее ранжирование основным знакам истины.</target>
        </trans-unit>
        <trans-unit id="9d6449537c42279d12e406059563c338784d06f3" translate="yes" xml:space="preserve">
          <source>In multilabel learning, the joint set of binary classification tasks is expressed with label binary indicator array: each sample is one row of a 2d array of shape (n_samples, n_classes) with binary values: the one, i.e. the non zero elements, corresponds to the subset of labels. An array such as &lt;code&gt;np.array([[1, 0, 0], [0, 1, 1], [0, 0, 0]])&lt;/code&gt; represents label 0 in the first sample, labels 1 and 2 in the second sample, and no labels in the third sample.</source>
          <target state="translated">В многоэлементном обучении объединенный набор задач двоичной классификации выражается с помощью двоичного индикаторного массива меток: каждая выборка представляет собой одну строку двумерного массива формы (n_samples, n_classes) с двоичными значениями: единица, то есть ненулевые элементы, соответствует подмножество меток. Такой массив, как &lt;code&gt;np.array([[1, 0, 0], [0, 1, 1], [0, 0, 0]])&lt;/code&gt; представляет метку 0 в первом примере, метки 1 и 2 во втором примере. , а в третьем примере меток нет.</target>
        </trans-unit>
        <trans-unit id="65f6ef4e3d2b7a1359958abf87c802c2de77e1d9" translate="yes" xml:space="preserve">
          <source>In normal usage, the Calinski-Harabasz index is applied to the results of a cluster analysis:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c2c0f769c8a98dc6df3f2e7afe566ac80c0f339" translate="yes" xml:space="preserve">
          <source>In normal usage, the Calinski-Harabaz index is applied to the results of a cluster analysis.</source>
          <target state="translated">При обычном использовании к результатам кластерного анализа применяется индекс Калински-Харабаз.</target>
        </trans-unit>
        <trans-unit id="5f0c7d20ec265094d1673fd625fd38165b384452" translate="yes" xml:space="preserve">
          <source>In normal usage, the Davies-Bouldin index is applied to the results of a cluster analysis as follows:</source>
          <target state="translated">При обычном использовании индекс Дэвиса-Болдин применяется к результатам кластерного анализа следующим образом:</target>
        </trans-unit>
        <trans-unit id="0488e7351783ef8ef785f4bdea49af8c75724adf" translate="yes" xml:space="preserve">
          <source>In normal usage, the Silhouette Coefficient is applied to the results of a cluster analysis.</source>
          <target state="translated">При обычном использовании к результатам кластерного анализа применяется коэффициент силуэта.</target>
        </trans-unit>
        <trans-unit id="af7916eabb756a4304309b1e18ceea097a7a5071" translate="yes" xml:space="preserve">
          <source>In order to address the wider task of Natural Language Understanding, the local structure of sentences and paragraphs should thus be taken into account. Many such models will thus be casted as &amp;ldquo;Structured output&amp;rdquo; problems which are currently outside of the scope of scikit-learn.</source>
          <target state="translated">Таким образом, для решения более широкой задачи понимания естественного языка необходимо учитывать локальную структуру предложений и абзацев. Таким образом, многие такие модели будут представлены как задачи &amp;laquo;Структурированный вывод&amp;raquo;, которые в настоящее время выходят за рамки scikit-learn.</target>
        </trans-unit>
        <trans-unit id="819693d214fc959100941f9c2bf3cb570fc069ec" translate="yes" xml:space="preserve">
          <source>In order to address this, scikit-learn provides utilities for the most common ways to extract numerical features from text content, namely:</source>
          <target state="translated">Чтобы решить эту проблему,scikit-learn предоставляет утилиты для наиболее распространённых способов извлечения числовых функций из текстового содержимого,а именно:</target>
        </trans-unit>
        <trans-unit id="5bdd52099ccc039c40b609f18b326c63aea62fae" translate="yes" xml:space="preserve">
          <source>In order to be able to store such a matrix in memory but also to speed up algebraic operations matrix / vector, implementations will typically use a sparse representation such as the implementations available in the &lt;code&gt;scipy.sparse&lt;/code&gt; package.</source>
          <target state="translated">Чтобы иметь возможность хранить такую ​​матрицу в памяти, а также для ускорения алгебраических операций матрица / вектор, реализации обычно используют разреженное представление, такое как реализации, доступные в пакете &lt;code&gt;scipy.sparse&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="af0531a207de85560d0c6e1dcc4e5a478aa65d8d" translate="yes" xml:space="preserve">
          <source>In order to build histograms, the input data &lt;code&gt;X&lt;/code&gt; needs to be binned into integer-valued bins. This binning procedure does require sorting the feature values, but it only happens once at the very beginning of the boosting process (not at each node, like in &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0bf98f40bc311f4824763dea8c552bc0812d861" translate="yes" xml:space="preserve">
          <source>In order to feed predictive or clustering models with the text data, one first need to turn the text into vectors of numerical values suitable for statistical analysis. This can be achieved with the utilities of the &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; as demonstrated in the following example that extract &lt;a href=&quot;https://en.wikipedia.org/wiki/Tf-idf&quot;&gt;TF-IDF&lt;/a&gt; vectors of unigram tokens from a subset of 20news:</source>
          <target state="translated">Чтобы снабдить прогнозные модели или модели кластеризации текстовыми данными, сначала нужно преобразовать текст в векторы числовых значений, пригодные для статистического анализа. Это может быть достигнуто с помощью утилит &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; , как показано в следующем примере, которые извлекают векторы &lt;a href=&quot;https://en.wikipedia.org/wiki/Tf-idf&quot;&gt;TF-IDF&lt;/a&gt; токенов униграммы из подмножества 20news:</target>
        </trans-unit>
        <trans-unit id="c3614fb1e15f18200960459d2e1c203458a6eae2" translate="yes" xml:space="preserve">
          <source>In order to fit linear models with those predictors it is therefore necessary to perform standard feature transformations as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a439a73e36b65ee0a94b3f1d9d89e3ac154697cf" translate="yes" xml:space="preserve">
          <source>In order to get faster execution times for this first example we will work on a partial dataset with only 4 categories out of the 20 available in the dataset:</source>
          <target state="translated">Для того,чтобы получить более быстрое время выполнения для этого первого примера,мы будем работать с частичным набором данных только с 4 категориями из 20 доступных в наборе данных:</target>
        </trans-unit>
        <trans-unit id="da7edac191ef2f2a6bab6d167570c5dc3d626b83" translate="yes" xml:space="preserve">
          <source>In order to learn good latent representations from a small dataset, we artificially generate more labeled data by perturbing the training data with linear shifts of 1 pixel in each direction.</source>
          <target state="translated">Для изучения хороших латентных представлений из небольшого набора данных мы искусственно генерируем более маркированные данные,возмущая тренировочные данные линейными сдвигами на 1 пиксель в каждом направлении.</target>
        </trans-unit>
        <trans-unit id="6983d2c6ff1cbf277ea5d9522b128070bfd0a615" translate="yes" xml:space="preserve">
          <source>In order to make the vectorizer =&amp;gt; transformer =&amp;gt; classifier easier to work with, &lt;code&gt;scikit-learn&lt;/code&gt; provides a &lt;a href=&quot;../../modules/generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; class that behaves like a compound classifier:</source>
          <target state="translated">Чтобы упростить работу с векторизатором =&amp;gt; преобразователем =&amp;gt; классификатором, &lt;code&gt;scikit-learn&lt;/code&gt; предоставляет класс &lt;a href=&quot;../../modules/generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;Pipeline&lt;/code&gt; &lt;/a&gt; который ведет себя как составной классификатор:</target>
        </trans-unit>
        <trans-unit id="5257e11193f291f6f81d5d2347e3cbb71ec9f310" translate="yes" xml:space="preserve">
          <source>In order to perform machine learning on text documents, we first need to turn the text content into numerical feature vectors.</source>
          <target state="translated">Для того чтобы выполнять машинное обучение на текстовых документах,сначала необходимо превратить текстовое содержание в числовые функциональные векторы.</target>
        </trans-unit>
        <trans-unit id="7b973d24b18f4331d1cc68b945953f9c40c766fe" translate="yes" xml:space="preserve">
          <source>In order to predict the class labels based on the predicted class-probabilities (scikit-learn estimators in the VotingClassifier must support &lt;code&gt;predict_proba&lt;/code&gt; method):</source>
          <target state="translated">Чтобы предсказать метки классов на основе прогнозируемых вероятностей классов (оценки scikit-learn в VotingClassifier должны поддерживать метод &lt;code&gt;predict_proba&lt;/code&gt; ):</target>
        </trans-unit>
        <trans-unit id="a7ffbb7849ad7a74935991324e062c6b6722378d" translate="yes" xml:space="preserve">
          <source>In order to re-weight the count features into floating point values suitable for usage by a classifier it is very common to use the tf&amp;ndash;idf transform.</source>
          <target state="translated">Чтобы повторно взвесить функции счетчика в значения с плавающей запятой, пригодные для использования классификатором, очень часто используется преобразование tf &amp;ndash; idf.</target>
        </trans-unit>
        <trans-unit id="4707665df8a323c1a68b209bc6166b3798e4ea75" translate="yes" xml:space="preserve">
          <source>In order to rebuild a similar model with future versions of scikit-learn, additional metadata should be saved along the pickled model:</source>
          <target state="translated">Чтобы восстановить аналогичную модель с будущими версиями scikit-learn,дополнительные метаданные должны быть сохранены вдоль маринованной модели:</target>
        </trans-unit>
        <trans-unit id="168239ecf279021917cbfef805f1d7d711ae1c44" translate="yes" xml:space="preserve">
          <source>In order to test if a classification score is significative a technique in repeating the classification procedure after randomizing, permuting, the labels. The p-value is then given by the percentage of runs for which the score obtained is greater than the classification score obtained in the first place.</source>
          <target state="translated">Для того,чтобы проверить,является ли балл классификации значимым,необходимо использовать технику повторения процедуры классификации после рандомизации,прослушивания этикеток.Р-значение дается в процентах прогонов,для которых полученная оценка больше,чем классификационная оценка,полученная на первом месте.</target>
        </trans-unit>
        <trans-unit id="fdc8e1656ba1332f0933f9f656403151b15252d2" translate="yes" xml:space="preserve">
          <source>In other words, return an input X_original whose transform would be X.</source>
          <target state="translated">Другими словами,верните вход X_original,преобразование которого будет X.</target>
        </trans-unit>
        <trans-unit id="f84fbaf022a2c87e2f72b92c7b8059751d7f8963" translate="yes" xml:space="preserve">
          <source>In other words, we &lt;em&gt;decomposed&lt;/em&gt; matrix \(\mathbf{X}\).</source>
          <target state="translated">Другими словами, мы &lt;em&gt;разложили&lt;/em&gt; матрицу \ (\ mathbf {X} \).</target>
        </trans-unit>
        <trans-unit id="573ad5780d66d8749d635925a4f90732aa002652" translate="yes" xml:space="preserve">
          <source>In particular Rosenberg and Hirschberg (2007) define the following two desirable objectives for any cluster assignment:</source>
          <target state="translated">В частности,Розенберг и Хиршберг (2007)определяют следующие две желательные цели для любого кластерного задания:</target>
        </trans-unit>
        <trans-unit id="dafd8fff090495231531a6dce6a0d9bf23cd3c87" translate="yes" xml:space="preserve">
          <source>In particular in a &lt;strong&gt;supervised setting&lt;/strong&gt; it can be successfully combined with fast and scalable linear models to train &lt;strong&gt;document classifiers&lt;/strong&gt;, for instance:</source>
          <target state="translated">В частности, при &lt;strong&gt;контролируемой настройке&lt;/strong&gt; его можно успешно комбинировать с быстрыми и масштабируемыми линейными моделями для обучения &lt;strong&gt;классификаторов документов&lt;/strong&gt; , например:</target>
        </trans-unit>
        <trans-unit id="b70db829e86f8b0b87ee4b4ea9165e2800cb135e" translate="yes" xml:space="preserve">
          <source>In particular the interrogative form &amp;ldquo;Is this&amp;rdquo; is only present in the last document:</source>
          <target state="translated">В частности, вопросительная форма Is this присутствует только в последнем документе:</target>
        </trans-unit>
        <trans-unit id="48a72aaef5f57348c3c02ddfbd84f34663c56133" translate="yes" xml:space="preserve">
          <source>In particular we name:</source>
          <target state="translated">В частности,мы называем:</target>
        </trans-unit>
        <trans-unit id="32bae48b70c29501503578b88b61dfab45b0637c" translate="yes" xml:space="preserve">
          <source>In particular, \(\nu = 3/2\):</source>
          <target state="translated">В частности,\(\nu=3/2\):</target>
        </trans-unit>
        <trans-unit id="204dd46cfb26952328568f02a630bc8ec2809e56" translate="yes" xml:space="preserve">
          <source>In particular, truncated SVD works on term count/tf-idf matrices as returned by the vectorizers in &lt;a href=&quot;../classes#module-sklearn.feature_extraction.text&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt;&lt;/a&gt;. In that context, it is known as latent semantic analysis (LSA).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff34c019cd4067dd0b8a1a6d1536db31ff351b58" translate="yes" xml:space="preserve">
          <source>In particular, truncated SVD works on term count/tf-idf matrices as returned by the vectorizers in sklearn.feature_extraction.text. In that context, it is known as latent semantic analysis (LSA).</source>
          <target state="translated">В частности,усеченный SVD работает на матрицах count/tf-idf сроков,возвращаемых векторизаторами в sklearn.feature_extraction.text.В этом контексте он известен как латентный семантический анализ (LSA).</target>
        </trans-unit>
        <trans-unit id="74d856933005d819af2a4b7d2ce24317b5186453" translate="yes" xml:space="preserve">
          <source>In practice Spectral Clustering is very useful when the structure of the individual clusters is highly non-convex or more generally when a measure of the center and spread of the cluster is not a suitable description of the complete cluster. For instance when clusters are nested circles on the 2D plan.</source>
          <target state="translated">На практике Spectral Clustering (спектральная кластеризация)очень полезна,когда структура отдельных кластеров сильно не сгущается или,в более общем плане,когда мера центра и распространения кластера не является подходящим описанием полного кластера.Например,когда кластеры вложены в круги на 2D плане.</target>
        </trans-unit>
        <trans-unit id="316ef03a3b1d8845e6fcfccde0af625da5037900" translate="yes" xml:space="preserve">
          <source>In practice Spectral Clustering is very useful when the structure of the individual clusters is highly non-convex or more generally when a measure of the center and spread of the cluster is not a suitable description of the complete cluster. For instance when clusters are nested circles on the 2D plane.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21d1a0735c97d36c546ea3246065facc34b4f5a9" translate="yes" xml:space="preserve">
          <source>In practice Spectral Clustering is very useful when the structure of the individual clusters is highly non-convex or more generally when a measure of the center and spread of the cluster is not a suitable description of the complete cluster. For instance, when clusters are nested circles on the 2D plane.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5662b7bb73c6d21ae298513382716bd3fe526ba2" translate="yes" xml:space="preserve">
          <source>In practice the local density is obtained from the k-nearest neighbors. The LOF score of an observation is equal to the ratio of the average local density of his k-nearest neighbors, and its own local density: a normal instance is expected to have a local density similar to that of its neighbors, while abnormal data are expected to have much smaller local density.</source>
          <target state="translated">На практике локальная плотность получается у k-самых близких соседей.Показатель LOF наблюдения равен соотношению средней локальной плотности его k-крестных соседей и его собственной локальной плотности:ожидается,что нормальный экземпляр будет иметь локальную плотность,аналогичную плотности его соседей,в то время как аномальные данные будут иметь гораздо меньшую локальную плотность.</target>
        </trans-unit>
        <trans-unit id="7ab811a62d63edef5c9695fca6cafd8cc266404c" translate="yes" xml:space="preserve">
          <source>In practice those estimates are stored as an attribute named &lt;code&gt;feature_importances_&lt;/code&gt; on the fitted model. This is an array with shape &lt;code&gt;(n_features,)&lt;/code&gt; whose values are positive and sum to 1.0. The higher the value, the more important is the contribution of the matching feature to the prediction function.</source>
          <target state="translated">На практике эти оценки сохраняются как атрибут с именем &lt;code&gt;feature_importances_&lt;/code&gt; в подобранной модели. Это массив с формой &lt;code&gt;(n_features,)&lt;/code&gt; , значения которой положительны и в сумме равны 1.0. Чем выше значение, тем важнее вклад функции сопоставления в функцию прогнозирования.</target>
        </trans-unit>
        <trans-unit id="2f91c327e74b19930bc0b8d2d9c2f5d99fe44af7" translate="yes" xml:space="preserve">
          <source>In practice we often ignore the shape of the distribution and just transform the data to center it by removing the mean value of each feature, then scale it by dividing non-constant features by their standard deviation.</source>
          <target state="translated">На практике мы часто игнорируем форму распределения и просто преобразовываем данные в центр,удаляя среднее значение каждого признака,а затем масштабируем его,разделяя неконстантные признаки на их стандартное отклонение.</target>
        </trans-unit>
        <trans-unit id="4c632dd9d37d8e850afe2fbbbdbddfedb108d119" translate="yes" xml:space="preserve">
          <source>In practice, \(\mu\) and \(\Sigma\) are replaced by some estimates. The usual covariance maximum likelihood estimate is very sensitive to the presence of outliers in the data set and therefor, the corresponding Mahalanobis distances are. One would better have to use a robust estimator of covariance to guarantee that the estimation is resistant to &amp;ldquo;erroneous&amp;rdquo; observations in the data set and that the associated Mahalanobis distances accurately reflect the true organisation of the observations.</source>
          <target state="translated">На практике \ (\ mu \) и \ (\ Sigma \) заменяются некоторыми оценками. Обычная ковариационная оценка максимального правдоподобия очень чувствительна к наличию выбросов в наборе данных и, следовательно, соответствующих расстояний Махаланобиса. Лучше было бы использовать надежную оценку ковариации, чтобы гарантировать, что оценка устойчива к &amp;laquo;ошибочным&amp;raquo; наблюдениям в наборе данных и что соответствующие расстояния Махаланобиса точно отражают истинную организацию наблюдений.</target>
        </trans-unit>
        <trans-unit id="7f19bfe5f66f3783151b8147191d95599d9b587d" translate="yes" xml:space="preserve">
          <source>In practice, the k-means algorithm is very fast (one of the fastest clustering algorithms available), but it falls in local minima. That&amp;rsquo;s why it can be useful to restart it several times.</source>
          <target state="translated">На практике алгоритм k-средних очень быстр (один из самых быстрых доступных алгоритмов кластеризации), но он попадает в локальные минимумы. Вот почему может быть полезно перезапустить его несколько раз.</target>
        </trans-unit>
        <trans-unit id="514529e761d628932a46cfab06e171128c270c12" translate="yes" xml:space="preserve">
          <source>In practice, whether parallelism is helpful at improving runtime depends on many factors. It is usually a good idea to experiment rather than assuming that increasing the number of workers is always a good thing. In some cases it can be highly detrimental to performance to run multiple copies of some estimators or functions in parallel (see oversubscription below).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f131bcc125dc920f59e2c48cc0ec0622c3531f86" translate="yes" xml:space="preserve">
          <source>In practice, you will have to handle yourself the column data type. If you want some columns to be considered as &lt;code&gt;category&lt;/code&gt;, you will have to convert them into categorical columns. If you are using pandas, you can refer to their documentation regarding &lt;a href=&quot;https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html&quot;&gt;Categorical data&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c017831824360a69856c6ccfffcd3f1b73574d4" translate="yes" xml:space="preserve">
          <source>In practise, a stacking predictor predict as good as the best predictor of the base layer and even sometimes outputperform it by combining the different strength of the these predictors. However, training a stacking predictor is computationally expensive.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0aad0cfd8ffb7884222ad0979279d2b7ce81ef15" translate="yes" xml:space="preserve">
          <source>In principle, any function can be passed that provides a &lt;code&gt;rvs&lt;/code&gt; (random variate sample) method to sample a value. A call to the &lt;code&gt;rvs&lt;/code&gt; function should provide independent random samples from possible parameter values on consecutive calls.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9809378b0338436bd7bbe8f2e2070a6272b570d" translate="yes" xml:space="preserve">
          <source>In problems where it is desired to give more importance to certain classes or certain individual samples keywords &lt;code&gt;class_weight&lt;/code&gt; and &lt;code&gt;sample_weight&lt;/code&gt; can be used.</source>
          <target state="translated">В задачах, где желательно придать большее значение определенным классам или определенным отдельным образцам, можно использовать ключевые слова &lt;code&gt;class_weight&lt;/code&gt; и &lt;code&gt;sample_weight&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="274191e11959a25ec702f3eb0728b40adf181870" translate="yes" xml:space="preserve">
          <source>In problems where it is desired to give more importance to certain classes or certain individual samples, the parameters &lt;code&gt;class_weight&lt;/code&gt; and &lt;code&gt;sample_weight&lt;/code&gt; can be used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c88cb15e9453fb980c7d19e00322e852632f7bf2" translate="yes" xml:space="preserve">
          <source>In random forests (see &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;RandomForestClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt;&lt;code&gt;RandomForestRegressor&lt;/code&gt;&lt;/a&gt; classes), each tree in the ensemble is built from a sample drawn with replacement (i.e., a bootstrap sample) from the training set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cae7f41bfdb577edc832687cbceee9865d3220c5" translate="yes" xml:space="preserve">
          <source>In random forests (see &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;RandomForestClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt;&lt;code&gt;RandomForestRegressor&lt;/code&gt;&lt;/a&gt; classes), each tree in the ensemble is built from a sample drawn with replacement (i.e., a bootstrap sample) from the training set. In addition, when splitting a node during the construction of the tree, the split that is chosen is no longer the best split among all features. Instead, the split that is picked is the best split among a random subset of the features. As a result of this randomness, the bias of the forest usually slightly increases (with respect to the bias of a single non-random tree) but, due to averaging, its variance also decreases, usually more than compensating for the increase in bias, hence yielding an overall better model.</source>
          <target state="translated">В случайных лесах (см. &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt; &lt;code&gt;RandomForestClassifier&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt; &lt;code&gt;RandomForestRegressor&lt;/code&gt; &lt;/a&gt; ) каждое дерево в ансамбле строится из выборки, взятой с заменой (т. Е. Выборки начальной загрузки) из обучающего набора. Кроме того, при разделении узла во время построения дерева выбранное разделение больше не является лучшим разделением среди всех функций. Вместо этого выбранное разбиение является лучшим разбиением среди случайного подмножества функций. В результате этой случайности смещение леса обычно немного увеличивается (по сравнению с смещением одного неслучайного дерева), но из-за усреднения его дисперсия также уменьшается, обычно более чем компенсируя увеличение смещения, следовательно, дает в целом лучшую модель.</target>
        </trans-unit>
        <trans-unit id="eee63fdeeb00f1867cdf7e3f336a4276e1d12ae2" translate="yes" xml:space="preserve">
          <source>In regression, the expected mean squared error of an estimator can be decomposed in terms of bias, variance and noise. On average over datasets of the regression problem, the bias term measures the average amount by which the predictions of the estimator differ from the predictions of the best possible estimator for the problem (i.e., the Bayes model). The variance term measures the variability of the predictions of the estimator when fit over different instances LS of the problem. Finally, the noise measures the irreducible part of the error which is due the variability in the data.</source>
          <target state="translated">В регрессии ожидаемая средняя квадратная ошибка оценщика может быть разложена в терминах смещения,дисперсии и шума.В среднем по наборам данных задачи регрессии,член смещения измеряет среднюю величину,на которую предсказания оценщика отличаются от предсказаний лучшего из возможных оценщиков задачи (т.е.модели Байеса).Дисперсионный член измеряет изменчивость предсказаний оценщика,когда подгоняется под различные экземпляры LS задачи.Наконец,шум измеряет неисчерпаемую часть ошибки,которая обусловлена изменчивостью данных.</target>
        </trans-unit>
        <trans-unit id="3eae88b0a075df5d4090eee16e911849fedcc7b3" translate="yes" xml:space="preserve">
          <source>In regression, the output remains as \(f(x)\); therefore, output activation function is just the identity function.</source>
          <target state="translated">В регрессии выход остается в виде \(f(x)\);поэтому выходная функция активации является лишь идентификационной функцией.</target>
        </trans-unit>
        <trans-unit id="253be6f032627aec5a3b2c4240659e2190b9fba2" translate="yes" xml:space="preserve">
          <source>In scikit-learn a random split into training and test sets can be quickly computed with the &lt;a href=&quot;generated/sklearn.model_selection.train_test_split#sklearn.model_selection.train_test_split&quot;&gt;&lt;code&gt;train_test_split&lt;/code&gt;&lt;/a&gt; helper function. Let&amp;rsquo;s load the iris data set to fit a linear support vector machine on it:</source>
          <target state="translated">В scikit-learn случайное разбиение на обучающие и тестовые наборы можно быстро вычислить с &lt;a href=&quot;generated/sklearn.model_selection.train_test_split#sklearn.model_selection.train_test_split&quot;&gt; &lt;code&gt;train_test_split&lt;/code&gt; &lt;/a&gt; вспомогательной функции train_test_split . Давайте загрузим набор данных радужной оболочки, чтобы он соответствовал машине линейных опорных векторов:</target>
        </trans-unit>
        <trans-unit id="bdcdb5bf0b220e10633a04e3b3d7b23fb832fcf9" translate="yes" xml:space="preserve">
          <source>In scikit-learn, an estimator for classification is a Python object that implements the methods &lt;code&gt;fit(X, y)&lt;/code&gt; and &lt;code&gt;predict(T)&lt;/code&gt;.</source>
          <target state="translated">В scikit-learn оценщик для классификации - это объект Python, который реализует методы &lt;code&gt;fit(X, y)&lt;/code&gt; и &lt;code&gt;predict(T)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a15700735758e7e1606b13cd4f276e5fe1e0ef96" translate="yes" xml:space="preserve">
          <source>In scikit-learn, bagging methods are offered as a unified &lt;a href=&quot;generated/sklearn.ensemble.baggingclassifier#sklearn.ensemble.BaggingClassifier&quot;&gt;&lt;code&gt;BaggingClassifier&lt;/code&gt;&lt;/a&gt; meta-estimator (resp. &lt;a href=&quot;generated/sklearn.ensemble.baggingregressor#sklearn.ensemble.BaggingRegressor&quot;&gt;&lt;code&gt;BaggingRegressor&lt;/code&gt;&lt;/a&gt;), taking as input a user-specified base estimator along with parameters specifying the strategy to draw random subsets. In particular, &lt;code&gt;max_samples&lt;/code&gt; and &lt;code&gt;max_features&lt;/code&gt; control the size of the subsets (in terms of samples and features), while &lt;code&gt;bootstrap&lt;/code&gt; and &lt;code&gt;bootstrap_features&lt;/code&gt; control whether samples and features are drawn with or without replacement. When using a subset of the available samples the generalization accuracy can be estimated with the out-of-bag samples by setting &lt;code&gt;oob_score=True&lt;/code&gt;. As an example, the snippet below illustrates how to instantiate a bagging ensemble of &lt;code&gt;KNeighborsClassifier&lt;/code&gt; base estimators, each built on random subsets of 50% of the samples and 50% of the features.</source>
          <target state="translated">В scikit-learn методы &lt;a href=&quot;generated/sklearn.ensemble.baggingclassifier#sklearn.ensemble.BaggingClassifier&quot;&gt; &lt;code&gt;BaggingClassifier&lt;/code&gt; &lt;/a&gt; предлагаются в виде унифицированного метаоценки BaggingClassifier (соответственно, &lt;a href=&quot;generated/sklearn.ensemble.baggingregressor#sklearn.ensemble.BaggingRegressor&quot;&gt; &lt;code&gt;BaggingRegressor&lt;/code&gt; &lt;/a&gt; ), принимающего в качестве входных данных указанную пользователем базовую оценку вместе с параметрами, определяющими стратегию рисования случайных подмножеств. В частности, &lt;code&gt;max_samples&lt;/code&gt; и &lt;code&gt;max_features&lt;/code&gt; управляют размером подмножеств (с точки зрения образцов и функций), в то время как &lt;code&gt;bootstrap&lt;/code&gt; и &lt;code&gt;bootstrap_features&lt;/code&gt; контролируют, отрисовываются ли образцы и функции с заменой или без нее. При использовании подмножества доступных образцов точность обобщения можно оценить с помощью образцов вне пакета, установив &lt;code&gt;oob_score=True&lt;/code&gt; . В качестве примера приведенный ниже фрагмент иллюстрирует, как создать экземпляр ансамбля &lt;code&gt;KNeighborsClassifier&lt;/code&gt; базовых оценщиков KNeighborsClassifier , каждый из которых построен на случайных подмножествах из 50% выборок и 50% функций.</target>
        </trans-unit>
        <trans-unit id="0848ab34fddbc88dcbfdd395d0519986e8d182eb" translate="yes" xml:space="preserve">
          <source>In scikit-learn, this transformation (with a user-defined shrinkage coefficient) can be directly applied to a pre-computed covariance with the &lt;a href=&quot;generated/sklearn.covariance.shrunk_covariance#sklearn.covariance.shrunk_covariance&quot;&gt;&lt;code&gt;shrunk_covariance&lt;/code&gt;&lt;/a&gt; method. Also, a shrunk estimator of the covariance can be fitted to data with a &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance&quot;&gt;&lt;code&gt;ShrunkCovariance&lt;/code&gt;&lt;/a&gt; object and its &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance.fit&quot;&gt;&lt;code&gt;ShrunkCovariance.fit&lt;/code&gt;&lt;/a&gt; method. Again, results depend on whether the data are centered, so one may want to use the &lt;code&gt;assume_centered&lt;/code&gt; parameter accurately.</source>
          <target state="translated">В scikit-learn это преобразование (с определяемым пользователем коэффициентом усадки) можно напрямую применить к предварительно вычисленной ковариации с &lt;a href=&quot;generated/sklearn.covariance.shrunk_covariance#sklearn.covariance.shrunk_covariance&quot;&gt; &lt;code&gt;shrunk_covariance&lt;/code&gt; &lt;/a&gt; метода shrunk_covariance . Кроме того, сжатую оценку ковариации можно &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance&quot;&gt; &lt;code&gt;ShrunkCovariance&lt;/code&gt; &lt;/a&gt; к данным с помощью объекта ShrunkCovariance и его метода &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance.fit&quot;&gt; &lt;code&gt;ShrunkCovariance.fit&lt;/code&gt; &lt;/a&gt; . Опять же, результаты зависят от того, центрированы ли данные, поэтому можно точно использовать параметр &lt;code&gt;assume_centered&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="77c9e3634b9d256acc307751b68c900b0b833a29" translate="yes" xml:space="preserve">
          <source>In single precision, &lt;code&gt;mean&lt;/code&gt; can be inaccurate:</source>
          <target state="translated">При одинарной точности &lt;code&gt;mean&lt;/code&gt; может быть неточным:</target>
        </trans-unit>
        <trans-unit id="640c5c337251b299605fe0c1704cd43d50fcda84" translate="yes" xml:space="preserve">
          <source>In some cases it&amp;rsquo;s not necessary to include higher powers of any single feature, but only the so-called &lt;em&gt;interaction features&lt;/em&gt; that multiply together at most \(d\) distinct features. These can be gotten from &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt;&lt;code&gt;PolynomialFeatures&lt;/code&gt;&lt;/a&gt; with the setting &lt;code&gt;interaction_only=True&lt;/code&gt;.</source>
          <target state="translated">В некоторых случаях необязательно включать более высокие степени какой-либо отдельной функции, а только так называемые &lt;em&gt;функции взаимодействия,&lt;/em&gt; которые умножаются вместе не более чем на \ (d \) различных функций. Их можно получить из &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt; &lt;code&gt;PolynomialFeatures&lt;/code&gt; &lt;/a&gt; с установкой &lt;code&gt;interaction_only=True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4976a8ab8df4ced9a6ceb9c8368b484dbc953550" translate="yes" xml:space="preserve">
          <source>In some cases, only interaction terms among features are required, and it can be gotten with the setting &lt;code&gt;interaction_only=True&lt;/code&gt;:</source>
          <target state="translated">В некоторых случаях требуются только условия взаимодействия между функциями, и это может быть получено с помощью параметра &lt;code&gt;interaction_only=True&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="fc4d9d9d36cc2fd0e96fb6fded728410f07d4165" translate="yes" xml:space="preserve">
          <source>In some specific cases (when the code that is run in parallel releases the GIL), scikit-learn will indicate to &lt;code&gt;joblib&lt;/code&gt; that a multi-threading backend is preferable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b40a5cc0ca592bd5c1306138f251a81fe534579" translate="yes" xml:space="preserve">
          <source>In spite of their apparently over-simplified assumptions, naive Bayes classifiers have worked quite well in many real-world situations, famously document classification and spam filtering. They require a small amount of training data to estimate the necessary parameters. (For theoretical reasons why naive Bayes works well, and on which types of data it does, see the references below.)</source>
          <target state="translated">Несмотря на свои,казалось бы,чрезмерно упрощенные допущения,наивные классификаторы Бейеса неплохо сработали во многих реальных ситуациях,известных как классификация документов и фильтрация спама.Они требуют небольшого количества обучающих данных для оценки необходимых параметров.(По теоретическим причинам,почему наивный Бэйес работает хорошо,и на какие типы данных он работает,см.ссылки ниже).</target>
        </trans-unit>
        <trans-unit id="389828ed3005eb646a2fbe827835555cbdc74437" translate="yes" xml:space="preserve">
          <source>In terms of accuracy, LOO often results in high variance as an estimator for the test error. Intuitively, since \(n - 1\) of the \(n\) samples are used to build each model, models constructed from folds are virtually identical to each other and to the model built from the entire training set.</source>
          <target state="translated">С точки зрения точности LOO часто приводит к высокой дисперсии в качестве оценочного показателя ошибки теста.Интуитивно,так как для построения каждой модели используются образцы \(n-1\),то модели,построенные из складок,практически идентичны друг другу и модели,построенные из всего обучающего набора.</target>
        </trans-unit>
        <trans-unit id="36132aafc76511f4279f2a1765dcbaeb9d7a44b1" translate="yes" xml:space="preserve">
          <source>In terms of time and space complexity, Theil-Sen scales according to</source>
          <target state="translated">С точки зрения пространственно-временной сложности,шкала Тейл-Зена в соответствии с</target>
        </trans-unit>
        <trans-unit id="8cac8320893acecd46013a1cd740f5237cabb213" translate="yes" xml:space="preserve">
          <source>In that case, the model with 2 components and full covariance (which corresponds to the true generative model) is selected.</source>
          <target state="translated">В этом случае выбирается модель с 2 компонентами и полной ковариацией (что соответствует истинной генеративной модели).</target>
        </trans-unit>
        <trans-unit id="56b0989d4ac400367ce631898b8b32a7aa114deb" translate="yes" xml:space="preserve">
          <source>In that way, we emphasize that the greater the variance of a feature, the larger the weight of the corresponding coefficient on the output, all else being equal.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df23be83a828beae97b01644c9cebfd6ec568f81" translate="yes" xml:space="preserve">
          <source>In the &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt;&lt;code&gt;TfidfTransformer&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt;&lt;code&gt;TfidfVectorizer&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;smooth_idf=False&lt;/code&gt;, the &amp;ldquo;1&amp;rdquo; count is added to the idf instead of the idf&amp;rsquo;s denominator:</source>
          <target state="translated">В &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt; &lt;code&gt;TfidfTransformer&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt; &lt;code&gt;TfidfVectorizer&lt;/code&gt; &lt;/a&gt; с &lt;code&gt;smooth_idf=False&lt;/code&gt; счетчик &amp;laquo;1&amp;raquo; добавляется к idf вместо знаменателя idf:</target>
        </trans-unit>
        <trans-unit id="5bd53e1aa867b99daf4cb138797f33e24d9cfda1" translate="yes" xml:space="preserve">
          <source>In the &lt;a href=&quot;generated/sklearn.neural_network.bernoullirbm#sklearn.neural_network.BernoulliRBM&quot;&gt;&lt;code&gt;BernoulliRBM&lt;/code&gt;&lt;/a&gt;, all units are binary stochastic units. This means that the input data should either be binary, or real-valued between 0 and 1 signifying the probability that the visible unit would turn on or off. This is a good model for character recognition, where the interest is on which pixels are active and which aren&amp;rsquo;t. For images of natural scenes it no longer fits because of background, depth and the tendency of neighbouring pixels to take the same values.</source>
          <target state="translated">В &lt;a href=&quot;generated/sklearn.neural_network.bernoullirbm#sklearn.neural_network.BernoulliRBM&quot;&gt; &lt;code&gt;BernoulliRBM&lt;/code&gt; &lt;/a&gt; все единицы являются стохастическими двоичными единицами. Это означает, что входные данные должны быть либо двоичными, либо с действительными значениями от 0 до 1, что означает вероятность того, что видимый блок включится или выключится. Это хорошая модель для распознавания символов, когда интересует, какие пиксели активны, а какие нет. Для изображений естественных сцен он больше не подходит из-за фона, глубины и тенденции соседних пикселей принимать одинаковые значения.</target>
        </trans-unit>
        <trans-unit id="729860dcb0b5963ed7d873f5d8718ecbded39d56" translate="yes" xml:space="preserve">
          <source>In the &lt;code&gt;l1&lt;/code&gt; case, theory says that prediction consistency (i.e. that under given hypothesis, the estimator learned predicts as well as a model knowing the true distribution) is not possible because of the bias of the &lt;code&gt;l1&lt;/code&gt;. It does say, however, that model consistency, in terms of finding the right set of non-zero parameters as well as their signs, can be achieved by scaling &lt;code&gt;C1&lt;/code&gt;.</source>
          <target state="translated">В случае &lt;code&gt;l1&lt;/code&gt; теория утверждает, что непротиворечивость предсказания (то есть, что при данной гипотезе оценщик, обученный, предсказывает, а также модель, знающая истинное распределение) невозможна из-за смещения &lt;code&gt;l1&lt;/code&gt; . Однако в нем говорится, что согласованность модели с точки зрения нахождения правильного набора ненулевых параметров, а также их знаков может быть достигнута путем масштабирования &lt;code&gt;C1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3ac113ba1d5ea8579f40e00fa885b5d980c4ba43" translate="yes" xml:space="preserve">
          <source>In the &lt;code&gt;l1&lt;/code&gt; penalty case, the cross-validation-error correlates best with the test-error, when scaling our &lt;code&gt;C&lt;/code&gt; with the number of samples, &lt;code&gt;n&lt;/code&gt;, which can be seen in the first figure.</source>
          <target state="translated">В случае штрафа &lt;code&gt;l1&lt;/code&gt; ошибка перекрестной проверки лучше всего коррелирует с ошибкой теста при масштабировании нашего &lt;code&gt;C&lt;/code&gt; с количеством выборок &lt;code&gt;n&lt;/code&gt; , что можно увидеть на первом рисунке.</target>
        </trans-unit>
        <trans-unit id="4495b7082e60ec7cb3a7d3cf1946536697a0e6b3" translate="yes" xml:space="preserve">
          <source>In the above case, the classifier is fit on a 1d array of multiclass labels and the &lt;code&gt;predict()&lt;/code&gt; method therefore provides corresponding multiclass predictions. It is also possible to fit upon a 2d array of binary label indicators:</source>
          <target state="translated">В приведенном выше случае классификатор помещается в 1d-массив мультиклассовых меток, и поэтому метод &lt;code&gt;predict()&lt;/code&gt; обеспечивает соответствующие многоклассовые предсказания. Также возможно разместить на 2-м массиве бинарных индикаторов меток:</target>
        </trans-unit>
        <trans-unit id="41d2181ce120b72b14a943b5e6f5608fe64d404d" translate="yes" xml:space="preserve">
          <source>In the above example, &lt;code&gt;char_wb&lt;/code&gt; analyzer is used, which creates n-grams only from characters inside word boundaries (padded with space on each side). The &lt;code&gt;char&lt;/code&gt; analyzer, alternatively, creates n-grams that span across words:</source>
          <target state="translated">В приведенном выше примере &lt;code&gt;char_wb&lt;/code&gt; анализатор char_wb , который создает н-граммы только из символов внутри границ слова (с пробелами с каждой стороны). В качестве альтернативы анализатор &lt;code&gt;char&lt;/code&gt; создает n-граммы, охватывающие слова:</target>
        </trans-unit>
        <trans-unit id="02dd6b844a6f6c7bb7b63318a0172b18e25d4984" translate="yes" xml:space="preserve">
          <source>In the above example, the &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt; expects a 1D array as input and therefore the columns were specified as a string (&lt;code&gt;'city'&lt;/code&gt;). However, other transformers generally expect 2D data, and in that case you need to specify the column as a list of strings (&lt;code&gt;['city']&lt;/code&gt;).</source>
          <target state="translated">В приведенном выше примере &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; ожидает в качестве входных данных одномерный массив, поэтому столбцы были указаны как строка ( &lt;code&gt;'city'&lt;/code&gt; ). Однако другие преобразователи обычно ожидают 2D-данных, и в этом случае вам нужно указать столбец как список строк ( &lt;code&gt;['city']&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="af32f30ac84780c46ec03071f0807a02a06be37e" translate="yes" xml:space="preserve">
          <source>In the above example, the &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt; expects a 1D array as input and therefore the columns were specified as a string (&lt;code&gt;'title'&lt;/code&gt;). However, &lt;a href=&quot;generated/sklearn.preprocessing.onehotencoder#sklearn.preprocessing.OneHotEncoder&quot;&gt;&lt;code&gt;preprocessing.OneHotEncoder&lt;/code&gt;&lt;/a&gt; as most of other transformers expects 2D data, therefore in that case you need to specify the column as a list of strings (&lt;code&gt;['city']&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8be3ffb93abc4e32a08a3f61b709f6ed3e6124c4" translate="yes" xml:space="preserve">
          <source>In the above example-code, we firstly use the &lt;code&gt;fit(..)&lt;/code&gt; method to fit our estimator to the data and secondly the &lt;code&gt;transform(..)&lt;/code&gt; method to transform our count-matrix to a tf-idf representation. These two steps can be combined to achieve the same end result faster by skipping redundant processing. This is done through using the &lt;code&gt;fit_transform(..)&lt;/code&gt; method as shown below, and as mentioned in the note in the previous section:</source>
          <target state="translated">В приведенном выше примере кода мы, во-первых, используем метод &lt;code&gt;fit(..)&lt;/code&gt; чтобы подогнать нашу оценку к данным, и, во-вторых, метод &lt;code&gt;transform(..)&lt;/code&gt; для преобразования нашей матрицы-счетчика в представление tf-idf. Эти два шага можно объединить, чтобы быстрее достичь того же конечного результата, пропустив избыточную обработку. Это делается с помощью метода &lt;code&gt;fit_transform(..)&lt;/code&gt; как показано ниже и как указано в примечании в предыдущем разделе:</target>
        </trans-unit>
        <trans-unit id="370df873906104ebc3c5f7c3ad3752f50f2bb258" translate="yes" xml:space="preserve">
          <source>In the above illustrating figure, we consider some points from a randomly generated dataset. We focus on the stochastic KNN classification of point no. 3. The thickness of a link between sample 3 and another point is proportional to their distance, and can be seen as the relative weight (or probability) that a stochastic nearest neighbor prediction rule would assign to this point. In the original space, sample 3 has many stochastic neighbors from various classes, so the right class is not very likely. However, in the projected space learned by NCA, the only stochastic neighbors with non-negligible weight are from the same class as sample 3, guaranteeing that the latter will be well classified. See the &lt;a href=&quot;#nca-mathematical-formulation&quot;&gt;mathematical formulation&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc1fc9feffcc3ab7062a5968abf403f994be456d" translate="yes" xml:space="preserve">
          <source>In the above process, rejection sampling is used to make sure that n is more than 2, and that the document length is never zero. Likewise, we reject classes which have already been chosen. The documents that are assigned to both classes are plotted surrounded by two colored circles.</source>
          <target state="translated">В описанном выше процессе выборка отказов используется для того,чтобы убедиться,что n больше 2,а длина документа никогда не будет равна нулю.Точно так же мы отвергаем уже выбранные классы.Документы,которые назначены обоим классам,построены в окружении двух цветных кругов.</target>
        </trans-unit>
        <trans-unit id="35ac86e1f976c024d854c94dc1a07d9250df373b" translate="yes" xml:space="preserve">
          <source>In the above process, rejection sampling is used to make sure that n is never zero or more than &lt;code&gt;n_classes&lt;/code&gt;, and that the document length is never zero. Likewise, we reject classes which have already been chosen.</source>
          <target state="translated">В приведенном выше процессе выборка отклонения используется, чтобы убедиться, что n никогда не равно нулю или больше &lt;code&gt;n_classes&lt;/code&gt; , и что длина документа никогда не равна нулю. Точно так же мы отклоняем уже выбранные классы.</target>
        </trans-unit>
        <trans-unit id="35b3eed71c5956697e4e941c9abda7fa7875d908" translate="yes" xml:space="preserve">
          <source>In the binary (two-class) case, \(tp\), \(tn\), \(fp\) and \(fn\) are respectively the number of true positives, true negatives, false positives and false negatives, the MCC is defined as</source>
          <target state="translated">В двоичном (двухклассовом)случае,\(tp\),\(tn\),\(fp\)и \(fn\),соответственно,число истинных положительных результатов,истинных отрицательных результатов,ложных положительных результатов и ложных отрицательных результатов,MCC определяется,как</target>
        </trans-unit>
        <trans-unit id="8cf754386b9e93bff61012cc7eebd891fe098125" translate="yes" xml:space="preserve">
          <source>In the binary case, balanced accuracy is equal to the arithmetic mean of &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;sensitivity&lt;/a&gt; (true positive rate) and &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;specificity&lt;/a&gt; (true negative rate), or the area under the ROC curve with binary predictions rather than scores.</source>
          <target state="translated">В двоичном случае сбалансированная точность равна среднему арифметическому &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;чувствительности&lt;/a&gt; (истинно положительный показатель) и &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;специфичности&lt;/a&gt; (истинно отрицательный показатель) или площади под кривой ROC с двоичными прогнозами, а не баллами.</target>
        </trans-unit>
        <trans-unit id="43cd3b6bd763c03854427d73b603fdca48b2b30e" translate="yes" xml:space="preserve">
          <source>In the binary case, balanced accuracy is equal to the arithmetic mean of &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;sensitivity&lt;/a&gt; (true positive rate) and &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;specificity&lt;/a&gt; (true negative rate), or the area under the ROC curve with binary predictions rather than scores:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a998ef5238ae7921fe9486295ae64f00deab3566" translate="yes" xml:space="preserve">
          <source>In the binary case, we can extract true positives, etc as follows:</source>
          <target state="translated">В бинарном случае мы можем извлечь истинные положительные результаты и т.д.следующим образом:</target>
        </trans-unit>
        <trans-unit id="3e94daaa4e8fed019552e1789dc3caf5c267c82f" translate="yes" xml:space="preserve">
          <source>In the binary case:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="193e8f9e646cb769a122ba34f156f35dc1f6d79e" translate="yes" xml:space="preserve">
          <source>In the case of &amp;ldquo;one-vs-one&amp;rdquo; &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt;&lt;code&gt;NuSVC&lt;/code&gt;&lt;/a&gt;, the layout of the attributes is a little more involved. In the case of a linear kernel, the attributes &lt;code&gt;coef_&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; have the shape &lt;code&gt;(n_classes * (n_classes - 1) / 2, n_features)&lt;/code&gt; and &lt;code&gt;(n_classes *
(n_classes - 1) / 2)&lt;/code&gt; respectively. This is similar to the layout for &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; described above, with each row now corresponding to a binary classifier. The order for classes 0 to n is &amp;ldquo;0 vs 1&amp;rdquo;, &amp;ldquo;0 vs 2&amp;rdquo; , &amp;hellip; &amp;ldquo;0 vs n&amp;rdquo;, &amp;ldquo;1 vs 2&amp;rdquo;, &amp;ldquo;1 vs 3&amp;rdquo;, &amp;ldquo;1 vs n&amp;rdquo;, . . . &amp;ldquo;n-1 vs n&amp;rdquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2482e7f51309cef70ec85538824011f95f0813b1" translate="yes" xml:space="preserve">
          <source>In the case of &amp;ldquo;one-vs-one&amp;rdquo; &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt;, the layout of the attributes is a little more involved. In the case of having a linear kernel, the attributes &lt;code&gt;coef_&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; have the shape &lt;code&gt;[n_class * (n_class - 1) / 2, n_features]&lt;/code&gt; and &lt;code&gt;[n_class * (n_class - 1) / 2]&lt;/code&gt; respectively. This is similar to the layout for &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; described above, with each row now corresponding to a binary classifier. The order for classes 0 to n is &amp;ldquo;0 vs 1&amp;rdquo;, &amp;ldquo;0 vs 2&amp;rdquo; , &amp;hellip; &amp;ldquo;0 vs n&amp;rdquo;, &amp;ldquo;1 vs 2&amp;rdquo;, &amp;ldquo;1 vs 3&amp;rdquo;, &amp;ldquo;1 vs n&amp;rdquo;, . . . &amp;ldquo;n-1 vs n&amp;rdquo;.</source>
          <target state="translated">В случае &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt; &amp;laquo;один на один&amp;raquo; компоновка атрибутов немного сложнее. В случае линейного ядра атрибуты &lt;code&gt;coef_&lt;/code&gt; и &lt;code&gt;intercept_&lt;/code&gt; имеют форму &lt;code&gt;[n_class * (n_class - 1) / 2, n_features]&lt;/code&gt; и &lt;code&gt;[n_class * (n_class - 1) / 2]&lt;/code&gt; соответственно. Это похоже на схему для &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; ,&lt;/a&gt; описанную выше, где каждая строка теперь соответствует двоичному классификатору. Порядок для классов от 0 до n следующий: &amp;laquo;0 против 1&amp;raquo;, &amp;laquo;0 против 2&amp;raquo;,&amp;hellip; &amp;laquo;0 против n&amp;raquo;, &amp;laquo;1 против 2&amp;raquo;, &amp;laquo;1 против 3&amp;raquo;, &amp;laquo;1 против n&amp;raquo;,. . . &amp;laquo;П-1 против п&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="7befa9fe69dc29e17ce8c14ce1f24dcd596f25dc" translate="yes" xml:space="preserve">
          <source>In the case of Gaussian process classification, &amp;ldquo;one_vs_one&amp;rdquo; might be computationally cheaper since it has to solve many problems involving only a subset of the whole training set rather than fewer problems on the whole dataset. Since Gaussian process classification scales cubically with the size of the dataset, this might be considerably faster. However, note that &amp;ldquo;one_vs_one&amp;rdquo; does not support predicting probability estimates but only plain predictions. Moreover, note that &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessclassifier#sklearn.gaussian_process.GaussianProcessClassifier&quot;&gt;&lt;code&gt;GaussianProcessClassifier&lt;/code&gt;&lt;/a&gt; does not (yet) implement a true multi-class Laplace approximation internally, but as discussed above is based on solving several binary classification tasks internally, which are combined using one-versus-rest or one-versus-one.</source>
          <target state="translated">В случае классификации гауссовского процесса &amp;laquo;one_vs_one&amp;raquo; может быть дешевле с вычислительной точки зрения, поскольку он должен решать многие проблемы, включающие только подмножество всего обучающего набора, а не меньшее количество проблем во всем наборе данных. Поскольку классификация процессов по Гауссу кубически масштабируется в зависимости от размера набора данных, это может быть значительно быстрее. Однако обратите внимание, что &amp;laquo;one_vs_one&amp;raquo; не поддерживает прогнозирование оценок вероятности, а только простые прогнозы. Кроме того, обратите внимание, что &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessclassifier#sklearn.gaussian_process.GaussianProcessClassifier&quot;&gt; &lt;code&gt;GaussianProcessClassifier&lt;/code&gt; &lt;/a&gt; (пока) не реализует истинное мультиклассовое приближение Лапласа внутри, но, как обсуждалось выше, основано на решении нескольких внутренних задач двоичной классификации, которые комбинируются с использованием одного против остальных или одного против одного.</target>
        </trans-unit>
        <trans-unit id="35a5ada3d16c18d2778299b423e5960182d45740" translate="yes" xml:space="preserve">
          <source>In the case of LDA, the Gaussians for each class are assumed to share the same covariance matrix: \(\Sigma_k = \Sigma\) for all \(k\). This leads to linear decision surfaces, which can be seen by comparing the log-probability ratios \(\log[P(y=k | X) / P(y=l | X)]\):</source>
          <target state="translated">В случае LDA предполагается,что гаусси для каждого класса имеют одну и ту же ковариационную матрицу:\(\Sigma_k=\Sigma\)для всех \(k\).Это приводит к линейным поверхностям принятия решений,что можно увидеть,сравнивая лог-вероятностные соотношения \(\log[P(y=k | X)/P(y=l | X)]\):</target>
        </trans-unit>
        <trans-unit id="9191afe7181654f4c123a5274615786e30f48b2b" translate="yes" xml:space="preserve">
          <source>In the case of QDA, there are no assumptions on the covariance matrices \(\Sigma_k\) of the Gaussians, leading to quadratic decision surfaces. See &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[3]&lt;/a&gt; for more details.</source>
          <target state="translated">В случае QDA нет никаких предположений относительно ковариационных матриц \ (\ Sigma_k \) гауссианов, приводящих к квадратичным решающим поверхностям. См. &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[3]&lt;/a&gt; для более подробной информации.</target>
        </trans-unit>
        <trans-unit id="be50ffb98df62eb79c354d934aa76c5587bf8cba" translate="yes" xml:space="preserve">
          <source>In the case of multi-class classification &lt;code&gt;coef_&lt;/code&gt; is a two-dimensional array of &lt;code&gt;shape=[n_classes, n_features]&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; is a one-dimensional array of &lt;code&gt;shape=[n_classes]&lt;/code&gt;. The i-th row of &lt;code&gt;coef_&lt;/code&gt; holds the weight vector of the OVA classifier for the i-th class; classes are indexed in ascending order (see attribute &lt;code&gt;classes_&lt;/code&gt;). Note that, in principle, since they allow to create a probability model, &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; and &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; are more suitable for one-vs-all classification.</source>
          <target state="translated">В случае мультиклассовой классификации &lt;code&gt;coef_&lt;/code&gt; - это двумерный массив &lt;code&gt;shape=[n_classes, n_features]&lt;/code&gt; а &lt;code&gt;intercept_&lt;/code&gt; - одномерный массив &lt;code&gt;shape=[n_classes]&lt;/code&gt; . I-я строка &lt;code&gt;coef_&lt;/code&gt; содержит весовой вектор классификатора OVA для i-го класса; классы индексируются в порядке возрастания (см. атрибут &lt;code&gt;classes_&lt;/code&gt; ). Обратите внимание, что в принципе, поскольку они позволяют создать модель вероятности, &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; и &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; больше подходят для классификации &quot;один против всех&quot;.</target>
        </trans-unit>
        <trans-unit id="a5109fe6449c3757593d6d14759e9857d15d95c4" translate="yes" xml:space="preserve">
          <source>In the case of multi-class classification &lt;code&gt;coef_&lt;/code&gt; is a two-dimensional array of shape (n_classes, n_features) and &lt;code&gt;intercept_&lt;/code&gt; is a one-dimensional array of shape (n_classes,). The i-th row of &lt;code&gt;coef_&lt;/code&gt; holds the weight vector of the OVA classifier for the i-th class; classes are indexed in ascending order (see attribute &lt;code&gt;classes_&lt;/code&gt;). Note that, in principle, since they allow to create a probability model, &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; and &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; are more suitable for one-vs-all classification.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1959581346965192dc91c946ef9926bceb1c51a" translate="yes" xml:space="preserve">
          <source>In the case of multi-class classification, the mean log-marginal likelihood of the one-versus-rest classifiers are returned.</source>
          <target state="translated">В случае классификации по нескольким классам возвращается средняя лог-маржинальная вероятность классификации по принципу &quot;один против одного&quot;.</target>
        </trans-unit>
        <trans-unit id="a45d03e82085c1e194b2b19d0700767439a7ac42" translate="yes" xml:space="preserve">
          <source>In the case of one-hot/one-of-K coding, the constructed feature names and values are returned rather than the original ones.</source>
          <target state="translated">В случае одноразового/одноразового кодирования возвращаются не оригинальные,а построенные имена и значения признаков.</target>
        </trans-unit>
        <trans-unit id="108b9e0576d5a78538771fb415a46ae76d1a6e26" translate="yes" xml:space="preserve">
          <source>In the case of text classification, word occurrence vectors (rather than word count vectors) may be used to train and use this classifier. &lt;code&gt;BernoulliNB&lt;/code&gt; might perform better on some datasets, especially those with shorter documents. It is advisable to evaluate both models, if time permits.</source>
          <target state="translated">В случае классификации текста для обучения и использования этого классификатора могут использоваться векторы появления слов (а не векторы подсчета слов). &lt;code&gt;BernoulliNB&lt;/code&gt; может лучше работать с некоторыми наборами данных, особенно с более короткими документами. Желательно оценить обе модели, если позволяет время.</target>
        </trans-unit>
        <trans-unit id="1ee37ddaa2e2b7fb0103fdddd162d9ad76a8f2dd" translate="yes" xml:space="preserve">
          <source>In the case of the digits dataset, the task is to predict, given an image, which digit it represents. We are given samples of each of the 10 possible classes (the digits zero through nine) on which we &lt;em&gt;fit&lt;/em&gt; an &lt;a href=&quot;https://en.wikipedia.org/wiki/Estimator&quot;&gt;estimator&lt;/a&gt; to be able to &lt;em&gt;predict&lt;/em&gt; the classes to which unseen samples belong.</source>
          <target state="translated">В случае набора данных цифр задача состоит в том, чтобы по изображению предсказать, какую цифру оно представляет. Мы приведены образцы каждого из 10 возможных классов (цифры от нуля до девяти) , на котором мы &lt;em&gt;подходят&lt;/em&gt; к &lt;a href=&quot;https://en.wikipedia.org/wiki/Estimator&quot;&gt;оценщик&lt;/a&gt; , чтобы быть в состоянии &lt;em&gt;предсказать&lt;/em&gt; классы , к которым невидимые образцы принадлежат.</target>
        </trans-unit>
        <trans-unit id="0484e6facaecfeba6a4ff8e0552fa9a5ac1c52dd" translate="yes" xml:space="preserve">
          <source>In the case that one or more classes are absent in a training portion, a default score needs to be assigned to all instances for that class if &lt;code&gt;method&lt;/code&gt; produces columns per class, as in {&amp;lsquo;decision_function&amp;rsquo;, &amp;lsquo;predict_proba&amp;rsquo;, &amp;lsquo;predict_log_proba&amp;rsquo;}. For &lt;code&gt;predict_proba&lt;/code&gt; this value is 0. In order to ensure finite output, we approximate negative infinity by the minimum finite float value for the dtype in other cases.</source>
          <target state="translated">В случае, если один или несколько классов отсутствуют в обучающей части, оценка по умолчанию должна быть назначена всем экземплярам для этого класса, если &lt;code&gt;method&lt;/code&gt; создает столбцы для каждого класса, как в {'solution_function', 'pred_proba', 'pred_log_proba'} . Для &lt;code&gt;predict_proba&lt;/code&gt; это значение равно 0. Чтобы гарантировать конечный результат, мы аппроксимируем отрицательную бесконечность минимальным конечным значением с плавающей запятой для dtype в других случаях.</target>
        </trans-unit>
        <trans-unit id="74ff5bfdda6b3e93f59169f7c22fc2d68fa3fcf3" translate="yes" xml:space="preserve">
          <source>In the case when the binary labels are fractional (probabilistic), inverse_transform chooses the class with the greatest value. Typically, this allows to use the output of a linear model&amp;rsquo;s decision_function method directly as the input of inverse_transform.</source>
          <target state="translated">В случае, когда двоичные метки дробные (вероятностные), inverse_transform выбирает класс с наибольшим значением. Как правило, это позволяет использовать выходные данные метода линейной модели solution_function непосредственно в качестве входных данных inverse_transform.</target>
        </trans-unit>
        <trans-unit id="e087c17fe61957d86c5cc0e9905f0323cd8dea87" translate="yes" xml:space="preserve">
          <source>In the cases of a tie, the &lt;a href=&quot;generated/sklearn.ensemble.votingclassifier#sklearn.ensemble.VotingClassifier&quot;&gt;&lt;code&gt;VotingClassifier&lt;/code&gt;&lt;/a&gt; will select the class based on the ascending sort order. E.g., in the following scenario</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d852af4ac330c07eec96a31a9559a88b3b70655" translate="yes" xml:space="preserve">
          <source>In the cases of a tie, the &lt;code&gt;VotingClassifier&lt;/code&gt; will select the class based on the ascending sort order. E.g., in the following scenario</source>
          <target state="translated">В случае ничьей &lt;code&gt;VotingClassifier&lt;/code&gt; выберет класс в порядке возрастания. Например, в следующем сценарии</target>
        </trans-unit>
        <trans-unit id="84352a0fa93e8d3c09e63ba562819b09bff22e0e" translate="yes" xml:space="preserve">
          <source>In the checkerboard case, each row belongs to all column clusters, and each column belongs to all row clusters. Here is an example of this structure where the variance of the values within each bicluster is small:</source>
          <target state="translated">В случае шахматной доски каждая строка принадлежит всем кластерам столбцов,и каждый столбец принадлежит всем кластерам строк.Приведем пример такой структуры,где дисперсия значений внутри каждого билюстра невелика:</target>
        </trans-unit>
        <trans-unit id="6a06bacf0f95acd504bad8493dc228833ae72576" translate="yes" xml:space="preserve">
          <source>In the event that the 95% confidence interval based on Fisher transform spans zero, a warning is raised.</source>
          <target state="translated">В случае,если доверительный интервал 95%,основанный на преобразовании Фишера,охватывает ноль,повышается предупреждение.</target>
        </trans-unit>
        <trans-unit id="2da0fe066fd806cee05903c8f41b8c38bb726d66" translate="yes" xml:space="preserve">
          <source>In the example below, using a small shrink threshold increases the accuracy of the model from 0.81 to 0.82.</source>
          <target state="translated">В приведенном ниже примере использование небольшого усадочного порога увеличивает точность модели с 0,81 до 0,82.</target>
        </trans-unit>
        <trans-unit id="ae3527cc8009043f3459062f8b3ac5f4c7cdc080" translate="yes" xml:space="preserve">
          <source>In the figure below, the color indicates cluster membership, with large circles indicating core samples found by the algorithm. Smaller circles are non-core samples that are still part of a cluster. Moreover, the outliers are indicated by black points below.</source>
          <target state="translated">На рисунке ниже цвет обозначает принадлежность к кластерам,а большие кружки указывают на найденные алгоритмом образцы ядра.Маленькие круги-это неосновные образцы,которые все еще являются частью кластера.Более того,отклонения обозначаются черными точками внизу.</target>
        </trans-unit>
        <trans-unit id="cfa64cd986932f750b1c68de33ab3971d444bf3d" translate="yes" xml:space="preserve">
          <source>In the first column, first row the learning curve of a naive Bayes classifier is shown for the digits dataset. Note that the training score and the cross-validation score are both not very good at the end. However, the shape of the curve can be found in more complex datasets very often: the training score is very high at the beginning and decreases and the cross-validation score is very low at the beginning and increases. In the second column, first row we see the learning curve of an SVM with RBF kernel. We can see clearly that the training score is still around the maximum and the validation score could be increased with more training samples. The plots in the second row show the times required by the models to train with various sizes of training dataset. The plots in the third row show how much time was required to train the models for each training sizes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbb41405aaf08b233f5d5a9cb37143ee4833765d" translate="yes" xml:space="preserve">
          <source>In the first figure, we visualize the value of the kernel, i.e. the similarity of the sequences, using a colormap. Brighter color here indicates higher similarity.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a915ebedbc9fc712ae336eb7409727fc370425dc" translate="yes" xml:space="preserve">
          <source>In the first row, the classifiers are built using the sepal width and the sepal length features only, on the second row using the petal length and sepal length only, and on the third row using the petal width and the petal length only.</source>
          <target state="translated">В первом ряду классификаторы построены с использованием только ширины чашелистики и длины чашелистики,во втором ряду только с использованием длины лепестка и длины чашелистики,а в третьем ряду только с использованием ширины лепестка и длины лепестка.</target>
        </trans-unit>
        <trans-unit id="974efdfc7b27c9e04d6e731c42ba40fb3d593ff5" translate="yes" xml:space="preserve">
          <source>In the following example, we construct a NearestNeighbors class from an array representing our data set and ask who&amp;rsquo;s the closest point to [1,1,1]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd9366b471cf174a5dc26260b1ee3e4775bd8a95" translate="yes" xml:space="preserve">
          <source>In the following example, we construct a NeighborsClassifier class from an array representing our data set and ask who&amp;rsquo;s the closest point to [1, 1, 1]:</source>
          <target state="translated">В следующем примере мы создаем класс NeighborsClassifier из массива, представляющего наш набор данных, и спрашиваем, кто ближайшая точка к [1, 1, 1]:</target>
        </trans-unit>
        <trans-unit id="f873541d5e32ccd97b454877a7265b9e862eeb9a" translate="yes" xml:space="preserve">
          <source>In the following example, we construct a NeighborsClassifier class from an array representing our data set and ask who&amp;rsquo;s the closest point to [1,1,1]</source>
          <target state="translated">В следующем примере мы создаем класс NeighborsClassifier из массива, представляющего наш набор данных, и спрашиваем, кто ближайшая точка к [1,1,1]</target>
        </trans-unit>
        <trans-unit id="65f9f2f58e8b0fd298381aa88835a40b1607c17f" translate="yes" xml:space="preserve">
          <source>In the following figure, 100 points are drawn from a bimodal distribution, and the kernel density estimates are shown for three choices of kernels:</source>
          <target state="translated">На следующем рисунке из бимодального распределения взято 100 точек,а для трех вариантов ядра показаны оценки плотности:</target>
        </trans-unit>
        <trans-unit id="a08df9eebc31ca3edc4756b37a4fdadef1454fe3" translate="yes" xml:space="preserve">
          <source>In the following plot, the maximum effective alpha value is removed, because it is the trivial tree with only one node.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24263a7351535bc4435386a661d4637b721eb5a0" translate="yes" xml:space="preserve">
          <source>In the following plot, we see a function \(f(x) = \cos (\frac{3}{2} \pi x)\) and some noisy samples from that function. We use three different estimators to fit the function: linear regression with polynomial features of degree 1, 4 and 15. We see that the first estimator can at best provide only a poor fit to the samples and the true function because it is too simple (high bias), the second estimator approximates it almost perfectly and the last estimator approximates the training data perfectly but does not fit the true function very well, i.e. it is very sensitive to varying training data (high variance).</source>
          <target state="translated">На следующем рисунке мы видим функцию \(f(x)=\cos (\frac{3}{2}\pi x)\)и некоторые шумные примеры из этой функции.Для подгонки функции мы используем три различных оценочных параметра:линейную регрессию с полиномиальными признаками степени 1,4 и 15.Мы видим,что первый оценщик в лучшем случае может обеспечить только плохое соответствие выборки и истинной функции,так как она слишком проста (большое смещение),второй оценщик аппроксимирует ее почти идеально,а последний оценщик аппроксимирует тренировочные данные идеально,но не очень хорошо подходит к истинной функции,т.е.очень чувствительна к различным тренировочным данным (высокая дисперсия).</target>
        </trans-unit>
        <trans-unit id="605a0ccca31d97f6c29fd62c728a36908756654e" translate="yes" xml:space="preserve">
          <source>In the following section, we will interpret the coefficients of the model. While we do so, we should keep in mind that any conclusion we draw is about the model that we build, rather than about the true (real-world) generative process of the data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de54ef0bf525631d31eb0623dcd55f8a9ddc120b" translate="yes" xml:space="preserve">
          <source>In the following sub-sections, we will describe each of those functions, preceded by some notes on common API and metric definition.</source>
          <target state="translated">В следующих подразделах мы опишем каждую из этих функций,чему предшествуют некоторые заметки об общем API и метрическом определении.</target>
        </trans-unit>
        <trans-unit id="7549668dfe247eb9e0e172cc89f620a63604992b" translate="yes" xml:space="preserve">
          <source>In the following we will use the built-in dataset loader for 20 newsgroups from scikit-learn. Alternatively, it is possible to download the dataset manually from the website and use the &lt;a href=&quot;../../modules/generated/sklearn.datasets.load_files#sklearn.datasets.load_files&quot;&gt;&lt;code&gt;sklearn.datasets.load_files&lt;/code&gt;&lt;/a&gt; function by pointing it to the &lt;code&gt;20news-bydate-train&lt;/code&gt; sub-folder of the uncompressed archive folder.</source>
          <target state="translated">Далее мы будем использовать встроенный загрузчик набора данных для 20 групп новостей из scikit-learn. В качестве альтернативы можно загрузить набор данных вручную с веб-сайта и использовать функцию &lt;a href=&quot;../../modules/generated/sklearn.datasets.load_files#sklearn.datasets.load_files&quot;&gt; &lt;code&gt;sklearn.datasets.load_files&lt;/code&gt; &lt;/a&gt; , указав ее в &lt;code&gt;20news-bydate-train&lt;/code&gt; папки несжатого архива.</target>
        </trans-unit>
        <trans-unit id="2cb0b9817ecf09ea4893bb9df9d328ce75ef2d1b" translate="yes" xml:space="preserve">
          <source>In the following, &amp;ldquo;city&amp;rdquo; is a categorical attribute while &amp;ldquo;temperature&amp;rdquo; is a traditional numerical feature:</source>
          <target state="translated">В дальнейшем &amp;laquo;город&amp;raquo; - это категориальный атрибут, а &amp;laquo;температура&amp;raquo; - это традиционный числовой показатель:</target>
        </trans-unit>
        <trans-unit id="3e019b4cbe3ce7f1554fa08ce08898c560cb8a3b" translate="yes" xml:space="preserve">
          <source>In the following, we start a Python interpreter from our shell and then load the &lt;code&gt;iris&lt;/code&gt; and &lt;code&gt;digits&lt;/code&gt; datasets. Our notational convention is that &lt;code&gt;$&lt;/code&gt; denotes the shell prompt while &lt;code&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; denotes the Python interpreter prompt:</source>
          <target state="translated">Далее мы запускаем интерпретатор Python из нашей оболочки, а затем загружаем наборы данных &lt;code&gt;iris&lt;/code&gt; и &lt;code&gt;digits&lt;/code&gt; . Наше условное обозначение таково, что &lt;code&gt;$&lt;/code&gt; обозначает приглашение оболочки, а &lt;code&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; обозначает приглашение интерпретатора Python:</target>
        </trans-unit>
        <trans-unit id="fe30ab8cfcc104ee94b5fb01793274570a377034" translate="yes" xml:space="preserve">
          <source>In the formula above, \(\mathbf{b}\) and \(\mathbf{c}\) are the intercept vectors for the visible and hidden layers, respectively. The joint probability of the model is defined in terms of the energy:</source>
          <target state="translated">В приведенной выше формуле \(\mathbf{b}\)и \(\mathbf{c}\)являются векторами перехвата для видимого и скрытого слоев соответственно.Совместная вероятность модели определяется с точки зрения энергии:</target>
        </trans-unit>
        <trans-unit id="e448c91ec6db1584eec64770c66e9fad7266b47b" translate="yes" xml:space="preserve">
          <source>In the graphical model, each node is a random variable and has a role in the generative process. A shaded node indicates an observed variable and an unshaded node indicates a hidden (latent) variable. In this case, words in the corpus are the only data that we observe. The latent variables determine the random mixture of topics in the corpus and the distribution of words in the documents. The goal of LDA is to use the observed words to infer the hidden topic structure.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66070e8da21856ec34fc0b507e5d723e9475a567" translate="yes" xml:space="preserve">
          <source>In the multi-class and multi-label case, this is the average of the F1 score of each class with weighting depending on the &lt;code&gt;average&lt;/code&gt; parameter.</source>
          <target state="translated">В случае с несколькими классами и несколькими метками это средний балл F1 каждого класса с взвешиванием, зависящим от &lt;code&gt;average&lt;/code&gt; параметра.</target>
        </trans-unit>
        <trans-unit id="47604d7ff8f733fb868ecbca5a77b859a57fe5aa" translate="yes" xml:space="preserve">
          <source>In the multiclass case, the Matthews correlation coefficient can be &lt;a href=&quot;http://rk.kvl.dk/introduction/index.html&quot;&gt;defined&lt;/a&gt; in terms of a &lt;a href=&quot;generated/sklearn.metrics.confusion_matrix#sklearn.metrics.confusion_matrix&quot;&gt;&lt;code&gt;confusion_matrix&lt;/code&gt;&lt;/a&gt;\(C\) for \(K\) classes. To simplify the definition consider the following intermediate variables:</source>
          <target state="translated">В случае мультикласса коэффициент корреляции Мэтьюза может быть &lt;a href=&quot;http://rk.kvl.dk/introduction/index.html&quot;&gt;определен&lt;/a&gt; в терминах &lt;a href=&quot;generated/sklearn.metrics.confusion_matrix#sklearn.metrics.confusion_matrix&quot;&gt; &lt;code&gt;confusion_matrix&lt;/code&gt; &lt;/a&gt; \ (C \) для классов \ (K \). Чтобы упростить определение, рассмотрим следующие промежуточные переменные:</target>
        </trans-unit>
        <trans-unit id="b8d01a57cb617acafda7dfb6fdd570d7cb46be7c" translate="yes" xml:space="preserve">
          <source>In the multiclass case, the training algorithm uses the one-vs-rest (OvR) scheme if the &amp;lsquo;multi_class&amp;rsquo; option is set to &amp;lsquo;ovr&amp;rsquo;, and uses the cross- entropy loss if the &amp;lsquo;multi_class&amp;rsquo; option is set to &amp;lsquo;multinomial&amp;rsquo;. (Currently the &amp;lsquo;multinomial&amp;rsquo; option is supported only by the &amp;lsquo;lbfgs&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;newton-cg&amp;rsquo; solvers.)</source>
          <target state="translated">В случае мультикласса алгоритм обучения использует схему one-vs-rest (OvR), если опция multi_class установлена ​​на ovr, и использует потерю кросс-энтропии, если опция multi_class установлена ​​на multinomial '. (В настоящее время опция 'multinomial' поддерживается только решателями 'lbfgs', 'sag' и 'newton-cg'.)</target>
        </trans-unit>
        <trans-unit id="df1f72c5b54cf7ce11968ba990ade83d8b80475a" translate="yes" xml:space="preserve">
          <source>In the multiclass case, the training algorithm uses the one-vs-rest (OvR) scheme if the &amp;lsquo;multi_class&amp;rsquo; option is set to &amp;lsquo;ovr&amp;rsquo;, and uses the cross-entropy loss if the &amp;lsquo;multi_class&amp;rsquo; option is set to &amp;lsquo;multinomial&amp;rsquo;. (Currently the &amp;lsquo;multinomial&amp;rsquo; option is supported only by the &amp;lsquo;lbfgs&amp;rsquo;, &amp;lsquo;sag&amp;rsquo;, &amp;lsquo;saga&amp;rsquo; and &amp;lsquo;newton-cg&amp;rsquo; solvers.)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fc004eb44e3b89b80f2b6796f35d04551e921cc" translate="yes" xml:space="preserve">
          <source>In the multiclass case:</source>
          <target state="translated">В случае мультикласса:</target>
        </trans-unit>
        <trans-unit id="d77598124fa8bad46b51e89decd127c4c83bc1e3" translate="yes" xml:space="preserve">
          <source>In the multilabel case with binary label indicators, where the first label set [0,1] has an error:</source>
          <target state="translated">В случае с многомаркировочными индикаторами бинарных этикеток,где первый набор этикеток [0,1]имеет ошибку:</target>
        </trans-unit>
        <trans-unit id="4557110f167a92f3d0af48823270c458eb95839b" translate="yes" xml:space="preserve">
          <source>In the multilabel case with binary label indicators:</source>
          <target state="translated">В многомаркировочном корпусе с индикаторами бинарных этикеток:</target>
        </trans-unit>
        <trans-unit id="e898613ef6934f2809451f3fa3e427c4a4bd49ce" translate="yes" xml:space="preserve">
          <source>In the multilabel case, this calculates a confusion matrix per sample</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b2a464789db8978cf9674eef13e9bc3f4a4cf79" translate="yes" xml:space="preserve">
          <source>In the multilabel case:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3dbb497f0422701e359a6bab16a477019a81aa92" translate="yes" xml:space="preserve">
          <source>In the multilabel learning literature, OvR is also known as the binary relevance method.</source>
          <target state="translated">В учебной литературе по многомаркировке OvR также известен как метод двоичной релевантности.</target>
        </trans-unit>
        <trans-unit id="b098a0ed402e179dee6b5de05c6210f893507735" translate="yes" xml:space="preserve">
          <source>In the new space, each dimension is the distance to the cluster centers. Note that even if X is sparse, the array returned by &lt;code&gt;transform&lt;/code&gt; will typically be dense.</source>
          <target state="translated">В новом пространстве каждое измерение - это расстояние до центров кластеров. Обратите внимание, что даже если X является разреженным, массив, возвращаемый &lt;code&gt;transform&lt;/code&gt; , обычно будет плотным.</target>
        </trans-unit>
        <trans-unit id="a90aa674a36fbb7c4f65ac18f5e6a5a0eb4c7bc3" translate="yes" xml:space="preserve">
          <source>In the official &lt;a href=&quot;http://vis-www.cs.umass.edu/lfw/README.txt&quot;&gt;README.txt&lt;/a&gt; this task is described as the &amp;ldquo;Restricted&amp;rdquo; task. As I am not sure as to implement the &amp;ldquo;Unrestricted&amp;rdquo; variant correctly, I left it as unsupported for now.</source>
          <target state="translated">В официальном &lt;a href=&quot;http://vis-www.cs.umass.edu/lfw/README.txt&quot;&gt;README.txt&lt;/a&gt; эта задача описана как &amp;laquo;Ограниченная&amp;raquo;. Поскольку я не уверен, что правильно реализую вариант &amp;laquo;Без ограничений&amp;raquo;, я оставил его как неподдерживаемый на данный момент.</target>
        </trans-unit>
        <trans-unit id="5f046ff1a0210873f4b93ca532a15f1f001fc328" translate="yes" xml:space="preserve">
          <source>In the second figure, we show some regression result on a dataset of 6 sequences. Here we use the 1st, 2nd, 4th, and 5th sequences as the training set to make predictions on the 3rd and 6th sequences.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="901c760a214576d30b4ced7bbcce771984b42233" translate="yes" xml:space="preserve">
          <source>In the simple one-dimensional problem that we have seen in the example it is easy to see whether the estimator suffers from bias or variance. However, in high-dimensional spaces, models can become very difficult to visualize. For this reason, it is often helpful to use the tools described below.</source>
          <target state="translated">В простой одномерной задаче,которую мы видели в примере,легко увидеть,страдает ли оценщик от смещения или дисперсии.Однако в высокоразмерных пространствах модели могут стать очень трудно визуализируемыми.По этой причине часто бывает полезно использовать инструменты,описанные ниже.</target>
        </trans-unit>
        <trans-unit id="bada0a0c8458a65354b2c23e7134e865cc4bf85c" translate="yes" xml:space="preserve">
          <source>In the single label multiclass case, the rows of the returned matrix sum to 1.</source>
          <target state="translated">В случае с одной этикеткой мультикласса,строки возвращаемой матрицы складываются в 1.</target>
        </trans-unit>
        <trans-unit id="696912c12d134eed0fdc2e472302634288905dc5" translate="yes" xml:space="preserve">
          <source>In the small-samples situation, in which &lt;code&gt;n_samples&lt;/code&gt; is on the order of &lt;code&gt;n_features&lt;/code&gt; or smaller, sparse inverse covariance estimators tend to work better than shrunk covariance estimators. However, in the opposite situation, or for very correlated data, they can be numerically unstable. In addition, unlike shrinkage estimators, sparse estimators are able to recover off-diagonal structure.</source>
          <target state="translated">В ситуации с малыми выборками, когда &lt;code&gt;n_samples&lt;/code&gt; имеет порядок &lt;code&gt;n_features&lt;/code&gt; или меньше, разреженные оценки обратной ковариации, как правило, работают лучше, чем оценки сжатой ковариации. Однако в противоположной ситуации или для сильно коррелированных данных они могут быть численно нестабильными. Кроме того, в отличие от оценщиков усадки, разреженные оценщики способны восстанавливать недиагональную структуру.</target>
        </trans-unit>
        <trans-unit id="1c648bbbf8ddd269e7c36de7c1822a2705968fac" translate="yes" xml:space="preserve">
          <source>In the specific case of scikit-learn, it may be better to use joblib&amp;rsquo;s replacement of pickle (&lt;code&gt;dump&lt;/code&gt; &amp;amp; &lt;code&gt;load&lt;/code&gt;), which is more efficient on objects that carry large numpy arrays internally as is often the case for fitted scikit-learn estimators, but can only pickle to the disk and not to a string:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5f33dda5b96ece3c041650e9fa8db02e62bfd46" translate="yes" xml:space="preserve">
          <source>In the specific case of scikit-learn, it may be better to use joblib&amp;rsquo;s replacement of pickle (&lt;code&gt;joblib.dump&lt;/code&gt; &amp;amp; &lt;code&gt;joblib.load&lt;/code&gt;), which is more efficient on objects that carry large numpy arrays internally as is often the case for fitted scikit-learn estimators, but can only pickle to the disk and not to a string:</source>
          <target state="translated">В конкретном случае scikit-learn может быть лучше использовать замену pickle в &lt;code&gt;joblib.dump&lt;/code&gt; ( joblib.dump &amp;amp; &lt;code&gt;joblib.load&lt;/code&gt; ), которая более эффективна для объектов, которые несут большие массивы numpy внутри, как это часто бывает для встроенных scikit- выучить оценщики, но можно копировать только на диск, а не на строку:</target>
        </trans-unit>
        <trans-unit id="4d7c6f4a78fb7d42f5b6b076760e4c0fb27e052c" translate="yes" xml:space="preserve">
          <source>In the specific case of scikit-learn, it may be more interesting to use joblib&amp;rsquo;s replacement for pickle (&lt;code&gt;joblib.dump&lt;/code&gt; &amp;amp; &lt;code&gt;joblib.load&lt;/code&gt;), which is more efficient on big data but it can only pickle to the disk and not to a string:</source>
          <target state="translated">В конкретном случае scikit-learn может быть более интересным использовать замену joblib для pickle ( &lt;code&gt;joblib.dump&lt;/code&gt; &amp;amp; &lt;code&gt;joblib.load&lt;/code&gt; ), которая более эффективна для больших данных, но может обрабатывать только диск, а не строку :</target>
        </trans-unit>
        <trans-unit id="6bc18b31ba734fa9a1f609c8898b12e640d531fb" translate="yes" xml:space="preserve">
          <source>In the statistics community, it is common practice to perform multiple imputations, generating, for example, &lt;code&gt;m&lt;/code&gt; separate imputations for a single feature matrix. Each of these &lt;code&gt;m&lt;/code&gt; imputations is then put through the subsequent analysis pipeline (e.g. feature engineering, clustering, regression, classification). The &lt;code&gt;m&lt;/code&gt; final analysis results (e.g. held-out validation errors) allow the data scientist to obtain understanding of how analytic results may differ as a consequence of the inherent uncertainty caused by the missing values. The above practice is called multiple imputation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3fa57071e687f0bc6b84bf63b957df19fb1d89e" translate="yes" xml:space="preserve">
          <source>In the third figure, we demonstrate a classification model by training on 6 sequences and make predictions on another 5 sequences. The ground truth here is simply whether there is at least one &amp;lsquo;A&amp;rsquo; in the sequence. Here the model makes four correct classifications and fails on one.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e8940d2e745f9a24bd23b0a1547dcf715a870bb" translate="yes" xml:space="preserve">
          <source>In the total set of features, only the 4 first ones are significant. We can see that they have the highest score with univariate feature selection. The SVM assigns a large weight to one of these features, but also Selects many of the non-informative features. Applying univariate feature selection before the SVM increases the SVM weight attributed to the significant features, and will thus improve classification.</source>
          <target state="translated">В общем наборе функций значимы только 4 первых.Мы видим,что они набрали наибольшее количество баллов при одномерном выборе функций.SVM присваивает большой вес одной из этих функций,но также выбирает многие из неинформативных функций.Применение одномерного выделения функций до SVM увеличивает вес SVM,присваиваемый значимым функциям,и,таким образом,улучшает классификацию.</target>
        </trans-unit>
        <trans-unit id="5cab08ab26978fd8cb0ee3262a21c03baca4d379" translate="yes" xml:space="preserve">
          <source>In the transformed &lt;code&gt;X&lt;/code&gt;, the first column is the encoding of the feature with categories &amp;ldquo;male&amp;rdquo;/&amp;rdquo;female&amp;rdquo;, while the remaining 6 columns is the encoding of the 2 features with respectively 3 categories each.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3dd53135ff49dbe7e421a248bf614a3ea8f0d5e" translate="yes" xml:space="preserve">
          <source>In the vector quantization literature, &lt;code&gt;cluster_centers_&lt;/code&gt; is called the code book and each value returned by &lt;code&gt;predict&lt;/code&gt; is the index of the closest code in the code book.</source>
          <target state="translated">В литературе по векторному квантованию &lt;code&gt;cluster_centers_&lt;/code&gt; называется кодовой книгой, и каждое значение, возвращаемое &lt;code&gt;predict&lt;/code&gt; является индексом ближайшего кода в кодовой книге.</target>
        </trans-unit>
        <trans-unit id="71ea1d0e6870ae14110d577f25dbcd29b63431c3" translate="yes" xml:space="preserve">
          <source>In their 2004 paper &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;1&lt;/a&gt;, O. Ledoit and M. Wolf propose a formula to compute the optimal shrinkage coefficient \(\alpha\) that minimizes the Mean Squared Error between the estimated and the real covariance matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a63d5086bf9614df56a7612405271e0122a8145" translate="yes" xml:space="preserve">
          <source>In their 2004 paper &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;, O. Ledoit and M. Wolf propose a formula to compute the optimal shrinkage coefficient \(\alpha\) that minimizes the Mean Squared Error between the estimated and the real covariance matrix.</source>
          <target state="translated">В своей статье 2004 г. &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt; О. Ледуа и М. Вольф предлагают формулу для вычисления оптимального коэффициента усадки \ (\ alpha \), который минимизирует среднеквадратичную ошибку между оцененной и реальной ковариационной матрицей.</target>
        </trans-unit>
        <trans-unit id="ee9767309b3df05ebf7c392a0bb4e8915eee3d46" translate="yes" xml:space="preserve">
          <source>In these settings, the &lt;a href=&quot;../../modules/clustering#spectral-clustering&quot;&gt;Spectral clustering&lt;/a&gt; approach solves the problem know as &amp;lsquo;normalized graph cuts&amp;rsquo;: the image is seen as a graph of connected voxels, and the spectral clustering algorithm amounts to choosing graph cuts defining regions while minimizing the ratio of the gradient along the cut, and the volume of the region.</source>
          <target state="translated">В этих настройках подход &lt;a href=&quot;../../modules/clustering#spectral-clustering&quot;&gt;спектральной кластеризации&lt;/a&gt; решает проблему, известную как &amp;laquo;нормализованные разрезы графа&amp;raquo;: изображение рассматривается как граф связанных вокселей, а алгоритм спектральной кластеризации сводится к выбору разрезов графа, определяющих области, при минимизации соотношения градиента вдоль разрез, и объем области.</target>
        </trans-unit>
        <trans-unit id="e2e4475ec0999dd975ba681e19179d817d6681ae" translate="yes" xml:space="preserve">
          <source>In this case we would like to know if a model trained on a particular set of groups generalizes well to the unseen groups. To measure this, we need to ensure that all the samples in the validation fold come from groups that are not represented at all in the paired training fold.</source>
          <target state="translated">В этом случае нам хотелось бы знать,хорошо ли обобщена модель,обученная по определенному набору групп,к невидимым группам.Чтобы измерить это,мы должны убедиться,что все образцы в папке валидации пришли из групп,которые вообще не представлены в парной тренировочной папке.</target>
        </trans-unit>
        <trans-unit id="8e6586aaac37d3a887b7276aee6797fdd6471b11" translate="yes" xml:space="preserve">
          <source>In this case, &lt;code&gt;X_train&lt;/code&gt; and &lt;code&gt;X_test&lt;/code&gt; are guaranteed to have the same number of features. Another way to achieve the same result is to fix the number of features:</source>
          <target state="translated">В этом случае &lt;code&gt;X_train&lt;/code&gt; и &lt;code&gt;X_test&lt;/code&gt; гарантированно имеют одинаковое количество функций. Другой способ добиться того же результата - исправить ряд функций:</target>
        </trans-unit>
        <trans-unit id="c94c921d6a6a8582b29da8ef5a3a44fe1ea80a89" translate="yes" xml:space="preserve">
          <source>In this case, the classifier is fit upon instances each assigned multiple labels. The &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.multilabelbinarizer#sklearn.preprocessing.MultiLabelBinarizer&quot;&gt;&lt;code&gt;MultiLabelBinarizer&lt;/code&gt;&lt;/a&gt; is used to binarize the 2d array of multilabels to &lt;code&gt;fit&lt;/code&gt; upon. As a result, &lt;code&gt;predict()&lt;/code&gt; returns a 2d array with multiple predicted labels for each instance.</source>
          <target state="translated">В этом случае классификатор подходит для экземпляров, каждому из которых присвоено несколько меток. &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.multilabelbinarizer#sklearn.preprocessing.MultiLabelBinarizer&quot;&gt; &lt;code&gt;MultiLabelBinarizer&lt;/code&gt; &lt;/a&gt; используется для бинаризации в 2d массива multilabels в &lt;code&gt;fit&lt;/code&gt; после. В результате прогноз &lt;code&gt;predict()&lt;/code&gt; возвращает двумерный массив с несколькими предсказанными метками для каждого экземпляра.</target>
        </trans-unit>
        <trans-unit id="4367a423584d0b6ba622189fa17b21bb3e206f2c" translate="yes" xml:space="preserve">
          <source>In this case, the cross-validation retained the same ratio of classes across each CV split. Next we&amp;rsquo;ll visualize this behavior for a number of CV iterators.</source>
          <target state="translated">В этом случае перекрестная проверка сохранила одинаковое соотношение классов по каждому разделению резюме. Далее мы визуализируем это поведение для ряда итераторов CV.</target>
        </trans-unit>
        <trans-unit id="d121f450bc55250670235f93c8cd2083eb40a561" translate="yes" xml:space="preserve">
          <source>In this context, we can define the notions of precision, recall and F-measure:</source>
          <target state="translated">В этом контексте мы можем определить понятия точности,вспоминания и F-измерения:</target>
        </trans-unit>
        <trans-unit id="308ef10a0e6fa4feab74c9fff8eae0756aa171db" translate="yes" xml:space="preserve">
          <source>In this dataset, each sample corresponds to an insurance policy, i.e. a contract within an insurance company and an individual (policyholder). Available features include driver age, vehicle age, vehicle power, etc.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b69830262e95394b14f5a754f7290cc7372dc2b1" translate="yes" xml:space="preserve">
          <source>In this dataset, each sample corresponds to an insurance policy. Available features include driver age, vehicle age, vehicle power, etc.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b7e5d4a758a26d1b659ba54387246d5cebcf12f" translate="yes" xml:space="preserve">
          <source>In this example the dependent variable Y is set as a function of the input features: y = X*w + c. The coefficient vector w is randomly sampled from a normal distribution, whereas the bias term c is set to a constant.</source>
          <target state="translated">В данном примере зависимая переменная Y задается как функция входных признаков:y=X*w+c.Вектор коэффициента w случайным образом выбирается из нормального распределения,а член смещения c задается константой.</target>
        </trans-unit>
        <trans-unit id="5d530c717737ac885c81ddc70c9c4fe51f2f2e42" translate="yes" xml:space="preserve">
          <source>In this example the silhouette analysis is used to choose an optimal value for &lt;code&gt;n_clusters&lt;/code&gt;. The silhouette plot shows that the &lt;code&gt;n_clusters&lt;/code&gt; value of 3, 5 and 6 are a bad pick for the given data due to the presence of clusters with below average silhouette scores and also due to wide fluctuations in the size of the silhouette plots. Silhouette analysis is more ambivalent in deciding between 2 and 4.</source>
          <target state="translated">В этом примере анализ силуэта используется для выбора оптимального значения для &lt;code&gt;n_clusters&lt;/code&gt; . График силуэта показывает, что значения &lt;code&gt;n_clusters&lt;/code&gt; 3, 5 и 6 - плохой выбор для данных данных из-за наличия кластеров с оценками силуэта ниже среднего, а также из-за значительных колебаний в размере графиков силуэтов. Анализ силуэта более неоднозначен при выборе между 2 и 4.</target>
        </trans-unit>
        <trans-unit id="0b7aa73d7d4561b0e25989b4fff6f5d53474b724" translate="yes" xml:space="preserve">
          <source>In this example we compare some estimators for the purpose of missing feature imputation with &lt;a href=&quot;../../modules/generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;sklearn.impute.IterativeImputer&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="550c896ceafe31d2e76547c4031642097a79581f" translate="yes" xml:space="preserve">
          <source>In this example we compare the various initialization strategies for K-means in terms of runtime and quality of the results.</source>
          <target state="translated">В данном примере мы сравниваем различные стратегии инициализации K-средних по времени исполнения и качеству результатов.</target>
        </trans-unit>
        <trans-unit id="d9bed364e1f96090d42e72d8ad4e31b8f81dfc1d" translate="yes" xml:space="preserve">
          <source>In this example we prefer the &lt;code&gt;elasticnet&lt;/code&gt; penalty as it is often a good compromise between model compactness and prediction power. One can also further tune the &lt;code&gt;l1_ratio&lt;/code&gt; parameter (in combination with the regularization strength &lt;code&gt;alpha&lt;/code&gt;) to control this tradeoff.</source>
          <target state="translated">В этом примере мы предпочитаем штраф за &lt;code&gt;elasticnet&lt;/code&gt; поскольку это часто является хорошим компромиссом между компактностью модели и мощностью прогнозирования. Можно также дополнительно настроить параметр &lt;code&gt;l1_ratio&lt;/code&gt; (в сочетании с силой регуляризации &lt;code&gt;alpha&lt;/code&gt; ), чтобы контролировать этот компромисс.</target>
        </trans-unit>
        <trans-unit id="5f4ca84332e1fc2168e90c43c86e1d784ebd5f8c" translate="yes" xml:space="preserve">
          <source>In this example we see how to robustly fit a linear model to faulty data using the RANSAC algorithm.</source>
          <target state="translated">В данном примере мы видим,как с помощью алгоритма RANSAC надежно подогнать линейную модель к ошибочным данным.</target>
        </trans-unit>
        <trans-unit id="8b2f8ba713590c7461bca4df745b9c8578a9ee4a" translate="yes" xml:space="preserve">
          <source>In this example we will illustrate both approaches. We start by defining a few helper functions for loading the data and visualizing results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9cb7bd690b6a99c0206d146b05cd9c20c5a47dca" translate="yes" xml:space="preserve">
          <source>In this example we will investigate different imputation techniques:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38fc37287fc51222e73dd7c83e6c92e563107ff6" translate="yes" xml:space="preserve">
          <source>In this example you might try to:</source>
          <target state="translated">В этом примере вы можете попытаться:</target>
        </trans-unit>
        <trans-unit id="8a61e0fa0737723bbfe9d0174ce3aad285419f4d" translate="yes" xml:space="preserve">
          <source>In this example, &lt;code&gt;X&lt;/code&gt; is &lt;code&gt;float32&lt;/code&gt;, which is cast to &lt;code&gt;float64&lt;/code&gt; by &lt;code&gt;fit_transform(X)&lt;/code&gt;.</source>
          <target state="translated">В этом примере &lt;code&gt;X&lt;/code&gt; - это &lt;code&gt;float32&lt;/code&gt; , который приводится к &lt;code&gt;float64&lt;/code&gt; с помощью &lt;code&gt;fit_transform(X)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2812da8873763c11175cae962f9ab9000ab381c4" translate="yes" xml:space="preserve">
          <source>In this example, an image with connected circles is generated and spectral clustering is used to separate the circles.</source>
          <target state="translated">В этом примере генерируется изображение с соединенными окружностями,а для разделения окружностей используется спектральная кластеризация.</target>
        </trans-unit>
        <trans-unit id="79a59d7ef51f3f34cd5dc94073ebe194acbc66c6" translate="yes" xml:space="preserve">
          <source>In this example, both modeling approaches yield comparable performance metrics. For implementation reasons, the percentage of explained variance \(D^2\) is not available for the product model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69af0b849be70a0524a821dde21a609feb16811a" translate="yes" xml:space="preserve">
          <source>In this example, pixels are represented in a 3D-space and K-means is used to find 64 color clusters. In the image processing literature, the codebook obtained from K-means (the cluster centers) is called the color palette. Using a single byte, up to 256 colors can be addressed, whereas an RGB encoding requires 3 bytes per pixel. The GIF file format, for example, uses such a palette.</source>
          <target state="translated">В данном примере пиксели представлены в 3D-пространстве,а K-средние используются для поиска 64 цветовых кластеров.В литературе по обработке изображений кодовая книга,полученная из К-средних (кластерные центры),называется цветовой палитрой.С помощью одного байта можно адресовать до 256 цветов,в то время как для кодирования RGB требуется 3 байта на пиксел.Формат GIF-файлов,например,использует такую палитру.</target>
        </trans-unit>
        <trans-unit id="2f0fb947da0f2bfc5faf32b771a3cb10ff049eda" translate="yes" xml:space="preserve">
          <source>In this example, the numeric data is standard-scaled after mean-imputation, while the categorical data is one-hot encoded after imputing missing values with a new category (&lt;code&gt;'missing'&lt;/code&gt;).</source>
          <target state="translated">В этом примере числовые данные стандартно масштабируются после вменения среднего значения, в то время как категориальные данные кодируются в горячем режиме после вменения отсутствующих значений в новую категорию ( &lt;code&gt;'missing'&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="354a556d83cef273107f176ebec9db1b19a5c757" translate="yes" xml:space="preserve">
          <source>In this example, the sinusoid is approximated by a polynomial using different pairs of initial values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d88656bc2e040320cf9595554acac12be98f916c" translate="yes" xml:space="preserve">
          <source>In this example, we compare the estimation errors that are made when using various types of location and covariance estimates on contaminated Gaussian distributed data sets:</source>
          <target state="translated">В этом примере мы сравниваем ошибки оценки,которые делаются при использовании различных типов оценок местоположения и ковариаций на загрязненных гауссовских распределенных наборах данных:</target>
        </trans-unit>
        <trans-unit id="26a8e8ae6383655dcfc18bd00f71528218aa360e" translate="yes" xml:space="preserve">
          <source>In this example, we compute the permutation importance on the Wisconsin breast cancer dataset using &lt;a href=&quot;../../modules/generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;permutation_importance&lt;/code&gt;&lt;/a&gt;. The &lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;RandomForestClassifier&lt;/code&gt;&lt;/a&gt; can easily get about 97% accuracy on a test dataset. Because this dataset contains multicollinear features, the permutation importance will show that none of the features are important. One approach to handling multicollinearity is by performing hierarchical clustering on the features&amp;rsquo; Spearman rank-order correlations, picking a threshold, and keeping a single feature from each cluster.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b7bcaf87ef3b0730f7083836942b0b038810927" translate="yes" xml:space="preserve">
          <source>In this example, we give an overview of the &lt;a href=&quot;../../modules/generated/sklearn.compose.transformedtargetregressor#sklearn.compose.TransformedTargetRegressor&quot;&gt;&lt;code&gt;sklearn.compose.TransformedTargetRegressor&lt;/code&gt;&lt;/a&gt;. Two examples illustrate the benefit of transforming the targets before learning a linear regression model. The first example uses synthetic data while the second example is based on the Boston housing data set.</source>
          <target state="translated">В этом примере мы даем обзор &lt;a href=&quot;../../modules/generated/sklearn.compose.transformedtargetregressor#sklearn.compose.TransformedTargetRegressor&quot;&gt; &lt;code&gt;sklearn.compose.TransformedTargetRegressor&lt;/code&gt; &lt;/a&gt; . Два примера демонстрируют преимущества преобразования целей перед изучением модели линейной регрессии. В первом примере используются синтетические данные, а во втором примере - набор данных о жилищном строительстве в Бостоне.</target>
        </trans-unit>
        <trans-unit id="5f4a1f2d68c8f41cbf437ea7e001b2f1285b3f2f" translate="yes" xml:space="preserve">
          <source>In this example, we illustrate the use case in which different regressors are stacked together and a final linear penalized regressor is used to output the prediction. We compare the performance of each individual regressor with the stacking strategy. Stacking slightly improves the overall performance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd9410f53a0f1d1aa2f5ff77c7bafaf9751d4c08" translate="yes" xml:space="preserve">
          <source>In this example, we set the value of &lt;code&gt;gamma&lt;/code&gt; manually. To find good values for these parameters, we can use tools such as &lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;grid search&lt;/a&gt; and &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;cross validation&lt;/a&gt;.</source>
          <target state="translated">В этом примере мы устанавливаем значение &lt;code&gt;gamma&lt;/code&gt; вручную. Чтобы найти подходящие значения для этих параметров, мы можем использовать такие инструменты, как &lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;поиск по сетке&lt;/a&gt; и &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;перекрестная проверка&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="be5803bd91839824804bc4aadf2784b6ed10723a" translate="yes" xml:space="preserve">
          <source>In this example, we will compare the impurity-based feature importance of &lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;RandomForestClassifier&lt;/code&gt;&lt;/a&gt; with the permutation importance on the titanic dataset using &lt;a href=&quot;../../modules/generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;permutation_importance&lt;/code&gt;&lt;/a&gt;. We will show that the impurity-based feature importance can inflate the importance of numerical features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f66533d22104292e30bad75824b906ee4fc1acd9" translate="yes" xml:space="preserve">
          <source>In this example, we will construct display objects, &lt;a href=&quot;../../modules/generated/sklearn.metrics.confusionmatrixdisplay#sklearn.metrics.ConfusionMatrixDisplay&quot;&gt;&lt;code&gt;ConfusionMatrixDisplay&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../modules/generated/sklearn.metrics.roccurvedisplay#sklearn.metrics.RocCurveDisplay&quot;&gt;&lt;code&gt;RocCurveDisplay&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;../../modules/generated/sklearn.metrics.precisionrecalldisplay#sklearn.metrics.PrecisionRecallDisplay&quot;&gt;&lt;code&gt;PrecisionRecallDisplay&lt;/code&gt;&lt;/a&gt; directly from their respective metrics. This is an alternative to using their corresponding plot functions when a model&amp;rsquo;s predictions are already computed or expensive to compute. Note that this is advanced usage, and in general we recommend using their respective plot functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e0782ea6d7859077c07d60aaa0a30b1c4373f50" translate="yes" xml:space="preserve">
          <source>In this plot you can see the training scores and validation scores of an SVM for different values of the kernel parameter gamma. For very low values of gamma, you can see that both the training score and the validation score are low. This is called underfitting. Medium values of gamma will result in high values for both scores, i.e. the classifier is performing fairly well. If gamma is too high, the classifier will overfit, which means that the training score is good but the validation score is poor.</source>
          <target state="translated">На этом графике вы можете увидеть обучающие и проверочные оценки SVM для различных значений гамма-параметра ядра.Для очень низких значений гаммы,вы можете видеть,что и оценка обучения и оценка валидации низкие.Это называется подгонкой.Средние значения гаммы приведут к высоким значениям для обоих баллов,т.е.классификатор работает достаточно хорошо.Если гамма слишком высока,то классификатор будет переоснащаться,что означает,что тренировочный балл хороший,а валидационный балл плохой.</target>
        </trans-unit>
        <trans-unit id="2c39a03080473177a8509645110953edafebbd76" translate="yes" xml:space="preserve">
          <source>In this scheme, features and samples are defined as follows:</source>
          <target state="translated">В этой схеме особенности и образцы определяются следующим образом:</target>
        </trans-unit>
        <trans-unit id="5941fbb58c226f551ff80660bcd51a84bcc2bae1" translate="yes" xml:space="preserve">
          <source>In this section we will see how to:</source>
          <target state="translated">В этом разделе мы посмотрим,как это сделать:</target>
        </trans-unit>
        <trans-unit id="6ce5845b6414a0cfccffc603f3efdd4b47c7ce4b" translate="yes" xml:space="preserve">
          <source>In this section, we introduce the &lt;a href=&quot;https://en.wikipedia.org/wiki/Machine_learning&quot;&gt;machine learning&lt;/a&gt; vocabulary that we use throughout scikit-learn and give a simple learning example.</source>
          <target state="translated">В этом разделе мы познакомим вас со словарем &lt;a href=&quot;https://en.wikipedia.org/wiki/Machine_learning&quot;&gt;машинного обучения,&lt;/a&gt; который мы используем в scikit-learn, и дадим простой обучающий пример.</target>
        </trans-unit>
        <trans-unit id="e7b54ae8e73f20fa370a273bbb52814367b82582" translate="yes" xml:space="preserve">
          <source>In this snippet we make use of a &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;sklearn.svm.LinearSVC&lt;/code&gt;&lt;/a&gt; coupled with &lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt;&lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt;&lt;/a&gt; to evaluate feature importances and select the most relevant features. Then, a &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;sklearn.ensemble.RandomForestClassifier&lt;/code&gt;&lt;/a&gt; is trained on the transformed output, i.e. using only relevant features. You can perform similar operations with the other feature selection methods and also classifiers that provide a way to evaluate feature importances of course. See the &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt; examples for more details.</source>
          <target state="translated">В этом фрагменте мы используем &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;sklearn.svm.LinearSVC&lt;/code&gt; в&lt;/a&gt; сочетании с &lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt; &lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt; &lt;/a&gt; для оценки важности функций и выбора наиболее важных функций. Затем &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt; &lt;code&gt;sklearn.ensemble.RandomForestClassifier&lt;/code&gt; &lt;/a&gt; обучается на преобразованном выходе, то есть с использованием только соответствующих функций. Вы можете выполнять аналогичные операции с другими методами выбора функций, а также с классификаторами, которые, конечно, предоставляют способ оценки важности функций. См. Примеры &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; для более подробной информации.</target>
        </trans-unit>
        <trans-unit id="87aee0924ee2a28e2d573efd8e050c2a5c1632a3" translate="yes" xml:space="preserve">
          <source>In unsupervised learning we only have a dataset \(X = \{x_1, x_2, \dots, x_n \}\). How can this dataset be described mathematically? A very simple &lt;code&gt;continuous latent variable&lt;/code&gt; model for \(X\) is</source>
          <target state="translated">При обучении без учителя у нас есть только набор данных \ (X = \ {x_1, x_2, \ dots, x_n \} \). Как можно математически описать этот набор данных? Очень простая модель &lt;code&gt;continuous latent variable&lt;/code&gt; для \ (X \) - это</target>
        </trans-unit>
        <trans-unit id="a1efe7e891f38316d324e0fe7b8b483308bcbebf" translate="yes" xml:space="preserve">
          <source>Includes values in confusion matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c89a6ca6f29b888687c7afd577a282b5b95a2be5" translate="yes" xml:space="preserve">
          <source>Incorporating statistics from test data into the preprocessors makes cross-validation scores unreliable (known as &lt;em&gt;data leakage&lt;/em&gt;), for example in the case of scalers or imputing missing values.</source>
          <target state="translated">Включение статистики из тестовых данных в препроцессоры делает результаты перекрестной проверки ненадежными (известными как &lt;em&gt;утечка данных&lt;/em&gt; ), например, в случае масштабаторов или вменения пропущенных значений.</target>
        </trans-unit>
        <trans-unit id="4c33f1e1286c254eaae3fbe03197d5578f08f56a" translate="yes" xml:space="preserve">
          <source>Increasing &lt;code&gt;max_depth&lt;/code&gt; for AdaBoost lowers the standard deviation of the scores (but the average score does not improve).</source>
          <target state="translated">Увеличение &lt;code&gt;max_depth&lt;/code&gt; для AdaBoost снижает стандартное отклонение оценок (но средний балл не улучшается).</target>
        </trans-unit>
        <trans-unit id="e79b1358981354168a853701629e2643ba45bf93" translate="yes" xml:space="preserve">
          <source>Increasing false positive rates such that element i is the false positive rate of predictions with score &amp;gt;= thresholds[i].</source>
          <target state="translated">Увеличение количества ложных срабатываний, так что элемент i является показателем ложных срабатываний прогнозов с оценкой&amp;gt; = пороговые значения [i].</target>
        </trans-unit>
        <trans-unit id="3ca08d3a2216068596512fa76cc1f85e2464a3a8" translate="yes" xml:space="preserve">
          <source>Increasing thresholds on the decision function used to compute precision and recall.</source>
          <target state="translated">Увеличение пороговых значений функции принятия решений,используемой для расчета точности и вызова.</target>
        </trans-unit>
        <trans-unit id="7ae5f53b337e575381bac1d47d2d4a4d2e4839b6" translate="yes" xml:space="preserve">
          <source>Increasing true positive rates such that element i is the true positive rate of predictions with score &amp;gt;= thresholds[i].</source>
          <target state="translated">Увеличение истинно положительных показателей, так что элемент i является истинно положительным показателем прогнозов с оценкой&amp;gt; = пороговые значения [i].</target>
        </trans-unit>
        <trans-unit id="54206634ab03f8962d59d7c24e12c85ebd45b5e1" translate="yes" xml:space="preserve">
          <source>Incremental PCA</source>
          <target state="translated">Инкрементальный PCA</target>
        </trans-unit>
        <trans-unit id="0254682de6b7d13bd44669747bb093c1dca18b21" translate="yes" xml:space="preserve">
          <source>Incremental Principal Component Analysis.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="acaf3165fc4e0ddec759b9648ee12eed48089691" translate="yes" xml:space="preserve">
          <source>Incremental fit on a batch of samples.</source>
          <target state="translated">Инкрементная посадка на партию образцов.</target>
        </trans-unit>
        <trans-unit id="a79a34aec33f8c8b084e4316cf8e243a4d6601e6" translate="yes" xml:space="preserve">
          <source>Incremental fit with X.</source>
          <target state="translated">Инкрементальная посадка с Х.</target>
        </trans-unit>
        <trans-unit id="87210470540ea5af2ee40f330fdeea4017f1c0aa" translate="yes" xml:space="preserve">
          <source>Incremental fit with X. All of X is processed as a single batch.</source>
          <target state="translated">Инкрементная посадка с Х.Все Х обрабатывается как одна партия.</target>
        </trans-unit>
        <trans-unit id="5b9d567927b0a80924b0a28fdea6cf19b23d2e57" translate="yes" xml:space="preserve">
          <source>Incremental principal component analysis (IPCA) is typically used as a replacement for principal component analysis (PCA) when the dataset to be decomposed is too large to fit in memory. IPCA builds a low-rank approximation for the input data using an amount of memory which is independent of the number of input data samples. It is still dependent on the input data features, but changing the batch size allows for control of memory usage.</source>
          <target state="translated">Инкрементный анализ основных компонентов (IPCA)обычно используется в качестве замены анализа основных компонентов (PCA),когда разлагаемый набор данных слишком велик,чтобы поместиться в память.IPCA строит низкоуровневую аппроксимацию для входных данных,используя объем памяти,который не зависит от количества образцов входных данных.Она все еще зависит от особенностей входных данных,но изменение размера партии позволяет контролировать использование памяти.</target>
        </trans-unit>
        <trans-unit id="66088e706ece2d903ed2071fa2d42be9315774b6" translate="yes" xml:space="preserve">
          <source>Incremental principal components analysis (IPCA).</source>
          <target state="translated">Инкрементальный анализ основных компонентов (IPCA).</target>
        </trans-unit>
        <trans-unit id="ef7722207a6c2343d08e45f401cd00ccd19381c7" translate="yes" xml:space="preserve">
          <source>Incrementally fit the model to data.</source>
          <target state="translated">Инкрементально подогнать модель под данные.</target>
        </trans-unit>
        <trans-unit id="505bf67b8aa7cec37d64a9ce9b03d73f70b38b8b" translate="yes" xml:space="preserve">
          <source>Incrementally fit the model to data. Fit a separate model for each output variable.</source>
          <target state="translated">Инкрементально подогнать модель под данные.Подгоните отдельную модель для каждой выходной переменной.</target>
        </trans-unit>
        <trans-unit id="e7353e5363cf13ee1c3efdc144e75ff650f6c2d1" translate="yes" xml:space="preserve">
          <source>Incrementally trained logistic regression (when given the parameter &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e12e704fa3eb16be83d58c2167c9c4f83379a1d" translate="yes" xml:space="preserve">
          <source>Indeed many estimators are designed with the assumption that each feature takes values close to zero or more importantly that all features vary on comparable scales. In particular, metric-based and gradient-based estimators often assume approximately standardized data (centered features with unit variances). A notable exception are decision tree-based estimators that are robust to arbitrary scaling of the data.</source>
          <target state="translated">Действительно,многие оценщики разрабатываются исходя из предположения,что каждый элемент принимает значения,близкие к нулю,или,что более важно,что все элементы различаются на сопоставимых шкалах.В частности,оценщики на основе метрик и градиентов часто предполагают приблизительно стандартизированные данные (центрированные характеристики с отклонениями в единицах).Заметным исключением являются оценки на основе дерева решений,которые устойчивы к произвольному масштабированию данных.</target>
        </trans-unit>
        <trans-unit id="9cde6c3dae7189a85444fb86f682cb4ecd226cef" translate="yes" xml:space="preserve">
          <source>Indeed, from the plot above the most important factor in determining WAGE appears to be the variable UNION, even if our intuition might tell us that variables like EXPERIENCE should have more impact.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7933c6d72de999f40e22d3286d9c782fd636305b" translate="yes" xml:space="preserve">
          <source>Independent Component Analysis: ICA</source>
          <target state="translated">Независимый компонентный анализ:ICA</target>
        </trans-unit>
        <trans-unit id="d170598045cdc9e2df037718a96d1706ed03e640" translate="yes" xml:space="preserve">
          <source>Independent component analysis separates a multivariate signal into additive subcomponents that are maximally independent. It is implemented in scikit-learn using the &lt;a href=&quot;generated/sklearn.decomposition.fastica#sklearn.decomposition.FastICA&quot;&gt;&lt;code&gt;Fast ICA&lt;/code&gt;&lt;/a&gt; algorithm. Typically, ICA is not used for reducing dimensionality but for separating superimposed signals. Since the ICA model does not include a noise term, for the model to be correct, whitening must be applied. This can be done internally using the whiten argument or manually using one of the PCA variants.</source>
          <target state="translated">Независимый компонентный анализ разделяет многомерный сигнал на аддитивные подкомпоненты, которые максимально независимы. Это реализовано в scikit-learn с использованием алгоритма &lt;a href=&quot;generated/sklearn.decomposition.fastica#sklearn.decomposition.FastICA&quot;&gt; &lt;code&gt;Fast ICA&lt;/code&gt; &lt;/a&gt; . Обычно ICA используется не для уменьшения размерности, а для разделения наложенных сигналов. Поскольку модель ICA не включает термин &amp;laquo;шум&amp;raquo;, для того, чтобы модель была правильной, необходимо применить отбеливание. Это можно сделать внутренне, используя аргумент whiten, или вручную, используя один из вариантов PCA.</target>
        </trans-unit>
        <trans-unit id="420bdf88d0c37e0c49c684e7be83be0c3065749b" translate="yes" xml:space="preserve">
          <source>Independent component analysis, a latent variable model with non-Gaussian latent variables.</source>
          <target state="translated">Независимый компонентный анализ,модель латентных переменных с негауссовыми латентными переменными.</target>
        </trans-unit>
        <trans-unit id="e81fd2ba1ed4351b51becec6b3e044be03272d29" translate="yes" xml:space="preserve">
          <source>Independent parameter in poly/sigmoid kernel.</source>
          <target state="translated">Независимый параметр в поли/сигмоидном ядре.</target>
        </trans-unit>
        <trans-unit id="75b2e172573134b992419919380eaa4d379125c8" translate="yes" xml:space="preserve">
          <source>Independent parameter in poly/sigmoid kernel. 0 by default.</source>
          <target state="translated">Независимый параметр в поли/сигмоидном ядре.0 по умолчанию.</target>
        </trans-unit>
        <trans-unit id="93ccb8f475af3ead0828a4d704d80fd7c1bcca2a" translate="yes" xml:space="preserve">
          <source>Independent term in decision function.</source>
          <target state="translated">Независимый срок в функции принятия решений.</target>
        </trans-unit>
        <trans-unit id="d60b4ce63cb13d9b546e71bb468305b122e1ff12" translate="yes" xml:space="preserve">
          <source>Independent term in decision function. Set to 0.0 if &lt;code&gt;fit_intercept = False&lt;/code&gt;.</source>
          <target state="translated">Независимый член в функции принятия решения. Установите 0,0, если &lt;code&gt;fit_intercept = False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="62ca36e367478a373b265bf6692ac1dd0b87c736" translate="yes" xml:space="preserve">
          <source>Independent term in kernel function. It is only significant in &amp;lsquo;poly&amp;rsquo; and &amp;lsquo;sigmoid&amp;rsquo;.</source>
          <target state="translated">Независимый член в функции ядра. Он имеет значение только в &amp;laquo;поли&amp;raquo; и &amp;laquo;сигмовиде&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="498514c5789196d4e7f38be6d2ccefad9084f660" translate="yes" xml:space="preserve">
          <source>Independent term in poly and sigmoid kernels. Ignored by other kernels.</source>
          <target state="translated">Независимый термин в поли-и сигмовидных ядрах.Игнорируется другими ядрами.</target>
        </trans-unit>
        <trans-unit id="c818388cffefe0c1449b9099e6b8c434f2466b05" translate="yes" xml:space="preserve">
          <source>Independent term in the decision function.</source>
          <target state="translated">Независимый срок в функции принятия решений.</target>
        </trans-unit>
        <trans-unit id="b8069da00c91cf6e966b739b57f9cbe347e859d2" translate="yes" xml:space="preserve">
          <source>Independent term in the linear model.</source>
          <target state="translated">Независимый термин в линейной модели.</target>
        </trans-unit>
        <trans-unit id="191e8d234bde29edd43499e6f75fe115a0a775a9" translate="yes" xml:space="preserve">
          <source>Independent term in the linear model. Set to 0.0 if &lt;code&gt;fit_intercept = False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c78017fad7dc4be13e21b61b07a09cb5931df33" translate="yes" xml:space="preserve">
          <source>Index of the cluster each sample belongs to.</source>
          <target state="translated">Индекс кластера,к которому принадлежит каждая выборка.</target>
        </trans-unit>
        <trans-unit id="79bbc01c7afbd569e88078c06011f6a142dc18ba" translate="yes" xml:space="preserve">
          <source>Index of the column of X to be swapped.</source>
          <target state="translated">Индекс столбца X для замены.</target>
        </trans-unit>
        <trans-unit id="ed1d58c02de7a13d74564b832a9effc7dd7512f7" translate="yes" xml:space="preserve">
          <source>Index of the row of X to be swapped.</source>
          <target state="translated">Индекс строки X,которую нужно поменять.</target>
        </trans-unit>
        <trans-unit id="ec76f2d92b2be403363a104dc4a87849c9c331a9" translate="yes" xml:space="preserve">
          <source>Indexable data-structures can be arrays, lists, dataframes or scipy sparse matrices with consistent first dimension.</source>
          <target state="translated">Индексируемыми структурами данных могут быть массивы,списки,кадры данных или научные разрозненные матрицы с последовательным первым измерением.</target>
        </trans-unit>
        <trans-unit id="436737ead6b730ec05aa4979d3ab186eb46b0b4a" translate="yes" xml:space="preserve">
          <source>Indexes the data on its second axis. Integers are interpreted as positional columns, while strings can reference DataFrame columns by name. A scalar string or int should be used where &lt;code&gt;transformer&lt;/code&gt; expects X to be a 1d array-like (vector), otherwise a 2d array will be passed to the transformer. A callable is passed the input data &lt;code&gt;X&lt;/code&gt; and can return any of the above.</source>
          <target state="translated">Индексирует данные на своей второй оси. Целые числа интерпретируются как позиционные столбцы, а строки могут ссылаться на столбцы DataFrame по имени. Скалярная строка или int должна использоваться там, где &lt;code&gt;transformer&lt;/code&gt; ожидает, что X будет 1d массивом (вектором), иначе 2d массив будет передан преобразователю. Вызываемому объекту передаются входные данные &lt;code&gt;X&lt;/code&gt; , и он может возвращать любые из вышеперечисленных.</target>
        </trans-unit>
        <trans-unit id="14c06502f716a74d640158c7430747c2d65e82bc" translate="yes" xml:space="preserve">
          <source>Indexes the data on its second axis. Integers are interpreted as positional columns, while strings can reference DataFrame columns by name. A scalar string or int should be used where &lt;code&gt;transformer&lt;/code&gt; expects X to be a 1d array-like (vector), otherwise a 2d array will be passed to the transformer. A callable is passed the input data &lt;code&gt;X&lt;/code&gt; and can return any of the above. To select multiple columns by name or dtype, you can use &lt;a href=&quot;sklearn.compose.make_column_selector#sklearn.compose.make_column_selector&quot;&gt;&lt;code&gt;make_column_selector&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="33324894ea0a98c1ef1f880dc97967e00c913318" translate="yes" xml:space="preserve">
          <source>Indicate that func accepts a sparse matrix as input. If validate is False, this has no effect. Otherwise, if accept_sparse is false, sparse matrix inputs will cause an exception to be raised.</source>
          <target state="translated">Укажите,что эта функция принимает на вход разреженную матрицу.Если валидная-False,то это не имеет никакого эффекта.Иначе,если accept_sparse будет ложным,то разреженные входные данные матрицы вызовут исключение.</target>
        </trans-unit>
        <trans-unit id="eb7cd0d8cb7fae1e80a3e28d3771772ae8884b48" translate="yes" xml:space="preserve">
          <source>Indicate that the input X array should be checked before calling &lt;code&gt;func&lt;/code&gt;. The possibilities are:</source>
          <target state="translated">Укажите, что входной массив X должен быть проверен перед вызовом &lt;code&gt;func&lt;/code&gt; . Возможности:</target>
        </trans-unit>
        <trans-unit id="ae286e88bfa268243cfd38132ccb40e58428bfed" translate="yes" xml:space="preserve">
          <source>Indicate that transform should forward the y argument to the inner callable.</source>
          <target state="translated">Укажите,что преобразование должно перенаправить аргумент y во внутренний вызываемый.</target>
        </trans-unit>
        <trans-unit id="9d241566a403a6506d3449cf17d407da2b6e2613" translate="yes" xml:space="preserve">
          <source>Indicates an ordering for the class labels</source>
          <target state="translated">Указывает на заказ этикеток класса</target>
        </trans-unit>
        <trans-unit id="5daac4dde04b0b12288306e9a52dc06ec04c0c8f" translate="yes" xml:space="preserve">
          <source>Indicates an ordering for the class labels. All entries should be unique (cannot contain duplicate classes).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1159dbae1b402de01888d0798e1ed328834a2b28" translate="yes" xml:space="preserve">
          <source>Indicates the monotonic constraint to enforce on each feature. -1, 1 and 0 respectively correspond to a positive constraint, negative constraint and no constraint. Read more in the &lt;a href=&quot;../ensemble#monotonic-cst-gbdt&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61bd4246c5310fe8fe14b7816d8991bfb310307e" translate="yes" xml:space="preserve">
          <source>Indicator used to add binary indicators for missing values. &lt;code&gt;None&lt;/code&gt; if add_indicator is False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f992c130abda366b807271662ae2ae17c7305e7" translate="yes" xml:space="preserve">
          <source>Indices according to which X will be subsampled.</source>
          <target state="translated">Индексы,в соответствии с которыми Х будет подвергаться субдискретизации.</target>
        </trans-unit>
        <trans-unit id="13d9e5d82e7cab8325fb7843fa12831d259a69f1" translate="yes" xml:space="preserve">
          <source>Indices of &lt;code&gt;components_&lt;/code&gt; in the training set.</source>
          <target state="translated">Индексы &lt;code&gt;components_&lt;/code&gt; в обучающей выборке.</target>
        </trans-unit>
        <trans-unit id="eeb5984b85169d88759ac10f7fe9d10f5246bc74" translate="yes" xml:space="preserve">
          <source>Indices of active variables at the end of the path.</source>
          <target state="translated">Индексы активных переменных в конце пути.</target>
        </trans-unit>
        <trans-unit id="fff8cc57ffbca371ebcb1bd938597e8d339ff509" translate="yes" xml:space="preserve">
          <source>Indices of cluster centers</source>
          <target state="translated">Индексы кластерных центров</target>
        </trans-unit>
        <trans-unit id="2c68ceeb78b6311d290c266259420efe85138435" translate="yes" xml:space="preserve">
          <source>Indices of columns in the dataset that belong to the bicluster.</source>
          <target state="translated">Индексы колонок в наборе данных,которые принадлежат билюстрам.</target>
        </trans-unit>
        <trans-unit id="d4d2ad6637f8190da67b396b7e452baac4f7558f" translate="yes" xml:space="preserve">
          <source>Indices of core samples.</source>
          <target state="translated">Индексы образцов керна.</target>
        </trans-unit>
        <trans-unit id="82cd4a5510ba380bec1e554cdeb5d721222207d6" translate="yes" xml:space="preserve">
          <source>Indices of features for a given plot. A tuple of one integer will plot a partial dependence curve of one feature. A tuple of two integers will plot a two-way partial dependence curve as a contour plot.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c71c298055da26ecac09942b9115f5fc73f7640d" translate="yes" xml:space="preserve">
          <source>Indices of rows in the dataset that belong to the bicluster.</source>
          <target state="translated">Индексы строк в наборе данных,которые принадлежат билюстрам.</target>
        </trans-unit>
        <trans-unit id="d9c7ee7b4f1a89fde0903f47c0111e0985a4d274" translate="yes" xml:space="preserve">
          <source>Indices of samples used when training the estimators. &lt;code&gt;None&lt;/code&gt; when &lt;code&gt;estimator&lt;/code&gt; does not have &lt;code&gt;_pairwise&lt;/code&gt; attribute.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5ecd973c55633f90c97a971f74a80fe11af3310" translate="yes" xml:space="preserve">
          <source>Indices of support vectors.</source>
          <target state="translated">Индексы векторов поддержки.</target>
        </trans-unit>
        <trans-unit id="9ccd80ce2c5e0529264583d000f7c9651892271d" translate="yes" xml:space="preserve">
          <source>Indices of the approximate nearest points in the population matrix.</source>
          <target state="translated">Индексы приблизительных ближайших точек в матрице населения.</target>
        </trans-unit>
        <trans-unit id="94147abfa5127a12fe3c3b0c7153a32b171d401a" translate="yes" xml:space="preserve">
          <source>Indices of the nearest points in the population matrix.</source>
          <target state="translated">Индексы ближайших точек в матрице населения.</target>
        </trans-unit>
        <trans-unit id="3db97f5586a1b88a52d6998bdcb68ce6424bd44e" translate="yes" xml:space="preserve">
          <source>Individual decision trees can be interpreted easily by simply visualizing the tree structure. Gradient boosting models, however, comprise hundreds of regression trees thus they cannot be easily interpreted by visual inspection of the individual trees. Fortunately, a number of techniques have been proposed to summarize and interpret gradient boosting models.</source>
          <target state="translated">Отдельные деревья решений можно легко интерпретировать,просто визуализируя структуру дерева.Модели с градиентным увеличением,однако,состоят из сотен деревьев регрессии,поэтому они не могут быть легко интерпретированы визуальным осмотром отдельных деревьев.К счастью,был предложен ряд методик для обобщения и интерпретации моделей повышения градиента.</target>
        </trans-unit>
        <trans-unit id="dda28c621b6ebb6a75808a25ba823af15c148423" translate="yes" xml:space="preserve">
          <source>Individual decision trees intrinsically perform feature selection by selecting appropriate split points. This information can be used to measure the importance of each feature; the basic idea is: the more often a feature is used in the split points of a tree the more important that feature is. This notion of importance can be extended to decision tree ensembles by simply averaging the feature importance of each tree (see &lt;a href=&quot;#random-forest-feature-importance&quot;&gt;Feature importance evaluation&lt;/a&gt; for more details).</source>
          <target state="translated">Отдельные деревья решений по сути выполняют выбор функций путем выбора соответствующих точек разделения. Эта информация может использоваться для измерения важности каждой функции; Основная идея такова: чем чаще функция используется в точках разделения дерева, тем важнее эта функция. Это понятие важности может быть распространено на ансамбли деревьев решений путем простого усреднения важности характеристик каждого дерева (подробнее см. В разделе &lt;a href=&quot;#random-forest-feature-importance&quot;&gt;Оценка важности&lt;/a&gt; характеристик).</target>
        </trans-unit>
        <trans-unit id="a4ca1ad4d7f055ed4989788bfa5efeb8e8f28cc3" translate="yes" xml:space="preserve">
          <source>Individual decision trees intrinsically perform feature selection by selecting appropriate split points. This information can be used to measure the importance of each feature; the basic idea is: the more often a feature is used in the split points of a tree the more important that feature is. This notion of importance can be extended to decision tree ensembles by simply averaging the impurity-based feature importance of each tree (see &lt;a href=&quot;#random-forest-feature-importance&quot;&gt;Feature importance evaluation&lt;/a&gt; for more details).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3bee3019e098ad6b65e2ff793a0e712b529b8f1" translate="yes" xml:space="preserve">
          <source>Individual samples are assumed to be files stored a two levels folder structure such as the following:</source>
          <target state="translated">Предполагается,что отдельными примерами являются файлы,хранящиеся в двухуровневой структуре папок,как,например,следующее:</target>
        </trans-unit>
        <trans-unit id="675958cddf4afedd9b3304a64c0ebf41aefd317c" translate="yes" xml:space="preserve">
          <source>Individual steps may also be replaced as parameters, and non-final steps may be ignored by setting them to &lt;code&gt;'passthrough'&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0fc01010c6e24d626cecdd62fd33ec75c0c929c" translate="yes" xml:space="preserve">
          <source>Individual steps may also be replaced as parameters, and non-final steps may be ignored by setting them to &lt;code&gt;None&lt;/code&gt;:</source>
          <target state="translated">Отдельные шаги также можно заменить как параметры, а нефинальные шаги можно игнорировать, установив для них значение &lt;code&gt;None&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="1005c12f11beba0f3b6f9dd6a7112c31b922588d" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample</source>
          <target state="translated">Индивидуальные веса для каждого образца</target>
        </trans-unit>
        <trans-unit id="1fda26bba39629c5adc019bfeebf23b6ea1cae92" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample raises error if sample_weight is passed and base_estimator fit method does not support it.</source>
          <target state="translated">Индивидуальные веса для каждого примера повышают ошибку,если передан sample_weight и метод подгонки base_estimator не поддерживает его.</target>
        </trans-unit>
        <trans-unit id="fa75f1e4d13933a19ded3aa860129fc7cab3ed7d" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample, ignored if None is passed.</source>
          <target state="translated">Индивидуальные веса для каждого образца,игнорируются,если Никто не пройден.</target>
        </trans-unit>
        <trans-unit id="00c4a167764cbf2ab25348f070ffdca6c4a1b160" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample. If given a float, every sample will have the same weight.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f445327eb6fc51f2a25624b484ae69f8950143fb" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample. If given a float, every sample will have the same weight. If sample_weight is not None and solver=&amp;rsquo;auto&amp;rsquo;, the solver will be set to &amp;lsquo;cholesky&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="718e842694bb04faf5cc021c83e29c576f98c12d" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample. If sample_weight is not None and solver=&amp;rsquo;auto&amp;rsquo;, the solver will be set to &amp;lsquo;cholesky&amp;rsquo;.</source>
          <target state="translated">Индивидуальные веса для каждого образца. Если sample_weight не равно None и solver = 'auto', решатель будет установлен на 'cholesky'.</target>
        </trans-unit>
        <trans-unit id="080f186426dd365e06ebdb64bb4da000ce313de8" translate="yes" xml:space="preserve">
          <source>Inductive Clustering</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="390c151b41ae038aa81f8d4fccaa7e2c366dd521" translate="yes" xml:space="preserve">
          <source>Inertia can be recognized as a measure of how internally coherent clusters are. It suffers from various drawbacks:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4facccaf3ac8930794a0b5d15e4cd633a166965" translate="yes" xml:space="preserve">
          <source>Inertia is not a normalized metric: we just know that lower values are better and zero is optimal. But in very high-dimensional spaces, Euclidean distances tend to become inflated (this is an instance of the so-called &amp;ldquo;curse of dimensionality&amp;rdquo;). Running a dimensionality reduction algorithm such as &lt;a href=&quot;decomposition#pca&quot;&gt;Principal component analysis (PCA)&lt;/a&gt; prior to k-means clustering can alleviate this problem and speed up the computations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f221e5d04a99f60098722e2605a369c8541e6c9c" translate="yes" xml:space="preserve">
          <source>Inertia is not a normalized metric: we just know that lower values are better and zero is optimal. But in very high-dimensional spaces, Euclidean distances tend to become inflated (this is an instance of the so-called &amp;ldquo;curse of dimensionality&amp;rdquo;). Running a dimensionality reduction algorithm such as &lt;a href=&quot;pca&quot;&gt;PCA&lt;/a&gt; prior to k-means clustering can alleviate this problem and speed up the computations.</source>
          <target state="translated">Инерция - это не нормализованная метрика: мы просто знаем, что более низкие значения лучше, а ноль - оптимально. Но в очень многомерных пространствах евклидовы расстояния имеют тенденцию становиться завышенными (это пример так называемого &amp;laquo;проклятия размерности&amp;raquo;). Запуск алгоритма уменьшения размерности, такого как &lt;a href=&quot;pca&quot;&gt;PCA,&lt;/a&gt; перед кластеризацией k-средних может облегчить эту проблему и ускорить вычисления.</target>
        </trans-unit>
        <trans-unit id="e010b0c9058bbaf9975d3f14818f3861029f83a1" translate="yes" xml:space="preserve">
          <source>Inertia makes the assumption that clusters are convex and isotropic, which is not always the case. It responds poorly to elongated clusters, or manifolds with irregular shapes.</source>
          <target state="translated">Инерция делает допущение,что кластеры выпуклые и изотропные,что не всегда так.Она плохо реагирует на вытянутые кластеры или коллекторы неправильной формы.</target>
        </trans-unit>
        <trans-unit id="2d57b1c4d1f958efe3710f23677dd552a8a1384c" translate="yes" xml:space="preserve">
          <source>Inertia, or the within-cluster sum of squares criterion, can be recognized as a measure of how internally coherent clusters are. It suffers from various drawbacks:</source>
          <target state="translated">Инерция,или внутрикластерный критерий суммы квадратов,может быть признан как мера того,насколько внутренне когерентны кластеры.Она страдает от различных недостатков:</target>
        </trans-unit>
        <trans-unit id="1b9b7d4cd56309d7954eee8c5d88a8d58559a22d" translate="yes" xml:space="preserve">
          <source>Inference of the model can be time consuming.</source>
          <target state="translated">Вывод модели может занять много времени.</target>
        </trans-unit>
        <trans-unit id="52570031388abf13077117eb25231bb2412ec6ba" translate="yes" xml:space="preserve">
          <source>Inferred batch size from &lt;code&gt;batch_size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3406f3eade82db35711ae0ecbcd4dea59f7e1be" translate="yes" xml:space="preserve">
          <source>Inferred value for &lt;code&gt;increasing&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f5d2c4b74b9f6de8f1a369f5793fd5ad3db1bd0" translate="yes" xml:space="preserve">
          <source>Influence of outliers on location and covariance estimates</source>
          <target state="translated">Влияние отклонений на оценку местоположения и ковариаций</target>
        </trans-unit>
        <trans-unit id="b8c700f6663aab653644d35fb6aa9a0e53919c01" translate="yes" xml:space="preserve">
          <source>Information on how to contribute. This also contains useful information for advanced users, for example how to build their own estimators.</source>
          <target state="translated">Информация о том,как внести свой вклад.Она также содержит полезную информацию для продвинутых пользователей,например,о том,как строить свои собственные оценки.</target>
        </trans-unit>
        <trans-unit id="c4fbdb7aab44015fbed39936864f9255a99074c1" translate="yes" xml:space="preserve">
          <source>Information-criterion based model selection is very fast, but it relies on a proper estimation of degrees of freedom, are derived for large samples (asymptotic results) and assume the model is correct, i.e. that the data are actually generated by this model. They also tend to break when the problem is badly conditioned (more features than samples).</source>
          <target state="translated">Выбор модели на основе информационных критериев очень быстр,но он основывается на правильной оценке степеней свободы,выводится для больших выборок (асимптотических результатов)и предполагает,что модель корректна,т.е.данные реально генерируются этой моделью.Они также имеют тенденцию ломаться,когда проблема плохо решена (больше признаков,чем выборки).</target>
        </trans-unit>
        <trans-unit id="132062fafb54cb7d1e8b42d922906ff561bc3d9c" translate="yes" xml:space="preserve">
          <source>Inherits from SGDClassifier. &lt;code&gt;Perceptron()&lt;/code&gt; is equivalent to &lt;code&gt;SGDClassifier(loss=&quot;perceptron&quot;, eta0=1, learning_rate=&quot;constant&quot;, penalty=None)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="897de0e7da29095e5d730f2c7102743d023bc056" translate="yes" xml:space="preserve">
          <source>Initial value for alpha (precision of the noise). If not set, alpha_init is 1/Var(y).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5584ccc82484d2c61a85300c7acd35cb5205fef6" translate="yes" xml:space="preserve">
          <source>Initial value for lambda (precision of the weights). If not set, lambda_init is 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="168bf67b39abe0e5515698a4ec915c75e07ca524" translate="yes" xml:space="preserve">
          <source>Initial value for the dictionary for warm restart scenarios.</source>
          <target state="translated">Начальное значение для словаря для сценариев теплого рестарта.</target>
        </trans-unit>
        <trans-unit id="64b2b9f72c239478fc1b9e586ac8147218ca87bd" translate="yes" xml:space="preserve">
          <source>Initial value for the sparse code for warm restart scenarios.</source>
          <target state="translated">Начальное значение для разреженного кода для сценариев теплого рестарта.</target>
        </trans-unit>
        <trans-unit id="1a6282c9a9baf1c9231fe6132d9510c0860835e2" translate="yes" xml:space="preserve">
          <source>Initial values for the components for warm restart scenarios.</source>
          <target state="translated">Начальные значения для компонентов для сценариев теплого рестарта.</target>
        </trans-unit>
        <trans-unit id="ff1f0a80e07dd6cd648bd3a5e935a909ec2cb299" translate="yes" xml:space="preserve">
          <source>Initial values for the loadings for warm restart scenarios.</source>
          <target state="translated">Начальные значения нагрузок для сценариев теплого рестарта.</target>
        </trans-unit>
        <trans-unit id="e597ad1e68022a1929058718fd92959e281b3619" translate="yes" xml:space="preserve">
          <source>Initialization of embedding. Possible options are &amp;lsquo;random&amp;rsquo;, &amp;lsquo;pca&amp;rsquo;, and a numpy array of shape (n_samples, n_components). PCA initialization cannot be used with precomputed distances and is usually more globally stable than random initialization.</source>
          <target state="translated">Инициализация встраивания. Возможные варианты: 'random', 'pca' и массив формы numpy (n_samples, n_components). Инициализация PCA не может использоваться с предварительно вычисленными расстояниями и обычно более стабильна в глобальном масштабе, чем случайная инициализация.</target>
        </trans-unit>
        <trans-unit id="726483459f359a8ededc78286c7835b11430e40a" translate="yes" xml:space="preserve">
          <source>Initialization of the linear transformation. Possible options are &amp;lsquo;auto&amp;rsquo;, &amp;lsquo;pca&amp;rsquo;, &amp;lsquo;lda&amp;rsquo;, &amp;lsquo;identity&amp;rsquo;, &amp;lsquo;random&amp;rsquo;, and a numpy array of shape (n_features_a, n_features_b).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e644154875d3e41452e4b87177ec7a98e4e47540" translate="yes" xml:space="preserve">
          <source>Initialization value for coefficients of logistic regression. Useless for liblinear solver.</source>
          <target state="translated">Значение инициализации для коэффициентов логистической регрессии.Бесполезно для литологического решателя.</target>
        </trans-unit>
        <trans-unit id="ed7011971816dd0f1903ad54a411facedaee4ded" translate="yes" xml:space="preserve">
          <source>Initialization value of the sparse codes. Only used if &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt;.</source>
          <target state="translated">Значение инициализации разреженных кодов. Используется, только если &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8989f9ab8650a480a58e2f03b20f1b5428df4549" translate="yes" xml:space="preserve">
          <source>Initialization value of the sparse codes. Only used if &lt;code&gt;algorithm='lasso_cd'&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f66672d1a211feccb2663e524389cc7bbdc9544" translate="yes" xml:space="preserve">
          <source>Initialize self. See help(type(self)) for accurate signature.</source>
          <target state="translated">Инициализируй себя.См.справку(type(self))для точной подписи.</target>
        </trans-unit>
        <trans-unit id="ccac906d8789727d67e839b8a0f34db2f9002a71" translate="yes" xml:space="preserve">
          <source>Initializing components, sampling from layers during fit.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4694fddfebcd07057574f3bedbe073aecef8cbe" translate="yes" xml:space="preserve">
          <source>Inliers are labeled 1, while outliers are labeled -1. The predict method makes use of a threshold on the raw scoring function computed by the estimator. This scoring function is accessible through the &lt;code&gt;score_samples&lt;/code&gt; method, while the threshold can be controlled by the &lt;code&gt;contamination&lt;/code&gt; parameter.</source>
          <target state="translated">Выбросы помечены как 1, а выбросы - как -1. В методе прогнозирования используется порог необработанной функции оценки, вычисляемый оценщиком. Эта функция оценки доступна через метод &lt;code&gt;score_samples&lt;/code&gt; , в то время как порог может контролироваться параметром &lt;code&gt;contamination&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2495be2cc170e277a5d9d5dd99a3f779ff0175c9" translate="yes" xml:space="preserve">
          <source>Inner sufficient statistics that are kept by the algorithm. Passing them at initialization is useful in online settings, to avoid loosing the history of the evolution. A (n_components, n_components) is the dictionary covariance matrix. B (n_features, n_components) is the data approximation matrix</source>
          <target state="translated">Внутренняя статистика,которая поддерживается алгоритмом.Передача их при инициализации полезна в онлайн-настройках,чтобы не потерять историю эволюции.A (n_components,n_components)-ковариационная матрица словаря.B (n_features,n_components)-матрица аппроксимации данных.</target>
        </trans-unit>
        <trans-unit id="06dcf06c32dda54c31aa74eee694be9763d822e4" translate="yes" xml:space="preserve">
          <source>Inner sufficient statistics that are kept by the algorithm. Passing them at initialization is useful in online settings, to avoid losing the history of the evolution. A (n_components, n_components) is the dictionary covariance matrix. B (n_features, n_components) is the data approximation matrix</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4cb705151cf2a5dcfea8029a0e74d39c67469fa5" translate="yes" xml:space="preserve">
          <source>Inplace column scaling of a CSC/CSR matrix.</source>
          <target state="translated">Масштабирование столбцов матрицы CSC/CSR.</target>
        </trans-unit>
        <trans-unit id="15ad21d3f40808b965488683b0faaff07ad4b5e9" translate="yes" xml:space="preserve">
          <source>Inplace column scaling of a CSR matrix.</source>
          <target state="translated">Введите масштабирование столбца матрицы CSR.</target>
        </trans-unit>
        <trans-unit id="75290bdbc975498c98c7572ec067e43ddceb0c68" translate="yes" xml:space="preserve">
          <source>Inplace row normalize using the l1 norm</source>
          <target state="translated">Ввод строк нормализуется по норме l1.</target>
        </trans-unit>
        <trans-unit id="bc0180825da8415aba8c76f27c29d7e471b70c2a" translate="yes" xml:space="preserve">
          <source>Inplace row normalize using the l2 norm</source>
          <target state="translated">Ввод строки нормализуется с помощью нормы l2</target>
        </trans-unit>
        <trans-unit id="d91ae689358e283ef6d343e24e55244f1fb1cad2" translate="yes" xml:space="preserve">
          <source>Inplace row scaling of a CSR or CSC matrix.</source>
          <target state="translated">Введите масштабирование строк матрицы CSR или CSC.</target>
        </trans-unit>
        <trans-unit id="16ca749420dd58126c1f3f4ccf95ce2fc49387c9" translate="yes" xml:space="preserve">
          <source>Input array.</source>
          <target state="translated">Входной массив.</target>
        </trans-unit>
        <trans-unit id="f6fcca00499ce6b21e6114d56b450f6d3d43ccb2" translate="yes" xml:space="preserve">
          <source>Input checker utility for building a cross-validator</source>
          <target state="translated">Утилита проверки входа для построения перекрёстного валидатора</target>
        </trans-unit>
        <trans-unit id="3f43a2e4863dbf39da8cfbd5e4e557f3052ec269" translate="yes" xml:space="preserve">
          <source>Input data</source>
          <target state="translated">Исходные данные</target>
        </trans-unit>
        <trans-unit id="a2e2ac083ce3186e216de5448418ffc50e83a494" translate="yes" xml:space="preserve">
          <source>Input data for prediction.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41aa04ac5754100b497c803419573444b7e1d42b" translate="yes" xml:space="preserve">
          <source>Input data representation and sparsity</source>
          <target state="translated">Представление входных данных и редкость</target>
        </trans-unit>
        <trans-unit id="66a8a4e34fe15bd5eafb5d984d77b9c0e3866728" translate="yes" xml:space="preserve">
          <source>Input data that will be transformed.</source>
          <target state="translated">Вводите данные,которые будут преобразованы.</target>
        </trans-unit>
        <trans-unit id="fbb05f66a147e8520f226c078931507f60d0caac" translate="yes" xml:space="preserve">
          <source>Input data that will be transformed. It cannot be sparse.</source>
          <target state="translated">Вводите данные,которые будут преобразованы.Они не могут быть скудными.</target>
        </trans-unit>
        <trans-unit id="1e3e0a570b83c9cbe639106afeb9bedd23e3fcfd" translate="yes" xml:space="preserve">
          <source>Input data to be transformed.</source>
          <target state="translated">Входные данные для преобразования.</target>
        </trans-unit>
        <trans-unit id="071feefe9143dba47a473de169ba49367bfce443" translate="yes" xml:space="preserve">
          <source>Input data to be transformed. Use &lt;code&gt;dtype=np.float32&lt;/code&gt; for maximum efficiency. Sparse matrices are also supported, use sparse &lt;code&gt;csr_matrix&lt;/code&gt; for maximum efficiency.</source>
          <target state="translated">Входные данные для преобразования. Используйте &lt;code&gt;dtype=np.float32&lt;/code&gt; для максимальной эффективности. Также поддерживаются разреженные матрицы, используйте разреженные &lt;code&gt;csr_matrix&lt;/code&gt; для максимальной эффективности.</target>
        </trans-unit>
        <trans-unit id="688f24dc1e25fac1dc510cf29e6e51a5cdee42ba" translate="yes" xml:space="preserve">
          <source>Input data used to build forests. Use &lt;code&gt;dtype=np.float32&lt;/code&gt; for maximum efficiency.</source>
          <target state="translated">Исходные данные, используемые для построения лесов. Используйте &lt;code&gt;dtype=np.float32&lt;/code&gt; для максимальной эффективности.</target>
        </trans-unit>
        <trans-unit id="ece9df27fcdc2d8935842ef4ed6ac1e8d53f8b6c" translate="yes" xml:space="preserve">
          <source>Input data, of which specified subsets are used to fit the transformers.</source>
          <target state="translated">Входные данные,из которых заданные подмножества используются для подгонки трансформаторов.</target>
        </trans-unit>
        <trans-unit id="8c020a67c0398f86d112987222d02c36283701ba" translate="yes" xml:space="preserve">
          <source>Input data, target values.</source>
          <target state="translated">Входные данные,целевые значения.</target>
        </trans-unit>
        <trans-unit id="0d15fc28721eb2bcf2d53de59215da674d786463" translate="yes" xml:space="preserve">
          <source>Input data, used to fit transformers.</source>
          <target state="translated">Входные данные,используемые для подгонки трансформаторов.</target>
        </trans-unit>
        <trans-unit id="6db69e17f58030ae15478a3e504e982203a8ead7" translate="yes" xml:space="preserve">
          <source>Input data, where &amp;ldquo;n_samples&amp;rdquo; is the number of samples and &amp;ldquo;n_features&amp;rdquo; is the number of features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aee2f5203193bb3069f6e2f7b08e833e91d53841" translate="yes" xml:space="preserve">
          <source>Input data, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the number of features.</source>
          <target state="translated">Входные данные, где &lt;code&gt;n_samples&lt;/code&gt; - количество выборок, а &lt;code&gt;n_features&lt;/code&gt; - количество функций.</target>
        </trans-unit>
        <trans-unit id="8f9c683e36e31c7c38c7e8d6a2daeccf181d4c94" translate="yes" xml:space="preserve">
          <source>Input data, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">Входные данные,где n_samples-количество примеров,а n_features-количество признаков.</target>
        </trans-unit>
        <trans-unit id="260753716624ad2077f13f38ada17a33c0f48cba" translate="yes" xml:space="preserve">
          <source>Input data.</source>
          <target state="translated">Вводите данные.</target>
        </trans-unit>
        <trans-unit id="c414149f534c72aa4d2016c93404604f17aa41fd" translate="yes" xml:space="preserve">
          <source>Input data. Columns are assumed to have unit norm.</source>
          <target state="translated">Вводите данные.Считается,что столбцы имеют единичную норму.</target>
        </trans-unit>
        <trans-unit id="fc921091c020b61d18864b21129c4eb989ef6d69" translate="yes" xml:space="preserve">
          <source>Input data. If &lt;code&gt;None&lt;/code&gt;, the output will be the pairwise similarities between all samples in &lt;code&gt;X&lt;/code&gt;.</source>
          <target state="translated">Входные данные. Если &lt;code&gt;None&lt;/code&gt; , то выход будет попарные сходство между всеми образцами в &lt;code&gt;X&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="afaf08d18a1423dc1a78bf3492e5ce0eb50d8638" translate="yes" xml:space="preserve">
          <source>Input data. If &lt;code&gt;dissimilarity=='precomputed'&lt;/code&gt;, the input should be the dissimilarity matrix.</source>
          <target state="translated">Входные данные. Если &lt;code&gt;dissimilarity=='precomputed'&lt;/code&gt; , входными данными должна быть матрица несходства.</target>
        </trans-unit>
        <trans-unit id="c7e2acaca5145e47486c9c2928ab5532aee98fd4" translate="yes" xml:space="preserve">
          <source>Input data. If X is not provided, only the global clustering step is done.</source>
          <target state="translated">Вводите данные.Если X не предоставляется,то выполняется только глобальный шаг кластеризации.</target>
        </trans-unit>
        <trans-unit id="609eafdfc25268bf81369faed57dc8b7d067fce7" translate="yes" xml:space="preserve">
          <source>Input data. Note that if X is None then the Gram matrix must be specified, i.e., cannot be None or False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d39fe8b9c923e952612de77f70ad5aff60c34542" translate="yes" xml:space="preserve">
          <source>Input object to check / convert.</source>
          <target state="translated">Ввод объекта для проверки/преобразования.</target>
        </trans-unit>
        <trans-unit id="ca7fd27e447d5e335b2e80d1b2bb1406dceac239" translate="yes" xml:space="preserve">
          <source>Input object to check / convert. Must be two-dimensional and square, otherwise a ValueError will be raised.</source>
          <target state="translated">Ввод объекта для проверки/преобразования.Должен быть двумерным и квадратным,иначе будет поднят ValueError.</target>
        </trans-unit>
        <trans-unit id="f24bf584af83fad1f47a5035ff05cdc62fd1daef" translate="yes" xml:space="preserve">
          <source>Input points.</source>
          <target state="translated">Точки входа.</target>
        </trans-unit>
        <trans-unit id="71b2d21e1f2e71c0dcf88bd09dfe9ef6fd499ea3" translate="yes" xml:space="preserve">
          <source>Input targets</source>
          <target state="translated">Входные цели</target>
        </trans-unit>
        <trans-unit id="b58e4bce1b7ebb41f970a06dbe933522f9ad2c46" translate="yes" xml:space="preserve">
          <source>Input targets multiplied by X: X.T * y</source>
          <target state="translated">Входные цели,умноженные на X:X.T*y</target>
        </trans-unit>
        <trans-unit id="69a0e9f3a009e8ccbba64367545e9fbe88306b19" translate="yes" xml:space="preserve">
          <source>Input targets.</source>
          <target state="translated">Входные цели.</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
